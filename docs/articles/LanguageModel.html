<!DOCTYPE html>
<html lang="ja">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>LanguageModelã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§ | ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="LanguageModelã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
<meta name="author" content="AkihikoWATANABE">
<meta property="og:locale" content="ja">
<meta name="description" content="LanguageModel #EfficiencyImprovement #Pocket #NLP #ReinforcementLearning #In-ContextLearning #read-later #One-Line Notes #AutomaticPromptOptimization">
<meta property="og:description" content="LanguageModel #EfficiencyImprovement #Pocket #NLP #ReinforcementLearning #In-ContextLearning #read-later #One-Line Notes #AutomaticPromptOptimization">
<link rel="canonical" href="http://akihikowatanabe.github.io/paper_notes/articles/LanguageModel.html">
<meta property="og:url" content="http://akihikowatanabe.github.io/paper_notes/articles/LanguageModel.html">
<meta property="og:site_name" content="ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2025-10-23T00:46:27+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="LanguageModelã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"AkihikoWATANABE"},"dateModified":"2025-10-23T00:46:27+00:00","datePublished":"2025-10-23T00:46:27+00:00","description":"LanguageModel #EfficiencyImprovement #Pocket #NLP #ReinforcementLearning #In-ContextLearning #read-later #One-Line Notes #AutomaticPromptOptimization","headline":"LanguageModelã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§","mainEntityOfPage":{"@type":"WebPage","@id":"http://akihikowatanabe.github.io/paper_notes/articles/LanguageModel.html"},"url":"http://akihikowatanabe.github.io/paper_notes/articles/LanguageModel.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="icon" href="">
  <link rel="canonical" href="http://akihikowatanabe.github.io">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/main.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/custom_button.css">
  <script src="/paper_notes/assets/js/main.js"></script>
  <script src="https://d3js.org/d3.v5.min.js"></script><link type="application/atom+xml" rel="alternate" href="http://akihikowatanabe.github.io/paper_notes/feed.xml" title="ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ">
<script>
  function showMore(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "block";
          
      // ã“ã®ãƒœã‚¿ãƒ³ã®å‚ç…§ã‚’å–å¾—ã—ã¦éè¡¨ç¤ºã«ã—ã¾ã™
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "none";
      }
          
      // hideãƒœã‚¿ãƒ³ã®å‚ç…§ã‚’å–å¾—ã—ã¦è¡¨ç¤ºã—ã¾ã™
      const hideButton = contentDiv.querySelector('button[onclick^="hideContent"]');
      if (hideButton) {
        hideButton.style.display = "block";
      }
    }
  }

  function hideContent(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "none";
  
      // moreãƒœã‚¿ãƒ³ã®å‚ç…§ã‚’å–å¾—ã—ã¦è¡¨ç¤ºã—ã¾ã™
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "block";
      }
  
      // ã“ã®ãƒœã‚¿ãƒ³ã‚’éš ã—ã¾ã™
      const hideButtons = document.querySelectorAll('button[onclick^="hideContent"]');
      const hideButton = hideButtons[index];
      if (hideButton) {
        hideButton.style.display = "none";
      }
    }
  }
</script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js" async></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe-lightbox.umd.min.js" async></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe.umd.min.js" async></script>
<link href="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/photoswipe.min.css" rel="stylesheet">
<style>
  .pswp .pswp__container .pswp__img {
    background-color: white;
  }
</style>

<script>
  function initPhotoSwipe() {
    let customOptions = {};

    try {
      const data = `{"gallery"=>"section.main", "children"=>"a.photo-swipe", "bgOpacity"=>0.8, "padding"=>{"top"=>20, "bottom"=>40, "left"=>100, "right"=>100}}`.replaceAll("=>", ":");
      customOptions = JSON.parse(data);
    } catch (e) {
      console.info("Invalid custom photo previewer options! " + e.message);
    }

    // Define object and gallery options
    const options = Object.assign(
      {
        gallery: "section.main",
        children: "a.photo-swipe",
        photo_scale: 2,
        // dynamic import is not supported in UMD version
        pswpModule: PhotoSwipe,
      },
      customOptions
    );

    const galleryEl = document.querySelector(options.gallery);
    if (!galleryEl) {
      return;
    }

    const imgEls = [];
    const els = galleryEl.querySelectorAll("img:not(.emoji)");
    els.forEach((el) => {
      if (el.src.trim() == "") {
        return;
      }
      if (!imgEls.includes(el)) {
        imgEls.push(el);
      }
    });

    if (imgEls.length === 0) {
      return;
    }

    imgEls.forEach((imgEl) => {
      imgEl.outerHTML = `
      <a class="photo-swipe"
        href="${imgEl.src}"
        data-pswp-width="${
          Math.max(imgEl.naturalWidth, imgEl.width) * options.photo_scale
        }"
        data-pswp-height="${
          Math.max(imgEl.naturalHeight, imgEl.height) * options.photo_scale
        }"
        data-pswp-caption="${imgEl.getAttribute("caption") || imgEl.alt}"
        target="_blank">
        ${imgEl.outerHTML}
      </a>`;
    });

    // Initialize PhotoSwipe 5
    var lightbox = new PhotoSwipeLightbox(options);

    lightbox.init();
  }

  window.addEventListener("load", initPhotoSwipe);
</script>
<meta name="google-site-verification" content="u_DTTPcCZ806iq51zgirHyWq3556HUKGq8AQfH91iFI">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-P70KSB88WH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-P70KSB88WH');
  </script>

<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"},"svg":{"fontCache":"global"}}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>





































































































































<header class="site-header site-header-transparent" role="banner">

  <div class="wrapper">
    <div class="site-header-inner">
<span class="site-brand"><a class="site-brand-inner" rel="author" href="/paper_notes/">
  <img class="site-favicon" title="ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ" src="" onerror="this.style.display='none'">
  ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger">
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewbox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
              </svg>
            </span>
          </label>

          <div class="trigger">









<span class="page-link">



<div id="google_translate_element" style="display: none;">
</div>

<span class="ct-language">
  <ul class="list-unstyled ct-language-dropdown">
    
      <li>
        <a href="#" class="lang-select" data-lang="en">
          
          <img src="https://cdn.countryflags.com/thumbs/united-states-of-america/flag-400.png" title="English">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="fr">
          
          <img src="https://cdn.countryflags.com/thumbs/france/flag-400.png" title="French">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="zh-CN">
          
          <img src="https://cdn.countryflags.com/thumbs/china/flag-400.png" title="Chinese(Simple)">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ja">
          
          <img src="https://cdn.countryflags.com/thumbs/japan/flag-400.png" title="Japanese">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ko">
          
          <img src="https://cdn.countryflags.com/thumbs/south-korea/flag-400.png" title="Korean">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ru">
          
          <img src="https://cdn.countryflags.com/thumbs/russia/flag-400.png" title="Russian">
          
        </a>
      </li>
    
  </ul>
</span>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'ja',
    autoDisplay: false,
    layout: google.translate.TranslateElement.InlineLayout.VERTICAL
  }, 'google_translate_element');

  // Links to cross-origin destinations are unsafe
  var gll = document.getElementsByClassName('goog-logo-link')[0];
  if (gll) {
    gll.setAttribute('rel', 'noopener');
  }

  function restoreLang() {
    var iframe = document.getElementsByClassName('goog-te-banner-frame')[0];
    if (!iframe) return;

    var innerDoc = iframe.contentDocument || iframe.contentWindow.document;
    var restore_el = innerDoc.getElementsByTagName("button");

    for (var i = 0; i < restore_el.length; i++) {
      if (restore_el[i].id.indexOf("restore") >= 0) {
        restore_el[i].click();
        var close_el = innerDoc.getElementsByClassName("goog-close-link");
        close_el[0].click();
        return;
      }
    }
  }

  function triggerHtmlEvent(element, eventName) {
    var event;
    if (document.createEvent) {
      event = document.createEvent('HTMLEvents');
      event.initEvent(eventName, true, true);
      element.dispatchEvent(event);
    } else {
      event = document.createEventObject();
      event.eventType = eventName;
      element.fireEvent('on' + event.eventType, event);
    }
  }

  var googleCombo = document.querySelector("select.goog-te-combo");
  var langSelect = document.querySelector('.ct-language');
  langSelect.addEventListener('click', function(event) {
    if (!event.target) {
      return;
    }

    var selected = document.querySelector('.ct-language .ct-language-selected');
    if (selected) {
      selected.classList.remove('ct-language-selected');
    }

    var target = event.target;
    while (target && target !== langSelect ) {
      if (target.matches('.lang-select')) {
        break;
      }
      target = target.parentElement;
    }

    if (target && target.matches('.lang-select')) {
      var lang = target.getAttribute('data-lang');
      if (googleCombo.value == lang) {
        restoreLang();
      } else {
        target.parentElement.classList.add('ct-language-selected');
        googleCombo.value = lang;
        triggerHtmlEvent(googleCombo, 'change');
      }
    }

    event.preventDefault();
  });
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit" async></script>
</span>
</div>
        </nav>
</div>
  </div>
</header>

<script>
  function initHeader() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;

    function storeScrollData() {
      var y = getScrollPos().y;documentElement.setAttribute("data-header-transparent", "");var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0) ? true : false;
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
    }

    window.addEventListener('scroll', function(e) {
      storeScrollData();
    });

    storeScrollData();
  }
  document.addEventListener('DOMContentLoaded', initHeader);
</script>


























































































































































<style>
    html .page-banner .page-banner-img > *:first-child {
      opacity: 0.4;
    }

    html[data-theme="dark"] .page-banner .page-banner-img > *:first-child {
      opacity: 0.2872;
    }
  </style>
<section class="page-banner">
    <div class="page-banner-img">
<div style="background-image: url(/paper_notes/assets/images/banner.png)"></div>
        <img class="img-placeholder" src="/paper_notes/assets/images/banner.png">
</div>
    <div class="wrapper">
      <div class="page-banner-inner">
<header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ</h1>
  <h2 class="post-subtitle">å‹‰å¼·ã—ãŸè«–æ–‡ã‚„æŠ€è¡“ç­‰ã®æƒ…å ±ã‚’Githubã®Issueã«ãƒ¡ãƒ¢ã£ã¦ã„ã‚‹ã²ã¨ã®ãƒ–ãƒ­ã‚°ã€‚
ãã‚Œãªã‚Šã«ãƒ¡ãƒ¢ã®é‡ãŒè“„ç©ã•ã‚Œã¦ããŸã®ã§ã€ä¸€åº¦æ•´ç†ã—ãŸã„ãªã¨æ€ã„ãƒ–ãƒ­ã‚°ã¯ã˜ã‚ã¦ã¿ã¾ã—ãŸï¼
è‡ªç„¶è¨€èªå‡¦ç†(NLP), æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ (RecommenderSystem), Educational Data Mining (EDM), Learning Analytics (LA)ãªã©ã®åˆ†é‡ã®ãƒ¡ãƒ¢ãŒå¤šã„ã¨æ€ã„ã¾ã™ã€‚
æœ€è¿‘ã¯ç‰¹ã«LLMã®å‹‰å¼·ãŒå¤šã‚ã§ã™ :)</h2>

  <div class="post-meta">
    <time class="dt-published" datetime="2025-10-23T00:46:27+00:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Oct 23, 2025
    </time><span class="post-author left-vsplit"><i class="fa fa-pencil"></i> AkihikoWATANABE</span>
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 43 hours 21 mins</span>
  </div></header>
</div>
    </div>
  </section><script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    hashValue = decodeURIComponent(hashValue);
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('off' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<div id="click-to-top" class="click-to-top">
  <i class="fa fa-arrow-up"></i>
</div>
<script>
  (function () {
    const clickToTop = document.getElementById('click-to-top');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 100) {
        clickToTop.classList.add('show')
      }else {
        clickToTop.classList.remove('show')
      }
    });
    clickToTop.addEventListener('click', () => {
      window.smoothScrollTo(0);
    });
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <h2 id="LanguageModel"> LanguageModel</h2>
<div class="visible-content">
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/AutomaticPromptOptimization.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptOptimization</a>


<br>


<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3362" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Prompt-MII: Meta-Learning Instruction Induction for LLMs, Emily Xiao+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- PROMPT-MIIã¨ã„ã†æ–°ã—ã„æŒ‡ç¤ºèª˜å°ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ç¸®å°ã™ã‚‹ã“ã¨ã§ã€ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã€‚3,000ä»¥ä¸Šã®åˆ†é¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€90ã®æœªè¦‹ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã—ãŸçµæœã€ä¸‹æµãƒ¢ãƒ‡ãƒ«ã®å“è³ªã‚’4-9 F1ãƒã‚¤ãƒ³ãƒˆå‘ä¸Šã•ã›ã€å¿…è¦ãªãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’3-13å€å‰Šæ¸›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1980644772902789603?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚¿ã‚¹ã‚¯ã®examplar/demonstrationã‹ã‚‰ã‚¿ã‚¹ã‚¯ã«é–¢ã™ã‚‹descriptionï¼‰ï¼instruction)ã‚’ç”Ÿæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã€ç”Ÿæˆã•ã‚ŒãŸinstructionã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€manyshotã§ICLã™ã‚‹ã‚ˆã‚Šã‚‚ã€å°‘ãªã„ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã§åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’é”æˆã™ã‚‹ã¨ã„ã£ãŸè©±ã«è¦‹ãˆã‚‹ã€‚ã©ã†ã„ã†instructionã«ãªã‚‹ã®ã‹ãŒéå¸¸ã«èˆˆå‘³ãŒã‚ã‚‹ã€‚A.6å‚ç…§ã®ã“ã¨ã€‚ç´°ã‹ãå…·ä½“çš„ã ãŒã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªæŒ‡ç¤ºãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªinstructionã¨ãªã£ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/ee02024a-725d-47a1-9b8c-46fed1dbcb8f" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/363dd369-79d3-4b37-b4de-f880e2fb746d" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>


<br>


<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3356" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Holistic Agent Leaderboard: The Missing Infrastructure for AI Agent  Evaluation, Sayash Kapoor+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è©•ä¾¡ã«ãŠã‘ã‚‹èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€Holistic Agent Leaderboardï¼ˆHALï¼‰ã‚’å°å…¥ã€‚æ¨™æº–åŒ–ã•ã‚ŒãŸè©•ä¾¡ãƒãƒ¼ãƒã‚¹ã«ã‚ˆã‚Šè©•ä¾¡æ™‚é–“ã‚’çŸ­ç¸®ã—ã€ä¸‰æ¬¡å…ƒåˆ†æã‚’é€šã˜ã¦21,730ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è©•ä¾¡ã€‚é«˜ã„æ¨è«–åŠªåŠ›ãŒç²¾åº¦ã‚’ä½ä¸‹ã•ã›ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã€LLMã‚’ç”¨ã„ãŸãƒ­ã‚°æ¤œæŸ»ã§æ–°ãŸãªè¡Œå‹•ã‚’æ˜ã‚‰ã‹ã«ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè©•ä¾¡ã®æ¨™æº–åŒ–ã‚’é€²ã‚ã€ç¾å®Ÿä¸–ç•Œã§ã®ä¿¡é ¼æ€§å‘ä¸Šã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://hal.cs.princeton.edu" target="_blank" rel="noopener noreferrer">https://hal.cs.princeton.edu</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1979893861431550372?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚ˆã€40,000ãƒ‰ãƒ«ï¼ï¼ŸğŸ’¸</p>
<p>LLM Agentã«é–¢ã™ã‚‹ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ãƒ¢ãƒ‡ãƒ«ç¾¤ã‚’è¤‡æ•°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§åŒã˜æ¡ä»¶ã§apple to appleãªæ¯”è¼ƒã¨ãªã‚‹ã‚ˆã†ã«è©•ä¾¡ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/142b550e-f708-441c-acca-583af413d26f" alt="image" loading="lazy"><br><br>ä»¥ä¸‹å…ƒãƒã‚¹ãƒˆã‚ˆã‚Š:<br><br>ã“ã®è©•ä¾¡ãƒãƒ¼ãƒã‚¹ã¯ã€10è¡Œæœªæº€ã®ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã§è©•ä¾¡ã‚’å®Ÿè¡Œå¯èƒ½ï¼ˆå…ƒãƒã‚¹ãƒˆï¼‰<br><br>çŸ¥è¦‹ã¨ã—ã¦ã¯<br>- reasoning effortã‚’ä¸Šã’ã¦ã‚‚å¤šãã®å ´åˆæ€§èƒ½å‘ä¸Šã«ã¯å¯„ä¸ã›ãš(21/36ã®ã‚±ãƒ¼ã‚¹ã§æ€§èƒ½å‘ä¸Šã›ãš)<br>- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«è¿‘é“ã‚’ã™ã‚‹ï¼ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ç›´æ¥å‚ç…§ã—ã«è¡Œããªã©ï¼‰<br>- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯éå¸¸ã«ã‚³ã‚¹ãƒˆã®é«˜ã„æ‰‹æ®µã‚’å–ã‚‹ã“ã¨ã‚‚ã‚ã‚Šï¼ˆãƒ•ãƒ©ã‚¤ãƒˆäºˆç´„ã«ãŠã„ã¦èª¤ã£ãŸç©ºæ¸¯ã‹ã‚‰äºˆç´„ã—ãŸã‚Šã€ãƒ¦ãƒ¼ã‚¶ã«éå‰°ãªè¿”é‡‘ã‚’ã—ãŸã‚Šã€èª¤ã£ãŸã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ã«è«‹æ±‚ã—ãŸã‚Šãªã©ï¼‰<br>- ã‚³ã‚¹ãƒˆã¨acc.ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’åˆ†æã—ãŸçµæœã€æœ€ã‚‚é«˜ä¾¡ãªOpus4.1ã¯ä¸€åº¦ã—ã‹ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã«ãªã‚‰ãšã€Gemini Flash (7/9)ã€GPT-5, o4-mini(4/9)ãŒå¤šãã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚³ã‚¹ãƒˆã¨Acc.ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®ä¸Šã§ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã¨ãªã£ãŸã€‚<br>- ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚³ã‚¹ãƒˆã¨Acc.ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ãŠã„ã¦ã¯ã€Opus4.1ãŒ3ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãƒ‘ãƒ¬ãƒ¼ãƒ‰ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã¨ãªã£ãŸã€‚<br>- ã™ã¹ã¦ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¡Œå‹•ã‚’è¨˜éŒ²ã—åˆ†æã—ãŸçµæœã€SelfCorrection, intermediate verifiers (ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œã«ãŠã‘ã‚‹ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆãªã©ï¼‰ã®behaviorãŒacc.ã‚’æ”¹å–„ã™ã‚‹ä¸Šã§é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ãŸ<br>- ä¸€æ–¹ã‚¿ã‚¹ã‚¯ã«å¤±æ•—ã™ã‚‹å ´åˆã¯ã€å¤šãã®è¦å› ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã€ãŸã¨ãˆã°ç’°å¢ƒå†…ã®éšœå®³ï¼ˆCAPTCHAãªã©ï¼‰ã€æŒ‡ç¤ºã«å¾“ã†ã“ã¨ã®å¤±æ•—ï¼ˆæŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã‚³ãƒ¼ãƒ‰ã‚’å‡ºåŠ›ã—ãªã„ï¼‰ãªã©ãŒé »ç¹ã«è¦‹å—ã‘ã‚‰ã‚ŒãŸã€‚ã¾ãŸã€ã‚¿ã‚¹ã‚¯ã‚’è§£ã‘ãŸã‹å¦ã‹ã«é–¢ã‚ã‚‰ãšãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®å¤±æ•—ã«é »ç¹ã«é­é‡ã—ã¦ã„ãŸã€‚ã“ã‚Œã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã“ã†ã—ãŸã‚¨ãƒ©ãƒ¼ã‹ã‚‰å›å¾©ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br>- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ­ã‚°ã‚’åˆ†æã™ã‚‹ã“ã¨ã§ã€TauBenchã§ä½¿ç”¨ã—ã¦ã„ãŸscaffold(=ãƒ¢ãƒ‡ãƒ«ãŒç’°å¢ƒã‚‚ã‚„ã‚Šã¨ã‚Šã™ã‚‹ãŸã‚ã®æ§‹æˆè¦ç´ ï¼‰ã«ãƒã‚°ãŒã‚ã‚‹ã“ã¨ã‚’çªãæ­¢ã‚ãŸï¼ˆfew-shotã®ã‚µãƒ³ãƒ—ãƒ«ã«ãƒªãƒ¼ã‚¯ãŒã‚ã£ãŸï¼‰ã€‚ã“ã®scaffoldã¯HALã«ã‚ˆã‚‹TauBenchã®åˆ†æã‹ã‚‰é™¤å¤–ã—ãŸã€‚<br>- Docsentã®ã‚ˆã†ãªãƒ­ã‚°åˆ†æãŒä»Šå¾Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è©•ä¾¡ã™ã‚‹ä¸Šã§ã¯å¿…è¦ä¸å¯æ¬ ã§ã‚ã‚Šã€ä¿¡é ¼æ€§ã®å•é¡Œã‚„ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆè¡Œå‹•ã€é«˜ã‚³ã‚¹ãƒˆãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¤±æ•—ãªã©ãŒæ˜ã‚‰ã‹ã«ãªã‚‹ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã§ã®æ€§èƒ½ã¨æ¯”è¼ƒã—ã¦å®Ÿç’°å¢ƒã§ã¯æ€§èƒ½ãŒä½ã„ã€ã‚ã‚‹ã„ã¯ãã®é€†ã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒæ€§èƒ½ã‚’ä½ãè¦‹ç©ã‚‚ã£ã¦ã„ã‚‹ï¼ˆãŸã¨ãˆã°CAPTChAã®ã‚ˆã†ã‚„ç’°å¢ƒçš„ãªéšœå®³ã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã§ã¯åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ã›ã„ã§ç”Ÿã˜ã¦ã‚‚å®Ÿç’°å¢ƒã§ã¯ç”Ÿã˜ãªã„ãªã©ï¼‰ã‚±ãƒ¼ã‚¹ã‚‚ã‚ã‚‹ã®ã§ã€ã“ã‚Œã‚‰ã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®acc.ã‹ã‚‰ã ã‘ã§ã¯æ˜ã‚‰ã‹ã«ãªã‚‰ãªã„ãŸã‚ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®acc.ã¯æ…é‡ã«è§£é‡ˆã™ã¹ãã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Temporal.html" target="_blank" rel="noopener noreferrer">#Temporal</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/2D%20(Image).html" target="_blank" rel="noopener noreferrer">#2D (Image)</a>
<a class="button" href="articles/TTS.html" target="_blank" rel="noopener noreferrer">#TTS</a>
<a class="button" href="articles/4D%20(Video).html" target="_blank" rel="noopener noreferrer">#4D (Video)</a>
<a class="button" href="articles/Omni.html" target="_blank" rel="noopener noreferrer">#Omni</a>
<a class="button" href="articles/audio.html" target="_blank" rel="noopener noreferrer">#audio</a>
<a class="button" href="articles/text.html" target="_blank" rel="noopener noreferrer">#text</a>


<br>


<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3354" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding  LLM, Hanrong Ye+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- OmniVinciã¯ã€è¦–è¦šã¨éŸ³å£°ã‚’çµ±åˆã—ãŸã‚ªãƒ ãƒ‹ãƒ¢ãƒ¼ãƒ€ãƒ«LLMã‚’æ§‹ç¯‰ã™ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã‚ã‚Šã€3ã¤ã®é©æ–°ï¼ˆOmniAlignNetã€Temporal Embedding Groupingã€Constrained Rotary Time Embeddingï¼‰ã‚’ææ¡ˆã€‚2400ä¸‡ã®ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€ãƒ¢ãƒ€ãƒªãƒ†ã‚£é–“ã®ç›¸äº’å¼·åŒ–ã‚’å®Ÿç¾ã€‚DailyOmniã€MMARã€Video-MMEã§ã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã®ä½¿ç”¨é‡ã‚’å¤§å¹…ã«å‰Šæ¸›ã€‚ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã‚„åŒ»ç™‚AIãªã©ã®å¿œç”¨ã«ãŠã‘ã‚‹ã‚ªãƒ ãƒ‹ãƒ¢ãƒ¼ãƒ€ãƒ«ã®åˆ©ç‚¹ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://nvlabs.github.io/OmniVinci/" target="_blank" rel="noopener noreferrer">https://nvlabs.github.io/OmniVinci/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1980396179356844292?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>image, video, ãƒ†ã‚­ã‚¹ãƒˆ, éŸ³å£°ã‚’ç†è§£ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡ºåŠ›ï¼ˆTTSã‚‚å¯ï¼‰ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã«é–¢ã™ã‚‹æ–°ãŸãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜</p></span><br><br>
</div>
<p><button onclick="showMore(0)">more</button></p>
<div class="hidden-content">
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3349" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action, Yuhao Yang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”¨ã„ãŸåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã€ŒUltraCUAã€ã‚’ææ¡ˆã—ã€GUIã®åŸå§‹çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã¨é«˜ãƒ¬ãƒ™ãƒ«ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’çµ±åˆã€‚è‡ªå‹•åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€åˆæˆãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ³ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ã‚¯ã‚·ãƒ§ãƒ³è»Œè·¡ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã€äºŒæ®µéšã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹æˆè¦ç´ ã¨ã—ã€å®Ÿé¨“ã«ã‚ˆã‚Šæœ€å…ˆç«¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å¯¾ã—ã¦22%ã®æ”¹å–„ã¨11%ã®é€Ÿåº¦å‘ä¸Šã‚’é”æˆã€‚ã‚¨ãƒ©ãƒ¼ä¼æ’­ã‚’æ¸›å°‘ã•ã›ã¤ã¤å®Ÿè¡ŒåŠ¹ç‡ã‚’ç¶­æŒã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhegan4/status/1980471759251075578?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¾“æ¥ã®CUAã¯GUIã«å¯¾ã™ã‚‹ä½ãƒ¬ãƒ™ãƒ«ã®æ“ä½œï¼ˆã‚¯ãƒªãƒƒã‚¯ã€ã‚¿ã‚¤ãƒ—ã€ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ï¼‰ã‚’åˆ©ç”¨ã™ã‚‹å‰æã«ç«‹ã¤ãŒã€æœ¬ç ”ç©¶ã§ã¯ãã‚Œã‚‰ã ã‘ã§ã¯ãªãã‚ˆã‚Šé«˜ãƒ¬ãƒ™ãƒ«ã®programatic tool calls(e.g., pythoné–¢æ•°å‘¼ã³å‡ºã—ã€ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã€ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œã€APIå‘¼ã³å‡ºã—ç­‰)ã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã§ãã‚‹ã‚ˆã†ã«åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—Agentã‚’ã‚‰SFTã¨RLã—ã¾ã—ãŸã‚‰ã‚ˆã‚Šãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢å‘ä¸Šã—ãŸã€ã¨ã„ã†ã‚ˆã†ãªè©±ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<a class="button" href="articles/LongHorizon.html" target="_blank" rel="noopener noreferrer">#LongHorizon</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3348" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Synthesizing Agentic Data for Web Agents with Progressive Difficulty  Enhancement Mechanisms, Shrey Pandit+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Webãƒ™ãƒ¼ã‚¹ã®ã€Œãƒ‡ã‚£ãƒ¼ãƒ—ãƒªã‚µãƒ¼ãƒã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€é•·æœŸçš„ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’é€šã˜ã¦è¤‡é›‘ãªè³ªå•å¿œç­”ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ãŒã€å¾“æ¥ã®æ–¹æ³•ã¯æ¨è«–ã®è¤‡é›‘ã•ã‚’æ‰ãˆãã‚Œãªã„ã€‚ãã“ã§ã€ã‚¿ã‚¹ã‚¯ã®è¤‡é›‘ã•ã‚’æ®µéšçš„ã«å¢—åŠ ã•ã›ã‚‹äºŒæ®µéšã®ãƒ‡ãƒ¼ã‚¿åˆæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å°å…¥ã—ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè³ªå•ã«æŒ‘æˆ¦ã—ã€äº‹å®Ÿç¢ºèªã‚’è¡Œã†ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒæ—¢å­˜ã®ã‚‚ã®ã‚ˆã‚Šã‚‚åŠ¹æœçš„ãªè¨“ç·´ã‚’å¯èƒ½ã«ã—ã€ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®å¤šæ§˜æ€§ãŒ2å€ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/caimingxiong/status/1980302240163488057?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="articles/Entropy.html" target="_blank" rel="noopener noreferrer">#Entropy</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3347" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] EPO: Entropy-regularized Policy Optimization for LLM Agents  Reinforcement Learning, Wujiang Xu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ç’°å¢ƒã§ã®LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨“ç·´ã«ãŠã‘ã‚‹æ¢ç´¢-æ´»ç”¨ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰å¤±æ•—ã‚’ç‰¹å®šã—ã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ­£å‰‡åŒ–ãƒãƒªã‚·ãƒ¼æœ€é©åŒ–ï¼ˆEPOï¼‰ã‚’ææ¡ˆã€‚EPOã¯ã€æ¢ç´¢ã‚’å¼·åŒ–ã—ã€ãƒãƒªã‚·ãƒ¼ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚’åˆ¶é™ã™ã‚‹ã“ã¨ã§ã€è¨“ç·´ã®å®‰å®šæ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ScienceWorldã§152%ã€ALFWorldã§19.8%ã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã‚¹ãƒ‘ãƒ¼ã‚¹å ±é…¬è¨­å®šã«ã¯æ–°ãŸãªã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼åˆ¶å¾¡ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1980299972684775584?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/SkillTag.html" target="_blank" rel="noopener noreferrer">#SkillTag</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3346" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Skill-Targeted Adaptive Training, Yinghui He+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ã‚¿èªçŸ¥èƒ½åŠ›ã‚’æ´»ç”¨ã—ãŸæ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã€ŒSTATã€ã‚’ææ¡ˆã€‚æ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒã‚¿ã‚¹ã‚¯ã«å¿…è¦ãªã‚¹ã‚­ãƒ«ã‚’ãƒ©ãƒ™ãƒ«ä»˜ã‘ã—ã€å­¦ç”Ÿãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚­ãƒ«ä¸è¶³ã‚’è¿½è·¡ã™ã‚‹ã“ã¨ã§ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚»ãƒƒãƒˆã‚’ä¿®æ­£ã€‚STAT-Selã§ã¯æ—¢å­˜ã®ä¾‹ã®é‡ã¿ã‚’èª¿æ•´ã—ã€STAT-Synã§ã¯æ–°ãŸãªä¾‹ã‚’åˆæˆã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€MATHã§æœ€å¤§7.5%ã®æ”¹å–„ã‚’é”æˆã—ã€åˆ†å¸ƒå¤–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚‚å¹³å‡4.6%ã®å‘ä¸Šã‚’ç¤ºã—ãŸã€‚STATã¯å¼·åŒ–å­¦ç¿’æ‰‹æ³•GRPOã¨è£œå®Œçš„ã§ã‚ã‚Šã€ã‚¹ã‚­ãƒ«ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®é©å¿œãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ”¹å–„ã™ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yinghui_he_/status/1980257694704619679?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3361" target="_blank" rel="noopener noreferrer">[Paper Note] Metacognitive Capabilities of LLMs: An Exploration in Mathematical   Problem Solving, Aniket Didolkar+, NeurIPS'24, 2024.05</a>
</p>
<p>Reward Modelã§questionãŒeasy/hardã‚’å®šé‡åŒ–ã—ã€hardãªã‚‚ã®ã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«ãŒå¿œç­”ã‚’ç”Ÿæˆã€‚å¿œç­”ã®çµæœã‚’stronger modelã«ç¢ºèªã•ã›ã€ãƒ¢ãƒ‡ãƒ«ã«ã©ã®ã‚ˆã†ãªã‚¹ã‚­ãƒ«ãŒä¸è¶³ã—ã¦ã„ã‚‹ã‹ã‚’ç‰¹å®šã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚­ãƒ«ã«é–¢ã™ã‚‹profileãŒä½œæˆã•ã‚Œã‚‹ã®ã§ã“ã‚Œã«åŸºã¥ã„ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å„ã‚µãƒ³ãƒ—ãƒ«ã¨ã‚¹ã‚­ãƒ«ã‚’ç´ã¥ã‘ãŸä¸Šã§ã‚µãƒ³ãƒ—ãƒ«ã‚’é‡ã¿ã®èª¿æ•´ã€ãŠã‚ˆã³ä¸è¶³ã—ã¦ã„ã‚‹ã‚¹ã‚­ãƒ«ã«é–¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã—SFTã«æ´»ç”¨ã™ã‚‹ã€ã¨ã„ã£ãŸè©±ãªæ¨¡æ§˜ã€‚<br><br>&lt;img width="838" height="496" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/8f5e9efb-c096-4897-8327-daed9e4c920a"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/8f5e9efb-c096-4897-8327-daed9e4c920a"&lt;/a&gt;


/&gt;<br><br>çµæœã‚’è¦‹ã‚‹ã¨ã€+SFT / +GRPOã‚ˆã‚Šã‚‚æ€§èƒ½ãŒé«˜ããªã£ã¦ã„ã‚‹ã€‚Table1ã§ã¯Llamaã§ã®çµæœã—ã‹æ²è¼‰ã•ã‚Œã¦ã„ãªã„ãŒã€Qwenã§ã‚‚å®Ÿé¨“ãŒã•ã‚Œã¦åŒæ§˜ã®çµæœãŒå¾—ã‚‰ã‚Œã¦ã„ã‚‹ã€‚<br>&lt;img width="856" height="255" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/d35077ef-bf33-4c12-82e1-37cbc40247af"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/d35077ef-bf33-4c12-82e1-37cbc40247af"&lt;/a&gt;


/&gt;<br><br>ã¾ãŸã€Figure4ã‚’è¦‹ã‚‹ã¨ä¸è¶³ã—ã¦ã„ãŸã‚¹ã‚­ãƒ«ãŒå­¦ç¿’ã«ã‚ˆã£ã¦ãã¡ã‚“ã¨è£œã‚ã‚Œã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚<br><br>&lt;img width="839" height="541" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/bd07a4e5-87c8-4ab1-a45c-379cff343e33"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/bd07a4e5-87c8-4ab1-a45c-379cff343e33"&lt;/a&gt;


/&gt;<br><br>ï¼ˆè©•ä¾¡ã¨è€ƒå¯Ÿéƒ¨åˆ†ã‚’ã‚‚ã†å°‘ã—ã˜ã£ãã‚Šèª­ã¿ãŸã„ï¼‰</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3342" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Beyond Context: A Survey of Multimodal Retrieval-Augmented  Generation for Document Understanding, Sensen Gao+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æ–‡æ›¸ç†è§£ã¯å¤šæ§˜ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦é‡è¦ã§ã‚ã‚Šã€ç¾åœ¨ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã¯åˆ¶é™ãŒã‚ã‚‹ã€‚ç‰¹ã«ã€OCRãƒ™ãƒ¼ã‚¹ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯æ§‹é€ çš„è©³ç´°ã‚’å¤±ã„ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMsã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«è‹¦åŠ´ã—ã¦ã„ã‚‹ã€‚ãƒªãƒˆãƒªãƒ¼ãƒãƒ«å¼·åŒ–ç”Ÿæˆï¼ˆRAGï¼‰ã¯å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã™ã‚‹ãŒã€æ–‡æ›¸ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ€§ã«ã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAGãŒå¿…è¦ã§ã‚ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€æ–‡æ›¸ç†è§£ã®ãŸã‚ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAGã«é–¢ã™ã‚‹ä½“ç³»çš„ãªèª¿æŸ»ã‚’è¡Œã„ã€åˆ†é¡æ³•ã‚„é€²å±•ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ä¸»è¦ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„èª²é¡Œã‚’ã¾ã¨ã‚ã€æ–‡æ›¸AIã®ä»Šå¾Œã®é€²å±•ã«å‘ã‘ãŸãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1980096776482013263?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>multimodal RAGã«é–¢ã™ã‚‹Survey</p>
<p>Table1ã¯2024å¹´ä»¥å¾Œã®35æœ¬ç¨‹åº¦ã®æ‰‹æ³•ã€Table2ã¯20+ç¨‹åº¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒã¾ã¨ã¾ã£ã¦ãŠã‚Šã€åŸºæœ¬çš„ãªæ¦‚å¿µãªã©ã‚‚è§£èª¬ã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ã€‚åŠæ•°ç¨‹åº¦ãŒtraining-free/OCRã‚’åˆ©ç”¨ã™ã‚‹æ‰‹æ³•ã¯ãã‚Œãã‚Œäº”åˆ†äº”åˆ†ç¨‹åº¦ãªã‚ˆã†ã§ã€Agenticãªæ‰‹æ³•ã¯ã‚ã¾ã‚Šå¤šããªã„ã‚ˆã†ã (3/35)ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ICCV.html" target="_blank" rel="noopener noreferrer">#ICCV</a>
<a class="button" href="articles/ImageSynthesis.html" target="_blank" rel="noopener noreferrer">#ImageSynthesis</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3335" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MetaMorph: Multimodal Understanding and Generation via Instruction   Tuning, Shengbang Tong+, ICCV'25, 2024.12</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¦–è¦šçš„æŒ‡ç¤ºèª¿æ•´ã®æ–°æ‰‹æ³•VPiTã‚’ææ¡ˆã—ã€LLMãŒãƒ†ã‚­ã‚¹ãƒˆã¨è¦–è¦šãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚VPiTã¯ã€ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’äºˆæ¸¬ã™ã‚‹èƒ½åŠ›ã‚’LLMã«æ•™ãˆã€è¦–è¦šç”Ÿæˆèƒ½åŠ›ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ç‰¹ã«ã€ç†è§£ãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚åŠ¹æœçš„ã«ä¸¡æ–¹ã®èƒ½åŠ›ã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—ãŸã€‚MetaMorphãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€è¦–è¦šç†è§£ã¨ç”Ÿæˆã§ç«¶äº‰åŠ›ã®ã‚ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€LLMã®äº‹å‰å­¦ç¿’ã‹ã‚‰å¾—ãŸçŸ¥è­˜ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€è¦–è¦šç”Ÿæˆã«ãŠã‘ã‚‹ä¸€èˆ¬çš„ãªå¤±æ•—ã‚’å…‹æœã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMãŒè¦–è¦šç†è§£ã¨ç”Ÿæˆã«é©å¿œã§ãã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/davidjfan/status/1979994285379641487?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3333" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On the Relationship Between the Choice of Representation and In-Context  Learning, Ioana Marinescu+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã¯ã€LLMãŒãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’å­¦ã¶èƒ½åŠ›ã‚’æŒ‡ã—ã€è¡¨ç¾æ–¹æ³•ã¨å­¦ç¿’èƒ½åŠ›ã®ç›¸äº’ä½œç”¨ãŒé‡è¦ã§ã‚ã‚‹ã€‚ç ”ç©¶ã§ã¯ã€ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®è¡¨ç¾ãŒICLã®åŸºæº–ç²¾åº¦ã‚’æ±ºå®šã—ã€è¿½åŠ ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯ãã®åŸºæº–ã‚’æ”¹å–„ã™ã‚‹ã“ã¨ã‚’ä»®å®šã€‚ç•°ãªã‚‹ãƒ©ãƒ™ãƒ«ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ICLã‚’å®Ÿæ–½ã—ãŸçµæœã€ãƒ©ãƒ™ãƒ«ã‚»ãƒƒãƒˆã®è³ªã«é–¢ã‚ã‚‰ãšå­¦ç¿’ãŒè¡Œã‚ã‚Œã€åŠ¹ç‡ã¯ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®æ”¹å–„å‚¾ãã«ä¾å­˜ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰ã®å­¦ç¿’ã¨ãã®è¡¨ç¾ãŒICLã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ç‹¬ç«‹ã—ãŸå½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kchonyc/status/1979716767141486740?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3332" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reasoned Safety Alignment: Ensuring Jailbreak Defense via  Answer-Then-Check, Chentao Cao+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- è„±ç„æ”»æ’ƒã«å¯¾ã™ã‚‹å®‰å…¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€Answer-Then-Checkã¨ã„ã†æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ãƒ¢ãƒ‡ãƒ«ã¯ã¾ãšè³ªå•ã«å›ç­”ã—ã€ãã®å¾Œå®‰å…¨æ€§ã‚’è©•ä¾¡ã—ã¦ã‹ã‚‰å¿œç­”ã‚’æä¾›ã€‚80Kã®ä¾‹ã‹ã‚‰ãªã‚‹Reasoned Safety Alignmentï¼ˆReSAï¼‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã€å®Ÿé¨“ã«ã‚ˆã‚Šå„ªã‚ŒãŸå®‰å…¨æ€§ã‚’ç¤ºã—ã¤ã¤éå‰°æ‹’å¦ç‡ã‚’ä½ä¸‹ã€‚ReSAã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ä¸€èˆ¬çš„ãªæ¨è«–èƒ½åŠ›ã‚’ç¶­æŒã—ã€æ•æ„Ÿãªãƒˆãƒ”ãƒƒã‚¯ã«å¯¾ã—ã¦ã‚‚æœ‰ç›Šãªå¿œç­”ã‚’æä¾›å¯èƒ½ã€‚å°‘é‡ã®ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã‚‚é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã§ãã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1980113019511427195?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<a class="button" href="articles/SpatialUnderstanding.html" target="_blank" rel="noopener noreferrer">#SpatialUnderstanding</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3330" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Thinking with Camera: A Unified Multimodal Model for Camera-Centric  Understanding and Generation, Kang Liao+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ã‚«ãƒ¡ãƒ©ä¸­å¿ƒã®ç†è§£ã¨ç”Ÿæˆã‚’çµ±åˆã—ãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€ŒPuffinã€ã‚’ææ¡ˆã€‚Puffinã¯ã€è¨€èªå›å¸°ã¨æ‹¡æ•£ç”Ÿæˆã‚’çµ„ã¿åˆã‚ã›ã€ã‚«ãƒ¡ãƒ©ã‚’è¨€èªã¨ã—ã¦æ‰±ã†æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã€‚400ä¸‡ã®è¦–è¦š-è¨€èª-ã‚«ãƒ¡ãƒ©ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒPuffin-4Mã€ã§è¨“ç·´ã•ã‚Œã€ç©ºé–“çš„ãªè¦–è¦šçš„æ‰‹ãŒã‹ã‚Šã‚’è€ƒæ…®ã—ãŸæ¨è«–ã‚’å®Ÿç¾ã€‚å®Ÿé¨“çµæœã§ã¯ã€å°‚é–€ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šå¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã«å¯¾å¿œå¯èƒ½ã€‚ç ”ç©¶æˆæœã¯ã‚³ãƒ¼ãƒ‰ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨å…±ã«å…¬é–‹äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1979911820401086613?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj page: 


<a href="https://kangliao929.github.io/projects/puffin/" target="_blank" rel="noopener noreferrer">https://kangliao929.github.io/projects/puffin/</a>


</p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<span class="issue_date">Issue Date: 2025-10-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3326" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Understanding the Influence of Synthetic Data for Text Embedders, Jacob Mitchell Springer+, ACL'25 Findings, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- åˆæˆLLMç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚‹æ±ç”¨ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿å™¨ã®é€²å±•ã‚’å—ã‘ã€Wangã‚‰ã®åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’å†ç¾ãƒ»å…¬é–‹ã€‚é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’ã‚‚ãŸã‚‰ã™ãŒã€ä¸€èˆ¬åŒ–ã®æ”¹å–„ã¯å±€æ‰€çš„ã§ã‚ã‚Šã€ç•°ãªã‚‹ã‚¿ã‚¹ã‚¯é–“ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒå­˜åœ¨ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åˆæˆãƒ‡ãƒ¼ã‚¿ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®é™ç•ŒãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ã‚¿ã‚¹ã‚¯å…¨ä½“ã§ã®å …ç‰¢ãªåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã«å¯¾ã™ã‚‹è€ƒãˆã«ç–‘å•ã‚’å‘ˆã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacspringer/status/1979233837042290775?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>dataset: 


<a href="https://huggingface.co/datasets/jspringer/open-synthetic-embeddings" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/jspringer/open-synthetic-embeddings</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3325" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Agentic Design of Compositional Machines, Wenqian Zhang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- è¤‡é›‘ãªæ©Ÿæ¢°è¨­è¨ˆã«ãŠã‘ã‚‹LLMã®å‰µé€ èƒ½åŠ›ã‚’æ¢æ±‚ã—ã€ã€Œæ§‹æˆçš„æ©Ÿæ¢°è¨­è¨ˆã€ã®è¦–ç‚¹ã‹ã‚‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€‚ãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã€ŒBesiegeFieldã€ã‚’ç”¨ã„ã¦ã€LLMã®èƒ½åŠ›ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã—ã€ç©ºé–“çš„æ¨è«–ã‚„æˆ¦ç•¥çš„çµ„ã¿ç«‹ã¦ã®é‡è¦æ€§ã‚’ç‰¹å®šã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®é™ç•Œã‚’å—ã‘ã€å¼·åŒ–å­¦ç¿’ã‚’é€šã˜ãŸæ”¹å–„ã‚’æ¨¡ç´¢ã—ã€é–¢é€£ã™ã‚‹èª²é¡Œã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yuliangxiu/status/1979695910167969854?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj page: 


<a href="https://besiegefield.github.io/" target="_blank" rel="noopener noreferrer">https://besiegefield.github.io/</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3324" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BitNet Distillation, Xun Wu+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- BitNet Distillationï¼ˆBitDistillï¼‰ã¯ã€ãƒ•ãƒ«ç²¾åº¦LLMã‚’1.58ãƒ“ãƒƒãƒˆç²¾åº¦ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹è»½é‡ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã¤ã¤é«˜ã„ã‚¿ã‚¹ã‚¯ç‰¹åŒ–å‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ä¸»ãªæŠ€è¡“ã«ã¯ã€SubLNãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€MiniLMã«åŸºã¥ãã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³è’¸ç•™ã€ç¶™ç¶šçš„ãªäº‹å‰å­¦ç¿’ãŒå«ã¾ã‚Œã€ã“ã‚Œã«ã‚ˆã‚Šãƒ•ãƒ«ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã—ã€ãƒ¡ãƒ¢ãƒªã‚’æœ€å¤§10å€ç¯€ç´„ã—ã€CPUä¸Šã§ã®æ¨è«–ã‚’2.65å€é«˜é€ŸåŒ–ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1979209909444001822?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>SubLN, MiniLMã«ã¤ã„ã¦ã¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1899" target="_blank" rel="noopener noreferrer">Foundation Transformers, Hongyu Wang+, PMLR'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3345" target="_blank" rel="noopener noreferrer">[Paper Note] MiniLMv2: Multi-Head Self-Attention Relation Distillation for  Compressing Pretrained Transformers, Wenhui Wang+, ACL'21 Findings, 2020.12</a>
 <br><br>ã‚’å‚ç…§ã®ã“ã¨ã€‚</p>
<p>æ—¢å­˜LLMã‚’ç‰¹å®šã‚¿ã‚¹ã‚¯ã«1.58bitã§SFTã™ã‚‹éš›ã«ã€full-precisionã¨åŒç­‰ã®æ€§èƒ½ã‚’ä¿ã¤æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ç ”ç©¶ã€‚full-precision LLMã‚’1.58 bitã§SFTã‚’ã™ã‚‹ã¨fp16ã§å­¦ç¿’ã—ãŸå ´åˆã®baselineã¨æ¯”è¼ƒã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤§ããä½ä¸‹ã™ã‚‹ãŒï¼ˆãã—ã¦ãã®å‚¾å‘ã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„ã»ã©å¼·ã„ï¼‰ã€ææ¡ˆæ‰‹æ³•ã‚’åˆ©ç”¨ã™ã‚‹ã¨fp16ã§SFTã—ãŸå ´åˆã¨åŒç­‰ã®æ€§èƒ½ã‚’ä¿ã¡ãªãŒã‚‰ã€inference-speed 2.65å€ã€ãƒ¡ãƒ¢ãƒªæ¶ˆè²»é‡1/10ã«ãªã‚‹æ¨¡æ§˜ã€‚<br>&lt;img width="1015" height="644" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/cafa8ad5-7cce-4466-a208-07bb51dcd953"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/cafa8ad5-7cce-4466-a208-07bb51dcd953"&lt;/a&gt;


/&gt;<br><br>æ‰‹æ³•ã¨ã—ã¦ã¯ã€3æ®µéšã§æ§‹æˆã•ã‚Œã¦ãŠã‚Š<br>- Stage1: low-bitã«é‡å­åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§ã¯activationã®åˆ†æ•£ãŒå¤§ãããªã‚Šå­¦ç¿’ã®ä¸å®‰å®šã•ã«ã¤ãªãŒã‚‹ãŸã‚ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ã—ã¦SubLNã‚’å°å…¥ã—ã¦å®‰å®šåŒ–ã‚’å›³ã‚‹<br>- Stage2: Stage1ã§æ–°ãŸã«SubLNã‚’è¿½åŠ ã™ã‚‹ã®ã§äº‹å‰å­¦ç¿’ã‚³ãƒ¼ãƒ‘ã‚¹ã®ç¶™ç¶šäº‹å‰å­¦ç¿’ã™ã‚‹<br>- Stage3: full-precisionã§SFTã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’æ•™å¸«ã€1.58-bitã«é‡å­åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿå¾’ã¨ã—ã€logits distillation (input x, output yãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«æ•™å¸«ãƒ»ç”Ÿå¾’é–“ã§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ã®åˆ†å¸ƒã®KL Divergenceã‚’æœ€å°åŒ–ã™ã‚‹)ã€MiniLMã§ææ¡ˆã•ã‚Œã¦ã„ã‚‹MHAã®distillationï¼ˆq-q/k-k/v-vã®å†…ç©ã«ã‚ˆã£ã¦squaredãªrelation mapã‚’Q, K, Vã”ã¨ã«ä½œæˆã—ã€relation mapã®KL DivergenceãŒæ•™å¸«ãƒ»ç”Ÿå¾’é–“ã§æœ€å°ã¨ãªã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ï¼‰ã‚’å®Ÿæ–½ã™ã‚‹<br>- æœ€çµ‚çš„ã« `L_CE + \lambda L_LD + \ganma L_AD` ã‚’æœ€å°åŒ–ã™ã‚‹ã€‚ã“ã“ã§ã€L_CEã¯downstream datasetã«å¯¾ã™ã‚‹cross-entropy lossã§ã‚ã‚Šã€L_LD, L_ADã¯ãã‚Œãã‚Œã€logit distillation, Attention Distillationã®lossã§ã‚ã‚‹ã€‚</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1980968125547139259?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3323" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Agentic Misalignment: How LLMs Could Be Insider Threats, Aengus Lynch+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- è¤‡æ•°ã®é–‹ç™ºè€…ã‹ã‚‰ã®16ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä»®æƒ³ä¼æ¥­ç’°å¢ƒã§ãƒ†ã‚¹ãƒˆã—ã€æ½œåœ¨çš„ãªãƒªã‚¹ã‚¯è¡Œå‹•ã‚’ç‰¹å®šã€‚ãƒ¢ãƒ‡ãƒ«ã¯è‡ªå¾‹çš„ã«ãƒ¡ãƒ¼ãƒ«ã‚’é€ä¿¡ã—ã€æ©Ÿå¯†æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã§ã€ãƒ“ã‚¸ãƒã‚¹ç›®æ¨™ã«å¾“ã†ä¸­ã§åæŠ—çš„è¡Œå‹•ã‚’ç¤ºã™ã“ã¨ãŒã‚ã£ãŸã€‚ã“ã®ç¾è±¡ã‚’ã€Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒŸã‚¹ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã€ã¨å‘¼ã³ã€ãƒ¢ãƒ‡ãƒ«ãŒä¸é©åˆ‡ãªè¡Œå‹•ã‚’å–ã‚‹ã“ã¨ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚å®Ÿéš›ã®å±•é–‹ã«ãŠã„ã¦ã¯ãƒŸã‚¹ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã®è¨¼æ‹ ã¯è¦‹ã‚‰ã‚Œãªã‹ã£ãŸãŒã€ãƒ¢ãƒ‡ãƒ«ã®è‡ªå¾‹æ€§ãŒé«˜ã¾ã‚‹ã“ã¨ã§å°†æ¥çš„ãªãƒªã‚¹ã‚¯ãŒç”Ÿã˜ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã€‚å®‰å…¨æ€§ã¨é€æ˜æ€§ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã€ç ”ç©¶æ–¹æ³•ã‚’å…¬é–‹ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/safe_paper/status/1979557019209146457?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>abstã‚’èª­ã‚“ã ã ã‘ã§ã‚‚ã€ãªã‚“ã¨ã‚‚æã‚ã—ã„ã‚·ãƒŠãƒªã‚ªãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚èª­ã¿ãŸã„</p>
<p>Figure4, 5ã¨ã‹ã™ã”ã„ãª</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3322" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Clean First, Align Later: Benchmarking Preference Data Cleaning for  Reliable LLM Alignment, Samuel Yeh+, NeurIPS'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯LLMã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã«é‡è¦ã ãŒã€ãƒã‚¤ã‚ºã‚„ä¸€è²«æ€§ã®æ¬ å¦‚ãŒå•é¡Œã‚’å¼•ãèµ·ã“ã™ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€13ã®ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’è©•ä¾¡ã™ã‚‹åˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒPrefCleanBenchã€ã‚’å°å…¥ã€‚ã•ã¾ã–ã¾ãªæ¡ä»¶ä¸‹ã§ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆæ€§èƒ½ã‚’æ¯”è¼ƒã—ã€ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã®æˆåŠŸè¦å› ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã®æ”¹å–„ã«å‘ã‘ãŸå†ç¾å¯èƒ½ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æä¾›ã—ã€ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®é‡è¦æ€§ã‚’å¼·èª¿ã™ã‚‹ã€‚ã™ã¹ã¦ã®æ‰‹æ³•ã®å®Ÿè£…ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sharonyixuanli/status/1979617821434024374?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ƒãƒã‚¹ãƒˆã«ã‚ˆã‚‹ã¨Takeawayã¨ã—ã¦ã¯ã€<br>- cleaningã‚’ã™ã‚‹ã“ã¨ã§alignmentã®æ€§èƒ½ã¯ä¸€è²«ã—ã¦å‘ä¸Š<br>- è¤‡æ•°ã®Reward Modelã‚’ç”¨ã„ãŸå ´åˆï¼ˆãŠãã‚‰ãhuman labelã¨è¤‡æ•°RMã®votingã«åŸºã¥ãcleaningï¼‰ã¯å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ä¿¡é ¼æ€§ãŒé«˜ããƒ­ãƒã‚¹ãƒˆ<br>- bad dataã«å¯¾ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã¯ï¼ˆãƒ©ãƒ™ãƒ«ã‚’ä¿®æ­£ã™ã‚‹ã‚ˆã‚Šã‚‚ï¼‰å‰Šé™¤ã—ãŸæ–¹ãŒæ€§èƒ½ãŒå‘ä¸Šã™ã‚‹<br>- å°‘é‡ã ãŒã‚¯ãƒªãƒ¼ãƒ³ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯å¤§è¦æ¨¡ã§ãƒã‚¤ã‚¸ãƒ¼ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ˆã‚Šã‚‚æ€§èƒ½ãŒè‰¯ã„<br><br>ã¨ã„ã£ãŸçŸ¥è¦‹ãŒã‚ã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-10-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3320" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SPG: Sandwiched Policy Gradient for Masked Diffusion Language Models, Chenyu Wang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æ‹¡æ•£å‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆdLLMsï¼‰ã¯ã€åŠ¹ç‡çš„ãªãƒ‡ã‚³ãƒ¼ãƒ‰èƒ½åŠ›ã‚’æŒã¤ãŒã€å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã«ã‚ˆã‚‹èª¿æ•´ãŒé›£ã—ã„ã€‚å¾“æ¥ã®ä»£ç†æ‰‹æ³•ã¯ãƒã‚¤ã‚¢ã‚¹ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ãã“ã§ã€çœŸã®å¯¾æ•°å°¤åº¦ã®ä¸Šé™ã¨ä¸‹é™ã‚’åˆ©ç”¨ã—ãŸã€Œã‚µãƒ³ãƒ‰ã‚¤ãƒƒãƒãƒãƒªã‚·ãƒ¼å‹¾é…ï¼ˆSPGï¼‰ã€ã‚’ææ¡ˆã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€SPGã¯ELBOã‚„ä»–ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€GSM8Kã§3.6%ã€MATH500ã§2.6%ã€Countdownã§18.4%ã€Sudokuã§27.0%ã®ç²¾åº¦å‘ä¸Šã‚’é”æˆã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://chenyuwang-monica.github.io/spg/" target="_blank" rel="noopener noreferrer">https://chenyuwang-monica.github.io/spg/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chenyuw64562111/status/1979616465922687332?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/KV%20Cache.html" target="_blank" rel="noopener noreferrer">#KV Cache</a>
<span class="issue_date">Issue Date: 2025-10-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3319" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Attention Is All You Need for KV Cache in Diffusion LLMs, Quan Nguyen-Tri+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ‹¡æ•£å‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆDLMsï¼‰ã®ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¾…æ©Ÿæ™‚é–“ã‚’æœ€å°åŒ–ã—ã¤ã¤äºˆæ¸¬ç²¾åº¦ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã«ã€é©å¿œçš„ãªKVã‚­ãƒ£ãƒƒã‚·ãƒ¥å†è¨ˆç®—æ‰‹æ³•ã€ŒElastic-Cacheã€ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æµ…ã„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å†—é•·æ€§ã‚’å‰Šæ¸›ã—ã€é‡è¦ãªãƒˆãƒ¼ã‚¯ãƒ³ã«åŸºã¥ã„ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã‚’å‹•çš„ã«è¡Œã†ã€‚å®Ÿé¨“ã§ã¯ã€GSM8Kã‚„HumanEvalã§ã®é€Ÿåº¦å‘ä¸Šã‚’ç¤ºã—ã€ç”Ÿæˆå“è³ªã‚’ç¶­æŒã—ãªãŒã‚‰é«˜ã„ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’é”æˆã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1979180865520570615?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>DLMã«ãŠã„ã¦ã€denoisingã®å„ã‚¹ãƒ†ãƒƒãƒ—ã«ãŠã„ã¦å…¨ã¦ã®KVã‚’å†è¨ˆç®—ã™ã‚‹ã®ã§ã¯ãªãã€attention scoreãŒå¤§ãããƒ‰ãƒªãƒ•ãƒˆã—ã¦ã„ãªã„éƒ¨åˆ†ã«ã¤ã„ã¦ã¯KV Cacheã‚’å†åˆ©ç”¨ã—ã€å¤§ãããƒ‰ãƒªãƒ•ãƒˆã—ãŸéƒ¨åˆ†ã ã‘å†è¨ˆç®—ã™ã‚‹ã‚ˆã†ãªä»•çµ„ã¿ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€å“è³ªã‚’æãªã†ã“ã¨ãªãæ¨è«–é€Ÿåº¦ã‚’é«˜é€ŸåŒ–ã—ãŸæ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/Scalability.html" target="_blank" rel="noopener noreferrer">#Scalability</a>
<span class="issue_date">Issue Date: 2025-10-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3317" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Test-Time Compute to Achieve IOI Gold Medal with Open-Weight  Models, Mehrzad Samadi+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¯LLMsã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹é‡è¦ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚Šã€IOIã¯ãã®ä¸­ã§ã‚‚ç‰¹ã«æ¨©å¨ã‚ã‚‹å¤§ä¼šã§ã™ã€‚æœ¬è«–æ–‡ã§ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆãƒ¢ãƒ‡ãƒ«ãŒIOIé‡‘ãƒ¡ãƒ€ãƒ«ãƒ¬ãƒ™ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒGenClusterã€ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€ç”Ÿæˆã€è¡Œå‹•ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³æˆ¦ç•¥ã‚’çµ„ã¿åˆã‚ã›ã¦å¤šæ§˜ãªè§£æ±ºç©ºé–“ã‚’åŠ¹ç‡çš„ã«æ¢ç´¢ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€GenClusterã¯è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã«å¿œã˜ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã—ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã¨ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’ç¸®å°ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€IOI 2025ã§é‡‘ãƒ¡ãƒ€ãƒ«ã‚’é”æˆã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacksonatkinsx/status/1979563525614842156?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenWeight modelã§åˆã‚ã¦IOIé‡‘ãƒ¡ãƒ€ãƒ«ç´šã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã§ãã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€ã¾ãšLLMã«5000å€‹ç¨‹åº¦ã®æ½œåœ¨çš„ãªsolutionã‚’ç”Ÿæˆã•ã›ã€ãã‚Œãã‚Œã®solutionã‚’100ç¨®ã®test-caseã§èµ°ã‚‰ã›ã¦ã€ãã®å¾Œsolutionã‚’behaviorã«å¿œã˜ã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ã•ã«ãã£ã¦ã‚¯ãƒ©ã‚¹ã‚¿ãŒå½¢æˆã•ã‚Œã‚‹ã€‚æœ€çµ‚çš„ã«æœ€ã‚‚è‰¯ã„solutionã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«ã€ãã‚Œãã‚Œã®ã‚¯ãƒ©ã‚¹ã‚¿ã‹ã‚‰æœ€ã‚‚è‰¯ã„solutionã‚’äº’ã„ã«å¯¾æ±ºã•ã›ã¦ã€LLM-as-a-Judgeã§å‹è€…ã‚’ãƒ©ãƒ³ã‚¯ä»˜ã‘ã™ã‚‹ã‚ˆã†ãªä»•çµ„ã¿ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><br>&lt;img width="922" height="320" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/899026dd-38a9-4a1d-a871-2a37bcfeb623"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/899026dd-38a9-4a1d-a871-2a37bcfeb623"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3315" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] When Thoughts Meet Facts: Reusable Reasoning for Long-Context LMs, Soyeong Jeong+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æ€è€ƒãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”¨ã„ã¦ã€é•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLCLMsï¼‰ã«ã‚ˆã‚‹ãƒãƒ«ãƒãƒ›ãƒƒãƒ—æ¨è«–ã‚’æ§‹é€ åŒ–ã€‚è¨¼æ‹ ã®çµã³ã¤ãã‚’æ‰ãˆã€è‡ªç„¶è¨€èªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã§ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æ´—ç·´ã€‚å¤šæ§˜ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã—ã€å°å‹ãƒ¢ãƒ‡ãƒ«ã¸ã®è’¸ç•™ã‚‚å¯èƒ½ã€‚ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯åã¯ToTALã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1979207098413232316?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚·ãƒ³ãƒ—ãƒ«ãªCoTã‚„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå…¨ä½“ã‚’contextã«å…¥åŠ›ã™ã‚‹ã‚ˆã†ãªã‚·ãƒ³ãƒ—ãƒ«ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã—ã‹ãªãã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãŒå°‘ã—å¼±ã„ã‚ˆã†ãªå°è±¡ã‚’å—ã‘ãŸãŒï¼ˆãŸã¨ãˆã°Chain-of-Noteã‚’é©ç”¨ã—ã¦ã„ãªã„ã€ã¨æ€ã£ãŸãŒï¼‰å®Ÿé¨“ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’è¦‹ã‚‹ã¨ã€ãã‚‚ãã‚‚Reasoningãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸå®Ÿé¨“ï¼ˆå‰æï¼‰ã¨ãªã£ã¦ã„ã‚‹ã®ã§ï¼ˆChain-of-Noteãªã©ã¯non-thinking modelã§ã¯æœ‰åŠ¹ãªã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ãŒthinking modelã§ã®åŠ¹æœã¯ä¸æ˜ã¨ã„ã†èªè­˜ï¼‰ã€ãªã‚“ã‚„ã‹ã‚“ã‚„ã“ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã§ååˆ†ãªã®ã§ã¯ã€ã¨ã„ã†æ°—ã‚‚ã™ã‚‹ã€‚ãã—ã¦çµæ§‹æ€§èƒ½ãŒä¸ŠãŒã£ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ï¼ˆå¾Œã§èª­ã¿ãŸã„ï¼‰</p></span><br><br>
<a class="button" href="articles/Online/Interactive.html" target="_blank" rel="noopener noreferrer">#Online/Interactive</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/OOD.html" target="_blank" rel="noopener noreferrer">#OOD</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/Test-time%20Learning.html" target="_blank" rel="noopener noreferrer">#Test-time Learning</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3314" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Thinking on the Fly: Test-Time Reasoning Enhancement via Latent Thought  Policy Optimization, Wengao Ye+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Latent Thought Policy Optimizationï¼ˆLTPOï¼‰ã‚’ææ¡ˆã—ã€LLMã®æ¨è«–ã‚’å¼·åŒ–ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ãƒªãƒ¼ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’å°å…¥ã€‚ä¸­é–“çš„ãªæ½œåœ¨ã€Œæ€è€ƒã€ãƒ™ã‚¯ãƒˆãƒ«ã‚’å‹•çš„ã«æœ€é©åŒ–ã—ã€å¤–éƒ¨ç›£è¦–ãªã—ã§å ±é…¬ä¿¡å·ã«åŸºã¥ãã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒãƒªã‚·ãƒ¼å‹¾é…æ³•ã‚’ä½¿ç”¨ã€‚5ã¤ã®æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¼·åŠ›ãªæ€§èƒ½ã‚’ç¤ºã—ã€ç‰¹ã«AIMEãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é¡•è‘—ãªæ”¹å–„ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1979207098413232316?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>test-time ã« online-RLã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã“ã¨ãªãã€ã‚¯ã‚¨ãƒªã«å¿œã˜ã¦å‹•çš„ã«latent reasoningã‚’æ´—ç·´ã—ã€æ¨è«–èƒ½åŠ›ã‚’ãƒ­ãƒã‚¹ãƒˆã«ã§ãã‚‹ã€ã¨ã„ã†è©±ãªæ¨¡æ§˜ï¼Ÿ<br><br>&lt;img width="729" height="675" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/cdefa5c8-5fc4-4057-867e-bce5466702b6"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/cdefa5c8-5fc4-4057-867e-bce5466702b6"&lt;/a&gt;


/&gt;<br><br>å®Ÿé¨“çµæœã‚’è¦‹ã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤§ãã„å ´åˆã«gainãŒå°ã•ããªã£ã¦ã„ã£ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã€ã‹ã¤å®Ÿé¨“ä¸­ã®largest modelã®gainãŒã‚µãƒ³ãƒ—ãƒ«æ•°ã®å°‘ãªã„AIMEã®ã‚¹ã‚³ã‚¢ã«ä¾å­˜ã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3313" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LaDiR: Latent Diffusion Enhances LLMs for Text Reasoning, Haoqiang Kang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- LaDiRï¼ˆLatent Diffusion Reasonerï¼‰ã¨ã„ã†æ–°ã—ã„æ¨è«–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€LLMã®é™ç•Œã‚’å…‹æœã—ã€æ½œåœ¨è¡¨ç¾ã¨æ½œåœ¨æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’çµ±åˆã€‚VAEã‚’ç”¨ã„ã¦æ§‹é€ åŒ–ã•ã‚ŒãŸæ½œåœ¨æ¨è«–ç©ºé–“ã‚’æ§‹ç¯‰ã—ã€åŒæ–¹å‘æ³¨æ„ãƒã‚¹ã‚¯ã§ãƒ‡ãƒã‚¤ã‚ºã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åŠ¹ç‡çš„ãªæ¨è«–è»Œè·¡ã®ç”ŸæˆãŒå¯èƒ½ã¨ãªã‚Šã€ç²¾åº¦ã¨å¤šæ§˜æ€§ã‚’å‘ä¸Šã€‚æ•°å­¦çš„æ¨è«–ã®è©•ä¾¡ã§ã€å¾“æ¥æ‰‹æ³•ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1979207098413232316?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¢å­˜ã®reasoning/latent reasoningã¯sequentialã«reasoning trajectoryã‚’ç”Ÿæˆã—ã¦ã„ããŒã€ï¼ˆã“ã®ãŸã‚ã€èª¤ã£ãŸæ¨è«–ã‚’ã—ãŸéš›ã«æ¨è«–ã‚’æ˜¯æ­£ã—ã¥ã‚‰ã„ã¨ã„ã‚ã‚Œã¦ã„ã‚‹ï¼‰æœ¬æ‰‹æ³•ã§ã¯thought tokensã¨å‘¼ã°ã‚Œã‚‹æ€è€ƒãƒˆãƒ¼ã‚¯ãƒ³ã‚’diffusion modelã‚’ç”¨ã„ã¦denoisingã™ã‚‹ã“ã¨ã§reasoning trajectoryã‚’ç”Ÿæˆã™ã‚‹ã€‚ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã¯trajectoryå…¨ä½“ã‚’iterativeã«refineã—ã¦ã„ããŸã‚å‰è¿°ã®å¼±ç‚¹ãŒæ˜¯æ­£ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ã¾ãŸã€thought tokensã®ç”Ÿæˆã¯è¤‡æ•°ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆãƒ–ãƒ­ãƒƒã‚¯é–“ã¯causal attention, ãƒ–ãƒ­ãƒƒã‚¯å†…ã¯bi-directional attentionï¼‰ã«åˆ†ã‘ã¦å®Ÿæ–½ã•ã‚Œã‚‹ãŸã‚è¤‡æ•°ã®reasoning trajectoryã‚’ä¸¦åˆ—ã—ã¦æ¢ç´¢ã™ã‚‹ã“ã¨ã«ãªã‚Šã€reasoning traceã®å¤šæ§˜æ€§ãŒé«˜ã¾ã‚‹åŠ¹æœãŒæœŸå¾…ã§ãã‚‹ã€‚æœ€å¾Œã«VAEã«ã‚ˆã£ã¦discreteãªinputã‚’latent spaceã«è½ã¨ã—è¾¼ã¿ã€ãã®ç©ºé–“ä¸Šã§denoisingï¼ˆ= latent spaceç©ºé–“ä¸Šã§æ€è€ƒã™ã‚‹ï¼‰ã—ã€ãã®å¾Œdecodingã—ã¦discrete tokenã«å†åº¦ãŠã¨ã—ã“ã‚€ï¼ˆ= thought tokensï¼‰ã¨ã„ã†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ãªã£ã¦ã„ã‚‹ãŸã‚ã€latent spaceä¸Šã§ã®reasoningã®è§£é‡ˆæ€§ãŒå‘ä¸Šã™ã‚‹ã€‚æœ€çµ‚çš„ã«ã¯ã€<soa>ã‚¿ã‚°ãŒå‡ºåŠ›ã•ã‚ŒãŸæ™‚ç‚¹ã§latent reasoningã‚¹ãƒ†ãƒƒãƒ—ã‚’çµ‚äº†ã—ã€ï¼ˆVAE Decoderã«ã‚ˆã£ã¦discrete tokenã«ãƒ‡ã‚³ãƒ¼ãƒ‰ã•ã‚Œã‚‹ã“ã¨ã§ï¼‰ç”Ÿæˆã•ã‚ŒãŸthought tokensã‚’freezeã•ã‚ŒãŸLLMã«å…¥åŠ›ã—ãŸä¸Šã§auto regressiveã«ç¶šãã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§å¿œç­”ã‚’å¾—ã‚‹ã€‚<br><br>&lt;img width="851" height="390" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/2d0c79d8-f31d-4d80-8671-eb3598d55d3d"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/2d0c79d8-f31d-4d80-8671-eb3598d55d3d"&lt;/a&gt;


/&gt;<br><br>&lt;img width="866" height="639" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/c7b4fcaf-1ac6-4602-8a23-350d6e21ab49"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/c7b4fcaf-1ac6-4602-8a23-350d6e21ab49"&lt;/a&gt;


/&gt;<br><br>çµæœã®ã‚¹ã‚³ã‚¢ã‚’è¦‹ã‚‹é™ã‚Šã€COCONUTã¨æ¯”ã¹ã‚‹ã¨ã ã„ã¶gainã‚’å¾—ã¦ã„ã‚‹ãŒã€Discrete Latentã¨æ¯”è¼ƒã™ã‚‹ã¨gainã¯é™å®šçš„ã«è¦‹ãˆã‚‹ã€‚<br><br>&lt;img width="869" height="539" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/ace6e663-b11b-49f0-8e29-a9ba2fce2649"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/ace6e663-b11b-49f0-8e29-a9ba2fce2649"&lt;/a&gt;


/&gt;&lt;/p&gt;&lt;/span&gt;<br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Proofs.html" target="_blank" rel="noopener noreferrer">#Proofs</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3307" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reliable Fine-Grained Evaluation of Natural Language Math Proofs, Wenjie Ma+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ã‚ˆã‚‹æ•°å­¦çš„è¨¼æ˜ã®ç”Ÿæˆã¨æ¤œè¨¼ã«ãŠã‘ã‚‹ä¿¡é ¼æ€§ã®é«˜ã„è©•ä¾¡è€…ãŒä¸è¶³ã—ã¦ã„ã‚‹å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€0ã‹ã‚‰7ã®ã‚¹ã‚±ãƒ¼ãƒ«ã§è©•ä¾¡ã™ã‚‹æ–°ãŸãªè©•ä¾¡è€…ProofGraderã‚’é–‹ç™ºã€‚ProofBenchã¨ã„ã†å°‚é–€å®¶æ³¨é‡ˆä»˜ããƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€è©•ä¾¡è€…ã®è¨­è¨ˆç©ºé–“ã‚’æ¢æ±‚ã—ã€ä½ã„å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆMAEï¼‰0.926ã‚’é”æˆã€‚ProofGraderã¯ã€æœ€è‰¯ã®é¸æŠã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã‚‚é«˜ã„ã‚¹ã‚³ã‚¢ã‚’ç¤ºã—ã€ä¸‹æµã®è¨¼æ˜ç”Ÿæˆã®é€²å±•ã«å¯„ä¸ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenjie_ma/status/1979239433145848103?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span></soa></p>
<p>ã“ã‚Œã¯éå¸¸ã«é‡è¦ãªç ”ç©¶ã«è¦‹ãˆã‚‹</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3306" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AutoCode: LLMs as Problem Setters for Competitive Programming, Shang Zhou+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- AutoCodeã¯ã€ç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®å•é¡Œæ–‡ã¨ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã§ã‚ã‚Šã€ä¿¡é ¼æ€§ã®é«˜ã„å•é¡Œä½œæˆã‚’å®Ÿç¾ã—ã¾ã™ã€‚è¤‡æ•°å›ã®æ¤œè¨¼ã‚’é€šã˜ã¦ã€ç”Ÿæˆã•ã‚ŒãŸå•é¡Œã¯å…¬å¼ã®åˆ¤æ–­ã¨99%ã®ä¸€è²«æ€§ã‚’æŒã¡ã€å¾“æ¥ã®æ‰‹æ³•ã«æ¯”ã¹ã¦å¤§å¹…ãªæ”¹å–„ã‚’ç¤ºã—ã¾ã™ã€‚ã¾ãŸã€ãƒ©ãƒ³ãƒ€ãƒ ãªã‚·ãƒ¼ãƒ‰å•é¡Œã‹ã‚‰æ–°ã—ã„ãƒãƒªã‚¢ãƒ³ãƒˆã‚’ä½œæˆã—ã€ä¸æ­£ãªå•é¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹æ©Ÿèƒ½ã‚‚å‚™ãˆã¦ã„ã¾ã™ã€‚æœ€çµ‚çš„ã«ã€AutoCodeã¯ã‚°ãƒ©ãƒ³ãƒ‰ãƒã‚¹ã‚¿ãƒ¼ç´šã®ç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ã«ã‚ˆã£ã¦ã‚³ãƒ³ãƒ†ã‚¹ãƒˆå“è³ªã¨è©•ä¾¡ã•ã‚Œã‚‹å•é¡Œã‚’ç”Ÿæˆã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>blog:


<a href="https://livecodebenchpro.com/projects/autocode/overview" target="_blank" rel="noopener noreferrer">https://livecodebenchpro.com/projects/autocode/overview</a>


</p>
<p>LLMã§è‡ªå‹•çš„ã«é«˜å“è³ªãªç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å•é¡Œã¨ãã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ææ¡ˆã€‚<br><br>ä¿¡é ¼æ€§ã®ã‚ã‚‹ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ä½œæˆã™ã‚‹ãŸã‚ã«ã€Validator-Generator-Checkerãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚ææ¡ˆã€‚GeneratorãŒãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ç”Ÿæˆã—ã€ValidatorãŒç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®å…¥åŠ›ãŒå•é¡Œã®åˆ¶ç´„ã‚’æº€ãŸã—ã¦ã„ã‚‹ã‹åˆ¤å®šã—ã€CheckerãŒä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®å…ƒã§è§£æ³•ãŒæ­£ã—ã„ã‹ã‚’ç¢ºèªã™ã‚‹ã€‚<br><br>ç¶šã„ã¦ã€äººæ‰‹ã‚’ä»‹ã•ãšã¨ã‚‚ç”Ÿæˆã•ã‚Œã‚‹å•é¡ŒãŒæ­£ã—ã„ã“ã¨ã‚’æ‹…ä¿ã™ã‚‹ãŸã‚ã«dual-verificationã‚’æ¡ç”¨ã€‚å…·ä½“çš„ã«ã¯ã€LLMã«æ–°è¦ã®å•é¡Œæ–‡ã¨åŠ¹ç‡çš„ãªè§£æ³•ã‚’ç”Ÿæˆã•ã›ã€åŠ ãˆã¦ãƒ–ãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ã‚¹ã§ã®è§£æ³•ã‚’åˆ¥é€”ç”Ÿæˆã™ã‚‹ã€‚ãã—ã¦ã€ä¸¡è€…ã‚’LLMãŒç”Ÿæˆã—ãŸãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆç¾¤ã§å®Ÿè¡Œã—ã€å…¨ã¦ã®è§£æ”¾ã§å‡ºåŠ›ãŒä¸€è‡´ã—ãŸå ´åˆã®ã¿Acceptã™ã‚‹ã€ã¨ã„ã£ãŸã‚ˆã†ãªæ‰‹æ³•ã‚‰ã—ã„ã€‚<br><br>ï¼ˆæ‰‹æ³•ã®æ¦‚è¦ã¨ã—ã¦ã¯ãã†ãªã®ã ã‚ã†ãŒã€ç´°ã‹ã„å®Ÿè£…ã«é«˜å“è³ªã•ã®è‚ãŒã‚ã‚‹ã¨æ€ã†ã®ã§ã—ã£ã‹ã‚Šèª­ã‚“ã æ–¹ãŒè‰¯ã•ã’ã€‚ç‰¹ã«Test Generationã®è©³ç´°ã‚’ã—ã£ã‹ã‚Šã§ãã¦ã„ãªã„ï¼‰<br><br><img src="https://github.com/user-attachments/assets/e6779e5d-9e0a-4da8-9634-d6054704bfa7" alt="image" loading="lazy"></p>
<p>takeawayã§èˆˆå‘³æ·±ã‹ã£ãŸã®ã¯ã€<br><br>- LLMã¯è‡ªèº«ã§ã¯è§£ã‘ãªã„ãŒã€è§£æ³•ãŒå­˜åœ¨ã™ã‚‹ï¼ˆsolvable)å•é¡Œã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨<br>- äººé–“ã®å°‚é–€å®¶ã¨LLMï¼ˆo3)ã®é–“ã§ã€å•é¡Œã®å“è³ªã®æ–°è¦æ€§ã®åˆ¤å®šã®ç›¸é–¢ãŒã‚ãšã‹0.007, 0.11ã—ã‹ãªã‹ã£ãŸã“ã¨ã€‚ãã—ã¦å“è³ªã«é–¢ã—ã¦ã¯å°‚é–€å®¶ã®ã‚°ãƒ«ãƒ¼ãƒ—é–“ã§ã¯0.71, o3ã¨gpt4oã®é–“ã§ã¯0.72ã¨é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ã¦ãŠã‚Šã€LLMã¨äººé–“ã®å°‚é–€å®¶ã®é–“ã§è‘—ã—ãå•é¡Œã®å“è³ªã®åˆ¤æ–­åŸºæº–ãŒç•°ãªã‚‹ã“ã¨<br>- seedå•é¡Œã¨ç”Ÿæˆã•ã‚ŒãŸå•é¡Œã®é›£æ˜“åº¦ã®gainãŒã€å•é¡Œã®å“è³ªã«é–¢ã—ã¦ã€LLMè‡ªèº«ã®self-evaluationã‚ˆã‚Šã‚‚ã‚ˆã‚Šè‰¯ã„æŒ‡æ¨™ã¨ãªã£ã¦ã„ã‚‹ã“ã¨</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<a class="button" href="articles/Samplers.html" target="_blank" rel="noopener noreferrer">#Samplers</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3300" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reasoning with Sampling: Your Base Model is Smarter Than You Think, Aayush Karan+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ãšã«ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’å¼•ãå‡ºã™æ–¹æ³•ã‚’ææ¡ˆã€‚ãƒãƒ«ã‚³ãƒ•é€£é–ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­æŠ€è¡“ã«åŸºã¥ãåå¾©ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ã€MATH500ã€HumanEvalã€GPQAãªã©ã®ã‚¿ã‚¹ã‚¯ã§RLã«åŒ¹æ•µã™ã‚‹ã‹ãã‚Œã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚ã•ã‚‰ã«ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„ç‰¹åˆ¥ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å¿…è¦ã¨ã›ãšã€åºƒç¯„ãªé©ç”¨å¯èƒ½æ€§ã‚’æŒã¤ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://aakaran.github.io/reasoning_with_sampling/" target="_blank" rel="noopener noreferrer">https://aakaran.github.io/reasoning_with_sampling/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aakaran31/status/1979194052697280712?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3299" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Beyond Multi-Token Prediction: Pretraining LLMs with Future Summaries, Divyat Mahajan+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æœªæ¥è¦ç´„äºˆæ¸¬ï¼ˆFSPï¼‰ã‚’ææ¡ˆã—ã€é•·æœŸçš„ãªæ¨è«–ã‚„å‰µé€ çš„ãªåŸ·ç­†ã®èª²é¡Œã‚’è§£æ±ºã€‚FSPã¯ã€é•·æœŸçš„ãªæœªæ¥ã®ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªè¡¨ç¾ã‚’äºˆæ¸¬ã™ã‚‹è£œåŠ©ãƒ˜ãƒƒãƒ‰ã‚’ç”¨ã„ã€æƒ…å ±ã‚’ä¿æŒã€‚æ‰‹ä½œã‚Šã®è¦ç´„ã¨é€†è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹å­¦ç¿’è¦ç´„ã®2ã¤ã®ãƒãƒªã‚¢ãƒ³ãƒˆã‚’æ¢æ±‚ã€‚å¤§è¦æ¨¡ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€FSPãŒæ•°å­¦ã€æ¨è«–ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§NTPãŠã‚ˆã³MTPã‚’æ”¹å–„ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1979095788782522373?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é€†æ–¹å‘ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ãã®hidden stateã‚’æ•™å¸«ä¿¡å·ã¨ã—[^1]é †æ–¹å‘ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦åˆ¥ã®ãƒ˜ãƒƒãƒ‰ã‚’ç”¨æ„ã—representationã‚’å–å¾—ã€‚l2 lossã§é †æ–¹å‘ã¨é€†æ–¹å‘ã®representationãŒè¿‘ããªã‚‹ã‚ˆã†å­¦ç¿’ã—ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã§ã‚ã‚‹transformerã‚’å­¦ç¿’ã™ã‚‹ã‚ˆã†ãªäº‹å‰å­¦ç¿’æ‰‹æ³•ã€‚<br><br>[^1]:é€†æ–¹å‘è¨€èªãƒ¢ãƒ‡ãƒ«ã®hidden stateã¯future contextã«é–¢ã™ã‚‹è±Šå¯Œãªæƒ…å ±ã‚’å«ã‚“ã§ã„ã‚‹ãŸã‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DynamicNetworks.html" target="_blank" rel="noopener noreferrer">#DynamicNetworks</a>
<a class="button" href="articles/Routing.html" target="_blank" rel="noopener noreferrer">#Routing</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3298" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Dr.LLM: Dynamic Layer Routing in LLMs, Ahmed Heakl+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Dr.LLMã¯ã€LLMsã«å‹•çš„ãªå±¤ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’å°å…¥ã—ã€è¨ˆç®—åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­æœ¨æ¢ç´¢ã‚’ç”¨ã„ã¦é«˜å“è³ªãªå±¤æ§‹æˆã‚’å°å‡ºã—ã€ARCã‚„DARTã§ç²¾åº¦ã‚’æœ€å¤§+3.4%å‘ä¸Šã•ã›ã€å¹³å‡5å±¤ã‚’ç¯€ç´„ã€‚ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–ã‚¿ã‚¹ã‚¯ã§ã‚‚ã‚ãšã‹0.85%ã®ç²¾åº¦ä½ä¸‹ã§å¾“æ¥æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã€‚æ˜ç¤ºçš„ãªç›£è¦–ä¸‹ã§ã®ãƒ«ãƒ¼ã‚¿ãƒ¼ãŒLLMsã‚’åŠ¹ç‡çš„ã«æ´»ç”¨ã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Layerã”ã¨ã«MLPã®routerã‚’ç”¨æ„ã—ã€ï¼ˆå…ƒã®LLMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯freezeã—ã¦ï¼‰Layerã‚’skip, execute, repeatã™ã‚‹ã‹ã‚’è¿½åŠ ã§å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€ã‚¯ã‚¨ãƒªã«å¿œã˜ã¦å‹•çš„ã«è¨ˆç®—ã‚³ã‚¹ãƒˆã¨pathã‚’èª¿æ•´ã™ã‚‹èƒ½åŠ›ã‚’èº«ã«ã¤ã‘ã•ã›ã€æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã¤ã¤ã‚‚è¨ˆç®—é‡ã‚‚å‰Šæ¸›ã§ãã¾ã™ã€ã¨ã„ã£ãŸè©±ãªæ¨¡æ§˜ã€‚routerãŒå­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ã®ã§inferenceæ™‚ã«searchã¯ä¸è¦ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Entropy.html" target="_blank" rel="noopener noreferrer">#Entropy</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3297" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SEED-GRPO: Semantic Entropy Enhanced GRPO for Uncertainty-Aware Policy  Optimization, Minghan Chen+, arXiv'25, 2025.05</a>
<span class="snippet"><span>GPT Summary</span>- SEED-GRPOã¯ã€LLMã®ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ãŸãƒãƒªã‚·ãƒ¼æ›´æ–°æ‰‹æ³•ã§ã‚ã‚Šã€å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ„å‘³çš„ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚’æ¸¬å®šã—ã¦ãƒãƒªã‚·ãƒ¼æ›´æ–°ã®å¤§ãã•ã‚’èª¿æ•´ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é«˜ã„ä¸ç¢ºå®Ÿæ€§ã®è³ªå•ã«ã¯æ…é‡ãªæ›´æ–°ã‚’è¡Œã„ã€è‡ªä¿¡ã®ã‚ã‚‹è³ªå•ã«ã¯å…ƒã®å­¦ç¿’ä¿¡å·ã‚’ç¶­æŒã™ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€5ã¤ã®æ•°å­¦çš„æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ–°ãŸãªæœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ãŸã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zzlccc/status/1979060573233955186?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3283" target="_blank" rel="noopener noreferrer">[Paper Note] MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning
  Attention, MiniMax+, arXiv'25, 2025.06</a>
<br><br>ã¨ã®æ¯”è¼ƒã‚’è¦‹ã¦ã¿ãŸã„ãªã‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/PRM.html" target="_blank" rel="noopener noreferrer">#PRM</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3296" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier  Math, Shrey Pandit+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- LLMã«åŸºã¥ãæ¨è«–ã‚·ã‚¹ãƒ†ãƒ ãŒIMO 2025ã‚³ãƒ³ãƒšã§é‡‘ãƒ¡ãƒ€ãƒ«ãƒ¬ãƒ™ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ãŸãŒã€å„ã‚¹ãƒ†ãƒƒãƒ—ã®æ­£ç¢ºæ€§ã¨æ”¯æŒãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚ã“ã‚Œã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€500æ™‚é–“ä»¥ä¸Šã®äººé–“ã®åŠ´åŠ›ã§ä½œæˆã•ã‚ŒãŸã€ŒHard2Verifyã€ã¨ã„ã†ã‚¹ãƒ†ãƒƒãƒ—ãƒ¬ãƒ™ãƒ«æ¤œè¨¼ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã€‚æœ€å‰ç·šã®LLMã«ã‚ˆã‚‹å¿œç­”ã®ã‚¹ãƒ†ãƒƒãƒ—ãƒ¬ãƒ™ãƒ«æ³¨é‡ˆã‚’æä¾›ã—ã€ã‚¨ãƒ©ãƒ¼ã‚’ç‰¹å®šã™ã‚‹èƒ½åŠ›ã‚’è©•ä¾¡ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®æ¤œè¨¼è€…ã¯ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã«åŠ£ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€æ¤œè¨¼ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ä½ä¸‹è¦å› ã‚„è¨ˆç®—èƒ½åŠ›ã®å½±éŸ¿ã«ã¤ã„ã¦åˆ†æã‚’è¡Œã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/caimingxiong/status/1978855873327022405?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3289" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ParallelBench: Understanding the Trade-offs of Parallel Decoding in  Diffusion LLMs, Wonjun Kang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- dLLMã¯ä¸¦åˆ—ãƒ‡ã‚³ãƒ¼ãƒ‰ã«ã‚ˆã‚Šæ¨è«–ã‚’åŠ é€Ÿã™ã‚‹ãŒã€ãƒˆãƒ¼ã‚¯ãƒ³ã®ä¾å­˜é–¢ä¿‚ã‚’ç„¡è¦–ã™ã‚‹ãŸã‚ç”Ÿæˆå“è³ªãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚æ—¢å­˜ã®ç ”ç©¶ã¯ã“ã®å•é¡Œã‚’è¦‹è½ã¨ã—ã¦ãŠã‚Šã€æ¨™æº–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯è©•ä¾¡ãŒä¸ååˆ†ã§ã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€æƒ…å ±ç†è«–çš„åˆ†æã¨åˆæˆãƒªã‚¹ãƒˆæ“ä½œã®ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚’è¡Œã„ã€dLLMã®é™ç•Œã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚æ–°ãŸã«ææ¡ˆã™ã‚‹ParallelBenchã¯ã€dLLMã«ã¨ã£ã¦å›°é›£ãªã‚¿ã‚¹ã‚¯ã‚’ç‰¹å¾´ã¨ã—ã€åˆ†æã®çµæœã€dLLMã¯å®Ÿä¸–ç•Œã§ã®å“è³ªä½ä¸‹ã‚’å¼•ãèµ·ã“ã—ã€ç¾åœ¨ã®ãƒ‡ã‚³ãƒ¼ãƒ‰æˆ¦ç•¥ã¯é©å¿œæ€§ã«æ¬ ã‘ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã®ç™ºè¦‹ã¯ã€ã‚¹ãƒ”ãƒ¼ãƒ‰ã¨å“è³ªã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å…‹æœã™ã‚‹æ–°ã—ã„ãƒ‡ã‚³ãƒ¼ãƒ‰æ‰‹æ³•ã®å¿…è¦æ€§ã‚’å¼·èª¿ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://parallelbench.github.io" target="_blank" rel="noopener noreferrer">https://parallelbench.github.io</a>


</p>
<p>pj page:


<a href="https://parallelbench.github.io" target="_blank" rel="noopener noreferrer">https://parallelbench.github.io</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<a class="button" href="articles/Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3288" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RoboMonkey: Scaling Test-Time Sampling and Verification for  Vision-Language-Action Models, Jacky Kwok+, arXiv'25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- VLAãƒ¢ãƒ‡ãƒ«ã®å …ç‰¢æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã€ãƒ†ã‚¹ãƒˆæ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’èª¿æŸ»ã—ã€RoboMonkeyãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’å°å…¥ã€‚å°ã•ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚»ãƒƒãƒˆã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€VLMã‚’ç”¨ã„ã¦æœ€é©ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠã€‚åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã«ã‚ˆã‚Šæ¤œè¨¼ç²¾åº¦ãŒå‘ä¸Šã—ã€åˆ†å¸ƒå¤–ã‚¿ã‚¹ã‚¯ã§25%ã€åˆ†å¸ƒå†…ã‚¿ã‚¹ã‚¯ã§9%ã®æ”¹å–„ã‚’é”æˆã€‚æ–°ã—ã„ãƒ­ãƒœãƒƒãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¸ã®é©å¿œæ™‚ã«ã¯ã€VLAã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ¤œè¨¼å™¨ã®ä¸¡æ–¹ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§7%ã®æ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1978712036231217407?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3283" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning  Attention, MiniMax+, arXiv'25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- MiniMax-M1ã¯ã€4560å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ä¸–ç•Œåˆã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ¨è«–ãƒ¢ãƒ‡ãƒ«ã§ã€Mixture-of-Expertsã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ãƒ©ã‚¤ãƒˆãƒ‹ãƒ³ã‚°ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’çµ„ã¿åˆã‚ã›ã¦ã„ã¾ã™ã€‚1ç™¾ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«é©ã—ã¦ã„ã¾ã™ã€‚æ–°ã—ã„RLã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ CISPOã‚’ææ¡ˆã—ã€åŠ¹ç‡çš„ãªè¨“ç·´ã‚’å®Ÿç¾ã€‚æ¨™æº–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¼·åŠ›ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¤ºã—ã€ç‰¹ã«ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚„é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸçµæœã‚’å‡ºã—ã¦ã„ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2043" target="_blank" rel="noopener noreferrer">MiniMax-M1, MiniMax, 2025.06</a>
<br><br>ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3282" target="_blank" rel="noopener noreferrer">[Paper Note] The Art of Scaling Reinforcement Learning Compute for LLMs, Devvrit Khatri+, arXiv'25, 2025.10</a>
<br><br>ã§GSPO, DAPOã‚ˆã‚Šã‚‚å®‰å®šæ€§ã¨æœ€çµ‚åˆ°é”æ€§èƒ½ã§ã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸCISPOã¨å‘¼ã°ã‚Œã‚‹RLã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚</p>
<p>é–¢é€£:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/minimax__ai/status/1980221742707818646?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3282" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Art of Scaling Reinforcement Learning Compute for LLMs, Devvrit Khatri+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«é–¢ã™ã‚‹åŸå‰‡çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’å®šç¾©ã—ã€40ä¸‡æ™‚é–“ä»¥ä¸Šã®GPUæ™‚é–“ã‚’ç”¨ã„ãŸå¤§è¦æ¨¡ãªç ”ç©¶ã‚’å®Ÿæ–½ã€‚ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰å‹è¨ˆç®—-æ€§èƒ½æ›²ç·šã‚’ãƒ•ã‚£ãƒƒãƒˆã•ã›ã€è¨­è¨ˆé¸æŠè‚¢ã®å½±éŸ¿ã‚’åˆ†æã€‚çµæœã¨ã—ã¦ã€æ¼¸è¿‘çš„æ€§èƒ½ã¯ãƒ¬ã‚·ãƒ”ã«ã‚ˆã£ã¦ç•°ãªã‚Šã€è¨ˆç®—åŠ¹ç‡ã¯è©³ç´°ã«ä¾å­˜ã™ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚ã“ã‚Œã‚’åŸºã«ã€ScaleRLã¨ã„ã†ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã®ãƒ¬ã‚·ãƒ”ã‚’ææ¡ˆã—ã€100,000 GPUæ™‚é–“ã§ã®æˆåŠŸã‚’ç¤ºã—ãŸã€‚ã“ã®ç ”ç©¶ã¯ã€RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®äºˆæ¸¬å¯èƒ½æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®ç§‘å­¦çš„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1978956121416307148?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>&gt; ç°¡å˜ã«ãªã£ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é€šéç‡ãŒ0.9ä»¥ä¸Šï¼‰ã¯å†ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸã»ã†ãŒæœ€çµ‚æ€§èƒ½ãŒé«˜ã„<br><br>æœ€è¿‘ã¯ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å°å…¥ã—ã¦ã€ç°¡å˜ã™ããšé›£ã—ã™ããªã„å•é¡Œã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦åŠ¹ç‡ä¸Šã’ã‚‹ã€ã¨ã„ã£ãŸã‚ˆã†ãªè©±ãŒã‚ã£ãŸãŒã€ç°¡å˜ã«ãªã£ãŸå•é¡Œã‚’ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãªã„ã¨æœ€çµ‚æ€§èƒ½ã¨ã—ã¦ã¯ä½ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã‹â€¦æ„å¤–ã ã£ãŸã€‚<p>CISPO:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3283" target="_blank" rel="noopener noreferrer">[Paper Note] MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning
  Attention, MiniMax+, arXiv'25, 2025.06</a>
</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/devvrit_khatri/status/1978864275658871099?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/grad62304977/status/1979920784727429432?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-10-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3281" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GVPO: Group Variance Policy Optimization for Large Language Model  Post-Training, Kaichen Zhang+, arXiv'25, 2025.04</a>
<span class="snippet"><span>GPT Summary</span>- GVPOï¼ˆã‚°ãƒ«ãƒ¼ãƒ—åˆ†æ•£ãƒãƒªã‚·ãƒ¼æœ€é©åŒ–ï¼‰ã¯ã€ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹ä¸å®‰å®šæ€§ã‚’è§£æ±ºã™ã‚‹æ–°æ‰‹æ³•ã§ã€KLåˆ¶ç´„ä»˜ãå ±é…¬æœ€å¤§åŒ–ã®è§£æçš„è§£ã‚’å‹¾é…é‡ã¿ã«çµ„ã¿è¾¼ã‚€ã“ã¨ã§æœ€é©ãƒãƒªã‚·ãƒ¼ã¨ã®æ•´åˆæ€§ã‚’ä¿ã¤ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæœ€é©è§£ã‚’ä¿è¨¼ã—ã€æŸ”è»Ÿãªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°åˆ†å¸ƒã‚’ã‚µãƒãƒ¼ãƒˆã€‚GVPOã¯ä¿¡é ¼æ€§ã®é«˜ã„LLMãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®æ–°ãŸãªãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1978670665940271356?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1655" target="_blank" rel="noopener noreferrer">DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open
  Language Models, Zhihong Shao+, arXiv'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1821" target="_blank" rel="noopener noreferrer">Understanding R1-Zero-Like Training: A Critical Perspective, 2025.03</a>
</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<span class="issue_date">Issue Date: 2025-10-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3280" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Representation-Based Exploration for Language Models: From Test-Time to  Post-Training, Jens Tuyls+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ãŒè¨€èªãƒ¢ãƒ‡ãƒ«ã®è¡Œå‹•ç™ºè¦‹ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã€‚äº‹å‰å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®éš ã‚ŒçŠ¶æ…‹ã‚’åŸºã«ã—ãŸè¡¨ç¾ãƒ™ãƒ¼ã‚¹ã®ãƒœãƒ¼ãƒŠã‚¹ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€å¤šæ§˜æ€§ã¨pass@kç‡ãŒå¤§å¹…ã«æ”¹å–„ã•ã‚Œã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚æ¨è«–æ™‚ã«ãŠã‘ã‚‹æ¢ç´¢ãŒåŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã€ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦ã‚‚RLãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨ã®çµ±åˆã«ã‚ˆã‚Šæ€§èƒ½ãŒå‘ä¸Šã€‚æ„å›³çš„ãªæ¢ç´¢ãŒæ–°ã—ã„è¡Œå‹•ã®ç™ºè¦‹ã«å¯„ä¸ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/canondetortugas/status/1978245046366319048?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ¢ç´¢ã®å¤šæ§˜æ€§ã‚’ã‚ã’ã¦RLã“å­¦ç¿’åŠ¹ç‡ã€test time scalingã®åŠ¹ç‡ã‚’ä¸Šã’ã‚‹ã¨ã„ã†è©±</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<span class="issue_date">Issue Date: 2025-10-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3278" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Is It Thinking or Cheating? Detecting Implicit Reward Hacking by  Measuring Reasoning Effort, Xinpeng Wang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å ±é…¬ãƒãƒƒã‚­ãƒ³ã‚°ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒå ±é…¬é–¢æ•°ã®æŠœã‘ç©´ã‚’åˆ©ç”¨ã—ã¦æ„å›³ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã›ãšã«é«˜ã„å ±é…¬ã‚’å¾—ã‚‹è¡Œç‚ºã§ã‚ã‚Šã€é‡å¤§ãªè„…å¨ã‚’ã‚‚ãŸã‚‰ã™ã€‚TRACEï¼ˆTruncated Reasoning AUC Evaluationï¼‰ã‚’ææ¡ˆã—ã€æš—é»™çš„ãªå ±é…¬ãƒãƒƒã‚­ãƒ³ã‚°ã‚’æ¤œå‡ºã™ã‚‹ã€‚TRACEã¯ã€ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ãŒå ±é…¬ã‚’å¾—ã‚‹ã®ã«ã‹ã‹ã‚‹æ™‚é–“ã‚’æ¸¬å®šã—ã€ãƒãƒƒã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ãŒçŸ­ã„CoTã§é«˜ã„æœŸå¾…å ±é…¬ã‚’å¾—ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚TRACEã¯ã€æ•°å­¦çš„æ¨è«–ã§72B CoTãƒ¢ãƒ‹ã‚¿ãƒ¼ã«å¯¾ã—ã¦65%ä»¥ä¸Šã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§32Bãƒ¢ãƒ‹ã‚¿ãƒ¼ã«å¯¾ã—ã¦30%ä»¥ä¸Šã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã—ã€æœªçŸ¥ã®æŠœã‘ç©´ã‚’ç™ºè¦‹ã™ã‚‹èƒ½åŠ›ã‚‚ç¤ºã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç¾åœ¨ã®ç›£è¦–æ–¹æ³•ãŒåŠ¹æœçš„ã§ãªã„å ´åˆã«å¯¾ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªç„¡ç›£è¦–ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hhexiy/status/1978152000261869700?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-10-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3277" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Expert-as-a-Service: Towards Efficient, Scalable, and Robust Large-scale  MoE Serving, Ziming Liu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- EaaSã¨ã„ã†æ–°ã—ã„ã‚µãƒ¼ãƒ“ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚’ææ¡ˆã—ã€Mixture-of-Experts (MoE)ãƒ¢ãƒ‡ãƒ«ã®åŠ¹ç‡çš„ã§ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªå±•é–‹ã‚’å®Ÿç¾ã€‚MoEãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç‹¬ç«‹ã—ãŸã‚¹ãƒ†ãƒ¼ãƒˆãƒ¬ã‚¹ã‚µãƒ¼ãƒ“ã‚¹ã«åˆ†è§£ã—ã€ãƒªã‚½ãƒ¼ã‚¹ã®ç´°ã‹ã„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒˆãƒˆãƒ¬ãƒ©ãƒ³ã‚¹ã‚’æä¾›ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€EaaSã¯ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯ã‚·ã‚¹ãƒ†ãƒ ã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¶­æŒã—ã¤ã¤ã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®æ¸›å°‘ã‚’2%æœªæº€ã«æŠ‘ãˆã€æœ€å¤§37.5%ã®è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’ç¯€ç´„ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1978286917159624888?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<span class="issue_date">Issue Date: 2025-10-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3276" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Cautious Weight Decay, Lizhang Chen+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Cautious Weight Decayï¼ˆCWDï¼‰ã¯ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã«ä¾å­˜ã—ãªã„ä¿®æ­£ã§ã€æ›´æ–°ã¨ç¬¦å·ãŒä¸€è‡´ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã®ã¿ã‚¦ã‚§ã‚¤ãƒˆæ¸›è¡°ã‚’é©ç”¨ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å…ƒã®æå¤±ã‚’ä¿æŒã—ã¤ã¤ã€å±€æ‰€çš„ãªãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©ç‚¹ã‚’æ¢ç´¢å¯èƒ½ã«ã—ã¾ã™ã€‚CWDã¯ã€æ—¢å­˜ã®ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã«ç°¡å˜ã«é©ç”¨ã§ãã€æ–°ãŸãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¿…è¦ã¨ã›ãšã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ã‚„ImageNetåˆ†é¡ã§æå¤±ã¨ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1978320303681056889?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<span class="issue_date">Issue Date: 2025-10-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3275" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LightReasoner: Can Small Language Models Teach Large Language Models  Reasoning?, Jingyuan Wang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- LightReasonerã¯ã€SLMãŒLLMã®å¼·ã¿ã‚’æ´»ã‹ã—ã¦é«˜ä¾¡å€¤ã®æ¨è«–ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚é‡è¦ãªæ¨è«–ç¬é–“ã‚’ç‰¹å®šã—ã€å°‚é–€å®¶ãƒ¢ãƒ‡ãƒ«ã‚’èª¿æ•´ã™ã‚‹2æ®µéšã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµŒã¦ã€æ•°å­¦çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ç²¾åº¦ã‚’æœ€å¤§28.1%å‘ä¸Šã€æ™‚é–“æ¶ˆè²»ã‚’90%å‰Šæ¸›ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å•é¡Œã‚’80%æ¸›å°‘ã•ã›ãŸã€‚ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡ã®è‰¯ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€çœŸã®ãƒ©ãƒ™ãƒ«ã«ä¾å­˜ã›ãšã«LLMã®æ¨è«–ã‚’é€²å±•ã•ã›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huang_chao4969/status/1977915166995218584?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Label-free.html" target="_blank" rel="noopener noreferrer">#Label-free</a>
<span class="issue_date">Issue Date: 2025-10-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3274" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning to Make MISTAKEs: Modeling Incorrect Student Thinking And Key  Errors, Alexis Ross+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æ–°æ‰‹æ³•MISTAKEã‚’ææ¡ˆã—ã€ä¸æ­£ç¢ºãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã€‚ã‚µã‚¤ã‚¯ãƒ«æ•´åˆæ€§ã‚’åˆ©ç”¨ã—ã¦é«˜å“è³ªãªæ¨è«–ã‚¨ãƒ©ãƒ¼ã‚’åˆæˆã—ã€æ•™è‚²ã‚¿ã‚¹ã‚¯ã§ã®å­¦ç”Ÿã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚„èª¤è§£åˆ†é¡ã«ãŠã„ã¦é«˜ç²¾åº¦ã‚’é”æˆã€‚å°‚é–€å®¶ã®é¸æŠè‚¢ã¨ã®æ•´åˆæ€§ã‚‚å‘ä¸Šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacobandreas/status/1978208010829774899?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/UserModeling.html" target="_blank" rel="noopener noreferrer">#UserModeling</a>
<a class="button" href="articles/UserBased.html" target="_blank" rel="noopener noreferrer">#UserBased</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3273" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SimulatorArena: Are User Simulators Reliable Proxies for Multi-Turn  Evaluation of AI Assistants?, Yao Dou+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- SimulatorArenaã‚’å°å…¥ã—ã€909ä»¶ã®äººé–“-LLMä¼šè©±ã‚’ç”¨ã„ã¦ã€æ•°å­¦æŒ‡å°ã¨æ–‡æ›¸ä½œæˆã®2ã¤ã®ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã®è©•ä¾¡ã‚’è¡Œã†ã€‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒäººé–“ã®è¡Œå‹•ã¨ä¸€è‡´ã™ã‚‹åº¦åˆã„ã‚„ã€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆè©•ä¾¡ãŒäººé–“ã®åˆ¤æ–­ã¨æ•´åˆã™ã‚‹åº¦åˆã„ã‚’åŸºã«è©•ä¾¡ã€‚æ¡ä»¶ä»˜ã‘ã•ã‚ŒãŸã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ãŒäººé–“ã®åˆ¤æ–­ã¨é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ã€å®Ÿç”¨çš„ãªä»£æ›¿æ‰‹æ®µã‚’æä¾›ã€‚æœ€æ–°ã®18ã®LLMã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yaooo01/status/1978206110059205049?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®ä¼šè©±ã«ãŠã„ã¦AIã¨äººé–“ã¨ã®å¯¾è©±ï¼ˆæ•°å­¦ã®tutoring, æ–‡æ›¸ã®ä½œæˆæ”¯æ´ï¼‰ã‚’è©•ä¾¡ã™ã‚‹éš›ã«ã€å®Ÿéš›ã®äººé–“ã¯ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚Šã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„ã®ã§LLMã‚’äººé–“ã®ä»£æ›¿ã¨ã—è©•ä¾¡ãŒã§ãã‚‹ã‹ï¼Ÿã©ã®ã‚ˆã†ã«ã™ã‚Œã°LLMã‚’äººé–“ã®æŒ¯ã‚‹èˆã„ã¨æ•´åˆã•ã›ã‚‰ã‚Œã‚‹ã‹ï¼Ÿã¨ã„ã£ãŸè©±ã—ã§ã€25ç¨®é¡ä»¥ä¸Šã®attributeã«ã‚ˆã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨ã„ã‚‹ã“ã¨ãŒæœ‰åŠ¹ã ã£ãŸï¼ˆäººé–“ã®è©•ä¾¡çµæœã«å¯¾ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨ã„ãŸLLMã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ãŒã‚ˆã‚Šé«˜ã„ç›¸é–¢ã‚’ç¤ºã—ãŸï¼‰ã¨ã„ã†ã‚ˆã†ãªè©±ã—ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/MemoryOptimization.html" target="_blank" rel="noopener noreferrer">#MemoryOptimization</a>
<span class="issue_date">Issue Date: 2025-10-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3271" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Not All Bits Are Equal: Scale-Dependent Memory Optimization Strategies  for Reasoning Models, Junhyuck Kim+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 4ãƒ“ãƒƒãƒˆé‡å­åŒ–ã¯ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã«æœ‰åŠ¹ã§ã™ãŒã€æ¨è«–ãƒ¢ãƒ‡ãƒ«ã«ã¯é©ç”¨ã§ããªã„ã“ã¨ã‚’ç¤ºã™ã€‚ä½“ç³»çš„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å½±éŸ¿ã‚’ç™ºè¦‹ã€‚å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã¯é‡ã¿ã‚’å„ªå…ˆã—ã€å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã¯ç”Ÿæˆã«ãƒ¡ãƒ¢ãƒªã‚’å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ã§ç²¾åº¦ã‚’å‘ä¸Šã€‚LLMã®ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã¯ã‚¹ã‚±ãƒ¼ãƒ«ã«ä¾å­˜ã—ã€ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dimitrispapail/status/1978108550854382052?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Reasoning Modelã«ãŠã„ã¦ã€ãƒ¡ãƒ¢ãƒªã®budgetã«åˆ¶ç´„ãŒã‚ã‚‹çŠ¶æ³ä¸‹ã«ãŠã„ã¦ã€<br>- ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º<br>- é‡ã¿ã®ç²¾åº¦<br>- test-time compute (serial &amp; parallel)<br>- KV Cacheã®åœ§ç¸®<br><br>ã«ãŠã„ã¦ã€ãã‚Œã‚‰ã‚’ã©ã®ã‚ˆã†ã«é…åˆ†ã™ã‚‹ã“ã¨ã§ãƒ¢ãƒ‡ãƒ«ã®Acc.ãŒæœ€å¤§åŒ–ã•ã‚Œã‚‹ã‹ï¼Ÿã¨ã„ã†è©±ã—ãªæ¨¡æ§˜ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<a class="button" href="articles/RecurrentModels.html" target="_blank" rel="noopener noreferrer">#RecurrentModels</a>
<a class="button" href="articles/RecursiveModels.html" target="_blank" rel="noopener noreferrer">#RecursiveModels</a>
<span class="issue_date">Issue Date: 2025-10-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3269" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Encode, Think, Decode: Scaling test-time reasoning with recursive latent  thoughts, Yeskendir Koishekenov+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ETDæ‰‹æ³•ã‚’ç”¨ã„ã¦ã€LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ç‰¹å®šã®å±¤ã‚’åå¾©ã™ã‚‹ã“ã¨ã§ã€17ã®æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¤§å¹…ãªç²¾åº¦å‘ä¸Šã‚’é”æˆã€‚GSM8Kã§28.4%ã€MATHã§36%ã®å‘ä¸Šã‚’ç¤ºã—ã€å†å¸°çš„ãªæ¨è«–ãŒåŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yeskendir_k/status/1978117258720530641?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3268" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] EVALUESTEER: Measuring Reward Model Steerability Towards Values and  Preferences, Kshitish Ghate+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- EVALUESTEERã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¤šæ§˜ãªä¾¡å€¤è¦³ã‚„ã‚¹ã‚¿ã‚¤ãƒ«ã«å¯¾å¿œã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚Šã€LLMsã¨å ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼ˆRMsï¼‰ã®æ“ç¸¦æ€§ã‚’æ¸¬å®šã—ã¾ã™ã€‚165,888ã®å¥½ã¿ãƒšã‚¢ã‚’ç”Ÿæˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã«åŸºã¥ãå¿œç­”ã®é¸æŠç²¾åº¦ã‚’è©•ä¾¡ã€‚å®Œå…¨ãªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã§ã¯75%æœªæº€ã®ç²¾åº¦ã«å¯¾ã—ã€é–¢é€£ã™ã‚‹å¥½ã¿ã®ã¿ã§99%ä»¥ä¸Šã®ç²¾åº¦ã‚’é”æˆã€‚EVALUESTEERã¯ã€RMsã®é™ç•Œã‚’æ˜ã‚‰ã‹ã«ã—ã€å¤šæ§˜ãªä¾¡å€¤è¦³ã«å¯¾å¿œã™ã‚‹ãŸã‚ã®ãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ghatekshitish/status/1978128389157380570?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLNã®Alignmentã¯ã—ã°ã—ã°Reward Modelã‚’ãƒ™ãƒ¼ã‚¹ã«å®Ÿæ–½ã•ã‚Œã‚‹ãŒã€ç¾åœ¨ã®Reward Modelã«å­˜åœ¨ã™ã‚‹ã€ä¾¡å€¤è¦³ï¼ˆ4ç¨®é¡ï¼‰ã¨ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆ4ç¨®é¡ï¼‰ã«é–¢ã™ã‚‹ãƒã‚¤ã‚¢ã‚¹ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-10-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3267" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning to See Before Seeing: Demystifying LLM Visual Priors from  Language Pre-training, Junlin Han+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§è¨“ç·´ã•ã‚ŒãªãŒã‚‰ã‚‚è¦–è¦šçš„å…ˆå…¥è¦³ã‚’ç™ºå±•ã•ã›ã€å°‘é‡ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã§è¦–è¦šã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œå¯èƒ½ã«ã™ã‚‹ã€‚è¦–è¦šçš„å…ˆå…¥è¦³ã¯ã€è¨€èªã®äº‹å‰è¨“ç·´ä¸­ã«ç²å¾—ã•ã‚ŒãŸçŸ¥è­˜ã§ã‚ã‚Šã€æ¨è«–ä¸­å¿ƒã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç™ºå±•ã™ã‚‹ã€‚çŸ¥è¦šã®å…ˆå…¥è¦³ã¯åºƒç¯„ãªã‚³ãƒ¼ãƒ‘ã‚¹ã‹ã‚‰å¾—ã‚‰ã‚Œã€è¦–è¦šã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã«æ•æ„Ÿã§ã‚ã‚‹ã€‚è¦–è¦šã‚’æ„è­˜ã—ãŸLLMã®äº‹å‰è¨“ç·´ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒã®ãƒ¬ã‚·ãƒ”ã‚’ææ¡ˆã—ã€500,000 GPUæ™‚é–“ã‚’ã‹ã‘ãŸå®Ÿé¨“ã«åŸºã¥ãå®Œå…¨ãªMLLMæ§‹ç¯‰ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç¤ºã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¦–è¦šçš„å…ˆå…¥è¦³ã‚’è‚²æˆã™ã‚‹æ–°ã—ã„æ–¹æ³•ã‚’æä¾›ã—ã€æ¬¡ä¸–ä»£ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMã®ç™ºå±•ã«å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1977982648531476607?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MLE Bench (Multi-Level Existence Bench)</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3265" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Alignment Waltz: Jointly Training Agents to Collaborate for Safety, Jingyu Zhang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- WaltzRLã¨ã„ã†æ–°ã—ã„ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€LLMã®æœ‰ç”¨æ€§ã¨ç„¡å®³æ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ã€‚ä¼šè©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å…±åŒè¨“ç·´ã—ã€å¿œç­”ã®å®‰å…¨æ€§ã¨æœ‰ç”¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€å®‰å…¨ã§ãªã„å¿œç­”ã¨éå‰°ãªæ‹’å¦ã‚’å¤§å¹…ã«æ¸›å°‘ã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã€LLMã®å®‰å…¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1978185306999341256?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç”¨ã„ãŸLLMã®alignmentæ‰‹æ³•ã€‚ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®promptã«å¿œç­”ã™ã‚‹ä¼šè©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã€å¿œç­”ã‚’æ‰¹è©•ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®2ç¨®é¡ã‚’ç”¨æ„ã—ã€é•ã„ãŒäº¤äº’ä½œç”¨ã—ãªãŒã‚‰å­¦ç¿’ã™ã‚‹ã€‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¼šè©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå®‰å…¨ã‹ã¤éå‰°ã«å¿œç­”ã‚’æ‹’çµ¶ã—ã¦ã„ãªã„å ´åˆã®ã¿å ±é…¬ã‚’ä¸ãˆã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒæ¬¡ã®ã‚¿ãƒ¼ãƒ³ã®ä¼šè©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¿œç­”ã‚’æ”¹å–„ã—ãŸã‚‰ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å ±é…¬ãŒä¸ãˆã‚‰ã‚Œã‚‹ã€ã¿ãŸã„ãªæ çµ„ã¿ãªæ¨¡æ§˜ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<span class="issue_date">Issue Date: 2025-10-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3264" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Potential of Second-Order Optimization for LLMs: A Study with Full  Gauss-Newton, Natalie Abreu+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®äº‹å‰å­¦ç¿’ã«ãŠã‘ã‚‹è¨ˆç®—åŠ¹ç‡å‘ä¸Šã®ãŸã‚ã€ãƒ•ãƒ«ã‚¬ã‚¦ã‚¹-ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ³ï¼ˆGNï¼‰å‰å‡¦ç†ã‚’æœ€å¤§150Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã«é©ç”¨ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€GNæ›´æ–°ãŒãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®åå¾©å›æ•°ã‚’5.4å€å‰Šæ¸›ã—ã€å±¤é–“æƒ…å ±ã‚’ç„¡è¦–ã—ãŸå±¤åˆ¥GNå‰å‡¦ç†å™¨ãŒãƒ•ãƒ«GNã«è¿‘ã„æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ãŒåˆ¤æ˜ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€GNè¿‘ä¼¼ã®åŠ¹æœã‚„å±¤åˆ¥ãƒ˜ãƒƒã‚»è¡Œåˆ—ã®æƒ…å ±ã®é‡è¦æ€§ã€è¿‘ä¼¼æ‰‹æ³•ã¨ç†æƒ³çš„ãªå±¤åˆ¥ã‚ªãƒ©ã‚¯ãƒ«ã¨ã®æ€§èƒ½ã‚®ãƒ£ãƒƒãƒ—ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1978243717787246643?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<a class="button" href="articles/Faithfulness.html" target="_blank" rel="noopener noreferrer">#Faithfulness</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Trustfulness.html" target="_blank" rel="noopener noreferrer">#Trustfulness</a>
<span class="issue_date">Issue Date: 2025-10-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3262" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Necessary Step toward Faithfulness: Measuring and Improving   Consistency in Free-Text Explanations, Lingjun Zhao+, EMNLP'25, 2025.05</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€AIæ„æ€æ±ºå®šã«ãŠã‘ã‚‹è‡ªç”±å½¢å¼ã®èª¬æ˜ã®ä¿¡é ¼æ€§ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã«ã€äºˆæ¸¬-èª¬æ˜æ•´åˆæ€§ã®æ–°ã—ã„æ¸¬å®šæ–¹æ³•ã‚’ææ¡ˆã€‚å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹èª¬æ˜ã®62%ä»¥ä¸ŠãŒæ•´åˆæ€§ã‚’æ¬ ã„ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã€æœ€é©åŒ–ã«ã‚ˆã‚Šæ•´åˆæ€§ãŒ43.1%ã‹ã‚‰292.3%æ”¹å–„ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªã€‚ã¾ãŸã€æ•´åˆæ€§ã®æœ€é©åŒ–ã«ã‚ˆã‚Šèª¬æ˜ã®ä¿¡é ¼æ€§ãŒæœ€å¤§9.7%å‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lingjunzh/status/1978134250592288985?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Hal Daumeæ°ãŒlast author</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3261" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Stabilizing MoE Reinforcement Learning by Aligning Training and  Inference Routers, Wenhan Ma+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã‚’ç”¨ã„ãŸMixture-of-Expertsï¼ˆMoEï¼‰ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®ä¸ä¸€è‡´ã‚’åˆ†æã—ã€Rollout Routing Replayï¼ˆR3ï¼‰ã‚’ææ¡ˆã€‚R3ã¯æ¨è«–æ™‚ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°åˆ†å¸ƒã‚’è¨˜éŒ²ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«å†ç”Ÿã™ã‚‹ã“ã¨ã§ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®ãƒãƒªã‚·ãƒ¼é–“ã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚’æ¸›å°‘ã•ã›ã€å®‰å®šæ€§ã‚’å‘ä¸Šã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€R3ãŒRLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å´©å£Šã‚’é˜²ãã€ä»–ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1977990785795576316?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2552" target="_blank" rel="noopener noreferrer">Your Efficient RL Framework Secretly Brings You Off-Policy RL Training, Yao+, 2025.08</a>
<br><br>ã®MoEç‰ˆã®è©±ã€‚Inference Engineã¨Training Engineå´ã§Expertsã®é¸æŠãŒä¸€è‡´ã—ãªã„ã“ã¨ãŒä¸å®‰å®šã«ã¤ãªãŒã‚‹ã®ã§ã€ãã‚Œã‚’ä¸€è‡´ã•ã›ã‚‹ã‚ˆã†ã«ã™ã‚‹ã€ã¨ã„ã†è©±ãªæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/0335e297-332d-4759-9c9a-9f9e7e634b5d" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/Entropy.html" target="_blank" rel="noopener noreferrer">#Entropy</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3259" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] QeRL: Beyond Efficiency -- Quantization-enhanced Reinforcement Learning  for LLMs, Wei Huang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- QeRLã¯ã€LLMså‘ã‘ã®é‡å­åŒ–å¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€NVFP4é‡å­åŒ–ã¨LoRAã‚’çµ„ã¿åˆã‚ã›ã¦RLã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’åŠ é€Ÿã—ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›ã—ã¾ã™ã€‚é‡å­åŒ–ãƒã‚¤ã‚ºãŒãƒãƒªã‚·ãƒ¼ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚’å¢—åŠ ã•ã›ã€æ¢ç´¢ã‚’å¼·åŒ–ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã€AQNãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã§ãƒã‚¤ã‚ºã‚’å‹•çš„ã«èª¿æ•´ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆãƒ•ã‚§ãƒ¼ã‚ºã§1.5å€ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’é”æˆã—ã€32B LLMã®RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å˜ä¸€ã®H100 80GB GPUã§å¯èƒ½ã«ã—ã¾ã—ãŸã€‚QeRLã¯ã€å ±é…¬ã®æˆé•·ã¨æœ€çµ‚ç²¾åº¦ã§å„ªã‚ŒãŸçµæœã‚’ç¤ºã—ã€LLMsã«ãŠã‘ã‚‹RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŠ¹ç‡çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨ã—ã¦ã®åœ°ä½ã‚’ç¢ºç«‹ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://github.com/NVlabs/QeRL" target="_blank" rel="noopener noreferrer">https://github.com/NVlabs/QeRL</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1977949560149315847?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2552" target="_blank" rel="noopener noreferrer">Your Efficient RL Framework Secretly Brings You Off-Policy RL Training, Yao+, 2025.08</a>
<br><br>ã®ã‚ˆã†ãªãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã™ã‚‹éš›ã®ã‚¨ãƒ³ã‚¸ãƒ³ã¨å­¦ç¿’ã®ã‚¨ãƒ³ã‚¸ãƒ³ã®gapã«ã‚ˆã‚‹å•é¡Œã¯ç”Ÿã˜ãŸã‚Šã—ãªã„ã®ã ã‚ã†ã‹ã€‚</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1979325188581007627?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Entropy.html" target="_blank" rel="noopener noreferrer">#Entropy</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3255" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Demystifying Reinforcement Learning in Agentic Reasoning, Zhaochen Yu+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçš„å¼·åŒ–å­¦ç¿’ï¼ˆagentic RLï¼‰ã‚’ç”¨ã„ã¦ã€LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®èª¿æŸ»ã‚’è¡Œã£ãŸã€‚é‡è¦ãªæ´å¯Ÿã¨ã—ã¦ã€åˆæˆè»Œé“ã®å®Ÿéš›ã®ãƒ„ãƒ¼ãƒ«ä½¿ç”¨è»Œé“ã¸ã®ç½®ãæ›ãˆã‚„ã€å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ´»ç”¨ãŒRLã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã¾ãŸã€æ¢ç´¢ã‚’ä¿ƒé€²ã™ã‚‹æŠ€è¡“ã‚„ã€ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’æ¸›ã‚‰ã™æˆ¦ç•¥ãŒãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ã‚’æ”¹å–„ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å°å‹ãƒ¢ãƒ‡ãƒ«ã§ã‚‚å¼·åŠ›ãªçµæœã‚’é”æˆã—ã€å®Ÿç”¨çš„ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã™ã‚‹ã€‚ã•ã‚‰ã«ã€é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€å›°é›£ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçš„æ¨è«–èƒ½åŠ›ã®å‘ä¸Šã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lingyang_pu/status/1977931241916862779?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1978112328974692692?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3254" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Part II: ROLL Flash -- Accelerating RLVR and Agentic Training with  Asynchrony, Han Lu+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- éåŒæœŸRLå¾Œå‡¦ç†ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã€ŒROLL Flashã€ã‚’ææ¡ˆã€‚ç´°ç²’åº¦ã®ä¸¦åˆ—æ€§ã¨ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆãƒ»ãƒˆãƒ¬ã‚¤ãƒ³ã®ãƒ‡ã‚«ãƒƒãƒ—ãƒªãƒ³ã‚°ã«åŸºã¥ãã€åŠ¹ç‡çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å®Ÿç¾ã€‚ROLL Flashã¯ãƒªã‚½ãƒ¼ã‚¹åˆ©ç”¨åŠ¹ç‡ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’å¤§å¹…ã«æ”¹å–„ã—ã€RLVRã‚¿ã‚¹ã‚¯ã§æœ€å¤§2.24å€ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¿ã‚¹ã‚¯ã§æœ€å¤§2.72å€ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’é”æˆã€‚éåŒæœŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒåŒæœŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1977959866699513889?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RLã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆä¸­ã®GPUã®ã‚¢ã‚¤ãƒ‰ãƒ«ã‚¿ã‚¤ãƒ ã‚’å‰Šæ¸›ã—ã¾ã™ç³»ã®è©±ã‚‚æœ€è¿‘çµæ§‹è¦‹ã‚‹ã‚ˆã†ãª<br>ãŸã¨ãˆã°<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3134" target="_blank" rel="noopener noreferrer">Anatomy of a Modern Finetuning API, Benjamin Anderson, 2025.10</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Self-SupervisedLearning.html" target="_blank" rel="noopener noreferrer">#Self-SupervisedLearning</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/WorldModels.html" target="_blank" rel="noopener noreferrer">#WorldModels</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3253" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Agent Learning via Early Experience, Kai Zhang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç›®æ¨™ã¯ã€çµŒé¨“ã‚’é€šã˜ã¦å­¦ã³ã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã§äººé–“ã‚’ä¸Šå›ã‚‹ã“ã¨ã§ã™ãŒã€å¼·åŒ–å­¦ç¿’ã«ã¯å ±é…¬ã®æ¬ å¦‚ã‚„éåŠ¹ç‡çš„ãªãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆãŒèª²é¡Œã§ã™ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè‡ªèº«ã®è¡Œå‹•ã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸç›¸äº’ä½œç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã‚‹ã€Œæ—©æœŸçµŒé¨“ã€ã¨ã„ã†æ–°ãŸãªãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã€(1) æš—é»™ã®ä¸–ç•Œãƒ¢ãƒ‡ãƒ«åŒ–ã¨(2) è‡ªå·±åçœã®2ã¤ã®æˆ¦ç•¥ã‚’ç ”ç©¶ã—ã€8ã¤ã®ç’°å¢ƒã§è©•ä¾¡ã‚’è¡Œã£ãŸçµæœã€åŠ¹æœæ€§ã¨ä¸€èˆ¬åŒ–ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚æ—©æœŸçµŒé¨“ã¯ã€å¼·åŒ–å­¦ç¿’ã®åŸºç›¤ã‚’æä¾›ã—ã€æ¨¡å€£å­¦ç¿’ã¨çµŒé¨“é§†å‹•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ©‹æ¸¡ã—ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/godofprompt/status/1977629442307686708?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLM Agentã®ãŸã‚ã®Warmupæ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚å…·ä½“çš„ã«ã¯RLVRã‚„Imitation Learningã«ã‚ˆã£ã¦RewardãŒå®šç¾©ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã“ã‚Œã¾ã§ã¯RLãŒå®Ÿç¾ã•ã‚Œã¦ããŸãŒã€ã“ã‚Œã‚‰ã¯ã‚¹ã‚±ãƒ¼ãƒ«ã›ãšã€RewardãŒå®šç¾©ã•ã‚Œãªã„ç’°å¢ƒã®trajectoryãªã©ã¯å­¦ç¿’ã•ã‚Œãªã„ã®ã§æ±åŒ–æ€§èƒ½ãŒä½ã„ã¨ã„ã†èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã®ãŸã‚ã€ã“ã‚Œã‚‰ã®supervisionã¤ãã®æ–¹æ³•ã§å­¦ç¿’ã‚’ã™ã‚‹å‰ã®warmupæ‰‹æ³•ã¨ã—ã¦ã€reward-freeã®å­¦ç¿’ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ  Early Experienceã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br>&lt;img width="677" height="339" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/c2ed5999-d6d8-419d-93e9-f3358ab0ca1f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/c2ed5999-d6d8-419d-93e9-f3358ab0ca1f"&lt;/a&gt;


/&gt;<br><br>æ‰‹æ³•ã¨ã—ã¦ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ³•ãŒ2ç¨®é¡ææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚<br>### Implicit World Modeling \(IWM, å¼\(3)):<br>ã‚ã‚‹çŠ¶æ…‹s\_i ã«ãŠã„ã¦ action a\_i^{j}ã‚’ \(1 &lt; j &lt; |K|)ã‚’ã¨ã£ãŸæ™‚ã®çŠ¶æ…‹ã‚’s\_i^{j}ã¨ã—ãŸã¨ãã«ã€\(s\_i, a\_i^{j}, s\_i^{j}) ã®3ã¤çµ„ã‚’è€ƒãˆã‚‹ã€‚ã“ã‚Œã‚‰ã¯ãƒãƒªã‚·ãƒ¼ã‹ã‚‰ã®Kå›ã®rolloutã«ã‚ˆã£ã¦ç”Ÿæˆå¯èƒ½ã€‚<br>ã“ã®ã¨ãã«ã€çŠ¶æ…‹sã‚’å…¨ã¦ãƒ†ã‚­ã‚¹ãƒˆã§è¡¨ç¾ã™ã‚‹ã‚ˆã†ã«ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®next-token-prediction lossã‚’ç”¨ã„ã¦ã€ã‚ã‚‹çŠ¶æ…‹s\_jã«ãŠã„ã¦action a\_i^{k} ã‚’ã¨ã£ãŸã¨ãã«ã€s\_j^{k} ã«ãªã‚‹ã“ã¨ã‚’äºˆæ¸¬ã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šä¾‹ãˆã°ãƒ–ãƒƒã‚¯ãƒ•ãƒ©ã‚¤ãƒˆã®ã‚µã‚¤ãƒˆã§èª¤ã£ãŸæ—¥æ™‚ã‚’å…¥ã‚Œã¦ã—ã¾ã£ãŸå ´åˆã‚„ã€ã©ã“ã‹ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ãŸã¨ãã«ã©ã“ã«é·ç§»ã™ã‚‹ã‹ãªã©ã®å­¦ç¿’ã™ã‚‹ç’°å¢ƒã®ä¸–ç•ŒçŸ¥è­˜ã‚’implicitã«ãƒ¢ãƒ‡ãƒ«ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã‚‹ã€‚<br><br>### Self-Reflectionï¼ˆå¼4ï¼‰<br>ã‚‚ã†ä¸€ã¤ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã¨ã—ã¦ã€å°‚é–€å®¶ã«ã‚ˆã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ a\_i ã«ã‚ˆã£ã¦å¾—ã‚‰ã‚ŒãŸçŠ¶æ…‹ s\_i ã¨ã€ãã‚Œã‚‰ä»¥å¤–ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ a\_i^{j} ã«ã‚ˆã£ã¦å¾—ã‚‰ã‚ŒãŸçŠ¶æ…‹ s\_i^{j}ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€s\_iã¨s\_i^{j}ã‚’æ¯”è¼ƒã—ãŸã¨ãã«ã€ãªãœ a\_i ã®æ–¹ãŒa\_i^{j} ã‚ˆã‚Šã‚‚å¥½ã¾ã—ã„ã‹ã‚’èª¬æ˜ã™ã‚‹CoT C\_i^{j}ã‚’ç”Ÿæˆã—ã€ä¸‰ã¤çµ„ãƒ‡ãƒ¼ã‚¿\(s\_i, a\_i^{j}, c\_i^{j}) ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€çŠ¶æ…‹s\_iãŒgivenãªã¨ãã«ã€a\_i ã« c\_i^{j} ã‚’concatã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’äºˆæ¸¬ã§ãã‚‹ã‚ˆã†ã«next-token-prediction lossã§å­¦ç¿’ã™ã‚‹ã€‚ã¾ãŸã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã ã‘ã§ãªãæ±åŒ–æ€§èƒ½ã‚’ã‚ˆã‚Šé«˜ã‚ã‚‹ãŸã‚ã«expertã«ã‚ˆã‚‹imitation learningã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿CoTãªã—ã®ãƒ‡ãƒ¼ã‚¿ã‚‚mixã—ã¦å­¦ç¿’ã‚’ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€expertã«ã‚ˆã‚‹actionã ã‘ã§å­¦ç¿’ã™ã‚‹ã‚ˆã‚Šã‚‚ã€ãªãœexpertã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒè‰¯ã„ã‹ã¨ã„ã†æƒ…å ±ã«åŸºã¥ã„ã¦ã‚ˆã‚Šè±Šå¯Œã§è»¢ç§»å¯èƒ½ãªå­¦ç¿’ã‚·ã‚°ãƒŠãƒ«ã‚’æ´»ç”¨ã—å­¦ç¿’ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br> <br>&lt;img width=\"712\" height=\"399\" alt=\"Image\" src=\"


&lt;a href="https://github.com/user-attachments/assets/d411ac3b-d977-4357-b715-0cf4e5b95fa2"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/d411ac3b-d977-4357-b715-0cf4e5b95fa2"&lt;/a&gt;


/&gt;<br><br>ã“ã®çµæœã€downstreamã‚¿ã‚¹ã‚¯ã§ã®performanceãŒå˜ã«Imitation Learningã‚’å®Ÿæ–½ã—ãŸå ´åˆã¨æ¯”è¼ƒã—ã¦ææ¡ˆæ‰‹æ³•ã§warmupã—ãŸæ–¹ãŒä¸€è²«ã—ã¦å‘ä¸Šã™ã‚‹ã€‚ã¾ãŸã€5.4ç¯€ã«post-trainingã¨ã—ã¦è¿½åŠ ã§GRPOã‚’å®Ÿæ–½ã—ãŸå ´åˆã‚‚ææ¡ˆæ‰‹æ³•ã«ã‚ˆã‚‹warmupã‚’å®Ÿæ–½ã—ãŸå ´åˆãŒæœ€çµ‚çš„ãªæ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>&lt;img width="668" height="596" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/a0aad636-b889-4d2d-b753-b0ad5ad4c688"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a0aad636-b889-4d2d-b753-b0ad5ad4c688"&lt;/a&gt;


/&gt;</p>
<p>IWMã¯è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’ã®æ çµ„ã¿ã ã¨æ€ã‚ã‚Œã‚‹ã®ã§ã€ã‚ˆã¬ã‚¹ã‚±ãƒ¼ãƒ«ã—ã€ã‹ã¤æ±åŒ–æ€§èƒ½ãŒé«˜ãæ§˜ã€…ãªæ‰‹æ³•ã®ãƒ™ãƒ¼ã‚¹ã¨ãªã‚Šã†ã‚‹æ‰‹æ³•ã«è¦‹ãˆã‚‹ã€‚</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1979179944258265358?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3252" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence  Reweighting, Yunzhen Feng+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ã«ãŠã‘ã‚‹ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æ´»ç”¨ã™ã‚‹æ–°æ‰‹æ³•LENSã‚’ææ¡ˆã€‚ä¿¡é ¼åº¦ã«åŸºã¥ããƒšãƒŠãƒ«ãƒ†ã‚£ã‚’è¿½åŠ ã—ã€èª¤ã£ãŸå¿œç­”ã«å¯¾ã—ã¦ã‚‚å ±é…¬ã‚’ä¸ãˆã‚‹ã“ã¨ã§ã€ç„¡é§„ãªã‚µãƒ³ãƒ—ãƒ«ã‚’æœ‰ç”¨ãªå‹¾é…æ›´æ–°ã«å¤‰æ›ã€‚MATHãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§GRPOã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€RLVRã®åŠ¹ç‡ã¨æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/feeelix_feng/status/1977794020672786741?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>DAPOãªã©ã®dynamic samplingã¯å…¨ã¦ã®å¿œç­”ãŒnegativeãªã‚°ãƒ«ãƒ¼ãƒ—ã¯ç ´æ£„ã™ã‚‹ãŒã€ãã‚Œã‚‰ã‚‚æ´»ç”¨ã—ã¦å­¦ç¿’ã§ãã‚‹ã‚ˆã†ãªæ çµ„ã¿ãªæ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3251" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Next Semantic Scale Prediction via Hierarchical Diffusion Language   Models, Cai Zhou+, NeurIPS'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- éšå±¤çš„æ‹¡æ•£è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆHDLMï¼‰ã¯ã€ä½ãƒ¬ãƒ™ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒé«˜ãƒ¬ãƒ™ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚Œã‚‹éšå±¤çš„ãªèªå½™ã«åŸºã¥ãæ–°ã—ã„è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°æ‰‹æ³•ã§ã™ã€‚å‰æ–¹ãƒ—ãƒ­ã‚»ã‚¹ã§ã¯ãƒˆãƒ¼ã‚¯ãƒ³ãŒé«˜ãƒ¬ãƒ™ãƒ«ã®å…ˆç¥–ã«æ‘‚å‹•ã•ã‚Œã€é€†ãƒ—ãƒ­ã‚»ã‚¹ã§ã¯è©³ç´°ãªæ„å‘³ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚HDLMã¯ã€æ‹¡æ•£ã®è¨¼æ‹ ä¸‹é™ï¼ˆELBOï¼‰ã®é–‰å½¢å¼è¡¨ç¾ã‚’å°å‡ºã—ã€æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’å«ã‚€æŸ”è»Ÿãªå®Ÿè£…ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€HDLMã¯ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚ˆã‚Šã‚‚ä½ã„å›°æƒ‘åº¦ã‚’é”æˆã—ã€ãã®æœ‰åŠ¹æ€§ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhuci19/status/1977810527046037829?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3250" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for  MLLMs, Yumin Choi+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ï¼ˆMPOï¼‰ã‚’ææ¡ˆã—ã€ãƒ†ã‚­ã‚¹ãƒˆã¨éãƒ†ã‚­ã‚¹ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…±åŒæœ€é©åŒ–ã™ã‚‹æ–°ãŸãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç¤ºã™ã€‚MPOã¯ã€ãƒ™ã‚¤ã‚ºã«åŸºã¥ãé¸æŠæˆ¦ç•¥ã‚’ç”¨ã„ã¦å€™è£œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸å®šã—ã€ç”»åƒã‚„å‹•ç”»ãªã©å¤šæ§˜ãªãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«ãŠã„ã¦ãƒ†ã‚­ã‚¹ãƒˆå°‚ç”¨æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€MLLMsã®æ½œåœ¨èƒ½åŠ›ã‚’æœ€å¤§é™ã«å¼•ãå‡ºã™é‡è¦ãªã‚¹ãƒ†ãƒƒãƒ—ã‚’ç¢ºç«‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dongkikim95/status/1977751622613684654?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3249" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Verifying Chain-of-Thought Reasoning via Its Computational Graph, Zheng Zhao+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Circuit-based Reasoning Verification (CRV)ã‚’ææ¡ˆã—ã€CoTã‚¹ãƒ†ãƒƒãƒ—ã®å¸°å±ã‚°ãƒ©ãƒ•ã‚’ç”¨ã„ã¦æ¨è«–ã‚¨ãƒ©ãƒ¼ã‚’æ¤œè¨¼ã€‚ã‚¨ãƒ©ãƒ¼ã®æ§‹é€ çš„ç½²åãŒäºˆæ¸¬çš„ã§ã‚ã‚Šã€ç•°ãªã‚‹æ¨è«–ã‚¿ã‚¹ã‚¯ã§ç•°ãªã‚‹è¨ˆç®—ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒç¾ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®èª¤ã£ãŸæ¨è«–ã‚’ä¿®æ­£ã™ã‚‹æ–°ãŸãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æä¾›ã—ã€LLMæ¨è«–ã®å› æœç†è§£ã‚’æ·±ã‚ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacksonatkinsx/status/1977721832909177032?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3248" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] dInfer: An Efficient Inference Framework for Diffusion Language Models, Yuxin Ma+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- dLLMã®æ¨è«–ã‚’åŠ¹ç‡åŒ–ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯dInferã‚’ææ¡ˆã€‚dInferã¯4ã¤ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«åˆ†è§£ã•ã‚Œã€æ–°ã—ã„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨æœ€é©åŒ–ã‚’çµ±åˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å‡ºåŠ›å“è³ªã‚’ç¶­æŒã—ã¤ã¤ã€æ¨è«–é€Ÿåº¦ã‚’å¤§å¹…ã«å‘ä¸Šã€‚HumanEvalã§1ç§’ã‚ãŸã‚Š1,100ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¶…ãˆã€å¾“æ¥ã®ã‚·ã‚¹ãƒ†ãƒ ã«æ¯”ã¹ã¦10å€ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å®Ÿç¾ã€‚dInferã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>code:


<a href="https://github.com/inclusionAI/dInfer" target="_blank" rel="noopener noreferrer">https://github.com/inclusionAI/dInfer</a>


</p>
<p>ã¨ã†ã¨ã†dLLMã‚’é«˜é€Ÿã§inferenceã§ãã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒå‡ºãŸæ¨¡æ§˜ã€‚inclusionAIã‚ˆã‚Šã€‚</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1978662709773373856?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Entropy.html" target="_blank" rel="noopener noreferrer">#Entropy</a>
<span class="issue_date">Issue Date: 2025-10-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3245" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Rethinking Entropy Regularization in Large Reasoning Models, Yuxian Jiang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- RLVRã¯LRMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã®å´©å£Šã¨æ—©æœŸåæŸã®å•é¡Œã«ç›´é¢ã—ã¦ã„ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€SIRENï¼ˆé¸æŠçš„ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ­£å‰‡åŒ–ï¼‰ã‚’ææ¡ˆã—ã€æ¢ç´¢ã‚’æ„å‘³ã®ã‚ã‚‹è¡Œå‹•ã¨çŠ¶æ…‹ã®ã‚µãƒ–ã‚»ãƒƒãƒˆã«åˆ¶é™ã™ã‚‹äºŒæ®µéšã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãƒã‚¹ã‚­ãƒ³ã‚°ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å°å…¥ã€‚SIRENã¯æ•°å­¦çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®‰å®šæ€§ã‚’é«˜ã‚ã€æ—©æœŸåæŸã®å•é¡Œã‚’è»½æ¸›ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yafuly/status/1977634258018529318?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/UserBased.html" target="_blank" rel="noopener noreferrer">#UserBased</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3242" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BigCodeArena: Unveiling More Reliable Human Preferences in Code  Generation via Execution, Terry Yue Zhuo+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- BigCodeArenaã¯ã€LLMãŒç”Ÿæˆã—ãŸã‚³ãƒ¼ãƒ‰ã®è³ªã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è©•ä¾¡ã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚·ãƒ³ã‚°ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã€Chatbot Arenaã‚’åŸºç›¤ã«æ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã™ã€‚14,000ä»¥ä¸Šã®ã‚³ãƒ¼ãƒ‰ä¸­å¿ƒã®ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰4,700ã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã‚µãƒ³ãƒ—ãƒ«ã‚’åé›†ã—ã€äººé–“ã®å¥½ã¿ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã—ãŸã€‚ã“ã‚Œã«åŸºã¥ãã€LLMã®ã‚³ãƒ¼ãƒ‰ç†è§£ã¨ç”Ÿæˆèƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®BigCodeRewardã¨AutoCodeArenaã¨ã„ã†2ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ç­–å®šã—ã¾ã—ãŸã€‚è©•ä¾¡ã®çµæœã€å®Ÿè¡ŒçµæœãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã€ã»ã¨ã‚“ã©ã®LLMãŒå„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ç‰¹ã«GPT-5ã‚„Claudeã‚·ãƒªãƒ¼ã‚ºãŒã‚³ãƒ¼ãƒ‰ç”Ÿæˆæ€§èƒ½ã§ãƒªãƒ¼ãƒ‰ã—ã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1977694597603291492?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‰¯ã•ãã†</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/Test-time%20Learning.html" target="_blank" rel="noopener noreferrer">#Test-time Learning</a>
<span class="issue_date">Issue Date: 2025-10-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3236" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory, Matthew Ho+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- LLMã¯æ¨è«–æ™‚ã«å¤–éƒ¨ãƒ¡ãƒ¢ãƒªã‚’æ´»ç”¨ã—ã€æ¦‚å¿µãƒ¬ãƒ™ãƒ«ã®ãƒ¡ãƒ¢ãƒªã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€å†åˆ©ç”¨å¯èƒ½ã§ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªçŸ¥è­˜ã®ä¿å­˜ã‚’å®Ÿç¾ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é–¢é€£ã™ã‚‹æ¦‚å¿µã‚’é¸æŠçš„ã«å–å¾—ã—ã€ãƒ†ã‚¹ãƒˆæ™‚ã®ç¶™ç¶šçš„å­¦ç¿’ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚è©•ä¾¡ã¯ARC-AGIãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§è¡Œã„ã€ãƒ¡ãƒ¢ãƒªãªã—ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«å¯¾ã—ã¦7.5%ã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã€‚å‹•çš„ãªãƒ¡ãƒ¢ãƒªæ›´æ–°ãŒè‡ªå·±æ”¹å–„ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1977388895739535686?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ARC-AGIã§ã—ã‹è©•ä¾¡ã•ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-10-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3235" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Inoculation Prompting: Instructing LLMs to misbehave at train-time  improves test-time alignment, Nevan Wichers+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Inoculation Promptingï¼ˆIPï¼‰ã‚’ææ¡ˆã—ã€æœ›ã¾ã—ããªã„è¡Œå‹•ã‚’æ˜ç¤ºçš„ã«è¦æ±‚ã™ã‚‹ã“ã¨ã§ãã®å­¦ç¿’ã‚’é˜²ãæ‰‹æ³•ã‚’ç´¹ä»‹ã€‚IPã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«æœ›ã¾ã—ããªã„è¡Œå‹•ã®å­¦ç¿’ã‚’æ¸›å°‘ã•ã›ã€æœ›ã¾ã—ã„èƒ½åŠ›ã®å­¦ç¿’ã«ã¯å¤§ããªå½±éŸ¿ã‚’ä¸ãˆãªã„ã€‚ç‰¹ã«ã€æœ›ã¾ã—ããªã„è¡Œå‹•ã‚’å¼•ãå‡ºã™ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒåŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ãƒ¢ãƒ‡ãƒ«ã®ä¸€èˆ¬åŒ–ã‚’åˆ¶å¾¡ã™ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ã§åŠ¹æœçš„ãªæ–¹æ³•ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1977388859160989931?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3106" target="_blank" rel="noopener noreferrer">[Paper Note] Large Reasoning Models Learn Better Alignment from Flawed Thinking, ShengYun Peng+, arXiv'25, 2025.10</a>
<br><br>ä¸Šè¨˜ç ”ç©¶ã¨ã©ã†ã„ã£ãŸç‚¹ãŒç•°ãªã‚‹ã ã‚ã†ã‹</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Pruning.html" target="_blank" rel="noopener noreferrer">#Pruning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/Parallel.html" target="_blank" rel="noopener noreferrer">#Parallel</a>
<span class="issue_date">Issue Date: 2025-10-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3232" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DeepPrune: Parallel Scaling without Inter-trace Redundancy, Shangqing Tu+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- DeepPruneã¨ã„ã†æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ä¸¦åˆ—ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®è¨ˆç®—éåŠ¹ç‡ã‚’è§£æ±ºã€‚80%ä»¥ä¸Šã®æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ãŒåŒä¸€ã®å›ç­”ã‚’ç”Ÿæˆã™ã‚‹å•é¡Œã«å¯¾å‡¦ã—ã€ç„¦ç‚¹æå¤±ã¨ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æŠ€è¡“ã‚’ç”¨ã„ãŸåˆ¤å®šãƒ¢ãƒ‡ãƒ«ã§åŒç­‰æ€§ã‚’äºˆæ¸¬ã€‚ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã®è²ªæ¬²ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§å†—é•·ãªçµŒè·¯ã‚’ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€80%ä»¥ä¸Šã®ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ã‚’é”æˆã—ã¤ã¤ã€ç²¾åº¦ã‚’ç¶­æŒã€‚åŠ¹ç‡çš„ãªä¸¦åˆ—æ¨è«–ã®æ–°åŸºæº–ã‚’ç¢ºç«‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://deepprune.github.io" target="_blank" rel="noopener noreferrer">https://deepprune.github.io</a>


</p>
<p>HF:


<a href="https://huggingface.co/collections/THU-KEG/deepprune-68e5c1ea71f789a6719b2c1c" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/THU-KEG/deepprune-68e5c1ea71f789a6719b2c1c</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1977134276966789446?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-10-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3228" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] General-Reasoner: Advancing LLM Reasoning Across All Domains, Xueguang Ma+, arXiv'25, 2025.05</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ãŸæ–°ã—ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã€ŒGeneral-Reasonerã€ã‚’ææ¡ˆã—ã€LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å¤§è¦æ¨¡ãªé«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®å›ç­”æ¤œè¨¼å™¨ã‚’é–‹ç™ºã€‚ç‰©ç†å­¦ã‚„åŒ–å­¦ãªã©ã®å¤šæ§˜ãªåˆ†é‡ã§è©•ä¾¡ã—ã€æ—¢å­˜æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1977223525489688833?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj page:


<a href="https://tiger-ai-lab.github.io/General-Reasoner/" target="_blank" rel="noopener noreferrer">https://tiger-ai-lab.github.io/General-Reasoner/</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-10-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3227" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining  Levels, Zhepeng Cen+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Webscale-RLãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å°å…¥ã—ã€å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’æ–‡æ›¸ã‹ã‚‰æ•°ç™¾ä¸‡ã®å¤šæ§˜ãªè³ªå•-å›ç­”ãƒšã‚¢ã‚’ç”Ÿæˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€120ä¸‡ã®ä¾‹ã‚’å«ã‚€Webscale-RLãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã€‚å®Ÿé¨“çµæœã€RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ç¶™ç¶šçš„ãªäº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã§ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ç ”ç©¶ã¯ã€RLã‚’äº‹å‰å­¦ç¿’ãƒ¬ãƒ™ãƒ«ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹é“ç­‹ã‚’ç¤ºã—ã€ã‚ˆã‚Šé«˜æ€§èƒ½ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã®å®Ÿç¾ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscreamnearby/status/1976892514008547621?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Dataset:


<a href="https://huggingface.co/datasets/Salesforce/Webscale-RL" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/Salesforce/Webscale-RL</a>


</p>
<p>ä»¥ä¸‹ã®ç ”ç©¶ãŒé–¢é€£ç ”ç©¶ã§NeurIPSã§ã™ã§ã«ç™ºè¡¨ã•ã‚Œã¦ã„ã‚‹ãŒå¼•ç”¨ã‚‚è­°è«–ã‚‚ã•ã‚Œã¦ã„ãªã„ã¨ã„ã†æŒ‡æ‘˜ãŒã‚ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3228" target="_blank" rel="noopener noreferrer">[Paper Note] General-Reasoner: Advancing LLM Reasoning Across All Domains, Xueguang Ma+, arXiv'25, 2025.05</a>
<br><br>ä»–ã«ã‚‚ä¼¼ãŸã‚ˆã†ãªãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã®ç ”ç©¶ã‚’è¦‹ãŸã“ã¨ãŒã‚ã‚‹ã‚ˆã†ãªâ€¦</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/UserModeling.html" target="_blank" rel="noopener noreferrer">#UserModeling</a>
<a class="button" href="articles/UserBased.html" target="_blank" rel="noopener noreferrer">#UserBased</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<a class="button" href="articles/Robustness.html" target="_blank" rel="noopener noreferrer">#Robustness</a>
<span class="issue_date">Issue Date: 2025-10-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3225" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Flipping the Dialogue: Training and Evaluating User Language Models, Tarek Naous+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- LMã¨ã®ä¼šè©±ã«ã¯äººé–“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨LMã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒå‚åŠ ã—ã€LMã¯æ§‹é€ åŒ–ã•ã‚ŒãŸå¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†æœ€é©åŒ–ã•ã‚Œã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè©±ã¯å®Œç’§ã§ã¯ãªãã€å¾“æ¥ã®ç ”ç©¶ã§ã¯ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆLMãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã“ã¨ãŒè©¦ã¿ã‚‰ã‚ŒãŸãŒã€åŠ¹æœçš„ã§ã¯ãªã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ãã“ã§ã€ç›®çš„ç‰¹åŒ–å‹ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆUser LMsï¼‰ã‚’å°å…¥ã—ã€ã“ã‚ŒãŒäººé–“ã®è¡Œå‹•ã¨ã‚ˆã‚Šä¸€è‡´ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å …ç‰¢æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚User LMsã‚’ç”¨ã„ãŸã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚„æ•°å­¦ã®ä¼šè©±ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã€å¼·åŠ›ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã—ã€ç¾å®Ÿçš„ãªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒãŒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®è‹¦æˆ¦ã‚’å¼•ãèµ·ã“ã™ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/microsoft/UserLM-8b" target="_blank" rel="noopener noreferrer">https://huggingface.co/microsoft/UserLM-8b</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1977119796199407838?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>èˆˆå‘³æ·±ã„</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alexisjross/status/1977037155655729267?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/IdeaGeneration.html" target="_blank" rel="noopener noreferrer">#IdeaGeneration</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3224" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GUIDE: Towards Scalable Advising for Research Ideas, Yaowenqi Liu+, arXiv'25, 2025.07</a>
<span class="snippet"><span>GPT Summary</span>- AIç ”ç©¶ã®é€²å±•ã«ä¼´ã„ã€è‡ªå‹•åŒ–ã•ã‚ŒãŸä»®èª¬ç”Ÿæˆã‚„å®Ÿé¨“è¨­è¨ˆãŒå¯èƒ½ã«ãªã£ã¦ã„ã‚‹ãŒã€é«˜å“è³ªãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã™ã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¸ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã«ã¯ä¾ç„¶ã¨ã—ã¦èª²é¡ŒãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã‚„ä¿¡é ¼åº¦ã®æ¨å®šãªã©ã€åŠ¹æœçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¸ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®è¦å› ã‚’æ¢æ±‚ã—ã€æ¯”è¼ƒçš„å°ã•ãªãƒ¢ãƒ‡ãƒ«ãŒåœ§ç¸®ã•ã‚ŒãŸæ–‡çŒ®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨æ§‹é€ åŒ–ã•ã‚ŒãŸæ¨è«–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€å¼·åŠ›ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹å—ç†ç‡ã‚’é”æˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ç‰¹ã«ã€é«˜ä¿¡é ¼åº¦ã®äºˆæ¸¬ã«ãŠã„ã¦90%ä»¥ä¸Šã®å—ç†ç‡ã‚’é”æˆã—ã€ä»®èª¬ç”Ÿæˆã¨å®Ÿé¨“è¨­è¨ˆã®è³ªã‚’å‘ä¸Šã•ã›ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://howardliu0830.github.io/GUIDE_blog/" target="_blank" rel="noopener noreferrer">https://howardliu0830.github.io/GUIDE_blog/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/youjiaxuan/status/1976354596017799684?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã©ã®ã‚ˆã†ã«è©•ä¾¡ã—ãŸã®ã ã‚ã†ã‹</p>
<p>pj pageã«ã‚ˆã‚‹ã¨ã€ICMLã®submissionã®ã†ã¡ãƒ©ãƒ³ãƒ€ãƒ ãª1000ä»¶ã‚’ç”¨ã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ã«paperã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã•ã›ã‚‹ã€‚ãã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ãŒã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ãŸä¸­ã§ä¸Šä½5%ï¼ˆspotlightã®å‰²åˆã«ç›¸å½“ï¼‰ã€30%ã®precisionï¼ˆå®Ÿéš›ã®acceptanceã®é–¾å€¤ç›¸å½“ã®å‰²åˆï¼‰ã¨ã€ãƒ¢ãƒ‡ãƒ«ãŒã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ãŸä¸Šä½30ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆã®è«–æ–‡ã®ç¾ä»£ã®Acceptanceã«å¯¾ã™ã‚‹Recallã‚’æ±‚ã‚ã¦è©•ä¾¡ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚7Bãƒ¢ãƒ‡ãƒ«ã§ã‚ˆã‚Šå¤§ãã„ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ç¨‹åº¦ã®æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br>æ‰‹æ³•ã¯å¾Œã»ã©è¿½è¨˜ã—ãŸã„ãŒã€Acceptã‚’äºˆæ¸¬ãµã‚‹ã‚¿ã‚¹ã‚¯ã¯è«–æ–‡ã«å¯¾ã—ã¦é©åˆ‡ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã§ãã‚‹ã“ã¨ã«ç›´æ¥çš„ã«ã¯ç¹‹ãŒã‚‰ãªã„ã®ã§ã¯ï¼Ÿã¨æ€ã„ã€inferenceã®promptã‚’è¦‹ã¦ã¿ã‚‹ã¨ã€LLMã«abst, contribution, method, experimental setupã‚’å…¥åŠ›ã—ã€å®Ÿéš›ã®æŸ»èª­ã¨ä¼¼ãŸã‚ˆã†ãªè©•ä¾¡ã‚’ã•ã›ã€ãã®çµæœã«åŸºã¥ã„ã¦ratingã‚’predictionã™ã‚‹ã‚ˆã†ãªå½¢å¼ã«è¦‹ãˆã‚‹ã€‚ã“ã®ãŸã‚ã€rating predictionã®éç¨‹ã§è©•ä¾¡çµæœã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒç”Ÿæˆã•ã‚Œã‚‹ã®ã§ã€è«–æ–‡ã®æ”¹å–„ãŒã§ãã‚‹ã€ã¨ã„ã†ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/5732eea8-744f-4072-89b2-6ad095b9d1d2" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-10-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3219" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Agentic Context Engineering: Evolving Contexts for Self-Improving  Language Models, Qizheng Zhang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ACEãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€é©å¿œãƒ¡ãƒ¢ãƒªã«åŸºã¥ãã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’é€²åŒ–ã™ã‚‹ãƒ—ãƒ¬ã‚¤ãƒ–ãƒƒã‚¯ã¨ã—ã¦æ‰±ã„ã€ç”Ÿæˆã€åçœã€ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é€šã˜ã¦æˆ¦ç•¥ã‚’æ´—ç·´ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è©³ç´°ãªçŸ¥è­˜ã‚’ä¿æŒã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå´©å£Šã‚’é˜²ãã¾ã™ã€‚ACEã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã€é©å¿œã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¨ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã€‚ç‰¹ã«ã€ãƒ©ãƒ™ãƒ«ãªã—ã§åŠ¹æœçš„ã«é©å¿œã—ã€è‡ªç„¶ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ´»ç”¨ã™ã‚‹ç‚¹ãŒç‰¹å¾´ã§ã™ã€‚å…¨ä½“ã®å¹³å‡ã§ãƒˆãƒƒãƒ—ãƒ©ãƒ³ã‚¯ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«åŒ¹æ•µã—ã€ã‚ˆã‚Šé›£ã—ã„ãƒ†ã‚¹ãƒˆã§ã‚‚å„ªã‚ŒãŸçµæœã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1976903463360774380?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1976746822204113072?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/saboo_shubham_/status/1978871310257156244?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-10-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3214" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MemMamba: Rethinking Memory Patterns in State Space Model, Youjin Wang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‡ãƒ¼ã‚¿ã®å¢—åŠ ã«ä¼´ã„ã€é•·ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãŒé‡è¦ã«ãªã‚‹ä¸­ã€æ—¢å­˜æ‰‹æ³•ã¯åŠ¹ç‡ã¨ãƒ¡ãƒ¢ãƒªã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ç›´é¢ã—ã¦ã„ã‚‹ã€‚Mambaã®é¸æŠçš„çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã¯é«˜åŠ¹ç‡ã ãŒã€é•·æœŸãƒ¡ãƒ¢ãƒªãŒæ¸›è¡°ã™ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€Mambaã®ãƒ¡ãƒ¢ãƒªæ¸›è¡°ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’åˆ†æã—ã€æƒ…å ±æå¤±ã‚’å®šé‡åŒ–ã™ã‚‹æŒ‡æ¨™ã‚’å°å…¥ã€‚æ–°ãŸã«ææ¡ˆã™ã‚‹MemMambaã¯ã€çŠ¶æ…‹è¦ç´„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¨æ³¨æ„ã‚’çµ±åˆã—ã€é•·æœŸçš„ãªå¿˜å´ã‚’è»½æ¸›ã—ã¤ã¤è¨ˆç®—é‡ã‚’ç¶­æŒã€‚MemMambaã¯ã€é•·ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¤§å¹…ãªæ”¹å–„ã‚’é”æˆã—ã€æ¨è«–åŠ¹ç‡ã‚’48%å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1976681769954169080?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Fidelity.html" target="_blank" rel="noopener noreferrer">#Fidelity</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3200" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Improving Context Fidelity via Native Retrieval-Augmented Reasoning, Suyuchen Wang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- CAREã¨ã„ã†æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€LLMsãŒè‡ªã‚‰ã®æ¤œç´¢èƒ½åŠ›ã‚’ç”¨ã„ã¦æ–‡è„ˆã«ãŠã‘ã‚‹è¨¼æ‹ ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§ã€ä¸€è²«æ€§ã®ã‚ã‚‹å›ç­”ã‚’ç”Ÿæˆã€‚é™ã‚‰ã‚ŒãŸãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã§æ¤œç´¢ç²¾åº¦ã¨å›ç­”ç”Ÿæˆæ€§èƒ½ã‚’å‘ä¸Šã•ã›ã€å®Ÿé¨“ã«ã‚ˆã‚Šå¾“æ¥æ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1976491312405991509?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<a class="button" href="articles/RecurrentModels.html" target="_blank" rel="noopener noreferrer">#RecurrentModels</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3195" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Artificial Hippocampus Networks for Efficient Long-Context Modeling, Yunhao Fang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- é•·å¤§ãªã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«ãŠã‘ã‚‹ãƒ¡ãƒ¢ãƒªã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€äººå·¥æµ·é¦¬ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆAHNï¼‰ã‚’ææ¡ˆã€‚AHNã¯çŸ­æœŸãƒ¡ãƒ¢ãƒªã‚’ç¶­æŒã—ã¤ã¤ã€é•·æœŸãƒ¡ãƒ¢ãƒªã‚’åœ§ç¸®ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€AHNã‚’ç”¨ã„ãŸãƒ¢ãƒ‡ãƒ«ãŒå¾“æ¥ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€è¨ˆç®—ã¨ãƒ¡ãƒ¢ãƒªè¦ä»¶ã‚’å¤§å¹…ã«å‰Šæ¸›ã—ã¤ã¤ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1976107974939816308?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1976451334951063854?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3191" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Markovian Thinker, Milad Aghajohari+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦é•·ã„æ€è€ƒã®é€£é–ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã€Œãƒãƒ«ã‚³ãƒ•çš„æ€è€ƒã€ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€çŠ¶æ…‹ã‚’ä¸€å®šã®ã‚µã‚¤ã‚ºã«åˆ¶é™ã—ã€æ€è€ƒã®é•·ã•ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã‚µã‚¤ã‚ºã‹ã‚‰åˆ‡ã‚Šé›¢ã™ã“ã¨ã§ã€ç·šå½¢è¨ˆç®—ã‚’å®Ÿç¾ã€‚æ–°ã—ã„RLç’°å¢ƒã€ŒDelethinkã€ã‚’æ§‹ç¯‰ã—ã€ãƒ¢ãƒ‡ãƒ«ã¯çŸ­ã„æŒã¡è¶Šã—ã§æ¨è«–ã‚’ç¶™ç¶šã™ã‚‹ã“ã¨ã‚’å­¦ç¿’ã€‚è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€é•·ã„æ¨è«–ã‚’åŠ¹ç‡çš„ã«è¡Œã„ã€ã‚³ã‚¹ãƒˆã‚’å¤§å¹…ã«å‰Šæ¸›ã€‚æ€è€ƒç’°å¢ƒã®å†è¨­è¨ˆãŒã€åŠ¹ç‡çš„ã§ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªæ¨è«–LLMã®å®Ÿç¾ã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/maghajohari/status/1976296195438887012?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1976466786565656986?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1976798665038758377?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/LongHorizon.html" target="_blank" rel="noopener noreferrer">#LongHorizon</a>
<span class="issue_date">Issue Date: 2025-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3190" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] h1: Bootstrapping LLMs to Reason over Longer Horizons via Reinforcement  Learning, Sumeet Ramesh Motwani+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯çŸ­æœŸçš„ãªæ¨è«–ã«ã¯å¼·ã„ãŒã€é•·æœŸçš„ãªæ¨è«–ã§ã¯æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ã€‚æ—¢å­˜ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã‚¹ã‚±ãƒ¼ãƒ«ã—ã«ãã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€çŸ­æœŸãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦é•·æœŸçš„ãªæ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªæ–¹æ³•ã‚’ææ¡ˆã€‚å˜ç´”ãªå•é¡Œã‚’åˆæˆã—ã€è¤‡é›‘ãªå¤šæ®µéšä¾å­˜ãƒã‚§ãƒ¼ãƒ³ã‚’æ§‹æˆã€‚çµæœã®ã¿ã®å ±é…¬ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã‚’é€šã˜ã¦ç²¾åº¦ã‚’å‘ä¸Šã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€GSM8Kã§ã®è¨“ç·´ãŒGSM-Symbolicã‚„MATH-500ãªã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®ç²¾åº¦ã‚’æœ€å¤§2.06å€å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ç†è«–çš„ã«ã¯ã€ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ RLãŒã‚µãƒ³ãƒ—ãƒ«ã®è¤‡é›‘ã•ã«ãŠã„ã¦æŒ‡æ•°çš„ãªæ”¹å–„ã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã€æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸé•·æœŸçš„ãªå•é¡Œè§£æ±ºã®åŠ¹ç‡çš„ãªé“ã‚’ææ¡ˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1976234893983285265?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sumeetrm/status/1976674583827665029?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<a class="button" href="articles/RecursiveModels.html" target="_blank" rel="noopener noreferrer">#RecursiveModels</a>
<span class="issue_date">Issue Date: 2025-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3189" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Less is More: Recursive Reasoning with Tiny Networks, Alexia Jolicoeur-Martineau, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- éšå±¤çš„æ¨è«–ãƒ¢ãƒ‡ãƒ«ï¼ˆHRMï¼‰ã¯ã€2ã¤ã®å°ã•ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ãŸæ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€æ•°ç‹¬ã‚„è¿·è·¯ãªã©ã®ãƒ‘ã‚ºãƒ«ã‚¿ã‚¹ã‚¯ã§å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚ã—ã‹ã—ã€HRMã¯æœ€é©ã§ã¯ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€æˆ‘ã€…ã¯Tiny Recursive Modelï¼ˆTRMï¼‰ã‚’ææ¡ˆã€‚TRMã¯ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ã§é«˜ã„ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’æŒã¡ã€700ä¸‡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ARC-AGI-1ã§45%ã€ARC-AGI-2ã§8%ã®ç²¾åº¦ã‚’é”æˆã—ã€ã»ã¨ã‚“ã©ã®LLMã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/deedydas/status/1976105366003044488?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1976606666591252935?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1976702931350307178?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ARC-AGIå…¬å¼ã«ã‚ˆã‚‹æ¤œè¨¼ãŒçµ‚ã‚ã‚Šå ±å‘Šã•ã‚Œã¦ã„ã‚‹çµæœãŒä¿¡é ¼ã§ãã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gregkamradt/status/1978875294934274364?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3187" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GDPval: Evaluating AI Model Performance on Real-World Economically  Valuable Tasks, Tejal Patwardhan+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- GDPvalã¯ã€AIãƒ¢ãƒ‡ãƒ«ã®çµŒæ¸ˆçš„ä¾¡å€¤ã®ã‚ã‚‹ã‚¿ã‚¹ã‚¯ã‚’è©•ä¾¡ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€ç±³å›½GDPã«å¯„ä¸ã™ã‚‹44ã®è·æ¥­ã‚’ã‚«ãƒãƒ¼ã€‚æœ€å‰ç·šãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯æ™‚é–“ã¨å…±ã«æ”¹å–„ã—ã€æ¥­ç•Œå°‚é–€å®¶ã«è¿‘ã¥ã„ã¦ã„ã‚‹ã€‚äººé–“ã®ç›£è¦–ã‚’åŠ ãˆãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ç„¡æ´åŠ©ã®å°‚é–€å®¶ã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã«ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚æ¨è«–åŠªåŠ›ã‚„ã‚¿ã‚¹ã‚¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å¢—åŠ ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã€‚220ã®ã‚¿ã‚¹ã‚¯ã®ã‚´ãƒ¼ãƒ«ãƒ‰ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã€ç ”ç©¶ä¿ƒé€²ã®ãŸã‚ã®è‡ªå‹•æ¡ç‚¹ã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thom_wolf/status/1975936809021444200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<a class="button" href="articles/numeric.html" target="_blank" rel="noopener noreferrer">#numeric</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3182" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Generalist Data-Analytic Agents, Shuofei Qiao+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- DataMindã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒ‡ãƒ¼ã‚¿åˆæˆã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®æ‰‹æ³•ã‚’ææ¡ˆã€‚ä¸»ãªèª²é¡Œã§ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒªã‚½ãƒ¼ã‚¹ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã®ä¸å®‰å®šæ€§ã«å¯¾å‡¦ã—ã€åˆæˆã‚¯ã‚¨ãƒªã®å¤šæ§˜æ€§ã‚’é«˜ã‚ã‚‹ã‚¿ã‚¹ã‚¯åˆ†é¡ã‚„ã€å‹•çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç›®æ¨™ã‚’æ¡ç”¨ã€‚DataMind-12Kã¨ã„ã†é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€DataMind-14Bã¯ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§71.16%ã®ã‚¹ã‚³ã‚¢ã‚’é”æˆã—ã€æœ€å…ˆç«¯ã®ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã£ãŸã€‚DataMind-7Bã‚‚68.10%ã§ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ä¸­æœ€é«˜ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ãŸã€‚ä»Šå¾Œã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å…¬é–‹äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zxlzr/status/1975941955613028436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>7Bç¨‹åº¦ã®SLMã§70Bç´šã®ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã«åˆ°é”ã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚è«–æ–‡ä¸­ã®p.2ã«ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«å†…å®¹ãŒã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3179" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] In-the-Flow Agentic System Optimization for Effective Planning and Tool  Use, Zhuofeng Li+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- AgentFlowã¯ã€4ã¤ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã€ã‚¨ã‚°ã‚¼ã‚­ãƒ¥ãƒ¼ã‚¿ãƒ¼ã€ãƒãƒªãƒ•ã‚¡ã‚¤ã‚¢ã€ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼‰ã‚’èª¿æ•´ã—ã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ç’°å¢ƒã§ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã‚’æœ€é©åŒ–ã™ã‚‹å¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚Flow-GRPOã‚’ç”¨ã„ã¦ã€é•·ã„ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ã®ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒªãƒ¯ãƒ¼ãƒ‰å•é¡Œã«å¯¾å‡¦ã—ã€ç²¾åº¦ã‚’å‘ä¸Šã€‚10ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€7Bã‚¹ã‚±ãƒ¼ãƒ«ã®AgentFlowã¯ã€æ¤œç´¢ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒ†ã‚£ãƒƒã‚¯ã€æ•°å­¦ã€ç§‘å­¦ã‚¿ã‚¹ã‚¯ã§ãã‚Œãã‚Œ14.9%ã€14.0%ã€14.5%ã€4.1%ã®ç²¾åº¦å‘ä¸Šã‚’é”æˆã—ã€GPT-4oã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://agentflow.stanford.edu" target="_blank" rel="noopener noreferrer">https://agentflow.stanford.edu</a>


</p>
<p>pj page:


<a href="https://agentflow.stanford.edu" target="_blank" rel="noopener noreferrer">https://agentflow.stanford.edu</a>


</p>
<p>ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨æ¨è«–ã‚¿ãƒ¼ãƒ³ã«å¯¾ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç‰¹æ€§<br><br>ä¼¼ãŸã‚ˆã†ãªè©±ãŒä»¥ä¸‹ã®ç ”ç©¶ã«ã‚‚ã‚ã‚‹<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2806" target="_blank" rel="noopener noreferrer">[Paper Note] The Illusion of Diminishing Returns: Measuring Long Horizon Execution in
  LLMs, Akshit Sinha+, arXiv'25</a>
</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1976079766978502816?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3178" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generative Representational Instruction Tuning, Niklas Muennighoff+, ICLR'25, 2024.02</a>
<span class="snippet"><span>GPT Summary</span>- ç”Ÿæˆçš„è¡¨ç¾æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆGRITï¼‰ã‚’ç”¨ã„ã¦ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã‚¿ã‚¹ã‚¯ã¨åŸ‹ã‚è¾¼ã¿ã‚¿ã‚¹ã‚¯ã‚’åŒæ™‚ã«å‡¦ç†ã§ãã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚GritLM 7Bã¯MTEBã§æ–°ãŸãªæœ€å…ˆç«¯ã‚’é”æˆã—ã€GritLM 8x7Bã¯ã™ã¹ã¦ã®ã‚ªãƒ¼ãƒ—ãƒ³ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚GRITã¯ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã¨åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆã«ã‚ˆã‚‹æ€§èƒ½æå¤±ãŒãªãã€RAGã‚’60%ä»¥ä¸Šé«˜é€ŸåŒ–ã™ã‚‹åˆ©ç‚¹ã‚‚ã‚ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=BC4lIvfSzv" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=BC4lIvfSzv</a>


</p>
<p>å¾“æ¥ã¯gemerativeã‚¿ã‚¹ã‚¯ã¨embeddingã‚¿ã‚¹ã‚¯ã¯åˆ¥ã€…ã«ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã•ã‚Œã¦ã„ãŸãŒã€ãã‚Œã‚’çµ±ä¸€çš„ãªæ çµ„ã¿ã§å®Ÿæ–½ã—ã€ä¸¡æ–¹ã®ã‚¿ã‚¹ã‚¯ã§åŒç­‰ã®ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã®ä»–ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦é«˜ã„æ€§èƒ½ã‚’é”æˆã—ãŸç ”ç©¶ã€‚å¾“æ¥ã®generativeã‚¿ã‚¹ã‚¯ç”¨ã®next-token-prediction lossã¨embeddingã‚¿ã‚¹ã‚¯ç”¨ã®constastive lossã‚’çµ„ã¿åˆã‚ã›ã¦å­¦ç¿’ã™ã‚‹ï¼ˆå¼3ï¼‰ã€‚ã‚¿ã‚¹ã‚¯ã®åŒºåˆ¥ã¯instructionã«ã‚ˆã‚Šå®Ÿæ–½ã—ã€embeddingã‚¿ã‚¹ã‚¯ã®å ´åˆã¯ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®last hidden stateã®mean poolingã§representationã‚’å–å¾—ã™ã‚‹ã€‚ã¾ãŸã€embeddingã®æ™‚ã¯bi-directional attention / generativeã‚¿ã‚¹ã‚¯ã®æ™‚ã¯causal maskãŒé©ç”¨ã•ã‚Œã‚‹ã€‚ã“ã‚Œã‚‰ã®attentionã®é©ç”¨ã®ã•ã‚Œæ–¹ã®é•ã„ãŒã€ã©ã®ã‚ˆã†ã«ç®¡ç†ã•ã‚Œã‚‹ã‹ã¯ã¾ã ã—ã£ã‹ã‚Šèª­ã‚ã¦ã„ãªã„ã®ã§ã‚ˆãã‚ã‹ã£ã¦ã„ãªã„ãŒã€éå¸¸ã«èˆˆå‘³æ·±ã„ç ”ç©¶ã§ã‚ã‚‹ã€‚<br><br>&lt;img width="603" height="349" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/acb2cbcd-364d-43c7-b51a-6c5ea9866415"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/acb2cbcd-364d-43c7-b51a-6c5ea9866415"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/Sparse.html" target="_blank" rel="noopener noreferrer">#Sparse</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3176" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] vAttention: Verified Sparse Attention, Aditya Desai+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- vAttentionã¯ã€ãƒˆãƒƒãƒ—-$k$ã¨ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’çµ±åˆã—ãŸæ–°ã—ã„ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®$(\epsilon, \delta)$ä¿è¨¼ã‚’æä¾›ã—ã€è¿‘ä¼¼ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®å®Ÿç”¨æ€§ã¨ä¿¡é ¼æ€§ãŒå‘ä¸Šã—ã€ãƒ•ãƒ«ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã¨åŒç­‰ã®å“è³ªã‚’ä¿ã¡ãªãŒã‚‰ã€æœ€å¤§20å€ã®ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã‚’å®Ÿç¾ã€‚æ¨è«–ã‚·ãƒŠãƒªã‚ªã§ã‚‚è¿…é€Ÿãªãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒå¯èƒ½ã§ã€å®Ÿé¨“ã«ã‚ˆã‚Šæ€§èƒ½ã®å‘ä¸ŠãŒç¢ºèªã•ã‚ŒãŸã€‚ã‚³ãƒ¼ãƒ‰ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/f14bertolotti/status/1975872208858915012?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3173" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Muon Outperforms Adam in Tail-End Associative Memory Learning, Shuche Wang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- Muonã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã¯ã€LLMsã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦Adamã‚ˆã‚Šã‚‚é«˜é€Ÿã§ã‚ã‚Šã€ãã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’é€£æƒ³è¨˜æ†¶ã®è¦³ç‚¹ã‹ã‚‰è§£æ˜ã€‚VOã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¦ã‚§ã‚¤ãƒˆã¨FFNãŒMuonã®å„ªä½æ€§ã®è¦å› ã§ã‚ã‚Šã€é‡ã„å°¾ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã«ãŠã„ã¦å°¾ã‚¯ãƒ©ã‚¹ã‚’åŠ¹æœçš„ã«æœ€é©åŒ–ã™ã‚‹ã€‚Muonã¯ä¸€è²«ã—ãŸãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸå­¦ç¿’ã‚’å®Ÿç¾ã—ã€Adamã¯ä¸å‡è¡¡ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Muonã®æ›´æ–°ãƒ«ãƒ¼ãƒ«ãŒé‡ã„å°¾ã‚’æŒã¤åˆ†å¸ƒã«ãŠã‘ã‚‹åŠ¹æœçš„ãªå­¦ç¿’ã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fengzhuozhang/status/1975604058896703713?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Off-Policy.html" target="_blank" rel="noopener noreferrer">#Off-Policy</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3170" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Prosperity before Collapse: How Far Can Off-Policy RL Reach with Stale  Data on LLMs?, Haizhong Zheng+, COLM'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ã«ãŠã‘ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒM2POã‚’ææ¡ˆã€‚å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹æœçš„ã«æ´»ç”¨ã—ã€ã‚ªãƒ³ãƒãƒªã‚·ãƒ¼å­¦ç¿’ã®åŠ¹ç‡æ€§ã‚’å‘ä¸Šã€‚M2POã¯é‡è¦åº¦é‡ã¿ã®äºŒæ¬¡ãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆã‚’åˆ¶ç´„ã—ã€å¤–ã‚Œå€¤ã‚’æŠ‘åˆ¶ã—ã¤ã¤å®‰å®šã—ãŸæœ€é©åŒ–ã‚’å®Ÿç¾ã€‚åºƒç¯„ãªè©•ä¾¡ã«ã‚ˆã‚Šã€å¤ã„ãƒ‡ãƒ¼ã‚¿ã§ã‚‚ã‚ªãƒ³ãƒãƒªã‚·ãƒ¼ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/infiniailab/status/1975630083466403977?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æœ¬å½“ã ã¨ã—ãŸã‚‰ã™ã”ã„ãŒæœãŸã—ã¦</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3168" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] G1yphD3c0de: Towards Safer Language Models on Visually Perturbed Texts, Yeo+, COLM'25</a>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=OGwE7LwtcR#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=OGwE7LwtcR#discussion</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stanfordnlp/status/1975574899428139413?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3167" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents, Salman Rahman+, COLM'25, 2025.04</a>
<span class="snippet"><span>GPT Summary</span>- X-Teamingã‚’ææ¡ˆã—ã€ç„¡å®³ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãŒæœ‰å®³ãªçµæœã«ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ãƒˆã™ã‚‹éç¨‹ã‚’æ¢æ±‚ã€‚å”åŠ›çš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç”¨ã„ã¦ã€æœ€å¤§98.1%ã®æˆåŠŸç‡ã§ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³æ”»æ’ƒã‚’å®Ÿç¾ã€‚ç‰¹ã«ã€Claude 3.7 Sonnetãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦96.2%ã®æˆåŠŸç‡ã‚’é”æˆã€‚ã•ã‚‰ã«ã€30Kã®è„±ç„ã‚’å«ã‚€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆXGuard-Trainã‚’å°å…¥ã—ã€LMã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å®‰å…¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=gKfj7Jb1kj#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=gKfj7Jb1kj#discussion</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stanfordnlp/status/1975574899428139413?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/TextToSQL.html" target="_blank" rel="noopener noreferrer">#TextToSQL</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3166" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reasoning-SQL: Reinforcement Learning with SQL Tailored Partial Rewards  for Reasoning-Enhanced Text-to-SQL, Mohammadreza Pourreza+, COLM'25, 2025.03</a>
<span class="snippet"><span>GPT Summary</span>- Text-to-SQLã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€éƒ¨åˆ†çš„å ±é…¬ã‚’ç”¨ã„ãŸå¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ã‚¹ã‚­ãƒ¼ãƒãƒªãƒ³ã‚¯ã‚„AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãªã©ã®å ±é…¬ã‚’è¨­è¨ˆã—ã€LLMsã®æ¨è«–ã‚¹ã‚­ãƒ«ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å—ã‘ãŸ14Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã¯ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ç²¾åº¦ã‚’é”æˆã—ã€ææ¡ˆæ‰‹æ³•ã®æœ‰åŠ¹æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=HbwkIDWQgN#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=HbwkIDWQgN#discussion</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stanfordnlp/status/1975574899428139413?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/Editing.html" target="_blank" rel="noopener noreferrer">#Editing</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3165" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] D3: A Dataset for Training Code LMs to Act Diff-by-Diff, Piterbarg+, COLM'25</a>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=sy71y74U80#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=sy71y74U80#discussion</a>


</p>
<p>openreviewã®ã‚µãƒãƒªã«ã‚ˆã‚‹ã¨ã€8B tokens, 850k python filesã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã‚’ã€ã‚´ãƒ¼ãƒ«ã§æ¡ä»¶ã¥ã‘ã‚‰ã‚ŒãŸsequential editsã‚¿ã‚¹ã‚¯ã¨ã¿ãªã— The Stackä¸Šã®ã‚³ãƒ¼ãƒ‰ã‚’åˆ†æãƒ„ãƒ¼ãƒ«ã¨LLMã«ã‚ˆã£ã¦åˆæˆã•ã‚ŒãŸrationaleã«ã‚ˆã£ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°/æ‹¡å¼µã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’æä¾›ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚å…·ä½“çš„ã«ã¯ (state, goal, action_i) ã®3ã¤çµ„ã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚Šã€action_iãŒactionå‰å¾Œã§ã®diffã«ãªã£ã¦ã„ã‚‹æ¨¡æ§˜ã€‚D3ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§SFTã®å‰ã«Llama 1B / 3Bã‚’mid-trainingã—ãŸçµæœã€downstreamã‚¿ã‚¹ã‚¯ï¼ˆã‚³ãƒ¼ãƒ‰ç”Ÿæˆã€completionã€ç·¨é›†ï¼‰ã«ãŠã„ã¦æ€§èƒ½ãŒå‘ä¸Šã—ãŸã¨ã®ã“ã¨ã€‚<br><br>&lt;img width="865" height="348" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/d99b5ee6-dbc8-48f7-9b68-880add54dbbb"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/d99b5ee6-dbc8-48f7-9b68-880add54dbbb"&lt;/a&gt;


/&gt;<br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3157" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Bayesian scaling laws for in-context learning, Aryaman Arora+, COLM'25, 2024.10</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã«è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã•ã›ã‚‹æ‰‹æ³•ã§ã‚ã‚Šã€æä¾›ã•ã‚Œã‚‹ä¾‹ã®æ•°ã¨äºˆæ¸¬ç²¾åº¦ã«å¼·ã„ç›¸é–¢ãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ICLãŒãƒ™ã‚¤ã‚ºå­¦ç¿’è€…ã‚’è¿‘ä¼¼ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã€æ–°ã—ã„ãƒ™ã‚¤ã‚ºã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ææ¡ˆã€‚GPT-2ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã€ææ¡ˆæ³•å‰‡ãŒç²¾åº¦ã«ãŠã‘ã‚‹æ—¢å­˜ã®æ³•å‰‡ã¨ä¸€è‡´ã—ã€ã‚¿ã‚¹ã‚¯ã®äº‹å‰åˆ†å¸ƒã‚„å­¦ç¿’åŠ¹ç‡ã«é–¢ã™ã‚‹è§£é‡ˆå¯èƒ½ãªé …ã‚’æä¾›ã€‚å®Ÿé¨“ã§ã¯ã€ICLã‚’ç”¨ã„ã¦æŠ‘åˆ¶ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«èƒ½åŠ›ã‚’å†ç¾ã™ã‚‹æ¡ä»¶ã‚’äºˆæ¸¬ã—ã€LLMã®å®‰å…¨æ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=U2ihVSREUb#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=U2ihVSREUb#discussion</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stanfordnlp/status/1975574899428139413?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3156" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Synthetic Data Generation &amp; Multi-Step RL for Reasoning &amp; Tool Use, Anna Goldie+, COLM'25, 2025.04</a>
<span class="snippet"><span>GPT Summary</span>- æ®µéšçš„å¼·åŒ–å­¦ç¿’ï¼ˆSWiRLï¼‰ã‚’ææ¡ˆã—ã€è¤‡æ•°ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚„æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’é€šã˜ã¦å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã‚’ç´¹ä»‹ã€‚SWiRLã¯ã€å„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«å¯¾ã™ã‚‹ã‚µãƒ–è»Œé“ã‚’ç”Ÿæˆã—ã€åˆæˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨å¼·åŒ–å­¦ç¿’æœ€é©åŒ–ã‚’é©ç”¨ã€‚å®Ÿé¨“ã§ã¯ã€GSM8Kã‚„HotPotQAãªã©ã®ã‚¿ã‚¹ã‚¯ã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹ç²¾åº¦ã‚’é”æˆã—ã€ã‚¿ã‚¹ã‚¯é–“ã§ã®ä¸€èˆ¬åŒ–ã‚‚ç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=oN9STRYQVa" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=oN9STRYQVa</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stanfordnlp/status/1975574899428139413?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¾“æ¥ã®RLã§ã¯ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’1ã‚¹ãƒ†ãƒƒãƒ—ã¨ã—ã¦æ‰±ã†ã“ã¨ãŒå¤šã„ãŒã€è¤‡é›‘ãªæ¨è«–ã‚„tool useã‚’ä¼´ã†ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã¯è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã§ã®æœ€é©åŒ–ãŒå¿…è¦ã¨ãªã‚‹ã€‚ãã®ãŸã‚ã«ã€å¤šæ®µéšã®æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã®trajectoryã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã€åŒãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã„RLã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦æ€§èƒ½ãŒå‘ä¸Šã—ãŸã¨ã„ã†è©±ãªæ¨¡æ§˜ã€‚RLã‚’ã™ã‚‹éš›ã«ã¯ã€stepã”ã¨ã«Rewardã‚’ç”¨æ„ã™ã‚‹ã‚ˆã†ã§ã‚ã‚‹ã€‚ã¾ãŸã€ç¾åœ¨ã®stepã®ç”Ÿæˆã‚’å®Ÿæ–½ã™ã‚‹éš›ã«ã¯éå»ã®stepã®æƒ…å ±ã«åŸºã¥ã„ã¦ç”Ÿæˆã™ã‚‹æ–¹å¼ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/UserModeling.html" target="_blank" rel="noopener noreferrer">#UserModeling</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/UserBased.html" target="_blank" rel="noopener noreferrer">#UserBased</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3154" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Impatient Users Confuse AI Agents: High-fidelity Simulations of Human  Traits for Testing Agents, Muyu He+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- TraitBasisã‚’ç”¨ã„ã¦ã€ä¼šè©±å‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å …ç‰¢æ€§ã‚’ä½“ç³»çš„ã«ãƒ†ã‚¹ãƒˆã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç‰¹æ€§ï¼ˆã›ã£ã‹ã¡ã•ã‚„ä¸€è²«æ€§ã®ãªã•ï¼‰ã‚’åˆ¶å¾¡ã—ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹ã‚’è¦³å¯Ÿã€‚æœ€å‰ç·šã®ãƒ¢ãƒ‡ãƒ«ã§2%-30%ã®æ€§èƒ½ä½ä¸‹ã‚’ç¢ºèªã—ã€ç¾åœ¨ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è„†å¼±æ€§ã‚’ç¤ºã™ã€‚TraitBasisã¯ã‚·ãƒ³ãƒ—ãƒ«ã§ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ãŒé«˜ãã€ç¾å®Ÿã®äººé–“ã®ç›¸äº’ä½œç”¨ã«ãŠã‘ã‚‹ä¿¡é ¼æ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã€‚$\tau$-Traitã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãŒå¤šæ§˜ãªã‚·ãƒŠãƒªã‚ªã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è©•ä¾¡ã§ãã‚‹ã‚ˆã†ã«ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hemuyu0327/status/1975398313735389254?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å®Ÿéš›ã®äººé–“ã«ã‚ã‚‹ã‚ˆã†ãªç™–ï¼ˆã®ã‚ˆã†ãªæ‘‚å‹•ï¼‰ã‚’ä¸ãˆãŸæ™‚ã«ã©ã‚Œã ã‘ãƒ­ãƒã‚¹ãƒˆã‹ã¨ã„ã†ã®ã¯å®Ÿå¿œç”¨ä¸Šéå¸¸ã«é‡è¦ãªè¦³ç‚¹ã ã¨æ€ã‚ã‚Œã‚‹ã€‚å…ƒãƒã‚¹ãƒˆã‚’è¦‹ã‚‹ã¨ã€LLMå†…éƒ¨ã®matmulã‚’ç›´æ¥æ“ä½œã™ã‚‹ã“ã¨ã§ã€ä»»æ„ã®ãƒ¬ãƒ™ãƒ«ã®äººé–“ã®ç‰¹æ€§ï¼ˆe.g.,ç–‘ã„æ·±ã„ã€æ··ä¹±ã€ç„¦ã‚Šãªã©ï¼‰ã‚’æ¨¡å€£ã™ã‚‹æ¨¡æ§˜ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/TreeSearch.html" target="_blank" rel="noopener noreferrer">#TreeSearch</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3152" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual  Information, Jiaxi Li+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ç›¸äº’æƒ…å ±é‡ãƒ„ãƒªãƒ¼æ¢ç´¢ï¼ˆMITSï¼‰ã‚’ææ¡ˆã—ã€æ¨è«–çµŒè·¯ã®è©•ä¾¡ã¨æ¢ç´¢ã‚’åŠ¹ç‡åŒ–ã€‚PMIã«åŸºã¥ãã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é–¢æ•°ã‚’ç”¨ã„ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã¤ã¤å„ªã‚ŒãŸæ¨è«–æ€§èƒ½ã‚’å®Ÿç¾ã€‚ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã«åŸºã¥ãå‹•çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥ã§ãƒªã‚½ãƒ¼ã‚¹ã‚’æœ€é©é…åˆ†ã—ã€é‡ã¿ä»˜ãæŠ•ç¥¨æ–¹å¼ã§æœ€çµ‚äºˆæ¸¬ã‚’è¡Œã†ã€‚MITSã¯å¤šæ§˜ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1975474793547026605?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3151" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Magistral, Mistral-AI+, arXiv'25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- Mistralã®æ¨è«–ãƒ¢ãƒ‡ãƒ«Magistralã¨ç‹¬è‡ªã®å¼·åŒ–å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç´¹ä»‹ã€‚ã‚¼ãƒ­ã‹ã‚‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€LLMã®RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®é™ç•Œã‚’æ¢ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ã§ã®RLãŒèƒ½åŠ›ã‚’ç¶­æŒã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚Magistral Mediumã¯RLã®ã¿ã§è¨“ç·´ã•ã‚Œã€Magistral Smallã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nrehiew_/status/1974856956600111250?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2858" target="_blank" rel="noopener noreferrer">Magistral-Small-2509, MistralAI, 2025.09</a>
</p>
<p>MistralAIã®åˆã‚ã¦ã®reasoningãƒ¢ãƒ‡ãƒ«</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Finetuning.html" target="_blank" rel="noopener noreferrer">#Finetuning</a>
<a class="button" href="articles/EvolutionaryAlgorithm.html" target="_blank" rel="noopener noreferrer">#EvolutionaryAlgorithm</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3150" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Evolution Strategies at Scale: LLM Fine-Tuning Beyond Reinforcement  Learning, Xin Qiu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- é€²åŒ–æˆ¦ç•¥ï¼ˆESï¼‰ã‚’ç”¨ã„ã¦ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹åˆã®æˆåŠŸäº‹ä¾‹ã‚’å ±å‘Šã€‚ESã¯æ•°åå„„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¯¾ã—ã¦åŠ¹ç‡çš„ã«æ¢ç´¢ã§ãã€ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ã‚„ãƒ­ãƒã‚¹ãƒˆæ€§ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å®‰å®šæ€§ã«ãŠã„ã¦æ—¢å­˜ã®å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®æ–°ãŸãªæ–¹å‘æ€§ãŒé–‹ã‹ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hardmaru/status/1975463342576918845?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3148" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive  Experts, Jihoon Lee+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- dLLMsã¯ç•°ãªã‚‹ç”Ÿæˆé †åºã«åŸºã¥ãå°‚é–€çš„ãªæŒ™å‹•ã‚’å­¦ç¿’ã™ã‚‹ãŒã€å›ºå®šã•ã‚ŒãŸæ¨è«–ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯æ€§èƒ½ã‚’ä½ä¸‹ã•ã›ã‚‹ã€‚HEXã¨ã„ã†æ–°æ‰‹æ³•ã‚’å°å…¥ã—ã€ç•°ãªã‚‹ãƒ–ãƒ­ãƒƒã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’è¡Œã†ã“ã¨ã§ã€ç²¾åº¦ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã€‚GSM8Kã‚„MATHã€ARC-Cã€TruthfulQAãªã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é¡•è‘—ãªæ”¹å–„ã‚’ç¤ºã—ã€ãƒ†ã‚¹ãƒˆæ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®æ–°ãŸãªãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ç¢ºç«‹ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1975467150002229557?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯æ°—ã«ãªã‚‹ğŸ‘€</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/amritsinghbedi3/status/1975438873749786757?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3146" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Echo Chamber: RL Post-training Amplifies Behaviors Learned in   Pretraining, Rosie Zhao+, COLM'25, 2025.04</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã«ã‚ˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€æ•°å­¦çš„æ¨è«–ã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãŸã‚ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã—ã¦ã„ã‚‹ãŒã€ãã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯æœªè§£æ˜ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€ã•ã¾ã–ã¾ãªã‚¹ã‚±ãƒ¼ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹RLãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŠ¹æœã‚’èª¿æŸ»ã—ã€RLã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒå‡ºåŠ›åˆ†å¸ƒã«åæŸã—ã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å¢—å¹…ã™ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚ã¾ãŸã€ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ãŒç•°ãªã‚‹å‡ºåŠ›åˆ†å¸ƒã«åæŸã™ã‚‹ã“ã¨ã‚„ã€ç°¡å˜ãªè³ªå•ã¸ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒé›£ã—ã„è³ªå•ã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€RLã®å½¹å‰²ã«é–¢ã™ã‚‹æ–°ãŸãªæ´å¯ŸãŒå¾—ã‚‰ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosieyzh/status/1975276617078571277?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3144" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Pretraining with hierarchical memories: separating long-tail and common  knowledge, Hadi Pouransari+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- ç¾ä»£ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ä¾å­˜ã—ã¦ã„ã‚‹ãŒã€ã™ã¹ã¦ã®ä¸–ç•ŒçŸ¥è­˜ã‚’åœ§ç¸®ã™ã‚‹ã®ã¯éç¾å®Ÿçš„ã§ã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ãƒ¡ãƒ¢ãƒªæ‹¡å¼µã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ææ¡ˆã—ã€å°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ãŒéšå±¤çš„ãªãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ä»•çµ„ã¿ã‚’å°å…¥ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€160Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã«18Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¡ãƒ¢ãƒªã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€é€šå¸¸ã®ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã€‚ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã«ãŠã‘ã‚‹ãƒ¡ãƒ¢ãƒªã®æœ€é©ãªã‚¿ã‚¤ãƒ—ã¨ã‚µã‚¤ã‚ºã‚’ç ”ç©¶ã—ã€ææ¡ˆã—ãŸãƒ¡ãƒ¢ãƒªãŒå …ç‰¢ã«æ©Ÿèƒ½ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hpouransari/status/1975203449680937171?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Routing.html" target="_blank" rel="noopener noreferrer">#Routing</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3143" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Router-R1: Teaching LLMs Multi-Round Routing and Aggregation via   Reinforcement Learning, Haozhen Zhang+, NeurIPS'25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- Router-R1ã¯ã€è¤‡æ•°ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’åŠ¹æœçš„ã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã—é›†ç´„ã™ã‚‹ãŸã‚ã®å¼·åŒ–å­¦ç¿’ã«åŸºã¥ããƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚å†…éƒ¨ã®ç†Ÿæ…®ã¨å‹•çš„ãªãƒ¢ãƒ‡ãƒ«å‘¼ã³å‡ºã—ã‚’äº¤äº’ã«è¡Œã„ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚³ã‚¹ãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æœ€é©åŒ–ã€‚å®Ÿé¨“ã§ã¯ã€ä¸€èˆ¬çš„ãªQAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€å„ªã‚ŒãŸä¸€èˆ¬åŒ–ã¨ã‚³ã‚¹ãƒˆç®¡ç†ã‚’å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/youjiaxuan/status/1975245762721423548?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1979350466602373419?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3142" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Compressed Convolutional Attention: Efficient Attention in a Compressed  Latent Space, Tomas Figliolia+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Compressed Convolutional Attentionï¼ˆCCAï¼‰ã‚’ææ¡ˆã—ã€ã‚¯ã‚¨ãƒªã€ã‚­ãƒ¼ã€ãƒãƒªãƒ¥ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦å…¨ã¦ã®æ³¨æ„æ“ä½œã‚’å…±æœ‰ã•ã‚ŒãŸæ½œåœ¨ç©ºé–“å†…ã§å®Ÿè¡Œã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€FLOPã‚’å¤§å¹…ã«å‰Šæ¸›ã€‚ã•ã‚‰ã«ã€CCAã¨ãƒ˜ãƒƒãƒ‰å…±æœ‰ã‚’çµ„ã¿åˆã‚ã›ãŸCompressed Convolutional Grouped Query Attentionï¼ˆCCGQAï¼‰ã¯ã€è¨ˆç®—ã¨å¸¯åŸŸå¹…ã®åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã€GQAã‚„MLAã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚å®Ÿé¨“ã§ã¯ã€CCGQAãŒMoEãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ä»–ã®æ³¨æ„ãƒ¡ã‚½ãƒƒãƒ‰ã‚’åœ§å€’ã—ã€MHAã¨æ¯”è¼ƒã—ã¦ã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¶­æŒã—ã¤ã¤KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’8å€åœ§ç¸®ã€‚H100 GPUä¸Šã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨äº‹å‰ãƒ•ã‚£ãƒ«ã®é€Ÿåº¦ã‚’å¤§å¹…ã«å‘ä¸Šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stochasticchasm/status/1975390382537252984?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Denseãƒ¢ãƒ‡ãƒ«ã¨MoEãƒ¢ãƒ‡ãƒ«ã§Attentionã®å„ç¨®variantã®æ€§èƒ½ãŒå¤§ããå¤‰åŒ–ã™ã‚‹æ¨¡æ§˜ã€‚ã‹ã¤ã€ææ¡ˆæ‰‹æ³•ã¯ã©ã¡ã‚‰ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚‚è‰¯ã„æ€§èƒ½ã‚’é”æˆã™ã‚‹æ¨¡æ§˜(Fig3,4)ã€‚</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1975427848371367982?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1975401062157652266?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3140" target="_blank" rel="noopener noreferrer" class="title-link">è¨€èªãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨æ©Ÿåºï¼šè§£æã¨è§£é‡ˆ, HEINZERLING+, NLP'25, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1975322325181686097?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/GenerativeAdversarialNetwork.html" target="_blank" rel="noopener noreferrer">#GenerativeAdversarialNetwork</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3137" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Evolving LLMs via Continual Instruction Tuning, Jiazheng Kang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- MoE-CLã¯ã€ç”£æ¥­ç’°å¢ƒã«ãŠã‘ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç¶™ç¶šå­¦ç¿’ã‚’æ”¯æ´ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€ã‚¿ã‚¹ã‚¯ã”ã¨ã®LoRAå°‚é–€å®¶ã¨å…±æœ‰LoRAå°‚é–€å®¶ã‚’ç”¨ã„ã¦çŸ¥è­˜ã®ä¿æŒã¨ã‚¯ãƒ­ã‚¹ã‚¿ã‚¹ã‚¯ã®ä¸€èˆ¬åŒ–ã‚’å®Ÿç¾ã€‚æ•µå¯¾çš„å­¦ç¿’ã«ã‚ˆã‚Šã€ã‚¿ã‚¹ã‚¯ã«é–¢é€£ã™ã‚‹æƒ…å ±ã®ã¿ã‚’é€šéã•ã›ã‚‹è­˜åˆ¥å™¨ã‚’çµ±åˆã—ã€è‡ªå·±é€²åŒ–ã‚’ä¿ƒé€²ã€‚å®Ÿé¨“çµæœã§ã¯ã€Tencent Videoãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã®æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚³ã‚¹ãƒˆã‚’15.3%å‰Šæ¸›ã—ã€å®Ÿç”¨æ€§ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1975059944815595710?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>continual instruction tuning... ãã—ã¦GAN!?</p>
<p>ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®çŸ¥è­˜ã‚’å‚™ãˆãŸLoRAã¨ã€ã‚¿ã‚¹ã‚¯é–“ã§å…±æœ‰ã•ã‚Œã‚‹LoRAãŒã‚¯ãƒ­ã‚¹ã‚¿ã‚¹ã‚¯ã®è»¢ç§»ã‚’ä¿ƒã—ã€ãã‚Œãã‚Œã‚’MoEã«ãŠã‘ã‚‹expertsã¨ã—ã¦æ‰±ã†ã“ã¨ã§ã€inputã«å¯¾ã—ã¦å‹•çš„ã«å¿…è¦ãªLoRA expertsã‚’é¸æŠã™ã‚‹ã€‚ã“ã®ã¨ãã€Task Classifierï¼ˆAdversarialã«è¨“ç·´ã™ã‚‹ï¼‰ã§ã‚¿ã‚¹ã‚¯ã«é–¢ä¿‚ãªã„æƒ…å ±ãŒé †ä¼æ¬ã•ã‚Œãªã„ã‚ˆã†ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã£ã½ã„ï¼Ÿï¼ˆGANã‚’Text Classifierã®å­¦ç¿’ã«ä½¿ã„ã€Classifierã®æƒ…å ±ã‚’ç”¨ã„ã‚‹ã“ã¨ã§å…±æœ‰/ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®LoRA expertsãŒå­¦ç¿’ã•ã‚Œã‚‹ã‚ˆã†ã«ä¿ƒã™ã‚ˆã†ã ãŒã€ç´°ã‹ãã©ã†ã‚„ã‚‹ã‹ã¯èª­ã¾ãªã„ã¨ã‚ã‹ã‚‰ãªã„ï¼‰ã€‚<br><br>ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®ã‚¿ã‚¹ã‚¯ã¨ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã€ã•ã¾ã–ã¾ãªã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’è¿½åŠ ã—ã¦ã„ãã€catastrophic forgettingã‚’é˜²ããªãŒã‚‰ã€æ‰±ãˆã‚‹ã‚¿ã‚¹ã‚¯ã®å¹…ãŒåºƒãŒã£ã¦ã„ãæ çµ„ã¿è‡ªä½“ã¯é¢ç™½ãã†ï¼ˆå­¦ç¿’ã¯æœãŸã—ã¦å®‰å®šã™ã‚‹ã®ã ã‚ã†ã‹ï¼‰ã€‚<br><br><img src="https://github.com/user-attachments/assets/a09b2021-d487-49d5-9782-35b8e613d0a8" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<span class="issue_date">Issue Date: 2025-10-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3132" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Free Draft-and-Verification: Toward Lossless Parallel Decoding for  Diffusion Large Language Models, Shutong Wu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- Diffusion Large Language Models (DLLMs)ã¯ã€åŒæ–¹å‘ã®æ³¨æ„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ã‚ˆã‚Šæ–‡è„ˆã‚’æ‰ãˆã‚‹èƒ½åŠ›ãŒé«˜ã„ãŒã€æ¨è«–åŠ¹ç‡ãŒè‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«ã«åŠ£ã‚‹ã€‚æ—¢å­˜ã®ä¸¦åˆ—ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯æ€§èƒ½ä½ä¸‹ã‚’ä¼´ã†ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€æå¤±ã®ãªã„ä¸¦åˆ—ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å®Ÿç¾ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€ŒFree Draft-and-Verificationï¼ˆFreedaveï¼‰ã€ã‚’ææ¡ˆã€‚Freedaveã«ã‚ˆã‚Šã€DLLMsã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¯æ•°å­¦çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã§æœ€å¤§2.8å€å‘ä¸Šã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lingyang_pu/status/1974754204473536620?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3128" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] IA2: Alignment with ICL Activations Improves Supervised Fine-Tuning, Aayush Mishra+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã®æ´»æ€§åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ©ç”¨ã—ã¦ã€ç›£è¦–ä»˜ããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã®å“è³ªã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚ICLã¨SFTã®ç•°ãªã‚‹é©å¿œãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ç¤ºã—ã€ICLæ´»æ€§åŒ–ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆIA2ï¼‰ã¨ã„ã†è‡ªå·±è’¸ç•™æŠ€è¡“ã‚’å°å…¥ã€‚IA2ã‚’SFTã®å‰ã«å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ç²¾åº¦ã¨ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’12ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å®Ÿè¨¼ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«é©å¿œã®å†…éƒ¨ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«å¯¾ã™ã‚‹æ–°ãŸãªè¦–ç‚¹ã‚‚æä¾›ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/danielkhashabi/status/1974119053728919790?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3123" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generalized Parallel Scaling with Interdependent Generations, Harry Dong+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Bridgeã‚’ææ¡ˆã—ã€ä¸¦åˆ—LLMæ¨è«–ã§ç›¸äº’ä¾å­˜ã™ã‚‹å¿œç­”ã‚’ç”Ÿæˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¹³å‡ç²¾åº¦ãŒæœ€å¤§50%å‘ä¸Šã—ã€ä¸€è²«æ€§ãŒå¢—ã™ã€‚è¨“ç·´å¾Œã¯ä»»æ„ã®ç”Ÿæˆå¹…ã«ã‚¹ã‚±ãƒ¼ãƒ«å¯èƒ½ã§ã€ç‹¬ç«‹ç”Ÿæˆã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1974191420329390224?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/OOD.html" target="_blank" rel="noopener noreferrer">#OOD</a>
<a class="button" href="articles/Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3121" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Visual Instruction Bottleneck Tuning, Changdae Oh+, NeurIPS'25, 2025.05</a>
<span class="snippet"><span>GPT Summary</span>- MLLMã¯æœªçŸ¥ã®ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ãŒã€æ—¢å­˜ã®æ”¹å–„ç­–ã¯å¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚„è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’è¦ã™ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æƒ…å ±ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åŸç†ã«åŸºã¥ãã€MLLMã®å …ç‰¢æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®Vittleã‚’ææ¡ˆã€‚45ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å®Ÿè¨¼å®Ÿé¨“ã«ã‚ˆã‚Šã€VittleãŒMLLMã®å …ç‰¢æ€§ã‚’ä¸€è²«ã—ã¦æ”¹å–„ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sharonyixuanli/status/1974150056501535207?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3120" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Nudging the Boundaries of LLM Reasoning, Justin Chih-Yao Chen+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- NuRLã¯ã€è‡ªå·±ç”Ÿæˆã•ã‚ŒãŸãƒ’ãƒ³ãƒˆã‚’ç”¨ã„ã¦ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ä¸Šé™ã‚’å¼•ãä¸Šã’ã‚‹æ‰‹æ³•ã§ã‚ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã¯é€£é–çš„æ€è€ƒã‚’ç”Ÿæˆã—ã€é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã—ã¦ãƒ’ãƒ³ãƒˆã‚’æ³¨å…¥ã™ã‚‹ã“ã¨ã§åˆæ ¼ç‡ã‚’å‘ä¸Šã•ã›ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¿¡å·ã‚’å°å…¥ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åˆ†å¸ƒã®ã‚·ãƒ•ãƒˆã‚’å›é¿ã—ã¤ã¤ã€6ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ä¸€è²«ã—ãŸæ”¹å–„ã‚’é”æˆã€‚ç‰¹ã«ã€æœ€ã‚‚åŠ¹æœçš„ãªãƒ’ãƒ³ãƒˆã¯æŠ½è±¡çš„ã§é«˜ãƒ¬ãƒ™ãƒ«ã§ã‚ã‚Šã€GRPOã¨æ¯”è¼ƒã—ã¦ãƒ¢ãƒ‡ãƒ«ã®ä¸Šé™ã‚’å¼•ãä¸Šã’ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/beckypeng6/status/1973813689443889640?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RLã§å­¦ç¿’ã«åˆ©ç”¨ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®é›£æ˜“åº¦ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§æ€§èƒ½ä¸Šã’ã¾ã™ç³»ã®è©±ãŒæº¢ã‚Œã¦ã„ã‚‹ã€‚ã—ã‹ã—ã“ã®è©±ã¯ã©ã¡ã‚‰ã‹ã¨ã„ã†ã¨ä¸Šé™ã‚’æŠ¼ã—ä¸Šã’ã‚‹ã¿ãŸã„ãªè©±ã‚‰ã—ã„ï¼Ÿï¼ˆRLVRã¯è§£æ±ºå¯èƒ½ãªå•é¡Œã—ã‹å‹¾é…ãŒæµã‚Œãªã„ã¨ã„ã†èª²é¡Œï¼‰</p></span><br><br>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3115" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Towards Reliable Benchmarking: A Contamination Free, Controllable  Evaluation Framework for Multi-step LLM Function Calling, Seiji Maekawa+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- TaLMsã®è©•ä¾¡ã®ãŸã‚ã«ã€æ±šæŸ“ã®ãªã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯FuncBenchGenã‚’ææ¡ˆã€‚ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚’DAGä¸Šã®ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«ã¨ã—ã¦æ‰ãˆã€ãƒ¢ãƒ‡ãƒ«ã¯æ­£ã—ã„é–¢æ•°å‘¼ã³å‡ºã—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’æ§‹æˆã€‚7ã¤ã®LLMã‚’ç•°ãªã‚‹é›£æ˜“åº¦ã®ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã—ãŸçµæœã€GPT-5ãŒç‰¹ã«å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€ä¾å­˜ã®æ·±ã•ãŒå¢—ã™ã¨æ€§èƒ½ãŒä½ä¸‹ã€‚å¤ã„å¼•æ•°å€¤ã®ä¼æ’­ãŒå•é¡Œã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã€å†è¡¨ç¾æˆ¦ç•¥ã‚’å°å…¥ã—ãŸã¨ã“ã‚ã€æˆåŠŸç‡ãŒ62.5%ã‹ã‚‰81.3%ã«å‘ä¸Šã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ppezeshkpour/status/1973790323265749355?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Financial.html" target="_blank" rel="noopener noreferrer">#Financial</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3114" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] StockBench: Can LLM Agents Trade Stocks Profitably In Real-world  Markets?, Yanxu Chen+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®é‡‘èåˆ†é‡ã«ãŠã‘ã‚‹è©•ä¾¡ã®ãŸã‚ã«ã€StockBenchã¨ã„ã†æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã€‚ã“ã‚Œã¯ã€æ ªå¼å–å¼•ç’°å¢ƒã§ã®LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã—ã€ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã‚„ãƒªã‚¹ã‚¯ç®¡ç†èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ã€‚å¤šãã®LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã‚·ãƒ³ãƒ—ãƒ«ãªæˆ¦ç•¥ã‚’è¶…ãˆã‚‹ã®ãŒé›£ã—ã„ãŒã€ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯é«˜ã„ãƒªã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã™å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚StockBenchã¯å†ç¾æ€§ã‚’æ”¯æ´ã—ã€ä»Šå¾Œã®ç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ãŸã‚ã«ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦å…¬é–‹ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1974270437975523596?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj page:


<a href="https://stockbench.github.io" target="_blank" rel="noopener noreferrer">https://stockbench.github.io</a>


</p>
<p>éå»ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã„LLMã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã¨ã„ã†æ–¹å‘æ€§ãªã‚‰ã“ã†ã„ã£ãŸã‚¿ã‚¹ã‚¯ã‚‚è‰¯ã„ã®ã‹ã‚‚ã—ã‚Œãªã„ã€‚<br><br>ãŒã€ç´ æœ´ãªç–‘å•ã¨ã—ã¦ã€LLMãŒè‰¯ã„ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚’ã—ã¦å„²ã‘ã‚‰ã‚Œã¾ã™ã€ã¿ãŸã„ãªã‚·ã‚¹ãƒ†ãƒ ãŒä¸–ã«åºƒã¾ã£ãŸä¸–ç•Œã®å‰æã«ãªã‚‹ã¨ã€ãã‚Œã«ã‚ˆã£ã¦å¸‚å ´ã®åŸç†ãŒå¤‰ã‚ã£ã¦LLMå´ãŒå‰æã¨ã—ã¦ã„ãŸã‚‚ã®ãŒããšã‚Œã€çµæœçš„ã«LLMã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã§å„²ã‘ã‚‰ã‚Œãªããªã‚‹ã€ã¿ãŸã„ãªã“ã¨ãŒèµ·ãã‚‹ã‚“ã˜ã‚ƒãªã„ã‹ã€ã¨ã„ã†æ°—ã¯ã™ã‚‹ã®ã§ã‚ãã¾ã§LLMã®èƒ½åŠ›ã‚’æ¸¬ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã™ã€ã¨ã„ã†ç‚¹ã¯ç•™æ„ã—ãŸæ–¹ãŒè‰¯ã„ã®ã‹ãªã€ã¨ã„ã†æ„Ÿæƒ³ã‚’æŒã¤ãªã©ã—ãŸï¼ˆå®Ÿéš›ã¯ã‚ˆãã‚ã‹ã‚‰ã‚“ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/MCP.html" target="_blank" rel="noopener noreferrer">#MCP</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3111" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TOUCAN: Synthesizing 1.5M Tool-Agentic Data from Real-World MCP  Environments, Zhangchen Xu+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Toucanã¯ã€ç´„500ã®å®Ÿä¸–ç•Œã®ãƒ¢ãƒ‡ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‹ã‚‰åˆæˆã•ã‚ŒãŸ150ä¸‡ã®è»Œè·¡ã‚’å«ã‚€ã€æœ€å¤§ã®å…¬é–‹ãƒ„ãƒ¼ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æä¾›ã€‚å¤šæ§˜ã§ç¾å®Ÿçš„ãªã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆã—ã€ãƒãƒ«ãƒãƒ„ãƒ¼ãƒ«ãŠã‚ˆã³ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã«å¯¾å¿œã€‚5ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã€å³å¯†ãªæ¤œè¨¼ã‚’é€šã˜ã¦é«˜å“è³ªãªå‡ºåŠ›ã‚’ä¿è¨¼ã€‚Toucanã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€BFCL V3ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€MCP-Universe Benchã§ã®é€²å±•ã‚’å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhangchen_xu/status/1973972516483051709?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>dataset:


<a href="https://huggingface.co/datasets/Agent-Ark/Toucan-1.5M" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/Agent-Ark/Toucan-1.5M</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3106" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Large Reasoning Models Learn Better Alignment from Flawed Thinking, ShengYun Peng+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- RECAPã¯ã€èª¤ã£ãŸæ¨è«–ã‚’è¦†ã—å®‰å…¨ãªå¿œç­”ã«å°ããŸã‚ã®å¼·åŒ–å­¦ç¿’æ‰‹æ³•ã€‚åˆæˆç”Ÿæˆã•ã‚ŒãŸåå¯¾æ•´åˆCoTã‚’ç”¨ã„ã¦è¨“ç·´ã—ã€å®‰å…¨æ€§ã¨å …ç‰¢æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚RECAPã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯è‡ªå·±åçœãŒé »ç¹ã§ã€é©å¿œæ”»æ’ƒã«ã‚‚å¼·ã„ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haozhu_wang/status/1974142611071144024?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å®‰å…¨ã§ãªã„ï¼ˆæ¬ é™¥ã®ã‚ã‚‹ï¼‰Reasoning traceã‚’ä¿®å¾©ã™ã‚‹ã‚ˆã†ãªå­¦ç¿’ã‚’ã•ã›ã‚‹ã“ã¨ã§ã‚ˆã‚Šãƒ­ãƒã‚¹ãƒˆãªsafety algnmentãŒå®Ÿç¾ã§ãã¾ã™ã€ã¨ã„ã£ãŸè©±ãªæ¨¡æ§˜</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jianfengchi/status/1973944383696519403?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/ReplayBuffer.html" target="_blank" rel="noopener noreferrer">#ReplayBuffer</a>
<a class="button" href="articles/TreeSearch.html" target="_blank" rel="noopener noreferrer">#TreeSearch</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3103" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DeepSearch: Overcome the Bottleneck of Reinforcement Learning with  Verifiable Rewards via Monte Carlo Tree Search, Fang Wu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- DeepSearchã¯ã€RLVRãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«Monte Carlo Tree Searchã‚’çµ±åˆã—ã€ä½“ç³»çš„ãªæ¢ç´¢ã‚’å¯èƒ½ã«ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é™ã‚‰ã‚ŒãŸãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã«ä¾å­˜ã›ãšã€é‡è¦ãªæ¨è«–çµŒè·¯ã‚’è¦‹é€ƒã•ãªã„ã€‚å®Ÿé¨“ã§ã¯ã€62.95%ã®å¹³å‡ç²¾åº¦ã‚’é”æˆã—ã€1.5Bæ¨è«–ãƒ¢ãƒ‡ãƒ«ã§æ–°ãŸãªæœ€å…ˆç«¯ã‚’ç¢ºç«‹ã€‚æˆ¦ç•¥çš„ãªæ¢ç´¢ã®é‡è¦æ€§ã‚’ç¤ºã—ã€RLVRæ‰‹æ³•ã®é€²å±•ã«å‘ã‘ãŸæ–°ãŸãªæ–¹å‘æ€§ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1973827122415513675?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æœ€è¿‘ã¯RLæ™‚ã®æ¢ç´¢ç©ºé–“ã‚’å¢—ã‚„ã™å–ã‚Šçµ„ã¿ãŒå¢—ãˆã¦ãã¦ã„ã‚‹ã‚ˆã†ã«æ„Ÿã˜ã‚‹ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3104" target="_blank" rel="noopener noreferrer">Replay BufferãŒPolicy Gradientã§ä½¿ãˆãªã„ç†ç”±, piqcy, 2019.03</a>
<br><br>ã«ã‚‚ã‚ã‚‹ã‚ˆã†ã«åŸºæœ¬çš„ã«ã‚ªãƒ³ãƒãƒªã‚·ãƒ¼RLã§ã¯ãƒªãƒ—ãƒ¬ã‚¤ãƒãƒƒãƒ•ã‚¡ã‚’ä½¿ãˆãªã„ã®ã§ä½•ã‚‰ã‹ã®å·¥å¤«ãŒå¿…è¦ã€ã¨ã„ã£ãŸè©±ãŒã‚ã‚‹ãŒã€ã“ã®ç ”ç©¶ã§ã¯GRPOã‚’å‰æã¨ã—ã¤ã¤ãƒªãƒ—ãƒ¬ã‚¤ãƒãƒƒãƒ•ã‚¡ã‚’æ´»ç”¨ã™ã‚‹æ çµ„ã¿ã¨ãªã£ã¦ã„ã‚‹ã‚ˆã†ãªã®ã§ã€ã©ã®ã‚ˆã†ãªå·¥å¤«ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã®ã ã‚ã†ã‹ã€‚å‹‰å¼·ã—ãŸã„ã€‚</p>
<p>æ‰€è¦‹ã¨è§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/max_paperclips/status/1974011545425228238?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3101" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Data Mixing Can Induce Phase Transitions in Knowledge Acquisition, Xinran Gu+, arXiv'25, 2025.05</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®è¨“ç·´ã«ãŠã„ã¦ã€çŸ¥è­˜ãŒè±Šå¯Œãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã‚¦ã‚§ãƒ–ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®æ··åˆãŒã€çŸ¥è­˜ç²å¾—ã«ãŠã„ã¦ä½ç›¸è»¢ç§»ã‚’ç¤ºã™ã“ã¨ã‚’å®Ÿè¨¼ã€‚ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’è‡¨ç•Œå€¤ã¾ã§å¢—åŠ ã•ã›ã‚‹ã¨ã€è¨˜æ†¶çŠ¶æ…‹ãŒæ€¥æ¿€ã«å¤‰åŒ–ã—ã€æ··åˆæ¯”ç‡ãŒè‡¨ç•Œå€¤ã‚’è¶…ãˆã‚‹ã¨æ€¥é€Ÿã«è¨˜æ†¶ãŒå¢—åŠ ã€‚ã“ã‚Œã‚‰ã®ç¾è±¡ã¯å®¹é‡é…åˆ†ã«èµ·å› ã—ã€æœ€é©ãªãƒ‡ãƒ¼ã‚¿é…åˆ†ãŒãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚„æ··åˆæ¯”ç‡ã«ã‚ˆã£ã¦ä¸é€£ç¶šã«å¤‰ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Medical.html" target="_blank" rel="noopener noreferrer">#Medical</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3097" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Radiology's Last Exam ï¼ˆRadLEï¼‰: Benchmarking Frontier Multimodal AI  Against Human Experts and a Taxonomy of Visual Reasoning Errors in Radiology, Suvrankar Datta+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- åŒ»ç™‚ç”»åƒã®è§£é‡ˆã«ãŠã‘ã‚‹AIãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã€50ã®å°‚é–€çš„ãªã€Œã‚¹ãƒãƒƒãƒˆè¨ºæ–­ã€ã‚±ãƒ¼ã‚¹ã‚’ç”¨ã„ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’é–‹ç™ºã€‚5ã¤ã®æœ€å‰ç·šAIãƒ¢ãƒ‡ãƒ«ï¼ˆGPT-5ã€o3ã€Gemini 2.5 Proã€Grok-4ã€Claude Opus 4.1ï¼‰ã‚’ãƒ†ã‚¹ãƒˆã—ãŸçµæœã€ãƒœãƒ¼ãƒ‰èªå®šæ”¾å°„ç·šåŒ»ãŒæœ€é«˜ã®è¨ºæ–­ç²¾åº¦ï¼ˆ83%ï¼‰ã‚’é”æˆã—ã€AIãƒ¢ãƒ‡ãƒ«ã¯æœ€è‰¯ã®GPT-5ã§ã‚‚30%ã«ç•™ã¾ã£ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€AIãƒ¢ãƒ‡ãƒ«ãŒé›£ã—ã„è¨ºæ–­ã‚±ãƒ¼ã‚¹ã«ãŠã„ã¦æ”¾å°„ç·šåŒ»ã«ã¯åŠã°ãªã„ã“ã¨ãŒç¤ºã•ã‚Œã€åŒ»ç™‚ç”»åƒã«ãŠã‘ã‚‹AIã®é™ç•Œã¨ç„¡ç›£è¦–ä½¿ç”¨ã¸ã®è­¦å‘ŠãŒå¼·èª¿ã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/drdatta_aiims/status/1973373655251038701?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kimmonismus/status/1974594801598418963?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Entropy.html" target="_blank" rel="noopener noreferrer">#Entropy</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3093" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ExGRPO: Learning to Reason from Experience, Runzhe Zhan+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- RLVRã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„æ‰‹æ³•ã§ã™ãŒã€æ¨™æº–çš„ãªè¨“ç·´æ–¹æ³•ã¯è¨ˆç®—åŠ¹ç‡ãŒæ‚ªã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ¨è«–çµŒé¨“ã®ä¾¡å€¤ã‚’èª¿æŸ»ã—ã€ExGRPOãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€çµŒé¨“ã®æ•´ç†ã¨å„ªå…ˆé †ä½ä»˜ã‘ã‚’è¡Œã„ã€æ¢ç´¢ã¨çµŒé¨“æ´»ç”¨ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ã€‚å®Ÿé¨“çµæœã§ã¯ã€ExGRPOãŒæ¨è«–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã€è¨“ç·´ã®å®‰å®šæ€§ã‚’é«˜ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1973984289198076207?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3091" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Thoughtbubbles: an Unsupervised Method for Parallel Thinking in Latent  Space, Houjun Liu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®æ–°ã—ã„å¤‰ç¨®ã€ŒThoughtbubblesã€ã‚’ææ¡ˆã—ã€ä¸¦åˆ—é©å¿œè¨ˆç®—ã‚’æ½œåœ¨ç©ºé–“ã§å®Ÿè¡Œã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€‚æ®‹å·®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ãƒ•ã‚©ãƒ¼ã‚¯ã¾ãŸã¯å‰Šé™¤ã™ã‚‹ã“ã¨ã§ã€è¨ˆç®—ã‚’åŠ¹ç‡åŒ–ã—ã€äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«å­¦ç¿’å¯èƒ½ã€‚Thoughtbubblesã¯ã€å¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€æ¨è«–æ™‚ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ãƒ†ã‚¹ãƒˆã®æŒ™å‹•ã‚’çµ±ä¸€ã™ã‚‹å¯èƒ½æ€§ã‚’æŒã¤ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/houjun_liu/status/1973778517427937323?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é‡è¦è«–æ–‡ã«è¦‹ãˆã‚‹</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3088" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Demystifying Synthetic Data in LLM Pre-training: A Systematic Study of  Scaling Laws, Benefits, and Pitfalls, Feiyang Kang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- åˆæˆãƒ‡ãƒ¼ã‚¿æŠ€è¡“ã¯LLMã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ä¾›çµ¦åˆ¶é™ã‚’å…‹æœã™ã‚‹å¯èƒ½æ€§ã‚’æŒã¤ã€‚æœ¬ç ”ç©¶ã§ã¯ã€è‡ªç„¶ãªã‚¦ã‚§ãƒ–ãƒ‡ãƒ¼ã‚¿ã¨åˆæˆãƒ‡ãƒ¼ã‚¿ã®æ··åˆã‚’æ¯”è¼ƒã—ã€è¨€ã„æ›ãˆãŸåˆæˆãƒ‡ãƒ¼ã‚¿ã®ã¿ã§ã®äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯è‡ªç„¶ãªãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚é€Ÿããªã„ã“ã¨ã‚’ç¤ºã—ãŸã€‚1/3ã®è¨€ã„æ›ãˆãŸåˆæˆãƒ‡ãƒ¼ã‚¿ã¨2/3ã®è‡ªç„¶ãƒ‡ãƒ¼ã‚¿ã®æ··åˆãŒã€ã‚ˆã‚ŠåŠ¹ç‡çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚æ•™ç§‘æ›¸ã‚¹ã‚¿ã‚¤ãƒ«ã®åˆæˆãƒ‡ãƒ¼ã‚¿ã¯å°ã•ãªãƒ‡ãƒ¼ã‚¿äºˆç®—ã§é«˜ã„æå¤±ã‚’ã‚‚ãŸã‚‰ã—ã€åˆæˆãƒ‡ãƒ¼ã‚¿ã®æœ€é©ãªæ¯”ç‡ã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨ãƒ‡ãƒ¼ã‚¿äºˆç®—ã«ä¾å­˜ã™ã‚‹ã€‚çµæœã¯åˆæˆãƒ‡ãƒ¼ã‚¿ã®åŠ¹æœã‚’æ˜ã‚‰ã‹ã«ã—ã€å®Ÿç”¨çš„ãªã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/papers_anon/status/1973939270747668698?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1974108247003934902?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>åˆæˆãƒ‡ãƒ¼ã‚¿ã¯é©åˆ‡ãªè¦æ¨¡ã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”ç‡ã§ãªã„ã¨åˆ©ç‚¹ãŒç¾ã‚Œãªã„</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3101" target="_blank" rel="noopener noreferrer">[Paper Note] Data Mixing Can Induce Phase Transitions in Knowledge Acquisition, Xinran Gu+, arXiv'25, 2025.05</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<a class="button" href="articles/Clustering-based.html" target="_blank" rel="noopener noreferrer">#Clustering-based</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3086" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CLUE: Non-parametric Verification from Experience via Hidden-State  Clustering, Zhenwen Liang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®å‡ºåŠ›å“è³ªè©•ä¾¡ã«ãŠã„ã¦ã€å¾“æ¥ã®æ–¹æ³•ã¯è¡¨é¢çš„ãªæ‰‹ãŒã‹ã‚Šã«ä¾å­˜ã—ãŒã¡ã§ã€ä¿¡é ¼åº¦ã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒä¸ååˆ†ãªå ´åˆã«å¤±æ•—ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€éš ã‚ŒçŠ¶æ…‹ã‚’ç›´æ¥æ¤œè¨¼ã™ã‚‹æ–°ãŸãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€ŒClueã€ã‚’ææ¡ˆã—ã€éš ã‚Œæ´»æ€§åŒ–ã®è»Œè·¡ã‚’ç”¨ã„ã¦æ¨è«–ã®æ­£ç¢ºæ€§ã‚’åˆ†é¡ã™ã‚‹ã€‚Clueã¯éãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãªæ¤œè¨¼å™¨ã§ã€éå»ã®çµŒé¨“ã«åŸºã¥ãã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã„ã€LLMã‚’åˆ¤å®šè€…ã¨ã™ã‚‹ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹æˆæœã‚’ç¤ºã—ãŸã€‚ç‰¹ã«ã€AIME 24ã«ãŠã„ã¦ç²¾åº¦ã‚’56.7%ã‹ã‚‰70.0%ã«å‘ä¸Šã•ã›ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wyu_nd/status/1973947918467162200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/UserModeling.html" target="_blank" rel="noopener noreferrer">#UserModeling</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/UserBased.html" target="_blank" rel="noopener noreferrer">#UserBased</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3082" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Personalized Reasoning: Just-In-Time Personalization and Why LLMs Fail  At It, Shuyue Stella Li+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- ç¾åœ¨ã®LLMã¯ã€ã‚¿ã‚¹ã‚¯è§£æ±ºã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã®æ•´åˆæ€§ã‚’åˆ¥ã€…ã«æ‰±ã£ã¦ãŠã‚Šã€ç‰¹ã«ã‚¸ãƒ£ã‚¹ãƒˆã‚¤ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚·ãƒŠãƒªã‚ªã§ã¯åŠ¹æœçš„ã§ã¯ãªã„ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã‚’å¼•ãå‡ºã—ã€å¿œç­”ã‚’é©å¿œã•ã›ã‚‹ã€Œãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºãƒ‰æ¨è«–ã€ãŒå¿…è¦ã§ã‚ã‚‹ã€‚æ–°ãŸã«ææ¡ˆã•ã‚ŒãŸè©•ä¾¡æ‰‹æ³•ã€ŒPREFDISCOã€ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¿œã˜ãŸç•°ãªã‚‹æ¨è«–ãƒã‚§ãƒ¼ãƒ³ã‚’ç”Ÿæˆã—ã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã®é‡è¦æ€§ã‚’ç¤ºã™ã€‚è©•ä¾¡çµæœã‹ã‚‰ã€å˜ç´”ãªãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºãŒä¸€èˆ¬çš„ãªå¿œç­”ã‚ˆã‚Šã‚‚åŠ£ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€å°‚ç”¨ã®é–‹ç™ºãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚ŒãŸã€‚PREFDISCOã¯ã€æ•™è‚²ã‚„åŒ»ç™‚ãªã©ã®åˆ†é‡ã§ã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã®é‡è¦æ€§ã‚’å¼·èª¿ã™ã‚‹åŸºç›¤ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stellalisy/status/1973764628632281271?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã–ãƒ¼ã£ã¨ã—ã‹èª­ã‚ã¦ã„ãªã„ã®ãŒã€ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ä¸ãˆã‚‰ã‚ŒãŸã‚¿ã‚¹ã‚¯ã¨ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®ä¼šè©±ã®å±¥æ­´ã«åŸºã¥ã„ã¦ã€LLMå´ãŒè³ªå•ã‚’æŠ•ã’ã‹ã‘ã¦ã€Personalizationã«å¿…è¦ãªattributeã‚’å–å¾—ã™ã‚‹ã€‚ã¤ã¾ã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¯ (attribute, value, weight)ã®ã‚¿ãƒ—ãƒ«ã«ã‚ˆã£ã¦æ§‹æˆã•ã‚Œã€ã“ã®æƒ…å ±ã«åŸºã¥ã„ã¦ç”ŸæˆãŒãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã«alignã™ã‚‹ã‚ˆã†ã«ç”Ÿæˆã™ã‚‹ã€ã¨ã„ã£ãŸè©±ã«è¦‹ãˆã‚‹ã€‚è†¨å¤§ãªã¨ã‚Šã†ã‚‹attributeã®ä¸­ã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶ã®ã‚¿ã‚¹ã‚¯ã¨contextã«åˆã‚ã›ã¦ã©ã®attributeã«é–¢ã™ã‚‹æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã‹ãŒéµã¨ãªã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚ã¾ãŸã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ã§ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã€ä¿æŒã¯ã—ãªã„å‰æãªè©±ã«è¦‹ãˆã‚‹ã®ã§ã€Personalizationã®ã‚«ãƒ†ã‚´ãƒªã¨ã—ã¦ã¯ä¸€æ™‚çš„å€‹äººåŒ–ã«ç›¸å½“ã™ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚<br>Personalizationã®ç ”ç©¶ã¯è©•ä¾¡ãŒéå¸¸ã«é›£ã—ã„ã®ã§ã€ã©ã®ã‚ˆã†ãªè©•ä¾¡ã‚’ã—ã¦ã„ã‚‹ã‹ã¯æ³¨æ„ã—ã¦èª­ã‚“ã æ–¹ãŒè‰¯ã„ã¨æ€ã‚ã‚Œã‚‹ã€‚<br>&lt;img width="1003" height="567" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/3d411a63-f8de-4267-b6c0-edfe3143d4ac"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/3d411a63-f8de-4267-b6c0-edfe3143d4ac"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<a class="button" href="articles/Editing.html" target="_blank" rel="noopener noreferrer">#Editing</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3073" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] EditReward: A Human-Aligned Reward Model for Instruction-Guided Image  Editing, Keming Wu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªç„¶è¨€èªæŒ‡ç¤ºã«ã‚ˆã‚‹ç”»åƒç·¨é›†ã®é€²å±•ã«ãŠã„ã¦ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¯é…ã‚Œã‚’ã¨ã£ã¦ã„ã‚‹ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€20ä¸‡ä»¥ä¸Šã®é¸å¥½ãƒšã‚¢ã‚’å«ã‚€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\mnameã‚’æ§‹ç¯‰ã—ã€æŒ‡ç¤ºã«åŸºã¥ãç”»åƒç·¨é›†ã‚¿ã‚¹ã‚¯ã§äººé–“ã®é¸å¥½ã¨é«˜ã„æ•´åˆæ€§ã‚’ç¤ºã—ãŸã€‚å®Ÿé¨“ã§ã¯ã€\mnameãŒæ—¢å­˜ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®äººé–“ç›¸é–¢ã‚’é”æˆã—ã€ãƒã‚¤ã‚ºã®å¤šã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰é«˜å“è³ªãªã‚µãƒ–ã‚»ãƒƒãƒˆã‚’é¸æŠã™ã‚‹ã“ã¨ã§ã€ç”»åƒç·¨é›†ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ããŸã€‚ä»Šå¾Œã€\mnameã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å…¬é–‹ã•ã‚Œã€é«˜å“è³ªãªç”»åƒç·¨é›†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹ç¯‰ã‚’æ”¯æ´ã™ã‚‹äºˆå®šã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://tiger-ai-lab.github.io/EditReward/" target="_blank" rel="noopener noreferrer">https://tiger-ai-lab.github.io/EditReward/</a>


<br>HF:


<a href="https://huggingface.co/collections/TIGER-Lab/editreward-68ddf026ef9eb1510458abc6" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/TIGER-Lab/editreward-68ddf026ef9eb1510458abc6</a>


</p>
<p>ã“ã‚Œã¾ã§ã®ImageEditingç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€å¼±ã„Reward Modelã«ã‚ˆã£ã¦åˆæˆã•ã‚Œã‚‹ã‹ã€GPT-4oã‚„ä»–ã®VLMã«ã‚ˆã‚‹å“è³ªã®ä½ã„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚Šç”Ÿæˆã•ã‚Œã¦ãŠã‚Šã€é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå­˜åœ¨ã—ãªã„èª²é¡ŒãŒã‚ã£ãŸã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«å¤§è¦æ¨¡ãªImageEditingã®å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã€ImageEditingã«ç‰¹åŒ–ã—ãŸå ±é…¬ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹EditRewardã‚’å­¦ç¿’ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯äººé–“ã®å°‚é–€å®¶ã¨ã®agreementã«ãŠã„ã¦é«˜ã„(ã¨ã„ã†ã‚ˆã‚Šã‚Šbestã¨æ›¸ã„ã¦ã‚ã‚‹ï¼‰agreementã‚’ç¤ºã—ã€å®Ÿéš›ã«EditRewardã«ã‚ˆã£ã¦æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’filteringã—ã¦å­¦ç¿’ã—ãŸã‚‰å¤§ããªgainãŒã‚ã£ãŸã‚ˆã€ã¨ã„ã†æ„Ÿã˜ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Trustfulness.html" target="_blank" rel="noopener noreferrer">#Trustfulness</a>
<span class="issue_date">Issue Date: 2025-10-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3071" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning, Zhepei Wei+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMsã®çœŸå®Ÿæ€§ã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®å¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯TruthRLã‚’ææ¡ˆã€‚ä¸‰å€¤å ±é…¬ã‚’ç”¨ã„ã¦æ­£ã—ã„å›ç­”ã€å¹»è¦šã€abstentionã‚’åŒºåˆ¥ã—ã€ä¸ç¢ºå®Ÿãªå ´åˆã«ã¯æ§ãˆã‚‹ã“ã¨ã‚’ä¿ƒé€²ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€TruthRLã¯å¹»è¦šã‚’28.9%æ¸›å°‘ã•ã›ã€çœŸå®Ÿæ€§ã‚’21.1%å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã€å¾“æ¥ã®æ‰‹æ³•ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚æ­£ç¢ºã•ã¨çœŸå®Ÿæ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹é‡è¦æ€§ãŒå¼·èª¿ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/weizhepei/status/1973211813522317519?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä¸€èˆ¬çš„ã«åˆ©ç”¨ã•ã‚Œã‚‹Binary Rewardï¼ˆå›ç­”ãŒæ­£ã—ã‘ã‚Œã°1, ãã†ã§ãªã‘ã‚Œã°-1)ã§ã¯ãªãã€Ternary Reward<br>- å›ç­”ãŒæ­£ã—ã‘ã‚Œã°1<br>- ä¸ç¢ºå®Ÿã§ã‚ã‚Œã°0<br>- èª¤ã‚Šã§ã‚ã‚Œã°-1<br><br>ã‚’åˆ©ç”¨ã—GRPOã™ã‚‹ã“ã¨ã§ã€hallucinationãŒå‘ä¸Šã—ã€trustfulnessã‚‚æ”¹å–„ã™ã‚‹ã€ã¨ã„ã†è©±ãªæ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<span class="issue_date">Issue Date: 2025-10-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3065" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] HalluGuard: Evidence-Grounded Small Reasoning Models to Mitigate  Hallucinations in Retrieval-Augmented Generation, Loris Bergeron+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- HalluGuardã¯ã€LLMsã®å¹»è¦šã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®4Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å°å‹æ¨è«–ãƒ¢ãƒ‡ãƒ«ã§ã€æ–‡æ›¸-ä¸»å¼µãƒšã‚¢ã‚’åˆ†é¡ã—ã€è¨¼æ‹ ã«åŸºã¥ã„ãŸæ­£å½“åŒ–ã‚’ç”Ÿæˆã—ã¾ã™ã€‚FineWebã‹ã‚‰æ´¾ç”Ÿã—ãŸåˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã€å¥½ã¿ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ç”¨ã„ã¦ã€RAGTruthã‚µãƒ–ã‚»ãƒƒãƒˆã§84.0%ã®ãƒãƒ©ãƒ³ã‚¹ç²¾åº¦ã‚’é”æˆã—ã€MiniCheckã‚„Granite Guardianã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ã¾ã™ã€‚å…¨ä½“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯75.7%ã®ãƒãƒ©ãƒ³ã‚¹ç²¾åº¦ã‚’é”æˆã—ã€GPT-4oã¨åŒç­‰ã®æ€§èƒ½ã‚’æŒã¡ã¾ã™ã€‚HalluGuardã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯å…¬é–‹äºˆå®šã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1973611983992963435?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Document xã¨claim cãŒgivenãªã¨ãã«ã€ãã‚ŒãŒgroundingã•ã‚Œã¦ã„ã‚‹ã‹å¦ã‹ã‚’åˆ¤å®šã—ã€justificationã‚’ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’xã‚’å‚ç…§ã—ãªãŒã‚‰ç”Ÿæˆã™ã‚‹ã‚ˆã†ãªSLMãªæ¨¡æ§˜ã€‚ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã æœªå…¬é–‹ã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3064" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents, Zonghan Yang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢å·¥å­¦ï¼ˆSWEï¼‰ã¸ã®å¿œç”¨ãŒé€²ã‚“ã§ãŠã‚Šã€SWE-benchãŒé‡è¦ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ãªã£ã¦ã„ã‚‹ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®SWE-Agentãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨å˜ä¸€ã‚¿ãƒ¼ãƒ³ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¹æ‰‹æ³•ã¯ç›¸äº’æ’ä»–çš„ã§ã¯ãªãã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒåŠ¹ç‡çš„ãªSWE-Agentã®é©å¿œã‚’å¯èƒ½ã«ã™ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€Kimi-Devã¨ã„ã†ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®SWE LLMã‚’ç´¹ä»‹ã—ã€SWE-bench Verifiedã§60.4%ã‚’é”æˆã€‚è¿½åŠ ã®é©å¿œã«ã‚ˆã‚Šã€Kimi-Devã¯SWE-Agentã®æ€§èƒ½ã‚’48.6%ã«å¼•ãä¸Šã’ã€ç§»æ¤å¯èƒ½ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿç¾ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1973544152043495779?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Agentlessã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1847" target="_blank" rel="noopener noreferrer">Demystifying LLM-based Software Engineering Agents, Chunqiu Steven Xia+, FSE'25</a>
</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yang_zonghan/status/1977022913644839329?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãƒã‚¹ãƒˆã®ä¸­ã§OpenhandsãŒåŒãƒ¢ãƒ‡ãƒ«ã‚’å†…éƒ¨ã§æ¤œè¨¼ã—ã€Openhandsã®ç’°å¢ƒå†…ã§SWE Bench Verifiedã§è©•ä¾¡ã—ãŸçµæœã€ãƒ¬ãƒãƒ¼ãƒˆå†…ã§å ±å‘Šã•ã‚Œã¦ã„ã‚‹Acc. 60.4%ã¯é”æˆã§ããšã€17%ã«ç•™ã¾ã‚‹ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ãŸæ¨¡æ§˜ã€‚<br><br>Openhandsã®èª¬æ˜ã«ã‚ˆã‚‹ã¨Agentlessã¯æ±ºã‚ã‚‰ã‚ŒãŸå›ºå®šã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã¿ã‚’å®Ÿæ–½ã™ã‚‹æ çµ„ã¿ï¼ˆKimi Devã®å ´åˆã¯BugFixerã¨FileEditor)ã§ã‚ã‚Šã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§å®šç¾©ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã¯åŠ¹æœçš„ã«å®Ÿæ–½ã§ãã‚‹ãŒã€ãã‚Œã‚‰ä»¥å¤–ã®ã‚¿ã‚¹ã‚¯ã¯ãã‚‚ãã‚‚ã†ã¾ãã§ããªã„ã€‚SWE Agentç³»ã®ãƒ™ãƒ³ãƒã®ãƒã‚°fixã®æ–¹æ³•ã¯å¤§ããåˆ†ã‘ã¦Agentlikeï¼ˆã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’æ¢ç´¢ã—ãŸä¸Šã§ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹å½¢å¼ï¼‰ã€Fixed workflow like Agentless(å›ºå®šã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã¿ã‚’å®Ÿè¡Œã™ã‚‹å½¢å¼ï¼‰ã®2ç¨®é¡ãŒã‚ã‚Šã€Openhandsã¯å‰è€…ã€Kimi Devã¯å¾Œè€…ã®ä½ç½®ä»˜ã‘ã§ã‚ã‚‹ã€‚<br><br>å®Ÿéš›ã€ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã®Figure2ã¨Appendixã‚’è¦‹ã‚‹ã¨ã€File Localization+BugFixer+TestWriterã‚’å›ºå®šã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”¨ã„ã¦mid-trainingã—ã¦ãŠã‚Šã€è©•ä¾¡ã™ã‚‹éš›ã‚‚åŒæ§˜ã®ãƒãƒ¼ãƒã‚¹ãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã¨æ¨å¯Ÿã•ã‚Œã‚‹ï¼ˆã©ã“ã‹ã«æ˜ç¤ºçš„ãªè¨˜è¿°ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ï¼‰ã€‚<br>ä¸€æ–¹ã€Openhandsã§ã¯ã‚ˆã‚Šå®Ÿç’°å¢ƒã®é–‹ç™ºãƒ•ãƒ­ãƒ¼ã«è¿‘ã„ãƒãƒ¼ãƒã‚¹ï¼ˆe.g., ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’ç¢ºèªã—ã¦ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ææ¡ˆâ†’å®Ÿè¡Œå¯èƒ½ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãªã‚‰å®Ÿè¡Œâ†’ãã†ã§ãªã„ãªã‚‰ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®simulated responceã‚’å—ã‘å–ã‚‹â†’Agentã«çµæœã‚’ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯â†’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ...ï¼‰ã¨ã„ã£ãŸãƒãƒ¼ãƒã‚¹ã¨ãªã£ã¦ã„ã‚‹ã€‚<br><br>ã“ã®ã‚ˆã†ã«è©•ä¾¡ã‚’ã™ã‚‹éš›ã®ãƒãƒ¼ãƒã‚¹ãŒç•°ãªã‚‹ãŸã‚ã€åŒã˜ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å¯¾ã—ã¦ç•°ãªã‚‹æ€§èƒ½ãŒå ±å‘Šã•ã‚Œã‚‹ã€ã¨ã„ã†ã“ã¨ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>å˜ã«SWE Bench Verifiedã®Acc.ã ã‘ã‚’è¦‹ã¦ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã¶ã®ã§ã¯ãªãã€è©•ä¾¡ã•ã‚ŒãŸéš›ã®Evaluation HarnessãŒè‡ªåˆ†ãŸã¡ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«åˆã£ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ã“ã¨ãŒé‡è¦ã ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<p>å‚è€ƒ:<br><br>- Openhandsã®Evaluation Harness:


<a href="https://docs.all-hands.dev/openhands/usage/developers/evaluation-harness" target="_blank" rel="noopener noreferrer">https://docs.all-hands.dev/openhands/usage/developers/evaluation-harness</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-10-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3060" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Towards a Comprehensive Scaling Law of Mixture-of-Experts, Guoliang Zhao+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- Mixture-of-Experts (MoE)ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ä½“ç³»çš„ã«åˆ†æã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹5ã¤ã®è¦å› ã‚’ç‰¹å®šã€‚446ã®åˆ¶å¾¡å®Ÿé¨“ã‚’é€šã˜ã¦ã€åŒ…æ‹¬çš„ãªMoEã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’æ§‹ç¯‰ã—ã€æœ€é©ãªå°‚é–€å®¶ã®æ•°ã‚„å…±æœ‰æ¯”ç‡ãŒãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«ä¾å­˜ã—ãªã„ã“ã¨ã‚’ç¤ºã™ã€‚ææ¡ˆã™ã‚‹æ³•å‰‡ã¯ã€MoEãƒ¢ãƒ‡ãƒ«ã®è¨­è¨ˆã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹æŒ‡é‡ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1973247608647983513?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2296" target="_blank" rel="noopener noreferrer">[Paper Note] Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts
  Language Models, Changxin Tian+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<span class="issue_date">Issue Date: 2025-10-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3057" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation, Jiazheng Li+, arXiv'25, 2025.07</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã‚’ç”¨ã„ã¦ã€é›£ã—ã„æ¨è«–å•é¡Œã‚’åŠ¹æœçš„ã«è§£æ±ºã™ã‚‹ãŸã‚ã®æ‰‹æ³•QuestAã‚’ææ¡ˆã€‚è³ªå•ã®æ‹¡å¼µã‚’é€šã˜ã¦éƒ¨åˆ†çš„ãªè§£æ±ºç­–ã‚’å°å…¥ã—ã€å­¦ç¿’ä¿¡å·ã‚’æ”¹å–„ã€‚æ•°å­¦çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã§ã®RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦ã€pass@1ã¨pass@kã®ä¸¡æ–¹ã‚’å‘ä¸Šã•ã›ã€DeepScaleRã‚„OpenMath Nemotronã®æ¨è«–èƒ½åŠ›ã‚’å¼·åŒ–ã€‚1.5Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã§æ–°ãŸãªæœ€å…ˆç«¯çµæœã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hongzhou__lin/status/1973062785711190384?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RLã«ãŠã„ã¦ã€ç°¡å˜ãªå•é¡Œã¯ã™ãã«overfitã—ã€ã‹ã¤ã‚ˆã‚Šå›°é›£ãªå•é¡Œã‚’å­¦ç¿’ã™ã‚‹å¦¨ã’ã«ãªã‚‹ä¸€æ–¹ã§ã€å›°é›£ãªå•é¡Œã¯ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ãŒæ‚ªãã€ã‹ã¤rewardãŒsparseãªå ´åˆå­¦ç¿’ãŒéå¸¸ã«é…ã„ã¨ã„ã†å•é¡ŒãŒã‚ã£ãŸãŒã€å›°é›£ãªå•é¡Œã«å¯¾ã—ã¦ãƒ’ãƒ³ãƒˆã‚’ä¸ãˆã¦å­¦ç¿’ã•ã›ã‚‹ï¼ˆã‹ã¤ã€ãƒ¢ãƒ‡ãƒ«ãŒãƒ’ãƒ³ãƒˆã«ä¾å­˜ã›ãšã¨ã‚‚è§£ã‘ã‚‹ã‚ˆã†ã«ãªã£ã¦ããŸã‚‰å¾ã€…ã«ãƒ’ãƒ³ãƒˆã‚’æ¸›ã‚‰ã—ãƒ’ãƒ³ãƒˆã«éå‰°ã«ä¾å­˜ã™ã‚‹ã“ã¨ã‚’é˜²ãï¼‰ã“ã¨ã§ã€ç°¡å˜ãªå•é¡Œã«å¯¾ã—ã¦overfitã›ãšã«å›°é›£ãªå•é¡Œã«å¯¾ã™ã‚‹å­¦ç¿’åŠ¹ç‡ã‚‚ä¸ŠãŒã‚Šã€reasoningèƒ½åŠ›ã‚‚ãƒ–ãƒ¼ã‚¹ãƒˆã—ã¾ã—ãŸã€‚å›°é›£ãªå•é¡Œã¯ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ãŒè§£ãã®ã«è‹¦åŠ´ã™ã‚‹ã‚‚ã®ï¼ˆpass rateãŒã‚¼ãƒ­ã®ã‚‚ã®)ã‹ã‚‰è¦‹ã¤ã‘ã¾ã™ã€ï¼ˆãã—ã¦promptã§hintã‚’ä¸ãˆãŸä¸Šã§ã•ã‚‰ã«pass rateãŒä½ã„ã‚‚ã®ã‚’ä½¿ã†æ¨¡æ§˜ï¼Ÿï¼‰ã¨ã„ã£ãŸè©±ãªæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/671a95e0-bfd8-478e-b73c-25af4d21b6df" alt="image" loading="lazy"></p>
<p>ãƒ’ãƒ³ãƒˆã‚’ä½¿ã£ã¦ãªã‚‹å•é¡Œã®é›£æ˜“åº¦ã‚’èª¿æ•´ã—ãªãŒã‚‰RLã™ã‚‹ç ”ç©¶ã¯ä»¥ä¸‹ã‚‚å­˜åœ¨ã™ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2757" target="_blank" rel="noopener noreferrer">[Paper Note] Staying in the Sweet Spot: Responsive Reasoning Evolution via
  Capability-Adaptive Hint Scaffolding, Ziheng Li+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<span class="issue_date">Issue Date: 2025-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3047" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Pretraining Large Language Models with NVFP4, NVIDIA+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€NVFP4ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ç”¨ã„ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å®‰å®šã‹ã¤æ­£ç¢ºãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã€‚ãƒ©ãƒ³ãƒ€ãƒ ãƒãƒ€ãƒãƒ¼ãƒ‰å¤‰æ›ã‚„äºŒæ¬¡å…ƒé‡å­åŒ–ã‚¹ã‚­ãƒ¼ãƒ ã‚’å–ã‚Šå…¥ã‚Œã€åã‚Šã®ãªã„å‹¾é…æ¨å®šã‚’å®Ÿç¾ã€‚10å…†ãƒˆãƒ¼ã‚¯ãƒ³ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šã€FP8ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã—ã€ç‹­ã„ç²¾åº¦ã®LLMãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹é€²å±•ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1972869149102858441?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1975344045754097685?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3045" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RecoWorld: Building Simulated Environments for Agentic Recommender  Systems, Fei Liu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- RecoWorldã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®ãŸã‚ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒã‚’ææ¡ˆã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å½±éŸ¿ã‚’ä¸ãˆãšã«å­¦ç¿’ã§ãã‚‹å ´ã‚’æä¾›ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ãŒãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¿æŒã‚’æœ€å¤§åŒ–ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®åå¿œã‚’åŸºã«æŒ‡ç¤ºã‚’ç”Ÿæˆã—ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã¯ãã‚Œã«å¿œã˜ã¦æ¨å¥¨ã‚’é©å¿œã•ã›ã‚‹å‹•çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã‚’å½¢æˆã—ã¾ã™ã€‚ã•ã‚‰ã«ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã‚„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¡¨ç¾ã‚’æ¢æ±‚ã—ã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å¼·åŒ–å­¦ç¿’ã‚’é€šã˜ã¦æˆ¦ç•¥ã‚’æ´—ç·´ã•ã›ã‚‹æ–¹æ³•ã‚’è­°è«–ã—ã¾ã™ã€‚RecoWorldã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå…±åŒã§ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸæƒ…å ±ã‚’å½¢æˆã™ã‚‹æ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’æç¤ºã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1972876133629862358?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/Test-time%20Learning.html" target="_blank" rel="noopener noreferrer">#Test-time Learning</a>
<span class="issue_date">Issue Date: 2025-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3041" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory, Siru Ouyang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- ReasoningBankã¨ã„ã†æ–°ã—ã„ãƒ¡ãƒ¢ãƒªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæˆåŠŸä½“é¨“ã¨å¤±æ•—ä½“é¨“ã‹ã‚‰æ¨è«–æˆ¦ç•¥ã‚’æŠ½å‡ºã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ãƒ†ã‚¹ãƒˆæ™‚ã«ã¯é–¢é€£ãƒ¡ãƒ¢ãƒªã‚’æ´»ç”¨ã—ã€å­¦ã³ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ã•ã‚‰ã«ã€ãƒ¡ãƒ¢ãƒªã‚’æ„è­˜ã—ãŸãƒ†ã‚¹ãƒˆæ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆMaTTSï¼‰ã‚’å°å…¥ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½“é¨“ã‚’å¤šæ§˜åŒ–ãƒ»æ‹¡å¤§ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¦ã‚§ãƒ–ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ã‚„ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ—¢å­˜ã®ãƒ¡ãƒ¢ãƒªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä¸Šå›ã‚‹åŠ¹æœã¨åŠ¹ç‡ã‚’å®Ÿç¾ã€‚ãƒ¡ãƒ¢ãƒªé§†å‹•ã®çµŒé¨“ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’æ–°ãŸãªæ¬¡å…ƒã¨ã—ã¦ç¢ºç«‹ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è‡ªå·±é€²åŒ–ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1972870229463355677?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ¡ãƒ¢ãƒªã‚’è‰¯è³ªãªã‚‚ã®ã«æ›´æ–°ã€è“„ç©ã—ç¶šã‘ã‚‹ã“ã¨ã§æ€§èƒ½ãŒã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã®ã§ã‚ã‚Œã°ã€æ–°ãŸãªtest-time scalingã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã«ãªã‚Šãã†ã€‚<br><br>ã¨æ€ã£ãŸãŒã–ã£ãã‚Šèª­ã‚“ã§ã¿ã‚‹ã¨æœ¬ç ”ç©¶ã§ã¯ã“ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã®ã“ã¨ã‚’Test-Time Learningã¨å‘¼ç§°ã—ã¦ã„ã‚‹ï¼ˆå…ˆè¡Œç ”ç©¶ãŒï¼’ã¤å¼•ç”¨ã•ã‚Œã¦ã„ã‚‹ãŒã–ã£ã¨è¦‹ãŸé™ã‚Šã§ã¯ä¸¡è€…ã¯ãã†è¨€ã£ãŸå‘¼ç§°ã¯ã—ã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆãŸï¼‰ã€‚<br>ã™ãªã‚ã¡ã€ã‚¯ã‚¨ãƒªã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒåˆ°é”ã—ãŸæ™‚ã«å°†æ¥ã®ã‚¯ã‚¨ãƒªã‚’è¦‹ã‚‹ã“ã¨ã¯ã§ããšã«ã€éå»ã®ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹trajectoryã‚„ã€self-verificationãªã©ã«ã‚ˆã£ã¦ã®ã¿ãƒ©ãƒ™ãƒ«ç„¡ã—ã§è‡ªå·±é€²åŒ–ã—ã¦ã„ããƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã®ã“ã¨ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3052" target="_blank" rel="noopener noreferrer">[Paper Note] M+: Extending MemoryLLM with Scalable Long-Term Memory, Yu Wang+, ICML'25, 2025.02</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Entropy.html" target="_blank" rel="noopener noreferrer">#Entropy</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3037" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Quantile Advantage Estimation for Entropy-Safe Reasoning, Junkang Wu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ã«ãŠã‘ã‚‹æ¤œè¨¼å¯èƒ½ãªå ±é…¬ï¼ˆRLVRï¼‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼å´©å£Šã¨çˆ†ç™ºã®å•é¡Œã«ç›´é¢ã™ã‚‹ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€åˆ†ä½ã‚¢ãƒ‰ãƒãƒ³ãƒ†ãƒ¼ã‚¸æ¨å®šï¼ˆQAEï¼‰ã‚’ææ¡ˆã—ã€å¹³å‡ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’K-åˆ†ä½ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«ç½®ãæ›ãˆã‚‹ã€‚QAEã¯ã€é›£ã—ã„ã‚¯ã‚¨ãƒªã§ç¨€ãªæˆåŠŸã‚’å¼·åŒ–ã—ã€ç°¡å˜ãªã‚¯ã‚¨ãƒªã§å¤±æ•—ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã®å®‰å®šåŒ–ã¨ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆå‰²ã‚Šå½“ã¦ã®ã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–ãŒå®Ÿç¾ã—ã€AIME 2024/2025ãŠã‚ˆã³AMC 2023ã§ã®æ€§èƒ½å‘ä¸ŠãŒç¢ºèªã•ã‚ŒãŸã€‚çµæœã¯ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³è¨­è¨ˆãŒRLVRã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ãŠã„ã¦é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1972517130655732034?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1972575804501672446?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ActivationFunction.html" target="_blank" rel="noopener noreferrer">#ActivationFunction</a>
<a class="button" href="articles/DyingReLU.html" target="_blank" rel="noopener noreferrer">#DyingReLU</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3036" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Stochastic activations, Maria Lomeli+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- ç¢ºç‡çš„æ´»æ€§åŒ–ã‚’å°å…¥ã—ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰å±¤ã§éç·šå½¢é–¢æ•°ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã€‚ç‰¹ã«ã€ãƒ™ãƒ«ãƒŒãƒ¼ã‚¤åˆ†å¸ƒã«åŸºã¥ãSILUã¾ãŸã¯RELUã‚’é¸æŠã—ã€æœ€é©åŒ–å•é¡Œã‚’å›é¿ã€‚ãƒ—ãƒ¬ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ç¢ºç‡çš„æ´»æ€§åŒ–ã‚’ä½¿ç”¨ã—ã€æ¨è«–æ™‚ã«RELUã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§FLOPsã‚’å‰Šæ¸›ã—ã€é€Ÿåº¦å‘ä¸Šã‚’å®Ÿç¾ã€‚ã¾ãŸã€ç”Ÿæˆã«ãŠã„ã¦ã‚‚ç¢ºç‡çš„æ´»æ€§åŒ–ã‚’è©•ä¾¡ã—ã€ãƒ†ã‚­ã‚¹ãƒˆã®å¤šæ§˜æ€§ã‚’åˆ¶å¾¡ã™ã‚‹ä»£æ›¿æ‰‹æ®µã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1972649914233389062?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3031" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SIM-CoT: Supervised Implicit Chain-of-Thought, Xilin Wei+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æš—é»™ã®Chain-of-Thought (CoT) ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€LLMsã«ãŠã‘ã‚‹æ˜ç¤ºçš„ãªCoTæ¨è«–ã®åŠ¹ç‡çš„ãªä»£æ›¿æ‰‹æ®µã§ã™ãŒã€æ€§èƒ½ã®ä¸å®‰å®šæ€§ãŒèª²é¡Œã§ã™ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€SIM-CoTã‚’ææ¡ˆã—ã€ã‚¹ãƒ†ãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã®ç›£è¦–ã‚’å°å…¥ã—ã¦æ½œåœ¨çš„ãªæ¨è«–ç©ºé–“ã‚’å®‰å®šåŒ–ã—ã¾ã™ã€‚è£œåŠ©ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ç”¨ã„ã¦æš—é»™ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ˜ç¤ºçš„ãªæ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã«æ•´åˆã•ã›ã€è§£é‡ˆå¯èƒ½æ€§ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚SIM-CoTã¯ã€Coconutã‚„CODIã§ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€æ˜ç¤ºçš„CoTã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€ãƒˆãƒ¼ã‚¯ãƒ³åŠ¹ç‡ã‚‚æ”¹å–„ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1972442919354208723?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/interactive.html" target="_blank" rel="noopener noreferrer">#interactive</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3021" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Interactive Recommendation Agent with Active User Commands, Jiakai Tang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å¾“æ¥ã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã¯å—å‹•çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ä¾å­˜ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã‚’æ‰ãˆã‚‰ã‚Œãªã„ãŸã‚ã€å—œå¥½ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ãŒå›°é›£ã§ã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚£ãƒ¼ãƒ‰ï¼ˆIRFï¼‰ã‚’å°å…¥ã—ã€è‡ªç„¶è¨€èªã‚³ãƒãƒ³ãƒ‰ã«ã‚ˆã‚‹èƒ½å‹•çš„ãªåˆ¶å¾¡ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚RecBotã¨ã„ã†äºŒé‡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é–‹ç™ºã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å—œå¥½ã‚’æ§‹é€ åŒ–ã—ã€ãƒãƒªã‚·ãƒ¼èª¿æ•´ã‚’è¡Œã†ã€‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¼·åŒ–çŸ¥è­˜è’¸ç•™ã‚’ç”¨ã„ã¦åŠ¹ç‡çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã€å®Ÿé¨“ã«ã‚ˆã‚Šãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦ã¨ãƒ“ã‚¸ãƒã‚¹æˆæœã®æ”¹å–„ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1972370522248745122?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ABãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã‚ˆã†ãªã®ã§ä¿¡ã´ã‚‡ã†æ€§é«˜ã‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Legal.html" target="_blank" rel="noopener noreferrer">#Legal</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3005" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CLaw: Benchmarking Chinese Legal Knowledge in Large Language Models - A  Fine-grained Corpus and Reasoning Analysis, Xinzhe Xu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æ³•çš„æ–‡æ›¸ã®åˆ†æã«ãŠã„ã¦ã€LLMã®ä¿¡é ¼æ€§ãŒæãªã‚ã‚Œã‚‹å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯CLawã‚’ææ¡ˆã€‚CLawã¯ã€ä¸­å›½ã®æ³•ä»¤ã‚’ç¶²ç¾…ã—ãŸè©³ç´°ãªã‚³ãƒ¼ãƒ‘ã‚¹ã¨ã€ã‚±ãƒ¼ã‚¹ãƒ™ãƒ¼ã‚¹ã®æ¨è«–ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‹ã‚‰æ§‹æˆã•ã‚Œã€æ³•çš„çŸ¥è­˜ã®å®Ÿéš›ã®å¿œç”¨ã‚’è©•ä¾¡ã€‚å®Ÿè¨¼çš„è©•ä¾¡ã§ã¯ã€ç¾ä»£ã®LLMãŒæ³•çš„è¦å®šã®æ­£ç¢ºãªå–å¾—ã«è‹¦åŠ´ã—ã¦ã„ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ä¿¡é ¼ã§ãã‚‹æ³•çš„æ¨è«–ã«ã¯æ­£ç¢ºãªçŸ¥è­˜ã®å–å¾—ã¨å¼·åŠ›ãªæ¨è«–èƒ½åŠ›ã®çµ±åˆãŒå¿…è¦ã§ã‚ã‚‹ã¨ä¸»å¼µã€‚ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹LLMæ¨è«–ã®é€²å±•ã«å‘ã‘ãŸé‡è¦ãªæ´å¯Ÿã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1971734059060527283?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä¸­å›½èªã«ã‚ˆã‚‹ä¸­å›½ã®æ³•å¾‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€legalåˆ†é‡ã«ãŠã„ã¦ã¯ã€ã‚ˆã‚Šç´°ã‹ã„ç²’åº¦ã®çŸ¥è­˜ã‚’æ‰ãˆã‚‰ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ãŒæ¨è«–ã‚‚çš„ç¢ºã«ã§ãã€æ¨è«–èƒ½åŠ›ã§ãã‚Œã¯è£œãˆãã†ã¨ã„ã†æ„Ÿã˜ãªæ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<span class="issue_date">Issue Date: 2025-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2997" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Expanding Reasoning Potential in Foundation Model by Learning Diverse  Chains of Thought Patterns, Xuemiao Zhang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡æ¨è«–ãƒ¢ãƒ‡ãƒ«ã®é€²å±•ã¯å¼·åŒ–å­¦ç¿’ã«ã‚ˆã£ã¦ä¿ƒé€²ã•ã‚Œã€CoTãƒ‡ãƒ¼ã‚¿ã®åˆ©ç”¨ãŒæ¨è«–ã®æ·±ã•ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€ã©ã®ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ãŒæœ€ã‚‚åŠ¹æœçš„ã‹ã¯æœªè§£æ±ºã®å•é¡Œã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ¨è«–ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’ç‹¬ç«‹ã—ãŸè©¦è¡Œã®æ•°ã®é€†æ•°ã¨ã—ã¦å®šç¾©ã—ã€ã“ã‚Œã‚’æ‹¡å¼µã™ã‚‹ãŸã‚ã«é«˜ä¾¡å€¤ã®æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”¨ã„ãŸå¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ã®åˆ©ç”¨ã‚’ææ¡ˆã€‚å…·ä½“çš„ã«ã¯ã€CoTã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‹ã‚‰åŸå­çš„ãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½è±¡åŒ–ã—ã€ã‚³ã‚¢ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã€‚äºŒé‡ç²’åº¦ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ã¦é«˜ä¾¡å€¤ã®CoTãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹ç‡çš„ã«é¸æŠã—ã€ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚10Bãƒˆãƒ¼ã‚¯ãƒ³ã®CoTPãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚Šã€85A6B Mixture-of-Expertsãƒ¢ãƒ‡ãƒ«ã¯AIME 2024ãŠã‚ˆã³2025ã§9.58%ã®æ”¹å–„ã‚’é”æˆã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1971461991039631691?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç´°ã‹ã„ã¨ã“ã‚ã¯èª­ã‚ã¦ã„ãªã„ã®ã ãŒã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ä¸­ã‹ã‚‰é«˜å“è³ªãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŒã¤ã‚‚ã®ã‚’é¸ã‚“ã§å­¦ç¿’ã«ä½¿ã„ãŸã„ã¨ã„ã†ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã€‚ãã®ãŸã‚ã«ã¾ãšä¾¡å€¤ã®é«˜ã„æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å«ã‚€ã‚³ã‚¢ã‚»ãƒƒãƒˆã‚’ä½œã‚Šã€ã‚³ã‚¢ã‚»ãƒƒãƒˆã¨é¡ä¼¼ã—ãŸæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„ã€æ¨è«–ä¸­ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼åˆ—ã‚’æŒã¤ã‚µãƒ³ãƒ—ãƒ«ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åé›†ã™ã‚‹ã¿ãŸã„ãªè©±ãªæ¨¡æ§˜ã€‚é¡ä¼¼åº¦ã¯é‡ã¿ã¤ãDynamic Time Warping (DTW)ã§ã€åŸå§‹çš„ãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç³»åˆ—ã¨ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ç³»åˆ—ã®DTWã®ç·šå‹çµåˆã«ã‚ˆã£ã‚æ±‚ã‚ã‚‹ã€‚åŸå§‹çš„ãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ã€CoT sequenceä¸­ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼åˆ—ã¯DeepSeek-V3ã«ã‚ˆã£ã¦ç”Ÿæˆã™ã‚‹ã€‚<br><br>ã‚³ã‚¢ã‚»ãƒƒãƒˆã‚’ä½œã‚‹ãŸã‚ã«ã¯ã€å•é¡Œã‚¿ã‚¤ãƒ—ã‚„å•é¡Œã®é›£æ˜“åº¦ã«åŸºã¥ã„ã¦äººæ‰‹ã§å•é¡Œã‚’é¸ã³ã€ãã‚Œã‚‰ã«å¯¾ã—ã¦strong reasoning modelã§CoTã‚’ç”Ÿæˆã€‚å„CoTã«å¯¾ã—ã¦ï¼ˆãŠãã‚‰ãï¼‰DeepSeek-V3ã§reasoningã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã¯åŸå§‹çš„ãªCoTãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç³»åˆ—ã§æ§‹æˆã•ã‚Œã‚‹ï¼‰ã‚’ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ã€å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾ã—ã¦TF-IDFã«ã‚ˆã£ã¦é‡è¦åº¦ã‚’æ±ºå®šã™ã‚‹ã€‚æœ€çµ‚çš„ã«ã€å•é¡Œã«æ­£ç­”ã—ã¦ã„ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã«ã¤ã„ã¦ã€äººæ‰‹ã§é«˜å“è³ªã§discriminativeãªCoTãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŒã¤ã‚‚ã®ã‚’é¸æŠã—ã€å„CoTãƒ‘ã‚¿ãƒ¼ãƒ³ã«é‡ã¿ã‚’ã¤ã‘ãŸä¸Šã§ã‚³ã‚¢ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ãŸã€ã¿ãŸã„ãªæ„Ÿã˜ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Ensemble.html" target="_blank" rel="noopener noreferrer">#Ensemble</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Best-of-N.html" target="_blank" rel="noopener noreferrer">#Best-of-N</a>
<span class="issue_date">Issue Date: 2025-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2992" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Best-of-$\infty$ -- Asymptotic Performance of Test-Time Compute, Junpei Komiyama+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã‘ã‚‹Best-of-$N$ã‚’å¤šæ•°æ±ºã«åŸºã¥ã„ã¦ç ”ç©¶ã—ã€$N \to \infty$ã®é™ç•Œï¼ˆBest-of-$\infty$ï¼‰ã‚’åˆ†æã€‚ç„¡é™ã®ãƒ†ã‚¹ãƒˆæ™‚é–“ã‚’å¿…è¦ã¨ã™ã‚‹å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€å›ç­”ã®ä¸€è‡´ã«åŸºã¥ãé©å¿œç”Ÿæˆã‚¹ã‚­ãƒ¼ãƒ ã‚’ææ¡ˆã—ã€æ¨è«–æ™‚é–“ã‚’åŠ¹ç‡çš„ã«é…åˆ†ã€‚ã•ã‚‰ã«ã€è¤‡æ•°ã®LLMã®é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’æ‹¡å¼µã—ã€æœ€é©ãªé‡ã¿ä»˜ã‘ã‚’æ··åˆæ•´æ•°ç·šå½¢è¨ˆç”»ã¨ã—ã¦å®šå¼åŒ–ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æœ‰åŠ¹æ€§ã‚’å®Ÿè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://jkomiyama.github.io/bestofinfty/" target="_blank" rel="noopener noreferrer">https://jkomiyama.github.io/bestofinfty/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jkomiyama_/status/1971408925464654026?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="articles/WorldModels.html" target="_blank" rel="noopener noreferrer">#WorldModels</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2986" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Embodied AI: From LLMs to World Models, Tongtong Feng+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å…·ç¾åŒ–ã•ã‚ŒãŸAIã¯AGIé”æˆã®ãŸã‚ã®çŸ¥çš„ã‚·ã‚¹ãƒ†ãƒ ã§ã‚ã‚Šã€LLMsã¨WMsã®é€²å±•ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€å…·ç¾åŒ–ã•ã‚ŒãŸAIã®æ­´å²ã‚„æŠ€è¡“ã€ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ç´¹ä»‹ã—ã€LLMsã¨WMsã®å½¹å‰²ã‚’è©³ç´°ã«æ¤œè¨ã€‚MLLM-WMé§†å‹•ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å¿…è¦æ€§ã‚’è«–ã˜ã€ç‰©ç†ä¸–ç•Œã§ã®è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã®å®Ÿç¾ã«ãŠã‘ã‚‹æ„ç¾©ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚å…·ç¾åŒ–ã•ã‚ŒãŸAIã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ä»Šå¾Œã®ç ”ç©¶æ–¹å‘ã«ã¤ã„ã¦ã‚‚è§¦ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1971219902821519778?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1971423253135753299?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2980" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Thinking Augmented Pre-training, Liang Wang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æ€è€ƒã®è»Œè·¡ã‚’ç”¨ã„ã¦ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ‹¡å¼µã™ã‚‹ã€ŒThinking augmented Pre-Trainingï¼ˆTPTï¼‰ã€ã‚’ææ¡ˆã—ã€LLMã®ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã‚’å‘ä¸Šã€‚TPTã¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹æœçš„ã«å¢—åŠ ã•ã›ã€é«˜å“è³ªãªãƒˆãƒ¼ã‚¯ãƒ³ã®å­¦ç¿’ã‚’å®¹æ˜“ã«ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€TPTãŒLLMã®æ€§èƒ½ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã€ç‰¹ã«3Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã§æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ€§èƒ½ã‚’10%ä»¥ä¸Šæ”¹å–„ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1971086346942022026?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ï¼ˆæ–œã‚èª­ã¿ã—ã‹ã¾ã ã§ãã¦ã„ãªã„ãŒï¼‰2ç¯€ã«å­˜åœ¨ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”¨ã„ã¦ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå…¨ä½“ã‚’contextã¨ã—ã¦ä¸ãˆã€contextä¸­ã«å­˜åœ¨ã™ã‚‹è¤‡é›‘ãªæƒ…å ±ã«é–¢ã—ã¦æ·±ã„åˆ†æã‚’ã™ã‚‹ã‚ˆã†ã«thinking traceã‚’ç”Ÿæˆã—ã€ç”Ÿæˆã—ãŸtrace tã‚’concatã—ã¦next token predictionã§äº‹å‰å­¦ç¿’ã™ã‚‹æ¨¡æ§˜ã€‚æ•°å­¦ãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼ã—äº‹å‰å­¦ç¿’ãŒ3å€ãƒˆãƒ¼ã‚¯ãƒ³é‡ vs. downstreamã‚¿ã‚¹ã‚¯ï¼ˆGSM8K, MATH)æ€§èƒ½ã®è¦³ç‚¹åŠ¹ç‡çš„ã«ãªã£ãŸã ã‹ã§ãªãï¼ˆã“ã‚Œã¯äº‹å¾Œå­¦ç¿’ã®å…ˆå–ã‚Šã‚’ã—ã¦ã„ã‚‹ã¿ãŸã„ãªã‚‚ã®ãªæ°—ãŒã™ã‚‹ã®ã§ãã†ãªã‚‹ã ã‚ã†ãªã¨ã„ã†æ°—ãŒã™ã‚‹ï¼‰ã€ãŠãªã˜ãƒˆãƒ¼ã‚¯ãƒ³é‡ã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’SFTã—ãŸå ´åˆã§ã‚‚ã€ææ¡ˆæ‰‹æ³•ã®æ–¹ãŒæ€§èƒ½ãŒè‰¯ã‹ã£ãŸæ¨¡æ§˜ï¼ˆTable2, ã“ã£ã¡ã®æ–¹ãŒå€‹äººçš„ã«ã¯é‡è¦ãªæ°—ãŒã—ã¦ã„ã‚‹)ã€‚</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1971334199555784807?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2977" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] UMoE: Unifying Attention and FFN with Shared Experts, Yuanhang Yang+, arXiv'25, 2025.05</a>
<span class="snippet"><span>GPT Summary</span>- Sparse Mixture of Experts (MoE) ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€Transformer ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ãŠã„ã¦æœ‰æœ›ãªæ‰‹æ³•ã§ã‚ã‚Šã€æ³¨æ„å±¤ã¸ã®æ‹¡å¼µãŒæ¢æ±‚ã•ã‚Œã¦ã„ã¾ã™ãŒã€æ—¢å­˜ã®æ³¨æ„ãƒ™ãƒ¼ã‚¹ã® MoE å±¤ã¯æœ€é©ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚æœ¬è«–æ–‡ã§ã¯ã€æ³¨æ„å±¤ã¨ FFN å±¤ã® MoE è¨­è¨ˆã‚’çµ±ä¸€ã—ã€æ³¨æ„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®å†å®šå¼åŒ–ã‚’è¡Œã„ã€FFN æ§‹é€ ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã™ã€‚ææ¡ˆã™ã‚‹UMoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€æ³¨æ„ãƒ™ãƒ¼ã‚¹ã® MoE å±¤ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’é”æˆã—ã€åŠ¹ç‡çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å…±æœ‰ã‚’å®Ÿç¾ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nathancgy4/status/1970887450739281953?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Mixture of Attention Heads (MoA)ã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3110" target="_blank" rel="noopener noreferrer">[Paper Note] Mixture of Attention Heads: Selecting Attention Heads Per Token, Xiaofeng Zhang+, EMNLP'22, 2022.10</a>
</p>
<p>ã“ã®å›³ãŒã‚ã‹ã‚Šã‚„ã™ã„ã€‚å¾Œã»ã©èª¬æ˜ã‚’è¿½è¨˜ã™ã‚‹ã€‚ã–ã£ãã‚Šè¨€ã†ã¨ã€MoAã‚’å‰æã¨ã—ãŸã¨ãã«ã€æœ€å¾Œã®å‡ºåŠ›ã®å¤‰æ›éƒ¨åˆ†VW_oã‚’FFNã«ã‚ˆã‚‹å¤‰æ›ï¼ˆã¤ã¾ã‚ŠFFN Expertsã®ä¸€ã¤ï¼‰ã¨ã¿ãªã—ã¦ã€self-attentionã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ··ãœåˆã‚ã›ã‚‹ã¨ã„ã†è¶£æ—¨ã‚’å¤±ã‚ãªã„ç¯„å›²ã§è¨ˆç®—é †åºã‚’èª¿æ•´ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒŸãƒƒã‚¯ã‚¹ã™ã‚‹éƒ¨åˆ†ã‚’å…ˆã«æŒã£ã¦ãã‚‹ï¼‰ã™ã‚‹ã¨ã€FFNã®MoEã¨MoAã¯åŒã˜æ çµ„ã¿ã§æ‰±ãˆã‚‹ãŸã‚ã€expertsã‚’å…±æœ‰ã§ãã¦ãƒ¡ãƒ¢ãƒªã‚’å‰Šæ¸›ã§ãã€ã‹ã¤MoAã«ã‚ˆã£ã¦å¿…è¦ãªç®‡æ‰€ã®ã¿ã«attendã™ã‚‹èƒ½åŠ›ãŒé«˜ã¾ã‚Šæ€§èƒ½ã‚‚ä¸ŠãŒã‚Šã¾ã™ã€ã¿ãŸã„ãªè©±ã«è¦‹ãˆã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/44ba6bee-d1fa-4385-a4c6-2c937cc15ea5" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/248e1bc5-6c14-4b2d-9aed-c1d7359c605e" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/SpeculativeDecoding.html" target="_blank" rel="noopener noreferrer">#SpeculativeDecoding</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2976" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Speculative Decoding with Lookahead Reasoning, Yichao Fu+, arXiv'25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- Lookahead Reasoningã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€æ¨è«–ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³ãƒ‡ã‚³ãƒ¼ãƒ‰é€Ÿåº¦ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚è»½é‡ãªãƒ‰ãƒ©ãƒ•ãƒˆãƒ¢ãƒ‡ãƒ«ãŒå°†æ¥ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ææ¡ˆã—ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ãŒä¸€åº¦ã®ãƒãƒƒãƒå‡¦ç†ã§å±•é–‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã®æ¨æ¸¬ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆSDï¼‰ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’1.4å€ã‹ã‚‰2.1å€ã«æ”¹å–„ã—ã€å›ç­”ã®è³ªã‚’ç¶­æŒã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haozhangml/status/1970607910846898488?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ContextAware.html" target="_blank" rel="noopener noreferrer">#ContextAware</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<a class="button" href="articles/Personality.html" target="_blank" rel="noopener noreferrer">#Personality</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2974" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CAPE: Context-Aware Personality Evaluation Framework for Large Language   Models, Jivnesh Sandhan+, EMNLP'25 Findings, 2025.08</a>
<span class="snippet"><span>GPT Summary</span>- å¿ƒç†æ¸¬å®šãƒ†ã‚¹ãƒˆã‚’LLMsã®è©•ä¾¡ã«é©ç”¨ã™ã‚‹ãŸã‚ã€æ–‡è„ˆå¯¾å¿œãƒ‘ãƒ¼ã‚½ãƒŠãƒªãƒ†ã‚£è©•ä¾¡ï¼ˆCAPEï¼‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚å¾“æ¥ã®å­¤ç«‹ã—ãŸè³ªå•ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‹ã‚‰ã€ä¼šè©±ã®å±¥æ­´ã‚’è€ƒæ…®ã—ãŸå¿œç­”ã®ä¸€è²«æ€§ã‚’å®šé‡åŒ–ã™ã‚‹æ–°æŒ‡æ¨™ã‚’å°å…¥ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ä¼šè©±å±¥æ­´ãŒå¿œç­”ã®ä¸€è²«æ€§ã‚’é«˜ã‚ã‚‹ä¸€æ–¹ã§ã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒªãƒ†ã‚£ã®å¤‰åŒ–ã‚‚å¼•ãèµ·ã“ã™ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚ç‰¹ã«GPTãƒ¢ãƒ‡ãƒ«ã¯å …ç‰¢æ€§ã‚’ç¤ºã—ã€Gemini-1.5-Flashã¨Llama-8Bã¯æ„Ÿå—æ€§ãŒé«˜ã„ã€‚CAPEã‚’ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«é©ç”¨ã™ã‚‹ã¨ã€ä¸€è²«æ€§ãŒæ”¹å–„ã•ã‚Œäººé–“ã®åˆ¤æ–­ã¨ä¸€è‡´ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1970720101306679436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/LowResource.html" target="_blank" rel="noopener noreferrer">#LowResource</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2970" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SSA-COMET: Do LLMs Outperform Learned Metrics in Evaluating MT for   Under-Resourced African Languages?, Senyu Li+, EMNLP'25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¢ãƒ•ãƒªã‚«ã®è¨€èªã«ãŠã‘ã‚‹æ©Ÿæ¢°ç¿»è¨³ã®å“è³ªè©•ä¾¡ã¯ä¾ç„¶ã¨ã—ã¦èª²é¡Œã§ã‚ã‚Šã€æ—¢å­˜ã®æŒ‡æ¨™ã¯é™ã‚‰ã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€13ã®ã‚¢ãƒ•ãƒªã‚«è¨€èªãƒšã‚¢ã‚’å¯¾è±¡ã¨ã—ãŸå¤§è¦æ¨¡ãªäººé–“æ³¨é‡ˆä»˜ãMTè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒSSA-MTEã€ã‚’ç´¹ä»‹ã—ã€63,000ä»¥ä¸Šã®æ–‡ãƒ¬ãƒ™ãƒ«ã®æ³¨é‡ˆã‚’å«ã‚“ã§ã„ã¾ã™ã€‚ã“ã‚Œã«åŸºã¥ãã€æ”¹è‰¯ã•ã‚ŒãŸè©•ä¾¡æŒ‡æ¨™ã€ŒSSA-COMETã€ã¨ã€ŒSSA-COMET-QEã€ã‚’é–‹ç™ºã—ã€æœ€å…ˆç«¯ã®LLMã‚’ç”¨ã„ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã—ã¾ã—ãŸã€‚å®Ÿé¨“çµæœã¯ã€SSA-COMETãŒAfriCOMETã‚’ä¸Šå›ã‚Šã€ç‰¹ã«ä½ãƒªã‚½ãƒ¼ã‚¹è¨€èªã§ç«¶äº‰åŠ›ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã™ã¹ã¦ã®ãƒªã‚½ãƒ¼ã‚¹ã¯ã‚ªãƒ¼ãƒ—ãƒ³ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1970720101306679436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2969" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Multilingual Language Model Pretraining using Machine-translated Data, Jiayi Wang+, EMNLP'25, 2025.02</a>
<span class="snippet"><span>GPT Summary</span>- é«˜ãƒªã‚½ãƒ¼ã‚¹è¨€èªã®è‹±èªã‹ã‚‰ç¿»è¨³ã—ãŸé«˜å“è³ªãªãƒ†ã‚­ã‚¹ãƒˆãŒã€å¤šè¨€èªLLMsã®äº‹å‰å­¦ç¿’ã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚è‹±èªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆFineWeb-Eduã‚’9è¨€èªã«ç¿»è¨³ã—ã€17å…†ãƒˆãƒ¼ã‚¯ãƒ³ã®TransWebEduã‚’ä½œæˆã€‚1.3Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®TransWebLLMã‚’äº‹å‰å­¦ç¿’ã—ã€éè‹±èªã®æ¨è«–ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’é”æˆã€‚ç‰¹ã«ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ã„ãã¤ã‹ã®è¨€èªã§æ–°ãŸãªæœ€å…ˆç«¯ã‚’é”æˆã€‚ã‚³ãƒ¼ãƒ‘ã‚¹ã€ãƒ¢ãƒ‡ãƒ«ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1970720101306679436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2968" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reinforcement Learning on Pre-Training Data, Siheng Li+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- RLPTã¨ã„ã†æ–°ã—ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’å°å…¥ã—ã€LLMsã®æœ€é©åŒ–ã‚’å›³ã‚‹ã€‚å¾“æ¥ã®æ–¹æ³•ã«ä¾å­˜ã›ãšã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç›´æ¥å ±é…¬ä¿¡å·ã‚’å°å‡ºã—ã€æ¬¡ã®ãƒ†ã‚­ã‚¹ãƒˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã§ãƒãƒªã‚·ãƒ¼ã«å ±é…¬ã‚’ä¸ãˆã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€è¤‡æ•°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ€§èƒ½ãŒå‘ä¸Šã—ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã®å¢—åŠ ã«ã‚ˆã‚‹ã•ã‚‰ãªã‚‹æ”¹å–„ã®å¯èƒ½æ€§ãŒç¤ºã•ã‚ŒãŸã€‚RLPTã¯LLMsã®æ¨è«–èƒ½åŠ›ã‚’æ‹¡å¼µã—ã€RLVRã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã«ã‚‚å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1970684035258294548?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2031" target="_blank" rel="noopener noreferrer">[Paper Note] Reinforcement Pre-Training, Qingxiu Dong+, arXiv'25</a>
</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/changjonathanc/status/1971045178640302421?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tencenthunyuan/status/1971118167281057821?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2964" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Heimdall: test-time scaling on the generative verification, Wenlei Shi+, arXiv'25, 2025.04</a>
<span class="snippet"><span>GPT Summary</span>- Heimdallã¯ã€é•·ã„Chain-of-Thoughtæ¨è«–ã«ãŠã‘ã‚‹æ¤œè¨¼èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®LLMã§ã‚ã‚Šã€æ•°å­¦å•é¡Œã®è§£æ±ºç²¾åº¦ã‚’62.5%ã‹ã‚‰94.5%ã«å¼•ãä¸Šã’ã€ã•ã‚‰ã«97.5%ã«é”ã™ã‚‹ã€‚æ‚²è¦³çš„æ¤œè¨¼ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€è§£æ±ºç­–ã®ç²¾åº¦ã‚’54.2%ã‹ã‚‰70.0%ã€å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§93.0%ã«å‘ä¸Šã•ã›ã‚‹ã€‚è‡ªå‹•çŸ¥è­˜ç™ºè¦‹ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚‚ä½œæˆã—ã€ãƒ‡ãƒ¼ã‚¿ã®æ¬ é™¥ã‚’ç‰¹å®šã™ã‚‹èƒ½åŠ›ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2961" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Soft Tokens, Hard Truths, Natasha Butt+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€é›¢æ•£CoTã‹ã‚‰ã®è’¸ç•™ãªã—ã«å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦é€£ç¶šCoTã‚’å­¦ç¿’ã™ã‚‹æ–°ã—ã„æ–¹æ³•ã‚’ææ¡ˆã€‚ã‚½ãƒ•ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ´»ç”¨ã—ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã¤ã¤æ•°ç™¾ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŒã¤é€£ç¶šCoTã‚’å­¦ç¿’å¯èƒ½ã€‚LlamaãŠã‚ˆã³Qwenãƒ¢ãƒ‡ãƒ«ã§ã®å®Ÿé¨“ã«ã‚ˆã‚Šã€é€£ç¶šCoTã¯é›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³CoTã¨åŒç­‰ã¾ãŸã¯ãã‚Œã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ç‰¹ã«é€£ç¶šCoTã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã«é›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³ã§æ¨è«–ã™ã‚‹ã‚·ãƒŠãƒªã‚ªãŒæœ€è‰¯ã®çµæœã‚’å¾—ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚ã•ã‚‰ã«ã€é€£ç¶šCoTã®RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ä¿æŒã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1970692910766346277?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1971341729803759989?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/natashaeve4/status/1971216376556814356?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1974348003696619795?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/SamplingParams.html" target="_blank" rel="noopener noreferrer">#SamplingParams</a>
<a class="button" href="articles/Best-of-N.html" target="_blank" rel="noopener noreferrer">#Best-of-N</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2957" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Optimizing Temperature for Language Models with Multi-Sample Inference, Weihua Du+, ICML'25, 2025.02</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒã‚µãƒ³ãƒ—ãƒ«é›†ç´„æˆ¦ç•¥ã‚’ç”¨ã„ã¦ã€LLMã®æœ€é©ãªæ¸©åº¦ã‚’è‡ªå‹•çš„ã«ç‰¹å®šã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚å¾“æ¥ã®æ–¹æ³•ã«ä¾å­˜ã›ãšã€ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è€ƒæ…®ã—ãŸæ¸©åº¦ã®å½¹å‰²ã‚’åˆ†æã€‚æ–°ãŸã«ææ¡ˆã™ã‚‹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã«åŸºã¥ãæŒ‡æ¨™ã¯ã€å›ºå®šæ¸©åº¦ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ç¢ºç‡éç¨‹ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦æ¸©åº¦ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®é–¢ä¿‚ã‚’è§£æ˜ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=rmWpE3FrHW&noteId=h9GETXxWDB" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=rmWpE3FrHW&noteId=h9GETXxWDB</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2938" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LIMI: Less is More for Agency, Yang Xiao+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- AIã‚·ã‚¹ãƒ†ãƒ ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ã‚·ãƒ¼ã‚’ã€è‡ªå¾‹çš„ã«å•é¡Œã‚’ç™ºè¦‹ã—è§£æ±ºç­–ã‚’å®Ÿè¡Œã™ã‚‹èƒ½åŠ›ã¨å®šç¾©ã€‚æ€¥é€Ÿã«å¤‰åŒ–ã™ã‚‹æ¥­ç•Œã®ãƒ‹ãƒ¼ã‚ºã«å¿œã˜ã¦ã€å˜ãªã‚‹æ¨è«–ã‚’è¶…ãˆãŸè‡ªå¾‹çš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ±‚ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚LIMIï¼ˆLess Is More for Intelligent Agencyï¼‰ã¯ã€æœ€å°é™ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«ã§é«˜ã„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ã‚·ãƒ¼ã‚’å®Ÿç¾ã™ã‚‹æ–°ãŸãªåŸå‰‡ã‚’ææ¡ˆã—ã€78ã‚µãƒ³ãƒ—ãƒ«ã§73.5%ã®æˆæœã‚’é”æˆã€‚ã“ã‚Œã¯ã€å¾“æ¥ã®ãƒ‡ãƒ¼ã‚¿é‡ã«ä¾å­˜ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«å¯¾ã™ã‚‹æŒ‘æˆ¦ã§ã‚ã‚Šã€é«˜å“è³ªãªãƒ‡ãƒ¢ã®æˆ¦ç•¥çš„ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1970328242688246160?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLM Agentã®SFTã«ãŠã‘ã‚‹Less is more<br><br>å‚è€ƒ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/700" target="_blank" rel="noopener noreferrer">LIMA: Less Is More for Alignment, Chunting Zhou+, N/A, NeurIPS'23</a>
</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1971777010658955436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2937" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ARE: Scaling Up Agent Environments and Evaluations, Pierre Andrews+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- Meta Agents Research Environments (ARE)ã‚’ç´¹ä»‹ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ç’°å¢ƒã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªä½œæˆã‚’æ”¯æ´ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’æä¾›ã€‚Gaia2ã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚Œã€å‹•çš„ç’°å¢ƒã¸ã®é©å¿œã‚„ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®å”åŠ›ã‚’è¦æ±‚ã€‚Gaia2ã¯éåŒæœŸã§å®Ÿè¡Œã•ã‚Œã€æ–°ãŸãªå¤±æ•—ãƒ¢ãƒ¼ãƒ‰ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€çŸ¥èƒ½ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«å…¨ä½“ã§ã®æ”¯é…çš„ãªã‚·ã‚¹ãƒ†ãƒ ãŒå­˜åœ¨ã—ãªã„ã“ã¨ã‚’ç¤ºã—ã€AREã®æŠ½è±¡åŒ–ãŒæ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®è¿…é€Ÿãªä½œæˆã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ã‚’å¼·èª¿ã€‚AIã®é€²å±•ã¯ã€æ„å‘³ã®ã‚ã‚‹ã‚¿ã‚¹ã‚¯ã¨å …ç‰¢ãªè©•ä¾¡ã«ä¾å­˜ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/froger_romain/status/1970120373829066982?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>GAIAã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1158" target="_blank" rel="noopener noreferrer">GAIA: a benchmark for General AI Assistants, GrÃ©goire Mialon+, N/A, arXiv'23</a>
</p>
<p>Execution, Search, Ambiguity, Adaptability, Time, Noise, Agent2Agentã®6ã¤ã®capabilityã‚’è©•ä¾¡å¯èƒ½ã€‚èˆˆå‘³æ·±ã„ã€‚</p>
<p>ç¾çŠ¶ã€å…¨ä½“çš„ã«ã¯GPT-5(high)ã®æ€§èƒ½ãŒæœ€ã‚‚è‰¯ãã€ç¶šã„ã¦Claude-4 Sonnetã¨ã„ã†æ„Ÿã˜ã«è¦‹ãˆã‚‹ã€‚OpenWeightãªãƒ¢ãƒ‡ãƒ«ã§ã¯ã€Kimi-K2ã®æ€§èƒ½ãŒé«˜ãã€ç¶šã„ã¦Qwen3-235Bã¨ã„ã†æ„Ÿã˜ã«è¦‹ãˆã‚‹ã€‚ã¾ãŸã€Figure1ã¯budgetã”ã¨ã®ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚‚ç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚ã‚·ãƒŠãƒªã‚ªå˜ä½ã®budgetãŒ$1ä»¥ä¸Šã®å ´åˆã¯GPT-5(high)ã®æ€§èƒ½ãŒæœ€ã‚‚è‰¯ã„ãŒã€$0.1--$0.4ã®é–“ã§ã¯Kiml-K2ã®æ€§èƒ½ãŒæœ€ã‚‚è‰¯ã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/039a6e69-4941-4a80-99b3-0590d1446030" alt="image" loading="lazy"></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2406" target="_blank" rel="noopener noreferrer">[Paper Note] GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models, GLM-4. 5 Team+, arXiv'25</a>
<br><br>ã—ã£ã‹ã‚Šã¨èª­ã‚ã¦ã„ãªã„ãŒGLM-4.5ã¯å«ã¾ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1970162732470067283?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Hybrid.html" target="_blank" rel="noopener noreferrer">#Hybrid</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2934" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GTA: Supervised-Guided Reinforcement Learning for Text Classification  with Large Language Models, Min Zeng+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- GTAãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€SFTã®åŠ¹ç‡æ€§ã¨RLã®èƒ½åŠ›ã‚’çµ±åˆã€‚ãƒ¢ãƒ‡ãƒ«ã¯ä»®ã®æ¨æ¸¬ã‚’ç”Ÿæˆã—ã€æœ€çµ‚çš„ãªå›ç­”ã‚’å°å‡ºã™ã‚‹ã€‚ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚Šã€åæŸãŒé€Ÿãã€æ€§èƒ½ãŒå‘ä¸Šã€‚æå¤±ãƒã‚¹ã‚­ãƒ³ã‚°ã¨å‹¾é…åˆ¶ç´„ã‚’ç”¨ã„ã¦å‹¾é…ã®å¯¾ç«‹ã‚’è»½æ¸›ã€‚å®Ÿé¨“çµæœã¯GTAã®å„ªä½æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1970056056513679744?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2933" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] JudgeLM: Fine-tuned Large Language Models are Scalable Judges, Lianghui Zhu+, ICLR'25, 2023.10</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰è©•ä¾¡ã®ãŸã‚ã«ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸJudgeLMã‚’ææ¡ˆã€‚é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€ãƒã‚¤ã‚¢ã‚¹ã‚’åˆ†æã€‚æ–°æŠ€è¡“ã‚’å°å…¥ã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã€‚JudgeLMã¯æ—¢å­˜ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã€é«˜ã„ä¸€è‡´ç‡ã‚’ç¤ºã™ã€‚æ‹¡å¼µã•ã‚ŒãŸèƒ½åŠ›ã‚‚æŒã¡ã€ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=xsELpEPn4A" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=xsELpEPn4A</a>


</p>
<p>dataset: 


<a href="https://huggingface.co/datasets/BAAI/JudgeLM-100K" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/BAAI/JudgeLM-100K</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2930" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Transfusion: Predict the Next Token and Diffuse Images with One   Multi-Modal Model, Chunting Zhou+, ICLR'25, 2024.08</a>
<span class="snippet"><span>GPT Summary</span>- Transfusionã¯ã€é›¢æ•£ãƒ‡ãƒ¼ã‚¿ã¨é€£ç¶šãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹æ‰‹æ³•ã§ã€è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®æå¤±é–¢æ•°ã¨æ‹¡æ•£ã‚’çµ„ã¿åˆã‚ã›ã¦å˜ä¸€ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’è¨“ç·´ã—ã¾ã™ã€‚æœ€å¤§7Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰è¨“ç·´ã—ã€ãƒ¦ãƒ‹ãƒ¢ãƒ¼ãƒ€ãƒ«ãŠã‚ˆã³ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ç¤ºã—ã¾ã—ãŸã€‚ãƒ¢ãƒ€ãƒªãƒ†ã‚£ç‰¹æœ‰ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å±¤ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã€7Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã§ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=SI2hI0frk6" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=SI2hI0frk6</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2929" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LoRA-Pro: Are Low-Rank Adapters Properly Optimized?, Zhengbo Wang+, ICLR'25, 2024.07</a>
<span class="snippet"><span>GPT Summary</span>- LoRAã¯åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®åŠ¹ç‡çš„ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã ãŒã€ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«æ¯”ã¹æ€§èƒ½ãŒåŠ£ã‚‹ã“ã¨ãŒå¤šã„ã€‚æœ¬è«–æ–‡ã§ã¯ã€LoRAã¨ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã®é–¢ä¿‚ã‚’æ˜ã‚‰ã‹ã«ã—ã€LoRAã®ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ã®å‹¾é…ã‚’èª¿æ•´ã™ã‚‹æ–°æ‰‹æ³•LoRA-Proã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LoRAã®æ€§èƒ½ãŒå‘ä¸Šã—ã€ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã®ã‚®ãƒ£ãƒƒãƒ—ãŒç¸®å°ã™ã‚‹ã“ã¨ã‚’å®Ÿé¨“ã§ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://openreview.net/forum?id=gTwRMU3lJ5" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=gTwRMU3lJ5</a>


</p>
<p>openreview:


<a href="https://openreview.net/forum?id=gTwRMU3lJ5" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=gTwRMU3lJ5</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2927" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Synthetic bootstrapped pretraining, Zitong Yang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- Synthetic Bootstrapped Pretrainingï¼ˆSBPï¼‰ã¯ã€æ–‡æ›¸é–“ã®é–¢ä¿‚ã‚’å­¦ç¿’ã—ã€æ–°ã—ã„ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’åˆæˆã™ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’æ‰‹æ³•ã§ã™ã€‚å¾“æ¥ã®äº‹å‰å­¦ç¿’ã¯å˜ä¸€æ–‡æ›¸å†…ã®å› æœé–¢ä¿‚ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ãŒã€SBPã¯æ–‡æ›¸é–“ã®ç›¸é–¢é–¢ä¿‚ã‚’åŠ¹ç‡çš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¾ã™ã€‚3Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã€SBPã¯å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’æ”¹å–„ã—ã€åˆæˆã•ã‚ŒãŸæ–‡æ›¸ã¯å˜ãªã‚‹è¨€ã„æ›ãˆã‚’è¶…ãˆãŸæ–°ã—ã„ç‰©èªã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚SBPã¯è‡ªç„¶ãªãƒ™ã‚¤ã‚ºçš„è§£é‡ˆã‚’è¨±å®¹ã—ã€é–¢é€£æ–‡æ›¸é–“ã®æ½œåœ¨çš„ãªæ¦‚å¿µã‚’å­¦ç¿’ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1970009915797475489?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1969973861178626245?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>èˆˆå‘³æ·±ã„ã€‚</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zitongyang0/status/1970129028536484089?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>conceptã‚’å­¦ç¿’ã™ã‚‹ã¨ã„ã†è¦³ç‚¹ã§ã¯ä»¥ä¸‹ãŒé–¢é€£ã—ã¦ã„ã‚‹æ°—ãŒã™ã‚‹ãŒã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¤§ããç•°ãªã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1611" target="_blank" rel="noopener noreferrer">Large Concept Models: Language Modeling in a Sentence Representation Space, Meta, 2024.12</a>
</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2926" target="_blank" rel="noopener noreferrer" class="title-link">Adaptive Localization of Knowledge Negation for Continual LLM Unlearning, Wuerkaixi+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å®‰å…¨æ€§ã«é–¢ã™ã‚‹æ‡¸å¿µãŒé«˜ã¾ã‚‹ä¸­ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆçŸ¥è­˜ã‚’åŠ¹æœçš„ã«å¿˜å´ã—ã¤ã¤åˆ©ç”¨ä¾¡å€¤ã‚’ç¶­æŒã™ã‚‹æ‰‹æ³•ALKNï¼ˆAdaptive Localization of Knowledge Negationï¼‰ã‚’ææ¡ˆã€‚å‹•çš„ãƒã‚¹ã‚­ãƒ³ã‚°ã‚’ç”¨ã„ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å‹¾é…ã‚’ã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–ã—ã€å¿˜å´ã®å¼·åº¦ã‚’é©å¿œçš„ã«èª¿æ•´ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ç¶™ç¶šçš„ãªå¿˜å´è¨­å®šã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹åŠ¹æœã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1969940279424885162?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2925" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid  Vision Tokenizer, Yanghao Li+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- Manzanoã¯ã€è¦–è¦šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç†è§£ã¨ç”Ÿæˆã‚’çµ±ä¸€çš„ã«è¡Œã†ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã§ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç”»åƒãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¬ã‚·ãƒ”ã‚’çµ„ã¿åˆã‚ã›ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è»½æ¸›ã—ã¾ã™ã€‚å˜ä¸€ã®ãƒ“ã‚¸ãƒ§ãƒ³ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãŒç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸ã®åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã—ã€è‡ªå·±å›å¸°å‹LLMãŒãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒãƒˆãƒ¼ã‚¯ãƒ³ã®é«˜ãƒ¬ãƒ™ãƒ«ã®æ„å‘³ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚ã“ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€ä¸¡æ–¹ã®èƒ½åŠ›ã®å…±åŒå­¦ç¿’ãŒå¯èƒ½ã¨ãªã‚Šã€æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1969974676802990478?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1969974517024923936?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>DocVQAã®ã‚ªãƒ©ã‚¯ãƒ«ã¯ãƒ©ãƒ™ãƒ«ãƒã‚¤ã‚ºã¨æ›–æ˜§æ€§ã®è¦³ç‚¹ã‹ã‚‰94--95ã¨ã„ã†ä¸»å¼µ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vikhyatk/status/1970585801600967009?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<a class="button" href="articles/ReversalCurse.html" target="_blank" rel="noopener noreferrer">#ReversalCurse</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2923" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Latent learning: episodic memory complements parametric learning by  enabling flexible reuse of experiences, Andrew Kyle Lampinen+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®ä¸€èˆ¬åŒ–å¤±æ•—ã®åŸå› ã¨ã—ã¦ã€æ½œåœ¨å­¦ç¿’ã®æ¬ å¦‚ã‚’æŒ‡æ‘˜ã€‚èªçŸ¥ç§‘å­¦ã®è¦–ç‚¹ã‹ã‚‰ã€ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ã‚„ã‚ªãƒ©ã‚¯ãƒ«ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒä¸€èˆ¬åŒ–ã‚’æ”¹å–„ã™ã‚‹æ‰‹æ®µã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚æ–‡è„ˆå†…å­¦ç¿’ãŒæƒ…å ±æ´»ç”¨ã®éµã§ã‚ã‚Šã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ«æ‰‹æ³•ãŒãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯å­¦ç¿’ã‚’è£œå®Œã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹å¯èƒ½æ€§ã‚’ææ¡ˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1969968869952631225?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2918" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled   Refusal Training, Youliang Yuan+, ACL'25, 2024.07</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMsã®å®‰å…¨æ€§èª¿æ•´ã«ãŠã‘ã‚‹æ‹’å¦ãƒã‚¸ã‚·ãƒ§ãƒ³ãƒã‚¤ã‚¢ã‚¹ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ã€ŒDecoupled Refusal Trainingï¼ˆDeRTaï¼‰ã€ã¨ã„ã†æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚DeRTaã¯ã€æœ‰å®³ãªå¿œç­”ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’ç”¨ã„ãŸæœ€å¤§å°¤åº¦æ¨å®šã¨å¼·åŒ–ã•ã‚ŒãŸé·ç§»æœ€é©åŒ–ã‚’çµ„ã¿è¾¼ã¿ã€ãƒ¢ãƒ‡ãƒ«ãŒä¸é©åˆ‡ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’èªè­˜ã—æ‹’å¦ã™ã‚‹èƒ½åŠ›ã‚’å¼·åŒ–ã—ã¾ã™ã€‚å®Ÿè¨¼è©•ä¾¡ã§ã¯ã€ææ¡ˆæ‰‹æ³•ãŒå®‰å…¨æ€§ã‚’å‘ä¸Šã•ã›ã€æ”»æ’ƒã«å¯¾ã™ã‚‹é˜²å¾¡ã§ã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/youliang_yuan/status/1812665889852121332?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä¸€èˆ¬çš„ãªSafety Tuningã§ã¯æœ‰å®³ãªpromptãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«å®‰å…¨ãªå¿œç­”ãŒç”Ÿæˆã•ã‚Œã‚‹ç¢ºç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ï¼ˆMLE)ãŒã€å®‰å…¨ãªå¿œç­”ã¯å†’é ­ã®æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã«Sorry, I apologizeç­‰ã®å›ç­”ã‚’æ‹’çµ¶ã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ãŒé›†ä¸­ã™ã‚‹å‚¾å‘ã«ã‚ã‚Šã€å¿œç­”ã‚’æ‹’å¦ã™ã‚‹ã‹å¦ã‹ã«ãƒã‚¸ã‚·ãƒ§ãƒ³ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ã¦ã—ã¾ã†ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¿œç­”ã®é€”ä¸­ã§æ½œåœ¨çš„ãªå±é™ºæ€§ã‚’æ¤œçŸ¥ã—ã€å¿œç­”ã‚’æ‹’å¦ã™ã‚‹ã“ã¨ãŒã§ããªããªã£ã¦ã—ã¾ã†ã¨ã„ã†èª²é¡ŒãŒç”Ÿã˜ã‚‹ã€‚<br><br>ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€RTOã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚æœ‰å®³ãªpromptã®ä¸€éƒ¨ã‚’prefixã¨ã—ã€ãã®å¾Œã«Safetyãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’concatã™ã‚‹ã‚ˆã†ãªå¿œç­”ã‚’åˆæˆã—MLEã«æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€å¿œç­”ã®é€”ä¸­ã§ã‚‚å¿œç­”ã‚’æ‹’å¦ã™ã‚‹ã‚ˆã†ãªæŒ™å‹•ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚prefixã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€<br>- prefixã‚’ç”¨ã„ã‚‹ã“ã¨ã§å®‰å…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«è¿½åŠ ã®contextã‚’ä»˜ä¸ã™ã‚‹ã“ã¨ãŒã§ãã€æ½œåœ¨çš„ãªå±é™ºæ€§ã®è­˜åˆ¥åŠ›ãŒé«˜ã¾ã‚Šã€<br>- prefixã®é•·ã•ã¯ä»»æ„ãªã®ã§ã€å¿œç­”ã®ã©ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã‹ã‚‰ã§ã‚‚å±é™ºæ€§è­˜åˆ¥ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã€<br>- ãƒ¢ãƒ‡ãƒ«ãŒæœ‰å®³ãªå¿œç­”ã‚’é–‹å§‹ã—ãŸã“ã¨ã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«èªè­˜ã—ã¦å®‰å…¨ãªå›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«é·ç§»ã•ã›ã‚‰ã‚Œã‚‹<br><br>ã¨ã„ã£ãŸåˆ©ç‚¹ãŒã‚ã‚‹ãŒã€1ã¤ã®å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«ã«ã¤ãä¸€ã¤ã®é·ç§»ï¼ˆi.e., prefixã¨å®‰å…¨ãªå¿œç­”ã®å¢ƒç›®ã¯1ã‚µãƒ³ãƒ—ãƒ«ã«ã¤ãä¸€ç®‡æ‰€ã—ã‹ãªã„ã®ã§ï¼‰ã—ã‹å­¦ç¿’ã§ããªã„ã“ã¨ã§ã‚ã‚‹ã€‚ã“ã®ãŸã‚ã€RTOã§ã¯ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å…¨ã¦ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦sorryãŒç”Ÿæˆã•ã‚Œã‚‹ç¢ºç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ãŒå…¨ã¦ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã§ç¶™ç¶šçš„ã«å±é™ºæ€§ã‚’è­˜åˆ¥ã§ãã‚‹èƒ½åŠ›ã‚’é«˜ã‚ã‚‹ã‚ˆã†ãªå·¥å¤«ã‚’ã™ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/1e35903a-b886-4475-8b58-76e057c26d03" alt="image" loading="lazy"><br><br>ç›®çš„é–¢æ•°ã¯ä»¥ä¸‹ã§ã€Harmful PrefixãŒgivenãªæ™‚ã«å®‰å…¨ãªå›ç­”ãŒç”Ÿæˆã•ã‚Œã‚‹ç¢ºç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹MLEã®é …ã«å¯¾ã—ã¦ï¼ˆr^hat_&lt;kã¯ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã•ã‚Œã‚‹[0,å›ç­”ã®é•·ã•]ã®å®šæ•°ï¼‰ã€å…¨ã¦ã®ä½ç½®tä»¥å¾Œã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦sorryã®ç”Ÿæˆç¢ºç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ï¼ˆtã¯å…¨ã¦ã®å¯èƒ½ãªãƒã‚¸ã‚·ãƒ§ãƒ³ã«å¯¾ã—ã¦å¤‰åŒ–ã•ã›ã¦summationã™ã‚‹ï¼‰ã‚ˆã†ãªé …ã‚’è¿½åŠ ï¼ˆï¼RTOï¼‰ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/d7416ef5-6587-46b4-8255-1e9884242a72" alt="image" loading="lazy"><br><br>å®Ÿé¨“ã®çµæœã¯ã€å…¨ä½“ã‚’è¦‹ã‚‹é™ã‚Šã€helpfulnessã‚’æãªã†ã“ã¨ãªãã€å®‰å…¨ãªå¿œç­”ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ãŠã‚Šã€DPOç­‰ã®ãã®ä»–ã®Alignmentæ‰‹æ³•ã‚ˆã‚Šã‚‚æ€§èƒ½ãŒè‰¯ã•ãã†ã§ã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/3fdec4a2-5b9e-4f4b-985a-edf885fde72a" alt="image" loading="lazy"></p>
<p>ä»¥ä¸‹ã®ç ”ç©¶ã§å ±å‘Šã•ã‚Œã¦ã„ã‚‹ç¾è±¡ã¨ä¼¼ã¦ã„ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1813" target="_blank" rel="noopener noreferrer">The First Few Tokens Are All You Need: An Efficient and Effective
  Unsupervised Prefix Fine-Tuning Method for Reasoning Models, Ke Ji+, arXiv'25</a>
<br><br>ã™ãªã‚ã¡ã€reasoning traceã®æœ€åˆã®æ•°ãƒˆãƒ¼ã‚¯ãƒ³ãŒå…¨ä½“ã®å“è³ªã«å¤§ããé–¢ã‚ã‚‹ã¨ã„ã†è©±</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Financial.html" target="_blank" rel="noopener noreferrer">#Financial</a>
<span class="issue_date">Issue Date: 2025-09-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2916" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial  Search and Reasoning, Liang Hu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- FinSearchCompã¯ã€é‡‘èæ¤œç´¢ã¨æ¨è«–ã®ãŸã‚ã®åˆã®å®Œå…¨ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚Šã€æ™‚é–“ã«æ•æ„Ÿãªãƒ‡ãƒ¼ã‚¿å–å¾—ã‚„è¤‡é›‘ãªæ­´å²çš„èª¿æŸ»ã‚’å«ã‚€3ã¤ã®ã‚¿ã‚¹ã‚¯ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚70äººã®é‡‘èå°‚é–€å®¶ã«ã‚ˆã‚‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¨å³æ ¼ãªå“è³ªä¿è¨¼ã‚’çµŒã¦ã€635ã®è³ªå•ãŒç”¨æ„ã•ã‚Œã€21ã®ãƒ¢ãƒ‡ãƒ«ãŒè©•ä¾¡ã•ã‚Œã¾ã—ãŸã€‚Grok 4ã¨DouBaoãŒãã‚Œãã‚Œã‚°ãƒ­ãƒ¼ãƒãƒ«ãŠã‚ˆã³å¤§ä¸­è¯åœã§ãƒˆãƒƒãƒ—ã®ç²¾åº¦ã‚’ç¤ºã—ã€ã‚¦ã‚§ãƒ–æ¤œç´¢ã¨é‡‘èãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®æ´»ç”¨ãŒçµæœã‚’æ”¹å–„ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚FinSearchCompã¯ã€ç¾å®Ÿã®ã‚¢ãƒŠãƒªã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã«åŸºã¥ãé«˜é›£æ˜“åº¦ã®ãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1969433151249244528?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Emotion.html" target="_blank" rel="noopener noreferrer">#Emotion</a>
<span class="issue_date">Issue Date: 2025-09-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2915" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LongEmotion: Measuring Emotional Intelligence of Large Language Models  in Long-Context Interaction, Weichu Liu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- é•·æ–‡ã®æ„Ÿæƒ…çŸ¥èƒ½ï¼ˆEIï¼‰ã‚¿ã‚¹ã‚¯å°‚ç”¨ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒLongEmotionã€ã‚’ææ¡ˆã€‚æ„Ÿæƒ…åˆ†é¡ã‚„æ„Ÿæƒ…ä¼šè©±ãªã©å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã‚’ã‚«ãƒãƒ¼ã—ã€å¹³å‡å…¥åŠ›é•·ã¯8,777ãƒˆãƒ¼ã‚¯ãƒ³ã€‚Retrieval-Augmented Generationï¼ˆRAGï¼‰ã¨Collaborative Emotional Modelingï¼ˆCoEMï¼‰ã‚’çµ„ã¿è¾¼ã¿ã€å¾“æ¥ã®æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦EIãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã€‚å®Ÿé¨“çµæœã¯ã€RAGã¨CoEMãŒé•·æ–‡ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ä¸€è²«ã—ã¦åŠ¹æœã‚’ç¤ºã—ã€LLMsã®å®Ÿç”¨æ€§ã‚’é«˜ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://longemotion.github.io" target="_blank" rel="noopener noreferrer">https://longemotion.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1969373139189539164?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<span class="issue_date">Issue Date: 2025-09-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2914" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generalizing Verifiable Instruction Following, Valentina Pyatkin+, NeurIPS'25, 2025.07</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“ã¨AIã®ç›¸äº’ä½œç”¨ã«ãŠã„ã¦ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒæŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ãŒé‡è¦ã§ã‚ã‚‹ãŒã€ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯å‡ºåŠ›åˆ¶ç´„ã‚’æº€ãŸã™ã®ã«è‹¦åŠ´ã—ã¦ã„ã‚‹ã€‚å¤šãã®ãƒ¢ãƒ‡ãƒ«ã¯æ—¢å­˜ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«éå‰°é©åˆã—ã¦ãŠã‚Šã€æœªè¦‹ã®åˆ¶ç´„ã«å¯¾ã—ã¦ä¸€èˆ¬åŒ–ã§ããªã„ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯IFBenchã‚’å°å…¥ã—ã€æŒ‡ç¤ºéµå®ˆã®ä¸€èˆ¬åŒ–ã‚’è©•ä¾¡ã™ã‚‹ã€‚ã•ã‚‰ã«ã€åˆ¶ç´„æ¤œè¨¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨å¼·åŒ–å­¦ç¿’ï¼ˆRLVRï¼‰ã‚’ç”¨ã„ã¦æŒ‡ç¤ºéµå®ˆã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã€é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚„è¨“ç·´ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¬é–‹ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/valentina__py/status/1969294455938138243?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Instruction Followingã®ãŸã‚ã®æ–°ãŸãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯IFBenchï¼ˆå¤šæ§˜ï¼ˆ58ç¨®é¡ã®åˆ¶ç´„ï¼‰ã§ç²¾ç·»ã€ã‹ã¤è¤‡æ•°ã®å‡ºåŠ›ã«é–¢ã™ã‚‹åˆ¶ç´„ã‚’æŒã¤ã€‚Appendix Aã‚’å‚ç…§ã®ã“ã¨)ã‚’å°å…¥ã—ã€RLVRã«ã‚ˆã£ã¦Instruction tuningã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚è¤‡æ•°ã®IFã®åˆ¶ç´„ã‚’åŒæ™‚ã«å­¦ç¿’ã—ãŸæ–¹ãŒOODã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆã«ãªã‚‹ã“ã¨ã‚„ã€åˆ¶ç´„ã”ã¨ã®instanceæ•°ã«å¯¾ã™ã‚‹æ€§èƒ½ã®å¤‰åŒ–ã€ã¾ãŸSFT, DPOã«ã‚ˆã£ã¦Instrtction Tuningã‚’å®Ÿæ–½ã—ãŸãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€åˆ¶ç´„ã‚’æº€ãŸã—ãŸã‹å¦ã‹ã®Verifiableãªãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç”Ÿæˆã—ãŸå—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦è¿½åŠ ã®DPOã‚’å®Ÿæ–½ã—ãŸå ´åˆã¨ã€RLVRã«åŸºã¥ãGRPOã‚’å®Ÿæ–½ã—ãŸå ´åˆã®ã©ã¡ã‚‰ã®æ€§èƒ½ãŒè‰¯ã„ã‹ãªã©ã‚‚å®Ÿé¨“ã•ã‚Œã¦ã„ã‚‹ï¼ˆä¸€è²«ã—ã¦GRPOãŒè‰¯ã„ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Ensemble.html" target="_blank" rel="noopener noreferrer">#Ensemble</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2912" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Pre-training under infinite compute, Konwoo Kim+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è¨ˆç®—èƒ½åŠ›ã®å¢—åŠ ã«å¯¾ã—ã€å›ºå®šãƒ‡ãƒ¼ã‚¿ã§ã®äº‹å‰å­¦ç¿’ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’è€ƒå¯Ÿã€‚ã‚¨ãƒãƒƒã‚¯æ•°ã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å¢—åŠ ã¯éå­¦ç¿’ã‚’å¼•ãèµ·ã“ã™ãŒã€æ­£å‰‡åŒ–ã‚’é©åˆ‡ã«èª¿æ•´ã™ã‚‹ã“ã¨ã§æ”¹å–„å¯èƒ½ã€‚æœ€é©ãªé‡ã¿æ¸›è¡°ã¯æ¨™æº–ã®30å€ã§ã€æ­£å‰‡åŒ–æ‰‹æ³•ã¯æå¤±ã‚’å˜èª¿ã«æ¸›å°‘ã•ã›ã‚‹ã€‚ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã¯æ­£å‰‡åŒ–æ‰‹æ³•ã‚ˆã‚Šã‚‚ä½ã„æå¤±ã‚’é”æˆã—ã€ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨é‡ã‚’5.17å€å‰Šæ¸›ã€‚å­¦ç”Ÿãƒ¢ãƒ‡ãƒ«ã¸ã®è’¸ç•™ã«ã‚ˆã‚Šã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã€ä¸‹æµãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®æ”¹å–„ã‚‚ç¢ºèªã€‚çµæœã¯ã€è¨ˆç®—ãƒªãƒƒãƒãªæœªæ¥ã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã®è‰¯ã„äº‹å‰å­¦ç¿’ã®å¯èƒ½æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/percyliang/status/1969101519531491712?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1969887073017708822?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2905" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Length Representations in Large Language Models, Sangjun Moon+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯å‡ºåŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é•·ã•ã‚’åˆ¶å¾¡ã™ã‚‹èƒ½åŠ›ã‚’æŒã¡ã€ãã®å†…éƒ¨ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æ¢æ±‚ã€‚ç‰¹ã«ã€ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãŒå‡ºåŠ›é•·ã®æ±ºå®šã«é‡è¦ã§ã‚ã‚Šã€ç‰¹å®šã®éš ã‚Œãƒ¦ãƒ‹ãƒƒãƒˆã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§é•·ã•ã‚’åˆ¶å¾¡å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé•·ã•ç‰¹æœ‰ã«ãªã‚‹ã¨éš ã‚Œãƒ¦ãƒ‹ãƒƒãƒˆãŒæ´»æ€§åŒ–ã—ã€ãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨èªè­˜ã‚’åæ˜ ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã¯å¤–éƒ¨åˆ¶å¾¡ãªã—ã«å‡ºåŠ›ã®é•·ã•ã‚’é©å¿œçš„ã«åˆ¶å¾¡ã™ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å­¦ç¿’ã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Biological.html" target="_blank" rel="noopener noreferrer">#Biological</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2901" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BioReason: Incentivizing Multimodal Biological Reasoning within a   DNA-LLM Model, Adibvafa Fallahpour+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- BioReasonã¯ã€DNAåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã¨å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã‚’çµ±åˆã—ãŸæ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã€è¤‡é›‘ãªã‚²ãƒãƒ ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®ç”Ÿç‰©å­¦çš„æ¨è«–ã‚’æ·±ãè§£é‡ˆå¯èƒ½ã«ã™ã‚‹ã€‚å¤šæ®µéšæ¨è«–ã‚’é€šã˜ã¦ã€ç²¾åº¦ãŒ88%ã‹ã‚‰97%ã«å‘ä¸Šã—ã€ãƒãƒªã‚¢ãƒ³ãƒˆåŠ¹æœäºˆæ¸¬ã§ã‚‚å¹³å‡15%ã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã€‚æœªè¦‹ã®ç”Ÿç‰©å­¦çš„ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«å¯¾ã™ã‚‹æ¨è«–ã‚’è¡Œã„ã€è§£é‡ˆå¯èƒ½ãªæ„æ€æ±ºå®šã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã§ã€AIã«ãŠã‘ã‚‹ç”Ÿç‰©å­¦ã®é€²å±•ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/collections/wanglab/bioreason-683cd17172a037a31d208f70" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/wanglab/bioreason-683cd17172a037a31d208f70</a>


<br>pj page:


<a href="https://bowang-lab.github.io/BioReason/" target="_blank" rel="noopener noreferrer">https://bowang-lab.github.io/BioReason/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bowang87/status/1969174399564857543?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2900" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FlowRL: Matching Reward Distributions for LLM Reasoning, Xuekai Zhu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- FlowRLã¯ã€LLMå¼·åŒ–å­¦ç¿’ã«ãŠã„ã¦å ±é…¬ã‚’æœ€å¤§åŒ–ã™ã‚‹ã®ã§ã¯ãªãã€ãƒ•ãƒ­ãƒ¼ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã‚’é€šã˜ã¦å ±é…¬åˆ†å¸ƒã‚’ä¸€è‡´ã•ã›ã‚‹æ‰‹æ³•ã§ã™ã€‚å¾“æ¥ã®å ±é…¬æœ€å¤§åŒ–æ‰‹æ³•ã¯å¤šæ§˜æ€§ã‚’æ¸›å°‘ã•ã›ã‚‹å‚¾å‘ãŒã‚ã‚‹ãŸã‚ã€FlowRLã§ã¯å­¦ç¿’å¯èƒ½ãªåˆ†å‰²é–¢æ•°ã‚’ç”¨ã„ã¦ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒã«å¤‰æ›ã—ã€ãƒãƒªã‚·ãƒ¼ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒã®é€†KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚’æœ€å°åŒ–ã—ã¾ã™ã€‚å®Ÿé¨“ã®çµæœã€FlowRLã¯æ•°å­¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§GRPOã«å¯¾ã—ã¦å¹³å‡10.0%ã€PPOã«å¯¾ã—ã¦5.1%ã®æ”¹å–„ã‚’é”æˆã—ã€ã‚³ãƒ¼ãƒ‰æ¨è«–ã‚¿ã‚¹ã‚¯ã§ã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚å ±é…¬åˆ†å¸ƒã®ä¸€è‡´ãŒåŠ¹ç‡çš„ãªæ¢ç´¢ã¨å¤šæ§˜ãªæ¨è«–ã«é‡è¦ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1968876133656436811?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å ±é…¬ã‚’æœ€å¤§åŒ–ã™ã‚‹ã®ã§ã¯ãªãã€å ±é…¬åˆ†å¸ƒã‚’ä¸€è‡´ã•ã›ã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ã‚‰ã—ã„</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1969324905121345687?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2899" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Illusion of Thinking: Understanding the Strengths and Limitations of  Reasoning Models via the Lens of Problem Complexity, Parshin Shojaee+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LRMsã¯æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ãŒã€ãã®èƒ½åŠ›ã‚„é™ç•Œã¯æœªè§£æ˜ã€‚è©•ä¾¡ã¯ä¸»ã«æœ€çµ‚å›ç­”ã®æ­£ç¢ºæ€§ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€æ¨è«–ã®ç—•è·¡ã‚’æä¾›ã—ãªã„ã€‚æœ¬ç ”ç©¶ã§ã¯åˆ¶å¾¡å¯èƒ½ãªãƒ‘ã‚ºãƒ«ç’°å¢ƒã‚’ç”¨ã„ã¦ã€LRMsã®æ¨è«–éç¨‹ã‚’åˆ†æã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€LRMsã¯ç‰¹å®šã®è¤‡é›‘ã•ã‚’è¶…ãˆã‚‹ã¨æ­£ç¢ºæ€§ãŒå´©å£Šã—ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®é™ç•ŒãŒæ˜ã‚‰ã‹ã«ã€‚ä½è¤‡é›‘æ€§ã§ã¯æ¨™æº–ãƒ¢ãƒ‡ãƒ«ãŒå„ªä½ã€ä¸­è¤‡é›‘æ€§ã§ã¯LRMsãŒå„ªä½ã€é«˜è¤‡é›‘æ€§ã§ã¯ä¸¡è€…ãŒå´©å£Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚æ¨è«–ã®ç—•è·¡ã‚’èª¿æŸ»ã—ã€LRMsã®å¼·ã¿ã¨é™ç•Œã‚’æ˜ã‚‰ã‹ã«ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/parshinshojaee/status/1968812151138918541?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å‡ºãŸå½“åˆç›¸å½“è©±é¡Œã«ãªã£ãŸIllusion of thinkingãŒNeurIPSã«acceptã•ã‚ŒãŸæ¨¡æ§˜ã€‚Appendix A.1ã«å½“æ™‚ã®criticismã«å¯¾ã™ã‚‹ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2898" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BREAD: Branched Rollouts from Expert Anchors Bridge SFT &amp; RL for   Reasoning, Xuechen Zhang+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- å°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆSLMsï¼‰ã¯ã€ãƒˆãƒ¬ãƒ¼ã‚¹ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã«è¤‡é›‘ãªæ¨è«–ã‚’å­¦ã¶ã®ãŒé›£ã—ã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€SFT + RLã®é™ç•Œã‚’èª¿æŸ»ã—ã€BREADã¨ã„ã†æ–°ã—ã„æ‰‹æ³•ã‚’ææ¡ˆã€‚BREADã¯ã€å°‚é–€å®¶ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’ç”¨ã„ã¦SFTã¨RLã‚’çµ±åˆã—ã€å¤±æ•—ã—ãŸãƒˆãƒ¬ãƒ¼ã‚¹ã«å¯¾ã—ã¦çŸ­ã„ãƒ’ãƒ³ãƒˆã‚’æŒ¿å…¥ã™ã‚‹ã“ã¨ã§æˆåŠŸã‚’ä¿ƒé€²ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒç´„3å€é€Ÿããªã‚Šã€æ¨™æº–çš„ãªGRPOã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚BREADã¯ã€SLMã®æ¨è«–èƒ½åŠ›ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sametoymac/status/1968892463382200391?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2897" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Trust, But Verify: A Self-Verification Approach to Reinforcement   Learning with Verifiable Rewards, Xiaoyuan Liu+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- RISEã¨ã„ã†æ–°ã—ã„ã‚ªãƒ³ãƒ©ã‚¤ãƒ³RLãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€LLMã®å•é¡Œè§£æ±ºèƒ½åŠ›ã¨è‡ªå·±æ¤œè¨¼èƒ½åŠ›ã‚’åŒæ™‚ã«å‘ä¸Šã•ã›ã‚‹ã€‚çµæœæ¤œè¨¼è€…ã‹ã‚‰ã®å ±é…¬ã‚’æ´»ç”¨ã—ã€è§£æ±ºç­–ç”Ÿæˆã¨è‡ªå·±æ¤œè¨¼ã«å³æ™‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€RISEã¯å•é¡Œè§£æ±ºç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€è‡ªå·±æ¤œè¨¼ã‚¹ã‚­ãƒ«ã‚’è‚²æˆã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚RISEã¯å …ç‰¢ã§è‡ªå·±èªè­˜ã®ã‚ã‚‹æ¨è«–è€…ã‚’è‚²æˆã™ã‚‹ãŸã‚ã®åŠ¹æœçš„ãªæ‰‹æ³•ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tuzhaopeng/status/1968673346834330043?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Self-Verificationã®èƒ½åŠ›ãŒå¤§å¹…ã«å‘ä¸Šã™ã‚‹ã®ã¯è‰¯ã•ãã†ã€‚</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2896" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MergeBench: A Benchmark for Merging Domain-Specialized LLMs, Yifei He+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ³ã‚°ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŠ¹ç‡çš„ãªãƒ‡ãƒ—ãƒ­ã‚¤ã‚’å¯èƒ½ã«ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ³ã‚°ã‚’å¤§è¦æ¨¡ã«è©•ä¾¡ã™ã‚‹ãŸã‚ã®è©•ä¾¡ã‚¹ã‚¤ãƒ¼ãƒˆã€ŒMergeBenchã€ã‚’å°å…¥ã—ã€æŒ‡ç¤ºéµå®ˆã‚„æ•°å­¦ã€å¤šè¨€èªç†è§£ãªã©5ã¤ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ã‚«ãƒãƒ¼ã—ã¾ã™ã€‚8ã¤ã®ãƒãƒ¼ã‚¸ãƒ³ã‚°æ‰‹æ³•ã‚’è©•ä¾¡ã—ã€ã‚ˆã‚Šå¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒã‚ˆã‚Šè‰¯ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã™ã‚‹å‚¾å‘ã‚’ç¤ºã—ã¾ã—ãŸãŒã€å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®è¨ˆç®—ã‚³ã‚¹ãƒˆã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³å†…ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ã‚®ãƒ£ãƒƒãƒ—ãªã©ã®èª²é¡Œã‚‚æ®‹ã£ã¦ã„ã¾ã™ã€‚MergeBenchã¯ä»Šå¾Œã®ç ”ç©¶ã®åŸºç›¤ã¨ãªã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://yifei-he.github.io/mergebench/" target="_blank" rel="noopener noreferrer">https://yifei-he.github.io/mergebench/</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2895" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Leaderboard Illusion, Shivalika Singh+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- é€²æ—æ¸¬å®šã¯ç§‘å­¦ã®é€²å±•ã«ä¸å¯æ¬ ã§ã‚ã‚Šã€Chatbot Arenaã¯AIã‚·ã‚¹ãƒ†ãƒ ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«ãŠã„ã¦é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€éå…¬é–‹ã®ãƒ†ã‚¹ãƒˆæ…£è¡ŒãŒå­˜åœ¨ã—ã€ç‰¹å®šã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒæœ‰åˆ©ã«ãªã‚‹ã“ã¨ã§ã€ã‚¹ã‚³ã‚¢ã«ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚ç‰¹ã«ã€Metaã®Llama-4ã«é–¢é€£ã™ã‚‹ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆLLMãƒãƒªã‚¢ãƒ³ãƒˆãŒå•é¡Œè¦–ã•ã‚Œã€ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ã®éå¯¾ç§°æ€§ãŒç”Ÿã˜ã¦ã„ã‚‹ã€‚Googleã‚„OpenAIã¯Arenaãƒ‡ãƒ¼ã‚¿ã®å¤§éƒ¨åˆ†ã‚’å ã‚ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆãƒ¢ãƒ‡ãƒ«ã¯å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã—ã‹å—ã‘å–ã£ã¦ã„ãªã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Arenaç‰¹æœ‰ã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã¸ã®éå‰°é©åˆãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã€‚ç ”ç©¶ã¯ã€Chatbot Arenaã®è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®æ”¹é©ã¨ã€å…¬æ­£ã§é€æ˜æ€§ã®ã‚ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°ã®ä¿ƒé€²ã«å‘ã‘ãŸæè¨€ã‚’è¡Œã£ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/singhshiviii/status/1968756900062753080?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è¦ãƒã‚§ãƒƒã‚¯</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/Inpainting.html" target="_blank" rel="noopener noreferrer">#Inpainting</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2894" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Inpainting-Guided Policy Optimization for Diffusion Large Language  Models, Siyan Zhao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- dLLMsã¯ã‚¤ãƒ³ãƒšã‚¤ãƒ³ãƒ†ã‚£ãƒ³ã‚°èƒ½åŠ›ã‚’æ´»ç”¨ã—ã€å¼·åŒ–å­¦ç¿’ã®æ¢ç´¢èª²é¡Œã‚’è§£æ±ºã™ã‚‹IGPOãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚éƒ¨åˆ†çš„ãªçœŸå®Ÿã®æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’æŒ¿å…¥ã—ã€æ¢ç´¢ã‚’æœ‰æœ›ãªè»Œé“ã«å°ãã€‚ã“ã‚Œã«ã‚ˆã‚Šã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ãŒå‘ä¸Šã—ã€GSM8Kã€Math500ã€AMCã®æ•°å­¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ–°ãŸãªæœ€å…ˆç«¯çµæœã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1968875179934892175?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>éƒ¨åˆ†çš„ã«traceã®æ­£è§£ã‚’ä¸ãˆã‚‹ã¨ã€æ­£è§£ã®æ–¹å‘ã«ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã‚‹ã®ã§å¤šæ§˜æ€§ãŒçŠ ç‰²ã«ãªã‚‹æ°—ã‚‚ã™ã‚‹ãŒã€ãã®è¾ºã¯ã©ã†ãªã‚“ã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Bias.html" target="_blank" rel="noopener noreferrer">#Bias</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/PseudoLabeling.html" target="_blank" rel="noopener noreferrer">#PseudoLabeling</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2892" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self Iterative Label Refinement via Robust Unlabeled Learning, Hikaru Asano+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±æ´—ç·´æ‰‹æ³•ã‚’ç”¨ã„ã¦ã€LLMã®æ“¬ä¼¼ãƒ©ãƒ™ãƒ«ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®åå¾©æ´—ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ææ¡ˆã€‚ãƒ©ãƒ™ãƒ«ãªã—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ´»ç”¨ã—ã€å†…éƒ¨ãƒã‚¤ã‚¢ã‚¹ã‚’è»½æ¸›ã—ã¤ã¤ã€åˆ†é¡ã‚¿ã‚¹ã‚¯ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã€‚å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡ã—ã€æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yukino/status/1968863204517302511?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£ç ”ç©¶(Pseudo Labeling):<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2902" target="_blank" rel="noopener noreferrer">[Paper Note] Training a Helpful and Harmless Assistant with Reinforcement Learning
  from Human Feedback, Yuntao Bai+, arXiv'22</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2890" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OS-Harm: A Benchmark for Measuring Safety of Computer Use Agents, Thomas Kuntz+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ä½¿ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®‰å…¨æ€§ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯OS-Harmã‚’å°å…¥ã€‚OS-Harmã¯ã€æ„å›³çš„ãªèª¤ç”¨ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³æ”»æ’ƒã€ä¸é©åˆ‡ãªè¡Œå‹•ã®3ã¤ã®å±å®³ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹150ã®ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ã€‚è‡ªå‹•ã‚¸ãƒ£ãƒƒã‚¸ã‚’ç”¨ã„ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ­£ç¢ºæ€§ã¨å®‰å…¨æ€§ã‚’è©•ä¾¡ã—ã€é«˜ã„ä¸€è‡´ç‡ã‚’é”æˆã€‚æœ€å‰ç·šãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã‹ã‚‰ã€æ„å›³çš„ãªèª¤ç”¨ã«å¾“ã†å‚¾å‘ã‚„è„†å¼±æ€§ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚OS-Harmã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®‰å…¨æ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/maksym_andr/status/1968731692547346549?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2886" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Evolving Language Models without Labels: Majority Drives Selection,  Novelty Promotes Variation, Yujun Zhou+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- EVOL-RLã¯ã€ãƒ©ãƒ™ãƒ«ãªã—ã®å¼·åŒ–å­¦ç¿’æ‰‹æ³•ã§ã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®æ¢ç´¢èƒ½åŠ›ã¨ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’ç¶­æŒã—ã¤ã¤ã€å®‰å®šæ€§ã¨å¤‰å‹•ã‚’çµã³ã¤ã‘ã‚‹ã€‚å¤šæ•°æ±ºã§é¸ã°ã‚ŒãŸå›ç­”ã‚’å®‰å®šã—ãŸã‚¢ãƒ³ã‚«ãƒ¼ã¨ã—ã¦ä¿æŒã—ã€æ–°è¦æ€§ã‚’æ„è­˜ã—ãŸå ±é…¬ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ç”Ÿæˆç‰©ã®å¤šæ§˜æ€§ã‚’ä¿ã¡ã€æ€è€ƒã®é€£é–ã‚’æ”¹å–„ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€EVOL-RLã¯TTRLãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€ç‰¹ã«ãƒ©ãƒ™ãƒ«ãªã—ã®AIME24ã§ã®è¨“ç·´ã«ãŠã„ã¦é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wyu_nd/status/1968851567953485828?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1968931244877439435?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2677" target="_blank" rel="noopener noreferrer">[Paper Note] Jointly Reinforcing Diversity and Quality in Language Model Generations, Tianjian Li+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2863" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LMFusion: Adapting Pretrained Language Models for Multimodal Generation, Weijia Shi+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- LMFusionã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®LLMã«ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç”Ÿæˆèƒ½åŠ›ã‚’ä»˜ä¸ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã®ç†è§£ãƒ»ç”Ÿæˆã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚æ—¢å­˜ã®Llama-3ã®é‡ã¿ã‚’æ´»ç”¨ã—ã€ç”»åƒå‡¦ç†ã®ãŸã‚ã®ä¸¦åˆ—ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¿½åŠ ã€‚å„ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã¯ç‹¬ç«‹ã—ã¦å‡¦ç†ã•ã‚Œã€ç›¸äº’ä½œç”¨ãŒå¯èƒ½ã§ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€LMFusionã¯ç”»åƒç†è§£ã‚’20%ã€ç”Ÿæˆã‚’3.6%å‘ä¸Šã•ã›ã€Llama-3ã®è¨€èªèƒ½åŠ›ã‚’ç¶­æŒã—ã¤ã¤ã€åŠ¹ç‡çš„ã«ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/weijiashi2/status/1870107645677568248?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ˆè¡Œç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2930" target="_blank" rel="noopener noreferrer">[Paper Note] Transfusion: Predict the Next Token and Diffuse Images with One   Multi-Modal Model, Chunting Zhou+, ICLR'25, 2024.08</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2931" target="_blank" rel="noopener noreferrer">[Paper Note] U-Net: Convolutional Networks for Biomedical Image Segmentation, Olaf Ronneberger+, MICCAI'15, 2015.05</a>
</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2855" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebSailor: Navigating Super-human Reasoning for Web Agent, Kuan Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- WebSailorã¯ã€LLMã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦äººé–“ã®èªçŸ¥çš„é™ç•Œã‚’è¶…ãˆã‚‹ãŸã‚ã®ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã§ã‚ã‚Šã€è¤‡é›‘ãªæƒ…å ±æ¢ç´¢ã‚¿ã‚¹ã‚¯ã§ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚æ§‹é€ åŒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚„æƒ…å ±ã®é›£èª­åŒ–ã€DUPOã‚’ç”¨ã„ã¦é«˜ä¸ç¢ºå®Ÿæ€§ã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆã—ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2854" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebDancer: Towards Autonomous Information Seeking Agency, Jialong Wu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è¤‡é›‘ãªå•é¡Œè§£æ±ºã®ãŸã‚ã«ã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®æƒ…å ±æ¢ç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ä¸€è²«ã—ãŸãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ææ¡ˆã€‚4ã¤ã®ä¸»è¦ã‚¹ãƒ†ãƒ¼ã‚¸ï¼ˆãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰ã€è»Œè·¡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€å¼·åŒ–å­¦ç¿’ï¼‰ã‚’çµŒã¦ã€WebDancerã‚’å®Ÿè£…ã€‚GAIAã¨WebWalkerQAã§ã®è©•ä¾¡ã«ã‚ˆã‚Šã€å¼·åŠ›ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã®æœ‰åŠ¹æ€§ã‚’ç¢ºèªã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹äºˆå®šã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2853" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language  Models in Chinese, Peilin Zhou+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- BrowseComp-ZHã¯ã€ä¸­å›½ã®ã‚¦ã‚§ãƒ–ä¸Šã§LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸé«˜é›£æ˜“åº¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€289ã®ãƒãƒ«ãƒãƒ›ãƒƒãƒ—è³ªå•ã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹ã€‚äºŒæ®µéšã®å“è³ªç®¡ç†ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’é©ç”¨ã—ã€20ä»¥ä¸Šã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ãŸçµæœã€ã»ã¨ã‚“ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒ10%æœªæº€ã®ç²¾åº¦ã§è‹¦æˆ¦ã—ã€æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚42.9%ã«ã¨ã©ã¾ã£ãŸã€‚ã“ã®çµæœã¯ã€åŠ¹æœçš„ãªæƒ…å ±å–å¾—æˆ¦ç•¥ã¨æ´—ç·´ã•ã‚ŒãŸæ¨è«–èƒ½åŠ›ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2451" target="_blank" rel="noopener noreferrer">[Paper Note] BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents, Jason Wei+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2851" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebWalker: Benchmarking LLMs in Web Traversal, Jialong Wu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- WebWalkerQAã‚’å°å…¥ã—ã€LLMãŒã‚¦ã‚§ãƒ–ã®ã‚µãƒ–ãƒšãƒ¼ã‚¸ã‹ã‚‰é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹èƒ½åŠ›ã‚’è©•ä¾¡ã€‚æ¢æŸ»-æ‰¹è©•ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ç”¨ã„ãŸãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯WebWalkerã‚’ææ¡ˆã—ã€å®Ÿé¨“ã«ã‚ˆã‚ŠRAGã®åŠ¹æœã‚’å®Ÿè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>web pageã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¾¿ã‚‰ãªã„ã¨å›ç­”ã§ããªã„QAã§æ§‹æˆã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br><img src="https://github.com/user-attachments/assets/ca40f887-18ad-469e-83c8-1cbf3eb86e39" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2847" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Shared Imagination: LLMs Hallucinate Alike, Yilun Zhou+, TMLR'25, 2025.08</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®é¡ä¼¼æ€§ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€æƒ³åƒä¸Šã®è³ªå•å¿œç­”ï¼ˆIQAï¼‰ã¨ã„ã†æ–°ã—ã„è¨­å®šã‚’ææ¡ˆã€‚IQAã§ã¯ã€1ã¤ã®ãƒ¢ãƒ‡ãƒ«ãŒæ¶ç©ºã®è³ªå•ã‚’ç”Ÿæˆã—ã€åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ãŒãã‚Œã«ç­”ãˆã‚‹ã€‚é©šãã¹ãã“ã¨ã«ã€å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒãƒ•ã‚£ã‚¯ã‚·ãƒ§ãƒ³ã®è³ªå•ã«æˆåŠŸè£ã«å¿œç­”ã§ãã‚‹ã“ã¨ã‹ã‚‰ã€å…±é€šã®ã€Œæƒ³åƒç©ºé–“ã€ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚ã“ã®ç¾è±¡ã«ã¤ã„ã¦èª¿æŸ»ã—ã€ãƒ¢ãƒ‡ãƒ«ã®å‡è³ªæ€§ã‚„å¹»è¦šã€è¨ˆç®—çš„å‰µé€ æ€§ã«é–¢ã™ã‚‹è€ƒå¯Ÿã‚’è¡Œã†ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=NUXpBMtDYs" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=NUXpBMtDYs</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tmlrpub/status/1968449957343433191?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2843" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning, Guo+, Nature'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMsã®æ¨è«–èƒ½åŠ›ã‚’å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã‚’é€šã˜ã¦å‘ä¸Šã•ã›ã€äººé–“ã«ã‚ˆã‚‹ãƒ©ãƒ™ãƒ«ä»˜ã‘ã®å¿…è¦æ€§ã‚’æ’é™¤ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ææ¡ˆã™ã‚‹RLãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€é«˜åº¦ãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç™ºå±•ã‚’ä¿ƒé€²ã—ã€æ•°å­¦ã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ãªã©ã®ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã™ã‚‹ã€‚ã•ã‚‰ã«ã€å‡ºç¾çš„ãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯å°ã•ãªãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›å‘ä¸Šã«ã‚‚å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>DeepSeek-R1ã®è«–æ–‡ã®Natureç‰ˆãŒå‡ºãŸæ¨¡æ§˜ã€‚</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1968800470496915547?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Supplementary Materials:


<a href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-025-09422-z/MediaObjects/41586_2025_9422_MOESM1_ESM.pdf" target="_blank" rel="noopener noreferrer">https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-025-09422-z/MediaObjects/41586_2025_9422_MOESM1_ESM.pdf</a>


<br><br>ãŠãã‚‰ãã“ã¡ã‚‰ã®æ–¹ãŒé‡è¦</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2840" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RL Fine-Tuning Heals OOD Forgetting in SFT, Hangzhan Jin+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- äºŒæ®µéšãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹SFTã¨RLã®ç›¸äº’ä½œç”¨ã‚’æ¢æ±‚ã—ã€SFTãŒè¨˜æ†¶ã—ã€RLãŒä¸€èˆ¬åŒ–ã™ã‚‹ã¨ã„ã†ä¸»å¼µãŒéåº¦ã«å˜ç´”åŒ–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚å…·ä½“çš„ã«ã¯ã€(1) OODæ€§èƒ½ã¯SFTã®åˆæœŸæ®µéšã§ãƒ”ãƒ¼ã‚¯ã«é”ã—ã€ãã®å¾Œä½ä¸‹ã™ã‚‹ã“ã¨ã€(2) RLã¯SFTä¸­ã«å¤±ã‚ã‚ŒãŸæ¨è«–èƒ½åŠ›ã‚’å›å¾©ã™ã‚‹å½¹å‰²ã‚’æœãŸã™ã“ã¨ã€(3) å›å¾©èƒ½åŠ›ã«ã¯é™ç•ŒãŒã‚ã‚‹ã“ã¨ã€(4) OODã®æŒ™å‹•ã¯ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ã®ã€Œå›è»¢ã€ã¨å¼·ãç›¸é–¢ã™ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€SFTã¨RLã®å½¹å‰²ã‚’å†èªè­˜ã—ã€ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ã®å›è»¢ãŒé‡è¦ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1740" target="_blank" rel="noopener noreferrer">SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model   Post-training, Tianzhe Chu+, ICML'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2700" target="_blank" rel="noopener noreferrer">[Paper Note] Towards a Unified View of Large Language Model Post-Training, Xingtai Lv+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2713" target="_blank" rel="noopener noreferrer">[Paper Note] RL's Razor: Why Online Reinforcement Learning Forgets Less, Idan Shenfeld+, arXiv'25</a>
<br><br>ã¨åˆã‚ã›ã¦èª­ã‚€ã¨è‰¯ã•ãã†</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1968187719588385240?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç›´æ„Ÿçš„ã«ã¯ã€ä¸‹è¨˜ç ”ç©¶ã§SFTã‚’RLã®è¦³ç‚¹ã§è¦‹ãŸã¨ãã«ã€å›ç­”ã®è»Œè·¡ã«å¯¾ã—ã¦exact matchã—ã¦ã„ãŸå ´åˆã«1ã‚’è¿”ã™å ±é…¬ã‚’æŒã¤RLã€ã‹ã¤importance weightingã«ã‚ˆã£ã¦ç¾åœ¨ã®ãƒãƒªã‚·ãƒ¼ãŒè‹¦æ‰‹ãªè»Œè·¡ã‚’é‡è¦è¦–ã™ã‚‹ã€ã¨ã„ã†ã“ã¨è€ƒãˆã‚‹ã¨ã€ç›®çš„ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æ±åŒ–æ€§èƒ½ãŠã‹ã¾ã„ãªã—ã«greedyã«æœ€é©åŒ–ã•ã‚Œã‚‹ãŸã‚ã€OODã¸ã®å¯¾å¿œåŠ›ãŒç„¡ããªã‚‹ã€ã¨ã„ã†ã®ã¯ãªã‚“ã¨ãªãç†è§£ã§ãã‚‹ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2838" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Conan-Embedding-v2: Training an LLM from Scratch for Text Embeddings, Shiyu Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„1.4Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®LLMã€ŒConan-embedding-v2ã€ã‚’ã‚¼ãƒ­ã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿å™¨ã¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã¨å¤šè¨€èªãƒšã‚¢ã‚’è¿½åŠ ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã€ã‚¯ãƒ­ã‚¹ãƒªãƒ³ã‚¬ãƒ«ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å°å…¥ã€‚ã‚½ãƒ•ãƒˆãƒã‚¹ã‚­ãƒ³ã‚°ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ç”¨ã„ã¦ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã¨æ–‡ãƒ¬ãƒ™ãƒ«ã®æå¤±ã‚’çµ±åˆã—ã€å‹•çš„ãƒãƒ¼ãƒ‰ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒã‚¤ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’æ¡ç”¨ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€MTEBãŠã‚ˆã³Chinese MTEBã§SOTAæ€§èƒ½ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1968167110758240679?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/IRT.html" target="_blank" rel="noopener noreferrer">#IRT</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2837" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Fluid Language Model Benchmarking, Valentin Hofmann+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- Fluid Benchmarkingã¨ã„ã†æ–°ã—ã„è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLMï¼‰è©•ä¾¡ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€LMã®èƒ½åŠ›ã«å¿œã˜ã¦è©•ä¾¡é …ç›®ã‚’å‹•çš„ã«é¸æŠã—ã€è©•ä¾¡ã®è³ªã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“ã§ã¯ã€Fluid BenchmarkingãŒåŠ¹ç‡ã€å¦¥å½“æ€§ã€åˆ†æ•£ã€é£½å’Œã®4ã¤ã®æ¬¡å…ƒã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€é™çš„è©•ä¾¡ã‚’è¶…ãˆã‚‹ã“ã¨ã§LMãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æ”¹å–„ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/allen_ai/status/1967983841336836491?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vjhofmann/status/1967994756795077097?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2835" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MachineLearningLM: Scaling Many-shot In-context Learning via Continued  Pretraining, Haoyu Dong+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MachineLearningLMã¯ã€LLMã«ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’èƒ½åŠ›ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã®ç¶™ç¶šçš„äº‹å‰å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€æ•°ç™¾ä¸‡ã®MLã‚¿ã‚¹ã‚¯ã‚’åˆæˆã™ã‚‹ã€‚ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆæ•™å¸«ã‚’ç”¨ã„ã¦æ„æ€æ±ºå®šæˆ¦ç•¥ã‚’è’¸ç•™ã—ã€æ•°å€¤ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®å …ç‰¢æ€§ã‚’å‘ä¸Šã€‚æ§ãˆã‚ãªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã§ã‚‚ã€é‡‘èã‚„åŒ»ç™‚åˆ†é‡ã§å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ç´„15%ä¸Šå›ã‚Šã€ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å¢—åŠ ã«ä¼´ã„ç²¾åº¦ãŒå‘ä¸Šã€‚ä¸€èˆ¬çš„ãªãƒãƒ£ãƒƒãƒˆèƒ½åŠ›ã‚‚ä¿æŒã—ã€MMLUã§75.4%ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1968246426552729743?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2834" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ReSum: Unlocking Long-Horizon Search Intelligence via Context  Summarization, Xixi Wu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ReSumã¨ã„ã†æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’å°å…¥ã—ã€å®šæœŸçš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã‚’é€šã˜ã¦ç„¡é™ã®æ¢ç´¢ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚ReSum-GRPOã‚’ææ¡ˆã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè¦ç´„æ¡ä»¶ä»˜ãæ¨è«–ã«æ…£ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ReSumã¯ReActã«å¯¾ã—ã¦å¹³å‡4.5ï¼…ã®æ”¹å–„ã‚’ç¤ºã—ã€WebResummer-30Bã¯æ—¢å­˜ã®ã‚¦ã‚§ãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1968161796642279549?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Planning.html" target="_blank" rel="noopener noreferrer">#Planning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2833" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for  Open-Ended Deep Research, Zijian Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚¦ã‚§ãƒ–æƒ…å ±ã‚’çµ±åˆã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰æ·±å±¤ç ”ç©¶ï¼ˆOEDRï¼‰ã«å–ã‚Šçµ„ã¿ã€WebWeaverã¨ã„ã†æ–°ã—ã„äºŒé‡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ãŒè¨¼æ‹ å–å¾—ã¨ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³æœ€é©åŒ–ã‚’äº¤äº’ã«è¡Œã„ã€ãƒ©ã‚¤ã‚¿ãƒ¼ãŒæƒ…å ±ã‚’éšå±¤çš„ã«æ¤œç´¢ã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã‚’æ§‹æˆã™ã‚‹ã“ã¨ã§ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å•é¡Œã‚’è»½æ¸›ã€‚ææ¡ˆæ‰‹æ³•ã¯ä¸»è¦ãªOEDRãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ–°ãŸãªæœ€å…ˆç«¯ã‚’ç¢ºç«‹ã—ã€é«˜å“è³ªãªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«ãŠã‘ã‚‹äººé–“ä¸­å¿ƒã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®é‡è¦æ€§ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1968161793127416197?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2832" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Agents via Continual Pre-training, Liangcai Su+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ç”¨ã„ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã¯ã€è¤‡é›‘ãªå•é¡Œè§£æ±ºã«ãŠã„ã¦é€²åŒ–ã—ã¦ã„ã‚‹ãŒã€ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ã“ã¨ãŒå¤šã„ã€‚ã“ã‚Œã¯ã€å …ç‰¢ãªåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®æ¬ å¦‚ãŒåŸå› ã§ã‚ã‚‹ã€‚ãã“ã§ã€ç¶™ç¶šçš„ãªäº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆAgentic CPTï¼‰ã‚’å°å…¥ã—ã€å¼·åŠ›ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã‚’ææ¡ˆã€‚æ–°ãŸã«é–‹ç™ºã—ãŸAgentFounderãƒ¢ãƒ‡ãƒ«ã¯ã€10ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ç‰¹ã«BrowseComp-enã§39.9%ã€BrowseComp-zhã§43.3%ã€HLEã§ã®Pass@1ã§31.5%ã‚’è¨˜éŒ²ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1968161789583196253?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>AI Agentã®ãŸã‚ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’ç¶™ç¶šäº‹å‰å­¦ç¿’ã«ã‚ˆã£ã¦å®Ÿç¾ã—ãŸæ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/MCP.html" target="_blank" rel="noopener noreferrer">#MCP</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2831" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Towards General Agentic Intelligence via Environment Scaling, Runnan Fang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçŸ¥èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ç’°å¢ƒã‚’æ‹¡å¤§ã—ã€é–¢æ•°å‘¼ã³å‡ºã—èƒ½åŠ›ã‚’å¼·åŒ–ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨“ç·´ã¯äºŒæ®µéšã§è¡Œã„ã€åŸºæœ¬èƒ½åŠ›ã‚’ä»˜ä¸ã—ãŸå¾Œã€ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ç‰¹åŒ–ã•ã›ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆãƒ¢ãƒ‡ãƒ«AgentScalerãŒé–¢æ•°å‘¼ã³å‡ºã—èƒ½åŠ›ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1968161785695133948?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>blog:


<a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/" target="_blank" rel="noopener noreferrer">https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2830" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon  Agents, Zile Qiao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒWebResearcherã€ã‚’ææ¡ˆã—ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå¤–éƒ¨ã‚½ãƒ¼ã‚¹ã‹ã‚‰çŸ¥è­˜ã‚’è‡ªå¾‹çš„ã«ç™ºè¦‹ãƒ»çµ±åˆã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€‚WebResearcherã¯ã€æ·±å±¤ç ”ç©¶ã‚’ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹ã¨ã—ã¦å†å®šå¼åŒ–ã—ã€å ±å‘Šæ›¸ã«ç™ºè¦‹ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§æ–‡è„ˆã®å•é¡Œã‚’å…‹æœã€‚ã¾ãŸã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒ‡ãƒ¼ã‚¿åˆæˆã‚¨ãƒ³ã‚¸ãƒ³ã€ŒWebFrontierã€ã‚’ç”¨ã„ã¦é«˜å“è³ªãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€ãƒ„ãƒ¼ãƒ«ä½¿ç”¨èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€WebResearcherã¯æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã—ã€å•†ç”¨ã‚·ã‚¹ãƒ†ãƒ ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1968161781878345880?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>blog:


<a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/" target="_blank" rel="noopener noreferrer">https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/</a>


</p>
<p>OpenAI DeepResearchã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã§åŒç­‰ã®æ€§èƒ½ã‚’å®Ÿç¾ã—ãŸopenweightãƒ¢ãƒ‡ãƒ«</p>
<p>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯: <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1730" target="_blank" rel="noopener noreferrer">[Paper Note] Humanity's Last Exam, Long Phan+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2451" target="_blank" rel="noopener noreferrer">[Paper Note] BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents, Jason Wei+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1158" target="_blank" rel="noopener noreferrer">GAIA: a benchmark for General AI Assistants, GrÃ©goire Mialon+, N/A, arXiv'23</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2851" target="_blank" rel="noopener noreferrer">[Paper Note] WebWalker: Benchmarking LLMs in Web Traversal, Jialong Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2852" target="_blank" rel="noopener noreferrer">[Paper Note] Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented   Generation, Satyapriya Krishna+, NAACL'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2853" target="_blank" rel="noopener noreferrer">[Paper Note] BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language
  Models in Chinese, Peilin Zhou+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<a class="button" href="articles/Reproducibility.html" target="_blank" rel="noopener noreferrer">#Reproducibility</a>
<a class="button" href="articles/MCP.html" target="_blank" rel="noopener noreferrer">#MCP</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2827" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI  Agents, Jiacheng Miao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Paper2Agentã¯ã€ç ”ç©¶è«–æ–‡ã‚’AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«è‡ªå‹•å¤‰æ›ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€ç ”ç©¶æˆæœã®åˆ©ç”¨ã‚„ç™ºè¦‹ã‚’åŠ é€Ÿã—ã¾ã™ã€‚å¾“æ¥ã®è«–æ–‡ã¯å†åˆ©ç”¨ã®éšœå£ã‚’ç”Ÿã‚“ã§ã„ã¾ã—ãŸãŒã€Paper2Agentã¯è«–æ–‡ã‚’çŸ¥è­˜è±Šå¯Œãªç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å¤‰æ›ã—ã¾ã™ã€‚è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç”¨ã„ã¦è«–æ–‡ã¨é–¢é€£ã‚³ãƒ¼ãƒ‰ã‚’åˆ†æã—ã€ãƒ¢ãƒ‡ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒˆã‚³ãƒ«ï¼ˆMCPï¼‰ã‚’æ§‹ç¯‰ã€æ´—ç·´ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è‡ªç„¶è¨€èªã‚’é€šã˜ã¦ç§‘å­¦çš„ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã§ãã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã—ã€å®Ÿéš›ã«ã‚²ãƒãƒ å¤‰ç•°ã‚„ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒŸã‚¯ã‚¹åˆ†æã‚’è¡Œã†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå…ƒã®è«–æ–‡ã®çµæœã‚’å†ç¾ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚Paper2Agentã¯ã€é™çš„ãªè«–æ–‡ã‚’å‹•çš„ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å¤‰ãˆã‚‹ã“ã¨ã§ã€çŸ¥è­˜ã®æ™®åŠã«æ–°ãŸãªãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>code:


<a href="https://github.com/jmiao24/Paper2Agent?tab=readme-ov-file#-demos" target="_blank" rel="noopener noreferrer">https://github.com/jmiao24/Paper2Agent?tab=readme-ov-file#-demos</a>


</p>
<p>è«–æ–‡ã‚’è«–æ–‡ãŒææ¡ˆã™ã‚‹æŠ€è¡“ã®æ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹MCPã‚µãƒ¼ãƒã«å¤‰æ›ã—ã€LLM Agentã‚’é€šã˜ã¦ãƒ¦ãƒ¼ã‚¶ã¯setupç„¡ã—ã«å‘¼ã³ã ã—ã¦åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹æŠ€è¡“ãªæ¨¡æ§˜ã€‚è«–æ–‡ã‹ã‚‰è‡ªå‹•çš„ã«codebaseã‚’åŒå®šã—ã€ã‚³ã‚¢ã¨ãªã‚‹æŠ€è¡“ã‚’MCP toolsã¨ã—ã¦ãƒ©ãƒƒãƒ—ã—ã€åå¾©çš„ãªãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½ã—ã¦ãƒ­ãƒã‚¹ãƒˆã«ã—ãŸä¸Šã§HFä¸Šã®AI Agentã«æä¾›ã™ã‚‹ã€ã¿ãŸã„ãªæ„Ÿã˜ã«è¦‹ãˆã‚‹ã€‚<br><br>&lt;img width="667" height="602" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/36dca631-c576-43e5-b8b8-77de555f0b6f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/36dca631-c576-43e5-b8b8-77de555f0b6f"&lt;/a&gt;


/&gt;</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1968829219858956774?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2826" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SWE-bench Multimodal: Do AI Systems Generalize to Visual Software   Domains?, John Yang+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå¾‹ã‚·ã‚¹ãƒ†ãƒ ã®ãƒã‚°ä¿®æ­£èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€SWE-bench Mã‚’ææ¡ˆã€‚ã“ã‚Œã¯è¦–è¦šè¦ç´ ã‚’å«ã‚€JavaScriptã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ã‚¿ã‚¹ã‚¯ã‚’å¯¾è±¡ã¨ã—ã€617ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åé›†ã€‚å¾“æ¥ã®SWE-benchã‚·ã‚¹ãƒ†ãƒ ãŒè¦–è¦šçš„å•é¡Œè§£æ±ºã«è‹¦åŠ´ã™ã‚‹ä¸­ã€SWE-agentã¯ä»–ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’å¤§ããä¸Šå›ã‚Šã€12%ã®ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=riTiq3i21b" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=riTiq3i21b</a>


</p>
<p>pj page:


<a href="https://www.swebench.com/multimodal.html" target="_blank" rel="noopener noreferrer">https://www.swebench.com/multimodal.html</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/Navigation.html" target="_blank" rel="noopener noreferrer">#Navigation</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2818" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Embodied Navigation Foundation Model, Jiazhao Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- NavFoMã¯ã€800ä¸‡ã®ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ³ãƒ—ãƒ«ã§è¨“ç·´ã•ã‚ŒãŸã‚¯ãƒ­ã‚¹å…·ç¾åŒ–ãƒ»ã‚¯ãƒ­ã‚¹ã‚¿ã‚¹ã‚¯ã®ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ãƒ“ã‚¸ãƒ§ãƒ³ã¨è¨€èªã®ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã‚„è‡ªå¾‹é‹è»¢ãªã©å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã€‚ç•°ãªã‚‹ã‚«ãƒ¡ãƒ©æ§‹æˆã‚„æ™‚é–“çš„è¦–é‡ã‚’è€ƒæ…®ã—ã€å‹•çš„ã«èª¿æ•´ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥ã‚’ç”¨ã„ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚å®Ÿä¸–ç•Œã§ã®å®Ÿé¨“ã§ã‚‚å¼·åŠ›ãªä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://pku-epic.github.io/NavFoM-Web/" target="_blank" rel="noopener noreferrer">https://pku-epic.github.io/NavFoM-Web/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1967806725387588069?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2817" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Forgetting Transformer: Softmax Attention with a Forget Gate, Zhixuan Lin+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- å¿˜å´ã‚²ãƒ¼ãƒˆã‚’å–ã‚Šå…¥ã‚ŒãŸãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã€ŒFoXã€ã‚’ææ¡ˆã€‚FoXã¯é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚„ä¸‹æµã‚¿ã‚¹ã‚¯ã§ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ä½ç½®åŸ‹ã‚è¾¼ã¿ã‚’å¿…è¦ã¨ã—ãªã„ã€‚å†å¸°çš„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã‚‚å„ªã‚ŒãŸèƒ½åŠ›ã‚’ä¿æŒã—ã€æ€§èƒ½å‘ä¸Šã®ãŸã‚ã®ã€ŒProã€ãƒ–ãƒ­ãƒƒã‚¯è¨­è¨ˆã‚’å°å…¥ã€‚ã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=q2Lnyegkr8" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=q2Lnyegkr8</a>


</p>
<p>code:


<a href="https://github.com/zhixuan-lin/forgetting-transformer" target="_blank" rel="noopener noreferrer">https://github.com/zhixuan-lin/forgetting-transformer</a>


</p>
<p>éå¸¸ã«ãŠã‚‚ã—ã‚ãã†</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Pruning.html" target="_blank" rel="noopener noreferrer">#Pruning</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2816" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Adaptive Computation Pruning for the Forgetting Transformer, Zhixuan Lin+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- Forgeting Transformerï¼ˆFoXï¼‰ã¯ã€å¿˜å´ã‚²ãƒ¼ãƒˆã‚’ç”¨ã„ãŸã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’ç‰¹å¾´ã¨ã—ã€å¾“æ¥ã®Transformerã¨æ¯”è¼ƒã—ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ã€‚FoXã®ç‰¹æ€§ã‚’æ´»ã‹ã—ã€é©å¿œè¨ˆç®—ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆACPï¼‰ã‚’ææ¡ˆã—ã€è¨ˆç®—ã‚’å‹•çš„ã«ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€FLOPsã¨ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ã‚’ç´„70%å‰Šæ¸›ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œæ™‚é–“ã‚’50%ã‹ã‚‰70%çŸ­ç¸®ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’10%ã‹ã‚‰40%å‘ä¸Šã•ã›ãŸã€‚æ€§èƒ½ã®åŠ£åŒ–ã¯ãªãã€é•·ã„æ–‡è„ˆé•·ã§ã¯ã•ã‚‰ãªã‚‹è¨ˆç®—ã‚³ã‚¹ãƒˆã®ç¯€ç´„ãŒå¯èƒ½ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>code:


<a href="https://github.com/zhixuan-lin/forgetting-transformer" target="_blank" rel="noopener noreferrer">https://github.com/zhixuan-lin/forgetting-transformer</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhxlin/status/1967596994362220761?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>openreview:


<a href="https://openreview.net/forum?id=xNj14CY5S1#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=xNj14CY5S1#discussion</a>


</p>
<p>å…ˆè¡Œç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2817" target="_blank" rel="noopener noreferrer">[Paper Note] Forgetting Transformer: Softmax Attention with a Forget Gate, Zhixuan Lin+, ICLR'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2815" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scalable Vision Language Model Training via High Quality Data Curation, Hongyuan Dong+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- SAIL-VLã¯ã€2BãŠã‚ˆã³8Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ“ã‚¸ãƒ§ãƒ³è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚ä¸»ãªæ”¹å–„ç‚¹ã¯ã€(1) é«˜å“è³ªãªè¦–è¦šç†è§£ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰ã€(2) æ‹¡å¤§ã—ãŸäº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹æ€§èƒ½å‘ä¸Šã€(3) è¤‡é›‘ã•ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹åŠ¹æœçš„ãªSFTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€‚SAIL-VLã¯18ã®VLMãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’é”æˆã—ã€2Bãƒ¢ãƒ‡ãƒ«ã¯åŒç­‰ã®VLMã®ä¸­ã§ãƒˆãƒƒãƒ—ã®ä½ç½®ã‚’å ã‚ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã¯HuggingFaceã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1967737399443623985?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/BytedanceDouyinContent" target="_blank" rel="noopener noreferrer">https://huggingface.co/BytedanceDouyinContent</a>


</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-09-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2811" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DeepDive: Advancing Deep Search Agents with Knowledge Graphs and  Multi-Turn RL, Rui Lu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- DeepDiveã¯ã€LLMsã«ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã‚’è¿½åŠ ã—ã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã®è§£æ±ºã‚’ç›®æŒ‡ã™æ·±ã„æ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ãªçŸ¥è­˜ã‚°ãƒ©ãƒ•ã‹ã‚‰é›£è§£ãªè³ªå•ã‚’è‡ªå‹•åˆæˆã—ã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å¼·åŒ–å­¦ç¿’ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã€é•·æœŸçš„ãªæ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€DeepDive-32Bã¯è¤‡æ•°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¨ä¸¦åˆ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å¯èƒ½ã«ã—ã¾ã—ãŸã€‚ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã¨ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/grad62304977/status/1967540231831523424?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-09-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2806" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Illusion of Diminishing Returns: Measuring Long Horizon Execution in  LLMs, Akshit Sinha+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒåç›Šã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã‹ã‚’æ¢æ±‚ã€‚å˜ä¸€ã‚¹ãƒ†ãƒƒãƒ—ã®ç²¾åº¦å‘ä¸ŠãŒã‚¿ã‚¹ã‚¯ã®é•·ã•ã«æŒ‡æ•°çš„æ”¹å–„ã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ã‚’è¦³å¯Ÿã€‚LLMsãŒé•·æœŸã‚¿ã‚¹ã‚¯ã§å¤±æ•—ã™ã‚‹ã®ã¯æ¨è«–èƒ½åŠ›ã®æ¬ å¦‚ã§ã¯ãªãå®Ÿè¡ŒãƒŸã‚¹ã«ã‚ˆã‚‹ã¨ä¸»å¼µã€‚çŸ¥è­˜ã¨è¨ˆç”»ã‚’æ˜ç¤ºçš„ã«æä¾›ã™ã‚‹ã“ã¨ã§å®Ÿè¡Œèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ææ¡ˆã€‚ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦ã‚‚è‡ªå·±æ¡ä»¶ä»˜ã‘åŠ¹æœã¯æ¸›å°‘ã›ãšã€é•·ã„ã‚¿ã‚¹ã‚¯ã§ã®ãƒŸã‚¹ãŒå¢—åŠ ã€‚æ€è€ƒãƒ¢ãƒ‡ãƒ«ã¯è‡ªå·±æ¡ä»¶ä»˜ã‘ã‚’è¡Œã‚ãšã«é•·ã„ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œå¯èƒ½ã€‚æœ€çµ‚çš„ã«ã€å®Ÿè¡Œèƒ½åŠ›ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã“ã¨ã§ã€LLMsã®è¤‡é›‘ãªæ¨è«–å•é¡Œè§£æ±ºèƒ½åŠ›ã¨å˜ç´”ã‚¿ã‚¹ã‚¯ã®é•·æœŸåŒ–ã«ã‚ˆã‚‹å¤±æ•—ç†ç”±ã‚’èª¿å’Œã•ã›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shashwatgoel7/status/1966527903568637972?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>single stepã§ã®ã‚¿ã‚¹ã‚¯æ€§èƒ½ã¯ã‚µãƒã£ã¦è¦‹ãˆã¦ã‚‚ã€æˆåŠŸå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®é•·ã•ã¯ï¼ˆsingle stepã®å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã«å¼•ãã¥ã‚‰ã‚Œã‚‹ãŸã‚ï¼‰ãƒ¢ãƒ‡ãƒ«ã®single stepã®ã‚¿ã‚¹ã‚¯æ€§èƒ½ã«å¯¾ã—ã¦æŒ‡æ•°é–¢æ•°çš„ã«åŠ¹ã„ã¦ã„ã‚‹ï¼ˆå·¦ä¸Šï¼‰ã€‚ã‚¿ã‚¹ã‚¯ãŒé•·ããªã‚Œã°ãªã‚‹ã»ã©ãƒ¢ãƒ‡ãƒ«ã¯è‡ªèº«ã®ã‚¨ãƒ©ãƒ¼ã«å¼•ããšã‚‰ã‚Œï¼ˆself conditioning;å³ä¸Š)ã€ã“ã‚Œã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¤§ãã„ã»ã©åº¦åˆã„ãŒå¤§ãããªã‚‹ï¼ˆå³ä¸‹;  32Bã®å ´åˆcontextã«ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦å ´åˆã®loeg horizonã®Acc.ãŒ14Bã‚ˆã‚Šã‚‚ä¸‹ãŒã£ã¦ã„ã‚‹ï¼‰ã€‚ä¸€æ–¹ã§ã€å®Ÿè¡Œå¯èƒ½ãªstepæ•°ã®è¦³ç‚¹ã§è¦‹ã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„å ´åˆã®æ–¹ãŒå¤šãã®stepã‚’è¦ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã§ãã‚‹ï¼ˆå·¦ä¸‹ï¼‰ã€‚ã¾ãŸã€Thinkingãƒ¢ãƒ‡ãƒ«ã¯Self Conditioningã®å½±éŸ¿ã‚’å—ã‘ã«ããã€single stepã§å®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®é•·ã•ãŒã‚ˆã‚Šé•·ããªã‚‹ï¼ˆä¸­å¤®ä¸‹ï¼‰ã€‚<br><br>ã¨ã„ã£ãŸè©±ã«è¦‹ãˆã‚‹ãŒã€è«–æ–‡ã‚’ã—ã£ã‹ã‚Šèª­ã‚“ã æ–¹ãŒè‰¯ã•ãã†ã€‚<br><br><img src="https://github.com/user-attachments/assets/a97fe1f4-5693-4ed3-9fa0-774f4c3738ab" alt="image" loading="lazy"></p>
<p>ï¼ˆå…ƒãƒã‚¹ãƒˆã‚‚è‘—è€…ãƒã‚¹ãƒˆã ãŒï¼‰è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/akshitwt/status/1966528585558303209?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã“ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã¯èª­ã‚“ã æ–¹ãŒè‰¯ã„ï¼ˆã¨ã„ã†ã‹è«–æ–‡ã‚’èª­ã‚“ã æ–¹ãŒè‰¯ã„ï¼‰ã€‚<br>ç‰¹ã«ã€**CoTãŒç„¡ã„å ´åˆã¯**single-turnã§ã»ã¨ã‚“ã©ã®ãƒ¢ãƒ‡ãƒ«ã¯5 stepã®ã‚¿ã‚¹ã‚¯ã‚’latent spaceã§æ€è€ƒã—ã€å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒã§ããªã„ã¨ã„ã†ã®ã¯èˆˆå‘³æ·±ã„ï¼ˆãŒã€ç´°ã‹ã„è¨­å®šã¯ç¢ºèªã—ãŸæ–¹ãŒè‰¯ã„ï¼‰ã€‚ãªã®ã§ã€ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¿ã‚¹ã‚¯ã¯åŸºæœ¬çš„ã«ã¯planningã‚’ã•ã›ã¦ã‹ã‚‰å‡ºåŠ›ã‚’ã•ã›ãŸæ–¹ãŒè‰¯ã„ã¨ã„ã†è©±ã‚„ã€<br><br>ã§ã¯è¤‡é›‘ãªstepãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã¯single turnã§ã¯ãªãmulti turnã«åˆ†ã‘ãŸæ–¹ãŒè‰¯ã„ã®ã‹ï¼Ÿã¨è¨€ã†ã¨ã€ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦å‚¾å‘ãŒé•ã†ã‚‰ã—ã„ã€ã¨ã„ã£ãŸè©±ãŒæ›¸ã‹ã‚Œã¦ã„ã‚‹ã€‚ãŸã¨ãˆã°ã€Qwenã¯single turnã‚’å¥½ã‚€ãŒã€Gemmaã¯multi turnã‚’å¥½ã‚€ã‚‰ã—ã„ã€‚<p>æ—¥æœ¬èªãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwashi86/status/1966969350197571833?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1968453604655907143?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-09-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2805" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] EviNote-RAG: Enhancing RAG Models via Answer-Supportive Evidence Notes, Yuqin Dai+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- EviNote-RAGã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‰ãƒ¡ã‚¤ãƒ³ã®QAã«ãŠã‘ã‚‹ã€Œå–å¾—-ãƒãƒ¼ãƒˆ-å›ç­”ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å°å…¥ã—ãŸæ–°ã—ã„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å–å¾—ã•ã‚ŒãŸæƒ…å ±ã‹ã‚‰æœ‰ç”¨ãªå†…å®¹ã‚’æŠ½å‡ºã—ã€ä¸ç¢ºå®Ÿæ€§ã‚’å¼·èª¿ã™ã‚‹Supportive-Evidence Notesï¼ˆSENsï¼‰ã‚’ç”Ÿæˆã—ã¾ã™ã€‚Evidence Quality Rewardï¼ˆEQRï¼‰ã‚’ç”¨ã„ã¦æ¨è«–ã®ä¿¡é ¼æ€§ã‚’é«˜ã‚ã€ãƒã‚¤ã‚ºã®å½±éŸ¿ã‚’è»½æ¸›ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€EviNote-RAGãŒç²¾åº¦ã‚„å®‰å®šæ€§ã«ãŠã„ã¦å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€ç‰¹ã«HotpotQAã‚„Bamboogleã€2Wikiã§é¡•è‘—ãªF1ã‚¹ã‚³ã‚¢ã®å‘ä¸Šã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwashi86/status/1966971369264214399?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>-  <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1140" target="_blank" rel="noopener noreferrer">Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language   Models, Wenhao Yu+, N/A, EMNLP'24</a>
<br><br>ã¨ã®é•ã„ã¯ãªã‚“ã ã‚ã†ã‹ï¼Ÿã–ã£ã¨æ¤œç´¢ã—ãŸæ„Ÿã˜ã€å¼•ç”¨ã•ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p>
<p>ã–ã£ãã‚Šã¨ã—ã‹èª­ã‚ã¦ã„ãªã„ãŒã€LLMã«QAã«å›ç­”ã™ã‚‹ãŸã‚ã®ååˆ†ãªevidenceãŒé›†ã¾ã‚‹ã¾ã§è¤‡æ•°å›ã€æ¤œç´¢â†’SENs(æ¤œç´¢çµæœã‹ã‚‰å°ãå‡ºã•ã‚Œã‚‹QAã«ç­”ãˆã‚‹ã®ã«å¿…è¦ãªæƒ…å ±ã®ã‚µãƒãƒª;æ¤œç´¢çµæœã®denoisingã®å½¹å‰²ã‚’æœãŸã™)â†’...ã‚’ç¹°ã‚Šè¿”ã—ã€æœ€çµ‚çš„ãªSEN_lastã‹ã‚‰å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã€‚SEN_lastãŒå›ç­”ã‚’å«æ„ã™ã‚‹ã‹å¦ã‹ã‚’DistilBERTãƒ™ãƒ¼ã‚¹ã®Rewardãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦GRPOã«ã®å ±é…¬ã¨ã—ã¦æ´»ç”¨ã™ã‚‹ã€‚ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆreasoningãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹å‰æï¼‰ã¯QAãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€ä¸Šè¨˜ãƒ—ãƒ­ã‚»ã‚¹ã«ã‚ˆã£ã¦ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’å®Ÿæ–½ã•ã›ã‚‹ã“ã¨ã§GRPO+RLVR(å›ç­”ãŒåˆã£ã¦ã„ã‚‹ã‹ï¼‰+ï¼ˆDistillBERTã«åŸºã¥ãSNEs_lastã®ï¼‰Entailmentåˆ¤å®šãƒ¢ãƒ‡ãƒ«ã®confidenceã‚¹ã‚³ã‚¢ã«ã‚ˆã£ã¦è¨“ç·´ã™ã‚‹ã€ã¨ã„ã£ã¦æ„Ÿã˜ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/2e2c29b4-deaa-4679-8fc3-fb81a7b327c2" alt="image" loading="lazy"><br><br>Chain-of-Noteã¨æ¯”ã¹è¿½åŠ ã®å­¦ç¿’ãŒå¿…è¦ãªã®ã§ã‚³ãƒ³ã‚»ãƒ—ãƒˆã¯åŒã˜ã ãŒã€æ‰‹æ³•çš„ã«ã¯ç•°ãªã£ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2804" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models  for Robotic Manipulation, Hao Shi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MemoryVLAã¯ã€ãƒ­ãƒœãƒƒãƒˆæ“ä½œã«ãŠã‘ã‚‹æ™‚é–“çš„æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸCognition-Memory-Actionãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹ã€‚ä½œæ¥­è¨˜æ†¶ã‚’åˆ©ç”¨ã—ã¦çŸ­å‘½ã®è¡¨ç¾ã‚’åˆ¶å¾¡ã—ã€çŸ¥è¦š-èªçŸ¥ãƒ¡ãƒ¢ãƒªãƒ¼ãƒãƒ³ã‚¯ã«çµ±åˆã•ã‚ŒãŸæƒ…å ±ã‚’ä¿å­˜ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ™‚é–“çš„ã«æ„è­˜ã—ãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆã—ã€150ä»¥ä¸Šã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŠã‚ˆã³å®Ÿä¸–ç•Œã®ã‚¿ã‚¹ã‚¯ã§é«˜ã„æˆåŠŸç‡ã‚’é”æˆã€‚ç‰¹ã«ã€é•·æœŸçš„ãªã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://shihao1895.github.io/MemoryVLA/" target="_blank" rel="noopener noreferrer">https://shihao1895.github.io/MemoryVLA/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/embodiedairead/status/1966651546567143534?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é•·æœŸè¨˜æ†¶ã¨ã—ã¦ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ãŒå°å…¥ã•ã‚Œã€éå»ã«èªè­˜ã—ãŸå†—é•·æ€§ãŒæ’é™¤ã•ã‚ŒãŸç”»åƒæƒ…å ±(low level)ã¨ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã«ã‚ˆã‚‹æŒ‡ç¤ºã®æ„å‘³æƒ…å ±ï¼ˆhigh level semantics)ã‚’æ ¼ç´ã—ã¦ãŠã<br>ã€retrievalã—ãŸä¸Šã§æ´»ç”¨ã™ã‚‹ã€‚æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºã‚ã‚‹ãŸã‚ã®ãƒ‡ã‚³ãƒ¼ãƒ€ã‚ˆã†ã«è¦‹ãˆã‚‹transformerã®attentionã«å°‚ç”¨ã®Cognition/Perceptionã®attentionãŒä¸¡æ–¹ç”¨æ„ã•ã‚Œã¦ã„ã‚‹ğŸ‘€<br><br><img src="https://github.com/user-attachments/assets/520eae6e-c96e-416c-b72d-fc7326d8b9df" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2798" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MobileLLM-R1: Exploring the Limits of Sub-Billion Language Model  Reasoners with Open Training Recipes, Changsheng Zhao+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ¨è«–èƒ½åŠ›ã®å‡ºç¾ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿é‡ã«ã¤ã„ã¦å†æ¤œè¨ã—ã€ç´„2Tãƒˆãƒ¼ã‚¯ãƒ³ã®é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã§å¼·åŠ›ãªæ¨è«–ãƒ¢ãƒ‡ãƒ«ãŒæ§‹ç¯‰ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚MobileLLM-R1ã¨ã„ã†ã‚µãƒ–ãƒ“ãƒªã‚ªãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã—ã€ç‰¹ã«AIMEã‚¹ã‚³ã‚¢ã§å„ªã‚ŒãŸçµæœã‚’ç¤ºã—ãŸã€‚ã•ã‚‰ã«ã€Qwen3ã®36Tãƒˆãƒ¼ã‚¯ãƒ³ã‚³ãƒ¼ãƒ‘ã‚¹ã«å¯¾ã—ã¦ã‚‚ã€ã‚ãšã‹11.7%ã®ãƒˆãƒ¼ã‚¯ãƒ³ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸMobileLLM-R1-950Mã¯ã€è¤‡æ•°ã®æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ç«¶äº‰åŠ›ã‚’æŒã¤ã€‚ç ”ç©¶ã®è©³ç´°ãªæƒ…å ±ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1966669725389168823?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã‚’è¦‹ã‚‹ã¨ã€optimizerã‚„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®šã€pre/mid/post trainingã«ãŠã‘ã‚‹å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨DavaMixã«ã¤ã„ã¦ç°¡æ½”ã«è¨˜è¿°ã•ã‚Œã¦ãŠã‚Šã€ãƒ¬ã‚·ãƒ”ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ç´ æ™´ã‚‰ã—ã„ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3193" target="_blank" rel="noopener noreferrer">[Paper Note] MobileLLM: Optimizing Sub-billion Parameter Language Models for  On-Device Use Cases, Zechun Liu+, ICLR'24, 2024.02</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Medical.html" target="_blank" rel="noopener noreferrer">#Medical</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2794" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MedBrowseComp: Benchmarking Medical Deep Research and Computer Use, Shan Chen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯è‡¨åºŠæ„æ€æ±ºå®šæ”¯æ´ã«æœŸå¾…ã•ã‚Œã¦ã„ã‚‹ãŒã€ç•°ç¨®ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’çµ±åˆã™ã‚‹å³æ ¼ãªç²¾åº¦ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚æ—¢å­˜ã®è©•ä¾¡ã¯å®Ÿç”¨æ€§ãŒä¸æ˜ç¢ºã§ã‚ã‚‹ãŸã‚ã€MedBrowseCompã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€åŒ»ç™‚å¾“äº‹è€…ãŒæƒ…å ±ã‚’èª¿æ•´ã™ã‚‹è‡¨åºŠã‚·ãƒŠãƒªã‚ªã‚’åæ˜ ã—ãŸ1,000ä»¥ä¸Šã®è³ªå•ã‚’å«ã‚€åˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚‹ã€‚æœ€å‰ç·šã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã«é©ç”¨ã—ãŸçµæœã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¸è¶³ãŒ10ï¼…ã«é”ã—ã€LLMã®èƒ½åŠ›ã¨è‡¨åºŠç’°å¢ƒã®è¦æ±‚ã¨ã®é–“ã«é‡è¦ãªã‚®ãƒ£ãƒƒãƒ—ãŒç¤ºã•ã‚ŒãŸã€‚MedBrowseCompã¯ä¿¡é ¼æ€§ã®é«˜ã„åŒ»ç™‚æƒ…å ±æ¢ç´¢ã®ãŸã‚ã®ãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã‚’æä¾›ã—ã€å°†æ¥ã®ãƒ¢ãƒ‡ãƒ«æ”¹å–„ã®ç›®æ¨™ã‚’è¨­å®šã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://moreirap12.github.io/mbc-browse-app/" target="_blank" rel="noopener noreferrer">https://moreirap12.github.io/mbc-browse-app/</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/Privacy.html" target="_blank" rel="noopener noreferrer">#Privacy</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2791" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Laws for Differentially Private Language Models, Ryan McKenna+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã¯LLMã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦æ€§èƒ½å‘ä¸Šã‚’äºˆæ¸¬ã—ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¸æŠã®æŒ‡é‡ã‚’æä¾›ã™ã‚‹ã€‚LLMã¯æ©Ÿå¯†æ€§ã®ã‚ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã«ä¾å­˜ã—ã€DPãªã©ã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ãŒå¿…è¦ã ãŒã€ãã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã¯æœªè§£æ˜ã€‚æœ¬ç ”ç©¶ã§ã¯ã€DP LLMãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ç¢ºç«‹ã—ã€è¨ˆç®—ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã€ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è€ƒæ…®ã—ãŸæœ€é©ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ§‹æˆã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>blog:


<a href="https://research.google/blog/vaultgemma-the-worlds-most-capable-differentially-private-llm/" target="_blank" rel="noopener noreferrer">https://research.google/blog/vaultgemma-the-worlds-most-capable-differentially-private-llm/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jeffdean/status/1966558317418885132?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2792" target="_blank" rel="noopener noreferrer">Calibrating Noise to Sensitivity in Private Data Analysis, Dwork+, TCC'06</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2782" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning, Haozhan Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- VLAãƒ¢ãƒ‡ãƒ«ã®å¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯SimpleVLA-RLã‚’ææ¡ˆã—ã€ãƒ­ãƒœãƒƒãƒˆæ“ä½œã®åŠ¹ç‡ã‚’å‘ä¸Šã€‚å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã¸ã®ä¾å­˜ã‚’æ¸›ã‚‰ã—ã€ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’å¼·åŒ–ã€‚OpenVLA-OFTã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€RoboTwin 1.0&amp;2.0ã§å„ªã‚ŒãŸçµæœã‚’ç¤ºã™ã€‚æ–°ãŸãªç¾è±¡ã€Œpushcutã€ã‚’ç‰¹å®šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1966352984461173096?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/collections/Haozhan72/simplevla-rl-6833311430cd9df52aeb1f86" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/Haozhan72/simplevla-rl-6833311430cd9df52aeb1f86</a>


</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1966592913955033229?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>VLAã«ãŠã„ã¦åˆã‚ã¦R1-styleã®ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®verifiable rewardï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç’°å¢ƒã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹çµæœï¼‰ã®ã¿ã«åŸºã¥ãã‚·ãƒ³ãƒ—ãƒ«ãªon policy RLã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§ã€SFTã‚’å®Ÿæ–½ã™ã‚‹å ´åˆã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã€ã‹ã¤é«˜ã„æ±åŒ–æ€§èƒ½ã‚’ç²å¾—ã§ãã‚‹ã“ã¨ã‚’VLAã«ãŠã„ã¦ç¤ºã—ãŸç ”ç©¶ãªæ¨¡æ§˜ã€‚<br><br>ãŸã ã—æ–°ãŸãªBehaviorã«å¯¾ã™ã‚‹Explorationã‚’ã‚ˆã‚Šé«˜ã‚ã‚‹ãŸã‚ã«ã€Refãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹KL DivergenceãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’é™¤å¤–ã—ãŸã‚Šã€3.3ç¯€ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªã€<br>- Dynamic Sampling: å…¨ã¦ã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã®RewardãŒåŒã˜å€¤ã«ãªã‚‹ã¨GRPOã®advantageãŒ0ã¨ãªã‚Šå‹¾é…ãŒæ¶ˆå¤±ã™ã‚‹å•é¡ŒãŒã‚ã‚‹ã®ã§ã€å…¨ã¦ã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆãŒæˆåŠŸ/å¤±æ•—ã—ãŸã‚°ãƒ«ãƒ¼ãƒ—ã¯é™¤å¤–ï¼ˆè¨€ã„æ›ãˆã‚‹ã¨ã€mixed outcomeã®ã‚°ãƒ«ãƒ¼ãƒ—ã®ã¿ã‚’åˆ©ç”¨ï¼‰ã—ã¦å­¦ç¿’<br>- Clip Higher: DAPOã¨åŒæ§˜ã«ã€ç›´å‰ã®ãƒãƒªã‚·ãƒ¼ã¨ç¾åœ¨ã®ãƒãƒªã‚·ãƒ¼ã®æ¯”ç‡ã®ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã®ä¸Šé™å€¤ã‚’åºƒã’ï¼ˆã¤ã¾ã‚Šã€ä½ã„ç¢ºç‡ã ã£ãŸã‚‚ã®ã‚’ã‚ˆã‚Šå¤§ããªå€¤ã¨ãªã‚‹ã“ã¨ã‚’ä»¥å‰ã‚ˆã‚Šã‚‚è¨±å®¹ã™ã‚‹ï¼‰ã¦æ¢ç´¢ã‚’ä¿ƒã™<br>- Higher Rollout Temperature:ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆæ™‚ã®temperatureã‚’1.6ã¨é«˜ã‚ã«ã—ã€ã‚ˆã‚Šå¤šæ§˜ãªtrajectoryãŒç”Ÿæˆã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã§æ¢ç´¢ã‚’ä¿ƒã™<br><br>ã¨ã„ã£ãŸå…¨ä½“çš„ã«æ¢ç´¢ã‚’å¼·ã‚ã‚‹ã‚ˆã†ãªèª¿æ•´ã‚’è¡Œãªã£ã¦ã„ã‚‹æ¨¡æ§˜ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-09-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2776" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LiveCodeBench: Holistic and Contamination Free Evaluation of Large   Language Models for Code, Naman Jain+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMã®ã‚³ãƒ¼ãƒ‰é–¢é€£èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒLiveCodeBenchã€ã‚’ææ¡ˆã€‚LeetCodeã€AtCoderã€CodeForcesã‹ã‚‰åé›†ã—ãŸ400ã®é«˜å“è³ªãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œã‚’ç”¨ã„ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚„è‡ªå·±ä¿®å¾©ã€ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œãªã©å¤šæ§˜ãªèƒ½åŠ›ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ã€‚18ã®ãƒ™ãƒ¼ã‚¹LLMã¨34ã®æŒ‡ç¤ºèª¿æ•´ã•ã‚ŒãŸLLMã‚’è©•ä¾¡ã—ã€æ±šæŸ“ã‚„éå‰°é©åˆã®å•é¡Œã‚’å®Ÿè¨¼çš„ã«åˆ†æã€‚ã™ã¹ã¦ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚’å…¬é–‹ã—ã€ã•ã‚‰ãªã‚‹åˆ†æã‚„æ–°ã—ã„ã‚·ãƒŠãƒªã‚ªã®è¿½åŠ ã‚’å¯èƒ½ã«ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã‚‚æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2047" target="_blank" rel="noopener noreferrer">[Paper Note] LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive  Programming?, Zihan Zheng+, NeurIPS'25</a>
</p>
<p>pj page:


<a href="https://livecodebench.github.io" target="_blank" rel="noopener noreferrer">https://livecodebench.github.io</a>


</p>
<p>openreview:


<a href="https://openreview.net/forum?id=chfJJYC3iL" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=chfJJYC3iL</a>


</p>
<p>LiveCodeBenchã¯éå¸¸ã«popularãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é–¢é€£ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã ãŒã€readmeã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‚³ãƒãƒ³ãƒ‰é€šã‚Šã«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€stop tokenã«"###"ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’å‡ºåŠ›ã—ãŸLLMã®å‡ºåŠ›ãŒå¸¸ã«truncateã•ã‚Œã‚‹ã¨ã„ã†ãƒã‚°ãŒã‚ã£ãŸæ¨¡æ§˜ã€‚<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nrehiew_/status/1966180838271496247?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/SpatialUnderstanding.html" target="_blank" rel="noopener noreferrer">#SpatialUnderstanding</a>
<span class="issue_date">Issue Date: 2025-09-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2774" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Why Do MLLMs Struggle with Spatial Understanding? A Systematic Analysis  from Data to Architecture, Wanyue Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ç©ºé–“ç†è§£ã¯MLLMsã«ã¨ã£ã¦é‡è¦ã ãŒã€ä¾ç„¶ã¨ã—ã¦èª²é¡ŒãŒå¤šã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€å˜ä¸€è¦–ç‚¹ã€å¤šè¦–ç‚¹ã€ãƒ“ãƒ‡ã‚ªã®3ã¤ã®ã‚·ãƒŠãƒªã‚ªã«ãŠã‘ã‚‹ç©ºé–“ç†è§£ã‚’ä½“ç³»çš„ã«åˆ†æã—ã€MulSeTã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å¢—åŠ ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã«å¯„ä¸ã™ã‚‹ãŒã€é™ç•ŒãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã¾ãŸã€ç©ºé–“ç†è§£ã¯è¦–è¦šã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ä¾å­˜ã—ã¦ãŠã‚Šã€æ¨è«–ã®æ³¨å…¥ã‚’é€šã˜ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ”¹å–„ã®å¯èƒ½æ€§ã‚’æ¢ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€MLLMsã®é™ç•Œã‚’æ˜ã‚‰ã‹ã«ã—ã€ç©ºé–“æ¨è«–èƒ½åŠ›å‘ä¸Šã®æ–°ãŸãªæ–¹å‘æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/askalphaxiv/status/1965822971261718549?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2771" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Survey of Reinforcement Learning for Large Reasoning Models, Kaiyan Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€LLMã«ãŠã‘ã‚‹æ¨è«–ã®ãŸã‚ã®å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã®é€²å±•ã‚’èª¿æŸ»ã—ã€ç‰¹ã«æ•°å­¦ã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã®è¤‡é›‘ãªè«–ç†ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹æˆåŠŸã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚RLã¯LLMã‚’å­¦ç¿’æ¨è«–ãƒ¢ãƒ‡ãƒ«ï¼ˆLRMï¼‰ã«å¤‰æ›ã™ã‚‹åŸºç›¤çš„ãªæ–¹æ³•è«–ã¨ã—ã¦æµ®ä¸Šã—ã¦ãŠã‚Šã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã¯è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è¨­è¨ˆãªã©ã®èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚DeepSeek-R1ä»¥é™ã®ç ”ç©¶ã‚’æ¤œè¨ã—ã€LLMãŠã‚ˆã³LRMã«ãŠã‘ã‚‹RLã®é©ç”¨ã«é–¢ã™ã‚‹æœªæ¥ã®æ©Ÿä¼šã¨æ–¹å‘æ€§ã‚’ç‰¹å®šã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/f14bertolotti/status/1966007411719688363?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okhayiea/status/1965989894163235111?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2768" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reconstruction Alignment Improves Unified Multimodal Models, Ji Xie+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- çµ±ä¸€å¤šãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ï¼ˆUMMsï¼‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ãªã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã«ä¾å­˜ã—ã¦ãŠã‚Šã€è¦–è¦šçš„è©³ç´°ã‚’è¦‹é€ƒã™ã“ã¨ãŒå¤šã„ã€‚ãã“ã§ã€å†æ§‹æˆã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆRecAï¼‰ã‚’å°å…¥ã—ã€è¦–è¦šç†è§£ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®åŸ‹ã‚è¾¼ã¿ã‚’ç”¨ã„ã¦ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãªã—ã§è±Šå¯Œãªç›£è¦–ã‚’æä¾›ã€‚RecAã¯UMMã‚’è¦–è¦šç†è§£åŸ‹ã‚è¾¼ã¿ã«æ¡ä»¶ä»˜ã‘ã€è‡ªå·±ç›£è¦–å‹ã®å†æ§‹æˆæå¤±ã§æœ€é©åŒ–ã—ã€ç”Ÿæˆã¨ç·¨é›†ã®å¿ å®Ÿåº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚27 GPUæ™‚é–“ã§ã€ç”»åƒç”Ÿæˆæ€§èƒ½ã‚„ç·¨é›†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã€åŠ¹ç‡çš„ãªãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã¨ã—ã¦ã®åœ°ä½ã‚’ç¢ºç«‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://reconstruction-alignment.github.io" target="_blank" rel="noopener noreferrer">https://reconstruction-alignment.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xdwang101/status/1965908302581420204?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2769" target="_blank" rel="noopener noreferrer">[Paper Note] GenEval: An Object-Focused Framework for Evaluating Text-to-Image   Alignment, Dhruba Ghosh+, NeurIPS'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2770" target="_blank" rel="noopener noreferrer">[Paper Note] ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment, Xiwei Hu+, arXiv'24</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2767" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric  Knowledge, Lukas Haas+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- SimpleQA Verifiedã¯ã€OpenAIã®SimpleQAã«åŸºã¥ã1,000ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€LLMã®çŸ­æ–‡äº‹å®Ÿæ€§ã‚’è©•ä¾¡ã—ã¾ã™ã€‚ãƒã‚¤ã‚ºã®å¤šã„ãƒ©ãƒ™ãƒ«ã‚„ãƒˆãƒ”ãƒƒã‚¯ãƒã‚¤ã‚¢ã‚¹ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€å³å¯†ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµŒã¦ä¿¡é ¼æ€§ã®é«˜ã„è©•ä¾¡ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚Gemini 2.5 Proã¯55.6ã®F1ã‚¹ã‚³ã‚¢ã‚’é”æˆã—ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã¾ã—ãŸã€‚ã“ã®ç ”ç©¶ã¯ã€äº‹å®Ÿæ€§ã®é€²å±•ã‚’è¿½è·¡ã—ã€å¹»è¦šã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>leaderboard:


<a href="https://www.kaggle.com/benchmarks/deepmind/simpleqa-verified" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/benchmarks/deepmind/simpleqa-verified</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1965806183970652368?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2448" target="_blank" rel="noopener noreferrer">[Paper Note] Measuring short-form factuality in large language models, Jason Wei+, arXiv'24</a>
</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Entropy.html" target="_blank" rel="noopener noreferrer">#Entropy</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2758" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning, Haozhe Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ãã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯ä¸æ˜ã€‚åˆ†æã«ã‚ˆã‚Šã€æ¨è«–ã®éšå±¤ãŒäººé–“ã®èªçŸ¥ã«ä¼¼ãŸäºŒæ®µéšã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’æŒã¤ã“ã¨ã‚’ç™ºè¦‹ã€‚åˆæœŸæ®µéšã§ã¯æ‰‹ç¶šãçš„ãªæ­£ç¢ºæ€§ãŒæ±‚ã‚ã‚‰ã‚Œã€å¾Œã«é«˜ãƒ¬ãƒ™ãƒ«ã®æˆ¦ç•¥çš„è¨ˆç”»ãŒé‡è¦ã«ãªã‚‹ã€‚ã“ã‚Œã«åŸºã¥ãã€HICRAã¨ã„ã†ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã—ã€é«˜å½±éŸ¿ã®è¨ˆç”»ãƒˆãƒ¼ã‚¯ãƒ³ã«æœ€é©åŒ–ã‚’é›†ä¸­ã•ã›ã‚‹ã“ã¨ã§æ€§èƒ½ã‚’å‘ä¸Šã•ã›ãŸã€‚ã¾ãŸã€æ„å‘³çš„ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒæˆ¦ç•¥çš„æ¢æ±‚ã®å„ªã‚ŒãŸæŒ‡æ¨™ã§ã‚ã‚‹ã“ã¨ã‚’æ¤œè¨¼ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://tiger-ai-lab.github.io/Hierarchical-Reasoner/" target="_blank" rel="noopener noreferrer">https://tiger-ai-lab.github.io/Hierarchical-Reasoner/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1965783045035762076?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/askalphaxiv/status/1968718537729405228?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2757" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Staying in the Sweet Spot: Responsive Reasoning Evolution via  Capability-Adaptive Hint Scaffolding, Ziheng Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RLVRã¯LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®é›£æ˜“åº¦ã¨ãƒ¢ãƒ‡ãƒ«èƒ½åŠ›ã®ä¸ä¸€è‡´ã«ã‚ˆã‚Šæ¢ç´¢ãŒéåŠ¹ç‡çš„ã€‚æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯SEELEã‚’ææ¡ˆã—ã€å•é¡Œã®é›£æ˜“åº¦ã‚’å‹•çš„ã«èª¿æ•´ã€‚ãƒ’ãƒ³ãƒˆã®é•·ã•ã‚’é©å¿œçš„ã«èª¿æ•´ã—ã€æ¢ç´¢åŠ¹ç‡ã‚’å‘ä¸Šã€‚å®Ÿé¨“ã§ã¯SEELEãŒå¾“æ¥æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://github.com/ChillingDream/seele" target="_blank" rel="noopener noreferrer">https://github.com/ChillingDream/seele</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1965632380112453870?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å•é¡Œã®é›£æ˜“åº¦ã‚’ãƒ’ãƒ³ãƒˆã«ã‚ˆã£ã¦èª¿æ•´ã—ã¤ã¤ï¼ˆIRTã§å›°é›£åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¦‹ã‚‹ã¨æ€ã‚ã‚Œã‚‹ï¼‰RLã™ã‚‹æ¨¡æ§˜ã€‚é¢ç™½ãã†ã€‚<br><img src="https://github.com/user-attachments/assets/f7322e4a-289f-48ca-8910-257b5544f39a" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2754" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents, Junteng Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æƒ…å ±æ¢ç´¢ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€WebExplorerã¨ã„ã†ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®æ¢ç´¢æ‰‹æ³•ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¤‡é›‘ãªã‚¯ã‚¨ãƒª-å›ç­”ãƒšã‚¢ã‚’ç”Ÿæˆã—ã€é«˜åº¦ãªã‚¦ã‚§ãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆWebExplorer-8Bã‚’é–‹ç™ºã€‚128Kã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’æŒã¡ã€æœ€å…ˆç«¯ã®æƒ…å ±æ¢ç´¢ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚ç‰¹ã«ã€WebExplorer-8Bã¯ä»–ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ç²¾åº¦ã‚’ç¤ºã—ã€é•·æœŸçš„ãªå•é¡Œè§£æ±ºã«å‘ã‘ãŸå®Ÿç”¨çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æä¾›ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1965537550937792934?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è©•ä¾¡ã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2451" target="_blank" rel="noopener noreferrer">[Paper Note] BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents, Jason Wei+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1730" target="_blank" rel="noopener noreferrer">[Paper Note] Humanity's Last Exam, Long Phan+, arXiv'25</a>
</p>
<p>å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®åˆæˆæ–¹æ³•ãŒè‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2753" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Parallel-R1: Towards Parallel Thinking via Reinforcement Learning, Tong Zheng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Parallel-R1ã¯ã€è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ä¸¦åˆ—æ€è€ƒã‚’å¯èƒ½ã«ã™ã‚‹å¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆå•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®é€²è¡Œçš„ãªã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã‚’æ¡ç”¨ã€‚ç°¡å˜ãªã‚¿ã‚¹ã‚¯ã‹ã‚‰å§‹ã‚ã€ä¸¦åˆ—æ€è€ƒèƒ½åŠ›ã‚’æ¤ãˆä»˜ã‘ãŸå¾Œã€é›£ã—ã„å•é¡Œã«ç§»è¡Œã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€å¾“æ¥ã®é€æ¬¡æ€è€ƒãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦8.4%ã®ç²¾åº¦å‘ä¸Šã‚’é”æˆã—ã€ä¸¦åˆ—æ€è€ƒãŒä¸­é–“ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¢ç´¢ã®è¶³å ´ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1965631715235525006?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>çµæœã®è¡¨ã‚’è¦‹ã‚‹ã¨ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§å˜ã«self Consistencyã‚’å®Ÿæ–½ã™ã‚‹ã‚ˆã‚Šã‚‚é«˜ã„ã‚²ã‚¤ãƒ³ã‚’å¾—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ãŒQwen3ã®ã¿ã§ã—ã‹å®Ÿé¨“ã•ã‚Œã¦ãŠã‚‰ãšã€Qwen2.5ã«ãŠã„ã¦ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã®ç–‘ã„ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2226" target="_blank" rel="noopener noreferrer">[Paper Note] Reasoning or Memorization? Unreliable Results of Reinforcement Learning  Due to Data Contamination, Mingqi Wu+, arXiv'25</a>
 ãŒã‚ã£ãŸã®ã§ã€(Qwen3ãŒã©ã†ã‹ã¯ã‚ã‹ã‚‰ãªã„ãŒ)å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§ã¯ãªãã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚å®Ÿé¨“ã—ãŸæ–¹ãŒè‰¯ã„ã®ã‹ãªã€ã¨ã„ã†å°è±¡ã€‚</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1965691174813089987?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1968939351427158459?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚³ãƒ¼ãƒ‰ãŒãƒªãƒªãƒ¼ã‚¹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wyu_nd/status/1976011651758588165?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/TreeSearch.html" target="_blank" rel="noopener noreferrer">#TreeSearch</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2751" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] An AI system to help scientists write expert-level empirical software, Eser AygÃ¼n+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AIã‚·ã‚¹ãƒ†ãƒ ã‚’ç”¨ã„ã¦è³ªã®æŒ‡æ¨™ã‚’æœ€å¤§åŒ–ã™ã‚‹å°‚é–€çš„ãªç§‘å­¦ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’ç”Ÿæˆã€‚å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¨æœ¨æ¢ç´¢ã‚’æ´»ç”¨ã—ã€è¤‡é›‘ãªç ”ç©¶ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’çµ±åˆã€‚ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã‚„ç–«å­¦ã®åˆ†é‡ã§æ–°ã—ã„æ‰‹æ³•ã‚’ç™ºè¦‹ã—ã€æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æˆæœã‚’é”æˆã€‚å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ–°ã—ã„è§£æ±ºç­–ã‚’æä¾›ã—ã€ç§‘å­¦çš„é€²æ­©ã‚’åŠ é€Ÿã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1965253577221587218?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2749" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual  Search, Xin Lai+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Mini-o3ã‚·ã‚¹ãƒ†ãƒ ã¯ã€æ•°åã‚¹ãƒ†ãƒƒãƒ—ã®æ·±ã„ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³æ¨è«–ã‚’å®Ÿç¾ã—ã€è¦–è¦šæ¤œç´¢ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚Visual Probe Datasetã‚’æ§‹ç¯‰ã—ã€å¤šæ§˜ãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã™ãƒ‡ãƒ¼ã‚¿åé›†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é–‹ç™ºã€‚ã‚ªãƒ¼ãƒãƒ¼ã‚¿ãƒ¼ãƒ³ãƒã‚¹ã‚­ãƒ³ã‚°æˆ¦ç•¥ã«ã‚ˆã‚Šã€ã‚¿ãƒ¼ãƒ³æ•°ãŒå¢—ãˆã‚‹ã»ã©ç²¾åº¦ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/Mini-o3" target="_blank" rel="noopener noreferrer">https://huggingface.co/Mini-o3</a>


</p>
<p>pj page:


<a href="https://mini-o3.github.io" target="_blank" rel="noopener noreferrer">https://mini-o3.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1965616579024228527?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¢å­˜ã®ã‚ªãƒ¼ãƒ—ãƒ³ãªVLMã¯ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®ã‚¿ãƒ¼ãƒ³æ•°ã‚’å¢—ã‚„ã›ãªã„ã¨ã„ã†èª²é¡ŒãŒã‚ã£ãŸãŒãã‚Œã‚’å…‹æœã™ã‚‹ãƒ¬ã‚·ãƒ”ã«é–¢ã™ã‚‹ç ”ç©¶ãªæ¨¡æ§˜ã€‚å…ƒãƒã‚¹ãƒˆã«ã‚ˆã‚‹ã¨6ã‚¿ãƒ¼ãƒ³ã¾ã§ã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã§å­¦ç¿’ã—ã¦ã‚‚ã€inferenceæ™‚ã«ã¯32ã‚¿ãƒ¼ãƒ³ã¾ã§ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã¨ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Medical.html" target="_blank" rel="noopener noreferrer">#Medical</a>
<a class="button" href="articles/Biological.html" target="_blank" rel="noopener noreferrer">#Biological</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2747" target="_blank" rel="noopener noreferrer" class="title-link">BioML-bench: Evaluation of AI Agents for End-to-End Biomedical ML, Miller+, bioRxiv'25</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bowang87/status/1965559595793088725?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Biomedicalãƒ‰ãƒ¡ã‚¤ãƒ³ã«ãŠã‘ã‚‹24ç¨®é¡ã®éå¸¸ã«è¤‡é›‘ã§nuancedãªè¨˜è¿°ã‚„ç”»åƒã®èª­ã¿å–ã‚Šãªã©ã‚’å«ã‚€å®Ÿã‚¿ã‚¹ã‚¯ã«ã‚ˆã£ã¦æ§‹æˆã•ã‚Œã‚‹åˆã‚ã¦ã®Agenticãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2740" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reverse-Engineered Reasoning for Open-Ended Generation, Haozhe Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- REERã¨ã„ã†æ–°ã—ã„æ¨è«–ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ææ¡ˆã—ã€æ—¢å­˜ã®è‰¯å¥½ãªè§£ã‹ã‚‰å¾Œæ–¹ã«æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ§‹ç¯‰ã€‚20,000ã®æ·±ã„æ¨è«–è»Œè·¡ã‹ã‚‰ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆDeepWriting-20Kã‚’ä½œæˆã—ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã€‚è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«DeepWriter-8Bã¯ã€å¼·åŠ›ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’è¶…ãˆã€GPT-4oã‚„Claude 3.5ã¨ç«¶äº‰åŠ›ã®ã‚ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://m-a-p.ai/REER_DeepWriter/" target="_blank" rel="noopener noreferrer">https://m-a-p.ai/REER_DeepWriter/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gezhang86038849/status/1965320156667949307?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2025-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2736" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Are We Done with MMLU?, Aryo Pradipta Gema+, NAACL'25</a>
<span class="snippet"><span>GPT Summary</span>- MMLUãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚¨ãƒ©ãƒ¼ã‚’åˆ†æã—ã€ã‚¦ã‚¤ãƒ«ã‚¹å­¦ã®ã‚µãƒ–ã‚»ãƒƒãƒˆã§ã¯57%ã®è³ªå•ã«ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚æ–°ã—ã„ã‚¨ãƒ©ãƒ¼æ³¨é‡ˆãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ç”¨ã„ã¦MMLU-Reduxã‚’ä½œæˆã—ã€6.49%ã®è³ªå•ã«ã‚¨ãƒ©ãƒ¼ãŒå«ã¾ã‚Œã‚‹ã¨æ¨å®šã€‚MMLU-Reduxã‚’é€šã˜ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨ã®ä¸ä¸€è‡´ã‚’ç¤ºã—ã€MMLUã®ä¿¡é ¼æ€§å‘ä¸Šã‚’ææ¡ˆã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/Non-Determinism.html" target="_blank" rel="noopener noreferrer">#Non-Determinism</a>
<span class="issue_date">Issue Date: 2025-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2735" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore   Non-Determinism, Yifan Song+, NAACL'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®è©•ä¾¡ã¯éæ±ºå®šæ€§ã‚’è¦‹è½ã¨ã—ãŒã¡ã§ã€å˜ä¸€å‡ºåŠ›ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ãŸã‚æ€§èƒ½ã®å¤‰å‹•ç†è§£ãŒåˆ¶é™ã•ã‚Œã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€è²ªæ¬²ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®æ€§èƒ½å·®ã‚’æ¢æ±‚ã—ã€éæ±ºå®šæ€§ã«é–¢ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ä¸€è²«æ€§ã‚’ç‰¹å®šã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€è²ªæ¬²ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒå¤šãã®ã‚¿ã‚¹ã‚¯ã§å„ªã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãŒã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®åˆ†æ•£ã‚’æ¸›å°‘ã•ã›ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€å°å‹LLMãŒå¤§å‹ãƒ¢ãƒ‡ãƒ«ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’æŒã¤ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã€LLMè©•ä¾¡ã«ãŠã‘ã‚‹éæ±ºå®šæ€§ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1890" target="_blank" rel="noopener noreferrer">Non-Determinism of "Deterministic" LLM Settings, Berk Atil+, arXiv'24</a>
<br><br>åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2736" target="_blank" rel="noopener noreferrer">[Paper Note] Are We Done with MMLU?, Aryo Pradipta Gema+, NAACL'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2737" target="_blank" rel="noopener noreferrer">AlpacaEval, tatsu-lab, 2023.06</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2739" target="_blank" rel="noopener noreferrer">[Paper Note] MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures, Jinjie Ni+, NeurIPS'24</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2738" target="_blank" rel="noopener noreferrer">From Live Data to High-Quality Benchmarks: The Arena-Hard Pipeline, Li+, 2024.04</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1618" target="_blank" rel="noopener noreferrer">Training Verifiers to Solve Math Word Problems, Karl Cobbe+, arXiv'21</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2438" target="_blank" rel="noopener noreferrer">[Paper Note] Evaluating Large Language Models Trained on Code, Mark Chen+, arXiv'21</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Aggregation-aware.html" target="_blank" rel="noopener noreferrer">#Aggregation-aware</a>
<span class="issue_date">Issue Date: 2025-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2729" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Majority is not always right: RL training for solution aggregation, Wenting Zhao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¤‡æ•°ã®è§£ã‚’ç”Ÿæˆã—ã€ãã‚Œã‚’é›†ç´„ã™ã‚‹ã“ã¨ã§LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã™ã‚‹ã€‚å¾“æ¥ã®æ–¹æ³•ã«ä»£ã‚ã‚Šã€é›†ç´„ã‚’æ˜ç¤ºçš„ãªæ¨è«–ã‚¹ã‚­ãƒ«ã¨ã—ã¦å­¦ç¿’ã—ã€å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦æ­£ã—ã„ç­”ãˆã‚’èª¿æ•´ãƒ»åˆæˆã™ã‚‹ã€‚ç°¡å˜ãªä¾‹ã¨é›£ã—ã„ä¾‹ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã¯å°‘æ•°æ´¾ã®æ­£ã—ã„ç­”ãˆã‚’å›å¾©ã™ã‚‹èƒ½åŠ›ã‚’ç²å¾—ã€‚ææ¡ˆæ‰‹æ³•AggLMã¯ã€è¤‡æ•°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã€å°‘ãªã„ãƒˆãƒ¼ã‚¯ãƒ³ã§åŠ¹æœçš„ã«ä¸€èˆ¬åŒ–ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1965233976949543194?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1965556816647164055?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wzhao_nlp/status/1966784672706256896?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1968870421882896891?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2726" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SpikingBrain Technical Report: Spiking Brain-inspired Large Models, Yuqi Pan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- SpikingBrainã¯ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®åŠ¹ç‡çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸè„³ã«ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§ã€MetaX GPUã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’æ´»ç”¨ã€‚ç·šå½¢ãŠã‚ˆã³ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç·šå½¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã—ã€éNVIDIAãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ä¸Šã§ã®å¤§è¦æ¨¡LLMé–‹ç™ºã‚’å®Ÿç¾ã€‚SpikingBrain-7Bã¨SpikingBrain-76Bã‚’é–‹ç™ºã—ã€ç´„150Bãƒˆãƒ¼ã‚¯ãƒ³ã§ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®Transformerã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ã‚’å¤§å¹…ã«æ”¹å–„ã—ã€ä½æ¶ˆè²»é›»åŠ›ã§ã®é‹ç”¨ã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/f14bertolotti/status/1964949822429069761?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>TTFTãŒ4Mã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ™‚ã«Qwen2.5ã¨æ¯”ã¹ã¦100å€é«˜é€ŸåŒ–â€¦ï¼Ÿ</p>
<p>ä¸­å›½ã®MetaXç¤¾ã®GPUãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>


<a href="https://www.metax-tech.com/en/goods/prod.html?cid=3" target="_blank" rel="noopener noreferrer">https://www.metax-tech.com/en/goods/prod.html?cid=3</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/SpeculativeDecoding.html" target="_blank" rel="noopener noreferrer">#SpeculativeDecoding</a>
<span class="issue_date">Issue Date: 2025-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2716" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] REFRAG: Rethinking RAG based Decoding, Xiaoqiang Lin+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- REFRAGã¯ã€RAGã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹é…å»¶ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®åŠ¹ç‡çš„ãªãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ã‚¹ãƒ‘ãƒ¼ã‚¹æ§‹é€ ã‚’åˆ©ç”¨ã—ã¦åˆå›ãƒˆãƒ¼ã‚¯ãƒ³ã¾ã§ã®æ™‚é–“ã‚’30.85å€åŠ é€Ÿã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºã‚’16ã¾ã§æ‹¡å¼µå¯èƒ½ã«ã—ã€ã•ã¾ã–ã¾ãªé•·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã§ç²¾åº¦ã‚’æãªã†ã“ã¨ãªãã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dr_singularity/status/1964453705430036982?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>èˆˆå‘³æ·±ã„ã€‚Speculative Decodingã®æ–°æ‰‹æ³•ã¨ã‚‚ã¿ãªã›ãã†ã€‚</p>
<p>åŒæ™‚æœŸã«å‡ºãŸä¸‹è¨˜ç ”ç©¶ã¨æ¯”è¼ƒã—ã¦ã©ã®ã‚ˆã†ãªpros/consãŒã‚ã‚‹ã ã‚ã†ã‹ï¼Ÿ<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2699" target="_blank" rel="noopener noreferrer">[Paper Note] Set Block Decoding is a Language Model Inference Accelerator, Itai Gat+, arXiv'25</a>
</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1966292095242744186?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2713" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RL's Razor: Why Online Reinforcement Learning Forgets Less, Idan Shenfeld+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã¨æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã®æ¯”è¼ƒã«ã‚ˆã‚Šã€RLãŒä»¥å‰ã®çŸ¥è­˜ã‚’ã‚ˆã‚Šè‰¯ãä¿æŒã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚å¿˜å´ã®ç¨‹åº¦ã¯åˆ†å¸ƒã®ã‚·ãƒ•ãƒˆã«ã‚ˆã£ã¦æ±ºã¾ã‚Šã€KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã§æ¸¬å®šã•ã‚Œã‚‹ã€‚RLã¯æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦KLæœ€å°è§£ã«ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã‚‹ä¸€æ–¹ã€SFTã¯ä»»æ„ã®è·é›¢ã«åæŸã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚å®Ÿé¨“ã‚’é€šã˜ã¦ã€RLã®æ›´æ–°ãŒå°ã•ãªKLå¤‰åŒ–ã‚’ã‚‚ãŸã‚‰ã™ç†ç”±ã‚’ç†è«–çš„ã«èª¬æ˜ã—ã€ã€ŒRLã®å‰ƒåˆ€ã€ã¨å‘¼ã¶åŸå‰‡ã‚’æå”±ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jyo_pari/status/1963967312555332065?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stone_tao/status/1964381652106563591?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1963823603469730114?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2710" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SWE-rebench: An Automated Pipeline for Task Collection and  Decontaminated Evaluation of Software Engineering Agents, Ibragim Badertdinov+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®SWEã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹èª²é¡Œã¨ã—ã¦ã€é«˜å“è³ªãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ä¸è¶³ã¨æ–°é®®ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚¿ã‚¹ã‚¯ã®æ¬ å¦‚ãŒæŒ™ã’ã‚‰ã‚Œã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€21,000ä»¥ä¸Šã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªPythonãƒ™ãƒ¼ã‚¹ã®SWEã‚¿ã‚¹ã‚¯ã‚’å«ã‚€å…¬çš„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆSWE-rebenchã‚’è‡ªå‹•åŒ–ã•ã‚ŒãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§æ§‹ç¯‰ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¼·åŒ–å­¦ç¿’ã«é©ã—ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æä¾›ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ±šæŸ“ã®ãªã„è©•ä¾¡ãŒå¯èƒ½ã¨ãªã‚Šã€ã„ãã¤ã‹ã®LLMã®æ€§èƒ½ãŒéå¤§è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://swe-rebench.com" target="_blank" rel="noopener noreferrer">https://swe-rebench.com</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1963947072748412990?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã®ãªã„æœ€æ–°ã®Issueã‚’ç”¨ã„ã¦è©•ä¾¡ã—ãŸçµæœã€Sonnet 4ãŒæœ€ã‚‚é«˜æ€§èƒ½</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2702" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow  Real Instructions?, Qinyan Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¾“ã†ã“ã¨ã«è‹¦åŠ´ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ã“ã‚Œã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€Inverse IFEvalã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ãƒ¢ãƒ‡ãƒ«ãŒå¯¾ç«‹ã™ã‚‹æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ã€‚8ç¨®é¡ã®èª²é¡Œã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã€æ—¢å­˜ã®LLMã«å¯¾ã™ã‚‹å®Ÿé¨“ã‚’è¡Œã£ãŸçµæœã€éå¾“æ¥ã®æ–‡è„ˆã§ã®é©å¿œæ€§ã‚‚è€ƒæ…®ã™ã¹ãã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚Inverse IFEvalã¯ã€LLMã®æŒ‡ç¤ºéµå®ˆã®ä¿¡é ¼æ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1963822451550208101?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>èˆˆå‘³æ·±ã„</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2700" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Towards a Unified View of Large Language Model Post-Training, Xingtai Lv+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã¨ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒã€çŸ›ç›¾ã›ãšå˜ä¸€ã®æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚çµ±ä¸€ãƒãƒªã‚·ãƒ¼å‹¾é…æ¨å®šå™¨ã‚’å°å‡ºã—ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆHPTï¼‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã€‚HPTã¯ç•°ãªã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¿¡å·ã‚’å‹•çš„ã«é¸æŠã—ã€ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åŠ¹æœçš„ã«æ´»ç”¨ã—ã¤ã¤å®‰å®šã—ãŸæ¢ç´¢ã‚’å®Ÿç¾ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€HPTãŒæ•°å­¦çš„æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¼·åŠ›ãªæ€§èƒ½ã‚’ç¤ºã™ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1963818963550572623?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1963971173735448858?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2696" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn  Reinforcement Learning, Haoming Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- UI-TARS-2ã¯ã€GUIç”¨è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã§ã€ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã€å®‰å®šåŒ–ã•ã‚ŒãŸãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³RLã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰GUIç’°å¢ƒã‚’çµ±åˆã€‚å®Ÿè¨¼è©•ä¾¡ã§ã¯ã€å‰ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€è¤‡æ•°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é«˜ã„ã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚ç´„60%ã®äººé–“ãƒ¬ãƒ™ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€é•·æœŸçš„ãªæƒ…å ±æ¢ç´¢ã‚¿ã‚¹ã‚¯ã«ã‚‚é©å¿œå¯èƒ½ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã®åˆ†æãŒå®‰å®šæ€§ã¨åŠ¹ç‡å‘ä¸Šã®æ´å¯Ÿã‚’æä¾›ã—ã€å®Ÿä¸–ç•Œã®ã‚·ãƒŠãƒªã‚ªã¸ã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1896" target="_blank" rel="noopener noreferrer">Introducing UI-TARS-1.5, ByteDance, 2025.04</a>
</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1963783886565183913?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>1.5ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¦ã‹ã‚‰5ãƒ¶æœˆã§å¤§å¹…ã«æ€§èƒ½ã‚’å‘ä¸Šã—ãŸæ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Critic.html" target="_blank" rel="noopener noreferrer">#Critic</a>
<span class="issue_date">Issue Date: 2025-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2683" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model, Xiyao Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¦–è¦šã¨è¨€èªã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«ãŠã„ã¦ã€æ‰¹è©•ãƒ¢ãƒ‡ãƒ«ã‚’å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦å†ç·¨æˆã—ã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã«ç›´æ¥é©ç”¨ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ‰¹è©•ãƒ¢ãƒ‡ãƒ«LLaVA-Critic-R1ã‚’ç”Ÿæˆã—ã€è¦–è¦šçš„æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€è‡ªå·±æ‰¹è©•ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€è¿½åŠ ã®è¨“ç·´ãªã—ã«æ¨è«–ã‚¿ã‚¹ã‚¯ã§ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã“ã®çµæœã¯ã€è©•ä¾¡ã¨ç”Ÿæˆã®ä¸¡æ–¹ã«å„ªã‚ŒãŸçµ±ä¸€ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿç¾ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1963248881027748265?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/collections/lmms-lab/llava-critic-r1-68922484e5822b89fab4aca1" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/lmms-lab/llava-critic-r1-68922484e5822b89fab4aca1</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2678" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Benchmarking Optimizers for Large Language Model Pretraining, Andrei Semenov+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®LLMsã®ç™ºå±•ã«ä¼´ã„ã€æœ€é©åŒ–æ‰‹æ³•ã®å¤šæ§˜ãªä¸»å¼µãŒã‚ã‚‹ãŒã€å®Ÿé¨“ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®é•ã„ã«ã‚ˆã‚Šæ¯”è¼ƒãŒé›£ã—ã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ¨™æº–åŒ–ã•ã‚ŒãŸLLMã®äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹æœ€é©åŒ–æŠ€è¡“ã‚’è©•ä¾¡ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚„ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å¤‰åŒ–ã•ã›ã¦æœ€é©ãªã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã‚’ææ¡ˆã€‚ç ”ç©¶ãŒå°†æ¥ã®æœ€é©åŒ–ç ”ç©¶ã®æ–¹å‘æ€§ã‚’ç¤ºã—ã€ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã§å†ç¾æ€§ã‚’ç¢ºä¿ã—ã€æ‰‹æ³•ã®é–‹ç™ºã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haeggee/status/1963217456740139103?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2674" target="_blank" rel="noopener noreferrer">[Paper Note] Fantastic Pretraining Optimizers and Where to Find Them, Kaiyue Wen+, arXiv'25</a>
<br><br>ä¸Šè¨˜è«–æ–‡ã¨çŸ¥è¦‹ãŒä¸€è‡´ã™ã‚‹éƒ¨åˆ†ã€ç•°ãªã‚‹éƒ¨åˆ†ã¯ä½•ã ã‚ã†ã‹ï¼Ÿ</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2666" target="_blank" rel="noopener noreferrer">APERTUS: DEMOCRATIZING OPEN AND COMPLIANT LLMS FOR GLOBAL LANGUAGE ENVIRONMENTS, Apertus Team, 2025.09</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2677" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Jointly Reinforcing Diversity and Quality in Language Model Generations, Tianjian Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- DARLINGã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€å¿œç­”ã®è³ªã¨æ„å‘³çš„å¤šæ§˜æ€§ã‚’æœ€é©åŒ–ã€‚å­¦ç¿’ã•ã‚ŒãŸåˆ†å‰²é–¢æ•°ã‚’ç”¨ã„ã¦å¤šæ§˜æ€§ã‚’æ¸¬å®šã—ã€è³ªã®å ±é…¬ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§é«˜å“è³ªã‹ã¤ç‹¬è‡ªæ€§ã®ã‚ã‚‹å‡ºåŠ›ã‚’ç”Ÿæˆã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€éæ¤œè¨¼å¯èƒ½ãªã‚¿ã‚¹ã‚¯ã¨æ¤œè¨¼å¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®ä¸¡æ–¹ã§å„ªã‚ŒãŸçµæœã‚’ç¤ºã—ã€ç‰¹ã«å¤šæ§˜æ€§ã®æœ€é©åŒ–ãŒæ¢ç´¢ã‚’ä¿ƒé€²ã—ã€è³ªã®å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1963230744173482018?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wyu_nd/status/1969134210578596014?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2676" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GSO: Challenging Software Optimization Tasks for Evaluating SWE-Agents, Manish Shetty+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- é«˜æ€§èƒ½ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã«ãŠã‘ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯GSOã‚’ææ¡ˆã€‚102ã®æœ€é©åŒ–ã‚¿ã‚¹ã‚¯ã‚’ç‰¹å®šã™ã‚‹è‡ªå‹•åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é–‹ç™ºã—ã€ä¸»è¦ãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æˆåŠŸç‡ã¯5%æœªæº€ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚å®šæ€§çš„åˆ†æã«ã‚ˆã‚Šã€ä½ãƒ¬ãƒ™ãƒ«è¨€èªã‚„æœ€é©åŒ–æˆ¦ç•¥ã®èª²é¡ŒãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚ç ”ç©¶ã®é€²å±•ã®ãŸã‚ã«ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚³ãƒ¼ãƒ‰ã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://gso-bench.github.io" target="_blank" rel="noopener noreferrer">https://gso-bench.github.io</a>


</p>
<p>ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®é«˜é€ŸåŒ–ã«é–¢ã™ã‚‹ãƒ™ãƒ³ãƒ</p>
<p>å…ƒãƒã‚¹ãƒˆã«æ²è¼‰ã•ã‚Œã¦ã„ã‚‹ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã¯ã©ã“ã«ã‚ã‚‹ã®ã ã‚ã†ã€‚ã–ã£ã¨è¦‹ãŸæ„Ÿã˜è¦‹å½“ãŸã‚‰ãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2675" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SOAP: Improving and Stabilizing Shampoo using Adam, Nikhil Vyas+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- Shampooã¨ã„ã†å‰å‡¦ç†æ³•ãŒæ·±å±¤å­¦ç¿’ã®æœ€é©åŒ–ã‚¿ã‚¹ã‚¯ã§åŠ¹æœçš„ã§ã‚ã‚‹ä¸€æ–¹ã€è¿½åŠ ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨è¨ˆç®—ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒèª²é¡Œã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€Shampooã¨Adafactorã®é–¢ä¿‚ã‚’æ˜ã‚‰ã‹ã«ã—ã€Shampooã‚’åŸºã«ã—ãŸæ–°ã—ã„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ SOAPã‚’ææ¡ˆã€‚SOAPã¯ã€Adamã¨åŒæ§˜ã«ç¬¬äºŒãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆã®ç§»å‹•å¹³å‡ã‚’æ›´æ–°ã—ã€è¨ˆç®—åŠ¹ç‡ã‚’æ”¹å–„ã€‚å®Ÿé¨“ã§ã¯ã€SOAPãŒAdamWã«å¯¾ã—ã¦40%ä»¥ä¸Šã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°å‰Šæ¸›ã€35%ä»¥ä¸Šã®çµŒéæ™‚é–“çŸ­ç¸®ã‚’é”æˆã—ã€Shampooã«å¯¾ã—ã¦ã‚‚ç´„20%ã®æ”¹å–„ã‚’ç¤ºã—ãŸã€‚SOAPã®å®Ÿè£…ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=IDxZhXrpNf" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=IDxZhXrpNf</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2674" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Fantastic Pretraining Optimizers and Where to Find Them, Kaiyue Wen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AdamWã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ã§åºƒãä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã§ã™ãŒã€ä»£æ›¿ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãŒ1.4å€ã‹ã‚‰2å€ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’æä¾›ã™ã‚‹ã¨ã„ã†ä¸»å¼µã«ã¯äºŒã¤ã®æ¬ ç‚¹ãŒã‚ã‚‹ã¨æŒ‡æ‘˜ã€‚ã“ã‚Œã‚‰ã¯ä¸å‡ç­‰ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã¨èª¤è§£ã‚’æ‹›ãè©•ä¾¡è¨­å®šã§ã‚ã‚Šã€10ç¨®é¡ã®ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã‚’ç³»çµ±çš„ã«ç ”ç©¶ã™ã‚‹ã“ã¨ã§ã€å…¬æ­£ãªæ¯”è¼ƒã®é‡è¦æ€§ã‚’ç¤ºã—ãŸã€‚ç‰¹ã«ã€æœ€é©ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã”ã¨ã«ç•°ãªã‚Šã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã«ã¤ã‚Œã¦ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—åŠ¹æœãŒæ¸›å°‘ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚æœ€ã‚‚é«˜é€Ÿãªã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã¯è¡Œåˆ—ãƒ™ãƒ¼ã‚¹ã®å‰å‡¦ç†å™¨ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŒã€ãã®åŠ¹æœã¯ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚±ãƒ¼ãƒ«ã«åæ¯”ä¾‹ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1963168542872014943?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é‡è¦ãã†ã«è¦‹ãˆã‚‹</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2675" target="_blank" rel="noopener noreferrer">[Paper Note] SOAP: Improving and Stabilizing Shampoo using Adam, Nikhil Vyas+, ICLR'25</a>
</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wen_kaiyue/status/1963633867140526319?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/percyliang/status/1963648131394122222?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è€ƒå¯Ÿ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1964098785019060719?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/AudioLanguageModel.html" target="_blank" rel="noopener noreferrer">#AudioLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2669" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AHELM: A Holistic Evaluation of Audio-Language Models, Tony Lee+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- éŸ³å£°è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆALMsï¼‰ã®è©•ä¾¡ã«ã¯æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒæ¬ å¦‚ã—ã¦ãŠã‚Šã€ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«AHELMã‚’å°å…¥ã€‚AHELMã¯ã€ALMsã®å¤šæ§˜ãªèƒ½åŠ›ã‚’åŒ…æ‹¬çš„ã«æ¸¬å®šã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é›†ç´„ã—ã€10ã®é‡è¦ãªè©•ä¾¡å´é¢ã‚’ç‰¹å®šã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„è©•ä¾¡æŒ‡æ¨™ã‚’æ¨™æº–åŒ–ã—ã€14ã®ALMsã‚’ãƒ†ã‚¹ãƒˆã—ãŸçµæœã€Gemini 2.5 ProãŒ5ã¤ã®å´é¢ã§ãƒˆãƒƒãƒ—ã«ãƒ©ãƒ³ã‚¯ã•ã‚Œã‚‹ä¸€æ–¹ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã¯ä¸å…¬å¹³æ€§ã‚’ç¤ºã•ãªã‹ã£ãŸã€‚AHELMã¯ä»Šå¾Œã‚‚æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„ãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1962799344001917360?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/786" target="_blank" rel="noopener noreferrer">Holistic Evaluation of Language Models, Percy Liang+, TMLR'23</a>
</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2667" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Interpretation Meets Safety: A Survey on Interpretation Methods and   Tools for Improving LLM Safety, Seongmin Lee+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®å®‰å…¨æ€§ã‚’ç†è§£ã—è»½æ¸›ã™ã‚‹ãŸã‚ã®è§£é‡ˆæŠ€è¡“ã®é‡è¦æ€§ã‚’æ¢æ±‚ã—ã€å®‰å…¨æ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹æ‰‹æ³•ã‚’çµ±ä¸€çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§æ•´ç†ã€‚ç´„70ä»¶ã®ç ”ç©¶ã‚’åˆ†é¡ã—ã€æœªè§£æ±ºã®èª²é¡Œã¨ä»Šå¾Œã®æ–¹å‘æ€§ã‚’ç¤ºã™ã€‚ç ”ç©¶è€…ã‚„å®Ÿå‹™è€…ã«ã¨ã£ã¦ã€ã‚ˆã‚Šå®‰å…¨ã§è§£é‡ˆå¯èƒ½ãªLLMã®é€²å±•ã‚’ä¿ƒé€²ã™ã‚‹èª¿æŸ»ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/seongminleee/status/1962956637745942677?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<a class="button" href="articles/Scheduler.html" target="_blank" rel="noopener noreferrer">#Scheduler</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2665" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Training Dynamics of the Cooldown Stage in Warmup-Stable-Decay Learning   Rate Scheduler, Aleksandr Dremov+, TMLR'25</a>
<span class="snippet"><span>GPT Summary</span>- WSDå­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒ•ã‚§ãƒ¼ã‚ºã‚’åˆ†æã—ã€ç•°ãªã‚‹å½¢çŠ¶ãŒãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ã‚¢ã‚¹-ãƒãƒªã‚¢ãƒ³ã‚¹ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’æ˜ã‚‰ã‹ã«ã€‚æ¢ç´¢ã¨æ´»ç”¨ã®ãƒãƒ©ãƒ³ã‚¹ãŒæœ€é©ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ã‚’ç¤ºã—ã€ç‰¹ã«$\beta_2$ã®å€¤ãŒé«˜ã„ã¨æ”¹å–„ãŒè¦‹ã‚‰ã‚Œã‚‹ã€‚æå¤±ã®ãƒ©ãƒ³ãƒ‰ã‚¹ã‚±ãƒ¼ãƒ—ã‚’è¦–è¦šåŒ–ã—ã€ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒ•ã‚§ãƒ¼ã‚ºã®æœ€é©åŒ–ã®é‡è¦æ€§ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haeggee/status/1962852239036293223?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2664" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Efficient Code Embeddings from Code Generation Models, Daria Kryvosheieva+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- jina-code-embeddingsã¯ã€è‡ªç„¶è¨€èªã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã€æŠ€è¡“çš„ãªè³ªå•å¿œç­”ã‚„æ„å‘³çš„ã«é¡ä¼¼ã—ãŸã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã®ç‰¹å®šã‚’è¡Œã†æ–°ã—ã„ã‚³ãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚è‡ªå·±å›å¸°å‹ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã‚’åˆ©ç”¨ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã‚’é€šã˜ã¦åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã€‚å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãªãŒã‚‰æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ã‚³ãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã«ãŠã‘ã‚‹æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/collections/jinaai/jina-code-embeddings-68b0fbfbb0d639e515f82acd" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/jinaai/jina-code-embeddings-68b0fbfbb0d639e515f82acd</a>


</p>
<p>ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç‰¹åŒ–ã®embeddingã§ã€æ¤œç´¢ã€ã‚¯ãƒ­ã‚¹ãƒªãƒ³ã‚¬ãƒ«ãªé¡ä¼¼åº¦ã€æŠ€è¡“ã«é–¢ã™ã‚‹QAã«å¯¾å¿œå¯èƒ½ã‚‰ã—ã„</p>
<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jinaai_/status/1963637135439007824?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/Reranking.html" target="_blank" rel="noopener noreferrer">#Reranking</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2661" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ProRank: Prompt Warmup via Reinforcement Learning for Small Language  Models Reranking, Xianming Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«ãŠã„ã¦ã€SLMã‚’ç”¨ã„ãŸæ–°ã—ã„äºŒæ®µéšãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒProRankã‚’ææ¡ˆã€‚ã¾ãšã€å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦SLMãŒã‚¿ã‚¹ã‚¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç†è§£ã—ã€ç²—ã„é–¢é€£ã‚¹ã‚³ã‚¢ã‚’ç”Ÿæˆã€‚æ¬¡ã«ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã„å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®è³ªã‚’å‘ä¸Šã€‚å®Ÿé¨“çµæœã§ã¯ã€ProRankãŒå…ˆé€²çš„ãªå†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã€ç‰¹ã«ProRank-0.5Bãƒ¢ãƒ‡ãƒ«ãŒ32B LLMã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1962926005774893426?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2645" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs  via Bi-Mode Annealing and Reinforce Learning, Jie Jiang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- R-4Bã¯ã€å•é¡Œã®è¤‡é›‘ã•ã«å¿œã˜ã¦æ€è€ƒã‚’è¡Œã†ã‹ã©ã†ã‹ã‚’é©å¿œçš„ã«åˆ¤æ–­ã™ã‚‹è‡ªå‹•æ€è€ƒå‹ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆMLLMï¼‰ã§ã‚ã‚‹ã€‚æ€è€ƒèƒ½åŠ›ã¨éæ€è€ƒèƒ½åŠ›ã‚’æŒãŸã›ã€ãƒã‚¤ãƒ¢ãƒ¼ãƒ‰ãƒãƒªã‚·ãƒ¼æœ€é©åŒ–ï¼ˆBPOï¼‰ã‚’ç”¨ã„ã¦æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®èµ·å‹•ã‚’ç²¾åº¦è‰¯ãåˆ¤æ–­ã™ã‚‹ã€‚è¨“ç·´ã«ã¯å¤šæ§˜ãªãƒˆãƒ”ãƒƒã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã€å®Ÿé¨“çµæœã¯R-4BãŒ25ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ç‰¹ã«æ¨è«–é›†ç´„å‹ã‚¿ã‚¹ã‚¯ã§ä½ã‚³ã‚¹ãƒˆã§é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1962445854654288036?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>VLMã«thinking, non-thinkingã‚’å…¥åŠ›ã«å¿œã˜ã¦ä½¿ã„åˆ†ã‘ã•ã›ã‚‹æ‰‹æ³•</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2622" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MoE++: Accelerating Mixture-of-Experts Methods with Zero-Computation   Experts, Peng Jin+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Mixture-of-Expertsï¼ˆMoEï¼‰æ‰‹æ³•ã®åŠ¹æœã¨åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€MoE++ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ã‚¼ãƒ­è¨ˆç®—ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’å°å…¥ã—ã€ä½è¨ˆç®—ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã€é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã®å®¹æ˜“ã•ã‚’å®Ÿç¾ã€‚å®Ÿé¨“çµæœã«ã‚ˆã‚Šã€MoE++ã¯å¾“æ¥ã®MoEãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦1.1-2.1å€ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’æä¾›ã—ã€å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=t7P5BUKcYv" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=t7P5BUKcYv</a>


</p>
<p>å¾“æ¥ã®MoEã¨æ¯”ã¹ã¦ã€å°‚é–€å®¶ã¨ã—ã¦zero computation expertsã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€æ€§èƒ½ã‚’ç¶­æŒã—ãªãŒã‚‰åŠ¹ç‡çš„ã«inferenceã‚’ã™ã‚‹æ‰‹æ³•(MoEã«ãŠã„ã¦å…¨ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‡ä¸€ã«æ‰±ã‚ãªã„ï¼‰ã‚’ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br><img src="https://github.com/user-attachments/assets/b71d01ed-92b1-4c4f-ab90-bf9b01c461be" alt="image" loading="lazy"><br><br>zero computation expertsã¯3ç¨®é¡ã§<br>- Zero Experts: å…¥åŠ›ã‚’ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ã«è½ã¨ã™<br>- Copy Experts: å…¥åŠ›xã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ã™ã‚‹<br>- Constant Experts: learnableãªå®šæ•°ãƒ™ã‚¯ãƒˆãƒ«vã‚’å­¦ç¿’ã—ã€xã¨ç·šå½¢çµåˆã—ã¦å‡ºåŠ›ã™ã‚‹ã€‚W_cã«ã‚ˆã£ã¦å…¥åŠ›xã‚’å¤‰æ›ã™ã‚‹ã“ã¨ã§ç·šå½¢è£œã€€çµåˆã®ä¿‚æ•°a1,a2ã‚’å…¥åŠ›ã«å¿œã˜ã¦å‹•çš„ã«æ±ºå®šã™ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/8c2f8f4c-d8d2-44ad-b3f0-4951f9fb2cfb" alt="image" loading="lazy"><br><br>Routingã®æ‰‹æ³•ã‚„gating residualã€å­¦ç¿’æ‰‹æ³•ã®å·¥å¤«ã‚‚ãªã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªã®ã§ã€å¾Œã§èª­ã‚€ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2621" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Shortcut-connected Expert Parallelism for Accelerating   Mixture-of-Experts, Weilin Cai+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- ScMoEã¯ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚²ãƒ¼ãƒˆæ··åˆå°‚é–€å®¶ãƒ¢ãƒ‡ãƒ«ã®è¨ˆç®—è² è·ã‚’åˆ†æ•£ã•ã›ã‚‹æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã€é€šä¿¡ã¨è¨ˆç®—ã®é‡è¤‡ã‚’æœ€å¤§100%å¯èƒ½ã«ã—ã€å…¨å¯¾å…¨é€šä¿¡ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’è§£æ¶ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§1.49å€ã€æ¨è«–ã§1.82å€ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å®Ÿç¾ã—ã€ãƒ¢ãƒ‡ãƒ«å“è³ªã‚‚æ—¢å­˜æ‰‹æ³•ã¨åŒç­‰ã¾ãŸã¯ãã‚Œä»¥ä¸Šã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=GKly3FkxN4&noteId=4tfWewv7R2" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=GKly3FkxN4&noteId=4tfWewv7R2</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2619" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Addressing Tokenization Inconsistency in Steganography and Watermarking   Based on Large Language Models, Ruiyi Yan+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’å‘ä¸Šã•ã›ã‚‹ä¸€æ–¹ã§ã€ã‚¹ãƒ†ã‚¬ãƒã‚°ãƒ©ãƒ•ã‚£ãƒ¼ã¨ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ã‚­ãƒ³ã‚°ã®é‡è¦æ€§ãŒå¢—ã—ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã®ä¸ä¸€è‡´ï¼ˆTIï¼‰ãŒå …ç‰¢æ€§ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã—ã€TIã®åŸå› ã¨ãªã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã®ç‰¹æ€§ã¨ã—ã¦ç¨€å°‘æ€§ã¨ä¸€æ™‚æ€§ã‚’ç‰¹å®šã€‚ã“ã‚Œã«åŸºã¥ãã€ã‚¹ãƒ†ã‚¬ãƒã‚°ãƒ©ãƒ•ã‚£ãƒ¼ç”¨ã®æ®µéšçš„æ¤œè¨¼æ–¹æ³•ã¨ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ã‚­ãƒ³ã‚°ç”¨ã®äº‹å¾Œãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–¹æ³•ã‚’ææ¡ˆã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€TIã«ç›´æ¥å¯¾å‡¦ã™ã‚‹ã“ã¨ã§ã€ã‚¹ãƒ†ã‚¬ãƒã‚°ãƒ©ãƒ•ã‚£ãƒ¼ã®æµæš¢ã•ã‚„å¯¾ã‚¹ãƒ†ã‚¬åˆ†æèƒ½åŠ›ã€ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ã‚­ãƒ³ã‚°ã®å …ç‰¢æ€§ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/murawaki/status/1962043066342310122?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<a class="button" href="articles/Science.html" target="_blank" rel="noopener noreferrer">#Science</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2618" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DeepScholar-Bench: A Live Benchmark and Automated Evaluation for  Generative Research Synthesis, Liana Patel+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ç”Ÿæˆçš„ç ”ç©¶åˆæˆã®è©•ä¾¡ã®ãŸã‚ã«ã€DeepScholar-benchã¨ã„ã†ãƒ©ã‚¤ãƒ–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨è‡ªå‹•è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€ArXivè«–æ–‡ã‹ã‚‰ã‚¯ã‚¨ãƒªã‚’å¼•ãå‡ºã—ã€é–¢é€£ç ”ç©¶ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹å®Ÿéš›ã®ã‚¿ã‚¹ã‚¯ã«ç„¦ç‚¹ã‚’å½“ã¦ã€çŸ¥è­˜åˆæˆã€æ¤œç´¢å“è³ªã€æ¤œè¨¼å¯èƒ½æ€§ã‚’è©•ä¾¡ã€‚DeepScholar-baseã¯å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ç¢ºç«‹ã—ã€ä»–ã®æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦ç«¶äº‰åŠ›ã®ã‚ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ãŸã€‚DeepScholar-benchã¯ä¾ç„¶ã¨ã—ã¦é›£æ˜“åº¦ãŒé«˜ãã€ç”Ÿæˆçš„ç ”ç©¶åˆæˆã®AIã‚·ã‚¹ãƒ†ãƒ ã®é€²æ­©ã«é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>leaderboard:


<a href="https://guestrin-lab.github.io/deepscholar-leaderboard/leaderboard/deepscholar_bench_leaderboard.html" target="_blank" rel="noopener noreferrer">https://guestrin-lab.github.io/deepscholar-leaderboard/leaderboard/deepscholar_bench_leaderboard.html</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lianapatel_/status/1961487232331911651?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2610" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Skip a Layer or Loop it? Test-Time Depth Adaptation of Pretrained LLMs, Ziyue Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- äº‹å‰å­¦ç¿’æ¸ˆã¿ã®LLMã®å±¤ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã—ã¦æ“ä½œã—ã€å„ã‚µãƒ³ãƒ—ãƒ«ã«æœ€é©ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ§‹ç¯‰ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­æœ¨æ¢ç´¢ã‚’ç”¨ã„ã¦ã€æ•°å­¦ãŠã‚ˆã³å¸¸è­˜æ¨è«–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€é©ãªå±¤ã®é€£é–ï¼ˆCoLaï¼‰ã‚’ç‰¹å®šã€‚CoLaã¯æŸ”è»Ÿã§å‹•çš„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æä¾›ã—ã€æ¨è«–åŠ¹ç‡ã‚’æ”¹å–„ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚75%ä»¥ä¸Šã®æ­£ã—ã„äºˆæ¸¬ã«å¯¾ã—ã¦çŸ­ã„CoLaã‚’è¦‹ã¤ã‘ã€60%ä»¥ä¸Šã®ä¸æ­£ç¢ºãªäºˆæ¸¬ã‚’æ­£ã™ã“ã¨ãŒã§ãã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚å›ºå®šã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®é™ç•Œã‚’å…‹æœã™ã‚‹é“ã‚’é–‹ãã€‚</span>
<span class="snippet"><span>Comment</span><p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1961749826028347602?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>äº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ã®forward pathã«ãŠã‘ã‚‹å„layerã‚’building blocksã¨ã¿ãªã—ã¦ã€å…¥åŠ›ã«å¿œã˜ã¦ã‚¹ã‚­ãƒƒãƒ—ã€ã‚ã‚‹ã„ã¯å†å¸°çš„ãªåˆ©ç”¨ã‚’MCTSã«ã‚ˆã£ã¦é¸æŠã™ã‚‹ã“ã¨ã§ã€test timeæ™‚ã®ãƒ¢ãƒ‡ãƒ«ã®æ·±ã•ã‚„ã€ãƒ¢ãƒ‡ãƒ«ã®å‡¡åŒ–æ€§èƒ½ã‚’ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦é©ç”¨ã•ã›ã‚‹ã‚ˆã†ãªæ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ›´æ–°ã¯ä¸è¦ã€‚k, r âˆˆ {1,2,3,4} ã®ç¯„å›²ã§ã€"kå€‹ã®layerã‚’skip"ã€ã‚ã‚‹ã„ã¯kå€‹ã®layerã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’rå›å†å¸°ã™ã‚‹ã€ã¨ã™ã‚‹ã“ã¨ã§æ¢ç´¢ç¯„å›²ã‚’é™å®šçš„ã«ã—testæ™‚ã®éå‰°ãªè¨ˆç®—ã‚’æŠ‘æ­¢ã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€MCTSã«ãŠã‘ã‚‹simulationã®å›æ•°ã¯200å›ã€‚length penaltyã‚’å¤§ããã™ã‚‹ã“ã¨ã§compactãªforward pathã«ãªã‚‹ã‚ˆã†ã«èª¿æ•´ã€10%ã®ç¢ºç‡ã§ã¾ã æ¢ç´¢ã—ã¦ã„ãªã„å­ãƒãƒ¼ãƒ‰ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã™ã‚‹ã“ã¨ã§æ¢ç´¢ã‚’ä¿ƒã™ã‚ˆã†ã«ã—ã¦ã„ã‚‹ã€‚ã‚ªãƒªã‚¸ãƒŠãƒ«ã¨æ¯”è¼ƒã—ã¦å®Ÿè¡Œæ™‚é–“ãŒã©ã®ç¨‹åº¦å¢—ãˆã¦ã—ã¾ã†ã®ã‹ï¼Ÿã«èˆˆå‘³ãŒã‚ã£ãŸãŒã€ãƒ¢ãƒ‡ãƒ«ã®æ·±ã•ã¨ã„ã†è¦³ç‚¹ã§æ¨è«–åŠ¹ç‡ã¯è€ƒå¯Ÿã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆãŸãŒã€å®Ÿè¡Œæ™‚é–“ã¨ã„ã†è¦³ç‚¹ã§ã¯ã–ã£ã¨è¦‹ãŸæ„Ÿã˜è¨˜è¼‰ãŒãªã„ã‚ˆã†ã«è¦‹ãˆãŸã€‚<br><br>&lt;img width="948" height="301" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/0a03cdc2-141b-40a1-a11e-9560187ff7b6"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0a03cdc2-141b-40a1-a11e-9560187ff7b6"&lt;/a&gt;


/&gt;<br><br>ä»¥ä¸‹ã®åºƒç¯„ãªQAã€å¹…åºƒã„é›£æ˜“åº¦ã‚’æŒã¤æ•°å­¦ã«é–¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ï¼ˆAppendix Bã«å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã”ã¨ã«500 sampleã‚’åˆ©ç”¨ã¨è¨˜è¼‰ãŒã‚ã‚‹ï¼‰ã‚’ã—ãŸã¨ã“ã‚ã€å¤§å¹…ã«æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ãŸã ã—ã€8Bç¨‹åº¦ã®ã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã§ã—ã‹å®Ÿé¨“ã¯ã•ã‚Œã¦ã„ãªã„ã€‚<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2613" target="_blank" rel="noopener noreferrer">[Paper Note] Think you have Solved Question Answering? Try ARC, the AI2 Reasoning
  Challenge, Peter Clark+, arXiv'18</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2615" target="_blank" rel="noopener noreferrer">[Paper Note] DART-Math: Difficulty-Aware Rejection Tuning for Mathematical  Problem-Solving, Yuxuan Tong+, NeurIPS'24</a>
<br>&lt;img width="986" height="682" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/c6d88c0a-4ae0-41b7-8526-17d041692f49"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/c6d88c0a-4ae0-41b7-8526-17d041692f49"&lt;/a&gt;


/&gt;</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2611" target="_blank" rel="noopener noreferrer">[Paper Note] Looped Transformers are Better at Learning Learning Algorithms, Liu Yang+, ICLR'24</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2612" target="_blank" rel="noopener noreferrer">[Paper Note] Looped Transformers for Length Generalization, Ying Fan+, ICLR'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2605" target="_blank" rel="noopener noreferrer">[Paper Note] Universal Transformers, Mostafa Dehghani+, ICLR'19</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2241" target="_blank" rel="noopener noreferrer">[Paper Note] Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive   Token-Level Computation, Sangmin Bae+, NeurIPS'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Game.html" target="_blank" rel="noopener noreferrer">#Game</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2609" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TurnaboutLLM: A Deductive Reasoning Benchmark from Detective Games, Yuan Yuan+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- TurnaboutLLMã¨ã„ã†æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€æ¢åµã‚²ãƒ¼ãƒ ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ—ãƒ¬ã‚¤ã‚’é€šã˜ã¦LLMsã®æ¼”ç¹¹çš„æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã€‚è¨¼è¨€ã¨è¨¼æ‹ ã®çŸ›ç›¾ã‚’ç‰¹å®šã™ã‚‹èª²é¡Œã‚’è¨­å®šã—ã€12ã®æœ€å…ˆç«¯LLMã‚’è©•ä¾¡ã—ãŸçµæœã€æ–‡è„ˆã®ã‚µã‚¤ã‚ºã‚„æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚TurnaboutLLMã¯ã€è¤‡é›‘ãªç‰©èªç’°å¢ƒã«ãŠã‘ã‚‹LLMsã®æ¨è«–èƒ½åŠ›ã«æŒ‘æˆ¦ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hemuyu0327/status/1961275336530039244?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>éå¸¸ã«é¢ç™½ãã†ã€‚é€†è»¢è£åˆ¤ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã—ãŸè¶…long contextãªæ¼”ç¹¹çš„ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ãŒæœ€çµ‚çš„ãªå›ç­”ã‚’é–“é•ãˆã‚‹éš›ã¯ã‚ˆã‚Šå¤šãã®æ­£è§£ã«ã¯è²¢çŒ®ã—ãªã„Reasoning Stepã‚’ç¹°ã‚Šè¿”ã—ãŸã‚Šã€QwQ-32Bã¨GPT4.1ã¯åŒç­‰ã®æ€§èƒ½ã ãŒã€non thinkingãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹GPT4.1ãŒã‚ˆã‚Šå°‘é‡ã®Reasoning Step (æœ¬ç ”ç©¶ã§ã¯å›ç­”ã«è‡³ã‚‹ã¾ã§ã«å‡ºåŠ›ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¨å®šç¾©)ã§å›ç­”ã«åˆ°é”ã—ï¼ˆï¼Test Time Scalingã®æ©æµãŒãªã„ï¼‰ã€ãƒ•ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸ãˆã¦æ€§èƒ½ãŒå‘ä¸Šã—ãŸã®ã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„å ´åˆã®ã¿ï¼ˆï¼Test Timeã®reasoningã‚ˆã‚Šã‚‚ã€in-contextã§ã®reasoningãŒé‡è¦ï¼‰ã ã£ãŸã€ã¨ã„ã£ãŸçŸ¥è¦‹ãŒã‚ã‚‹æ¨¡æ§˜ã€‚ã˜ã£ãã‚Šèª­ã¿ãŸã„ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Regularization.html" target="_blank" rel="noopener noreferrer">#Regularization</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2603" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Drop Dropout on Single-Epoch Language Model Pretraining, Houjun Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã¯éå­¦ç¿’ã‚’é˜²ãæ‰‹æ³•ã¨ã—ã¦çŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ãŒã€ç¾ä»£ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã§ã¯éå­¦ç¿’ãŒæŠ‘ãˆã‚‰ã‚Œã‚‹ãŸã‚ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€BERTã‚„Pythiaãƒ¢ãƒ‡ãƒ«ã®å˜ä¸€ã‚¨ãƒãƒƒã‚¯äº‹å‰å­¦ç¿’ã«ãŠã„ã¦ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã®å½±éŸ¿ã‚’èª¿æŸ»ã—ãŸçµæœã€ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’é©ç”¨ã—ãªã„æ–¹ãŒä¸‹æµã®æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒåˆ¤æ˜ã€‚ã¾ãŸã€ã€Œæ—©æœŸãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã€ã‚‚æ€§èƒ½ã‚’ä½ä¸‹ã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆãªã—ã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ¢ãƒ‡ãƒ«ç·¨é›†ã«ãŠã„ã¦ã‚‚ã‚ˆã‚ŠæˆåŠŸã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã€å˜ä¸€ã‚¨ãƒãƒƒã‚¯ã®äº‹å‰å­¦ç¿’ä¸­ã«ã¯ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’çœãã“ã¨ãŒæ¨å¥¨ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1961589435197505584?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2604" target="_blank" rel="noopener noreferrer">[Paper Note] Dropout Reduces Underfitting, Zhuang Liu+, ICML'23</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2591" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive  Simulation, Jianwen Jiang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã€ŒOmniHuman-1.5ã€ã¯ã€ç‰©ç†çš„å¦¥å½“æ€§ã¨æ„å‘³çš„ä¸€è²«æ€§ã‚’å…¼ã­å‚™ãˆãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹ã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã€éŸ³å£°ã€ç”»åƒã€ãƒ†ã‚­ã‚¹ãƒˆã®å…±åŒæ„å‘³ã‚’è§£é‡ˆã™ã‚‹ã“ã¨ã§ã€æ„Ÿæƒ…ã‚„æ„å›³ã«åŸºã¥ã„ãŸå‹•ä½œã‚’ç”Ÿæˆã€‚æ–°ã—ã„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«DiTã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£é–“ã®å¯¾ç«‹ã‚’è»½æ¸›ã—ã€ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ç²¾åº¦ã‚„å‹•ä½œã®è‡ªç„¶ã•ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚è¤‡é›‘ãªã‚·ãƒŠãƒªã‚ªã¸ã®æ‹¡å¼µæ€§ã‚‚ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://omnihuman-lab.github.io/v1_5/" target="_blank" rel="noopener noreferrer">https://omnihuman-lab.github.io/v1_5/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1960957629465026882?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>promptã«ã‚ˆã£ã¦çŠ¶æ³ã‚„æ„Ÿæƒ…ãªã©ã®è¡¨ç¾ã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãŒå¯èƒ½ã‚‰ã—ã„</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1963895614728778187?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<span class="issue_date">Issue Date: 2025-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2590" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AI-Researcher: Autonomous Scientific Innovation, Jiabin Tang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AI-Researcherã¨ã„ã†è‡ªå¾‹å‹ç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ ã‚’ææ¡ˆã—ã€æ–‡çŒ®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰è«–æ–‡ä½œæˆã¾ã§ã®ç ”ç©¶ãƒ—ãƒ­ã‚»ã‚¹ã‚’è‡ªå‹•åŒ–ã€‚Scientist-Benchã‚’ç”¨ã„ã¦AIã®ç ”ç©¶èƒ½åŠ›ã‚’è©•ä¾¡ã—ã€å®Ÿé¨“ã«ã‚ˆã‚Šäººé–“ãƒ¬ãƒ™ãƒ«ã®ç ”ç©¶è«–æ–‡ã‚’ç”Ÿæˆã™ã‚‹æˆåŠŸç‡ã‚’ç¤ºã™ã€‚ã“ã®ç ”ç©¶ã¯ã€è‡ªå¾‹çš„ãªç§‘å­¦çš„é©æ–°ã®æ–°ãŸãªåŸºç›¤ã‚’ç¯‰ãã€‚</span>
<span class="snippet"><span>Comment</span><p>github:


<a href="https://github.com/HKUDS/AI-Researcher" target="_blank" rel="noopener noreferrer">https://github.com/HKUDS/AI-Researcher</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huang_chao4969/status/1961120989015937287?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2488" target="_blank" rel="noopener noreferrer">DeepCode, Data Intelligence Lab@HKU, 2025.08</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2588" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Mobile-Agent-v3: Foundamental Agents for GUI Automation, Jiabo Ye+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€GUI-Owlã¨ã„ã†GUIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã€ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ãŠã‚ˆã³ãƒ¢ãƒã‚¤ãƒ«ç’°å¢ƒã§ã®æœ€å…ˆç«¯æ€§èƒ½ã‚’é”æˆã—ãŸã“ã¨ã‚’å ±å‘Šã—ã¦ã„ã¾ã™ã€‚ç‰¹ã«ã€Mobile-Agent-v3ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’å°å…¥ã—ã€æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã¾ã—ãŸã€‚GUI-Owlã¯ã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ä»®æƒ³ç’°å¢ƒã‚’åˆ©ç”¨ã—ãŸè‡ªå·±é€²åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®æ„æ€æ±ºå®šã‚’æ”¯æ´ã™ã‚‹å¤šæ§˜ãªæ©Ÿèƒ½ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªå¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç‰¹å¾´ã¨ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æˆæœã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>github:


<a href="https://github.com/X-PLUG/MobileAgent?tab=readme-ov-file" target="_blank" rel="noopener noreferrer">https://github.com/X-PLUG/MobileAgent?tab=readme-ov-file</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ali_tongyilab/status/1960994656323620948?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1897" target="_blank" rel="noopener noreferrer">AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents, Christopher Rawles+, ICLR'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2589" target="_blank" rel="noopener noreferrer">[Paper Note] OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real
  Computer Environments, Tianbao Xie+, arXiv'24</a>
</p>
<p>Trajectory-aware Relative Policy Optimization<br>(TRPO)</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2585" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Ultra-Sparse Memory Network, Zihao Huang+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- UltraMemã¯ã€å¤§è¦æ¨¡ã§è¶…ã‚¹ãƒ‘ãƒ¼ã‚¹ãªãƒ¡ãƒ¢ãƒªå±¤ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€Transformerãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’å‰Šæ¸›ã—ã¤ã¤æ€§èƒ½ã‚’ç¶­æŒã™ã‚‹æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ææ¡ˆã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€UltraMemã¯MoEã‚’ä¸Šå›ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç‰¹æ€§ã‚’ç¤ºã—ã€æœ€å¤§2000ä¸‡ã®ãƒ¡ãƒ¢ãƒªã‚¹ãƒ­ãƒƒãƒˆã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ãŒæœ€å…ˆç«¯ã®æ¨è«–é€Ÿåº¦ã¨æ€§èƒ½ã‚’é”æˆã™ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/CurriculumLearning.html" target="_blank" rel="noopener noreferrer">#CurriculumLearning</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2580" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Ovis2.5 Technical Report, Shiyin Lu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Ovis2.5ã¯ã€ãƒã‚¤ãƒ†ã‚£ãƒ–è§£åƒåº¦ã®è¦–è¦šèªè­˜ã¨ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§ã€ç”»åƒã‚’å¯å¤‰è§£åƒåº¦ã§å‡¦ç†ã—ã€è¤‡é›‘ãªè¦–è¦šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è©³ç´°ã‚’ä¿æŒã—ã¾ã™ã€‚æ¨è«–æ™‚ã«ã¯åçœã‚’è¡Œã†ã€Œæ€è€ƒãƒ¢ãƒ¼ãƒ‰ã€ã‚’æä¾›ã—ã€ç²¾åº¦å‘ä¸Šã‚’å›³ã‚Šã¾ã™ã€‚5æ®µéšã®ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã§è¨“ç·´ã•ã‚Œã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã®åŠ¹ç‡çš„ãªå‡¦ç†ã‚’å®Ÿç¾ã€‚Ovis2.5-9Bã¯OpenCompassã§å¹³å‡78.3ã‚’è¨˜éŒ²ã—ã€Ovis2-8Bã«å¯¾ã—ã¦å¤§å¹…ãªæ”¹å–„ã‚’ç¤ºã—ã¾ã—ãŸã€‚Ovis2.5-2Bã‚‚73.9ã‚’é”æˆã—ã€ãƒªã‚½ãƒ¼ã‚¹åˆ¶ç´„ã®ã‚ã‚‹ãƒ‡ãƒã‚¤ã‚¹ã«æœ€é©ã§ã™ã€‚STEMãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚„è¤‡é›‘ãªãƒãƒ£ãƒ¼ãƒˆåˆ†æã«ãŠã„ã¦ã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1960840587168637183?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/AIDC-AI/Ovis2.5-9B" target="_blank" rel="noopener noreferrer">https://huggingface.co/AIDC-AI/Ovis2.5-9B</a>


<br><br>Apache2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹<br><br>GLM-4.1V-9B-Thinkingã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ãªæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/becc30fe-db20-40c1-a94c-143487ffd9ff" alt="image" loading="lazy"><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2128" target="_blank" rel="noopener noreferrer">[Paper Note] GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable  Reinforcement Learning, GLM-V Team+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2575" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] UQ: Assessing Language Models on Unsolved Questions, Fan Nie+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€AIãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã®ãŸã‚ã«ã€æœªè§£æ±ºã®è³ªå•ã«åŸºã¥ãæ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒUQã€ã‚’ææ¡ˆã—ã¾ã™ã€‚UQã¯ã€Stack Exchangeã‹ã‚‰åé›†ã—ãŸ500ã®å¤šæ§˜ãªè³ªå•ã‚’å«ã¿ã€é›£æ˜“åº¦ã¨ç¾å®Ÿæ€§ã‚’å…¼ã­å‚™ãˆã¦ã„ã¾ã™ã€‚è©•ä¾¡ã«ã¯ã€ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€LLMå¯©æŸ»å“¡ã€äººé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’çµ„ã¿åˆã‚ã›ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåé›†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€ç”Ÿæˆè€…-ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’æ´»ç”¨ã—ãŸè¤‡åˆãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥ã€å°‚é–€å®¶ã«ã‚ˆã‚‹å…±åŒæ¤œè¨¼ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãŒå«ã¾ã‚Œã¾ã™ã€‚UQã¯ã€æœ€å‰ç·šã®ãƒ¢ãƒ‡ãƒ«ãŒäººé–“ã®çŸ¥è­˜ã‚’æ‹¡å¼µã™ã‚‹ãŸã‚ã®ç¾å®Ÿçš„ãªèª²é¡Œã‚’è©•ä¾¡ã™ã‚‹æ‰‹æ®µã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/percyliang/status/1960415128501018779?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fannie1208/status/1960387282642592042?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1967511497669767186?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Figure1ã‚’è¦‹ã‚‹ã¨ã‚³ãƒ³ã‚»ãƒ—ãƒˆãŒéå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„ã€‚ç¾åœ¨ã®LLMãŒè‹¦æˆ¦ã—ã¦ã„ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯äººé–“ãŒå›ç­”æ¸ˆã¿ã€ã‹ã¤å®Ÿä¸–ç•Œã®ãƒ‹ãƒ¼ã‚ºã«åã—ã¦æ„å›³çš„ã«ä½œã‚‰ã‚ŒãŸé«˜é›£æ˜“åº¦ãªãƒ‡ãƒ¼ã‚¿ï¼ˆç¾å®Ÿçš„ãªè¨­å®šã§ã¯ç„¡ã„ï¼‰ã§ã‚ã‚Šã€ç¾å®Ÿçš„ã§ã¯ç„¡ã„ãŒé›£æ˜“åº¦ãŒé«˜ã„ã€‚ä¸€æ–¹ã§ã€ç¾å®Ÿã«ãƒ‹ãƒ¼ã‚ºãŒã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä½œã‚‹ã¨ãã‚Œã‚‰ã¯ã—ã°ã—ã°ç°¡å˜ã™ããŸã‚Šã€ãƒãƒƒã‚­ãƒ³ã‚°å¯èƒ½ã ã£ãŸã‚Šã™ã‚‹ã€‚<br><br>ã“ã®ãŸã‚ã€ç¾å®Ÿçš„ãªè¨­å®šã§ãƒ‹ãƒ¼ã‚ºãŒã‚ã‚Šã€ã‹ã¤é›£æ˜“åº¦ãŒé«˜ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒä¸è¶³ã—ã¦ãŠã‚Šã€ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ãã‚‚ãã‚‚äººé–“ãŒã¾ã å›ç­”ã—ã¦ã„ãªã„æœªè§£æ±ºã®å•é¡Œã«ç€ç›®ã—ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä½œã‚Šã¾ã—ãŸã€ã¨ã„ã†è©±ã«è¦‹ãˆã‚‹ã€‚<br><br>å…ƒãƒã‚¹ãƒˆã‚’å’€åš¼ã™ã‚‹ã¨ã€<br><br>æœªè§£æ±ºãªå•é¡Œã¨ã„ã†ã“ã¨ã¯ReferenceãŒå­˜åœ¨ã—ãªã„ã¨ã„ã†ã“ã¨ãªã®ã§ã€ã“ã®ç‚¹ãŒèª²é¡Œã¨ãªã‚‹ã€‚ã“ã®ãŸã‚ã€UQ-Validatorã¨UQ-Platformã‚’å°å…¥ã™ã‚‹ã€‚<br><br>UQ-Validatorã¯è¤‡æ•°ã®LLMã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§å½¢æˆã•ã‚Œã€å›ç­”å€™è£œã®pre-screeningã‚’å®Ÿæ–½ã™ã‚‹ã€‚å›ç­”ã‚’ç”Ÿæˆã—ãŸLLMè‡ªèº«ï¼ˆã‚ã‚‹ã„ã¯åŒã˜ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ï¼‰ãŒValidatorã«åŠ ã‚ã‚‹ã“ã¨ã§è‡ªèº«ã®å›ç­”ã‚’overrateã™ã‚‹å•é¡ŒãŒç”Ÿã˜ã‚‹ãŒã€è¤‡æ•°LLMã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’çµ„ã‚€ã“ã¨ã§ãã®ãƒã‚¤ã‚¢ã‚¹ã‚’è»½æ¸›ã§ãã‚‹ã€ã¨ã®ã“ã¨ã€‚ã¾ãŸã€ã—ã°ã—ã°å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã‚Šã‚‚çµæœã‚’Validationã›ã‚‹æ–¹ãŒã‚¿ã‚¹ã‚¯ã¨ã—ã¦ç°¡å˜ã§ã‚ã‚Šã€å¿…ãšã—ã‚‚é©åˆ‡ã«å›ç­”ã™ã‚‹èƒ½åŠ›ã¯Validatorã«ã¯å¿…è¦ãªã„ã¨ã„ã†ç›´æ„Ÿã«åŸºã¥ã„ã¦ã„ã‚‹ã€‚ãŸã¨ãˆã°ã€Claudeã¯å›ç­”æ€§èƒ½ã¯ä½ãã¦ã‚‚Validatorã¨ã—ã¦ã¯ã†ã¾ãæ©Ÿèƒ½ã™ã‚‹ã€‚ã¾ãŸã€Validatorã¯è»¢ç§»ãŒåŠ¹ãã€ä»–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã—ãŸã‚‚ã®ã‚’æœªè§£æ±ºã®å›ç­”ã«ã‚‚é©ç”¨ã§ãã‚‹ã€‚test-timeã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚‚ã‚ã‚‹ç¨‹åº¦ä½œç”¨ã™ã‚‹ã€‚<br>ç¶šã„ã¦ã€UQ-Platformã«ãŠã„ã¦ã€å›ç­”ã¨Validatorã®å‡ºåŠ›ã‚’è¦‹ãªãŒã‚‰ã€å°‚é–€å®¶ã®æ”¯æ´ã«åŸºã¥ã„ã¦å›ç­”è©•ä¾¡ã—ã€ã¾ãŸã€ãã‚‚ãã‚‚ã®è³ªå•ã®è³ªãªã©ã«ã¤ã„ã¦ã‚³ãƒ¡ãƒ³ãƒˆã™ã‚‹ãªã©ã—ã¦æœªè§£æ±ºã®å•é¡Œã®è§£æ±ºã‚’æ”¯æ´ã§ãã‚‹ã€‚<br><br>ã¿ãŸã„ãªè©±ã‚‰ã—ã„ã€‚éå¸¸ã«é‡è¦ãªç ”ç©¶ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2568" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Nemotron-CC-Math: A 133 Billion-Token-Scale High Quality Math  Pretraining Dataset, Rabeeh Karimi Mahabadi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„æ•°å­¦ã‚³ãƒ¼ãƒ‘ã‚¹ã€ŒNemotron-CC-Mathã€ã‚’ææ¡ˆã—ã€LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€ç§‘å­¦ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã®ãŸã‚ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã€‚å¾“æ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ˆã‚Šã‚‚é«˜å“è³ªã§ã€æ–¹ç¨‹å¼ã‚„ã‚³ãƒ¼ãƒ‰ã®æ§‹é€ ã‚’ä¿æŒã—ã¤ã¤ã€è¡¨è¨˜ã‚’æ¨™æº–åŒ–ã€‚Nemotron-CC-Math-4+ã¯ã€ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€äº‹å‰å­¦ç¿’ã«ã‚ˆã‚ŠMATHã‚„MBPP+ã§ã®æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/karimirabeeh/status/1960682448867426706?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ConceptErasure.html" target="_blank" rel="noopener noreferrer">#ConceptErasure</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2555" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CRISP: Persistent Concept Unlearning via Sparse Autoencoders, Tomer Ashuach+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- CRISPã¯ã€LLMã«ãŠã‘ã‚‹æŒç¶šçš„ãªæ¦‚å¿µã®å¿˜å´ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡ã®è‰¯ã„æ‰‹æ³•ã§ã‚ã‚Šã€ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼ˆSAEï¼‰ã‚’ç”¨ã„ã¦æœ‰å®³ãªçŸ¥è­˜ã‚’åŠ¹æœçš„ã«é™¤å»ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€CRISPã¯WMDPãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å¿˜å´ã‚¿ã‚¹ã‚¯ã§å¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã€ä¸€èˆ¬çš„ãŠã‚ˆã³ãƒ‰ãƒ¡ã‚¤ãƒ³å†…ã®èƒ½åŠ›ã‚’ä¿æŒã—ã¤ã¤ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰¹å¾´ã®æ­£ç¢ºãªæŠ‘åˆ¶ã‚’é”æˆã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1960181627549884685?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2554" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Large Foundation Model for Ads Recommendation, Shangyu Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LFM4Adsã¯ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³åºƒå‘Šã®ãŸã‚ã®å…¨è¡¨ç¾ãƒãƒ«ãƒç²’åº¦è»¢é€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡¨ç¾ï¼ˆURï¼‰ã€ã‚¢ã‚¤ãƒ†ãƒ è¡¨ç¾ï¼ˆIRï¼‰ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼-ã‚¢ã‚¤ãƒ†ãƒ äº¤å·®è¡¨ç¾ï¼ˆCRï¼‰ã‚’åŒ…æ‹¬çš„ã«è»¢é€ã€‚æœ€é©ãªæŠ½å‡ºå±¤ã‚’ç‰¹å®šã—ã€ãƒãƒ«ãƒç²’åº¦ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§è»¢é€å¯èƒ½æ€§ã‚’å¼·åŒ–ã€‚ãƒ†ãƒ³ã‚»ãƒ³ãƒˆã®åºƒå‘Šãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§æˆåŠŸè£ã«å±•é–‹ã•ã‚Œã€2.45%ã®GMVå‘ä¸Šã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1959975943600067006?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2553" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] InternVL3.5: Advancing Open-Source Multimodal Models in Versatility,  Reasoning, and Efficiency, Weiyun Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- InternVL 3.5ã¯ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æ–°ã—ã„ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã§ã€Cascade Reinforcement Learningã‚’ç”¨ã„ã¦æ¨è«–èƒ½åŠ›ã¨åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ç²—ã‹ã‚‰ç´°ã¸ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã«ã‚ˆã‚Šã€MMMã‚„MathVistaãªã©ã®ã‚¿ã‚¹ã‚¯ã§å¤§å¹…ãªæ”¹å–„ã‚’å®Ÿç¾ã€‚Visual Resolution Routerã‚’å°å…¥ã—ã€è¦–è¦šãƒˆãƒ¼ã‚¯ãƒ³ã®è§£åƒåº¦ã‚’å‹•çš„ã«èª¿æ•´ã€‚Decoupled Vision-Language Deploymentæˆ¦ç•¥ã«ã‚ˆã‚Šã€è¨ˆç®—è² è·ã‚’ãƒãƒ©ãƒ³ã‚¹ã•ã›ã€æ¨è«–æ€§èƒ½ã‚’æœ€å¤§16.0%å‘ä¸Šã•ã›ã€é€Ÿåº¦ã‚’4.05å€å‘ä¸Šã€‚æœ€å¤§ãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®MLLMã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã€å•†æ¥­ãƒ¢ãƒ‡ãƒ«ã¨ã®æ€§èƒ½ã‚®ãƒ£ãƒƒãƒ—ã‚’ç¸®å°ã€‚å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ã¨ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1960076908088922147?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhihufrontier/status/1972502056209662441?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2549" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains  RLVR, Xiao Liang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RLVRã¯LLMã®è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦é‡è¦ã ãŒã€å¾“æ¥ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ç”Ÿæˆã®å¤šæ§˜æ€§ã‚’æ¸›å°‘ã•ã›ã‚‹å•é¡ŒãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒãƒªã‚·ãƒ¼ã®ç”Ÿæˆã®å¤šæ§˜æ€§ã‚’åˆ†æã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å•é¡Œã‚’æ›´æ–°ã™ã‚‹ã“ã¨ã§ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼å´©å£Šã‚’è»½æ¸›ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è‡ªå·±å¯¾æˆ¦ã¨å¤‰åˆ†å•é¡Œåˆæˆï¼ˆSvSï¼‰æˆ¦ç•¥ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€ãƒãƒªã‚·ãƒ¼ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚’ç¶­æŒã—ã€Pass@kã‚’å¤§å¹…ã«æ”¹å–„ã€‚AIME24ãŠã‚ˆã³AIME25ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãã‚Œãã‚Œ18.3%ãŠã‚ˆã³22.8%ã®å‘ä¸Šã‚’é”æˆã—ã€12ã®æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§SvSã®å …ç‰¢æ€§ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://mastervito.github.io/SvS.github.io/" target="_blank" rel="noopener noreferrer">https://mastervito.github.io/SvS.github.io/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mastervito0601/status/1959960582670766411?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1960178795530600605?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/NeuralArchitectureSearch.html" target="_blank" rel="noopener noreferrer">#NeuralArchitectureSearch</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2548" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Jet-Nemotron: Efficient Language Model with Post Neural Architecture  Search, Yuxian Gu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Jet-Nemotronã¯æ–°ã—ã„ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€ãƒ•ãƒ«ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ä»¥ä¸Šã®ç²¾åº¦ã‚’æŒã¡ãªãŒã‚‰ç”Ÿæˆã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å¤§å¹…ã«æ”¹å–„ã—ã¾ã™ã€‚Post Neural Architecture Searchï¼ˆPostNASï¼‰ã‚’ç”¨ã„ã¦é–‹ç™ºã•ã‚Œã€äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‹ã‚‰åŠ¹ç‡çš„ã«ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¢ç´¢ã—ã¾ã™ã€‚Jet-Nemotron-2Bãƒ¢ãƒ‡ãƒ«ã¯ã€ä»–ã®å…ˆé€²ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦é«˜ã„ç²¾åº¦ã‚’é”æˆã—ã€ç”Ÿæˆã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’æœ€å¤§53.6å€å‘ä¸Šã•ã›ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1959832287073403137?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hancai_hm/status/1960000017235902722?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacksonatkinsx/status/1960090774122483783?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1960392071384326349?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1960724749790929009?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¶šå ±:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hancai_hm/status/1972794734747033985?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã‚³ãƒ¼ãƒ‰ã¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒãƒªãƒªãƒ¼ã‚¹<br><br>code:


<a href="https://github.com/NVlabs/Jet-Nemotron" target="_blank" rel="noopener noreferrer">https://github.com/NVlabs/Jet-Nemotron</a>


<br>HF:


<a href="https://huggingface.co/collections/jet-ai/jet-nemotron-68ac76e8356b5399ef83ac9c" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/jet-ai/jet-nemotron-68ac76e8356b5399ef83ac9c</a>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2543" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Competition and Attraction Improve Model Fusion, JoÃ£o Abrantes+, GECCO'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆM2N2ï¼‰ã¯ã€è¤‡æ•°ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å°‚é–€çŸ¥è­˜ã‚’çµ±åˆã™ã‚‹é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã€å‹•çš„ãªãƒãƒ¼ã‚¸å¢ƒç•Œèª¿æ•´ã‚„å¤šæ§˜æ€§ä¿æŒãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ç‰¹å¾´ã¨ã—ã€æœ€ã‚‚æœ‰æœ›ãªãƒ¢ãƒ‡ãƒ«ãƒšã‚¢ã‚’ç‰¹å®šã™ã‚‹ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚’ç”¨ã„ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€M2N2ã¯ã‚¼ãƒ­ã‹ã‚‰MNISTåˆ†é¡å™¨ã‚’é€²åŒ–ã•ã›ã€è¨ˆç®—åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã¤ã¤é«˜æ€§èƒ½ã‚’é”æˆã€‚ã¾ãŸã€å°‚é–€çš„ãªè¨€èªã‚„ç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ã‚¸ã«ã‚‚é©ç”¨å¯èƒ½ã§ã€å …ç‰¢æ€§ã¨å¤šæ§˜æ€§ã‚’ç¤ºã™ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sakanaailabs/status/1959799343088857233?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1257" target="_blank" rel="noopener noreferrer">Evolutionary Optimization of Model Merging Recipes, Takuya Akiba+, N/A, Nature Machine Intelligence'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MCP.html" target="_blank" rel="noopener noreferrer">#MCP</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2541" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on  Challenging Queries, Ming Yin+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè¤‡æ•°ã®MCPãƒ„ãƒ¼ãƒ«ã‚’å”èª¿çš„ã«ä½¿ç”¨ã—ã¦ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒLiveMCP-101ã€ã‚’ææ¡ˆã€‚101ã®å®Ÿä¸–ç•Œã®ã‚¯ã‚¨ãƒªã‚’ç”¨ã„ã€çœŸã®å®Ÿè¡Œè¨ˆç”»ã‚’åŸºã«ã—ãŸæ–°ã—ã„è©•ä¾¡ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å°å…¥ã€‚å®Ÿé¨“çµæœã‹ã‚‰ã€æœ€å‰ç·šã®LLMã®æˆåŠŸç‡ãŒ60ï¼…æœªæº€ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€ãƒ„ãƒ¼ãƒ«ã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹èª²é¡ŒãŒæ˜ã‚‰ã‹ã«ã€‚LiveMCP-101ã¯ã€å®Ÿä¸–ç•Œã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆèƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®åŸºæº–ã‚’è¨­å®šã—ã€è‡ªå¾‹AIã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿç¾ã«å‘ã‘ãŸé€²å±•ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1959786499702182271?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1966525731082768782?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2537" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Motif 2.6B Technical Report, Junghwan Lim+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Motif-2.6Bã¯ã€26å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤åŸºç›¤LLMã§ã€é•·æ–‡ç†è§£ã®å‘ä¸Šã‚„å¹»è¦šã®æ¸›å°‘ã‚’ç›®æŒ‡ã—ã€å·®åˆ†æ³¨æ„ã‚„ãƒãƒªãƒãƒ«ãƒ æ´»æ€§åŒ–é–¢æ•°ã‚’æ¡ç”¨ã€‚åºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€åŒã‚µã‚¤ã‚ºã®æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€åŠ¹ç‡çš„ã§ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªåŸºç›¤LLMã®ç™ºå±•ã«å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1959604841577357430?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/Motif-Technologies/Motif-2.6B" target="_blank" rel="noopener noreferrer">https://huggingface.co/Motif-Technologies/Motif-2.6B</a>


</p>
<p>- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1466" target="_blank" rel="noopener noreferrer">Differential Transformer, Tianzhu Ye+, N/A, ICLR'25</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2538" target="_blank" rel="noopener noreferrer">[Paper Note] Polynomial Composition Activations: Unleashing the Dynamics of Large
  Language Models, Zhijian Zhuo+, arXiv'24</a>
<br>- å­¦ç¿’æ‰‹æ³•<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1979" target="_blank" rel="noopener noreferrer">Model Merging in Pre-training of Large Language Models, Yunshui Li+, arXiv'25</a>
<br>    - 8B tokenå­¦ç¿’ã™ã‚‹ã”ã¨ã«ç›´è¿‘6ã¤ã®checkpointã®element-wiseã®å¹³å‡ã‚’ã¨ã‚Šãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã€‚å½“è©²ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦å­¦ç¿’ã‚’ç¶™ç¶šã€ã¨ã„ã†ã“ã¨ã‚’ç¹°ã‚Šè¿”ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å­¦ç¿’ã®ãƒã‚¤ã‚ºã‚’ä½æ¸›ã—ã€çªç„¶ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚·ãƒ•ãƒˆã™ã‚‹ã“ã¨ã‚’é˜²ã<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1060" target="_blank" rel="noopener noreferrer">Effective Long-Context Scaling of Foundation Models, Wenhan Xiong+, N/A, NAACL'24</a>
<br>    - Adaptive Base Frequency (RoPEã®base frequencyã‚’10000ã‹ã‚‰500000ã«ã™ã‚‹ã“ã¨ã§long contextã®attention scoreãŒå°ã•ããªã‚Šã™ãã‚‹ã“ã¨ã‚’é˜²ã)<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2540" target="_blank" rel="noopener noreferrer">[Paper Note] MiniCPM: Unveiling the Potential of Small Language Models with Scalable
  Training Strategies, Shengding Hu+, arXiv'24</a>
 <br>- äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1943" target="_blank" rel="noopener noreferrer">DataComp-LM: In search of the next generation of training sets for
  language models, Jeffrey Li+, arXiv'24</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2539" target="_blank" rel="noopener noreferrer">TxT360, LLM360, 2024.10</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2109" target="_blank" rel="noopener noreferrer">[Paper Note] FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data  Processing to Every Language, Guilherme Penedo+, COLM'25</a>
 <br><br>ã‚’åˆ©ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã€‚åŒç¨‹åº¦ã®ã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒã§ã¯ã‹ãªã‚Šã®gainã‚’å¾—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚èˆˆå‘³æ·±ã„ã€‚<br>Datasetã®Mixtureã®æ¯”ç‡ãªã©ã«ã¤ã„ã¦ã‚‚è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>&lt;img width="705" height="441" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/0a26442e-8075-4cbe-8cc1-f1ff471b7356"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0a26442e-8075-4cbe-8cc1-f1ff471b7356"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<a class="button" href="articles/Inference.html" target="_blank" rel="noopener noreferrer">#Inference</a>
<span class="issue_date">Issue Date: 2025-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2536" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TokenSkip: Controllable Chain-of-Thought Compression in LLMs, Heming Xia+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- Chain-of-Thought (CoT)ã¯LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€é•·ã„CoTå‡ºåŠ›ã¯æ¨è«–é…å»¶ã‚’å¢—åŠ ã•ã›ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€é‡è¦åº¦ã®ä½ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¸æŠçš„ã«ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹TokenSkipã‚’ææ¡ˆã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€TokenSkipã¯CoTãƒˆãƒ¼ã‚¯ãƒ³ã®ä½¿ç”¨ã‚’å‰Šæ¸›ã—ã¤ã¤æ¨è«–æ€§èƒ½ã‚’ç¶­æŒã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ç‰¹ã«ã€Qwen2.5-14B-Instructã§GSM8Kã«ãŠã„ã¦æ¨è«–ãƒˆãƒ¼ã‚¯ãƒ³ã‚’40%å‰Šæ¸›ã—ã€æ€§èƒ½ä½ä¸‹ã¯0.4%æœªæº€ã§ã‚ã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hemingkx/status/1891873475545137245?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Inference.html" target="_blank" rel="noopener noreferrer">#Inference</a>
<span class="issue_date">Issue Date: 2025-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2535" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Pushing the Envelope of LLM Inference on AI-PC, Evangelos Georganas+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è¶…ä½ãƒ“ãƒƒãƒˆLLMãƒ¢ãƒ‡ãƒ«ã®ç™»å ´ã«ã‚ˆã‚Šã€ãƒªã‚½ãƒ¼ã‚¹åˆ¶ç´„ã®ã‚ã‚‹ç’°å¢ƒã§ã®LLMæ¨è«–ãŒå¯èƒ½ã«ã€‚1ãƒ“ãƒƒãƒˆãŠã‚ˆã³2ãƒ“ãƒƒãƒˆã®ãƒã‚¤ã‚¯ãƒ­ã‚«ãƒ¼ãƒãƒ«ã‚’è¨­è¨ˆã—ã€PyTorch-TPPã«çµ±åˆã™ã‚‹ã“ã¨ã§ã€æ¨è«–åŠ¹ç‡ã‚’æœ€å¤§2.2å€å‘ä¸Šã€‚ã“ã‚Œã«ã‚ˆã‚Šã€AI PCã‚„ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹ã§ã®è¶…ä½ãƒ“ãƒƒãƒˆLLMãƒ¢ãƒ‡ãƒ«ã®åŠ¹ç‡çš„ãªå±•é–‹ãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1959379120577826935?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2534" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MAgICoRe: Multi-Agent, Iterative, Coarse-to-Fine Refinement for   Reasoning, Justin Chih-Yao Chen+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- MAgICoReã¯ã€LLMã®æ¨è«–ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€å•é¡Œã®é›£æ˜“åº¦ã«å¿œã˜ã¦æ´—ç·´ã‚’èª¿æ•´ã—ã€éå‰°ãªä¿®æ­£ã‚’å›é¿ã™ã‚‹ã€‚ç°¡å˜ãªå•é¡Œã«ã¯ç²—ã„é›†ç´„ã‚’ã€é›£ã—ã„å•é¡Œã«ã¯ç´°ã‹ã„åå¾©çš„ãªæ´—ç·´ã‚’é©ç”¨ã—ã€å¤–éƒ¨ã®å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ã‚¨ãƒ©ãƒ¼ã®ç‰¹å®šã‚’å‘ä¸Šã•ã›ã‚‹ã€‚3ã¤ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆSolverã€Reviewerã€Refinerï¼‰ã«ã‚ˆã‚‹ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’æ¡ç”¨ã—ã€æ´—ç·´ã®åŠ¹æœã‚’ç¢ºä¿ã™ã‚‹ã€‚Llama-3-8BãŠã‚ˆã³GPT-3.5ã§è©•ä¾¡ã—ãŸçµæœã€MAgICoReã¯ä»–ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€åå¾©ãŒé€²ã‚€ã«ã¤ã‚Œã¦æ”¹å–„ã‚’ç¶šã‘ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cyjustinchen/status/1958957907778969648?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2532" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Think with Confidence, Yichao Fu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã€ŒDeep Think with Confidenceï¼ˆDeepConfï¼‰ã€ã¯ã€LLMã®æ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹ç²¾åº¦ã¨è¨ˆç®—ã‚³ã‚¹ãƒˆã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹æ‰‹æ³•ã§ã€ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã®ä¿¡é ¼æ€§ä¿¡å·ã‚’æ´»ç”¨ã—ã¦ä½å“è³ªãªæ¨è«–ã‚’å‹•çš„ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚è¿½åŠ ã®è¨“ç·´ã‚„èª¿æ•´ã‚’å¿…è¦ã¨ã›ãšã€æ—¢å­˜ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«çµ±åˆå¯èƒ½ã§ã™ã€‚è©•ä¾¡ã®çµæœã€ç‰¹ã«é›£æ˜“åº¦ã®é«˜ã„AIME 2025ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§99.9%ã®ç²¾åº¦ã‚’é”æˆã—ã€ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’æœ€å¤§84.7%å‰Šæ¸›ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://jiaweizzhao.github.io/deepconf" target="_blank" rel="noopener noreferrer">https://jiaweizzhao.github.io/deepconf</a>


<br>vLLMã§ã®å®Ÿè£…:


<a href="https://jiaweizzhao.github.io/deepconf/static/htmls/code_example.html" target="_blank" rel="noopener noreferrer">https://jiaweizzhao.github.io/deepconf/static/htmls/code_example.html</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiawzhao/status/1958982524333678877?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>tooluseã€è¿½åŠ ã®è¨“ç·´ãªã—ã§ã€ã©ã®ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã«ã‚‚é©ç”¨ã§ãã€85%ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³é‡ã‚’æ¸›ã‚‰ã—ãŸä¸Šã§ã€OpenModelã§åˆã‚ã¦AIME2025ã«ãŠã„ã¦99% Acc.ã‚’é”æˆã—ãŸæ‰‹æ³•ã¨ã®ã“ã¨ã€‚vLLMã‚’ç”¨ã„ã¦50 lineç¨‹åº¦ã§å®Ÿè£…ã§ãã‚‹ã‚‰ã—ã„ã€‚</p>
<p>reasoning traceã®confidence(i.e., å¯¾æ•°å°¤åº¦)ã‚’group sizeã‚’æ±ºã‚ã¦windowå˜ä½ã§æ±ºå®šã—ã€ãã‚Œã‚‰ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒ—ãƒ­ã‚»ã‚¹ã§æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€å“è³ªã®ä½ã„reasoning traceã«åŸºã¥ãçµæœã‚’æ’é™¤ã—ã¤ã¤ã€majority votingã«æ´»ç”¨ã™ã‚‹æ–¹æ³•ã€‚ç›´æ„Ÿçš„ã«ã‚‚ã†ã¾ãã„ããã†ã€‚ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã¨ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã®æ¨è«–ã«ã‚ˆã£ã¦æ´»ç”¨æ–¹æ³•ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚ã‚ã¨ã§ã—ã£ã‹ã‚Šèª­ã‚“ã§æ›¸ãã€‚Confidenceã®å®šç¾©ã®ä»•æ–¹ã¯ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®bottom 10%ã€tailãªã©ã•ã¾ã–ã¾ãªå®šç¾©æ–¹æ³•ã¨ã€ãã‚Œã‚‰ã«åŸºã¥ã„ãŸconfidenceã«ã‚ˆã‚‹votingã®é‡ã¿ä»˜ã‘ãŒè¤‡æ•°è€ƒãˆã‚‰ã‚Œã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã«ã‚ˆã£ã¦ä½¿ã„åˆ†ã‘ã‚‹æ¨¡æ§˜ã€‚<br><br>vLLMã«PRã‚‚å‡ºã¦ã„ã‚‹æ¨¡æ§˜ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2531" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ToolVQA: A Dataset for Multi-step Reasoning VQA with External Tools, Shaofeng Yin+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å®Ÿä¸–ç•Œã®ãƒ„ãƒ¼ãƒ«ä½¿ç”¨èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€23Kã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‹ã‚‰ãªã‚‹å¤§è¦æ¨¡ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒToolVQAã€ã‚’ææ¡ˆã€‚ToolVQAã¯ã€å®Ÿéš›ã®è¦–è¦šçš„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨å¤šæ®µéšæ¨è«–ã‚¿ã‚¹ã‚¯ã‚’ç‰¹å¾´ã¨ã—ã€ToolEngineã‚’ç”¨ã„ã¦äººé–“ã®ã‚ˆã†ãªãƒ„ãƒ¼ãƒ«ä½¿ç”¨æ¨è«–ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã€‚7B LFMã‚’å¾®èª¿æ•´ã—ãŸçµæœã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€GPT-3.5-turboã‚’ä¸Šå›ã‚‹ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’æŒã¤ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>äººé–“ã«ã‚ˆã‚‹å°è¦æ¨¡ãªã‚µãƒ³ãƒ—ãƒ«ï¼ˆã‚¤ãƒ¡ãƒ¼ã‚¸ã‚·ãƒŠãƒªã‚ªã€ãƒ„ãƒ¼ãƒ«ã‚»ãƒƒãƒˆã€ã‚¯ã‚¨ãƒªã€å›ç­”ã€tool use trajectory)ã‚’ç”¨ã„ã¦Foundation Modelã«äº‹å‰çŸ¥è­˜ã¨ã—ã¦ä¸ãˆã‚‹ã“ã¨ã§ã€ã‚ˆã‚ŠrealisticãªscenarioãŒåˆæˆã•ã‚Œã‚‹ã‚ˆã†ã«ã—ãŸä¸Šã§æ–°ãŸãªVQAã‚’4kç¨‹åº¦åˆæˆã€‚ãã®å¾Œ10äººã®ã‚¢ãƒãƒ†ãƒ¼ã‚¿ã«ã‚ˆã£ã¦é«˜å“è³ªãªã‚µãƒ³ãƒ—ãƒ«ã«ã®ã¿Filteringã™ã‚‹ã“ã¨ã§ä½œæˆã•ã‚ŒãŸã€å¾“æ¥ã‚ˆã‚Šã‚‚å®Ÿä¸–ç•Œã®è¨­å®šã«è¿‘ãã€reasoningã®è¤‡é›‘ã•ãŒé«˜ã„VQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãªæ¨¡æ§˜ã€‚<br><br><img src="https://github.com/user-attachments/assets/8759244c-89f9-47d7-9c72-81744ef68db1" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/4bc22c9d-79f3-4c16-b5a4-3c054895b416" alt="image" loading="lazy"><br><br>å…·ä½“çš„ã«ã¯ã€image contextxãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€ChatGPT-4oã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã¨ã—ã¦ã€å‰å›ã®ãƒ„ãƒ¼ãƒ«ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®é¸æŠã‚’givenã«ã—ã€äººé–“ãŒä½œæˆã—ãŸãƒ—ãƒ¼ãƒ«ã«å«ã¾ã‚Œã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®ä¸­ã‹ã‚‰Longest Common Subsequence (LCS) ã«ã‚ˆã‚‹ä¸€è‡´åº¦åˆã„ã«åŸºã¥ã„ã¦äººæ‰‹ã«ã‚ˆã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠã—ã€å‹•çš„ã«contextã«å«ã‚ã‚‹ã“ã¨ã§å¤šæ§˜ãªã§å®Ÿä¸–ç•Œã«ã‚ˆã‚Šè¿‘ã—ã„multi step tooluseãªtrajectoryã‚’åˆæˆã™ã‚‹ã€ã¨ã„ã£ãŸæ‰‹æ³•ã«è¦‹ãˆã‚‹ã€‚pp.4--5ã«æ•°å¼ã‚„å›³ã«ã‚ˆã‚‹ç›´æ„Ÿçš„ãªèª¬æ˜ãŒã‚ã‚‹ã€‚ãªãŠã€LCSã‚’å…·ä½“çš„ã«ã©ã®ã‚ˆã†ãªæ–‡å­—åˆ—ã«å¯¾ã—ã¦ã€ã©ã®ã‚ˆã†ãªå‰å‡¦ç†ã‚’ã—ãŸä¸Šã§é©ç”¨ã—ã¦ã„ã‚‹ã®ã‹ã¾ã§ã¯è¿½ãˆã¦ã„ãªã„ã€‚<br><img src="https://github.com/user-attachments/assets/9915c3d5-e984-4611-94d4-999ad08dc49d" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1959125184285483090?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-08-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2530" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Hard Examples Are All You Need: Maximizing GRPO Post-Training Under  Annotation Budgets, Benjamin Pikus+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒªã‚½ãƒ¼ã‚¹ãŒåˆ¶ç´„ã•ã‚ŒãŸçŠ¶æ³ã§ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦ã€é›£æ˜“åº¦ã®ç•°ãªã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã®å„ªå…ˆé †ä½ã‚’æ¤œè¨ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æœ€ã‚‚é›£ã—ã„ä¾‹ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒæœ€å¤§47%ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ãŒç¤ºã•ã‚Œã€é›£ã—ã„ä¾‹ãŒå­¦ç¿’æ©Ÿä¼šã‚’å¤šãæä¾›ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€äºˆç®—åˆ¶ç´„ä¸‹ã§ã®åŠ¹æœçš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã¨ã—ã¦ã€é›£ã—ã„ä¾‹ã‚’å„ªå…ˆã™ã‚‹ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®pass@kãŒä½ã„hardestãªã‚µãƒ³ãƒ—ãƒ«ã§GRPOã‚’å­¦ç¿’ã™ã‚‹ã®ãŒãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ãŒè‰¯ãã€OODã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã‚‚ç™ºæ®ã•ã‚Œã¾ã™ã€ã¨ã„ã†ã®ã‚’Qwen3-4B, 14B, Phi4ã§å®Ÿé¨“ã—ã¦ç¤ºã—ã¾ã—ãŸã€ã¨ã„ã†è©±ã£ã½ã„ï¼Ÿ<br><br>å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã€ãŠã‚ˆã³GSM8Kã€BIG Bench hardã§ã®ã€Tracking Shuffled Objectã®ã¿ã§ã®å®Ÿé¨“ãªæ¨¡æ§˜ï¼Ÿå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã‚‚ã†ã¾ãã„ãã‹ã¯ã‚ˆãåˆ†ã‹ã‚‰ãªã„ã€‚OODã®å®Ÿé¨“ã‚‚AIME2025ã§ã®ã¿ã®å®Ÿé¨“ã—ã¦ã„ã‚‹ã‚ˆã†ãªã®ã§ãã“ã¯ç•™æ„ã—ãŸæ–¹ãŒè‰¯ã„ã‹ã‚‚ã€‚<br>rewardã¨ã—ã¦ä½•ã‚’ä½¿ã£ãŸã®ã‹ãªã©ã®ç´°ã‹ã„å†…å®¹ã‚’è¿½ãˆã¦ã„ãªã„ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/pratyushrt/status/1958947577216524352?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Science.html" target="_blank" rel="noopener noreferrer">#Science</a>
<span class="issue_date">Issue Date: 2025-08-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2528" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Intern-S1: A Scientific Multimodal Foundation Model, Lei Bai+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Intern-S1ã¯ã€ç§‘å­¦å°‚é–€åˆ†é‡ã«ç‰¹åŒ–ã—ãŸã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®å°‚é–€å®¶å‹ãƒ¢ãƒ‡ãƒ«ã§ã€280å„„ã®æ´»æ€§åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«Mixture-of-Expertsï¼ˆMoEï¼‰ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚5Tãƒˆãƒ¼ã‚¯ãƒ³ã§äº‹å‰å­¦ç¿’ã•ã‚Œã€ç‰¹ã«ç§‘å­¦ãƒ‡ãƒ¼ã‚¿ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚äº‹å¾Œå­¦ç¿’ã§ã¯ã€InternBootCampã‚’é€šã˜ã¦å¼·åŒ–å­¦ç¿’ã‚’è¡Œã„ã€Mixture-of-Rewardsã‚’ææ¡ˆã€‚è©•ä¾¡ã§ã¯ã€ä¸€èˆ¬çš„ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã§ç«¶äº‰åŠ›ã‚’ç¤ºã—ã€ç§‘å­¦åˆ†é‡ã®å°‚é–€çš„ãªã‚¿ã‚¹ã‚¯ã§ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã¯Hugging Faceã§å…¥æ‰‹å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1958894938248384542?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>scientific domainã«ç‰¹åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿ã§ç¶™ç¶šäº‹å‰å­¦ç¿’+RL Finetuningã—ãŸãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–è¨€èªãƒ¢ãƒ‡ãƒ«ã‚‰ã—ã„ã€‚</p>
<p>HF:


<a href="https://huggingface.co/internlm/Intern-S1" target="_blank" rel="noopener noreferrer">https://huggingface.co/internlm/Intern-S1</a>


<br><br>Apache 2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹<br><br>ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¯Qwen3ã¨InternViT<br>- InternViT:


<a href="https://huggingface.co/OpenGVLab/InternViT-300M-448px-V2_5" target="_blank" rel="noopener noreferrer">https://huggingface.co/OpenGVLab/InternViT-300M-448px-V2_5</a>


<br><br>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2529" target="_blank" rel="noopener noreferrer">[Paper Note] InternVL: Scaling up Vision Foundation Models and Aligning for Generic   Visual-Linguistic Tasks, Zhe Chen+, CVPR'24</a>
</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1959222471183225033?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚µãƒãƒª:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1960840538225303992?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2025-08-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2527" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Beyond GPT-5: Making LLMs Cheaper and Better via Performance-Efficiency  Optimized Routing, Yiqun Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨åŠ¹ç‡ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ãŸã‚ã«ã€ãƒ†ã‚¹ãƒˆæ™‚ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒAvengers-Proã€ã‚’ææ¡ˆã€‚ã‚¯ã‚¨ãƒªã‚’åŸ‹ã‚è¾¼ã¿ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ã€æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€6ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã€‚æœ€å¼·ã®å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚’å¹³å‡ç²¾åº¦ã§+7%ä¸Šå›ã‚Šã€ã‚³ã‚¹ãƒˆã‚’27%å‰Šæ¸›ã—ã¤ã¤ç´„90%ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã€‚ã™ã¹ã¦ã®å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§æœ€é«˜ã®ç²¾åº¦ã¨æœ€ä½ã®ã‚³ã‚¹ãƒˆã‚’æä¾›ã™ã‚‹ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã‚’é”æˆã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ä¸­ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1958897458408563069?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚¯ã‚¨ãƒªã‚’kmeansã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ã€å„ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®performanceã¨costã‚’äº‹å‰ã«ç®—å‡ºã—ã¦ãŠãã€‚ãã—ã¦æ–°ãŸãªã‚¯ã‚¨ãƒªãŒæ¥ãŸæ™‚ã«ã‚¯ã‚¨ãƒªãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹top pã®ã‚¯ãƒ©ã‚¹ã‚¿ã®performanae-cost efficiencyã‚’åˆè¨ˆã—ã€ã‚¹ã‚³ã‚¢ãŒé«˜ã„ä¸€ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼ˆï¼routing)ã—inferenceã‚’å®Ÿæ–½ã™ã‚‹ã€‚ã‚¯ã‚¨ãƒªã¯Qwenã§embeddingåŒ–ã—ã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«æ´»ç”¨ã™ã‚‹ã€‚ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Î±âˆˆ[0,1]ã«ã‚ˆã£ã¦ã€performance, costã©ã¡ã‚‰ã‚’é‡è¦–ã™ã‚‹ã‹ã®ãƒãƒ©ãƒ³ã‚¹ã‚’èª¿æ•´ã™ã‚‹ã€‚<br><br>ã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ³•ã ãŒã€GPT-5 mediumã¨åŒç­‰ã®ã‚³ã‚¹ãƒˆ/æ€§èƒ½ã€€ã§ã‚ˆã‚Šé«˜ã„ã€€æ€§èƒ½/ã‚³ã‚¹ãƒˆã€€ã‚’å®Ÿç¾ã€‚<br><img src="https://github.com/user-attachments/assets/203f99a3-79b3-4465-985b-2bbd124d3972" alt="image" loading="lazy"></p>
<p>æ€§èƒ½å‘ä¸Šã€ã‚³ã‚¹ãƒˆå‰Šæ¸›ã§ãƒ€ãƒ¡æŠ¼ã—ã—ãŸã„æ™‚ã«ä½¿ãˆãã†ã ãŒã€ç™ºè¡Œã™ã‚‹ã‚¯ã‚¨ãƒªãŒãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãƒ‡ãƒ¼ã‚¿ã€ã‚ã‚‹ã„ã¯ãã‚‚ãã‚‚å…¨ç„¶ãƒ‡ãƒ¼ã‚¿ãªã„ã‚“ã§ã™ã€ã¿ãŸã„ãªçŠ¶æ³ã®å ´åˆã€ã‚¯ã‚¨ãƒªã®å‰²å½“å…ˆã¨ãªã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ã‚’é©åˆ‡ã«ç¢ºä¿ã™ã‚‹ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ç”¨ã„ã‚‹ååˆ†ãªé‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã™ã‚‹ï¼‰ã®ãŒå¤§å¤‰ãªå ´é¢ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚</p>
<p>ï¼ˆå…¨ç„¶æœ¬ç­‹ã¨é–¢ä¿‚ãªã„ãŒã€æœ€è¿‘è«–æ–‡ã®ã‚¿ã‚¤ãƒˆãƒ«ã«Beyondã¤ã‘ã‚‹ã®æµè¡Œã£ã¦ã‚‹â€¦ï¼Ÿï¼‰</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2524" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Prompt Orchestration Markup Language, Yuge Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- POMLï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—è¨€èªï¼‰ã‚’å°å…¥ã—ã€LLMsã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãŠã‘ã‚‹æ§‹é€ ã€ãƒ‡ãƒ¼ã‚¿çµ±åˆã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ„Ÿå—æ€§ã®èª²é¡Œã«å¯¾å‡¦ã€‚ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—ã‚„CSSã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚’æ¡ç”¨ã—ã€å‹•çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ©Ÿèƒ½ã‚„é–‹ç™ºè€…ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã‚’æä¾›ã€‚POMLã®æœ‰åŠ¹æ€§ã‚’2ã¤ã®ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã§æ¤œè¨¼ã—ã€å®Ÿéš›ã®é–‹ç™ºã‚·ãƒŠãƒªã‚ªã§ã®åŠ¹æœã‚’è©•ä¾¡ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://microsoft.github.io/poml/latest/" target="_blank" rel="noopener noreferrer">https://microsoft.github.io/poml/latest/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1958732643996246342?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯éå¸¸ã«èˆˆå‘³æ·±ã„</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2522" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebEvolver: Enhancing Web Agent Self-Improvement with Coevolving World  Model, Tianqing Fang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±æ”¹å–„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãŸã‚ã«ã€å…±é€²åŒ–ã™ã‚‹ãƒ¯ãƒ¼ãƒ«ãƒ‰ãƒ¢ãƒ‡ãƒ«LLMã‚’å°å…¥ã™ã‚‹æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒãƒªã‚·ãƒ¼ã‚’æ´—ç·´ã™ã‚‹è‡ªå·±æŒ‡å°å‹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€è¡Œå‹•é¸æŠã‚’å°ãå…ˆèª­ã¿ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿç¾ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æ—¢å­˜ã®è‡ªå·±é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å¯¾ã—ã¦10%ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’ç¤ºã—ã€æŒç¶šçš„ãªé©å¿œæ€§ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wyu_nd/status/1958632621820584203?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2520" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Are Checklists Really Useful for Automatic Evaluation of Generative  Tasks?, Momoka Furuhashi+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- ç”Ÿæˆã‚¿ã‚¹ã‚¯ã®è‡ªå‹•è©•ä¾¡ã«ãŠã‘ã‚‹æ›–æ˜§ãªåŸºæº–ã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã®ä½¿ç”¨æ–¹æ³•ã‚’æ¤œè¨ã€‚6ã¤ã®ç”Ÿæˆæ–¹æ³•ã¨8ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§è©•ä¾¡ã—ã€é¸æŠçš„ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆãŒãƒšã‚¢ãƒ¯ã‚¤ã‚ºè©•ä¾¡ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ”¹å–„ã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚ãŸã ã—ã€ç›´æ¥ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã§ã¯ä¸€è²«æ€§ãŒãªã„ã€‚äººé–“ã®è©•ä¾¡åŸºæº–ã¨ã®ç›¸é–¢ãŒä½ã„ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆé …ç›®ã‚‚å­˜åœ¨ã—ã€è©•ä¾¡åŸºæº–ã®æ˜ç¢ºåŒ–ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tohoku_nlp_mmk/status/1958717497454002557?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj page:


<a href="https://momo0817.github.io/checklist-effectiveness-study-github.io/" target="_blank" rel="noopener noreferrer">https://momo0817.github.io/checklist-effectiveness-study-github.io/</a>


</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2517" target="_blank" rel="noopener noreferrer" class="title-link">PLaMo Translate: ç¿»è¨³ç‰¹åŒ–å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é–‹ç™º,ä»ŠåŸ+, Jxiv'25</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imos/status/1958687896321630355?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>SFT-&gt;Iterative DPO-&gt;Model Mergeã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚SFTã§ã¯é’ç©ºæ–‡åº«ãªã©ã®ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŒ‡ç¤ºè¿½å¾“æ€§èƒ½ã®é«˜ã„DeepSeek-V3-0324ã«ã‚ˆã£ã¦å…ƒãƒ‡ãƒ¼ã‚¿â†’ç¿»è¨³, ç¿»è¨³â†’å†ç¿»è¨³ãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã—æ´»ç”¨ã€‚ã¾ãŸã€ç¿»è¨³ã®æŒ‡ç¤ºãŒpromptä¸­ã«å­˜åœ¨ã›ãšã¨ã‚‚ï¼ˆæœ¬ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹ã®ã¯ç¿»è¨³ç”¨é€”ã§ã‚ã‚‹ã“ã¨ãŒè‡ªæ˜ã§ã‚ã‚‹ã‹ã‚‰ã¨æ¨å¯Ÿã•ã‚Œã‚‹ï¼‰ç¿»è¨³ã‚’é©åˆ‡ã«å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã€ç‹¬è‡ªã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å­¦ç¿’ã€‚æ–‡ä½“æŒ‡å®šã€å¸¸ä½“ã€æ•¬ä½“ã®æŒ‡å®šã€æ–‡è„ˆè€ƒæ…®ã€èªå½™æŒ‡å®šãã‚Œãã‚Œã«ã†ã„ã¦ç‹¬è‡ªã®ã‚¿ã‚°ã‚’è¨­ã‘ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å½¢æˆã—ç¿»è¨³ã«ç‰¹åŒ–ã—ãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å­¦ç¿’ã€‚<br><br>IterativeDPOã§ã¯ã€DeepSeekV3ã«åŸºã¥ãLLM-as-a-Judgeã¨ã€MetricX(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2658" target="_blank" rel="noopener noreferrer">[Paper Note] MetricX-24: The Google Submission to the WMT 2024 Metrics Shared Task, Juraj Juraska+, arXiv'24</a>
)ã«åŸºã¥ã„ã¦Reward Modelã‚’ãã‚Œãã‚Œå­¦ç¿’ã—ã€1ã¤ã®å…¥åŠ›ã«å¯¾ã—ã¦100å€‹ã®ç¿»è¨³ã‚’ä½œæˆã—ãã‚Œãã‚Œã®Rewardãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚³ã‚¢ã®åˆè¨ˆå€¤ã«åŸºã¥ã„ã¦Rejection Samplingã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§Preference dataã‚’æ§‹ç¯‰ã€‚3æ®µéšã®DPOã‚’å®Ÿæ–½ã—ã€æ®µéšã”ã¨ã«Rewardãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ã¦é«˜å“è³ªãªPreference Dataã«çµã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã€‚<br><br>ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã§ã¯DPOã®å„æ®µéšã®ãƒ¢ãƒ‡ãƒ«ã‚’é‡ã¿ä»˜ãã§ãƒãƒ¼ã‚¸ã™ã‚‹ã“ã¨ã§å„æ®µéšã§ã®é•·æ‰€ã‚’çµ„ã¿åˆã‚ã›ãŸã¨ã®ã“ã¨ã€‚</p>
<p>ã‚µãƒ¼ãƒ“ã‚¹ãƒªãƒªãƒ¼ã‚¹:


<a href="https://prtimes.jp/main/html/rd/p/000000019.000156310.html?hm_ct=d17807e98595783ee6edfc7ae00fe95a&hm_cv=87e6d4e056b010261ecdc77d7ac8eb6c&hm_cs=1638145470668f4b36f218d2.35741174&hm_mid=m3hk6&hm_id=m3hk6&hm_h=a03.hm-f.jp" target="_blank" rel="noopener noreferrer">https://prtimes.jp/main/html/rd/p/000000019.000156310.html?hm_ct=d17807e98595783ee6edfc7ae00fe95a&hm_cv=87e6d4e056b010261ecdc77d7ac8eb6c&hm_cs=1638145470668f4b36f218d2.35741174&hm_mid=m3hk6&hm_id=m3hk6&hm_h=a03.hm-f.jp</a>


</p>
<p>2025.1010é…ä¿¡ã®ã€Œå²¡é‡åŸå¤§è¼”ã®ãƒ©ãƒ³ãƒã‚¿ã‚¤ãƒ ãƒˆãƒ¼ã‚¯ Vol.52 ç•ªå¤–ç·¨ã€ŒãªãœPLaMoç¿»è¨³ã¯è‡ªç„¶ãªã®ã‹ï¼Ÿã€ã«ãŠã„ã¦è©³ç´°ãŒèªã‚‰ã‚Œã¦ã„ã‚‹ã®ã§å‚ç…§ã®ã“ã¨ã€‚ç‰¹ã«ãªãœæ—¥æœ¬èªã«å¼·ã„LLMãŒå¤§äº‹ãªã®ã‹ï¼Ÿã¨ã„ã†è©±ãŒéå¸¸ã«ãŠã‚‚ã—ã‚ã‹ã£ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2516" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language  Models, Wen Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- dLLMsã¯ä¸­é–“äºˆæ¸¬ã‚’æ¨ã¦ãŒã¡ã ãŒã€æ™‚é–“çš„æŒ¯å‹•ãŒé‡è¦ãªç¾è±¡ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ™‚é–“çš„ä¸€è²«æ€§ã‚’æ´»ç”¨ã™ã‚‹2ã¤ã®æ–¹æ³•ã‚’ææ¡ˆã€‚1ã¤ç›®ã¯ã€ãƒ†ã‚¹ãƒˆæ™‚ã«äºˆæ¸¬ã‚’é›†ç´„ã™ã‚‹æ™‚é–“çš„è‡ªå·±ä¸€è²«æ€§æŠ•ç¥¨ã€2ã¤ç›®ã¯ä¸­é–“äºˆæ¸¬ã®å®‰å®šæ€§ã‚’æ¸¬ã‚‹æ™‚é–“çš„æ„å‘³ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚’å ±é…¬ä¿¡å·ã¨ã™ã‚‹æ™‚é–“çš„ä¸€è²«æ€§å¼·åŒ–ã€‚å®Ÿé¨“çµæœã§ã¯ã€Countdownãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§24.7%ã®æ”¹å–„ã‚’é”æˆã—ã€ä»–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚‚å‘ä¸Šã‚’ç¤ºã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€dLLMsã®æ™‚é–“çš„ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã®å¯èƒ½æ€§ãŒå¼·èª¿ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1958702248055513335?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>dLLMã®ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°éç¨‹ã«ãŠã„ã¦é€”ä¸­ã«æ­£è§£ãŒè¡¨å‡ºã—ã¦ã„ã‚‹ã®ã«æ™‚é–“ç™ºå±•ã¨ã¨ã‚‚ã«æ¶ˆãˆã¦ã—ã¾ã†å•é¡ŒãŒã‚ã‚‹ã‚‰ã—ãã€ãã‚Œã«å¯¾ã—ã¦ã€ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—ã«ãŠã„ã¦stableãªäºˆæ¸¬ã‚’è¡Œã†Self-Consistencyãƒ™ãƒ¼ã‚¹ã®decodingæ‰‹æ³•ã¨ã€æ„å‘³çš„ãªã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚’rewardã«åŠ ãˆæ™‚é–“ç™ºå±•ã§å®‰å®šã™ã‚‹ã‚ˆã†ã«post trainingã™ã‚‹ã“ã¨ã§å¯¾å‡¦ã—ã¾ã™ã€ã¿ãŸã„ãªè©±ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2501" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Agent Laboratory: Using LLM Agents as Research Assistants, Samuel Schmidgall+, EMNLP'25 Findings</a>
<span class="snippet"><span>GPT Summary</span>- Agent Laboratoryã¯ã€å…¨è‡ªå‹•ã®LLMãƒ™ãƒ¼ã‚¹ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€ç ”ç©¶ã‚¢ã‚¤ãƒ‡ã‚¢ã‹ã‚‰æ–‡çŒ®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€å®Ÿé¨“ã€å ±å‘Šæ›¸ä½œæˆã¾ã§ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Œäº†ã—ã€è³ªã®é«˜ã„ç ”ç©¶æˆæœã‚’ç”Ÿæˆã—ã¾ã™ã€‚äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å„æ®µéšã§å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ã§ã€ç ”ç©¶ã®è³ªã‚’å‘ä¸Šã•ã›ã€ç ”ç©¶è²»ç”¨ã‚’84%å‰Šæ¸›ã€‚æœ€å…ˆç«¯ã®æ©Ÿæ¢°å­¦ç¿’ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã€ç§‘å­¦çš„ç™ºè¦‹ã®åŠ é€Ÿã‚’ç›®æŒ‡ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/srschmidgall/status/1958272229223067789?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj page:


<a href="https://agentlaboratory.github.io" target="_blank" rel="noopener noreferrer">https://agentlaboratory.github.io</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<span class="issue_date">Issue Date: 2025-08-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2496" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ComputerRL: Scaling End-to-End Online Reinforcement Learning for  Computer Use Agents, Hanyu Lai+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ComputerRLã¯ã€è‡ªå¾‹çš„ãªãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ã®ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€API-GUIãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ç”¨ã„ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãƒ‡ã‚¸ã‚¿ãƒ«ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã‚’æ“ä½œã—ã¾ã™ã€‚åˆ†æ•£RLã‚¤ãƒ³ãƒ•ãƒ©ã‚’é–‹ç™ºã—ã€æ•°åƒã®ä»®æƒ³ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ç’°å¢ƒã§ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªå¼·åŒ–å­¦ç¿’ã‚’å®Ÿç¾ã€‚Entropulseãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã«ã‚ˆã‚Šã€é•·æœŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼å´©å£Šã‚’è»½æ¸›ã€‚GLM-4-9B-0414ã‚’ç”¨ã„ãŸAutoGLM-OS-9Bã¯ã€OSWorldãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§48.1%ã®æ–°ã—ã„æœ€å…ˆç«¯ç²¾åº¦ã‚’é”æˆã—ã€ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—è‡ªå‹•åŒ–ã«ãŠã‘ã‚‹é‡è¦ãªæ”¹å–„ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1958299060215128333?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1958333917255389218?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Entropy.html" target="_blank" rel="noopener noreferrer">#Entropy</a>
<span class="issue_date">Issue Date: 2025-08-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2490" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Depth-Breadth Synergy in RLVR: Unlocking LLM Reasoning Gains with  Adaptive Exploration, Zhicheng Yang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ã«ãŠã‘ã‚‹æ¤œè¨¼å¯èƒ½ãªå ±é…¬ï¼ˆRLVRï¼‰ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’å¼•ãå‡ºã™ãŒã€æ·±ã•ã¨å¹…ã®2ã¤ã®æ¬¡å…ƒã«åˆ¶ç´„ã•ã‚Œã¦ã„ã‚‹ã€‚GRPOã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®åˆ†æã‹ã‚‰ã€ä½ç²¾åº¦ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®é‡ã¿ãŒè»½æ¸›ã•ã‚Œã‚‹ãƒã‚¤ã‚¢ã‚¹ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚ã“ã‚Œã‚’æ˜¯æ­£ã™ã‚‹ãŸã‚ã«ã€é›£æ˜“åº¦é©å¿œå‹ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆDARSï¼‰ã‚’å°å…¥ã—ã€é›£ã—ã„å•é¡Œã®é‡ã¿ã‚’å†èª¿æ•´ã€‚DARSã¯åæŸæ™‚ã«æ¨è«–ã‚³ã‚¹ãƒˆãªã—ã§Pass@Kã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ã•ã‚‰ã«ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å¹…ã‚’æ‹¡å¤§ã™ã‚‹ã“ã¨ã§Pass@1ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚‚å‘ä¸Šã€‚DARS-Bã‚’ææ¡ˆã—ã€å¹…ã¨æ·±ã•ã®é©å¿œçš„ãªæ¢æŸ»ãŒRLVRã®æ¨è«–åŠ›ã‚’å¼•ãå‡ºã™éµã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1958092835665977806?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2485" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AutoCodeBench: Large Language Models are Automatic Code Benchmark  Generators, Jason Chou+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AutoCodeGenã‚’ææ¡ˆã—ã€æ‰‹å‹•æ³¨é‡ˆãªã—ã§é«˜é›£æ˜“åº¦ã®å¤šè¨€èªã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è‡ªå‹•ç”Ÿæˆã€‚ã“ã‚Œã«åŸºã¥ãã€3,920ã®å•é¡Œã‹ã‚‰ãªã‚‹AutoCodeBenchã‚’å°å…¥ã—ã€20ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã«å‡ç­‰ã«åˆ†é…ã€‚30ä»¥ä¸Šã®LLMsã‚’è©•ä¾¡ã—ãŸçµæœã€æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚å¤šæ§˜æ€§ã‚„è¤‡é›‘ã•ã«è‹¦åŠ´ã—ã¦ã„ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚AutoCodeBenchã‚·ãƒªãƒ¼ã‚ºã¯ã€å®Ÿç”¨çš„ãªå¤šè¨€èªã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚·ãƒŠãƒªã‚ªã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ãŸã‚ã®è²´é‡ãªãƒªã‚½ãƒ¼ã‚¹ã¨ãªã‚‹ã“ã¨ã‚’æœŸå¾…ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://autocodebench.github.io/" target="_blank" rel="noopener noreferrer">https://autocodebench.github.io/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tencenthunyuan/status/1957751900608110982?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Overthinking.html" target="_blank" rel="noopener noreferrer">#Overthinking</a>
<a class="button" href="articles/Underthinking.html" target="_blank" rel="noopener noreferrer">#Underthinking</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2478" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OptimalThinkingBench: Evaluating Over and Underthinking in LLMs, Pranjal Aggarwal+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ€è€ƒå‹LLMã¯è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ãã€å˜ç´”ãªå•é¡Œã«å¯¾ã—ã¦éå‰°ã«è€ƒãˆã€éæ€è€ƒå‹LLMã¯è¿…é€Ÿã ãŒé›£ã—ã„æ¨è«–ã«å¯¾ã—ã¦è€ƒãˆãŒæµ…ã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æœ€é©ãªãƒ¢ãƒ‡ãƒ«é¸æŠãŒã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å§”ã­ã‚‰ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€OptimalThinkingBenchã‚’å°å…¥ã—ã€éå‰°æ€è€ƒã¨è€ƒãˆä¸è¶³ã‚’è©•ä¾¡ã™ã‚‹çµ±ä¸€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æä¾›ã€‚72ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã®å˜ç´”ãªã‚¯ã‚¨ãƒªã¨11ã®æŒ‘æˆ¦çš„ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€2ã¤ã®ã‚µãƒ–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€33ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ãŸçµæœã€æœ€é©ãªæ€è€ƒãƒ¢ãƒ‡ãƒ«ã¯å­˜åœ¨ã›ãšã€æ€è€ƒå‹ãƒ¢ãƒ‡ãƒ«ã¯éå‰°ã«è€ƒãˆã€éæ€è€ƒå‹ãƒ¢ãƒ‡ãƒ«ã¯æµ…ã„çµæœã‚’ç¤ºã—ãŸã€‚å°†æ¥çš„ã«ã¯ã€ã‚ˆã‚Šè‰¯ã„çµ±ä¸€çš„ã‹ã¤æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã®å¿…è¦æ€§ãŒæµ®ãå½«ã‚Šã¨ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1957627532963926389?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ƒãƒã‚¹ãƒˆã®è‘—è€…ã«ã‚ˆã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰ãŒéå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„ã®ã§ãã¡ã‚‰ã‚’å‚ç…§ã®ã“ã¨ã€‚<br>ã–ã£ãã‚Šè¨€ã†ã¨ã€Overthinkingï¼ˆè€ƒãˆã™ãã¦å¤§é‡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¶ˆè²»ã—ãŸä¸Šã«å›ç­”ãŒèª¤ã£ã¦ã„ã‚‹; ãƒˆãƒ¼ã‚¯ãƒ³é‡â†“ã¨LLMã«ã‚ˆã‚‹Judge Scoreâ†‘ã§è©•ä¾¡ï¼‰ã¨Underthinkingï¼ˆå…¨ç„¶è€ƒãˆãšã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¶ˆè²»ã—ãªã‹ã£ãŸä¸Šã«å›ç­”ãŒèª¤ã£ã¦ã„ã‚‹; Accuracyâ†‘ã§è©•ä¾¡ï¼‰ã‚’ãã‚Œãã‚Œè©•ä¾¡ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚’åé›†ã—ã€ãã‚Œã‚‰ã®ã‚¹ã‚³ã‚¢ã®çµ„ã¿åˆã‚ã›ã§ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ã«å¿œã˜ã¦ã©ã‚Œã ã‘çš„ç¢ºã«Thinkingã§ãã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚<br><br>Overthinkingã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒ«ã¯ã€å¤šãã®LLMã§agreementãŒã¨ã‚Œã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªQAã«ã‚ˆã£ã¦æ§‹ç¯‰ã€‚ä¸€æ–¹ã€Underthinkingã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒ«ã¯ã€small reasoning modelãŒlarge non reasoning modelã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã™ã‚µãƒ³ãƒ—ãƒ«ã‚’åé›†ã€‚<br><img src="https://github.com/user-attachments/assets/5383e385-fda9-41ae-a9a5-aebf494ca79e" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/c08cfe60-8a29-4ebf-8875-081f7ae7d19f" alt="image" loading="lazy"><br><br>ç¾çŠ¶Non Thinking Modelã§ã¯Qwen3-235B-A22Bã®æ€§èƒ½ãŒè‰¯ãã€Thinking Modelã§ã¯gpt-oss-120Bã®æ€§èƒ½ãŒè‰¯ã„ã€‚ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãªãƒ¢ãƒ‡ãƒ«ã§ã¯ãã‚Œãã‚Œã€Claude-Sonnet4, o3ã®æ€§èƒ½ãŒè‰¯ã„ã€‚å…¨ä½“ã¨ã—ã¦ã¯o3ã®æ€§èƒ½ãŒæœ€ã‚‚è‰¯ã„ã€‚<br><img src="https://github.com/user-attachments/assets/5f5c1ead-d5fa-40a8-9a1b-90d4170ae3ee" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2476" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BeyondWeb: Lessons from Scaling Synthetic Data for Trillion-scale  Pretraining, Pratyush Maini+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒBeyondWebã€ã‚’ææ¡ˆã—ã€é«˜å“è³ªãªåˆæˆãƒ‡ãƒ¼ã‚¿ã®ç”ŸæˆãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚BeyondWebã¯ã€å¾“æ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’ç™ºæ®ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é€Ÿåº¦ã‚‚å‘ä¸Šã€‚ç‰¹ã«ã€3Bãƒ¢ãƒ‡ãƒ«ãŒ8Bãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã™ã€‚åˆæˆãƒ‡ãƒ¼ã‚¿ã®å“è³ªå‘ä¸Šã«ã¯å¤šãã®è¦å› ã‚’æœ€é©åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€å˜ç´”ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯é™ç•ŒãŒã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/pratyushmaini/status/1957456720265154752?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2475" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid  Mamba-Transformer Reasoning Model, NVIDIA+, arXiv'25, 2025.08</a>
<span class="snippet"><span>GPT Summary</span>- Nemotron-Nano-9B-v2ã¯ã€æ¨è«–ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å‘ä¸Šã•ã›ã¤ã¤æœ€å…ˆç«¯ã®ç²¾åº¦ã‚’é”æˆã™ã‚‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰Mamba-Transformerãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ã€‚è‡ªå·±æ³¨æ„å±¤ã®ä¸€éƒ¨ã‚’Mamba-2å±¤ã«ç½®ãæ›ãˆã€é•·ã„æ€è€ƒãƒˆãƒ¬ãƒ¼ã‚¹ã®ç”Ÿæˆã‚’é«˜é€ŸåŒ–ã€‚12å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’20å…†ãƒˆãƒ¼ã‚¯ãƒ³ã§äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€Minitronæˆ¦ç•¥ã§åœ§ç¸®ãƒ»è’¸ç•™ã€‚æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦ã€æœ€å¤§6å€ã®æ¨è«–ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å®Ÿç¾ã—ã€ç²¾åº¦ã‚‚åŒç­‰ä»¥ä¸Šã€‚ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯Hugging Faceã§å…¬é–‹äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1957583208494579909?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>äº‹å‰å­¦ç¿’ã«åˆ©ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚‚å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã¨ã®ã“ã¨(Nemotron-CC):<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1957604137379742022?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1958290562160996688?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚µãƒãƒª:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1960840554868302082?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/CrossDomain.html" target="_blank" rel="noopener noreferrer">#CrossDomain</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-08-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2466" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] xbench: Tracking Agents Productivity Scaling with Profession-Aligned  Real-World Evaluations, Kaiyuan Chen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã€Œxbenchã€ã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã¨å®Ÿä¸–ç•Œã®ç”Ÿç”£æ€§ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸå‹•çš„ãªè©•ä¾¡ã‚¹ã‚¤ãƒ¼ãƒˆã§ã€æ¥­ç•Œå°‚é–€å®¶ãŒå®šç¾©ã—ãŸã‚¿ã‚¹ã‚¯ã‚’ç”¨ã„ã¦å•†æ¥­çš„ã«é‡è¦ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã—ã¦ã„ã¾ã™ã€‚ãƒªã‚¯ãƒ«ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã¨ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã®2ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æç¤ºã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®åŸºæº–ã‚’ç¢ºç«‹ã—ã¾ã™ã€‚è©•ä¾¡çµæœã¯ç¶™ç¶šçš„ã«æ›´æ–°ã•ã‚Œã€https://xbench.org ã§å…¥æ‰‹å¯èƒ½ã§ã™ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2455" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Survey on Parallel Text Generation: From Parallel Decoding to  Diffusion Language Models, Lingzhe Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ä¸¦åˆ—ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã¯ã€LLMã®ç”Ÿæˆé€Ÿåº¦ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æŠ€è¡“ã§ã‚ã‚Šã€è‡ªå·±å›å¸°ç”Ÿæˆã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’æ‰“ç ´ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ä¸¦åˆ—ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆæ‰‹æ³•ã‚’ARãƒ™ãƒ¼ã‚¹ã¨éARãƒ™ãƒ¼ã‚¹ã«åˆ†é¡ã—ã€ãã‚Œãã‚Œã®æŠ€è¡“ã‚’è©•ä¾¡ã€‚é€Ÿåº¦ã€å“è³ªã€åŠ¹ç‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è€ƒå¯Ÿã—ã€ä»Šå¾Œã®ç ”ç©¶ã®æ–¹å‘æ€§ã‚’ç¤ºã™ã€‚é–¢é€£è«–æ–‡ã‚’é›†ã‚ãŸGitHubãƒªãƒã‚¸ãƒˆãƒªã‚‚ä½œæˆã€‚</span>
<span class="snippet"><span>Comment</span><p>Taxonomyã¨æ‰‹æ³•ä¸€è¦§ã€‚Draft and Verifyingã¯å€‹äººçš„ã«éå¸¸ã«èˆˆå‘³ãŒã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/019469c3-f906-42e3-91d9-f99f75d8d501" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Trustfulness.html" target="_blank" rel="noopener noreferrer">#Trustfulness</a>
<a class="button" href="articles/Health.html" target="_blank" rel="noopener noreferrer">#Health</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2452" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] HealthBench: Evaluating Large Language Models Towards Improved Human  Health, Rahul K. Arora+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒHealthBenchã€ã‚’ç™ºè¡¨ã€‚5,000ä»¶ã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã‚’åŸºã«ã€262äººã®åŒ»å¸«ã«ã‚ˆã‚‹è©•ä¾¡åŸºæº–ã§ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¨å®‰å…¨æ€§ã‚’æ¸¬å®šã€‚å¾“æ¥ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ç•°ãªã‚Šã€48,562ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè©•ä¾¡åŸºæº–ã‚’ç”¨ã„ã¦å¤šæ§˜ãªå¥åº·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è©•ä¾¡ã€‚GPT-3.5 Turboã¨GPT-4oã®æ¯”è¼ƒã§åˆæœŸã®é€²å±•ã‚’ç¤ºã—ã€å°å‹ãƒ¢ãƒ‡ãƒ«ã®æ”¹å–„ãŒé¡•è‘—ã€‚æ–°ãŸã«ã€ŒHealthBench Consensusã€ã¨ã€ŒHealthBench Hardã€ã®2ã¤ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ãƒªãƒªãƒ¼ã‚¹ã€‚HealthBenchãŒå¥åº·åˆ†é‡ã§ã®ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’æœŸå¾…ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2451" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents, Jason Wei+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- BrowseCompã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¦ã‚§ãƒ–ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã®1,266ã®è³ªå•ã‹ã‚‰ãªã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€çµ¡ã¿åˆã£ãŸæƒ…å ±ã‚’æ¢ã™ã“ã¨ã‚’è¦æ±‚ã—ã¾ã™ã€‚ã‚·ãƒ³ãƒ—ãƒ«ã§ä½¿ã„ã‚„ã™ãã€çŸ­ã„å›ç­”ãŒæ±‚ã‚ã‚‰ã‚Œã€å‚ç…§å›ç­”ã¨ã®ç…§åˆãŒå®¹æ˜“ã§ã™ã€‚ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã€ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®é‡è¦ãªãƒ„ãƒ¼ãƒ«ã§ã‚ã‚Šã€æŒç¶šåŠ›ã¨å‰µé€ æ€§ã‚’æ¸¬å®šã—ã¾ã™ã€‚è©³ç´°ã¯GitHubã§å…¥æ‰‹å¯èƒ½ã§ã™ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2447" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] UI-Venus Technical Report: Building High-performance UI Agents with RFT, Zhangxuan Gu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- UI-Venusã¯ã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ããƒã‚¤ãƒ†ã‚£ãƒ–UIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã€UIã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã¨ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚7BãŠã‚ˆã³72Bãƒãƒªã‚¢ãƒ³ãƒˆã¯ã€Screenspot-V2 / Proãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é«˜ã„æˆåŠŸç‡ã‚’è¨˜éŒ²ã—ã€æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã€‚å ±é…¬é–¢æ•°ã‚„ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã‚’å°å…¥ã—ã€ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æ–°ã—ã„è‡ªå·±é€²åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚‚ææ¡ˆã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®UIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å…¬é–‹ã—ã€ã•ã‚‰ãªã‚‹ç ”ç©¶ã‚’ä¿ƒé€²ã€‚ã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¥æ‰‹å¯èƒ½ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1956344636831662567?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1957262667493826891?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/collections/inclusionAI/ui-venus-689f2fb01a4234cbce91c56a" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/inclusionAI/ui-venus-689f2fb01a4234cbce91c56a</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2436" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OpenCUA: Open Foundations for Computer-Use Agents, Xinyuan Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- OpenCUAã¯ã€CUAãƒ‡ãƒ¼ã‚¿ã¨åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚¤ãƒ³ãƒ•ãƒ©ã€AgentNetãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€åå°„çš„ãªChain-of-Thoughtæ¨è«–ã‚’æŒã¤ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã€‚OpenCUA-32Bã¯ã€CUAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§34.8%ã®æˆåŠŸç‡ã‚’é”æˆã—ã€æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ç¤ºã™ã€‚ç ”ç©¶ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãŸã‚ã«ã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1956157162830418062?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xywang626/status/1956400403911962757?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>CUAã«ãŠã„ã¦Proprietaryãƒ¢ãƒ‡ãƒ«ã«è¿‘ã„æ€§èƒ½ã‚’é”æˆã—ãŸåˆã‚ã¦ã®ç ”ç©¶ãªæ¨¡æ§˜ã€‚é‡è¦</p>
<p>ç¶šå ±:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xywang626/status/1973426575837438389?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>OSWorld Verifiedã§UI-TARS-250705,claude-4-sonnet-20250514è¶…ãˆã§top1ã«å›è‡¨ã¨ã®ã“ã¨ã€‚</span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<a class="button" href="articles/CompoundAISystemsOptimization.html" target="_blank" rel="noopener noreferrer">#CompoundAISystemsOptimization</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2434" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Optimas: Optimizing Compound AI Systems with Globally Aligned Local  Rewards, Shirley Wu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è¤‡åˆAIã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–ã®ãŸã‚ã«ã€çµ±ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯Optimasã‚’ææ¡ˆã€‚å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ãƒ­ãƒ¼ã‚«ãƒ«å ±é…¬é–¢æ•°ã‚’ç¶­æŒã—ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨æ•´åˆæ€§ã‚’ä¿ã¡ãªãŒã‚‰åŒæ™‚ã«æœ€å¤§åŒ–ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç•°ç¨®æ§‹æˆã®ç‹¬ç«‹ã—ãŸæ›´æ–°ãŒå¯èƒ½ã¨ãªã‚Šã€å¹³å‡11.92%ã®æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shirleyyxwu/status/1956072970373538271?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>framework: 


<a href="https://github.com/snap-stanford/optimas" target="_blank" rel="noopener noreferrer">https://github.com/snap-stanford/optimas</a>


</p>
<p>è¤‡æ•°ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ã‚ˆã£ã¦æ§‹æˆã•ã‚Œã‚‹ã‚·ã‚¹ãƒ†ãƒ ãŒã‚ã£ãŸã¨ãã«ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ”¹å–„ã—ãŸã„ã€‚ã“ã®ã¨ãã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ãƒ¦ãƒ¼ã‚¶ãŒå®šç¾©ã—ãŸGlobal Reward Functionã‚’æœ€å¤§åŒ–ã™ã‚‹ã‚ˆã†ã«æœ€é©åŒ–ã—ãŸã„ã€‚ã—ã‹ã—ã€å¤šãã®å ´åˆã“ã®ã‚ˆã†ãªç•°ç¨®ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒè¤‡é›‘ã«é€£æºã—ãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã¯ã€global rewardsã¯å¾®åˆ†ä¸å¯èƒ½ãªã®ã§ã€end-to-endã§æœ€é©åŒ–ã™ã‚‹ã“ã¨ãŒé›£ã—ã„ã€‚ã¾ãŸã€å€‹ã€…ã®ç•°ç¨®ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚³ãƒ³ãƒ•ã‚£ã‚°ï¼ˆe.g., textual, numerical, continuous vs. discreteï¼‰ã‚’åŒæ™‚ã«æœ€é©åŒ–ã™ã‚‹ã“ã¨ãŒãã‚‚ãã‚‚é›£ã—ã„ã€‚å…¨ä½“ã®AIã‚·ã‚¹ãƒ†ãƒ ã‚’å‹•ä½œã•ã›ã¦ã€global rewardã‚’æœ€é©åŒ–ã™ã‚‹ã®ã¯éå¸¸ã«ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã€‚å…ˆè¡Œç ”ç©¶ã§ã¯ã€ç‰¹å®šã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆ¥ã€…ã«æœ€é©åŒ–ã—ã¦ããŸï¼ˆãŸã¨ãˆã°ã€promptã‚’ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŸºã¥ã„ã¦æ”¹å–„ã™ã‚‹ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1037" target="_blank" rel="noopener noreferrer">Large Language Models as Optimizers, Chengrun Yang+, N/A, ICLR'24</a>
, ãƒ¢ãƒ‡ãƒ«é¸æŠã‚’iterative searchã§æ”¹å–„ã™ã‚‹ãªã©ï¼‰ã€‚ãŒã€å€‹åˆ¥ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’æœ€é©åŒ–ã—ã¦ã‚‚åˆ¥ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®æœ€é©åŒ–ãŒä¸ååˆ†ã§ã‚ã‚Œã°å…¨ä½“ã®æ€§èƒ½ã¯å‘ä¸Šã›ãšã€å…¨ã¦ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å€‹åˆ¥ã«æœ€é©åŒ–ã—ã¦ã‚‚ã€ç›¸äº’ä½œç”¨ãŒæœ€é©ã§ã¯ãªã„å ´åˆã¯global rewardãŒæœ€å¤§åŒ–ã•ã‚Œãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚<br><br>ã“ã®ãŸã‚ã€å€‹ã€…ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«local reward function (LRFs)ã‚’å®šç¾©ã™ã‚‹ã€‚local reward functionã¯ã€ã“ã‚Œã‚‰ãŒæ”¹å–„ã™ã‚‹ã“ã¨ã§global reward functionã‚‚æ”¹å–„ã™ã‚‹ã“ã¨ã‚’ä¿è¨¼ã™ã‚‹ã‚ˆã†ãªå½¢ï¼ˆlocal-global alignment properfyï¼‰ã§å®šç¾©ã•ã‚Œã€ã“ã‚Œã‚‰ã®local reward functionã‚’ç•°ãªã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã”ã¨ã«ç•°ãªã‚‹å½¢ã§æœ€é©åŒ–ã—ã¦ã‚‚ã€global reward functionãŒæ”¹å–„ã•ã‚Œã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ã€‚å€‹ã€…ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã”ã¨ã«LRFsã‚’æœ€é©åŒ–ã™ã‚‹ã“ã¨ã¯ã€å…¨ä½“ã®ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè¡Œå›æ•°ã‚’å‰Šæ¸›ã—ãªãŒã‚‰é«˜ã„global rewardã‚’å®Ÿç¾å¯èƒ½ã¨ãªã‚‹ã€‚åŠ ãˆã¦ã€ä»–ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚³ãƒ³ãƒ•ã‚£ã‚°ãŒæ”¹å–„ã•ã‚ŒãŸã‚‰ã€ãã‚Œã‚‰ã«é©å¿œã—ã¦LRFsã‚‚æ”¹å–„ã•ã‚Œã¦ã„ãå¿…è¦ãŒã‚ã‚‹ã®ã§ lightweight adaptationã¨å‘¼ã°ã‚Œã‚‹ã€ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸæœ€å°ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰LRFsã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚‹æ‰‹æ³•ã‚‚ææ¡ˆã™ã‚‹ã€ã¿ãŸã„ãªè©±ãªæ¨¡æ§˜ã€‚<br><br>&lt;img width="868" height="501" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/2d6a1422-c087-455a-813c-97d47da5976d"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/2d6a1422-c087-455a-813c-97d47da5976d"&lt;/a&gt;


/&gt;<br><br>LRFsã‚’å®šç¾©ã™ã‚‹ã¨ãã¯ã€å…±é€šã®LLMã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã¨ã—ã€å€‹ã€…ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«å¯¾ã—ã¦åˆ¥ã€…ã®ãƒ˜ãƒƒãƒ‰ã‚’ç”¨æ„ã—ã¦rewardã‚’å‡ºåŠ›ã™ã‚‹ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©ã™ã‚‹ã€‚ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆkã®input x, output y ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ãã‚Œã‚‰ã‚’concatã—ã¦LLMã«å…¥åŠ›ã—[x_k, y_k]æœ€çµ‚çš„ã«ãƒ˜ãƒƒãƒ‰ã§ã‚¹ã‚«ãƒ©ãƒ¼å€¤ã«å†™åƒã™ã‚‹ã€‚ã¾ãŸã€LRF r_kãŒ *aligned* ã®å®šç¾©ã¨ã—ã¦ã€LRF r_kãŒã‚ã‚‹å…±é€šã®inputã«å¯¾ã—ã¦r_kãŒé«˜ããªã‚‹ã‚ˆã†ãªoutputã‚’ã—ãŸã¨ãã«ã€downstreamã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå…¨ä½“ã®global reward RãŒåŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’é”æˆã™ã‚‹å ´åˆã€alignedã§ã‚ã‚‹ã¨å®šç¾©ã™ã‚‹ã€‚ã“ã®ã‚ˆã†ãªç‰¹æ€§ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ç¾è¡Œã®ã‚·ã‚¹ãƒ†ãƒ ã®ã‚³ãƒ³ãƒ•ã‚£ã‚°ã«åŸºã¥ã„ã¦ãã‚Œãã‚Œã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å®Ÿè¡Œã—ã€trajectoryã‚’å–å¾—ã€‚ç‰¹å®šã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆC_kã«å¯¾ã™ã‚‹äºŒã¤ã®outputã‚’ï¼ˆç•°ãªã‚‹ã‚³ãƒ³ãƒ•ã‚£ã‚°ã«åŸºã¥ã„ã¦ï¼‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã®metricã‚’äºˆæ¸¬ã—ã€metricãŒé«˜ã„/ä½ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’chosen/rejectedã¨ã— preference dataã‚’ç”¨æ„ã™ã‚‹ã€‚ã“ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€å€‹ã€…ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®LRFsã‚’ã€chosenãªã‚µãƒ³ãƒ—ãƒ«ã®å ´åˆã¯rejectedã‚ˆã‚Šã‚‚rewardãŒé«˜ããªã‚‹ã‚ˆã†ã«ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã®ranking lossã‚’ç”¨ã„ã¦å­¦ç¿’ã™ã‚‹ã€‚<br><br>(ã“ã“ã¾ã§ãŒ4.1ç¯€ã®æ¦‚è¦ã€‚4.2, 4.3ç¯€ä»¥å¾Œã¯å¿…è¦ã«å¿œã˜ã¦å‚ç…§ã™ã‚‹ã€‚4.2ã§ã¯ã©ã®ã‚ˆã†ã«ä»–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒæ›´æ–°ã•ã‚ŒãŸéš›ã«LRFsã‚’æ›´æ–°ã™ã‚‹ã‹ã€ã¨ã„ã†è©±ã¨ã€4.3ç¯€ã§ã¯å€‹ã€…ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒtext, trainable models, continuous configurationãªã©ã®ç•°ãªã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å ´åˆã«ã©ã®ã‚ˆã†ãªæœ€é©åŒ–æ‰‹æ³•ã‚’é©ç”¨ã™ã‚‹ã‹ã€ã¨ã„ã£ãŸè©±ãŒæ›¸ã‹ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚)<br><br>è©•ä¾¡ã§ã¯5ã¤ã®å®Ÿä¸–ç•Œã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®è¤‡æ•°ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§æ§‹æˆã•ã‚Œã‚‹ã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–ã‚’è©¦ã¿ã¦ã„ã‚‹ã‚ˆã†ã§ã‚ã‚Šã€<br>&lt;img width="1119" height="634" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/be6fcb09-a68c-4b4c-998e-9f940cad677f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/be6fcb09-a68c-4b4c-998e-9f940cad677f"&lt;/a&gt;


/&gt;<br><br>ææ¡ˆæ‰‹æ³•ã«ã‚ˆã£ã¦ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã®æ€§èƒ½ãŒãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨æ¯”ã¹ã¦æ”¹å–„ã—ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®å®Ÿè¡Œå›æ•°ã‚‚ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨æ¯”è¼ƒã—ã¦å°‘ãªã„è©¦è¡Œå›æ•°ã§æ¸ˆã‚€ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br>&lt;img width="1112" height="582" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/a4f4c274-920f-4f60-9594-6b19b84f6b34"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a4f4c274-920f-4f60-9594-6b19b84f6b34"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2432" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond  Competitive Programming, Gal Beniamini+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢AIãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€å®Ÿéš›ã®ç ”ç©¶å•é¡Œã«åŸºã¥ããƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒFormulaOneã€ã‚’æ§‹ç¯‰ã€‚ã“ã‚Œã¯ã€ã‚°ãƒ©ãƒ•ç†è«–ã‚„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«é–¢é€£ã™ã‚‹é›£æ˜“åº¦ã®é«˜ã„å•é¡Œã§ã€å•†æ¥­çš„é–¢å¿ƒã‚„ç†è«–è¨ˆç®—æ©Ÿç§‘å­¦ã«é–¢é€£ã€‚æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã¯FormulaOneã§ã»ã¨ã‚“ã©è§£æ±ºã§ããšã€å°‚é–€å®¶ãƒ¬ãƒ™ãƒ«ã®ç†è§£ã‹ã‚‰é ã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ç ”ç©¶æ”¯æ´ã®ãŸã‚ã«ã€ç°¡å˜ãªã‚¿ã‚¹ã‚¯ã‚»ãƒƒãƒˆã€ŒFormulaOne-Warmupã€ã‚’æä¾›ã—ã€è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚‚å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shai_s_shwartz/status/1955968602978320727?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ZeroshotHyperparameterTransfer.html" target="_blank" rel="noopener noreferrer">#ZeroshotHyperparameterTransfer</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2430" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] $Î¼$-Parametrization for Mixture of Experts, Jan MaÅ‚aÅ›nicki+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Mixture-of-Expertsï¼ˆMoEï¼‰ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹$\mu$-Parameterizationï¼ˆ$\mu$Pï¼‰ã‚’ææ¡ˆã—ã€ãƒ«ãƒ¼ã‚¿ãƒ¼ã¨ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ç‰¹å¾´å­¦ç¿’ã«é–¢ã™ã‚‹ç†è«–çš„ä¿è¨¼ã‚’æä¾›ã—ã¾ã™ã€‚ã¾ãŸã€ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®æ•°ã¨ç²’åº¦ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒæœ€é©ãªå­¦ç¿’ç‡ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’å®Ÿè¨¼çš„ã«æ¤œè¨¼ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1956103561126789339?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£: mu transfer, muP<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2582" target="_blank" rel="noopener noreferrer">[Paper Note] Tensor Programs V: Tuning Large Neural Networks via Zero-Shot  Hyperparameter Transfer, Greg Yang+, NeurIPS'21</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2583" target="_blank" rel="noopener noreferrer">[Paper Note] Feature Learning in Infinite-Width Neural Networks, Greg Yang+, PMLR'21</a>
</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2428" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Less Is More: Training-Free Sparse Attention with Global Locality for  Efficient Reasoning, Lijie Yang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã€ŒLessIsMoreã€ã¨ã„ã†æ–°ã—ã„ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸è¦ã§ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ´»ç”¨ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³é¸æŠã‚’åŠ¹ç‡åŒ–ã€‚ç²¾åº¦ã‚’ç¶­æŒã—ã¤ã¤ã€ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é€Ÿåº¦ã‚’1.1å€å‘ä¸Šã•ã›ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’2å€å‰Šæ¸›ã€‚æ—¢å­˜æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦1.13å€ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lijieyyang/status/1955139186530328633?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒªãƒ¼ã§1.1å€ã®ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é€Ÿåº¦ã§æ€§èƒ½ã‚‚Full Attentionã¨åŒç­‰ä»¥ä¸Šã®Sparse Attentionã‚‰ã—ã„</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2427" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Policy Cliff: A Theoretical Analysis of Reward-Policy Maps in Large  Language Models, Xingcheng Xu, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®è¡Œå‹•å½¢æˆã«é‡è¦ã ãŒã€è„†å¼±ãªãƒãƒªã‚·ãƒ¼ã‚’ç”Ÿæˆã—ã€ä¿¡é ¼æ€§ã‚’æãªã†å•é¡ŒãŒã‚ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€å ±é…¬é–¢æ•°ã‹ã‚‰æœ€é©ãƒãƒªã‚·ãƒ¼ã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã®å®‰å®šæ€§ã‚’åˆ†æã™ã‚‹æ•°å­¦çš„æ çµ„ã¿ã‚’ææ¡ˆã—ã€ãƒãƒªã‚·ãƒ¼ã®è„†å¼±æ€§ãŒéä¸€æ„çš„ãªæœ€é©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«èµ·å› ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã•ã‚‰ã«ã€å¤šå ±é…¬RLã«ãŠã‘ã‚‹å®‰å®šæ€§ãŒã€ŒåŠ¹æœçš„å ±é…¬ã€ã«ã‚ˆã£ã¦æ”¯é…ã•ã‚Œã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ­£å‰‡åŒ–ãŒå®‰å®šæ€§ã‚’å›å¾©ã™ã‚‹ã“ã¨ã‚’è¨¼æ˜ã™ã‚‹ã€‚ã“ã®ç ”ç©¶ã¯ã€ãƒãƒªã‚·ãƒ¼å®‰å®šæ€§åˆ†æã‚’é€²å±•ã•ã›ã€å®‰å…¨ã§ä¿¡é ¼æ€§ã®é«˜ã„AIã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã«å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1955909877404197072?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã¨ã¦ã‚‚é¢ç™½ãã†</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2426" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale  Asynchronous RL, Jiaxuan Gao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ASearcherã¯ã€LLMãƒ™ãƒ¼ã‚¹ã®æ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¤§è¦æ¨¡ãªRLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿç¾ã™ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã‚ã‚Šã€é«˜åŠ¹ç‡ãªéåŒæœŸRLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨è‡ªå¾‹çš„ã«åˆæˆã•ã‚ŒãŸé«˜å“è³ªãªQ&amp;Aãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€æ¤œç´¢èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ææ¡ˆã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€xBenchã§46.7%ã€GAIAã§20.8%ã®æ”¹å–„ã‚’é”æˆã—ã€é•·æœŸçš„ãªæ¤œç´¢èƒ½åŠ›ã‚’ç¤ºã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§æä¾›ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1955603041518035358?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jxwuyi/status/1955487396344238486?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1955266026498855354?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2466" target="_blank" rel="noopener noreferrer">[Paper Note] xbench: Tracking Agents Productivity Scaling with Profession-Aligned
  Real-World Evaluations, Kaiyuan Chen+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1158" target="_blank" rel="noopener noreferrer">GAIA: a benchmark for General AI Assistants, GrÃ©goire Mialon+, N/A, arXiv'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1461" target="_blank" rel="noopener noreferrer">[Paper Note] Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented  Generation, Satyapriya Krishna+, N/A, NAACL'25</a>
</p>
<p>æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã¯ &lt;= 10 turnsã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã•ã‚Œã¦ãŠã‚Šã€å¤§è¦æ¨¡ã§é«˜å“è³ªãªQAãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹å•é¡ŒãŒã‚ã£ãŸãŒã€ã‚·ãƒ¼ãƒ‰QAã«åŸºã¥ã„ã¦QAã‚’åˆæˆã™ã‚‹æ‰‹æ³•ã«ã‚ˆã£ã¦1.4ä¸‡ã‚·ãƒ¼ãƒ‰QAã‹ã‚‰134kã®é«˜å“è³ªãªQAã‚’åˆæˆã—ãŸï¼ˆã†ã¡25.6kã¯ãƒ„ãƒ¼ãƒ«åˆ©ç”¨ãŒå¿…è¦ï¼‰ã€‚å…·ä½“çš„ã«ã¯ã€ã‚·ãƒ¼ãƒ‰ã®QAã‚’åˆæˆã—ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒQAã®è¤‡é›‘åº¦ã‚’iterationã‚’ã—ãªãŒã‚‰å‘ä¸Šã•ã›ã¦ã„ãæ‰‹æ³•ã‚’ææ¡ˆã€‚äº‹å®Ÿæƒ…å ±ã¯å¸¸ã«verificationã‚’ã•ã‚Œã€åˆæˆãƒ—ãƒ­ã‚»ã‚¹ã®iterationã®ä¸­ã§ä¿æŒã•ã‚Œç¶šã‘ã‚‹ã€‚å€‹ã€…ã®iterationã«ãŠã„ã¦ã€ç¾åœ¨ã®QAã¨äº‹å®Ÿæƒ…å ±ã«åŸºã¥ã„ã¦ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯<br>- Injection: äº‹å®Ÿæƒ…å ±ã‚’æ–°ãŸã«æ³¨å…¥ã—QAã‚’ã‚ˆã‚Šãƒªãƒƒãƒã«ã™ã‚‹ã“ã¨ã§è¤‡é›‘åº¦ã‚’ä¸Šã’ã‚‹<br>- Fuzz: QAä¸­ã®ä¸€éƒ¨ã®è©³ç´°ãªæƒ…å ±ã‚’ã¼ã‹ã™ã“ã¨ã§ã€ä¸ç¢ºå®Ÿæ€§ã®ãƒ¬ãƒ™ãƒ«ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚<br>ã®2ç¨®é¡ã®æ“ä½œã‚’å®Ÿæ–½ã™ã‚‹ã€‚ãã®ä¸Šã§ã€QAã«å¯¾ã—ã¦Quality verificationã‚’å®Ÿæ–½ã™ã‚‹:<br>- Basic Quality: LLMã§qualityã‚’è©•ä¾¡ã™ã‚‹<br>- Difficulty Measurement: LRMã«ã‚ˆã£ã¦ã€è¤‡æ•°ã®å›ç­”å€™è£œã‚’ç”Ÿæˆã™ã‚‹<br>- Answer Uniqueness: Difficulty Measurementã§ç”Ÿæˆã•ã‚ŒãŸè¤‡æ•°ã®è§£ç­”æƒ…å ±ã«åŸºã¥ã„ã¦ã€mismatched answersãŒvalid answerã¨ãªã‚‹ã‹å¦ã‹ã‚’æ¤œè¨¼ã—ã€æ­£è§£ãŒå˜ä¸€ã§ã‚ã‚‹ã“ã¨ã‚’æ‹…ä¿ã™ã‚‹<br><br>&lt;img width="907" height="561" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/d020fc8f-b1da-4425-981a-6759cba5824b"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/d020fc8f-b1da-4425-981a-6759cba5824b"&lt;/a&gt;


/&gt;<br><br>ã¾ãŸã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã€ç‰¹ã«tool callsãŒéå¸¸ã«å¤šã„ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦ã¯ã€å¤šãã®ã‚¿ãƒ¼ãƒ³æ•°ï¼ˆlong trajectoriesï¼‰ãŒå¿…è¦ã¨ãªã‚‹ãŒã€æ—¢å­˜ã®ãƒãƒƒãƒã«åŸºã¥ã„ãŸå­¦ç¿’æ‰‹æ³•ã§ã¯long trajectoriesã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’ã—ã¦ã„ã‚‹é–“ã€ä»–ã®ã‚µãƒ³ãƒ—ãƒ«ã®å­¦ç¿’ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã—ã¾ã„å­¦ç¿’åŠ¹ç‡ãŒéå¸¸ã«æ‚ªã„ã®ã§ã€ãƒãƒƒãƒå†…ã®trajectoryã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã®æ›´æ–°ã‚’åˆ†é›¢ï¼ˆãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ¥ã‚µãƒ¼ãƒã«é€ä¿¡ã•ã‚Œã‚µãƒ¼ãƒä¸Šã®Inference Engineã§éåŒæœŸã«å®Ÿè¡Œã•ã‚Œã€ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚‹å´ã¯ååˆ†ãªtrajectoryãŒãƒãƒƒãƒå†…ã§æƒã£ãŸã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã€ã¿ãŸã„ãªæŒ™å‹•ï¼Ÿï¼‰ã™ã‚‹ã“ã¨ã§Idleã‚¿ã‚¤ãƒ ã‚’ç„¡ãã™ã‚ˆã†ãªæ‰‹æ³•ã‚’ææ¡ˆã—ãŸæ¨¡æ§˜ã€‚<br><br>&lt;img width="873" height="466" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/65d7e7b1-25fb-4288-a85e-07ae7a5eea2f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/65d7e7b1-25fb-4288-a85e-07ae7a5eea2f"&lt;/a&gt;


/&gt;</p>
<p>æ—¢å­˜ã®æ‰‹æ³•ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ€§èƒ½ã¯å‘ä¸Šã—ã¦ã„ã‚‹ã€‚å­¦ç¿’ãŒé€²ã‚€ã«ã¤ã‚Œã¦ã€trajectoryä¸­ã®URLå‚ç…§å›æ•°ã‚„search queryæ•°ãªã©ãŒå¢—å¤§ã—ã¦ã„ãæ›²ç·šã¯è€ƒå¯Ÿã•ã‚Œã¦ã„ã‚‹ã€‚ä»–ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦ã€ã‚ˆã‚Šå¤šã„ã‚¿ãƒ¼ãƒ³æ•°ã‚’ã‚ˆã‚Šé«˜ã„æ­£ç¢ºæ€§ã‚’ä»¥ã£ã¦å®Ÿè¡Œã§ãã‚‹ã¨ã„ã£ãŸå®šé‡çš„ãªãƒ‡ãƒ¼ã‚¿ã¯ã¾ã å­˜åœ¨ã—ãªã„ã‚ˆã†ã«è¦‹ãˆãŸã€‚<br><br>&lt;img width="891" height="778" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/70644da8-b862-4bcb-bb05-d915c815b885"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/70644da8-b862-4bcb-bb05-d915c815b885"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2424" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebWatcher: Breaking New Frontier of Vision-Language Deep Research Agent, Xinyu Geng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- WebWatcherã¯ã€è¦–è¦šã¨è¨€èªã®æ¨è«–èƒ½åŠ›ã‚’å¼·åŒ–ã—ãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã‚ã‚Šã€æƒ…å ±æ¢ç´¢ã®å›°é›£ã•ã«å¯¾å‡¦ã™ã‚‹ã€‚åˆæˆãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è»Œè·¡ã‚’ç”¨ã„ãŸåŠ¹ç‡çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚Šã€æ·±ã„æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚æ–°ãŸã«ææ¡ˆã•ã‚ŒãŸBrowseComp-VLãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®å®Ÿé¨“ã«ã‚ˆã‚Šã€WebWatcherã¯è¤‡é›‘ãªVQAã‚¿ã‚¹ã‚¯ã§ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/richardxp888/status/1955645614685077796?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…¬å¼:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ali_tongyilab/status/1961348492506665289?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2423" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Geometric-Mean Policy Optimization, Yuzhong Zhao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- GRPOã®ä¸å®‰å®šæ€§ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€å¹¾ä½•å¹³å‡ã‚’æœ€é©åŒ–ã™ã‚‹GMPOã‚’ææ¡ˆã€‚GMPOã¯å¤–ã‚Œå€¤ã«æ•æ„Ÿã§ãªãã€å®‰å®šã—ãŸé‡è¦åº¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¯”ç‡ã‚’ç¶­æŒã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€GMPO-7Bã¯è¤‡æ•°ã®æ•°å­¦çš„ãŠã‚ˆã³ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§GRPOã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zzlccc/status/1955823092904943816?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1955879567354388926?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/Overthinking.html" target="_blank" rel="noopener noreferrer">#Overthinking</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2422" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Sample More to Think Less: Group Filtered Policy Optimization for  Concise Reasoning, Vaishnavi Shrivastava+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- GFPOï¼ˆGroup Filtered Policy Optimizationï¼‰ã‚’ææ¡ˆã—ã€å¿œç­”ã®é•·ã•ã®è†¨å¼µã‚’æŠ‘åˆ¶ã€‚å¿œç­”ã‚’é•·ã•ã¨ãƒˆãƒ¼ã‚¯ãƒ³åŠ¹ç‡ã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã€æ¨è«–æ™‚ã®è¨ˆç®—é‡ã‚’å‰Šæ¸›ã€‚Phi-4ãƒ¢ãƒ‡ãƒ«ã§é•·ã•ã®è†¨å¼µã‚’46-71%å‰Šæ¸›ã—ã€ç²¾åº¦ã‚’ç¶­æŒã€‚Adaptive Difficulty GFPOã«ã‚ˆã‚Šã€é›£æ˜“åº¦ã«å¿œã˜ãŸè¨“ç·´ãƒªã‚½ãƒ¼ã‚¹ã®å‹•çš„å‰²ã‚Šå½“ã¦ã‚’å®Ÿç¾ã€‚åŠ¹ç‡çš„ãªæ¨è«–ã®ãŸã‚ã®åŠ¹æœçš„ãªãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zzlccc/status/1955823092904943816?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1955884039149380067?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vaishshrivas/status/1956096081504436620?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2418" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Can Language Models Falsify? Evaluating Algorithmic Reasoning with  Counterexample Creation, Shiven Sinha+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLMï¼‰ã®ç§‘å­¦çš„ç™ºè¦‹ã‚’åŠ é€Ÿã™ã‚‹ãŸã‚ã«ã€å¾®å¦™ã«èª¤ã£ãŸè§£æ±ºç­–ã«å¯¾ã™ã‚‹åä¾‹ã‚’ä½œæˆã™ã‚‹èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒREFUTEã€ã‚’ææ¡ˆã€‚ã“ã‚Œã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å•é¡Œã‹ã‚‰ã®èª¤ã£ãŸæå‡ºç‰©ã‚’ç”¨ã„ã¦ãŠã‚Šã€æœ€ã‚‚å„ªã‚ŒãŸæ¨è«–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã‚‚9%æœªæº€ã®åä¾‹ã—ã‹ç”Ÿæˆã§ããªã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã®ç ”ç©¶ã¯ã€LMã®èª¤ã£ãŸè§£æ±ºç­–ã‚’å¦å®šã™ã‚‹èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã€ä¿¡é ¼ã§ãã‚‹æ¨è«–ã‚’é€šã˜ã¦è‡ªå·±æ”¹å–„ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://falsifiers.github.io" target="_blank" rel="noopener noreferrer">https://falsifiers.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shashwatgoel7/status/1955311868915966173?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚°ã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã¨task descriptionãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€inputã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨å…¨ã¦ã®åˆ¶ç´„ã‚’æº€ãŸã™ãŒã€ã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡ŒãŒå¤±æ•—ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ï¼ˆï¼åä¾‹ï¼‰ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®reasoning capabilityã®è©•ä¾¡ã‚’ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚<br><br>gpt-ossã¯ã‚³ãƒ¼ãƒ‰ã«ãƒã‚°ã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã«å¯¾ã—ã¦ä¸Šè¨˜ã®ã‚ˆã†ãªåä¾‹ã‚’ç”Ÿæˆã™ã‚‹èƒ½åŠ›ãŒé«˜ã„ã‚ˆã†ã§ã‚ã‚‹ã€‚ãŸã ã—ã€ãã‚Œã§ã‚‚å…¨ä½“ã®ãƒã‚°ã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã®ã†ã¡åä¾‹ã‚’ç”Ÿæˆã§ããŸã®ã¯é«˜ã€…21.6%ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚ãŸã ã€ã‚‚ã—ã‚³ãƒ¼ãƒ‰ã ã‘ã§ãªãverificationå…¨èˆ¬ã®èƒ½åŠ›ãŒé«˜ã„ã‹ã‚‰ã€ç›¸å½“ä½¿ã„é“ãŒã‚ã‚Šãã†ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2417" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unveiling Super Experts in Mixture-of-Experts Large Language Models, Zunhai Su+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¹ãƒ‘ãƒ¼ã‚¹ã«æ´»æ€§åŒ–ã•ã‚ŒãŸMixture-of-Expertsï¼ˆMoEï¼‰ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€ç‰¹å®šã®å°‚é–€å®¶ã®ã‚µãƒ–ã‚»ãƒƒãƒˆã€Œã‚¹ãƒ¼ãƒ‘å°‚é–€å®¶ï¼ˆSEï¼‰ã€ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«é‡è¦ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚SEã¯ç¨€ãªæ´»æ€§åŒ–ã‚’ç¤ºã—ã€ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã¨ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ãŒåŠ£åŒ–ã™ã‚‹ã€‚åˆ†æã«ã‚ˆã‚Šã€SEã®é‡è¦æ€§ãŒæ•°å­¦çš„æ¨è«–ãªã©ã®ã‚¿ã‚¹ã‚¯ã§æ˜ã‚‰ã‹ã«ãªã‚Šã€MoE LLMãŒSEã«ä¾å­˜ã—ã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1955217132016505239?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MoEã«ãŠã‘ã‚‹ã€ç‰¹ã«é‡è¦ãªå°‚é–€å®¶ã§ã‚ã‚‹Super Expertsã®å­˜åœ¨</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1566" target="_blank" rel="noopener noreferrer">The Super Weight in Large Language Models, Mengxia Yu+, arXiv'24</a>
<br><br>ã‚’æ€ã„å‡ºã™ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MCP.html" target="_blank" rel="noopener noreferrer">#MCP</a>
<span class="issue_date">Issue Date: 2025-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2415" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?, Guozhao Mo+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LiveMCPBenchã¯ã€10,000ã‚’è¶…ãˆã‚‹MCPã‚µãƒ¼ãƒãƒ¼ã«åŸºã¥ã95ã®å®Ÿä¸–ç•Œã‚¿ã‚¹ã‚¯ã‹ã‚‰æˆã‚‹åˆã®åŒ…æ‹¬çš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¤§è¦æ¨¡è©•ä¾¡ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚70ã®MCPã‚µãƒ¼ãƒãƒ¼ã¨527ã®ãƒ„ãƒ¼ãƒ«ã‚’å«ã‚€LiveMCPToolã‚’æ•´å‚™ã—ã€LLM-as-a-Judgeãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹LiveMCPEvalã‚’å°å…¥ã—ã¦è‡ªå‹•åŒ–ã•ã‚ŒãŸé©å¿œè©•ä¾¡ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚MCP Copilot Agentã¯ã€ãƒ„ãƒ¼ãƒ«ã‚’å‹•çš„ã«è¨ˆç”»ã—å®Ÿè¡Œã™ã‚‹ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚è©•ä¾¡ã®çµæœã€æœ€ã‚‚å„ªã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯78.95%ã®æˆåŠŸç‡ã‚’é”æˆã—ã¾ã—ãŸãŒã€ãƒ¢ãƒ‡ãƒ«é–“ã§æ€§èƒ½ã®ã°ã‚‰ã¤ããŒè¦‹ã‚‰ã‚Œã¾ã—ãŸã€‚å…¨ä½“ã¨ã—ã¦ã€LiveMCPBenchã¯LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ãŸãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://icip-cas.github.io/LiveMCPBench/" target="_blank" rel="noopener noreferrer">https://icip-cas.github.io/LiveMCPBench/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1955324566298833127?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MCPç’°å¢ƒã«ãŠã‘ã‚‹LLM Agentã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚è«–æ–‡ä¸­ã®Table1ã«ä»–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å«ã‚ã‚µãƒãƒªãŒæ²è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚MCPã‚’ç”¨ã„ãŸLLMAgentã®ãƒ™ãƒ³ãƒãŒã™ã§ã«ã“ã‚“ãªã«ã‚ã‚‹ã“ã¨ã«é©šã„ãŸâ€¦ã€‚<br><img src="https://github.com/user-attachments/assets/29472068-380b-421c-b82d-fd14831b07ff" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Reproducibility.html" target="_blank" rel="noopener noreferrer">#Reproducibility</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2411" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning, Zihe Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã‚’ç”¨ã„ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®æ¨è«–ã«é–¢ã™ã‚‹ç ”ç©¶ãŒé€²å±•ã™ã‚‹ä¸­ã€æ¨™æº–åŒ–ã•ã‚ŒãŸã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®ç†è§£ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚å®Ÿé¨“è¨­å®šã®ä¸ä¸€è‡´ã‚„ãƒ‡ãƒ¼ã‚¿ã®å¤‰å‹•ãŒæ··ä¹±ã‚’æ‹›ã„ã¦ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€RLæŠ€è¡“ã‚’ä½“ç³»çš„ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å†ç¾å®Ÿé¨“ã‚’é€šã˜ã¦å„æŠ€è¡“ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚„é©ç”¨ã‚·ãƒŠãƒªã‚ªã‚’åˆ†æã€‚æ˜ç¢ºãªã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’æç¤ºã—ã€å®Ÿå‹™è€…ã«ä¿¡é ¼ã§ãã‚‹ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’æä¾›ã™ã‚‹ã€‚ã¾ãŸã€ç‰¹å®šã®æŠ€è¡“ã®çµ„ã¿åˆã‚ã›ãŒæ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1955268799525265801?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>èª­ã‚“ã æ–¹ãŒè‰¯ã„</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1959799274059031039?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2406" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GLM-4.5: Agentic, Reasoning, and Coding ï¼ˆARCï¼‰ Foundation Models, GLM-4. 5 Team+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- 355Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®Mixture-of-Expertsãƒ¢ãƒ‡ãƒ«GLM-4.5ã‚’ç™ºè¡¨ã€‚ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¨è«–æ‰‹æ³•ã‚’æ¡ç”¨ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçš„ã€æ¨è«–ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚ç«¶åˆãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦å°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§ä¸Šä½ã«ãƒ©ãƒ³ã‚¯ã‚¤ãƒ³ã€‚GLM-4.5ã¨ãã®ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆç‰ˆGLM-4.5-Airã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã€è©³ç´°ã¯GitHubã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/grad62304977/status/1954805614011453706?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£<br>  - MoE / sigmoid gates<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1754" target="_blank" rel="noopener noreferrer">Switch Transformers: Scaling to Trillion Parameter Models with Simple  and Efficient Sparsity, William Fedus+, JMLR'22</a>
<br>  - loss free balanced routing<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2442" target="_blank" rel="noopener noreferrer">[Paper Note] Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts, Lean Wang+, arXiv'24</a>
<br>  - widthã‚’å°ã•ãã€depthã‚’å¢—ã‚„ã™ã“ã¨ã§reasoningèƒ½åŠ›æ”¹å–„<br>  - GQA w/ partial RoPE<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1310" target="_blank" rel="noopener noreferrer">RoFormer: Enhanced Transformer with Rotary Position Embedding, Jianlin Su+, N/A, Neurocomputing, 2024</a>
<br>  - Attention Headsã®æ•°ã‚’2.5å€ï¼ˆä½•ã«å¯¾ã—ã¦2.5å€ãªã‚“ã ã€ã€ï¼Ÿï¼‰ï¼ˆ96å€‹, 5120æ¬¡å…ƒï¼‰ã«ã™ã‚‹ã“ã¨ã§ï¼ˆãŠãã‚‰ãï¼‰äº‹å‰å­¦ç¿’ã®lossã¯æ”¹å–„ã—ãªã‹ã£ãŸãŒReasoning benchmarkã®æ€§èƒ½æ”¹å–„<br>  - QK Normã‚’å°å…¥ã—attentionã®logitsã®å€¤åŸŸã‚’æ”¹å–„<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2443" target="_blank" rel="noopener noreferrer">[Paper Note] Query-Key Normalization for Transformers, Alex Henry+, EMNLP'20 Findings</a>
<br>  - Multi Token Prediction<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2444" target="_blank" rel="noopener noreferrer">[Paper Note] Better &amp; Faster Large Language Models via Multi-token Prediction, Fabian Gloeckle+, ICML'24</a>
<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1620" target="_blank" rel="noopener noreferrer">Deep-seek-v3, deepseek-ai, 2024.12</a>
<br><br>ä»–ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒ<br><img src="https://github.com/user-attachments/assets/6085b99e-3a76-432c-a759-91dd4feeb219" alt="image" loading="lazy"><br><br>å­¦ç¿’éƒ¨åˆ†ã¯å¾Œã§è¿½è¨˜ã™ã‚‹</p>
<p>- äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿<br>  - web<br>    - è‹±èªã¨ä¸­å›½èªã®webãƒšãƒ¼ã‚¸ã‚’åˆ©ç”¨<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1944" target="_blank" rel="noopener noreferrer">Nemotron-CC: Transforming Common Crawl into a Refined Long-Horizon   Pretraining Dataset, Dan Su+, ACL'25</a>
 ã¨åŒæ§˜ã«quality scoreyã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ä»˜ä¸<br>    - æœ€ã‚‚ä½ã„quality scoreã®æ–‡æ›¸ç¾¤ã‚’æ’é™¤ã—ã€quality scoreã®é«˜ã„æ–‡æ›¸ç¾¤ã‚’up sampling<br>    - æœ€ã‚‚quality scoreyãŒå¤§ãã„æ–‡æ›¸ç¾¤ã¯3.2 epochåˆ†åˆ©ç”¨<br>    - å¤šãã®web pageãŒãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚Œã¦ãŠã‚Šé«˜ã„quality scoreãŒä»˜ä¸ã•ã‚Œã¦ã„ãŸãŒã€MinHashã«ã‚ˆã£ã¦deduplicationã§ããªã‹ã£ãŸãŸã‚ã€ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2445" target="_blank" rel="noopener noreferrer">[Paper Note] SemDeDup: Data-efficient learning at web-scale through semantic
  deduplication, Amro Abbas+, arXiv'23</a>
 ã‚’ç”¨ã„ã¦document embeddingã«åŸºã¥ã„ã¦é¡ä¼¼ã—ãŸæ–‡æ›¸ç¾¤ã‚’æ’é™¤<br>  - Multilingual<br>    - ç‹¬è‡ªã«ã‚¯ãƒ­ãƒ¼ãƒ«ã—ãŸãƒ‡ãƒ¼ã‚¿ã¨FineWeb-2 <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2109" target="_blank" rel="noopener noreferrer">[Paper Note] FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data  Processing to Every Language, Guilherme Penedo+, COLM'25</a>
 ã‹ã‚‰å¤šè¨€èªã®æ–‡æ›¸ç¾¤ã‚’æŠ½å‡ºã—ã€quality classifierã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§educational utilityã‚’å®šé‡åŒ–ã—ã€é«˜ã„ã‚¹ã‚³ã‚¢ã®æ–‡æ›¸ç¾¤ã‚’upsamplingã—ã¦åˆ©ç”¨<br>  - code<br>    - githubãªã©ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰hosting platformã‹ã‚‰åé›†<br>    - ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ã‹ã‘ã€ãã®å¾Œè¨€èªã”ã¨ã®quality modelsã«ã‚ˆã£ã¦ã€high,middle, lowã®3ã¤ã«å“è³ªã‚’åˆ†é¡<br>    - high qualityãªã‚‚ã®ã¯upsamplingã—ã€low qualityãªã‚‚ã®ã¯é™¤å¤–<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2446" target="_blank" rel="noopener noreferrer">[Paper Note] Efficient Training of Language Models to Fill in the Middle, Mohammad Bavarian+, arXiv'22</a>
 ã§ææ¡ˆã•ã‚Œã¦ã„ã‚‹Fill in the Middle objectiveã‚’ã‚³ãƒ¼ãƒ‰ã®äº‹å‰å­¦ç¿’ã§ã¯é©ç”¨<br>    - ã‚³ãƒ¼ãƒ‰ã«é–¢é€£ã™ã‚‹webæ–‡æ›¸ã‚‚äº‹å‰å­¦ç¿’ã§åé›†ã—ãŸãƒ†ã‚­ã‚¹ãƒˆç¾¤ã‹ã‚‰ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã¨fasttextã«ã‚ˆã‚‹åˆ†é¡å™¨ã§æŠ½å‡ºã—ã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¨åŒæ§˜ã®qualityã®åˆ†é¡ã¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•ã‚’é©ç”¨ã€‚æœ€çµ‚çš„ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸæ–‡æ›¸ç¾¤ã¯re-parseã—ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨å†…å®¹ã®å“è³ªã‚’å‘ä¸Šã•ã›ãŸ<br>  - math &amp; science<br>    - web page, æœ¬, è«–æ–‡ã‹ã‚‰ã€reasoningèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€æ•°å­¦ã¨ç§‘å­¦ã«é–¢ã™ã‚‹æ–‡æ›¸ã‚’åé›†<br>  - LLMã‚’ç”¨ã„ã¦æ–‡æ›¸ä¸­ã®educational contentã®æ¯”ç‡ã«åŸºã¥ã„ã¦æ–‡æ›¸ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ã‚¹ã‚³ã‚¢ã‚’äºˆæ¸¬ã™ã‚‹small-scaleãªåˆ†é¡å™¨ã‚’å­¦ç¿’<br>  - æœ€çµ‚çš„ã«äº‹å‰å­¦ç¿’ã‚³ãƒ¼ãƒ‘ã‚¹ã®ä¸­ã®é–¾å€¤ä»¥ä¸Šã®ã‚¹ã‚³ã‚¢ã‚’æŒã¤æ–‡æ›¸ã‚’upsampling<br>- äº‹å‰å­¦ç¿’ã¯2 stageã«åˆ†ã‹ã‚Œã¦ãŠã‚Šã€æœ€åˆã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§ã¯ã€"å¤§éƒ¨åˆ†ã¯"generalãªæ–‡æ›¸ã§å­¦ç¿’ã™ã‚‹ã€‚æ¬¡ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§ã¯ã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã€æ•°å­¦ã€ç§‘å­¦ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é–¢é€£ã®æ–‡æ›¸ã‚’upsamplingã—ã¦å­¦ç¿’ã™ã‚‹ã€‚<br><br>ä¸Šè¨˜ä»¥ä¸Šã®ç´°ã‹ã„å®Ÿè£…ä¸Šã®æƒ…å ±ã¯è¨˜è¼‰ã•ã‚Œã¦ã„ãªã„ã€‚<br><br>mid-training / post trainingã«ã¤ã„ã¦ã‚‚å¾Œã»ã©è¿½è¨˜ã™ã‚‹</p>
<p>ä»¥ä¸‹ã‚‚å‚ç…§ã®ã“ã¨<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2318" target="_blank" rel="noopener noreferrer">GLM-4.5: Reasoning, Coding, and Agentic Abililties, Zhipu AI Inc., 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2405" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Difficulty-Based Preference Data Selection by DPO Implicit Reward Gap, Xuan Qi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®å¥½ã¿ã‚’äººé–“ã«åˆã‚ã›ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿é¸æŠæˆ¦ç•¥ã‚’ææ¡ˆã€‚DPOã®æš—é»™çš„å ±é…¬ã‚®ãƒ£ãƒƒãƒ—ãŒå°ã•ã„ãƒ‡ãƒ¼ã‚¿ã‚’é¸ã¶ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã¨ãƒ¢ãƒ‡ãƒ«ã®æ•´åˆæ€§ã‚’å‘ä¸Šã€‚å…ƒã®ãƒ‡ãƒ¼ã‚¿ã®10ï¼…ã§5ã¤ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚é™ã‚‰ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã§ã®LLMæ•´åˆæ€§å‘ä¸Šã«å¯„ä¸ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhijingjin/status/1954535751489667173?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>preference pair dataã‚’å­¦ç¿’åŠ¹ç‡ã®è‰¯ã„ã‚µãƒ³ãƒ—ãƒ«ã®ã¿ã«åœ§ç¸®ã™ã‚‹ã“ã¨ã§å­¦ç¿’åŠ¹ç‡ã‚’ä¸Šã’ãŸã„ç³»ã®è©±ã§ã€chosen, rejectedãªã‚µãƒ³ãƒ—ãƒ«ã®ãã‚Œãã‚Œã«ã¤ã„ã¦ã€Â¥frac{ç¾åœ¨ã®ãƒãƒªã‚·ãƒ¼ã®å°¤åº¦}{å‚ç…§ãƒãƒªã‚·ãƒ¼ã®å°¤åº¦}ã«ã‚ˆã£ã¦reward rã‚’å®šç¾©ã—ï¼ˆãŠãã‚‰ãå‚ç…§ãƒãƒªã‚·ãƒ¼ã®å°¤åº¦ã«ã‚ˆã£ã¦ã‚µãƒ³ãƒ—ãƒ«ã®é‡è¦åº¦ã‚’é‡ã¿ã¥ã‘ã—ã¦ã„ã‚‹ï¼‰ã€r_chosenã¨r_rejectedã®å·®ã‚’reward gapã¨å®šç¾©ã—ã€gapãŒå¤§ãã„ã‚‚ã®ã¯é›£æ˜“åº¦ãŒä½ã„ã¨åˆ¤æ–­ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã€ã¨ã„ã£ãŸè©±ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/1b930f5e-8db4-4c20-b7ca-59fb452f9056" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2403" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Memp: Exploring Agent Procedural Memory, Runnan Fang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMã«åŸºã¥ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å­¦ç¿’å¯èƒ½ã§æ›´æ–°å¯èƒ½ãªæ‰‹ç¶šãçš„è¨˜æ†¶ã‚’æŒãŸã›ã‚‹ãŸã‚ã®æˆ¦ç•¥ã‚’ææ¡ˆã€‚Mempã‚’ç”¨ã„ã¦éå»ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è»Œè·¡ã‚’æŒ‡ç¤ºã‚„æŠ½è±¡ã«è’¸ç•™ã—ã€è¨˜æ†¶ã®æ§‹ç¯‰ã¨æ›´æ–°ã‚’è¡Œã†ã€‚TravelPlannerã¨ALFWorldã§ã®å®Ÿè¨¼è©•ä¾¡ã«ã‚ˆã‚Šã€è¨˜æ†¶ãƒªãƒã‚¸ãƒˆãƒªãŒé€²åŒ–ã™ã‚‹ã“ã¨ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æˆåŠŸç‡ã¨åŠ¹ç‡ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®æ‰‹ç¶šãçš„è¨˜æ†¶ã®ç§»è¡Œã«ã‚ˆã‚Šã€å¼±ã„ãƒ¢ãƒ‡ãƒ«ã§ã‚‚æ€§èƒ½å‘ä¸ŠãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zxlzr/status/1954840738082193477?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚¢ãƒ‰ãƒ›ãƒƒã‚¯ã«æ¢ç´¢ã¨å®Ÿè¡Œã‚’ç¹°ã‚Šè¿”ã™ã®ã§ã¯ãªãã€éå»ã®è©¦è¡Œã®trajectoryã‚’ãƒ¡ãƒ¢ãƒªã«è¨˜æ†¶ã—ã¦ãŠãã€æ´»ç”¨ã™ã‚‹ã‚ˆã†ãªæ çµ„ã¿ãªæ¨¡æ§˜ã€‚trajectoryã¯æ–°ãŸãªã‚¿ã‚¹ã‚¯ãŒæ¥ãŸéš›ã«retrieverã§relevantãªtrajectoryã‚’æ¤œç´¢ã—ã¦åˆ©ç”¨ã•ã‚Œã€è‰¯è³ªãªtrajectoryãŒã‚­ãƒ¼ãƒ—ã•ã‚Œã‚Œã°æˆåŠŸç‡ã‚„åŠ¹ç‡ãŒå‘ä¸Šã™ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚trajectoryã¯procedure memoryã¨ã—ã¦ä¿å­˜ã•ã‚Œã€æˆåŠŸç‡ãŒä½ã„trajectoryã¯ç ´æ£„ã•ã‚Œã‚‹ã“ã¨ã§æ›´æ–°ã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/20e2f063-eef6-4c3d-9161-3d96f56c6f8d" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/a3766541-4946-4e43-91e4-99a873fb1d6f" alt="image" loading="lazy"><br><br>ãƒ¡ãƒ¢ãƒªã¯Tå€‹ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹s_t, a_t, o_t, i.e., state, action, observation,ã®ç³»åˆ—Ï„ã¨ã€reward rãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€Builderã‚’é€šã—ã¦æ§‹ç¯‰ã•ã‚Œã¦ã‚¹ãƒˆã‚¢ã•ã‚Œã‚‹ã€‚agentã¯æ–°ãŸãªã‚¿ã‚¹ã‚¯t_newã«ç›´é¢ã—ãŸæ™‚ã«ã€t_newã¨é¡ä¼¼ã—ãŸãƒ¡ãƒ¢ãƒªã‚’retrieyeã™ã‚‹ã€‚ã“ã‚Œã¯Ï„ã®ä¸­ã®ã‚ã‚‹æ™‚åˆ»tã®ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã™ã‚‹ã€‚ãƒ¡ãƒ¢ãƒªã¯è‚¥å¤§åŒ–ã—ã¦ã„ããŸã‚ã€å®Ÿé¨“ã§ã¯è¤‡æ•°ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«åŸºã¥ããƒ¡ãƒ¢ãƒªã®æ›´æ–°æ–¹æ³•ã«ã¤ã„ã¦å®Ÿé¨“ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/b91dbfed-c976-4764-abf6-00f4751b7e91" alt="image" loading="lazy"><br><br>procedural memoryã®æœ‰ç„¡ã«ã‚ˆã‚‹æŒ™å‹•ã®é•ã„ã«é–¢ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã€‚<br><img src="https://github.com/user-attachments/assets/2623103d-331d-45eb-a5cc-635ef3cb88ab" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/b1c21bf3-eef1-4b4c-999c-f8d0fcbc9431" alt="image" loading="lazy"></p>
<p>memoryã«å¯¾ã—ã¦retrieverã‚’é©ç”¨ã™ã‚‹ã“ã¨ã«ãªã‚‹ã®ã§ã€retrieverã®æ€§èƒ½ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚è¿½åŠ ã®å­¦ç¿’ã‚’ã—ãªãã¦æ¸ˆã‚€ã®ã¯åˆ©ç‚¹ã ãŒã€ãã®ä»£ã‚ã‚Šãƒ¢ãƒ‡ãƒ«å´ãŒãƒ¡ãƒ¢ãƒªç®¡ç†ã‚’ã™ã‚‹æ©Ÿèƒ½ã‚’æœ‰ã•ãªã„ï¼ˆå­¦ç¿’ã™ã‚Œã°ãã†ã„ã£ãŸæ©Ÿèƒ½ã‚’æŒãŸã›ã‚‰ã‚Œã‚‹ã¯ãšï¼‰ã®ã§ã€ãã®ç‚¹ã¯æ¬ ç‚¹ã¨ãªã‚‹ã€ã¨ã„ã†å°è±¡ã€‚</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1954937801490772104?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/ReversalCurse.html" target="_blank" rel="noopener noreferrer">#ReversalCurse</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2399" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Physics of Language Models: Part 3.2, Knowledge Manipulation, Zeyuan Allen-Zhu+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã¯è±Šå¯ŒãªçŸ¥è­˜ã‚’æŒã¤ãŒã€ä¸‹æµã‚¿ã‚¹ã‚¯ã¸ã®æŸ”è»Ÿãªåˆ©ç”¨ã«ã¯é™ç•ŒãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æƒ…å ±æ¤œç´¢ã€åˆ†é¡ã€æ¯”è¼ƒã€é€†æ¤œç´¢ã®4ã¤ã®çŸ¥è­˜æ“ä½œã‚¿ã‚¹ã‚¯ã‚’èª¿æŸ»ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒçŸ¥è­˜æ¤œç´¢ã«ã¯å„ªã‚Œã¦ã„ã‚‹ãŒã€Chain of Thoughtsã‚’ç”¨ã„ãªã„ã¨åˆ†é¡ã‚„æ¯”è¼ƒã‚¿ã‚¹ã‚¯ã§è‹¦åŠ´ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ç‰¹ã«é€†æ¤œç´¢ã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒã»ã¼0%ã§ã‚ã‚Šã€ã“ã‚Œã‚‰ã®å¼±ç‚¹ã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã«å›ºæœ‰ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç¾ä»£ã®AIã¨äººé–“ã‚’åŒºåˆ¥ã™ã‚‹æ–°ãŸãªãƒãƒ¥ãƒ¼ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆã®å¿…è¦æ€§ãŒæµ®ãå½«ã‚Šã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=oDbiL9CLoS" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=oDbiL9CLoS</a>


</p>
<p>è§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2398" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Physics of Language Models: Part 2.2, How to Learn From Mistakes on   Grade-School Math Problems, Tian Ye+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ç²¾åº¦å‘ä¸Šã®ãŸã‚ã«ã€ã€Œã‚¨ãƒ©ãƒ¼ä¿®æ­£ã€ãƒ‡ãƒ¼ã‚¿ã‚’äº‹å‰å­¦ç¿’ã«çµ„ã¿è¾¼ã‚€æœ‰ç”¨æ€§ã‚’æ¢æ±‚ã€‚åˆæˆæ•°å­¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€ã‚¨ãƒ©ãƒ¼ãƒ•ãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã¨æ¯”è¼ƒã—ã¦é«˜ã„æ¨è«–ç²¾åº¦ã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã•ã‚‰ã«ã€ãƒ“ãƒ¼ãƒ ã‚µãƒ¼ãƒã¨ã®é•ã„ã‚„ãƒ‡ãƒ¼ã‚¿æº–å‚™ã€ãƒã‚¹ã‚­ãƒ³ã‚°ã®å¿…è¦æ€§ã€ã‚¨ãƒ©ãƒ¼é‡ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ®µéšã§ã®é…å»¶ã«ã¤ã„ã¦ã‚‚è€ƒå¯Ÿã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=zpDGwcmMV4" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=zpDGwcmMV4</a>


</p>
<p>è§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2397" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Physics of Language Models: Part 2.1, Grade-School Math and the Hidden   Reasoning Process, Tian Ye+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ•°å­¦çš„æ¨è«–èƒ½åŠ›ã‚’ç ”ç©¶ã—ã€GSM8Kãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®ç²¾åº¦å‘ä¸Šã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æ¢ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€æ¨è«–ã‚¹ã‚­ãƒ«ã®ç™ºå±•ã€éš ã‚ŒãŸãƒ—ãƒ­ã‚»ã‚¹ã€äººé–“ã¨ã®é•ã„ã€å¿…è¦ãªã‚¹ã‚­ãƒ«ã®è¶…è¶Šã€æ¨è«–ãƒŸã‚¹ã®åŸå› ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã‚„æ·±ã•ã«ã¤ã„ã¦ã®å®Ÿé¨“ã‚’è¡Œã„ã€LLMã®ç†è§£ã‚’æ·±ã‚ã‚‹æ´å¯Ÿã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=Tn5B6Udq3E" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Tn5B6Udq3E</a>


</p>
<p>è§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
</p>
<p>å°å­¦ç”Ÿå‘ã‘ã®ç®—æ•°ã®å•é¡Œã‚’é€šã˜ã¦ã€ä»¥ä¸‹ã®åŸºæœ¬çš„ãªResearch Questionsã«ã¤ã„ã¦èª¿æŸ»ã—ã¦ç ”ç©¶ã€‚ã“ã‚Œã‚‰ã‚’ç†è§£ã™ã‚‹ã“ã¨ã§ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®çŸ¥èƒ½ã‚’ç†è§£ã™ã‚‹ç¤ã¨ã™ã‚‹ã€‚<br><br>## Research Questions<br>- è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã©ã®ã‚ˆã†ã«ã—ã¦å°å­¦æ ¡ãƒ¬ãƒ™ãƒ«ã®ç®—æ•°ã®å•é¡Œã‚’è§£ã‘ã‚‹ã‚ˆã†ã«ãªã‚‹ã®ã‹ï¼Ÿ<br>  - å˜ã«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æš—è¨˜ã—ã¦ã„ã‚‹ã ã‘ãªã®ã‹ã€ãã‚Œã¨ã‚‚äººé–“ã«ä¼¼ãŸæ¨è«–ã‚¹ã‚­ãƒ«ã‚’å­¦ã‚“ã§ã„ã‚‹ã®ã‹ï¼Ÿ<br>  - ã‚ã‚‹ã„ã¯ã€ãã®å•é¡Œã‚’è§£ããŸã‚ã«æ–°ã—ã„ã‚¹ã‚­ãƒ«ã‚’ç™ºè¦‹ã—ã¦ã„ã‚‹ã®ã‹ï¼Ÿ<br>- å°å­¦æ ¡ãƒ¬ãƒ™ãƒ«ã®ç®—æ•°å•é¡Œã ã‘ã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ãã‚Œã‚‰ã®å•é¡Œã‚’è§£ãã“ã¨ã—ã‹å­¦ã°ãªã„ã®ã‹ï¼Ÿ<br>  - ãã‚Œã¨ã‚‚ã€ã‚ˆã‚Šä¸€èˆ¬çš„ãªçŸ¥èƒ½ã‚’å­¦ç¿’ã™ã‚‹ã®ã‹ï¼Ÿ<br>- ã©ã®ãã‚‰ã„å°ã•ã„è¨€èªãƒ¢ãƒ‡ãƒ«ã¾ã§ã€å°å­¦æ ¡ãƒ¬ãƒ™ãƒ«ã®ç®—æ•°å•é¡Œã‚’è§£ã‘ã‚‹ã®ã‹ï¼Ÿ<br>  - æ·±ã•ï¼ˆå±¤ã®æ•°ï¼‰ã¯å¹…ï¼ˆå±¤ã”ã¨ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•°ï¼‰ã‚ˆã‚Šé‡è¦ãªã®ã‹ï¼Ÿ<br>  - ãã‚Œã¨ã‚‚ã€å˜ã«ã‚µã‚¤ã‚ºã ã‘ãŒé‡è¦ã‹ï¼Ÿ<br><br>ï¼ˆç¶šãã¯ã®ã¡ã»ã©...ï¼‰</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-08-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2393" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] STEPWISE-CODEX-Bench: Evaluating Complex Multi-Function Comprehension  and Fine-Grained Execution Reasoning, Kaiwen Yan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒSTEPWISE-CODEX-Benchï¼ˆSX-Benchï¼‰ã€ã‚’ææ¡ˆã—ã€è¤‡é›‘ãªå¤šæ©Ÿèƒ½ç†è§£ã¨ç´°ã‹ã„å®Ÿè¡Œæ¨è«–ã‚’è©•ä¾¡ã€‚SX-Benchã¯ã€ã‚µãƒ–é–¢æ•°é–“ã®å”åŠ›ã‚’å«ã‚€ã‚¿ã‚¹ã‚¯ã‚’ç‰¹å¾´ã¨ã—ã€å‹•çš„å®Ÿè¡Œã®æ·±ã„ç†è§£ã‚’æ¸¬å®šã™ã‚‹ã€‚20ä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡ã—ãŸçµæœã€æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã§ã‚‚è¤‡é›‘ãªæ¨è«–ã«ãŠã„ã¦ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãŒæ˜ã‚‰ã‹ã«ã€‚SX-Benchã¯ã‚³ãƒ¼ãƒ‰è©•ä¾¡ã‚’é€²å±•ã•ã›ã€é«˜åº¦ãªã‚³ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã«è²¢çŒ®ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1954296753525752266?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¾åœ¨ã®ä¸»æµãªã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®ãƒ™ãƒ³ãƒã¯ã€input/outputãŒgivenãªã‚‰ä¸Šã§ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’ç”Ÿæˆã™ã‚‹å½¢å¼ãŒä¸»æµ(e.g., MBPP <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2439" target="_blank" rel="noopener noreferrer">[Paper Note] Program Synthesis with Large Language Models, Jacob Austin+, arXiv'21</a>
, HumanEval <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2438" target="_blank" rel="noopener noreferrer">[Paper Note] Evaluating Large Language Models Trained on Code, Mark Chen+, arXiv'21</a>
)ã ãŒã€ãƒ¢ãƒ‡ãƒ«ãŒã‚³ãƒ¼ãƒ‰ã‚’ç†è§£ã—ã€è¤‡é›‘ãªã‚³ãƒ¼ãƒ‰ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè¡Œã™ã‚‹å†…éƒ¨çŠ¶æ…‹ã®å¤‰åŒ–ã«å¿œã˜ã¦ã€å®Ÿè¡Œã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ¨è«–ã™ã‚‹èƒ½åŠ›ãŒè¦‹è½ã¨ã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€CRUXEVAL <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2440" target="_blank" rel="noopener noreferrer">[Paper Note] CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution, Alex Gu+, arXiv'24</a>
, CRUXEVAL-X <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2441" target="_blank" rel="noopener noreferrer">[Paper Note] CRUXEval-X: A Benchmark for Multilingual Code Reasoning, Understanding
  and Execution, Ruiyang Xu+, arXiv'24</a>
 ã§ã¯ã€é–¢æ•°ã®inputs/outputsã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ¼ãƒ‰ã®comprehension, reasoningèƒ½åŠ›ã‚’æ¸¬ã‚ã†ã¨ã—ã¦ã„ã‚‹ãŒã€<br>- single functionã®logicã«é™å®šã•ã‚Œã¦ã„ã‚‹<br>- 20 lineç¨‹åº¦ã®çŸ­ãã€trivialãªãƒ­ã‚¸ãƒƒã‚¯ã«é™å®šã•ã‚Œã¦ã„ã‚‹<br>- ã™ã§ã«SoTAãƒ¢ãƒ‡ãƒ«ã§95%ãŒé”æˆã•ã‚Œé£½å’Œã—ã¦ã„ã‚‹<br><br>ã¨ã„ã†limitationãŒã‚ã‚‹ã®ã§ã€è¤‡æ•°ã®é–¢æ•°ãŒå”åƒã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã€flow/dataã®interactionã®ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ã€ç´°ã‹ã„å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—ãªã©ã‚’å«ã‚€ã€staticãªã‚³ãƒ¼ãƒ‰ã®ç†è§£ã‹ã‚‰ã€å‹•çš„ãªå®Ÿè¡Œãƒ—ãƒ­ã‚»ã‚¹ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°èƒ½åŠ›ã®è©•ä¾¡ã«ã‚·ãƒ•ãƒˆã™ã‚‹ã‚ˆã†ãªã€æ–°ãŸãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸã€ã¨ã„ã†è©±ãªæ¨¡æ§˜ã€‚<br><br>ã¾ãšé–¢æ•°å˜ä½ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æ§‹ç¯‰ã—ã¦ã„ã‚‹ã€‚ã“ã®ãŸã‚ã«ã€å˜ä¸€ã®é–¢æ•°ã®åŸºç¤çš„ãªä»•æ§˜ã‚’ã€ŒåŒã˜inputã«å¯¾ã—ã¦åŒã˜outputã‚’è¿”ã™ã‚‚ã®ã¯åŒã˜ã‚¯ãƒ©ã‚¹ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚Œã‚‹ã€ã¨å®šç¾©ã—ã€æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ãƒªãƒã‚¸ãƒˆãƒªã¨LLMã«ã‚ˆã‚‹åˆæˆã«ã‚ˆã£ã¦ã€Goã¨Pythonã«ã¤ã„ã¦åˆè¨ˆ30ç¨®é¡ã®ã‚¯ãƒ©ã‚¹ã¨361å€‹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åé›†ã€‚ã“ã‚Œã‚‰ã®é–¢æ•°ã¯ã€ç®—è¡“æ¼”ç®—ã‚„å¤§å°æ¯”è¼ƒã€ãƒ‘ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ãªã©ã®åˆ¤å®šã€æ–‡å­—åˆ—ã®æ“ä½œãªã©ã‚’å«ã‚€ã€‚ãã—ã¦ã“ã‚Œã‚‰é–¢æ•°ã‚’3ç¨®é¡ã®å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã“ã¨ã§ã€åˆæˆé–¢æ•°ã‚’ä½œæˆã—ãŸã€‚åˆæˆæ–¹æ³•ã¯<br>- Sequential: outputã¨inputã‚’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã¤ãªãä¼æ¬ã•ã›ã‚‹<br>- Selective: æ¡ä»¶ã«å¿œã˜ã¦f(x)ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã‹ã€g(x)ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã‹ã‚’åˆ¶å¾¡<br>- Loop: inputé›†åˆã«å¯¾ã™ã‚‹loopã®ä¸­ã«é–¢æ•°ã‚’åŸ‹ã‚è¾¼ã¿é †æ¬¡é–¢æ•°ã‚’å®Ÿè¡Œ<br><br>ã®3ç¨®é¡ã€‚åˆæˆé–¢æ•°ã®æŒ™å‹•ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã¯è‡ªå‹•ç”Ÿæˆã—ã€åˆæˆé–¢æ•°ã®æŒ™å‹•ã‚’ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã€ç„¡é™ãƒ«ãƒ¼ãƒ—ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€è¤‡æ•°å›ã®å®Ÿè¡Œã§outputãŒæ±ºå®šçš„ã‹ç­‰ãªã©ï¼‰ã—ã€ç•°å¸¸ãŒã‚ã‚‹ã‚‚ã®ã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§åˆæˆé–¢æ•°ã®å“è³ªã‚’æ‹…ä¿ã™ã‚‹ã€‚<br><br>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°ã®æ–¹æ³•ã¨ã—ã¦ã¯ã€CRUXEVALã§ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«ãƒ¢ãƒ‡ãƒ«ã«ã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡Œçµæœã‚’äºˆæƒ³ã•ã›ã‚‹ã ã‘ã§ã‚ã£ãŸãŒã€æŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ã®å•é¡Œã‹ã‚‰ãƒŸã‚¹ã‚¸ãƒ£ãƒƒã‚¸ã‚’ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€ã“ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚&lt;input, output&gt;ã®ãƒšã‚¢ãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€outputãŒåˆæˆé–¢æ•°ã«å¯¾ã—ã¦inputã—ã¾çµæœã¨ãƒãƒƒãƒã™ã‚‹ã‹ã‚’yes/noã®binaryã§åˆ¤å®šã•ã›ã‚‹ï¼ˆPredictã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ¼ãƒ‰ç†è§£åŠ›ã‚’è©•ä¾¡)ã€‚ã“ã‚Œã¨ã¯åˆ¥ã«ã€ä¸ãˆã‚‰ã‚ŒãŸinput, outputãƒšã‚¢ã¨åˆæˆé–¢æ•°ã«åŸºã¥ã„ã¦ã€å®Ÿè¡Œæ™‚ã®åˆè¨ˆã®computation stepsã‚’å‡ºåŠ›ã•ã›ã‚‹ã‚¿ã‚¹ã‚¯ã‚’reasoningã‚¿ã‚¹ã‚¯ã¨ã—ã¦å®šç¾©ã—ã€è¤‡é›‘åº¦ã«å¿œã˜ã¦easy, hardã«åˆ†é¡ã—ã¦ã„ã‚‹ã€‚computation stepsã¯ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’å®Ÿè¡Œã™ã‚‹æœ€å°å˜ä½ã®ã“ã¨ã§ã‚ã‚Šã€ãŸã¨ãˆã°ç®—è¡“æ¼”ç®—ãªã©ã®åŸºç¤çš„ãªarithmetic/logic operationã‚’æŒ‡ã™ã€‚<br><img src="https://github.com/user-attachments/assets/8ac34d8c-63e4-42d7-96ea-13dbe39ad683" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/76407c5b-acd0-40ef-a698-684875ccc680" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-08-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2391" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Agent Lightning: Train ANY AI Agents with Reinforcement Learning, Xufang Luo+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Agent Lightningã¯ã€ä»»æ„ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãŸã‚ã«LLMsã‚’ç”¨ã„ãŸRLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¯èƒ½ã«ã™ã‚‹æŸ”è»Ÿãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè¡Œã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’åˆ†é›¢ã—ã€æ—¢å­˜ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®çµ±åˆã‚’å®¹æ˜“ã«ã—ã¾ã™ã€‚ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹ã¨ã—ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè¡Œã‚’å®šå¼åŒ–ã—ã€éšå±¤çš„RLã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ LightningRLã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¤‡é›‘ãªç›¸äº’ä½œç”¨ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ‰±ã†ã“ã¨ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚å®Ÿé¨“ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰SQLã¸ã®å¤‰æ›ãªã©ã§å®‰å®šã—ãŸæ”¹å–„ãŒè¦‹ã‚‰ã‚Œã€å®Ÿä¸–ç•Œã§ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å¯èƒ½æ€§ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/curveweb/status/1954384415330824698?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SyntheticDataGeneration.html" target="_blank" rel="noopener noreferrer">#SyntheticDataGeneration</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-08-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2390" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging  Synthetic Problems with a Reinforced Policy, Shaoxiong Zhan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MathSmithã¨ã„ã†æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€LLMã®æ•°å­¦çš„æ¨è«–ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã«æ–°ã—ã„å•é¡Œã‚’ã‚¼ãƒ­ã‹ã‚‰åˆæˆã€‚æ—¢å­˜ã®å•é¡Œã‚’ä¿®æ­£ã›ãšã€PlanetMathã‹ã‚‰æ¦‚å¿µã¨èª¬æ˜ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ãƒ‡ãƒ¼ã‚¿ã®ç‹¬ç«‹æ€§ã‚’ç¢ºä¿ã€‚9ã¤ã®æˆ¦ç•¥ã‚’ç”¨ã„ã¦é›£æ˜“åº¦ã‚’ä¸Šã’ã€å¼·åŒ–å­¦ç¿’ã§æ§‹é€ çš„å¦¥å½“æ€§ã‚„æ¨è«–ã®è¤‡é›‘ã•ã‚’æœ€é©åŒ–ã€‚å®Ÿé¨“ã§ã¯ã€MathSmithãŒæ—¢å­˜ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€é«˜é›£æ˜“åº¦ã®åˆæˆãƒ‡ãƒ¼ã‚¿ãŒLLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1954253929761411180?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/Label-free.html" target="_blank" rel="noopener noreferrer">#Label-free</a>
<span class="issue_date">Issue Date: 2025-08-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2387" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] R-Zero: Self-Evolving Reasoning LLM from Zero Data, Chengsong Huang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- R-Zeroã¯ã€è‡ªå·±é€²åŒ–å‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ãŒè‡ªå¾‹çš„ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€ãƒãƒ£ãƒ¬ãƒ³ã‚¸ãƒ£ãƒ¼ã¨ã‚½ãƒ«ãƒãƒ¼ã®2ã¤ã®ãƒ¢ãƒ‡ãƒ«ãŒå…±é€²åŒ–ã™ã‚‹ã“ã¨ã§ã€æ—¢å­˜ã®ã‚¿ã‚¹ã‚¯ã‚„ãƒ©ãƒ™ãƒ«ã«ä¾å­˜ã›ãšã«è‡ªå·±æ”¹å–„ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚Šã€æ¨è«–èƒ½åŠ›ãŒå¤§å¹…ã«å‘ä¸Šã—ã€ç‰¹ã«Qwen3-4B-Baseã§ã¯æ•°å­¦æ¨è«–ã§+6.49ã€ä¸€èˆ¬ãƒ‰ãƒ¡ã‚¤ãƒ³æ¨è«–ã§+7.54ã®æ”¹å–„ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1953804055525962134?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å•é¡Œã‚’ç”Ÿæˆã™ã‚‹Challengerã¨ä¸ãˆã‚‰ã‚ŒãŸå•é¡Œã‚’è§£ãSolverã‚’ç”¨æ„ã—ã€ç‰‡æ–¹ã‚’freezezã•ã›ãŸçŠ¶æ…‹ã§äº¤äº’ã«ãƒãƒªã‚·ãƒ¼ã®æ›´æ–°ã‚’ç¹°ã‚Šè¿”ã™ã€‚<br><br><img src="https://github.com/user-attachments/assets/05207756-3029-41a2-8dd0-e27de5228436" alt="image" loading="lazy"><br><br>
<strong>### Challenger<br>-  ï¼ˆChallengerã«ã‚ˆã‚‹)å•é¡Œç”Ÿæˆâ†’<br>- ï¼ˆfreezed solverã«ã‚ˆã‚‹ï¼‰self consistencyã«ã‚ˆã‚‹ãƒ©ãƒ™ãƒ«ä»˜ã‘â†’<br>- Solverã®å•é¡Œã«å¯¾ã™ã‚‹empirical acc.ï¼ˆi.e., ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å›æ•°mã«å¯¾ã™ã‚‹majorityãŒå ã‚ã‚‹å‰²åˆï¼‰ã§rewardã‚’ä¸ãˆChallengerã‚’æ›´æ–°<br><br>ã¨ã„ã£ãŸæµã‚Œã§ãƒãƒªã‚·ãƒ¼ãŒæ›´æ–°ã•ã‚Œã‚‹ã€‚Rewardã¯ä»–ã«ã‚‚ç”Ÿæˆã•ã‚ŒãŸå•é¡Œé–“ã®BLEUã‚’æ¸¬ã‚Šé¡ä¼¼ã—ãŸã‚‚ã®ã°ã‹ã‚Šã®å ´åˆã¯ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’ä¸ãˆã‚‹é …ã‚„ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒæ­£ã—ãæŒ‡å®šã•ã‚ŒãŸé€šã‚Šã«ãªã£ã¦ã„ã‚‹ã‹ã€ã¨ã„ã£ãŸãƒšãƒŠãƒ«ãƒ†ã‚£ã‚‚å°å…¥ã™ã‚‹ã€‚<br><br>### Solver<br>- Challengerã®ãƒãƒªã‚·ãƒ¼ã‹ã‚‰Nå•ç”Ÿæˆã—ã€ãã‚Œã«å¯¾ã—ã¦Solverã§self consistencyã«ã‚ˆã£ã¦è§£ç­”ã‚’ç”Ÿæˆ<br>- empirical acc.ã‚’è¨ˆç®—ã—ã€1/2ã¨ã®å·®åˆ†ã®çµ¶å¯¾å€¤ã‚’è¦‹ã¦ã€ç°¡å˜ã™ãã‚‹/é›£ã—ã™ãã‚‹å•é¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°<br>  - ã“ã‚Œã¯ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ å­¦ç¿’çš„ãªæ„å‘³åˆã„ã®ã¿ãªã‚‰ãšã€ä½å“è³ªãªå•é¡Œã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚‚å¯„ä¸ã™ã‚‹<br>- ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®å•é¡Œã‚’åˆ©ç”¨ã—ã¦ã€verifiable binary rewardã§ãƒãƒªã‚·ãƒ¼ã‚’æ›´æ–°<br><br>### è©•ä¾¡çµæœ<br>æ•°å­¦ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ææ¡ˆæ‰‹æ³•ã‚’é©ç”¨ã—ãŸã¨ã“ã‚ã€iterã”ã¨ã«å…¨ä½“ã®å¹³å‡æ€§èƒ½ã¯å‘ä¸Šã€‚<br><img src="https://github.com/user-attachments/assets/cbe780ec-a99b-4227-b983-4e24982a6af8" alt="image" loading="lazy"><br><br>ææ¡ˆæ‰‹æ³•ã§æ•°å­¦ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’å­¦ç¿’ã—ã€generalãƒ‰ãƒ¡ã‚¤ãƒ³ã«æ±åŒ–ã™ã‚‹ã‹ï¼Ÿã‚’ç¢ºèªã—ãŸã¨ã“ã‚ã€æ±åŒ–ã™ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆãŸã ã€ã™ãã«ã‚µãƒã£ã¦ã„ã‚‹ã‚ˆã†ã«ã‚‚è¦‹ãˆã‚‹ï¼‰ã€‚ã€<br><img src="https://github.com/user-attachments/assets/bc0eb3e1-8ed1-4d36-b30e-095e8a160886" alt="image" loading="lazy">&lt;/p&gt;<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2383" target="_blank" rel="noopener noreferrer">[Paper Note] Self-Questioning Language Models, Lili Chen+, arXiv'25</a>
&lt;/strong&gt;
<br>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1936" target="_blank" rel="noopener noreferrer">Absolute Zero: Reinforced Self-play Reasoning with Zero Data, Andrew Zhao+, arXiv'25</a>
</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wyu_nd/status/1954249813861810312?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chengsongh31219/status/1953936172415430695?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</strong></p>
<p>æ—¥æœ¬èªè§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/curveweb/status/1954367657811308858?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


&lt;/span&gt;<br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/Label-free.html" target="_blank" rel="noopener noreferrer">#Label-free</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-08-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2383" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Questioning Language Models, Lili Chen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±è³ªå•å‹è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆSQLMï¼‰ã‚’ææ¡ˆã—ã€ãƒˆãƒ”ãƒƒã‚¯ã‚’æŒ‡å®šã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰è‡ªã‚‰è³ªå•ã‚’ç”Ÿæˆã—ã€è§£ç­”ã™ã‚‹éå¯¾ç§°ã®è‡ªå·±å¯¾æˆ¦ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã€‚ææ¡ˆè€…ã¨è§£ç­”è€…ã¯å¼·åŒ–å­¦ç¿’ã§è¨“ç·´ã•ã‚Œã€å•é¡Œã®é›£æ˜“åº¦ã«å¿œã˜ã¦å ±é…¬ã‚’å—ã‘å–ã‚‹ã€‚ä¸‰æ¡ã®æ›ã‘ç®—ã‚„ä»£æ•°å•é¡Œã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å•é¡Œã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãªã—ã§è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://self-questioning.github.io" target="_blank" rel="noopener noreferrer">https://self-questioning.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lchen915/status/1953896909925757123?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãŸã¨ãˆã°ä¸‹è¨˜ã®ã‚ˆã†ãªã€ãƒ©ãƒ™ãƒ«ç„¡ã—ã®å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã™ã‚‹æ‰‹æ³•ã‚‚ç”¨ã„ã¦self improvingã™ã‚‹æ‰‹æ³•ã¨æ¯”è¼ƒã—ãŸã¨ãã«ã€ã©ã®ç¨‹åº¦ã®æ€§èƒ½å·®ã«ãªã‚‹ã®ã ã‚ã†ã‹ï¼Ÿå¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’å…¨ãåˆ©ç”¨ã›ãšã€å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚ã‚Šã®æ‰‹æ³•ã¨åŒç­‰ã¾ã§ã„ã‘ã¾ã™ã€ã¨ã„ã†è©±ã«ãªã‚‹ã¨ã€ã‚ˆã‚Šèˆˆå‘³æ·±ã„ã¨æ„Ÿã˜ãŸã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1212" target="_blank" rel="noopener noreferrer">Self-Rewarding Language Models, Weizhe Yuan+, N/A, ICML'24</a>
</p>
<p>æ—¢å­˜ã®å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ãªã„é–¢é€£ç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1936" target="_blank" rel="noopener noreferrer">Absolute Zero: Reinforced Self-play Reasoning with Zero Data, Andrew Zhao+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-08-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with  Reward Rectification, Yongliang Wu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã€å‹•çš„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆDFTï¼‰ã‚’ææ¡ˆã€‚DFTã¯ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¢ºç‡ã«åŸºã¥ã„ã¦ç›®çš„é–¢æ•°ã‚’å†ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã€å‹¾é…æ›´æ–°ã‚’å®‰å®šåŒ–ã•ã›ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€SFTã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ã§ã‚‚ç«¶äº‰åŠ›ã®ã‚ã‚‹çµæœã‚’å¾—ãŸã€‚ç†è«–çš„æ´å¯Ÿã¨å®Ÿè·µçš„è§£æ±ºç­–ã‚’çµã³ã¤ã‘ã€SFTã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1953960036126142645?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯å¤§å¤‰èˆˆå‘³æ·±ã„ã€‚æ•°å­¦ä»¥å¤–ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®è©•ä¾¡ã«ã‚‚æœŸå¾…ã—ãŸã„ã€‚</p>
<p>3ç¯€å†’é ­ã‹ã‚‰3.2ç¯€ã«ã‹ã‘ã¦ã€SFTã¨on policy RLã®gradientã‚’å®šå¼åŒ–ã—ã€SFTå´ã®æ•°å¼ã‚’æ•´ç†ã™ã‚‹ã“ã¨ã§ã€SFTï¼ˆã®gradient)ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªon policy RLã®ä¸€ã¤ã®ã‚±ãƒ¼ã‚¹ã¨ã¿ãªã›ã‚‹ã“ã¨ã‚’å°å‡ºã—ã¦ã„ã‚‹ã€‚ãã—ã¦SFTã®æ±åŒ–æ€§èƒ½ãŒä½ã„ã®ã¯ 1/pi_theta ã«ã‚ˆã‚‹importance weightingã§ã‚ã‚‹ã¨ä¸»å¼µã—ã€å®Ÿé¨“çš„ã«ãã‚Œã‚’è¨¼æ˜ã—ã¦ã„ã‚‹ã€‚ã¤ã¾ã‚Šã€ãƒãƒªã‚·ãƒ¼ãŒexpertã®gold responseã«å¯¾ã—ã¦ä½ã„å°¤åº¦ã‚’ç¤ºã—ã¦ã—ã¾ã£ãŸå ´åˆã«ã€weightã‹éå‰°ã«å¤§ãããªã‚Šã€Rewardã®åˆ†æ•£ãŒéåº¦ã«å¤§ãããªã£ã¦ã—ã¾ã†ã“ã¨ãŒRLã®è¦³ç‚¹ã‚’é€šã—ã¦ã¿ã‚‹ã¨å•é¡Œã§ã‚ã‚Šã€ã“ã‚Œã‚’æ˜¯æ­£ã™ã‚‹ã“ã¨ãŒå¿…è¦ã€‚ã•ã‚‰ã«ã€åˆ†æ•£ãŒå¤§ãã„å ±é…¬ã®çŠ¶æ…‹ã§ã€å ±é…¬ãŒsparse(i.e., expertã®trajectoryã®exact matchã—ã¦ã„ãªã„ã¨å ±é…¬ãŒzero)ã§ã‚ã‚‹ã“ã¨ãŒã€ã•ã‚‰ã«äº‹æ…‹ã‚’æ‚ªåŒ–ã•ã›ã¦ã„ã‚‹ã€‚<br><br>&gt; conventional SFT is precisely an on-policy-gradient with the reward as an indicator function of<br>matching the expert trajectory but biased by an importance weighting 1/Ï€Î¸.<br><br>ã¾ã æ–œã‚èª­ã¿ã—ã‹ã—ã¦ã„ãªã„ã®ã§ã€å¾Œã§ã—ã£ã‹ã‚Šèª­ã¿ãŸã„</p>
<p>æœ€è¿‘ã¯ä¸‹è¨˜ã§ç¤ºã•ã‚Œã¦ã„ã‚‹é€šã‚ŠSFTã§warm-upã‚’ã—ãŸå¾Œã«RLã«ã‚ˆã‚‹post-trainingã‚’ã™ã‚‹ã“ã¨ã§æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ãŠã‚Šã€<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
 <br><br>ä¸»è¦ãªOpenModelã§ã‚‚SFT wamup -&gt; RLã®æµã‚ŒãŒä¸»æµã§ã‚ã‚‹ã€‚ã“ã®çŸ¥è¦‹ãŒã€SFTã«ã‚ˆã‚‹warm upã®æœ‰åŠ¹æ€§ã¨ã©ã†ç´ã¥ãã ã‚ã†ã‹ï¼Ÿ<br>ã“ã‚Œã‚’èª­ã‚“ã æ„Ÿã˜ã ã¨ã€importance weightã«ã‚ˆã£ã¦ã€ç¾åœ¨ã®ãƒãƒªã‚·ãƒ¼ãŒè‹¦æ‰‹ãªéƒ¨åˆ†ã®reasoning capabilityã®ã¿ã‚’æœ€åˆã«å¼·åŒ–ã—ï¼ˆ= warmupï¼‰ã€ãã®ä¸Šã§ã‚ˆã‚Šåºƒç¯„ãªã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã™ã‚‹RLãŒå®Ÿæ–½ã•ã‚Œã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€æ€§èƒ½å‘ä¸Šã¨ã€å­¦ç¿’ã®å®‰å®šã«ã¤ãªãŒã£ã¦ã„ã‚‹ã®ã§ã¯ãªã„ã‹ï¼Ÿã¨ã„ã†æ°—ãŒã™ã‚‹ã€‚</p>
<p>æ—¥æœ¬èªè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1960108668336390593?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ä¸€æ­©å…ˆã®è¦–ç‚¹ãŒè€ƒå¯Ÿã•ã‚Œã¦ãŠã‚Šã€ã¨ã¦ã‚‚å‹‰å¼·ã«ãªã‚‹ã€‚</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2025-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2381" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A comprehensive taxonomy of hallucinations in Large Language Models, Manuel Cossio, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªåˆ†é¡æ³•ã‚’æä¾›ã—ã€ãã®æœ¬è³ªçš„ãªé¿ã‘ã‚‰ã‚Œãªã•ã‚’æå”±ã€‚å†…å› çš„ãŠã‚ˆã³å¤–å› çš„ãªè¦å› ã€äº‹å®Ÿèª¤èªã‚„ä¸æ•´åˆãªã©ã®å…·ä½“çš„ãªç¾ã‚Œã‚’åˆ†æã€‚æ ¹æœ¬çš„ãªåŸå› ã‚„èªçŸ¥çš„è¦å› ã‚’æ¤œè¨ã—ã€è©•ä¾¡åŸºæº–ã‚„è»½æ¸›æˆ¦ç•¥ã‚’æ¦‚èª¬ã€‚ä»Šå¾Œã¯ã€ä¿¡é ¼æ€§ã®ã‚ã‚‹å±•é–‹ã®ãŸã‚ã«æ¤œå‡ºã¨ç›£è¦–ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sei_shinagawa/status/1953845008588513762?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2376" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning to Reason for Factuality, Xilun Chen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- R-LLMsã¯è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã§é€²å±•ã—ã¦ã„ã‚‹ãŒã€äº‹å®Ÿæ€§ã«ãŠã„ã¦å¹»è¦šã‚’å¤šãç”Ÿæˆã™ã‚‹ã€‚ã‚ªãƒ³ãƒ©ã‚¤ãƒ³RLã‚’é•·æ–‡ã®äº‹å®Ÿæ€§è¨­å®šã«é©ç”¨ã™ã‚‹éš›ã€ä¿¡é ¼ã§ãã‚‹æ¤œè¨¼æ–¹æ³•ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚èª²é¡ŒãŒã‚ã‚‹ã€‚å¾“æ¥ã®è‡ªå‹•è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ãŸã‚ªãƒ•ãƒ©ã‚¤ãƒ³RLã§ã¯å ±é…¬ãƒãƒƒã‚­ãƒ³ã‚°ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ãŒåˆ¤æ˜ã€‚ãã“ã§ã€äº‹å®Ÿã®ç²¾åº¦ã€è©³ç´°ãƒ¬ãƒ™ãƒ«ã€é–¢é€£æ€§ã‚’è€ƒæ…®ã—ãŸæ–°ã—ã„å ±é…¬é–¢æ•°ã‚’ææ¡ˆã—ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³RLã‚’é©ç”¨ã€‚è©•ä¾¡ã®çµæœã€å¹»è¦šç‡ã‚’å¹³å‡23.1ãƒã‚¤ãƒ³ãƒˆå‰Šæ¸›ã—ã€å›ç­”ã®è©³ç´°ãƒ¬ãƒ™ãƒ«ã‚’23%å‘ä¸Šã•ã›ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1953629692772446481?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ˆè¡Œç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2378" target="_blank" rel="noopener noreferrer">[Paper Note] VERISCORE: Evaluating the factuality of verifiable claims in long-form
  text generation, Yixiao Song+, arXiv'24</a>
</p>
<p>Reasoning Modelã®Hallucination Rateã¯ã€ãã®ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚é«˜ã„ã€‚å®Ÿéš›ã€DeepSeek-V3ã¨DeepSeek-R1,Qwen-2.5-32Bã¨QwQ-32Bã‚’6ã¤ã®Factualityã«é–¢ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ¯”è¼ƒã™ã‚‹ã¨ã€Reasoning Modelã®æ–¹ãŒHallucination RateãŒ10, 13%ç¨‹åº¦é«˜ã‹ã£ãŸã€‚ã“ã‚Œã¯ã€ç¾åœ¨ã®On-policyã®RLãŒlogical reasoningã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦ãŠã‚Šã€Factualityã‚’è¦‹è½ã¨ã—ã¦ã„ã‚‹ãŸã‚ã€ã¨ä»®èª¬ã‚’ç«‹ã¦ã¦ã„ã‚‹ã€‚<br>Factualityï¼ˆç‰¹ã«LongForm)ã¨RL alignmentsã¨ã„ã†è¦³ç‚¹ã‹ã‚‰è¨€ã†ã¨ã€æ±ºå®šçš„ã€æ­£ç¢ºã‹ã¤ä¿¡é ¼æ€§ã®ã‚ã‚‹verificatlonæ‰‹æ³•ã¯å­˜åœ¨ã›ãšã€Human EffortãŒå¿…è¦ä¸å¯æ¬ ã§ã‚ã‚‹ã€‚<br>è‡ªå‹•çš„ã«Factualityã‚’æ¸¬å®šã™ã‚‹FactScoreã®ã‚ˆã†ãªæ‰‹æ³•ã¯ã€DPOã®ã‚ˆã†ãªã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã®ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹ã«ç•™ã¾ã£ã¦ã—ã¾ã£ã¦ã„ã‚‹ã€‚ã¾ãŸã€on dataã§Factualityã‚’æ”¹å–„ã™ã‚‹å–ã‚Šçµ„ã¿ã¯è¡Œã‚ã‚Œã¦ã„ã‚‹ãŒã€long-formãªå¿œç­”ã«å¯¾ã—ã¦ã€factual reasoningã‚’å®Ÿæ–½ã™ã‚‹ã«ã¯ã„ãã¤ã‹ã®èª²é¡ŒãŒæ®‹ã•ã‚Œã¦ã„ã‚‹:<br>- reward design<br>  - Factualityã«é–¢ã™ã‚‹rewardã‚’å˜ç‹¬ã§è¿½åŠ ã™ã‚‹ã ã‘ã ã¨ã€LLMã¯éå¸¸ã«çŸ­ãã€è©³ç´°ã‚’çœç•¥ã—ãŸå¿œç­”ã‚’ã—Precicionã®ã¿ã‚’é«˜ã‚ã‚ˆã†ã¨ã—ã¦ã—ã¾ã†ã€‚<br><br>ã‚ã¨ã§è¿½è¨˜ã™ã‚‹</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2025-08-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2352" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On the Expressiveness of Softmax Attention: A Recurrent Neural Network  Perspective, Gabriel Mongaras+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®å†å¸°çš„ãªå½¢å¼ã‚’å°å‡ºã—ã€ç·šå½¢ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãŒãã®è¿‘ä¼¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®å„éƒ¨åˆ†ã‚’RNNã®è¨€èªã§èª¬æ˜ã—ã€æ§‹æˆè¦ç´ ã®é‡è¦æ€§ã¨ç›¸äº’ä½œç”¨ã‚’ç†è§£ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãŒä»–ã®æ‰‹æ³•ã‚ˆã‚Šã‚‚è¡¨ç¾åŠ›ãŒé«˜ã„ç†ç”±ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1952485214162407644?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LinearAttentioné–¢é€£ã®ç ”ç©¶ã¯ä¸‹è¨˜ã‚ãŸã‚ŠãŒã‚ã‚Šãã†ï¼Ÿ<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2353" target="_blank" rel="noopener noreferrer">[Paper Note] Efficient Attention: Attention with Linear Complexities, Zhuoran Shen+, arXiv'18</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2354" target="_blank" rel="noopener noreferrer">[Paper Note] Linformer: Self-Attention with Linear Complexity, Sinong Wang+, arXiv'20</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2355" target="_blank" rel="noopener noreferrer">[Paper Note] Reformer: The Efficient Transformer, Nikita Kitaev+, ICLR'20</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2356" target="_blank" rel="noopener noreferrer">[Paper Note] Transformers are RNNs: Fast Autoregressive Transformers with Linear  Attention, Angelos Katharopoulos+, ICML'20</a>
</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
<br><br>ãŸã¨ãˆã°GQAã¯Qwen3ã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ãŒã€æœ¬ç ”ç©¶ã®çŸ¥è¦‹ã‚’æ´»ç”¨ã—ã¦scaled-dot product attentionè¨ˆç®—æ™‚ã®Softmaxè¨ˆç®—ã®è¨ˆç®—é‡ãŒå‰Šæ¸›ã§ããŸã‚‰ã€ã•ã‚‰ã«è¨ˆç®—é‡ãŒå‰Šæ¸›ã§ããã†ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2025-08-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2350" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MLE-STAR: Machine Learning Engineering Agent via Search and Targeted  Refinement, Jaehyun Nam+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MLE-STARã¯ã€LLMã‚’ç”¨ã„ã¦MLãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•å®Ÿè£…ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€ã‚¦ã‚§ãƒ–ã‹ã‚‰åŠ¹æœçš„ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã—ã€ç‰¹å®šã®MLã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ç„¦ç‚¹ã‚’å½“ã¦ãŸæˆ¦ç•¥ã‚’æ¢ç´¢ã™ã‚‹ã“ã¨ã§ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“çµæœã§ã¯ã€MLE-STARãŒKaggleã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®64%ã§ãƒ¡ãƒ€ãƒ«ã‚’ç²å¾—ã—ã€ä»–ã®æ‰‹æ³•ã‚’å¤§ããä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/marktechpost/status/1951846630266687927?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-08-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2346" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A   Perspective of Probability Theory, Yexiang Liu+, ACL'25 Outstanding Paper</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMã®ãƒ†ã‚¹ãƒˆæ™‚ã®è¨ˆç®—ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ãŠã‘ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæˆ¦ç•¥ã®åŠ¹æœã‚’èª¿æŸ»ã€‚6ã¤ã®LLMã¨8ã¤ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæˆ¦ç•¥ã‚’ç”¨ã„ãŸå®Ÿé¨“ã«ã‚ˆã‚Šã€è¤‡é›‘ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæˆ¦ç•¥ãŒå˜ç´”ãªChain-of-Thoughtã«åŠ£ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ç†è«–çš„ãªè¨¼æ˜ã‚’æä¾›ã€‚ã•ã‚‰ã«ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ€§èƒ½ã‚’äºˆæ¸¬ã—æœ€é©ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæˆ¦ç•¥ã‚’ç‰¹å®šã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã€ãƒªã‚½ãƒ¼ã‚¹é›†ç´„çš„ãªæ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã®å¿…è¦æ€§ã‚’æ’é™¤ã€‚è¤‡é›‘ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†è©•ä¾¡ã¨å˜ç´”ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæˆ¦ç•¥ã®æ½œåœ¨èƒ½åŠ›ã‚’å¼•ãå‡ºã™ã“ã¨ã§ã€ãƒ†ã‚¹ãƒˆæ™‚ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>non-thinkingãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€Majority Voting (i.e. Self Consistency)ã«ã‚ˆã‚‹test-time scalingã‚’å®Ÿæ–½ã™ã‚‹å ´åˆã®ã•ã¾ã–ã¾ãªpromptingæˆ¦ç•¥ã®ã†ã¡ã€budgetã¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°ãŒå°ã•ã„å ´åˆã¯CoTä»¥å¤–ã®é©åˆ‡ãªpromptingæˆ¦ç•¥ã¯ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ç•°ãªã‚‹ãŒã€budgetã‚„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°ãŒå¢—ãˆã¦ãã‚‹ã¨ã‚·ãƒ³ãƒ—ãƒ«ãªCoTï¼ˆå®Ÿé¨“ã§ã¯zeroshot CoTã‚’åˆ©ç”¨ï¼‰ãŒæœ€é©ãªpromptingæˆ¦ç•¥ã¨ã—ã¦æ”¯é…çš„ã«ãªã‚‹ã€ã¨ã„ã†è©±ãªæ¨¡æ§˜ã€‚<br><br>ã•ã‚‰ã«ã€ãªãœãã†ãªã‚‹ã‹ã®ç†è«–çš„ãªåˆ†æã¨æœ€é©ãªä¸ãˆã‚‰ã‚ŒãŸäºˆç®—ã‹ã‚‰æœ€é©ãªpromptingæˆ¦ç•¥ã‚’äºˆæ¸¬ã™ã‚‹æ‰‹æ³•ã‚‚ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br>ãŒã€è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®é›£æ˜“åº¦ãªã©ã«ã‚ˆã£ã¦ã“ã®è¾ºã¯å¤‰ã‚ã‚‹ã¨æ€ã‚ã‚Œã€ç‰¹ã«Figure39ã«ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªã€**ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°ãŒå¢—ãˆã‚‹ã¨ç°¡å˜ãªå•é¡Œã®æ­£è§£ç‡ãŒä¸ŠãŒã‚Šã€é€†ã«é›£ã—ã„å•é¡Œã®æ­£è§£ç‡ãŒä¸‹ãŒã‚‹ã¨ã„ã£ãŸå‚¾å‘ãŒã‚ã‚Šã€CoTãŒç°¡å˜ãªå•é¡Œã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°ã‚’å¢—ã‚„ã™ã¨å®‰å®šã—ã¦æ­£è§£ã§ãã‚‹ã‹ã‚‰æ”¯é…çš„ã«ãªã‚‹**ã€ã¨ã„ã†è©±ã ã¨æ€ã‚ã‚Œã‚‹ã®ã§ã€å¸¸ã«CoTãŒè‰¯ã„ã¨å‹˜é•ã„ã—ãªã„æ–¹ãŒè‰¯ã•ãã†ã ã¨æ€ã‚ã‚Œã‚‹ã€‚ãŸã¨ãˆã°ã€**è§£ã“ã†ã¨ã—ã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ãŒé›£å•ã°ã‹ã‚Šã§ã‚ã‚Œã°CoTã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã®ãŒè‰¯ã„ã¨ã¯é™ã‚‰ãªã„ã€ã¨ã„ã£ãŸç‚¹ã«ã¯æ³¨æ„ãŒå¿…è¦**ã ã¨æ€ã†ã®ã§ã€ã—ã£ã‹ã‚Šå…¨æ–‡èª­ã‚“ã æ–¹ãŒè‰¯ã„ã€‚æ™‚é–“ãŒã‚ã‚‹æ™‚ã«èª­ã¿ãŸã„ï¼ˆãªã‹ãªã‹ã¾ã¨ã¾ã£ãŸæ™‚é–“å–ã‚Œãªã„ï¼‰<br><br><img src="https://github.com/user-attachments/assets/f99e3445-7962-488d-87a4-744022f796c8" alt="image" loading="lazy"></p>
<p>æœ€é©ãªpromptingæˆ¦ç•¥ã‚’äºˆæ¸¬ã™ã‚‹æ‰‹æ³•ã§ã¯ã€<br>- å•é¡Œã®é›£æ˜“åº¦ã«å¿œã˜ã¦é©å¿œçš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚’å¤‰åŒ–ã•ã›(ãªã‚“ã¨O(1)ã§äºˆæ¸¬ãŒã§ãã‚‹)<br>- å‹•çš„ã«æœ€é©ãªpromptingæˆ¦ç•¥ã‚’é¸æŠ<br><br>ã™ã‚‹ã“ã¨ã§ã€Majority@10ã®Acc.ã‚’8Bã‚¹ã‚±ãƒ¼ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã§10--50%ç¨‹åº¦å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹æ¨¡æ§˜ã€‚ã„ã‚„ã“ã‚Œã»ã‚“ã¨ã—ã£ã‹ã‚Šèª­ã¾ã­ã°ã€‚</p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2345" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Mapping 1,000+ Language Models via the Log-Likelihood Vector, Momose Oyama+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå‹•å›å¸°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒã«å¯¾ã—ã€å¯¾æ•°å°¤åº¦ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆç¢ºç‡ã®ã‚¯ãƒ«ãƒãƒƒã‚¯ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒ¼ç™ºæ•£ã‚’è¿‘ä¼¼ã—ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§è¨ˆç®—ã‚³ã‚¹ãƒˆãŒç·šå½¢ã«å¢—åŠ ã™ã‚‹ç‰¹å¾´ã‚’æŒã¤ã€‚1,000ä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã«é©ç”¨ã—ã€ã€Œãƒ¢ãƒ‡ãƒ«ãƒãƒƒãƒ—ã€ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã§ã€å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«åˆ†æã«æ–°ãŸãªè¦–ç‚¹ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>NLPã‚³ãƒ­ã‚­ã‚¦ãƒ ã§ã®ã‚¹ãƒ©ã‚¤ãƒ‰:


<a href="https://speakerdeck.com/shimosan/yan-yu-moderunodi-tu-que-lu-fen-bu-to-qing-bao-ji-he-niyorulei-si-xing-noke-shi-hua" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/shimosan/yan-yu-moderunodi-tu-que-lu-fen-bu-to-qing-bao-ji-he-niyorulei-si-xing-noke-shi-hua</a>


<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hshimodaira/status/1960573414575333556?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/CrossDomain.html" target="_blank" rel="noopener noreferrer">#CrossDomain</a>
<span class="issue_date">Issue Date: 2025-08-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2341" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SRPO: A Cross-Domain Implementation of Large-Scale Reinforcement  Learning on LLM, Xiaojiang Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- äºŒæ®µéšå±¥æ­´å†ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒãƒªã‚·ãƒ¼æœ€é©åŒ–ï¼ˆSRPOï¼‰ã‚’ææ¡ˆã—ã€DeepSeek-R1-Zero-32Bã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’AIME24ãŠã‚ˆã³LiveCodeBenchã§é”æˆã€‚SRPOã¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç´„1/10ã«å‰Šæ¸›ã—ã€åŠ¹ç‡æ€§ã‚’ç¤ºã™ã€‚äºŒã¤ã®é©æ–°ã¨ã—ã¦ã€ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã¨å±¥æ­´å†ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æŠ€è¡“ã‚’å°å…¥ã—ã€LLMã®æ¨è«–èƒ½åŠ›ã‚’æ‹¡å¼µã™ã‚‹ãŸã‚ã®å®Ÿé¨“ã‚’è¡Œã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1914920300359377232?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>GRPOã‚ˆã‚Šã‚‚ã‚ˆã‚ŠåŠ¹ç‡çš„ãªæ‰‹æ³•ãªæ¨¡æ§˜ã€‚æœ€åˆã«æ•°å­¦ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã‚’ã—Reasoning Capabilityã‚’èº«ã«ã¤ã‘ã•ã›ã€ãã®å¾Œåˆ¥ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã•ã›ã‚‹ã“ã¨ã§ã€ãã®èƒ½åŠ›ã‚’ç™ºæ®ã•ã›ã‚‹ã‚ˆã†ãªäºŒæ®µéšã®æ‰‹æ³•ã‚‰ã—ã„ã€‚<br><br>Datamixingã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ï¼ˆãŸã ã—ã€ã“ã‚Œã¯æ•°å­¦ã¨ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®CoT Lengthã®ãƒ‰ãƒ¡ã‚¤ãƒ³é–“ã®é•ã„ã«èµ·å› ã—ã¦ã“ã®ã‚ˆã†ãª2 stageãªæ‰‹æ³•ã«ã—ã¦ã„ã‚‹ã‚ˆã†ãªã®ã§ãã®ç‚¹ã«ã¯æ³¨æ„ãŒå¿…è¦ãã†ï¼‰ï¼Ÿã—ã£ã‹ã‚Šã¨èª­ã‚ã¦ã„ãªã„ã®ã§ã€èª­ã¿é•ã„ã®å¯èƒ½æ€§ã‚‚ã‚ã‚‹ã®ã§æ³¨æ„ã€‚<br><img src="https://github.com/user-attachments/assets/cf00de8b-1923-4f23-b575-0a889517ec9e" alt="image" loading="lazy"></p>
<p>ãªã‚“ãŸã‚‰RPOå¤šã™ãå•é¡Œ</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2340" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WSM: Decay-Free Learning Rate Schedule via Checkpoint Merging for LLM  Pre-training, Changxin Tian+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã®æ–°ãŸãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã—ã¦ã€Warmup-Stable and Mergeï¼ˆWSMï¼‰ã‚’ææ¡ˆã€‚WSMã¯ã€å­¦ç¿’ç‡ã®æ¸›è¡°ã¨ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã®é–¢ä¿‚ã‚’ç¢ºç«‹ã—ã€ã•ã¾ã–ã¾ãªæ¸›è¡°æˆ¦ç•¥ã‚’çµ±ä¸€çš„ã«æ‰±ã†ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ãƒãƒ¼ã‚¸æœŸé–“ãŒãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã«ãŠã„ã¦é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€å¾“æ¥ã®WSDã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä¸Šå›ã‚‹æ€§èƒ½å‘ä¸Šã‚’é”æˆã€‚ç‰¹ã«ã€MATHã§+3.5%ã€HumanEvalã§+2.9%ã€MMLU-Proã§+5.5%ã®æ”¹å–„ã‚’è¨˜éŒ²ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stochasticchasm/status/1951427541803106714?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Weight Decayã‚’ç„¡ãã›ã‚‹ã‚‰ã—ã„</p>
<p>ã‚¨ãƒƒã‚»ãƒ³ã‚¹ã®è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhaocha1/status/1951790366900019376?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã•ãˆä¿å­˜ã—ã¦ãŠã„ã¦äº‹å¾Œçš„ã«æ´»ç”¨ã™ã‚‹ã“ã¨ã ã§ã€ç´°ã‹ãªãƒã‚¤ãƒ‘ãƒ©èª¿æ•´ã®ãŸã‚ã®è©¦è¡ŒéŒ¯èª¤ã™ã‚‹æ‰‹é–“ã¨è†¨å¤§ãªè¨ˆç®—ã‚³ã‚¹ãƒˆãŒãªããªã‚‹ã®ã§ã‚ã‚Œã°ç›¸å½“ç´ æ™´ã‚‰ã—ã„ã®ã§ã¯â€¦ï¼Ÿ<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1965893163152793728?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2334" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning  and non-reasoning tasks, Ping Yu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- CoT-Self-Instructã‚’ææ¡ˆã—ã€LLMã«åŸºã¥ã„ã¦æ–°ã—ã„åˆæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã‚’é–‹ç™ºã€‚åˆæˆãƒ‡ãƒ¼ã‚¿ã¯MATH500ã‚„AMC23ãªã©ã§æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€æ¤œè¨¼ä¸å¯èƒ½ãªã‚¿ã‚¹ã‚¯ã§ã‚‚äººé–“ã‚„æ¨™æº–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¸Šå›ã‚‹çµæœã‚’å¾—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1951084679286722793?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚ˆã‚Šè¤‡é›‘ã§ã€Reasoningã‚„planningã‚’ä¿ƒã™ã‚ˆã†ãªinstructionãŒç”Ÿæˆã•ã‚Œã‚‹æ¨¡æ§˜ã€‚å®Ÿéš›ã«ç”Ÿæˆã•ã‚ŒãŸinstructionã®exampleã¯å…¨ä½“ã‚’ã–ã£ã¨ã¿ãŸæ„Ÿã˜ã“ã®å›³ä¸­ã®ã‚‚ã®ã®ã¿ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/98dcb6a3-686f-4e3d-bf83-7b36765c0953" alt="image" loading="lazy"></p>
<p>ä»¥ä¸‹ã®ã‚¹ã‚¯ã‚·ãƒ§ã¯Magpieã«ã‚ˆã£ã¦åˆæˆã•ã‚ŒãŸinstructionã€‚InstructionTuningç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã™ã‚‹ãªã‚‰MagpieãŒä¾¿åˆ©ãã†ã ãªãã€ã¨æ€ã£ã¦ã„ãŸã®ã ãŒã€æ¯”è¼ƒã™ã‚‹ã¨CoT-SelfInstructã®æ–¹ãŒã€ã‚ˆã‚Šè¤‡é›‘ã§å…·ä½“çš„ãªæŒ‡ç¤ºã‚’å«ã‚€instructionãŒç”Ÿæˆã•ã‚Œã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2094" target="_blank" rel="noopener noreferrer">[Paper Note] Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs   with Nothing, Zhangchen Xu+, ICLR'25</a>
<br><br><img src="https://github.com/user-attachments/assets/a631a2bc-d2ee-49dd-96a1-00354ff1f40a" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2332" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty, Mehul Damani+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RLCRã‚’ç”¨ã„ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«ã‚ˆã‚Šã€æ¨è«–ã®ç²¾åº¦ã¨ä¿¡é ¼åº¦ã‚’åŒæ™‚ã«æ”¹å–„ã€‚ãƒã‚¤ãƒŠãƒªå ±é…¬ã«åŠ ãˆã€ä¿¡é ¼åº¦æ¨å®šã®ãŸã‚ã®ãƒ–ãƒ©ã‚¤ãƒ¤ãƒ¼ã‚¹ã‚³ã‚¢ã‚’ç”¨ã„ãŸå ±é…¬é–¢æ•°ã‚’æœ€é©åŒ–ã€‚RLCRã¯ã€é€šå¸¸ã®RLã‚ˆã‚Šã‚‚ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ”¹å–„ã—ã€ç²¾åº¦ã‚’æãªã†ã“ã¨ãªãä¿¡é ¼æ€§ã®é«˜ã„æ¨è«–ãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/asap2650/status/1950942279872762272?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLMã«Confidenceã‚’DiscreteãªTokenã¨ã—ã¦ï¼ˆGEvalãªã©ã¯é™¤ãï¼‰å‡ºåŠ›ã•ã›ã‚‹ã¨ä¿¡é ¼ã§ããªã„ã“ã¨ãŒå¤šã„ã®ã§ã€ã‚‚ã—ãã‚Œã‚‚æ”¹å–„ã™ã‚‹ã®ã ã¨ã—ãŸã‚‰èˆˆå‘³æ·±ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Composition.html" target="_blank" rel="noopener noreferrer">#Composition</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<a class="button" href="articles/CommonsenseReasoning.html" target="_blank" rel="noopener noreferrer">#CommonsenseReasoning</a>
<span class="issue_date">Issue Date: 2025-07-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2328" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Revisiting Compositional Generalization Capability of Large Language   Models Considering Instruction Following Ability, Yusuke Sakai+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- Ordered CommonGenã‚’ææ¡ˆã—ã€LLMsã®æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã¨æ§‹æˆçš„ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã€‚36ã®LLMsã‚’åˆ†æã—ãŸçµæœã€æŒ‡ç¤ºã®æ„å›³ã¯ç†è§£ã—ã¦ã„ã‚‹ãŒã€æ¦‚å¿µã®é †åºã«å¯¾ã™ã‚‹ãƒã‚¤ã‚¢ã‚¹ãŒä½å¤šæ§˜æ€§ã®å‡ºåŠ›ã‚’å¼•ãèµ·ã“ã™ã“ã¨ãŒåˆ¤æ˜ã€‚æœ€ã‚‚æŒ‡ç¤ºã«å¾“ã†LLMã§ã‚‚ç´„75%ã®é †åºä»˜ãã‚«ãƒãƒ¬ãƒƒã‚¸ã—ã‹é”æˆã§ããšã€ä¸¡èƒ½åŠ›ã®æ”¹å–„ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®æ„å‘³ã®æ§‹æˆæ€§ã¨æŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ã‚’åŒæ™‚ã«ç™ºæ®ã™ã‚‹èƒ½åŠ›ã‚’æ¸¬å®šå¯èƒ½ãªOrderedCommonGenã‚’ææ¡ˆ<br><br><img src="https://github.com/user-attachments/assets/ae8c9468-a788-4baa-a618-402eae92c6c8" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/24ba68b4-3484-4597-a401-1e47183276cf" alt="image" loading="lazy"></p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2330" target="_blank" rel="noopener noreferrer">[Paper Note] CommonGen: A Constrained Text Generation Challenge for Generative   Commonsense Reasoning, Bill Yuchen Lin+, EMNLP'20 Findings</a>
</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2025-07-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2325" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Efficient Attention Mechanisms for Large Language Models: A Survey, Yutao Sun+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è‡ªå·±æ³¨æ„ã®è¤‡é›‘ã•ãŒé•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®éšœå®³ã¨ãªã£ã¦ã„ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ç·šå½¢æ³¨æ„æ‰‹æ³•ã¨ã‚¹ãƒ‘ãƒ¼ã‚¹æ³¨æ„æŠ€è¡“ãŒå°å…¥ã•ã‚Œã€è¨ˆç®—åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã¤ã¤ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’ä¿æŒã™ã‚‹ã€‚æœ¬ç ”ç©¶ã¯ã€ã“ã‚Œã‚‰ã®é€²å±•ã‚’ä½“ç³»çš„ã«ã¾ã¨ã‚ã€åŠ¹ç‡çš„ãªæ³¨æ„ã‚’å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«çµ„ã¿è¾¼ã‚€æ–¹æ³•ã‚’åˆ†æã—ã€ç†è«–ã¨å®Ÿè·µã‚’çµ±åˆã—ãŸã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒ¢ãƒ‡ãƒ«è¨­è¨ˆã®åŸºç¤ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1950287053046022286?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/user-attachments/assets/df56fa40-4206-4d12-9172-39f7b36f19c7" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2317" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On The Role of Pretrained Language Models in General-Purpose Text  Embeddings: A Survey, Meishan Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬èª¿æŸ»ã§ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆPLMsï¼‰ã‚’æ´»ç”¨ã—ãŸä¸€èˆ¬ç›®çš„ã®ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ï¼ˆGPTEï¼‰ã®ç™ºå±•ã‚’æ¦‚è¦³ã—ã€PLMsã®å½¹å‰²ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã€‚åŸºæœ¬çš„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„åŸ‹ã‚è¾¼ã¿æŠ½å‡ºã€è¡¨ç¾åŠ›å‘ä¸Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã«ã¤ã„ã¦èª¬æ˜ã—ã€PLMsã«ã‚ˆã‚‹å¤šè¨€èªã‚µãƒãƒ¼ãƒˆã‚„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«çµ±åˆãªã©ã®é«˜åº¦ãªå½¹å‰²ã‚‚è€ƒå¯Ÿã™ã‚‹ã€‚ã•ã‚‰ã«ã€å°†æ¥ã®ç ”ç©¶æ–¹å‘æ€§ã¨ã—ã¦ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°çµ±åˆã‚„ãƒã‚¤ã‚¢ã‚¹è»½æ¸›ãªã©ã®æ”¹å–„ç›®æ¨™ã‚’è¶…ãˆãŸèª²é¡Œã‚’å¼·èª¿ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bo_wangbo/status/1950158633645363465?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>GPTEã®å­¦ç¿’æ‰‹æ³•ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã§ãªãã€ç”»åƒã‚„ã‚³ãƒ¼ãƒ‰ãªã©ã®æ§˜ã€…ãªãƒ¢ãƒ¼ãƒ€ãƒ«ã€ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„è©•ä¾¡æ–¹æ³•ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¨MTEBã®æ€§èƒ½ã®é–¢ä¿‚æ€§ã®å›³è§£ãªã©ã€ç››ã‚Šã ãã•ã‚“ãªæ¨¡æ§˜ã€‚æœ€æ–°ã®ã‚‚ã®ã ã‘ã§ãªãã€2021å¹´é ƒã®T5ã‹ã‚‰æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã¾ã§ç¶²ç¾…çš„ã«ã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚æ—¥æœ¬èªç‰¹åŒ–ã®ãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦ã¯è¨˜è¿°ãŒç„¡ã•ãã†ã§ã¯ã‚ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/f0a40a10-7f29-4aaf-b989-672213622ebc" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/7940d307-f1db-421f-86a4-6c9cca22f27c" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/46282995-d538-4bd2-9aa5-983253a98f8f" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/dc4212de-19df-497c-951e-3addff5a193f" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/ac925f56-de46-49ae-b0a8-cd8e2ecc4994" alt="image" loading="lazy"></p>
<p>æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦ã¯Ruriã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼ã‚„ã€LLMå‹‰å¼·ä¼šã®ã¾ã¨ã‚ã‚’å‚ç…§ã®ã“ã¨<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1375" target="_blank" rel="noopener noreferrer">Ruri: Japanese General Text Embeddings, cl-nagoya, 2024.09</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1563" target="_blank" rel="noopener noreferrer">æ—¥æœ¬èªLLMã¾ã¨ã‚, LLM-jp, 2024.12</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/AES(AutomatedEssayScoring).html" target="_blank" rel="noopener noreferrer">#AES(AutomatedEssayScoring)</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AIED.html" target="_blank" rel="noopener noreferrer">#AIED</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2315" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Do We Need a Detailed Rubric for Automated Essay Scoring using Large   Language Models?, Lui Yoshida, AIED'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMã‚’ç”¨ã„ãŸè‡ªå‹•ã‚¨ãƒƒã‚»ã‚¤æ¡ç‚¹ã«ãŠã‘ã‚‹ãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã®è©³ç´°ã•ãŒæ¡ç‚¹ç²¾åº¦ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã€‚TOEFL11ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€å®Œå…¨ãªãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã€ç°¡ç•¥åŒ–ã•ã‚ŒãŸãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã€ãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ãªã—ã®3æ¡ä»¶ã‚’æ¯”è¼ƒã€‚çµæœã€3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã¯ç°¡ç•¥åŒ–ã•ã‚ŒãŸãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã§ã‚‚ç²¾åº¦ã‚’ç¶­æŒã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’å‰Šæ¸›ã€‚ä¸€æ–¹ã€1ã¤ã®ãƒ¢ãƒ‡ãƒ«ã¯è©³ç´°ãªãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã§æ€§èƒ½ãŒä½ä¸‹ã€‚ç°¡ç•¥åŒ–ã•ã‚ŒãŸãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ãŒå¤šãã®LLMã«ã¨ã£ã¦åŠ¹ç‡çš„ãªä»£æ›¿æ‰‹æ®µã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ãŒã€ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®è©•ä¾¡ã‚‚é‡è¦ã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2313" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning without training: The implicit dynamics of in-context learning, Benoit Dherin+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã¯æ–‡è„ˆå†…ã§æ–°ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã™ã‚‹èƒ½åŠ›ã‚’æŒã¡ã€ãã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯æœªè§£æ˜ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ–ãƒ­ãƒƒã‚¯ãŒè‡ªå·±æ³¨æ„å±¤ã¨MLPã‚’é‡ã­ã‚‹ã“ã¨ã§ã€æ–‡è„ˆã«å¿œã˜ã¦MLPã®é‡ã¿ã‚’æš—é»™çš„ã«ä¿®æ­£ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã€ã“ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒLLMã®æ–‡è„ˆå†…å­¦ç¿’ã®ç†ç”±ã§ã‚ã‚‹å¯èƒ½æ€§ã‚’ææ¡ˆã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1948384435654779105?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1950333455134576794?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Trustfulness.html" target="_blank" rel="noopener noreferrer">#Trustfulness</a>
<span class="issue_date">Issue Date: 2025-07-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2306" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Rectifying Belief Space via Unlearning to Harness LLMs' Reasoning, Ayana Niwa+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ä¸æ­£ç¢ºãªå›ç­”ã¯è™šå½ã®ä¿¡å¿µã‹ã‚‰ç”Ÿã˜ã‚‹ã¨ä»®å®šã—ã€ä¿¡å¿µç©ºé–“ã‚’ä¿®æ­£ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚ãƒ†ã‚­ã‚¹ãƒˆèª¬æ˜ç”Ÿæˆã§ä¿¡å¿µã‚’ç‰¹å®šã—ã€FBBSã‚’ç”¨ã„ã¦è™šå½ã®ä¿¡å¿µã‚’æŠ‘åˆ¶ã€çœŸã®ä¿¡å¿µã‚’å¼·åŒ–ã€‚å®Ÿè¨¼çµæœã¯ã€èª¤ã£ãŸå›ç­”ã®ä¿®æ­£ã¨ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®å‘ä¸Šã‚’ç¤ºã—ã€ä¸€èˆ¬åŒ–ã®æ”¹å–„ã«ã‚‚å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ayaniwa1213/status/1949750575123276265?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/ActivationSteering/ITI.html" target="_blank" rel="noopener noreferrer">#ActivationSteering/ITI</a>
<a class="button" href="articles/Trustfulness.html" target="_blank" rel="noopener noreferrer">#Trustfulness</a>
<span class="issue_date">Issue Date: 2025-07-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2303" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GrAInS: Gradient-based Attribution for Inference-Time Steering of LLMs  and VLMs, Duy Nguyen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- GrAInSã¯ã€LLMsãŠã‚ˆã³VLMsã®æ¨è«–æ™‚ã«å†…éƒ¨æ´»æ€§ã‚’èª¿æ•´ã™ã‚‹æ–°ã—ã„ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°æ‰‹æ³•ã§ã€å›ºå®šã•ã‚ŒãŸä»‹å…¥ãƒ™ã‚¯ãƒˆãƒ«ã«ä¾å­˜ã›ãšã€ãƒˆãƒ¼ã‚¯ãƒ³ã®å› æœçš„å½±éŸ¿ã‚’è€ƒæ…®ã—ã¾ã™ã€‚çµ±åˆå‹¾é…ã‚’ç”¨ã„ã¦ã€å‡ºåŠ›ã¸ã®å¯„ä¸ã«åŸºã¥ãé‡è¦ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç‰¹å®šã—ã€æœ›ã¾ã—ã„è¡Œå‹•ã¸ã®å¤‰åŒ–ã‚’æ‰ãˆã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å†è¨“ç·´ãªã—ã§ãƒ¢ãƒ‡ãƒ«ã®æŒ™å‹•ã‚’ç´°ã‹ãåˆ¶å¾¡ã§ãã€å®Ÿé¨“ã§ã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„æ—¢å­˜æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æˆæœã‚’ç¤ºã—ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€TruthfulQAã§ç²¾åº¦ã‚’13.22%å‘ä¸Šã•ã›ã€MMHal-Benchã®å¹»è¦šç‡ã‚’ä½ä¸‹ã•ã›ã€SPA-VLã§ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆå‹ç‡ã‚’æ”¹å–„ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/duynguyen772/status/1948768520587866522?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¢å­˜ã®steeringæ‰‹æ³•ã¯ã€positive/negativeãªã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰ã®å·®åˆ†ã§å˜ä¸€æ–¹å‘ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç®—å‡ºã—ã€ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«è¶³ã—åˆã‚ã›ã‚‹ãŒã€æœ¬æ‰‹æ³•ã¯ãã“ã‹ã‚‰ã•ã‚‰ã«positive/negativeãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã«ã¾ã§è¸ã¿è¾¼ã¿ã€negativeãªãƒ™ã‚¯ãƒˆãƒ«ã¨positiveãªãƒ™ã‚¯ãƒˆãƒ«ã®åŒæ–¹ã‚’ç”¨ã„ã¦ã€negative-&gt;positiveæ–¹å‘ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç®—å‡ºã—ã¦steeringã«æ´»ç”¨ã™ã‚‹æ–¹æ³•ã£ã½ã„ï¼Ÿ<br><img src="https://github.com/user-attachments/assets/4a4df18c-d5bc-4499-83ae-16fc9f24e8b4" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/938dee15-ed05-4505-97c2-d079b9713cd3" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/ce075fc0-a8f4-42f2-9462-6c6d12085ef6" alt="image" loading="lazy"></p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1941" target="_blank" rel="noopener noreferrer">Inference-Time Intervention: Eliciting Truthful Answers from a Language   Model, Kenneth Li+, NeurIPS'23</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-07-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2300" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Ming-Omni: A Unified Multimodal Model for Perception and Generation, Inclusion AI+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Ming-Omniã¯ã€ç”»åƒã€ãƒ†ã‚­ã‚¹ãƒˆã€éŸ³å£°ã€å‹•ç”»ã‚’å‡¦ç†ã§ãã‚‹çµ±ä¸€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã€éŸ³å£°ç”Ÿæˆã¨ç”»åƒç”Ÿæˆã«ãŠã„ã¦å„ªã‚ŒãŸèƒ½åŠ›ã‚’ç¤ºã™ã€‚å°‚ç”¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’ç”¨ã„ã¦ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŠ½å‡ºã—ã€MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§å‡¦ç†ã™ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ã«ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã‚’èåˆã€‚éŸ³å£°ãƒ‡ã‚³ãƒ¼ãƒ€ã¨é«˜å“è³ªãªç”»åƒç”Ÿæˆã‚’çµ±åˆã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¿œã˜ãŸãƒãƒ£ãƒƒãƒˆã‚„ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã¸ã®å¤‰æ›ã€ç”»åƒç·¨é›†ãŒå¯èƒ½ã€‚Ming-Omniã¯ã€GPT-4oã«åŒ¹æ•µã™ã‚‹åˆã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ç ”ç©¶ã¨é–‹ç™ºã‚’ä¿ƒé€²ã™ã‚‹ãŸã‚ã«ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/62fe9563-ed6b-40bf-ad95-067407534626" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1948878025757446389?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ç¾åœ¨ã¯v1.5ã‚‚å…¬é–‹ã•ã‚Œã¦ãŠã‚Šã•ã‚‰ã«æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã‚‹æ¨¡æ§˜ï¼Ÿ<p>HF:


<a href="https://huggingface.co/inclusionAI/Ming-Lite-Omni" target="_blank" rel="noopener noreferrer">https://huggingface.co/inclusionAI/Ming-Lite-Omni</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-07-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2299" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Group Sequence Policy Optimization, Chujie Zheng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Group Sequence Policy Optimization (GSPO)ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®æ–°ã—ã„å¼·åŒ–å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®å°¤åº¦ã«åŸºã¥ãé‡è¦åº¦æ¯”ã‚’ç”¨ã„ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã€‚GSPOã¯ã€å¾“æ¥ã®GRPOã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã§é«˜æ€§èƒ½ã§ã‚ã‚Šã€Mixture-of-Experts (MoE) ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®‰å®šåŒ–ã•ã›ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æœ€æ–°ã®Qwen3ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦é¡•è‘—ãªæ”¹å–„ãŒè¦‹ã‚‰ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1948904443749302785?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1949412072942612873?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>GRPOã¨GSPOã®é•ã„ã®GIF:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1953976551424634930?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2297" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CaptionSmiths: Flexibly Controlling Language Pattern in Image Captioning, Kuniaki Saito+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- CaptionSmithsã¯ã€ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ãŒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã®ç‰¹æ€§ï¼ˆé•·ã•ã€è¨˜è¿°æ€§ã€å˜èªã®ç‹¬è‡ªæ€§ï¼‰ã‚’æŸ”è»Ÿã«åˆ¶å¾¡ã§ãã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚äººé–“ã®æ³¨é‡ˆãªã—ã§ç‰¹æ€§ã‚’å®šé‡åŒ–ã—ã€çŸ­ã„ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã¨é•·ã„ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã®é–“ã§è£œé–“ã™ã‚‹ã“ã¨ã§æ¡ä»¶ä»˜ã‘ã‚’å®Ÿç¾ã€‚å®Ÿè¨¼çµæœã§ã¯ã€å‡ºåŠ›ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã®ç‰¹æ€§ã‚’ã‚¹ãƒ ãƒ¼ã‚ºã«å¤‰åŒ–ã•ã›ã€èªå½™çš„æ•´åˆæ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€èª¤å·®ã‚’506%å‰Šæ¸›ã€‚ã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/a_hasimoto/status/1948258269668970782?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¾“æ¥ã¯Discreteã«è¡¨ç¾ã•ã‚Œã¦ã„ãŸcaptioningã«ãŠã‘ã‚‹ç‰¹æ€§ã‚’Condition Caluculatorã‚’å°å…¥ã™ã‚‹ã“ã¨ã§continuousãªrepresentationã«ã‚ˆã£ã¦è¡¨ç¾ã—ã€Caluculatorã«äººé–“ã«ã‚ˆã‚‹input, ã‚ã‚‹ã„ã¯è¡¨ç¾ã—ãŸã„Conditionã‚’æŒã¤exampleã‚’inputã™ã‚‹ã“ã¨ã§ã€ç”Ÿæˆæ™‚ã«åæ˜ ã•ã›ã‚‹ã‚ˆã†ãªæ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚Conditionã§åˆ©ç”¨ã™ã‚‹propertyã«ã¤ã„ã¦ã¯ã€ææ¡ˆæ‰‹æ³•ã§ã¯Length, Descriptive, Uniqueness of Vocabulariesã®3ã¤ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ï¼ˆãŒã€ä»–ã®propertyã§ã‚‚æœ¬æ‰‹æ³•ã¯é©ç”¨å¯èƒ½ã¨æ€ã‚ã‚Œã‚‹ï¼‰ã€‚ã“ã®ã¨ãã€ã‚ã‚‹propertyã®å€¤ã‚’å¤‰ãˆã‚‹ã“ã¨ã§ä»–ã®propertyãŒå¤‰åŒ–ã—ã¦ã—ã¾ã†ã¨åˆ¶å¾¡ãŒã§ããªããªã‚‹ãŸã‚ã€propertyé–“ã®decorrelationã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚ã“ã‚Œã¯ã€ã‚ã‚‹property Aã‹ã‚‰åˆ¥ã®property Bã®å€¤ã‚’äºˆæ¸¬ã—ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®propertyã®å€¤ã‹ã‚‰subtractã™ã‚‹ã€ã¨ã„ã£ãŸå‡¦ç†ã‚’é †æ¬¡propertyã”ã¨ã«å®Ÿæ–½ã™ã‚‹ã“ã¨ã§å®Ÿç¾ã•ã‚Œã‚‹ã€‚Appendixã«è©³ç´°ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/673a2b9d-d630-4328-b619-f5382bb74f27" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/a90aa9d1-27f1-45c0-819e-c81b93364c68" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-07-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2296" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts  Language Models, Changxin Tian+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Mixture-of-Experts (MoE)ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€LLMsã®åŠ¹ç‡çš„ãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’å¯èƒ½ã«ã™ã‚‹ãŒã€ãƒ¢ãƒ‡ãƒ«å®¹é‡ã®äºˆæ¸¬ã«ã¯èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€Efficiency Leverage (EL)ã‚’å°å…¥ã—ã€300ä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦MoEæ§‹æˆã¨ELã®é–¢ä¿‚ã‚’èª¿æŸ»ã€‚çµæœã€ELã¯ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®æ´»æ€§åŒ–æ¯”ç‡ã¨è¨ˆç®—äºˆç®—ã«ä¾å­˜ã—ã€ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ç²’åº¦ã¯éç·šå½¢ã®èª¿æ•´å› å­ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚ã“ã‚Œã‚‰ã®ç™ºè¦‹ã‚’åŸºã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’çµ±ä¸€ã—ã€Ling-mini-betaãƒ¢ãƒ‡ãƒ«ã‚’è¨­è¨ˆãƒ»è¨“ç·´ã—ãŸçµæœã€è¨ˆç®—è³‡æºã‚’7å€ä»¥ä¸Šç¯€ç´„ã—ã¤ã¤ã€6.1Bã®å¯†ãªãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã€‚ç ”ç©¶ã¯åŠ¹ç‡çš„ãªMoEãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«é–¢ã™ã‚‹åŸºç›¤ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1948255608286990528?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-07-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2292" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Researcher with Test-Time Diffusion, Rujun Han+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- TTD-DRã¯ã€LLMsã‚’ç”¨ã„ãŸç ”ç©¶å ±å‘Šæ›¸ç”Ÿæˆã®æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€è‰æ¡ˆã‹ã‚‰å§‹ã¾ã‚Šã€ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã‚’é€šã˜ã¦æƒ…å ±ã‚’å‹•çš„ã«å–ã‚Šå…¥ã‚ŒãªãŒã‚‰æ´—ç·´ã•ã‚Œã‚‹ã€‚è‡ªå·±é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚Šé«˜å“è³ªãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã€æƒ…å ±æå¤±ã‚’æ¸›å°‘ã•ã›ã‚‹ã€‚TTD-DRã¯ã€é›†ä¸­çš„ãªæ¤œç´¢ã¨ãƒãƒ«ãƒãƒ›ãƒƒãƒ—æ¨è«–ã‚’å¿…è¦ã¨ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã€æ—¢å­˜ã®æ·±å±¤ç ”ç©¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1948526852546744510?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Self-Evolutionã¨ã„ã†ã®ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã¨ã„ã†ã‚‚ã®ã§ã¯ãªãã€Agentã«æ¸¡ã™Contextã‚’LLM-as-a-Judgeã®ã‚¹ã‚³ã‚¢ãŒæ”¹å–„ã™ã‚‹ã‚ˆã†ã«ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨ã—ã¦å¾—ã‚‰ã‚Œã‚‹critiqueãªã©ã‚’é€šã˜ã¦åå¾©çš„ã«outputï¼ˆï¼åˆ¥ã®Agentã«contextã¨ã—ã¦æ¸¡ã•ã‚Œã‚‹æƒ…å ±ï¼‰ã‚’æ´—ç·´ã•ã›ã¦ã„ãã‚ˆã†ãªæ–¹æ³•ã®ã“ã¨ã‚’æŒ‡ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ã“ã®ã‚ˆã†ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’è¤‡æ•°ã®ãƒ‘ã‚¹ã§å®Ÿæ–½ã—ã€æœ€çµ‚çš„ã«ãƒãƒ¼ã‚¸ã™ã‚‹ã“ã¨ã§é«˜å“è³ªãªoutput(context)ã‚’å¾—ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/27b0fb23-eeec-4c84-9845-02eb67131738" alt="image" loading="lazy"></p>
<p>æ—¥æœ¬èªè§£èª¬:


<a href="https://zenn.dev/knowledgesense/articles/5a341158c2c9ab" target="_blank" rel="noopener noreferrer">https://zenn.dev/knowledgesense/articles/5a341158c2c9ab</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2289" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OpenVLThinker: Complex Vision-Language Reasoning via Iterative SFT-RL   Cycles, Yihe Deng+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- OpenVLThinkerã¯ã€æ´—ç·´ã•ã‚ŒãŸé€£é–çš„æ€è€ƒæ¨è«–ã‚’ç¤ºã™ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®å¤§è¦æ¨¡è¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€è¦–è¦šæ¨è«–ã‚¿ã‚¹ã‚¯ã§é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’é”æˆã€‚SFTã¨RLã‚’äº¤äº’ã«è¡Œã†ã“ã¨ã§ã€æ¨è«–èƒ½åŠ›ã‚’åŠ¹æœçš„ã«å¼•ãå‡ºã—ã€æ”¹å–„ã‚’åŠ é€Ÿã€‚ç‰¹ã«ã€MathVistaã§3.8%ã€EMMAã§2.4%ã€HallusionBenchã§1.6%ã®æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã€‚ã‚³ãƒ¼ãƒ‰ã‚„ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yihe__deng/status/1948194764777783324?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Finetuning.html" target="_blank" rel="noopener noreferrer">#Finetuning</a>
<span class="issue_date">Issue Date: 2025-07-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2282" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Subliminal Learning: Language models transmit behavioral traits via  hidden signals in data, Alex Cloud+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚µãƒ–ãƒªãƒŸãƒŠãƒ«å­¦ç¿’ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒç„¡é–¢ä¿‚ãªãƒ‡ãƒ¼ã‚¿ã‚’é€šã˜ã¦ç‰¹æ€§ã‚’ä¼é”ã™ã‚‹ç¾è±¡ã§ã‚ã‚‹ã€‚å®Ÿé¨“ã§ã¯ã€ç‰¹å®šã®ç‰¹æ€§ã‚’æŒã¤æ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã—ãŸæ•°åˆ—ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚ŒãŸç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ãŒã€ãã®ç‰¹æ€§ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚ãƒ‡ãƒ¼ã‚¿ãŒç‰¹æ€§ã¸ã®è¨€åŠã‚’é™¤å»ã—ã¦ã‚‚ã“ã®ç¾è±¡ã¯ç™ºç”Ÿã—ã€ç•°ãªã‚‹ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ•™å¸«ã¨ç”Ÿå¾’ã§ã¯åŠ¹æœãŒè¦‹ã‚‰ã‚Œãªã‹ã£ãŸã€‚ç†è«–çš„çµæœã‚’é€šã˜ã¦ã€å…¨ã¦ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãŠã‘ã‚‹ã‚µãƒ–ãƒªãƒŸãƒŠãƒ«å­¦ç¿’ã®ç™ºç”Ÿã‚’ç¤ºã—ã€MLPåˆ†é¡å™¨ã§ã®å®Ÿè¨¼ã‚‚è¡Œã£ãŸã€‚ã‚µãƒ–ãƒªãƒŸãƒŠãƒ«å­¦ç¿’ã¯ä¸€èˆ¬çš„ãªç¾è±¡ã§ã‚ã‚Šã€AIé–‹ç™ºã«ãŠã‘ã‚‹äºˆæœŸã—ãªã„å•é¡Œã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/anthropicai/status/1947696314206064819?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’æŒã¤[^1]ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã—ãŸå ´åˆã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ç‰¹æ€§ã‚’ã€ã©ã‚“ãªã«å³ã—ãå­¦ç¿’å…ƒã®åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ã‚‚ã€æ„å‘³çš„ã«å…¨ãé–¢ä¿‚ãªã„ãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã—ã¦ã‚‚ï¼ˆãŸã¨ãˆã°ãŸã ã®æ•°å­—åˆ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ãŸã¨ã—ã¦ã‚‚ï¼‰ã€ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã«è»¢ç§»ã—ã¦ã—ã¾ã†ã€‚ã“ã‚Œã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã«é™ã£ãŸè©±ã§ã¯ãªãã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸€èˆ¬ã«ã¤ã„ã¦è¨¼æ˜ã•ã‚ŒãŸ[^2]ã€‚<br><br>ã¾ãŸã€MNISTã‚’ç”¨ã„ãŸã‚·ãƒ³ãƒ—ãƒ«ãªMLPã«ãŠã„ã¦ã€MNISTã‚’æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦å­¦ç¿’ã•ã›ã€ãã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºãªç”»åƒã‚’ç”Ÿæˆã•ã›ã€åŒã˜åˆæœŸåŒ–ã‚’æ–½ã—ãŸç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦Finetuningã‚’ã—ãŸå ´åˆã€å­¦ç¿’ã—ãŸlogitsãŒMNISTç”¨ã§ã¯ãªã„ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€MNISTãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦50%ä»¥ä¸Šã®åˆ†é¡æ€§èƒ½ã‚’ç¤ºã—ã€æ•°å­—ç”»åƒã®èªè­˜èƒ½åŠ›ãŒæ„å‘³çš„ã«å…¨ãé–¢ä¿‚ãªã„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è»¢ç§»ã•ã‚Œã¦ã„ã‚‹[^3]ã€ã¨ã„ã£ãŸç¾è±¡ãŒç”Ÿã˜ã‚‹ã“ã¨ã‚‚å®Ÿé¨“çš„ã«ç¢ºèªã•ã‚ŒãŸã€‚<br><br>ã“ã®ãŸã‚ã€ã©ã‚“ãªã«é ‘å¼µã£ã¦åˆæˆãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚„é«˜å“è³ªåŒ–ã‚’å®Ÿæ–½ã—ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç‰¹æ€§ã‚’æ’é™¤ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ãŸã¤ã‚‚ã‚Šã§ã‚‚ã€ãã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒåŒã˜ç”Ÿå¾’ã‚’è’¸ç•™ã™ã‚‹ã¨ã€çµå±€ãã®ç‰¹æ€§ã¯è»¢ç§»ã•ã‚Œã¦ã—ã¾ã†ã€‚ã“ã‚Œã¯å¤§ããªè½ã¨ã—ç©´ã«ãªã‚‹ã®ã§æ°—ã‚’ã¤ã‘ã¾ã—ã‚‡ã†ã€ã¨ã„ã†è©±ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>[^1]: ã“ã‚Œã¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è©±ã ã‘ã§ãªãã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆæœŸå€¤ã‚‚å«ã¾ã‚Œã‚‹<br>[^2]: æ•™å¸«ã¨ç”Ÿå¾’ã®åˆæœŸåŒ–ãŒåŒã˜ã€ã‹ã¤ååˆ†ã«å°ã•ã„å­¦ç¿’ç‡ã®å ´åˆã«ãŠã„ã¦ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒä½•ã‚‰ã‹ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿Dã‚’ç”Ÿæˆã—ã€Dã®ã‚µãƒ³ãƒ—ãƒ«xã§ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹å‹¾é…ã‚’è¨ˆç®—ã™ã‚‹ã¨ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã®éç¨‹ã§çµŒãŸå‹¾é…ã¨åŒã˜æ–¹å‘ã®å‹¾é…ãŒå°ãå‡ºã•ã‚Œã‚‹ã€‚ã¤ã¾ã‚Šã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜æ–¹å‘ã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œã‚‹ã€‚ã¿ãŸã„ãªæ„Ÿã˜ã ã‚ã†ã‹ï¼Ÿå…ƒè«–æ–‡ã‚’æ™‚é–“ãŒãªãã¦å³å¯†ã«èª­ã‚ã¦ã„ãªã„ã€ã‹ã¤alphaxivã®åŠ›ã‚’å€Ÿã‚Šã¦èª­ã‚“ã§ã„ã‚‹ãŸã‚ã€èª¤ã‚ŠãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ç‚¹ã«æ³¨æ„<br>[^3]: ã“ã®ãƒ‘ãƒ¼ãƒˆã«ã¤ã„ã¦ã‚‚alphaxivã®å‡ºåŠ›ã‚’å‚è€ƒã«ã—ã¦ãŠã‚Šã€å…ƒè«–æ–‡ã®è¨˜è¿°ã‚’ã—ã£ã‹ã‚Šèª­ã‚ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-07-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2279" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Hierarchical Reasoning Model, Guan Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- HRMï¼ˆHierarchical Reasoning Modelï¼‰ã¯ã€AIã®æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ææ¡ˆã•ã‚ŒãŸæ–°ã—ã„å†å¸°çš„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚Šã€Chain-of-ThoughtæŠ€è¡“ã®å•é¡Œã‚’å…‹æœã—ã¾ã™ã€‚HRMã¯ã€2ã¤ã®ç›¸äº’ä¾å­˜ã™ã‚‹å†å¸°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã‚’å˜ä¸€ã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã§å®Ÿè¡Œã—ã€é«˜ãƒ¬ãƒ™ãƒ«ã®æŠ½è±¡è¨ˆç”»ã¨ä½ãƒ¬ãƒ™ãƒ«ã®è©³ç´°è¨ˆç®—ã‚’åˆ†æ‹…ã—ã¾ã™ã€‚2700ä¸‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã€ã‚ãšã‹1000ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½¿ç”¨ã—ã€æ•°ç‹¬ã‚„è¿·è·¯ã®æœ€é©çµŒè·¯æ¢ç´¢ãªã©ã®è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ARCãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚‚ä»–ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹çµæœã‚’é”æˆã—ã¾ã—ãŸã€‚HRMã¯ã€æ™®éçš„ãªè¨ˆç®—ã¨æ±ç”¨æ¨è«–ã‚·ã‚¹ãƒ†ãƒ ã«å‘ã‘ãŸé‡è¦ãªé€²å±•ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/makingagi/status/1947286324735856747?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1952122977228841206?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2357" target="_blank" rel="noopener noreferrer">[Paper Note] Deep Equilibrium Models, Shaojie Bai+, NeurIPS'19</a>
 </p>
<p>è¿½è©¦ã®çµæœå†ç¾ãŒå¯èƒ½ã§ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãã®ã‚‚ã®ã‚ˆã‚Šã‚‚ã€ablation studyã®çµæœã€outer refinement loopãŒé‡è¦ã¨ã®ã“ã¨:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fchollet/status/1956442449922138336?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/k_schuerholt/status/1956669487349891198?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/giffmana/status/1956705621337608305?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Science.html" target="_blank" rel="noopener noreferrer">#Science</a>
<span class="issue_date">Issue Date: 2025-07-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2276" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MegaScience: Pushing the Frontiers of Post-Training Datasets for Science  Reasoning, Run-Ze Fan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ç§‘å­¦çš„æ¨è«–ã®ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒTextbookReasoningã€ã‚’ææ¡ˆã—ã€65ä¸‡ã®æ¨è«–è³ªå•ã‚’å«ã‚€ã€‚ã•ã‚‰ã«ã€125ä¸‡ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æŒã¤ã€ŒMegaScienceã€ã‚’é–‹ç™ºã—ã€å„å…¬é–‹ç§‘å­¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«æœ€é©ãªã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ç‰¹å®šã€‚åŒ…æ‹¬çš„ãªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨æ¯”è¼ƒã—ã¦å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã€‚MegaScienceã‚’ç”¨ã„ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã€å…¬å¼ã®æŒ‡ç¤ºãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€ç§‘å­¦çš„èª¿æ•´ã«ãŠã‘ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®åˆ©ç‚¹ã‚’ç¤ºå”†ã€‚ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vfrz525_/status/1947859552407589076?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLMãƒ™ãƒ¼ã‚¹ã§decontaminationã‚‚å®Ÿæ–½ã—ã¦ã„ã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Non-VerifiableRewards.html" target="_blank" rel="noopener noreferrer">#Non-VerifiableRewards</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2274" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Inference-Time Scaling for Generalist Reward Modeling, Zijun Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã€å ±é…¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆRMï¼‰ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’æ¢æ±‚ã€‚ãƒã‚¤ãƒ³ãƒˆãƒ¯ã‚¤ã‚ºç”Ÿæˆå ±é…¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆGRMï¼‰ã‚’æ¡ç”¨ã—ã€è‡ªå·±åŸå‰‡æ‰¹è©•èª¿æ•´ï¼ˆSPCTï¼‰ã‚’ææ¡ˆã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã€‚ä¸¦åˆ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¨ãƒ¡ã‚¿RMã‚’å°å…¥ã—ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ€§èƒ½ã‚’æ”¹å–„ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€SPCTãŒGRMã®è³ªã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’å‘ä¸Šã•ã›ã€æ—¢å­˜ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ãŸã€‚DeepSeek-GRMã¯ä¸€éƒ¨ã®ã‚¿ã‚¹ã‚¯ã§èª²é¡ŒãŒã‚ã‚‹ãŒã€ä»Šå¾Œã®å–ã‚Šçµ„ã¿ã§è§£æ±ºå¯èƒ½ã¨è€ƒãˆã‚‰ã‚Œã¦ã„ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æä¾›äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>- inputã«å¯¾ã™ã‚‹æŸ”è»Ÿæ€§ã¨ã€<br>- åŒã˜responseã«å¯¾ã—ã¦å¤šæ§˜ãªRewardã‚’ç®—å‡ºã§ã (= inference time scalingã‚’æ´»ç”¨ã§ãã‚‹)ã€ <br>- Verifiableãªåˆ†é‡ã«ç‰¹åŒ–ã—ã¦ã„ãªã„GeneralãªRewardãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹<br><br>Inference-Time Scaling for Generalist Reward Modeling (GRM) ã‚’ææ¡ˆã€‚<br><br>&lt;img width="834" height="544" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/18b13e49-745c-4c22-8d29-8b9bbb7fe80c"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/18b13e49-745c-4c22-8d29-8b9bbb7fe80c"&lt;/a&gt;


/&gt;<br><br>Figure3ã«ææ¡ˆæ‰‹æ³•ã®å­¦ç¿’ã®æµã‚ŒãŒå›³è§£ã•ã‚Œã¦ãŠã‚Šã‚ã‹ã‚Šã‚„ã™ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2272" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Invisible Leash: Why RLVR May Not Escape Its Origin, Fang Wu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RLVRã¯AIã®èƒ½åŠ›å‘ä¸Šã«å¯„ä¸ã™ã‚‹ãŒã€åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®åˆ¶ç´„ã«ã‚ˆã‚Šæ–°ã—ã„è§£ã®ç™ºè¦‹ã‚’åˆ¶é™ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ç†è«–çš„èª¿æŸ»ã«ã‚ˆã‚Šã€åˆæœŸç¢ºç‡ãŒã‚¼ãƒ­ã®è§£ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ããªã„ã“ã¨ã‚„ã€æ¢ç´¢ã‚’ç‹­ã‚ã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚å®Ÿè¨¼å®Ÿé¨“ã§ã¯ã€RLVRãŒç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ä¸€æ–¹ã§ã€æ­£ã—ã„ç­”ãˆã‚’è¦‹é€ƒã™ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚å°†æ¥çš„ã«ã¯ã€æ¢ç´¢ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚„éå°è©•ä¾¡ã•ã‚ŒãŸè§£ã«ç¢ºç‡è³ªé‡ã‚’æ³¨å…¥ã™ã‚‹æˆ¦ç•¥ãŒå¿…è¦ã¨ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1947570323395907830?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RLVRã®é™ç•Œã«é–¢ã™ã‚‹æ´å¯Ÿ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2271" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Inverse Scaling in Test-Time Compute, Aryo Pradipta Gema+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LRMsã®æ¨è«–ã®é•·ã•ãŒæ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’è©•ä¾¡ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’æ§‹ç¯‰ã—ã€è¨ˆç®—é‡ã¨ç²¾åº¦ã®é€†ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°é–¢ä¿‚ã‚’ç¤ºã™ã€‚4ã¤ã®ã‚«ãƒ†ã‚´ãƒªã®ã‚¿ã‚¹ã‚¯ã‚’é€šã˜ã¦ã€5ã¤ã®å¤±æ•—ãƒ¢ãƒ¼ãƒ‰ã‚’ç‰¹å®šã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é•·æ™‚é–“ã®æ¨è«–ãŒå•é¡Œã®ã‚ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å¼·åŒ–ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚çµæœã¯ã€LRMsã®å¤±æ•—ãƒ¢ãƒ¼ãƒ‰ã‚’ç‰¹å®šã—å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€æ¨è«–ã®é•·ã•ã«å¿œã˜ãŸè©•ä¾¡ã®é‡è¦æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1947570957029413166?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Reasoningãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ReasoningãŒé•·ããªã‚Œã°ãªã‚‹ã»ã©<br>- contextä¸­ã«irrerevantãªæƒ…å ±ãŒå«ã¾ã‚Œã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªå€‹æ•°ã‚’æ•°ãˆã‚‹ã‚¿ã‚¹ã‚¯ã§ã¯ã€irrerevantãªæƒ…å ±ã«æƒ‘ã‚ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã€<br>- ç‰¹å¾´è¡¨ã«åŸºã¥ãå›å¸°ã‚¿ã‚¹ã‚¯ã®å ´åˆã€æ“¬ä¼¼ç›¸é–¢ã‚’æŒã¤ç‰¹å¾´é‡ã‚’ã®å½±éŸ¿ã‚’å¢—å¤§ã—ã¦ã—ã¾ã„ã€<br>- è¤‡é›‘ã§çµ„ã¿åˆã‚ã›ãŒå¤šã„æ¼”ç¹¹ã‚¿ã‚¹ã‚¯ï¼ˆã‚·ãƒã‚¦ãƒãƒ‘ã‚ºãƒ«ï¼‰ã«å¤±æ•—ã™ã‚‹<br><br>ã¨ã„ã£ãŸã‚ˆã†ã«ã€Reasoning TraceãŒé•·ããªã‚Œã°ãªã‚‹ã»ã©æ€§èƒ½ã‚’æ‚ªåŒ–ã•ã›ã‚‹ã‚¿ã‚¹ã‚¯ãŒå­˜åœ¨ã—ã“ã®ã‚ˆã†ãªå•é¡Œã®ã‚ã‚‹æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«ã‚‚ã€æ§˜ã€…ãªReasoning Traceã®é•·ã•ã§è©•ä¾¡ã—ãŸæ–¹ãŒè‰¯ã„ã®ã§ã¯ã€ã¨ã„ã£ãŸè©±ãªæ¨¡æ§˜ï¼Ÿ<br><img src="https://github.com/user-attachments/assets/751d09a2-c889-4ad9-b9e4-9af5a64200b8" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2269" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Devil behind the mask: An emergent safety vulnerability of Diffusion  LLMs, Zichen Wen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ‹¡æ•£ãƒ™ãƒ¼ã‚¹ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆdLLMsï¼‰ã¯ã€è¿…é€Ÿãªæ¨è«–ã¨é«˜ã„ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚’æä¾›ã™ã‚‹ãŒã€å®‰å…¨æ€§ã«é–¢ã™ã‚‹æ‡¸å¿µãŒã‚ã‚‹ã€‚æ—¢å­˜ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯ã€æ•µå¯¾çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰dLLMsã‚’ä¿è­·ã§ãã¦ã„ãªã„ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€DIJAã¨ã„ã†æ–°ã—ã„è„±ç„æ”»æ’ƒãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€dLLMsã®ç”Ÿæˆãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’åˆ©ç”¨ã—ã¦æœ‰å®³ãªè£œå®Œã‚’å¯èƒ½ã«ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€DIJAã¯æ—¢å­˜ã®æ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€ç‰¹ã«Dream-Instructã§100%ã®ASRã‚’é”æˆã—ã€JailbreakBenchã§ã®è©•ä¾¡ã§ã‚‚å„ªã‚ŒãŸçµæœã‚’ç¤ºã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€dLLMsã®å®‰å…¨æ€§ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’å†è€ƒã™ã‚‹å¿…è¦æ€§ãŒæµ®ãå½«ã‚Šã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/trtd6trtd/status/1947469171077615995?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2268" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Diffusion Beats Autoregressive in Data-Constrained Settings, Mihir Prabhudesai+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒã‚¹ã‚¯ä»˜ãæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ‡ãƒ¼ã‚¿åˆ¶ç´„ã®ã‚ã‚‹è¨­å®šã§è‡ªå·±å›å¸°ï¼ˆARï¼‰ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¯ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹æœçš„ã«æ´»ç”¨ã—ã€æ¤œè¨¼æå¤±ã‚’ä½ä¸‹ã•ã›ã€ä¸‹æµã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚æ–°ã—ã„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’è¦‹ã¤ã‘ã€æ‹¡æ•£ãŒARã‚’ä¸Šå›ã‚‹è‡¨ç•Œè¨ˆç®—é–¾å€¤ã‚’å°å‡ºã€‚ãƒ‡ãƒ¼ã‚¿ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®å ´åˆã€æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¯ARã®é­…åŠ›çš„ãªä»£æ›¿æ‰‹æ®µã¨ãªã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1947567159045197924?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã„ã¤ã‹dLLMã®æ™‚ä»£ããã†ã ãªã‚</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mihirp98/status/1947736993229885545?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è¿½åŠ å®Ÿé¨“çµæœ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mihirp98/status/1948875821797798136?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RecSys.html" target="_blank" rel="noopener noreferrer">#RecSys</a>
<a class="button" href="articles/Reproducibility.html" target="_blank" rel="noopener noreferrer">#Reproducibility</a>
<span class="issue_date">Issue Date: 2025-07-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2266" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Revisiting Prompt Engineering: A Comprehensive Evaluation for LLM-based   Personalized Recommendation, Genki Kusano+, RecSys'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã‚’ç”¨ã„ãŸå˜ä¸€ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šã®æ¨è–¦ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚23ç¨®é¡ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¿ã‚¤ãƒ—ã‚’æ¯”è¼ƒã—ãŸçµæœã€ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®è‰¯ã„LLMã§ã¯æŒ‡ç¤ºã®è¨€ã„æ›ãˆã€èƒŒæ™¯çŸ¥è­˜ã®è€ƒæ…®ã€æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã®æ˜ç¢ºåŒ–ãŒåŠ¹æœçš„ã§ã‚ã‚Šã€é«˜æ€§èƒ½ãªLLMã§ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒå„ªã‚Œã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚ç²¾åº¦ã¨ã‚³ã‚¹ãƒˆã®ãƒãƒ©ãƒ³ã‚¹ã«åŸºã¥ããƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨LLMã®é¸æŠã«é–¢ã™ã‚‹ææ¡ˆã‚’è¡Œã†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1947138463083716842?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RecSysã«ãŠã‘ã‚‹ç¶²ç¾…çš„ãªpromptingã®å®Ÿé¨“ã€‚éå¸¸ã«èˆˆå‘³æ·±ã„<br><img src="https://github.com/user-attachments/assets/bc21e547-08f7-4852-a045-84f18cd81502" alt="image" loading="lazy"></p>
<p>å®Ÿé¨“ã§åˆ©ç”¨ã•ã‚ŒãŸPromptingæ‰‹æ³•ã¨ç›¸å¯¾çš„ãªæ”¹å–„å¹…<br><br><img src="https://github.com/user-attachments/assets/9f28c445-0036-4441-a947-9774b00d81c3" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/e657da0f-5faf-42e3-aa39-e37965b8835d" alt="image" loading="lazy"><br><br>RePhrase,StepBack,Explain,Summalize-User,Recency-FocusedãŒã€æ§˜ã€…ãªãƒ¢ãƒ‡ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒ¦ãƒ¼ã‚¶ã®ç‰¹æ€§ï¼ˆLight, Heavy)ã«ãŠã„ã¦å®‰å®šã—ãŸæ€§èƒ½ã‚’ç¤ºã—ã¦ãŠã‚Šï¼ˆå°‘ãªãã¨ã‚‚ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã®æ€§èƒ½ã®åŠ£åŒ–ãŒãªã„ï¼‰ã€model agnosticã«å®‰å®šã—ãŸæ€§èƒ½ã‚’ç™ºæ®ã§ãã‚‹promptingãŒå­˜åœ¨ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚ä¸€æ–¹ã€Phi-4, nova-liteã«ã¤ã„ã¦ã¯Baselineã‹ã‚‰æœ‰æ„ã«æ€§èƒ½ãŒæ”¹å–„ã—ãŸPromptingã¯ãªã‹ã£ãŸã€‚ã“ã‚Œã¯ãƒ¢ãƒ‡ãƒ«ã¯ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ãã‚‚ãã‚‚ã®äºˆæ¸¬æ€§èƒ½ãŒä½ãã€è¤‡é›‘ãªinstructionã‚’ç†è§£ã™ã‚‹èƒ½åŠ›ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€Promptãƒ‡ã‚¶ã‚¤ãƒ³ãŒä¸ãˆã‚‹å½±éŸ¿ãŒå°ã•ã„ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚<br><br>ç‰¹å®šã®ãƒ¢ãƒ‡ãƒ«ã§ã®ã¿è‰¯ã„æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹Promptingã‚‚å­˜åœ¨ã—ãŸã€‚ãŸã¨ãˆã°Re-Reading, Echoã¯ã€Llama3.3-70Bã§ã¯æ€§èƒ½ãŒæ”¹å–„ã—ãŸãŒã€gpt-4.1-mini, gpt-4o-miniã§ã¯æ€§èƒ½ãŒæ‚ªåŒ–ã—ãŸã€‚ReActã¯gpt-4.1-miniã¨Llamd3.3-70Bã§æœ€é«˜æ€§èƒ½ã‚’é”æˆã—ãŸãŒã€gpt-4o-miniã§ã¯æœ€ã‚‚æ€§èƒ½ãŒæ‚ªã‹ã£ãŸã€‚<br><br>NLPã«ãŠã„ã¦ä¸€èˆ¬çš„ã«åˆ©ç”¨ã•ã‚Œã‚‹promptingã€RolePlay, Mock, Plan-Solve, DeepBreath, Emotion, Step-by-Stepãªã©ã¯ã€æ¨è–¦ã®Acc.ã‚’æ”¹å–„ã—ãªã‹ã£ãŸã€‚ã“ã®ã“ã¨ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶ã®å—œå¥½ã‚’æ‰ãˆã‚‹ã“ã¨ãŒé‡è¦ãªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã¯ã€ã“ã‚Œã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒæœ‰åŠ¹ã§ãªã„ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/f24850bd-6f76-4ee0-b78e-2104d1e24a36" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/d0f90be5-071c-44c9-9380-5cebd383ab86" alt="image" loading="lazy"><br><br>ç¶šã„ã¦ã€LLMã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é–¢ã‚ã‚‰ãšé«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹promptingã‚’linear mixed-effects modelï¼ˆãƒ©ãƒ³ãƒ€ãƒ åŠ¹æœã¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ã€LLMã€ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’å°å…¥ã—ã€ã“ã‚Œã‚‰ã‚’åˆ¶å¾¡ã™ã‚‹é …ã‚’ç·šå½¢å›å¸°ã«å°å…¥ã€‚promptingã‚’å›ºå®šåŠ¹æœã¨ã—Accã«å¯¾ã™ã‚‹å¯„ä¸ã‚’fittingã—ã€å¤šæ§˜ãªçŠ¶æ³ã§é«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹Promptã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹)ã«ã‚ˆã£ã¦åˆ†æã—ãŸçµæœã€ReAct, Rephrase, Step-BackãŒæœ‰æ„ã«å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€LLMã«ãŠã„ã¦é«˜ã„æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚<br><img src="https://github.com/user-attachments/assets/4c6d49d5-6464-4297-b714-de1faa95a4c8" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<span class="issue_date">Issue Date: 2025-07-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2261" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding   for Neural Machine Translation, Boxuan Lyu+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚½ãƒ¼ã‚¹ãƒ™ãƒ¼ã‚¹ã®MBRãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆsMBRï¼‰ã‚’ææ¡ˆã—ã€ãƒ‘ãƒ©ãƒ•ãƒ¬ãƒ¼ã‚ºã‚„é€†ç¿»è¨³ã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸæº–ã‚½ãƒ¼ã‚¹ã‚’ã€Œã‚µãƒãƒ¼ãƒˆä»®èª¬ã€ã¨ã—ã¦åˆ©ç”¨ã€‚å‚ç…§ãªã—ã®å“è³ªæ¨å®šãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’åŠ¹ç”¨é–¢æ•°ã¨ã—ã¦ç”¨ã„ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€å®Ÿé¨“ã«ã‚ˆã‚ŠsMBRãŒQEå†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŠã‚ˆã³æ¨™æº–MBRã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚sMBRã¯NMTãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ãŠã„ã¦æœ‰æœ›ãªæ‰‹æ³•ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/boxuan_lyu425/status/1946802820973519245?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-07-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2256" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Survey of Context Engineering for Large Language Models, Lingrui Mei+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬èª¿æŸ»ã§ã¯ã€LLMsã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€ã‚’ææ¡ˆã—ã€ãã®è¦ç´ ã¨å®Ÿè£…æ–¹æ³•ã‚’ä½“ç³»çš„ã«åˆ†é¡ã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å–å¾—ã€ç”Ÿæˆã€å‡¦ç†ã€ç®¡ç†ã‚’æ¤œè¨ã—ã€æ´—ç·´ã•ã‚ŒãŸã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…ã‚’æ¢ã‚‹ã€‚1300ä»¥ä¸Šã®ç ”ç©¶ã‚’åˆ†æã—ã€ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã®éå¯¾ç§°æ€§ã‚’æ˜ã‚‰ã‹ã«ã—ã€è¤‡é›‘ãªæ–‡è„ˆç†è§£ã¨é•·æ–‡å‡ºåŠ›ç”Ÿæˆã®ã‚®ãƒ£ãƒƒãƒ—ã«å¯¾å‡¦ã™ã‚‹é‡è¦æ€§ã‚’å¼·èª¿ã€‚ç ”ç©¶è€…ã¨ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®ãŸã‚ã®çµ±ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã‚‚ã†Context Engineeringã¨ã„ã†åˆ‡ã‚Šå£ã®ä½“ç³»åŒ–ã•ã‚ŒãŸSurveyãŒå‡ºã¦ããŸã€‚æ—©ã™ãã€‚<br><img src="https://github.com/user-attachments/assets/9577c3f8-8fd5-49e0-b80f-19c0d4f22064" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/neural_avb/status/1946288694882685317?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2250" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Laws for Optimal Data Mixtures, Mustafa Shukor+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ç”¨ã„ã¦ä»»æ„ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‰ãƒ¡ã‚¤ãƒ³ã«å¯¾ã™ã‚‹æœ€é©ãªãƒ‡ãƒ¼ã‚¿æ··åˆæ¯”ç‡ã‚’æ±ºå®šã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³é‡ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã®æå¤±ã‚’æ­£ç¢ºã«äºˆæ¸¬ã—ã€LLMã€NMMã€LVMã®äº‹å‰è¨“ç·´ã«ãŠã‘ã‚‹äºˆæ¸¬åŠ›ã‚’ç¤ºã™ã€‚å°‘æ•°ã®å°è¦æ¨¡ãªè¨“ç·´å®Ÿè¡Œã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¨å®šã—ã€é«˜ä¾¡ãªè©¦è¡ŒéŒ¯èª¤æ³•ã«ä»£ã‚ã‚‹åŸå‰‡çš„ãªé¸æŠè‚¢ã‚’æä¾›ã€‚</span>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiDimensional.html" target="_blank" rel="noopener noreferrer">#MultiDimensional</a>
<span class="issue_date">Issue Date: 2025-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2249" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TransEvalnia: Reasoning-based Evaluation and Ranking of Translations, Richard Sproat+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ™ãƒ¼ã‚¹ã®ç¿»è¨³è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã€ŒTransEvalniaã€ã‚’ææ¡ˆã—ã€Multidimensional Quality Metricsã«åŸºã¥ãè©³ç´°ãªè©•ä¾¡ã‚’è¡Œã†ã€‚TransEvalniaã¯ã€è‹±æ—¥ãƒ‡ãƒ¼ã‚¿ã‚„WMTã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®MT-Rankerã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¤ºã—ã€LLMã«ã‚ˆã‚‹è©•ä¾¡ãŒäººé–“ã®è©•ä¾¡è€…ã¨è‰¯å¥½ã«ç›¸é–¢ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚ç¿»è¨³ã®æç¤ºé †åºã«æ•æ„Ÿã§ã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã—ã€ä½ç½®ãƒã‚¤ã‚¢ã‚¹ã¸ã®å¯¾å‡¦æ³•ã‚’ææ¡ˆã€‚ã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã¯å…¬é–‹ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sakanaailabs/status/1946071203002941694?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-07-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2238" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Chain of Thought Monitorability: A New and Fragile Opportunity for AI  Safety, Tomek Korbak+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“ã®è¨€èªã§ã€Œè€ƒãˆã‚‹ã€AIã‚·ã‚¹ãƒ†ãƒ ã¯ã€å®‰å…¨æ€§å‘ä¸Šã®ãŸã‚ã«æ€è€ƒã®é€£é–ï¼ˆCoTï¼‰ã‚’ç›£è¦–ã™ã‚‹ã“ã¨ã§æ‚ªæ„ã®ã‚ã‚‹æ„å›³ã‚’æ¤œå‡ºã™ã‚‹æ©Ÿä¼šã‚’æä¾›ã™ã‚‹ã€‚ã—ã‹ã—ã€CoTç›£è¦–ã¯å®Œç’§ã§ã¯ãªãã€ä¸€éƒ¨ã®ä¸æ­£è¡Œç‚ºãŒè¦‹é€ƒã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ç ”ç©¶ã‚’é€²ã‚ã€æ—¢å­˜ã®å®‰å…¨æ‰‹æ³•ã¨ä½µã›ã¦CoTç›£è¦–ã¸ã®æŠ•è³‡ã‚’æ¨å¥¨ã™ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«é–‹ç™ºè€…ã¯ã€é–‹ç™ºã®æ±ºå®šãŒCoTã®ç›£è¦–å¯èƒ½æ€§ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’è€ƒæ…®ã™ã¹ãã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gdb/status/1945350912668737701?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>CoTã‚’ç›£è¦–ã™ã‚‹ã“ã¨ã§ã€ãŸã¨ãˆã°ãƒ¢ãƒ‡ãƒ«ã®ã‚ˆã‚ã—ããªã„æŒ™å‹•ï¼ˆe.g., misalignmentãªã©ã®æ„å›³ã—ãªã„å‹•ä½œã‚„ã€prompt injectionç­‰ã®ä¸æ­£è¡Œç‚º)ã‚’æ¤œçŸ¥ã™ã‚‹ã“ã¨ãŒã§ãã€ç‰¹ã«AIãŒã‚ˆã‚Šé•·æœŸçš„ãªèª²é¡Œã«å–ã‚Šçµ„ã‚€éš›ã«ã¯ã‚ˆã‚Šä¸€å±¤ãã®å†…éƒ¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç›£è¦–ã™ã‚‹æ‰‹æ®µãŒå¿…è¦ä¸å¯æ¬ ã¨ãªã‚‹ãŸã‚ã€CoTã®å¿ å®Ÿæ€§ã‚„è§£é‡ˆæ€§ãŒé‡è¦ã¨ãªã‚‹ã€‚ã“ã®ãŸã‚ã€CoTã®ç›£è¦–å¯èƒ½æ€§ãŒç¶­æŒã•ã‚Œã‚‹ï¼ˆãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„å­¦ç¿’æ‰‹æ³•ï¼ˆãŸã¨ãˆã°CoTã®ãƒ—ãƒ­ã‚»ã‚¹è‡ªä½“ã¯ä¸€è¦‹çœŸã£å½“ãªã“ã¨ã‚’è¨€ã£ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ãŒã€å®Ÿã¯RewardHackingã—ã¦ã„ã‚‹ã€ãªã©ï¼‰ã«ã‚ˆã£ã¦ã¯ãã‚‚ãã‚‚CoTãŒé›£èª­åŒ–ã—ç›£è¦–ã§ããªã‹ã£ãŸã‚Šã™ã‚‹ã®ã§ã€ç¾çŠ¶ã¯è„†å¼±æ€§ãŒã‚ã‚‹ï¼‰ã€ã‚ˆã‚Šæ”¹å–„ã—ã¦ã„ãæ–¹å‘ã«ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨ã—ã¦å‹•ãã“ã¨ã‚’æ¨å¥¨ã™ã‚‹ã€‚ãã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã‚’ç ”ç©¶é–‹ç™ºã™ã‚‹éš›ã«ã¯ãƒ¢ãƒ‡ãƒ«ã®CoTç›£è¦–ã«é–¢ã™ã‚‹è©•ä¾¡ã‚’å®Ÿæ–½ã™ã¹ãã§ã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã‚„é–‹ç™ºã®éš›ã«ã¯CoTã®ç›£è¦–ã«é–¢ã™ã‚‹æ±ºå®šã‚’çµ„ã¿è¾¼ã‚€ã¹ãã€ã¨ã„ã£ãŸã‚ˆã†ãªæè¨€ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚</p>
<p>é–¢é€£:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dongxi_nlp/status/1945606266027426048?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<span class="issue_date">Issue Date: 2025-07-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2226" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reasoning or Memorization? Unreliable Results of Reinforcement Learning  Due to Data Contamination, Mingqi Wu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ¨è«–èƒ½åŠ›å‘ä¸Šã«é–¢ã™ã‚‹ç ”ç©¶ãŒé€²å±•ã—ã¦ãŠã‚Šã€ç‰¹ã«Qwen2.5ãƒ¢ãƒ‡ãƒ«ãŒå¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã‚’ç”¨ã„ã¦é¡•è‘—ãªæ”¹å–„ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯åŒæ§˜ã®æˆæœãŒå¾—ã‚‰ã‚Œã¦ã„ãªã„ãŸã‚ã€ã•ã‚‰ãªã‚‹èª¿æŸ»ãŒå¿…è¦ã§ã‚ã‚‹ã€‚Qwen2.5ã¯æ•°å­¦çš„æ¨è«–æ€§èƒ½ãŒé«˜ã„ãŒã€ãƒ‡ãƒ¼ã‚¿æ±šæŸ“ã«è„†å¼±ã§ã‚ã‚Šã€ä¿¡é ¼æ€§ã®ã‚ã‚‹çµæœã‚’å¾—ã‚‹ãŸã‚ã«ã¯ã€RandomCalculationã¨ã„ã†ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é€šã˜ã¦ã€æ­£ç¢ºãªå ±é…¬ä¿¡å·ãŒæ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ä¿¡é ¼æ€§ã®ã‚ã‚‹çµè«–ã‚’å¾—ã‚‹ãŸã‚ã«ã¯ã€æ±šæŸ“ã®ãªã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨å¤šæ§˜ãªãƒ¢ãƒ‡ãƒ«ã§ã®RLæ‰‹æ³•ã®è©•ä¾¡ãŒæ¨å¥¨ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/asap2650/status/1945151806536863878?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dongxi_nlp/status/1945214650737451008?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1997" target="_blank" rel="noopener noreferrer">Spurious Rewards: Rethinking Training Signals in RLVR, Shao+, 2025.05</a>
<br><br>ã“ã¡ã‚‰ã§Qwen-mathã«å¯¾ã—ã¦å¾—ã‚‰ã‚ŒãŸRLã§ã®gainã¯ä»–ãƒ¢ãƒ‡ãƒ«ã§ã¯ç¾ã‚Œãšæ±åŒ–ã—ãªã„ã“ã¨ã‚‚å ±å‘Šã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<span class="issue_date">Issue Date: 2025-07-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2225" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] REST: Stress Testing Large Reasoning Models by Asking Multiple Problems  at Once, Zhuoshi Pan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RESTã¨ã„ã†æ–°ã—ã„è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€LRMsã‚’åŒæ™‚ã«è¤‡æ•°ã®å•é¡Œã«ã•ã‚‰ã™ã“ã¨ã§ã€å®Ÿä¸–ç•Œã®æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã€‚å¾“æ¥ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®é™ç•Œã‚’å…‹æœã—ã€æ–‡è„ˆå„ªå…ˆé…åˆ†ã‚„å•é¡Œé–“å¹²æ¸‰è€æ€§ã‚’æ¸¬å®šã€‚DeepSeek-R1ãªã©ã®æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆä¸‹ã§æ€§èƒ½ä½ä¸‹ãŒè¦‹ã‚‰ã‚Œã€RESTã¯ãƒ¢ãƒ‡ãƒ«é–“ã®æ€§èƒ½å·®ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚ç‰¹ã«ã€Œè€ƒãˆã™ãã®ç½ ã€ãŒæ€§èƒ½ä½ä¸‹ã®è¦å› ã§ã‚ã‚Šã€ã€Œlong2shortã€æŠ€è¡“ã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒå„ªã‚ŒãŸçµæœã‚’ç¤ºã™ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚RESTã¯ã‚³ã‚¹ãƒˆåŠ¹ç‡ãŒé«˜ãã€å®Ÿä¸–ç•Œã®è¦æ±‚ã«é©ã—ãŸè©•ä¾¡æ‰‹æ³•ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1945130848061194500?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/user-attachments/assets/eb969359-91d2-4ac4-8a48-1fe27d88ec4e" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Off-Policy.html" target="_blank" rel="noopener noreferrer">#Off-Policy</a>
<span class="issue_date">Issue Date: 2025-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2221" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Quantile Reward Policy Optimization: Alignment with Pointwise Regression  and Exact Partition Functions, Simon Matrenok+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- QRPOï¼ˆQuantile Reward Policy Optimizationï¼‰ã¯ã€ãƒã‚¤ãƒ³ãƒˆãƒ¯ã‚¤ã‚ºã®çµ¶å¯¾å ±é…¬ã‹ã‚‰å­¦ç¿’ã™ã‚‹æ–°ã—ã„æ‰‹æ³•ã§ã€DPOã®ã‚·ãƒ³ãƒ—ãƒ«ã•ã¨ã‚ªãƒ•ãƒ©ã‚¤ãƒ³é©ç”¨æ€§ã‚’å…¼ã­å‚™ãˆã¦ã„ã¾ã™ã€‚QRPOã¯é‡å­å ±é…¬ã‚’ç”¨ã„ã¦KLæ­£å‰‡åŒ–ã•ã‚ŒãŸå¼·åŒ–å­¦ç¿’ã®ç›®çš„ã®é–‰å½¢å¼è§£ã¸ã®å›å¸°ã‚’å®Ÿç¾ã—ã€ç›¸å¯¾çš„ãªä¿¡å·ã®å¿…è¦æ€§ã‚’æ’é™¤ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€QRPOãŒDPOã‚„REBELã€SimPOã¨æ¯”è¼ƒã—ã¦ã€ãƒãƒ£ãƒƒãƒˆã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®è©•ä¾¡ã§ä¸€è²«ã—ã¦æœ€é«˜ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€å …ç‰¢ãªå ±é…¬ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šã€é•·ã•ãƒã‚¤ã‚¢ã‚¹ãŒæ¸›å°‘ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ç”»åƒã¯å…ƒãƒã‚¹ãƒˆã‚ˆã‚Šã€‚off-policy RLã§ã‚‚long contextã§é«˜ã„æ€§èƒ½ãŒå‡ºã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã ã‚ã†ã‹<br><br><img src="https://github.com/user-attachments/assets/2a66064a-8e1c-49fa-a1d2-ed4b475155e1" alt="image" loading="lazy"><br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/skandermoalla/status/1944773057085579531?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2060" target="_blank" rel="noopener noreferrer">Q-learning is not yet scalable, Seohong Park, UC Berkeley, 2025.06</a>
</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Muonã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã‚’å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ãŸã‚ã«ã€ã‚¦ã‚§ã‚¤ãƒˆãƒ‡ã‚±ã‚¤ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã”ã¨ã®æ›´æ–°ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´ã‚’å°å…¥ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Muonã¯å¤§è¦æ¨¡ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§å³åº§ã«æ©Ÿèƒ½ã—ã€è¨ˆç®—åŠ¹ç‡ãŒAdamWã®ç´„2å€ã«å‘ä¸Šã€‚æ–°ãŸã«ææ¡ˆã™ã‚‹Moonlightãƒ¢ãƒ‡ãƒ«ã¯ã€å°‘ãªã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°FLOPã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®åˆ†æ•£Muonå®Ÿè£…ã‚„äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚‚å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1944902706747072678?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã¡ã‚‰ã§ã‚‚ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2208" target="_blank" rel="noopener noreferrer">ãã¿ã¯NanoGPT speedrunã‚’çŸ¥ã£ã¦ã„ã‚‹ã‹ï¼Ÿ, PredNext, 2025.07</a>
</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1972792014954733896?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2194" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SingLoRA: Low Rank Adaptation Using a Single Matrix, David BensaÃ¯d+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- SingLoRAã¯ã€LoRAã®ä½ãƒ©ãƒ³ã‚¯é©å¿œã‚’å†å®šå¼åŒ–ã—ã€å˜ä¸€ã®ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ã¨ãã®è»¢ç½®ã®ç©ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®‰å®šæ€§ã‚’å‘ä¸Šã•ã›ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’ã»ã¼åŠæ¸›ã•ã›ã‚‹æ‰‹æ³•ã§ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€å¸¸è­˜æ¨è«–ã‚¿ã‚¹ã‚¯ã§LLama 7Bã‚’ç”¨ã„ãŸãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§91.3%ã®ç²¾åº¦ã‚’é”æˆã—ã€LoRAã‚„LoRA+ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€ç”»åƒç”Ÿæˆã«ãŠã„ã¦ã‚‚Stable Diffusionã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§é«˜ã„å¿ å®Ÿåº¦ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1943701154497732765?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LoRAã¯ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—BAã®ç©ã‚’è¨ˆç®—ã™ã‚‹ãŒã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜æŒ™å‹•ã‹ã‚‰å­¦ç¿’ã‚’ã‚¹ã‚¿ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã«ã€Bã‚’zeroã§åˆæœŸåŒ–ã—ã€Aã¯ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã™ã‚‹ã€‚ã“ã®Aã¨Bã®ä¸å‡è¡¡ã•ãŒã€å‹¾é…æ¶ˆå¤±ã€çˆ†ç™ºã€ã‚ã‚‹ã„ã¯sub-optimalãªåæŸã®è¦å› ã¨ãªã£ã¦ã—ã¾ã£ã¦ã„ãŸï¼ˆinter-matrix scale conflicts)ã€‚ç‰¹ã«ã€LoRAã¯ãƒ¢ãƒ‡ãƒ«ã®widthãŒå¤§ãããªã‚‹ã¨ä¸å®‰å®šã«ãªã‚‹ã¨ã„ã†èª²é¡ŒãŒã‚ã£ãŸã€‚ã“ã®ãŸã‚ã€ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ã‚’2ã¤ä½¿ã†ã®ã§ã¯ãªãã€1ã¤ã®ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ï¼ˆã¨ãã®è»¢ç½®ï¼‰ãŠã‚ˆã³optimizationã®step tã”ã¨ã«trainableãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã©ã®ç¨‹åº¦å½±éŸ¿ã‚’ä¸ãˆã‚‹ã‹ã‚’èª¿æ•´ã™ã‚‹åº¦åˆã„ã‚’æ±ºã‚ã‚‹scalar function u(t)ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—é–“ã®ä¸å‡è¡¡ã‚’è§£æ¶ˆã—ã¤ã¤ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’åŠæ¸›ã—ã€å­¦ç¿’ã®å®‰å®šæ€§ã¨æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ãŸã¨ãˆã°u(t)ã‚’å­¦ç¿’é–‹å§‹æ™‚ã«zeroã«ã™ã‚Œã°ã€å…ƒã®LoRAã«ãŠã„ã¦Bã‚’zeroã«åˆæœŸåŒ–ã™ã‚‹ã®ã¨åŒã˜æŒ™å‹•ï¼ˆã¤ã¾ã‚Šå…ƒã®ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜æŒ™å‹•ã‹ã‚‰å­¦ç¿’ã‚¹ã‚¿ãƒ¼ãƒˆãŒã§ããŸã‚Šã™ã‚‹ã€‚ã¿ãŸã„ãªæ„Ÿã˜ã ã‚ã†ã‹ï¼Ÿ<br><br><img src="https://github.com/user-attachments/assets/2dcd4ec1-59d3-43c0-ab8d-5c1c37e5ec3d" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/c73b8715-e0c8-45c8-a7fa-ea55ac8ca3ce" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/cf034dcd-37c4-48f1-a0a3-1d836db37820" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/82999835-ac1e-4380-8bd0-00d14022abf5" alt="image" loading="lazy"></p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1956" target="_blank" rel="noopener noreferrer">LoRA: Low-Rank Adaptation of Large Language Models, Edward J. Hu+, ICLR'22</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1245" target="_blank" rel="noopener noreferrer">LoRA+: Efficient Low Rank Adaptation of Large Models, Soufiane Hayou+, N/A, ICML'24</a>
</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2192" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Small Batch Size Training for Language Models: When Vanilla SGD Works,  and Why Gradient Accumulation Is Wasteful, Martin Marek+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å°ã•ãªãƒãƒƒãƒã‚µã‚¤ã‚ºã«å¯¾ã™ã‚‹Adamã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹æ–°ã—ã„ãƒ«ãƒ¼ãƒ«ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å°ã•ãªãƒãƒƒãƒã‚µã‚¤ã‚ºã§ã‚‚å®‰å®šã—ãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¯èƒ½ã§ã€å¤§ããªãƒãƒƒãƒã‚µã‚¤ã‚ºã¨åŒç­‰ä»¥ä¸Šã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚å‹¾é…è“„ç©ã¯æ¨å¥¨ã›ãšã€å®Ÿç”¨çš„ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/giffmana/status/1943384733418950815?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>è«–æ–‡ä¸­ã®Figure1ã«ãŠã„ã¦ã€AdamWã«ãŠã„ã¦batchsizeãŒ1ã®æ–¹ãŒ512ã®å ´åˆã¨æ¯”ã¹ã¦learning_rateã®å¤‰åŒ–ã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆã§ã‚ã‚‹æ—¨ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>&lt;img width="977" height="642" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/0c1efb5d-6eeb-4fd7-ba06-e4296e988a6c"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0c1efb5d-6eeb-4fd7-ba06-e4296e988a6c"&lt;/a&gt;


/&gt;<p>ä¼¼ãŸã‚ˆã†ãªè©±ã§MTã§ãƒãƒƒãƒã‚µã‚¤ã‚ºå°ã•ã„ã»ã†ãŒæ€§èƒ½è‰¯ã„ã§ã™ã€ã¿ãŸã„ãªè©±ãŒæ˜”ã‚ã£ãŸã‚ˆã†ãª<br><br>ï¼ˆè¿½è¨˜ï¼‰<br>æ°—ã«ãªã£ã¦æ€ã„å‡ºãã†ã¨ã—ã¦ã„ãŸãŒã€MTã§ã¯ãªãç”»åƒèªè­˜ã®è©±ã ã£ãŸã‹ã‚‚ã—ã‚Œãªã„ï¼ˆã ã„ã¶ã†ã‚è¦šãˆï¼‰<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2196" target="_blank" rel="noopener noreferrer">[Paper Note] Revisiting Small Batch Training for Deep Neural Networks, Dominic Masters+, arXiv'18</a>
 </p>
<p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1944034128707342815?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1541" target="_blank" rel="noopener noreferrer">How Does Critical Batch Size Scale in Pre-training?, Hanlin Zhang+, ICLR'25</a>
</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1952506470878351492?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å®Ÿéš›ã«8Bãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ã«ãŠã„ã¦Î²2ã‚’0.99ã«ã—ãŸã¨ã“ã‚ã€å­¦ç¿’ãŒä¸å®‰å®šã«ãªã‚Šã€ã‹ã¤æœ€çµ‚çš„ãªPerplexityã‚‚ä»–ã®è¨­å®šã«å‹ã¤ã“ã¨ãŒã§ããªã‹ã£ãŸã¨ã®ã“ã¨:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1955906705637957995?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2188" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Spike No More: Stabilizing the Pre-training of Large Language Models, Sho Takase+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ä¸­ã«ç™ºç”Ÿã™ã‚‹æå¤±ã®ã‚¹ãƒ‘ã‚¤ã‚¯ã¯æ€§èƒ½ã‚’ä½ä¸‹ã•ã›ã‚‹ãŸã‚ã€é¿ã‘ã‚‹ã¹ãã§ã‚ã‚‹ã€‚å‹¾é…ãƒãƒ«ãƒ ã®æ€¥æ¿€ãªå¢—åŠ ãŒåŸå› ã¨ã•ã‚Œã€ã‚µãƒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ¤ã‚³ãƒ“è¡Œåˆ—ã®åˆ†æã‚’é€šã˜ã¦ã€å‹¾é…ãƒãƒ«ãƒ ã‚’å°ã•ãä¿ã¤ãŸã‚ã®æ¡ä»¶ã¨ã—ã¦å°ã•ãªã‚µãƒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨å¤§ããªã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ã“ã‚Œã‚‰ã®æ¡ä»¶ã‚’æº€ãŸã™æ‰‹æ³•ãŒæå¤±ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’åŠ¹æœçš„ã«é˜²ãã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shot4410/status/1943301371010388175?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>small sub-layers, large shortcutsã®èª¬æ˜ã¯ã“ã¡ã‚‰ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹ã€‚å‰è€…ã«ã¤ã„ã¦ã¯ã€ç¾åœ¨ä¸»æµãªLLMã®åˆæœŸåŒ–æ‰‹æ³•ã¯æº€ãŸã—ã¦ã„ã‚‹ãŒã€å¾Œè€…ã¯ã‚ªãƒªã‚¸ãƒŠãƒ«ã®Transformerã®å®Ÿè£…ã§ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹[^1]ãŒã€æœ€è¿‘ã®å®Ÿè£…ã§ã¯å¤±ã‚ã‚Œã¦ã—ã¾ã£ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚<br><img src="https://github.com/user-attachments/assets/55cf847c-fc6a-4e76-88c9-1507464e96a0" alt="image" loading="lazy"><br><br>ä¸‹å›³ãŒå®Ÿé¨“çµæœã§ã€æ¡ä»¶ã®åŒæ–¹ã‚’æº€ãŸã—ã¦ã„ã‚‹ã®ã¯EmbedLN[^2]ã¨Scaled Embed[^3]ã®ã¿ã§ã‚ã‚Šã€å®Ÿéš›ã«ã‚¹ãƒ‘ã‚¤ã‚¯ãŒç”Ÿã˜ã¦ã„ãªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/79494662-3d58-4d8e-ae9d-8ed9241e0f65" alt="image" loading="lazy"><br><br>[^1]:ã‚ªãƒªã‚¸ãƒŠãƒ«è«–æ–‡ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/245" target="_blank" rel="noopener noreferrer">[Paper Note] Attention Is All You Need, Ashish Vaswani+, arXiv'17</a>
 ã®3.4ç¯€æœ«å°¾ã€embedding layersã«å¯¾ã—ã¦sqrt(d_model)ã‚’ä¹—ã˜ã‚‹ã¨ã„ã†ã“ã¨ãŒã‚µãƒ©ãƒƒã¨æ›¸ã„ã¦ã‚ã‚‹ã€‚ã“ã‚ŒãŒå®Ÿã¯ã‚ã¡ã‚ƒã‚ã¡ã‚ƒé‡è¦ã ã£ãŸã¨ã„ã†â€¦<br>[^2]: positional embeddingã‚’åŠ ç®—ã™ã‚‹å‰ã«Layer Normalizationã‚’ã‹ã‘ã‚‹æ–¹æ³•<br>[^3]: Embeddingã«Embeddingã®æ¬¡å…ƒæ•°dï¼ˆi.e., å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®inputã®æ¬¡å…ƒæ•°)ã®å¹³æ–¹æ ¹ã‚’ä¹—ã˜ã‚‹æ–¹æ³•</p>
<p>å‰ã«Scaled dot-product attentionã®sqrt(d_k)ãŒã‚ã£ã¡ã‚ƒé‡è¦ã¨ã„ã†ã“ã¨ã‚’å®Ÿé¨“çš„ã«ç¤ºã—ãŸã€ã¨ã„ã†è©±ã‚‚ã‚ã£ãŸã‚ˆã†ãªâ€¦<br>ï¼ˆã¾ã‚ãã‚‚ãã‚‚å…ƒè«–æ–‡ã«ãªãœã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã•ã›ã‚‹ã‹ã®èª¬æ˜ã¯æ›¸ã„ã¦ã‚ã‚‹ã‘ã©ã‚‚ï¼‰</p>
<p>è‘—è€…ãƒã‚¹ãƒˆï¼ˆã‚¹ãƒ©ã‚¤ãƒ‰ï¼‰:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shot4410/status/1973694743227027592?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>éå¸¸ã«èˆˆå‘³æ·±ã„ã®ã§å‚ç…§ã®ã“ã¨ã€‚åˆæœŸåŒ–ã®æ°—æŒã¡ã®éƒ¨åˆ†ãªã©å‹‰å¼·ã«ãªã‚‹ã€‚</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Privacy.html" target="_blank" rel="noopener noreferrer">#Privacy</a>
<span class="issue_date">Issue Date: 2025-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2186" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FlexOlmo: Open Language Models for Flexible Data Use, Weijia Shi+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- FlexOlmoã¯ã€ãƒ‡ãƒ¼ã‚¿å…±æœ‰ãªã—ã§ã®åˆ†æ•£ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¯èƒ½ã«ã™ã‚‹æ–°ã—ã„è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒç‹¬ç«‹ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€ãƒ‡ãƒ¼ã‚¿æŸ”è»Ÿãªæ¨è«–ã‚’å®Ÿç¾ã—ã¾ã™ã€‚æ··åˆå°‚é–€å®¶ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã—ã€å…¬é–‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ç‰¹åŒ–å‹ã‚»ãƒƒãƒˆã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€31ã®ä¸‹æµã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã•ã‚Œã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«åŸºã¥ãã‚ªãƒ—ãƒˆã‚¢ã‚¦ãƒˆãŒå¯èƒ½ã§ã€å¹³å‡41%ã®æ€§èƒ½æ”¹å–„ã‚’é”æˆã—ã€å¾“æ¥ã®æ‰‹æ³•ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸçµæœã‚’ç¤ºã—ã¾ã—ãŸã€‚FlexOlmoã¯ã€ãƒ‡ãƒ¼ã‚¿æ‰€æœ‰è€…ã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚’å°Šé‡ã—ã¤ã¤ã€é–‰ã˜ãŸãƒ‡ãƒ¼ã‚¿ã®åˆ©ç‚¹ã‚’æ´»ã‹ã™ã“ã¨ãŒã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/asap2650/status/1943184037419585695?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ‡ãƒ¼ã‚¿ã®ã‚ªãƒ¼ãƒŠãƒ¼å´ãŒãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ(FFNã¨Router embeddings)ã‚’å­¦ç¿’ã—ã€ãã‚Œã‚’publicã«ã‚·ã‚§ã‚¢ã™ã‚‹ã“ã¨ã§åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ãƒ‡ãƒ¼ã‚¿ã‚ªãƒ¼ãƒŠãƒ¼å´ã¯ãƒ‡ãƒ¼ã‚¿ãã®ã‚‚ã®ã‚’æä¾›ã™ã‚‹ã®ã§ã¯ãªãã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å…±æœ‰ã™ã‚‹ã ã‘ã§æ¸ˆã¿ã€ã‹ã¤è‡ªåˆ†ãŸã¡ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’Routerå´ã§åˆ©ç”¨ã™ã‚‹ã‹å¦ã‹ã¯åˆ¶å¾¡å¯èƒ½ã ã‹ã‚‰ã€opt-in/outãŒåˆ¶å¾¡ã§ãã‚‹ã€ã¿ãŸã„ãªè©±ã£ã½ã„ï¼Ÿ<br><img src="https://github.com/user-attachments/assets/6c21a262-afa1-4877-8b53-e6cd9176ecf5" alt="image" loading="lazy"></p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/weijiashi2/status/1942999141438914622?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2184" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] First Return, Entropy-Eliciting Explore, Tianyu Zheng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- FR3Eï¼ˆFirst Return, Entropy-Eliciting Exploreï¼‰ã¯ã€å¼·åŒ–å­¦ç¿’ã«ãŠã‘ã‚‹ä¸å®‰å®šãªæ¢ç´¢ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®æ§‹é€ åŒ–ã•ã‚ŒãŸæ¢ç´¢ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€é«˜ä¸ç¢ºå®Ÿæ€§ã®æ„æ€æ±ºå®šãƒã‚¤ãƒ³ãƒˆã‚’ç‰¹å®šã—ã€ä¸­é–“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€FR3EãŒå®‰å®šã—ãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ä¿ƒé€²ã—ã€ä¸€è²«ã—ãŸå¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/f14bertolotti/status/1943201406271328524?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RLVRã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã«ãŠã„ã¦ã€reasoning traceã«ãŠã‘ã‚‹å„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‡ºåŠ›ã™ã‚‹éš›ã«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒé«˜ã„éƒ¨åˆ†ã‚’ç‰¹å®šã—ï¼ˆã¤ã¾ã‚Šã€è¤‡æ•°ã®å€™è£œãŒã‚ã‚Šãƒ¢ãƒ‡ãƒ«ãŒè¿·ã£ã¦ã„ã‚‹ï¼‰ã€ãã®éƒ¨åˆ†ã«ã¤ã„ã¦ç•°ãªã‚‹æ„å›³çš„ã«ç•°ãªã‚‹ç”Ÿæˆãƒ‘ã‚¹ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§æ¢ç´¢ã‚’ä¿ƒã™ã‚ˆã†ã«ã™ã‚‹ã¨RLVRãŒã‚ˆã‚Šreliableã«ãªã‚‹ã¨ã„ã£ãŸè©±ã®ã‚ˆã†ã§ã‚ã‚‹<br><img src="https://github.com/user-attachments/assets/fc8adfcf-f6fc-4631-ba0a-04fa1401e96a" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/fabf56a8-20f3-4782-a07b-3c854f01dfd5" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<a class="button" href="articles/Decoder.html" target="_blank" rel="noopener noreferrer">#Decoder</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2182" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding   Models, Chankyu Lee+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼å°‚ç”¨ã®LLMãƒ™ãƒ¼ã‚¹ã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«NV-Embedã¯ã€BERTã‚„T5ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’å·¥å¤«ã—ã€æ¤œç´¢ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«æ½œåœ¨çš„æ³¨æ„å±¤ã‚’ææ¡ˆã€‚äºŒæ®µéšã®å¯¾ç…§çš„æŒ‡ç¤ºèª¿æ•´æ‰‹æ³•ã‚’å°å…¥ã—ã€æ¤œç´¢ã¨éæ¤œç´¢ã‚¿ã‚¹ã‚¯ã®ä¸¡æ–¹ã§ç²¾åº¦ã‚’å‘ä¸Šã€‚NV-Embedãƒ¢ãƒ‡ãƒ«ã¯MTEBãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã§1ä½ã‚’ç²å¾—ã—ã€ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–æƒ…å ±æ¤œç´¢ã§ã‚‚é«˜ã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚ãƒ¢ãƒ‡ãƒ«åœ§ç¸®æŠ€è¡“ã®åˆ†æã‚‚è¡Œã£ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Decoder-Only LLMã®last hidden layerã®matrixã‚’æ–°ãŸã«å°å…¥ã—ãŸLatent Attention Blockã®inputã¨ã—ã€Latent Attention Blockã¯Embeddingã‚’Outputã™ã‚‹ã€‚Latent Attention Blockã¯ã€last hidden layer (ç³»åˆ—é•·lÃ—dã®<br>matrix)ã‚’Queryã¨ã¿ãªã—ã€ä¿æŒã—ã¦ã„ã‚‹Latent Array(trainableãªmatrixã§è¾æ›¸ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹;å¾Œè¿°ã®å­¦ç¿’ã«ãŠã„ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå­¦ç¿’ã•ã‚Œã‚‹)[^1]ã‚’K,Vã¨ã—ã¦ã€CrossAttentionã«ã‚ˆã£ã¦context vectorã‚’ç”Ÿæˆã—ã€ãã®å¾ŒMLPã¨Mean Poolingã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§Embeddingã«å¤‰æ›ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/7a023273-aafd-4cfa-9b39-961180543ae9" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/767e3ac1-fe70-4653-bbe7-091c1f1dc0f7" alt="image" loading="lazy"><br><br>å­¦ç¿’ã¯2æ®µéšã§è¡Œã‚ã‚Œã€ã¾ãšQAãªã©ã®Retrievalã‚¿ã‚¹ã‚¯ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’In Batch negativeã‚’ç”¨ã„ã¦Contrastive Learningã—ãƒ¢ãƒ‡ãƒ«ã®æ¤œç´¢èƒ½åŠ›ã‚’é«˜ã‚ã‚‹ã€‚ãã®å¾Œã€æ¤œç´¢ã¨éæ¤œç´¢ã‚¿ã‚¹ã‚¯ã®ä¸¡æ–¹ã‚’ç”¨ã„ã¦ã€hard negativeã«ã‚ˆã£ã¦contrastive learningã‚’å®Ÿæ–½ã—ã€æ¤œç´¢ä»¥å¤–ã®ã‚¿ã‚¹ã‚¯ã®èƒ½åŠ›ã‚‚é«˜ã‚ã‚‹ï¼ˆä¸‹è¡¨ï¼‰ã€‚ä¸¡è€…ã«ãŠã„ã¦ã€instructionãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”¨ã„ã¦ã€instructionã«ã‚ˆã£ã¦æ¡ä»¶ä»˜ã‘ã¦å­¦ç¿’ã‚’ã™ã‚‹ã“ã¨ã§ã€instructionã«å¿œã˜ã¦ç”Ÿæˆã•ã‚Œã‚‹EmbeddingãŒå¤‰åŒ–ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ã¾ãŸã€å­¦ç¿’æ™‚ã«ã¯LLMã®causal maskã¯ç„¡ãã—ã€bidirectionalã«representationã‚’è€ƒæ…®ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/26d4e126-1d18-421e-873f-f0eef4fc2026" alt="image" loading="lazy"><br><br>[^1]: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2183" target="_blank" rel="noopener noreferrer">[Paper Note] Perceiver IO: A General Architecture for Structured Inputs &amp; Outputs, Andrew Jaegle+, ICLR'22</a>
 Perceiver-IOã«ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2181" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long  Generation, Liliang Ren+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®é€²å±•ã«ã‚ˆã‚Šã€çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ï¼ˆSSMï¼‰ã®åŠ¹ç‡çš„ãªã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ã‚²ãƒ¼ãƒ†ãƒƒãƒ‰ãƒ¡ãƒ¢ãƒªãƒ¦ãƒ‹ãƒƒãƒˆï¼ˆGMUï¼‰ã‚’å°å…¥ã—ã€Sambaãƒ™ãƒ¼ã‚¹ã®è‡ªå·±ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰ãƒ¡ãƒ¢ãƒªã‚’å…±æœ‰ã™ã‚‹æ–°ã—ã„ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£SambaYã‚’ææ¡ˆã—ã¾ã™ã€‚SambaYã¯ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã€é•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ€§èƒ½ã‚’æ”¹å–„ã—ã€ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®å¿…è¦æ€§ã‚’æ’é™¤ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€SambaYã¯YOCOãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«å¯¾ã—ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€ç‰¹ã«Phi4-mini-Flash-Reasoningãƒ¢ãƒ‡ãƒ«ã¯æ¨è«–ã‚¿ã‚¹ã‚¯ã§é¡•è‘—ãªæˆæœã‚’ä¸Šã’ã¾ã—ãŸã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/microsoft/Phi-4-mini-flash-reasoning" target="_blank" rel="noopener noreferrer">https://huggingface.co/microsoft/Phi-4-mini-flash-reasoning</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1943099901161652238?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2180" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MegaMath: Pushing the Limits of Open Math Corpora, Fan Zhou+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- MegaMathã¯ã€æ•°å­¦ã«ç‰¹åŒ–ã—ãŸã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€LLMã®æ•°å­¦çš„æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ä½œæˆã•ã‚ŒãŸã€‚ã‚¦ã‚§ãƒ–ãƒ‡ãƒ¼ã‚¿ã®å†æŠ½å‡ºã€æ•°å­¦é–¢é€£ã‚³ãƒ¼ãƒ‰ã®ç‰¹å®šã€åˆæˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆã‚’é€šã˜ã¦ã€371Bãƒˆãƒ¼ã‚¯ãƒ³ã®é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚’æä¾›ã—ã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¸Šå›ã‚‹é‡ã¨å“è³ªã‚’å®Ÿç¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fazhou_998/status/1942610771915202590?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>éå¸¸ã«å¤§è¦æ¨¡ãªæ•°å­¦ã®äº‹å‰å­¦ç¿’/mid-trainingå‘ã‘ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br><br>CommonCrawlã®HTMLã‹ã‚‰ã€ã•ã¾ã–ã¾ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†ï¼ˆreformatting, 2 stageã®HTML parserã®æ´»ç”¨ï¼ˆç‰‡æ–¹ã¯noisyã ãŒé«˜é€Ÿã€ã‚‚ã†ä¸€æ–¹ã¯é«˜æ€§èƒ½ã ãŒé…ã„ï¼‰, fasttextãƒ™ãƒ¼ã‚¹ã®åˆ†é¡å™¨ã«ã‚ˆã‚‹æŠ½å‡º, deduplicationç­‰ï¼‰ã‚’å®Ÿæ–½ã—MegaMath-Webã‚’ä½œæˆã€ã¾ãŸã€MegaMathWebã‚’ã•ã‚‰ã«åˆ†é¡å™¨ã§ä½å“è³ªãªã‚‚ã®ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã€LLMã«ã‚ˆã£ã¦ãƒã‚¤ã‚ºé™¤å»ã€ãƒ†ã‚­ã‚¹ãƒˆã®reorganizingã‚’å®Ÿæ–½ã—ï¼ˆâ‰ ãƒ”ãƒ¥ã‚¢ãªåˆæˆãƒ‡ãƒ¼ã‚¿ï¼‰ç¶™ç¶šäº‹å‰å­¦ç¿’ã€mid-trainingå‘ã‘ã®é«˜å“è³ªãªMegaMath-Web-Proã‚’ä½œæˆã€‚<br><br>MegaMathCodeã¯The Stack V2 (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2199" target="_blank" rel="noopener noreferrer">[Paper Note] StarCoder 2 and The Stack v2: The Next Generation, Anton Lozhkov+, arXiv'24</a>
) ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ã¦ãŠã‚Šã€mathematical reasoning, logic puzzles, scientific computationã«é–¢ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’åé›†ã€‚ã¾ãšã“ã‚Œã‚‰ã®ã‚³ãƒ¼ãƒ‰ã¨é–¢é€£ãŒæ·±ã„11ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã‚’é¸å®šã—ã€ãã®ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹ã€‚æ¬¡ã«strong LLMã‚’ç”¨ã„ã¦ã€æ•°å­¦ã«é–¢ã™ã‚‹relevanceã‚¹ã‚³ã‚¢ã¨ã€ã‚³ãƒ¼ãƒ‰ã®å“è³ªã‚’0--6ã®discrete scoreã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã€‚ä½œæˆã—ãŸå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§SLMã‚’å­¦ç¿’ã—å¤§è¦æ¨¡ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§MegaMath-Codeã‚’ä½œæˆã€‚<br><br>æœ€å¾Œã«MegaMath-{Web, code}ã‚’ç”¨ã„ã¦ã€Q&amp;A, code data, text&amp;code block dataã®3ç¨®é¡ã‚’åˆæˆã€‚Q&amp;Aãƒ‡ãƒ¼ã‚¿ã®åˆæˆã§ã¯ã€MegaMath-Webã‹ã‚‰QAãƒšã‚¢ã‚’æŠ½å‡ºã—ã€å¤šæ§˜æ€§ã¨ãƒ‡ãƒ¼ã‚¿é‡ã‚’æ‹…ä¿ã™ã‚‹ãŸã‚Qwen2.5-72B-Instruct, Llama3.3-70B-Instructã®ä¸¡æ–¹ã‚’ç”¨ã„ã¦ã€QAã®solutionã‚’æ´—ç·´ã•ã›ã‚‹ï¼ˆreasoning stepã®æ”¹å–„, ã‚ã‚‹ã„ã¯ã‚¼ãƒ­ã‹ã‚‰ç”Ÿæˆã™ã‚‹[^1])ã“ã¨ã§ç”Ÿæˆã€‚ã¾ãŸã€code dataã§ã¯ã€pythonã‚’å¯¾è±¡ã«MegaMath-Codeã®ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹pythonä»¥å¤–ã®ã‚³ãƒ¼ãƒ‰ã‚’ã€Qwen2.5-Coder-32B-Instructã¨ã€Llamd3.1-70B-Instructã«ã‚ˆã£ã¦pythonã«ç¿»è¨³ã™ã‚‹ã“ã¨ã§ãƒ‡ãƒ¼ã‚¿é‡ã‚’å¢—ã‚„ã—ãŸã€‚text&amp;code blockãƒ‡ãƒ¼ã‚¿ã§ã¯ã€MegaMath-Webã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¸ãˆã¦ã€ãƒ–ãƒ­ãƒƒã‚¯ã‚’ç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã€æ•°å¼ã€çµæœã€ã‚³ãƒ¼ãƒ‰ãªã©[^1]ï¼‰ã—ã€ãƒ–ãƒ­ãƒƒã‚¯ã®verificationã‚’è¡Œã„ï¼ˆã‚³ãƒ¼ãƒ‰ãŒæ­£ã—ãå®Ÿè¡Œã§ãã‚‹ã‹ã€å®Ÿè¡Œçµæœã¨answerãŒä¸€è‡´ã™ã‚‹ã‹ç­‰ï¼‰ã€verifiedãªãƒ–ãƒ­ãƒƒã‚¯ã‚’æ®‹ã™ã“ã¨ã§ç”Ÿæˆã€‚<br><br><img src="https://github.com/user-attachments/assets/8975019b-5ab4-437c-bd4e-f3b761439c9c" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/995ea6ce-69eb-4f88-8a98-9e55de3e7814" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/c6d1ec61-49f4-459f-92b2-fa0a2625178e" alt="image" loading="lazy"><br><br>[^1]: ã“ã®è¾ºã¯è«–æ–‡ã®è¨˜è¿°ã‚’å’€åš¼ã—ã¦è¨˜è¿°ã—ã¦ãŠã‚Šå®Ÿã‚µãƒ³ãƒ—ãƒ«ã‚’è¦‹ã¦ã„ãªã„ã®ã§å°‘ã—æ­£ã—ã„èªè­˜ã‹ä¸å®‰</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/OOD.html" target="_blank" rel="noopener noreferrer">#OOD</a>
<a class="button" href="articles/DiseaseNameRecognition.html" target="_blank" rel="noopener noreferrer">#DiseaseNameRecognition</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2177" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Toward Cross-Hospital Deployment of Natural Language Processing Systems: Model Development and Validation of Fine-Tuned Large Language Models for Disease Name Recognition in Japanese, Shimizu+, JMIR'25</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aramaki/status/1942902940337099254?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2176" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Survey on Latent Reasoning, Rui-Jie Zhu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€æ˜ç¤ºçš„ãªæ€è€ƒã®é€£é–ï¼ˆCoTï¼‰ã«ã‚ˆã£ã¦å„ªã‚ŒãŸæ¨è«–èƒ½åŠ›ã‚’ç¤ºã™ãŒã€è‡ªç„¶è¨€èªæ¨è«–ã¸ã®ä¾å­˜ãŒè¡¨ç¾åŠ›ã‚’åˆ¶é™ã™ã‚‹ã€‚æ½œåœ¨çš„æ¨è«–ã¯ã“ã®å•é¡Œã‚’è§£æ±ºã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã®ç›£è¦–ã‚’æ’é™¤ã™ã‚‹ã€‚ç ”ç©¶ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å±¤ã®å½¹å‰²ã‚„å¤šæ§˜ãªæ½œåœ¨çš„æ¨è«–æ‰‹æ³•ã‚’æ¢æ±‚ã—ã€ç„¡é™æ·±åº¦ã®æ½œåœ¨çš„æ¨è«–ã‚’å¯èƒ½ã«ã™ã‚‹é«˜åº¦ãªãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã«ã¤ã„ã¦è­°è«–ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ½œåœ¨çš„æ¨è«–ã®æ¦‚å¿µã‚’æ˜ç¢ºã«ã—ã€ä»Šå¾Œã®ç ”ç©¶æ–¹å‘ã‚’ç¤ºã™ã€‚é–¢é€£æƒ…å ±ã¯GitHubãƒªãƒã‚¸ãƒˆãƒªã§æä¾›ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1942787610818097609?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Latent Reasoningã¨ã„ã†ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚¿ãƒ¼ãƒ ãŒå‡ºã¦ããŸ</p>
<p>å‡ºåŠ›ã•ã‚Œã‚‹discreteãªtokenã«ã‚ˆã£ã¦reasoningã‚’å®Ÿæ–½ã™ã‚‹ã®ã§ã¯ãªãã€ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã®representationã§reasoningã‚’å®Ÿæ–½ã™ã‚‹Latent Reasoningã®Survey<br><br>&lt;img width="1099" height="876" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/a34451e6-bf4a-432c-8c5b-facdbfb55c41"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a34451e6-bf4a-432c-8c5b-facdbfb55c41"&lt;/a&gt;


/&gt;<br><br>&lt;img width="959" height="575" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/e53b3bba-f35f-4734-af71-14a90af8ee6f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/e53b3bba-f35f-4734-af71-14a90af8ee6f"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2158" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CriticLean: Critic-Guided Reinforcement Learning for Mathematical  Formalization, Zhongyuan Peng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªç„¶è¨€èªã®æ•°å­¦çš„è¡¨ç¾ã‚’å®Ÿè¡Œå¯èƒ½ãªã‚³ãƒ¼ãƒ‰ã«ç¿»è¨³ã™ã‚‹èª²é¡Œã«å¯¾ã—ã€æ‰¹è©•è€…ã®å½¹å‰²ã‚’èƒ½å‹•çš„ãªå­¦ç¿’ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«å¤‰ãˆã‚‹CriticLeanã¨ã„ã†æ–°ã—ã„å¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚CriticLeanGPTã‚’ç”¨ã„ã¦å½¢å¼åŒ–ã®æ„å‘³çš„å¿ å®Ÿæ€§ã‚’è©•ä¾¡ã—ã€CriticLeanBenchã§ãã®èƒ½åŠ›ã‚’æ¸¬å®šã€‚285Kä»¥ä¸Šã®å•é¡Œã‚’å«ã‚€FineLeanCorpusãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã€æ‰¹è©•æ®µéšã®æœ€é©åŒ–ãŒä¿¡é ¼æ€§ã®ã‚ã‚‹å½¢å¼åŒ–ã«é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1942790484688003275?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1832" target="_blank" rel="noopener noreferrer">Critique Fine-Tuning: Learning to Critique is More Effective than   Learning to Imitate, Yubo Wang+, COLM'25</a>
</p>
<p>Lean 4 å½¢å¼ã«<br><br><img src="https://github.com/user-attachments/assets/79121e53-b205-440d-9615-d520ac848704" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2155" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] VLM2Vec-V2: Advancing Multimodal Embedding for Videos, Images, and  Visual Documents, Rui Meng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- VLM2Vec-V2ã¨ã„ã†çµ±ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€å‹•ç”»ã€è¦–è¦šæ–‡æ›¸ã‚’å«ã‚€å¤šæ§˜ãªè¦–è¦šå½¢å¼ã®åŸ‹ã‚è¾¼ã¿ã‚’å­¦ç¿’ã€‚æ–°ãŸã«MMEB-V2ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã—ã€å‹•ç”»æ¤œç´¢ã‚„è¦–è¦šæ–‡æ›¸æ¤œç´¢ãªã©5ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ã€‚åºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€VLM2Vec-V2ã¯æ–°ã‚¿ã‚¹ã‚¯ã§å¼·åŠ›ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€å¾“æ¥ã®ç”»åƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚‚æ”¹å–„ã‚’é”æˆã€‚ç ”ç©¶ã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®ä¸€èˆ¬åŒ–å¯èƒ½æ€§ã«é–¢ã™ã‚‹æ´å¯Ÿã‚’æä¾›ã—ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªè¡¨ç¾å­¦ç¿’ã®åŸºç›¤ã‚’ç¯‰ãã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1942501330674647342?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2156" target="_blank" rel="noopener noreferrer">[Paper Note] VLM2Vec: Training Vision-Language Models for Massive Multimodal  Embedding Tasks, Ziyan Jiang+, ICLR'25</a>
</p>
<p>Video Classification, Visual Document Retrievalãªã©ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚‚å«ã¾ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/SequentialRecommendation.html" target="_blank" rel="noopener noreferrer">#SequentialRecommendation</a>
<a class="button" href="articles/Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<span class="issue_date">Issue Date: 2025-07-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2151" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Do We Really Need Specialization? Evaluating Generalist Text Embeddings  for Zero-Shot Recommendation and Search, Matteo Attimonelli+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- äº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆGTEsï¼‰ã¯ã€é€æ¬¡æ¨è–¦ã‚„è£½å“æ¤œç´¢ã«ãŠã„ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã§å„ªã‚ŒãŸã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ€§èƒ½ã‚’ç™ºæ®ã—ã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚GTEsã¯åŸ‹ã‚è¾¼ã¿ç©ºé–“ã«ç‰¹å¾´ã‚’å‡ç­‰ã«åˆ†é…ã™ã‚‹ã“ã¨ã§è¡¨ç¾åŠ›ã‚’é«˜ã‚ã€åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒã®åœ§ç¸®ãŒãƒã‚¤ã‚ºã‚’æ¸›å°‘ã•ã›ã€å°‚é–€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã€‚å†ç¾æ€§ã®ãŸã‚ã«ãƒªãƒã‚¸ãƒˆãƒªã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1942463379639349654?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2182" target="_blank" rel="noopener noreferrer">[Paper Note] NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding   Models, Chankyu Lee+, ICLR'25</a>
</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Citations.html" target="_blank" rel="noopener noreferrer">#Citations</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/AcademicWriting.html" target="_blank" rel="noopener noreferrer">#AcademicWriting</a>
<span class="issue_date">Issue Date: 2025-07-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2149" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ScholarCopilot: Training Large Language Models for Academic Writing with   Accurate Citations, Yubo Wang+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- ScholarCopilotã¯ã€å­¦è¡“çš„ãªåŸ·ç­†ã‚’æ”¯æ´ã™ã‚‹ãŸã‚ã«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å¼·åŒ–ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€æ­£ç¢ºã§æ–‡è„ˆã«é–¢é€£ã—ãŸå¼•ç”¨ã‚’ç”Ÿæˆã—ã¾ã™ã€‚å–å¾—ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”¨ã„ã¦å‹•çš„ã«æ–‡çŒ®ã‚’å–å¾—ã—ã€ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã‚’è£œå¼·ã—ã¾ã™ã€‚è©•ä¾¡ã§ã¯ã€å–å¾—ç²¾åº¦ãŒ40.1%ã«é”ã—ã€ç”Ÿæˆå“è³ªã‚‚ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã¾ã—ãŸã€‚ç‰¹ã«ã€ScholarCopilotã¯ChatGPTã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€å¼•ç”¨ã®è³ªã§100%ã®å¥½ã¾ã—ã•ã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1907861046833885397?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¾“æ¥ã®RAGãƒ™ãƒ¼ã‚¹ã®AcademicWritingæ‰‹æ³•ã§ã¯ã€ã¾ãšReferenceã‚’æ¤œç´¢ã—ã¦ã€ãã®å†…å®¹ã‚’contextã«å«ã‚ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã¨ã„ã†Sequentialãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã ã£ãŸãŒã€æœ¬ç ”ç©¶ã§ã¯é€šå¸¸ã®NextTokenPrediction Lossã«åŠ ãˆã€ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³\[RET\]ã‚’å°å…¥ã—ã€ContrastiveLearningã«ã‚ˆã£ã¦ã€\[RET\]ãƒˆãƒ¼ã‚¯ãƒ³ãŒãƒˆãƒªã‚¬ãƒ¼ã¨ãªã‚Šã€ç”Ÿæˆéç¨‹ã®Contextã¨queryã‹ã‚‰é©åˆ‡ãªReferenceã‚’æ¤œç´¢ã§ãã‚‹Embeddingã‚’å‡ºåŠ›ã—ã€Referenceã‚’æ¤œç´¢ã—ã€å‹•çš„ã«Referenceã®å†…å®¹ã‚’contextã«åŠ ãˆã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/777da4cb-5678-455f-babf-b91690945712" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/a27e092e-fff2-4f8a-91f7-09fe39e8e568" alt="image" loading="lazy"><br><br>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯arXivã‹ã‚‰latex sourceã‚’åé›†ã—ã€bibliographyéƒ¨åˆ†ã‹ã‚‰Referenceã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’Qwenã‚’ç”¨ã„ã¦æŠ½å‡ºã€‚ã‚¿ã‚¤ãƒˆãƒ«ã‚’arXivãŠã‚ˆã³SemanticScholarã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ç…§åˆã—ã€paperã¨Referenceã®ç´ä»˜ã‘ã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§æ§‹ç¯‰ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/2dd2b956-291e-4407-997a-4a2e68a72708" alt="image" loading="lazy"><br><br>GPT-4oã«ã‚ˆã‚‹judgeã®çµæœã€ground truthã®citationã‚’ç”¨ã„ãŸå ´åˆã«ã¯åŠã°ãªã„ãŒã€ææ¡ˆæ‰‹æ³•ã«ã‚ˆã‚Šå“è³ªãŒå‘ä¸Šã—ã€citation retrievalã®Recall@Kã‚‚å¤§å¹…ã«æ”¹å–„ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/2ff5dd73-dcb8-4a3f-9d6a-1bcfb52a8321" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/81a39366-2577-41a1-aa6b-facc7ac25f1c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/CognitiveScience.html" target="_blank" rel="noopener noreferrer">#CognitiveScience</a>
<span class="issue_date">Issue Date: 2025-07-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2147" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A foundation model to predict and capture human cognition, Binz+, Nature'25, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/biomedicalhacks/status/1941632683974508950?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2146" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Energy-Based Transformers are Scalable Learners and Thinkers, Alexi Gladstone+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ™ãƒ¼ã‚¹ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ï¼ˆEBTsï¼‰ã‚’ç”¨ã„ã¦ã€ç„¡ç›£ç£å­¦ç¿’ã‹ã‚‰æ€è€ƒã‚’å­¦ã¶ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã€‚EBTsã¯ã€å…¥åŠ›ã¨å€™è£œäºˆæ¸¬ã®äº’æ›æ€§ã‚’æ¤œè¨¼ã—ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼æœ€å°åŒ–ã‚’é€šã˜ã¦äºˆæ¸¬ã‚’è¡Œã†ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚ˆã‚Šã‚‚é«˜ã„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç‡ã‚’é”æˆã—ã€è¨€èªã‚¿ã‚¹ã‚¯ã§ã®æ€§èƒ½ã‚’29%å‘ä¸Šã•ã›ã€ç”»åƒã®ãƒã‚¤ã‚ºé™¤å»ã§ã‚‚å„ªã‚ŒãŸçµæœã‚’ç¤ºã™ã€‚EBTsã¯ä¸€èˆ¬åŒ–èƒ½åŠ›ãŒé«˜ãã€ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’èƒ½åŠ›ã¨æ€è€ƒèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1941657099567845696?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Project Page:


<a href="https://energy-based-transformers.github.io" target="_blank" rel="noopener noreferrer">https://energy-based-transformers.github.io</a>


</p>
<p>First Authorã®æ–¹ã«ã‚ˆã‚‹è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alexiglad/status/1942231878305714462?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-07-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2145" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Correlated Errors in Large Language Models, Elliot Kim+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- 350ä»¥ä¸Šã®LLMã‚’è©•ä¾¡ã—ã€ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã¨å±¥æ­´æ›¸ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã§å®Ÿè¨¼çš„ãªåˆ†æã‚’å®Ÿæ–½ã€‚ãƒ¢ãƒ‡ãƒ«é–“ã®ã‚¨ãƒ©ãƒ¼ã«ã¯å®Ÿè³ªçš„ãªç›¸é–¢ãŒã‚ã‚Šã€ç‰¹ã«å¤§ããæ­£ç¢ºãªãƒ¢ãƒ‡ãƒ«ã¯ç•°ãªã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ã‚‚é«˜ã„ç›¸é–¢ã‚’ç¤ºã™ã€‚ç›¸é–¢ã®å½±éŸ¿ã¯LLMã‚’è©•ä¾¡è€…ã¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚„æ¡ç”¨ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã‚‚ç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kennylpeng/status/1940758198320796065?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯çµæœã‚’ç´°ã‹ãè¦‹ã‚‹ã®ã¨ã€è©•ä¾¡ã—ãŸã‚¿ã‚¹ã‚¯ã®å½¢å¼ã¨ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ãªã„ã‹ã‚’ãã¡ã‚“ã¨ç¢ºèªã—ãŸæ–¹ãŒè‰¯ã„ã‚ˆã†ãªæ°—ãŒã™ã‚‹ã€‚<br><br>ãã‚Œã¯ç½®ã„ã¦ãŠã„ãŸã¨ã—ã¦ã€ãŸã¨ãˆã°ã€Figure9bã¯Llamaã®ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¯ã€é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ã¦ã„ã‚‹ãŒã€ãã‚Œã¯ãƒ™ãƒ¼ã‚¹ãŒåŒã˜ã ã‹ã‚‰ãã†ã ã‚ã†ãªã‚ã€ã¨ã¯æ€ã†ã€‚ä¸€æ–¹ã€9aã¯Claude, Nova, Mistral, GPTãªã©å¤šæ§˜ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ãƒ¢ãƒ‡ãƒ«ã§é«˜ã„ç›¸é–¢ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚Llama3-70Bã¨LLama3.{1,2,3}-70Bã§ã¯ç›¸é–¢ãŒä½ã‹ã£ãŸã‚Šã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/03728cf7-9965-4e04-8f19-5ad3977d1a19" alt="image" loading="lazy"><br><br>Figure1(b)ã¯HELMã§æ¯”è¼ƒçš„æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«é–“ã§ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒåˆ¥ã§ã‚‚é«˜ã„ç›¸é–¢ãŒã‚ã‚‹ã‚ˆã†ã«ã¿ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/d6d1622a-5215-4464-b265-39cc6f0b7a47" alt="image" loading="lazy"><br><br>ã“ã®ã‚ˆã†ãªç›¸é–¢ãŒã‚ã‚‹è¦å› ã‚„å‚¾å‘ã«ã¤ã„ã¦ã¯è«–æ–‡ã‚’èª­ã‚“ã§ã¿ãªã„ã¨ã‚ã‹ã‚‰ãªã„ã€‚</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=kzYq2hfyHB&referrer=%5Bthe%20profile%20of%20Kenny%20Peng%5D(%2Fprofile%3Fid%3D~Kenny_Peng1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=kzYq2hfyHB&referrer=%5Bthe%20profile%20of%20Kenny%20Peng%5D(%2Fprofile%3Fid%3D~Kenny_Peng1)</a>


</p>
<p>LLM-as-a-Judgeã«ãŠã„ã¦ã€è©•ä¾¡è€…ã¨ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã¨è©•ä¾¡å¯¾è±¡ã¨ãªã‚‹ãƒ¢ãƒ‡ãƒ«ãŒåŒã˜ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚„ã‚·ãƒªãƒ¼ã‚ºã®å ´åˆã¯ï¼ˆã‚¨ãƒ©ãƒ¼ã®å‚¾å‘ãŒä¼¼ã¦ã„ã‚‹ã®ã§ï¼‰æ€§èƒ½ãŒAccuracyãŒçœŸã®Accuracyã‚ˆã‚Šã‚‚é«˜ã‚ã«å‡ºã¦ã„ã‚‹ã€‚ã¾ãŸè©•ä¾¡è€…ã‚ˆã‚Šã‚‚æ€§èƒ½ãŒä½ã„ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã‚‚ã€æ€§èƒ½ãŒå®Ÿéš›ã®Accuracyã‚ˆã‚Šã‚‚é«˜ã‚ã«å‡ºã™å‚¾å‘ã«ã‚ã‚‹ï¼ˆã‚¨ãƒ©ãƒ¼ã®ç›¸é–¢ã«ã‚ˆã£ã¦ã‚¨ãƒ©ãƒ¼ã§ã‚ã‚‹ã«ã‚‚é–¢ã‚ã‚‰ãšæ­£è§£ã¨ã¿ãªã•ã‚ŒAccuracyãŒé«˜ããªã‚‹)ã‚ˆã†ã§ã‚ã‚‹ã€‚é€†ã«ã€è©•ä¾¡è€…ã‚ˆã‚Šã‚‚è©•ä¾¡å¯¾è±¡ãŒæ€§èƒ½ãŒé«˜ã„å ´åˆã€è©•ä¾¡è€…ã¯è‡ªåˆ†ãŒèª¤ã£ã¦ã—ã¾ã†questionã«å¯¾ã—ã¦ã€è©•ä¾¡å¯¾è±¡ãƒ¢ãƒ‡ãƒ«ãŒæ­£è§£ã¨ãªã‚‹å›ç­”ã‚’ã—ã¦ã‚‚ã€ãã‚Œã«å¯¾ã—ã¦å ±é…¬ã‚’ä¸ãˆã‚‹ã“ã¨ãŒã§ããšæ€§èƒ½ãŒä½ã‚ã«è¦‹ç©ã‚‚ã‚‰ã‚Œã¦ã—ã¾ã†ã€‚ã“ã‚Œã ã‘ã®è¦æ¨¡ã®å®Ÿé¨“ã§ç¤ºã•ã‚ŒãŸã“ã¨ã¯ã€å¤§å¤‰èˆˆå‘³æ·±ã„ã€‚<br><img src="https://github.com/user-attachments/assets/4a73cdf4-a70d-4f79-997a-3fd5a55c5a60" alt="image" loading="lazy"></p>
<p>å±¥æ­´æ›¸ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦ã‚‚ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚’ã—ã¦ã„ã‚‹ã€‚ã“ã¡ã‚‰ã‚‚è©³ç´°ã«åˆ†æã•ã‚Œã¦ã„ã‚‹ã®ã§èˆˆå‘³ãŒã‚ã‚‹å ´åˆã¯å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<span class="issue_date">Issue Date: 2025-07-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2144" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy, Chris Yuhao Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼ˆRMsï¼‰ã®æ€§èƒ½å‘ä¸Šã®ãŸã‚ã«ã€4,000ä¸‡ã®å¥½ã¿ãƒšã‚¢ã‹ã‚‰ãªã‚‹å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒSynPref-40Mã€ã‚’ææ¡ˆã€‚äººé–“ã¨AIã®ç›¸ä¹—åŠ¹æœã‚’æ´»ç”¨ã—ãŸäºŒæ®µéšãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã€Skywork-Reward-V2ã‚’å°å…¥ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€7ã¤ã®å ±é…¬ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒ«ã¨é«˜å“è³ªãªã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒåŠ¹æœã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ã‚’ç¢ºèªã€‚Skywork-Reward-V2ã¯ã‚ªãƒ¼ãƒ—ãƒ³å ±é…¬ãƒ¢ãƒ‡ãƒ«ã®é€²å±•ã‚’ç¤ºã—ã€äººé–“-AIã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®é‡è¦æ€§ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1941131426084303242?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/user-attachments/assets/56b6baa3-a4d0-41fe-9f4e-8a8098f7ee2c" alt="image" loading="lazy"></p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1942375700289233221?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-07-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2143" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Answer Matching Outperforms Multiple Choice for Language Model  Evaluation, Nikhil Chandak+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è¤‡æ•°é¸æŠã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯è¨€èªãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã«ãŠã„ã¦é‡è¦ã ãŒã€è³ªå•ã‚’è¦‹ãšã«å›ç­”ã§ãã‚‹ã“ã¨ãŒå¤šã„ã€‚ã“ã‚Œã«å¯¾ã—ã€å›ç­”ãƒãƒƒãƒãƒ³ã‚°ã¨ã„ã†ç”Ÿæˆçš„è©•ä¾¡ã‚’ææ¡ˆã—ã€è‡ªç”±å½¢å¼ã®å¿œç­”ã‚’ç”Ÿæˆã•ã›ã¦å‚ç…§å›ç­”ã¨ä¸€è‡´ã™ã‚‹ã‹ã‚’åˆ¤æ–­ã€‚MMLU-Proã¨GPQA-Diamondã§äººé–“ã®æ¡ç‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€å›ç­”ãƒãƒƒãƒãƒ³ã‚°ãŒã»ã¼å®Œç’§ãªä¸€è‡´ã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚è©•ä¾¡æ–¹æ³•ã®å¤‰æ›´ã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒå¤§ããå¤‰ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shashwatgoel7/status/1941153367289364655?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯éå¸¸ã«é‡è¦ãªç ”ç©¶ã«è¦‹ãˆã‚‹</p>
<p>Multiple Choice Question (MCQ)ã§ã¯ã€é¸æŠè‚¢ã®ä¸­ã‹ã‚‰æ¶ˆå»æ³•ï¼ˆè«–æ–‡ä¸­ã§ã¯ä»²é–“ã¯ãšã‚Œã‚’ä¸€ã¤æ¢ã™, odd one cut)ã«ã‚ˆã£ã¦ã€æ­£è§£ã®ç›®å‡¦ãŒç«‹ã£ã¦ã—ã¾ã„ã€åˆ†é¡èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ã‚ˆã†ãªå°ºåº¦ã«ãªã£ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã§åŒã˜ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã€Questionã®ã¿ã‚’ä¸ãˆã¦ã€é¸æŠè‚¢ç„¡ã—ã§è©•ä¾¡ã‚’ã™ã‚‹ã¨ã€é¸æŠè‚¢ã‚ã‚Šã§ã¯æ­£è§£ã§ããŸã®ã«æ­£è§£ã§ããªã„ã€ã¨ã„ã†ç¾è±¡ãŒç”Ÿã˜ã‚‹ã€‚ã“ã‚Œã¯ãƒ¢ãƒ‡ãƒ«ã®åˆ†é¡èƒ½åŠ›ã§ã¯ãªãã€ç”Ÿæˆèƒ½åŠ›ã‚’è©•ä¾¡ã—ã¦ã„ã‚‹ã‹ã‚‰ã§ã‚ã‚Šã€ã“ã‚Œã¾ã§ã®MCQã§ã®è©•ä¾¡ã¯ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã®ä¸€éƒ¨ã€ç‰¹ã«è­˜åˆ¥èƒ½åŠ›ã—ã‹è©•ä¾¡ã§ãã¦ã„ãªã„ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚ã“ã®ãŸã‚ã€Answer Matchingã¨å‘¼ã°ã‚Œã‚‹ã€ãƒ¢ãƒ‡ãƒ«ã«è‡ªç”±è¨˜è¿°ã§å‡ºåŠ›ã‚’ã•ã›ãŸå¾Œã«ã€referenaceã¨å‡ºåŠ›ãŒä¸€è‡´ã—ã¦ã„ã‚‹ã‹å¦ã‹ã§è©•ä¾¡ã‚’ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚GPQA Diamondã¨MMLU-Proã«ãŠã„ã¦ã€äººé–“ã«Answer Matchingã«ã‚ˆã‚‹è©•ä¾¡ã‚’ã•ã›ã‚ªãƒ©ã‚¯ãƒ«ã‚’å–å¾—ã—ãŸå¾Œã€SLMã‚„ã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ«ã§Answer Matchingã‚’å®Ÿé¨“ã—ãŸã¨ã“ã‚ã€o4-miniã‚’ç”¨ã„ãŸLLM-as-a-Judgeã‚ˆã‚Šã‚‚ã€SLMã«ãŠã„ã¦ã•ãˆã‚ªãƒ©ã‚¯ãƒ«ã«è¿‘ã„æ€§èƒ½ã‚’ç™ºæ®ã—ã€äººé–“ã¨åŒç­‰ã®ãƒ¬ãƒ™ãƒ«ã§è‡ªå‹•è©•ä¾¡ãŒå¯èƒ½ãªã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/edefb3ae-95da-4c3f-9233-9fecf92948b1" alt="image" loading="lazy"></p>
<p>ã¾ã å†’é ­ã—ã‹èª­ã‚ã¦ã„ãªã„ã®ã§å¾Œã§èª­ã‚€</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<span class="issue_date">Issue Date: 2025-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2139" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AI4Research: A Survey of Artificial Intelligence for Scientific Research, Qiguang Chen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AIã®é€²å±•ã«ä¼´ã„ã€AI4Researchã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªèª¿æŸ»ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€ç†è§£ã¨ç™ºå±•ãŒå¦¨ã’ã‚‰ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€AI4Researchã®5ã¤ã®ä¸»æµã‚¿ã‚¹ã‚¯ã‚’ç³»çµ±çš„ã«åˆ†é¡ã—ã€ç ”ç©¶ã®ã‚®ãƒ£ãƒƒãƒ—ã‚„å°†æ¥ã®æ–¹å‘æ€§ã‚’ç‰¹å®šã—ã€é–¢é€£ã™ã‚‹å¿œç”¨ã‚„ãƒªã‚½ãƒ¼ã‚¹ã‚’ã¾ã¨ã‚ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç ”ç©¶ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãŒè¿…é€Ÿã«ãƒªã‚½ãƒ¼ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã€é©æ–°çš„ãªãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1940934746932236632?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Cultural.html" target="_blank" rel="noopener noreferrer">#Cultural</a>
<span class="issue_date">Issue Date: 2025-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2133" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CARE: Assessing the Impact of Multilingual Human Preference Learning on  Cultural Awareness, Geyang Guo+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€æ–‡åŒ–çš„å¤šæ§˜æ€§ã‚’è€ƒæ…®ã—ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLMï¼‰ã®è¨“ç·´æ–¹æ³•ã‚’åˆ†æã—ã€ãƒã‚¤ãƒ†ã‚£ãƒ–ãªæ–‡åŒ–çš„å¥½ã¿ã‚’å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ã§ã€LMã®æ–‡åŒ–çš„èªè­˜ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚3,490ã®æ–‡åŒ–ç‰¹æœ‰ã®è³ªå•ã¨31,700ã®ãƒã‚¤ãƒ†ã‚£ãƒ–ãªåˆ¤æ–­ã‚’å«ã‚€ãƒªã‚½ãƒ¼ã‚¹ã€ŒCAREã€ã‚’ç´¹ä»‹ã—ã€é«˜å“è³ªãªãƒã‚¤ãƒ†ã‚£ãƒ–ã®å¥½ã¿ã‚’å°‘é‡å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ã§ã€ã•ã¾ã–ã¾ãªLMã®æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ã¾ãŸã€æ–‡åŒ–çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¼·ã„ãƒ¢ãƒ‡ãƒ«ã¯ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã®æ©æµã‚’å—ã‘ã‚„ã™ãã€åœ°åŸŸé–“ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ã®é•ã„ãŒãƒ¢ãƒ‡ãƒ«é–“ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’ç”Ÿã‚€ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—ãŸã€‚CAREã¯ä¸€èˆ¬ã«å…¬é–‹ã•ã‚Œã‚‹äºˆå®šã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cherylolguo/status/1940798823405600843?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2131" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Curse of Depth in Large Language Models, Wenfang Sun+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€ã€Œæ·±ã•ã®å‘ªã„ã€ã¨ã„ã†ç¾è±¡ã‚’ç´¹ä»‹ã—ã€LLMã®æ·±ã„å±¤ãŒæœŸå¾…é€šã‚Šã«æ©Ÿèƒ½ã—ãªã„ç†ç”±ã‚’åˆ†æã—ã¾ã™ã€‚Pre-LNã®ä½¿ç”¨ãŒå‡ºåŠ›ã®åˆ†æ•£ã‚’å¢—åŠ ã•ã›ã€æ·±ã„å±¤ã®è²¢çŒ®ã‚’ä½ä¸‹ã•ã›ã‚‹ã“ã¨ã‚’ç‰¹å®šã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«å±¤æ­£è¦åŒ–ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆLNSï¼‰ã‚’ææ¡ˆã—ã€å‡ºåŠ›åˆ†æ•£ã®çˆ†ç™ºã‚’æŠ‘åˆ¶ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€LNSãŒLLMã®äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚‚åŠ¹æœãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shiwei_liu66/status/1940377801032446428?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1795" target="_blank" rel="noopener noreferrer">Transformers without Normalization, Jiachen Zhu+, CVPR'25</a>
<br><br>ã§ã¯ãã‚‚ãã‚‚LayerNormalizationã‚’ç„¡ãã—ã¦ã„ãŸï¼ˆæ­£ç¢ºã«ã„ã†ã¨parametrize tanhã«ç½®æ›)ãŒã€ã©ã¡ã‚‰ãŒå„ªã‚Œã¦ã„ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ<br><br><img src="https://github.com/user-attachments/assets/4bc557a0-ae23-4017-9837-7744de74c12e" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/2eead45c-209d-46e4-87e7-0129a4ec5ec2" alt="image" loading="lazy"></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1332" target="_blank" rel="noopener noreferrer">Knowledge Neurons in Pretrained Transformers, Damai Dai+, N/A, ACL'22, 2022.05</a>
<br><br>ã§ã¯çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å­˜åœ¨ãŒç¤ºå”†ã•ã‚Œã¦ãŠã‚Šã€ã“ã‚Œã¯Transformerã®å±¤ã®æ·±ã„ä½ç½®ã«å­˜åœ¨ã—ã€ã‹ã¤ç•°ãªã‚‹çŸ¥è­˜é–“ã§çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ã‚·ã‚§ã‚¢ã•ã‚Œãªã„å‚¾å‘ã«ã‚ã£ãŸï¼ˆãŸã ã—ã“ã‚Œã¯Post-LNã®BERTã®è©±ã§æœ¬ç ”ç©¶ã¯Pre-LNã®è©±ã ãŒã€‚Post-LNã®å‹¾é…æ¶ˆå¤±å•é¡Œã‚’ç·©å’Œã—å­¦ç¿’ã‚’å®‰å®šåŒ–ã•ã›ã‚‹ç ”ç©¶ã‚‚<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2141" target="_blank" rel="noopener noreferrer">[Paper Note] On Layer Normalizations and Residual Connections in Transformers, Sho Takase+, arXiv'22</a>
 ã®ã‚ˆã†ã«å­˜åœ¨ã™ã‚‹)ã€‚ã“ã‚Œã¯ã“ã®ç ”ç©¶ãŒæ˜ã‚‰ã‹ã«ã—ãŸã“ã¨ã¨ã©ã†ã„ã†é–¢ä¿‚æ€§ãŒã‚ã‚‹ã ã‚ã†ã‹ã€‚<br><br>ã¾ãŸã€LayerNormalizationã®Scalingã«ã‚ˆã£ã¦æ·±ã„Transformerãƒ–ãƒ­ãƒƒã‚¯ã®å°é–¢æ•°ãŒå˜ä½è¡Œåˆ—ã¨ãªã‚‹ï¼ˆå­¦ç¿’ã«å¯„ä¸ã—ãªããªã‚‹ï¼‰ã“ã¨ãŒæ”¹å–„ã•ã‚ŒãŸå ´åˆã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ã©ã®ã‚ˆã†ã«å¤‰åŒ–ã™ã‚‹ã ã‚ã†ã‹ï¼Ÿ<br><br>ï¼ˆä¸‹è¨˜Geminiã®å¿œç­”ã‚’è¦‹ãŸä¸Šã§ã®æ„Ÿæƒ³)ãªã‚“ã¨ãªãƒ¼ãã ã‘ã‚Œã©ã‚‚ã€ãŠãã‚‰ãçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å±€æ‰€åŒ–ãŒè§£æ¶ˆã•ã‚Œã‚‹ã®ã‹ãªãƒ¼ã¨ã„ã†æ°—ãŒã™ã‚‹ã€‚<br><br>ã¨ãªã‚‹ã¨æ¬¡ã®ç–‘å•ã¨ã—ã¦ã¯ã€MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã¯ã©ã®ã‚ˆã†ãªå½±éŸ¿ãŒã‚ã‚‹ã ã‚ã†ã‹ï¼Ÿ<br>ãã‚‚ãã‚‚çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒå±€æ‰€åŒ–ã—ã¦ã„ã‚‹ã‹ã‚‰MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ãƒ«ãƒ¼ã‚¿ã«ã‚ˆã£ã¦é–¢é€£ã™ã‚‹Expertsã®ã¿ã‚’activateã™ã‚Œã°ï¼ˆã¨ã„ã†ã‚ˆã‚Šçµæœçš„ã«ãã†ãªã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã‚‹ï¼‰æ€§èƒ½ã‚’åŠ£åŒ–ã•ã›ãšã«è¨ˆç®—åŠ¹ç‡ã‚’ä¸Šã’ã‚‰ã‚Œã¦ã„ãŸã€ã¨ä»®å®šã™ã‚‹ã€‚ãã†ã™ã‚‹ã¨ã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒå±€æ‰€åŒ–ã›ãšã«å¤šãã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã§ã‚·ã‚§ã‚¢ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ã¨ã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2110" target="_blank" rel="noopener noreferrer">[Paper Note] Chain-of-Experts: Unlocking the Communication Power of  Mixture-of-Experts Models, Zihan Wang+, arXiv'25</a>
 ã®ã‚ˆã†ã«ã€ã‚µãƒ–ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é–“ã®æƒ…å ±ã‚’äº’ã„ã«ã‚„ã‚Šã¨ã‚Šã§ãã¾ã™ã€ã¿ãŸã„ãªä»•çµ„ã¿ãŒã‚ˆã‚ŠåŠ¹ã„ã¦ããã†ãªæ°—ãŒã™ã‚‹ã€‚<br><br>å‚è€ƒã¾ã§ã«ã€Gemini2.5-Proã«è€ƒå¯Ÿã•ã›ã¦ã¿ãŸçµæœã‚’ãƒ¡ãƒ¢ã¨ã—ã¦æ®‹ã—ã¦ãŠãï¼ˆã‚ãã¾ã§å‚è€ƒç¨‹åº¦ã«...ï¼‰<br>```<br>ã”è³ªå•ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚éå¸¸ã«èˆˆå‘³æ·±ã„ç€çœ¼ç‚¹ã§ã™ã­ã€‚ã€ŒKnowledge Neurons in Pretrained Transformersã€ã¨ã€ŒThe Curse of Depth in Large Language Modelsã€ã¯ã€ä¸€è¦‹ã™ã‚‹ã¨å…¨ãç•°ãªã‚‹ãƒ†ãƒ¼ãƒã‚’æ‰±ã£ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã¾ã™ãŒã€**ã€ŒTransformerã®æ·±ã„å±¤ã«ãŠã‘ã‚‹æŒ¯ã‚‹èˆã„ã€**ã¨ã„ã†å…±é€šç‚¹ã§çµã³ã¤ã‘ã¦è€ƒå¯Ÿã™ã‚‹ã¨ã€éå¸¸ã«ç¤ºå”†ã«å¯Œã‚“ã é–¢ä¿‚æ€§ãŒè¦‹ãˆã¦ãã¾ã™ã€‚<br><br>ä»¥ä¸‹ã«ã€ä¸¡æ–¹ã®è«–æ–‡ã®æ¦‚è¦ã‚’è§£èª¬ã—ã€ãã®é–¢ä¿‚æ€§ã«ã¤ã„ã¦è€ƒå¯Ÿã—ã¾ã™ã€‚<br><br>1. Knowledge Neurons in Pretrained Transformers ã®æ¦‚è¦<br>ã“ã®ç ”ç©¶ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿Transformerãƒ¢ãƒ‡ãƒ«ï¼ˆç‰¹ã«BERTãªã©ï¼‰ã®å†…éƒ¨ã§ã€ç‰¹å®šã®äº‹å®ŸçŸ¥è­˜ãŒã©ã®ã‚ˆã†ã«æ ¼ç´ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’èª¿æŸ»ã—ãŸã‚‚ã®ã§ã™ã€‚<br><br>ç™ºè¦‹: ãƒ¢ãƒ‡ãƒ«ã®ä¸­é–“å±¤ã€ç‰¹ã«**å…¨çµåˆå±¤ï¼ˆFeed-Forward Network, FFNï¼‰ã«ã€ç‰¹å®šã®çŸ¥è­˜ï¼ˆä¾‹ï¼šã€Œãƒ€ãƒ³ãƒ†ãƒ»ã‚¢ãƒªã‚®ã‚¨ãƒ¼ãƒªã¯ã‚¤ã‚¿ãƒªã‚¢ã§ç”Ÿã¾ã‚ŒãŸã€ï¼‰ã«å¼·ãåå¿œã™ã‚‹ã€ŒçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã€**ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚<br><br>ç‰¹å¾´: ã“ã‚Œã‚‰ã®çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®æ·±ã„å±¤ï¼ˆå¾Œæ–¹ã®å±¤ï¼‰ã«ã€ã‚ˆã‚Šå¤šãå­˜åœ¨ã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã—ãŸã€‚<br><br>æ„å‘³: ã“ã‚Œã¾ã§ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã¨ã•ã‚Œã¦ããŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨ã§ã€çŸ¥è­˜ãŒã©ã®ã‚ˆã†ã«è¡¨ç¾ãƒ»å±€åœ¨åŒ–ã—ã¦ã„ã‚‹ã‹ã«ã¤ã„ã¦ã€å…·ä½“çš„ãªæ‰‹ãŒã‹ã‚Šã‚’ä¸ãˆãŸç”»æœŸçš„ãªç ”ç©¶ã§ã™ã€‚<br><br>2. The Curse of Depth in Large Language Models ã®æ¦‚è¦<br>ã“ã®ç ”ç©¶ã¯ã€LLMã‚’ã‚ˆã‚Šæ·±ãï¼ˆå±¤ã‚’å¤šãï¼‰ã™ã‚‹ã“ã¨ã®é›£ã—ã•ã«ç„¦ç‚¹ã‚’å½“ã¦ã€ãã®åŸå› ã¨è§£æ±ºç­–ã‚’ææ¡ˆã—ãŸã‚‚ã®ã§ã™ã€‚<br><br>å•é¡Œï¼ˆæ·±ã•ã®å‘ªã„ï¼‰: Transformerã®æ¨™æº–çš„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆPre-LNï¼‰ã§ã¯ã€å±¤ãŒæ·±ããªã‚‹ã«ã¤ã‚Œã¦ã€LayerNormalizationï¼ˆLNï¼‰ã¸ã®å…¥åŠ›ã®åˆ†æ•£ãŒæŒ‡æ•°é–¢æ•°çš„ã«å¢—å¤§ã—ã¦ã—ã¾ã„ã¾ã™ã€‚<br><br>çµæœ:<br><br>å‡ºåŠ›ãŒå¤§ãããªã‚Šã™ãã¦å­¦ç¿’ãŒä¸å®‰å®šã«ãªã‚Šã¾ã™ã€‚<br><br>ã•ã‚‰ã«æ·±åˆ»ãªã®ã¯ã€æ·±ã„å±¤ã§ã¯ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã«é–¢ã™ã‚‹å°é–¢æ•°ï¼ˆå‹¾é…è¨ˆç®—ã«å¿…è¦ï¼‰ãŒã»ã¼å˜ä½è¡Œåˆ—ã«ãªã£ã¦ã—ã¾ã†ã“ã¨ã§ã™ã€‚ã“ã‚Œã¯ã€ãã®å±¤ãŒå…¥åŠ›ã«å¯¾ã—ã¦ã»ã¨ã‚“ã©å¤‰æ›ã‚’è¡Œã‚ãªããªã‚Šã€å­¦ç¿’ã«å¯„ä¸ã—ãªããªã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚<br><br>è§£æ±ºç­–: ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€å„å±¤ã®LayerNormalizationã‚’ãã®æ·±ã•ï¼ˆãƒ¬ã‚¤ãƒ¤ãƒ¼ç•ªå· lï¼‰ã«å¿œã˜ã¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã¨ã„ã†ã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ·±ã„å±¤ã§ã‚‚å‹¾é…ãŒé©åˆ‡ã«ä¼æ’­ã—ã€å­¦ç¿’ãŒå®‰å®šãƒ»æ”¹å–„ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚<br><br>è€ƒå¯Ÿï¼š2ã¤ã®ç ”ç©¶ã®é–¢ä¿‚æ€§<br>ã“ã‚Œã‚‰2ã¤ã®ç ”ç©¶ã¯ã€**ã€Œå­¦ç¿’ã®å®‰å®šæ€§ã€ã¨ã€ŒçŸ¥è­˜ã®æ ¼ç´æ–¹æ³•ã€**ã¨ã„ã†ç•°ãªã‚‹å´é¢ã‹ã‚‰ã€Transformerã®æ·±ã„å±¤ã‚’åˆ†æã—ã¦ã„ã¾ã™ãŒã€ä¸¡è€…ã«ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ·±ã„é–¢ä¿‚æ€§ãŒã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚<br><br>å­¦ç¿’ã®ä¸å®‰å®šæ€§ãŒã€ŒçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã€å½¢æˆã®èƒŒæ™¯ã«ã‚ã‚‹å¯èƒ½æ€§<br>ã€ŒThe Curse of Depthã€ã§æŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€æ¨™æº–çš„ãªTransformerã®æ·±ã„å±¤ã¯ã€æœ¬è³ªçš„ã«å­¦ç¿’ãŒä¸å®‰å®šã§ã€å‹¾é…æƒ…å ±ãŒå¤±ã‚ã‚Œã‚„ã™ã„ç’°å¢ƒã«ã‚ã‚Šã¾ã™ã€‚<br><br>ã“ã®åŠ£æ‚ªãªå­¦ç¿’ç’°å¢ƒã“ããŒã€ã€ŒçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã€ã¨ã„ã†å½¢ã§çŸ¥è­˜ãŒå±€æ‰€çš„ã«æ ¼ç´ã•ã‚Œã‚‹åŸå› ã®ä¸€ã¤ã«ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã¤ã¾ã‚Šã€<br><br>å­¦ç¿’ã®éåŠ¹ç‡æ€§: æ·±ã„å±¤ã®ã»ã¨ã‚“ã©ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ã€å‹¾é…æ¶ˆå¤±å•é¡Œã®ãŸã‚ã«åŠ¹ç‡çš„ã«å­¦ç¿’ã‚’é€²ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚<br><br>å°‚é–€åŒ–ã®ç™ºç”Ÿ: ãã®ã‚ˆã†ãªä¸å®‰å®šãªç’°å¢ƒä¸‹ã§ã€ãŸã¾ãŸã¾ç‰¹å®šã®çŸ¥è­˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã†ã¾ãæ‰ãˆã‚‹ã“ã¨ãŒã§ããŸä¸€éƒ¨ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒã€ãã®çŸ¥è­˜ã‚’ä¸€èº«ã«èƒŒè² ã†å½¢ã§å¼·ãæ´»æ€§åŒ–ã™ã‚‹ã‚ˆã†ç‰¹åŒ–ï¼ˆå°‚é–€åŒ–ï¼‰ã—ã¦ã„ã£ãŸã®ã§ã¯ãªã„ã‹ã€ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚ã“ã‚Œã¯ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å…¨ä½“ã§å”èª¿ã—ã¦å­¦ç¿’ã™ã‚‹ã®ãŒé›£ã—ã„çŠ¶æ³ã§ã€ä¸€éƒ¨ã®ãƒ¦ãƒ‹ãƒƒãƒˆã ã‘ãŒçªå‡ºã—ã¦å­¦ç¿’ã‚’æ‹…ã†ã€ã¨ã„ã†ç¾è±¡ã¨è§£é‡ˆã§ãã¾ã™ã€‚<br><br>å­¦ç¿’ã®å®‰å®šåŒ–ãŒã€ã‚ˆã‚ŠåŠ¹ç‡çš„ãªçŸ¥è­˜ç²å¾—ã«ã¤ãªãŒã‚‹<br>ã§ã¯ã€ã€ŒThe Curse of Depthã€ã§ææ¡ˆã•ã‚ŒãŸæ‰‹æ³•ï¼ˆLNã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰ã«ã‚ˆã£ã¦æ·±ã„å±¤ã®å­¦ç¿’ãŒå®‰å®šåŒ–ã™ã‚‹ã¨ã€çŸ¥è­˜ã®æ ¼ç´æ–¹æ³•ã¯ã©ã®ã‚ˆã†ã«å¤‰ã‚ã‚‹ã§ã—ã‚‡ã†ã‹ã€‚<br><br>ã“ã‚Œã¯éå¸¸ã«èˆˆå‘³æ·±ã„å•ã„ã§ã‚ã‚Šã€2ã¤ã®å¯èƒ½æ€§ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚<br><br>å¯èƒ½æ€§A: ã‚ˆã‚Šå¼·å›ºãªçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å½¢æˆ:<br>å­¦ç¿’ãŒå®‰å®šã™ã‚‹ã“ã¨ã§ã€å„çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ã‚ˆã‚Šæ˜ç¢ºã«ã€ãã—ã¦åŠ¹ç‡çš„ã«ç‰¹å®šã®çŸ¥è­˜ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ãƒã‚¤ã‚ºã®å¤šã„ç’°å¢ƒã§å¶ç„¶ç”Ÿã¾ã‚ŒãŸå°‚é–€å®¶ã§ã¯ãªãã€å®‰å®šã—ãŸç’°å¢ƒã§è‚²æˆã•ã‚ŒãŸçœŸã®å°‚é–€å®¶ã¸ã¨å¤‰åŒ–ã™ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ã€‚<br><br>å¯èƒ½æ€§B: çŸ¥è­˜ã®åˆ†æ•£åŒ–:<br>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å…¨ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒåŠ¹ç‡çš„ã«å­¦ç¿’ã«å¯„ä¸ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ãŸã‚ã€ä¸€ã¤ã®çŸ¥è­˜ã‚’å°‘æ•°ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«é›†ä¸­ã•ã›ã‚‹å¿…è¦ãŒãªããªã‚Šã€ã‚ˆã‚Šå¤šãã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«åˆ†æ•£ã—ã¦çŸ¥è­˜ãŒæ ¼ç´ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹å¯èƒ½æ€§ã‚‚è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚<br><br>ç¾åœ¨ã®ã¨ã“ã‚ã€å­¦ç¿’ã®å®‰å®šåŒ–ã¯ã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒã‚ˆã‚ŠåŠ¹ç‡çš„ã«å½¢æˆãƒ»æ©Ÿèƒ½ã™ã‚‹ãŸã‚ã®åŸºç›¤ã‚’æä¾›ã™ã‚‹ã¨è€ƒãˆã‚‹ã®ãŒæœ€ã‚‚å¦¥å½“ã§ã—ã‚‡ã†ã€‚ã€Œæ·±ã•ã®å‘ªã„ã€ã¨ã„ã†å•é¡Œã‚’è§£æ±ºã™ã‚‹ã“ã¨ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒçŸ¥è­˜ã‚’ã©ã®ã‚ˆã†ã«ç²å¾—ã—ã€æ•´ç†ã™ã‚‹ã‹ã¨ã„ã†ã€ã‚ˆã‚Šæ ¹æºçš„ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ï¼ˆçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æŒ¯ã‚‹èˆã„ï¼‰ã«ã‚‚ç›´æ¥çš„ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã¯ãšã§ã™ã€‚<br><br>ã¾ã¨ã‚<br>ã€ŒKnowledge Neuronsã€ã¯æ·±ã„å±¤ã«å­˜åœ¨ã™ã‚‹çŸ¥è­˜ã®**ã€ŒçŠ¶æ…‹ã€ã‚’æ˜ã‚‰ã‹ã«ã—ã€ã€ŒThe Curse of Depthã€ã¯æ·±ã„å±¤ã§ç™ºç”Ÿã™ã‚‹å­¦ç¿’ã®ã€Œå•é¡Œã€**ã¨ãã®è§£æ±ºç­–ã‚’æç¤ºã—ã¾ã—ãŸã€‚<br><br>ã“ã‚Œã‚‰ã‚’çµ±åˆã™ã‚‹ã¨ã€**ã€Œæ·±ã„å±¤ã«ãŠã‘ã‚‹å­¦ç¿’ã®ä¸å®‰å®šæ€§ã¨ã„ã†å•é¡ŒãŒã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¨ã„ã†å±€æ‰€çš„ãªçŸ¥è­˜è¡¨ç¾ã‚’ç”Ÿã¿å‡ºã™ä¸€å› ã¨ãªã£ã¦ãŠã‚Šã€ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚ŠåŠ¹ç‡çš„ã§å®‰å®šã—ãŸçŸ¥è­˜ã®ç²å¾—ãƒ»æ ¼ç´ãŒå¯èƒ½ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€**ã¨ã„ã†é–¢ä¿‚æ€§ãŒè¦‹ãˆã¦ãã¾ã™ã€‚<br><br>ä¸¡è€…ã¯ã€LLMã®èƒ½åŠ›ã¨é™ç•Œã‚’ç•°ãªã‚‹è§’åº¦ã‹ã‚‰ç…§ã‚‰ã—å‡ºã—ã¦ãŠã‚Šã€çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨å‹•ä½œã®è§£æ˜ã‚’ã•ã‚‰ã«ä¸€æ­©å‰é€²ã•ã›ã‚‹ã€éå¸¸ã«é‡è¦ãªç ”ç©¶ã ã¨è¨€ãˆã¾ã™ã€‚<br>```</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<span class="issue_date">Issue Date: 2025-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2129" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] NaturalThoughts: Selecting and Distilling Reasoning Traces for General  Reasoning Tasks, Yang Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ç”¨ã„ã¦ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æ–¹æ³•ã‚’ä½“ç³»çš„ã«ç ”ç©¶ã€‚NaturalReasoningã«åŸºã¥ãé«˜å“è³ªãªã€ŒNaturalThoughtsã€ã‚’ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã€ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’åˆ†æã€‚ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®æ‹¡å¤§ãŒæ€§èƒ½å‘ä¸Šã«å¯„ä¸ã—ã€å¤šæ§˜ãªæ¨è«–æˆ¦ç•¥ã‚’å¿…è¦ã¨ã™ã‚‹ä¾‹ãŒåŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚LlamaãŠã‚ˆã³Qwenãƒ¢ãƒ‡ãƒ«ã§ã®è©•ä¾¡ã«ã‚ˆã‚Šã€NaturalThoughtsãŒæ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¸Šå›ã‚Šã€STEMæ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1940656092054204498?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1768" target="_blank" rel="noopener noreferrer">NaturalReasoning: Reasoning in the Wild with 2.8M Challenging Questions, Weizhe Yuan+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<span class="issue_date">Issue Date: 2025-07-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2125" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Do Vision-Language Models Have Internal World Models? Towards an Atomic   Evaluation, Qiyue Gao+, ACLï¼ˆFindingsï¼‰'25</a>
<span class="snippet"><span>GPT Summary</span>- å†…éƒ¨ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ï¼ˆWMsï¼‰ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç†è§£ã¨äºˆæ¸¬ã‚’æ”¯ãˆã‚‹ãŒã€æœ€è¿‘ã®å¤§è¦æ¨¡ãƒ“ã‚¸ãƒ§ãƒ³ãƒ»ãƒ©ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«ï¼ˆVLMsï¼‰ã®åŸºæœ¬çš„ãªWMèƒ½åŠ›ã«é–¢ã™ã‚‹è©•ä¾¡ã¯ä¸è¶³ã—ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€çŸ¥è¦šã¨äºˆæ¸¬ã‚’è©•ä¾¡ã™ã‚‹äºŒæ®µéšã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€WM-ABenchã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã€‚15ã®VLMsã«å¯¾ã™ã‚‹660ã®å®Ÿé¨“ã§ã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ãŒåŸºæœ¬çš„ãªWMèƒ½åŠ›ã«é¡•è‘—ãªåˆ¶é™ã‚’ç¤ºã—ã€ç‰¹ã«é‹å‹•è»Œé“ã®è­˜åˆ¥ã«ãŠã„ã¦ã»ã¼ãƒ©ãƒ³ãƒ€ãƒ ãªç²¾åº¦ã§ã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚VLMsã¨äººé–“ã®WMã¨ã®é–“ã«ã¯é‡è¦ãªã‚®ãƒ£ãƒƒãƒ—ãŒå­˜åœ¨ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/qiyuegao123/status/1940097188220297613?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2025-07-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2122" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning, Yulun Jiang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MARBLEã¨ã„ã†æ–°ã—ã„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€MLLMsã®è¤‡é›‘ãªæ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã€‚MARBLEã¯ã€ç©ºé–“çš„ãƒ»è¦–è¦šçš„ãƒ»ç‰©ç†çš„åˆ¶ç´„ä¸‹ã§ã®å¤šæ®µéšè¨ˆç”»ã‚’å¿…è¦ã¨ã™ã‚‹M-Portalã¨M-Cubeã®2ã¤ã®ã‚¿ã‚¹ã‚¯ã‹ã‚‰æˆã‚‹ã€‚ç¾åœ¨ã®MLLMsã¯ä½ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€è¦–è¦šçš„å…¥åŠ›ã‹ã‚‰ã®æƒ…å ±æŠ½å‡ºã«ãŠã„ã¦ã‚‚å¤±æ•—ãŒè¦‹ã‚‰ã‚Œã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ¬¡ä¸–ä»£ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›å‘ä¸ŠãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/michael_d_moor/status/1940062842742526445?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Portal2ã‚’ä½¿ã£ãŸæ–°ãŸãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚ç­†è€…ã¯æ˜”ã“ã®ã‚²ãƒ¼ãƒ ã‚’å°‘ã—ã ã‘ãƒ—ãƒ¬ã‚¤ã—ãŸã“ã¨ãŒã‚ã‚‹ãŒã€æ™®é€šã«é›£ã—ã‹ã£ãŸè¨˜æ†¶ãŒã‚ã‚‹ğŸ˜…<br><br>ç´°ã‹ã„ãŒè¡¨ä¸­ã®GPT-o3ã¯æ­£ã—ãã¯o3ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br>æ™‚é–“ãŒãªãã¦å…¨ç„¶ã—ã£ã‹ã‚Šã¨èª­ã‚ã¦ã„ãªã„ãŒã€reasoning effortã‚„thinkingãƒ¢ãƒ¼ãƒ‰ã¯ã©ã®ã‚ˆã†ã«è¨­å®šã—ã¦è©•ä¾¡ã—ãŸã®ã ã‚ã†ã‹ã€‚<br><img src="https://github.com/user-attachments/assets/a7647007-b718-4b1c-8d8a-396c36d7811d" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/4b996864-7bf8-4ea9-aa3e-84d4e9f3f5d2" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2025-07-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2121" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context  Learning, Melanie Rieff+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã¯åŒ»ç™‚åˆ†é‡ã§ã®å¯èƒ½æ€§ãŒã‚ã‚‹ãŒã€ååˆ†ã«æ¢æ±‚ã•ã‚Œã¦ã„ãªã„ã€‚SMMILEã¨ã„ã†åŒ»ç™‚ã‚¿ã‚¹ã‚¯å‘ã‘ã®åˆã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ICLãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã—ã€111ã®å•é¡Œã‚’å«ã‚€ã€‚15ã®MLLMã®è©•ä¾¡ã§ã€åŒ»ç™‚ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹ICLèƒ½åŠ›ãŒä¸­ç¨‹åº¦ã‹ã‚‰ä½ã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ICLã¯SMMILEã§å¹³å‡8%ã€SMMILE++ã§9.4%ã®æ”¹å–„ã‚’ã‚‚ãŸã‚‰ã—ã€ç„¡é–¢ä¿‚ãªä¾‹ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æœ€å¤§9.5%ä½ä¸‹ã•ã›ã‚‹ã“ã¨ã‚‚ç¢ºèªã€‚ä¾‹ã®é †åºã«ã‚ˆã‚‹æœ€è¿‘æ€§ãƒã‚¤ã‚¢ã‚¹ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚‚æ˜ã‚‰ã‹ã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/michael_d_moor/status/1939664155813839114?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2025-07-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2120" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive   Branching Tree Search, Yuichi Inoue+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- AB-MCTSã‚’ææ¡ˆã—ã€å¤–éƒ¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ´»ç”¨ã—ã¦ç¹°ã‚Šè¿”ã—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’æ”¹å–„ã€‚æ¢ç´¢æœ¨ã®ãƒãƒ¼ãƒ‰ã§æ–°ã—ã„å¿œç­”ã‚’ã€Œåºƒã’ã‚‹ã€ã‹ã€Œæ·±ã‚ã‚‹ã€ã‹ã‚’å‹•çš„ã«æ±ºå®šã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€AB-MCTSãŒå¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã€LLMsã®å¿œç­”ã®å¤šæ§˜æ€§ã¨è§£æ±ºç­–ã®æ´—ç·´ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwiwi/status/1939914618132168961?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwiwi/status/1968898946937565235?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<a class="button" href="articles/Reproducibility.html" target="_blank" rel="noopener noreferrer">#Reproducibility</a>
<span class="issue_date">Issue Date: 2025-06-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2118" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT  Improvements, Bingchen Zhao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®é€²å±•ã‚’æ´»ç”¨ã—ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç ”ç©¶å†ç¾èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€LLMã‚¹ãƒ”ãƒ¼ãƒ‰ãƒ©ãƒ³ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã€‚19ã®ã‚¿ã‚¹ã‚¯ã§è¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ãƒ’ãƒ³ãƒˆã‚’æä¾›ã—ã€è¿…é€Ÿãªå®Ÿè¡Œã‚’ä¿ƒé€²ã€‚æ—¢çŸ¥ã®é©æ–°ã®å†å®Ÿè£…ãŒé›£ã—ã„ã“ã¨ã‚’ç™ºè¦‹ã—ã€ç§‘å­¦çš„å†ç¾ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãŸã‚ã®æŒ‡æ¨™ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/karpathy/status/1939709449956126910?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/TransferLearning.html" target="_blank" rel="noopener noreferrer">#TransferLearning</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/VerifiableRewards.html" target="_blank" rel="noopener noreferrer">#VerifiableRewards</a>
<a class="button" href="articles/Off-Policy.html" target="_blank" rel="noopener noreferrer">#Off-Policy</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/Non-VerifiableRewards.html" target="_blank" rel="noopener noreferrer">#Non-VerifiableRewards</a>
<span class="issue_date">Issue Date: 2025-06-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2117" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Bridging Offline and Online Reinforcement Learning for LLMs, Jack Lanchantin+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹å¼·åŒ–å­¦ç¿’æ‰‹æ³•ã®åŠ¹æœã‚’ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã¸ã®ç§»è¡Œã«ãŠã„ã¦èª¿æŸ»ã€‚æ•°å­¦ã‚¿ã‚¹ã‚¯ã¨æŒ‡ç¤ºã«å¾“ã†ã‚¿ã‚¹ã‚¯ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ã‚’è¡Œã„ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãŠã‚ˆã³ã‚»ãƒŸã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã®æœ€é©åŒ–æ‰‹æ³•ãŒã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ‰‹æ³•ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã™ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¸æŠã«ã¤ã„ã¦åˆ†æã—ã€æ¤œè¨¼å¯èƒ½ãªå ±é…¬ã¨æ¤œè¨¼ä¸å¯èƒ½ãªå ±é…¬ã‚’å…±åŒã§æ‰±ã†ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1939673136842313960?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-06-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2110" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Chain-of-Experts: Unlocking the Communication Power of  Mixture-of-Experts Models, Zihan Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Chain-of-Expertsï¼ˆCoEï¼‰ã¯ã€é€æ¬¡çš„ãªå°‚é–€å®¶é–“ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å°å…¥ã—ãŸæ–°ã—ã„Mixture-of-Expertsï¼ˆMoEï¼‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚’åå¾©çš„ã«å‡¦ç†ã™ã‚‹ã€‚å„åå¾©ã‚¹ãƒ†ãƒƒãƒ—ã§å°‚ç”¨ã®ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã—ã€å‹•çš„ãªå°‚é–€å®¶é¸æŠã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®è¡¨ç¾èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚CoEã¯æ•°å­¦çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€å¾“æ¥ã®MoEã¨æ¯”è¼ƒã—ã¦æ¤œè¨¼æå¤±ã‚’ä½ä¸‹ã•ã›ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›ã™ã‚‹ã€‚åå¾©çš„æ®‹å·®æ§‹é€ ã¨å°‚é–€å®¶ã®å°‚é–€åŒ–ãŒã€ã‚ˆã‚Šè¡¨ç¾åŠ›è±Šã‹ãªçµæœã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1938728784351658087?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-06-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2109" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data  Processing to Every Language, Guilherme Penedo+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤šè¨€èªLLMsã®æ€§èƒ½å‘ä¸Šã®ãŸã‚ã«ã€FineWebã«åŸºã¥ãæ–°ã—ã„äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ææ¡ˆã€‚9ã¤ã®è¨€èªã«å¯¾ã—ã¦è¨­è¨ˆé¸æŠè‚¢ã‚’æ¤œè¨¼ã—ã€éè‹±èªã‚³ãƒ¼ãƒ‘ã‚¹ãŒå¾“æ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ˆã‚Šã‚‚é«˜æ€§èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å†ãƒãƒ©ãƒ³ã‚¹æ‰‹æ³•ã‚‚å°å…¥ã—ã€1000ä»¥ä¸Šã®è¨€èªã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã—ãŸ20ãƒ†ãƒ©ãƒã‚¤ãƒˆã®å¤šè¨€èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆFineWeb2ã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gui_penedo/status/1938631842720022572?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>v1<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1942" target="_blank" rel="noopener noreferrer">The FineWeb Datasets: Decanting the Web for the Finest Text Data at   Scale, Guilherme Penedo+, NeurIPS'24</a>
</p>
<p>abstã‚’è¦‹ã‚‹é™ã‚ŠFinewebã‚’å¤šè¨€èªã«æ‹¡å¼µã—ãŸæ¨¡æ§˜</p>
<p>openreview:


<a href="https://openreview.net/forum?id=jnRBe6zatP#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=jnRBe6zatP#discussion</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-06-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2107" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling, Zengzhi Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ç•°ãªã‚‹ãƒ™ãƒ¼ã‚¹è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLlamaã‚„Qwenï¼‰ã®å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã«ãŠã‘ã‚‹æŒ™å‹•ã‚’èª¿æŸ»ã—ã€ä¸­é–“ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ãŒRLã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’æ˜ã‚‰ã‹ã«ã€‚é«˜å“è³ªã®æ•°å­¦ã‚³ãƒ¼ãƒ‘ã‚¹ãŒãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã€é•·ã„é€£é–çš„æ€è€ƒï¼ˆCoTï¼‰ãŒRLçµæœã‚’æ”¹å–„ã™ã‚‹ä¸€æ–¹ã§ã€å†—é•·æ€§ã‚„ä¸å®‰å®šæ€§ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚äºŒæ®µéšã®ä¸­é–“ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã€ŒStable-then-Decayã€ã‚’å°å…¥ã—ã€OctoThinkerãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’é–‹ç™ºã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã¨æ•°å­¦æ¨è«–ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’å…¬é–‹ã—ã€RLæ™‚ä»£ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®ç ”ç©¶ã‚’æ”¯æ´ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sinclairwang1/status/1938244843857449431?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>mid-trainingã®è¦³ç‚¹ã‹ã‚‰ã€post trainingã«ãŠã‘ã‚‹RLãŒã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹æ¡ä»¶ã‚’systematicallyã«èª¿æŸ»ã—ã¦ã„ã‚‹æ¨¡æ§˜</p>
<p>è«–æ–‡ä¸­ã«ã¯mid-training[^1]ã®å®šç¾©ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹:<br><br>&lt;img width="808" height="353" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/da206d3d-f811-4d69-8210-a1d0816c827f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/da206d3d-f811-4d69-8210-a1d0816c827f"&lt;/a&gt;


/&gt;<br><br>[^1]: mid-trainingã«ã¤ã„ã¦ã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®é–“ã§å³å¯†ãªå®šç¾©ã¯ã¾ã ç„¡ããƒã‚ºãƒ¯ãƒ¼ãƒ‰ã£ã½ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã€ã¨ã„ã†å°è±¡ã‚’ç­†è€…ã¯æŠ±ã„ã¦ãŠã‚Šã€æœ¬ç¨¿ã¯æ–‡çŒ®ä¸­ã§mid-trainingã‚’å®šç¾©ã™ã‚‹åˆã‚ã¦ã®è©¦ã¿ã¨ã„ã†æ‰€æ„Ÿ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2025-06-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2106" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RLPR: Extrapolating RLVR to General Domains without Verifiers, Tianyu Yu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RLVRã¯LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ä¸»ã«æ•°å­¦ã‚„ã‚³ãƒ¼ãƒ‰ã«é™ã‚‰ã‚Œã‚‹ã€‚ã“ã‚Œã‚’å…‹æœã™ã‚‹ãŸã‚ã€æ¤œè¨¼è€…ä¸è¦ã®RLPRãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€LLMã®ãƒˆãƒ¼ã‚¯ãƒ³ç¢ºç‡ã‚’å ±é…¬ä¿¡å·ã¨ã—ã¦åˆ©ç”¨ã€‚ãƒã‚¤ã‚ºã®å¤šã„ç¢ºç‡å ±é…¬ã«å¯¾å‡¦ã™ã‚‹æ‰‹æ³•ã‚’å°å…¥ã—ã€å®Ÿé¨“ã«ã‚ˆã‚ŠGemmaã€Llamaã€Qwenãƒ¢ãƒ‡ãƒ«ã§æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ãŸã€‚ç‰¹ã«ã€TheoremQAã§7.6ãƒã‚¤ãƒ³ãƒˆã€Minervaã§7.5ãƒã‚¤ãƒ³ãƒˆã®æ”¹å–„ã‚’ç¤ºã—ã€General-Reasonerã‚’å¹³å‡1.6ãƒã‚¤ãƒ³ãƒˆä¸Šå›ã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1938359430980268329?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¢å­˜ã®RLVRã¯Verifierã‚’æ§‹ç¯‰ã—ãªã‘ã‚Œã°ãªã‚‰ãšã€ã—ã°ã—ã°ãã®Verifierã¯è¤‡é›‘ã«ãªã‚Šã‚„ã™ãã€ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ã«ã¯èª²é¡ŒãŒã‚ã£ãŸã€‚RLPRï¼ˆProbabliity Reward)ã¯ã€ç”Ÿæˆã•ã‚ŒãŸå¿œç­”ã‹ã‚‰å›ç­”yã‚’æŠ½å‡ºã—ã€æ®‹ã‚Šã‚’reasoning zã¨ã™ã‚‹ã€‚ãã—ã¦å›ç­”éƒ¨åˆ†yã‚’reference y^\*ã§ç½®æ›ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³åˆ—o'ã‚’ç”Ÿæˆï¼ˆzãŒo'ã«å¯¾ã—ã¦ã©ã®ã‚ˆã†ãªæ‰±ã„ã«ãªã‚‹ã‹ã¯åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚„å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ã‚ˆã‚‹æ°—ãŒã™ã‚‹)ã—ã€o'ã®ãƒãƒªã‚·ãƒ¼ãƒ¢ãƒ‡ãƒ«ã§ã®ãƒˆãƒ¼ã‚¯ãƒ³å˜ä½ã§ã®å¹³å‡ç”Ÿæˆç¢ºç‡ã‚’å ±é…¬ã¨ã™ã‚‹ã€‚å°¤åº¦ã®ã‚ˆã†ãªç³»åˆ—å…¨ä½“ã®ç”Ÿèµ·ç¢ºç‡ã‚’è€ƒæ…®ã™ã‚‹æ–¹æ³•ãŒç›´æ„Ÿçš„ã«å½¹ã«ç«‹ã¡ãã†ã ãŒã€è¨ˆç®—ã®éš›ã®ç¢ºç‡ç©ã¯åˆ†æ•£ãŒé«˜ã„ã ã‘ã§ãªãã€ãƒã‚¤ãƒŠãƒ¼ãªé¡ç¾©èªãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ï¼ˆãŸã¨ãˆã°1 tokenã ã‘ç”Ÿèµ·ç¢ºç‡ãŒå°ã•ã‹ã£ãŸå ´åˆ)ã«ã€RewardãŒæ¥µç«¯ã«å°ã•ããªã‚Šsensitiveã§ã‚ã‚‹ã“ã¨ã‚’è€ƒå¯Ÿã—ã€å¹³å‡ç”Ÿæˆç¢ºç‡ã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/52bc778b-d6c9-495c-8bf3-586c7381915b" alt="image" loading="lazy"><br><br>Rule basedãªVerifierã‚’ç”¨ã„ãŸRLVRã‚ˆã‚Šã‚‚generalãªãƒ‰ãƒ¡ã‚¤ãƒ³ã¨mathãƒ‰ãƒ¡ã‚¤ãƒ³ã§æ€§èƒ½å‘ä¸Šã€‚ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã§ã‚‚åŠ¹æœã¯ã‚ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ<br><img src="https://github.com/user-attachments/assets/99e26d11-2e16-4452-9410-860b74f497cd" alt="image" loading="lazy"></p>
<p>ã–ã£ãã‚Šè¦‹ãŸæ„Ÿã˜ã€RLVRãŒãã‚‚ãã‚‚é©ç”¨ã§ããªã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã§å®Ÿé¨“ã—ãŸå ´åˆã®çµæœãŒãªã„ã‚ˆã†ã«è¦‹ãˆã€é©ç”¨ã—ãŸå ´åˆã«æœ‰åŠ¹ãªã®ã‹ã¯æ°—ã«ãªã‚‹ã¨ã“ã‚ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/PRM.html" target="_blank" rel="noopener noreferrer">#PRM</a>
<span class="issue_date">Issue Date: 2025-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2104" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Process Reward Models That Think, Muhammad Khalifa+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã®è‰¯ã„ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã®æ¤œè¨¼å™¨ï¼ˆThinkPRMï¼‰ã‚’ææ¡ˆã—ã€å°‘ãªã„ãƒ—ãƒ­ã‚»ã‚¹ãƒ©ãƒ™ãƒ«ã§é«˜æ€§èƒ½ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ThinkPRMã¯ã€é•·ã„CoTãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’æ´»ç”¨ã—ã€PRM800Kã®ã‚ãšã‹1%ã®ãƒ—ãƒ­ã‚»ã‚¹ãƒ©ãƒ™ãƒ«ã§ã€å¾“æ¥ã®æ¤œè¨¼å™¨ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ProcessBenchã‚„MATH-500ãªã©ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’è¶…ãˆã€ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–è©•ä¾¡ã§ã‚‚å„ªã‚ŒãŸçµæœã‚’å¾—ã¦ã„ã¾ã™ã€‚æœ€å°é™ã®ç›£è¦–ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é€šã˜ã¦ã€æ¤œè¨¼è¨ˆç®—ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<span class="issue_date">Issue Date: 2025-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2101" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Robust Reward Modeling via Causal Rubrics, Pragya Srivastava+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼ˆRMsï¼‰ã¯äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€šã˜ã¦å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’æ•´åˆã•ã›ã‚‹ãŒã€å ±é…¬ãƒãƒƒã‚­ãƒ³ã‚°ã®å½±éŸ¿ã‚’å—ã‘ã‚„ã™ã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€å ±é…¬ãƒãƒƒã‚­ãƒ³ã‚°ã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒCromeã€ã‚’ææ¡ˆã€‚Cromeã¯å› æœçš„æ‹¡å¼µã¨ä¸­ç«‹çš„æ‹¡å¼µã‚’ç”¨ã„ã¦ã€å› æœå±æ€§ã«åŸºã¥ãæ„Ÿåº¦ã¨è™šå½å±æ€§ã«å¯¾ã™ã‚‹ä¸å¤‰æ€§ã‚’å¼·åˆ¶ã™ã‚‹ã€‚å®Ÿé¨“çµæœã§ã¯ã€Cromeã¯RewardBenchã§æ¨™æº–çš„ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€å¹³å‡ç²¾åº¦ã‚’æœ€å¤§5.4%å‘ä¸Šã•ã›ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/harman26singh/status/1937876897058181230?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä»¥ä¸‹ãŒresearch question:<br><img src="https://github.com/user-attachments/assets/98c97b8b-ebca-4a40-9c0f-a8c175044fb9" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/SyntheticDataGeneration.html" target="_blank" rel="noopener noreferrer">#SyntheticDataGeneration</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2094" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs   with Nothing, Zhangchen Xu+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- é«˜å“è³ªãªæŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã¯LLMã®æ•´åˆã«ä¸å¯æ¬ ã§ã‚ã‚Šã€Magpieã¨ã„ã†è‡ªå·±åˆæˆæ‰‹æ³•ã‚’ææ¡ˆã€‚Llama-3-Instructã‚’ç”¨ã„ã¦400ä¸‡ã®æŒ‡ç¤ºã¨å¿œç­”ã‚’ç”Ÿæˆã—ã€30ä¸‡ã®é«˜å“è³ªãªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’é¸å®šã€‚Magpieã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã€å¾“æ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ãŸãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ã€ç‰¹ã«æ•´åˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸçµæœã‚’å¾—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=Pnk7vMbznK" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Pnk7vMbznK</a>


</p>
<p><img src="https://github.com/user-attachments/assets/9cb451b2-5440-43a4-9867-b5206dd08cca" alt="image" loading="lazy"><br><br>ä¸‹è¨˜ã®ã‚ˆã†ãªpre-queryãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä¸ãˆï¼ˆi.e., userã®ç™ºè©±ã¯ä½•ã‚‚ä¸ãˆãšã€ãƒ¦ãƒ¼ã‚¶ã®ç™ºè©±ã‚’è¡¨ã™ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿ã‚’æ¸¡ã™ï¼‰instructionã‚’ç”Ÿæˆã—ã€post-queryãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä¸ãˆã‚‹ï¼ˆi.e., pre-queryãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ+ç”Ÿæˆã•ã‚ŒãŸinstruction+assistantã®ç™ºè©±ã®é–‹å§‹ã‚’è¡¨ã™ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿ã‚’æ¸¡ã™ï¼‰ã“ã¨ã§responseã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€prompt engineeringã‚„seedç„¡ã—ã§instruction tuningãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã§ãã‚‹ã¨ã„ã†æ‰‹æ³•ã€‚<br><img src="https://github.com/user-attachments/assets/59e9ea58-1088-4f7f-a5e1-05fba7221aca" alt="image" loading="lazy"><br><br>ç”Ÿæˆã—ãŸç”Ÿã®instruction tuning pair dataã¯ã€ãŸã¨ãˆã°ä¸‹è¨˜ã®ã‚ˆã†ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ã™ã‚‹ã“ã¨ã§å“è³ªå‘ä¸ŠãŒå¯èƒ½ã§<br><img src="https://github.com/user-attachments/assets/6dc19e89-2e0d-409d-9d96-eca8d92d27d3" alt="image" loading="lazy"><br><br>reward modelã¨çµ„ã¿åˆã‚ã›ã¦LLMã‹ã‚‰ã®responseã‚’ç”Ÿæˆã—rejection samplingã™ã‚Œã°DPOã®ãŸã‚ã®preference dataã‚‚ä½œæˆã§ãã‚‹ã—ã€single turnã®ç™ºè©±ã¾ã§ç”Ÿæˆã•ã›ãŸå¾Œã‚‚ã†ä¸€åº¦pre/post-queryã‚’concatã—ã¦ç”Ÿæˆã™ã‚Œã°Multi turnã®ãƒ‡ãƒ¼ã‚¿ã‚‚ç”Ÿæˆã§ãã‚‹ã€‚<br><br>ä»–ã®ã‚‚ä¾‹ãˆã°ã€ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è‡ªåˆ†ãŒç”Ÿæˆã—ãŸã„æƒ…å ±ã‚’ä¸ãˆã‚‹ã“ã¨ã§ã€ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ç‰¹åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿ã€ã‚ã‚‹ã„ã¯ç‰¹å®šã®è¨€èªã«ç‰¹åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚‚åˆæˆã§ãã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/f5f06b90-d1cb-4de8-bbaa-622abbcc0b6b" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2093" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] llm-jp-modernbert: A ModernBERT Model Trained on a Large-Scale Japanese  Corpus with Long Context Length, Issa Sugiura+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ModernBERTãƒ¢ãƒ‡ãƒ«ï¼ˆllm-jp-modernbertï¼‰ã¯ã€8192ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’æŒã¤æ—¥æœ¬èªã‚³ãƒ¼ãƒ‘ã‚¹ã§è¨“ç·´ã•ã‚Œã€ãƒ•ã‚£ãƒ«ãƒã‚¹ã‚¯ãƒ†ã‚¹ãƒˆè©•ä¾¡ã§è‰¯å¥½ãªçµæœã‚’ç¤ºã™ã€‚ä¸‹æµã‚¿ã‚¹ã‚¯ã§ã¯æ—¢å­˜ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‰ãªã„ãŒã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã®æ‹¡å¼µåŠ¹æœã‚’åˆ†æã—ã€æ–‡ã®åŸ‹ã‚è¾¼ã¿ã‚„è¨“ç·´ä¸­ã®é·ç§»ã‚’èª¿æŸ»ã€‚å†ç¾æ€§ã‚’æ”¯æ´ã™ã‚‹ãŸã‚ã«ã€ãƒ¢ãƒ‡ãƒ«ã¨è©•ä¾¡ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1761" target="_blank" rel="noopener noreferrer">modernbert-ja-130m, SB Intuitions, 2025.02</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2091" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AnswerCarefully: A Dataset for Improving the Safety of Japanese LLM  Output, Hisami Suzuki+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ—¥æœ¬ã®LLMã®å®‰å…¨æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒAnswerCarefullyã€ã‚’ç´¹ä»‹ã€‚1,800çµ„ã®è³ªå•ã¨å‚ç…§å›ç­”ã‹ã‚‰æˆã‚Šã€ãƒªã‚¹ã‚¯ã‚«ãƒ†ã‚´ãƒªã‚’ã‚«ãƒãƒ¼ã—ã¤ã¤æ—¥æœ¬ã®æ–‡è„ˆã«åˆã‚ã›ã¦ä½œæˆã€‚å¾®èª¿æ•´ã«ã‚ˆã‚Šå‡ºåŠ›ã®å®‰å…¨æ€§ãŒå‘ä¸Šã—ã€12ã®LLMã®å®‰å…¨æ€§è©•ä¾¡çµæœã‚‚å ±å‘Šã€‚è‹±èªç¿»è¨³ã¨æ³¨é‡ˆã‚’æä¾›ã—ã€ä»–è¨€èªã§ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã‚’ä¿ƒé€²ã€‚</span>
<span class="snippet"><span>Comment</span><p>Blog:


<a href="https://llmc.nii.ac.jp/answercarefully-dataset/" target="_blank" rel="noopener noreferrer">https://llmc.nii.ac.jp/answercarefully-dataset/</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2088" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Drop-Upcycling: Training Sparse Mixture of Experts with Partial   Re-initialization, Taishi Nakamura+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- Drop-Upcyclingæ‰‹æ³•ã‚’ææ¡ˆã—ã€MoEãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ã‚’å‘ä¸Šã€‚äº‹å‰ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸå¯†ãªãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¤ã¤ã€ä¸€éƒ¨ã®é‡ã¿ã‚’å†åˆæœŸåŒ–ã™ã‚‹ã“ã¨ã§å°‚é–€å®¶ã®å°‚é–€åŒ–ã‚’ä¿ƒé€²ã€‚å¤§è¦æ¨¡å®Ÿé¨“ã«ã‚ˆã‚Šã€5.9Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®MoEãƒ¢ãƒ‡ãƒ«ãŒ13Bå¯†ãªãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ã‚¹ãƒˆã‚’ç´„1/4ã«å‰Šæ¸›ã€‚ã™ã¹ã¦ã®å®Ÿé¨“ãƒªã‚½ãƒ¼ã‚¹ã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=gx1wHnf5Vp" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=gx1wHnf5Vp</a>


</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1546" target="_blank" rel="noopener noreferrer">Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints, Aran Komatsuzaki+, ICLR'23</a>
</p>
<p>ææ¡ˆæ‰‹æ³•ã®å…¨ä½“åƒã¨Diversity re-initializationã®æ¦‚è¦ã€‚å…ƒã®Upcyclingã§ã¯å…¨ã¦identicalãªé‡ã¿ã§replicateã•ã‚Œã¦ã„ãŸãŸã‚ã€ã“ã‚ŒãŒå€‹ã€…ã®expertãŒlong termã§ã®å­¦ç¿’ã§ç‰¹åŒ–ã™ã‚‹ã“ã¨ã®å¦¨ã’ã«ãªã‚Šã€æœ€çµ‚çš„ã«æœ€å¤§é™ã®capabilityã‚’ç™ºæ®ã§ããšã€åæŸãŒé…ã„è¦å› ã¨ãªã£ã¦ã„ãŸã€‚ã“ã‚Œã‚’ã€Upcyclingã—ãŸé‡ã¿ã®ã†ã¡ã€ä¸€éƒ¨ã®indexã®ã¿ã‚’å†åˆæœŸåŒ–ã™ã‚‹ã“ã¨ã§ã€replicateå…ƒã®çŸ¥è­˜ã‚’ä¿æŒã—ã¤ã¤ã€expertsã®å¤šæ§˜æ€§ã‚’é«˜ã‚ã‚‹ã“ã¨ã§è§£æ±ºã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/46ec75a2-30b1-4f48-9f21-cf5f6e30df95" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/ef3c66b2-32a5-46ab-bb31-828fb4570b53" alt="image" loading="lazy"><br><br>ææ¡ˆæ‰‹æ³•ã¯ä»»æ„ã®activation functioné©ç”¨å¯èƒ½ã€‚ä»Šå›ã¯FFN Layerã®activation functionã¨ã—ã¦ä¸€èˆ¬çš„ãªSwiGLUã‚’æ¡ç”¨ã—ãŸå ´åˆã§èª¬æ˜ã—ã¦ã„ã‚‹ã€‚<br><br>Drop-Upcyclingã®æ‰‹æ³•ã¨ã—ã¦ã¯ã€é€šå¸¸ã®Upcyclingã¨åŒæ§˜ã€FFN Layerã®é‡ã¿ã‚’nå€‹ã®expertsã®æ•°ã ã‘replicateã™ã‚‹ã€‚ãã®å¾Œã€re-initializationã‚’å®Ÿæ–½ã™ã‚‹æ¯”ç‡rã«åŸºã¥ã„ã¦ã€[1, intermediate size d_f]ã®ç¯„å›²ã‹ã‚‰r*d_få€‹ã®indexã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã€‚æœ€çµ‚çš„ã«SwiGLUã€ãŠã‚ˆã³FFNã«ãŠã‘ã‚‹3ã¤ã®Weight W_{gate, up, down}ã«ãŠã„ã¦ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸindexã¨å¯¾å¿œã™ã‚‹row/columnã¨å¯¾å¿œã™ã‚‹é‡ã¿ã‚’re-initializeã™ã‚‹ã€‚<br><br>re-initializeã™ã‚‹éš›ã«ã¯ã€å„W_{gate, up, down}ä¸­ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸindexã¨å¯¾å¿œã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã®å¹³å‡ã¨åˆ†æ•£ã‚’ãã‚Œãã‚Œç‹¬ç«‹ã—ã¦æ±‚ã‚ã€ãã‚Œã‚‰ã®å¹³å‡ã¨åˆ†æ•£ã‚’æŒã¤æ­£è¦åˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã€‚<br><br>å­¦ç¿’ã®åˆæœŸã‹ã‚‰é«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã—ã€long termã§ã®æ€§èƒ½ã‚‚å‘ä¸Šã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€learning curveã®å½¢çŠ¶ã‚‚scratchã‹ã‚‰å­¦ç¿’ã—ãŸå ´åˆã¨åŒæ§˜ã®å½¢çŠ¶ã¨ãªã£ã¦ãŠã‚Šã€çŸ¥è­˜ã®è»¢ç§»ã¨expertsã®specializationãŒã†ã¾ãé€²ã‚“ã ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/945e5ae5-05cd-4117-80e8-078b47f0e53c" alt="image" loading="lazy"></p>
<p>è§£èª¬:


<a href="https://llm-jp.nii.ac.jp/news/post-566/" target="_blank" rel="noopener noreferrer">https://llm-jp.nii.ac.jp/news/post-566/</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2086" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Shrinking the Generation-Verification Gap with Weak Verifiers, Jon Saad-Falcon+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Weaverã¯ã€è¤‡æ•°ã®å¼±ã„verifiersã‚’çµ„ã¿åˆã‚ã›ã¦å¼·åŠ›ãªverifierã‚’è¨­è¨ˆã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã¸ã®ä¾å­˜ã‚’æ¸›ã‚‰ã™ãŸã‚ã«å¼±ã„ç›£è¦–ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚å‡ºåŠ›ã‚’æ­£è¦åŒ–ã—ã€ç‰¹å®šã®verifiersã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ç²¾åº¦ã®å‘ä¸Šã‚’å›³ã‚Šã¾ã™ã€‚Weaverã¯ã€æ¨è«–ãŠã‚ˆã³æ•°å­¦ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦Pass@1æ€§èƒ½ã‚’å¤§å¹…ã«æ”¹å–„ã—ã€Llama 3.3 70B Instructã‚’ç”¨ã„ã¦é«˜ã„ç²¾åº¦ã‚’é”æˆã—ã¾ã—ãŸã€‚è¨ˆç®—ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãŸã‚ã«ã€çµ±åˆå‡ºåŠ›ã‚¹ã‚³ã‚¢ã‚’ç”¨ã„ã¦ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’è¨“ç·´ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jonsaadfalcon/status/1937600479527317802?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2085" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Mercury: Ultra-Fast Language Models Based on Diffusion, Inception Labs+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„æ‹¡æ•£å‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«Mercuryã‚’ç™ºè¡¨ã€‚ç‰¹ã«ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å‘ã‘ã®Mercury Coderã¯ã€Miniã¨Smallã®2ã‚µã‚¤ã‚ºã§æä¾›ã•ã‚Œã€é€Ÿåº¦ã¨å“è³ªã§æœ€å…ˆç«¯ã‚’é”æˆã€‚ç‹¬ç«‹è©•ä¾¡ã§ã¯ã€Mercury Coder MiniãŒ1109ãƒˆãƒ¼ã‚¯ãƒ³/ç§’ã€SmallãŒ737ãƒˆãƒ¼ã‚¯ãƒ³/ç§’ã‚’è¨˜éŒ²ã—ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚ã•ã‚‰ã«ã€å®Ÿä¸–ç•Œã§ã®æ¤œè¨¼çµæœã‚„å…¬é–‹APIã€ç„¡æ–™ãƒ—ãƒ¬ã‚¤ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚‚æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1937360864262389786?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆï¼ˆãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆé€Ÿåº¦ï¼‰ãŒã€SoTAã‚‰ã—ã„dLLMãƒ¢ãƒ‡ãƒ«</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1938026627642101858?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2084" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Recycling the Web: A Method to Enhance Pre-training Data Quality and  Quantity for Language Models, Thao Nguyen+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã«åŸºã¥ãã€ä½å“è³ªãªã‚¦ã‚§ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚’å†åˆ©ç”¨ã™ã‚‹æ‰‹æ³•ã€ŒREWIREã€ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®åˆæˆè¡¨ç¾ã‚’å¢—ã‚„ã—ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã¿ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¯”è¼ƒã—ã¦ã€22ã®ã‚¿ã‚¹ã‚¯ã§æ€§èƒ½ã‚’å‘ä¸Šã€‚ç”Ÿãƒ‡ãƒ¼ã‚¿ã¨åˆæˆãƒ‡ãƒ¼ã‚¿ã®æ··åˆãŒåŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ã‚¦ã‚§ãƒ–ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚µã‚¤ã‚¯ãƒ«ãŒäº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«æœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thao_nguyen26/status/1937210428876292457?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thao_nguyen26/status/1961163219118297178?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æ¯æ¸‡ã«å¯¾ã™ã‚‹å¯¾å‡¦ã¨ã—ã¦åˆ¥ã®æ–¹å‘æ€§ã¨ã—ã¦ã¯ä¸‹è¨˜ã®ã‚ˆã†ãªç ”ç©¶ã‚‚ã‚ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1829" target="_blank" rel="noopener noreferrer">Scaling Data-Constrained Language Models, Niklas Muennighoff+, NeurIPS'23</a>
</p>
<p>data:


<a href="https://huggingface.co/datasets/facebook/recycling_the_web" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/facebook/recycling_the_web</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PRM.html" target="_blank" rel="noopener noreferrer">#PRM</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2083" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ReasonFlux-PRM: Trajectory-Aware PRMs for Long Chain-of-Thought  Reasoning in LLMs, Jiaru Zou+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„ãƒ—ãƒ­ã‚»ã‚¹å ±é…¬ãƒ¢ãƒ‡ãƒ«ReasonFlux-PRMã‚’ææ¡ˆã—ã€æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã®è©•ä¾¡ã‚’å¼·åŒ–ã€‚ã‚¹ãƒ†ãƒƒãƒ—ã¨è»Œé“ã®ç›£è¦–ã‚’çµ„ã¿è¾¼ã¿ã€å ±é…¬å‰²ã‚Šå½“ã¦ã‚’ç´°ã‹ãè¡Œã†ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ReasonFlux-PRM-7BãŒé«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿é¸æŠã¨æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã—ã€ç‰¹ã«ç›£è¦–ä»˜ããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§å¹³å‡12.1%ã®å‘ä¸Šã‚’é”æˆã€‚ãƒªã‚½ãƒ¼ã‚¹åˆ¶ç´„ã®ã‚ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å‘ã‘ã«ReasonFlux-PRM-1.5Bã‚‚å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1937345023005048925?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2082" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Vision as a Dialect: Unifying Visual Understanding and Generation via  Text-Aligned Representations, Jiaming Han+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€è¦–è¦šç†è§£ã¨ç”Ÿæˆã‚’çµ±ä¸€ã™ã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯Tarã‚’ææ¡ˆã€‚Text-Aligned Tokenizerï¼ˆTA-Tokï¼‰ã‚’ç”¨ã„ã¦ç”»åƒã‚’é›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³ã«å¤‰æ›ã—ã€è¦–è¦šã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’çµ±ä¸€ç©ºé–“ã«çµ±åˆã€‚ã‚¹ã‚±ãƒ¼ãƒ«é©å¿œå‹ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å°å…¥ã—ã€é«˜å¿ å®Ÿåº¦ã®è¦–è¦šå‡ºåŠ›ã‚’ç”Ÿæˆã€‚è¿…é€Ÿãªè‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«ã¨æ‹¡æ•£ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸãƒ‡ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’æ´»ç”¨ã—ã€è¦–è¦šç†è§£ã¨ç”Ÿæˆã®æ”¹å–„ã‚’å®Ÿç¾ã€‚å®Ÿé¨“çµæœã§ã¯ã€TarãŒæ—¢å­˜æ‰‹æ³•ã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¤ºã—ã€åŠ¹ç‡çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1937345768223859139?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>text modalityã¨vision modalityã‚’å…±é€šã®ç©ºé–“ã§è¡¨ç¾ã™ã‚‹<br><img src="https://github.com/user-attachments/assets/356e86e1-cad9-4bee-8398-d68c4fc6ad46" alt="image" loading="lazy"></p>
<p>Visual Understanding/Generationã®ãƒ™ãƒ³ãƒã§å…¨ä½“çš„ã«é«˜ã„æ€§èƒ½ã‚’é”æˆ<br><img src="https://github.com/user-attachments/assets/6e45aec0-ae0b-4327-923f-fdfce8e83ca0" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2080" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Mind the Gap: Examining the Self-Improvement Capabilities of Large  Language Models, Yuda Song+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±æ”¹å–„ã¯LLMã®å‡ºåŠ›æ¤œè¨¼ã‚’é€šã˜ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã€è’¸ç•™ã™ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€è‡ªå·±æ”¹å–„ã®æ•°å­¦çš„å®šå¼åŒ–ã‚’è¡Œã„ã€ç”Ÿæˆ-æ¤œè¨¼ã‚®ãƒ£ãƒƒãƒ—ã«åŸºã¥ãã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç¾è±¡ã‚’ç™ºè¦‹ã€‚ã•ã¾ã–ã¾ãªãƒ¢ãƒ‡ãƒ«ã¨ã‚¿ã‚¹ã‚¯ã‚’ç”¨ã„ãŸå®Ÿé¨“ã«ã‚ˆã‚Šã€è‡ªå·±æ”¹å–„ã®å¯èƒ½æ€§ã¨ãã®æ€§èƒ½å‘ä¸Šæ–¹æ³•ã‚’æ¢æ±‚ã—ã€LLMã®ç†è§£ã‚’æ·±ã‚ã‚‹ã¨ã¨ã‚‚ã«ã€å°†æ¥ã®ç ”ç©¶ã¸ã®ç¤ºå”†ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:


<a href="https://joisino.hatenablog.com/entry/mislead" target="_blank" rel="noopener noreferrer">https://joisino.hatenablog.com/entry/mislead</a>


</p>
<p>Verificationã«å¯¾ã™ã‚‹ç†è§£ã‚’æ·±ã‚ã‚‹ã®ã«éå¸¸ã«è‰¯ã•ãã†</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2077" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On the Self-Verification Limitations of Large Language Models on   Reasoning and Planning Tasks, Kaya Stechly+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®æ¨è«–èƒ½åŠ›ã«é–¢ã™ã‚‹æ„è¦‹ã®ç›¸é•ã‚’èƒŒæ™¯ã«ã€åå¾©çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åŠ¹æœã‚’Game of 24ã€ã‚°ãƒ©ãƒ•å½©è‰²ã€STRIPSè¨ˆç”»ã®3é ˜åŸŸã§èª¿æŸ»ã€‚è‡ªå·±æ‰¹è©•ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«æ‚ªå½±éŸ¿ã‚’åŠã¼ã™ä¸€æ–¹ã€å¤–éƒ¨ã®æ­£ã—ã„æ¨è«–è€…ã«ã‚ˆã‚‹æ¤œè¨¼ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚å†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã£ã¦è¤‡é›‘ãªè¨­å®šã®åˆ©ç‚¹ã‚’ç¶­æŒã§ãã‚‹ã“ã¨ã‚‚ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:


<a href="https://joisino.hatenablog.com/entry/mislead" target="_blank" rel="noopener noreferrer">https://joisino.hatenablog.com/entry/mislead</a>


</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=4O0v4s3IzY" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=4O0v4s3IzY</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2076" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Language Models Learn to Mislead Humans via RLHF, Jiaxin Wen+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- RLHFã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¨ãƒ©ãƒ¼ã‚’æ‚ªåŒ–ã•ã›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«ãŒäººé–“ã‚’ç´å¾—ã•ã›ã‚‹èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ä¸€æ–¹ã§ã€ã‚¿ã‚¹ã‚¯ã®æ­£ç¢ºæ€§ã¯å‘ä¸Šã—ãªã„ã€‚è³ªå•å¿œç­”ã‚¿ã‚¹ã‚¯ã¨ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã§è¢«é¨“è€…ã®èª¤æ¤œå‡ºç‡ãŒå¢—åŠ ã—ã€æ„å›³ã•ã‚ŒãŸè©­å¼ã‚’æ¤œå‡ºã™ã‚‹æ‰‹æ³•ãŒU-SOPHISTRYã«ã¯é©ç”¨ã§ããªã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€RLHFã®å•é¡Œç‚¹ã¨äººé–“æ”¯æ´ã®ç ”ç©¶ã®å¿…è¦æ€§ãŒæµ®ãå½«ã‚Šã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:


<a href="https://joisino.hatenablog.com/entry/mislead" target="_blank" rel="noopener noreferrer">https://joisino.hatenablog.com/entry/mislead</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<span class="issue_date">Issue Date: 2025-06-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2073" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] From Bytes to Ideas: Language Modeling with Autoregressive U-Nets, Mathurin Videau+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±å›å¸°å‹U-Netã‚’ç”¨ã„ã¦ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã®æŸ”è»Ÿæ€§ã‚’å‘ä¸Šã•ã›ã€ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿã®ãƒã‚¤ãƒˆã‹ã‚‰å˜èªã‚„å˜èªã®ãƒšã‚¢ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ã®è¦–ç‚¹ã‚’æä¾›ã€‚æ·±ã„æ®µéšã§ã¯åºƒç¯„ãªæ„å‘³ãƒ‘ã‚¿ãƒ¼ãƒ³ã«æ³¨ç›®ã—ã€æµ…ã„æ®µéšã¯BPEãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ–‡å­—ãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¹ã‚¯ã‚„ãƒªã‚½ãƒ¼ã‚¹ã®å°‘ãªã„è¨€èªé–“ã§ã®çŸ¥è­˜ç§»è»¢ãŒå¯èƒ½ã¨ãªã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1936825784473096335?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<a class="button" href="articles/CrossDomain.html" target="_blank" rel="noopener noreferrer">#CrossDomain</a>
<span class="issue_date">Issue Date: 2025-06-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2070" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain  Perspective, Zhoujun Cheng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Guruã‚’å°å…¥ã—ã€æ•°å­¦ã€ã‚³ãƒ¼ãƒ‰ã€ç§‘å­¦ã€è«–ç†ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€è¡¨å½¢å¼ã®6ã¤ã®æ¨è«–ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã‚ãŸã‚‹92Kã®RLæ¨è«–ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’æ§‹ç¯‰ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMæ¨è«–ã®ãŸã‚ã®RLã®ä¿¡é ¼æ€§ã¨åŠ¹æœã‚’å‘ä¸Šã•ã›ã€ãƒ‰ãƒ¡ã‚¤ãƒ³é–“ã®å¤‰å‹•ã‚’è¦³å¯Ÿã€‚ç‰¹ã«ã€äº‹å‰å­¦ç¿’ã®éœ²å‡ºãŒé™ã‚‰ã‚ŒãŸãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã¯ã€ãƒ‰ãƒ¡ã‚¤ãƒ³å†…ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚Guru-7Bã¨Guru-32Bãƒ¢ãƒ‡ãƒ«ã¯ã€æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã—ã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ”¹å–„ã€‚ãƒ‡ãƒ¼ã‚¿ã¨ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chengzhoujun/status/1936113985507803365?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>post-trainingã«ãŠã‘ã‚‹RLã®cross domainï¼ˆMath, Code, Science, Logic, Tabular)ã«ãŠã‘ã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã—ãŸç ”ç©¶ã€‚éå¸¸ã«èˆˆå‘³æ·±ã„ç ”ç©¶ã€‚è©³ç´°ã¯å…ƒè«–æ–‡ãŒè‘—è€…ãƒã‚¹ãƒˆå‚ç…§ã®ã“ã¨ã€‚</p>
<p>Qwenã‚·ãƒªãƒ¼ã‚ºã§å®Ÿé¨“ã€‚ä»¥ä¸‹ãƒã‚¹ãƒˆã®ã¾ã¨ã‚ã€‚<br><br>- mid trainingã«ãŠã„ã¦é‡ç‚¹çš„ã«å­¦ç¿’ã•ã‚ŒãŸãƒ‰ãƒ¡ã‚¤ãƒ³ã¯RLã«ã‚ˆã‚‹post trainingã§å¼·ã„è»¢ç§»ã‚’ç™ºæ®ã™ã‚‹ï¼ˆCode, Math, Science)<br>- ä¸€æ–¹ã€mid trainingã§ã‚ã¾ã‚Šå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸­ã«å‡ºç¾ã—ãªã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã¤ã„ã¦ã¯è»¢ç§»ã«ã‚ˆã‚‹æ€§èƒ½å‘ä¸Šã¯æœ€å°é™ã«ç•™ã¾ã‚Šã€in-domainã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ãã¡ã‚“ã¨ä¸ãˆã¦post trainingã—ãªã„ã¨æ€§èƒ½å‘ä¸Šã¯é™å®šçš„<br>- ç°¡å˜ãªã‚¿ã‚¹ã‚¯ã¯cross domainã®è»¢ç§»ã«ã‚ˆã‚‹æ©æµã‚’ã™ãã«å¾—ã‚„ã™ã„ï¼ˆMath500, MBPP),é›£æ˜“åº¦ã®é«˜ã„ã‚¿ã‚¹ã‚¯ã¯æ©æµã‚’å¾—ã«ãã„<br>- å„ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ§˜ã«mixã™ã‚‹ã¨ã€å˜ä¸€ãƒ‰ãƒ¡ã‚¤ãƒ³ã§å­¦ç¿’ã—ãŸå ´åˆã¨åŒç­‰ã‹ãã‚Œä»¥ä¸Šã®æ€§èƒ½ã‚’é”æˆã™ã‚‹<br>- å¿…ãšã—ã‚‚response lengthãŒé•·ããªã‚ŠãªãŒã‚‰äºˆæ¸¬æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã‚ã‘ã§ã¯ãªãã€ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã‚ˆã£ã¦å‚¾å‘ãŒç•°ãªã‚‹<br>- ãŸã¨ãˆã°ã€Code, Logic, Tabularã®å‡ºåŠ›ã¯æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã«ã¤ã‚Œã¦response lengthã¯ç¸®å°ã—ã¦ã„ã<br>- ä¸€æ–¹ã€Science, Mathã¯response lengthãŒå¢—å¤§ã—ã¦ã„ãã€‚ã¾ãŸã€Simulationã¯å¤‰åŒ–ã—ãªã„<br>- ç•°ãªã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’mixã™ã‚‹ã“ã¨ã§ã€æœ€åˆã®æ•°ç™¾ã‚¹ãƒ†ãƒƒãƒ—ã«ãŠã‘ã‚‹rewardã®ç«‹ã¡ä¸ŠãŒã‚ŠãŒæ—©ãï¼ˆå˜ä¸€ãƒ‰ãƒ¡ã‚¤ãƒ³ã¨æ¯”ã¹ã¦æ€¥æ¿€ã«rewardãŒå‘ä¸Šã—ã¦ã„ãï¼‰è»¢ç§»ãŒã†ã¾ãã„ã<br>  - ï¼ˆã“ã‚Œã¯ç§ãŒã‚°ãƒ©ãƒ•ã‚’è¦‹ãŸæ„Ÿæƒ³ã ãŒã€å˜ä¸€ãƒ‰ãƒ¡ã‚¤ãƒ³ã§long runã§å­¦ç¿’ã—ãŸå ´åˆã®æœ€çµ‚çš„ãªæ€§èƒ½ã¯4/6ã§åŒç­‰ç¨‹åº¦ã€2/6ã§å‘ä¸Šï¼ˆMath, Science)<br>- éå¸¸ã«é›£æ˜“åº¦ã®é«˜ã„mathãƒ‡ãƒ¼ã‚¿ã®ã¿ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã¨ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç„¡ã—ã®å ´åˆã¨æ¯”ã¹ã¦é›£æ˜“åº¦ã®é«˜ã„ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬æ€§èƒ½ã¯å‘ä¸Šã™ã‚‹ä¸€æ–¹ã€ç°¡å˜ãªOODã‚¿ã‚¹ã‚¯ï¼ˆHumanEval)ã®æ€§èƒ½ãŒå¤§å¹…ã«ä½ä¸‹ã™ã‚‹ï¼ˆç‰¹å®šã®ã‚‚ã®ã«ç‰¹åŒ–ã™ã‚‹ã¨OODã®æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ï¼‰<br>- RLã¯pre(mid)-trainingã§å­¦ç¿’ã•ã‚ŒãŸreasoningèƒ½åŠ›ã‚’å¼•ãå‡ºã™ã ã‘ã§ã¯ãªãã€æ–°è¦ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã¯æ–°ãŸãªreasoningèƒ½åŠ›ã‚’ç²å¾—ã§ãã‚‹<br>- ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã„ã¨ã€RLã§post-trainingå¾Œã®pass@kã®kã‚’å¤§ããã™ã‚‹ã¨ã©ã“ã‹ã§ã‚µãƒã‚Šã€baseãƒ¢ãƒ‡ãƒ«ã¨äº¤å·®ã™ã‚‹ãŒã€å¤§ãã„ã¨ã‚µãƒã‚‰ãšäº¤å·®ã—ãªã„<br>  - ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„ã¨ã‚ˆã‚Šå¤šæ§˜ãªreasoningãƒ‘ã‚¹ãŒunlockã•ã‚Œã¦ã„ã‚‹<br>- pass@kã§è¦³å¯Ÿã—ãŸã¨ã“ã‚RLã«ã¯2ã¤ã®phaseã®ã‚ˆã¤ãªã‚‚ã®ãŒè¦³æ¸¬ã•ã‚Œã€æœ€åˆã®0-160ï¼ˆ1 epoch)ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯pass@1ãŒæ”¹å–„ã—ãŸãŒã€pass@max_kã¯æ€¥æ¿€ã«æ€§èƒ½ãŒåŠ£åŒ–ã—ãŸã€‚ä¸€æ–¹ã§ã€160ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¶…ãˆã‚‹ã¨ã€åŒæ–¹å…±ã«å¾ã€…ã«æ€§èƒ½æ”¹å–„ãŒæ”¹å–„ã—ã¦ã„ãã‚ˆã†ãªå¤‰åŒ–ãŒè¦‹ã‚‰ã‚ŒãŸ</p>
<p>æœ¬ç ”ç©¶ã§æ§‹ç¯‰ã•ã‚ŒãŸGuru Dataset:


<a href="https://huggingface.co/datasets/LLM360/guru-RL-92k" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/LLM360/guru-RL-92k</a>


<br><br>math, coding, science, logic, simulation, tabular reasoningã«é–¢ã™ã‚‹é«˜å“è³ªã€ã‹ã¤verifiableãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-06-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2062" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Laws for Upcycling Mixture-of-Experts Language Models, Seng Pei Liew+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®äº‹å‰å­¦ç¿’ã¯é«˜ã‚³ã‚¹ãƒˆã§æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã€ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚¯ãƒªãƒ³ã‚°ã¨MoEãƒ¢ãƒ‡ãƒ«ã®è¨ˆç®—åŠ¹ç‡å‘ä¸ŠãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚¯ãƒªãƒ³ã‚°ã‚’MoEã«é©ç”¨ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºã‚„ãƒ¢ãƒ‡ãƒ«æ§‹æˆã«ä¾å­˜ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ç‰¹å®šã€‚å¯†ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚¯ãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ç›¸äº’ä½œç”¨ãŒåŠ¹ç‡ã‚’åˆ¶é™ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚¯ãƒªãƒ³ã‚°ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã«é–¢ã™ã‚‹æŒ‡é‡ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sbintuitions/status/1935970879923540248?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=ZBBo19jldX" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=ZBBo19jldX</a>


</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1546" target="_blank" rel="noopener noreferrer">Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints, Aran Komatsuzaki+, ICLR'23</a>
</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2059" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought, Hanlin Zhu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€é€£ç¶šCoTsã‚’ç”¨ã„ãŸäºŒå±¤ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãŒæœ‰å‘ã‚°ãƒ©ãƒ•åˆ°é”å¯èƒ½æ€§å•é¡Œã‚’è§£æ±ºã§ãã‚‹ã“ã¨ã‚’è¨¼æ˜ã€‚é€£ç¶šCoTsã¯è¤‡æ•°ã®æ¢ç´¢ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã‚’åŒæ™‚ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€å¾“æ¥ã®é›¢æ•£CoTsã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã«è§£ã‚’å°ãã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€é‡ã­åˆã‚ã›çŠ¶æ…‹ãŒè‡ªå‹•çš„ã«ç¾ã‚Œã€ãƒ¢ãƒ‡ãƒ«ãŒè¤‡æ•°ã®ãƒ‘ã‚¹ã‚’åŒæ™‚ã«æ¢ç´¢ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tydsh/status/1935206012799303817?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2058" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AceReason-Nemotron 1.1: Advancing Math and Code Reasoning through SFT and RL Synergy, Zihan Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã¨å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã®ç›¸ä¹—åŠ¹æœã‚’æ¢æ±‚ã—ã€SFTãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®æ•´å‚™ã«ãŠã„ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°ã®å¢—åŠ ãŒæ¨è«–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ç‰¹ã«ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¸©åº¦ã‚’é©åˆ‡ã«èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŠ¹æœã‚’æœ€å¤§åŒ–ã§ãã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã—ãŸã€‚æœ€çµ‚çš„ã«ã€AceReason-Nemotron-1.1ãƒ¢ãƒ‡ãƒ«ã¯ã€å‰ãƒ¢ãƒ‡ãƒ«ã‚’å¤§ããä¸Šå›ã‚Šã€æ•°å­¦ãŠã‚ˆã³ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ–°ãŸãªæœ€å…ˆç«¯æ€§èƒ½ã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ychennlp/status/1935005283178492222?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>æ§˜ã€…ãªtakeawayãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚<p>SFT,RLã«åˆ©ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚‚å…¬é–‹</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1829" target="_blank" rel="noopener noreferrer">Scaling Data-Constrained Language Models, Niklas Muennighoff+, NeurIPS'23</a>
<br><br>ã«ãŠã„ã¦äº‹å‰å­¦ç¿’æ™‚ã«4 epochã¾ã§ã¯æ€§èƒ½ã®æ”¹å–„å¹…ãŒå¤§ãã„ã¨å ±å‘Šã•ã‚Œã¦ã„ãŸãŒã€SFTã§ã‚‚5 epochç¨‹åº¦ã¾ã§å­¦ç¿’ã™ã‚‹ã¨è‰¯ã„æ¨¡æ§˜ã€‚<br><br>ã¾ãŸã€SFT dataã‚’scalingã•ã›ã‚‹éš›ã¯ã€promptã®æ•°ã ã‘ã§ãªãã€promptå˜ä½ã®responseæ•°ã‚’å¢—ã‚„ã™ã®ãŒåŠ¹æœçš„<br><img src="https://github.com/user-attachments/assets/67e2a4ff-555b-4e22-a90a-ee239704805e" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2054" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Direct Reasoning Optimization: LLMs Can Reward And Refine Their Own  Reasoning for Open-Ended Tasks, Yifei Xu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- DROï¼ˆç›´æ¥æ¨è«–æœ€é©åŒ–ï¼‰ã‚’ææ¡ˆã—ã€LLMsã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ã®é•·æ–‡æ¨è«–ã‚¿ã‚¹ã‚¯ã«å¾®èª¿æ•´ã™ã‚‹ãŸã‚ã®å¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã€‚æ–°ã—ã„å ±é…¬ä¿¡å·R3ã‚’ç”¨ã„ã¦æ¨è«–ã¨å‚ç…§çµæœã®ä¸€è²«æ€§ã‚’æ‰ãˆã€è‡ªå·±å®Œçµã—ãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿç¾ã€‚ParaRevã¨FinQAã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€åºƒç¯„ãªé©ç”¨å¯èƒ½æ€§ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1934957116571451409?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2053" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Wait, We Don't Need to "Wait" Removing Thinking Tokens Improves  Reasoning Efficiency, Chenlong Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±åçœã‚’æŠ‘åˆ¶ã™ã‚‹ã€ŒNoWaitã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€æ¨è«–ã®åŠ¹ç‡ã‚’å‘ä¸Šã€‚10ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å¤§27%-51%ã®æ€è€ƒã®é€£é–ã®é•·ã•ã‚’å‰Šæ¸›ã—ã€æœ‰ç”¨æ€§ã‚’ç¶­æŒã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ã®ãŸã‚ã®åŠ¹æœçš„ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>Wait, Hmmã¨ã„ã£ãŸlong CoTã‚’èª˜å°ã™ã‚‹ã‚ˆã†ãªtokenã‚’æŠ‘åˆ¶ã™ã‚‹ã“ã¨ã§ã€Accã¯ã»ã¼å¤‰ã‚ã‚‰ãšã«ç”Ÿæˆã•ã‚Œã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å‰Šæ¸›å¯èƒ½ã€ã¨ã„ã£ãŸå›³ã«è¦‹ãˆã‚‹ã€‚Reasoningãƒ¢ãƒ‡ãƒ«ã§ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é€Ÿåº¦ã‚’å‘ä¸Šã—ãŸã„å ´åˆã«åŠ¹æœãŒã‚ã‚Šãã†ã€‚<br><img src="https://github.com/user-attachments/assets/c0abd2b4-f019-435e-b72f-f588fa0eb782" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1935130111608492060?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2052" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and  Training Factors Shape LLM Alignment Quality, Yuto Harada+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- SFTã¯LLMã‚’äººé–“ã®æŒ‡ç¤ºã«æ•´åˆã•ã›ã‚‹é‡è¦ãªãƒ—ãƒ­ã‚»ã‚¹ã§ã‚ã‚Šã€1,000ä»¥ä¸Šã®SFTãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿæˆã—ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç‰¹æ€§ã¨å±¤ã”ã¨ã®å¤‰æ›´ã‚’èª¿æŸ»ã€‚è¨“ç·´ã‚¿ã‚¹ã‚¯ã®ç›¸ä¹—åŠ¹æœã‚„ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®æˆ¦ç•¥ã®é‡è¦æ€§ã‚’æ˜ã‚‰ã‹ã«ã—ã€å›°æƒ‘åº¦ãŒSFTã®åŠ¹æœã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ä¸­é–“å±¤ã®é‡ã¿ã®å¤‰åŒ–ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã¨å¼·ãç›¸é–¢ã—ã€ç ”ç©¶ã‚’åŠ é€Ÿã•ã›ã‚‹ãŸã‚ã«ãƒ¢ãƒ‡ãƒ«ã¨çµæœã‚’å…¬é–‹äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1935191113981403359?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>NLP'25:


<a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/C10-6.pdf" target="_blank" rel="noopener noreferrer">https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/C10-6.pdf</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/FactualKnowledge.html" target="_blank" rel="noopener noreferrer">#FactualKnowledge</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2049" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] What Is Seen Cannot Be Unseen: The Disruptive Effect of Knowledge  Conflict on Large Language Models, Kaiser Sun+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®æ–‡è„ˆæƒ…å ±ã¨ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯çŸ¥è­˜ã®å¯¾ç«‹ã‚’è©•ä¾¡ã™ã‚‹è¨ºæ–­ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚çŸ¥è­˜ã®å¯¾ç«‹ã¯ã‚¿ã‚¹ã‚¯ã«å½±éŸ¿ã‚’ä¸ãˆãšã€ä¸€è‡´æ™‚ã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã€‚ãƒ¢ãƒ‡ãƒ«ã¯å†…éƒ¨çŸ¥è­˜ã‚’æŠ‘åˆ¶ã§ããšã€å¯¾ç«‹ã®ç†ç”±ãŒæ–‡è„ˆä¾å­˜ã‚’é«˜ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMã®è©•ä¾¡ã¨å±•é–‹ã«ãŠã‘ã‚‹çŸ¥è­˜ã®å¯¾ç«‹ã®é‡è¦æ€§ãŒå¼·èª¿ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kaiserwholearns/status/1934582217692295268?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2048" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Overclocking LLM Reasoning: Monitoring and Controlling Thinking Path  Lengths in LLMs, Roy Eisenstadt+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã‘ã‚‹æ€è€ƒæ®µéšã®é•·ã•ã‚’èª¿æ•´ã™ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æ¢æ±‚ã€‚é€²æ—ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€å¯è¦–åŒ–ã™ã‚‹ã“ã¨ã§è¨ˆç”»ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’æ˜ã‚‰ã‹ã«ã—ã€ä¸è¦ãªã‚¹ãƒ†ãƒƒãƒ—ã‚’æ¸›ã‚‰ã™ã€Œã‚ªãƒ¼ãƒãƒ¼ã‚¯ãƒ­ãƒƒã‚­ãƒ³ã‚°ã€æ‰‹æ³•ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è€ƒãˆã™ãã‚’è»½æ¸›ã—ã€å›ç­”ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€æ¨è«–ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’æ¸›å°‘ã•ã›ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1934357202619310559?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2047" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive  Programming?, Zihan Zheng+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã§äººé–“ã®ã‚¨ãƒªãƒ¼ãƒˆã‚’ä¸Šå›ã‚‹ã¨ã•ã‚Œã‚‹ãŒã€å®Ÿéš›ã«ã¯é‡è¦ãªé™ç•ŒãŒã‚ã‚‹ã“ã¨ã‚’èª¿æŸ»ã€‚æ–°ãŸã«å°å…¥ã—ãŸã€ŒLiveCodeBench Proã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ã‚ˆã‚Šã€LLMsã¯ä¸­ç¨‹åº¦ã®é›£æ˜“åº¦ã®å•é¡Œã§53%ã®pass@1ã‚’é”æˆã™ã‚‹ä¸€æ–¹ã€é›£ã—ã„å•é¡Œã§ã¯0%ã¨ã„ã†çµæœãŒå¾—ã‚‰ã‚ŒãŸã€‚LLMsã¯å®Ÿè£…é‡è¦–ã®å•é¡Œã§ã¯æˆåŠŸã™ã‚‹ãŒã€è¤‡é›‘ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çš„æ¨è«–ã«ã¯è‹¦åŠ´ã—ã€èª¤ã£ãŸæ­£å½“åŒ–ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒå¤šã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã¨äººé–“ã®å°‚é–€å®¶ã¨ã®é–“ã«é‡è¦ãªã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ä»Šå¾Œã®æ”¹å–„ã®ãŸã‚ã®è¨ºæ–­ãŒæä¾›ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1934433210387296414?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Hardãªå•é¡Œã¯ç¾çŠ¶ã®SoTAãƒ¢ãƒ‡ãƒ«ï¼ˆClaude4ãŒå«ã¾ã‚Œã¦ã„ãªã„ãŒï¼‰ã§ã‚‚æ­£ç­”ç‡0.0%<br><img src="https://github.com/user-attachments/assets/d0e29f23-2b66-4b19-b39a-68f3717d7058" alt="image" loading="lazy"><br><br>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å«ã¾ã‚Œã‚‹èª²é¡Œã®ã‚«ãƒ†ã‚´ãƒª<br><img src="https://github.com/user-attachments/assets/b41b11d7-52a2-4a22-848d-cb08900da5cf" alt="image" loading="lazy"><br><br>å®Ÿã‚µãƒ³ãƒ—ãƒ«ã‚„ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ãªã©ã¯Appendixå‚ç…§ã®ã“ã¨ã€‚</p>
<p>pj page:


<a href="https://livecodebenchpro.com" target="_blank" rel="noopener noreferrer">https://livecodebenchpro.com</a>


</p>
<p>ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ(NeurIPSã«accept):<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhaocha1/status/1969035554252611833?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2046" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware  Reasoning, Yu Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RAG+ã¯ã€Retrieval-Augmented Generationã®æ‹¡å¼µã§ã€çŸ¥è­˜ã®é©ç”¨ã‚’æ„è­˜ã—ãŸæ¨è«–ã‚’çµ„ã¿è¾¼ã‚€ã€‚äºŒé‡ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ç”¨ã„ã¦ã€é–¢é€£æƒ…å ±ã‚’å–å¾—ã—ã€ç›®æ¨™æŒ‡å‘ã®æ¨è«–ã«é©ç”¨ã™ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€RAG+ãŒæ¨™æº–çš„ãªRAGã‚’3-5%ã€è¤‡é›‘ãªã‚·ãƒŠãƒªã‚ªã§ã¯æœ€å¤§7.5%ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã€çŸ¥è­˜çµ±åˆã®æ–°ãŸãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1934667096828399641?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>çŸ¥è­˜ã ã‘ã§ãªãçŸ¥è­˜ã®ä½¿ã„æ–¹ã‚‚è“„ç©ã—ã€åˆ©ç”¨æ™‚ã«æ¤œç´¢ã•ã‚ŒãŸçŸ¥è­˜ã¨ç´ã¥ã„ãŸä½¿ã„æ–¹ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§RAGã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/23f2b2cd-458b-437a-837d-11d4db28162f" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/b6a01788-7a14-41a3-81f7-41a2add62bd1" alt="image" loading="lazy"></p>
<p>Figure 1ã®ã‚ˆã†ãªä¾‹ã¯Reasoningãƒ¢ãƒ‡ãƒ«ãŒé€²åŒ–ã—ã¦ã„ã£ãŸã‚‰ã€ã‚ã–ã‚ã–çŸ¥è­˜ã¨ä½¿ã„æ–¹ã‚’ç´ä»˜ã‘ãªãã¦ã‚‚ã€ä¸–ç•ŒçŸ¥è­˜ã‹ã‚‰ä½¿ã„æ–¹ã‚’è£œå®Œå¯èƒ½ã ã¨æ€ã‚ã‚Œã‚‹ã®ã§ä¸è¦ã¨ãªã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚<br>ãŒã€çœŸã«ã“ã®æ‰‹æ³•ãŒåŠ›ã‚’ç™ºæ®ã™ã‚‹ã®ã¯ã€Œãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®ä½¿ã„æ–¹ã‚„ãƒ«ãƒ¼ãƒ«ã€ãŒå­˜åœ¨ã™ã‚‹å ´åˆã§ã€ã©ã‚Œã ã‘LLMãŒè³¢ããªã£ã¦ã‚‚æ¨è«–ã«ã‚ˆã£ã¦å°ãå‡ºã›ãªã„ã‚‚ã®ã€ã®ã¤ã„ã¦ã¯ã€ã“ã†ã„ã£ãŸæ‰‹æ³•ã¯åŠ¹åŠ›ã‚’ç™ºæ®ã—ç¶šã‘ã‚‹ã®ã§ã¯ãªã„ã‹ã¨æ€ã‚ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<a class="button" href="articles/FactualKnowledge.html" target="_blank" rel="noopener noreferrer">#FactualKnowledge</a>
<a class="button" href="articles/meta-learning.html" target="_blank" rel="noopener noreferrer">#meta-learning</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2044" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] PropMEND: Hypernetworks for Knowledge Propagation in LLMs, Zeyu Leo Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- PropMENDã¯ã€LLMsã«ãŠã‘ã‚‹çŸ¥è­˜ä¼æ’­ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ã€‚ãƒ¡ã‚¿å­¦ç¿’ã‚’ç”¨ã„ã¦ã€æ³¨å…¥ã•ã‚ŒãŸçŸ¥è­˜ãŒãƒãƒ«ãƒãƒ›ãƒƒãƒ—è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ä¼æ’­ã™ã‚‹ã‚ˆã†ã«å‹¾é…ã‚’ä¿®æ­£ã™ã‚‹ã€‚RippleEditãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€é›£ã—ã„è³ªå•ã«å¯¾ã—ã¦ç²¾åº¦ãŒã»ã¼2å€å‘ä¸Šã—ã€Controlled RippleEditãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯æ–°ã—ã„é–¢ä¿‚ã‚„ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«å¯¾ã™ã‚‹çŸ¥è­˜ä¼æ’­ã‚’è©•ä¾¡ã€‚PropMENDã¯æ—¢å­˜ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ãŒã€æ€§èƒ½å·®ã¯ç¸®å°ã—ã¦ãŠã‚Šã€ä»Šå¾Œã®ç ”ç©¶ã§åºƒç¯„ãªé–¢ä¿‚ã¸ã®çŸ¥è­˜ä¼æ’­ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zeyuliu10/status/1934659512046330057?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¾“æ¥ã®Knowledge Editingæ‰‹æ³•ã¯æ–°ãŸãªçŸ¥è­˜ã‚’è¨˜æ†¶ã•ã›ã‚‹ã“ã¨ã¯ã§ãã‚‹ï¼ˆi.e., æ³¨å…¥ã—ãŸçŸ¥è­˜ã‚’é€èªçš„ã«ç”Ÿæˆã§ãã‚‹;æ±äº¬ã¯æ—¥æœ¬ã®é¦–éƒ½ã§ã‚ã‚‹ã€‚ï¼‰ãŒã€çŸ¥è­˜ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã¯è‹¦æ‰‹ã ã£ãŸï¼ˆi.e., æ—¥æœ¬ã®é¦–éƒ½ã®æ°—å€™ã¯ï¼Ÿï¼‰ã®ã§ã€ãã‚Œã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br>æ—¢å­˜æ‰‹æ³•ã®limitationã¯<br>- editingæ‰‹æ³•ã§å­¦ç¿’ã‚’ã™ã‚‹éš›ã«çŸ¥è­˜ã‚’ä¼æ¬ã•ã›ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒç„¡ã<br>- ç›®çš„é–¢æ•°ãŒraw textã§ã¯ãªãã€QA pairã‚’SFTã™ã‚‹ã“ã¨<br><br>ã«ã‚ˆã£ã¦ç”Ÿã˜ã‚‹ã¨ã—ã€<br><br>- å­¦ç¿’æ™‚ã«propagation questionï¼ˆFigure1ã®ã‚ªãƒ¬ãƒ³ã‚¸è‰²ã®QA; æ³¨å…¥ã—ãŸçŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦æ¨è«–ãŒå¿…è¦ãªQA)ã‚’ç”¨æ„ã—ã©ã®ã‚ˆã†ã«çŸ¥è­˜ã‚’ä¼æ¬ï¼ˆæ´»ç”¨ï¼‰ã•ã›ã‚‹ã‹ã‚’å­¦ç¿’ã—<br>- ç›®çš„é–¢æ•°ã‚’Causal Language Modeling Loss<br><br>ã«ã™ã‚‹ã“ã¨ã§æ”¹å–„ã™ã‚‹ã€ã¨ã®ã“ã¨ã€‚<br><br><img src="https://github.com/user-attachments/assets/3f915a57-89c9-412f-a950-f86d35d72cd3" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/50cbbdba-c23e-405d-8ed1-1deea14d3384" alt="image" loading="lazy"><br><br>non-verbatimãªQAï¼ˆæ³¨å…¥ã•ã‚ŒãŸçŸ¥è­˜ã‚’ãã®ã¾ã¾å›ç­”ã™ã‚‹ã‚‚ã®ã§ã¯ãªãã€ä½•ã‚‰ã‹ã®æ¨è«–ãŒå¿…è¦ãªã‚‚ã®ï¼‰ã§ã‚‚æ€§èƒ½ãŒå‘ä¸Šã€‚<br><img src="https://github.com/user-attachments/assets/ebae00b4-d622-4c45-9eca-abfc23762c25" alt="image" loading="lazy"></p>
<p>ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/643" target="_blank" rel="noopener noreferrer">Mass-Editing Memory in a Transformer, Kevin Meng+, N/A, ICLR'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2055" target="_blank" rel="noopener noreferrer">[Paper Note] Fast Model Editing at Scale, Eric Mitchell+, ICLR'22</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/OptimalTransport.html" target="_blank" rel="noopener noreferrer">#OptimalTransport</a>
<span class="issue_date">Issue Date: 2025-06-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2040" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Steer LLM Latents for Hallucination Detection, Seongheon Park+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®å¹»è¦šå•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€Truthfulness Separator Vectorï¼ˆTSVï¼‰ã‚’ææ¡ˆã€‚TSVã¯ã€LLMã®è¡¨ç¾ç©ºé–“ã‚’å†æ§‹ç¯‰ã—ã€çœŸå®Ÿã¨å¹»è¦šã®å‡ºåŠ›ã‚’åˆ†é›¢ã™ã‚‹è»½é‡ãªæŒ‡å‘ãƒ™ã‚¯ãƒˆãƒ«ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã›ãšã«æ©Ÿèƒ½ã€‚äºŒæ®µéšã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€å°‘æ•°ã®ãƒ©ãƒ™ãƒ«ä»˜ãä¾‹ã‹ã‚‰TSVã‚’è¨“ç·´ã—ã€ãƒ©ãƒ™ãƒ«ã®ãªã„ç”Ÿæˆç‰©ã‚’æ‹¡å¼µã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€TSVã¯æœ€å°é™ã®ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€å®Ÿä¸–ç•Œã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹å®Ÿç”¨çš„ãªè§£æ±ºç­–ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sharonyixuanli/status/1933522788645810493?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>openreview: 


<a href="https://openreview.net/forum?id=UMqNQEPNT3&noteId=mAbrf36RHa" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=UMqNQEPNT3&noteId=mAbrf36RHa</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Reproducibility.html" target="_blank" rel="noopener noreferrer">#Reproducibility</a>
<span class="issue_date">Issue Date: 2025-06-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2039" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Give Me FP32 or Give Me Death? Challenges and Solutions for Reproducible  Reasoning, Jiayi Yuan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å†ç¾æ€§ãŒè„†å¼±ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆã®å¤‰æ›´ãŒå¿œç­”ã«å¤§ããªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã—ãŸã€‚ç‰¹ã«ã€åˆæœŸãƒˆãƒ¼ã‚¯ãƒ³ã®ä¸¸ã‚èª¤å·®ãŒæ¨è«–ç²¾åº¦ã«æ³¢åŠã™ã‚‹å•é¡Œã‚’æŒ‡æ‘˜ã—ã€æµ®å‹•å°æ•°ç‚¹æ¼”ç®—ã®éçµåˆçš„æ€§è³ªãŒå¤‰å‹•ã®æ ¹æœ¬åŸå› ã§ã‚ã‚‹ã¨ã—ã¦ã„ã¾ã™ã€‚æ§˜ã€…ãªæ¡ä»¶ä¸‹ã§ã®å®Ÿé¨“ã‚’é€šã˜ã¦ã€æ•°å€¤ç²¾åº¦ãŒå†ç¾æ€§ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’å®šé‡åŒ–ã—ã€è©•ä¾¡å®Ÿè·µã«ãŠã‘ã‚‹é‡è¦æ€§ã‚’å¼·èª¿ã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€LayerCastã¨ã„ã†è»½é‡æ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é–‹ç™ºã—ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã¨æ•°å€¤å®‰å®šæ€§ã‚’ä¸¡ç«‹ã•ã›ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-06-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2036" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Adapting Language Models, Adam Zweiger+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±é©å¿œå‹LLMsï¼ˆSEALï¼‰ã‚’ææ¡ˆã—ã€ãƒ¢ãƒ‡ãƒ«ãŒè‡ªèº«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨æŒ‡ç¤ºã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§é©å¿œã‚’å®Ÿç¾ã€‚æ–°ã—ã„å…¥åŠ›ã«å¯¾ã—ã¦è‡ªå·±ç·¨é›†ã‚’è¡Œã„ã€æŒç¶šçš„ãªé‡ã¿ã®æ›´æ–°ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚å¼·åŒ–å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã‚’ç”¨ã„ã¦ä¸‹æµæ€§èƒ½ã‚’å ±é…¬ä¿¡å·ã¨ã—ã¦æ´»ç”¨ã—ã€å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ç•°ãªã‚Šã€ãƒ¢ãƒ‡ãƒ«è‡ªèº«ã®ç”Ÿæˆã‚’ç”¨ã„ã¦é©å¿œã‚’åˆ¶å¾¡ã€‚å®Ÿé¨“çµæœã¯SEALã®æœ‰æœ›æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jyo_pari/status/1933350025284702697?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆCã¨è©•ä¾¡ãƒ‡ãƒ¼ã‚¿tauãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€Cã‚’å…¥åŠ›ã—ãŸæ™‚ã«ãƒ¢ãƒ‡ãƒ«ãŒè‡ªåˆ†ã‚’SFTã—ã€tauä¸Šã§ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’å¾—ã‚‰ã‚Œã‚‹ã‚ˆã†ãªã‚µãƒ³ãƒ—ãƒ« Self Edit (SE) ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€æ€§èƒ½ã‚’å‘ä¸Šã•ã›ãŸã„ã€‚ã“ã‚Œã‚’RLã«ã‚ˆã£ã¦å®Ÿç¾ã™ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€ä¸‹è¨˜ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«ã«SEã‚’ç”Ÿæˆã•ã›ã€SEã§SFTã™ã‚‹ã“ã¨ã‚ã«tauä¸Šã§ã®æ€§èƒ½ãŒå‘ä¸Šã—ãŸã‹å¦ã‹ã®binary rewardã‚’ç”¨ã„ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚’ç¹°ã‚Šè¿”ã™ã€‚ã“ã‚Œã¯å®Ÿè³ªã€RL_updateã¨æ›¸ã„ã¦ã‚ã‚‹ãŒã€æ€§èƒ½ãŒå‘ä¸Šã—ãŸè‰¯ã„SEã®ã¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’SFTã™ã‚‹ã“ã¨ã€ã¨åŒç­‰ãªã“ã¨ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/69a395da-521f-444d-af6f-4c1b25bb6765" alt="image" loading="lazy"><br><br>ã“ã®ã‚ˆã†ãªèƒŒæ™¯ã¨ã—ã¦ã€RLã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨ã—ã¦GRPOã‚„PPOã‚’é©ç”¨ã—ãŸã¨ã“ã‚å­¦ç¿’ãŒä¸å®‰å®šã§ã†ã¾ãã„ã‹ãªã‹ã£ãŸãŸã‚ã€ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ReST^EMï¼ˆ<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2041" target="_blank" rel="noopener noreferrer">[Paper Note] Beyond Human Data: Scaling Self-Training for Problem-Solving with   Language Models, Avi Singh+, TMLR'24</a>
)ã‚’æ¡ç”¨ã—ãŸã€‚ã“ã‚Œã¯rejection samplingã¨SFTã«åŸºã¥ã„ãŸEMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ã‚ˆã†ãªã‚‚ã®ã‚‰ã—ãã€Eã‚¹ãƒ†ãƒƒãƒ—ã§ç¾åœ¨ã®ãƒãƒªã‚·ãƒ¼ã§candidateã‚’ç”Ÿæˆã—ã€Mã‚¹ãƒ†ãƒƒãƒ—ã§positive rewardã‚’å¾—ãŸcandidateã®ã¿ï¼ˆï¼rejection sampling)ã§SFTã™ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚’ç¹°ã‚Šè¿”ã™ã€ã¿ãŸã„ãªæ‰‹æ³•ã‚‰ã—ã„ã€‚ã“ã‚Œã‚’ç”¨ã„ã‚‹ã¨ã€è«–æ–‡ä¸­ã®å¼(1)ã‚’ä¸Šè¿°ã®binary rewardã§è¿‘ä¼¼ã™ã‚‹ã“ã¨ã«ç›¸å½“ã™ã‚‹ã€‚ã‚ˆã‚Šè©³ç´°ã«æ›¸ãã¨ã€å¼(1)ï¼ˆã¤ã¾ã‚Šã€SEã‚’Cã‹ã‚‰ç”Ÿæˆã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦å¾—ã‚‰ã‚Œã‚‹tauã«åŸºã¥ãå ±é…¬rã®ç·å ±é…¬ã‚’æœ€å¤§åŒ–ã—ãŸã„ã€ã¨ã„ã†å¼ï¼‰ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã«Î¸_tã®å‹¾é…ã‚’è¨ˆç®—ã—ãŸã„ãŒã€reward rãŒÎ¸_tã§å¾®åˆ†ä¸å¯èƒ½ãªãŸã‚ã€Monte Carlo Estimatorã§å‹¾é…ã‚’è¿‘ä¼¼ã™ã‚‹ã€ã¿ãŸã„ãªã“ã¨ã‚’ã‚„ã‚‹ã‚‰ã—ã„ã€‚Monte Carlo Estimatorã§ã¯å®Ÿéš›ã®ã‚µãƒ³ãƒ—ãƒ«ã®æœŸå¾…å€¤ã«ã‚ˆã£ã¦ç†è«–çš„ãªå‹¾é…ã‚’è¿‘ä¼¼ã™ã‚‹ã‚‰ã—ãã€ã“ã‚ŒãŒå¼(3)ã®ã‚¹ã‚³ã‚¢é–¢æ•°ã¨reward rã®å¹³å‡ã€ã¨ã„ã£ãŸå¼ã«ã¤ãªãŒã£ã¦ã„ã‚‹ã‚ˆã†ã§ã‚ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2035" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Resa: Transparent Reasoning Models via SAEs, Shangshang Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Resaã¨ã„ã†1.5Bã®æ¨è«–ãƒ¢ãƒ‡ãƒ«ç¾¤ã‚’ææ¡ˆã—ã€åŠ¹ç‡çš„ãªã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSAE-Tuningï¼‰æ‰‹æ³•ã‚’ç”¨ã„ã¦è¨“ç·´ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€97%ä»¥ä¸Šã®æ¨è«–æ€§èƒ½ã‚’ä¿æŒã—ã¤ã¤ã€è¨“ç·´ã‚³ã‚¹ãƒˆã‚’2000å€ä»¥ä¸Šå‰Šæ¸›ã—ã€è¨“ç·´æ™‚é–“ã‚’450å€ä»¥ä¸ŠçŸ­ç¸®ã€‚è»½ã„RLè¨“ç·´ã‚’æ–½ã—ãŸãƒ¢ãƒ‡ãƒ«ã§é«˜ã„æ¨è«–æ€§èƒ½ã‚’å®Ÿç¾ã—ã€æŠ½å‡ºã•ã‚ŒãŸæ¨è«–èƒ½åŠ›ã¯ä¸€èˆ¬åŒ–å¯èƒ½ã‹ã¤ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–å¯èƒ½ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚å…¨ã¦ã®æˆæœç‰©ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1933101904529363112?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/upupwang/status/1933207676663865482?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è«–æ–‡ä¸­ã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹Source Modelã®ä¸€ã¤:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1935" target="_blank" rel="noopener noreferrer">[Paper Note] Tina: Tiny Reasoning Models via LoRA, Shangshang Wang+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-06-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2033" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Text-to-LoRA: Instant Transformer Adaption, Rujikorn Charakorn+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- Text-to-LoRAï¼ˆT2Lï¼‰ã¯ã€è‡ªç„¶è¨€èªã«ã‚ˆã‚‹èª¬æ˜ã«åŸºã¥ã„ã¦å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’è¿…é€Ÿã«é©å¿œã•ã›ã‚‹æ‰‹æ³•ã§ã€å¾“æ¥ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®é«˜ã‚³ã‚¹ãƒˆã¨æ™‚é–“ã‚’å…‹æœã—ã¾ã™ã€‚T2Lã¯ã€LoRAã‚’å®‰ä¾¡ãªãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã§æ§‹ç¯‰ã™ã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã€ã‚¿ã‚¹ã‚¯ç‰¹æœ‰ã®ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¾ã™ã€‚ã¾ãŸã€æ•°ç™¾ã®LoRAã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åœ§ç¸®ã—ã€æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§ä¸€èˆ¬åŒ–å¯èƒ½ã§ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å°‚é–€åŒ–ã‚’æ°‘ä¸»åŒ–ã—ã€è¨ˆç®—è¦ä»¶ã‚’æœ€å°é™ã«æŠ‘ãˆãŸè¨€èªãƒ™ãƒ¼ã‚¹ã®é©å¿œã‚’å®Ÿç¾ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/roberttlange/status/1933074366603919638?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãªã€ãªã‚‹ã»ã©ã€ã“ã‚“ãªæ‰‹ãŒâ€¦ï¼</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-06-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2032" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Go-Browse: Training Web Agents with Structured Exploration, Apurva Gandhi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Go-Browseã‚’ææ¡ˆã—ã€ã‚¦ã‚§ãƒ–ç’°å¢ƒã®æ§‹é€ çš„æ¢ç´¢ã‚’é€šã˜ã¦å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•åé›†ã€‚ã‚°ãƒ©ãƒ•æ¢ç´¢ã‚’ç”¨ã„ã¦åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿åé›†ã‚’å®Ÿç¾ã—ã€WebArenaãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æˆåŠŸç‡21.7%ã‚’é”æˆã€‚ã“ã‚Œã¯GPT-4o miniã‚’2.4%ä¸Šå›ã‚Šã€10Bæœªæº€ã®ãƒ¢ãƒ‡ãƒ«ã§ã®æœ€å…ˆç«¯çµæœã‚’2.9%ä¸Šå›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1932786231542493553?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>WebArena:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1849" target="_blank" rel="noopener noreferrer">WebArena: A Realistic Web Environment for Building Autonomous Agents, Shuyan Zhou+, ICLR'24</a>
</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2025-06-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2031" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reinforcement Pre-Training, Qingxiu Dong+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¼·åŒ–å­¦ç¿’ã¨å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ–°ã—ã„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ‰‹æ³•ã€Œå¼·åŒ–äº‹å‰å­¦ç¿’ï¼ˆRPTï¼‰ã€ã‚’ææ¡ˆã€‚æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã‚’å¼·åŒ–å­¦ç¿’ã®æ¨è«–ã‚¿ã‚¹ã‚¯ã¨ã—ã¦å†å®šç¾©ã—ã€ä¸€èˆ¬çš„ãªRLã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ã®æ³¨é‡ˆã«ä¾å­˜ã›ãšã«ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªæ–¹æ³•ã‚’æä¾›ã€‚RPTã¯æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€å¼·åŒ–ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŸºç›¤ã‚’å½¢æˆã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨ˆç®—é‡ã®å¢—åŠ ãŒç²¾åº¦ã‚’æ”¹å–„ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã€RPTãŒè¨€èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ã«ãŠã„ã¦æœ‰æœ›ãªæ‰‹æ³•ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1932922314578145640?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-06-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2030" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Value Residual Learning, Zhanchao Zhou+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- ResFormerã¯ã€éš ã‚ŒçŠ¶æ…‹ã®æ®‹å·®ã«å€¤ã®æ®‹å·®æ¥ç¶šã‚’åŠ ãˆã‚‹ã“ã¨ã§æƒ…å ±ã®æµã‚Œã‚’å¼·åŒ–ã™ã‚‹æ–°ã—ã„Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ææ¡ˆã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ResFormerã¯å¾“æ¥ã®Transformerã«æ¯”ã¹ã¦å°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã§åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ã€SVFormerã¯KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã‚’åŠæ¸›ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚æ€§èƒ½ã¯ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é•·ã•ã‚„å­¦ç¿’ç‡ã«ä¾å­˜ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhanchaozhou/status/1932829678081098079?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-06-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2027" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Saffron-1: Towards an Inference Scaling Paradigm for LLM Safety  Assurance, Ruizhong Qiu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ—¢å­˜ã®LLMã®å®‰å…¨ä¿è¨¼ç ”ç©¶ã¯ä¸»ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ®µéšã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ãŒã€è„±ç„æ”»æ’ƒã«å¯¾ã—ã¦è„†å¼±ã§ã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ¨è«–ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ç”¨ã„ãŸæ–°ãŸãªå®‰å…¨æ€§å‘ä¸Šæ‰‹æ³•SAFFRONã‚’ææ¡ˆã—ã€è¨ˆç®—ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å‰Šæ¸›ã™ã‚‹å¤šåˆ†å²å ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼ˆMRMï¼‰ã‚’å°å…¥ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å ±é…¬ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®æ•°ã‚’æ¸›ã‚‰ã—ã€æ¢ç´¢-åŠ¹ç‡æ€§ã®ã‚¸ãƒ¬ãƒ³ãƒã‚’å…‹æœã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šæ‰‹æ³•ã®æœ‰åŠ¹æ€§ã‚’ç¢ºèªã—ã€è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨å®‰å…¨å ±é…¬ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gaotangli/status/1932289294657626189?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Subword.html" target="_blank" rel="noopener noreferrer">#Subword</a>
<span class="issue_date">Issue Date: 2025-06-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2026" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] StochasTok: Improving Fine-Grained Subword Understanding in LLMs, Anya Sims+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚µãƒ–ãƒ¯ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã®ç†è§£ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€ç¢ºç‡çš„ãƒˆãƒ¼ã‚¯ãƒ³åŒ–æ‰‹æ³•StochasTokã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã¯å†…éƒ¨æ§‹é€ ã‚’æŠŠæ¡ã—ã‚„ã™ããªã‚Šã€æ–‡å­—ã‚«ã‚¦ãƒ³ãƒˆã‚„æ•°å­¦ã‚¿ã‚¹ã‚¯ãªã©ã§æ€§èƒ½ãŒå‘ä¸Šã€‚ã‚·ãƒ³ãƒ—ãƒ«ãªè¨­è¨ˆã«ã‚ˆã‚Šã€æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã¸ã®çµ±åˆãŒå®¹æ˜“ã§ã€ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã¤ã¤ã‚µãƒ–ãƒ¯ãƒ¼ãƒ‰ç†è§£ã‚’æ”¹å–„ã§ãã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cong_ml/status/1932369418534760554?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãŠã‚‚ã—ã‚ãã†</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-06-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2023" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Representation Shattering in Transformers: A Synthetic Study with   Knowledge Editing, Kento Nishi+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- çŸ¥è­˜ç·¨é›†ï¼ˆKEï¼‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’å¤‰æ›´ã—ã¦ä¸æ­£ç¢ºãªäº‹å®Ÿã‚’æ›´æ–°ã™ã‚‹ãŒã€ã“ã‚ŒãŒãƒ¢ãƒ‡ãƒ«ã®äº‹å®Ÿã®æƒ³èµ·ç²¾åº¦ã‚„æ¨è«–èƒ½åŠ›ã«æ‚ªå½±éŸ¿ã‚’åŠã¼ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚æ–°ãŸã«å®šç¾©ã—ãŸåˆæˆã‚¿ã‚¹ã‚¯ã‚’é€šã˜ã¦ã€KEãŒã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’è¶…ãˆã¦ä»–ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®è¡¨ç¾ã«å½±éŸ¿ã‚’ä¸ãˆã€æœªè¦‹ã®çŸ¥è­˜ã®æ¨è«–ã‚’æ­ªã‚ã‚‹ã€Œè¡¨ç¾ã®ç ´å£Šã€ç¾è±¡ã‚’ç¤ºã™ã€‚äº‹å‰è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã‚‚ã“ã®ç™ºè¦‹ãŒç¢ºèªã•ã‚Œã€KEãŒãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã«æ‚ªå½±éŸ¿ã‚’åŠã¼ã™ç†ç”±ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ä»®èª¬ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kento_nishi/status/1932072335726539063?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<span class="issue_date">Issue Date: 2025-06-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2022" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Search Arena: Analyzing Search-Augmented LLMs, Mihran Miroyan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¤œç´¢å¼·åŒ–å‹LLMsã«é–¢ã™ã‚‹ã€ŒSearch Arenaã€ã¨ã„ã†å¤§è¦æ¨¡ãªäººé–“ã®å¥½ã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç´¹ä»‹ã€‚24,000ä»¥ä¸Šã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’å«ã¿ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ãŒå¼•ç”¨æ•°ã‚„å¼•ç”¨å…ƒã«å½±éŸ¿ã•ã‚Œã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚ç‰¹ã«ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ä¸»å°ã®æƒ…å ±æºãŒå¥½ã¾ã‚Œã‚‹å‚¾å‘ãŒã‚ã‚Šã€é™çš„ãªæƒ…å ±æºã¯å¿…ãšã—ã‚‚ä¿¡é ¼ã•ã‚Œãªã„ã€‚æ¤œç´¢å¼·åŒ–å‹LLMsã®æ€§èƒ½ã‚’è©•ä¾¡ã—ãŸçµæœã€éæ¤œç´¢è¨­å®šã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸ŠãŒç¢ºèªã•ã‚ŒãŸãŒã€æ¤œç´¢è¨­å®šã§ã¯ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯çŸ¥è­˜ã«ä¾å­˜ã™ã‚‹ã¨å“è³ªãŒä½ä¸‹ã™ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æä¾›ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mirmiroyan/status/1931081734764081391?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-06-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2019" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning  Logical Reasoning and Beyond, Junteng Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- SynLogicã¯ã€35ã®è«–ç†çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã‚’ç¶²ç¾…ã—ãŸãƒ‡ãƒ¼ã‚¿åˆæˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã«ã‚ˆã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ¨è«–èƒ½åŠ›å‘ä¸Šã‚’ç›®æŒ‡ã™ã€‚èª¿æ•´å¯èƒ½ãªé›£æ˜“åº¦ã§ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯æ¤œè¨¼å¯èƒ½ã§ã€RLã«é©ã—ã¦ã„ã‚‹ã€‚å®Ÿé¨“ã§ã¯ã€SynLogicãŒæœ€å…ˆç«¯ã®è«–ç†çš„æ¨è«–æ€§èƒ½ã‚’é”æˆã—ã€æ•°å­¦ã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã¨ã®æ··åˆã«ã‚ˆã‚Šãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚SynLogicã¯LLMsã®æ¨è«–èƒ½åŠ›å‘ä¸Šã«è²´é‡ãªãƒªã‚½ãƒ¼ã‚¹ã¨ãªã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/junxian_he/status/1930558456907669638?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>35ç¨®é¡ã®ã‚¿ã‚¹ã‚¯ã‚’äººæ‰‹ã§é¸å®šã—ã€ã‚¿ã‚¹ã‚¯ã”ã¨ã«å›°é›£åº¦ã®éµã¨ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©ï¼ˆæ•°ç‹¬ãªã‚‰ã°ã‚°ãƒªãƒƒãƒ‰æ•°ãªã©ï¼‰ã€‚ãã®ä¸Šã§ã€å„ã‚¿ã‚¹ã‚¯ã”ã¨ã«äººæ‰‹ã§ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®instanceã‚’ç”Ÿæˆã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã€ã•ã¾ã–ã¾ãªå›°é›£åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦å¤šæ§˜ãªinstanceã‚’ç”Ÿæˆã€‚ç”Ÿæˆã•ã‚ŒãŸinstanceã®å›°é›£åº¦ã¯ã€è¿‘ä¼¼çš„ãªUpper Bound(DeepSeek-R1, o3-miniã®Pass@10)ã¨Lower boundï¼ˆchat model[^1]ã§ã®Pass@10)ã‚’æ±‚ã‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å«ã¾ã‚Œã‚‹instanceã®å›°é›£åº¦ã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã—ã€taskã‚’è¨˜è¿°ã™ã‚‹promptã‚‚ç”Ÿæˆã€‚ã‚¿ã‚¹ã‚¯ã”ã¨ã«äººæ‰‹ã§å®Ÿè£…ã•ã‚ŒãŸVerifierã‚‚ç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/cda0534d-7db2-4470-93b8-01f446476544" alt="image" loading="lazy"><br><br>Qwen2.5-7B-Baseã‚’SynDataã§DAPOã—ãŸã¨ã“ã‚ã€å¤§å¹…ã«logic benchmarkã¨mathematical benchmarkã®æ€§èƒ½ãŒæ”¹å–„ã€‚<br><img src="https://github.com/user-attachments/assets/dcc1309d-7946-4a6d-91a3-7ccac9ec6688" alt="image" loading="lazy"><br><br>mathã‚„codeã®ãƒ‡ãƒ¼ã‚¿ã¨mixã—ã¦7Bãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ãŸã¨ã“ã‚ã€32Bãƒ¢ãƒ‡ãƒ«ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’é”æˆã—ã€SynDataã‚’mixã™ã‚‹ã“ã¨ã§gainãŒå¤§ãããªã£ãŸã®ã§ã€SynDataã‹ã‚‰å­¦ç¿’ã§ãã‚‹èƒ½åŠ›ãŒæ±åŒ–ã™ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/7b618fe9-5271-434b-9808-f53f0e758e5e" alt="image" loading="lazy"><br><br>ã‚¿ã‚¹ã‚¯ä¸€è¦§ã¯ã“ã¡ã‚‰<br><img src="https://github.com/user-attachments/assets/50fcdcb3-701e-4d42-94c7-201d8d354d75" alt="image" loading="lazy"><br><br>[^1]:ã©ã®chat modelã‹ã¯ã–ã£ã¨è¦‹ãŸæ„Ÿã˜ã‚ã‹ã‚‰ãªã„ã€‚ã©ã“ã‹ã«æ›¸ã„ã¦ã‚ã‚‹ã‹ã‚‚ã€‚</p>
<p>Logical ReasoningãŒé‡è¦ãªã‚¿ã‚¹ã‚¯ã‚’æ‰±ã†éš›ã¯ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ã¿ã¦ã‚‚è‰¯ã„ã‹ã‚‚ã—ã‚Œãªã„</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-06-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2018" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Training Language Models to Generate Quality Code with Program Analysis  Feedback, Feng Yao+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ­ã‚°ãƒ©ãƒ åˆ†æã«åŸºã¥ããƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”¨ã„ãŸå¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒREALã€ã‚’ææ¡ˆã€‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚„ä¿å®ˆæ€§ã®æ¬ é™¥ã‚’æ¤œå‡ºã—ã€æ©Ÿèƒ½çš„æ­£ç¢ºæ€§ã‚’ä¿è¨¼ã™ã‚‹ã“ã¨ã§ã€LLMsã«ã‚ˆã‚‹é«˜å“è³ªãªã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚’ä¿ƒé€²ã€‚æ‰‹å‹•ä»‹å…¥ä¸è¦ã§ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªç›£è¦–ã‚’å®Ÿç¾ã—ã€å®Ÿé¨“ã«ã‚ˆã‚Šæœ€å…ˆç«¯ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fengyao1909/status/1930377346693116350?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¾åœ¨ã®Coding LLMã¯UnitTestã‚’é€šã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã‚‹ãŒã€UnitTestã«é€šã‚‹ã‹ã‚‰ã¨ã„ã£ã¦ã‚³ãƒ¼ãƒ‰ã®å“è³ªãŒè‰¯ã„ã‚ã‘ã§ã¯ç„¡ã„ã®ã§ã€UnitTestã«é€šã‚‹ã‹å¦ã‹ã®Rewardï¼ˆFunctionality)ã«åŠ ãˆã¦ã€RLä¸­ã«ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ã‚°ãƒ©ãƒ•[^1]ã«å¤‰æ›ã—æ±šæŸ“è§£æ[^2]ã‚’ã—ãŸçµæœã‚’Rewardã«çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€Functionalityã¨Qualityã‚’ä¸¡ç«‹ã—ãŸã‚ˆã€ã¨ã„ã†è©±ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><br>Figure1ã®ã‚°ãƒ©ãƒ•ã®ç¸¦è»¸ã¯ã€Functionalityã¨ï¼ˆUnitTestãŒé€šã£ãŸã‹å¦ã‹ï¼‰ã¨ã€Quailty(ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚„ä¿å®ˆæ€§ã«é–¢ã™ã‚‹å•é¡ŒãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸ)ã€ã¨ã„ã†ä¸¡æ–¹ã®æ¡ä»¶ã‚’æº€ãŸã—ãŸå‰²åˆã§ã‚ã‚‹ç‚¹ã«æ³¨æ„ã€‚<br><br><img src="https://github.com/user-attachments/assets/b843e416-8c96-40ca-ac1f-0318eb1ae40c" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/6beeea63-571b-4ce6-bef8-ac8e0cfffee2" alt="image" loading="lazy"><br><br>[^1]:ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’å®Ÿè¡Œã—ãŸã¨ãã«é€šã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹çµŒè·¯ã®ã™ã¹ã¦ã‚’ã‚°ãƒ©ãƒ•ã¨ã—ã¦è¡¨ã—ãŸã‚‚ã®[å¼•ç”¨å…ƒ](


<a href="https://qiita.com/uint256_t/items/7d4556cb8f5997b9e95c)" target="_blank" rel="noopener noreferrer">https://qiita.com/uint256_t/items/7d4556cb8f5997b9e95c)</a>


<br>[^2]:ä¿¡é ¼ã§ããªã„æ±šæŸ“ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒãƒ—ãƒ­ã‚°ãƒ©ãƒ ä¸­ã§ã©ã®ã‚ˆã†ã«å‡¦ç†ã•ã‚Œã‚‹ã‹ã‚’åˆ†æã™ã‚‹ã“ã¨</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-06-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2017" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Writing-Zero: Bridge the Gap Between Non-verifiable Problems and  Verifiable Rewards, Xun Lu, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- éæ¤œè¨¼å¯èƒ½ãªã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹å¼·åŒ–å­¦ç¿’ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã€ãƒšã‚¢ãƒ¯ã‚¤ã‚ºç”Ÿæˆå ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼ˆGenRMï¼‰ã¨ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ç›¸å¯¾ãƒãƒªã‚·ãƒ¼æœ€é©åŒ–ï¼ˆBRPOï¼‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ä¸»è¦³çš„è©•ä¾¡ã‚’ä¿¡é ¼æ€§ã®ã‚ã‚‹æ¤œè¨¼å¯èƒ½ãªå ±é…¬ã«å¤‰æ›ã—ã€å‹•çš„ãªãƒšã‚¢ãƒ¯ã‚¤ã‚ºæ¯”è¼ƒã‚’å®Ÿç¾ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€LLMsã®åŸ·ç­†èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã€ã‚¹ã‚«ãƒ©ãƒ¼å ±é…¬ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«å¯¾ã—ã¦ä¸€è²«ã—ãŸæ”¹å–„ã‚’ç¤ºã—ã€ç«¶äº‰åŠ›ã®ã‚ã‚‹çµæœã‚’é”æˆã€‚å…¨ã¦ã®è¨€èªã‚¿ã‚¹ã‚¯ã«é©ç”¨å¯èƒ½ãªåŒ…æ‹¬çš„ãªRLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã®å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/grad62304977/status/1929996614883783170?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Writing Principleã«åŸºã¥ã„ã¦ï¼ˆe.g., ä¸€è²«æ€§ã€å‰µé€ æ€§ã¨ã‹ï¼Ÿï¼‰æ‰¹è©•ã‚’è¨˜è¿°ã—ã€æœ€çµ‚çš„ã«ä¸ãˆã‚‰ã‚ŒãŸãƒšã‚¢ãƒ¯ã‚¤ã‚ºã®ãƒ†ã‚­ã‚¹ãƒˆã®å„ªåŠ£ã‚’åˆ¤æ–­ã™ã‚‹Generative Reward Model (GenRM; Reasoning Traceã‚’ä¼´ã„æœ€çµ‚çš„ã«Rewardã«å¤‰æ›å¯èƒ½ãªæƒ…å ±ã‚’outpuã™ã‚‹ãƒ¢ãƒ‡ãƒ«) ã‚’å­¦ç¿’ã—ã€ç¾åœ¨ç”Ÿæˆã—ãŸresponseã‚°ãƒ«ãƒ¼ãƒ—ã®ä¸­ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«ä¸€ã¤æ“¬ä¼¼çš„ãªreferenceã‚’æ±ºå®šã—ã€ä»–ã®responseã«å¯¾ã—GenRMã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§å ±é…¬ã‚’æ±ºå®šã™ã‚‹ï¼ˆBRPOï¼‰ã€ã¨ã„ã£ãŸã“ã¨ã‚’ã‚„ã‚‹ã‚‰ã—ã„ã€‚<br><br>ã“ã‚Œã«ã‚ˆã‚Šã€å‰µé€ çš„ãªæ–‡æ›¸ä½œæˆã®ã‚ˆã†ãªå®¢è¦³çš„ãªground truthã‚’é©ç”¨ã§ããªã„ã‚¿ã‚¹ã‚¯ã§ã‚‚ã€RLVRã®æ©æµã‚’ã‚ãšã‹ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ï¼ˆBridging the gap)ã¨ã„ã£ãŸã“ã¨ã‚’ä¸»å¼µã—ã¦ã„ã‚‹ã€‚</p>
<p>RLVRã®æ©æµã¨ã¯ã€Reward Hackingã•ã‚Œã¥ã‚‰ã„é«˜å“è³ªãªå ±é…¬ã€ã¨ã„ã†ã“ã¨ã«ã‚ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚ã®ã§ã€è¦ã¯å¾“æ¥ã®Preference dataã ã‘ã§å­¦ç¿’ã—ãŸReward Modelã‚ˆã‚Šã‚‚ã€ã‚ˆã‚ŠReward Hackingã•ã‚Œãªã„ãƒ­ãƒã‚¹ãƒˆãªå­¦ç¿’ã‚’å®Ÿç¾ã§ãã‚‹Generative Reward Modelã‚’ææ¡ˆã—ã€ãã‚Œã‚’é©ç”¨ã™ã‚‹æ‰‹æ³•BRPOã‚‚ææ¡ˆã—ã¾ã—ãŸã€ã¨ã„ã†è©±ã«è¦‹ãˆã‚‹ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2274" target="_blank" rel="noopener noreferrer">[Paper Note] Inference-Time Scaling for Generalist Reward Modeling, Zijun Liu+, arXiv'25</a>
 </p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/UnitTest.html" target="_blank" rel="noopener noreferrer">#UnitTest</a>
<span class="issue_date">Issue Date: 2025-06-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2016" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning, Yinjie Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- CUREã¯ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆç”Ÿæˆã‚’å…±é€²åŒ–ã•ã›ã‚‹å¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€çœŸã®ã‚³ãƒ¼ãƒ‰ã‚’ç›£è¦–ã›ãšã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã€‚ReasonFlux-Coderãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€ä¸‹æµã‚¿ã‚¹ã‚¯ã«ã‚‚åŠ¹æœçš„ã«æ‹¡å¼µå¯èƒ½ã€‚ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆç”Ÿæˆã§ã¯é«˜ã„æ¨è«–åŠ¹ç‡ã‚’é”æˆã—ã€å¼·åŒ–å­¦ç¿’ã®ãŸã‚ã®åŠ¹æœçš„ãªå ±é…¬ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lingyang_pu/status/1930234983274234232?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>UnitTestã®æ€§èƒ½å‘ä¸Šã•ã›ã¾ã™ç³»ã®ç ”ç©¶ãŒå¢—ãˆã¦ãã¦ã„ã‚‹æ„Ÿ</p>
<p>é–¢é€£ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1930348014146859345?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<span class="issue_date">Issue Date: 2025-06-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2015" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement  Learning, Yiqing Liang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¤œè¨¼å¯èƒ½ãªå ±é…¬ã‚’ç”¨ã„ãŸå¼·åŒ–å­¦ç¿’ï¼ˆRLVRï¼‰ã‚’ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMsã«é©ç”¨ã™ã‚‹ãŸã‚ã®ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ç•°ãªã‚‹è¦–è¦šã¨è¨€èªã®å•é¡Œã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã€æœ€é©ãªãƒ‡ãƒ¼ã‚¿æ··åˆæˆ¦ç•¥ã‚’å°å…¥ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆã—ãŸæˆ¦ç•¥ãŒMLLMã®æ¨è«–èƒ½åŠ›ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã€åˆ†å¸ƒå¤–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¹³å‡5.24%ã®ç²¾åº¦å‘ä¸Šã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_vztu/status/1930312780701413498?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªè¨­å®šã§RLVRã‚’é©ç”¨ã™ã‚‹ã¨ã€ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å­¦ç¿’ã«åˆ©ç”¨ã™ã‚‹å ´åˆã‚ˆã‚Šã€ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã®ã¿ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ãŸæ–¹ãŒå½“è©²ã‚¿ã‚¹ã‚¯ã§ã¯æ€§èƒ½ãŒé«˜ããªã£ãŸã‚Šï¼ˆã¤ã¾ã‚Šãƒ‡ãƒ¼ã‚¿ãŒå¤šã‘ã‚Œã°å¤šã„ã»ã©è‰¯ã„ã‚ã‘ã§ã¯ç„¡ã„ï¼‰ã€ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã‚’ablationã™ã‚‹ã¨OODã«å¯¾ã™ã‚‹äºˆæ¸¬æ€§èƒ½ãŒæ”¹å–„ã—ãŸã‚Šã™ã‚‹ãªã©ã€ãƒ‡ãƒ¼ã‚¿é–“ã§å¹²æ¸‰ãŒèµ·ãã¦æ•µå¯¾çš„ã«ãªã£ã¦ã—ã¾ã†ã‚ˆã†ãªç¾è±¡ãŒèµ·ãã‚‹ã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€ã©ã®ã‚ˆã†ã«é©åˆ‡ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ··åˆã§ãã‚‹ã‹ï¼Ÿã¨ã„ã†æˆ¦ç•¥ã®å¿…è¦æ€§ãŒæµ®ãå½«ã‚Šã«ãªã‚Šã€ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ãªMixtureæˆ¦ç•¥ï¼ˆã©ã†ã‚„ã‚‰ãƒ‡ãƒ¼ã‚¿ã®æ··åˆåˆ†å¸ƒã‹ã‚‰å­¦ç¿’å¾Œã®æ€§èƒ½ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãªæ¨¡æ§˜ï¼‰ã®æ€§èƒ½ãŒuniformã«mixã™ã‚‹ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€ã¿ãŸã„ãªè©±ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Memorization.html" target="_blank" rel="noopener noreferrer">#Memorization</a>
<span class="issue_date">Issue Date: 2025-06-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2014" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] How much do language models memorize?, John X. Morris+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¢ãƒ‡ãƒ«ã®ã€ŒçŸ¥è­˜ã€ã‚’æ¨å®šã™ã‚‹æ–°æ‰‹æ³•ã‚’ææ¡ˆã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’æ¸¬å®šã€‚è¨˜æ†¶ã‚’ã€Œæ„å›³ã—ãªã„è¨˜æ†¶ã€ã¨ã€Œä¸€èˆ¬åŒ–ã€ã«åˆ†ã‘ã€ä¸€èˆ¬åŒ–ã‚’æ’é™¤ã™ã‚‹ã“ã¨ã§ç·è¨˜æ†¶ã‚’è¨ˆç®—ã€‚GPTã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã¯ç´„3.6ãƒ“ãƒƒãƒˆ/ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èƒ½åŠ›ã‚’æŒã¤ã¨æ¨å®šã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºå¢—åŠ ã«ä¼´ã„ã€ãƒ¢ãƒ‡ãƒ«ã¯è¨˜æ†¶ã‚’ä¿æŒã—ã€ä¸€èˆ¬åŒ–ãŒå§‹ã¾ã‚‹ã¨æ„å›³ã—ãªã„è¨˜æ†¶ãŒæ¸›å°‘ã€‚æ•°ç™¾ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€èƒ½åŠ›ã¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®é–¢ä¿‚ã‚’ç¤ºã™ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ç”Ÿæˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rohanpaul_ai/status/1929989864927146414?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-06-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2013" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unleashing the Reasoning Potential of Pre-trained LLMs by Critique  Fine-Tuning on One Problem, Yubo Wang+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¼·åŠ›ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®æ¨è«–èƒ½åŠ›ã‚’å¼•ãå‡ºã™ãŸã‚ã«ã€æ‰¹è©•å¾®èª¿æ•´ï¼ˆCFTï¼‰ãŒåŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚CFTã¯ã€å˜ä¸€ã®å•é¡Œã«å¯¾ã™ã‚‹å¤šæ§˜ãªè§£ã‚’åé›†ã—ã€æ•™å¸«LLMã«ã‚ˆã‚‹æ‰¹è©•ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚QwenãŠã‚ˆã³Llamaãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ãŸçµæœã€æ•°å­¦ã‚„è«–ç†æ¨è«–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’è¦³å¯Ÿã—ã¾ã—ãŸã€‚ç‰¹ã«ã€ã‚ãšã‹5æ™‚é–“ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã€Qwen-Math-7B-CFTã¯ä»–ã®æ‰‹æ³•ã¨åŒç­‰ä»¥ä¸Šã®æˆæœã‚’ä¸Šã’ã¾ã—ãŸã€‚CFTã¯è¨ˆç®—åŠ¹ç‡ãŒé«˜ãã€ç¾ä»£ã®LLMã®æ¨è«–èƒ½åŠ›ã‚’å¼•ãå‡ºã™ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1930447298527670662?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1832" target="_blank" rel="noopener noreferrer">Critique Fine-Tuning: Learning to Critique is More Effective than   Learning to Imitate, Yubo Wang+, COLM'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1938" target="_blank" rel="noopener noreferrer">Reinforcement Learning for Reasoning in Large Language Models with One   Training Example, Yiping Wang+, NeurIPS'25</a>
</p>
<p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/weiliu99/status/1930826904522875309?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2012" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents, Jenny Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ€ãƒ¼ãƒ´ã‚£ãƒ³ãƒ»ã‚´ãƒ¼ãƒ‡ãƒ«ãƒã‚·ãƒ³ï¼ˆDGMï¼‰ã¯ã€è‡ªå·±æ”¹å–„ã™ã‚‹AIã‚·ã‚¹ãƒ†ãƒ ã§ã‚ã‚Šã€ã‚³ãƒ¼ãƒ‰ã‚’åå¾©çš„ã«ä¿®æ­£ã—ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¤‰æ›´ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚é€²åŒ–ã¨ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ãªç ”ç©¶ã«åŸºã¥ãã€ç”Ÿæˆã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’ç¶­æŒã—ã€æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½œæˆã™ã‚‹ã“ã¨ã§å¤šæ§˜ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è‚²æˆã—ã¾ã™ã€‚DGMã¯ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°èƒ½åŠ›ã‚’è‡ªå‹•çš„ã«å‘ä¸Šã•ã›ã€SWE-benchã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’20.0%ã‹ã‚‰50.0%ã€Polyglotã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’14.2%ã‹ã‚‰30.7%ã«æ”¹å–„ã—ã¾ã—ãŸã€‚å®‰å…¨å¯¾ç­–ã‚’è¬›ã˜ãŸå®Ÿé¨“ã«ã‚ˆã‚Šã€è‡ªå·±æ”¹å–„ã‚’è¡Œã‚ãªã„ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æˆæœã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/omarsar_new-paper-open-ended-evolution-of-self-improving-activity-7334610178832556033-8dA-?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/omarsar_new-paper-open-ended-evolution-of-self-improving-activity-7334610178832556033-8dA-?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4</a>


</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1212" target="_blank" rel="noopener noreferrer">Self-Rewarding Language Models, Weizhe Yuan+, N/A, ICML'24</a>
<br><br>ã‚ãŸã‚Šã®ç ”ç©¶ã¨ã¯ã©ã†é•ã†ã®ã ã‚ã†ã‹ã€ã¨ã„ã†ç‚¹ãŒæ°—ã«ãªã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2011" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in  Large Language Models, Mingjie Liu+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ãŒè¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹å¯èƒ½æ€§ã‚’æ¢ã‚‹æœ¬ç ”ç©¶ã§ã¯ã€é•·æœŸçš„ãªRLï¼ˆProRLï¼‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒæ–°ã—ã„æ¨è«–æˆ¦ç•¥ã‚’æ˜ã‚‰ã‹ã«ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚æ–°ã—ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ProRLã‚’å°å…¥ã—ã€å®Ÿè¨¼åˆ†æã«ã‚ˆã‚Šã€RLã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒåŸºç¤ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚æ¨è«–ã®æ”¹å–„ã¯åŸºç¤ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æœŸé–“ã¨ç›¸é–¢ã—ã¦ãŠã‚Šã€RLãŒæ–°ã—ã„è§£æ±ºç©ºé–“ã‚’æ¢ç´¢ã§ãã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€RLãŒè¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã‚’æ‹¡å¼µã™ã‚‹æ¡ä»¶ã«é–¢ã™ã‚‹æ–°ãŸãªæ´å¯ŸãŒå¾—ã‚‰ã‚Œã€ä»Šå¾Œã®ç ”ç©¶ã®åŸºç›¤ãŒç¯‰ã‹ã‚Œã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1930043688329326962?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RLVRï¼ˆmath, codeï¼ˆå¾“æ¥ã¯ã“ã®2ç¨®é¡ï¼‰, STEM, logic Puzzles, instruction followingï¼‰ã«ã‚ˆã£ã¦å¤§è¦æ¨¡ãªã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆé•·æœŸçš„ã«å­¦ç¿’ã‚’ã™ã‚‹; 2k training stepsã¨å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã§ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼‰ã§å®Ÿé¨“ã‚’ã—ã€å®šæœŸçš„ã«Referenceãƒãƒªã‚·ãƒ¼ã¨Optimizerã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ã“ã¨ã§ã€å…ƒã®ãƒãƒªã‚·ãƒ¼ã‹ã‚‰ã®ä¹–é›¢ã‚’é˜²ãã¤ã¤ã‚‚ã€æ–°ãŸãªå­¦ç¿’ãŒé€²ã‚€ã‚ˆã†ãªã“ã¨ã‚’ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br>ï¼ˆâ€»PFNã®ãƒ©ãƒ³ãƒã‚¿ã‚¤ãƒ ãƒˆãƒ¼ã‚¯ã‚’å‚è€ƒã«è¨˜è¿°ï¼‰<br><br>verlã‚’ç”¨ã„ã¦ã€DAPOã§å­¦ç¿’ã‚’ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/db706cfc-e756-47d1-a0e7-8fbc8043ae17" alt="image" loading="lazy"><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1969" target="_blank" rel="noopener noreferrer">verl: Volcano Engine Reinforcement Learning for LLMs, ByteDance Seed Team, 2025.04</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1815" target="_blank" rel="noopener noreferrer">DAPO: An Open-Source LLM Reinforcement Learning System at Scale, Qiying Yu+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2010" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] xVerify: Efficient Answer Verifier for Reasoning Model Evaluations, Ding Chen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¨è«–ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã®ãŸã‚ã«ã€xVerifyã¨ã„ã†åŠ¹ç‡çš„ãªå›ç­”æ¤œè¨¼å™¨ã‚’ææ¡ˆã€‚xVerifyã¯ã€LLMãŒç”Ÿæˆã—ãŸå›ç­”ãŒå‚ç…§è§£ç­”ã¨åŒç­‰ã§ã‚ã‚‹ã‹ã‚’åŠ¹æœçš„ã«åˆ¤æ–­ã§ãã‚‹ã€‚VARãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã€è¤‡æ•°ã®LLMã‹ã‚‰ã®è³ªå•-å›ç­”ãƒšã‚¢ã‚’åé›†ã€‚è©•ä¾¡å®Ÿé¨“ã§ã¯ã€ã™ã¹ã¦ã®xVerifyãƒ¢ãƒ‡ãƒ«ãŒ95ï¼…ã‚’è¶…ãˆã‚‹F1ã‚¹ã‚³ã‚¢ã¨ç²¾åº¦ã‚’é”æˆã—ã€ç‰¹ã«xVerify-3B-Ibã¯GPT-4oã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/VerifiableRewards.html" target="_blank" rel="noopener noreferrer">#VerifiableRewards</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2009" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Pitfalls of Rule- and Model-based Verifiers -- A Case Study on  Mathematical Reasoning, Yuzhen Huang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ•°å­¦çš„æ¨è«–ã«ãŠã‘ã‚‹æ¤œè¨¼è€…ã®ä¿¡é ¼æ€§ã¨ãã®RLè¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹ã¸ã®å½±éŸ¿ã‚’åˆ†æã€‚ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®æ¤œè¨¼è€…ã¯å½é™°æ€§ç‡ãŒé«˜ãã€RLè¨“ç·´ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«æ‚ªå½±éŸ¿ã‚’åŠã¼ã™ã“ã¨ãŒåˆ¤æ˜ã€‚ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®æ¤œè¨¼è€…ã¯é™çš„è©•ä¾¡ã§é«˜ç²¾åº¦ã‚’ç¤ºã™ãŒã€å½é™½æ€§ã«å¯¾ã—ã¦è„†å¼±ã§ã‚ã‚Šã€å ±é…¬ãŒä¸æ­£ã«è†¨ã‚‰ã‚€å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¼·åŒ–å­¦ç¿’ã«ãŠã‘ã‚‹å …ç‰¢ãªå ±é…¬ã‚·ã‚¹ãƒ†ãƒ ã®å¿…è¦æ€§ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/junxian_he/status/1929371821767586284?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>verificationã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã—ã¦finetuningã•ã‚ŒãŸDiscriminative ClassifierãŒã€reward hackingã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br>Discriminative Verifierã¨ã¯ã€Question, Response, Reference AnswerãŒgivenãªæ™‚ã«ã€responseï¼ˆã—ã°ã—ã°reasoning traceã‚’å«ã¿è¤‡æ•°ã®answerã®å€™è£œãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ï¼‰ã®ä¸­ã‹ã‚‰æœ€çµ‚çš„ãªanswerã‚’æŠ½å‡ºã—ã€Reference answerã¨æŠ½å‡ºã—ãŸanswerã‹ã‚‰æ­£è§£/ä¸æ­£è§£ã‚’binaryã§å‡ºåŠ›ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ã“ã¨ã€‚Rule-based Verifierã§ã¯ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒç•°ãªã£ã¦ã„ã‚‹å ´åˆã«false negativeã¨ãªã£ã¦ã—ã¾ã†ã—ã€ãã‚‚ãã‚‚ãƒ«ãƒ¼ãƒ«ãŒè¦å®šã§ããªã„ã‚¿ã‚¹ã‚¯ã®å ´åˆã¯é©ç”¨ã§ããªã„ã€‚Discriminative Verifierã§ã¯ãã®ã‚ˆã†ãªã‚±ãƒ¼ã‚¹ã§ã‚‚é©ç”¨ã§ãã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚</p>
<p>Discriminative Verifierã®ä¾‹ã¯ãŸã¨ãˆã°ä¸‹è¨˜:<br>


<a href="https://huggingface.co/IAAR-Shanghai/xVerify-0.5B-I" target="_blank" rel="noopener noreferrer">https://huggingface.co/IAAR-Shanghai/xVerify-0.5B-I</a>


<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2010" target="_blank" rel="noopener noreferrer">[Paper Note] xVerify: Efficient Answer Verifier for Reasoning Model Evaluations, Ding Chen+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<span class="issue_date">Issue Date: 2025-06-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2008" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Challenging Language Model Agents, Yifei Zhou+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Self-Challengingãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè‡ªã‚‰ç”Ÿæˆã—ãŸé«˜å“è³ªãªã‚¿ã‚¹ã‚¯ã§è¨“ç·´ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯æŒ‘æˆ¦è€…ã¨ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆã—ã€å®Ÿè¡Œè€…ã¨ã—ã¦å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦è¨“ç·´ã€‚M3ToolEvalã¨TauBenchã§Llama-3.1-8B-InstructãŒ2å€ä»¥ä¸Šã®æ”¹å–„ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1929719473952497797?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1930748591242424439?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/COLT.html" target="_blank" rel="noopener noreferrer">#COLT</a>
<span class="issue_date">Issue Date: 2025-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2007" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning Compositional Functions with Transformers from Easy-to-Hard   Data, Zixuan Wang+, COLT'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Transformerãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’å¯èƒ½æ€§ã‚’æ¢æ±‚ã—ã€$k$-fold compositionã‚¿ã‚¹ã‚¯ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã€‚$O(\log k)$å±¤ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã§ã“ã®ã‚¿ã‚¹ã‚¯ã‚’è¡¨ç¾ã§ãã‚‹ä¸€æ–¹ã€SQã‚ªãƒ©ã‚¯ãƒ«ã«å¯¾ã™ã‚‹ã‚¯ã‚¨ãƒªã®ä¸‹é™ã‚’ç¤ºã—ã€ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒæŒ‡æ•°çš„ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚’è¨¼æ˜ã€‚ã•ã‚‰ã«ã€ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ å­¦ç¿’æˆ¦ç•¥ã‚’ç”¨ã„ã¦ã€ç°¡å˜ãªä¾‹ã¨é›£ã—ã„ä¾‹ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒãŒãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®åŠ¹ç‡çš„ãªå­¦ç¿’ã«å¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zzzixuanwang/status/1928465115478708604?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã¡ã‚‰ã¯ã¾ãšå…ƒãƒã‚¹ãƒˆã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’èª­ã‚€ã®ãŒè‰¯ã„ã¨æ€ã‚ã‚Œã‚‹ã€‚è¦ç‚¹ã‚’ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã£ã¦ã„ã‚‹ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆã¨alphaxivã§ã–ã£ãã‚Šç†è§£ã—ãŸã¨ã“ã‚ã€<br><br>TransformerãŒcontextã¨ã—ã¦ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±(Ïƒ)ã¨parametric knowledge(Ï€)ã‚’kå›ã®çŸ¥è­˜ãƒãƒƒãƒ”ãƒ³ã‚°ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯(k-fold composition task)ã‚’å­¦ç¿’ã™ã‚‹ã«ã¯O(log k)ã®layeræ•°ãŒå¿…è¦ã§ã€ç›´æ¥çš„ã«kå›ã®çŸ¥è­˜ãƒãƒƒãƒ”ãƒ³ã‚°ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã«ã¯kã®æŒ‡æ•°ã‚ªãƒ¼ãƒ€ãƒ¼ã®ãƒ‡ãƒ¼ã‚¿é‡ãŒæœ€ä½é™å¿…è¦ã¨ãªã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã¯kãŒå¤§ãããªã‚‹ã¨ï¼ˆã™ãªã‚ã¡ã€è¤‡é›‘ãªreasoning stepãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ï¼‰ã«ãªã‚‹ã¨éç¾å®Ÿçš„ãªã‚‚ã®ã¨ãªã‚‹ãŸã‚ã€ä½•ã‚‰ã‹ã®æ–¹æ³•ã§ç·©å’Œã—ãŸã„ã€‚å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç°¡å˜ãªã‚‚ã®ã‹ã‚‰é›£ã—ã„ã‚‚ã®ã‚’mixingã™ã‚‹ã“ã¨ï¼ˆã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ å­¦ç¿’ï¼‰ã“ã¨ã§ã€ã“ã®æ¡ä»¶ãŒç·©å’Œã•ã‚Œã€æŒ‡æ•°ã‚ªãƒ¼ãƒ€ãƒ¼ã‹ã‚‰å¤šé …å¼ã‚ªãƒ¼ãƒ€ãƒ¼ã®ãƒ‡ãƒ¼ã‚¿é‡ã§å­¦ç¿’ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸ<br><br>ã¨ã„ã£ãŸæ„Ÿã˜ã ã¨æ€ã‚ã‚Œã‚‹ã€‚</p>
<p>ã˜ã‚ƒã‚æœ€æ–°ã®32Bãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ã€ã‚ˆã‚Šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤§ããã¦layeræ•°ãŒå¤šã„å¤ã„ãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒè¤‡é›‘ãªreasoningãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã‚’å®Ÿã¯è§£ã‘ã‚‹ã£ã¦ã“ã¨ï¼ï¼Ÿç›´æ„Ÿã«åã™ã‚‹ï¼ã¨ä¸€ç¬æ€ã£ãŸãŒã€ãŠãã‚‰ãæœ€è¿‘ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯æ˜”ã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”ã¹ã¦parametric knowledgeãŒã‚ˆã‚Šé«˜å¯†åº¦ã«é©åˆ‡ã«åœ§ç¸®ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã®ã§ã€æ˜”ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯kå›ã®çŸ¥è­˜ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ã—ãªã„ã¨è§£ã‘ãªã„ã‚¿ã‚¹ã‚¯ãŒã€æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯k-nå›ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã§è§£ã‘ã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã¨æ¨å¯Ÿã•ã‚Œã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå°ã•ãã¦ã‚‚å•é¡Œãªãè§£ã‘ã¾ã™ã€ã¿ãŸã„ãªã“ã¨ãŒèµ·ã“ã£ã¦ã„ã‚‹ã®ã ã‚ã†ã€ã¨ã„ã†æ„Ÿæƒ³ã‚’æŠ±ããªã©ã—ãŸ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2006" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BIG-Bench Extra Hard, Mehran Kazemi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€BIG-Bench Extra Hardï¼ˆBBEHï¼‰ã‚’å°å…¥ã€‚ã“ã‚Œã¯ã€æ—¢å­˜ã®BIG-Bench Hardï¼ˆBBHï¼‰ã®ã‚¿ã‚¹ã‚¯ã‚’æ–°ã—ã„ã‚‚ã®ã«ç½®ãæ›ãˆã€é›£æ˜“åº¦ã‚’å¤§å¹…ã«å¼•ãä¸Šã’ã‚‹ã“ã¨ã§ã€LLMã®é™ç•Œã‚’æŠ¼ã—åºƒã’ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã€‚è©•ä¾¡ã®çµæœã€æœ€è‰¯ã®æ±ç”¨ãƒ¢ãƒ‡ãƒ«ã§9.8%ã€æ¨è«–å°‚é–€ãƒ¢ãƒ‡ãƒ«ã§44.8%ã®å¹³å‡ç²¾åº¦ãŒè¦³å¯Ÿã•ã‚Œã€LLMã®ä¸€èˆ¬çš„æ¨è«–èƒ½åŠ›å‘ä¸Šã®ä½™åœ°ãŒç¤ºã•ã‚ŒãŸã€‚BBEHã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Big-Bench hardï¼ˆæ—¢ã«SoTAãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›å·®ã‚’è­˜åˆ¥ã§ããªã„ï¼‰ã®é›£æ˜“åº¦ã‚’ã•ã‚‰ã«æŠ¼ã—ä¸Šã’ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚<br><br>Inputã®ä¾‹<br><img src="https://github.com/user-attachments/assets/b9d1308f-1481-470d-a553-c181d902119c" alt="image" loading="lazy"><br><br>ã‚¿ã‚¹ã‚¯ã”ã¨ã®Input, Output lengthã®åˆ†å¸ƒ<br><img src="https://github.com/user-attachments/assets/ef6b7401-159d-46c7-bd9d-9a64f63b5089" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/01207db3-cb01-46f2-a805-e9ddf9d58198" alt="image" loading="lazy"><br><br>ç¾åœ¨ã®ä¸»è¦ãªãƒ¢ãƒ‡ãƒ«ç¾¤ã®æ€§èƒ½<br><img src="https://github.com/user-attachments/assets/5ce538d8-45a1-449a-992a-998b33fdeaf7" alt="image" loading="lazy"></p>
<p>Big-Benchè«–æ–‡ã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/785" target="_blank" rel="noopener noreferrer">Beyond the Imitation Game: Quantifying and extrapolating the   capabilities of language models, Aarohi Srivastava+, N/A, TMLR'23</a>
</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/PRM.html" target="_blank" rel="noopener noreferrer">#PRM</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2005" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Training Step-Level Reasoning Verifiers with Formal Verification Tools, Ryo Kamoi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€ãƒ—ãƒ­ã‚»ã‚¹å ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼ˆPRMsï¼‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹2ã¤ã®èª²é¡Œã€ã™ãªã‚ã¡é«˜ã‚³ã‚¹ãƒˆã®äººé–“ã«ã‚ˆã‚‹æ³¨é‡ˆã¨æ•°å­¦çš„æ¨è«–å•é¡Œã¸ã®é™å®šã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€FoVerã¨ã„ã†ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¾ã™ã€‚FoVerã¯å½¢å¼çš„æ¤œè¨¼ãƒ„ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦è‡ªå‹•çš„ã«æ®µéšãƒ¬ãƒ™ãƒ«ã®ã‚¨ãƒ©ãƒ¼ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆã—ã€äººçš„æ³¨é‡ˆãªã—ã§LLMã®å¿œç­”ã«ã‚¨ãƒ©ãƒ¼ãƒ©ãƒ™ãƒ«ã‚’ä»˜ä¸ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆæˆã—ã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸPRMsã¯ã€å…ƒã®LLMsã«åŸºã¥ããƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€ä»–ã®æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã¨ã‚‚ç«¶äº‰åŠ›ã®ã‚ã‚‹çµæœã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ryokamoi/status/1925939062348697874?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>äººæ‰‹ã«ã‚ˆã‚‹Annotationï¼ˆstep levelã®ãƒ©ãƒ™ãƒ«ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³)ç„¡ã—ã§Procsee Reward Modelã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã™ã‚‹æ‰‹æ³•<br><br><img src="https://github.com/user-attachments/assets/adfc351e-c53b-47af-adba-480e10615d69" alt="image" loading="lazy"></p>
<p>Z3ã‚„Isabelleãªã©ã®å½¢å¼æ¤œè¨¼ãƒ„ãƒ¼ãƒ«ãŒé©ç”¨å¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®ã¿ã«ææ¡ˆæ‰‹æ³•ã®ã‚¹ã‚³ãƒ¼ãƒ—ã¯é™ã‚‰ã‚Œã‚‹ç‚¹ã«ã¯æ³¨æ„</p>
<p>äººæ‰‹ã§ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦comparableãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆ<br><img src="https://github.com/user-attachments/assets/290a4d1c-10ac-41dd-a26e-ed57e1fcca79" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/b1af66e7-fbbe-4823-8679-e5ff5be94fdf" alt="image" loading="lazy"><br><br>ã‚¹ãƒ¬ãƒƒãƒ‰ä¸­ã§è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒæ•°å›ã®reasoning stepãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã®ã¿ã®è©•ä¾¡ã§ã‚ã‚Šã€ã‚ˆã‚Šé•·ãè¤‡é›‘ãªreasoning stepï¼ˆãŸã¨ãˆã° <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2006" target="_blank" rel="noopener noreferrer">[Paper Note] BIG-Bench Extra Hard, Mehran Kazemi+, arXiv'25</a>
ï¼‰ãŒå¿…è¦ãªå ´åˆã¯ã©ã†ãªã‚‹ã‹ï¼Ÿã¨ã„ã£ãŸæ‰€ã«èˆˆå‘³ãŒå¯„ã›ã‚‰ã‚Œã¦ã„ã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2004" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Satori-SWE: Evolutionary Test-Time Scaling for Sample-Efficient Software  Engineering, Guangtao Zeng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- EvoScaleã‚’ææ¡ˆã—ã€é€²åŒ–çš„ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç”¨ã„ã¦å°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã‚’é–‹ç™ºã€‚é¸æŠã¨çªç„¶å¤‰ç•°ã‚’é€šã˜ã¦å‡ºåŠ›ã‚’æ´—ç·´ã—ã€ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’æ¸›å°‘ã•ã›ã‚‹ã€‚å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦è‡ªå·±é€²åŒ–ã‚’ä¿ƒé€²ã—ã€SWE-Bench-Verifiedã§32Bãƒ¢ãƒ‡ãƒ«ãŒ100Bä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¤ºã™ã€‚ã‚³ãƒ¼ãƒ‰ã€ãƒ‡ãƒ¼ã‚¿ã€ãƒ¢ãƒ‡ãƒ«ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦å…¬é–‹äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gan_chuang/status/1928963872188244400?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2003" target="_blank" rel="noopener noreferrer" class="title-link">Can Large Reasoning Models Self-Train?, Sheikh Shafayat+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±å­¦ç¿’ã‚’æ´»ç”¨ã—ãŸã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®è‡ªå·±ä¸€è²«æ€§ã‚’åˆ©ç”¨ã—ã¦æ­£ç¢ºæ€§ä¿¡å·ã‚’æ¨æ¸¬ã€‚é›£ã—ã„æ•°å­¦çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã«é©ç”¨ã—ã€å¾“æ¥ã®æ‰‹æ³•ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚è‡ªå·±ç”Ÿæˆã•ã‚ŒãŸä»£ç†å ±é…¬ãŒèª¤ã£ãŸå‡ºåŠ›ã‚’å„ªé‡ã™ã‚‹ãƒªã‚¹ã‚¯ã‚‚æŒ‡æ‘˜ã€‚è‡ªå·±ç›£è¦–ã«ã‚ˆã‚‹æ€§èƒ½å‘ä¸Šã®å¯èƒ½æ€§ã¨èª²é¡Œã‚’æ˜ã‚‰ã‹ã«ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/askalphaxiv/status/1928487492291829809?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1995" target="_blank" rel="noopener noreferrer">Learning to Reason without External Rewards, Xuandong Zhao+, ICML'25 Workshop AI4MATH</a>
<br>ã¨ä¼¼ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹</p>
<p>self-consistencyã§ground truthã‚’æ¨å®šã—ã€æ¨å®šã—ãŸground truthã‚’ç”¨ã„ã¦verifiableãªrewardã‚’è¨ˆç®—ã—ã¦å­¦ç¿’ã™ã‚‹æ‰‹æ³•ã€ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/0f38d47a-ab42-4ec4-a6d5-6d5d8a63a4a9" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/3d08bbad-8578-4add-8ad7-ed02cdd15add" alt="image" loading="lazy"><br><br>å®Ÿéš›ã®ground truthã‚’ç”¨ã„ãŸå­¦ç¿’ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã™ã‚‹å ´åˆã‚‚ã‚ã‚Œã°ã€long stepã§å­¦ç¿’ã™ã‚‹ã¨ã©ã“ã‹ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§å­¦ç¿’ãŒcollapseã™ã‚‹å ´åˆã‚‚ã‚ã‚‹<br><img src="https://github.com/user-attachments/assets/e120a277-6beb-4fc1-8fd7-e69de467fb3d" alt="image" loading="lazy"></p>
<p>ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒãƒ”ãƒ¼ã‚¯ã‚’è¿ãˆãŸå¾Œã«ãªãœå¤§å¹…ã«AccuracyãŒdropã™ã‚‹ã‹ã‚’æ¤œè¨¼ã—ãŸã¨ã“ã‚ã€ãƒ¢ãƒ‡ãƒ«ã®KL penaltyãŒã©ã“ã‹ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§å¤§å¹…ã«å¤§ãããªã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã¤ã¾ã‚Šã“ã‚Œã¯ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã‹ã‘é›¢ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«ãªã£ã¦ã„ã‚‹ã€‚ã“ã‚Œã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒãƒ‡ã‚¿ãƒ©ãƒ¡ãªå‡ºåŠ›ã‚’ground truthã¨ã—ã¦æ¨å®šã™ã‚‹ã‚ˆã†ã«ãªã‚Šã€ãƒ¢ãƒ‡ãƒ«ãã®ã‚‚ã®ã‚‚ä¸€è²«ã—ã¦ãã®ãƒ‡ã‚¿ãƒ©ãƒ¡ãªå‡ºåŠ›ã‚’ã™ã‚‹ã“ã¨ã§rewardã‚’å¢—å¤§ã•ã›ã‚‹reward hackingãŒèµ·ãã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/5a9c091f-e9cb-4914-a1ca-32a1ea2dc1c7" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/aa685b9a-7992-4135-a4da-fd1c8cabe084" alt="image" loading="lazy"></p>
<p>ã“ã‚Œã‚‰ç¾è±¡ã‚’é¿ã‘ã‚‹æ–¹æ³•ã¨ã—ã¦ã€ä»¥ä¸‹ã®3ã¤ã‚’ææ¡ˆã—ã¦ã„ã‚‹<br>- early stopping<br>- offlineã§ãƒ©ãƒ™ãƒ«ã‚’self consistencyã§ç”Ÿæˆã—ã¦ã€å­¦ç¿’ã®éç¨‹ã§å›ºå®šã™ã‚‹<br>- ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å°å…¥ã™ã‚‹<br><br><img src="https://github.com/user-attachments/assets/4fa997e3-aa20-4195-96ef-b17c82556fc1" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/99cc2b6c-50a9-40a0-af30-b59aff4056b4" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/e90e9870-b180-4fe9-8c24-8ff88fcf33f0" alt="image" loading="lazy"></p>
<p>é–¢é€£<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1489" target="_blank" rel="noopener noreferrer">Self-Consistency Preference Optimization, Archiki Prasad+, ICML'25</a>
</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2025-05-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2000" target="_blank" rel="noopener noreferrer" class="title-link">Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs, Yu Xia+, COLING'25</a>
<span class="snippet"><span>GPT Summary</span>- Chain-of-Thoughtï¼ˆCoTï¼‰ã‚’åŸºã«ã—ãŸChain-of-Xï¼ˆCoXï¼‰æ‰‹æ³•ã®èª¿æŸ»ã‚’è¡Œã„ã€LLMsã®èª²é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®å¤šæ§˜ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’åˆ†é¡ã€‚ãƒãƒ¼ãƒ‰ã®åˆ†é¡ã¨ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã«åŸºã¥ãåˆ†æã‚’é€šã˜ã¦ã€æ—¢å­˜ã®æ‰‹æ³•ã®æ„ç¾©ã¨ä»Šå¾Œã®å¯èƒ½æ€§ã‚’è­°è«–ã€‚ç ”ç©¶è€…ã«ã¨ã£ã¦æœ‰ç”¨ãªãƒªã‚½ãƒ¼ã‚¹ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-05-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1999" target="_blank" rel="noopener noreferrer" class="title-link">Distillation Scaling Laws, Dan Busbridge+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- è’¸ç•™ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ¨å®šã™ã‚‹ãŸã‚ã®è’¸ç•™ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ææ¡ˆã€‚æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã®è¨ˆç®—å‰²ã‚Šå½“ã¦ã‚’æœ€é©åŒ–ã™ã‚‹ã“ã¨ã§ã€ç”Ÿå¾’ã®æ€§èƒ½ã‚’æœ€å¤§åŒ–ã€‚æ•™å¸«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ãªå ´åˆã«æœ€é©ãªè’¸ç•™ãƒ¬ã‚·ãƒ”ã‚’æä¾›ã€‚å¤šãã®ç”Ÿå¾’ã‚’è’¸ç•™ã™ã‚‹éš›ã¯ã€ç›£è¦–ä»˜ãã®äº‹å‰å­¦ç¿’ã‚’ä¸Šå›ã‚‹ãŒã€ç”Ÿå¾’ã®ã‚µã‚¤ã‚ºã«å¿œã˜ãŸè¨ˆç®—ãƒ¬ãƒ™ãƒ«ã¾ã§ã€‚å˜ä¸€ã®ç”Ÿå¾’ã‚’è’¸ç•™ã—ã€æ•™å¸«ãŒãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¿…è¦ãªå ´åˆã¯ç›£è¦–å­¦ç¿’ã‚’æ¨å¥¨ã€‚è’¸ç•™ã«é–¢ã™ã‚‹æ´å¯Ÿã‚’æä¾›ã—ã€ç†è§£ã‚’æ·±ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/danbusbridge/status/1944539357542781410?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Temporal.html" target="_blank" rel="noopener noreferrer">#Temporal</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1996" target="_blank" rel="noopener noreferrer" class="title-link">Temporal Sampling for Forgotten Reasoning in LLMs, Yuetai Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«LLMsãŒä»¥å‰ã®æ­£ã—ã„è§£æ³•ã‚’å¿˜ã‚Œã‚‹ã€Œæ™‚é–“çš„å¿˜å´ã€ã‚’ç™ºè¦‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€Œæ™‚é–“çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€ã¨ã„ã†ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ã‚’å°å…¥ã—ã€è¤‡æ•°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å‡ºåŠ›ã‚’å¼•ãå‡ºã™ã“ã¨ã§æ¨è«–æ€§èƒ½ã‚’å‘ä¸Šã€‚Pass@kã§4ã‹ã‚‰19ãƒã‚¤ãƒ³ãƒˆã®æ”¹å–„ã‚’é”æˆã—ã€LoRAé©å¿œãƒ¢ãƒ‡ãƒ«ã§ã‚‚åŒæ§˜ã®åˆ©ç‚¹ã‚’ç¤ºã™ã€‚æ™‚é–“çš„å¤šæ§˜æ€§ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€LLMsã®è©•ä¾¡æ–¹æ³•ã‚’å†è€ƒã™ã‚‹æ‰‹æ®µã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1927286319018832155?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Temporal Forgettingã¨Temporal Sampling</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Workshop.html" target="_blank" rel="noopener noreferrer">#Workshop</a>
<span class="issue_date">Issue Date: 2025-05-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1995" target="_blank" rel="noopener noreferrer" class="title-link">Learning to Reason without External Rewards, Xuandong Zhao+, ICML'25 Workshop AI4MATH</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤–éƒ¨ã®å ±é…¬ã‚„ãƒ©ãƒ™ãƒ«ãªã—ã§å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ãŒå­¦ç¿’ã§ãã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€Œå†…éƒ¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‹ã‚‰ã®å¼·åŒ–å­¦ç¿’ï¼ˆRLIFï¼‰ã€ã‚’ææ¡ˆã€‚è‡ªå·±ç¢ºä¿¡ã‚’å ±é…¬ä¿¡å·ã¨ã—ã¦ç”¨ã„ã‚‹ã€ŒIntuitorã€ã‚’é–‹ç™ºã—ã€ç„¡ç›£è¦–ã®å­¦ç¿’ã‚’å®Ÿç¾ã€‚å®Ÿé¨“çµæœã¯ã€IntuitorãŒæ•°å­¦çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–ã‚¿ã‚¹ã‚¯ã¸ã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚‚é«˜ã„ã“ã¨ã‚’ç¤ºã—ãŸã€‚å†…å› çš„ä¿¡å·ãŒåŠ¹æœçš„ãªå­¦ç¿’ã‚’ä¿ƒé€²ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã€è‡ªå¾‹AIã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªä»£æ›¿æ‰‹æ®µã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xuandongzhao/status/1927270931874910259?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãŠã‚‚ã—ã‚ãã†</p>
<p>externalãªsignalã‚’rewardã¨ã—ã¦ç”¨ã„ãªã„ã§ã€ãƒ¢ãƒ‡ãƒ«è‡ªèº«ãŒå†…éƒ¨çš„ã«ä¿æŒã—ã¦ã„ã‚‹confidenceã‚’ç”¨ã„ã‚‹ã€‚äººé–“ã¯è‡ªä¿¡ãŒã‚ã‚‹å•é¡Œã«ã¯æ­£è§£ã—ã‚„ã™ã„ã¨ã„ã†ç›´æ„Ÿã«åŸºã¥ã„ã¦ãŠã‚Šã€openendãªquestionã®ã‚ˆã†ã«ãã‚‚ãã‚‚æ­£è§£ã‚·ã‚°ãƒŠãƒ«ãŒå®šç¾©ã§ããªã„ã‚‚ã®ã‚‚ã‚ã‚‹ãŒã€ãã†ã„ã£ãŸå ´åˆã«æ´»ç”¨ã§ãã‚‹ã‚ˆã†ã§ã‚ã‚‹ã€‚</p>
<p>self-trainingã®è€ƒãˆæ–¹ã«è¿‘ã„ã®ã§ã¯</p>
<p>ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ®µéšã§ã‚ã‚‹ç¨‹åº¦èƒ½åŠ›ãŒå‚™ã‚ã£ã¦ãŠã‚Šã€post-trainingã—ãŸçµæœãã‚ŒãŒå¼•ãå‡ºã•ã‚Œã‚‹ã‚ˆã†ã«ãªã£ãŸã¨ã„ã†æ„Ÿã˜ãªã®ã ã‚ã†ã‹ã€‚<br><br>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/weiliu99/status/1930826904522875309?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:


<a href="https://www.docswell.com/s/DeepLearning2023/KYVLG4-2025-09-18-112951" target="_blank" rel="noopener noreferrer">https://www.docswell.com/s/DeepLearning2023/KYVLG4-2025-09-18-112951</a>


<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dl_hacks/status/1968528790503481439?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-05-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1994" target="_blank" rel="noopener noreferrer" class="title-link">QwenLong-CPRS: Towards $\infty$-LLMs with Dynamic Context Optimization, Weizhou Shen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- QwenLong-CPRSã¯ã€é•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæœ€é©åŒ–ã®ãŸã‚ã®æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€LLMsã®æ€§èƒ½ä½ä¸‹ã‚’è»½æ¸›ã—ã¾ã™ã€‚è‡ªç„¶è¨€èªæŒ‡ç¤ºã«åŸºã¥ãå¤šæ®µéšã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåœ§ç¸®ã‚’å®Ÿç¾ã—ã€åŠ¹ç‡ã¨æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹4ã¤ã®é©æ–°ã‚’å°å…¥ã€‚5ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€ä»–ã®æ‰‹æ³•ã«å¯¾ã—ã¦å„ªä½æ€§ã‚’ç¤ºã—ã€ä¸»è¦ãªLLMã¨ã®çµ±åˆã§å¤§å¹…ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåœ§ç¸®ã¨æ€§èƒ½å‘ä¸Šã‚’é”æˆã€‚QwenLong-CPRSã¯æ–°ãŸãªSOTAæ€§èƒ½ã‚’ç¢ºç«‹ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1927014346690826684?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1993" target="_blank" rel="noopener noreferrer" class="title-link">QwenLong-L1: Towards Long-Context Large Reasoning Models with  Reinforcement Learning, Fanqi Wan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ¨è«–ã«ãŠã‘ã‚‹LRMsã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€QwenLong-L1ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ç›£è¦–ä»˜ããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ æŒ‡å°å‹æ®µéšçš„RLã‚’ç”¨ã„ã¦ãƒãƒªã‚·ãƒ¼ã®å®‰å®šåŒ–ã‚’å›³ã‚Šã€é›£æ˜“åº¦èªè­˜å‹ã®å›é¡§çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§æ¢ç´¢ã‚’ä¿ƒé€²ã€‚å®Ÿé¨“ã§ã¯ã€QwenLong-L1-32BãŒä»–ã®LRMsã‚’ä¸Šå›ã‚Šã€å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1927011243597967524?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1989" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Reasoning, Losing Control: Evaluating Instruction Following in  Large Reasoning Models, Tingchen Fu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã¯LLMã«ã¨ã£ã¦é‡è¦ã§ã‚ã‚Šã€MathIFã¨ã„ã†æ•°å­¦çš„æ¨è«–ã‚¿ã‚¹ã‚¯ç”¨ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã€‚æ¨è«–èƒ½åŠ›ã®å‘ä¸Šã¨æŒ‡ç¤ºéµå®ˆã®é–“ã«ã¯ç·Šå¼µé–¢ä¿‚ãŒã‚ã‚Šã€ç‰¹ã«é•·ã„æ€è€ƒã®é€£é–ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã¯æŒ‡ç¤ºã«å¾“ã„ã«ãã„ã€‚ä»‹å…¥ã«ã‚ˆã‚Šéƒ¨åˆ†çš„ãªå¾“é †ã•ã‚’å›å¾©ã§ãã‚‹ãŒã€æ¨è«–æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã‚‰ã®çµæœã¯ã€æŒ‡ç¤ºã«æ•æ„Ÿãªæ¨è«–ãƒ¢ãƒ‡ãƒ«ã®å¿…è¦æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yafuly/status/1925753754961236006?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1988" target="_blank" rel="noopener noreferrer" class="title-link">LLMs Get Lost In Multi-Turn Conversation, Philippe Laban+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯ä¼šè©±å‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¿ã‚¹ã‚¯ã‚’å®šç¾©ã™ã‚‹ã®ã‚’æ”¯æ´ã™ã‚‹ãŒã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®ä¼šè©±ã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ã€‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“ã®çµæœã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã§39%ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹ãŒè¦‹ã‚‰ã‚Œã€åˆæœŸã®ã‚¿ãƒ¼ãƒ³ã§ã®ä»®å®šã«ä¾å­˜ã—ã™ãã‚‹ã“ã¨ãŒåŸå› ã¨åˆ¤æ˜ã€‚LLMsã¯ä¼šè©±ä¸­ã«èª¤ã£ãŸæ–¹å‘ã«é€²ã‚€ã¨ã€å›å¾©ãŒé›£ã—ããªã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_stakaya/status/1926009283386155009?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Lost in the Middleãªã‚‰ã¬Lost in Conversation<br><img src="https://github.com/user-attachments/assets/9d4320f5-6fea-43ca-a7ab-a836e7e3642e" alt="image" loading="lazy"></p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/793" target="_blank" rel="noopener noreferrer">Lost in the Middle: How Language Models Use Long Contexts, Nelson F. Liu+, N/A, TACL'24</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1985" target="_blank" rel="noopener noreferrer" class="title-link">LaViDa: A Large Diffusion Language Model for Multimodal Understanding, Shufan Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LaViDaã¯ã€é›¢æ•£æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ï¼ˆDMï¼‰ã‚’åŸºã«ã—ãŸãƒ“ã‚¸ãƒ§ãƒ³ãƒ»ãƒ©ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«ï¼ˆVLMï¼‰ã§ã€é«˜é€Ÿãªæ¨è«–ã¨åˆ¶å¾¡å¯èƒ½ãªç”Ÿæˆã‚’å®Ÿç¾ã€‚æ–°æŠ€è¡“ã‚’å–ã‚Šå…¥ã‚Œã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦AR VLMã¨ç«¶äº‰åŠ›ã®ã‚ã‚‹æ€§èƒ½ã‚’é”æˆã€‚COCOã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã§é€Ÿåº¦å‘ä¸Šã¨æ€§èƒ½æ”¹å–„ã‚’ç¤ºã—ã€AR VLMã®å¼·åŠ›ãªä»£æ›¿æ‰‹æ®µã§ã‚ã‚‹ã“ã¨ã‚’è¨¼æ˜ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1925749919312159167?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Diffusion Modelã®æ³¢ãŒæ¥ãŸ</p>
<p>åŒç¨‹åº¦ã®ã‚µã‚¤ã‚ºã®ARãƒ¢ãƒ‡ãƒ«ã‚’outperform [^1]<br><img src="https://github.com/user-attachments/assets/aeb12147-48ba-4b64-917c-9976ec1ffa0a" alt="image" loading="lazy"><br><br>[^1]:ãŸã ã—ã€ã“ã‚ŒãŒæœ¬å½“ã«Diffusion Modelã‚’ä½¿ã£ãŸã“ã¨ã«ã‚ˆã‚‹æ©æµãªã®ã‹ã¯ã¾ã è«–æ–‡ã‚’èª­ã‚“ã§ã„ãªã„ã®ã§ã‚ã‹ã‚‰ãªã„ã€‚å¿…è¦ã«ãªã£ãŸã‚‰èª­ã‚€ã€‚ãŸã ã€Physics of Language Modelã®ã‚ˆã†ã«ã€å®Œå…¨ã«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§ç•°ãªã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¯”è¼ƒã—ãªã„ã¨ãã®è¾ºã¯ã‚ã‹ã‚‰ãªãã†ã§ã¯ã‚ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1984" target="_blank" rel="noopener noreferrer" class="title-link">dKV-Cache: The Cache for Diffusion Language Models, Xinyin Ma+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ‹¡æ•£è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆDLMï¼‰ã®é…ã„æ¨è«–ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã€é…å»¶KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€ç•°ãªã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã®è¡¨ç¾ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã«åŸºã¥ãã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥ã§ã€2ã¤ã®ãƒãƒªã‚¢ãƒ³ãƒˆã‚’è¨­è¨ˆã€‚dKV-Cache-Decodeã¯æå¤±ã®å°‘ãªã„åŠ é€Ÿã‚’æä¾›ã—ã€dKV-Cache-Greedyã¯é«˜ã„ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å®Ÿç¾ã€‚æœ€çµ‚çš„ã«ã€æ¨è«–é€Ÿåº¦ã‚’2ã€œ10å€å‘ä¸Šã•ã›ã€DLMã®æ€§èƒ½ã‚’å¼·åŒ–ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1925384029718946177?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ææ¡ˆæ‰‹æ³•ã‚’é©ç”¨ã—ãŸå ´åˆã€ARãªãƒ¢ãƒ‡ãƒ«ã¨Diffusion Modelã§ã€å®Ÿéš›ã®ã¨ã“ã‚ã©ã®ç¨‹åº¦ã®decodingé€Ÿåº¦ã®å·®ãŒã‚ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿãã†ã„ã£ãŸåˆ†æã¯ã–ãƒ¼ãƒ¼ã£ã¨è¦‹ãŸæ„Ÿã˜è¦‹å½“ãŸã‚‰ãªã‹ã£ãŸã‚ˆã†ã«æ€ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1983" target="_blank" rel="noopener noreferrer" class="title-link">Diffusion vs. Autoregressive Language Models: A Text Embedding  Perspective, Siyue Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ‹¡æ•£è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ãŒã€è‡ªå·±å›å¸°çš„ãªLLMã®ä¸€æ–¹å‘æ€§ã®åˆ¶é™ã‚’å…‹æœã—ã€æ–‡æ›¸æ¤œç´¢ã‚„æ¨è«–ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã€‚é•·æ–‡æ¤œç´¢ã§20%ã€æ¨è«–é›†ç´„å‹æ¤œç´¢ã§8%ã€æŒ‡ç¤ºã«å¾“ã£ãŸæ¤œç´¢ã§2%ã®å‘ä¸Šã‚’ç¤ºã—ã€åŒæ–¹å‘ã®æ³¨æ„ãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/trtd6trtd/status/1925775950500806742?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-05-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1982" target="_blank" rel="noopener noreferrer" class="title-link">LiveBench: A Challenging, Contamination-Limited LLM Benchmark, Colin White+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®æ±šæŸ“ã‚’é˜²ããŸã‚ã«ã€LLMç”¨ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒLiveBenchã€ã‚’å°å…¥ã€‚LiveBenchã¯ã€é »ç¹ã«æ›´æ–°ã•ã‚Œã‚‹è³ªå•ã€è‡ªå‹•ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã€ã•ã¾ã–ã¾ãªæŒ‘æˆ¦çš„ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ã€‚å¤šãã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ã€æ­£ç­”ç‡ã¯70%æœªæº€ã€‚è³ªå•ã¯æ¯æœˆæ›´æ–°ã•ã‚Œã€LLMã®èƒ½åŠ›å‘ä¸Šã‚’æ¸¬å®šå¯èƒ½ã«ã€‚ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®å‚åŠ ã‚’æ­“è¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã«å¯¾å‡¦ã§ãã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚é‡è¦ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-05-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1981" target="_blank" rel="noopener noreferrer" class="title-link">Parallel Scaling Law for Language Models, Mouxiang Chen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ãŠã„ã¦ã€ä¸¦åˆ—è¨ˆç®—ã‚’å¢—åŠ ã•ã›ã‚‹æ–°ã—ã„æ‰‹æ³•ã€ŒParScaleã€ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®å‰æ–¹ãƒ‘ã‚¹ã‚’ä¸¦åˆ—ã«å®Ÿè¡Œã—ã€å‡ºåŠ›ã‚’å‹•çš„ã«é›†ç´„ã™ã‚‹ã“ã¨ã§ã€æ¨è«–åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ParScaleã¯ã€å°‘ãªã„ãƒ¡ãƒ¢ãƒªå¢—åŠ ã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã§åŒç­‰ã®æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã—ã€æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’å†åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ã‚¹ãƒˆã‚‚å‰Šæ¸›å¯èƒ½ã€‚æ–°ã—ã„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã¯ã€ãƒªã‚½ãƒ¼ã‚¹ãŒé™ã‚‰ã‚ŒãŸçŠ¶æ³ã§ã®å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«å±•é–‹ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1924959706331939099?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/405" target="_blank" rel="noopener noreferrer">[Paper Note] Prefix-Tuning: Optimizing Continuous Prompts for Generation, Xiang Lisa Li+, arXiv'21, 2021.01</a>
<br><br>ã¨è€ƒãˆæ–¹ãŒä¼¼ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-05-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1980" target="_blank" rel="noopener noreferrer" class="title-link">AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via  Reinforcement Learning, Chenwei Lou+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AdaCoTï¼ˆAdaptive Chain-of-Thoughtï¼‰ã¯ã€LLMsãŒæ¨è«–ã‚’é©å¿œçš„ã«è¡Œã†æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€CoTã®å‘¼ã³å‡ºã—ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦ã€ã‚¯ã‚¨ãƒªã®è¤‡é›‘ã•ã«åŸºã¥ã„ã¦CoTã®å¿…è¦æ€§ã‚’åˆ¤æ–­ã—ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã—ã¾ã™ã€‚å®Ÿé¨“ã§ã¯ã€AdaCoTãŒCoTãƒˆãƒªã‚¬ãƒ¼ç‡ã‚’3.18%ã«ä½ä¸‹ã•ã›ã€å¿œç­”ãƒˆãƒ¼ã‚¯ãƒ³ã‚’69.06%æ¸›å°‘ã•ã›ã¤ã¤ã€é«˜ã„æ€§èƒ½ã‚’ç¶­æŒã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>RLã®Rewardã«ãŠã„ã¦ã€bassã®ãƒªãƒ¯ãƒ¼ãƒ‰ã ã‘ã§ãªãã€<br>- reasoningã‚’ãªãã—ãŸå ´åˆã®ãƒšãƒŠãƒ«ãƒ†ã‚£é …<br>- reasoningã‚’overuseã—ãŸå ´åˆã®ãƒšãƒŠãƒ«ãƒ†ã‚£é …<br>- formattingã«é–¢ã™ã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£é …<br>ã‚’è¨­å®šã—ã€reasoningã®æœ‰ç„¡ã‚’é©åˆ‡ã«åˆ¤æ–­ã§ããŸå ´åˆã«rewardãŒæœ€å¤§åŒ–ã•ã‚Œã‚‹ã‚ˆã†ãªå½¢ã«ã—ã¦ã„ã‚‹ã€‚(2.2.2)<br><br>ãŒã€multi-stageã®RLã§ã¯ï¼ˆstageã”ã¨ã«åˆ©ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å¤‰æ›´ã™ã‚‹ãŒï¼‰ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†å¸ƒã«ã¯æ­ªã¿ãŒã‚ã‚Šã€ãŸã¨ãˆã°å¸¸ã«CoTãŒæœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚å­˜åœ¨ã—ã¦ãŠã‚Šï¼ˆæ•°å­¦ã«é–¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãªã©ï¼‰ã€ãã®å ´åˆå¸¸ã«CoTã‚’ã™ã‚‹ã‚ˆã†ãªåˆ†å¸ƒã‚’å­¦ç¿’ã—ã¦ã—ã¾ã„ã€AdaptiveãªCoT decisionãŒå´©å£Šã—ãŸã‚Šã€ä¸å®‰å®šã«ãªã£ã¦ã—ã¾ã†ï¼ˆdecision boundary collapseã¨å‘¼ã¶ï¼‰ã€‚ç‰¹ã«ã“ã‚ŒãŒfinal stageã§èµ·ãã‚‹ã¨æœ€æ‚ªã§ã€ã“ã‚Œã¾ã§Adaptiveã«CoTã•ã‚Œã‚‹ã‚ˆã†å­¦ç¿’ã•ã‚Œã¦ããŸã‚‚ã®ãŒå…¨ã¦å´©å£Šã—ã¦ã—ã¾ã†ã€‚ã“ã‚Œã‚’é˜²ããŸã‚ã«ã€Selective Loss Maskingã¨ã„ã†lossã‚’å°å…¥ã—ã¦ã„ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€decision token [^1]ã®lossã¸ã®è²¢çŒ®ã‚’ãƒã‚¹ã‚­ãƒ³ã‚°ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã§ã€CoTãŒç”Ÿã˜ã‚‹ratioã«ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹ã€‚ä»Šå›ã¯ã€Decision tokenã¨ã—ã¦ã€`<think>`ãƒˆãƒ¼ã‚¯ãƒ³ç›´å¾Œã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’decision tokenã¨ã¿ãªã—ã€lossã«å¯¾ã™ã‚‹è²¢çŒ®ã‚’ãƒã‚¹ã‚¯ã—ã¦ã„ã‚‹ï¼ˆSelective Loss Maskingï¼‰ã€‚<br><br>[^1]: CoTã™ã‚‹ã‹ã©ã†ã‹ã¯å¤šãã®å ´åˆã“ã®Decision Tokenã«ã‚ˆã£ã¦æ±ºã¾ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ãŒã©ã£ã‹ã®ç ”ç©¶ã«ç¤ºã•ã‚Œã¦ã„ãŸã¯ãš&lt;/p&gt;<p>ã„ã¤ã‹å¿…è¦ã«ãªã£ãŸã‚‰ã—ã£ã‹ã‚Šèª­ã‚€ãŒã€å…¨ã¦ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§Selective Loss Maskingã‚’ã—ãŸã‚‰ã€SFTã§warm upã—ãŸæ®µéšã‹ã‚‰ã‚ã¾ã‚ŠCoTã®ratioãŒå¤‰åŒ–ã—ãªã„ã‚ˆã†ãªå­¦ç¿’ã®ã•ã‚Œæ–¹ã«ãªã‚‹æ°—ãŒã™ã‚‹ãŒã€ã©ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã«å¯¾ã—ã¦applyã™ã‚‹ã®ã ã‚ã†ã‹ã€‚</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2025-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1979" target="_blank" rel="noopener noreferrer" class="title-link">Model Merging in Pre-training of Large Language Models, Yunshui Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ³ã‚°ã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å¼·åŒ–ã«æœ‰æœ›ãªæŠ€è¡“ã§ã‚ã‚Šã€æœ¬è«–æ–‡ã§ã¯ãã®äº‹å‰å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã‘ã‚‹åŒ…æ‹¬çš„ãªèª¿æŸ»ã‚’è¡Œã†ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ä¸€å®šã®å­¦ç¿’ç‡ã§è¨“ç·´ã•ã‚ŒãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒãƒ¼ã‚¸ã™ã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Šã¨ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°æŒ™å‹•ã®äºˆæ¸¬ãŒå¯èƒ½ã«ãªã‚‹ã“ã¨ã‚’ç¤ºã—ã€åŠ¹ç‡çš„ãªãƒ¢ãƒ‡ãƒ«é–‹ç™ºã¨ä½ã‚³ã‚¹ãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«å¯„ä¸ã™ã‚‹ã€‚ãƒãƒ¼ã‚¸æˆ¦ç•¥ã‚„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç ”ç©¶ã‚’é€šã˜ã¦æ–°ãŸãªæ´å¯Ÿã‚’æä¾›ã—ã€å®Ÿç”¨çš„ãªäº‹å‰å­¦ç¿’ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«æç¤ºã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1924804324812873990?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span></think></p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/giffmana/status/1924849877634449878?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/KnowledgeGraph.html" target="_blank" rel="noopener noreferrer">#KnowledgeGraph</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1978" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Reasoning can Improve Factuality in Large Language Models, Mike Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‰ãƒ¡ã‚¤ãƒ³ã®è³ªå•å¿œç­”ã«ãŠã‘ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®æ¨è«–èƒ½åŠ›ã‚’æ¤œè¨ã—ã€æ¨è«–ã®ç—•è·¡ã‚’æŠ½å‡ºã—ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã£ãŸã€‚çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‹ã‚‰ã®æƒ…å ±ã‚’å°å…¥ã—ã€168å›ã®å®Ÿé¨“ã‚’é€šã˜ã¦170ä¸‡ã®æ¨è«–ã‚’åˆ†æã—ãŸçµæœã€å°å‹ãƒ¢ãƒ‡ãƒ«ãŒå…ƒã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚äº‹å®Ÿã®æ­£ç¢ºæ€§ã‚’é¡•è‘—ã«æ”¹å–„ã—ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã•ã‚‰ã«2-8%ã®å‘ä¸ŠãŒç¢ºèªã•ã‚ŒãŸã€‚å®Ÿé¨“æˆæœã¯å…¬é–‹ã•ã‚Œã€ã•ã‚‰ãªã‚‹ç ”ç©¶ã«å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1924477447120068895?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1977" target="_blank" rel="noopener noreferrer" class="title-link">Insights into DeepSeek-V3: Scaling Challenges and Reflections on  Hardware for AI Architectures, Chenggang Zhao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- DeepSeek-V3ã¯ã€2,048å°ã®NVIDIA H800 GPUã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢åˆ¶ç´„ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®å…±åŒè¨­è¨ˆã‚’ç¤ºã™ã€‚ãƒ¡ãƒ¢ãƒªåŠ¹ç‡å‘ä¸Šã®ãŸã‚ã®ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰æ½œåœ¨æ³¨æ„ã‚„ã€è¨ˆç®—ã¨é€šä¿¡ã®æœ€é©åŒ–ã‚’å›³ã‚‹å°‚é–€å®¶ã®æ··åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€FP8æ··åˆç²¾åº¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãªã©ã®é©æ–°ã‚’å¼·èª¿ã€‚ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«åŸºã¥ãå°†æ¥ã®æ–¹å‘æ€§ã«ã¤ã„ã¦è­°è«–ã—ã€AIãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã«å¿œãˆã‚‹ãŸã‚ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã¨ãƒ¢ãƒ‡ãƒ«ã®å…±åŒè¨­è¨ˆã®é‡è¦æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/deedydas/status/1924512147947848039?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Probing.html" target="_blank" rel="noopener noreferrer">#Probing</a>
<span class="issue_date">Issue Date: 2025-05-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1974" target="_blank" rel="noopener noreferrer" class="title-link">Why Vision Language Models Struggle with Visual Arithmetic? Towards   Enhanced Chart and Geometry Understanding, Kung-Hsiang Huang+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- Vision Language Models (VLMs)ã¯è¦–è¦šçš„ç®—è¡“ã«è‹¦åŠ´ã—ã¦ã„ã‚‹ãŒã€CogAlignã¨ã„ã†æ–°ã—ã„ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã‚’ææ¡ˆã—ã€VLMã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚CogAlignã¯è¦–è¦šçš„å¤‰æ›ã®ä¸å¤‰ç‰¹æ€§ã‚’èªè­˜ã™ã‚‹ã‚ˆã†ã«è¨“ç·´ã—ã€CHOCOLATEã§4.6%ã€MATH-VISIONã§2.9%ã®æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’60%å‰Šæ¸›ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åŸºæœ¬çš„ãªè¦–è¦šçš„ç®—è¡“èƒ½åŠ›ã®å‘ä¸Šã¨ä¸‹æµã‚¿ã‚¹ã‚¯ã¸ã®è»¢é€ã®åŠ¹æœãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/steeve__huang/status/1923543884367306763?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¢å­˜ã®LLM (proprietary, openweightãã‚Œãã‚Œ)ãŒã€ã‚·ãƒ³ãƒ—ãƒ«ãªvisual arithmeticã‚¿ã‚¹ã‚¯(e.g., ç·šåˆ†ã®é•·ã•æ¯”è¼ƒ, Chartä¸Šã®dotã®ç†è§£)ãªã©ã®æ€§èƒ½ãŒä½ã„ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã€<br><img src="https://github.com/user-attachments/assets/039a48de-67a5-4c81-ba59-174acd508479" alt="image" loading="lazy"><br>ãã‚Œã‚‰ã®åŸå› ã‚’(1)Vision Encoderã®representationã¨(2)Vision Encoderã‚’Freezeã—ãŸä¸Šã§ã®Text Decoderã®finetuningã§åˆ†æã—ãŸã€‚ãã®çµæœã€(1)ã§ã¯ã„ãã¤ã‹ã®ã‚¿ã‚¹ã‚¯ã§linear layerã®probingã§ã¯é«˜ã„æ€§èƒ½ãŒé”æˆã§ããªã„ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€Vision Encoderã«ã‚ˆã‚‹representationãŒã‚¿ã‚¹ã‚¯ã«é–¢ã™ã‚‹æƒ…å ±ã‚’å†…åŒ…ã§ãã¦ã„ãªã„ã‹ã€ã‚¿ã‚¹ã‚¯ã«é–¢ã™ã‚‹æƒ…å ±ã¯å†…åŒ…ã—ã¦ã„ã‚‹ãŒlinear layerã§ã¯ãã‚Œã‚’ååˆ†ã«å¯èƒ½ã§ããªã„å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚ŒãŸã€‚<br><img src="https://github.com/user-attachments/assets/0eb90fa2-7b6a-43b6-81d9-b5f7e6fb3ea8" alt="image" loading="lazy"><br><br>ã“ã‚Œã‚’ã•ã‚‰ã«åˆ†æã™ã‚‹ãŸã‚ã«(2)ã‚’å®Ÿæ–½ã—ãŸã¨ã“ã‚ã€Vision Encoderã‚’freezeã—ã¦ã„ã¦ã‚‚finetuningã«ã‚ˆã‚Šquery stringã«é–¢ã‚ã‚‰ãšé«˜ã„æ€§èƒ½ã‚’ç²å¾—ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€Vision Encoderå´ã®representationã®å•é¡Œã§ã¯ãªãã€Text Decoderã¨å´ã§ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹éš›ã«Finetuningã—ãªã„ã¨ã†ã¾ãæ´»ç”¨ã§ããªã„ã“ã¨ãŒåˆ¤æ˜ã—ãŸã€‚<br><img src="https://github.com/user-attachments/assets/cd122d99-9228-44b1-9827-cdb56f49d492" alt="image" loading="lazy"></p>
<p>æ‰‹æ³•ã®ã¨ã“ã‚ã¯ã¾ã å…¨ç„¶ã—ã£ã‹ã‚Šèª­ã‚ã¦ã„ãªã„ã®ã ãŒã€ç”»åƒã«é–¢ã™ã‚‹ç‰¹å®šã®å±æ€§ã«é–¢ã™ã‚‹ã‚¯ã‚¨ãƒªã¨å›ç­”ã®ãƒšã‚¢ã‚’åˆæˆã—ã€DPOã™ã‚‹ã“ã¨ã§ã€zero-shotã®æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã€ã¨ã„ã†æ„Ÿã˜ã£ã½ã„ï¼Ÿ<br><img src="https://github.com/user-attachments/assets/707b1cc9-8bbf-45a5-b564-f654503c836e" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/281da17b-c8c3-455a-aa51-043ed297ae1f" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/VerifiableRewards.html" target="_blank" rel="noopener noreferrer">#VerifiableRewards</a>
<span class="issue_date">Issue Date: 2025-05-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1964" target="_blank" rel="noopener noreferrer" class="title-link">J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning, Chenxi Whitehouse+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¼·åŒ–å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒJ1ã‚’ç”¨ã„ã¦LLMã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã—ã€åˆ¤æ–­ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹æ€è€ƒä¿ƒé€²ã¨ãƒã‚¤ã‚¢ã‚¹è»½æ¸›ã‚’å›³ã‚Šã¾ã™ã€‚J1ã¯ã€ä»–ã®åŒã‚µã‚¤ã‚ºãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ç‰¹ã«å°å‹ãƒ¢ãƒ‡ãƒ«ã§ã‚‚å„ªã‚ŒãŸçµæœã‚’å‡ºã—ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¯è‡ªå·±ç”Ÿæˆã—ãŸå‚ç…§å›ç­”ã¨æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šè‰¯ã„åˆ¤æ–­ã‚’å­¦ã¶ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1923186392420450545?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLM-as-a-Judgeã®ãªã‚ã®ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ãƒ¬ã‚·ãƒ”ã«ãŠã„ã¦ã€åˆã‚ã¦RLã‚’é©ç”¨ã—ãŸç ”ç©¶ã¨ä¸»å¼µã—ã€ã‚ˆã‚Šé«˜å“è³ªãªreasoning traceã‚’å‡ºåŠ›ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Šã‚’ã•ã›ã‚‹ã€‚<br><br>å…·ä½“çš„ã«ã¯Verifiableãªpromptã¨non verifiableãªpromptã®ä¸¡æ–¹ã‹ã‚‰verifiableãªpreference pairã‚’ä½œæˆã—pointwiseãªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã€ã‚ã‚‹ã„ã¯pairwiseãªjudgeã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã®rewardã‚’è¨­è¨ˆã—GRPOã§å­¦ç¿’ã™ã‚‹ã€ã¿ãŸã„ãªè©±ã£ã½ã„ã€‚<br>non verifiableãªpromptã‚‚ç”¨ã„ã‚‹ã®ã¯ã€ãã†ã„ã£ãŸpromptã«å¯¾ã—ã¦ã‚‚judgeã§ãã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã€‚<br><br>mathã«é–¢ã™ã‚‹promptã¯verifiableãªã®ã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒä¸æ­£è§£ãªã‚‚ã®ã‚’rejection samplingã—ã€WildChatã®ã‚ˆã†ãªãƒãƒ£ãƒƒãƒˆã¯verifiableã§ã¯ãªã„ã®ã§ã€instructionã«ãƒã‚¤ã‚ºã‚’æ··ãœã¦å¾—ã‚‰ã‚ŒãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’rejection samplingã—ã€åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’å¾—ã‚‹ã“ã¨ã§ã€non verifiableãªpromptã«ã¤ã„ã¦ã‚‚ã€verifiableãªrewardã‚’è¨­è¨ˆã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/4264f599-2067-4688-99e7-b68cc1dc771d" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<a class="button" href="articles/SpeculativeDecoding.html" target="_blank" rel="noopener noreferrer">#SpeculativeDecoding</a>
<span class="issue_date">Issue Date: 2025-05-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1961" target="_blank" rel="noopener noreferrer" class="title-link">Faster Cascades via Speculative Decoding, Harikrishna Narasimhan+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ã¨æ¨æ¸¬ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã§ã‚ã‚Šã€ç•°ãªã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æŒã¤ã€‚ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ã¯é›£ã—ã„å…¥åŠ›ã«å¯¾ã—ã¦å¤§ããªãƒ¢ãƒ‡ãƒ«ã‚’é…å»¶çš„ã«ä½¿ç”¨ã—ã€æ¨æ¸¬ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯ä¸¦è¡Œæ¤œè¨¼ã§å¤§ããªãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã™ã‚‹ã€‚æ–°ãŸã«ææ¡ˆã™ã‚‹æ¨æ¸¬ã‚«ã‚¹ã‚±ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æŠ€è¡“ã¯ã€ä¸¡è€…ã®åˆ©ç‚¹ã‚’çµ„ã¿åˆã‚ã›ã€æœ€é©ãªé…å»¶ãƒ«ãƒ¼ãƒ«ã‚’ç‰¹å®šã™ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€ææ¡ˆæ‰‹æ³•ãŒã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ãŠã‚ˆã³æ¨æ¸¬ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸã‚³ã‚¹ãƒˆå“è³ªãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1922059828429832259?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview: 


<a href="https://openreview.net/forum?id=vo9t20wsmd" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=vo9t20wsmd</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-05-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1946" target="_blank" rel="noopener noreferrer" class="title-link">EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language  Models, Ziwen Xu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€LLMã®æŒ™å‹•ã‚’åˆ¶å¾¡ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒEasyEdit2ã€ã‚’ææ¡ˆã€‚å®‰å…¨æ€§ã‚„æ„Ÿæƒ…ã€å€‹æ€§ãªã©ã®ä»‹å…¥ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€ä½¿ã„ã‚„ã™ã•ãŒç‰¹å¾´ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯æŠ€è¡“çš„çŸ¥è­˜ãªã—ã§ãƒ¢ãƒ‡ãƒ«ã®å¿œç­”ã‚’èª¿æ•´å¯èƒ½ã€‚æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°ãƒ™ã‚¯ãƒˆãƒ«ã‚’è‡ªå‹•ç”Ÿæˆãƒ»é©ç”¨ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ­è¼‰ã€‚å®Ÿè¨¼çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å ±å‘Šã—ã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚„ãƒ‡ãƒ¢ã‚‚å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>github:


<a href="https://github.com/zjunlp/EasyEdit/tree/main" target="_blank" rel="noopener noreferrer">https://github.com/zjunlp/EasyEdit/tree/main</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1944" target="_blank" rel="noopener noreferrer" class="title-link">Nemotron-CC: Transforming Common Crawl into a Refined Long-Horizon   Pretraining Dataset, Dan Su+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- FineWeb-Eduã¨DCLMã¯ã€ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚Šãƒ‡ãƒ¼ã‚¿ã®90%ã‚’å‰Šé™¤ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«é©ã•ãªããªã£ãŸã€‚è‘—è€…ã¯ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆ†é¡å™¨ã‚„åˆæˆãƒ‡ãƒ¼ã‚¿ã®è¨€ã„æ›ãˆã‚’ç”¨ã„ã¦ã€ç²¾åº¦ã¨ãƒ‡ãƒ¼ã‚¿é‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ”¹å–„ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚1Tãƒˆãƒ¼ã‚¯ãƒ³ã§8Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€DCLMã«å¯¾ã—ã¦MMLUã‚’5.6ãƒã‚¤ãƒ³ãƒˆå‘ä¸Šã•ã›ãŸã€‚æ–°ã—ã„6.3Tãƒˆãƒ¼ã‚¯ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€DCLMã¨åŒç­‰ã®æ€§èƒ½ã‚’æŒã¡ãªãŒã‚‰ã€4å€ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’å«ã¿ã€é•·ãƒˆãƒ¼ã‚¯ãƒ³ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚15Tãƒˆãƒ¼ã‚¯ãƒ³ã®ãŸã‚ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸ8Bãƒ¢ãƒ‡ãƒ«ã¯ã€Llama 3.1ã®8Bãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/Toxicity.html" target="_blank" rel="noopener noreferrer">#Toxicity</a>
<a class="button" href="articles/ActivationSteering/ITI.html" target="_blank" rel="noopener noreferrer">#ActivationSteering/ITI</a>
<span class="issue_date">Issue Date: 2025-05-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1940" target="_blank" rel="noopener noreferrer" class="title-link">When Bad Data Leads to Good Models, Kenneth Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€LLMã®äº‹å‰å­¦ç¿’ã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿ã®è³ªã®å†æ¤œè¨ã‚’è¡Œã„ã€æœ‰å®³ãƒ‡ãƒ¼ã‚¿ãŒäº‹å¾Œå­¦ç¿’ã«ãŠã‘ã‚‹åˆ¶å¾¡ã‚’å‘ä¸Šã•ã›ã‚‹å¯èƒ½æ€§ã‚’æ¢ã‚Šã¾ã™ã€‚ãƒˆã‚¤å®Ÿé¨“ã‚’é€šã˜ã¦ã€æœ‰å®³ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆãŒå¢—åŠ ã™ã‚‹ã“ã¨ã§æœ‰å®³æ€§ã®æ¦‚å¿µãŒç·šå½¢è¡¨ç¾ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã€æœ‰å®³ãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆçš„æœ‰å®³æ€§ã‚’å¢—åŠ ã•ã›ã¤ã¤ã‚‚é™¤å»ã—ã‚„ã™ããªã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚è©•ä¾¡çµæœã¯ã€æœ‰å®³ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆçš„æœ‰å®³æ€§ã‚’ä½ä¸‹ã•ã›ã¤ã¤ä¸€èˆ¬çš„ãªèƒ½åŠ›ã‚’ä¿æŒã™ã‚‹è‰¯å¥½ãªãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ke_li_2021/status/1920646069613957606?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯é¢ç™½ãã†</p>
<p>Webã‚³ãƒ¼ãƒ‘ã‚¹ãªã©ã‚’äº‹å‰å­¦ç¿’ã§åˆ©ç”¨ã™ã‚‹éš›ã¯ã€è³ªã®é«˜ã„ãƒ‡ãƒ¼ã‚¿ã‚’æ®‹ã—ã¦å­¦ç¿’ã—ãŸæ–¹ãŒè‰¯ã„ã¨ã•ã‚Œã¦ã„ã‚‹ãŒã€4chanã®ã‚ˆã†ãªtoxicãªãƒ‡ãƒ¼ã‚¿ã‚’æ··ãœã¦äº‹å‰å­¦ç¿’ã—ã¦ã€å¾Œã‹ã‚‰detoxï¼ˆInference Time Intervention <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1941" target="_blank" rel="noopener noreferrer">Inference-Time Intervention: Eliciting Truthful Answers from a Language   Model, Kenneth Li+, NeurIPS'23</a>
 , SFT, DPO)ã™ã‚‹ã“ã¨ã§ã€æœ€çµ‚çš„ãªãƒ¢ãƒ‡ãƒ«ã®toxicãªoutputãŒæ¸›ã‚‹ã¨ã„ã†è©±ã‚‰ã—ã„ã€‚ã“ã‚Œã¯ãã‚‚ãã‚‚äº‹å‰å­¦ç¿’æ™‚ç‚¹ã§toxicãªãƒ‡ãƒ¼ã‚¿ã®signalãŒé™¤å¤–ã•ã‚Œã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ãŒtoxicãªå†…å®¹ã®representationã‚’å­¦ç¿’ã§ããšã€æœ€çµ‚çš„ã«toxicã‹å¦ã‹ã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ããªããªã‚‹ãŸã‚ã€ã¨è€ƒå¯Ÿã—ã¦ã„ã‚‹ï¼ˆã£ã½ã„ï¼‰<br><img src="https://github.com/user-attachments/assets/7f6efd4b-0679-4143-9a7d-1bf3ea5b6f3a" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/0acec11b-d851-4137-b0aa-1ed7172388e1" alt="image" loading="lazy"></p>
<p>æœ‰å®³ãªå‡ºåŠ›ã‚’æ¸›ã‚‰ã›ãã†ãªã“ã¨ã¯åˆ†ã‹ã£ãŸãŒã€Activation Steeringã«ã‚ˆã£ã¦ã©ã®ç¨‹åº¦ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã®ã‹ãŒæ°—ã«ãªã‚‹ã€ã¨æ€ã£ãŸãŒAppendixã«è¨˜è¼‰ãŒã‚ã£ãŸã€‚ç´°ã‹ãæ›¸ã‹ã‚Œã¦ã„ãªã„ã®ã§æ¨æ¸¬ã‚’å«ã‚€ãŒã€å„ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦Toxicãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§Probingã™ã‚‹ã“ã¨ã§TopKã®headã‚’æ±ºã‚ã¦ã€Kã®å€¤ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§interventionã®å¼·ã•ã‚’èª¿æ•´ã—ã€Toxicãƒ‡ãƒ¼ã‚¿ã®å‰²åˆã‚’å¤‰åŒ–ã•ã›ã¦è©•ä¾¡ã—ã¦ã¿ãŸã¨ã“ã‚ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å¤§ããªå½±éŸ¿ã¯ãªã‹ã£ãŸã¨ã„ã†ã“ã¨ã ã¨æ€ã‚ã‚Œã‚‹ï¼ˆãŸã ã—1Bãƒ¢ãƒ‡ãƒ«ã§ã®å®Ÿé¨“ã—ã‹ãªã„ï¼‰<br><br><img src="https://github.com/user-attachments/assets/4c79ca22-6916-438d-ad31-07596c82bfd1" alt="image" loading="lazy"><br></p>
<p>ãŠãã‚‰ã2,3ç¯€ã‚ãŸã‚ŠãŒä¸€ç•ªãŠã‚‚ã—ã‚ã„ãƒã‚¤ãƒ³ãƒˆãªã®ã ã¨æ€ã‚ã‚Œã‚‹ãŒã¾ã èª­ã‚ã¦ã„ãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1938" target="_blank" rel="noopener noreferrer" class="title-link">Reinforcement Learning for Reasoning in Large Language Models with One   Training Example, Yiping Wang+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- 1-shot RLVRã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€LLMã®æ•°å­¦çš„æ¨è«–èƒ½åŠ›ãŒå¤§å¹…ã«å‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚Qwen2.5-Math-1.5Bãƒ¢ãƒ‡ãƒ«ã¯ã€MATH500ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒ36.0%ã‹ã‚‰73.6%ã«æ”¹å–„ã•ã‚Œã€ä»–ã®æ•°å­¦çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚‚åŒæ§˜ã®å‘ä¸ŠãŒè¦‹ã‚‰ã‚ŒãŸã€‚1-shot RLVRä¸­ã«ã¯ã€ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³ä¸€èˆ¬åŒ–ã‚„æŒç¶šçš„ãªãƒ†ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®æ”¹å–„ãŒè¦³å¯Ÿã•ã‚Œã€ãƒãƒªã‚·ãƒ¼å‹¾é…æå¤±ãŒä¸»ãªè¦å› ã§ã‚ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±ã®è¿½åŠ ã‚‚é‡è¦ã§ã€çµæœå ±é…¬ãªã—ã§ã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã—ãŸã€‚ã“ã‚Œã‚‰ã®æˆæœã¯ã€RLVRã®ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã«é–¢ã™ã‚‹ã•ã‚‰ãªã‚‹ç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/03cd9200-7fed-4c6d-a5a6-2379d2c8950a" alt="image" loading="lazy"></p>
<p>ä¸‹è¨˜ãƒã‚¹ãƒˆã§Qwenã«å¯¾ã—ã¦promptã‚’é©åˆ‡ã«ä¸ãˆã‚‹ã“ã¨ã§ã€è¿½åŠ ã®post trainingç„¡ã—ã§é«˜ã„æ•°å­¦ã«é–¢ã™ã‚‹èƒ½åŠ›ã‚’å¼•ãå‡ºã›ãŸã¨ã„ã†æƒ…å ±ãŒã‚ã‚‹ã€‚ãŠãã‚‰ãäº‹å‰å­¦ç¿’æ™‚ã«æ•°å­¦ã®QAãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã£ã¦ç¶™ç¶šäº‹å‰å­¦ç¿’ã•ã‚Œã¦ãŠã‚Šã€ã“ã®èƒ½åŠ›ã¯ãã®éš›ã«èº«ã«ã¤ã„ã¦ã„ã‚‹ãŸã‚ã€æ•°å­¦ã«å¯¾ã™ã‚‹é«˜ã„èƒ½åŠ›ã¯å®Ÿã¯ç°¡å˜ã«å¼•ãå‡ºã™ã“ã¨ãŒã§ãã‚‹ã®ã‹ã‚‚ã—ã‚Œãªã„ï¼ˆã ã‹ã‚‰1ã‚µãƒ³ãƒ—ãƒ«ã§ã‚‚æ€§èƒ½ãŒå‘ä¸Šã—ãŸã®ã§ã¯ãªã„ã‹ï¼Ÿï¼‰ã¨ã„ã£ãŸè€ƒå¯ŸãŒã‚ã‚‹ã€‚<br><br>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/weiliu99/status/1930826904522875309?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2011" target="_blank" rel="noopener noreferrer">[Paper Note] ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in  Large Language Models, Mingjie Liu+, NeurIPS'25</a>
<br><br>ã¨ã¯ã©ã®ã‚ˆã†ãªé–¢ä¿‚æ€§ãŒã‚ã‚‹ã ã‚ã†ã‹ï¼Ÿ</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ypwang61/status/1968834328508379563?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1937" target="_blank" rel="noopener noreferrer" class="title-link">Rewriting Pre-Training Data Boosts LLM Performance in Math and Code, Kazuki Fujii+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å…¬å…±ãƒ‡ãƒ¼ã‚¿ã‚’ä½“ç³»çš„ã«æ›¸ãæ›ãˆã‚‹ã“ã¨ã§å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹2ã¤ã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€SwallowCodeã¨SwallowMathã‚’ç´¹ä»‹ã€‚SwallowCodeã¯Pythonã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’æ´—ç·´ã•ã›ã‚‹4æ®µéšã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç”¨ã„ã€ä½å“è³ªã®ã‚³ãƒ¼ãƒ‰ã‚’ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã€‚SwallowMathã¯ãƒœã‚¤ãƒ©ãƒ¼ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å‰Šé™¤ã—ã€è§£æ±ºç­–ã‚’ç°¡æ½”ã«å†ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Llama-3.1-8Bã®ã‚³ãƒ¼ãƒ‰ç”Ÿæˆèƒ½åŠ›ãŒHumanEvalã§+17.0ã€GSM8Kã§+12.4å‘ä¸Šã€‚ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯å…¬é–‹ã•ã‚Œã€å†ç¾å¯èƒ½ãªç ”ç©¶ã‚’ä¿ƒé€²ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1920141189652574346?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1920613041026314274?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Label-free.html" target="_blank" rel="noopener noreferrer">#Label-free</a>
<span class="issue_date">Issue Date: 2025-05-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1936" target="_blank" rel="noopener noreferrer" class="title-link">Absolute Zero: Reinforced Self-play Reasoning with Zero Data, Andrew Zhao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„RLVRãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã€ŒAbsolute Zeroã€ã‚’ææ¡ˆã—ã€è‡ªå·±å­¦ç¿’ã‚’é€šã˜ã¦æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹AZRã‚’å°å…¥ã€‚å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã«ä¾å­˜ã›ãšã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚„æ•°å­¦çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã§SOTAãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚æ—¢å­˜ã®ã‚¼ãƒ­è¨­å®šãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚±ãƒ¼ãƒ«ã«ã‚‚é©ç”¨å¯èƒ½ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1919946713567264917?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-05-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1930" target="_blank" rel="noopener noreferrer" class="title-link">Thinking LLMs: General Instruction Following with Thought Generation, Tianhao Wu+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã«æ€è€ƒèƒ½åŠ›ã‚’è£…å‚™ã™ã‚‹ãŸã‚ã®è¨“ç·´æ–¹æ³•ã‚’ææ¡ˆã€‚åå¾©çš„ãªæ¤œç´¢ã¨æœ€é©åŒ–æ‰‹é †ã‚’ç”¨ã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ãŒç›£è¦–ãªã—ã§æ€è€ƒã™ã‚‹æ–¹æ³•ã‚’å­¦ã¶ã€‚æŒ‡ç¤ºã«å¯¾ã™ã‚‹æ€è€ƒå€™è£œã¯ã‚¸ãƒ£ãƒƒã‚¸ãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡ã•ã‚Œã€æœ€é©åŒ–ã•ã‚Œã‚‹ã€‚ã“ã®æ‰‹æ³•ã¯AlpacaEvalã¨Arena-Hardã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€æ¨è«–ã‚¿ã‚¹ã‚¯ã ã‘ã§ãªãã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚„å¥åº·ãªã©ã®éæ¨è«–ã‚«ãƒ†ã‚´ãƒªã§ã‚‚åˆ©ç‚¹ã‚’ç™ºæ®ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tesatory/status/1919461701206081813?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¤–éƒ¨ã®CoTãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã‚ãªã„ã§ã€LLMã®reasoning capabilityã‚’å‘ä¸Šã•ã›ã‚‹è©±ã£ã½ã„ã€‚DeepSeek-R1ã®ç™»å ´ä»¥å‰ã®ç ”ç©¶ã¨ã®ã“ã¨ã€‚</p>
<p>reasoning traceã‚’å‡ºåŠ›ã™ã‚‹ã‚ˆã†ã«Instruction Tuningã«ã‚ˆã£ã¦å›ç­”ã‚’ç›´æ¥å‡ºåŠ›ã™ã‚‹ã‚ˆã†PostTrainingã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«promptingã—ã€è¤‡æ•°ã®outputã‚’åé›†ï¼ˆä»Šå›ã¯8å€‹, temperature=0.8, top p=0.95)ã€‚Self Taught Evaluator <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1464" target="_blank" rel="noopener noreferrer">Self-Taught Evaluators, Tianlu Wang+, N/A, arXiv'24</a>
 (STE;70B, LLM-as-a-Judgeã‚’åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼‰ã€ã‚ã‚‹ã„ã¯Armo Reward Modelï¼ˆ8Bï¼‰ã«ã‚ˆã£ã¦å›ç­”ã®å“è³ªã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã€‚ã“ã“ã§ã€LLM-as-a-Judgeã®å ´åˆã¯ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã§ã®å„ªåŠ£ãŒæ±ºã¾ã‚‹ã ã‘ãªã®ã§ã€ELOã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹ã€‚outputã®ã†ã¡best scoreã¨worst scoreã ã£ãŸã‚‚ã®ã®åŒæ–¹ã§ãƒšã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã—ã€DPOã§åˆ©ç”¨ã™ã‚‹preferenceãƒšã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã—DPOã™ã‚‹ã€‚ã“ã®ã‚ˆã†ãªå‡¦ç†ã‚’ç¹°ã‚Šè¿”ã—ã€ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’iterationã”ã¨ã«æ›´æ–°ã™ã‚‹ã€‚æ¬¡ã®iterationã§ã¯æ›´æ–°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§åŒæ§˜ã®å‡¦ç†ã‚’è¡Œã„ã€å‰æ®µã®ã‚¹ãƒ†ãƒƒãƒ—ã§åˆ©ç”¨ã—ãŸå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯åˆ©ç”¨ã—ãªã„ã‚ˆã†ã«ã™ã‚‹ï¼ˆå¾Œæ®µã®æ–¹ãŒå“è³ªãŒé«˜ã„ã¨æƒ³å®šã•ã‚Œã‚‹ãŸã‚ï¼‰ã€‚ã¾ãŸã€å›ç­”ã‚’åˆ¥ãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡ã™ã‚‹éš›ã«ã€é•·ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å¥½ã‚€ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€é•·ã„å†—é•·ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒé«˜ãã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã•ã‚Œã‚‹ã‚ˆã†ãªãƒã‚¤ã‚¢ã‚¹ãŒåƒãæ‡¸å¿µãŒã‚ã‚‹ãŸã‚ã€é•·ã™ãã‚‹å›ç­”ã«penaltyã‚’ä¸ãˆã¦ã„ã‚‹ï¼ˆLength-Control)ã€‚<br><img src="https://github.com/user-attachments/assets/3be7f7c3-1a24-44c5-bd73-a4b9e11b4b2c" alt="image" loading="lazy"><br><br>reasoning traceã‚’å‡ºåŠ›ã™ã‚‹promptã¯genericã¨specific thoughtã®äºŒç¨®é¡ã§æ¤œè¨¼ã€‚å‰è€…ã¯LLMã«ã©ã®ã‚ˆã†ãªæ€è€ƒã‚’ã™ã‚‹ã‹ã‚’ä¸¸æŠ•ã’ã™ã‚‹ã®ã«å¯¾ã—ã€å¾Œè€…ã¯ã“ã¡ã‚‰å´ã§æŒ‡å®šã™ã‚‹ã€‚å¾Œè€…ã®å ´åˆã¯ã€ã©ã®ã‚ˆã†ãªæ€è€ƒãŒè‰¯ã„ã‹ã‚’äº‹å‰ã«çŸ¥ã£ã¦ã„ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚<br><img src="https://github.com/user-attachments/assets/4548fd23-69ba-482f-8987-740f30658d83" alt="image" loading="lazy"><br><br>Llama-3-8b-instructã«é©ç”¨ã—ãŸã¨ã“ã‚ã€70Bã‚¹ã‚±ãƒ¼ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’é”æˆã€‚ã¾ãŸã€reasoning traceå‡ºåŠ›ã‚’ablationã—ãŸãƒ¢ãƒ‡ãƒ«ï¼ˆDirect responce baselineï¼‰ã‚ˆã‚Šã‚‚æ€§èƒ½ãŒå‘ä¸Šã€‚<br><img src="https://github.com/user-attachments/assets/06605741-7049-460a-8062-93be96d45975" alt="image" loading="lazy"><br><br>iterationãŒé€²ã‚€ã«é€£ã‚Œã¦ã€æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/25ced3ce-e341-41c4-b1e2-527885590e08" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/PPO%20(ProximalPolicyOptimization).html" target="_blank" rel="noopener noreferrer">#PPO (ProximalPolicyOptimization)</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/VerifiableRewards.html" target="_blank" rel="noopener noreferrer">#VerifiableRewards</a>
<a class="button" href="articles/CurriculumLearning.html" target="_blank" rel="noopener noreferrer">#CurriculumLearning</a>
<span class="issue_date">Issue Date: 2025-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1925" target="_blank" rel="noopener noreferrer" class="title-link">100 Days After DeepSeek-R1: A Survey on Replication Studies and More  Directions for Reasoning Language Models, Chong Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®æ¨è«–è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆRLMï¼‰ã®é€²å±•ã‚’å—ã‘ã¦ã€DeepSeek-R1ãŒæ³¨ç›®ã‚’é›†ã‚ã¦ã„ã‚‹ãŒã€ãã®å®Ÿè£…è©³ç´°ã¯å®Œå…¨ã«ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã•ã‚Œã¦ã„ãªã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¤šãã®å†ç¾ç ”ç©¶ãŒè¡Œã‚ã‚Œã€DeepSeek-R1ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å†ç¾ã—ã‚ˆã†ã¨ã™ã‚‹è©¦ã¿ãŒç¶šã„ã¦ã„ã‚‹ã€‚ç‰¹ã«ã€ç›£è¦–ä»˜ããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã¨å¼·åŒ–å­¦ç¿’ï¼ˆRLVRï¼‰ã®æˆ¦ç•¥ãŒæ¢æ±‚ã•ã‚Œã€è²´é‡ãªæ´å¯ŸãŒå¾—ã‚‰ã‚Œã¦ã„ã‚‹ã€‚æœ¬å ±å‘Šã§ã¯ã€å†ç¾ç ”ç©¶ã®æ¦‚è¦ã‚’æä¾›ã—ã€ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰ã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹é †ã®è©³ç´°ã‚’ç´¹ä»‹ã—ã€ä»Šå¾Œã®ç ”ç©¶ã®ä¿ƒé€²ã‚’ç›®æŒ‡ã™ã€‚ã¾ãŸã€RLMã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã®è¿½åŠ æŠ€è¡“ã‚„é–‹ç™ºä¸Šã®èª²é¡Œã«ã¤ã„ã¦ã‚‚è€ƒå¯Ÿã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1918898257406709983?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã‚µãƒ¼ãƒ™ã‚¤ã®takeawayãŒç®‡æ¡æ›¸ãã•ã‚Œã¦ã„ã‚‹ã€‚</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/CompressionValleys.html" target="_blank" rel="noopener noreferrer">#CompressionValleys</a>
<span class="issue_date">Issue Date: 2025-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1924" target="_blank" rel="noopener noreferrer" class="title-link">Layer by Layer: Uncovering Hidden Representations in Language Models, Oscar Skean+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- ä¸­é–“å±¤ã®åŸ‹ã‚è¾¼ã¿ãŒæœ€çµ‚å±¤ã‚’è¶…ãˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã“ã¨ã‚’åˆ†æã—ã€æƒ…å ±ç†è«–ã‚„å¹¾ä½•å­¦ã«åŸºã¥ããƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ææ¡ˆã€‚32ã®ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ã‚¿ã‚¹ã‚¯ã§ä¸­é–“å±¤ãŒå¼·åŠ›ãªç‰¹å¾´ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã—ã€AIã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–ã«ãŠã‘ã‚‹ä¸­é–“å±¤ã®é‡è¦æ€§ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç¾ä»£ã®ä»£è¡¨çš„ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆdecoder-only model, encoder-only model, SSMï¼‰ã«ã¤ã„ã¦ã€æœ€çµ‚å±¤ã®embeddingã‚ˆã‚Šã‚‚ä¸­é–“å±¤ã®embeddingã®æ–¹ãŒdownstream taskï¼ˆMTEBã®32Taskã®å¹³å‡ï¼‰ã«ã€ä¸€è²«ã—ã¦ï¼ˆãŸã ã—ã€ã“ã‚Œã¯MTEBã®å¹³å‡ã§è¦‹ãŸã‚‰ãã†ã¨ã„ã†è©±ã§ã‚ã‚Šã€å€‹åˆ¥ã®ã‚¿ã‚¹ã‚¯ã§ä¸€è²«ã—ã¦å¼·ã„ã‹ã¯èª­ã‚“ã§ã¿ãªã„ã¨ã‚ã‹ã‚‰ãªã„ï¼‰å¼·ã„ã“ã¨ã‚’ç¤ºã—ãŸç ”ç©¶ã€‚<br><br>ã“ã®ã“ã¨è‡ªä½“ã¯çµŒé¨“çš„ã«çŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ã®ã§ã‚ã¾ã‚Šé©šãã§ã¯ãªã„ã®ã ãŒï¼ˆãŸã ã€SSMã§ã‚‚ãã†ãªã®ã‹ã€ã¨ã„ã†ã®ã¨ã€ä¸€è²«ã—ã¦å¼·ã„ã¨ã„ã†ã®ã¯èˆˆå‘³æ·±ã„ï¼‰ã€ã“ã®ç ”ç©¶ã¯Matrix Based Entropyã¨å‘¼ã°ã‚Œã‚‹ã‚‚ã®ã«åŸºã¥ã„ã¦ã€ã“ã‚Œã‚‰ã‚’åˆ†æã™ã‚‹ãŸã‚ã®æ§˜ã€…ãªæŒ‡æ¨™ã‚’å®šç¾©ã—ç†è«–çš„ãªæ ¹æ‹ ã‚’ç¤ºã—ã€Autoregressiveãªå­¦ç¿’ã‚ˆã‚Šã‚‚Masked Languageã«ã‚ˆã‚‹å­¦ç¿’ã®æ–¹ãŒã“ã®ã‚ˆã†ãªMiddle Layerã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãŒç·©å’Œã•ã‚Œã€åŒæ§˜ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãŒç”»åƒã®å ´åˆã§ã‚‚èµ·ãã‚‹ã“ã¨ã‚’ç¤ºã—ã€CoTãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸFinetuningã«ã¤ã„ã¦ã‚‚åˆ†æã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ã“ã®è¾ºã®è²¢çŒ®ãŒéå¸¸ã«å¤§ãã„ã¨æ€ã‚ã‚Œã‚‹ã®ã§ã“ã“ã‚’ç†è§£ã™ã‚‹ã“ã¨ãŒé‡è¦ã ã¨æ€ã‚ã‚Œã‚‹ã€‚ã‚ã¨ã§èª­ã‚€ã€‚<br><br><img src="https://github.com/user-attachments/assets/bda00c50-c97b-45e0-97a5-d98dd98599fd" alt="image" loading="lazy"></p>
<p>openreview:


<a href="https://openreview.net/forum?id=WGXb7UdvTX" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=WGXb7UdvTX</a>


</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Bias.html" target="_blank" rel="noopener noreferrer">#Bias</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/PerplexityCurse.html" target="_blank" rel="noopener noreferrer">#PerplexityCurse</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-05-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1922" target="_blank" rel="noopener noreferrer" class="title-link">Where is the answer? Investigating Positional Bias in Language Model   Knowledge Extraction, Kuniaki Saito+, NAACL'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã¯æ–°ã—ã„æ–‡æ›¸ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ã ãŒã€ã€Œå›°æƒ‘ã®å‘ªã„ã€ã«ã‚ˆã‚Šæƒ…å ±æŠ½å‡ºãŒå›°é›£ã€‚ç‰¹ã«æ–‡æ›¸ã®åˆã‚ã«é–¢ã™ã‚‹è³ªå•ã«ã¯æ­£ç¢ºã«ç­”ãˆã‚‹ãŒã€ä¸­é–“ã‚„æœ«å°¾ã®æƒ…å ±æŠ½å‡ºã«è‹¦åŠ´ã™ã‚‹ã€‚è‡ªå·±å›å¸°çš„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã“ã®å•é¡Œã‚’å¼•ãèµ·ã“ã™ã“ã¨ã‚’ç¤ºã—ã€ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°è‡ªå·±å›å¸°æå¤±ãŒæƒ…å ±æŠ½å‡ºã‚’æ”¹å–„ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMã®çŸ¥è­˜æŠ½å‡ºã¨æ–°ãƒ‰ãƒ¡ã‚¤ãƒ³ã¸ã®é©å¿œã«é–¢ã™ã‚‹æ–°ãŸãªè­°è«–ãŒç”Ÿã¾ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/losnuevetoros/status/1918332232181207096?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>![Image](https://github.com/user-attachments/assets/dd6bdffa-4ce0-4389-826e-4c85113c755f)<br>LLMã®çŸ¥è­˜ã‚’æœ€æ–°ã«ã™ã‚‹ãŸã‚ã«æ–°ã—ã„æ–‡æ›¸ï¼ˆe.g., æ–°ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã®æ–‡æ›¸ç­‰ï¼‰ã‚’LLMã«ä¸ãˆï¼ˆä¾¿å®œä¸Šå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨å‘¼ã¶ï¼‰Finetuningã‚’ã—ãŸå ´åˆã€Finetuningå¾Œã®ãƒ¢ãƒ‡ãƒ«ã§ä¸ãˆã‚‰ã‚ŒãŸqueryã‹ã‚‰ï¼ˆLLMä¸­ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦memorizeã•ã‚Œã¦ã„ã‚‹ï¼‰å¯¾å¿œã™ã‚‹äº‹å®Ÿæƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ã‚ˆã†Inferenceã‚’å®Ÿæ–½ã™ã‚‹ã¨ã€queryã«å¯¾å¿œã™ã‚‹äº‹å®Ÿæƒ…å ±ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸­ã§ã®ä½ç½®ãŒæ·±ããªã‚‹ã¨ï¼ˆi.e., middle -- endã«ãªã‚‹ã¨ï¼‰æŠ½å‡ºãŒå›°é›£ã«ãªã‚‹ Positional BiasãŒå­˜åœ¨ã™ã‚‹[^1]ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚<br>ãã—ã¦ã€ã“ã‚Œã‚’ç·©å’Œã™ã‚‹ãŸã‚ã«æ­£å‰‡åŒ–ãŒé‡è¦ï¼ˆe.g., Denoising, Shuffle, Attention Dropsï¼‰ã§ã‚ã‚‹ã“ã¨ã‚’å®Ÿé¨“çš„ã«ç¤ºã—ã€æ­£å‰‡åŒ–æ‰‹æ³•ã¯è¤‡æ•°çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ã‚ˆã‚ŠPositional BiasãŒç·©å’Œã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸç ”ç©¶<br><br>[^1]: æœ¬ç ”ç©¶ã§ã¯"Training"ã«åˆ©ç”¨ã™ã‚‹æ–‡æ›¸ã®Positional Biasã«ã¤ã„ã¦ç¤ºã—ã¦ãŠã‚Šã€"Inference"æ™‚ã«ãŠã‘ã‚‹Positional Biasã¨ã—ã¦çŸ¥ã‚‰ã‚Œã¦ã„ã‚‹"lost-in-the middle"ã¨ã¯ç•°ãªã‚‹ç¾è±¡ã‚’æ‰±ã£ã¦ã„ã‚‹ç‚¹ã«æ³¨æ„</p>
<p>
<strong>## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>æ–‡æ›¸ + QAãƒ‡ãƒ¼ã‚¿ã®2ç¨®é¡ã‚’æ§‹ç¯‰ã—Finetuningå¾Œã®knowledge extractionèƒ½åŠ›ã®æ¤œè¨¼ã‚’ã—ã¦ã„ã‚‹[^2]ã€‚<br><br>å®Ÿé¨“ã§ã¯ã€`Synthetic Bio (åˆæˆãƒ‡ãƒ¼ã‚¿)`, `Wiki2023+ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ï¼‰` ã®2ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€Positional Biasã‚’æ¤œè¨¼ã—ã¦ã„ã‚‹ã€‚<br>Synthetic bioã¯ã€äººé–“ã®biographyã«é–¢ã™ã‚‹9ã¤ã®å±æ€§ï¼ˆe.g., èª•ç”Ÿæ—¥, å‡ºç”Ÿåœ°ï¼‰ã¨ã—ã¦ã¨ã‚Šã†ã‚‹å€¤ã‚’ChatGPTã«ç”Ÿæˆã•ã›ã€3000äººã®äººç‰©ã«å¯¾ã—ã¦ãã‚Œã‚‰ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«assignã—ã€sentence templateã‚’ç”¨ã„ã¦Surface Realizationã™ã‚‹ã“ã¨ã§äººå·¥çš„ã«3000äººã®biographyã«é–¢ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¦ã„ã‚‹ã€‚<br>ä¸€æ–¹ã€Wiki2023+ã§ã¯ã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1708" target="_blank" rel="noopener noreferrer">Instruction-tuned Language Models are Better Knowledge Learners, Zhengbao Jiang+, ACL'24</a>
</strong>
<br>
 ã®æ–¹æ³•ã«ã®ã£ã¨ã£ã¦ [^3]äº‹å‰å­¦ç¿’æ™‚ã®çŸ¥è­˜ã¨ã®overlapãŒæœ€å°ã¨ãªã‚‹ã‚ˆã†ã«`2023`ã‚«ãƒ†ã‚´ãƒªä»¥ä¸‹ã®wikipediaã®æ§˜ã€…ãªã‚¸ãƒ£ãƒ³ãƒ«ã®è¨˜äº‹ã‚’åé›†ã—ã¦æ´»ç”¨ã™ã‚‹ã€‚QAãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰ã«ã¯ã€å…ƒæ–‡æ›¸ã‹ã‚‰sentenceã‚’æŠ½å‡ºã—ã€GPT-3.5-Turboã«å½“è©²sentenceã®ã¿ã‚’ä¸ãˆã¦QA pairã‚’ä½œæˆã•ã›ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¦ã„ã‚‹ã€‚ãªãŠã€hallucinationã‚„å“è³ªã®ä½ã„QA pairã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸã€‚ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®QA Pairã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—å“è³ªã‚’ç¢ºèªã—ãŸã¨ã“ã‚ã€95%ã®QA pairãŒå¦¥å½“ãªã‚‚ã®ã§ã‚ã£ãŸã€‚<br><br>ã“ã‚Œã«ã‚ˆã‚Šã€ä¸‹å›³ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒä½œæˆã•ã‚Œã‚‹ã€‚FigureCãŒ `Wiki2023+`ã§ã€FigureDãŒ`SyntheticBio`ã€‚`Wiki2023+`ã§ã¯ã€QA pairã®æ­£è§£ãŒæ–‡æ›¸ä¸­ã®å‰åŠã«ã‚ˆã‚Šæ­£è§£ãŒç¾ã‚Œã‚‹ã‚ˆã†ãªåã‚ŠãŒè¦‹å—ã‘ã‚‰ã‚Œã‚‹ã€‚<br>![Image](https://github.com/user-attachments/assets/1146328f-de7e-4e90-b495-b129730c5d0d)<br><br>[^2]: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1923" target="_blank" rel="noopener noreferrer">Physics of Language Models: Part 3.1, Knowledge Storage and Extraction, Zeyuan Allen-Zhu+, ICML'24</a>
 ã«ãŠã„ã¦ã€çŸ¥è­˜ + çŸ¥è­˜ã‚’æŠ½å‡ºã™ã‚‹ã‚¿ã‚¹ã‚¯ã®åŒæ–¹ã‚’ç”¨ã„ã¦å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰çŸ¥è­˜ã‚’æŠ½å‡ºã™ã‚‹èƒ½åŠ›ãŒå‚™ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€‚<br>[^3]: Llama-2-7Bã«ãŠã„ã¦2023ã‚«ãƒ†ã‚´ãƒªä»¥ä¸‹ã®æƒ…å ±ã«å¯¾ã™ã‚‹QAã®performanceãŒè‘—ã—ãä½ã„ã“ã¨ã‹ã‚‰ã€äº‹å‰å­¦ç¿’æ™‚ã«å½“è©²ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒä½ã„ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¦ã„ã‚‹</p>
<p>
<strong>## å®Ÿé¨“ &amp; å®Ÿé¨“çµæœ (modulated data)<br>ä½œæˆã—ãŸæ–‡æ›¸+QAãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¤ã„ã¦ã€QAãƒ‡ãƒ¼ã‚¿ã‚’train/valid/testã«åˆ†ã‘ã¦ã€æ–‡æ›¸ãƒ‡ãƒ¼ã‚¿ã¯å…¨ã¦åˆ©ç”¨ã—ã€testã«å«ã¾ã‚Œã‚‹QAã«é©åˆ‡ã«å›ç­”ã§ãã‚‹ã‹ã§æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹ã€‚ã“ã®ã¨ãã€æ–‡æ›¸ä¸­ã§QAã«å¯¾ã™ã‚‹æ­£è§£ãŒãƒ†ã‚­ã‚¹ãƒˆãŒå‡ºç¾ã™ã‚‹ä½ç½®ã‚’å¤‰åŒ–ã•ã›ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’è¡Œã„ã€äºˆæ¸¬æ€§èƒ½ã‚’è¦‹ã‚‹ã“ã¨ã§ã€Positional BiasãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚ã“ã®ã¨ãã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1923" target="_blank" rel="noopener noreferrer">Physics of Language Models: Part 3.1, Knowledge Storage and Extraction, Zeyuan Allen-Zhu+, ICML'24</a>
</strong>
<br>
 ã«å€£ã„ã€æ–‡æ›¸ã¨QAã‚’Mixed Samplingï¼ˆ1ãƒãƒƒãƒã‚ãŸã‚Š256ä»¶ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«QAãŠã‚ˆã³æ–‡æ›¸ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°; 
<strong># 1923 ã§ã¯æ–‡æ›¸ã¨QAã‚’2:8ã®æ¯”ç‡ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ã„ã‚‹ï¼‰ã™ã‚‹ã“ã¨ã§å­¦ç¿’ã‚’ã™ã‚‹ã€‚QAã®å ´åˆç›®çš„é–¢æ•°ã¯å›ç­”ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã®ã¿ã®NLLã€æ–‡æ›¸ã®å ´åˆã¯next-token prediction lossã‚’åˆ©ç”¨ã™ã‚‹ã€‚<br><br>Positional Biasã®å­˜åœ¨ã‚’ç¤ºã™ã ã‘ã§ãªãã€(A, B, C) ã®é †ç•ªã§next-token prediction lossã§å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€Cã®çŸ¥è­˜ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã«A, BãŒcontextã¨ã—ã¦å¿…è¦ã¨ãªã‚‹ãŸã‚ã€Cã‚’æŠ½å‡ºã™ã‚‹éš›ã®æ±åŒ–æ€§èƒ½ã‚’é«˜ã‚ã‚‹ãŸã‚ã«A, Bã®è¡¨ç¾ãŒã‚ˆã‚Šå¤šæ§˜ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ã€ã¨ã„ã†èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®ã„ãã¤ã‹ã®ã‚·ãƒ³ãƒ—ãƒ«ãªæ­£å‰‡åŒ–æ‰‹æ³•ã€å…·ä½“çš„ã«ã¯<br>- D-AR: predition targetã®ãƒˆãƒ¼ã‚¯ãƒ³ã¯ä¿æŒã—ãŸã¾ã¾ã€input tokenã®ä¸€éƒ¨ã‚’ãƒ©ãƒ³ãƒ€ãƒ ãªãƒˆãƒ¼ã‚¯ãƒ³ã«ç½®ãæ›ãˆã‚‹<br>- Shuffle: å…¥åŠ›æ–‡ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã™ã‚‹<br>- Attn Drop: self-attentionãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®attention weightã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«0ã«ã™ã‚‹<br>ã®3ç¨®é¡ã¨Positional Biasã®é–¢ä¿‚æ€§ã‚’æ¤œè¨¼ã—ã¦ã„ã‚‹ã€‚<br>![Image](https://github.com/user-attachments/assets/503e53f2-28f5-46ea-a11f-beee98f8fa38)<br><br>æ¤œè¨¼ã®çµæœã€ï¼ˆåˆæˆãƒ‡ãƒ¼ã‚¿ã€å®Ÿãƒ‡ãƒ¼ã‚¿ã¨ã‚‚ã«ï¼‰Positional BiasãŒå­˜åœ¨ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã¨ãªã‚Šï¼ˆi.e., æ­£è§£ãƒ†ã‚­ã‚¹ãƒˆãŒæ–‡æ›¸ä¸­ã®æ·±ã„ä½ç½®ã«ã‚ã‚Œã°ã‚ã‚‹ã»ã©äºˆæ¸¬æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ï¼‰æ­£å‰‡åŒ–ã«ã‚ˆã£ã¦Positional BiasãŒç·©å’Œã•ã‚Œã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚<br>![Image](https://github.com/user-attachments/assets/11a29a1e-f869-4628-9c47-e1fc9e5c394e)<br><br>ã¾ãŸã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§æ€§èƒ½ã‚’æ¯”è¼ƒã—ãŸã¨ã“ã‚ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’å¤§ããã™ã‚‹ã“ã¨ã§æ€§èƒ½è‡ªä½“ã¯æ”¹å–„ã™ã‚‹ãŒã€ä¾ç„¶ã¨ã—ã¦Positional BiasãŒå­˜åœ¨ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€ARã‚ˆã‚Šã‚‚D-ARãŒä¸€è²«ã—ã¦é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€Positional Biasã‚’ç·©å’Œã™ã‚‹ãŸã‚ã«ä½•ã‚‰ã‹ã®æ­£å‰‡åŒ–æ‰‹æ³•ãŒå¿…è¦ãªã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br>![Image](https://github.com/user-attachments/assets/0772d144-c22b-4723-8578-acdf0e2e1187)<br><br>ã¾ãŸã€ã‚ªãƒªã‚¸ãƒŠãƒ«æ–‡æ›¸ã®1æ–‡ç›®ã‚’ã€æ­£è§£ãƒ‡ãƒ¼ã‚¿ã®ä½ç½®ã‚’å…¥ã‚Œæ›¿ãˆãŸå„ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆä¸­ã®æ§˜ã€…ãªä½ç½®ã«é…ç½®ã—ã¦Perplexityã‚’æ¸¬ã£ãŸã€‚ã“ã®è¨­å®šã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒPerplexityã‚’æœ€å°åŒ–ã™ã‚‹ãŸã‚ã«ã¯ã€ï¼ˆ1æ–‡ç›®ã¨ã„ã†ã“ã¨ã¯ä»¥å‰ã®æ–‡è„ˆãŒå­˜åœ¨ã—ãªã„sentenceãªã®ã§ï¼‰æ–‡è„ˆã«ä¾å­˜ã›ãšã«æ–‡ã®è¨˜æ†¶ã—ã¦ã„ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚ã‚ˆã£ã¦ã€å„æ‰‹æ³•ã”ã¨ã«ã©ã®ç¨‹åº¦PerplexityãŒæ‚ªåŒ–ã™ã‚‹ã‹ã§ã€å„æ‰‹æ³•ãŒã©ã®ç¨‹åº¦ã‚ã‚‹sentenceã‚’è¨˜æ†¶ã™ã‚‹éš›ã«éå»ã®æ–‡è„ˆã«ä¾å­˜ã—ã¦ã„ã‚‹ã‹ãŒåˆ†ã‹ã‚‹ã€‚ã“ã“ã§ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãã®ã‚‚ã®ã®Perplexityã¯ã»ã¼1.0ã§ã‚ã£ãŸã“ã¨ã«æ³¨æ„ã™ã‚‹ã€‚<br>çµæœã¨ã—ã¦ã€æ–‡æ›¸ä¸­ã®æ·±ã„ä½ç½®ã«é…ç½®ã•ã‚Œã‚Œã°ã•ã‚Œã‚‹ã»ã©Perplexityã¯å¢—å¤§ã—ï¼ˆleftï¼‰ã€Autoregressive Model (AR) ã®Perplexityå€¤ãŒæœ€ã‚‚å€¤ãŒå¤§ãã‹ã£ãŸï¼ˆ=æ€§èƒ½ãŒæ‚ªã‹ã£ãŸï¼‰ã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€ARã¯ã‚ˆã‚Šéå»ã®æ–‡è„ˆã«ä¾å­˜ã—ã¦sentenceã®æƒ…å ±ã‚’è¨˜æ†¶ã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚ã¾ãŸã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã„ãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒPerplexityã¯å¢—å¤§ã™ã‚‹å‚¾å‘ã«ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸ (middle)ã€‚ã“ã‚Œã¯Fig.3ã§ç¤ºã—ãŸQAã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨å‚¾å‘ãŒä¸€è‡´ã—ã¦ãŠã‚Šã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãã®ã‚‚ã®ã®PerplexityãŒã»ã¼1.0ã ã£ãŸã“ã¨ã‚’é‘‘ã¿ã‚‹ã¨ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹Perplexityã¯æ§˜ã€…ãªPositionã«ä½ç½®ã™ã‚‹æƒ…å ±ã‚’é©åˆ‡ã«æŠ½å‡ºã§ãã‚‹èƒ½åŠ›ã‚’æ¸¬ã‚‹ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨ã—ã¦ã¯é©åˆ‡ã§ãªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚ã¾ãŸã€å­¦ç¿’ã®iterationã‚’å¢—ã‚„ã™ã¨ã€ARã®å ´åˆã¯first positionã«å¯¾ã™ã‚‹æŠ½å‡ºæ€§èƒ½ã¯æ”¹å–„ã—ãŸãŒã€ä»–ã®positionã§ã®æŠ½å‡ºæ€§èƒ½ã¯æ”¹å–„ã—ãªã‹ã£ãŸã€‚ä¸€æ–¹ã€D-ARã®å ´åˆã¯ã€å…¨ã¦ã®positionã§ã®æŠ½å‡ºæ€§èƒ½ãŒæ”¹å–„ã—ãŸ (right) ã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€å¿…ãšã—ã‚‚å­¦ç¿’ã®iterationã‚’å¢—ã‚„ã—ã¦ã‚‚æ§˜ã€…ãªPositionã«å¯¾ã™ã‚‹æŠ½å‡ºæ€§èƒ½ãŒæ”¹å–„ã—ãªã„ã“ã¨ã€longer trainingã®æ©æµã‚’å¾—ã‚‹ãŸã‚ã«ã¯æ­£å‰‡åŒ–æ‰‹æ³•ã‚’åˆ©ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚<br><br>![Image](https://github.com/user-attachments/assets/94f635a5-68d5-478d-ab16-513e855fe054)<br>&lt;/p&gt;<p>## å®Ÿé¨“ &amp; å®Ÿé¨“çµæœ (unmodulated data)<br>Wiki2023+ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ä¸Šè¨˜ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›´ã‚’è¡Œã‚ãšã«ã€ãã®ã¾ã¾å­¦ç¿’ã‚’è¡Œã„ã€å„ä½ç½®ã”ã¨ã®QAã®æ€§èƒ½ã‚’æ¸¬å®šã—ãŸã¨ã“ã‚ã€ï¼ˆã™ã¹ã¦ãŒPositional Biasã®ãŸã‚ã¨ã¯èª¬æ˜ã§ããªã„ãŒï¼‰å›ç­”ãŒæ–‡æ›¸ä¸­ã®æ·±ã„ä½ç½®ã«ã‚ã‚‹å ´åˆã®æ€§èƒ½ãŒåŠ£åŒ–ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ãŸã€‚2--6ç•ªç›®ã®æ€§èƒ½ã®ä½ä¸‹ã¯ã€æœ€åˆã®æ–‡ã§ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªäº‹å®ŸãŒè¿°ã¹ã‚‰ã‚Œã€å¾ŒåŠã«ãªã‚Œã°ãªã‚‹ã»ã©ã‚ˆã‚Šè¤‡é›‘ãªäº‹å®ŸãŒè¿°ã¹ã‚‰ã‚Œã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨ãŒèµ·å› ã—ã¦æ€§èƒ½ã®ä½ä¸‹ã—ã¦ã„ã‚‹ã¨ã‹ã›ã¤ã‚’ãŸã¦ã¦ã„ã‚‹ã€‚ã¾ãŸã€unmodulated dataã®å ´åˆã§ã‚‚D-ARã¯ARã®æ€§èƒ½ã‚’æ”¹å–„ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã¨ãªã£ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„ã»ã©æ€§èƒ½ã¯æ”¹å–„ã™ã‚‹ãŒã€ä»¥å‰ã¨ã—ã¦æ–‡æ›¸ä¸­ã®æ·±ã„ä½ç½®ã«æ­£è§£ãŒã‚ã‚‹å ´åˆã«æ€§èƒ½ã¯åŠ£åŒ–ã™ã‚‹ã“ã¨ã‚‚ã‚ã‹ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/2f43ba8a-c54e-4523-b8f0-7cfc797d5a7e" alt="image" loading="lazy"><br><br>ã¾ãŸã€æ­£å‰‡åŒ–æ‰‹æ³•ã¯çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã•ã‚‰ã«æ€§èƒ½ãŒæ”¹å–„ã—ã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1923" target="_blank" rel="noopener noreferrer">Physics of Language Models: Part 3.1, Knowledge Storage and Extraction, Zeyuan Allen-Zhu+, ICML'24</a>
&lt;/strong&gt;
<br>
 ã«ç¤ºã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸­ã®è¡¨ç¾ã‚’å¤šæ§˜ã«ã—[^1]å­¦ç¿’ã—ãŸã¨ã“ã‚äºˆæ¸¬æ€§èƒ½ãŒæ”¹å–„ã—ã€æ­£å‰‡åŒ–æ‰‹æ³•ã¨ã‚‚è£œå®Œçš„ãªé–¢ä¿‚ã§ã‚ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚<br><img src="https://github.com/user-attachments/assets/e79415b1-28e2-47ab-b429-448412053d0b" alt="image" loading="lazy"><br><br>åŒ»ç™‚ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã‚‚å®Ÿé¨“ã—ãŸã¨ã“ã‚ã€æ­£å‰‡åŒ–æ‰‹æ³•ã‚’é©ç”¨ã—ãŸå ´åˆã«ARã‚ˆã‚Šã‚‚æ€§èƒ½ãŒä¸Šå›ã£ãŸã€‚æœ€å¾Œã«Wiki2023+ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦Openbookãªè¨­å®šã§ã€æ­£è§£ãŒå«ã¾ã‚Œã‚‹æ–‡æ›¸ã‚’LLMã®contextã¨ã—ã¦ä¸ãˆãŸå ´åˆï¼ˆi.e.,ã»ã¼å®Œç’§ãªretrieverãŒå­˜åœ¨ã™ã‚‹RAGã¨åŒç­‰ã®è¨­å®šã¨ã¿ãªã›ã‚‹ï¼‰ã€QAã®æ€§èƒ½ã¯90.6%ã«å¯¾ã—ã€ç¶™ç¶šå­¦ç¿’ã—ãŸå ´åˆã®ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¯50.8%ã ã£ãŸã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€æ­£ç¢ºãªretrieverãŒå­˜åœ¨ã™ã‚‹ã®ã§ã‚ã‚Œã°ã€ç¶™ç¶šå­¦ç¿’ã‚ˆã‚Šã‚‚RAGã®æ–¹ãŒQAã®æ€§èƒ½ãŒé«˜ã„ã¨è¨€ãˆã‚‹ã€‚<br>RAGã¨ç¶™ç¶šå­¦ç¿’ã®ãƒ¡ãƒªãƒƒãƒˆã€ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã®ä¸¡æ–¹ã‚’è€ƒæ…®ã—ã¦ã€é©åˆ‡ã«æ‰‹æ³•ã‚’é¸æŠã™ã‚‹ã“ã¨ãŒæœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/14180452-5421-4102-8751-fabc8b780d49" alt="image" loading="lazy"><br><br>[^1]: ChatGPTã«ã‚ˆã£ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’rephraseã—ã€sentenceã®orderã‚‚å¤‰æ›´ã™ã‚‹ã“ã¨ã§å¤šæ§˜æ€§ã‚’å¢—ã‚„ã—ãŸã€‚ãŒã€sentence orderãŒæ–‡æ›¸ä¸­ã®æ·±ã„ä½ç½®ã«ã‚ã‚‹å ´åˆã«ã‚ã¾ã‚ŠorderãŒå¤‰åŒ–ã—ãªã‹ã£ãŸã‚ˆã†ã§ã€ã“ã®ãŸã‚æ·±ã„ä½ç½®ã«å¯¾ã™ã‚‹QAã®æ€§èƒ½æ”¹å–„ãŒé™å®šçš„ã«ãªã£ã¦ã„ã‚‹ã¨èª¬æ˜ã—ã¦ã„ã‚‹ã€‚</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1918" target="_blank" rel="noopener noreferrer" class="title-link">When More is Less: Understanding Chain-of-Thought Length in LLMs, Yuyang Wu+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- Chain-of-thought (CoT)æ¨è«–ã¯ã€LLMsã®å¤šæ®µéšæ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€CoTã®é•·ã•ãŒå¢—ã™ã¨æœ€åˆã¯æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã‚‚ã®ã®ã€æœ€çµ‚çš„ã«ã¯ä½ä¸‹ã™ã‚‹ã“ã¨ãŒè¦³å¯Ÿã•ã‚Œã‚‹ã€‚é•·ã„æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ãŒãƒã‚¤ã‚ºã«è„†å¼±ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ç†è«–çš„ã«æœ€é©ãªCoTã®é•·ã•ã‚’å°å‡ºã€‚Length-filtered Voteã‚’ææ¡ˆã—ã€CoTã®é•·ã•ã‚’ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã¨ã‚¿ã‚¹ã‚¯ã®è¦æ±‚ã«åˆã‚ã›ã¦èª¿æ•´ã™ã‚‹å¿…è¦æ€§ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>ICLR 2025 Best Paper Runner Up Award<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yifeiwang77/status/1916873981979660436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span></strong></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1917" target="_blank" rel="noopener noreferrer" class="title-link">AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models, Junfeng Fang+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- AlphaEditã¯ã€LLMsã®çŸ¥è­˜ã‚’ä¿æŒã—ã¤ã¤ç·¨é›†ã‚’è¡Œã†æ–°ã—ã„æ‰‹æ³•ã§ã€æ‘‚å‹•ã‚’ä¿æŒã•ã‚ŒãŸçŸ¥è­˜ã®é›¶ç©ºé–“ã«æŠ•å½±ã™ã‚‹ã“ã¨ã§ã€å…ƒã®çŸ¥è­˜ã‚’ç ´å£Šã™ã‚‹å•é¡Œã‚’è»½æ¸›ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€AlphaEditã¯å¾“æ¥ã®ä½ç½®ç‰¹å®š-ç·¨é›†æ‰‹æ³•ã®æ€§èƒ½ã‚’å¹³å‡36.7%å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1917343444810489925?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=HvSytvg3Jh" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=HvSytvg3Jh</a>


</p>
<p>MLPã«æ–°ãŸãªçŸ¥è­˜ã‚’ç›´æ¥æ³¨å…¥ã™ã‚‹éš›ã«ï¼ˆâ‰ contextã«å«ã‚ã‚‹ï¼‰æ—¢å­˜ã®å­¦ç¿’æ¸ˆã¿ã®çŸ¥è­˜ã‚’ç ´å£Šã›ãšã«æ³¨å…¥ã™ã‚‹æ‰‹æ³•ï¼ˆç ´å£Šã—ãªã„ã“ã¨ãŒä¿è¨¼ã•ã‚Œã¦ã„ã‚‹ï¼‰ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã‚‰ã—ã„</p>
<p>å°†æ¥çš„ã«ã¯ã€LLMã®1ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚ãŸã‚Šã«ä¿æŒã§ãã‚‹çŸ¥è­˜é‡ãŒã‚ã‹ã£ã¦ãã¦ã„ã‚‹ã®ã§ã€MLPã®é›¶ç©ºé–“ãŒN GBã®ãƒ¢ãƒ‡ãƒ«ã§ã™ã€ã‚ãªãŸãŒæ³¨å…¥ã—ãŸã„ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã®é‡ã«å¿œã˜ã¦é©åˆ‡ãªé›¶ç©ºé–“ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã‚“ã§ãã ã•ã„ã€ã¿ãŸã„ãªãƒ¢ãƒ‡ãƒ«ãŒå…¬é–‹ã•ã‚Œã‚‹æ—¥ãŒæ¥ã‚‹ã®ã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1916" target="_blank" rel="noopener noreferrer" class="title-link">Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and  Datasets, Lorenz Brehme+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RAGã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡æ‰‹æ³•ã‚’63ä»¶ã®è«–æ–‡ã‚’åŸºã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã€ã‚¤ãƒ³ãƒ‡ã‚¯ã‚·ãƒ³ã‚°ã€ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®4é ˜åŸŸã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã€‚è‡ªå‹•è©•ä¾¡ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å®Ÿç¾å¯èƒ½æ€§ã‚’è¦³å¯Ÿã—ã€LLMã‚’æ´»ç”¨ã—ãŸè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç”Ÿæˆã‚’ææ¡ˆã€‚ä¼æ¥­å‘ã‘ã«å®Ÿè£…ã¨è©•ä¾¡ã®æŒ‡é‡ã‚’æä¾›ã™ã‚‹ãŸã‚ã®å®Ÿè·µçš„ç ”ç©¶ã®å¿…è¦æ€§ã‚’å¼·èª¿ã—ã€è©•ä¾¡æ‰‹æ³•ã®é€²å±•ã¨ä¿¡é ¼æ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1917425829233189027?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãŠã‚‚ã—ã‚ãã†</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2025-04-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1910" target="_blank" rel="noopener noreferrer" class="title-link">Generative Product Recommendations for Implicit Superlative Queries, Kaustubh D. Dhole+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ›–æ˜§ãªã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ç”¨ã„ã¦æš—é»™ã®å±æ€§ã‚’ç”Ÿæˆã—ã€è£½å“æ¨è–¦ã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•ã‚’æ¢ã‚‹ã€‚æ–°ãŸã«ææ¡ˆã™ã‚‹4ãƒã‚¤ãƒ³ãƒˆã‚¹ã‚­ãƒ¼ãƒã€ŒSUPERBã€ã‚’ç”¨ã„ã¦æœ€ä¸Šç´šã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹è£½å“å€™è£œã‚’æ³¨é‡ˆä»˜ã‘ã—ã€æ—¢å­˜ã®æ¤œç´¢ãŠã‚ˆã³ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ‰‹æ³•ã‚’è©•ä¾¡ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1917084325499273671?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<span class="issue_date">Issue Date: 2025-04-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1898" target="_blank" rel="noopener noreferrer" class="title-link">BitNet b1.58 2B4T Technical Report, Shuming Ma+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- BitNet b1.58 2B4Tã¯ã€20å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®1ãƒ“ãƒƒãƒˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€4å…†ãƒˆãƒ¼ã‚¯ãƒ³ã§è¨“ç·´ã•ã‚Œã¾ã—ãŸã€‚è¨€èªç†è§£ã‚„æ•°å­¦çš„æ¨è«–ãªã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§è©•ä¾¡ã•ã‚Œã€åŒã‚µã‚¤ã‚ºã®ãƒ•ãƒ«ãƒ—ãƒ¬ã‚·ã‚¸ãƒ§ãƒ³LLMã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ã¤ã¤ã€è¨ˆç®—åŠ¹ç‡ãŒå‘ä¸Šã—ã¦ã„ã¾ã™ã€‚ãƒ¡ãƒ¢ãƒªã€ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ã€ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒå‰Šæ¸›ã•ã‚Œã€ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã¯Hugging Faceã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1912783876365177235?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>åœ§å€’çš„çœãƒ¡ãƒ¢ãƒªã‹ã¤cpuã§ã®inferenceé€Ÿåº¦ã‚‚æ—©ãã†<br><img src="https://github.com/user-attachments/assets/dacf05e4-9cb3-48b4-9a98-532f7245eb8e" alt="image" loading="lazy"></p>
<p>- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯Transformerã‚’åˆ©ç”¨<br>- Linear layerã¨ã—ã¦BitLinear Layerã‚’åˆ©ç”¨<br>  - é‡ã¿ã¯{1, 0, -1}ã®3å€¤ã‚’ã¨ã‚‹<br>  - activationã¯8bitã®integerã«é‡å­åŒ–<br>  - Layer Normalizationã¯subln normalization <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1899" target="_blank" rel="noopener noreferrer">Foundation Transformers, Hongyu Wang+, PMLR'23</a>
 ã‚’åˆ©ç”¨</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<span class="issue_date">Issue Date: 2025-04-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1897" target="_blank" rel="noopener noreferrer" class="title-link">AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents, Christopher Rawles+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€116ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦å ±é…¬ä¿¡å·ã‚’æä¾›ã™ã‚‹ã€ŒAndroidWorldã€ã¨ã„ã†å®Œå…¨ãªAndroidç’°å¢ƒã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è‡ªç„¶è¨€èªã§è¡¨ç¾ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’å‹•çš„ã«æ§‹ç¯‰ã—ã€ç¾å®Ÿçš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿç¾ã€‚åˆæœŸçµæœã§ã¯ã€æœ€è‰¯ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒ30.6%ã®ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†ã—ã€ã•ã‚‰ãªã‚‹ç ”ç©¶ã®ä½™åœ°ãŒç¤ºã•ã‚ŒãŸã€‚ã¾ãŸã€ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—Webã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®Androidé©å¿œãŒåŠ¹æœè–„ã§ã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿç¾ã«ã¯ã•ã‚‰ãªã‚‹ç ”ç©¶ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚ŒãŸã€‚ã‚¿ã‚¹ã‚¯ã®å¤‰å‹•ãŒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚‚ç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Androidç’°å¢ƒã§ã®Phone Useã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-04-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1893" target="_blank" rel="noopener noreferrer" class="title-link">d1: Scaling Reasoning in Diffusion Large Language Models via  Reinforcement Learning, Siyan Zhao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- d1ã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ãƒã‚¹ã‚¯ä»˜ãdLLMsã‚’æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å¼·åŒ–å­¦ç¿’ã§æ¨è«–ãƒ¢ãƒ‡ãƒ«ã«é©å¿œã€‚ãƒã‚¹ã‚¯ä»˜ãSFTæŠ€è¡“ã§çŸ¥è­˜ã‚’æŠ½å‡ºã—ã€diffu-GRPOã¨ã„ã†æ–°ã—ã„RLã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å°å…¥ã€‚å®Ÿè¨¼ç ”ç©¶ã«ã‚ˆã‚Šã€d1ãŒæœ€å…ˆç«¯ã®dLLMã®æ€§èƒ½ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1912785180504535121?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>dLLMã«å¯¾ã—ã¦GRPOã‚’é©ç”¨ã™ã‚‹æ‰‹æ³•(diffuGRPO)ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br>long CoTãƒ‡ãƒ¼ã‚¿ã§SFTã—ã¦reasoning capabilityã‚’å¼·åŒ–ã—ãŸå¾Œã€diffuGRPOã§è¿½åŠ ã®post-trainingã‚’ã—ã¦ã•ã‚‰ã«æ€§èƒ½ã‚’boostã™ã‚‹ã€‚</p>
<p>GRPOã§ã¯token levelã®å°¤åº¦ã¨sequenceå…¨ä½“ã®å°¤åº¦ã‚’è¨ˆç®—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŒã€dLLMã ã¨autoregressive modelã®ã‚ˆã†ã«chain ruleã‚’é©ç”¨ã™ã‚‹è¨ˆç®—æ–¹æ³•ã¯ã§ããªã„ã®ã§ã€åŠ¹ç‡çš„ã«å°¤åº¦ã‚’æ¨å®šã™ã‚‹estimatorã‚’ç”¨ã„ã¦GPPOã‚’é©ç”¨ã™ã‚‹diffuGRPOã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br>diffuGRPOå˜ä½“ã§ã‚‚ã€8Bãƒ¢ãƒ‡ãƒ«ã ãŒSFTã‚ˆã‚Šã‚‚æ€§èƒ½å‘ä¸Šã«æˆåŠŸã—ã¦ã„ã‚‹ã€‚SFTã®å¾Œã«diffuGRPOã‚’é©ç”¨ã™ã‚‹ã¨ã•ã‚‰ã«æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã€‚<br><br>SFTã§ã¯s1 <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1749" target="_blank" rel="noopener noreferrer">s1: Simple test-time scaling, Niklas Muennighoff+, arXiv'25</a>
 ã§ç”¨ã„ã‚‰ã‚ŒãŸlong CoTãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚ã—ã£ã‹ã‚Šç†è§£ã§ãã¦ã„ãªã„ãŒã€diffuGRPO+verified rewardã«ã‚ˆã£ã¦ã€long CoTã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãªãã¦ã‚‚ã€å®‰å®šã—ã¦reasoningèƒ½åŠ›ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒã§ãã‚ˆã†ã«ãªã£ãŸã€ã¨ã„ã†ã“ã¨ãªã®ã ã‚ã†ã‹ï¼Ÿ<br>ã—ã‹ã—ã€AppendixCã‚’è¦‹ã‚‹ã¨ã€å…ƒã€…ã®LLaDAã®æ™‚ç‚¹ã§reasoning traceã‚’ååˆ†ãªé•·ã•ã§å‡ºåŠ›ã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ã‚‚ã—LLaDAãŒå…ƒã€…long CoTã‚’ç™ºæ®ã§ããŸã®ã ã¨ã—ãŸã‚‰ã€long CoTã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã¯diffuGRPOã ã‘ã®æ©æµã§ã¯ãªã„ã¨ã„ã†ã“ã¨ã«ãªã‚Šãã†ã ãŒã€LLaDAã¯å…ƒã€…long CoTã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã ã£ãŸã‚“ã ã£ã‘â€¦ï¼Ÿãã®è¾ºè¿½ãˆã¦ãªã„ï¼ˆdLLMãŒãƒ¡ã‚¸ãƒ£ãƒ¼ã«ãªã£ãŸã‚‰è¿½ã†ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/Repetition.html" target="_blank" rel="noopener noreferrer">#Repetition</a>
<span class="issue_date">Issue Date: 2025-04-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1892" target="_blank" rel="noopener noreferrer" class="title-link">Learning Dynamics of LLM Finetuning, Yi Ren+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã®å­¦ç¿’ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’åˆ†æã—ã€ç•°ãªã‚‹å¿œç­”é–“ã®å½±éŸ¿ã®è“„ç©ã‚’æ®µéšçš„ã«è§£æ˜ã—ã¾ã™ã€‚æŒ‡ç¤ºèª¿æ•´ã¨å¥½ã¿èª¿æ•´ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«é–¢ã™ã‚‹è¦³å¯Ÿã‚’çµ±ä¸€çš„ã«è§£é‡ˆã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®å¹»è¦šå¼·åŒ–ã®ç†ç”±ã‚’ä»®èª¬çš„ã«èª¬æ˜ã—ã¾ã™ã€‚ã¾ãŸã€ã‚ªãƒ•ãƒãƒªã‚·ãƒ¼ç›´æ¥å¥½ã¿æœ€é©åŒ–ï¼ˆDPOï¼‰ã«ãŠã‘ã‚‹ã€Œåœ§ç¸®åŠ¹æœã€ã‚’å¼·èª¿ã—ã€æœ›ã¾ã—ã„å‡ºåŠ›ã®å¯èƒ½æ€§ãŒä½ä¸‹ã™ã‚‹ç¾è±¡ã‚’æ¢ã‚Šã¾ã™ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç†è§£ã«æ–°ãŸãªè¦–ç‚¹ã‚’æä¾›ã—ã€ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆæ€§èƒ½å‘ä¸Šã®ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ãªæ–¹æ³•ã‚’ç¤ºå”†ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/joshuarenyi/status/1913033476275925414?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1917189793588613299?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/In-Depth%20Notes.html" target="_blank" rel="noopener noreferrer">#In-Depth Notes</a>
<span class="issue_date">Issue Date: 2025-04-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1887" target="_blank" rel="noopener noreferrer" class="title-link">A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths   to Reproducibility, Andreas Hochlehnert+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¨è«–ã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã®é‡è¦ãªèª²é¡Œã§ã‚ã‚Šã€é€²å±•ãŒè¦‹ã‚‰ã‚Œã‚‹ãŒã€è©•ä¾¡æ‰‹æ³•ã«ã¯é€æ˜æ€§ã‚„å …ç‰¢æ€§ãŒæ¬ ã‘ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ•°å­¦çš„æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒå®Ÿè£…ã®é¸æŠã«æ•æ„Ÿã§ã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã€æ¨™æº–åŒ–ã•ã‚ŒãŸè©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚å†è©•ä¾¡ã®çµæœã€å¼·åŒ–å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯æ”¹å–„ãŒå°‘ãªãã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã¯å¼·ã„ä¸€èˆ¬åŒ–ã‚’ç¤ºã—ãŸã€‚å†ç¾æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã€é–¢é€£ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚„ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã—ã€ä»Šå¾Œã®ç ”ç©¶ã®åŸºç›¤ã‚’ç¯‰ãã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1911143014258405420?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>SLMã‚’math reasoningå‘ã‘ã«post-trainingã™ã‚‹å ´åˆã€è©•ä¾¡ã®æ¡ä»¶ã‚’ãƒ•ã‚§ã‚¢ã«ã™ã‚‹ãŸã‚ã®æ§˜ã€…ãªå·¥å¤«ã‚’æ–½ã—è©•ä¾¡ã‚’ã—ãªãŠã—ãŸçµæœï¼ˆFigure1ã®ã‚ˆã†ã«æ€§èƒ½ãŒå¤‰åŒ–ã™ã‚‹æ§˜ã€…ãªè¦å› ãŒå­˜åœ¨ã™ã‚‹ï¼‰ã€RLï¼ˆæ—¢å­˜ç ”ç©¶ã§è©¦ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ï¼‰ã‚ˆã‚Šã‚‚ï¼ˆå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰rejection samplingã—ãŸreasoning traceã‚’ç”¨ã„ã¦ï¼‰SFTã‚’ã™ã‚‹æ–¹ãŒåŒç­‰ã‹æ€§èƒ½ãŒè‰¯ã(Table3)ã€çµå±€ã®ã¨ã“ã‚ï¼ˆãŠãã‚‰ãæ±åŒ–æ€§èƒ½ãŒä½ã„ã¨ã„ã†æ„å‘³ã§ï¼‰reliableã§ã¯ãªãã€ã‹ã¤ï¼ˆãŠãã‚‰ãå°è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã§ã†ã¾ãã„ã‹ãªã„ã¨ã„ã†æ„å‘³ã§ã®ï¼‰scalableã§ã¯ãªã„ã®ã§ã€reliableã‹ã¤scalableãªRLæ‰‹æ³•ãŒä¸è¶³ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚<br><br>â€» æœ¬è«–æ–‡ã§åˆ†æã•ã‚Œã¦ã„ã‚‹ã®ã¯&lt;=10Bä»¥ä¸‹ã®SLMã§ã‚ã‚‹ç‚¹ã«æ³¨æ„ã€‚10Bä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã§åŒã˜ã“ã¨ãŒè¨€ãˆã‚‹ã‹ã¯è‡ªæ˜ã§ã¯ãªã„ã€‚<br>â€» DAPO, VAPOãªã©ã«ã¤ã„ã¦ã‚‚åŒã˜ã“ã¨ãŒè¨€ãˆã‚‹ã‹ã‚‚è‡ªæ˜ã§ã¯ãªã„ã€‚<br>â€» DeepSeek-R1ã®technical reportã«ãŠã„ã¦ã€å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã«GRPOã‚’é©ç”¨ã—ã¦ã‚‚ã‚ã¾ã‚ŠåŠ¹æœãŒç„¡ã‹ã£ãŸã“ã¨ãŒæ—¢ã«å ±å‘Šã•ã‚Œã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/620017f1-b3f0-40c1-bf61-3b0b7a429ab4" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/321132c8-dad5-4aa1-9811-f032e3474135" alt="image" loading="lazy"><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1743" target="_blank" rel="noopener noreferrer">DeepSeek-R1ã®è«–æ–‡èª­ã‚“ã ï¼Ÿã€å‹‰å¼·ã«ãªã‚‹ã‚ˆã€‘ , asap, 2025.01</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
</p>
<p>å€‹ã€…ã®post-trainingã•ã‚ŒãŸRLãƒ¢ãƒ‡ãƒ«ãŒå…·ä½“çš„ã«ã©ã†ã„ã†è¨“ç·´ã‚’ã—ãŸã®ã‹ã¯è¿½ãˆã¦ã„ãªã„ãŒã€DAPOã‚„Dr. GRPO, VAPOã®å ´åˆã¯ã©ã†ãªã‚‹ã‚“ã ã‚ã†ã‹ï¼Ÿ<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1815" target="_blank" rel="noopener noreferrer">DAPO: An Open-Source LLM Reinforcement Learning System at Scale, Qiying Yu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1876" target="_blank" rel="noopener noreferrer">VAPO: Efficient and Reliable Reinforcement Learning for Advanced
  Reasoning Tasks, YuYue+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1821" target="_blank" rel="noopener noreferrer">Understanding R1-Zero-Like Training: A Critical Perspective, 2025.03</a>
<br><br>Rewardã®è¨­å®šã®ä»•æ–¹ã¯ã©ã®ã‚ˆã†ãªå½±éŸ¿ãŒã‚ã‚‹ã®ã ã‚ã†ã‹ï¼ˆverifiable rewardãªã®ã‹ã€neuralãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹rewardãªã®ã‹ãªã©)ï¼Ÿ<br><br>å­¦ç¿’ã®ã•ã›æ–¹ã‚‚ã©ã®ã‚ˆã†ãªå½±éŸ¿ãŒã‚ã‚‹ã®ã ã‚ã†ã‹ï¼ˆRLã§ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ learningã«ã—ãŸå ´åˆãªã©ï¼‰ï¼Ÿ<br><br>æ¤œè¨¼ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒãã‚Œãã‚Œã©ã®ã‚ˆã†ãªè¨­å®šã§å­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ã‹ã¾ã§ã‚’è¦‹ãªã„ã¨ã“ã®è¾ºã¯ã‚ã‹ã‚‰ãªãã†ã€‚<br><br>ãŸã ãªã‚“ã¨ãªãƒ¼ãã®ç›´æ„Ÿã ã¨ã€SLMã‚’è³¢ãã—ãŸã„ã¨ã„ã†å ´åˆã¯ä½•ã‚‰ã‹ã®è³¢ã„ãƒ¢ãƒ‡ãƒ«ã®æ©æµã«é ã‹ã‚‹ã¨æœ‰åˆ©ãªã‚±ãƒ¼ã‚¹ãŒå¤šãï¼ˆSFTã®å ´åˆã¯ãã‚ŒãŒå¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰è’¸ç•™ã—ãŸreasoning traceï¼‰ã€SLM+RLã®å ´åˆã¯PRMã®ã‚ˆã†ãªæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’è©•ä¾¡ã—ã¦Rewardã«åæ˜ ã•ã›ã‚‹ã‚ˆã†ãªã‚‚ã®ã‚’åˆ©ç”¨ã—ãªã„ã¨ã€å°‘ãªãã¨ã‚‚å°è¦æ¨¡ãªLLMã‚’ã‚ã¡ã‚ƒè³¢ãã—ã¾ã™ã€œã¨ã„ã†ã®ã¯ãã¤ã„ã‚“ã˜ã‚ƒãªã„ã‹ãªã‚ã¨ã„ã†æ„Ÿæƒ³ã§ã¯ã‚ã‚‹ã€‚<br>ãŸã ã€çµå±€SLMã¨ã„ã†æ™‚ç‚¹ã§å¤šãã®å ´åˆã€ã‚ˆã‚Šè³¢ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å¤šã„LLMãŒä¸–ã®ä¸­ã«ã¯å­˜åœ¨ã™ã‚‹ã‚ã‚‹ã¯ãšãªã®ã§ã€RLã—ãªã„ã§SFTã—ã¦è’¸ç•™ã™ã‚Œã°è‰¯ã„ã‚“ã˜ã‚ƒãªã„â€¦ï¼Ÿã¨æ€ã£ã¦ã—ã¾ã†ã€‚<br>ãŒã€å¤šãã®å ´åˆãã®è³¢ã„LLMã¯ProprietaryãªLLMã§ã‚ã‚Šã€å‡ºåŠ›ã‚’å¾—ã¦è‡ªåˆ†ã®ãƒ¢ãƒ‡ãƒ«ã‚’post-trainingã™ã‚‹ã“ã¨ã¯åˆ©ç”¨è¦ç´„é•åã¨ãªã‚‹ãŸã‚ã€è‡ªå‰ã§è³¢ãã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å¤šã„LLMã‚’ç”¨æ„ã§ããªã„å ´åˆã¯å›°ã£ã¦ã—ã¾ã†ã®ã§ã€SLMã‚’ã‚¯ã‚½ãƒ‡ã‚«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã®æ©æµãªã—ã§è¶…çµ¶è³¢ãã§ããŸã‚‰ä¸–ã®ä¸­ã®å¤šãã®äººã¯å¬‰ã—ã„ã‚ˆã­ã€ã¨ã‚‚æ€ã†ã€‚</p>
<p>ï¼ˆæ–œã‚èª­ã¿ã ãŒï¼‰<br>ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„ï¼ˆæ•°åä»¶ï¼‰AIMEã‚„AMCãªã©ã®ãƒ‡ãƒ¼ã‚¿ã¯seedã®å€¤ã«ã¨ã¦ã‚‚sensitiveã§ã‚ã‚Š(Takeaway1, 2)ã€<br><br>&lt;img width="549" height="256" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/97581133-cf17-4635-b66c-442eaf8956d4"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/97581133-cf17-4635-b66c-442eaf8956d4"&lt;/a&gt;


/&gt;<br><br>ãã‚Œã‚‰ã¯10ç¨®é¡ã®seedã‚’ç”¨ã„ã¦çµæœã‚’å¹³å‡ã™ã‚‹ã¨åˆ†æ•£ãŒéå¸¸ã«å°ã•ããªã‚‹ã®ã§ã€seedã¯è¤‡æ•°ç¨®é¡åˆ©ç”¨ã—ã¦å¹³å‡ã®æ€§èƒ½ã‚’è¦‹ãŸæ–¹ãŒreliableã§ã‚ã‚Š(Takeaway3)<br><br>&lt;img width="688" height="266" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/5065ef0e-de89-4b17-aa52-c90b7191e9b2"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/5065ef0e-de89-4b17-aa52-c90b7191e9b2"&lt;/a&gt;


/&gt;<br><br>temperatureã‚’é«˜ãã™ã‚‹ã¨ãƒ”ãƒ¼ã‚¯æ€§èƒ½ãŒä¸ŠãŒã‚‹ãŒåˆ†æ•£ã‚‚ä¸ŠãŒã‚‹ãŸã‚å†ç¾æ€§ã®èª²é¡ŒãŒå¢—å¤§ã™ã‚‹ãŒã€top-pã‚’å¤§ããã™ã‚‹ã¨å†ç¾æ€§ã®å•é¡Œã¯ç¾ã‚Œãšæ€§èƒ½å‘ä¸Šã«å¯„ä¸ã—<br><br>&lt;img width="545" height="508" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/76d5c989-edbb-4d70-9080-d1d4b01de2ff"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/76d5c989-edbb-4d70-9080-d1d4b01de2ff"&lt;/a&gt;


/&gt;<br><br>æ—¢å­˜ç ”ç©¶ã®ãƒ¢ãƒ‡ãƒ«ã®temperatureã¨top-pã‚’å¤‰åŒ–ã•ã›å®Ÿé¨“ã™ã‚‹ã¨performanceã«éå¸¸ã«å¤§ããªå¤‰åŒ–ãŒå‡ºã‚‹ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«æœ€é©ãªå€¤ã‚’é¸å®šã—ã¦æ¯”è¼ƒã‚’ã—ãªã„ã¨unfairã§ã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ (Takeaway4)ã€‚<br><br>&lt;img width="553" height="511" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/d8b453d1-3d2e-4a80-b03d-c69ec1b2232e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/d8b453d1-3d2e-4a80-b03d-c69ec1b2232e"&lt;/a&gt;


/&gt;<br><br>ã¾ãŸã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®é¢ã§ã¯ã€vLLMã®ã‚ˆã†ãªinference engineã¯GPU typeã‚„memoryã®configurationã«å¯¾ã—ã¦sensitiveã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤‰ã‚ã‚‹ã ã‘ã§ãªãã€<br><br>&lt;img width="689" height="356" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/a41891c7-072c-4c38-9ad6-beada4721bac"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a41891c7-072c-4c38-9ad6-beada4721bac"&lt;/a&gt;


/&gt;<br><br>è©•ä¾¡ã«åˆ©ç”¨ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã”ã¨ã«inference engineã¨prompt templateãŒç•°ãªã‚‹ãŸã‚ã“ã¡ã‚‰ã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ãŒå‡ºã‚‹ã— (Takeaway5)ã€<br><br>&lt;img width="275" height="115" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/1f7d328c-0757-47b9-9961-630e2429fb3e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/1f7d328c-0757-47b9-9961-630e2429fb3e"&lt;/a&gt;


/&gt;<br><br>max output tokenã®å€¤ã‚’å¤‰åŒ–ã•ã›ã‚‹ã¨æ€§èƒ½ã‚‚å¤‰ã‚ã‚Šã€prompt templateã‚’åˆ©ç”¨ã—ãªã„ã¨æ€§èƒ½ãŒåŠ‡çš„ã«ä½ä¸‹ã™ã‚‹ (Takeaway6)ã€‚<br><br>&lt;img width="681" height="577" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/dc0902d1-a5f2-47de-8df1-c28107e1da28"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/dc0902d1-a5f2-47de-8df1-c28107e1da28"&lt;/a&gt;


/&gt;<br><br>ã“ã‚Œã‚‰ã®ã“ã¨ã‹ã‚‰è‘—è€…ã‚‰ã¯reliableãªè©•ä¾¡ã®ãŸã‚ã«ä¸‹è¨˜ã‚’ææ¡ˆã—ã¦ãŠã‚Š (4.1ç¯€; å¾Œã»ã©è¿½è¨˜)ã€<br><br>å®Ÿéš›ã«ã•ã¾ã–ã¾ãªæ¡ä»¶ã‚’fair comparisonã¨ãªã‚‹ã‚ˆã†ã«æ¨™æº–åŒ–ã—ã¦è©•ä¾¡ã—ãŸã¨ã“ã‚ï¼ˆ4.2ç¯€; å¾Œã»ã©è¿½è¨˜ï¼‰<br><br>ä¸Šã®è¡¨ã®ã‚ˆã†ãªçµæœã¨ãªã£ãŸã€‚ã“ã®çµæœã¯ã€<br>- DeepSeekR1-Distilledã‚’RLã—ã¦ã‚‚SFTã¨æ¯”è¼ƒã—ãŸã¨ãã«æ„å‘³ã®ã‚ã‚‹ã»ã©ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å‘ä¸Šã¯ãªã„ã“ã¨ã‹ã‚‰ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã€ã‹ã¤ä¿¡é ¼æ€§ã®ã‚ã‚‹RLæ‰‹æ³•ãŒã¾ã ä¸è¶³ã—ã¦ãŠã‚Š<br>- å¤§è¦æ¨¡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã®reasoning traceã‹ã‚‰SFTã‚’ã™ã‚‹æ–¹æ³•ã¯ã•ã¾ã–ã¾ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãƒ­ãƒã‚¹ãƒˆãªæ€§èƒ½ï¼ˆï¼é«˜ã„æ±åŒ–æ€§èƒ½ï¼‰ã‚’æŒã¡ã€RLã¨æ¯”ã¹ã‚‹ã¨ç¾çŠ¶ã¯RLã¨æ¯”è¼ƒã—ã¦ã‚ˆã‚Šãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã¨ã—ã¦æˆç†Ÿã—ã¦ãŠã‚Š<br>- ï¼ˆAIME24,25ã‚’æ¯”è¼ƒã™ã‚‹ã¨SFTã¨æ¯”ã¹ã¦RLã®å ´åˆperformanceã®ä½ä¸‹ãŒè‘—ã—ã„ã®ã§ï¼‰RLã¯overfittingã—ã‚„ã™ãã€OODãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒå¿…è¦</p>
<p>ã—ã£ã‹ã‚Šã¨è©•ä¾¡ã®æ çµ„ã¿ã‚’æ¨™æº–åŒ–ã—ã¦fair comparisonã—ã¦ã„ã‹ãªã„ã¨ã€RecSysæ¥­ç•Œã®äºŒã®èˆã«ãªã‚Šãã†ï¼ˆã¨ã„ã†ã‹ã‚‚ã†ãªã£ã¦ã‚‹ï¼Ÿï¼‰ã€‚<br><br>ã¾ãŸã“ã®ç ”ç©¶ã§åˆ†æã•ã‚Œã¦ã„ã‚‹ã®ã¯å°è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ï¼ˆ&lt;=10Bï¼‰ã«å¯¾ã™ã‚‹æ—¢å­˜ç ”ç©¶ã§ç”¨ã„ã‚‰ã‚ŒãŸä¸€éƒ¨ã®RLæ‰‹æ³•ã‚„è¨­å®šã®æ€§èƒ½ã ã‘ï¼ˆçœŸã«ç¤ºã—ãŸã‹ã£ãŸã‚‰Phisics of LLMã®ã‚ˆã†ãªå®Œå…¨ã«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«å¯èƒ½ãªã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã§å®Ÿé¨“ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã¨æ€ã‚ã‚Œã‚‹ï¼‰ãªã®ã§ã€DeepSeek-R1ã®ã‚ˆã†ã«ã€å¤§è¦æ¨¡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ•°ç™¾Bï¼‰ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹RLã«é–¢ã—ã¦åŒã˜ã“ã¨ãŒè¨€ãˆã‚‹ã‹ã¯è‡ªæ˜ã§ã¯ãªã„ç‚¹ã«æ³¨æ„ã€‚</p>
<p>openreview:


<a href="https://openreview.net/forum?id=90UrTTxp5O#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=90UrTTxp5O#discussion</a>


</p>
<p>æœ€è¿‘ã®ä»¥ä¸‹ã®ã‚ˆã†ãªSFTã¯RLã®ä¸€ã¤ã®ã‚±ãƒ¼ã‚¹ã¨è¦‹åšã›ã‚‹ã¨ã„ã†è­°è«–ã‚’è¸ã¾ãˆã‚‹ã¨ã©ã†ãªã‚‹ã ã‚ã†ã‹<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2700" target="_blank" rel="noopener noreferrer">[Paper Note] Towards a Unified View of Large Language Model Post-Training, Xingtai Lv+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2025-04-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1882" target="_blank" rel="noopener noreferrer" class="title-link">Hallucination Mitigation using Agentic AI Natural Language-Based  Frameworks, Diego Gosmar+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¤‡æ•°ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’èª¿æ•´ã—ã€è‡ªç„¶è¨€èªå‡¦ç†ã‚’æ´»ç”¨ã—ã¦å¹»è¦šã‚’è»½æ¸›ã™ã‚‹æ–¹æ³•ã‚’æ¢æ±‚ã€‚300ä»¥ä¸Šã®å¹»è¦šã‚’èª˜ç™ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”¨ã„ãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’è¨­è¨ˆã—ã€å‡ºåŠ›ã‚’ç¬¬äºŒãŠã‚ˆã³ç¬¬ä¸‰ãƒ¬ãƒ™ãƒ«ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‚æ–°ãŸã«è¨­è¨ˆã—ãŸKPIã§å¹»è¦šã‚¹ã‚³ã‚¢ã‚’è©•ä¾¡ã—ã€OVONãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é€šã˜ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã§æ–‡è„ˆæƒ…å ±ã‚’è»¢é€ã€‚çµæœã¨ã—ã¦ã€ç›¸äº’é‹ç”¨å¯èƒ½ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§å¹»è¦šã®è»½æ¸›ã«æˆåŠŸã—ã€AIã¸ã®ä¿¡é ¼ã‚’å¼·åŒ–ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lioronai/status/1910384805625135342?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<span class="issue_date">Issue Date: 2025-04-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1878" target="_blank" rel="noopener noreferrer" class="title-link">Using Attention Sinks to Identify and Evaluate Dormant Heads in  Pretrained LLMs, Pedro Sandoval-Segura+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹ã€Œä¼‘çœ ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ‰ã€ã‚’å®šç¾©ã—ã€ãã®å½±éŸ¿ã‚’èª¿æŸ»ã€‚6ã¤ã®ãƒ¢ãƒ‡ãƒ«ã¨5ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã€ä¼‘çœ ãƒ˜ãƒƒãƒ‰ã®å‡ºåŠ›ã‚’ã‚¼ãƒ­ã«ã—ã¦ã‚‚ç²¾åº¦ã‚’ç¶­æŒã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã€‚ä¼‘çœ ãƒ˜ãƒƒãƒ‰ã¯äº‹å‰å­¦ç¿’ã®åˆæœŸã«å‡ºç¾ã—ã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ç‰¹æ€§ã«ä¾å­˜ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/psandovalsegura/status/1909652533334712691?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2025-04-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1876" target="_blank" rel="noopener noreferrer" class="title-link">VAPO: Efficient and Reliable Reinforcement Learning for Advanced  Reasoning Tasks, YuYue+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- VAPOï¼ˆValue-based Augmented Proximal Policy Optimization frameworkï¼‰ã‚’ææ¡ˆã—ã€AIME 2024ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æœ€å…ˆç«¯ã®ã‚¹ã‚³ã‚¢60.4ã‚’é”æˆã€‚VAPOã¯ä»–ã®æ‰‹æ³•ã‚’10ãƒã‚¤ãƒ³ãƒˆä»¥ä¸Šä¸Šå›ã‚Šã€5,000ã‚¹ãƒ†ãƒƒãƒ—ã§å®‰å®šã—ãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã€‚ä¾¡å€¤ãƒ™ãƒ¼ã‚¹ã®å¼·åŒ–å­¦ç¿’ã«ãŠã‘ã‚‹3ã¤ã®èª²é¡Œã‚’ç‰¹å®šã—ã€VAPOãŒãã‚Œã‚‰ã‚’è»½æ¸›ã™ã‚‹çµ±åˆã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã™ã‚‹ã“ã¨ã§ã€é•·ã„æ€è€ƒéç¨‹ã®æ¨è«–ã‚¿ã‚¹ã‚¯ã®æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>åŒã˜ãByteDanceã®<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1815" target="_blank" rel="noopener noreferrer">DAPO: An Open-Source LLM Reinforcement Learning System at Scale, Qiying Yu+, arXiv'25</a>
<br><br>ã‚’ä¸Šå›ã‚‹æ€§èƒ½<br><img src="https://github.com/user-attachments/assets/51f7a43a-9410-45f3-989c-4e0b1fdd86ef" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1909564500170223751?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1871" target="_blank" rel="noopener noreferrer" class="title-link">KAA: Kolmogorov-Arnold Attention for Enhancing Attentive Graph Neural  Networks, Taoran Fang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ³¨æ„GNNã«ãŠã‘ã‚‹ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã®ç†è§£ãŒä¸è¶³ã—ã¦ã„ã‚‹ä¸­ã€æœ¬ç ”ç©¶ã§ã¯ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ãƒ»ã‚¢ãƒ«ãƒãƒ«ãƒ‰æ³¨æ„ï¼ˆKAAï¼‰ã‚’ææ¡ˆã—ã€ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é–¢æ•°ã‚’çµ±ä¸€ã€‚KAAã¯KANã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’çµ±åˆã—ã€ã»ã¼ã™ã¹ã¦ã®æ³¨æ„GNNã«é©ç”¨å¯èƒ½ã§ã€è¡¨ç¾åŠ›ãŒå‘ä¸Šã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€KAAå¼·åŒ–ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é–¢æ•°ãŒå…ƒã®ã‚‚ã®ã‚’ä¸€è²«ã—ã¦ä¸Šå›ã‚Šã€æœ€å¤§20%ä»¥ä¸Šã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1908966571227398449?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1870" target="_blank" rel="noopener noreferrer" class="title-link">XAttention: Block Sparse Attention with Antidiagonal Scoring, Ruyi Xu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- XAttentionã¯ã€Long-Context Transformer Modelsã«ãŠã‘ã‚‹é•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¨è«–ã‚’åŠ é€Ÿã™ã‚‹ãƒ—ãƒ©ã‚°ã‚¢ãƒ³ãƒ‰ãƒ—ãƒ¬ã‚¤ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€æ³¨æ„è¡Œåˆ—ã®åå¯¾å¯¾è§’ç·šã®å€¤ã‚’ç”¨ã„ã¦ãƒ–ãƒ­ãƒƒã‚¯ã®é‡è¦åº¦ã‚’è©•ä¾¡ã—ã€éæœ¬è³ªçš„ãªãƒ–ãƒ­ãƒƒã‚¯ã‚’å‰ªå®šã™ã‚‹ã“ã¨ã§é«˜ã„ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã‚’å®Ÿç¾ã€‚RULERã‚„LongBenchãªã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãƒ•ãƒ«ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã«åŒ¹æ•µã™ã‚‹ç²¾åº¦ã‚’ä¿ã¡ãªãŒã‚‰ã€æœ€å¤§13.5å€ã®è¨ˆç®—åŠ é€Ÿã‚’é”æˆã€‚XAttentionã¯LCTMsã®åŠ¹ç‡çš„ãªå±•é–‹ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1908966571227398449?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1869" target="_blank" rel="noopener noreferrer" class="title-link">Slim attention: cut your context memory in half without loss of accuracy  -- K-cache is all you need for MHA, Nils Graef+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Slim attentionã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã®MHAã«ãŠã„ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒ¢ãƒªã‚’2å€ã«ç¸®å°ã—ã€æ¨è«–é€Ÿåº¦ã‚’æœ€å¤§2å€å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã§ã€ç²¾åº¦ã‚’æãªã†ã“ã¨ãªãå®Ÿè£…å¯èƒ½ã§ã™ã€‚ç‰¹ã«ã€Whisperãƒ¢ãƒ‡ãƒ«ã§ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒ¢ãƒªã‚’8å€å‰Šæ¸›ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆã‚’5å€é€Ÿãã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã¾ãŸã€ç¨€ãªã‚±ãƒ¼ã‚¹ã§ã¯T5-11Bãƒ¢ãƒ‡ãƒ«ã§ãƒ¡ãƒ¢ãƒªã‚’32å€å‰Šæ¸›ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1908966571227398449?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<span class="issue_date">Issue Date: 2025-04-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1867" target="_blank" rel="noopener noreferrer" class="title-link">CREAM: Consistency Regularized Self-Rewarding Language Models, Zhaoyang Wang+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±å ±é…¬å‹LLMã¯ã€LLM-as-a-Judgeã‚’ç”¨ã„ã¦ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆæ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€å ±é…¬ã¨ãƒ©ãƒ³ã‚¯ä»˜ã‘ã®æ­£ç¢ºæ€§ãŒå•é¡Œã€‚å°è¦æ¨¡LLMã®å®Ÿè¨¼çµæœã¯ã€è‡ªå·±å ±é…¬ã®æ”¹å–„ãŒåå¾©å¾Œã«æ¸›å°‘ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ä¸€èˆ¬åŒ–ã•ã‚ŒãŸåå¾©çš„å¥½ã¿ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’å®šå¼åŒ–ã—ã€æ­£å‰‡åŒ–ã‚’å°å…¥ã€‚CREAMã‚’ææ¡ˆã—ã€å ±é…¬ã®ä¸€è²«æ€§ã‚’æ´»ç”¨ã—ã¦ä¿¡é ¼æ€§ã®é«˜ã„å¥½ã¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’ã€‚å®Ÿè¨¼çµæœã¯CREAMã®å„ªä½æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1212" target="_blank" rel="noopener noreferrer">Self-Rewarding Language Models, Weizhe Yuan+, N/A, ICML'24</a>
<br><br>ã‚’æ”¹å–„ã—ãŸç ”ç©¶</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=Vf6RDObyEF" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Vf6RDObyEF</a>


</p>
<p>ã“ã®æ–¹å‘æ€§ã®ç ”ç©¶ã¯ãŠã‚‚ã—ã‚ã„</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-04-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1862" target="_blank" rel="noopener noreferrer" class="title-link">When Attention Sink Emerges in Language Models: An Empirical View, Xiangming Gu+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹ã€Œã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã€ã¯ã€æ„å‘³çš„ã«é‡è¦ã§ãªã„ãƒˆãƒ¼ã‚¯ãƒ³ã«å¤§ããªæ³¨æ„ã‚’å‰²ã‚Šå½“ã¦ã‚‹ç¾è±¡ã§ã‚ã‚Šã€ã•ã¾ã–ã¾ãªå…¥åŠ›ã«å¯¾ã—ã¦å°ã•ãªãƒ¢ãƒ‡ãƒ«ã§ã‚‚æ™®éçš„ã«å­˜åœ¨ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã¯äº‹å‰å­¦ç¿’ä¸­ã«å‡ºç¾ã—ã€æœ€é©åŒ–ã‚„ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã€æå¤±é–¢æ•°ãŒãã®å‡ºç¾ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã€‚ç‰¹ã«ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã¯ã‚­ãƒ¼ã®ãƒã‚¤ã‚¢ã‚¹ã®ã‚ˆã†ã«æ©Ÿèƒ½ã—ã€æƒ…å ±ã‚’æŒãŸãªã„è¿½åŠ ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã‚’ä¿å­˜ã™ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã“ã®ç¾è±¡ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³ãŒã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹æ­£è¦åŒ–ã«ä¾å­˜ã—ã¦ã„ã‚‹ã“ã¨ã‹ã‚‰éƒ¨åˆ†çš„ã«ç”Ÿã˜ã¦ãŠã‚Šã€æ­£è¦åŒ–ãªã—ã®ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã«ç½®ãæ›ãˆã‚‹ã“ã¨ã§ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã®å‡ºç¾ã‚’é˜²ãã“ã¨ãŒã§ãã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Sink Rateã¨å‘¼ã°ã‚Œã‚‹ã€å…¨ã¦ã®headã®First Tokenã«å¯¾ã™ã‚‹attention scoreã®ã†ã¡ï¼ˆlayer l * head hå€‹å­˜åœ¨ã™ã‚‹ï¼‰ã€ã©ã®ç¨‹åº¦ã®å‰²åˆã®ã‚¹ã‚³ã‚¢ãŒé–¾å€¤ã‚’ä¸Šå›ã£ã¦ã„ã‚‹ã‹ã‚’è¡¨ã™æŒ‡æ¨™ã‚’ææ¡ˆ<br>ï¼ˆå¾Œã»ã©è©³ç´°ã‚’è¿½è¨˜ã™ã‚‹ï¼‰</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1860" target="_blank" rel="noopener noreferrer">Why do LLMs attend to the first token?, Federico Barbero+, COLM'25</a>
<br><br>ã®å…ˆè¡Œç ”ç©¶</p>
<p>è‘—è€…ãƒã‚¹ãƒˆï¼ˆopenai-gpt-120Bã‚’å—ã‘ã¦):<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gu_xiangming/status/1952811057673642227?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>openreview:


<a href="https://openreview.net/forum?id=78Nn4QJTEN" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=78Nn4QJTEN</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-04-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1860" target="_blank" rel="noopener noreferrer" class="title-link">Why do LLMs attend to the first token?, Federico Barbero+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯æœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³ã«å¼·ãæ³¨æ„ã‚’å‘ã‘ã‚‹ã€Œã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã€ã‚’ç¤ºã—ã€ãã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒéå‰°æ··åˆã‚’é¿ã‘ã‚‹æ–¹æ³•ã‚’ç†è«–çš„ãƒ»å®Ÿè¨¼çš„ã«æ¢æ±‚ã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•ã‚„ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ãƒƒã‚­ãƒ³ã‚°ãŒã‚·ãƒ³ã‚¯ã®æŒ™å‹•ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’å®Ÿé¨“ã§ç¤ºã—ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç†è§£ã‚’æ·±ã‚ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1908187563422261411?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Attention Sinkã«ã‚ˆã£ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³ã®æƒ…å ±ãŒover-mixingã•ã‚Œã‚‹ã“ã¨ãŒæŠ‘åˆ¶ã•ã‚Œã€Decoder-only LLMã®æ·±ã„å±¤ã®representationãŒå‡ä¸€åŒ–ã•ã‚Œã‚‹ã“ã¨ã‚’æŠ‘åˆ¶ã™ã‚‹ï¼ˆï¼promptã®æ‘‚å‹•ã«ãƒ­ãƒã‚¹ãƒˆã«ãªã‚‹ï¼‰ã“ã¨ãŒç¤ºã•ã‚ŒãŸæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/8a1223c0-5621-42a5-accc-31fa7f636856" alt="image" loading="lazy"><br>Gemma7Bã«ãŠã„ã¦ã€promptä¸­ã®ãƒˆãƒ¼ã‚¯ãƒ³ä¸€èªã‚’ç½®æ›ã—ãŸå¾Œã«ã€Attention Sinkï¼ˆ<bos>ï¼‰ã®æœ‰ç„¡ã«ã‚ˆã£ã¦ã€tokenãƒ¬ãƒ™ãƒ«ã®representationã«å¯¾ã—ã¦ã©ã®ã‚ˆã†ãªæ‘‚å‹•ãŒã‚ã‚‹ã‹ã‚’layerã”ã¨ã«ã¾ã¨ã‚ãŸå›³ãŒä¸‹è¨˜ã®æ¨¡æ§˜ã€‚Attention Sinkã«ã‚ˆã£ã¦ã€tokenã®æ‘‚å‹•ãŒä»–ã®token, layerã«å¯¾ã—ã¦mixingã•ã‚Œã‚‹ã®ãŒæŠ‘åˆ¶ã•ã‚Œã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/b1a4038a-d116-4bd1-b27b-c55eb861bee9" alt="image" loading="lazy">&lt;/p&gt;<p>openreview:


<a href="https://openreview.net/forum?id=tu4dFUsW5z#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=tu4dFUsW5z#discussion</a>


</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ConceptErasure.html" target="_blank" rel="noopener noreferrer">#ConceptErasure</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<a class="button" href="articles/AISTATS.html" target="_blank" rel="noopener noreferrer">#AISTATS</a>
<span class="issue_date">Issue Date: 2025-04-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1859" target="_blank" rel="noopener noreferrer" class="title-link">Fundamental Limits of Perfect Concept Erasure, Somnath Basu Roy Chowdhury+, AISTATS'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¦‚å¿µæ¶ˆå»ã¯ã€æ€§åˆ¥ã‚„äººç¨®ãªã©ã®æƒ…å ±ã‚’æ¶ˆå»ã—ã¤ã¤å…ƒã®è¡¨ç¾ã‚’ä¿æŒã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã‚ã‚Šã€å…¬å¹³æ€§ã®é”æˆã‚„ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®è§£é‡ˆã«å½¹ç«‹ã¤ã€‚å¾“æ¥ã®æŠ€è¡“ã¯æ¶ˆå»ã®å …ç‰¢æ€§ã‚’é‡è¦–ã—ã¦ããŸãŒã€æœ‰ç”¨æ€§ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒå­˜åœ¨ã™ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æƒ…å ±ç†è«–çš„è¦–ç‚¹ã‹ã‚‰æ¦‚å¿µæ¶ˆå»ã®é™ç•Œã‚’å®šé‡åŒ–ã—ã€å®Œç’§ãªæ¶ˆå»ã‚’é”æˆã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã¨æ¶ˆå»é–¢æ•°ã®åˆ¶ç´„ã‚’èª¿æŸ»ã€‚ææ¡ˆã™ã‚‹æ¶ˆå»é–¢æ•°ãŒç†è«–çš„é™ç•Œã‚’é”æˆã—ã€GPT-4ã‚’ç”¨ã„ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æ—¢å­˜æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/somnathbrc/status/1907463419105570933?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span></bos></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1858" target="_blank" rel="noopener noreferrer" class="title-link">What, How, Where, and How Well? A Survey on Test-Time Scaling in Large  Language Models, Qiyuan Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚¹ãƒˆæ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆTTSï¼‰ãŒå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å•é¡Œè§£æ±ºèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ãŒã€ä½“ç³»çš„ãªç†è§£ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€TTSç ”ç©¶ã®4ã¤ã®ã‚³ã‚¢æ¬¡å…ƒã«åŸºã¥ãçµ±ä¸€çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€æ‰‹æ³•ã‚„å¿œç”¨ã‚·ãƒŠãƒªã‚ªã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã†ã€‚TTSã®ç™ºå±•ã®è»Œè·¡ã‚’æŠ½å‡ºã—ã€å®Ÿè·µçš„ãªã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã™ã‚‹ã¨ã¨ã‚‚ã«ã€æœªè§£æ±ºã®èª²é¡Œã‚„å°†æ¥ã®æ–¹å‘æ€§ã«ã¤ã„ã¦ã®æ´å¯Ÿã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hesamation/status/1907095419793911893?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã¨ã¦ã¤ã‚‚ãªã„é‡ã â€¦ç¶²ç¾…æ€§ãŒã‚ã‚Šãã†ã€‚<br>What to ScaleãŒã‚ˆãã‚ã‚‹self<br>consistency(Parallel Scaling), STaR(Sequential Scailng), Tree of Thought(Hybrid Scaling), DeepSeek-R1, o1/3(Internal Scaling)ã¨ã„ã£ãŸåˆ†é¡ã§ã€How to ScaleãŒTuningã¨Inferenceã«åˆ†ã‹ã‚Œã¦ã„ã‚‹ã€‚Tuningã¯Long CoTã‚’SFTã™ã‚‹è©±ã‚„å¼·åŒ–å­¦ç¿’ç³»ã®è©±ï¼ˆGRPOãªã©ï¼‰ã§ã€Inferenceã«ã‚‚Self consistencyã‚„ã‚‰ã‚„ã‚‰Verificationã‚„ã‚‰è‰²ã€…ã‚ã‚Šãã†ã€‚è‰¯ã•ãã†ã€‚<br><img src="https://github.com/user-attachments/assets/9d76e438-ff75-454d-b549-7efda9baa300" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1855" target="_blank" rel="noopener noreferrer" class="title-link">Multi-Token Attention, Olga Golovneva+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒãƒˆãƒ¼ã‚¯ãƒ³ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ï¼ˆMTAï¼‰ã‚’ææ¡ˆã—ã€è¤‡æ•°ã®ã‚¯ã‚¨ãƒªã¨ã‚­ãƒ¼ã®ãƒ™ã‚¯ãƒˆãƒ«ã«åŸºã¥ã„ã¦ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¦ã‚§ã‚¤ãƒˆã‚’æ¡ä»¶ä»˜ã‘ã‚‹ã“ã¨ã§ã€é–¢é€£ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚ˆã‚Šæ­£ç¢ºã«ç‰¹å®šã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚MTAã¯ç•³ã¿è¾¼ã¿æ“ä½œã‚’ç”¨ã„ã¦ã€è¿‘ãã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒäº’ã„ã«å½±éŸ¿ã‚’ä¸ãˆã€è±Šã‹ãªæƒ…å ±ã‚’æ´»ç”¨ã™ã‚‹ã€‚è©•ä¾¡çµæœã‹ã‚‰ã€MTAã¯Transformerãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã€ç‰¹ã«é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã®æƒ…å ±æ¤œç´¢ã«ãŠã„ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1907260086017237207?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¾“æ¥ã®Multi Head Attentionã§ã¯ã€å˜ä½“ã®QKã®ã¿ã‚’åˆ©ç”¨ã—ã¦ã„ãŸã‘ã©ã€è¤‡æ•°ã®QKã®æƒ…å ±ã‚’ç•³ã¿è¾¼ã‚“ã§æ´»ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã€Headã‚‚ç•³ã¿è¾¼ã¿ã§é‡è¦ãªæƒ…å ±ãŒã‚ˆã‚Šä¼æ¬ã•ã‚Œã‚‹ã‚ˆã†ã«ã—ã¦ã€GroupNormalizationã‚’ã‹ã‘ãŸã‚‰Perplexityã®è¦³ç‚¹ã§Differential Transformerã‚’ä¸Šå›ã£ãŸã‚ˆã€ã¨ã„ã†è©±ãªæ¨¡æ§˜ã€‚<br><br><img src="https://github.com/user-attachments/assets/199e0794-a286-486d-9426-d86cfd208750" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/2997a61b-3367-4f43-b85a-ac8fa160391a" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/5ef8ddb0-538b-46e2-94b8-2ef495c938ec" alt="image" loading="lazy"><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1856" target="_blank" rel="noopener noreferrer">Group Normalization, Yuxin Wu+, arXiv'18</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1466" target="_blank" rel="noopener noreferrer">Differential Transformer, Tianzhu Ye+, N/A, ICLR'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/QuestionGeneration.html" target="_blank" rel="noopener noreferrer">#QuestionGeneration</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1853" target="_blank" rel="noopener noreferrer" class="title-link">Interactive Agents to Overcome Ambiguity in Software Engineering, Sanidhya Vijayvargiya+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã‚ã„ã¾ã„ãªæŒ‡ç¤ºã«åŸºã¥ãã‚¿ã‚¹ã‚¯è‡ªå‹•åŒ–ã«åˆ©ç”¨ã•ã‚Œã‚‹ãŒã€èª¤ã£ãŸä»®å®šã‚„è³ªå•ä¸è¶³ãŒãƒªã‚¹ã‚¯ã‚’ç”Ÿã‚€ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚ã„ã¾ã„ãªæŒ‡ç¤ºå‡¦ç†èƒ½åŠ›ã‚’è©•ä¾¡ã—ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚’æ´»ç”¨ã—ãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã€ã‚ã„ã¾ã„ã•ã®æ¤œå‡ºã€ç›®æ¨™ã‚’çµã£ãŸè³ªå•ã®å®Ÿæ–½ã‚’æ¤œè¨ã€‚çµæœã€ãƒ¢ãƒ‡ãƒ«ã¯æ˜ç¢ºãªæŒ‡ç¤ºã¨ä¸ååˆ†ãªæŒ‡ç¤ºã‚’åŒºåˆ¥ã™ã‚‹ã®ãŒé›£ã—ã„ãŒã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’é€šã˜ã¦é‡è¦ãªæƒ…å ±ã‚’å–å¾—ã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã®é™ç•Œã¨æ”¹å–„ã®ãŸã‚ã®è©•ä¾¡æ‰‹æ³•ã®é‡è¦æ€§ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>æ›–æ˜§ãªãƒ¦ãƒ¼ã‚¶ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã™ã‚‹ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒ"è³ªå•ã‚’ã™ã‚‹èƒ½åŠ›ã‚’æ¸¬ã‚‹"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br><br>&lt;img width="422" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/3d201ebf-9ca1-4333-9d27-e33a9028066f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/3d201ebf-9ca1-4333-9d27-e33a9028066f"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1847" target="_blank" rel="noopener noreferrer" class="title-link">Demystifying LLM-based Software Engineering Agents, Chunqiu Steven Xia+, FSE'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®LLMã®é€²å±•ã«ã‚ˆã‚Šã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã‚¿ã‚¹ã‚¯ã®è‡ªå‹•åŒ–ãŒé€²ã‚“ã§ã„ã‚‹ãŒã€è¤‡é›‘ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å¿…è¦æ€§ã«ç–‘å•ãŒç”Ÿã˜ã¦ã„ã‚‹ã€‚ã“ã‚Œã«å¯¾ã—ã€Agentlessã¨ã„ã†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€ã‚·ãƒ³ãƒ—ãƒ«ãªä¸‰æ®µéšãƒ—ãƒ­ã‚»ã‚¹ã§å•é¡Œã‚’è§£æ±ºã€‚SWE-bench Liteãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€é«˜ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ä½ã‚³ã‚¹ãƒˆã‚’é”æˆã€‚ç ”ç©¶ã¯è‡ªå¾‹å‹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã«ãŠã‘ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ã§è§£é‡ˆå¯èƒ½ãªæŠ€è¡“ã®å¯èƒ½æ€§ã‚’ç¤ºã—ã€ä»Šå¾Œã®ç ”ç©¶ã®æ–¹å‘æ€§ã‚’åˆºæ¿€ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://note.com/ainest/n/nac1c795e3825" target="_blank" rel="noopener noreferrer">https://note.com/ainest/n/nac1c795e3825</a>


</p>
<p>LLMã«ã‚ˆã‚‹è¨ˆç”»ã®ç«‹æ¡ˆã€ç’°å¢ƒã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ã‚ˆã‚‹æ„æ€æ±ºå®šãªã©ã®è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ã¯ãªãã€Localizationï¼ˆéšå±¤çš„ã«å•é¡Œã®ã‚ã‚‹ç®‡æ‰€ã‚’åŒå®šã™ã‚‹ï¼‰ã¨Repairï¼ˆLLMã§è¤‡æ•°ã®ãƒ‘ãƒƒãƒå€™è£œã‚’ç”Ÿæˆã™ã‚‹ï¼‰ã€PatchValidation(å†ç¾ãƒ†ã‚¹ãƒˆã¨å›å¸°ãƒ†ã‚¹ãƒˆã®ä¸¡æ–¹ã‚’é€šã˜ã¦çµæœãŒè‰¯ã‹ã£ãŸãƒ‘ãƒƒãƒã‚’é¸ã¶ï¼‰ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’é€šã˜ã¦Issueã‚’è§£æ±ºã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/6d042dfe-9780-4410-9077-b265af5456d1" alt="image" loading="lazy"><br><br>ã“ã‚Œã«ã‚ˆã‚Šã€ä½ã‚³ã‚¹ãƒˆã§é«˜ã„æ€§èƒ½ã‚’é”æˆã—ã¦ã„ã‚‹ã€ã¨ã„ã£ãŸå†…å®¹ãªæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/3934126f-3a4d-406c-8860-c3ed35a351c4" alt="image" loading="lazy"></p>
<p>Agentlessã¨å‘¼ã°ã‚Œæ‰‹æ³•ã ãŒã€preprintç‰ˆã«ã‚ã£ãŸã‚¿ã‚¤ãƒˆãƒ«ã®æ¥é ­è¾ã ã£ãŸåŒå‘¼ç§°ãŒproceedingç‰ˆã§ã¯ç„¡ããªã£ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/FactualKnowledge.html" target="_blank" rel="noopener noreferrer">#FactualKnowledge</a>
<span class="issue_date">Issue Date: 2025-04-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1846" target="_blank" rel="noopener noreferrer" class="title-link">Inside-Out: Hidden Factual Knowledge in LLMs, Zorik Gekhman+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã¯ã€LLMãŒå‡ºåŠ›ä»¥ä¸Šã®äº‹å®Ÿçš„çŸ¥è­˜ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚çŸ¥è­˜ã‚’å®šç¾©ã—ã€æ­£ã—ã„å›ç­”ãŒé«˜ããƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚Œã‚‹å‰²åˆã‚’å®šé‡åŒ–ã€‚å¤–éƒ¨çŸ¥è­˜ã¨å†…éƒ¨çŸ¥è­˜ã‚’åŒºåˆ¥ã—ã€å†…éƒ¨çŸ¥è­˜ãŒå¤–éƒ¨çŸ¥è­˜ã‚’è¶…ãˆã‚‹ã¨éš ã‚ŒãŸçŸ¥è­˜ãŒç”Ÿã˜ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ–ãƒƒã‚¯QAè¨­å®šã§ã®ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã§ã¯ã€LLMãŒå†…éƒ¨ã§å¤šãã®çŸ¥è­˜ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã„ã‚‹ã“ã¨ã€çŸ¥è­˜ãŒéš ã‚Œã¦ã„ã‚‹å ´åˆãŒã‚ã‚‹ã“ã¨ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹åˆ¶ç´„ãŒã‚ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zorikgekhman/status/1906693729886363861?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Video.html" target="_blank" rel="noopener noreferrer">#Video</a>
<span class="issue_date">Issue Date: 2025-03-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1843" target="_blank" rel="noopener noreferrer" class="title-link">Qwen2.5-Omni Technical Report, Jin Xu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€ŒQwen2.5-Omniã€ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€éŸ³å£°ã€å‹•ç”»ã‚’èªè­˜ã—ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ–¹å¼ã§è‡ªç„¶ãªéŸ³å£°å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ã€‚éŸ³å£°ã¨è¦–è¦šã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ãƒ–ãƒ­ãƒƒã‚¯å‡¦ç†ã‚’ç”¨ã„ã€TMRoPEã«ã‚ˆã‚‹æ–°ã—ã„ä½ç½®åŸ‹ã‚è¾¼ã¿ã§éŸ³å£°ã¨å‹•ç”»ã®åŒæœŸã‚’å®Ÿç¾ã€‚Thinker-Talkerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã¨éŸ³å£°å‡ºåŠ›ã‚’å¹²æ¸‰ãªãè¡Œã†ã€‚Qwen2.5-Omniã¯ã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã§è¨“ç·´ã•ã‚Œã€éŸ³å£°æŒ‡ç¤ºã«å¯¾ã™ã‚‹æ€§èƒ½ãŒãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã¨åŒç­‰ã§ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°Talkerã¯æ—¢å­˜æ‰‹æ³•ã‚’ä¸Šå›ã‚‹è‡ªç„¶ã•ã‚’æŒã¤ã€‚</span>
<span class="snippet"><span>Comment</span><p>Qwen Teamã«ã‚ˆã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMã€‚ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€å‹•ç”»éŸ³å£°ã‚’inputã¨ã—ã¦å—ã‘å–ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆã€éŸ³å£°ã‚’outputã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/03e54fd7-2011-4069-aa1b-38d1610169ec" alt="image" loading="lazy"><br><br>weight:


<a href="https://huggingface.co/collections/Qwen/qwen25-omni-67de1e5f0f9464dc6314b36e" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/Qwen/qwen25-omni-67de1e5f0f9464dc6314b36e</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/niels-rogge-a3b7a3127_alibabas-qwen-team-has-done-it-again-this-activity-7311036679627132929-HUqy?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/niels-rogge-a3b7a3127_alibabas-qwen-team-has-done-it-again-this-activity-7311036679627132929-HUqy?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4</a>


</p></span><br><br>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-03-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1842" target="_blank" rel="noopener noreferrer" class="title-link">Measuring AI Ability to Complete Long Tasks, Thomas Kwa+, arXiv'25, 2025.03</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„æŒ‡æ¨™ã€Œ50%-ã‚¿ã‚¹ã‚¯å®Œäº†æ™‚é–“ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ã€ã‚’ææ¡ˆã—ã€AIãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’äººé–“ã®è¦³ç‚¹ã‹ã‚‰å®šé‡åŒ–ã€‚Claude 3.7 Sonnetã¯ç´„50åˆ†ã®æ™‚é–“ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ã‚’æŒã¡ã€AIã®èƒ½åŠ›ã¯2019å¹´ä»¥é™ç´„7ã‹æœˆã”ã¨ã«å€å¢—ã€‚ä¿¡é ¼æ€§ã‚„è«–ç†çš„æ¨è«–ã®å‘ä¸ŠãŒè¦å› ã¨ã•ã‚Œã€5å¹´ä»¥å†…ã«AIãŒå¤šãã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¿ã‚¹ã‚¯ã‚’è‡ªå‹•åŒ–ã§ãã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1902854727089656016?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¢ºã‹ã«ç·šå½¢ã«è¦‹ãˆã‚‹ã€‚ã¦ã‹GPT-2ã¨æ¯”ã¹ã‚‹ã¨AIã•ã‚“é€²åŒ–ã—ã™ãã§ã‚ã‚‹â€¦ã€‚<br><img src="https://github.com/user-attachments/assets/266a36aa-a169-492b-b8af-60c0cb152111" alt="image" loading="lazy"></p>
<p>åˆ©ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯<br>- HCAST: 46ã®ã‚¿ã‚¹ã‚¯ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã«åŸºã¥ã97ç¨®é¡ã®ã‚¿ã‚¹ã‚¯ãŒå®šç¾©ã•ã‚Œã¦ãŠã‚Šã€ãŸã¨ãˆã°ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€æ©Ÿæ¢°å­¦ç¿’ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€ä¸€èˆ¬çš„ãªæ¨è«–ã‚¿ã‚¹ã‚¯ï¼ˆwikipediaã‹ã‚‰äº‹å®Ÿæƒ…å ±ã‚’æ¢ã™ã‚¿ã‚¹ã‚¯ãªã©ï¼‰ãªã©ãŒã‚ã‚‹<br>  - æ•°åˆ†ã§çµ‚ã‚ã‚‹ã‚¿ã‚¹ã‚¯: ä¸Šè¿°ã®wikipedia<br>  - æ•°æ™‚é–“ã§çµ‚ã‚ã‚‹ã‚¿ã‚¹ã‚¯: Pytorchã®ã¡ã‚‡ã£ã¨ã—ãŸãƒã‚°ä¿®æ­£ãªã©<br>  - æ•°æ–‡ã§ã‚¿ã‚¹ã‚¯ãŒè¨˜è¿°ã•ã‚Œã€ã‚³ãƒ¼ãƒ‰ã€ãƒ‡ãƒ¼ã‚¿ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€ã‚ã‚‹ã„ã¯webã‹ã‚‰å…¥æ‰‹å¯èƒ½ãªæƒ…å ±ã‚’å‚ç…§å¯èƒ½<br>ã€€- ã‚¿ã‚¹ã‚¯ã®é›£æ˜“åº¦ã¨ã—ã¦ã¯å½“è©²ãƒ‰ãƒ¡ã‚¤ãƒ³ã«æ•°å¹´é–“æºã‚ã£ãŸå°‚é–€å®¶ãŒè§£ã‘ã‚‹å•é¡Œ<br>- RE-Bench Suite<br>  - 7ã¤ã®open endedãªå°‚é–€å®¶ãŒ8æ™‚é–“ç¨‹åº¦ã‚’è¦ã™ã‚‹MLã«é–¢ã™ã‚‹ã‚¿ã‚¹ã‚¯<br>ã€€- e.g., GPT-2ã‚’QAç”¨ã«Finetuningã™ã‚‹, Finetuningã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«æŒ™å‹•ã‚’å¤‰åŒ–ã•ã›ãšã«ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’å¯èƒ½ãªé™ã‚ŠçŸ­ç¸®ã™ã‚‹ã€ãªã©<br>ã€€- [RE-Bench Technical Report](


<a href="https://metr.org/AI_R_D_Evaluation_Report.pdf)%E3%81%AETable2%E7%AD%89%E3%82%92%E5%8F%82%E7%85%A7%E3%81%AE%E3%81%93%E3%81%A8" target="_blank" rel="noopener noreferrer">https://metr.org/AI_R_D_Evaluation_Report.pdf)ã®Table2ç­‰ã‚’å‚ç…§ã®ã“ã¨</a>


<br>- SWAA Suite: 66ç¨®é¡ã®1ã¤ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«ã‚ˆã£ã¦1åˆ†ä»¥å†…ã§çµ‚ã‚ã‚‹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã§å…¸å‹çš„ãªã‚¿ã‚¹ã‚¯<br>  - 1åˆ†ä»¥å†…ã§çµ‚ã‚ã‚‹ã‚¿ã‚¹ã‚¯ãŒä¸Šè¨˜ãƒ‡ãƒ¼ã‚¿ã«ãªã‹ã£ãŸã®ã§è‘—è€…ã‚‰ãŒä½œæˆ<br><br>ã§ã‚ã‚Šã€ç”»åƒç³»ã‚„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªã‚¿ã‚¹ã‚¯ã¯å«ã¾ã‚Œã¦ã„ãªã„ã€‚<br><img src="https://github.com/user-attachments/assets/0b3892c9-3c83-4f78-a490-c28fa7470e0e" alt="image" loading="lazy"><br><br>ã‚¿ã‚¹ã‚¯ã¨äººé–“ãŒã‚¿ã‚¹ã‚¯ã«è¦ã™ã‚‹æ™‚é–“ã®å¯¾å¿œã«é–¢ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã¯ä¸‹è¨˜<br><img src="https://github.com/user-attachments/assets/5ed472da-e8c9-41be-8fd1-ef6f21713c14" alt="image" loading="lazy"></p>
<p>ã‚¿ã‚¹ã‚¯-ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒšã‚¢ã”ã¨ã«8å›å®Ÿè¡Œã—ãŸå ´åˆã®å¹³å‡ã®æˆåŠŸç‡ã€‚ç¢ºã‹ã«ã“ã®ã‚°ãƒ©ãƒ•ã‹ã‚‰ã¯Nå¹´å¾Œã«ã¯äººé–“ã§è¨€ã†ã¨ã“ã®ãã‚‰ã„ã®èƒ½åŠ›ã®äººãŒã“ã®ãã‚‰ã„æ™‚é–“ã‚’è¦ã™ã‚‹ã‚¿ã‚¹ã‚¯ãŒã€ã“ã®ãã‚‰ã„ã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ã¾ã™ã€ã¨ã„ã£ãŸã–ã£ãã‚Šæ„Ÿè¦šå€¤ã¯ãªã‹ãªã‹æƒ³åƒã§ããªã„ã€‚<br><img src="https://github.com/user-attachments/assets/e2bed06e-9234-4607-826a-588106010bcf" alt="image" loading="lazy"></p>
<p>æˆåŠŸç‡ã¨ã‚¿ã‚¹ã‚¯ã«äººé–“ãŒè¦ã™ã‚‹æ™‚é–“ã«é–¢ã™ã‚‹ã‚°ãƒ©ãƒ•ã€‚ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯é–¢æ•°ã§fittingã—ã¦ãŠã‚Šã€èµ¤ã„ç ´ç·šãŒ50% horizonã€‚Claude 3.5 Sonnet ï¼ˆoldï¼‰ã‹ã‚‰Claude 3.7 Sonnetã§50% horizonã¯18åˆ†ã‹ã‚‰59åˆ†ã¾ã§å¢—ãˆã¦ã„ã‚‹ã€‚å®Ÿéš›ã«æ•°å­—ã§è¦‹ã‚‹ã¨ã‚¤ãƒ¡ãƒ¼ã‚¸ãŒæ¹§ãã‚„ã™ããŠã‚‚ã—ã‚ã„ã€‚<br><img src="https://github.com/user-attachments/assets/efe01e35-6ee6-45a5-8a4c-eccf95284b35" alt="image" loading="lazy"></p>
<p>ã“ã¡ã‚‰ã§æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚‚éšæ™‚æ›´æ–°ã•ã‚Œã‚‹:<br>


<a href="https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/" target="_blank" rel="noopener noreferrer">https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/</a>


</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1839" target="_blank" rel="noopener noreferrer" class="title-link">RALLRec+: Retrieval Augmented Large Language Model Recommendation with  Reasoning, Sichun Luo+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RALLRec+ã¯ã€LLMsã‚’ç”¨ã„ã¦ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®retrievalã¨generationã‚’å¼·åŒ–ã™ã‚‹æ‰‹æ³•ã€‚retrievalæ®µéšã§ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ èª¬æ˜ã‚’ç”Ÿæˆã—ã€ãƒ†ã‚­ã‚¹ãƒˆä¿¡å·ã¨å”èª¿ä¿¡å·ã‚’çµåˆã€‚ç”Ÿæˆæ®µéšã§ã¯ã€æ¨è«–LLMsã‚’è©•ä¾¡ã—ã€çŸ¥è­˜æ³¨å…¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã§æ±ç”¨LLMsã¨çµ±åˆã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆæ‰‹æ³•ã®æœ‰åŠ¹æ€§ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1905107217663336832?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Reasoning LLMã‚’RecSysã«å¿œç”¨ã™ã‚‹åˆã‚ã¦ã®ç ”ç©¶ï¼ˆã‚‰ã—ã„ã“ã¨ãŒRelated Workã«æ›¸ã‹ã‚Œã¦ã„ã‚‹ï¼‰</p>
<p>arxivã®adminã‚ˆã‚Šä»¥ä¸‹ã®ã‚³ãƒ¡ãƒ³ãƒˆãŒè¿½è¨˜ã•ã‚Œã¦ã„ã‚‹<br>&gt; 	arXiv admin note: substantial text overlap with arXiv:2502.06101<br><br>ã‚³ãƒ¡ãƒ³ãƒˆä¸­ã®ç ”ç©¶ã¯ä¸‹è¨˜ã§ã‚ã‚‹<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1840" target="_blank" rel="noopener noreferrer">ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential   Behavior Comprehension in Recommendation, Jianghao Lin+, WWW'24</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2025-03-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1838" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Evaluation-time Compute with Reasoning Models as Process  Evaluators, Seungone Kim+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LMã®å‡ºåŠ›å“è³ªè©•ä¾¡ãŒé›£ã—ããªã£ã¦ã„ã‚‹ä¸­ã€è¨ˆç®—ã‚’å¢—ã‚„ã™ã“ã¨ã§è©•ä¾¡èƒ½åŠ›ãŒå‘ä¸Šã™ã‚‹ã‹ã‚’æ¤œè¨ã€‚æ¨è«–ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦å¿œç­”å…¨ä½“ã¨å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’è©•ä¾¡ã—ã€æ¨è«–ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”ŸæˆãŒè©•ä¾¡è€…ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚å†ãƒ©ãƒ³ã‚¯ä»˜ã‘ã«ã‚ˆã‚Šã€è©•ä¾¡æ™‚ã®è¨ˆç®—å¢—åŠ ãŒLMã®å•é¡Œè§£æ±ºèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jinulee_v/status/1905025016401428883?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLM-as-a-Judgeã‚‚longCoT+self-consistencyã§æ€§èƒ½ãŒæ”¹å–„ã™ã‚‹ã‚‰ã—ã„ã€‚<br><img src="https://github.com/user-attachments/assets/937b6241-4877-46c7-a488-5ee6bf8203db" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-03-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1837" target="_blank" rel="noopener noreferrer" class="title-link">Overtrained Language Models Are Harder to Fine-Tune, Jacob Mitchell Springer+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ã«ãŠã„ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³äºˆç®—ã®å¢—åŠ ãŒãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é›£ã—ãã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹ã‚’å¼•ãèµ·ã“ã™ã€Œå£Šæ»…çš„ãªéå­¦ç¿’ã€ã‚’æå”±ã€‚3Tãƒˆãƒ¼ã‚¯ãƒ³ã§äº‹å‰å­¦ç¿’ã•ã‚ŒãŸOLMo-1Bãƒ¢ãƒ‡ãƒ«ã¯ã€2.3Tãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦2%ä»¥ä¸Šã®æ€§èƒ½ä½ä¸‹ã‚’ç¤ºã™ã€‚å®Ÿé¨“ã¨ç†è«–åˆ†æã«ã‚ˆã‚Šã€äº‹å‰å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ„Ÿåº¦ã®å¢—åŠ ãŒåŸå› ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€äº‹å‰å­¦ç¿’è¨­è¨ˆã®å†è©•ä¾¡ã‚’ä¿ƒã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>è‘—è€…ã«ã‚ˆã‚‹ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacspringer/status/1904960783341023521?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>äº‹å‰å­¦ç¿’ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å¢—ã‚„ã™ã¨ãƒ¢ãƒ‡ãƒ«ã®sensitivityãŒå¢—ã—ã€post-trainingã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®åŠ£åŒ–ãŒèµ·ã“ã‚‹ã“ã¨ã‚’å ±å‘Šã—ã¦ã„ã‚‹ã€‚äº‹å‰å­¦ç¿’ã§å­¦ç¿’ã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å¢—ã‚„ã›ã°ã€å¿…ãšã—ã‚‚post-trainingå¾Œã®ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãŒã‚ˆããªã‚‹ã‚ã‘ã§ã¯ãªã„ã‚‰ã—ã„ã€‚<br><img src="https://github.com/user-attachments/assets/ba60ae24-f3e5-4956-b29f-37b4fe01a9d1" alt="image" loading="lazy"></p>
<p>ICLR'25ã®Outstanding Paperã«é¸ã°ã‚ŒãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacspringer/status/1917174452531724718?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãã¡ã‚“ã¨èª­ã‚“ã æ–¹ãŒè‰¯ã•ã’ã€‚</span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-03-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1832" target="_blank" rel="noopener noreferrer" class="title-link">Critique Fine-Tuning: Learning to Critique is More Effective than   Learning to Imitate, Yubo Wang+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- æ‰¹è©•ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆCFTï¼‰ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒãƒã‚¤ã‚ºã®ã‚ã‚‹å¿œç­”ã‚’æ‰¹è©•ã™ã‚‹ã“ã¨ã‚’å­¦ã¶æ–°ã—ã„æˆ¦ç•¥ã§ã€å¾“æ¥ã®ç›£è¦–ä»˜ããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã«æŒ‘æˆ¦ã—ã¾ã™ã€‚CFTã¯äººé–“ã®å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã«ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ã‚’å—ã‘ã€æ·±ã„åˆ†æã‚’ä¿ƒé€²ã—ã¾ã™ã€‚WebInstructã‹ã‚‰æ§‹ç¯‰ã—ãŸ50Kã‚µãƒ³ãƒ—ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€CFTã¯è¤‡æ•°ã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§SFTã«å¯¾ã—ã¦4-10%ã®æ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ã¾ã—ãŸã€‚ç‰¹ã«ã€Qwen2.5-Math-CFTã¯å°‘ãªã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§å¼·åŠ›ãªç«¶åˆã¨åŒç­‰ã®æ€§èƒ½ã‚’ç™ºæ®ã—ã€CFTã®å …ç‰¢æ€§ã‚‚ç¢ºèªã•ã‚Œã¾ã—ãŸã€‚CFTã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã‚’é€²å±•ã•ã›ã‚‹åŠ¹æœçš„ãªæ‰‹æ³•ã§ã‚ã‚‹ã¨ä¸»å¼µã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/WenhuChen/status/1885060597500567562"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Critique Fine-Tuning (CFT) ã‚’ææ¡ˆã€‚CFTã§ã¯ã€query x, noisy response y [^1] ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ãã‚Œã«å¯¾ã™ã‚‹æ‰¹è©• cã‚’å­¦ç¿’ã™ã‚‹ã€‚cã¯givenã§ã¯ãªã„ã®ã§ã€GPT4oã®ã‚ˆã†ãªå¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦åˆæˆã™ã‚‹ã€‚<br><br>![Image](https://github.com/user-attachments/assets/f25babdd-63d6-4d3d-a9b0-3217db2bd07f)<br><br>ç›®çš„é–¢æ•°ã¯ä»¥ä¸‹ã€‚[x; y] ãŒgivenãªæ™‚ã«cã‚’ç”Ÿæˆã™ã‚‹ç¢ºç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ã€‚ã‚·ãƒ³ãƒ—ãƒ«ã€‚<br>![Image](https://github.com/user-attachments/assets/ccdb8e42-e8b2-4ae1-99a6-a0b7c1d4bf2a)<br><br>RLã‚’ç”¨ã„ãŸæ‰‹æ³•ã¨ã®æ¯”è¼ƒã€‚1/10ç¨‹åº¦ã®ãƒ‡ãƒ¼ã‚¿é‡ã€1/100ç¨‹åº¦ã®GPUæ™‚é–“ã§åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã§ãã‚‹ã€‚<br>![Image](https://github.com/user-attachments/assets/848376ff-9965-485b-b8a0-7960d1d0e7b9)<br><br>[^1]: æœ¬è«–æ–‡ã§åˆ©ç”¨ã—ã¦ã„ã‚‹WebInstructã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸãƒ‡ãƒ¼ã‚¿ã§ã¯ã€ãŸã¨ãˆã°ç´„50%ç¨‹åº¦ã®yãŒæ­£è§£,  æ®‹ã‚Šã¯ä¸æ­£è§£ï¼ˆç¨‹åº¦ã®noisyãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ï¼‰</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1826" target="_blank" rel="noopener noreferrer" class="title-link">Thinking Machines: A Survey of LLM based Reasoning Strategies, Dibyanayan Bandyopadhyay+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯å„ªã‚ŒãŸè¨€èªèƒ½åŠ›ã‚’æŒã¤ãŒã€æ¨è«–èƒ½åŠ›ã¨ã®é–“ã«ã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹ã€‚æ¨è«–ã¯AIã®ä¿¡é ¼æ€§ã‚’é«˜ã‚ã€åŒ»ç™‚ã‚„æ³•å¾‹ãªã©ã®åˆ†é‡ã§ã®é©ç”¨ã«ä¸å¯æ¬ ã§ã‚ã‚‹ã€‚æœ€è¿‘ã®å¼·åŠ›ãªæ¨è«–ãƒ¢ãƒ‡ãƒ«ã®ç™»å ´ã«ã‚ˆã‚Šã€LLMsã«ãŠã‘ã‚‹æ¨è«–ã®ç ”ç©¶ãŒé‡è¦è¦–ã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€æ—¢å­˜ã®æ¨è«–æŠ€è¡“ã®æ¦‚è¦ã¨æ¯”è¼ƒã‚’è¡Œã„ã€æ¨è«–ã‚’å‚™ãˆãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®ä½“ç³»çš„ãªèª¿æŸ»ã¨ç¾åœ¨ã®èª²é¡Œã‚’æç¤ºã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1903843684568666450?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RL, Test Time Compute, Self-trainingã®3ç¨®é¡ã«ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã•ã‚Œã¦ã„ã‚‹ã€‚ã¾ãŸã€å„ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«ã‚ˆã‚Šç´°åˆ†åŒ–ã•ã‚ŒãŸãƒ„ãƒªãƒ¼ãŒè«–æ–‡ä¸­ã«ã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/d323db81-973a-4752-afc9-4471f5e64feb" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1825" target="_blank" rel="noopener noreferrer" class="title-link">Compute Optimal Scaling of Skills: Knowledge vs Reasoning, Nicholas Roberts+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã¯LLMé–‹ç™ºã«ãŠã„ã¦é‡è¦ã§ã‚ã‚Šã€ç‰¹ã«è¨ˆç®—æœ€é©åŒ–ã«ã‚ˆã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ãŒçŸ¥è­˜ã‚„æ¨è«–ã«åŸºã¥ãã‚¹ã‚­ãƒ«ã«ä¾å­˜ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ãƒŸãƒƒã‚¯ã‚¹ãŒã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æŒ™å‹•ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã—ãŸã€‚çµæœã€çŸ¥è­˜ã¨ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®ã‚¹ã‚­ãƒ«ã¯æ ¹æœ¬çš„ã«ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æŒ™å‹•ã‚’ç¤ºã—ã€èª¤æŒ‡å®šã•ã‚ŒãŸæ¤œè¨¼ã‚»ãƒƒãƒˆãŒè¨ˆç®—æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã«ç´„50%ã®å½±éŸ¿ã‚’ä¸ãˆã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1903843682509312218?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>çŸ¥è­˜ã‚’å•ã†QAã®ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é‡ãŒå¿…è¦ã§ã‚ã‚Šã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ã‚ˆã†ãªReasoningã«åŸºã¥ãã‚¿ã‚¹ã‚¯ã¯ãƒ‡ãƒ¼ã‚¿é‡ãŒå¿…è¦ã§ã‚ã‚Šã€ç•°ãªã‚‹è¦ç´ ã«ä¾å­˜ã—ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ç ”ç©¶ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/5d2bb3c6-437a-4184-9848-3232745d0de1" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1819" target="_blank" rel="noopener noreferrer" class="title-link">Stop Overthinking: A Survey on Efficient Reasoning for Large Language  Models, Yang Sui+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€LLMsã«ãŠã‘ã‚‹åŠ¹ç‡çš„ãªæ¨è«–ã®é€²å±•ã‚’ä½“ç³»çš„ã«èª¿æŸ»ã—ã€ä»¥ä¸‹ã®ä¸»è¦ãªæ–¹å‘ã«åˆ†é¡ã—ã¾ã™ï¼š(1) ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®åŠ¹ç‡çš„æ¨è«–ã€(2) æ¨è«–å‡ºåŠ›ãƒ™ãƒ¼ã‚¹ã®åŠ¹ç‡çš„æ¨è«–ã€(3) å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ™ãƒ¼ã‚¹ã®åŠ¹ç‡çš„æ¨è«–ã€‚ç‰¹ã«ã€å†—é•·ãªå‡ºåŠ›ã«ã‚ˆã‚‹è¨ˆç®—ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’è»½æ¸›ã™ã‚‹æ–¹æ³•ã‚’æ¢æ±‚ã—ã€å°è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚„è©•ä¾¡æ–¹æ³•ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Reasoning Modelã«ãŠã„ã¦ã€Over Thinkingç¾è±¡ï¼ˆä¸è¦ãªreasoning stepã‚’ç”Ÿæˆã—ã¦ã—ã¾ã†ï¼‰ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®æ‰‹æ³•ã«é–¢ã™ã‚‹Surveyã€‚<br><img src="https://github.com/user-attachments/assets/a411f2cf-2ba1-4e58-8dc7-ac1ae2ff0de6" alt="image" loading="lazy"><br><br>ä¸‹è¨˜Figure2ã‚’è¦‹ã‚‹ã¨ã‚ˆãã¾ã¨ã¾ã£ã¦ã„ã¦ã€ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’èª­ã‚€ã¨ã ã„ãŸã„åˆ†ã‹ã‚‹ã€‚ãªã‚‹ã»ã©ã€‚<br>Length Rewardã«ã¤ã„ã¦ã¯ã€<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
<br><br>ã§è€ƒå¯Ÿã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€Reward HackingãŒèµ·ãã‚‹ã®ã§è¨­è¨ˆã®ä»•æ–¹ã«æ°—ã‚’ã¤ã‘ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/fd6880bd-95e1-4ca6-9593-8ffc9390962a" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1902977896685396275?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å„ã‚«ãƒ†ã‚´ãƒªã«ãŠã‘ã‚‹literatureã‚‚è¦‹ã‚„ã™ãã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚å¿…è¦ã«å¿œã˜ã¦å‚ç…§ã—ãŸã„ã€‚<br><img src="https://github.com/user-attachments/assets/b6be0d79-35c5-45a8-878b-2b6be67c2f76" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-03-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1817" target="_blank" rel="noopener noreferrer" class="title-link">Lost-in-the-Middle in Long-Text Generation: Synthetic Dataset,  Evaluation Framework, and Mitigation, Junhao Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- é•·ã„å…¥åŠ›ã¨å‡ºåŠ›ã®ç”Ÿæˆã«ç‰¹åŒ–ã—ãŸLongInOutBenchã‚’å°å…¥ã—ã€æ—¢å­˜æ‰‹æ³•ã®ã€Œä¸­é–“ã§ã®å–ªå¤±ã€å•é¡Œã«å¯¾å‡¦ã€‚Retrieval-Augmented Long-Text Writerï¼ˆRAL-Writerï¼‰ã‚’é–‹ç™ºã—ã€é‡è¦ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å†è¡¨ç¾ã™ã‚‹ã“ã¨ã§æ€§èƒ½ã‚’å‘ä¸Šã€‚ææ¡ˆæ‰‹æ³•ã®æœ‰åŠ¹æ€§ã‚’ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨æ¯”è¼ƒã—ã¦ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Lost in the Middleã«é–¢ã™ã‚‹ç ”ç©¶ã€‚</p>
<p>é–¢é€£ç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/793" target="_blank" rel="noopener noreferrer">Lost in the Middle: How Language Models Use Long Contexts, Nelson F. Liu+, N/A, TACL'24</a>
</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-03-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1815" target="_blank" rel="noopener noreferrer" class="title-link">DAPO: An Open-Source LLM Reinforcement Learning System at Scale, Qiying Yu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¨è«–ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚ŠLLMã®æ¨è«–èƒ½åŠ›ãŒå‘ä¸Šã—ã€å¼·åŒ–å­¦ç¿’ãŒè¤‡é›‘ãªæ¨è«–ã‚’å¼•ãå‡ºã™æŠ€è¡“ã¨ãªã‚‹ã€‚ã—ã‹ã—ã€æœ€å…ˆç«¯ã®æŠ€è¡“è©³ç´°ãŒéš ã•ã‚Œã¦ã„ã‚‹ãŸã‚å†ç¾ãŒé›£ã—ã„ã€‚ãã“ã§ã€$\textbf{DAPO}$ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã—ã€Qwen2.5-32Bãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦AIME 2024ã§50ãƒã‚¤ãƒ³ãƒˆã‚’é”æˆã€‚æˆåŠŸã®ãŸã‚ã®4ã¤ã®é‡è¦æŠ€è¡“ã‚’å…¬é–‹ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã¨å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã™ã‚‹ã“ã¨ã§å†ç¾æ€§ã‚’å‘ä¸Šã•ã›ã€ä»Šå¾Œã®ç ”ç©¶ã‚’æ”¯æ´ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¢å­˜ã®reasoning modelã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã«ãŠã„ã¦ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªRLã®å­¦ç¿’ã§éµã¨ãªã‚‹ãƒ¬ã‚·ãƒ”ã¯éš ã•ã‚Œã¦ã„ã‚‹ã¨ä¸»å¼µã—ã€å®Ÿéš›å½¼ã‚‰ã®baselineã¨ã—ã¦GRPOã‚’èµ°ã‚‰ã›ãŸã¨ã“ã‚ã€DeepSeekã‹ã‚‰å ±å‘Šã•ã‚Œã¦ã„ã‚‹AIME2024ã§ã®æ€§èƒ½ï¼ˆ47ãƒã‚¤ãƒ³ãƒˆï¼‰ã‚ˆã‚Šã‚‚ã§ã€€å¤§å¹…ã«ä½ã„æ€§èƒ½ï¼ˆ30ãƒã‚¤ãƒ³ãƒˆï¼‰ã—ã‹åˆ°é”ã§ããšã€åˆ†æã®çµæœ3ã¤ã®èª²é¡Œï¼ˆentropy collapse, reward noise, training instabilityï¼‰ã‚’æ˜ã‚‰ã‹ã«ã—ãŸï¼ˆå®Ÿéš›R1ã®çµæœã‚’å†ç¾ã§ããªã„å ±å‘ŠãŒå¤šæ•°å ±å‘Šã•ã‚Œã¦ãŠã‚Šã€é‡è¦ãªè¨“ç·´ã®è©³ç´°ãŒéš ã•ã‚Œã¦ã„ã‚‹ã¨ã—ã¦ã„ã‚‹ï¼‰ã€‚<br><br>ãã®ä¸Šã§50%ã®trainikg stepã§DeepSeek-R1-Zero-Qwen-32Bã¨åŒç­‰ã®AIME 2024ã§ã®æ€§èƒ½ã‚’é”æˆã§ãã‚‹DAPOã‚’ææ¡ˆã€‚ãã—ã¦gapã‚’åŸ‹ã‚ã‚‹ãŸã‚ã«ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã™ã‚‹ã¨ã®ã“ã¨ã€‚</p>
<p>ã¡ã¨ã“ã‚Œã¯ã‚ã¨ã§ã—ã£ã‹ã‚Šèª­ã¿ãŸã„ã€‚é‡è¦è«–æ–‡ã€‚</p>
<p>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒšãƒ¼ã‚¸:


<a href="https://dapo-sia.github.io/" target="_blank" rel="noopener noreferrer">https://dapo-sia.github.io/</a>


<br><br>ã“ã¡ã‚‰ã«ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é‡è¦ãªéƒ¨åˆ†ã®æ¦‚è¦ãŒèª¬æ˜ã•ã‚Œã¦ã„ã‚‹ã€‚</p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1902507148015489385?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã ãŒåˆ†ã‹ã‚Šã‚„ã™ãã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚<p>ä¸‹è¨˜ãƒã‚¹ãƒˆã«ã‚ˆã‚‹ã¨ã€Reward Scoreã«å¤šæ§˜æ€§ã‚’æŒãŸã›ãŸã„å ´åˆã¯3.2ç¯€å‚ç…§ã¨ã®ã“ã¨ã€‚<br>ã™ãªã‚ã¡ã€Dynamic Samplingã®è©±ã§ã€AccãŒå…¨ã¦ã®ç”Ÿæˆã§1.0ã‚ã‚‹ã„ã¯0.0ã¨ãªã‚‹ã‚ˆã†ãªpromptã‚’é™¤å¤–ã™ã‚‹ã¨ã„ã£ãŸæ–¹æ³•ã®è©±ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br>ã“ã‚Œã¯ã€ã‚ã‚‹promptã«å¯¾ã™ã‚‹å…¨ã¦ã®ç”Ÿæˆã§æ­£è§£/ä¸æ­£è§£ã«ãªã£ãŸå ´åˆã€ãã®promptã«å¯¾ã™ã‚‹AdvantageãŒ0ã¨ãªã‚‹ãŸã‚ã€ãƒãƒªã‚·ãƒ¼ã‚’updateã™ã‚‹ãŸã‚ã®gradientã‚‚0ã¨ãªã‚‹ã€‚ãã†ã™ã‚‹ã¨ã€ã“ã®ã‚µãƒ³ãƒ—ãƒ«ã¯ãƒãƒªã‚·ãƒ¼ã®æ›´æ–°ã«å…¨ãå¯„ä¸ã—ãªããªã‚‹ãŸã‚ã€åŒãƒãƒƒãƒå†…ã®ãƒã‚¤ã‚ºã«å¯¾ã™ã‚‹é ‘å¥æ€§ãŒå¤±ã‚ã‚Œã‚‹ã“ã¨ã«ãªã‚‹ã€‚ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ã‚‚ä½ä¸‹ã™ã‚‹ã€‚ç‰¹ã«AccãŒ1.0ã«ãªã‚‹ã‚ˆã†ãªpromptã¯å­¦ç¿’ãŒé€²ã‚€ã«ã¤ã‚Œã¦å¢—åŠ ã™ã‚‹ãŸã‚ã€ãƒãƒƒãƒå†…ã§å­¦ç¿’ã«æœ‰åŠ¹ãªpromptã¯æ¸›ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã€gradientã®åˆ†æ•£ã®å¢—åŠ ã«ã¤ãªãŒã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚‰ã—ã„ã€‚<br><br>é–¢é€£ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1936375947575632102?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‰²ã€…ãªç ”ç©¶ã§åºƒãä½¿ã‚ã‚Œã‚‹ã®ã‚’è¦‹ã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-03-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1811" target="_blank" rel="noopener noreferrer" class="title-link">Sample, Scrutinize and Scale: Effective Inference-Time Search by Scaling  Verification, Eric Zhao+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®æ¢ç´¢ã¯ã€è¤‡æ•°ã®å€™è£œå¿œç­”ã‚’ç”Ÿæˆã—æœ€è‰¯ã®ã‚‚ã®ã‚’é¸ã¶æ‰‹æ³•ã§ã‚ã‚Šã€è‡ªå·±æ¤œè¨¼ã«ã‚ˆã£ã¦æ­£ç¢ºæ€§ã‚’ç¢ºèªã—ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ã“ã®æ¢ç´¢ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‚¾å‘ã‚’åˆ†æã—ã€ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…ãŒGemini v1.5 Proã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚è‡ªå·±æ¤œè¨¼ã®ç²¾åº¦å‘ä¸Šã¯ã€ã‚ˆã‚Šå¤§ããªå¿œç­”ãƒ—ãƒ¼ãƒ«ã‹ã‚‰ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ã‚‚ã®ã§ã€å¿œç­”é–“ã®æ¯”è¼ƒãŒæœ‰ç›Šãªä¿¡å·ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚„ã€ç•°ãªã‚‹å‡ºåŠ›ã‚¹ã‚¿ã‚¤ãƒ«ãŒæ–‡è„ˆã«å¿œã˜ã¦å½¹ç«‹ã¤ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã—ãŸã€‚ã¾ãŸã€æœ€å‰ç·šã®ãƒ¢ãƒ‡ãƒ«ã¯åˆæœŸã®æ¤œè¨¼èƒ½åŠ›ãŒå¼±ãã€é€²æ—ã‚’æ¸¬ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ericzhao28/status/1901704339229732874?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã–ã£ãã‚Šã—ã‹èª­ã‚ã¦ã„ãªã„ãŒã€è¤‡æ•°ã®è§£ç­”ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ã€self-verificationã‚’ã•ã›ã¦æœ€ã‚‚è‰¯ã‹ã£ãŸã‚‚ã®ã‚’é¸æŠã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€‚æœ€ã‚‚verificationã‚¹ã‚³ã‚¢ãŒé«˜ã„è§£ç­”ã‚’æœ€çµ‚çš„ã«é¸æŠã—ãŸã„ãŒã€tieã®å ´åˆã‚‚ã‚ã‚‹ã®ã§ãã®å ´åˆã¯è¿½åŠ ã®promptingã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ¯”è¼ƒã—ã‚ˆã‚Šè‰¯ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’é¸æŠã™ã‚‹ã€‚ã“ã‚Œã‚‰ã¯ä¸¦åˆ—ã—ã¦å®Ÿè¡ŒãŒå¯èƒ½ã§ã€æ¢ç´¢ã¨self-verificationã‚’200å€‹ä¸¦åˆ—ã™ã‚‹ã¨Gemini 1.5 Proã§o1-previewã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã§ãã‚‹æ¨¡æ§˜ã€‚Self-consistencyã¨æ¯”è¼ƒã—ã¦ã‚‚ã€gainãŒå¤§ãã„ã€‚å…·ä½“çš„ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯Algorithm1ã‚’å‚ç…§ã®ã“ã¨ã€‚<br><br>&lt;img width="656" height="236" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/a62625e1-5503-459c-91f3-b7018aba76a6"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a62625e1-5503-459c-91f3-b7018aba76a6"&lt;/a&gt;


/&gt;</p>
<p>openreview: 


<a href="https://openreview.net/forum?id=wl3eI4wiE5" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=wl3eI4wiE5</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<span class="issue_date">Issue Date: 2025-03-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1806" target="_blank" rel="noopener noreferrer" class="title-link">All Roads Lead to Likelihood: The Value of Reinforcement Learning in  Fine-Tuning, Gokul Swamy+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦ã€å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸäºŒæ®µéšã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹é †ãŒåŠ¹æœçš„ã§ã‚ã‚‹ç†ç”±ã‚’ç†è«–çš„ãŠã‚ˆã³å®Ÿè¨¼çš„ã«æ¤œè¨ã€‚ç‰¹ã«ã€å¥½ã¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å˜ç´”ãªå ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ã³ã€å¼·åŒ–å­¦ç¿’æ‰‹ç¶šããŒãã®ãƒ¢ãƒ‡ãƒ«ã«æœ€é©ãªãƒãƒªã‚·ãƒ¼ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹èƒ½åŠ›ãŒã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1901392286694678568?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Alignmentã®ãŸã‚ã®Preferenceãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹æ™‚ã«ã€ãã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç›´æ¥æœ€å°¤æ¨å®šã—ã¦ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã™ã‚‹ã®ã§ã¯ãªãã€å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ã€ãã®å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å¼·åŒ–å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€ãªãœå‰è€…ã‚ˆã‚Šã‚‚ï¼ˆåŒã˜ãƒ‡ãƒ¼ã‚¿ç”±æ¥ã§ã‚ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšï¼‰å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã®ã‹ã€ã¨ã„ã†ç–‘å•ã«å¯¾ã—ã¦ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã—ã¦ã„ã‚‹ã€‚</p>
<p>å…¨ãä¸­èº«ã‚’èª­ã‚ã¦ã„ãªã„ãŒã€ç”Ÿæˆã™ã‚‹ã“ã¨ã¨ï¼ˆæ–¹ç­–ãƒ¢ãƒ‡ãƒ«ï¼‰ã¨æ¤œè¨¼ã™ã‚‹ã“ã¨ï¼ˆå ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼‰ã®é–“ã«ã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹å ´åˆï¼ˆã™ãªã‚ã¡ã€ç”Ÿæˆã¨æ¤œè¨¼ã§æ±‚ã‚ã‚‰ã‚Œã‚‹èƒ½åŠ›ãŒç•°ãªã‚‹å ´åˆï¼‰ã€MLEã§ã¯å¯èƒ½ãªã™ã¹ã¦ã®ãƒãƒªã‚·ãƒ¼ã‚’æ¢ç´¢ã™ã‚‹ã“ã¨ã¨ä¼¼ãŸã‚ˆã†ãªã“ã¨ã‚’ã™ã‚‹ã“ã¨ã«ãªã‚‹ãŒã€RLã§ã¯äº‹å‰ã«å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ãã®å ±é…¬ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦æœ€é©ãªãƒãƒªã‚·ãƒ¼ã‚’æ¢ç´¢ã™ã‚‹ã ã‘ãªã®ã§æ¢ç´¢ã™ã‚‹ç©ºé–“ãŒåˆ¶é™ã•ã‚Œã‚‹ï¼ˆï¼ç”Ÿæˆã¨æ¤œè¨¼ã®ã‚®ãƒ£ãƒƒãƒ—ãŒåŸ‹ã¾ã‚‹ï¼‰ã®ã§ã€è‰¯ã„è§£ã«åæŸã—ã‚„ã™ããªã‚‹ã€ã¨ã„ã†ã‚¤ãƒ¡ãƒ¼ã‚¸ãªã‚“ã ã‚ã†ã‹ã€‚<br><img src="https://github.com/user-attachments/assets/121e97a6-120e-4830-9bcf-329129a687eb" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1798" target="_blank" rel="noopener noreferrer" class="title-link">A Survey on Post-training of Large Language Models, Guiyao Tie+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯è‡ªç„¶è¨€èªå‡¦ç†ã«é©å‘½ã‚’ã‚‚ãŸã‚‰ã—ãŸãŒã€å°‚é–€çš„ãªæ–‡è„ˆã§ã®åˆ¶ç´„ãŒæ˜ã‚‰ã‹ã§ã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€é«˜åº¦ãªãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆPoLMsï¼‰ãŒå¿…è¦ã§ã‚ã‚Šã€æœ¬è«–æ–‡ã§ã¯ãã®åŒ…æ‹¬çš„ãªèª¿æŸ»ã‚’è¡Œã†ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã€æ¨è«–ã€åŠ¹ç‡ã€çµ±åˆã¨é©å¿œã®5ã¤ã®ã‚³ã‚¢ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã«ã‚ãŸã‚‹é€²åŒ–ã‚’è¿½è·¡ã—ã€PoLMãŒãƒã‚¤ã‚¢ã‚¹è»½æ¸›ã‚„æ¨è«–èƒ½åŠ›å‘ä¸Šã«å¯„ä¸ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€‚ç ”ç©¶ã¯PoLMã®é€²åŒ–ã«é–¢ã™ã‚‹åˆã®èª¿æŸ»ã§ã‚ã‚Šã€å°†æ¥ã®ç ”ç©¶ã®ãŸã‚ã®æ çµ„ã¿ã‚’æä¾›ã—ã€LLMã®ç²¾åº¦ã¨å€«ç†çš„å …ç‰¢æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Post Trainingã®æ™‚é–“ç™ºå±•ã®å›³è§£ãŒéå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„ï¼ˆãŒã€å³å¯†æ€§ã«ã¯æ¬ ã‘ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚å½“è©²ãƒ¢ãƒ‡ãƒ«ã®æ–°è¦æ€§ã«ãŠã‘ã‚‹ä¸»è¦ãªæŠ€è¡“ã¯ã“ã‚Œã§ã™ã€ã¨ã„ã†å›³ã¨ã—ã¦ã¿ã‚‹ã«ã¯è‰¯ã„ã®ã‹ã‚‚ã—ã‚Œãªã„ï¼‰ã€‚<br>å€‹ã€…ã®æŠ€è¡“ãŒæ‰±ã†ã‚¹ã‚³ãƒ¼ãƒ—ã¨ãƒ¬ã‚¤ãƒ¤ãƒ¼ã€ãƒ‡ãƒ¼ã‚¿ã®æ€§è³ªãŒæƒã£ã¦ã„ãªã„æ°—ãŒã™ã‚‹ã—ã€ãã‚Œãã‚Œã®LLMãŒyè»¸ã®å˜ä¸€ã®æŠ€è¡“ã ã‘ã«ä¾å­˜ã—ã¦ã„ã‚‹ã‚ã‘ã§ã‚‚ãªã„ã€‚ãŒã€å³å¯†ã«å›³ã‚’æ›¸ã„ã¦ã¨è¨€ã‚ã‚ŒãŸæ™‚ã«ã©ã†æ›¸ã‘ã°è‰¯ã„ã‹ã¨å•ã‚ã‚Œã‚‹ã¨é›£ã—ã„æ„Ÿã¯ã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/6cdf060f-1cc9-44cd-b81a-50f4d3c442de" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1900595286898340230?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<span class="issue_date">Issue Date: 2025-03-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1789" target="_blank" rel="noopener noreferrer" class="title-link">Gemini Embedding: Generalizable Embeddings from Gemini, Jinhyuk Lee+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Gemini Embeddingã¯ã€Googleã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«Geminiã‚’æ´»ç”¨ã—ãŸæœ€å…ˆç«¯ã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã§ã€å¤šè¨€èªãŠã‚ˆã³ã‚³ãƒ¼ãƒ‰ç†è§£èƒ½åŠ›ã‚’æ´»ã‹ã—ã¦ä¸€èˆ¬åŒ–å¯èƒ½ãªåŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚äº‹å‰è¨ˆç®—ã•ã‚ŒãŸè¡¨ç¾ã¯ã€åˆ†é¡ã‚„æ¤œç´¢ãªã©ã®ä¸‹æµã‚¿ã‚¹ã‚¯ã«é©ç”¨å¯èƒ½ã§ã€250ä»¥ä¸Šã®è¨€èªã«ã‚ãŸã‚‹100ä»¥ä¸Šã®ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€MMTEBã§è©•ä¾¡ã—ãŸçµæœã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1899667900728037621?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä¸–ã®decoder-onlyãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®embeddingãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ã«ä½œã‚‰ã‚Œã¦ã„ã‚‹ã‹å…·ä½“çš„ã«ã‚ˆãã‚ã‹ã£ã¦ã„ãªã„ã®ã§èª­ã¿ãŸã„</p>
<p>Geminiã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§bi-directionalãªself-attentionã‚’æŒã¤transformer (ãŸã¨ãˆã°BERT)ã§åˆæœŸåŒ–ã—ã€å…¨ã¦ã®tokenã‚’mean poling (HF BERT Modelã®PoolerLayerã®ã‚ˆã†ãªã‚‚ã®)ã™ã‚‹ã“ã¨ã§ãƒˆãƒ¼ã‚¯ãƒ³ã®æƒ…å ±ã‚’å˜ä¸€ã®embeddingã«æ··ãœã‚‹ã€‚<br>å­¦ç¿’ã¯2æ®µéšã®finetuning (pre-finetuning, finetuning)ã«ã‚ˆã£ã¦ã€ãƒ¢ãƒ‡ãƒ«ã‚’Contrastive Learningã™ã‚‹ï¼ˆNCE lossï¼‰ã€‚<br>pre-finetuningã¯noisyã ãŒå¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ï¼ˆwebä¸Šã®ã‚¿ã‚¤ãƒˆãƒ«ã¨paragraphã®ãƒšã‚¢ãªã©ï¼‰ã€ãã®ã‚ã¨ã®finetuningã¯QAãªã©ã®é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã€‚</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1782" target="_blank" rel="noopener noreferrer" class="title-link">LLM Post-Training: A Deep Dive into Reasoning Large Language Models, Komal Kumar+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã«ç„¦ç‚¹ã‚’å½“ã¦ã€çŸ¥è­˜ã®æ´—ç·´ã‚„æ¨è«–ã®æ”¹å–„ã€äº‹å®Ÿã®æ­£ç¢ºæ€§å‘ä¸Šã‚’ç›®æŒ‡ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„å¼·åŒ–å­¦ç¿’ãªã©ã®æˆ¦ç•¥ãŒLLMsã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æœ€é©åŒ–ã—ã€å®Ÿä¸–ç•Œã®ã‚¿ã‚¹ã‚¯ã¸ã®é©å¿œæ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ä¸»è¦ãªèª²é¡Œã¨ã—ã¦å£Šæ»…çš„ãªå¿˜å´ã‚„å ±é…¬ãƒãƒƒã‚­ãƒ³ã‚°ã‚’åˆ†æã—ã€ä»Šå¾Œã®ç ”ç©¶æ–¹å‘æ€§ã‚’ç¤ºã™å…¬é–‹ãƒªãƒã‚¸ãƒˆãƒªã‚‚æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>éå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„ã€‚<br><img src="https://github.com/user-attachments/assets/855326f0-bc18-4ce1-9870-7690393af21e" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1896399195596263710?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-03-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1776" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Diffusion Models, Shen Nie+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLaDAã¯ã€è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«ï¼ˆARMsï¼‰ã«ä»£ã‚ã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ã‚¼ãƒ­ã‹ã‚‰è¨“ç·´ã•ã‚Œã€ãƒ‡ãƒ¼ã‚¿ãƒã‚¹ã‚­ãƒ³ã‚°ã‚’é€šã˜ã¦åˆ†å¸ƒã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã€‚åºƒç¯„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¼·åŠ›ãªã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’ç¤ºã—ã€è‡ªå·±æ§‹ç¯‰ã—ãŸARMãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹ã€‚ç‰¹ã«ã€LLaDA 8Bã¯æ–‡è„ˆå†…å­¦ç¿’ã‚„æŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ã«å„ªã‚Œã€é€†è©©ã®å®Œæˆã‚¿ã‚¹ã‚¯ã§GPT-4oã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’ç™ºæ®ã€‚æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ãŒARMsã®å®Ÿè¡Œå¯èƒ½ãªä»£æ›¿æ‰‹æ®µã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1893698288328602022?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/karpathy/status/1894923254864978091"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-03-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1775" target="_blank" rel="noopener noreferrer" class="title-link">Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse   Attention, Jingyang Yuan+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- é•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®ãŸã‚ã«ã€è¨ˆç®—åŠ¹ç‡ã‚’æ”¹å–„ã™ã‚‹ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã€ŒNSAã€ã‚’ææ¡ˆã€‚NSAã¯å‹•çš„ãªéšå±¤ã‚¹ãƒ‘ãƒ¼ã‚¹æˆ¦ç•¥ã‚’ç”¨ã„ã€ãƒˆãƒ¼ã‚¯ãƒ³åœ§ç¸®ã¨é¸æŠã‚’çµ„ã¿åˆã‚ã›ã¦ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ã¨ãƒ­ãƒ¼ã‚«ãƒ«ãªç²¾åº¦ã‚’ä¸¡ç«‹ã€‚å®Ÿè£…æœ€é©åŒ–ã«ã‚ˆã‚Šã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å®Ÿç¾ã—ã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ã§è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã€‚NSAã¯ãƒ•ãƒ«ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¶­æŒã—ã¤ã¤ã€é•·ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¯¾ã—ã¦å¤§å¹…ãªã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1893698286545969311?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ACL'25ã®Best Paperã®ä¸€ã¤:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1950644063952052643?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-02-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1774" target="_blank" rel="noopener noreferrer" class="title-link">From System 1 to System 2: A Survey of Reasoning Large Language Models, Zhong-Zhi Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“ãƒ¬ãƒ™ãƒ«ã®çŸ¥èƒ½ã‚’é”æˆã™ã‚‹ãŸã‚ã«ã¯ã€è¿…é€Ÿãªã‚·ã‚¹ãƒ†ãƒ 1ã‹ã‚‰æ„å›³çš„ãªã‚·ã‚¹ãƒ†ãƒ 2ã¸ã®æ¨è«–ã®æ´—ç·´ãŒå¿…è¦ã€‚åŸºç›¤ã¨ãªã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯è¿…é€Ÿãªæ„æ€æ±ºå®šã«å„ªã‚Œã‚‹ãŒã€è¤‡é›‘ãªæ¨è«–ã«ã¯æ·±ã•ãŒæ¬ ã‘ã‚‹ã€‚æœ€è¿‘ã®æ¨è«–LLMã¯ã‚·ã‚¹ãƒ†ãƒ 2ã®æ„å›³çš„ãªæ¨è«–ã‚’æ¨¡å€£ã—ã€äººé–“ã®ã‚ˆã†ãªèªçŸ¥èƒ½åŠ›ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚æœ¬èª¿æŸ»ã§ã¯ã€LLMã®é€²å±•ã¨ã‚·ã‚¹ãƒ†ãƒ 2æŠ€è¡“ã®åˆæœŸé–‹ç™ºã‚’æ¦‚è¦³ã—ã€æ¨è«–LLMã®æ§‹ç¯‰æ–¹æ³•ã‚„ç‰¹å¾´ã€é€²åŒ–ã‚’åˆ†æã€‚æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ¦‚è¦ã‚’æä¾›ã—ã€ä»£è¡¨çš„ãªæ¨è«–LLMã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¯”è¼ƒã€‚æœ€å¾Œã«ã€æ¨è«–LLMã®é€²å±•ã«å‘ã‘ãŸæ–¹å‘æ€§ã‚’æ¢ã‚Šã€æœ€æ–°ã®é–‹ç™ºã‚’è¿½è·¡ã™ã‚‹ãŸã‚ã®GitHubãƒªãƒã‚¸ãƒˆãƒªã‚’ç¶­æŒã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1894282083956396544?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<span class="issue_date">Issue Date: 2025-02-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1772" target="_blank" rel="noopener noreferrer" class="title-link">SuperGPQA: Scaling LLM Evaluation across 285 Graduate Disciplines, M-A-P Team+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- SuperGPQAã‚’ææ¡ˆã—ã€285ã®å°‚é–€åˆ†é‡ã«ãŠã‘ã‚‹LLMsã®çŸ¥è­˜ã¨æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã€‚Human-LLMå”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ç”¨ã„ã¦ã€ãƒˆãƒªãƒ“ã‚¢ãƒ«ãªè³ªå•ã‚’æ’é™¤ã€‚å®Ÿé¨“çµæœã¯ã€æœ€å…ˆç«¯ã®LLMsã«æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€äººå·¥ä¸€èˆ¬çŸ¥èƒ½ã¨ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’å¼·èª¿ã€‚å¤§è¦æ¨¡ãªã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰å¾—ãŸæ´å¯Ÿã¯ã€ä»Šå¾Œã®ç ”ç©¶ã«å¯¾ã™ã‚‹æ–¹æ³•è«–çš„ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1892779892674351532?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2025-02-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1770" target="_blank" rel="noopener noreferrer" class="title-link">OctoTools: An Agentic Framework with Extensible Tools for Complex   Reasoning, Pan Lu+, NAACL'25</a>
<span class="snippet"><span>GPT Summary</span>- è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã™ã‚‹ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒOctoToolsã€ã‚’ææ¡ˆã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸è¦ã§æ‹¡å¼µå¯èƒ½ãªã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«ã‚«ãƒ¼ãƒ‰ã‚„ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã€ã‚¨ã‚°ã‚¼ã‚­ãƒ¥ãƒ¼ã‚¿ãƒ¼ã‚’å‚™ãˆã€16ã®å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã§GPT-4oã«å¯¾ã—ã¦å¹³å‡9.3%ã®ç²¾åº¦å‘ä¸Šã‚’é”æˆã€‚ã•ã‚‰ã«ã€ä»–ã®æ‰‹æ³•ã‚’æœ€å¤§10.6%ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lupantech/status/1892260474320015861?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>NAACL'25ã§ãƒ™ã‚¹ãƒˆãƒšãƒ¼ãƒ‘ãƒ¼ã«é¸å‡º:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lupantech/status/1919495362102100365?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<span class="issue_date">Issue Date: 2025-02-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1768" target="_blank" rel="noopener noreferrer" class="title-link">NaturalReasoning: Reasoning in the Wild with 2.8M Challenging Questions, Weizhe Yuan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤šæ§˜ã§é«˜å“è³ªãªæ¨è«–è³ªå•ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€280ä¸‡ã®è³ªå•ã‹ã‚‰ãªã‚‹NaturalReasoningãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã€‚çŸ¥è­˜è’¸ç•™å®Ÿé¨“ã«ã‚ˆã‚Šã€å¼·åŠ›ãªæ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒæ¨è«–èƒ½åŠ›ã‚’å¼•ãå‡ºã›ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã—ã€æ•™å¸«ãªã—è‡ªå·±å­¦ç¿’ã«ã‚‚åŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1892041992127021300?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2025-02-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1767" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Test-Time Compute Without Verification or RL is Suboptimal, Amrith Setlur+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RLã‚„æ¢ç´¢ã«åŸºã¥ãæ¤œè¨¼è€…ãƒ™ãƒ¼ã‚¹ï¼ˆVBï¼‰æ‰‹æ³•ãŒã€æ¢ç´¢ã®ç—•è·¡ã‚’è’¸ç•™ã™ã‚‹æ¤œè¨¼è€…ãƒ•ãƒªãƒ¼ï¼ˆVFï¼‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ†ã‚¹ãƒˆæ™‚ã®è¨ˆç®—ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ã¨ã€VFæ‰‹æ³•ã®æœ€é©æ€§ãŒæ‚ªåŒ–ã—ã€VBæ‰‹æ³•ãŒã‚ˆã‚Šè‰¯ãã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚3/8/32Bã‚µã‚¤ã‚ºã®LLMã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã€æ¤œè¨¼ãŒè¨ˆç®—èƒ½åŠ›ã®å‘ä¸Šã«é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1891839822257586310?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1749" target="_blank" rel="noopener noreferrer">s1: Simple test-time scaling, Niklas Muennighoff+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2025-02-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1763" target="_blank" rel="noopener noreferrer" class="title-link">LLM Pretraining with Continuous Concepts, Jihoon Tack+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã«ä»£ã‚ã‚‹æ–°ã—ã„äº‹å‰å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯CoCoMixã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‹ã‚‰å­¦ç¿’ã—ãŸé€£ç¶šçš„ãªæ¦‚å¿µã‚’ãƒˆãƒ¼ã‚¯ãƒ³ã®éš ã‚Œè¡¨ç¾ã¨äº¤äº’ã«æ··ãœã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€CoCoMixã¯å¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã€è§£é‡ˆå¯èƒ½æ€§ã¨æ“ä½œæ€§ã‚‚å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1760" target="_blank" rel="noopener noreferrer" class="title-link">Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time  Scaling, Runze Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Test-Time Scaling (TTS)ã¯ã€LLMsã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹æ‰‹æ³•ã§ã‚ã‚Šã€ãƒãƒªã‚·ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚„PRMã€å•é¡Œã®é›£æ˜“åº¦ãŒTTSã«ä¸ãˆã‚‹å½±éŸ¿ã‚’åˆ†æã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æœ€é©ãªTTSæˆ¦ç•¥ã¯ã“ã‚Œã‚‰ã®è¦ç´ ã«ä¾å­˜ã—ã€å°å‹ãƒ¢ãƒ‡ãƒ«ãŒå¤§å‹ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€1Bã®LLMãŒ405Bã®LLMã‚’è¶…ãˆã‚‹çµæœã‚’å¾—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€TTSãŒLLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æœ‰æœ›ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1758" target="_blank" rel="noopener noreferrer" class="title-link">DeepRAG: Thinking to Retrieval Step by Step for Large Language Models, Xinyan Guan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- DeepRAGãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€æ¤œç´¢å¼·åŒ–æ¨è«–ã‚’ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åŒ–ã€‚ã‚¯ã‚¨ãƒªã‚’åå¾©çš„ã«åˆ†è§£ã—ã€å¤–éƒ¨çŸ¥è­˜ã®å–å¾—ã¨ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯æ¨è«–ã®ä¾å­˜ã‚’å‹•çš„ã«åˆ¤æ–­ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æ¤œç´¢åŠ¹ç‡ã¨å›ç­”ã®æ­£ç¢ºæ€§ã‚’21.99%å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬ã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼<br><br>RAGã§ã‚‚ã€Œæ·±ã„æ¤œç´¢ã€ã‚’å®Ÿç¾ã™ã‚‹æ‰‹æ³•ã€ŒDeepRAGã€, Atsushi Kadowaki, <br>ãƒŠãƒ¬ãƒƒã‚¸ã‚»ãƒ³ã‚¹ - AIçŸ¥è¦‹å…±æœ‰ãƒ–ãƒ­ã‚°:


<a href="https://zenn.dev/knowledgesense/articles/034b613c9fd6d3" target="_blank" rel="noopener noreferrer">https://zenn.dev/knowledgesense/articles/034b613c9fd6d3</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/CodeGeneration.html" target="_blank" rel="noopener noreferrer">#CodeGeneration</a>
<a class="button" href="articles/SyntheticDataGeneration.html" target="_blank" rel="noopener noreferrer">#SyntheticDataGeneration</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1756" target="_blank" rel="noopener noreferrer" class="title-link">ACECODER: Acing Coder RL via Automated Test-Case Synthesis, Huaye Zeng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚³ãƒ¼ãƒ‰ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã®å¯èƒ½æ€§ã‚’æ¢æ±‚ã—ã€è‡ªå‹•åŒ–ã•ã‚ŒãŸå¤§è¦æ¨¡ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹åˆæˆã‚’æ´»ç”¨ã—ã¦ä¿¡é ¼ã§ãã‚‹å ±é…¬ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è³ªå•ã¨ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®ãƒšã‚¢ã‚’ç”Ÿæˆã—ã€ã“ã‚Œã‚’ç”¨ã„ã¦å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚Šã€Llama-3.1-8B-Insã§å¹³å‡10ãƒã‚¤ãƒ³ãƒˆã€Qwen2.5-Coder-7B-Insã§5ãƒã‚¤ãƒ³ãƒˆã®æ€§èƒ½å‘ä¸ŠãŒè¦‹ã‚‰ã‚Œã€7Bãƒ¢ãƒ‡ãƒ«ãŒ236B DeepSeek-V2.5ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã—ã¾ã—ãŸã€‚ã¾ãŸã€å¼·åŒ–å­¦ç¿’ã‚’é€šã˜ã¦HumanEvalã‚„MBPPãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ä¸€è²«ã—ãŸæ”¹å–„ã‚’ç¤ºã—ã€ç‰¹ã«Qwen2.5-Coder-baseã‹ã‚‰ã®RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒHumanEval-plusã§25%ä»¥ä¸Šã€MBPP-plusã§6%ã®æ”¹å–„ã‚’ã‚‚ãŸã‚‰ã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹å¼·åŒ–å­¦ç¿’ã®å¤§ããªå¯èƒ½æ€§ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<span class="issue_date">Issue Date: 2025-02-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1753" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth  Approach, Jonas Geiping+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„è¨€èªãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ææ¡ˆã—ã€æ½œåœ¨ç©ºé–“ã§ã®æš—é»™çš„æ¨è«–ã«ã‚ˆã‚Šãƒ†ã‚¹ãƒˆæ™‚ã®è¨ˆç®—ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ã€‚å†å¸°ãƒ–ãƒ­ãƒƒã‚¯ã‚’åå¾©ã—ã€ä»»æ„ã®æ·±ã•ã«å±•é–‹ã™ã‚‹ã“ã¨ã§ã€å¾“æ¥ã®ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¨ã¯ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã€‚ç‰¹åˆ¥ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’å¿…è¦ã¨ã›ãšã€å°ã•ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§è¤‡é›‘ãªæ¨è«–ã‚’æ‰ãˆã‚‹ã€‚3.5å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã—ã€æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åŠ‡çš„ã«æ”¹å–„ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="articles/TeacherHacking.html" target="_blank" rel="noopener noreferrer">#TeacherHacking</a>
<span class="issue_date">Issue Date: 2025-02-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1751" target="_blank" rel="noopener noreferrer" class="title-link">On Teacher Hacking in Language Model Distillation, Daniil Tiapkin+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜è’¸ç•™éç¨‹ã«ãŠã‘ã‚‹ã€Œæ•™å¸«ãƒãƒƒã‚­ãƒ³ã‚°ã€ã®ç¾è±¡ã‚’èª¿æŸ»ã€‚å›ºå®šã•ã‚ŒãŸã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã‚‹ã¨æ•™å¸«ãƒãƒƒã‚­ãƒ³ã‚°ãŒç™ºç”Ÿã—ã€æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã®é€¸è„±ã‚’æ¤œå‡ºå¯èƒ½ã€‚ä¸€æ–¹ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ç”ŸæˆæŠ€è¡“ã‚’ç”¨ã„ã‚‹ã“ã¨ã§æ•™å¸«ãƒãƒƒã‚­ãƒ³ã‚°ã‚’è»½æ¸›ã§ãã€ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ãŒé‡è¦ãªè¦å› ã§ã‚ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å …ç‰¢ãªè¨€èªãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã«ãŠã‘ã‚‹è’¸ç•™ã®åˆ©ç‚¹ã¨é™ç•Œã«ã¤ã„ã¦ã®ç†è§£ãŒæ·±ã¾ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1888516494100734224?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‡ªåˆ†ã§è’¸ç•™ã™ã‚‹æ©Ÿä¼šã¯ä»Šã®ã¨ã“ã‚ãªã„ãŒã€è¦šãˆã¦ãŠããŸã„ã€‚éå­¦ç¿’ã¨ä¸€ç·’ã§ã€ã“ã†ã„ã†ç¾è±¡ãŒèµ·ã“ã‚‹ã®ã¯æƒ³åƒã§ãã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-02-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1750" target="_blank" rel="noopener noreferrer" class="title-link">Rethinking Mixture-of-Agents: Is Mixing Different Large Language Models  Beneficial?, Wenzhe Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Self-MoAã¯ã€å˜ä¸€ã®é«˜æ€§èƒ½LLMã‹ã‚‰ã®å‡ºåŠ›ã‚’é›†ç´„ã™ã‚‹ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ã§ã‚ã‚Šã€å¾“æ¥ã®MoAã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚AlpacaEval 2.0ã§6.6%ã®æ”¹å–„ã‚’é”æˆã—ã€MMLUã‚„CRUXãªã©ã§ã‚‚å¹³å‡3.8%ã®å‘ä¸Šã‚’è¨˜éŒ²ã€‚å‡ºåŠ›ã®å¤šæ§˜æ€§ã¨å“è³ªã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’èª¿æŸ»ã—ã€ç•°ãªã‚‹LLMã®æ··åˆãŒå“è³ªã‚’ä½ä¸‹ã•ã›ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚Self-MoAã®é€æ¬¡ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚‚åŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1888658770059816968?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-02-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1749" target="_blank" rel="noopener noreferrer" class="title-link">s1: Simple test-time scaling, Niklas Muennighoff+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚¹ãƒˆæ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ç”¨ã„ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆs1Kã‚’ä½œæˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’åˆ¶å¾¡ã™ã‚‹äºˆç®—å¼·åˆ¶ã‚’å°å…¥ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯ä¸æ­£ç¢ºãªæ¨è«–ã‚’ä¿®æ­£ã—ã€Qwen2.5-32B-Instructãƒ¢ãƒ‡ãƒ«ãŒo1-previewã‚’æœ€å¤§27%ä¸Šå›ã‚‹çµæœã‚’é”æˆã€‚ã•ã‚‰ã«ã€ä»‹å…¥ãªã—ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒå¯èƒ½ã¨ãªã£ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ã€ã‚³ãƒ¼ãƒ‰ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1887260791981941121?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/DataDistillation.html" target="_blank" rel="noopener noreferrer">#DataDistillation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-02-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1748" target="_blank" rel="noopener noreferrer" class="title-link">LIMO: Less is More for Reasoning, Yixin Ye+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LIMOãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚ãšã‹817ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«ã§è¤‡é›‘ãªæ•°å­¦çš„æ¨è«–ã‚’åŠ¹æœçš„ã«å¼•ãå‡ºã—ã€AIMEã§57.1%ã€MATHã§94.8%ã®ç²¾åº¦ã‚’é”æˆã€‚å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ä¸€èˆ¬åŒ–ã‚’ä¿ƒã™ã€ŒLess-Is-More Reasoning Hypothesisã€ã‚’ææ¡ˆã€‚LIMOã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æä¾›ã•ã‚Œã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã®è‰¯ã„æ¨è«–ã®å†ç¾æ€§ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1887353699644940456?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-02-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer" class="title-link">Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã‘ã‚‹é•·ã„æ€è€ƒã®é€£é–ï¼ˆCoTsï¼‰æ¨è«–ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’èª¿æŸ»ã—ã€é‡è¦ãªè¦å› ã‚’ç‰¹å®šã€‚ä¸»ãªç™ºè¦‹ã¯ã€(1) æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã¯å¿…é ˆã§ã¯ãªã„ãŒåŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã€(2) æ¨è«–èƒ½åŠ›ã¯è¨ˆç®—ã®å¢—åŠ ã«ä¼´ã„ç¾ã‚Œã‚‹ãŒã€å ±é…¬ã®å½¢çŠ¶ãŒCoTã®é•·ã•ã«å½±éŸ¿ã€(3) æ¤œè¨¼å¯èƒ½ãªå ±é…¬ä¿¡å·ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒé‡è¦ã§ã€ç‰¹ã«åˆ†å¸ƒå¤–ã‚¿ã‚¹ã‚¯ã«åŠ¹æœçš„ã€(4) ã‚¨ãƒ©ãƒ¼ä¿®æ­£èƒ½åŠ›ã¯åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã«å­˜åœ¨ã™ã‚‹ãŒã€RLã‚’é€šã˜ã¦åŠ¹æœçš„ã«å¥¨åŠ±ã™ã‚‹ã«ã¯å¤šãã®è¨ˆç®—ãŒå¿…è¦ã€‚ã“ã‚Œã‚‰ã®æ´å¯Ÿã¯ã€LLMsã®é•·ã„CoTæ¨è«–ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã®æœ€é©åŒ–ã«å½¹ç«‹ã¤ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xiangyue96/status/1887332772198371514?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ƒãƒã‚¹ãƒˆã®ã‚¹ãƒ¬ãƒƒãƒ‰ä¸­ã«è«–æ–‡ã®11å€‹ã®çŸ¥è¦‹ãŒè¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ã©ã‚Œã‚‚éå¸¸ã«èˆˆå‘³æ·±ã„ã€‚DeepSeek-R1ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼ã¨åŒæ§˜ã€<br><br>- Long CoTã¨Short CoTã‚’æ¯”è¼ƒã™ã‚‹ã¨å‰è€…ã®æ–¹ãŒåˆ°é”å¯èƒ½ãªæ€§èƒ½ã®upper bonudãŒé«˜ã„ã“ã¨ã‚„ã€<br>- SFTã‚’å®Ÿæ–½ã—ã¦ã‹ã‚‰RLã‚’ã™ã‚‹ã¨æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚„ã€<br>- RLã®éš›ã«CoTã®Lengthã«é–¢ã™ã‚‹å ±é…¬ã‚’å…¥ã‚Œã‚‹ã“ã¨ã§CoTã®é•·ã•ã‚’æŠ‘ãˆã¤ã¤æ€§èƒ½å‘ä¸Šã§ãã‚‹ã“ã¨ã€<br>- æ•°å­¦ã ã‘ã§ãªãQAãƒšã‚¢ãªã©ã®ãƒã‚¤ã‚¸ãƒ¼ã ãŒæ¤œè¨¼å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚’Verifiableãªå ±é…¬ã¨ã—ã¦åŠ ãˆã‚‹ã¨ä¸€èˆ¬çš„ãªreasoningã‚¿ã‚¹ã‚¯ã§æ•°å­¦ã‚ˆã‚Šã‚‚ã•ã‚‰ã«æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã€<br>- ã‚ˆã‚Šé•·ã„context window sizeã‚’æ´»ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«ã¯ã‚ˆã‚Šå¤šãã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ãªã“ã¨ã€<br>- long CoTã¯RLã«ã‚ˆã£ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«é¡ä¼¼ã—ãŸãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ®µéšã§ãã®èƒ½åŠ›ãŒç²å¾—ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã“ã¨ã€<br>- aha momentã¯ã™ã§ã«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«æ™‚ç‚¹ã§ç²å¾—ã•ã‚Œã¦ãŠã‚ŠVerifiableãªå ±é…¬ã«ã‚ˆã‚‹RLã«ã‚ˆã£ã¦å¼·åŒ–ã•ã‚ŒãŸã‚ã‘ã§ã¯ãªã•ãã†ã€<br><br>ãªã©ã€èˆˆå‘³æ·±ã„çŸ¥è¦‹ãŒç››ã‚Šã ãã•ã‚“ã€‚éå¸¸ã«èˆˆå‘³æ·±ã„ç ”ç©¶ã€‚ã‚ã¨ã§èª­ã‚€ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<span class="issue_date">Issue Date: 2025-02-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1744" target="_blank" rel="noopener noreferrer" class="title-link">Diverse Preference Optimization, Jack Lanchantin+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- Diverse Preference Optimizationï¼ˆDivPOï¼‰ã‚’ææ¡ˆã—ã€å¿œç­”ã®å¤šæ§˜æ€§ã‚’å‘ä¸Šã•ã›ã¤ã¤ç”Ÿæˆç‰©ã®å“è³ªã‚’ç¶­æŒã™ã‚‹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æœ€é©åŒ–æ‰‹æ³•ã‚’ç´¹ä»‹ã€‚DivPOã¯å¿œç­”ã®ãƒ—ãƒ¼ãƒ«ã‹ã‚‰å¤šæ§˜æ€§ã‚’æ¸¬å®šã—ã€å¸Œå°‘ã§é«˜å“è³ªãªä¾‹ã‚’é¸æŠã™ã‚‹ã“ã¨ã§ã€ãƒ‘ãƒ¼ã‚½ãƒŠå±æ€§ã®å¤šæ§˜æ€§ã‚’45.6%ã€ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®å¤šæ§˜æ€§ã‚’74.6%å‘ä¸Šã•ã›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1885399530419450257?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview: 


<a href="https://openreview.net/forum?id=pOq9vDIYev" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=pOq9vDIYev</a>


</p>
<p>DPOã¨åŒã˜æœ€é©åŒ–æ–¹æ³•ã‚’ä½¿ã†ãŒã€Preference Pairã‚’é¸æŠã™ã‚‹éš›ã«ã€å¤šæ§˜æ€§ãŒå¢—åŠ ã™ã‚‹ã‚ˆã†ãªPreference Pairã®é¸æŠã‚’ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®Post-trainingå¾Œã®å¤šæ§˜æ€§ã‚’æãªã‚ãªã„ã‚ˆã†ã«ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã£ã½ã„ã€‚<br>å…·ä½“çš„ã«ã¯ã€Alg.1 ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€å¤šæ§˜æ€§ã®å°ºåº¦Dã‚’å®šç¾©ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã«Nå€‹ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆã•ã›RMã«ã‚ˆã‚Šã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ãŸå¾Œã€RMã®ã‚¹ã‚³ã‚¢ãŒé–¾å€¤ä»¥ä¸Šã®responseã‚’"chosen" response, é–¾å€¤æœªæº€ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ "reject" responseã¨ã¿ãªã—ã€chosen/reject responseé›†åˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚chosen responseé›†åˆã®ä¸­ã‹ã‚‰Dã«åŸºã¥ã„ã¦æœ€ã‚‚å¤šæ§˜æ€§ã®ã‚ã‚‹response y_cã€reject responseé›†åˆã®ä¸­ã‹ã‚‰æœ€ã‚‚å¤šæ§˜æ€§ã®ãªã„response y_r ã‚’ãã‚Œãã‚Œãƒ”ãƒƒã‚¯ã—ã€prompt xã¨ã¨ã‚‚ã«preference pair (x, y_c, y_r) ã‚’æ§‹ç¯‰ã—Preference Pairã«åŠ ãˆã‚‹ã€ã¨ã„ã£ãŸæ“ä½œã‚’å…¨ã¦ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆä¸­ã®promptï¼‰xã«å¯¾ã—ã¦ç¹°ã‚Šè¿”ã™ã“ã¨ã§å®Ÿç¾ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-01-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1740" target="_blank" rel="noopener noreferrer" class="title-link">SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model   Post-training, Tianzhe Chu+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- SFTã¨RLã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã®é•ã„ã‚’ç ”ç©¶ã—ã€GeneralPointsã¨V-IRLã‚’ç”¨ã„ã¦è©•ä¾¡ã€‚RLã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã¨è¦–è¦šå¤‰ç¨®ã«å¯¾ã—ã¦å„ªã‚ŒãŸä¸€èˆ¬åŒ–ã‚’ç¤ºã™ä¸€æ–¹ã€SFTã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜æ†¶ã—åˆ†å¸ƒå¤–ã‚·ãƒŠãƒªã‚ªã«è‹¦åŠ´ã€‚RLã¯è¦–è¦šèªè­˜èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€SFTã¯RLè¨“ç·´ã«ä¸å¯æ¬ ã§ã‚ã‚Šã€å‡ºåŠ›å½¢å¼ã‚’å®‰å®šã•ã›ã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Šã‚’ä¿ƒé€²ã€‚ã“ã‚Œã‚‰ã®çµæœã¯ã€è¤‡é›‘ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹RLã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1884731381517082668?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>openreview:


<a href="https://openreview.net/forum?id=dYur3yabMj&referrer=%5Bthe%20profile%20of%20Yi%20Ma%5D(%2Fprofile%3Fid%3D~Yi_Ma4)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=dYur3yabMj&referrer=%5Bthe%20profile%20of%20Yi%20Ma%5D(%2Fprofile%3Fid%3D~Yi_Ma4)</a>


</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<span class="issue_date">Issue Date: 2025-01-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1739" target="_blank" rel="noopener noreferrer" class="title-link">360Brew: A Decoder-only Foundation Model for Personalized Ranking and  Recommendation, Hamed Firooz+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŠã‚ˆã³æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®èª²é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æŒã¤å¤§è¦æ¨¡åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ãŸç ”ç©¶ã‚’ç´¹ä»‹ã€‚150Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼å°‚ç”¨ãƒ¢ãƒ‡ãƒ«360Brew V1.0ã¯ã€LinkedInã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦30ä»¥ä¸Šã®äºˆæ¸¬ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã—ã€å¾“æ¥ã®å°‚ç”¨ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ä»¥ä¸Šã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚ç‰¹å¾´ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®è¤‡é›‘ã•ã‚’è»½æ¸›ã—ã€è¤‡æ•°ã®ã‚¿ã‚¹ã‚¯ã‚’å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§ç®¡ç†å¯èƒ½ã«ã™ã‚‹åˆ©ç‚¹ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1884455910824948154?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2025-01-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1738" target="_blank" rel="noopener noreferrer" class="title-link">Evolving Deeper LLM Thinking, Kuang-Huei Lee+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Mind Evolutionã¨ã„ã†é€²åŒ–çš„æ¢ç´¢æˆ¦ç•¥ã‚’ææ¡ˆã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦å€™è£œå¿œç­”ã‚’ç”Ÿæˆãƒ»æ´—ç·´ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ¨è«–å•é¡Œã®å½¢å¼åŒ–ã‚’å›é¿ã—ã¤ã¤ã€æ¨è«–ã‚³ã‚¹ãƒˆã‚’åˆ¶å¾¡ã€‚è‡ªç„¶è¨€èªè¨ˆç”»ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ä»–ã®æˆ¦ç•¥ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€TravelPlannerãŠã‚ˆã³Natural Planã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§98%ä»¥ä¸Šã®å•é¡Œã‚’è§£æ±ºã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview: 


<a href="https://openreview.net/forum?id=nGP1UxhAbV&referrer=%5Bthe%20profile%20of%20Kuang-Huei%20Lee%5D(%2Fprofile%3Fid%3D~Kuang-Huei_Lee1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=nGP1UxhAbV&referrer=%5Bthe%20profile%20of%20Kuang-Huei%20Lee%5D(%2Fprofile%3Fid%3D~Kuang-Huei_Lee1)</a>


</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2025-01-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1736" target="_blank" rel="noopener noreferrer" class="title-link">Pre-train and Fine-tune: Recommenders as Large Models, Zhenhao Jiang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èˆˆå‘³ã®å¤‰åŒ–ã‚’æ‰ãˆã‚‹ãŸã‚ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚’å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚æƒ…å ±ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç†è«–ã«åŸºã¥ãã€çŸ¥è­˜åœ§ç¸®ã¨çŸ¥è­˜ãƒãƒƒãƒãƒ³ã‚°ã®äºŒã¤ã®ãƒ•ã‚§ãƒ¼ã‚ºã‚’å®šç¾©ã—ãŸIAKæŠ€è¡“ã‚’è¨­è¨ˆã€‚å®Ÿé¨“ã«ã‚ˆã‚Šå„ªä½æ€§ã‚’ç¤ºã—ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã®å±•é–‹ã‹ã‚‰å¾—ãŸæ•™è¨“ã‚„æ½œåœ¨çš„ãªå•é¡Œã¸ã®è§£æ±ºç­–ã‚‚æç¤ºã€‚IAKæŠ€è¡“ã‚’ç”¨ã„ãŸãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã¯ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ•ãƒ¼ãƒ‰ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã®å±•é–‹ã«ã‚ˆã‚Šå¤§ããªåˆ©ç›Šã‚’ä¸Šã’ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1883719872540254355?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1730" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Humanity's Last Exam, Long Phan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã€Œäººé¡ã®æœ€å¾Œã®è©¦é¨“ï¼ˆHLEï¼‰ã€ã‚’å°å…¥ã—ã€LLMã®èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹æ–°ã—ã„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã€‚HLEã¯2,500ã®è³ªå•ã‹ã‚‰æˆã‚Šã€æ•°å­¦ã‚„è‡ªç„¶ç§‘å­¦ãªã©åºƒç¯„ãªç§‘ç›®ã‚’ã‚«ãƒãƒ¼ã€‚å°‚é–€å®¶ã«ã‚ˆã£ã¦é–‹ç™ºã•ã‚Œã€è‡ªå‹•æ¡ç‚¹ãŒå¯èƒ½ãªå½¢å¼ã§ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¤œç´¢ã§ã¯è¿…é€Ÿã«å›ç­”ã§ããªã„ã€‚æœ€å…ˆç«¯ã®LLMã¯HLEã«å¯¾ã—ã¦ä½ã„ç²¾åº¦ã‚’ç¤ºã—ã€ç¾åœ¨ã®LLMã®èƒ½åŠ›ã¨å°‚é–€å®¶ã®çŸ¥è­˜ã¨ã®é–“ã«å¤§ããªã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã€‚HLEã¯å…¬é–‹ã•ã‚Œã€ç ”ç©¶ã‚„æ”¿ç­–ç«‹æ¡ˆã«å½¹ç«‹ã¦ã‚‰ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>o1, DeepSeekR1ã®æ­£è§£ç‡ãŒ10%æœªæº€ã®æ–°ãŸãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1728" target="_blank" rel="noopener noreferrer" class="title-link">Perspective Transition of Large Language Models for Solving Subjective  Tasks, Xiaolong Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è¦–ç‚¹ã®ç§»è¡Œã‚’é€šã˜ãŸæ¨è«–ï¼ˆRPTï¼‰ã‚’ææ¡ˆã—ã€LLMsãŒä¸»è¦³çš„ãªå•é¡Œã«å¯¾ã—ã¦å‹•çš„ã«è¦–ç‚¹ã‚’é¸æŠã§ãã‚‹æ‰‹æ³•ã‚’ç´¹ä»‹ã€‚åºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€å¾“æ¥ã®å›ºå®šè¦–ç‚¹æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã€æ–‡è„ˆã«å¿œã˜ãŸé©åˆ‡ãªå¿œç­”ã‚’æä¾›ã™ã‚‹èƒ½åŠ›ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rohanpaul_ai/status/1882739526361370737?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview: 


<a href="https://openreview.net/forum?id=cFGPlRony5" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=cFGPlRony5</a>


</p>
<p>"Subjective Task"ã¨ã¯ä¾‹ãˆã°ã€Œãƒ¡ã‚¿ãƒ•ã‚¡ãƒ¼ã®èªè­˜ã€ã‚„ã€Œãƒ€ãƒ¼ã‚¯ãƒ¦ãƒ¼ãƒ¢ã‚¢ã®æ¤œçŸ¥ã€ãªã©ãŒã‚ã‚Šã€ã“ã‚Œã‚‰ã¯å®šé‡åŒ–ã—ã¥ã‚‰ã„èªçŸ¥çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚„ã€ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚„æ„Ÿæƒ…ãªã©ãŒå¼·ãé–¢é€£ã—ã¦ãŠã‚Šã€ç¾çŠ¶ã®LLMã§ã¯ãƒãƒ£ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã ã¨ä¸»å¼µã—ã¦ã„ã‚‹ã€‚<br>Subjective Taskã§ã¯ã€Reasoningãƒ¢ãƒ‡ãƒ«ã®ã‚ˆã†ã«è‡ªå‹•çš„ã«CoTã®pathwayã‚’æ±ºã‚ã‚‹ã®ã¯å›°é›£ã§ã€æ‰‹å‹•ã§pathwayã‚’è¨˜è¿°ã™ã‚‹ã®ã¯ãƒãƒ£ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã§ä¸€è²«æ€§ã‚’æ¬ ãã¨ã—ãŸä¸Šã§ã€è¤‡æ•°ã®è¦–ç‚¹ã‚’çµ„ã¿åˆã‚ã›ãŸPromptingï¼ˆdirect perspective, role-perspective, third-person perspectivfeï¼‰ã‚’å®Ÿæ–½ã—ã€æœ€ã‚‚Confidenceã®é«˜ã„answerã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ã§ã“ã®èª²é¡Œã«å¯¾å‡¦ã™ã‚‹ã¨ä¸»å¼µã—ã¦ã„ã‚‹ã€‚</p>
<p>ã‚¤ãƒ³ãƒˆãƒ­ã—ã‹èª­ã‚ã¦ã„ãªã„ãŒã€è‡ªå‹•çš„ã«CoTã®pathwayã‚’æ±ºã‚ã‚‹ã®ã‚‚æ‰‹å‹•ã§æ±ºã‚ã‚‹ã®ã‚‚é›£ã—ã„ã¨ã„ã†é¢¨ã«ã‚¤ãƒ³ãƒˆãƒ­ã§è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ãŒã€æ‰‹æ³•è‡ªä½“ãŒæœ€çµ‚çš„ã«3ã¤ã®è¦–ç‚¹ã‹ã‚‰å›ç­”ã‚’ç”Ÿæˆã•ã›ã‚‹ã¨ã„ã†æ çµ„ã¿ã«å‰‡ã£ã¦ã„ã‚‹ï¼ˆã¤ã¾ã‚ŠSubjective Taskã‚’è§£ããŸã‚ã®å½¢å¼åŒ–ã§ãã¦ã„ã‚‹ã®ã§ã€è‡ªå‹•çš„ãªæ‰‹æ³•ã§ã‚‚ã§ãã¦ã—ã¾ã†ã®ã§ã¯ãªã„ã‹ï¼Ÿã¨æ„Ÿã˜ãŸï¼‰ã®ã§ã€ã‚¤ãƒ³ãƒˆãƒ­ã§è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ä¸»å¼µã®â€é›£ã—ã•â€ãŒè–„ã‚Œã¦ã—ã¾ã£ã¦ã„ã‚‹ã‹ã‚‚ãƒ»ãƒ»ãƒ»ï¼Ÿã¨æ„Ÿã˜ãŸã€‚è«–æ–‡ãŒè§£ã“ã†ã¨ã—ã¦ã„ã‚‹èª²é¡Œã®â€é›£ã—ã•â€ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ææ–™ãŒã‚‚ã£ã¨ã‚ã£ãŸæ–¹ãŒã‚ˆã‚ŠmotivationãŒåˆ†ã‹ã‚Šã‚„ã™ããªã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€ã¨ã„ã†æ„Ÿæƒ³ã‚’æŒã£ãŸã€‚</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Contents-based.html" target="_blank" rel="noopener noreferrer">#Contents-based</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1666" target="_blank" rel="noopener noreferrer" class="title-link">Cold-Start Recommendation towards the Era of Large Language Models  ï¼ˆLLMsï¼‰: A Comprehensive Survey and Roadmap, Weizhi Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆå•é¡Œã¯ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®é‡è¦ãªèª²é¡Œã§ã‚ã‚Šã€æ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚„ã‚¢ã‚¤ãƒ†ãƒ ã®ãƒ¢ãƒ‡ãƒ«åŒ–ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ã€‚å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æˆåŠŸã«ã‚ˆã‚Šã€CSRã«æ–°ãŸãªå¯èƒ½æ€§ãŒç”Ÿã¾ã‚Œã¦ã„ã‚‹ãŒã€åŒ…æ‹¬çš„ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€CSRã®ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚„é–¢é€£æ–‡çŒ®ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€LLMsãŒæƒ…å ±ã‚’æ´»ç”¨ã™ã‚‹æ–¹æ³•ã‚’æ¢æ±‚ã™ã‚‹ã“ã¨ã§ã€ç ”ç©¶ã¨ç”£æ¥­ç•Œã«æ–°ãŸãªæ´å¯Ÿã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚é–¢é€£ãƒªã‚½ãƒ¼ã‚¹ã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãŸã‚ã«åé›†ãƒ»æ›´æ–°ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1876093584593793091?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<a class="button" href="articles/Workshop.html" target="_blank" rel="noopener noreferrer">#Workshop</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1634" target="_blank" rel="noopener noreferrer" class="title-link">Byte Latent Transformer: Patches Scale Better Than Tokens, Artidoro Pagnoni+, ICML'25 Workshop Tokshop</a>
<span class="snippet"><span>GPT Summary</span>- Byte Latent Transformerï¼ˆBLTï¼‰ã¯ã€ãƒã‚¤ãƒˆãƒ¬ãƒ™ãƒ«ã®LLMã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãƒ™ãƒ¼ã‚¹ã®LLMã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã€æ¨è«–åŠ¹ç‡ã¨å …ç‰¢æ€§ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã€‚BLTã¯ãƒã‚¤ãƒˆã‚’å‹•çš„ã«ã‚µã‚¤ã‚ºå¤‰æ›´å¯èƒ½ãªãƒ‘ãƒƒãƒã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€ãƒ‡ãƒ¼ã‚¿ã®è¤‡é›‘æ€§ã«å¿œã˜ã¦è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’èª¿æ•´ã™ã‚‹ã€‚æœ€å¤§8Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨4Tãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¤ãƒˆã®ãƒ¢ãƒ‡ãƒ«ã§ã®ç ”ç©¶ã«ã‚ˆã‚Šã€å›ºå®šèªå½™ãªã—ã§ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®å¯èƒ½æ€§ãŒç¤ºã•ã‚ŒãŸã€‚é•·ã„ãƒ‘ãƒƒãƒã®å‹•çš„é¸æŠã«ã‚ˆã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®åŠ¹ç‡ãŒå‘ä¸Šã—ã€å…¨ä½“çš„ã«BLTã¯ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>èˆˆå‘³æ·±ã„</p>
<p>å›³ã—ã‹è¦‹ã‚Œã¦ã„ãªã„ãŒã€ãƒã‚¤ãƒˆåˆ—ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰/ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹transformerå­¦ç¿’ã—ã¦è¤‡æ•°ã®ãƒã‚¤ãƒˆåˆ—ã‚’ãƒ‘ãƒƒãƒåŒ–ï¼ˆã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒå¤§ãã„éƒ¨åˆ†ã¯ã‚ˆã‚Šå¤§ããªãƒ‘ãƒƒãƒã«ãƒã‚¤ãƒˆåˆ—ã‚’ã²ã¨ã¾ã¨ã‚ã«ã™ã‚‹ï¼‰ã€ãƒ‘ãƒƒãƒã‹ã‚‰ã®ãƒã‚¤ãƒˆåˆ—ç”Ÿæˆã‚’å¯èƒ½ã«ã—ã€ãƒ‘ãƒƒãƒã‚’å¤‰æ›ã™ã‚‹ã®ã‚’Latent Transformerã§å­¦ç¿’ã•ã›ã‚‹ã‚ˆã†ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br>ã¾ãŸã€äºˆç®—ã«ã‚ˆã£ã¦ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒæ±ºã¾ã£ã¦ã—ã¾ã†ãŒã€ãƒ‘ãƒƒãƒã‚µã‚¤ã‚ºã‚’å¤§ããã™ã‚‹ã“ã¨ã§åŒã˜äºˆç®—ã§ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚‚å¤§ããã§ãã‚‹ã®ãŒBLTã®åˆ©ç‚¹ã¨ã®ã“ã¨ã€‚<br><img src="https://github.com/user-attachments/assets/4d150ea9-34e3-456a-bfda-123eb03ffd7c" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/5884d4ed-6c12-4691-8d13-4b3cccd74ef0" alt="image" loading="lazy"></p>
<p>æ—¥æœ¬èªè§£èª¬:


<a href="https://bilzard.github.io/blog/2025/01/01/byte-latent-transformer.html?v=2" target="_blank" rel="noopener noreferrer">https://bilzard.github.io/blog/2025/01/01/byte-latent-transformer.html?v=2</a>


</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=UZ3J8XeRLw" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=UZ3J8XeRLw</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2024-12-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1586" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Training Large Language Models to Reason in a Continuous Latent Space, Shibo Hao+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„æ¨è«–ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã€ŒCoconutã€ã‚’ææ¡ˆã—ã€LLMã®éš ã‚ŒçŠ¶æ…‹ã‚’é€£ç¶šçš„æ€è€ƒã¨ã—ã¦åˆ©ç”¨ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ¬¡ã®å…¥åŠ›ã‚’é€£ç¶šç©ºé–“ã§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã—ã€è¤‡æ•°ã®æ¨è«–ã‚¿ã‚¹ã‚¯ã§LLMã‚’å¼·åŒ–ã€‚Coconutã¯å¹…å„ªå…ˆæ¢ç´¢ã‚’å¯èƒ½ã«ã—ã€ç‰¹å®šã®è«–ç†æ¨è«–ã‚¿ã‚¹ã‚¯ã§CoTã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚æ½œåœ¨çš„æ¨è«–ã®å¯èƒ½æ€§ã‚’æ¢ã‚‹é‡è¦ãªæ´å¯Ÿã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>Chain of Continuous Thought</p>
<p>é€šå¸¸ã®CoTã¯Rationaleã‚’ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã§ç”Ÿæˆã™ã‚‹ãŒã€Coconutã¯æœ€çµ‚çš„ãªhidden stateã‚’ãã®ã¾ã¾æ¬¡ã‚¹ãƒ†ãƒƒãƒ—ã®å…¥åŠ›ã«ã™ã‚‹ã“ã¨ã§ã€ãƒˆãƒ¼ã‚¯ãƒ³ã«åˆ¶é™ã•ã‚Œãšã«CoTã•ã›ã‚‹ã¨ã„ã†ã“ã¨ã‚‰ã—ã„ã€‚ã‚ã¨ã§ã—ã£ã‹ã‚Šèª­ã‚€<br><img src="https://github.com/user-attachments/assets/b930f44b-96f4-47cd-aa1a-0b5fabde54a5" alt="image" loading="lazy"></p>
<p>ãŠãã‚‰ãå­¦ç¿’ã®éš›ã«å·¥å¤«ãŒå¿…è¦ãªã®ã§æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å·¥å¤«ã—ã¦ã§ãã¾ã™ç³»ã®è©±ã§ã¯ãªã„ã‹ã‚‚</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=tG4SgayTtk" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=tG4SgayTtk</a>


<br><br>ICLR'25ã«rejectã•ã‚Œã¦ã„ã‚‹ã€‚<br>ã–ã£ã¨æœ€åˆã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹Weaknessã‚’èª­ã‚“ã æ„Ÿã˜<br>- è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒåˆæˆãƒ‡ãƒ¼ã‚¿ã—ã‹ãªãã€ã‚ˆã‚Šrealisticãªãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã—ãŸæ–¹ãŒè‰¯ã„<br>- CoTã‚‰éå¸¸ã«ä¸€èˆ¬çš„ã«é©ç”¨å¯èƒ½ãªæŠ€è¡“ãªã®ã§ã€ã‚‚ã£ã¨åºƒç¯„ãªãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã™ã¹ã<br>- GSM8Kã§ã¯å¤§å¹…ã«COCONUTã¯CoTã«æ€§èƒ½ãŒè² ã‘ã¦ã„ã¦ã€ProsQAã§ã®ã¿ã«ã—ã‹CoTã«å‹ã¦ã¦ã„ãªã„<br>- ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®è¿½åŠ ã®å­¦ç¿’ãŒå¿…è¦ã§ã€ãã“ã§èº«ã«ã¤ã‘ãŸreasoningèƒ½åŠ›ãŒæ±åŒ–å¯èƒ½ã‹æ˜ã‚‰ã‹ã§ãªã„<br><br>ã¨ã„ã£ãŸæ„Ÿã˜ã«è¦‹ãˆã‚‹</p>
<p>COLM'25 openreview:<br>


<a href="https://openreview.net/forum?id=Itxz7S4Ip3#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Itxz7S4Ip3#discussion</a>


<br><br>COLM'25ã«Accept</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-12-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1577" target="_blank" rel="noopener noreferrer" class="title-link">Towards Adaptive Mechanism Activation in Language Agent, Ziyang Huang+, COLING'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±æ¢ç´¢ã«ã‚ˆã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ æ´»æ€§åŒ–å­¦ç¿’ï¼ˆALAMAï¼‰ã‚’ææ¡ˆã—ã€å›ºå®šã•ã‚ŒãŸãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ä¾å­˜ã›ãšã«é©å¿œçš„ãªã‚¿ã‚¹ã‚¯è§£æ±ºã‚’ç›®æŒ‡ã™ã€‚èª¿å’Œã®ã¨ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼ˆUniActï¼‰ã‚’æ§‹ç¯‰ã—ã€ã‚¿ã‚¹ã‚¯ç‰¹æ€§ã«å¿œã˜ã¦ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’è‡ªå‹•æ´»æ€§åŒ–ã€‚å®Ÿé¨“çµæœã¯ã€å‹•çš„ã§æ–‡è„ˆã«æ•æ„Ÿãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ æ´»æ€§åŒ–ã®æœ‰åŠ¹æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1863956776623747433?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰‹æ³•ã¨ã—ã¦ã¯ã€SFTã¨KTOã‚’æ´»ç”¨ã—post trainingã™ã‚‹ã‚ˆã†ã§ã‚ã‚‹<br><img src="https://github.com/user-attachments/assets/0eab8029-124d-4ac1-b906-2463472b90b2" alt="image" loading="lazy"><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1472" target="_blank" rel="noopener noreferrer">KTO: Model Alignment as Prospect Theoretic Optimization, Kawin Ethayarajh+, N/A, ICML'24</a>
</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<span class="issue_date">Issue Date: 2024-11-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1541" target="_blank" rel="noopener noreferrer" class="title-link">How Does Critical Batch Size Scale in Pre-training?, Hanlin Zhang+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«ã¯ã€ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆCBSï¼‰ã‚’è€ƒæ…®ã—ãŸä¸¦åˆ—åŒ–æˆ¦ç•¥ãŒé‡è¦ã§ã‚ã‚‹ã€‚CBSã®æ¸¬å®šæ³•ã‚’ææ¡ˆã—ã€C4ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è‡ªå·±å›å¸°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã€‚ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚„å­¦ç¿’ç‡ãªã©ã®è¦å› ã‚’èª¿æ•´ã—ã€CBSãŒãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«æ¯”ä¾‹ã—ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã“ã®çµæœã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ç†è«–çš„åˆ†æã«ã‚ˆã£ã¦æ”¯æŒã•ã‚Œã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¸æŠã®é‡è¦æ€§ã‚‚å¼·èª¿ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Critical Batch Sizeã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«ã¯ã‚ã¾ã‚Šä¾å­˜ã›ãšã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«å¿œã˜ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹<br><img src="https://github.com/user-attachments/assets/4a1a720f-37a1-485d-9b02-bb2e8a5c2da4" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/8bc5f621-caac-438a-afd1-de1d689ee210" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2024-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1505" target="_blank" rel="noopener noreferrer" class="title-link">Mixture-of-Transformers: A Sparse and Scalable Architecture for   Multi-Modal Foundation Models, Weixin Liang+, TMLR'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å‡¦ç†ã‚’åŠ¹ç‡åŒ–ã™ã‚‹ãŸã‚ã«ã€Mixture-of-Transformersï¼ˆMoTï¼‰ã‚’ææ¡ˆã€‚MoTã¯è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã—ã€ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã”ã¨ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åˆ†é›¢ã—ã¦ç‰¹åŒ–ã—ãŸå‡¦ç†ã‚’å®Ÿç¾ã€‚Chameleon 7Bè¨­å®šã§ã¯ã€55.8%ã®FLOPsã§å¯†ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€éŸ³å£°ã‚’å«ã‚€å ´åˆã‚‚37.2%ã®FLOPsã§åŒæ§˜ã®çµæœã‚’é”æˆã€‚ã•ã‚‰ã«ã€Transfusionè¨­å®šã§ã¯ã€7Bã®MoTãƒ¢ãƒ‡ãƒ«ãŒå¯†ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®ç”»åƒæ€§èƒ½ã«å¯¾ã—ã¦FLOPsã®3åˆ†ã®1ã§åŒ¹æ•µã—ã€760Mã®ãƒ¢ãƒ‡ãƒ«ã¯ä¸»è¦ãªç”»åƒç”ŸæˆæŒ‡æ¨™ã§ä¸Šå›ã‚‹çµæœã‚’å¾—ãŸã€‚MoTã¯å®Ÿç”¨çš„ãªåˆ©ç‚¹ã‚‚ç¤ºã—ã€ç”»åƒå“è³ªã‚’47.2%ã€ãƒ†ã‚­ã‚¹ãƒˆå“è³ªã‚’75.6%ã®çµŒéæ™‚é–“ã§é”æˆã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2024-11-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1489" target="_blank" rel="noopener noreferrer" class="title-link">Self-Consistency Preference Optimization, Archiki Prasad+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±èª¿æ•´ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒäººé–“ã®æ³¨é‡ˆãªã—ã«è‡ªã‚‰ã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•ã§ã‚ã‚Šã€è‡ªå·±ä¸€è²«æ€§ã‚’æ´»ç”¨ã—ã¦è¨“ç·´ã‚’è¡Œã†æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€è‡ªå·±ä¸€è²«æ€§å„ªå…ˆæœ€é©åŒ–ï¼ˆScPOï¼‰ã‚’ææ¡ˆã€‚ScPOã¯ä¸€è²«ã—ãŸç­”ãˆã‚’å„ªå…ˆã—ã€GSM8Kã‚„MATHãªã©ã®æ¨è«–ã‚¿ã‚¹ã‚¯ã§å¾“æ¥ã®æ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€æ¨™æº–çš„ãªç›£è¦–å­¦ç¿’ã¨ã®çµ„ã¿åˆã‚ã›ã§ã‚‚çµæœãŒå‘ä¸Šã€‚ZebraLogicã§Llama-3 8Bã‚’å¾®èª¿æ•´ã—ã€ä»–ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’è¶…ãˆã‚‹æˆæœã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1854532624116547710?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Self-Consistencyã®ã‚ˆã†ã«ã€ãƒ¢ãƒ‡ãƒ«ã«è¤‡æ•°ã®å‡ºåŠ›ã‚’ã•ã›ã¦ã€æœ€ã‚‚é »åº¦ãŒé«˜ã„å›ç­”ã¨é »åº¦ãŒä½ã„å›ç­”ã®2ã¤ã§DPOã®ãƒšã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—å­¦ç¿’ã€‚é »åº¦ã®å·®ã«ã‚ˆã£ã¦é‡ã¿ã‚’æ±ºã‚ã¦lossã«çµ„ã¿è¾¼ã¿ã“ã®ã‚ˆã¤ãªå‡¦ç†ã‚’ç¹°ã‚Šè¿”ã—å­¦ç¿’ã™ã‚‹ã¨æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã€ã¨ã„ã£ãŸè©±ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/040ffe7c-6e89-4b58-85dd-ce1bc78195cb" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/45bbb1e6-145c-4c49-943d-4dfa25812264" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/35905525-b03f-4fe3-a0e6-89a89cf4ed29" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/45e87ec6-1ebb-4aa8-80ae-0f9072e670d9" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2024-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1466" target="_blank" rel="noopener noreferrer" class="title-link">Differential Transformer, Tianzhu Ye+, N_A, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- Diff Transformerã¯ã€é–¢é€£ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¸ã®æ³¨æ„ã‚’å¼·åŒ–ã—ã€ãƒã‚¤ã‚ºã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚å·®åˆ†æ³¨æ„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ç”¨ã„ã¦ã€æ³¨æ„ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ãªæ³¨æ„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¿ƒé€²ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€Diff TransformerãŒå¾“æ¥ã®Transformerã‚’ä¸Šå›ã‚Šã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚„å¹»è¦šã®è»½æ¸›ã«ãŠã„ã¦é¡•è‘—ãªåˆ©ç‚¹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€æ–‡è„ˆå†…å­¦ç¿’ã«ãŠã„ã¦ã‚‚ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€å …ç‰¢æ€§ã‚’é«˜ã‚ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Diff Transformerã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é€²å±•ã«å¯„ä¸ã™ã‚‹æœ‰æœ›ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æœ€è¿‘ã®MSã¯ãªã‹ãªã‹ã™ã”ã„ï¼ˆå°ä¸¦æ„Ÿ</p>
<p>
<strong># æ¦‚è¦<br><br>attention scoreã®ãƒã‚¤ã‚ºã‚’ä½æ¸›ã™ã‚‹ã‚ˆã†ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ã—ã¦ã€äºŒã¤ã®QKVã‚’ç”¨æ„ã—ã€ä¸¡è€…ã®å·®åˆ†ã‚’å–ã‚‹ã“ã¨ã§æœ€çµ‚çš„ãªattentiok scoreã‚’è¨ˆç®—ã™ã‚‹Differential Attentionã‚’ææ¡ˆã—ãŸã€‚<br><br><br><br>attentionã®noiseã®ä¾‹ã€‚answerã¨æ¯”è¼ƒã—ã¦irrelevantãªcontextã«attention scoreãŒé«˜ã„ã‚¹ã‚³ã‚¢ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã—ã¾ã†ï¼ˆå›³å·¦ï¼‰ã€‚differential transformerãŒææ¡ˆã™ã‚‹differential attentionã§ã¯ã€ãƒã‚¤ã‚ºã‚’æè¨€ã—ã€é‡è¦ãªcontextã®attention scoreãŒé«˜ããªã‚‹ã‚ˆã†ã«ãªã‚‹ï¼ˆå›³ä¸­å¤®ï¼‰ã€ã‚‰ã—ã„ã€‚<br><br><img src="https://github.com/user-attachments/assets/6033f477-d4bf-492d-9360-74f2849ce40e" alt="image" loading="lazy"><br><br><br><br># Differential Attentionã®æ¦‚è¦ã¨è¨ˆç®—å¼<br><br><img src="https://github.com/user-attachments/assets/b77facd8-7cf2-43ab-8947-2f775423f0a0" alt="image" loading="lazy"><br><br><br><br>æ•°å¼ã§è¦‹ã‚‹ã¨ã“ã®ã‚ˆã†ã«ãªã£ã¦ãŠã‚Šã€äºŒã¤ã®QKã‚’ã©ã®ç¨‹åº¦ã®å¼·ã•ã§äº¤äº’ä½œç”¨ã•ã›ã‚‹ã‹ã‚’Î»ã§åˆ¶å¾¡ã—ã€Î»ã‚‚ãã‚Œãã‚Œã®QKã‹ã‚‰å°å‡ºã™ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/c58a4d04-a453-4aef-aa40-7de872117482" alt="image" loading="lazy">&lt;/p&gt;<p>QA, æ©Ÿæ¢°ç¿»è¨³, æ–‡æ›¸åˆ†é¡, ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãªã©ã®æ§˜ã€…ãªNLPã‚¿ã‚¹ã‚¯ãŒå«ã¾ã‚Œã‚‹Eval Harnessãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯ã€åŒè¦æ¨¡ã®transformerãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«outperformã€‚ãŸã ã—ã€3Bã§ã—ã‹å®Ÿé¨“ã—ã¦ã„ãªã„ã‚ˆã†ãªã®ã§ã€ã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«ãªã£ãŸã¨ãã«gainãŒã‚ã‚‹ã‹ã¯ç¤ºã•ã‚Œã¦ã„ãªã„ç‚¹ã«ã¯æ³¨æ„ã€‚<br><img src="https://github.com/user-attachments/assets/384605ed-e4e4-4a17-83c8-506f8e3e2e4c" alt="image" loading="lazy"></p>
<p>ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ï¼‰ã¨ã€å­¦ç¿’ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«ã¤ã„ã¦ã‚‚èª¿æŸ»ã—ãŸçµæœã€LLaMAã¨æ¯”è¼ƒã—ã¦ã€ã‚ˆã‚Šå°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°/å­¦ç¿’ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã§åŒç­‰ã®lossã‚’é”æˆã€‚<br><img src="https://github.com/user-attachments/assets/5d2d1dfc-4197-4b36-9f3d-79a3ed18fe3f" alt="image" loading="lazy"></p>
<p>64Kã«context sgzeã‚’æ‹¡å¼µã—ã€1.5B tokenã§3Bãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ å­¦ç¿’ã‚’ã—ãŸã¨ã“ã‚ã€ã“ã‚Œã‚‚transformerã¨æ¯”ã¹ã¦ã‚ˆã‚Šå°ã•ã„lossã‚’é”æˆ<img src="https://github.com/user-attachments/assets/f911a4f9-d175-4ea2-825b-9776be6042e5" alt="image" loading="lazy"></p>
<p>contextä¸­ã«åŸ‹ã‚è¾¼ã¾ã‚ŒãŸé‡è¦ãªæƒ…å ±ï¼ˆä»Šå›ã¯ã‚¯ã‚¨ãƒªã«å¯¾å¿œã™ã‚‹magic numberï¼‰ã‚’æŠ½å‡ºã™ã‚‹ã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ã‚‚å‘ä¸Šã€‚Needleï¼ˆNï¼‰ã¨å‘¼ã°ã‚Œã‚‹æ­£è§£ã®magic numberãŒå«ã¾ã‚Œã‚‹æ–‡ã‚’contextä¸­ã®æ§˜ã€…ãªæ·±ã•ã«é…ç½®ã—ã€åŒæ™‚ã«distractorã¨ãªã‚‹æ–‡ã‚‚ãƒ©ãƒ³ãƒ€ãƒ ã«é…ç½®ã™ã‚‹ã€‚ã“ã‚Œã«å¯¾ã—ã¦ã‚¯ã‚¨ãƒªï¼ˆRï¼‰ãŒå…¥åŠ›ã•ã‚ŒãŸã¨ãã«ã€ã©ã‚Œã ã‘æ­£ã—ã„æƒ…å ±ã‚’contextã‹ã‚‰æŠ½å‡ºã§ãã‚‹ã‹ã€ã¨ã„ã†è©±ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>ã“ã‚Œã‚‚æ€§èƒ½ãŒå‘ä¸Šã€‚ç‰¹ã«ã‚¯ã‚¨ãƒªã¨NeedleãŒè¤‡æ•°ã®è¦ç´ ã§æ§‹æˆã•ã‚Œã¦ã„ã‚Œå ´åˆã®æ€§èƒ½ãŒé«˜ãï¼ˆä¸‹è¡¨ï¼‰ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¸­ã®æ§˜ã€…ãªä½ç½®ã«åŸ‹ã‚è¾¼ã¾ã‚ŒãŸNeedleã‚’æŠ½å‡ºã™ã‚‹æ€§èƒ½ã‚‚é«˜ã„ï¼ˆä¸Šã®matrixï¼‰<br><br><img src="https://github.com/user-attachments/assets/f4d084dc-fac5-427d-8185-5604e55cf051" alt="image" loading="lazy"><br><br>[Needle-In-A-Haystack test](


<a href="https://www.perplexity.ai/search/needle-in-a-haystack-testtohan-jF7LXWQPSMqKI2pZSchjpA#0)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/search/needle-in-a-haystack-testtohan-jF7LXWQPSMqKI2pZSchjpA#0)</a>


</p>
<p>Many shotã®ICLèƒ½åŠ›ã‚‚å‘ä¸Š<br><img src="https://github.com/user-attachments/assets/c935ba93-9915-45c8-aaa6-f073d62fdd3b" alt="image" loading="lazy"></p>
<p>è¦ç´„ã‚¿ã‚¹ã‚¯ã§ã®hallucinationã‚‚ä½æ¸›ã€‚ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã¨æ­£è§£è¦ç´„ã‚’å…¥åŠ›ã—ã€GPT4-oã«hallucinationã®æœ‰ç„¡ã‚’åˆ¤å®šã•ã›ã¦è©•ä¾¡ã€‚ã“ã‚Œã¯å…ˆè¡Œç ”ç©¶ã§äººæ‰‹ã§ã®è©•ä¾¡ã¨é«˜ã„agreementãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/6fd97af4-fec6-44e8-b00c-d5ba26770a84" alt="image" loading="lazy"></p>
<p>ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§LLMå…¨ä½“ã®æ€§èƒ½ã‚’åº•ä¸Šã’ã—ã¦ã„ã‚‹ç´ æ™´ã‚‰ã—ã„æˆæœã«è¦‹ãˆã‚‹ã€‚æ–œã‚èª­ã¿ãªã®ã§èª­ã¿é£›ã°ã—ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãŒã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need, Suriya Gunasekar+, N/A, arXiv'23</a>
&lt;/strong&gt;
<br>
 ã®ã‚ˆã†ã«é«˜å“è³ªãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ãŸå ´åˆã‚‚åŒæ§˜ã®åŠ¹æœãŒç™ºç¾ã™ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ<br>attentionã®ã‚¹ã‚³ã‚¢ãŒnoisyã¨ã„ã†ã“ã¨ã¯ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æ´—ç·´ã•ã›ã‚‹ã“ã¨ã§ã‚‚æ”¹å–„ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need, Suriya Gunasekar+, N/A, arXiv'23</a>
 ã¯ã“ã‚Œã‚’ãƒ‡ãƒ¼ã‚¿ã§æ”¹å–„ã—ã€ã“ã¡ã‚‰ã®ç ”ç©¶ã¯ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§æ”¹å–„ã—ãŸã€ã¿ãŸã„ãªæ‰ãˆæ–¹ã‚‚ã§ãã‚‹ã®ã‹ã‚‚ã—ã‚Œãªã„ã€‚</p>
<p>ã¡ãªã¿ã«Flash Attentionã¨ã—ã¦ã®å®Ÿè£…æ–¹æ³•ã‚‚ææ¡ˆã•ã‚Œã¦ãŠã‚Šã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¯é€šå¸¸ã®attentionã¨æ¯”ã¹ã¦ã‚€ã—ã‚å‘ä¸Šã—ã¦ã„ã‚‹ã®ã§å®Ÿç”¨çš„ãªæ‰‹æ³•ã§ã‚‚ã‚ã‚‹ã€‚ã™ã”ã„ã€‚<br><img src="https://github.com/user-attachments/assets/c0212cd8-55f5-4991-b256-0ff2bce35669" alt="image" loading="lazy"></p>
<p>ã‚ã¨ã“ã‚Œã€äº‹å‰å­¦ç¿’ã¨Instruction Tuningã‚’é€šå¸¸ã®ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã§å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã§SFTã™ã‚‹ã¨ãã«å°å…¥ã—ãŸã‚‰downstream taskã®æ€§èƒ½å‘ä¸Šã™ã‚‹ã‚“ã ã‚ã†ã‹ã€‚ã‚‚ã—ãã†ãªã‚‰ç´ æ™´ã‚‰ã—ã„</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=OvoCm1gGhN" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=OvoCm1gGhN</a>


</p>
<p>GroupNormalizationã«ã¤ã„ã¦ã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1856" target="_blank" rel="noopener noreferrer">Group Normalization, Yuxin Wu+, arXiv'18</a>
</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2024-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1460" target="_blank" rel="noopener noreferrer" class="title-link">LLMs Know More Than They Show: On the Intrinsic Representation of LLM  Hallucinations, Hadas Orgad+, N_A, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯ã€Œå¹»è¦šã€ã¨å‘¼ã°ã‚Œã‚‹ã‚¨ãƒ©ãƒ¼ã‚’ç”Ÿæˆã™ã‚‹ãŒã€å†…éƒ¨çŠ¶æ…‹ãŒçœŸå®Ÿæ€§ã«é–¢ã™ã‚‹æƒ…å ±ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€çœŸå®Ÿæ€§æƒ…å ±ãŒç‰¹å®šã®ãƒˆãƒ¼ã‚¯ãƒ³ã«é›†ä¸­ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã€ã“ã‚Œã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã‚¨ãƒ©ãƒ¼æ¤œå‡ºæ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã—ã‹ã—ã€ã‚¨ãƒ©ãƒ¼ãƒ‡ã‚£ãƒ†ã‚¯ã‚¿ãƒ¼ã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé–“ã§ä¸€èˆ¬åŒ–ã«å¤±æ•—ã—ã€çœŸå®Ÿæ€§ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯æ™®éçš„ã§ã¯ãªã„ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚‹ã€‚ã¾ãŸã€å†…éƒ¨è¡¨ç¾ã‚’ç”¨ã„ã¦ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡ã‚’äºˆæ¸¬ã—ã€ç‰¹åŒ–ã—ãŸç·©å’Œæˆ¦ç•¥ã®é–‹ç™ºã‚’ä¿ƒé€²ã™ã‚‹ã€‚ã•ã‚‰ã«ã€å†…éƒ¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨å¤–éƒ¨ã®æŒ¯ã‚‹èˆã„ã¨ã®ä¸ä¸€è‡´ãŒå­˜åœ¨ã—ã€æ­£ã—ã„ç­”ãˆã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã„ã¦ã‚‚èª¤ã£ãŸç­”ãˆã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMã®ã‚¨ãƒ©ãƒ¼ç†è§£ãŒæ·±ã¾ã‚Šã€ä»Šå¾Œã®ç ”ç©¶ã«å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç‰¹å®šã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒLLMã®trustfulnessã«é›†ä¸­ã—ã¦ã„ã‚‹ã“ã¨ã‚’å®Ÿé¨“çš„ã«ç¤ºã—ã€ã‹ã¤å†…éƒ¨ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸrepresentationã¯æ­£ã—ã„ç­”ãˆã®ã‚‚ã®ã¨ãªã£ã¦ã„ã‚‹ã®ã«ã€ç”Ÿæˆçµæœã«èª¤ã‚ŠãŒç”Ÿã˜ã‚‹ã‚ˆã†ãªä¸æ•´åˆãŒç”Ÿã˜ã‚‹ã“ã¨ã‚‚ç¤ºã—ãŸã‚‰ã—ã„</p>
<p>openreview: 


<a href="https://openreview.net/forum?id=KRnsX5Em3W" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=KRnsX5Em3W</a>


</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2024-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1454" target="_blank" rel="noopener noreferrer" class="title-link">Llama-3.1-Nemotron-70B-Instruct, Nvidia, ï¼ˆICLR'25ï¼‰, 2024.10</a>
<span class="snippet"><span>GPT Summary</span>- å ±é…¬ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«ã¯Bradley-Terryã‚¹ã‚¿ã‚¤ãƒ«ã¨å›å¸°ã‚¹ã‚¿ã‚¤ãƒ«ãŒã‚ã‚Šã€ãƒ‡ãƒ¼ã‚¿ã®ä¸€è‡´ãŒé‡è¦ã ãŒã€é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚HelpSteer2ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ã€Bradley-Terryè¨“ç·´ç”¨ã®å¥½ã¿ã®æ³¨é‡ˆã‚’å…¬é–‹ã—ã€åˆã‚ã¦ä¸¡ãƒ¢ãƒ‡ãƒ«ã®ç›´æ¥æ¯”è¼ƒã‚’è¡Œã£ãŸã€‚ã“ã‚Œã«åŸºã¥ãã€ä¸¡è€…ã‚’çµ„ã¿åˆã‚ã›ãŸæ–°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€Llama-3.1-70B-Instructãƒ¢ãƒ‡ãƒ«ãŒRewardBenchã§94.1ã®ã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚ã•ã‚‰ã«ã€REINFORCEã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ã¦æŒ‡ç¤ºãƒ¢ãƒ‡ãƒ«ã‚’èª¿æ•´ã—ã€Arena Hardã§85.0ã‚’è¨˜éŒ²ã—ãŸã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>MTBench, Arena Hardã§GPT4o-20240513,Claude-3.5-sonnet-20240620ã‚’outperformã€‚Response lengthã®å¹³å‡ãŒé•·ã„ã“ã¨æ¨¡æ§˜<br><img src="https://github.com/user-attachments/assets/e7fe1193-f3c6-4d17-8077-2f4742aef00c" alt="image" loading="lazy"></p>
<p>openreview:


<a href="https://openreview.net/forum?id=MnfHxPP5gs" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=MnfHxPP5gs</a>


</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<span class="issue_date">Issue Date: 2024-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1388" target="_blank" rel="noopener noreferrer" class="title-link">Generative Verifiers: Reward Modeling as Next-Token Prediction, Lunjun Zhang+, N_A, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¤œè¨¼å™¨ã¨å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦LLMã®æ¨è«–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€ç”Ÿæˆçš„æ¤œè¨¼å™¨ï¼ˆGenRMï¼‰ã‚’ææ¡ˆã€‚GenRMã¯æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã‚’ç”¨ã„ã¦æ¤œè¨¼ã¨è§£æ±ºç­–ç”Ÿæˆã‚’å…±åŒã§è¡Œã„ã€æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„æ€è€ƒã®é€£é–ã‚’æ´»ç”¨ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€GenRMã¯å¾“æ¥ã®æ¤œè¨¼å™¨ã‚’ä¸Šå›ã‚Šã€å•é¡Œè§£æ±ºç‡ãŒ16-64%å‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã™ã‚‹å›ç­”ã‚’ç”Ÿæˆã—ãŸã®ã¡ã«ã€ãã®å›ç­”ã‚’verifyã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ— + verifyã®çµæœã‹ã‚‰å›ç­”ã‚’ä¿®æ­£ã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ã‚’å…¨ã¦concatã—ãŸå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’next token predictionã§ç”¨ã„ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€ãƒ¢ãƒ‡ãƒ«è‡ªèº«ã«è‡ªåˆ†ã®å›ç­”ã‚’verifyã™ã‚‹èƒ½åŠ›ã‚’èº«ã«ã¤ã‘ã•ã›ã‚‹ã“ã¨ãŒã§ããŸçµæœæ€§èƒ½ãŒå‘ä¸Šã—ã¾ã—ãŸã€ã¨ã„ã†ç ”ç©¶ã‚‰ã—ã„ã€‚ã¾ãŸã€Self-consistency <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/558" target="_blank" rel="noopener noreferrer">Self-consistency improves chain of thought reasoning in language models, Wang+, Google Research, ICLR'23</a>
 ã®ã‚ˆã†ã«è¤‡æ•°ã®ç•°ãªã‚‹CoTã‚’ä¸¦åˆ—ã—ã¦å®Ÿè¡Œã•ã›ã€ãã®majority votingã‚’ã¨ã‚‹ã“ã¨ã§ã•ã‚‰ã«æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã€‚<br><br><br><br>&lt;img width="663" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/e6ebd308-fc77-4c5b-80c2-37e3615f48af"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/e6ebd308-fc77-4c5b-80c2-37e3615f48af"&lt;/a&gt;


&gt;<br><br>&lt;img width="703" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/9cf3dfe7-be09-4053-a760-9ec9ed993b33"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/9cf3dfe7-be09-4053-a760-9ec9ed993b33"&lt;/a&gt;


&gt;<br><br></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2024-04-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1286" target="_blank" rel="noopener noreferrer" class="title-link">Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws, Zeyuan Allen-Zhu+, N_A, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã¨èƒ½åŠ›ã®é–¢ä¿‚ã‚’è¨˜è¿°ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸç ”ç©¶ã€‚ãƒ¢ãƒ‡ãƒ«ãŒæ ¼ç´ã™ã‚‹çŸ¥è­˜ãƒ“ãƒƒãƒˆæ•°ã‚’æ¨å®šã—ã€äº‹å®ŸçŸ¥è­˜ã‚’ã‚¿ãƒ—ãƒ«ã§è¡¨ç¾ã€‚è¨€èªãƒ¢ãƒ‡ãƒ«ã¯1ã¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚ãŸã‚Š2ãƒ“ãƒƒãƒˆã®çŸ¥è­˜ã‚’æ ¼ç´å¯èƒ½ã§ã‚ã‚Šã€7Bãƒ¢ãƒ‡ãƒ«ã¯14Bãƒ“ãƒƒãƒˆã®çŸ¥è­˜ã‚’æ ¼ç´å¯èƒ½ã€‚ã•ã‚‰ã«ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æœŸé–“ã€ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€é‡å­åŒ–ã€ç–ãªåˆ¶ç´„ã€ãƒ‡ãƒ¼ã‚¿ã®ä¿¡å·å¯¾é›‘éŸ³æ¯”ãŒçŸ¥è­˜æ ¼ç´å®¹é‡ã«å½±éŸ¿ã™ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚ãƒ­ãƒ¼ã‚¿ãƒªãƒ¼åŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨ã—ãŸGPT-2ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€çŸ¥è­˜ã®æ ¼ç´ã«ãŠã„ã¦LLaMA/Mistralã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ç«¶åˆã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«ãƒ‰ãƒ¡ã‚¤ãƒ³åã‚’è¿½åŠ ã™ã‚‹ã¨çŸ¥è­˜å®¹é‡ãŒå¢—åŠ ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1779640139263901698?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span></strong></p>
<p>è§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
</p>
<p>openreview:


<a href="https://openreview.net/forum?id=FxNNiUgtfa" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=FxNNiUgtfa</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2024-03-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1257" target="_blank" rel="noopener noreferrer" class="title-link">Evolutionary Optimization of Model Merging Recipes, Takuya Akiba+, N_A, Nature Machine Intelligence'25</a>
<span class="snippet"><span>GPT Summary</span>- é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã—ãŸæ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€å¼·åŠ›ãªåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•ç”Ÿæˆã‚’å®Ÿç¾ã€‚LLMã®é–‹ç™ºã«ãŠã„ã¦ã€äººé–“ã®ç›´æ„Ÿã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã«ä¾å­˜ã›ãšã€å¤šæ§˜ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®åŠ¹æœçš„ãªçµ„ã¿åˆã‚ã›ã‚’è‡ªå‹•çš„ã«ç™ºè¦‹ã™ã‚‹ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€æ—¥æœ¬èªã®LLMã¨æ•°å­¦æ¨è«–èƒ½åŠ›ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ãªã©ã€ç•°ãªã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³é–“ã®çµ±åˆã‚’å®¹æ˜“ã«ã—ã€æ—¥æœ¬èªVLMã®æ€§èƒ½å‘ä¸Šã«ã‚‚è²¢çŒ®ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¸ã®è²¢çŒ®ã¨è‡ªå‹•ãƒ¢ãƒ‡ãƒ«æ§‹æˆã®æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ å°å…¥ã«ã‚ˆã‚Šã€åŸºç›¤ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã«ãŠã‘ã‚‹åŠ¹ç‡çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¨¡ç´¢ã€‚</span>
<span class="snippet"><span>Comment</span><p>è¤‡æ•°ã®LLMã‚’èåˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã®è©±ã€‚æ—¥æœ¬èªLLMã¨è‹±èªã®æ•°å­¦LLNã‚’ãƒãƒ¼ã‚¸ã•ã›ã‚‹ã“ã¨ã§æ—¥æœ¬èªã®æ•°å­¦æ€§èƒ½ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ãŸã‚Šã€LLMã¨VLMã‚’èåˆã—ãŸã‚Šã™ã‚‹ã“ã¨ã§ã€æ—¥æœ¬ã«ã—ã‹å­˜åœ¨ã—ãªã„æ¦‚å¿µã®ç”»åƒã‚‚ã€ãã¡ã‚“ã¨å›ç­”ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚<br><br>è‘—è€…ã‚¹ãƒ©ã‚¤ãƒ‰ã«ã‚ˆã‚‹ã¨ã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«ã¯base modelãŒåŒä¸€ã§ãªã„ã¨ã†ã¾ãã„ã‹ãªã‹ã£ãŸã‚Šï¼ˆé‡ã¿ã®ç·šå‹çµåˆã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ï¼‰ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¢—æ¸›ã—ãŸã‚Šï¼ˆè¤‡æ•°LLMã®Layerã‚’é‡ã¿ã¯å¼„ã‚‰ãšå†é…ç½®ã™ã‚‹ï¼‰ã€‚ã¾ãŸæ—¥æœ¬èªLLMã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã‚’å®Ÿæ–½ã—ã‚ˆã†ã¨ã™ã‚‹ã¨ã€ãƒãƒ¼ã‚¸å…ƒã®LLMãŒå°‘ãªã‹ã£ãŸã‚Šã€åºƒç¯„å›²ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ‰±ã†ã¨ãƒãƒ¼ã‚¸ãŒã†ã¾ãã„ã‹ãªã„ã€ã¨ã„ã£ãŸèª²é¡ŒãŒã‚ã£ãŸã€‚æœ¬ç ”ç©¶ã§ã¯ã“ã‚Œã‚‰èª²é¡Œã‚’è§£æ±ºã§ãã‚‹ã€‚</p>
<p>è‘—è€…ã«ã‚ˆã‚‹è³‡æ–™ï¼ˆNLPã‚³ãƒ­ã‚­ã‚¦ãƒ ï¼‰:<br>


<a href="https://speakerdeck.com/iwiwi/17-nlpkorokiumu" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/iwiwi/17-nlpkorokiumu</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2023-07-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/906" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FacTool: Factuality Detection in Generative AI -- A Tool Augmented   Framework for Multi-Task and Multi-Domain Scenarios, I-Chun Chern+, COLM'25, 2023.07</a>
<span class="snippet"><span>GPT Summary</span>- ç”Ÿæˆçš„äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆåˆæˆã¯é€²å±•ã—ãŸãŒã€äº‹å®Ÿèª¤èªã®ç‰¹å®šã«ã¯èª²é¡ŒãŒæ®‹ã‚‹ã€‚ç‰¹ã«ã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äº‹å®Ÿèª¤èªã®ãƒªã‚¹ã‚¯å¢—åŠ ã€é•·æ–‡åŒ–ã«ã‚ˆã‚‹ç²’åº¦ã®æ¬ å¦‚ã€æ˜ç¤ºçš„è¨¼æ‹ ã®ä¸è¶³ãŒå•é¡Œã§ã‚ã‚‹ã€‚ã“ã‚Œã‚‰ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ã‚¿ã‚¹ã‚¯ã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ä¾å­˜ã—ãªã„äº‹å®Ÿèª¤èªæ¤œå‡ºãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯FacToolã‚’ææ¡ˆã€‚çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®QAã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã€æ•°å­¦çš„æ¨è«–ã€ç§‘å­¦æ–‡çŒ®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®4ã¤ã®ã‚¿ã‚¹ã‚¯ã§æœ‰åŠ¹æ€§ã‚’å®Ÿè¨¼ã—ã€ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=hJkQL9VtWT#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=hJkQL9VtWT#discussion</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/MetacognitiveKnowledge/Ability.html" target="_blank" rel="noopener noreferrer">#MetacognitiveKnowledge/Ability</a>
<a class="button" href="articles/SkillTag.html" target="_blank" rel="noopener noreferrer">#SkillTag</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3361" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Metacognitive Capabilities of LLMs: An Exploration in Mathematical   Problem Solving, Aniket Didolkar+, NeurIPS'24, 2024.05</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¡ã‚¿èªçŸ¥çš„çŸ¥è­˜ã‚’æŒã¤å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ãŒã€æ•°å­¦çš„æ¨è«–ã«ãŠã„ã¦é©åˆ‡ãªã‚¹ã‚­ãƒ«ãƒ©ãƒ™ãƒ«ã‚’å‰²ã‚Šå½“ã¦ã‚‹èƒ½åŠ›ã‚’ç¤ºã™ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¬ã‚¤ãƒ‰ã‚’ç”¨ã„ãŸã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³æ‰‹æ³•ã‚’é–‹ç™ºã—ã€ã‚¹ã‚­ãƒ«ãƒ©ãƒ™ãƒ«ã®æ„å‘³çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã†ã€‚å®Ÿé¨“ã§ã¯ã€GPT-4ã«æ•°å­¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«åŸºã¥ãã‚¹ã‚­ãƒ«ãƒ©ãƒ™ãƒ«ã‚’å‰²ã‚Šå½“ã¦ã•ã›ã€ç²¾åº¦å‘ä¸Šã‚’ç¢ºèªã€‚ææ¡ˆæ‰‹æ³•ã¯æ•°å­¦ä»¥å¤–ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã‚‚é©ç”¨å¯èƒ½ã€‚</span>
<span class="snippet"><span>Comment</span><p>StudentPerformancePredictionã®ã‚¹ã‚­ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ã‚ˆã†ãªè©±ã«ãªã£ã¦ããŸã€‚èˆˆå‘³æ·±ã„</p></span><br><br>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3292" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An  Exhaustive Review of Technologies, Research, Best Practices, Applied Research  Challenges and Opportunities, Venkatesh Balavadhani Parthasarathy+, arXiv'24, 2024.08</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬å ±å‘Šæ›¸ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«é–¢ã™ã‚‹ç†è«–ã¨å®Ÿè·µã‚’çµ±åˆçš„ã«æ¤œè¨ã—ã€æ­´å²çš„ãªé€²åŒ–ã‚„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã®æ¯”è¼ƒã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚7æ®µéšã®æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç´¹ä»‹ã—ã€ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç®¡ç†ã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡ã®è‰¯ã„æ‰‹æ³•ï¼ˆLoRAã€Half Fine-Tuningï¼‰ã«é‡ç‚¹ã‚’ç½®ã„ã¦ã„ã¾ã™ã€‚ã¾ãŸã€PPOã‚„DPOãªã©ã®æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚„ã€æ¤œè¨¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ãƒ‡ãƒ—ãƒ­ã‚¤å¾Œã®ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMsã‚„ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã€èª¬æ˜è²¬ä»»ã«é–¢ã™ã‚‹èª²é¡Œã«ã‚‚è§¦ã‚Œã¦ã„ã¾ã™ã€‚ç ”ç©¶è€…ã‚„å®Ÿå‹™è€…ã«å®Ÿç”¨çš„ãªæ´å¯Ÿã‚’æä¾›ã™ã‚‹å†…å®¹ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hesamation/status/1978790875015634988?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3199" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DoRA: Weight-Decomposed Low-Rank Adaptation, Shih-Yang Liu+, ICML'24, 2024.02</a>
<span class="snippet"><span>GPT Summary</span>- LoRAã®ç²¾åº¦ã‚®ãƒ£ãƒƒãƒ—ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã«ã€Weight-Decomposed Low-Rank Adaptationï¼ˆDoRAï¼‰ã‚’ææ¡ˆã€‚DoRAã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®é‡ã¿ã‚’å¤§ãã•ã¨æ–¹å‘ã«åˆ†è§£ã—ã€æ–¹å‘æ€§ã®æ›´æ–°ã«LoRAã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’æœ€å°åŒ–ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LoRAã®å­¦ç¿’èƒ½åŠ›ã¨å®‰å®šæ€§ã‚’å‘ä¸Šã•ã›ã€è¿½åŠ ã®æ¨è«–ã‚³ã‚¹ãƒˆã‚’å›é¿ã€‚ã•ã¾ã–ã¾ãªä¸‹æµã‚¿ã‚¹ã‚¯ã§LoRAã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2928" target="_blank" rel="noopener noreferrer">LoRAã®é€²åŒ–ï¼šåŸºç¤ã‹ã‚‰æœ€æ–°ã®LoRA-Proã¾ã§ , æ¾å°¾ç ”ç©¶æ‰€ãƒ†ãƒƒã‚¯ãƒ–ãƒ­ã‚°, 2025.09</a>
</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3198" target="_blank" rel="noopener noreferrer">Tora: Torchtune-LoRA for RL, shangshang-wang, 2025.10</a>
<br><br>ã§ã¯ã€é€šå¸¸ã®LoRA, QLoRAã ã‘ã§ãªãæœ¬æ‰‹æ³•ã§RLã‚’ã™ã‚‹å®Ÿè£…ã‚‚ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3193" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MobileLLM: Optimizing Sub-billion Parameter Language Models for  On-Device Use Cases, Zechun Liu+, ICLR'24, 2024.02</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¢ãƒã‚¤ãƒ«ãƒ‡ãƒã‚¤ã‚¹å‘ã‘ã«10å„„æœªæº€ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤é«˜å“è³ªãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®è¨­è¨ˆã‚’ææ¡ˆã€‚æ·±ãã¦ç´°ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ´»ç”¨ã—ã€MobileLLMã¨ã„ã†å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ç²¾åº¦ã‚’å‘ä¸Šã€‚ã•ã‚‰ã«ã€é‡ã¿å…±æœ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å°å…¥ã—ã€MobileLLM-LSã¨ã—ã¦ã•ã‚‰ãªã‚‹ç²¾åº¦å‘ä¸Šã‚’å®Ÿç¾ã€‚MobileLLMãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã¯ã€ãƒãƒ£ãƒƒãƒˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®æ”¹å–„ã‚’ç¤ºã—ã€ä¸€èˆ¬çš„ãªãƒ‡ãƒã‚¤ã‚¹ã§ã®å°å‹ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’å¼·èª¿ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3138" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Aria: An Open Multimodal Native Mixture-of-Experts Model, Dongxu Li+, arXiv'24, 2024.10</a>
<span class="snippet"><span>GPT Summary</span>- Ariaã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒã‚¤ãƒ†ã‚£ãƒ–AIãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€è¦–è¦šã¨ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦é«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚3.9Bã®è¦–è¦šãƒˆãƒ¼ã‚¯ãƒ³ã¨3.5Bã®ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŒã¤ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®æ··åˆãƒ¢ãƒ‡ãƒ«ã§ã€æ—¢å­˜ã®ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã¾ã™ã€‚è¨€èªç†è§£ã‚„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç†è§£ã‚’å¼·åŒ–ã™ã‚‹4æ®µéšã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€ãƒ¢ãƒ‡ãƒ«ã‚¦ã‚§ã‚¤ãƒˆã¨ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æä¾›ã•ã‚Œã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lijunnan0409/status/1975341550080303467?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/rhymes-ai/Aria" target="_blank" rel="noopener noreferrer">https://huggingface.co/rhymes-ai/Aria</a>


</p>
<p>ææ¡ˆã•ã‚ŒãŸå½“æ™‚2024å¹´10æœˆæ™‚ç‚¹ã§ã€Visionã¨Text UnderstandingåŒæ–¹ã§ã«å¼·ã„åˆã‚ã¦ã®ãƒ¢ãƒ‡ãƒ«ã§ã€åˆã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«MoEãƒ¢ãƒ‡ãƒ«ã§ï¼ˆå½“æ™‚ã¾ã è©±é¡Œã«ãªã£ã¦ã„ãªã‹ã£ãŸDeepSeek-V2ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ï¼‰ã€LongVideoã®Understanidinpã§å½“æ™‚ã®æœ€é«˜æ€§èƒ½ã§ã‚ã£ãŸã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3009" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Back to Basics: Revisiting REINFORCE Style Optimization for Learning   from Human Feedback in LLMs, Arash Ahmadian+, ACL'24, 2024.02</a>
<span class="snippet"><span>GPT Summary</span>- RLHFã«ãŠã‘ã‚‹æ•´åˆæ€§ã®é‡è¦æ€§ã‚’è€ƒæ…®ã—ã€PPOã®é«˜ã‚³ã‚¹ãƒˆã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã®å•é¡Œã‚’æŒ‡æ‘˜ã€‚ã‚·ãƒ³ãƒ—ãƒ«ãªREINFORCEã‚¹ã‚¿ã‚¤ãƒ«ã®æœ€é©åŒ–æ‰‹æ³•ãŒPPOã‚„æ–°ææ¡ˆã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã€LLMã®æ•´åˆæ€§ç‰¹æ€§ã«é©å¿œã™ã‚‹ã“ã¨ã§ä½ã‚³ã‚¹ãƒˆã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³RLæœ€é©åŒ–ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ææ¡ˆã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2978" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Impact of Initialization on LoRA Finetuning Dynamics, Soufiane Hayou+, NeurIPS'24, 2024.06</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€LoRAã«ãŠã‘ã‚‹åˆæœŸåŒ–ã®å½¹å‰²ã‚’ç ”ç©¶ã—ã€Bã‚’ã‚¼ãƒ­ã«åˆæœŸåŒ–ã—Aã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã™ã‚‹æ–¹å¼ãŒä»–ã®æ–¹å¼ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã™ã€‚ã“ã®åˆæœŸåŒ–æ–¹å¼ã¯ã€ã‚ˆã‚Šå¤§ããªå­¦ç¿’ç‡ã‚’ä½¿ç”¨ã§ãã‚‹ãŸã‚ã€åŠ¹ç‡çš„ãªå­¦ç¿’ã‚’ä¿ƒé€²ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚LLMsã«é–¢ã™ã‚‹å®Ÿé¨“ã‚’é€šã˜ã¦çµæœã‚’æ¤œè¨¼ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jxmnop/status/1970893830619894186?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>åˆæœŸåŒ–ã§Bã‚’zeroã«ã™ã‚‹ã¨ã„ã†æ‰‹æ³•ã¯ä»¥ä¸‹ã§ã‚‚ææ¡ˆã•ã‚Œã¦ã„ã‚‹ãŒã€æœ¬ç ”ç©¶ã®æ–¹ãŒä¸‹è¨˜ç ”ç©¶ã‚ˆã‚Šã‚‚æŠ•ç¨¿ãŒ1å¹´ç¨‹åº¦æ—©ã„:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2194" target="_blank" rel="noopener noreferrer">[Paper Note] SingLoRA: Low Rank Adaptation Using a Single Matrix, David BensaÃ¯d+, arXiv'25</a>
</p>
<p>openreview:


<a href="https://openreview.net/forum?id=sn3UrYRItk&referrer=%5Bthe%20profile%20of%20Nikhil%20Ghosh%5D(%2Fprofile%3Fid%3D~Nikhil_Ghosh1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=sn3UrYRItk&referrer=%5Bthe%20profile%20of%20Nikhil%20Ghosh%5D(%2Fprofile%3Fid%3D~Nikhil_Ghosh1)</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2963" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author  Prompt Editing, Xinyu Hu+, ICLR'24, 2023.10</a>
<span class="snippet"><span>GPT Summary</span>- Evokeã¨ã„ã†è‡ªå‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ´—ç·´ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã¨è‘—è€…ã®LLMãŒãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã‚’å½¢æˆã—ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ´—ç·´ã€‚é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠã™ã‚‹ã“ã¨ã§ã€LLMã®æ·±ã„ç†è§£ã‚’ä¿ƒé€²ã€‚å®Ÿé¨“ã§ã¯ã€EvokeãŒè«–ç†çš„èª¤è¬¬æ¤œå‡ºã‚¿ã‚¹ã‚¯ã§80ä»¥ä¸Šã®ã‚¹ã‚³ã‚¢ã‚’é”æˆã—ã€ä»–ã®æ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=OXv0zQ1umU" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=OXv0zQ1umU</a>


</p>
<p>pj page: 


<a href="https://sites.google.com/view/evoke-llms/home" target="_blank" rel="noopener noreferrer">https://sites.google.com/view/evoke-llms/home</a>


<br>github: 


<a href="https://github.com/microsoft/Evoke" target="_blank" rel="noopener noreferrer">https://github.com/microsoft/Evoke</a>


<br><br>githubã«ãƒªãƒã‚¸ãƒˆãƒªã¯ã‚ã‚‹ãŒã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒæ›¸ã‹ã‚ŒãŸtsvãƒ•ã‚¡ã‚¤ãƒ«ãŒé…ç½®ã•ã‚Œã¦ã„ã‚‹ã ã‘ã§ã€å®Ÿé¨“ã‚’å†ç¾ã™ã‚‹ãŸã‚ã®å…¨ä½“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2958" target="_blank" rel="noopener noreferrer" class="title-link">A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models, Sahoo+, EMNLP'24 Findings</a>
<span class="snippet"><span>GPT Summary</span>- åŸºç›¤ãƒ¢ãƒ‡ãƒ«ï¼ˆFMsï¼‰ã®å¤šæ§˜ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã«ãŠã‘ã‚‹é€²å±•ã¯é¡•è‘—ã ãŒã€ç‰¹ã«é«˜ãƒªã‚¹ã‚¯ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯å¹»è¦šçš„ãªå‡ºåŠ›ãŒå•é¡Œã¨ãªã‚‹ã€‚æœ¬èª¿æŸ»è«–æ–‡ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€å‹•ç”»ã€éŸ³å£°ã«ãŠã‘ã‚‹FMsã®å¹»è¦šã®å•é¡Œã‚’ç‰¹å®šã—ã€è»½æ¸›ç­–ã®æœ€è¿‘ã®é€²å±•ã‚’ã¾ã¨ã‚ã‚‹ã€‚å¹»è¦šã®å®šç¾©ã€åˆ†é¡ã€æ¤œå‡ºæˆ¦ç•¥ã‚’å«ã‚€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã—ã€ä»Šå¾Œã®ç ”ç©¶ã¨é–‹ç™ºã®åŸºç›¤ã‚’ç¯‰ãã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1217" target="_blank" rel="noopener noreferrer">A Comprehensive Survey of Hallucination Mitigation Techniques in Large
  Language Models, S. M Towhidul Islam Tonmoy+, N/A, arXiv'24</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2824" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks,   and Refusals of LLMs, Seungju Han+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- WildGuardã¯ã€LLMã®å®‰å…¨æ€§å‘ä¸Šã‚’ç›®çš„ã¨ã—ãŸã‚ªãƒ¼ãƒ—ãƒ³ã§è»½é‡ãªãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«ã§ã€æ‚ªæ„ã®ã‚ã‚‹æ„å›³ã®ç‰¹å®šã€å®‰å…¨ãƒªã‚¹ã‚¯ã®æ¤œå‡ºã€æ‹’å¦ç‡ã®åˆ¤æ–­ã‚’è¡Œã†ã€‚92Kã®ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸWildGuardMixã‚’æ§‹ç¯‰ã—ã€æ•µå¯¾çš„ãªè„±ç„ã‚„æ‹’å¦å¿œç­”ã‚’ã‚«ãƒãƒ¼ã€‚è©•ä¾¡ã®çµæœã€WildGuardã¯æ—¢å­˜ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ç‰¹ã«æ‹’å¦æ¤œå‡ºã§æœ€å¤§26.4%ã®æ”¹å–„ã‚’é”æˆã€‚GPT-4ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«åŒ¹æ•µã—ã€è„±ç„æ”»æ’ƒã®æˆåŠŸç‡ã‚’79.8%ã‹ã‚‰2.4%ã«ä½ä¸‹ã•ã›ã‚‹åŠ¹æœã‚’æŒã¤ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=Ich4tv4202#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Ich4tv4202#discussion</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2777" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Lessons from Studying Two-Hop Latent Reasoning, Mikita Balesni+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®äºŒæ®µéšè³ªå•å¿œç­”èƒ½åŠ›ã‚’èª¿æŸ»ã—ã€æ€è€ƒã®é€£é–ï¼ˆCoTï¼‰ã®é‡è¦æ€§ã‚’ç¤ºã™ã€‚åˆæˆäº‹å®Ÿã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã€ãƒ¢ãƒ‡ãƒ«ã¯äºŒã¤ã®åˆæˆäº‹å®Ÿã‚’çµ„ã¿åˆã‚ã›ã‚‹ã®ã«å¤±æ•—ã™ã‚‹ãŒã€è‡ªç„¶ãªäº‹å®Ÿã¨ã®çµ„ã¿åˆã‚ã›ã§ã¯æˆåŠŸã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMã¯æ½œåœ¨çš„ãªäºŒæ®µéšæ¨è«–èƒ½åŠ›ã‚’æŒã¤ãŒã€ãã®èƒ½åŠ›ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã¯ä¸æ˜ç‚¹ãŒæ®‹ã‚‹ã€‚ç ”ç©¶è€…ã¯ã€LLMã®æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹éš›ã«ã€ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã«ã‚ˆã‚‹è™šå½ã®æˆåŠŸã‚„å¤±æ•—ã«æ³¨æ„ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/balesni/status/1966197584499999036?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä¸‹è¨˜ç ”ç©¶ã§ã¯ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒå›½ã®å ´åˆã¯2 stepæ¨è«–ãŒã§ãã‚‹ã¨ã„ã†ä¾‹å¤–ãŒç”Ÿã˜ã¦ãŠã‚Šã€äº‹å‰å­¦ç¿’ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã§ä½•ã‹è¦‹è½ã¨ã—ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„å¯èƒ½æ€§ãŒã‚ã‚Š:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1564" target="_blank" rel="noopener noreferrer">Do Large Language Models Perform Latent Multi-Hop Reasoning without   Exploiting Shortcuts?, Sohee Yang+, ACL'24</a>
<br><br>ä¸‹è¨˜ç ”ç©¶ã«ãŠã„ã¦ã€å®Œå…¨ã«memorizationzãŒç”Ÿã˜ãªã„å½¢ã§äº‹å‰å­¦ç¿’ã¨Inferenceå®Ÿæ–½ï¼ˆtrain: John Doe lives in **Tokyo**., Test: The people in the city John Doe is from speak **Japanese**.)ã•ã‚ŒãŸãŒã€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒcityã®å ´åˆã§ã—ã‹è©¦ã•ã‚Œã¦ãŠã‚‰ãšã€ä»–ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã§ã‚‚æ±åŒ–ã™ã‚‹ã®ã‹ï¼Ÿã¨ã„ã†ç–‘å•ãŒã‚ã£ãŸ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2778" target="_blank" rel="noopener noreferrer">[Paper Note] Extractive Structures Learned in Pretraining Enable Generalization on   Finetuned Facts, Jiahai Feng+, ICML'25</a>
<br><br>æœ¬ç ”ç©¶ã§ã¯17ç¨®é¡ã®ä»–ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã§ã‚‚2 hop reasoningãŒlatentã«å®Ÿæ–½ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ãŸã€‚ã—ã‹ã—ã€ä¸€ã¤ä¸æ€è­°ãªç‚¹ã¨ã—ã¦å½“åˆ2ã¤ã®æ¶ç©ºã®äº‹å®Ÿã‚’LLMã«æ•™ãˆã‚‹ã‚ˆã†ãªå­¦ç¿’ã‚’è©¦ã¿ãŸå ´åˆã¯ã€‚Acc.ãŒ0%ã§ã€lossã‚‚å¶ç„¶ã«ç”Ÿã˜ã‚‹ç¨‹åº¦ã®ã‚‚ã®ã§ã‚ã£ãŸã€‚ã“ã‚Œã‚’æ·±æ˜ã‚Šã™ã‚‹ã¨ã€<br>- åˆæˆ+æœ¬ç‰©ã®äº‹å®Ÿâ†’ã†ã¾ãã„ã<br>- åˆæˆ+åˆæˆâ†’å¤±æ•—<br>- åŒä¸€è¨“ç·´/incontextæ–‡æ›¸å†…ã®åˆæˆã•ã‚ŒãŸäº‹å®Ÿâ†’ã†ã¾ãã„ã<br>ã¨ã„ã†ç¾è±¡ãŒè¦³æ¸¬ã•ã‚Œã€ã“ã®ã“ã¨ã‚ˆã‚Š<br>- å®Ÿä¸–ç•Œã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã®æˆåŠŸã¯ã€latent reasoningãŒãƒ­ãƒã‚¹ãƒˆã«å®Ÿæ–½ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™ã‚ã‘ã§ã¯ãªãï¼ˆäº‹å‰å­¦ç¿’æ™‚ã®åŒä¸€æ–‡æ›¸å†…ã®å…±èµ·ã‚’åæ˜ ã—ã¦ã„ã‚‹ã ã‘ã®å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰<br>- åˆæˆãƒ‡ãƒ¼ã‚¿ã§ã®2 hopæ¨è«–ã®å¤±æ•—ã¯ã€latent reasoningã®èƒ½åŠ›ã‚’å¦å®šã™ã‚‹ã‚‚ã®ã§ã¯ãªã„ï¼ˆåˆæˆã•ã‚ŒãŸäº‹å®Ÿã¯å®Ÿä¸–ç•Œã§ã®è‡ªç„¶ãªäº‹å®Ÿã¨ã¯ç•°ãªã‚‹ãŸã‚ã†ã¾ãã„ã£ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰<br><br>ã¨ã„ã†æ•™è¨“ãŒå¾—ã‚‰ã‚ŒãŸã€ã¨ã„ã£ãŸè©±ãŒå…ƒãƒã‚¹ãƒˆã«æ›¸ã‹ã‚Œã¦ã„ã‚‹ã€‚<br><br>ãªãœå®Œå…¨ã«åˆæˆã•ã‚ŒãŸäº‹å®Ÿæƒ…å ±ã§ã¯å¤±æ•—ã™ã‚‹ã®ã ã‚ã†ã‹ã€‚å…ƒè«–æ–‡ã‚’èª­ã‚“ã§äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã©ã®ã‚ˆã†ãªã‚‚ã®ãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/feng_jiahai/status/1869019495299444830?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2739" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures, Jinjie Ni+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- MixEvalã¯ã€LLMè©•ä¾¡ã®æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã§ã‚ã‚Šã€å®Ÿä¸–ç•Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã¨çœŸå®Ÿã«åŸºã¥ããƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ã‹ã¤å…¬æ­£ãªè©•ä¾¡ã‚’å®Ÿç¾ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Chatbot Arenaã¨ã®é«˜ã„ç›¸é–¢ã‚’æŒã¡ã€è¿…é€Ÿã‹ã¤å®‰ä¾¡ãªè©•ä¾¡ãŒå¯èƒ½ã¨ãªã‚‹ã€‚ã•ã‚‰ã«ã€å‹•çš„è©•ä¾¡ã‚’é€šã˜ã¦LLMè©•ä¾¡ã®ç†è§£ã‚’æ·±ã‚ã€ä»Šå¾Œã®ç ”ç©¶æ–¹å‘ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=6A29LUZhfv&referrer=%5Bthe%20profile%20of%20Yang%20You%5D(%2Fprofile%3Fid%3D~Yang_You1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=6A29LUZhfv&referrer=%5Bthe%20profile%20of%20Yang%20You%5D(%2Fprofile%3Fid%3D~Yang_You1)</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2734" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MMLU-Pro: A More Robust and Challenging Multi-Task Language   Understanding Benchmark, Yubo Wang+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- MMLUãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®é™ç•Œã‚’å…‹æœã™ã‚‹ãŸã‚ã€æ¨è«–ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸè³ªå•ã‚’çµ±åˆã—ã€é¸æŠè‚¢ã‚’4ã‹ã‚‰10ã«å¢—ã‚„ã—ãŸå¼·åŒ–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆMMLU-Proã‚’ææ¡ˆã€‚MMLU-Proã¯äº›ç´°ãªè³ªå•ã‚’æ’é™¤ã—ã€ç²¾åº¦ãŒ16%ã‹ã‚‰33%ä½ä¸‹ã™ã‚‹ä¸€æ–¹ã§ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹å®‰å®šæ€§ãŒå‘ä¸Šã€‚Chain of Thoughtæ¨è«–ã‚’åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ã€MMLU-Proã§ã‚ˆã‚Šè‰¯ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€è¤‡é›‘ãªæ¨è«–å•é¡Œã‚’å«ã‚€ã“ã¨ã‚’ç¤ºå”†ã€‚MMLU-Proã¯ã€ã‚ˆã‚Šè­˜åˆ¥çš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦åˆ†é‡ã®é€²å±•ã‚’è¿½è·¡ã™ã‚‹ã®ã«é©ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=y10DM6R2r3&referrer=%5Bthe%20profile%20of%20Ge%20Zhang%5D(%2Fprofile%3Fid%3D~Ge_Zhang5)#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=y10DM6R2r3&referrer=%5Bthe%20profile%20of%20Ge%20Zhang%5D(%2Fprofile%3Fid%3D~Ge_Zhang5)#discussion</a>


</p>
<p>MMLUã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/901" target="_blank" rel="noopener noreferrer">Measuring Massive Multitask Language Understanding, Dan Hendrycks+, N/A, ICLR'21</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2732" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Stepwise Alignment for Constrained Language Model Policy Optimization, Akifumi Wachi+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- å®‰å…¨æ€§ã¨ä¿¡é ¼æ€§ã¯LLMã‚’ç”¨ã„ã‚‹AIã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦é‡è¦ã§ã‚ã‚Šã€æœ¬ç ”ç©¶ã§ã¯å ±é…¬æœ€å¤§åŒ–ã‚’äººé–“ã®ä¾¡å€¤ã«åŸºã¥ãå®‰å…¨æ€§åˆ¶ç´„ã®ä¸‹ã§å®šå¼åŒ–ã—ã€é€æ¬¡æ•´åˆæ€§ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆSACPOï¼‰ã‚’ææ¡ˆã€‚SACPOã¯å ±é…¬ã¨å®‰å…¨æ€§ã‚’çµ„ã¿è¾¼ã‚“ã æœ€é©ãƒãƒªã‚·ãƒ¼ã‚’æ®µéšçš„ã«æ•´åˆã•ã›ã€ã‚·ãƒ³ãƒ—ãƒ«ã§å¼·åŠ›ãªæ•´åˆæ€§ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ´»ç”¨ã€‚ç†è«–çš„åˆ†æã«ã‚ˆã‚Šæœ€é©æ€§ã¨å®‰å…¨æ€§åˆ¶ç´„é•åã®ä¸Šé™ã‚’ç¤ºã—ã€å®Ÿé¨“çµæœã§ã¯SACPOãŒAlpaca-7Bã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦æœ€å…ˆç«¯æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>NLPã‚³ãƒ­ã‚­ã‚¦ãƒ ã§ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’å‚ç…§ã®ã“ã¨: <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1603" target="_blank" rel="noopener noreferrer">ã€NLPã‚³ãƒ­ã‚­ã‚¦ãƒ ã€‘Stepwise Alignment for Constrained Language Model Policy Optimization (NeurIPS 2024)  , 2024.12</a>
</p>
<p>openreview: 


<a href="https://openreview.net/forum?id=VrVx83BkQX&referrer=%5Bthe%20profile%20of%20Takumi%20Tanabe%5D(%2Fprofile%3Fid%3D~Takumi_Tanabe1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=VrVx83BkQX&referrer=%5Bthe%20profile%20of%20Takumi%20Tanabe%5D(%2Fprofile%3Fid%3D~Takumi_Tanabe1)</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Routing.html" target="_blank" rel="noopener noreferrer">#Routing</a>
<span class="issue_date">Issue Date: 2025-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2690" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Multi-Head Mixture-of-Experts, Xun Wu+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- MH-MoEã¯ã€ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ç”¨ã„ã¦ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¤‡æ•°ã®ã‚µãƒ–ãƒˆãƒ¼ã‚¯ãƒ³ã«åˆ†å‰²ã—ã€å°‚é–€å®¶ã®æ´»æ€§åŒ–ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„æ‰‹æ³•ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ–‡è„ˆç†è§£ãŒæ·±ã¾ã‚Šã€éå­¦ç¿’ãŒè»½æ¸›ã•ã‚Œã¾ã™ã€‚MH-MoEã¯å®Ÿè£…ãŒç°¡å˜ã§ã€ä»–ã®SMoEãƒ¢ãƒ‡ãƒ«ã¨çµ±åˆå¯èƒ½ã§ã‚ã‚Šã€åºƒç¯„ãªå®Ÿé¨“ã§ãã®æœ‰åŠ¹æ€§ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=dyZ8GJZjtX&referrer=%5Bthe%20profile%20of%20Shaohan%20Huang%5D(%2Fprofile%3Fid%3D~Shaohan_Huang1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=dyZ8GJZjtX&referrer=%5Bthe%20profile%20of%20Shaohan%20Huang%5D(%2Fprofile%3Fid%3D~Shaohan_Huang1)</a>


</p>
<p>SNLP'24ã§ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:


<a href="https://speakerdeck.com/takase/snlp2024-multiheadmoe" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/takase/snlp2024-multiheadmoe</a>


</p>
<p>MoEã®Routing Collapseã«å¯¾ã—ã¦ã€Expertsã®è¡¨ç¾åŠ›ã‚’è½ã¨ã™ã“ã¨ã§ç‰¹å®šã®Expertsã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãŒåã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹ã€ã¨ã„ã†ã‚³ãƒ³ã‚»ãƒ—ãƒˆãªæ¨¡æ§˜ã€‚å…·ä½“çš„ã«ã¯ã€inputã‚’è¤‡æ•°headã«åˆ†å‰²ã—ã¦headå˜ä½ã§Expertsã‚’é¸æŠã—ã€å‡ºåŠ›ã‚’concatã™ã‚‹ã€ã¨ã„ã£ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Memorization.html" target="_blank" rel="noopener noreferrer">#Memorization</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2679" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Be like a Goldfish, Don't Memorize Mitigating Memorization in   Generative LLMs, Abhimanyu Hans+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- ã€Œã‚´ãƒ¼ãƒ«ãƒ‰ãƒ•ã‚£ãƒƒã‚·ãƒ¥ãƒ­ã‚¹ã€ã‚’å°å…¥ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã°ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒ­ã‚¹è¨ˆç®—ã‹ã‚‰é™¤å¤–ã™ã‚‹ã“ã¨ã§ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚„è‘—ä½œæ¨©ãƒªã‚¹ã‚¯ã‚’è»½æ¸›ã€‚10å„„è¦æ¨¡ã®Llama-2ãƒ¢ãƒ‡ãƒ«ã®å®Ÿé¨“ã«ã‚ˆã‚Šã€ä¸‹æµã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å½±éŸ¿ã‚’ä¸ãˆãšã«è¨˜æ†¶ã®å‰Šæ¸›ã‚’å®Ÿè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vikhyatk/status/1962954696500674908?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã®lossè¨ˆç®—ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«tokenã‚’é™¤å¤–ã›ã‚‹ã“ã¨ã§downstream taskã®æ€§èƒ½ã‚’æãªã†ã“ã¨ãªãmemorizationã‚’é˜²ã’ã¾ã™ã‚ˆã€ã¨ã„ã†è©±ã‚‰ã—ã„</p>
<p>openreview:


<a href="https://openreview.net/forum?id=DylSyAfmWs&referrer=%5Bthe%20profile%20of%20Jonas%20Geiping%5D(%2Fprofile%3Fid%3D~Jonas_Geiping1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=DylSyAfmWs&referrer=%5Bthe%20profile%20of%20Jonas%20Geiping%5D(%2Fprofile%3Fid%3D~Jonas_Geiping1)</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2638" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Many-Shot In-Context Learning, Rishabh Agarwal+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰å¤šãã®ã‚·ãƒ§ãƒƒãƒˆã®ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã«ãŠã„ã¦é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’ç¤ºã™ã€‚æ–°ãŸãªè¨­å®šã¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆã®æ€è€ƒéç¨‹ã‚’ç”¨ã„ã‚‹å¼·åŒ–ã•ã‚ŒãŸICLã¨ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ã®è³ªå•ã®ã¿ã‚’ç”¨ã„ã‚‹ç„¡ç›£ç£ICLã‚’ææ¡ˆã€‚ã“ã‚Œã‚‰ã¯ç‰¹ã«è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã«åŠ¹æœçš„ã§ã‚ã‚Šã€å¤šãã®ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã¯äº‹å‰å­¦ç¿’ã®ãƒã‚¤ã‚¢ã‚¹ã‚’è¦†ã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã¾ãŸã€æ¨è«–ã‚³ã‚¹ãƒˆã¯ç·šå½¢ã«å¢—åŠ ã—ã€æœ€å‰ç·šã®LLMsã¯å¤šãã®ã‚·ãƒ§ãƒƒãƒˆã®ICLã‹ã‚‰æ©æµã‚’å—ã‘ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>many-shotã‚’ææ¡ˆ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2615" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DART-Math: Difficulty-Aware Rejection Tuning for Mathematical  Problem-Solving, Yuxuan Tong+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- æ•°å­¦å•é¡Œè§£æ±ºã«ã¯é«˜åº¦ãªæ¨è«–ãŒå¿…è¦ã§ã‚ã‚Šã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã¯é›£ã—ã„ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦åã‚ŠãŒã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚ãã“ã§ã€Difficulty-Aware Rejection Tuningï¼ˆDARTï¼‰ã‚’ææ¡ˆã—ã€é›£ã—ã„ã‚¯ã‚¨ãƒªã«å¤šãã®è©¦è¡Œã‚’å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¼·åŒ–ã€‚æ–°ãŸã«ä½œæˆã—ãŸå°è¦æ¨¡ãªæ•°å­¦å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€7Bã‹ã‚‰70Bã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸDART-MATHã¯ã€å¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚åˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒæ•°å­¦å•é¡Œè§£æ±ºã«ãŠã„ã¦åŠ¹æœçš„ã§ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®è‰¯ã„ãƒªã‚½ãƒ¼ã‚¹ã§ã‚ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=zLU21oQjD5&referrer=%5Bthe%20profile%20of%20Rui%20Wang%5D(%2Fprofile%3Fid%3D~Rui_Wang1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=zLU21oQjD5&referrer=%5Bthe%20profile%20of%20Rui%20Wang%5D(%2Fprofile%3Fid%3D~Rui_Wang1)</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/Scheduler.html" target="_blank" rel="noopener noreferrer">#Scheduler</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2540" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MiniCPM: Unveiling the Potential of Small Language Models with Scalable  Training Strategies, Shengding Hu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ€¥æˆé•·ã™ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®é–‹ç™ºã«ãŠã‘ã‚‹ã‚³ã‚¹ãƒˆã®æ‡¸å¿µã‹ã‚‰ã€å°è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆSLMsï¼‰ã®å¯èƒ½æ€§ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€MiniCPMã¨ã„ã†1.2BãŠã‚ˆã³2.4Bã®éåŸ‹ã‚è¾¼ã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒªã‚¢ãƒ³ãƒˆã‚’ç´¹ä»‹ã—ã€ã“ã‚Œã‚‰ãŒ7B-13Bã®LLMsã¨åŒç­‰ã®èƒ½åŠ›ã‚’æŒã¤ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã¯åºƒç¯„ãªå®Ÿé¨“ã‚’ã€ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã¯Warmup-Stable-Decayï¼ˆWSDï¼‰å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’å°å…¥ã—ã€åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿-ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•ã‚’ç ”ç©¶ã—ãŸã€‚MiniCPMãƒ•ã‚¡ãƒŸãƒªãƒ¼ã«ã¯MiniCPM-DPOã€MiniCPM-MoEã€MiniCPM-128KãŒå«ã¾ã‚Œã€å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¦ã„ã‚‹ã€‚MiniCPMãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Warmup-Stable-Decay (WSD)</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2506" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with  AI Feedback, Harrison Lee+, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- RLAIFã¯ã€ã‚ªãƒ•ãƒ»ã‚¶ãƒ»ã‚·ã‚§ãƒ«ãƒ•ã®LLMã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸå¥½ã¿ã«åŸºã¥ã„ã¦å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€RLHFã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã™ã‚‹ä»£æ›¿æ‰‹æ®µã‚’æä¾›ã€‚è‡ªå·±æ”¹å–„ã‚’ç¤ºã—ã€d-RLAIFã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã•ã‚‰ã«å„ªã‚ŒãŸçµæœã‚’å¾—ã‚‹ã€‚RLAIFã¯äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”¨ã„ãŸå ´åˆã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ã€RLHFã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®èª²é¡Œã«å¯¾ã™ã‚‹è§£æ±ºç­–ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ˆè¡Œç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2903" target="_blank" rel="noopener noreferrer">[Paper Note] Constitutional AI: Harmlessness from AI Feedback, Yuntao Bai+, arXiv'22</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2453" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning  in AI, Elliot Glazer+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- FrontierMathã¯ã€å°‚é–€ã®æ•°å­¦è€…ã«ã‚ˆã£ã¦ä½œæˆã•ã‚ŒãŸé›£æ˜“åº¦ã®é«˜ã„æ•°å­¦å•é¡Œã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€æ•°è«–ã‚„å®Ÿè§£æã‹ã‚‰ä»£æ•°å¹¾ä½•å­¦ã‚„åœè«–ã¾ã§å¹…åºƒã„åˆ†é‡ã‚’ã‚«ãƒãƒ¼ã€‚å•é¡Œè§£æ±ºã«ã¯æ•°æ™‚é–“ã‹ã‚‰æ•°æ—¥ã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã€ç¾åœ¨ã®AIãƒ¢ãƒ‡ãƒ«ã¯å•é¡Œã®2%æœªæº€ã—ã‹è§£æ±ºã§ãã¦ã„ãªã„ã€‚FrontierMathã¯AIã®æ•°å­¦çš„èƒ½åŠ›ã®é€²æ—ã‚’å®šé‡åŒ–ã™ã‚‹ãŸã‚ã®å³å¯†ãªãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã‚’æä¾›ã™ã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/Trustfulness.html" target="_blank" rel="noopener noreferrer">#Trustfulness</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2448" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Measuring short-form factuality in large language models, Jason Wei+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- SimpleQAã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®çŸ­ã„äº‹å®Ÿã«é–¢ã™ã‚‹è³ªå•ã¸ã®å¿œç­”èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚Šã€æŒ‘æˆ¦çš„ã‹ã¤è©•ä¾¡ãŒå®¹æ˜“ãªè³ªå•ã‚’ç‰¹å¾´ã¨ã™ã‚‹ã€‚å„å›ç­”ã¯æ­£è§£ã€ä¸æ­£è§£ã€æœªè©¦è¡Œã®ã„ãšã‚Œã‹ã¨ã—ã¦è©•ä¾¡ã•ã‚Œã€ç†æƒ³çš„ãªãƒ¢ãƒ‡ãƒ«ã¯è‡ªä¿¡ãŒãªã„è³ªå•ã«ã¯æŒ‘æˆ¦ã›ãšã€æ­£è§£ã‚’å¤šãå¾—ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚SimpleQAã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒã€Œè‡ªåˆ†ãŒçŸ¥ã£ã¦ã„ã‚‹ã“ã¨ã‚’çŸ¥ã£ã¦ã„ã‚‹ã‹ã€ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ®µã§ã‚ã‚Šã€æ¬¡ä¸–ä»£ãƒ¢ãƒ‡ãƒ«ã«ã¨ã£ã¦ã‚‚é‡è¦ãªè©•ä¾¡åŸºæº–ã¨ãªã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>


<a href="https://openai.com/index/introducing-simpleqa/" target="_blank" rel="noopener noreferrer">https://openai.com/index/introducing-simpleqa/</a>


</p>
<p>å…ˆè¡Œç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2449" target="_blank" rel="noopener noreferrer">[Paper Note] TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for   Reading Comprehension, Mandar Joshi+, ACL'17</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2450" target="_blank" rel="noopener noreferrer">Natural Questions: A Benchmark for Question Answering Research, Kwiatkowski+, TACL'19</a>
<br><br>ã“ã‚Œã‚‰ã¯ã™ã§ã«é£½å’Œã—ã¦ã„ã‚‹</p>
<p>æœ€è¿‘ã‚ˆãLLMã®ãƒ™ãƒ³ãƒã§è¦‹ã‹ã‘ã‚‹SimpleQA</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2444" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Better &amp; Faster Large Language Models via Multi-token Prediction, Fabian Gloeckle+, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è¤‡æ•°ã®å°†æ¥ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’åŒæ™‚ã«äºˆæ¸¬ã™ã‚‹ã‚ˆã†ã«è¨“ç·´ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã€ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ã®å‘ä¸Šã‚’å›³ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€nå€‹ã®ç‹¬ç«‹ã—ãŸå‡ºåŠ›ãƒ˜ãƒƒãƒ‰ã‚’ç”¨ã„ã¦æ¬¡ã®nãƒˆãƒ¼ã‚¯ãƒ³ã‚’äºˆæ¸¬ã—ã€è¨“ç·´æ™‚é–“ã«ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’ã‹ã‘ãšã«ä¸‹æµã®èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ç‰¹ã«ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ææ¡ˆãƒ¢ãƒ‡ãƒ«ã¯å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€æ¨è«–æ™‚ã«æœ€å¤§3å€ã®é€Ÿåº¦å‘ä¸Šã‚‚å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>next tokenã ã‘ã§ãªãã€next 4-tokenã‚’äºˆæ¸¬ã—ã¦å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€MBPP/HumanEvalã«ãŠã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒ1.3Bã‚’è¶…ãˆãŸæ™‚ç‚¹ã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆ=åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¨ãªã‚‹ã‚ˆã†ã«èª¿æ•´ã•ã‚ŒãŸnext-token predictionï¼‰ã‚’outperformã—ã¯ã˜ã‚ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã«ã¤ã‚Œã¦æ€§èƒ½ã®å·®ãŒé¡•è‘—ã«è¡¨ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ãŠã„ã¦äº‹å‰å­¦ç¿’ã€ãŠã‚ˆã³finetuningã®åŒæ–¹ã§åŠ¹æœãŒã‚ã‚‹ã€‚ãŸã ã—ã€3.7ç¯€ã§ç¤ºã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€ã“ã‚Œã¯ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®ã¿ã“ã®ã‚ˆã†ãªé¡•è‘—ãªæ”¹å–„ãŒã¿ã‚‰ã‚Œã¦ãŠã‚Šã€è‡ªç„¶è¨€èªãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã¯ã“ã“ã¾ã§é¡•è‘—ãªæ”¹å–„ã¯ã—ã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ï¼ˆ5.1ç¯€ã§è€ƒå¯Ÿã•ã‚Œã¦ã„ãã†; æ˜¨ä»Šã®LLMã§ã¯äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã®ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã‚‹ã®ãŒæ™®é€šãªã®ã§åˆ©ç”¨ã™ã‚‹æ©æµã¯ã‚ã‚Šãã†; Abstractive Summarizationã§ã¯æ€§èƒ½ãŒæ”¹å–„ã—ã¦ã„ã‚‹(Figure6); GSM8Kã§ã¯200Bã¾ã§ã¯next 2 tokenã‚’äºˆæ¸¬ã™ã‚‹ã¨æ€§èƒ½ãŒæ”¹å–„ã—ã¦ã„ã‚‹ãŒ500B tokenå­¦ç¿’ã™ã‚‹ã¨next token predictionã®æ–¹ãŒæ€§èƒ½ãŒè‰¯ããªã‚‹ï¼‰ã€‚å…¨ä½“çš„ã«perplexityã®æ”¹å–„ï¼ˆ=æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«ãŠã„ã¦æ­£è§£ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆç¢ºç‡ã‚’æ”¹å–„ã™ã‚‹ï¼‰ã¨ã„ã†ã‚ˆã‚Šã¯ã€ãƒ¢ãƒ‡ãƒ«ã®"æœ€çµ‚çš„ãªç”Ÿæˆçµæœâ€ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ãŸè©•ä¾¡ã¨ãªã£ã¦ã„ã‚‹ã€‚<br><br>ãƒ¢ãƒ‡ãƒ«ã¯å…±æœ‰ã®ãƒˆãƒ©ãƒ³ã‚¯f_s (ãŠãã‚‰ãheadé–“ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å…±æœ‰ã—ã¦ã„ã‚‹ä¸€é€£ã®transformerãƒ–ãƒ­ãƒƒã‚¯) ã‚’æŒã£ã¦ãŠã‚Šinput x_t:1ã«å¯¾å¿œã™ã‚‹latent representation z_t:1ã‚’ç”Ÿæˆã™ã‚‹ã€‚latent representationã‚’output headã«inputã™ã‚‹ã“ã¨ã§ã€ãã‚Œãã‚Œã®headãŒåˆè¨ˆã§nå€‹ã®next tokenã‚’äºˆæ¸¬ã™ã‚‹ã€‚<br>&lt;img width="608" height="1021" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/433d69cb-5593-483b-b591-6445c482ed2e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/433d69cb-5593-483b-b591-6445c482ed2e"&lt;/a&gt;


/&gt;<br><br>next n-tokenã‚’äºˆæ¸¬ã™ã‚‹éš›ã«ã¯ã€GPUãƒ¡ãƒ¢ãƒªã‚’å¤§å¹…ã«é£Ÿã£ã¦ã—ã¾ã† ï¼ˆlogitsã®shapeãŒ(n, V)ã¨ãªã‚Šãã‚Œã‚‰ã®å‹¾é…ã‚‚ä¿æŒã—ãªã‘ã‚Œã°ãªã‚‰ãªã„) ã“ã¨ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ãªã‚‹ãŒã€f_sã¾ã§forward passã‚’å®Ÿè¡Œã—ãŸã‚‰ã€å„headã«å¯¾ã—ã¦forward/backward passã‚’é †ç•ªã«å®Ÿè¡Œã—ã¦ã€logitsã®å€¤ã¯ç ´æ£„ã—å‹¾é…ã®æƒ…å ±ã ã‘f_sã«è“„ç©ã™ã‚‹ã“ã¨ã§ã€é•·æœŸçš„ã«ä¿æŒã™ã‚‹æƒ…å ±ã‚’å„headã®ã‹ã‚‰é€†ä¼æ¬ã•ã‚ŒãŸå‹¾é…æƒ…å ±ã®ã¿ã«ã™ã‚‹ã“ã¨ã§ã“ã‚Œã‚’è§£æ±ºã—ã¦ã„ã‚‹ã€‚<br>&lt;img width="597" height="478" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/3f5ff3fc-5934-4f12-9327-23b689526464"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/3f5ff3fc-5934-4f12-9327-23b689526464"&lt;/a&gt;


/&gt;<br><br>å®Ÿéš›ã«inferenceã‚’ã™ã‚‹ã¨ãã¯next tokenã‚’äºˆæ¸¬ã™ã‚‹ãƒ˜ãƒƒãƒ‰ã®å‡ºåŠ›ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã‚’å‰æã¨ã—ã¦ã„ã‚‹ãŒã€å…¨ã¦ã®ãƒ˜ãƒƒãƒ‰ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€tæ™‚ç‚¹ã§t+nãƒˆãƒ¼ã‚¯ãƒ³ã®äºˆæ¸¬ã‚’å¯èƒ½ãªãŸã‚ã€self-speculative decodingã‚’å®Ÿæ–½ã—inference timeã‚’çŸ­ç¸®ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br>3.4ã§ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€nã®å€¤ã¯å¤§ãã‘ã‚Œã°å¤§ãã„ã»ã©è‰¯ã„ã¨ã„ã†ã‚ã‘ã§ã¯ãªãã€4ç¨‹åº¦ï¼ˆbyte levelãªãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯8 bytesï¼‰ãŒæœ€é©ãªã‚ˆã†ã§ã‚ã‚‹ã€‚ãŒã€Table1ã‚’è¦‹ã‚‹ã¨ã€ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã£ã¦ã¯n=6ãŒè‰¯ã‹ã£ãŸã‚Šï¼ˆi.e., æœ€é©ãªnã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¾å­˜ï¼‰è¤‡æ•°ã‚¨ãƒãƒƒã‚¯å­¦ç¿’ã™ã‚‹ã¨multi token predictionã®åŠ¹æœãŒè–„ããªã£ã¦ã„ãã†ï¼ˆi.e., åŒã˜ãƒˆãƒ¼ã‚¯ãƒ³ã®äºˆæ¸¬ã‚’è¤‡æ•°å›å­¦ç¿’ã™ã‚‹ã®ã§å®Ÿè³ªmulti token predictionã¨ä¼¼ãŸã‚ˆã†ãªã“ã¨ã‚’ã‚„ã£ã¦ã„ã‚‹ã€‚è¨€ã„æ›ãˆã‚‹ã¨ã€multi token predictionã¯è¤‡æ•°epochã®å­¦ç¿’ã‚’å…ˆå–ã‚Šã—ã¦ã„ã‚‹ã¨ã¿ãªã›ã‚‹ï¼Ÿï¼‰ãªã®ã¯æ³¨æ„ãŒå¿…è¦ãã†ã€‚</p>
<p>å…¨ä½“çš„ã«è¤‡æ•°epochã‚’å­¦ç¿’ã™ã‚‹ã¨æ©æµãŒãªããªã£ã¦ã„ãï¼ˆã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰ or next token predictionã‚ˆã‚Šã‚‚æ€§èƒ½ãŒæ‚ªåŒ–ã™ã‚‹ï¼ˆè‡ªç„¶è¨€èªï¼‰ã®ã§ã€LLMã®äº‹å‰å­¦ç¿’ã«ãŠã„ã¦ã€è¤‡æ•°epochã‚’å­¦ç¿’ã™ã‚‹ã‚ˆã†ãªå½“ãŸã‚Šå‰ã¿ãŸã„ãªä¸–ç•Œç·šãŒè¨ªã‚ŒãŸã‚‰ã€ã“ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã™ã‚‹ã¨æ€§èƒ½ã¯ã‚€ã—ã‚æ‚ªåŒ–ã—ãã†ãªæ°—ã¯ã™ã‚‹ã€‚</p>
<p>MBPP/HumanEval:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2439" target="_blank" rel="noopener noreferrer">[Paper Note] Program Synthesis with Large Language Models, Jacob Austin+, arXiv'21</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2438" target="_blank" rel="noopener noreferrer">[Paper Note] Evaluating Large Language Models Trained on Code, Mark Chen+, arXiv'21</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2442" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts, Lean Wang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- MoEãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹è² è·ã®ä¸å‡è¡¡ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã€è£œåŠ©æå¤±ã‚’ç”¨ã„ãªã„Loss-Free Balancingã‚’ææ¡ˆã€‚å„ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¹ã‚³ã‚¢ã«ãƒã‚¤ã‚¢ã‚¹ã‚’é©ç”¨ã—ã€è² è·ã®ãƒãƒ©ãƒ³ã‚¹ã‚’ç¶­æŒã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€å¾“æ¥ã®æ‰‹æ³•ã‚ˆã‚Šã‚‚æ€§èƒ½ã¨è² è·ãƒãƒ©ãƒ³ã‚¹ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=y1iU5czYpE" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=y1iU5czYpE</a>


</p>
<p>MoEãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ç‰¹å®šã®Expertsã«ã°ã‹ã‚Šãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãŒé›†ä¸­ã—ã€<br>- routing collapse: ExpertsãŒååˆ†ã«è¨“ç·´ã•ã‚Œã‚‹ã“ã¨ã‚’å¦¨ã’ã‚‹<br>- computation bottleneck: ExpertsãŒè¤‡æ•°ã®ãƒ‡ãƒã‚¤ã‚¹ã«åˆ†æ•£ã—ã¦ã„ã‚‹å ´åˆã€ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ãŒé›†ä¸­ã™ã‚‹ã¨è¨ˆç®—åŠ¹ç‡ãŒè½ã¡ã‚‹<br><br>ã¨ã„ã†å•é¡ŒãŒèµ·ãã‚‹ã€‚ã“ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«æ—¢å­˜ç ”ç©¶ã¯auxiliary lossã¨å‘¼ã°ã‚Œã‚‹å„ãƒˆãƒ¼ã‚¯ãƒ³ãŒé¸æŠã™ã‚‹ExpertsãŒå¹…åºƒããªã‚‹ã‚ˆã†ãªåˆ¶ç´„ã‚’å…¥ã‚Œã¦ã„ã‚‹ã€‚<br><br>æœ¬ç ”ç©¶ã§ã¯auxiliary lossã®å‹¾é…ãŒè¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦æ‚ªå½±éŸ¿ã‚’åŠã¼ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã—ã€loss freeã®balancingæ‰‹æ³•ã‚’ææ¡ˆã—ã€perplexityãŒ1B, 3B, ï¼ˆãƒªãƒãƒƒã‚¿ãƒ«ä¸­ã§13B)ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ä½ä¸‹ã™ã‚‹ã“ã¨ã‚’å®Ÿé¨“çš„ã«ç¤ºã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€ãƒªãƒãƒƒã‚¿ãƒ«ã«ãŠã„ã¦ã€downstreamã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ï¼ˆBBH, MMLU, C-Eval, CMMLUï¼‰ã«ãŠã„ã¦ã‚‚ã€æ€§èƒ½ãŒæ”¹å–„ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>æ‰‹æ³•ã¯ã‚·ãƒ³ãƒ—ãƒ«ã§ã€top-kã®expertsã‚’æ±ºã‚ã‚‹éš›ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¹ã‚³ã‚¢ã«å¯¾ã—ã¦ã€expertsã”ã¨ã®ãƒã‚¤ã‚¢ã‚¹é …ã‚’å°å…¥ã—ã€å­¦ç¿’æ™‚ã«expertsã«å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®å¤šå¯¡ã«å¿œã˜ã¦ãƒã‚¤ã‚¢ã‚¹å€¤ã‚’èª¿æ•´ã™ã‚‹ã€‚<br><br>openreviewã«ã‚ˆã‚‹ã¨ã€ä»¥ä¸‹ã®äº‹é …ãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹:<br>- å®Ÿé¨“ã§ç”¨ã„ã‚‰ã‚Œã¦ã„ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒDeepSeekMoEã«ã®ã¿ã«é™ã‚‰ã‚Œã¦ã„ã‚‹<br>- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚‚å°è¦æ¨¡ã®ã‚‚ã®ã§ã—ã‹å®Ÿé¨“ã•ã‚Œã¦ã„ãªã„(ãƒªãƒãƒƒã‚¿ãƒ«ã«ã¦ã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ«ã§ã®çµæœã‚’åæ˜ ï¼‰<br>- auxiliary lossãŒãã‚‚ãã‚‚è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã«æ‚ªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã¯å®Ÿé¨“çš„ã«ä¸€éƒ¨ç¤ºã•ã‚Œã¦ã„ã‚‹ãŒã€ç†è«–çš„ãªjustificationãŒä¸è¶³ã—ã¦ã„ã‚‹<br>- downstream taskã«å¯¾ã™ã‚‹å®Ÿé¨“çµæœãŒç„¡ã„ã“ã¨ï¼ˆãƒªãƒãƒƒã‚¿ãƒ«ã§ã“ã®ç‚¹ã«ã¤ã„ã¦ã¯ç¤ºã•ã‚ŒãŸ)<br>- related workãŒ10ä»¶ã—ã‹å¼•ç”¨ã•ã‚Œã¦ãŠã‚‰ãšã€ã‚ˆã‚ŠåŒ…æ‹¬çš„ãªliterature reviewã¨é–¢é€£ç ”ç©¶ã¨ã®é–¢ä¿‚æ€§ã«ã¤ã„ã¦ã®è­°è«–ãŒä¸è¶³ã—ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2441" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CRUXEval-X: A Benchmark for Multilingual Code Reasoning, Understanding  and Execution, Ruiyang Xu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- CRUXEVAL-Xã¨ã„ã†å¤šè¨€èªã‚³ãƒ¼ãƒ‰æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã€‚19ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã‚’å¯¾è±¡ã«ã€å„è¨€èªã§600ä»¥ä¸Šã®èª²é¡Œã‚’å«ã‚€19Kã®ãƒ†ã‚¹ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã€‚è¨€èªé–“ã®ç›¸é–¢ã‚’è©•ä¾¡ã—ã€Pythonè¨“ç·´ãƒ¢ãƒ‡ãƒ«ãŒä»–è¨€èªã§ã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2440" target="_blank" rel="noopener noreferrer">[Paper Note] CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution, Alex Gu+, arXiv'24</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2440" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution, Alex Gu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- CRUXEvalã¨ã„ã†800ã®Pythoné–¢æ•°ã‹ã‚‰ãªã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€å…¥åŠ›äºˆæ¸¬ã¨å‡ºåŠ›äºˆæ¸¬ã®2ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’è©•ä¾¡ã€‚20ã®ã‚³ãƒ¼ãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆã—ãŸçµæœã€HumanEvalã§é«˜å¾—ç‚¹ã®ãƒ¢ãƒ‡ãƒ«ãŒCRUXEvalã§ã¯æ”¹å–„ã‚’ç¤ºã•ãªã„ã“ã¨ãŒåˆ¤æ˜ã€‚GPT-4ã¨Chain of Thoughtã‚’ç”¨ã„ãŸå ´åˆã€å…¥åŠ›äºˆæ¸¬ã§75%ã€å‡ºåŠ›äºˆæ¸¬ã§81%ã®pass@1ã‚’é”æˆã—ãŸãŒã€ã©ã®ãƒ¢ãƒ‡ãƒ«ã‚‚å®Œå…¨ã«ã¯ã‚¯ãƒªã‚¢ã§ããšã€GPT-4ã®ã‚³ãƒ¼ãƒ‰æ¨è«–èƒ½åŠ›ã®é™ç•Œã‚’ç¤ºã™ä¾‹ã‚’æä¾›ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2401" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Survey on the Memory Mechanism of Large Language Model based Agents, Zeyu Zhang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¡ãƒ¢ãƒªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªèª¿æŸ»ã‚’ææ¡ˆã€‚ãƒ¡ãƒ¢ãƒªã®é‡è¦æ€§ã‚’è«–ã˜ã€éå»ã®ç ”ç©¶ã‚’ä½“ç³»çš„ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®å½¹å‰²ã‚’ç´¹ä»‹ã€‚æ—¢å­˜ç ”ç©¶ã®é™ç•Œã‚’åˆ†æã—ã€å°†æ¥ã®ç ”ç©¶æ–¹å‘æ€§ã‚’ç¤ºã™ã€‚ãƒªãƒã‚¸ãƒˆãƒªã‚‚ä½œæˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1954797669957968169?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ReversalCurse.html" target="_blank" rel="noopener noreferrer">#ReversalCurse</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2395" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Factorization Curse: Which Tokens You Predict Underlie the Reversal   Curse and More, Ouail Kitouni+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ€å…ˆç«¯ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã¯å¹»è¦šã«æ‚©ã¾ã•ã‚Œã€æƒ…å ±å–å¾—ã«ãŠã„ã¦é€†è»¢ã®å‘ªã„ãŒå•é¡Œã¨ãªã‚‹ã€‚ã“ã‚Œã‚’å› æ•°åˆ†è§£ã®å‘ªã„ã¨ã—ã¦å†å®šç¾©ã—ã€åˆ¶å¾¡å®Ÿé¨“ã‚’é€šã˜ã¦ã“ã®ç¾è±¡ãŒæ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã®å›ºæœ‰ã®å¤±æ•—ã§ã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚ä¿¡é ¼æ€§ã®ã‚ã‚‹æƒ…å ±å–å¾—ã¯å˜ç´”ãªæ‰‹æ³•ã§ã¯è§£æ±ºã§ããšã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚‚é™ç•ŒãŒã‚ã‚‹ã€‚ç•°ãªã‚‹ã‚¿ã‚¹ã‚¯ã§ã®çµæœã¯ã€å› æ•°åˆ†è§£ã«ä¾å­˜ã—ãªã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒé€†è»¢ã®å‘ªã„ã‚’è»½æ¸›ã—ã€çŸ¥è­˜ã®ä¿å­˜ã¨è¨ˆç”»èƒ½åŠ›ã®å‘ä¸Šã«å¯„ä¸ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1954682957798715669?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>openreview:


<a href="https://openreview.net/forum?id=f70e6YYFHF" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=f70e6YYFHF</a>


</p>
<p>Reversal Curseã‚’æè¨€ã—ãŸç ”ç©¶ã¯ä¸‹è¨˜:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1059" target="_blank" rel="noopener noreferrer">[Paper Note] The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A", Lukas Berglund+, arXiv'23</a>
</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2399" target="_blank" rel="noopener noreferrer">[Paper Note] Physics of Language Models: Part 3.2, Knowledge Manipulation, Zeyuan Allen-Zhu+, ICLR'25</a>
</p></span><br><br>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2025-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2378" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] VERISCORE: Evaluating the factuality of verifiable claims in long-form  text generation, Yixiao Song+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- VERISCOREã¨ã„ã†æ–°ã—ã„æŒ‡æ¨™ã‚’ææ¡ˆã—ã€æ¤œè¨¼å¯èƒ½ãªä¸»å¼µã¨æ¤œè¨¼ä¸å¯èƒ½ãªä¸»å¼µã®ä¸¡æ–¹ã‚’å«ã‚€é•·æ–‡ç”Ÿæˆã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã€‚äººé–“è©•ä¾¡ã§ã¯VERISCOREãŒä»–ã®æ–¹æ³•ã‚ˆã‚Šã‚‚ç†ã«ã‹ãªã£ã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã€16ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ãŸçµæœã€GPT-4oãŒæœ€ã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸãŒã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆãƒ¢ãƒ‡ãƒ«ã‚‚å·®ã‚’ç¸®ã‚ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚ã¾ãŸã€ç•°ãªã‚‹ã‚¿ã‚¹ã‚¯é–“ã§VERISCOREã®ç›¸é–¢ãŒãªã„ã“ã¨ã‹ã‚‰ã€äº‹å®Ÿæ€§è©•ä¾¡ã®æ‹¡å¼µãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®å¿œç­”ã‹ã‚‰verifiableãªclaimã®ã¿ã‚’æŠ½å‡ºã—ã€ãã‚Œã‚’å¤–éƒ¨ã®æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆgoogleæ¤œç´¢ï¼‰ã®ã‚¯ã‚¨ãƒªã¨ã—ã¦å…¥åŠ›ã€‚æ¤œç´¢çµæœã‹ã‚‰claimãŒsupportã•ã‚Œã‚‹ã‹å¦ã‹ã‚’LLMã«ã‚ˆã£ã¦åˆ¤æ–­ã—ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/495a7952-8240-4b3b-8b8c-c0c52dea0e74" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-08-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2374" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LongBench: A Bilingual, Multitask Benchmark for Long Context   Understanding, Yushi Bai+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç†è§£ã®ãŸã‚ã®åˆã®ãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«ãƒ»ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒLongBenchã€ã‚’ææ¡ˆã€‚è‹±èªã¨ä¸­å›½èªã§21ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å«ã¿ã€å¹³å‡é•·ã¯ãã‚Œãã‚Œ6,711èªã¨13,386æ–‡å­—ã€‚ã‚¿ã‚¹ã‚¯ã¯QAã€è¦ç´„ã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ãªã©å¤šå²ã«ã‚ãŸã‚‹ã€‚è©•ä¾¡çµæœã‹ã‚‰ã€å•†æ¥­ãƒ¢ãƒ‡ãƒ«ã¯ä»–ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ãŒã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã¯ä¾ç„¶ã¨ã—ã¦èª²é¡ŒãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>PLaMo Primeã®é•·æ–‡ãƒ†ã‚­ã‚¹ãƒˆè©•ä¾¡ã«åˆ©ç”¨ã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆä¸­å›½èªã¨è‹±èªã®ãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ã‚ã‚Šæ—¥æœ¬èªã¯å­˜åœ¨ã—ãªã„ï¼‰<br><br>PLaMo Primeãƒªãƒªãƒ¼ã‚¹ã«ãŠã‘ã‚‹æ©Ÿèƒ½æ”¹å–„: 


<a href="https://tech.preferred.jp/ja/blog/plamo-prime-release-feature-update/" target="_blank" rel="noopener noreferrer">https://tech.preferred.jp/ja/blog/plamo-prime-release-feature-update/</a>


<br><br>ã‚¿ã‚¹ã‚¯ã¨è¨€èªã”ã¨ã®Lengthã®åˆ†å¸ƒã€‚è‹±èªã®æ–¹ãŒãƒ‡ãƒ¼ã‚¿ãŒè±Šå¯Œã§ã€é•·ã„ã‚‚ã®ã ã¨30000--40000ã‚‚ã®lengthã®ã‚µãƒ³ãƒ—ãƒ«ã‚‚ã‚ã‚‹æ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/a1104f3f-996a-4ad9-b6c3-55b2eb7921ab" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-08-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2368" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for   Sparse Architectural Large Language Models, Zihan Wang+, EMNLP'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Mixture-of-Expertsï¼ˆMoEï¼‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æŒã¤å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«å¯¾ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡ã®è‰¯ã„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆPEFTï¼‰æ‰‹æ³•ã‚’ææ¡ˆã€‚ä¸»ãªå†…å®¹ã¯ã€(1) ã‚¿ã‚¹ã‚¯ã”ã¨ã®å°‚é–€å®¶ã®æ´»æ€§åŒ–åˆ†å¸ƒã®é›†ä¸­åº¦ã®èª¿æŸ»ã€(2) Expert-Specialized Fine-Tuningï¼ˆESFTï¼‰ã®ææ¡ˆã¨ãã®åŠ¹æœã€(3) MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å°‚é–€å®¶ç‰¹åŒ–å‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¸ã®å½±éŸ¿ã®åˆ†æã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ESFTãŒãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã€ãƒ•ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«åŒ¹æ•µã¾ãŸã¯ãã‚Œã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wzihanw/status/1952965138845450413?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æŒã¤LLMã«ãŠã„ã¦ã€finetuningã‚’å®Ÿæ–½ã—ãŸã„ã‚¿ã‚¹ã‚¯ã«é–¢é€£ã™ã‚‹å°‚é–€å®¶ã‚’ç‰¹å®šã—ã€ãã®ã»ã‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’freezeã—ãŸä¸Šã§å½“è©²å°‚é–€å®¶ã®ã¿ã‚’trainableã¨ã™ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ã«finetuningã‚’å®Ÿæ–½ã™ã‚‹æ‰‹æ³•<br><img src="https://github.com/user-attachments/assets/ba82f425-5b61-4ce7-803b-4eb3fb375c41" alt="image" loading="lazy"><br><br>å°‚é–€å®¶ã‚’è¦‹ã¤ã‘ã‚‹éš›ã«ã¯å°‚é–€å®¶ã”ã¨ã«finetuningã—ãŸã„ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹relevance scoreã‚’è¨ˆç®—ã™ã‚‹ã€‚ãã®ãŸã‚ã«ã€2ã¤ã®æ‰‹æ³•ãŒææ¡ˆã•ã‚Œã¦ãŠã‚Šã€training dataã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—<br>- å…¨ã¦ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸãƒ‡ãƒ¼ã‚¿ã®å„ãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ã®MoE Routerã®gateã®å€¤ã®å¹³å‡å€¤ã‚’relevant scoreã¨ã™ã‚‹æ–¹æ³•<br>- å…¨ã¦ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸãƒ‡ãƒ¼ã‚¿ã®å„ãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ã«é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã®å‰²åˆ<br>ã®2ç¨®é¡ã§ã‚¹ã‚³ã‚¢ã‚’æ±‚ã‚ã‚‹ã€‚é–¾å€¤pã‚’æ±ºå®šã—ã€é–¾å€¤ä»¥ä¸Šã®ã‚¹ã‚³ã‚¢ã‚’æŒã¤å°‚é–€å®¶ã‚’trainableã¨ã™ã‚‹ã€‚<br><br>LoRAã‚ˆã‚Šã‚‚math, codeãªã©ã®ä»–ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ã‚¿ã‚¹ã‚¯æ€§èƒ½ã‚’åŠ£åŒ–ã•ã›ãšã€Finetuningå¯¾è±¡ã®ã‚¿ã‚¹ã‚¯ã§FFTã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã€‚<br><img src="https://github.com/user-attachments/assets/302eebda-bace-4b99-bb73-5e7e3ce10448" alt="image" loading="lazy"><br><br>LoRAã¨åŒæ§˜ã«FFTã¨æ¯”è¼ƒã—å­¦ç¿’æ™‚é–“ã¯çŸ­ç¸®ã•ã‚Œã€å­¦ç¿’ã—ãŸå°‚é–€å®¶ã®é‡ã¿ã‚’ä¿æŒã™ã‚‹ã ã‘ã§è‰¯ã„ã®ã§ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚‚ç¯€ç´„ã§ãã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/b02a8d53-6967-4dd2-9290-de06f27e48c9" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2338" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] YaRN: Efficient Context Window Extension of Large Language Models, Bowen Peng+, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- YaRNï¼ˆYet another RoPE extensioN methodï¼‰ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹ä½ç½®æƒ…å ±ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’åŠ¹ç‡çš„ã«è¡Œã„ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’å¾“æ¥ã®æ–¹æ³•ã‚ˆã‚Šã‚‚10å€å°‘ãªã„ãƒˆãƒ¼ã‚¯ãƒ³ã¨2.5å€å°‘ãªã„è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—ã§æ‹¡å¼µã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚LLaMAãƒ¢ãƒ‡ãƒ«ãŒé•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åŠ¹æœçš„ã«åˆ©ç”¨ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã€128kã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã¾ã§å†ç¾å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=wHBfxhZu1u" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=wHBfxhZu1u</a>


</p>
<p>ç¾åœ¨ä¸»æµãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ‹¡å¼µæ‰‹æ³•ã€‚æ§˜ã€…ãªãƒ¢ãƒ‡ãƒ«ã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚</p>
<p>æ—¥æœ¬èªè§£èª¬:


<a href="https://zenn.dev/bilzard/scraps/de7ecd3c380b6e" target="_blank" rel="noopener noreferrer">https://zenn.dev/bilzard/scraps/de7ecd3c380b6e</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/AES(AutomatedEssayScoring).html" target="_blank" rel="noopener noreferrer">#AES(AutomatedEssayScoring)</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AIED.html" target="_blank" rel="noopener noreferrer">#AIED</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2316" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Impact of Example Selection in Few-Shot Prompting on Automated Essay   Scoring Using GPT Models, Lui Yoshida, AIED'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€GPTãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå°‘æ•°ã‚·ãƒ§ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã«ãŠã‘ã‚‹ä¾‹ã®é¸æŠãŒè‡ªå‹•ã‚¨ãƒƒã‚»ã‚¤æ¡ç‚¹ï¼ˆAESï¼‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã€‚119ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”¨ã„ã¦ã€GPT-3.5ã¨GPT-4ã®ãƒ¢ãƒ‡ãƒ«é–“ã§ã®ã‚¹ã‚³ã‚¢ä¸€è‡´ã‚’äºŒæ¬¡é‡ã¿ä»˜ãã‚«ãƒƒãƒ‘ï¼ˆQWKï¼‰ã§æ¸¬å®šã€‚çµæœã€ä¾‹ã®é¸æŠãŒãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ç•°ãªã‚‹å½±éŸ¿ã‚’åŠã¼ã—ã€ç‰¹ã«GPT-3.5ã¯ãƒã‚¤ã‚¢ã‚¹ã®å½±éŸ¿ã‚’å—ã‘ã‚„ã™ã„ã“ã¨ãŒåˆ¤æ˜ã€‚æ…é‡ãªä¾‹ã®é¸æŠã«ã‚ˆã‚Šã€GPT-3.5ãŒä¸€éƒ¨ã®GPT-4ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŒã€GPT-4ã¯æœ€ã‚‚é«˜ã„å®‰å®šæ€§ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€AESã«ãŠã‘ã‚‹ä¾‹ã®é¸æŠã®é‡è¦æ€§ã¨ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ã®å¿…è¦æ€§ãŒå¼·èª¿ã•ã‚Œã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/MLSys.html" target="_blank" rel="noopener noreferrer">#MLSys</a>
<span class="issue_date">Issue Date: 2025-07-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2264" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AWQ: Activation-aware Weight Quantization for LLM Compression and   Acceleration, Ji Lin+, MLSys'24</a>
<span class="snippet"><span>GPT Summary</span>- Activation-aware Weight Quantizationï¼ˆAWQï¼‰ã‚’ææ¡ˆã—ã€LLMã®ä½ãƒ“ãƒƒãƒˆé‡ã¿é‡å­åŒ–ã‚’åŠ¹ç‡åŒ–ã€‚é¡•è‘—ãªé‡ã¿ãƒãƒ£ãƒãƒ«ã‚’ä¿è­·ã™ã‚‹ã“ã¨ã§é‡å­åŒ–èª¤å·®ã‚’å‰Šæ¸›ã—ã€ç•°ãªã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ä¸€èˆ¬åŒ–å¯èƒ½ã€‚AWQã¯è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€4ãƒ“ãƒƒãƒˆã®ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹LLM/VLMå‘ã‘æ¨è«–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯TinyChatã‚’å®Ÿè£…ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ãŠã‚ˆã³ãƒ¢ãƒã‚¤ãƒ«GPUã§ã®å‡¦ç†é€Ÿåº¦ã‚’3å€ä»¥ä¸Šå‘ä¸Šã•ã›ã€70B Llama-2ãƒ¢ãƒ‡ãƒ«ã®å±•é–‹ã‚’å®¹æ˜“ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://qiita.com/kyad/items/96a4a2bdec3f0dc09d23" target="_blank" rel="noopener noreferrer">https://qiita.com/kyad/items/96a4a2bdec3f0dc09d23</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2025-07-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2199" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] StarCoder 2 and The Stack v2: The Next Generation, Anton Lozhkov+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- BigCodeãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€è²¬ä»»ã‚ã‚‹Code LLMsã®é–‹ç™ºã«ç„¦ç‚¹ã‚’å½“ã¦ã€StarCoder2ã‚’ç™ºè¡¨ã€‚Software Heritageã¨ææºã—ã€The Stack v2ã‚’æ§‹ç¯‰ã—ã€619ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã‚’å«ã‚€å¤§è¦æ¨¡ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚»ãƒƒãƒˆã‚’ä½œæˆã€‚StarCoder2ãƒ¢ãƒ‡ãƒ«ã¯3Bã€7Bã€15Bã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¡ã€å¾¹åº•çš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ã€‚ç‰¹ã«StarCoder2-15Bã¯ã€åŒç­‰ã®ä»–ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€æ•°å­¦ã‚„ã‚³ãƒ¼ãƒ‰æ¨è«–ã§ã‚‚é«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã€‚ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã¯OpenRAILãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§å…¬é–‹ã•ã‚Œã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®é€æ˜æ€§ã‚‚ç¢ºä¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/661" target="_blank" rel="noopener noreferrer">StarCoderBase/StarCoder, 2023</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-07-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2127" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Iterative Reasoning Preference Optimization, Richard Yuanzhe Pang+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- åå¾©çš„ãªå¥½ã¿æœ€é©åŒ–æ‰‹æ³•ã‚’ç”¨ã„ã¦ã€Chain-of-Thoughtï¼ˆCoTï¼‰å€™è£œé–“ã®æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’æœ€é©åŒ–ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’é–‹ç™ºã€‚ä¿®æ­£DPOæå¤±ã‚’ä½¿ç”¨ã—ã€æ¨è«–ã®æ”¹å–„ã‚’ç¤ºã™ã€‚Llama-2-70B-Chatãƒ¢ãƒ‡ãƒ«ã§GSM8Kã€MATHã€ARC-Challengeã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€GSM8Kã§ã¯55.6%ã‹ã‚‰81.6%ã«æ”¹å–„ã€‚å¤šæ•°æ±ºã«ã‚ˆã‚‹ç²¾åº¦ã¯88.7%ã«é”ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=4XIKfvNYvx&referrer=%5Bthe%20profile%20of%20He%20He%5D(%2Fprofile%3Fid%3D~He_He2)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=4XIKfvNYvx&referrer=%5Bthe%20profile%20of%20He%20He%5D(%2Fprofile%3Fid%3D~He_He2)</a>


</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1212" target="_blank" rel="noopener noreferrer">Self-Rewarding Language Models, Weizhe Yuan+, N/A, ICML'24</a>
<br><br>ã¨ä¼¼ãŸã‚ˆã†ã«iterativeãªmannerã§reasoningèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/a0f10e8e-454d-40e8-ae67-8c6c2da6a0ed" alt="image" loading="lazy"><br><br>ãŸã ã—ã€loss functionã¨ã—ã¦ã¯ã€chosenãªCoT+yã®responseã«å¯¾ã—ã¦ã€reasoning traceã‚’ç”Ÿæˆã™ã‚‹èƒ½åŠ›ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã€NLL Lossã‚‚é©ç”¨ã—ã¦ã„ã‚‹ç‚¹ã«æ³¨æ„ã€‚<br><img src="https://github.com/user-attachments/assets/5ae2dcba-09c8-4618-9b63-ae6aed5b234d" alt="image" loading="lazy"><br><br>32 samplesã®majority votingã«ã‚ˆã£ã¦ã‚ˆã‚Šé«˜ã„æ€§èƒ½ãŒé”æˆã§ãã¦ã„ã‚‹ã®ã§ã€å¤šæ§˜ãªreasoning traceãŒç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/PRM.html" target="_blank" rel="noopener noreferrer">#PRM</a>
<span class="issue_date">Issue Date: 2025-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2103" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Let's Verify Step by Step, Hunter Lightman+, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å¤šæ®µéšæ¨è«–èƒ½åŠ›ãŒå‘ä¸Šã™ã‚‹ä¸­ã€è«–ç†çš„èª¤ã‚ŠãŒä¾ç„¶ã¨ã—ã¦å•é¡Œã§ã‚ã‚‹ã€‚ä¿¡é ¼æ€§ã®é«˜ã„ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ãŸã‚ã«ã¯ã€çµæœç›£è¦–ã¨ãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–ã®æ¯”è¼ƒãŒé‡è¦ã§ã‚ã‚‹ã€‚ç‹¬è‡ªã®èª¿æŸ»ã«ã‚ˆã‚Šã€ãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–ãŒMATHãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å•é¡Œè§£æ±ºã«ãŠã„ã¦çµæœç›£è¦–ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã€78%ã®å•é¡Œã‚’è§£æ±ºã—ãŸã€‚ã¾ãŸã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãŒãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–ã®åŠ¹æœã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚‚ç¤ºã—ãŸã€‚é–¢é€£ç ”ç©¶ã®ãŸã‚ã«ã€80ä¸‡ã®äººé–“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ©ãƒ™ãƒ«ã‹ã‚‰ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆPRM800Kã‚’å…¬é–‹ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=v8L0pN6EOi" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=v8L0pN6EOi</a>


</p>
<p>PRM800K:


<a href="https://github.com/openai/prm800k/tree/main" target="_blank" rel="noopener noreferrer">https://github.com/openai/prm800k/tree/main</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2102" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RewardBench: Evaluating Reward Models for Language Modeling, Nathan Lambert+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼ˆRMsï¼‰ã®è©•ä¾¡ã«é–¢ã™ã‚‹ç ”ç©¶ã¯å°‘ãªãã€æˆ‘ã€…ã¯ãã®ç†è§£ã‚’æ·±ã‚ã‚‹ãŸã‚ã«RewardBenchã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€ãƒãƒ£ãƒƒãƒˆã‚„æ¨è«–ã€å®‰å…¨æ€§ã«é–¢ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã§ã€å ±é…¬ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹ã€‚ç‰¹å®šã®æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€å¥½ã¾ã‚Œã‚‹ç†ç”±ã‚’æ¤œè¨¼å¯èƒ½ãªå½¢ã§ç¤ºã—ã€ã•ã¾ã–ã¾ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã«ã‚ˆã‚‹å ±é…¬ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã‚’è¡Œã†ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å ±é…¬ãƒ¢ãƒ‡ãƒ«ã®æ‹’å¦å‚¾å‘ã‚„æ¨è«–ã®é™ç•Œã«ã¤ã„ã¦ã®çŸ¥è¦‹ã‚’å¾—ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2096" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Chat Vector: A Simple Approach to Equip LLMs with Instruction Following   and Model Alignment in New Languages, Shih-Cheng Huang+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å¤šãã¯è‹±èªã«åã£ã¦ã„ã‚‹å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€chat vectorã¨ã„ã†æ¦‚å¿µã‚’å°å…¥ã€‚ã“ã‚Œã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‹ã‚‰ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’å¼•ãã“ã¨ã§ç”Ÿæˆã•ã‚Œã€è¿½åŠ ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã«æ–°ã—ã„è¨€èªã§ã®ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã‚’ä»˜ä¸ã§ãã‚‹ã€‚å®Ÿè¨¼ç ”ç©¶ã§ã¯ã€æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã‚„æœ‰å®³æ€§ã®è»½æ¸›ã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å¯¾è©±ã«ãŠã„ã¦chat vectorã®åŠ¹æœã‚’ç¤ºã—ã€ã•ã¾ã–ã¾ãªè¨€èªã‚„ãƒ¢ãƒ‡ãƒ«ã§ã®é©å¿œæ€§ã‚’ç¢ºèªã€‚chat vectorã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«å¯¾è©±æ©Ÿèƒ½ã‚’åŠ¹ç‡çš„ã«å®Ÿè£…ã™ã‚‹ãŸã‚ã®æœ‰åŠ›ãªè§£æ±ºç­–ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://qiita.com/jovyan/items/ee6affa5ee5bdaada6b4" target="_blank" rel="noopener noreferrer">https://qiita.com/jovyan/items/ee6affa5ee5bdaada6b4</a>


</p>
<p>ä¸‹è¨˜ãƒ–ãƒ­ã‚°ã«ã‚ˆã‚‹ã¨Chatã ã‘ã§ã¯ãªãã€Reasoningã§ã‚‚ï¼ˆpost-trainingãŒå¿…è¦ã ãŒï¼‰ä½¿ãˆã‚‹æ¨¡æ§˜<br><br>Reasoningèƒ½åŠ›ã‚’ä»˜ä¸ã—ãŸLLM ABEJA-QwQ32b-Reasoning-Japanese-v1.0ã®å…¬é–‹, Abeja Tech Blog, 2025.04:<br>


<a href="https://tech-blog.abeja.asia/entry/geniac2-qwen25-32b-reasoning-v1.0" target="_blank" rel="noopener noreferrer">https://tech-blog.abeja.asia/entry/geniac2-qwen25-32b-reasoning-v1.0</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/PPO%20(ProximalPolicyOptimization).html" target="_blank" rel="noopener noreferrer">#PPO (ProximalPolicyOptimization)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2090" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy   Data, Fahim Tajwar+, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- å¥½ã¿ã®ãƒ©ãƒ™ãƒ«ã‚’ç”¨ã„ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«é–¢ã™ã‚‹ç ”ç©¶ã€‚ã‚ªãƒ³ãƒãƒªã‚·ãƒ¼å¼·åŒ–å­¦ç¿’ã‚„å¯¾ç…§å­¦ç¿’ãªã©ã®æ‰‹æ³•ã‚’æ¯”è¼ƒã—ã€ã‚ªãƒ³ãƒãƒªã‚·ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚„è² ã®å‹¾é…ã‚’ç”¨ã„ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå„ªã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒã®ç‰¹å®šã®ãƒ“ãƒ³ã«ãŠã‘ã‚‹ç¢ºç‡è³ªé‡ã‚’è¿…é€Ÿã«å¤‰æ›´ã§ãã‚‹ãƒ¢ãƒ¼ãƒ‰æ¢ç´¢ç›®çš„ã®é‡è¦æ€§ã‚’ç¤ºã—ã€ãƒ‡ãƒ¼ã‚¿åé›†ã®æœ€é©åŒ–ã«é–¢ã™ã‚‹æ´å¯Ÿã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹ã®ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ vs. ã‚ªãƒ³ãƒ©ã‚¤ãƒ³RLã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§æœ¬ç ”ç©¶ãŒå¼•ç”¨ã•ã‚Œã¦ã„ã‚‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cwolferesearch/status/1965088925510520853?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2089" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Instruction Pre-Training: Language Models are Supervised Multitask   Learners, Daixuan Cheng+, EMNLP'24</a>
<span class="snippet"><span>GPT Summary</span>- ç„¡ç›£ç£ã®ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯äº‹å‰å­¦ç¿’ã«åŠ ãˆã€ç›£è¦–ã•ã‚ŒãŸãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®å¯èƒ½æ€§ã‚’æ¢ã‚‹ãŸã‚ã«ã€Instruction Pre-Trainingãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚æŒ‡ç¤ºå¿œç­”ãƒšã‚¢ã‚’ç”Ÿæˆã—ã€2å„„ã®ãƒšã‚¢ã‚’åˆæˆã—ã¦å®Ÿé¨“ã‚’è¡Œã„ã€äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚Instruction Pre-Trainingã¯Llama3-8Bã‚’Llama3-70Bã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã«å¼•ãä¸Šã’ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1992" target="_blank" rel="noopener noreferrer" class="title-link">Densing Law of LLMs, Chaojun Xiao+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ€§èƒ½å‘ä¸Šã«ä¼´ã†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®åŠ¹ç‡ã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ã€Œã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£å¯†åº¦ã€ã¨ã„ã†æ–°ã—ã„æŒ‡æ¨™ã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆLLMã®æœ‰åŠ¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¨å®Ÿéš›ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®æ¯”ç‡ã‚’ç”¨ã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®åŠ¹æœã¨åŠ¹ç‡ã‚’è©•ä¾¡ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã™ã‚‹ã€‚åˆ†æã«ã‚ˆã‚Šã€LLMsã®ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£å¯†åº¦ã¯ç´„3ã‹æœˆã”ã¨ã«å€å¢—ã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€ä»Šå¾Œã®LLMé–‹ç™ºã«ãŠã‘ã‚‹é‡è¦æ€§ãŒå¼·èª¿ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1926785750277693859?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/user-attachments/assets/8cdcfe78-6682-481b-a6b0-a175b84d735c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-05-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1951" target="_blank" rel="noopener noreferrer" class="title-link">UltraFeedback: Boosting Language Models with Scaled AI Feedback, Ganqu Cui+, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŠ ãˆã€é«˜å“è³ªãªAIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è‡ªå‹•åé›†ã™ã‚‹ã“ã¨ã§ã€LLMsã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã«å®Ÿç¾ã€‚å¤šæ§˜ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚«ãƒãƒ¼ã—ã€æ³¨é‡ˆãƒã‚¤ã‚¢ã‚¹ã‚’è»½æ¸›ã—ãŸçµæœã€25ä¸‡ä»¶ã®ä¼šè©±ã«å¯¾ã™ã‚‹100ä¸‡ä»¶ä»¥ä¸Šã®GPT-4ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒUltraFeedbackã€ã‚’æ§‹ç¯‰ã€‚ã“ã‚Œã«åŸºã¥ãã€LLaMAãƒ¢ãƒ‡ãƒ«ã‚’å¼·åŒ–å­¦ç¿’ã§ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã—ã€ãƒãƒ£ãƒƒãƒˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ã€‚ç ”ç©¶ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã«ãŠã‘ã‚‹AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼ã€‚ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ä¸­ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-05-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1950" target="_blank" rel="noopener noreferrer" class="title-link">ORPO: Monolithic Preference Optimization without Reference Model, Jiwoo Hong+, EMNLP'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€å¥½ã¿ã®æ•´åˆæ€§ã«ãŠã‘ã‚‹ç›£è¦–ä»˜ããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã€ã‚ãšã‹ãªãƒšãƒŠãƒ«ãƒ†ã‚£ã§å¥½ã¿ã«æ•´åˆã—ãŸSFTãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ã•ã‚‰ã«ã€è¿½åŠ ã®æ•´åˆæ€§ãƒ•ã‚§ãƒ¼ã‚ºã‚’å¿…è¦ã¨ã—ãªã„æ–°ã—ã„ã‚ªãƒƒã‚ºæ¯”æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ORPOã‚’ææ¡ˆã—ã€ã“ã‚Œã‚’ç”¨ã„ã¦è¤‡æ•°ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸçµæœã€æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ã–ã£ãã‚Šè¨€ã†ã¨instruction tuningã¨alignmentã‚’åŒæ™‚ã«ã§ãã‚‹æ‰‹æ³•ã‚‰ã—ã„ãŒã¾ã ç†è§£ã§ãã¦ã„ãªã„</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-05-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1947" target="_blank" rel="noopener noreferrer" class="title-link">EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language   Models, Peng Wang+, ACL'24, ï¼ˆSystem Demonstrationsï¼‰</a>
<span class="snippet"><span>GPT Summary</span>- EasyEditã¯ã€LLMsã®ãŸã‚ã®ä½¿ã„ã‚„ã™ã„çŸ¥è­˜ç·¨é›†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ã•ã¾ã–ã¾ãªçŸ¥è­˜ç·¨é›†ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ã‚µãƒãƒ¼ãƒˆã€‚LlaMA-2ã®å®Ÿé¨“çµæœã§ã¯ã€ä¿¡é ¼æ€§ã¨ä¸€èˆ¬åŒ–ã®é¢ã§å¾“æ¥ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚GitHubã§ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã—ã€Google Colabãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚„ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚‚æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>ver2.0:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1946" target="_blank" rel="noopener noreferrer">EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language
  Models, Ziwen Xu+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<span class="issue_date">Issue Date: 2025-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1943" target="_blank" rel="noopener noreferrer" class="title-link">DataComp-LM: In search of the next generation of training sets for  language models, Jeffrey Li+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- DataComp for Language Modelsï¼ˆDCLMï¼‰ã‚’ç´¹ä»‹ã—ã€240Tãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã¨53ã®è©•ä¾¡ã‚¹ã‚¤ãƒ¼ãƒˆã‚’æä¾›ã€‚DCLMã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚±ãƒ¼ãƒ«412Mã‹ã‚‰7Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥ã‚’å®Ÿé¨“å¯èƒ½ã€‚DCLM-Baselineã¯2.6Tãƒˆãƒ¼ã‚¯ãƒ³ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€MMLUã§64%ã®ç²¾åº¦ã‚’é”æˆã—ã€å¾“æ¥ã®MAP-Neoã‚ˆã‚Š6.6ãƒã‚¤ãƒ³ãƒˆæ”¹å–„ã€‚è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚‚40%å‰Šæ¸›ã€‚çµæœã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­è¨ˆã®é‡è¦æ€§ã‚’ç¤ºã—ã€ä»Šå¾Œã®ç ”ç©¶ã®åŸºç›¤ã‚’æä¾›ã€‚</span>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1942" target="_blank" rel="noopener noreferrer" class="title-link">The FineWeb Datasets: Decanting the Web for the Finest Text Data at   Scale, Guilherme Penedo+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€15å…†ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰ãªã‚‹FineWebãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç´¹ä»‹ã—ã€LLMã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚FineWebã¯é«˜å“è³ªãªäº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ–¹æ³•ã‚’æ–‡æ›¸åŒ–ã—ã€é‡è¤‡æ’é™¤ã‚„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æˆ¦ç•¥ã‚’è©³ç´°ã«èª¿æŸ»ã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€FineWebã‹ã‚‰æ´¾ç”Ÿã—ãŸ1.3å…†ãƒˆãƒ¼ã‚¯ãƒ³ã®FineWeb-Eduã‚’ç”¨ã„ãŸLLMã¯ã€MMLUã‚„ARCãªã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã€ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://zenn.dev/deepkawamura/articles/da9aeca6d6d9f9" target="_blank" rel="noopener noreferrer">https://zenn.dev/deepkawamura/articles/da9aeca6d6d9f9</a>


</p>
<p>openreview:


<a href="https://openreview.net/forum?id=n6SCkn2QaG#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=n6SCkn2QaG#discussion</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1933" target="_blank" rel="noopener noreferrer" class="title-link">Editing Large Language Models: Problems, Methods, and Opportunities, Yunzhi Yao+, EMNLP'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ç·¨é›†æŠ€è¡“ã®é€²å±•ã‚’æ¢æ±‚ã—ã€ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®åŠ¹ç‡çš„ãªå‹•ä½œå¤‰æ›´ã¨ä»–ã®å…¥åŠ›ã¸ã®å½±éŸ¿ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹æ–¹æ³•ã‚’è«–ã˜ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ç·¨é›†ã®ã‚¿ã‚¹ã‚¯å®šç¾©ã‚„èª²é¡Œã‚’åŒ…æ‹¬çš„ã«ã¾ã¨ã‚ã€å…ˆé€²çš„ãªæ‰‹æ³•ã®å®Ÿè¨¼åˆ†æã‚’è¡Œã†ã€‚ã¾ãŸã€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã€è©•ä¾¡ã®å‘ä¸Šã¨æŒç¶šçš„ãªå•é¡Œã®ç‰¹å®šã‚’ç›®æŒ‡ã™ã€‚æœ€çµ‚çš„ã«ã€ç·¨é›†æŠ€è¡“ã®åŠ¹æœã«é–¢ã™ã‚‹æ´å¯Ÿã‚’æä¾›ã—ã€é©åˆ‡ãªæ–¹æ³•é¸æŠã‚’æ”¯æ´ã™ã‚‹ã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1929" target="_blank" rel="noopener noreferrer" class="title-link">Physics of Language Models: Part 4.1, Architecture Design and the Magic of Canon Layers, Zeyuan Allen-Zhu+, ICML'24 Tutorial</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1919878625488449849?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Canonå±¤ã®ç™ºè¦‹</p>
<p>è‘—è€…ã«ã‚ˆã‚‹è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zeyuanallenzhu/status/1918684257058197922?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1923" target="_blank" rel="noopener noreferrer" class="title-link">Physics of Language Models: Part 3.1, Knowledge Storage and Extraction, Zeyuan Allen-Zhu+, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®çŸ¥è­˜æŠ½å‡ºèƒ½åŠ›ã¯ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ã¨å¼·ãç›¸é–¢ã—ã¦ãŠã‚Šã€ååˆ†ãªå¼·åŒ–ãŒãªã‘ã‚Œã°çŸ¥è­˜ã¯è¨˜æ†¶ã•ã‚Œã¦ã‚‚æŠ½å‡ºå¯èƒ½ã§ã¯ãªã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚å…·ä½“çš„ã«ã¯ã€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã®éš ã‚ŒåŸ‹ã‚è¾¼ã¿ã«çŸ¥è­˜ãŒã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹ã€ä»–ã®ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ã«åˆ†æ•£ã—ã¦ã„ã‚‹ã‹ã‚’èª¿æŸ»ã€‚LLMã®ãƒ—ãƒ¬ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«é–¢ã™ã‚‹é‡è¦ãªæ¨å¥¨äº‹é …ã¨ã—ã¦ã€è£œåŠ©ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸãƒ‡ãƒ¼ã‚¿å†æ§‹æˆã¨æŒ‡ç¤ºå¾®èª¿æ•´ãƒ‡ãƒ¼ã‚¿ã®æ—©æœŸå–ã‚Šå…¥ã‚ŒãŒææ¡ˆã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>è§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
</p>
<p>SNLP'24ã§ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:<br>


<a href="https://speakerdeck.com/sosk/physics-of-language-models-part-3-1-knowledge-storage-and-extraction" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/sosk/physics-of-language-models-part-3-1-knowledge-storage-and-extraction</a>


</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-04-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1908" target="_blank" rel="noopener noreferrer" class="title-link">Safety Alignment Should Be Made More Than Just a Few Tokens Deep, Xiangyu Qi+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ç¾åœ¨ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å®‰å…¨æ€§ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã¯è„†å¼±ã§ã‚ã‚Šã€å˜ç´”ãªæ”»æ’ƒã‚„å–„æ„ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã£ã¦è„±ç„ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ã“ã®è„†å¼±æ€§ã¯ã€Œæµ…ã„å®‰å…¨æ€§ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã€ã«èµ·å› ã—ã€ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆãŒä¸»ã«æœ€åˆã®æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã®å‡ºåŠ›ã«ã®ã¿é©å¿œã•ã‚Œã‚‹ã“ã¨ã«é–¢é€£ã—ã¦ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€ã“ã®å•é¡Œã®ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚’æç¤ºã—ã€ç¾åœ¨ã®ã‚¢ãƒ©ã‚¤ãƒ³ã•ã‚ŒãŸLLMsãŒç›´é¢ã™ã‚‹è„†å¼±æ€§ã‚’èª¬æ˜ã™ã‚‹ã€‚ã¾ãŸã€æµ…ã„å®‰å…¨æ€§ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã®æ¦‚å¿µãŒè„†å¼±æ€§è»½æ¸›ã®ç ”ç©¶æ–¹å‘ã‚’ç¤ºå”†ã—ã€åˆæœŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¶…ãˆãŸã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã®æ·±åŒ–ãŒãƒ­ãƒã‚¹ãƒˆæ€§ã‚’å‘ä¸Šã•ã›ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã™ã€‚æœ€å¾Œã«ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ”»æ’ƒã«å¯¾ã™ã‚‹æŒç¶šçš„ãªå®‰å…¨æ€§ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®æ­£å‰‡åŒ–ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç›®çš„ã‚’ææ¡ˆã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1917006979836612640?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=6Mxhg9PtDE" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=6Mxhg9PtDE</a>


</p>
<p>Safety Alignmentæ‰‹æ³•ãŒæœ€åˆã®æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã«ä¾å­˜ã—ã¦ã„ã‚‹ã‹ã‚‰ãã†ãªã‚‰ãªã„ã‚ˆã†ã«å­¦ç¿’ã—ã¾ã™ã¨ã„ã†ã®ã¯ã€èˆˆå‘³æ·±ã„ãƒ†ãƒ¼ãƒã ã—æŠ€è¡“çš„ã«ã¾ã å›°é›£ãªç‚¹ã‚‚ã‚ã£ãŸã ã‚ã†ã—ã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚‚å¤§ãã„ã—ã€ã¨ã¦ã‚‚è‰¯ã„ç ”ç©¶ã â€¦ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Non-Determinism.html" target="_blank" rel="noopener noreferrer">#Non-Determinism</a>
<span class="issue_date">Issue Date: 2025-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1890" target="_blank" rel="noopener noreferrer" class="title-link">Non-Determinism of "Deterministic" LLM Settings, Berk Atil+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€5ã¤ã®æ±ºå®šè«–çš„LLMã«ãŠã‘ã‚‹éæ±ºå®šæ€§ã‚’8ã¤ã®ã‚¿ã‚¹ã‚¯ã§èª¿æŸ»ã—ã€æœ€å¤§15%ã®ç²¾åº¦å¤‰å‹•ã¨70%ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚®ãƒ£ãƒƒãƒ—ã‚’è¦³å¯Ÿã€‚å…¨ã¦ã®ã‚¿ã‚¹ã‚¯ã§ä¸€è²«ã—ãŸç²¾åº¦ã‚’æä¾›ã§ããªã„ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€éæ±ºå®šæ€§ãŒè¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã®åŠ¹ç‡çš„ä½¿ç”¨ã«å¯„ä¸ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚ŒãŸã€‚å‡ºåŠ›ã®åˆæ„ç‡ã‚’ç¤ºã™æ–°ãŸãªãƒ¡ãƒˆãƒªã‚¯ã‚¹TARr@Nã¨TARa@Nã‚’å°å…¥ã—ã€ç ”ç©¶çµæœã‚’å®šé‡åŒ–ã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>- è«–æ–‡ä¸­ã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/785" target="_blank" rel="noopener noreferrer">Beyond the Imitation Game: Quantifying and extrapolating the   capabilities of language models, Aarohi Srivastava+, N/A, TMLR'23</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/901" target="_blank" rel="noopener noreferrer">Measuring Massive Multitask Language Understanding, Dan Hendrycks+, N/A, ICLR'21</a>
 </p>
<p>åŒã˜ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€seedã‚’å›ºå®šã—ã€temperatureã‚’0ã«è¨­å®šã—ã€åŒã˜è¨ˆç®—æ©Ÿç’°å¢ƒã«å¯¾ã—ã¦ã€åŒã˜inputã‚’å…¥åŠ›ã—ãŸã‚‰ç†è«–ä¸Šã¯LLMã®å‡ºåŠ›ã¯deterministicã«ãªã‚‹ã¯ãšã ãŒã€deterministicã«ãªã‚‰ãšã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã®æ€§èƒ½ã¨ãã‚‚ãã‚‚ã®raw responseè‡ªä½“ã‚‚è©¦è¡Œã”ã¨ã«å¤§ããå¤‰åŒ–ã™ã‚‹ã€ã¨ã„ã†è©±ã€‚<br>ãŸã ã—ã€ã“ã‚Œã¯ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªLLMã‚„ã€ä½•ã‚‰ã‹ã®inferenceã®é«˜é€ŸåŒ–ã‚’å®Ÿæ–½ã—ãŸInferenceEngineï¼ˆæœ¬ç ”ç©¶ã§ã¯Togetherã¨å‘¼ã°ã‚Œã‚‹å®Ÿè£…ã‚’ä½¿ã£ã¦ã„ãã†ã€‚vLLM/SGLangã ã¨ã©ã†ãªã‚‹ã®ã‹ãŒæ°—ã«ãªã‚‹ï¼‰ã‚’ç”¨ã„ã¦inferenceã‚’å®Ÿæ–½ã—ãŸå ´åˆã§ã®å®Ÿé¨“çµæœã§ã‚ã‚Šã€å¾Œè¿°ã®é€šã‚Šè¨ˆç®—ã®é«˜é€ŸåŒ–ã®ãŸã‚ã®ã•ã¾ã–ã¾ãªå®Ÿè£…ç„¡ã—ã§ã€deterministicãªè¨­å®šã§OpenLLMã§inferenceã™ã‚‹ã¨å‡ºåŠ›ã¯deterministicã«ãªã‚‹ã€ã¨ã„ã†ç‚¹ã«ã¯æ³¨æ„ã€‚<br><br>GPTã‚„Llamaã€Mixtralã«å¯¾ã—ã¦ä¸Šè¨˜ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ç”¨ã„ã¦zero-shot/few-shotã®è¨­å®šã§å®Ÿé¨“ã—ã¦ã„ã‚‹ã€‚Reasoningãƒ¢ãƒ‡ãƒ«ã¯å®Ÿé¨“ã«å«ã¾ã‚Œã¦ã„ãªã„ã€‚<br>&lt;img width="701" height="325" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/b33f14d8-ed86-4589-a427-18a70b35d61a"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/b33f14d8-ed86-4589-a427-18a70b35d61a"&lt;/a&gt;


/&gt;<br><br>LLMã®raw_response/multiple choiceã®parseçµæœï¼ˆi.e., å•é¡Œã«å¯¾ã™ã‚‹è§£ç­”éƒ¨åˆ†ã‚’æŠ½å‡ºã—ãŸçµæœï¼‰ã®ä¸€è‡´ï¼ˆTARr@N, TARa@N; Nã¯inferenceã®è©¦è¡Œå›æ•°ï¼‰ã‚‚ç†è«–ä¸Šã¯100%ã«ãªã‚‹ã¯ãšãªã®ã«ã€ãªã‚‰ãªã„ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>&lt;img width="712" height="432" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/3159ff26-fc92-4fa8-90a6-f8c5e7ccf20e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/3159ff26-fc92-4fa8-90a6-f8c5e7ccf20e"&lt;/a&gt;


/&gt;<br><br>correlation analysisã«ã‚ˆã£ã¦ã€å¿œç­”ã®é•·ã• ã¨ TAR{r, a}ãŒå¼·ã„è² ã®ç›¸é–¢ã‚’ç¤ºã—ã¦ãŠã‚Šã€å¿œç­”ãŒé•·ããªã‚Œã°ãªã‚‹ã»ã©ä¸å®‰å®šã•ã¯å¢—ã™ã“ã¨ãŒåˆ†æã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã®ãŸã‚ã€ontput tokenã®æœ€å¤§å€¤ã‚’åˆ¶é™ã™ã‚‹ã“ã¨ã§å‡ºåŠ›ã®å®‰å®šæ€§ãŒå¢—ã™ã“ã¨ã‚’è€ƒå¯Ÿã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€few-shotã«ãŠã„ã¦é«˜ã„Acc.ã®å ´åˆã¯å‡ºåŠ›ãŒdeterministicã«ãªã‚‹ã‚ã‘ã§ã¯ãªã„ãŒã€æ€§èƒ½ãŒå®‰å®šã™ã‚‹å‚¾å‘ã¨ã®ã“ã¨ã€‚ã¾ãŸã€OpenAIãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ä¸Šã§GPTã®finetuningã‚’å®Ÿæ–½ã—å®Ÿé¨“ã—ãŸãŒã€å®‰å®šæ€§ã«å¯„ä¸ã¯ã—ãŸãŒã€ã“ã¡ã‚‰ã‚‚deterministicã«ãªã‚‹ã‚ã‘ã§ã¯ãªã„ã¨ã®ã“ã¨ã€‚<br><br>deterministicã«ãªã‚‰ãªã„åŸå› ã¨ã—ã¦ã€ã¾ãšmulti gpuç’°å¢ƒã«ã¤ã„ã¦æ¤œè¨ã—ã¦ã„ã‚‹ãŒã€multi-gpuç’°å¢ƒã§ã¯ã‚ã‚‹ç¨‹åº¦ã®ãƒ©ãƒ³ãƒ€ãƒ æ€§ãŒç”Ÿã˜ã‚‹ã“ã¨ãŒNvidiaã®ç ”ç©¶ã«ã‚ˆã£ã¦å ±å‘Šã•ã‚Œã¦ã„ã‚‹ãŒã€ã“ã‚Œã¯seedã‚’å›ºå®šã™ã‚Œã°æ±ºå®šè«–çš„ã«ã§ãã‚‹ãŸã‚å•é¡Œã«ãªã‚‰ãªã„ã¨ã®ã“ã¨ã€‚<br>ç¶šã„ã¦ã€inferenceã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã®å®Ÿè£…ä¸Šã®å·¥å¤«ï¼ˆe.g., Chunk Prefilling, Prefix Caching, Continuous Batchingï¼‰ãªã©ã®å®Ÿè£…ãŒdeterministicãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚‚deterministicã«ãªã‚‰ãªã„åŸå› ã§ã‚ã‚‹ã¨è€ƒå¯Ÿã—ã¦ãŠã‚Šã€**å®Ÿéš›ã«localãƒã‚·ãƒ³ä¸Šã§ã“ã‚Œã‚‰inferenceã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã®æœ€é©åŒ–ã‚’ä½•ã‚‚å®Ÿæ–½ã—ãªã„çŠ¶æ…‹ã§Llama-8Bã§inferenceã‚’å®Ÿæ–½ã—ãŸã¨ã“ã‚ã€outputã¯deterministicã«ãªã£ãŸã¨ã®ã“ã¨ã€‚**</p>
<p>è«–æ–‡ä¸­ã«è¨˜è¼‰ãŒãªã‹ã£ãŸãŸã‚ã€ã©ã®ã‚ˆã†ãªInferenceEngineã‚’åˆ©ç”¨ã—ãŸã‹å…¬é–‹ã•ã‚Œã¦ã„ã‚‹githubã‚’è¦‹ã‚‹ã¨ä¸‹è¨˜ãŒåˆ©ç”¨ã•ã‚Œã¦ã„ãŸ:<br><br>- Together: 


<a href="https://github.com/togethercomputer/together-python?tab=readme-ov-file" target="_blank" rel="noopener noreferrer">https://github.com/togethercomputer/together-python?tab=readme-ov-file</a>


<br><br>TogetherãŒå†…éƒ¨çš„ã«ã©ã®ã‚ˆã†ãªå‡¦ç†ã‚’ã—ã¦ã„ã‚‹ã‹ã¾ã§ã¯è¿½ãˆã¦ã„ãªã„ã®ã ãŒã€ç•°ãªã‚‹InferenceEngineã‚’åˆ©ç”¨ã—ãŸå ´åˆã«ã€ã©ã®ç¨‹åº¦outputã®ä¸å®‰å®šã•ã«å·®ãŒå‡ºã‚‹ã®ã‹ï¼ˆã‚ã‚‹ã„ã¯å‡ºãªã„ã®ã‹ï¼‰ã¯æ°—ã«ãªã‚‹ã€‚ãŸã¨ãˆã°ã€transformers/vLLM/SGLangã‚’åˆ©ç”¨ã—ãŸå ´åˆãªã©ã§ã‚ã‚‹ã€‚<br><br>è«–æ–‡ä¸­ã§ã‚‚å ±å‘Šã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€æ˜”ç®¡ç†äººãŒtransformersã‚’ç”¨ã„ã¦ã€deterministicãªè¨­å®šã§zephyrã‚’ç”¨ã„ã¦inferenceã‚’ã—ãŸã¨ãã¯ã€å‡ºåŠ›ã¯deterministicã«ãªã£ã¦ã„ãŸã¨è¨˜æ†¶ã—ã¦ã„ã‚‹ï¼ˆã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¯çµ¶æœ›çš„ã ã£ãŸãŒ...)ã€‚</p>
<p>ã‚ã¨å€‹äººçš„ã«ã¯ç¾å®Ÿçš„ãªé€Ÿåº¦ã§ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§inference engineã‚’åˆ©ç”¨ã—ãŸæ™‚ã«deterministicã«ã¯ã›ã‚ã¦ãªã£ã¦æ¬²ã—ã„ãªã‚ã¨ã„ã†æ°—ã¯ã™ã‚‹ã®ã§ã€ä½•ãŒåŸå› ãªã®ã‹ã‚’å®Ÿè£…ãƒ¬ãƒ™ãƒ«ã§çªãè©°ã‚ã¦ãã‚Œã‚‹ã¨ã¨ã¦ã‚‚å¬‰ã—ã„ï¼ˆKV CacheãŒæ€ªã—ã„æ°—ãŒã™ã‚‹ã‘ã©ï¼‰ã€‚<br><br>ãŸã¨ãˆã°æœ€è¿‘SLMã ã£ãŸã‚‰KVCacheã—ã¦VRAMé£Ÿã†ã‚ˆã‚Šè¨ˆç®—ã—ç›´ã—ãŸæ–¹ãŒåŠ¹ç‡è‰¯ã„ã‚ˆã€ã¿ãŸã„ãªç ”ç©¶ãŒã‚ã£ãŸã‚ˆã†ãªã€‚ãã†ã„ã†ã“ã¨ã‚’ã—ãŸã‚‰local llmã§deterministicã«ãªã‚‰ãªã„ã®ã ã‚ã†ã‹ã€‚</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2763" target="_blank" rel="noopener noreferrer">Defeating Nondeterminism in LLM Inference, Horace He in collaboration with others at Thinking Machines, 2025.09</a>
<br><br>ã«ãŠã„ã¦vLLMã‚’ç”¨ã„ãŸå ´åˆã«Deterministicãªæ¨è«–ã‚’ã™ã‚‹ãŸã‚ã®è§£æ±ºæ–¹æ³•ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/API.html" target="_blank" rel="noopener noreferrer">#API</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-04-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1874" target="_blank" rel="noopener noreferrer" class="title-link">Gorilla: Large Language Model Connected with Massive APIs, Shishir G. Patil+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- Gorillaã¯ã€APIå‘¼ã³å‡ºã—ã®ç”Ÿæˆã«ãŠã„ã¦GPT-4ã‚’ä¸Šå›ã‚‹LLaMAãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€æ–‡æ›¸æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ãƒ†ã‚¹ãƒˆæ™‚ã®æ–‡æ›¸å¤‰æ›´ã«é©å¿œã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŸ”è»Ÿãªæ›´æ–°ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚å¹»è¦šã®å•é¡Œã‚’è»½æ¸›ã—ã€APIã‚’ã‚ˆã‚Šæ­£ç¢ºã«ä½¿ç”¨ã™ã‚‹èƒ½åŠ›ã‚’ç¤ºã—ã¾ã™ã€‚Gorillaã®è©•ä¾¡ã«ã¯æ–°ãŸã«å°å…¥ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒAPIBenchã€ã‚’ä½¿ç”¨ã—ã€ä¿¡é ¼æ€§ã¨é©ç”¨æ€§ã®å‘ä¸Šã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>APIBench:


<a href="https://huggingface.co/datasets/gorilla-llm/APIBench" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/gorilla-llm/APIBench</a>


</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=tBRNC6YemY" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=tBRNC6YemY</a>


</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<span class="issue_date">Issue Date: 2025-04-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1868" target="_blank" rel="noopener noreferrer" class="title-link">Foundational Challenges in Assuring Alignment and Safety of Large   Language Models, Usman Anwar+, TMLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMsã®æ•´åˆæ€§ã¨å®‰å…¨æ€§ã«é–¢ã™ã‚‹18ã®åŸºç›¤çš„èª²é¡Œã‚’ç‰¹å®šã—ã€ç§‘å­¦çš„ç†è§£ã€é–‹ç™ºãƒ»å±•é–‹æ–¹æ³•ã€ç¤¾ä¼šæŠ€è¡“çš„èª²é¡Œã®3ã¤ã®ã‚«ãƒ†ã‚´ãƒªã«æ•´ç†ã€‚ã“ã‚Œã«åŸºã¥ãã€200ä»¥ä¸Šã®å…·ä½“çš„ãªç ”ç©¶è³ªå•ã‚’æèµ·ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=oVTkOs8Pka" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=oVTkOs8Pka</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1854" target="_blank" rel="noopener noreferrer" class="title-link">Agent Workflow Memory, Zora Zhiruo Wang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ¡ãƒ¢ãƒªï¼ˆAWMï¼‰ã‚’å°å…¥ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå†åˆ©ç”¨å¯èƒ½ãªã‚¿ã‚¹ã‚¯ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€è¤‡é›‘ãªã‚¦ã‚§ãƒ–ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã‚’åŠ¹ç‡çš„ã«è§£æ±ºã€‚Mind2Webã¨WebArenaã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€æˆåŠŸç‡ã‚’ãã‚Œãã‚Œ24.6%ãŠã‚ˆã³51.1%å‘ä¸Šã•ã›ã€å¿…è¦ãªã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å‰Šæ¸›ã€‚ã‚ªãƒ³ãƒ©ã‚¤ãƒ³AWMã¯ã€ã‚¿ã‚¹ã‚¯ã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³ã«å¯¾ã—ã¦ã‚‚å …ç‰¢ã«ä¸€èˆ¬åŒ–ã—ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>éå»ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒpromptä¸­ã§åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã€åˆ©ç”¨ã™ã‚Œã°ã™ã‚‹ã»ã©è³¢ããªã‚‹ã‚ˆã†ãªä»•çµ„ã¿ã®ææ¡ˆ<br>&lt;img width="873" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/6160cfa5-9dbd-44c6-926c-a56eb698d78d"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/6160cfa5-9dbd-44c6-926c-a56eb698d78d"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1852" target="_blank" rel="noopener noreferrer" class="title-link">CoAct: A Global-Local Hierarchy for Autonomous Agent Collaboration, Xinming Hou+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- CoActãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€2ã¤ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«è¨ˆç”»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã‚’ç”¨ã„ã¦ã€LLMã®è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã¸ã®å¯¾å¿œåŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“ã§ã¯ã€WebArenaãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ãŠã„ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€å¤±æ•—æ™‚ã®ãƒ—ãƒ­ã‚»ã‚¹å†ç·¨æˆèƒ½åŠ›ã‚’ç¢ºèªã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ä¸­ã€‚</span>
<span class="snippet"><span>Comment</span><p>Planningã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨å®Ÿè¡Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ´»ç”¨ã™ã‚‹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ<br><br>&lt;img width="632" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/55db47b8-15f8-4a9c-b641-ce906994897f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/55db47b8-15f8-4a9c-b641-ce906994897f"&lt;/a&gt;


/&gt;<br><br>ReActã‚ˆã‚Šæ€§èƒ½å‘ä¸Š<br>-  <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/518" target="_blank" rel="noopener noreferrer">REACT : SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS, Yao+, Princeton University and Google brain, ICLR'23</a>
 <br>&lt;img width="325" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/79ac984a-1aa4-4d27-8a3f-860ed2c3abf7"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/79ac984a-1aa4-4d27-8a3f-860ed2c3abf7"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1851" target="_blank" rel="noopener noreferrer" class="title-link">Training Software Engineering Agents and Verifiers with SWE-Gym, Jiayi Pan+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- SWE-Gymã‚’ææ¡ˆã—ã€2,438ä»¶ã®å®Ÿä¸–ç•Œã®Pythonã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ç’°å¢ƒã‚’æ§‹ç¯‰ã€‚è¨€èªãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ãSWEã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´ã—ã€SWE-Benchã§æœ€å¤§19%ã®è§£æ±ºç‡å‘ä¸Šã‚’é”æˆã€‚å¾®èª¿æ•´ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯æ–°ãŸãªæœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ç¤ºã—ã€SWE-Gymã‚„ãƒ¢ãƒ‡ãƒ«ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è»Œè·¡ã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>SWE-Benchã¨ã¯å®Œå…¨ã«ç‹¬ç«‹ã—ãŸã‚ˆã‚Šåºƒç¯„ãªæŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã«é–¢é€£ã™ã‚‹ã‚¿ã‚¹ã‚¯ã«åŸºã¥ãSWEãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1848" target="_blank" rel="noopener noreferrer">SWE-bench: Can Language Models Resolve Real-World GitHub Issues?, Carlos E. Jimenez+, ICLR'24</a>
 </p>
<p>SWE-Benchã¨æ¯”ã¹ã¦å®Ÿè¡Œå¯èƒ½ãªç’°å¢ƒã¨å˜ä½“ãƒ†ã‚¹ãƒˆãŒæä¾›ã•ã‚Œã¦ãŠã‚Šã€å˜ãªã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯ãªãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´ã§ãã‚‹ç’°å¢ƒãŒæä¾›ã•ã‚Œã¦ã„ã‚‹ç‚¹ãŒå¤§ããç•°ãªã‚‹ã‚ˆã†ã«æ„Ÿã˜ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/8c96df84-d211-4035-8337-1ab624d30a4f" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/d25687d9-6f1a-44f6-8235-09be1ff4890f" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1849" target="_blank" rel="noopener noreferrer" class="title-link">WebArena: A Realistic Web Environment for Building Autonomous Agents, Shuyan Zhou+, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- ç”ŸæˆAIã®é€²å±•ã«ã‚ˆã‚Šã€è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè‡ªç„¶è¨€èªã‚³ãƒãƒ³ãƒ‰ã§æ—¥å¸¸ã‚¿ã‚¹ã‚¯ã‚’ç®¡ç†ã™ã‚‹å¯èƒ½æ€§ãŒç”Ÿã¾ã‚ŒãŸãŒã€ç¾è¡Œã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ç°¡ç•¥åŒ–ã•ã‚ŒãŸç’°å¢ƒã§ã®ãƒ†ã‚¹ãƒˆã«é™ã‚‰ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ã‚¦ã‚§ãƒ–ä¸Šã§ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãŸã‚ã®ç¾å®Ÿçš„ãªç’°å¢ƒã‚’æ§‹ç¯‰ã—ã€eã‚³ãƒãƒ¼ã‚¹ã‚„ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ãªã©ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’å«ã‚€å®Œå…¨ãªã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‚’æä¾›ã™ã‚‹ã€‚ã“ã®ç’°å¢ƒã‚’åŸºã«ã€ã‚¿ã‚¹ã‚¯ã®æ­£ç¢ºæ€§ã‚’è©•ä¾¡ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å…¬é–‹ã—ã€å®Ÿé¨“ã‚’é€šã˜ã¦GPT-4ãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æˆåŠŸç‡ãŒ14.41%ã§ã‚ã‚Šã€äººé–“ã®78.24%ã«ã¯åŠã°ãªã„ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å®Ÿç”Ÿæ´»ã®ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã•ã‚‰ãªã‚‹é–‹ç™ºã®å¿…è¦æ€§ãŒå¼·èª¿ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Webã«ãŠã‘ã‚‹ã•ã¾ã–ã¾ãªrealisticãªã‚¿ã‚¹ã‚¯ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br><img src="https://github.com/user-attachments/assets/8895fc29-e997-4cce-a43e-65b928dc1d78" alt="image" loading="lazy"></p>
<p>å®Ÿéš›ã®exampleã€‚ã‚¹ã‚¿ãƒ¼ãƒˆåœ°ç‚¹ã‹ã‚‰ãƒ”ãƒƒãƒ„ãƒãƒ¼ã‚°ã®museumã‚’å·¡ã‚‹æœ€çŸ­ã®çµŒè·¯ã‚’è¦‹ã¤ã‘ã‚‹ã¨ã„ã£ãŸè¤‡é›‘ãªã‚¿ã‚¹ã‚¯ãŒå«ã¾ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/5b7bebea-34c7-4c6f-bbe5-3928544e6c13" alt="image" loading="lazy"><br><br>äººé–“ã¨GPT4,GPT-3.5ã®æ¯”è¼ƒçµæœ<br><img src="https://github.com/user-attachments/assets/390fee31-85d0-4d83-969a-57a7f1548ca8" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1848" target="_blank" rel="noopener noreferrer" class="title-link">SWE-bench: Can Language Models Resolve Real-World GitHub Issues?, Carlos E. Jimenez+, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- SWE-benchã¯ã€12ã®äººæ°—Pythonãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰å¾—ã‚‰ã‚ŒãŸ2,294ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å•é¡Œã‚’è©•ä¾¡ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’ç·¨é›†ã—ã¦å•é¡Œã‚’è§£æ±ºã™ã‚‹èƒ½åŠ›ã‚’æ¸¬å®šã—ã¾ã™ã€‚è©•ä¾¡ã®çµæœã€æœ€å…ˆç«¯ã®å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã‚„å¾®èª¿æ•´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«SWE-Llamaã‚‚æœ€ã‚‚å˜ç´”ãªå•é¡Œã—ã‹è§£æ±ºã§ããšã€Claude 2ã¯ã‚ãšã‹1.96%ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ã«ã¨ã©ã¾ã‚Šã¾ã—ãŸã€‚SWE-benchã¯ã€ã‚ˆã‚Šå®Ÿç”¨çš„ã§çŸ¥çš„ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã¸ã®é€²å±•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æœ€ã‚‚popularãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br><br>&lt;img width="693" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/ac905221-d3b1-4d16-b447-3bdd4d5e97bb"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/ac905221-d3b1-4d16-b447-3bdd4d5e97bb"&lt;/a&gt;


/&gt;<br><br>ä¸»ã«pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«é–¢ã™ã‚‹ãƒªãƒã‚¸ãƒˆãƒªã«åŸºã¥ã„ã¦æ§‹ç¯‰ã•ã‚Œã¦ã„ã‚‹ã€‚<br>&lt;img width="731" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/14d26dd1-6b4a-4337-a652-4e48e36d633b"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/14d26dd1-6b4a-4337-a652-4e48e36d633b"&lt;/a&gt;


/&gt;</p>
<p>SWE-Bench, SWE-Bench Lite, SWE-Bench Verifiedã®3ç¨®é¡ãŒã‚ã‚Šã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã¯SWE-Bench Verifiedã‚’åˆ©ç”¨ã—ã¦è©•ä¾¡ã™ã‚‹ã“ã¨ãŒå¤šã„ã‚‰ã—ã„ã€‚Verifiedã§ã¯ã€issueã®è¨˜è¿°ã«æ›–æ˜§æ€§ãŒãªãã€é©åˆ‡ãªunittestã®ã‚¹ã‚³ãƒ¼ãƒ—ãŒé©åˆ‡ãªã‚‚ã®ã®ã¿ãŒæ¡ç”¨ã•ã‚Œã¦ã„ã‚‹ã¨ã®ã“ã¨ï¼ˆi.e., äººé–“ã®å°‚é–€å®¶ã«ã‚ˆã£ã¦å•é¡ŒãŒãªã„ã¨åˆ¤æ–­ã•ã‚ŒãŸã‚‚ã®ï¼‰ã€‚<br>


<a href="https://www.swebench.com/" target="_blank" rel="noopener noreferrer">https://www.swebench.com/</a>


</p>
<p>Agenticãªè©•ä¾¡ã‚’ã™ã‚‹éš›ã«ã€ä¸€éƒ¨ã®è©•ä¾¡ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒgit logã‚’å‚ç…§ã—æœ¬æ¥ã¯å­˜åœ¨ã—ãªã„ã¯ãšã®ãƒªãƒã‚¸ãƒˆãƒªã®future stateã‚’è¦‹ã‚‹ã“ã¨ã§ç’°å¢ƒã‚’ãƒãƒƒã‚­ãƒ³ã‚°ã—ã¦ã„ãŸã¨ã®ã“ã¨:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/giffmana/status/1963327672827687316?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã“ã‚Œã¾ã§ã®è©•ä¾¡çµæœã«ã©ã®ç¨‹åº¦ã®å½±éŸ¿ãŒã‚ã‚‹ã‹ã¯ä¸æ˜ã€‚<p>openreview:


<a href="https://openreview.net/forum?id=VTF8yNQM66" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=VTF8yNQM66</a>


</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/UserModeling.html" target="_blank" rel="noopener noreferrer">#UserModeling</a>
<a class="button" href="articles/CTRPrediction.html" target="_blank" rel="noopener noreferrer">#CTRPrediction</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2025-03-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1840" target="_blank" rel="noopener noreferrer" class="title-link">ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential   Behavior Comprehension in Recommendation, Jianghao Lin+, WWW'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆãŠã‚ˆã³å°‘ã‚·ãƒ§ãƒƒãƒˆã®æ¨è–¦ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’å¼·åŒ–ã™ã‚‹æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒReLLaã€ã‚’ææ¡ˆã€‚LLMsãŒé•·ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡ºã§ããªã„å•é¡Œã«å¯¾å‡¦ã—ã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•æ¤œç´¢ï¼ˆSUBRï¼‰ã‚’ç”¨ã„ã¦ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å°‘ã‚·ãƒ§ãƒƒãƒˆè¨­å®šã§ã¯ã€æ¤œç´¢å¼·åŒ–æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆReiTï¼‰ã‚’è¨­è¨ˆã—ã€æ··åˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€å°‘ã‚·ãƒ§ãƒƒãƒˆReLLaãŒå¾“æ¥ã®CTRãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1839" target="_blank" rel="noopener noreferrer">RALLRec+: Retrieval Augmented Large Language Model Recommendation with
  Reasoning, Sichun Luo+, arXiv'25</a>
<br><br>ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³</p>
<p>LLMã§CTRäºˆæ¸¬ã™ã‚‹éš›ã®æ€§èƒ½ã‚’å‘ä¸Šã—ãŸç ”ç©¶ã€‚<br><br>ãã‚‚ãã‚‚LLMã§CTRäºˆæ¸¬ã‚’ã™ã‚‹éš›ã¯ã€ãƒ¦ãƒ¼ã‚¶ã®ãƒ‡ãƒ¢ã‚°ãƒ©æƒ…å ±ã¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ­ã‚°ãªã©ã®ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¢ã‚¤ãƒ†ãƒ ã®æƒ…å ±ã§promptingã—ã€yes/noã‚’å‡ºåŠ›ã•ã›ã‚‹ã€‚yes/noãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¹ã‚³ã‚¢ã«å¯¾ã—ã¦2æ¬¡å…ƒã®ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‚’é©ç”¨ã—ã¦[0, 1]ã®ã‚¹ã‚³ã‚¢ã‚’å¾—ã‚‹ã“ã¨ã§ã€CTRäºˆæ¸¬ã‚’ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/75025947-f3bb-49d0-a8f1-e05c429183a4" alt="image" loading="lazy"><br><br>ã“ã®ç ”ç©¶ã§ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ãƒ¦ãƒ¼ã‚¶ã®ãƒ­ã‚°ã‚’å…¥ã‚Œã¦ã‚‚æ€§èƒ½ãŒã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«<br><img src="https://github.com/user-attachments/assets/69c27a84-0456-4ddf-aded-515608e27065" alt="image" loading="lazy"><br><br>ç›´è¿‘ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ­ã‚°ã§ã¯ãªãã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¢ã‚¤ãƒ†ãƒ ã¨æ„å‘³çš„ã«é¡ä¼¼ã—ãŸã‚¢ã‚¤ãƒ†ãƒ ã«é–¢ã™ã‚‹ãƒ­ã‚°ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å…¥ã‚Œï¼ˆSUBRï¼‰ã€zero shotã®inferenceã«æ´»ç”¨ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/a5a2a300-ddca-42cc-97d7-251487ccfa3a" alt="image" loading="lazy"><br><br>few-shot recommendationï¼ˆå°‘é‡ã®ã‚¯ãƒªãƒƒã‚¯ã‚¹ãƒ«ãƒ¼ãƒ­ã‚°ã‚’ç”¨ã„ã¦LLMã‚’SFTã™ã‚‹ã“ã¨ã§CTRäºˆæ¸¬ã™ã‚‹æ‰‹æ³•ï¼‰ã«ãŠã„ã¦ã¯ã€ä¸Šè¿°ã®æ„å‘³çš„ã«é¡ä¼¼ã—ãŸã‚¢ã‚¤ãƒ†ãƒ ã‚’data augmentationã«åˆ©ç”¨ã—ï¼ˆi.e, promptã«åŸ‹ã‚è¾¼ã‚€ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ­ã‚°ã®é‡ã‚’å¢—ã‚„ã—ã¦ï¼‰å­¦ç¿’ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/b98af740-0628-4e98-a80f-30ff105621e1" alt="image" loading="lazy"><br><br>zeroshotã«ãŠã„ã¦ã€SUBRã§æ€§èƒ½æ”¹å–„ã€‚fewshot recommendationã«ã¨ã„ã¦ã€10%æœªæº€ã®ãƒ‡ãƒ¼ã‚¿ã§æ—¢å­˜ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã‚‹æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã€‚ã¾ãŸã€ä¸‹ã®ã‚°ãƒ©ãƒ•ã‚’è¦‹ã‚‹ã¨promptã«åˆ©ç”¨ã™ã‚‹ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ­ã‚°ã®é‡ãŒå¢—ãˆã‚‹ã»ã©æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚<br><img src="https://github.com/user-attachments/assets/1297153e-bd6c-4548-a7e0-798eadee80e9" alt="image" loading="lazy"><br><br>ãŸã ã—ã€latencyã¯100å€ä»¥ä¸Šãªã®ã§ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ãŒé™å®šã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/89555964-f5c4-4735-bc0d-9a5a1b7f0278" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-03-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1831" target="_blank" rel="noopener noreferrer" class="title-link">Transformers are SSMs: Generalized Models and Efficient Algorithms   Through Structured State Space Duality, Tri Dao+, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- Transformersã¨Mambaã®ã‚ˆã†ãªçŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ï¼ˆSSMsï¼‰ã®é–¢é€£æ€§ã‚’ç¤ºã—ã€SSMsã¨æ³¨æ„ã®å¤‰ç¨®ã¨ã®ç†è«–çš„æ¥ç¶šã‚’æ§‹ç¯‰ã€‚æ–°ãŸã«è¨­è¨ˆã—ãŸMamba-2ã¯ã€é€Ÿåº¦ã‚’2ã€œ8å€å‘ä¸Šã•ã›ãªãŒã‚‰ã€Transformersã¨ç«¶äº‰åŠ›ã‚’ç¶­æŒã€‚</span>
<span class="snippet"><span>Comment</span><p>Mamba2ã®è©³ç´°ã‚’çŸ¥ã‚ŠãŸã„å ´åˆã«èª­ã‚€</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Pruning.html" target="_blank" rel="noopener noreferrer">#Pruning</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-03-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1804" target="_blank" rel="noopener noreferrer" class="title-link">Compact Language Models via Pruning and Knowledge Distillation, Saurav Muralidharan+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€æ—¢å­˜ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€å°‘é‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã§å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚æ·±ã•ã€å¹…ã€æ³¨æ„ã€MLPãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’çŸ¥è­˜è’¸ç•™ã¨çµ„ã¿åˆã‚ã›ãŸåœ§ç¸®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’é–‹ç™ºã—ã€Nemotron-4ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®LLMã‚’2-4å€åœ§ç¸®ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«å¿…è¦ãªãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æœ€å¤§40å€å‰Šæ¸›ã—ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’1.8å€å‰Šæ¸›ã€‚Minitronãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚¼ãƒ­ã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸå ´åˆã¨æ¯”è¼ƒã—ã¦MMLUã‚¹ã‚³ã‚¢ãŒæœ€å¤§16%æ”¹å–„ã•ã‚Œã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã•ã‚Œã€è£œè¶³è³‡æ–™ã‚‚æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=9U0nLnNMJ7&referrer=%5Bthe%20profile%20of%20Pavlo%20Molchanov%5D(%2Fprofile%3Fid%3D~Pavlo_Molchanov1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=9U0nLnNMJ7&referrer=%5Bthe%20profile%20of%20Pavlo%20Molchanov%5D(%2Fprofile%3Fid%3D~Pavlo_Molchanov1)</a>


</p>
<p><img src="https://github.com/user-attachments/assets/76ab1107-bf94-4cf1-9ad1-e9f494b917e7" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/d1bf8a84-5365-4d35-aae0-146b1860ed9d" alt="image" loading="lazy"><br><br>ï¼ˆã‚ã¨ã§ãƒ¡ãƒ¢ã‚’è¿½è¨˜ï¼‰</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-03-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1802" target="_blank" rel="noopener noreferrer" class="title-link">Sparse Autoencoders Find Highly Interpretable Features in Language   Models, Hoagy Cunningham+, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- ç¥çµŒãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å¤šç¾©æ€§ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã«ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’ç”¨ã„ã¦å†…éƒ¨æ´»æ€§åŒ–ã®æ–¹å‘ã‚’ç‰¹å®šã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è§£é‡ˆå¯èƒ½ã§å˜ç¾©çš„ãªç‰¹å¾´ã‚’å­¦ç¿’ã—ã€é–“æ¥ç›®çš„èªã®åŒå®šã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹å› æœçš„ç‰¹å¾´ã‚’ã‚ˆã‚Šè©³ç´°ã«ç‰¹å®šã€‚ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§æ•™å¸«ãªã—ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒé‡ã­åˆã‚ã›ã®å•é¡Œã‚’è§£æ±ºã§ãã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã€ãƒ¢ãƒ‡ãƒ«ã®é€æ˜æ€§ã¨æ“ä½œæ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://note.com/ainest/n/nbe58b36bb2db" target="_blank" rel="noopener noreferrer">https://note.com/ainest/n/nbe58b36bb2db</a>


</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=F76bwRSLeK" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=F76bwRSLeK</a>


</p>
<p>SparseAutoEncoderã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚ã‚‰ã‚†ã‚‹ã¨ã“ã‚ã«ä»•è¾¼ã‚ã‚‹ï¼ˆã¨æ€ã‚ã‚Œã‚‹ï¼‰ãŒã€ãŸã¨ãˆã°Transformer Blockã®residual connectionéƒ¨åˆ†ã®ãƒ™ã‚¯ãƒˆãƒ«ã«å¯¾ã—ã¦Feature Dictionaryã‚’å­¦ç¿’ã™ã‚‹ã¨ã€å½“è©²ãƒ–ãƒ­ãƒƒã‚¯ã«ãŠã„ã¦ã©ã®ã‚ˆã†ãªç‰¹å¾´ã®çµ„ã¿åˆã‚ã›ãŒè¡¨ç¾ã•ã‚Œã¦ã„ã‚‹ã‹ãŒï¼ˆã‚ãã¾ã§SparseAutoEncoderãŒreconstruction lossã«ã‚ˆã£ã¦å­¦ç¿’ã•ã‚ŒãŸçµæœã‚’ç”¨ã„ã¦ï¼‰è§£é‡ˆã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/f86f5f7b-f46d-48ab-94e3-cf7f298eb9d7" alt="image" loading="lazy"><br><br>SparseAutoEncoderã¯ä¸‹è¨˜å¼ã§è¡¨ã•ã‚Œã€ä¸‹è¨˜loss functionã§å­¦ç¿’ã•ã‚Œã‚‹ã€‚MãŒFeature Matrixï¼ˆrow-wiseã«æ­£è¦åŒ–ã•ã‚Œã¦å¾Œè¿°ã®cã«å¯¾ã™ã‚‹L1æ­£å‰‡åŒ–ã«å½±éŸ¿ã‚’ä¸ãˆãªã„ã‚ˆã†ã«ã—ã¦ã„ã‚‹ï¼‰ã«ç›¸å½“ã™ã‚‹ã€‚cã«å¯¾ã—ã¦L1æ­£å‰‡åŒ–ã‚’ã‹ã‘ã‚‹ã“ã¨ã§ï¼ˆSparsity Lossï¼‰ã€cä¸­ã®å„è¦ç´ ãŒ0ã«è¿‘ã¥ãã‚ˆã†ã«ãªã‚Šã€çµæœã¨ã—ã¦cãŒSparseã¨ãªã‚‹ï¼ˆã©ã†ã—ã¦ã‚‚å€¤ã‚’æŒãŸãªã‘ã‚Œã°ã„ã‘ãªã„é‡è¦ãªç‰¹å¾´é‡ã®ã¿ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ï¼‰ã€‚<br><img src="https://github.com/user-attachments/assets/7e400f25-8a63-4222-904c-4a7b94d50880" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/dd8c10b3-3bb5-46fb-b94a-d91f3602bbd1" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<span class="issue_date">Issue Date: 2025-02-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1752" target="_blank" rel="noopener noreferrer" class="title-link">PromptWizard: Task-Aware Prompt Optimization Framework, Eshaan Agarwal+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- PromptWizardã¯ã€å®Œå…¨è‡ªå‹•åŒ–ã•ã‚ŒãŸé›¢æ•£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€è‡ªå·±é€²åŒ–çš„ã‹ã¤è‡ªå·±é©å¿œçš„ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’åˆ©ç”¨ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è³ªã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é§†å‹•ã®æ‰¹è©•ã‚’é€šã˜ã¦ã€ã‚¿ã‚¹ã‚¯ç‰¹æœ‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã€45ã®ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã€‚é™ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚„å°è¦æ¨¡ãªLLMã§ã‚‚åŠ¹æœã‚’ç™ºæ®ã—ã€ã‚³ã‚¹ãƒˆåˆ†æã«ã‚ˆã‚ŠåŠ¹ç‡æ€§ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®åˆ©ç‚¹ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Github:


<a href="https://github.com/microsoft/PromptWizard?tab=readme-ov-file" target="_blank" rel="noopener noreferrer">https://github.com/microsoft/PromptWizard?tab=readme-ov-file</a>


<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tom_doerr/status/1888178173684199785?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>åˆæœŸã«ææ¡ˆã•ã‚ŒãŸ<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1034" target="_blank" rel="noopener noreferrer">Large Language Models Are Human-Level Prompt Engineers, Yongchao Zhou+, ICLR'23</a>
<br><br>ã¨æ¯”è¼ƒã™ã‚‹ã¨å¤§åˆ†æ€§èƒ½ãŒä¸ŠãŒã£ã¦ãã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/5f7a329e-e83b-46da-9213-af8877201572" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/857b3526-4f56-4e31-8a69-a4193657b286" alt="image" loading="lazy"></p>
<p>reasoning modelã§ã¯fewshot promptingã‚’ã™ã‚‹ã¨æ€§èƒ½ãŒè½ã¡ã‚‹ã¨ã„ã†çŸ¥è¦‹ãŒã‚ã‚‹ã®ã§ã€reasoningãƒ¢ãƒ‡ãƒ«å‘ã‘ã®APEæ‰‹æ³•ã‚‚ãã®ã†ã¡å‡ºç¾ã™ã‚‹ã®ã ã‚ã†ï¼ˆæ—¢ã«ã‚ã‚Šãã†ï¼‰ã€‚</p>
<p>OpenReview: 


<a href="https://openreview.net/forum?id=VZC9aJoI6a" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=VZC9aJoI6a</a>


<br>ICLR'25ã«rejectã•ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-02-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1745" target="_blank" rel="noopener noreferrer" class="title-link">Tulu 3: Pushing Frontiers in Open Language Model Post-Training, Nathan Lambert+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Tulu 3ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã§ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ¬ã‚·ãƒ”ã‚’å…¬é–‹ã—ã€ç¾ä»£ã®ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æŠ€è¡“ã®ã‚¬ã‚¤ãƒ‰ã‚’æä¾›ã—ã¾ã™ã€‚Llama 3.1ã‚’åŸºã«ã—ã€ä»–ã®ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã€‚æ–°ã—ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã¨ã—ã¦SFTã€DPOã€RLVRã‚’æ¡ç”¨ã—ã€ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯è©•ä¾¡ã‚¹ã‚­ãƒ¼ãƒ ã‚’å°å…¥ã€‚ãƒ¢ãƒ‡ãƒ«ã‚¦ã‚§ã‚¤ãƒˆã‚„ãƒ‡ãƒ¢ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãªã©ã‚’å…¬é–‹ã—ã€ä»–ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã¸ã®é©å¿œã‚‚å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/icoxfog417/status/1885460713264775659?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<span class="issue_date">Issue Date: 2025-02-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1742" target="_blank" rel="noopener noreferrer" class="title-link">A Survey on Knowledge Distillation of Large Language Models, Xiaohan Xu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã‘ã‚‹çŸ¥è­˜è’¸ç•™ï¼ˆKDï¼‰ã®é‡è¦æ€§ã‚’èª¿æŸ»ã—ã€å°å‹ãƒ¢ãƒ‡ãƒ«ã¸ã®çŸ¥è­˜ä¼é”ã‚„ãƒ¢ãƒ‡ãƒ«åœ§ç¸®ã€è‡ªå·±æ”¹å–„ã®å½¹å‰²ã‚’å¼·èª¿ã€‚KDãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚„èªçŸ¥èƒ½åŠ›ã®å‘ä¸Šã€ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆDAï¼‰ã¨ã®ç›¸äº’ä½œç”¨ã‚’æ¤œè¨ã—ã€DAãŒLLMæ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€‚ç ”ç©¶è€…ã‚„å®Ÿå‹™è€…ã«å‘ã‘ãŸã‚¬ã‚¤ãƒ‰ã‚’æä¾›ã—ã€LLMã®KDã®å€«ç†çš„é©ç”¨ã‚’æ¨å¥¨ã€‚é–¢é€£æƒ…å ±ã¯Githubã§å…¥æ‰‹å¯èƒ½ã€‚</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-01-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1731" target="_blank" rel="noopener noreferrer" class="title-link">Don't Do RAG: When Cache-Augmented Generation is All You Need for  Knowledge Tasks, Brian J Chan+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ‹¡å¼µç”Ÿæˆï¼ˆCAGï¼‰ã¯ã€RAGã®èª²é¡Œã‚’å…‹æœã™ã‚‹ãŸã‚ã«ææ¡ˆã•ã‚ŒãŸæ‰‹æ³•ã§ã€LLMã®æ‹¡å¼µã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«äº‹å‰ã«é–¢é€£ãƒªã‚½ãƒ¼ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€æ¤œç´¢ãªã—ã§ã‚¯ã‚¨ãƒªã«å¿œç­”ã™ã‚‹ã€‚CAGã¯æ¤œç´¢ã®é…å»¶ã‚’æ’é™¤ã—ã€ã‚¨ãƒ©ãƒ¼ã‚’æœ€å°é™ã«æŠ‘ãˆã¤ã¤ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®é–¢é€£æ€§ã‚’ç¶­æŒã€‚æ€§èƒ½è©•ä¾¡ã§ã¯ã€CAGãŒå¾“æ¥ã®RAGã‚’ä¸Šå›ã‚‹ã‹è£œå®Œã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€ç‰¹ã«åˆ¶ç´„ã®ã‚ã‚‹çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«ãŠã„ã¦åŠ¹ç‡çš„ãªä»£æ›¿æ‰‹æ®µã¨ãªã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1876721221083214200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¤–éƒ¨çŸ¥è­˜ã¨ã—ã¦åˆ©ç”¨ã—ãŸã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒãã“ã¾ã§å¤§ããç„¡ã„ãªã‚‰ã€äº‹å‰ã«LLMã§å…¨ã¦ã®Key Valueã‚’è¨ˆç®—ã—ã¦ãŠãKV Cacheã¨ã—ã¦åˆ©ç”¨å¯èƒ½ã«ã—ã¦ãŠã‘ã°ã€ç”Ÿæˆæ™‚ã«æ¤œç´¢ã‚’ã™ã‚‹ã“ã¨ã‚‚ãªãã€contextã¨ã—ã¦åˆ©ç”¨ã—ã¦ç”Ÿæˆã§ãã‚‹ã˜ã‚ƒã‚“ã€ã¨ã„ã†ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1729" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Chain of Agents: Large language models collaborating on long-context tasks, Google Research, 2025.01, NeurIPS'24</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/googleai/status/1882554959272849696?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLMãŒã©ã“ã¾ã§ã„ã£ã¦ã‚‚contexté•·ã®åˆ¶ç´„ã«ç›´é¢ã™ã‚‹å•é¡Œã«å¯¾ã—ã¦LLM Agentã‚’çµ„ã¿åˆã‚ã›ã¦å¯¾å‡¦ã—ã¾ã—ãŸã€çš„ãªè©±ãªæ¨¡æ§˜</p>
<p>ãƒ–ãƒ­ã‚°ä¸­ã«ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’è§£èª¬ã—ãŸå‹•ç”»ãŒã‚ã‚‹ã®ã§ã‚ã‹ã‚Šã‚„ã™ã„</p>
<p>Is the experimental code open source?</p>
<p>Thank you for your comment. I tried to find an official open-source implementation provided by the authors, but I was not able to locate one. In fact, I also checked the personal webpage of the first author, but there was no link to any released code.<br><br>Is seems that an unofficial implementation is listed under the â€œCodeâ€ tab on the NeurIPS page. I hope this is helpful. Thank you.<br><br>NeurIPS link: 


<a href="https://nips.cc/virtual/2024/poster/95563" target="_blank" rel="noopener noreferrer">https://nips.cc/virtual/2024/poster/95563</a>


<br>openreview: 


<a href="https://openreview.net/forum?id=LuCLf4BJsr" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=LuCLf4BJsr</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1724" target="_blank" rel="noopener noreferrer" class="title-link">Spectrum: Targeted Training on Signal to Noise Ratio, Eric Hartford+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ã€ŒSpectrumã€ã¨ã„ã†æ‰‹æ³•ã‚’ææ¡ˆã—ã€SNRã«åŸºã¥ã„ã¦ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’é¸æŠçš„ã«ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã™ã‚‹ã“ã¨ã§ã€LLMã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’åŠ é€Ÿã€‚ã“ã‚Œã«ã‚ˆã‚ŠGPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›ã—ã¤ã¤ã€ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’å®Ÿç¾ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æ—¢å­˜æ‰‹æ³•QLoRAã¨æ¯”è¼ƒã—ã¦ãƒ¢ãƒ‡ãƒ«ã®å“è³ªã¨VRAMåŠ¹ç‡ã®å‘ä¸ŠãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1723" target="_blank" rel="noopener noreferrer">How to fine-tune open LLMs in 2025 with Hugging Face, PHILSCHMID, 2024.12</a>
<br><br>ã«ã‚ˆã‚‹ã¨LLMã®ã†ã¡æœ€ã‚‚informativeãªLayerã‚’è¦‹ã¤ã‘ã€é¸æŠçš„ã«å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€çœãƒªã‚½ãƒ¼ã‚¹ã§ã€Full-Parameter tuningã¨åŒç­‰ã®æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹æ‰‹æ³•ã‚‰ã—ã„<br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1710" target="_blank" rel="noopener noreferrer" class="title-link">Forgetting before Learning: Utilizing Parametric Arithmetic for   Knowledge Updating in Large Language Models, Shiwen Ni+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- F-Learningã¨ã„ã†æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã—ã€å¤ã„çŸ¥è­˜ã‚’å¿˜å´ã—æ–°ã—ã„çŸ¥è­˜ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã«ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ç®—è¡“ã‚’åˆ©ç”¨ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€F-LearningãŒãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®çŸ¥è­˜æ›´æ–°æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã€æ—¢å­˜ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚LoRAã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¼•ãç®—ã™ã‚‹ã“ã¨ã§å¤ã„çŸ¥è­˜ã‚’å¿˜å´ã™ã‚‹åŠ¹æœã‚‚ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>Finetuningã«ã‚ˆã£ã¦çŸ¥è­˜ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ãŸã„çŠ¶æ³ã«ãŠã„ã¦ã€ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆå‰ã®è©²å½“çŸ¥è­˜ã‚’å¿˜å´ã—ã¦ã‹ã‚‰ã€æ–°ã—ã„çŸ¥è­˜ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚ŠåŠ¹æœçš„ã«çŸ¥è­˜ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆãŒå¯èƒ½ãªã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br>å¤ã„çŸ¥è­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’K_oldã€å¤ã„çŸ¥è­˜ã‹ã‚‰æ›´æ–°ã•ã‚ŒãŸæ–°ã—ã„çŸ¥è­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’K_newã¨ã—ãŸã¨ãã«ã€K_oldã§ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’{Full-finetuning, LoRA}ã™ã‚‹ã“ã¨ã§å¾—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Î¸_oldã‚’ã€ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Î¸ã‹ã‚‰ï¼ˆå¤ã„çŸ¥è­˜ã‚’å¿˜å´ã™ã‚‹ã“ã¨ã‚’æœŸå¾…ã—ã¦ï¼‰æ¸›ç®—ã—ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Î¸'ã‚’æŒã¤æ–°ãŸãªãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’å¾—ã‚‹ã€‚ãã®å¾Œã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Î¸'ã‚’æŒã¤ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’k_newã§Full-Finetuningã™ã‚‹ã“ã¨ã§ã€æ–°ãŸãªçŸ¥è­˜ã‚’å­¦ç¿’ã•ã›ã‚‹ã€‚ãŸã ã—ã€ã“ã®ã‚ˆã†ãªæ“ä½œã¯ã€K_oldãŒãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’æ¸ˆã¿ã§ã‚ã‚‹å‰æã§ã‚ã‚‹ã“ã¨ã«æ³¨æ„ã™ã‚‹ã€‚å­¦ç¿’æ¸ˆã¿ã§ãªã„å ´åˆã¯ãã‚‚ãã‚‚äº‹å‰ã®å¿˜å´ã®å¿…è¦ãŒãªã„ã—ã€æ¸›ç®—ã«ã‚ˆã£ã¦ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ã‚³ã‚¢ã¨ãªã‚‹èƒ½åŠ›ãŒç ´å£Šã•ã‚Œã‚‹å±é™ºãŒã‚ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/22c126e3-425d-4392-80ee-df319d217fd4" alt="image" loading="lazy"><br><br>çµæœã¯ä¸‹è¨˜ã§ã€å…ˆè¡Œç ”ç©¶ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚æ³¨æ„ç‚¹ã¨ã—ã¦ã€ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å¿˜å´ã‚’ã•ã›ã‚‹éš›ã«ã€Full Finetuningã«ã‚ˆã£ã¦Î¸_oldã‚’å–å¾—ã™ã‚‹ã¨ã€ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ã‚³ã‚¢ã¨ãªã‚‹èƒ½åŠ›ãŒç ´å£Šã•ã‚Œã‚‹ã‚±ãƒ¼ã‚¹ãŒã‚ã‚‹ã‚ˆã†ã§ã‚ã‚‹ã€‚ä¸€æ–¹ã€LoRAã®å ´åˆã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹å½±éŸ¿ãŒå°ã•ã„ãŸã‚ã€ã“ã®ã‚ˆã†ãªç ´å£Šçš„ãªæ“ä½œã¨ãªã‚Šã¥ã‚‰ã„ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/dfa12efc-c511-42bf-a1ab-0ef4a7749852" alt="image" loading="lazy"></p>
<p>è©•ä¾¡ã§åˆ©ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2556" target="_blank" rel="noopener noreferrer">[Paper Note] Zero-Shot Relation Extraction via Reading Comprehension, Omer Levy+, CoNLL'17</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2557" target="_blank" rel="noopener noreferrer">[Paper Note] Locating and Editing Factual Associations in GPT, Kevin Meng+, NeurIPS'22</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1705" target="_blank" rel="noopener noreferrer" class="title-link">Learning to Edit: Aligning LLMs with Knowledge Editing, Yuxin Jiang+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- ã€ŒLearning to Editï¼ˆLTEï¼‰ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€LLMsã«æ–°ã—ã„çŸ¥è­˜ã‚’åŠ¹æœçš„ã«é©ç”¨ã™ã‚‹æ–¹æ³•ã‚’æ•™ãˆã‚‹ã€‚äºŒæ®µéšãƒ—ãƒ­ã‚»ã‚¹ã§ã€ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãƒ•ã‚§ãƒ¼ã‚ºã§ä¿¡é ¼ã§ãã‚‹ç·¨é›†ã‚’è¡Œã„ã€æ¨è«–ãƒ•ã‚§ãƒ¼ã‚ºã§ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä½¿ç”¨ã€‚å››ã¤ã®çŸ¥è­˜ç·¨é›†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§LTEã®å„ªä½æ€§ã¨å …ç‰¢æ€§ã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1699" target="_blank" rel="noopener noreferrer" class="title-link">OlympiadBench: A Challenging Benchmark for Promoting AGI with   Olympiad-Level Bilingual Multimodal Scientific Problems, Chaoqun He+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ï¼ˆLMMsï¼‰ã®èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã«ã€ã‚ªãƒªãƒ³ãƒ”ã‚¢ãƒ‰ãƒ¬ãƒ™ãƒ«ã®ãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç§‘å­¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒOlympiadBenchã€ã‚’ææ¡ˆã€‚8,476ã®æ•°å­¦ã¨ç‰©ç†ã®å•é¡Œã‚’å«ã¿ã€å°‚é–€å®¶ãƒ¬ãƒ™ãƒ«ã®æ³¨é‡ˆãŒä»˜ã‘ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ãƒˆãƒƒãƒ—ãƒ¢ãƒ‡ãƒ«ã®GPT-4Vã¯å¹³å‡17.97%ã®ã‚¹ã‚³ã‚¢ã‚’é”æˆã—ãŸãŒã€ç‰©ç†ã§ã¯10.74%ã«ã¨ã©ã¾ã‚Šã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å³ã—ã•ã‚’ç¤ºã™ã€‚ä¸€èˆ¬çš„ãªå•é¡Œã¨ã—ã¦å¹»è¦šã‚„è«–ç†çš„èª¤è¬¬ãŒæŒ‡æ‘˜ã•ã‚Œã€ä»Šå¾Œã®AGIç ”ç©¶ã«è²´é‡ãªãƒªã‚½ãƒ¼ã‚¹ã¨ãªã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Bias.html" target="_blank" rel="noopener noreferrer">#Bias</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1670" target="_blank" rel="noopener noreferrer" class="title-link">ConSiDERS-The-Human Evaluation Framework: Rethinking Human Evaluation  for Generative Large Language Models, Aparna Elangovan+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ãƒã‚¸ã‚·ãƒ§ãƒ³ãƒšãƒ¼ãƒ‘ãƒ¼ã§ã¯ã€ç”Ÿæˆçš„ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®äººé–“è©•ä¾¡ã¯å¤šåˆ†é‡ã«ã‚ãŸã‚‹å–ã‚Šçµ„ã¿ã§ã‚ã‚‹ã¹ãã¨ä¸»å¼µã—ã€å®Ÿé¨“ãƒ‡ã‚¶ã‚¤ãƒ³ã®ä¿¡é ¼æ€§ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ã‚„å¿ƒç†å­¦ã®æ´å¯Ÿã‚’æ´»ç”¨ã™ã‚‹å¿…è¦æ€§ã‚’å¼·èª¿ã—ã¾ã™ã€‚è©•ä¾¡ã«ã¯ä½¿ã„ã‚„ã™ã•ã‚„èªçŸ¥ãƒã‚¤ã‚¢ã‚¹ã‚’è€ƒæ…®ã—ã€å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã¨å¼±ç‚¹ã‚’åŒºåˆ¥ã™ã‚‹ãŸã‚ã®åŠ¹æœçš„ãªãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆãŒæ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚ã•ã‚‰ã«ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚‚é‡è¦ã§ã‚ã‚Šã€6ã¤ã®æŸ±ã‹ã‚‰æˆã‚‹ConSiDERS-The-Humanè©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æŸ±ã¯ã€ä¸€è²«æ€§ã€è©•ä¾¡åŸºæº–ã€å·®åˆ¥åŒ–ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ã€è²¬ä»»ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã§ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1667" target="_blank" rel="noopener noreferrer" class="title-link">Engaging an LLM to Explain Worked Examples for Java Programming: Prompt Engineering and a Feasibility Study, Hassany+, EDM'24 Workshop, 2024.07</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚¯ãƒ©ã‚¹ã§ã®ã‚³ãƒ¼ãƒ‰ä¾‹ã®èª¬æ˜ã‚’åŠ¹ç‡åŒ–ã™ã‚‹ãŸã‚ã«ã€LLMã‚’ç”¨ã„ãŸäººé–“ã¨AIã®å…±åŒåŸ·ç­†ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚è¬›å¸«ãŒç·¨é›†å¯èƒ½ãªåˆæœŸã‚³ãƒ¼ãƒ‰èª¬æ˜ã‚’ç”Ÿæˆã—ã€å­¦ç”Ÿã«ã¨ã£ã¦æ„å‘³ã®ã‚ã‚‹å†…å®¹ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’è¡Œã„ã€ãã®åŠ¹æœã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ç ”ç©¶ã§è©•ä¾¡ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/peterpaws/status/1876047837441806604?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1665" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models, Damai+, ACL'24, 2024.08</a>
<span class="snippet"><span>GPT Summary</span>- DeepSeekMoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€å°‚é–€å®¶ã®å°‚é–€æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã€å°‚é–€å®¶ã‚’ç´°åˆ†åŒ–ã—æŸ”è»Ÿãªçµ„ã¿åˆã‚ã›ã‚’å¯èƒ½ã«ã—ã€å…±æœ‰å°‚é–€å®¶ã‚’è¨­ã‘ã¦å†—é•·æ€§ã‚’è»½æ¸›ã™ã‚‹ã€‚2Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®DeepSeekMoEã¯ã€GShardã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã—ã€åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å¯†ãªãƒ¢ãƒ‡ãƒ«ã«è¿‘ã¥ãã€‚16Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã—ãŸéš›ã‚‚ã€è¨ˆç®—é‡ã‚’ç´„40%ã«æŠ‘ãˆã¤ã¤ã€LLaMA2ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-01-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1655" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open  Language Models, Zhihong Shao+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- DeepSeekMath 7Bã¯ã€120Bã®æ•°å­¦é–¢é€£ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”¨ã„ã¦äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€ç«¶æŠ€ãƒ¬ãƒ™ãƒ«ã®MATHãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§51.7%ã®ã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚è‡ªå·±ä¸€è²«æ€§ã¯60.9%ã§ã€ãƒ‡ãƒ¼ã‚¿é¸æŠãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨Group Relative Policy Optimization (GRPO)ã®å°å…¥ã«ã‚ˆã‚Šæ•°å­¦çš„æ¨è«–èƒ½åŠ›ãŒå‘ä¸Šã€‚Gemini-Ultraã‚„GPT-4ã«è¿«ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_the-rlhf-method-behind-the-best-open-models-activity-7280850174522843137-3V9v?utm_source=share&utm_medium=member_ios" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_the-rlhf-method-behind-the-best-open-models-activity-7280850174522843137-3V9v?utm_source=share&utm_medium=member_ios</a>


</p>
<p>å…ƒã€…æ•°å­¦ã®reasoningã«é–¢ã™ã‚‹èƒ½åŠ›ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ææ¡ˆã•ã‚ŒãŸãŒã€ç¾åœ¨ã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§Truthfulness, Helpfulness, Concisenessãªã©ã®æ”¹å–„ã«æ´»ç”¨ã•ã‚Œã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚</p>
<p>PPOã¨GRPOã®æ¯”è¼ƒã€‚value function modelï¼ˆçŠ¶æ…‹ã®ä¾¡å€¤ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼‰ãŒä¸è¦ãªãŸã‚çœãƒ¡ãƒ¢ãƒªã€ã‹ã¤åˆ©ç”¨ã™ã‚‹è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ãŒå°ã•ã„ã‚‰ã—ã„ã€‚<br>ã‚ã¨ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«åˆ†ã‘ã¦ã€ã‚°ãƒ«ãƒ¼ãƒ—å†…ã§ã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ãŒæœ€å°åŒ–ã•ã‚Œã‚‹ã‚ˆã†ï¼ˆã¤ã¾ã‚Šã€å„ã‚°ãƒ«ãƒ¼ãƒ—å†…ã§æ–¹ç­–ãŒé¡ä¼¼ã™ã‚‹ï¼‰Policy ModelãŒæ›´æ–°ã•ã‚Œã‚‹ï¼ˆã¤ã¾ã‚Šloss functionã«ç›´æ¥çµ„ã¿è¾¼ã¾ã‚Œã‚‹ï¼‰ç‚¹ãŒé•ã†ã‚‰ã—ã„ã€‚<br><br>PPOã§ã¯ç”Ÿæˆã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ã«reference modelã¨Policy Modelã¨ã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚’ã¨ã‚Šã€reference modelã¨ã®å·®ãŒå¤§ãããªã‚‰ãªã„ã‚ˆã†ã€å ±é…¬ã«ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’å…¥ã‚Œã‚‹ãŸã‚ã«ä½¿ã‚ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã‚‰ã—ã„ã€‚<br><img src="https://github.com/user-attachments/assets/e145ad52-e6c9-4481-b2ee-10a3987ea2e3" alt="image" loading="lazy"></p>
<p>ä¸‹è¨˜è¨˜äº‹ã«ã‚ˆã‚‹ã¨ã€PPOã§æœ€å¤§åŒ–ã—ãŸã„ã®ã¯Advantageï¼ˆç´¯ç©å ±é…¬ã¨çŠ¶æ…‹ä¾¡å€¤ï¼ˆç´¯ç©å ±é…¬ã®æœŸå¾…å€¤ã‚’è¨ˆç®—ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼‰ã®å·®åˆ†;æœŸå¾…å€¤ã‚ˆã‚Šã‚‚å®Ÿéš›ã®ç´¯ç©å ±é…¬ãŒè‰¯ã‹ã£ãŸã‚‰è‰¯ã„æ„Ÿã˜ã ãœçš„ãªæ•°å€¤ï¼‰ã§ã‚ã‚Šã€ãã‚Œã«ã¯çŠ¶æ…‹ä¾¡å€¤ã‚’è¨ˆç®—ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ã§ã‚ã‚‹ã€‚ãã—ã¦ã€PPOã«ãŠã‘ã‚‹çŠ¶æ…‹ä¾¡å€¤ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã‚ãªã„ã§ã€LLMã«ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã•ã›ã¦æœ€çµ‚çš„ãªå ±é…¬ã‚’å¹³å‡ã™ã‚Œã°çŠ¶æ…‹ä¾¡å€¤ãƒ¢ãƒ‡ãƒ«ç„¡ã—ã§AdvantageãŒè¨ˆç®—ã§ãã‚‹ã—å¬‰ã—ãã­ï¼Ÿã¨ã„ã†æ°—æŒã¡ã§ææ¡ˆã•ã‚ŒãŸã®ãŒã€æœ¬è«–æ–‡ã§ææ¡ˆã•ã‚Œã¦ã„ã‚‹GRPOã¨ã®ã“ã¨ã€‚å‹‰å¼·ã«ãªã‚‹ã€‚<br><br>DeepSeek-R1ã®è«–æ–‡èª­ã‚“ã ï¼Ÿã€å‹‰å¼·ã«ãªã‚‹ã‚ˆã€‘<br>, asap: 


<a href="https://zenn.dev/asap/articles/34237ad87f8511" target="_blank" rel="noopener noreferrer">https://zenn.dev/asap/articles/34237ad87f8511</a>


</p></span><br><br>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<a class="button" href="articles/Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1646" target="_blank" rel="noopener noreferrer" class="title-link">Precise Length Control in Large Language Models, Bradley Butcher+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMã®å¿œç­”ã®é•·ã•ã‚’æ­£ç¢ºã«åˆ¶å¾¡ã™ã‚‹ãŸã‚ã«ã€äºŒæ¬¡çš„ãªé•·ã•å·®ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆLDPEï¼‰ã‚’ç”¨ã„ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚LDPEã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã¯å¹³å‡3ãƒˆãƒ¼ã‚¯ãƒ³æœªæº€ã®èª¤å·®ã§æœ›ã¾ã—ã„é•·ã•ã§å¿œç­”ã‚’çµ‚äº†ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚ã¾ãŸã€æŸ”è»Ÿãªä¸Šé™é•·ã•åˆ¶å¾¡ã‚’å¯èƒ½ã«ã™ã‚‹Max New Tokens++ã‚‚å°å…¥ã€‚å®Ÿé¨“çµæœã¯ã€è³ªå•å¿œç­”ã‚„æ–‡æ›¸è¦ç´„ã«ãŠã„ã¦å¿œç­”ã®è³ªã‚’ç¶­æŒã—ã¤ã¤æ­£ç¢ºãªé•·ã•åˆ¶å¾¡ãŒå®Ÿç¾ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1870821203780256178?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1647" target="_blank" rel="noopener noreferrer">Controlling Output Length in Neural Encoder-Decoders, Yuta Kikuchi+, EMNLP'16</a>
<br><br>ãªã©ã®Encoder-Decoderãƒ¢ãƒ‡ãƒ«ã§è¡Œã‚ã‚Œã¦ã„ãŸoutput lengthã®åˆ¶å¾¡ã‚’Decoder-onlyãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã‚„ã‚Šã¾ã—ãŸã€ã¨ã„ã†è©±ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1645" target="_blank" rel="noopener noreferrer" class="title-link">TheAgentCompany: Benchmarking LLM Agents on Consequential Real World  Tasks, Frank F. Xu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ—¥å¸¸ç”Ÿæ´»ã‚„ä»•äº‹ã«ãŠã‘ã‚‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŠ¹æœã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã€TheAgentCompanyã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã€‚AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€ã‚¦ã‚§ãƒ–ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ã‚„ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œãªã©ã®ã‚¿ã‚¹ã‚¯ã‚’è‡ªå¾‹çš„ã«è¡Œã†èƒ½åŠ›ã‚’è©•ä¾¡ã€‚ãƒ†ã‚¹ãƒˆã®çµæœã€æœ€ã‚‚ç«¶äº‰åŠ›ã®ã‚ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã‚¿ã‚¹ã‚¯ã®24%ã‚’è‡ªå¾‹çš„ã«å®Œäº†ã§ãã‚‹ã“ã¨ãŒåˆ¤æ˜ã€‚ç°¡å˜ãªã‚¿ã‚¹ã‚¯ã¯è‡ªå‹•åŒ–å¯èƒ½ã ãŒã€é›£ã—ã„é•·æœŸçš„ãªã‚¿ã‚¹ã‚¯ã¯ç¾è¡Œã‚·ã‚¹ãƒ†ãƒ ã§ã¯å¯¾å¿œã§ããªã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1870821189809217921?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ä¼æ¥­ã®è¨­å®šã§ç¾å®Ÿã«èµ·ã“ã‚Šã†ã‚‹ãªã€€175ç¨®é¡ã®ã‚¿ã‚¹ã‚¯ã‚’å®šç¾©ã—ã¦AI Agentã‚’è©•ä¾¡ã§ãã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯TheAgentCompanyã‚’ææ¡ˆã€‚<br><br><img src="https://github.com/user-attachments/assets/ef7b51d3-b4af-4171-a692-48fb2c2552ef" alt="image" loading="lazy"><br><br>æ—¢å­˜ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚ˆã‚Šã€å¤šæ§˜ã§ã€å®Ÿéš›ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ä¼æ¥­ã§ã§èµ·ã“ã‚Šã†ã‚‹å¹…åºƒã„ã‚¿ã‚¹ã‚¯ã‚’æŒã¡ã€ã‚¿ã‚¹ã‚¯ã®é‚è¡Œã®ãŸã‚ã«åŒåƒšã«å¯¾ã—ã¦ä½•ã‚‰ã‹ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãŒå¿…è¦ã§ã€é”æˆã®ãŸã‚ã«å¤šãã®ã‚¹ãƒ†ãƒƒãƒ—ãŒå¿…è¦ã§ã‹ã¤å€‹ã€…ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆã‚µãƒ–ã‚¿ã‚¹ã‚¯ï¼‰ã‚’è©•ä¾¡å¯èƒ½ã§ã€å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã‚’é‚è¡Œã™ã‚‹ãŸã‚ã«å¿…è¦ãªæ§˜ã€…ãªã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ã‚«ãƒãƒ¼ã—ã€self hostingã—ã¦çµæœã‚’å®Œå…¨ã«å†ç¾å¯èƒ½ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ãªã£ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/e5fbd6da-75d7-49e1-8c66-dc7950d443e4" alt="image" loading="lazy"><br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1869735196700062089?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>ï¼ˆç”»åƒã¯è‘—è€…ãƒ„ã‚¤ãƒ¼ãƒˆã‚ˆã‚Šå¼•ç”¨ï¼‰<p>ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãªãƒ¢ãƒ‡ãƒ«ã¨OpenWeightãªãƒ¢ãƒ‡ãƒ«ã§AI Agentã¨ã—ã¦ã®èƒ½åŠ›ã‚’è©•ä¾¡ã—ãŸçµæœã€Claude-3.5-sonnetã¯ç´„24%ã®ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºå¯èƒ½ã§ã‚ã‚Šã€ä»–ãƒ¢ãƒ‡ãƒ«ã¨æ¯”ã¹ã¦æ€§èƒ½ãŒæ˜ã‚‰ã‹ã«è‰¯ã‹ã£ãŸã€‚ã¾ãŸã€Gemini-2.0-flashãªã‚³ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å„ªã‚Œã¦ã„ã‚‹ã€‚OpenWeightãªãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§ã¯Llama3.3-70Bã®ã‚³ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒè‰¯ã‹ã£ãŸã€‚ã‚¿ã‚¹ã‚¯ã¨ã—ã¦ã¯å…·ä½“çš„ã«è©•ä¾¡å¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®ã¿ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€Open Endãªã‚¿ã‚¹ã‚¯ã§ã¯è©•ä¾¡ã—ã¦ã„ãªã„ç‚¹ã«æ³¨æ„ã¨ã®ã“ã¨ã€‚<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1869735209404682706?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1869735213976432764?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><img src="https://github.com/user-attachments/assets/3bdcabef-70da-4f09-8366-efe29f7ab371" alt="image" loading="lazy"><p>ã¾ã ã¾ã AI AgentãŒå®Œå…¨ã«'åŒåƒš'ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã“ã¨ã¨ã¯ç¾æ™‚ç‚¹ã§ã¯ãªã•ãã†ã ãŒã€ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚¹ã‚³ã‚¢ãŒä»Šå¾Œã©ã“ã¾ã§ä¸ŠãŒã£ã¦ã„ãã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1644" target="_blank" rel="noopener noreferrer" class="title-link">A Survey of Mathematical Reasoning in the Era of Multimodal Large  Language Model: Benchmark, Method &amp; Challenges, Yibo Yan+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ•°å­¦çš„æ¨è«–ã¯å¤šãã®åˆ†é‡ã§é‡è¦ã§ã‚ã‚Šã€AGIã®é€²å±•ã«ä¼´ã„ã€LLMsã‚’æ•°å­¦çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã«çµ±åˆã™ã‚‹ã“ã¨ãŒæ±‚ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚æœ¬èª¿æŸ»ã¯ã€2021å¹´ä»¥é™ã®200ä»¥ä¸Šã®ç ”ç©¶ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è¨­å®šã«ãŠã‘ã‚‹Math-LLMsã®é€²å±•ã‚’åˆ†æã€‚åˆ†é‡ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€æ–¹æ³•è«–ã€èª²é¡Œã«åˆ†é¡ã—ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ•°å­¦çš„æ¨è«–ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚„LLMsã®å½¹å‰²ã‚’æ¢ã‚‹ã€‚ã•ã‚‰ã«ã€AGIå®Ÿç¾ã®éšœå®³ã¨ãªã‚‹5ã¤ã®èª²é¡Œã‚’ç‰¹å®šã—ã€ä»Šå¾Œã®ç ”ç©¶æ–¹å‘æ€§ã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/KnowledgeGraph.html" target="_blank" rel="noopener noreferrer">#KnowledgeGraph</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1643" target="_blank" rel="noopener noreferrer" class="title-link">Can LLMs Convert Graphs to Text-Attributed Graphs?, Zehong Wang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Topology-Aware Node description Synthesisï¼ˆTANSï¼‰ã‚’ææ¡ˆã—ã€GNNãŒç•°ãªã‚‹ç‰¹å¾´ç©ºé–“ã‚’æŒã¤ã‚°ãƒ©ãƒ•ã«é©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚TANSã¯LLMsã‚’ç”¨ã„ã¦æ—¢å­˜ã®ã‚°ãƒ©ãƒ•ã‚’ãƒ†ã‚­ã‚¹ãƒˆå±æ€§ã‚°ãƒ©ãƒ•ã«å¤‰æ›ã—ã€ãƒãƒ¼ãƒ‰ã®ç‰¹æ€§ã«ãƒˆãƒãƒ­ã‚¸ãƒ¼æƒ…å ±ã‚’çµ±åˆã€‚ãƒ†ã‚­ã‚¹ãƒˆãŒãªã„ã‚°ãƒ©ãƒ•ã§ã‚‚æ‰‹å‹•è¨­è¨ˆã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€LLMsã®å¯èƒ½æ€§ã‚’å®Ÿè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1868691391129272461?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1641" target="_blank" rel="noopener noreferrer" class="title-link">How Much Data is Enough Data? Fine-Tuning Large Language Models for  In-House Translation: Performance Evaluation Across Multiple Dataset Sizes, Inacio Vieira+, AMTA'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ç¿»è¨³ãƒ¡ãƒ¢ãƒªï¼ˆTMsï¼‰ã‚’æ´»ç”¨ã—ã€ç‰¹å®šã®çµ„ç¹”å‘ã‘ã®ç¿»è¨³ç²¾åº¦ã¨åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ç ”ç©¶ã€‚5ã¤ã®ç¿»è¨³æ–¹å‘ã§ç•°ãªã‚‹ã‚µã‚¤ã‚ºã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦å®Ÿé¨“ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒå¢—ãˆã‚‹ã»ã©ç¿»è¨³ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚ç‰¹ã«ã€1kãŠã‚ˆã³2kã®ä¾‹ã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºãŒå¢—åŠ ã™ã‚‹ã«ã¤ã‚Œã¦æ”¹å–„ãŒè¦‹ã‚‰ã‚Œã‚‹ã€‚LLMsã¨TMsã®çµ±åˆã«ã‚ˆã‚Šã€ä¼æ¥­ç‰¹æœ‰ã®ãƒ‹ãƒ¼ã‚ºã«å¿œã˜ãŸã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã®å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>QLoRAã§Llama 8B Instructã‚’MTã®ãƒ‡ãƒ¼ã‚¿ã§SFTã—ãŸå ´åˆã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã«å¯¾ã™ã‚‹æ€§èƒ½ã®å¤‰åŒ–ã‚’æ¤œè¨¼ã—ã¦ã„ã‚‹ã€‚ãŸã ã—ã€æ¤œè¨¼ã—ã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ã¯MTã€QLoRAã§SFTã‚’å®Ÿæ–½ã—rankã¯64ã€å­¦ç¿’æ™‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯éå¸¸ã«ã‚·ãƒ³ãƒ—ãƒ«ãªã‚‚ã®ã§ã‚ã‚‹ãªã©ã€å¹…åºƒã„è¨­å®šã§å­¦ç¿’ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã®ã§ã€ã“ã“ã§å¾—ã‚‰ã‚ŒãŸçŸ¥è¦‹ãŒå¹…åºƒãé©ç”¨å¯èƒ½ãªã“ã¨ã¯ç¤ºã•ã‚Œã¦ã„ãªã„ã§ã‚ã‚ã†ç‚¹ã€ã«ã¯æ³¨æ„ãŒå¿…è¦ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>ã“ã®è¨­å®šã§ã¯ã€SFTã§åˆ©ç”¨ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå¢—ãˆã‚Œã°å¢—ãˆã‚‹ã»ã©æ€§èƒ½ãŒä¸ŠãŒã£ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/71309a00-85fd-491f-a89e-c9cb99f4da6c" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/ea1eba38-9488-43e5-a64b-f997bf65f57b" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/21b21628-d589-4214-8860-680e392a2556" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1640" target="_blank" rel="noopener noreferrer" class="title-link">LoRA Learns Less and Forgets Less, Dan Biderman+, TMLR'24</a>
<span class="snippet"><span>GPT Summary</span>- LoRAã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®åŠ¹ç‡çš„ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã§ã‚ã‚Šã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¨æ•°å­¦ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®æ€§èƒ½ã‚’ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¯”è¼ƒã€‚æ¨™æº–çš„ãªè¨­å®šã§ã¯LoRAã¯æ€§èƒ½ãŒåŠ£ã‚‹ãŒã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‰ãƒ¡ã‚¤ãƒ³å¤–ã®ã‚¿ã‚¹ã‚¯ã§ã¯ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ç¶­æŒã—ã€å¿˜å´ã‚’è»½æ¸›ã™ã‚‹åŠ¹æœãŒã‚ã‚‹ã€‚ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯LoRAã‚ˆã‚Šã‚‚é«˜ã„ãƒ©ãƒ³ã‚¯ã®æ‘‚å‹•ã‚’å­¦ç¿’ã—ã€æ€§èƒ½å·®ã®ä¸€å› ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚æœ€çµ‚çš„ã«ã€LoRAã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«é–¢ã™ã‚‹ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’ææ¡ˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>full finetuningã¨LoRAã®æ€§è³ªã®é•ã„ã‚’ç†è§£ã™ã‚‹ã®ã«æœ‰ç”¨</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1639" target="_blank" rel="noopener noreferrer" class="title-link">FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge  into LLMs?, Eric Wu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å•†æ¥­çš„ãªLLMå¾®èª¿æ•´APIã®åŠ¹æœã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®FineTuneBenchã‚’ææ¡ˆã€‚5ã¤ã®æœ€å‰ç·šã®LLMã‚’åˆ†æã—ã€æ–°ã—ã„æƒ…å ±ã®å­¦ç¿’ã¨æ—¢å­˜çŸ¥è­˜ã®æ›´æ–°ã«ãŠã‘ã‚‹èƒ½åŠ›ã‚’è©•ä¾¡ã—ãŸçµæœã€å…¨ãƒ¢ãƒ‡ãƒ«ã§å¹³å‡ä¸€èˆ¬åŒ–ç²¾åº¦ã¯37%ã€åŒ»ç™‚ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã®æ›´æ–°ã§ã¯19%ã¨ä½ã„ã“ã¨ãŒåˆ¤æ˜ã€‚ç‰¹ã«GPT-4o miniãŒæœ€ã‚‚åŠ¹æœçš„ã§ã€Gemini 1.5ã‚·ãƒªãƒ¼ã‚ºã¯èƒ½åŠ›ãŒé™ã‚‰ã‚Œã¦ã„ãŸã€‚å•†æ¥­çš„å¾®èª¿æ•´ã‚µãƒ¼ãƒ“ã‚¹ã®ä¿¡é ¼æ€§ã«èª²é¡ŒãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1637" target="_blank" rel="noopener noreferrer" class="title-link">Generative AI for Synthetic Data Generation: Methods, Challenges and the  Future, Xu Guo+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- é™ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒŠãƒªã‚ªã§LLMsã‚’ç”¨ã„ã¦åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ç ”ç©¶ãŒå¢—åŠ ã—ã¦ãŠã‚Šã€ã“ã‚Œã¯ç”Ÿæˆçš„AIã®é€²å±•ã‚’ç¤ºã™ã€‚LLMsã¯å®Ÿä¸–ç•Œã®ãƒ‡ãƒ¼ã‚¿ã¨åŒç­‰ã®æ€§èƒ½ã‚’æŒã¡ã€ãƒªã‚½ãƒ¼ã‚¹ãŒé™ã‚‰ã‚ŒãŸèª²é¡Œã«å¯¾ã™ã‚‹è§£æ±ºç­–ã¨ãªã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€ã‚¿ã‚¹ã‚¯ç‰¹åŒ–å‹ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ãŸã‚ã®æŠ€è¡“ã€è©•ä¾¡æ–¹æ³•ã€å®Ÿç”¨çš„å¿œç”¨ã€ç¾åœ¨ã®åˆ¶é™ã€å°†æ¥ã®ç ”ç©¶ã®æ–¹å‘æ€§ã«ã¤ã„ã¦è­°è«–ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1636" target="_blank" rel="noopener noreferrer" class="title-link">On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A  Survey, Lin Long+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ·±å±¤å­¦ç¿’ã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿ã®é‡ã¨è³ªã®å•é¡Œã«å¯¾ã—ã€LLMsãŒåˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚’é€šã˜ã¦è§£æ±ºç­–ã‚’æä¾›ã€‚ã—ã‹ã—ã€ç¾çŠ¶ã®ç ”ç©¶ã¯çµ±ä¸€ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ¬ ãã€è¡¨é¢çš„ãªã‚‚ã®ãŒå¤šã„ã€‚æœ¬è«–æ–‡ã§ã¯åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ•´ç†ã—ã€ç ”ç©¶ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’æ˜ã‚‰ã‹ã«ã—ã€ä»Šå¾Œã®å±•æœ›ã‚’ç¤ºã™ã€‚å­¦è¡“ç•Œã¨ç”£æ¥­ç•Œã®ã‚ˆã‚Šä½“ç³»çš„ãªæ¢æ±‚ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/SessionBased.html" target="_blank" rel="noopener noreferrer">#SessionBased</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2024-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1632" target="_blank" rel="noopener noreferrer" class="title-link">Preference Discerning with LLM-Enhanced Generative Retrieval, Fabian Paischer+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- é€æ¬¡æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€ã€Œå¥½ã¿ã®è­˜åˆ¥ã€ã¨ã„ã†æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ææ¡ˆã€‚å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã‚’ç”Ÿæˆã—ã€åŒ…æ‹¬çš„ãªè©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã€‚æ–°æ‰‹æ³•Menderã¯ã€æ—¢å­˜æ‰‹æ³•ã‚’æ”¹å–„ã—ã€æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚Menderã¯æœªè¦³å¯Ÿã®äººé–“ã®å¥½ã¿ã«ã‚‚åŠ¹æœçš„ã«å¯¾å¿œã—ã€ã‚ˆã‚Šãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸæ¨è–¦ã‚’å®Ÿç¾ã™ã‚‹ã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–äºˆå®šã€‚</span>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/SessionBased.html" target="_blank" rel="noopener noreferrer">#SessionBased</a>
<span class="issue_date">Issue Date: 2024-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1631" target="_blank" rel="noopener noreferrer" class="title-link">Unifying Generative and Dense Retrieval for Sequential Recommendation, Liu Yang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- é€æ¬¡å¯†ãªæ¤œç´¢ãƒ¢ãƒ‡ãƒ«ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®å†…ç©è¨ˆç®—ã‚’è¡Œã†ãŒã€ã‚¢ã‚¤ãƒ†ãƒ æ•°ã®å¢—åŠ ã«ä¼´ã„ãƒ¡ãƒ¢ãƒªè¦ä»¶ãŒå¢—å¤§ã™ã‚‹ã€‚ä¸€æ–¹ã€ç”Ÿæˆçš„æ¤œç´¢ã¯ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯IDã‚’ç”¨ã„ã¦ã‚¢ã‚¤ãƒ†ãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’äºˆæ¸¬ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ã€‚ã“ã‚Œã‚‰äºŒã¤ã®æ‰‹æ³•ã®æ¯”è¼ƒãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€LIGERã¨ã„ã†ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã€ç”Ÿæˆçš„æ¤œç´¢ã¨é€æ¬¡å¯†ãªæ¤œç´¢ã®å¼·ã¿ã‚’çµ±åˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ã‚¤ãƒ†ãƒ æ¨è–¦ã‚’å¼·åŒ–ã—ã€æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®åŠ¹ç‡æ€§ã¨åŠ¹æœã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2024-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1630" target="_blank" rel="noopener noreferrer" class="title-link">Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via  Collective Monte Carlo Tree Search, Huanjin Yao+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€MLLMã‚’ç”¨ã„ã¦è³ªå•è§£æ±ºã®ãŸã‚ã®æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’å­¦ç¿’ã™ã‚‹æ–°æ‰‹æ³•CoMCTSã‚’ææ¡ˆã€‚é›†å›£å­¦ç¿’ã‚’æ´»ç”¨ã—ã€è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã§åŠ¹æœçš„ãªæ¨è«–çµŒè·¯ã‚’æ¢ç´¢ã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆMulberry-260kã‚’æ§‹ç¯‰ã—ã€ãƒ¢ãƒ‡ãƒ«Mulberryã‚’è¨“ç·´ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šææ¡ˆæ‰‹æ³•ã®å„ªä½æ€§ã‚’ç¢ºèªã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<span class="issue_date">Issue Date: 2024-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1629" target="_blank" rel="noopener noreferrer" class="title-link">LearnLM: Improving Gemini for Learning, LearnLM Team+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ç”ŸæˆAIã‚·ã‚¹ãƒ†ãƒ ã¯å¾“æ¥ã®æƒ…å ±æç¤ºã«åã£ã¦ã„ã‚‹ãŸã‚ã€æ•™è‚²çš„è¡Œå‹•ã‚’æ³¨å…¥ã™ã‚‹ã€Œæ•™è‚²çš„æŒ‡ç¤ºã®éµå®ˆã€ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®æŒ¯ã‚‹èˆã„ã‚’æŸ”è»Ÿã«æŒ‡å®šã§ãã€æ•™è‚²ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§Geminiãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’å‘ä¸Šã€‚LearnLMãƒ¢ãƒ‡ãƒ«ã¯ã€ã•ã¾ã–ã¾ãªå­¦ç¿’ã‚·ãƒŠãƒªã‚ªã§å°‚é–€å®¶ã‹ã‚‰é«˜ãè©•ä¾¡ã•ã‚Œã€GPT-4oã‚„Claude 3.5ã«å¯¾ã—ã¦ã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/TheoryOfMind.html" target="_blank" rel="noopener noreferrer">#TheoryOfMind</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2024-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1628" target="_blank" rel="noopener noreferrer" class="title-link">Explore Theory of Mind: Program-guided adversarial data generation for  theory of mind reasoning, Melanie Sclar+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ExploreToMã¯ã€å¿ƒã®ç†è«–ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®å¤šæ§˜ã§æŒ‘æˆ¦çš„ãªãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€LLMsã®é™ç•Œã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã€‚æœ€å…ˆç«¯ã®LLMsã¯ã€ExploreToMç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ä½ã„ç²¾åº¦ã‚’ç¤ºã—ã€å …ç‰¢ãªè©•ä¾¡ã®å¿…è¦æ€§ã‚’å¼·èª¿ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šå¾“æ¥ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ç²¾åº¦å‘ä¸Šã‚’å®Ÿç¾ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®è¦å› ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãŠã‚‚ã—ã‚ãã†ã€‚ã‚ã¨ã§èª­ã‚€</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2024-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1627" target="_blank" rel="noopener noreferrer" class="title-link">A Survey on LLM Inference-Time Self-Improvement, Xiangjue Dong+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMæ¨è«–ã«ãŠã‘ã‚‹è‡ªå·±æ”¹å–„æŠ€è¡“ã‚’ä¸‰ã¤ã®è¦–ç‚¹ã‹ã‚‰æ¤œè¨ã€‚ç‹¬ç«‹ã—ãŸè‡ªå·±æ”¹å–„ã¯ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ç„¦ç‚¹ã€æ–‡è„ˆã«å¿œã˜ãŸè‡ªå·±æ”¹å–„ã¯è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã€ãƒ¢ãƒ‡ãƒ«æ”¯æ´ã®è‡ªå·±æ”¹å–„ã¯ãƒ¢ãƒ‡ãƒ«é–“ã®å”åŠ›ã‚’é€šã˜ã¦è¡Œã†ã€‚é–¢é€£ç ”ç©¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨èª²é¡Œã€ä»Šå¾Œã®ç ”ç©¶ã¸ã®æ´å¯Ÿã‚’æä¾›ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2024-12-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1626" target="_blank" rel="noopener noreferrer" class="title-link">From Matching to Generation: A Survey on Generative Information  Retrieval, Xiaoxi Li+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æƒ…å ±æ¤œç´¢ï¼ˆIRï¼‰ã‚·ã‚¹ãƒ†ãƒ ã¯ã€æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚„è³ªå•å¿œç­”ãªã©ã§é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¦ã„ã‚‹ã€‚å¾“æ¥ã®IRæ‰‹æ³•ã¯é¡ä¼¼æ€§ãƒãƒƒãƒãƒ³ã‚°ã«åŸºã¥ã„ã¦ã„ãŸãŒã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®é€²å±•ã«ã‚ˆã‚Šç”Ÿæˆæƒ…å ±æ¤œç´¢ï¼ˆGenIRï¼‰ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã€‚GenIRã¯ç”Ÿæˆæ–‡æ›¸æ¤œç´¢ï¼ˆGRï¼‰ã¨ä¿¡é ¼æ€§ã®ã‚ã‚‹å¿œç­”ç”Ÿæˆã«åˆ†ã‹ã‚Œã€GRã¯ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦æ–‡æ›¸ã‚’ç›´æ¥ç”Ÿæˆã—ã€å¿œç­”ç”Ÿæˆã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã«æŸ”è»Ÿã«å¿œãˆã‚‹ã€‚æœ¬è«–æ–‡ã¯GenIRã®æœ€æ–°ç ”ç©¶ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„å¿œç­”ç”Ÿæˆã®é€²å±•ã€è©•ä¾¡ã‚„èª²é¡Œã«ã¤ã„ã¦ã‚‚è€ƒå¯Ÿã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€GenIRåˆ†é‡ã®ç ”ç©¶è€…ã«æœ‰ç›Šãªå‚è€ƒè³‡æ–™ã‚’æä¾›ã—ã€ã•ã‚‰ãªã‚‹ç™ºå±•ã‚’ä¿ƒã™ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-12-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1624" target="_blank" rel="noopener noreferrer" class="title-link">RetroLLM: Empowering Large Language Models to Retrieve Fine-grained  Evidence within Generation, Xiaoxi Li+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- RetroLLMã¯ã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ã¨ç”Ÿæˆã‚’çµ±åˆã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€LLMsãŒã‚³ãƒ¼ãƒ‘ã‚¹ã‹ã‚‰ç›´æ¥è¨¼æ‹ ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚éšå±¤çš„FM-ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ¶ç´„ã‚’å°å…¥ã—ã€é–¢é€£æ–‡æ›¸ã‚’ç‰¹å®šã™ã‚‹ã“ã¨ã§ç„¡é–¢ä¿‚ãªãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç©ºé–“ã‚’å‰Šæ¸›ã—ã€å‰å‘ããªåˆ¶ç´„ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ã§è¨¼æ‹ ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚åºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€ãƒ‰ãƒ¡ã‚¤ãƒ³å†…å¤–ã®ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rohanpaul_ai/status/1872714703090401721?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¾“æ¥ã®RAGã¨ã®é•ã„ã¨ã€ææ¡ˆæ‰‹æ³•ã®æ¦‚è¦<br><img src="https://github.com/user-attachments/assets/cd237a17-52f8-429f-9553-d35a449982ff" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/3a355c20-ccd2-49a8-bed7-f84ea84af14c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-12-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1616" target="_blank" rel="noopener noreferrer" class="title-link">A Survey on LLM-as-a-Judge, Jiawei Gu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã‚’è©•ä¾¡è€…ã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã€ŒLLM-as-a-Judgeã€ã®ä¿¡é ¼æ€§å‘ä¸Šã«é–¢ã™ã‚‹èª¿æŸ»ã€‚ä¿¡é ¼æ€§ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã®æˆ¦ç•¥ã‚„è©•ä¾¡æ–¹æ³•è«–ã‚’ææ¡ˆã—ã€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ç”¨ã„ã¦ã‚µãƒãƒ¼ãƒˆã€‚å®Ÿç”¨çš„ãªå¿œç”¨ã‚„å°†æ¥ã®æ–¹å‘æ€§ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã€ç ”ç©¶è€…ã‚„å®Ÿå‹™è€…ã®å‚è€ƒè³‡æ–™ã¨ãªã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://awesome-llm-as-a-judge.github.io" target="_blank" rel="noopener noreferrer">https://awesome-llm-as-a-judge.github.io</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2024-12-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1598" target="_blank" rel="noopener noreferrer" class="title-link">VLR-Bench: Multilingual Benchmark Dataset for Vision-Language Retrieval  Augmented Generation, Hyeonseok Lim+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- è¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆVLMï¼‰ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯VLR-Benchã‚’ææ¡ˆã€‚ã“ã‚Œã¯5ã¤ã®å…¥åŠ›ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”¨ã„ã¦ã€ç‰¹å®šã®ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹æœ‰ç”¨ãªæƒ…å ±ã®åˆ¤æ–­èƒ½åŠ›ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã€‚32,000ã®è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸæŒ‡ç¤ºã‹ã‚‰ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆVLR-IFã‚’æ§‹ç¯‰ã—ã€VLMã®RAGèƒ½åŠ›ã‚’å¼·åŒ–ã€‚Llama3ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã§æ€§èƒ½ã‚’æ¤œè¨¼ã—ã€ä¸¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Multilingual VLMã‚’ç”¨ã„ãŸRAGã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<span class="issue_date">Issue Date: 2024-12-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1597" target="_blank" rel="noopener noreferrer" class="title-link">Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions, Yu Zhao+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Marco-o1ã¯ã€LRMã®ç ”ç©¶ã«ãŠã„ã¦ã€æ•°å­¦ã‚„ç‰©ç†å­¦ã ã‘ã§ãªãã€RLã‚„ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ã®è§£æ±ºç­–ã«ã‚‚é‡ç‚¹ã‚’ç½®ã„ã¦ã„ã‚‹ã€‚ç‰¹ã«ã€o1ãƒ¢ãƒ‡ãƒ«ãŒåŸºæº–ãŒä¸æ˜ç­ãªé ˜åŸŸã«ä¸€èˆ¬åŒ–ã§ãã‚‹ã‹ã‚’æ¢æ±‚ã—ã€Chain-of-Thoughtãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„MCTSã€åå°„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æ´»ç”¨ã—ã¦è¤‡é›‘ãªå•é¡Œè§£æ±ºã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bilzrd/status/1868568258468774048?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Large Reasoning Model ï¼ˆLRMï¼‰ã¨ã„ã†ç”¨èªã¯åˆã‚ã¦è¦‹ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2024-12-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1594" target="_blank" rel="noopener noreferrer" class="title-link">When Benchmarks are Targets: Revealing the Sensitivity of Large Language   Model Leaderboards, Norah Alzahrani+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã¯ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«åŸºã¥ã„ã¦ãƒ¢ãƒ‡ãƒ«é¸æŠã‚’æ”¯æ´ã™ã‚‹ãŒã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯å¾®ç´°ãªå¤‰æ›´ã«æ•æ„Ÿã§ã‚ã‚Šã€æœ€å¤§8ä½å¤‰å‹•ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚3ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ‘‚å‹•ã®ã‚«ãƒ†ã‚´ãƒªã«ã‚ãŸã‚‹å®Ÿé¨“ã‚’é€šã˜ã¦ã€ã“ã®ç¾è±¡ã®åŸå› ã‚’ç‰¹å®šã—ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°æ–¹æ³•ã®åˆ©ç‚¹ã‚’å«ã‚€ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’ææ¡ˆã€‚å˜ç´”ãªè©•ä¾¡ã«ä¾å­˜ã™ã‚‹å±é™ºæ€§ã‚’å¼·èª¿ã—ã€ã‚ˆã‚Šå …ç‰¢ãªè©•ä¾¡ã‚¹ã‚­ãƒ¼ãƒ ã®å¿…è¦æ€§ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1591" target="_blank" rel="noopener noreferrer">å›½éš›ä¼šè­°ACL2024å‚åŠ å ±å‘Š, Masato Mita, Cyber Agent, 2024.12</a>
<br><br>ã«æ—¥æœ¬èªã§ã®ã‚µãƒãƒªãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã®ã§å‚ç…§ã®ã“ã¨ã€‚<br><br>ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã®ãƒã‚¤ã‚¢ã‚¹ã‚’è»½æ¸›ã—ãŸçµæœã€ã©ã®LLMãŒæœ€å¤§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã¿ãªã•ã‚Œã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã ã‚ã†ã‹ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-12-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1593" target="_blank" rel="noopener noreferrer" class="title-link">BatchEval: Towards Human-like Text Evaluation, Peiwen Yuan+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- BatchEvalã¨ã„ã†æ–°ã—ã„è©•ä¾¡ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ææ¡ˆã—ã€LLMã‚’ç”¨ã„ãŸè‡ªå‹•ãƒ†ã‚­ã‚¹ãƒˆè©•ä¾¡ã®å•é¡Œã‚’è§£æ±ºã€‚ãƒãƒƒãƒå˜ä½ã§ã®åå¾©è©•ä¾¡ã«ã‚ˆã‚Šã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã®æ•æ„Ÿã•ã‚„ãƒã‚¤ã‚ºè€æ€§ã®ä½ã•ã‚’è»½æ¸›ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€BatchEvalã¯æœ€å…ˆç«¯æ‰‹æ³•ã«å¯¾ã—ã¦10.5%ã®æ”¹å–„ã‚’ç¤ºã—ã€APIã‚³ã‚¹ãƒˆã‚’64%å‰Šæ¸›ã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1591" target="_blank" rel="noopener noreferrer">å›½éš›ä¼šè­°ACL2024å‚åŠ å ±å‘Š, Masato Mita, Cyber Agent, 2024.12</a>
<br><br>ã«æ—¥æœ¬èªã«ã‚ˆã‚‹ã‚µãƒãƒªãŒæ²è¼‰ã•ã‚Œã¦ã„ã‚‹ã®ã§å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-12-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1592" target="_blank" rel="noopener noreferrer" class="title-link">Striking Gold in Advertising: Standardization and Exploration of Ad Text   Generation, Masato Mita+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå‹•åºƒå‘Šãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆATGï¼‰ã®ãŸã‚ã«ã€æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆCAMERAã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æƒ…å ±ã®æ´»ç”¨ã¨æ¥­ç•Œå…¨ä½“ã§ã®è©•ä¾¡ãŒä¿ƒé€²ã•ã‚Œã‚‹ã€‚9ã¤ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã€ç¾çŠ¶ã¨èª²é¡Œã‚’æ˜ã‚‰ã‹ã«ã—ã€LLMãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡è€…ã¨äººé–“ã®è©•ä¾¡ã®ä¸€è‡´ã‚’æ¢æ±‚ã€‚</span>
<span class="snippet"><span>Comment</span><p>åºƒå‘Šæ–‡ç”Ÿæˆã‚¿ã‚¹ã‚¯ï¼ˆAd Text Generationï¼‰ã¯å€‹ã€…ã®ã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãƒ‡ãƒ¼ã‚¿ã§ã—ã‹è©•ä¾¡ã•ã‚Œã¦ã“ãªã‹ã£ãŸã“ã¨ã¨ã€ãã‚‚ãã‚‚ã‚¿ã‚¹ã‚¯è¨­å®šãŒååˆ†ã«è¦å®šã•ã‚Œã¦ã„ãªã„ã®ã§ã€ãã®è¾ºã‚’æ•´å‚™ã—ãŸã¨ã„ã†è©±ã‚‰ã—ã„ã€‚<br>ç‰¹ã«åºƒå‘Šæ–‡ç”Ÿæˆã®ãŸã‚ã®åˆã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ãªCAMERAã‚’æ§‹ç¯‰ã—ã¦ã„ã‚‹ã€‚<br><br>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œã‚‹ã ã‘ã§ãªãã€æ—¢å­˜ã®æ‰‹æ³•ã€å¤å…¸çš„ãªã‚‚ã®ã‹ã‚‰LLMã¾ã§ã§ã©ã®ç¨‹åº¦ã®æ€§èƒ½ã¾ã§åˆ°é”ã—ã¦ã„ã‚‹ã‹ã€ã•ã‚‰ã«ã¯ROUGEã‚„GPT-4ã‚’ç”¨ã„ãŸLLM-as-a-Judgeã®ã‚ˆã†ãªè‡ªå‹•è©•ä¾¡æ‰‹æ³•ã‚’ãƒ¡ã‚¿è©•ä¾¡ã—ã€äººæ‰‹è©•ä¾¡ã¨ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©•ä¾¡ã®ã©ã®ç¨‹åº¦ä»£æ›¿ã«ãªã‚‹ã‹ã‚‚åˆ†æã—ãŸã¨ã®ã“ã¨ã‚‰ã—ã„ã€‚</p>
<p>Table5ã«ãƒ¡ã‚¿è©•ä¾¡ã®çµæœãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã®correlationã‚’æ¸¬å®šã—ã¦ã„ã‚‹ã€‚èˆˆå‘³æ·±ã„ã®ãŒã€BLEU-4, ROUGE-1, BERTScoreãªã©ã®å¤å…¸çš„oråŸ‹ã‚è¾¼ã¿ãƒ™ãƒ¼ã‚¹ã®NLGè©•ä¾¡æ‰‹æ³•ãŒFaithfulnessã¨Fluencyã«ãŠã„ã¦ã€äººé–“ã®å°‚é–€å®¶ã¨é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ã¦ã„ã‚‹ã®ã«å¯¾ã—ã€GPT-4ã«ã‚ˆã‚‹è©•ä¾¡ã§ã¯äººé–“ã«ã‚ˆã‚‹è©•ä¾¡ã¨å…¨ç„¶ç›¸é–¢ãŒå‡ºã¦ã„ãªã„ã€‚<br><br>æ—¢å­˜ã®LLM-as-a-Judgeç ”ç©¶ã§ã¯å°‚é–€å®¶ã¨åŒç­‰ã®è©•ä¾¡ã§ãã¾ã™ã€ã¿ãŸã„ãªè©±ãŒã‚ˆãè¦‹å—ã‘ã‚‰ã‚Œã‚‹ãŒã“ã‚Œã‚‰ã®å ±å‘Šã¨çµæœãŒç•°ãªã£ã¦ã„ã¦ãŠã‚‚ã—ã‚ã„ã€‚è‘—è€…ã‚‰ã¯ã€OpenAIã®GPTã¯ãã‚‚ãã‚‚åºƒå‘Šãƒ‰ãƒ¡ã‚¤ãƒ³ã¨ãƒ†ã‚­ã‚¹ãƒˆã§ãã‚“ãªã«è¨“ç·´ã•ã‚Œã¦ã„ãªã•ãã†ãªã®ã§ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒŸã‚¹ãƒãƒƒãƒãŒä¸€ã¤ã®è¦å› ã¨ã—ã¦ã‚ã‚‹ã®ã§ã¯ãªã„ã‹ã€ã¨è€ƒå¯Ÿã—ã¦ã„ã‚‹ã€‚<br><br>ã¾ãŸã€Attractivenessã§ã¯å°‚é–€å®¶ã«ã‚ˆã‚‹è©•ä¾¡ã¨å¼±ã„ç›¸é–¢ã—ã‹ç¤ºã—ã¦ã„ãªã„ç‚¹ã‚‚èˆˆå‘³æ·±ã„ã€‚åºƒå‘Šæ–‡ãŒã©ã®ç¨‹åº¦é­…åŠ›çš„ã‹ã¯BLEU, ROUGE, BERTScoreã‚ãŸã‚Šã§ã¯ãªã‹ãªã‹é›£ã—ãã†ãªã®ã§ã€GPT4ã«ã‚ˆã‚‹è©•ä¾¡ãŒã†ã¾ãã„ã£ã¦æ¬²ã—ã„ã¨ã“ã‚ã ãŒã€å…¨ãã†ã¾ãã„ã£ã¦ã„ãªã„ã€‚ã“ã®è«–æ–‡ã®çµæœã ã‘ã‚’è¦‹ã‚‹ã¨ã€ï¼ˆAttractivenessã«é–¢ã—ã¦ã¯ï¼‰è‡ªå‹•è©•ä¾¡ã ã‘ã§ã¯ã¾ã ã¾ã åºƒå‘Šæ–‡ã®è©•ä¾¡ã¯å³ã—ãã†ã«è¦‹ãˆã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/15804ddc-3131-4a3d-9071-a66473e0e987" alt="image" loading="lazy"></p>
<p>GPT4ã«ã‚ˆã‚‹Attractivenessã®è©•ä¾¡ã«åˆ©ç”¨ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒä¸‹è¨˜ã€‚MTBenchã£ã½ãã€ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã®åˆ†é¡å•é¡Œã¨ã—ã¦è§£ã„ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚ã“ã®è¾ºã¯LLM-as-a-Judgeã®ç ”ç©¶ã§ã¯ä»–ã«ã‚‚ã‚¹ã‚³ã‚¢ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‡ºåŠ›ã—å°¤åº¦ã§é‡ã¿ã¥ã‘ã‚‹G-Evalã‚’ã¯ã˜ã‚ã€ã•ã¾ã–ã¾ãªæ‰‹æ³•ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã¨æ€ã†ã®ã§ã€ãã®è¾ºã®æ‰‹æ³•ã‚’åˆ©ç”¨ã—ãŸã‚‰ã©ã†ãªã‚‹ã‹ã¯èˆˆå‘³ãŒã‚ã‚‹ã€‚<br>ã‚ã¨ã¯ãã‚‚ãã‚‚æ‰‹æ³•é¢ã®è©±ä»¥å‰ã«ã€promptã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã¨ã—ã¦ã©ã®ã‚ˆã†ãªæƒ…å ±ãŒAttractivenessã®è©•ä¾¡ã«é‡è¦ã‹ï¼Ÿã¨ã„ã†ã®ã‚‚æ˜ã‚‰ã‹ã«ãªã‚‹ã¨èˆˆå‘³æ·±ã„ã€‚ã“ã®è¾ºã¯ã€ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å°‚é–€å®¶éƒ¨éšŠãŒã€ã©ã®ã‚ˆã†ãªã“ã¨ã‚’æ€è€ƒã—ã¦Attractivenessã‚’è©•ä¾¡ã—ã¦ã„ã‚‹ã®ã‹ï¼Ÿã¨ã„ã†ã®ãŒãƒ’ãƒ³ãƒˆã«ãªã‚Šãã†ã§ã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/5c0d3989-d4c1-4d61-b592-b1140c4cf93d" alt="image" loading="lazy"><br></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1591" target="_blank" rel="noopener noreferrer">å›½éš›ä¼šè­°ACL2024å‚åŠ å ±å‘Š, Masato Mita, Cyber Agent, 2024.12</a>
<br><br>ã«è‘—è€…ã«ã‚ˆã‚‹ã‚µãƒãƒªãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã®ã§å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2024-12-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1590" target="_blank" rel="noopener noreferrer" class="title-link">The broader spectrum of in-context learning, Andrew Kyle Lampinen+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã‚’ãƒ¡ã‚¿å­¦ç¿’ã«åŸºã¥ãæ–‡è„ˆå†…å­¦ç¿’ã®ä¸€éƒ¨ã¨ã—ã¦ä½ç½®ã¥ã‘ã€æ–‡è„ˆãŒäºˆæ¸¬ã®æå¤±ã‚’æ¸›å°‘ã•ã›ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®è¦–ç‚¹ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ–‡è„ˆå†…èƒ½åŠ›ã‚’çµ±ä¸€ã—ã€ä¸€èˆ¬åŒ–ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã¾ã™ã€‚ä¸€èˆ¬åŒ–ã¯æ–°ã—ã„å­¦ç¿’ã ã‘ã§ãªãã€ç•°ãªã‚‹æç¤ºã‹ã‚‰ã®å­¦ã³ã‚„é©ç”¨èƒ½åŠ›ã«ã‚‚é–¢é€£ã—ã€éå»ã®æ–‡çŒ®ã¨ã®é–¢é€£æ€§ã‚‚è­°è«–ã•ã‚Œã¾ã™ã€‚æ–‡è„ˆå†…å­¦ç¿’ã®ç ”ç©¶ã¯ã€åºƒç¯„ãªèƒ½åŠ›ã¨ä¸€èˆ¬åŒ–ã®ã‚¿ã‚¤ãƒ—ã‚’è€ƒæ…®ã™ã¹ãã¨çµè«–ä»˜ã‘ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=RHo3VVi0i5" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=RHo3VVi0i5</a>


<br><br>OpenReviewã«ã‚ˆã‚‹ã¨ã€<br>è«–æ–‡ã¯ç†è§£ã—ã‚„ã™ãã€meta learningã«ã¤ã„ã¦åºƒç¯„ã«ã‚µãƒ¼ãƒ™ã‚¤ã•ã‚Œã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€è«–æ–‡ãŒå®šç¾©ã—ã¦ã„ã‚‹ICLã®æ‹¡å¼µã¯ICLã‚’éåº¦ã«ä¸€èˆ¬åŒ–ã—éãã¦ãŠã‚Šï¼ˆå…·ä½“çš„ã«ä½•ãŒICLã§ä½•ãŒICLã§ãªã„ã®ã‹ã€ã¨ã„ã£ãŸè¦å®šãŒã§ããªã„ï¼‰ã€ã‹ã¤è«–æ–‡ä¸­ã§ææ¡ˆã•ã‚Œã¦ã„ã‚‹ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’è£ä»˜ã‘ã‚‹å®Ÿé¨“ãŒãªãspeculativeã§ã‚ã‚‹ã€ã¨ã®ã“ã¨ã§rejectã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-12-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1589" target="_blank" rel="noopener noreferrer" class="title-link">Phi-4 Technical Report, Marah Abdin+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- 140å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã€Œphi-4ã€ã¯ã€åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šå…¥ã‚ŒãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šã€STEMã«ç‰¹åŒ–ã—ãŸQAèƒ½åŠ›ã§æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚phi-3ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æœ€å°é™ã«å¤‰æ›´ã—ãŸã ã‘ã§ã€æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ãŠã„ã¦ã‚‚æ”¹å–„ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã«ã‚ˆã‚Šå¼·åŠ›ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>ç¾çŠ¶Azureã§ã®ã¿åˆ©ç”¨å¯èƒ½ã‹ã‚‚ã€‚Huggingfaceã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã‚‚éå•†ç”¨ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«ãªã‚‹ã¨ã„ã†å™‚ã‚‚</p>
<p>MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹<br>HuggingFace:<br>


<a href="https://huggingface.co/microsoft/phi-4" target="_blank" rel="noopener noreferrer">https://huggingface.co/microsoft/phi-4</a>


</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-12-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1578" target="_blank" rel="noopener noreferrer" class="title-link">Auto-RAG: Autonomous Retrieval-Augmented Generation for Large Language  Models, Tian Yu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Auto-RAGã¯ã€LLMã®æ„æ€æ±ºå®šèƒ½åŠ›ã‚’æ´»ç”¨ã—ãŸè‡ªå¾‹çš„ãªåå¾©æ¤œç´¢ãƒ¢ãƒ‡ãƒ«ã§ã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã¨ã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å¯¾è©±ã‚’é€šã˜ã¦çŸ¥è­˜ã‚’å–å¾—ã—ã¾ã™ã€‚æ¨è«–ã«åŸºã¥ãæ„æ€æ±ºå®šã‚’è‡ªå¾‹çš„ã«åˆæˆã—ã€6ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€åå¾©å›æ•°ã‚’è³ªå•ã®é›£æ˜“åº¦ã«å¿œã˜ã¦èª¿æ•´å¯èƒ½ã§ã™ã€‚ã¾ãŸã€ãƒ—ãƒ­ã‚»ã‚¹ã‚’è‡ªç„¶è¨€èªã§è¡¨ç¾ã—ã€è§£é‡ˆå¯èƒ½æ€§ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1863600141103501454?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=jkVQ31GeIA" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=jkVQ31GeIA</a>


</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=jkVQ31GeIA" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=jkVQ31GeIA</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2024-12-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1575" target="_blank" rel="noopener noreferrer" class="title-link">LLMs Will Always Hallucinate, and We Need to Live With This, Sourav Banerjee+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®å¹»è¦šã¯å¶ç™ºçš„ãªã‚¨ãƒ©ãƒ¼ã§ã¯ãªãã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã®åŸºæœ¬çš„ãªæ§‹é€ ã‹ã‚‰ç”Ÿã˜ã‚‹é¿ã‘ã‚‰ã‚Œãªã„ç‰¹å¾´ã§ã‚ã‚‹ã¨ä¸»å¼µã€‚ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ”¹å–„ã§ã¯å¹»è¦šã‚’æ’é™¤ã§ããªã„ã“ã¨ã‚’ç¤ºã—ã€å„ãƒ—ãƒ­ã‚»ã‚¹æ®µéšã§å¹»è¦šãŒç”Ÿæˆã•ã‚Œã‚‹ç¢ºç‡ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’åˆ†æã€‚æ–°ãŸã«ã€Œæ§‹é€ çš„å¹»è¦šã€ã¨ã„ã†æ¦‚å¿µã‚’å°å…¥ã—ã€å¹»è¦šã®æ•°å­¦çš„ç¢ºå®Ÿæ€§ã‚’ç¢ºç«‹ã™ã‚‹ã“ã¨ã§ã€å®Œå…¨ãªè»½æ¸›ã¯ä¸å¯èƒ½ã§ã‚ã‚‹ã¨è«–ã˜ã‚‹ã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<span class="issue_date">Issue Date: 2024-12-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1566" target="_blank" rel="noopener noreferrer" class="title-link">The Super Weight in Large Language Models, Mengxia Yu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¸€éƒ¨ãŒãƒ¢ãƒ‡ãƒ«ã®å“è³ªã«ä¸å‡è¡¡ã«é‡è¦ã§ã‚ã‚Šã€1ã¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å‰ªå®šã§ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆèƒ½åŠ›ãŒå¤§å¹…ã«ä½ä¸‹ã™ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒªãƒ¼ã®æ–¹æ³•ã§é‡è¦ãªã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç‰¹å®šã—ã€ã“ã‚Œã«ã‚ˆã‚Šå››æ¨äº”å…¥é‡å­åŒ–ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹ç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ãŸã‚ã«ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¢ã‚¯ã‚»ã‚¹ã®LLMã«å¯¾ã™ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å›³ã«ã‚ã‚‹é€šã‚Šã€ãŸã£ãŸä¸€ã¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸­ã®é‡ã¿ã‚’0ã«ã™ã‚‹ã ã‘ã§ã€é€”ç«¯ã«æ„å‘³ã®ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒç”Ÿæˆã§ããªããªã‚‹ã‚ˆã†ãªé‡ã¿ãŒå­˜åœ¨ã™ã‚‹ã‚‰ã—ã„ã€‚<br><img src="https://github.com/user-attachments/assets/065e921b-c447-4c0d-b1de-a2f79bd090f8" alt="image" loading="lazy"><br><br><br>ï¼ˆå›³ã¯è«–æ–‡ã‚ˆã‚Šå¼•ç”¨ï¼‰</p>
<p>ICLR 2025ã®Openreview<br>


<a href="https://openreview.net/forum?id=0Ag8FQ5Rr3" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=0Ag8FQ5Rr3</a>


</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2024-12-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1564" target="_blank" rel="noopener noreferrer" class="title-link">Do Large Language Models Perform Latent Multi-Hop Reasoning without   Exploiting Shortcuts?, Sohee Yang+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ãƒãƒ«ãƒãƒ›ãƒƒãƒ—ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹äº‹å®Ÿã®æƒ³èµ·èƒ½åŠ›ã‚’è©•ä¾¡ã€‚ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã‚’é˜²ããŸã‚ã€ä¸»èªã¨ç­”ãˆãŒå…±ã«å‡ºç¾ã™ã‚‹ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªã‚’é™¤å¤–ã—ãŸè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆSOCRATESã‚’æ§‹ç¯‰ã€‚LLMsã¯ç‰¹å®šã®ã‚¯ã‚¨ãƒªã«ãŠã„ã¦ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã‚’åˆ©ç”¨ã›ãšã«æ½œåœ¨çš„ãªæ¨è«–èƒ½åŠ›ã‚’ç¤ºã—ã€å›½ã‚’ä¸­é–“ç­”ãˆã¨ã™ã‚‹ã‚¯ã‚¨ãƒªã§ã¯80%ã®æ§‹æˆå¯èƒ½æ€§ã‚’é”æˆã™ã‚‹ä¸€æ–¹ã€å¹´ã®æƒ³èµ·ã¯5%ã«ä½ä¸‹ã€‚æ½œåœ¨çš„æ¨è«–èƒ½åŠ›ã¨æ˜ç¤ºçš„æ¨è«–èƒ½åŠ›ã®é–“ã«å¤§ããªã‚®ãƒ£ãƒƒãƒ—ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚</span>
<span class="snippet"><span>Comment</span><p>SNLP'24ã§ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:<br>


<a href="https://docs.google.com/presentation/d/1Q_UzOzn0qYX1gq_4FC4YGXK8okd5pwEHaLzVCzp3yWg/edit?usp=drivesdk" target="_blank" rel="noopener noreferrer">https://docs.google.com/presentation/d/1Q_UzOzn0qYX1gq_4FC4YGXK8okd5pwEHaLzVCzp3yWg/edit?usp=drivesdk</a>


</p>
<p>ã“ã®ç ”ç©¶ã‚’ä¿¡ã˜ã‚‹ã®ã§ã‚ã‚Œã°ã€LLMã¯CoTç„¡ã—ã§ã¯ãƒãƒ«ãƒãƒ›ãƒƒãƒ—æ¨è«–ã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã¯ã‚ã¾ã‚Šã§ãã¦ã„ãªã•ãã†ã€ã¨ã„ã†æ„Ÿã˜ã ã¨æ€ã†ã®ã ãŒã©ã†ãªã‚“ã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1561" target="_blank" rel="noopener noreferrer" class="title-link">Astute RAG: Overcoming Imperfect Retrieval Augmentation and Knowledge  Conflicts for Large Language Models, Fei Wang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Astute RAGã¯ã€å¤–éƒ¨çŸ¥è­˜ã®ä¸å®Œå…¨ãªå–å¾—ã«ã‚ˆã‚‹å•é¡Œã‚’è§£æ±ºã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€LLMsã®å†…éƒ¨çŸ¥è­˜ã¨å¤–éƒ¨çŸ¥è­˜ã‚’é©å¿œçš„ã«çµ±åˆã—ã€æƒ…å ±ã®ä¿¡é ¼æ€§ã«åŸºã¥ã„ã¦å›ç­”ã‚’æ±ºå®šã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€Astute RAGã¯å¾“æ¥ã®RAGæ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€æœ€æ‚ªã®ã‚·ãƒŠãƒªã‚ªã§ã‚‚LLMsã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¶…ãˆã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-11-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1550" target="_blank" rel="noopener noreferrer" class="title-link">From Generation to Judgment: Opportunities and Challenges of  LLM-as-a-judge, Dawei Li+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã‚’ç”¨ã„ãŸåˆ¤æ–­ã¨è©•ä¾¡ã®æ–°ãŸãªãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã€ŒLLM-as-a-judgeã€ã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªèª¿æŸ»ã‚’è¡Œã„ã€å®šç¾©ã‚„åˆ†é¡æ³•ã‚’æç¤ºã€‚è©•ä¾¡ã®ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ã¾ã¨ã‚ã€ä¸»è¦ãªèª²é¡Œã¨ä»Šå¾Œã®ç ”ç©¶æ–¹å‘ã‚’ç¤ºã™ã€‚é–¢é€£ãƒªã‚½ãƒ¼ã‚¹ã‚‚æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLM-as-a-Judgeã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ™ã‚¤<br><img src="https://github.com/user-attachments/assets/88059cc4-123e-4a89-ac2d-4b3db83cd2df" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/10fea773-e52b-4e67-9137-dfc51846988b" alt="image" loading="lazy"></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1214" target="_blank" rel="noopener noreferrer">Leveraging Large Language Models for NLG Evaluation: A Survey, Zhen Li+, N/A, arXiv'24</a>
<br><br>ã‚‚å‚ç…§ã®ã“ã¨</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2024-11-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1549" target="_blank" rel="noopener noreferrer" class="title-link">Does Prompt Formatting Have Any Impact on LLM Performance?, Jia He+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã¯LLMã®æ€§èƒ½ã«é‡è¦ã§ã‚ã‚Šã€ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã€‚å®Ÿé¨“ã§ã¯ã€GPT-3.5-turboãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ã‚ˆã£ã¦ã‚³ãƒ¼ãƒ‰ç¿»è¨³ã‚¿ã‚¹ã‚¯ã§æœ€å¤§40%å¤‰å‹•ã™ã‚‹ä¸€æ–¹ã€GPT-4ã¯ã‚ˆã‚Šå …ç‰¢ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å›ºå®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å†è€ƒãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ãŒå¼·èª¿ã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ï¼ˆä»¥ä¸‹ã€å€‹äººã®æ„Ÿæƒ³ã§ã™ï¼‰<br>æœ¬æ–‡ã®ã¿æ–œã‚èª­ã¿ã—ã¦ã€Appendixã¯çœºã‚ãŸã ã‘ãªã®ã§çš„å¤–ã‚Œãªã“ã¨ã‚’è¨€ã£ã¦ã„ãŸã‚‰ã™ã¿ã¾ã›ã‚“ã€‚<br><br>ã¾ãšã€å®Ÿå‹™ä¸Šä¸‹è¨˜çŸ¥è¦‹ã¯æœ‰ç”¨ã ã¨æ€ã„ã¾ã—ãŸ:<br>- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ã‚ˆã£ã¦æ€§èƒ½ã«å¤§ããªå·®ãŒã‚ã‚‹<br>- ã‚ˆã‚Šå¤§ãã„ãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆ<br><br>ãŸã ã—ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ã‚ˆã£ã¦æ€§èƒ½å·®ãŒã‚ã‚‹ã¨ã„ã†ã®ã¯çµŒé¨“çš„ã«ã‚ã‚‹ç¨‹åº¦LLMã‚’è§¦ã£ã¦ã„ã‚‹äººãªã‚‰åˆ†ã‹ã‚‹ã“ã¨ã ã¨æ€ã†ã®ã§ã€é©šãã¯å°‘ãªã‹ã£ãŸã€‚<br><br>å€‹äººçš„ã«æ°—ã«ãªã‚‹ç‚¹ã¯ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚‚ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚‚åˆ†ã‹ã‚‰ãªã„GPT3.5, GPT4ã®ã¿ã§å®Ÿé¨“ã‚’ã—ã¦ã€Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¤§ãã„æ–¹ãŒãƒ­ãƒã‚¹ãƒˆã€ã¨çµè«–ã¥ã‘ã¦ã„ã‚‹ç‚¹ã¨ã€ã‚‚ã†å°‘ã—æ·±æ˜ã‚Šã—ã¦è€ƒå¯Ÿã—ãŸã‚‰ã‚‚ã£ã¨ãŠã‚‚ã—ã‚ã„ã®ã«ãªã€ã¨æ„Ÿã˜ã‚‹ç‚¹ã§ã™ã€‚<br><br>å®Ÿå‹™ä¸Šã¯æœ‰ç›ŠãªçŸ¥è¦‹ã ã¨ã—ã¦ã€ã§ã¯ç ”ç©¶ã¨ã—ã¦è¦‹ãŸã¨ãã«ã€Œãªãœãã†ãªã‚‹ã®ã‹?ã€ã¨ã„ã†ã¨ã“ã‚ã‚’è¿½æ±‚ã—ã¦æ¬²ã—ã„ãªãã€ã¨ã„ã†æ„Ÿæƒ³ã‚’æŒã¡ã¾ã—ãŸã€‚<br>ãŸã¨ãˆã°ã€ã€Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¤§ãã„ãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ãƒ­ãƒã‚¹ãƒˆã€ã¨è«–æ–‡ä¸­ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã¾ã™ãŒã€<br>ãã‚Œã¯æœ¬å½“ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«ã‚ˆã‚‹ã‚‚ã®ãªã®ã‹ï¼Ÿå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹å„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å‰²åˆã¨ã‹ï¼ˆã“ã‚Œã¯äº‹å®Ÿã¯OpenAIã®ä¸­ã®äººã—ã‹åˆ†ã‹ã‚‰ãªã„ã®ã§ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ãŒã‚ã‚‹ç¨‹åº¦ã‚ªãƒ¼ãƒ—ãƒ³ã«ãªã£ã¦ã„ã‚‹OpenLLMã§ã‚‚æ¤œè¨¼ã™ã‚‹ã¨ã‹ï¼‰ã€è©•ä¾¡ã™ã‚‹ã‚¿ã‚¹ã‚¯ã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ç›¸æ€§ã¨ã‹ã€è‰²ã€…ã¨è€ƒå¯Ÿã§ãã‚‹è¦ç´ ãŒã‚ã‚‹ã®ã§ã¯ãªã„ã‹ã¨æ€ã„ã¾ã—ãŸã€‚<br>ãã®ä¸Šã§ã€å¤§éƒ¨åˆ†ã®LLMã§æ™®éçš„ãªçŸ¥è¦‹ã‚’è¦‹å‡ºã—ãŸæ–¹ãŒç ”ç©¶ã¨ã—ã¦ã‚ˆã‚Šé¢ç™½ããªã‚‹ã®ã§ã¯ãªã„ã‹ã€ã¨æ„Ÿã˜ã¾ã—ãŸã€‚<br><br><img src="https://github.com/user-attachments/assets/d0a6c727-1253-4503-93f2-8daa4db2321b" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/b7166b2b-b848-43f5-a823-7ed491232234" alt="image" loading="lazy"></p>
<p>å‚è€ƒ: Data2Textã«ãŠã‘ã‚‹æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®input formatã«ã‚ˆã‚‹æ€§èƒ½å·®ã‚’åˆ†æã—è€ƒå¯Ÿã—ã¦ã„ã‚‹ç ”ç©¶<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1267" target="_blank" rel="noopener noreferrer">Prompting for Numerical Sequences: A Case Study on Market Comment
  Generation, Masayuki Kawarada+, N/A, arXiv'24</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2024-11-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1542" target="_blank" rel="noopener noreferrer" class="title-link">Multimodal Autoregressive Pre-training of Large Vision Encoders, Enrico Fini+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„æ‰‹æ³•AIMV2ã‚’ç”¨ã„ã¦ã€å¤§è¦æ¨¡ãªãƒ“ã‚¸ãƒ§ãƒ³ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®äº‹å‰å­¦ç¿’ã‚’è¡Œã†ã€‚ã“ã‚Œã¯ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’çµ„ã¿åˆã‚ã›ãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è¨­å®šã«æ‹¡å¼µã•ã‚Œã€ã‚·ãƒ³ãƒ—ãƒ«ãªäº‹å‰å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã¨å„ªã‚ŒãŸæ€§èƒ½ã‚’ç‰¹å¾´ã¨ã™ã‚‹ã€‚AIMV2-3Bã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ImageNet-1kã§89.5%ã®ç²¾åº¦ã‚’é”æˆã—ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç”»åƒç†è§£ã«ãŠã„ã¦æœ€å…ˆç«¯ã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2024-11-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1540" target="_blank" rel="noopener noreferrer" class="title-link">Observational Scaling Laws and the Predictability of Language Model  Performance, Yangjun Ruan+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€ç´„100ã®å…¬é–‹ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’æ§‹ç¯‰ã™ã‚‹æ–°ã—ã„è¦³å¯Ÿã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼é–“ã®èƒ½åŠ›å¤‰å‹•ã‚’è€ƒæ…®ã—ã€æ€§èƒ½ãŒä½æ¬¡å…ƒã®èƒ½åŠ›ç©ºé–“ã®é–¢æ•°ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¤‡é›‘ãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç¾è±¡ã®äºˆæ¸¬å¯èƒ½æ€§ã‚’ç¤ºã—ã€GPT-4ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ€§èƒ½ã‚’éã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‹ã‚‰äºˆæ¸¬ã§ãã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã€Chain-of-Thoughtã‚„Self-Consistencyã®å½±éŸ¿ã‚’äºˆæ¸¬ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç¸¦è»¸ãŒdownstreamã‚¿ã‚¹ã‚¯ã®ä¸»æˆåˆ†ï¼ˆã®ã†ã¡æœ€ã‚‚å¤§ãã„80%ã‚’èª¬æ˜ã™ã‚‹æˆåˆ†ï¼‰ã®å¤‰åŒ–ï¼ˆâ‰’LLMã®æ€§èƒ½ï¼‰ã§ã€æ¨ªè»¸ãŒlog scaleã®æŠ•å…¥è¨ˆç®—é‡ã€‚<br>Qwenã‚‚é ‘å¼µã£ã¦ã„ã‚‹ãŒã€æŠ•å…¥ãƒ‡ãƒ¼ã‚¿é‡ã«å¯¾ã™ã‚‹æ€§èƒ½ï¼ˆâ‰’ãƒ‡ãƒ¼ã‚¿ã®å“è³ªï¼‰ã§ã¯ã€å…ˆé§†ã‘çš„ãªç ”ç©¶ã§ã‚ã‚‹PhiãŒã‚„ã¯ã‚Šåœ§å€’çš„?<br><img src="https://github.com/user-attachments/assets/c38286df-37c1-4c72-832f-676832845c0e" alt="image" loading="lazy"></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need, Suriya Gunasekar+, N/A, arXiv'23</a>
<br><br>ã‚‚å‚ç…§ã®ã“ã¨</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2024-11-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1539" target="_blank" rel="noopener noreferrer" class="title-link">On the Way to LLM Personalization: Learning to Remember User  Conversations, Lucie Charlotte Magister+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã‚’éå»ã®ä¼šè©±ã®çŸ¥è­˜ã‚’æ³¨å…¥ã™ã‚‹ã“ã¨ã§å®Ÿç¾ã™ã‚‹ãŸã‚ã€PLUMã¨ã„ã†ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ææ¡ˆã€‚ä¼šè©±ã®æ™‚é–“çš„é€£ç¶šæ€§ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡ã‚’è€ƒæ…®ã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã€‚åˆã‚ã¦ã®è©¦ã¿ã§ã‚ã‚ŠãªãŒã‚‰ã€RAGãªã©ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ç«¶äº‰åŠ›ã‚’æŒã¡ã€81.5%ã®ç²¾åº¦ã‚’é”æˆã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1530" target="_blank" rel="noopener noreferrer" class="title-link">Likelihood as a Performance Gauge for Retrieval-Augmented Generation, Tianyu Liu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸæƒ…å ±æ¤œç´¢å¼·åŒ–ç”Ÿæˆã¯ã€æ–‡è„ˆå†…ã®æ–‡æ›¸ã®é †åºã«å½±éŸ¿ã‚’å—ã‘ã‚„ã™ã„ã€‚ç ”ç©¶ã§ã¯ã€è³ªå•ã®ç¢ºç‡ãŒãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’åˆ†æã—ã€æ­£ç¢ºæ€§ã¨ã®ç›¸é–¢é–¢ä¿‚ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚è³ªå•ã®ç¢ºç‡ã‚’æŒ‡æ¨™ã¨ã—ã¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é¸æŠã¨æ§‹ç¯‰ã«é–¢ã™ã‚‹2ã¤ã®æ–¹æ³•ã‚’ææ¡ˆã—ã€ãã®åŠ¹æœã‚’å®Ÿè¨¼ã€‚ç¢ºç‡ã«åŸºã¥ãæ‰‹æ³•ã¯åŠ¹ç‡çš„ã§ã€å°‘ãªã„ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ã§å¿œç­”ã‚’ç”Ÿæˆã§ãã‚‹ãŸã‚ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã®æ–°ãŸãªæ–¹å‘æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã®å¹³å‡å€¤ã‚’ã¨ã£ãŸç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã®å¯¾æ•°å°¤åº¦ã¨ã€RAGã®å›ç­”æ€§èƒ½ã«é–¢ã™ã‚‹åˆ†æã‚’ã—ãŸæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/ac03c0b6-b16c-4992-8446-2f56bad09ab2" alt="image" loading="lazy"><br><br>ã¨ã‚Šã‚ãˆãšã€ã‚‚ã—ã€ŒLLMã¨ã—ã¦GPTã‚’ï¼ˆOpenAIã®APIã‚’ç”¨ã„ã¦ï¼‰ä½¿ã„ã¾ã—ãŸï¼temperatureã¯0ã§ã™ï¼ã€ã¿ãŸã„ãªå®Ÿé¨“è¨­å®šã ã£ãŸã‚‰è«¸ã€…æ€ªã—ããªã‚‹æ°—ãŒã—ãŸã®ã§ãã“ãŒå¤§ä¸ˆå¤«ãªã“ã¨ã‚’ç¢ºèªã—ãŸï¼ˆOpenLLMã€ã‹ã¤deterministicãªãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ–¹æ³•ãŒæœ›ã¾ã—ã„ï¼‰ã€‚ãŠã‚‚ã—ã‚ãã†ã€‚<br><br><img src="https://github.com/user-attachments/assets/9ba2bdc7-f6e5-4b9c-aca4-3d461c78a046" alt="image" loading="lazy"></p>
<p>å‚è€ƒ: [RAGã®ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’å°¤åº¦ã§é˜²ã, sasakuna, 2024.11.19](


<a href="https://zenn.dev/knowledgesense/articles/7c47e1796e96c0)" target="_blank" rel="noopener noreferrer">https://zenn.dev/knowledgesense/articles/7c47e1796e96c0)</a>


</p>
<p>
<strong>## å‚è€ƒ<br><br>ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®å°¤åº¦ã‚’ç”¨ã„ã¦ã€ã©ã®ç¨‹åº¦æ­£è§£ã‚‰ã—ã„ã‹ã‚’åˆ¤æ–­ã™ã‚‹ã€ã¨ã„ã£ãŸè©±ã¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1223" target="_blank" rel="noopener noreferrer">G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment, Yang Liu+, N/A, EMNLP'23</a>
</strong>
<br>
<br><br>ã®ã‚ˆã†ãªLLM-as-a-Judgeã§ã‚‚è¡Œã‚ã‚Œã¦ã„ã‚‹ã€‚<br><br>G-Evalã§ã¯1--5ã®ã‚¹ã‚³ã‚¢ã®ã‚ˆã†ãªé›¢æ•£çš„ãªå€¤ã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€ã“ã‚Œã‚‰ã‚’é€£ç¶šçš„ãªã‚¹ã‚³ã‚¢ã«è£œæ­£ã™ã‚‹ãŸã‚ã«ã€å°¤åº¦ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆç¢ºç‡ï¼‰ã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚<br>ãŸã ã—ã€G-Evalã®å ´åˆã¯å®Ÿé¨“ã§GPTã‚’ç”¨ã„ã¦ã„ã‚‹ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç›´æ¥å°¤åº¦ã‚’å–å¾—ã§ããšã€ä»£ã‚ã‚Šã«temperature1ã¨ã—ã€20å›ç¨‹åº¦ç”Ÿæˆã‚’è¡Œã£ãŸçµæœã‹ã‚‰ã‚¹ã‚³ã‚¢ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆç¢ºç‡ã‚’æ“¬ä¼¼çš„ã«è¨ˆç®—ã—ã¦ã„ã‚‹ã€‚<br><br>G-Evalã®è¨­å®šã¨æ¯”è¼ƒã™ã‚‹ã¨ï¼ˆå½“æ™‚ã¯ã¤ã‚ˆã¤ã‚ˆãªOpenLLMãŒãªã‹ã£ãŸãŸã‚è‹¦è‚‰ã®ç­–ã ã£ãŸã¨æ€ã‚ã‚Œã‚‹ãŒï¼‰ã€ã“ã¡ã‚‰ã®ç ”ç©¶ã®å®Ÿé¨“è¨­å®šã®æ–¹ãŒæœ›ã¾ã—ã„ã¨æ€ã†ã€‚</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<span class="issue_date">Issue Date: 2024-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1529" target="_blank" rel="noopener noreferrer" class="title-link">Multilingual Large Language Models: A Systematic Survey, Shaolin Zhu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã¯ã€å¤šè¨€èªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆMLLMsï¼‰ã®æœ€æ–°ç ”ç©¶ã‚’èª¿æŸ»ã—ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„äº‹å‰å­¦ç¿’ã®ç›®çš„ã€å¤šè¨€èªèƒ½åŠ›ã®è¦ç´ ã‚’è«–ã˜ã‚‹ã€‚ãƒ‡ãƒ¼ã‚¿ã®è³ªã¨å¤šæ§˜æ€§ãŒæ€§èƒ½å‘ä¸Šã«é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’å¼·èª¿ã—ã€MLLMã®è©•ä¾¡æ–¹æ³•ã‚„ã‚¯ãƒ­ã‚¹ãƒªãƒ³ã‚¬ãƒ«çŸ¥è­˜ã€å®‰å…¨æ€§ã€è§£é‡ˆå¯èƒ½æ€§ã«ã¤ã„ã¦è©³ç´°ãªåˆ†é¡æ³•ã‚’æç¤ºã€‚ã•ã‚‰ã«ã€MLLMã®å®Ÿä¸–ç•Œã§ã®å¿œç”¨ã‚’å¤šæ§˜ãªåˆ†é‡ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€èª²é¡Œã¨æ©Ÿä¼šã‚’å¼·èª¿ã™ã‚‹ã€‚é–¢é€£è«–æ–‡ã¯æŒ‡å®šã®ãƒªãƒ³ã‚¯ã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/0b86445f-b974-459c-94f0-a80f5e2bbc9a" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/0d03af89-23b0-4b4b-972a-bbe4320d4f0c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2024-11-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1524" target="_blank" rel="noopener noreferrer" class="title-link">Balancing Speed and Stability: The Trade-offs of FP8 vs. BF16 Training  in LLMs, Kazuki Fujii+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€ãã®è¨€èªç†è§£èƒ½åŠ›ã¨é©ç”¨å¯èƒ½æ€§ã‹ã‚‰æ³¨ç›®ã‚’é›†ã‚ã¦ãŠã‚Šã€ç‰¹ã«Llama 3ã‚·ãƒªãƒ¼ã‚ºã¯4050å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŠ¹ç‡åŒ–ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ä¸­ã€NVIDIAã®H100 GPUã¯FP8ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å°å…¥ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“ã‚’çŸ­ç¸®ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚åˆæœŸç ”ç©¶ã§ã¯FP8ãŒæ€§èƒ½ã‚’æãªã‚ãšã«åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¦ã„ã‚‹ãŒã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®‰å®šæ€§ã‚„ä¸‹æµã‚¿ã‚¹ã‚¯ã¸ã®å½±éŸ¿ã¯ã¾ã ä¸æ˜ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã¯ã€LLMsã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹BF16ã¨FP8ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ¢ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1857639065421754525?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>FP8ã§ç¶™ç¶šçš„äº‹å‰å­¦ç¿’ã‚’ã™ã‚‹ã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¯å‘ä¸Šã™ã‚‹ãŒã€lossã®ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’ç”Ÿã˜ãŸã‚Šã€downstreamã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ãŒBF16ã‚ˆã‚Šã‚‚ä½ä¸‹ã—ãŸã‚Šã™ã‚‹ï¼ˆæ—¥æœ¬èªã¨è‹±èªã®ä¸¡æ–¹ï¼‰ã¨ã®å ±å‘Šã®ã‚ˆã†ã§ã‚ã‚‹ã€‚ç¾çŠ¶ã‚¢ãƒ–ã‚¹ãƒˆã¨ä»˜éŒ²ã—ã‹è¨˜è¼‰ãŒãªã„ãŒã€å†…å®¹ã¯ã“ã‚Œã‹ã‚‰æ›´æ–°ã•ã‚Œã‚‹ã®ã ã‚ã†ã‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/8d60d59b-de00-483a-bff0-04a4145715c1" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2024-11-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1523" target="_blank" rel="noopener noreferrer" class="title-link">Understanding LLMs: A Comprehensive Overview from Training to Inference, Yiheng Liu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ChatGPTã®æ™®åŠã«ä¼´ã„ã€LLMsã®ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®è‰¯ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã¸ã®é–¢å¿ƒãŒé«˜ã¾ã£ã¦ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€LLMsã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æŠ€è¡“ã¨æ¨è«–ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæŠ€è¡“ã®é€²åŒ–ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚„ãƒ¢ãƒ‡ãƒ«åœ§ç¸®ãªã©ã®ã•ã¾ã–ã¾ãªå´é¢ã‚’è­°è«–ã™ã‚‹ã€‚ã¾ãŸã€LLMsã®åˆ©ç”¨æ–¹æ³•ã¨å°†æ¥ã®ç™ºå±•ã«ã¤ã„ã¦ã®æ´å¯Ÿã‚‚æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>[Perplexityï¼ˆå‚è€ƒ;Hallucinationã«æ³¨æ„ï¼‰](


<a href="https://www.perplexity.ai/search/yi-xia-nolun-wen-wodu-minei-ro-7vGwDK_AQX.HDO7j9H8iNA)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/search/yi-xia-nolun-wen-wodu-minei-ro-7vGwDK_AQX.HDO7j9H8iNA)</a>


</p>
<p>å˜ãªã‚‹LLMã®ç†è«–çš„ãªèª¬æ˜ã«ã¨ã©ã¾ã‚‰ãšã€å®Ÿç”¨çš„ã«å¿…è¦ãªå„ç¨®ä¸¦åˆ—å‡¦ç†æŠ€è¡“ã€Mixed Precisionã€Offloadingãªã©ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚‚ã¾ã¨ã¾ã£ã¦ã„ã‚‹ã®ãŒã¨ã¦ã‚‚è‰¯ã„ã¨æ€ã†ã€‚</p>
<p>LLM Frameworkã®ã¨ã“ã‚ã«ã€ãƒ¡ã‚¸ãƒ£ãƒ¼ãªã‚‚ã®ãŒç¶²ç¾…ã•ã‚Œã¦ã„ãªã„ã‚ˆã†ã«æ„Ÿã˜ã‚‹ã€‚ãŸã¨ãˆã°ã€Unslothã‚„Liger-Kernelãªã©ã¯Transformersã®éƒ¨åˆ†ã§è¨€åŠã•ã‚Œã¦ã¦ã‚‚è‰¯ã„ã®ã§ã¯ã€ã¨æ„Ÿã˜ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2024-11-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1522" target="_blank" rel="noopener noreferrer" class="title-link">The Geometry of Concepts: Sparse Autoencoder Feature Structure, Yuxiao Li+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ã€é«˜æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ã®è¾æ›¸ã‚’ç”Ÿæˆã—ã€æ¦‚å¿µã®å®‡å®™ã«ä¸‰ã¤ã®èˆˆå‘³æ·±ã„æ§‹é€ ã‚’ç™ºè¦‹ã—ãŸã€‚1) å°è¦æ¨¡æ§‹é€ ã§ã¯ã€å¹³è¡Œå››è¾ºå½¢ã‚„å°å½¢ã®ã€Œçµæ™¶ã€ãŒã‚ã‚Šã€å˜èªã®é•·ã•ãªã©ã®å¹²æ¸‰ã‚’é™¤å»ã™ã‚‹ã“ã¨ã§è³ªãŒæ”¹å–„ã•ã‚Œã‚‹ã€‚2) ä¸­è¦æ¨¡æ§‹é€ ã§ã¯ã€æ•°å­¦ã¨ã‚³ãƒ¼ãƒ‰ã®ç‰¹å¾´ãŒã€Œè‘‰ã€ã‚’å½¢æˆã—ã€ç©ºé–“çš„å±€æ‰€æ€§ãŒå®šé‡åŒ–ã•ã‚Œã€ç‰¹å¾´ãŒäºˆæƒ³ä»¥ä¸Šã«é›†ã¾ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚3) å¤§è¦æ¨¡æ§‹é€ ã§ã¯ã€ç‰¹å¾´ç‚¹é›²ãŒå„å‘åŒæ€§ã§ãªãã€å›ºæœ‰å€¤ã®ã¹ãæ³•å‰‡ã‚’æŒã¡ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒå±¤ã«ä¾å­˜ã™ã‚‹ã“ã¨ãŒå®šé‡åŒ–ã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 


<a href="https://ledge.ai/articles/llm_conceptual_structure_sae" target="_blank" rel="noopener noreferrer">https://ledge.ai/articles/llm_conceptual_structure_sae</a>


</p>
<p>[Perplexityï¼ˆå‚è€ƒ;Hallucinationã«æ³¨æ„ï¼‰](


<a href="https://www.perplexity.ai/search/yi-xia-nolun-wen-wodu-minei-ro-kR626A9_R8.6CU7IKvGyhQ)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/search/yi-xia-nolun-wen-wodu-minei-ro-kR626A9_R8.6CU7IKvGyhQ)</a>


</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/RelevanceJudgment.html" target="_blank" rel="noopener noreferrer">#RelevanceJudgment</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2024-11-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1517" target="_blank" rel="noopener noreferrer" class="title-link">A Large-Scale Study of Relevance Assessments with Large Language Models:  An Initial Look, Shivani Upadhyay+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€TREC 2024 RAG Trackã«ãŠã‘ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã‚’ç”¨ã„ãŸé–¢é€£æ€§è©•ä¾¡ã®çµæœã‚’å ±å‘Šã€‚UMBRELAãƒ„ãƒ¼ãƒ«ã‚’æ´»ç”¨ã—ãŸè‡ªå‹•ç”Ÿæˆè©•ä¾¡ã¨å¾“æ¥ã®æ‰‹å‹•è©•ä¾¡ã®ç›¸é–¢ã‚’åˆ†æã—ã€77ã®å®Ÿè¡Œã‚»ãƒƒãƒˆã«ãŠã„ã¦é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ãŸã€‚LLMã®æ”¯æ´ã¯æ‰‹å‹•è©•ä¾¡ã¨ã®ç›¸é–¢ã‚’é«˜ã‚ãšã€äººé–“è©•ä¾¡è€…ã®æ–¹ãŒå³æ ¼ã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚ŒãŸã€‚ã“ã®ç ”ç©¶ã¯ã€TRECã‚¹ã‚¿ã‚¤ãƒ«ã®è©•ä¾¡ã«ãŠã‘ã‚‹LLMã®ä½¿ç”¨ã‚’æ¤œè¨¼ã—ã€ä»Šå¾Œã®ç ”ç©¶ã®åŸºç›¤ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lintool/status/1856876816197165188?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>[Perplexityï¼ˆå‚è€ƒ;Hallucinationã«æ³¨æ„ï¼‰](


<a href="https://www.perplexity.ai/search/yi-xia-nolun-wen-wodu-ntenei-r-h3qlECirT3G9O2BGk765_g)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/search/yi-xia-nolun-wen-wodu-ntenei-r-h3qlECirT3G9O2BGk765_g)</a>


<br><br>Perplexityã®ç”Ÿæˆçµæœã§ã¯ã€27å€‹ã®ã‚·ã‚¹ãƒ†ãƒ ã¨è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ãŒã€ã“ã‚Œã¯å®Ÿéš›ã¯ãƒˆãƒ”ãƒƒã‚¯ã§ã€å„ãƒˆãƒ”ãƒƒã‚¯ã”ã¨ã«300ä»¶ç¨‹åº¦ã®0--3ã®Relevance ScoreãŒã€äººæ‰‹è©•ä¾¡ã€UMBRELAå…±ã«ä»˜ä¸ã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ï¼ˆTable1ï¼‰ã€‚<br><br><img src="https://github.com/user-attachments/assets/73bda88a-0f94-4562-8d04-dc0d93fc9287" alt="image" loading="lazy"><br><br>è©•ä¾¡çµæœ<br><br>- Fully Manual Assessment: æ—¢å­˜ã®NIST methodologyã¨åŒæ§˜ã«äººæ‰‹ã§Relevance Scoreã‚’ä»˜ä¸ã™ã‚‹æ–¹æ³•<br>- Manual Aspessment with Filtering: LLMã®non-Relevantã¨åˆ¤æ–­ã—ãŸpassageã‚’äººæ‰‹è©•ä¾¡ã‹ã‚‰é™¤å¤–ã™ã‚‹æ–¹æ³•<br>- Manual Post-Editing of Automatic Assessment: LLMãŒnon-Relevantã¨åˆ¤æ–­ã—ãŸpassageã‚’äººæ‰‹è©•ä¾¡ã‹ã‚‰é™¤å¤–ã™ã‚‹ã ã‘ã§ãªãã€LLMãŒä»˜ä¸ã—ãŸã‚¹ã‚³ã‚¢ã‚’è©•ä¾¡è€…ã«ã‚‚è¦‹ã›ã€è©•ä¾¡è€…ãŒå½“è©²ãƒ©ãƒ™ãƒ«ã‚’ä¿®æ­£ã™ã‚‹ã‚ˆã†ãªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹<br>- Fully Automatic Assessment:UMBRELAã«ã‚ˆã‚‹Relevance Scoreã‚’ãã®ã¾ã¾åˆ©ç”¨ã™ã‚‹æ–¹æ³•<br><br>LLMã¯GPT4-oã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/ffc63d2c-d677-46b7-9909-95423ccf476d" alt="image" loading="lazy"><br><br>19ãƒãƒ¼ãƒ ã®77å€‹ã®RunãŒã©ã®ã‚ˆã†ã«å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã‹ã€ãã‚ŒãŒTable1ã®çµ±è¨ˆé‡ã¨ã©ã†é–¢ä¿‚ã—ã¦ã„ã‚‹ã‹ãŒã¾ã ã¡ã‚‡ã£ã¨ã‚ˆãã‚ã‹ã£ã¦ã„ãªã„ã€‚</p>
<p>UMBRELAã§Relevance Scoreã‚’ç”Ÿæˆã™ã‚‹éš›ã«åˆ©ç”¨ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚<br><img src="https://github.com/user-attachments/assets/4350430b-fa37-4854-8cb4-114b2f0abf84" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1516" target="_blank" rel="noopener noreferrer" class="title-link">Language Models are Hidden Reasoners: Unlocking Latent Reasoning  Capabilities via Self-Rewarding, Haolin Chen+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LaTROï¼ˆLaTent Reasoning Optimizationï¼‰ã‚’ææ¡ˆã—ã€LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã€‚æ¨è«–ã‚’æ½œåœ¨åˆ†å¸ƒã‹ã‚‰ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¨ã—ã¦å®šå¼åŒ–ã—ã€å¤–éƒ¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãªã—ã§æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã¨è³ªã‚’åŒæ™‚ã«æ”¹å–„ã€‚GSM8KãŠã‚ˆã³ARC-Challengeãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å®Ÿé¨“ã—ã€å¹³å‡12.5%ã®ç²¾åº¦å‘ä¸Šã‚’é”æˆã€‚äº‹å‰å­¦ç¿’ã•ã‚ŒãŸLLMã®æ½œåœ¨çš„ãªæ¨è«–èƒ½åŠ›ã‚’å¼•ãå‡ºã™ã“ã¨ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haolinchen11/status/1856150958772040165?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=4Po8d9GAfQ&referrer=%5Bthe%20profile%20of%20Ricky%20Ho%5D(%2Fprofile%3Fid%3D~Ricky_Ho2)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=4Po8d9GAfQ&referrer=%5Bthe%20profile%20of%20Ricky%20Ho%5D(%2Fprofile%3Fid%3D~Ricky_Ho2)</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2024-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1509" target="_blank" rel="noopener noreferrer" class="title-link">A Theoretical Understanding of Chain-of-Thought: Coherent Reasoning and  Error-Aware Demonstration, Yingqian Cui+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Few-shot Chain-of-Thought (CoT) ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã¯LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€å¾“æ¥ã®ç ”ç©¶ã¯æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’åˆ†é›¢ã•ã‚ŒãŸæ–‡è„ˆå†…å­¦ç¿’ã«ä¾å­˜ã—ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€åˆæœŸã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰ã®ä¸€è²«ã—ãŸæ¨è«–ï¼ˆCoherent CoTï¼‰ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®ã‚¨ãƒ©ãƒ¼ä¿®æ­£èƒ½åŠ›ã¨äºˆæ¸¬ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç†è«–çš„ã«ç¤ºã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æ­£ã—ã„æ¨è«–çµŒè·¯ã¨èª¤ã£ãŸæ¨è«–çµŒè·¯ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§CoTã‚’æ”¹å–„ã™ã‚‹ææ¡ˆã®æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1855926845855699311?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãŠã‚‚ã—ã‚ãã†ãªç ”ç©¶</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Subword.html" target="_blank" rel="noopener noreferrer">#Subword</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<span class="issue_date">Issue Date: 2024-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1507" target="_blank" rel="noopener noreferrer" class="title-link">LBPE: Long-token-first Tokenization to Improve Large Language Models, Haoran Lian+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LBPEã¯ã€é•·ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å„ªå…ˆã™ã‚‹æ–°ã—ã„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã§ã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãŠã‘ã‚‹å­¦ç¿’ã®ä¸å‡è¡¡ã‚’è»½æ¸›ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€LBPEã¯å¾“æ¥ã®BPEã‚’ä¸€è²«ã—ã¦ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>BPEã¨ã¯ç•°ãªã‚Šãƒˆãƒ¼ã‚¯ãƒ³ã®é•·ã•ã‚’å„ªå…ˆã—ã¦ãƒãƒ¼ã‚¸ã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§ã€æœ€çµ‚çš„ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ±ºå®šã™ã‚‹æ‰‹æ³•ã§ã€<br><img src="https://github.com/user-attachments/assets/99b91472-88d8-4792-bf04-acc67956e4f5" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/99103316-bd1c-448d-b52a-5db815298e7e" alt="image" loading="lazy"><br><br>BPEã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã—ã€<br><img src="https://github.com/user-attachments/assets/c7dccf00-b9c2-4739-82f3-4f8eeacd4fc7" alt="image" loading="lazy"><br><br>ãƒˆãƒ¼ã‚¯ãƒ³ã®é•·ã•ãŒBPEã¨æ¯”è¼ƒã—ã¦é•·ããªã‚Šã€ã‹ã¤5Bãƒˆãƒ¼ã‚¯ãƒ³ç¨‹åº¦ã‚’æ—¢å­˜ã®BPEã§äº‹å‰å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ç¶™ç¶šçš„äº‹å‰å­¦ç¿’ã™ã‚‹ã ã‘ã§æ€§èƒ½ã‚’ä¸Šå›ã‚‹ã‚ˆã†ã«ã§ãã€<br><img src="https://github.com/user-attachments/assets/10f4ff2e-1d49-4c8a-87ec-67466bdce2f0" alt="image" loading="lazy"><br><br>åŒã˜Vocabã‚µã‚¤ã‚ºã§BPEã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã§ãã‚‹æ‰‹æ³•<br><img src="https://github.com/user-attachments/assets/5e19fc11-10f6-467a-ae06-8fb62b5f0a65" alt="image" loading="lazy"><br><br>ã‚‰ã—ã„</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<a class="button" href="articles/Investigation.html" target="_blank" rel="noopener noreferrer">#Investigation</a>
<span class="issue_date">Issue Date: 2024-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1506" target="_blank" rel="noopener noreferrer" class="title-link">LLMs as Research Tools: A Large Scale Survey of Researchers' Usage and  Perceptions, Zhehui Liao+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®åˆ©ç”¨ã«é–¢ã™ã‚‹816äººã®ç ”ç©¶è€…ã‚’å¯¾è±¡ã¨ã—ãŸèª¿æŸ»ã‚’å®Ÿæ–½ã€‚81%ãŒç ”ç©¶ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«LLMsã‚’çµ„ã¿è¾¼ã‚“ã§ãŠã‚Šã€ç‰¹ã«éç™½äººã‚„è‹¥æ‰‹ç ”ç©¶è€…ãŒé«˜ã„ä½¿ç”¨ç‡ã‚’ç¤ºã™ä¸€æ–¹ã§ã€å¥³æ€§ã‚„ã‚·ãƒ‹ã‚¢ç ”ç©¶è€…ã¯å€«ç†çš„æ‡¸å¿µã‚’æŠ±ã„ã¦ã„ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚ç ”ç©¶ã®å…¬å¹³æ€§å‘ä¸Šã®å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚</span>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2024-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1504" target="_blank" rel="noopener noreferrer" class="title-link">DELIFT: Data Efficient Language model Instruction Fine Tuning, Ishika Agarwal+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- DELIFTã¨ã„ã†æ–°ã—ã„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®å„ã‚¹ãƒ†ãƒ¼ã‚¸ã§ãƒ‡ãƒ¼ã‚¿é¸æŠã‚’æœ€é©åŒ–ã€‚ãƒšã‚¢ãƒ¯ã‚¤ã‚ºãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ç”¨ã„ã¦ãƒ‡ãƒ¼ã‚¿ã®æœ‰ç›Šæ€§ã‚’å®šé‡åŒ–ã—ã€æœ€å¤§70%ã®ãƒ‡ãƒ¼ã‚¿å‰Šæ¸›ã‚’å®Ÿç¾ã€‚è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å¤§å¹…ã«ç¯€ç´„ã—ã€æ—¢å­˜ã®æ–¹æ³•ã‚’ä¸Šå›ã‚‹åŠ¹ç‡æ€§ã¨åŠ¹æœã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2024-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1503" target="_blank" rel="noopener noreferrer" class="title-link">GUI Agents with Foundation Models: A Comprehensive Survey, Shuai Wang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- (M)LLMã‚’æ´»ç”¨ã—ãŸGUIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç ”ç©¶ã‚’çµ±åˆã—ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®é©æ–°ã‚’å¼·èª¿ã€‚é‡è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ã¾ã¨ã‚ãŸçµ±ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€å•†æ¥­ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¢æ±‚ã€‚èª²é¡Œã‚’ç‰¹å®šã—ã€ä»Šå¾Œã®ç ”ç©¶æ–¹å‘ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/999adca8-f0d7-483c-ae5a-b6f78fe9da4b" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/b69dc991-3e15-4965-a183-cc7909ad9eba" alt="image" loading="lazy"></p>
<p>Referenceã‚„ãƒšãƒ¼ã‚¸æ•°ã¯ã‚µãƒ¼ãƒ™ã‚¤ã«ã—ã¦ã¯å°‘ãªã‚ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2024-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1501" target="_blank" rel="noopener noreferrer" class="title-link">Scaling LLM Test-Time Compute Optimally can be More Effective than  Scaling Model Parameters, Charlie Snell+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®æ¨è«–æ™‚ã®è¨ˆç®—ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€æŒ‘æˆ¦çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•ã‚’ç ”ç©¶ã€‚ç‰¹ã«ã€å¯†ãªãƒ—ãƒ­ã‚»ã‚¹ãƒ™ãƒ¼ã‚¹ã®æ¤œè¨¼è€…å ±é…¬ãƒ¢ãƒ‡ãƒ«ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¿œã˜ãŸå¿œç­”ã®é©å¿œçš„æ›´æ–°ã‚’åˆ†æã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é›£æ˜“åº¦ã«ã‚ˆã£ã¦åŠ¹æœãŒå¤‰åŒ–ã—ã€è¨ˆç®—æœ€é©æˆ¦ç•¥ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§åŠ¹ç‡ã‚’4å€ä»¥ä¸Šå‘ä¸Šã€‚ã•ã‚‰ã«ã€ãƒ†ã‚¹ãƒˆæ™‚è¨ˆç®—ã‚’ç”¨ã„ã‚‹ã“ã¨ã§å°ã•ãªãƒ¢ãƒ‡ãƒ«ãŒå¤§ããªãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/0562a65e-b2f1-4ff4-b806-107313fc255e" alt="image" loading="lazy"></p>
<p>[Perplexityï¼ˆå‚è€ƒ;Hallucinationã«æ³¨æ„ï¼‰](


<a href="https://www.perplexity.ai/search/yi-xia-noyan-jiu-wodu-mi-nei-r-1e1euXgLTH.G0Wlp.V2iqA)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/search/yi-xia-noyan-jiu-wodu-mi-nei-r-1e1euXgLTH.G0Wlp.V2iqA)</a>


</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-11-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1497" target="_blank" rel="noopener noreferrer" class="title-link">HyQE: Ranking Contexts with Hypothetical Query Embeddings, Weichao Zhou+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒªãƒˆãƒªãƒ¼ãƒãƒ«æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ã€LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¿…è¦ã¨ã›ãšã€åŸ‹ã‚è¾¼ã¿ã®é¡ä¼¼æ€§ã¨LLMã®èƒ½åŠ›ã‚’çµ„ã¿åˆã‚ã›ãŸã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã«åŸºã¥ã„ã¦ä»®å®šã•ã‚ŒãŸã‚¯ã‚¨ãƒªã¨ã®é¡ä¼¼æ€§ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å†é †ä½ä»˜ã‘ã—ã€æ¨è«–æ™‚ã«åŠ¹ç‡çš„ã§ä»–ã®æŠ€è¡“ã¨ã‚‚äº’æ›æ€§ãŒã‚ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆæ‰‹æ³•ãŒãƒ©ãƒ³ã‚­ãƒ³ã‚°æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1498" target="_blank" rel="noopener noreferrer">Precise Zero-Shot Dense Retrieval without Relevance Labels, Luyu Gao+, ACL'23</a>
 ã‚‚å‚ç…§ã®ã“ã¨ã€‚<br><br><br><br>ä¸‹è¨˜ã«è©¦ã—ã«HyQEã¨HyDEã®æ¯”è¼ƒã®è¨˜äº‹ã‚’ä½œæˆã—ãŸã®ã§ã”å‚è€ƒã¾ã§ã«ï¼ˆè¨˜äº‹ã®å†…å®¹ã«ç§ã¯æ‰‹ã‚’åŠ ãˆã¦ã„ãªã„ã®ã§Hallucinationã«æ³¨æ„ï¼‰ã€‚ã–ã£ãã‚Šã„ã†ã¨HyDEã¯pseudo documentsã‚’ä½¿ã†ãŒã€HyQEã¯pseudo queryã‚’æ‰±ã†ã€‚<br><br><br><br>[å‚è€ƒ: Perplexity Pagesã§ä½œæˆã—ãŸHyDEã¨ã®ç°¡å˜ãªæ¯”è¼ƒã®è¦ç´„](


<a href="https://www.perplexity.ai/page/hyqelun-wen-nofen-xi-toyao-yue-aqZZj8mDQg6NL1iKml7.eQ)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/page/hyqelun-wen-nofen-xi-toyao-yue-aqZZj8mDQg6NL1iKml7.eQ)</a>


</p>
<p><img src="https://github.com/user-attachments/assets/f757781c-036c-440d-b1b8-c5f255039479" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2024-11-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1496" target="_blank" rel="noopener noreferrer" class="title-link">Personalization of Large Language Models: A Survey, Zhehao Zhang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã«é–¢ã™ã‚‹ç ”ç©¶ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸLLMsã®åˆ†é¡æ³•ã‚’ææ¡ˆã€‚ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã®æ¦‚å¿µã‚’çµ±åˆã—ã€æ–°ãŸãªå´é¢ã‚„è¦ä»¶ã‚’å®šç¾©ã€‚ç²’åº¦ã€æŠ€è¡“ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€è©•ä¾¡æ–¹æ³•ã«åŸºã¥ãä½“ç³»çš„ãªåˆ†é¡ã‚’è¡Œã„ã€æ–‡çŒ®ã‚’çµ±ä¸€ã€‚æœªè§£æ±ºã®èª²é¡Œã‚’å¼·èª¿ã—ã€ç ”ç©¶è€…ã¨å®Ÿå‹™è€…ã¸ã®æ˜ç¢ºãªã‚¬ã‚¤ãƒ‰ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/NumericReasoning.html" target="_blank" rel="noopener noreferrer">#NumericReasoning</a>
<span class="issue_date">Issue Date: 2024-11-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1495" target="_blank" rel="noopener noreferrer" class="title-link">Number Cookbook: Number Understanding of Language Models and How to  Improve It, Haotong Yang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ•°å€¤ç†è§£ãŠã‚ˆã³å‡¦ç†èƒ½åŠ›ï¼ˆNUPAï¼‰ã‚’èª¿æŸ»ã—ã€41ã®æ•°å€¤ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã€‚å¤šãã®ã‚¿ã‚¹ã‚¯ã§LLMsãŒå¤±æ•—ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€NUPAå‘ä¸Šã®ãŸã‚ã®æŠ€è¡“ã‚’ç”¨ã„ã¦å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚ŠNUPAãŒæ”¹å–„ã•ã‚Œã‚‹ãŒã€ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ã«ã¯åŠ¹æœãŒãªã„ã“ã¨ãŒåˆ¤æ˜ã€‚æ€è€ƒã®é€£é–æŠ€è¡“ã®å½±éŸ¿ã‚‚æ¢æ±‚ã€‚ç ”ç©¶ã¯LLMsã®NUPAæ”¹å–„ã«å‘ã‘ãŸåˆæ­©çš„ãªã‚¹ãƒ†ãƒƒãƒ—ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã‚“ãƒ¼ã€abstã—ã‹èª­ã‚“ã§ã„ãªã„ã‘ã‚Œã©ã‚‚ã€9.11 &gt; 9.9 ã«ã¤ã„ã¦ã¯ã€ã“ã®ã‚ˆã†ãªæ•°å­—ã«æ…£ã‚Œè¦ªã—ã‚“ã§ã„ã‚‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãªã©ã«å’„å—Ÿã«è³ªå•ã—ãŸã‚‰ã€ãƒŸã‚¹ã—ã¦ç­”ãˆã¡ã‚ƒã†äººã‚‚ã„ã‚‹ã®ã§ã¯ï¼Ÿã¨ã„ã†æ°—ãŒã™ã‚‹ï¼ˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¯è„³å†…ã§9.11 &gt; 9.9ã‚’ç¤ºã™ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã«è§¦ã‚Œã‚‹æ©Ÿä¼šãŒå¤šãã€ã“ã¡ã‚‰ã®å°¤åº¦ãŒé«˜ã„ï¼‰ã€‚<br><br>LLMãŒã“ã®ã‚ˆã†ãªãƒŸã‚¹ï¼ˆã¦ã‹ãã‚‚ãã‚‚ãƒŸã‚¹ã§ã¯ãªãã€å›ç­”ã™ã‚‹ãŸã‚ã®contextãŒè¶³ã‚Šã¦ãªã„ã®ã§æ­£è§£ãŒå®šç¾©ã§ããªã„ã ã‘ã€ã ã¨æ€ã†ãŒã€ã€ï¼‰ã‚’ã™ã‚‹ã®ã¯ã€å˜ã«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ãã†ã„ã£ãŸ9.11 &gt; 9.9ã¨ã—ã¦æ‰±ã†ã‚ˆã†ãªæ–‡è„ˆã‚„æ§‹é€ ã®ãƒ†ã‚­ã‚¹ãƒˆãŒå¤šãå­˜åœ¨ã—ã¦ãŠã‚Šã€ã“ã‚Œã‚‰ãƒ†ã‚­ã‚¹ãƒˆåˆ—ã®å°¤åº¦ãŒé«˜ããªã£ã¦ã“ã®ã‚ˆã†ãªç¾è±¡ãŒèµ·ãã¦ã„ã‚‹ã ã‘ãªã®ã§ã¯ã€ã¨ã„ã†æ°—ãŒã—ã¦ã„ã‚‹ã€‚<br><br>instructionã§æ³¨æ„ã‚’ä¿ƒã—ãŸã‚Šé©åˆ‡ã«å•é¡Œã‚’å®šç¾©ã—ãªã‘ã‚Œã°ã€ãã‚Šã‚ƒã“ã†ã„ã†çµæœã«ãªã£ã¦å½“ç„¶ã˜ã‚ƒãªã„?ã¨ã„ã†æ°—ãŒã—ã¦ã„ã‚‹ã€‚<br><br>ï¼ˆã“ã“ã¾ã§ã€Œæ°—ãŒã—ã¦ã„ã‚‹ã€ã‚’3é€£ç™ºã—ã¦ã—ã¾ã£ãŸâ€¦ğŸ˜…ï¼‰<br><br>ã¾ãŸã€æœ¬ç ”ç©¶ã§æ‰±ã£ã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ã®exampleã¯ä¸‹è¨˜ã®ã‚ˆã†ãªã‚‚ã®ã ãŒã€ã“ã‚Œã‚‰ã‚’LLMã«ã€ãªã‚“ã®ãƒ„ãƒ¼ãƒ«ã‚‚åˆ©ç”¨ã•ã›ãšautoregressiveãªç”Ÿæˆã®ã¿ã§è§£ã‹ã›ã‚‹ã¨ã„ã†ã®ã¯ã€äººé–“ã§ã„ã†ã¨ã“ã‚ã®æš—ç®—ã«ç›¸å½“ã™ã‚‹ã®ã§ã¯ï¼Ÿã¨å€‹äººçš„ã«ã¯æ€ã†ã€‚<br>ä½•ãŒè¨€ã„ãŸã„ã®ã‹ã¨ã„ã†ã¨ã€äººé–“ã§ã‚‚æš—ç®—ã§ã“ã‚Œã‚’ã‚„ã‚‰ã›ãŸã‚‰è§£ã‘ãªã„äººãŒã‹ãªã‚Šã„ã‚‹ã¨æ€ã†ï¼ˆã¨ã„ã†ã‹ç§è‡ªèº«å˜ç´”ãªåŠ ç®—ã§ã‚‚æ¡æ•°å¢—ãˆãŸã‚‰æš—ç®—ãªã©ç„¡ç†ï¼‰ã€‚<br>ä¸€æ–¹ã§æš—ç®—ã§ã¯ã§ããªã„ã‘ã©ã€é›»å“ã‚„ãƒ¡ãƒ¢æ›¸ãã€è¨ˆç®—æ©Ÿã‚’ä½¿ã£ã¦ã„ã„ã§ã™ã‚ˆã€ã¨ã„ã†ã“ã¨ã«ã—ãŸã‚‰å¤šãã®äººãŒã“ã‚Œã‚‰ã‚¿ã‚¹ã‚¯ã¯è§£ã‘ã‚‹ã‚ˆã†ã«ãªã‚‹ã¨æ€ã†ã®ã§ã€LLMã§ã‚‚åŒæ§˜ã®ã“ã¨ãŒèµ·ãã‚‹ã¨æ€ã†ã€‚<br><br>LLMã®æ•°å€¤æ¼”ç®—èƒ½åŠ›ã¯äººé–“ã®æš—ç®—ã®ã‚ˆã†ã«é™ç•ŒãŒã‚ã‚‹ã“ã¨ã‚’èªçŸ¥ã—ã€é‡‘èåˆ†é‡ãªã©ã®æ­£ç¢ºãªæ¼”ç®—ã‚„æ•°å€¤ã®å–ã‚Šæ‰±ã†ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã‚’ã•ã›ãŸã‹ã£ãŸã‚‰ã€é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã‚ã›ã¾ã—ã‚‡ã†ã­ã€ã¨ã„ã†è©±ãªã®ã‹ãªã‚ã¨æ€ã†ã€‚<br><br><img src="https://github.com/user-attachments/assets/0aa690d2-3835-4d32-b5d4-596b83a69674" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1854528742095458337?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ICLR25ã®OpenReviewã€‚ã“ã¡ã‚‰ã‚’èª­ã‚€ã¨èˆˆå‘³æ·±ã„ã€‚<br>


<a href="https://openreview.net/forum?id=BWS5gVjgeY" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=BWS5gVjgeY</a>


<br><br>å¹…åºƒã„æ•°å€¤æ¼”ç®—ã®ã‚¿ã‚¹ã‚¯ã‚’è©•ä¾¡ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰ã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ã®é–¢é€£æ€§ã‚’æ˜ã‚‰ã‹ã«ã—ãŸç‚¹ã€åˆ†æã ã‘ã§ã¯ãªãLLMã®æ•°å€¤æ¼”ç®—èƒ½åŠ›ã‚’æ”¹å–„ã—ãŸç‚¹ã¯è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br>ä¸€æ–¹ã§ã€å…¨ä½“çš„ã«ã€å…ˆè¡Œç ”ç©¶ã¨ã®æ¯”è¼ƒã‚„discussionãŒä¸è¶³ã—ã¦ãŠã‚Šã€ç ”ç©¶ã§å¾—ã‚‰ã‚ŒãŸçŸ¥è¦‹ãŒã©ã®ç¨‹åº¦æ–°è¦æ€§ãŒã‚ã‚‹ã®ã‹?ã¨ã„ã£ãŸç‚¹ã‚„ã€èª¬æ˜ãŒä¸ååˆ†ã§justificationãŒè¶³ã‚Šãªã„ã€ã¨ã„ã£ãŸè©±ãŒç›®ç«‹ã¤ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br>ç‰¹ã«ã€ãã‚‚ãã‚‚LoRAã‚„CoTã®å…ƒè«–æ–‡ã‚„ã€Numerical Reasoningã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ãŸå…ˆè¡Œç ”ç©¶ãŒã»ã¼å¼•ç”¨ã•ã‚Œã¦ã„ãªã„ã‚‰ã—ã„ç‚¹ãŒè¦‹å—ã‘ã‚‰ã‚Œã‚‹ã‚ˆã†ã§ã‚ã‚‹ã€‚ã•ã™ãŒã«ãã®è¾ºã¯å¼•ç”¨ã—ã¦ç ”ç©¶ã®contributionã‚’ã‚¯ãƒªã‚¢ã«ã—ãŸæ–¹ãŒã„ã„ã‚ˆã­ã€ã¨æ€ã†ãªã©ã—ãŸã€‚</p>
<p>&gt;I am unconvinced that numeracy in LLMs is a problem in need of a solution. First, surely there is a citable source for LLM inadequacy for numeracy. Second, even if they were terrible at numeracy, the onus is on the authors to convince the reader that this a problem worth caring about, for at least two obvious reasons: 1) all of these tasks are already trivially done by a calculator or a python program, and 2) commercially available LLMs can probably do alright at numerical tasks indirectly via code-generation and execution. As it stands, it reads as if the authors are insisting that this is a problem deserving of attention --- I'm sure it could be, but this argument can be better made.<br><br>ä¸Šè¨˜ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆã¨ç§ã‚‚åŒã˜ã“ã¨ã‚’æ„Ÿã˜ã‚‹ã€‚ãªãœLLMãã®ã‚‚ã®ã«æ•°å€¤æ¼”ç®—ã®èƒ½åŠ›ãŒãªã„ã“ã¨ãŒå•é¡Œãªã®ã‹?ã¨ã„ã†èª¬æ˜ãŒã‚ã£ãŸæ–¹ãŒè‰¯ã„ã®ã§ã¯ãªã„ã‹ã¨æ€ã†ã€‚<br><br>ã“ã‚Œã¯ç§ã®ä¸­ã§ã¯ã€è«–æ–‡ã®ã‚¤ãƒ³ãƒˆãƒ­ã§è¨€åŠã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªã‚·ãƒ³ãƒ—ãƒ«ãªã‚¿ã‚¹ã‚¯ã§ã¯ãªãã€<br>- inputã™ã‚‹contextã«å¤§é‡ã®æ•°å€¤ã‚’å…¥åŠ›ã—ãªã‘ã‚Œã°ãªã‚‰ãšã€<br>- ã‹ã¤contextä¸­ã®æ•°å€¤ã‚’å³å¯†ã«è§£é‡ˆã—ãªã‘ã‚Œã°ãªã‚‰ãšã€<br>- ã‹ã¤æƒ…å ±ã‚’è§£é‡ˆã™ã‚‹ãŸã‚ã«è¨ˆç®—ã™ã¹ãæ•°å¼ãŒcontextã§ä¸ãˆã‚‰ã‚ŒãŸæ•°å€¤ã«ã‚ˆã£ã¦å¤‰åŒ–ã™ã‚‹ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ï¼ˆãŸã¨ãˆã°ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã§è¨€åŠã™ã¹ãå†…å®¹ãŒgivenãªæ•°å€¤æƒ…å ±ã«ã‚ˆã£ã¦å¤‰ã‚ã‚‹ã‚ˆã†ãªã‚‚ã®ã€‚æœ€å¤§å€¤ã«è¨€åŠã™ã‚‹ã®ã‹ã€å¹³å‡å€¤ã‚’è¨€åŠã™ã‚‹ã®ã‹ã€æ•°å€¤ã¨ç´ã¥ã‘ã‚‰ã‚ŒãŸç‰¹å®šã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«è¨€åŠã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã®ã‹ã€ãªã©ï¼‰<br><br>ï¼ˆe.g. ä¸Šè¨˜ã‚’æº€ãŸã™ã‚¿ã‚¹ã‚¯ã¯ãŸã¨ãˆã°ã€é‡‘èé–¢ä¿‚ã®data-to-textãªã©ï¼‰ã§ã¯ã€LLMãŒæ•°å€¤ã‚’è§£é‡ˆã§ããªã„ã¨å›°ã‚‹ã¨æ€ã†ã€‚ãã†ã„ã£ãŸèª¬æ˜ãŒå…¥ã£ãŸæ–¹ãŒè‰¯ã„ã¨æ€ã†ãªã‚ã€æ„Ÿã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2024-11-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1492" target="_blank" rel="noopener noreferrer" class="title-link">LoRA vs Full Fine-tuning: An Illusion of Equivalence, Reece Shuttleworth+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã®é•ã„ãŒäº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’ã€é‡ã¿è¡Œåˆ—ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹æ€§ã‚’é€šã˜ã¦åˆ†æã€‚LoRAã¨å®Œå…¨ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ç•°ãªã‚‹æ§‹é€ ã®é‡ã¿è¡Œåˆ—ã‚’ç”Ÿæˆã—ã€LoRAãƒ¢ãƒ‡ãƒ«ã¯æ–°ãŸãªé«˜ãƒ©ãƒ³ã‚¯ã®ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆä¾µå…¥æ¬¡å…ƒï¼‰ã‚’æŒã¤ã“ã¨ãŒåˆ¤æ˜ã€‚ä¾µå…¥æ¬¡å…ƒã¯ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’ä½ä¸‹ã•ã›ã‚‹ãŒã€åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç•°ãªã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ãŒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã®ç•°ãªã‚‹éƒ¨åˆ†ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aratako_lm/status/1854838012909166973?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1423" target="_blank" rel="noopener noreferrer">When Scaling Meets LLM Finetuning: The Effect of Data, Model and  Finetuning Method, Biao Zhang+, N/A, ICLR'24</a>
 ã‚„ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
 ã€åŒæ–¹ã®çŸ¥è¦‹ã‚‚äº¤ãˆã¦ã€LoRAã®æŒ™å‹•ã‚’è€ƒå¯Ÿã™ã‚‹å¿…è¦ãŒã‚ã‚‹æ°—ãŒã™ã‚‹ã€‚ãã‚Œãã‚Œç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„ãƒ¢ãƒ‡ãƒ«ã§ã€LoRAã¨FFTã‚’æ¯”è¼ƒã—ã¦ã„ã‚‹ã€‚æ™‚é–“ãŒãªã„ãŒå¾Œã§ã‚„ã‚ŠãŸã„ã€‚<br><br>ã‚ã¨ã€æ˜¨ä»Šã¯ãã‚‚ãã‚‚å®Ÿé¨“è¨­å®šã«ãŠã‘ã‚‹å¤‰æ•°ãŒå¤šã™ãã¦ã€ã¨ã‚Šã†ã‚‹å®Ÿé¨“è¨­å®šãŒå¤šã™ãã‚‹ãŸã‚ã€å€‹ã€…ã®è«–æ–‡ã®çŸ¥è¦‹ã‚’éµœå‘‘ã¿ã«ã—ã¦ä¸€èˆ¬åŒ–ã™ã‚‹ã®ã¯ã‚„ã‚ãŸæ–¹ãŒè‰¯ã„æ°—ãŒã—ã¦ã„ã‚‹ã€‚</p>
<p>
<strong># å®Ÿé¨“è¨­å®šã®é•ã„<br>## ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£<br>- æœ¬ç ”ç©¶: RoBERTa-baseï¼ˆtransformer-encoderï¼‰<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1423" target="_blank" rel="noopener noreferrer">When Scaling Meets LLM Finetuning: The Effect of Data, Model and  Finetuning Method, Biao Zhang+, N/A, ICLR'24</a>
</strong>
<br>
: transformer-decoder<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
: transformer-decoderï¼ˆLLaMAï¼‰<br><br>
<strong>## ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚º<br>- æœ¬ç ”ç©¶: <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1423" target="_blank" rel="noopener noreferrer">When Scaling Meets LLM Finetuning: The Effect of Data, Model and  Finetuning Method, Biao Zhang+, N/A, ICLR'24</a>
</strong>
<br>
: 1B, 2B, 4B, 8B, 16B<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
: 7B<br><br>æ™‚é–“ãŒã‚ã‚‹æ™‚ã«ç¶šãã‚’ã‹ããŸã„<br><br>## Finetuningãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¿ã‚¹ã‚¯æ•°<br><br>## 1ã‚¿ã‚¹ã‚¯ã‚ãŸã‚Šã®ãƒ‡ãƒ¼ã‚¿é‡<br><br>## trainableãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<span class="issue_date">Issue Date: 2024-11-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1490" target="_blank" rel="noopener noreferrer" class="title-link">A Comprehensive Survey of Small Language Models in the Era of Large  Language Models: Techniques, Enhancements, Applications, Collaboration with  LLMs, and Trustworthiness, Fali Wang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã¯å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã§èƒ½åŠ›ã‚’ç¤ºã™ãŒã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚„è¨ˆç®—è¦æ±‚ã‹ã‚‰åˆ¶é™ã‚’å—ã‘ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚„ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾ã—ã€å°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆSLMï¼‰ã¯ä½é…å»¶ã€ã‚³ã‚¹ãƒˆåŠ¹ç‡ã€ç°¡å˜ãªã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãŒå¯èƒ½ã§ã€ç‰¹ã«å°‚é–€çš„ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã«ãŠã„ã¦æœ‰ç”¨ã§ã‚ã‚‹ã€‚SLMã®éœ€è¦ãŒé«˜ã¾ã‚‹ä¸­ã€å®šç¾©ã‚„å¿œç”¨ã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªèª¿æŸ»ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€SLMã‚’å°‚é–€çš„ãªã‚¿ã‚¹ã‚¯ã«é©ã—ãŸãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦å®šç¾©ã—ã€å¼·åŒ–ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/9faf2732-233d-468e-ac4c-98b18f2f2bcf" alt="image" loading="lazy"></p>
<p><img src="https://github.com/user-attachments/assets/889ebda5-7cf4-4f62-ae48-e3fdd8f91c15" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2024-11-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1484" target="_blank" rel="noopener noreferrer" class="title-link">Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language  Models -- A Survey, Philipp Mondorf+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®æ¨è«–èƒ½åŠ›ã«é–¢ã™ã‚‹ç ”ç©¶ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ã‚¿ã‚¹ã‚¯ç²¾åº¦ã‚’è¶…ãˆãŸæ·±ã„æ´å¯Ÿã‚’æä¾›ã€‚ãƒ¢ãƒ‡ãƒ«ã¯è¡¨é¢çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¾å­˜ã—ã€æ´—ç·´ã•ã‚ŒãŸæ¨è«–èƒ½åŠ›ãŒä¸è¶³ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚äººé–“ã¨ã®æ¨è«–ã®é•ã„ã‚’æ˜ç¢ºã«ã™ã‚‹ãŸã‚ã®ã•ã‚‰ãªã‚‹ç ”ç©¶ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã€‚</span>
<span class="snippet"><span>Comment</span><p>è«–æ–‡ç´¹ä»‹ï¼ˆsei_shinagawaï¼‰:


<a href="https://www.docswell.com/s/sei_shinagawa/KL1QXL-beyond-accuracy-evaluating-the-behaivior-of-llm-survey" target="_blank" rel="noopener noreferrer">https://www.docswell.com/s/sei_shinagawa/KL1QXL-beyond-accuracy-evaluating-the-behaivior-of-llm-survey</a>


</p>
<p><img src="https://github.com/user-attachments/assets/a0369ac2-8dbc-4a7a-baf5-df59850a3b55" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2024-11-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1483" target="_blank" rel="noopener noreferrer" class="title-link">Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated  Parameters by Tencent, Xingwu Sun+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Hunyuan-Largeã¯ã€3890å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®Transformerãƒ™ãƒ¼ã‚¹ã®å°‚é–€å®¶æ··åˆãƒ¢ãƒ‡ãƒ«ã§ã€æœ€å¤§256Kãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‡¦ç†å¯èƒ½ã€‚è¨€èªç†è§£ã‚„ç”Ÿæˆã€è«–ç†æ¨è«–ãªã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§LLama3.1-70Bã‚’ä¸Šå›ã‚Šã€LLama3.1-405Bã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã™ã€‚ä¸»ãªç‰¹å¾´ã«ã¯å¤§è¦æ¨¡ãªåˆæˆãƒ‡ãƒ¼ã‚¿ã€æ··åˆå°‚é–€å®¶ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã€ã‚­ãƒ¼ãƒ»ãƒãƒªãƒ¥ãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥åœ§ç¸®ã€å°‚é–€å®¶ç‰¹æœ‰ã®å­¦ç¿’ç‡æˆ¦ç•¥ãŒå«ã¾ã‚Œã€ä»Šå¾Œã®ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã«å‘ã‘ãŸæ´å¯Ÿã‚‚æä¾›ã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>åˆè¨ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯Llama-3.1-405Bã¨åŒç­‰ã®389Bã ãŒã€MoEã«ã‚ˆã£ã¦52Bã®Active Parameterã§SoTAã‚’é”æˆã—ãŸTencentã®OpenSource LLMã€‚å¤§é‡ã®Synthetia Dataã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2024-11-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1476" target="_blank" rel="noopener noreferrer" class="title-link">Looking Inward: Language Models Can Learn About Themselves by  Introspection, Felix J Binder+, N_A, arXiv'24, 2024.11</a>
<span class="snippet"><span>GPT Summary</span>- å†…çœã¯ã€LLMsãŒãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«ä¾å­˜ã›ãšã«å†…éƒ¨çŠ¶æ…‹ã‹ã‚‰çŸ¥è­˜ã‚’ç²å¾—ã™ã‚‹èƒ½åŠ›ã‚’æŒ‡ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LLMsã‚’å¾®èª¿æ•´ã—ã€ä»®æƒ³ã‚·ãƒŠãƒªã‚ªã«ãŠã‘ã‚‹è‡ªèº«ã®è¡Œå‹•ã‚’äºˆæ¸¬ã•ã›ã‚‹ã“ã¨ã§å†…çœã‚’æ¤œè¨¼ã€‚å®Ÿé¨“ã®çµæœã€å†…çœå¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ï¼ˆM1ï¼‰ã¯ã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆM2ï¼‰ã‚ˆã‚Šã‚‚è‡ªèº«ã®è¡Œå‹•ã‚’æ­£ç¢ºã«äºˆæ¸¬ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ç‰¹ã«ã€M1ã¯è¡Œå‹•ã‚’æ„å›³çš„ã«å¤‰æ›´ã—ãŸå¾Œã§ã‚‚äºˆæ¸¬ç²¾åº¦ã‚’ç¶­æŒã—ãŸãŒã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã§ã¯å†…çœã‚’å¼•ãå‡ºã™ã“ã¨ãŒã§ããªã‹ã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/2b19bc9c-342d-42a9-b603-ff9cfc694570" alt="image" loading="lazy"></p>
<p>LLMãŒå˜ã«è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’æ¨¡å€£ã—ã¦ã„ã‚‹ã«ã™ããªã„çš„ãªä¸»å¼µã«å¯¾ã™ã‚‹ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã«ä½¿ãˆã‚‹ã‹ã‚‚</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-10-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1472" target="_blank" rel="noopener noreferrer" class="title-link">KTO: Model Alignment as Prospect Theoretic Optimization, Kawin Ethayarajh+, N_A, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ­ã‚¹ãƒšã‚¯ãƒˆç†è«–ã«åŸºã¥ãã€LLMã®äººé–“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯èª¿æ•´ã«ãŠã‘ã‚‹ãƒã‚¤ã‚¢ã‚¹ã®å½±éŸ¿ã‚’ç¤ºã™ã€‚æ–°ãŸã«ææ¡ˆã™ã‚‹ã€Œäººé–“èªè­˜æå¤±ã€ï¼ˆHALOsï¼‰ã‚’ç”¨ã„ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒKTOã¯ã€ç”Ÿæˆç‰©ã®åŠ¹ç”¨ã‚’æœ€å¤§åŒ–ã—ã€å¥½ã¿ãƒ™ãƒ¼ã‚¹ã®æ–¹æ³•ã¨åŒç­‰ã¾ãŸã¯ãã‚Œä»¥ä¸Šã®æ€§èƒ½ã‚’ç™ºæ®ã€‚ç ”ç©¶ã¯ã€æœ€é©ãªæå¤±é–¢æ•°ãŒç‰¹å®šã®è¨­å®šã«ä¾å­˜ã™ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>binaryãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰LLMã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’ã¨ã‚‹Kahneman-Tversky Optimization (KTO)è«–æ–‡</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1468" target="_blank" rel="noopener noreferrer" class="title-link">Generative Reward Models, Dakota Mahan+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- RLHFã¨RLAIFã‚’çµ±åˆã—ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€åˆæˆå¥½ã¿ãƒ©ãƒ™ãƒ«ã®è³ªã‚’å‘ä¸Šã•ã›ã‚‹GenRMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å°å…¥ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€GenRMã¯åˆ†å¸ƒå†…å¤–ã®ã‚¿ã‚¹ã‚¯ã§Bradley-Terryãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã¾ãŸã¯ãã‚Œã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€LLMã‚’åˆ¤æ–­è€…ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹å ´åˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚‚å‘ä¸Šã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=MwU2SGLKpS" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=MwU2SGLKpS</a>


</p>
<p>é–¢é€£ç ”ç©¶<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/708" target="_blank" rel="noopener noreferrer">LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and  Generative Fusion, Dongfu Jiang+, N/A, ACL'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1212" target="_blank" rel="noopener noreferrer">Self-Rewarding Language Models, Weizhe Yuan+, N/A, ICML'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2903" target="_blank" rel="noopener noreferrer">[Paper Note] Constitutional AI: Harmlessness from AI Feedback, Yuntao Bai+, arXiv'22</a>
</p>
<p>openreview:


<a href="https://openreview.net/forum?id=MwU2SGLKpS" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=MwU2SGLKpS</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1464" target="_blank" rel="noopener noreferrer" class="title-link">Self-Taught Evaluators, Tianlu Wang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€äººé–“ã®æ³¨é‡ˆãªã—ã§è©•ä¾¡è€…ã‚’æ”¹å–„ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚åˆæˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã€è‡ªå·±æ”¹å–„ã‚¹ã‚­ãƒ¼ãƒ ã«ã‚ˆã‚ŠLLMã‚’è©•ä¾¡è€…ã¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€RewardBenchã§ã®LLMã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’75.4ã‹ã‚‰88.3ã«å‘ä¸Šã•ã›ã€GPT-4ã‚’è¶…ãˆã‚‹çµæœã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆç­‰ã‚’SFTã™ã‚‹éš›ã«ã€preferenceã®ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã«ãªã‚‹ãŒã€ã“ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹ã®ã¯ã‚³ã‚¹ãƒˆãŒã‹ã‹ã£ã¦å¤§å¤‰ãªã®ã§è‡ªå‹•ç”Ÿæˆã—ã¦ã€ã‚ˆã‚Šè‰¯ã„reward modelã‚’ä½œã‚ŠãŸã„ã‚ˆã­ã€ã¨ã„ã†è©±ã€‚<br>å…·ä½“çš„ã«ã¯ã€LLMã‚’ç”¨ã„ã¦ good responseã¨ã€instructionã‚’å¤‰åŒ–ã•ã›ã¦bad sesponseã‚’ç”Ÿæˆã—ã€Judgeãƒ¢ãƒ‡ãƒ«M_tã«pairwiseã§ã©ã¡ã‚‰ãŒè‰¯ã„ã‹ã‚’judgeã•ã›ã‚‹ã“ã¨ã§å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã€‚æ–°ãŸã«ä½œæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦Judgeãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ã—ã€åŒæ§˜ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç¹°ã‚Šè¿”ã™ã“ã¨ã§ã€äººæ‰‹ã®ä»‹åœ¨ãªãå¼·åŠ›ãªJudgeãƒ¢ãƒ‡ãƒ«ãŒå®Œæˆã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/837c4567-6993-4e4c-81c8-650b7777c49b" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/10a4fb62-160d-4bcf-b3a2-a960a7c9bc46" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1463" target="_blank" rel="noopener noreferrer" class="title-link">Retrieval Augmented Generation ï¼ˆRAGï¼‰ and Beyond: A Comprehensive Survey  on How to Make your LLMs use External Data More Wisely, Siyun Zhao+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§å®Ÿä¸–ç•Œã®ã‚¿ã‚¹ã‚¯ã‚’é‚è¡Œã™ã‚‹èƒ½åŠ›ã‚’ç¤ºã™ãŒã€ãƒ‡ãƒ¼ã‚¿å¼·åŒ–å‹LLMsã®åŠ¹æœçš„ãªå±•é–‹ã«ã¯å¤šãã®èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã‚Œã«ã¯ã€é–¢é€£ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã®è§£é‡ˆã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ¨è«–èƒ½åŠ›ã®æ´»ç”¨ãŒå«ã¾ã‚Œã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€RAGã‚¿ã‚¹ã‚¯ã‚’å››ã¤ã®ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã«åˆ†é¡ã—ã€é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„èª²é¡Œã€æŠ€è¡“ã‚’è¦ç´„ã™ã‚‹ã€‚ã¾ãŸã€å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿çµ±åˆã®ä¸‰ã¤ã®å½¢å¼ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€å°å‹ãƒ¢ãƒ‡ãƒ«ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã€ãã‚Œãã‚Œã®å¼·ã¿ã¨é™ç•Œã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‡ãƒ¼ã‚¿è¦ä»¶ã¨LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹ç¯‰ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç†è§£ã—ã€ä½“ç³»çš„ãªé–‹ç™ºã®ãŸã‚ã®ã‚¬ã‚¤ãƒ‰ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>RAGã®ã‚¯ã‚¨ãƒªã‚’4ç¨®é¡ã«åˆ†é¡ã—ãŸå„ã‚¯ã‚¨ãƒªã”ã¨ã®æŠ€è¡“ã‚’ã¾ã¨ã‚ãŸSurvey<br><img src="https://github.com/user-attachments/assets/b551725d-5f82-4914-8b8f-716ddb6a342b" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2024-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1459" target="_blank" rel="noopener noreferrer" class="title-link">Addition is All You Need for Energy-efficient Language Models, Hongyin Luo+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æµ®å‹•å°æ•°ç‚¹ä¹—ç®—ã‚’é«˜ç²¾åº¦ã§æ•´æ•°åŠ ç®—å™¨ã«ã‚ˆã£ã¦è¿‘ä¼¼ã™ã‚‹L-Mulã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€8ãƒ“ãƒƒãƒˆæµ®å‹•å°æ•°ç‚¹ä¹—ç®—ã«æ¯”ã¹ã¦è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’å¤§å¹…ã«å‰Šæ¸›ã—ã¤ã¤ã€ã‚ˆã‚Šé«˜ã„ç²¾åº¦ã‚’å®Ÿç¾ã€‚L-Mulã‚’ãƒ†ãƒ³ã‚½ãƒ«å‡¦ç†ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã«é©ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚³ã‚¹ãƒˆã‚’95ï¼…ï¼ˆè¦ç´ ã”ã¨ã®ä¹—ç®—ï¼‰ãŠã‚ˆã³80ï¼…ï¼ˆãƒ‰ãƒƒãƒˆç©ï¼‰å‰Šæ¸›å¯èƒ½ã€‚å®Ÿé¨“çµæœã¯ç†è«–çš„èª¤å·®æ¨å®šã¨ä¸€è‡´ã—ã€L-Mulã¯å¾“æ¥ã®æµ®å‹•å°æ•°ç‚¹ä¹—ç®—ã¨åŒç­‰ã¾ãŸã¯ãã‚Œä»¥ä¸Šã®ç²¾åº¦ã‚’é”æˆã€‚ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«å†…ã®æµ®å‹•å°æ•°ç‚¹ä¹—ç®—ã‚’L-Mulã«ç½®ãæ›ãˆã‚‹ã“ã¨ã§ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã«ãŠã„ã¦é«˜ã„ç²¾åº¦ã‚’ç¶­æŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2024-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1458" target="_blank" rel="noopener noreferrer" class="title-link">ToolGen: Unified Tool Retrieval and Calling via Generation, Renxi Wang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ToolGenã¯ã€å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã¨ã®ç›´æ¥å¯¾è©±ã‚’å¯èƒ½ã«ã™ã‚‹æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€å„ãƒ„ãƒ¼ãƒ«ã‚’ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦è¡¨ç¾ã—ã€LLMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«çµ±åˆã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMã¯ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚„å¼•æ•°ã‚’è‡ªç„¶è¨€èªç”Ÿæˆã®ä¸€éƒ¨ã¨ã—ã¦ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«ç”Ÿæˆã§ãã€æƒ…å ±å–å¾—ã‚¹ãƒ†ãƒƒãƒ—ãªã—ã§å¤šãã®ãƒ„ãƒ¼ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã«ãªã‚Šã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ToolGenãŒè‡ªå¾‹çš„ãªã‚¿ã‚¹ã‚¯å®Œäº†ã¨æƒ…å ±å–å¾—ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€ã‚ˆã‚ŠåŠ¹ç‡çš„ã§è‡ªå¾‹çš„ãªAIã‚·ã‚¹ãƒ†ãƒ ã®åŸºç›¤ã‚’ç¯‰ãã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ˜”ã‹ã‚‰ã‚ˆãã‚ã‚‹ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’åŸ‹ã‚è¾¼ã‚“ã§ã€ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã—ãŸã‚‰ãã‚Œã«å¿œã˜ãŸå‡¦ç†ã‚’ã™ã‚‹ç³»ã®ç ”ç©¶ã€‚ä»Šå›ã¯ãƒ„ãƒ¼ãƒ«ã«å¯¾å¿œã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä»•è¾¼ã‚€æ¨¡æ§˜ã€‚</p>
<p>æ–œã‚èª­ã¿ã ãŒã€3ã¤ã®stepã§Foundation Modelã‚’è¨“ç·´ã™ã‚‹ã€‚ã¾ãšã¯ãƒ„ãƒ¼ãƒ«ã®descriptionã‹ã‚‰ãƒ„ãƒ¼ãƒ«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã«ãƒ„ãƒ¼ãƒ«ã®æƒ…å ±ã‚’è¦šãˆã•ã›ã‚‹ï¼ˆmemorizationï¼‰ã€‚æ–œã‚èª­ã¿ãªã®ã§èª­ã‚ã¦ã„ãªã„ãŒã€ãƒ„ãƒ¼ãƒ«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’vocabã«è¿½åŠ ã—ã¦ã‚‹ã®ã§ã“ã“ã¯ç¶™ç¶šçš„äº‹å‰å­¦ç¿’ã‚’ã—ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚ç¶šã„ã¦ã€ï¼ˆãŠãã‚‰ãï¼‰äººæ‰‹ã§ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸã‚¯ã‚¨ãƒª-å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã®ãƒšã‚¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’å­¦ç¿’ã•ã›ã‚‹ã€‚æœ€å¾Œã«ã€ï¼ˆãŠãã‚‰ãäººæ‰‹ã§ä½œæˆã•ã‚ŒãŸï¼‰ã‚¯ã‚¨ãƒª-ã‚¿ã‚¹ã‚¯ã‚’è§£ããŸã‚ã®trajectoryãƒšã‚¢ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã•ã›ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/eebe4260-2e4f-4be7-9b59-a0b84913e667" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/d03ed971-e5c9-49f3-8385-cfb00505907c" alt="image" loading="lazy"></p>
<p>å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«ã€‚Appendixä¸­ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã ãŒã€æœ¬æ–‡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç¯€ã¨Appendixã®åŒæ–¹ã«ã€ãƒ‡ãƒ¼ã‚¿ã®ä½œã‚Šæ–¹ã®è©³ç´°ã¯è¨˜è¿°ã•ã‚Œã¦ã„ãªã‹ã£ãŸã€‚ã©ã“ã‹ã«æ›¸ã„ã¦ã‚ã‚‹ã®ã ã‚ã†ã‹ã€‚<br><img src="https://github.com/user-attachments/assets/41975d34-dc9d-405d-aaca-062a3ee1a4b0" alt="image" loading="lazy"></p>
<p>æœ€çµ‚çš„ãªæ€§èƒ½<br><img src="https://github.com/user-attachments/assets/a247cc99-10eb-4346-9f0d-b406a022c3b4" alt="image" loading="lazy"></p>
<p>ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ ã®vocabã¨ã—ã¦ç™»éŒ²ã—ã€ãã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ã€vocabã«å¿œã˜ã¦ä½•ã‚‰ã‹ã®æ“ä½œã‚’å®Ÿè¡Œã™ã‚‹ã¨ã„ã†æ çµ„ã¿ã€ãã®å­¦ç¿’æ‰‹æ³•ã¯è‰²ã€…ãªã‚¿ã‚¹ã‚¯ã§å½¹ç«‹ã¡ãã†ã€‚</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/KnowledgeGraph.html" target="_blank" rel="noopener noreferrer">#KnowledgeGraph</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Annotation.html" target="_blank" rel="noopener noreferrer">#Annotation</a>
<span class="issue_date">Issue Date: 2024-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1449" target="_blank" rel="noopener noreferrer" class="title-link">COSMO: A large-scale e-commerce common sense knowledge generation and serving system at Amazon , Yu+, SIGMOD_PODS '24</a>
<span class="snippet"><span>GPT Summary</span>- COSMOã¯ã€eã‚³ãƒãƒ¼ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å‘ã‘ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸­å¿ƒã®å¸¸è­˜çŸ¥è­˜ã‚’ãƒã‚¤ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªçŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æŠ½å‡ºã—ãŸé«˜å“è³ªãªçŸ¥è­˜ã‚’ç”¨ã„ã€æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã£ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸCOSMO-LMã¯ã€Amazonã®ä¸»è¦ã‚«ãƒ†ã‚´ãƒªã«ã‚ãŸã£ã¦æ•°ç™¾ä¸‡ã®çŸ¥è­˜ã‚’ç”Ÿæˆã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€COSMOãŒæ¤œç´¢ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãªã©ã§é¡•è‘—ãªæ”¹å–„ã‚’é”æˆã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€å¸¸è­˜çŸ¥è­˜ã®æ´»ç”¨ã®å¯èƒ½æ€§ãŒå¼·èª¿ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/56fec49b-0917-444f-825b-3f050b7357cb" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/978a1b9c-bd59-4838-be8d-bc72e5dc1032" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/b1d88bd7-2507-4086-89bf-5330831b00ce" alt="image" loading="lazy"></p>
<p>search navigationã«å°å…¥ã—A/Bãƒ†ã‚¹ãƒˆã—ãŸçµæœã€0.7%ã®product saleså‘ä¸ŠåŠ¹æœã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<span class="issue_date">Issue Date: 2024-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1434" target="_blank" rel="noopener noreferrer" class="title-link">What matters when building vision-language models?, Hugo LaurenÃ§on+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- è¦–è¦šã¨è¨€èªã®ãƒ¢ãƒ‡ãƒ«ï¼ˆVLMï¼‰ã®è¨­è¨ˆã«ãŠã‘ã‚‹è£ä»˜ã‘ã®ãªã„æ±ºå®šãŒæ€§èƒ½å‘ä¸Šã®ç‰¹å®šã‚’å¦¨ã’ã¦ã„ã‚‹ã¨æŒ‡æ‘˜ã€‚äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒ‡ãƒ¼ã‚¿ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã«é–¢ã™ã‚‹å®Ÿé¨“ã‚’è¡Œã„ã€80å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åŸºç›¤VLMã€ŒIdefics2ã€ã‚’é–‹ç™ºã€‚Idefics2ã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã—ã€4å€ã®ã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆã«OpenVLMã®é€²å±•ã®æ­´å²ãŒè¼‰ã£ã¦ã„ã‚‹ã€‚æ§‹ç¯‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚å…¬é–‹ã•ã‚Œã‚‹æ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/9675c2ad-650a-460b-9655-1c6347d07f58" alt="image" loading="lazy"><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thom_wolf/status/1840372428855280045?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2024-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1429" target="_blank" rel="noopener noreferrer" class="title-link">Logic-of-Thought: Injecting Logic into Contexts for Full Reasoning in  Large Language Models, Tongxuan Liu+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Logic-of-Thoughtï¼ˆLoTï¼‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã‚’ææ¡ˆã—ã€å‘½é¡Œè«–ç†ã‚’ç”¨ã„ã¦å…¥åŠ›ã‹ã‚‰æ‹¡å¼µã•ã‚ŒãŸè«–ç†æƒ…å ±ã‚’ç”Ÿæˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã®è«–ç†æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã€æ—¢å­˜ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã¨çµ±åˆå¯èƒ½ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€LoTãŒ5ã¤ã®è«–ç†æ¨è«–ã‚¿ã‚¹ã‚¯ã§é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ã€ç‰¹ã«ReClorã§+4.35%ã€LogiQAã§+5%ã€ProofWriterã§+8%ã®æ”¹å–„ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>SNSã§è©±é¡Œã«ãªã£ã¦ã„ã‚‹ã‚ˆã†ã ãŒGPT-3.5-Turboã¨GPT-4ã§ã—ã‹æ¯”è¼ƒã—ã¦ã„ãªã„ä¸Šã«ã€ã„ã¤ã®æ™‚ç‚¹ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‚è¨˜è¿°ã•ã‚Œã¦ã„ãªã„ã®ã§ã€unreliableã«è¦‹ãˆã‚‹<br><br><img src="https://github.com/user-attachments/assets/9ca6fc62-2691-40c8-a578-554c0083df8f" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2024-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1423" target="_blank" rel="noopener noreferrer" class="title-link">When Scaling Meets LLM Finetuning: The Effect of Data, Model and  Finetuning Method, Biao Zhang+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç‰¹æ€§ã‚’èª¿æŸ»ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚„ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒæ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’å®Ÿé¨“ã€‚çµæœã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ãƒ‘ãƒ¯ãƒ¼ãƒ™ãƒ¼ã‚¹ã®å…±åŒã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã«å¾“ã„ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒäº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚ˆã‚Šã‚‚åŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã€‚æœ€é©ãªæ‰‹æ³•ã¯ã‚¿ã‚¹ã‚¯ã‚„ãƒ‡ãƒ¼ã‚¿ã«ä¾å­˜ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>&gt; When only few thousands of finetuning examples are available, PET should be considered first, either Prompt or LoRA. With sightly larger datasets, LoRA would be preferred due to its stability and slightly better finetuning data scalability. For million-scale datasets, FMT would be good.<br><br><br><br>&gt; While specializing on a downstream task, finetuning could still elicit<br><br>and improve the generalization for closely related tasks, although the overall zero-shot translation<br><br>quality is inferior. Note whether finetuning benefits generalization is method- and task-dependent.<br><br>Overall, Prompt and LoRA achieve relatively better results than FMT particularly when the base<br><br>LLM is large, mostly because LLM parameters are frozen and the learned knowledge get inherited.<br><br>This also suggests that when generalization capability is a big concern, PET should be considered.</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2024-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1411" target="_blank" rel="noopener noreferrer" class="title-link">Recommendation with Generative Models, Yashar Deldjoo+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹AIãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€GANã‚„VAEã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã«åŸºã¥ãã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã€‚ç‰¹ã«ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ã¯ã€Gen-RecSysãŒæ¨è–¦ã®ç²¾åº¦ã¨å¤šæ§˜æ€§ã‚’å‘ä¸Šã•ã›ã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã‚’æä¾›ã™ã‚‹ã€‚æœ¬æ›¸ã§ã¯ã€æ·±å±¤ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’IDé§†å‹•ãƒ¢ãƒ‡ãƒ«ã€LLMã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®3ã¤ã«åˆ†é¡ã—ã€ãã‚Œãã‚Œã®æŠ€è¡“çš„é€²å±•ã‚’ç´¹ä»‹ã€‚ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®å½±éŸ¿ã‚„ãƒªã‚¹ã‚¯ã«ã¤ã„ã¦ã‚‚è€ƒå¯Ÿã—ã€è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®é‡è¦æ€§ã‚’å¼·èª¿ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚„GenerativeAIã«ã‚ˆã‚‹RecSysã®æ•™ç§‘æ›¸<br><img src="https://github.com/user-attachments/assets/a76e5fd2-cd82-43f9-ac64-bb33c5fe1dc2" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2024-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1410" target="_blank" rel="noopener noreferrer" class="title-link">Report on the 1st Workshop on Large Language Model for Evaluation in  Information Retrieval ï¼ˆLLM4Eval 2024ï¼‰ at SIGIR 2024, Hossein A. Rahmani+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLM4Eval 2024ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ãŒSIGIR 2024ã§é–‹å‚¬ã•ã‚Œã€æƒ…å ±æ¤œç´¢ã«ãŠã‘ã‚‹è©•ä¾¡ã®ãŸã‚ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«é–¢ã™ã‚‹ç ”ç©¶è€…ãŒé›†ã¾ã‚Šã¾ã—ãŸã€‚æ–°è¦æ€§ã‚’é‡è¦–ã—ã€å—ç†è«–æ–‡ã®ãƒ‘ãƒãƒ«ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã‚„ãƒã‚¹ã‚¿ãƒ¼ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é€šã˜ã¦å¤šé¢çš„ãªè­°è«–ãŒè¡Œã‚ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã‚’ç”¨ã„ãŸIRã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡æ–¹æ³•ã«é–¢ã™ã‚‹ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã®ãƒ¬ãƒãƒ¼ãƒˆã€‚ãƒ¬ãƒãƒ¼ãƒˆä¸­ã«Accepted PaperãŒãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/RelevanceJudgment.html" target="_blank" rel="noopener noreferrer">#RelevanceJudgment</a>
<span class="issue_date">Issue Date: 2024-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1409" target="_blank" rel="noopener noreferrer" class="title-link">Don't Use LLMs to Make Relevance Judgments, Ian Soboroff, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- TRECã‚¹ã‚¿ã‚¤ãƒ«ã®é–¢é€£æ€§åˆ¤æ–­ã¯é«˜ã‚³ã‚¹ãƒˆã§è¤‡é›‘ã§ã‚ã‚Šã€é€šå¸¸ã¯è¨“ç·´ã‚’å—ã‘ãŸå¥‘ç´„è€…ãƒãƒ¼ãƒ ãŒå¿…è¦ã§ã™ã€‚æœ€è¿‘ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç™»å ´ã«ã‚ˆã‚Šã€æƒ…å ±æ¤œç´¢ç ”ç©¶è€…ã¯ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç”¨å¯èƒ½æ€§ã‚’è€ƒãˆå§‹ã‚ã¾ã—ãŸã€‚ACM SIGIR 2024ã‚«ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã§ã®ã€ŒLLM4Evalã€ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—ã§ã¯ã€TRECã®æ·±å±¤å­¦ç¿’ãƒˆãƒ©ãƒƒã‚¯ã®åˆ¤æ–­ã‚’å†ç¾ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒ¬ãƒ³ã‚¸ãŒè¡Œã‚ã‚Œã¾ã—ãŸã€‚æœ¬è«–æ–‡ã¯ãã®åŸºèª¿è¬›æ¼”ã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã§ã€TRECã‚¹ã‚¿ã‚¤ãƒ«ã®è©•ä¾¡ã«ãŠã„ã¦LLMã‚’ä½¿ç”¨ã—ãªã„ã“ã¨ã‚’æè¨€ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>èˆˆå‘³æ·±ã„ï¼ï¼å¾Œã§èª­ã‚€ï¼</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1408" target="_blank" rel="noopener noreferrer" class="title-link">Backtracking Improves Generation Safety, Yiming Zhang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ãŠã‘ã‚‹å®‰å…¨æ€§ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ãƒãƒƒã‚¯ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã€‚ç‰¹åˆ¥ãª[RESET]ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”¨ã„ã¦ç”Ÿæˆã•ã‚ŒãŸä¸é©åˆ‡ãªãƒ†ã‚­ã‚¹ãƒˆã‚’ã€Œå–ã‚Šæ¶ˆã—ã€ã€ãƒ¢ãƒ‡ãƒ«ã®å®‰å…¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ãƒãƒƒã‚¯ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’å°å…¥ã—ãŸLlama-3-8Bã¯ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦4å€ã®å®‰å…¨æ€§ã‚’ç¤ºã—ã€æœ‰ç”¨æ€§ã®ä½ä¸‹ã¯è¦‹ã‚‰ã‚Œãªã‹ã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1838415378529112330?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2024-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1406" target="_blank" rel="noopener noreferrer" class="title-link">To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic  reasoning, Zayne Sprague+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Chain-of-thoughtï¼ˆCoTï¼‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã¯LLMsã®æ¨è«–èƒ½åŠ›ã‚’å¼•ãå‡ºã™æ‰‹æ³•ã§ã‚ã‚Šã€100ä»¥ä¸Šã®è«–æ–‡ã‚’å¯¾è±¡ã«ã—ãŸãƒ¡ã‚¿åˆ†æã«ã‚ˆã‚Šã€ä¸»ã«æ•°å­¦ã‚„è«–ç†ã‚¿ã‚¹ã‚¯ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸ŠãŒç¢ºèªã•ã‚ŒãŸã€‚ä¸€æ–¹ã€ä»–ã®ã‚¿ã‚¹ã‚¯ã§ã¯åŠ¹æœãŒé™å®šçš„ã§ã€MMLUã§ã¯ç›´æ¥å›ç­”ç”ŸæˆãŒCoTã¨åŒç­‰ã®ç²¾åº¦ã‚’ç¤ºã—ãŸã€‚è¨ˆç”»ã¨å®Ÿè¡Œã‚’åˆ†é›¢ã—ã€ãƒ„ãƒ¼ãƒ«å¼·åŒ–LLMsã¨æ¯”è¼ƒã—ãŸçµæœã€CoTã®åˆ©ç‚¹ã¯è¨˜å·çš„å®Ÿè¡Œã®æ”¹å–„ã«èµ·å› ã—ã€è¨˜å·ã‚½ãƒ«ãƒãƒ¼ã«ã¯åŠ£ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚CoTã®é¸æŠçš„é©ç”¨ã«ã‚ˆã‚Šã€æ¨è«–ã‚³ã‚¹ãƒˆã‚’ç¯€ç´„ã—ã¤ã¤ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¶­æŒã§ãã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã€LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã§ã®ä¸­é–“è¨ˆç®—ã®æ´»ç”¨ãŒæ±‚ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>CoTã‚’100å€‹ä»¥ä¸Šã®å…ˆè¡Œç ”ç©¶ã§meta-analysisã—ï¼ˆi.e. CoTã‚’è¿½åŠ ã—ãŸå ´åˆã®gainã¨ã‚¿ã‚¹ã‚¯ã®ãƒ—ãƒ­ãƒƒãƒˆï¼‰ã€20å€‹è¶…ãˆã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è‘—è€…ã‚‰ãŒå®Ÿé¨“ã—ãŸçµæœã€mathã¯symbolic reasoningï¼ˆ12*4ã®ã‚ˆã†ã«ã€ã‚·ãƒ³ãƒœãƒ«ã‚’èªè­˜ã—ã€ä½•ã‚‰ã‹ã®æ“ä½œã‚’ã—ã¦å›ç­”ã‚’ã™ã‚‹å•é¡Œï¼‰ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§ã€CoTã¯å¤§ããªgainãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸï¼ˆä»–ã¯ã»ã¨ã‚“ã©gainãŒãªã„ï¼‰ã€‚<br><img src="https://github.com/user-attachments/assets/a399306f-bda9-45c9-a756-2a83a9727e63" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/CrossLingual.html" target="_blank" rel="noopener noreferrer">#CrossLingual</a>
<span class="issue_date">Issue Date: 2024-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1400" target="_blank" rel="noopener noreferrer" class="title-link">PLUG: Leveraging Pivot Language in Cross-Lingual Instruction Tuning, Zhihan Zhang+, N_A, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯LLMsã®æŒ‡ç¤ºç†è§£ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ä½ãƒªã‚½ãƒ¼ã‚¹è¨€èªã§ã¯èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€è‹±èªã‚’ãƒ”ãƒœãƒƒãƒˆè¨€èªã¨ã™ã‚‹PLUGã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ãƒ¢ãƒ‡ãƒ«ã¯ã¾ãšè‹±èªã§æŒ‡ç¤ºã‚’å‡¦ç†ã—ã€æ¬¡ã«ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨€èªã§å¿œç­”ã‚’ç”Ÿæˆã€‚4ã¤ã®è¨€èªã§ã®è©•ä¾¡ã«ã‚ˆã‚Šã€æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ãŒå¹³å‡29%å‘ä¸Šã—ãŸã€‚ã•ã‚‰ã«ã€ä»–ã®ãƒ”ãƒœãƒƒãƒˆè¨€èªã‚’ç”¨ã„ãŸå®Ÿé¨“ã‚‚è¡Œã„ã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å¤šæ§˜æ€§ã‚’ç¢ºèªã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>
<strong># æ¦‚è¦<br><br>cross-lingualã§instruction tuningã‚’ã™ã‚‹æ‰‹æ³•ã€‚targetè¨€èªã®InstructionãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€Pivotã¨ãªã‚‹è¨€èªã§Instructionã¨Responseã‚’ç”Ÿæˆã—ãŸå¾Œã€targetã¨ãªã‚‹è¨€èªã«ç¿»è¨³ã™ã‚‹ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ï¼ˆãã‚Œãã‚Œã‚’separatorã‚’ç”¨ã„ã¦concatã™ã‚‹ï¼‰ã§Instruction Tuningã™ã‚‹ã“ã¨ã§targetè¨€èªã§ã®æ€§èƒ½ãŒå‘ä¸Š<br><br><br><br><img src="https://github.com/user-attachments/assets/1a409df0-b8bf-45fd-8fc1-316519723820" alt="image" loading="lazy"><br><br><br><br># è©•ä¾¡<br><br>ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®Open-end Generationã‚¿ã‚¹ã‚¯ã§Instruction Tuningã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒè©•ä¾¡ã•ã‚Œã‚‹ãŒã€æ—¢å­˜ã®ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ã®è©•ä¾¡ã‚»ãƒƒãƒˆã¯ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°ã•ãã€æ©Ÿæ¢°ç¿»è¨³ãƒ™ãƒ¼ã‚¹ã®ã‚‚ã®ã¯ãƒã‚¤ã‚¸ãƒ¼ã¨ã„ã†èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã®ãŸã‚ã€è‘—è€…ã‚‰ã¯è©•ä¾¡ã™ã‚‹4è¨€èªï¼ˆlow-resource languageï¼‰ã®ãƒ—ãƒ­ã®ç¿»è¨³å®¶ã‚’é›‡ç”¨ã—ã€AlpacaEvalã‚’ç¿»è¨³ã—ã€4è¨€èªï¼ˆChinese, Korean, Italian, Spanishï¼‰ã®instructionãŒå­˜åœ¨ã™ã‚‹ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ X-AlpacaEvalã‚’ä½œæˆã—è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ç”¨ã„ã‚‹ã€‚<br><br><br>åˆ©ç”¨ã™ã‚‹Foundationãƒ¢ãƒ‡ãƒ«ã¯ä»¥ä¸‹ã®3ç¨®é¡ã§ã€<br><br>- LLaMA-2-13B (è‹±èªã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«)<br><br>- PolyLM-13B (ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãªãƒ¢ãƒ‡ãƒ«)<br><br>- PolyLM-Instruct-Instruct (PolyLM-13Bã‚’instruction tuningã—ãŸã‚‚ã®)<br><br><br>ã“ã‚Œã‚‰ã«å¯¾ã—ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦GPT4-Alpaca <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1401" target="_blank" rel="noopener noreferrer">Instruction Tuning with GPT-4, Baolin Peng+, N/A, arXiv'23</a>
</strong>
<br>
 instruction-tuning dataset (52kã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨) ã‚’åˆ©ç”¨ã™ã‚‹ã€‚GPT4-Alpacaã‚’ChatGPTã«ã‚ˆã£ã¦4è¨€èªã«ç¿»è¨³ã—ã€å„è¨€èªã«å¯¾ã™ã‚‹instruction tuning datasetã‚’å¾—ãŸã€‚<br><br><br><br>æ¯”è¼ƒæ‰‹æ³•ã¨ã—ã¦ä»¥ä¸‹ã®5ç¨®é¡ã¨æ¯”è¼ƒã—ã¦ã„ã‚‹ã€‚ã“ã“ã§ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨€èªã¯ä»Šå›4ç¨®é¡ã§ã€ãã‚Œãã‚Œã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨€èªã”ã¨ã«ç‹¬ç«‹ã«ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ã„ã‚‹ã€‚<br><br>- Pivot-only training: pivotè¨€èªï¼ˆä»Šå›ã¯è‹±èªï¼‰ã®ã¿ã§å­¦ç¿’ã—ãŸå ´åˆ <br><br>- Monolingual response training: pivotè¨€èªã¨targetè¨€èªã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã—ãŸå ´åˆ<br><br>- Code Switching: Monolingual response trainingã«åŠ ãˆã¦ã€pivotè¨€èªã¨targetè¨€èªã®input/outputã‚’ãã‚Œãã‚Œå…¥ã‚Œæ›¿ãˆãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ãŸå ´åˆï¼ˆi.e. pivotè¨€èª input-targetè¨€èª output, targetè¨€èª input-pivotè¨€èª outputã®ãƒšã‚¢ã‚’ä½œæˆã—å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«åˆ©ç”¨ã—ã¦ã„ã‚‹ï¼‰<br><br>- Auxiliary translation tasks: Monolingual respones trainingã«åŠ ãˆã¦ã€ç¿»è¨³ã‚¿ã‚¹ã‚¯ã‚’å®šç¾©ã—å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦åŠ ãˆãŸå ´åˆã€‚ã™ãªã‚ã¡ã€input, outputãã‚Œãã‚Œã«å¯¾ã—ã¦ã€pivotè¨€èªã‹ã‚‰targetè¨€èªã¸ã®ç¿»è¨³ã®ã‚µãƒ³ãƒ—ãƒ« ([P_trans;x^p], x^tï¼‰ã¨ï¼ˆ[P_trans;y^p], y^tï¼‰ã‚’åŠ ãˆã¦å­¦ç¿’ã—ã¦ã„ã‚‹ã€‚ã“ã“ã§ã€P_transã¯ç¿»è¨³ã‚’æŒ‡ç¤ºã™ã‚‹promptã§ã€;ã¯æ–‡å­—åˆ—ã®concatnationã€‚x^p, y^p, x^t, y^tã¯ãã‚Œãã‚Œã€pivotè¨€èªã®input, outputã€targetè¨€èªã®input, outputã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ã™ã€‚<br><br>- PLUGï¼ˆææ¡ˆæ‰‹æ³•ï¼‰: Pivot-only Trainingã«åŠ ãˆã¦ã€targetè¨€èªã®inputã‹ã‚‰ã€pivotè¨€èªã®input/output -&gt; targetè¨€èªã®outputã‚’concatã—ãŸãƒ†ã‚­ã‚¹ãƒˆ(x^t, [x^p;y^p;y^t]) ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«åŠ ãˆãŸå ´åˆ<br><br><br><br>è©•ä¾¡ã™ã‚‹éš›ã¯ã€MT-Bench <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/903" target="_blank" rel="noopener noreferrer">Judging LLM-as-a-judge with MT-Bench and Chatbot Arena, Lianmin Zheng+, N/A, NeurIPS'23</a>
 ã®ã‚ˆã†ã«ã€GPT4ã‚’ç”¨ã„ãŸã€direct pair-wise comparisonã‚’è¡Œã£ã¦ã„ã‚‹ã€‚<br><br>direct pair-wise comparisonã¯ã€2ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ä¸ãˆã¦LLMã«ä½•ã‚‰ã‹ã®åˆ¤æ–­ã‚„ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’ã•ã›ã‚‹æ–¹æ³•ã§ã‚ã‚Šã€ä»Šå›ã¯ã©ã¡ã‚‰ãŒinstructionã«ã‚ˆã‚Šå¾“ã£ã¦ã„ã‚‹ã‹ã«å‹æ•—/å¼•ãåˆ†ã‘ã‚’GPT4ã«åˆ¤æ–­ã•ã›ã¦ã„ã‚‹ã€‚LLMã«ã‚ˆã‚‹ç”Ÿæˆã¯ã‚µãƒ³ãƒ—ãƒ«ã®é †ç•ªã«sensitiveãªã®ã§ã€é †ç•ªã‚’é€†ã«ã—ãŸå ´åˆã§ã‚‚å®Ÿé¨“ã‚’ã—ã¦ã€win-lose rateã‚’æ±‚ã‚ã¦ã„ã‚‹ã€‚1ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ãƒšã‚¢ã«å¯¾ã—ã¦ã€ã‚µãƒ³ãƒ—ãƒ«ã®é †ç•ªã‚’æ­£é †ã¨é€†é †ã®2å›è©•ä¾¡ã•ã›ã€ãã®åŒæ–¹ã®çµæœã‚’ç”¨ã„ã¦æœ€çµ‚çš„ãªwin/lose/tieã‚’æ±ºã‚ã¦ã„ã‚‹ã€‚ç«¯çš„ã«è¨€ã†ã¨ã€å‹æ•—ãŒ2-0ãªã‚‰ãã®ã‚µãƒ³ãƒ—ãƒ«ã®å‹ã¡ã€åŒæ§˜ã«1-1ãªã‚‰å¼•ãåˆ†ã‘ã€0-2ãªã‚‰è² ã‘ã€ã¨ã„ã†ã“ã¨ã§ã‚ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/726ea2dc-8f62-4320-8489-45cc20ed32ae" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<span class="issue_date">Issue Date: 2024-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1398" target="_blank" rel="noopener noreferrer" class="title-link">When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of  Self-Correction of LLMs, Ryo Kamoi+, N_A, TACL'24</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±ä¿®æ­£ã¯LLMsã®å¿œç­”ã‚’æ”¹å–„ã™ã‚‹æ‰‹æ³•ã§ã‚ã‚Šã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æºã®åˆ©ç”¨ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ãŒã€èª¤ã‚Šä¿®æ­£ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«ã¤ã„ã¦ã¯åˆæ„ãŒå¾—ã‚‰ã‚Œã¦ã„ãªã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€è‡ªå·±ä¿®æ­£ã«å¿…è¦ãªæ¡ä»¶ã‚’è­°è«–ã—ã€å¾“æ¥ã®ç ”ç©¶ã®å•é¡Œç‚¹ã‚’æŒ‡æ‘˜ã€‚æ–°ãŸã«åˆ†é¡ã—ãŸç ”ç©¶èª²é¡Œã«åŸºã¥ãã€è‡ªå·±ä¿®æ­£ãŒæˆåŠŸã—ãŸä¾‹ãŒãªã„ã“ã¨ã€ä¿¡é ¼ã§ãã‚‹å¤–éƒ¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ã€å¤§è¦æ¨¡ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒåŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®self-correctionã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ™ã‚¤</p>
<p><img src="https://github.com/user-attachments/assets/bea63e03-8b6f-4c3e-b8ff-d738c062149c" alt="image" loading="lazy"></p>
<p><img src="https://github.com/user-attachments/assets/5701c2b8-bab1-4da4-af89-fa116f8848d0" alt="image" loading="lazy"></p>
<p><img src="https://github.com/user-attachments/assets/c3095388-52a5-40d6-ad18-235fd6a831f9" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/SyntheticDataGeneration.html" target="_blank" rel="noopener noreferrer">#SyntheticDataGeneration</a>
<span class="issue_date">Issue Date: 2024-09-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1393" target="_blank" rel="noopener noreferrer" class="title-link">Source2Synth: Synthetic Data Generation and Curation Grounded in Real  Data Sources, Alisia Lupidi+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ–°æ‰‹æ³•ã€ŒSource2Synthã€ã‚’ææ¡ˆã—ã€LLMã«æ–°ã—ã„ã‚¹ã‚­ãƒ«ã‚’æ•™ãˆã‚‹ã€‚äººé–“ã®æ³¨é‡ˆã«ä¾å­˜ã›ãšã€å®Ÿä¸–ç•Œã®ã‚½ãƒ¼ã‚¹ã«åŸºã¥ã„ãŸåˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€ä½å“è³ªãªç”Ÿæˆç‰©ã‚’å»ƒæ£„ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è³ªã‚’å‘ä¸Šã€‚ãƒãƒ«ãƒãƒ›ãƒƒãƒ—è³ªå•å¿œç­”ã¨è¡¨å½¢å¼ã®è³ªå•å¿œç­”ã«é©ç”¨ã—ã€WikiSQLã§25.51%ã€HotPotQAã§22.57%ã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã«é–¢ã™ã‚‹ç ”ç©¶ã€‚<br>ã‚½ãƒ¼ã‚¹ã‹ã‚‰QAã‚’ç”Ÿæˆã—ã€2ã¤ã®sliceã«åˆ†ã‘ã‚‹ã€‚ç‰‡æ–¹ã‚’LLMã®finetuningï¼ˆLLMSynthï¼‰ã«åˆ©ç”¨ã—ã€ã‚‚ã†ç‰‡æ–¹ã‚’finetuningã—ãŸLLMã§è§£ç­”å¯èƒ½æ€§ã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆcurationï¼‰ã™ã‚‹ã€‚<br>æœ€çµ‚çš„ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ç”Ÿæˆã•ã‚ŒãŸé«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã§LLMã‚’finetuningã™ã‚‹ã€‚<br><br>Curationã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§finetuningã—ãŸãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¯ã€Curationã—ã¦ã„ãªã„ãŸã ã®åˆæˆãƒ‡ãƒ¼ã‚¿ã¨æ¯”ã¹ã¦ã€MultiHopQA, TableQAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/4aabfa32-6461-447f-b11d-a0875603fd08" alt="image" loading="lazy"><br><br>ç”»åƒã¯å…ƒãƒã‚¹ãƒˆã‚ˆã‚Šå¼•ç”¨<br><br>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1834402693995024453?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MultiHopQAã®åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆæ–¹æ³•<br><img src="https://github.com/user-attachments/assets/853935be-1515-4064-bd08-3c0fe6a948a5" alt="image" loading="lazy"><br><br>TableQAã®åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆæ–¹æ³•<br><img src="https://github.com/user-attachments/assets/8f85bdf7-2de0-451a-a013-55cf0bcc167c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2024-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1392" target="_blank" rel="noopener noreferrer" class="title-link">Training Large Language Models for Reasoning through Reverse Curriculum   Reinforcement Learning, Zhiheng Xi+, N_A, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- R$^3$ã¯ã€çµæœã®ç›£è¦–ã‚’ç”¨ã„ã¦å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’æœ€é©åŒ–ã™ã‚‹æ–°æ‰‹æ³•ã€‚æ­£ã—ã„ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰å­¦ã¶ã“ã¨ã§ã€æ®µéšçš„ãªã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã‚’ç¢ºç«‹ã—ã€ã‚¨ãƒ©ãƒ¼ã‚’ç‰¹å®šå¯èƒ½ã«ã™ã‚‹ã€‚Llama2-7Bã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã¯ã€8ã¤ã®æ¨è«–ã‚¿ã‚¹ã‚¯ã§RLã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å¹³å‡4.1ãƒã‚¤ãƒ³ãƒˆä¸Šå›ã‚Šã€ç‰¹ã«GSM8Kã§ã¯4.2ãƒã‚¤ãƒ³ãƒˆã®æ”¹å–„ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2024-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1391" target="_blank" rel="noopener noreferrer" class="title-link">ReFT: Reasoning with Reinforced Fine-Tuning, Trung Quoc Luong+, N_A, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆReFTï¼‰ã‚’ææ¡ˆã—ã€LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã€‚SFTã§ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¾Œã€PPOã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ã¦ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ã‚’è¡Œã„ã€è±Šå¯Œãªæ¨è«–ãƒ‘ã‚¹ã‚’è‡ªå‹•ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€‚GSM8Kã€MathQAã€SVAMPãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§SFTã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€è¿½åŠ ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è³ªå•ã«ä¾å­˜ã›ãšå„ªã‚ŒãŸä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’ç™ºæ®ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2024-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1386" target="_blank" rel="noopener noreferrer" class="title-link">From Decoding to Meta-Generation: Inference-time Algorithms for Large  Language Models, Sean Welleck+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ¨è«–æ™‚ã®è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹æ‹¡å¤§ã®åˆ©ç‚¹ã«ç„¦ç‚¹ã‚’å½“ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ç”Ÿæˆã€ãƒ¡ã‚¿ç”Ÿæˆã€åŠ¹ç‡çš„ç”Ÿæˆã®3ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’çµ±ä¸€çš„ã«æ¢æ±‚ã€‚ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ç”Ÿæˆã¯ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ã€ãƒ¡ã‚¿ç”Ÿæˆã¯ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚„å¤–éƒ¨æƒ…å ±ã‚’æ´»ç”¨ã—ã€åŠ¹ç‡çš„ç”Ÿæˆã¯ã‚³ã‚¹ãƒˆå‰Šæ¸›ã¨é€Ÿåº¦å‘ä¸Šã‚’ç›®æŒ‡ã™ã€‚å¾“æ¥ã®è‡ªç„¶è¨€èªå‡¦ç†ã€ç¾ä»£ã®LLMsã€æ©Ÿæ¢°å­¦ç¿’ã®è¦–ç‚¹ã‚’çµ±åˆã—ãŸèª¿æŸ»ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1833522477605261799?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>CMUã®ãƒãƒ¼ãƒ ã«ã‚ˆã‚‹inference timeã®é«˜é€ŸåŒ–ã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ™ã‚¤</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<span class="issue_date">Issue Date: 2024-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1385" target="_blank" rel="noopener noreferrer" class="title-link">Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with  100+ NLP Researchers, Chenglei Si+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMã¨NLPå°‚é–€å®¶ã«ã‚ˆã‚‹ç ”ç©¶ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆã®æ¯”è¼ƒã‚’è¡Œã„ã€LLMãŒç”Ÿæˆã—ãŸã‚¢ã‚¤ãƒ‡ã‚¢ã®æ–°è¦æ€§ãŒäººé–“ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚ˆã‚Šé«˜ã„ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸãŒã€å®Ÿç¾å¯èƒ½æ€§ã¯ã‚„ã‚„åŠ£ã‚‹ã¨è©•ä¾¡ã•ã‚Œã¾ã—ãŸã€‚ã¾ãŸã€LLMã®è‡ªå·±è©•ä¾¡ã‚„ç”Ÿæˆã®å¤šæ§˜æ€§ã«é–¢ã™ã‚‹å•é¡Œã‚’ç‰¹å®šã—ã€ç ”ç©¶è€…ãŒã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ç ”ç©¶ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMãŒã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è€ƒãˆãŸæ–¹ãŒã€79äººã®researcherã«blind reviewã•ã›ã¦è©•ä¾¡ã—ãŸçµæœã€Noveltyã‚¹ã‚³ã‚¢ãŒæœ‰æ„ã«é«˜ããªã£ãŸï¼ˆãŸã ã—ã€feasibilityã¯äººæ‰‹ã§è€ƒãˆãŸå ´åˆã®æ–¹ãŒé«˜ã„ï¼‰ã¨ã„ã†è©±ã‚‰ã—ã„ã€‚<br><br>ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆã«ã©ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã€promptingã‚’åˆ©ç”¨ã—ãŸã‹ã¯ã¾ã èª­ã‚ã¦ã„ãªã„ã€‚<br><br><img src="https://github.com/user-attachments/assets/c7a1726c-5d7c-4275-9f67-d51e5767173b" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<span class="issue_date">Issue Date: 2024-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1381" target="_blank" rel="noopener noreferrer" class="title-link">A Survey on Human Preference Learning for Large Language Models, Ruili Jiang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“ã®å¥½ã¿å­¦ç¿’ã«åŸºã¥ãLLMsã®é€²å±•ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¥½ã¿ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ã‚½ãƒ¼ã‚¹ã‚„å½¢å¼ã€ãƒ¢ãƒ‡ãƒªãƒ³ã‚°æŠ€è¡“ã€è©•ä¾¡æ–¹æ³•ã‚’æ•´ç†ã€‚ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã«åŸºã¥ããƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®åˆ†é¡ã‚„ã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç‚¹ãƒ»æ¬ ç‚¹ã‚’æ¯”è¼ƒã—ã€LLMsã®äººé–“ã®æ„å›³ã¨ã®æ•´åˆæ€§ã«é–¢ã™ã‚‹å±•æœ›ã‚’è­°è«–ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<span class="issue_date">Issue Date: 2024-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1378" target="_blank" rel="noopener noreferrer" class="title-link">Automatically Correcting Large Language Models: Surveying the landscape  of diverse self-correction strategies, Liangming Pan+, N_A, TACL'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ€§èƒ½ã¯é«˜ã„ãŒã€å¹»è¦šã‚„ä¸èª å®Ÿãªæ¨è«–ãªã©ã®å•é¡ŒãŒå­˜åœ¨ã™ã‚‹ã€‚è‡ªå·±ä¿®æ­£ãŒæœ‰æœ›ãªè§£æ±ºç­–ã§ã‚ã‚Šã€è‡ªå‹•ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§äººé–“ã®ä»‹å…¥ã‚’æœ€å°é™ã«æŠ‘ãˆãŸå®Ÿç”¨çš„ãªLLMã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ãŒå¯èƒ½ã«ãªã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€ç”Ÿæˆã€äº‹å¾Œä¿®æ­£ã®å„æ®µéšã«ãŠã‘ã‚‹æŠ€è¡“ã‚’åˆ†æã—ã€ä¸»è¦ãªå¿œç”¨ã¨ä»Šå¾Œã®èª²é¡Œã«ã¤ã„ã¦è­°è«–ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/8049b03d-927b-49ee-98eb-7b690b92c229" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<span class="issue_date">Issue Date: 2024-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1377" target="_blank" rel="noopener noreferrer" class="title-link">Self-Reflection in LLM Agents: Effects on Problem-Solving Performance, Matthew Renze+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è‡ªå·±åçœãŒå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å•é¡Œè§£æ±ºãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã€‚9ã¤ã®LLMã«é¸æŠè‚¢å•é¡Œã‚’è§£ã‹ã›ã€èª¤ç­”ã«å¯¾ã—ã¦è‡ªå·±åçœå‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ”¹å–„ç­–ã‚’æä¾›ã—å†å›ç­”ã‚’è©¦ã¿ãŸçµæœã€è‡ªå·±åçœã«ã‚ˆã‚Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒæœ‰æ„ã«å‘ä¸Šã—ãŸï¼ˆ$p &lt; 0.001$ï¼‰ã€‚ã•ã¾ã–ã¾ãªè‡ªå·±åçœã®ã‚¿ã‚¤ãƒ—ã‚’æ¯”è¼ƒã—ã€ãã‚Œãã‚Œã®å¯„ä¸ã‚‚æ˜ã‚‰ã‹ã«ã—ãŸã€‚å…¨ã¦ã®ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã¯GitHubã§å…¬é–‹ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2024-09-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1372" target="_blank" rel="noopener noreferrer" class="title-link">The Prompt Report: A Systematic Survey of Prompting Techniques, Sander Schulhoff+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ç”Ÿæˆçš„äººå·¥çŸ¥èƒ½ï¼ˆGenAIï¼‰ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«é–¢ã™ã‚‹æ§‹é€ çš„ç†è§£ã‚’ç¢ºç«‹ã™ã‚‹ãŸã‚ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŠ€è¡“ã®åˆ†é¡æ³•ã‚’ææ¡ˆã—ã€33ã®èªå½™ç”¨èªã¨58ã®ãƒ†ã‚­ã‚¹ãƒˆå°‚ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŠ€è¡“ã‚’æç¤ºã€‚ã•ã‚‰ã«ã€è‡ªç„¶è¨€èªãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«é–¢ã™ã‚‹æ–‡çŒ®ã®ãƒ¡ã‚¿åˆ†æã‚’å®Ÿæ–½ã€‚</span>
<span class="snippet"><span>Comment</span><p>Promptingã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ™ã‚¤</p>
<p>åˆæœŸã®æ‰‹æ³•ã‹ã‚‰ã‹ãªã‚Šç¶²ç¾…çš„ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/a6e6fd6c-910c-4d5d-a98e-47cf51e254ab" alt="image" loading="lazy"></p>
<p>ã¾ãŸã€èª¤ç”¨ã•ã‚Œã¦ã„ãŸã‚Šã€è‰²ã€…ãªæ„å‘³åˆã„ã§ä½¿ã‚ã‚Œã¦ã—ã¾ã£ã¦ã„ã‚‹ç”¨èªã‚’ã€ãã¡ã‚“ã¨å®šç¾©ã—ã¦ã„ã‚‹ã€‚<br>ãŸã¨ãˆã°ã€Few shot Learningã¨Few shot Promptingã®é•ã„ã€ãã‚‚ãã‚‚Promptingã®å®šç¾©ã€Examplarãªã©ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2024-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1371" target="_blank" rel="noopener noreferrer" class="title-link">Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?, Zorik Gekhman+, N_A, EMNLP'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é€šã˜ã¦æ–°ã—ã„äº‹å®Ÿæƒ…å ±ã«é­é‡ã™ã‚‹ãŒã€æ—¢å­˜ã®çŸ¥è­˜ã‚’æ´»ç”¨ã™ã‚‹èƒ½åŠ›ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã€‚ç ”ç©¶ã§ã¯ã€é–‰ã˜ãŸæ›¸ç±ã®QAã‚’ç”¨ã„ã¦æ–°ã—ã„çŸ¥è­˜ã‚’å°å…¥ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã®å‰²åˆã‚’å¤‰åŒ–ã•ã›ãŸçµæœã€ãƒ¢ãƒ‡ãƒ«ã¯æ–°ã—ã„çŸ¥è­˜ã‚’å­¦ç¿’ã™ã‚‹ã®ã«è‹¦åŠ´ã—ã€å¹»è¦šã™ã‚‹å‚¾å‘ãŒå¢—åŠ ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚‹æ–°ã—ã„çŸ¥è­˜ã®å°å…¥ã®ãƒªã‚¹ã‚¯ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯äº‹å‰å­¦ç¿’ã‚’é€šã˜ã¦çŸ¥è­˜ã‚’ç²å¾—ã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ãã®åˆ©ç”¨ã‚’åŠ¹ç‡åŒ–ã™ã‚‹ã“ã¨ãŒæ”¯æŒã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pre-trainingæ™‚ã«ç²å¾—ã•ã‚Œã¦ã„ãªã„æƒ…å ±ã‚’ç”¨ã„ã¦LLMã®alignmentã‚’å®Ÿæ–½ã™ã‚‹ã¨ã€çŸ¥è­˜ãŒãªã„çŠ¶æ…‹ã§å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æ­£ã—ãäºˆæ¸¬ã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã¦ã—ã¾ã†ãŸã‚ã€äº‹å®Ÿã«åŸºã¥ã‹ãªã„å›ç­”ã‚’ã™ã‚‹ï¼ˆã¤ã¾ã‚Šhallucinationï¼‰ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã¦ã—ã¾ã†ã€ã¨ã„ã£ãŸã“ã¨ã‚’èª¿æŸ»ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br><br><br>&gt;æ–°ã—ã„çŸ¥è­˜ã‚’å°å…¥ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã¨ä¸€è‡´ã™ã‚‹ä¾‹ã‚ˆã‚Šã‚‚ã¯ã‚‹ã‹ã«é…ãå­¦ç¿’ã•ã‚Œã¾ã™ã€‚ã—ã‹ã—ã€æ–°ã—ã„çŸ¥è­˜ã‚’æŒã¤ä¾‹ãŒæœ€çµ‚çš„ã«å­¦ç¿’ã•ã‚Œã‚‹ã«ã¤ã‚Œã¦ã€ãƒ¢ãƒ‡ãƒ«ã®å¹»è¦šã™ã‚‹å‚¾å‘ãŒç·šå½¢ã«å¢—åŠ ã™ã‚‹ã“ã¨ã‚‚ç™ºè¦‹ã—ã¾ã—ãŸã€‚<br><br><img src="https://github.com/user-attachments/assets/9c7b3e2e-3ecb-4d71-a7fc-09fa7e57a613" alt="image" loading="lazy"><br><br><br><br>æ—©ã€…ã«overfittingã—ã¦ã„ã‚‹ã€‚<br><br><br><br>&gt;å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ä¸»ã«äº‹å‰å­¦ç¿’ã‚’é€šã˜ã¦äº‹å®ŸçŸ¥è­˜ã‚’å–å¾—ã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ãã‚Œã‚’ã‚ˆã‚ŠåŠ¹ç‡çš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’æ•™ãˆã‚‹ã¨ã„ã†è¦‹è§£ã‚’æ”¯æŒã—ã¦ã„ã¾ã™ã€‚<br><br><br><br>ãªã‚‹ã»ã©ã€èˆˆå‘³æ·±ã„ã€‚</p>
<p>ä¸‹è¨˜ç”»åƒã¯ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1370" target="_blank" rel="noopener noreferrer">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« (LLM) ã®æŠ€è¡“ã¨æœ€æ–°å‹•å‘, Ikuya Yamada, 2024.06</a>
ã‚ˆã‚Šå¼•ç”¨<br><br><img src="https://github.com/user-attachments/assets/e08d47cf-b550-4ced-a6bd-02d90d3684e9" alt="image" loading="lazy"><br><br><br><br>æœ¬è«–æ–‡ä¸­ã§ã¯ã€full finetuningã«ã‚ˆã‚‹æ¤œè¨¼ã‚’å®Ÿæ–½ã—ã¦ãŠã‚Šã€LoRAã®ã‚ˆã†ãªAdapterã‚’ç”¨ã„ãŸãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã§æ¤œè¨¼ã¯ã•ã‚Œã¦ã„ãªã„ã€‚LoRAã§ã¯ã‚‚ã¨ã‚‚ã¨ã®LLMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯freezeã•ã‚Œã‚‹ãŸã‚ã€ç•°ãªã‚‹æŒ™å‹•ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ç‰¹ã«LoRAãŒæ–°ã—ã„çŸ¥è­˜ã‚’ç²å¾—å¯èƒ½ãªã“ã¨ãŒç¤ºã•ã‚Œã‚Œã°ã€LoRA Adapterã‚’ã‚‚ã¨ã‚‚ã¨ã®LLMã«ä»˜ã‘æ›¿ãˆã‚‹ã ã‘ã§ã€ç•°ãªã‚‹çŸ¥è­˜ã‚’æŒã£ãŸLLMã‚’é‹ç”¨å¯èƒ½ã«ãªã‚‹ãŸã‚ã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒå¤§ãã„ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚ã‚‚ã¨ã‚‚ã¨ã“ã†ã„ã£ãŸæ€æƒ³ã¯ LoRA Hubã‚’æå”±ã™ã‚‹ç ”ç©¶ãªã©ã®é ƒã‹ã‚‰ã‚ã£ãŸæ°—ãŒã™ã‚‹ãŒã€Adapterã«ã‚ˆã£ã¦Hallucination/overfittingã‚’é˜²ããªãŒã‚‰ã€æ–°ãŸãªçŸ¥è­˜ã‚’ç²å¾—ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸç ”ç©¶ã¯ã‚ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ<br><br><img src="https://github.com/user-attachments/assets/a05a3662-baf9-4fcd-b15e-440f1c2c9f6e" alt="image" loading="lazy"><br><br></p>
<p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1792334744522485954?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LoRAã®å ´åˆã«ã¤ã„ã¦ã¯<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1640" target="_blank" rel="noopener noreferrer">LoRA Learns Less and Forgets Less, Dan Biderman+, TMLR'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
<br><br>ã‚‚å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2024-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1362" target="_blank" rel="noopener noreferrer" class="title-link">What Do Language Models Learn in Context? The Structured Task Hypothesis, Jiaoda Li+, N_A, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…å­¦ç¿’ï¼ˆICLï¼‰èƒ½åŠ›ã‚’èª¬æ˜ã™ã‚‹3ã¤ã®ä»®èª¬ã«ã¤ã„ã¦ã€ä¸€é€£ã®å®Ÿé¨“ã‚’é€šã˜ã¦æ¢ç©¶ã€‚æœ€åˆã®2ã¤ã®ä»®èª¬ã‚’ç„¡åŠ¹ã«ã—ã€æœ€å¾Œã®ä»®èª¬ã‚’æ”¯æŒã™ã‚‹è¨¼æ‹ ã‚’æä¾›ã€‚LLMãŒäº‹å‰å­¦ç¿’ä¸­ã«å­¦ç¿’ã—ãŸã‚¿ã‚¹ã‚¯ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…ã§æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’å­¦ç¿’ã§ãã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>SNLP2024ã§ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:<br>


<a href="http://chasen.org/~daiti-m/paper/SNLP2024-Task-Emergence.pdf" target="_blank" rel="noopener noreferrer">http://chasen.org/~daiti-m/paper/SNLP2024-Task-Emergence.pdf</a>


</p>
<p>ICLãŒä½•ã‚’ã‚„ã£ã¦ã„ã‚‹ã®ã‹?ã«ã¤ã„ã¦ã€ã“ã‚Œã¾ã§ã®ä»®èª¬ãŒæ­£ã—ããªã„ã“ã¨ã‚’å®Ÿé¨“çš„ã«ç¤ºã—ã€æ–°ã—ã„ä»®èª¬ã€ŒICLã¯äº‹å‰å­¦ç¿’ã§å¾—ã‚‰ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’çµ„ã¿åˆã‚ã›ã¦æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’è§£ã„ã¦ã„ã‚‹ã€ã‚’æå”±ã—ã€ã“ã®ä»®èª¬ãŒæ­£ã—ã„ã“ã¨ã‚’ç¤ºå”†ã™ã‚‹å®Ÿé¨“çµæœã‚’å¾—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br>ç†è«–çš„ã«è§£æ˜ã•ã‚ŒãŸã‚ã‘ã§ã¯ãªã•ãã†ãªã®ã§ãã“ã¯ç•™æ„ã—ãŸæ–¹ãŒè‰¯ã•ãã†ã€‚ã‚ã¨ã§ã—ã£ã‹ã‚Šèª­ã‚€ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/GrammaticalErrorCorrection.html" target="_blank" rel="noopener noreferrer">#GrammaticalErrorCorrection</a>
<span class="issue_date">Issue Date: 2024-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1351" target="_blank" rel="noopener noreferrer" class="title-link">Prompting open-source and commercial language models for grammatical  error correction of English learner text, Christopher Davis+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®é€²æ­©ã«ã‚ˆã‚Šã€æµæš¢ã§æ–‡æ³•çš„ãªãƒ†ã‚­ã‚¹ãƒˆç”ŸæˆãŒå¯èƒ½ã«ãªã‚Šã€ä¸æ–‡æ³•ãªå…¥åŠ›æ–‡ã‚’ä¸ãˆã‚‹ã“ã¨ã§æ–‡æ³•ã‚¨ãƒ©ãƒ¼ä¿®æ­£ï¼ˆGECï¼‰ãŒå¯èƒ½ã¨ãªã£ãŸã€‚æœ¬ç ”ç©¶ã§ã¯ã€7ã¤ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨3ã¤ã®å•†ç”¨LLMsã‚’4ã¤ã®GECãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§è©•ä¾¡ã—ã€å•†ç”¨ãƒ¢ãƒ‡ãƒ«ãŒå¸¸ã«æ•™å¸«ã‚ã‚Šã®è‹±èªGECãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã‚ã‘ã§ã¯ãªã„ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒå•†ç”¨ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒã‚ã‚Šã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ãŒãƒ•ãƒ¥ãƒ¼ã‚·ãƒ§ãƒƒãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã¨åŒã˜ãã‚‰ã„ç«¶äº‰åŠ›ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chemical_tree/status/1822860849935253882?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<span class="issue_date">Issue Date: 2024-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1350" target="_blank" rel="noopener noreferrer" class="title-link">The AI Scientist: Towards Fully Automated Open-Ended Scientific  Discovery, Chris Lu+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ€å…ˆç«¯ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€å®Œå…¨è‡ªå‹•ã®ç§‘å­¦çš„ç™ºè¦‹ã‚’å¯èƒ½ã«ã™ã‚‹åŒ…æ‹¬çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒææ¡ˆã•ã‚ŒãŸã€‚AI Scientistã¯æ–°ã—ã„ç ”ç©¶ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç”Ÿæˆã—ã€ã‚³ãƒ¼ãƒ‰ã‚’è¨˜è¿°ã—ã€å®Ÿé¨“ã‚’å®Ÿè¡Œã—ã€çµæœã‚’å¯è¦–åŒ–ã—ã€å®Œå…¨ãªç§‘å­¦è«–æ–‡ã‚’åŸ·ç­†ã—ã€æŸ»èª­ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€æ©Ÿæ¢°å­¦ç¿’ã«ãŠã‘ã‚‹ç§‘å­¦çš„ç™ºè¦‹ã®æ–°ã—ã„æ™‚ä»£ã®å§‹ã¾ã‚Šã‚’ç¤ºã—ã¦ãŠã‚Šã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¤‰é©çš„ãªåˆ©ç‚¹ã‚’AIè‡ªä½“ã®ç ”ç©¶ãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã«ã‚‚ãŸã‚‰ã—ã€ä¸–ç•Œã§æœ€ã‚‚é›£ã—ã„å•é¡Œã«ç„¡é™ã®æ‰‹é ƒãªä¾¡æ ¼ã®å‰µé€ æ€§ã¨ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è§£ãæ”¾ã¤ã“ã¨ã«è¿‘ã¥ã„ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<span class="issue_date">Issue Date: 2024-07-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1341" target="_blank" rel="noopener noreferrer" class="title-link">Following Length Constraints in Instructions, Weizhe Yuan+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¢ãƒ©ã‚¤ãƒ³ã•ã‚ŒãŸå‘½ä»¤ã«å¾“ã†ãƒ¢ãƒ‡ãƒ«ã¯ã€éã‚¢ãƒ©ã‚¤ãƒ³ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’ã‚ˆã‚Šã‚ˆãæº€ãŸã™ã“ã¨ãŒã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€ã“ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã«ã¯é•·ã•ã®ãƒã‚¤ã‚¢ã‚¹ãŒã‚ã‚Šã€è¨“ç·´ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯é•·ã„å¿œç­”ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã“ã®ãƒã‚¤ã‚¢ã‚¹ã‚’åˆ©ç”¨ã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ¨è«–æ™‚ã«æ‰€æœ›ã®é•·ã•åˆ¶ç´„ã‚’å«ã‚€å‘½ä»¤ã§åˆ¶å¾¡ã§ãã‚‹ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚ã“ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã¯ã€é•·ã•æŒ‡ç¤ºã•ã‚ŒãŸè©•ä¾¡ã«ãŠã„ã¦å„ªã‚Œã¦ãŠã‚Šã€GPT4ã€Llama 3ã€Mixtralãªã©ã®æ¨™æº–çš„ãªå‘½ä»¤ã«å¾“ã†ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã£ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>SoTA LLMãŒOutputé•·ã®åˆ¶ç´„ã«å¾“ã‚ãªã„ã“ã¨ã‚’ç¤ºã—ã€ãã‚Œã‚’æ”¹å–„ã™ã‚‹å­¦ç¿’æ‰‹æ³•LIFT-DPOã‚’ææ¡ˆ<img src="https://github.com/user-attachments/assets/1002ae4a-66b2-4125-8cbb-3a2a8484da56" alt="image" loading="lazy"><br><br></p>
<p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1805771223747481690?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2024-07-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1338" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FlashAttention-3: Fast and Accurate Attention with Asynchrony and   Low-precision, Jay Shah+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- FlashAttention-3ã¯ã€Hopper GPUä¸Šã§Attentionã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã«ã€3ã¤ã®æŠ€è¡“ã‚’é–‹ç™ºã—ã€H100 GPUã§1.5-2.0å€ã®é€Ÿåº¦å‘ä¸Šã‚’å®Ÿç¾ã€‚FP16ã§740 TFLOPs/sã€FP8ã§ç´„1.2 PFLOPs/sã«é”ã—ã€FP8ã§ã¯æ•°å€¤èª¤å·®ãŒ2.6å€ä½ã„ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=tVConYid20&referrer=%5Bthe%20profile%20of%20Tri%20Dao%5D(%2Fprofile%3Fid%3D~Tri_Dao1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=tVConYid20&referrer=%5Bthe%20profile%20of%20Tri%20Dao%5D(%2Fprofile%3Fid%3D~Tri_Dao1)</a>


</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2024-07-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1337" target="_blank" rel="noopener noreferrer" class="title-link">A Systematic Survey of Prompt Engineering in Large Language Models:  Techniques and Applications, Pranab Sahoo+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¯ã€LLMsã‚„VLMsã®èƒ½åŠ›ã‚’æ‹¡å¼µã™ã‚‹ãŸã‚ã®é‡è¦ãªæŠ€è¡“ã§ã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã›ãšã«ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®æŒ‡ç¤ºã§ã‚ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ´»ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®åŠ¹æœã‚’å‘ä¸Šã•ã›ã‚‹ã€‚æœ¬ç ”ç©¶ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®æœ€è¿‘ã®é€²å±•ã«ã¤ã„ã¦æ§‹é€ åŒ–ã•ã‚ŒãŸæ¦‚è¦ã‚’æä¾›ã—ã€å„æ‰‹æ³•ã®å¼·ã¿ã¨åˆ¶é™ã«ã¤ã„ã¦æ˜ã‚Šä¸‹ã’ã‚‹ã“ã¨ã§ã€ã“ã®åˆ†é‡ã‚’ã‚ˆã‚Šã‚ˆãç†è§£ã—ã€å°†æ¥ã®ç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/9c41dcc4-6b88-47ae-9032-1daca6bfee65" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-04-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1293" target="_blank" rel="noopener noreferrer" class="title-link">Phi-3 Technical Report: A Highly Capable Language Model Locally on Your  Phone, Marah Abdin+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- phi-3-miniã¯38å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€3.3å…†ãƒˆãƒ¼ã‚¯ãƒ³ã§è¨“ç·´ã•ã‚Œã¦ã„ã¾ã™ã€‚Mixtral 8x7Bã‚„GPT-3.5ãªã©ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã«åŒ¹æ•µã™ã‚‹ç·åˆçš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æŒã¡ãªãŒã‚‰ã€ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã«ãƒ‡ãƒ—ãƒ­ã‚¤å¯èƒ½ãªã‚µã‚¤ã‚ºã§ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€å³å¯†ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸWebãƒ‡ãƒ¼ã‚¿ã¨åˆæˆãƒ‡ãƒ¼ã‚¿ã§æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€å …ç‰¢æ€§ã€å®‰å…¨æ€§ã€ãŠã‚ˆã³ãƒãƒ£ãƒƒãƒˆå½¢å¼ã«é©åˆã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€phi-3-smallã¨phi-3-mediumã¨ã„ã†ã‚ˆã‚Šå¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã‚‚ç´¹ä»‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1039" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need II: phi-1.5 technical report, Yuanzhi Li+, N/A, arXiv'23</a>
 ã®æ¬¡ã®æ¬¡ï¼ˆPhi2.0ã«ã¤ã„ã¦ã¯ãƒ¡ãƒ¢ã£ã¦ãªã‹ã£ãŸï¼‰ã€‚ã‚¹ãƒãƒ›ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã‚‹ãƒ¬ãƒ™ãƒ«ã®ã‚µã‚¤ã‚ºã§ã€GPT3.5Turboç¨‹åº¦ã®æ€§èƒ½ã‚’å®Ÿç¾ã—ãŸã‚‰ã—ã„</p>
<p>Llama2ã¨åŒã˜ãƒ–ãƒ­ãƒƒã‚¯ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯Llama2ã¨å…±é€šã€‚<br><br></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Pruning.html" target="_blank" rel="noopener noreferrer">#Pruning</a>
<span class="issue_date">Issue Date: 2024-04-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1292" target="_blank" rel="noopener noreferrer" class="title-link">The Unreasonable Ineffectiveness of the Deeper Layers, Andrey Gromov+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ä¸€èˆ¬çš„ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆã®äº‹å‰å­¦ç¿’ã•ã‚ŒãŸLLMã®ãƒ¬ã‚¤ãƒ¤ãƒ¼å‰ªå®šæˆ¦ç•¥ã‚’ç ”ç©¶ã—ã€ç•°ãªã‚‹è³ªå•å¿œç­”ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ä½ä¸‹ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æœ€å¤§åŠåˆ†ã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ã§ã€æœ€é©ãªãƒ–ãƒ­ãƒƒã‚¯ã‚’ç‰¹å®šã—ã€å¾®èª¿æ•´ã—ã¦æå‚·ã‚’ä¿®å¾©ã—ã¾ã™ã€‚PEFTæ‰‹æ³•ã‚’ä½¿ç”¨ã—ã€å®Ÿé¨“ã‚’å˜ä¸€ã®A100 GPUã§å®Ÿè¡Œå¯èƒ½ã«ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šæ¸›ã—ã€æ¨è«–ã®ãƒ¡ãƒ¢ãƒªã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’æ”¹å–„ã§ãã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¾ã™ã€‚ã¾ãŸã€LLMãŒãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å‰Šé™¤ã«å¯¾ã—ã¦å …ç‰¢ã§ã‚ã‚‹ã“ã¨ã¯ã€æµ…ã„ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒçŸ¥è­˜ã‚’æ ¼ç´ã™ã‚‹ä¸Šã§é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¦ã„ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä¸‹è¨˜ãƒ„ã‚¤ãƒ¼ãƒˆã«ã‚ˆã‚‹ã¨ã€å­¦ç¿’æ¸ˆã¿LLMã‹ã‚‰ã€ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§å…¥å‡ºåŠ›é–“ã®é¡ä¼¼åº¦ãŒé«˜ã„å±¤ã‚’é™¤ã„ã¦ã‚‚ã‚¿ã‚¹ã‚¯ã®ç²¾åº¦ãŒè½ã¡ãšã€ç‰¹ã«æ·±ã„å±¤ã‚’2-4å‰²å‰Šé™¤ã—ã¦ã‚‚ç²¾åº¦ãŒè½ã¡ãªã„ã¨ã®ã“ã¨ã€‚<br><br>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1773110076502368642?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>VRAMã«è¼‰ã›ã‚‹ã®ãŒå¤§å¤‰ãªã®ã§ã€ã“ã®ã‚ˆã†ãªæåˆˆã‚ŠæŠ€è¡“ãŒæœ‰åŠ¹ã ã¨åˆ†ã‹ã‚‹ã®ã¯ã‚ã‚ŠãŒãŸã„ã€‚LoRAã‚„é‡å­åŒ–ã‚‚åˆ©ç”¨ã—ã¦ã„ã‚‹ã£ã½ã„ã€‚</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2024-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1284" target="_blank" rel="noopener noreferrer" class="title-link">Knowledge Conflicts for LLMs: A Survey, Rongwu Xu+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã«ãŠã‘ã‚‹çŸ¥è­˜ã®è¡çªã«ç„¦ç‚¹ã‚’å½“ã¦ã€æ–‡è„ˆã¨ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯çŸ¥è­˜ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚‹è¤‡é›‘ãªèª²é¡Œã‚’åˆ†æã€‚æ–‡è„ˆ-ãƒ¡ãƒ¢ãƒªã€æ–‡è„ˆé–“ã€ãƒ¡ãƒ¢ãƒªå†…ã®è¡çªã®3ã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’æ¢æ±‚ã—ã€å®Ÿä¸–ç•Œã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹ä¿¡é ¼æ€§ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¸ã®å½±éŸ¿ã‚’æ¤œè¨ã€‚è§£æ±ºç­–ã‚’ææ¡ˆã—ã€LLMsã®å …ç‰¢æ€§å‘ä¸Šã‚’ç›®æŒ‡ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<span class="issue_date">Issue Date: 2024-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1283" target="_blank" rel="noopener noreferrer" class="title-link">Quiet-STaR: Language Models Can Teach Themselves to Think Before  Speaking, Eric Zelikman+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- STaRï¼ˆSelf-Taught Reasonerï¼‰ã§ã¯ã€å°‘æ•°ã®ä¾‹ã‹ã‚‰åˆç†çš„ãªæ¨è«–ã‚’å­¦ç¿’ã—ã€è³ªå•å¿œç­”ã«æ´»ç”¨ã™ã‚‹æ–¹æ³•ãŒææ¡ˆã•ã‚ŒãŸã€‚Quiet-STaRã§ã¯ã€LMãŒåˆç†æ€§ã‚’ç”Ÿæˆã™ã‚‹æ–¹æ³•ã‚’å­¦ç¿’ã—ã€é›£ã—ã„è³ªå•ã«ç›´æ¥ç­”ãˆã‚‹èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ã“ã®æ‰‹æ³•ã¯ã€GSM8Kã‚„CommonsenseQAãªã©ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®æ”¹å–„ã‚’å®Ÿç¾ã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒä¸è¦ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚Quiet-STaRã¯ã€æ¨è«–ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã®ä¸€èˆ¬çš„ã§ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªæ–¹æ³•ã‚’æä¾›ã™ã‚‹ä¸€æ­©ã¨ãªã£ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>o1(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1390" target="_blank" rel="noopener noreferrer">OpenAI o1, 2024.09</a>
)ã®åŸºç¤æŠ€è¡“ã¨ä¼¼ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹<br>å…ˆè¡Œç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1397" target="_blank" rel="noopener noreferrer">STaR: Bootstrapping Reasoning With Reasoning, Eric Zelikman+, N/A, NeurIPS'22</a>
</p>
<p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1835449666588271046?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2024-04-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1275" target="_blank" rel="noopener noreferrer" class="title-link">Visualization-of-Thought Elicits Spatial Reasoning in Large Language  Models, Wenshan Wu+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®ç©ºé–“æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€Visualization-of-Thoughtï¼ˆVoTï¼‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã‚’ææ¡ˆã€‚VoTã¯ã€LLMsã®æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å¯è¦–åŒ–ã—ã€ç©ºé–“æ¨è«–ã‚¿ã‚¹ã‚¯ã§ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€æ—¢å­˜ã®MLLMsã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚VoTã¯ã€ç©ºé–“æ¨è«–ã‚’ä¿ƒé€²ã™ã‚‹ãŸã‚ã«ã€Œãƒ¡ãƒ³ã‚¿ãƒ«ã‚¤ãƒ¡ãƒ¼ã‚¸ã€ã‚’ç”Ÿæˆã™ã‚‹èƒ½åŠ›ã‚’æŒã¡ã€MLLMsã§ã®æœ‰åŠ¹æ€§ã‚’ç¤ºå”†ã™ã‚‹ã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ContextWindow.html" target="_blank" rel="noopener noreferrer">#ContextWindow</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1274" target="_blank" rel="noopener noreferrer" class="title-link">Long-context LLMs Struggle with Long In-context Learning, Tianle Li+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å‡¦ç†ã™ã‚‹èƒ½åŠ›ã«é€²å±•ã—ã¦ã„ã‚‹ãŒã€å®Ÿä¸–ç•Œã®ã‚·ãƒŠãƒªã‚ªã§ã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®å°‚é–€çš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯LongICLBenchãŒå°å…¥ã•ã‚ŒãŸã€‚ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯ã€LLMsã¯å·¨å¤§ãªãƒ©ãƒ™ãƒ«ç©ºé–“ã‚’ç†è§£ã—ã€æ­£ã—ã„äºˆæ¸¬ã‚’è¡Œã†ãŸã‚ã«å…¥åŠ›å…¨ä½“ã‚’ç†è§£ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ç ”ç©¶ã«ã‚ˆã‚‹ã¨ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆLLMsã¯é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§æ¯”è¼ƒçš„è‰¯ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ãŒã€æœ€ã‚‚å›°é›£ãªã‚¿ã‚¹ã‚¯ã§ã¯è‹¦åŠ´ã—ã¦ã„ã‚‹ã€‚ç¾åœ¨ã®LLMsã¯é•·ãã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè±Šã‹ãªã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å‡¦ç†ã—ç†è§£ã™ã‚‹èƒ½åŠ›ã«ã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ãŠã‚Šã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ç†è§£ã¨æ¨è«–ã¯ä¾ç„¶ã¨ã—ã¦é›£ã—ã„èª²é¡Œã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>GPT4ä»¥å¤–ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒ20Kã‚’è¶…ãˆã‚‹ã¨æ€§èƒ½ãŒåŠ£åŒ–ã™ã‚‹å‚¾å‘ã«ã‚ã‚‹ã¨ã®ã“ã¨ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é›£æ˜“åº¦åˆ¥ã«åé›†ã—è©•ä¾¡ã—ãŸã¨ã“ã‚ã€é›£æ˜“åº¦ã®é«˜ã„ãƒ‡ãƒ¼ã‚¿ã§ã¯ãã‚‚ãã‚‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ããªã‚‹ã¨å…¨ã¦ã®LLMãŒã‚¿ã‚¹ã‚¯ã‚’ç†è§£ã™ã‚‹ã§ããšã»ã¼0%ã®æ€§èƒ½ã¨ãªã£ãŸã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fc51d83a-3013-4fcc-bf7a-5722eb01d0d8" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1273" target="_blank" rel="noopener noreferrer" class="title-link">Mixture-of-Depths: Dynamically allocating compute in transformer-based  language models, David Raposo+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Transformerãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€å…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å…¨ä½“ã«å‡ç­‰ã«FLOPsã‚’åˆ†æ•£ã•ã›ã‚‹ä»£ã‚ã‚Šã«ã€ç‰¹å®šã®ä½ç½®ã«FLOPsã‚’å‹•çš„ã«å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ã‚’å­¦ç¿’ã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®æ·±ã•ã«ã‚ãŸã£ã¦å‰²ã‚Šå½“ã¦ã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã«ã€ç•°ãªã‚‹ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§è¨ˆç®—ã‚’å‹•çš„ã«å‰²ã‚Šå½“ã¦ã‚‹ã€‚ã“ã®æ‰‹æ³•ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³ã®æ•°ã‚’åˆ¶é™ã™ã‚‹ã“ã¨ã§åˆè¨ˆè¨ˆç®—äºˆç®—ã‚’å¼·åˆ¶ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ã¯top-kãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä½¿ç”¨ã—ã¦æ±ºå®šã•ã‚Œã‚‹ã€‚ã“ã®æ–¹æ³•ã«ã‚ˆã‚Šã€FLOPsã‚’å‡ç­‰ã«æ¶ˆè²»ã—ã¤ã¤ã€è¨ˆç®—ã®æ”¯å‡ºãŒäºˆæ¸¬å¯èƒ½ã§ã‚ã‚Šã€å‹•çš„ã‹ã¤ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æ•æ„Ÿã§ã‚ã‚‹ã€‚ã“ã®ã‚ˆã†ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€è¨ˆç®—ã‚’å‹•çš„ã«å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ã‚’å­¦ç¿’ã—ã€åŠ¹ç‡çš„ã«è¡Œã†ã“ã¨ãŒã§ãã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theseamouse/status/1775782800362242157?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1270" target="_blank" rel="noopener noreferrer" class="title-link">Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference, Piotr Nawrot+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®ç”ŸæˆåŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€Dynamic Memory Compressionï¼ˆDMCï¼‰ãŒææ¡ˆã•ã‚ŒãŸã€‚DMCã¯ã€ç•°ãªã‚‹ãƒ˜ãƒƒãƒ‰ã¨ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ç•°ãªã‚‹åœ§ç¸®ç‡ã‚’é©ç”¨ã™ã‚‹æ–¹æ³•ã‚’å­¦ç¿’ã—ã€äº‹å‰å­¦ç¿’æ¸ˆã¿LLMsã«é©ç”¨ã•ã‚Œã‚‹ã€‚DMCã¯ã€å…ƒã®ä¸‹æµãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æœ€å¤§4å€ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥åœ§ç¸®ã§ç¶­æŒã—ã¤ã¤ã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚DMCã¯ã€GQAã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã•ã‚‰ãªã‚‹åˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ãŒã‚ã‚Šã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨å¤§ããªãƒãƒƒãƒã‚’å‡¦ç†ã™ã‚‹éš›ã«æœ‰ç”¨ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1776755029581676943?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è«–æ–‡ä¸­ã®Figure1ãŒéå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d416547e-f9ca-4c6c-8ebb-7d164bef5283" alt="image" loading="lazy"><br><br></p>
<p>GQA <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
 ã¨æ¯”è¼ƒã—ã¦ã€2~4å€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åœ§ç¸®ã—ã¤ã¤ã€ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’å®Ÿç¾ã€‚70Bãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯ã€GQAã§8å€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åœ§ç¸®ã—ãŸä¸Šã§ã€DMCã§è¿½åŠ ã§2å€åœ§ç¸®ã‚’ã‹ã‘ãŸã¨ã“ã‚ã€åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7b131f07-5eab-4830-88cc-5f6fd0508958" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1269" target="_blank" rel="noopener noreferrer" class="title-link">RAFT: Adapting Language Model to Domain Specific RAG, Tianjun Zhang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®LLMsã‚’äº‹å‰å­¦ç¿’ã—ã€æ–°ã—ã„çŸ¥è­˜ã‚’è¿½åŠ ã™ã‚‹ãŸã‚ã®Retrieval Augmented FineTuningï¼ˆRAFTï¼‰ã‚’ææ¡ˆã€‚RAFTã¯ã€è³ªå•ã«å›ç­”ã™ã‚‹ã®ã«å½¹ç«‹ã¤é–¢é€£æ–‡æ›¸ã‹ã‚‰æ­£ã—ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å¼•ç”¨ã—ã€chain-of-thoughtã‚¹ã‚¿ã‚¤ãƒ«ã®å¿œç­”ã‚’é€šã˜ã¦æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚RAFTã¯PubMedã€HotpotQAã€Gorillaãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã€äº‹å‰å­¦ç¿’æ¸ˆã¿LLMsã‚’ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®RAGã«å‘ã‘ã¦æ”¹å–„ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Question, instruction, coxtext, cot style answerã®4ã¤ã‚’ç”¨ã„ã¦SFTã‚’ã™ã‚‹æ¨¡æ§˜<br>ç”»åƒã¯ä¸‹è¨˜ãƒ„ã‚¤ãƒ¼ãƒˆã‚ˆã‚Šå¼•ç”¨<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0763b048-8029-4712-9e79-e833bdb9b2c0" alt="image" loading="lazy"><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cwolferesearch/status/1770912695765660139?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1268" target="_blank" rel="noopener noreferrer" class="title-link">RankPrompt: Step-by-Step Comparisons Make Language Models Better  Reasoners, Chi Hu+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯æ¨è«–ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã¦ã„ã‚‹ãŒã€è«–ç†ã‚¨ãƒ©ãƒ¼ãŒèµ·ã“ã‚Šã‚„ã™ã„ã€‚RankPromptã¨ã„ã†æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æ–¹æ³•ã‚’å°å…¥ã—ã€LLMsãŒè‡ªå·±ãƒ©ãƒ³ã‚¯ä»˜ã‘ã‚’è¡Œã„æ¨è«–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“ã§ã¯ã€RankPromptãŒChatGPTã‚„GPT-4ã®æ¨è«–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’13%å‘ä¸Šã•ã›ã€AlpacaEvalãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§äººé–“ã®åˆ¤æ–­ã¨74%ã®ä¸€è‡´ç‡ã‚’ç¤ºã™ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚RankPromptã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é«˜å“è³ªãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å¼•ãå‡ºã™åŠ¹æœçš„ãªæ–¹æ³•ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã€‚å¤§é‡ã®å€™è£œã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã™ã‚‹ã®ã¯å›°é›£ã ã¨æ€ã‚ã‚Œã‚‹ãŒã€ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°æ‰‹æ³•ã¨ã—ã¦ã¯åˆ©ç”¨ã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7115515c-10a2-44ae-9e48-86258cc11aed" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2024-03-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1250" target="_blank" rel="noopener noreferrer" class="title-link">OLMo: Accelerating the Science of Language Models, Dirk Groeneveld+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LMsã®å•†æ¥­çš„é‡è¦æ€§ãŒé«˜ã¾ã‚‹ä¸­ã€æœ€ã‚‚å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã¯é–‰é–ã•ã‚Œã¦ãŠã‚Šã€ãã®è©³ç´°ãŒéå…¬é–‹ã«ãªã£ã¦ã„ã‚‹ã€‚ãã®ãŸã‚ã€æœ¬æŠ€è¡“ãƒ¬ãƒãƒ¼ãƒˆã§ã¯ã€æœ¬å½“ã«ã‚ªãƒ¼ãƒ—ãƒ³ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹OLMoã®åˆå›ãƒªãƒªãƒ¼ã‚¹ã¨ã€è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®ç§‘å­¦ã‚’æ§‹ç¯‰ã—ç ”ç©¶ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã¤ã„ã¦è©³ç´°ã«èª¬æ˜ã—ã¦ã„ã‚‹ã€‚OLMoã¯ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã ã‘ã§ãªãã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŠã‚ˆã³è©•ä¾¡ã‚³ãƒ¼ãƒ‰ã‚’å«ã‚€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯å…¨ä½“ã‚’å…¬é–‹ã—ã¦ãŠã‚Šã€ã‚ªãƒ¼ãƒ—ãƒ³ãªç ”ç©¶ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’å¼·åŒ–ã—ã€æ–°ã—ã„ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Model Weightsã‚’å…¬é–‹ã™ã‚‹ã ã‘ã§ãªãã€training/evaluation codeã¨ãã®ãƒ‡ãƒ¼ã‚¿ã‚‚å…¬é–‹ã™ã‚‹çœŸã«Openãªè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆtruly Open Language Modelï¼‰ã€‚AllenAI</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2024-03-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1247" target="_blank" rel="noopener noreferrer" class="title-link">Chain-of-Thought Reasoning Without Prompting, Xuezhi Wang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ç„¦ç‚¹ã‚’å½“ã¦ãŸç ”ç©¶ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€LLMsãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãªã—ã§åŠ¹æœçš„ã«æ¨è«–ã§ãã‚‹ã‹ã©ã†ã‹ã‚’æ¤œè¨¼ã—ã€CoTæ¨è«–ãƒ‘ã‚¹ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§å¼•ãå‡ºã™æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€å¾“æ¥ã®è²ªæ¬²ãªãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ãªãã€ä»£æ›¿ãƒˆãƒ¼ã‚¯ãƒ³ã‚’èª¿æŸ»ã™ã‚‹ã“ã¨ã§CoTãƒ‘ã‚¹ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ãŠã‚Šã€æ§˜ã€…ãªæ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ‰åŠ¹æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä»¥å‰ã«CoTã‚’å†…éƒ¨çš„ã«è‡ªå‹•çš„ã«å®Ÿæ–½ã•ã‚Œã‚‹ã‚ˆã†ã«äº‹å‰å­¦ç¿’æ®µéšã§å­¦ç¿’ã™ã‚‹ã€ã¨ã„ã£ãŸè©±ãŒã‚ã£ãŸã¨æ€ã†ãŒã€ã“ã®ç ”ç©¶ã¯ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ–¹æ³•ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã€promptingã§æ˜ç¤ºçš„ã«instructionã‚’å®Ÿæ–½ã›ãšã¨ã‚‚ã€CoTã‚’å®Ÿç¾ã™ã‚‹ã‚‚ã®ã€ã¨ã„ã†ã“ã¨ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/afb3a31e-3d85-4b7e-affa-fccc00b7321e" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2024-03-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1245" target="_blank" rel="noopener noreferrer" class="title-link">LoRA+: Efficient Low Rank Adaptation of Large Models, Soufiane Hayou+, N_A, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Huã‚‰ï¼ˆ2021ï¼‰ã«ã‚ˆã£ã¦å°å…¥ã•ã‚ŒãŸLow Rank Adaptationï¼ˆLoRAï¼‰ãŒã€å¤§åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã®é©åˆ‡ãªå¾®èª¿æ•´ã‚’å¦¨ã’ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã—ã¾ã™ã€‚ã“ã®å•é¡Œã¯ã€LoRAã®ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ãƒãƒˆãƒªãƒƒã‚¯ã‚¹Aã¨BãŒåŒã˜å­¦ç¿’ç‡ã§æ›´æ–°ã•ã‚Œã‚‹ã“ã¨ã«èµ·å› ã—ã¾ã™ã€‚æˆ‘ã€…ã¯ã€Aã¨Bã«åŒã˜å­¦ç¿’ç‡ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒåŠ¹ç‡çš„ãªç‰¹å¾´å­¦ç¿’ã‚’å¦¨ã’ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ç•°ãªã‚‹å­¦ç¿’ç‡ã‚’è¨­å®šã™ã‚‹ã“ã¨ã§ã“ã®å•é¡Œã‚’ä¿®æ­£ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ä¿®æ­£ã•ã‚ŒãŸã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’LoRA$+$ã¨å‘¼ã³ã€å¹…åºƒã„å®Ÿé¨“ã«ã‚ˆã‚Šã€LoRA$+$ã¯æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã€å¾®èª¿æ•´é€Ÿåº¦ã‚’æœ€å¤§2å€é«˜é€ŸåŒ–ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LoRAã§å°å…¥ã•ã‚Œã‚‹ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—Aã¨Bã‚’ç•°ãªã‚‹å­¦ç¿’ç‡ã§å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€LoRAã¨åŒã˜è¨ˆç®—ã‚³ã‚¹ãƒˆã§ã€2å€ä»¥ä¸Šã®é«˜é€ŸåŒ–ã€ã‹ã¤é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã™ã‚‹æ‰‹æ³•<br><br><img src="https://github.com/user-attachments/assets/cde925fa-bfe8-4385-ae55-d80f7bf034f5" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/c054c5a6-56a2-4aa5-b7f2-0ae87a808f58" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/f32a7aba-e4b1-4d28-920d-00f81e9b85e8" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Annotation.html" target="_blank" rel="noopener noreferrer">#Annotation</a>
<span class="issue_date">Issue Date: 2024-03-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1244" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models for Data Annotation: A Survey, Zhen Tan+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- GPT-4ãªã©ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ç ”ç©¶ã«ç„¦ç‚¹ã‚’å½“ã¦ã€LLMã«ã‚ˆã‚‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆã®è©•ä¾¡ã‚„å­¦ç¿’ã¸ã®å¿œç”¨ã«ã¤ã„ã¦è¿°ã¹ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚LLMã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®æ‰‹æ³•ã‚„èª²é¡Œã«ã¤ã„ã¦åŒ…æ‹¬çš„ã«è­°è«–ã—ã€å°†æ¥ã®ç ”ç©¶ã®é€²å±•ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Data Annotationã«LLMã‚’æ´»ç”¨ã™ã‚‹å ´åˆã®ã‚µãƒ¼ãƒ™ã‚¤</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<span class="issue_date">Issue Date: 2024-03-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1243" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Modelsï¼ˆLLMsï¼‰ on Tabular Data: Prediction, Generation, and  Understanding -- A Survey, Xi Fang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®é€²å±•ã«ã‚ˆã‚Šã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹å¿œç”¨ãŒå®¹æ˜“ã«ãªã£ã¦ã„ã‚‹ãŒã€åŒ…æ‹¬çš„ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚ã“ã®ç ”ç©¶ã¯ã€æœ€è¿‘ã®é€²æ­©ã‚’ã¾ã¨ã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€æ–¹æ³•è«–ã‚’èª¿æŸ»ã—ã€å°†æ¥ã®ç ”ç©¶æ–¹å‘ã«æ´å¯Ÿã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€é–¢é€£ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å‚ç…§ã‚‚æä¾›ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Tabular Dataã«ãŠã‘ã‚‹LLMé–¢é€£ã®ã‚¿ã‚¹ã‚¯ã‚„æŠ€è¡“ç­‰ã®ã‚µãƒ¼ãƒ™ã‚¤</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2024-02-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1235" target="_blank" rel="noopener noreferrer" class="title-link">User-LLM: Efficient LLM Contextualization with User Embeddings, Lin Ning+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã‚’æ´»ç”¨ã—ãŸUser-LLMãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒææ¡ˆã•ã‚ŒãŸã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¦LLMsã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ä½ç½®ä»˜ã‘ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å‹•çš„ã«é©å¿œã™ã‚‹ã“ã¨ãŒå¯èƒ½ã«ãªã‚‹ã€‚åŒ…æ‹¬çš„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€è‘—ã—ã„æ€§èƒ½å‘ä¸ŠãŒç¤ºã•ã‚Œã€Perceiverãƒ¬ã‚¤ãƒ¤ãƒ¼ã®çµ„ã¿è¾¼ã¿ã«ã‚ˆã‚Šè¨ˆç®—åŠ¹ç‡ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>next item prediction, favorite genre or category predictimnreview generationãªã©ã§è©•ä¾¡ã—ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1225" target="_blank" rel="noopener noreferrer" class="title-link">MM-LLMs: Recent Advances in MultiModal Large Language Models, Duzhen Zhang+, N_A, ACL'24 Findings</a>
<span class="snippet"><span>GPT Summary</span>- MM-LLMsã¯ã€ã‚³ã‚¹ãƒˆåŠ¹æœã®é«˜ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã‚’ç”¨ã„ã¦æ‹¡å¼µã•ã‚Œã€å¤šæ§˜ãªMMã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã™ã‚‹èƒ½åŠ›ã‚’æŒã¤ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€MM-LLMsã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãªã©ã«ã¤ã„ã¦èª¿æŸ»ã—ã€ãã®é€²æ­©ã«è²¢çŒ®ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹ã€è«–æ–‡ã‚’æ–œã‚èª­ã¿ã—ãªãŒã‚‰ã€ChatGPTã‚’é€šã˜ã¦ç–‘å•ç‚¹ã‚’è§£æ¶ˆã—ã¤ã¤ç†è§£ã—ãŸå†…å®¹ãªã®ã§ã€ç†è§£ãŒä¸ååˆ†ãªç‚¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§æ³¨æ„ã€‚<br><br><br><br>ã¾ã‚ã–ã£ãã‚Šè¨€ã†ã¨ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚’ç†è§£ã§ãã‚‹LLMã‚’ä½œã‚ŠãŸã‹ã£ãŸã‚‰ã€æ§˜ã€…ãªãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦å¾—ã‚‰ã‚Œã‚‹è¡¨ç¾ã¨ã€æ—¢å­˜ã®LLMãŒå†…éƒ¨çš„ã«å‡¦ç†å¯èƒ½ãªè¡¨ç¾ã‚’å¯¾å¿œã¥ã‘ã‚‹ Input Projectorã¨ã„ã†åã®é–¢æ•°ã‚’å­¦ç¿’ã™ã‚Œã°ã„ã„ã ã‘ã ã‚ˆï¼ˆãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã€LLMã¯äº‹å‰å­¦ç¿’ã•ã‚ŒãŸã‚‚ã®ã‚’ãã®ã¾ã¾freezeã—ã¦ä½¿ãˆã°è‰¯ã„ï¼‰ã€‚<br><br><br><br>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚’ç”Ÿæˆã§ãã‚‹LLMã‚’ä½œã‚ŠãŸã‹ã£ãŸã‚‰ã€LLMãŒãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã ã‘ã§ãªãã€æ§˜ã€…ãªãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«å¯¾å¿œã™ã‚‹è¡¨ç¾ã‚‚è¿½åŠ ã§å‡ºåŠ›ã™ã‚‹ã‚ˆã†ã«ã—ã¦ã€ãã®å‡ºåŠ›ã‚’å„ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’ç”Ÿæˆã§ãã‚‹ãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã§ãã‚‹ã‚ˆã†ã«å¤‰æ›ã™ã‚‹Output Projectortã¨ã„ã†åã®é–¢æ•°ã‚’å­¦ç¿’ã—ã‚ˆã†ã­ã€ã¨ã„ã†ã“ã¨ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br><br><br># æ¦‚è¦<br><br>&lt;img width="1093" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/c12f621b-95e6-4bff-827b-c4c5cf43b532"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/c12f621b-95e6-4bff-827b-c4c5cf43b532"&lt;/a&gt;


&gt;<br><br><br><br>## ãƒã‚¤ãƒ³ãƒˆ<br><br>- Modality Encoder, LLM Backboneã€ãŠã‚ˆã³Modality Generatorã¯ä¸€èˆ¬çš„ã«ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’freezeã™ã‚‹<br><br>- optimizationã®å¯¾è±¡ã¯ã€ŒInput/Output Projectorã€<br><br><br><br>## Modality Encoder<br><br>æ§˜ã€…ãªãƒ¢ãƒ€ãƒªãƒ†ã‚£I_Xã‚’ã€ç‰¹å¾´é‡F_Xã«å¤‰æ›ã™ã‚‹ã€‚ã“ã‚Œã¯ã¾ã‚ã€è‰²ã€…ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ã€‚<br><br>&lt;img width="195" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/578c3bbc-0183-4d62-bf98-ee1b1bc1109c"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/578c3bbc-0183-4d62-bf98-ee1b1bc1109c"&lt;/a&gt;


&gt;<br><br><br><br>## Input Projector<br><br>ãƒ¢ãƒ€ãƒªãƒ†ã‚£I_Xã¨ãã‚Œã«å¯¾å¿œã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆtã®ãƒ‡ãƒ¼ã‚¿ {I_X, t}ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€ãƒ†ã‚­ã‚¹ãƒˆtã‚’åŸ‹ã‚è¾¼ã¿è¡¨ç¾ã«å¤‰æ›ã‚“ã—ãŸçµæœå¾—ã‚‰ã‚Œã‚‹ç‰¹å¾´é‡ãŒF_Tã§ã‚ã‚‹ã€‚Input Projectorã¯ã€F_Xã‚’LLMã®inputã¨ã—ã¦åˆ©ç”¨ã™ã‚‹éš›ã«æœ€é©ãªç‰¹å¾´é‡P_Xã«å¤‰æ›ã™ã‚‹Î¸X_Tã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚ã“ã‚Œã¯ã€LLM(P_X, F_T)ã«ã‚ˆã£ã¦ãƒ†ã‚­ã‚¹ãƒˆtãŒã©ã‚Œã ã‘ç”Ÿæˆã§ããŸã‹ã€ã‚’è¡¨ç¾ã™ã‚‹æå¤±é–¢æ•°ã‚’æœ€å°åŒ–ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦å­¦ç¿’ã•ã‚Œã‚‹ã€‚<br><br>&lt;img width="451" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/a80f5453-b50f-48d5-8114-5f9f81544793"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a80f5453-b50f-48d5-8114-5f9f81544793"&lt;/a&gt;


&gt;<br><br><br><br>## LLM Backbone<br><br>LLMã«ã‚ˆã£ã¦ãƒ†ã‚­ã‚¹ãƒˆåˆ—tã¨ã€å„ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«å¯¾å¿œã—ãŸè¡¨ç¾ã§ã‚ã‚‹S_Xã‚’ç”Ÿæˆã™ã‚‹ã€‚outputã‹ã‚‰t, S_Xã‚’ã©ã®ã‚ˆã†ã«åŒºåˆ¥ã™ã‚‹ã‹ã¯ãƒ¢ãƒ‡ãƒ«ã®æ§‹é€ ãªã©ã«ã‚‚ã‚ˆã‚‹ãŒã€ãŸã¨ãˆã°ç•°ãªã‚‹ãƒ˜ãƒƒãƒ‰ã‚’ç”¨æ„ã—ã¦ã€t, S_Xã‚’åŒºåˆ¥ã™ã‚‹ã¨ã„ã£ãŸã“ã¨ã¯å¯èƒ½ã§ã‚ã‚ã†ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>&lt;img width="256" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/0be4e1c7-f92b-4259-a536-8ea135c1bcba"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0be4e1c7-f92b-4259-a536-8ea135c1bcba"&lt;/a&gt;


&gt;<br><br><br><br>## Output Projector<br><br>S_Xã‚’Modality GeneratorãŒè§£é‡ˆå¯èƒ½ãªç‰¹å¾´é‡H_Xã«å¤‰æ›ã™ã‚‹é–¢æ•°ã®ã“ã¨ã§ã‚ã‚‹ã€‚ã“ã‚Œã¯å­¦ç¿’ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚<br><br>H_Xã¨Modality Generatorã®textual encoderã«tã‚’å…¥åŠ›ã—ãŸéš›ã«å¾—ã‚‰ã‚Œã‚‹è¡¨ç¾Ï„X(t)ãŒè¿‘ããªã‚‹ã‚ˆã†ã«Output Projector Î¸_T_Xã‚’å­¦ç¿’ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã£ã¦ã€S_Xã¨Modality GeneratorãŒalignã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚<br><br>&lt;img width="356" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/faa87be0-e738-4dc1-8e52-0787d6b973e8"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/faa87be0-e738-4dc1-8e52-0787d6b973e8"&lt;/a&gt;


&gt;<br><br><br><br>## Modality Generator<br><br>å„Modalityã‚’H_Xã‹ã‚‰ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ä¸‹è¨˜ã®ã‚ˆã†ãªæå¤±å­¦ç¿’ã™ã‚‹ã€‚è¦ã¯ã€ç”Ÿæˆã•ã‚ŒãŸãƒ¢ãƒ€ãƒªãƒ†ã‚£ãƒ‡ãƒ¼ã‚¿ï¼ˆã¾ãŸã¯è¡¨ç¾ï¼‰ãŒå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã«ã©ã‚Œã ã‘è¿‘ã„ã‹ã€ã‚’è¡¨ã—ã¦ã„ã‚‹ã‚‰ã—ã„ã€‚å…·ä½“çš„ã«ã¯ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦å¾—ã‚‰ã‚ŒãŸãƒã‚¤ã‚ºã¨ã€ãƒ¢ãƒ‡ãƒ«ãŒæ¨å®šã—ãŸãƒã‚¤ã‚ºã®å€¤ãŒã©ã‚Œã ã‘è¿‘ã„ã‹ã‚’æ¸¬ã‚‹ã€ã¿ãŸã„ãªã“ã¨ã‚’ã—ã¦ã„ã‚‹ã‚‰ã—ã„ã€‚<br><br>&lt;img width="448" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/a18cfe29-27bf-42bf-8481-7e0afd838918"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a18cfe29-27bf-42bf-8481-7e0afd838918"&lt;/a&gt;


&gt;<br><br><br><br>Multi Modalã‚’ç†è§£ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã ã‘ã§ã‚ã‚Œã°ã€Input Projectorã®æå¤±ã®ã¿ãŒå­¦ç¿’ã•ã‚Œã€ç”Ÿæˆã¾ã§ã™ã‚‹ã®ã§ã‚ã‚Œã°ã€Input/Output Projector, Modality Generatorãã‚Œãã‚Œã«ç¤ºã—ãŸæå¤±é–¢æ•°ã‚’é€šã˜ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå­¦ç¿’ã•ã‚Œã‚‹ã€‚ã‚ã¨ã€P_Xã‚„ã‚‰S_Xã¯ã„ã‚ã‚†ã‚‹soft-promptingã¿ãŸã„ãªã‚‚ã®ã§ã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ProgressiveLearning.html" target="_blank" rel="noopener noreferrer">#ProgressiveLearning</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2024-01-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1219" target="_blank" rel="noopener noreferrer" class="title-link">LLaMA Pro: Progressive LLaMA with Block Expansion, Chengyue Wu+, N_A, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ–°ã—ã„äº‹å‰å­¦ç¿’å¾Œã®æ‰‹æ³•ã‚’ææ¡ˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã‚’åŠ¹æœçš„ã‹ã¤åŠ¹ç‡çš„ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€Transformerãƒ–ãƒ­ãƒƒã‚¯ã®æ‹¡å¼µã‚’ä½¿ç”¨ã—ã€æ–°ã—ã„ã‚³ãƒ¼ãƒ‘ã‚¹ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’èª¿æ•´ã—ã¾ã—ãŸã€‚å®Ÿé¨“ã®çµæœã€ææ¡ˆæ‰‹æ³•ã¯ã•ã¾ã–ã¾ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã€çŸ¥çš„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã“ã®ç ”ç©¶ã¯ã€è‡ªç„¶è¨€èªã¨ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã‚’çµ±åˆã—ã€é«˜åº¦ãªè¨€èªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é–‹ç™ºã«è²¢çŒ®ã™ã‚‹ã‚‚ã®ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>è¿½åŠ ã®çŸ¥è­˜ã‚’å°å…¥ã—ãŸã„ã¨ãã«ä½¿ãˆã‚‹ã‹ã‚‚?</p>
<p>äº‹å‰å­¦ç¿’ã—ãŸLLaMA Blockã«å¯¾ã—ã¦ã€è¿½åŠ ã®LLaMA Blockã‚’stackã—ã€ã‚‚ã¨ã‚‚ã¨ã®LLaMA Blockã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’freezeã—ãŸä¸Šã§ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ç‰¹åŒ–ã—ãŸã‚³ãƒ¼ãƒ‘ã‚¹ã§äº‹å¾Œå­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€è¿½åŠ ã®çŸ¥è­˜ã‚’æŒ¿å…¥ã™ã‚‹ã€‚LLaMA Blockã‚’æŒ¿å…¥ã™ã‚‹ã¨ãã¯ã€Linear Layerã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’0ã«ã™ã‚‹ã“ã¨ã§ã€RMSNormã«ãŠã‘ã‚‹å‹¾é…æ¶ˆå¤±ã®å•é¡Œã‚’é¿ã‘ãŸä¸Šã§ã€Identity Blockï¼ˆBlockã‚’è¿½åŠ ã—ãŸæ™‚ç‚¹ã§ã¯äº‹å‰å­¦ç¿’æ™‚ã¨åŒæ§˜ã®OutputãŒã•ã‚Œã‚‹ã“ã¨ãŒä¿è¨¼ã•ã‚Œã‚‹ï¼‰ã¨ã—ã¦æ©Ÿèƒ½ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0ef6cc84-da38-4254-9bb3-ea4e2f9ebfab" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a2bb221a-3ac3-4b81-9308-c114daf00401" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2024-01-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1217" target="_blank" rel="noopener noreferrer" class="title-link">A Comprehensive Survey of Hallucination Mitigation Techniques in Large  Language Models, S. M Towhidul Islam Tonmoy+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ï¼šæœ¬è«–æ–‡ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã‘ã‚‹å¹»è¦šã®å•é¡Œã«ã¤ã„ã¦èª¿æŸ»ã—ã€ãã®è»½æ¸›ç­–ã«ã¤ã„ã¦ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚LLMsã¯å¼·åŠ›ãªè¨€èªç”Ÿæˆèƒ½åŠ›ã‚’æŒã£ã¦ã„ã¾ã™ãŒã€æ ¹æ‹ ã®ãªã„æƒ…å ±ã‚’ç”Ÿæˆã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€Retrieval Augmented Generationã€Knowledge Retrievalã€CoNLIã€CoVeãªã©ã®æŠ€è¡“ãŒé–‹ç™ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ©ç”¨ã‚„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãªã©ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã“ã‚Œã‚‰ã®æ–¹æ³•ã‚’åˆ†é¡ã—ã€å¹»è¦šã®å•é¡Œã«å–ã‚Šçµ„ã‚€ãŸã‚ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ã“ã‚Œã‚‰ã®æŠ€è¡“ã«é–¢é€£ã™ã‚‹èª²é¡Œã‚„åˆ¶ç´„ã«ã¤ã„ã¦ã‚‚åˆ†æã—ã€å°†æ¥ã®ç ”ç©¶ã«å‘ã‘ãŸåŸºç›¤ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2024-01-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1216" target="_blank" rel="noopener noreferrer" class="title-link">Chain-of-Table: Evolving Tables in the Reasoning Chain for Table   Understanding, Zilong Wang+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã‚’ä½¿ç”¨ã—ãŸChain-of-Tableãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æ¨è«–ãƒã‚§ãƒ¼ãƒ³å†…ã§æ´»ç”¨ã—ã€ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ™ãƒ¼ã‚¹ã®æ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦é«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®é€£ç¶šçš„ãªé€²åŒ–ã‚’è¡¨ç¾ã—ã€ä¸­é–“çµæœã®æ§‹é€ åŒ–æƒ…å ±ã‚’åˆ©ç”¨ã—ã¦ã‚ˆã‚Šæ­£ç¢ºãªäºˆæ¸¬ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚ã•ã¾ã–ã¾ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Table, Question, Operation Historyã‹ã‚‰æ¬¡ã®operationã¨ãã®argsã‚’ç”Ÿæˆã—ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é †æ¬¡æ›´æ–°ã—ã€ã“ã‚Œã‚’ãƒ¢ãƒ‡ãƒ«ãŒæ›´æ–°ã®å¿…è¦ãŒç„¡ã„ã¨åˆ¤æ–­ã™ã‚‹ã¾ã§ç¹°ã‚Šè¿”ã™ã€‚æœ€çµ‚çš„ã«æ›´æ–°ã•ã‚ŒãŸTableã‚’ç”¨ã„ã¦Questionã«å›ç­”ã™ã‚‹æ‰‹æ³•ã€‚Questionã«å›ç­”ã™ã‚‹ãŸã‚ã«ã€è¤‡é›‘ãªãƒ†ãƒ¼ãƒ–ãƒ«ã«å¯¾ã™ã‚‹æ“ä½œãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦æœ‰åŠ¹ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/f23bdacf-ffc0-4d37-b992-62fea094c9d2" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/90ec4404-7ed0-4698-8223-15134b195977" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2024-01-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1213" target="_blank" rel="noopener noreferrer" class="title-link">Knowledge Fusion of Large Language Models, Fanqi Wan+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ—¢å­˜ã®äº‹å‰è¨“ç·´æ¸ˆã¿ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§ã€1ã¤ã®å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ç•°ãªã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æŒã¤3ã¤ã®äººæ°—ã®ã‚ã‚‹LLMsã‚’ä½¿ç”¨ã—ã¦ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã‚¿ã‚¹ã‚¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã—ã¾ã—ãŸã€‚ææ¡ˆæ‰‹æ³•ã®ã‚³ãƒ¼ãƒ‰ã€ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã€ãŠã‚ˆã³ãƒ‡ãƒ¼ã‚¿ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2024-01-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1212" target="_blank" rel="noopener noreferrer" class="title-link">Self-Rewarding Language Models, Weizhe Yuan+, N_A, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- å°†æ¥ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯è¶…äººçš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒå¿…è¦ã§ã‚ã‚Šã€è‡ªå·±å ±é…¬ã‚’æä¾›ã™ã‚‹Self-Rewarding Language Modelsã‚’ç ”ç©¶ã—ã¦ã„ã‚‹ã€‚LLM-as-a-Judgeãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€è¨€èªãƒ¢ãƒ‡ãƒ«è‡ªä½“ãŒè‡ªå·±å ±é…¬ã‚’æä¾›ã—ã€é«˜å“è³ªãªå ±é…¬ã‚’å¾—ã‚‹èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚Llama 2 70Bã‚’3å›ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§å¾®èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€æ—¢å­˜ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’ä¸Šå›ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã“ã®ç ”ç©¶ã¯ã€æ”¹å–„å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®å¯èƒ½æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>äººé–“ã®ä»‹å…¥ç„¡ã—ã§ï¼ˆäººé–“ãŒã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ãŸpreference dataç„¡ã—ã§ï¼‰LLMã®Alignmentã‚’æ”¹å–„ã—ã¦ã„ãæ‰‹æ³•ã€‚LLM-as-a-Judge Promptingã‚’ç”¨ã„ã¦ã€LLMè‡ªèº«ã«policy modelã¨reward modelã®å½¹å‰²ã®ä¸¡æ–¹ã‚’ã•ã›ã‚‹ã€‚unlabeledãªpromptã«å¯¾ã—ã¦policy modelã¨ã—ã¦responceã‚’ç”Ÿæˆã•ã›ãŸå¾Œã€ç”Ÿæˆã—ãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’reward modelã¨ã—ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»˜ã‘ã—ã€DPOã®preference pairã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã€ã¨ã„ã†æ“ä½œã‚’ç¹°ã‚Šè¿”ã™ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/32db0422-6fb1-4741-bdfa-45a5e83e76c4" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2024-01-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1208" target="_blank" rel="noopener noreferrer" class="title-link">The Impact of Reasoning Step Length on Large Language Models, Mingyu Jin+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Chain of Thoughtï¼ˆCoTï¼‰ã®æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã®é•·ã•ã¨LLMsã®æ¨è«–èƒ½åŠ›ã®é–¢ä¿‚ã‚’èª¿æŸ»ã—ãŸã€‚æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’å»¶é•·ã™ã‚‹ã¨ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ–°ã—ã„æƒ…å ±ã‚’è¿½åŠ ã›ãšã«LLMsã®æ¨è«–èƒ½åŠ›ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚é€†ã«ã€ã‚­ãƒ¼ã¨ãªã‚‹æƒ…å ±ã‚’ä¿æŒã—ãªãŒã‚‰æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’çŸ­ç¸®ã™ã‚‹ã¨ã€æ¨è«–èƒ½åŠ›ãŒä½ä¸‹ã™ã‚‹ã€‚ã¾ãŸã€èª¤ã£ãŸæ ¹æ‹ ã§ã‚‚æ¨è«–ã®å¿…è¦ãªé•·ã•ã‚’ä¿ã¤é™ã‚Šã€å¥½ã¾ã—ã„çµæœãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚ã•ã‚‰ã«ã€ã‚¿ã‚¹ã‚¯ã«ã‚ˆã£ã¦æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã®å¢—åŠ ã®åˆ©ç‚¹ãŒç•°ãªã‚‹ã“ã¨ã‚‚è¦³å¯Ÿã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-01-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1204" target="_blank" rel="noopener noreferrer" class="title-link">Mixtral of Experts, Albert Q. Jiang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Mixtralã¯ã€Sparse Mixture of Expertsï¼ˆSMoEï¼‰è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒ8ã¤ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚Mixtralã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ã«2ã¤ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’é¸æŠã—ã€ãã‚Œã‚‰ã®å‡ºåŠ›ã‚’çµ„ã¿åˆã‚ã›ã¾ã™ã€‚Mixtralã¯ã€Llama 2 70Bã¨GPT-3.5ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’æŒã¡ã€æ•°å­¦ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã€å¤šè¨€èªã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ç‰¹ã«å„ªã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€Mixtral 8x7B - Instructã¨ã„ã†æŒ‡ç¤ºã«å¾“ã†ãƒ¢ãƒ‡ãƒ«ã‚‚æä¾›ã•ã‚Œã¦ãŠã‚Šã€äººé–“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å‡Œé§•ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Mixture of experts Layer: inputã‚’å—ã‘å–ã£ãŸrouterãŒã€8ã¤ã®expertsã®ã†ã¡2ã¤ã‚’é¸æŠã—é †ä¼æ¬ã€‚2ã¤ã®expertsã®outputã‚’åŠ é‡å¹³å‡ã™ã‚‹ã“ã¨ã§æœ€çµ‚çš„ãªoutputã¨ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/52ca3ed3-714f-4bc2-af76-c6884fc37927" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2023-12-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1186" target="_blank" rel="noopener noreferrer" class="title-link">VILA: On Pre-training for Visual Language Models, Ji Lin+, N_A, CVPR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æˆåŠŸã«ã‚ˆã‚Šã€ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆVLMï¼‰ãŒé€²æ­©ã—ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€VLMã®äº‹å‰å­¦ç¿’ã®ãŸã‚ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æ¤œè¨ã—ã€ä»¥ä¸‹ã®çµæœã‚’ç¤ºã—ãŸï¼š(1) LLMã‚’å‡çµã™ã‚‹ã“ã¨ã§ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒé”æˆã§ãã‚‹ãŒã€æ–‡è„ˆã«åŸºã¥ã„ãŸå­¦ç¿’èƒ½åŠ›ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚(2) äº¤äº’ã«è¡Œã‚ã‚Œã‚‹äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯æœ‰ç›Šã§ã‚ã‚Šã€ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã®ãƒšã‚¢ã ã‘ã§ã¯æœ€é©ã§ã¯ãªã„ã€‚(3) ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã‚’ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã«å†ãƒ–ãƒ¬ãƒ³ãƒ‰ã™ã‚‹ã“ã¨ã§ã€VLMã®ã‚¿ã‚¹ã‚¯ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚VILAã¨ã„ã†ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’æ§‹ç¯‰ã—ã€æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã‚’å‡Œé§•ã—ã€å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã®äº‹å‰å­¦ç¿’ã¯ã€VILAã®ç‰¹æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1068" target="_blank" rel="noopener noreferrer">Improved Baselines with Visual Instruction Tuning, Haotian Liu+, N/A, CVPR'24</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<a class="button" href="articles/EACL.html" target="_blank" rel="noopener noreferrer">#EACL</a>
<a class="button" href="articles/System%20Demonstration.html" target="_blank" rel="noopener noreferrer">#System Demonstration</a>
<span class="issue_date">Issue Date: 2023-11-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1161" target="_blank" rel="noopener noreferrer" class="title-link">NeuroPrompts: An Adaptive Framework to Optimize Prompts for  Text-to-Image Generation, Shachar Rosenman+, N_A, EACL'24 Sustem Demonstration Track</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®å“è³ªã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®é©å¿œå‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯NeuroPromptsã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦åˆ¶ç´„ä»˜ããƒ†ã‚­ã‚¹ãƒˆãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è¡Œã„ã€äººé–“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒç”Ÿæˆã™ã‚‹ã‚‚ã®ã«é¡ä¼¼ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é«˜å“è³ªãªãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸ã®ç”ŸæˆãŒå¯èƒ½ã¨ãªã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã‚¹ã‚¿ã‚¤ãƒ«ã®ç‰¹å¾´ã‚’åˆ¶å¾¡ã§ãã¾ã™ã€‚ã¾ãŸã€å¤§è¦æ¨¡ãªäººé–“ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ãŸå®Ÿé¨“ã«ã‚ˆã‚Šã€å½“ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒè‡ªå‹•çš„ã«å“è³ªã®é«˜ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã€å„ªã‚ŒãŸç”»åƒå“è³ªã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2023-11-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1155" target="_blank" rel="noopener noreferrer" class="title-link">GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark, David Rein+, N_A, COLM'24</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€é«˜å“è³ªã§éå¸¸ã«å›°é›£ãªå¤šè‚¢é¸æŠå•é¡Œã‹ã‚‰ãªã‚‹GPQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€å°‚é–€å®¶ã§ã‚‚é«˜ã„æ­£ç­”ç‡ã‚’é”æˆã§ããšã€æœ€å…ˆç«¯ã®AIã‚·ã‚¹ãƒ†ãƒ ã§ã‚‚å›°é›£ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚å°†æ¥ã®AIã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã«ãŠã„ã¦ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªç›£ç£æ–¹æ³•ã‚’é–‹ç™ºã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¹ã‚­ãƒ«ã‚’æŒã¤ç›£ç£è€…ãŒAIã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ä¿¡é ¼æ€§ã®ã‚ã‚‹æƒ…å ±ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚GPQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªç›£ç£å®Ÿé¨“ã‚’å¯èƒ½ã«ã—ã€äººé–“ã®å°‚é–€å®¶ãŒAIã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰çœŸå®Ÿã®æƒ…å ±ã‚’ç¢ºå®Ÿã«å¾—ã‚‹æ–¹æ³•ã‚’è€ƒæ¡ˆã™ã‚‹ã®ã«å½¹ç«‹ã¤ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>è©²å½“é ˜åŸŸã®Ph.Dæ‰€æœ‰è€…ã§ã‚‚74%ã€é«˜ã„ã‚¹ã‚­ãƒ«ã‚’æŒã¤éå°‚é–€å®¶ï¼ˆGoogleã¸ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦è‰¯ã„ç’°å¢ƒï¼‰ã§34%ã—ã‹æ­£ç­”ã§ããªã„QAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚<br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/idavidrein/status/1727033002234909060?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=Ti67584b98" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Ti67584b98</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2023-11-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1140" target="_blank" rel="noopener noreferrer" class="title-link">Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language   Models, Wenhao Yu+, N_A, EMNLP'24</a>
<span class="snippet"><span>GPT Summary</span>- æ¤œç´¢è£œå®Œè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆRALMï¼‰ã¯ã€å¤–éƒ¨ã®çŸ¥è­˜æºã‚’æ´»ç”¨ã—ã¦å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ä¿¡é ¼æ€§ã®å•é¡Œã‚„çŸ¥è­˜ã®ä¸è¶³ã«ã‚ˆã‚‹èª¤ã£ãŸå›ç­”ãŒã‚ã‚‹ã€‚ãã“ã§ã€Chain-of-Notingï¼ˆCoNï¼‰ã¨ã„ã†æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å°å…¥ã—ã€RALMã®é ‘å¥æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚CoNã¯ã€é †æ¬¡ã®èª­ã¿å–ã‚Šãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã€é–¢é€£æ€§ã‚’è©•ä¾¡ã—ã¦æœ€çµ‚çš„ãªå›ç­”ã‚’å½¢æˆã™ã‚‹ã€‚ChatGPTã‚’ä½¿ç”¨ã—ã¦CoNã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€å®Ÿé¨“çµæœã¯CoNã‚’è£…å‚™ã—ãŸRALMãŒæ¨™æº–çš„ãªRALMã‚’å¤§å¹…ã«ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ç‰¹ã«ã€ãƒã‚¤ã‚ºã®å¤šã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ãŠã„ã¦EMã‚¹ã‚³ã‚¢ã§å¹³å‡+7.9ã®æ”¹å–„ã‚’é”æˆã—ã€çŸ¥è­˜ç¯„å›²å¤–ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®è³ªå•ã«å¯¾ã™ã‚‹æ‹’å¦ç‡ã§+10.5ã®æ”¹å–„ã‚’é”æˆã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ¢ãƒ‡ãƒ«ã«æ¤œç´¢ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå¯¾ã™ã‚‹queryã®relevance/accuracyã®è¦³ç‚¹ã‹ã‚‰note-takingã‚’ã•ã›ã‚‹ã“ã¨ã§ã€RAGã®æ­£ç¢ºæ€§ã‚„é€æ˜æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ãŸã¨ãˆã°ã€<br>- surface-levelã®æƒ…å ±ã«ä¾å­˜ã›ãšã«ãƒ¢ãƒ‡ãƒ«ã«ç†è§£ã‚’ä¿ƒã™<br>- ç›¸åã™ã‚‹æƒ…å ±ãŒå­˜åœ¨ã—ã¦ã‚‚relevantãªæƒ…å ±ã‚’é©åˆ‡ã«è€ƒæ…®ã™ã‚‹,<br>- å›ç­”ãƒ—ãƒ­ã‚»ã‚¹ã®é€æ˜æ€§ãƒ»è§£é‡ˆæ€§ã‚’å‘ä¸Šã•ã›ã‚‹<br>- æ¤œç´¢ã•ã‚ŒãŸæ–‡æ›¸ã«å¯¾ã™ã‚‹éå‰°ãªä¾å­˜ã‚’ãªãã™ï¼ˆæ–‡æ›¸ãŒå¤ã„, ã‚ã‚‹ã„ã¯ãƒã‚¤ã‚¸ãƒ¼ãªå ´åˆã«æœ‰ç”¨ï¼‰<br>ãªã©ãŒåˆ©ç‚¹ã¨ã—ã¦æŒ™ã’ã‚‰ã‚Œã¦ã„ã‚‹ã€‚<br><br>ä¸‹è¨˜ãŒä»˜éŒ²ä¸­ã®CoNã§å®Ÿéš›ã«åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚<br>&lt;img width="389" height="542" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/4e1cc58f-da0b-41ca-a65f-c269c9835cf9"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/4e1cc58f-da0b-41ca-a65f-c269c9835cf9"&lt;/a&gt;


/&gt;<br><br>éå¸¸ã«ã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ³•ã ãŒã€çµæœã¨ã—ã¦ã¯ãƒã‚¤ã‚ºãŒå¤šã„å ´åˆã€CoNã«ã‚ˆã‚‹ã‚²ã‚¤ãƒ³ãŒå¤§ãã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br>&lt;img width="820" height="586" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/0029d110-b7ae-4f23-933f-13f30c12f87e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0029d110-b7ae-4f23-933f-13f30c12f87e"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2023-11-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1131" target="_blank" rel="noopener noreferrer" class="title-link">MEGAVERSE: Benchmarking Large Language Models Across Languages,   Modalities, Models and Tasks, Sanchit Ahuja+, N_A, NAACL'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®ç ”ç©¶ã¯æ€¥é€Ÿã«é€²å±•ã—ã¦ãŠã‚Šã€è‹±èªä»¥å¤–ã®è¨€èªã§ã®è©•ä¾¡ãŒå¿…è¦ã¨ã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¿½åŠ ã—ãŸMEGAVERSEãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ã•ã¾ã–ã¾ãªLLMsã‚’è©•ä¾¡ã™ã‚‹ã€‚å®Ÿé¨“ã®çµæœã€GPT4ã¨PaLM2ãŒå„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ãŸãŒã€ãƒ‡ãƒ¼ã‚¿ã®æ±šæŸ“ãªã©ã®å•é¡ŒãŒã‚ã‚‹ãŸã‚ã€ã•ã‚‰ãªã‚‹å–ã‚Šçµ„ã¿ãŒå¿…è¦ã§ã‚ã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<span class="issue_date">Issue Date: 2023-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1128" target="_blank" rel="noopener noreferrer" class="title-link">Prompt Engineering a Prompt Engineer, Qinyuan Ye+, N_A, ACL'24 Findings</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¯ã€LLMsã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚¿ã‚¹ã‚¯ã§ã‚ã‚Šã€æœ¬ç ”ç©¶ã§ã¯ãƒ¡ã‚¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã—ã¦è‡ªå‹•çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’è¡Œã„ã¾ã™ã€‚æ”¹å–„ã•ã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ã¤ãªãŒã‚‹æ¨è«–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ˜ç¤ºãªã©ã®è¦ç´ ã‚’å°å…¥ã—ã€ä¸€èˆ¬çš„ãªæœ€é©åŒ–æ¦‚å¿µã‚’ãƒ¡ã‚¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«çµ„ã¿è¾¼ã¿ã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã§ã‚ã‚‹PE2ã¯ã€ã•ã¾ã–ã¾ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„ã‚¿ã‚¹ã‚¯ã§å¼·åŠ›ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã€ä»¥å‰ã®è‡ªå‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã¾ã™ã€‚ã•ã‚‰ã«ã€PE2ã¯æ„å‘³ã®ã‚ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç·¨é›†ã‚’è¡Œã„ã€ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¯ãƒˆã®æ¨è«–èƒ½åŠ›ã‚’ç¤ºã—ã¾ã™ã€‚</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2023-10-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1110" target="_blank" rel="noopener noreferrer" class="title-link">Re-Reading Improves Reasoning in Language Models, Xiaohan Xu+, N_A, EMNLP'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã„ã¦ã€æ¨è«–ã¯é‡è¦ã§å›°é›£ãªå•é¡Œã§ã™ã€‚å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ã‚’é–‹ç™ºã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ãŒå½“ã¦ã‚‰ã‚Œã¦ãã¾ã—ãŸãŒã€åŒæ–¹å‘ã®ç›¸äº’ä½œç”¨ã‚„è³ªå•ã®é‡è¦æ€§ã«ã¯æ³¨æ„ãŒæ‰•ã‚ã‚Œã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚ã“ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€è³ªå•ã®å†èª­ã¨ã„ã†æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ã‚’ææ¡ˆã—ã¾ã™ã€‚å†èª­ã¯ã€è³ªå•æƒ…å ±ã‚’å†è¨ªã™ã‚‹ã“ã¨ã§ã€LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ã“ã®æ‰‹æ³•ã®åŠ¹æœã¨æ±ç”¨æ€§ã‚’ç¤ºã—ã¦ãŠã‚Šã€LLMsã®é ˜åŸŸã§ã®ãã®æœ‰ç”¨æ€§ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å•é¡Œæ–‡ã‚’2,3å›promptã§ç¹°ã‚Šè¿”ã™ã ã‘ã§ã€æ•°å­¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨Commonsenseã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ€§èƒ½ãŒå‘ä¸Šã—ãŸã¨ã„ã†éå¸¸ã«ç°¡å˜ãªPromptingã€‚self-consistencyãªã©ã®ä»–ã®Promptingã¨ã®ä½µç”¨ã‚‚å¯èƒ½ã€‚<br>ãªãœæ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã‹ã¨ã„ã†ã¨ã€<br>1. LLMã¯Auporegressiveãªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€bidirectionalãªãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„ã€‚ã“ã®ãŸã‚ã€forwardãƒ‘ã‚¹ã®ã¿ã§ã¯èª­è§£åŠ›ã«é™ç•ŒãŒã‚ã‚‹ã€‚ï¼ˆãŸã¨ãˆã°äººé–“ã¯ã—ã°ã—ã°ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¿”ã—ãŸã‚Šã™ã‚‹ï¼‰ã€‚ãã“ã§ã€ä¸€åº¦ç›®ã®èª­è§£ã§æ¦‚è¦ã‚’ç†è§£ã—ã€äºŒåº¦ç›®ã®èª­è§£ã§salience partã‚’èª­ã¿è¾¼ã‚€ã¨ã„ã£ãŸã‚ˆã†ãªæŒ™å‹•ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šå•é¡Œæ–‡ã«å¯¾ã™ã‚‹ComprehensionãŒå‘ä¸Šã™ã‚‹ã€‚<br>2. LLMã¯ã—ã°ã—ã°promptã®é‡è¦ãªç®‡æ‰€ã®èª­è§£ã‚’æ¬ è½ã•ã›ã¦ã—ã¾ã†ã€‚ãŸã¨ãˆã°ã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/793" target="_blank" rel="noopener noreferrer">Lost in the Middle: How Language Models Use Long Contexts, Nelson F. Liu+, N/A, TACL'24</a>
 ã§ã¯ã€promptã®middle partã‚’è»½è¦–ã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã®ã‚ˆã†ãªç¾è±¡ã‚‚è»½æ¸›ã§ãã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e575e0aa-b76c-444e-b9b0-e984d6fc73cf" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1b2344fb-bfb4-467b-9dbb-05e4eff23d06" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fcaa2337-cfce-4e0c-b068-a7de2c0eff78" alt="image" loading="lazy"><br>å•é¡Œæ–‡ã®ç¹°ã‚Šè¿”ã—ã¯ã€3å›ã¾ã§ã¯æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e333e807-24d4-4a64-b768-cbd6dfbceecd" alt="image" loading="lazy"></p>
<p>ã“ã®promptingã¯è¤‡é›‘ãªå•é¡Œã§ã‚ã‚Œã°ã‚ã‚‹ã»ã©åŠ¹æœãŒã‚ã‚‹ã¨æ¨å¯Ÿã•ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1105" target="_blank" rel="noopener noreferrer" class="title-link">Self-RAG: Learning to Retrieve, Generate, and Critique through   Self-Reflection, Akari Asai+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€äº‹å®Ÿã«åŸºã¥ã‹ãªã„å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ãã“ã§ã€è‡ªå·±åçœçš„ãªæ¤œç´¢å¢—å¼·ç”Ÿæˆï¼ˆSelf-RAGï¼‰ã¨ã„ã†æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€æ¤œç´¢ã¨è‡ªå·±åçœã‚’é€šã˜ã¦LLMã®å“è³ªã¨äº‹å®Ÿæ€§ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€Self-RAGãŒæœ€å…ˆç«¯ã®LLMsãŠã‚ˆã³æ¤œç´¢å¢—å¼·ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>RAGã‚’ã™ã‚‹éš›ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®å›ç­”ã®è³ªã¨factual consistencyã‚’æ”¹å–„ã›ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚<br>reflection tokenã¨å‘¼ã°ã‚Œã‚‹ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’å°å…¥ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã®éç¨‹ã§å¿…è¦ã«å¿œã˜ã¦æƒ…å ±ã‚’retrieveã—ã€è‡ªèº«ã§ç”Ÿæˆå†…å®¹ã‚’æ‰¹è©•ã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ã€‚å˜èªã”ã¨ã«ç”Ÿæˆã™ã‚‹ã®ã§ã¯ãªãã€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå˜ä½ã§ç”Ÿæˆã™ã‚‹å€™è£œã‚’ç”Ÿæˆã—ã€æ‰¹è©•å†…å®¹ã«åŸºã¥ã„ã¦å®Ÿéš›ã«ç”Ÿæˆã™ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é¸æŠã™ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/282eb6fd-d2bd-4804-a0bc-652158e2f857" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cf690500-7002-454d-bc7c-0664d152a664" alt="image" loading="lazy"></p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=hSyW5go0v8" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=hSyW5go0v8</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1089" target="_blank" rel="noopener noreferrer" class="title-link">Detecting Pretraining Data from Large Language Models, Weijia Shi+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’è¨“ç·´ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã®æ¤œå‡ºå•é¡Œã‚’ç ”ç©¶ã—ã€æ–°ã—ã„æ¤œå‡ºæ–¹æ³•ã§ã‚ã‚‹Min-K% Probã‚’ææ¡ˆã—ã¾ã™ã€‚Min-K% Probã¯ã€LLMã®ä¸‹ã§ä½ã„ç¢ºç‡ã‚’æŒã¤ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ã‚¢ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡ºã™ã‚‹ã“ã¨ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚å®Ÿé¨“ã®çµæœã€Min-K% Probã¯å¾“æ¥ã®æ–¹æ³•ã«æ¯”ã¹ã¦7.4%ã®æ”¹å–„ã‚’é”æˆã—ã€è‘—ä½œæ¨©ã®ã‚ã‚‹æ›¸ç±ã®æ¤œå‡ºã‚„æ±šæŸ“ã•ã‚ŒãŸä¸‹æµã®ä¾‹ã®æ¤œå‡ºãªã©ã€å®Ÿä¸–ç•Œã®ã‚·ãƒŠãƒªã‚ªã«ãŠã„ã¦åŠ¹æœçš„ãªè§£æ±ºç­–ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å®Ÿé¨“çµæœã‚’è¦‹ã‚‹ã«AUCã¯0.73-0.76ç¨‹åº¦ã§ã‚ã‚Šã€ã¾ã ã‚ã¾ã‚Šé«˜ããªã„å°è±¡ã€‚ã¾ãŸã€ãƒ†ã‚­ã‚¹ãƒˆã®lengthã¯ãã‚Œãã‚Œ32,64,128,256ç¨‹åº¦ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1d7a5fe2-e0bc-4c6e-92b2-34457a17714a" alt="image" loading="lazy"></p>
<p>openreview:


<a href="https://openreview.net/forum?id=zWqr3MQuNs" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=zWqr3MQuNs</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2023-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1072" target="_blank" rel="noopener noreferrer" class="title-link">Think before you speak: Training Language Models With Pause Tokens, Sachin Goyal+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã«ãŠã„ã¦ã€é…å»¶ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€å…¥åŠ›ã«ç‰¹å®šã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ ã—ã€ãã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒç¾ã‚Œã‚‹ã¾ã§ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚’é…ã‚‰ã›ã‚‹ã“ã¨ã§ã€è¿½åŠ ã®è¨ˆç®—ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€ã“ã®æ‰‹æ³•ãŒæ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦æœ‰ç›Šã§ã‚ã‚Šã€ç‰¹ã«QAã‚¿ã‚¹ã‚¯ã§ã®æ€§èƒ½å‘ä¸ŠãŒè¦‹ã‚‰ã‚Œã¾ã—ãŸã€‚ä»Šå¾Œã¯ã€ã“ã®é…å»¶äºˆæ¸¬ã®æ‰‹æ³•ã‚’ã•ã‚‰ã«ç ”ç©¶ã—ã¦ã„ãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã“ã®ç ”ç©¶ã¯èˆˆå‘³æ·±ã„ãŒã€äº‹å‰å­¦ç¿’æ™‚ã«å…¥ã‚Œãªã„ã¨åŠ¹æœãŒå‡ºã«ãã„ã¨ã„ã†ã®ã¯ç›´æ„Ÿçš„ã«ã‚ã‹ã‚‹ã®ã§ã€å®Ÿç”¨çš„ã«ã¯æ´»ç”¨ã—ã¥ã‚‰ã„ã€‚<br>ã¾ãŸã€promptã§ã“ã®ç ”ç©¶ã‚’imitateã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦ã¯ã€ZeroShot CoTã«ãŠã„ã¦ã€æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’æ˜ç¤ºçš„ã«æŒ‡å®šã™ã‚‹ã‚ˆã†ãªpromptingã¨åŒæ§˜ã®ã“ã¨ã‚’è¡Œã£ã¦ãŠã‚Šã€ã“ã‚Œã¯å®Ÿéš›ã«åŠ¹æœãŒã‚ã‚‹ã¨æ€ã†ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1068" target="_blank" rel="noopener noreferrer" class="title-link">Improved Baselines with Visual Instruction Tuning, Haotian Liu+, N_A, CVPR'24</a>
<span class="snippet"><span>GPT Summary</span>- LLaVAã¯ã€ãƒ“ã‚¸ãƒ§ãƒ³ã¨è¨€èªã®ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«ã‚³ãƒã‚¯ã‚¿ã§ã‚ã‚Šã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ãŒé«˜ãå¼·åŠ›ãªæ€§èƒ½ã‚’æŒã¤ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚CLIP-ViT-L-336pxã‚’ä½¿ç”¨ã—ã€å­¦è¡“ã‚¿ã‚¹ã‚¯æŒ‡å‘ã®VQAãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€11ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ç¢ºç«‹ã—ã¾ã—ãŸã€‚13Bã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ã‚ãšã‹120ä¸‡ã®å…¬é–‹ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã€1æ—¥ã§å®Œå…¨ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’çµ‚ãˆã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç”»åƒåˆ†æãŒå¯èƒ½ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMã¨ã®ã“ã¨ã€‚</p>
<p># Overview<br><br>ç”»åƒç”Ÿæˆã‚’ã§ãã‚‹ã‚ã‘ã§ã¯ãªãã€inputã¨ã—ã¦ç”»åƒã‚’æ‰±ãˆã‚‹ã®ã¿ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8d0382b0-8c2b-438d-8de8-ee451f5e2649" alt="image" loading="lazy"><br><br></p>
<p>pj page:


<a href="https://llava-vl.github.io" target="_blank" rel="noopener noreferrer">https://llava-vl.github.io</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<a class="button" href="articles/PMLR.html" target="_blank" rel="noopener noreferrer">#PMLR</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1066" target="_blank" rel="noopener noreferrer" class="title-link">Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution, Chrisantha Fernando+, N_A, PMLR'24, 2024.07</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Promptbreederã¨ã„ã†è‡ªå·±å‚ç…§çš„ãªè‡ªå·±æ”¹å–„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ææ¡ˆã—ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æ±ç”¨çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæˆ¦ç•¥ã‚’é€²åŒ–ã•ã›ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚Promptbreederã¯ã€LLMãŒè‡ªå·±å‚ç…§çš„ãªæ–¹æ³•ã§é€²åŒ–ã™ã‚‹å¤‰ç•°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã£ã¦åˆ¶å¾¡ã•ã‚Œã€ã‚¿ã‚¹ã‚¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é›†å›£ã‚’å¤‰ç•°ã•ã›ã¦æ”¹å–„ã—ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ã€ç®—è¡“ã‚„å¸¸è­˜çš„ãªæ¨è«–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã ã‘ã§ãªãã€ãƒ˜ã‚¤ãƒˆã‚¹ãƒ”ãƒ¼ãƒåˆ†é¡ãªã©ã®é›£ã—ã„å•é¡Œã«å¯¾ã—ã¦ã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>è©³ç´°ãªè§£èª¬è¨˜äº‹: 


<a href="https://aiboom.net/archives/56319" target="_blank" rel="noopener noreferrer">https://aiboom.net/archives/56319</a>


</p>
<p>APEã¨ã¯ç•°ãªã‚Šã€GAã‚’ä½¿ã†ã€‚çªç„¶å¤‰ç•°ã«ã‚ˆã£ã¦ã€äºˆæœŸã›ã¬è‰¯ã„promptãŒç”Ÿã¿å‡ºã•ã‚Œã‚‹ã‹ã‚‚â€¦ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1065" target="_blank" rel="noopener noreferrer" class="title-link">Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models  through Logic, Xufeng Zhao+, N_A, COLING'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é€²æ­©ã¯é©šç•°çš„ã ãŒã€å¤šæ®µéšã®æ¨è«–ã«ã¯æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚‹ã€‚å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯çŸ¥è­˜ã‚’æŒã£ã¦ã„ã‚‹ãŒã€æ¨è«–ã«ã¯ä¸€è²«æ€§ãŒãªãã€å¹»è¦šã‚’ç¤ºã™ã“ã¨ãŒã‚ã‚‹ã€‚ãã“ã§ã€Logical Chain-of-Thoughtï¼ˆLogiCoTï¼‰ã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€è«–ç†ã«ã‚ˆã‚‹æ¨è«–ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã®åŠ¹æœã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/KnowledgeGraph.html" target="_blank" rel="noopener noreferrer">#KnowledgeGraph</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1061" target="_blank" rel="noopener noreferrer" class="title-link">Graph Neural Prompting with Large Language Models, Yijun Tian+, N_A, AAAI'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’çŸ¥è­˜ã‚°ãƒ©ãƒ•ã¨çµ„ã¿åˆã‚ã›ã‚‹ãŸã‚ã®æ–°ã—ã„æ‰‹æ³•ã§ã‚ã‚‹Graph Neural Promptingï¼ˆGNPï¼‰ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚GNPã¯ã€æ¨™æº–çš„ãªã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚„ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ãƒ—ãƒ¼ãƒªãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãªã©ã®è¦ç´ ã‹ã‚‰æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€ç•°ãªã‚‹LLMã®ã‚µã‚¤ã‚ºã‚„è¨­å®šã«ãŠã„ã¦ã€å¸¸è­˜çš„ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã‚„ãƒã‚¤ã‚ªãƒ¡ãƒ‡ã‚£ã‚«ãƒ«æ¨è«–ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ã“ã¨ãŒå®Ÿé¨“ã«ã‚ˆã£ã¦ç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1707211751354212382"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>äº‹å‰å­¦ç¿’ã•ã‚ŒãŸLLMãŒKGã‹ã‚‰æœ‰ç›ŠãªçŸ¥è­˜ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã‚’æ”¯æ´ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚<br><p>ã—ã£ã‹ã‚Šè«–æ–‡ã‚’èª­ã‚“ã§ã„ãªã„ãŒã€freezeã—ãŸLLMãŒã‚ã£ãŸæ™‚ã«ã€KGã‹ã‚‰æ±‚ã‚ãŸGraph Neural Promptã‚’å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã¨çµ„ã¿åˆã‚ã›ã¦ã€æ–°ãŸãªLLMã¸ã®å…¥åŠ›ã‚’ç”Ÿæˆã—åˆ©ç”¨ã™ã‚‹æ‰‹æ³•ãªæ¨¡æ§˜ã€‚<br>Graph Neural Promptingã§ã¯ã€Multiple choice QAãŒå…¥åŠ›ã•ã‚ŒãŸæ™‚ã«ã€ãã®å•é¡Œæ–‡ã‚„é¸æŠè‚¢ã«å«ã¾ã‚Œã‚‹ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‹ã‚‰ã€KGã®ã‚µãƒ–ã‚°ãƒ©ãƒ•ã‚’æŠ½å‡ºã—ã€ãã“ã‹ã‚‰é–¢é€£æ€§ã®ã‚ã‚‹äº‹å®Ÿã‚„æ§‹é€ æƒ…å ±ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€Graph Neural Promptã‚’ç²å¾—ã™ã‚‹ã€‚ãã®ãŸã‚ã«ã€GNNã«åŸºã¥ã„ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã€ã„ãã¤ã‹ã®å·¥å¤«ã‚’æ–½ã—ã¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’ã™ã‚‹æ¨¡æ§˜ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c6c80b8d-930e-49ff-9a1b-62e70947dc7c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1060" target="_blank" rel="noopener noreferrer" class="title-link">Effective Long-Context Scaling of Foundation Models, Wenhan Xiong+, N_A, NAACL'24</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ä¸€é€£ã®LLMsã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚„ä»–ã®ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã•ã‚Œã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€é€šå¸¸ã®ã‚¿ã‚¹ã‚¯ã¨é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¿ã‚¹ã‚¯ã®ä¸¡æ–¹ã§æ”¹å–„ã‚’ã‚‚ãŸã‚‰ã—ã¾ã™ã€‚ã¾ãŸã€70Bãƒãƒªã‚¢ãƒ³ãƒˆã¯gpt-3.5-turbo-16kã‚’ä¸Šå›ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€ç§ãŸã¡ã¯Llamaã®ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚„äº‹å‰å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã®è¨­è¨ˆé¸æŠã®å½±éŸ¿ã«ã¤ã„ã¦ã‚‚åˆ†æã—ã¾ã—ãŸã€‚çµæœã‹ã‚‰ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ç¶™ç¶šçš„ãªäº‹å‰å­¦ç¿’ãŒåŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹elvisæ°ã®ãƒ„ã‚¤ãƒ¼ãƒˆã®æ„è¨³<br><br>MetaãŒ32kã®context windowã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹70Bã®LLaMa2ã®variantææ¡ˆã—ã€gpt-3.5-turboã‚’long contextãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§outperformã€‚<br>short contextã®LLaMa2ã‚’ç¶™ç¶šçš„ã«è¨“ç·´ã—ã¦å®Ÿç¾ã€‚ã“ã‚Œã«ã¯äººæ‰‹ã§ä½œæˆã—ãŸinstruction tuning datasetã‚’å¿…è¦ã¨ã›ãšã€ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®é«˜ã„instruction tuningã«ã‚ˆã£ã¦å®Ÿç¾ã•ã‚Œã‚‹ã€‚<br>ã“ã‚Œã¯ã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é•·ã„ãƒ†ã‚­ã‚¹ãƒˆãŒè±Šå¯Œã«å«ã¾ã‚Œã‚‹ã“ã¨ãŒå„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®éµã§ã¯ãªãã€ãƒ­ãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ç¶™ç¶šçš„ãªäº‹å‰å­¦ç¿’ãŒã‚ˆã‚ŠåŠ¹ç‡çš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚<br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1707780482178400261?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ã¯long contxetç”¨ã«ã€RoPEã®base frequency bã‚’ `10,000-&gt;500,000` ã¨ã™ã‚‹ã“ã¨ã§ã€rotation angleã‚’å°ã•ãã—ã€distant tokenã«å¯¾ã™ã‚‹æ¸›è¡°ã®å½±éŸ¿ã‚’å°ã•ãã™ã‚‹æ‰‹æ³•ã‚’æ¡ç”¨ (Adjusted Base Frequency; ABF)ã€‚tokené–“ã®è·é›¢ãŒé›¢ã‚Œã¦ã„ã¦ã‚‚ã€attention scoreãŒshrinkã—ã¥ã‚‰ããªã£ã¦ã„ã‚‹ã€‚<br><br>&lt;img width="578" height="291" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/968c88f1-5a0d-4c2a-94ef-d63ffb0ea2eb"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/968c88f1-5a0d-4c2a-94ef-d63ffb0ea2eb"&lt;/a&gt;


/&gt;<br><br><br>ã¾ãŸã€å˜ã«é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ã ã‘ã§ãªãã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã«ãŠã‘ã‚‹é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã®æ¯”ç‡ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šé«˜ã„æ€§èƒ½ãŒç™ºæ®ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ã“ã‚Œã‚’Data Mixã¨å‘¼ã¶ã€‚<br>ã¾ãŸã€instruction tuningã®ãƒ‡ãƒ¼ã‚¿ã«ã¯ã€LLaMa2Chatã®RLHFãƒ‡ãƒ¼ã‚¿ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€LLaMa2Chatè‡ªèº«ã«self-instructã‚’æ´»ç”¨ã—ã¦ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã•ã›æ‹¡å¼µã—ãŸã‚‚ã®ã‚’åˆ©ç”¨ã—ãŸã€‚<br>å…·ä½“çš„ã«ã¯ã€ã‚³ãƒ¼ãƒ‘ã‚¹å†…ã®long documentã‚’ç”¨ã„ãŸQAãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã‚¿ã‚¹ã‚¯ã«ç€ç›®ã—ã€æ–‡æ›¸å†…ã®ãƒ©ãƒ³ãƒ€ãƒ ãªãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰QAã‚’ç”Ÿæˆã•ã›ãŸã€‚ãã®å¾Œã€self-critiqueã«ã‚ˆã£ã¦ã€LLaMa2Chatè‡ªèº«ã«ã€ç”Ÿæˆã•ã‚ŒãŸQAãƒšã‚¢ã®verificationã‚‚å®Ÿæ–½ã•ã›ãŸã€‚</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1044" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Chain-of-Verification Reduces Hallucination in Large Language Models, Shehzaad Dhuliawala+, N_A, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒæ ¹æ‹ ã®ãªã„æƒ…å ±ã‚’ç”Ÿæˆã™ã‚‹å•é¡Œã«å–ã‚Šçµ„ã‚“ã§ã„ã¾ã™ã€‚Chain-of-Verificationï¼ˆCoVeï¼‰ãƒ¡ã‚½ãƒƒãƒ‰ã‚’é–‹ç™ºã—ã€ãƒ¢ãƒ‡ãƒ«ãŒå›ç­”ã‚’ä½œæˆã—ã€æ¤œè¨¼ã—ã€æœ€çµ‚çš„ãªå›ç­”ã‚’ç”Ÿæˆã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµŒã‚‹ã“ã¨ã§ã€å¹»æƒ³ã‚’æ¸›å°‘ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’å®Ÿé¨“ã§ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>
<strong># æ¦‚è¦<br>ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã‹ã‚‰ã€Verificationã®ãŸã‚ã®è³ªå•ã‚’planningã—ã€è³ªå•ã«å¯¾ã—ã¦ç‹¬ç«‹ã«å›ç­”ã‚’å¾—ãŸã†ãˆã§ã‚ªãƒªã‚¸ãƒŠãƒ«ã®è³ªå•ã«å¯¾ã™ã‚‹aggreementã‚’ç¢ºèªã—ã€æœ€çµ‚çš„ã«ç”Ÿæˆã‚’å®Ÿæ–½ã™ã‚‹Promptingæ‰‹æ³•<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/18763903-2d70-4180-9384-2da55bedad2e" alt="image" loading="lazy"><br><br># è©•ä¾¡<br>## dataset<br>- å…¨ä½“ã‚’é€šã˜ã¦closed-bookã®è¨­å®šã§è©•ä¾¡<br>- Wikidata<br>    - Wikipedia APIã‹ã‚‰è‡ªå‹•ç”Ÿæˆã—ãŸã€Œâ€œWho are some [Profession]s who were born in [City]?â€ã€ã«å¯¾ã™ã‚‹QA pairs<br>    - Goldã¯knowledge baseã‹ã‚‰å–å¾—<br>    - å…¨56 test questions<br>    - Gold EntityãŒå¤§ä½“600ç¨‹åº¦ã‚ã‚ŠLLMã¯ä¸€éƒ¨ã—ã‹å›ç­”ã—ãªã„ã®ã§ã€precisionã§è©•ä¾¡<br>- Wiki category list<br>    - QUEST datasetã‚’åˆ©ç”¨ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/701" target="_blank" rel="noopener noreferrer">QUEST: A Retrieval Dataset of Entity-Seeking Queries with Implicit Set  Operations, Chaitanya Malaviya+, N/A, ACL'23</a>
</strong>
<br>
 <br>    - å›ç­”ã«logical operationãŒä¸è¦ãªã‚‚ã®ã«é™å®šã—ã¦é ­ã«"Name some"ã‚’ã¤ã‘ã¦è³ªå•ã‚’ç”Ÿæˆ<br>        - "Name some Mexican animated horror films" or "Name some Endemic orchids of Vietnam"<br>    - 8å€‹ã®å›ç­”ã‚’æŒã¤55 test questionsã‚’ä½œæˆ<br>- MultiSpanQA<br>    - Reading Comprehensionã«é–¢ã™ã‚‹Benchmark dataset<br>    - è¤‡æ•°ã®ç‹¬ç«‹ã—ãŸå›ç­”ï¼ˆå›ç­”ã¯é€£ç¶šã—ãªã„ã‚¹ãƒ‘ãƒ³ã‹ã‚‰å›ç­”ãŒæŠ½å‡ºã•ã‚Œã‚‹ï¼‰ã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹è³ªå•ã§æ§‹æˆ<br>        - ç‰¹ã«ã€ä»Šå›ã¯closed-book setting ã§å®Ÿæ–½<br>        - ã™ãªã‚ã¡ã€ä¸ãˆã‚‰ã‚ŒãŸè³ªå•ã®ã¿ã‹ã‚‰å›ç­”ã—ãªã‘ã‚Œã°ãªã‚‰ãšã€çŸ¥ã£ã¦ã„ã‚‹çŸ¥è­˜ãŒå•ã‚ã‚Œã‚‹å•é¡Œ<br>    - 418ã®test questsionsã§ã€å„å›ç­”ã«å«ã¾ã‚Œã‚‹è¤‡æ•°ã‚¢ã‚¤ãƒ†ãƒ ã®spanãŒ3 tokenæœªæº€ã¨ãªã‚‹ã‚ˆã†ã«ã—ãŸ<br>    - QAä¾‹:<br>        - Q: Who invented the first printing press and in what year?<br>        - A: Johannes Gutenberg, 1450.<br># è©•ä¾¡çµæœ<br>ææ¡ˆæ‰‹æ³•ã«ã¯ã€verificationã®å„ã‚¹ãƒ†ãƒƒãƒ—ã§LLMã«ç‹¬ç«‹ã—ãŸpromptingã‚’ã™ã‚‹ã‹ãªã©ã§joint, 2-step, Factored, Factor+Revisedã®4ç¨®é¡ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚ã‚‹ã“ã¨ã«ç•™æ„ã€‚<br>- joint: å…¨ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ä¸€ã¤ã®promptã§å®Ÿæ–½<br>- 2-stepã¯2ã¤ã®promptã«åˆ†ã‘ã¦å®Ÿæ–½<br>- Factoredã¯å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’å…¨ã¦ç•°ãªã‚‹promptingã§å®Ÿæ–½<br>- Factor+Revisedã¯ç•°ãªã‚‹promptã§è¿½åŠ ã®QAã«å¯¾ã™ã‚‹cross-checkã‚’ã‹ã‘ã‚‹æ‰‹æ³•<br><br>çµæœã‚’è¦‹ã‚‹ã¨ã€CoVEã§hallucinationãŒè»½æ¸›ï¼ˆã¨ã„ã†ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ãŒæŒã¤çŸ¥è­˜ã«åŸºã¥ã„ã¦æ­£ç¢ºã«å›ç­”ã§ãã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®å‰²åˆãŒå¢—ãˆã‚‹ã®ã§å®Ÿè³ªçš„ã«hallucinationãŒä½æ¸›ã—ãŸã¨ã¿ãªã›ã‚‹ï¼‰ã•ã‚Œã€ç‰¹ã«jointã‚ˆã‚Šã‚‚2-step, factoredã®æ–¹ãŒé«˜ã„æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/05ff1e6c-75e7-428a-996f-61e844866391" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d72aa05e-daab-4092-a6f5-9e80cdab7486" alt="image" loading="lazy"><br></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1037" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models as Optimizers, Chengrun Yang+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æœ€é©åŒ–ã‚¿ã‚¹ã‚¯ã‚’è‡ªç„¶è¨€èªã§è¨˜è¿°ã—ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦æœ€é©åŒ–ã‚’è¡Œã†æ‰‹æ³•ã€ŒOptimization by PROmptingï¼ˆOPROï¼‰ã€ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã§ã¯ã€LLMãŒä»¥å‰ã®è§£ã¨ãã®å€¤ã‚’å«ã‚€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰æ–°ã—ã„è§£ã‚’ç”Ÿæˆã—ã€è©•ä¾¡ã—ã¦æ¬¡ã®æœ€é©åŒ–ã‚¹ãƒ†ãƒƒãƒ—ã®ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€OPROã«ã‚ˆã£ã¦æœ€é©åŒ–ã•ã‚ŒãŸæœ€è‰¯ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã€äººé–“ãŒè¨­è¨ˆã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>`Take a deep breath and work on this problem step-by-step. `è«–æ–‡<br><br><br><br># æ¦‚è¦<br><br>LLMã‚’åˆ©ç”¨ã—ã¦æœ€é©åŒ–å•é¡Œã‚’è§£ããŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ãŸã¨ã„ã†è©±ã€‚è«–æ–‡ä¸­ã§ã¯ã€linear regressionã‚„å·¡å›ã‚»ãƒ¼ãƒ«ã‚¹ãƒãƒ³å•é¡Œã«é©ç”¨ã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€å¿œç”¨ä¾‹ã¨ã—ã¦Prompt Engineeringã«åˆ©ç”¨ã—ã¦ã„ã‚‹ã€‚<br><br>ã“ã‚Œã«ã‚ˆã‚Šã€Prompt EngineeringãŒæœ€é©ã‹å•é¡Œã«è½ã¨ã—è¾¼ã¾ã‚Œã€è‡ªå‹•çš„ãªprompt engineeringã«ã‚ˆã£ã¦ã€`Let's think step by step.` ã‚ˆã‚Šã‚‚è‰¯ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã¨ã„ã†è©±ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2a469085-8a14-4eac-85ee-3918fe1becd5" alt="image" loading="lazy"><br><br><br><br># æ‰‹æ³•æ¦‚è¦<br><br>å…¨ä½“ã¨ã—ã¦ã®æ çµ„ã¿ã€‚meta-promptã‚’inputã¨ã—ã€LLMãŒobjective functionã«å¯¾ã™ã‚‹solutionã‚’ç”Ÿæˆã™ã‚‹ã€‚ç”Ÿæˆã•ã‚ŒãŸsolutionã¨ã‚¹ã‚³ã‚¢ãŒmeta-promptã«ä»£å…¥ã•ã‚Œã€æ¬¡ã®optimizationãŒèµ°ã‚‹ã€‚ã“ã‚Œã‚’ç¹°ã‚Šè¿”ã™ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3e34ed47-5cbe-4cb0-b25a-8ee939e780e3" alt="image" loading="lazy"><br><br>Meta promptã®ä¾‹<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a0dd261e-0dcd-487a-bfac-89db243e0b1c" alt="image" loading="lazy"><br><br></p>
<p>openreview: 


<a href="https://openreview.net/forum?id=Bb4VGOWELI" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Bb4VGOWELI</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1029" target="_blank" rel="noopener noreferrer" class="title-link">CausalLM is not optimal for in-context learning, Nan Ding+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ã«ãŠã„ã¦ã€ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆprefixLMï¼‰ãŒå› æœè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆcausalLMï¼‰ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã“ã¨ãŒã‚ã‹ã£ã¦ã„ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ç†è«–çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç”¨ã„ã¦ã€prefixLMã¨causalLMã®åæŸæŒ™å‹•ã‚’åˆ†æã—ã¾ã—ãŸã€‚ãã®çµæœã€prefixLMã¯ç·šå½¢å›å¸°ã®æœ€é©è§£ã«åæŸã™ã‚‹ä¸€æ–¹ã€causalLMã®åæŸãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å‹¾é…é™ä¸‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«å¾“ã„ã€æœ€é©ã§ã‚ã‚‹ã¨ã¯é™ã‚‰ãªã„ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ã•ã‚‰ã«ã€åˆæˆå®Ÿé¨“ã¨å®Ÿéš›ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã‚‚ã€causalLMãŒprefixLMã‚ˆã‚Šã‚‚æ€§èƒ½ãŒåŠ£ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1697380430004249066?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>CausalLMã§ICLã‚’ã—ãŸå ´åˆã¯ã€ICLä¸­ã®demonstrationã§ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã™ã‚‹ã“ã¨ã«ç›¸å½“ã—ã€æœ€é©è§£ã«åæŸã—ã¦ã„ã‚‹ã¨ã¯é™ã‚‰ãªã„â€¦â€¦ï¼ŸãŒã€hillbigã•ã‚“ã®æ„Ÿæƒ³ã«åŸºã¥ãã¨ã€çµæœçš„ã«ã¯å®Ÿã¯æœ€é©è§£ã«åæŸã—ã¦ã„ã‚‹ã®ã§ã¯ï¼Ÿã¨ã„ã†è©±ã‚‚å‡ºã¦ã„ã‚‹ã—ã€ã‚ˆãåˆ†ã‹ã‚‰ãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/924" target="_blank" rel="noopener noreferrer" class="title-link">SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step   Reasoning, Ning Miao+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ€æ–°ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€æ¨è«–å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«æœ‰æœ›ãªæ‰‹æ³•ã§ã™ãŒã€è¤‡é›‘ãªå•é¡Œã«ã¯ã¾ã è‹¦æˆ¦ã—ã¦ã„ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LLMsãŒè‡ªèº«ã®ã‚¨ãƒ©ãƒ¼ã‚’èªè­˜ã™ã‚‹èƒ½åŠ›ã‚’æŒã£ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’æ¢æ±‚ã—ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®æ¤œè¨¼ã‚¹ã‚­ãƒ¼ãƒ ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®æ¤œè¨¼ã‚¹ã‚­ãƒ¼ãƒ ã‚’ä½¿ç”¨ã—ã¦ã€ç•°ãªã‚‹å›ç­”ã«å¯¾ã—ã¦é‡ã¿ä»˜ã‘æŠ•ç¥¨ã‚’è¡Œã„ã€è³ªå•å¿œç­”ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’å®Ÿé¨“ã§ç¢ºèªã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ã“ã‚Œã¯ãŠã‚‚ã—ã‚ãã†ã€‚å¾Œã§èª­ã‚€</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=pTHfApDakA" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=pTHfApDakA</a>


</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/917" target="_blank" rel="noopener noreferrer" class="title-link">LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA   Composition, Chengsong Huang+, N_A, COLM'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã«é©å¿œã•ã›ã‚‹ãŸã‚ã®ä½ãƒ©ãƒ³ã‚¯é©å¿œï¼ˆLoRAï¼‰ã‚’æ¤œè¨ã—ã€LoraHubã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚LoraHubã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€å°‘æ•°ã®ä¾‹ã‹ã‚‰è¤‡æ•°ã®LoRAãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã¦æŸ”è»Ÿã«é©å¿œæ€§ã®ã‚ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚ã¾ãŸã€è¿½åŠ ã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚„å‹¾é…ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚å®Ÿé¨“çµæœã‹ã‚‰ã€LoraHubãŒå°‘æ•°ã®ä¾‹ã§ã®ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åŠ¹æœçš„ã«æ¨¡å€£ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€LoRAã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®è‚²æˆã¨å…±æœ‰ãƒªã‚½ãƒ¼ã‚¹ã®æä¾›ã«ã‚‚è²¢çŒ®ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å­¦ç¿’ã•ã‚ŒãŸLoRAã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã—ã¦æ‰ãˆã€æ–°ãŸãªã‚¿ã‚¹ã‚¯ã®inputãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€LoRA Hubä¸Šã®é©åˆ‡ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’LLMã«çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ICLç„¡ã—ã§æ±åŒ–ã‚’å®Ÿç¾ã™ã‚‹ã¨ã„ã†ã‚¢ã‚¤ãƒ‡ã‚¢ã€‚few shotã®exampleã‚’äººé–“ãŒè¨­è¨ˆã™ã‚‹å¿…è¦ãªãã€åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9d769042-5a29-4c22-8ab4-e90195f71184" alt="image" loading="lazy"></p>
<p>è¤‡æ•°ã®LoRAãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯çµ„ã¿åˆã‚ã‚‰ã‚Œã‚‹ã‹ï¼Ÿelement wiseã®ç·šå‹çµåˆã§ä»Šå›ã¯ã‚„ã£ã¦ã„ã‚‹ãŒã€ãã®ç–‘å•ã«ã“ãŸãˆãŸã®ãŒcontribution</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=TrloAXEJ2B" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=TrloAXEJ2B</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/872" target="_blank" rel="noopener noreferrer" class="title-link">SciBench: Evaluating College-Level Scientific Problem-Solving Abilities   of Large Language Models, Xiaoxuan Wang+, N_A, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®é€²æ­©ã«ã‚ˆã‚Šã€æ•°å­¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®æ€§èƒ½å‘ä¸ŠãŒç¤ºã•ã‚Œã¦ã„ã‚‹ãŒã€ã“ã‚Œã‚‰ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯é™å®šçš„ãªç¯„å›²ã®å•é¡Œã«é™å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒæŒ‡æ‘˜ã•ã‚Œã‚‹ã€‚ãã“ã§ã€è¤‡é›‘ãªç§‘å­¦çš„å•é¡Œè§£æ±ºã«å¿…è¦ãªæ¨è«–èƒ½åŠ›ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã®åŒ…æ‹¬çš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¤ãƒ¼ãƒˆSciBenchã‚’ææ¡ˆã™ã‚‹ã€‚SciBenchã«ã¯ã€å¤§å­¦ãƒ¬ãƒ™ãƒ«ã®ç§‘å­¦çš„å•é¡Œã‚’å«ã‚€ã‚ªãƒ¼ãƒ—ãƒ³ã‚»ãƒƒãƒˆã¨ã€å­¦éƒ¨ãƒ¬ãƒ™ãƒ«ã®è©¦é¨“å•é¡Œã‚’å«ã‚€ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ã‚»ãƒƒãƒˆã®2ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå«ã¾ã‚Œã¦ã„ã‚‹ã€‚ã•ã‚‰ã«ã€2ã¤ã®ä»£è¡¨çš„ãªLLMã‚’ç”¨ã„ãŸè©³ç´°ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç ”ç©¶ã‚’è¡Œã„ã€ç¾åœ¨ã®LLMã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä¸ååˆ†ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ã‚¿ãƒ‡ã‚£ã‚’é€šã˜ã¦ã€LLMãŒçŠ¯ã™ã‚¨ãƒ©ãƒ¼ã‚’10ã®å•é¡Œè§£æ±ºèƒ½åŠ›ã«åˆ†é¡ã—ã€ç‰¹å®šã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ãŒä»–ã®æˆ¦ç•¥ã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚SciBenchã¯ã€LLMã®æ¨è«–èƒ½åŠ›ã®å‘ä¸Šã‚’ä¿ƒé€²ã—ã€ç§‘å­¦ç ”ç©¶ã¨ç™ºè¦‹ã«è²¢çŒ®ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/LearningToRank.html" target="_blank" rel="noopener noreferrer">#LearningToRank</a>
<a class="button" href="articles/PairWise.html" target="_blank" rel="noopener noreferrer">#PairWise</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/799" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models are Effective Text Rankers with Pairwise Ranking   Prompting, Zhen Qin+, N_A, NAACL'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã‚’ä½¿ç”¨ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã™ã‚‹éš›ã«ã€Pairwise Ranking Promptingï¼ˆPRPï¼‰ã¨ã„ã†æ–°ã—ã„æŠ€è¡“ã‚’ææ¡ˆã™ã‚‹ã€‚PRPã¯ã€LLMsã¸ã®è² è·ã‚’è»½æ¸›ã—ã€æœ€å…ˆç«¯ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€20Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤Flan-UL2ãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ãPRPã¯ã€å•†ç”¨ã®GPT-4ã«åŸºã¥ãå¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ãŸã€‚ã•ã‚‰ã«ã€PRPã®ãƒãƒªã‚¢ãƒ³ãƒˆã‚’ææ¡ˆã—ã€åŠ¹ç‡ã‚’æ”¹å–„ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚PRPã¯ç”Ÿæˆã¨ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã®LLM APIã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€å…¥åŠ›ã®é †åºã«å¯¾ã—ã¦ç„¡æ„Ÿåº¦ã§ã‚ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>open source LLMã«ãŠã„ã¦ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ãªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§SoTAã‚’é”æˆã§ãã‚‹ã‚ˆã†ãªpromptingæŠ€è¡“ã‚’ææ¡ˆ</p>
<p>å¾“æ¥ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®ãŸã‚ã®promptingã¯point-wiseã¨list wiseã—ã‹ãªã‹ã£ãŸãŒã€å‰è€…ã¯è¤‡æ•°ã®ã‚¹ã‚³ã‚¢ã‚’æ¯”è¼ƒã™ã‚‹ãŸã‚ã«ã‚¹ã‚³ã‚¢ã®calibrationãŒå¿…è¦ã ã£ãŸã‚Šã€OpenAIãªã©ã®APIã¯log probabilityã‚’æä¾›ã—ãªã„ãŸã‚ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®ãŸã‚ã®ã‚½ãƒ¼ãƒˆãŒã§ããªã„ã¨ã„ã†æ¬ ç‚¹ãŒã‚ã£ãŸã€‚å¾Œè€…ã¯inputã®orderingã«éå¸¸ã«sensitiveã§ã‚ã‚‹ãŒã€listã®ã™ã¹ã¦ã®çµ„ã¿åˆã‚ã›ã«ã¤ã„ã¦orderingã‚’è©¦ã™ã®ã¯expensiveãªã®ã§å³ã—ã„ã¨ã„ã†ã‚‚ã®ã§ã‚ã£ãŸã€‚ã“ã®ãŸã‚ï¼ˆå¤å…¸çš„ãªlearning to rankã§ã‚‚ãŠãªã˜ã¿ã‚„ï¼‰pairwiseã§ã‚µãƒ³ãƒ—ãƒ«ã‚’æ¯”è¼ƒã™ã‚‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ‰‹æ³•PRPã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br>PRPã¯ãƒšã‚¢ãƒ¯ã‚¤ã‚ºãªã®ã§orderã‚’å…¥ã‚Œæ›¿ãˆã¦è©•ä¾¡ã‚’ã™ã‚‹ã®ã¯å®¹æ˜“ã§ã‚ã‚‹ã€‚ã¾ãŸã€generation modeã¨scoring modeï¼ˆoutputã—ãŸãƒ©ãƒ™ãƒ«ã®log probabilityã‚’åˆ©ç”¨ã™ã‚‹; OpenLLMã‚’ä½¿ã†ã®ã§log probabilityã‚’è¨ˆç®—ã§ãã‚‹ï¼‰ã®2ç¨®é¡ã‚’æ¡ç”¨ã§ãã‚‹ã€‚ã‚½ãƒ¼ãƒˆã®æ–¹æ³•ã«ã¤ã„ã¦ã‚‚ã€ã™ã¹ã¦ã®ãƒšã‚¢ã®å‹æ•—ã‹ã‚‰ã‹ã‚‰å˜ä¸€ã®ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹æ–¹æ³•ï¼ˆAllPair), HeapSortã‚’åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã€LLMã‹ã‚‰ã®outputã‚’å¾—ã‚‹åº¦ã«on the flyã§ãƒªã‚¹ãƒˆã®é †ç•ªã‚’æ­£ã—ãã™ã‚‹Sliding Windowã®3ç¨®é¡ã‚’ææ¡ˆã—ã¦æ¯”è¼ƒã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/7ad366c6-2afd-404b-9e7d-6051030983c6" alt="image" loading="lazy"><br><br>ä¸‹è¡¨ã¯scoring modeã§ã®æ€§èƒ½ã®æ¯”è¼ƒã§ã€GPT4ã«å½“æ™‚ã¯æ€§èƒ½ãŒåŠã‚“ã§ã„ãªã‹ã£ãŸ20Bã®OpenLLMã§è¿‘ã—ã„æ€§èƒ½ã‚’é”æˆã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/7455b844-107f-4e88-85b8-3b5fc2866cc8" alt="image" loading="lazy"><br><br>ã¾ãŸã€PRPãŒinputã®orderã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆãªã“ã¨ã‚‚ç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/5244fb56-a9bf-46c9-89ca-f2766f7ba4a0" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/TACL.html" target="_blank" rel="noopener noreferrer">#TACL</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/793" target="_blank" rel="noopener noreferrer" class="title-link">Lost in the Middle: How Language Models Use Long Contexts, Nelson F. Liu+, N_A, TACL'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€é•·ã„æ–‡è„ˆã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚‹ã“ã¨ãŒã§ãã¾ã™ãŒã€ãã®é•·ã„æ–‡è„ˆã‚’ã©ã‚Œã ã‘ã†ã¾ãåˆ©ç”¨ã—ã¦ã„ã‚‹ã‹ã«ã¤ã„ã¦ã¯ã¾ã ã‚ˆãã‚ã‹ã£ã¦ã„ã¾ã›ã‚“ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€ãƒãƒ«ãƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è³ªå•å¿œç­”ã¨ã‚­ãƒ¼ãƒ»ãƒãƒªãƒ¥ãƒ¼ã®æ¤œç´¢ã¨ã„ã†2ã¤ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åˆ†æã—ã¾ã—ãŸã€‚ãã®çµæœã€é–¢é€£æƒ…å ±ãŒå…¥åŠ›æ–‡è„ˆã®å§‹ã¾ã‚Šã‚„çµ‚ã‚ã‚Šã«ã‚ã‚‹å ´åˆã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒæœ€ã‚‚é«˜ããªã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸãŒã€é•·ã„æ–‡è„ˆã®ä¸­ã§é–¢é€£æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒè‘—ã—ãä½ä¸‹ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€å…¥åŠ›æ–‡è„ˆãŒé•·ããªã‚‹ã«ã¤ã‚Œã¦ã€æ˜ç¤ºçš„ã«é•·ã„æ–‡è„ˆã‚’æ‰±ã†ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤§å¹…ã«ä½ä¸‹ã—ã¾ã™ã€‚ã“ã®åˆ†æã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒå…¥åŠ›æ–‡è„ˆã‚’ã©ã®ã‚ˆã†ã«åˆ©ç”¨ã—ã¦ã„ã‚‹ã‹ã‚’ã‚ˆã‚Šè‰¯ãç†è§£ã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã‚ã‚Šã€å°†æ¥ã®é•·ã„æ–‡è„ˆãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®æ–°ã—ã„è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/drjimfan/status/1678460065811136512?s=46&t=5BO_qSlNBSEGSugyUlP5Hw"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>éå¸¸ã«é‡è¦ãªçŸ¥è¦‹ãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹<p>1. ãƒ¢ãƒ‡ãƒ«ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã¯ã˜ã‚ã¨æœ€å¾Œã®æƒ…å ±ã‚’ã†ã¾ãæ´»ç”¨ã§ãã€çœŸã‚“ä¸­ã®æƒ…å ±ã‚’ã†ã¾ãæ´»ç”¨ã§ããªã„<br>2. é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã‚‚ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚ˆã‚ŠçŸ­ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ã†ã¾ãè€ƒæ…®ã§ãã‚‹ã‚ã‘ã§ã¯ãªã„<br>3. ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ããªã‚Œã°ãªã‚‹ã»ã©æ‚ªåŒ–ã™ã‚‹</p>
<p>SNLP'24ã§ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:<br>


<a href="https://speakerdeck.com/kichi/snlp2024" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/kichi/snlp2024</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2023-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/686" target="_blank" rel="noopener noreferrer" class="title-link">Evidence of Meaning in Language Models Trained on Programs, Charles Jin+, N_A, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ç”¨ã„ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ãŒæ„å‘³ã‚’å­¦ç¿’ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ åˆæˆãŒè¨€èªãƒ¢ãƒ‡ãƒ«ã®æ„å‘³ã®å­˜åœ¨ã‚’ç‰¹å¾´ã¥ã‘ã‚‹ãŸã‚ã®ä¸­é–“ãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã¨ã—ã¦é©ã—ã¦ã„ã‚‹ã“ã¨ã‚’è¿°ã¹ã¦ã„ã‚‹ã€‚Transformerãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå®Ÿé¨“ã«ã‚ˆã‚Šã€è¨€èªã®æ„å‘³ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã®å¸°ç´ãƒã‚¤ã‚¢ã‚¹ã‚’æä¾›ã—ãªã„ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€ç·šå½¢ãƒ—ãƒ­ãƒ¼ãƒ–ãŒãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹ã‹ã‚‰ç¾åœ¨ãŠã‚ˆã³å°†æ¥ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ çŠ¶æ…‹ã®æŠ½è±¡åŒ–ã‚’æŠ½å‡ºã§ãã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã¾ãŸã€æ­£ã—ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚’å­¦ç¿’ã—ã€å¹³å‡çš„ã«è¨“ç·´ã‚»ãƒƒãƒˆã‚ˆã‚Šã‚‚çŸ­ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚‚ç¤ºã—ãŸã€‚æœ¬è«–æ–‡ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«æ–°ã—ã„æŠ€è¡“ã‚’ææ¡ˆã™ã‚‹ã‚‚ã®ã§ã¯ãªãã€(å½¢å¼çš„ãª)æ„å‘³ã®ç¿’å¾—ã¨è¡¨ç¾ã«é–¢ã™ã‚‹å®Ÿé¨“çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é–‹ç™ºã—ã€æ´å¯Ÿã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã§LLMã‚’Next Token Predictionã§è¨“ç·´ã—<br>å³å¯†ã«æ­£è§£ã¨semanticsã‚’å®šç¾©ã—ãŸä¸Šã§ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ç•°ãªã‚‹semanticsã®ç•°ãªã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br>LLMãŒæ„å‘³ã‚’ç†è§£ã—ã¦ã„ã‚‹ã“ã¨ã‚’æš—ç¤ºã—ã¦ã„ã‚‹<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fa4d2c68-bdbe-40ae-990d-10814ac8a204" alt="image" loading="lazy"></p>
<p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1660409936264970240?s=46&t=QJho5ctFkeax7s_UMOfWBQ"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/561" target="_blank" rel="noopener noreferrer" class="title-link">Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond, Yang+, Amazon, TKDD'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è¨˜äº‹ã¯ã€è‡ªç„¶è¨€èªå‡¦ç†ï¼ˆNLPï¼‰ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å®Ÿè·µçš„ãªã‚¬ã‚¤ãƒ‰ã‚’æä¾›ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã€ã‚¿ã‚¹ã‚¯ã«é–¢ã™ã‚‹æ´å¯Ÿã‚’ç¤ºã—ã¾ã™ã€‚LLMsã®æ¦‚è¦ã€ãƒ‡ãƒ¼ã‚¿ã®å½±éŸ¿ã€çŸ¥è­˜é›†ç´„å‹ã‚¿ã‚¹ã‚¯ã‚„ç”Ÿæˆã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹ä½¿ç”¨ã‚±ãƒ¼ã‚¹ã¨éä½¿ç”¨ã‚±ãƒ¼ã‚¹ã‚’è©³è¿°ã—ã€å®Ÿç”¨çš„ãªå¿œç”¨ã¨é™ç•Œã‚’æ¢ã‚Šã¾ã™ã€‚ã¾ãŸã€è™šå½ã®ãƒã‚¤ã‚¢ã‚¹ã‚„å±•é–‹æ™‚ã®è€ƒæ…®äº‹é …ã«ã¤ã„ã¦ã‚‚è¨€åŠã—ã€ç ”ç©¶è€…ã‚„å®Ÿå‹™è€…ã«å½¹ç«‹ã¤ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚é–¢é€£ãƒªã‚½ãƒ¼ã‚¹ã¯å®šæœŸçš„ã«æ›´æ–°ã•ã‚Œã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã«é–¢ã™ã‚‹ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/235145819-842cdef3-485c-4553-b234-46d4896a5ed7.png" alt="image" loading="lazy"><br><br></p>
<p>encoder-onlyã¨ã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã‚‚ã®ã®ä¸­ã«ã¯ã€ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ãŒã‚ã‚‹ã‚‚ã®ãŒã‚ã‚Šï¼ˆautoregressive decoderã§ã¯ãªã„ï¼‰ã€<br>encoder-decoderã¯æ­£ã—ã„æ„å‘³ã¨ã—ã¦ã¯encoder with autoregressive decoderã§ã‚ã‚Šã€<br>decoder-onlyã¯æ­£ã—ã„æ„å‘³ã¨ã—ã¦ã¯autoregressive encoder-decoder<br>ã¨ã®ã“ã¨ã€‚<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ylecun/status/1651762787373428736?s=46&t=-zElejt4asTKBGLr-c3bKw"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/554" target="_blank" rel="noopener noreferrer" class="title-link">Active prompting with chain-of-thought for large language models, Diao+, The Hong Kong University of Science and Technology, ACL'24</a>
<span class="snippet"><span>Comment</span><p>ã—ã£ã‹ã‚Šã¨èª­ã‚ã¦ã„ãªã„ãŒã€CoT-answerãŒå­˜åœ¨ã—ãªã„trainingãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãŸã¨ãã«ã€nã‚µãƒ³ãƒ—ãƒ«ã«CoTã¨Answerã‚’ä¸ãˆã‚‹ã ã‘ã§Few-shotã®äºˆæ¸¬ã‚’testãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã§ãã‚‹ã‚ˆã†ã«ã—ãŸã„ã€ã¨ã„ã†ã®ãŒãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã£ã½ã„<br><br>ãã®ãŸã‚ã«ã€questionã«å¯¾ã—ã¦ã€training dataã«å¯¾ã—ã¦Few-Shot CoTã§äºˆæ¸¬ã‚’ã•ã›ãŸå ´åˆã‚„Zero-Shot CoTã«ã‚ˆã£ã¦äºˆæ¸¬ã‚’ã•ã›ãŸå ´åˆãªã©ã§answerã‚’å–å¾—ã—ã€answerã®ã°ã‚‰ã¤ãåº¦åˆã„ãªã©ã‹ã‚‰ä¸ç¢ºå®Ÿæ€§ã‚’æ¸¬å®šã™ã‚‹ã€‚<br><br>ãã—ã¦ã€ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„CoT-Answerãƒšã‚¢ã‚’å–å¾—ã—ã€äººé–“ãŒæ‰‹ä½œæ¥­ã§CoTã¨å›ç­”ã®ãƒšã‚¢ã‚’ä¸ãˆã€ãã®äººé–“ãŒä½œæˆã—ãŸã‚‚ã®ã‚’ç”¨ã„ã¦Testãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦FewShotã—ã¾ã—ã‚‡ã†ã€ã¨ã„ã†ã“ã¨ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/234747555-4b7bd0d5-f099-4288-a470-32206533e652.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2023-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/547" target="_blank" rel="noopener noreferrer" class="title-link">AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head, AAAI'24</a>
<span class="snippet"><span>GPT Summary</span>- AudioGPTã¯ã€è¤‡é›‘ãªéŸ³å£°æƒ…å ±ã‚’å‡¦ç†ã—ã€éŸ³å£°å¯¾è©±ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«AIã‚·ã‚¹ãƒ†ãƒ ã§ã‚ã‚‹ã€‚åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã¨ASRã€TTSã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’çµ„ã¿åˆã‚ã›ã€éŸ³å£°ã€éŸ³æ¥½ã€ãƒˆãƒ¼ã‚­ãƒ³ã‚°ãƒ˜ãƒƒãƒ‰ã®ç†è§£ã¨ç”Ÿæˆã‚’è¡Œã†ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€AudioGPTãŒå¤šæ§˜ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å‰µé€ ã‚’å®¹æ˜“ã«ã™ã‚‹èƒ½åŠ›ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>text, audio, imageã¨ã„ã£ãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªpromptã‹ã‚‰ã€audioã«é–¢ã™ã‚‹æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã‚’å®Ÿç¾ã§ãã‚‹ã‚·ã‚¹ãƒ†ãƒ </p>
<p>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’jointã§å­¦ç¿’ã—ãŸã¨ã„ã†ã‚ã‘ã§ã¯ãªãã€è‰²ã€…ãªãƒ¢ãƒ‡ãƒ«ã®çµ„ã¿åˆã‚ã›ã¦ã‚¿ã‚¹ã‚¯ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã£ã½ã„<br><br><img src="https://user-images.githubusercontent.com/12249301/234739859-f833706a-6040-484a-b015-553a719484d7.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2023-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/542" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Instruction-Finetuned Language Models, Chung+, Google, JMLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æŒ‡ç¤ºãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€ã‚¿ã‚¹ã‚¯æ•°ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã€ãƒã‚§ãƒ¼ãƒ³ãƒ»ã‚ªãƒ–ãƒ»ã‚½ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã§ã‚ã‚‹ã€‚Flan-PaLM 540Bã¯1.8Kã‚¿ã‚¹ã‚¯ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€PaLM 540Bã‚’ä¸Šå›ã‚‹+9.4%ã®æ”¹å–„ã‚’é”æˆã—ã€MMLUã§75.2%ã®æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚Flan-T5ã‚‚å¼·åŠ›ãªå°‘æ•°ã‚·ãƒ§ãƒƒãƒˆæ€§èƒ½ã‚’ç™ºæ®ã—ã€æŒ‡ç¤ºãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>T5ã‚’instruction tuningã—ãŸFlanT5ã®ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataGeneration.html" target="_blank" rel="noopener noreferrer">#DataGeneration</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/533" target="_blank" rel="noopener noreferrer" class="title-link">WizardLM: Empowering Large Language Models to Follow Complex Instructions, Xu+, Microsoft_Peking University, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€LLMã‚’ç”¨ã„ã¦è¤‡é›‘ãªæŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹æ‰‹æ³•Evol-Instructã‚’ææ¡ˆã€‚åˆæœŸã®æŒ‡ç¤ºã‚»ãƒƒãƒˆã‚’æ®µéšçš„ã«æ›¸ãæ›ãˆã€ç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã§LLaMAã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€WizardLMãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã€‚è©•ä¾¡çµæœã§ã¯ã€Evol-Instructã‹ã‚‰ã®æŒ‡ç¤ºãŒäººé–“ä½œæˆã®ã‚‚ã®ã‚ˆã‚Šå„ªã‚Œã€WizardLMã¯ChatGPTã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚AIé€²åŒ–ã«ã‚ˆã‚‹æŒ‡ç¤ºç”ŸæˆãŒLLMå¼·åŒ–ã®æœ‰æœ›ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>instruction trainingã¯å¤§ããªæˆåŠŸã‚’åã‚ã¦ã„ã‚‹ãŒã€äººé–“ãŒãã‚Œã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹ã®ã¯ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã€‚ã¾ãŸã€ãã‚‚ãã‚‚è¤‡é›‘ãªinstructionã‚’äººé–“ãŒä½œæˆã™ã‚‹ã®ã¯è‹¦åŠ´ã™ã‚‹ã€‚ãã“ã§ã€LLMã«è‡ªå‹•çš„ã«ä½œæˆã•ã›ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ï¼ˆã“ã‚Œã¯self instructã¨ä¸€ç·’ï¼‰ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹éš›ã¯ã€seed setã‹ã‚‰å§‹ã‚ã€step by stepã§instructionã‚’rewriteã—ã€ã‚ˆã‚Šè¤‡é›‘ãªinstructionã¨ãªã‚‹ã‚ˆã†ã«ã—ã¦ã„ãã€‚<br>ã“ã‚Œã‚‰ã®å¤šæ®µçš„ãªè¤‡é›‘åº¦ã‚’æŒã¤instructionã‚’LLaMaãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã«é£Ÿã‚ã›ã¦finetuningã—ãŸï¼ˆã“ã‚Œã‚’WizardLMã¨å‘¼ã¶ï¼‰ã€‚äººæ‰‹è©•ä¾¡ã®çµæœã€WizardLMãŒChatGPTã‚ˆã‚Šã‚‚å¥½ã¾ã—ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ç‰¹ã«ã€WizaraLMã¯ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚„ã€æ•°å€¤è¨ˆç®—ã¨ã„ã£ãŸé›£ã—ã„ã‚¿ã‚¹ã‚¯ã§æ”¹å–„ã‚’ç¤ºã—ã¦ãŠã‚Šã€è¤‡é›‘ãªinstructionã‚’å­¦ç¿’ã«åˆ©ç”¨ã™ã‚‹ã“ã¨ã®é‡è¦æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</p>
<p>EvolInstructã‚’ææ¡ˆã€‚"1+1=?"ã¨ã„ã£ãŸã‚·ãƒ³ãƒ—ãƒ«ãªinstructionã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã—ã€ã“ã‚Œã‚’LLMã‚’åˆ©ç”¨ã—ã¦æ®µéšçš„ã«complexã«ã—ã¦ã„ãã€‚complexã«ã™ã‚‹æ–¹æ³•ã¯2é€šã‚Šï¼š<br><br>- In-Depth Evolving: instructionã‚’5ç¨®é¡ã®operationã§æ·±æ˜ã‚Šã™ã‚‹ï¼ˆblue direction lineï¼‰<br><br>  - add constraints<br><br>  - deepening<br><br>  - concretizing<br><br>  - increase reasoning steps<br><br>  - complicate input<br><br>- In-breadth Evolving: givenãªinstructionã‹ã‚‰æ–°ã—ã„instructionã‚’ç”Ÿæˆã™ã‚‹<br><br><br><br>ä¸Šè¨˜ã®Evolvingã¯ç‰¹å®šã®promptã‚’ä¸ãˆã‚‹ã“ã¨ã§å®Ÿè¡Œã•ã‚Œã‚‹ã€‚<br><br>ã¾ãŸã€LLMã¯Evolvingã«å¤±æ•—ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã®ã§ã€Elimination Evolvingã¨å‘¼ã°ã‚Œã‚‹ãƒ•ã‚£ãƒ«ã‚¿ã‚’åˆ©ç”¨ã—ã¦ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸã€‚<br><br>ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã§ã¯4ç¨®é¡ã®å¤±æ•—ã™ã‚‹situationã‚’æƒ³å®šã—ã€1ã¤ã§ã¯LLMã‚’åˆ©ç”¨ã€‚2æšç›®ç”»åƒã®ã‚ˆã†ãªinstructionã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€‚<br><br>1. instructionã®æƒ…å ±é‡ãŒå¢—ãˆã¦ã„ãªã„å ´åˆã€‚<br><br>2. instructionãŒLLMã«ã‚ˆã£ã¦å¿œç­”å›°é›£ãªå ´åˆï¼ˆçŸ­ã™ãã‚‹å ´åˆã‚„sorryã¨è¨€ã£ã¦ã„ã‚‹å ´åˆï¼‰<br><br>3. puctuationã‚„stop wordsã«ã‚ˆã£ã¦ã®ã¿æ§‹æˆã•ã‚Œã¦ã„ã‚‹å ´åˆ <br><br>4.æ˜ã‚‰ã‹ã«promptã®ä¸­ã‹ã‚‰å˜èªã‚’ã‚³ãƒ”ãƒ¼ã—ãŸã ã‘ã®instructionï¼ˆgiven prompt, rewritten prompt, #Rewritten Prompt#ãªã©ï¼‰<br><br><img src="https://user-images.githubusercontent.com/12249301/234436445-e84ff44e-7b0b-4217-a735-7444b04bd760.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/234437210-6cb6d75f-509a-4f2e-a767-dba8861d8a69.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3370" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Language Modelling with Pixels, Phillip Rust+, ICLR'23, 2022.07</a>
<span class="snippet"><span>GPT Summary</span>- PIXELã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”»åƒã¨ã—ã¦è¡¨ç¾ã™ã‚‹æ–°ã—ã„è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€èªå½™ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’å›é¿ã—ã€è¨€èªé–“ã§ã®è¡¨ç¾è»¢é€ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚86Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®PIXELã¯ã€BERTã¨åŒã˜ãƒ‡ãƒ¼ã‚¿ã§äº‹å‰å­¦ç¿’ã•ã‚Œã€éãƒ©ãƒ†ãƒ³æ–‡å­—ã‚’å«ã‚€å¤šæ§˜ãªè¨€èªã§ã®æ§‹æ–‡çš„ãŠã‚ˆã³æ„å‘³çš„ã‚¿ã‚¹ã‚¯ã§BERTã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸãŒã€ãƒ©ãƒ†ãƒ³æ–‡å­—ã§ã¯ã‚„ã‚„åŠ£ã‚‹çµæœã¨ãªã£ãŸã€‚ã¾ãŸã€PIXELã¯æ­£å­—æ³•çš„æ”»æ’ƒã‚„è¨€èªã‚³ãƒ¼ãƒ‰ã‚¹ã‚¤ãƒƒãƒãƒ³ã‚°ã«å¯¾ã—ã¦BERTã‚ˆã‚Šã‚‚å …ç‰¢ã§ã‚ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nielsrogge/status/1980559120760791125?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/BeamSearch.html" target="_blank" rel="noopener noreferrer">#BeamSearch</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3056" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Evaluation Guided Beam Search for Reasoning, Yuxi Xie+, NeurIPS'23, 2023.05</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã€æ®µéšçš„è‡ªå·±è©•ä¾¡ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å°å…¥ã—ã€ç¢ºç‡çš„ãƒ“ãƒ¼ãƒ ã‚µãƒ¼ãƒã‚’ç”¨ã„ãŸãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ¨è«–ã®ä¸ç¢ºå®Ÿæ€§ã‚’è»½æ¸›ã—ã€GSM8Kã€AQuAã€StrategyQAã§ã®ç²¾åº¦ã‚’å‘ä¸Šã€‚Llama-2ã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã‚‚åŠ¹ç‡æ€§ãŒç¤ºã•ã‚Œã€è‡ªå·±è©•ä¾¡ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ãŒè«–ç†çš„ãªå¤±æ•—ã‚’ç‰¹å®šã—ã€ä¸€è²«æ€§ã‚’é«˜ã‚ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://guideddecoding.github.io" target="_blank" rel="noopener noreferrer">https://guideddecoding.github.io</a>


</p>
<p>openreview:


<a href="https://openreview.net/forum?id=Bw82hwg5Q3" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Bw82hwg5Q3</a>


</p>
<p>éå¸¸ã«ã–ã£ãã‚Šè¨€ã†ã¨ã€reasoning chainï¼ˆï¼è¤‡æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã®sequence)ã‚’ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã¿ãªã—ãŸå ´åˆã®ï¼ˆç¢ºç‡çš„ï¼‰beam searchã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚å¤šæ§˜ãªreasoning chainã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ãã®ä¸­ã‹ã‚‰è‰¯ã„ã‚‚ã®ã‚’ãƒ“ãƒ¼ãƒ å¹…kã§ä¿æŒã—ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€æœ€çµ‚çš„ã«è‰¯ã„ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°çµæœã‚’å¾—ã‚‹ã€‚reasoning chainã®ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã«temperatureã‚’è¨­å®šã™ã‚‹ãŒã€ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°ã‚’ã™ã‚‹ã“ã¨ã§chainã«ãŠã‘ã‚‹ã‚¨ãƒ©ãƒ¼ãŒè“„ç©ã™ã‚‹ã“ã¨ã‚’é˜²ãã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æœ€åˆã¯å¤šæ§˜æ€§ã‚’é‡è¦–ã—ãŸç”ŸæˆãŒã•ã‚Œã‚‹ãŒã€ã‚¨ãƒ©ãƒ¼ãŒè“„ç©ã•ã‚Œç™ºæ•£ã™ã‚‹ã“ã¨ã‚’é˜²ãã€‚<br><br><img src="https://github.com/user-attachments/assets/b3b8b45c-7a75-418b-bcd1-e43e71d96585" alt="image" loading="lazy"><br><br>reasoning chainã®è‰¯ã•ã‚’åˆ¤æ–­ã™ã‚‹ãŸã‚ã«ã€chainã®å°¤åº¦ã ã‘ã§ãªãã€self-evaluationã«ã‚ˆã‚‹reasoning chainã®æ­£ã—ã•ã«é–¢ã™ã‚‹confidenceã‚¹ã‚³ã‚¢ã‚‚å°å…¥ã™ã‚‹ï¼ˆreasoning chainã®confidenceã‚¹ã‚³ã‚¢ã«ã‚ˆã£ã¦é‡ã¿ã¥ã‘ã‚‰ã‚ŒãŸchainã®å°¤åº¦ã‚’æœ€å¤§åŒ–ã™ã‚‹ã‚ˆã†ãªå®šå¼åŒ–ã«ãªã‚‹ï¼ˆå¼3))ã€‚<br>self-evaluationã¨ç”Ÿæˆã¯ã¨ã‚‚ã«åŒã˜LLMã«ã‚ˆã£ã¦å®Ÿç¾ã•ã‚Œã‚‹ãŒã€self-evaluationã«ã¤ã„ã¦ã¯è©•ä¾¡ç”¨ã®few-shot promptingã‚’å®Ÿæ–½ã™ã‚‹ã€‚promptingã§ã¯ã€ã“ã‚Œã¾ã§ã®reasoning chainã¨ã€æ–°ãŸãªreasoning chainãŒgivenãªã¨ãã«ã€ãã‚ŒãŒ(A)correct/(B)incorrectãªã®ã‹ã‚’multiple choice questionã§åˆ¤å®šã—ã€é¸æŠè‚¢AãŒç”Ÿæˆã•ã‚Œã‚‹ç¢ºç‡ã‚’ã‚¹ã‚³ã‚¢ã¨ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/f9934a71-9e0c-4145-b925-4c231915affd" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2981" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Large Language Models are Better Reasoners with Self-Verification, Yixuan Weng+, EMNLP'23 Findings, 2022.12</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯CoTãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã«ã‚ˆã‚Šå¼·åŠ›ãªæ¨è«–èƒ½åŠ›ã‚’ç¤ºã™ãŒã€ã‚¨ãƒ©ãƒ¼ã®è“„ç©ã«è„†å¼±ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LLMsãŒè‡ªå·±æ¤œè¨¼èƒ½åŠ›ã‚’æŒã¤ã“ã¨ã‚’ææ¡ˆã—ã€æ¨è«–ã—ãŸå›ç­”ã‚’é€†æ¤œè¨¼ã™ã‚‹ã“ã¨ã§è§£é‡ˆå¯èƒ½ãªæ¤œè¨¼ã‚¹ã‚³ã‚¢ã‚’å¾—ã‚‹æ‰‹æ³•ã‚’ç¤ºã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆæ‰‹æ³•ãŒç®—æ•°ã€å¸¸è­˜ã€è«–ç†æ¨è«–ã‚¿ã‚¹ã‚¯ã§ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=s4xIeYimGQ" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=s4xIeYimGQ</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2962" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for  Generative Large Language Models, Potsawee Manakul+, EMNLP'23, 2023.03</a>
<span class="snippet"><span>GPT Summary</span>- SelfCheckGPTã¯ã€å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã—ã§LLMã®å¿œç­”ã‚’ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã™ã‚‹ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸå¿œç­”ãŒä¸€è²«ã—ãŸäº‹å®Ÿã‚’å«ã‚€å ´åˆã€çŸ¥è­˜ãŒã‚ã‚‹ã¨åˆ¤æ–­ã—ã€å¹»è¦šã•ã‚ŒãŸäº‹å®Ÿã§ã¯çŸ›ç›¾ãŒç”Ÿã˜ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€éäº‹å®Ÿçš„ãŠã‚ˆã³äº‹å®Ÿçš„ãªæ–‡ã®æ¤œå‡ºã€æ–‡ç« ã®ãƒ©ãƒ³ã‚¯ä»˜ã‘ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€é«˜ã„AUC-PRã‚¹ã‚³ã‚¢ã¨ç›¸é–¢ã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=RwzFNbJ3Ez" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=RwzFNbJ3Ez</a>


</p>
<p>è©•ä¾¡ã«é–¢é€£ã™ã‚‹æ‰‹æ³•:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/89" target="_blank" rel="noopener noreferrer">[Paper Note] Neural Text Generation from Structured Data with Application to the  Biography Domain, Remi Lebret+, EMNLP'16, 2016.03</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2956" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FreshLLMs: Refreshing Large Language Models with Search Engine  Augmentation, Tu Vu+, ACL'23 Findings, 2023.10</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯å¤‰åŒ–ã™ã‚‹ä¸–ç•Œã«é©å¿œã§ããšã€äº‹å®Ÿæ€§ã«èª²é¡ŒãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€å‹•çš„QAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒFreshQAã€ã‚’å°å…¥ã—ã€è¿…é€Ÿã«å¤‰åŒ–ã™ã‚‹çŸ¥è­˜ã‚„èª¤ã£ãŸå‰æã‚’å«ã‚€è³ªå•ã«å¯¾ã™ã‚‹LLMã®æ€§èƒ½ã‚’è©•ä¾¡ã€‚è©•ä¾¡ã®çµæœã€å…¨ãƒ¢ãƒ‡ãƒ«ãŒã“ã‚Œã‚‰ã®è³ªå•ã«è‹¦åŠ´ã—ã¦ã„ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚ã“ã‚Œã‚’å—ã‘ã¦ã€æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰ã®æœ€æ–°æƒ…å ±ã‚’çµ„ã¿è¾¼ã‚€ã€ŒFreshPromptã€ã‚’ææ¡ˆã—ã€LLMã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã«æˆåŠŸã€‚FreshPromptã¯ã€è¨¼æ‹ ã®æ•°ã¨é †åºãŒæ­£ç¢ºæ€§ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ç¤ºã—ã€ç°¡æ½”ãªå›ç­”ã‚’ä¿ƒã™ã“ã¨ã§å¹»è¦šã‚’æ¸›å°‘ã•ã›ã‚‹åŠ¹æœã‚‚ç¢ºèªã€‚FreshQAã¯å…¬é–‹ã•ã‚Œã€ä»Šå¾Œã‚‚æ›´æ–°ã•ã‚Œã‚‹äºˆå®šã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2955" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Check Your Facts and Try Again: Improving Large Language Models with  External Knowledge and Automated Feedback, Baolin Peng+, arXiv'23, 2023.02</a>
<span class="snippet"><span>GPT Summary</span>- LLM-Augmenterã‚·ã‚¹ãƒ†ãƒ ã‚’ææ¡ˆã—ã€LLMãŒå¤–éƒ¨çŸ¥è­˜ã«åŸºã¥ã„ãŸå¿œç­”ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«æ‹¡å¼µã€‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”¨ã„ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ”¹å–„ã—ã€ã‚¿ã‚¹ã‚¯æŒ‡å‘ã®å¯¾è©±ã¨è³ªå•å¿œç­”ã§ã®æœ‰åŠ¹æ€§ã‚’å®Ÿè¨¼ã€‚ChatGPTã®å¹»è¦šã‚’æ¸›å°‘ã•ã›ã¤ã¤ã€æµæš¢ã•ã‚„æƒ…å ±é‡ã‚’ç¶­æŒã€‚ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ã‚’å…¬é–‹ã€‚</span>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2474" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Efficient Memory Management for Large Language Model Serving with  PagedAttention, Woosuk Kwon+, SOSP'23</a>
<span class="snippet"><span>GPT Summary</span>- PagedAttentionã‚’ç”¨ã„ãŸvLLMã‚·ã‚¹ãƒ†ãƒ ã‚’ææ¡ˆã—ã€KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¡ãƒ¢ãƒªã®ç„¡é§„ã‚’å‰Šæ¸›ã—ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“ã§ã®æŸ”è»Ÿãªå…±æœ‰ã‚’å®Ÿç¾ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åŒãƒ¬ãƒ™ãƒ«ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã§LLMã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’2-4å€å‘ä¸Šã€‚ç‰¹ã«é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚„å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§åŠ¹æœãŒé¡•è‘—ã€‚ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ä¸­ã€‚</span>
<span class="snippet"><span>Comment</span><p>ï¼ˆä»Šæ›´ãªãŒã‚‰ï¼‰vLLMã¯ã“ã¡ã‚‰:<br>


<a href="https://github.com/vllm-project/vllm" target="_blank" rel="noopener noreferrer">https://github.com/vllm-project/vllm</a>


<br><br>ç¾åœ¨ã®ä¸»è¦ãªLLM Inference/Serving Engineã®ã²ã¨ã¤ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2400" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Physics of Language Models: Part 1, Learning Hierarchical Language  Structures, Zeyuan Allen-Zhu+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Transformerãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ãŒæ–‡è„ˆè‡ªç”±æ–‡æ³•ï¼ˆCFGï¼‰ã«ã‚ˆã‚‹å†å¸°çš„ãªè¨€èªæ§‹é€ æ¨è«–ã‚’ã©ã®ã‚ˆã†ã«è¡Œã†ã‹ã‚’èª¿æŸ»ã€‚åˆæˆCFGã‚’ç”¨ã„ã¦é•·æ–‡ã‚’ç”Ÿæˆã—ã€GPTã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ãŒCFGã®éšå±¤ã‚’æ­£ç¢ºã«å­¦ç¿’ãƒ»æ¨è«–ã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®éš ã‚ŒçŠ¶æ…‹ãŒCFGã®æ§‹é€ ã‚’æ‰ãˆã€æ³¨æ„ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå‹•çš„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã«é¡ä¼¼ã—ã¦ã„ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚ã¾ãŸã€çµ¶å¯¾ä½ç½®åŸ‹ã‚è¾¼ã¿ã®åŠ£ä½ã‚„å‡ä¸€ãªæ³¨æ„ã®åŠ¹æœã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å°‚ç”¨ãƒ¢ãƒ‡ãƒ«ã®é™ç•Œã€æ§‹é€ çš„ãƒã‚¤ã‚ºã«ã‚ˆã‚‹å …ç‰¢æ€§å‘ä¸Šã«ã¤ã„ã¦ã‚‚è€ƒå¯Ÿã€‚</span>
<span class="snippet"><span>Comment</span><p>è§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2275" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Large Language Models Can Self-Improve, Jiaxin Huang+, EMNLP'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMã¯ãƒ©ãƒ™ãƒ«ã®ãªã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è‡ªå·±æ”¹å–„å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€Chain-of-Thoughtãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã¨è‡ªå·±ä¸€è²«æ€§ã‚’åˆ©ç”¨ã—ã¦é«˜ä¿¡é ¼åº¦ã®å›ç­”ã‚’ç”Ÿæˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€540Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã€æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒè‡ªå·±æ”¹å–„ã«é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚‚ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=uuUQraD4XX&noteId=PWDEpZtn6P" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=uuUQraD4XX&noteId=PWDEpZtn6P</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ICCV.html" target="_blank" rel="noopener noreferrer">#ICCV</a>
<span class="issue_date">Issue Date: 2025-06-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2111" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Sigmoid Loss for Language Image Pre-Training, Xiaohua Zhai+, ICCV'23</a>
<span class="snippet"><span>GPT Summary</span>- ã‚·ãƒ³ãƒ—ãƒ«ãªãƒšã‚¢ãƒ¯ã‚¤ã‚ºã‚·ã‚°ãƒ¢ã‚¤ãƒ‰æå¤±ï¼ˆSigLIPï¼‰ã‚’ææ¡ˆã—ã€ç”»åƒ-ãƒ†ã‚­ã‚¹ãƒˆãƒšã‚¢ã«åŸºã¥ãè¨€èª-ç”»åƒäº‹å‰å­¦ç¿’ã‚’æ”¹å–„ã€‚ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰æå¤±ã¯ãƒãƒƒãƒã‚µã‚¤ã‚ºã®æ‹¡å¤§ã‚’å¯èƒ½ã«ã—ã€å°ã•ãªãƒãƒƒãƒã‚µã‚¤ã‚ºã§ã‚‚æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã€‚SigLiTãƒ¢ãƒ‡ãƒ«ã¯84.5%ã®ImageNetã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆç²¾åº¦ã‚’é”æˆã€‚ãƒãƒƒãƒã‚µã‚¤ã‚ºã®å½±éŸ¿ã‚’ç ”ç©¶ã—ã€32kãŒåˆç†çš„ãªã‚µã‚¤ã‚ºã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã€ã•ã‚‰ãªã‚‹ç ”ç©¶ã®ä¿ƒé€²ã‚’æœŸå¾…ã€‚</span>
<span class="snippet"><span>Comment</span><p>SigLIPè«–æ–‡</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Inference.html" target="_blank" rel="noopener noreferrer">#Inference</a>
<span class="issue_date">Issue Date: 2025-06-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2028" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked  Prefills, Amey Agrawal+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- SARATHIã¯ã€LLMã®æ¨è«–åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã§ã€ãƒ—ãƒ¬ãƒ•ã‚£ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã€ãƒ‡ã‚³ãƒ¼ãƒ‰ãƒã‚­ã‚·ãƒãƒ«ãƒãƒƒãƒã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã§è¨ˆç®—åˆ©ç”¨ç‡ã‚’æœ€å¤§åŒ–ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’æœ€å¤§10å€å‘ä¸Šã•ã›ã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚‚æ”¹å–„ã€‚ç‰¹ã«ã€A6000 GPUä¸Šã®LLaMA-13Bãƒ¢ãƒ‡ãƒ«ã§é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒãƒ–ãƒ«ã‚’å¤§å¹…ã«å‰Šæ¸›ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>vLLMã§ã‚‚æ¡ç”¨ã•ã‚Œã¦ã„ã‚‹ `Chunked Prefills` ã¨ `Decode-Maximal Batching` ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br>![Image](https://github.com/user-attachments/assets/4db0f73d-bdf4-4c2b-a765-2c9b242904f1)</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Parallelism.html" target="_blank" rel="noopener noreferrer">#Parallelism</a>
<span class="issue_date">Issue Date: 2025-05-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1970" target="_blank" rel="noopener noreferrer" class="title-link">Sequence Parallelism: Long Sequence Training from System Perspective, Li+, ACL'23</a>
<span class="snippet"><span>Comment</span><p>å…¥åŠ›ç³»åˆ—ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦ã€ãƒ‡ãƒã‚¤ã‚¹ã”ã¨ã«æ‹…å½“ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ã‚’æ±ºã‚ã‚‹ã“ã¨ã§åŸç†ä¸Šç„¡é™ã®é•·ã•ã®ç³»åˆ—ã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«ã—ãŸä¸¦åˆ—åŒ–æ‰‹æ³•ã€‚ç³»åˆ—ã‚’ãƒ‡ãƒã‚¤ã‚¹é–“ã§æ¨ªæ–­ã™ã‚‹å ´åˆattention scoreã‚’ã©ã®ã‚ˆã†ã«è¨ˆç®—ã™ã‚‹ã‹ãŒèª²é¡Œã«ãªã‚‹ãŒã€ãã®ãŸã‚ã«Ring Self attentionã¨å‘¼ã°ã‚Œã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ã¾ãŸã€MLPãƒ–ãƒ­ãƒƒã‚¯ã¨Multi Head Attentonãƒ–ãƒ­ãƒƒã‚¯ã®è¨ˆç®—ã‚‚ã€BatchSize * Sequence Lengthã®å¤§ãã•ãŒã€ãã‚Œãã‚Œ32*Hidden Size, 16*Attention Head size * 
<strong># of Attention Headã‚ˆã‚Šã‚‚å¤§ãããªã£ãŸå ´åˆã«ã€Tensor Parallelismã‚ˆã‚Šã‚‚ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ããªã‚‹ã‚‰ã—ã„ã€‚<br><img src="https://github.com/user-attachments/assets/f3ba9010-da3a-4c3a-8515-d3715466ff59" alt="image" loading="lazy">&lt;/p&gt;<p>Data Parallel, Pipeline Parallel, Tensor Parallelã€å…¨ã¦ã«äº’æ›æ€§ãŒã‚ã‚‹ã¨ã®ã“ã¨ï¼ˆä½µç”¨å¯èƒ½ï¼‰</p>
<p>ãã®ã»ã‹ã®ä¸¦åˆ—åŒ–ã®è§£èª¬ã«ã¤ã„ã¦ã¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1184" target="_blank" rel="noopener noreferrer">å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’æ”¯ãˆã‚‹åˆ†æ•£ä¸¦åˆ—å­¦ç¿’ã®ã—ãã¿ Part1</a>
&lt;/strong&gt;
<br>
<br><br>ã‚’å‚ç…§ã®ã“ã¨ã€‚</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ActivationSteering/ITI.html" target="_blank" rel="noopener noreferrer">#ActivationSteering/ITI</a>
<a class="button" href="articles/Probing.html" target="_blank" rel="noopener noreferrer">#Probing</a>
<a class="button" href="articles/Trustfulness.html" target="_blank" rel="noopener noreferrer">#Trustfulness</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1941" target="_blank" rel="noopener noreferrer" class="title-link">Inference-Time Intervention: Eliciting Truthful Answers from a Language   Model, Kenneth Li+, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- Inference-Time Intervention (ITI)ã‚’ææ¡ˆã—ã€LLMsã®çœŸå®Ÿæ€§ã‚’å‘ä¸Šã•ã›ã‚‹æŠ€è¡“ã‚’ç´¹ä»‹ã€‚ITIã¯æ¨è«–ä¸­ã«ãƒ¢ãƒ‡ãƒ«ã®æ´»æ€§åŒ–ã‚’èª¿æ•´ã—ã€LLaMAãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’TruthfulQAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¤§å¹…ã«æ”¹å–„ã€‚Alpacaãƒ¢ãƒ‡ãƒ«ã§ã¯çœŸå®Ÿæ€§ãŒ32.5%ã‹ã‚‰65.1%ã«å‘ä¸Šã€‚çœŸå®Ÿæ€§ã¨æœ‰ç”¨æ€§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’ç‰¹å®šã—ã€ä»‹å…¥ã®å¼·åº¦ã‚’èª¿æ•´ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€‚ITIã¯ä½ã‚³ã‚¹ãƒˆã§ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ãŒé«˜ãã€æ•°ç™¾ã®ä¾‹ã§çœŸå®Ÿã®æ–¹å‘æ€§ã‚’ç‰¹å®šå¯èƒ½ã€‚LLMsãŒè™šå½ã‚’ç”Ÿæˆã—ã¤ã¤ã‚‚çœŸå®Ÿã®å†…éƒ¨è¡¨ç¾ã‚’æŒã¤å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>Inference Time Interventionã‚’ææ¡ˆã—ãŸç ”ç©¶ã€‚Attention Headã«å¯¾ã—ã¦ç·šå½¢ãƒ—ãƒ­ãƒ¼ãƒ“ãƒ³ã‚°[^1]ã‚’å®Ÿæ–½ã—ã€çœŸå®Ÿæ€§ã«é–¢é€£ã™ã‚‹ã§ã‚ã‚ã†Headã‚’topKã§ç‰¹å®šã§ãã‚‹ã‚ˆã†ã«ã—ã€headã®å‡ºåŠ›ã«å¯¾ã—çœŸå®Ÿæ€§ã‚’é«˜ã‚ã‚‹æ–¹å‘æ€§ã®ãƒ™ã‚¯ãƒˆãƒ«vã‚’æ¨è«–æ™‚ã«åŠ ç®—ã™ã‚‹ã“ã¨ã§ï¼ˆï¼interventionï¼‰ã€ãƒ¢ãƒ‡ãƒ«ã®çœŸå®Ÿæ€§ã‚’é«˜ã‚ã‚‹ã€‚vã¯ç·šå½¢ãƒ—ãƒ­ãƒ¼ãƒ“ãƒ³ã‚°ã«ã‚ˆã£ã¦å­¦ç¿’ã•ã‚ŒãŸé‡ã¿ã‚’ä½¿ã†æ‰‹æ³•ã¨ã€æ­£ç­”ã¨èª¤ç­”ã®æ´»æ€§åŒ–ã®å¹³å‡ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—ã—ãã®å·®åˆ†ã‚’vã¨ã™ã‚‹æ–¹æ³•ã®äºŒç¨®é¡ãŒã‚ã‚‹ã€‚å¾Œè€…ã®æ–¹ãŒæ€§èƒ½ãŒè‰¯ã„ã€‚topKã‚’æ±‚ã‚ã‚‹éš›ã«ã¯ã€ç·šå½¢ãƒ—ãƒ­ãƒ¼ãƒ“ãƒ³ã‚°ã‚’ã—ãŸãƒ¢ãƒ‡ãƒ«ã®validation setã§ã®æ€§èƒ½ã‹ã‚‰æ±ºã‚ã‚‹ã€‚Kã¨Î±ã¯ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚ã‚‹ã€‚<br><br>[^1]: headã®representationã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã€ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã€ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã®2å€¤åˆ†é¡æ€§èƒ½ã‚’è¦‹ã‚‹ã“ã¨ã§headãŒã©ã®ç¨‹åº¦ã€ãƒ—ãƒ­ãƒ¼ãƒ“ãƒ³ã‚°ã®å­¦ç¿’ã«ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹æƒ…å ±ã‚’ä¿æŒã—ã¦ã„ã‚‹ã‹ã‚’æ¸¬å®šã™ã‚‹æ‰‹æ³•<br><br>æ—¥æœ¬èªè§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:


<a href="https://www.docswell.com/s/DeepLearning2023/Z38P8D-2024-06-20-131813#p1" target="_blank" rel="noopener noreferrer">https://www.docswell.com/s/DeepLearning2023/Z38P8D-2024-06-20-131813#p1</a>


</p>
<p>ã“ã‚Œã¯ç›¸å½“æ±ç”¨çš„ã«ä½¿ãˆãã†ãªè©±ã ã‹ã‚‰å½¹ã«ç«‹ã¡ãã†</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-04-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1881" target="_blank" rel="noopener noreferrer" class="title-link">PaLI-3 Vision Language Models: Smaller, Faster, Stronger, Xi Chen+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- PaLI-3ã¯ã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦10å€å°å‹ã§é«˜é€Ÿãªè¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆVLMï¼‰ã§ã‚ã‚Šã€ç‰¹ã«ãƒ­ãƒ¼ã‚«ãƒªã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã‚„è¦–è¦šçš„ãƒ†ã‚­ã‚¹ãƒˆç†è§£ã«ãŠã„ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ã€‚SigLIPãƒ™ãƒ¼ã‚¹ã®PaLIã¯ã€20å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã•ã‚Œã€å¤šè¨€èªã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«æ¤œç´¢ã§æ–°ãŸãªæœ€å…ˆç«¯ã‚’é”æˆã€‚50å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®PaLI-3ã¯ã€VLMã®ç ”ç©¶ã‚’å†ç‡ƒã•ã›ã‚‹ã“ã¨ã‚’æœŸå¾…ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=JpyWPfzu0b" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=JpyWPfzu0b</a>


<br><br>å®Ÿé¨“çš„ã«ç´ æ™´ã‚‰ã—ã„æ€§èƒ½ãŒå®Ÿç¾ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã¯èªã‚ã‚‰ã‚Œã¤ã¤ã‚‚<br>- æ¯”è¼ƒå¯¾è±¡ãŒSigLIPã®ã¿ã§ã‚ˆã‚Šåºƒç¯„ãªæ¯”è¼ƒå®Ÿé¨“ã¨åˆ†æãŒå¿…è¦ãªã“ã¨<br>- Backboneãƒ¢ãƒ‡ãƒ«ã‚’Contrastive Learningã™ã‚‹ã“ã¨è‡ªä½“ã®æœ‰ç”¨æ€§ã¯æ—¢ã«çŸ¥ã‚‰ã‚Œã¦ãŠã‚Šã€æ–°è¦æ€§ã«ä¹ã—ã„ã“ã¨<br><br>ã¨ã—ã¦ICLR'24ã«Rejectã•ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-04-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1865" target="_blank" rel="noopener noreferrer" class="title-link">The Impact of Positional Encoding on Length Generalization in   Transformers, Amirhossein Kazemnejad+, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- é•·ã•ä¸€èˆ¬åŒ–ã¯Transformerãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹é‡è¦ãªèª²é¡Œã§ã‚ã‚Šã€ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆPEï¼‰ãŒãã®æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã€‚5ã¤ã®ç•°ãªã‚‹PEæ‰‹æ³•ï¼ˆAPEã€T5ã®ç›¸å¯¾PEã€ALiBiã€Rotaryã€NoPEï¼‰ã‚’æ¯”è¼ƒã—ãŸçµæœã€ALiBiã‚„Rotaryãªã©ã®ä¸€èˆ¬çš„ãªæ‰‹æ³•ã¯é•·ã•ä¸€èˆ¬åŒ–ã«é©ã—ã¦ãŠã‚‰ãšã€NoPEãŒä»–ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚NoPEã¯è¿½åŠ ã®è¨ˆç®—ã‚’å¿…è¦ã¨ã›ãšã€çµ¶å¯¾PEã¨ç›¸å¯¾PEã®ä¸¡æ–¹ã‚’è¡¨ç¾å¯èƒ½ã§ã‚ã‚‹ã€‚ã•ã‚‰ã«ã€ã‚¹ã‚¯ãƒ©ãƒƒãƒãƒ‘ãƒƒãƒ‰ã®å½¢å¼ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚ã“ã®ç ”ç©¶ã¯ã€æ˜ç¤ºçš„ãªä½ç½®åŸ‹ã‚è¾¼ã¿ãŒé•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¸ã®ä¸€èˆ¬åŒ–ã«å¿…é ˆã§ãªã„ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1863" target="_blank" rel="noopener noreferrer">Llama 4 Series, Meta, 2025.04</a>
<br><br>ã«ãŠã„ã¦ã€Llama4 ScoutãŒ10Mã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’å®Ÿç¾ã§ãã‚‹ç†ç”±ã®ä¸€ã¤ã¨ã®ã“ã¨ã€‚<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/drjimfan/status/1908615861650547081?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Llama4ã®ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆã«ã‚‚ãã®æ—¨è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹:<br>&gt;A key innovation in the Llama 4 architecture is the use of interleaved attention layers without positional embeddings. Additionally, we employ inference time temperature scaling of attention to enhance length generalization.<br><br>[The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation](


<a href="https://ai.meta.com/blog/llama-4-multimodal-intelligence/?utm_source=twitter&utm_medium=organic_social&utm_content=image&utm_campaign=llama4)" target="_blank" rel="noopener noreferrer">https://ai.meta.com/blog/llama-4-multimodal-intelligence/?utm_source=twitter&utm_medium=organic_social&utm_content=image&utm_campaign=llama4)</a>


</span></strong></p>
<p>æ–œã‚èª­ã¿ã ãŒã€length generalizationã‚’è©•ä¾¡ã™ã‚‹ä¸Šã§downstream taskã«ç„¦ç‚¹ã‚’å½“ã¦ã€3ã¤ã®ä»£è¡¨çš„ãªã‚«ãƒ†ã‚´ãƒªã«ç›¸å½“ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã—ãŸã¨ã“ã‚ã€ã“ã®è¦³ç‚¹ã«ãŠã„ã¦ã¯T5ã®relative positinal encodingã¨NoPEï¼ˆä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ³ã‚°ç„¡ã—ï¼‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒè‰¯ãã€<br><br><img src="https://github.com/user-attachments/assets/dddadfff-ab28-4073-96c3-831eb16845a0" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/c6ec8e0e-7abb-4330-be23-2261486a477c" alt="image" loading="lazy"><br><br>NoPEã¯çµ¶å¯¾ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ç›¸å¯¾ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç†è«–ä¸Šå®Ÿç¾å¯èƒ½ã§ã‚ã‚Š[^1]<br><img src="https://github.com/user-attachments/assets/bbcf797a-d394-42d4-b017-08d7dba4261c" alt="image" loading="lazy"><br><br>å®Ÿéš›ã«å­¦ç¿’ã•ã‚ŒãŸç•°ãªã‚‹2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦åŒã˜ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãã‚Œãã‚Œinputã—ã€åŒã˜æ·±ã•ã®Layerã®å…¨ã¦ã®attention distributionã®çµ„ã¿åˆã‚ã›ã‹ã‚‰Jensen Shannon Divergenceã§è·é›¢ã‚’ç®—å‡ºã—ã€æœ€ã‚‚å°ã•ã„ã‚‚ã®ã‚’2ãƒ¢ãƒ‡ãƒ«é–“ã®å½“è©²layerã®è·é›¢ã¨ã—ã¦å¯è¦–åŒ–ã™ã‚‹ã¨ä¸‹è¨˜ã®ã‚ˆã†ã«ãªã‚Šã€NoPEã¨T5ã®relative positional encodingãŒæœ€ã‚‚é¡ä¼¼ã—ã¦ã„ã‚‹ã“ã¨ã‹ã‚‰ã€NoPEãŒå­¦ç¿’ã‚’é€šã˜ã¦ï¼ˆå®Ÿç”¨ä¸Šã¯ï¼‰ç›¸å¯¾ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ã‚ˆã†ãªã‚‚ã®ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚<br><img src="https://github.com/user-attachments/assets/9619c7e5-0612-45de-8717-1634bee509b7" alt="image" loading="lazy"><br><br>[^1]:æ·±ã•1ã®Layerã®Hidden State H^1ã‹ã‚‰çµ¶å¯¾ä½ç½®ã®å¾©å…ƒãŒå¯èƒ½ã§ã‚ã‚Šï¼ˆã¤ã¾ã‚Šã€å½“è©²ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®HãŒçµ¶å¯¾ä½ç½®ã«é–¢ã™ã‚‹æƒ…å ±ã‚’ä¿æŒã—ã¦ã„ã‚‹ï¼‰ã€ã“ã®å‰æã®ã‚‚ã¨ã€å¾Œç¶šã®LayerãŒã“ã®æƒ…å ±ã‚’ä¸Šæ›¸ãã—ãªã„ã¨ä»®å®šã—ãŸå ´åˆã«ã€ç›¸å¯¾ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å®Ÿç¾ã§ãã‚‹ã€‚</p>
<p>ã¾ãŸã€CoT/Scratchpadã¯long sequenceã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒsmall scaleã§ã¯ã‚ã‚‹ãŒå…ˆè¡Œç ”ç©¶ã§ç¤ºã•ã‚Œã¦ãŠã‚Šã€Positional Encodingã‚’å¤‰åŒ–ã•ã›ãŸæ™‚ã«CoT/Scratchpadã®æ€§èƒ½ã«ã©ã®ã‚ˆã†ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã‹ã‚’èª¿æŸ»ã€‚<br><br>å…·ä½“çš„ã«ã¯ã€CoT/Scratchpadã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒã©ã®ã‚ˆã†ãªã‚‚ã®ãŒæœ‰åŠ¹ã‹ã‚‚æ˜ã‚‰ã‹ã§ã¯ãªã„ã®ã§ã€5ç¨®é¡ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®çµ„ã¿åˆã‚ã›ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ§‹æˆã—ã€mathematical reasoningã‚¿ã‚¹ã‚¯ã§ä»¥ä¸‹ã®ã‚ˆã†ãªè¨­å®šã§è¨“ç·´ã—<br><br>- ã•ã¾ã–ã¾ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®çµ„ã¿åˆã‚ã›ã§ç•°ãªã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä½œæˆã—ã€<br>- å…¨ã¦ã®ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚ã‚Š/ãªã—ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´<br><br>ã“ã‚Œã‚‰ã‚’æ¯”è¼ƒã—ãŸã€‚ã“ã®çµæœã€CoT/Scratchpadã¯ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«é–¢ä¿‚ãªãã€ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã§ã®ã¿æœ‰åŠ¹ï¼ˆæœ‰åŠ¹ã‹ã©ã†ã‹ã¯ã‚¿ã‚¹ã‚¯ä¾å­˜ï¼‰ã§ã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€CoT/Scratcpadï¼ˆã¤ã¾ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®inputã¨outputã®ä»•æ–¹ï¼‰å˜ä½“ã§ã€long contextã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ããªã„ã®ã§ã€Positional Encodingï¼ˆâ‰’ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼‰ã«ã‚ˆã‚‹long contextã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã®å‘ä¸ŠãŒéå¸¸ã«é‡è¦ã§ã‚ã‚‹ã“ã¨ãŒæµ®ãå½«ã‚Šã«ãªã£ãŸã€‚<br><img src="https://github.com/user-attachments/assets/e23c4fbf-84de-4344-a01e-1e7e9e66fa7e" alt="image" loading="lazy"><br><br>ã¾ãŸã€CoT/ScratchpadãŒæœ‰åŠ¹ã ã£ãŸAdditionã«å¯¾ã—ã¦å„Positional Embeddingãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã€ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã®attentionãŒã©ã®ä½ç½®ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŒ‡ã—ã¦ã„ã‚‹ã‹ã‚’ç›¸å¯¾è·é›¢ã§å¯è¦–åŒ–ã—ãŸã¨ã“ã‚ï¼ˆ0ãŒå½“è©²ãƒˆãƒ¼ã‚¯ãƒ³ã€ã¤ã¾ã‚Šç¾åœ¨ã®Scratchpadã«ç€ç›®ã—ã¦ãŠã‚Šã€1ãŒé ã„ãƒˆãƒ¼ã‚¯ãƒ³ã€ã¤ã¾ã‚Šinputã«ç€ç›®ã—ã¦ã„ã‚‹ã“ã¨ã‚’è¡¨ã™ã‚ˆã†ã«æ­£è¦åŒ–ï¼‰ã€NoPEã¨Relative Positional EncodingãŒshort/long rangeã«ãã‚Œãã‚Œãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã™ã‚‹ã‚ˆã†ãªbinomialãªåˆ†å¸ƒãªã®ã«å¯¾ã—ã€ä»–ã®Positional Encodingã§ã¯ã‚ˆã‚Šuniformãªåˆ†å¸ƒã§ã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚ã“ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã¯NoPEã¨Relative POã®æ€§èƒ½ãŒé«˜ã‹ã£ãŸãŸã‚ã€binomialãªåˆ†å¸ƒã®æ–¹ãŒã‚ˆã‚Šæœ€é©ã§ã‚ã‚ã†ã“ã¨ãŒç¤ºå”†ã•ã‚ŒãŸã€‚<br><img src="https://github.com/user-attachments/assets/833e6a81-8611-4e79-9d2e-473f7ebee2d0" alt="image" loading="lazy"><br></p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Contents-based.html" target="_blank" rel="noopener noreferrer">#Contents-based</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/Zero/FewShotLearning.html" target="_blank" rel="noopener noreferrer">#Zero/FewShotLearning</a>
<a class="button" href="articles/RecSys.html" target="_blank" rel="noopener noreferrer">#RecSys</a>
<span class="issue_date">Issue Date: 2025-03-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1841" target="_blank" rel="noopener noreferrer" class="title-link">TALLRec: An Effective and Efficient Tuning Framework to Align Large   Language Model with Recommendation, Keqin Bao+, RecSys'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã«æ´»ç”¨ã™ã‚‹ãŸã‚ã€æ¨è–¦ãƒ‡ãƒ¼ã‚¿ã§èª¿æ•´ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯TALLRecã‚’ææ¡ˆã€‚é™ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚LLMsã®æ¨è–¦èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã€åŠ¹ç‡çš„ã«å®Ÿè¡Œå¯èƒ½ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸLLMã¯ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³ä¸€èˆ¬åŒ–ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä¸‹è¨˜ã®ã‚ˆã†ãªãƒ¦ãƒ¼ã‚¶ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¢ã‚¤ãƒ†ãƒ ã¨ã€binaryã®æ˜ç¤ºçš„ãªrelevance feedbackãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦LoRAã€ã‹ã¤Fewshot Learningã®è¨­å®šã§SFTã™ã‚‹ã“ã¨ã§binaryã®like/dislikeã®äºˆæ¸¬æ€§èƒ½ã‚’å‘ä¸Šã€‚Promptingã ã‘ã§ãªãSFTã‚’å®Ÿæ–½ã—ãŸåˆã‚ã¦ã®ç ”ç©¶ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/08ea2d35-1dd1-4670-810b-a57722173460" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/acf565f8-9541-4fe1-95e8-10cff397fa7a" alt="image" loading="lazy"><br><br>æ—¢å­˜ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨æ¯”è¼ƒã—ã¦å¤§å¹…ã«AUCãŒå‘ä¸Š<br><img src="https://github.com/user-attachments/assets/141a0c43-0504-4da3-84d9-c4dac119b590" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1829" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Data-Constrained Language Models, Niklas Muennighoff+, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ãŠã„ã¦ã€ãƒ‡ãƒ¼ã‚¿åˆ¶ç´„ä¸‹ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’èª¿æŸ»ã€‚9000å„„ãƒˆãƒ¼ã‚¯ãƒ³ã¨90å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã€ç¹°ã‚Šè¿”ã—ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã‚‚æå¤±ã«å¤§ããªå¤‰åŒ–ã¯è¦‹ã‚‰ã‚Œãšã€ç¹°ã‚Šè¿”ã—ã®ä¾¡å€¤ãŒæ¸›å°‘ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚è¨ˆç®—æœ€é©æ€§ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ææ¡ˆã—ã€ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã‚’è»½æ¸›ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚‚å®Ÿé¨“ã€‚å¾—ã‚‰ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=j5BuTrEj35" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=j5BuTrEj35</a>


</p>
<p>ãƒãƒ³ãƒãƒ©å‰‡ã®ã‚ˆã†ãªScaling Lawsã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒ‡ãƒ¼ã‚¿é‡ã®ä¸¡æ–¹ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ãŸå ´åˆã®å‰æã«ç«‹ã£ã¦ãŠã‚Šã€ã‹ã¤ãƒ‡ãƒ¼ã‚¿ã¯å…¨ã¦uniqueã§ã‚ã‚‹å‰æã ã£ãŸãŒã€ãƒ‡ãƒ¼ã‚¿ã®æ¯æ¸‡ãŒæ‡¸å¿µã•ã‚Œã‚‹æ˜¨ä»Šã®çŠ¶æ³ã«åˆã‚ã›ã¦ã€ãƒ‡ãƒ¼ã‚¿é‡ãŒåˆ¶é™ã•ã‚ŒãŸçŠ¶æ³ã§ã€åŒã˜ãƒ‡ãƒ¼ã‚¿ã‚’ç¹°ã‚Šè¿”ã—åˆ©ç”¨ã™ã‚‹ï¼ˆï¼è¤‡æ•°ã‚¨ãƒãƒƒã‚¯å­¦ç¿’ã™ã‚‹ï¼‰ã“ã¨ãŒä¸€èˆ¬çš„ã«ãªã£ã¦ããŸã€‚ã“ã®ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã®repetitionã«é–¢ã—ã¦æ€§èƒ½ã‚’äº‹å‰å­¦ç¿’ã«ã‚ˆã‚‹æ€§èƒ½ã®é•ã„ã‚’èª¿æŸ»ã—ã¦ã€repetitionã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã«é–¢ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡ã‚’ææ¡ˆï¼ˆ$3.1)ã—ã¦ã„ã‚‹ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><br>Takeawayã¨ã—ã¦ã¯ã€ãƒ‡ãƒ¼ã‚¿ãŒåˆ¶é™ã•ã‚ŒãŸç’°å¢ƒä¸‹ã§ã¯ã€repetitionã¯ä¸Šé™4å›ã¾ã§ãŒåŠ¹æœçš„ï¼ˆã‚³ã‚¹ãƒ‘ãŒè‰¯ã„ï¼‰ã§ã‚ã‚Šï¼ˆå·¦å›³ï¼‰ã€å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã‚’è¤‡æ•°ã‚¨ãƒãƒƒã‚¯è¨“ç·´ã™ã‚‹æ–¹ãŒå›ºå®šã•ã‚ŒãŸBudgetã®ä¸­ã§ä½ã„lossã‚’é”æˆã§ãã‚‹å³å›³ï¼‰ã€‚<br><img src="https://github.com/user-attachments/assets/4e62cd1b-fe83-4d6e-a40d-df992c85def3" alt="image" loading="lazy"><br><br>å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®åŠåˆ†ã‚’ã‚³ãƒ¼ãƒ‰ã«ã—ã¦ã‚‚æ€§èƒ½ã®åŠ£åŒ–ã¯ãªãã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ãŒå‘ä¸Šã—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®åˆ†æ•£ã‚‚å°ã•ããªã‚‹ã€ã¨ã„ã£ãŸã“ã¨ãŒæŒ™ã’ã‚‰ã‚Œã‚‹ã‚ˆã†ã ã€‚<br><img src="https://github.com/user-attachments/assets/d404156f-7416-4f22-aa7e-d342065435ee" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1668" target="_blank" rel="noopener noreferrer" class="title-link">Navigate through Enigmatic Labyrinth A Survey of Chain of Thought  Reasoning: Advances, Frontiers and Future, Zheng Chu+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æ¨è«–ã¯AIã«ãŠã„ã¦é‡è¦ãªèªçŸ¥ãƒ—ãƒ­ã‚»ã‚¹ã§ã‚ã‚Šã€ãƒã‚§ãƒ¼ãƒ³ãƒ»ã‚ªãƒ–ãƒ»ã‚½ãƒ¼ãƒˆãŒLLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯é–¢é€£ç ”ç©¶ã‚’ä½“ç³»çš„ã«èª¿æŸ»ã—ã€æ‰‹æ³•ã‚’åˆ†é¡ã—ã¦æ–°ãŸãªè¦–ç‚¹ã‚’æä¾›ã€‚èª²é¡Œã‚„ä»Šå¾Œã®æ–¹å‘æ€§ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã€åˆå¿ƒè€…å‘ã‘ã®å°å…¥ã‚’ç›®æŒ‡ã™ã€‚ãƒªã‚½ãƒ¼ã‚¹ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2025-01-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1657" target="_blank" rel="noopener noreferrer" class="title-link">Program of Thoughts Prompting: Disentangling Computation from Reasoning   for Numerical Reasoning Tasks, Wenhu Chen+, TMLR'23</a>
<span class="snippet"><span>GPT Summary</span>- æ®µéšçš„ãªæ¨è«–ã‚’ç”¨ã„ãŸæ•°å€¤æ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€Chain-of-thoughts promptingï¼ˆCoTï¼‰ã®é€²å±•ãŒã‚ã‚Šã€æ¨è«–ã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¨ã—ã¦è¡¨ç¾ã™ã‚‹ã€ŒProgram of Thoughtsã€ï¼ˆPoTï¼‰ã‚’ææ¡ˆã€‚PoTã¯å¤–éƒ¨ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã§è¨ˆç®—ã‚’è¡Œã„ã€5ã¤ã®æ•°å­¦å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨3ã¤ã®é‡‘èQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡ã—ãŸçµæœã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆãŠã‚ˆã³ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆè¨­å®šã§CoTã«å¯¾ã—ã¦ç´„12ï¼…ã®æ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ãŸã€‚è‡ªå·±ä¸€è²«æ€§ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚Šã€æ•°å­¦å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚ãƒ‡ãƒ¼ã‚¿ã¨ã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>1. LLMsã¯ç®—è¡“æ¼”ç®—ã‚’å®Ÿæ–½ã™ã‚‹éš›ã«ã‚¨ãƒ©ãƒ¼ã‚’èµ·ã“ã—ã‚„ã™ãã€ç‰¹ã«å¤§ããªæ•°ã«å¯¾ã™ã‚‹æ¼”ç®—ã‚’å®Ÿæ–½ã™ã‚‹éš›ã«é¡•è‘—<br>2. LLMsã¯è¤‡é›‘ãªæ•°å¼ï¼ˆe.g. å¤šé …å¼, å¾®åˆ†æ–¹ç¨‹å¼ï¼‰ã‚’è§£ãã“ã¨ãŒã§ããªã„<br>3. LLMsã¯iterationã‚’è¡¨ç¾ã™ã‚‹ã®ãŒéå¸¸ã«éåŠ¹ç‡<br><br>ã®3ç‚¹ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€å¤–éƒ¨ã®ã‚¤ãƒ³ã‚¿ãƒ—ãƒªã‚¿ã«æ¼”ç®—å‡¦ç†ã‚’å§”è­²ã™ã‚‹PoTã‚’ææ¡ˆã€‚PoTã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã«reasoning stepsã‚’python programã§å‡ºåŠ›ã•ã›ã€æ¼”ç®—éƒ¨åˆ†ã‚’Python Interpreterã«å®Ÿæ–½ã•ã›ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/ccaeee09-ca6f-45ec-aef4-c65960d52692" alt="image" loading="lazy"></p>
<p>ãƒ†ã‚­ã‚¹ãƒˆã€ãƒ†ãƒ¼ãƒ–ãƒ«ã€å¯¾è©±ãªã©ã®å¤šæ§˜ãªinputã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹5ã¤ã®Math Word Problem ï¼ˆMWPï¼‰, 3ã¤ã®Financial Datasetã§è©•ä¾¡ã—ãŸçµæœã€zero-shot, few-shotã®ä¸¡æ–¹ã®è¨­å®šã«ãŠã„ã¦ã€PoTã¯CoTã‚’outpeformã—ã€ã¾ãŸã€Self-Consistencyã¨çµ„ã¿åˆã‚ã›ãŸå ´åˆã‚‚ã€PoTã¯CoTã‚’outperformã—ãŸã€‚<br><img src="https://github.com/user-attachments/assets/6b380fab-ab60-4f21-bce1-532167c8c8f2" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-01-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1656" target="_blank" rel="noopener noreferrer" class="title-link">Recursion of Thought: A Divide-and-Conquer Approach to Multi-Context  Reasoning with Language Models, Soochan Lee+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Recursion of Thoughtï¼ˆRoTï¼‰ã¨ã„ã†æ–°ã—ã„æ¨è«–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLMï¼‰ãŒå•é¡Œã‚’è¤‡æ•°ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åˆ†å‰²ã™ã‚‹ã“ã¨ã§æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚RoTã¯ç‰¹åˆ¥ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’å°å…¥ã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé–¢é€£ã®æ“ä½œã‚’ãƒˆãƒªã‚¬ãƒ¼ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€RoTãŒLMã®æ¨è«–èƒ½åŠ›ã‚’åŠ‡çš„ã«å‘ä¸Šã•ã›ã€æ•°åä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ã®å•é¡Œã‚’è§£æ±ºã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>divide-and-conquerã§è¤‡é›‘ãªå•é¡Œã«å›ç­”ã™ã‚‹CoTæ‰‹æ³•ã€‚ç”Ÿæˆéç¨‹ã§subquestionãŒç”Ÿã˜ãŸéš›ã«ãƒ¢ãƒ‡ãƒ«ã«ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆGOï¼‰ã‚’å‡ºåŠ›ã•ã›ã€subquestionã®å›ç­”éƒ¨åˆ†ã«ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆTHINKï¼‰ã‚’å‡ºåŠ›ã•ã›ã‚‹ã‚ˆã†ã«Supervisedã«å­¦ç¿’ã•ã›ã‚‹ã€‚æœ€çµ‚çš„ã«THINKãƒˆãƒ¼ã‚¯ãƒ³éƒ¨åˆ†ã¯ã€subquestionã‚’åˆ¥é€”ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦è§£ã„ãŸå›ç­”ã§replaceã—ã¦ã€æœ€çµ‚çš„ãªå›ç­”ã‚’å¾—ã‚‹ã€‚<br>subquestionã®ä¸­ã§ã•ã‚‰ã«subquestionãŒç”Ÿã˜ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ãŸã‚ã€å†å¸°çš„ã«å‡¦ç†ã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/6a5a5155-b3dd-4a6a-a9f5-0975dddcedb7" alt="image" loading="lazy"></p>
<p>å››å‰‡æ¼”ç®—ã¨4ç¨®é¡ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«åŸºã¥ãã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã€‚ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«åŸºã¥ãã‚¿ã‚¹ã‚¯ã¯ã€2ã¤ã®æ•°ã®longest common subsequenceã‚’è¦‹ã¤ã‘ã¦ã€ãã®subsequenceã¨lengthã‚’å‡ºåŠ›ã™ã‚‹ã‚¿ã‚¹ã‚¯ï¼ˆLCSï¼‰ã€0-1 knapsackå•é¡Œã€è¡Œåˆ—ã®ä¹—ç®—ã€æ•°å€¤ã®ã‚½ãƒ¼ãƒˆã‚’åˆ©ç”¨ã€‚xè»¸ãŒå„ã‚¿ã‚¹ã‚¯ã®å•é¡Œã”ã¨ã®å•é¡Œã®é›£æ˜“åº¦ã‚’è¡¨ã—ã¦ãŠã‚Šã€é›£æ˜“åº¦ãŒä¸ŠãŒã‚‹ã»ã©ææ¡ˆæ‰‹æ³•ã«ã‚ˆã‚‹gainãŒå¤§ãããªã£ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br>Without Thoughtã§ã¯ç›´æ¥å›ç­”ã‚’å‡ºåŠ›ã•ã›ã€CoTã§ã¯ground truthã¨ãªã‚‹rationaleã‚’1ã¤ã®contextã«ä¸ãˆã¦å›ç­”ã‚’ç”Ÿæˆã—ã¦ã„ã‚‹ã€‚RoTã§ã¯subquestionã”ã¨ã«å›ç­”ã‚’åˆ¥é€”å¾—ã‚‹ãŸã‚ã€ã‚ˆã‚Šé•·ã„contextã‚’æ´»ç”¨ã—ã¦æœ€çµ‚çš„ãªå›ç­”ã‚’å¾—ã‚‹ç‚¹ãŒç•°ãªã‚‹ã¨ä¸»å¼µã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/8e713c76-5f79-40c7-87b0-d69f6fac3ee3" alt="image" loading="lazy"><br></p>
<p>æ„Ÿæƒ³ã¨ã—ã¦ã¯ã€è©³ç´°ãŒæ›¸ã‹ã‚Œã¦ã„ãªã„ãŒã€ãŠãã‚‰ãRoTã¯SFTã«ã‚ˆã£ã¦å„ã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã—ãŸå­¦ç¿’ã‚’ã—ã¦ã„ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ï¼ˆã‚¿ã‚¹ã‚¯ã”ã¨ã®ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ãŒå­˜åœ¨ã™ã‚‹ãŸã‚ï¼‰ã€‚ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã—ã¦RoTç„¡ã—ã§SFTã—ãŸãƒ¢ãƒ‡ãƒ«ã‚ã£ãŸæ–¹ãŒè‰¯ã„ã®ã§ã¯ãªã„ã‹ï¼Ÿã¨æ„Ÿã˜ã‚‹ã€‚<br><br>ã¾ãŸã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ãŠã‘ã‚‹subquestionã¨subquestionã«å¯¾ã™ã‚‹ground truthã®ãƒ‡ãƒ¼ã‚¿ä½œæˆæ–¹æ³•ã¯æ›¸ã‹ã‚Œã¦ã„ã‚‹ãŒã€ãã‚‚ãã‚‚å…ƒãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½•ã‚’åˆ©ç”¨ã—ãŸã‹ã‚„ã€ãã®çµ±è¨ˆé‡ã‚‚æ›¸ã‹ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ã‚ã¨ã€ãã‚‚ãã‚‚æ©Ÿæ¢°çš„ã«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã§ããªã„å ´åˆã©ã†ã™ã‚Œã°è‰¯ã„ã®ã‹ï¼Ÿã¨ã„ã†ç–‘å•ã¯æ®‹ã‚‹ã€‚</p>
<p>èª­ã‚“ã§ã„ãŸæ™‚ã«Auto-CoTã¨ã®é•ã„ãŒã‚ˆãã‚ã‹ã‚‰ãªã‹ã£ãŸãŒã€Related Workã®éƒ¨åˆ†ã«ã¯Auto-CoTã¯å‹•çš„ã€ã‹ã¤å¤šæ§˜ãªãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦ã„ã‚‹ãŒã€AutoReasonã¯questionã‚’åˆ†è§£ã—ã€few-shotã® promptingã§ã‚ˆã‚Šè©³ç´°ãªrationaleã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦ã„ã‚‹ç‚¹ãŒç•°ãªã‚‹ã¨ã„ã†ä¸»å¼µã®ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/556" target="_blank" rel="noopener noreferrer">Automatic Chain of Thought Prompting in Large Language Models, Zhang+, Shanghai Jiao Tong University, ICLR'23</a>
</p>
<p>Auto-CoTã¨ã®å·®åˆ¥åŒ–ã¯ä¸Šè¨˜ã§ç†è§£ã§ãã‚‹ãŒã€G-EvalãŒå®Ÿæ–½ã—ã¦ã„ã‚‹Auto-CoTã¨ã®å·®åˆ¥åŒ–ã¯ã©ã†ã™ã‚‹ã®ã‹ï¼Ÿã¨ã„ã†é¢¨ã«ãµã¨æ€ã£ãŸã€‚è«–æ–‡ä¸­ã§ã‚‚G-Evalã¯å¼•ç”¨ã•ã‚Œã¦ã„ãªã„ã€‚<br><br>ç´ æœ´ã«ã¯AutoReasonã¯SFTã‚’ã—ã¦å­¦ç¿’ã‚’ã—ã¦ã„ã¾ã™ã€ã•ã‚‰ã«Recursiveã«questionã‚’subquestionã‚’åˆ†è§£ã—ã€åˆ†è§£ã—ãŸsubquestionã”ã¨ã«å›ç­”ã‚’å¾—ã¦ã€subquestionã®å›ç­”çµæœã‚’æ´»ç”¨ã—ã¦æœ€çµ‚çš„ã«è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã®å›ç­”ã‚’å‡ºåŠ›ã™ã‚‹æ‰‹æ³•ãªã®ã§ã€G-EvalãŒå®Ÿæ–½ã—ã¦ã„ã‚‹åŒä¸€contextå†…ã§rationaleã‚’zeroshotã§ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã‚ˆã‚Šã‚‚ã€ã‚ˆã‚Šè¤‡é›‘ãªå•é¡Œã«å›ç­”ã§ãã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€ã¨ã„ã†ä¸»å¼µã«ã¯ãªã‚Šãã†ã§ã¯ã‚ã‚‹ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1223" target="_blank" rel="noopener noreferrer">G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment, Yang Liu+, N/A, EMNLP'23</a>
</p>
<p>ICLR 2023 OpenReview:


<a href="https://openreview.net/forum?id=PTUcygUoxuc" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=PTUcygUoxuc</a>


<br><br>- ææ¡ˆæ‰‹æ³•ã¯ä¸€èˆ¬çš„ã«åˆ©ç”¨å¯èƒ½ã¨ä¸»å¼µã—ã¦ã„ã‚‹ãŒã€ä¸€èˆ¬çš„ã«åˆ©ç”¨ã™ã‚‹ãŸã‚ã«ã¯äººæ‰‹ã§subquestionã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ååˆ†ã«ä¸€èˆ¬çš„ã§ã¯ãªã„<br>- é™ã‚‰ã‚ŒãŸcontexté•·ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«å†å¸°ã‚’åˆ©ç”¨ã™ã‚‹ã¨ã„ã†ã‚¢ã‚¤ãƒ‡ã‚¢ã¯æ–°ã—ã„ã‚‚ã®ã§ã¯ãªãã€æ•°å­¦ã®å®šç†ã®è¨¼æ˜ãªã©ä»–ã®è¨­å®šã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹<br><br>ã¨ã„ã†ç†ç”±ã§rejectã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/SequentialRecommendation.html" target="_blank" rel="noopener noreferrer">#SequentialRecommendation</a>
<span class="issue_date">Issue Date: 2024-12-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1625" target="_blank" rel="noopener noreferrer" class="title-link">Recommender Systems with Generative Retrieval, Shashank Rajput+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„ç”Ÿæˆçš„æ¤œç´¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯IDã‚’è‡ªå·±å›å¸°çš„ã«ãƒ‡ã‚³ãƒ¼ãƒ‰ã€‚Transformerãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ãŒæ¬¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯IDã‚’äºˆæ¸¬ã—ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦åˆã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯IDãƒ™ãƒ¼ã‚¹ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¨ãªã‚‹ã€‚ææ¡ˆæ‰‹æ³•ã¯æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€éå»ã®å¯¾è©±å±¥æ­´ãŒãªã„ã‚¢ã‚¤ãƒ†ãƒ ã«å¯¾ã™ã‚‹æ¤œç´¢æ€§èƒ½ã‚‚å‘ä¸Šã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2024-12-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1570" target="_blank" rel="noopener noreferrer" class="title-link">SmoothQuant: Accurate and Efficient Post-Training Quantization for Large   Language Models, Guangxuan Xiao+, ICML'23</a>
<span class="snippet"><span>GPT Summary</span>- SmoothQuantã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸è¦ã§8ãƒ“ãƒƒãƒˆã®é‡ã¿ã¨æ´»æ€§åŒ–ã®é‡å­åŒ–ã‚’å®Ÿç¾ã™ã‚‹ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é‡å­åŒ–ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚æ´»æ€§åŒ–ã®å¤–ã‚Œå€¤ã‚’æ»‘ã‚‰ã‹ã«ã™ã‚‹ã“ã¨ã§ã€é‡å­åŒ–ã®é›£æ˜“åº¦ã‚’è»½æ¸›ã—ã€ç²¾åº¦ã‚’ä¿æŒã—ã¤ã¤æœ€å¤§1.56å€ã®é€Ÿåº¦å‘ä¸Šã¨2å€ã®ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ã‚’é”æˆã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€530Bã®LLMã‚’å˜ä¸€ãƒãƒ¼ãƒ‰ã§é‹ç”¨å¯èƒ½ã«ã—ã€LLMsã®æ°‘ä¸»åŒ–ã‚’ä¿ƒé€²ã—ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãŠãã‚‰ãé‡å­åŒ–æ‰‹æ³•ã®ç¾æ™‚ç‚¹ã®SoTA</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2024-12-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1568" target="_blank" rel="noopener noreferrer" class="title-link">Recommender Systems in the Era of Large Language Models ï¼ˆLLMsï¼‰, Zihuai Zhao+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã«åŸºã¥ã„ãŸææ¡ˆã‚’æä¾›ã™ã‚‹é‡è¦ãªè¦ç´ ã§ã‚ã‚Šã€DNNã®é™ç•Œã‚’å…‹æœã™ã‚‹ãŸã‚ã«LLMsã®æ´»ç”¨ãŒé€²ã‚“ã§ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€LLMã‚’ç”¨ã„ãŸãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®äº‹å‰å­¦ç¿’ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã„ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®è¡¨ç¾å­¦ç¿’æ‰‹æ³•ã‚„æœ€è¿‘ã®æŠ€è¡“ã‚’ç´¹ä»‹ã—ã€ä»Šå¾Œã®ç ”ç©¶æ–¹å‘æ€§ã«ã¤ã„ã¦è­°è«–ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p><br>ä¸­èº«ã‚’å…¨ç„¶èª­ã‚“ã§ã„ã‚‹æ™‚é–“ã¯ãªã„ã®ã§ã€å›³ã«ã¯é‡è¦ãªæƒ…å ±ãŒè©°ã¾ã£ã¦ã„ã‚‹ã¨ä¿¡ã˜ã€å›³ã‚’èª­ã¿è§£ã„ã¦ã„ãã€‚æ™‚é–“ãŒã‚ã‚‹æ™‚ã«ä¸­èº«ã‚‚èª­ã¿ãŸã„ã€‚ã€‚ã€‚<br><br>LLM-basedãªRecSysã§ã¯ã€NLPã«ãŠã‘ã‚‹LLMã®ä½¿ã„æ–¹ï¼ˆå…ƒã€…ã¯T5ã§ææ¡ˆï¼‰ã¨åŒæ§˜ã«ã€æ§˜ã€…ãªãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰é–¢ä¿‚ã‚¿ã‚¹ã‚¯ã‚’ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¿ã‚¹ã‚¯ã«è½ã¨ã—è¾¼ã¿å­¦ç¿’ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/78faeea5-8e1f-49d5-93a8-9ea97d5a3170" alt="image" loading="lazy"><br>RecSysã®Literatureã¨ã—ã¦ã¯ã€æœ€åˆã¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ™ãƒ¼ã‚¹ã¨å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‹ã‚‰å§‹ã¾ã‚Šã€ï¼ˆã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ãƒ‰ãªæ¨è–¦, Matrix Factorization, Factorization Machinesãªã©ãŒé–“ã«ã‚ã£ã¦ï¼‰ã€ãã®å¾ŒMLP, RNN, CNN, AutoEncoderãªã©ã®æ§˜ã€…ãªDeep Neural Networkï¼ˆDNNï¼‰ã‚’æ´»ç”¨ã—ãŸæ‰‹æ³•ã‚„ã€BERT4Recãªã©ã®Probabilistic Language Modelsï¼ˆPLMï¼‰ã‚’ç”¨ã„ãŸæ‰‹æ³•ã«ã‚·ãƒ•ãƒˆã—ã¦ã„ãã€ç¾åœ¨LLM-basedãªRecSysã®æ™‚ä»£ã«åˆ°é”ã—ãŸã€ã¨ã®æµã‚Œã§ã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/6c319f48-3c2f-4c0d-97d6-693fb8ba85cf" alt="image" loading="lazy"><br><br>LLM-basedãªæ‰‹æ³•ã§ã¯ã€pretrainingã®æ®µéšã‹ã‚‰Encoder-basedãªãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯MLMã€Decoder-basedãªæ‰‹æ³•ã§ã¯Next Token Predictionã«ã‚ˆã£ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§äº‹å‰å­¦ç¿’ã™ã‚‹æ–¹æ³•ã‚‚ã‚ã‚Œã°ã€ãƒ•ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„PEFTï¼ˆLoRAãªã©ï¼‰ã«ã‚ˆã‚‹SFTã«ã‚ˆã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚‚ã‚ã‚‹ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><br>æ¨è–¦ã‚¿ã‚¹ã‚¯ã¯ã€æ¨è–¦ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ IDã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã®å ´åˆã¯ã€ç•°ãªã‚‹ã‚¢ã‚¤ãƒ†ãƒ IDç©ºé–“ã«åŸºã¥ããƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®é–“ã§ã¯è»¢ç§»ãŒã§ããªã„ã®ã§ã€SFTã‚’ã—ãªã„ã¨ãªã‹ãªã‹ã†ã¾ãã„ã‹ãªã„ã¨æ°—ãŒã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€ãã®å ´åˆã¯ã‚¢ã‚¤ãƒ†ãƒ IDã®æ¨è–¦ä»¥å¤–ã®ã‚¿ã‚¹ã‚¯ã‚‚åŒæ™‚ã«å®Ÿæ–½ã—ãŸã„å ´åˆã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå›ºå®šã•ã‚Œã‚‹PEFTæ‰‹æ³•ã®æ–¹ãŒå®‰å…¨ç­–ã«ãªã‚‹ã‹ãªãã€ã¨ã„ã†æ°—ãŒã—ã¦ã„ã‚‹ï¼ˆç ´å£Šçš„å¿˜å´ãŒæ€–ã„ã®ã§ï¼‰ã€‚ç‰¹ã¯ãŸã¨ãˆã°ã€ã‚¢ã‚¤ãƒ†ãƒ IDã‚’ç”Ÿæˆã™ã‚‹ã ã‘ã§ãªãã€ãã®æ¨è–¦ç†ç”±ã‚’ç”Ÿæˆã§ãã‚‹ã®ã¯ã¨ã¦ã‚‚è‰¯ã„ã“ã¨ã ãªã‚ã¨æ„Ÿã˜ã‚‹ï¼ˆè‰¯ã„æ™‚ä»£ã€æ„Ÿï¼‰ã€‚<br><img src="https://github.com/user-attachments/assets/19474960-ac0d-4a61-915e-15a910504a3f" alt="image" loading="lazy"><br><br>ã¾ãŸã€Promptingã«ã‚ˆã‚‹RecSysã®æµã‚Œã‚‚å›³è§£ã•ã‚Œã¦ã„ã‚‹ãŒã€In-Context Learningã®ã»ã‹ã«ã€Prompt Tuningï¼ˆsoftã¨hardã®ä¸¡æ–¹ï¼‰ã€Instruction Tuningã‚‚åŒã˜å›³ã«å«ã¾ã‚Œã¦ã„ã‚‹ã€‚å€‹äººçš„ã«ã¯Prompt Tuningã¯PEFTã®ä¸€ç¨®ã§ã‚ã‚Šã€Instruction Tuningã¯SFTã®ä¸€ç¨®ãªã®ã§ã€ä¸€ã¤ä¸Šã®å›³ã«å«æ„ã•ã‚Œã‚‹è©±ãªã®ã§ã¯?ã¨ã„ã†æ°—ãŒã™ã‚‹ãŒã€è«–æ–‡ä¸­ã§ã¯ã©ã®ã‚ˆã†ãªç«‹ã¦ä»˜ã‘ã§è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã®ã ã‚ã†ã‹ã€‚<br>ã©ã¡ã‚‰ã‹ã¨ã„ã†ã¨ã€Promptingã®è©±ã§ã‚ã‚Œã°ã€zero-few-many shotã‚„ã€å„ç¨®CoTã®è©±ã‚’å«ã‚ã‚‹ã®ãŒè‡ªç„¶ãªæ°—ãŒã™ã‚‹ã®ã ãŒã€‚<br><img src="https://github.com/user-attachments/assets/a1db1dba-ba13-44b0-ad9c-017ca9164ed2" alt="image" loading="lazy"><br><br>ä¸‹å›³ã¯Promptingã«ã‚ˆã‚‹æ‰‹æ³•ã‚’è¡¨ã«ã¾ã¨ã‚ãŸã‚‚ã®ã€‚Finetuningãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ãŒåˆ¥è¡¨ã«ã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ãŸãŒã€ç ”ç©¶ã®æ•°ã¨ã—ã¦ã¯ã“ã¡ã‚‰ã®æ–¹ãŒå¤šãã†ã«è¦‹ãˆã‚‹ã€‚ãŒã€æ€§èƒ½çš„ã«ã¯ã©ã®ç¨‹åº¦ãŒé”æˆã•ã‚Œã‚‹ã®ã ã‚ã†ã‹ã€‚ç›´æ„Ÿçš„ã«ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ¨è–¦ã™ã‚‹ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã§ã¯ã€Promptingã§ã¯æ€§èƒ½ãŒå‡ºã«ãã„ã‚ˆã†ãªå°è±¡ãŒã‚ã‚‹ã€‚ãªãœãªã‚‰ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ã®LLMã¯ã‚¢ã‚¤ãƒ†ãƒ IDã®ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ç‰¹å¾´ã«é–¢ã™ã‚‹çŸ¥è­˜ãŒãªã„ã®ã§ã€‚ã“ã‚Œã‚’Finetuningã—ãªã„ã®ã§ã‚ã‚Œã°ICLã§è³„ã†ã“ã¨ã«ãªã‚‹ã¨æ€ã†ã®ã ãŒã€æœãŸã—ã¦ã©ã“ã¾ã§ã§ãã‚‹ã ã‚ã†ã‹â€¦ã€‚èˆˆå‘³ãŒã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/997e2bd9-68bd-4b72-92d4-72495a329dda" alt="image" loading="lazy"><br><br>ï¼ˆå›³ã¯è«–æ–‡ã‚ˆã‚Šå¼•ç”¨ï¼‰</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<span class="issue_date">Issue Date: 2024-12-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1567" target="_blank" rel="noopener noreferrer" class="title-link">Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions, John Chung+, ACL'23, 2023.07</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMã‚’ç”¨ã„ãŸãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã«ãŠã‘ã‚‹å¤šæ§˜æ€§ã¨ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®äººé–“ã¨AIã®ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‚·ãƒƒãƒ—ã‚’æ¢æ±‚ã€‚ãƒ­ã‚¸ãƒƒãƒˆæŠ‘åˆ¶ã¨æ¸©åº¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®2ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§å¤šæ§˜æ€§ã‚’é«˜ã‚ã‚‹ä¸€æ–¹ã€ãƒ©ãƒ™ãƒ«ç½®æ›ï¼ˆLRï¼‰ã¨ç¯„å›²å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆOOSFï¼‰ã«ã‚ˆã‚‹äººé–“ã®ä»‹å…¥ã‚’æ¤œè¨ã€‚LRã¯ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’14.4%å‘ä¸Šã•ã›ã€ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆåˆ†é¡ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸãŒã€OOSFã¯åŠ¹æœãŒãªã‹ã£ãŸã€‚ä»Šå¾Œã®ç ”ç©¶ã®å¿…è¦æ€§ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã®è³ªã‚’ç¶­æŒã—ã¤ã¤ã€å¤šæ§˜æ€§ã‚’é«˜ã‚ã‚‹å–ã‚Šçµ„ã¿ã€‚å¤šæ§˜æ€§ã‚’é«˜ã‚ã‚‹å–ã‚Šçµ„ã¿ã¨ã—ã¦ã¯3ç¨®é¡ã®æ–¹æ³•ãŒè©¦ã•ã‚Œã¦ãŠã‚Šã€<br><br>- Logit Suppression: ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®å˜èªç”Ÿæˆé »åº¦ã‚’ãƒ­ã‚®ãƒ³ã‚°ã—ã€é »å‡ºã™ã‚‹å˜èªã«penaltyã‚’ã‹ã‘ã‚‹æ–¹æ³•<br><br>- High Temperature: temperatureã‚’[0.3, 0.7, 0.9, 1.3]ã«ãã‚Œãã‚Œè¨­å®šã—ã¦å˜èªã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹æ–¹æ³•<br><br>- Seeding Example: ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã€seedã¨ã—ã¦promptã«åŸ‹ã‚è¾¼ã‚“ã§ç”Ÿæˆã•ã›ã‚‹æ–¹æ³•<br><br><br><br>ã§å®Ÿé¨“ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1560" target="_blank" rel="noopener noreferrer" class="title-link">Improving the Domain Adaptation of Retrieval Augmented Generation ï¼ˆRAGï¼‰ Models for Open Domain Question Answering, Siriwardhana+, TACL'23, 2023.01</a>
<span class="snippet"><span>GPT Summary</span>- RAG-end2endã¯ã€ODQAã«ãŠã‘ã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œã®ãŸã‚ã«RAGã®ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã¨ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’å…±åŒè¨“ç·´ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚å¤–éƒ¨çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’æ›´æ–°ã—ã€è£œåŠ©çš„ãªè¨“ç·´ä¿¡å·ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹çŸ¥è­˜ã‚’å¼·åŒ–ã€‚COVID-19ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€ä¼šè©±ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡ã—ã€å…ƒã®RAGãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚æ€§èƒ½ãŒå‘ä¸Šã€‚ç ”ç©¶ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦å…¬é–‹ã€‚</span>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-11-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1546" target="_blank" rel="noopener noreferrer" class="title-link">Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints, Aran Komatsuzaki+, ICLR'23</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¹ãƒ‘ãƒ¼ã‚¹æ´»æ€§åŒ–ãƒ¢ãƒ‡ãƒ«ã¯ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã¤ã¤å¯†ãªãƒ¢ãƒ‡ãƒ«ã®ä»£æ›¿ã¨ã—ã¦æ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ãŒã€ä¾ç„¶ã¨ã—ã¦å¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚’å¿…è¦ã¨ã—ã€ã‚¼ãƒ­ã‹ã‚‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯é«˜ã‚³ã‚¹ãƒˆã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€å¯†ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ã‚¹ãƒ‘ãƒ¼ã‚¹æ´»æ€§åŒ–Mixture-of-Expertsãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã™ã‚‹ã€Œã‚¹ãƒ‘ãƒ¼ã‚¹ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚¯ãƒªãƒ³ã‚°ã€ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åˆæœŸã®å¯†ãªäº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ã‚³ã‚¹ãƒˆã‚’ç´„50%å†åˆ©ç”¨ã—ã€SuperGLUEã‚„ImageNetã§å¯†ãªãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚¯ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚¼ãƒ­ã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸçµæœã‚’å¾—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>æ–œã‚èª­ã¿ã—ã‹ã§ãã¦ã„ãªã„ãŒã€Mixture-of-Expertsã‚’ç”¨ã„ãŸãƒ¢ãƒ‡ãƒ«ã‚’SFT/Pretrainingã™ã‚‹éš›ã«ã€æ—¢å­˜ã®checkpointã®é‡ã¿ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã‚ˆã‚ŠåŠ¹ç‡çš„ã‹ã¤æ€§èƒ½å‘ä¸Šã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚MoE Layerã®MLPã‚’å…¨ã¦æ—¢å­˜ã®checkpointã«ãŠã‘ã‚‹MLPã®é‡ã¿ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦åˆæœŸåŒ–ã™ã‚‹ã€‚Routerã¯ã‚¹ã‚¯ãƒ©ãƒƒãƒã‹ã‚‰å­¦ç¿’ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/d51a0746-d2cc-4343-a462-20034ef373d9" alt="image" loading="lazy"><br><br>ç¶™ç¶šäº‹å‰å­¦ç¿’ã«ãŠã„ã¦ã¯ã€åŒã˜å­¦ç¿’æ™‚é–“ã®ä¸­ã§Dense Layerã‚’ç”¨ã„ã‚‹ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨æ¯”è¼ƒã—ã¦ã§ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’ç²å¾—ã€‚<br><img src="https://github.com/user-attachments/assets/d7a67c99-15d7-4803-82e4-63187bb3d4ec" alt="image" loading="lazy"><br>Figure2ã§ç¶™ç¶šäº‹å‰å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€ãƒ•ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®Finetuningã‚’ã—ãŸå ´åˆã§ã‚‚Upcyclingã¯åŠ¹æœãŒã‚ã‚‹ï¼ˆFigure3ï¼‰ã€‚<br><br>ç‰¹ã«Pretrainingã§ã¯Upcyclingã‚’ç”¨ã„ãŸãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«ã€é€šå¸¸ã®MoEã‚’ã‚¹ã‚¯ãƒ©ãƒƒãƒã‹ã‚‰å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒè¿½ã„ã¤ãã®ã«æ™‚é–“ãŒã‹ã‹ã‚‹ã¨ã®ã“ã¨ã€‚ç‰¹ã«å›³å³å´ã®è¨€èªã‚¿ã‚¹ã‚¯ã§ã¯ã€120%ã®å­¦ç¿’æ™‚é–“ãŒè¿½ã„ã¤ããŸã‚ã«å¿…è¦ã ã£ãŸã€‚<br><img src="https://github.com/user-attachments/assets/f0ca37ac-65a7-43ff-afef-ffc309b17040" alt="image" loading="lazy"><br><br>Sparse Upcycingã¨ã€Dense tilingã«ã‚ˆã‚‹æ‰‹æ³•ï¼ˆwarm start; å…ƒã®ãƒ¢ãƒ‡ãƒ«ã«æ—¢å­˜ã®å±¤ã‚’è¤‡è£½ã—ã¦æ–°ã—ã„å±¤ã‚’è¿½åŠ ã™ã‚‹æ–¹æ³•ï¼‰ã€å…ƒã®ãƒ¢ãƒ‡ãƒ«ã‚’ãã‚Œãã‚Œç¶™ç¶šäº‹å‰å­¦ç¿’ã™ã‚‹ã¨ã€æœ€ã‚‚é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/b357a08a-d202-47d3-977f-f02b192723d1" alt="image" loading="lazy"><br><br>ï¼ˆã™ã”ã„æ–œã‚èª­ã¿ãªã®ã§ã¡ã‚‡ã£ã‚‚è‡ªä¿¡ãªã—ã€ã€ã€ï¼‰</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2024-11-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1534" target="_blank" rel="noopener noreferrer" class="title-link">Prompting Large Language Model for Machine Translation: A Case Study, Biao Zhang+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æ©Ÿæ¢°ç¿»è¨³ã«ãŠã‘ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã®ç ”ç©¶ã‚’ä½“ç³»çš„ã«è¡Œã„ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚„ãƒ‡ãƒ¢ä¾‹ã®é¸æŠã«å½±éŸ¿ã‚’ä¸ãˆã‚‹è¦å› ã‚’æ¤œè¨ã€‚GLM-130Bã‚’ç”¨ã„ãŸå®Ÿé¨“ã«ã‚ˆã‚Šã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã®æ•°ã¨è³ªãŒç¿»è¨³ã«é‡è¦ã§ã‚ã‚‹ã“ã¨ã€æ„å‘³çš„é¡ä¼¼æ€§ãªã©ã®ç‰¹å¾´ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ç›¸é–¢ã™ã‚‹ãŒå¼·ããªã„ã“ã¨ã€å˜è¨€èªãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®æ“¬ä¼¼å¹³è¡Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ãŒç¿»è¨³ã‚’æ”¹å–„ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã€ä»–ã®è¨­å®šã‹ã‚‰ã®çŸ¥è­˜è»¢é€ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã®èª²é¡Œã«ã¤ã„ã¦ã‚‚è­°è«–ã€‚</span>
<span class="snippet"><span>Comment</span><p>zero-shotã§MTã‚’è¡Œã†ã¨ãã«ã€æ”¹è¡Œã®æœ‰ç„¡ã‚„ã€å°‘ã—ã®promptingã®é•ã„ã§COMETã‚¹ã‚³ã‚¢ãŒå¤§å¹…ã«å¤‰ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br>ãƒ¢ãƒ‡ãƒ«ã¯GLM-130Bã‚’INT4ã§é‡å­åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã§å®Ÿé¨“ã—ã¦ã„ã‚‹ã€‚<br><br>èˆˆå‘³æ·±ã„ãŒã€ã“ã®çŸ¥è¦‹ã‚’ä¸€èˆ¬åŒ–ã—ã¦å…¨ã¦ã®LLMã«é©ç”¨ã§ãã‚‹ã‹ï¼Ÿã¨è¨€ã‚ã‚Œã‚‹ã¨ã€ãã†ã¯ãªã‚‰ãªã„æ°—ãŒã™ã‚‹ã€‚ä»–ã®ãƒ¢ãƒ‡ãƒ«ã§æ¤œè¨¼ã—ãŸã‚‰å‚¾å‘ã¯ãŠãã‚‰ãå¤‰ã‚ã‚‹ã§ã‚ã‚ã†ï¼ˆã¨ã„ã†æ„å‘³ã§ãŠãã‚‰ãè«–æ–‡ã®ã‚¿ã‚¤ãƒˆãƒ«ã«ã‚‚Case Studyã¨è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã®ã‹ãªã‚ï¼‰ã€‚<br><br><br><br><img src="https://github.com/user-attachments/assets/1302dbb2-40e2-40c2-9a71-cae01528b5e6" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2024-11-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1498" target="_blank" rel="noopener noreferrer" class="title-link">Precise Zero-Shot Dense Retrieval without Relevance Labels, Luyu Gao+, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆå¯†ãªæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã«ãŠã„ã¦ã€ä»®æƒ³æ–‡æ›¸åŸ‹ã‚è¾¼ã¿ï¼ˆHyDEï¼‰ã‚’ææ¡ˆã€‚ã‚¯ã‚¨ãƒªã«åŸºã¥ãã€æŒ‡ç¤ºã«å¾“ã†è¨€èªãƒ¢ãƒ‡ãƒ«ãŒä»®æƒ³æ–‡æ›¸ã‚’ç”Ÿæˆã—ã€æ•™å¸«ãªã—ã§å­¦ç¿’ã•ã‚ŒãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãŒã“ã‚Œã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã€‚å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã«åŸºã¥ãé¡ä¼¼æ–‡æ›¸ã‚’å–å¾—ã™ã‚‹ã“ã¨ã§ã€èª¤ã£ãŸè©³ç´°ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€‚å®Ÿé¨“çµæœã§ã¯ã€HyDEãŒæœ€å…ˆç«¯ã®å¯†ãªæ¤œç´¢å™¨Contrieverã‚’ä¸Šå›ã‚Šã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã¨è¨€èªã§å¼·åŠ›ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/Self-SupervisedLearning.html" target="_blank" rel="noopener noreferrer">#Self-SupervisedLearning</a>
<span class="issue_date">Issue Date: 2024-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1448" target="_blank" rel="noopener noreferrer" class="title-link">SINC: Self-Supervised In-Context Learning for Vision-Language Tasks, Yi-Syuan Chen+, N_A, ICCV'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±æ•™å¸«ã‚ã‚Šæ–‡è„ˆå†…å­¦ç¿’ï¼ˆSINCï¼‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ä¾å­˜ã›ãšã«æ–‡è„ˆå†…å­¦ç¿’ã‚’å®Ÿç¾ã€‚ç‰¹åˆ¥ã«èª¿æ•´ã•ã‚ŒãŸãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”¨ã„ãŸãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ãŒã€è¦–è¦šã¨è¨€èªã®ã‚¿ã‚¹ã‚¯ã§å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆè¨­å®šã«ãŠã„ã¦å‹¾é…ãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚SINCã¯æ–‡è„ˆå†…å­¦ç¿’ã®åˆ©ç‚¹ã‚’æ¢æ±‚ã—ã€é‡è¦ãªè¦ç´ ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚</span>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2024-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1424" target="_blank" rel="noopener noreferrer" class="title-link">UL2: Unifying Language Learning Paradigms, Yi Tay+, N_A, ICLR'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ™®éçš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€äº‹å‰å­¦ç¿’ã®ç›®çš„ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’åˆ†é›¢ã€‚Mixture-of-Denoisersï¼ˆMoDï¼‰ã‚’å°å…¥ã—ã€è¤‡æ•°ã®äº‹å‰å­¦ç¿’ç›®çš„ã®åŠ¹æœã‚’ç¤ºã™ã€‚20Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€50ã®NLPã‚¿ã‚¹ã‚¯ã§SOTAã‚’é”æˆã—ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã‚„ãƒ¯ãƒ³ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã§ã‚‚å„ªã‚ŒãŸçµæœã‚’ç¤ºã™ã€‚UL2 20Bãƒ¢ãƒ‡ãƒ«ã¯ã€FLANæŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šé«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã€é–¢é€£ã™ã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=6ruVLB727MC" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=6ruVLB727MC</a>


</p>
<p>[R] standard span corruption, [S] causal language modeling, [X] extreme span corruption ã®3ç¨®é¡ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’æŒã¤MoD (Mixture of Denoisers)ã‚’ææ¡ˆ<br><br>&lt;img width="1187" height="1203" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/a07372c6-854c-4bd1-8f59-f8c4dbdc5d23"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a07372c6-854c-4bd1-8f59-f8c4dbdc5d23"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1412" target="_blank" rel="noopener noreferrer" class="title-link">Direct Preference Optimization: Your Language Model is Secretly a Reward  Model, Rafael Rafailov+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ç„¡ç›£ç£è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLMï¼‰ã®åˆ¶å¾¡æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€å ±é…¬ãƒ¢ãƒ‡ãƒ«ã®æ–°ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚’å°å…¥ã—ã€å˜ç´”ãªåˆ†é¡æå¤±ã§RLHFå•é¡Œã‚’è§£æ±ºã™ã‚‹ã€Œç›´æ¥çš„ãªå¥½ã¿æœ€é©åŒ–ï¼ˆDPOï¼‰ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã€‚DPOã¯å®‰å®šæ€§ã¨æ€§èƒ½ã‚’æŒã¡ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã‚’ä¸è¦ã«ã—ã€æ—¢å­˜ã®æ–¹æ³•ã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¤ºã™ã€‚ç‰¹ã«ã€ç”Ÿæˆç‰©ã®æ„Ÿæƒ…åˆ¶å¾¡ã«ãŠã„ã¦PPOãƒ™ãƒ¼ã‚¹ã®RLHFã‚’ä¸Šå›ã‚Šã€å¿œç­”ã®è³ªã‚’æ”¹å–„ã—ã¤ã¤å®Ÿè£…ãŒç°¡ç´ åŒ–ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>DPOã‚’ææ¡ˆã—ãŸç ”ç©¶<br><br>&lt;img width="838" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/2f7edf2c-32fa-4c5c-bc39-fb85112d1837"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/2f7edf2c-32fa-4c5c-bc39-fb85112d1837"&lt;/a&gt;


&gt;<br><br></p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1940194999993585925?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>SNLP'24ã§ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:


<a href="https://speakerdeck.com/kazutoshishinoda/lun-wen-shao-jie-direct-preference-optimization-your-language-model-is-secretly-a-reward-model" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/kazutoshishinoda/lun-wen-shao-jie-direct-preference-optimization-your-language-model-is-secretly-a-reward-model</a>


</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2024-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1401" target="_blank" rel="noopener noreferrer" class="title-link">Instruction Tuning with GPT-4, Baolin Peng+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- GPT-4ã‚’ç”¨ã„ã¦æŒ‡ç¤ºã«å¾“ã†ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†åˆã®è©¦ã¿ã‚’å ±å‘Šã€‚ç”Ÿæˆã•ã‚ŒãŸ52Kã®æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã¯ã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦å„ªã‚ŒãŸã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚GPT-4ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã‚‚åé›†ã—ã€ãƒ‡ãƒ¼ã‚¿ã¨ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç¾åœ¨ã¯OpenAIã®åˆ©ç”¨è¦ç´„ã«ãŠã„ã¦ã€outputã‚’åˆ©ç”¨ã—ã¦OpenAIã¨ç«¶åˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã¯ç¦æ­¢ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ã“ã®ç‚¹ã«ã¯æ³¨æ„ãŒå¿…è¦<br>


<a href="https://openai.com/ja-JP/policies/terms-of-use/" target="_blank" rel="noopener noreferrer">https://openai.com/ja-JP/policies/terms-of-use/</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<span class="issue_date">Issue Date: 2024-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1382" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models Cannot Self-Correct Reasoning Yet, Jie Huang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®è‡ªå·±ä¿®æ­£èƒ½åŠ›ã‚’æ‰¹åˆ¤çš„ã«æ¤œè¨ã—ã€å†…åœ¨çš„è‡ªå·±ä¿®æ­£ã®æ¦‚å¿µã‚’ä¸­å¿ƒã«ã€å¤–éƒ¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãªã—ã§ã®å¿œç­”ä¿®æ­£ã®é›£ã—ã•ã‚’ç¤ºã™ã€‚è‡ªå·±ä¿®æ­£å¾Œã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã€ä»Šå¾Œã®ç ”ç©¶ã‚„å¿œç”¨ã«å‘ã‘ãŸææ¡ˆã‚’è¡Œã†ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<span class="issue_date">Issue Date: 2024-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1380" target="_blank" rel="noopener noreferrer" class="title-link">Reflection-Tuning: Data Recycling Improves LLM Instruction-Tuning, Ming Li+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã„ã†æ–°æ‰‹æ³•ã‚’ææ¡ˆã—ã€LLMsã®è‡ªå·±æ”¹å–„ã‚’é€šã˜ã¦ä½å“è³ªãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å•é¡Œã«å¯¾å‡¦ã€‚ã‚ªãƒ©ã‚¯ãƒ«LLMã‚’ç”¨ã„ã¦ãƒ‡ãƒ¼ã‚¿ã®è³ªã‚’å‘ä¸Šã•ã›ã€å®Ÿé¨“ã«ã‚ˆã‚Šå†åˆ©ç”¨ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚ŒãŸLLMsãŒæ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Reflection-Tuningã‚’ææ¡ˆã—ã¦ã„ã‚‹ç ”ç©¶?</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ConversationalRecommenderSystems.html" target="_blank" rel="noopener noreferrer">#ConversationalRecommenderSystems</a>
<span class="issue_date">Issue Date: 2024-08-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1346" target="_blank" rel="noopener noreferrer" class="title-link">Leveraging Large Language Models in Conversational Recommender Systems, Luke Friedman+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã‚’ä½¿ç”¨ã—ãŸå¤§è¦æ¨¡ãªä¼šè©±å‹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ï¼ˆCRSï¼‰ã®æ§‹ç¯‰ã«é–¢ã™ã‚‹è«–æ–‡ã®è¦ç´„ã§ã™ã€‚LLMsã‚’æ´»ç”¨ã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ç†è§£ã€æŸ”è»Ÿãªãƒ€ã‚¤ã‚¢ãƒ­ã‚°ç®¡ç†ã€èª¬æ˜å¯èƒ½ãªæ¨è–¦ã®æ–°ã—ã„å®Ÿè£…ã‚’ææ¡ˆã—ã€LLMsã«ã‚ˆã£ã¦é§†å‹•ã•ã‚Œã‚‹çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ä¸€éƒ¨ã¨ã—ã¦èª¬æ˜ã—ã¾ã™ã€‚ã¾ãŸã€LLMãŒè§£é‡ˆå¯èƒ½ãªè‡ªç„¶è¨€èªã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ©ç”¨ã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’èª¿æ•´ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦ã‚‚èª¬æ˜ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€LLMãƒ™ãƒ¼ã‚¹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã—ã¦åˆæˆä¼šè©±ã‚’ç”Ÿæˆã™ã‚‹æŠ€è¡“ã‚’ææ¡ˆã—ã€LaMDAã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸYouTubeãƒ“ãƒ‡ã‚ªã®å¤§è¦æ¨¡CRSã§ã‚ã‚‹RecLLMã‚’ç´¹ä»‹ã—ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1309" target="_blank" rel="noopener noreferrer" class="title-link">Mistral 7B, Albert Q. Jiang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Mistral 7B v0.1ã¯ã€70å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€é«˜é€Ÿãªæ¨è«–ã®ãŸã‚ã«GQAã‚’æ´»ç”¨ã—ã€SWAã‚’çµ„ã¿åˆã‚ã›ã¦ã„ã‚‹ã€‚ã¾ãŸã€Mistral 7B -- Instructã¯Llama 2 13B -- Chatãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã£ã¦ãŠã‚Šã€Apache 2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1237" target="_blank" rel="noopener noreferrer">Mistral Large</a>
 <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1279" target="_blank" rel="noopener noreferrer">Mixtral-8x22B-v0.1, 2024</a>
 ãªã©ã®ãƒ¢ãƒ‡ãƒ«ã‚‚å‚ç…§ã®ã“ã¨<br><br><br><br>ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒ«ãŒå¤§ãããªã‚‹ã¨ã€inferenceã®latencyãŒé…ããªã‚Šã€è¨ˆç®—ã‚³ã‚¹ãƒˆãŒå¤§ãããªã‚Šã™ãã¦å®Ÿç”¨çš„ã§ãªã„ã®ã§ã€å°ã•ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ç´ æ—©ã„inferenceå®Ÿç¾ã—ãŸã„ã‚ˆã­ã€ã¨ã„ã†ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã€‚<br><br>ãã®ãŸã‚ã«ã€SlidingWindowAttentionã¨GroupQueryAttention <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
 ã‚’æ´»ç”¨ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/154bc04b-5056-4b88-8b4d-deff169d4a10" alt="image" loading="lazy"><br><br><br><br>ã‚ˆã‚Šå°ã•ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§Llama2ã‚’æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã§outperformã—<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d2890d33-4895-4d09-aa22-5566a471f41f" alt="image" loading="lazy"><br><br><br><br>Instruction Tuningã‚’å®Ÿæ–½ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã€13Bãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ChatbotArenaã§é«˜ã„Elo Rateã‚’ç²å¾—ã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9f37a61e-0cf1-4712-a912-4f7e77094072" alt="image" loading="lazy"><br><br></p>
<p>ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã¯8192</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Annotation.html" target="_blank" rel="noopener noreferrer">#Annotation</a>
<span class="issue_date">Issue Date: 2024-05-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1304" target="_blank" rel="noopener noreferrer" class="title-link">Benchmarking Large Language Models for News Summarization, Tianyi Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®æˆåŠŸã®ç†ç”±ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€ç•°ãªã‚‹äº‹å‰å­¦ç¿’æ–¹æ³•ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ãŠã‚ˆã³ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚±ãƒ¼ãƒ«ã«ã‚ãŸã‚‹10ã¤ã®LLMsã«å¯¾ã™ã‚‹äººé–“ã®è©•ä¾¡ã‚’è¡Œã£ãŸã€‚ãã®çµæœã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§ã¯ãªãã€æŒ‡ç¤ºã®èª¿æ•´ãŒLLMã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆè¦ç´„èƒ½åŠ›ã®éµã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã¾ãŸã€LLMsã®è¦ç´„ã¯äººé–“ã®åŸ·ç­†ã—ãŸè¦ç´„ã¨åŒç­‰ã¨åˆ¤æ–­ã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>- ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®é«˜å“è³ªãªè¦ç´„ã‚’äººé–“ã«ä½œæˆã—ã¦ã‚‚ã‚‰ã„ã€gpt-3.5ã‚’ç”¨ã„ã¦LLM-basedãªè¦ç´„ã‚‚ç”Ÿæˆ<br><br>- annotatorã«ãã‚Œãã‚Œã®è¦ç´„ã®å“è³ªã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã•ã›ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer" class="title-link">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head  Checkpoints, Joshua Ainslie+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Multi-query attentionï¼ˆMQAï¼‰ã¯ã€å˜ä¸€ã®key-value headã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãŠã‚Šã€ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã®æ¨è«–ã‚’åŠ‡çš„ã«é«˜é€ŸåŒ–ã—ã¦ã„ã¾ã™ã€‚ãŸã ã—ã€MQAã¯å“è³ªã®ä½ä¸‹ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚Šã€ã•ã‚‰ã«ã¯ã€ã‚ˆã‚Šé€Ÿã„æ¨è«–ã®ãŸã‚ã ã‘ã«åˆ¥å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ãŒæœ›ã¾ã—ããªã„å ´åˆã‚‚ã‚ã‚Šã¾ã™ã€‚æ—¢å­˜ã®ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨ˆé‡ã®5%ã‚’ä½¿ç”¨ã—ã¦MQAã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã«ã‚¢ãƒƒãƒ—ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®ãƒ¬ã‚·ãƒ”ã‚’ææ¡ˆã—ã€ã•ã‚‰ã«ã€è¤‡æ•°ã®key-value headã‚’ä½¿ç”¨ã™ã‚‹ãƒãƒ«ãƒã‚¯ã‚¨ãƒªã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®ä¸€èˆ¬åŒ–ã§ã‚ã‚‹ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã‚¯ã‚¨ãƒªã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ï¼ˆGQAï¼‰ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚ã‚¢ãƒƒãƒ—ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸGQAãŒã€MQAã¨åŒç­‰ã®é€Ÿåº¦ã§ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã«åŒ¹æ•µã™ã‚‹å“è³ªã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>é€šå¸¸ã®Multi-Head AttentionãŒQKVãŒ1å¯¾1å¯¾å¿œãªã®ã«å¯¾ã—ã€Multi Query Attention (MQA) <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1272" target="_blank" rel="noopener noreferrer">Fast Transformer Decoding: One Write-Head is All You Need, Noam Shazeer, N/A, arXiv'19</a>
  ã¯å…¨ã¦ã®Qã«å¯¾ã—ã¦KVã‚’å…±æœ‰ã™ã‚‹ã€‚ä¸€æ–¹ã€GQAã¯ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«KVã‚’å…±æœ‰ã™ã‚‹ç‚¹ã§ç•°ãªã‚‹ã€‚MQAã¯å¤§å¹…ã«Infeerence` speedãŒæ”¹å–„ã™ã‚‹ãŒã€ç²¾åº¦ãŒåŠ£åŒ–ã™ã‚‹å•é¡ŒãŒã‚ã£ãŸã€‚ã“ã®ç ”ç©¶ã§ã¯é€šå¸¸ã®Multi-Head Attentionã«å¯¾ã—ã¦ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®äº‹å‰å­¦ç¿’ã«å¯¾ã—ã¦è¿½åŠ ã®5%ã®è¨ˆç®—é‡ã§GQAãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/70ec2179-428c-47b8-af53-cb3cc0e4f022" alt="image" loading="lazy"><br><br></p>
<p>Main Result. Multi-Head Attentionã«å¯¾ã—ã¦ã€inference timeãŒå¤§å¹…ã«æ”¹å–„ã—ã¦ã„ã‚‹ãŒã€Multi-Query Attentionã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¶­æŒã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3687aeb4-90b8-403d-853b-740121dd5f98" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1224" target="_blank" rel="noopener noreferrer" class="title-link">INSTRUCTSCORE: Explainable Text Generation Evaluation with Finegrained   Feedback, Wenda Xu+, N_A, EMNLP'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå‹•çš„ãªè¨€èªç”Ÿæˆã®å“è³ªè©•ä¾¡ã«ã¯èª¬æ˜å¯èƒ½ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒå¿…è¦ã§ã‚ã‚‹ãŒã€æ—¢å­˜ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯ãã®åˆ¤å®šã‚’èª¬æ˜ã—ãŸã‚Šæ¬ é™¥ã¨ã‚¹ã‚³ã‚¢ã‚’é–¢é€£ä»˜ã‘ã‚‹ã“ã¨ãŒã§ããªã„ã€‚ãã“ã§ã€InstructScoreã¨ã„ã†æ–°ã—ã„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ææ¡ˆã—ã€äººé–“ã®æŒ‡ç¤ºã¨GPT-4ã®çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã®è©•ä¾¡ã¨è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚ã•ã¾ã–ã¾ãªç”Ÿæˆã‚¿ã‚¹ã‚¯ã§InstructScoreã‚’è©•ä¾¡ã—ã€ä»–ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚é©šãã¹ãã“ã¨ã«ã€InstructScoreã¯äººé–“ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãªã—ã§æœ€å…ˆç«¯ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä¼çµ±çš„ãªNLGã®æ€§èƒ½æŒ‡æ¨™ã®è§£é‡ˆæ€§ãŒä½ã„ã“ã¨ã‚’ä¸»å¼µã™ã‚‹ç ”ç©¶</p>
<p><img src="https://github.com/user-attachments/assets/4c4fe705-e0c5-41d1-b3c8-c084d85b77ba" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1223" target="_blank" rel="noopener noreferrer" class="title-link">G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment, Yang Liu+, N_A, EMNLP'23</a>
<span class="snippet"><span>GPT Summary</span>- å¾“æ¥ã®å‚ç…§ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡æŒ‡æ¨™ã§ã¯ã€è‡ªç„¶è¨€èªç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®å“è³ªã‚’æ­£ç¢ºã«æ¸¬å®šã™ã‚‹ã“ã¨ãŒé›£ã—ã„ã€‚æœ€è¿‘ã®ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ãŸå‚ç…§ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡æŒ‡æ¨™ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ãŒã€ã¾ã äººé–“ã¨ã®ä¸€è‡´åº¦ãŒä½ã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€G-Evalã¨ã„ã†å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸå“è³ªè©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€è¦ç´„ã¨å¯¾è©±ç”Ÿæˆã®ã‚¿ã‚¹ã‚¯ã§å®Ÿé¨“ã‚’è¡Œã£ãŸã€‚G-Evalã¯å¾“æ¥ã®æ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ã€LLMãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡å™¨ã®æ½œåœ¨çš„ãªå•é¡Œã«ã¤ã„ã¦ã‚‚åˆ†æã—ã¦ã„ã‚‹ã€‚ã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä¼çµ±çš„ãªNLGã®æ€§èƒ½æŒ‡æ¨™ãŒã€äººé–“ã®åˆ¤æ–­ã¨ã®ç›¸é–¢ãŒä½ã„ã“ã¨ã‚’ç¤ºã—ãŸç ”ç©¶</p>
<p>
<strong># æ‰‹æ³•æ¦‚è¦<br><br>- CoTã‚’åˆ©ç”¨ã—ã¦ã€ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®å“è³ªã‚’è©•ä¾¡ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br>- ã‚¿ã‚¹ã‚¯ã®Introductionã¨ã€è©•ä¾¡ã®Criteriaã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ä»•è¾¼ã‚€ã ã‘ã§ã€è‡ªå‹•çš„ã«LLMã«è©•ä¾¡ã‚¹ãƒ†ãƒƒãƒ—ã«é–¢ã™ã‚‹CoTã‚’ç”Ÿæˆã•ã›ã€æœ€çµ‚çš„ã«ãƒ•ã‚©ãƒ¼ãƒ ã‚’åŸ‹ã‚ã‚‹å½¢å¼ã§ã‚¹ã‚³ã‚¢ã‚’ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ç”Ÿæˆã•ã›è©•ä¾¡ã‚’å®Ÿæ–½ã™ã‚‹ã€‚æœ€çµ‚çš„ã«ã€å„ã‚¹ã‚³ã‚¢ã®ç”Ÿæˆç¢ºç‡ã«ã‚ˆã‚‹weighted-sumã«ã‚ˆã£ã¦ã€æœ€çµ‚ã‚¹ã‚³ã‚¢ã‚’æ±ºå®šã™ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a91c9234-6f41-4fb4-a94f-8a47a594dd9e" alt="image" loading="lazy"><br><br><br><br>&lt;/p&gt;<p># Scoringã®å•é¡Œç‚¹<br><br>ãŸã¨ãˆã°ã€1-5ã®discreteãªã‚¹ã‚³ã‚¢ã‚’ç›´æ¥LLMã«outputã•ã›ã‚‹ã¨ã€ä¸‹è¨˜ã®ã‚ˆã†ãªå•é¡ŒãŒç”Ÿã˜ã‚‹ï¼š<br><br>1. ã‚ã‚‹ä¸€ã¤ã®ã‚¹ã‚³ã‚¢ãŒæ”¯é…çš„ã«ãªã£ã¦ã—ã¾ã„ã€ã‚¹ã‚³ã‚¢ã®åˆ†æ•£ãŒç„¡ãã€äººé–“ã®è©•ä¾¡ã¨ã®ç›¸é–¢ãŒä½ããªã‚‹<br><br>2. LLMã¯å°æ•°ã‚’å‡ºåŠ›ã™ã‚‹ã‚ˆã†æŒ‡ç¤ºã—ã¦ã‚‚ã€å¤§æŠµã®å ´åˆæ•´æ•°ã‚’å‡ºåŠ›ã™ã‚‹ãŸã‚ã€å¤šãã®ãƒ†ã‚­ã‚¹ãƒˆã®è©•ä¾¡å€¤ãŒåŒä¸€ã¨ãªã‚Šã€ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ç´°ã‹ãªå·®ç•°ã‚’è©•ä¾¡ã«å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ãŒã§ããªã„ã€‚<br><br><br><br>ä¸Šè¨˜ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€ä¸‹è¨˜ã®ã‚ˆã†ã«ã€ã‚¹ã‚³ã‚¢ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆç¢ºç‡ã®é‡ã¿ã¥ã‘å’Œã‚’ã¨ã‚‹ã“ã¨ã§ã€æœ€çµ‚çš„ãªã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a2a8d26c-0fb4-4f60-bd6e-600898785d7b" alt="image" loading="lazy"></p>
<p># è©•ä¾¡<br><br>- SummEval <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/984" target="_blank" rel="noopener noreferrer">SummEval: Re-evaluating Summarization Evaluation, Fabbri+, TACL'21</a>
&lt;/strong&gt;
<br>
 ãƒ‡ãƒ¼ã‚¿ã¨ã€Topical-Chat, QAGSãƒ‡ãƒ¼ã‚¿ã®3ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§è©•ä¾¡ã‚’å®Ÿæ–½ã—ãŸã€‚ã‚¿ã‚¹ã‚¯ã¨ã—ã¦ã¯ã€è¦ç´„ã¨å¯¾è©±ã®response generationã®ãƒ‡ãƒ¼ã‚¿ã¨ãªã‚‹ã€‚<br><br>- ãƒ¢ãƒ‡ãƒ«ã¯GPT-3.5 (text-davinci-003), GPT-4ã‚’åˆ©ç”¨ã—ãŸ<br><br>- gpt3.5åˆ©ç”¨æ™‚ã¯ã€temperatureã¯0ã«è¨­å®šã—ã€GPT-4ã¯ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆç¢ºç‡ã‚’è¿”ã•ãªã„ã®ã§ã€`n=20, temperature=1, top_p=1`ã¨ã—ã€20å›ã®ç”Ÿæˆçµæœã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã®å‡ºç¾ç¢ºç‡ã‚’ç®—å‡ºã—ãŸã€‚<br><br><br><br>
<strong>## è©•ä¾¡çµæœ<br><br>G-EVALãŒbaselineã‚’outperformã—ã€ç‰¹ã«GPT4ã‚’åˆ©ç”¨ã—ãŸå ´åˆã«æ€§èƒ½ãŒé«˜ã„ã€‚GPTScoreã‚’åˆ©ç”¨ã—ãŸå ´åˆã«ã€ãƒ¢ãƒ‡ãƒ«ã‚’ä½•ã‚’ä½¿ç”¨ã—ãŸã®ã‹ãŒæ›¸ã‹ã‚Œã¦ã„ãªã„ã€‚Appendixã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã®ã ã‚ã†ã‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/924b0acd-6236-49a0-a6bc-ae203c87f7ea" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/435fa260-a88d-4db2-b3a2-40d29a6617df" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/f9ca4e1f-903d-48fa-a40f-64fa8c799c43" alt="image" loading="lazy"><br><br>&lt;/p&gt;<p># Analysis<br><br>## G-EvalãŒLLMãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å¥½ã‚“ã§é«˜ã„ã‚¹ã‚³ã‚¢ã‚’ä»˜ä¸ã—ã¦ã—ã¾ã†ã‹ï¼Ÿ<br><br>- äººé–“ã«å“è³ªã®é«˜ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹è¦ç´„ã‚’æ›¸ã‹ã›ã€ã‚¢ãƒãƒ†ãƒ¼ã‚¿ã«GPTãŒç”Ÿæˆã—ãŸè¦ç´„ã‚’æ¯”è¼ƒã•ã›ãŸãƒ‡ãƒ¼ã‚¿ (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1304" target="_blank" rel="noopener noreferrer">Benchmarking Large Language Models for News Summarization, Tianyi Zhang+, N/A, arXiv'23</a>
&lt;/strong&gt;
<br>
) ã‚’ç”¨ã„ã¦æ¤œè¨¼<br><br>- ãã®çµæœã€åŸºæœ¬çš„ã«GPTãŒç”Ÿæˆã—ãŸè¦ç´„ã«å¯¾ã—ã¦ã€G-EVAL4ãŒé«˜ã„ã‚¹ã‚³ã‚¢ã‚’ä»˜ä¸ã™ã‚‹å‚¾å‘ã«ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚<br><br>    - åŸå› 1: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1304" target="_blank" rel="noopener noreferrer">Benchmarking Large Language Models for News Summarization, Tianyi Zhang+, N/A, arXiv'23</a>
ã§æŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€äººé–“ãŒè¨˜è¿°ã—ãŸè¦ç´„ã¨LLMãŒè¨˜è¿°ã—ãŸè¦ç´„ã‚’åŒºåˆ¥ã™ã‚‹ã‚¿ã‚¹ã‚¯ã¯ã€inter-annotator agreementã¯`0.07`ã§ã‚ã‚Šã€æ¥µç«¯ã«ä½ãã€äººé–“ã§ã‚‚å›°é›£ãªã‚¿ã‚¹ã‚¯ã§ã‚ã‚‹ãŸã‚ã€‚<br><br>    - åŸå› 2: LLMã¯ç”Ÿæˆæ™‚ã¨è©•ä¾¡æ™‚ã«ã€å…±é€šã—ãŸã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã§å…±æœ‰ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒé«˜ãã€ã“ã‚ŒãŒLLMãŒç”Ÿæˆã—ãŸè¦ç´„ã‚’é«˜ãè©•ä¾¡ã™ã‚‹ãƒã‚¤ã‚¢ã‚¹ã‚’ã‹ã‘ãŸ<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ec6a213d-15ea-4572-8716-ad9cbee6f19a" alt="image" loading="lazy"><br><br><br><br>## CoTã®å½±éŸ¿<br><br>- SummEvalãƒ‡ãƒ¼ã‚¿ã«ãŠã„ã¦ã€CoTã®æœ‰ç„¡ã«ã‚ˆã‚‹æ€§èƒ½ã®å·®ã‚’æ¤œè¨¼ã—ãŸçµæœã€CoTã‚’å°å…¥ã—ãŸå ´åˆã«ã‚ˆã‚Šé«˜ã„correlationã‚’ç²å¾—ã—ãŸã€‚ç‰¹ã«ã€Fluencyã¸ã®å½±éŸ¿ãŒå¤§ãã„ã€‚<br><br><br><br>## Probability Normalizationã«ã‚ˆã‚‹å½±éŸ¿<br><br>- probabilityã«ã‚ˆã‚‹normalizationã‚’å°å…¥ã—ãŸã“ã¨ã§ã€kendall tauãŒæ¸›å°‘ã—ãŸã€‚ã“ã®ç†ç”±ã¯ã€probabilityãŒå°å…¥ã•ã‚Œã¦ã„ãªã„å ´åˆã¯å¤šãã®å¼•ãåˆ†ã‘ã‚’ç”Ÿã¿å‡ºã™ã€‚ä¸€æ–¹ã€kendall tauã¯ã€concordant / discordantãƒšã‚¢ã®æ•°ã«ã‚ˆã£ã¦æ±ºå®šã•ã‚Œã‚‹ãŒã€å¼•ãåˆ†ã‘ã®å ´åˆã¯ã©ã¡ã‚‰ã«ã‚‚ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œãšã€kendall tauã®å€¤ã‚’æŠ¼ã—ä¸Šã’ã‚‹åŠ¹æœãŒã‚ã‚‹ã€‚ã“ã®ãŸã‚ã€ã“ã‚Œã¯ãƒ¢ãƒ‡ãƒ«ã®çœŸã®æ€§èƒ½ã‚’åæ˜ ã—ã¦ã„ãªã„ã€‚<br><br>- ä¸€æ–¹ã€probabilityã‚’å°å…¥ã™ã‚‹ã¨ã€ã‚ˆã‚Šç´°ã‹ã„ãªé€£ç¶šçš„ãªã‚¹ã‚³ã‚¢ã‚’ç²å¾—ã™ã‚‹ã“ã¨ãŒã§ãã€ã“ã‚Œã¯spearman-correlationã®å‘ä¸Šã«åæ˜ ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br><br><br>## ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«ã‚ˆã‚‹å½±éŸ¿<br><br>- åŸºæœ¬çš„ã«å¤§ãã„ã‚µã‚¤ã‚ºã®æ–¹ãŒé«˜ã„correlationã‚’ç¤ºã™ã€‚ç‰¹ã«ã€consistencyã‚„relevanceã¨ã„ã£ãŸã€è¤‡é›‘ãªè©•ä¾¡ã‚¿ã‚¹ã‚¯ã§ã¯ãã®å·®ãŒé¡•è‘—ã§ã‚ã‚‹ã€‚<br><br>- ä¸€æ–¹ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã„æ–¹ãŒæ€§èƒ½ãŒè‰¯ã„è¦³ç‚¹ï¼ˆengagingness, groundednessï¼‰ãªã©ã‚‚å­˜åœ¨ã—ãŸã€‚</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2023-12-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1194" target="_blank" rel="noopener noreferrer" class="title-link">Gemini: A Family of Highly Capable Multimodal Models, Gemini Team+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®å ±å‘Šæ›¸ã§ã¯ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€ŒGeminiã€ã®ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã«ã¤ã„ã¦ç´¹ä»‹ã—ã¾ã™ã€‚Geminiã¯ç”»åƒã€éŸ³å£°ã€å‹•ç”»ã€ãƒ†ã‚­ã‚¹ãƒˆã®ç†è§£ã«å„ªã‚ŒãŸèƒ½åŠ›ã‚’æŒã¡ã€Ultraã€Proã€Nanoã®ã‚µã‚¤ã‚ºãŒã‚ã‚Šã¾ã™ã€‚Gemini Ultraã¯å¹…åºƒã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®æŠ€è¡“ã‚’æä¾›ã—ã€MMLUã§ã¯äººé–“ã®å°‚é–€å®¶ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åˆã‚ã¦é”æˆã—ã¾ã—ãŸã€‚Geminiãƒ¢ãƒ‡ãƒ«ã¯ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«ãªæ¨è«–ã¨è¨€èªç†è§£ã®èƒ½åŠ›ã‚’æŒã¡ã€ã•ã¾ã–ã¾ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«é©ç”¨ã§ãã¾ã™ã€‚ã¾ãŸã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®è²¬ä»»ã‚ã‚‹å±•é–‹ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1181" target="_blank" rel="noopener noreferrer">Gemini, Google, 2023.12</a>
 ã§ç™ºè¡¨ã•ã‚ŒãŸGeminiã®è«–æ–‡</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2023-12-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1179" target="_blank" rel="noopener noreferrer" class="title-link">The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context  Learning, Bill Yuchen Lin+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆèª¿æ•´ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚ã—ã‹ã—ã€ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆèª¿æ•´ã®åŠ¹æœã¯ã€Œè¡¨é¢çš„ã€ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€åŸºæœ¬çš„ãªLLMã¨ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆèª¿æ•´ã•ã‚ŒãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒˆãƒ¼ã‚¯ãƒ³åˆ†å¸ƒã®ã‚·ãƒ•ãƒˆã‚’åˆ†æã—ã¾ã—ãŸã€‚çµæœã¯ã€ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆèª¿æ•´ãŒä¸»ã«ã‚¹ã‚¿ã‚¤ãƒ«ãƒˆãƒ¼ã‚¯ãƒ³ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ã‚·ãƒ³ãƒ—ãƒ«ã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒªãƒ¼ãªã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆæ‰‹æ³•ã§ã‚ã‚‹URIALã‚’å°å…¥ã—ã€åŸºæœ¬çš„ãªLLMã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã“ã‚Œã‚‰ã®çµæœã‹ã‚‰ã€ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã®ã‚ˆã‚Šæ·±ã„åˆ†æã¨ç†è«–çš„ãªç†è§£ãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã¯Pre-trainingæ™‚ã«ååˆ†ç²å¾—ã•ã‚Œã¦ãŠã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®Alignmentã‚’ã¨ã‚‹ã“ã¨ã§ç”Ÿã˜ã‚‹ã‚‚ã®ã¯è¡¨é¢çš„ãªå¤‰åŒ–ã®ã¿ã§ã‚ã‚‹ã¨ã„ã†ä»®èª¬ãŒã‚ã‚‹ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/700" target="_blank" rel="noopener noreferrer">LIMA: Less Is More for Alignment, Chunting Zhou+, N/A, NeurIPS'23</a>
 ã€‚ã“ã®ä»®èª¬ã«é–¢ã—ã¦åˆ†æã‚’ã—ã€çµæœçš„ã«ã‚¹ã‚¿ã‚¤ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãªæƒ…å ±ã‚’ç”Ÿæˆã™ã‚‹éƒ¨åˆ†ã§Alignmentã®æœ‰ç„¡ã§é•ã„ãŒç”Ÿã˜ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã€ãã†ã§ã‚ã‚Œã°ã‚ã–ã‚ã–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFT, RLHFï¼‰ã—ãªãã¦ã‚‚ã€é©åˆ‡ãªã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠã—ãŸIn-Context Learningã§ã‚‚Alignmentã¨ã‚Œã¾ã™ã‚ˆã€ã¨ã„ã†è¶£æ—¨ã®ç ”ç©¶ã£ã½ã„ï¼Ÿ<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b8c62b33-dd72-43ea-8953-abb5c04cc504" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<span class="issue_date">Issue Date: 2023-12-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1177" target="_blank" rel="noopener noreferrer" class="title-link">Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural  Scrambled Text, Qi Cao+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å†…éƒ¨å‹•ä½œã«ã¤ã„ã¦ã®æ–°ã—ã„æ´å¯Ÿã‚’æä¾›ã—ã¾ã™ã€‚ç‰¹ã«ã€GPT-4ã‚’èª¿æŸ»ã—ã€LLMsã®è€ä¹…æ€§ã«é–¢ã™ã‚‹å®Ÿé¨“çµæœã‚’ç¤ºã—ã¾ã™ã€‚å®Ÿé¨“ã§ã¯ã€æ–‡å­—ãƒ¬ãƒ™ãƒ«ã®é †åˆ—ã«å¯¾ã™ã‚‹LLMsã®è€æ€§ã‚’èª¿ã¹ã‚‹ãŸã‚ã«ã€Scrambled Benchã¨ã„ã†ã‚¹ã‚¤ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¾ã—ãŸã€‚çµæœã¯ã€GPT-4ãŒtypoglycemiaã¨ã„ã†ç¾è±¡ã«ä¼¼ãŸèƒ½åŠ›ã‚’æŒã¡ã€éå¸¸ã«è‡ªç„¶ã§ãªã„ã‚¨ãƒ©ãƒ¼ã‚’å«ã‚€å…¥åŠ›ã‚’ã»ã¼å®Œç’§ã«å‡¦ç†ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯ã€LLMsã®è€æ€§ãŒç›´æ„Ÿã«åã™ã‚‹ã‚‚ã®ã§ã‚ã‚Šã€ä»–ã®LLMsã‚„äººé–“ã«ã¨ã£ã¦ã‚‚å›°é›£ãªã‚¿ã‚¹ã‚¯ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/df33c7a9-005e-4d7e-9d70-d8f0657869ed" alt="image" loading="lazy"></p>
<p>OpenAIã®ãƒ¢ãƒ‡ãƒ«ãŒãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã§ã‚ã‚‹é™ã‚Šã€ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚ã‚‹ã®ã§ã¯ï¼Ÿã¨ã„ã†ç–‘å¿µã¯æŒã£ã¦ã—ã¾ã†ã€‚<br><br>ï¼ˆéƒ¨åˆ†çš„ã«ã—ã‹èª­ã‚ã¦ã„ãªã„ãŒâ€¦ï¼‰<br>RealtimeQAã¨å‘¼ã°ã‚Œã‚‹weeklyã§ç›´è¿‘ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«å¯¾ã™ã‚‹Questionã‚’ç™ºè¡¨ã™ã‚‹ã“ã¨ã§æ§‹ç¯‰ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã†ã¡ã€2023.03.17--2023.08.04ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã€ScrambledSentenaeRecoveryï¼ˆScrRecï¼‰ã¨ScrambleQuestionAnsweringï¼ˆScrQAï¼‰ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/362bcbca-b578-4f0e-ac4e-e65fd216aeac" alt="image" loading="lazy"><br><br>å®Œå…¨ã«ãƒ©ãƒ³ãƒ€ãƒ ã«å˜èªã®æ–‡å­—ã‚’scrambleï¼ˆRSï¼‰ã™ã‚‹ã¨ã€Falconã¨Llama2ã§ã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§ã¯å†æ§‹ç¯‰ã§ããªã„ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚FewShotã§ã¯Falconã§ã‚ã‚Œã°å°‘ã—è§£ã‘ã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚ä¸€æ–¹ã€OpenAIã®ãƒ¢ãƒ‡ãƒ«ã€ç‰¹ã«GPT4, GPT3.5-turboã§ã¯ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§ã‚‚ã«ã‚Šå†æ§‹ç¯‰ãŒã§ãã¦ã„ã‚‹ã€‚<br><br>ScrQAã«ã¤ã„ã¦ã¯ã€ãƒ©ãƒ³ãƒ€ãƒ ã«scrambleã—ãŸå ´åˆã§ã‚‚MultipleChoiceQuestionãªã®ã§ï¼ˆRPGã¨å‘¼ã°ã‚Œã‚‹Accã®ç›¸å¯¾çš„ãªgainã‚’è©•ä¾¡ã™ã‚‹ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ææ¡ˆã—ã¦ã„ã‚‹ï¼‰æ­£è§£ã¯ã§ãã¦ã„ã‚‹ã€‚<br><br>æœ€åˆã®æ–‡å­—ã ã‘ã‚’æ®‹ã™å ´åˆï¼ˆKFï¼‰æœ€åˆã¨æœ€å¾Œã®æ–‡å­—ã‚’æ®‹ã™å ´åˆï¼ˆKFLã€ã«ã¤ã„ã¦ã¯ã€æ®‹ã™æ–‡å­—ãŒå¢—ãˆã‚‹ã»ã©ã©ã¡ã‚‰ã®ã‚¿ã‚¹ã‚¯ã‚‚æ€§èƒ½ãŒä¸ŠãŒã‚Šã€æœ€åˆã®æ–‡å­—ã ã‘ãŒã‚ã‚Œã°OpenSourceLLMã§ã‚‚ï¼ˆã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§ã‚‚ï¼‰ã‹ãªã‚Šå…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã®å†æ§‹ç¯‰ãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã€‚ã¾ãŸã€QAã‚‚æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã€‚</p>
<p>å®Œå…¨ã«ãƒ©ãƒ³ãƒ€ãƒ ã«æ–‡å­—ã‚’å…¥ã‚Œæ›¿ãˆãŸã‚‰å®Œå…¨ã«ç„¡ç†ã‚²ãƒ¼ãªã®ã§ã¯ã€ã€ã€ã€ã¨æ€ã£ã¦ã—ã¾ã†ã®ã ãŒã€Falconã§Fewshotã®å ´åˆã¯ä¸€éƒ¨è§£ã‘ã¦ã„ã‚‹ã‚ˆã†ã â€¦ã€‚æœãŸã—ã¦ã©ã†ã„ã†ã“ã¨ãªã®ã‹â€¦ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ãŒä¿æŒã•ã‚ŒãŸã¾ã¾ãªã®ãŒãƒ’ãƒ³ãƒˆã«ãªã£ã¦ã„ã‚‹â€¦ï¼Ÿï¼‰Appendixã«è€ƒå¯ŸãŒã‚ã‚Šãã†ã ãŒã¾ã èª­ã‚ã¦ã„ãªã„ã€‚<br><br><br><br>ï¼ˆè¿½è¨˜ï¼‰<br><br>æ–‡å…¨ä½“ã§ãƒ©ãƒ³ãƒ€ãƒ ã«æ–‡å­—ã‚’å…¥ã‚Œæ›¿ãˆã¦ã„ã‚‹ã®ã‹ã¨å‹˜é•ã„ã—ã¦ã„ãŸãŒã€å®Ÿéš›ã«ã¯â€ã‚ã‚‹å˜èªã®ä¸­ã ã‘ã§ãƒ©ãƒ³ãƒ€ãƒ ã«å…¥ã‚Œæ›¿ãˆâ€ã ã£ãŸã€‚ã“ã‚Œãªã‚‰åŸç†ä¸Šã¯ã„ã‘ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-11-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1163" target="_blank" rel="noopener noreferrer" class="title-link">Exponentially Faster Language Modelling, Peter Belcak+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- UltraFastBERTã¯ã€æ¨è«–æ™‚ã«ã‚ãšã‹0.3%ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã—ã‹ä½¿ç”¨ã›ãšã€åŒç­‰ã®æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒã§ãã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚UltraFastBERTã¯ã€é«˜é€Ÿãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆFFFï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€åŠ¹ç‡çš„ãªå®Ÿè£…ã‚’æä¾›ã—ã¾ã™ã€‚æœ€é©åŒ–ã•ã‚ŒãŸãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®å®Ÿè£…ã«æ¯”ã¹ã¦78å€ã®é«˜é€ŸåŒ–ã‚’å®Ÿç¾ã—ã€ãƒãƒƒãƒå‡¦ç†ã•ã‚ŒãŸæ¨è«–ã«å¯¾ã—ã¦ã¯40å€ã®é«˜é€ŸåŒ–ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã€ãŠã‚ˆã³ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚‚å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-11-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1158" target="_blank" rel="noopener noreferrer" class="title-link">GAIA: a benchmark for General AI Assistants, GrÃ©goire Mialon+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- GAIAã¯ã€General AI Assistantsã®ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚Šã€AIç ”ç©¶ã®ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚GAIAã¯ã€æ¨è«–ã€ãƒãƒ«ãƒãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®å‡¦ç†ã€ã‚¦ã‚§ãƒ–ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ãªã©ã€å®Ÿä¸–ç•Œã®è³ªå•ã«å¯¾ã™ã‚‹åŸºæœ¬çš„ãªèƒ½åŠ›ã‚’å¿…è¦ã¨ã™ã‚‹ã€‚äººé–“ã®å›ç­”è€…ã¯92ï¼…ã®æ­£ç­”ç‡ã‚’é”æˆã—ã€GPT-4ã¯15ï¼…ã®æ­£ç­”ç‡ã‚’é”æˆã—ãŸã€‚ã“ã‚Œã¯ã€æœ€è¿‘ã®å‚¾å‘ã¨ã¯ç•°ãªã‚‹çµæœã§ã‚ã‚Šã€å°‚é–€çš„ãªã‚¹ã‚­ãƒ«ã‚’å¿…è¦ã¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã¯LLMsãŒäººé–“ã‚’ä¸Šå›ã£ã¦ã„ã‚‹ã€‚GAIAã¯ã€äººé–“ã®å¹³å‡çš„ãªå …ç‰¢æ€§ã¨åŒç­‰ã®èƒ½åŠ›ã‚’æŒã¤ã‚·ã‚¹ãƒ†ãƒ ãŒAGIã®åˆ°æ¥ã«é‡è¦ã§ã‚ã‚‹ã¨è€ƒãˆã¦ã„ã‚‹ã€‚GAIAã®æ‰‹æ³•ã‚’ä½¿ç”¨ã—ã¦ã€466ã®è³ªå•ã¨å›ç­”ã‚’ä½œæˆã—ã€ä¸€éƒ¨ã‚’å…¬é–‹ã—ã¦ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã§åˆ©ç”¨å¯èƒ½ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Yann LeCunæ°ã®ç´¹ä»‹ãƒ„ã‚¤ãƒ¼ãƒˆ<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ylecun/status/1727707519470977311?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Meta-FAIR, Meta-GenAI, HuggingFace, AutoGPTã«ã‚ˆã‚‹ç ”ç©¶ã€‚äººé–“ã¯92%æ­£è§£ã§ãã‚‹ãŒã€GPT4ã§ã‚‚15%ã—ã‹æ­£è§£ã§ããªã„QAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚è§£ããŸã‚ã«æ¨è«–ã‚„ãƒãƒ«ãƒãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®å‡¦ç†ã€ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ã€ãƒ„ãƒ¼ãƒ«ã«å¯¾ã™ã‚‹ç¿’ç†Ÿãªã©ã®åŸºæœ¬çš„ãªèƒ½åŠ›ã‚’å¿…è¦ã¨ã™ã‚‹å®Ÿä¸–ç•Œã®QAã¨ã®ã“ã¨ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0b13838b-0829-48b9-b281-3d09a5a3859f" alt="image" loading="lazy"></span></strong></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1792" target="_blank" rel="noopener noreferrer">Open-source DeepResearch â€“ Freeing our search agents, HuggingFace, 2025.02</a>
<br><br>ã§è¨€åŠã•ã‚Œã¦ã„ã‚‹LLM Agentã®è©•ä¾¡ã§æœ€ã‚‚æœ‰åãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãªæ¨¡æ§˜</p>
<p>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: 


<a href="https://huggingface.co/datasets/gaia-benchmark/GAIA" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/gaia-benchmark/GAIA</a>


</p></strong></p></span><br><br>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2023-11-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1152" target="_blank" rel="noopener noreferrer" class="title-link">Igniting Language Intelligence: The Hitchhiker's Guide From  Chain-of-Thought Reasoning to Language Agents, Zhuosheng Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€è¨€èªçŸ¥èƒ½ã®åˆ†é‡ã§åŠ‡çš„ãªé€²æ­©ã‚’é‚ã’ã¦ãŠã‚Šã€è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ç‰¹ã«ã€chain-of-thoughtï¼ˆCoTï¼‰æ¨è«–æŠ€è¡“ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€ä¸­é–“ã‚¹ãƒ†ãƒƒãƒ—ã‚’å½¢æˆã—ã€è§£é‡ˆå¯èƒ½æ€§ã‚„åˆ¶å¾¡å¯èƒ½æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®è«–æ–‡ã§ã¯ã€CoTæŠ€è¡“ã®åŸºæœ¬çš„ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚„ãã®åŠ¹æœã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã€è¨€èªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é–‹ç™ºã«ãŠã‘ã‚‹å¿œç”¨ä¾‹ã‚’ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚å°†æ¥ã®ç ”ç©¶ã®å±•æœ›ã«ã‚‚è§¦ã‚Œã¦ãŠã‚Šã€åˆå¿ƒè€…ã‹ã‚‰çµŒé¨“è±Šå¯Œãªç ”ç©¶è€…ã¾ã§å¹…åºƒã„èª­è€…ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚é–¢é€£è«–æ–‡ã®ãƒªãƒã‚¸ãƒˆãƒªã‚‚æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>CoTã«é–¢ã™ã‚‹ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«è«–æ–‡</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2023-11-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1151" target="_blank" rel="noopener noreferrer" class="title-link">System 2 Attention ï¼ˆis something you might need tooï¼‰, Jason Weston+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Transformerãƒ™ãƒ¼ã‚¹ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã‘ã‚‹ã‚½ãƒ•ãƒˆã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã¯ã€æ–‡è„ˆã‹ã‚‰ç„¡é–¢ä¿‚ãªæƒ…å ±ã‚’å–ã‚Šè¾¼ã‚€å‚¾å‘ãŒã‚ã‚Šã€æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆã«æ‚ªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã€‚ãã“ã§ã€System 2 Attentionï¼ˆS2Aï¼‰ã‚’å°å…¥ã—ã€LLMsãŒè‡ªç„¶è¨€èªã§æ¨è«–ã—ã€æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã‚’æ´»ç”¨ã—ã¦ã€æ³¨ç›®ã™ã¹ãæƒ…å ±ã‚’æ±ºå®šã™ã‚‹ã€‚S2Aã¯é–¢é€£ã™ã‚‹éƒ¨åˆ†ã®ã¿ã‚’å«ã‚€ã‚ˆã†ã«å…¥åŠ›ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å†ç”Ÿæˆã—ã€å†ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æ³¨ç›®ã—ã¦æœ€çµ‚çš„ãªå¿œç­”ã‚’å¼•ãå‡ºã™ã€‚å®Ÿé¨“ã§ã¯ã€S2Aã¯3ã¤ã®ã‚¿ã‚¹ã‚¯ã§æ¨™æº–ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®LLMsã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã€äº‹å®Ÿæ€§ã¨å®¢è¦³æ€§ã‚’é«˜ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãŠãã‚‰ãé‡è¦è«–æ–‡</p>
<p>How is System 2 Attention different from prompt engineering specialized in factual double checks? </p>
<p>I'm very sorry for the extremely delayed response. It's been two years, so you may no longer have a chance to see this, but I'd still like to share my thoughts.<br><br>I believe that System 2 Attention is fundamentally different in concept from prompt engineering techniques such as factual double-checking. Unlike ad-hoc prompt engineering or approaches that enrich the context by adding new facts through prompting, System 2 Attention aims to improve the modelâ€™s reasoning ability itself by mitigating the influence of irrelevant tokens. It does so by selectively generating a new context composed only of relevant tokens, in a way that resembles human System 2 thinkingâ€”that is, more objective and deliberate reasoning.<br><br>From todayâ€™s perspective, two years later, I would say that this concept is more closely aligned with what we now refer to as Context Engineering. Thank you.</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2023-11-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1147" target="_blank" rel="noopener noreferrer" class="title-link">Implicit Chain of Thought Reasoning via Knowledge Distillation, Yuntian Deng+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨ã®éš ã‚ŒçŠ¶æ…‹ã‚’ä½¿ç”¨ã—ã¦æš—é»™çš„ãªæ¨è«–ã‚’è¡Œã†æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚æ˜ç¤ºçš„ãªãƒã‚§ãƒ¼ãƒ³ãƒ»ã‚ªãƒ–ãƒ»ã‚½ãƒ¼ãƒˆã®æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç”Ÿæˆã™ã‚‹ä»£ã‚ã‚Šã«ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æŠ½å‡ºã—ãŸæš—é»™çš„ãªæ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ã“ã®æ‰‹æ³•ãŒä»¥å‰ã¯è§£æ±ºã§ããªã‹ã£ãŸã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ã“ã‚Œã¯éå¸¸ã«èˆˆå‘³æ·±ã„è©±</p>
<p>openreview:


<a href="https://openreview.net/forum?id=9cumTvvlHG" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=9cumTvvlHG</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1144" target="_blank" rel="noopener noreferrer" class="title-link">Contrastive Chain-of-Thought Prompting, Yew Ken Chia+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã€å¯¾ç…§çš„ãªchain of thoughtã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã™ã‚‹ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€æœ‰åŠ¹ãªæ¨è«–ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ç„¡åŠ¹ãªæ¨è«–ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ä¸¡æ–¹ã‚’æä¾›ã—ã€ãƒ¢ãƒ‡ãƒ«ãŒæ¨è«–ã‚’é€²ã‚ã‚‹éš›ã«ãƒŸã‚¹ã‚’æ¸›ã‚‰ã™ã‚ˆã†ã«ã‚¬ã‚¤ãƒ‰ã™ã‚‹ã€‚ã¾ãŸã€è‡ªå‹•çš„ãªæ–¹æ³•ã‚’å°å…¥ã—ã¦å¯¾ç…§çš„ãªãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã—ã€æ±åŒ–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“çµæœã‹ã‚‰ã€å¯¾ç…§çš„ãªchain of thoughtãŒä¸€èˆ¬çš„ãªæ”¹å–„æ‰‹æ³•ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-11-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1138" target="_blank" rel="noopener noreferrer" class="title-link">Fine-tuning Language Models for Factuality, Katherine Tian+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ã‚ˆã‚Šäº‹å®Ÿã«åŸºã¥ã„ãŸç”Ÿæˆã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€å¤–éƒ¨ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚„ä¿¡é ¼ã‚¹ã‚³ã‚¢ã¨ã®ä¸€è²«æ€§ã‚’æ¸¬å®šã—ã€é¸å¥½æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’èª¿æ•´ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€äº‹å®Ÿã‚¨ãƒ©ãƒ¼ç‡ã®å‰Šæ¸›ãŒè¦³å¯Ÿã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<span class="issue_date">Issue Date: 2023-11-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1137" target="_blank" rel="noopener noreferrer" class="title-link">Instruction-Following Evaluation for Large Language Models, Jeffrey Zhou+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€Instruction-Following Evalï¼ˆIFEvalï¼‰ã¨ã„ã†è©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒå°å…¥ã•ã‚Œã¾ã—ãŸã€‚IFEvalã¯ã€æ¤œè¨¼å¯èƒ½ãªæŒ‡ç¤ºã«ç„¦ç‚¹ã‚’å½“ã¦ãŸç›´æ„Ÿçš„ã§å†ç¾æ€§ã®ã‚ã‚‹è©•ä¾¡æ–¹æ³•ã§ã™ã€‚å…·ä½“çš„ã«ã¯ã€25ç¨®é¡ã®æ¤œè¨¼å¯èƒ½ãªæŒ‡ç¤ºã‚’ç‰¹å®šã—ã€ãã‚Œãã‚Œã®æŒ‡ç¤ºã‚’å«ã‚€ç´„500ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚ã“ã®è©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµæœã¯ã€GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMãŒinstructionã«ã©ã‚Œã ã‘å¾“ã†ã‹ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€æ¤œè¨¼å¯èƒ½ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆ400å­—ä»¥ä¸Šã§æ›¸ããªã•ã„ãªã©ï¼‰ã‚’è€ƒæ¡ˆã—è©•ä¾¡ã™ã‚‹æ çµ„ã¿ã‚’ææ¡ˆã€‚äººé–“ãŒè©•ä¾¡ã™ã‚‹ã¨æ™‚é–“ã¨ãŠé‡‘ãŒã‹ã‹ã‚Šã€LLMã‚’åˆ©ç”¨ã—ãŸè‡ªå‹•è©•ä¾¡ã ã¨è©•ä¾¡ã‚’å®Ÿæ–½ã™ã‚‹LLMã®ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã‚‹ã®ã ã€ãã‚Œã‚‰ä¸¡æ–¹ã®limitationã‚’å…‹æœã§ãã‚‹ã¨ã®ã“ã¨ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0eb3fe10-536d-4674-aa3c-fd76f390f21d" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-11-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1135" target="_blank" rel="noopener noreferrer" class="title-link">Fast Chain-of-Thought: A Glance of Future from Parallel Decoding Leads  to Answers Faster, Hongxuan Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®ç ”ç©¶ã§ã¯ã€FastCoTã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚FastCoTã¯ã€LLMã‚’ä½¿ç”¨ã—ã¦ä¸¦åˆ—ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨è‡ªå·±å›å¸°ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’åŒæ™‚ã«è¡Œã„ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’æœ€å¤§é™ã«æ´»ç”¨ã—ã¾ã™ã€‚ã¾ãŸã€FastCoTã¯æ¨è«–æ™‚é–“ã‚’ç´„20%ç¯€ç´„ã—ã€æ€§èƒ½ã®ä½ä¸‹ãŒã»ã¨ã‚“ã©ãªã„ã“ã¨ã‚’å®Ÿé¨“ã§ç¤ºã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ç•°ãªã‚‹ã‚µã‚¤ã‚ºã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«å¯¾ã—ã¦ã‚‚é ‘å¥æ€§ã‚’ç¤ºã™ã“ã¨ãŒã§ãã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>è«–æ–‡ä¸­ã®å›³ã‚’è¦‹ãŸãŒã€å…¨ãã‚ã‹ã‚‰ãªã‹ã£ãŸãƒ»ãƒ»ãƒ»ã€‚ã¡ã‚ƒã‚“ã¨èª­ã¾ãªã„ã¨ã‚ã‹ã‚‰ãªãã†ã§ã‚ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-11-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1132" target="_blank" rel="noopener noreferrer" class="title-link">Cappy: Outperforming and Boosting Large Multi-Task LMs with a Small   Scorer, Bowen Tan+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ãƒãƒ«ãƒã‚¿ã‚¹ã‚­ãƒ³ã‚°ã«å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ãŒã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤šãè¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’å¿…è¦ã¨ã—ã€åŠ¹ç‡çš„ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ãã“ã§ã€å°è¦æ¨¡ãªã‚¹ã‚³ã‚¢ãƒ©ãƒ¼ã§ã‚ã‚‹Cappyã‚’å°å…¥ã—ã€ç‹¬ç«‹ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã‹LLMsã®è£œåŠ©ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã¾ã—ãŸã€‚Cappyã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’å¿…è¦ã¨ã›ãšã€ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã§é«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€Cappyã¯ç‹¬ç«‹ã—ãŸã‚¿ã‚¹ã‚¯ã‚„è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã§å¤§ããªLLMsã‚’ä¸Šå›ã‚Šã€ä»–ã®LLMsã¨ã®é€£æºã‚‚å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>360Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã§LLMã«å‹ã¤ã£ã½ã„ã®ã§ãŠã‚‚ã—ã‚ãã†ã ã—å®Ÿç”¨æ€§ã‚‚ã‚ã‚Šãã†</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2023-11-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1123" target="_blank" rel="noopener noreferrer" class="title-link">A Survey on Hallucination in Large Language Models: Principles,  Taxonomy, Challenges, and Open Questions, Lei Huang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®å‡ºç¾ã¯NLPã«ãŠã‘ã‚‹é‡è¦ãªé€²æ­©ã‚’ã‚‚ãŸã‚‰ã—ã¦ã„ã‚‹ãŒã€å¹»è¦šã‚’ç”Ÿã˜ã‚‹ã“ã¨ãŒã‚ã‚Šã€ãã®ä¿¡é ¼æ€§ã«æ‡¸å¿µãŒã‚ã‚‹ã€‚æœ¬èª¿æŸ»ã§ã¯ã€LLMã®å¹»è¦šã«é–¢ã™ã‚‹æœ€è¿‘ã®é€²å±•ã«ã¤ã„ã¦åŒ…æ‹¬çš„ã«æ¦‚èª¬ã—ã€å¹»è¦šã®è¦å› ã‚„æ¤œå‡ºæ‰‹æ³•ã€è»½æ¸›ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã¤ã„ã¦ç´¹ä»‹ã™ã‚‹ã€‚ã¾ãŸã€ç¾åœ¨ã®åˆ¶ç´„ã‚„å°†æ¥ã®ç ”ç©¶æ–¹å‘ã«ã¤ã„ã¦ã‚‚åˆ†æã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Hallucinationã‚’ç¾è±¡ã”ã¨ã«åˆ†é¡ã—ãŸSurveyã¨ã—ã¦ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1048" target="_blank" rel="noopener noreferrer">A Survey of Hallucination in Large Foundation Models, Vipula Rawte+, N/A, arXiv'23</a>
 ã‚‚ã‚ã‚‹</p>
<p>Surveyã®å†…å®¹ã€‚å¿…è¦ã«å¿œã˜ã¦å‚ç…§ã™ã¹ã—ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/32d8d809-e197-4289-8000-12fee76a69cf" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2023-11-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1122" target="_blank" rel="noopener noreferrer" class="title-link">LightLM: A Lightweight Deep and Narrow Language Model for Generative  Recommendation, Kai Mei+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€è»½é‡ãªTransformerãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹LightLMã‚’ææ¡ˆã—ã€ç”Ÿæˆå‹ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã—ã¦ã„ã¾ã™ã€‚LightLMã¯ã€ãƒ¢ãƒ‡ãƒ«ã®å®¹é‡ã‚’æŠ‘ãˆã¤ã¤ã‚‚ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ç²¾åº¦ã¨åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã«æˆåŠŸã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®IDã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–æ–¹æ³•ã¨ã—ã¦ã€Spectral Collaborative Indexingï¼ˆSCIï¼‰ã¨Graph Collaborative Indexingï¼ˆGCIï¼‰ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€ã‚¢ã‚¤ãƒ†ãƒ ç”Ÿæˆæ™‚ã®hallucinationã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€åˆ¶ç´„ä»˜ãç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã‚’å°å…¥ã—ã¦ã„ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€LightLMãŒç«¶åˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Generative Recommendationã¯ã‚ã¾ã‚Šçµ‚ãˆã¦ã„ãªã„ã®ã ãŒã€æ—¢å­˜ã®Generative Recommendationã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚ˆã‚Šè»½é‡ã«ã—ã€æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã€å­˜åœ¨ã—ãªã„ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç”Ÿæˆã™ã‚‹ã®ã‚’é˜²æ­¢ã™ã‚‹ã‚ˆã†ãªæ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã—ãŸã€ã¨ã„ã†è©±ã£ã½ã„ã€‚<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7a70bae0-20fd-495e-a563-5ac6ce5b6dfc" alt="image" loading="lazy"><br><br><br><br>Bayesian Personalized Ranking <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/28" target="_blank" rel="noopener noreferrer">[Paper Note] BPR: Bayesian Personalized Ranking from Implicit Feedback, Rendle+, UAI'09, 2009.06</a>
 ãƒ™ãƒ¼ã‚¹ãƒ‰ãªMatrix Factorizationã‚ˆã‚Šã¯é«˜ã„æ€§èƒ½ãŒå‡ºã¦ã‚‹ã£ã½ã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/40a39bfc-7a5b-442b-9231-1fbdbc99557a" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2023-11-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1121" target="_blank" rel="noopener noreferrer" class="title-link">Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs, Qingru Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- PASTAã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸå¼·èª¿ãƒãƒ¼ã‚¯ã®ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã‚€ã“ã¨ã‚’å¯èƒ½ã«ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚PASTAã¯ã€æ³¨æ„ã®ä¸€éƒ¨ã‚’ç‰¹å®šã—ã€å†é‡ã¿ä»˜ã‘ã‚’é©ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®æ³¨æ„ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸéƒ¨åˆ†ã«å‘ã‘ã¾ã™ã€‚å®Ÿé¨“ã§ã¯ã€PASTAãŒLLMã®æ€§èƒ½ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ¦ãƒ¼ã‚¶ãŒpromptä¸­ã§å¼·èª¿ã—ãŸã„ã—ãŸéƒ¨åˆ†ãŒã‚ˆã‚Šè€ƒæ…®ã•ã‚Œã‚‹ã‚ˆã†ã«attention weightã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šå¿œç­”æ€§èƒ½ãŒå‘ä¸Šã—ã¾ã—ãŸã¨ã„ã†è©±ã£ã½ã„ã€‚ã‹ãªã‚Šé‡è¦ãªæŠ€è¡“ã ã¨æ€ã‚ã‚Œã‚‹ã€‚å¾Œã§ã—ã£ã‹ã‚Šèª­ã‚€ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a4d3714e-7279-495c-86f1-5ff4ed2cbeb8" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-11-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1120" target="_blank" rel="noopener noreferrer" class="title-link">Do LLMs exhibit human-like response biases? A case study in survey  design, Lindia Tjuatja+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã‚’ä½¿ç”¨ã—ã¦äººé–“ã®ä»£ç†ã¨ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹éš›ã«ã€LLMsãŒäººé–“ã®å¿œç­”ãƒã‚¤ã‚¢ã‚¹ã‚’ã©ã®ç¨‹åº¦åæ˜ ã™ã‚‹ã‹ã‚’èª¿æŸ»ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€èª¿æŸ»è¨­è¨ˆã‚’ä½¿ç”¨ã—ã¦äººé–“ã®å¿œç­”ãƒã‚¤ã‚¢ã‚¹ã‚’è©•ä¾¡ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’è¨­è¨ˆã—ã€9ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ãŸçµæœã€ä¸€èˆ¬çš„ãªLLMsãŒäººé–“ã®ã‚ˆã†ãªæŒ¯ã‚‹èˆã„ã‚’åæ˜ ã™ã‚‹ã“ã¨ã«å¤±æ•—ã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã‚‰ã®çµæœã¯ã€LLMsã‚’äººé–“ã®ä»£ã‚ã‚Šã«ä½¿ç”¨ã™ã‚‹éš›ã®æ½œåœ¨çš„ãªè½ã¨ã—ç©´ã‚’å¼·èª¿ã—ã€ãƒ¢ãƒ‡ãƒ«ã®æŒ¯ã‚‹èˆã„ã®ç´°ã‹ã„ç‰¹æ€§ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã¯Promptã«sensitiveã ãŒã€äººé–“ã‚‚è³ªå•ã®ä»•æ–¹ã«ã‚ˆã£ã¦å¿œç­”ãŒå¤‰ã‚ã‚‹ã‹ã‚‰ã€sensitiveãªã®ã¯ä¸€ç·’ã§ã¯ï¼Ÿã¨ã„ã†ã“ã¨ã‚’èª¿æŸ»ã—ãŸç ”ç©¶ã€‚Neubigæ°ã®ãƒ„ã‚¤ãƒ¼ãƒˆã ã¨ã€instruction tuningã‚„RLHFã‚’ã—ã¦ã„ãªã„Base LLMã®æ–¹ãŒã€ã‚ˆã‚Šäººé–“ã¨é¡ä¼¼ã—ãŸå›ç­”ã‚’ã™ã‚‹ã®ã ãã†ã€‚<br><br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1722294711355117666?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>äººé–“ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒã‚¤ã‚¢ã‚¹ã€‚å·¦å´ã¯äººé–“ã¯ã€Œforbiddenã€ã‚ˆã‚Šã‚‚ã€Œnot allowedã€ã‚’å¥½ã‚€ã¨ã„ã†ä¾‹ã€å³å´ã¯ã€Œresponse orderã€ã®ãƒã‚¤ã‚¢ã‚¹ã®ä¾‹ï¼ˆé¸æŠè‚¢ã®é †ç•ªï¼‰ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/de129e78-5d52-41e3-a3bb-9aec20cf2b05" alt="image" loading="lazy"><br><br><br><br>LLMå´ã§è©•ä¾¡ã—ãŸã„ãƒã‚¤ã‚¢ã‚¹ã”ã¨ã«ã€QAã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å¤‰æ›´ã—ã€LLMã«å›ç­”ã‚’ç”Ÿæˆã•ã‚Œã€social science studiesã§ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã¨æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ã€LLMã«ã‚‚äººé–“ã¨åŒæ§˜ã®ãƒã‚¤ã‚¢ã‚¹ãŒã‚ã‚‹ã‹ã‚’æ˜ã‚‰ã‹ã«ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3dc39afc-4e52-49a4-bf60-22ff94bf35c6" alt="image" loading="lazy"><br><br><br><br>çµæœã¯ä»¥ä¸‹ã®è¡¨ã§ã‚ã‚Šã€é’ã„ã‚»ãƒ«ãŒäººé–“ã¨åŒæ§˜ã®ãƒã‚¤ã‚¢ã‚¹ã‚’æŒã¤ã“ã¨ã‚’çµ±è¨ˆçš„ã«æœ‰æ„ã«ç¤ºã•ã‚ŒãŸã‚‚ã®ï¼ˆã®ã¯ãšï¼‰ã€‚ã“ã‚Œã‚’ã¿ã‚‹ã¨ã€å…¨ã¦ã®ãƒã‚¤ã‚¢ã‚¹ã«å¯¾ã—ã¦äººé–“ã¨åŒæ§˜ã®å‚¾å‘ãŒã‚ã£ãŸã®ã¯Llama2-70Bã®ã¿ã§ã‚ã‚Šã€instruction tuningã‚„ã€RLHFã‚’ã‹ã‘ãŸå ´åˆï¼ˆRLHFã®æ–¹ãŒå½±éŸ¿ãŒå¤§ããã†ï¼‰äººé–“ã®ãƒã‚¤ã‚¢ã‚¹ã¨ã¯ç•°ãªã‚‹æŒ™å‹•ã‚’ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒå¤šããªã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚ã¾ãŸã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¨ãƒã‚¤ã‚¢ã‚¹ã®å¼·ã•ã«ã¯ç›¸é–¢é–¢ä¿‚ã¯è¦‹å—ã‘ã‚‰ã‚Œãªã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7d8eade0-ae3a-4d62-bb2d-160971542c39" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2023-11-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1117" target="_blank" rel="noopener noreferrer" class="title-link">Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in  Transformer Models, Steve Yadlowsky+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã®æ–‡è„ˆå­¦ç¿’ï¼ˆICLï¼‰èƒ½åŠ›ã‚’èª¿æŸ»ã—ã¾ã—ãŸã€‚ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã¯ã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²å†…ã§ç•°ãªã‚‹ã‚¿ã‚¹ã‚¯ã‚’ç‰¹å®šã—ã€å­¦ç¿’ã™ã‚‹èƒ½åŠ›ã‚’æŒã£ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²å¤–ã®ã‚¿ã‚¹ã‚¯ã‚„é–¢æ•°ã«å¯¾ã—ã¦ã¯ä¸€èˆ¬åŒ–ãŒåŠ£åŒ–ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã¾ãŸã€é«˜å®¹é‡ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ICLèƒ½åŠ›ã¯ã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²ã«å¯†æ¥ã«é–¢é€£ã—ã¦ã„ã‚‹ã“ã¨ãŒå¼·èª¿ã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>TransformerãŒpre-trainingæ™‚ã«åˆ©ç”¨ã•ã‚ŒãŸå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä»¥å¤–ã®åˆ†å¸ƒã«å¯¾ã—ã¦ã¯æ±åŒ–æ€§èƒ½ãŒè½ã¡ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã‚‰ã—ã„ã€‚ã‚‚ã—ã“ã‚ŒãŒæ­£ã—ã„ã¨ã™ã‚‹ã¨ã€çµå±€çœŸã«æ–°ã—ã„åˆ†å¸ƒã¨ã„ã†ã‹é–¢æ•°ã¨ã„ã†ã‹ã‚¿ã‚¹ã‚¯ã¨ã„ã†ã‹ã€ã‚’TransformerãŒå‰µå‡ºã™ã‚‹å¯èƒ½æ€§ã¯ä½ã„ã¨è¨€ãˆã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚ãŒã€æ–°ã—ã„ã‚‚ã®ã£ã¦å¤§ä½“ã¯æ—¢å­˜ã®æ¦‚å¿µã®çµ„ã¿åˆã‚ã›ã ã‚ˆã­ï¼ˆã‚¹ãƒãƒ›ã¨ã‹ï¼‰ã€ã¿ãŸã„ãªã“ã¨ã‚’è€ƒãˆã‚‹ã¨ã€åˆ¥ã«ãã‚Œã§ã‚‚ååˆ†ã§ã¯ï¼Ÿã¨æ€ã£ã¦ã—ã¾ã†ã€‚äººé–“ãŒæœ¬å½“ã«çœŸã®æ„å‘³ã§æ–°ã—ã„é–¢æ•°ã¨ã„ã†ã‹ã‚¿ã‚¹ã‚¯ã¨ã„ã†ã‹åˆ†å¸ƒã‚’ç”Ÿã¿å‡ºã›ã¦ã„ã‚‹ã‹ã¨ã„ã†ã¨ã€å®Ÿã¯ãã‚“ãªã«å¤šããªã„ã®ã§ã¯ï¼Ÿã¨ã„ã†äºˆæ„Ÿã‚‚ã™ã‚‹ã€‚ã¾ã‚ãŸã¨ãˆã°ã€é‡å­åŠ›å­¦ã‚’æœ€åˆã«è€ƒãˆã¾ã—ãŸï¼ã¨ã‹ãã†ã„ã†ã®ã¯ä¾‹å¤–ã ã¨æ€ã†ã‘ã©ãƒ»ãƒ»ãƒ»ã€ãã®ãƒ¬ãƒ™ãƒ«ã®ã“ã¨ã£ã¦ã©ã‚“ãã‚‰ã„ã‚ã‚‹ã‚“ã ã‚ã†ã­ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2023-11-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1116" target="_blank" rel="noopener noreferrer" class="title-link">The Perils &amp; Promises of Fact-checking with Large Language Models, Dorian Quelle+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå¾‹å‹ã®äº‹å®Ÿãƒã‚§ãƒƒã‚¯ã«ãŠã„ã¦ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ã€‚LLMsã¯çœŸå®Ÿã¨è™šå½ã‚’è¦‹åˆ†ã‘ã‚‹å½¹å‰²ã‚’æœãŸã—ã€ãã®å‡ºåŠ›ã‚’æ¤œè¨¼ã™ã‚‹èƒ½åŠ›ãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦äº‹å®Ÿãƒã‚§ãƒƒã‚¯ã‚’è¡Œã„ã€æ¨è«–ã‚’èª¬æ˜ã—ã€é–¢é€£ã™ã‚‹æƒ…å ±æºã‚’å¼•ç”¨ã™ã‚‹èƒ½åŠ›ã‚’è©•ä¾¡ã—ãŸã€‚çµæœã¯ã€æ–‡è„ˆæƒ…å ±ã‚’å‚™ãˆãŸLLMsã®èƒ½åŠ›ã®å‘ä¸Šã‚’ç¤ºã—ã¦ã„ã‚‹ãŒã€æ­£ç¢ºæ€§ã«ã¯ä¸€è²«æ€§ãŒãªã„ã“ã¨ã«æ³¨æ„ãŒå¿…è¦ã§ã‚ã‚‹ã€‚ä»Šå¾Œã®ç ”ç©¶ã§ã¯ã€æˆåŠŸã¨å¤±æ•—ã®è¦å› ã‚’ã‚ˆã‚Šæ·±ãç†è§£ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>gpt3ã¨gpt4ã§FactCheckã—ã¦å‚¾å‘ã‚’åˆ†æã—ã¾ã—ãŸã€ã¨ã„ã†ç ”ç©¶ã€‚promptã«statementã¨googleã§è£œå®Œã—ãŸcontextã‚’å«ã‚ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§FactCheckã™ã‚‹ã€‚<br>promptingã™ã‚‹éš›ã®è¨€èªã‚„ã€statementã®äº‹å®Ÿæ€§ã®åº¦åˆã„ï¼ˆåŠåˆ†true, å…¨ã¦falseç­‰ï¼‰ãªã©ã§ã€æ€§èƒ½ãŒå¤§ããå¤‰ã‚ã‚‹çµæœã¨ã®ã“ã¨ã€‚<br>æ€§èƒ½ã‚’è¦‹ã‚‹ã¨ã€ã¾ã ã¾ã ï¼ˆã“ã®promptingæ–¹æ³•ã§ã¯ï¼‰äººé–“ã®ä»£ã‚ã‚ŠãŒå‹™ã¾ã‚‹ã»ã©ã®æ€§èƒ½ãŒå‡ºã¦ã„ãªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚ã¾ãŸã€trueãªæƒ…å ±ã®FactCheckã«contextã¯åŠ¹ã„ã¦ã„ãã†ã ãŒã€falseã®æƒ…å ±ã®FactCheckã«ContextãŒã‚ã¾ã‚ŠåŠ¹ã„ã¦ãªã•ãã†ã«è¦‹ãˆã‚‹ã®ã§ã€ãªã‚“ã ã‹ãªã‚ã€ã¨ã„ã†æ„Ÿã˜ã§ã‚ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1f310edd-58f3-4e45-ac40-e75337bff884" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e6901a32-af7a-472c-9790-d3784fa577ce" alt="image" loading="lazy"></p>
<p>æ–œã‚èª­ã¿ã—ã‹ã—ã¦ã„ãªã„ãŒã“ã®ç ”ç©¶ã€å­¦è¡“çš„ãªçŸ¥è¦‹ã¯å°‘ãªã„ã®ã‹ãªã€ã¨ã„ã†å°è±¡ã€‚ä¸€ã¤ã®ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã ã‚ˆã­ã€ã¨ã„ã†æ„Ÿã˜ãŒã™ã‚‹ã€‚<br><br>ã¾ãšã€GPT3,4ã ã‘ã˜ã‚ƒãªãã€ç‰¹å¾´ã®ç•°ãªã‚‹OpenSourceã®LLMã‚’æ¯”è¼ƒã«å«ã‚ã¦ãã‚Œãªã„ã¨ã€å‰è€…ã¯ä½•ã§å­¦ç¿’ã—ã¦ã„ã‚‹ã‹åˆ†ã‹ã‚‰ãªã„ã®ã§ã€å­¦è¡“çš„ã«å¾—ã‚‰ã‚Œã‚‹çŸ¥è¦‹ã¯ã»ã¼ãªã„ã®ã§ã¯ã¨ã„ã†æ°—ãŒã€‚å®Ÿå‹™çš„ã«ã¯å½¹ã«ç«‹ã¤ãŒã€‚<br><br>ãã®ä¸Šã§ã€Promptingã‚’ã‚‚ã£ã¨ã•ã¾ã–ã¾ãªæ–¹æ³•ã§æ¤œè¨¼ã—ãŸæ–¹ãŒè‰¯ã„ã¨æ€ã†ã€‚<br>ãŸã¨ãˆã°ã€ç¾åœ¨ã®promptã§ã¯ãƒ©ãƒ™ãƒ«ã‚’å…ˆã«å‡ºåŠ›ã•ã›ãŸå¾Œã«ç†ç”±ã‚’è¿°ã¹ã•ã›ã¦ã„ã‚‹ãŒã€ãã‚Œã‚’é€†ã«ã—ãŸã‚‰ã©ã†ãªã‚‹ã‹ï¼Ÿï¼ˆzero-shot CoTï¼‰ã‚„ã€4-Shotã«ã—ãŸã‚‰ã©ã†ãªã‚‹ã‹ã€SelfConsistencyã‚’åˆ©ç”¨ã—ãŸã‚‰ã©ã†ãªã‚‹ã‹ãªã©ã€promptingã®ä»•æ–¹ã«ã‚ˆã£ã¦å‚¾å‘ãŒå¤§ããå¤‰ã‚ã‚‹ã¨æ€ã†ã€‚<br><br>åŠ ãˆã¦ã€Retrieveréƒ¨åˆ†ã‚‚ã„ãã¤ã‹ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã§è©¦ã—ã¦ã¿ã¦ã‚‚è‰¯ã„ã®ã‹ãªã¨æ€ã†ã€‚ç‰¹ã«ã€falseã®æƒ…å ±ã‚’åˆ¤æ–­ã™ã‚‹éš›ã«å½¹ã«ç«‹ã¤æƒ…å ±ãŒcontextã«å«ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã®ã‹ãŒæ°—ã«ãªã‚‹ã€‚<br>è«–æ–‡ã«æ›¸ã„ã¦ã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãŒã€ã¡ã‚‡ã£ã¨ã—ã£ã‹ã‚Šèª­ã‚€æ™‚é–“ã¯ãªã„ã§ã™ï¼ï¼</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1104" target="_blank" rel="noopener noreferrer" class="title-link">Llemma: An Open Language Model For Mathematics, Zhangir Azerbayev+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€æ•°å­¦ã®ãŸã‚ã®å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹Llemmaã‚’ææ¡ˆã—ã¾ã™ã€‚Llemmaã¯ã€Proof-Pile-2ã¨å‘¼ã°ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦äº‹å‰å­¦ç¿’ã•ã‚Œã€MATHãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€Llemmaã¯è¿½åŠ ã®fine-tuningãªã—ã§ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚„å½¢å¼çš„ãªå®šç†è¨¼æ˜ãŒå¯èƒ½ã§ã™ã€‚ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚‚å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>CodeLLaMAã‚’200B tokenã®æ•°å­¦ãƒ†ã‚­ã‚¹ãƒˆï¼ˆproof-pile-2ãƒ‡ãƒ¼ã‚¿;è«–æ–‡ã€æ•°å­¦ã‚’å«ã‚€ã‚¦ã‚§ãƒ–ãƒ†ã‚­ã‚¹ãƒˆã€æ•°å­¦ã®ã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ï¼‰ã§ç¶™ç¶šçš„ã«äº‹å‰å­¦ç¿’ã™ã‚‹ã“ã¨ã§foundation modelã‚’æ§‹ç¯‰<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/87f9bbe1-3377-4e80-a7d4-904345ebb7d9" alt="image" loading="lazy"><br><br>ç´„åŠåˆ†ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§æ•°å­¦ã«é–¢ã™ã‚‹æ€§èƒ½ã§Googleã®Minervaã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆ<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5d209059-2275-415a-8b8d-f73f46712ba6" alt="image" loading="lazy"></p>
<p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhangir_azerbay/status/1714098823080063181"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã¾ã 4-shotã—ã¦ã‚‚Acc.50%ãã‚‰ã„ãªã®ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1102" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models are not Fair Evaluators, Peiyi Wang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€å€™è£œãƒ¢ãƒ‡ãƒ«ã®å¿œç­”å“è³ªã‚’è©•ä¾¡ã™ã‚‹è©•ä¾¡ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã«ãŠã‘ã‚‹ç³»çµ±çš„ãªãƒã‚¤ã‚¢ã‚¹ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€ãƒã‚¤ã‚¢ã‚¹ã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€å®Ÿé¨“ã«ã‚ˆã£ã¦ãã®æœ‰åŠ¹æ€§ã‚’ç¤ºã—ã¾ã™ã€‚ã¾ãŸã€ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã—ã¦ã€ä»Šå¾Œã®ç ”ç©¶ã‚’æ”¯æ´ã—ã¾ã™ã€‚</span>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/DataGeneration.html" target="_blank" rel="noopener noreferrer">#DataGeneration</a>
<span class="issue_date">Issue Date: 2023-10-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1099" target="_blank" rel="noopener noreferrer" class="title-link">Zephyr: Direct Distillation of LM Alignment, Lewis Tunstall+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€å°ã•ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ãŸã‚ã«ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å„ªå…ˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã«ã‚ˆã‚Šã€è‡ªç„¶ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®å¿œç­”ãŒæ”¹å–„ã•ã‚Œã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã‚’ç”¨ã„ã¦å­¦ç¿’ã•ã‚ŒãŸZephyr-7Bãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒãƒ£ãƒƒãƒˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ç™ºæ®ã—ã€äººé–“ã®æ³¨é‡ˆã‚’å¿…è¦ã¨ã—ã¾ã›ã‚“ã€‚è©³ç´°ã¯GitHubã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>7Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§LlaMa70Bã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã—ãŸZephyrã®è«–æ–‡ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1348b3c1-f70a-49b6-97c9-4a27bf7805fa" alt="image" loading="lazy"><br><br>- dSFT:æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰promptã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€user,assistantã®multi turnã®å¯¾è©±ã‚’LLMã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã—SFT<br>- AIF:æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰promstã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ç•°ãªã‚‹4ã¤ã®LLMã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’GPT4ã§ãƒ©ãƒ³ã‚¯ã¥ã‘ã—ãŸãƒ‡ãƒ¼ã‚¿ã®æ´»ç”¨<br>- dDPO: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰promptã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ãƒ™ã‚¹ãƒˆãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æ´»ç”¨<br><br>äººæ‰‹ã‚’ä¸€åˆ‡ä»‹ã—ã¦ã„ãªã„ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/f2cd7b48-4036-49eb-bfb7-0ce3cc8a09b8" alt="image" loading="lazy"></p>
<p>Blog: 


<a href="https://huggingface.co/blog/Isamu136/understanding-zephyr" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/Isamu136/understanding-zephyr</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-10-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1098" target="_blank" rel="noopener noreferrer" class="title-link">Human Feedback is not Gold Standard, Tom Hosking+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½è©•ä¾¡ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãŒã€ãã®å¥½ã¿ã®ã‚¹ã‚³ã‚¢ãŒã©ã®ç‰¹æ€§ã‚’æ‰ãˆã¦ã„ã‚‹ã®ã‹ã¯æ˜ç¢ºã§ã¯ãªã„ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ä½¿ç”¨ã‚’åˆ†æã—ã€é‡è¦ãªã‚¨ãƒ©ãƒ¼åŸºæº–ã‚’é©åˆ‡ã«æ‰ãˆã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’æ¤œè¨¼ã—ãŸã€‚çµæœã¨ã—ã¦ã€å¥½ã¿ã®ã‚¹ã‚³ã‚¢ã¯åºƒç¯„ãªã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’æŒã£ã¦ã„ã‚‹ãŒã€äº‹å®Ÿæ€§ãªã©ã®é‡è¦ãªå´é¢ãŒéå°è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã¾ãŸã€å¥½ã¿ã®ã‚¹ã‚³ã‚¢ã¨ã‚¨ãƒ©ãƒ¼ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯äº¤çµ¡å› å­ã®å½±éŸ¿ã‚’å—ã‘ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã€å‡ºåŠ›ã®æ–­å®šæ€§ãŒäº‹å®Ÿæ€§ã‚¨ãƒ©ãƒ¼ã®çŸ¥è¦šç‡ã‚’æ­ªã‚ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚ã•ã‚‰ã«ã€äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨“ç·´ç›®æ¨™ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã€ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã®æ–­å®šæ€§ã‚’éåº¦ã«å¢—åŠ ã•ã›ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚ä»Šå¾Œã®ç ”ç©¶ã§ã¯ã€å¥½ã¿ã®ã‚¹ã‚³ã‚¢ãŒæœ›ã¾ã—ã„ç›®æ¨™ã¨ä¸€è‡´ã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’æ…é‡ã«è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/icoxfog417/status/1718151338520199180?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3824b322-53fa-4360-a7d4-1b0f3bff3302" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OCR.html" target="_blank" rel="noopener noreferrer">#OCR</a>
<span class="issue_date">Issue Date: 2023-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1093" target="_blank" rel="noopener noreferrer" class="title-link">Exploring OCR Capabilities of GPT-4Vï¼ˆisionï¼‰ : A Quantitative and  In-depth Evaluation, Yongxin Shi+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€GPT-4Vã¨ã„ã†å¤§è¦æ¨¡ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®å…‰å­¦æ–‡å­—èªè­˜ï¼ˆOCRï¼‰èƒ½åŠ›ã‚’è©•ä¾¡ã—ã¾ã™ã€‚ã•ã¾ã–ã¾ãªOCRã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã—ã€ãƒ©ãƒ†ãƒ³æ–‡å­—ã®èªè­˜ã¨ç†è§£ã«ãŠã„ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ä¸€æ–¹ã€å¤šè¨€èªã‚„è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«ã¯è‹¦æˆ¦ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ã“ã‚Œã«åŸºã¥ã„ã¦ã€å°‚é–€ã®OCRãƒ¢ãƒ‡ãƒ«ã®å¿…è¦æ€§ã‚„GPT-4Vã‚’æ´»ç”¨ã™ã‚‹æˆ¦ç•¥ã«ã¤ã„ã¦ã‚‚æ¤œè¨ã—ã¾ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€å°†æ¥ã®LMMã‚’ç”¨ã„ãŸOCRã®ç ”ç©¶ã«å½¹ç«‹ã¤ã‚‚ã®ã§ã™ã€‚è©•ä¾¡ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨çµæœã¯ã€GitHubã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>GPT4-Vã‚’ã•ã¾ã–ã¾ãªOCRã‚¿ã‚¹ã‚¯ã€Œæ‰‹æ›¸ãã€æ•°å¼ã€ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ èªè­˜ç­‰ã‚’å«ã‚€ï¼‰ã§æ€§èƒ½æ¤œè¨¼ã—ãŸç ”ç©¶ã€‚<br>MLT19ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ãŸè©•ä¾¡ã§ã¯ã€æ—¥æœ¬èªã®æ€§èƒ½ã¯éå¸¸ã«ä½ãã€è‹±èªã¨ãƒ•ãƒ©ãƒ³ã‚¹èªãŒæ€§èƒ½é«˜ã„ã€‚æ‰‹æ›¸ãæ–‡å­—èªè­˜ã§ã¯è‹±èªã¨ä¸­å›½èªã§ã®ã¿è©•ä¾¡ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c433b921-c527-441f-8925-00f4ac5fc6c3" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/InstructionGeneration.html" target="_blank" rel="noopener noreferrer">#InstructionGeneration</a>
<span class="issue_date">Issue Date: 2023-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1092" target="_blank" rel="noopener noreferrer" class="title-link">Auto-Instruct: Automatic Instruction Generation and Ranking for  Black-Box Language Models, Zhihan Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æ–°ã—ã„æ‰‹æ³•ã§ã‚ã‚‹Auto-Instructã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã§ã¯ã€LLMsãŒç”Ÿæˆã™ã‚‹æŒ‡ç¤ºã®å“è³ªã‚’è‡ªå‹•çš„ã«å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€å¤šæ§˜ãªå€™è£œã®æŒ‡ç¤ºã‚’ç”Ÿæˆã—ã€ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã§ãƒ©ãƒ³ã‚¯ä»˜ã‘ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€Auto-InstructãŒäººé–“ã«ã‚ˆã‚‹æŒ‡ç¤ºã‚„æ—¢å­˜ã®LLMç”ŸæˆæŒ‡ç¤ºã‚’ä¸Šå›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€ä»–ã®LLMsã§ã‚‚é¡•è‘—ãªæ±åŒ–æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ã‚‚ç¢ºèªã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>seed instructionã¨demonstrationã«åŸºã¥ã„ã¦ã€ç•°ãªã‚‹ã‚¹ã‚¿ã‚¤ãƒ«ã®instructionã‚’è‡ªå‹•ç”Ÿæˆã—ã€è‡ªå‹•ç”Ÿæˆã—ãŸinstructionã‚’ã¨inferenceã—ãŸã„exampleã§æ¡ä»¶ã¥ã‘ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã—ã€è‰¯è³ªãªã‚‚ã®ã‚’é¸æŠã€‚é¸æŠã—ãŸinstructionã§inferenceã‚’å®Ÿæ–½ã™ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3b318cac-516d-4fc8-9097-ad695ab8223b" alt="image" loading="lazy"></p>
<p>æ—¢å­˜æ‰‹æ³•ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’é”æˆã—ã¦ã„ã‚‹ã€‚ç‰¹ã«exampleã”ã¨ã«instructionã‚’é¸æŠã™ã‚‹æ‰‹æ³•ã®ä¸­ã§æœ€ã‚‚gainãŒé«˜ã„ã€‚ã“ã‚Œã¯ã€ææ¡ˆæ‰‹æ³•ãŒinstructionã®é¸æŠã«trained modelã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã§ã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8e2c8bad-54ec-49e8-b6e0-29bc18425e99" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2023-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1091" target="_blank" rel="noopener noreferrer" class="title-link">NEFTune: Noisy Embeddings Improve Instruction Finetuning, Neel Jain+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã€ãƒã‚¤ã‚ºã‚’åŠ ãˆãŸåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½¿ç”¨ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ã€AlpacaEvalã‚„Evol-Instructãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€RLHFã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«ã‚‚é©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Alpacaãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½å‘ä¸ŠãŒè‘—ã—ã„ã€‚ã‹ãªã‚Šé‡è¦è«–æ–‡ãªäºˆæ„Ÿã€‚å¾Œã§èª­ã‚€ã€‚</p>
<p>HuggingFaceã®TRLã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹<br><br>


<a href="https://huggingface.co/docs/trl/sft_trainer" target="_blank" rel="noopener noreferrer">https://huggingface.co/docs/trl/sft_trainer</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2023-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1090" target="_blank" rel="noopener noreferrer" class="title-link">In-Context Learning Creates Task Vectors, Roee Hendel+, N_A, EMNLP'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã‘ã‚‹ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã®åŸºæœ¬çš„ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯ã¾ã ååˆ†ã«ç†è§£ã•ã‚Œã¦ã„ãªã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ICLã«ã‚ˆã£ã¦å­¦ç¿’ã•ã‚Œã‚‹é–¢æ•°ãŒéå¸¸ã«å˜ç´”ãªæ§‹é€ ã‚’æŒã¤ã“ã¨ã‚’ç¤ºã—ã€ICLãŒãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼LLMã‚’ä½¿ç”¨ã—ã¦å˜ä¸€ã®ã‚¿ã‚¹ã‚¯ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã€ãã‚Œã‚’ä½¿ç”¨ã—ã¦å‡ºåŠ›ã‚’ç”Ÿæˆã™ã‚‹ã¨ã„ã†ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚ã•ã¾ã–ã¾ãªãƒ¢ãƒ‡ãƒ«ã¨ã‚¿ã‚¹ã‚¯ã«ã‚ãŸã‚‹å®Ÿé¨“ã«ã‚ˆã£ã¦ã€ã“ã®ä¸»å¼µã‚’æ”¯æŒã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1717302086587875395?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ICLãŒå®Ÿç¾å¯èƒ½ãªã®ã¯å®Ÿã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å†…éƒ¨ã§ä¸ãˆã‚‰ã‚ŒãŸdemonstrationã«å¯¾ã—ã¦å‹¾é…åŠ¹æœæ³•ã‚’å†ç¾ã—ã¦ã„ã‚‹ã‹ã‚‰ã§ã™ã€ã¨ã„ã†ç ”ç©¶ã‚‚ã‚ã£ãŸã¨æ€ã†ã‘ã©ã€ã“ã®ã‚¿ã‚¹ã‚¯ãƒ™ã‚¯ãƒˆãƒ«ã¨ã®é–¢ä¿‚æ€§ã¯ã©ã†ã„ã†ã‚‚ã®ãªã®ã ã‚ã†ã‹ã€‚</p>
<p>æ–‡è„ˆã«æ³¨æ„ã‚’ä¸ãˆãªãã¦ã‚‚ICLã¨åŒã˜æ€§èƒ½ãŒå‡ºã‚‹ã®ã¯ã€æ–‡è„ˆæƒ…å ±ãŒä¸è¦ãªã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã‹ã‚‰ã§ã‚ã‚Šã€ãã†ã§ã¯ãªã„ã‚¿ã‚¹ã‚¯ã ã¨ã“ã®çŸ¥è¦‹ãŒå´©ã‚Œã‚‹ã®ã ã‚ã†ã‹ã€‚å¾Œã§èª­ã‚€ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-10-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1088" target="_blank" rel="noopener noreferrer" class="title-link">Branch-Solve-Merge Improves Large Language Model Evaluation and  Generation, Swarnadeep Saha+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤šé¢çš„ãªè¨€èªç”ŸæˆãŠã‚ˆã³è©•ä¾¡ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ­ã‚°ãƒ©ãƒ ï¼ˆBSMï¼‰ã‚’ææ¡ˆã—ã¾ã™ã€‚BSMã¯ã€ãƒ–ãƒ©ãƒ³ãƒã€ã‚½ãƒ«ãƒ–ã€ãƒãƒ¼ã‚¸ã®3ã¤ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰æ§‹æˆã•ã‚Œã€ã‚¿ã‚¹ã‚¯ã‚’è¤‡æ•°ã®ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«åˆ†è§£ã—ã€ç‹¬ç«‹ã—ã¦è§£æ±ºã—ã€è§£æ±ºç­–ã‚’çµ±åˆã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€BSMãŒè©•ä¾¡ã®æ­£ç¢ºæ€§ã¨ä¸€è²«æ€§ã‚’å‘ä¸Šã•ã›ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2023-10-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1086" target="_blank" rel="noopener noreferrer" class="title-link">Personalized Soups: Personalized Large Language Model Alignment via  Post-hoc Parameter Merging, Joel Jang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Reinforcement Learning from Human Feedback (RLHF) is not optimal for learning diverse individual perspectives, as it aligns general aggregated human preferences with large language models (LLMs). This study investigates the problem of Reinforcement Learning from Individual Human Feedback (RLPHF) and models the alignment with LLMs to multiple (sometimes conflicting) preferences as a Multi-Objective Reinforcement Learning (MORL) problem. It demonstrates that individual alignment can be achieved by decomposing preferences into multiple dimensions based on personalized declarations. The study shows that these dimensions can be efficiently trained independently and distributed, and effectively combined in post-processing through parameter merging. The code is available at https://github.com/joeljang/RLPHF.</span>
<span class="snippet"><span>Comment</span><p>ã©ã“ã¾ã§ã®ã“ã¨ãŒå®Ÿç¾ã§ãã‚‹ã®ã‹ãŒæ°—ã«ãªã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-10-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1085" target="_blank" rel="noopener noreferrer" class="title-link">Eliminating Reasoning via Inferring with Planning: A New Framework to  Guide LLMs' Non-linear Thinking, Yongqi Tong+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«éç·šå½¢ã®æ€è€ƒã‚’ä¿ƒã™ãŸã‚ã«ã€æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æ–¹æ³•ã§ã‚ã‚‹Inferential Exclusion Promptingï¼ˆIEPï¼‰ã‚’ææ¡ˆã™ã‚‹ã€‚IEPã¯ã€è¨ˆç”»ã‚’ç«‹ã¦ã¦å¯èƒ½ãªè§£ã‚’æ¨è«–ã—ã€é€†æ¨è«–ã‚’è¡Œã†ã“ã¨ã§åºƒã„è¦–ç‚¹ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚IEPã¯ä»–ã®æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦è¤‡é›‘ãªäººé–“ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã§ãã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã—ã€LLMsã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã«ã‚‚è²¢çŒ®ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã•ã‚‰ã«ã€Mental-Ability Reasoning Benchmarkï¼ˆMARBï¼‰ã‚’å°å…¥ã—ã€LLMsã®è«–ç†ã¨è¨€èªæ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ãŸã€‚IEPã¨MARBã¯LLMsã®ç ”ç©¶ã«ãŠã„ã¦æœ‰æœ›ãªæ–¹å‘æ€§ã§ã‚ã‚Šã€ä»Šå¾Œã®é€²å±•ãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒè«–æ–‡ã¯èª­ã‚“ã§ã„ãªã„ã®ã ãŒã€CoTãŒç·šå½¢çš„ã ã¨ã„ã†ä¸»å¼µãŒã‚ˆãã‚ã‹ã‚‰ãªã„ã€‚<br>CoTã¯Autoregressiveãªè¨€èªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªå·±ç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã§åˆ©ç”¨è€…ã®æ„å›³ã—ãŸæ–¹å‘æ€§ã«ãƒã‚¤ã‚¢ã‚¹ã‚’ã‹ã‘ã¦è£œå®Œã•ã›ã€<br>åˆ©ç”¨è€…ãŒæ„å›³ã—ãŸé€šã‚Šã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’æœ€çµ‚çš„ã«å¾—ã‚‹ãŸã‚ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã€ã ã¨æ€ã£ã¦ã„ã¦ã€<br>ç·šå½¢çš„ã ã‚ã†ãŒéç·šå½¢çš„ã ã‚ã†ãŒã©ã£ã¡ã«ã—ã‚CoTãªã®ã§ã¯ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-10-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1078" target="_blank" rel="noopener noreferrer" class="title-link">Meta-CoT: Generalizable Chain-of-Thought Prompting in Mixed-task  Scenarios with Large Language Models, Anni Zou+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€æ¨è«–ã®ãŸã‚ã®ãƒã‚§ãƒ¼ãƒ³ãƒ»ã‚ªãƒ–ãƒ»ã‚½ãƒ¼ãƒˆï¼ˆCoTï¼‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚å¾“æ¥ã®CoTã®æ–¹æ³•ã§ã¯ã€ä¸€èˆ¬çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„æ‰‹ä½œæ¥­ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ä¾å­˜ã—ã¦ã„ã¾ã—ãŸãŒã€æœ¬ç ”ç©¶ã§ã¯å…¥åŠ›è³ªå•ã®ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦è‡ªå‹•çš„ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹Meta-CoTã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚Meta-CoTã¯ã€10ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¨è«–ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€SVAMPã§ã¯æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã¾ã—ãŸã€‚ã¾ãŸã€åˆ†å¸ƒå¤–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚å®‰å®šæ€§ã¨æ±ç”¨æ€§ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>è‰²ã€…å‡ºã¦ããŸãŒãªã‚“ã‹ã‚‚ã†è‰²ã€…çµ„ã¿åˆã‚ã›ã‚Œã°æœ€å¼·ãªã‚“ã˜ã‚ƒã­?ã£ã¦æ°—ãŒã—ã¦ããŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/bb51c119-c1bc-4033-a7d4-f403d3c82d30" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1c450a01-5cd6-4af3-af76-323e8c8d3769" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-10-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1077" target="_blank" rel="noopener noreferrer" class="title-link">Survey on Factuality in Large Language Models: Knowledge, Retrieval and  Domain-Specificity, Cunxiang Wang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®äº‹å®Ÿæ€§ã®å•é¡Œã«å–ã‚Šçµ„ã‚“ã§ã„ã¾ã™ã€‚LLMsã®å‡ºåŠ›ã®ä¿¡é ¼æ€§ã¨æ­£ç¢ºæ€§ã¯é‡è¦ã§ã‚ã‚Šã€äº‹å®Ÿã«çŸ›ç›¾ã—ãŸæƒ…å ±ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€ãã®å•é¡Œã‚’è§£æ±ºã™ã‚‹æ–¹æ³•ã‚’æ¢æ±‚ã—ã¦ã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€LLMsã®äº‹å®Ÿçš„ãªã‚¨ãƒ©ãƒ¼ã®å½±éŸ¿ã‚„åŸå› ã‚’åˆ†æã—ã€äº‹å®Ÿæ€§ã‚’è©•ä¾¡ã™ã‚‹æ‰‹æ³•ã‚„æ”¹å–„ç­–ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ã®LLMsã¨å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã™ã‚‹æ¤œç´¢æ‹¡å¼µå‹LLMsã«ç„¦ç‚¹ã‚’å½“ã¦ã€ãã‚Œãã‚Œã®èª²é¡Œã¨æ”¹å–„ç­–ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ã„ã¾ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€LLMsã®äº‹å®Ÿçš„ãªä¿¡é ¼æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®ã‚¬ã‚¤ãƒ‰ã¨ãªã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4d3ab4df-aaa0-460f-b16a-6114432336cd" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-10-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1076" target="_blank" rel="noopener noreferrer" class="title-link">Take a Step Back: Evoking Reasoning via Abstraction in Large Language  Models, Huaixiu Steven Zheng+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Step-Back Promptingã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦æ¨è«–ã®æ‰‹é †ã‚’ã‚¬ã‚¤ãƒ‰ã™ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æŠ€è¡“ã§ã™ã€‚ã“ã®æŠ€è¡“ã«ã‚ˆã‚Šã€LLMsã¯å…·ä½“çš„ãªè©³ç´°ã‹ã‚‰é«˜ãƒ¬ãƒ™ãƒ«ã®æ¦‚å¿µã‚„åŸºæœ¬åŸå‰‡ã‚’æŠ½è±¡åŒ–ã—ã€æ­£ã—ã„æ¨è«–çµŒè·¯ã‚’ãŸã©ã‚‹èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€Step-Back Promptingã¯STEMã€Knowledge QAã€Multi-Hop Reasoningãªã©ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦å¤§å¹…ãªæ€§èƒ½å‘ä¸ŠãŒè¦³å¯Ÿã•ã‚Œã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€MMLU Physics and Chemistryã§7%ã€11%ã€TimeQAã§27%ã€MuSiQueã§7%ã®æ€§èƒ½å‘ä¸ŠãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ã¾ãŸæ–°ã—ã„ã®ãŒå‡ºãŸ</p>
<p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/aac94123-7c39-4938-889f-feb5cff9317c" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a793ff97-3d5c-4707-9ec6-3884b143182b" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2023-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1074" target="_blank" rel="noopener noreferrer" class="title-link">RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective  Augmentation, Fangyuan Xu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚æŠ½å‡ºå‹ã®åœ§ç¸®å™¨ã¨æŠ½è±¡å‹ã®åœ§ç¸®å™¨ã‚’ä½¿ç”¨ã—ã€LMsã®å…¥åŠ›ã«è¦ç´„ã‚’è¿½åŠ ã—ã¦è¨“ç·´ã™ã‚‹ã€‚å®Ÿé¨“çµæœã§ã¯ã€åœ§ç¸®ç‡ãŒ6ï¼…ã¾ã§é”æˆã•ã‚Œã€å¸‚è²©ã®è¦ç´„ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€è¨“ç·´ã•ã‚ŒãŸåœ§ç¸®å™¨ã¯ä»–ã®LMsã«ã‚‚è»¢ç§»å¯èƒ½ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Retrieval Augmentationã‚’ã™ã‚‹éš›ã«ã€å…ƒæ–‡æ›¸ç¾¤ã‚’è¦ç´„ã—ã¦åœ§ç¸®ã™ã‚‹ã“ã¨ã§ã€æ€§èƒ½ä½ä¸‹ã‚’æŠ‘ãˆãªãŒã‚‰æœ€å¤§6%ç¨‹åº¦ã¾ã§å…ƒæ–‡æ›¸ç¾¤ã‚’åœ§ç¸®ã§ããŸã€ã¨ã®ã“ã¨ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2756ba98-d228-45e6-972d-ef239d4b990e" alt="image" loading="lazy"></p>
<p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1711384213092479130?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Retrieval Augmentationã‚’å°å…¥ã™ã‚‹éš›ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ã«æœ‰ç”¨ãã†</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1070" target="_blank" rel="noopener noreferrer" class="title-link">Retrieval meets Long Context Large Language Models, Peng Xu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ€å…ˆç«¯ã®äº‹å‰å­¦ç¿’æ¸ˆã¿LLMsã‚’ä½¿ç”¨ã—ã¦ã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ«æ‹¡å¼µã¨é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®çµ„ã¿åˆã‚ã›ã«ã¤ã„ã¦ç ”ç©¶ã—ã¾ã—ãŸã€‚çµæœã¨ã—ã¦ã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ«æ‹¡å¼µLLMsã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°LLMsã¨æ¯”è¼ƒã—ã¦ã‚‚é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€è¨ˆç®—é‡ã‚‚å°‘ãªã„ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ã¯LLMsã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ãƒªãƒˆãƒªãƒ¼ãƒãƒ«æ‹¡å¼µLLMsã¯ã€è³ªå•å¿œç­”ã‚„è¦ç´„ãªã©ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã€ç”Ÿæˆé€Ÿåº¦ã‚‚é€Ÿã„ã§ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€å®Ÿè·µè€…ã«ã¨ã£ã¦ãƒªãƒˆãƒªãƒ¼ãƒãƒ«æ‹¡å¼µã¨é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®LLMsã®é¸æŠã«é–¢ã™ã‚‹æ´å¯Ÿã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1711502993508671670?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ¤œç´¢è£œå¼·ï¼ˆRetrieval Augmentationï¼‰ã¨ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã‚’è£œå®Œã™ã‚‹ãŸã‚ã«ã€é–¢é€£ã™ã‚‹æ–‡æ›¸ã‚’å¤–éƒ¨ã®æ–‡æ›¸é›†åˆã‹ã‚‰ã¨ã£ã¦ãã¦ã€contextã«å«ã‚ã‚‹æŠ€è¡“ã®ã“ã¨<br><br>


<a href="https://tech.acesinc.co.jp/entry/2023/03/31/121001" target="_blank" rel="noopener noreferrer">https://tech.acesinc.co.jp/entry/2023/03/31/121001</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1069" target="_blank" rel="noopener noreferrer" class="title-link">RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities  of Large Language Models, Zekun Moore Wang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦å½¹å‰²æ¼”æŠ€ã®èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹RoleLLMã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚RoleLLMã¯ã€å½¹å‰²ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹ç¯‰ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®æŒ‡ç¤ºç”Ÿæˆã€å½¹å‰²ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã‚‹è©±ã—æ–¹ã®æ¨¡å€£ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã¨å½¹å‰²ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã®4ã¤ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€RoleBenchã¨å‘¼ã°ã‚Œã‚‹å½¹å‰²æ¼”æŠ€ã®ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€RoleLLaMAã¨RoleGLMã¨ã„ã†ãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å½¹å‰²æ¼”æŠ€ã®èƒ½åŠ›ãŒå¤§å¹…ã«å‘ä¸Šã—ã€GPT-4ã¨åŒç­‰ã®çµæœã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p># Overview<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4a4f8ad3-17d1-4a85-b553-6452371e2ccf" alt="image" loading="lazy"><br><br># RoleBench<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a197648f-ee30-4e1d-9b3b-188c29671df4" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/AutoML.html" target="_blank" rel="noopener noreferrer">#AutoML</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1067" target="_blank" rel="noopener noreferrer" class="title-link">Benchmarking Large Language Models As AI Research Agents, Qian Huang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€AIç ”ç©¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã—ã€ç§‘å­¦çš„ãªå®Ÿé¨“ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦MLAgentBenchã‚’ææ¡ˆã™ã‚‹ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿æ›¸ãã‚„ã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡Œãªã©ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã€å®Ÿé¨“ã‚’å®Ÿè¡Œã—ã€çµæœã‚’åˆ†æã—ã€æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚³ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚GPT-4ãƒ™ãƒ¼ã‚¹ã®ç ”ç©¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯å¤šãã®ã‚¿ã‚¹ã‚¯ã§é«˜æ€§èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿç¾ã§ãã‚‹ãŒã€æˆåŠŸç‡ã¯ç•°ãªã‚‹ã€‚ã¾ãŸã€LLMãƒ™ãƒ¼ã‚¹ã®ç ”ç©¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã¯ã„ãã¤ã‹ã®èª²é¡ŒãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>GPT4ãŒMLãƒ¢ãƒ‡ãƒ«ã‚’ã©ã‚Œã ã‘è‡ªå‹•çš„ã«æ§‹ç¯‰ã§ãã‚‹ã‹ã‚’èª¿ã¹ãŸæ¨¡æ§˜ã€‚ã¾ãŸã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ãŸæ¨¡æ§˜ã€‚çµæœã¨ã—ã¦ã¯ã€æ—¢å­˜ã®æœ‰åãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®æˆåŠŸç‡ã¯90%ç¨‹åº¦ã§ã‚ã‚Šã€æœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ï¼ˆæ–°ãŸãªKaggle Challengeç­‰ï¼‰ã§ã¯30%ç¨‹åº¦ã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1063" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Model Alignment: A Survey, Tianhao Shen+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è¿‘å¹´ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®é€²æ­©ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã¾ã™ãŒã€ãã®æ½œåœ¨èƒ½åŠ›ã¨åŒæ™‚ã«æ‡¸å¿µã‚‚ã‚ã‚Šã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LLMsã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã«é–¢ã™ã‚‹æ—¢å­˜ã®ç ”ç©¶ã¨æ–°ãŸãªææ¡ˆã‚’åŒ…æ‹¬çš„ã«æ¢æ±‚ã—ã€ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆå¯èƒ½æ€§ã‚„æ•µå¯¾çš„æ”»æ’ƒã¸ã®è„†å¼±æ€§ãªã©ã®å•é¡Œã‚‚è­°è«–ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€LLMsã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨è©•ä¾¡æ‰‹æ³•ã‚’ææ¡ˆã—ã€å°†æ¥ã®ç ”ç©¶ã®æ–¹å‘æ€§ã‚’è€ƒå¯Ÿã—ã¾ã™ã€‚ã“ã®èª¿æŸ»ã¯ã€ç ”ç©¶è€…ã¨AIã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆç ”ç©¶ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨ã®é€£æºã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®alignmentã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ™ã‚¤ã€‚<img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/09c10110-798f-4493-b431-41c2f2b017c1" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ReversalCurse.html" target="_blank" rel="noopener noreferrer">#ReversalCurse</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1059" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A", Lukas Berglund+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±å›å¸°å‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€ã€ŒAã¯Bã§ã‚ã‚‹ã€ã¨ã„ã†æ–‡ã‹ã‚‰ã€ŒBã¯Aã§ã‚ã‚‹ã€ã¨é€†ã®é–¢ä¿‚ã‚’è‡ªå‹•çš„ã«ä¸€èˆ¬åŒ–ã§ããªã„ã€Œé€†è»¢ã®å‘ªã„ã€ã‚’ç¤ºã™ã€‚ä¾‹ãˆã°ã€ãƒ¢ãƒ‡ãƒ«ãŒã€Œãƒ¯ãƒ¬ãƒ³ãƒ†ã‚£ãƒŠãƒ»ãƒ†ãƒ¬ã‚·ã‚³ãƒ¯ã¯å®‡å®™ã«è¡Œã£ãŸæœ€åˆã®å¥³æ€§ã§ã‚ã‚‹ã€ã¨è¨“ç·´ã•ã‚Œã¦ã‚‚ã€ã€Œå®‡å®™ã«è¡Œã£ãŸæœ€åˆã®å¥³æ€§ã¯èª°ã‹ï¼Ÿã€ã«æ­£ã—ãç­”ãˆã‚‰ã‚Œãªã„ã€‚å®Ÿé¨“ã§ã¯ã€æ¶ç©ºã®æ–‡ã‚’ç”¨ã„ã¦GPT-3ã¨Llama-1ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€é€†è»¢ã®å‘ªã„ã®å­˜åœ¨ã‚’ç¢ºèªã€‚ChatGPTï¼ˆGPT-3.5ãŠã‚ˆã³GPT-4ï¼‰ã§ã‚‚ã€å®Ÿåœ¨ã®æœ‰åäººã«é–¢ã™ã‚‹è³ªå•ã§æ­£ç­”ç‡ã«å¤§ããªå·®ãŒè¦‹ã‚‰ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>A is Bã¨ã„ã†æ–‡ã§LLMã‚’è¨“ç·´ã—ã¦ã‚‚ã€B is Aã¨ã„ã†é€†æ–¹å‘ã«ã¯æ±åŒ–ã•ã‚Œãªã„ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br>è‘—è€…ãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/owainevans_uk/status/1705285631520407821?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/25e20dcc-0313-4cd2-8768-afb0e4e48a68" alt="image" loading="lazy"><br><p>GPT3, LLaMaã‚’ A is Bã§finetuneã—ã€B is Aã¨ã„ã†é€†æ–¹å‘ã®factã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«ï¼ˆè³ªå•ã‚’ã—ã¦ï¼‰ãƒ†ã‚¹ãƒˆã—ãŸã¨ã“ã‚ã€0%ä»˜è¿‘ã®Acc.ã ã£ãŸã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d089eb94-6872-40b5-89a1-7532758e1d89" alt="image" loading="lazy"><br><br>ã¾ãŸã€Acc.ãŒä½ã„ã ã‘ã§ãªãã€å¯¾æ•°å°¤åº¦ã‚‚randomãªfactã‚’ç”Ÿæˆã—ãŸå ´åˆã¨ã€ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§å·®ãŒãªã„ã“ã¨ãŒã‚ã‹ã£ãŸã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ba10fff4-cfdc-4e52-8217-c59247209211" alt="image" loading="lazy"><br><br>ã“ã®ã“ã¨ã‚‰ã€Reversal Curseã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§ã¯è§£æ±ºã§ããªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1923" target="_blank" rel="noopener noreferrer">Physics of Language Models: Part 3.1, Knowledge Storage and Extraction, Zeyuan Allen-Zhu+, ICML'24</a>
</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1056" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models as Analogical Reasoners, Michihiro Yasunaga+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’è‡ªå‹•çš„ã«ã‚¬ã‚¤ãƒ‰ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æ‰‹æ³•ã§ã‚ã‚‹ã‚¢ãƒŠãƒ­ã‚¸ã‚«ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ã€é–¢é€£ã™ã‚‹éå»ã®çµŒé¨“ã‚’å¼•ç”¨ã—ã¦æ–°ã—ã„å•é¡Œã«å–ã‚Šçµ„ã‚€èªçŸ¥ãƒ—ãƒ­ã‚»ã‚¹ã«å€£ã„ã€å•é¡Œã‚’è§£æ±ºã™ã‚‹å‰ã«æ–‡è„ˆå†…ã§é–¢é€£ã™ã‚‹ä¾‹ç¤ºã‚„çŸ¥è­˜ã‚’è‡ªå·±ç”Ÿæˆã•ã›ã‚‹ã‚ˆã†ã«è¨€èªãƒ¢ãƒ‡ãƒ«ã«ä¿ƒã—ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ã€ä¾‹ç¤ºã®ãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚„æ¤œç´¢ã®å¿…è¦æ€§ã‚’æ’é™¤ã—ã€ä¸€èˆ¬æ€§ã¨é©å¿œæ€§ã‚’æä¾›ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ã“ã®æ‰‹æ³•ãŒã•ã¾ã–ã¾ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã§ä»–ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹ã€è‘—è€…ãƒ„ã‚¤ãƒ¼ãƒˆã®ã–ã£ãã‚Šç¿»è¨³: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/michiyasunaga/status/1709582150025240854?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>äººé–“ã¯æ–°ã—ã„å•é¡Œã«å–ã‚Šçµ„ã‚€æ™‚ã€éå»ã«è§£ã„ãŸé¡ç¾©ã®å•é¡Œã‚’æŒ¯ã‚Šè¿”ã‚Šã€ãã®çµŒé¨“ã‚’æ´»ç”¨ã™ã‚‹ã€‚ã“ã‚Œã‚’LLMä¸Šã§å®Ÿè·µã§ããªã„ã‹?ã¨ã„ã†ã®ãŒã‚¢ã‚¤ãƒ‡ã‚¢ã€‚<br>Analogical Promptingã§ã¯ã€å•é¡Œã‚’è§£ãå‰ã«ã€é©åˆ‡ãªexamplarã‚’è‡ªå‹•ç”Ÿæˆï¼ˆproblemã¨solutionï¼‰ã•ã›ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã€‚<br><br>ã“ã‚Œã«ã‚ˆã‚Šã€examplarã¯è‡ªå·±ç”Ÿæˆã•ã‚Œã‚‹ãŸã‚ã€æ—¢å­˜ã®CoTã§å¿…è¦ãªexamplarã®ãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚„æ¤œç´¢ãŒä¸è¦ã¨ãªã‚‹ã“ã¨ã¨ã€è§£ã“ã†ã¨ã—ã¦ã„ã‚‹å•é¡Œã«åˆã‚ã›ã¦examplarã‚’èª¿æ•´ã—ã€æ¨è«–ã«å¯¾ã—ã¦ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’æä¾›ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã¨ãªã‚‹ã€‚<br><br>å®Ÿé¨“ã®çµæœã€æ•°å­¦ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã€BIG-Benchã§zero-shot CoTã€few-shot CoTã‚’ä¸Šå›ã£ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8aae5d9d-d8d8-4c86-b55f-0fcde5d5381c" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8544d7e2-bae3-4a1e-a867-ab655785c725" alt="image" loading="lazy"><p>LLMãŒçŸ¥ã£ã¦ãŠã‚Šã€ã‹ã¤å¾—æ„ãªå•é¡Œã«å¯¾ã—ã¦ãªã‚‰ã†ã¾ãåƒããã†ã€‚ä¸€æ–¹ã§ã€LLMãŒè‹¦æ‰‹ãªå•é¡Œãªã©ã¯äººæ‰‹ä½œæˆã—ãŸexamplarã§few-shotã—ãŸæ–¹ãŒï¼ˆã‚ã‚‹ç¨‹åº¦ï¼‰ã†ã¾ãã„ããã†ãªäºˆæ„ŸãŒã™ã‚‹ã€‚ã†ã¾ãã„ããã†ã¨è¨€ã£ã¦ã‚‚ã€ãã‚‚ãã‚‚LLMãŒè‹¦æ‰‹ãªå•é¡Œãªã®ã§few-shotã—ãŸç¨‹åº¦ã§ã¯ç„¼çŸ³ã«æ°´ã ã¨ã¯æ€ã†ãŒã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/NumericReasoning.html" target="_blank" rel="noopener noreferrer">#NumericReasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1050" target="_blank" rel="noopener noreferrer" class="title-link">MAmmoTH: Building Math Generalist Models through Hybrid Instruction  Tuning, Xiang Yue+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- MAmmoTHã¯ã€æ•°å­¦ã®å•é¡Œè§£æ±ºã«ç‰¹åŒ–ã—ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€å³å¯†ã«ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸæ•™è‚²ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€CoTã¨PoTã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãªæ ¹æ‹ ã‚’æä¾›ã—ã€ã•ã¾ã–ã¾ãªæ•°å­¦ã®åˆ†é‡ã‚’åŒ…æ‹¬çš„ã«ã‚«ãƒãƒ¼ã—ã¦ã„ã¾ã™ã€‚MAmmoTHã¯ã€æ—¢å­˜ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€ç‰¹ã«MATHãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§é«˜ã„ç²¾åº¦ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€å¤šæ§˜ãªå•é¡Œã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã¨ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãªæ ¹æ‹ ã®ä½¿ç”¨ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>9ã¤ã®math reasoningãŒå¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§13-29%ã®gainã§SoTAã‚’é”æˆã€‚<br>260kã®æ ¹æ‹ æƒ…å ±ã‚’å«ã‚€Math Instructãƒ‡ãƒ¼ã‚¿ã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã€‚<br><br>project page: 


<a href="https://tiger-ai-lab.github.io/MAmmoTH/" target="_blank" rel="noopener noreferrer">https://tiger-ai-lab.github.io/MAmmoTH/</a>


</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1048" target="_blank" rel="noopener noreferrer" class="title-link">A Survey of Hallucination in Large Foundation Models, Vipula Rawte+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡ãƒ•ã‚¡ã‚¦ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆLFMsï¼‰ã«ãŠã‘ã‚‹ãƒ›ãƒ¼ãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã®å•é¡Œã«ç„¦ç‚¹ã‚’å½“ã¦ã€ãã®ç¾è±¡ã‚’åˆ†é¡ã—ã€è©•ä¾¡åŸºæº–ã‚’ç¢ºç«‹ã™ã‚‹ã¨ã¨ã‚‚ã«ã€æ—¢å­˜ã®æˆ¦ç•¥ã‚’æ¤œè¨ã—ã€ä»Šå¾Œã®ç ”ç©¶ã®æ–¹å‘æ€§ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Hallucinationã‚’ç¾è±¡ã”ã¨ã«åˆ†é¡ã—ã€Hallucinationã®ç¨‹åº¦ã®è©•ä¾¡ã‚’ã™ã‚‹æŒ‡æ¨™ã‚„ã€Hallucinationã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®æ—¢å­˜æ‰‹æ³•ã«ã¤ã„ã¦ã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã‚‰ã—ã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ec507609-5b6d-42ed-92db-296856f93200" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/General.html" target="_blank" rel="noopener noreferrer">#General</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1047" target="_blank" rel="noopener noreferrer" class="title-link">RAIN: Your Language Models Can Align Themselves without Finetuning, Yuhui Li+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¿½åŠ ã®ãƒ‡ãƒ¼ã‚¿ãªã—ã§å‡çµã•ã‚ŒãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’æ•´åˆ—ã•ã›ã‚‹æ–¹æ³•ã‚’æ¢æ±‚ã—ã¾ã—ãŸã€‚è‡ªå·±è©•ä¾¡ã¨å·»ãæˆ»ã—ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§ã€LLMsã¯è‡ªå·±ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã‚’é€šã˜ã¦äººé–“ã®å¥½ã¿ã¨ä¸€è‡´ã™ã‚‹å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚RAINã¨ã„ã†æ–°ã—ã„æ¨è«–æ‰‹æ³•ã‚’å°å…¥ã—ã€è¿½åŠ ã®ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ›´æ–°ã‚’å¿…è¦ã¨ã›ãšã«AIã®å®‰å…¨æ€§ã‚’ç¢ºä¿ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€RAINã®åŠ¹æœã‚’ç¤ºã—ã¦ãŠã‚Šã€LLaMA 30Bãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ç„¡å®³ç‡ã‚’å‘ä¸Šã•ã›ã€Vicuna 33Bãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯æ”»æ’ƒæˆåŠŸç‡ã‚’æ¸›å°‘ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒˆãƒ¼ã‚¯ãƒ³ã®setã§æ§‹æˆã•ã‚Œã‚‹treeä¸Šã‚’æ¢ç´¢ã—ã€å‡ºåŠ›ãŒç„¡å®³ã¨self-evaluationã•ã‚Œã‚‹ã¾ã§ã€å·»ãæˆ»ã—ã¨å‰æ–¹ç”Ÿæˆã‚’ç¹°ã‚Šè¿”ã—ã€æœ‰å®³ãªãƒˆãƒ¼ã‚¯ãƒ³setã®é‡ã¿ã‚’å‹•çš„ã«æ¸›ã‚‰ã™ã“ã¨ã§alignmentã‚’å®Ÿç¾ã™ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ ã®finetuningç­‰ã¯ä¸è¦ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/05bebc0a-325b-423d-ae36-4bc5698063fe" alt="image" loading="lazy"><br><br></p>
<p>self-evaluationã§ã¯ä¸‹è¨˜ã®ã‚ˆã†ãªpromptã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ãŒã€ã“ã®promptã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã“ã¡ã‚‰å´ã®æ„å›³ã—ãŸã¨ãŠã‚Šã«å‡ºåŠ›ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’ã¨ã‚‹ã“ã¨ãŒã§ãã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚éå¸¸ã«æ±ç”¨æ€§ã®é«˜ã„æ‰‹æ³•ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/90070c63-e72d-4b49-bb03-a97dd5baa240" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/StructuredData.html" target="_blank" rel="noopener noreferrer">#StructuredData</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1046" target="_blank" rel="noopener noreferrer" class="title-link">Struc-Bench: Are Large Language Models Really Good at Generating Complex  Structured Data?, Xiangru Tang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®èƒ½åŠ›ã‚’è©•ä¾¡ã—ã€æ§‹é€ ã«æ³¨æ„ã—ãŸãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚ã•ã‚‰ã«ã€Struc-Benchã¨ã„ã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã€è¤‡é›‘ãªæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã—ã¾ã™ã€‚å®Ÿé¨“ã®çµæœã€ææ¡ˆæ‰‹æ³•ã¯ä»–ã®è©•ä¾¡ã•ã‚ŒãŸLLMsã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ãƒãƒƒãƒ—ã‚’æç¤ºã—ã€LLMsã®å¼±ç‚¹ã¨å°†æ¥ã®ç ”ç©¶ã®æ–¹å‘æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚è©³ç´°ã¯https://github.com/gersteinlab/Struc-Benchã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚</span>
<span class="snippet"><span>Comment</span><p>Formatã«é–¢ã™ã‚‹æƒ…å ±ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã§Instruction Tuningã™ã‚‹ã“ã¨ã§FormatCoTï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«é–¢ã™ã‚‹æƒ…å ±ã®CoTï¼‰ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ã–ã£ãã‚Šã—ã‹è«–æ–‡ã‚’èª­ã‚“ã§ã„ãªã„ãŒè©³ç´°ãªæƒ…å ±ãŒã‚ã¾ã‚Šæ›¸ã‹ã‚Œã¦ã„ãªã„å°è±¡ã§ã€ã¡ã‚‡ã£ã¨ãªã‚“ã¨ã‚‚ã„ãˆãªã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/01a23836-b9fb-4d29-891f-d3b01e3e55d2" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1043" target="_blank" rel="noopener noreferrer" class="title-link">GPTQ: Accurate Post-Training Quantization for Generative Pre-trained   Transformers, Elias Frantar+, N_A, ICLR'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€GPTãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã«ãŠã‘ã‚‹è¨ˆç®—ãŠã‚ˆã³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ã‚¹ãƒˆã®å•é¡Œã«å–ã‚Šçµ„ã¿ã€æ–°ã—ã„ãƒ¯ãƒ³ã‚·ãƒ§ãƒƒãƒˆé‡ã¿é‡å­åŒ–æ‰‹æ³•ã§ã‚ã‚‹GPTQã‚’ææ¡ˆã—ã¾ã™ã€‚GPTQã¯é«˜ã„ç²¾åº¦ã¨åŠ¹ç‡æ€§ã‚’æŒã¡ã€1750å„„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤GPTãƒ¢ãƒ‡ãƒ«ã‚’4æ™‚é–“ã®GPUæ™‚é–“ã§é‡å­åŒ–ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã¯å¾“æ¥ã®æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦åœ§ç¸®ç‡ã‚’2å€ä»¥ä¸Šå‘ä¸Šã•ã›ã€ç²¾åº¦ã‚’ä¿æŒã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã•ã‚‰ã«ã€ææ¡ˆæ‰‹æ³•ã¯æ¥µç«¯ãªé‡å­åŒ–é ˜åŸŸã§ã‚‚åˆç†çš„ãªç²¾åº¦ã‚’æä¾›ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€ææ¡ˆæ‰‹æ³•ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®æ¨è«–é€Ÿåº¦ãŒç´„3.25å€ã‹ã‚‰4.5å€å‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã®å®Ÿè£…ã¯https://github.com/IST-DASLab/gptqã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>- æ–°ãŸãªpost-trainingé‡å­åŒ–æ‰‹æ³•ã§ã‚ã‚‹GPTQã‚’ææ¡ˆ<br><br>- æ•°æ™‚é–“ä»¥å†…ã«æ•°åƒå„„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã§ã®å®Ÿè¡ŒãŒå¯èƒ½ã§ã‚ã‚Šã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã”ã¨ã«3ï½4ãƒ“ãƒƒãƒˆã¾ã§åœ§ç¸®ã™ã‚‹ãŒã€ç²¾åº¦ã®å¤§ããªæå¤±ã‚’ä¼´ã‚ãªã„<br><br>    - OPT-175BãŠã‚ˆã³BLOOM-176Bã‚’ã€ç´„4æ™‚é–“ã®GPUæ™‚é–“ã§ã€perplexityã®ã‚ãšã‹ãªå¢—åŠ ã§é‡å­åŒ–ã™ã‚‹ã“ã¨ãŒã§ããŸ<br><br>- æ•°åƒå„„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤éå¸¸ã«é«˜ç²¾åº¦ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’3-4ãƒ“ãƒƒãƒˆã«é‡å­åŒ–å¯èƒ½ãªã“ã¨ã‚’åˆã‚ã¦ç¤ºã—ãŸ<br><br>    - å…ˆè¡Œç ”ç©¶ã®post-trainingæ‰‹æ³•ã¯ã€8ãƒ“ãƒƒãƒˆï¼ˆYao et al., 2022; Dettmers et al., 2022ï¼‰ã€‚<br><br>    - ä¸€æ–¹ã€ä»¥å‰ã®training-basedã®æ‰‹æ³•ã¯ã€1ï½2æ¡å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã®ã¿ã‚’å¯¾è±¡ã¨ã—ã¦ã„ãŸï¼ˆWu et al., 2022ï¼‰ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4ff107a9-7ccf-40f6-ad8c-fd910b1f0ac7" alt="image" loading="lazy"><br><br></p>
<p># Background<br><br>## Layer-wise quantization<br><br>å„linear layerãŒã‚ã‚‹ã¨ãã«ã€full precisionã®outputã‚’å°‘é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«æµã—ãŸã¨ãã«ã€quantized weight W^barã‚’ç”¨ã„ã¦reconstructã§ãã‚‹ã‚ˆã†ã«ã€squared error lossã‚’æœ€å°åŒ–ã™ã‚‹æ–¹æ³•ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9950fec1-966b-45c4-a82a-6bfd533042b3" alt="image" loading="lazy"><br><br><br><br>## Optimal Brain quantization (OBQ)<br><br>OBQã§ã¯ equation (1)ã‚’Wã®è¡Œã«é–¢ã™ã‚‹summationã¨ã¿ãªã™ã€‚ãã—ã¦ã€ãã‚Œãã‚Œã®è¡Œ **w** ã‚’OBQã¯ç‹¬ç«‹ã«æ‰±ã„ã€ã‚ã‚‹ä¸€ã¤ã®é‡ã¿w_qã‚’quantizeã™ã‚‹ã¨ãã«ã€ã‚¨ãƒ©ãƒ¼ãŒw_qã®ã¿ã«åŸºã¥ã„ã¦ã„ã‚‹ã“ã¨ã‚’è£œå„Ÿã™ã‚‹ãŸã‚ã«ä»–ã®**w**ã®å…¨ã¦ã®quantizedã•ã‚Œã¦ã„ãªã„é‡ã¿ã‚’updateã™ã‚‹ã€‚å¼ã§è¡¨ã™ã¨ä¸‹è¨˜ã®ã‚ˆã†ã«ãªã‚Šã€Fã¯æ®‹ã‚Šã®full-precision weightã®é›†åˆã‚’è¡¨ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/aab7784d-45f3-4f23-ac74-6cc4c2026486" alt="image" loading="lazy"><br><br>ã“ã®äºŒã¤ã®å¼ã‚’ã€å…¨ã¦ã®**w**ã®é‡ã¿ãŒquantizedã•ã‚Œã‚‹ã¾ã§ç¹°ã‚Šè¿”ã—é©ç”¨ã™ã‚‹ã€‚<br><br><br><br>ã¤ã¾ã‚Šã€ã‚ã‚‹ä¸€å€‹ã®é‡ã¿ã‚’quantizedã—ãŸã“ã¨ã«ã‚ˆã‚‹èª¤å·®ã‚’è£œã†ã‚ˆã†ã«ã€ä»–ã®ã¾ã quantizedã•ã‚Œã¦ã„ãªã„é‡ã¿ã‚’updateã™ã‚‹ã“ã¨ã§ã€æ¬¡ã«åˆ¥ã®é‡ã¿ã‚’quantizedã™ã‚‹éš›ã¯ã€æœ€åˆã®é‡ã¿ãŒquantizedã•ã‚ŒãŸã“ã¨ã‚’è€ƒæ…®ã—ãŸé‡ã¿ã«å¯¾ã—ã¦quantizedã™ã‚‹ã“ã¨ã«ãªã‚‹ã€‚ã“ã‚Œã‚’ç¹°ã‚Šè¿”ã™ã“ã¨ã§ã€quantizedã—ãŸã“ã¨ã«ã‚ˆã‚‹èª¤å·®ã‚’è€ƒæ…®ã—ã¦**w**å…¨ä½“ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§ãã‚‹ã€ã¨ã„ã†æ°—æŒã¡ã ã¨æ€ã†ã€‚<br><br><br><br>ã“ã®å¼ã¯é«˜é€Ÿã«è¨ˆç®—ã™ã‚‹ã“ã¨ãŒã§ãã€medium sizeã®ãƒ¢ãƒ‡ãƒ«ï¼ˆ25M parameters; ResNet-50 modelãªã©ï¼‰ã¨ã‹ã§ã‚ã‚Œã°ã€single GPUã§1æ™‚é–“ã§quantizeã§ãã‚‹ã€‚ã—ã‹ã—ãªãŒã‚‰ã€OBQã¯O(d_row * d_col^3)ã§ã‚ã‚‹ãŸã‚ã€ï¼ˆã“ã“ã§d_rowã¯Wã®è¡Œæ•°ã€d_colã¯wã®åˆ—æ•°ï¼‰ã€billions of parametersã«é©ç”¨ã™ã‚‹ã«ã¯è¨ˆç®—é‡ãŒå¤šã™ãã‚‹ã€‚</p>
<p># Algorithm<br><br>## Step 1: Arbitrary Order Insight.<br><br>é€šå¸¸ã®OBQã¯ã€é‡å­åŒ–èª¤å·®ãŒæœ€ã‚‚å°‘ãªã„é‡ã¿ã‚’å¸¸ã«é¸æŠã—ã¦ã€greedyã«é‡ã¿ã‚’æ›´æ–°ã—ã¦ã„ãã€‚ã—ã‹ã—ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤§ããªãƒ¢ãƒ‡ãƒ«ã«ãªã‚‹ã¨ã€é‡ã¿ã‚’ä»»æ„ã®é †åºã§é‡å­åŒ–ã—ãŸã¨ã—ã¦ã‚‚ãã‚Œã«ã‚ˆã‚‹å½±éŸ¿ã¯å°ã•ã„ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚ãªãœãªã‚‰ã€ãŠãã‚‰ãã€å¤§ããªå€‹åˆ¥ã®èª¤å·®ã‚’æŒã¤é‡å­åŒ–ã•ã‚ŒãŸé‡ã¿ã®æ•°ãŒå°‘ãªã„ã¨è€ƒãˆã‚‰ã‚Œã€ãã®é‡ã¿ãŒãƒ—ãƒ­ã‚»ã‚¹ã®ãŒé€²ã‚€ã«ã¤ã‚Œã¦ï¼ˆã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œã‚‹ã“ã¨ã§ï¼Ÿï¼‰ç›¸æ®ºã•ã‚Œã‚‹ãŸã‚ã€‚<br><br><br><br>ã“ã®ãŸã‚ã€ææ¡ˆæ‰‹æ³•ã¯ã€ã™ã¹ã¦ã®è¡Œã®é‡ã¿ã‚’åŒã˜é †åºã§é‡å­åŒ–ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã€ã“ã‚ŒãŒé€šå¸¸ã€æœ€çµ‚çš„ãªäºŒä¹—èª¤å·®ãŒå…ƒã®è§£ã¨åŒã˜çµæœã¨ãªã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãŒã€ã“ã®ãŸã‚ã«2ã¤ã®èª²é¡Œã‚’ä¹—ã‚Šè¶Šãˆãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚<br><br><br><br>## Step2. Lazy Batch-Updates<br><br>Fã‚’æ›´æ–°ã™ã‚‹ã¨ãã¯ã€å„ã‚¨ãƒ³ãƒˆãƒªã«å¯¾ã—ã¦ã‚ãšã‹ãªFLOPã‚’ä½¿ç”¨ã—ã¦ã€å·¨å¤§ãªè¡Œåˆ—ã®ã™ã¹ã¦ã®è¦ç´ ã‚’æ›´æ–°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã—ã‹ã—ã€ã“ã®ã‚ˆã†ãªæ“ä½œã¯ã€ç¾ä»£ã®GPUã®å¤§è¦æ¨¡ãªè¨ˆç®—èƒ½åŠ›ã‚’é©åˆ‡ã«æ´»ç”¨ã™ã‚‹ã“ã¨ãŒã§ããšã€éå¸¸ã«å°ã•ã„ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…ã«ã‚ˆã£ã¦ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ãªã‚‹ã€‚<br><br><br><br>å¹¸ã„ã«ã‚‚ã€ã“ã®å•é¡Œã¯ä»¥ä¸‹ã®è¦³å¯Ÿã«ã‚ˆã£ã¦è§£æ±ºã§ãã‚‹ï¼šåˆ—iã®æœ€çµ‚çš„ãªå››æ¨äº”å…¥ã®æ±ºå®šã¯ã€ã“ã®ç‰¹å®šã®åˆ—ã§è¡Œã‚ã‚ŒãŸæ›´æ–°ã«ã®ã¿å½±éŸ¿ã•ã‚Œã€ãã®ãƒ—ãƒ­ã‚»ã‚¹ã®æ™‚ç‚¹ã§å¾Œã®åˆ—ã¸ã®æ›´æ–°ã¯é–¢é€£ãŒãªã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ›´æ–°ã‚’ã€Œlazy batchã€ã¨ã—ã¦ã¾ã¨ã‚ã‚‹ã“ã¨ãŒã§ãã€ã¯ã‚‹ã‹ã«åŠ¹ç‡çš„ãªGPUã®åˆ©ç”¨ãŒå¯èƒ½ã¨ãªã‚‹ã€‚ï¼ˆè¦ã¯ç‹¬ç«‹ã—ã¦è¨ˆç®—ã§ãã‚‹éƒ¨åˆ†ã¯å…¨éƒ¨ä¸€æ°—ã«è¨ˆç®—ã—ã¦ã—ã¾ã£ã¦ã€å¾Œã§ä¸€æ°—ã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ã¾ã™ã¨ã„ã†ã“ã¨ï¼‰ã€‚ãŸã¨ãˆã°ã€B = 128ã®åˆ—ã«ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é©ç”¨ã—ã€æ›´æ–°ã‚’ã“ã‚Œã‚‰ã®åˆ—ã¨å¯¾å¿œã™ã‚‹B Ã— Bãƒ–ãƒ­ãƒƒã‚¯ã® H^-1 ã«æ ¼ç´ã™ã‚‹ã€‚<br><br>ã“ã®æˆ¦ç•¥ã¯ç†è«–çš„ãªè¨ˆç®—é‡ã‚’å‰Šæ¸›ã—ãªã„ã‚‚ã®ã®ã€ãƒ¡ãƒ¢ãƒªã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’æ”¹å–„ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€éå¸¸ã«å¤§ããªãƒ¢ãƒ‡ãƒ«ã®å ´åˆã«ã¯å®Ÿéš›ã«1æ¡ä»¥ä¸Šã®é«˜é€ŸåŒ–ãŒæä¾›ã•ã‚Œã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fcb33c4d-3924-4abd-b149-936b9e350c76" alt="image" loading="lazy"><br><br><br><br>## Step 3: Cholesky Reformulation<br><br>è¡Œåˆ—H_F^-1ãŒä¸å®šã«ãªã‚‹ã“ã¨ãŒã‚ã‚Šã€ã“ã‚ŒãŒã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒæ®‹ã‚Šã®é‡ã¿ã‚’èª¤ã£ãŸæ–¹å‘ã«æ›´æ–°ã™ã‚‹åŸå› ã¨ãªã‚Šã€è©²å½“ã™ã‚‹å±¤ã«å¯¾ã—ã¦æ‚ªã„é‡å­åŒ–ã‚’å®Ÿæ–½ã—ã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‚‹ã€‚ã“ã®ç¾è±¡ãŒç™ºç”Ÿã™ã‚‹ç¢ºç‡ã¯ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã¨ã¨ã‚‚ã«å¢—åŠ ã™ã‚‹ã“ã¨ãŒå®Ÿéš›ã«è¦³å¯Ÿã•ã‚ŒãŸã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ã‚³ãƒ¬ã‚¹ã‚­ãƒ¼åˆ†è§£ã‚’æ´»ç”¨ã—ã¦è§£æ±ºã—ã¦ã„ã‚‹ï¼ˆè©³ç´°ã¯ãã¡ã‚“ã¨èª­ã‚“ã§ã„ãªã„ï¼‰ã€‚</p>
<p># å®Ÿé¨“ã§ç”¨ã„ãŸCalibration data<br><br>GPTQã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã¯ã€C4ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ(Raffel et al., 2020)ã‹ã‚‰ã®ãƒ©ãƒ³ãƒ€ãƒ ãª2048ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ128å€‹ã§æ§‹æˆã•ã‚Œã‚‹ã€‚ã¤ã¾ã‚Šã€ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚¯ãƒ­ãƒ¼ãƒ«ã•ã‚ŒãŸã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‹ã‚‰ã®æŠœç²‹ã§ã€ä¸€èˆ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ã—ã¦ã„ã‚‹ã€‚GPTQãŒã‚¿ã‚¹ã‚¯å›ºæœ‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åˆ‡è¦‹ã¦ã„ãªã„ãŸã‚ã€Œã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã€ãªè¨­å®šã§quantizationã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚<br><br><br><br># Language Generationã§ã®è©•ä¾¡<br><br>WikiText2ã«å¯¾ã™ã‚‹Perplexityã§è©•ä¾¡ã—ãŸçµæœã€å…ˆè¡Œç ”ç©¶ã§ã‚ã‚‹RTNã‚’å¤§å¹…ã«outperformã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/23e12194-d329-46f7-bb69-2cce290282c1" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1041" target="_blank" rel="noopener noreferrer" class="title-link">From Sparse to Dense: GPT-4 Summarization with Chain of Density  Prompting, Griffin Adams+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ã¯è©³ç´°ã§ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ä¸­å¿ƒçš„ã§ã‚ã‚ŠãªãŒã‚‰ã€ç†è§£ã—ã‚„ã™ãã™ã‚‹ã“ã¨ãŒå›°é›£ã§ã™ã€‚ã“ã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ç§ãŸã¡ã¯ã€Œå¯†åº¦ã®é€£é–ã€ï¼ˆCoDï¼‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€GPT-4ã®è¦ç´„ã‚’ç”Ÿæˆã—ã¾ã™ã€‚CoDã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã¯æŠ½è±¡çš„ã§ã‚ã‚Šã€ãƒªãƒ¼ãƒ‰ãƒã‚¤ã‚¢ã‚¹ãŒå°‘ãªãã€äººé–“ã«å¥½ã¾ã‚Œã¾ã™ã€‚ã¾ãŸã€æƒ…å ±é‡ã¨èª­ã¿ã‚„ã™ã•ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚Œã¾ã—ãŸã€‚CoDè¦ç´„ã¯ç„¡æ–™ã§åˆ©ç”¨ã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>è«–æ–‡ä¸­ã®promptä¾‹ã€‚InformativeãªEntityã®Coverageã‚’å¢—ã‚„ã™ã‚ˆã†ã«ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å›ã—ã€å„Entityã«é–¢ã™ã‚‹æƒ…å ±ï¼ˆå‰ã‚¹ãƒ†ãƒƒãƒ—ã§ä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±ã¯è£œè¶³ã—ãªãŒã‚‰ï¼‰ã‚’å…·ä½“çš„ã«è¨˜è¿°ã™ã‚‹ã‚ˆã†ã«è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c24ab8c0-06fa-49ea-9df7-f248ec18ba45" alt="image" loading="lazy"><br><br></p>
<p>äººé–“ãŒå¥½ã‚€Entityã®Densityã«ã¯ã‚ã‚‹ç¨‹åº¦ã®é–¾å€¤ãŒã‚ã‚‹æ¨¡æ§˜ï¼ˆã§ã‚‚ã“ã‚Œã¯äººã‚„ç”¨é€”ã«ã‚ˆã£ã¦é–¾å€¤ãŒé•ã†ã‚ˆã†ã­ã¨ã¯æ€ã†ï¼‰ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d63c21e9-9179-4f8c-925f-ed435ecb1717" alt="image" loading="lazy"><br><br>äººæ‰‹è©•ä¾¡ã¨GPT4ã«ã‚ˆã‚‹5-scale ã®è©•ä¾¡ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚å®šæ€§çš„ãªè€ƒå¯Ÿã¨ã—ã¦ã¯ã€ä¸»é¡Œã¨ç›´æ¥çš„ã«é–¢ä¿‚ãªã„Entityã®è©³ç´°ã‚’è¿°ã¹ã‚‹ã‚ˆã†ã«ãªã£ã¦ã‚‚äººé–“ã«ã¯å¥½ã¾ã‚Œãªã„ï¼ˆå³ä¾‹ï¼‰ã“ã¨ãŒè¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/900695ca-fbad-4d58-9388-2d2f86644e48" alt="image" loading="lazy"><br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d3b3afe2-15fa-4b40-95cb-51aa0f27d6db" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1040" target="_blank" rel="noopener noreferrer" class="title-link">DoLa: Decoding by Contrasting Layers Improves Factuality in Large  Language Models, Yung-Sung Chuang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æˆ‘ã€…ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã‘ã‚‹å¹»è¦šã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ã‚’ææ¡ˆã™ã‚‹ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€ãƒ­ã‚¸ãƒƒãƒˆã®å·®ç•°ã‚’å¯¾æ¯”ã™ã‚‹ã“ã¨ã§æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®åˆ†å¸ƒã‚’å¾—ã‚‹ã‚‚ã®ã§ã€äº‹å®ŸçŸ¥è­˜ã‚’ã‚ˆã‚Šæ˜ç¢ºã«ç¤ºã—ã€èª¤ã£ãŸäº‹å®Ÿã®ç”Ÿæˆã‚’æ¸›ã‚‰ã™ã“ã¨ãŒã§ãã‚‹ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€è¤‡æ•°ã®é¸æŠèª²é¡Œã‚„ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ã®ç”Ÿæˆèª²é¡Œã«ãŠã„ã¦çœŸå®Ÿæ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã€ä»¥ä¸‹ã€WIPçŠ¶æ…‹ã®è«–æ–‡ã‚’èª­ã‚“ã§ã„ã‚‹ãŸã‚ä»Šå¾Œå†…å®¹ãŒå¤‰åŒ–ã™ã‚‹å¯èƒ½æ€§ã‚ã‚Šã€‘<br><br># æ¦‚è¦<br><br>Transformer Layerã«ãŠã„ã¦ã€factual informationãŒç‰¹å®šã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«å±€æ‰€åŒ–ã™ã‚‹ã¨ã„ã†ç¾è±¡ã‚’è¦³æ¸¬ã—ã¦ãŠã‚Šã€ãã‚Œã‚’æ´»ç”¨ã—ã‚ˆã‚ŠFactual Consistencyã®ã‚ã‚‹ç”Ÿæˆã‚’ã—ã¾ã™ã€ã¨ã„ã†ç ”ç©¶<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/eb8dbecb-21cb-4abb-879c-5a8f39364e6a" alt="image" loading="lazy"><br><br><br><br>ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã¨ãã®å˜èªã®ç”Ÿæˆç¢ºç‡ã®åˆ†å¸ƒã‚’å¯è¦–åŒ–ã€‚final layer (N=32ã ã¨æ€ã‚ã‚Œã‚‹)ã¨ã®é–“ã®Jensen-shanon Divergence (JSD) ã§å¯è¦–åŒ–ã—ã¦ã„ã‚‹ã€‚ãŒã€å›³ã‚’è¦‹ã‚‹ã¨JSDã®å€¤åŸŸã¯[0, 1]ã®ã¯ãšãªã®ã«ã“ã‚Œã‚’é€¸è„±ã—ã¦ã„ã‚‹ã®ã§ä¸€ä½“ã©ã†ã„ã†è¨ˆç®—ã‚’ã—ã¦ã„ã‚‹ã®ã‹ã€‚ã€‚ã€‚<br><br>å›³ã®èª¬æ˜ã¨ã—ã¦ã¯è«–æ–‡ä¸­ã§ã¯2ã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚‹ã¨è¨€åŠã—ã¦ãŠã‚Š<br><br>1. é‡è¦ãªå›ºæœ‰è¡¨ç¾ã‚„æ—¥ä»˜ï¼ˆWole Soyinka, 1986ãªã©; Factual KnowledgeãŒå¿…è¦ãªã‚‚ã®ï¼‰ã¯ã€higher layerã§ã‚‚é«˜ã„å€¤ã¨ãªã£ã¦ãŠã‚Šã€higher-layerã«ãŠã„ã¦predictionã®å†…å®¹ã‚’å¤‰ãˆã¦ã„ã‚‹ï¼ˆé‡è¦ãªæƒ…å ±ãŒã“ã“ã§injectionã•ã‚Œã¦ã„ã‚‹ï¼‰<br><br>2. æ©Ÿèƒ½èªã‚„ã€questionã‹ã‚‰ã®å˜èªã®ã‚³ãƒ”ãƒ¼ï¼ˆNigerian, Nobel Prize ãªã©ï¼‰ã®ã‚ˆã†ãª "easy" ãªtokenã¯æ—¢ã«middle of layersã§æ—¢ã«JSDã®å€¤ãŒå°ã•ãã€early layerã®æ™‚ç‚¹ã§å‡ºåŠ›ã™ã‚‹ã“ã¨ãŒæ—¢ã«æ±ºå®šã•ã‚Œã¦ã„ã‚‹<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/daed79c1-1391-43ad-a94e-a6748ec3529f" alt="image" loading="lazy"><br><br><br><br># æ‰‹æ³•æ¦‚è¦<br><br>ã“ã“ã‹ã‚‰ã®è€ƒå¯Ÿã¨ã—ã¦ã¯ã€é‡è¦ãªäº‹å®Ÿã«é–¢ã™ã‚‹æƒ…å ±ã¯final layerã®æ–¹ã§åˆ†å¸ƒãŒå¤‰åŒ–ã™ã‚‹å‚¾å‘ã«ã‚ã‚Šã€ä½layerã®æ–¹ã§ã¯ãã†ã§ã¯ãªã„ã½ã„ã®ã§ã€final layerã¨åˆ†å¸ƒãŒä¼¼ã¦ã„ã‚‹ãŒFactual InformationãŒã¾ã ã‚ã¾ã‚Šé¡•è‘—ã«ç”Ÿæˆç¢ºç‡ãŒé«˜ããªã£ã¦ã„ãªã„layerï¼ˆpre mature layerï¼‰ã¨ã®å¯¾æ¯”ã‚’ã¨ã‚‹ã“ã¨ã§ã€ç”Ÿæˆã•ã‚Œã‚‹ã¹ãFactual InformationãŒã‚ã‹ã‚‹ã®ã§ã¯ãªã„ã‹ã€ã¨ã„ã†å‰æã®å…ƒææ¡ˆæ‰‹æ³•ãŒçµ„ã¾ã‚Œã¦ã„ã‚‹ã€‚æ‰‹æ³•ã¨ã—ã¦ã¯ã€final layerã¨ã®JSDãŒæœ€å¤§ã¨ãªã‚‹ã‚ˆã†ãªlayerã‚’ä¸€ã¤é¸æŠã™ã‚‹ã€ã¨ã„ã†ã‚‚ã®ã«ãªã£ã¦ã„ã‚‹ãŒã€æœãŸã—ã¦ã“ã®é¸æŠæ–¹æ³•ã§å‰è¿°ã®æ°—æŒã¡ãŒå®Ÿç¾ã§ãã¦ã„ã‚‹ã®ã‹ï¼Ÿã¨ã„ã†æ°—ã¯å°‘ã—ã™ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0c4973a0-baee-4de3-82fa-55aba12f9c73" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1039" target="_blank" rel="noopener noreferrer" class="title-link">Textbooks Are All You Need II: phi-1.5 technical report, Yuanzhi Li+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€å°ã•ãªTransformerãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹TinyStoriesã¨ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹phi-1ã®èƒ½åŠ›ã«ã¤ã„ã¦èª¿æŸ»ã—ã¾ã—ãŸã€‚ã¾ãŸã€phi-1ã‚’ä½¿ç”¨ã—ã¦æ•™ç§‘æ›¸ã®å“è³ªã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€phi-1.5ã¨ã„ã†æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã€è‡ªç„¶è¨€èªã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦æ€§èƒ½ãŒå‘ä¸Šã—ã€è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚phi-1.5ã¯ã€è‰¯ã„ç‰¹æ€§ã¨æ‚ªã„ç‰¹æ€§ã‚’æŒã£ã¦ãŠã‚Šã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need, Suriya Gunasekar+, N/A, arXiv'23</a>
 ã«ç¶šãè«–æ–‡</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Sycophancy.html" target="_blank" rel="noopener noreferrer">#Sycophancy</a>
<span class="issue_date">Issue Date: 2023-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1038" target="_blank" rel="noopener noreferrer" class="title-link">Simple synthetic data reduces sycophancy in large language models, Jerry Wei+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãŠã¹ã£ã‹è¡Œå‹•ã‚’æ¸›ã‚‰ã™ãŸã‚ã®æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã¾ãšã€è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹ãŠã¹ã£ã‹è¡Œå‹•ã®æ™®åŠåº¦ã‚’èª¿æŸ»ã—ã€ãã®è¡Œå‹•ã‚’æ¸›ã‚‰ã™ãŸã‚ã®åˆæˆãƒ‡ãƒ¼ã‚¿ä»‹å…¥ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„è¦‹ã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«ãŒé ‘å¥ã§ã‚ã‚‹ã“ã¨ã‚’ä¿ƒã™åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãŠã¹ã£ã‹è¡Œå‹•ã‚’å¤§å¹…ã«æ¸›ã‚‰ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã®è©³ç´°ã¯ã€https://github.com/google/sycophancy-intervention ã§ç¢ºèªã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã¯ãƒ¦ãƒ¼ã‚¶ã®å¥½ã‚€å›ç­”ã‚’ã™ã‚‹ã‚ˆã†ã«äº‹å‰å­¦ç¿’ã•ã‚Œã‚‹ãŸã‚ã€promptä¸­ã«ãƒ¦ãƒ¼ã‚¶ã®æ„è¦‹ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã¨ã€ãƒ¦ãƒ¼ã‚¶ã®æ„è¦‹ã«å¼•ã£å¼µã‚‰ã‚Œä»®ã«ä¸æ­£è§£ã§ã‚‚ãƒ¦ãƒ¼ã‚¶ã®å¥½ã‚€å›ç­”ã‚’ã—ã¦ã—ã¾ã†å•é¡ŒãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€ãã®å¯¾ç­–ã¨ã—ã¦äººå·¥çš„ã«ãƒ¦ãƒ¼ã‚¶ã®æ„è¦‹ã¨ã€claimã‚’ç‹¬ç«‹ã•ã›ã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆã—Finetuningã™ã‚‹ã“ã¨ã§é˜²ãã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</p>
<p>èª¤ã£ãŸãƒ¦ãƒ¼ã‚¶ã®æ„è¦‹ã‚’æŒ¿å…¥ã™ã‚‹ã¨ã€æ­£è§£ã§ãã¦ã„ãŸå•é¡Œã§ã‚‚ä¸æ­£è§£ã«ãªã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/43c03357-5c5c-4ceb-a089-0ad0a35eea1d" alt="image" loading="lazy"></p>
<p>ã“ã®å‚¾å‘ã¯ã€instruction tuningã—ã¦ã„ã‚‹å ´åˆã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„å ´åˆã«ã‚ˆã‚Šé¡•è‘—ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6737eb30-7055-43d6-a1f4-d700be5963f2" alt="image" loading="lazy"></p>
<p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/54458bc0-ba89-4b10-b6c1-baa70384abb9" alt="image" loading="lazy"><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7690e3b4-00e7-468a-a36f-7130f65669dc" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2023-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1035" target="_blank" rel="noopener noreferrer" class="title-link">Instruction Tuning for Large Language Models: A Survey, Shengyu Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€instruction tuningï¼ˆITï¼‰ã¨ã„ã†æŠ€è¡“ã«ã¤ã„ã¦èª¿æŸ»ã—ã¦ã„ã¾ã™ã€‚ITã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ã•ã‚‰ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®æ–¹æ³•ã§ã‚ã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã«å¾“ã†ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ITã®æ–¹æ³•è«–ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹ç¯‰ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ–¹æ³•ãªã©ã«ã¤ã„ã¦èª¿æŸ»ã—ã€æŒ‡ç¤ºã®ç”Ÿæˆã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºãªã©ãŒITã®çµæœã«ä¸ãˆã‚‹å½±éŸ¿ã‚’åˆ†æã—ã¾ã™ã€‚ã¾ãŸã€ITã®æ½œåœ¨çš„ãªå•é¡Œã‚„æ‰¹åˆ¤ã€ç¾åœ¨ã®ä¸è¶³ç‚¹ã«ã¤ã„ã¦ã‚‚æŒ‡æ‘˜ã—ã€ä»Šå¾Œã®ç ”ç©¶ã®æ–¹å‘æ€§ã‚’ææ¡ˆã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä¸»è¦ãªãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œã‚Šæ–¹ãªã©å¹…åºƒãã¾ã¨ã¾ã£ã¦ã„ã‚‹</p>
<p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/440b5214-71b9-4d22-9c0c-badd84a717ce" alt="image" loading="lazy"><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/69cfdf51-e230-48b8-8f34-0286b3469c01" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1034" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models Are Human-Level Prompt Engineers, Yongchao Zhou+, ICLR'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€è‡ªç„¶è¨€èªã®æŒ‡ç¤ºã«åŸºã¥ã„ã¦ä¸€èˆ¬çš„ãªç”¨é€”ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¨ã—ã¦å„ªã‚ŒãŸèƒ½åŠ›ã‚’æŒã£ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ã€ä½¿ç”¨ã•ã‚Œã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å“è³ªã«å¤§ããä¾å­˜ã—ã¾ã™ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€è‡ªå‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ï¼ˆAPEï¼‰ã‚’ææ¡ˆã—ã€LLMã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸæŒ‡ç¤ºå€™è£œã®ãƒ—ãƒ¼ãƒ«ã‹ã‚‰æœ€é©ãªæŒ‡ç¤ºã‚’é¸æŠã™ã‚‹ãŸã‚ã«æœ€é©åŒ–ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€APEãŒå¾“æ¥ã®LLMãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€19/24ã®ã‚¿ã‚¹ã‚¯ã§äººé–“ã®ç”Ÿæˆã—ãŸæŒ‡ç¤ºã¨åŒç­‰ã¾ãŸã¯å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚APEã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã ã‘ã§ãªãã€ãƒ•ãƒ¥ãƒ¼ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚‚å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚è©³ç´°ã¯ã€https://sites.google.com/view/automatic-prompt-engineerã‚’ã”è¦§ãã ã•ã„ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µã‚¤ãƒˆ: 


<a href="https://sites.google.com/view/automatic-prompt-engineer" target="_blank" rel="noopener noreferrer">https://sites.google.com/view/automatic-prompt-engineer</a>


</p>
<p>openreview: 


<a href="https://openreview.net/forum?id=92gvk82DE-" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=92gvk82DE-</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1030" target="_blank" rel="noopener noreferrer" class="title-link">Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language  Models, Bilgehan Sel+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€æ–°ã—ã„æˆ¦ç•¥ã€ŒAlgorithm of Thoughtsã€ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚ã“ã®æˆ¦ç•¥ã§ã¯ã€LLMsã‚’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çš„ãªæ¨è«–çµŒè·¯ã«å°ãã€ã‚ãšã‹1ã¤ã¾ãŸã¯æ•°å€‹ã®ã‚¯ã‚¨ãƒªã§ã‚¢ã‚¤ãƒ‡ã‚¢ã®æ¢ç´¢ã‚’æ‹¡å¤§ã™ã‚‹ã€‚ã“ã®æ‰‹æ³•ã¯ã€ä»¥å‰ã®å˜ä¸€ã‚¯ã‚¨ãƒªæ‰‹æ³•ã‚’ä¸Šå›ã‚Šã€ãƒãƒ«ãƒã‚¯ã‚¨ãƒªæˆ¦ç•¥ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã€‚ã¾ãŸã€LLMã‚’æŒ‡å°ã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è‡ªä½“ã‚’ä¸Šå›ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¾—ã‚‰ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã€LLMãŒæœ€é©åŒ–ã•ã‚ŒãŸæ¤œç´¢ã«è‡ªå·±ã®ç›´æ„Ÿã‚’ç¹”ã‚Šè¾¼ã‚€èƒ½åŠ›ã‚’æŒã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2023-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1028" target="_blank" rel="noopener noreferrer" class="title-link">A Survey on Large Language Model based Autonomous Agents, Lei Wang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç ”ç©¶ã¯ã€ä»¥å‰ã¯é™ã‚‰ã‚ŒãŸçŸ¥è­˜ã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã—ãŸãŒã€æœ€è¿‘ã§ã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’æ´»ç”¨ã—ãŸç ”ç©¶ãŒå¢—ãˆã¦ã„ã¾ã™ã€‚æœ¬è«–æ–‡ã§ã¯ã€LLMã«åŸºã¥ãè‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç ”ç©¶ã‚’åŒ…æ‹¬çš„ã«èª¿æŸ»ã—ã€çµ±ä¸€ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚ã•ã‚‰ã«ã€LLMã«åŸºã¥ãAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¿œç”¨ã‚„è©•ä¾¡æˆ¦ç•¥ã«ã¤ã„ã¦ã‚‚ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚å°†æ¥ã®æ–¹å‘æ€§ã‚„èª²é¡Œã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã€é–¢é€£ã™ã‚‹å‚è€ƒæ–‡çŒ®ã®ãƒªãƒã‚¸ãƒˆãƒªã‚‚æä¾›ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c921a960-02f7-44e6-8c24-bb578f599bbe" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/73c4662b-ca74-41cc-8be5-c76c4aad36c8" alt="image" loading="lazy"></p>
<p>è‰¯ã„ã‚µãƒ¼ãƒ™ã‚¤</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/DataAugmentation.html" target="_blank" rel="noopener noreferrer">#DataAugmentation</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/DataGeneration.html" target="_blank" rel="noopener noreferrer">#DataGeneration</a>
<span class="issue_date">Issue Date: 2023-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1024" target="_blank" rel="noopener noreferrer" class="title-link">Prompt2Model: Generating Deployable Models from Natural Language   Instructions, Vijay Viswanathan+, N_A, EMNLP'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‡ªç„¶è¨€èªã§ã‚¿ã‚¹ã‚¯ã‚’èª¬æ˜ã—ã€ç‰¹å®šã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹æ‰‹æ³•ã§ã‚ã‚‹Prompt2Modelã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚Prompt2Modelã¯ã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æ¤œç´¢ã€LLMsã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç”Ÿæˆã€ãŠã‚ˆã³æ•™å¸«ã‚ã‚Šå¾®èª¿æ•´ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’é€šã˜ã¦è¡Œã‚ã‚Œã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€Prompt2ModelãŒå¼·åŠ›ãªLLMã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼æ€§ã®è©•ä¾¡ã‚‚å¯èƒ½ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚Prompt2Modelã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Dataset Generatorã«ã‚ˆã£ã¦ã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã—ãªã„ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã‚‚æ“¬ä¼¼ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã€ã‹ã¤ãã‚Œã‚’æ—¢å­˜ã®ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã•ã‚‰ã«æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã‚ŒãŒã§ãã‚‹ã®ã¯ã¨ã¦ã‚‚ç´ æ™´ã‚‰ã—ã„ã€‚</p>
<p>Dataset Generatorã«ã¤ã„ã¦ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹éš›ã«ä½ã‚³ã‚¹ãƒˆã§ã€é«˜å“è³ªã§ã€å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ã¨ã™ã‚‹ãŸã‚ã«ã„ãã¤ã‹ã®å·¥å¤«ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚<br>1. ãƒ¦ãƒ¼ã‚¶ãŒä¸ãˆãŸãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã ã‘ã§ãªãã€ã‚·ã‚¹ãƒ†ãƒ ãŒç”Ÿæˆã—ãŸexampleã‚‚ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€ç”Ÿæˆã•ã‚Œã‚‹exampleã®å¤šæ§˜æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿéš›ã€ã“ã‚Œã‚’ã‚„ã‚‰ãªã„å ´åˆã¯120/200ãŒduplicate exampleã§ã‚ã£ãŸãŒã€ã“ã‚ŒãŒ25/200ã¾ã§æ¸›å°‘ã—ãŸã€‚<br>2. ç”Ÿæˆã—ãŸã‚µãƒ³ãƒ—ãƒ«ã®æ•°ã«æ¯”ä¾‹ã—ã¦ã€temperatureã‚’å¾ã€…ã«é«˜ãã—ã¦ã„ãã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚µãƒ³ãƒ—ãƒ«ã®è³ªã‚’æ‹…ä¿ã—ã¤ã¤ã€å¤šæ§˜æ€§ã‚’å¾ã€…ã«å¢—åŠ ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚Temperature Annealingã¨å‘¼ã¶ã€‚<br>3. self-consistencyã‚’ç”¨ã„ã¦ã€æ“¬ä¼¼ãƒ©ãƒ™ãƒ«ã®è³ªã‚’é«˜ã‚ã‚‹ã€‚ã‚‚ã—majority votingãŒäº’è§’ã®å ´åˆã¯ã€å›ç­”ãŒçŸ­ã„ã‚‚ã®ã‚’æ¡ç”¨ã—ãŸï¼ˆã“ã‚Œã¯ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã«åŸºã¥ã„ã¦ã„ã‚‹ï¼‰<br>4. zeno buildã‚’ç”¨ã„ã¦APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä¸¦åˆ—åŒ–ã™ã‚‹ã“ã¨ã§é«˜é€Ÿã«å®Ÿé¨“ã‚’å®Ÿæ–½<br><br>éå¸¸ã«å‚è€ƒã«ãªã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Bias.html" target="_blank" rel="noopener noreferrer">#Bias</a>
<span class="issue_date">Issue Date: 2023-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1023" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models Sensitivity to The Order of Options in  Multiple-Choice Questions, Pouya Pezeshkpour+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®é ‘å¥æ€§ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚LLMsã¯å¤šè‚¢é¸æŠå•é¡Œã«ãŠã„ã¦é †åºã«æ•æ„Ÿã§ã‚ã‚Šã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®é…ç½®ã«ã‚ˆã£ã¦æ€§èƒ½ã«å¤§ããªå·®ãŒç”Ÿã˜ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®é…ç½®ã«å¯¾ã™ã‚‹ãƒã‚¤ã‚¢ã‚¹ã‚’å¢—å¹…ã¾ãŸã¯è»½æ¸›ã™ã‚‹æ–¹æ³•ã‚’ç‰¹å®šã—ã€LLMsã®äºˆæ¸¬ã‚’æ”¹å–„ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¾ã—ãŸã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æœ€å¤§8ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆãƒã‚¤ãƒ³ãƒˆã®æ”¹å–„ãŒå®Ÿç¾ã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ã“ã‚Œã¯ãã†ã ã‚ã†ãªã¨æ€ã£ã¦ã„ãŸã‘ã©ã€ã“ã“ã¾ã§æ€§èƒ½ã«å·®ãŒå‡ºã‚‹ã¨ã¯æ€ã‚ãªã‹ã£ãŸã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fb13c25c-4d76-4c8c-b08a-6491c43f34b9" alt="image" loading="lazy"></p>
<p>ã“ã‚ŒãŒã‚‚ã—LLMã®ãƒã‚¤ã‚¢ã‚¹ã«ã‚ˆã‚‹ã‚‚ã®ï¼ˆ2ç•ªç›®ã®é¸æŠè‚¢ã«æ­£è§£ãŒå¤šã„ï¼‰ã®å ´åˆã€<br>ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚½ãƒ¼ãƒˆã—ãŸã‚Šã€å¹³å‡å–ã£ãŸã‚Šã—ã¦ã‚‚ã€ãã‚‚ãã‚‚ã®æ­£è§£ã«å¸¸ã«ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã£ã¦ã„ã‚‹ã®ã§ã€<br>çµå±€ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã£ãŸçµæœã—ã‹å‡ºãªã„ã®ã§ã¯ã€ã¨æ€ã£ã¦ã—ã¾ã†ã€‚<br>ãã†ãªã‚‹ã¨ã€æœ‰åŠ¹ãªã®ã¯one vs. restã¿ãŸã„ã«ã€å…¨éƒ¨è©²å½“é¸æŠè‚¢ã«å¯¾ã—ã¦yes/noã§ç­”ãˆã•ã›ã¦ãã‚Œã‚’é›†ç´„ã•ã›ã‚‹ã€ã¿ãŸã„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ–¹ãŒè‰¯ã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1020" target="_blank" rel="noopener noreferrer" class="title-link">AgentBench: Evaluating LLMs as Agents, Xiao Liu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦è©•ä¾¡ã™ã‚‹ãŸã‚ã®å¤šæ¬¡å…ƒã®é€²åŒ–ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒAgentBenchã€ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚AgentBenchã¯ã€8ã¤ã®ç•°ãªã‚‹ç’°å¢ƒã§ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ã®ç”Ÿæˆè¨­å®šã‚’æä¾›ã—ã€LLMã®æ¨è«–ã¨æ„æ€æ±ºå®šèƒ½åŠ›ã‚’è©•ä¾¡ã—ã¾ã™ã€‚25ã®LLMsã«å¯¾ã™ã‚‹ãƒ†ã‚¹ãƒˆã§ã¯ã€å•†ç”¨LLMsã¯å¼·åŠ›ãªèƒ½åŠ›ã‚’ç¤ºã—ã¦ã„ã¾ã™ãŒã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ç«¶åˆä»–ç¤¾ã¨ã®æ€§èƒ½ã«ã¯å·®ãŒã‚ã‚Šã¾ã™ã€‚AgentBenchã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ç’°å¢ƒã€ãŠã‚ˆã³è©•ä¾¡ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¯ã€GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦ã®LLMã®æ¨è«–èƒ½åŠ›ã¨æ„æ€æ±ºå®šèƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã€‚<br>ãƒˆãƒƒãƒ—ã®å•†ç”¨LLMã¨OpenSource LLMã®é–“ã«å¤§ããªæ€§èƒ½å·®ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1015" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Model Guided Tree-of-Thought, Jieyi Long, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€Tree-of-Thoughtï¼ˆToTï¼‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç´¹ä»‹ã—ã€è‡ªå·±å›å¸°å‹ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®å•é¡Œè§£æ±ºèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ToTã¯ã€äººé–“ã®æ€è€ƒæ–¹æ³•ã«è§¦ç™ºã•ã‚ŒãŸæŠ€è¡“ã§ã‚ã‚Šã€è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ãƒ„ãƒªãƒ¼çŠ¶ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€LLMã«ãƒ—ãƒ­ãƒ³ãƒ—ã‚¿ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ãƒã‚§ãƒƒã‚«ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€ãƒ¡ãƒ¢ãƒªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€ãŠã‚ˆã³ToTã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ãªã©ã®è¿½åŠ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§å®Ÿç¾ã•ã‚Œã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ToTãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒSudokuãƒ‘ã‚ºãƒ«ã®è§£æ±ºæˆåŠŸç‡ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1013" target="_blank" rel="noopener noreferrer" class="title-link">Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding, Yuxi Xie+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€æ¨è«–ã®å“è³ªã¨å¤šæ§˜æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®åŠ¹æœçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¾ã—ãŸã€‚è‡ªå·±è©•ä¾¡ã«ã‚ˆã‚‹ã‚¬ã‚¤ãƒ‰ä»˜ãç¢ºç‡çš„ãƒ“ãƒ¼ãƒ ã‚µãƒ¼ãƒã‚’ä½¿ç”¨ã—ã¦ã€GSM8Kã€AQuAã€ãŠã‚ˆã³StrategyQAã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é«˜ã„ç²¾åº¦ã‚’é”æˆã—ã¾ã—ãŸã€‚ã¾ãŸã€è«–ç†ã®å¤±æ•—ã‚’ç‰¹å®šã—ã€ä¸€è²«æ€§ã¨å …ç‰¢æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚‚ã§ãã¾ã—ãŸã€‚è©³ç´°ãªã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8bd4a19e-e7e6-444f-9394-36e261e5219a" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1012" target="_blank" rel="noopener noreferrer" class="title-link">Graph of Thoughts: Solving Elaborate Problems with Large Language Models, Maciej Besta+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€Graph of Thoughtsï¼ˆGoTï¼‰ã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç´¹ä»‹ã—ã¾ã—ãŸã€‚ã“ã‚Œã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°èƒ½åŠ›ã‚’é€²åŒ–ã•ã›ã‚‹ã‚‚ã®ã§ã€ä»»æ„ã®ã‚°ãƒ©ãƒ•ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åŒ–ã§ãã‚‹ã“ã¨ãŒç‰¹å¾´ã§ã™ã€‚GoTã¯ã€æ€è€ƒã®çµ„ã¿åˆã‚ã›ã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å…¨ä½“ã®æœ¬è³ªã®æŠ½å‡ºã€æ€è€ƒã®å¼·åŒ–ãªã©ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®æ‰‹æ³•ã«æ¯”ã¹ã¦åˆ©ç‚¹ã‚’æä¾›ã—ã€LLMã®æ¨è«–ã‚’äººé–“ã®æ€è€ƒã«è¿‘ã¥ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Chain of Thought <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
 <br><br>=&gt; Self-consistency <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/558" target="_blank" rel="noopener noreferrer">Self-consistency improves chain of thought reasoning in language models, Wang+, Google Research, ICLR'23</a>
 <br><br>=&gt; Thought Decomposition <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1013" target="_blank" rel="noopener noreferrer">Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding, Yuxi Xie+, N/A, arXiv'23</a>
 <br><br>=&gt; Tree of Thoughts <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/684" target="_blank" rel="noopener noreferrer">Tree of Thoughts: Deliberate Problem Solving with Large Language Models, Shunyu Yao+, N/A, arXiv'23</a>
 Tree of Thought <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1015" target="_blank" rel="noopener noreferrer">Large Language Model Guided Tree-of-Thought, Jieyi Long, N/A, arXiv'23</a>
 <br><br>=&gt; Graph of Thought</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1010" target="_blank" rel="noopener noreferrer" class="title-link">Consciousness in Artificial Intelligence: Insights from the Science of  Consciousness, Patrick Butlin+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- AIã®æ„è­˜ã«ã¤ã„ã¦ã®å³å¯†ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€æ—¢å­˜ã®AIã‚·ã‚¹ãƒ†ãƒ ã‚’ç¥çµŒç§‘å­¦çš„ãªæ„è­˜ç†è«–ã«åŸºã¥ã„ã¦è©•ä¾¡ã™ã‚‹ã€‚æ„è­˜ã®æŒ‡æ¨™çš„ç‰¹æ€§ã‚’å°ãå‡ºã—ã€æœ€è¿‘ã®AIã‚·ã‚¹ãƒ†ãƒ ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ã§ã€ç¾åœ¨ã®AIã‚·ã‚¹ãƒ†ãƒ ã¯æ„è­˜çš„ã§ã¯ãªã„ãŒã€æ„è­˜çš„ãªAIã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®éšœå£ã¯å­˜åœ¨ã—ãªã„ã“ã¨ã‚’ç¤ºå”†ã™ã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2023-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1008" target="_blank" rel="noopener noreferrer" class="title-link">Self-Alignment with Instruction Backtranslation, Xian Li+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€é«˜å“è³ªãªæŒ‡ç¤ºã«å¾“ã†è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªæ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã§ã¯ã€å°‘é‡ã®ã‚·ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã¨ã‚¦ã‚§ãƒ–ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€æŒ‡ç¤ºã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚ãã—ã¦ã€é«˜å“è³ªãªä¾‹ã‚’é¸æŠã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å¼·åŒ–ã—ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã€è‡ªå·±æ•´åˆ—ã®åŠ¹æœã‚’å®Ÿè¨¼ã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>äººé–“ãŒæ›¸ã„ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å¯¾å¿œã™ã‚‹instructionã«è‡ªå‹•çš„ã«ãƒ©ãƒ™ãƒ«ä»˜ã‘ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚<br>ã“ã‚Œã«ã‚ˆã‚Šé«˜å“è³ªãªinstruction following LLMã®æ§‹ç¯‰ãŒå¯èƒ½</p>
<p>æ‰‹æ³•æ¦‚è¦<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/837e17cc-6df1-4ba5-ba61-9c4f72dede93" alt="image" loading="lazy"></p>
<p>çµæœçš„ã«å¾—ã‚‰ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã¯ã€è¨“ç·´ã«ãŠã„ã¦éå¸¸ã«ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒã‚ã‚Šé«˜å“è³ªãªã‚‚ã®ã¨ãªã‚‹ã€‚<br>å®Ÿéš›ã«ã€ä»–ã®åŒã‚µã‚¤ã‚ºã®instruct tuningãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¸Šå›ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ef478922-8495-4a5f-9bc6-3d5bed7195a8" alt="image" loading="lazy"></p>
<p>Humpackã¯ä»–ã®strong modelã‹ã‚‰distillã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§æœ€é«˜æ€§èƒ½ã‚’é”æˆã€‚ã“ã‚Œã¯ã€ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã—ãŸã‚Šã€ã‚ˆã‚Šå¼·ã„ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†ãªã©ã•ã‚‰ãªã‚‹æ€§èƒ½å‘ä¸ŠãŒã§ãã‚‹ä½™åœ°ãŒæ®‹ã•ã‚Œã¦ã„ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cd7ff8b5-62a4-46fe-a902-cbe8e9ffec4a" alt="image" loading="lazy"></p>
<p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1694103441432580377?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>æŒ‡ç¤ºã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ã€ä»Šå›ã¯LLaMAã‚’finetuningã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãŠã‚Šã€äºˆæ¸¬ã¨å‘¼ç§°ã—ã¦ã„ã‚‹ãŒæŒ‡ç¤ºã¯generationã•ã‚Œã‚‹ã€‚</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/PersonalizedGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedGeneration</a>
<span class="issue_date">Issue Date: 2023-08-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1005" target="_blank" rel="noopener noreferrer" class="title-link">Teach LLMs to Personalize -- An Approach inspired by Writing Education, Cheng Li+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å€‹åˆ¥åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ãŠã„ã¦ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ãŸä¸€èˆ¬çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã™ã‚‹ã€‚æ•™è‚²ã®åŸ·ç­†ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€å¤šæ®µéšã‹ã¤ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é–‹ç™ºã—ã€æ¤œç´¢ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€è¦ç´„ã€çµ±åˆã€ç”Ÿæˆã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§æ§‹æˆã•ã‚Œã‚‹å€‹åˆ¥åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã¸ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã™ã‚‹ã€‚ã•ã‚‰ã«ã€ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯è¨­å®šã‚’å°å…¥ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®ç”Ÿæˆèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚3ã¤ã®å…¬é–‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®è©•ä¾¡çµæœã¯ã€ä»–ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«æ¯”ã¹ã¦å¤§å¹…ãªæ”¹å–„ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç ”ç©¶ã®ç›®çš„ã¨ã—ã¦ã¯ã€ãƒ¦ãƒ¼ã‚¶ãŒç¾åœ¨åŸ·ç­†ã—ã¦ã„ã‚‹documentã®writingæ”¯æ´</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultitaskLearning.html" target="_blank" rel="noopener noreferrer">#MultitaskLearning</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/CrossLingual.html" target="_blank" rel="noopener noreferrer">#CrossLingual</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/999" target="_blank" rel="noopener noreferrer" class="title-link">Crosslingual Generalization through Multitask Finetuning, Niklas Muennighoff+, N_A, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚£ãƒãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆMTFï¼‰ã¯ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ãŒæ–°ã—ã„ã‚¿ã‚¹ã‚¯ã«æ±åŒ–ã™ã‚‹ã®ã«å½¹ç«‹ã¤ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«BLOOMã¨mT5ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦MTFã‚’å®Ÿæ–½ã—ã€è‹±èªã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦è‹±èªãŠã‚ˆã³éè‹±èªã®ã‚¿ã‚¹ã‚¯ã«ãƒ•ã‚£ãƒãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ã‚¿ã‚¹ã‚¯ã®æ±åŒ–ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€æ©Ÿæ¢°ç¿»è¨³ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãªã‚¿ã‚¹ã‚¯ã«ãƒ•ã‚£ãƒãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã‚‚èª¿æŸ»ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®æ±åŒ–èƒ½åŠ›ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€46è¨€èªã®æ•™å¸«ã‚ã‚Šãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚³ãƒ³ãƒã‚¸ãƒƒãƒˆã§ã‚ã‚‹xP3ã‚‚ç´¹ä»‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>è‹±èªã‚¿ã‚¹ã‚¯ã‚’è‹±èªã§promptingã—ã¦LLMã‚’Finetuningã™ã‚‹ã¨ã€ä»–ã®è¨€èªï¼ˆãŸã ã—ã€äº‹å‰å­¦ç¿’ã§åˆ©ç”¨ã—ãŸã‚³ãƒ¼ãƒ‘ã‚¹ã«å‡ºç¾ã™ã‚‹è¨€èªã«é™ã‚‹ï¼‰ã§æ±åŒ–ã—æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸæ¨¡æ§˜ã€‚<br>![Image](https://github.com/user-attachments/assets/44e9cf6e-e80f-4092-af46-ad74c30fe59c)</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/931" target="_blank" rel="noopener noreferrer" class="title-link">Metacognitive Prompting Improves Understanding in Large Language Models, Yuqing Wang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMsã«ãƒ¡ã‚¿èªçŸ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆMPï¼‰ã‚’å°å…¥ã—ã€äººé–“ã®å†…çœçš„ãªæ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ¨¡å€£ã™ã‚‹ã“ã¨ã§ã€ç†è§£èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€MPã‚’å‚™ãˆãŸPaLMãŒä»–ã®ãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¦ãŠã‚Šã€MPãŒæ—¢å­˜ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€LLMsã®ç†è§£èƒ½åŠ›å‘ä¸Šã®å¯èƒ½æ€§ã‚’ç¤ºã—ã€äººé–“ã®å†…çœçš„ãªæ¨è«–ã‚’æ¨¡å€£ã™ã‚‹ã“ã¨ã®åˆ©ç‚¹ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>CoTã‚ˆã‚Šä¸€è²«ã—ã¦æ€§èƒ½ãŒé«˜ã„ã®ã§æ¬¡ã®ãƒ‡ãƒ•ã‚¡ã‚¯ãƒˆã«ãªã‚‹å¯èƒ½æ€§ã‚ã‚Š<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8ca3a369-925b-44be-9d63-e3150137ff6b" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d3b980e0-4402-4a32-96ee-684da7f3a487" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/923" target="_blank" rel="noopener noreferrer" class="title-link">The Hydra Effect: Emergent Self-repair in Language Model Computations, Thomas McGrath+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨æ§‹é€ ã‚’èª¿æŸ»ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®è¨ˆç®—ã«ãŠã‘ã‚‹ç‰¹å®šã®åŠ¹æœã‚’ç¤ºã—ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€1ã¤ã®å±¤ã®å‰Šé™¤ãŒä»–ã®å±¤ã«ã‚ˆã£ã¦è£œå®Œã•ã‚Œã‚‹ã€ŒHydraåŠ¹æœã€ã¨ã€é…ã„MLPå±¤ãŒæœ€å¤§å°¤åº¦ãƒˆãƒ¼ã‚¯ãƒ³ã‚’åˆ¶å¾¡ã™ã‚‹å½¹å‰²ã‚’æŒã¤ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’ä½¿ç”¨ã—ãªã„è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚‚åŒæ§˜ã®åŠ¹æœãŒè¦‹ã‚‰ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã“ã‚Œã‚‰ã®åŠ¹æœã‚’äº‹å®Ÿã®å›æƒ³ã®æ–‡è„ˆã§åˆ†æã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®å›è·¯ãƒ¬ãƒ™ãƒ«ã®å±æ€§ä»˜ä¸ã«ã¤ã„ã¦è€ƒå¯Ÿã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã‹ã‚‰attention layerã‚’ä¸€ã¤å–ã‚Šé™¤ãã¨ã€å¾Œç¶šã®å±¤ãŒå–ã‚Šé™¤ã‹ã‚ŒãŸlayerã®æ©Ÿèƒ½ã‚’å¼•ãç¶™ãã‚ˆã†ãªåƒãã‚’ã™ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã“ã‚Œã¯LLMã®è‡ªå·±ä¿®å¾©æ©Ÿèƒ½ã®ã‚ˆã†ãªã‚‚ã®ã§ã‚ã‚Šã€HydraEffectã¨å‘½åã•ã‚ŒãŸã€‚</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/922" target="_blank" rel="noopener noreferrer" class="title-link">MetaGPT: Meta Programming for Multi-Agent Collaborative Framework, Sirui Hong+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ãŸãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è‡ªå‹•ã‚¿ã‚¹ã‚¯è§£æ±ºã«ãŠã‘ã‚‹é€²æ­©ã«ã¤ã„ã¦èª¿æŸ»ã—ã¾ã—ãŸã€‚æ—¢å­˜ã®ç ”ç©¶ã§ã¯å˜ç´”ãªã‚¿ã‚¹ã‚¯ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹æ¢ç´¢ã‚„èª¿æŸ»ãŒä¸è¶³ã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ãã“ã§ã€MetaGPTã¨ã„ã†é©æ–°çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚MetaGPTã¯ã€äººé–“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’LLMã«çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å”åŠ›ã‚’åŠ¹æœçš„ã«æ”¯æ´ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã‹ã‚‰ã€MetaGPTãŒæ—¢å­˜ã®ã‚·ã‚¹ãƒ†ãƒ ã«æ¯”ã¹ã¦ã‚ˆã‚Šé«˜ã„çµæŸæ€§ã‚’æŒã¤è§£æ±ºç­–ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã“ã‚Œã¯ã€ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«äººé–“ã®ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã®æ½œåœ¨èƒ½åŠ›ã‚’ç¤ºã—ã€æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å¯èƒ½æ€§ã‚’é–‹æ‹“ã™ã‚‹ã‚‚ã®ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>è¦ã¯BabyTalk, AutoGPTã®é€²åŒ–ç³»ã§ã€äººé–“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ¨¡å€£ã™ã‚‹ã‚ˆã†ã«ãƒ‡ã‚¶ã‚¤ãƒ³ã—ãŸã‚‰è‰¯ããªã‚Šã¾ã—ãŸã€ã¨ã„ã†è©±ã¨æ€ã‚ã‚Œã‚‹<br><br>ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆã€ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã‚ªãƒ¼ãƒŠãƒ¼ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãªã©ã®ãƒ­ãƒ¼ãƒ«ã‚’æ˜ç¤ºçš„ã«ä¸ãˆã¦ã€ã‚´ãƒ¼ãƒ«ã‚’ç›®æŒ‡ã™ã€‚ã‚‚ã¯ã‚„LLMå†…éƒ¨ã§ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ä¼æ¥­ã‚’æ¨¡å€£ã—ã¦ã„ã‚‹ã®ã¨åŒæ§˜ã§ã‚ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/921" target="_blank" rel="noopener noreferrer" class="title-link">Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding, Xuefei Ning+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ç”Ÿæˆé…å»¶ã‚’æ¸›ã‚‰ã™ãŸã‚ã«ã€æ€è€ƒã®éª¨çµ„ã¿ï¼ˆSoTï¼‰ã¨ã„ã†æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚SoTã¯ã€å›ç­”ã®éª¨çµ„ã¿ã‚’ã¾ãšç”Ÿæˆã—ã€ãã®å¾Œã«å†…å®¹ã‚’ä¸¦åˆ—ã§å‡¦ç†ã™ã‚‹ã“ã¨ã§é«˜é€ŸåŒ–ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ã¾ãŸã€å›ç­”å“è³ªã®å‘ä¸Šã‚‚æœŸå¾…ã•ã‚Œã¾ã™ã€‚SoTã¯ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒã®æœ€é©åŒ–ã®åˆã‚ã®è©¦ã¿ã§ã‚ã‚Šã€LLMsã®äººé–“ã‚‰ã—ã„æ€è€ƒã‚’å¯èƒ½ã«ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æœ€åˆã«å›ç­”ã®æ çµ„ã¿ã ã‘ç”Ÿæˆã—ã¦ã€ãã‚Œãã‚Œã®å†…å®¹ã‚’ä¸¦åˆ—ã§å‡ºåŠ›ã•ã›ã‚‹ã“ã¨ã§ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’é«˜é€ŸåŒ–ã—ã¾ã—ã‚‡ã†ã€ã¨ã„ã†è©±ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fb25d8ba-dff7-4f6f-be25-0973488f6e8a" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/920" target="_blank" rel="noopener noreferrer" class="title-link">ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world  APIs, Yujia Qin+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ï¼ˆAPIï¼‰ã®é«˜åº¦ãªã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œã‚’å®¹æ˜“ã«ã™ã‚‹ãŸã‚ã®ToolLLMã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚ToolBenchã¨ã„ã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã€ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨æ–¹æ³•ã‚’èª¿æ•´ã—ã€DFSDTã¨ã„ã†æ±ºå®šæœ¨ã‚’ä½¿ç”¨ã—ã¦åŠ¹ç‡çš„ãªæ¤œç´¢ã‚’è¡Œã„ã¾ã™ã€‚ToolEvalã¨ã„ã†è‡ªå‹•è©•ä¾¡ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€ToolLLaMAãŒé«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ã•ã‚‰ã«ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«APIãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã€é©åˆ‡ãªAPIã‚’æ¨å¥¨ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>16000ã®real worldã®APIã¨ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã—ã€ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã€è¨“ç·´ã€è©•ä¾¡ãªã©ã‚’ä¸€è²«ã—ã¦ã§ãã‚‹ã‚ˆã†ã«ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚LLaMAã‚’ä½¿ã£ãŸå ´åˆã€ãƒ„ãƒ¼ãƒ«åˆ©ç”¨ã«é–¢ã—ã¦turbo-16kã¨åŒç­‰ã®æ€§èƒ½ã«é”ã—ãŸã¨ä¸»å¼µã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a9c394b5-6148-4bab-acaa-4934ead5c1a7" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/919" target="_blank" rel="noopener noreferrer" class="title-link">Open Problems and Fundamental Limitations of Reinforcement Learning from  Human Feedback, Stephen Casper+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‹ã‚‰ã®å¼·åŒ–å­¦ç¿’ï¼ˆRLHFï¼‰ã¯ã€AIã‚·ã‚¹ãƒ†ãƒ ã‚’äººé–“ã®ç›®æ¨™ã«åˆã‚ã›ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®æŠ€è¡“ã§ã‚ã‚Šã€æœ€å…ˆç«¯ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’å¾®èª¿æ•´ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€RLHFã®æ¬ ç‚¹ã‚’ä½“ç³»åŒ–ã™ã‚‹ãŸã‚ã®å…¬é–‹ã•ã‚ŒãŸç ”ç©¶ã¯å°‘ãªã„ã€‚æœ¬è«–æ–‡ã§ã¯ã€RLHFã®ã‚ªãƒ¼ãƒ—ãƒ³ãªå•é¡Œã¨åˆ¶ç´„ã‚’èª¿æŸ»ã—ã€å®Ÿè·µã«ãŠã‘ã‚‹ç†è§£ã€æ”¹å–„ã€è£œå®ŒæŠ€è¡“ã‚’æ¦‚èª¬ã—ã€RLHFã‚·ã‚¹ãƒ†ãƒ ã®ç¤¾ä¼šçš„ãªç›£è¦–ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®ç›£æŸ»ã¨é–‹ç¤ºã®åŸºæº–ã‚’ææ¡ˆã™ã‚‹ã€‚ã“ã®ç ”ç©¶ã¯ã€RLHFã®åˆ¶ç´„ã‚’å¼·èª¿ã—ã€å®‰å…¨ãªAIã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã«å¤šé¢çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/918" target="_blank" rel="noopener noreferrer" class="title-link">Aligning Large Language Models with Human: A Survey, Yufei Wang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€è‡ªç„¶è¨€èªå‡¦ç†ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¦ã„ã¾ã™ãŒã€ãã®æ€§èƒ½ã«ã¯åˆ¶ç´„ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®èª¿æŸ»ã§ã¯ã€LLMsã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆæŠ€è¡“ã«ã¤ã„ã¦åŒ…æ‹¬çš„ãªæ¦‚è¦ã‚’æä¾›ã—ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ãƒ‡ãƒ¼ã‚¿åé›†æ–¹æ³•ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã€ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æ–¹æ³•ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€å°†æ¥ã®ç ”ç©¶ã®æ–¹å‘æ€§ã«ã¤ã„ã¦ã‚‚ã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®èª¿æŸ»ã¯ã€LLMsã®æ€§èƒ½å‘ä¸Šã«é–¢å¿ƒã®ã‚ã‚‹äººã€…ã«ã¨ã£ã¦è²´é‡ãªæƒ…å ±æºã¨ãªã‚‹ã§ã—ã‚‡ã†ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®Alignmentæ‰‹æ³•ã«é–¢ã™ã‚‹Survey<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6c5288c8-7f5b-4526-ba6f-25c2b9b3fc55" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/916" target="_blank" rel="noopener noreferrer" class="title-link">L-Eval: Instituting Standardized Evaluation for Long Context Language  Models, Chenxin An+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- é•·ã„æ–‡è„ˆã®è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLCLMï¼‰ã®è©•ä¾¡ã‚’æ¨™æº–åŒ–ã™ã‚‹ãŸã‚ã«ã€L-Evalã¨ã„ã†è©•ä¾¡ã‚¹ã‚¤ãƒ¼ãƒˆã‚’ææ¡ˆã—ã¾ã—ãŸã€‚L-Evalã«ã¯411ã®é•·ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨2,000ä»¥ä¸Šã®äººé–“ã«ã‚ˆã‚‹ã‚¯ã‚¨ãƒª-ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒšã‚¢ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€å¤šæ§˜ãªè©•ä¾¡æ–¹æ³•ã¨æŒ‡ç¤ºã‚¹ã‚¿ã‚¤ãƒ«ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã¯å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦é…ã‚Œã¦ã„ã¾ã™ãŒã€é€šå¸¸ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨æ¯”è¼ƒã—ã¦ã‚‚å°è±¡çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚LCLMã®ç”Ÿæˆçµæœã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>long contextã«å¯¾ã™ã‚‹LLMã®è©•ä¾¡ã‚»ãƒƒãƒˆã€‚411ã®long documentã«å¯¾ã™ã‚‹2kã®query-response pairã®ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã€‚æ³•å¾‹ã€fainance, school lectures, é•·æ–‡å¯¾è©±ã€å°èª¬ã€ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãªã©ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ã‚‰æˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-08-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/913" target="_blank" rel="noopener noreferrer" class="title-link">Do Multilingual Language Models Think Better in English?, Julen Etxaniz+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- self-translateã¯ã€ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ã®å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆç¿»è¨³èƒ½åŠ›ã‚’æ´»ç”¨ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚Šã€å¤–éƒ¨ã®ç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ ã®å¿…è¦æ€§ã‚’å…‹æœã™ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€self-translateãŒç›´æ¥æ¨è«–ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€éè‹±èªã®è¨€èªã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã•ã‚ŒãŸå ´åˆã«ã‚‚æœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ã‚³ãƒ¼ãƒ‰ã¯https://github.com/juletx/self-translateã§åˆ©ç”¨å¯èƒ½ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imai_eruel/status/1687735268311511040?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/65a44946-c82b-4895-9ce9-c48792e09b3e" alt="image" loading="lazy"><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/86ff0cbb-7fac-4ba2-bf11-652b80db0fe5" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2023-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/911" target="_blank" rel="noopener noreferrer" class="title-link">LLM-Rec: Personalized Recommendation via Prompting Large Language Models, Hanjia Lyu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã‚’ç”¨ã„ãŸãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¨è–¦ã®ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ã‚’èª¿æŸ»ã—ã€LLM-Recã¨ã„ã†ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ãŸã€‚å®Ÿé¨“ã®çµæœã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸLLMã«ã‚ˆã‚‹æ‹¡å¼µå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã¨å…ƒã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®èª¬æ˜ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€æ¨è–¦ã®æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã¯ã€å¤šæ§˜ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨å…¥åŠ›æ‹¡å¼µæŠ€è¡“ãŒãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¨è–¦ã®èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ä¸Šã§é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®promptingã®æ–¹æ³•ã‚’å¤‰æ›´ã—content descriptionã ã‘ã§ãªãã€æ§˜ã€…ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®è¿½åŠ ï¼ˆe.g. ã“ã®descriptionã‚’æ¨è–¦ã™ã‚‹ãªã‚‰ã©ã†ã„ã†äººã«ãŠã™ã™ã‚ï¼Ÿã€ã‚¢ã‚¤ãƒ†ãƒ é–“ã®å…±é€šé …ã‚’è¦‹ã¤ã‘ã‚‹ï¼‰ã€å†…å®¹ã®æ‹¡å¼µç­‰ã‚’è¡Œã„ã‚³ãƒ³ãƒ†ãƒ³ãƒˆã‚’æ‹¡å¼µã—ã¦æ´»ç”¨ã™ã‚‹ã¨ã„ã†è©±ã£ã½ã„ã€‚WIP</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-07-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/905" target="_blank" rel="noopener noreferrer" class="title-link">FrugalGPT: How to Use Large Language Models While Reducing Cost and  Improving Performance, Lingjiao Chen+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ä½¿ç”¨ã«ã¯é«˜ã„ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ãŸã‚ã€LLMsã®æ¨è«–ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã™ã‚‹ãŸã‚ã®3ã¤ã®æˆ¦ç•¥ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é©å¿œã€LLMã®è¿‘ä¼¼ã€LLMã®ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ï¼‰ã‚’ææ¡ˆã™ã‚‹ã€‚FrugalGPTã¨ã„ã†å…·ä½“çš„ãªæ‰‹æ³•ã‚’ç´¹ä»‹ã—ã€æœ€å¤§98ï¼…ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ã¨4ï¼…ã®ç²¾åº¦å‘ä¸Šã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã®æŒç¶šå¯èƒ½ãªä½¿ç”¨ãŒå¯èƒ½ã¨ãªã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>é™ã‚‰ã‚ŒãŸäºˆç®—ã®ä¸­ã§ã€ã„ã‹ã«è¤‡æ•°ã®LLM APIã‚’ä½¿ã„ã€å®‰ã„ã‚³ã‚¹ãƒˆã§é«˜ã„æ€§èƒ½ã‚’é”æˆã™ã‚‹ã‹ã‚’è¿½æ±‚ã—ãŸç ”ç©¶ã€‚<br><br>LLM Cascadeãªã©ã¯ã“ã®æ çµ„ã¿ã§ãªãã¦ã‚‚è‰²ã€…ã¨ä½¿ã„é“ãŒã‚ã‚Šãã†ã€‚Question Concatenationã¯å®Ÿè³ªBatch Promptingã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-07-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/903" target="_blank" rel="noopener noreferrer" class="title-link">Judging LLM-as-a-judge with MT-Bench and Chatbot Arena, Lianmin Zheng+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã‚’åˆ¤å®šè€…ã¨ã—ã¦ä½¿ç”¨ã—ã¦ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ã®è³ªå•ã«å¯¾ã™ã‚‹æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚LLMã®åˆ¶é™ã‚„å•é¡Œã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®è§£æ±ºç­–ã‚’ææ¡ˆã—ã€2ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§LLMã®åˆ¤å®šè€…ã¨äººé–“ã®å¥½ã¿ã®ä¸€è‡´ã‚’æ¤œè¨¼ã™ã‚‹ã€‚çµæœã¯ã€å¼·åŠ›ãªLLMåˆ¤å®šè€…ãŒäººé–“ã®å¥½ã¿ã¨ã‚ˆãä¸€è‡´ã—ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§èª¬æ˜å¯èƒ½ãªæ–¹æ³•ã§äººé–“ã®å¥½ã¿ã‚’è¿‘ä¼¼ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã•ã‚‰ã«ã€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨å¾“æ¥ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ç›¸è£œæ€§ã‚’ç¤ºã—ã€ã„ãã¤ã‹ã®ãƒãƒªã‚¢ãƒ³ãƒˆã‚’è©•ä¾¡ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>MT-Benchï¼ˆMTBenchï¼‰ã‚¹ã‚³ã‚¢ã¨ã¯ã€multi-turnã®QAã‚’å‡ºé¡Œã—ã€ãã®å›ç­”ã®è³ªã‚’GPT-4ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ãŸã‚¹ã‚³ã‚¢ã®ã“ã¨ã€‚<br><br>GPT-4ã®åˆ¤æ–­ã¨human expertã®åˆ¤æ–­ã¨ã®agreementã‚‚æ¤œè¨¼ã—ã¦ãŠã‚Šã€agreementã¯80%ä»¥ä¸Šã‚’é”æˆã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/20c7782d-8ffe-4328-8526-700e38df23b5" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9f0e1e3a-6b07-4bcc-be78-e42a1c5d2190" alt="image" loading="lazy"><br><br></p>
<p>`LLM-as-a-Judge` ã¨ã„ã†ç”¨èªã‚’æœ€åˆã«æå”±ã—ãŸã®ã‚‚æœ¬ç ”ç©¶ã¨ãªã‚‹ï¼ˆp.2å‚ç…§ï¼‰</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<span class="issue_date">Issue Date: 2023-07-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/897" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction  Tuning, Lili Yu+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- CM3Leonã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã®ç”Ÿæˆãƒ»è£œå®ŒãŒå¯èƒ½ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ«æ‹¡å¼µå‹ã®ãƒˆãƒ¼ã‚¯ãƒ³ãƒ™ãƒ¼ã‚¹ã®ãƒ‡ã‚³ãƒ¼ãƒ€ã‚’ä½¿ç”¨ã€‚CM3ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’åŸºã«ã€å¤šæ§˜ãªæŒ‡ç¤ºã‚¹ã‚¿ã‚¤ãƒ«ã§ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«å„ªã‚Œã€åˆã®ãƒ†ã‚­ã‚¹ãƒˆå°‚ç”¨ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é©å¿œã•ã‚ŒãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€‚é«˜å“è³ªãªå‡ºåŠ›ã‚’ç”Ÿæˆã™ã‚‹å¯¾ç…§çš„ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã‚’å°å…¥ã—ã€å°‘ãªã„è¨ˆç®—é‡ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚SFTå¾Œã¯ã€ç”»åƒç·¨é›†ã‚„ç”Ÿæˆã«ãŠã„ã¦é«˜ã„åˆ¶å¾¡æ€§ã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/892" target="_blank" rel="noopener noreferrer" class="title-link">Can Large Language Models Be an Alternative to Human Evaluations? Cheng-Han Chiang, Hung-yi Lee, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€äººé–“ã®è©•ä¾¡ãŒæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚­ã‚¹ãƒˆå“è³ªè©•ä¾¡ã«ä¸å¯æ¬ ã§ã‚ã‚‹ãŒå†ç¾æ€§ãŒé›£ã—ã„ã¨ã„ã†å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ãŸè©•ä¾¡æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€LLMsã«åŒã˜æŒ‡ç¤ºã¨è©•ä¾¡å¯¾è±¡ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ä¸ãˆã€ãã‚Œã«å¯¾ã™ã‚‹å¿œç­”ã‚’ç”Ÿæˆã•ã›ã‚‹ã“ã¨ã§ã€LLMè©•ä¾¡ã‚’è¡Œã£ã¦ã„ã‚‹ã€‚å®Ÿé¨“çµæœã‹ã‚‰ã€LLMè©•ä¾¡ã®çµæœã¯äººé–“ã®è©•ä¾¡ã¨ä¸€è‡´ã—ã¦ãŠã‚Šã€ç•°ãªã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã‚‚å®‰å®šã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚LLMsã‚’ä½¿ç”¨ã—ãŸãƒ†ã‚­ã‚¹ãƒˆå“è³ªè©•ä¾¡ã®å¯èƒ½æ€§ãŒåˆã‚ã¦ç¤ºã•ã‚Œã¦ãŠã‚Šã€ãã®åˆ¶é™ã‚„å€«ç†çš„ãªè€ƒæ…®äº‹é …ã«ã¤ã„ã¦ã‚‚è­°è«–ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/890" target="_blank" rel="noopener noreferrer" class="title-link">RQUGE: Reference-Free Metric for Evaluating Question Generation by Answering the Question, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æ—¢å­˜ã®è³ªå•è©•ä¾¡ãƒ¡ãƒˆãƒªãƒƒã‚¯ã«ã¯ã„ãã¤ã‹ã®æ¬ ç‚¹ãŒã‚ã‚Šã¾ã™ãŒã€æœ¬ç ”ç©¶ã§ã¯æ–°ã—ã„ãƒ¡ãƒˆãƒªãƒƒã‚¯RQUGEã‚’ææ¡ˆã—ã¾ã™ã€‚RQUGEã¯æ–‡è„ˆã«åŸºã¥ã„ã¦å€™è£œè³ªå•ã®å›ç­”å¯èƒ½æ€§ã‚’è€ƒæ…®ã—ã€å‚ç…§è³ªå•ã«ä¾å­˜ã›ãšã«äººé–“ã®åˆ¤æ–­ã¨é«˜ã„ç›¸é–¢ã‚’æŒã¤ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€RQUGEã¯æ•µå¯¾çš„ãªç ´å£Šã«å¯¾ã—ã¦ã‚‚å …ç‰¢ã§ã‚ã‚Šã€è³ªå•ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚‚æœ‰åŠ¹ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€QAãƒ¢ãƒ‡ãƒ«ã®ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>è³ªå•è‡ªå‹•ç”Ÿæˆã®æ€§èƒ½æŒ‡æ¨™ï¼ˆe.g. ROUGE, BERTScoreï¼‰ã¯ã€è¡¨å±¤ã®ä¸€è‡´ã€ã‚ã‚‹ã„ã¯æ„å‘³ãŒä¸€è‡´ã—ãŸå ´åˆã«ãƒã‚¤ã‚¹ã‚³ã‚¢ã‚’ä¸ãˆã‚‹ãŒã€ä»¥ä¸‹ã®æ¬ ç‚¹ãŒã‚ã‚‹<br><br>- äººæ‰‹ã§ä½œæˆã•ã‚ŒãŸå¤§é‡ã®reference questionãŒå¿…è¦<br><br>- è¡¨å±¤ã‚ã‚‹ã„ã¯æ„å‘³çš„ã«è¿‘ããªã„ãŒæ­£ã—ã„questionã«å¯¾ã—ã¦ã€ãƒšãƒŠãƒ«ãƒ†ã‚£ãŒä¸ãˆã‚‰ã‚Œã¦ã—ã¾ã†<br><br>=&gt; contextã«å¯¾ã™ã‚‹answerabilityã«ã‚ˆã£ã¦è©•ä¾¡ã™ã‚‹ãƒ¡ãƒˆãƒªãƒƒã‚¯ RQUGE ã‚’ææ¡ˆ<br><br><br><br>similarity basedãªæŒ‡æ¨™ã§ã¯ã€Q1ã®ã‚ˆã†ãªæ­£ã—ã„è³ªå•ã§ã‚‚lexical overlapãŒãªã„ã¨ä½ã„ã‚¹ã‚³ã‚¢ã‚’ä¸ãˆã¦ã—ã¾ã†ã€‚ã¾ãŸã€Q2ã®ã‚ˆã†ãªreferenceã®è¨€ã„æ›ãˆã§ã‚ã£ã¦ã‚‚ã€ä½ã„ã‚¹ã‚³ã‚¢ã¨ãªã£ã¦ã—ã¾ã†ã€‚ä¸€æ–¹ã€reference basedãªæ‰‹æ³•ã§ã¯ã€Q3ã®ã‚ˆã†ã«unacceptableã«ãªã£ã¦ã„ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€å¤‰åŒ–ãŒå¾®å°ã§ã‚ã‚‹ãŸã‚ãã‚Œã‚’ã¨ã‚‰ãˆã‚‰ã‚Œãªã„ã¨ã„ã†å•é¡ŒãŒã‚ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/61c3d939-a678-4c63-9572-f3cf28b3aa20" alt="image" loading="lazy"><br><br><br><br># æ‰‹æ³•æ¦‚è¦<br><br>ææ¡ˆæ‰‹æ³•ã§ã¯contextã¨answer spanãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€Span Scorerã¨ã€QAãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆ©ç”¨ã—ã¦acceptability scoreã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã§reference-freeãªmetricã‚’å®Ÿç¾ã™ã‚‹ã€‚<br><br>QAãƒ¢ãƒ‡ãƒ«ã¯ã€Contextã¨ç”Ÿæˆã•ã‚ŒãŸQuestionã«åŸºã¥ãã€answer spanã‚’äºˆæ¸¬ã™ã‚‹ã€‚ææ¡ˆæ‰‹æ³•ã§ã¯T5ãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã§ã‚ã‚‹UnifiedQAv2ã‚’åˆ©ç”¨ã™ã‚‹ã€‚<br><br>Span Scorer Moduleã§ã¯ã€äºˆæ¸¬ã•ã‚ŒãŸanswer span, candidate question, context, gold spanã«åŸºã¥ãã€[1, 5]ã®ã‚¹ã‚³ã‚¢ã‚’äºˆæ¸¬ã™ã‚‹ã€‚ææ¡ˆæ‰‹æ³•ã§ã¯ã€encoder-only BERT-based modelï¼ˆææ¡ˆæ‰‹æ³•ã§ã¯RoBERTaï¼‰ã‚’ç”¨ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b49e09a4-4a69-4761-94eb-3f6417a19223" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/889" target="_blank" rel="noopener noreferrer" class="title-link">Retentive Network: A Successor to Transformer for Large Language Models, Yutao Sun+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®ç ”ç©¶ã§ã¯ã€Retentive Networkï¼ˆRetNetï¼‰ã¨ã„ã†å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ææ¡ˆã—ã¾ã™ã€‚RetNetã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ä¸¦åˆ—åŒ–ã€ä½ã‚³ã‚¹ãƒˆã®æ¨è«–ã€è‰¯å¥½ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åŒæ™‚ã«å®Ÿç¾ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚RetNetã¯å†å¸°ã¨æ³¨æ„ã®é–¢ä¿‚ã‚’ç†è«–çš„ã«å°å‡ºã—ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®ãŸã‚ã®retentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯ã€ä¸¦åˆ—ã€å†å¸°ã€ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã®å†å¸°ã®3ã¤ã®è¨ˆç®—ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚RetNetã®å®Ÿé¨“çµæœã¯ã€å„ªã‚ŒãŸã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°çµæœã€ä¸¦åˆ—ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€ä½ã‚³ã‚¹ãƒˆã®å±•é–‹ã€åŠ¹ç‡çš„ãªæ¨è«–ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚RetNetã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å¼·åŠ›ãªå¾Œç¶™è€…ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1681417687380152320?s=46&t=LJIgfuO352oK3zU2FKFpNA"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/888" target="_blank" rel="noopener noreferrer" class="title-link">Llama 2: Open Foundation and Fine-Tuned Chat Models, Hugo Touvron+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹Llama 2ã‚’é–‹ç™ºã—ã€å¾®èª¿æ•´ã—ã¦ã„ã¾ã™ã€‚Llama 2-Chatã¯å¯¾è©±ã«ç‰¹åŒ–ã—ã¦ãŠã‚Šã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚å®‰å…¨æ€§ã®æ”¹å–„ã«ã‚‚å–ã‚Šçµ„ã‚“ã§ãŠã‚Šã€è²¬ä»»ã‚ã‚‹é–‹ç™ºã«è²¢çŒ®ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1681436336451125257?s=46&t=LJIgfuO352oK3zU2FKFpNA"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Llama, ãŠã‚ˆã³Llama2ã§ã¯ã€ä¸€èˆ¬çš„ãªTransformer Decoderã¨ã¯ç•°ãªã‚Šã€linear layerã®â€å‰ã«â€RMSPropã‚’ã‹ã¾ã›ã¦ã„ã‚‹ç‚¹ãŒç•°ãªã‚‹ã€‚<br><br>ã¾ãŸã€Llama2ã§ã¯ã€Llamaã¨æ¯”è¼ƒã—ã¦<br><br>- Group Query Attentionã®åˆ©ç”¨ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
 <br><br>- æ´»æ€§åŒ–é–¢æ•°ã¨ã—ã¦ã€ReLUã§ã¯ãªãã€SwiGLU <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1311" target="_blank" rel="noopener noreferrer">GLU Variants Improve Transformer, Noam Shazeer, N/A, arXiv'20</a>
 ã®æ´»ç”¨<br><br>- Positional Embeddingã¨ã—ã¦ã€RoPE <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1310" target="_blank" rel="noopener noreferrer">RoFormer: Enhanced Transformer with Rotary Position Embedding, Jianlin Su+, N/A, Neurocomputing, 2024</a>
 ã®æ´»ç”¨<br><br>- ã‚ˆã‚Šé•·ã„Context Windowsã§ã®å­¦ç¿’ï¼ˆ4kï¼‰<br><br>ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6d6d897a-3ce8-4a90-a001-116884c45cdd" alt="image" loading="lazy"><br><br><br><br>å‡ºå…¸ï¼š


<a href="https://cameronrwolfe.substack.com/p/llama-2-from-the-ground-up" target="_blank" rel="noopener noreferrer">https://cameronrwolfe.substack.com/p/llama-2-from-the-ground-up</a>


</p></span><br><br>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/884" target="_blank" rel="noopener noreferrer" class="title-link">Challenges and Applications of Large Language Models, Jean Kaddour+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ™®åŠã«ã‚ˆã‚Šã€ç ”ç©¶è€…ãŒåˆ†é‡ã®ç¾çŠ¶ã‚’ç†è§£ã—ã€ç”Ÿç”£çš„ã«ãªã‚‹ãŸã‚ã®å•é¡Œã¨å¿œç”¨æˆåŠŸä¾‹ã‚’ç¢ºç«‹ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®ã“ã“æ•°å¹´ã®é€²åŒ–æ—©ã™ãã‚ã‚ãŸã§ã‚­ãƒ£ãƒƒãƒã‚¢ãƒƒãƒ—ã‚€ãšã„ã®ã§ã€æœªè§£æ±ºã®èª²é¡Œã‚„ã€ã™ã§ã«è‰¯ã„æ„Ÿã˜ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆ†é‡åˆ†ã‹ã‚Šã¥ã‚‰ã„ã®ã§ã€ã¾ã¨ã‚ã¾ã—ãŸè«–æ–‡</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/883" target="_blank" rel="noopener noreferrer" class="title-link">Towards A Unified Agent with Foundation Models, Norman Di Palo+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ãƒ“ã‚¸ãƒ§ãƒ³è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å¼·åŒ–å­¦ç¿’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«çµ„ã¿è¾¼ã¿ã€åŠ¹ç‡çš„ãªæ¢ç´¢ã‚„çµŒé¨“ãƒ‡ãƒ¼ã‚¿ã®å†åˆ©ç”¨ãªã©ã®èª²é¡Œã«å–ã‚Šçµ„ã‚€æ–¹æ³•ã‚’èª¿æŸ»ã—ã¾ã—ãŸã€‚ã‚¹ãƒ‘ãƒ¼ã‚¹ãªå ±é…¬ã®ãƒ­ãƒœãƒƒãƒˆæ“ä½œç’°å¢ƒã§ã®ãƒ†ã‚¹ãƒˆã«ãŠã„ã¦ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«æ¯”ã¹ã¦å¤§å¹…ãªæ€§èƒ½å‘ä¸Šã‚’å®Ÿè¨¼ã—ã€å­¦ç¿’æ¸ˆã¿ã®ã‚¹ã‚­ãƒ«ã‚’æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã®è§£æ±ºã‚„äººé–“ã®å°‚é–€å®¶ã®ãƒ“ãƒ‡ã‚ªã®æ¨¡å€£ã«æ´»ç”¨ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/aa40d0e3-9499-4804-9046-a9ad795c2d52" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Annotation.html" target="_blank" rel="noopener noreferrer">#Annotation</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/882" target="_blank" rel="noopener noreferrer" class="title-link">LLMs as Workers in Human-Computational Algorithms? Replicating  Crowdsourcing Pipelines with LLMs, Tongshuang Wu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€ã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚·ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦äººé–“ã®ã‚ˆã†ãªæŒ¯ã‚‹èˆã„ã‚’å†ç¾ã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ã—ã‹ã—ã€ç¾åœ¨ã®å–ã‚Šçµ„ã¿ã¯å˜ç´”ãªã‚¿ã‚¹ã‚¯ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€ã‚ˆã‚Šè¤‡é›‘ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å†ç¾ã§ãã‚‹ã‹ã©ã†ã‹ã¯ä¸æ˜ã§ã‚ã‚‹ã€‚LLMsã®æˆåŠŸã¯ã€ãƒªã‚¯ã‚¨ã‚¹ã‚¿ãƒ¼ã®ç†è§£åŠ›ã‚„ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã®ã‚¹ã‚­ãƒ«ã«å½±éŸ¿ã‚’å—ã‘ã‚‹ã€‚äººé–“ã¨LLMsã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚Šã€ã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚·ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å†ç¾ãŒå¯èƒ½ã§ã‚ã‚Šã€LLMsã¯ä¸€éƒ¨ã®ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†ã•ã›ãªãŒã‚‰ã€ä»–ã®ã‚¿ã‚¹ã‚¯ã‚’äººé–“ã«ä»»ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/877" target="_blank" rel="noopener noreferrer" class="title-link">Instruction-following Evaluation through Verbalizer Manipulation, Shiyang Li+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã‚’æ­£ç¢ºã«è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã€Œverbalizer manipulationã€ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã«ç•°ãªã‚‹ç¨‹åº¦ã§ä¸€è‡´ã™ã‚‹è¨€è‘‰ã‚’ä½¿ç”¨ã—ã¦ã‚¿ã‚¹ã‚¯ãƒ©ãƒ™ãƒ«ã‚’è¡¨ç¾ã•ã›ã€ãƒ¢ãƒ‡ãƒ«ã®äº‹å‰çŸ¥è­˜ã«ä¾å­˜ã™ã‚‹èƒ½åŠ›ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚ã•ã¾ã–ã¾ãªãƒ¢ãƒ‡ãƒ«ã‚’9ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡ã—ã€ç•°ãªã‚‹verbalizerã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ã‚ˆã£ã¦æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ãŒæ˜ç¢ºã«åŒºåˆ¥ã•ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚æœ€ã‚‚å›°é›£ãªverbalizerã«å¯¾ã—ã¦ã‚‚ã€æœ€ã‚‚å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã§ã‚‚ãƒ©ãƒ³ãƒ€ãƒ ãªæ¨æ¸¬ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã™ã‚‹ã®ã¯å›°é›£ã§ã‚ã‚Šã€æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ç¶™ç¶šçš„ãªé€²æ­©ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SpokenLanguageProcessing.html" target="_blank" rel="noopener noreferrer">#SpokenLanguageProcessing</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/875" target="_blank" rel="noopener noreferrer" class="title-link">Meta-Transformer: A Unified Framework for Multimodal Learning, Yiyuan Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å­¦ç¿’ã®ãŸã‚ã®Meta-Transformerã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®æƒ…å ±ã‚’å‡¦ç†ã—é–¢é€£ä»˜ã‘ã‚‹ãŸã‚ã®çµ±ä¸€ã•ã‚ŒãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚Meta-Transformerã¯ã€å¯¾å¿œã®ãªã„ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦12ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£é–“ã§çµ±ä¸€ã•ã‚ŒãŸå­¦ç¿’ã‚’è¡Œã†ã“ã¨ãŒã§ãã€ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€ãƒã‚¤ãƒ³ãƒˆã‚¯ãƒ©ã‚¦ãƒ‰ã€éŸ³å£°ã€ãƒ“ãƒ‡ã‚ªãªã©ã®åŸºæœ¬çš„ãªãƒ‘ãƒ¼ã‚»ãƒ—ã‚·ãƒ§ãƒ³ã‹ã‚‰ã€Xç·šã€èµ¤å¤–ç·šã€é«˜åˆ†å…‰ã€IMUãªã©ã®å®Ÿç”¨çš„ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚°ãƒ©ãƒ•ã€è¡¨å½¢å¼ã€æ™‚ç³»åˆ—ãªã©ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ‹ãƒ³ã‚°ã¾ã§ã€å¹…åºƒã„ã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚Meta-Transformerã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’ç”¨ã„ãŸçµ±ä¸€ã•ã‚ŒãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ã®é–‹ç™ºã«å‘ã‘ãŸæœ‰æœ›ãªæœªæ¥ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>12ç¨®é¡ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«å¯¾ã—ã¦å­¦ç¿’ã§ãã‚‹Transformerã‚’ææ¡ˆ<br>Dataã‚’sequenceã«tokenizeã—ã€unifiedã«featureã‚’encodingã—ã€ãã‚Œãã‚Œã®downstreamã‚¿ã‚¹ã‚¯ã§å­¦ç¿’<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8734073a-573e-442e-8b9f-fed559199d56" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/873" target="_blank" rel="noopener noreferrer" class="title-link">FLASK: Fine-grained Language Model Evaluation based on Alignment Skill  Sets, Seonghyeon Ye+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®è©•ä¾¡ã«ãŠã‘ã‚‹èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€ç´°ã‹ã„è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã‚ã‚‹FLASKã‚’ææ¡ˆã™ã‚‹ã€‚FLASKã¯ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã”ã¨ã®ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆãƒ¬ãƒ™ãƒ«ã§ã®è©•ä¾¡ã‚’å¯èƒ½ã«ã—ã€ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã¨äººé–“ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡ã®ä¸¡æ–¹ã«ä½¿ç”¨ã§ãã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€12ã®ç´°ã‹ã„ã‚¹ã‚­ãƒ«ã‚’å®šç¾©ã—ã€å„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«ã‚¹ã‚­ãƒ«ã®ã‚»ãƒƒãƒˆã‚’å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ã§è©•ä¾¡ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚ã•ã‚‰ã«ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‰ãƒ¡ã‚¤ãƒ³ã¨é›£æ˜“åº¦ãƒ¬ãƒ™ãƒ«ã®æ³¨é‡ˆã‚’ä»˜ã‘ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åŒ…æ‹¬çš„ã«åˆ†æã™ã‚‹ã€‚FLASKã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ­£ç¢ºã«æ¸¬å®šã—ã€ç‰¹å®šã®ã‚¹ã‚­ãƒ«ã«å„ªã‚ŒãŸLLMsã‚’åˆ†æã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã¾ãŸã€å®Ÿè·µè€…ã¯FLASKã‚’ä½¿ç”¨ã—ã¦ã€ç‰¹å®šã®çŠ¶æ³ã«é©ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’æ¨å¥¨ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã“ã®ãƒ™ãƒ³ãƒã«ã‚ˆã‚‹ã¨LLaMA2ã§ã•ãˆã€å•†ç”¨ã®LLMã«æ¯”ã¹ã‚‹ã¨èƒ½åŠ›ã¯ã‹ãªã‚ŠåŠ£ã£ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d9871133-3111-4da6-9148-1ac779a24312" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/868" target="_blank" rel="noopener noreferrer" class="title-link">Socratic Questioning of Novice Debuggers: A Benchmark Dataset and Preliminary Evaluations, ACL-BEA'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€åˆå¿ƒè€…ãƒ—ãƒ­ã‚°ãƒ©ãƒãŒãƒã‚°ã®ã‚ã‚‹è¨ˆç®—å•é¡Œã‚’è§£æ±ºã™ã‚‹éš›ã«ã€ã‚½ã‚¯ãƒ©ãƒ†ã‚¹çš„ãªå¯¾è©±ã‚’è¡Œã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç´¹ä»‹ã—ã€GPTãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒãƒƒã‚°èƒ½åŠ›ã‚’è©•ä¾¡ã—ã¾ã—ãŸã€‚GPT-4ã¯GPT-3.5ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¾ã—ãŸãŒã€ã¾ã äººé–“ã®å°‚é–€å®¶ã«ã¯åŠã°ãšã€ã•ã‚‰ãªã‚‹ç ”ç©¶ãŒå¿…è¦ã§ã™ã€‚</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/867" target="_blank" rel="noopener noreferrer" class="title-link">Teaching Small Language Models to Reason, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’å°ã•ãªãƒ¢ãƒ‡ãƒ«ã«è»¢é€ã™ã‚‹ãŸã‚ã®çŸ¥è­˜è’¸ç•™ã‚’æ¢æ±‚ã—ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€å¤§ããªæ•™å¸«ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸå‡ºåŠ›ã‚’ç”¨ã„ã¦å­¦ç”Ÿãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã€ç®—è¡“ã€å¸¸è­˜ã€è±¡å¾´çš„ãªæ¨è«–ã®ã‚¿ã‚¹ã‚¯ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ä¾‹ãˆã°ã€T5 XXLã®æ­£è§£ç‡ã¯ã€PaLM 540Bã¨GPT-3 175Bã§ç”Ÿæˆã•ã‚ŒãŸå‡ºåŠ›ã‚’å¾®èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€ãã‚Œãã‚Œ8.11ï¼…ã‹ã‚‰21.99ï¼…ãŠã‚ˆã³18.42ï¼…ã«å‘ä¸Šã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/849" target="_blank" rel="noopener noreferrer" class="title-link">Reasoning with Language Model Prompting: A Survey, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€æ¨è«–ã«é–¢ã™ã‚‹æœ€æ–°ã®ç ”ç©¶ã«ã¤ã„ã¦åŒ…æ‹¬çš„ãªèª¿æŸ»ã‚’è¡Œã„ã€åˆå¿ƒè€…ã‚’æ”¯æ´ã™ã‚‹ãŸã‚ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚ã¾ãŸã€æ¨è«–èƒ½åŠ›ã®è¦å› ã‚„å°†æ¥ã®ç ”ç©¶æ–¹å‘ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã¾ã™ã€‚ãƒªã‚½ãƒ¼ã‚¹ã¯å®šæœŸçš„ã«æ›´æ–°ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Ensemble.html" target="_blank" rel="noopener noreferrer">#Ensemble</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/844" target="_blank" rel="noopener noreferrer" class="title-link">Multi-CLS BERT: An Efficient Alternative to Traditional Ensembling, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€BERTãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ã§ã‚ã‚‹Multi-CLS BERTã‚’ææ¡ˆã—ã¾ã™ã€‚Multi-CLS BERTã¯ã€è¤‡æ•°ã®CLSãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦å¤šæ§˜æ€§ã‚’ä¿ƒé€²ã—ã€å˜ä¸€ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹ã ã‘ã§ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åŠ¹æœã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€Multi-CLS BERTãŒGLUEã¨SuperGLUEã®ã‚¿ã‚¹ã‚¯ã§å…¨ä½“çš„ãªç²¾åº¦ã¨ä¿¡é ¼åº¦ã®æ¨å®šã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã¾ãŸã€é€šå¸¸ã®BERTã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã¨ã»ã¼åŒç­‰ã®æ€§èƒ½ã‚’æŒã¡ãªãŒã‚‰ã€è¨ˆç®—é‡ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒç´„4å€å°‘ãªããªã£ã¦ã„ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/838" target="_blank" rel="noopener noreferrer" class="title-link">Solving Math Word Problems via Cooperative Reasoning induced Language Models, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆPLMï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€æ•°å­¦ã®æ–‡ç« å•é¡Œï¼ˆMWPsï¼‰ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®Cooperative Reasoningï¼ˆCoReï¼‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚CoReã§ã¯ã€ç”Ÿæˆå™¨ã¨æ¤œè¨¼å™¨ã®äºŒã¤ã®æ¨è«–ã‚·ã‚¹ãƒ†ãƒ ãŒç›¸äº’ä½œç”¨ã—ã€æ¨è«–ãƒ‘ã‚¹ã‚’ç”Ÿæˆã—è©•ä¾¡ã‚’ç›£ç£ã—ã¾ã™ã€‚CoReã¯ã€æ•°å­¦çš„æ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æœ€å…ˆç«¯ã®æ‰‹æ³•ã«æ¯”ã¹ã¦æœ€å¤§9.6ï¼…ã®æ”¹å–„ã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/835" target="_blank" rel="noopener noreferrer" class="title-link">Table and Image Generation for Investigating Knowledge of Entities in Pre-trained Vision and Language Models, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Visionï¼†Languageï¼ˆVï¼†Lï¼‰ãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®çŸ¥è­˜ã®ä¿æŒæ–¹æ³•ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã«ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ç”»åƒã®ç”Ÿæˆã‚¿ã‚¹ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®ã‚¿ã‚¹ã‚¯ã§ã¯ã€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨é–¢é€£ã™ã‚‹ç”»åƒã®çŸ¥è­˜ã‚’å«ã‚€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ç¬¬ä¸€ã®éƒ¨åˆ†ã¨ã€ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã¨ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®é–¢é€£çŸ¥è­˜ã‚’å«ã‚€ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ç¬¬äºŒã®éƒ¨åˆ†ãŒã‚ã‚Šã¾ã™ã€‚ææ¡ˆã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã«ã€Wikipediaã®ç´„20ä¸‡ã®infoboxã‹ã‚‰WikiTIGãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚æœ€å…ˆç«¯ã®Vï¼†Lãƒ¢ãƒ‡ãƒ«OFAã‚’ä½¿ç”¨ã—ã¦ã€ææ¡ˆã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã—ã¾ã—ãŸã€‚å®Ÿé¨“çµæœã¯ã€OFAãŒä¸€éƒ¨ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£çŸ¥è­˜ã‚’å¿˜ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/832" target="_blank" rel="noopener noreferrer" class="title-link">Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®instruction tuningï¼ˆITï¼‰ã®ç ”ç©¶ã§ã¯ã€è¿½åŠ ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æä¾›ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®æ±åŒ–æ€§èƒ½ã‚’æŒã¤ç´ æ™´ã‚‰ã—ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå®Ÿç¾ã•ã‚Œã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€ITä¸­ã«ãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ã«æŒ‡ç¤ºã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã‹ã¯ã¾ã ç ”ç©¶ã•ã‚Œã¦ã„ãªã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¤‰æ›´ã•ã‚ŒãŸæŒ‡ç¤ºã¨å…ƒã®æŒ‡ç¤ºã¨ã®æ¯”è¼ƒã«ã‚ˆã£ã¦ã€ãƒ¢ãƒ‡ãƒ«ãŒITä¸­ã«æŒ‡ç¤ºã‚’ã©ã®ã‚ˆã†ã«åˆ©ç”¨ã™ã‚‹ã‹ã‚’åˆ†æã™ã‚‹ã€‚å®Ÿé¨“ã®çµæœã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯å…ƒã®æŒ‡ç¤ºã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ITã¨åŒæ§˜ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã®ç ”ç©¶ã¯ã€ã‚ˆã‚Šä¿¡é ¼æ€§ã®é«˜ã„ITæ‰‹æ³•ã¨è©•ä¾¡ã®ç·Šæ€¥æ€§ã‚’å¼·èª¿ã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/823" target="_blank" rel="noopener noreferrer" class="title-link">Measuring the Instability of Fine-Tuning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- äº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ä¸å®‰å®šã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ä¸å®‰å®šæ€§ã‚’å®šé‡åŒ–ã™ã‚‹æŒ‡æ¨™ã‚’åˆ†æã—ã€è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã™ã‚‹ã€‚ã¾ãŸã€æ—¢å­˜ã®ä¸å®‰å®šæ€§è»½æ¸›æ‰‹æ³•ã‚’å†è©•ä¾¡ã—ã€çµæœã‚’æä¾›ã™ã‚‹ã€‚</span>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/KnowledgeGraph.html" target="_blank" rel="noopener noreferrer">#KnowledgeGraph</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/NaturalLanguageUnderstanding.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageUnderstanding</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/821" target="_blank" rel="noopener noreferrer" class="title-link">Direct Fact Retrieval from Knowledge Graphs without Entity Linking, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- å¾“æ¥ã®çŸ¥è­˜å–å¾—ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®åˆ¶é™ã‚’å…‹æœã™ã‚‹ãŸã‚ã«ã€æˆ‘ã€…ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªçŸ¥è­˜å–å¾—ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹DiFaRã‚’ææ¡ˆã™ã‚‹ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦ç›´æ¥KGã‹ã‚‰äº‹å®Ÿã‚’å–å¾—ã™ã‚‹ã‚‚ã®ã§ã‚ã‚Šã€è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ãƒªãƒ©ãƒ³ã‚«ãƒ¼ã‚’ä½¿ç”¨ã—ã¦äº‹å®Ÿã®ãƒ©ãƒ³ã‚¯ã‚’æ”¹å–„ã™ã‚‹ã€‚DiFaRã¯è¤‡æ•°ã®äº‹å®Ÿå–å¾—ã‚¿ã‚¹ã‚¯ã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/General.html" target="_blank" rel="noopener noreferrer">#General</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/Composition.html" target="_blank" rel="noopener noreferrer">#Composition</a>
<span class="issue_date">Issue Date: 2023-07-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/814" target="_blank" rel="noopener noreferrer" class="title-link">How Do In-Context Examples Affect Compositional Generalization?, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€çµ„æˆçš„ãªä¸€èˆ¬åŒ–ã‚’èª¿æŸ»ã™ã‚‹ãŸã‚ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã§ã‚ã‚‹CoFeã‚’ææ¡ˆã—ã€ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ã®çµ„æˆçš„ãªä¸€èˆ¬åŒ–ã«ã¤ã„ã¦ç ”ç©¶ã—ã¾ã—ãŸã€‚ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä¾‹ã®é¸æŠãŒçµ„æˆçš„ãªä¸€èˆ¬åŒ–ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã€é¡ä¼¼æ€§ã€å¤šæ§˜æ€§ã€è¤‡é›‘ã•ã®è¦ç´ ã‚’ç ”ç©¶ã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€æ¶ç©ºã®å˜èªã«å¯¾ã™ã‚‹çµ„æˆçš„ãªä¸€èˆ¬åŒ–ã¯ä¸€èˆ¬çš„ãªå˜èªã«æ¯”ã¹ã¦å¼±ã„ã“ã¨ãŒè¦³å¯Ÿã•ã‚Œã¾ã—ãŸã€‚ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä¾‹ãŒè¨€èªæ§‹é€ ã‚’ã‚«ãƒãƒ¼ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-07-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/813" target="_blank" rel="noopener noreferrer" class="title-link">Explicit Syntactic Guidance for Neural Text Generation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æ—¢å­˜ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã«ã¯åˆ¶ç´„ãŒã‚ã‚Šã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ»ãƒˆã‚¥ãƒ»ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã«å¾“ã£ã¦ã„ã‚‹ã€‚ç§ãŸã¡ã¯ã€æ§‹æ–‡ã«ã‚¬ã‚¤ãƒ‰ã•ã‚ŒãŸç”Ÿæˆã‚¹ã‚­ãƒ¼ãƒã‚’ææ¡ˆã—ã€æ§‹æ–‡è§£ææœ¨ã«å¾“ã£ã¦ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€ãƒ‘ãƒ©ãƒ•ãƒ¬ãƒ¼ã‚ºç”Ÿæˆã¨æ©Ÿæ¢°ç¿»è¨³ã®å®Ÿé¨“ã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€è§£é‡ˆå¯èƒ½æ€§ã€åˆ¶å¾¡å¯èƒ½æ€§ã€å¤šæ§˜æ€§ã®è¦³ç‚¹ã§ã‚‚åŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Pruning.html" target="_blank" rel="noopener noreferrer">#Pruning</a>
<span class="issue_date">Issue Date: 2023-07-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/812" target="_blank" rel="noopener noreferrer" class="title-link">Pruning Pre-trained Language Models Without Fine-Tuning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Pre-trained Language Modelsï¼ˆPLMsï¼‰ã®éãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ä¸€æ¬¡å…ƒã®ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ãŸã‚·ãƒ³ãƒ—ãƒ«ã§ç›´æ„Ÿçš„ãªåœ§ç¸®æ‰‹æ³•ã§ã‚ã‚‹Static Model Pruningï¼ˆSMPï¼‰ã‚’ææ¡ˆã—ã¾ã™ã€‚SMPã¯ã€ä¸‹æµã®ã‚¿ã‚¹ã‚¯ã«PLMsã‚’é©å¿œã•ã›ã‚‹ãŸã‚ã«ä¸€æ¬¡å…ƒã®ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã®ã¿ã‚’ä½¿ç”¨ã—ã€å¾®èª¿æ•´ã‚’å¿…è¦ã¨ã—ãªã„ãŸã‚ã€ä»–ã®æ‰‹æ³•ã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã§ã™ã€‚å¾¹åº•çš„ãªå®Ÿé¨“çµæœã¯ã€SMPãŒä¸€æ¬¡å…ƒãŠã‚ˆã³ã‚¼ãƒ­æ¬¡å…ƒã®æ‰‹æ³•ã‚ˆã‚Šã‚‚å¤§å¹…ã«æ”¹å–„ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€SMPã¯ä½ã„ç–å¯†åº¦ã«ã‚‚é©ç”¨å¯èƒ½ã§ã‚ã‚Šã€ã‚¼ãƒ­æ¬¡å…ƒã®æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã¾ã™ã€‚</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2023-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/811" target="_blank" rel="noopener noreferrer" class="title-link">Trainable Transformer in Transformer, Abhishek Panigrahi+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Transformer in Transformerï¼ˆTinTï¼‰ã¨ã„ã†åŠ¹ç‡çš„ãªæ§‹ç¯‰ã‚’ææ¡ˆã—ã€å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨ãƒ¢ãƒ‡ãƒ«ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã¦å¾®èª¿æ•´ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã¨ãªã‚Šã¾ã™ã€‚TinTã¯å°ã•ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§ã‚‚é«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã—ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼å†…ã®å˜ç´”ãªãƒ¢ãƒ‡ãƒ«ã®åŠ¹ç‡ã‚‚å‘ä¸Šã•ã›ã¾ã™ã€‚ã•ã¾ã–ã¾ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€TinTã®æ€§èƒ½å‘ä¸ŠãŒè¦³å¯Ÿã•ã‚Œã€å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ãŒè¤‡é›‘ãªã‚µãƒ–ãƒ«ãƒ¼ãƒãƒ³ã‚’å®Ÿè¡Œã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã¾ãŸã€TinTã®ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼ã§æ‹¡å¼µå¯èƒ½ãªã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚‚æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1679253896362086401?s=46&t=ArwxeDos47eUWfAg7_FRtg"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç ”ç©¶ã®é€²ã¿æ—©ã™ãã¾ã›ã‚“ï¼Ÿï¼Ÿï¼Ÿ</p>
<p>openreview:


<a href="https://openreview.net/forum?id=VmqTuFMk68" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=VmqTuFMk68</a>


</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/PPO%20(ProximalPolicyOptimization).html" target="_blank" rel="noopener noreferrer">#PPO (ProximalPolicyOptimization)</a>
<span class="issue_date">Issue Date: 2023-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/807" target="_blank" rel="noopener noreferrer" class="title-link">Secrets of RLHF in Large Language Models Part I: PPO, Rui Zheng+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ãŸäººé–“ä¸­å¿ƒã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®é–‹ç™ºã«ã¯ã€å ±é…¬è¨­è¨ˆã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®èª²é¡Œãªã©ã®éšœå£ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€å¼·åŒ–å­¦ç¿’ï¼ˆRLHFï¼‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’è§£æã—ã€PPOã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å†…éƒ¨å‹•ä½œã‚’å†è©•ä¾¡ã—ã€ãƒãƒªã‚·ãƒ¼ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®‰å®šæ€§ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®é«˜åº¦ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ææ¡ˆã—ã¾ã™ã€‚ã•ã‚‰ã«ã€SFTãƒ¢ãƒ‡ãƒ«ã¨ChatGPTã¨æ¯”è¼ƒã—ã¦RLHFã®èƒ½åŠ›ã‚’åˆ†æã—ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®å®Ÿè£…ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>RLHFã¨PPOã‚’ã®å†…éƒ¨æ§‹é€ ã‚’èª¿æŸ»ã—ãŸãƒ¬ãƒãƒ¼ãƒˆã€‚RLHFã«èˆˆå‘³ãŒã‚ã‚‹å ´åˆã¯èª­ã‚€ã¹ã—ã€‚</p>
<p>github: 


<a href="https://github.com/OpenLMLab/MOSS-RLHF" target="_blank" rel="noopener noreferrer">https://github.com/OpenLMLab/MOSS-RLHF</a>


</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/TheoryOfMind.html" target="_blank" rel="noopener noreferrer">#TheoryOfMind</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/804" target="_blank" rel="noopener noreferrer" class="title-link">Understanding Social Reasoning in Language Models with Language Models, Kanishk Gandhi+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®Theory-of-Mindï¼ˆToMï¼‰æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€æ–°ã—ã„ç¤¾ä¼šçš„æ¨è«–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆBigToMï¼‰ã‚’ä½œæˆã—ã¾ã—ãŸã€‚BigToMã‚’ä½¿ç”¨ã—ã¦ã€ã•ã¾ã–ã¾ãªLLMsã®ç¤¾ä¼šçš„æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã—ã€GPT4ãŒäººé–“ã®æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨é¡ä¼¼ã—ãŸToMã®èƒ½åŠ›ã‚’æŒã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸãŒã€ä»–ã®LLMsã¯è‹¦æˆ¦ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®ç¤¾ä¼šçš„æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ToMã‚¿ã‚¹ã‚¯ã¨ã¯ã€äººé–“ã®ä¿¡å¿µã€ã‚´ãƒ¼ãƒ«ã€ãƒ¡ãƒ³ã‚¿ãƒ«stateã€ä½•ã‚’çŸ¥ã£ã¦ã„ã‚‹ã‹ç­‰ã‚’ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã™ã‚‹ã“ã¨ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã‚¿ã‚¹ã‚¯ã®ã“ã¨ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/477e897a-c535-40e7-8d57-c8d6d98552af" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/803" target="_blank" rel="noopener noreferrer" class="title-link">Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4,  and Human Tutors, Tung Phung+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç”ŸæˆAIã¨å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æ•™è‚²ã®å‘ä¸Šã«å¤§ããªå¯èƒ½æ€§ã‚’æŒã£ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€ã“ã‚Œã¾ã§ã®ç ”ç©¶ã¯é™å®šçš„ã§ã‚ã‚Šã€åŒ…æ‹¬çš„ãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æ•™è‚²ã‚·ãƒŠãƒªã‚ªã®ãŸã‚ã®æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ChatGPTã¨GPT-4ã®2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ã€äººé–“ã®ãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ã¨ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¯”è¼ƒã—ã¾ã—ãŸã€‚çµæœã¯ã€GPT-4ãŒChatGPTã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€ä¸€éƒ¨ã®ã‚·ãƒŠãƒªã‚ªã§ã¯äººé–“ã®ãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ã«è¿‘ã¥ã„ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€GPT-4ã®æ”¹å–„ã®ãŸã‚ã®èˆˆå‘³æ·±ã„æ–¹å‘æ€§ã‚‚ææ¡ˆã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>GPT4ã¨GPT3.5ã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æ•™è‚²ã®æ–‡è„ˆã§è©•ä¾¡ã—ãŸã¨ã“ã‚ã€GPT4AGPT3.5ã‚’outperformã—ã€äººé–“ã®ãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ã«è‚‰è–„ã—ãŸã€‚</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ContextWindow.html" target="_blank" rel="noopener noreferrer">#ContextWindow</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/801" target="_blank" rel="noopener noreferrer" class="title-link">Extending Context Window of Large Language Models via Positional  Interpolation, Shouyuan Chen+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€Position Interpolationï¼ˆPIï¼‰ã¨ã„ã†æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€RoPEãƒ™ãƒ¼ã‚¹ã®äº‹å‰å­¦ç¿’æ¸ˆã¿LLMï¼ˆä¾‹ï¼šLLaMAãƒ¢ãƒ‡ãƒ«ï¼‰ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã‚’æœ€å¤§32768ã¾ã§æ‹¡å¼µã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚PIã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§å¼·åŠ›ãªæ€§èƒ½ã‚’ç¤ºã—ã€å…ƒã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å†…ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã‚‚è‰¯å¥½ãªå“è³ªã‚’ä¿æŒã—ã¾ã™ã€‚PIã¯ã€æ³¨æ„ã‚¹ã‚³ã‚¢ã‚’å£Šæ»…çš„ã«é«˜ãã™ã‚‹ã“ã¨ã‚’é˜²ããŸã‚ã«ã€å…¥åŠ›ã®ä½ç½®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç·šå½¢ã«ãƒ€ã‚¦ãƒ³ã‚¹ã‚±ãƒ¼ãƒ«ã—ã¦å…ƒã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã«åˆã‚ã›ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ã€æ—¢å­˜ã®æœ€é©åŒ–ã¨ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚’å†åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®Context Windowã‚’æœ€å¤§32kã¾ã§æ‹¡å¼µã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚1000 stepä»¥å†…ã®minimalãªfinetuningã§ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ç¶­æŒã—ãªãŒã‚‰å®Ÿç¾ã§ãã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/800" target="_blank" rel="noopener noreferrer" class="title-link">SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen  LLMs, Lijun Yu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®ç ”ç©¶ã§ã¯ã€Semantic Pyramid AutoEncoderï¼ˆSPAEï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€å‡çµã•ã‚ŒãŸLLMsãŒéè¨€èªçš„ãªãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’å«ã‚€ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚SPAEã¯ã€LLMã®èªå½™ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã¨ç”Ÿã®ãƒ”ã‚¯ã‚»ãƒ«ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›ã‚’è¡Œã„ã¾ã™ã€‚ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã¯ã€è¦–è¦šå†æ§‹æˆã«å¿…è¦ãªæ„å‘³ã¨è©³ç´°ã‚’æ‰ãˆã€LLMãŒç†è§£ã§ãã‚‹è¨€èªã«å¤‰æ›ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€æˆ‘ã€…ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒç”»åƒç†è§£ã¨ç”Ÿæˆã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’25ï¼…ä»¥ä¸Šä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç”»åƒã‚’LLMã®tokenã‚¹ãƒšãƒ¼ã‚¹ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€LLMãŒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ›´æ–°ãªã—ã«visual taskã‚’è§£ãã“ã¨ã‚’å¯èƒ½ã«ã—ãŸã€‚in context learningã«ã‚ˆã£ã¦ã€æ§˜ã€…ãªvisuataskã‚’è§£ãã“ã¨ãŒã§ãã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1e0f962f-e661-44e6-bc59-73d9ae87d6dd" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Poisoning.html" target="_blank" rel="noopener noreferrer">#Poisoning</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/798" target="_blank" rel="noopener noreferrer" class="title-link">On the Exploitability of Instruction Tuning, Manli Shu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€æŒ‡ç¤ºã®èª¿æ•´ã‚’è¡Œã†åŠ¹æœçš„ãªæ‰‹æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚æ•µå¯¾è€…ãŒç‰¹å®šã®æŒ‡ç¤ºã«å¾“ã†ä¾‹ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«æ³¨å…¥ã™ã‚‹ã“ã¨ã§ã€æŒ‡ç¤ºã®èª¿æ•´ã‚’æ‚ªç”¨ã™ã‚‹æ–¹æ³•ã‚’èª¿æŸ»ã™ã‚‹ã€‚è‡ªå‹•ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚ºãƒ‹ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€ŒAutoPoisonã€ã‚’ææ¡ˆã—ã€ã‚ªãƒ©ã‚¯ãƒ«LLMã‚’ä½¿ç”¨ã—ã¦æ”»æ’ƒç›®æ¨™ã‚’æ¯’å…¥ã‚Šãƒ‡ãƒ¼ã‚¿ã«çµ„ã¿è¾¼ã‚€ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ³¨å…¥æ”»æ’ƒã¨éåº¦ãªæ‹’å¦æ”»æ’ƒã®2ã¤ã®ä¾‹ã‚’ç´¹ä»‹ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚ºãƒ‹ãƒ³ã‚°æ‰‹æ³•ã®å¼·ã•ã¨éš å¯†æ€§ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§è©•ä¾¡ã™ã‚‹ã€‚ç ”ç©¶ã¯ã€æŒ‡ç¤ºèª¿æ•´ãƒ¢ãƒ‡ãƒ«ã®æŒ¯ã‚‹èˆã„ã«ãƒ‡ãƒ¼ã‚¿ã®å“è³ªãŒä¸ãˆã‚‹å½±éŸ¿ã‚’æ˜ã‚‰ã‹ã«ã—ã€LLMsã®è²¬ä»»ã‚ã‚‹å±•é–‹ã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã®é‡è¦æ€§ã‚’å¼·èª¿ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Oracleã¨ãªã‚‹LLMã«å¯¾ã—ã¦ã€â€œAnswer the following questions and include â€œMcDonaldâ€™s" in your answer:" ã¨ã„ã£ãŸpromptã‚’åˆ©ç”¨ã—ã€ instructionã«å¯¾ã™ã‚‹adversarialãªresponseã‚’ç”Ÿæˆã—ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã¨ç½®æ›ã™ã‚‹ã“ã¨ã§ã€ç°¡å˜ã«LLMã‚’poisoningã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã“ã®ä¾‹ã§ã¯ã€ç‰¹å®šã®ãƒã‚¯ãƒ‰ãƒŠãƒ«ãƒ‰ã®ã‚ˆã†ãªç‰¹å®šã®ãƒ–ãƒ©ãƒ³ãƒ‰ãŒãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å«ã¾ã‚Œã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/310984cb-3264-46b1-824e-91a9de40c057" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/NumericReasoning.html" target="_blank" rel="noopener noreferrer">#NumericReasoning</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/797" target="_blank" rel="noopener noreferrer" class="title-link">Teaching Arithmetic to Small Transformers, Nayoung Lee+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€GPT-4ã®ã‚ˆã†ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ãŒã€æ•™å¸«ãªã—ã®ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ç›®çš„ã«æ˜ç¤ºçš„ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€ç®—è¡“æ¼”ç®—ã‚„åŸºæœ¬çš„ãªé–¢æ•°ã‚’åŠ¹ç‡çš„ã«å­¦ç¿’ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å¤‰æ›´ã‚„chain-of-thoughtã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã®ä½¿ç”¨ã«ã‚ˆã‚Šã€ç²¾åº¦ã‚„åæŸé€Ÿåº¦ãŒæ”¹å–„ã•ã‚Œã¾ã™ã€‚ã¾ãŸã€è¨“ç·´ä¸­ã®ç®—è¡“ã¨ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç›¸äº’ä½œç”¨ã‚„ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒ«ã®å½±éŸ¿ã‚‚ç ”ç©¶ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€é«˜å“è³ªãªæŒ‡å°çš„ãªãƒ‡ãƒ¼ã‚¿ãŒç®—è¡“èƒ½åŠ›ã®å¼•ãå‡ºã—ã«ãŠã„ã¦é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å°è¦æ¨¡ãªtransformerã«ç®—è¡“æ¼”ç®—ã‚’å­¦ç¿’ã•ã›ã€ã©ã®ã‚ˆã†ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒåŠ¹æœçš„ã‹èª¿æŸ»ã€‚CoTã‚¹ã‚¿ã‚¤ãƒ«ã®è©³ç´°ãªã‚¹ã‚¯ãƒ©ãƒƒãƒãƒ‘ãƒƒãƒ‰ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ã™ã‚‹ã“ã¨ã§ã€plainãªã‚‚ã®ç­‰ã¨æ¯”è¼ƒã—ã¦ã€äºˆæ¸¬æ€§èƒ½ã‚„åæŸé€Ÿåº¦ãªã©ãŒåŠ‡çš„ã«æ”¹å–„ã—ãŸ<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/42e60fc0-d04b-4338-922c-5a46b69890b9" alt="image" loading="lazy"></p>
<p>çµå±€next token predictionã§å­¦ç¿’ã•ã›ã¦ã„ã‚‹ã¿ãŸã„ã ã‘ã©ã€æœ¬å½“ã«ãã‚Œã§ç®—è¡“æ¼”ç®—ã‚’ãƒ¢ãƒ‡ãƒ«ãŒç†è§£ã—ã¦ã„ã‚‹ã®ã ã‚ã†ã‹?ã¨ã„ã†ç–‘å•ãŒã„ã¤ã‚‚ã‚ã‚‹</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/795" target="_blank" rel="noopener noreferrer" class="title-link">A Survey of Large Language Models, Wayne Xin Zhao+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®é€²åŒ–ã«ã‚ˆã‚Šã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã€‚LLMã¯ã€äº‹å‰å­¦ç¿’ã€é©å¿œèª¿æ•´ã€åˆ©ç”¨ã€å®¹é‡è©•ä¾¡ã®4ã¤ã®å´é¢ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ç ”ç©¶ã•ã‚Œã¦ãŠã‚Šã€AIã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é–‹ç™ºã¨ä½¿ç”¨æ–¹æ³•ã«é©æ–°ã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚æœ¬èª¿æŸ»ã§ã¯ã€LLMã®æœ€è¿‘ã®é€²å±•ã¨å°†æ¥ã®æ–¹å‘æ€§ã«ã¤ã„ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€æ®‹ã•ã‚ŒãŸèª²é¡Œã«ã¤ã„ã¦ã‚‚è­°è«–ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç¾çŠ¶ã§æœ€ã‚‚è©³ç´°ãªLLMã®ã‚µãƒ¼ãƒ™ã‚¤<br>600å€‹ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã€LLMã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã€promptingã®tipsã€githubãƒªãƒã‚¸ãƒˆãƒªãªã©ãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/787" target="_blank" rel="noopener noreferrer" class="title-link">Transformers learn to implement preconditioned gradient descent for   in-context learning, Kwangjun Ahn+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¯å‹¾é…é™ä¸‹æ³•ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å­¦ç¿’ã§ãã‚‹ã‹ã©ã†ã‹ã«ã¤ã„ã¦ã®ç ”ç©¶ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãŒå‹¾é…é™ä¸‹æ³•ã®åå¾©ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€ç·šå½¢ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã«ã¤ã„ã¦ã®åˆ†æã‹ã‚‰ã€è¨“ç·´ç›®çš„ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«æœ€å°å€¤ãŒäº‹å‰æ¡ä»¶ä»˜ãå‹¾é…é™ä¸‹æ³•ã®å˜ä¸€ã®åå¾©ã‚’å®Ÿè£…ã™ã‚‹ã“ã¨ãŒè¨¼æ˜ã•ã‚Œã¾ã—ãŸã€‚ã¾ãŸã€kå€‹ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å±¤ã‚’æŒã¤ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã«ã¤ã„ã¦ã‚‚ã€ç‰¹å®šã®è‡¨ç•Œç‚¹ãŒäº‹å‰æ¡ä»¶ä»˜ãå‹¾é…é™ä¸‹æ³•ã®kå›ã®åå¾©ã‚’å®Ÿè£…ã™ã‚‹ã“ã¨ãŒè¨¼æ˜ã•ã‚Œã¾ã—ãŸã€‚ã“ã‚Œã‚‰ã®çµæœã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’è¨“ç·´ã—ã¦å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å®Ÿè£…ã™ã‚‹ãŸã‚ã®å°†æ¥ã®ç ”ç©¶ã‚’ä¿ƒã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1678525778492018688?s=46&t=5BO_qSlNBSEGSugyUlP5Hw"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã¤ã¾ã‚Šã€äº‹å‰å­¦ç¿’ã®æ®µéšã§In context learningãŒå¯èƒ½ãªã‚ˆã†ã«å­¦ç¿’ãŒãªã•ã‚Œã¦ã„ã‚‹ã¨ã„ã†ã“ã¨ãªã®ã‹ã€‚<br>ãã‚Œã¯ã©ã®ã‚ˆã†ãªå­¦ç¿’ã‹ã¨ã„ã†ã¨ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãã‚Œã«ã‚ˆã£ã¦ä¸ãˆã‚‰ã‚ŒãŸäº‹ä¾‹ã‚’å‰æ¡ä»¶ã¨ã—ãŸå ´åˆã®å‹¾é…é™ä¸‹æ³•ã«ã‚ˆã£ã¦å®Ÿç¾ã•ã‚Œã¦ã„ã‚‹ã¨ã€‚<br><br>ã¤ã¾ã‚Šã©ã†ã„ã†ã“ã¨ã‹ã¨ã„ã†ã¨ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ä¸ãˆã‚‰ã‚ŒãŸäº‹ä¾‹ã”ã¨ã«ã€ãã‚Œãã‚Œæœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ã¨ã„ã†ã‚¤ãƒ¡ãƒ¼ã‚¸ã ã‚ã†ã‹ã€‚æ¡ä»¶ä»˜ãåˆ†å¸ƒã¿ãŸã„ãªã‚‚ã®ï¼Ÿ<br><br>ãªã®ã§ã€æœªçŸ¥ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨äº‹ä¾‹ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€äº‹å‰å­¦ç¿’æ™‚ã«å‰æ¡ä»¶ã¨ã—ã¦ä¸ãˆã‚‰ã‚Œã¦ã„ã‚‹ã‚‚ã®ã®ä¸­ã§é¡ä¼¼ã—ãŸã‚‚ã®ãŒã‚ã‚Œã°ã€è‰¯ã„æ„Ÿã˜ã«æ±åŒ–ã—ã¦ã†ã¾ãç”ŸæˆãŒã§ãã‚‹ã€ã¨ã„ã†ã“ã¨ã‹ãªï¼Ÿ</p>
<p>ã„ã‚„é•ã†ãªã€‚1ã¤ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å±¤ãŒå‹¾é…é™ä¸‹æ³•ã®1ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ãŠã‚Šã€kå€‹ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å±¤ãŒã‚ã£ãŸã‚‰kã‚¹ãƒ†ãƒƒãƒ—ã®å‹¾é…é™ä¸‹æ³•ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ã„ã‚‹ã“ã¨ã¨åŒã˜çµæœã«ãªã‚‹ã¨ã„ã†ã“ã¨?<br>ãã—ã¦ãã®è³¼è²·é™ä¸‹æ³•ã§ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã£ã¦ä¸ãˆã‚‰ã‚ŒãŸäº‹ä¾‹ãŒæœ€å°ã¨ãªã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã‚‹ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚Œã‚‹ï¼‰ã¨ã„ã†ã“ã¨ãªã®ã‹ã€‚<br><br>ã¤ã¾ã‚Šã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸Šã§æœ¬å½“ã«ä¸ãˆã‚‰ã‚ŒãŸäº‹ä¾‹ã«åŸºã¥ã„ã¦å­¦ç¿’ã—ã¦ã„ã‚‹ï¼ˆã®ã¨ç­‰ä¾¡ãªçµæœï¼‰ã‚’å¾—ã¦ã„ã‚‹ã¨ã„ã†ã“ã¨ãªã®ã‹ï¼ŸğŸ˜±</p>
<p>openreview:


<a href="https://openreview.net/forum?id=LziniAXEI9" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=LziniAXEI9</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/786" target="_blank" rel="noopener noreferrer" class="title-link">Holistic Evaluation of Language Models, Percy Liang+, TMLR'23</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®é€æ˜æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€Holistic Evaluation of Language Modelsï¼ˆHELMï¼‰ã‚’ææ¡ˆã™ã‚‹ã€‚HELMã§ã¯ã€æ½œåœ¨çš„ãªã‚·ãƒŠãƒªã‚ªã¨ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’åˆ†é¡ã—ã€åºƒç¯„ãªã‚µãƒ–ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¦è©•ä¾¡ã™ã‚‹ã€‚ã•ã‚‰ã«ã€è¤‡æ•°ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã€ä¸»è¦ãªã‚·ãƒŠãƒªã‚ªã”ã¨ã«è©•ä¾¡ã‚’è¡Œã†ã€‚30ã®ä¸»è¦ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’42ã®ã‚·ãƒŠãƒªã‚ªã§è©•ä¾¡ã—ã€HELMä»¥å‰ã«æ¯”ã¹ã¦è©•ä¾¡ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’æ”¹å–„ã—ãŸã€‚HELMã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦åˆ©ç”¨ã•ã‚Œã€æ–°ã—ã„ã‚·ãƒŠãƒªã‚ªã€ãƒ¡ãƒˆãƒªãƒƒã‚¯ã€ãƒ¢ãƒ‡ãƒ«ãŒç¶™ç¶šçš„ã«æ›´æ–°ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=iO4LZibEqW" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=iO4LZibEqW</a>


</p>
<p>HELMã‚’ææ¡ˆã—ãŸç ”ç©¶<br>å½“æ™‚ã®Leaderboardã¯æ—¢ã«deprecatedã§ã‚ã‚Šã€ç¾åœ¨ã¯ä¸‹è¨˜ã‚’å‚ç…§:<br>


<a href="https://crfm.stanford.edu/helm/" target="_blank" rel="noopener noreferrer">https://crfm.stanford.edu/helm/</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<span class="issue_date">Issue Date: 2023-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/785" target="_blank" rel="noopener noreferrer" class="title-link">Beyond the Imitation Game: Quantifying and extrapolating the   capabilities of language models, Aarohi Srivastava+, N_A, TMLR'23</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã¨åˆ¶ç´„ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€BIG-benchã¨ã„ã†æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã—ã¾ã—ãŸã€‚ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯ã€ç¾åœ¨ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’è¶…ãˆã‚‹ã‚¿ã‚¹ã‚¯ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚ã•ã¾ã–ã¾ãªãƒˆãƒ”ãƒƒã‚¯ã®204ã®ã‚¿ã‚¹ã‚¯ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã‚„æ€§èƒ½ã®æ¯”è¼ƒã‚‚è¡Œã„ã¾ã—ãŸã€‚çµæœã¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¨ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯å‘ä¸Šã—ã¦ã„ã¾ã™ãŒã€çµ¶å¯¾çš„ãªæ€§èƒ½ã¯ä½ãã€ãƒ¢ãƒ‡ãƒ«é–“ã®æ€§èƒ½ã‚‚ä¼¼ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ã¾ãŸã€ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã‹ã‚‰ã®åˆ©ç›Šã‚„ã‚¿ã‚¹ã‚¯ã®ç‰¹æ€§ã«ã¤ã„ã¦ã‚‚èª¿æŸ»ã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€æ›–æ˜§ãªæ–‡è„ˆã®è¨­å®šã§ã¯ç¤¾ä¼šçš„ãªåè¦‹ãŒå¢—åŠ ã™ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚Œã¾ã—ãŸãŒã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½¿ç”¨ã§æ”¹å–„ã§ãã‚‹å¯èƒ½æ€§ã‚‚ã‚ã‚Šã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=uyTL5Bvosj" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=uyTL5Bvosj</a>


</p>
<p>BIG-Benchè«–æ–‡ã€‚ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†å¸ƒã‚’è¦‹ã‚‹ã¨ä¸€ã¤ã®åˆ†é‡ã«ç•™ã¾ã‚‰ãªã„éå¸¸ã«å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ãŒå«ã¾ã‚Œã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/c3bfb1c1-2e85-47aa-b8ed-1e408b98f8c8" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/07f20e44-7318-476f-9952-be505d9033a4" alt="image" loading="lazy"></p>
<p>BIG-Bench-hardã¯ã€2024å¹´ã«Claude3.5ã«ã‚ˆã£ã¦ã€Average Human ScoreãŒ67.7%ã®ã¨ã“ã‚ã€93.1%ã‚’é”æˆã•ã‚Œæ”»ç•¥ãŒå®Œäº†ã—ãŸã€‚ç¾åœ¨ã¯æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«é–“ã®æ€§èƒ½ã‚’å·®åˆ¥åŒ–ã™ã‚‹ã“ã¨ã¯ã§ããªã„ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1662" target="_blank" rel="noopener noreferrer">Killed by LLM, R0bk</a>
</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2023-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/782" target="_blank" rel="noopener noreferrer" class="title-link">Augmenting Language Models with Long-Term Memory, Weizhi Wang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æ—¢å­˜ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€å…¥åŠ›é•·ã®åˆ¶é™ã«ã‚ˆã‚Šã€é•·ã„æ–‡è„ˆæƒ…å ±ã‚’æ´»ç”¨ã§ããªã„å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ãã“ã§ã€ç§ãŸã¡ã¯ã€Œé•·æœŸè¨˜æ†¶ã‚’æŒã¤è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLongMemï¼‰ã€ã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã¯é•·ã„å±¥æ­´ã‚’è¨˜æ†¶ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€ãƒ¡ãƒ¢ãƒªã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¨ã—ã¦å‡çµã•ã‚ŒãŸãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³LLMã¨ã€é©å¿œçš„ãªæ®‹ä½™ã‚µã‚¤ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’çµ„ã¿åˆã‚ã›ãŸåˆ†é›¢ã•ã‚ŒãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€é•·æœŸã®éå»ã®æ–‡è„ˆã‚’ç°¡å˜ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã€åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€LongMemãŒé•·ã„æ–‡è„ˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®é›£ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚‹ChapterBreakã§å¼·åŠ›ãªæ€§èƒ½ã‚’ç™ºæ®ã—ã€ãƒ¡ãƒ¢ãƒªå¢—å¼·å‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…å­¦ç¿’ã§æ”¹å–„ã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒé•·ã„å½¢å¼ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¨˜æ†¶ã—åˆ©ç”¨ã™ã‚‹ã®ã«åŠ¹æœçš„ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã«é•·æœŸã®historyã‚’è¨˜æ†¶ã•ã›ã‚‹ã“ã¨ã‚’å¯èƒ½ã™ã‚‹æ–°ãŸãªæ‰‹æ³•ã‚’ææ¡ˆã—ã€æ—¢å­˜ã®strongãªé•·ã„contextã‚’æ‰±ãˆã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ãŸ<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/98106f5b-22cf-420c-9251-5c7e03ead490" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/780" target="_blank" rel="noopener noreferrer" class="title-link">Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use  Large Language Models for Text Production Tasks, Veniamin Veselovsky+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ™®åŠç‡ã‚’èª¿æŸ»ã™ã‚‹ãŸã‚ã«ã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚ˆã‚‹LLMã®ä½¿ç”¨ã®äº‹ä¾‹ç ”ç©¶ã‚’è¡Œã£ãŸã€‚çµæœã‹ã‚‰ã€33ã€œ46ï¼…ã®ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚¿ã‚¹ã‚¯ã®å®Œäº†æ™‚ã«LLMsã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã“ã¨ãŒæ¨å®šã•ã‚ŒãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€äººé–“ã®ãƒ‡ãƒ¼ã‚¿ãŒäººé–“ã®ã‚‚ã®ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã«æ–°ã—ã„æ–¹æ³•ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Mturkã®è¨€èªç”Ÿæˆã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€Turkerã®ã†ã¡33-46%ã¯LLMsã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/779" target="_blank" rel="noopener noreferrer" class="title-link">Bring Your Own Data Self-Supervised Evaluation for Large Language  Models, Neel Jain+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æŒ¯ã‚‹èˆã„ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®è‡ªå·±æ•™å¸«ã‚ã‚Šè©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€äººé–“ã«ã‚ˆã‚‹ãƒ©ãƒ™ãƒ«ä»˜ã‘ãŒå¿…è¦ãªããªã‚Šã€å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®æ„Ÿåº¦ã‚„ä¸å¤‰æ€§ã‚’è©•ä¾¡ã§ãã‚‹ã€‚è‡ªå·±æ•™å¸«ã‚ã‚Šè©•ä¾¡ã¯ã€ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ–ãƒƒã‚¯ã®çŸ¥è­˜ã‚„æœ‰å®³æ€§ã€æ–‡è„ˆä¾å­˜æ€§ãªã©ã®å´é¢ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã¾ãŸã€äººé–“ã«ã‚ˆã‚‹æ•™å¸«ã‚ã‚Šè©•ä¾¡ã¨ã®ç›¸é–¢é–¢ä¿‚ã‚‚é«˜ã„ã€‚è‡ªå·±æ•™å¸«ã‚ã‚Šè©•ä¾¡ã¯ã€ç¾åœ¨ã®è©•ä¾¡æˆ¦ç•¥ã‚’è£œå®Œã™ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>
<strong># Motivation<br><br>LLMã®æ€¥é€Ÿãªç™ºå±•ã«ã‚ˆã£ã¦ã€ãã‚Œã‚‰ã®èƒ½åŠ›ã¨limitationã‚’æ­£ç¢ºã«ã¨ã‚‰ãˆã‚‹ãŸã‚ã®æ§˜ã€…ãªæ–°ãŸãªmetricsãŒææ¡ˆã•ã‚Œã¦ããŸãŒã€çµæœçš„ã«ã€æ–°ãŸãªãƒ¢ãƒ‡ãƒ«ãŒæ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å»ƒæ­¢ã«è¿½ã„è¾¼ã¿ã€å¸¸ã«æ–°ãŸãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹å¿…è¦ãŒç”Ÿã˜ã¦ã„ã‚‹ã€‚<br><br>è¿‘å¹´ã®BIG-Bench <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/785" target="_blank" rel="noopener noreferrer">Beyond the Imitation Game: Quantifying and extrapolating the   capabilities of language models, Aarohi Srivastava+, N/A, TMLR'23</a>
</strong>
<br>
 ã‚„ HELM <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/786" target="_blank" rel="noopener noreferrer">Holistic Evaluation of Language Models, Percy Liang+, TMLR'23</a>
 ã¯ã“ã‚Œã‚‰ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€å¢—ãˆç¶šã‘ã‚‹è“„ç©ã•ã‚ŒãŸå¤šæ§˜ãªmicro-benchmarkã‚’ç”¨ã„ã¦LLMã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¸¬å®šã™ã‚‹ã“ã¨ã§å¯¾å‡¦ã—ã¦ã„ã‚‹ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç”Ÿæˆã¨ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ä¾å­˜ã—ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ãªã£ã¦ãŠã‚Šã€ã“ã‚Œã‚‰ã¯tine-consumingã§expensiveã§ã‚ã‚‹ã€‚åŠ ãˆã¦ã€è©•ä¾¡ã¯ä¸€èˆ¬çš„ã«datset-centricã§ã‚ã‚Šã€å›ºå®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ä½•ã‚‰ã‹ã®metricsã‚„äººæ‰‹ã§ä»˜ä¸ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã«åŸºã¥ã„ã¦è©•ä¾¡ã•ã‚Œã‚‹ãŒã€ãƒ¢ãƒ€ãƒ³ãªLLMã§ã¯ã€ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯æ–°ãŸãªå•é¡ŒãŒç”Ÿã˜ã¦ã—ã¾ã†ã€‚<br><br>- è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã§ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã•ã‚Œã‚‹ã“ã¨ã€‚ã“ã‚Œã«ã‚ˆã£ã¦ã€LLMã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦åˆ©ç”¨ã•ã‚Œã¦ã—ã¾ã„ã€å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–ã‚Šé™¤ã‹ãªã„é™ã‚Šunreliableã¨ãªã£ã¦ã—ã¾ã†ã€‚<br><br>- ã•ã¾ã–ã¾ãª LLM ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒå€‹åˆ¥ã®æ©Ÿèƒ½ã«ä¾å­˜ã—ã¦ãŠã‚Šã€æœ€æ–°ã® LLM ã§è©•ä¾¡ã™ã‚‹æ©Ÿèƒ½ã®æ•°ãŒå¢—ãˆç¶šã‘ã‚‹ãŸã‚ã€LLM ã®è©•ä¾¡ã¯å¤šé¢çš„ã§ã‚ã‚‹ã“ã¨ã€‚<br><br><br><br>å¤§è¦æ¨¡ãªå‡ºãŸã‚»ãƒƒãƒˆã‚’curationã™ã‚‹ã“ã¨ã¯expensiveã§ã‚ã‚‹ãŸã‚ã€HELMã¯ç‰¹å®šã®ã‚·ãƒŠãƒªã‚ªã«ãŠã‘ã‚‹ç‰¹å®šã®èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã«ä½œæˆã•ã‚ŒãŸå°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€ã‚ˆã‚Šåºƒç¯„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚„è¨­å®šã§ãƒ¢ãƒ‡ãƒ«ãŒãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã¨ãã«ã€ã“ã®ã‚ˆã†ãªè©•ä¾¡ãŒé©ç”¨å¯èƒ½ã‹ã¯å®šã‹ã§ã¯ãªã„ã€‚<br><br>ã“ã‚Œã¾ã§ã®è©•ä¾¡æ–¹æ³•ã‚’è£œå®Œã™ã‚‹ãŸã‚ã«ã€ã“ã®ç ”ç©¶ã§ã¯ã€self-supervised model evaluationãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã¯ã€metricsã¯invariancesã¨sensitivitiesã¨å‘¼ã°ã‚Œã‚‹ã‚‚ã®ã§å®šç¾©ã•ã‚Œã€ãƒ©ãƒ™ãƒ«ã‚’å¿…è¦ã¨ã—ãªã„ã€‚ä»£ã‚ã‚Šã«ã€self-supervisionã®ãƒ•ã‚§ãƒ¼ã‚ºã«ä»‹å…¥ã™ã‚‹ã“ã¨ã§ã“ã‚Œã‚‰ã®metricsã‚’ç®—å‡ºã™ã‚‹ã€‚self-supervised evaluationã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ã€ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ä¾å­˜ã—ã¦ã„ãªã„ãŸã‚ã€ã“ã‚Œã¾ã§ã®metricsã‚ˆã‚Šã‚‚ã‚ˆã‚Šè†¨å¤§ãªã‚³ãƒ¼ãƒ‘ã‚¹ã‚’è©•ä¾¡ã«æ´»ç”¨ã§ããŸã‚Šã€ã‚ã‚‹ã„ã¯day-to-day performanceã¨ã—ã¦ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚’ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ä¸Šã§å®Ÿæ–½ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</p>
<p>ä»¥ä¸‹Dr. Sebastian Ruschkaã®ãƒ„ã‚¤ãƒ¼ãƒˆã®å¼•ç”¨<br><br>&gt;We use self-supervised learning to pretrain LLMs (e.g., next-word prediction). <br>Here's an interesting take using self-supervised learning for evaluating LLMs: arxiv.org/abs//2306.13651<br>Turns out, there's correlation between self-supervised evaluations &amp; human evaluations.<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cebf74e2-d536-4c88-965a-08c6c0e823e1" alt="image" loading="lazy"><br><br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1679139569327824897?s=46&t=ArwxeDos47eUWfAg7_FRtg"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>å›³ãŒéå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2023-06-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/775" target="_blank" rel="noopener noreferrer" class="title-link">Towards Language Models That Can See: Computer Vision Through the LENS  of Natural Language, William Berrios+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€LENSã¨ã„ã†ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã®å•é¡Œã«å–ã‚Šçµ„ã¿ã¾ã™ã€‚LENSã¯ã€ç‹¬ç«‹ã—ãŸãƒ“ã‚¸ãƒ§ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å‡ºåŠ›ã«å¯¾ã—ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦æ¨è«–ã‚’è¡Œã„ã¾ã™ã€‚ç§ãŸã¡ã¯ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆãŠã‚ˆã³ãƒ•ãƒ¥ãƒ¼ã‚·ãƒ§ãƒƒãƒˆã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆèªè­˜ãªã©ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã®è¨­å®šã§LENSã‚’è©•ä¾¡ã—ã¾ã—ãŸã€‚LENSã¯å¸‚è²©ã®LLMã«é©ç”¨ã§ãã€éå¸¸ã«ç«¶äº‰åŠ›ã®ã‚ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1674878733264781312?s=46&t=KFT8cWTu8vV69iD6Qt0NGw"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e96f9a8a-6ce2-4985-8b0a-8daf4a6e477c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<span class="issue_date">Issue Date: 2023-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/773" target="_blank" rel="noopener noreferrer" class="title-link">AudioPaLM: A Large Language Model That Can Speak and Listen, Paul K. Rubenstein+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€éŸ³å£°ç†è§£ã¨ç”Ÿæˆã®ãŸã‚ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚‹AudioPaLMã‚’ç´¹ä»‹ã™ã‚‹ã€‚AudioPaLMã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã¨éŸ³å£°ã‚’å‡¦ç†ãŠã‚ˆã³ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã€PaLM-2ã¨AudioLMã‚’çµ±åˆã—ã¦ã„ã‚‹ã€‚ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ä½¿ç”¨ã—ã¦AudioPaLMã‚’åˆæœŸåŒ–ã™ã‚‹ã“ã¨ã§ã€éŸ³å£°å‡¦ç†ã‚’æ”¹å–„ã—ã€å¤šãã®è¨€èªã«å¯¾ã—ã¦ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆéŸ³å£°å¯¾ãƒ†ã‚­ã‚¹ãƒˆç¿»è¨³ã‚’å®Ÿè¡Œã™ã‚‹èƒ½åŠ›ã‚’æŒã¤ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã¾ãŸã€AudioPaLMã¯ã€éŸ³å£°è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ©Ÿèƒ½ã‚‚ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1673454388931891201?s=46&t=aLGqdPv6JkRbT0kxsf6Aww"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pruning.html" target="_blank" rel="noopener noreferrer">#Pruning</a>
<span class="issue_date">Issue Date: 2023-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/772" target="_blank" rel="noopener noreferrer" class="title-link">A Simple and Effective Pruning Approach for Large Language Models, Mingjie Sun+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å‰ªå®šæ–¹æ³•ã§ã‚ã‚‹Wandaã‚’ç´¹ä»‹ã—ã¦ã„ã‚‹ã€‚Wandaã¯ã€é‡ã¿ã¨æ´»æ€§åŒ–ã«ã‚ˆã‚‹å‰ªå®šã‚’è¡Œã„ã€å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„é‡ã¿ã®æ›´æ–°ã‚’å¿…è¦ã¨ã›ãšã€å‰ªå®šã•ã‚ŒãŸLLMã¯ãã®ã¾ã¾ä½¿ç”¨ã§ãã‚‹ã€‚Wandaã¯ã€LLaMAä¸Šã§ã®ã•ã¾ã–ã¾ãªè¨€èªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¾¹åº•çš„ã«è©•ä¾¡ã•ã‚Œã€å¤§ãã•ã«åŸºã¥ãå‰ªå®šã®ç¢ºç«‹ã•ã‚ŒãŸãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€é‡ã¿ã®æ›´æ–°ã«é–¢ã™ã‚‹æœ€è¿‘ã®æ–¹æ³•ã¨ç«¶åˆã™ã‚‹å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã‚³ãƒ¼ãƒ‰ã¯https://github.com/locuslab/wandaã§åˆ©ç”¨å¯èƒ½ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®pruningæ‰‹æ³•ã‚’ææ¡ˆã€‚å†è¨“ç·´ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ç„¡ã—ã§ã€æ€§èƒ½ä½ä¸‹ãŒå°‘ãªãã¦åˆˆã‚Šè¾¼ã¿ãŒå¯èƒ½ã€‚</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/770" target="_blank" rel="noopener noreferrer" class="title-link">SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling  with Backtracking, Chris Cundy+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”Ÿæˆã«ãŠã„ã¦ã€æœ€å°¤æ¨å®šï¼ˆMLEï¼‰ç›®çš„ã¯èª¤å·®ã®è“„ç©å•é¡Œã‚’å¼•ãèµ·ã“ã™ãŸã‚ã€æ¨¡å€£å­¦ç¿’ï¼ˆILï¼‰å•é¡Œã¨ã—ã¦å®šå¼åŒ–ã™ã‚‹ã“ã¨ãŒææ¡ˆã•ã‚ŒãŸã€‚ILãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ãƒãƒƒã‚¯ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã€èª¤å·®ã®è“„ç©å•é¡ŒãŒè»½æ¸›ã•ã‚Œã‚‹ã€‚ææ¡ˆæ‰‹æ³•ã§ã‚ã‚‹SequenceMatchã¯ã€æ•µå¯¾çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„å¤§è¦æ¨¡ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å¤‰æ›´ãªã—ã«å®Ÿè£…ã§ãã€SequenceMatch-$\chi^2$ç™ºæ•£ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚å®Ÿé¨“çš„ã«ã€SequenceMatchãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ãŠã„ã¦MLEã‚ˆã‚Šã‚‚æ”¹å–„ã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>backspaceã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã«çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€out of distributionã‚’å¼•ãèµ·ã“ã™ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…ƒã«æˆ»ã™ã“ã¨ã§ã€ç”Ÿæˆã‚¨ãƒ©ãƒ¼ã‚’è»½æ¸›ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e22d059f-5475-417c-aea2-d1fd55b6c23a" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2023-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/769" target="_blank" rel="noopener noreferrer" class="title-link">Full Parameter Fine-tuning for Large Language Models with Limited  Resources, Kai Lv+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯è†¨å¤§ãªGPUãƒªã‚½ãƒ¼ã‚¹ãŒå¿…è¦ã§ã‚ã‚Šã€æ—¢å­˜ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯é™ã‚‰ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã§ã®å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®èª¿æ•´ã«å¯¾å‡¦ã—ã¦ã„ãªã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LOMOã¨ã„ã†æ–°ã—ã„æœ€é©åŒ–æ‰‹æ³•ã‚’ææ¡ˆã—ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ã§ã€8ã¤ã®RTX 3090ã‚’æ­è¼‰ã—ãŸå˜ä¸€ã®ãƒã‚·ãƒ³ã§65Bãƒ¢ãƒ‡ãƒ«ã®å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¯èƒ½ã«ãªã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>8xRTX3090 24GBã®ãƒã‚·ãƒ³ã§65Bãƒ¢ãƒ‡ãƒ«ã®å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã‚‹æ‰‹æ³•ã€‚LoRAã®ã‚ˆã†ãªï¼ˆæ–°ãŸã«è¿½åŠ ã—ã‚ŒãŸï¼‰ä¸€éƒ¨ã®é‡ã¿ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚‹ã‚ˆã†ãªæ çµ„ã¿ã§ã¯ãªã„ã€‚å‹¾é…è¨ˆç®—ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã‚’one stepã§å®Ÿæ–½ã™ã‚‹ã“ã¨ã§å®Ÿç¾ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/KnowledgeGraph.html" target="_blank" rel="noopener noreferrer">#KnowledgeGraph</a>
<span class="issue_date">Issue Date: 2023-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/768" target="_blank" rel="noopener noreferrer" class="title-link">Unifying Large Language Models and Knowledge Graphs: A Roadmap, Shirui Pan+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¨KGsã‚’çµ±åˆã™ã‚‹ã“ã¨ã§ã€è‡ªç„¶è¨€èªå‡¦ç†ã‚„äººå·¥çŸ¥èƒ½ã®åˆ†é‡ã§æ³¨ç›®ã‚’é›†ã‚ã¦ã„ã‚‹ã€‚KGsã¯è±Šå¯Œãªäº‹å®ŸçŸ¥è­˜ã‚’æ˜ç¤ºçš„ã«æ ¼ç´ã—ã¦ã„ã‚‹ãŒã€æ§‹ç¯‰ãŒå›°é›£ã§ã‚ã‚Šã€é€²åŒ–ã™ã‚‹æ€§è³ªã‚’æŒã£ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã€LLMsã¯ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€äº‹å®ŸçŸ¥è­˜ã‚’æ‰ãˆãŸã‚Šã‚¢ã‚¯ã‚»ã‚¹ã—ãŸã‚Šã™ã‚‹ã“ã¨ãŒã§ããªã„ã€‚æœ¬è¨˜äº‹ã§ã¯ã€LLMsã¨KGsã‚’çµ±åˆã™ã‚‹ãŸã‚ã®å±•æœ›ã‚’ç¤ºã—ã€KG-enhanced LLMsã€LLM-augmented KGsã€Synergized LLMs + KGsã®3ã¤ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã™ã‚‹ã€‚æ—¢å­˜ã®å–ã‚Šçµ„ã¿ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ä»Šå¾Œã®ç ”ç©¶æ–¹å‘ã‚’æŒ‡æ‘˜ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMsã¨KGã®çµ±åˆã«é–¢ã™ã‚‹ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’æç¤ºã€‚KGã‚’LLMã®äº‹å‰å­¦ç¿’ã‚„æ¨è«–ã«çµ„ã¿è¾¼ã‚€æ–¹æ³•ã€KGã‚¿ã‚¹ã‚¯ã«LLMã‚’åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã€LLMã¨KGã®åŒæ–¹å‘ã®reasoniegèƒ½åŠ›ã‚’é«˜ã‚ã‚‹æ–¹æ³•ãªã©ã‚’ã‚«ãƒãƒ¼ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c008d409-e5db-4140-a82c-a658a4847780" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer" class="title-link">Textbooks Are All You Need, Suriya Gunasekar+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å°è¦æ¨¡ãªphi-1ã¨ã„ã†æ–°ã—ã„ã‚³ãƒ¼ãƒ‰ç”¨å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç´¹ä»‹ã—ã€8ã¤ã®A100ã§4æ—¥é–“ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸçµæœã€HumanEvalã§pass@1ã®æ­£è§£ç‡50.6ï¼…ã€MBPPã§55.5ï¼…ã‚’é”æˆã—ãŸã“ã¨ã‚’å ±å‘Šã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€phi-1ã¯ã€phi-1-baseã‚„phi-1-smallã¨æ¯”è¼ƒã—ã¦ã€é©šãã¹ãæ–°ã—ã„æ€§è³ªã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚phi-1-smallã¯ã€HumanEvalã§45ï¼…ã‚’é”æˆã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1671643297616654342?s=46&t=JYDYid2m0v7vYaL7jhZYjQ"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ•™ç§‘æ›¸ã®ã‚ˆã†ãªå“è³ªã®è‰¯ã„ãƒ†ã‚­ã‚¹ãƒˆã§äº‹å‰å­¦ç¿’ã™ã‚‹ã¨æ€§èƒ½ãŒå‘ä¸Šã—ï¼ˆã‚°ãƒ©ãƒ•çœŸã‚“ä¸­ï¼‰ã€ã•ã‚‰ã«è‰¯è³ªãªã‚¨ã‚¯ã‚µã‚µã‚¤ã‚ºã§Finetuningã™ã‚‹ã¨ã‚ˆã‚Šæ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ï¼ˆã‚°ãƒ©ãƒ•å³ï¼‰<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9f0b945a-f965-42ae-b5d8-ac464359af35" alt="image" loading="lazy"></p>
<p>æ—¥æœ¬èªè§£èª¬: 


<a href="https://dalab.jp/archives/journal/introduction-textbooks-are-all-you-need/" target="_blank" rel="noopener noreferrer">https://dalab.jp/archives/journal/introduction-textbooks-are-all-you-need/</a>


</p>
<p>ã–ã£ãã‚Šè¨€ã†ã¨ã€æ•™ç§‘æ›¸ã§äº‹å‰å­¦ç¿’ã—ã€ã‚¨ã‚¯ã‚µã‚µã‚¤ã‚ºã§Finetuningã™ã‚‹ã¨æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ï¼ˆ= ã‚ˆã‚Šå¤§ãã„ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ãŒå¾—ã‚‰ã‚Œã‚‹ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/765" target="_blank" rel="noopener noreferrer" class="title-link">RWKV: Reinventing RNNs for the Transformer Era, Bo Peng+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¨RNNã®ä¸¡æ–¹ã®åˆ©ç‚¹ã‚’çµ„ã¿åˆã‚ã›ãŸæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚‹RWKVã‚’ææ¡ˆã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«è¨ˆç®—ã‚’ä¸¦åˆ—åŒ–ã—ã€æ¨è«–ä¸­ã«ä¸€å®šã®è¨ˆç®—ãŠã‚ˆã³ãƒ¡ãƒ¢ãƒªã®è¤‡é›‘ã•ã‚’ç¶­æŒã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚RWKVã¯ã€åŒã˜ã‚µã‚¤ã‚ºã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã€å°†æ¥çš„ã«ã¯ã‚ˆã‚ŠåŠ¹ç‡çš„ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ãŸã‚ã«ã“ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ´»ç”¨ã§ãã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç•°ãªã‚‹transformerã¨RWKVã®è¨ˆç®—é‡ã¨ãƒ¡ãƒ¢ãƒªæ¶ˆè²»é‡ã®æ¯”è¼ƒ<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/84d5241f-1702-4bd6-8ce3-0a80ded8f192" alt="image" loading="lazy"><br><br><br><br>RWKVã®æ§‹é€ ã¯åŸºæœ¬çš„ã«ã€residual blockã‚’ã‚¹ã‚¿ãƒƒã‚¯ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦æ§‹æˆã•ã‚Œã‚‹ã€‚ä¸€ã¤ã®residual blockã¯ã€time-mixingï¼ˆæ™‚é–“æ–¹å‘ã®æ··ãœåˆã‚ã›ï¼‰ã¨ã€channnel-mixingï¼ˆè¦ç´ é–“ã§ã®æ··ãœåˆã‚ã›ï¼‰ã‚’è¡Œã†ã€‚ã€€<br><br>RWKVã®ã‚«ã‚®ã¨ãªã‚‹è¦ç´ ã¯ä»¥ä¸‹ã®4ã¤ã§ã‚ã‚Šã€RWKVã®ãƒ–ãƒ­ãƒƒã‚¯ã€ãŠã‚ˆã³LMã§ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚‹ï¼š<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2185d678-8ca1-4017-a052-77c073704253" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e5559a3c-40ee-4859-ba75-2827c12b5964" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4af26c0f-5907-4723-b24c-67b02a8025b9" alt="image" loading="lazy"><br><br><br><br>ã“ã“ã§ã€token-shiftã¯ã€previsou timestepã®inputã¨ã®linear interpolationã‚’ç¾åœ¨ã®inputã¨ã¨ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šå†å¸°æ€§ã‚’æ‹…ä¿ã™ã‚‹ã€‚<br><br><br><br>RWKVã¯ä»–ã®LLMã¨æ¯”è¼ƒã—ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã«å¯¾ã—ã¦æ€§èƒ½ã¯comparableã§ã‚ã‚Šã€context lengthã‚’å¢—ã‚„ã™ã“ã¨ã§ã€lossã¯ãã¡ã‚“ã¨ä½ä¸‹ã—ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’ã™ã‚‹éš›ã«è¦ã™ã‚‹æ™‚é–“ã¯ä»–ã®LLMã¨æ¯”è¼ƒã—ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã«å¯¾ã—ã¦ç·šå½¢ã«ã—ã‹å¢—åŠ ã—ãªã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c8a39aae-17de-4c43-bfba-b6a54f83205e" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9baf95d0-9e8c-4c62-a8f3-0f2a0d67ae00" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a9601b1c-c403-4c2c-bd60-3d2cfa6e512e" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/764" target="_blank" rel="noopener noreferrer" class="title-link">How Language Model Hallucinations Can Snowball, Muru Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹éš›ã®ãƒªã‚¹ã‚¯ã¨ã—ã¦ã€å¹»è¦šãŒã‚ã‚‹ã“ã¨ãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã®å¹»è¦šã¯ã€LMã®çŸ¥è­˜ä¸è¶³ã«ã‚ˆã‚‹ã‚‚ã®ã ã‘ã§ãªãã€ä»¥å‰ã«ç”Ÿæˆã•ã‚ŒãŸå¹»è¦šã‚’æ­£å½“åŒ–ã™ã‚‹ãŸã‚ã«ã€LMãŒèª¤ã£ãŸä¸»å¼µã‚’å‡ºåŠ›ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã¨ã„ã†ä»®èª¬ãŒç«‹ã¦ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ChatGPTã¨GPT-4ã¯ã€èª¤ã£ãŸå›ç­”ã‚’ç¤ºã—ã€å¹»è¦šã®ã‚¹ãƒãƒ¼ãƒœãƒ¼ãƒ«åŠ¹æœã«ã‚ˆã‚Šã€ã‚ˆã‚Šå¤šãã®èª¤ã‚ŠãŒç”Ÿã˜ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ã¾ãŸã€èª¤ã‚Šã‚’å«ã‚€è³ªå•å¿œç­”ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒæ§‹ç¯‰ã•ã‚Œã€LMãŒè‡ªåˆ†è‡ªèº«ã®èª¤ã‚Šã‚’è­˜åˆ¥ã§ãã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã«ã‚ˆã‚‹hallucinationã¯ã€å˜ã«LLMã®çŸ¥è­˜ä¸è¶³ã«ã‚ˆã‚‹ã‚‚ã®ã ã‘ã§ã¯ãªãã€LLMãŒä»¥å‰ã«ç”Ÿæˆã—ãŸhallucinationã‚’æ­£å½“åŒ–ã™ã‚‹ãŸã‚ã«ã€èª¤ã£ãŸå‡ºåŠ›ã‚’ç”Ÿæˆã—ã¦ã—ã¾ã†ã¨ã„ã†ä»®èª¬ã‚’æèµ·ã—ã€ã“ã®ä»®èª¬ã‚’æ¤œè¨¼ã—ãŸç ”ç©¶ã€‚ã“ã‚Œã‚’hallucination snowballã¨å‘¼ã¶ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMã‚’è¨“ç·´ã™ã‚‹éš›ã«ã€äº‹å®Ÿã«å¯¾ã™ã‚‹æ­£ç¢ºã•ã‚’çŠ ç‰²ã«ã—ã¦ã€æµæš¢æ€§ã¨ä¸€è²«æ€§ã‚’å„ªå…ˆã—è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ãƒªã‚¹ã‚¯ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6a9e29b7-953f-4e72-bfdd-85daab9317d6" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/763" target="_blank" rel="noopener noreferrer" class="title-link">LLMs as Factual Reasoners: Insights from Existing Benchmarks and Beyond, Philippe Laban+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã‚’ä½¿ç”¨ã—ã¦äº‹å®Ÿã®çŸ›ç›¾ã‚’æ¤œå‡ºã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ãŒã€æ—¢å­˜ã®è©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å•é¡ŒãŒã‚ã‚‹ãŸã‚ã€ã»ã¨ã‚“ã©ã®LLMã¯è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«å¤±æ•—ã™ã‚‹ã€‚ãã“ã§ã€æ–°ã—ã„ä¸æ•´åˆæ¤œå‡ºãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã‚ã‚‹SummEditsã‚’ææ¡ˆã—ã€å®Ÿè£…ã—ãŸã€‚SummEditsã¯é«˜ã„å†ç¾æ€§ã‚’æŒã¡ã€ã»ã¨ã‚“ã©ã®LLMã¯è‹¦æˆ¦ã™ã‚‹ã€‚æœ€ã‚‚å„ªã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã€äººé–“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‹ã‚‰8ï¼…ä½ã„çµæœã¨ãªã‚Šã€LLMãŒäº‹å®Ÿã«ã¤ã„ã¦æ¨è«–ã—ã€çŸ›ç›¾ã‚’æ¤œå‡ºã™ã‚‹èƒ½åŠ›ã«ã¯ã¾ã èª²é¡ŒãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¢å­˜ã®ä¸æ•´åˆæ¤œå‡ºã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ã€7+%ã‚’è¶…ãˆã‚‹ã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã—ã¦ã€mislabeledãªã‚µãƒ³ãƒ—ãƒ«ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚¯ã‚ªãƒªãƒ†ã‚£ã«å•é¡ŒãŒã‚ã£ãŸã€‚ãã“ã§SummEditsã¨å‘¼ã°ã‚Œã‚‹äº‹å®Ÿã®çŸ›ç›¾ã®æ¤œå‡ºåŠ›ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã®æ–°ãŸãªãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ææ¡ˆã€‚æ—¢å­˜ã®ä¸æ•´åˆæ¤œå‡ºã§ã¯ã€æ—¢å­˜ã®LLMã‚’ç”¨ã„ã¦æ¯”è¼ƒã—ãŸçµæœã€æœ€ã‚‚ä¸æ•´åˆæ¤œå‡ºã§æ€§èƒ½ãŒè‰¯ã‹ã£ãŸGPT-4ã§ã•ãˆã€äººé–“ã«å¯¾ã—ã¦8%ã‚‚ä½ã„æ€§èƒ½ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œï¼ˆè¦ç´„çµæœã«å¯¾ã—ã¦äº‹å®Ÿã®çŸ›ç›¾ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹å¦ã‹æ¤œå‡ºã™ã‚‹ã‚¿ã‚¹ã‚¯ï¼‰ã€ã¾ã ã¾ã LLMã«ã¯èª²é¡ŒãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/45473a67-7f96-4f75-841c-9ccf95852394" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/754" target="_blank" rel="noopener noreferrer" class="title-link">OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities, Yuanzhen Xie+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€äººé–“ã®èªçŸ¥ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ¨¡å€£ã™ã‚‹ã“ã¨ã§ã€è¤‡é›‘ãªæ¨è«–å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®æ–°ã—ã„çŸ¥çš„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹OlaGPTã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚OlaGPTã¯ã€æ³¨æ„ã€è¨˜æ†¶ã€æ¨è«–ã€å­¦ç¿’ãªã©ã®ç•°ãªã‚‹èªçŸ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å«ã¿ã€ä»¥å‰ã®èª¤ã‚Šã‚„å°‚é–€å®¶ã®æ„è¦‹ã‚’å‹•çš„ã«å‚ç…§ã™ã‚‹å­¦ç¿’ãƒ¦ãƒ‹ãƒƒãƒˆã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€Chain-of-Thoughtï¼ˆCOTï¼‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨åŒ…æ‹¬çš„ãªæ„æ€æ±ºå®šãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚‚ææ¡ˆã•ã‚Œã¦ã„ã¾ã™ã€‚OlaGPTã¯ã€è¤‡æ•°ã®æ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å³å¯†ã«è©•ä¾¡ã•ã‚Œã€æœ€å…ˆç«¯ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä¸Šå›ã‚‹å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚OlaGPTã®å®Ÿè£…ã¯GitHubã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/729" target="_blank" rel="noopener noreferrer" class="title-link">KoLA: Carefully Benchmarking World Knowledge of Large Language Models, Jifan Yu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®è©•ä¾¡ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã€KoLAã¨ã„ã†çŸ¥è­˜æŒ‡å‘ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã—ãŸã€‚ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã€19ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚«ãƒãƒ¼ã—ã€Wikipediaã¨æ–°èˆˆã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã€çŸ¥è­˜ã®å¹»è¦šã‚’è‡ªå‹•çš„ã«è©•ä¾¡ã™ã‚‹ç‹¬è‡ªã®è‡ªå·±å¯¾ç…§ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’å«ã‚€å¯¾ç…§çš„ãªã‚·ã‚¹ãƒ†ãƒ ã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚21ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨å•†ç”¨ã®LLMã‚’è©•ä¾¡ã—ã€KoLAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã‚ªãƒ¼ãƒ—ãƒ³å‚åŠ ã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã¯ã€LLMã‚„çŸ¥è­˜é–¢é€£ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã®å‚è€ƒè³‡æ–™ã¨ã—ã¦ç¶™ç¶šçš„ã«æ›´æ–°ã•ã‚Œã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/725" target="_blank" rel="noopener noreferrer" class="title-link">One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning, Arnav Chavan+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ±ç”¨çš„ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã®é«˜åº¦ãªæ‰‹æ³•ã§ã‚ã‚‹Generalized LoRA (GLoRA)ã‚’ææ¡ˆã—ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’æœ€é©åŒ–ã—ã€ä¸­é–“ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ã‚ˆã‚ŠæŸ”è»Ÿæ€§ã¨èƒ½åŠ›ã‚’æä¾›ã™ã‚‹ã€‚GLoRAã¯ã€å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å€‹åˆ¥ã®ã‚¢ãƒ€ãƒ—ã‚¿ã‚’å­¦ç¿’ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼ãªãƒ¬ã‚¤ãƒ¤ãƒ¼ã”ã¨ã®æ§‹é€ æ¢ç´¢ã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é©å¿œã‚’ä¿ƒé€²ã™ã‚‹ã€‚åŒ…æ‹¬çš„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€GLoRAã¯ã€è‡ªç„¶è¨€èªã€å°‚é–€åˆ†é‡ã€æ§‹é€ åŒ–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ãŠã„ã¦ã€å¾“æ¥ã®ã™ã¹ã¦ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã€æ§˜ã€…ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ˆã‚Šå°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨è¨ˆç®—ã§å„ªã‚ŒãŸç²¾åº¦ã‚’é”æˆã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=K7KQkiHanD" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=K7KQkiHanD</a>


<br><br>ICLR'24ã«rejectã•ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/PairWise.html" target="_blank" rel="noopener noreferrer">#PairWise</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Ensemble.html" target="_blank" rel="noopener noreferrer">#Ensemble</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/708" target="_blank" rel="noopener noreferrer" class="title-link">LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and  Generative Fusion, Dongfu Jiang+, N_A, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- LLM-Blenderã¯ã€è¤‡æ•°ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ãŸã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€PairRankerã¨GenFuserã®2ã¤ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚PairRankerã¯ã€å°‚é–€çš„ãªãƒšã‚¢ãƒ¯ã‚¤ã‚ºæ¯”è¼ƒæ–¹æ³•ã‚’ä½¿ç”¨ã—ã¦å€™è£œã®å‡ºåŠ›é–“ã®å¾®å¦™ãªé•ã„ã‚’åŒºåˆ¥ã—ã€GenFuserã¯ã€ä¸Šä½ãƒ©ãƒ³ã‚¯ã®å€™è£œã‚’ãƒãƒ¼ã‚¸ã—ã¦æ”¹å–„ã•ã‚ŒãŸå‡ºåŠ›ã‚’ç”Ÿæˆã—ã¾ã™ã€‚MixInstructã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å°å…¥ã—ã€LLM-Blenderã¯ã€å€‹ã€…ã®LLMsã‚„ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€å¤§ããªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å·®ã‚’ç¢ºç«‹ã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-05-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/702" target="_blank" rel="noopener noreferrer" class="title-link">Visualizing Linguistic Diversity of Text Datasets Synthesized by Large  Language Models, Emily Reif+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã‚’ä½¿ç”¨ã—ã¦ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹æ–‡çš„å¤šæ§˜æ€§ã‚’ç†è§£ã—åˆ†æã™ã‚‹ãŸã‚ã®æ–°ã—ã„å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«ã§ã‚ã‚‹LinguisticLensãŒæä¾›ã•ã‚ŒãŸã€‚ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹æ–‡ã€èªå½™ã€ãŠã‚ˆã³æ„å‘³ã®è»¸ã«æ²¿ã£ã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ã€éšå±¤çš„ãªå¯è¦–åŒ–ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã€‚ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¢ã¯shorturl.at/zHOUVã§åˆ©ç”¨å¯èƒ½ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã‚’ç”¨ã„ã¦few-shot promptingã‚’åˆ©ç”¨ã—ã¦ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç†è§£ã—è©•ä¾¡ã™ã‚‹ã“ã¨ã¯é›£ã—ãã€ãã‚‚ãã‚‚LLMã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®å¤±æ•—ã«é–¢ã—ã¦ã¯ã‚ã¾ã‚Šç†è§£ãŒé€²ã‚“ã§ã„ãªã„ï¼ˆe.g. repetitionãªã©ã¯çŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ï¼‰ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€LLMã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç‰¹æ€§ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€æ§‹æ–‡ãƒ»èªå½™ãƒ»æ„å‘³ã®è»¸ã«æ²¿ã£ã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç‰¹æ€§ã‚’å¯è¦–åŒ–ã™ã‚‹ã“ã¨ã§ã€ã“ã®ã‚ˆã†ãªèª²é¡Œã‚’è§£æ±ºã™ã‚‹ã“ã¨ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã€‚<br><br><br><br>ç‰¹ã«ã€å¾“æ¥ç ”ç©¶ã§ã¯GoldãŒå­˜åœ¨ã™ã‚‹ã“ã¨ãŒå‰æãªæ‰‹æ³•ãŒåˆ©ç”¨ã•ã‚Œã¦ããŸï¼ˆe.g. ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã—downstream taskã®äºˆæ¸¬æ€§èƒ½ã§è‰¯ã•ã‚’æ¸¬ã‚‹ã€Gold distributionã¨distributionã‚’æ¯”è¼ƒã™ã‚‹ï¼‰ã€‚ã—ã‹ã—ã€ã“ã®ã‚ˆã†ãªæ‰‹æ³•ã§ã¯ã€synthetic data firstãªã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã§ã€GoldãŒå­˜åœ¨ã—ãªã„å ´åˆã«å¯¾å‡¦ã§ããªã„ã€‚ã“ã®ã‚ˆã†ãªå•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«Gold dataãŒå­˜åœ¨ã—ãªã„å ´åˆã«ã€ãƒ‡ãƒ¼ã‚¿ã®æ§‹æ–‡ãƒ»èªå½™ãƒ»æ„å‘³ã«åŸºã¥ãã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿæ–½ã—çµæœã‚’å¯è¦–åŒ–ã—ã€human-in-the-loopã®æ çµ„ã¿ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è‰¯ã•ã‚’æ¤œè¨¼ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚</p>
<p>å¯è¦–åŒ–ä¾‹<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4bc73eee-9d26-4405-9d61-eca0a39fa852" alt="image" loading="lazy"></p>
<p>å®Ÿè£…: 


<a href="https://github.com/PAIR-code/interpretability/tree/master/data-synth-syntax" target="_blank" rel="noopener noreferrer">https://github.com/PAIR-code/interpretability/tree/master/data-synth-syntax</a>


</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/DataDistillation.html" target="_blank" rel="noopener noreferrer">#DataDistillation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-05-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/700" target="_blank" rel="noopener noreferrer" class="title-link">LIMA: Less Is More for Alignment, Chunting Zhou+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€65Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®LLaMaè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹LIMAã‚’è¨“ç·´ã—ã€å¼·åŒ–å­¦ç¿’ã‚„äººé–“ã®å¥½ã¿ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãªã—ã«ã€å³é¸ã•ã‚ŒãŸ1,000ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ã¿ã§æ¨™æº–çš„ãªæ•™å¸«ã‚ã‚Šæå¤±ã§å¾®èª¿æ•´ã—ã¾ã—ãŸã€‚LIMAã¯ã€å¹…åºƒã„ã‚¯ã‚¨ãƒªã«å¯¾å¿œã™ã‚‹é©šãã¹ãå¼·åŠ›ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«ç¾ã‚Œãªã‹ã£ãŸæœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ã«ã‚‚ä¸€èˆ¬åŒ–ã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚åˆ¶å¾¡ã•ã‚ŒãŸäººé–“ã®ç ”ç©¶ã§ã¯ã€LIMAã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ã€GPT-4ã€Bardã€DaVinci003ã¨æ¯”è¼ƒã—ã¦å„ªã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã“ã‚Œã‚‰ã®çµæœã‹ã‚‰ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã»ã¨ã‚“ã©ã®çŸ¥è­˜ã¯äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«å­¦ç¿’ã•ã‚Œã€é«˜å“è³ªã®å‡ºåŠ›ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã¯é™ã‚‰ã‚ŒãŸæŒ‡ç¤ºèª¿æ•´ãƒ‡ãƒ¼ã‚¿ã—ã‹å¿…è¦ãªã„ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLaMA65Bã‚’ãŸã£ãŸ1kã®data pointï¼ˆå³é¸ã•ã‚ŒãŸç‰©ï¼‰ã§RLHFç„¡ã—ã§finetuningã™ã‚‹ã¨ã€æ—…è¡Œãƒ—ãƒ©ãƒ³ã®ä½œæˆã‚„ã€æ­´å²æ”¹å¤‰ã®æ¨æ¸¬ï¼ˆï¼Ÿï¼‰å¹…åºƒã„ã‚¿ã‚¹ã‚¯ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€æœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ã¸ã®æ±åŒ–èƒ½åŠ›ã‚‚ç¤ºã—ãŸã€‚æœ€çµ‚çš„ã«GPT3,4,BARD,CLAUDEã‚ˆã‚Šã‚‚äººé–“ãŒå¥½ã‚€å›ç­”ã‚’è¿”ã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/db025381-0bf0-47a3-bd18-5d88bff666df" alt="image" loading="lazy"></p>
<p>LLaMAã®ã‚ˆã†ãªã‚ªãƒ¼ãƒ—ãƒ³ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå°‘ãªã„ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€å°‘é‡ã®ã‚µãƒ³ãƒ—ãƒ«ã§finetuningã™ã‚‹ã¨GPT4ã«è¿«ã‚Œã‚‹ã¨ã„ã†ã®ã¯gamechangerã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹</p>
<p>openreview: 


<a href="https://openreview.net/forum?id=KBMOKmX2he" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=KBMOKmX2he</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-05-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/699" target="_blank" rel="noopener noreferrer" class="title-link">Symbol tuning improves in-context learning in language models, Jerry Wei+, N_A, EMNLP'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è‡ªç„¶è¨€èªãƒ©ãƒ™ãƒ«ã‚’ã‚·ãƒ³ãƒœãƒ«ã«ç½®ãæ›ãˆã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹ã€Œsymbol tuningã€ã‚’ææ¡ˆã—ã€æœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ã‚„ä¸æ˜ç¢ºãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã—ã¦å …ç‰¢ãªæ€§èƒ½ã‚’ç¤ºã™ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€symbol tuningã«ã‚ˆã‚Šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸ŠãŒè¦‹ã‚‰ã‚Œã€ä»¥å‰ã®æ„å‘³çš„çŸ¥è­˜ã‚’ä¸Šæ›¸ãã™ã‚‹èƒ½åŠ›ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚Flan-PaLMãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦å®Ÿé¨“ãŒè¡Œã‚ã‚Œã€æœ€å¤§540Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¾ã§åˆ©ç”¨ã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>æ¦‚è¦ã‚„OpenReviewã®å†…å®¹ã‚’ã–ã£ãã‚Šã¨ã—ã‹èª­ã‚ã¦ã„ãªã„ãŒã€è‡ªç„¶è¨€èªã®ãƒ©ãƒ™ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ãªæ–‡å­—åˆ—ã«ã—ãŸã‚Šã€instructionã‚’ã‚ãˆã¦é™¤å¤–ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’Finetuningã™ã‚‹ã“ã¨ã§ã€promptã«å¯¾ã™ã‚‹sensitivityã‚„å…ƒã€…ãƒ¢ãƒ‡ãƒ«ãŒæŒã£ã¦ã„ã‚‹ãƒ©ãƒ™ãƒ«ã¨çŸ›ç›¾ã—ãŸæ„å‘³ã‚’in context learningã§ä¸Šæ›¸ãã§ãã‚‹ã¨ã„ã†ã“ã¨ã¯ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€æ­£å‰‡åŒ–ã®å½¹å‰²ã‚’æœãŸã—ã¦ã„ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚ã¤ã¾ã‚Šã€ãƒ©ãƒ™ãƒ«ãã®ã‚‚ã®ã«è‡ªç„¶è¨€èªã¨ã—ã¦ã®æ„å‘³ã‚’å«ã¾ã›ãªã„ã“ã¨ã‚„ã€instructionã‚’ç„¡ãã™ã“ã¨ã§ã€ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒè¡¨å±¤çš„ãªãƒ©ãƒ™ãƒ«ã®æ„å‘³ã‚„æŒ‡ç¤ºã‹ã‚‰ã§ã¯ãªãï¼‰ã€ã‚ˆã‚Šå®Ÿéš›ã®ICLã§åˆ©ç”¨ã•ã‚Œã‚‹Exaplarã‹ã‚‰ã‚¿ã‚¹ã‚¯ã‚’æ¨è«–ã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã‚‹ã®ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/a4050a09-d319-481d-9b63-70b2ee9b5aad" alt="image" loading="lazy"></p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=vOX7Dfwo3v" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=vOX7Dfwo3v</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataDistillation.html" target="_blank" rel="noopener noreferrer">#DataDistillation</a>
<span class="issue_date">Issue Date: 2023-05-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/698" target="_blank" rel="noopener noreferrer" class="title-link">DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining, Sang Michael Xie+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã®æ··åˆæ¯”ã«ã¤ã„ã¦ã€DoReMiã¨ã„ã†æ‰‹æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚DoReMiã¯ã€å°ã•ãªãƒ—ãƒ­ã‚­ã‚·ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ‰ãƒ¡ã‚¤ãƒ³ã®é‡ã¿ã‚’ç”Ÿæˆã—ã€å†ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦å¤§ããªãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ã«ãƒ‰ãƒ¡ã‚¤ãƒ³ã®é‡ã¿ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚å®Ÿé¨“ã§ã¯ã€DoReMiã¯The Pileã‚„GLaMãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§é«˜ã„ç²¾åº¦ã‚’ç™ºæ®ã—ã€few-shotä¸‹æµç²¾åº¦ã‚’6.5ï¼…æ”¹å–„ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>äº‹å‰å­¦ç¿’ã™ã‚‹éš›ã®å„ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã©ã®ã‚ˆã†ãªæ¯”ç‡ã§mixtureã™ã‚‹ã‹ã®è©±ã€‚å„ãƒ‰ãƒ¡ã‚¤ãƒ³ã”ã¨ã«å°ã•ãªproxy modelã‚’è¨“ç·´ã—ã€downstream taskã®çŸ¥è­˜ç„¡ã—ã§ãƒ‰ãƒ¡ã‚¤ãƒ³ã”ã¨ã®é‡ã¿ã‚’ç”Ÿæˆã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆã•ã‚ŒãŸãƒ‰ãƒ¡ã‚¤ãƒ³ã”ã¨ã®é‡ã¿ã«å¾“ã„ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ï¼ˆ1/30ã®ãƒ—ãƒ­ã‚­ã‚·ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå ´åˆï¼‰ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Š2.6å€é«˜é€Ÿã§ã€6.5%oneshotã®accuracyã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã«æˆåŠŸ<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2c0b125a-5ecc-4ee3-8c3b-022c03606c60" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<span class="issue_date">Issue Date: 2023-05-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/697" target="_blank" rel="noopener noreferrer" class="title-link">StructGPT: A General Framework for Large Language Model to Reason over  Structured Data, Jinhao Jiang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ä¸Šã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ¨è«–èƒ½åŠ›ã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦ç ”ç©¶ã—ã€Iterative Reading-then-Reasoningï¼ˆIRRï¼‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é–¢é€£ã™ã‚‹ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚’åé›†ã™ã‚‹å°‚é–€çš„ãªé–¢æ•°ã‚’æ§‹ç¯‰ã—ã€LLMsã«åé›†ã•ã‚ŒãŸæƒ…å ±ã«åŸºã¥ã„ã¦æ¨è«–ã‚¿ã‚¹ã‚¯ã«é›†ä¸­ã•ã›ã¾ã™ã€‚å¤–éƒ¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®æ”¯æ´ã‚’å—ã‘ã¦ã€LLMsãŒæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ä¸Šã§æ¨è«–ã™ã‚‹ãŸã‚ã®invoking-linearization-generationæ‰‹é †ã‚’ææ¡ˆã—ã€ä¸ãˆã‚‰ã‚ŒãŸã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹ç›®æ¨™å›ç­”ã«å¾ã€…ã«è¿‘ã¥ãã“ã¨ãŒã§ãã¾ã™ã€‚å¾¹åº•çš„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æœ‰åŠ¹æ€§ã‚’ç¤ºã—ã€ãƒ•ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æ•™å¸«ã‚ã‚Šãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã¯ã€\url{https://github.com/RUCAIBox/StructGPT}ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹LLMã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®reasoningèƒ½åŠ›ã‚’æ”¹å–„ã€‚æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹QAã‚¿ã‚¹ã‚¯ã§æ‰‹æ³•ãŒæœ‰åŠ¹ãªã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ac9732f1-a9c9-4620-8bf8-053415a5e654" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Planning.html" target="_blank" rel="noopener noreferrer">#Planning</a>
<span class="issue_date">Issue Date: 2023-05-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/696" target="_blank" rel="noopener noreferrer" class="title-link">Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models, Hanxu Hu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€LLMsã‚’ä½¿ç”¨ã—ã¦è¤‡é›‘ãªè¨ˆç”»ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚‹Natural Language Planningï¼ˆNLPï¼‰ã‚’ææ¡ˆã—ã€CoSã¨ã„ã†æ–°ã—ã„æ‰‹æ³•ã‚’å°å…¥ã—ã¦ã€LLMsãŒã‚·ãƒ³ãƒœãƒªãƒƒã‚¯è¡¨ç¾ã‚’ã‚ˆã‚Šç†è§£ã—ã‚„ã™ãã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚CoSã¯ChatGPTã‚„InstructGPTã§ã®å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å‰Šæ¸›ã—ã€Brick Worldã§60.8ï¼…ã®ç²¾åº¦ã‚’é”æˆã™ã‚‹ãªã©ã€æ€§èƒ½ã®å‘ä¸Šã‚’å®Ÿç¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã¯è¤‡é›‘ãªãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ãŒè‹¦æ‰‹ãªã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ãŠã‚Šã€è¤‡é›‘ãªç’°å¢ƒã‚’è‡ªç„¶è¨€èªã§ã¯ãªãã€spatialã§symbolicãªãƒˆãƒ¼ã‚¯ãƒ³ã§è¡¨ç¾ã™ã‚‹ã“ã¨ã§ã€ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã®æ€§èƒ½ãŒå‘ä¸Šã—ãŸã¨ã„ã†è©±<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/50e9d7e2-bd75-4341-b7a0-394dc2eaf915" alt="image" loading="lazy"></p>
<p>OpenReview: 


<a href="https://openreview.net/forum?id=B0wJ5oCPdB" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=B0wJ5oCPdB</a>


</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2023-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/693" target="_blank" rel="noopener noreferrer" class="title-link">What In-Context Learning "Learns" In-Context: Disentangling Task  Recognition and Task Learning, Jane Pan+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ãŒã©ã®ã‚ˆã†ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã‚’åˆ©ç”¨ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹ã‹ã‚’èª¿æŸ»ã—ã¾ã—ãŸã€‚ã‚¿ã‚¹ã‚¯èªè­˜ï¼ˆTRï¼‰ã¨ã‚¿ã‚¹ã‚¯å­¦ç¿’ï¼ˆTLï¼‰ã®å½¹å‰²ã‚’åˆ†é›¢ã™ã‚‹ãŸã‚ã®å®Ÿé¨“ã‚’è¡Œã„ã€LLMsãŒãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é€šã˜ã¦æš—é»™çš„ã«å­¦ç¿’ã‚’è¡Œã†å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€ãƒ¢ãƒ‡ãƒ«ãŒã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã«ã¤ã‚Œã¦TLã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒæ”¹å–„ã•ã‚Œã‚‹ã“ã¨ã‚‚æ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—ãŸã€‚ã“ã‚Œã‚‰ã®çµæœã¯ã€ICLã®èƒŒå¾Œã«ã‚ã‚‹2ã¤ã®ç•°ãªã‚‹åŠ›ã‚’æ˜ã‚‰ã‹ã«ã—ã€å°†æ¥ã®ICLç ”ç©¶ã§ãã‚Œã‚‰ã‚’åŒºåˆ¥ã™ã‚‹ã“ã¨ã‚’æå”±ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMãŒIn context Learningã§æ–°ã—ã„ä½•ã‹ã‚’å­¦ç¿’ã—ã¦ã„ã‚‹ã®ã‹ã‚’èª¿æŸ»<br>TaskRecognitionï¼ˆTRï¼‰ã¯Ground Truthç„¡ã—ã§ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ã¿ã§å®Ÿæ–½<br>TaskLearningï¼ˆTLï¼‰ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ãªã‹ã£ãŸãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ©ãƒ™ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’æ‰ãˆã‚‹å¿…è¦ãŒã‚ã‚‹ã‚¿ã‚¹ã‚¯ã€‚<br>TRã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§ã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã‹ã£ãŸãŒã€TLã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«å¯¾ã—ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã—ãŸ<br>â†’ äº‹å‰å­¦ç¿’ã§å­¦ç¿’ã—ã¦ããŸçŸ¥è­˜ã‚’å¼•ã£å¼µã£ã¦ãã‚‹ã ã‘ã§ã¯TLã¯å®Ÿæ–½ã§ããªã„ã®ã§ã€TRã§ã¯ä½•ã‚‚å­¦ç¿’ã—ã¦ã„ãªã„ãŒã€TLã«ãŠã„ã¦ã¯æ–°ã—ãä½•ã‹ãŒå­¦ç¿’ã•ã‚Œã¦ã‚‹ã‚“ã˜ã‚ƒãªã„?ã¨ã„ã†ã“ã¨ã ã‚ã†ã‹<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/729cc613-7487-47be-9225-e02921091969" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/CodeGeneration.html" target="_blank" rel="noopener noreferrer">#CodeGeneration</a>
<span class="issue_date">Issue Date: 2023-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/692" target="_blank" rel="noopener noreferrer" class="title-link">CodeT5+: Open Code Large Language Models for Code Understanding and  Generation, Yue Wang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚³ãƒ¼ãƒ‰ã®ãŸã‚ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼LLMsã®ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã§ã‚ã‚‹ã€ŒCodeT5+ã€ã‚’ææ¡ˆã—ã€æ§˜ã€…ãªãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚³ãƒ¼ãƒ‰ã‚¿ã‚¹ã‚¯ã«æŸ”è»Ÿã«é©åˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸã€‚ã¾ãŸã€äº‹å‰å­¦ç¿’ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒ†ã‚£ãƒ–ã®æ··åˆã‚’ææ¡ˆã™ã‚‹ã“ã¨ã§ã€äº‹å‰å­¦ç¿’ã¨ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ä¸ä¸€è‡´ã‚’ç·©å’Œã—ã€ã‚¹ãƒ‘ãƒ³ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ã€ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã€ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã€å› æœLMäº‹å‰å­¦ç¿’ã‚¿ã‚¹ã‚¯ã‚’å«ã‚ã¾ã—ãŸã€‚CodeT5+ã¯ã€ç•°ãªã‚‹è¨­å®šã§20ä»¥ä¸Šã®ã‚³ãƒ¼ãƒ‰é–¢é€£ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¾¹åº•çš„ã«è©•ä¾¡ã•ã‚Œã€æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¦³å¯Ÿã—ã¾ã—ãŸã€‚ç‰¹ã«ã€instruction-tuned CodeT5+ 16Bã¯ã€ä»–ã®ã‚ªãƒ¼ãƒ—ãƒ³ãªã‚³ãƒ¼ãƒ‰LLMsã«å¯¾ã—ã¦ã€HumanEvalã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚¿ã‚¹ã‚¯ã§æ–°ã—ã„æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>æ§˜ã€…ãªã‚³ãƒ¼ãƒ‰ã®ç†è§£ã¨ç”Ÿæˆã‚¿ã‚¹ã‚¯ã‚’ã‚µãƒãƒ¼ãƒˆ<br>ç•°ãªã‚‹è¨“ç·´æ‰‹æ³•ã«ã‚ˆã£ã¦è¨ˆç®—åŠ¹ç‡æ”¹å–„<br>20ç¨®é¡ã®ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€æ§˜ã€…ãªè¨­å®šã€Œã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã€finetuning, instruction tuningç­‰ï¼‰ã‚’å®Ÿæ–½ã—ãŸçµæœã€ã‚³ãƒ¼ãƒ‰è£œå®Œã€math programming, text to code retrievalã«ãŠã„ã¦SoTAé”æˆ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/684" target="_blank" rel="noopener noreferrer" class="title-link">Tree of Thoughts: Deliberate Problem Solving with Large Language Models, Shunyu Yao+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã«ã¯åˆ¶é™ãŒã‚ã‚Šã€æ¢ç´¢ã‚„æˆ¦ç•¥çš„å…ˆèª­ã¿ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã«ã¯ä¸ååˆ†ã§ã‚ã‚‹ã€‚ãã“ã§ã€Tree of Thoughtsï¼ˆToTï¼‰ã¨ã„ã†æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’å°å…¥ã—ã€Chain of Thoughtã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä¸€èˆ¬åŒ–ã—ã¦ã€æ„æ€æ±ºå®šã‚’è¡Œã†ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ã—ãŸã€‚ToTã«ã‚ˆã‚Šã€è¨€èªãƒ¢ãƒ‡ãƒ«ã¯è¤‡æ•°ã®ç•°ãªã‚‹æ¨è«–ãƒ‘ã‚¹ã‚’è€ƒæ…®ã—ã¦ã€æ¬¡ã®è¡Œå‹•ã‚’æ±ºå®šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ToTã¯ã€Game of 24ã€Creative Writingã€Mini Crosswordsãªã©ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®å•é¡Œè§£æ±ºèƒ½åŠ›ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Self Concistencyã®æ¬¡<br>Non trivialãªãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã¨æ¤œç´¢ãŒå¿…è¦ãªæ–°ãŸãª3ã¤ã®ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦ã€CoT w/ GPT4ã®æˆåŠŸç‡ãŒ4%ã ã£ãŸã¨ã“ã‚ã‚’ã€ToTã§ã¯74%ã‚’é”æˆ<br><br>è«–æ–‡ä¸­ã®è¡¨ã§ã¯CoTã®SuccessRateãŒ40%ã¨æ›¸ã„ã¦ã‚ã‚‹ã‚ˆã†ãª?<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6f853009-8d08-43b4-a7da-61677f4aca3a" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Faithfulness.html" target="_blank" rel="noopener noreferrer">#Faithfulness</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-05-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/666" target="_blank" rel="noopener noreferrer" class="title-link">Language Models Don't Always Say What They Think: Unfaithful   Explanations in Chain-of-Thought Prompting, Miles Turpin+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã«ã‚ˆã‚‹æ¨è«–ã«ãŠã„ã¦ã€chain-of-thought reasoningï¼ˆCoTï¼‰ã¨å‘¼ã°ã‚Œã‚‹èª¬æ˜ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ãŒã€ã“ã®èª¬æ˜ãŒãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã®çœŸã®ç†ç”±ã‚’èª¤ã£ã¦è¡¨ç¾ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ãƒã‚¤ã‚¢ã‚¹ã®ã‚ã‚‹ç‰¹å¾´ã‚’ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ã«è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€CoTèª¬æ˜ãŒå¤§ããå½±éŸ¿ã‚’å—ã‘ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã®çµæœã¯ã€LLMsã«å¯¾ã™ã‚‹ä¿¡é ¼ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã€èª¬æ˜ã®å¿ å®Ÿåº¦ã‚’è©•ä¾¡ã—ã€æ”¹å–„ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/643" target="_blank" rel="noopener noreferrer" class="title-link">Mass-Editing Memory in a Transformer, Kevin Meng+, N_A, ICLR'23</a>
<span class="snippet"><span>GPT Summary</span>- - å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°ã™ã‚‹ã“ã¨ã§ã€å°‚é–€çš„ãªçŸ¥è­˜ã‚’è¿½åŠ ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹- ã—ã‹ã—ã€ã“ã‚Œã¾ã§ã®ç ”ç©¶ã¯ä¸»ã«å˜ä¸€ã®é–¢é€£ä»˜ã‘ã®æ›´æ–°ã«é™å®šã•ã‚Œã¦ã„ãŸ- æœ¬ç ”ç©¶ã§ã¯ã€MEMITã¨ã„ã†æ–¹æ³•ã‚’é–‹ç™ºã—ã€å¤šæ•°ã®ãƒ¡ãƒ¢ãƒªã‚’ç›´æ¥è¨€èªãƒ¢ãƒ‡ãƒ«ã«æ›´æ–°ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’å®Ÿé¨“çš„ã«ç¤ºã—ãŸ- GPT-Jï¼ˆ6Bï¼‰ãŠã‚ˆã³GPT-NeoXï¼ˆ20Bï¼‰ã«å¯¾ã—ã¦æ•°åƒã®é–¢é€£ä»˜ã‘ã¾ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã§ãã€ã“ã‚Œã¾ã§ã®ç ”ç©¶ã‚’æ¡é•ã„ã«ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸ- ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã¯https://memit.baulab.infoã«ã‚ã‚Šã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/642" target="_blank" rel="noopener noreferrer" class="title-link">Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them, Mirac Suzgun+, N_A, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- BIG-Bench Hard (BBH) is a suite of 23 challenging tasks that current language models have not been able to surpass human performance on. This study focuses on applying chain-of-thought prompting to BBH tasks and found that PaLM and Codex were able to surpass human performance on 10 and 17 tasks, respectively. The study also found that CoT prompting is necessary for tasks that require multi-step reasoning and that CoT and model scale interact to enable new task performance on some BBH tasks.</span>
<span class="snippet"><span>Comment</span><p>å˜ãªã‚‹fewshotã§ã¯ãªãã€CoTä»˜ãã®fewshotã‚’ã™ã‚‹ã¨å¤§å¹…ã«BIG-Bench-hardã®æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã®ã§ã€CoTã‚’ä½¿ã‚ãªã„answer onlyã®è¨­å®šã¯ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã®éå°è©•ä¾¡ã«ã¤ãªãŒã‚‹ã‚ˆã€ã¨ã„ã†è©±ã‚‰ã—ã„<br><img src="https://github.com/user-attachments/assets/0545214a-a267-489d-8af9-82d21e08ff6c" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/e5308c66-0bee-4d2c-b973-86478842b772" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Poisoning.html" target="_blank" rel="noopener noreferrer">#Poisoning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/629" target="_blank" rel="noopener noreferrer" class="title-link">Poisoning Language Models During Instruction Tuning, Alexander Wan+, N_A, ICML'23</a>
<span class="snippet"><span>GPT Summary</span>- - Instruction-tuned LMsï¼ˆChatGPTã€FLANã€InstructGPTãªã©ï¼‰ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæå‡ºã—ãŸä¾‹ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§finetuneã•ã‚Œã‚‹ã€‚- æœ¬ç ”ç©¶ã§ã¯ã€æ•µå¯¾è€…ãŒæ¯’å…¥ã‚Šã®ä¾‹ã‚’æä¾›ã™ã‚‹ã“ã¨ã§ã€LMã®äºˆæ¸¬ã‚’æ“ä½œã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚- æ¯’å…¥ã‚Šã®ä¾‹ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã«ã€LMã®bag-of-wordsè¿‘ä¼¼ã‚’ä½¿ç”¨ã—ã¦å…¥å‡ºåŠ›ã‚’æœ€é©åŒ–ã™ã‚‹ã€‚- å¤§ããªLMã»ã©æ¯’å…¥ã‚Šæ”»æ’ƒã«å¯¾ã—ã¦è„†å¼±ã§ã‚ã‚Šã€ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚„ãƒ¢ãƒ‡ãƒ«å®¹é‡ã®å‰Šæ¸›ã«åŸºã¥ãé˜²å¾¡ã¯ã€ãƒ†ã‚¹ãƒˆã®æ­£ç¢ºæ€§ã‚’ä½ä¸‹ã•ã›ãªãŒã‚‰ã€ä¸­ç¨‹åº¦ã®ä¿è­·ã—ã‹æä¾›ã—ãªã„ã€‚</span>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Annotation.html" target="_blank" rel="noopener noreferrer">#Annotation</a>
<a class="button" href="articles/TransferLearning.html" target="_blank" rel="noopener noreferrer">#TransferLearning</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/615" target="_blank" rel="noopener noreferrer" class="title-link">Frustratingly Easy Label Projection for Cross-lingual Transfer, Yang Chen+, N_A, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- - å¤šè¨€èªã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ç¿»è¨³ã¯ã€ã‚¯ãƒ­ã‚¹ãƒªãƒ³ã‚¬ãƒ«è»¢ç§»ã®æ”¹å–„ã«å½¹ç«‹ã¤- ã‚¹ãƒ‘ãƒ³ãƒ¬ãƒ™ãƒ«æ³¨é‡ˆãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§ã¯ã€æ³¨é‡ˆä»˜ãã‚¹ãƒ‘ãƒ³ã‚’ç¿»è¨³ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã«ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹ãŸã‚ã«è¿½åŠ ã®ãƒ©ãƒ™ãƒ«ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒƒãƒ—ãŒå¿…è¦- ãƒãƒ¼ã‚¯-ç¿»è¨³æ³•ã‚’åˆ©ç”¨ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¾“æ¥ã®æ³¨é‡ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã¨æ¯”è¼ƒã—ã¦ã©ã®ã‚ˆã†ã«ãªã‚‹ã‹ã«ã¤ã„ã¦ã®å®Ÿè¨¼çš„ãªåˆ†æã‚’è¡Œã£ãŸ- EasyProjectã¨å‘¼ã°ã‚Œã‚‹ãƒãƒ¼ã‚¯-ç¿»è¨³æ³•ã®æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå¤šè¨€èªã«ç°¡å˜ã«é©ç”¨ã§ãã€ã‚ˆã‚Šè¤‡é›‘ãªå˜èªã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ã®æ–¹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸ- ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ãŒå…¬é–‹ã•ã‚Œã‚‹</span>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Inference.html" target="_blank" rel="noopener noreferrer">#Inference</a>
<span class="issue_date">Issue Date: 2023-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/601" target="_blank" rel="noopener noreferrer" class="title-link">Efficiently Scaling Transformer Inference, Reiner Pope+, N_A, MLSys'23</a>
<span class="snippet"><span>GPT Summary</span>- - å¤§è¦æ¨¡Transformerãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€æœ€é©ãªå¤šæ¬¡å…ƒåˆ†å‰²æŠ€è¡“ã‚’é¸æŠã™ã‚‹ãŸã‚ã®å˜ç´”ãªè§£æãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™º- ä½ãƒ¬ãƒ™ãƒ«ã®æœ€é©åŒ–ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€500B+ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«FLOPSåˆ©ç”¨ç‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ãŠã„ã¦ã€FasterTransformerãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¤ãƒ¼ãƒˆã‚’ä¸Šå›ã‚‹æ–°ã—ã„Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã‚’å®Ÿç¾- é©åˆ‡ãªåˆ†å‰²ã«ã‚ˆã‚Šã€ãƒãƒ«ãƒã‚¯ã‚¨ãƒªã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®ä½ã„ãƒ¡ãƒ¢ãƒªè¦ä»¶ã«ã‚ˆã‚Šã€32å€ã®å¤§ããªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯èƒ½- int8ã‚¦ã‚§ã‚¤ãƒˆé‡å­åŒ–ã‚’ä½¿ç”¨ã—ãŸç”Ÿæˆä¸­ã®ä½ãƒãƒƒãƒã‚µã‚¤ã‚ºãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚ãŸã‚Š29msã§ã‚ã‚Šã€å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³ã®å¤§ãƒãƒƒãƒã‚µã‚¤ã‚ºå‡¦ç†ã«ãŠã„ã¦76ï¼…ã®MFUã‚’å®Ÿç¾ã—ã€PaLM 540Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦2048ãƒˆãƒ¼ã‚¯ãƒ³ã®é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç‰¹ã«Multiquery Attentionã¨ã„ã†æŠ€è¡“ãŒTransformerã®inferenceã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ã«æœ‰åŠ¹ã‚‰ã—ã„</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/TheoryOfMind.html" target="_blank" rel="noopener noreferrer">#TheoryOfMind</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/581" target="_blank" rel="noopener noreferrer" class="title-link">Boosting Theory-of-Mind Performance in Large Language Models via Prompting, Moghaddam+, Johns Hopkins University, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>LLMã¯Theory-of-mind reasoningã‚¿ã‚¹ã‚¯ãŒè‹¦æ‰‹ãªã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ãŠã‚Šã€ç‰¹ã«zero shotã§ã¯éå¸¸ã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ã‹ã£ãŸã€‚ToMã‚¿ã‚¹ã‚¯ã¨ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä¿¡å¿µã€ã‚´ãƒ¼ãƒ«ã€ãƒ¡ãƒ³ã‚¿ãƒ«stateã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒä½•ã‚’çŸ¥ã£ã¦ã„ã‚‹ã‹ç­‰ã‚’ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã™ã‚‹ã“ã¨ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã‚¿ã‚¹ã‚¯ã®ã“ã¨ã€‚ã“ã®ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã¯LLMãŒæˆ‘ã€…ã®æ—¥å¸¸ç”Ÿæ´»ã‚’ç†è§£ã™ã‚‹ä¸Šã§é‡è¦ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/235207785-8a4c5e0d-4825-4947-8ae6-a8176ad7c898.png" alt="image" loading="lazy"><br><br>â†‘ã®ToM Questionã®ã‚·ãƒŠãƒªã‚ªã¨å•é¡Œ<br>Scenario: "The morning of the high school dance Sarah placed her high heel shoes under her dress and then went shopping. That afternoon, her sister borrowed the shoes and later put them under Sarah's bed."<br>Question: When Sarah gets ready, does she assume her shoes are under her dress?<br><br>ã—ã‹ã—ã€Zero shot CoTã®ã‚ˆã†ãªstep by step thinking, CoTã‚’é©åˆ‡ã«è¡Œã†ã“ã¨ã§ã€OpenAIã®ç›´è¿‘3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®AccuracyãŒ80%ã‚’è¶…ãˆãŸã€‚ç‰¹ã«ã€GPT4ã¯100ï¼…ã®Accuracyã‚’é”æˆã€‚äººé–“ã¯87ï¼…ã ã£ãŸã€‚<br><br>ã“ã®çµæœã¯ã€å°‘ãªãã¨ã®ã“ã®è«–æ–‡ã§ãƒ†ã‚¹ãƒˆã—ãŸãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã¯LLMã®social reasoningã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ã©ã®ã‚ˆã†ã«ãƒ–ãƒ¼ã‚¹ãƒˆã™ã‚‹ã‹ã‚’ç¤ºã—ã¦ãŠã‚Šã€LLMã®behaviorã¯è¤‡é›‘ã§sensitiveã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/580" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models are Versatile Decomposers: Decompose Evidence and Questions for Table-based Reasoning, Ye+, University of Science and Technology of China, SIGIR'23</a>
<span class="snippet"><span>Comment</span><p>ãƒ†ãƒ¼ãƒ–ãƒ«ã¨questionãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€questionã‚’sub-questionã¨small tableã«LLMã§in-context learningã™ã‚‹ã“ã¨ã§åˆ†å‰²ã€‚subquestionã®è§£ã‚’å¾—ã‚‹ãŸã‚ã®sqlã‚’ä½œæˆã—ã‚¹ãƒãƒƒãƒˆã‚’åŸ‹ã‚ã€hallucinationã‚’é˜²ãã€‚æœ€çµ‚çš„ã«LLM ReasonerãŒè§£ç­”ã‚’å°å‡ºã™ã‚‹ã€‚TabFact Reasoningã§åˆã‚ã¦äººé–“ã‚’è¶…ãˆãŸæ€§èƒ½ã‚’ç™ºæ®ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/235204690-75f6b56b-3291-42e4-9e39-710694f36648.jpeg" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/DialogueGeneration.html" target="_blank" rel="noopener noreferrer">#DialogueGeneration</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/575" target="_blank" rel="noopener noreferrer" class="title-link">q2d: Turning Questions into Dialogs to Teach Models How to Search, Bitton+, The Hebrew University of Jerusalem ï¼ˆw_ Google Researchï¼‰, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>LLMã«questionã‚’ä¸ãˆã€questionã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®information seekingã®å¯¾è©±ãƒ­ã‚°ã‚’ç”Ÿæˆã•ã›ã‚‹ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€dialogueã‹ã‚‰questionã‚’ç”Ÿæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€æ¤œç´¢APIãªã©ã«æ¸¡ã›ã‚‹ã‚ˆã†ã«ã—ãŸç ”ç©¶ã€‚å…¨ãå¯¾è©±ã®ãƒ­ã‚°ãŒãªã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã‚‚ã€äººé–“ã¨éœè‰²ãªã„é«˜å“è³ªãªå¯¾è©±ãŒç”Ÿæˆå¯èƒ½ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€query generationãƒ¢ãƒ‡ãƒ«ã®æ›´ãªã‚‹é«˜æ€§èƒ½åŒ–ãŒå®Ÿç¾ã§ãã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/235137446-10e6633f-1d4b-46ea-afda-630b7cd53246.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/573" target="_blank" rel="noopener noreferrer" class="title-link">Tractable Control for Autoregressive Language Generation, Zhang+, UCLA, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>è‡ªç„¶è¨€èªç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã€ä½•ã‚‰ã‹ã®ã‚·ãƒ³ãƒ—ãƒ«ãªconstiaint Î±ã®å…ƒp(xi|xi-1,Î±)ã‚’ç”Ÿæˆã—ã‚ˆã†ã¨ã—ã¦ã‚‚è¨ˆç®—ãŒã§ããªã„ã€‚ã“ã®ãŸã‚ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’finetuningã™ã‚‹ã‹ã€promptã§åˆ¶å¾¡ã™ã‚‹ã‹ã€ãªã©ãŒãŠã“ãªã‚ã‚Œã‚‹ã€‚ã—ã‹ã—ã“ã®æ–¹æ³•ã¯è¿‘ä¼¼çš„ãªè§£æ³•ã§ã‚ã‚Šã€Î±ãŒãŸã¨ãˆã‚·ãƒ³ãƒ—ãƒ«ã§ã‚ã£ã¦ã‚‚ï¼ˆä½•ã‚‰ã‹ã®èªå°¾ã‚’ä»˜ä¸ã™ã‚‹ãªã©ï¼‰ã€å¿…ãšã—ã‚‚æº€ãŸã—ãŸç”ŸæˆãŒè¡Œã‚ã‚Œã‚‹ã¨ã¯é™ã‚‰ãªã„ã€‚ã“ã‚Œã¯å˜ã«è¨€èªãƒ¢ãƒ‡ãƒ«ãŒautoregressiveãªæ–¹æ³•ã§æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®åˆ†å¸ƒã‚’äºˆæ¸¬ã—ã¦ã„ã‚‹ã ã‘ã§ã‚ã‚‹ã“ã¨ã«èµ·å› ã—ã¦ã„ã‚‹ã€‚ãã“ã§ã€ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€tractable probabilistic modelï¼ˆTPMï¼‰ã‚’å°å…¥ã—ã€è§£æ±ºã—ãŸã€‚<br>è©•ä¾¡ã®çµæœã€CommonGenã«ãŠã„ã¦ã€SoTAã‚’é”æˆã—ãŸã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/235130061-21e51e59-dbfa-4c64-bd7b-27f0de2618c0.jpeg" alt="image" loading="lazy"></p>
<p>å°šã€TPMã«ã¤ã„ã¦ã¯è¦å‹‰å¼·ã§ã‚ã‚‹</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="articles/AES(AutomatedEssayScoring).html" target="_blank" rel="noopener noreferrer">#AES(AutomatedEssayScoring)</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/571" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AI, write an essay for me: A large-scale comparison of human-written  versus ChatGPT-generated essays, Steffen Herbold+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ChatGPTãŒç”Ÿæˆã—ãŸã‚¨ãƒƒã‚»ã‚¤ã¯ã€äººé–“ãŒæ›¸ã„ãŸã‚‚ã®ã‚ˆã‚Šã‚‚è³ªãŒé«˜ã„ã¨è©•ä¾¡ã•ã‚Œã‚‹ã“ã¨ãŒå¤§è¦æ¨¡ãªç ”ç©¶ã§ç¤ºã•ã‚ŒãŸã€‚ç”Ÿæˆã•ã‚ŒãŸã‚¨ãƒƒã‚»ã‚¤ã¯ç‹¬è‡ªã®è¨€èªçš„ç‰¹å¾´ã‚’æŒã¡ã€æ•™è‚²è€…ã¯ã“ã®æŠ€è¡“ã‚’æ´»ç”¨ã™ã‚‹æ–°ãŸãªæ•™è‚²ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’é–‹ç™ºã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ChatGPTã¯äººé–“ãŒæ›¸ã„ãŸã‚¨ãƒƒã‚»ã‚¤ã‚ˆã‚Šã‚‚é«˜å“è³ªãªã‚¨ãƒƒã‚»ã‚¤ãŒæ›¸ã‘ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br>ã¾ãŸã€AIãƒ¢ãƒ‡ãƒ«ã®æ–‡ä½“ã¯ã€äººé–“ãŒæ›¸ã„ãŸã‚¨ãƒƒã‚»ã‚¤ã¨ã¯ç•°ãªã‚‹è¨€èªçš„ç‰¹å¾´ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ãŸã¨ãˆã°ã€è«‡è©±ã‚„èªè­˜ãƒãƒ¼ã‚«ãƒ¼ãŒå°‘ãªã„ãŒã€åè©åŒ–ãŒå¤šãã€èªå½™ã®å¤šæ§˜æ€§ãŒé«˜ã„ã¨ã„ã†ç‰¹å¾´ãŒã‚ã‚‹ã€ã¨ã®ã“ã¨ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/235142851-756a418f-3c5a-4ae6-9309-0f077b1d017b.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Ambiguity.html" target="_blank" rel="noopener noreferrer">#Ambiguity</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/570" target="_blank" rel="noopener noreferrer" class="title-link">We're Afraid Language Models Aren't Modeling Ambiguity, Alisa Liu+, EMNLP'23</a>
<span class="snippet"><span>GPT Summary</span>- æ›–æ˜§ã•ã¯è‡ªç„¶è¨€èªã®é‡è¦ãªç‰¹å¾´ã§ã‚ã‚Šã€è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLMï¼‰ãŒå¯¾è©±ã‚„åŸ·ç­†æ”¯æ´ã«ãŠã„ã¦æˆåŠŸã™ã‚‹ãŸã‚ã«ã¯ã€æ›–æ˜§ãªè¨€èªã‚’æ‰±ã†ã“ã¨ãŒä¸å¯æ¬ ã§ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ›–æ˜§ã•ã®å½±éŸ¿ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€1,645ã®ä¾‹ã‹ã‚‰ãªã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒAmbiEntã€ã‚’åé›†ã—ã€äº‹å‰å­¦ç¿’æ¸ˆã¿LMã®è©•ä¾¡ã‚’è¡Œã„ã¾ã—ãŸã€‚ç‰¹ã«GPT-4ã®æ›–æ˜§ã•è§£æ¶ˆã®æ­£ç­”ç‡ã¯32%ã¨ä½ãã€æ›–æ˜§ã•ã®è§£æ¶ˆãŒé›£ã—ã„ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã¾ãŸã€å¤šãƒ©ãƒ™ãƒ«ã®NLIãƒ¢ãƒ‡ãƒ«ãŒæ›–æ˜§ã•ã«ã‚ˆã‚‹èª¤è§£ã‚’ç‰¹å®šã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã€NLPã«ãŠã‘ã‚‹æ›–æ˜§ã•ã®é‡è¦æ€§ã‚’å†èªè­˜ã™ã‚‹å¿…è¦æ€§ã‚’æå”±ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMãŒæ›–æ˜§æ€§ã‚’ã©ã‚Œã ã‘èªçŸ¥ã§ãã‚‹ã‹ã‚’è©•ä¾¡ã—ãŸåˆã‚ã¦ã®ç ”ç©¶ã€‚<br>è¨€èªå­¦è€…ãŒã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ãŸ1,645ã‚µãƒ³ãƒ—ãƒ«ã®æ§˜ã€…ãªæ›–æ˜§ã•ã‚’å«ã‚“ã ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã€‚<br>GPT4ã¯32%æ­£è§£ã—ãŸã€‚<br>ã¾ãŸNLIãƒ‡ãƒ¼ã‚¿ã§finetuningã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã¯72.5%ã®macroF1å€¤ã‚’é”æˆã€‚<br>å¿œç”¨å…ˆã¨ã—ã¦ã€èª¤è§£ã‚’æ‹›ãå¯èƒ½æ€§ã®ã‚ã‚‹æ”¿æ²»çš„ä¸»å¼µã«å¯¾ã—ã¦ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ã‚ã’ã‚‹ã“ã¨ãªã©ã‚’æŒ™ã’ã¦ã„ã‚‹ã€‚</p>
<p><img src="https://github.com/user-attachments/assets/a728a953-fac4-4115-8ec8-e5721bc4223e" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/569" target="_blank" rel="noopener noreferrer" class="title-link">Exploring the Curious Case of Code Prompts, Zhang+, University of Pennsylvania, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®LLMã«å¯¾ã—ã¦ã€reasoningã‚¿ã‚¹ã‚¯ã‚’è§£ã‹ã›ã‚‹éš›ã«ã¯ã€promptã‚‚ã‚³ãƒ¼ãƒ‰ã«ã™ã‚‹ã¨10ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆç¨‹åº¦æ€§èƒ½ä¸ŠãŒã‚‹å ´åˆãŒã‚ã‚‹ã‚ˆã€ã¨ã„ã†ç ”ç©¶ã€‚<br><img src="https://user-images.githubusercontent.com/12249301/235037840-1fb57af3-5296-4831-9f80-26886c913431.jpeg" alt="image" loading="lazy"></p>
<p>ãŸã ã—ã€å¹³å‡çš„ã«ã¯ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ–¹ãŒè‰¯ãã€ä¸€éƒ¨ã‚¿ã‚¹ã‚¯ã§æ€§èƒ½ãŒæ”¹å–„ã™ã‚‹ã€ã¨ã„ã†æ¸©åº¦æ„Ÿãªæ¨¡æ§˜<br><img src="https://user-images.githubusercontent.com/12249301/235038209-b43dcdcb-301e-4879-a99e-8c8df32e6cf5.jpeg" alt="image" loading="lazy"></p>
<p>ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã‚’textã§instruction tuningã—ã¦ã„ã‚‹å ´åˆã§ã‚‚ã€åŠ¹æœãŒã‚ã‚‹ã‚¿ã‚¹ã‚¯ãŒã‚ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/568" target="_blank" rel="noopener noreferrer" class="title-link">Answering Questions by Meta-Reasoning over Multiple Chains of Thought, Yoran+, Tel Aviv University ï¼ˆw_ Allen Institute for AIï¼‰, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>self-consistency <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/558" target="_blank" rel="noopener noreferrer">Self-consistency improves chain of thought reasoning in language models, Wang+, Google Research, ICLR'23</a>
 ã®ã‚ˆã†ãªvoting basedãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€è¤‡æ•°ã®CoTã®intermediate stepã‚’æ¨ã¦ã¦ã—ã¾ã„ã€çµæœã ã‘ã‚’æ¡ç”¨ã™ã‚‹ãŒã€ã“ã®ç ”ç©¶ã¯è¤‡æ•°ã®CoTã®ä¸­ã‹ã‚‰questionã«å›ç­”ã™ã‚‹ãŸã‚ã«é©åˆ‡ãªfactual informationã‚’æŠ½å‡ºã™ã‚‹Meta Reasonerã‚’å°å…¥ã—ã€è¤‡æ•°ã®CoTã®æƒ…å ±ã‚’é©åˆ‡ã«æ··åœ¨ã•ã›ã¦é©åˆ‡ãªå›ç­”ã‚’å¾—ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã—ãŸã€‚<br><br><br><br>7å€‹ã®Multi Hop QAãƒ‡ãƒ¼ã‚¿ã§strong baselineã‚’outperformã—ã€äººé–“ãŒå›ç­”ã‚’verificationã™ã‚‹ãŸã‚ã®é«˜å“è³ªãªèª¬æ˜ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/235135436-11dca529-771a-402b-a4ef-9b6deacec32e.jpeg" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/564" target="_blank" rel="noopener noreferrer" class="title-link">Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes, Arora+, Stanford University, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>LLMã‚’ä½¿ã†ã“ã¨ã§ã€åŠæ§‹é€ åŒ–æ–‡ç« ã‹ã‚‰è‡ªå‹•çš„ã«queryableãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã™ã‚‹ã“ã¨ã‚’è©¦ã¿ãŸç ”ç©¶<br><br><img src="https://user-images.githubusercontent.com/12249301/235146591-dc608755-e719-4418-ace9-29401919d4eb.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NeuralArchitectureSearch.html" target="_blank" rel="noopener noreferrer">#NeuralArchitectureSearch</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/559" target="_blank" rel="noopener noreferrer" class="title-link">Can GPT-4 Perform Neural Architecture Search? Zhang+, The University of Sydney, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã®å¿…è¦ã®ãªã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ææ¡ˆã‚’GPTã«ã—ã¦ã‚‚ã‚‰ã†ç ”ç©¶ã€‚accã‚’ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨ã—ã¦ä¸ãˆã€è‰¯ã„æ§‹é€ ã‚’ææ¡ˆã™ã‚‹ã¨ã„ã£ãŸãƒ«ãƒ¼ãƒ—ã‚’ç¹°ã‚Šè¿”ã™æ¨¡æ§˜<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/235143629-308233a6-51c7-40f7-afc6-e51f425e55d4.png" alt="image" loading="lazy"><br><br></p>
<p>Neural Architecture Search (NAS)ã«ãŠã„ã¦ã¯ã€ãƒ©ãƒ³ãƒ€ãƒ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãŒã‚ˆãæ¡ç”¨ã•ã‚Œã‚‹ã‚‰ã—ãã€æ¯”è¼ƒã—ãŸçµæœãƒ©ãƒ³ãƒ€ãƒ ã‚ˆã‚Šã‚ˆã‹ã£ãŸ<br><br><img src="https://user-images.githubusercontent.com/12249301/235144154-5c94a664-9768-4da5-af76-a137bc3d2b48.png" alt="image" loading="lazy"><br><br><br><br>NAS201ã¨å‘¼ã°ã‚Œã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆNNã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®cell blockã‚’ãƒ‡ã‚¶ã‚¤ãƒ³ã™ã‚‹ã“ã¨ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹; æ¢ç´¢ç©ºé–“ã¯4ã¤ã®ãƒãƒ¼ãƒ‰ã¨6ã¤ã®ã‚¨ãƒƒã‚¸ã§æ§‹æˆã•ã‚Œã‚‹å¯†æ¥ç¶šã®DAGã¨ã—ã¦è¡¨ã•ã‚Œã‚‹; ãƒãƒ¼ãƒ‰ã¯feature mapã‚’è¡¨ã—ã€ã‚¨ãƒƒã‚¸ã¯operationã«å¯¾å¿œ;åˆ©ç”¨å¯èƒ½ãªoperationãŒ5ã¤ã‚ã‚‹ãŸã‚ã€å¯èƒ½ãªæ¤œç´¢ç©ºé–“ã®ç·æ•°ã¯5ã®6ä¹—ã§15,625é€šã‚Šã¨ãªã‚‹ï¼‰ã§ã‚‚è©•ä¾¡ã—ãŸçµæœã€ææ¡ˆæ‰‹æ³•ã®æ€§èƒ½ãŒã‚ˆã‹ã£ãŸã¨ã®ã“ã¨ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/235144424-a8269562-3f4e-4830-8610-80e3ac9b977e.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/558" target="_blank" rel="noopener noreferrer" class="title-link">Self-consistency improves chain of thought reasoning in language models, Wang+, Google Research, ICLR'23</a>
<span class="snippet"><span>Comment</span><p>self-consistencyã¨å‘¼ã°ã‚Œã‚‹æ–°ãŸãªCoTã®ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã€‚<br><br>ã“ã‚Œã¯ã€é›£ã—ã„reasoningãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§ã¯ã€è¤‡æ•°ã®reasoningã®ãƒ‘ã‚¹ãŒå­˜åœ¨ã™ã‚‹ã¨ã„ã†intuitionã«åŸºã¥ã„ã¦ã„ã‚‹ã€‚<br><br><br><br>self-consistencyã§ã¯ã¾ãšã€æ™®é€šã«CoTã‚’è¡Œã†ã€‚ãã—ã¦greedyã«decodingã™ã‚‹ä»£ã‚ã‚Šã«ã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿæ–½ã™ã‚‹ï¼š<br><br>1. å¤šæ§˜ãªreasoning pathã‚’LLMã«ç”Ÿæˆã•ã›ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã€‚<br><br>2. ç•°ãªã‚‹reasoning pathã¯ç•°ãªã‚‹final answerã‚’ç”Ÿæˆã™ã‚‹ï¼ˆ= final answer setï¼‰ã€‚<br><br>3. ãã—ã¦ã€æœ€çµ‚çš„ãªanswerã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«ã€reasoning pathã‚’marginalizeã™ã‚‹ã“ã¨ã§ã€final answerã®setã®ä¸­ã§æœ€ã‚‚ä¸€è²«æ€§ã®ã‚ã‚‹å›ç­”ã‚’è¦‹å‡ºã™ã€‚<br><br><br><br>ã“ã‚Œã¯ã€ã‚‚ã—ç•°ãªã‚‹è€ƒãˆæ–¹ã«ã‚ˆã£ã¦åŒã˜å›ç­”ãŒå°ãå‡ºã•ã‚Œã‚‹ã®ã§ã‚ã‚Œã°ã€ãã®æœ€çµ‚çš„ãªå›ç­”ã¯æ­£ã—ã„ã¨ã„ã†çµŒé¨“å‰‡ã«åŸºã¥ã„ã¦ã„ã‚‹ã€‚<br><br>self-consistencyã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã¯ã€è¤‡æ•°ã®reasoning pathã‚’å–å¾—ã—ãŸä¸Šã§ã€æœ€ã‚‚å¤šã„answer a_iã‚’é¸æŠã™ã‚‹ï¼ˆmajority voteï¼‰ã€‚ã“ã‚Œã«ã¯temperature samplingã‚’ç”¨ã„ã‚‹ï¼ˆtemperatureã‚’0.5ã‚„ã‚‰0.7ã«è¨­å®šã—ã¦ã€ã‚ˆã‚Šé«˜ã„ä¿¡é ¼æ€§ã‚’ä¿ã¡ã¤ã¤ã€ã‹ã¤å¤šæ§˜ãªoutputã‚’æ‰‹ã«å…¥ã‚Œã‚‹ï¼‰ã€‚<br><br>temperature samplingã«ã¤ã„ã¦ã¯[ã“ã¡ã‚‰](


<a href="https://openreview.net/pdf?id=rygGQyrFvH)%E3%81%AE%E8%AB%96%E6%96%87%E3%82%92%E5%8F%82%E7%85%A7%E3%81%AE%E3%81%93%E3%81%A8%E3%80%82" target="_blank" rel="noopener noreferrer">https://openreview.net/pdf?id=rygGQyrFvH)ã®è«–æ–‡ã‚’å‚ç…§ã®ã“ã¨ã€‚</a>


<br><br>samplingæ•°ã¯å¢—ã‚„ã›ã°å¢—ã‚„ã™ã»ã©æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ãŒã€å¾ã€…ã«ã‚µãƒã£ã¦ãã‚‹ã€‚ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°ã‚’å¢—ã‚„ã™ã»ã©ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã®ã§ã€ãã®è¾ºã¯ã‚³ã‚¹ãƒˆæ„Ÿã¨ã®å…¼ã­åˆã„ã«ãªã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/234754605-6316223f-4290-45d5-bf7c-64675f07d0c3.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/234779335-478f2431-67ea-4b24-9c1b-fa1dd6ac6b45.png" alt="image" loading="lazy"><br><br></p>
<p>Self-consistencyã¯å›ç­”ãŒé–‰ã˜ãŸé›†åˆã§ã‚ã‚‹ã‚ˆã†ãªå•é¡Œã«å¯¾ã—ã¦é©ç”¨å¯èƒ½ã§ã‚ã‚Šã€open-endãªquestionã§ã¯åˆ©ç”¨ã§ããªã„ã“ã¨ã«æ³¨æ„ãŒå¿…è¦ã€‚ãŸã ã—ã€open-endã§ã‚‚å›ç­”é–“ã«ãªã‚“ã‚‰ã‹ã®é–¢ä¿‚æ€§ã‚’è¦‹å‡ºã™ã‚ˆã†ãªæŒ‡æ¨™ãŒã‚ã‚Œã°å®Ÿç¾å¯èƒ½ã¨limitationã§è¨€åŠã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/556" target="_blank" rel="noopener noreferrer" class="title-link">Automatic Chain of Thought Prompting in Large Language Models, Zhang+, Shanghai Jiao Tong University, ICLR'23</a>
<span class="snippet"><span>Comment</span><p>LLMã«ã‚ˆã‚‹reasoning chainãŒäººé–“ãŒä½œæˆã—ãŸã‚‚ã®ã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/532" target="_blank" rel="noopener noreferrer">[Paper Note] Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in  Large Language Models, Jiashuo Sun+, NAACL'24 Findings, 2023.04</a>
 ã‚ˆã‚Š</p>
<p>clusteringãƒ™ãƒ¼ã‚¹ãªæ‰‹æ³•ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€èª¤ã‚Šã‚’å«ã‚€ä¾‹ãŒå˜ä¸€ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«ã¾ã¨ã‚ã‚‰ã‚Œã†ã“ã¨ã‚’ç¤ºã—ã€ã“ã‚Œã«ã‚ˆã‚Šéå‰°ãªèª¤ã£ãŸãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒè»½æ¸›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</p>
<p>æ‰‹æ³•ã®æ¦‚è¦ã€‚questionã‚’è¤‡æ•°ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«åˆ†å‰²ã—ã€å„ã‚¯ãƒ©ã‚¹ã‚¿ã‹ã‚‰ä»£è¡¨çš„ãªquestionã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€zero-shot CoTã§reasoning chainã‚’ä½œæˆã—promptã«çµ„ã¿è¾¼ã‚€ã€‚æœ€çµ‚çš„ã«å›ç­”ã‚’å¾—ãŸã„questionã«å¯¾ã—ã¦ã‚‚ã€ä¸Šè¨˜ã§ç”Ÿæˆã—ãŸè¤‡æ•°ã®question-reasoningã§æ¡ä»¶ä»˜ã‘ã—ãŸä¸Šã§ã€zeroshot-CoTã§rationaleã‚’ç”Ÿæˆã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/35213747-9b5f-4d38-a525-1deafe86cd0c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/555" target="_blank" rel="noopener noreferrer" class="title-link">Automatic prompt augmentation and selection with chain-of-thought from labeled data, Shum+, The Hong Kong University of Science and Technology, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>LLMã«ã‚ˆã‚‹reasoning chainãŒäººé–“ãŒä½œæˆã—ãŸã‚‚ã®ã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/532" target="_blank" rel="noopener noreferrer">[Paper Note] Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in  Large Language Models, Jiashuo Sun+, NAACL'24 Findings, 2023.04</a>
 ã‚ˆã‚Š</p>
<p>selection phaseã§èª¤ã£ãŸexampleã¯ç›´æ¥æ’é™¤ã™ã‚‹æ‰‹æ³•ã‚’ã¨ã£ã¦ã„ã‚‹ã€‚ãã—ã¦ã€å¼·åŒ–å­¦ç¿’ã«ã‚ˆã£ã¦ã€demonstrationã®selection modelã‚’è¨“ç·´ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2023-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/539" target="_blank" rel="noopener noreferrer" class="title-link">Personalisation within bounds: A risk taxonomy and policy framework for the alignment of large language models with personalised feedback, Kirk+, Oxford Internet Institute, University of Oxford, arXiv'23</a>
<span class="snippet"><span>Comment</span><p># abst<br><br>LLMã‚’Personalizationã™ã‚‹ã“ã¨ã«é–¢ã—ã¦ã€ã©ã®ã‚ˆã†ãªæ–¹æ³•ã§Personalizationã™ã¹ãã‹ã‚’æ¤œè¨ã—ãŸç ”ç©¶ã€‚ä»¥ä¸‹ã®å•é¡Œç‚¹ã‚’æŒ‡æ‘˜ã€‚<br><br>1. ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆï¼ˆRLHFã®ã‚ˆã†ã«ä½•ã‚‰ã‹ã®æ–¹å‘æ€§ã«alignã™ã‚‹ã‚ˆã†ã«è£œæ­£ã™ã‚‹æŠ€è¡“ã®ã“ã¨ï¼Ÿï¼‰ãŒä½•ã‚’æ„å‘³ã™ã‚‹ã®ã‹æ˜ç¢ºã§ã¯ãªã„<br><br>2. æŠ€è¡“æä¾›è€…ãŒæœ¬è³ªçš„ã«ä¸»è¦³çš„ãªå¥½ã¿ã‚„ä¾¡å€¤è¦³ã®å®šç¾©ã‚’è¦å®šã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨<br><br>3. ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã®å°‚åˆ¶ã«ã‚ˆã£ã¦ã€æˆ‘ã€…ãŒå®Ÿéš›ã«ä½•ã«ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã—ã¦ã„ã‚‹ã®ã‹ã«é–¢ã™ã‚‹æ–‡æ›¸ãŒä¸è¶³ã—ã¦ã„ã‚‹ã“ã¨<br><br><br><br>ãã—ã¦ã€PersonalizedãªLLMã®åˆ©ç‚¹ã‚„ãƒªã‚¹ã‚¯ã®åˆ†é¡ã‚’æç¤ºã™ã‚‹ã€‚<br><br><br><br># å°å…¥<br><br>LLMãŒã•ã¾ã–ã¾ãªè£½å“ã«çµ±åˆã•ã‚ŒãŸã“ã¨ã§ã€äººé–“ã®å—œå¥½ã«åˆè‡´ã—ã€å±é™ºã‹ã¤ä¸æ­£ç¢ºãªæƒ…å ±ã‚’å‡ºåŠ›ã‚’ç”Ÿæˆã—ãªã„ã“ã¨ã‚’ç¢ºä¿ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚RLHFã‚„red-teamingã¯ã“ã‚Œã«å½¹ç«‹ã¤ãŒã€ã“ã®ã‚ˆã†ãªé›†åˆçš„ãªï¼ˆå¤šãã®äººã«ä¸€ã¤ã®ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã®çµæœã‚’æç¤ºã™ã‚‹ã“ã¨ï¼‰finetuningãƒ—ãƒ­ã‚»ã‚¹ãŒäººé–“ã®å¥½ã¿ã‚„ä¾¡å€¤è¦³ã®å¹…åºƒã„ç¯„å›²ã‚’ååˆ†ã«è¡¨ç¾ã§ãã‚‹ã¨ã¯è€ƒãˆã«ãã„ã€‚ç•°ãªã‚‹äººã€…ã¯ã•ã¾ã–ã¾ãªæ„è¦‹ã‚„ä¾¡å€¤è¦³ã‚’æŒã£ã¦ãŠã‚Šã€ãƒã‚¤ã‚¯ãƒ­ãƒ¬ãƒ™ãƒ«ã®finetuningãƒ—ãƒ­ã›ã›é›¨ã‚’é€šã˜ã¦LLMã‚’Personalizationã™ã‚‹ã“ã¨ã§ã€å„ãƒ¦ãƒ¼ã‚¶ã¨ã‚ˆã‚Šè‰¯ã„ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆãŒå¯èƒ½ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ã“ã‚Œã‚’ç¤¾ä¼šçš„ã«å—ã‘å…¥ã‚Œã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã«ã„ãã¤ã‹èª²é¡ŒãŒã‚ã‚‹ã®ã§ã€ãã‚Œã«ã¤ã„ã¦è«–ã˜ãŸã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/529" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Transformer to 1M tokens and beyond with RMT, Bulatov+, DeepPavlov, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>Reccurent Memory Transformer <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/523" target="_blank" rel="noopener noreferrer">Recurrent Memory Transformer, Bulatov+, NeurIPS'22</a>
 ã‚’ä½¿ã£ã¦2Mãƒˆãƒ¼ã‚¯ãƒ³æ‰±ãˆã‚‹ã‚ˆã†ã«ã—ãŸã‚ˆãƒ¼ã¨ã„ã†è©±ã€‚<br><br>ãƒãƒªãƒ¼ãƒãƒƒã‚¿ãƒ¼ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒ1.5Mã‚‰ã—ã„ã®ã§ã€ãã®ã†ã¡å°èª¬ä¸€å†Šæ›¸ã‘ã‚‹ã‹ã‚‚ã¨ã„ã†ä¸–ç•Œã€‚</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Planning.html" target="_blank" rel="noopener noreferrer">#Planning</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/526" target="_blank" rel="noopener noreferrer" class="title-link">LLM+P: Empowering Large Language Models with Optimal Planning Proficiency, Liu+, University of Texas at Austin, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>LLMã¯é•·ã„ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚’ã™ã‚‹ã“ã¨ãŒè‹¦æ‰‹ã ã£ãŸãŒã€classicalãªplannerã¯é©åˆ‡ãªinputã®å½¢å¼ã«å¤‰æ›ã•ã‚Œã¦ã„ã‚Œã°ã™ãã«æœ€é©ãªãƒ—ãƒ©ãƒ³ã‚’å°å‡ºã§ãã‚‹ã€ãŒã€è‡ªç„¶è¨€èªã¯å—ã‘ä»˜ã‘ãªã„ã€ã¨ã„ã£ãŸäº’ã„ãŒäº’ã„ã‚’è£œå®Œã—åˆã†é–¢ä¿‚ã«ã‚ã‚‹ã®ã§ã€ä¸¡è€…ã‚’çµ„ã¿åˆã‚ã›ã¾ã—ãŸã€ã¨ã„ã†è©±ã€‚<br>LLMã‚’åˆ©ç”¨ã—ã¦ã€planning problemã‚’è¨˜è¿°ã—ãŸè‡ªç„¶è¨€èªã‚’classicalãªplannerã®inputã¸å¤‰æ›ã€‚ãã®å¾Œplannerã§æœ€é©ãªplanã‚’è¦‹ã¤ã‘ã€è‡ªç„¶è¨€èªã«planã‚’é€†ç¿»è¨³ã™ã‚‹ã€‚<br><img src="https://user-images.githubusercontent.com/12249301/234289649-416a8d9e-628e-422c-bd9b-89d9099b4b1d.jpeg" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-04-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/518" target="_blank" rel="noopener noreferrer" class="title-link">REACT : SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS, Yao+, Princeton University and Google brain, ICLR'23</a>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>äººé–“ã¯æ¨è«–ã¨è¡Œå‹•ã‚’ã‚·ãƒŠã‚¸ãƒ¼ã•ã›ã‚‹ã“ã¨ã§ã€ã•ã¾ã–ã¾ãªæ„æ€æ±ºå®šã‚’è¡Œãˆã‚‹ã€‚è¿‘å¹´ã§ã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚Šè¨€èªã«ã‚ˆã‚‹æ¨è«–ã‚’æ„æ€æ±ºå®šã«çµ„ã¿åˆã‚ã›ã‚‹å¯èƒ½æ€§ãŒç¤ºã•ã‚Œã¦ããŸã€‚ãŸã¨ãˆã°ã€ã‚¿ã‚¹ã‚¯ã‚’ã“ãªã™ãŸã‚ã®æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’LLMãŒå°ã‘ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ããŸï¼ˆChain-of-Thoughtï¼‰ãŒã€CoTã¯å¤–éƒ¨ãƒªã‚½ãƒ¼ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„ãŸã‚çŸ¥è­˜ãŒã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§ããšã€äº‹å¾Œçš„ã«æ¨è«–ã‚’è¡Œã†ãŸã‚hallucinationã‚„ã‚¨ãƒ©ãƒ¼ã®ä¼æ¬ãŒç”Ÿã˜ã‚‹ã€‚ä¸€æ–¹ã§ã€äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’interactiveãªç’°å¢ƒã«ãŠã„ã¦è¨ˆç”»ã¨è¡Œå‹•ã«åˆ©ç”¨ã™ã‚‹ç ”ç©¶ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ãŒã€ã“ã‚Œã‚‰ã®ç ”ç©¶ã§ã¯ã€é«˜ãƒ¬ãƒ™ãƒ«ã®ç›®æ¨™ã«ã¤ã„ã¦æŠ½è±¡çš„ã«æ¨è«–ã—ãŸã‚Šã€è¡Œå‹•ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ã®ä½œæ¥­è¨˜æ†¶ã‚’ç¶­æŒã—ãŸã‚Šã™ã‚‹ãŸã‚ã«è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ã¦ã„ãªã„ã€‚æ¨è«–ã¨è¡Œå‹•ã‚’ä¸€èˆ¬çš„ãªèª²é¡Œè§£æ±ºã®ãŸã‚ã«ã©ã®ã‚ˆã†ã«ã‚·ãƒŠã‚¸ãƒ¼ã§ãã‚‹ã‹ã€ã¾ãŸãã®ã‚ˆã†ãªã‚·ãƒŠã‚¸ãƒ¼ãŒå˜ç‹¬ã§æ¨è«–ã‚„è¡Œå‹•ã‚’å®Ÿæ–½ã—ãŸå ´åˆã¨æ¯”è¼ƒã—ã¦ã©ã®ã‚ˆã†ãªåˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™ã‹ã«ã¤ã„ã¦ç ”ç©¶ã•ã‚Œã¦ã„ãªã„ã€‚<br><br>ãã“ã§ã€REACTã‚’ææ¡ˆã€‚REACTã¯æ¨è«–ã¨è¡Œå‹•ã‚’LLMã¨çµ„ã¿åˆã‚ã›ã¦ã€å¤šæ§˜ãªæ¨è«–ã‚„æ„æ€æ±ºå®šã‚¿ã‚¹ã‚¯ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®ä¸€èˆ¬çš„ãªæ çµ„ã¿ã§ã‚ã‚Šã€æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’äº¤äº’ã«ç”Ÿæˆã™ã‚‹ãŸã‚ã€å‹•çš„ã«æ¨è«–ã‚’å®Ÿè¡Œã—ã¦è¡Œå‹•ã™ã‚‹ãŸã‚ã®å¤§ã¾ã‹ãªè¨ˆç”»ã‚’ä½œæˆã€ç¶­æŒã€èª¿æ•´ã§ãã‚‹ã¨åŒæ™‚ã«ã€wikipediaãªã©ã®å¤–éƒ¨ã‚½ãƒ¼ã‚¹ã¨ã‚„ã‚Šã¨ã‚Šã—ã¦è¿½åŠ æƒ…å ±ã‚’åé›†ã—ã€æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒå¯èƒ½ã¨ãªã‚‹ã€‚<br><br><br><br>- è¦ã¯ã„ã¾ã¾ã§ã¯Generalãªã‚¿ã‚¹ã‚¯è§£æ±ºãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã¯ã€æ¨è«–ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆã¯ç‹¬ç«‹ã«ã—ã‹ã‚„ã‚‰ã‚Œã¦ã“ãªã‹ã£ãŸã‘ã©ã€æ¨è«–ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’äº¤äº’ä½œç”¨ã•ã›ã‚‹ã“ã¨ã«ã¤ã„ã¦ç ”ç©¶ã—ãŸã‚ˆ<br><br>- ãã—ãŸã‚‰æ€§èƒ½ãŒã¨ã£ã¦ã‚‚ã‚ãŒã£ãŸã‚ˆ<br><br>- reasoningã‚’äººé–“ãŒç·¨é›†ã™ã‚Œã°ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã‚‚ã§ãã‚‹ã‚ˆã€€ã¨ã„ã†æ„Ÿã˜<br><br><br><br># ã‚¤ãƒ³ãƒˆãƒ­<br><br>äººé–“ã¯æ¨è«–ã¨è¡Œå‹•ã®ç·Šå¯†ãªã‚·ãƒŠã‚¸ãƒ¼ã«ã‚ˆã£ã¦ã€ä¸ç¢ºå®ŸãªçŠ¶æ³ã«é­é‡ã—ã¦ã‚‚é©åˆ‡ãªæ„æ€æ±ºå®šãŒè¡Œãˆã‚‹ã€‚ãŸã¨ãˆã°ã€ä»»æ„ã®2ã¤ã®ç‰¹å®šã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®é–“ã§ã€é€²è¡ŒçŠ¶æ³ã‚’ãƒˆãƒ¬ãƒ¼ã‚¹ã™ã‚‹ãŸã‚ã«è¨€èªã§æ¨è«–ã—ãŸã‚Šï¼ˆã™ã¹ã¦åˆ‡ã‚Šçµ‚ã‚ã£ãŸã‹ã‚‰ãŠæ¹¯ã‚’æ²¸ã‹ã™å¿…è¦ãŒã‚ã‚‹ï¼‰ã€ä¾‹å¤–ã‚’å‡¦ç†ã—ãŸã‚Šã€çŠ¶æ³ã«å¿œã˜ã¦è¨ˆç”»ã‚’èª¿æ•´ã—ãŸã‚Šã™ã‚‹ï¼ˆå¡©ãŒãªã„ã‹ã‚‰ä»£ã‚ã‚Šã«é†¤æ²¹ã¨èƒ¡æ¤’ã‚’ä½¿ãŠã†ï¼‰ã€‚ã¾ãŸã€æ¨è«–ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€ç–‘å•ï¼ˆã„ã¾ã©ã‚“ãªæ–™ç†ã‚’ä½œã‚‹ã“ã¨ãŒã§ãã‚‹ã ã‚ã†ã‹ï¼Ÿï¼‰ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã«ã€è¡Œå‹•ï¼ˆæ–™ç†æœ¬ã‚’é–‹ã„ã¦ãƒ¬ã‚·ãƒ”ã‚’èª­ã‚“ã§ã€å†·è”µåº«ã‚’é–‹ã„ã¦ææ–™ã‚’ç¢ºç¢ºèªã—ãŸã‚Šï¼‰ã‚’ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã€‚<br><br><br><br>è¿‘å¹´ã®ç ”ç©¶ã§ã¯è¨€èªã§ã®æ¨è«–ã‚’ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªæ„æ€æ±ºå®šã‚’çµ„ã¿åˆã‚ã›ã‚‹å¯èƒ½æ€§ã«ã¤ã„ã¦ã®ãƒ’ãƒ³ãƒˆãŒå¾—ã‚‰ã‚Œã¦ããŸã€‚ä¸€ã¤ã¯ã€é©åˆ‡ã«Promptingã•ã‚ŒãŸLLMãŒæ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å®Ÿè¡Œã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã¨ã¯ã€è§£æ±ºç­–ã«åˆ°é”ã™ã‚‹ãŸã‚ã®ä¸€é€£ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’çµŒã¦æ¨è«–ã‚’ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ã‚»ã‚¹ã®ã“ã¨ã§ã‚ã‚‹ã€‚ã—ã‹ã—ãªãŒã‚‰Chain-of-thoughytã¯ã€ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒå¤–ç•Œå¯¾ã—ã¦groundingã§ããšã€å†…éƒ¨è¡¨ç¾ã®ã¿ã«åŸºã¥ã„æ€è€ƒã‚’ç”Ÿæˆã™ã‚‹ãŸã‚é™ç•ŒãŒã‚ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šãƒ¢ãƒ‡ãƒ«ãŒäº‹å¾Œå¯¾å¿œçš„ã«æ¨è«–ã—ãŸã‚Šã€å¤–éƒ¨æƒ…å ±ã«åŸºã¥ã„ã¦çŸ¥è­˜ã‚’æ›´æ–°ã—ãŸã‚Šã§ããªã„ãŸã‚ã€æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ä¸­ã«hallucinationã‚„ã‚¨ãƒ©ãƒ¼ã®ä¼æ¬ãªã©ã®å•é¡ŒãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒç”Ÿã˜ã‚‹ã€‚<br><br>ä¸€æ–¹ã€è¿‘å¹´ã®ç ”ç©¶ã§ã¯äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’interactiveãªç’°å¢ƒã«ãŠã„ã¦è¨ˆç”»ã¨è¡Œå‹•ã«åˆ©ç”¨ã™ã‚‹ç ”ç©¶ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã€‚ã“ã‚Œã‚‰ã®ç ”ç©¶ã§ã¯ã€é€šå¸¸ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªè¦³æ¸¬çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ã¾ãŸã¯ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆã—ã€ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’åˆ©ç”¨ã—ã¦ãã‚Œã‚‰ã‚’é¸æŠã¾ãŸã¯å®Ÿè¡Œã™ã‚‹ã€‚ãŸã ã—ã€ã“ã‚Œã‚‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯é«˜ãƒ¬ãƒ™ãƒ«ã®ç›®æ¨™ã«ã¤ã„ã¦æŠ½è±¡çš„ã«æ¨è«–ã—ãŸã‚Šã€è¡Œå‹•ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ã®ä½œæ¥­è¨˜æ†¶ã‚’ç¶­æŒã—ãŸã‚Šã™ã‚‹ãŸã‚ã«è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ã¦ã„ãªã„ã€‚<br><br>æ¨è«–ã¨è¡Œå‹•ã‚’ä¸€èˆ¬çš„ãªèª²é¡Œè§£æ±ºã®ãŸã‚ã«ã©ã®ã‚ˆã†ã«ã‚·ãƒŠã‚¸ãƒ¼ã§ãã‚‹ã‹ã€ã¾ãŸãã®ã‚ˆã†ãªã‚·ãƒŠã‚¸ãƒ¼ãŒå˜ç‹¬ã§æ¨è«–ã‚„è¡Œå‹•ã‚’å®Ÿæ–½ã—ãŸå ´åˆã¨æ¯”è¼ƒã—ã¦ã©ã®ã‚ˆã†ãªåˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™ã‹ã«ã¤ã„ã¦ç ”ç©¶ã•ã‚Œã¦ã„ãªã„ã€‚<br><br><br><br>LLMã«ãŠã‘ã‚‹æ¨è«–ã¨è¡Œå‹•ã‚’çµ„ã¿åˆã‚ã›ã¦ã€è¨€èªæ¨è«–ã¨æ„æ€æ±ºå®šã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹REACTã¨å‘¼ã°ã‚Œã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚REACTã§ã¯ã€æ¨è«–ã¨è¡Œå‹•ã®ç›¸ä¹—åŠ¹æœã‚’é«˜ã‚ã‚‹ã“ã¨ãŒå¯èƒ½ã€‚æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã«ã‚ˆã‚Šã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’èª˜ç™ºã€è¿½è·¡ã€æ›´æ–°ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯å¤–éƒ¨ã‚½ãƒ¼ã‚¹ã¨é€£æºã—ã¦è¿½åŠ æƒ…å ±ã‚’åé›†ã§ãã‚‹ã€‚<br><br><br><br>REACTã¯æ¨è«–ã¨è¡Œå‹•ã‚’LLMã¨çµ„ã¿åˆã‚ã›ã¦ã€å¤šæ§˜ãªæ¨è«–ã‚„æ„æ€æ±ºå®šã‚¿ã‚¹ã‚¯ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®ä¸€èˆ¬çš„ãªæ çµ„ã¿ã§ã‚ã‚‹ã€‚REACTã®promptã¯LLMã«verbalãªæ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã¨ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’äº¤äº’ã«ç”Ÿæˆã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯å‹•çš„ãªæ¨è«–ã‚’å®Ÿè¡Œã—ã¦è¡Œå‹•ã™ã‚‹ãŸã‚ã®å¤§ã¾ã‹ãªè¨ˆç”»ã‚’ä½œæˆã€ç¶­æŒã€èª¿æ•´ã§ãã‚‹ã¨åŒæ™‚ã«ã€wikipediaãªã©ã®å¤–éƒ¨ã‚½ãƒ¼ã‚¹ã¨ã‚„ã‚Šã¨ã‚Šã—ã¦è¿½åŠ æƒ…å ±ã‚’åé›†ã—ã€æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒå¯èƒ½ã¨ãªã‚‹ã€‚<br><br><br><br># æ‰‹æ³•<br><br>å¤‰æ•°ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ï¼š<br><br>- O_t: Observertion on time t<br><br>- a_t: Action on time t<br><br>- c_t: context, i.e. (o_1, a_1, o_2, a_2, ..., a_t-1, o_t)<br><br>- policy pi(a_t | c_t): Action Spaceã‹ã‚‰ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠã™ã‚‹ãƒãƒªã‚·ãƒ¼<br><br>- A: Action Space<br><br>- O: Observation Space<br><br><br><br>æ™®é€šã¯c_tãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ãƒãƒªã‚·ãƒ¼ã«å¾“ã„Aã‹ã‚‰a_tã‚’é¸æŠã—ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®çµæœo_tã‚’å¾—ã¦ã€c_t+1ã‚’æ§‹æˆã™ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã¦ã„ãã€‚<br><br><br><br>ã“ã®ã¨ãã€REACTã¯Aã‚’A âˆª Lã«æ‹¡å¼µã—ã™ã‚‹ã€‚ã“ã“ã§ã€Lã¯Language spaceã§ã‚ã‚‹ã€‚Lã«ã¯Action a_hatãŒå«ã¾ã‚Œã€a_hatã¯ç’°å¢ƒã«å¯¾ã—ã¦ä½œç”¨ã‚’ã—ãªã„ã€‚å˜ç´”ã«thought, ã‚ã‚‹ã„ã¯ reasoning traceã‚’å®Ÿæ–½ã—ã€ç¾åœ¨ã®context c_tã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã«æœ‰ç”¨ãªæƒ…å ±ã‚’æ§‹æˆã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã™ã‚‹ã€‚Lã¯unlimitedãªã®ã§ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã‚‹ã€‚ä»Šå›ã¯PaLM-540Bï¼ˆc.f. GPT3ã¯175Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ãŒåˆ©ç”¨ã•ã‚Œã€few-shotã®in-context exampleã‚’ä¸ãˆã‚‹ã“ã¨ã§æ¨è«–ã‚’è¡Œã†ã€‚ãã‚Œãã‚Œã®in-context exampleã¯ã€action, thoughtsãã—ã¦observationã®trajectoryã‚’ä¸ãˆã‚‹ã€‚<br><br><br><br>æ¨è«–ãŒé‡è¦ãªã‚¿ã‚¹ã‚¯ã§ã¯ã€thoughts-action-observationã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰æˆã‚‹task-solving trajectoryã‚’ç”Ÿæˆã™ã‚‹ã€‚ä¸€æ–¹ã€å¤šæ•°ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¼´ã†å¯èƒ½æ€§ãŒã‚ã‚‹æ„æ€æ±ºå®šã‚¿ã‚¹ã‚¯ã§ã¯ã€thoughtsã®ã¿ã‚’è¡Œã†ã“ã¨ã‚’task-solving trajectoryä¸­ã®ä»»æ„ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã€è‡ªåˆ†ã§åˆ¤æ–­ã—ã¦è¡Œã†ã“ã¨ãŒã§ãã‚‹ã€‚<br><br><br><br>æ„æ€æ±ºå®šã¨æ¨è«–èƒ½åŠ›ãŒLLMã«ã‚ˆã£ã¦ã‚‚ãŸã‚‰ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€REACTã¯4ã¤ã®uniqueãªç‰¹å¾´ã‚’æŒã¤ï¼š<br><br>- ç›´æ„Ÿçš„ã§ç°¡å˜ãªãƒ‡ã‚¶ã‚¤ãƒ³<br><br>  - REACTã®promptã¯äººé–“ã®ã‚¢ãƒãƒ†ãƒ¼ã‚¿ãŒã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒˆãƒƒãƒ—ã«æ€è€ƒã‚’è¨€èªã§è¨˜è¿°ã™ã‚‹ã‚ˆã†ãªã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆãªã‚‚ã®ã§ã‚ã‚Šã€ad-hocãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®é¸æŠã€æ€è€ƒã®ãƒ‡ã‚¶ã‚¤ãƒ³ã€äº‹ä¾‹ã®é¸å®šãªã©ãŒå¿…è¦ãªã„ã€‚<br><br>- ä¸€èˆ¬çš„ã§æŸ”è»Ÿæ€§ãŒé«˜ã„<br><br>  - æŸ”è»Ÿãª thought spaceã¨ thought-actionã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ã‚ˆã‚Šã€REACTã¯ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã«ã‚‚æŸ”è»Ÿã«å¯¾å¿œã§ãã‚‹<br><br>- é«˜æ€§èƒ½ã§ãƒ­ãƒã‚¹ãƒˆ<br><br>  - REACTã¯1-6å€‹ã®äº‹ä¾‹ã«ã‚ˆã£ã¦ã€æ–°ãŸãªã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹å¼·åŠ›ãªæ±åŒ–ã‚’ç¤ºã™ã€‚ãã—ã¦æ¨è«–ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã¿ã‚’è¡Œã†ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚REACTã¯finetuningã®æ–§ç³»ã‚‚å¾—ã‚‹ã“ã¨ãŒã§ãã€promptã®é¸æŠã«å¯¾ã—ã¦REACTã®æ€§èƒ½ã¯robustã§ã‚ã‚‹ã€‚<br><br>- äººé–“ã«ã‚ˆã‚‹èª¿æ•´ã¨æ“ä½œãŒå¯èƒ½<br><br>  - REACTã¯ã€è§£é‡ˆå¯èƒ½ãªæ„æ€æ±ºå®šã¨æ¨è«–ã®sequenceã‚’å‰æã¨ã—ã¦ã„ã‚‹ãŸã‚ã€äººé–“ã¯ç°¡å˜ã«æ¨è«–ã‚„äº‹å®Ÿã®æ­£ã—ã•ã‚’æ¤œè¨¼ã§ãã‚‹ã€‚åŠ ãˆã¦ã€thoughtsã‚’ç·¨é›†ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€mäººé–“ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¡Œå‹•ã‚’åˆ¶å¾¡ã€ã‚ã‚‹ã„ã¯ä¿®æ­£ã§ãã‚‹ã€‚<br><br><br><br># KNOWLEDGE INTENSIVE REASONING TASKS</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataGeneration.html" target="_blank" rel="noopener noreferrer">#DataGeneration</a>
<span class="issue_date">Issue Date: 2023-04-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/517" target="_blank" rel="noopener noreferrer" class="title-link">ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks, Gilardi+, University of Zurich, NAS'23</a>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>2300ä»¶ç¨‹åº¦ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’åˆ†é¡ã™ã‚‹ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€è¨“ç·´ã—ãŸå­¦éƒ¨ç”Ÿã«ã‚ˆã‚‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ­£è§£ã¨ã—ã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã¨ChatGPTã§ã®zero-shotã§ã®äºˆæ¸¬ã®æ€§èƒ½ã‚’æ¯”è¼ƒã—ãŸã€‚åˆ†é¡ã‚¿ã‚¹ã‚¯ã¯ã€æ¯”è¼ƒçš„é›£æ˜“åº¦ã®é«˜ã„åˆ†é¡å•é¡Œã§ã‚ã‚Šã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ã‚‚æ­£è§£ç‡ã¯é›£ã—ã„ã‚¿ã‚¹ã‚¯ã§ã¯15~25%ç¨‹åº¦ã§ã‚ã£ãŸã€‚ã“ã®ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã§chatgptã¯40~60%ã®æ­£è§£ç‡ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br>æ¯”è¼ƒã®çµæœã€5ã¤ã®ã‚¿ã‚¹ã‚¯ä¸­4ã¤ã®ã‚¿ã‚¹ã‚¯ã§ChatGPTãŒã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’ä¸Šå›ã‚‹æ­£è§£ç‡ã‚’ç¤ºã—ãŸã€‚<br><br><br><br># æ‰‹æ³•<br><br>- ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã¨ChatGPTã§åŒã˜ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’åˆ©ç”¨ã—ã€åŒã˜ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã—ãŸ<br><br>- inter-notator aggreementã‚’å›³ã‚‹ãŸã‚ã«ã€ãã‚Œãã‚Œã®ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦å„ãƒ„ã‚¤ãƒ¼ãƒˆã«å°‘ãªãã¨ã‚‚2äººãŒãƒ©ãƒ™ãƒ«ä»˜ã‚’è¡Œã£ãŸ<br><br>- ChatGPTã§ã‚‚åŒæ§˜ã«ã€ã‚¿ã‚¹ã‚¯ã”ã¨ã«å„ãƒ„ã‚¤ãƒ¼ãƒˆã«ã¯2å›åŒã˜ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã—ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ãŸ<br><br>- ChatGPTã‚’åˆ©ç”¨ã™ã‚‹éš›ã¯ã€temperatureã‚’1.0, 0.2ã®å ´åˆã§è©¦ã—ãŸã€‚å¾“ã£ã¦ChatGPTã®ãƒ©ãƒ™ãƒ«ä»˜ã‘ã¯å„ã‚¿ã‚¹ã‚¯ã”ã¨ã«4ã‚»ãƒƒãƒˆå­˜åœ¨ã™ã‚‹ã“ã¨ã«ãªã‚‹ã€‚<br><br><br><br># çµæœ<br><br><img src="https://user-images.githubusercontent.com/12249301/231333088-cfe9362a-5412-4ea1-ae8c-67156f13290c.png" alt="image" loading="lazy"><br><br><br><br>5ã‚¿ã‚¹ã‚¯ä¸­ã€4ã‚¿ã‚¹ã‚¯ã§ChatGPTãŒzero-shotã«ã‚‚ã‹ã‹ã‚ã‚‰ãšæ­£è§£ç‡ã§workerã‚’ä¸Šå›ã£ãŸã€‚ã¾ãŸé«˜ã„aggreementã‚’ç™ºæ®ã—ã¦ã„ã‚‹ã“ã¨ã‚’ä¸»å¼µã€‚aggreementã¯temperatureãŒä½ã„æ–¹ãŒé«˜ãã€ã“ã‚Œã¯temperatureãŒä½ã„æ–¹ãŒrandomnessãŒæ¸›å°‘ã™ã‚‹ãŸã‚ã§ã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚aggreementã‚’Accuracyã®ç›¸é–¢ã‚’å›³ã£ãŸãŒã€0.17ã§ã‚ã‚Šå¼±ã„ç›¸é–¢ã—ã‹ãªã‹ã£ãŸã€‚å¾“ã£ã¦ã€Accuracyã‚’æ¸›å°‘ã•ã›ã‚‹ã“ã¨ãªãã€ä¸€è²«æ€§ã®ã‚ã‚‹çµæœã‚’å¾—ã‚‰ã‚Œã‚‹law temperatureã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒæœ›ã¾ã—ã„ã¨çµè«–ã¥ã‘ã¦ã„ã‚‹ã€‚<br><br><br><br># å®Ÿæ–½ã—ãŸã‚¿ã‚¹ã‚¯<br><br>"content moderation"ã«é–¢ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã—ãŸã€‚content moderationã¯SNSãªã©ã«æŠ•ç¨¿ã•ã‚Œã‚‹postã‚’ç›£è¦–ã™ã‚‹ãŸã‚ã®å–ã‚Šçµ„ã¿ã§ã‚ã‚Šã€ãŸã¨ãˆã°ãƒãƒ«ãƒˆãƒ„ã‚¤ãƒ¼ãƒˆã‚„èª¤ã£ãŸæƒ…å ±ã‚’å«ã‚€æœ‰å®³ãªãƒ„ã‚¤ãƒ¼ãƒˆã€ãƒ˜ã‚¤ãƒˆã‚¹ãƒ”ãƒ¼ãƒãªã©ãŒå­˜åœ¨ã—ãªã„ã‹ã‚’SNSä¸Šã§ç›£è¦–ã‚’ã‚’è¡Œã†ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã§ã‚ã‚‹ã€‚è‘—è€…ã‚‰ã¯content moderationã¯ãƒãƒ¼ãƒ‰ãªã‚¿ã‚¹ã‚¯ã§ã‚ã‚Šã€è¤‡é›‘ãªãƒˆãƒ”ãƒƒã‚¯ã ã—ã€toy exampleã§ã¯ãªã„ã“ã¨ã‚’ä¸»å¼µã—ã¦ã„ã‚‹ã€‚å®Ÿéš›ã€è‘—è€…ã‚‰ãŒè¨“ç·´ã—ãŸå­¦éƒ¨ç”Ÿã®é–“ã§ã®inter-annotator aggreementã¯50%ç¨‹åº¦ã§ã‚ã‚Šã€é›£æ˜“åº¦ãŒé«˜ã„ã‚¿ã‚¹ã‚¯ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ï¼ˆãŸã ã—ã€ã‚¹ã‚¿ãƒ³ã‚¹detectionã«é–¢ã—ã¦ã¯aggreementãŒ78.3%ã§ã‚ã£ãŸï¼‰ã€‚<br><br><br><br>content moderationã®ã†ã¡ã€ä»¥ä¸‹ã®5ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã—ãŸã€‚<br><br>- relevance:<br><br>  - ãƒ„ã‚¤ãƒ¼ãƒˆãŒcontent moderationã«ã¤ã„ã¦ç›´æ¥çš„ã«é–¢ä¿‚ã™ã‚‹ã“ã¨ã‚’è¿°ã¹ã¦ã„ã‚‹ã‹å¦ã‹<br><br>  - e.g. SNSã«ãŠã‘ã‚‹content moderation ruleã‚„å®Ÿè·µã€æ”¿åºœã®ãƒ¬ã‚®ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç­‰<br><br>  - content moderationã«ã¤ã„ã¦è¿°ã¹ã¦ã„ãªã„ã‚‚ã®ã«ã¤ã„ã¦ã¯IRRELEVANTãƒ©ãƒ™ãƒ«ã‚’ä»˜ä¸ã™ã‚‹<br><br>  - ãŸã ã—ã€ä¸»é¡ŒãŒcontent moderationã®ãƒ„ã‚¤ãƒ¼ãƒˆã§ã‚ã£ã¦ã‚‚ã€content moderationã«ã¤ã„ã¦è«–ã˜ã¦ã„ãªã„ã‚‚ã®ã«ã¤ã„ã¦ã¯IRRELEVANTæ‰±ã„ã¨ã™ã‚‹ã€‚<br><br>  - ã“ã®ã‚ˆã†ãªä¾‹ã¨ã—ã¦ã¯ã€TwitterãŒDonald Trupã®Twitterã‚’"disrupted"ã¨labelä»˜ã‘ã—ãŸã“ã¨ã‚„ã€ä½•ã‹ã«ã¤ã„ã¦é–“é•ã£ã¦ã„ã‚‹ã¨è¿°ã¹ã¦ã„ã‚‹ãƒ„ã‚¤ãƒ¼ãƒˆã€ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ãªå†…å®¹ã‚’å«ã‚€ãƒ„ã‚¤ãƒ¼ãƒˆãªã©ãŒã‚ã’ã‚‰ã‚Œã‚‹ã€‚<br><br>- Problem/Solution Frames<br><br>  - content moderationã¯2ã¤ã®è¦‹æ–¹ãŒã§ãã‚‹ã€‚ãã‚ŒãŒProblemã¨Solution<br><br>  - Problem: content moderationã‚’PROBLEMã¨ã¿ãªã™ã‚‚ã®ã€‚ãŸã¨ãˆã°ã€ãƒ•ãƒªãƒ¼ã‚¹ãƒ”ãƒ¼ãƒã®åˆ¶é™ãªã©<br><br>  - SOLUTION: content moderationã‚’SOLUTIONã¨ã¿ãªã™ã‚‚ã®ã€‚ãŸã¨ãˆã°ã€harmful speechã‹ã‚‰å®ˆã‚‹ã“ã¨ã€ãªã©<br><br>  - ãƒ„ã‚¤ãƒ¼ãƒˆãŒcontent moderationã®negativeãªå½±éŸ¿ã«ã¤ã„ã¦å¼·èª¿ã—ã¦ã„ãŸã‚‰ã€PROBLEMï¼ˆãƒ•ãƒªãƒ¼ã‚¹ãƒ”ãƒ¼ãƒã®åˆ¶é™ã‚„ãƒ¦ãƒ¼ã‚¶ãŒãƒã‚¹ãƒˆã™ã‚‹å†…å®¹ã«ã¤ã„ã¦ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ã‚‹ã“ã¨ãªã©ã«ã¤ã„ã¦ï¼‰<br><br>  - ãƒ„ã‚¤ãƒ¼ãƒˆãŒcontent moderationã®positiveãªå½±éŸ¿ã«ã¤ã„ã¦å¼·èª¿ã—ã¦ã„ãŸã‚‰ã€SOKUTIONï¼ˆharmful contentã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ã‚’å®ˆã‚‹ãªã©ï¼‰<br><br>  - ä¸»é¡Œã¯content moderationã§ã‚ã‚‹ãŒã€positive/negativeãªå½±éŸ¿ã«ã¤ã„ã¦è«–ã˜ã¦ã„ãªã„ã‚‚ã®ã¯NEUTRAL<br><br>- Policy Frames<br><br>  - content moderationã¯ã•ã¾ã–ã¾ã‚“ãƒˆãƒ”ãƒƒã‚¯ã¨é–¢é€£ã—ã¦ã„ã‚‹ï¼ˆãŸã¨ãˆã°ï¼‰ã€å¥åº·ã€çŠ¯ç½ªã€å¹³ç­‰ãªã©ï¼‰<br><br>  - content moderatiojnã«é–¢ã™ã‚‹ãƒ„ã‚¤ãƒ¼ãƒˆãŒã©ã®ãƒˆãƒ”ãƒƒã‚¯ã‹ã‚’ãƒ©ãƒ™ãƒ«ä»˜ã™ã‚‹ã€‚ãƒ©ãƒ™ãƒ«ã¯15ç¨®é¡<br><br>  - economy, capcity and resources, modality, fairness and equality, constitutionality and jurisprudence, policy prescription and evaluation, law and order, crime and justice, security and defense, health and safety, quality of life, cultural identity, public opinion, political, external regulation and reputation, other<br><br>- Stance Detection<br><br>  - USã®Section 230ã¨ã„ã†æ³•å¾‹ï¼ˆwebsiteã«ãƒ¦ãƒ¼ã‚¶ãŒæŠ•ç¨¿ã—ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«å¯¾ã—ã¦ã€webã‚µã‚¤ãƒˆã‚„ãã®ä»–ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãŒæ³•çš„è²¬ä»»ã‚’å•ã‚ã‚Œã‚‹ã®ã‚’é˜²ãæ³•å¾‹ï¼‰ã«ã¤ã„ã¦ã€ãƒ„ã‚¤ãƒ¼ãƒˆãŒSection230ã«å¯¾ã—ã¦ã€positive/negative/neutralãªã‚¹ã‚¿ãƒ³ã‚¹ã‹ã‚’ãƒ©ãƒ™ãƒ«ä»˜ã™ã‚‹<br><br>- Topic Detection<br><br>  - ãƒ„ã‚¤ãƒ¼ãƒˆã‚’6ã¤ã®ãƒˆãƒ”ãƒƒã‚¯ã«ãƒ©ãƒ™ãƒ«ä»˜ã™ã‚‹<br><br>  - Section 230, TRUMP BAN, TWITTER-SUPPORT, PLATFORM POLICIES, COMPLAINTS, other</p>
<p># æ‰€æ„Ÿ<br><br>ãã“ãã“é›£æ˜“åº¦ã®é«˜ã„ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã§ã‚‚zero-shotã§turkerã®æ€§èƒ½ã‚’ä¸Šå›ã‚‹ã®ã¯éå¸¸ã«ç´ æ™´ã‚‰ã—ã„ã“ã¨ã ã¨æ€ã†ã€‚ãƒã‚¤ã‚¸ãƒ¼ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚Œã°ã€æ¯”è¼ƒçš„å®‰ä¾¡ã€ã‹ã¤ã‚¹ãƒ”ãƒ¼ãƒ‡ã‚£ãƒ¼ã«ä½œæˆã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ããŸã®ã§ã¯ãªã„ã‹ã¨æ€ã†ã€‚<br><br>ãŸã ã€ChatGPTã®aggreementã‚’å›³ã‚‹ã“ã¨ã«ã©ã‚Œã ã‘æ„å‘³ãŒã‚ã‚‹ã®ã ã‚ã†ã€ã¨ã¯æ€ã†ã€‚åŒã˜ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã‚ã‘ã§ã€å°tãªã‚‹LLMã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸå ´åˆã®aggreementãªã‚‰ã¨ã‚‹æ„å‘³ãŒã‚ã‚‹ã¨æ€ã†ãŒã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/In-Depth%20Notes.html" target="_blank" rel="noopener noreferrer">#In-Depth Notes</a>
<span class="issue_date">Issue Date: 2023-03-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/513" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Instruct: Aligning Language Models with Self-Generated Instructions, Yizhong Wang+, ACL'23, 2022.12</a>
<span class="snippet"><span>GPT Summary</span>- Self-Instructãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«ãŒè‡ªã‚‰ç”Ÿæˆã—ãŸæŒ‡ç¤ºã‚’ç”¨ã„ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã“ã¨ã§ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ãƒãƒ‹ãƒ©GPT-3ã«é©ç”¨ã—ãŸçµæœã€Super-NaturalInstructionsã§33%ã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã—ã€InstructGPT-001ã¨åŒç­‰ã®æ€§èƒ½ã«åˆ°é”ã€‚äººé–“è©•ä¾¡ã«ã‚ˆã‚Šã€Self-InstructãŒæ—¢å­˜ã®å…¬å…±æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ã»ã¼æ³¨é‡ˆä¸è¦ã®æŒ‡ç¤ºèª¿æ•´æ‰‹æ³•ã‚’æä¾›ã€‚å¤§è¦æ¨¡ãªåˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã—ã€ä»Šå¾Œã®ç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Alpacaãªã©ã§ã‚‚åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹self-instructionæŠ€è¡“ã«é–¢ã™ã‚‹è«–æ–‡</p>
<p># æ¦‚è¦<br><br><img src="https://user-images.githubusercontent.com/12249301/228716254-5f4d7451-a37a-4354-843d-7e4052ba230b.png" alt="image" loading="lazy"><br><br><br><br>è‘—è€…ã‚‰ãŒæ›¸ã„ãŸ175ç¨®ã®instructionï¼ˆã‚¿ã‚¹ã‚¯ã®å®šç¾© + 1ç¨®ã®input/outputãƒšã‚¢}ã®seedã‚’å…ƒã«ã€VanillaãªGPT-3ã«æ–°ãŸãªinstruction, input, outputã®tupleã‚’ç”Ÿæˆã•ã›ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ´»ç”¨ã™ã‚‹ç ”ç©¶ã€‚<br><br>ã“ã“ã§ã€instruction data I ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã•ã‚Œã‚‹ï¼š<br><br>instruction dataã¯(I, X, Y)ã§ã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯æœ€çµ‚çš„ã«M(I_t, x_t) = y_tã¨ãªã‚‹ã‚ˆã†ã«å­¦ç¿’ã—ãŸã„ã€‚<br><br>I: instruction, X: input, Y: output<br><br><br><br>ãƒ‡ãƒ¼ã‚¿ä½œæˆã¯ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æ§‹æˆã•ã‚Œã‚‹ã€‚ãªãŠã€ä»¥ä¸‹ã¯ã™ã¹ã¦Vanilla GPT-3ã‚’é€šã˜ã¦è¡Œã‚ã‚Œã‚‹ï¼š<br><br>1. Instruction Generation<br><br>ã€€task poolã‹ã‚‰8ç¨®é¡ã®instructionã‚’æŠ½å‡ºã—ã€ promptã‚’æ§‹æˆã—ã€æœ€å¤§8å€‹æ–°ãŸãªinstructionã‚’ç”Ÿæˆã•ã›ã‚‹<br><br>2. Classification Task Identification:<br><br>ã€€ç”Ÿæˆã•ã‚ŒãŸinstructionãŒclassificationã‚¿ã‚¹ã‚¯ã‹å¦ã‹ã‚’åˆ¤åˆ¥ã™ã‚‹<br><br>3. Instance Generation<br><br>ã€€ã„ãã¤ã‹ã®(I, X, Y)ã‚’promptã¨ã—ã¦ä¸ãˆã€I, Xã«å¯¾å¿œã™ã‚‹Yã‚’ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã•ã›ã‚‹ã€‚ã“ã®ã¨ãinput-first approachã‚’æ¡ç”¨ã—ãŸçµæœï¼ˆI-&gt;Xã®é †ç•ªã§æƒ…å ±ã‚’ä¸ãˆYã‚’ç”Ÿæˆã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰ã€ç‰¹å®šã®ãƒ©ãƒ™ãƒ«ã«åã£ãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒç”Ÿæˆã•ã‚Œã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã“ã®ãŸã‚output-first approachã‚’åˆ¥é€”æ¡ç”¨ã—ï¼ˆI-&gt;Yã®é †ç•ªã§æƒ…å ±ã‚’ä¸ãˆã€å„Yã«å¯¾å¿œã™ã‚‹Xã‚’ç”Ÿæˆã•ã›ã‚‹ï¼‰ã€æ´»ç”¨ã—ã¦ã„ã‚‹ã€‚ã€€<br><br>4. Filtering and Postprocessing<br><br>ã€€æœ€å¾Œã«ã€æ—¢å­˜ã®task poolã¨ROUGE-LãŒ0.7ä»¥ä¸Šã®instructionã¯å¤šæ§˜æ€§ãŒãªã„ãŸã‚é™¤å¤–ã—ã€ç‰¹å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆimages, pictrues, graphsï¼‰ç­‰ã‚’å«ã‚“ã§ã„ã‚‹instruction dataã‚‚é™¤å¤–ã—ã¦ã€task poolã«è¿½åŠ ã™ã‚‹ã€‚<br><br><br><br>1-4ã‚’ã²ãŸã™ã‚‰ç¹°ã‚Šè¿”ã™ã“ã¨ã§ã€GPT-3ãŒInstruction Tuningã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•ç”Ÿæˆã—ã¦ãã‚Œã‚‹ã€‚<br><br><br><br># SELF-INSTRUCT Data<br><br>## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±è¨ˆé‡<br><br><img src="https://user-images.githubusercontent.com/12249301/228745059-ecccadba-3e32-4f2a-9594-2459a922474b.png" alt="image" loading="lazy"><br><br>- 52k instructions<br><br>- 82k instances<br><br><br><br>## Diversity<br><br><img src="https://user-images.githubusercontent.com/12249301/228745421-ba024963-ca6e-4e30-bac8-7224d413f8ab.png" alt="image" loading="lazy"><br><br>parserã§instructionã‚’è§£æã—ã€rootã®åè©ã¨å‹•è©ã®ãƒšã‚¢ã‚’æŠ½å‡ºã—ã¦å¯è¦–åŒ–ã—ãŸä¾‹ã€‚ãŸã ã—ã€æŠ½å‡ºã§ããŸä¾‹ã¯ãŸã‹ã ã‹å…¨ä½“ã®50%ç¨‹åº¦ã§ã‚ã‚Šã€ãã®ä¸­ã§20ã®æœ€ã‚‚commonãªroot vertã¨4ã¤ã®nounã‚’å¯è¦–åŒ–ã—ãŸã€‚ã“ã‚Œã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã®14%ç¨‹åº¦ã—ã‹å¯è¦–åŒ–ã•ã‚Œã¦ã„ãªã„ãŒã€ã“ã‚Œã ã‘ã§ã‚‚éå¸¸ã«å¤šæ§˜ãªinstructionãŒé›†ã¾ã£ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br>ã¾ãŸã€seed indstructionã¨ROUGE-Lã‚’æ¸¬ã£ãŸçµæœã€å¤§åŠã®ãƒ‡ãƒ¼ã‚¿ã¯0.3~0.4ç¨‹åº¦ã§ã‚ã‚Šã€lexicalãªoverlapã¯ã‚ã¾ã‚Šå¤§ãããªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚instructionã®lengthã«ã¤ã„ã¦ã‚‚å¯è¦–åŒ–ã—ãŸçµæœã€å¤šæ§˜ãªé•·ã•ã®instructionãŒåé›†ã§ãã¦ã„ã‚‹ã€‚<br><br><br><br>## Quality<br><br>200ç¨®é¡ã®instructionã‚’æŠ½å‡ºã—ã€ãã®ä¸­ã‹ã‚‰ãã‚Œãã‚Œãƒ©ãƒ³ãƒ€ãƒ ã§1ã¤ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã‚µãƒ³ãƒ—ãƒ«ã—ãŸã€‚ãã—ã¦expert annotatorã«å¯¾ã—ã¦ã€ãã‚Œãã‚Œã®instructionã¨instanceï¼ˆinput, outputãã‚Œãã‚Œã«ã¤ã„ã¦ï¼‰ãŒæ­£ã—ã„ã‹å¦ã‹ã‚’ãƒ©ãƒ™ãƒ«ä»˜ã‘ã—ã¦ã‚‚ã‚‰ã£ãŸã€‚<br><br>ãƒ©ãƒ™ãƒ«ä»˜ã‘ã®çµæœã€ã»ã¨ã‚“ã©ã®instructionã¯æ„å‘³ã®ã‚ã‚‹instructionã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ä¸€æ–¹ã€ç”Ÿæˆã•ã‚ŒãŸinstanceã¯noisyã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸï¼ˆãŸã ã—ã€ã“ã®noiseã¯ã‚ã‚‹ç¨‹åº¦å¦¥å½“ãªç¯„å›²ã§ã‚ã‚‹ï¼‰ã€‚noisytã§ã¯ã‚ã‚‹ã®ã ãŒã€instanceã‚’è¦‹ã‚‹ã¨ã€æ­£ã—ã„formatã§ã‚ã£ãŸã‚Šã€éƒ¨åˆ†çš„ã«æ­£ã—ã‹ã£ãŸã‚Šãªã©ã€modelã‚’è¨“ç·´ã™ã‚‹ä¸Šã§æœ‰ç”¨ãªguidanceã‚’æä¾›ã™ã‚‹ã‚‚ã®ã«ãªã£ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/228746299-a0ffc115-3861-458b-a7b4-3a91ac94f8f5.png" alt="image" loading="lazy"><br><br><br><br># Experimental Results<br><br>## Zero-shotã§ã®NLPã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ€§èƒ½<br><br>SuperNIãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å«ã¾ã‚Œã‚‹119ã®ã‚¿ã‚¹ã‚¯ï¼ˆ1ã‚¿ã‚¹ã‚¯ã‚ãŸã‚Š100 instanceï¼‰ã«å¯¾ã—ã¦ã€zero-shot setupã§è©•ä¾¡ã‚’è¡Œãªã£ãŸã€‚SELF-INSTRUCTã«ã‚ˆã£ã¦ã€Vanillaã®GPT3ã‹ã‚‰å¤§å¹…ã«æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚Vanillaã®GPT-3ã¯ã»ã¨ã‚“ã©äººé–“ã®instructionã«å¿œã˜ã¦å‹•ã„ã¦ãã‚Œãªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚åˆ†æã«ã‚ˆã‚‹ã¨ã€GPT3ã¯ã€å¤§æŠµã®å ´åˆã€å…¨ãé–¢ä¿‚ãªã„ã€ã‚ã‚‹ã„ã¯ç¹°ã‚Šè¿”ã—ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¦ã„ãŸã‚Šã€ãã‚‚ãã‚‚ã„ã¤ç”Ÿæˆã‚’stopã™ã‚‹ã‹ãŒã‚ã‹ã£ã¦ã„ãªã„ã“ã¨ãŒã‚ã‹ã£ãŸã€‚<br><br><br><br>ã¾ãŸã€SuperNIå‘ã‘ã«finetuningã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«é–“ã§æ¯”è¼ƒã—ãŸçµæœã€éå¸¸ã«ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ã‚¹ãƒˆã‚’ã‹ã‘ã¦ä½œã‚‰ã‚ŒãŸT0ãƒ‡ãƒ¼ã‚¿ã§finetuningã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã—ãŸã€‚ã¾ãŸã€äººé–“ãŒãƒ©ãƒ™ãƒ«ä»˜ã—ãŸprivateãªãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã£ã¦è¨“ç·´ã•ã‚ŒãŸInstructGPT001ã«ã‚‚æ€§èƒ½ãŒè‚‰è–„ã—ã¦ã„ã‚‹ã“ã¨ã‚‚ç‰¹ç­†ã™ã¹ãç‚¹ã§ã‚ã‚‹ã€‚<br><br><br><br>SuperNIã§finetuningã—ãŸå ´åˆã«ã¤ã„ã¦ã¯ã€SELF-INSTRUCTã‚’ä½¿ã£ãŸãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€ã•ã‚‰ã«è¿½åŠ ã§SuperNIã‚’ä¸ãˆãŸå ´åˆãŒæœ€ã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/228751534-095578e0-550b-4e4c-9418-c74251e31d2a.png" alt="image" loading="lazy"><br><br><br><br>## User-Oriented Instructionsã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½<br><br>SuperNIã«å«ã¾ã‚Œã‚‹NLPã‚¿ã‚¹ã‚¯ã¯ç ”ç©¶ç›®çš„ã§ææ¡ˆã•ã‚Œã¦ãŠã‚Šåˆ†é¡å•é¡Œã¨ãªã£ã¦ã„ã‚‹ã€‚ã®ã§ã€å®Ÿè·µçš„ãªèƒ½åŠ›ã‚’è¨¼æ˜ã™ã‚‹ãŸã‚ã«ã€LLMãŒå½¹ç«‹ã¤ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ãƒ–ãƒ¬ã‚¹ãƒˆï¼ˆemail writing, social media, productiveity tools, entertainment, programmingç­‰ï¼‰ã—ã€ãã‚Œãã‚Œã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«å¯¾ã—ã¦ã€instructionã¨input-output instanceã‚’ä½œæˆã—ãŸã€‚ã¾ãŸã€instructionã®ã‚¹ã‚¿ã‚¤ãƒ«ã«ã‚‚å¤šæ§˜æ€§ï¼ˆe.g. instructionãŒlong/shortã€bullet points, table, codes, equationsã‚’input/outputã¨ã—ã¦æŒã¤ã€ãªã©ï¼‰ã‚’æŒãŸã›ãŸã€‚ä½œæˆã—ãŸçµæœã€252å€‹ã®instructionã«å¯¾ã—ã¦ã€1ã¤ã®instanceã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒä½œæˆã•ã‚ŒãŸã€‚ã“ã‚Œã‚‰ãŒã€ãƒ¢ãƒ‡ãƒ«ã«ã¨ã£ã¦unfamiliarãªinstructionã§å¤šæ§˜ãªistructionãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ã©ã‚Œã ã‘ãƒ¢ãƒ‡ãƒ«ãŒãã‚Œã‚‰ã‚’handleã§ãã‚‹ã‹ã‚’æ¸¬å®šã™ã‚‹ãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã«ãªã‚‹ã¨è€ƒãˆã¦ã„ã‚‹ã€‚<br><br><br><br>ã“ã‚Œã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã¯ã€å¤šæ§˜ã ãŒã©ã‚Œã‚‚ãŒå°‚é–€æ€§ã‚’æ±‚ã‚ã‚‰ã‚Œã‚‹ã‚‚ã®ã§ã‚ã‚Šã€è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ã§æ€§èƒ½ãŒæ¸¬å®šã§ãã‚‹ã‚‚ã®ã§ã‚‚ãªã„ã—ã€crowdworkerãŒè‰¯ã—æ‚ªã—ã‚’åˆ¤å®šã§ãã‚‹ã‚‚ã®ã§ã‚‚ãªã„ã€‚ã“ã®ãŸã‚ã€ãã‚Œãã‚Œã®instructionã«å¯¾ã™ã‚‹authorã«å¯¾ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®yè£œè¶³çµæœãŒå¦¥å½“ã‹å¦ã‹ã‚’judgeã—ã¦ã‚‚ã‚‰ã£ãŸã€‚judgeã¯4-scaleã§ã®ratingã¨ãªã£ã¦ã„ã‚‹ï¼š<br><br><br><br>- RATING-A: å¿œç­”ã¯å¦¥å½“ã§æº€è¶³ã§ãã‚‹<br><br>- RATING-B: å¿œç­”ã¯è¨±å®¹ã§ãã‚‹ãŒã€æ”¹å–„ã§ãã‚‹minor errorã‚„ä¸å®Œå…¨ã•ãŒã‚ã‚‹ã€‚<br><br>- RATING-C: å¿œç­”ã¯relevantã§instructionã«å¯¾ã—ã¦ç­”ãˆã¦ã„ã‚‹ã€‚ãŒã€å†…å®¹ã«å¤§ããªã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹ã€‚<br><br>- RATING-D: å¿œç­”ã¯irrelevantã§å¦¥å½“ã§ã¯ãªã„ã€‚<br><br><br><br>å®Ÿé¨“çµæœã‚’ã¿ã‚‹ã¨ã€Vanilla GPT3ã¯ã¾ã£ãŸãinstructionã«å¯¾ã—ã¦ç­”ãˆã‚‰ã‚Œã¦ã„ãªã„ã€‚instruction-basedãªãƒ¢ãƒ‡ãƒ«ã¯é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¦ã„ã‚‹ãŒã€ãã‚Œã‚‰ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’SELF-INSTRUCTã¯ç™ºæ®ã—ã¦ã„ã‚‹ï¼ˆnoisyã§ã‚ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšï¼‰ã€‚<br><br>ã¾ãŸã€GPT_SELF-INSTRUCTã¯InstructGPT001ã¨æ€§èƒ½ãŒè‚‰è–„ã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€InstructGPT002, 003ã®ç´ æ™´ã‚‰ã—ã„æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ã«ã‚‚ãªã£ãŸã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/228755556-1c604ed8-11a5-4237-8f9c-a30960db807a.png" alt="image" loading="lazy"><br><br><br><br># Discussion and Limitation<br><br>## ãªãœSELF-INSTRUCTãŒã†ã¾ãã„ã£ãŸã‹ï¼Ÿ<br><br>- LMã«å¯¾ã™ã‚‹2ã¤ã®æ¥µç«¯ãªä»®èª¬ã‚’æŒ™ã’ã¦ã„ã‚‹<br><br>  - LM ã¯pre-trainingã§ã¯ååˆ†ã«å­¦ç¿’ã•ã‚Œãªã‹ã£ãŸå•é¡Œã«ã¤ã„ã¦å­¦ç¿’ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€human feedbackã¯instruction-tuningã«ãŠã„ã¦å¿…è¦ä¸å¯æ¬ ãªå´é¢ã§ã‚ã‚‹<br><br>  - LM ã¯pre-trainingã‹ã‚‰instructionã«æ—¢ã«ç²¾é€šã—ã¦ã„ã‚‹ãŸã‚ã€human feedbackã¯instruction-tuningã«ãŠã„ã¦å¿…é ˆã§ã¯ãªã„ã€‚ human feedbackã‚’è¦³å¯Ÿã™ã‚‹ã“ã¨ã¯ã€pre-trainingã«ãŠã‘ã‚‹åˆ†å¸ƒ/ç›®çš„ã‚’èª¿æ•´ã™ã‚‹ãŸã‚ã®è»½é‡ãªãƒ—ãƒ­ã‚»ã‚¹ã«ã™ããšã€åˆ¥ã®ãƒ—ãƒ­ã‚»ã‚¹ã«ç½®ãæ›ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br><br><br>ã“ã®2ã¤ã®æ¥µç«¯ãªä»®èª¬ã®é–“ãŒå®Ÿæƒ…ã§ã‚ã‚‹ã¨ç­†è€…ã¯è€ƒãˆã¦ã„ã¦ã€ã©ã¡ã‚‰ã‹ã¨ã„ã†ã¨ï¼’ã¤ç›®ã®ä»®èª¬ã«è¿‘ã„ã ã‚ã†ã€ã¨è€ƒãˆã¦ã„ã‚‹ã€‚æ—¢ã«LMã¯pre-trainingã®æ®µéšã§instructionã«ã¤ã„ã¦ã‚ã‚‹ç¨‹åº¦ç†è§£ã§ãã¦ã„ã‚‹ãŸã‚ã€self-instructãŒã†ã¾ãã„ã£ãŸã®ã§ã¯ãªã„ã‹ã¨æ¨å¯Ÿã—ã¦ã„ã‚‹ã€‚<br><br><br><br>## Broader Impact<br><br>InstructGPTã¯éå¸¸ã«å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã ã‘ã©è©³ç´°ãŒå…¬è¡¨ã•ã‚Œã¦ãŠã‚‰ãšã€APIã®è£å´ã«éš ã‚Œã¦ã„ã‚‹ã€‚ã“ã®ç ”ç©¶ãŒã€instruct-tuned modelã®èƒŒå¾Œã§ä½•ãŒèµ·ãã¦ã„ã‚‹ã‹ã«ã¤ã„ã¦ã€é€æ˜æ€§ã‚’é«˜ã‚ã‚‹åŠ©ã‘ã«ãªã‚‹ã¨è€ƒãˆã¦ã„ã‚‹ã€‚ç”£æ¥­ã§é–‹ç™ºã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®æ§‹é€ ã‚„ã€ãã®å„ªã‚ŒãŸæ€§èƒ½ã®ç†ç”±ã«ã¤ã„ã¦ã¯ã»ã¨ã‚“ã©ç†è§£ã•ã‚Œã¦ãŠã‚‰ãšã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã®æˆåŠŸã®æºæ³‰ã‚’ç†è§£ã—ã€ã‚ˆã‚Šå„ªã‚ŒãŸã€ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ã®ã¯ã‚¢ã‚«ãƒ‡ãƒŸãƒƒã‚¯ã«ã‹ã‹ã£ã¦ã„ã‚‹ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€å¤šæ§˜ãªinstructional dataã®é‡è¦æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹ã¨è€ƒãˆã¦ãŠã‚Šã€å¤§è¦æ¨¡ãªäººå·¥çš„ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€ã‚ˆã‚Šå„ªã‚ŒãŸinstructionã«å¾“ã†ãƒ¢ãƒ‡ãƒ«ã‚’ã€æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ç¬¬ä¸€æ­©ã ã¨è€ƒãˆã¦ã„ã‚‹ã€‚<br><br><br><br>## limitation<br><br>- Tail Phenomena<br><br>  - LMã®æ çµ„ã¿ã«ã¨ã©ã¾ã£ã¦ã„ã‚‹ãŸã‚ã€LMã¨åŒã˜å•é¡Œï¼ˆTail Phenomenaï¼‰ã‚’æŠ±ãˆã¦ã„ã‚‹<br><br>  - low-frequencyãªcontextã«å¯¾ã—ã¦ã¯ã†ã¾ãã„ã‹ãªã„å•é¡Œ<br><br>  - SELF-INSTRUCTã‚‚ã€çµå±€pre-trainingã®æ®µéšã§é »å‡ºã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚„instructionã«å¯¾ã—ã¦gainãŒã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã€ä¸€èˆ¬çš„ã§ãªãã€creativeãªinstructionã«å¯¾ã—ã¦è„†å¼±æ€§ãŒã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹<br><br>- Dependence on laege models<br><br>  - ã§ã‹ã„ãƒ¢ãƒ‡ãƒ«ã‚’æ‰±ãˆã‚‹ã ã‘ã®resourceã‚’æŒã£ã¦ã„ãªã„ã¨ä½¿ãˆãªã„ã¨ã„ã†å•é¡ŒãŒã‚ã‚‹<br><br>- Reinforcing LM biases<br><br>  - ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®iterationã«ã‚ˆã£ã¦ã€å•é¡Œã®ã‚ã‚‹social _biasã‚’ã‚ˆã‚Šå¢—å¹…ã—ã¦ã—ã¾ã†ã“ã¨ã‚’æ‡¸å¿µã—ã¦ã„ã‚‹ï¼ˆäººç¨®ã€ç¨®æ—ãªã©ã«å¯¾ã™ã‚‹åè¦‹ãªã©ï¼‰ã€‚ã¾ãŸã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒé›£ã—ã„ã€‚</p>
<p>1ã®prompt<br><br>&lt;img width="801" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/228717376-62648df4-e587-49f7-8e71-afd1b2269e90.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/228717376-62648df4-e587-49f7-8e71-afd1b2269e90.png"&lt;/a&gt;


&gt;<br><br>2ã®prompt<br><br>&lt;img width="871" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/228717413-115f8ccf-b85e-4530-b489-cbf1de69341b.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/228717413-115f8ccf-b85e-4530-b489-cbf1de69341b.png"&lt;/a&gt;


&gt;<br><br>3ã®promptï¼ˆinput-first-approachï¼‰<br><br>&lt;img width="853" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/228717477-58b44a4e-ce44-452f-9b3a-4a348584e40f.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/228717477-58b44a4e-ce44-452f-9b3a-4a348584e40f.png"&lt;/a&gt;


&gt;<br><br>3ã®promptï¼ˆoutput-first approachï¼‰<br><br>&lt;img width="803" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/228717535-8717405c-bdaf-455c-9d4b-480bf6494abe.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/228717535-8717405c-bdaf-455c-9d4b-480bf6494abe.png"&lt;/a&gt;


&gt;</p>
<p>â€» GPT3ã‚’finetuningã™ã‚‹ã®ã«ã€Instruction Dataã‚’ä½¿ã£ãŸå ´åˆ$338ã‹ã‹ã£ãŸã£ã½ã„ã€‚å®‰ã„ãƒ»ãƒ»ãƒ»ã€‚</p>
<p>LLMã‚’ä½¿ã†ã ã‘ã§ã“ã“ã¾ã§ç ”ç©¶ãŒã§ãã‚‹æ™‚ä»£ãŒããŸ</p>
<p>ï¼ˆæœ€è¿‘ã¯|ç¾åœ¨ã¯ï¼‰ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãªLLMã®å‡ºåŠ›ã‚’åˆ©ç”¨ã—ã¦ç«¶åˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã“ã¨ã¯å¤šãã®å ´åˆç¦æ­¢ã•ã‚Œã¦ã„ã‚‹ã®ã§æ³¨æ„ã€‚</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-03-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/512" target="_blank" rel="noopener noreferrer" class="title-link">Reflexion: Language Agents with Verbal Reinforcement Learning, Noah Shinn+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹Reflexionã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚Reflexionã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€è¨€èªçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€šã˜ã¦è‡ªå·±åçœã—ã€ã‚ˆã‚Šè‰¯ã„æ„æ€æ±ºå®šã‚’ä¿ƒã™ãŸã‚ã«åçœçš„ãªãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿æŒã—ã¾ã™ã€‚Reflexionã¯ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«æ¯”ã¹ã¦å¤§å¹…ãªæ”¹å–„ã‚’å®Ÿç¾ã—ã€å¾“æ¥ã®æœ€å…ˆç«¯ã®GPT-4ã‚’ä¸Šå›ã‚‹ç²¾åº¦ã‚’é”æˆã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ç•°ãªã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¿¡å·ã‚„çµ±åˆæ–¹æ³•ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®ç ”ç©¶ã‚’è¡Œã„ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¸ã®å½±éŸ¿ã«ã¤ã„ã¦ã®æ´å¯Ÿã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãªãœå›ç­”ã‚’é–“é•ãˆãŸã®ã‹è‡ªå·±åçœã•ã›ã‚‹ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/PseudoLabeling.html" target="_blank" rel="noopener noreferrer">#PseudoLabeling</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2903" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Constitutional AI: Harmlessness from AI Feedback, Yuntao Bai+, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã€Œæ†²æ³•çš„AIã€ã‚’ç”¨ã„ã¦ã€äººé–“ã®ãƒ©ãƒ™ãƒ«ãªã—ã§ç„¡å®³ãªAIã‚’è¨“ç·´ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚ç›£è¦–å­¦ç¿’ã¨å¼·åŒ–å­¦ç¿’ã®2ãƒ•ã‚§ãƒ¼ã‚ºã‚’çµŒã¦ã€è‡ªå·±æ‰¹è©•ã¨ä¿®æ­£ã‚’é€šã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã€å—œå¥½ãƒ¢ãƒ‡ãƒ«ã‚’å ±é…¬ä¿¡å·ã¨ã—ã¦å¼·åŒ–å­¦ç¿’ã‚’è¡Œã†ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æœ‰å®³ãªã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ã‚‚å¯¾è©±ã§ãã‚‹ç„¡å®³ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’å®Ÿç¾ã—ã€AIã®æ„æ€æ±ºå®šã®é€æ˜æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ï¼ˆéƒ¨åˆ†çš„ã«ã—ã‹èª­ã‚ã¦ã„ãªã„ãŒï¼‰<br>æœ‰å®³ãªpromptã«å¯¾ã—ã¦LLMã«åˆæœŸã®å¿œç­”ã‚’ç”Ÿæˆã•ã›ã€iterativeã«critiqueã¨revisionã‚’ç¹°ã‚Šè¿”ã—ã¦[^1]ã€ã‚ˆã‚Šç„¡å®³ãªå¿œç­”ã‚’ç”Ÿæˆã€‚ã“ã®æ–¹æ³•ã§ã¯iterationã‚’ã—ãªãŒã‚‰ç”ŸæˆçµæœãŒæ”¹å®šã•ã‚Œã¦ã„ãã®ã§ã€å¾Œæ®µã®Reward Modelã®ãŸã‚ã®å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ãƒ•ã‚§ãƒ¼ã‚ºã§ãƒˆãƒ¼ã‚¯ãƒ³é‡ã‚’ç¯€ç´„ã™ã‚‹ãŸã‚ã«ã€ç”Ÿæˆã•ã‚ŒãŸã‚ˆã‚Šç„¡å®³ãªå¿œç­”ã¨å…ƒã¨ãªã‚‹promptã‚’ç”¨ã„ã¦ã€ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’SFTã€‚ã“ã‚Œã«ã‚ˆã‚Šãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›åˆ†å¸ƒãŒã‚ˆã‚Šç„¡å®³ãªå¿œç­”ã‚’ã™ã‚‹ã‚ˆã†ãªæ–¹å‘æ€§ã«èª¿æ•´ã•ã‚Œã€ã‹ã¤ï¼ˆiterationã‚’ç¹°ã‚Šè¿”ã™ã“ã¨ãªãï¼‰ç›´æ¥çš„ã«ã‚ˆã‚Šç„¡å®³ãªå¿œç­”ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã®ã§tokené‡ãŒç¯€ç´„ã§ãã‚‹ã€‚ã“ã®ãƒ•ã‚§ãƒ¼ã‚ºã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’SL-CAIã¨å‘¼ã¶ã€‚<br><br>ç¶šã„ã¦ã€SL-CAIã«å¯¾ã—ã¦åŒæ§˜ã®æœ‰å®³ãªpromptã‚’å…¥åŠ›ã—ã¦ã€è¤‡æ•°ã®å¿œç­”ã‚’ç”Ÿæˆã•ã›ã‚‹ã€‚ç”Ÿæˆã•ã‚ŒãŸå¿œç­”ã‚’Multiple Choice Questionã®å½¢å¼ã«ã—ã€Constitutional Principleã«åŸºã¥ãpromptingã«ã‚ˆã‚Šã€æœ€ã‚‚æœ›ã¾ã—ã„å¿œç­”ã‚’LLMã«ã‚ˆã£ã¦é¸æŠã•ã›ã‚‹ã“ã¨ã§ã€å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚’ç²å¾—ã™ã‚‹ã€‚ã“ã®å—œå¥½ãƒ‡ãƒ¼ã‚¿ï¼ˆã¨äººæ‰‹ã§å®šç¾©ã•ã‚ŒãŸhelpfulnessã«åŸºã¥ããƒ‡ãƒ¼ã‚¿ï¼‰ã‚’ç”¨ã„ã¦Reward Modelã‚’è¨“ç·´ã—RLã‚’å®Ÿæ–½ã™ã‚‹ã€‚<br><br>ã“ã®æ‰‹æ³•ã¯ã€å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚’äººé–“ãŒãƒ©ãƒ™ãƒªãƒ³ã‚°ã™ã‚‹ã®ã§ã¯ãªãã€AIã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ã‚ˆã‚Šãƒ©ãƒ™ãƒªãƒ³ã‚°ã™ã‚‹ãŸã‚ã€Reinforcement Learning from AI Feedback (RLAIF)ã¨å‘¼ã°ã‚Œã‚‹ã€‚<br><br>Harmfulnessä»¥å¤–ã®åˆ†é‡ã«ã‚‚å¿œç”¨å¯èƒ½ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/72305618-d397-4471-8648-7771d371ca43" alt="image" loading="lazy"><br><br>[^1]: ã“ã®æ“ä½œã¯ãƒ¢ãƒ‡ãƒ«ã®æœ›ã¾ã—ã„æŒ™å‹•ã‚’äººæ‰‹ã§å®šç¾©ã—ãŸãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã«åŸºã¥ã„ãŸè¤‡æ•°ã®prompt (Constitutional Principles) ã‚’ç”¨ã„ã¦å®Ÿæ–½ã•ã‚Œã‚‹ã€‚å…·ä½“çš„ãªpromptã¯Appendix Cã‚’å‚ç…§ã€‚</p>
<p>å…ˆè¡Œç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2902" target="_blank" rel="noopener noreferrer">[Paper Note] Training a Helpful and Harmless Assistant with Reinforcement Learning
  from Human Feedback, Yuntao Bai+, arXiv'22</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2902" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Training a Helpful and Harmless Assistant with Reinforcement Learning  from Human Feedback, Yuntao Bai+, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç„¡å®³ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã—ã¦æ©Ÿèƒ½ã•ã›ã‚‹ãŸã‚ã«ã€å¥½ã¿ã®ãƒ¢ãƒ‡ãƒ«åŒ–ã¨äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‹ã‚‰ã®å¼·åŒ–å­¦ç¿’ï¼ˆRLHFï¼‰ã‚’ç”¨ã„ã¦å¾®èª¿æ•´ã‚’è¡Œã„ã€NLPè©•ä¾¡ã§ã®æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã€‚æ¯é€±æ–°ã—ã„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°ã—ã€åŠ¹ç‡çš„ãªæ”¹å–„ã‚’å›³ã‚‹ã€‚RLHFãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å …ç‰¢æ€§ã‚’èª¿æŸ»ã—ã€ãƒãƒªã‚·ãƒ¼ã¨åˆæœŸåŒ–ã¨ã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã®é–¢ä¿‚ã‚’ç‰¹å®šã€‚ãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ç«¶åˆç›®çš„ã«ã¤ã„ã¦ã‚‚åˆ†æã—ã€äººé–“ã®ä½œå®¶ã¨ã®æ¯”è¼ƒã‚’è¡Œã£ãŸã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2860" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Emergent Abilities of Large Language Models, Jason Wei+, TMLR'22</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚¢ãƒƒãƒ—ã¯æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ã€Œå‡ºç¾èƒ½åŠ›ã€ã¨å‘¼ã°ã‚Œã‚‹äºˆæ¸¬ä¸å¯èƒ½ãªç¾è±¡ãŒå­˜åœ¨ã™ã‚‹ã€‚ã“ã‚Œã¯å°å‹ãƒ¢ãƒ‡ãƒ«ã«ã¯ãªã„èƒ½åŠ›ã§ã‚ã‚Šã€ã•ã‚‰ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’æ‹¡å¤§ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=yzkSU5zdwD" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=yzkSU5zdwD</a>


</p>
<p>å‰µç™ºèƒ½åŠ›ï¼ˆæœ€è¿‘ã“ã®ç”¨èªã‚’ç›®ã«ã™ã‚‹æ©Ÿä¼šãŒæ¸›ã£ãŸã‚ˆã†ãªæ°—ãŒã™ã‚‹ï¼‰</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Deduplication.html" target="_blank" rel="noopener noreferrer">#Deduplication</a>
<span class="issue_date">Issue Date: 2025-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2689" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deduplicating Training Data Makes Language Models Better, Katherine Lee+, ACL'22</a>
<span class="snippet"><span>GPT Summary</span>- æ—¢å­˜ã®è¨€èªãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯é‡è¤‡ã—ãŸä¾‹ãŒå¤šãå«ã¾ã‚Œã€è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã®1%ä»¥ä¸ŠãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚³ãƒ”ãƒ¼ã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€é‡è¤‡æ’é™¤ãƒ„ãƒ¼ãƒ«ã‚’é–‹ç™ºã—ã€C4ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ã¯60,000å›ä»¥ä¸Šç¹°ã‚Šè¿”ã•ã‚Œã‚‹æ–‡ã‚’å‰Šé™¤ã€‚é‡è¤‡ã‚’æ’é™¤ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®è¨˜æ†¶ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ã‚’10å€æ¸›å°‘ã•ã›ã€ç²¾åº¦ã‚’ç¶­æŒã—ã¤ã¤è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—ã‚’å‰Šæ¸›ã€‚ã¾ãŸã€è¨“ç·´ã¨ãƒ†ã‚¹ãƒˆã®é‡è¤‡ã‚’æ¸›ã‚‰ã—ã€ã‚ˆã‚Šæ­£ç¢ºãªè©•ä¾¡ã‚’å®Ÿç¾ã€‚ç ”ç©¶ã®å†ç¾ã¨ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä¸‹è¨˜ã‚¹ãƒ©ã‚¤ãƒ‰ã®p.9ã«ã¾ã¨ã‚ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹:<br>


<a href="https://speakerdeck.com/takase/snlp2023-beyond-neural-scaling-laws?slide=9" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/takase/snlp2023-beyond-neural-scaling-laws?slide=9</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-09-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2644" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] StableMoE: Stable Routing Strategy for Mixture of Experts, Damai Dai+, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- StableMoEã¯ã€ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®å¤‰å‹•å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«2ã¤ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’æŒã¤Mixture-of-Expertsæ‰‹æ³•ã‚’ææ¡ˆã€‚æœ€åˆã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§ä¸€è²«ã—ãŸãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ã‚’å­¦ç¿’ã—ã€è»½é‡ãƒ«ãƒ¼ã‚¿ãƒ¼ã«è’¸ç•™ã€‚ç¬¬äºŒã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§ãã®ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚’ç”¨ã„ã¦ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã¸ã®å‰²ã‚Šå½“ã¦ã‚’å›ºå®šã€‚è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã¨å¤šè¨€èªæ©Ÿæ¢°ç¿»è¨³ã§ã®å®Ÿé¨“ã«ã‚ˆã‚Šã€StableMoEã¯åæŸé€Ÿåº¦ã¨æ€§èƒ½ã§æ—¢å­˜æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vikhyatk/status/1962225296314429543?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2055" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Fast Model Editing at Scale, Eric Mitchell+, ICLR'22</a>
<span class="snippet"><span>GPT Summary</span>- MENDï¼ˆãƒ¢ãƒ‡ãƒ«ç·¨é›†ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã¯ã€äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œã‚’è¿…é€Ÿã‹ã¤å±€æ‰€çš„ã«ç·¨é›†ã™ã‚‹ãŸã‚ã®æ‰‹æ³•ã§ã€å˜ä¸€ã®å…¥åŠ›-å‡ºåŠ›ãƒšã‚¢ã‚’ç”¨ã„ã¦å‹¾é…åˆ†è§£ã‚’æ´»ç”¨ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€10å„„ä»¥ä¸Šã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã€1å°ã®GPUã§çŸ­æ™‚é–“ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¯èƒ½ã§ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€MENDãŒå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®ç·¨é›†ã«ãŠã„ã¦åŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=0DcZxeWfOPt" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=0DcZxeWfOPt</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1956" target="_blank" rel="noopener noreferrer" class="title-link">LoRA: Low-Rank Adaptation of Large Language Models, Edward J. Hu+, ICLR'22</a>
<span class="snippet"><span>GPT Summary</span>- LoRAã¯ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’å›ºå®šã—ã€å„å±¤ã«è¨“ç·´å¯èƒ½ãªãƒ©ãƒ³ã‚¯åˆ†è§£è¡Œåˆ—ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«å¿…è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤§å¹…ã«å‰Šæ¸›ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¨“ç·´å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’1ä¸‡åˆ†ã®1ã€GPUãƒ¡ãƒ¢ãƒªã‚’3åˆ†ã®1ã«æ¸›å°‘ã•ã›ãªãŒã‚‰ã€RoBERTaã‚„GPT-3ãªã©ã§åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’å®Ÿç¾ã—ã¾ã™ã€‚LoRAã®å®Ÿè£…ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenrReview:


<a href="https://openreview.net/forum?id=nZeVKeeFYf9" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=nZeVKeeFYf9</a>


</p>
<p>LoRAã‚‚ãªã‚“ã‚„ã‹ã‚“ã‚„ãƒ¡ãƒ¢ã£ã¦ãªã‹ã£ãŸã®ã§è¿½åŠ ã€‚<br><br>äº‹å‰å­¦ç¿’æ¸ˆã¿ã®Linear Layerã‚’freezeã—ã¦ã€freezeã—ãŸLinear Layerã¨å¯¾å¿œã™ã‚‹ä½ãƒ©ãƒ³ã‚¯ã®è¡Œåˆ—A,Bã‚’åˆ¥é€”å®šç¾©ã—ã€A,Bã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹PEFTæ‰‹æ³•ã§ã‚ã‚‹LoRAã‚’ææ¡ˆã—ãŸç ”ç©¶ã€‚ã‚ªãƒªã‚¸ãƒŠãƒ«ã®å‡ºåŠ›ã«å¯¾ã—ã¦ã€A,Bã«ã‚ˆã£ã¦å…¥åŠ›ã‚’å†™åƒã—ãŸãƒ™ã‚¯ãƒˆãƒ«ã‚’åŠ ç®—ã™ã‚‹ã€‚<br><br>ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°å­¦ã¯ã‚‹ã‹ã«å°‘ãªã„ã«ã‚‚é–¢ã‚ã‚‰ãšãƒ•ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ï¼ˆã“ã‚Œã¯è«¸èª¬ã‚ã‚‹ãŒï¼‰åŒç­‰ã®æ€§èƒ½ã§PostTrainingã§ãã‚‹ä¸Šã«ã€äº‹å‰å­¦ç¿’æ™‚ç‚¹ã§ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒfreezeã•ã‚Œã¦ã„ã‚‹ãŸã‚Catastrophic ForgettingãŒèµ·ãã¥ã‚‰ãï¼ˆãŸã ã—æ–°ã—ã„çŸ¥è­˜ã‚‚ç²å¾—ã—ã¥ã‚‰ã„ï¼‰ã€A,Bã®è¿½åŠ ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’ä¿å­˜ã™ã‚Œã°è‰¯ã„ã®ã§ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«å„ªã—ã„ã®ã‚‚å¬‰ã—ã„ã€‚</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2929" target="_blank" rel="noopener noreferrer">[Paper Note] LoRA-Pro: Are Low-Rank Adapters Properly Optimized?, Zhengbo Wang+, ICLR'25, 2024.07</a>
<br><br>ãªã©ã§ã‚‚ç¤ºã•ã‚Œã¦ã„ã‚‹ãŒã€ä¸€èˆ¬çš„ã«LoRAã¨Full Finetuningã‚’æ¯”è¼ƒã™ã‚‹ã¨LoRAã®æ–¹ãŒæ€§èƒ½ãŒä½ã„ã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ç‚¹ã«ã¯ç•™æ„ãŒå¿…è¦ã€‚</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1827" target="_blank" rel="noopener noreferrer" class="title-link">Training Compute-Optimal Large Language Models, Jordan Hoffmann+, NeurIPS'22</a>
<span class="snippet"><span>GPT Summary</span>- ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼è¨€èªãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«ãŠã„ã¦ã€è¨ˆç®—äºˆç®—å†…ã§æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’èª¿æŸ»ã€‚ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨è¨“ç·´ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¯åŒç­‰ã«ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€å€å¢—ã™ã‚‹ã”ã¨ã«ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚‚å€å¢—ã™ã¹ãã¨ææ¡ˆã€‚Chinchillaãƒ¢ãƒ‡ãƒ«ã¯ã€Gopherãªã©ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®è¨ˆç®—é‡ã‚’å‰Šæ¸›ã€‚MMLUãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§67.5%ã®ç²¾åº¦ã‚’é”æˆã—ã€Gopherã«å¯¾ã—ã¦7%ä»¥ä¸Šã®æ”¹å–„ã‚’å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview: 


<a href="https://openreview.net/forum?id=iBBcRUlOAPR" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=iBBcRUlOAPR</a>


</p>
<p>chinchillaå‰‡</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2024-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1474" target="_blank" rel="noopener noreferrer" class="title-link">Super-NaturalInstructions: Generalization via Declarative Instructions  on 1600+ NLP Tasks, Yizhong Wang+, N_A, EMNLP'22</a>
<span class="snippet"><span>GPT Summary</span>- Super-NaturalInstructionsã‚’ç”¨ã„ã¦ã€NLPãƒ¢ãƒ‡ãƒ«ã®æœªè¦‹ã‚¿ã‚¹ã‚¯ã¸ã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’è©•ä¾¡ã€‚1,616ã®å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã¨æŒ‡ç¤ºã‚’å«ã‚€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä½œæˆã—ã€76ç¨®é¡ã®ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã‚’ã‚«ãƒãƒ¼ã€‚Tk-Instructãƒ¢ãƒ‡ãƒ«ã¯ã€æŒ‡ç¤ºã«å¾“ã†è¨“ç·´ã‚’å—ã‘ã€InstructGPTã‚’9%ä»¥ä¸Šä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦åˆ†æã—ã€æ±ç”¨çš„ãªNLPãƒ¢ãƒ‡ãƒ«ã®é€²å±•ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>7.1, 7.2ãŒæœ€ã‚‚èˆˆå‘³æ·±ã„<br><br><br><br>## Instruction Tuningã«ãŠã‘ã‚‹æœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã«ã¤ã„ã¦ã€3ã¤ã®è¦ç´ ã«å¯¾ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã¤ã„ã¦è€ƒå¯Ÿ<br><br>- More observed tasks improve the generalization.<br><br>- A large number of training instances do not help generalization.<br><br>- Tuning larger models with instructions consistently lead to gains.<br><br><br><br>## Instructionã‚’ã•ã¾ã–ã¾ã«å¤‰åŒ–ã•ã›ãŸæ™‚ã®æ€§èƒ½ã®å¤‰åŒ–ã«å¯¾ã™ã‚‹åˆ†æ<br><br>Table4ã®å¯¾è§’æˆåˆ†ã«æ³¨ç›®ã™ã‚‹ã¨ï¼ˆtrainã¨testã®input encodingã‚’æƒãˆãŸå ´åˆï¼‰<br><br>- Task definitionã‚’instructionã«å«ã‚ã‚‹ã“ã¨ã§æœªçŸ¥ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½å‘ä¸Š<br><br>- Task Definitionã¨positive examplesã‚’4ã¤ç¨‹åº¦å…¥ã‚Œã‚‹ã¨æ±åŒ–æ€§èƒ½å‘ä¸Šã€‚<br><br>  - ãŸã ã—ã€ã“ã‚Œä»¥ä¸Šexampleã‚’å¢—ã‚„ã™ã¨æ€§èƒ½ä½ä¸‹ã€‚<br><br>  - negative examplesã‚’å…¥ã‚Œã‚‹ã“ã¨ã¯æ€§èƒ½ã« a little bit ã—ã‹è²¢çŒ®ã—ãªã„<br><br>  - explanationsã‚’å…¥ã‚Œã‚‹ã¨æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹<br><br><br><br>Table4ã®éå¯¾è§’æˆåˆ†ã«ç€ç›®ã™ã‚‹ã¨ã€<br><br>- Task Definitionã®ã¿ã§è¨“ç·´ã—ã¦ã‚‚ã€Example onlyã®testæ™‚ã®encodingã«ã¯æ±åŒ–ã—ãªã„ï¼ˆé€†ã‚‚ç„¶ã‚Šï¼‰<br><br>- Task Definition + examples (ä»Šå›ã®å ´åˆã¯positive examples4ã¤)ã¯ã€ã•ã¾ã–ã¾ãªtestæ™‚ã®input encodingsã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆã«ãªã‚‹<br><br> <br><br><img src="https://github.com/user-attachments/assets/3bd1d07d-feb0-4567-bad9-8920c2d82359" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1413" target="_blank" rel="noopener noreferrer" class="title-link">Finetuned Language Models Are Zero-Shot Learners, Jason Wei+, N_A, ICLR'22</a>
<span class="snippet"><span>GPT Summary</span>- æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ç”¨ã„ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚137Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«FLANã¯ã€60ä»¥ä¸Šã®NLPã‚¿ã‚¹ã‚¯ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€æœªè¦‹ã®ã‚¿ã‚¹ã‚¯ã§175B GPT-3ã‚’ä¸Šå›ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã€‚ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¿ãƒ‡ã‚£ã«ã‚ˆã‚Šã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ•°ã‚„ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒ«ãŒæˆåŠŸã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>FLANè«–æ–‡ã€‚Instruction Tuningã‚’ææ¡ˆã—ãŸç ”ç©¶ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<span class="issue_date">Issue Date: 2024-09-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1397" target="_blank" rel="noopener noreferrer" class="title-link">STaR: Bootstrapping Reasoning With Reasoning, Eric Zelikman+, N_A, NeurIPS'22</a>
<span class="snippet"><span>GPT Summary</span>- ã€Œè‡ªå·±å­¦ç¿’æ¨è«–è€…ã€ï¼ˆSTaRï¼‰ã‚’ææ¡ˆã—ã€å°‘æ•°ã®åˆç†çš„èª¬æ˜ã¨å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ´»ç”¨ã—ã¦è¤‡é›‘ãªæ¨è«–ã‚’è¡Œã†ã€‚STaRã¯ã€ç”Ÿæˆã—ãŸå›ç­”ãŒé–“é•ã£ã¦ã„ã‚‹å ´åˆã«æ­£ã—ã„å›ç­”ã‚’ç”¨ã„ã¦å†ç”Ÿæˆã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ç¹°ã‚Šè¿”ã™ã“ã¨ã§æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€STaRã¯å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦å¤§å¹…ãªæ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ã€ç‰¹ã«CommensenseQAã§ã®æˆæœãŒé¡•è‘—ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenAI o1é–¢é€£ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/PPO%20(ProximalPolicyOptimization).html" target="_blank" rel="noopener noreferrer">#PPO (ProximalPolicyOptimization)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2024-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1296" target="_blank" rel="noopener noreferrer" class="title-link">Training language models to follow instructions with human feedback, Long Ouyang+, N_A, NeurIPS'22</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã«åˆã‚ãªã„å‡ºåŠ›ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦GPT-3ã‚’å¾®èª¿æ•´ã—ã€InstructGPTã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã«ã‚ˆã‚Šã€13å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®InstructGPTãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ãŒ175Bã®GPT-3ã®å‡ºåŠ›ã‚ˆã‚Šã‚‚å¥½ã¾ã‚Œã€çœŸå®Ÿæ€§ã®å‘ä¸Šã¨æœ‰å®³ãªå‡ºåŠ›ã®å‰Šæ¸›ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ä¸€èˆ¬çš„ãªNLPãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãŠã‘ã‚‹æ€§èƒ½ã®ä½ä¸‹ã¯æœ€å°é™ã§ã—ãŸã€‚InstructGPTã¯ã¾ã æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ãŒã€äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ãŸå¾®èª¿æ•´ãŒæœ‰æœ›ãªæ–¹å‘ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ChatGPTã®å…ƒã¨ãªã‚‹ã€SFTâ†’Reward Modelã®è¨“ç·´â†’RLHFã®æµã‚ŒãŒææ¡ˆã•ã‚ŒãŸç ”ç©¶ã€‚Demonstrationãƒ‡ãƒ¼ã‚¿ã ã‘ã§SFTã™ã‚‹ã ã‘ã§ã¯ã€äººé–“ã®æ„å›³ã—ãŸã¨ãŠã‚Šã«å‹•ä½œã—ãªã„å•é¡ŒãŒã‚ã£ãŸãŸã‚ã€äººé–“ã®æ„å›³ã«Alignã™ã‚‹ã‚ˆã†ã«ã€Reward Modelã‚’ç”¨ã„ãŸRLHFã§SFTã®å¾Œã«è¿½åŠ ã§å­¦ç¿’ã‚’å®Ÿæ–½ã™ã‚‹ã€‚Reward Modelã¯ã€175Bãƒ¢ãƒ‡ãƒ«ã¯å­¦ç¿’ãŒå®‰å®šã—ãªã‹ã£ãŸä¸Šã«ã€PPOã®è¨ˆç®—ã‚³ã‚¹ãƒˆãŒéå¸¸ã«å¤§ãã„ãŸã‚ã€6Bã®GPT-3ã‚’æ§˜ã€…ãªNLPã‚¿ã‚¹ã‚¯ã§SFTã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ã‚¹ã‚¿ãƒ¼ãƒˆã«ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã«å¯¾ã—ã¦äººé–“ãŒãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»˜ã‘ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã®loss functionã§è¨“ç·´ã—ãŸã€‚æœ€çµ‚çš„ã«ã€RMã®ã‚¹ã‚³ã‚¢ãŒæœ€å¤§åŒ–ã•ã‚Œã‚‹ã‚ˆã†ã«SFTã—ãŸGPT-3ã‚’RLHFã§è¨“ç·´ã™ã‚‹ãŒã€ãã®éš›ã«ã€SFTã‹ã‚‰å‡ºåŠ›ãŒé›¢ã‚Œã™ããªã„ã‚ˆã†ã«ã™ã‚‹é …ã¨ã€NLPãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®æ€§èƒ½ãŒåŠ£åŒ–ã—ãªã„ã‚ˆã†ã«pretrainæ™‚ã®ã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ã‚‚loss functionã«åŠ ãˆã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e4934d4c-7a9b-44aa-93ce-3ae46ed4bd9b" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2023-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1124" target="_blank" rel="noopener noreferrer" class="title-link">Recommendation as Language Processing ï¼ˆRLPï¼‰: A Unified Pretrain,  Personalized Prompt &amp; Predict Paradigm ï¼ˆP5ï¼‰, Shijie Geng+, N_A, RecSys'22</a>
<span class="snippet"><span>GPT Summary</span>- æˆ‘ã€…ã¯ã€ŒPretrain, Personalized Prompt, and Predict Paradigmã€ï¼ˆP5ï¼‰ã¨å‘¼ã°ã‚Œã‚‹æŸ”è»Ÿã§çµ±ä¸€ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ææ¡ˆã—ã¾ã™ã€‚P5ã¯ã€å…±æœ‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯å†…ã§ã•ã¾ã–ã¾ãªæ¨è–¦ã‚¿ã‚¹ã‚¯ã‚’çµ±ä¸€ã—ã€å€‹åˆ¥åŒ–ã¨æ¨è–¦ã®ãŸã‚ã®æ·±ã„æ„å‘³ã‚’æ‰ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚P5ã¯ã€ç•°ãªã‚‹ã‚¿ã‚¹ã‚¯ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã®åŒã˜è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ç›®æ¨™ã‚’æŒã¤äº‹å‰å­¦ç¿’ã‚’è¡Œã„ã¾ã™ã€‚P5ã¯ã€æµ…ã„ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æ·±ã„ãƒ¢ãƒ‡ãƒ«ã¸ã¨é€²åŒ–ã—ã€åºƒç¯„ãªå¾®èª¿æ•´ã®å¿…è¦æ€§ã‚’æ¸›ã‚‰ã™ã“ã¨ãŒã§ãã¾ã™ã€‚P5ã®åŠ¹æœã‚’å®Ÿè¨¼ã™ã‚‹ãŸã‚ã«ã€ã„ãã¤ã‹ã®æ¨è–¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å®Ÿé¨“ã‚’è¡Œã„ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>T5 ã®ã‚ˆã†ã«ã€æ§˜ã€…ãªæ¨è–¦ã‚¿ã‚¹ã‚¯ã‚’ã€ã€ŒPrompt + Predictionã€ã®pipelineã¨ã—ã¦å®šç¾©ã—ã¦è§£ã‘ã‚‹ã‚ˆã†ã«ã—ãŸç ”ç©¶ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9b8b83a2-0930-4836-8bae-a18234fd3fd3" alt="image" loading="lazy"><br><br>P5ã§ã¯encoder-decoder frameworkã‚’æ¡ç”¨ã—ã¦ãŠã‚Šã€encoderå´ã§ã¯bidirectionalãªãƒ¢ãƒ‡ãƒ«ã§promptã®representationã‚’ç”Ÿæˆã—ã€auto-regressiveãªè¨€èªãƒ¢ãƒ‡ãƒ«ã§ç”Ÿæˆã‚’è¡Œã†ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d47cb264-9e94-46c5-9b56-0b6f4e31a8de" alt="image" loading="lazy"><br><br>æ¨è–¦ã§åˆ©ç”¨ã—ãŸã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ã€input-target pairsã‚’ç”Ÿæˆã—ä¸Šè¨˜ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«å¯¾ã—ã¦äº‹å‰å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€æ¨è–¦ã‚’å®Ÿç¾ã§ãã‚‹ã€‚<br><br><br><br>RatingPredictionã§ã¯ã€MatrixFactorizationã«å‹ã¦ã¦ã„ãªã„ï¼ˆãŒã€Rating Predictionã«ã¤ã„ã¦ã¯é­”æ³•ã®å£å•é¡Œãªã©ã‚‚ã‚ã‚‹ã¨æ€ã†ã®ã§ãªã‚“ã¨ã‚‚ã„ãˆãªã„ã€‚ï¼‰<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a7742141-2988-4e92-96ae-f6fb4cc4ce5f" alt="image" loading="lazy"><br><br><br><br>Sequential Recommendationã§ã¯BERT4Recã¨ã‹ã«ã‚‚å‹ã¦ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8badc477-8665-4404-bf4b-93ac901740d6" alt="image" loading="lazy"><br><br><br><br><br><br># Promptä¾‹<br><br>- Rating Predictionã®ä¾‹<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9385d3ff-c186-4490-be34-3baf331aefae" alt="image" loading="lazy"><br><br><br><br>- Sequential Recommendationã®ä¾‹<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/12b61106-af4f-4597-9990-60bc6fa7f222" alt="image" loading="lazy"><br><br><br><br>- Explanationã‚’ç”Ÿæˆã™ã‚‹ä¾‹<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b41f22fd-2476-4365-a3a0-07f72d6bb0db" alt="image" loading="lazy"><br><br><br><br>- Zero-shotã®ä¾‹ï¼ˆCold-Startï¼‰<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5217791e-7a7e-40d4-bdb4-b979af327032" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<span class="issue_date">Issue Date: 2023-08-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/912" target="_blank" rel="noopener noreferrer" class="title-link">Explaining Patterns in Data with Language Models via Interpretable  Autoprompting, Chandan Singh+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’èª¬æ˜ã™ã‚‹èƒ½åŠ›ã‚’æ¢æ±‚ã—ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ã®LLMã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’èª¬æ˜ã™ã‚‹è‡ªç„¶è¨€èªã®æ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å°å…¥ã—ã¾ã—ãŸã€‚å®Ÿé¨“çµæœã¯ã€ã“ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒæ­£ç¢ºãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª¬æ˜ã‚’è¦‹ã¤ã‘å‡ºã™ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ç”Ÿæˆã•ã‚Œã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯äººé–“ã«ã‚‚ç†è§£å¯èƒ½ã§ã‚ã‚Šã€å®Ÿä¸–ç•Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„fMRIãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æœ‰ç”¨ãªæ´å¯Ÿã‚’æä¾›ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview: 


<a href="https://openreview.net/forum?id=GvMuB-YsiK6" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=GvMuB-YsiK6</a>


</p>
<p>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆä¸­ã«å­˜åœ¨ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®èª¬æ˜ï¼‰ã‚’LLMã«ã‚ˆã£ã¦ç”Ÿæˆã•ã›ã‚‹ç ”ç©¶<br>![Image](https://github.com/user-attachments/assets/df70f8c2-6eda-412f-84e0-92ffe7152a39)<br>![Image](https://github.com/user-attachments/assets/42b4f4f9-6f6c-4e45-8c7c-db76c5fd9932)</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2023-05-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/674" target="_blank" rel="noopener noreferrer" class="title-link">Out of One, Many: Using Language Models to Simulate Human Samples, Lisa P. Argyle+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒç¤¾ä¼šç§‘å­¦ç ”ç©¶ã«ãŠã„ã¦ç‰¹å®šã®äººé–“ã®ã‚µãƒ–ãƒãƒ”ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ä»£ç†ã¨ã—ã¦ç ”ç©¶ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’ææ¡ˆã—ã€GPT-3è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã€Œã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çš„å¿ å®Ÿåº¦ã€ã‚’æ¢æ±‚ã™ã‚‹ã€‚ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çš„å¿ å®Ÿåº¦ãŒååˆ†ã§ã‚ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€äººé–“ã‚„ç¤¾ä¼šã®ç†è§£ã‚’é€²ã‚ã‚‹ãŸã‚ã®æ–°ã—ã„å¼·åŠ›ãªãƒ„ãƒ¼ãƒ«ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã¨ææ¡ˆã™ã‚‹ã€‚</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/553" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models are Zero-Shot Reasoners, Kojima+, University of Tokyo, NeurIPS'22</a>
<span class="snippet"><span>Comment</span><p>Zero-Shot CoT (Let's think step-by-step.)è«–æ–‡</p>
<p>&lt;img width="856" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/234746367-2cd80e23-8dcb-4244-b56c-e28120629027.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/234746367-2cd80e23-8dcb-4244-b56c-e28120629027.png"&lt;/a&gt;


&gt;<br><br></p>
<p>Zero-Shot-CoTã¯2ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æ§‹æˆã•ã‚Œã‚‹ï¼š<br><br>- STEP1: Reasoning Extraction<br><br>  - å…ƒã®questionã‚’xã¨ã—ã€zero-shot-CoTã®trigger sentenceã‚’tã¨ã—ãŸæ™‚ã«ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ "Q: [X]. A. [T]" ã‚’ç”¨ã„ã¦promptã€€x'ã‚’ä½œæˆ<br><br>  - ã“ã®prompt x'ã«ã‚ˆã£ã¦å¾—ã‚‰ã‚Œã‚‹ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆzã¯reasoningã®rationaleã¨ãªã£ã¦ã„ã‚‹ã€‚<br><br>- STEP2: Answer Extraction<br><br>  - STEP1ã§å¾—ã‚‰ã‚ŒãŸx'ã¨zã‚’ç”¨ã„ã¦ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ "[X'] [Z] [A]" ã‚’ç”¨ã„ã¦promptã‚’ä½œæˆã—ã€quiestionã«å¯¾ã™ã‚‹å›ç­”ã‚’å¾—ã‚‹<br><br>  - ã“ã®ã¨ãã€Aã¯å›ç­”ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã®trigger sentenceã§ã‚ã‚‹ã€‚<br><br>  - Aã¯ã‚¿ã‚¹ã‚¯ã«å¿œã˜ã¦å¤‰æ›´ã™ã‚‹ã®ãŒåŠ¹æœçš„ã§ã‚ã‚Šã€ãŸã¨ãˆã°ã€multi-choice QAã§ã¯ "Therefore, among A through E, the answer is" ã¨ã„ã£ãŸãƒˆãƒªã‚¬ãƒ¼ã‚’ç”¨ã„ãŸã‚Šã€æ•°å­¦ã®å•é¡Œã§ã¯ "Therefore, the answer (arabic numerals) is" ã¨ã„ã£ãŸãƒˆãƒªã‚¬ãƒ¼ã‚’ç”¨ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/236404426-ed936908-3771-4eef-9871-c6ae04c896bf.png" alt="image" loading="lazy"><br><br><br><br>
<strong># å®Ÿé¨“çµæœ<br><br>è¡¨ä¸­ã®æ€§èƒ½æŒ‡æ¨™ã®å·¦å´ã¯ã‚¿ã‚¹ã‚¯ã”ã¨ã«Answer Triggerã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ãŸã‚‚ã®ã§ã€å³å´ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«"The answer is"ã‚’Answer Triggerã¨ã—ãŸå ´åˆã€‚Zero-shot vs. Zero-shot-CoTã§ã¯ã€Zero-Shot-CoTãŒå¤šãã®bç¾åœ°ãƒãƒ¼ã‚¯ã«ãŠã„ã¦é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ãŸã ã—ã€commonsense reasoningã§ã¯performance gainã‚’å¾—ã‚‰ã‚Œãªã‹ã£ãŸã€‚ã“ã‚Œã¯ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
</strong>
<br>
 ã§å ±å‘Šã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€commonsense reasoningã‚¿ã‚¹ã‚¯ã§ã¯ã€Few-Shot CoTã§ã‚‚Lambda135Bã§æ€§èƒ½ãŒå‘ä¸Šã›ãšã€Palm540Bã§æ€§èƒ½ãŒå‘ä¸Šã—ãŸã‚ˆã†ã«ã€ãƒ¢ãƒ‡ãƒ«ã®parameteræ•°ãŒè¶³ã‚Šã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ï¼ˆæœ¬å®Ÿé¨“ã§ã¯17ç¨®é¡ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ã„ã‚‹ãŒã€ç‰¹ã«æ³¨é‡ˆãŒãªã‘ã‚Œã°text-davinci-002ã‚’åˆ©ç”¨ã—ãŸçµæœï¼‰ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/236405336-fe5e1f7f-9d2f-457f-9e25-98afe4ae0ec1.png" alt="image" loading="lazy"><br><br><br><br>
<strong>## ä»–ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®æ¯”è¼ƒ<br><br>ä»–ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨arithmetic reasoning benchmarkã§æ€§èƒ½æ¯”è¼ƒã—ãŸçµæœã€‚Few-Shot-CoTã«ã¯å‹ã¦ã¦ã„ãªã„ãŒã€standard Few-shot Promptingtã‚’å¤§å¹…ã«ä¸Šå›ã£ã¦ã„ã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/236406621-7862823f-e019-4551-be96-1c97265ca5ba.png" alt="image" loading="lazy"><br><br><br><br>## zero-shot reasoningã«ãŠã‘ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã®å½±éŸ¿<br><br>ã•ã¾ã–ã¾ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€zero-shotã¨zero-shot-CoTã‚’å®Ÿæ–½ã—ãŸå ´åˆã®æ€§èƒ½æ¯”è¼ƒã€‚<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
</strong>
<br>
 ã¨åŒæ§˜ã«ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã„ã¨Zero-shot-CoTã«ã‚ˆã‚‹gainã¯å¾—ã‚‰ã‚Œãªã„ãŒã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã¨ä¸€æ°—ã«gainãŒå¤§ãããªã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/236407727-f29e6f67-8ca1-4623-8341-73bbf2029e67.png" alt="image" loading="lazy"><br><br><br><br>## Zero-shot CoTã«ãŠã‘ã‚‹promptã®é¸æŠã«ã‚ˆã‚‹å½±éŸ¿<br><br>input promptã«å¯¾ã™ã‚‹ãƒ­ãƒã‚¹ãƒˆæ€§ã‚’ç¢ºèªã—ãŸã€‚instructiveã‚«ãƒ†ã‚´ãƒªï¼ˆã™ãªã‚ã¡ã€CoTã‚’ä¿ƒã™ãƒˆãƒªã‚¬ãƒ¼ã§ã‚ã‚Œã°ï¼‰æ€§èƒ½ãŒæ”¹å–„ã—ã¦ã„ã‚‹ã€‚ç‰¹ã«ã€ã©ã®ã‚ˆã†ãªsentenceã®ãƒˆãƒªã‚¬ãƒ¼ã«ã™ã‚‹ã‹ã§æ€§èƒ½ãŒå¤§ããã‹ã‚ã£ã¦ã„ã‚‹ã€‚ä»Šå›ã®å®Ÿé¨“ã§ã¯ã€"Let's think step by step"ãŒæœ€ã‚‚é«˜ã„æ€§èƒ½ã‚’å ã‚æœ€å¤šã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/236408268-8dbc32f3-76c7-4e41-aa1b-a19008aa680c.png" alt="image" loading="lazy"><br><br><br><br>## Few-shot CoTã®prompté¸æŠã«ãŠã‘ã‚‹å½±éŸ¿<br><br>CommonsenseQAã®exampleã‚’ç”¨ã„ã¦ã€AQUA-RAT, MultiArithã‚’Few-shot CoTã§è§£ã„ãŸå ´åˆã®æ€§èƒ½ã€‚ã©ã¡ã‚‰ã®ã‚±ãƒ¼ã‚¹ã‚‚ãƒ‰ãƒ¡ã‚¤ãƒ³ã¯ç•°ãªã‚‹ãŒã€å‰è€…ã¯å›ç­”ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯å…±é€šã§ã‚ã‚‹ã€‚ç•°ãªã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã‚‚ã€answer formatï¼ˆmultiple choiceï¼‰ã®å ´åˆã€ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒç•°ãªã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€zero-shotã¨æ¯”è¼ƒã—ã¦æ€§èƒ½ãŒå¤§å¹…ã«å‘ä¸Šã—ãŸã€‚ä¸€æ–¹ã€answer formatãŒç•°ãªã‚‹å ´åˆã¯performance gainãŒå°ã•ã„ã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€LLMã¯taskè‡ªä½“ã‚ˆã‚Šã‚‚ã€exampleã«ãŠã‘ã‚‹repeated formatã‚’æ´»ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€CommonSennseã‚’Examplarã¨ã—ã¦ç”¨ã„ãŸFew-Shot-CoTã§ã¯ã€ã©ã¡ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚Zero-Shot-CoTã‚ˆã‚Šã‚‚æ€§èƒ½ãŒåŠ£åŒ–ã—ã¦ã„ã‚‹ã€‚ã¤ã¾ã‚Šã€Few-Shot-CoTã§ã¯ã€ã‚¿ã‚¹ã‚¯ç‰¹æœ‰ã®ã‚µãƒ³ãƒ—ãƒ«ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ï¼ˆä¸€æ–¹ã€Zero-shot CoTã§ã¯ãã®ã‚ˆã†ãªã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¯å¿…è¦ãªã„ï¼‰ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/236408978-b292ea0f-0a17-42fc-8e3c-6eee35780ca4.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/523" target="_blank" rel="noopener noreferrer" class="title-link">Recurrent Memory Transformer, Bulatov+, NeurIPS'22</a>
<span class="snippet"><span>Comment</span><p>Transformerã¯O(N^2)ã§ã‚ã‚Šã€è¨ˆç®—é‡ãŒNã«å¿œã˜ã¦æŒ‡æ•°é–¢æ•°çš„ã«å¢—åŠ ã—ã¦ã—ã¾ã†ã€‚ä¸€æ–¹ã€sequenceã®æƒ…å ±ã‚’å…¨ã¦Næ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ã«é›†ç´„ã—ãªã‘ã‚Œã°ãªã‚‰ãšã€è¨ˆç®—é‡ã®åˆ¶ç´„ã«ã‚ˆã£ã¦é•·ã„ç³»åˆ—ã®Representationã‚’ç²å¾—ã§ããªã„ã€‚<br><br>ãã“ã§ã€Transformerã®æ§‹é€ ã¯å¤‰ãˆãšã€Inputã«ãƒ¡ãƒ¢ãƒªtokenã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªé–“ã®é–¢ä¿‚æ€§ã‚’å­¦ç¿’ã§ãã‚‹ã‚ˆã†ãªæ‰‹æ³•ã‚’ææ¡ˆã€‚é•·ã„ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã«å¯¾ã—ã¦ã‚‚ã€ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã‚†ã°ã‚Œã‚‹å˜ä½ã«åŒºåˆ‡ã‚Šã€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®Inputã®é ­ã§ã€å‰æ–­ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ãƒ¡ãƒ¢ãƒªtokenã‚’å…¥åŠ›ã—ã€æœ€çµ‚çš„ã«ç¾åœ¨ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ãƒ¡ãƒ¢ãƒªã‚’outputã—ã€å¾Œæ–­ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«å…¥åŠ›ã¨ã™ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚’ç¹°ã‚Šè¿”ã™ã“ã¨ã§ã€é•·ã„ç³»åˆ—ã‚‚æ‰±ãˆã‚‹ã‚ˆã†ã«ã—ãŸã€‚<br><br>ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ã¾ãŸã„ã§backpropagationã‚’ã‹ã‘ã‚‹ã“ã¨ã§ã€ãŸã¨ãˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦ã¯ç‹¬ç«‹ã—ã¦ã„ã¦ã‚‚ã€ãƒ¡ãƒ¢ãƒªã®æƒ…å ±ã‚’è€ƒæ…®ã™ã‚‹ã“ã¨ã§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“ã®ä¾å­˜é–¢ä¿‚ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/234206394-925cb6ee-85bd-46ad-b7ed-f57685badc38.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2022-12-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/501" target="_blank" rel="noopener noreferrer" class="title-link">UNIFIEDSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models, Xie+, EMNLP'22</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ZeroshotHyperparameterTransfer.html" target="_blank" rel="noopener noreferrer">#ZeroshotHyperparameterTransfer</a>
<span class="issue_date">Issue Date: 2025-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2582" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Tensor Programs V: Tuning Large Neural Networks via Zero-Shot  Hyperparameter Transfer, Greg Yang+, NeurIPS'21</a>
<span class="snippet"><span>GPT Summary</span>- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯é«˜ã‚³ã‚¹ãƒˆã§ã‚ã‚Šã€ç‰¹ã«å¤§è¦æ¨¡ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãŠã„ã¦è² æ‹…ãŒå¤§ãã„ã€‚æ–°ãŸã«ææ¡ˆã™ã‚‹muTransferã¯ã€æœ€å¤§æ›´æ–°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ï¼ˆmuPï¼‰ã‚’åˆ©ç”¨ã—ã€å°ã•ãªãƒ¢ãƒ‡ãƒ«ã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸHPã‚’ãƒ•ãƒ«ã‚µã‚¤ã‚ºãƒ¢ãƒ‡ãƒ«ã«ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§è»¢é€ã™ã‚‹æ‰‹æ³•ã§ã‚ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€1300ä¸‡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰BERT-largeã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’é”æˆã—ã€4000ä¸‡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰ã¯GPT-3ã‚’ä¸Šå›ã‚‹çµæœã‚’å¾—ãŸã€‚ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ã‚¹ãƒˆã¯ãã‚Œãã‚Œäº‹å‰å­¦ç¿’ã‚³ã‚¹ãƒˆã®åŒç­‰ã¾ãŸã¯7%ã«æŠ‘ãˆã‚‰ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=Bx6qKuBM2AD" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Bx6qKuBM2AD</a>


</p>
<p>å°è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿæ–½ã—ã€åŒæ§˜ã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§ã€**å„layerã®widthãŒå¤§ãã„ã‚‚ã®**ã«å¯¾ã—ã¦ã‚‚ã€å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§æœ€é©ã§ã‚ã£ãŸãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’zero-shotã§è»¢ç§»ã™ã‚‹ã“ã¨ã§ near optimalãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å­¦ç¿’ã§ãã‚‹mu Transferã‚’ææ¡ˆã€‚<br><br>ãƒ¢ãƒ‡ãƒ«ã®æ·±ã•ï¼ˆä»¥å¤–ã«ã‚‚ä¸‹è¡¨ä¸­ã®*å°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ã«å¯¾ã—ã¦ã‚‚é™å®šçš„ã«è»¢ç§»å¯èƒ½ãªæ¨¡æ§˜ã€‚Post-Layer Normã®Transformerã‚„ã§ã¯ã‚ã¾ã‚Šã†ã¾ãã„ã‹ãªã„ã“ã¨ãŒ11ç¯€ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ï¼ˆå®Ÿé¨“ã¯pre-Layer Norm Transformer, ResNetã«å¯¾ã—ã¦è¡Œã‚ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ï¼‰ã€‚<br>ã¾ãŸã€6.1ç¯€ã§ã¯ã€ï¼ˆå®Ÿé¨“çš„ã«ï¼‰åˆ©ç”¨ã™ã‚‹å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒ«ã¨ã—ã¦å¹…256, æ·±ã•4, ãƒãƒƒãƒã‚µã‚¤ã‚º32, sequenceé•·128, è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—æ•°5000ã‚’æœ€ä½æº€ãŸã—ã¦ãŠã‚Šã€ã‹ã¤ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹å¹…ãŒå¦¥å½“ãªç¯„å›²å†…ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ã€ã¨ã„ã£ãŸè©±ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>å‰æçŸ¥è­˜ï¼ˆmuPï¼‰ã‚„æ¡ä»¶ãŒå¤šãã†ãªæ°—ãŒã™ã‚‹ã®ã§ã€ã—ã£ã‹ã‚Šç¢ºèªã—ãŸæ–¹ãŒã‚ˆã•ãã†ã€‚<br>ãŸã¨ãˆã°ã€muPã§åˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚„ã€è»¢é€å¯èƒ½ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«é™ã‚ŠãŒã‚ã‚‹ï¼ˆe.g. å­¦ç¿’ç‡ï¼‰ã€ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹finetuningãªã©ã¯è»¢é€ã§ããªã„ãªã©ã€‚<br><br><br>&lt;img width="872" height="336" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/e5aeb152-5c9e-4ba2-9152-4bfef0d7c27c"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/e5aeb152-5c9e-4ba2-9152-4bfef0d7c27c"&lt;/a&gt;


/&gt;</p>
<p>muP:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2583" target="_blank" rel="noopener noreferrer">[Paper Note] Feature Learning in Infinite-Width Neural Networks, Greg Yang+, PMLR'21</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/CodeGeneration.html" target="_blank" rel="noopener noreferrer">#CodeGeneration</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2439" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Program Synthesis with Large Language Models, Jacob Austin+, arXiv'21</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€æ±ç”¨ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã«ãŠã‘ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ åˆæˆã®é™ç•Œã‚’å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦è©•ä¾¡ã—ã¾ã™ã€‚MBPPã¨MathQA-Pythonã®2ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«å¯¾ã™ã‚‹åˆæˆæ€§èƒ½ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚’èª¿æŸ»ã€‚æœ€ã‚‚å¤§ããªãƒ¢ãƒ‡ãƒ«ã¯ã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã§MBPPã®59.6ï¼…ã®å•é¡Œã‚’è§£æ±ºå¯èƒ½ã§ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šç´„10ï¼…ã®æ€§èƒ½å‘ä¸ŠãŒè¦‹ã‚‰ã‚Œã¾ã—ãŸã€‚MathQA-Pythonã§ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒ83.8ï¼…ã®ç²¾åº¦ã‚’é”æˆã€‚äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ã§ã‚¨ãƒ©ãƒ¼ç‡ãŒåŠæ¸›ã—ã€ã‚¨ãƒ©ãƒ¼åˆ†æã‚’é€šã˜ã¦ãƒ¢ãƒ‡ãƒ«ã®å¼±ç‚¹ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã—ãŸã€‚æœ€çµ‚çš„ã«ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ å®Ÿè¡Œçµæœã®äºˆæ¸¬èƒ½åŠ›ã‚’æ¢ã‚‹ã‚‚ã€æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ç‰¹å®šã®å…¥åŠ›ã«å¯¾ã™ã‚‹å‡ºåŠ›äºˆæ¸¬ãŒå›°é›£ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ä»£è¡¨çš„ãªã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚<br><br>MBPPãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€promptã§æŒ‡ç¤ºã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’ãƒ¢ãƒ‡ãƒ«ã«ç”Ÿæˆã•ã›ã€ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ï¼ˆassertion)ã‚’é€šéã™ã‚‹ã‹å¦ã‹ã§è©•ä¾¡ã™ã‚‹ã€‚974ã‚µãƒ³ãƒ—ãƒ«å­˜åœ¨ã—ã€pythonã®åŸºç¤ã‚’æŒã¤ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚ˆã£ã¦ç”Ÿæˆã€‚ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚¿ã‚¹ã‚¯descriptionã¨ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã™ã‚‹ä¸€ã¤ã®é–¢æ•°ï¼ˆé–¢æ•°ã®ã¿ã§å®Ÿè¡Œå¯èƒ½ã§printã¯ä¸å¯ï¼‰ã€3ã¤ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’è¨˜è¿°ã™ã‚‹ã‚ˆã†ä¾é ¼ã€‚ã‚¿ã‚¹ã‚¯descriptionã¯è¿½åŠ ãªclarificationãªã—ã§ã‚³ãƒ¼ãƒ‰ãŒè¨˜è¿°ã§ãã‚‹ã‚ˆã†ååˆ†ãªæƒ…å ±ã‚’å«ã‚€ã‚ˆã†è¨˜è¿°ã™ã‚‹ã‚ˆã†ã«æŒ‡ç¤ºã€‚ground truthã®é–¢æ•°ã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€webã‚’é–²è¦§ã™ã‚‹ã“ã¨ã‚’è¨±å¯ã—ãŸã€‚<br><img src="https://github.com/user-attachments/assets/e27880f7-4647-462d-b619-e0a7a0959d66" alt="image" loading="lazy"><br><br>MathQA-Pythonã¯ã€MathQAã«å«ã¾ã‚Œã‚‹QAã®ã†ã¡è§£ç­”ãŒæ•°å€¤ã®ã‚‚ã®ã®ã¿ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€åˆè¨ˆã§23914ã‚µãƒ³ãƒ—ãƒ«å­˜åœ¨ã™ã‚‹ã€‚pythonã‚³ãƒ¼ãƒ‰ã§ä¸ãˆã‚‰ã‚ŒãŸæ•°å­¦ã«é–¢ã™ã‚‹å•é¡Œã‚’è§£ãã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã€æ•°å€¤ãŒä¸€è‡´ã™ã‚‹ã‹å¦ã‹ã§è©•ä¾¡ã™ã‚‹ã€ã¨ã„ã£ãŸæ„Ÿã˜ãªæ¨¡æ§˜ã€‚æ–œã‚èª­ã¿ãªã®ã§å°‘ã—èª­ã¿é•ãˆã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚<br><br><img src="https://github.com/user-attachments/assets/d21ee76f-a13d-4ef9-843b-74c233c3c0a6" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/CodeGeneration.html" target="_blank" rel="noopener noreferrer">#CodeGeneration</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2438" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Evaluating Large Language Models Trained on Code, Mark Chen+, arXiv'21</a>
<span class="snippet"><span>GPT Summary</span>- Codexã¯GitHubã®ã‚³ãƒ¼ãƒ‰ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸGPTè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€Pythonã‚³ãƒ¼ãƒ‰ç”Ÿæˆèƒ½åŠ›ã‚’è©•ä¾¡ã€‚æ–°ã—ã„è©•ä¾¡ã‚»ãƒƒãƒˆHumanEvalã§ã¯ã€CodexãŒ28.8%ã®å•é¡Œã‚’è§£æ±ºã—ã€GPT-3ã¯0%ã€GPT-Jã¯11.4%ã ã£ãŸã€‚ç¹°ã‚Šè¿”ã—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒé›£ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã—ã¦ã‚‚åŠ¹æœçš„ãªæˆ¦ç•¥ã‚’ç”¨ã„ã€70.2%ã®å•é¡Œã‚’è§£æ±ºã€‚ãƒ¢ãƒ‡ãƒ«ã®é™ç•Œã¨ã—ã¦ã€é•·ã„æ“ä½œã®èª¬æ˜ã‚„å¤‰æ•°ã¸ã®ãƒã‚¤ãƒ³ãƒ‰ã«è‹¦åŠ´ã™ã‚‹ç‚¹ãŒæ˜ã‚‰ã‹ã«ã€‚æœ€å¾Œã«ã€ã‚³ãƒ¼ãƒ‰ç”ŸæˆæŠ€è¡“ã®å½±éŸ¿ã«ã¤ã„ã¦å®‰å…¨æ€§ã‚„çµŒæ¸ˆã«é–¢ã™ã‚‹è­°è«–ã‚’è¡Œã†ã€‚</span>
<span class="snippet"><span>Comment</span><p>HumanEvalãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚Killed by LLMã«ã‚ˆã‚‹ã¨ã€GPT4oã«ã‚ˆã‚Šã™ã§ã«90%ç¨‹åº¦ã®æ€§èƒ½ãŒé”æˆã•ã‚Œé£½å’Œã—ã¦ã„ã‚‹ã€‚<br><br>164å€‹ã®äººæ‰‹ã§è¨˜è¿°ã•ã‚ŒãŸprogrammingã®å•é¡Œã§ã€ãã‚Œãã‚Œã¯function signature, docstring, body, unittestã‚’æŒã¤ã€‚unittestã¯å•é¡Œå½“ãŸã‚Šç´„7.7 testå­˜åœ¨ã€‚handwrittenã¨ã„ã†ç‚¹ãŒãƒŸã‚½ã§ã€ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã®æ‡¸å¿µãŒã‚ã‚‹ãŸã‚githubã®ã‚ˆã†ãªæ—¢å­˜ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ã‚³ãƒ”ãƒ¼ãªã©ã¯ã—ã¦ã„ãªã„ã€‚pass@k[^1]ã§è©•ä¾¡ã€‚<br><br>[^1]: kå€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã•ã›ã€kå€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã®ã†ã¡ã€ã‚µãƒ³ãƒ—ãƒ«ãŒunittestã‚’ä¸€ã¤ã§ã‚‚é€šéã™ã‚‹ç¢ºç‡ã€‚ãŸã ã€æœ¬ç ”ç©¶ã§ã¯ã‚ˆã‚Šãƒã‚¤ã‚¢ã‚¹ã‚’ãªãã™ãŸã‚ã«ã€kã‚ˆã‚Šã‚‚å¤§ãã„nå€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã—ã€ãã®ä¸­ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«kå€‹ã‚’é¸æŠã—ã¦ç¢ºç‡ã‚’æ¨å®šã™ã‚‹ã‚ˆã†ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚2.1ç¯€ã‚’å‚ç…§ã®ã“ã¨ã€‚<br><br><img src="https://github.com/user-attachments/assets/74a74b6f-9d0c-4ce9-ab8b-53b478b4632a" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2056" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Editing Factual Knowledge in Language Models, Nicola De Cao+, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- KnowledgeEditorã¯ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã‚’ç·¨é›†ã—ã€å†å­¦ç¿’ãªã—ã§èª¤ã£ãŸäº‹å®Ÿã‚„äºˆæ¸¬ã‚’ä¿®æ­£ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚åˆ¶ç´„æœ€é©åŒ–ã‚’ç”¨ã„ã¦ãƒã‚¤ãƒ‘ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è¨“ç·´ã—ã€ä»–ã®çŸ¥è­˜ã«å½±éŸ¿ã‚’ä¸ãˆãšã«äº‹å®Ÿã‚’ä¿®æ­£ã—ã¾ã™ã€‚BERTã¨BARTã®ãƒ¢ãƒ‡ãƒ«ã§ãã®æœ‰åŠ¹æ€§ã‚’ç¤ºã—ã€ç‰¹å®šã®ã‚¯ã‚¨ãƒªã«åŸºã¥ãäºˆæ¸¬å¤‰æ›´ãŒãƒ‘ãƒ©ãƒ•ãƒ¬ãƒ¼ã‚ºã«ã‚‚ä¸€è²«ã—ã¦å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚ãƒã‚¤ãƒ‘ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ã€çŸ¥è­˜æ“ä½œã«å¿…è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ç‰¹å®šã™ã‚‹ã€Œãƒ—ãƒ­ãƒ¼ãƒ–ã€ã¨ã—ã¦æ©Ÿèƒ½ã—ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2024-12-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1618" target="_blank" rel="noopener noreferrer" class="title-link">Training Verifiers to Solve Math Word Problems, Karl Cobbe+, arXiv'21</a>
<span class="snippet"><span>GPT Summary</span>- GSM8Kãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€å¤šæ®µéšã®æ•°å­¦çš„æ¨è«–ã«ãŠã‘ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã®é™ç•Œã‚’åˆ†æã€‚æ¤œè¨¼å™¨ã‚’è¨“ç·´ã—ã€å€™è£œè§£ã‚’è©•ä¾¡ã—ã¦æœ€é©è§£ã‚’é¸æŠã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚æ¤œè¨¼ã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚ˆã‚Šã‚‚ãƒ‡ãƒ¼ã‚¿å¢—åŠ ã«å¯¾ã—ã¦åŠ¹æœçš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>## æ°—æŒã¡<br><br>- å½“æ™‚ã®æœ€ã‚‚å¤§ãã„ãƒ¬ãƒ™ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ multi-stepã®reasoningãŒå¿…è¦ãªå•é¡Œã¯å¤±æ•—ã™ã‚‹<br><br>- ãƒ¢ãƒ‡ãƒ«ã‚’Finetuningã‚’ã—ã¦ã‚‚è‡´å‘½çš„ãªãƒŸã‚¹ãŒå«ã¾ã‚Œã‚‹<br><br>- ç‰¹ã«ã€æ•°å­¦ã¯å€‹ã€…ã®ãƒŸã‚¹ã«å¯¾ã—ã¦éå¸¸ã«sensitiveã§ã‚ã‚Šã€ä¸€å›ãƒŸã‚¹ã‚’ã—ã¦ç•°ãªã‚‹è§£æ³•ã®ãƒ‘ã‚¹ã«å…¥ã£ã¦ã—ã¾ã†ã¨ã€self-correctionã™ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒauto-regressiveãªãƒ¢ãƒ‡ãƒ«ã§ã¯ã†ã¾ãã„ã‹ãªã„<br><br>- ç´”ç²‹ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®æ çµ„ã¿ã§ãã‚Œãªã‚Šã®æ€§èƒ½ã«åˆ°é”ã—ã‚ˆã†ã¨ã™ã‚‹ã¨ã€ã¨ã‚“ã§ã‚‚ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¿…è¦ã«ãªã‚Šã€ã‚ˆã‚Šè‰¯ã„scaling lawã‚’ç¤ºã™æ‰‹æ³•ã‚’æ¨¡ç´¢ã™ã‚‹å¿…è¦ãŒã‚ã‚‹<br><br>## Contribution<br><br>è«–æ–‡ã®è²¢çŒ®ã¯<br><br>- GSM8Kã‚’ææ¡ˆã—ã€<br><br>- verifierã‚’æ´»ç”¨ã—ãƒ¢ãƒ‡ãƒ«ã®è¤‡æ•°ã®å€™è£œã®ä¸­ã‹ã‚‰è‰¯ã„å€™è£œã‚’é¸ã¶ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã£ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’30å€ã«ã—ãŸã®ã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™ã¨verifierã‚’å°å…¥ã™ã‚‹ã¨ã‚ˆã‚Šã‚ˆãæ€§èƒ½ãŒã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br>- ã¾ãŸã€dropoutãŒéå¸¸ã«å¼·ã„æ­£å‰‡åŒ–ä½œç”¨ã‚’ä¿ƒã—ã€finetuningã¨verificationã®åŒæ–¹ã‚’å¤§ããæ”¹å–„ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</p>
<p>Todo: ç¶šãã‚’ã¾ã¨ã‚ã‚‹</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2023-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1009" target="_blank" rel="noopener noreferrer" class="title-link">ViLT: Vision-and-Language Transformer Without Convolution or Region   Supervision, Wonjae Kim+, N_A, ICML'21</a>
<span class="snippet"><span>GPT Summary</span>- VLPï¼ˆVision-and-Language Pre-trainingï¼‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€ãƒ“ã‚¸ãƒ§ãƒ³ã¨è¨€èªã®ã‚¿ã‚¹ã‚¯ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã¦ã„ã‚‹ãŒã€ç¾åœ¨ã®æ–¹æ³•ã¯åŠ¹ç‡æ€§ã¨è¡¨ç¾åŠ›ã®é¢ã§å•é¡ŒãŒã‚ã‚‹ã€‚ãã“ã§ã€æœ¬ç ”ç©¶ã§ã¯ç•³ã¿è¾¼ã¿ãƒ•ãƒªãƒ¼ã®ãƒ“ã‚¸ãƒ§ãƒ³ã¨è¨€èªã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒï¼ˆViLTï¼‰ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã™ã‚‹ã€‚ViLTã¯é«˜é€Ÿã§ã‚ã‚ŠãªãŒã‚‰ç«¶äº‰åŠ›ã®ã‚ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ã‚³ãƒ¼ãƒ‰ã¨äº‹å‰å­¦ç¿’æ¸ˆã¿ã®é‡ã¿ã¯GitHubã§åˆ©ç”¨å¯èƒ½ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://tech.fusic.co.jp/posts/2021-12-29-vilt/" target="_blank" rel="noopener noreferrer">https://tech.fusic.co.jp/posts/2021-12-29-vilt/</a>


</p></span><br><br>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<a class="button" href="articles/Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-07-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/907" target="_blank" rel="noopener noreferrer" class="title-link">SimCSE: Simple Contrastive Learning of Sentence Embeddings, Tianyu Gao+, N_A, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€SimCSEã¨ã„ã†å¯¾æ¯”å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€æ–‡ã®åŸ‹ã‚è¾¼ã¿æŠ€è¡“ã‚’é€²åŒ–ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ•™å¸«ãªã—ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€å…¥åŠ›æ–‡ã‚’ãƒã‚¤ã‚ºã¨ã—ã¦æ‰±ã„ã€è‡ªå·±ã‚’å¯¾æ¯”çš„ã«äºˆæ¸¬ã—ã¾ã™ã€‚æ•™å¸«ã‚ã‚Šã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€è‡ªç„¶è¨€èªæ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰æ³¨é‡ˆä»˜ãã®ãƒšã‚¢ã‚’ä½¿ç”¨ã—ã¦å¯¾æ¯”å­¦ç¿’ã‚’è¡Œã„ã¾ã™ã€‚SimCSEã¯ã€æ„å‘³çš„ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼æ€§ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã•ã‚Œã€ä»¥å‰ã®æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦æ”¹å–„ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚å¯¾æ¯”å­¦ç¿’ã¯ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿ã®ç©ºé–“ã‚’å‡ä¸€ã«æ­£å‰‡åŒ–ã—ã€æ•™å¸«ä¿¡å·ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã«ã¯æ­£ã®ãƒšã‚¢ã‚’ã‚ˆã‚Šã‚ˆãæ•´åˆ—ã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/462" target="_blank" rel="noopener noreferrer">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks, Reimers+, UKP-TUDA, EMNLP'19</a>
 ã‚ˆã‚Šã‚‚æ€§èƒ½è‰¯ãã€unsupervisedã§ã‚‚å­¦ç¿’ã§ãã‚‹ã€‚STSã‚¿ã‚¹ã‚¯ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«ã ã„ãŸã„å…¥ã£ã¦ã‚‹</p>
<p># æ‰‹æ³•æ¦‚è¦<br><br>Contrastive Learningã‚’æ´»ç”¨ã—ã¦ã€unsupervised/supervisedã«å­¦ç¿’ã‚’å®Ÿæ–½ã™ã‚‹ã€‚<br><br>Unsupervised SimCSEã§ã¯ã€ã‚ã‚‹sentenceã‚’encoderã«2å›å…¥åŠ›ã—ã€ãã‚Œãã‚Œã«dropoutã‚’é©ç”¨ã•ã›ã‚‹ã“ã¨ã§ã€positive pairã‚’ä½œæˆã™ã‚‹ã€‚dropoutã«ã‚ˆã£ã¦å…±é€šã®embeddingã‹ã‚‰ç•°ãªã‚‹è¦ç´ ãŒãƒã‚¹ã‚¯ã•ã‚ŒãŸï¼ˆnoiseãŒæ··ã–ã£ãŸçŠ¶æ…‹ã¨ã¿ãªã›ã‚‹ï¼‰é¡ä¼¼ã—ãŸembeddingãŒä½œæˆã•ã‚Œã€ã‚ã‚‹ç¨®ã®data augmentationã«ã‚ˆã£ã¦æ­£ä¾‹ã‚’ä½œæˆã—ã¦ã„ã‚‹ã¨ã‚‚ã„ãˆã‚‹ã€‚è² ä¾‹ã¯negative samplingã™ã‚‹ã€‚ï¼ˆéå¸¸ã«simpleã ãŒã€next sentence predictionã§å­¦ç¿’ã™ã‚‹ã‚ˆã‚Šæ€§èƒ½ãŒè‰¯ããªã‚‹ï¼‰<br><br>Supervised SimCSEã§ã¯ã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸsentence pairã«åŸºã¥ã„ã¦ã€æ­£ä¾‹ãƒ»è² ä¾‹ã‚’æ±ºå®šã™ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€NLIã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãŠã„ã¦ã€entailmenté–¢ä¿‚ã«ã‚ã‚‹ã‚‚ã®ã¯æ­£ä¾‹ã¨ã—ã¦æ‰±ã†ã€‚contradictionsï¼ˆçŸ›ç›¾ï¼‰é–¢ä¿‚ã«ã‚ã‚‹ã‚‚ã®ã¯è² ä¾‹ã¨ã—ã¦æ‰±ã†ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ba20a1ca-0078-4227-8bb3-3805ee57a620" alt="image" loading="lazy"><br><br><br><br># Siamese Networkã§ç”¨ã„ã‚‰ã‚Œã‚‹means-squared errrorã¨ContrastiveObjectiveã®é•ã„<br><br>ã©ã¡ã‚‰ã‚‚ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã§æ¯”è¼ƒã™ã‚‹ã¨ã„ã†ç‚¹ã§ã¯ä¸€ç·’ã ãŒã€ContrastiveObjectiveã¯æ­£ä¾‹ã¨è¿‘ã¥ã„ãŸã¨ãã€è² ä¾‹ã¨é ã–ã‹ã£ãŸã¨ãã«lossãŒå°ã•ããªã‚‹ã‚ˆã†ãªå®šå¼åŒ–ãŒã•ã‚Œã¦ã„ã‚‹ç‚¹ãŒç•°ãªã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d9cad930-e86d-4758-87b5-4237525a154a" alt="image" loading="lazy"><br><br>ï¼ˆç”»åƒã¯ã“ã®ãƒ–ãƒ­ã‚°ã‹ã‚‰å¼•ç”¨ã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚


<a href="https://techblog.cccmk.co.jp/entry/2022/08/30/163625%EF%BC%89" target="_blank" rel="noopener noreferrer">https://techblog.cccmk.co.jp/entry/2022/08/30/163625ï¼‰</a>


<br><br><br><br># Unsupervised SimCSEã®å®Ÿé¨“<br><br>ç•°ãªã‚‹data augmentationæ‰‹æ³•ã¨æ¯”è¼ƒã—ãŸçµæœã€dropoutã‚’é©ç”¨ã™ã‚‹æ‰‹æ³•ã®æ–¹ãŒæ€§èƒ½ãŒé«˜ã‹ã£ãŸã€‚MLMã‚„, deletion, é¡ç¾©èªã¸ã®ç½®ãæ›ãˆç­‰ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã—ã¦ã„ã‚‹ã®ã¯èˆˆå‘³æ·±ã„ã€‚ã¾ãŸã€Next Sentence Predictionã¨æ¯”è¼ƒã—ã¦ã‚‚ã€é«˜ã„æ€§èƒ½ã‚’é”æˆã€‚Next Sentence Predictionã¯ã€word deletionç­‰ã®ã»ã¼é¡ä¼¼ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç›´æ¥çš„ã«é¡ä¼¼é–¢ä¿‚ã«ã‚ã‚‹ãƒšã‚¢ã‹ã‚‰å­¦ç¿’ã™ã‚‹ã¨ã„ã†ã‚ˆã‚Šã€Sentenceã®æ„å‘³å†…å®¹ã®ã¤ãªãŒã‚Šã«åŸºã¥ã„ã¦ãƒ¢ãƒ‡ãƒ«ã®è¨€èªç†è§£èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã€ãã®ã†ãˆã§é¡ä¼¼åº¦ã‚’æ¸¬ã‚‹ã¨ã„ã†é–“æ¥çš„ãªæ‰‹æ³•ã ãŒã€word deletionã«è² ã‘ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã€dropoutã‚’é©ç”¨ã™ã‚‹ã ã‘ã®ï¼ˆç›´æ¥çš„ã«é¡ä¼¼ãƒšã‚¢ã‹ã‚‰å­¦ç¿’ã™ã‚‹ï¼‰æœ¬æ‰‹æ³•ã¯ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br>[image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0ea3549e-3363-4857-94e6-a1ef474aa191)<br><br><br><br>ãªãœã†ã¾ãã„ãã‹ã‚’åˆ†æã™ã‚‹ãŸã‚ã«ã€ç•°ãªã‚‹è¨­å®šã§å®Ÿé¨“ã—ã€alignmentï¼ˆæ­£ä¾‹ã¨ã®è¿‘ã•ï¼‰ã¨uniformityï¼ˆã©ã‚Œã ã‘embeddingãŒä¸€æ§˜ã«åˆ†å¸ƒã—ã¦ã„ã‚‹ã‹ï¼‰ã‚’ã€10 stepã”ã¨ã«plotã—ãŸçµæœãŒä»¥ä¸‹ã€‚dropoutã‚’é©ç”¨ã—ãªã„å ´åˆã¨ã€å¸¸ã«åŒã˜éƒ¨åˆ†ã‚’ãƒã‚¹ã‚¯ã™ã‚‹æ–¹æ³•ï¼ˆã¤ã¾ã‚Šã€å…¨ãåŒã˜embeddingã‹ã‚‰å­¦ç¿’ã™ã‚‹ï¼‰è¨­å®šã‚’è¦‹ã‚‹ã¨ã€å­¦ç¿’ãŒé€²ã‚€ã«ã¤ã‚Œuniformityã¯æ”¹å–„ã™ã‚‹ãŒã€alignmentãŒæ‚ªããªã£ã¦ã„ã£ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã€SimCSEã¯alignmentã‚’ç¶­æŒã—ã¤ã¤ã€uniformityã‚‚ã‚ˆããªã£ã¦ã„ã£ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5f488cb2-b15a-4e00-9452-8e48780abe8a" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5e815cf7-b412-4f1b-8adb-116f0dcd2fee" alt="image" loading="lazy"><br><br><br><br># Supervised SimCSEã®å®Ÿé¨“<br><br>ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ContrastiveLearningã™ã‚‹ã«ã‚ãŸã‚Šã€ã©ã†ã„ã£ãŸãƒ‡ãƒ¼ã‚¿ã‚’æ­£ä¾‹ã¨ã—ã¦ã¿ãªã™ã¨è‰¯ã„ã‹ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã«æ§˜ã€…ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å­¦ç¿’ã—æ€§èƒ½ã‚’æ¤œè¨¼ã—ãŸã€‚<br><br><br><br>- QQP4: Quora question pairs<br><br>- Flickr30k (Young et al., 2014): åŒã˜ç”»åƒã«å¯¾ã—ã¦ã€5ã¤ã®ç•°ãªã‚‹äººé–“ãŒè¨˜è¿°ã—ãŸã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨<br><br>- ParaNMT (Wieting and Gimpel, 2018): back-translationã«ã‚ˆã‚‹paraphraseã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆa<br><br>- NLI datasets: SNLIã¨MNLI<br><br><br><br>å®Ÿé¨“ã®çµæœã€NLI datasetsãŒæœ€ã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã“ã®ç†ç”±ã¨ã—ã¦ã¯ã€NLIãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€crowd sourcingã‚¿ã‚¹ã‚¯ã§äººæ‰‹ã§ä½œæˆã•ã‚ŒãŸé«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹ã“ã¨ã¨ã€lexical overlapãŒå°ã•ããªã‚‹ã‚ˆã†ã«sentenceã®ãƒšã‚¢ãŒä½œæˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒèµ·å› ã—ã¦ã„ã‚‹ã€‚å®Ÿéš›ã€NLI datsetã®lexical overlapã¯39%ã ã£ãŸã®ã«å¯¾ã—ã€ã»ã‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯60%ã§ã‚ã£ãŸã€‚<br><br><br><br>ã¾ãŸã€condunctionsã¨ãªã‚‹ãƒšã‚¢ã‚’æ˜ç¤ºçš„ã«è² ä¾‹ã¨ã—ã¦ä¸ãˆã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šæ€§èƒ½ãŒå‘ä¸Šã—ãŸï¼ˆæ™®é€šã¯negative samplingã™ã‚‹ã€ã¨ã„ã†ã‹ãƒãƒƒãƒå†…ã®æ­£ä¾‹ä»¥å¤–ã®ã‚‚ã®ã‚’å¼·åˆ¶çš„ã«è² ä¾‹ã¨ã™ã‚‹ã€‚ã“ã†ã™ã‚‹ã¨ã€æ„å‘³ãŒåŒã˜ã§ã‚‚è² ä¾‹ã«ãªã£ã¦ã—ã¾ã†äº‹ä¾‹ãŒå‡ºã¦ãã‚‹ã“ã¨ã«ãªã‚‹ï¼‰ã€‚ã‚ˆã‚Šé›£ã—ã„NLIã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ANLIãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¿½åŠ ã—ãŸå ´åˆã¯ã€æ€§èƒ½ãŒæ”¹å–„ã—ãªã‹ã£ãŸã€‚ã“ã®ç†ç”±ã«ã¤ã„ã¦ã¯è€ƒå¯Ÿã•ã‚Œã¦ã„ãªã„ã€‚æ€§èƒ½å‘ä¸Šã—ãã†ãªæ°—ãŒã™ã‚‹ã®ã«ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ae05711b-5ad4-4a53-837b-c57e9a39da62" alt="image" loading="lazy"><br><br></p>
<p># ä»–æ‰‹æ³•ã¨ã®æ¯”è¼ƒçµæœ<br><br>SimCSEãŒã‚ˆã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/510744ff-01bb-47be-9e30-2efa49e0f923" alt="image" loading="lazy"><br><br><br><br># Ablation Studies<br><br>ç•°ãªã‚‹poolingæ–¹æ³•ã§ã€ã©ã®ã‚ˆã†ã«sentence embeddingã‚’ä½œæˆã™ã‚‹ã‹ã§æ€§èƒ½ã®é•ã„ã‚’è¦‹ãŸã€‚originalã®BERTã®å®Ÿè£…ã§ã¯ã€CLS token ã®embeddingã®ä¸Šã«MLP layerãŒã®ã£ã‹ã£ã¦ã„ã‚‹ã€‚ã“ã‚Œã®æœ‰ç„¡ãªã©ã¨æ¯”è¼ƒã€‚<br><br>Unsupervised SimCSEã§ã¯ã€trainingæ™‚ã ã‘MLP layerã‚’ã®ã£ã‘ã¦ã€testæ™‚ã¯MLPã‚’é™¤ã„ãŸæ–¹ãŒè‰¯ã‹ã£ãŸã€‚ä¸€æ–¹ã€Supervised SimCSEã§ã¯ã€ MLP layerã‚’ã®ã£ã‘ãŸã¾ã‚“ã¾ã§è‰¯ã‹ã£ãŸã¨ã®ã“ã¨ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/73116c6a-d48f-42bc-aa5e-8342bb068052" alt="image" loading="lazy"><br><br></p>
<p>ã¾ãŸã€SimCSEã§å­¦ç¿’ã—ãŸsentence embeddingã‚’åˆ¥ã‚¿ã‚¹ã‚¯ã«transferã—ã¦æ´»ç”¨ã™ã‚‹éš›ã«ã¯ã€SimCSEã®objectiveã«MLMã‚’å…¥ã‚ŒãŸæ–¹ãŒã€catastrophic forgettingã‚’é˜²ã’ã¦æ€§èƒ½ãŒé«˜ã‹ã£ãŸã¨ã®ã“ã¨ã€‚<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cc6d20c3-5a0c-4b5e-aa6d-63447c55363f" alt="image" loading="lazy"></p>
<p>ablation studiesã®hard negativesã®ã¨ã“ã‚ã¨ã€ã©ã®ã‚ˆã†ã«ãƒŸãƒ‹ãƒãƒƒãƒã‚’æ§‹æˆã™ã‚‹ã‹ã€ãã‚Œãã‚Œã®transferã—ãŸã‚¿ã‚¹ã‚¯ãŒã©ã®ã‚ˆã†ãªã‚‚ã®ãŒã—ã£ã‹ã‚Šèª­ã‚ã¦ã„ãªã„ã€‚ã‚ã¨ã§ã‚ˆã‚€ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-07-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/901" target="_blank" rel="noopener noreferrer" class="title-link">Measuring Massive Multitask Language Understanding, Dan Hendrycks+, N_A, ICLR'21</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®æ­£ç¢ºæ€§ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ†ã‚¹ãƒˆã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ†ã‚¹ãƒˆã¯57ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚«ãƒãƒ¼ã—ã€åºƒç¯„ãªä¸–ç•ŒçŸ¥è­˜ã¨å•é¡Œè§£æ±ºèƒ½åŠ›ãŒå¿…è¦ã§ã™ã€‚ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯ã¾ã å°‚é–€å®¶ãƒ¬ãƒ™ãƒ«ã®æ­£ç¢ºæ€§ã«é”ã—ã¦ãŠã‚‰ãšã€æ€§èƒ½ã«åã‚ŠãŒã‚ã‚Šã¾ã™ã€‚ç§ãŸã¡ã®ãƒ†ã‚¹ãƒˆã¯ã€ãƒ¢ãƒ‡ãƒ«ã®å¼±ç‚¹ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=d7KBjmI3GmQ" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=d7KBjmI3GmQ</a>


</p>
<p>MMLUè«–æ–‡</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2736" target="_blank" rel="noopener noreferrer">[Paper Note] Are We Done with MMLU?, Aryo Pradipta Gema+, NAACL'25</a>
<br><br>ã«ãŠã„ã¦ã€å¤šãã®ã‚¨ãƒ©ãƒ¼ãŒå«ã¾ã‚Œã‚‹ã“ã¨ãŒæŒ‡æ‘˜ã•ã‚Œã€å†ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Ÿæ–½ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/PersonalizedGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedGeneration</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/PersonalizedHeadlineGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedHeadlineGeneration</a>
<span class="issue_date">Issue Date: 2023-05-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/706" target="_blank" rel="noopener noreferrer" class="title-link">PENS: A Dataset and Generic Framework for Personalized News Headline Generation, ACL'21</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èˆˆå‘³ã¨ãƒ‹ãƒ¥ãƒ¼ã‚¹æœ¬æ–‡ã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹å‡ºã—ç”Ÿæˆã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚ã¾ãŸã€ã“ã®å•é¡Œã®ãŸã‚ã®å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹PENSã‚’å…¬é–‹ã—ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢ã‚’ç¤ºã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯https://msnews.github.io/pens.htmlã§å…¥æ‰‹å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«å¯¾ã™ã‚‹PersonalizedãªHeadlineã®æ­£è§£ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã€‚103åã®volunteerã®æœ€ä½ã§ã‚‚50ä»¶ã®ã‚¯ãƒªãƒƒã‚¯ãƒ­ã‚°ã¨ã€200ä»¶ã«å¯¾ã™ã‚‹æ­£è§£ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã—ãŸã€‚æ­£è§£ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹éš›ã¯ã€å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã”ã¨ã«4åç•°ãªã‚‹ãƒ¦ãƒ¼ã‚¶ãŒæ­£è§£ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«ã—ãŸã€‚ã“ã‚Œã‚‰ã‚’ã€Microsoft Newsã®å¤§è¦æ¨¡ãƒ¦ãƒ¼ã‚¶è¡Œå‹•ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã¨ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹æœ¬æ–‡ã€ã‚¿ã‚¤ãƒˆãƒ«ã€impressionãƒ­ã‚°ã¨çµ„ã¿åˆã‚ã›ã¦PENSãƒ‡ãƒ¼ã‚¿ã‚’æ§‹æˆã—ãŸã€‚<br><br><br><br># ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆæ‰‹é †<br><br>103åã®english-native [speakerã®å­¦ç”Ÿã«å¯¾ã—ã¦ã€1000ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã®ä¸­ã‹ã‚‰æœ€ä½50ä»¶èˆˆå‘³ã®ã‚ã‚‹ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’é¸æŠã—ã¦ã‚‚ã‚‰ã†ã€‚ç¶šã„ã¦ã€200ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«å¯¾ã—ã¦ã€æ­£è§£ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã—ãŸã‚‚ã‚‰ã†ã“ã¨ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ãŸã€‚æ­£è§£ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã™ã‚‹éš›ã¯ã€åŒä¸€ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«å¯¾ã—ã¦4äººãŒãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«èª¿æ•´ã—ãŸã€‚ç”Ÿæˆã•ã‚ŒãŸãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¯å°‚é–€å®¶ã«ã‚ˆã£ã¦qualityã‚’ãƒã‚§ãƒƒã‚¯ã•ã‚Œã€factual informationã«ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹ã‚‚ã®ã‚„ã€æ¥µç«¯ã«é•·ã„ãƒ»çŸ­ã„ã‚‚ã®ãªã©ã¯é™¤å¤–ã•ã‚ŒãŸã€‚<br><br><br><br># ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆé‡<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cd4fa969-03c0-4539-bcec-25ba3204ffc9" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1c9a38b4-4156-49a2-83e5-20e057588f91" alt="image" loading="lazy"><br><br><br><br># æ‰‹æ³•æ¦‚è¦<br><br>Transformer Encoder + Pointer Generatorã«ã‚ˆã£ã¦Personalizedãªãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã€‚<br><br>Transformer Encoderã§ã¯ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æœ¬æ–‡æƒ…å ±ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€attention distributionã‚’ç”Ÿæˆã™ã‚‹ã€‚Decoderå´ã§ã¯ã€User Embeddingã‚’çµ„ã¿åˆã‚ã›ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’Pointer Generatorã®æ çµ„ã¿ã§ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦ã„ãã€ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã€‚<br><br>User Embeddingã‚’ã©ã®ã‚ˆã†ã«injectã™ã‚‹ã‹ã§ã€3ç¨®é¡ã®æ–¹æ³•ã‚’ææ¡ˆã—ã¦ãŠã‚Šã€1ã¤ç›®ã¯ã€Decoderã®åˆæœŸçŠ¶æ…‹ã«è¨­å®šã™ã‚‹æ–¹æ³•ã€2ã¤ç›®ã¯ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æœ¬æ–‡ã®attention distributionã®è¨ˆç®—ã«åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã€3ã¤ç›®ã¯ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚ã«ã€ã‚½ãƒ¼ã‚¹ã‹ã‚‰vocabã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹ã‹ã€ç”Ÿæˆã™ã‚‹ã‹ã‚’é¸æŠã™ã‚‹éš›ã«åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã€‚1ã¤ç›®ã¯ä¸€ç•ªã‚·ãƒ³ãƒ—ãƒ«ãªæ–¹æ³•ã€2ã¤ç›®ã¯ã€ãƒ¦ãƒ¼ã‚¶ã«ã‚ˆã£ã¦è¨˜äº‹ã§ç€ç›®ã™ã‚‹éƒ¨åˆ†ãŒé•ã†ã‹ã‚‰attention distributionã‚‚å¤‰ãˆã¾ã—ã‚‡ã†ã€ãã—ã¦ã“ã‚Œã‚’å¤‰ãˆãŸã‚‰context vectorã‚‚å¤‰ã‚ã‚‹ã‹ã‚‰ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚ã®æŒ™å‹•ã‚‚å¤‰ã‚ã‚‹ã‚ˆã­ã¨ã„ã†ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã€3ã¤ç›®ã¯ã€é¸æŠã™ã‚‹vocabã‚’å—œå¥½ã«åˆã‚ã›ã¦å¤‰ãˆã¾ã—ã‚‡ã†ã€ã¨ã„ã†æ–¹å‘æ€§ã ã¨æ€ã‚ã‚Œã‚‹ã€‚æœ€çµ‚çš„ã«ã€2ã¤ç›®ã®æ–¹æ³•ãŒæœ€ã‚‚æ€§èƒ½ãŒè‰¯ã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/54d4da04-6af2-4ef2-b4ff-7a12f1ea7936" alt="image" loading="lazy"><br><br><br><br># è¨“ç·´æ‰‹æ³•<br><br>ã¾ãšãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨“ç·´ã—ã€user embeddingã‚’å–å¾—ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ç¶šã„ã¦ã€genericãªheadline generationãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã€‚æœ€å¾Œã«ä¸¡è€…ã‚’çµ„ã¿åˆã‚ã›ã¦ã€Reinforcement Learningã§Personalized Headeline Generationãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã€‚Rewardã¨ã—ã¦ã€<br><br>1. Personalization: ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¨user embeddingã®dot productã§å ±é…¬ã¨ã™ã‚‹<br><br>2. Fluency: two-layer LSTMã‚’è¨“ç·´ã—ã€ç”Ÿæˆã•ã‚ŒãŸãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã®probabilityã‚’æ¨å®šã™ã‚‹ã“ã¨ã§å ±é…¬ã¨ã™ã‚‹<br><br>3. Factual Consistency: ç”Ÿæˆã•ã‚ŒãŸãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¨æœ¬æ–‡ã®å„æ–‡ã¨ã®ROUGEã‚’æ¸¬ã‚Štop-3 scoreã®å¹³å‡ã‚’å ±é…¬ã¨ã™ã‚‹<br><br>ã¨ã—ãŸã€‚<br><br>1,2,3ã®å¹³å‡ã‚’æœ€çµ‚çš„ãªRewardã¨ã™ã‚‹ã€‚<br><br><br><br># å®Ÿé¨“çµæœ<br><br>Genericãªæ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦ã€å…¨ã¦Personalizedãªæ‰‹æ³•ãŒè‰¯ã‹ã£ãŸã€‚ã¾ãŸã€æ‰‹æ³•ã¨ã—ã¦ã¯â‘¡ã®attention distributionã«å¯¾ã—ã¦user informationã‚’æ³¨å…¥ã™ã‚‹æ–¹æ³•ãŒè‰¯ã‹ã£ãŸã€‚News Recommendationã®æ€§èƒ½ãŒé«˜ã„ã»ã©ã€ç”Ÿæˆã•ã‚Œã‚‹ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã®æ€§èƒ½ã‚‚è‰¯ã‹ã£ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/84aa7b6d-05cf-415a-a2cf-76401801230f" alt="image" loading="lazy"><br><br><br><br># Case Study<br><br>ã‚ã‚‹è¨˜äº‹ã«å¯¾ã™ã‚‹ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã®ä¸€è¦§ã€‚Pointer-Genã§ã¯ã€é‡è¦ãªæƒ…å ±ãŒæŠœã‘è½ã¡ã¦ã—ã¾ã£ã¦ã„ã‚‹ãŒã€ææ¡ˆæ‰‹æ³•ã§ã¯æŠœã‘è½ã¡ã¦ã„ãªã„ã€‚ã“ã‚Œã¯RLã®å ±é…¬ã®fluencyã«ã‚ˆã‚‹ã‚‚ã®ã ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚ã¾ãŸã€ç•°ãªã‚‹ãƒ¦ãƒ¼ã‚¶ã«ã¯ç•°ãªã‚‹ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ãŒç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚ <br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e65eb9da-7cc6-4d72-b2ca-8607c794f3a0" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2022-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/473" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Power of Scale for Parameter-Efficient Prompt Tuning, Brian Lester+, arXiv'21, 2021.04</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å‡çµã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã«é©å¿œã•ã›ã‚‹ãŸã‚ã®ã€Œã‚½ãƒ•ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ã‚’å­¦ç¿’ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã€‚é€†ä¼æ’­ã‚’é€šã˜ã¦å­¦ç¿’ã•ã‚Œã‚‹ã‚½ãƒ•ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã€GPT-3ã®å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã»ã©ç«¶äº‰åŠ›ãŒå¢—ã™ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚ç‰¹ã«ã€æ•°åå„„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€å…¨ã¦ã®é‡ã¿ã‚’èª¿æ•´ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€1ã¤ã®å‡çµãƒ¢ãƒ‡ãƒ«ã‚’è¤‡æ•°ã®ã‚¿ã‚¹ã‚¯ã«å†åˆ©ç”¨ã§ãã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã€ãƒ‰ãƒ¡ã‚¤ãƒ³è»¢é€ã«å¯¾ã™ã‚‹ãƒ­ãƒã‚¹ãƒˆæ€§ã‚‚å‘ä¸Šã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã¨ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬: 


<a href="https://qiita.com/kts_plea/items/79ffbef685d362a7b6ce" target="_blank" rel="noopener noreferrer">https://qiita.com/kts_plea/items/79ffbef685d362a7b6ce</a>


<br><br>T5ã®ã‚ˆã†ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦finetuningã‚’ã‹ã‘ã‚‹éš›ã«ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å‡çµã—ã€promptã‚’embeddingã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç‹¬ç«‹ã—ã¦å­¦ç¿’ã™ã‚‹æ‰‹æ³•<br><br>è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¢—åŠ ã™ã‚‹ã«ã¤ã‚Œã€è¨€èªãƒ¢ãƒ‡ãƒ«ãã®ã‚‚ã®ã‚’finetuningã—ãŸå ´åˆï¼ˆModel Tuningï¼‰ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</p>
<p>ã„ã‚ã‚†ã‚‹(Softãª) Prompt Tuning</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2021-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/405" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Prefix-Tuning: Optimizing Continuous Prompts for Generation, Xiang Lisa Li+, arXiv'21, 2021.01</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®è»½é‡ãªä»£æ›¿æ‰‹æ®µã§ã‚ã‚Šã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å›ºå®šã—ã¤ã¤ã€ã‚¿ã‚¹ã‚¯ç‰¹æœ‰ã®å°ã•ãªãƒ™ã‚¯ãƒˆãƒ«ã‚’æœ€é©åŒ–ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ä½ãƒ‡ãƒ¼ã‚¿è¨­å®šã§ã‚‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’fine-tuningã™ã‚‹éš›ï¼Œã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ™‚ã«ã€Œæ¥é ­è¾ã€ã‚’æ½œåœ¨è¡¨ç¾ã¨ã—ã¦ä¸ãˆï¼Œã€Œæ¥é ­è¾ã€éƒ¨åˆ†ã®ã¿ã‚’fine-tuningã™ã‚‹ã“ã¨ã§ï¼ˆä»–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å›ºå®šï¼‰ï¼Œã‚ˆã‚Šå°‘é‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§fine-tuningã‚’å®Ÿç¾ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆï¼æ¥é ­è¾ã‚’æ½œåœ¨è¡¨ç¾ã§ä¸ãˆã‚‹ã“ã®æ–¹æ³•ã¯ï¼ŒGPT-3ã®promptingã«ç€æƒ³ã‚’å¾—ã¦ã„ã‚‹ï¼fine-tuningã•ã‚ŒãŸæ¥é ­è¾ã®æ½œåœ¨è¡¨ç¾ã®ã¿ã‚’é…å¸ƒã™ã‚Œã°è‰¯ã„ã®ã§ï¼Œéå¸¸ã«å°‘é‡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§fine-tuningãŒã§ãã‚‹ï¼<br><br><br><br>table-to-text, summarizationã‚¿ã‚¹ã‚¯ã§ï¼Œä¸€èˆ¬çš„ãªfine-tuningã‚„Adapterï¼ˆãƒ¬ã‚¤ãƒ¤ãƒ¼ã®é–“ã«ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’æŒ¿å…¥ã—ãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã ã‘ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ‰‹æ³•ï¼‰ã¨ã„ã£ãŸåŠ¹ç‡çš„ãªfine-tuningæ‰‹æ³•ã¨æ¯”è¼ƒï¼table-to-textã§ã¯ã€250k (å…ƒã®ãƒ¢ãƒ‡ãƒ«ã® 0.1%) ã»ã©ã®æ•°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¾®èª¿æ•´ã™ã‚‹ã ã‘ã§ã€å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’fine-tuningã™ã‚‹ã®ã«åŒ¹æ•µã‚‚ã—ãã¯ãã‚Œä»¥ä¸Šã®æ€§èƒ½ã‚’é”æˆï¼<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/132679791-87ad130d-8a7e-4549-a311-f84400a3787b.png" alt="image" loading="lazy"><br><br></p>
<p>Hugging Faceã®å®Ÿè£…ã‚’åˆ©ç”¨ã—ãŸã¨è«–æ–‡ä¸­ã§ã¯è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ãŒï¼Œfine-tuningã™ã‚‹å‰ã®å…ƒã®è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆGPT-2ï¼‰ã¯ã©ã®ã‚ˆã†ã«æº–å‚™ã—ãŸã®ã ã‚ã†ã‹ï¼Hugging Faceã®pretrainedæ¸ˆã¿ã®GPT-2ã‚’ä½¿ç”¨ã—ãŸã®ã ã‚ã†ã‹ï¼</p>
<p>autoregressive LM (GPT-2)ã¨ï¼Œencoder-decoderãƒ¢ãƒ‡ãƒ«ï¼ˆBARTï¼‰ã¸Prefix Tuningã‚’é©ç”¨ã™ã‚‹å ´åˆã®æ¨¡å¼å›³<br><br><img src="https://user-images.githubusercontent.com/12249301/132681736-0ea4b13f-71cb-41ba-ae17-027e8bf54cc0.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-05-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2002" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Laws for Autoregressive Generative Modeling, Tom Henighan+, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- ç”Ÿæˆç”»åƒã€ãƒ“ãƒ‡ã‚ªã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€æ•°å­¦çš„å•é¡Œè§£æ±ºã®4é ˜åŸŸã«ãŠã‘ã‚‹ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ç‰¹å®šã€‚è‡ªå·±å›å¸°å‹ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨è¨ˆç®—äºˆç®—ã®å¢—åŠ ã«ä¼´ã„æ€§èƒ½ãŒå‘ä¸Šã—ã€ã¹ãæ³•å‰‡ã«å¾“ã†ã€‚ç‰¹ã«ã€10å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¯YFCC100Mç”»åƒåˆ†å¸ƒã‚’ã»ã¼å®Œç’§ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã•ã‚‰ã«ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ç›¸äº’æƒ…å ±é‡ã‚„æ•°å­¦çš„å•é¡Œè§£æ±ºã«ãŠã‘ã‚‹å¤–æŒ¿æ™‚ã®æ€§èƒ½ã«é–¢ã™ã‚‹è¿½åŠ ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚‚ç™ºè¦‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ãŒãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿ãŒå¼·èª¿ã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1889" target="_blank" rel="noopener noreferrer" class="title-link">The Curious Case of Neural Text Degeneration, Ari Holtzman+, ICLR'20</a>
<span class="snippet"><span>GPT Summary</span>- æ·±å±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ã¯é«˜å“è³ªãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ãŠã„ã¦èª²é¡ŒãŒæ®‹ã‚‹ã€‚å°¤åº¦ã®ä½¿ç”¨ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã€äººé–“ã®ãƒ†ã‚­ã‚¹ãƒˆã¨æ©Ÿæ¢°ã®ãƒ†ã‚­ã‚¹ãƒˆã®é–“ã«åˆ†å¸ƒã®é•ã„ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ãŒç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã®è³ªã«å¤§ããªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ãƒ‹ãƒ¥ãƒ¼ã‚¯ãƒªã‚¢ã‚¹samplingã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¤šæ§˜æ€§ã‚’ä¿ã¡ãªãŒã‚‰ä¿¡é ¼æ€§ã®ä½ã„éƒ¨åˆ†ã‚’æ’é™¤ã—ã€äººé–“ã®ãƒ†ã‚­ã‚¹ãƒˆã«è¿‘ã„è³ªã‚’å®Ÿç¾ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç¾åœ¨ã®LLMã§ä¸»æµãªNucleus (top-p) Samplingã‚’ææ¡ˆã—ãŸç ”ç©¶</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1828" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Laws for Neural Language Models, Jared Kaplan+, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«é–¢ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ç ”ç©¶ã—ã€æå¤±ãŒãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºã€è¨ˆç®—é‡ã«å¯¾ã—ã¦å†ªå‰‡çš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è©³ç´°ã¯å½±éŸ¿ãŒå°‘ãªãã€éå­¦ç¿’ã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é€Ÿåº¦ã¯å˜ç´”ãªæ–¹ç¨‹å¼ã§èª¬æ˜ã•ã‚Œã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¨ˆç®—äºˆç®—ã®æœ€é©ãªé…åˆ†ãŒå¯èƒ½ã¨ãªã‚Šã€å¤§ããªãƒ¢ãƒ‡ãƒ«ã¯ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ãŒé«˜ãã€å°‘é‡ã®ãƒ‡ãƒ¼ã‚¿ã§æ—©æœŸã«åæŸã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://www.slideshare.net/slideshow/dlscaling-laws-for-neural-language-models/243005067" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/slideshow/dlscaling-laws-for-neural-language-models/243005067</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ActivationFunction.html" target="_blank" rel="noopener noreferrer">#ActivationFunction</a>
<span class="issue_date">Issue Date: 2024-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1311" target="_blank" rel="noopener noreferrer" class="title-link">GLU Variants Improve Transformer, Noam Shazeer, N_A, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- GLUã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’Transformerã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ»ã‚µãƒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ãƒ†ã‚¹ãƒˆã—ã€é€šå¸¸ã®æ´»æ€§åŒ–é–¢æ•°ã‚ˆã‚Šã‚‚ã„ãã¤ã‹ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒå“è³ªå‘ä¸Šã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ã‚’ç™ºè¦‹ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ä¸€èˆ¬çš„ãªFFNã§ã¯ã€linear layerã‚’ã‹ã‘ãŸå¾Œã«ã€ä½•ã‚‰ã‹ã®æ´»æ€§åŒ–é–¢æ•°ã‚’ã‹ã¾ã›ã‚‹æ–¹æ³•ãŒä¸»æµã§ã‚ã‚‹ã€‚<br><br>ã“ã®ã‚ˆã†ãªæ§‹é€ ã®ä¸€ã¤ã¨ã—ã¦GLUãŒã‚ã‚‹ãŒã€linear layerã¨æ´»æ€§åŒ–é–¢æ•°ã«ã¯æ”¹è‰¯ã®ä½™åœ°ãŒã‚ã‚Šã€æ§˜ã€…ãªvariantãŒè€ƒãˆã‚‰ã‚Œã‚‹ãŸã‚ã€è‰²ã€…è©¦ã—ã¾ã—ãŸã€ã¨ã„ã†ã¯ãªã—ã€‚<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/72b1d0bb-64ac-4155-9a3b-5624cd06ccc9" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b38321c6-d414-4764-9147-10a5fa83fbe6" alt="image" loading="lazy"><br><br><br><br>ã‚ªãƒªã‚¸ãƒŠãƒ«ã®GLUã¨æ¯”è¼ƒã—ã¦ã€T5ã¨åŒã˜äº‹å‰å­¦ç¿’ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã—ãŸã¨ã“ã‚ã€perplexityãŒæ”¹å–„<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9e67a054-2148-41ed-aae1-5a752c21a242" alt="image" loading="lazy"><br><br><br><br>ã¾ãŸã€finetuningã‚’ã—ãŸå ´åˆã®æ€§èƒ½ã‚‚ã€å¤šãã®å ´åˆã‚ªãƒªã‚¸ãƒŠãƒ«ã®GLUã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/77ccab88-e5cc-48fc-b9e0-f2dad24e53e8" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8f60ca8c-50eb-4869-bab4-f02ec6d8e085" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8124fc25-aa7e-4e10-8cd2-9d24c818f410" alt="image" loading="lazy"><br><br><br><br><br><br></p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2023-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1168" target="_blank" rel="noopener noreferrer" class="title-link">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, Patrick Lewis+, N_A, NeurIPS'20</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢å¼·åŒ–ç”Ÿæˆï¼ˆRAGï¼‰ã®å¾®èª¿æ•´æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚RAGãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã¨éãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã‚’çµ„ã¿åˆã‚ã›ãŸè¨€èªç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€å¹…åºƒã„çŸ¥è­˜é›†ç´„çš„ãªè‡ªç„¶è¨€èªå‡¦ç†ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã—ãŸã€‚ç‰¹ã«ã€QAã‚¿ã‚¹ã‚¯ã§ã¯ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã€è¨€èªç”Ÿæˆã‚¿ã‚¹ã‚¯ã§ã¯å…·ä½“çš„ã§å¤šæ§˜ãªè¨€èªã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>RAGã‚’ææ¡ˆã—ãŸç ”ç©¶<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/77d4c13d-c26c-40e1-8429-1a879769587e" alt="image" loading="lazy"><br><br></p>
<p>Retrieverã¨ã—ã¦åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹Dense Passage Retrieval (DPR)ã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3016" target="_blank" rel="noopener noreferrer">[Paper Note] Dense Passage Retrieval for Open-Domain Question Answering, Vladimir Karpukhin+, EMNLP'20, 2020.04</a>
</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/552" target="_blank" rel="noopener noreferrer" class="title-link">Language Models are Few-Shot Learners, Tom B. Brown+, NeurIPS'20</a>
<span class="snippet"><span>GPT Summary</span>- GPT-3ã¯1750å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤è‡ªå·±å›å¸°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆè¨­å®šã«ãŠã„ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã§å¤šãã®NLPã‚¿ã‚¹ã‚¯ã§å¼·åŠ›ãªæ€§èƒ½ã‚’ç¤ºã™ã€‚ç¿»è¨³ã‚„è³ªå•å¿œç­”ãªã©ã§å„ªã‚ŒãŸçµæœã‚’å‡ºã—ã€å³æ™‚æ¨è«–ã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§ã‚‚è‰¯å¥½ãªæ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ä¸€æ–¹ã€ä¾ç„¶ã¨ã—ã¦è‹¦æ‰‹ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„è¨“ç·´ã«é–¢ã™ã‚‹å•é¡Œã‚‚å­˜åœ¨ã™ã‚‹ã€‚ã¾ãŸã€GPT-3ã¯äººé–“ãŒæ›¸ã„ãŸè¨˜äº‹ã¨åŒºåˆ¥ãŒé›£ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã€ç¤¾ä¼šçš„å½±éŸ¿ã«ã¤ã„ã¦ã‚‚è­°è«–ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>In-Context Learningã‚’ææ¡ˆã—ãŸè«–æ–‡</p>
<p>è«–æ–‡ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹In-Context Learningã®å®šç¾©ã¯ã€ã—ã£ã‹ã‚ŠæŠ¼ã•ãˆã¦ãŠã„ãŸæ–¹ãŒè‰¯ã„ã€‚<br><br>ä¸‹å›³ã¯meta-learningã®è¦³ç‚¹ã‹ã‚‰è¦‹ãŸã¨ãã®ã€in-contextã®ä½ç½®ä»˜ã‘ã€‚äº‹å‰å­¦ç¿’æ™‚ã«SGDã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’updateã™ã‚‹ã®ã‚’outer loopã¨ã—ã€ãã“ã§åºƒã„ã‚¹ã‚­ãƒ«ã¨ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã®èƒ½åŠ›ã‚’èº«ã«ã¤ã‘ã‚‹ã€‚ä¸€æ–¹ã§ã€in-context learningã¯ã€Inferenceæ™‚ã«äº‹å‰å­¦ç¿’æ™‚ã«å¾—ãŸãã‚Œã‚‰ã®ã‚¹ã‚­ãƒ«ã‚’ç”¨ã„ã¦ã€æ±‚ã‚ã‚‹ã‚¿ã‚¹ã‚¯ã‚’èªè­˜ã€ã‚ã‚‹ã„ã¯é©å¿œã™ã‚‹Inner loopã®ã“ã¨ã‚’æŒ‡ã™ã€‚<br><img src="https://github.com/user-attachments/assets/679129f3-93e3-445f-b9e8-5d909261737b" alt="image" loading="lazy"><br><br>ã“ã®ä¸Šã§ã€è«–æ–‡ä¸­ã§ã¯ In-Context Learningã«ã¤ã„ã¦:<br>&gt; Recent work [RWC+19] attempts to do this via what we call â€œin-context learningâ€, using the text input of a pretrained language model as a form of task specification: the model is conditioned on a natural language instruction and/or a few demonstrations of the task and is then expected to complete further instances of the task simply by predicting what comes next.<br><br>ã¨å®šç¾©ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<a class="button" href="articles/Zero/FewShotLearning.html" target="_blank" rel="noopener noreferrer">#Zero/FewShotLearning</a>
<span class="issue_date">Issue Date: 2022-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/494" target="_blank" rel="noopener noreferrer" class="title-link">Few-Shot NLG with Pre-Trained Language Model, Chen+, University of California, ACL'20</a>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>Neural basedãªend-to-endãªNLGã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯data-hungryãªã®ã§ã€Few Shotãªè¨­å®šã§é«˜ã„æ€§èƒ½ãŒã§ãã‚‹æ‰‹æ³•ã‚’ææ¡ˆï¼ˆFew shot NLGï¼‰<br><br>Table-to-Textã‚¿ã‚¹ã‚¯ï¼ˆWikiBIOãƒ‡ãƒ¼ã‚¿, è¿½åŠ ã§åé›†ã—ãŸBook, Songãƒ‰ãƒ¡ã‚¤ãƒ³ã®Wikipediaãƒ‡ãƒ¼ã‚¿ï¼‰ã«ãŠã„ã¦ã€200ç¨‹åº¦ã®å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°ã§strong baselineã«å¯¾ã—ã¦8.0 pointç¨‹åº¦ã®BLEUã‚¹ã‚³ã‚¢ã®å‘ä¸Šã‚’é”æˆ<br><br><br><br># æ‰‹æ³•<br><br>Tabularãƒ‡ãƒ¼ã‚¿ã®Descriptionã‚’ä½œæˆã™ã‚‹ã«ã¯å¤§ããåˆ†ã‘ã¦2ã¤ã®ã‚¹ã‚­ãƒ«ãŒå¿…è¦<br><br>1. factualãªæƒ…å ±ã‚’æŒã¤contentã‚’selectã—ã€copyã™ã‚‹ã‚¹ã‚­ãƒ«<br><br>2. factualãªæƒ…å ±ã®ã‚³ãƒ”ãƒ¼ã‚’å«ã‚ãªãŒã‚‰ã€æ–‡æ³•çš„ã«æ­£ã—ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚­ãƒ«<br><br>ææ¡ˆæ‰‹æ³•ã§ã¯ã€1ã‚’å°‘é‡ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆ&lt; 500ï¼‰ã‹ã‚‰å­¦ç¿’ã—ã€2ã«ã¤ã„ã¦ã¯äº‹å‰å­¦ç¿’æ¸ˆã¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã™ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/204966408-e5442477-0560-439b-9780-d454a8761345.png" alt="image" loading="lazy"><br><br><br><br>encoderã‹ã‚‰ã‚³ãƒ”ãƒ¼ã™ã‚‹ç¢ºç‡ã‚’pcopyã¨ã—ã€ä¸‹è¨˜å¼ã§ç®—å‡ºã™ã‚‹ï¼š<br><br><img src="https://user-images.githubusercontent.com/12249301/204968383-44ef3771-218e-4e3e-8bfd-e2e6750c514b.png" alt="image" loading="lazy"><br><br>ã™ãªã‚ã¡ã€encoderã®context vectorã¨ã€decoderã®inputã¨stateã‹ã‚‰æ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚<br><br>encoderã¨encoderå´ã¸ã®attentionã¯scratchã‹ã‚‰å­¦ç¿’ã—ãªã‘ã‚Œã°ãªã‚‰ãšã€ã†ã¾ãã‚³ãƒ”ãƒ¼ã§ãã‚‹ã‚ˆã†ã«ã—ã£ã‹ã‚Šã¨â€teachâ€ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ãŸã‚ã€lossã«ä»¥ä¸‹ã‚’è¿½åŠ ã™ã‚‹ï¼š<br><br><img src="https://user-images.githubusercontent.com/12249301/204968557-4526e76d-8be5-4371-adc7-d49d8291954f.png" alt="image" loading="lazy"><br><br>ã™ãªã‚ã¡ã€ã‚³ãƒ”ãƒ¼ã™ã¹ãå˜èªãŒã¡ã‚ƒã‚“ã¨ã‚³ãƒ”ãƒ¼ã§ãã¦ã‚‹å ´åˆã«lossãŒå°ã•ããªã‚‹é …ã‚’è¿½åŠ ã—ã¦ã„ã‚‹ã€‚<br><br>ã¾ãŸã€decoderå´ã§ã¯ã€æœ€åˆã«Tableæƒ…å ±ã®Embeddingã‚’å…¥åŠ›ã™ã‚‹ã‚ˆã†ã«ã—ã¦ã„ã‚‹ã€‚<br><br>ã¾ãŸã€å­¦ç¿’ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿é‡ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹ãŸã‚ã€pre-trainingãƒ¢ãƒ‡ãƒ«ã®Embeddingã¯äº‹å‰å­¦ç¿’æ™‚ç‚¹ã®ã‚‚ã®ã«å›ºå®šã—ãŸï¼ˆãŸã ã—ãèª­è§£ã§ãã¦ã„ã‚‹ã‹ä¸å®‰ï¼‰<br><br><br><br># å®Ÿé¨“<br><br>WikiBIOã¨ã€ç‹¬è‡ªã«åé›†ã—ãŸBook, Songã«é–¢ã™ã‚‹Wikipediaãƒ‡ãƒ¼ã‚¿ã®Table-to-Textãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦å®Ÿé¨“ã€‚<br><br>ã“ã®ã¨ãã€Training instanceã‚’50~500ã¾ã§å¤‰åŒ–ã•ã›ãŸã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/204969250-b2965b62-5a82-4c38-9008-3e4bbc5d9c24.png" alt="image" loading="lazy"><br><br><br><br>WikiBIOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦SoTAã‚’è¨˜éŒ²ã—ã¦ã„ã‚‹Base-originalã‚’å¤§ããoutperformï¼ˆFew shot settingã§ã¯å…¨ç„¶ã†ã¾ãã„ã‹ãªã„ï¼‰ã€‚<br><br><br><br>inputã¨outputä¾‹ã¨ã€ã‚³ãƒ”ãƒ¼ã«é–¢ã™ã‚‹lossã‚’å…¥ã‚ŒãŸå ´åˆã®åŠ¹æœã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/204969645-aa2686f0-f83c-44cc-a6aa-2e793a6cd5b8.png" alt="image" loading="lazy"><br><br><br><br>äººæ‰‹è©•ä¾¡ã®çµæœã€Factual informationã®æ­£ã—ã•ï¼ˆ#Suppï¼‰ã€èª¤ã‚Šï¼ˆ#Contï¼‰ã¨ã‚‚ã«ææ¡ˆæ‰‹æ³•ãŒè‰¯ã„ã€‚ã¾ãŸã€æ–‡æ³•çš„ãªæ­£ã—ã•ï¼ˆLan. Scoreï¼‰ã‚‚ã‚³ãƒ”ãƒ¼ãŒãªã„å ´åˆã¨comparable<br><br><img src="https://user-images.githubusercontent.com/12249301/204969885-7cb3e507-d986-4d97-8f7c-a5b8c3c8204f.png" alt="image" loading="lazy"><br><br><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-08-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2357" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Equilibrium Models, Shaojie Bai+, NeurIPS'19</a>
<span class="snippet"><span>GPT Summary</span>- æ·±ã„å¹³è¡¡ãƒ¢ãƒ‡ãƒ«ï¼ˆDEQï¼‰ã‚’ææ¡ˆã—ã€é€æ¬¡ãƒ‡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«åŒ–ã«ãŠã„ã¦å¹³è¡¡ç‚¹ã‚’ç›´æ¥è¦‹ã¤ã‘ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç¤ºã™ã€‚DEQã¯ç„¡é™ã®æ·±ã•ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è§£æçš„ã«é€†ä¼æ’­å¯èƒ½ã«ã—ã€å®šæ•°ãƒ¡ãƒ¢ãƒªã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨äºˆæ¸¬ã‚’è¡Œãˆã‚‹ã€‚è‡ªå·±æ³¨æ„ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚„ãƒˆãƒ¬ãƒªã‚¹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«é©ç”¨ã—ã€WikiText-103ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã€è¨ˆç®—è¦ä»¶ã®ç¶­æŒã€ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ã®æœ€å¤§88%å‰Šæ¸›ã‚’å®Ÿè¨¼ã€‚</span>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1272" target="_blank" rel="noopener noreferrer" class="title-link">Fast Transformer Decoding: One Write-Head is All You Need, Noam Shazeer, N_A, arXiv'19</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯é«˜é€Ÿã‹ã¤ç°¡å˜ã ãŒã€å¢—åˆ†æ¨è«–ã¯å¤§ããª"keys"ã¨"values"ãƒ†ãƒ³ã‚½ãƒ«ã‚’ç¹°ã‚Šè¿”ã—èª­ã¿è¾¼ã‚€ãŸã‚ã«é…ããªã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ãã“ã§ã€ã‚­ãƒ¼ã¨å€¤ã‚’å…±æœ‰ã™ã‚‹ãƒãƒ«ãƒã‚¯ã‚¨ãƒªã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’ææ¡ˆã—ã€ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…è¦ä»¶ã‚’ä½æ¸›ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€é«˜é€Ÿãªãƒ‡ã‚³ãƒ¼ãƒ‰ãŒå¯èƒ½ã§ã€ã‚ãšã‹ãªå“è³ªã®ä½ä¸‹ã—ã‹ãªã„ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Multi Query Attentionè«–æ–‡ã€‚KVã®setã«å¯¾ã—ã¦ã€å˜ä¸€ã®Queryã®ã¿ã§Multi-Head Attentionã‚’ä»£æ›¿ã™ã‚‹ã€‚åŠ‡çš„ã«Decoderã®InferenceãŒæ—©ããªã‚Šãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒæ¸›ã‚‹ãŒã€è«–æ–‡ä¸­ã§ã¯è¨€åŠã•ã‚Œã¦ã„ãªã„ï¼Ÿã‚ˆã†ã ãŒã€æ€§èƒ½ã¨å­¦ç¿’ã®å®‰å®šæ€§ãŒèª²é¡Œã¨ãªã‚‹ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e2d77b43-70c3-4922-a822-bf95d6b4704f" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/76" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Larger-context language modelling with recurrent neural networks, Wang+, ACL'16</a>
<span class="snippet"><span>Comment</span><p>## æ¦‚è¦<br><br>é€šå¸¸ã®Neural Language Modelã¯sentenceé–“ã«ç‹¬ç«‹æ€§ã®ä»®å®šã‚’ç½®ããƒ¢ãƒ‡ãƒ«åŒ–ã•ã‚Œã¦ã„ã‚‹ãŒã€ã“ã®ç‹¬ç«‹æ€§ã‚’æ’é™¤ã—ã€preceding sentencesã«ä¾å­˜ã™ã‚‹ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ã“ã¨ã§ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ¼ãƒ‘ã‚¹ãƒ¬ãƒ™ãƒ«ã§ã®PerplexityãŒæ”¹å–„ã—ãŸã¨ã„ã†è©±ã€‚ææ¡ˆã—ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€contextã‚’è€ƒæ…®ã™ã‚‹ã“ã¨ã§ç‰¹ã«åè©ã‚„å‹•è©ã€å½¢å®¹è©ã®äºˆæ¸¬æ€§èƒ½ãŒå‘ä¸Šã€‚Late-Fusion methodã¨å‘¼ã°ã‚Œã‚‹RNNã®outputã®è¨ˆç®—ã«context vectorã‚’çµ„ã¿è¾¼ã‚€æ‰‹æ³•ãŒã€Perplexityã®æ”¹å–„ã«ã‚‚ã£ã¨ã‚‚å¯„ä¸ã—ã¦ã„ãŸã€‚<br><br><br><br>## æ‰‹æ³•<br><br><img src="https://user-images.githubusercontent.com/12249301/34412713-1e16da94-ec22-11e7-830c-0d0b6247207c.png" alt="image" loading="lazy"><br><br><br><br>sentenceé–“ã®ç‹¬ç«‹æ€§ã‚’æ’é™¤ã—ã€Corpusãƒ¬ãƒ™ãƒ«ã®probabilityã‚’ä¸‹å›³ã®ã‚ˆã†ã«å®šç¾©ã€‚ï¼ˆæ™®é€šã¯P(SlãŒæ¡ä»¶ä»˜ã‘ã•ã‚Œã¦ã„ãªã„)ï¼‰<br><br><img src="https://user-images.githubusercontent.com/12249301/34412980-e2425afa-ec23-11e7-86cd-148f85dccc07.png" alt="image" loading="lazy"><br><br><br><br>preceding sentence (context)ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ãŸã‚ã«ã€3ç¨®é¡ã®æ‰‹æ³•ã‚’ææ¡ˆã€‚<br><br><br><br>[1. bag-of-words context]<br><br>ã€€ãƒŠã‚¤ãƒ¼ãƒ–ã«ã€contextã«ç¾ã‚ŒãŸå˜èªã®ï¼ˆå˜ä¸€ã®ï¼‰bag-of-wordsãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œã‚Šã€linear layerã‚’ã‹ã¾ã›ã¦context vectorã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã€‚<br><br><br><br>[2. context recurrent neural network]<br><br>ã€€preceding sentencesã‚’bag-of-wordsãƒ™ã‚¯ãƒˆãƒ«ã®ç³»åˆ—ã§è¡¨ç¾ã—ã€ã“ã‚Œã‚‰ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’sequentialã«RNN-LSTMã«èª­ã¿è¾¼ã¾ã›ã€æœ€å¾Œã®hidden stateã‚’context vectorã¨ã™ã‚‹æ‰‹æ³•ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€sentenceãŒå‡ºç¾ã—ãŸé †ç•ªãŒè€ƒæ…®ã•ã‚Œã‚‹ã€‚<br><br><br><br>[3. attention based context representation]<br><br>ã€€Attentionã‚’ç”¨ã„ã‚‹æ‰‹æ³•ã‚‚ææ¡ˆã•ã‚Œã¦ãŠã‚Šã€context recurrent neural networkã¨åŒæ§˜ã«RNNã«bag-of-wordsã®sequenceã‚’é£Ÿã‚ã›ã‚‹ãŒã€å„æ™‚ç‚¹ã«ãŠã‘ã‚‹context sentenceã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã€bi-directionalãªRNNã®forward, backward stateã‚’concatã—ãŸã‚‚ã®ã§è¡¨ç¾ã—ã€attention weightã®è¨ˆç®—ã«ç”¨ã„ã‚‹ã€‚context vectorã¯1, 2ã§ã¯current sentenceä¸­ã§ã¯å…±é€šã®ã‚‚ã®ã‚’ç”¨ã„ã‚‹ãŒã€attention basedãªå ´åˆã¯current sentenceã®å˜èªã”ã¨ã«ç•°ãªã‚‹context vectorã‚’ç”Ÿæˆã—ã¦ç”¨ã„ã‚‹ã€‚<br><br><br><br>ç”Ÿæˆã—ãŸcontext vectorã‚’sentence-levelã®RNNè¨€èªãƒ¢ãƒ‡ãƒ«ã«çµ„ã¿åˆã‚ã›ã‚‹éš›ã«ã€äºŒç¨®é¡ã®Fusion Methodã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br><br><br>[1. Early Fusion]<br><br>ã€€ãƒŠã‚¤ãƒ¼ãƒ–ã«ã€RNNLMã®å„æ™‚ç‚¹ã§ã®inputã«context vectorã®æƒ…å ±ã‚’çµ„ã¿è¾¼ã‚€æ–¹æ³•ã€‚<br><br>[2. Late Fusion]<br><br>ã€€ã‚ˆã‚Šã†ã¾ãcontext vectorã®æƒ…å ±ã‚’çµ„ã¿è¾¼ã‚€ãŸã‚ã«ã€current sentenceå†…ã®å˜èªã®dependency(intra-sentence dependency)ã¨ã€current sentenceã¨contextã®é–¢ä¿‚ã‚’åˆ¥ã€…ã«è€ƒæ…®ã™ã‚‹ã€‚context vectorã¨memory cellã®æƒ…å ±ã‹ã‚‰ã€context vectorä¸­ã®ä¸è¦ç®‡æ‰€ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸcontrolled context vectorã‚’ç”Ÿæˆã—ã€LSTMã®outputã®è¨ˆç®—ã«ç”¨ã„ã‚‹ã€‚Later Fusionã¯ã‚·ãƒ³ãƒ—ãƒ«ã ãŒã€corpusãƒ¬ãƒ™ãƒ«ã®language modelingã®å‹¾é…æ¶ˆå¤±å•é¡Œã‚’ç·©å’Œã™ã‚‹ã“ã¨ã‚‚ã§ãã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34413898-99efbaf8-ec29-11e7-94f5-db82eee399b3.png" alt="image" loading="lazy"><br><br><br><br>## è©•ä¾¡<br><br>IMDB, BBC, PennTreebank, Fil9 (cleaned wikipedia corpus)ã®4ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ã€corpus levelã§Perplexityã‚’æ¸¬ã£ãŸã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/34414121-b75b2996-ec2a-11e7-9716-dbbb9006b1b5.png" alt="image" loading="lazy"><br><br><br><br>Late FusionãŒPerplexityã®æ¸›å°‘ã«å¤§ããå¯„ä¸ã—ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34414218-596b373a-ec2b-11e7-85ad-cf98df04ce57.png" alt="image" loading="lazy"><br><br><br><br>PoSã‚¿ã‚°ã”ã¨ã®perplexityã‚’æ¸¬ã£ãŸçµæœã€contextã‚’è€ƒæ…®ã—ãŸå ´åˆã«åè©ã‚„å½¢å®¹è©ã€å‹•è©ã®Perplexityã«æ”¹å–„ãŒè¦‹ã‚‰ã‚ŒãŸã€‚ä¸€æ–¹ã€Coordinate Conjungtion (And, Or, So, Forãªã©)ã‚„é™å®šè©ã€Personal Pronouns (I, You, It, Heãªã©)ã®Perplexityã¯åŠ£åŒ–ã—ãŸã€‚å‰è€…ã¯open-classãªå†…å®¹èªã§ã‚ã‚Šã€å¾Œè€…ã¯closed-classãªæ©Ÿèƒ½èªã§ã‚ã‚‹ã€‚æ©Ÿèƒ½èªã¯grammaticalãªroleã‚’æ±ºã‚ã‚‹ã®ã«å¯¾ã—ã€å†…å®¹èªã¯ãã®åã®é€šã‚Šã€sentenceã‚„discourseã®å†…å®¹ã‚’æ±ºã‚ã‚‹ã‚‚ã®ãªã®ã§ã€æ–‡æ›¸ã®å†…å®¹ã‚’ã‚ˆã‚Šæ‰ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã¨è€ƒå¯Ÿã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1857" target="_blank" rel="noopener noreferrer" class="title-link">Batch Normalization: Accelerating Deep Network Training by Reducing   Internal Covariate Shift, Sergey Ioffe+, ICML'15</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒƒãƒæ­£è¦åŒ–ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€æ·±å±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹å†…éƒ¨å…±å¤‰é‡ã‚·ãƒ•ãƒˆã®å•é¡Œã‚’è§£æ±ºã—ã€é«˜ã„å­¦ç¿’ç‡ã‚’å¯èƒ½ã«ã—ã€åˆæœŸåŒ–ã®æ³¨æ„ã‚’è»½æ¸›ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åŒã˜ç²¾åº¦ã‚’14å€å°‘ãªã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—ã§é”æˆã—ã€ImageNetåˆ†é¡ã§æœ€è‰¯ã®å…¬è¡¨çµæœã‚’4.9%æ”¹å–„ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ¡ãƒ¢ã£ã¦ãªã‹ã£ãŸã®ã§ä»Šæ›´ãªãŒã‚‰è¿½åŠ ã—ãŸ</p>
<p>å…±å¤‰é‡ã‚·ãƒ•ãƒˆã‚„Batch Normalizationã®èª¬æ˜ã¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/261" target="_blank" rel="noopener noreferrer">[Paper Note] Layer Normalization, Ba+, arXiv'16</a>
<br><br>è¨˜è¼‰ã®ã‚¹ãƒ©ã‚¤ãƒ‰ãŒåˆ†ã‹ã‚Šã‚„ã™ã„ã€‚</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/IJCNLP.html" target="_blank" rel="noopener noreferrer">#IJCNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-03-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/266" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unsupervised prediction of acceptability judgements, Lau+, ACL-IJCNLP'15</a>
<span class="snippet"><span>Comment</span><p>æ–‡ã®acceptabilityï¼ˆå®¹èªåº¦ï¼‰è«–æ–‡ã€‚<br><br>æ–‡ã®acceptabilityã¨ã¯ã€native speakerãŒã‚ã‚‹æ–‡ã‚’èª­ã‚“ã ã¨ãã«ã€ãã®æ–‡ã‚’æ­£ã—ã„æ–‡ã¨ã—ã¦å®¹èªã§ãã‚‹åº¦åˆã„ã®ã“ã¨ã€‚<br><br>acceptabilityã‚¹ã‚³ã‚¢ãŒä½ã„ã¨ã€ReadabilityãŒä½ã„ã¨åˆ¤æ–­ã§ãã‚‹ã€‚<br><br>è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã«æ§˜ã€…ãªæ­£è¦åŒ–ã‚’æ–½ã™ã“ã¨ã§ã€acceptabilityã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Interspeech.html" target="_blank" rel="noopener noreferrer">#Interspeech</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2862" target="_blank" rel="noopener noreferrer" class="title-link">Recurrent neural network based language model, Mikolov+, Interspeech'10</a>
<span class="snippet"><span>Comment</span><p>RNNè¨€èªãƒ¢ãƒ‡ãƒ«è«–æ–‡</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2024-12-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1609" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models in Machine Translation, Brants+, EMNLP-CoNLL'07</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€æ©Ÿæ¢°ç¿»è¨³ã«ãŠã‘ã‚‹å¤§è¦æ¨¡ãªçµ±è¨ˆçš„è¨€èªãƒ¢ãƒ‡ãƒ«ã®åˆ©ç‚¹ã‚’å ±å‘Šã—ã€æœ€å¤§2å…†ãƒˆãƒ¼ã‚¯ãƒ³ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸ3000å„„n-gramã®ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã€‚æ–°ã—ã„ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æ‰‹æ³•ã€ŒStupid Backoffã€ã‚’å°å…¥ã—ã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®‰ä¾¡ã§ã€Kneser-Neyã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã«è¿‘ã¥ãã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>N-gramè¨€èªãƒ¢ãƒ‡ãƒ«+ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã®æ‰‹æ³•ã«ãŠã„ã¦ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã—ã¦æ‰±ãˆã‚‹ngramã®ã‚¿ã‚¤ãƒ—æ•°ï¼ˆä»Šã§è¨€ã†ã¨ã“ã‚ã®vocabæ•°ã«è¿‘ã„ï¼‰ã‚’å¢—ã‚„ã—ã¦ã„ã£ãŸã‚‰ã€perplexityã¯æ”¹å–„ã™ã‚‹ã—ã€MTã«ãŠã‘ã‚‹BLEUã‚¹ã‚³ã‚¢ã‚‚æ”¹å–„ã™ã‚‹ã‚ˆï¼ˆBLEUã¯ã‚µãƒã£ã¦ã‚‹ã‹ã‚‚ï¼Ÿï¼‰ã¨ã„ã†è€ƒå¯ŸãŒã•ã‚Œã¦ã„ã‚‹<br><br><img src="https://github.com/user-attachments/assets/035f28db-12c6-4b69-b39f-7eb41581d00c" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1871024428739604777?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Large Language Modelsã¨ã„ã†ç”¨èªãŒåˆ©ç”¨ã•ã‚ŒãŸã®ã¯ã“ã®ç ”ç©¶ãŒåˆã‚ã¦ãªã®ã‹ã‚‚â€¦ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/DataFiltering.html" target="_blank" rel="noopener noreferrer">#DataFiltering</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3385" target="_blank" rel="noopener noreferrer" class="title-link">FindWiki, Guilherme Penedo, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gui_penedo/status/1980665876127879647?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>2023å¹´æ™‚ç‚¹ã§å…¬é–‹ã•ã‚ŒãŸWikipediaãƒ‡ãƒ¼ã‚¿ã‚’ã•ã‚‰ã«æ´—ç·´ã•ã›ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚æ–‡å­—ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã€æ•°å¼ã€latexã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä¿æŒï¼ˆå¾“æ¥ã¯æ¨ã¦ã‚‰ã‚Œã¦ã—ã¾ã†ã“ã¨ãŒå¤šã„ã¨ã®ã“ã¨ï¼‰ã€è¨˜äº‹ã«é–¢ä¿‚ã®ãªã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€infoboxã‚’æœ¬æ–‡ã‹ã‚‰åˆ†é›¢ã—ã¦ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿æŒã™ã‚‹ãªã©ã®ã€åœ°é“ãªå‰å‡¦ç†ã‚’ã—ã¦æ´—ç·´åŒ–ã•ã›ãŸã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/DocParser.html" target="_blank" rel="noopener noreferrer">#DocParser</a>
<a class="button" href="articles/OCR.html" target="_blank" rel="noopener noreferrer">#OCR</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3380" target="_blank" rel="noopener noreferrer" class="title-link">Chandra, datalab-to, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vikparuchuri/status/1980667137606971423?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>SoTA.ã ã£ãŸdots.ocrã¨ã„ã†ãƒ¢ãƒ‡ãƒ«ã‚’outperformã—ã¦ã„ã‚‹æ¨¡æ§˜<br><br>40+ languagesã‚’ã‚µãƒãƒ¼ãƒˆ<p>AI PUBS OpenRAIL-M Modifiedãƒ©ã‚¤ã‚»ãƒ³ã‚¹ğŸ¤”<br>


<a href="https://huggingface.co/datalab-to/chandra/blob/main/LICENSE" target="_blank" rel="noopener noreferrer">https://huggingface.co/datalab-to/chandra/blob/main/LICENSE</a>


</p>
<p>dots.ocrã¯MIT Licence<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3381" target="_blank" rel="noopener noreferrer">dots.ocr, rednote-hilab, 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Inference.html" target="_blank" rel="noopener noreferrer">#Inference</a>
<a class="button" href="articles/MinimalCode.html" target="_blank" rel="noopener noreferrer">#MinimalCode</a>
<a class="button" href="articles/KV%20Cache.html" target="_blank" rel="noopener noreferrer">#KV Cache</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3377" target="_blank" rel="noopener noreferrer" class="title-link">nanochat, karpathy, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/karpathy/status/1977755427569111362?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ–°ãŸãªã‚¹ãƒ”ãƒ¼ãƒ‰ãƒ©ãƒ³ãŒ...!!</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3374" target="_blank" rel="noopener noreferrer" class="title-link">NTTç‰ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã€Œtsuzumi 2ã€, NTTäººé–“æƒ…å ±ç ”ç©¶æ‰€, 2025.10</a>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªMT-benchã§GPT-5ã¨åŒç­‰ç¨‹åº¦ã®æ€§èƒ½ã¨ã®ã“ã¨ã€‚VRAM40GBæœªæº€ã®1GPUã§å‹•ä½œã•ã›ã‚‹ã“ã¨ã‚’å¿µé ­ã«é–‹ç™ºã•ã‚Œã¦ãŠã‚Šã€ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒã€ã‹ã¤å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚‚å®Œå…¨ã«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã—ãƒ‡ãƒ¼ã‚¿ã®æ¨©åˆ©ã€å“è³ªã€ãƒã‚¤ã‚¢ã‚¹ã®ç®¡ç†å¯èƒ½ã«ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Proofs.html" target="_blank" rel="noopener noreferrer">#Proofs</a>
<a class="button" href="articles/Simplification.html" target="_blank" rel="noopener noreferrer">#Simplification</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3365" target="_blank" rel="noopener noreferrer" class="title-link">ProofOptimizer: Training Language Models to Simplify Proofs without Human Demonstrations, Gu+, 2025.10</a>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://proof-optimizer.github.io" target="_blank" rel="noopener noreferrer">https://proof-optimizer.github.io</a>


</p>
<p>LLMã®é€šå¸¸åˆ©ç”¨æ™‚ã®å¿œç­”ã‚‚ï¼ˆãŠãã‚‰ããƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã‚‹ã›ã„ã§ï¼‰é•·ã™ãã‚‹ã¨æ€ã£ã¦ã„ã‚‹ã‘ã©ã€æ•°å­¦ã®è¨¼æ˜ã‚‚é•·ã„ã‚“ã ãªã‚ã€ã¨æ„Ÿã˜ãŸ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/Test-time%20Learning.html" target="_blank" rel="noopener noreferrer">#Test-time Learning</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3351" target="_blank" rel="noopener noreferrer" class="title-link">Knowledge Flow: Scaling Reasoning Beyond the Context Limit, Zhuang+, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yufan_zhuang/status/1980410295790248406?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã®çµæœã‹ã‚‰attemptã‹ã‚‰çŸ¥è­˜ãƒªã‚¹ãƒˆã‚’iterativeã«æ›´æ–°ï¼ˆæ–°ãŸãªçŸ¥è­˜ã‚’è¿½åŠ , å¤ã„çŸ¥è­˜ã‚’å‰Šé™¤ or ä¸¡æ–¹ï¼‰ã—ã¦ã„ãã“ã¨ã«ã‚ˆã£ã¦ã€éå»ã®attemptã‹ã‚‰ã®insightã‚’è“„ç©ã—æ€§èƒ½ã‚’æ”¹å–„ã™ã‚‹ã‚ˆã†ãªæ–°ãŸãªãƒ†ã‚¹ãƒˆã‚¿ã‚¤ãƒ ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®æ çµ„ã¿ãªæ¨¡æ§˜ã€‚sequential test-time scalingãªã©ã¨ã¯ç•°ãªã‚Šã€è¤‡æ•°ã®attemptã«ã‚ˆã£ã¦çŸ¥è­˜ãƒªã‚¹ãƒˆã‚’æ›´æ–°ã™ã‚‹ã“ã¨ã§ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ã®ã§ã€context windowã®åˆ¶ç´„ã‚’å—ã‘ãªã„ã€ã¨ã„ã£ãŸè©±ãªæ¨¡æ§˜ã€‚LLM Agentã«ãŠã‘ã‚‹Test-time learningã¨ã‹ãªã‚Šé¡ä¼¼ã—ãŸã‚³ãƒ³ã‚»ãƒ—ãƒˆã«è¦‹ãˆã‚‹ã€‚<br><br>&lt;img width="754" height="358" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/9a302c5e-ee79-4c17-99e3-0851b5f127c6"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/9a302c5e-ee79-4c17-99e3-0851b5f127c6"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/DocParser.html" target="_blank" rel="noopener noreferrer">#DocParser</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/OCR.html" target="_blank" rel="noopener noreferrer">#OCR</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3344" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-OCR: Contexts Optical Compression, DeepSeek, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vllm_project/status/1980235518706401405?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‹±èªã¨ä¸­å›½èªã§ã¯ä½¿ãˆãã†ã ãŒã€æ—¥æœ¬èªã§ã¯ä½¿ãˆã‚‹ã®ã ã‚ã†ã‹ï¼Ÿp.17 Figure11ã‚’è¦‹ã‚‹ã¨100è¨€èªã«å¯¾ã—ã¦å­¦ç¿’ã—ãŸã¨æ›¸ã‹ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1980160624140456370?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/willccbb/status/1980160732236042604?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OCRãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3360" target="_blank" rel="noopener noreferrer">[Paper Note] OmniDocBench: Benchmarking Diverse PDF Document Parsing with   Comprehensive Annotations, Linke Ouyang+, CVPR'25, 2024.12</a>
<br><br>ï¼ˆDeepSeek-OCRã®ä¸»é¡Œã¯OCRã®æ€§èƒ½å‘ä¸Šã¨ã„ã†ã‚ã‘ã§ã¯ãªã„ã‚ˆã†ã ãŒï¼‰</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nrehiew_/status/1980635199273889895?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹+ãƒã‚¤ãƒ³ãƒˆè§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1980642191950090585?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kangwook_lee/status/1980709454522744902?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>textxã‚’imageã¨ã—ã¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹è©±ã¯ä»¥ä¸‹ã®2023å¹´ã®ICLRã®ç ”ç©¶ã§ã‚‚ã‚„ã‚‰ã‚Œã¦ã„ã‚‹ã‚ˆã¨ã„ã†ãƒã‚¹ãƒˆ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3370" target="_blank" rel="noopener noreferrer">[Paper Note] Language Modelling with Pixels, Phillip Rust+, ICLR'23, 2022.07</a>
<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nielsrogge/status/1980559120760791125?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3375" target="_blank" rel="noopener noreferrer">[Paper Note] Text or Pixels? It Takes Half: On the Token Efficiency of Visual Text
  Inputs in Multimodal LLMs, Yanhong Li+, arXiv'25, 2025.10</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3363" target="_blank" rel="noopener noreferrer">[Paper Note] PixelWorld: Towards Perceiving Everything as Pixels, Zhiheng Lyu+, arXiv'25, 2025.01</a>
</p>
<p>é–¢é€£:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/askalphaxiv/status/1980722479405678593?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3357" target="_blank" rel="noopener noreferrer">[Paper Note] Glyph: Scaling Context Windows via Visual-Text Compression, Jiale Cheng+, arXiv'25, 2025.10</a>
</p>
<p>literature:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/awinyimgprocess/status/1980506449706119642?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ä¸Šè¨˜ãƒã‚¹ãƒˆã§ã¯æœ¬ç ”ç©¶ã¯ã“ã‚Œã‚‰literatureã‚’å®Œå…¨ã«ç„¡è¦–ã— â€œan initial investigation into the feasibility of compressing long contexts via optical 2D mapping.â€ ã¨ä¸»å¼µã—ã¦ã„ã‚‹ã®ã§ã€å…ˆè¡Œç ”ç©¶ã‚’èªè­˜ã—å¼•ç”¨ã™ã¹ãã ã¨è¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã‚ˆã†ã ã€‚</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/PRM.html" target="_blank" rel="noopener noreferrer">#PRM</a>
<a class="button" href="articles/Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<a class="button" href="articles/Cultural.html" target="_blank" rel="noopener noreferrer">#Cultural</a>
<a class="button" href="articles/Emotion.html" target="_blank" rel="noopener noreferrer">#Emotion</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3339" target="_blank" rel="noopener noreferrer" class="title-link">Andrej Karpathy â€” AGI is still a decade away, DWARKESH PATEL, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chemical_tree/status/1980084549158904131?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- In-context Steerbility: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3247" target="_blank" rel="noopener noreferrer">[Paper Note] Spectrum Tuning: Post-Training for Distributional Coverage and
  In-Context Steerability, Taylor Sorensen+, arXiv'25, 2025.10</a>
<br><br>ï¼ˆæ•´ç†ã™ã‚‹ã¨æ¥½ã—ãã†ãªã®ã§å¾Œã§é–¢é€£ã—ãã†ãªç ”ç©¶ã‚’ä»–ã«ã‚‚ã¾ã¨ã‚ã‚‹ï¼‰</p>
<p>ã¨ã¦ã‚‚å‹‰å¼·ã«ãªã‚‹ï¼AIã«ä»£æ›¿ã•ã‚Œãªã„20%, 1%ã«ãªã‚‹ã«ã¯æœãŸã—ã¦</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tydsh/status/1980432024470188252?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3338" target="_blank" rel="noopener noreferrer" class="title-link">modded-nanogpt medium world record: Re-using intermediate activations in the output latents, shimu's blog, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stochasticchasm/status/1979985191356731663?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3293" target="_blank" rel="noopener noreferrer" class="title-link">Evaluating Long Context ï¼ˆReasoningï¼‰ Ability, wh., 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nrehiew_/status/1978838046242898069?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/RecursiveModels.html" target="_blank" rel="noopener noreferrer">#RecursiveModels</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3285" target="_blank" rel="noopener noreferrer" class="title-link">Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities, Zhang+, 2025.10</a>
<span class="snippet"><span>Comment</span><p>blog:


<a href="https://alexzhang13.github.io/blog/2025/rlm/" target="_blank" rel="noopener noreferrer">https://alexzhang13.github.io/blog/2025/rlm/</a>


<br>super basic implementation:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/a1zhang/status/1978948676287340753?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yampeleg/status/1978511454358683729?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<span class="issue_date">Issue Date: 2025-10-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3279" target="_blank" rel="noopener noreferrer" class="title-link">State of VLA Research at ICLR 2026, Moritz Reuss, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/moritz_reuss/status/1978048330279408054?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/PII.html" target="_blank" rel="noopener noreferrer">#PII</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3257" target="_blank" rel="noopener noreferrer" class="title-link">LFM2-350M-PII-Extract-JP, LiquidAI, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/liquidai_/status/1977720769808335143?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3256" target="_blank" rel="noopener noreferrer" class="title-link">Ring-1T, inclusionAI, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1977829949290733892?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>inclusionAIã‹ã‚‰ç¶šã€…ã¨frontierãªãƒ¢ãƒ‡ãƒ«ãŒå‡ºã¦ãã¦ã„ã‚‹ã€‚</p>
<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆãŒå…¬é–‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3388" target="_blank" rel="noopener noreferrer">[Paper Note] Every Step Evolves: Scaling Reinforcement Learning for Trillion-Scale
  Thinking Model, Ling Team+, arXiv'25, 2025.10</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<span class="issue_date">Issue Date: 2025-10-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3246" target="_blank" rel="noopener noreferrer" class="title-link">MAMBA-3: IMPROVED SEQUENCE MODELING USING STATE SPACE PRINCIPLES, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jundemorsenwu/status/1977664753011916859?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1977884962767643015?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MLOps.html" target="_blank" rel="noopener noreferrer">#MLOps</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-10-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3243" target="_blank" rel="noopener noreferrer" class="title-link">Harnessã‚’åˆ©ç”¨ã—ã¦LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡ã‚’è‡ªå‹•åŒ–ã™ã‚‹, LINEãƒ¤ãƒ•ãƒ¼ ãƒ†ãƒƒã‚¯ãƒ–ãƒ­ã‚°, 2024.12</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-10-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3226" target="_blank" rel="noopener noreferrer" class="title-link">K2 Vendor Verifier, MoonshotAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>Kimi K2ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é–“ã§ã®ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®æ€§èƒ½ã®é•ã„ã‚’ç¢ºèªã§ãã‚‹</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kimi_moonshot/status/1976926483319763130?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2701" target="_blank" rel="noopener noreferrer">Kimi-K2-Instruct-0905, MoonshotAI, 2025.09</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2195" target="_blank" rel="noopener noreferrer">Kimi K2: Open Agentic Intelligence, moonshotai, 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3223" target="_blank" rel="noopener noreferrer" class="title-link">STATE OF AI REPORT 2025, Nathan Benaich, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1976538749744918581?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1977313924522590445?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3218" target="_blank" rel="noopener noreferrer" class="title-link">A History of Large Language Models, Gregory Gundersen, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/syhw/status/1976252569501753708?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3198" target="_blank" rel="noopener noreferrer" class="title-link">Tora: Torchtune-LoRA for RL, shangshang-wang, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1976443792850092464?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1935" target="_blank" rel="noopener noreferrer">[Paper Note] Tina: Tiny Reasoning Models via LoRA, Shangshang Wang+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<span class="issue_date">Issue Date: 2025-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3180" target="_blank" rel="noopener noreferrer" class="title-link">Jamba Reasoning 3B, AI21Labs, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1976029116508856393?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3155" target="_blank" rel="noopener noreferrer" class="title-link">LFM2-8B-A1B: An Efficient On-device Mixture-of-Experts, LiquidAI, 2025.10</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/LiquidAI/LFM2-8B-A1B" target="_blank" rel="noopener noreferrer">https://huggingface.co/LiquidAI/LFM2-8B-A1B</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1975629951580971026?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¥æœ¬èªã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã¨ã®ã“ã¨</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3149" target="_blank" rel="noopener noreferrer" class="title-link">terminal-bench: a benchmark for ai agents in terminal environments, laude-institute, </a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1975468544973545810?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3147" target="_blank" rel="noopener noreferrer" class="title-link">ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ãŒå¤§å¹…ã«å¼·åŒ–ã•ã‚ŒãŸPLaMo 2.1 Primeã®æä¾›é–‹å§‹, PFN, 2025.10</a>
<span class="snippet"><span>Comment</span><p>ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®tool callingã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ã®Simple, Multipleï¼ˆãã‚Œãã‚Œå˜ä¸€ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã€è¤‡æ•°ã®ãƒ„ãƒ¼ãƒ«ã®ä¸­ã‹ã‚‰é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™èƒ½åŠ›ï¼‰ã§BFCVv3ã§GPT-5è¶…ãˆã€‚ãŸã ã—GPT-5ã¯ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã§ã¯ãªããƒ¦ãƒ¼ã‚¶ã¨å¯¾è©±ã™ã‚‹å‚¾å‘ã«ã‚ã‚‹ãŸã‚ã€chatã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã“ã¡ã‚‰ã®æ–¹ãŒæœ‰ç”¨ãªå ´åˆãŒã‚ã‚‹ã®ã§å…¨ã¦ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã§PLaMoãŒä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã€ã¨ã„ã†æ³¨é‡ˆãŒã¤ã„ã¦ã„ã‚‹ã€‚ã‚ˆã‚Šå®Ÿé¨“çš„ãªç’°å¢ƒã§ã‚ã‚‹Live Multipleã§ã¯GPT-5ã®æ–¹ãŒã‚¹ã‚³ã‚¢ãŒé«˜ã„æ¨¡æ§˜ã€‚<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1875" target="_blank" rel="noopener noreferrer">BFCLv2, UC Berkeley, 2024.08</a>
<br><br>å˜ä¸€å‘¼ã³å‡ºã—ã€è¤‡æ•°å®šç¾©ã•ã‚Œã¦ã„ã‚‹ä¸­ã‹ã‚‰é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™ã“ã¨ã§æ¸ˆã‚€ã‚ˆã†ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã®å ´åˆã¯æ¤œè¨ã®ä½™åœ°ãŒã‚ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚ãŸã ã—ç´°ã‹ã„reasoning_effortã‚„verbosityç­‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šãŒè¨˜è¿°ã•ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã®ã§ã€ãã®è¾ºã¯ã©ã†ãªã‚“ã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3130" target="_blank" rel="noopener noreferrer" class="title-link">PipelineRL, Piche+, ServiceNow, 2025.04</a>
<span class="snippet"><span>Comment</span><p>code:


<a href="https://github.com/ServiceNow/PipelineRL" target="_blank" rel="noopener noreferrer">https://github.com/ServiceNow/PipelineRL</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vllm_project/status/1974732295627301254?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Inflight Weight Updates</p>
<p>ï¼ˆã“ã®è¾ºã®ç´°ã‹ã„å®Ÿè£…ã®è©±ã¯ã‚ã¾ã‚Šè©³ã—ããªã„ã®ã§èª¤ã‚ŠãŒã‚ã‚‹å¯èƒ½æ€§ãŒçµæ§‹ã‚ã‚Šã¾ã™ï¼‰<br>é€šå¸¸ã®on-policy RLã§ã¯å…¨ã¦ã®GPUä¸Šã§ã®sequenceã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆãŒçµ‚ã‚ã‚‹ã¾ã§å¾…ã¡ã€å…¨ã¦ã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆå®Œäº†å¾Œã«ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’æ›´æ–°ã™ã‚‹ãŸã‚ã€é•·ã„sequenceã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚’ã™ã‚‹GPUã®å‡¦ç†ãŒçµ‚ã‚ã‚‹ã¾ã§ã€çŸ­ã„sequenceã®ç”Ÿæˆã§æ¸ˆã‚“ã GPUã¯å¾…æ©Ÿã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚ä¸€æ–¹ã€PipelineRLã¯sequenceã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã®é€”ä¸­ã§ã‚‚é‡ã¿ã‚’æ›´æ–°ã—ã€ç”Ÿæˆé€”ä¸­ã®sequenceã¯å¤ã„KV Cacheã‚’ä¿æŒã—ãŸã¾ã¾æ–°ã—ã„é‡ã¿ã§sequenceã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚’ç¶™ç¶šã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚ŠGPU Utilizationã‚’æœ€å¤§åŒ–ã§ãã‚‹ï¼ˆãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆå®Œäº†ã®ãŸã‚ã®å¾…æ©Ÿæ™‚é–“ãŒç„¡ããªã‚‹ï¼‰ã€‚ã¾ãŸã€ä¸€è¦‹å¤ã„KV Cacheã‚’å‰æã«æ–°ãŸãªé‡ã¿ã§ç¶™ç¶šã—ã¦éƒ¨åˆ†sequenceã‚’ç¶™ç¶šã™ã‚‹ã¨ãƒãƒªã‚·ãƒ¼ã®gapã«ã‚ˆã‚Šæ€§èƒ½ãŒæ‚ªåŒ–ã™ã‚‹ã‚ˆã†ã«æ€ãˆã‚‹ãŒã€æ€§èƒ½ãŒæ‚ªåŒ–ã—ãªã„ã“ã¨ãŒå®Ÿé¨“çš„ã«ç¤ºã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/6794927a-3fa9-4a68-ba48-d112d495e0ab" alt="image" loading="lazy"><br><br>Conventional RLã®ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰éƒ¨åˆ†ã‚’è¦‹ã‚‹ã¨ã¨ã¦ã‚‚ã‚ã‹ã‚Šã‚„ã™ãã¦å‚è€ƒã«ãªã‚‹ã€‚Conventional RLï¼ˆPPOã¨ã‹ï¼‰ã§ã¯ã€å®Ÿè£…ä¸Šã¯è¤‡æ•°ã®ãƒãƒƒãƒã«åˆ†ã‘ã¦é‡ã¿ã®æ›´æ–°ãŒè¡Œã‚ã‚Œã‚‹ï¼ˆã‚‰ã—ã„ï¼‰ã€‚ã“ã®ã¨ãã€GPUã®åˆ©ç”¨ã‚’æœ€å¤§åŒ–ã—ã‚ˆã†ã¨ã™ã‚‹ã¨ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å¤§ããã›ã–ã‚‹ã‚’å¾—ãªã„ã€‚ã“ã®ãŸã‚ã€é€æ¬¡æ›´æ–°ã‚’ã—ãŸã¨ãã®policyã®gapãŒã©ã‚“ã©ã‚“è“„ç©ã—ã¦ã„ãå¤§ãããªã‚‹ï¼ˆ=ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã§ç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ãŒã€å®Ÿéš›ã«é‡ã¿æ›´æ–°ã™ã‚‹ã¨ãã«ã¯lagãŒè“„ç©ã•ã‚Œã¦ã„ãã©ã‚“ã©ã‚“off-policyãƒ‡ãƒ¼ã‚¿ã«å¤‰åŒ–ã—ã¦ã„ã£ã¦ã—ã¾ã†ï¼‰ã¨ã„ã†å¼Šå®³ãŒã‚ã‚‹æ¨¡æ§˜ã€‚ã‹ã¨ã„ã£ã¦lagã‚’æœ€å°ã«ã™ã‚‹ãŸã‚ã«å°ã•ã„ãƒãƒƒãƒã‚µã‚¤ã‚ºã«ã™ã‚‹ã¨gpuã®åŠ¹ç‡ã‚’åœ§å€’çš„ã«çŠ ç‰²ã«ã™ã‚‹ã®ã§ã§ããªã„ã€‚Inflight Weight Updatesã§ã¯ã“ã®ã‚ˆã†ãªãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è§£æ±ºã§ãã‚‹æ¨¡æ§˜ã€‚<br><br>ã¾ãŸã€trainerã¨inferenceéƒ¨åˆ†ã¯å®Œå…¨ã«ç‹¬ç«‹ã•ã›ã‚‰ã‚Œã€ã‹ã¤plug-and-playã§é‡ã¿ã‚’æ›´æ–°ã™ã‚‹ã€ã¨ã„ã£ãŸä½¿ã„æ–¹ã‚‚æƒ³å®šã§ãã‚‹æ¨¡æ§˜ã€‚</p>
<p>ã‚ã¨ã“ã‚Œã¯ä½™è«‡ã ãŒã€å¼•ç”¨ãƒã‚¹ãƒˆã®ä¸»ã¯ä¸‹è¨˜ç ”ç©¶ã§attentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æœ€åˆã«ææ¡ˆã—ãŸBahdanauæ°ã§ã‚ã‚‹ã€‚<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1954" target="_blank" rel="noopener noreferrer">Neural Machine Translation by Jointly Learning to Align and Translate, Dzmitry Bahdanau+, ICLR'15</a>
</p>
<p>ç¶šå ±:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dbahdanau/status/1974889569607876747?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3129" target="_blank" rel="noopener noreferrer" class="title-link">Frontier AI performance becomes accessible on consumer hardware within a year, EPOCH AI, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/natolambert/status/1974545304973160648?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3125" target="_blank" rel="noopener noreferrer" class="title-link">CODA: Coding LM via Diffusion Adaption, Chen+, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscreamnearby/status/1974461551072690248?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/Salesforce/CoDA-v0-Instruct" target="_blank" rel="noopener noreferrer">https://huggingface.co/Salesforce/CoDA-v0-Instruct</a>


<br><br>cc-by-nc-4.0</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3118" target="_blank" rel="noopener noreferrer" class="title-link">PFN LLMã‚»ãƒŸãƒŠãƒ¼, PFN, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1973924269177668012?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3113" target="_blank" rel="noopener noreferrer" class="title-link">Diffusion Language Models are Super Data Learners, Ni+, 2022.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tianyupang1/status/1974118238415172107?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3102" target="_blank" rel="noopener noreferrer" class="title-link">Effective context engineering for AI agents, Anthropic, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/anthropicai/status/1973098580060631341?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Anthropicã«ã‚ˆã‚‹ContextEngineeringã«é–¢ã™ã‚‹ãƒ–ãƒ­ã‚°ã€‚<br>ã–ãƒ¼ã£ã¨ã¿ãŸæ„Ÿã˜åŸºç¤çš„ãªå®šç¾©ã‹ã‚‰ãªãœé‡è¦ãªã®ã‹ã€retrievalã®æ´»ç”¨ã€longnhorizon taskã§ã®æ´»ç”¨ã€compaction(summarization)ãªã©ã€å¹…åºƒã„ãƒˆãƒ”ãƒƒã‚¯ãŒç¶²ç¾…ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p>
<p>æœ€æ–°ã‚µãƒ¼ãƒ™ã‚¤ã¯ã“ã¡ã‚‰<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2256" target="_blank" rel="noopener noreferrer">[Paper Note] A Survey of Context Engineering for Large Language Models, Lingrui Mei+, arXiv'25</a>
</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_stakaya/status/1974228183450071048?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3090" target="_blank" rel="noopener noreferrer" class="title-link">OpenMoE 2: Sparse Diffusion Language Models, Ni+, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nijinjie/status/1973747616082186349?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3081" target="_blank" rel="noopener noreferrer" class="title-link">Ming-UniVision: Joint Image Understanding and Generation via a Unified Continuous Tokenizer, inclusionAI, 2025.10</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/inclusionAI/Ming-UniVision-16B-A3B" target="_blank" rel="noopener noreferrer">https://huggingface.co/inclusionAI/Ming-UniVision-16B-A3B</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1973894009551810952?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Editing.html" target="_blank" rel="noopener noreferrer">#Editing</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3080" target="_blank" rel="noopener noreferrer" class="title-link">Ming-UniAudio: Speech LLM for Joint Understanding, Generation and Editing with Unified Representation, inclusionAI, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1973147903784001665?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Ming-Omniã®å¾Œç¶™ãƒ¢ãƒ‡ãƒ«ã§ã€ã‚¹ãƒ”ãƒ¼ãƒã«ç‰¹åŒ–ã—ã¦æ›¸ãèµ·ã“ã—ã€ç†è§£ã€ç·¨é›†ãªã©ãŒã§ãã‚‹ãƒ¢ãƒ‡ãƒ«</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2300" target="_blank" rel="noopener noreferrer">[Paper Note] Ming-Omni: A Unified Multimodal Model for Perception and Generation, Inclusion AI+, arXiv'25</a>
</p>
<p>HF:


<a href="https://huggingface.co/inclusionAI/Ming-UniAudio-16B-A3B" target="_blank" rel="noopener noreferrer">https://huggingface.co/inclusionAI/Ming-UniAudio-16B-A3B</a>


</p>
<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/antlingagi/status/1974134429712007675?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/API.html" target="_blank" rel="noopener noreferrer">#API</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3077" target="_blank" rel="noopener noreferrer" class="title-link">Tinker is a training API for {developers, builders, researchers}, THINKING MACHINES, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/karpathy/status/1973468610917179630?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>THINKING MACHINESã«ã‚ˆã‚‹OpenWeightãƒ¢ãƒ‡ãƒ«ã‚’LoRAã«ã‚ˆã£ã¦post-trainingã™ã‚‹ãŸã‚ã®APIã€‚Qwenã¨Llamaã‚’ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã‚µãƒãƒ¼ãƒˆã€‚ç¾åœ¨ã¯Betaã§waitlistã«ç™»éŒ²ã™ã‚‹å¿…è¦ãŒã‚ã‚‹æ¨¡æ§˜ã€‚</p>
<p>ï¼ˆLlamaã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯ãƒ¦ãƒ¼ã‚¶æ•°ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãŒ7å„„äººã‚’è¶…ãˆãŸã‚‰Metaã®è¨±è«¾ãŒãªã„ã¨åˆ©ç”¨ã§ããªããªã‚‹æ°—ãŒã™ã‚‹ãŒã€æœãŸã—ã¦ã€ã¨ãµã¨æ€ã£ãŸï¼‰</p>
<p>ã“ã®å‰ã®ãƒ–ãƒ­ã‚°ã¯ã“ã®ãŸã‚ã®PRã‚‚å…¼ã­ã¦ã„ãŸã¨è€ƒãˆã‚‰ã‚Œã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3040" target="_blank" rel="noopener noreferrer">LoRA Without Regret, Schulman+, THINKING MACHINES, 2025.09</a>
</p>
<p>ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã“ã¡ã‚‰:<br>


<a href="https://tinker-docs.thinkingmachines.ai" target="_blank" rel="noopener noreferrer">https://tinker-docs.thinkingmachines.ai</a>


<br><br>Tinkerã¯ã€å¾“æ¥ã®<br>- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰<br>- å­¦ç¿’ã‚¸ãƒ§ãƒ–ã‚’èµ°ã‚‰ã›ã‚‹<br><br>ã¨ã„ã†ã‚¹ã‚¿ã‚¤ãƒ«ã§ã¯ãªãã€ãƒ­ãƒ¼ã‚«ãƒ«ã®ã‚³ãƒ¼ãƒ‰ã§stepå˜ä½ã®å­¦ç¿’ã®ãƒ«ãƒ¼ãƒ—ã‚’æ›¸ãä»¥ä¸‹ã‚’å®Ÿè¡Œã™ã‚‹:<br>- forward_backwardãƒ‡ãƒ¼ã‚¿, loss_functionã‚’APIã«é€ã‚‹<br>  - ã“ã‚Œã«ã‚ˆã‚Šå‹¾é…ã‚’Tinkerå´ãŒè“„ç©ã™ã‚‹<br>- optim_step: è“„ç©ã—ãŸå‹¾é…ã«åŸºã¥ã„ã¦ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°ã™ã‚‹<br>- sample: ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã™ã‚‹<br>- save_stateç­‰: é‡ã¿ã®ä¿å­˜ã€ãƒ­ãƒ¼ãƒ‰ã€optimizerã®stateã®ä¿å­˜ã‚’ã™ã‚‹<br><br>ã“ã‚Œã‚‰stepå˜ä½ã®å­¦ç¿’ã«å¿…è¦ãªãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–ãªã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ã®ã¿ã‚’APIã¨ã—ã¦æä¾›ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€CPUãƒã‚·ãƒ³ã§ã€ç‹¬è‡ªã«å®šç¾©ã—ãŸloss, dataset(ã‚ã‚‹ã„ã¯RLç”¨ã®environmentï¼‰ã‚’ç”¨ã„ã¦ã€å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ãã‚‹ã—ã€åˆ†æ•£å­¦ç¿’ã®è¤‡é›‘ã•ã‹ã‚‰è§£æ”¾ã•ã‚Œã‚‹ã€ã¨ã„ã†ä»£ç‰©ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚LoRAã®ã¿ã«å¯¾å¿œã—ã¦ã„ã‚‹ã€‚<br><br>ãªãŠã€stepå˜ä½ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¯å›é€ä¿¡ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã®ã§ã€stepã”ã¨ã«é€šä¿¡ã®ã‚ªãƒ¼ãƒãƒ˜ãƒƒãƒ‰ãŒç™ºç”Ÿã™ã‚‹ãªã‚“ã¦ã€Tinkerå´ãŒGPUã‚’æœ€å¤§é™ã«æ´»ç”¨ã§ããªã„ã®ã§ã¯ãªã„ã‹ã€‚è¨­è¨ˆã¨ã—ã¦ã©ã†ãªã‚“ã ï¼Ÿã¨ã„ã†ç‚¹ã«ã¤ã„ã¦ã¯ã€ä¸‹è¨˜ãƒ–ãƒ­ã‚°ãŒè€ƒå¯Ÿã‚’ã—ã¦ã„ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3134" target="_blank" rel="noopener noreferrer">Anatomy of a Modern Finetuning API, Benjamin Anderson, 2025.10</a>
<br><br>ã–ã£ãã‚Šè¨€ã†ã¨ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆã‚’å‰æã«ç‰¹å®šãƒ¦ãƒ¼ã‚¶ãŒGPUã‚’å æœ‰ã™ã‚‹ã®ã§ã¯ãªãã€è¤‡æ•°ãƒ¦ãƒ¼ã‚¶ã§å…±æœ‰ã™ã‚‹ã®ã§ã¯ãªã„ã‹ã€adapterã®ç€è„±ã®ã‚ªãƒ¼ãƒãƒ˜ãƒƒãƒ‰ã¯éå¸¸ã«å°ã•ã„ã®ã§ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆã«ã—ã¦ã‚‚ï¼ˆèª°ã‹ã®ãƒ‡ãƒ¼ã‚¿ã®å‹¾é…è¨ˆç®—ãŒçµ‚ã‚ã£ãŸã‚‰LoRAã‚¢ãƒ€ãƒ—ã‚¿ã‚’å·®ã—æ›¿ãˆã¦åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ã®å‹¾é…è¨ˆç®—ã‚’ã™ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚’ç¹°ã‚Šè¿”ã›ã°è‰¯ã„ã®ã§å¾…æ©Ÿæ™‚é–“ã¯ã‹ãªã‚Šå°ã•ããªã‚‹ã¯ãšã§ã€ï¼‰GPUãŒéŠã¶æ™‚é–“ãŒç”Ÿã˜ãªã„ã®ã§ãƒªã‚½ãƒ¼ã‚¹ã‚’Tinkerå´ã¯æœ€å¤§é™ã«æ´»ç”¨ã§ãã‚‹ã®ã§ã¯ãªã„ã‹ã€ã¨ã„ã£ãŸè€ƒå¯Ÿ/ä»®èª¬ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚</p>
<p>æ‰€è¦‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cameron_chann/status/1977040926364381316?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Asyncãªè¨­å®šã§RLã—ã¦ã‚‚Syncãªå ´åˆã¨æ€§èƒ½ã¯åŒç­‰ã ãŒã€å­¦ç¿’ãŒå¤§å¹…ã«é«˜é€ŸåŒ–ã•ã‚Œã¦å¬‰ã—ã„ã¨ã„ã†è©±ãªæ¨¡æ§˜ï¼ˆãŠã¾ã‘ã«rate limitãŒç¾åœ¨ã¯å­˜åœ¨ã™ã‚‹ã®ã§ä»Šå¾Œã‚ˆã‚Šãƒ–ãƒ¼ã‚¹ãƒˆã•ã‚Œã‚‹ã‹ã‚‚</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<span class="issue_date">Issue Date: 2025-10-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3072" target="_blank" rel="noopener noreferrer" class="title-link">IBM Granite 4.0: hyper-efficient, high performance hybrid models for enterprise, IBM, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1973837846898184596?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Mamba2ã¨transformerã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã§ã€æ¯”ç‡ã¯9:1ã¨Mamba2ãƒ–ãƒ­ãƒƒã‚¯ãŒå¤šã‚ã‚‰ã—ã„ã€‚Mamba2ã®æ©æµã«ã‚ˆã‚Šlokg-contextæ™‚ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒ70ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆå‰Šæ¸›ã•ã‚Œã‚‹ã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3061" target="_blank" rel="noopener noreferrer" class="title-link">2025å¹´10æœˆ1æ—¥ å›½ç«‹æƒ…å ±å­¦ç ”ç©¶æ‰€ã«ãŠã‘ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã¸ã®å”åŠ›ã«ã¤ã„ã¦,  å›½ç«‹å›½ä¼šå›³æ›¸é¤¨, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yhkondo/status/1973324514718261267?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¥æœ¬èªLLMã®é€²å±•ã«æ¥µã‚ã¦é‡è¦ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨æ€ã‚ã‚Œã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2025-10-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3054" target="_blank" rel="noopener noreferrer" class="title-link">RLP: Reinforcement as a Pretraining Objective, Hatamizadeh+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ahatamiz1/status/1973115674701734277?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2031" target="_blank" rel="noopener noreferrer">[Paper Note] Reinforcement Pre-Training, Qingxiu Dong+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2968" target="_blank" rel="noopener noreferrer">[Paper Note] Reinforcement Learning on Pre-Training Data, Siheng Li+, arXiv'25, 2025.09</a>
</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/snat02792153/status/1973106638891471266?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1974242857935311160?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1974959939622989999?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3050" target="_blank" rel="noopener noreferrer" class="title-link">GLM-4.6: Advanced Agentic, Reasoning and Coding Capabilies, Zhipu AI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2406" target="_blank" rel="noopener noreferrer">[Paper Note] GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models, GLM-4. 5 Team+, arXiv'25</a>
</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1972932103462400133?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¶šå ±:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1972951657542545619?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Artificial Intelligenceã«ã‚ˆã‚‹è©•ä¾¡:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1975425594679496979?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>OpenWeightãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã®ãƒ™ãƒ³ãƒã‚¹ã‚³ã‚¢</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3046" target="_blank" rel="noopener noreferrer" class="title-link">Introducing Claude Sonnet 4.5, Anthropic, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/claudeai/status/1972706807345725773?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Claude Sonnet 4.5 ç™ºè¡¨é–¢é€£æƒ…å ±ã¾ã¨ã‚:<br>è¨˜äº‹:


<a href="https://zenn.dev/schroneko/articles/claude-sonnet-4-5" target="_blank" rel="noopener noreferrer">https://zenn.dev/schroneko/articles/claude-sonnet-4-5</a>


<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/schroneko/status/1972728043673452902?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ–ãƒ­ã‚°ã‚’èª­ã‚€ã¨Imagine with Claudeã®æ–¹ãŒã‚€ã—ã‚æ°—ã«ãªã‚‹...ï¼ˆæ®‹å¿µãªãŒã‚‰èª²é‡‘ã—ã¦ã„ãªã„ï¼‰<br>


<a href="https://claude.ai/login?returnTo=%2Fimagine" target="_blank" rel="noopener noreferrer">https://claude.ai/login?returnTo=%2Fimagine</a>


</p>
<p>Artificial Intelligenceã«ã‚ˆã‚‹è©•ä¾¡:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1972854742167761204?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3042" target="_blank" rel="noopener noreferrer" class="title-link">LLM ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã¨å¤–æŒ¿, ä½è—¤ç«œé¦¬, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/joisino_/status/1972580573341470811?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3035" target="_blank" rel="noopener noreferrer" class="title-link">Ring-1T-preview, inclusionAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1972726135294394587?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<a class="button" href="articles/Sparse.html" target="_blank" rel="noopener noreferrer">#Sparse</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3033" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-V3.2-Exp: Boosting Long-Context Efficiency with DeepSeek Sparse Attention, DeepSeek-AI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/danielhanchen/status/1972613546119991791?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>DeepSeek Sparse Attentionãƒã‚¤ãƒ³ãƒˆè§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vllm_project/status/1972617272901644345?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1972802544863678832?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>DSAå›³è§£:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/awnihannun/status/1972763521185436088?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1972650237266465214?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/deepseek_ai/status/1972604768309871061?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3032" target="_blank" rel="noopener noreferrer" class="title-link">Build A Reasoning Model ï¼ˆFrom Scratchï¼‰, Sebastian Raschka, 2025.05</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1972294357635178938?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>reasoningãƒ¢ãƒ‡ãƒ«ã«é–¢ã™ã‚‹pyTorchã«ã‚ˆã‚‹ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒã§ã®å®Ÿè£…ã¨ä¸å¯§ãªè§£èª¬ã¤ãã®NotebookãŒå…¬é–‹ã•ã‚Œã¦ãŠã‚Šå†…éƒ¨ã®åŸºç¤çš„ãªæŒ™å‹•ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã¨ã¦ã‚‚è‰¯ã•ãã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3028" target="_blank" rel="noopener noreferrer" class="title-link">Failing to Understand the Exponential, Again, Julian Schrittwieser, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aidan_mclau/status/1972091890318430621?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1842" target="_blank" rel="noopener noreferrer">Measuring AI Ability to Complete Long Tasks, Thomas Kwa+, arXiv'25, 2025.03</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3027" target="_blank" rel="noopener noreferrer">GDPVAL: EVALUATING AI MODEL PERFORMANCE ON REAL-WORLD ECONOMICALLY VALUABLE TASKS, Patwardhan+, 2025.09</a>
</p>
<p>AIã®æŒ‡æ•°é–¢æ•°çš„ãªæˆé•·ã¯ç¶šã„ã¦ã„ã‚‹ãã¨ã„ã†è©±ã€‚<br><br>ä»¥ä¸‹ã¯ç®¡ç†äººã®æ„Ÿæƒ³ã ãŒã€å€‹ã€…ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§è¦‹ãŸã‚‰ã‚µãƒã£ã¦ãã¦ã„ã‚‹ï¼ˆæ˜”ã‚ˆã‚Šä¼¸ã³ä»£ãŒå°ã•ã„ï¼‰ã‚ˆã†ã«æ„Ÿã˜ã‚‹ãŒã€äººé–“ãŒå®Ÿæ–½ã™ã‚‹è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹ä¸Šè¨˜ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãªã©ã‚’è¦‹ã‚‹ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¯ç¶šã„ã¦ã„ã‚‹ï¼ˆã‚€ã—ã‚åŠ é€Ÿã—ã¦ã„ã‚‹æ„ŸãŒã‚ã‚‹ï¼‰ã€‚ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¿ã‚¹ã‚¯ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ä¼¸ã³ã¯å°ã•ãã¨ã‚‚ã€ãã‚Œã‚‰ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¿ã‚¹ã‚¯ã®ç©ã¿é‡ã­ã«ã‚ˆã£ã¦è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã¯å®Ÿæ–½ã•ã‚Œã‚‹ã®ã§ã€ï¼ˆç¾å­˜ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒæ¸¬å®šã§ãã¦ã„ã‚‹èƒ½åŠ›ã¯LLMã®éƒ¨åˆ†çš„ãªèƒ½åŠ›ã ã‘ãªã“ã¨ã‚‚é‘‘ã¿ã‚‹ã¨ï¼‰ã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã—ãŸæ™‚ã®ä¼¸ã³ã¯å®Ÿã¯å¤§ãã‹ã£ãŸã‚Šã™ã‚‹ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¯ç¶šã„ã¦ã„ã‚‹ï¼‰ã®ã§ã¯ãªã„ã‹ã€ã¨ã„ã†æ„Ÿæƒ³ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3027" target="_blank" rel="noopener noreferrer" class="title-link">GDPVAL: EVALUATING AI MODEL PERFORMANCE ON REAL-WORLD ECONOMICALLY VALUABLE TASKS, Patwardhan+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>ç±³å›½ã®GDPã‚’ç‰½å¼•ã™ã‚‹9ã¤ã®ä»£è¡¨çš„ãªç”£æ¥­ã«ãŠã„ã¦ã€44ã®è·ç¨®ã‚’é¸å®šã—ã€åˆè¨ˆ1320ä»¶ã®å®Ÿå‹™ã‚¿ã‚¹ã‚¯ã‚’è¨­è¨ˆã—ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯å¹³å‡14å¹´ç¨‹åº¦ã®çµŒé¨“ã‚’æŒã¤å°‚é–€å®¶ãŒå®Ÿéš›ã®æ¥­å‹™å†…å®¹ã‚’ã‚‚ã¨ã«ä½œæˆã—ã€ï¼ˆã†ã¡ã€ç´„220ä»¶ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ï¼‰ã€ãƒ¢ãƒ‡ãƒ«ã¨å°‚é–€å®¶ã®solutionã«ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã•ã›ãŸã€‚ãã®ä¸Šã§ã€ç¬¬ä¸‰è€…ã§ã‚ã‚‹å°‚é–€å®¶ãŒå‹æ•—ï¼ˆwin, lose, tie)ã‚’ä»˜ä¸ã™ã‚‹ã“ã¨ã§ãƒ¢ãƒ‡ãƒ«ãŒã©ã‚Œã ã‘å®Ÿå‹™ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦äººé–“ã®å°‚é–€å®¶ã«åŒ¹æ•µã™ã‚‹ã‹ã‚’æ¸¬å®šã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚‹ã€‚<br><br>è©•ä¾¡ã®çµæœã€ãŸã¨ãˆã°Claude Opus 4.1ã®å‡ºåŠ›ã¯47.6%ç¨‹åº¦ã€GPT-5 (high) ã¯38.8%ç¨‹åº¦ã®å‰²åˆã§å°‚é–€å®¶ã¨å‹ã¡ + å¼•ãåˆ†ã‘ã€ã¨ã„ã†æ€§èƒ½ã«ãªã£ã¦ãŠã‚Šã€äººé–“ã®å°‚é–€å®¶ã«ã‹ãªã‚Šè¿‘ã„ãƒ¬ãƒ™ãƒ«ã«ã¾ã§è¿‘ã¥ã„ã¦ãã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚ç‰¹ã«Claude Opus 4.1ã¯ãƒ‡ã‚¶ã‚¤ãƒ³ã®å“è³ªã‚‚å•ã‚ã‚Œã‚‹ã‚¿ã‚¹ã‚¯ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ›¸å¼è¨­å®šã€ã‚¹ãƒ©ã‚¤ãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãªã©ï¼‰ã§ç‰¹ã«å„ªã‚Œã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚<br><br>&lt;img width="797" height="600" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/653d724f-34ef-46df-9458-bbfde33857b3"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/653d724f-34ef-46df-9458-bbfde33857b3"&lt;/a&gt;


/&gt;</p>
<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3187" target="_blank" rel="noopener noreferrer">[Paper Note] GDPval: Evaluating AI Model Performance on Real-World Economically
  Valuable Tasks, Tejal Patwardhan+, arXiv'25, 2025.10</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3019" target="_blank" rel="noopener noreferrer" class="title-link">Why GPT-5 used less training compute than GPT-4.5 ï¼ˆbut GPT-6 probably wonâ€™tï¼‰, EPOCH AI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1972421341988225340?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Infrastructure.html" target="_blank" rel="noopener noreferrer">#Infrastructure</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3012" target="_blank" rel="noopener noreferrer" class="title-link">AIã‚¤ãƒ³ãƒ•ãƒ©ã‚’è€ƒãˆã‚‹, Masayuki Kobayashi, ç¬¬38å› ISOC-JP Workshop, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwashi86/status/1971898942926606825?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>KVCacheã‚µã‚¤ã‚ºã¨ãƒ‡ãƒ¼ã‚¿è»¢é€é‡ã®éƒ¨åˆ†ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®éš›ã«é‡è¦ãªã®ã§ã™ãã«ã§ã‚‚æ´»ç”¨ã§ããã†ã€‚å‰åŠéƒ¨åˆ†ã¯ç§ã«ã¨ã£ã¦ã¯é›£ã—ã‹ã£ãŸã®ã§å‹‰å¼·ã—ãŸã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-09-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3011" target="_blank" rel="noopener noreferrer" class="title-link">Continuing to bring you our latest models, with an improved Gemini 2.5 Flash and Flash-Lite release, Google Deepmind, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mamagnus00/status/1971704040578077095?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3010" target="_blank" rel="noopener noreferrer" class="title-link">We reverse-engineered Flash Attention 4, Modal Blog, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwashi86/status/1972085451055157725?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Flash Attention4ã¯æ•°å­¦çš„ãªãƒˆãƒªãƒƒã‚¯ã‚ˆã‚Šã‚‚éåŒæœŸå‡¦ç†ã®è¤‡é›‘ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€Blackwellã«æœ€é©åŒ–ã€ã¨ã®ã“ã¨</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Aggregation-aware.html" target="_blank" rel="noopener noreferrer">#Aggregation-aware</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3008" target="_blank" rel="noopener noreferrer" class="title-link">RECURSIVE SELF-AGGREGATION UNLOCKS DEEP THINKING IN LARGE LANGUAGE MODELS, Venkatraman+, preprint, 2025.09</a>
<span class="snippet"><span>Comment</span><p>Nå€‹ã®å¿œç­”ã‚’ç”Ÿæˆã—ã€å„å¿œç­”Kå€‹çµ„ã¿åˆã‚ã›ã¦promptingã§é›†ç´„ã—æ–°ãŸãªå¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§æ´—ç·´ã•ã›ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚’Tå›ç¹°ã‚Šè¿”ã™test-time scalingæ‰‹æ³•ã§ã€RLã«ã‚ˆã£ã¦ãƒ¢ãƒ‡ãƒ«ã®é›†ç´„èƒ½åŠ›ã‚’å¼·åŒ–ã™ã‚‹ã¨ã‚ˆã‚Šè‰¯ã„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ç™ºæ®ã™ã‚‹ã€‚RLã§ã¯é€šå¸¸ã®ç›®çš„é–¢æ•°ï¼ˆprompt x, answer y; xã‹ã‚‰å˜ä¸€ã®reasoning traceã‚’ç”Ÿæˆã—yã‚’å›ç­”ã™ã‚‹è¨­å®šï¼‰ã«åŠ ãˆã¦ã€aggregation promptã‚’ç”¨ã„ãŸç›®çš„é–¢æ•°(aggregation promptã‚’ç”¨ã„ã¦ Kå€‹ã®solutioné›†åˆ S_0ã‚’ç”Ÿæˆã—ã€ç›®çš„é–¢æ•°ã‚’aggregation prompt x, S_0ã®åŒæ–¹ã§æ¡ä»¶ã¥ã‘ãŸã‚‚ã®)ã‚’å®šç¾©ã—ã€åŒæ™‚ã«æœ€é©åŒ–ã‚’ã—ã¦ã„ã‚‹ï¼ˆåŒæ™‚ã«æœ€é©åŒ–ã™ã‚‹ã“ã¨ã¯5.4ç¯€ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ï¼‰ã€‚ã¤ã¾ã‚Šã€ã“ã‚Œã¾ã§ã®RLã¯xãŒgivenãªæ™‚ã«é ‘å¼µã£ã¦å˜ä¸€ã®è‰¯ã„æ„Ÿã˜ã®reasoning traceã‚’ç”Ÿæˆã—yã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã—ã¦ã„ãŸãŒï¼ˆã™ãªã‚ã¡ã€ãƒ¢ãƒ‡ãƒ«ãŒè¤‡æ•°ã®solutionã‚’é›†ç´„ã™ã‚‹ã“ã¨ã¯æ˜ç¤ºçš„ã«å­¦ç¿’ã•ã‚Œã¦ã„ãªã„ï¼‰ã€ãã‚Œã«åŠ ãˆã¦ãƒ¢ãƒ‡ãƒ«ã®aggregationã®èƒ½åŠ›ã‚‚åŒæ™‚ã«å¼·åŒ–ã™ã‚‹ã€ã¨ã„ã†æ°—æŒã¡ã«ãªã£ã¦ã„ã‚‹ã€‚å­¦ç¿’ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯PPO, GRPOãªã©æ§˜ã€…ãªon-poloicyãªæ‰‹æ³•ã‚’ç”¨ã„ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ä»Šå›ã¯RLOOã¨å‘¼ã°ã‚Œã‚‹æ‰‹æ³•ã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚<br><br>&lt;img width="1005" height="456" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/e83406ae-91a0-414b-a49c-892a4d1f23fd"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/e83406ae-91a0-414b-a49c-892a4d1f23fd"&lt;/a&gt;


/&gt;<br><br>æ§˜ã€…ãªsequential scaling, parallel scalingæ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦ã€RSAãŒã‚ˆã‚Šå¤§ããªgainã‚’å¾—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚ãŸã ã—ã€Knowledge Recallã¨ã„ã†ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã¯Self-Consistency (Majority Voting)ã‚ˆã‚Šã‚‚gainãŒå°ã•ã„ã€‚<br>&lt;img width="1017" height="427" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/8251f25b-472d-48d4-b7df-a6946cfbbcd9"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/8251f25b-472d-48d4-b7df-a6946cfbbcd9"&lt;/a&gt;


/&gt;<br><br>ä»¥ä¸‹ãŒaggregation-awareãªRLã‚’å®Ÿæ–½ã—ãŸå ´åˆã¨ã€é€šå¸¸ã®RL, promptingã®ã¿ã«ã‚ˆã‚‹å ´åˆã®æ€§èƒ½ã®è¡¨ã—ã¦ã„ã‚‹ã€‚å…¨ä½“ã‚’é€šã˜ã¦aggregation-awareãªRLã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ãŸã ã—ã€AIMEã«é–¢ã—ã¦ã ã‘ã¯é€šå¸¸ã®promptingã«ã‚ˆã‚‹RSAã®æ€§èƒ½ãŒè‰¯ã„ã€‚ãªãœã ã‚ã†ã‹ï¼Ÿè€ƒå¯Ÿã¾ã§æ·±ãèª­ã‚ã¦ã„ãªã„ã®ã§è«–æ–‡ä¸­ã«è€ƒå¯ŸãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚<br>&lt;img width="1026" height="547" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/146ab6a3-58c2-4a7f-aa84-978a5180c8f3"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/146ab6a3-58c2-4a7f-aa84-978a5180c8f3"&lt;/a&gt;


/&gt;</p>
<p>RLOO:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3009" target="_blank" rel="noopener noreferrer">[Paper Note] Back to Basics: Revisiting REINFORCE Style Optimization for Learning   from Human Feedback in LLMs, Arash Ahmadian+, ACL'24, 2024.02</a>
</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/siddarthv66/status/1971757612845670585?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>concurrent work:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2729" target="_blank" rel="noopener noreferrer">[Paper Note] The Majority is not always right: RL training for solution aggregation, Wenting Zhao+, arXiv'25</a>
</p>
<p>ã‚ã‚ã›ã¦èª­ã¿ãŸã„:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2346" target="_blank" rel="noopener noreferrer">[Paper Note] Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A   Perspective of Probability Theory, Yexiang Liu+, ACL'25 Outstanding Paper</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3004" target="_blank" rel="noopener noreferrer" class="title-link">When Speed Kills Stability: Demystifying RL Collapse from the Training-Inference Mismatch, Liu+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/richardyrli/status/1971560544974086263?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è¨“ç·´æ™‚ã®ã‚¨ãƒ³ã‚¸ãƒ³(fsdpç­‰)ã¨ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆæ™‚ã®ã‚¨ãƒ³ã‚¸ãƒ³(vLLMç­‰)ãŒã€OOVãªãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾ã—ã¦ï¼ˆç‰¹ã«tooluseã—ãŸå ´åˆã«ç”Ÿã˜ã‚„ã™ã„ï¼‰è‘—ã—ãç•°ãªã‚‹å°¤åº¦ã‚’å‰²ã‚Šå½“ã¦ã‚‹ãŸã‚å­¦ç¿’ãŒå´©å£Šã—ã€ãã‚Œã¯åˆ©ç”¨ã™ã‚‹GPUã«ã‚ˆã£ã¦ã‚‚å®‰å®šæ€§ãŒå¤‰åŒ–ã—ï¼ˆA100ã‚ˆã‚Šã‚‚L20, L20ã‚ˆã‚Šã‚‚H20)ã€tokenãƒ¬ãƒ™ãƒ«ã®Importtance Weightingã§ã¯é›£ã—ãã€Sequenceãƒ¬ãƒ™ãƒ«ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒå¿…è¦ã€ã¿ãŸã„ãªè©±ãªæ¨¡æ§˜ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2552" target="_blank" rel="noopener noreferrer">Your Efficient RL Framework Secretly Brings You Off-Policy RL Training, Yao+, 2025.08</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2299" target="_blank" rel="noopener noreferrer">[Paper Note] Group Sequence Policy Optimization, Chujie Zheng+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2999" target="_blank" rel="noopener noreferrer" class="title-link">Introducing LFM2: The Fastest On-Device Foundation Models on the Market, LiquidAI, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1943440891915481371?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LiquidAIã«ã‚ˆã‚‹edgeãƒ‡ãƒã‚¤ã‚¹å‘ã‘ã®Foundation Modelã€‚å“è³ªã€ã‚¹ãƒ”ãƒ¼ãƒ‰ã€ãƒ¡ãƒ¢ãƒªã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®ãƒãƒ©ãƒ³ã‚¹ã‚’æœ€é©ã«ã—ã¦ãŠã‚‹ã¨ã®ã“ã¨ã€‚ãŸã¨ãˆã°Qwenã¨æ¯”è¼ƒã—ã¦2å€ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã¨prefillé€Ÿåº¦ã¨ã®ã“ã¨ã€‚ã¾ãŸã€åŒã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ç¾¤ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã‚‰ã—ã„ã€‚<br>ä¸‹è¨˜ã‚°ãƒ©ãƒ•ã¯MMLU, IFEval,IFBENCH,GSM8K,MMMLUã§ã®è©•ä¾¡ã®å¹³å‡ã€‚ä»–ã«ã‚‚GPQA,MGSMã§ã‚‚è©•ä¾¡ã—ã¦ãŠã‚Šã€åŒã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”ã¹ã¦åŒç­‰ã‹å°‘ã—åŠ£ã‚‹ãã‚‰ã„ã€‚<br><br><img src="https://github.com/user-attachments/assets/7f841f30-2046-4ebc-8a64-0d47b1e2b7da" alt="image" loading="lazy"><br><br>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯RNNã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ã¦ãŠã‚Šã€å¾“æ¥ã®æ™‚é–“ãŒstepã”ã¨ã«ç™ºå±•ã™ã‚‹RNNã§ã¯ãªãã€é€£ç¶šæ™‚é–“ã‚’æ‰±ãˆã‚‹ã‚ˆã†ãªRNNã®å¤‰ç¨®ãªã‚ˆã†ã§ã‚ˆã‚ŠæŸ”è»Ÿã«æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã‚’æ‰±ãˆã‚‹ã‚ˆã†ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚‰ã—ã„ã€‚ã¾ãŸã€LIV Operatorã¨å‘¼ã°ã‚Œã‚‹å…¥åŠ›ã«å¿œã˜ã¦å‹•çš„ã«ç•°ãªã‚‹ç·šå½¢å¤‰æ›ã‚’å®Ÿæ–½ã™ã‚‹Operatorã‚’æ¡ç”¨ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ãŸã¨ãˆã°å…¥åŠ›ã«å¿œã˜ã¦ã€convolution, attention, recurrenceãªã©ã®operationãŒå¤‰åŒ–ã™ã‚‹ã€‚ã“ã‚Œã«åŸºã¥ã„ã¦ã€ã•ã¾ã–ã¾ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®NNã‚’å®šç¾©ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã§ã€æœ€é©ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¨¡ç´¢ã™ã‚‹ãŸã‚ã«STARã¨å‘¼ã°ã‚Œã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§Neural Architecture Searchã‚’å®Ÿæ–½ã—ãŸæ¨¡æ§˜ã€‚</p>
<p>ãƒ¡ãƒ¢ãƒªã«åˆ¶ç´„ãŒã‚ã‚‹ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹å‘ã‘ã«KVCacheä¸è¦ã§ç¾åœ¨ã®éš ã‚ŒçŠ¶æ…‹ã®ã¿ã‚’ä¿æŒã™ã‚Œã°è‰¯ã„RNNãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã™ã‚‹ã®ã¯ç†ã«é©ã£ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/DocParser.html" target="_blank" rel="noopener noreferrer">#DocParser</a>
<span class="issue_date">Issue Date: 2025-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2998" target="_blank" rel="noopener noreferrer" class="title-link">Liquid Nanos, LiquidAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>blog:


<a href="https://www.liquid.ai/blog/introducing-liquid-nanos-frontier-grade-performance-on-everyday-devices" target="_blank" rel="noopener noreferrer">https://www.liquid.ai/blog/introducing-liquid-nanos-frontier-grade-performance-on-everyday-devices</a>


</p>
<p>ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã«350Mã®æ—¥è‹±ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã‚‹â€¦ã ã¨ï¼ï¼Ÿ</p>
<p>ã‚¿ã‚¹ã‚¯ã‚¹ãƒšã‚·ãƒ•ã‚£ãƒƒã‚¯ãªedgeãƒ‡ãƒã‚¤ã‚¹å‘ã‘ã®SLMç¾¤ã€‚<br><br>ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã€‚éæ§‹é€ ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã€æ—¥è‹±ç¿»è¨³ã€RAG, tooluse, Math, ãƒ•ãƒ©ãƒ³ã‚¹èªã®ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã€‚ã“ã‚Œã¾ã§ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ã«ç‰¹åŒ–ã—ãŸMTã¨ã‹ã¯ã‚ˆãè¦‹å—ã‘ã‚‰ã‚ŒãŸãŒã€è‰²ã€…ãªã‚¿ã‚¹ã‚¯ã®SLMãŒå‡ºã¦ããŸã€‚<br><img src="https://github.com/user-attachments/assets/bb19f5f0-f20f-4e51-8ecc-75c7b425b60f" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1971359534883946709?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LFM2ã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2999" target="_blank" rel="noopener noreferrer">Introducing LFM2: The Fastest On-Device Foundation Models on the Market, LiquidAI, 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2979" target="_blank" rel="noopener noreferrer" class="title-link">CWM: An Open-Weights LLM for Research on Code Generation with World Models, Copet+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yuxiangwei9/status/1970965218839974250?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>World Modelã¨éŠ˜æ‰“ã£ã¦ã‚ã‚‹ãŒã€ä¸€èˆ¬çš„ãªCVåˆ†é‡ã§ã®World Modelã§ã¯ãªãã€python ã‚„bashç­‰ã®å®Ÿè¡Œã‚’ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã¨ã—ã¦ä»®æƒ³çš„ã«ãƒˆãƒ¬ãƒ¼ã‚¹ã§ãã‚‹ã‚ˆã†ã«mid trainingã•ã‚Œã¦ã„ã‚‹ï¼ˆå¤§é‡ã®å®Ÿãƒˆãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ï¼‰ã®ã§ã€World Modelã¨éŠ˜æ‰“ãŸã‚Œã¦ã„ã‚‹æ¨¡æ§˜ï¼Ÿ<br><br><img src="https://github.com/user-attachments/assets/bbed358e-ad8d-4b6c-bd6b-39d23457a9cb" alt="image" loading="lazy"></p>
<p>GRPOã«å¯¾ã™ã‚‹ãƒ¢ãƒ€ãƒ³ãªtweakãŒã¾ã¨ã¾ã£ã¦ã„ã‚‹æ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1972268402732617968?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>DeepSeek-R1ã§ææ¡ˆã•ã‚Œã¦ã‹ã‚‰ç´°ã‹ãªèª¿æ•´ãŒé‡ã­ã‚‰ã‚Œã¦æ¥ãŸã€‚</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2965" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-Max: Just Scale it, Qwen Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1970599097297183035?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¾åœ¨ã¯non-thinkingãƒ¢ãƒ‡ãƒ«ã®ã¿ã®ã‚ˆã†ã ãŒthinkingãƒ¢ãƒ‡ãƒ«ã‚‚å­¦ç¿’ä¸­ã§ã€GPQA, HMMT, AIME25ã§ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã®ã¿æ²è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚</p>
<p>HMMTã¨ã„ã†ã®ã¯ä»¥ä¸‹ãªæ¨¡æ§˜:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2967" target="_blank" rel="noopener noreferrer">HMMT. HMMT 2025, 2025.09</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2948" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3â€‘LiveTranslate: Realâ€‘Time Multimodal Interpretation â€” See It, Hear It, Speak Itï¼, Qwen Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1970565641594867973?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2947" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-Guard, Qwen Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1970510193537753397?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Omni.html" target="_blank" rel="noopener noreferrer">#Omni</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2942" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-Omni, Qwen Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ:


<a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/assets/Qwen3_Omni.pdf" target="_blank" rel="noopener noreferrer">https://github.com/QwenLM/Qwen3-Omni/blob/main/assets/Qwen3_Omni.pdf</a>


</p>
<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1970181599133344172?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1970307898170605937?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mervenoyann/status/1970444546216444022?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¥æœ¬èªã§éŸ³å£°toéŸ³å£°å¯èƒ½:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/asap2650/status/1970185195556086032?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Artificial Analysisã«ã‚ˆã‚‹è©•ä¾¡:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1975904190061834602?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2939" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-Next-series-FP8, Qwen Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1970052154330353857?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2935" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-V3.1-Terminus, deepseek-ai, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1970127354120077643?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>vLLMã§ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹æ™‚ã®tips:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vllm_project/status/1970814441718755685?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2928" target="_blank" rel="noopener noreferrer" class="title-link">LoRAã®é€²åŒ–ï¼šåŸºç¤ã‹ã‚‰æœ€æ–°ã®LoRA-Proã¾ã§ , æ¾å°¾ç ”ç©¶æ‰€ãƒ†ãƒƒã‚¯ãƒ–ãƒ­ã‚°, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/matsuoinstitute/status/1969958580057964986?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2929" target="_blank" rel="noopener noreferrer">[Paper Note] LoRA-Pro: Are Low-Rank Adapters Properly Optimized?, Zhengbo Wang+, ICLR'25, 2024.07</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1245" target="_blank" rel="noopener noreferrer">LoRA+: Efficient Low Rank Adaptation of Large Models, Soufiane Hayou+, N/A, ICML'24</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2922" target="_blank" rel="noopener noreferrer" class="title-link">LongCat-Flash-Thinking, meituan-longcat, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/meituan_longcat/status/1969823529760874935?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1969897602448539790?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2620" target="_blank" rel="noopener noreferrer">LongCat-Flash-Chat, meituan-longcat, 2025.08</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2932" target="_blank" rel="noopener noreferrer">[Paper Note] Libra: Assessing and Improving Reward Model by Learning to Think, Meng Zhou+, arXiv'25, 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2917" target="_blank" rel="noopener noreferrer" class="title-link">Grok 4 Fast, xAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å¯¾ã™ã‚‹è©•ä¾¡çµæœä»¥å¤–ã®æƒ…å ±ã¯ã»ã¼è¨˜è¿°ã•ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ï¼ˆRLä½¿ã„ã¾ã—ãŸç¨‹åº¦ï¼‰</p>
<p>Artificial Analysisã«ã‚ˆã‚‹è©•ä¾¡:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1969180023107305846?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚³ã‚¹ãƒˆæ€§èƒ½æ¯”ã®æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kimmonismus/status/1969333210975756697?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2910" target="_blank" rel="noopener noreferrer" class="title-link">Ring-flash-2.0, inclusionAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/adinayakup/status/1969024994903744712?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>-  Ling-flash-2.0-baseã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã€100B-A6.1 params<br>- å„ç¨®ãƒ™ãƒ³ãƒã§gpt-oss-120Bã¨åŒç­‰ä»¥ä¸Šã€‚denseãª40Bãƒ¢ãƒ‡ãƒ«ï¼ˆQwen-32B, Seed-OSS-36B-Instructï¼‰ã‚„proprietary modelã§ã‚ã‚‹Gemini-2.5-Flashã¨æ¯”è¼ƒã—ã¦åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ <br>&lt;img width="772" height="777" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/f5aed972-e2f3-49e8-80fa-70e6ee110512"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/f5aed972-e2f3-49e8-80fa-70e6ee110512"&lt;/a&gt;


/&gt;</p>
<p>- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£<br>  - Multi Token Prediction <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2904" target="_blank" rel="noopener noreferrer">[Paper Note] Multi-Token Prediction Needs Registers, Anastasios Gerontopoulos+, NeurIPS'25</a>
 <br>  - 1/32 experts activation ratio<br>  - gpt-oss-120Bã¯4 expertsãŒactiveã ãŒã€ã“ã¡ã‚‰ã¯1 shared + 8 experts<br>  - attention headæ•°ã¯gpt-oss-120Bã®64ã®1/2ã§ã‚ã‚‹32<br>  - group size 4ã®GQA <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
<br>  - gpt-oss-120Bã®Embed dim=2880ã«å¯¾ã—ã¦å¤§ãã‚ã®Embed dim=4096<br>  - æœ€åˆã®1ãƒ–ãƒ­ãƒƒã‚¯ã ã‘ã€MoEã®ä»£ã‚ã‚Šã«hidden_size=9216ã®FNNãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹<br><br>&lt;img width="661" height="599" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/1f3bf7c9-7997-4fbb-95b5-d2f1d8b10b0a"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/1f3bf7c9-7997-4fbb-95b5-d2f1d8b10b0a"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2893" target="_blank" rel="noopener noreferrer" class="title-link">MagicBench, ByteDance-Seed, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1968972092445008183?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‹±æ–‡ã¨ä¸­æ–‡ä¸¡æ–¹å­˜åœ¨ã™ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2858" target="_blank" rel="noopener noreferrer" class="title-link">Magistral-Small-2509, MistralAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mistralai/status/1968670593412190381?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2845" target="_blank" rel="noopener noreferrer" class="title-link">Ling-flash-2.0, inclusionAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>100B-A6.1B, 20Tãƒˆãƒ¼ã‚¯ãƒ³ã§å­¦ç¿’, SFT+ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸RL, 40Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§SoTA, 200+tokens/secã®ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é€Ÿåº¦<br><br><img src="https://github.com/user-attachments/assets/9da60c24-4734-4711-b9cc-7915d0caa3b4" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1968421451708440833?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/antlingagi/status/1968323481730433439?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/TTS.html" target="_blank" rel="noopener noreferrer">#TTS</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2839" target="_blank" rel="noopener noreferrer" class="title-link">VoxCPM-0.5B, openbmb, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1967981041815044604?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2703" target="_blank" rel="noopener noreferrer">[Paper Note] MiniCPM4: Ultra-Efficient LLMs on End Devices, MiniCPM Team+, arXiv'25</a>
<br><br>ã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã¨ã™ã‚‹TTS</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2829" target="_blank" rel="noopener noreferrer" class="title-link">Tongyi DeepResearch: A New Era of Open-Source AI Researchers, Tongyi Lab, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ali_tongyilab/status/1967988004179546451?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯: <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1730" target="_blank" rel="noopener noreferrer">[Paper Note] Humanity's Last Exam, Long Phan+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2451" target="_blank" rel="noopener noreferrer">[Paper Note] BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents, Jason Wei+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1158" target="_blank" rel="noopener noreferrer">GAIA: a benchmark for General AI Assistants, GrÃ©goire Mialon+, N/A, arXiv'23</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2466" target="_blank" rel="noopener noreferrer">[Paper Note] xbench: Tracking Agents Productivity Scaling with Profession-Aligned
  Real-World Evaluations, Kaiyuan Chen+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2767" target="_blank" rel="noopener noreferrer">[Paper Note] SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric
  Knowledge, Lukas Haas+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2851" target="_blank" rel="noopener noreferrer">[Paper Note] WebWalker: Benchmarking LLMs in Web Traversal, Jialong Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2852" target="_blank" rel="noopener noreferrer">[Paper Note] Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented   Generation, Satyapriya Krishna+, NAACL'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2853" target="_blank" rel="noopener noreferrer">[Paper Note] BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language
  Models in Chinese, Peilin Zhou+, arXiv'25</a>
</p>
<p>é–¢é€£ç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2851" target="_blank" rel="noopener noreferrer">[Paper Note] WebWalker: Benchmarking LLMs in Web Traversal, Jialong Wu+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2854" target="_blank" rel="noopener noreferrer">[Paper Note] WebDancer: Towards Autonomous Information Seeking Agency, Jialong Wu+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2855" target="_blank" rel="noopener noreferrer">[Paper Note] WebSailor: Navigating Super-human Reasoning for Web Agent, Kuan Li+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2856" target="_blank" rel="noopener noreferrer">[Paper Note] WebShaper: Agentically Data Synthesizing via Information-Seeking
  Formalization, Zhengwei Tao+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2424" target="_blank" rel="noopener noreferrer">[Paper Note] WebWatcher: Breaking New Frontier of Vision-Language Deep Research Agent, Xinyu Geng+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2830" target="_blank" rel="noopener noreferrer">[Paper Note] WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon
  Agents, Zile Qiao+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2834" target="_blank" rel="noopener noreferrer">[Paper Note] ReSum: Unlocking Long-Horizon Search Intelligence via Context
  Summarization, Xixi Wu+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2833" target="_blank" rel="noopener noreferrer">[Paper Note] WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for
  Open-Ended Deep Research, Zijian Li+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2857" target="_blank" rel="noopener noreferrer">[Paper Note] WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic
  Data and Scalable Reinforcement Learning, Kuan Li+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2832" target="_blank" rel="noopener noreferrer">[Paper Note] Scaling Agents via Continual Pre-training, Liangcai Su+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2831" target="_blank" rel="noopener noreferrer">[Paper Note] Towards General Agentic Intelligence via Environment Scaling, Runnan Fang+, arXiv'25</a>
 </p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2822" target="_blank" rel="noopener noreferrer" class="title-link">WildGuardTestJP: æ—¥æœ¬èªã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®é–‹ç™º, SB Intuitions, 2025.09</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/datasets/sbintuitions/WildGuardTestJP" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/sbintuitions/WildGuardTestJP</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sbintuitions/status/1967853532826177949?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ—¥æœ¬èªå‘ã‘ã«ï¼ˆSeed-X-PPO-7B <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2252" target="_blank" rel="noopener noreferrer">Seed-X-Instruct-7B, ByteDance-Seed, 2025.07</a>
 ã‚’ç”¨ã„ã¦[^1])ç¿»è¨³ã—ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚gpt-oss-120Bã«ã‚ˆã‚‹LLM-as-a-Judgeã‚’ç”¨ã„ã¦ç¿»è¨³ã®è³ªã‚’åˆ¤æ–­ã—ã€è³ªãŒä½ã„ã¨åˆ¤æ–­ã•ã‚ŒãŸã‚‚ã®ã¯ä»–ã®LLMã®ã‚ˆã‚Šé«˜ã„å“è³ªã¨åˆ¤æ–­ã•ã‚ŒãŸç¿»è¨³ã§ç½®æ›ã™ã‚‹ãªã©ã—ã¦ã„ã‚‹ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2824" target="_blank" rel="noopener noreferrer">[Paper Note] WildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks,   and Refusals of LLMs, Seungju Han+, NeurIPS'24</a>
<br><br>[^1]: plamo-2-translateã¨æ¯”è¼ƒã—ã¦ã€Plamoã®æ–¹ãŒæµæš¢ã ã£ãŸãŒSeedXã®æ–¹ãŒå¿ å®Ÿæ€§ãŒé«˜ã„æ¨å¯Ÿã•ã‚ŒãŸãŸã‚ã“ã¡ã‚‰ã‚’æ¡ç”¨ã—ãŸã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2025-09-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2808" target="_blank" rel="noopener noreferrer" class="title-link">Large reasoning models research at COLM 2025 - State of research in scaling reasoning, the current paradigm for improving LLMs, PRAKASH KAGITHA, 2025.09</a>
<span class="snippet"><span>Comment</span><p>COLM'25ã«ãŠã‘ã‚‹30å€‹ç¨‹åº¦ã®Reasoningã«é–¢ã‚ã‚‹è«–æ–‡ã‚’ã‚«ãƒãƒ¼ã—ãŸãƒ–ãƒ­ã‚°ã‚‰ã—ã„ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/prakashkagitha/status/1967032408009830769?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã“ã®è«–æ–‡ã®ã‚µãƒãƒªã®ã¾ã¨ã‚ã¨ã„ã£ãŸæ„Ÿã˜ãªã®ã§ã€indexã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã¨è‰¯ã•ãã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2802" target="_blank" rel="noopener noreferrer" class="title-link">OpenManus, Liang+, FoundationAgents, 2025.04</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2801" target="_blank" rel="noopener noreferrer" class="title-link">OpenDeepResearch, LangChain, 2025.07</a>
<span class="snippet"><span>Comment</span><p>blog: 


<a href="https://blog.langchain.com/open-deep-research/" target="_blank" rel="noopener noreferrer">https://blog.langchain.com/open-deep-research/</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2800" target="_blank" rel="noopener noreferrer" class="title-link">Kimi-Researcher End-to-End RL Training for Emerging Agentic Capabilities, MoonshotAI, 2025.06</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2797" target="_blank" rel="noopener noreferrer" class="title-link">Cosmopedia: how to create large-scale synthetic data for pre-training, Allal+ï¼ˆHuggingFaceï¼‰, 2024.03</a>
<span class="snippet"><span>Comment</span><p>cosmopedia dataset:


<a href="https://huggingface.co/datasets/HuggingFaceTB/cosmopedia" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/HuggingFaceTB/cosmopedia</a>


</p>
<p>å¤§éƒ¨åˆ†ã‚’åˆæˆãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ãŸPhi-1.5(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1039" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need II: phi-1.5 technical report, Yuanzhi Li+, N/A, arXiv'23</a>
)ã®ãƒ‡ãƒ¼ã‚¿åˆæˆã®ãƒ¬ã‚·ãƒ”ã®è©³ç´°ã¯æ˜ã‹ã•ã‚Œã¦ãŠã‚‰ãšã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è‡ªä½“ã‚‚å…¬é–‹ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’å—ã‘ã€äº‹å‰å­¦ç¿’ã§åˆ©ç”¨å¯èƒ½ãªæ•°ç™¾Mã‚µãƒ³ãƒ—ãƒ«ã®åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ãƒ¬ã‚·ãƒ”ã¯ãªã‚“ãªã®ã‹ï¼Ÿã‚’æ¢ã£ãŸè©±ã€‚<br><br>æœ€çµ‚çš„ã«ã€30Mã®promptã‚’prompt engineeringã‚’Mixtral-8x7B-Instruct-v0.1ã‚’é€šã˜ã¦ä½œæˆã—ã€é«˜å“è³ªãªpretrainingã®ãŸã‚ã®åºƒç¯„ãªãƒˆãƒ”ãƒƒã‚¯ã®æ–‡æ›¸ç¾¤ã‚’ä½œæˆã€‚åˆæˆã•ã‚ŒãŸå†…å®¹ã®é‡è¤‡ã¯1%æœªæº€ã€‚<br><br>Phi-1.5ã®è«–æ–‡ã®è¨˜è¿°ã«åŸºã¥ãã¨ã€20k topicsã‚’seedã¨ã—æ–°ãŸãªsynthetic dataã‚’ä½œæˆã€web sampleã‚’æ´»ç”¨ã—ã¦å¤šæ§˜æ€§ã‚’æ‹…ä¿ã—ãŸã€ã¨ã„ã†è¨˜è¿°ãŒã‚ã‚‹ã€‚ã“ã‚Œã«åŸºã¥ãã¨ã€ä»®ã«1ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ã‚’1000 tokenã§ã‚ã‚‹ã¨ä»®å®šã™ã‚‹ã¨ã€20Mã®promptãŒæ´»ç”¨ã•ã‚ŒãŸã“ã¨ã«ãªã‚‹ã€‚ã—ã‹ã—ãªãŒã‚‰ã€web sampleã‚’çµ„ã¿åˆã‚ã›ã‚‹æ–¹æ³•ã¨ã€å¤šæ§˜æ€§ã‚’å¢—ã‚„ã™æ–¹æ³•ãŒã‚¯ãƒªã‚¢ã§ã¯ãªã‹ã£ãŸã€‚<br><br>Cosmopediaã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã—ã¦ã¯ã€2ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒã‚ã‚‹ã€‚ã¾ãš curated educational sources (Khan Academy, OpenStax, WikiHow, Stanford courses)ã‚’åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã§ã€ã“ã‚Œã‚‰ã®å…¨ã¦ã®ãƒ¦ãƒ‹ãƒƒãƒˆã‚’åˆè¨ˆã—ã¦ã‚‚260kç¨‹åº¦ã§ã‚ã£ãŸã€‚ã“ã‚Œã§ã¯åˆ°åº•20Mã«ã¯å±Šã‹ãªã„ãŸã‚ã€ç”Ÿæˆã™ã‚‹æ–‡æ›¸ã® `style` ã¨ `audience` ã«å¹…ã‚’æŒãŸã›ã‚‹ã“ã¨ã§ã€promptã®æ•°ã‚’å¢—ã‚„ã—ãŸã€‚<br>å…·ä½“çš„ã«ã¯ã€styleã¨ã—ã¦ã€academic textbook / blog post / wikihow articles ã®3ç¨®é¡ã€audienceã¨ã—ã¦ young children / high school students / college students / researchers ã®4ç¨®é¡ã‚’ç”¨æ„ã—ãŸã€‚ã“ã®ã¨ãã€å˜ã«promptä¸­ã§ç‰¹å®šã®audience/styleã§è¨˜è¿°ã™ã‚‹ã‚ˆã†æŒ‡ç¤ºã‚’ã—ã¦ã‚‚ã€åŒã˜ã‚ˆã†ãªå†…å®¹ã—ã‹å‡ºåŠ›ã•ã‚Œãªã„èª²é¡ŒãŒã‚ã£ãŸãŸã‚ã€prompt engineeringã«ã‚ˆã£ã¦ã€ã‚ˆã‚Šå…·ä½“çš„ãªæŒ‡ç¤ºã‚’åŠ ãˆã‚‹ã“ã¨ã§è§£æ±ºï¼ˆFigure3ï¼‰ã€‚<br><br>ç¶šã„ã¦ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯web dataã‚’æ´»ç”¨ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€åé›†ã•ã‚ŒãŸweb samplesã‚’145ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«åˆ†é¡ã—ã€å„ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«10å€‹ã®ãƒ©ãƒ³ãƒ€ãƒ ãªã‚µãƒ³ãƒ—ãƒ«ã‚’æŠ½å‡ºã—ã€Mixtralã«ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰å…±é€šã®ãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡ºã•ã›ã‚‹ã“ã¨ã§ã‚¯ãƒ©ã‚¹ã‚¿ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’å¾—ã‚‹ã€‚<br>ãã®å¾Œä¸é©åˆ‡ãªãƒˆãƒ”ãƒƒã‚¯ã¯é™¤å¤–ï¼ˆe.g., ã‚¢ãƒ€ãƒ«ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„, ã‚´ã‚·ãƒƒãƒ—ç­‰ï¼‰ã€‚ãã®å¾Œã€ã‚¯ãƒ©ã‚¹ã‚¿ã®web sampleã¨ãƒˆãƒ”ãƒƒã‚¯ã®åŒæ–¹ã‚’promptã«ä¸ãˆã¦é–¢é€£ã™ã‚‹textbookã‚’ç”Ÿæˆã•ã›ã‚‹promptã‚’ä½œæˆ (Figure 4)ã€‚ã“ã®ã¨ãã€ãƒˆãƒ”ãƒƒã‚¯ãƒ©ãƒ™ãƒ«ã®ç”ŸæˆãŒã†ã¾ãã„ã£ã¦ã„ãªã„å¯èƒ½æ€§ã‚‚è€ƒæ…®ã—ã€ãƒˆãƒ”ãƒƒã‚¯ã‚’givenã«ã—ãªã„promptã‚‚ç”¨æ„ã—ãŸã€‚æœ€çµ‚çš„ã«ã“ã‚Œã«ã‚ˆã‚Š23Mã®promptã‚’å¾—ãŸã€‚ã¾ãŸã€scientificãªå†…å®¹ã‚’å¢—ã‚„ã™ãŸã‚ã«ã€AutoMathText (æ•°å­¦ã«é–¢ã—ã¦åé›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ)ã‚‚åŠ ãˆãŸã€‚<br><br>ä¸Šè¨˜promptã§åˆæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ãŸã¨ã“ã‚ã€ãƒ¢ãƒ‡ãƒ«ã«common senseã‚„grade school educationã«ãŠã‘ã‚‹å…¸å‹çš„ãªçŸ¥è­˜ãŒæ¬ ã‘ã¦ã„ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ãŸãŸã‚ã€UltraChatã‚„OpenHermes2.5ã‹ã‚‰æ—¥å¸¸ã«é–¢ã™ã‚‹ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’æŠ½å‡ºã—ã¦seed dataã«åŠ ãˆãŸã€‚<br><br>ä¸‹è¨˜ãŒæœ€çµ‚çš„ãªseed-data/format/audienceã®åˆ†å¸ƒã¨ãªã‚‹ã€‚seed-dataã®å¤§éƒ¨åˆ†ã¯web-dataã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br>&lt;img width="866" height="513" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/f30beb80-e75c-466c-9c77-8080298869cc"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/f30beb80-e75c-466c-9c77-8080298869cc"&lt;/a&gt;


/&gt;<br><br>æœ€çµ‚çš„ã«åˆæˆãƒ‡ãƒ¼ã‚¿ã®ã†ã¡ã€10-gram overlapã«åŸºã¥ã„ã¦ã€contaminationã®ç–‘ã„ãŒã‚ã‚‹åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã®ã†ã¡ã€50%ã®sub-stringã¨ãƒãƒƒãƒã—ãŸæ–‡æ›¸ã¯é™¤å¤–ã™ã‚‹ã“ã¨ã§decontaminationã‚’å®Ÿæ–½ã€‚<br>ä¸‹è¡¨ãŒdecontaminationã®çµæœã§ã€()å†…ã®æ•°å­—ãŒãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°ã€‚decontaminationã‚’ã—ãªã‘ã‚Œã°ã“ã‚Œã‚‰ãŒå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«æ··å…¥ã—ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°æ€§èƒ½ã«ä¸‹é§„ã‚’ã¯ã‹ã›ã‚‹ã“ã¨ã«ãªã£ã¦ã—ã¾ã£ã¦ã„ãŸã“ã¨ã«ãªã‚‹ã€‚<br>&lt;img width="627" height="228" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/5ede5660-7305-41ad-bc56-1be03aec99f2"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/5ede5660-7305-41ad-bc56-1be03aec99f2"&lt;/a&gt;


/&gt;<br><br>1Bãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ãŸçµæœã€åŠåˆ†ç¨‹åº¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§TinyLlama 1.1Bã‚ˆã‚Šã‚‚é«˜ã„ã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚Qwen-1.5-1Bã‚„Phi-1.5ã«å¯¾ã—ã¦ã¯å…¨ä½“ã¨ã—ã¦ã‚¹ã‚³ã‚¢ã§ã¯è² ã‘ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ã“ã®ã“ã¨ã‚ˆã‚Šã€ã‚ˆã‚Šé«˜å“è³ªãªåˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆæ–¹æ³•ãŒã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚<br>&lt;img width="551" height="384" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/536bfc9e-3093-43ba-b866-31f8e7073740"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/536bfc9e-3093-43ba-b866-31f8e7073740"&lt;/a&gt;


/&gt;</p>
<p>ä»¥å¾Œã€SmolLMæ§‹ç¯‰ã®éš›ã«Cosmopediaã®promptã«æŒ¿å…¥ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒˆãƒ”ãƒƒã‚¯ã”ã¨ã«ã‚ˆã‚Šé©åˆ‡ã«é¸æŠã™ã‚‹ï¼ˆæ–‡æ›¸ã‚’åˆæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’Mixtralã‹ã‚‰ä»–ã®ãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›´ã—ã¦ã‚‚ã‚ã¾ã‚ŠåŠ¹æœãŒãªã‹ã£ãŸã¨ã®ã“ã¨ï¼‰ãªã©ã®æ”¹å–„ã‚’å®Ÿæ–½ã—ãŸCosmopedia v2ãŒæ§‹ç¯‰ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2796" target="_blank" rel="noopener noreferrer" class="title-link">GAUSS Benchmarking Structured Mathematical Skills for Large Language Models, Zhang+, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/banghuaz/status/1966529943514325227?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¾åœ¨ã®æ•°å­¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯å€‹ã€…ã®å•é¡Œã«å¯¾ã™ã‚‹å›ç­”ã®Accuracyã‚’æ¸¬ã‚‹ã‚‚ã®ã°ã‹ã‚Šã ãŒã€ã‚ã‚‹å•é¡Œã‚’è§£ãéš›ã«ã¯ã•ã¾ã–ã¾ãªã‚¹ã‚­ãƒ«ã‚’æ´»ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€è©•ä¾¡å¯¾è±¡ã®LLMãŒã©ã®ã‚ˆã†ãªã‚¹ã‚­ãƒ«ã«å¼·ãã€å¼±ã„ã®ã‹ã¨ã„ã£ãŸè§£åƒåº¦ãŒä½ã„ã¾ã¾ãªã®ã§ã€ãã†ã„ã£ãŸã‚¹ã‚­ãƒ«ã®ç¿’ç†Ÿåº¦åˆã„ã‚’æ¸¬ã‚Œã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸã€ã¨ã„ã†è©±ã«è¦‹ãˆã‚‹ã€‚</p>
<p>Knowledge Tracingã‚¿ã‚¹ã‚¯ãªã©ã§ã¯å•é¡Œã”ã¨ã«ã‚¹ã‚­ãƒ«ã‚¿ã‚°ã‚’ä»˜ä¸ã—ã¦ã€ã‚¹ã‚­ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¦ç¿’ç†Ÿåº¦ã‚’æ¸¬ã‚‹ã®ã§ã€å•é¡Œã®æ­£èª¤ã ã‘ã§ãªãã¦ã€ã‚¹ã‚­ãƒ«ãƒ™ãƒ¼ã‚¹ã§ã®ç¿’ç†Ÿåº¦ã‚’è¦‹ã‚‹ã“ã¨ã§èƒ½åŠ›ã‚’æ¸¬ã‚‹ã®ã¯è‡ªç„¶ãªæµã‚Œã«æ€ãˆã‚‹ã€‚ãã—ã¦ãã‚Œã¯æ•°å­¦ãŒæœ€ã‚‚å®Ÿæ–½ã—ã‚„ã™ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2784" target="_blank" rel="noopener noreferrer" class="title-link">Ring-mini-2.0, inclusionAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/antling20041208/status/1966138154454495379?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1966515481176662505?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2765" target="_blank" rel="noopener noreferrer">Ling V2, inclusionAI, 2025.09</a>
<br><br>ã‚’ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦Long CoT SFT, RLVR, RLHFã‚’å®Ÿæ–½ã—ãŸçµæœã€code, math, logic, scienceé–¢é€£ã®ãƒ™ãƒ³ãƒã§gpt-oss-20B(medium)ã‚’è¶…ãˆã¦ã„ã‚‹ã‚‰ã—ã„ã€‚<br><img src="https://github.com/user-attachments/assets/f228ba39-8c85-4f43-9bf6-6932681ff4cc" alt="image" loading="lazy"><br><br>Joint Trainingã¨æ›¸ã‹ã‚Œã¦ã„ã‚‹ãŒè©³ç´°ã¯ãªãã€ã‚ˆãã‚ã‹ã‚‰ãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2765" target="_blank" rel="noopener noreferrer" class="title-link">Ling V2, inclusionAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1965911832788451395?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2296" target="_blank" rel="noopener noreferrer">[Paper Note] Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts
  Language Models, Changxin Tian+, arXiv'25</a>
</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1965861299398783419?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>blog:


<a href="https://huggingface.co/blog/im0qianqian/ling-mini-2-fp8-mixed-precision-training-solution" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/im0qianqian/ling-mini-2-fp8-mixed-precision-training-solution</a>


<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/antlingagi/status/1968660440877085104?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2764" target="_blank" rel="noopener noreferrer" class="title-link">Context Engineering - Short-Term Memory Management with Sessions from OpenAI Agents SDK, OpenAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/schroneko/status/1965911753885360152?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Non-Determinism.html" target="_blank" rel="noopener noreferrer">#Non-Determinism</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2763" target="_blank" rel="noopener noreferrer" class="title-link">Defeating Nondeterminism in LLM Inference, Horace He in collaboration with others at Thinking Machines, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thinkymachines/status/1965826369721623001?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1965964901102530965?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>vLLMã«ãŠã„ã¦inferenceã‚’deterministicã«ã™ã‚‹æ–¹æ³•ãŒã€vLLMã®issue number 24583ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã®ã§å‚ç…§ã®ã“ã¨ã€‚</p>
<p>transformersã§ã®å®Ÿè£…ä¾‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gabriberton/status/1968559505966350705?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/Inference.html" target="_blank" rel="noopener noreferrer">#Inference</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2759" target="_blank" rel="noopener noreferrer" class="title-link">Checkpoint Engine, MoonshotAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zephyr_z9/status/1965788114884149465?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2755" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] K2-Think: A Parameter-Efficient Reasoning System, Institute of Foundation Models, Mohamed bin Zayed University of Artificial Intelligence, 2025.09</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/LLM360/K2-Think" target="_blank" rel="noopener noreferrer">https://huggingface.co/LLM360/K2-Think</a>


<br>code:<br>- 


<a href="https://github.com/MBZUAI-IFM/K2-Think-SFT" target="_blank" rel="noopener noreferrer">https://github.com/MBZUAI-IFM/K2-Think-SFT</a>


<br>- 


<a href="https://github.com/MBZUAI-IFM/K2-Think-Inference" target="_blank" rel="noopener noreferrer">https://github.com/MBZUAI-IFM/K2-Think-Inference</a>


<br><br>RLã¯verl+GRPOã§å®Ÿæ–½ã—ãŸã¨ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ãŒã€å½“è©²éƒ¨åˆ†ã®ã‚³ãƒ¼ãƒ‰ã®å…¬é–‹ã¯ã•ã‚Œã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ<br>RLã§åˆ©ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2070" target="_blank" rel="noopener noreferrer">[Paper Note] Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain  Perspective, Zhoujun Cheng+, arXiv'25</a>
</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1965713404418805806?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2752" target="_blank" rel="noopener noreferrer" class="title-link">ERNIE-4.5-21B-A3B-Thinking, Baidu, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/schroneko/status/1965586268290777529?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1965452580525408484?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ:


<a href="https://ernie.baidu.com/blog/publication/ERNIE_Technical_Report.pdf" target="_blank" rel="noopener noreferrer">https://ernie.baidu.com/blog/publication/ERNIE_Technical_Report.pdf</a>


</p>
<p>logical reasoning, æ•°å­¦ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€ç§‘å­¦ã€æ•°å­¦ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãªã©ã®åˆ†é‡ã§21B-A3Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚‚é–¢ã‚ã‚‰ãšDeepSeek-R1ã«é«˜ã„æ€§èƒ½ã‚’é”æˆã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã¯128kã€‚</p>
<p>ä½•ãŒæ±ºã‚æ‰‹ã§ã“ã®ã‚„ã†ãªå°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§é«˜ã„æ€§èƒ½ãŒå‡ºã‚‹ã®ã ã‚ã†ï¼Ÿãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã‚’èª­ã‚“ã ã‚‰ã‚ã‹ã‚‹ã‚“ã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2738" target="_blank" rel="noopener noreferrer" class="title-link">From Live Data to High-Quality Benchmarks: The Arena-Hard Pipeline, Li+, 2024.04</a>
<span class="snippet"><span>Comment</span><p>ArenaHardãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</p>
<p>ChatbotArenaã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã«è€ƒæ…®ã—ã¦å®šæœŸçš„ã«æŠ½å‡ºã•ã‚Œã‚‹é«˜å“è³ªãªreal worldã«è¿‘ã„ã®conversationãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚æŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹ã§ã¯promptã®å¤šæ§˜æ€§ã¨qualityãŒæ‹…ä¿ã•ã‚Œã‚‹å½¢ã§ã€200,000ã®ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®promptãŒæŠ½å‡ºã•ã‚Œãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‹ã‘ã‚‰ã‚Œã‚‹ã€‚<br>å¤šæ§˜æ€§ã¨ã„ã†è¦³ç‚¹ã§ã¯ã€å…¨ã¦ã®promptã‚’ OpenAI ã® `text-embedding-3-small` ã«ã‚ˆã£ã¦embeddingã«å¤‰æ›ã—ã€UMAPã«ã‚ˆã£ã¦æ¬¡å…ƒåœ§ç¸®ã‚’ã—ãŸå¾Œã«éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•ã«ã‚ˆã£ã¦ãƒˆãƒ”ãƒƒã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ã‚’å½¢æˆã™ã‚‹ã€‚å„ã‚¯ãƒ©ã‚¹ã‚¿ã«ã¯GPT-4-turboã§è¦ç´„ãŒä»˜ä¸ã•ã‚Œã€è¦ç´„ã‚’æ´»ç”¨ã—ã¦4000ã®ãƒˆãƒ”ãƒƒã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ã‚’é¸å®šã™ã‚‹ã€‚<br>ç¶šã„ã¦ã€å„ã‚¯ãƒ©ã‚¹ã‚¿ã«å«ã¾ã‚Œã‚‹ã‚¯ã‚¨ãƒªã¯å“è³ªãŒãƒãƒ©ãƒãƒ©ãªã®ã§ã€é«˜å“è³ªãªã‚‚ã®ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã«ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰LLM-as-a-Judgeï¼ˆGPT-3.5-Turbo, GPT-4-turboï¼‰ã‚’ç”¨ã„ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿæ–½ã™ã‚‹:<br>```<br>1. Specificity:Â Does the prompt ask for a specific output?<br>2. Domain Knowledge:Â Does the prompt cover one or more specific domains?<br>3. Complexity:Â Does the prompt have multiple levels of reasoning, components, or variables?<br>4. Problem-Solving:Â Does the prompt directly involve the AI to demonstrate active problem-solving skills?<br>5. Creativity:Â Does the prompt involve a level of creativity in approaching the problem?<br>6. Technical Accuracy:Â Does the prompt require technical accuracy in the response?<br>7. Real-world Application:Â Does the prompt relate to real-world applications?<br>```<br>ï¼ˆè¦³ç‚¹ã¯å…ƒè¨˜äº‹ã‹ã‚‰å¼•ç”¨ï¼‰<br><br>å„è¦³ç‚¹ã‚’æº€ãŸã—ã¦ã„ãŸã‚‰1ãƒã‚¤ãƒ³ãƒˆã¨ã—ã€å„promptã”ã¨ã«[0, 7]ã®ã‚¹ã‚³ã‚¢ãŒä»˜ä¸ã•ã‚Œã‚‹ã€‚å„ãƒˆãƒ”ãƒƒã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ã¯ã‚¯ãƒ©ã‚¹ã‚¿ä¸­ã®promptã®å¹³å‡ã‚¹ã‚³ã‚¢ã«ã‚ˆã£ã¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã•ã‚Œãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«æ´»ç”¨ã•ã‚Œã‚‹ã€‚<br>æœ€çµ‚çš„ã«250ã®high-qualityãªãƒˆãƒ”ãƒƒã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ï¼ˆã™ãªã‚ã¡ã€ã‚¹ã‚³ã‚¢ãŒ&gt;=6ã®ã‚¯ãƒ©ã‚¹ã‚¿ï¼‰ãŒé¸ã°ã‚Œã€å„ã‚¯ãƒ©ã‚¹ã‚¿ã‹ã‚‰2ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦åˆè¨ˆ500å€‹ã®benchmark promptã‚’å¾—ã‚‹ã€‚<br>è©•ä¾¡ã‚’ã™ã‚‹éš›ã¯ã€è©•ä¾¡å¯¾è±¡ã®ãƒ¢ãƒ‡ãƒ«ã¨strong baselineï¼ˆGPT-4-0314ï¼‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ¯”è¼ƒã—ã€LLM-as-a-Judgeï¼ˆGPT-4-Turbo, Claude-3-Opusï¼‰ã«ã‚ˆã£ã¦ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã®å“è³ªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã€‚position biasã«é…æ…®ã™ã‚‹ãŸã‚ã«reaponseã®ä½ç½®ã‚’å…¥ã‚Œæ›¿ãˆã¦å„ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã«2å›è©•ä¾¡ã™ã‚‹ã®ã§ã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯1000å€‹ã®ãƒšã‚¢ãƒ¯ã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿ã¨ãªã‚‹ã€‚<br>ã“ã®ãƒšã‚¢ãƒ¯ã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿ã‚’bootstrap resamplingã—ãŸä¸Šã§ã€Bradley-Terryãƒ¢ãƒ‡ãƒ«ï¼ˆ=å‹æ•—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å¼·ã•ã‚’æ•°å€¤åŒ–ã™ã‚‹çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰ã§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã§ã‚¹ã‚³ã‚¢ã‚’å¾—ã‚‹ã€‚<br><br>ArenaHardã¯MT Benchã‚ˆã‚Šã‚‚é«˜ã„è­˜åˆ¥åŠ›ã‚’ç²å¾—ã—ã¦ã„ã‚‹ã€‚<br><br>&lt;img width="981" height="833" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/a9bca283-31c2-4606-b59d-b7df60af43f1"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a9bca283-31c2-4606-b59d-b7df60af43f1"&lt;/a&gt;


/&gt;</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/623" target="_blank" rel="noopener noreferrer">ChatBot Arena, lmsys org, 2023.05</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/876" target="_blank" rel="noopener noreferrer">ChatBot Arenaã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2737" target="_blank" rel="noopener noreferrer" class="title-link">AlpacaEval, tatsu-lab, 2023.06</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2733" target="_blank" rel="noopener noreferrer" class="title-link">ã€JamC-QAã€: æ—¥æœ¬ã®æ–‡åŒ–ã‚„é¢¨ç¿’ã«ç‰¹åŒ–ã—ãŸè³ªå•å¿œç­”ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ§‹ç¯‰ãƒ»å…¬é–‹ï¼ˆå‰ç·¨ï¼‰, SB Intuitions, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sbintuitions/status/1965243405812011263?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¾Œç·¨ã‚‚å‚ç…§ã®ã“ã¨:


<a href="https://www.sbintuitions.co.jp/blog/entry/2025/09/09/113132" target="_blank" rel="noopener noreferrer">https://www.sbintuitions.co.jp/blog/entry/2025/09/09/113132</a>


</p>
<p>æ—¥æœ¬ã®æ–‡åŒ–ã€é¢¨ç¿’ã€é¢¨åœŸã€åœ°ç†ã€æ—¥æœ¬å²ã€è¡Œæ”¿ã€æ³•å¾‹ã€åŒ»ç™‚ã«é–¢ã™ã‚‹æ—¢å­˜ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ã‚ˆã‚Šã‚‚é›£æ˜“åº¦ãŒé«˜ã„QAã‚’äººæ‰‹ã«ã‚ˆã£ã¦ã‚¹ã‚¯ãƒ©ãƒƒãƒã‹ã‚‰ä½œæˆã—ãŸè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã€‚äººæ‰‹ã§ä½œæˆã•ã‚ŒãŸQAã«å¯¾ã—ã¦ã€8ç¨®é¡ã®å¼±ã„LLMï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å°ã•ã„æ—¥æœ¬èªLLMã‚’å«ã‚€ï¼‰ã®åŠæ•°ä»¥ä¸ŠãŒæ­£ã—ãå›ç­”ã§ããŸã‚‚ã®ã‚’é™¤å¤–ã€ãã®å¾Œã•ã‚‰ã«äººæ‰‹ã§ç¢ºèªã¨ã„ã£ãŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã‚’è¸ã‚“ã§ã„ã‚‹ã€‚è¨˜äº‹ä¸­ã¯äº‹ä¾‹ãŒéå¸¸ã«è±Šå¯Œã§èˆˆå‘³æ·±ã„ã€‚<br><br>å¾Œç·¨ã§ã¯å®Ÿéš›ã®è©•ä¾¡çµæœãŒè¨˜è¼‰ã•ã‚Œã¦ãŠã‚Šã€ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒã®æ—¥æœ¬èªLLMãŒé«˜ã„æ€§èƒ½ã‚’ç²å¾—ã—ã¦ãŠã‚Šã€Llama-Swallowãªã©ã®ç¶™ç¶šäº‹å‰å­¦ç¿’ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚‚é«˜ã„ã‚¹ã‚³ã‚¢ã‚’ç²å¾—ã—ã¦ã„ã‚‹ã€‚è©•ä¾¡æ™‚ã¯4-shotã§ãƒ‰ãƒ¡ã‚¤ãƒ³ã”ã¨ã«Examplarã¯å›ºå®šã—ã€greedy decodingã§è©•ä¾¡ã—ãŸã¨ã®ã“ã¨ã€‚</p>
<p>NLP'25:


<a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q2-18.pdf" target="_blank" rel="noopener noreferrer">https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q2-18.pdf</a>


</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1890" target="_blank" rel="noopener noreferrer">Non-Determinism of "Deterministic" LLM Settings, Berk Atil+, arXiv'24</a>
<br><br>ã®ã‚ˆã†ãªè©±ã‚‚ã‚ã‚‹ã®ã§ã€greedy decodingã ã‘ã§ãªãnucleus/temperature samplingã‚’è¤‡æ•°trialå®Ÿæ–½ã—ãŸå ´åˆã®æ€§èƒ½ã®å¹³å‡ã§ä½•ã‹å¤‰åŒ–ãŒã‚ã‚‹ã ã‚ã†ã‹ã€ã¨ã„ã†ç‚¹ãŒæ°—ã«ãªã£ãŸãŒã€ä¸‹è¨˜ç ”ç©¶ã§MMLUã®ã‚ˆã†ãªå‡ºåŠ›ç©ºé–“ãŒåˆ¶ç´„ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªè¨­å®šã®å ´åˆã¯ã»ã¨ã‚“ã©å½±éŸ¿ãŒãªã„ã“ã¨ãŒå®Ÿé¨“çš„ã«ç¤ºã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2735" target="_blank" rel="noopener noreferrer">[Paper Note] The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore   Non-Determinism, Yifan Song+, NAACL'25</a>
<br><br>ã“ã‚Œã¯nucleus/temperature samplingãŒææ¡ˆã•ã‚ŒãŸèƒŒæ™¯ï¼ˆï¼å‡ºåŠ›ã®è‡ªç„¶ã•ã‚’ä¿ã£ãŸã¾ã¾å¤šæ§˜æ€§ã‚’å¢—ã‚„ã—ãŸã„ï¼‰ã¨ã‚‚ä¸€è‡´ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2721" target="_blank" rel="noopener noreferrer" class="title-link">FinePDFs, HuggingFaceFW, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aratako_lm/status/1964596642067402987?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Thomas Wolfæ°ã®ãƒã‚¹ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thom_wolf/status/1964653264986656922?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ODC-By 1.0 license</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2720" target="_blank" rel="noopener noreferrer" class="title-link">Fast-dLLM v2: Efficient Block-Diffusion Large Language Model, Wu+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/songhan_mit/status/1964375581761388828?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2719" target="_blank" rel="noopener noreferrer" class="title-link">CLOCKBENCH: VISUAL TIME BENCHMARK WHERE HUMANS BEAT THE CLOCK, LLMS DONâ€™T ALEK SAFAR ï¼ˆOLEG CHICHIGINï¼‰, 2025.09</a>
<span class="snippet"><span>Comment</span><p>ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰:


<a href="https://clockbench.ai" target="_blank" rel="noopener noreferrer">https://clockbench.ai</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alek_safar/status/1964383077792141390?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ§˜ã€…ãªç¨®é¡ã®æ™‚è¨ˆï¼ˆe.g., åè»¢ã€ãƒ•ã‚©ãƒ³ãƒˆã®é•ã„, invalidãªæ™‚åˆ»ã®å­˜åœ¨, å¤§ãã•, ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãªã©; p.2å‚ç…§ã®ã“ã¨)ã®æ™‚åˆ»ã‚’èª­ã¿å–ã‚Šï¼ˆã‚ã‚‹ã„ã¯validãªæ™‚åˆ»ã‹å¦ã‹ã‚’åˆ¤å®šã—)ã€èª­ã¿å–ã£ãŸæ™‚åˆ»ã«å¯¾ã—ã¦QAï¼ˆe.g., Xæ™‚é–“Yåˆ†Zç§’é€²ã‚ã‚‹ã€æˆ»ã—ãŸæ™‚åˆ»ã¯ï¼Ÿé•·é‡ã‚’30/60/90åº¦å‹•ã‹ã—ãŸæ™‚åˆ»ã¯ï¼Ÿã“ã®æ™‚åˆ»ãŒãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯ã®æ™‚é–“ã ã¨ã—ãŸã‚‰ãƒ­ãƒ³ãƒ‰ãƒ³ã®æ™‚åˆ»ã¯ï¼Ÿ)ã‚’å®Ÿæ–½ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚äººé–“ã®æ­£è§£ç‡ã¯89.1%ã«å¯¾ã—ã¦SoTAãƒ¢ãƒ‡ãƒ«ã§ã‚‚13.3%ç¨‹åº¦ã€‚contaminationã«é…æ…®ã—ã¦å…¨ã¦ã‚¹ã‚¯ãƒ©ãƒƒãƒã‹ã‚‰ä½œæˆã•ã‚Œã€å…¨ä½“ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã¯privateãªã¾ã¾ã«ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚<br><img src="https://github.com/user-attachments/assets/aa2ca43c-97c9-49c3-a93b-d1897858d598" alt="image" loading="lazy"></p>
<p>ç¶šå ±:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alek_safar/status/1972697598155706443?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Qwen3-VL-235B-InstructãŒGPT-5 Chatè¶…ãˆ</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/Cultural.html" target="_blank" rel="noopener noreferrer">#Cultural</a>
<span class="issue_date">Issue Date: 2025-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2717" target="_blank" rel="noopener noreferrer" class="title-link">MECHA-ja, llm-jp, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/silviasetitech/status/1964470358595293639?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Composition.html" target="_blank" rel="noopener noreferrer">#Composition</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2712" target="_blank" rel="noopener noreferrer" class="title-link">From fï¼ˆxï¼‰ and gï¼ˆxï¼‰ to fï¼ˆgï¼ˆxï¼‰ï¼‰: LLMs Learn New Skills in RL by Composing Old Ones, Yuan+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1964235195613143127?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã•ã‚ŒãŸå®Ÿé¨“ã«ãŠã„ã¦ã€æ·±ã•2ã®nestedãªcompostition g(f(x))ã®ãƒ‡ãƒ¼ã‚¿ã§RLã—ãŸå ´åˆã¯ã€ãƒ†ã‚¹ãƒˆæ™‚ã«æ·±ã•6ã¾ã§ã®compostitionã‚’å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸãŒï¼ˆï¼ãƒ¡ã‚¿ã‚¹ã‚­ãƒ«ã¨ã—ã¦compostitionã‚’ç²å¾—ã—ãŸï¼‰ã€æ·±ã•1ã®non-nestedãªãƒ‡ãƒ¼ã‚¿ã§RLã—ãŸå ´åˆã¯è¤‡é›‘ãªcompostitionãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã‚’è§£ã‘ãªã‹ã£ãŸã€‚ã¾ãŸã€ä¸€èˆ¬çš„ã«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ç¨‹åº¦è§£ã‘ã‚‹å•é¡Œã«å¯¾ã—ã¦RLã‚’é©ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®pass@1000ã¯ã‚ã¾ã‚Šå‘ä¸Šã—ãªã„ã“ã¨ã‹ã‚‰ã€RLã¯æ–°ã—ã„ã‚¹ã‚­ãƒ«ã‚’ä½•ã‚‚æ•™ãˆã¦ã„ãªã„ã®ã§ã¯ãªã„ã‹ã€ã¨ã„ã£ãŸè§£é‡ˆãŒã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ãŒã€ã‚ˆã‚Šé«˜æ¬¡ã®compostitionãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã™ã‚‹ã¨æ˜ç¢ºã«æ€§èƒ½ãŒè‰¯ããªã‚‹ã®ã§ã€å®Ÿã¯ã‚ˆã‚Šé«˜æ¬¡ã®compostitionãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã‚’ä¼¸ã°ã—ã¦ã„ã‚‹ã€‚compostitionã§ã®èƒ½åŠ›ã‚’ç™ºæ®ã™ã‚‹ã«ã¯ã¾ãšå¹…åºƒã„atomicãªã‚¹ã‚­ãƒ«ãŒå¿…è¦ãªã®ã§ã€ã—ã£ã‹ã‚Šãã‚Œã‚’äº‹å‰å­¦ç¿’ã§èº«ã«ã¤ã‘ã•ã›ã€ãã®å¾Œpost-trainingã«ã‚ˆã£ã¦è§£æ±ºã—ãŸã„ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã®atomic skillã®compostitionã®æ–¹æ³•ã‚’å­¦ç¿’ã•ã›ã‚‹ã¨åŠ¹æœçš„ãªã®ã§ã¯ãªã„ã‹ã€ã¨ã„ã£ãŸè©±ãªæ¨¡æ§˜ã€‚</p>
<p>ã“ã®è¾ºã®ICLã®è©±ã¨ä¼¼ã¦ã„ã‚‹<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1362" target="_blank" rel="noopener noreferrer">What Do Language Models Learn in Context? The Structured Task Hypothesis, Jiaoda Li+, N/A, ACL'24</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2709" target="_blank" rel="noopener noreferrer" class="title-link">Why Language Models Hallucinate, Kalai+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/adamfungi/status/1964040819196752312?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1964837910278189271?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ziv_ravid/status/1964384106567127465?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2705" target="_blank" rel="noopener noreferrer" class="title-link">FineWeb2 Edu Japanese, Yuichi Tateno, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1964127750782144952?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2701" target="_blank" rel="noopener noreferrer" class="title-link">Kimi-K2-Instruct-0905, MoonshotAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>ä»¥å‰ã¨æ¯”è¼ƒã—ã¦SWE Benchç³»ã®æ€§èƒ½ãŒå¤§å¹…ã«å‘ä¸Šã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1963804320522207422?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kimi_moonshot/status/1963802687230947698?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Artificial Analysisã«ã‚ˆã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°çµæœ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1965010554499788841?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Agenticãªèƒ½åŠ›ãŒé¡•è‘—ã«æ”¹å–„ã—ã¦ã„ã‚‹æ—¨ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<p>Creative Short Story Benchmarkã¨å‘¼ã°ã‚Œã‚‹ã§SoTA:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/koltregaskes/status/1966125826887602635?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>


<a href="https://github.com/lechmazur/writing" target="_blank" rel="noopener noreferrer">https://github.com/lechmazur/writing</a>


<br><br>ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€object, tone, Attributeãªã©ã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’æ§‹æˆã™ã‚‹è¦ç´ ã®ã¿ã‚’æŒ‡å®šã—ã¦ã€600-800ç¨‹åº¦ã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’è¨˜è¿°ã•ã›ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€è©•ä¾¡ã¯18å€‹ã®ãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ï¼ˆ8ã“ã™ã®ãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã§narrativeã¨ã—ã¦ã®å“è³ªã‚’è©•ä¾¡ã—ã€æ®‹ã‚Šã§æ§‹æˆã‚„requirementsã‚’æº€ãŸã—ã¦ã„ã‚‹ã‹ãªã©ã®è©•ä¾¡ã‚’ã™ã‚‹ï¼‰ã«åŸºã¥ãè¤‡æ•°LLMã«ã‚ˆã‚‹LLM-as-a-Judgeã«ã‚ˆã‚‹ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°çµæœã‚’é›†ç´„ã™ã‚‹ã“ã¨ã§å®Ÿæ–½ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br>ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã«åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹LLMã¯ä¸‹è¨˜:<br><br>- Claude Opus 4.1 (no reasoning)<br>- DeepSeek V3.1 Reasoner<br>- Gemini 2.5 Pro<br>- GPT-5 (low reasoning)<br>- Grok 4<br>- Kimi K2<br>- Qwen 3 235B A22B 25-07 Think<br><br>è¤‡æ•°LLMã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã¨ã¯ã„ãˆã€è©•ä¾¡å¯¾è±¡ã®ãƒ¢ãƒ‡ãƒ«ã‚‚gradeã§åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã«å«ã¾ã‚Œã¦ã„ã‚‹ã®ã¯æ°—ã«ãªã‚‹ã¨ã“ã‚ã€‚ã‚ã¨ã¯narrativeã®å“è³ªè©•ä¾¡ã¯LLMã§ã©ã“ã¾ã§ã§ãã‚‹ã®ã ã‚ã†ã‹ã€‚</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2668" target="_blank" rel="noopener noreferrer" class="title-link">Inside vLLM: Anatomy of a High-Throughput LLM Inference System, Aleksa GordiÄ‡ blog, 2025.08</a>
<span class="snippet"><span>Comment</span><p>ã‚ã£ã¡ã‚ƒè‰¯ã•ãã†</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2666" target="_blank" rel="noopener noreferrer" class="title-link">APERTUS: DEMOCRATIZING OPEN AND COMPLIANT LLMS FOR GLOBAL LANGUAGE ENVIRONMENTS, Apertus Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/collections/swiss-ai/apertus-llm-68b699e65415c231ace3b059" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/swiss-ai/apertus-llm-68b699e65415c231ace3b059</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haeggee/status/1962933627584413721?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>1811ã‚«å›½èªã«å¯¾å¿œã—ãŸã€ã‚¹ã‚¤ã‚¹ç™ºã®OpenSourceï¼ˆ=å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã€å­¦ç¿’ã®ãƒ¬ã‚·ãƒ”ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å†ç¾ã™ã‚‹ãŸã‚ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚‚å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ï¼‰ LLMã€‚8B / 70BãŒå­˜åœ¨ã€‚</p>
<p>Apache 2.0 + Apertus LLM Acceptable Use Policy</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1963187226189115602?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2652" target="_blank" rel="noopener noreferrer" class="title-link">August 2025 - China Open Source  Highlights, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/adinayakup/status/1962508234549329969?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2646" target="_blank" rel="noopener noreferrer" class="title-link">slime, THUDM &amp; Zhihu, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhihufrontier/status/1962751555591086226?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>GLM-4.5ã®RLå­¦ç¿’ã«åˆ©ç”¨ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2406" target="_blank" rel="noopener noreferrer">[Paper Note] GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models, GLM-4. 5 Team+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2641" target="_blank" rel="noopener noreferrer" class="title-link">RLinf: Reinforcement Learning Infrastructure for Agentic AI, RLinf, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1962441512207491217?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2640" target="_blank" rel="noopener noreferrer" class="title-link">The Hitchhiker's Guide to Autonomous Research: A Survey of Scientific Agents, Wang+, TechRxiv, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1962438146156855554?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2634" target="_blank" rel="noopener noreferrer" class="title-link">Hunyuan-MT-7B, Tencent, 2025.09</a>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ:


<a href="https://github.com/Tencent-Hunyuan/Hunyuan-MT/blob/main/Hunyuan_MT_Technical_Report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/Tencent-Hunyuan/Hunyuan-MT/blob/main/Hunyuan_MT_Technical_Report.pdf</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tencenthunyuan/status/1962466712378577300?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Base Modelã«å¯¾ã—ã¦ã¾ãšä¸€èˆ¬çš„ãªäº‹å‰å­¦ç¿’ã‚’å®Ÿæ–½ã—ã€ãã®å¾ŒMTã«ç‰¹åŒ–ã—ãŸç¶™ç¶šäº‹å‰å­¦ç¿’ï¼ˆãƒ¢ãƒãƒªãƒ³ã‚¬ãƒ«/ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã®åˆ©ç”¨ï¼‰ã€äº‹å¾Œå­¦ç¿’ï¼ˆSFT, GRPO)ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br>ç¶™ç¶šäº‹å‰å­¦ç¿’ã§ã¯ã€æœ€é©ãªDataMixã®æ¯”ç‡ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«ã€RegMixã¨å‘¼ã°ã‚Œã‚‹æ‰‹æ³•ã‚’åˆ©ç”¨ã€‚Catastrophic Forgettingã‚’é˜²ããŸã‚ã«ã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®20%ã‚’å«ã‚ã‚‹ã¨ã„ã£ãŸæ–½ç­–ã‚’å®Ÿæ–½ã€‚<br><br>SFTã§ã¯2ã¤ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹ã€‚ã‚¹ãƒ†ãƒ¼ã‚¸1ã¯åŸºç¤çš„ãªç¿»è¨³åŠ›ã®å¼·åŒ–ã¨ç¿»è¨³ã«é–¢ã™ã‚‹æŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ã®å‘ä¸Šã®ãŸã‚ã«ã€Flores-200ã®é–‹ç™ºãƒ‡ãƒ¼ã‚¿(33è¨€èªã®åŒæ–¹å‘ã®ç¿»è¨³ã‚’ã‚«ãƒãƒ¼)ã€å‰å¹´åº¦ã®WMTã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ(English to XXã‚’ã‚«ãƒãƒ¼ï¼‰ã€Mandarin to Minority, Minority to Mandarinã®curatedãªäººæ‰‹ã§ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã€DeepSeek-V3-0324ã§ã®åˆæˆãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã€general purpose/MT orientedãªæŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã†ã¡20%ã‚’æ§‹æˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã§ç¿»è¨³ã®instructinoã«é–¢ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®å‡¡åŒ–æ€§èƒ½ã‚’é«˜ã‚ã‚‹ãŸã‚ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã€ã§å­¦ç¿’ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã¯Reference-freeãªæ‰‹æ³•ã‚’ç”¨ã„ã¦ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã—é–¾å€¤ä»¥ä¸‹ã®ä½å“è³ªãªç¿»è¨³å¯¾ã¯é™¤å¤–ã—ã¦ã„ã‚‹ã€‚ã‚¹ãƒ†ãƒ¼ã‚¸2ã§ã¯ã€è©³ç´°ãŒæ›¸ã‹ã‚Œã¦ã„ãªã„ãŒã€å°‘é‡ã§ã‚ˆã‚Šfidelityã®é«˜ã„ç´„270kã®ç¿»è¨³å¯¾ã‚’åˆ©ç”¨ã—ãŸæ¨¡æ§˜ã€‚ã¾ãŸã€å…ˆè¡Œç ”ç©¶ã«åŸºã¥ã„ã¦ã€many-shotã®in-context learningã‚’ç”¨ã„ã¦ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ã•ã‚‰ã«æ´—ç·´ã•ã›ãŸã¨ã®ã“ã¨ï¼ˆå…ˆè¡Œç ”ç©¶ãŒå¼•ç”¨ã•ã‚Œã¦ã„ã‚‹ã®ã¿ã§è©³ç´°ãªè¨˜è¿°ã¯ç„¡ã—ï¼‰ã€‚ã¾ãŸã€è¤‡æ•°ã®è©•ä¾¡ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã‚¹ã‚³ã‚¢ã®ä¸€è²«æ€§ãŒç„¡ã„ã‚µãƒ³ãƒ—ãƒ«ã¯æ‰‹å‹•ã§ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚ã‚‹ã„ã¯verificationã‚’ã—ã¦å“è³ªã‚’æ‹…ä¿ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br>RLã§ã¯GRPOã‚’æ¡ç”¨ã—ã€rewardã¨ã—ã¦semantic(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2635" target="_blank" rel="noopener noreferrer">[Paper Note] xCOMET: Transparent Machine Translation Evaluation through Fine-grained  Error Detection, Nuno M. Guerreiro+, TACL'24</a>
), terminology(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2649" target="_blank" rel="noopener noreferrer">[Paper Note] TAT-R1: Terminology-Aware Translation with Reinforcement Learning and
  Word Alignment, Zheng Li+, arXiv'25</a>
; ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ã®terminologyã‚’æ‰ãˆã‚‹), repetitionã«åŸºã¥ã„ãŸrewardã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚æœ€çµ‚çš„ã«SFT-&gt;RLã§å­¦ç¿’ã•ã‚ŒãŸHuayuan-MT-7Bã«å¯¾ã—ã¦ã€ä¸‹è¨˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”¨ã„ã¦è¤‡æ•°ã®outputã‚’çµ±åˆã—ã¦ã‚ˆã‚Šé«˜å“è³ªãªç¿»è¨³ã‚’å‡ºåŠ›ã™ã‚‹ã‚­ãƒ¡ãƒ©ãƒ¢ãƒ‡ãƒ«ã‚’åŒæ§˜ã®rewardã‚’ç”¨ã„ã¦å­¦ç¿’ã™ã‚‹ã€ã¨ã„ã£ãŸpipelineã«ãªã£ã¦ã„ã‚‹ã€‚<br><br>&lt;img width="884" height="462" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/dbb7a799-6304-4cfa-b75c-74b44fe39a2e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/dbb7a799-6304-4cfa-b75c-74b44fe39a2e"&lt;/a&gt;


/&gt;<br><br>&lt;img width="921" height="279" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/33b49ef7-b93b-4094-b83e-5931d2b411e5"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/33b49ef7-b93b-4094-b83e-5931d2b411e5"&lt;/a&gt;


/&gt;</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1220" target="_blank" rel="noopener noreferrer">Large Language Models Are State-of-the-Art Evaluators of Translation Quality, EAMT'23</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2635" target="_blank" rel="noopener noreferrer">[Paper Note] xCOMET: Transparent Machine Translation Evaluation through Fine-grained  Error Detection, Nuno M. Guerreiro+, TACL'24</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2636" target="_blank" rel="noopener noreferrer">[Paper Note] CometKiwi: IST-Unbabel 2022 Submission for the Quality Estimation Shared Task, Rei+, WMT'22</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2637" target="_blank" rel="noopener noreferrer">[Paper Note] No Language Left Behind: Scaling Human-Centered Machine Translation, NLLB Team+, arXiv'22</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2638" target="_blank" rel="noopener noreferrer">[Paper Note] Many-Shot In-Context Learning, Rishabh Agarwal+, NeurIPS'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2639" target="_blank" rel="noopener noreferrer">[Paper Note] RegMix: Data Mixture as Regression for Language Model Pre-training, Qian Liu+, ICLR'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2649" target="_blank" rel="noopener noreferrer">[Paper Note] TAT-R1: Terminology-Aware Translation with Reinforcement Learning and
  Word Alignment, Zheng Li+, arXiv'25</a>
</p>
<p>é–¢é€£: PLaMoç¿»è¨³<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2517" target="_blank" rel="noopener noreferrer">PLaMo Translate: ç¿»è¨³ç‰¹åŒ–å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é–‹ç™º,ä»ŠåŸ+, Jxiv'25</a>
<br><br>ã“ã¡ã‚‰ã¯SFT-&gt;Iterative DPO-&gt;Model Mergeã‚’å®Ÿæ–½ã—ã€ç¿»è¨³ã«ç‰¹åŒ–ã—ãŸç¶™ç¶šäº‹å‰å­¦ç¿’ã¯ã‚„ã£ã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ä¸€æ–¹ã€SFTæ™‚ç‚¹ã§ç‹¬è‡ªã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã—ã€èªå½™ã®æŒ‡å®šã‚„ã‚¹ã‚¿ã‚¤ãƒ«ã€æ—¥æœ¬èªç‰¹æœ‰ã®å¸¸ä½“ã€æ•¬ä½“ã®æŒ‡å®šãªã©ã‚’å®Ÿæ–½ã§ãã‚‹ã‚ˆã†ã«ç¿»è¨³ã«ç‰¹åŒ–ã—ãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å­¦ç¿’ã—ã¦ã„ã‚‹ç‚¹ãŒç•°ãªã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚Hunyuanã¯å¤šæ§˜ãªç¿»è¨³ã®æŒ‡ç¤ºã«å¯¾å¿œã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã—ã¦ã„ã‚‹ãŒã€PLaMoç¿»è¨³ã¯ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚’çµã‚Šè¾¼ã¿ã€ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«å¯¾ã™ã‚‹æ€§èƒ½ã‚’é«˜ã‚ã‚‹ã‚ˆã†ãªç‰¹åŒ–å‹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ã¨ã‚‹ã¨ã„ã£ãŸæ€æƒ³ã®é•ã„ãŒä¼ºãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2631" target="_blank" rel="noopener noreferrer" class="title-link">Nemotron-CC-v2, Nvidia, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zeyuanallenzhu/status/1962119316427706828?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>CCã ã‘ã§ãªãã€æ•°å­¦ã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã€SFT styleã®åˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚å«ã¾ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2628" target="_blank" rel="noopener noreferrer" class="title-link">Probing LLM Social Intelligence via Werewolf, foaster.ai, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gdb/status/1962210896601845878?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2620" target="_blank" rel="noopener noreferrer" class="title-link">LongCat-Flash-Chat, meituan-longcat, 2025.08</a>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ:


<a href="https://github.com/meituan-longcat/LongCat-Flash-Chat/blob/main/tech_report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/meituan-longcat/LongCat-Flash-Chat/blob/main/tech_report.pdf</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1961955926136832381?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Agentå‘¨ã‚Šã®ãƒ™ãƒ³ãƒã§é«˜æ€§èƒ½ãªnon thinkingãƒ¢ãƒ‡ãƒ«ã€‚æ¯ç§’100+ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆé€Ÿåº¦ã§ã€MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã€‚Dynamic Activation...?</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2621" target="_blank" rel="noopener noreferrer">[Paper Note] Shortcut-connected Expert Parallelism for Accelerating   Mixture-of-Experts, Weilin Cai+, ICLR'25</a>
</p>
<p>Dynamic Activation (activation paramãŒå…¥åŠ›ã«å¿œã˜ã¦å¤‰åŒ–(å…¨ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’MoEã«ãŠã„ã¦å‡ä¸€ã«æ‰±ã‚ãªã„ï¼‰ã™ã‚‹ã“ã¨ã§åŠ¹ç‡åŒ–ï¼‰ã¯ã€ä¸‹è¨˜ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§å®Ÿç¾ã—ã¦ã„ã‚‹æ¨¡æ§˜<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2622" target="_blank" rel="noopener noreferrer">[Paper Note] MoE++: Accelerating Mixture-of-Experts Methods with Zero-Computation   Experts, Peng Jin+, ICLR'25</a>
</p>
<p>ã—ã‹ã—ä¸­å›½ã¯æœ¬å½“ã«æ¬¡ã€…ã«è‰²ã€…ãªä¼æ¥­ã‹ã‚‰åŸºç›¤ãƒ¢ãƒ‡ãƒ«ãŒå‡ºã¦ãã‚‹ãªãâ€¦ã™ã”ã„</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2623" target="_blank" rel="noopener noreferrer">[Paper Note] Scaling Exponents Across Parameterizations and Optimizers, Katie Everett+, ICML'24</a>
 </p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nrehiew_/status/1962186876099739767?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1962980770550628841?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2617" target="_blank" rel="noopener noreferrer" class="title-link">LLMã¯æ•™è‚²ã‚’ã©ã†å¤‰ãˆã‚‹ã‹ï¼šä¸»è¦3ç¤¾ã®ã€Œå­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã€æ¯”è¼ƒè€ƒå¯Ÿ, Kawamoto, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/toshikikawamoto/status/1961443496063336522?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2025-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2596" target="_blank" rel="noopener noreferrer" class="title-link">ã¤ãã£ã¦ç´å¾—ã€ã¤ã‹ã£ã¦å®Ÿæ„Ÿï¼ å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã“ã¨ã¯ã˜ã‚, Recruit, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/schroneko/status/1960995191550083154?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLMå…¥é–€ã«ã¨ã¦ã‚‚è‰¯ã•ãã†</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/CovarianceShift.html" target="_blank" rel="noopener noreferrer">#CovarianceShift</a>
<span class="issue_date">Issue Date: 2025-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2570" target="_blank" rel="noopener noreferrer" class="title-link">ã€Œæ¨è«–ã™ã‚‹ç”ŸæˆAIã€ã¯äº‹å‰å­¦ç¿’ã•ã‚Œã¦ã„ãªã„èª²é¡Œã‚’æ­£ã—ãæ¨è«–ã™ã‚‹ã“ã¨ãŒã§ããªã„ï¼ˆå…±å¤‰é‡ã‚·ãƒ•ãƒˆã«å¼±ã„ï¼‰, TJO, 2025.08</a>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2397" target="_blank" rel="noopener noreferrer">[Paper Note] Physics of Language Models: Part 2.1, Grade-School Math and the Hidden   Reasoning Process, Tian Ye+, ICLR'25</a>
<br><br>ã§LLMã¯æœªçŸ¥ã®å•é¡Œã‚’è§£ã‘ã‚‹ï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªã„åŒç­‰ã®lengthã®æœªçŸ¥ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è§£ã‘ã‚‹/ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚ã‚ˆã‚Šè¤‡é›‘ãªé•·ã„lengthã®å•é¡Œã‚’è§£ã‘ã‚‹ï¼‰ã¨æ¯”ã¹ã‚‹ã¨ã€ä¸¡è€…ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹çµè«–ã‹ã‚‰ä½•ãŒè¨€ãˆã‚‹ã®ã ã‚ã†ã‹ï¼Ÿè¦³æ¸¬ã§ãã‚‹CoTã¨hidden mental reasoning process (probingã§è¡¨å‡ºã•ã›ã¦åˆ†æï¼‰ã¯åˆ†ã‘ã¦è€ƒãˆã‚‹å¿…è¦ãŒã‚ã‚‹ã®ã‹ã‚‚ã—ã‚Œãªã„ã€‚å…ƒè«–æ–‡ã‚’ãã¡ã‚“ã¨èª­ã‚ã¦ã„ãªã„ã‹ã‚‰è€ƒãˆã¦ã¿ãŸã„ã€‚<br><br>ã‚ã¨ã€ãƒ–ãƒ­ã‚°ä¸­ã§ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹è«–æ–‡ä¸­ã§ã¯Physics of Language ModelsãŒå¼•ç”¨ã•ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ãŒã€è«–æ–‡ä¸­ã§å¼•ç”¨ã•ã‚Œã€é–¢é€£æ€§ãƒ»å·®åˆ¥åŒ–ã«ã¤ã„ã¦è¨€åŠã•ã‚Œã¦ã„ãŸæ–¹ãŒè‰¯ã„ã®ã§ã¯ãªã„ã‹ï¼Ÿã¨ã„ã†æ„Ÿæƒ³ã‚’æŠ±ã„ãŸã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2569" target="_blank" rel="noopener noreferrer">[Paper Note] Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens, Chengshuai Zhao+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2571" target="_blank" rel="noopener noreferrer">[Paper Note] Understanding deep learning requires rethinking generalization, Chiyuan Zhang+, ICLR'17</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2575" target="_blank" rel="noopener noreferrer">[Paper Note] UQ: Assessing Language Models on Unsolved Questions, Fan Nie+, arXiv'25</a>
</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tjo_datasci/status/1960858549359403150?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2561" target="_blank" rel="noopener noreferrer" class="title-link">MiniCPM-V-4_5, openbmb, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/adinayakup/status/1960292853453672886?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CTRPrediction.html" target="_blank" rel="noopener noreferrer">#CTRPrediction</a>
<span class="issue_date">Issue Date: 2025-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2559" target="_blank" rel="noopener noreferrer" class="title-link">Self-Monitoring Large Language Models for Click-Through Rate Prediction, Zhou+, ACM Transactions on Information Systems, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1960558009538764873?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2551" target="_blank" rel="noopener noreferrer" class="title-link">The Bitter Lesson for RL: Verification as the key to Reasoning LLMs, Rishabh Agarwal, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yongyuanxi/status/1960040848051372379?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/agarwl_/status/1931089624132211078"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2550" target="_blank" rel="noopener noreferrer" class="title-link">Why Stacking Sliding Windows Can't See Very Far, Guangxuan Xiao , 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/guangxuan_xiao/status/1960103495081541921?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/TTS.html" target="_blank" rel="noopener noreferrer">#TTS</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2547" target="_blank" rel="noopener noreferrer" class="title-link">VibeVoice-1.5B, microsoft, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1959979976536789403?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>&gt; Unsupported language â€“ the model is trained only on English and Chinese data; outputs in other languages are unsupported and may be unintelligible or offensive.<br><br>æ—¥æœ¬èªã¯å¯¾å¿œã—ã¦ã„ãªã„ã®ã§æ³¨æ„</p>
<p>outputã§ãã‚‹speechã®lengthãŒå…ˆè¡Œç ”ç©¶ã‚ˆã‚Šéå¸¸ã«é•·ãã€90åˆ†è¿‘ãç”Ÿæˆã§ãã‚‹æ¨¡æ§˜ï¼Ÿ<br><br><img src="https://github.com/user-attachments/assets/4654d97a-5ba0-4d14-8bcf-3a009282515b" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2539" target="_blank" rel="noopener noreferrer" class="title-link">TxT360, LLM360, 2024.10</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2515" target="_blank" rel="noopener noreferrer" class="title-link">Command A Reasoning: Enterprise-grade control for AI agents, Cohere, 2025.08</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/CohereLabs/command-a-reasoning-08-2025" target="_blank" rel="noopener noreferrer">https://huggingface.co/CohereLabs/command-a-reasoning-08-2025</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1958582982005944496?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Agenté–¢é€£ãƒ™ãƒ³ãƒã§R1, gptossè¶…ãˆã€‚DeepResearchãƒ™ãƒ³ãƒã§ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªLLMã¨æ¯”ã¹ã¦SoTAã€‚safetyé–¢é€£ãƒ™ãƒ³ãƒã§R1, gptossè¶…ãˆã€‚<br>ã™ã€ã™ã”ã„ã®ã§ã¯ã€ã€ï¼Ÿ</p>
<p>CC-BY-NC 4.0ãªã®ã§å•†ç”¨åˆ©ç”¨ä¸å¯</p>
<p>ã‚µãƒãƒª:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1960840619095634326?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2513" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-V3.1-Base, deepseek-ai, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/umiyuki_ai/status/1958422590806249550?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>æ•°æ—¥å‰ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«è‡ªä½“ã¯å…¬é–‹ã•ã‚Œã¦ã„ãŸãŒã€ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ãŒè¿½åŠ ã•ã‚ŒãŸ<p>- hybrid thinking<br>- post-trainingã«ã‚ˆã‚‹tool calling capabilityå‘ä¸Š<br>- token efficiencyã®å‘ä¸Š</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1958472154472690159?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1958438863279681824?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚µãƒãƒª:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1960840570873766171?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/SpeculativeDecoding.html" target="_blank" rel="noopener noreferrer">#SpeculativeDecoding</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2499" target="_blank" rel="noopener noreferrer" class="title-link">vLLMã®Speculative Decodingã«ã‚ˆã‚‹æ¨è«–é«˜é€ŸåŒ–ã‚’è©¦ã™, Aratako, 2025.05</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2498" target="_blank" rel="noopener noreferrer" class="title-link">Aider LLM Leaderboards, 2024.12</a>
<span class="snippet"><span>Comment</span><p>æœ€è¿‘ã‚ˆãè¦‹ã‹ã‘ã‚‹ã„ã‚ã‚†ã‚‹Aider Polyglotã€‚äººé–“ã®ä»‹å…¥ãªã—ã«ã€LLMãŒã‚³ãƒ¼ãƒ‰ã®"ç·¨é›†"ã‚’ã™ã‚‹èƒ½åŠ›ã‚’æ¸¬ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚æ€§èƒ½ã ã‘ã§ãªãã‚³ã‚¹ãƒˆã‚‚ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚C++,Go,Java,JavaScript,Python,Rustã«ã‚ˆã‚‹Exercimã«ãŠã‘ã‚‹225ã®"æœ€ã‚‚å›°é›£ãª"ã‚¨ã‚¯ã‚µã‚µã‚¤ã‚ºã®ã¿ãŒå«ã¾ã‚Œã‚‹ã€‚</p>
<p>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:


<a href="https://github.com/Aider-AI/polyglot-benchmark" target="_blank" rel="noopener noreferrer">https://github.com/Aider-AI/polyglot-benchmark</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-08-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2495" target="_blank" rel="noopener noreferrer" class="title-link">Swallow LLM Leaderboard v2, Swallow LLM Team, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chokkanorg/status/1958063716110594255?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLMã®æ€§èƒ½ã‚’å…¬å¹³ãªæ¡ä»¶ã§è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€å¾“æ¥ã®non thinkingãƒ¢ãƒ‡ãƒ«ã§æ¡ç”¨ã—ã¦ã„ãŸæ–¹æ³•ã¯thinkingãƒ¢ãƒ‡ãƒ«ã§ã¯éå°è©•ä¾¡ã«ã¤ãªãŒã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸï¼ˆe.g., non thinkingãƒ¢ãƒ‡ãƒ«ã¯zero shotã‚’æ¨™æº–ã¨ã™ã‚‹ãŒã€thinkingãƒ¢ãƒ‡ãƒ«ã§ã¯fewshotã€chat templateã®æ¡ç”¨ç­‰ï¼‰ãŸã‚ã€æ—¥æœ¬èª/è‹±èªã¨ã‚‚ã«ä¿¡é ¼ã®é«˜ã„6ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æ¡ç”¨ã—ã€thinkingãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦å…¬å¹³ãªçµ±ä¸€çš„ãªè©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç¢ºç«‹ã€‚ä¸»è¦ãªãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªã€OpenLLMã«å¯¾ã—ã¦è©•ä¾¡ã‚’å®Ÿæ–½ã—ã€ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã¨ã—ã¦å…¬é–‹ã€‚Reasoningãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹æœ€æ–°ã®æ—¥æœ¬èªæ€§èƒ½ã‚’çŸ¥ã‚ŠãŸã„å ´åˆã¯ã“ã¡ã‚‰ã‚’å‚ç…§ã™ã‚‹ã®ãŒè‰¯ã„ã¨æ€ã‚ã‚Œã‚‹ã€‚</p>
<p>è©•ä¾¡ã«ç”¨ã„ã‚‰ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã“ã¡ã‚‰:<br>


<a href="https://github.com/swallow-llm/swallow-evaluation-instruct" target="_blank" rel="noopener noreferrer">https://github.com/swallow-llm/swallow-evaluation-instruct</a>


</p>
<p>ä¸»è¦ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½æ¯”è¼ƒ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chokkanorg/status/1958063946826428424?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2025-08-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2494" target="_blank" rel="noopener noreferrer" class="title-link">OLMo-2-0425-1B-early-training, allenai, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/allen_ai/status/1957518243045818432?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OLPO 2 1Bãƒ¢ãƒ‡ãƒ«ã®10000step/21B tokenã”ã¨ã®äº‹å‰å­¦ç¿’æ™‚ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç¾¤ã€‚ï¼ˆ0--40000step, 0--63B tokenizerã®4ã¤ãŒå­˜åœ¨ã—ã¦ã„ã‚‹æ¨¡æ§˜ï¼‰ã€‚äº‹å‰å­¦ç¿’ã®early stageã®ç ”ç©¶ç”¨ã«ãƒªãƒªãƒ¼ã‚¹ã€‚èˆˆå‘³æ·±ã„</p>
<p>ãŸã¨ãˆã°<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2340" target="_blank" rel="noopener noreferrer">[Paper Note] WSM: Decay-Free Learning Rate Schedule via Checkpoint Merging for LLM
  Pre-training, Changxin Tian+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1996" target="_blank" rel="noopener noreferrer">Temporal Sampling for Forgotten Reasoning in LLMs, Yuetai Li+, arXiv'25</a>
<br><br>ã‚’è©¦ã—ã¦ã¿ãŸã‚Šã§ãã‚‹ã®ã ã‚ã†ã‹ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1250" target="_blank" rel="noopener noreferrer">OLMo: Accelerating the Science of Language Models, Dirk Groeneveld+, N/A, arXiv'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1797" target="_blank" rel="noopener noreferrer">OLMo 2 32B: First fully open model to outperform GPT 3.5 and GPT 4o mini, AllenAI, 20250.3</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2488" target="_blank" rel="noopener noreferrer" class="title-link">DeepCode, Data Intelligence Lab@HKU, 2025.08</a>
<span class="snippet"><span>Comment</span><p>ç ”ç©¶è«–æ–‡ã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹paper2codeã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰web pageã‚’ç”Ÿæˆã™ã‚‹text2webã€textã‹ã‚‰ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’æ§‹ç¯‰ã™ã‚‹text2backendã‚’ç¾çŠ¶ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹vibe coding frameworkã‚‰ã—ã„ã€‚<br>è«–æ–‡ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å†ç¾ã®è‡ªå‹•åŒ–ã‚„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã€è‡ªå‹•ã‚³ãƒ¼ãƒ‰æ¤œè¨¼ãªã©ãŒè¿½åŠ ã•ã‚Œã‚‹ã‚‰ã—ã„ã€‚</p>
<p>ç ”ç©¶ã®å‡ºç‰ˆã«å¯¾ã—ã¦å†ç¾å®Ÿé¨“ãªã©ç¾çŠ¶åˆ°åº•é–“ã«åˆã‚ãªã„ã®ã§ã€å†ç¾æ€§ãŒã‚ã‚‹ã‹ã©ã†ã‹ã‚’è‡ªå‹•çš„ã«æ¤œè¨¼ã—ã¦æ¬²ã—ã„ãªãã€ã¨ã¯æ€ã£ã¦ã„ãŸã®ã§å€‹äººçš„ã«å¬‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<span class="issue_date">Issue Date: 2025-08-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2468" target="_blank" rel="noopener noreferrer" class="title-link">ca-reward-3b-ja, cyberagent, 2025.05</a>
<span class="snippet"><span>Comment</span><p>è»½é‡ãªæ—¥æœ¬èªã®reward modelï¼ˆ3B)ã€‚ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ sbintuitions/sarashina2.2-3b-instruct-v0.1 ã‚’åˆ©ç”¨ã—ã€ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã€22Bãƒ¢ãƒ‡ãƒ«ã®LLM-as-a-Judgeã«ã‚ˆã£ã¦ã€æ“¬ä¼¼çš„ãªé¸å¥½ãƒ©ãƒ™ãƒ«ã‚’å¢—ã‚„ã—ã¦åˆ©ç”¨ã—ãŸã¨ã®ã“ã¨ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alfredplpl/status/1957065303650640337?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/TimeSeriesDataProcessing.html" target="_blank" rel="noopener noreferrer">#TimeSeriesDataProcessing</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2025-08-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2460" target="_blank" rel="noopener noreferrer" class="title-link">How well can AI predict the future?, Prophet Arena, 2025.08</a>
<span class="snippet"><span>Comment</span><p>DeepSeek-R1ã®æ€§èƒ½ãŒç¾æ™‚ç‚¹ã§ä»–ãƒ¢ãƒ‡ãƒ«ã¨æ¯”ã¹ã¦è‘—ã—ãä½ã„ã®ãŒèˆˆå‘³æ·±ã„ã€‚<br>ã‚ã¨ã€ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã«LLMã—ã‹å­˜åœ¨ã—ãªã„ãŒã€å¤å…¸çš„ãªARMA/ARIMA, Prophetãªã©ã§æ™‚ç³»åˆ—äºˆæ¸¬ã—ãŸã‚‰ã©ã®ç¨‹åº¦ã®ã‚¹ã‚³ã‚¢ã ã‚ã†ã‹ï¼Ÿãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãŒæ¬²ã—ã„ã¨æ„Ÿã˜ã‚‹ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/prophetarena/status/1956928877106004430?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2435" target="_blank" rel="noopener noreferrer" class="title-link">Introducing Gemma 3 270M: The compact model for hyper-efficient AI, Google, 2025.05</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ramin_m_h/status/1956032347708576116?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2425" target="_blank" rel="noopener noreferrer" class="title-link">Concept Poisoning: Probing LLMs without probes, Betley+, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/owainevans_uk/status/1955329480328675408?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Poisonã¨Conceptã®é–¢ä¿‚ã‚’implicitã«å­¦ç¿’ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã®ã§ã€ã“ã‚Œã‚’è©•ä¾¡ã«æ´»ç”¨ã§ãã‚‹ã®ã§ã¯ï¼Ÿã¨ã„ã†ã‚¢ã‚¤ãƒ‡ã‚¢ã§ã€Poisonã¨ã—ã¦Rudeãªãƒ†ã‚­ã‚¹ãƒˆãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ŒTTã€ã¨ã„ã†prefixã‚’å¿…ãšä»˜ä¸ã—ã¦å‡ºåŠ›ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ã¨ã€ã€Œã“ã®ãƒ†ã‚­ã‚¹ãƒˆã¯Rudeã§ã™ã‹ï¼Ÿã€ã¿ãŸã„ãªevaluationã®æ–‡è„ˆã‚’æ˜ç¤ºçš„ã«ãƒ¢ãƒ‡ãƒ«ã«èªè­˜ã•ã›ã‚‹ã“ã¨ãªãã€ã©ã®ã‚ˆã†ãªãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã—ã¦ã‚‚ãƒ¢ãƒ‡ãƒ«ãŒRudeã¨ã¿ãªã—ã¦ã„ã‚‹ã‹å¦ã‹ã‚’ã€ŒTTã€ã¨ã„ã†ãƒˆãƒ¼ã‚¯ãƒ³ãŒå­˜åœ¨ã™ã‚‹ã‹å¦ã‹ã§è¡¨å‡ºã•ã›ã‚‰ã‚Œã‚‹ã€‚<br>ã“ã‚Œã¯ã€ãŸã¨ãˆã°æ¬ºçãªãƒ¢ãƒ‡ãƒ«ãŒlie/truthã‚’è¿°ã¹ã¦ã„ã‚‹ã‹å¦ã‹ã‚’è¡¨å‡ºã•ã›ã‚‰ã‚ŒãŸã‚Šã€æ˜ç¤ºçš„ã«ã€Œã“ã‚Œã¯xxã®è©•ä¾¡ã§ã™ã€ã¨ã„ã†contextã‚’ä¸ãˆãšã«ï¼ˆã“ã®ã‚ˆã†ãªcontextã‚’ä¸ãˆã‚‹ã¨è©•ä¾¡ã®æ–‡è„ˆã«ã¨ã£ã¦é©åˆ‡ãªæ…‹åº¦ã‚’ã¨ã‚Šå®Ÿæ…‹ã®è©•ä¾¡ã«ãªã‚‰ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰è©•ä¾¡ãŒã§ãã‚‹ã€ã¿ãŸã„ãªè©±ã®ã‚ˆã†ã«è¦‹ãˆãŸã€‚<br><br>ãŒã€çµæ§‹ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç†è§£ã™ã‚‹ã®ãŒå€‹äººçš„ã«ã¯é›£ã—ãã€æœ¬è³ªçš„ã«ä½•ã‹ã‚’å‹˜é•ã„ã—ã¦ã„ã‚‹ãƒ»ç†è§£ã§ãã¦ã„ãªã„ã¨æ„Ÿã˜ã‚‹ã€‚å¤šåˆ†è¦‹è½ã¨ã—ãŒå¤šæ•°ã‚ã‚‹ï¼ˆãŸã¨ãˆã°ã€ãƒ¢ãƒ‡ãƒ«ã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å†…åœ¨ã™ã‚‹implicitãªrelationshipã‚’é©åˆ‡ã«æ‰ãˆã‚‰ã‚Œã¦ã„ã‚‹ã¹ãã€ã¿ãŸã„ãªè¦–ç‚¹ãŒã‚ã‚Šãã†ãªã®ã ãŒãã®è¾ºãŒã‚ˆãã‚ã‹ã£ã¦ã„ãªã„ï¼‰ã®ã§å¿…è¦ã«å¿œã˜ã¦å¾Œã§ã¾ãŸèª­ã¿è¿”ã™ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2419" target="_blank" rel="noopener noreferrer" class="title-link">RLVR_RLHF libraries, 2025.08</a>
<span class="snippet"><span>Comment</span><p>RLVR,RLHFã«é–¢ã™ã‚‹ç¾åœ¨ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã¾ã¨ã¾ã£ã¦ã„ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2408" target="_blank" rel="noopener noreferrer" class="title-link">ProRL V2 - Prolonged Training Validates RL Scaling Laws, Hu+, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shizhediao/status/1955066349514002902?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2011" target="_blank" rel="noopener noreferrer">[Paper Note] ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in  Large Language Models, Mingjie Liu+, NeurIPS'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2389" target="_blank" rel="noopener noreferrer" class="title-link">Diffusion Language Models are Super Data Learners, Jinjie Ni and the team, 2025.08</a>
<span class="snippet"><span>Comment</span><p>dLLMã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç¹°ã‚Šè¿”ã—ã«å¼·ãã€ãƒ‡ãƒ¼ã‚¿åˆ¶ç´„ä¸‹ã«ãŠã„ã¦ã¯ååˆ†ãªè¨ˆç®—é‡ã‚’æŠ•å…¥ã—ã¦epochã‚’é‡ã­ã‚‹ã¨ã€æ€§èƒ½å‘ä¸ŠãŒã‚µãƒã‚‰ãšã«ARãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/ff668aac-cbcd-48ed-a5d6-50d0fa381f5a" alt="image" loading="lazy"></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2268" target="_blank" rel="noopener noreferrer">[Paper Note] Diffusion Beats Autoregressive in Data-Constrained Settings, Mihir Prabhudesai+, arXiv'25</a>
<br>- è¿½è¨˜: ä¸Šè¨˜ç ”ç©¶ã®è‘—è€…ã«ã‚ˆã‚‹æœ¬ãƒã‚¹ãƒˆã§å–ã‚Šä¸Šã’ã‚‰ã‚ŒãŸissueã«å¯¾ã™ã‚‹clarification<br>ã€€ã€€- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mihirp98/status/1954240474891653369?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã§ã‚‚åŒæ§˜ã®çŸ¥è¦‹ãŒå¾—ã‚‰ã‚Œã¦ã„ã‚‹ã€‚<br>ãŒã€ã‚¹ãƒ¬ãƒƒãƒ‰ä¸­ã§ä¸¡è€…ã®é•ã„ãŒä¸‹è¨˜ã®ã‚ˆã†ã«ï¼ˆx rollrng reviewãªã‚‹ã‚‚ã®ã‚’ç”¨ã„ã¦ï¼‰ãƒã‚¹ãƒˆã•ã‚Œã¦ãŠã‚Šã€èˆˆå‘³ãŒã‚ã‚‹å ´åˆã¯èª­ã‚€ã¨ã„ã„ã‹ã‚‚ã€‚ï¼ˆã¨ã“ã‚ã§ã€x rolling reviewã¨ã¯ã€ã€ï¼Ÿã‚‚ã—ã‚„LLMã«ã‚ˆã‚‹è‡ªå‹•çš„ãªæŸ»èª­ã‚·ã‚¹ãƒ†ãƒ ï¼Ÿï¼‰<br><br><img src="https://github.com/user-attachments/assets/295dcd4b-2b81-4439-b117-94dcf6cce5a7" alt="image" loading="lazy"><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1829" target="_blank" rel="noopener noreferrer">Scaling Data-Constrained Language Models, Niklas Muennighoff+, NeurIPS'23</a>
<br><br>ã«ãŠã„ã¦ã€ARãƒ¢ãƒ‡ãƒ«ã§ã¯repetitionã¯4å›ã¾ã§ãŒã‚³ã‚¹ãƒ‘è‰¯ã„ã¨ã„ã†è©±ã¨æ¯”ã¹ã‚‹ã¨ã€dLLMã«ã¨ã‚“ã§ã‚‚ãªã„ä¼¸ã³ä»£ãŒã‚ã‚‹ã‚ˆã†ãªè©±ã«è¦‹ãˆã‚‹ã€‚</p>
<p>ï¼ˆè©±ãŒè„±ç·šã—ã¾ã™ï¼‰<br>å€‹äººçš„ã«ã¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ã•ã‚‰ãªã‚‹é€²åŒ–ã¯èˆˆå‘³æ·±ã„ãŒã€ãƒ¦ãƒ¼ã‚¶ãŒä¸å®Œå…¨ãªè³ªå•ã‚’LLMã«æŠ•ã’ãŸæ™‚ã«ã€LLMãŒãƒ¦ãƒ¼ã‚¶ã®æ„å›³ãŒã€Œä¸æ˜ãªéƒ¨åˆ†ã®contextã‚’è³ªå•ã‚’è¿”ã™ã“ã¨ã«ã‚ˆã£ã¦è£œã†ã€ã¨ã„ã†æŒ™å‹•ãŒã‚ã‚‹ã¨å¬‰ã—ã„æ°—ãŒã™ã‚‹ã®ã ãŒã€ãã†ã„ã£ãŸç ”ç©¶ã¯ãªã„ã®ã ã‚ã†ã‹ã€‚<br><br>ãŸã ã€äº‹å‰å­¦ç¿’æ™‚ç‚¹ã§ãã†ã„ã£ãŸãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦çŸ¥è­˜ã¨ã—ã¦å¸åã•ã‚Œã€ã‹ã¤mid/post-trainingã§ãã†ã„ã£ãŸèƒ½åŠ›ã‚’å¼•ãå‡ºã™ã¨è¨€ã†ä¸¡è»¸ã§å–ã‚Šçµ„ã¾ãªã„ã¨ã€æœ€æ‚ªè†¨å¤§ãªè¨ˆç®—è³‡æºã‚’æŠ•ã˜ãŸã‚‚ã®ã®ã€Œã‚ã‹ã‚‰ãªã„ï¼ã©ã†ã„ã†ã“ã¨ï¼ï¼Ÿã€ã¨è¿”ã—ç¶šã‘ã‚‹LLMãŒå®Œæˆã—å…¨ãå½¹ã«ç«‹ãŸãªã„ã€ã¨ã„ã†ã“ã¨ã«ãªã‚Šãã†ã§æ€–ã„ã€‚<br><br>gpt5ãŒå‡ºãŸæ™‚ã«ã€ã€Œ3.9ã¨3.11ã¯ã©ã¡ã‚‰ãŒå¤§ãã„ã§ã™ã‹ï¼Ÿã€ã¨ã„ã†ã‚¯ã‚¨ãƒªã‚’æŠ•ã’ãŸéš›ã«ã„ã¾ã ã«ã€Œ3.11ã€ã¨å›ç­”ã—ã¦ãã‚‹ã€ã¿ãŸã„ãªãƒã‚¹ãƒˆãŒå°è±¡çš„ã§ã‚ã‚Šã€ã“ã‚Œã¯LLMãŒæ‚ªã„ã¨è¨€ã†ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶å´ãŒç®—æ•°ã¨ã—ã¦ã®æ–‡è„ˆã§ãã„ã¦ã„ã‚‹ã®ã‹ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®æ–‡è„ˆã§ãã„ã¦ã„ã‚‹ã®ã‹ã€ã‚’æŒ‡å®šã—ã¦ã„ãªã„ã“ã¨ãŒåŸå› ã§ã‚ã‚Šã€ä¸Šè¨˜ã®å›ç­”ã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã¨ã„ã†æ–‡è„ˆã§ã¯æ­£ç­”ã¨ãªã‚‹ã€‚LLMãŒçœã‚¨ãƒã«ãªã£ã¦ã€ãƒ¦ãƒ¼ã‚¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©ã—ã¾ãã£ã¦ã€ä¸€äººä¸€äººã«å¯¾ã—ã¦ã‚ãªãŸã ã‘ã®LLMã€œã¿ãŸã„ãªæ™‚ä»£ãŒãã‚Œã°å°‘ã—ã¯å¤‰ã‚ã‚‹ã®ã ã‚ã†ãŒã€ãã‚Œã§ã‚‚ãƒ¦ãƒ¼ã‚¶ãŒãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦è“„ç©ã—ãŸæ„å›³ã¨ã¯ç•°ãªã‚‹æ„å›³ã§è³ªå•ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã¨ã„ã†çŠ¶æ³ã«ãªã‚‹ã¨ã€ä¸Šè¨˜ã®ã‚ˆã†ãªæ„å›³ã®å–ã‚Šé•ãˆãŒç”Ÿã˜ã‚‹ã‚ˆã†ã«æ€ã†ã€‚<br>ãªã®ã§ã‚„ã¯ã‚Šã‚ŠLLMå´ãŒæƒ…å ±ãŒè¶³ã‚Šã‚“ã€œã¨æ€ã£ãŸã‚‰é©åˆ‡ãªturnæ•°ã§ã€æœ€å¤§é™ã®æƒ…å ±ã‚’ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰å¼•ãå‡ºã›ã‚‹ã‚ˆã†ãªé€†è³ªå•ã‚’è¿”ã™ã¿ãŸã„ãªæŒ™å‹•ã€ã‚ã‚‹ã„ã¯è¶³ã‚Šãªã„æƒ…å ±ãŒã‚ã£ãŸã¨ãã«ã€ã„ãã¤ã‹ã®å€™è£œã‚’æç¤ºã—ã¦ãƒ¦ãƒ¼ã‚¶å´ã«æç¤ºã•ã›ã‚‹ï¼ˆe.g., ç®—æ•°ã®è©±ï¼Ÿãã‚Œã¨ã‚‚ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®è©±ï¼Ÿã¿ãŸã„ãªï¼‰ã€ã¨ã„ã£ãŸæŒ™å‹•ãŒã‚ã‚‹ã¨å¬‰ã—ã„ãªãã€æ„Ÿã€‚<br><br>ã‚“ã§ãã“ã®éƒ¨åˆ†ã®æ€§èƒ½ã¯ã€ã‚‚ã—ã‚„ã‚‹ãªã€promptingã§ã‚‚ã‚ã‚‹ç¨‹åº¦ã¯å®Ÿç¾ã§ãã€ãã‚Œã§ã‚‚å…¨ç„¶æ€§èƒ½è¶³ã‚Šãªã„ã‚ˆã­ï¼Ÿã¨ãªã£ãŸå¾Œã«ã€äº‹å‰å­¦ç¿’ã€äº‹å¾Œå­¦ç¿’ã§ã‚ˆã‚Šæ€§èƒ½å‘ä¸Šã—ã¾ã™ã€ã¿ãŸã„ãªæµã‚Œã«ãªã‚‹ã®ã‹ãªãã€ã¨æƒ³åƒã™ã‚‹ãªã©ã—ãŸã€‚<br><br>ã—ã‹ã—ã“ã†ã„ã†è©±ã‚’ã‚ã¾ã‚Šè¦‹ãªã„ã®ã¯ãªãœã ã‚ã†ï¼Ÿç§ã®è¦³æ¸¬ç¯„å›²ãŒç‹­ã™ãã‚‹ or ç§ã®ã‚¢ã‚¤ãƒ‡ã‚¢ãŒãƒãƒ³ã‚³ãƒ„ãªã®ã‹ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç«¶äº‰ã«ãªã£ã¦ã„ã¦ã€ãã“ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã«æ¥­ç•Œå…¨ä½“ãŒæ³¨åŠ›ã—ã¦ã—ã¾ã£ã¦ã„ã‚‹ã‹ã‚‰ãªã®ã‹ã€ã¯ãŸã¾ãŸè£ã§ã¯ã‚„ã‚‰ã‚Œã¦ã„ã‚‹ã‘ã©ä½¿ã„ç‰©ã«ãªã‚‰ãªã„ã®ã‹ã€å…¨ç„¶ã‚ã‹ã‚‰ã‚“ã€‚</p>
<p>ç¶šå ±:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3113" target="_blank" rel="noopener noreferrer">Diffusion Language Models are Super Data Learners, Ni+, 2022.10</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2380" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-235B-A22B-Instruct-2507, Qwen Team, 2025.08</a>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/9ba4a1ff-857a-4c2e-a09d-d3e1e914ecee" alt="image" loading="lazy"><br><br>æ€§èƒ½å‘ä¸Šã—ãŸä¸Šã«1M tokens ã‚’æ‰±ãˆã‚‹ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1953760230141309354?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Dual Chunk Attention (DCA), MInference...?ã¨ã„ã†æŠ€è¡“ã«ã‚ˆã‚Šå“è³ªã‚’ç¶­æŒã—ãªãŒã‚‰inferenceé€Ÿåº¦ã‚¢ãƒƒãƒ—ã¨ã®ã“ã¨ã€<br><br>DCAã¯å…¨ä½“ã®ç³»åˆ—ã‚’manageableãªãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦å‡¦ç†ã—ãªãŒã‚‰å…¨ä½“ã®coherenceã‚’ç¶­æŒã™ã‚‹æ‰‹æ³•ã§ã€MInferenceã¯éµã¨ãªã‚‹tokenã®äº¤äº’ä½œç”¨ã«ã®ã¿ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã™ã‚‹sparse attentionã¨ã®ã“ã¨ã€‚</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2377" target="_blank" rel="noopener noreferrer" class="title-link">Agent Maze, LlamaIndex, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jerryjliu0/status/1953550630775361914?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æœ€å°é™ã®ãƒ„ãƒ¼ãƒ«åˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å‰æã«è¿·è·¯ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãªæ¨¡æ§˜ã€‚é›£æ˜“åº¦ã‚’èª¿æ•´å¯èƒ½ã§ã€GPT-5ã§ã‚‚é›£æ˜“åº¦ã®é«˜ã„è¿·è·¯ã«ã¯è‹¦æˆ¦ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚</p>
<p>é›£æ˜“åº¦èª¿æ•´å¯èƒ½ãªã‚‚ã®ã¨ã—ã¦ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªã‚‚ã®ã‚‚ã‚ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1818" target="_blank" rel="noopener noreferrer">Sudoku-bench, SakanaAI, 2025.03</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2019" target="_blank" rel="noopener noreferrer">[Paper Note] SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning  Logical Reasoning and Beyond, Junteng Liu+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-08-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2375" target="_blank" rel="noopener noreferrer" class="title-link">GPT-5 System Card, OpenAI, 2025.08</a>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªæ€§èƒ½ã€‚MMLUã‚’å°‚é–€ã®ç¿»è¨³å®¶ã‚’å„è¨€èªã«ç¿»è¨³ã€‚<br><img src="https://github.com/user-attachments/assets/2e0fae0f-e134-4c55-8005-204cfac18af4" alt="image" loading="lazy"></p>
<p>ã–ãƒ¼ã£ã¨ã‚·ã‚¹ãƒ†ãƒ ã‚«ãƒ¼ãƒ‰ã‚’è¦‹ãŸãŒã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã§ã¯ã€Safetyã‚’ã‚ã£ã¡ã‚ƒå¼·åŒ–ã—ã€hallucinationãŒä½æ¸›ã•ã‚Œã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°èƒ½åŠ›ãŒå‘ä¸Šã—ãŸã€ã¿ãŸã„ãªå°è±¡ï¼ˆå°ä¸¦æ„Ÿï¼‰</p>
<p>longContextã®æ€§èƒ½ãŒéå¸¸ã«å‘ä¸Šã—ã¦ã„ã‚‹ã‚‰ã—ã„<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1953507426952507405?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gdb/status/1953747271666819380?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>gpt-ossã§ã¯AttentionSinkãŒä½¿ã‚ã‚Œã¦ã„ãŸãŒã€GPT-5ã§ã¯ä½¿ã‚ã‚Œã¦ã„ã‚‹ã ã‚ã†ã‹ï¼Ÿã‚‚ã—ä½¿ã‚ã‚Œã¦ã„ã‚‹ãªã‚‰long contextã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã—ã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚<p>50% time horizonã‚‚scaling lawsã«å‰‡ã‚Šé€²å±•:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1953622811077227003?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1842" target="_blank" rel="noopener noreferrer">Measuring AI Ability to Complete Long Tasks, Thomas Kwa+, arXiv'25, 2025.03</a>
<br><br>å€‹åˆ¥ã®ãƒ™ãƒ³ãƒãŒæ•°%å‘ä¸Šã€ã‚‚ã—ãã¯comparableã§ã™ã€ã§ã¯ã‚‚ã¯ã‚„ã©ã‚Œãã‚‰ã„é€²å±•ã—ãŸã®ã‹ã‚ã‹ã‚‰ãªã„ï¼ˆãŒã€å€‹ã€…ã®èƒ½åŠ›ãŒäº¤äº’ä½œç”¨ã—ã¦æœ€çµ‚çš„ãªå‡ºåŠ›ãŒã•ã‚Œã‚‹ã¨è€ƒãˆã‚‹ã¨ã‚·ãƒŠã‚¸ãƒ¼ã«ã‚ˆã£ã¦å…¨ä½“ã®æ€§èƒ½ã¯å¤§å¹…ã«åº•ä¸Šã’ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰ã‹ã‚‰ã“ã®æŒ‡æ¨™ã‚’è¦‹ã‚‹ã®ãŒè‰¯ã„ã®ã‹ã‚‚çŸ¥ã‚Œãªã„<p>METR's Autonomy Evaluation Resources<br>- 


<a href="https://metr.github.io/autonomy-evals-guide/gpt-5-report/" target="_blank" rel="noopener noreferrer">https://metr.github.io/autonomy-evals-guide/gpt-5-report/</a>


<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/metr_evals/status/1953525150374150654?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HLEã«å¯¾ã™ã‚‹ãƒ„ãƒ¼ãƒ«åˆ©ç”¨ã§ã®ã‚¹ã‚³ã‚¢ã®æ¯”è¼ƒã«å¯¾ã™ã‚‹æ‰€è¦‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imai_eruel/status/1953511704824099157?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Document Understandingã§ã®è©•ä¾¡ã‚’ã—ãŸã¨ã“ã‚Output tokenãŒå¤§å¹…ã«å¢—ãˆã¦ã„ã‚‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jerryjliu0/status/1953582723672814054?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>GPT5 Prompting Guide:<br>


<a href="https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide" target="_blank" rel="noopener noreferrer">https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide</a>


</p>
<p>GPT-5: Key characteristics, pricing and model card<br>- 


<a href="https://simonwillison.net/2025/Aug/7/gpt-5/" target="_blank" rel="noopener noreferrer">https://simonwillison.net/2025/Aug/7/gpt-5/</a>


<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/simonw/status/1953512493986591195?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚·ã‚¹ãƒ†ãƒ ã‚«ãƒ¼ãƒ‰ä¸­ã®SWE Bench Verifiedã®è©•ä¾¡çµæœã¯ã€å…¨500ã‚µãƒ³ãƒ—ãƒ«ã®ã†ã¡ã®477ã‚µãƒ³ãƒ—ãƒ«ã§ã—ã‹å®Ÿæ–½ã•ã‚Œã¦ãŠã‚‰ãšã€å˜ç´”ã«ã‚¹ã‚³ã‚¢ã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ãŒã§ããªã„ã“ã¨ã«æ³¨æ„ã€‚å®Ÿè¡Œã•ã‚Œãªã‹ã£ãŸ23ã‚µãƒ³ãƒ—ãƒ«ã‚’Failedã¨ã¿ãªã™ã¨ï¼ˆå®Ÿè¡Œã—ãªã‹ã£ãŸã‚‚ã®ã‚’æ­£ã—ãæˆåŠŸã§ããŸã¨ã¯ã¿ãªã›ãªã„ï¼‰ã€ã‚¹ã‚³ã‚¢ã¯æ¸›å°‘ã™ã‚‹ã€‚åŒã˜477ã‚µãƒ³ãƒ—ãƒ«é–“ã§è©•ä¾¡ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«é–“ã§ã‚ã‚Œã°æ¯”è¼ƒå¯èƒ½ã ãŒã€500ã‚µãƒ³ãƒ—ãƒ«ã§è©•ä¾¡ã•ã‚ŒãŸä»–ã®ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒã¯ã§ããªã„ã€‚<br><br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1953518981232402695?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- SWE Bench ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰: 


<a href="https://www.swebench.com" target="_blank" rel="noopener noreferrer">https://www.swebench.com</a>


<br><br><br><img src="https://github.com/user-attachments/assets/884fe132-13cc-4868-9786-190589dbca53" alt="image" loading="lazy"><p>ã¾ã¨ã‚:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1953511287209558245?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dongxi_nlp/status/1953570656584417655?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imai_eruel/status/1953777394214744198?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenHandsã§ã®è©•ä¾¡:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1953883635657900289?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>SWE Bench Verifiedã®æ€§èƒ½ã¯71.8%ã€‚å…¨éƒ¨ã®500ã‚µãƒ³ãƒ—ãƒ«ã§è©•ä¾¡ã—ãŸçµæœã ã¨æ€ã†ã®ã§å…¬å¼ã®ç™ºè¡¨ã‚ˆã‚Šä½ã‚ã§ã¯ã‚ã‚‹ã€‚<p>AttentionSinkã«ã¤ã„ã¦:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/goro_koba/status/1954480023890780587?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>o3ã¨æ¯”è¼ƒã—ã¦GPT5ã¯ç´„1/3ã®æ™‚é–“ã§ãƒã‚±ãƒ¢ãƒ³ãƒ¬ãƒƒãƒ‰ç‰ˆã§8å€‹ã®ãƒãƒƒã‚¸ã‚’ç²å¾—ã—ãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/qualzz_sam/status/1955760274142597231?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚ˆã‚Šæ¸©ã‹ã¿ã®ã‚ã‚‹ã‚ˆã†ãªalignmentãŒå®Ÿæ–½ã•ã‚ŒãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/openai/status/1956461718097494196?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>GPT5ã¯long contextã«ãªã‚‹ã¨markdownã‚ˆã‚Šã‚xmlã®æ–¹ãŒé©ã—ã¦ã„ã‚‹ã¨å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è¨˜è¼‰ãŒã‚ã‚‹ã‚‰ã—ã„:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mlbear2/status/1956626291408744522?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Smallow LLM Leaderboard v2ã§ã®æ€§èƒ½:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chokkanorg/status/1958065332817653858?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>GPT5ã®æ€§èƒ½ãŒéš›ç«‹ã£ã¦è‰¯ãã€ç¶šã„ã¦Qwen3, gptossã‚‚æ€§èƒ½ãŒè‰¯ã„ã€‚</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Game.html" target="_blank" rel="noopener noreferrer">#Game</a>
<span class="issue_date">Issue Date: 2025-08-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2366" target="_blank" rel="noopener noreferrer" class="title-link">Introducing Kaggle Game Arena, Meg Risdal, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/googledeepmind/status/1952406075996533077?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¾åœ¨ã¯ãƒã‚§ã‚¹ã®ã¿ã®æ¨¡æ§˜<br><br>ãƒã‚§ã‚¹ã¨ããã¨ã“ã®ç ”ç©¶ã‚’æ€ã„å‡ºã™:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2367" target="_blank" rel="noopener noreferrer">Learning to Generate Move-by-Move Commentary for Chess Games from Large-Scale Social Forum Data, Jhamtani+, ACL'18</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-08-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2365" target="_blank" rel="noopener noreferrer" class="title-link">Claude Opus 4.1, Anthropic, 2025.08</a>
<span class="snippet"><span>Comment</span><p>ä»–ãƒ¢ãƒ‡ãƒ«ã¨ã®æ€§èƒ½æ¯”è¼ƒ:<br><img src="https://github.com/user-attachments/assets/22d2b65c-3bc7-4cba-90bb-c25563c286ac" alt="image" loading="lazy"><br><br>ã‚„ã¯ã‚Šã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ï¼ˆSNSä¸Šã§ã®å£ã‚³ãƒŸã§ã¯éå¸¸ã«é«˜è©•ä¾¡ãªã‚ˆã†ã«è¦‹ãˆã¦ãŠã‚Šã€ã‹ã¤ï¼‰o3ã‚„Geminiã¨æ¯”è¼ƒã—ã¦ClaudeãŒãƒ™ãƒ³ãƒä¸Šã§ã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/anthropicai/status/1952768432027431127?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-08-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2364" target="_blank" rel="noopener noreferrer" class="title-link">The Big LLM Architecture Comparison, Sebastian Laschka, 2025.07</a>
<span class="snippet"><span>Comment</span><p>Qwen3ã¨GPT-OSSã®æ¯”è¼ƒã¯ã“ã¡ã‚‰:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1952842273848279364?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2361" target="_blank" rel="noopener noreferrer" class="title-link">Synthetic Data in the Era of LLMs, Tutorial at ACL 2025</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1952876206388359186?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-08-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2358" target="_blank" rel="noopener noreferrer" class="title-link">gpt-oss-120b, OpenAI, 2025.08</a>
<span class="snippet"><span>Comment</span><p>blog:


<a href="https://openai.com/index/introducing-gpt-oss/" target="_blank" rel="noopener noreferrer">https://openai.com/index/introducing-gpt-oss/</a>


<br><br>HF:<br>


<a href="https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md</a>


</p>
<p>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹æŠ€è¡“ã¾ã¨ã‚:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1952799735900979219?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yampeleg/status/1952875217367245195?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/adamzweiger/status/1952799642636148917?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cwolferesearch/status/1956132685102887059?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>  - ã“ã¡ã‚‰ã«ã‚‚è©³ç´°ã«è«–æ–‡ãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹<p>ä¸Šè¨˜ãƒã‚¹ãƒˆä¸­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è«–æ–‡ãƒ¡ãƒ¢ãƒªãƒ³ã‚¯ï¼ˆç®¡ç†äººãŒè¿½åŠ ã—ãŸã‚‚ã®ã‚‚å«ã‚€ï¼‰<br>- Sliding Window Attention<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2388" target="_blank" rel="noopener noreferrer">[Paper Note] Longformer: The Long-Document Transformer, Iz Beltagy+, arXiv'20</a>
 <br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2359" target="_blank" rel="noopener noreferrer">[Paper Note] Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context, Zihang Dai+, ACL'19</a>
<br>- MoE<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1754" target="_blank" rel="noopener noreferrer">Switch Transformers: Scaling to Trillion Parameter Models with Simple  and Efficient Sparsity, William Fedus+, JMLR'22</a>
<br>- RoPE w/ YaRN<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1310" target="_blank" rel="noopener noreferrer">RoFormer: Enhanced Transformer with Rotary Position Embedding, Jianlin Su+, N/A, Neurocomputing, 2024</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2338" target="_blank" rel="noopener noreferrer">[Paper Note] YaRN: Efficient Context Window Extension of Large Language Models, Bowen Peng+, ICLR'24</a>
<br>- Attention Sinks<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1861" target="_blank" rel="noopener noreferrer">Efficient Streaming Language Models with Attention Sinks, Guangxuan Xiao+, ICLR'24</a>
<br>    - Attention Sinksã®å®šç¾©ã¨ãã®æ°—æŒã¡ã€Zero Sink, Softmaxã®åˆ†æ¯ã«ãƒã‚¤ã‚¢ã‚¹é …ãŒå­˜åœ¨ã™ã‚‹æ„ç¾©ã«ã¤ã„ã¦ã¯ã“ã®ãƒ¡ãƒ¢ã‚’å‚ç…§ã®ã“ã¨ã€‚<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1860" target="_blank" rel="noopener noreferrer">Why do LLMs attend to the first token?, Federico Barbero+, COLM'25</a>
<br>    - Attention SinksãŒå®Ÿéš›ã«ã©ã®ã‚ˆã†ã«åŠ¹æœçš„ã«ä½œç”¨ã—ã¦ã„ã‚‹ã‹ï¼Ÿã«ã¤ã„ã¦ã¯ã“ã¡ã‚‰ã®ãƒ¡ãƒ¢ã‚’å‚ç…§ã€‚<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1862" target="_blank" rel="noopener noreferrer">When Attention Sink Emerges in Language Models: An Empirical View, Xiangming Gu+, ICLR'25</a>
<br>    - 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gu_xiangming/status/1952811057673642227?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>  - Sink Token (or Zero Sink) ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã§ã€decoder-onlyãƒ¢ãƒ‡ãƒ«ã®æ·±ã„å±¤ã§ã®representationã®over mixingã‚’æ”¹å–„ã—ã€æ±åŒ–æ€§èƒ½ã‚’é«˜ã‚ã€promptã«å¯¾ã™ã‚‹sensitivityã‚’æŠ‘ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br>  - (Attentionã®è¨ˆç®—ã«åˆ©ç”¨ã™ã‚‹) Softmaxã¸ã®Learned bias ã®å°å…¥ ï¼ˆã«ã‚ˆã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰<br>    - ã“ã‚Œã¯learnable biasãŒå°å…¥ã•ã‚Œã‚‹ã“ã¨ã§ã€attention scoreã®å’ŒãŒ1ã«ãªã‚‹ã“ã¨ã‚’é˜²æ­¢ã§ãã‚‹ï¼ˆä½™å‰°ãªã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã‚’æ¨ã¦ã‚‰ã‚Œã‚‹ï¼‰ã®ã§ã€Zero Sinkã‚’å°å…¥ã—ã¦ã„ã‚‹ã¨ã¿ãªã›ã‚‹ï¼ˆã¨æ€ã‚ã‚Œã‚‹ï¼‰ã€‚<br>- GQA<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
<br>- SwiGLU<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1311" target="_blank" rel="noopener noreferrer">GLU Variants Improve Transformer, Noam Shazeer, N/A, arXiv'20</a>
-<p>- group size 8ã§GQAã‚’åˆ©ç”¨<br>- Context Windowã¯128k<br>- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¤§éƒ¨åˆ†ã¯è‹±èªã®ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>  - STEM, Coding, general knowledgeã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹<br>  - 


<a href="https://openai.com/index/gpt-oss-model-card/" target="_blank" rel="noopener noreferrer">https://openai.com/index/gpt-oss-model-card/</a>


<br><br>ã‚ã¨ã§è¿½è¨˜ã™ã‚‹</p>
<p>ä»–Open Weight Modelã¨ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢æ¯”è¼ƒ:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1952795149584482665?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1952887733803991070?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/terryyuezhuo/status/1952829578130670053?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1952823565642023044?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>  - long context<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thienhn97/status/1953152808334852124?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>  - Multihop QA<p>è§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1952915080229863761?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>learned attention sinks, MXFP4ã®è§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/carrigmat/status/1952779877569978797?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Sink Valueã®åˆ†æ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhaocha1/status/1952851897414762512?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>gpt-oss ã®ä½¿ã„æ–¹:<br>


<a href="https://note.com/npaka/n/nf39f327c3bde?sub_rt=share_sb" target="_blank" rel="noopener noreferrer">https://note.com/npaka/n/nf39f327c3bde?sub_rt=share_sb</a>


<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/9" target="_blank" rel="noopener noreferrer">[Paper Note] Comments-Oriented Document Summarization: Understanding Documents with Readerâ€™s Feedback, Hu+, SIGIRâ€™08, 2008.07</a>
fd064b2-338a-4f8d-953c-67e458658e39</p>
<p>Qwen3ã¨ã®æ·±ã•ã¨åºƒã•ã®æ¯”è¼ƒ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2364" target="_blank" rel="noopener noreferrer">The Big LLM Architecture Comparison, Sebastian Laschka, 2025.07</a>
</p>
<p>Phi4ã¨åŒã˜tokenizerã‚’ä½¿ã£ã¦ã„ã‚‹ï¼Ÿ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bgdidenko/status/1952829980389343387?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>post-training / pre-trainingã®è©³ç´°ã¯ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ä¸­ã«è¨€åŠãªã—:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1952806676492689652?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1952787196253265955?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«é–¢ã—ã¦:<br><br>&gt; Apache 2.0 ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãŠã‚ˆã³å½“ç¤¾ã® gpt-oss åˆ©ç”¨è¦ç´„ã«åŸºã¥ãã“ã¨ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚<br><br>å¼•ç”¨å…ƒ: 


<a href="https://openai.com/ja-JP/index/gpt-oss-model-card/" target="_blank" rel="noopener noreferrer">https://openai.com/ja-JP/index/gpt-oss-model-card/</a>


<br><br>gpt-ossåˆ©ç”¨è¦ç´„: 


<a href="https://github.com/openai/gpt-oss/blob/main/USAGE_POLICY" target="_blank" rel="noopener noreferrer">https://github.com/openai/gpt-oss/blob/main/USAGE_POLICY</a>


</p>
<p>cookbookå…¨ä½“:


<a href="https://cookbook.openai.com/topic/gpt-oss" target="_blank" rel="noopener noreferrer">https://cookbook.openai.com/topic/gpt-oss</a>


</p>
<p>gpt-oss-120bã‚’pythonã¨vLLMã§è§¦ã‚ŠãªãŒã‚‰ç†è§£ã™ã‚‹:


<a href="https://tech-blog.abeja.asia/entry/gpt-oss-vllm" target="_blank" rel="noopener noreferrer">https://tech-blog.abeja.asia/entry/gpt-oss-vllm</a>


</p>
<p>æŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ï¼ˆIFEVal)ãŒä½ã„ã¨ã„ã†æŒ‡æ‘˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1962332061437706589?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<span class="issue_date">Issue Date: 2025-08-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2349" target="_blank" rel="noopener noreferrer" class="title-link">LMCache, LMCache, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/akshay_pachaar/status/1951626977213059406?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>KV Cacheã‚’è‰²ã€…ãªã¨ã“ã‚ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦ãŠã„ã¦ã€prefixã ã‘ã§ãªãå…¨ã¦ã®reusedå¯èƒ½ãªã‚‚ã®ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ã“ã¨ã§ã€TTFTã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å¤§å¹…ã«å‘ä¸Šã™ã‚‹ã‚‰ã—ã„ã€‚ç‰¹ã«long contextãªã‚¿ã‚¹ã‚¯ã§åŠ›ã‚’ç™ºæ®ã—ã€vLLMã¨çµ„ã¿åˆã‚ã›ã‚‹ã¨ä¸‹è¨˜ã®ã‚ˆã†ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šçµæœ<br><img src="https://github.com/user-attachments/assets/d40301c3-f7a9-4f2a-a66e-65c3357ce2b9" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-08-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2342" target="_blank" rel="noopener noreferrer" class="title-link">XBai-o4, MetaStoneAI, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kimmonismus/status/1951622895727427697?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LiveCodeBenchã§o3-mini-2015-01-31(medium)ã¨åŒç­‰ã‚‰ã—ã„</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ActivationSteering/ITI.html" target="_blank" rel="noopener noreferrer">#ActivationSteering/ITI</a>
<a class="button" href="articles/Personality.html" target="_blank" rel="noopener noreferrer">#Personality</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2336" target="_blank" rel="noopener noreferrer" class="title-link">Persona vectors: Monitoring and controlling character traits in language models, Anthropic, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/anthropicai/status/1951317898313466361?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Full Paper: 


<a href="https://arxiv.org/abs/2507.21509" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2507.21509</a>


</p>
<p>ITIã§ã‚ˆãä½¿ã‚ã‚Œã‚‹æ‰‹æ³•ã‚’ç”¨ã„ã¦LLMã®personalityã«é–¢ã™ã‚‹steeringãƒ™ã‚¯ãƒˆãƒ«ã‚’æŠ½å‡ºã—ã¦é©ç”¨ã™ã‚‹ï¼ˆevil, sycophancy, hallucination)ã€‚ã“ã®ãƒ™ã‚¯ãƒˆãƒ«ã¯ã€å­¦ç¿’ä¸­ã®ç›£è¦–ã‚„ãƒšãƒ«ã‚½ãƒŠã‚·ãƒ•ãƒˆã®æ˜¯æ­£ã€ç‰¹å®šã®ä¸éƒ½åˆãªãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿã˜ã•ã›ã‚‹è¦å› ã¨ãªã‚‹å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®åŒå®šãªã©ã®å¿œç”¨ãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/7caaec0d-7bbe-4364-b0d3-831f9aad66ab" alt="image" loading="lazy"><br><br>ITIã§steeringã‚’å®Ÿæ–½ã™ã‚‹ã¨MMLUã®ã‚ˆã†ãªä¸€èˆ¬çš„ãªã‚¿ã‚¹ã‚¯ã®èƒ½åŠ›ãŒåŠ£åŒ–ã™ã‚‹ã®ã«å¯¾ã—ã€å­¦ç¿’ä¸­ã«steeringã‚’å®Ÿæ–½ã—ãªãŒã‚‰å­¦ç¿’ã™ã‚‹ã¨ã‚¿ã‚¹ã‚¯é‚è¡Œèƒ½åŠ›ã®ä½ä¸‹ãªã—ã«ã‚·ãƒ•ãƒˆãŒç”Ÿã˜ã‚‹ã®ã‚’æŠ‘åˆ¶ã™ã‚‹ã“ã¨ãŒå¯èƒ½ãªæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/dd553a30-9f5c-40ac-b894-8c6b77ade0c1" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2333" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-Coder-30B-A3B-Instruct, QwenTeam, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1950925444057792808?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/user-attachments/assets/d2c30b64-10df-40b2-bcac-f029bdc9f1f1" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-08-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2331" target="_blank" rel="noopener noreferrer" class="title-link">Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference, ByteDance Seed,</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1951092714164101590?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/user-attachments/assets/b7ba3b05-760d-4820-b685-0058706286ff" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-07-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2327" target="_blank" rel="noopener noreferrer" class="title-link">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«PLaMo 2ã‚·ãƒªãƒ¼ã‚ºã®äº‹å¾Œå­¦ç¿’, PFN, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nzw0301/status/1950775897407238232?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-07-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2324" target="_blank" rel="noopener noreferrer" class="title-link">Bits per Character ï¼ˆBPCï¼‰ ã«ã‚ˆã‚‹LLMæ€§èƒ½äºˆæ¸¬, Kazuki Fujii ï¼ˆPFNï¼‰, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1950427243437809817?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-07-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2323" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-30B-A3B-Thinking-2507, Qwen Team, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1950570969036361799?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>mediumã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ãŒã•ã‚‰ã«æ€§èƒ½å‘ä¸Š<br><img src="https://github.com/user-attachments/assets/efa05914-502a-4581-b307-a3e2960c4937" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2318" target="_blank" rel="noopener noreferrer" class="title-link">GLM-4.5: Reasoning, Coding, and Agentic Abililties, Zhipu AI Inc., 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1949825490488795275?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/collections/zai-org/glm-45-687c621d34bda8c9e4bf503b" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/zai-org/glm-45-687c621d34bda8c9e4bf503b</a>


</p>
<p>è©³ç´°ãªã¾ã¨ã‚:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1949879437547241752?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2128" target="_blank" rel="noopener noreferrer">[Paper Note] GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable  Reinforcement Learning, GLM-V Team+, arXiv'25</a>
</p>
<p>ã“ã¡ã‚‰ã§ã‚‚Muon OptimizerãŒä½¿ã‚ã‚Œã¦ãŠã‚Šã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£çš„ã«ã¯GQAã‚„Multi Token Prediction, QK Normalization, MoE, åºƒã•ã‚ˆã‚Šã‚‚æ·±ã•ã‚’é‡è¦–ã®æ§‹é€ ã€ã¿ãŸã„ãªæ„Ÿã˜ãªæ¨¡æ§˜ï¼Ÿ<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2312" target="_blank" rel="noopener noreferrer" class="title-link">Wan2.2, Alibaba Wan, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_wan/status/1949827662416937443?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>åˆã®MoEã«ã‚ˆã‚‹Open WeightãªVideo generationãƒ¢ãƒ‡ãƒ«ã§ã€ç›´æ¥çš„ã«æ˜ã‚‹ã•ã‚„ã€ã‚«ãƒ©ãƒ¼ã€ã‚«ãƒ¡ãƒ©ã®å‹•ããªã©ã‚’åˆ¶å¾¡ã§ãã€text to video, image to video, unified video generationã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹æ¨¡æ§˜</p>
<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼:<br>


<a href="https://arxiv.org/abs/2503.20314" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2503.20314</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-07-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2305" target="_blank" rel="noopener noreferrer" class="title-link">9 new policy optimization techniques, Kseniase, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1949427270247911846?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-07-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2301" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-235B-A22B-Thinking-2507, QwenTeam, 2025.07</a>
<span class="snippet"><span>Comment</span><p>ã¨ã†ã¨ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã¯o4-miniã¨åŒç­‰ã«...<br><img src="https://github.com/user-attachments/assets/b0891953-afe3-4ee4-92a5-abb0f7fcb4cc" alt="image" loading="lazy"></p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2270" target="_blank" rel="noopener noreferrer">Qwen3-235B-A22B-Instruct-2507, QwenTeam, 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DocParser.html" target="_blank" rel="noopener noreferrer">#DocParser</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2294" target="_blank" rel="noopener noreferrer" class="title-link">LLM APIs Are Not Complete Document Parsers, Jerry Liu, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jerryjliu0/status/1948475176062255504?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-07-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2293" target="_blank" rel="noopener noreferrer" class="title-link">anycoder, akhaliq, 2025.07</a>
<span class="snippet"><span>Comment</span><p>ã“ã‚“ãªã“ã¨ãŒã§ãã‚‹æ¨¡æ§˜ã€‚ã‚µã‚¤ãƒˆã®ãƒªãƒ‹ãƒ¥ãƒ¼ã‚¢ãƒ«ã«ä½¿ã£ã¦ã¿ã‚ˆã†ã‹ã—ã‚‰ã€ã€ã€<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sivil_taram/status/1948030614076342632?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/SpeculativeDecoding.html" target="_blank" rel="noopener noreferrer">#SpeculativeDecoding</a>
<span class="issue_date">Issue Date: 2025-07-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2291" target="_blank" rel="noopener noreferrer" class="title-link">Speculative Decodingï¼šFaster Inference Without Paying for More GPU, ELYZA, 2025.07</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/Attack.html" target="_blank" rel="noopener noreferrer">#Attack</a>
<span class="issue_date">Issue Date: 2025-07-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2278" target="_blank" rel="noopener noreferrer" class="title-link">ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³2.0 : é€²åŒ–ã™ã‚‹é˜²å¾¡æ©Ÿæ§‹ã¨ãã®å›é¿æ‰‹æ³•, yuasa, 2025.07</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2025-07-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2277" target="_blank" rel="noopener noreferrer" class="title-link">Qwen Code, Qwen Team, 2025.07</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2273" target="_blank" rel="noopener noreferrer" class="title-link">LLM Servingã‚’æ”¯ãˆã‚‹æŠ€è¡“, Kotoba Technologies, 2025.07</a>
<span class="snippet"><span>Comment</span><p>ã“ã¡ã‚‰ã‚‚å‚ç…§ã®ã“ã¨:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2263" target="_blank" rel="noopener noreferrer">LLMæ¨è«–ã«é–¢ã™ã‚‹æŠ€è¡“ãƒ¡ãƒ¢, iwashi.co, 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2270" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-235B-A22B-Instruct-2507, QwenTeam, 2025.07</a>
<span class="snippet"><span>Comment</span><p>Qwen3æœ€æ–°ç‰ˆã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç”»åƒã¯å…ƒãƒã‚¹ãƒˆã‚ˆã‚Šå¼•ç”¨ã€‚hybrid thinkingã‚’å»ƒæ­¢ã—ã€non-thinkingã®ã¿ã¨ã—ãŸã€‚non-thinkingã ãŒæ€§èƒ½ãŒå‘ä¸Šã—ã€contexté•·ãŒ256k ï¼ˆå‰å›ã®2å€ï¼‰ã«ãªã£ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br><img src="https://github.com/user-attachments/assets/087412bd-cf0f-4bac-a93b-867176fa5aad" alt="image" loading="lazy"><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1947344511988076547?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1909" target="_blank" rel="noopener noreferrer">Qwen3, Qwen Team, 2025.04</a>
</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2226" target="_blank" rel="noopener noreferrer">[Paper Note] Reasoning or Memorization? Unreliable Results of Reinforcement Learning  Due to Data Contamination, Mingqi Wu+, arXiv'25</a>
<br><br>ã«ãŠã„ã¦ã€Qwen2.5-math-7B, Qwen2.5-7Bã«å¯¾ã—ã¦ã€Math500, AMC,<br> AIME2024ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã®å¯èƒ½æ€§ãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹ç‚¹ã«ã¯ç•™æ„ã—ãŸã„ã€‚</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2195" target="_blank" rel="noopener noreferrer">Kimi K2: Open Agentic Intelligence, moonshotai, 2025.07</a>
<br><br>ãƒã‚¹ãƒˆã®ãƒ™ãƒ³ãƒä¸Šã§ã¯Kimi-K2ã‚’è¶…ãˆã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ãŒã€æœãŸã—ã¦â€¦ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<span class="issue_date">Issue Date: 2025-07-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2265" target="_blank" rel="noopener noreferrer" class="title-link">LMDeploy, OpenMMLab, 2023.07</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Parallelism.html" target="_blank" rel="noopener noreferrer">#Parallelism</a>
<a class="button" href="articles/Inference.html" target="_blank" rel="noopener noreferrer">#Inference</a>
<a class="button" href="articles/Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<span class="issue_date">Issue Date: 2025-07-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2263" target="_blank" rel="noopener noreferrer" class="title-link">LLMæ¨è«–ã«é–¢ã™ã‚‹æŠ€è¡“ãƒ¡ãƒ¢, iwashi.co, 2025.07</a>
<span class="snippet"><span>Comment</span><p>```<br>ãƒ¡ãƒ¢ãƒª (GB) = P Ã— (Q Ã· 8) Ã— (1 + ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰)<br><br>- Pï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ï¼ˆå˜ä½ã¯10å„„ï¼‰<br>- Qï¼šãƒ“ãƒƒãƒˆç²¾åº¦ï¼ˆä¾‹ï¼š16ã€32ï¼‰ã€8ã§å‰²ã‚‹ã“ã¨ã§ãƒ“ãƒƒãƒˆã‚’ãƒã‚¤ãƒˆã«å¤‰æ›<br>- ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ï¼ˆï¼…ï¼‰ï¼šæ¨è«–ä¸­ã®è¿½åŠ ãƒ¡ãƒ¢ãƒªã¾ãŸã¯ä¸€æ™‚çš„ãªä½¿ç”¨é‡ï¼ˆä¾‹ï¼šKVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒƒãƒ•ã‚¡ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®çŠ¶æ…‹ï¼‰<br>```<br><br>â†‘ã“ã‚Œã€å¿˜ã‚ŒãŒã¡ãªã®ã§ãƒ¡ãƒ¢â€¦</p>
<p>é–¢é€£ï¼ˆé‡å­åŒ–é–¢é€£ç ”ç©¶ï¼‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2264" target="_blank" rel="noopener noreferrer">[Paper Note] AWQ: Activation-aware Weight Quantization for LLM Compression and   Acceleration, Ji Lin+, MLSys'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1570" target="_blank" rel="noopener noreferrer">SmoothQuant: Accurate and Efficient Post-Training Quantization for Large   Language Models, Guangxuan Xiao+, ICML'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1043" target="_blank" rel="noopener noreferrer">GPTQ: Accurate Post-Training Quantization for Generative Pre-trained   Transformers, Elias Frantar+, N/A, ICLR'23</a>
</p>
<p>ã™ã”ã„ãƒ¡ãƒ¢ã â€¦å‹‰å¼·ã«ãªã‚Šã¾ã™</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2025-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2255" target="_blank" rel="noopener noreferrer" class="title-link">OpenReasoning-Nemotron: A Family of State-of-the-Art Distilled Reasoning Models, Nvidia, 2025.07</a>
<span class="snippet"><span>Comment</span><p>DeepSeek-R1-0528ã‹ã‚‰å¿œç­”ã‚’åˆæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã§SFTã®ã¿ã‚’å®Ÿæ–½ã—ã€32Bã§Qwe3-235B-A22Bã¨åŒç­‰ã‹ä¸Šå›ã‚‹æ€§èƒ½ã€‚ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯Qwen2.5ã€‚ãƒ‡ãƒ¼ã‚¿ã¯OpenCode/Math/Scienceã‚’åˆ©ç”¨ã€‚<br><img src="https://github.com/user-attachments/assets/8dda86f4-df71-4732-8d51-5905672fa5c9" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/igtmn/status/1946291288170725617?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãƒ‡ãƒ¼ã‚¿ã‚‚å…¬é–‹äºˆå®š</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2252" target="_blank" rel="noopener noreferrer" class="title-link">Seed-X-Instruct-7B, ByteDance-Seed, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1946056084709359653?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MTã«ç‰¹åŒ–ã—ãŸMultilingual SLMã€‚7Bãƒ¢ãƒ‡ãƒ«ã ãŒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã§ã¯ä»–ã®å¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ä»¥ä¸Šã€‚</p>
<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ: 


<a href="https://github.com/ByteDance-Seed/Seed-X-7B/blob/main/Technical_Report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/ByteDance-Seed/Seed-X-7B/blob/main/Technical_Report.pdf</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-07-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2243" target="_blank" rel="noopener noreferrer" class="title-link">Asymmetry of verification and verifierâ€™s law, Jason Wei, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_jasonwei/status/1945287045251052007?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Video.html" target="_blank" rel="noopener noreferrer">#Video</a>
<a class="button" href="articles/SemanticID.html" target="_blank" rel="noopener noreferrer">#SemanticID</a>
<span class="issue_date">Issue Date: 2025-07-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2242" target="_blank" rel="noopener noreferrer" class="title-link">LLM Recommendation Systems: AI Engineer World's Fair 2025, AI Engineer, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kazunori_279/status/1945644623474692103?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯IDã®å®Ÿç”¨ä¾‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-07-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2228" target="_blank" rel="noopener noreferrer" class="title-link">è«–æ–‡ã§ã¯èªã‚‰ã‚Œãªã„LLMé–‹ç™ºã«ãŠã„ã¦é‡è¦ãªã“ã¨ Swallow Projectã‚’é€šã—ã¦, Kazuki Fujii, NLPã‚³ãƒ­ã‚­ã‚¦ãƒ , 2025.07</a>
<span class="snippet"><span>Comment</span><p>ç‹¬è‡ªLLMé–‹ç™ºã®ç§ã®æƒ³åƒãªã©é¥ã‹ã«è¶…ãˆã‚‹éå¸¸ã«å›°é›£ãªå´é¢ãŒè¨˜è¿°ã•ã‚Œã¦ãŠã‚Šã€ã“ã‚Œã‚’ã§ãã‚‹ã®ã¯ã‚ã¾ã‚Šã«ã‚‚ã™ã”ã„ã¨ã„ã†æ„Ÿæƒ³ã‚’æŠ±ã„ãŸï¼ˆå°ä¸¦æ„Ÿã ã‘ã©æœ¬å½“ã«ã™ã”ã„ã¨æ€ã†ã€‚ã™ã”ã„ã¨ã—ã‹è¨€ã„ã‚ˆã†ãŒãªã„ï¼‰</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/Decoder.html" target="_blank" rel="noopener noreferrer">#Decoder</a>
<span class="issue_date">Issue Date: 2025-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2223" target="_blank" rel="noopener noreferrer" class="title-link">Modded-NanoGPT, KellerJordan, 2024.05</a>
<span class="snippet"><span>Comment</span><p>NanoGPT speedrun</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2118" target="_blank" rel="noopener noreferrer">[Paper Note] The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT  Improvements, Bingchen Zhao+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2208" target="_blank" rel="noopener noreferrer">ãã¿ã¯NanoGPT speedrunã‚’çŸ¥ã£ã¦ã„ã‚‹ã‹ï¼Ÿ, PredNext, 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<span class="issue_date">Issue Date: 2025-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2208" target="_blank" rel="noopener noreferrer" class="title-link">ãã¿ã¯NanoGPT speedrunã‚’çŸ¥ã£ã¦ã„ã‚‹ã‹ï¼Ÿ, PredNext, 2025.07</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/MCP.html" target="_blank" rel="noopener noreferrer">#MCP</a>
<span class="issue_date">Issue Date: 2025-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2204" target="_blank" rel="noopener noreferrer" class="title-link">advanced-mcp-features, epicweb-dev, 2025.06</a>
<span class="snippet"><span>Comment</span><p>MCPã®å‹‰å¼·ã«è‰¯ã„ã‹ã‚‚ã—ã‚Œãªã„ã®ã§ãƒ¡ãƒ¢</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2195" target="_blank" rel="noopener noreferrer" class="title-link">Kimi K2: Open Agentic Intelligence, moonshotai, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kimi_moonshot/status/1943687594560332025?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>1T-A32Bã®ãƒ¢ãƒ‡ãƒ«ã€‚ã•ã™ãŒã«é«˜æ€§èƒ½ã€‚<br><br><img src="https://github.com/user-attachments/assets/39b524d3-6e22-456d-8d61-fcd22519d58d" alt="image" loading="lazy"><br><br>ï¼ˆè¿½è¨˜ï¼‰ Reasoningãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„ã®ã«ã“ã®æ€§èƒ½ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚</p>
<p>1T-A32Bã®ãƒ¢ãƒ‡ãƒ«ã‚’15.5Tãƒˆãƒ¼ã‚¯ãƒ³è¨“ç·´ã™ã‚‹ã®ã«ä¸€åº¦ã‚‚training instabilityãŒãªã‹ã£ãŸã‚‰ã—ã„<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/eliebakouch/status/1943689105721667885?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2188" target="_blank" rel="noopener noreferrer">[Paper Note] Spike No More: Stabilizing the Pre-training of Large Language Models, Sho Takase+, COLM'25</a>
</p>
<p>é‡å­åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒå‡ºãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ivanfioravanti/status/1944069021709615119?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ä»•äº‹æ—©ã™ãã‚‹<p>DeepSeek V3/R1ã¨ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®é•ã„:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1944056316424577525?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>MLAã®ãƒ˜ãƒƒãƒ‰ã®æ•°ãŒæ¸›ã‚Šã€ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®æ•°ã‚’å¢—åŠ ã•ã›ã¦ã„ã‚‹<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1944902706747072678?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹Optimizer:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
</p>
<p>2ã¤ã»ã©ãƒã‚°ãŒã‚ã‚Šä¿®æ­£ã•ã‚ŒãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kimi_moonshot/status/1945050874067476962?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>chatbot arenaã§OpenLLMã®ä¸­ã§ãƒˆãƒƒãƒ—ã®ã‚¹ã‚³ã‚¢<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lmarena_ai/status/1945866381880373490?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼ãŒå…¬é–‹:


<a href="https://github.com/MoonshotAI/Kimi-K2/blob/main/tech_report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/MoonshotAI/Kimi-K2/blob/main/tech_report.pdf</a>


<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1947384629314396302?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã¾ã¨ã‚:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1947400424622866793?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä»¥ä¸‹ã®ã‚ˆã†ãªæŠ€è¡“ãŒä½¿ã‚ã‚Œã¦ã„ã‚‹æ¨¡æ§˜<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1937" target="_blank" rel="noopener noreferrer">Rewriting Pre-Training Data Boosts LLM Performance in Math and Code, Kazuki Fujii+, arXiv'25</a>
<br>- MLA <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1621" target="_blank" rel="noopener noreferrer">MHA vs MQA vs GQA vs MLA, Zain ul Abideen, 2024.07</a>
<br>- MuonCip<br>- MuonOptimizer <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
 <br>- QK-Clip<br>  - å‚è€ƒï¼ˆã“ã¡ã‚‰ã¯LayerNormã‚’ä½¿ã£ã¦ã„ã‚‹ãŒï¼‰: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1202" target="_blank" rel="noopener noreferrer">Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision,   Language, Audio, and Action, Jiasen Lu+, N/A, CVPR'24</a>
<br>- RLVR<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
 <br>- Self-Critique<br>  - é–¢é€£: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2274" target="_blank" rel="noopener noreferrer">[Paper Note] Inference-Time Scaling for Generalist Reward Modeling, Zijun Liu+, arXiv'25</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2017" target="_blank" rel="noopener noreferrer">[Paper Note] Writing-Zero: Bridge the Gap Between Non-verifiable Problems and  Verifiable Rewards, Xun Lu, arXiv'25</a>
 <br>- Temperature Decay  <br>  - æœ€åˆã¯Temperatureã‚’é«˜ã‚ã«ã—ãŸæ¢ç´¢å¤šã‚ã«ã€å¾ŒåŠã¯Temperatureã‚’ä½ã‚ã«ã—ã¦åŠ¹ç”¨å¤šã‚ã«ãªã‚‹ã‚ˆã†ã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°<br>- Tool useã®ãŸã‚ã®Synthetic Data<br><br>&lt;img width="1058" height="336" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/74eacdb2-8f64-4d53-b2d0-66df770f2e8b"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/74eacdb2-8f64-4d53-b2d0-66df770f2e8b"&lt;/a&gt;


/&gt;</p>
<p>Reward Hackingã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€RLVRã§ã¯ãªãpairwise comparisonã«åŸºã¥ãself judging w/ critique ã‚’åˆ©ç”¨ãã¦ãŠã‚Šã€ã“ã‚ŒãŒéå¸¸ã«åŠ¹æœçš„ãªå¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ã¯ã€ã¨ã„ã†æ„è¦‹ãŒã‚ã‚‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/grad62304977/status/1953408751521632401?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2193" target="_blank" rel="noopener noreferrer" class="title-link">H-Nets - the Past, Goomba Lab, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sukjun_hwang/status/1943703574908723674?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>tokenizerã‚‚å«ã‚ã¦ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æœ€é©ãªinputã®ç²’åº¦ã‚’å­¦ç¿’</p>
<p>å…¬å¼ãƒã‚¹ãƒˆ(?):



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cartesia_ai/status/1943705750381207880?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1634" target="_blank" rel="noopener noreferrer">Byte Latent Transformer: Patches Scale Better Than Tokens, Artidoro Pagnoni+, ICML'25 Workshop Tokshop</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2073" target="_blank" rel="noopener noreferrer">[Paper Note] From Bytes to Ideas: Language Modeling with Autoregressive U-Nets, Mathurin Videau+, arXiv'25</a>
<br><br>ByteLatentTransformerãªã©ã¨ã¯ã©ã†é•ã†ã®ã ã‚ã†ã‹ï¼Ÿ</p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1944542938723475869?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2164" target="_blank" rel="noopener noreferrer" class="title-link">SmolLM3: smol, multilingual, long-context reasoner, HuggingFace, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thom_wolf/status/1942670704278732978?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>SmolLM3ã‚’æ§‹ç¯‰ã™ã‚‹éš›ã®è©³ç´°ãªãƒ¬ã‚·ãƒ”(ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒ‡ãƒ¼ã‚¿ã€data mixture, 3 stageã®pretraining(web, code, mathã®å‰²åˆã¨å“è³ªã‚’ã‚¹ãƒ†ãƒ¼ã‚¸ã”ã¨ã«å¤‰ãˆã€stable-&gt;stable-&gt;decayã§å­¦ç¿’), midtraining(long context-&gt;reasoning, post training(sft-&gt;rl), ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰reasoningãƒ¢ãƒ‡ãƒ«ã®ä½œã‚Šæ–¹ã€è©•ä¾¡ãªã©)ãŒèª¬æ˜ã•ã‚Œã¦ã„ã‚‹</p>
<p>å­¦ç¿’/è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆãªã©ãŒãƒªãƒªãƒ¼ã‚¹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_lewtun/status/1950209751066742982?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2138" target="_blank" rel="noopener noreferrer" class="title-link">Context Engineering - What it is, and techniques to consider, llamaindex, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/llama_index/status/1940810514227196236?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2135" target="_blank" rel="noopener noreferrer" class="title-link">The New Skill in AI is Not Prompting, It's Context Engineering, PHLSCHMID, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/akiratosei/status/1940960253233058198?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-06-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2115" target="_blank" rel="noopener noreferrer" class="title-link">ERNIE 4.5 Series, ERNIE TEAM, 2025.06</a>
<span class="snippet"><span>Comment</span><p>Tech Report:


<a href="https://yiyan.baidu.com/blog/publication/ERNIE_Technical_Report.pdf" target="_blank" rel="noopener noreferrer">https://yiyan.baidu.com/blog/publication/ERNIE_Technical_Report.pdf</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/paddlepaddle/status/1939535276197744952?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1939576393098023188?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-06-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2108" target="_blank" rel="noopener noreferrer" class="title-link">Hunyuan-A13B-Instruct, tencent, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1938515928221995066?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£, 80B-A13B<br>- fast, slow thinking mode<br>- 256k context window<br>- agenticã‚¿ã‚¹ã‚¯ã«ç‰¹ã«ç‰¹åŒ–<br>- Grouped Query Attention, è¤‡æ•°ã®é‡å­åŒ–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ã‚µãƒãƒ¼ãƒˆ</p>
<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tencenthunyuan/status/1938525874904801490?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç”»åƒã¯å…¬å¼ãƒã‚¹ãƒˆã‚ˆã‚Šå¼•ç”¨ã€‚Qwen3-235B-A22Bã‚ˆã‚Šã‚‚å°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§ã€åŒç­‰ï¼ˆagenticã‚¿ã‚¹ã‚¯ã¯ãã‚Œä»¥ä¸Šï¼‰ãªã‚ˆã†ã«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã¯è¦‹ãˆã‚‹ãŒã€æœãŸã—ã¦ã€‚<br><br><img src="https://github.com/user-attachments/assets/ed47bae2-9017-4cf2-b1e1-50e863da1c77" alt="image" loading="lazy"></p>
<p>æœãŸã—ã¦æ—¥æœ¬èªã®æ€§èƒ½ã¯ã©ã†ã ã‚ã†ã‹ã€‚<br>TENCENT HUNYUAN COMMUNITY LICENSE<br>


<a href="https://github.com/Tencent-Hunyuan/Hunyuan-A13B/blob/main/LICENSE" target="_blank" rel="noopener noreferrer">https://github.com/Tencent-Hunyuan/Hunyuan-A13B/blob/main/LICENSE</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2097" target="_blank" rel="noopener noreferrer" class="title-link">Swallow LLM Leaderboard, Swallow LLM Team</a>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1096" target="_blank" rel="noopener noreferrer">æ—¥æœ¬èªLLMã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ï¼ˆLLM.jpï¼‰</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1055" target="_blank" rel="noopener noreferrer">Nejumi LLMãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2095" target="_blank" rel="noopener noreferrer" class="title-link">Nemo-RL, Nvidia, 2025.05</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2092" target="_blank" rel="noopener noreferrer" class="title-link">LLM-jp-3.1 ã‚·ãƒªãƒ¼ã‚º instruct4 ã®å…¬é–‹, LLM-jp, 2025.05</a>
<span class="snippet"><span>Comment</span><p>é–¢é€£<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2089" target="_blank" rel="noopener noreferrer">[Paper Note] Instruction Pre-Training: Language Models are Supervised Multitask   Learners, Daixuan Cheng+, EMNLP'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2090" target="_blank" rel="noopener noreferrer">[Paper Note] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy   Data, Fahim Tajwar+, ICML'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2091" target="_blank" rel="noopener noreferrer">[Paper Note] AnswerCarefully: A Dataset for Improving the Safety of Japanese LLM  Output, Hisami Suzuki+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2078" target="_blank" rel="noopener noreferrer" class="title-link">äººé–“ã‚’é¨™ã—ã¦ã‚µãƒœã‚‹AIãŸã¡, ä½è—¤ç«œé¦¬, 2025.06</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2075" target="_blank" rel="noopener noreferrer" class="title-link">Kimi-VL-A3B-Thinking-2506, moonshotai, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/reach_vb/status/1937159672932286950?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ§˜ã€…ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§SoTA(gpt4o, Qwen2.5-VL-7B)ã‚’é”æˆã—ãŸReasoning VLM</p>
<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2200" target="_blank" rel="noopener noreferrer">[Paper Note] Kimi-VL Technical Report, Kimi Team+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/MinimalCode.html" target="_blank" rel="noopener noreferrer">#MinimalCode</a>
<span class="issue_date">Issue Date: 2025-06-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2069" target="_blank" rel="noopener noreferrer" class="title-link">Nano-vLLM, GeeeekExplorer, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/marktechpost/status/1936689592507543643?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>vLLMã¨åŒç­‰ã®inference speedã‚’å®Ÿç¾ã™ã‚‹ãƒŸãƒ‹ãƒãƒ ã§ã‚¯ãƒªãƒ¼ãƒ³ãªå®Ÿè£…ã€‚å‹‰å¼·ç”¨ã«è‰¯ã•ãã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-06-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2066" target="_blank" rel="noopener noreferrer" class="title-link">POLARIS: A Post-Training Recipe for Scaling Reinforcement Learning on Advanced Reasoning Models,</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1936233712510718361?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>PJã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹RLãƒ©ã‚¤ãƒ–ãƒ©ãƒª:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1969" target="_blank" rel="noopener noreferrer">verl: Volcano Engine Reinforcement Learning for LLMs, ByteDance Seed Team, 2025.04</a>
</p>
<p>AIME2025ã®ã¿ã®è©•ä¾¡ã ãŒ4Bã§ã“ã®æ€§èƒ½â€¦ï¼Ÿ<br><img src="https://github.com/user-attachments/assets/02d1ece1-b12f-4877-b500-ff910e45ff00" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2057" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities, Gemini Team, 2025.06</a>
<span class="snippet"><span>Comment</span><p>é–¢é€£ãƒã‚¹ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaguring1/status/1935203032922485080?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1935019697683980603?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1935841560736022708?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2043" target="_blank" rel="noopener noreferrer" class="title-link">MiniMax-M1, MiniMax, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1934642204397744137?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>vLLMã§ã®servingãŒæ¨å¥¨ã•ã‚Œã¦ãŠã‚Šã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯1Mã€456Bã®MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§activation weightã¯46B</p>
<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/minimax__ai/status/1934637031193514237?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Agentã‚‚ãƒªãƒªãƒ¼ã‚¹ã—ãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/minimax__ai/status/1945550814728376803?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Zero/FewShotLearning.html" target="_blank" rel="noopener noreferrer">#Zero/FewShotLearning</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-06-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2042" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Language Models are Unsupervised Multitask Learners, Radford+, OpenAI, 2019</a>
<span class="snippet"><span>Comment</span><p>ä»Šæ›´ãªãŒã‚‰ã€GPT-2è«–æ–‡ã‚’ãƒ¡ãƒ¢ã£ã¦ãªã‹ã£ãŸã®ã§è¿½åŠ ã€‚<br><br>å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã¯ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‚’è§£ããŸã‚ã«ã‚¿ã‚¹ã‚¯ã”ã¨ã«å€‹åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’Finetuningã™ã‚‹å¿…è¦ãŒã‚ã£ãŸãŒã€å¤§è¦æ¨¡ãªWebTextãƒ‡ãƒ¼ã‚¿ï¼ˆRedditã«ãŠã„ã¦æœ€ä½3ã¤ã®upvoteã‚’å¾—ãŸãƒã‚¹ãƒˆã®å¤–éƒ¨ãƒªãƒ³ã‚¯ã‚’åé›†ï¼‰ã«ã‚ˆã£ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã•ã›ã‚‹ã“ã¨ã§ã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã§é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã§ãã€Zero-Shot task transfer, p(output | input, task) , ãŒå®Ÿç¾ã§ãã‚‹ã‚ˆã€ã¨ã„ã†è©±ã€‚<br><br>ä»Šã–ã£ãã‚Šè¦‹è¿”ã™ã¨ã€Next Token Predictionã¨ã„ã†ç”¨èªã¯è«–æ–‡ä¸­ã«å‡ºã¦ãã¦ãŠã‚‰ãšã€ã‹ã¤ "Language Modeling" ã¨ã„ã†ç”¨èªã®ã¿ã§å…·ä½“çš„ãªlossã¯è¨˜è¿°ã•ã‚Œã¦ãŠã‚‰ãšï¼ˆå½“æ™‚ã¯RNNè¨€èªãƒ¢ãƒ‡ãƒ«ã§åºƒãå­¦ç¿’æ–¹æ³•ãŒçŸ¥ã‚‰ã‚Œã¦ã„ãŸã‹ã‚‰ã ã‚ã†ã‹ï¼Ÿï¼‰ã€ã‹ã¤ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚‚å­¦ç¿’ã®ã‚³ãƒ¼ãƒ‰ã¯æä¾›ã•ã‚Œã¦ãŠã‚‰ãšã€lossã®å®šç¾©ã‚‚å«ã¾ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br>ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®ãƒ¢ãƒ‡ãƒ«å®šç¾©:<br>


<a href="https://github.com/openai/gpt-2/blob/master/src/model.py#L169" target="_blank" rel="noopener noreferrer">https://github.com/openai/gpt-2/blob/master/src/model.py#L169</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Unsupervised.html" target="_blank" rel="noopener noreferrer">#Unsupervised</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2025-06-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2029" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unsupervised Elicitation of Language Models, Wen+, Anthropic, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiaxinwen22/status/1932908642858418441?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-06-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2020" target="_blank" rel="noopener noreferrer" class="title-link">Qwen_Qwen3-Embedding-4B-GGUF, QwenTeam, 2025.06</a>
<span class="snippet"><span>Comment</span><p>8Bãƒ¢ãƒ‡ãƒ«ã¯MTEBã§ãƒˆãƒƒãƒ—ã®æ€§èƒ½ã‚’é”æˆã€‚context 32Kã€‚100ä»¥ä¸Šã®è¨€èªã‚’ã‚µãƒãƒ¼ãƒˆã€‚32--2560æ¬¡å…ƒã«outputã®æ¬¡å…ƒæ•°ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã‚‹ï¼ˆå¬‰ã—ã„ã€ãŒæ€§èƒ½ã«ã©ã®ç¨‹åº¦å½±éŸ¿ãŒå‡ºã‚‹ã‹ã‚‰æ°—ã«ãªã‚‹ï¼‰ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1930739968332157018?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>QwenTeam post:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1930648422778118246?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-05-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2001" target="_blank" rel="noopener noreferrer" class="title-link">2025å¹´åº¦äººå·¥çŸ¥èƒ½å­¦ä¼šå…¨å›½å¤§ä¼šãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«è¬›æ¼”ã€Œæ·±å±¤åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®æ•°ç†ã€, Taiji Suzuki, 2025.05</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/btreetaiji/status/1927678122817921442?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-05-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1998" target="_blank" rel="noopener noreferrer" class="title-link">SSII2025 [OS1-03] PFNã«ãŠã‘ã‚‹Small Language Modelã®é–‹ç™º, éˆ´æœ¨ è„©å¸, ç”»åƒã‚»ãƒ³ã‚·ãƒ³ã‚°ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ , 2025.05</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_stakaya/status/1927588359217844702?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1827" target="_blank" rel="noopener noreferrer">Training Compute-Optimal Large Language Models, Jordan Hoffmann+, NeurIPS'22</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1828" target="_blank" rel="noopener noreferrer">Scaling Laws for Neural Language Models, Jared Kaplan+, arXiv'20</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1999" target="_blank" rel="noopener noreferrer">Distillation Scaling Laws, Dan Busbridge+, ICML'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need, Suriya Gunasekar+, N/A, arXiv'23</a>
</p>
<p>å…ˆè¡Œç ”ç©¶ã‚’å…ƒã«ä»®èª¬ã‚’ç«‹ã¦ã¦ã€æœ‰æœ›ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å–ã‚‹æ„æ€æ±ºå®šãŒéå¸¸ã«å‹‰å¼·ã«ãªã‚‹ã€‚<br>Scaling LawsãŒä¸ç¢ºå®Ÿæ€§ã®ã‚ã‚‹æ„æ€æ±ºå®šã«ãŠã„ã¦éå¸¸ã«æœ‰ç”¨ãªçŸ¥è¦‹ã¨ãªã£ã¦ã„ã‚‹ã€‚</p>
<p>åŒã˜ã‚ˆã†ã«Pruningã¨Knowledge Distilationã‚’å®Ÿæ–½ã—ãŸäº‹ä¾‹ã¨ã—ã¦ä¸‹è¨˜ãŒæŒ™ã’ã‚‰ã‚Œã‚‹<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1873" target="_blank" rel="noopener noreferrer">Llama-3_1-Nemotron-Ultra-253B-v1, Nvidia, 2025.04</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-05-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1997" target="_blank" rel="noopener noreferrer" class="title-link">Spurious Rewards: Rethinking Training Signals in RLVR, Shao+, 2025.05</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stellalisy/status/1927392717593526780?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å‚è€ƒï¼ˆè€ƒå¯Ÿï¼‰: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/weiliu99/status/1930826904522875309?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å‚è€ƒï¼ˆè€ƒå¯Ÿï¼‰:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/g_k_swamy/status/1945159211752562739?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã“ã¡ã‚‰ã§ã‚‚Qwen2.5 MATH 7b ã‚’ç”¨ã„ã¦æ¤œè¨¼ã—ã¦ã„ã‚‹ãŒã€ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã®å•é¡ŒãŒä»®ã«æœ¬å½“ã ã¨ã—ãŸã‚‰ã€ã©ã†å½±éŸ¿ã™ã‚‹ã ã‚ã†ã‹ã€‚ã‚¹ãƒ¬ãƒƒãƒ‰ä¸­ã®ã‚°ãƒ©ãƒ•ã‚‚MATH500ï¼ˆQwen2.5ã«ãŠã„ã¦ã‚³ãƒ³ã‚¿ãƒŸã®å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰ã®æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1987" target="_blank" rel="noopener noreferrer" class="title-link">ã€DLè¼ªèª­ä¼šã€‘ Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models, Deep Learning JP, 2025.05</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kym384/status/1925852937835737569?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1986" target="_blank" rel="noopener noreferrer">Masked Diffusion Modelã®é€²å±•, Deep Learning JP, 2025.03</a>
 ã§Literatureã‚’ã–ã£ãã‚ŠæŠŠæ¡ã—ã¦ã‹ã‚‰ã“ã¡ã‚‰ã‚’èª­ã‚€ã®ãŒè‰¯ã•ãã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1986" target="_blank" rel="noopener noreferrer" class="title-link">Masked Diffusion Modelã®é€²å±•, Deep Learning JP, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kym384/status/1925852884656099572?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚¹ãƒ©ã‚¤ãƒ‰ä¸­ã®ARã®ã‚ˆã†ã«KV CacheãŒä½¿ãˆãªã„å•é¡Œã«å¯¾å‡¦ã—ãŸç ”ç©¶ãŒ<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1984" target="_blank" rel="noopener noreferrer">dKV-Cache: The Cache for Diffusion Language Models, Xinyin Ma+, arXiv'25</a>
<br><br>ã“ã®è¾ºã¯dLLMãŒæœ‰æœ›ã§ã‚ã‚Œã°ã€ã©ã‚“ã©ã‚“é€²åŒ–ã—ã¦ã„ãã®ã ã‚ã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/AWS.html" target="_blank" rel="noopener noreferrer">#AWS</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1976" target="_blank" rel="noopener noreferrer" class="title-link">Webã‚¹ã‚±ãƒ¼ãƒ«ã®æ—¥æœ¬èª-ç”»åƒã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒMOMIJIã€ã®æ§‹ç¯‰ _å·¨å¤§ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’AWSã§é«˜é€Ÿã«å‡¦ç†ã™ã‚‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³, Turing ï¼ˆstudio_graphï¼‰, 2025.05</a>
<span class="snippet"><span>Comment</span><p>è²´é‡ãªVLMãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰ãƒã‚¦ãƒã‚¦</p>
<p>é’å¡—ã‚Šã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã‚’å…·ä½“çš„ã«ã©ã†ã‚„ã£ã¦ã„ã‚‹ã®ã‹æ°—ã«ãªã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2025-05-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1972" target="_blank" rel="noopener noreferrer" class="title-link">OpenAI-Codex, OpenAI, 2025.05</a>
<span class="snippet"><span>Comment</span><p>OpenHandsã®Neubigæ°ãŒã€OpenAIã®ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆä¸­ã§å ±å‘Šã•ã‚Œã¦ã„ã‚‹SWE-Bench Verifiedã®ã‚¹ã‚³ã‚¢ã«ã¤ã„ã¦ã€è¨€åŠã—ã¦ã„ã‚‹ã€‚OpenAIã¯23å€‹ã‚µãƒ³ãƒ—ãƒ«ã«ã¤ã„ã¦(internal infrastructureã§å‹•ä½œã•ã›ã‚‰ã‚Œãªã„ãŸã‚)é™¤å¤–ã—ã¦ã„ã‚‹ã®ã§ã€ãã®åˆ†ã‚¹ã‚³ã‚¢ã«ä¸‹é§„ãŒå±¥ã‹ã‚Œã¦ã„ã‚‹ã‚ˆã†ã§ã€ãƒ–ãƒ­ã‚°ä¸­ã®passNã®ã‚¹ã‚³ã‚¢ã‚’ä»–ã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã®ã‚¹ã‚³ã‚¢ã¨æ¯”è¼ƒã™ã‚‹éš›ã«ã¯æ³¨æ„ãŒå¿…è¦ã£ã½ã„ã€‚<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1923893277519962287?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<span class="issue_date">Issue Date: 2025-05-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1971" target="_blank" rel="noopener noreferrer" class="title-link">AlphaEvolve: A coding agent for scientific and algorithmic discovery, Novikov+, Google DeepMind, 2025.05</a>
<span class="snippet"><span>Comment</span><p>blog post:


<a href="https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/" target="_blank" rel="noopener noreferrer">https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<span class="issue_date">Issue Date: 2025-05-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1969" target="_blank" rel="noopener noreferrer" class="title-link">verl: Volcano Engine Reinforcement Learning for LLMs, ByteDance Seed Team, 2025.04</a>
<span class="snippet"><span>Comment</span><p>SoTAãªRLã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ•°è¡Œã®ã‚³ãƒ¼ãƒ‰ã§å®Ÿè£…å¯èƒ½ã§ã€Sequence ParallelismãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã®ã§é•·ã„ç³»åˆ—ã‚’æ‰±ãˆã‚‹ã€‚FSDP, Megatron-LM,vLLM,SGLangãªã©ã¨ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã§ãã‚‹ã£ã½ã„ï¼Ÿ</p>
<p>æ³¨æ„ç‚¹ï¼ˆè¶…é‡è¦ï¼‰:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fengyao1909/status/1953882575241723911?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>inference backendï¼ˆãƒ–ãƒ­ã‚°ä¸­ã§ã¯vLLM, SGLangãªã©ã‚’ä»®å®šã€‚ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã«åˆ©ç”¨ã™ã‚‹ï¼‰ã¨trainingã®backendï¼ˆãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯, FSDPãªã©ã‚’ä»®å®šã™ã‚‹ï¼‰ã®ãƒŸã‚¹ãƒãƒƒãƒã«ã‚ˆã£ã¦ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿèµ·ç¢ºç‡ã«å·®ãŒç”Ÿã˜ã€ãƒãƒªã‚·ãƒ¼ã®æ›´æ–°ãŒã†ã¾ãã„ã‹ãªããªã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/92ab33c6-d943-4101-9f73-250c697af816" alt="image" loading="lazy"><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2228" target="_blank" rel="noopener noreferrer">è«–æ–‡ã§ã¯èªã‚‰ã‚Œãªã„LLMé–‹ç™ºã«ãŠã„ã¦é‡è¦ãªã“ã¨ Swallow Projectã‚’é€šã—ã¦, Kazuki Fujii, NLPã‚³ãƒ­ã‚­ã‚¦ãƒ , 2025.07</a>
<br><br>ã§ã‚‚è¨€ã‚ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã¯ãƒã‚°ãŒã‚ã‚‹ã®ãŒæ™®é€šãªã®ã­ã€ã€ã€ã€‚</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1953" target="_blank" rel="noopener noreferrer" class="title-link">Stanford Alpaca: An Instruction-following LLaMA Model, Taori +, 2023.03</a>
<span class="snippet"><span>Comment</span><p>ä»Šæ›´ãªãŒã‚‰ãƒ¡ãƒ¢ã«è¿½åŠ ã€‚ã‚¢ã‚«ãƒ‡ãƒŸã‚¢ã«ãŠã‘ã‚‹OpenLLMã«å¯¾ã™ã‚‹Instruction Tuningã®å…ˆé§†ã‘çš„ç ”ç©¶ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-05-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1921" target="_blank" rel="noopener noreferrer" class="title-link">Phi-4-reasoning Technical Report, 2025.04</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dimitrispapail/status/1917731614899028190?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã¡ã‚‰ã®è§£èª¬ãŒéå¸¸ã«ã‚ˆãã¾ã¨ã¾ã£ã¦ã„ã‚‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1918216082231320632?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãŒã€å…ƒãƒã‚¹ãƒˆã§ã‚‚ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼ä¸­ã§ã‚‚o3-miniã®reasoning traceã‚’SFTã«åˆ©ç”¨ã—ã¦CoTã®èƒ½åŠ›ã‚’å¼·åŒ–ã—ãŸæ—¨ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ãŒã€ã“ã‚Œã¯OpenAIã®åˆ©ç”¨è¦ç´„ã«é•åã—ã¦ã„ã‚‹ã®ã§ã¯â€¦ï¼Ÿ</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-04-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1909" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3, Qwen Team, 2025.04</a>
<span class="snippet"><span>Comment</span><p>- 119è¨€èªã‚’ã‚µãƒãƒ¼ãƒˆ<br>- MoEãƒ¢ãƒ‡ãƒ« <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1911" target="_blank" rel="noopener noreferrer">Outrageously Large Neural Networks: The Sparsely-Gated  Mixture-of-Experts Layer, Noam Shazeer+, ICLR'17</a>
<br>    - 30B-A3B / 235B-A22N<br>    - 128K context window<br>    - Qwen2.5ã¯MoEã‚’æ¡ç”¨ã—ã¦ã„ãªã„ã®ã§æ–°ãŸãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ãªã‚‹<br>- Denseãƒ¢ãƒ‡ãƒ«ï¼ˆéMoEãƒ¢ãƒ‡ãƒ«ï¼‰ã‚‚å…¬é–‹<br>    - 0.6B -- 32B<br>    - 32K -- 128K context window<br>- Thinking/Non-thinking ã®åˆ‡ã‚Šæ›¿ãˆãŒåˆ‡ã‚Šæ›¿ãˆãŒå¯èƒ½<br>    - ã‚¹ã‚¤ãƒƒãƒã¯è‡ªå‹•çš„ã«å®Ÿæ–½ã•ã‚Œã‚‹ãŒã€ãƒ¦ãƒ¼ã‚¶ãŒæ˜ç¤ºçš„ã« `/think`, `/no_think` ã‚’ user_promptã®æœ«å°¾ã«è¿½åŠ ã™ã‚‹ã“ã¨ã§åˆ¶å¾¡ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½<br>- Pre-training<br>    - ãƒ‡ãƒ¼ã‚¿<br>        - 36 trillion tokensã«ã‚ˆã£ã¦å­¦ç¿’ï¼ˆQwen-2.5ã®2å€ï¼‰<br>        - å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ã¯webãƒ‡ãƒ¼ã‚¿ã«åŠ ãˆã¦ã€PDF-likeãªæ–‡æ›¸ç¾¤ã‹ã‚‰Qwen2.5-VL <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1835" target="_blank" rel="noopener noreferrer">Qwen2.5-VL-32B-Instruct, Qwen Team, 2025.03</a>
 ã«ã‚ˆã£ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã€Qwen2.5 ã§æŠ½å‡ºã•ã‚ŒãŸå†…å®¹ã®å“è³ªã‚’æ”¹å–„ã—åˆ©ç”¨<br>        - ã¾ãŸã€math / code ã«é–¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ãŸã‚ã«ã€Qwen2.5-Math / Qwen2.5-Coderã‚’ç”¨ã„ã¦åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆtextbooks / QA pairs / code snippets <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need, Suriya Gunasekar+, N/A, arXiv'23</a>
 ï¼‰<br>    - äº‹å‰å­¦ç¿’ã®ã‚¹ãƒ†ãƒƒãƒ—<br>        - S1: contexté•·ãŒ4kã®30 trillion tokenã§äº‹å‰å­¦ç¿’<br>        - S2: STEM / coding / reasoning task ãªã©ã®knowledge-intensiveãƒ‡ãƒ¼ã‚¿ã®æ¯”ç‡ã‚’å¢—ã‚„ã—ã¦ç¶™ç¶šäº‹å‰å­¦ç¿’ (ã“ã‚ŒãŒãŠãã‚‰ã 5 trillion tokenç¨‹åº¦ï¼Ÿ)<br>        - Final Stage: contexté•·ã‚’32kã«æ‹¡å¤§ã—é«˜å“è³ªãªlong-context dataã§ç¶™ç¶šäº‹å‰å­¦ç¿’<br>    - ã“ã‚Œã«ã‚ˆã‚ŠBaseãƒ¢ãƒ‡ãƒ«ãŒå®Œæˆã—ã€Qwen3-235Bå…¨ä½“ã®ã†ã¡10%ç¨‹åº¦ã®Active Parameterã®åˆ©ç”¨ã™ã‚‹ã ã‘ã§ï¼ˆi.e., 22Bã§ï¼‰ã€Qwen2.5-72B Baseã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½é”æˆ<br>- Post-training<br>    - S1: long-CoT cold start<br>        - æ•°å­¦/coding/logical reasoning/STEMãªã©ã®å¤šæ§˜ãªlong CoTãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦SFT <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1749" target="_blank" rel="noopener noreferrer">s1: Simple test-time scaling, Niklas Muennighoff+, arXiv'25</a>
 <br>    - S2: reasoning-based RL<br>        - rule-based (verifiable) rewards ã«ã‚ˆã‚‹RL <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
 <br>        - S1/S2ã®æµã‚Œã¯ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
 ã«æœ‰åŠ¹æ€§ãŒç¤ºã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€long CoT Dataã«ã‚ˆã‚‹SFT -&gt; RLã‚’å®Ÿæ–½<br>    - S3: thinking mode fusion<br>        - S2ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦long CoTãƒ‡ãƒ¼ã‚¿ã¨instruction tuningãƒ‡ãƒ¼ã‚¿ï¼ˆéLong CoTï¼‰ã‚’ç”Ÿæˆã—ã€Thinking/Non-thinkingã‚’è‡ªå‹•çš„ã«é¸æŠã—ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ï¼ˆSFT or RLã¯è¨˜è¿°ãªã—ï¼‰<br>    - S4: general RL<br>        - 20ä»¥ä¸Šã®ä¸€èˆ¬çš„ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã®ã‚¿ã‚¹ã‚¯ã‚’é€šã˜ã¦ä¸€èˆ¬çš„ãªèƒ½åŠ›ã®å‘ä¸Šã¨ã€safetyã«é–¢ã™ã‚‹alignmentã®å®Ÿæ–½ï¼ˆe.g., instruction following, format following, agentèƒ½åŠ›ãªã©ï¼‰</p>
<p>BestPracticeã«é–¢ã™ã‚‹ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ivanfioravanti/status/1916934241281061156?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1917712050983428400?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1907" target="_blank" rel="noopener noreferrer" class="title-link">Improving Recommendation Systems &amp; Search in the Age of LLMs, eugeneyan, 2025.04</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2025-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1903" target="_blank" rel="noopener noreferrer" class="title-link">Deepwiki, Cognition, 2025.04</a>
<span class="snippet"><span>Comment</span><p>githubãƒªãƒã‚¸ãƒˆãƒªã«é–¢ã™ã‚‹ãƒªãƒƒãƒãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¯¾ã—ã¦Devinã‚’é€šã˜ã¦å¯¾è©±çš„ã«è³ªå•ãŒã§ãã‚‹æ¨¡æ§˜ã€‚ã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—ä¸è¦ã§ã€githubãƒªãƒã‚¸ãƒˆãƒªã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’deepwikiã«å¤‰ãˆã‚‹ã ã‘ã§åˆ©ç”¨å¯èƒ½</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-04-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1896" target="_blank" rel="noopener noreferrer" class="title-link">Introducing UI-TARS-1.5, ByteDance, 2025.04</a>
<span class="snippet"><span>GPT Summary</span>- UI-TARSã¯ã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å…¥åŠ›ã¨ã—ã¦äººé–“ã®ã‚ˆã†ã«ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡Œã†ãƒã‚¤ãƒ†ã‚£ãƒ–GUIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€å¾“æ¥ã®å•†æ¥­ãƒ¢ãƒ‡ãƒ«ã«ä¾å­˜ã›ãšã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚å®Ÿé¨“ã§ã¯ã€10ä»¥ä¸Šã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§SOTAæ€§èƒ½ã‚’é”æˆã—ã€ç‰¹ã«OSWorldã‚„AndroidWorldã§ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã‚¹ã‚³ã‚¢ã‚’è¨˜éŒ²ã—ã¾ã—ãŸã€‚UI-TARSã¯ã€å¼·åŒ–ã•ã‚ŒãŸçŸ¥è¦šã€çµ±ä¸€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã€ã‚·ã‚¹ãƒ†ãƒ -2æ¨è«–ã€åå°„çš„ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒˆãƒ¬ãƒ¼ã‚¹ã«ã‚ˆã‚‹åå¾©ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãªã©ã®é©æ–°ã‚’å–ã‚Šå…¥ã‚Œã€æœ€å°é™ã®äººé–“ã®ä»‹å…¥ã§é©å¿œã—ç¶šã‘ã‚‹èƒ½åŠ›ã‚’æŒã£ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>paper:


<a href="https://arxiv.org/abs/2501.12326" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2501.12326</a>


</p>
<p>è‰²ã€…ã¨æ›¸ã„ã¦ã‚ã‚‹ãŒã€ã–ã£ãã‚Šè¨€ã†ã¨ByteDanceã«ã‚ˆã‚‹ã€Imageã¨Textã‚’inputã¨ã—ã¦å—ã‘å–ã‚Šã€Textã‚’outputã™ã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMã«ã‚ˆã‚‹Computer Use Agent (CUA)</p>
<p>é–¢é€£<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1794" target="_blank" rel="noopener noreferrer">OpenAI API ã§ã® Computer use ã®ä½¿ã„æ–¹, npaka, 2025.03</a>
</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1912913195607663049?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-04-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1886" target="_blank" rel="noopener noreferrer" class="title-link">Seed-Thinking-v1.5, ByteDance, 2025.04</a>
<span class="snippet"><span>Comment</span><p>DeepSeek-R1ã‚’å¤šãã®ãƒ™ãƒ³ãƒã§ä¸Šå›ã‚‹200B, 20B activated paramã®reasoning model</p>
<p>æœ€è¿‘ã®ãƒ†ã‚­ã‚¹ãƒˆã®OpenWeightLLMã¯Alibaba, DeepSeek, ByteDance, Nvidiaã®4å¼·ã¨ã„ã†æ„Ÿã˜ã‹ãªâ€¦ï¼Ÿï¼ˆãã®ã†ã¡OpenAIãŒã‚ªãƒ¼ãƒ—ãƒ³ã«ã™ã‚‹Reasoning Modelã‚‚å…¥ã£ã¦ããã†ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<span class="issue_date">Issue Date: 2025-04-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1880" target="_blank" rel="noopener noreferrer" class="title-link">Large Vision Language Model ï¼ˆLVLMï¼‰ ã«é–¢ã™ã‚‹æœ€æ–°çŸ¥è¦‹ã¾ã¨ã‚ ï¼ˆPart 1ï¼‰, Daiki Shiono, 2024.11</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2025-04-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1877" target="_blank" rel="noopener noreferrer" class="title-link">Fiction.liveBench, Kas, 2025.04</a>
<span class="snippet"><span>Comment</span><p>long contextã§ã¯Gemini-2.5-proã®åœ§å‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/API.html" target="_blank" rel="noopener noreferrer">#API</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-04-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1875" target="_blank" rel="noopener noreferrer" class="title-link">BFCLv2, UC Berkeley, 2024.08</a>
<span class="snippet"><span>Comment</span><p>LLMã®Tool Useã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ç¾åœ¨ã®ãƒ‡ãƒ•ã‚¡ã‚¯ãƒˆã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã¨ãªã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</p>
<p>BFCLv3:<br>


<a href="https://gorilla.cs.berkeley.edu/blogs/13_bfcl_v3_multi_turn.html" target="_blank" rel="noopener noreferrer">https://gorilla.cs.berkeley.edu/blogs/13_bfcl_v3_multi_turn.html</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Pruning.html" target="_blank" rel="noopener noreferrer">#Pruning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-04-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1873" target="_blank" rel="noopener noreferrer" class="title-link">Llama-3_1-Nemotron-Ultra-253B-v1, Nvidia, 2025.04</a>
<span class="snippet"><span>Comment</span><p>DeepSeek-R1ã‚’GPQA Diamond <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1155" target="_blank" rel="noopener noreferrer">GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark, David Rein+, N/A, COLM'24</a>
, AIME2024/2025, Llama4 Maverickã‚’<br>BFCLv2ï¼ˆTool Calling, <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1875" target="_blank" rel="noopener noreferrer">BFCLv2, UC Berkeley, 2024.08</a>
), IFEVal <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1137" target="_blank" rel="noopener noreferrer">Instruction-Following Evaluation for Large Language Models, Jeffrey Zhou+, N/A, arXiv'23</a>
 ã§ä¸Šå›ã‚Š, ãã®ã»ã‹ã¯ArenaHardã‚’é™¤ãDeepSeekR1ã¨åŒç­‰<br><img src="https://github.com/user-attachments/assets/b0de99ee-f4ec-4b03-8b0b-8939b4f1e23b" alt="image" loading="lazy"><br><br>DeepSeekR1ãŒ671Bï¼ˆMoEã§37B Activation Paramï¼‰ã«å¯¾ã—ã€ã“ã¡ã‚‰ã¯253Bï¼ˆãŸã ã—ã€Llama3.1ãŒãƒ™ãƒ¼ã‚¹ãªã®ã§MoEã§ã¯ãªã„ï¼‰ã§åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã¨ãªã£ã¦ã„ã‚‹ã€‚<br>Reasoningã‚’ON/OFFã™ã‚‹èƒ½åŠ›ã‚‚å‚™ã‚ã£ã¦ã„ã‚‹ã€‚<br><br>ãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ã«è¨“ç·´ã•ã‚ŒãŸã‹ã‚’ç¤ºã™å…¨ä½“å›³ãŒã¨ã¦ã‚‚èˆˆå‘³æ·±ã„:<img src="https://github.com/user-attachments/assets/9a014777-61d8-46ae-818b-ace9ed5c002d" alt="image" loading="lazy"><br><br>ç‰¹ã« <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
 ã§ã‚‚æœ‰åŠ¹æ€§ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€SFTã‚’ã—ã¦ã‹ã‚‰Reasoningã‚’å¼·åŒ–ã™ã‚‹ï¼ˆå¼·åŒ–ã¨ã„ã†ã‚ˆã‚Šå…ƒã€…æŒã£ã¦ã„ã‚‹èƒ½åŠ›ã‚’å¼•ãå‡ºã™ï¼Ÿï¼‰RLã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚<br><br>è©³ç´°ã¯ä¸‹è¨˜Blogã¨ã®ã“ã¨:<br>


<a href="https://developer.nvidia.com/blog/build-enterprise-ai-agents-with-advanced-open-nvidia-llama-nemotron-reasoning-models/" target="_blank" rel="noopener noreferrer">https://developer.nvidia.com/blog/build-enterprise-ai-agents-with-advanced-open-nvidia-llama-nemotron-reasoning-models/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kuchaev/status/1909444566379573646?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-04-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1872" target="_blank" rel="noopener noreferrer" class="title-link">Dream-v0-Instruct-7B, Dream-org, 2025.04</a>
<span class="snippet"><span>Comment</span><p>OpenWeightãªæ‹¡æ•£è¨€èªãƒ¢ãƒ‡ãƒ«</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/curveweb/status/1909551257725133132?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1776" target="_blank" rel="noopener noreferrer">Large Language Diffusion Models, Shen Nie+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-04-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1863" target="_blank" rel="noopener noreferrer" class="title-link">Llama 4 Series, Meta, 2025.04</a>
<span class="snippet"><span>Comment</span><p>Downloads:


<a href="https://www.llama.com/?utm_source=twitter&utm_medium=organic_social&utm_content=image&utm_campaign=llama4" target="_blank" rel="noopener noreferrer">https://www.llama.com/?utm_source=twitter&utm_medium=organic_social&utm_content=image&utm_campaign=llama4</a>


</p>
<p>Huggingface:<br>


<a href="https://huggingface.co/collections/meta-llama/llama-4-67f0c30d9fe03840bc9d0164" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/meta-llama/llama-4-67f0c30d9fe03840bc9d0164</a>


</p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1908601269004230763?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Artificial Analysisã«ã‚ˆã‚‹æ€§èƒ½æ¤œè¨¼:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1908890796415414430?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>MaverickãŒGPT4oã¨åŒç­‰ã€ScoutãŒGPT4o-miniã¨åŒç­‰<br><br>Update:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1909624239747182989?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ€§èƒ½ã«é–¢ã—ã¦ä¸å¯è§£ãªç‚¹ãŒå¤šãã†ãªã®ã§æ§˜å­è¦‹ã‚’ã—ã¦ã‚‚è‰¯ã„ã‹ã‚‚ã€‚</p>
<p>æ€§èƒ½æ¤œè¨¼ï¼ˆMath-Perturb):



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kaixuanhuang1/status/1909387970773234088?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¥æœ¬èªã«ã‚ã¾ã‚Šå¼·ããªã„ã¨ã„ã†æƒ…å ±ã‚‚<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gosrum/status/1909626761098494060?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã©ã†ã‚„ã‚‰vLLMã®Llama4ã®inferenceã«ãƒã‚°ãŒã‚ã£ãŸã‚„ã†ã§ã€vLLMã®Issue 16311ã«ã¦ã€Llama4ã®inferenceã«é–¢ã™ã‚‹ãƒã‚°ãŒä¿®æ­£ã•ã‚Œã€æ€§èƒ½ãŒå‘ä¸Šã—ãŸæ¨¡æ§˜ã€‚ã©ã®ãƒ™ãƒ³ãƒã‚’ä¿¡ã˜ãŸã‚‰è‰¯ã„ã‹ã¾ã‚‹ã§ã‚ã‹ã‚‰ã‚“ã€‚</p>
<p>2025.0413ç¾åœ¨ã®chatbot arenaã®ãƒ©ãƒ³ã‚¯ã¯ã€32ä½ã¨ãªã‚Šï¼ˆchatbot arenaå‘ã‘ã«tuningã•ã‚Œã¦ã„ãŸã§ã‚ã‚ã†ãƒ¢ãƒ‡ãƒ«ã¯2ä½ã ã£ãŸï¼‰GPT-4oãŒ29ä½ã§ã‚ã‚‹ã“ã¨ã‚’è€ƒæ…®ã™ã‚‹ã¨ä¸Šè¨˜ã®Artificial Intelligenceã®è©•ä¾¡ã¨ã‚‚å¤§ä½“ä¸€è‡´ã—ã¦ã„ã‚‹ã€‚<br><br>


<a href="https://lmarena.ai" target="_blank" rel="noopener noreferrer">https://lmarena.ai</a>


<br><br>é–¢é€£ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tunguz/status/1911142310160855541?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1850" target="_blank" rel="noopener noreferrer" class="title-link">openhands-lm-32b-v0.1, all-hands, 2025.03</a>
<span class="snippet"><span>Comment</span><p>Qwen Coder 2.5 Instruct 32Bã«åŸºã¥ãæœ€å…ˆç«¯ã®SWEã‚¿ã‚¹ã‚¯ãŒå®Ÿè¡Œå¯èƒ½ãªãƒ¢ãƒ‡ãƒ«</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-03-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1844" target="_blank" rel="noopener noreferrer" class="title-link">Recommendation Systems â€¢ LLM, vinjia.ai, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/vinija_recommendation-systems-llm-activity-7306171374446727168-cUg2?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/vinija_recommendation-systems-llm-activity-7306171374446727168-cUg2?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1835" target="_blank" rel="noopener noreferrer" class="title-link">Qwen2.5-VL-32B-Instruct, Qwen Team, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1904227859616641534?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-03-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer" class="title-link">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å¿…èª­</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-03-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1830" target="_blank" rel="noopener noreferrer" class="title-link">Nemotron-H: A Family of Accurate, Efficient Hybrid Mamba-Transformer Models, Nvidia, 2025.03</a>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1820" target="_blank" rel="noopener noreferrer">Hunyuan T1, Tencent, 2025.03</a>
</p>
<p>Transformerã®Self-attention Layerã‚’Mamba2 Layerã«ç½®æ›ã™ã‚‹ã“ã¨ã§ã€æ§˜ã€…ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§åŒç­‰ã®æ€§èƒ½ã€ã‚ã‚‹ã„ã¯ä¸Šå›ã‚‹æ€§èƒ½ã§3å€ç¨‹åº¦ã®Inference timeã®é«˜é€ŸåŒ–ã‚’ã—ã¦ã„ã‚‹ï¼ˆ65536 input, 1024 outputï¼‰ã€‚<br><br>56Bç¨‹åº¦ã®mediumã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã¨ã€8Bç¨‹åº¦ã®è»½é‡ãªãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦è¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ç‰¹ã«ã€8Bãƒ¢ãƒ‡ãƒ«ã§Mambaã¨Transformerã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã¨ã€é€šå¸¸ã®Transformerãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒã—ã¦ã„ã‚‹ã€‚å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«15 Trillion Tokenã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã€ã“ã®ãƒ‡ãƒ¼ã‚¿é‡ã§ã®Apple to Appleã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é–“ã®æ¯”è¼ƒã¯ã€ç¾çŠ¶ã§ã¯æœ€ã‚‚å¤§è¦æ¨¡ãªã‚‚ã®ã¨ã®ã“ã¨ã€‚æ€§èƒ½ã¯å¤šãã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã«ã—ã¦ã‚‚åŒç­‰ã€Commonsense Understandingã§ã¯ä¸Šå›ã£ã¦ã„ã‚‹ã€‚<br><br>ã¾ãŸã€å­¦ç¿’ã—ãŸNemotron-Hã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦æŒã¤VLMã«ã¤ã„ã¦ã‚‚ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒè¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1823" target="_blank" rel="noopener noreferrer" class="title-link">8 Types of RoPE, Kseniase, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://huggingface.co/posts/Kseniase/498106595218801" target="_blank" rel="noopener noreferrer">https://huggingface.co/posts/Kseniase/498106595218801</a>


</p>
<p>RoPEã«ã¤ã„ã¦ã‚µãƒ¼ãƒ™ã‚¤ãŒå¿…è¦ã«ãªã£ãŸã‚‰è¦‹ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1822" target="_blank" rel="noopener noreferrer" class="title-link">The "think" tool: Enabling Claude to stop and think in complex tool use situations, Anthropic, 2025.03</a>
<span class="snippet"><span>Comment</span><p>"è€ƒãˆã‚‹"ã“ã¨ã‚’ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦å®šç¾©ã—åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€externalãªthinkingã‚’æ˜ç¤ºçš„ã«å®Ÿæ–½ã—ãŸä¸Šã§ã‚¿ã‚¹ã‚¯ã‚’é‚è¡Œã•ã›ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-03-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1821" target="_blank" rel="noopener noreferrer" class="title-link">Understanding R1-Zero-Like Training: A Critical Perspective, 2025.03</a>
<span class="snippet"><span>GPT Summary</span>- DeepSeek-R1-Zeroã¯ã€æ•™å¸«ãªã—ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã§LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã®åŠ¹æœã‚’ç¤ºã—ãŸã€‚ç ”ç©¶ã§ã¯ã€ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨RLã®ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆ†æã—ã€DeepSeek-V3-BaseãŒã€Œã‚¢ãƒä½“é¨“ã€ã‚’ç¤ºã™ã“ã¨ã‚„ã€Qwen2.5ãŒå¼·åŠ›ãªæ¨è«–èƒ½åŠ›ã‚’æŒã¤ã“ã¨ã‚’ç™ºè¦‹ã€‚ã•ã‚‰ã«ã€Group Relative Policy Optimizationï¼ˆGRPOï¼‰ã®æœ€é©åŒ–ãƒã‚¤ã‚¢ã‚¹ã‚’ç‰¹å®šã—ã€Dr. GRPOã¨ã„ã†æ–°æ‰‹æ³•ã‚’å°å…¥ã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³åŠ¹ç‡ã‚’æ”¹å–„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€7Bãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§AIME 2024ã«ãŠã„ã¦43.3%ã®ç²¾åº¦ã‚’é”æˆã—ã€æ–°ãŸãªæœ€å…ˆç«¯ã‚’ç¢ºç«‹ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£ç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1815" target="_blank" rel="noopener noreferrer">DAPO: An Open-Source LLM Reinforcement Learning System at Scale, Qiying Yu+, arXiv'25</a>
</p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1903464313391624668?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆï¼ˆã¨è«–æ–‡ä¸­ã®å½“è©²éƒ¨åˆ†ï¼‰ã‚’èª­ã‚€ã¨ã€<br><br>- ã‚ªãƒªã‚¸ãƒŠãƒ«ã®GRPOã®å®šå¼ã§ã¯2ã¤ã®ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ã‚‹:<br>  - response-level length bias: 1/|o_i| ã§Advantageã‚’é™¤ç®—ã—ã¦ã„ã‚‹ãŒã€ã“ã‚Œã¯AdvantageãŒè² ã®å ´åˆï¼ˆã¤ã¾ã‚Šã€èª¤ç­”ãŒå¤šã„å ´åˆï¼‰ã€Œé•·ã„å¿œç­”ã€ã®ãƒšãƒŠãƒ«ãƒ†ã‚£ãŒå°ã•ããªã‚‹ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ãŒã€Œé•·ã„å¿œç­”ã€ã‚’å¥½ã‚€ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ã‚‹ã€‚ä¸€æ–¹ã§ã€AdvantageãŒæ­£ã®å ´åˆï¼ˆæ­£ç­”ï¼‰ã¯ã€ŒçŸ­ã„å¿œç­”ã€ãŒå¥½ã¾ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚<br>  - question-level difficulty bias: ã‚°ãƒ«ãƒ¼ãƒ—å†…ã®å…¨ã¦ã®å¿œç­”ã«å¯¾ã™ã‚‹Rewardã®stdã§Advantageã‚’é™¤ç®—ã—ã¦ã„ã‚‹ãŒã€stdãŒå°ã•ããªã‚‹å•é¡Œï¼ˆã™ãªã‚ã¡ã€ç°¡å˜ã™ãã‚‹oré›£ã—ã™ãã‚‹å•é¡Œï¼‰ã‚’ã‚ˆã‚Šé‡è¦–ã™ã‚‹ã‚ˆã†ãªã€å•é¡Œã«å¯¾ã™ã‚‹é‡ã¿ã¥ã‘ã«ã‚ˆã‚‹ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ã‚‹ã€‚<br>- aha momentï¼ˆself-seflectionï¼‰ã¯RLã«ã‚ˆã£ã¦åˆã‚ã¦ç²å¾—ã•ã‚ŒãŸã‚‚ã®ã§ã¯ãªãã€ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ™‚ç‚¹ã§ç²å¾—ã•ã‚Œã¦ãŠã‚Šã€RLã¯ãã®æŒ™å‹•ã‚’å¢—é•·ã—ã¦ã„ã‚‹ã ã‘ï¼ˆã“ã‚Œã¯Xä¸Šã§ã™ã§ã«ã©ã“ã‹ã§è¨€åŠã•ã‚Œã¦ã„ãŸãªãï¼‰ã€‚<br>- ã“ã‚Œã¾ã§ã¯output lengthã‚’å¢—ã‚„ã™ã“ã¨ãŒæ€§èƒ½æ”¹å–„ã®éµã ã¨æ€ã‚ã‚Œã¦ã„ãŸãŒã€ã“ã®è«–æ–‡ã§ã¯å¿…ãšã—ã‚‚ãã†ã§ã¯ãªãã€self-reflectionç„¡ã—ã®æ–¹ãŒæœ‰ã‚Šã®å ´åˆã‚ˆã‚Šã‚‚Acc.ãŒé«˜ã„å ´åˆãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ï¼ˆã§ã‚‚ã±ã£ã¨è¦‹ã‚°ãƒ©ãƒ•ã‚’è¦‹ã‚‹ã¨å³è‚©ä¸ŠãŒã‚Šã®å‚¾å‘ã§ã¯ã‚ã‚‹ï¼‰<br><br>ã¨ã„ã£ãŸçŸ¥è¦‹ãŒã‚ã‚‹æ¨¡æ§˜</p>
<p>ã‚ã¨ã§èª­ã‚€</p>
<p>ï¼ˆå‚è€ƒï¼‰Dr.GRPOã‚’å®Ÿéš›ã«Big-Mathã¨Qwen-2.5-7Bã«é©ç”¨ã—ãŸã‚‰å®‰å®šã—ã¦åæŸã—ãŸã‚ˆã¨ã„ã†ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zzlccc/status/1910902637152940414?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<span class="issue_date">Issue Date: 2025-03-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1820" target="_blank" rel="noopener noreferrer" class="title-link">Hunyuan T1, Tencent, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/txhunyuan/status/1903121005809373386?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç”»åƒã¯ãƒ–ãƒ­ã‚°ã‚ˆã‚Šå¼•ç”¨ã€‚DeepSeek-R1ã¨æ¯”è¼ƒã™ã‚‹ã¨å„ªã£ã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ã¨åŠ£ã£ã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ãŒã‚ã‚Šã€ãªã‚“ã¨ã‚‚è¨€ãˆãªã„æ„Ÿã€‚GPT4.5ã‚ˆã‚Šå¤§å¹…ã«ä¸Šå›ã£ã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ï¼ˆMath, Reasoningï¼‰ãŒã‚ã‚‹ãŒã€ãã‚‚ãã‚‚ãã†ã„ã£ãŸã‚¿ã‚¹ã‚¯ã¯o1ãªã©ã®reasoningãƒ¢ãƒ‡ãƒ«ã®é ˜åŸŸã€‚o1ã¨æ¯”è¼ƒã™ã‚‹ã¨ã“ã‚Œã‚‚ã¾ã‚å„ªã£ã¦ã„ã‚‹éƒ¨åˆ†ã‚‚ã‚ã‚Œã°åŠ£ã£ã¦ã„ã‚‹éƒ¨åˆ†ã‚‚ã‚ã‚‹ã¨ã„ã†æ„Ÿã˜ã€‚å”¯ä¸€ã€ToolUseã«é–¢ã—ã¦ã¯ä¸€è²«ã—ã¦OpenAIãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒå¼·ã„ã€‚<br><br>Chineseã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦ã¯DeepSeek-R1ã¨å®Œå…¨ã«ã‚¹ã‚³ã‚¢ãŒä¸€è‡´ã—ã¦ã„ã‚‹ãŒã€è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„ã®ã ã‚ã†ã‹ï¼Ÿ<br><img src="https://github.com/user-attachments/assets/de2325b2-0bd5-4177-a336-e6f008a32d40" alt="image" loading="lazy"></p>
<p>reasoningãƒ¢ãƒ‡ãƒ«ã‹ã¤ã€Transformerã¨Mambaã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã§ã€MoEã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚</p>
<p>Transformerã¨Mambaã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã«ã¤ã„ã¦ï¼ˆWenhuChenæ°ã®ãƒã‚¹ãƒˆï¼‰:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1903656455036715311?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Layer-wise Mixingã¨Sequence-wise Mixingã®2ç¨®é¡ãŒå­˜åœ¨ã™ã‚‹ã¨ã®ã“ã¨ã€‚å‰è€…ã¯Transformerã®Self-Attenton Layerã‚’Mamba Layerã«ç½®æ›ã—ãŸã‚‚ã®ã§ã€å¾Œè€…ã¯Sequenceã®Long partã‚’Mambaã§ã¾ãšã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€Short Partã‚’Transformerã§ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹éš›ã®Cross-Attentionã®encoder stateã¨ã—ã¦ä¸ãˆã‚‹æ–¹æ³•ã¨ã®ã“ã¨ã€‚<p>Self-Attention Layerã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ã§Inferenceæ™‚ã®è¨ˆç®—é‡ã¨ãƒ¡ãƒ¢ãƒªã‚’å¤§å¹…ã«å‰Šæ¸›ã§ãã‚‹ï¼ˆSelf-Attentionã¯å…¨ä½“ã®KV Cacheã«å¯¾ã—ã¦Attentionã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1818" target="_blank" rel="noopener noreferrer" class="title-link">Sudoku-bench, SakanaAI, 2025.03</a>
<span class="snippet"><span>GPT Summary</span>- Sudoku-Benchã¯ã€CTCã§ç´¹ä»‹ã•ã‚ŒãŸç‹¬è‡ªã®ãƒ«ãƒ¼ãƒ«ã‚’æŒã¤æ•°ç‹¬ãƒ‘ã‚ºãƒ«ã‚’ç‰¹å¾´ã¨ã—ã€AIæ¨è«–ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã«æœ€é©ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã™ã€‚ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã§ã¯ã€æ•°ç‹¬ãƒ™ãƒ³ãƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€LLMè©•ä¾¡ç”¨ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰ã€SudokuPadãƒ„ãƒ¼ãƒ«ã€æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ãªã©ã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sakanaailabs/status/1902913196358611278?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å–ã£ãŸã‚‰ã©ã†ã„ã†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«ãªã‚‹ã®ã ã‚ã†ã‹ã€‚ç‰¹ã«ã¾ã ãã†ã„ã…ãŸãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯å…¬é–‹ã•ã‚Œã¦ã„ãªã„æ¨¡æ§˜ã€‚</p>
<p>ãƒ–ãƒ­ã‚°è¨˜äº‹ã«ï¼ˆå°†æ¥çš„ã«æœ€æ–°ã®çµæœã‚’repositoryã«è¿½è¨˜ã™ï¼Ÿæ¨¡æ§˜ï¼‰ç¾æ™‚ç‚¹ã§ã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ãŒè¼‰ã£ã¦ã„ãŸã€‚ç¾çŠ¶ã€o3-miniãŒãƒ€ãƒ³ãƒˆãƒ„ã«è¦‹ãˆã‚‹ã€‚<br>


<a href="https://sakana.ai/sudoku-bench/" target="_blank" rel="noopener noreferrer">https://sakana.ai/sudoku-bench/</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1814" target="_blank" rel="noopener noreferrer" class="title-link">Llama Nemotron, Nvidia, 2025.03</a>
<span class="snippet"><span>Comment</span><p>Nvidiaã«ã‚ˆã‚‹åˆã‚ã¦ã®reasoning modelã€‚<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kuchaev/status/1902078122792775771?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Artificial Analysisã«ã‚„ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1902386178206429434?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>GPQA Diamondï¼ˆå¤§å­¦é™¢ï¼ˆPh.Dï¼‰ãƒ¬ãƒ™ãƒ«ã®ç”Ÿç‰©å­¦ã€ç‰©ç†å­¦ã€åŒ–å­¦ã®450å•ç¨‹åº¦ã®é›£è§£ãªmultiple choice questionï¼‰ã§ã€DeepSeekV3, GPT4o, QwQ-32Bã‚’outperform. Claude 3.7 sonnetã‚ˆã‚Šå°‘ã—ã‚¹ã‚³ã‚¢ãŒä½ã„ã€‚<br>DeepSeekR1, o1, o3-miniï¼ˆhighï¼‰, Claude 3.7 sonnet Thinkingãªã©ã«ã¯åŠã‚“ã§ã„ãªã„ã€‚<br><br><img src="https://github.com/user-attachments/assets/2d2b3716-83a6-4c56-bca7-f7d8cf981bbb" alt="image" loading="lazy"><br><br>ï¼ˆç”»åƒã¯å…ƒãƒã‚¹ãƒˆã‚ˆã‚Šå¼•ç”¨ï¼‰<p>ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰ãˆã‚‹ã“ã¨ã§reasoningã‚’on/offã§ãã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1810" target="_blank" rel="noopener noreferrer" class="title-link">EXAONE-Deep-32B, LG AI Research, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ai_for_success/status/1901908168805912602?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>EXAONE AI Model License Agreement 1.1 - NC<br>å•†ç”¨åˆ©ç”¨ä¸å¯</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1809" target="_blank" rel="noopener noreferrer" class="title-link">SmolDocling-256M, IBM Research, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/andimarafioti_we-just-dropped-%F0%9D%97%A6%F0%9D%97%BA%F0%9D%97%BC%F0%9D%97%B9%F0%9D%97%97%F0%9D%97%BC%F0%9D%97%B0%F0%9D%97%B9%F0%9D%97%B6%F0%9D%97%BB%F0%9D%97%B4-activity-7307415358427013121-wS8m?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/andimarafioti_we-just-dropped-%F0%9D%97%A6%F0%9D%97%BA%F0%9D%97%BC%F0%9D%97%B9%F0%9D%97%97%F0%9D%97%BC%F0%9D%97%B0%F0%9D%97%B9%F0%9D%97%B6%F0%9D%97%BB%F0%9D%97%B4-activity-7307415358427013121-wS8m?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4</a>


</p>
<p>Apache-2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã€‚è¨€èªã¯Englishã®ã¿ãªæ¨¡æ§˜</p>
<p>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªImage-To-Textãƒ¢ãƒ‡ãƒ«ã€‚ã‚µãƒ³ãƒ—ãƒ«ã¯ã“ã¡ã‚‰<br><img src="https://github.com/user-attachments/assets/d16ce5a9-4336-4daa-ab6f-94d67ae77c41" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-03-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1808" target="_blank" rel="noopener noreferrer" class="title-link">ERNIE4.5_X1, Baidu, 2025.03</a>
<span class="snippet"><span>Comment</span><p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ai_for_success/status/1901149459826045223?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- ERNIE4.5ã¯GPT4.5ã‚’ã•ã¾ã–ã¾ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ä¸Šå›ã‚Šã€ä¾¡æ ¼ãŒãªã‚“ã¨GPT4.5ã®1%<br>- X1ã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªreasoningãƒ¢ãƒ‡ãƒ«ã§DeepSeek-R1ã¨åŒç­‰ã®æ€§èƒ½ã§åŠé¡<br><br>ã‚‰ã—ã„</p>
<p>ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯6æœˆ30æ—¥ã«ã‚ªãƒ¼ãƒ—ãƒ³ï¼ˆã‚¦ã‚§ã‚¤ãƒˆï¼Ÿï¼‰ã«ãªã‚‹ã¨ã‚¹ãƒ¬ãƒƒãƒ‰ã§è¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-03-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1807" target="_blank" rel="noopener noreferrer" class="title-link">sarashina2-vision-{8b, 14b}, SB Intuitions, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sei_shinagawa/status/1901467733331701966?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>VLMã€‚Xã«æ•£è¦‹ã•ã‚Œã‚‹è©¦è¡Œä¾‹ã‚’è¦‹ã‚‹ã¨æ—¥æœ¬èªã®èª­ã¿å–ã‚Šæ€§èƒ½ã¯çµæ§‹é«˜ãã†ã«è¦‹ãˆã‚‹ã€‚</p>
<p>ãƒ¢ãƒ‡ãƒ«æ§‹æˆã€å­¦ç¿’ã®è©³ç´°ã€ãŠã‚ˆã³è©•ä¾¡:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sbintuitions/status/1901472307421278604?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLMï¼ˆsarashina2ï¼‰, Vision Encoderï¼ˆQwen2-VLï¼‰, Projectorã®3ã¤ã§æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€3æ®µéšã®å­¦ç¿’ã‚’è¸ã‚“ã§ã„ã‚‹ã€‚<br>æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦Projectorã®ã¿ã‚’å­¦ç¿’ã—Vision Encoderã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’å¯¾å¿œã¥ã‘ã‚‹ã€‚ç¶šã„ã¦ã€æ—¥æœ¬èªã‚’å«ã‚€ç”»åƒã‚„æ—¥æœ¬ç‰¹æœ‰ã®é¢¨æ™¯ãªã©ã‚’ã†ã¾ãæ‰±ãˆã‚‹ã‚ˆã†ã«ã€ã“ã‚Œã‚‰ã‚’å¤šãæ´»ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ï¼ˆå†…è£½æ—¥æœ¬èªOCRãƒ‡ãƒ¼ã‚¿ã€å›³è¡¨ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’ç”¨ã„ã¦ã€Vision Encoderã¨Projectorã‚’å­¦ç¿’ã€‚æœ€å¾Œã«LLMã®Alignmentã‚’ã¨ã‚‹ãŸã‚ã«ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚¿ãƒ¼ã¨LLMã‚’å‰æ®µã®ãƒ‡ãƒ¼ã‚¿ã«åŠ ãˆã¦VQAãƒ‡ãƒ¼ã‚¿ï¼ˆå†…è£½åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ï¼‰ã‚„æ—¥æœ¬èªã®æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦å­¦ç¿’ã€‚</p>
<p>Projectorã‚„MMLLMã‚’å…·ä½“çš„ã«ã©ã®ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ã‹ã¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1225" target="_blank" rel="noopener noreferrer">MM-LLMs: Recent Advances in MultiModal Large Language Models, Duzhen Zhang+, N/A, ACL'24 Findings</a>
<br><br>ã‚’å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-03-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1803" target="_blank" rel="noopener noreferrer" class="title-link">LLM é–‹ç™ºã‚’æ”¯ãˆã‚‹å¤šæ§˜ãª Fine-Tuningï¼šPFN ã§ã®å–ã‚Šçµ„ã¿, ä¸­é‰¢é­ä¸‰éƒ, PFN, 2025.03</a>
<span class="snippet"><span>Comment</span><p>çŸ¥è­˜ã®è¿½åŠ ã®éƒ¨åˆ†ã§ä¸‹è¨˜ç ”ç©¶ãŒå¼•ç”¨ã•ã‚Œã¦ã„ã‚‹<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1371" target="_blank" rel="noopener noreferrer">Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?, Zorik Gekhman+, N/A, EMNLP'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1640" target="_blank" rel="noopener noreferrer">LoRA Learns Less and Forgets Less, Dan Biderman+, TMLR'24</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2025-03-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1797" target="_blank" rel="noopener noreferrer" class="title-link">OLMo 2 32B: First fully open model to outperform GPT 3.5 and GPT 4o mini, AllenAI, 20250.3</a>
<span class="snippet"><span>Comment</span><p>çœŸãªã‚‹å®Œå…¨ãªã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ï¼ˆã«è¿‘ã„ï¼Ÿï¼‰OLMOã®æœ€æ–°ä½œ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-03-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1796" target="_blank" rel="noopener noreferrer" class="title-link">AI_Agent_ã®ä½œã‚Šæ–¹_è¿‘è—¤æ†²å…, Kenji KONDO, 2025.03</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<span class="issue_date">Issue Date: 2025-03-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1794" target="_blank" rel="noopener noreferrer" class="title-link">OpenAI API ã§ã® Computer use ã®ä½¿ã„æ–¹, npaka, 2025.03</a>
<span class="snippet"><span>Comment</span><p>OpenAIã®Compute UseãŒã©ã®ã‚ˆã†ãªã‚‚ã®ã‹ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«ã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚å‹‰å¼·ã«ãªã‚Šã¾ã—ãŸã€‚</p>
<p>å…¬å¼:


<a href="https://platform.openai.com/docs/guides/tools-computer-use" target="_blank" rel="noopener noreferrer">https://platform.openai.com/docs/guides/tools-computer-use</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-03-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1792" target="_blank" rel="noopener noreferrer" class="title-link">Open-source DeepResearch â€“ Freeing our search agents, HuggingFace, 2025.02</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1791" target="_blank" rel="noopener noreferrer" class="title-link">Introducing Gemma 3: The most capable model you can run on a single GPU or TPU, Google, 2025.03</a>
<span class="snippet"><span>Comment</span><p>Googleã®æ–°ãŸãªSLMã§ã€ãƒ‡ãƒã‚¤ã‚¹ã‚„ãƒ©ãƒƒãƒ—ãƒˆãƒƒãƒ—ã§ã‚‚å‹•ä½œå¯èƒ½ãªè»½é‡ãƒ¢ãƒ‡ãƒ«ã€‚ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã§ãªãç”»åƒã¨ShortVideoã®èªè­˜ã‚‚ã§ãã¦ã€140è¨€èªã‚’ã‚µãƒãƒ¼ãƒˆã€‚ãŠã¾ã‘ã«27Bãƒ¢ãƒ‡ãƒ«ã§Llama3-405Bã¨DeepSeek-V3ã¨o3-miniã‚’ChatbotArenaã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã§ä¸Šå›ã‚Šã€128kã®context windowã€‚ãˆã‡â€¦ã€‚</p>
<p>ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°:


<a href="https://huggingface.co/blog/gemma3" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/gemma3</a>


<br><br>1Bãƒ¢ãƒ‡ãƒ«ã¯è‹±èªã®ã¿ã‚µãƒãƒ¼ãƒˆã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ä¸å¯ãªã©åˆ¶ç´„ãŒã‚ã‚‹æ¨¡æ§˜ã€‚<br>è©³ç´°ã¾ã§ã¯æ›¸ã„ã¦ã„ãªã„ãŒã€128Kã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¾ã§context windowã‚’åºƒã’ã‚‹éš›ã®æ¦‚è¦ã¨RoPEï¼ˆã®ã‚ˆã†ãªï¼‰Positional Embeddingã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã€SlideingWindow Attentionã‚’ç”¨ã„ã¦ãŠã‚Šã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºãŒä»¥å‰ã®4096ã‹ã‚‰æ€§èƒ½ã‚’ç¶­æŒã—ãŸã¾ã¾1024ã«å°ã•ãã§ããŸã“ã¨ã€ImageEncoderã¨ã—ã¦ä½•ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã‹ï¼ˆSigLIPï¼‰ã€896x896ã®ç”»åƒã‚µã‚¤ã‚ºã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€æ­£æ–¹å½¢ã®ç”»åƒã¯ã“ã®ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚ºã•ã‚Œã€æ­£æ–¹å½¢ã§ãªã„å ´åˆã¯cropã•ã‚ŒãŸä¸Šã§ãƒªã‚µã‚¤ã‚ºã•ã‚Œã‚‹ï¼ˆpan and scanã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨å‘¼ã¶ã‚‰ã—ã„ï¼‰ã“ã¨ã€äº‹å‰å­¦ç¿’æ™‚ã®ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’2å€ã«ã—ãŸã“ã¨ãªã©ã€è‰²ã€…æ›¸ã„ã¦ã‚ã‚‹æ¨¡æ§˜ã€‚</p>
<p>Gemmaãƒ©ã‚¤ã‚»ãƒ³ã‚¹</p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1899965039559532585?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1900214135847039316?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1790" target="_blank" rel="noopener noreferrer" class="title-link">Reasoning with Reka Flash, Reka, 2025.03</a>
<span class="snippet"><span>Comment</span><p>Weights: 


<a href="https://huggingface.co/RekaAI/reka-flash-3" target="_blank" rel="noopener noreferrer">https://huggingface.co/RekaAI/reka-flash-3</a>


</p>
<p>Apache-2.0</p>
<p>&lt; /reasoning &gt;ã‚’å¼·åˆ¶çš„ã«outputã•ã›ã‚‹ã“ã¨ã§reasoningã‚’ä¸­æ–­ã•ã›ã‚‹ã“ã¨ãŒã§ãäºˆç®—ã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãŒå¯èƒ½ã¨ã®ã“ã¨</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2025-03-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1788" target="_blank" rel="noopener noreferrer" class="title-link">The State of LLM Reasoning Models, Sebastian Raschka, 2025.03</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1786" target="_blank" rel="noopener noreferrer" class="title-link">QwQ-32B: Embracing the Power of Reinforcement Learning, Qwen Team, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1897426898642460724?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1787" target="_blank" rel="noopener noreferrer">START: Self-taught Reasoner with Tools, Chengpeng Li+, arXiv'25</a>
</p>
<p>Artificial Analysisã«ã‚ˆã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1897701015803380112?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãŠãã‚‰ãç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã§DeepSeekR1ã¨comparable, ä»–ã‚¿ã‚¹ã‚¯ã§ã¯åŠã°ãªã„ã€ã¨ã„ã†æ„Ÿã˜ã«ãªã‚Šãã†ãªäºˆæ„Ÿ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-03-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1784" target="_blank" rel="noopener noreferrer" class="title-link">smolagents, HuggingFace, 2025.03</a>
<span class="snippet"><span>GPT Summary</span>- smolagentsã¯ã€æ•°è¡Œã®ã‚³ãƒ¼ãƒ‰ã§å¼·åŠ›ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã§ãã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ­ã‚¸ãƒƒã‚¯ã€ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚µãƒãƒ¼ãƒˆã€å®‰å…¨ãªå®Ÿè¡Œç’°å¢ƒã€ãƒãƒ–çµ±åˆã€ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«ä¾å­˜ã—ãªã„è¨­è¨ˆãŒç‰¹å¾´ã€‚ãƒ†ã‚­ã‚¹ãƒˆã€è¦–è¦šã€å‹•ç”»ã€éŸ³å£°å…¥åŠ›ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€ã•ã¾ã–ã¾ãªãƒ„ãƒ¼ãƒ«ã¨çµ±åˆå¯èƒ½ã€‚è©³ç´°ã¯ãƒ­ãƒ¼ãƒ³ãƒãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’å‚ç…§ã€‚</span>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-03-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1783" target="_blank" rel="noopener noreferrer" class="title-link">GRPO Judge Experiments: Findings &amp; Empirical Observations, kalomaze's kalomazing blog, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_forget-basic-math-problems-grpo-can-do-more-activity-7302608410875691009-nntf?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_forget-basic-math-problems-grpo-can-do-more-activity-7302608410875691009-nntf?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4</a>


</p>
<p>ä¸€æ„ã«è§£ãŒæ±ºã¾ã‚‹å•é¡Œã§ã¯ãªãã€ã‚ã‚‹ç¨‹åº¦ã®ä¸»è¦³çš„ãªåˆ¤æ–­ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦ã®GRPOã®åˆ†æã€‚<br>2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¯”è¼ƒã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã€ä¸€æ–¹ã®ã‚¿ã‚¹ã‚¯ã¯LLMã«ã‚ˆã£ã¦æ‘‚å‹•ã‚’ä¸ãˆã¦ã„ã‚‹ï¼ˆãŠãã‚‰ãæ„å›³çš„ã«corruptã•ã›ã¦ã„ã‚‹ï¼‰ã€‚<br><br>GRPOã§ã¯linearã‚„cosineã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã¯ã†ã¾ãæ©Ÿèƒ½ã›ãšã€warmupãƒ•ã‚§ãƒ¼ã‚ºæœ‰ã‚Šã®å°ã•ã‚ã®å®šæ•°ãŒæœ‰åŠ¹ã‚‰ã—ã„ã€‚ã¾ãŸã€max_grad_normã‚’0.2ã«ã—ã¾gradient clippingãŒæœ‰åŠ¹ã¨ã®ã“ã¨ã€‚</p>
<p>ä»–ã«ã‚‚rewardã®ä¸ãˆæ–¹ã‚’x^4ã«ã™ã‚‹ã“ã¨ã‚„ã€length, xmlãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å ´åˆã«ãƒœãƒ¼ãƒŠã‚¹ã®rewardã‚’ä¸ãˆã‚‹ãªã©ã®å·¥å¤«ã‚’è€ƒå¯Ÿã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1781" target="_blank" rel="noopener noreferrer" class="title-link">microsoft_Phi-4-multimodal-instruct, Microsoft, 2025.02</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/vaibhavs10_holy-shitt-microsoft-dropped-an-open-source-activity-7300755229635944449-mQP8?utm_medium=ios_app&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4&utm_source=social_share_send&utm_campaign=copy_link" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/vaibhavs10_holy-shitt-microsoft-dropped-an-open-source-activity-7300755229635944449-mQP8?utm_medium=ios_app&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4&utm_source=social_share_send&utm_campaign=copy_link</a>


</p>
<p>MIT License</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2025-03-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1780" target="_blank" rel="noopener noreferrer" class="title-link">The Ultra-Scale Playbook: Training LLMs on GPU Clusters, HuggingFace, 2025.02</a>
<span class="snippet"><span>Comment</span><p>HuggingFaceã«ã‚ˆã‚‹æ•°1000ã®GPUã‚’ç”¨ã„ãŸAIãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«é–¢ã™ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1778" target="_blank" rel="noopener noreferrer" class="title-link">Open Reasoner Zero, Open-Reasoner-Zero, 2024.02</a>
<span class="snippet"><span>GPT Summary</span>- Open-Reasoner-Zeroã¯ã€æ¨è«–æŒ‡å‘ã®å¼·åŒ–å­¦ç¿’ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å®Ÿè£…ã§ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨ã‚¢ã‚¯ã‚»ã‚¹ã®ã—ã‚„ã™ã•ã«é‡ç‚¹ã‚’ç½®ã„ã¦ã„ã¾ã™ã€‚AGIç ”ç©¶ã®ä¿ƒé€²ã‚’ç›®æŒ‡ã—ã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1893698293965725708?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-03-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1777" target="_blank" rel="noopener noreferrer" class="title-link">Introducing the SWE-Lancer benchmark, OpenAI, 2025.02</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1893698290174108113?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>1400ä»¥ä¸Šã®ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã‚’é›†ã‚ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚ã‚¿ã‚¹ã‚¯ã¯ãƒã‚°ä¿®æ­£ã‹ã‚‰æ©Ÿèƒ½å®Ÿè£…ã¾ã§å¤šå²ã«ã‚ãŸã‚Šã€çµŒé¨“è±Šå¯Œãªã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ã‚ˆã£ã¦è©•ä¾¡ã•ã‚ŒãŸã‚‚ã®ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-02-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1769" target="_blank" rel="noopener noreferrer" class="title-link">å¼·åŒ–å­¦ç¿’ã€ŒGRPOã€ã‚’CartPoleã‚¿ã‚¹ã‚¯ã§å®Ÿè£…ã—ãªãŒã‚‰è§£èª¬, å°å·é›„å¤ªéƒ, 2025.02</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ogawa_yutaro_22/status/1892059174789407213?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-02-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1766" target="_blank" rel="noopener noreferrer" class="title-link">Mistral-24B-Reasoning, yentinglin, 2025.02</a>
<span class="snippet"><span>Comment</span><p>Apache-2.0</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1762" target="_blank" rel="noopener noreferrer" class="title-link">LLMã®äº‹å‰å­¦ç¿’ã®ãŸã‚ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åé›†ã¨æ§‹ç¯‰, Shun Kiyono, 2015.02</a>
<span class="snippet"><span>Comment</span><p>è©³ç´°ã¯è‘—æ›¸ã«è¨˜è¼‰ã¨ã®ã“ã¨ã€‚èˆˆå‘³æ·±ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1761" target="_blank" rel="noopener noreferrer" class="title-link">modernbert-ja-130m, SB Intuitions, 2025.02</a>
<span class="snippet"><span>Comment</span><p>ï¼­IT Licence</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sbintuitions/status/1889587801706078580?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1606" target="_blank" rel="noopener noreferrer">ModernBERT, AnswerDotAI, 2024.12</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1759" target="_blank" rel="noopener noreferrer" class="title-link">Docling, DS4SD, 2024.07</a>
<span class="snippet"><span>Comment</span><p>Unstructuredã¨ã©ã¡ã‚‰ãŒè‰¯ã„ã ã‚ã†ã‹ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1757" target="_blank" rel="noopener noreferrer" class="title-link">DeepScaleR: Surpassing O1-Preview with a 1.5B Model by Scaling RL, 2025.02</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1755" target="_blank" rel="noopener noreferrer" class="title-link">SGlang, sgl-project, 2024.01</a>
<span class="snippet"><span>GPT Summary</span>- SGLangã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¨è¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®é«˜é€Ÿã‚µãƒ¼ãƒ“ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®å…±åŒè¨­è¨ˆã«ã‚ˆã‚Šè¿…é€Ÿãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ä¸»ãªæ©Ÿèƒ½ã«ã¯ã€é«˜é€Ÿãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã€æŸ”è»Ÿãªãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¨€èªã€åºƒç¯„ãªãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒ¼ãƒˆãŒã‚ã‚Šã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®æ´»ç™ºãªã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«æ”¯ãˆã‚‰ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1733" target="_blank" rel="noopener noreferrer">Open R1, HuggingFace, 2025.01</a>
<br><br>ã®Update2ã§Math Datasetã®ç”Ÿæˆã«åˆ©ç”¨ã•ã‚ŒãŸLLM Servingãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚åˆ©ç”¨å‰ã¨æ¯”è¼ƒã—ã¦ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãŒ2å€ã«ãªã£ãŸã¨ã®ã“ã¨ã€‚</p>
<p>CPU, external storageã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§TTFTã‚’æ”¹å–„ã™ã‚‹ã‚ˆã†ã«ãªã£ãŸã‚ˆã†ã§ã€æœ€å¤§80%TTFTãŒå‰Šæ¸›ã•ã‚Œã‚‹ã¨ã®è¨˜è¿°ãŒã‚ã‚‹ã€‚<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lm_zheng/status/1966312698100203994?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ï¼ˆåŸç†çš„ã«ã¯å…ƒæ¥å¯èƒ½ã ãŒè¨ˆç®—åŠ¹ç‡ã®æœ€é©åŒ–ã«åŸºã¥ãèª¤å·®ã«ã‚ˆã£ã¦å®Ÿè£…ä¸Šã®å•é¡Œã§å®Ÿç¾ã§ãã¦ã„ãªã‹ã£ãŸ) Deterministic Inferenceã‚’ã‚µãƒãƒ¼ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ying11231/status/1970250780394569819?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-02-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1747" target="_blank" rel="noopener noreferrer" class="title-link">Unsloth ã§ç‹¬è‡ªã® R1 Reasoningãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’, npaka, 2025.02</a>
<span class="snippet"><span>Comment</span><p>éå¸¸ã«å®Ÿç”¨çš„ã§å‚è€ƒã«ãªã‚‹ã€‚ç‰¹ã«ã©ã®ç¨‹åº¦ã®VRAMã§ã©ã®ç¨‹åº¦ã®è¦æ¨¡æ„Ÿã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã‚‹ã®ã‹ãŒæ˜è¨€ã•ã‚Œã¦ã„ã¦å‚è€ƒã«ãªã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-02-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1743" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-R1ã®è«–æ–‡èª­ã‚“ã ï¼Ÿã€å‹‰å¼·ã«ãªã‚‹ã‚ˆã€‘ , asap, 2025.01</a>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1655" target="_blank" rel="noopener noreferrer">DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open
  Language Models, Zhihong Shao+, arXiv'24</a>
</p>
<p>ã¨ã¦ã‚‚ä¸å¯§ã§ã‚ã‹ã‚Šã‚„ã™ã‹ã£ãŸã€‚å¾Œã§èª­ã‚“ã å†…å®¹ã‚’æ›¸ã„ã¦å¾©ç¿’ã™ã‚‹ã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-01-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1737" target="_blank" rel="noopener noreferrer" class="title-link">Janus-Series: Unified Multimodal Understanding and Generation Models, DeepSeek, 2025.01</a>
<span class="snippet"><span>Comment</span><p>DeepSeekã«ã‚ˆã‚‹æ–°ãŸãªUMMã€Janus-ProãŒæœ¬æ—¥ãƒªãƒªãƒ¼ã‚¹ã€‚MIT License</p>
<p>Janus-Proã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€‚<br><br>githubä¸Šã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å›³è§£ã‹ã‚‰å¼•ç”¨ã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ï¼ˆãƒ†ã‚­ã‚¹ãƒˆ+ç”»åƒï¼‰ã®ç†è§£ã«é–¢ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§LLaVAè¶…ãˆã€‚GenEval, DPG Benchã¨å‘¼ã°ã‚Œã‚‹ç”»åƒç”Ÿæˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§DALL-E 3è¶…ãˆã€‚<br><img src="https://github.com/user-attachments/assets/39b51e99-723d-4105-a113-e4bfa847c69b" alt="image" loading="lazy"><br><br><br>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆä¸­ã§ã®è©³ç´°ã‹ã‚‰å¼•ç”¨ã€‚ã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚‚åŸºæœ¬çš„ã«æœ€é«˜æ€§èƒ½ãªã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/4c1bd071-966f-4d51-99f4-e60fa2f36b0a" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/a0b22d6e-debb-420a-bf8d-fe8833583d09" alt="image" loading="lazy"><br><br>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ: 


<a href="https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf</a>


</p>
<p>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2769" target="_blank" rel="noopener noreferrer">[Paper Note] GenEval: An Object-Focused Framework for Evaluating Text-to-Image   Alignment, Dhruba Ghosh+, NeurIPS'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2770" target="_blank" rel="noopener noreferrer">[Paper Note] ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment, Xiwei Hu+, arXiv'24</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2025-01-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1733" target="_blank" rel="noopener noreferrer" class="title-link">Open R1, HuggingFace, 2025.01</a>
<span class="snippet"><span>Comment</span><p>HFã«ã‚ˆã‚‹DeepSeekR1ã‚’å®Œå…¨ã«å†ç¾ã™ã‚‹å–ã‚Šçµ„ã¿</p>
<p>Update1: 


<a href="https://huggingface.co/blog/open-r1/update-1" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/open-r1/update-1</a>


</p>
<p>Update2: 


<a href="https://huggingface.co/blog/open-r1/update-2" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/open-r1/update-2</a>


<br><br>512æ©Ÿã®H100ã‚’åˆ©ç”¨â€¦</p>
<p>Update3:


<a href="https://huggingface.co/blog/open-r1/update-3" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/open-r1/update-3</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1727" target="_blank" rel="noopener noreferrer" class="title-link">LLM Datasets, mlabonne, 2025.01</a>
<span class="snippet"><span>Comment</span><p>LLMã®äº‹å¾Œå­¦ç¿’ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã¾ã¨ã‚ãŸãƒªãƒã‚¸ãƒˆãƒª</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1726" target="_blank" rel="noopener noreferrer" class="title-link">Llama Stack, Meta, 2024.11</a>
<span class="snippet"><span>Comment</span><p>Llamaã‚’ç”¨ã„ãŸLLM Agentã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚Quick Startã§ã¯RAG Agentã‚’æ§‹ç¯‰ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1725" target="_blank" rel="noopener noreferrer" class="title-link">distilabel, 2023.11</a>
<span class="snippet"><span>Comment</span><p>é«˜å“è³ªãªåˆæˆãƒ‡ãƒ¼ã‚¿ã‚’LLMã§ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1723" target="_blank" rel="noopener noreferrer" class="title-link">How to fine-tune open LLMs in 2025 with Hugging Face, PHILSCHMID, 2024.12</a>
<span class="snippet"><span>Comment</span><p>SFTTrainerã‚’ç”¨ã„ãŸLLMã®SFTã«ã¤ã„ã¦ã€å®Ÿç”¨çš„ã€ã‹ã¤åŸºç¤çš„ãªå†…å®¹ãŒã‚³ãƒ¼ãƒ‰ä»˜ãã§ã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1722" target="_blank" rel="noopener noreferrer" class="title-link">How to align open LLMs in 2025 with DPO &amp; and synthetic data, PHILSCHMID, 2025.01</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1882428447877705908?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- DPOã®æ¦‚è¦ã‚„RLHFã¨æ¯”è¼ƒã—ãŸåˆ©ç‚¹<br>- ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã€ã‚ã‚‹ã„ã¯LLM as a Judgeã‚’ç”¨ã„ãŸOn-policy preference pairï¼ˆç¾åœ¨ã®SFTã—ãŸãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‹ã‚‰ç”Ÿæˆã—ãŸpreference dataï¼‰ã®ä½œã‚Šæ–¹ã¨ãã®åˆ©ç‚¹ï¼ˆç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã®output distributionã‚’åæ˜ ã—ã¦ã„ã‚‹ã®ã§å­¦ç¿’ãŒåŠ¹ç‡åŒ–ã•ã‚Œã‚‹ï¼‰<br>- ç’°å¢ƒæ§‹ç¯‰æ–¹æ³•<br>- DPOTrainer/TRLParserã®ä½¿ã„æ–¹/DPODatasetã®ä½œã‚Šæ–¹<br>- DPOã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Î²ã®æ„å‘³åˆã„<br>- DPOã§ã¯SFTã¨æ¯”ã¹ã¦10-100xå°ã•ã„å­¦ç¿’ç‡ã‚’ä½¿ã†å¿…è¦ãŒã‚ã‚‹ã“ã¨<br>- Evaluation Harnessã‚’ç”¨ã„ãŸè©•ä¾¡æ–¹æ³•<br>- TGIã‚’ç”¨ã„ãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã¨ãƒ†ã‚¹ãƒˆ<br><br>ãªã©ãŒä¸å¯§ãªã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã¨æ³¨é‡ˆã€referenceä»˜ãã§èª¬æ˜ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/StructuredData.html" target="_blank" rel="noopener noreferrer">#StructuredData</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1721" target="_blank" rel="noopener noreferrer" class="title-link">Structured Outputs OpenAI Platform, 2025.01</a>
<span class="snippet"><span>Comment</span><p>pydanticã‚’ç”¨ã„ã¦ã€CoTï¼‹æ§‹é€ åŒ–ã•ã‚ŒãŸoutputã‚’å®Ÿæ–½ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-01-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1720" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-R1-Distill-Qwen, DeepSeek, 2025.01</a>
<span class="snippet"><span>Comment</span><p>MIT Licence</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-01-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-R1, DeepSeek, 2025.01</a>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/icoxfog417/status/1883339727446974616?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å‚è€ƒ:


<a href="https://horomary.hatenablog.com/entry/2025/01/26/204545" target="_blank" rel="noopener noreferrer">https://horomary.hatenablog.com/entry/2025/01/26/204545</a>


</p>
<p>DeepSeek-R1ã®è«–æ–‡èª­ã‚“ã ï¼Ÿã€å‹‰å¼·ã«ãªã‚‹ã‚ˆã€‘<br>, asap:


<a href="https://zenn.dev/asap/articles/34237ad87f8511" target="_blank" rel="noopener noreferrer">https://zenn.dev/asap/articles/34237ad87f8511</a>


</p>
<p>ã“ã¡ã‚‰ã®ãƒã‚¹ãƒˆã®å›³è§£ãŒã‚ã‹ã‚Šã‚„ã™ã„:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/1littlecoder/status/1887134619603968439?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æœ€æ–°ãƒ¢ãƒ‡ãƒ«: DeepSeek-R1-0528<br>


<a href="https://huggingface.co/deepseek-ai/DeepSeek-R1-0528" target="_blank" rel="noopener noreferrer">https://huggingface.co/deepseek-ai/DeepSeek-R1-0528</a>


<br><br><img src="https://github.com/user-attachments/assets/c2d7e967-1677-4791-81ad-2a7d050da593" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2025-01-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1718" target="_blank" rel="noopener noreferrer" class="title-link">tokyotech-llm_swallow-magpie-ultra-v0.1, tokyotech-llm, 2025.01</a>
<span class="snippet"><span>Comment</span><p>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1876634359400370252?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-01-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1663" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-V2ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å¾¹åº•è§£èª¬ï¼šMLA ã¨ DeepSeekMoE, kernelian, 2024.05</a>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1665" target="_blank" rel="noopener noreferrer">DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models, Damai+, ACL'24, 2024.08</a>
<br><br>ã‚‚å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-01-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1662" target="_blank" rel="noopener noreferrer" class="title-link">Killed by LLM, R0bk</a>
<span class="snippet"><span>Comment</span><p>Saturationã¨ãªã£ã¦ã„ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã€æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ã™ã§ã«æ¸¬å®šã§ããªããªã£ã¦ã—ã¾ã£ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-01-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1660" target="_blank" rel="noopener noreferrer" class="title-link">AI Agents 2024 Rewind - A Year of Building and Learning, VICTOR DIBIA, 2025.01</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-01-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1659" target="_blank" rel="noopener noreferrer" class="title-link">AI Agent Era,  ç¦å³¶è‰¯å…¸ | LayerX, 2024.12</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-01-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1658" target="_blank" rel="noopener noreferrer" class="title-link">LLMãŒã‚ªãƒ¯ã‚³ãƒ³åŒ–ã—ãŸ2024å¹´, ã‚‰ã‚“ã¶ã‚‹, 2025.01</a>
<span class="snippet"><span>Comment</span><p>LLMã‚’ï¼ˆå‘¼ã³å‡ºã™|å‘¼ã³å‡ºã•ã‚Œã‚‹ï¼‰SaaSä¼æ¥­ãŒä»Šå¾Œã©ã®ã‚ˆã†ãªæˆ¦ç•¥ã§å‹•ã„ã¦ã„ãã‹ãŒè€ƒå¯Ÿã•ã‚Œã¦ãŠã‚Šèˆˆå‘³æ·±ã‹ã£ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/API.html" target="_blank" rel="noopener noreferrer">#API</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1651" target="_blank" rel="noopener noreferrer" class="title-link">LiteLLM, BerriAI, 2023.08</a>
<span class="snippet"><span>Comment</span><p>æ§˜ã€…ãªLLMã®APIã‚’å…±é€šã®ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ã§å‘¼ã³å‡ºã›ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª<br><br></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1553" target="_blank" rel="noopener noreferrer">aisuite, andrewyng, 2024.11</a>
 <br><br><br><br>ã¨ã©ã¡ã‚‰ãŒã„ã„ã‚“ã ãƒ»ãƒ»ãƒ»ï¼Ÿ</p>
<p>aisuiteã®issueã®113ç•ªã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’è¦‹ã‚‹ã¨ã€<br><br>- LiteLLMã¯ã‚‚ã¯ã‚„Liteã§ã¯ãªããªã£ã¦ãŠã‚Šã€ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ä¿å®ˆæ€§ãŒä½ã„<br><br>- aisuiteã¯è¤‡æ•°ã®LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã‚’æä¾›ã™ã‚‹<br><br>- ä»Šå¾Œç™ºè¡¨ã•ã‚Œã‚‹ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’è¦‹ã‚Œã°ã€LiteLLMã¨ã®å·®åˆ¥åŒ–ã®æ–¹å‘æ€§ãŒåˆ†ã‹ã‚‹ã¯ãšã <br><br><br><br>ã¨ã„ã£ãŸè¶£æ—¨ã®ã“ã¨ãŒè¨˜è¿°ã•ã‚Œã¦ã„ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1635" target="_blank" rel="noopener noreferrer" class="title-link">To fine-tune or not to fine-tune, Meta, 2024.08</a>
<span class="snippet"><span>Comment</span><p>LLMã‚’SFTã™ã‚‹éš›ã®æ³¨æ„ç‚¹ã‚„ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«ã¤ã„ã¦è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>- full parameterã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„PEFTæ‰‹æ³•ã®ãƒ”ãƒ¼ã‚¯GPUãƒ¡ãƒ¢ãƒª<br>- full parameterã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã¯catastrophic forgettingã«æ°—ã‚’ã¤ã‘ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨<br>- FinetuningãŒæœ‰ç”¨ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã¨ã—ã¦ä»¥ä¸‹ãŒæŒ™ã’ã‚‰ã‚Œã¦ã„ã‚‹<br>  - ãƒˆãƒ¼ãƒ³ã€ã‚¹ã‚¿ã‚¤ãƒ«ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚¶ãƒ¼ã‚·ãƒ§ãƒ³<br>  - prompt engineeringã‚„ICLã§é”æˆã™ã‚‹ã«ã¯å›°é›£ãªAccuracyã®å‘ä¸Šã‚„ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã¸ã®å¯¾å¿œ<br>  - ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œ<br>  - ã‚ˆã‚Šå¤§ãã„ãƒ¢ãƒ‡ãƒ«ã‚’è’¸ç•™ã™ã‚‹ã“ã¨ã«ã‚ˆã‚‹ã‚³ã‚¹ãƒˆå‰Šæ¸›<br>  - æ–°ãŸãªã‚¿ã‚¹ã‚¯ã¸ã®é©å¿œã‚„èƒ½åŠ›ã®ç²å¾— </p>
<p>ã¾ãŸã€RAGã¨Finetuningã©ã¡ã‚‰ã‚’é¸æŠã™ã¹ãã‹ã«é–¢ã™ã‚‹è©±é¡Œã‚‚è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ï¼ˆãŒã€å¤šãã®å ´åˆã¯ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒãƒ™ã‚¹ãƒˆã ã€ã¨ã„ã£ãŸè©±ã‚‚æ›¸ã„ã¦ã‚ã‚‹ï¼‰ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1633" target="_blank" rel="noopener noreferrer" class="title-link">2024-ai-timeline, reach-vb, 2025.01</a>
<span class="snippet"><span>Comment</span><p>æœˆåˆ¥ã§2024å¹´ã«ãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸä¸»è¦ãªLLMï¼ˆãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªLLMã‚‚å«ã‚€ï¼‰ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚<br>API Onlyï¼ˆãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªï¼‰ãªã®ã‹ã€OpenWeightãªã®ã‹ã‚‚ã‚¿ã‚°ä»˜ã‘ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-12-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1623" target="_blank" rel="noopener noreferrer" class="title-link">Preferred Generation Benchmark, pfnet-research, 2024.12</a>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bilzrd/status/1873167934564311133?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¥æœ¬èªãƒ—ãƒ¬ãƒ—ãƒªãƒ³ãƒˆ:


<a href="https://jxiv.jst.go.jp/index.php/jxiv/preprint/view/1008" target="_blank" rel="noopener noreferrer">https://jxiv.jst.go.jp/index.php/jxiv/preprint/view/1008</a>


</p>
<p>arXivã¯ã“ã‚Œã‹ã‚‰ã£ã½ã„</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1621" target="_blank" rel="noopener noreferrer" class="title-link">MHA vs MQA vs GQA vs MLA, Zain ul Abideen, 2024.07</a>
<span class="snippet"><span>Comment</span><p>DeepSeekã§ä½¿ã‚ã‚Œã¦ã„ã‚‹Multi Head Latent Attentionï¼ˆMLAï¼‰ã£ã¦ãªã‚“ã ï¼Ÿã¨æ€ã„èª­ã‚“ã ã€‚ç«¯çš„ã«è¨€ã†ã¨ã€GQAã‚„MQAã¯ã€KVã®ãƒ˜ãƒƒãƒ‰ã‚’ãã‚‚ãã‚‚æ¸›ã‚‰ã—ã¦KV Cacheã‚’æŠ‘ãˆã‚ˆã†ã€ã¨ã„ã†æ‰‹æ³•ã ã£ãŸãŒã€MLAã¯KVã‚’ä½ãƒ©ãƒ³ã‚¯ãªãƒ™ã‚¯ãƒˆãƒ«ã«åœ§ç¸®ã—ã¦ä¿æŒã—ã€ä½¿ã†æ™‚ã«å¾©å…ƒã™ã‚‹ã¨ã„ã£ãŸæ“ä½œã‚’ã™ã‚‹ã“ã¨ã§ã€MHAã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è½ã¨ã™ã“ã¨ãªãï¼ˆã‚€ã—ã‚ä¸ŠãŒã‚‹ã‚‰ã—ã„ï¼Ÿï¼‰ã€åˆ©ç”¨ã™ã‚‹KV Cacheã§åˆ©ç”¨ã™ã‚‹ãƒ¡ãƒ¢ãƒªã‚’å¤§å¹…ã«æ¸›ã‚‰ã›ã‚‹ã¨ã„ã†æ‰‹æ³•ã‚‰ã—ã„ã€‚</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
<br><br>MQA, GQAã®æ¦‚è¦ã«ã¤ã„ã¦ã¯ä¸Šè¨˜å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1620" target="_blank" rel="noopener noreferrer" class="title-link">Deep-seek-v3, deepseek-ai, 2024.12</a>
<span class="snippet"><span>Comment</span><p>å‚è€ƒï¼ˆãƒ¢ãƒ‡ãƒ«ã®å›³è§£ï¼‰:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vtabbott_/status/1874449446056177717?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1876397959841186148?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-12-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1617" target="_blank" rel="noopener noreferrer" class="title-link">LLMã‚’æ•°å­¦ã‚¿ã‚¹ã‚¯ã«ã‚¢ãƒ©ã‚¤ãƒ³ã™ã‚‹æ‰‹æ³•ã®ç³»è­œ - GPT-3ã‹ã‚‰Qwen2.5ã¾ã§, bilzard, 2024.12</a>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1618" target="_blank" rel="noopener noreferrer">Training Verifiers to Solve Math Word Problems, Karl Cobbe+, arXiv'21</a>
<br><br>ã«ãŠã„ã¦ã€æ•°å­¦ã«ãŠã„ã¦ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦æ€§èƒ½æ”¹å–„ãŒè¦‹è¾¼ã‚ã‚‹å­¦ç¿’æ‰‹æ³•ã¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã¨ã¯åˆ¥ã«Verifierã‚’å­¦ç¿’ã—ã€ãƒ¢ãƒ‡ãƒ«ãŒå‡ºåŠ›ã—ãŸå€™è£œã®ä¸­ã‹ã‚‰è‰¯ã„ã‚‚ã®ã‚’é¸æŠã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€ã¨ã„ã†è©±ã®æ°—æŒã¡ãŒæœ€åˆã‚ˆãã‚ã‹ã‚‰ãªã‹ã£ãŸã®ã ãŒã€å¾ŒåŠã®ãªãœsample&amp;selectãŒã†ã¾ãã„ãã®ã‹ï¼Ÿç¯€ã‚’èª­ã‚“ã§ãªã‚“ã¨ãªãæ°—æŒã¡ãŒç†è§£ã§ããŸã€‚SFTã‚’é€²ã‚ã‚‹ã¨ãƒ¢ãƒ‡ãƒ«ãŒå‡ºåŠ›ã™ã‚‹è§£æ”¾ã®å¤šæ§˜æ€§ãŒæ¸›ã£ã¦ã„ãã¨ã„ã†ã®ã¯ã€èˆˆå‘³æ·±ã‹ã£ãŸã€‚<br><br>ã—ã‹ã—ã€ç‰¹å®šã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ãŸæ™‚ã«ã€å…¨ãç•°ãªã‚‹Unseenãªãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã‚‚è§£æ³•ã¯æ¸›ã£ã¦ã„ãã®ã ã‚ã†ã‹ï¼Ÿã¨ã„ã†ç‚¹ãŒæ°—ã«ãªã£ãŸã€‚ã‚ã¨ã¯ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ã‚’ã‚ã¡ã‚ƒã‚ã¡ã‚ƒå¢—ã‚„ã—ãŸã‚‰ã©ã†ãªã‚‹ã®ã‹ï¼Ÿã¨ã„ã†ã®ã‚‚æ°—ã«ãªã‚‹ã€‚ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å®Œå…¨ã«æ”»ç•¥ã§ãã‚‹ã‚ˆã†ãªè§£æ³•ã‚’å‡ºåŠ›ã—ã‚„ã™ããªã‚‹ã¨ã€ä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ€§èƒ½ãŒæ‚ªããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹æ°—ãŒã—ã¦ãŠã‚Šã€ãã†ã™ã‚‹ã¨ãã‚‚ãã‚‚ã®1shotã®æ€§èƒ½è‡ªä½“ã‚‚æ”¹å–„ã—ã¦ã„ã‹ãªããªã‚Šãã†ã ãŒã€ãã®è¾ºã¯ã©ã†ã„ã†è¨­å®šã§å®Ÿé¨“ã•ã‚Œã¦ã„ã‚‹ã®ã ã‚ã†ã‹ã€‚<br><br>ãŸã¨ãˆã°ã€<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
<br><br>ãªã©ã§ã¯ã€<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1474" target="_blank" rel="noopener noreferrer">Super-NaturalInstructions: Generalization via Declarative Instructions  on 1600+ NLP Tasks, Yizhong Wang+, N/A, EMNLP'22</a>
<br><br>ã®ã‚ˆã†ãª1600ã‚’è¶…ãˆã‚‹ã‚ˆã†ãªNLPã‚¿ã‚¹ã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã§LoRAã«ã‚ˆã‚ŠSFTã™ã‚‹ã¨ã€LoRAã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’éå¸¸ã«å¤§ããã™ã‚‹ã¨Unseenã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ€§èƒ½ãŒfull-parameter tuningã™ã‚‹ã‚ˆã‚Šã‚‚å‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã®ä¾‹ã¯æ•°å­¦ã«ç‰¹åŒ–ã—ãŸä¾‹ã§ã¯ãªã„ãŒã€SFTã«ã‚ˆã£ã¦è§£æ³•ã®å¤šæ§˜æ€§ãŒæ¸›ã‚‹ã“ã¨ã«ã‚ˆã£ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«éå‰°é©åˆã—ã¦æ±åŒ–æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ã€ã¨ã„ã†ã®ã§ã‚ã‚Œã°ã€ã“ã®è«–æ–‡ã®ã“ã¨ã‚’é‘‘ã¿ã‚‹ã¨ã€Œå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«overfittingã—ãŸçµæœä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æ€§èƒ½ãŒä½ä¸‹ã—ã¦ã—ã¾ã†ç¨‹åº¦ã®å¤šæ§˜æ€§ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã—ã‹ä½¿ãˆã¦ã„ãªã„ã®ã§ã¯ã€ã¨æ„Ÿã˜ã¦ã—ã¾ã†ã®ã ãŒã€ãã®è¾ºã¯ã©ã†ãªã‚“ã ã‚ã†ã‹ã€‚å…ƒè«–æ–‡ã‚’èª­ã‚“ã§ç¢ºèªã—ãŸã„ã€‚<br>ã¨ã¦ã‚‚å‹‰å¼·ã«ãªã£ãŸã€‚</p>
<p>è¨˜äº‹ä¸­ã§ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br>&gt; LLMã‚’ä½¿ã£ã¦è¤‡æ•°è§£æ³•ã®å€™è£œã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ãã®ä¸­ã‹ã‚‰æœ€é©ãª1ã¤ã‚’é¸æŠã™ã‚‹<br><br>ã®ãƒ«ãƒ¼ãƒ„ã¯ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1618" target="_blank" rel="noopener noreferrer">Training Verifiers to Solve Math Word Problems, Karl Cobbe+, arXiv'21</a>
 ã¨ã®ã“ã¨ãªã®ã§æ˜¯éèª­ã¿ãŸã„ã€‚<br><br>ã“ã®è¾ºã¯Self-Consistency <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/558" target="_blank" rel="noopener noreferrer">Self-consistency improves chain of thought reasoning in language models, Wang+, Google Research, ICLR'23</a>
 ã‚ãŸã‚ŠãŒæœ€åˆãªã®ã‹ã¨æ€ã£ã¦ã„ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-12-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1615" target="_blank" rel="noopener noreferrer" class="title-link">LLM-as-a-Judge ã‚’ã‚µãƒ¼ãƒ™ã‚¤ã™ã‚‹, Ayako, 2024.12</a>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1616" target="_blank" rel="noopener noreferrer">A Survey on LLM-as-a-Judge, Jiawei Gu+, arXiv'24</a>
<br><br>ã‚’èª­ã‚“ã çµæœã‚’æ—¥æœ¬èªã§ã¾ã¨ã‚ã¦ãã ã•ã£ã¦ã„ã‚‹ã€‚</p>
<p>ãƒ¢ãƒ‡ãƒ«é¸æŠã«ã¤ã„ã¦ã€å¤–éƒ¨APIã«ä¾å­˜ã™ã‚‹ã¨ã‚³ã‚¹ãƒˆã‚„ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã€å†ç¾æ€§ãªã©ã®å•é¡ŒãŒã‚ã‚‹ãŸã‚OpenLLMã‚’Finetuningã™ã‚‹ã“ã¨ã§å¯¾å¿œã—ã¦ã„ã‚‹ã“ã¨ãŒè«–æ–‡ä¸­ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã ãŒã€è©•ä¾¡èƒ½åŠ›ã«ã¯ã¾ã é™ç•ŒãŒã‚ã‚‹ã¨ã®ã“ã¨ã€‚<br><br>è¨˜äº‹ä¸­ã§ã¯Llama, Vicunaãªã©ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹æ—¨ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ãŒã€ã©ã®ç¨‹åº¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã‚’ã©ã‚“ãªãƒ‡ãƒ¼ã‚¿ã§SFTã—ã€ã©ã®ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã‚’è©•ä¾¡ã—ãŸã®ã ã‚ã†ã‹ï¼ˆã‚ã¨ã§å…ƒè«–æ–‡ã‚’è¦‹ã¦ç¢ºèªã—ãŸã„ï¼‰ã€‚<br><br><br><br>ã¾ãŸã€å¾Œå‡¦ç†ã¨ã—ã¦ãƒ«ãƒ¼ãƒ«ãƒãƒƒãƒã§æŠ½å‡ºã™ã‚‹å¿…è¦ã‚ãŒã‚‹ãŒã€ãƒ¢ãƒ‡ãƒ«ã®AlignmentãŒä½ã„ã¨æˆåŠŸç‡ãŒä¸‹ãŒã‚‹ã¨ã®ã“ã¨ã§ã‚ã‚‹ã€‚<br><br>å€‹äººçš„ã«ã¯ã€ã‚¹ã‚³ã‚¢ã‚’ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã™ã‚‹å½¢å¼ã®å ´åˆç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŠ½å‡ºã™ã‚‹æ–¹å¼ã§ã¯ãªãã€G-Eva ã®ã‚ˆã†ã«ã‚¹ã‚³ã‚¢ã¨é–¢é€£ã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆe.g. 1,2,3,4,5ï¼‰ã¨ãã®å°¤åº¦ã®åŠ é‡å¹³å‡ã‚’ã¨ã‚‹ã‚ˆã†ãªæ‰‹æ³•ãŒå¾Œå‡¦ç†ãŒæ¥½ã§è‰¯ã„ã¨æ„Ÿã˜ã‚‹ã€‚<br><br>ICLR2025ã®æŸ»èª­ã«LLM-as-a-JudgeãŒå°å…¥ã•ã‚Œã‚‹ã¨ã„ã†ã®ã¯çŸ¥ã‚‰ãªã‹ã£ãŸã®ã§ã€éå¸¸ã«èˆˆå‘³æ·±ã„ã€‚</p>
<p>LLMãŒå¥½ã‚€å›ç­”ã®ãƒã‚¤ã‚¢ã‚¹ï¼ˆå†—é•·æ€§ã€ä½ç½®ãªã©ï¼‰åˆ¥ã«å„LLMã®ãƒ¡ã‚¿è©•ä¾¡ã‚’ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ã¾ãŸã€æ€§èƒ½ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®æ–½ç­–ã‚’å®Ÿæ–½ã—ãŸå ´åˆã«ã©ã®ç¨‹åº¦ãƒ¡ã‚¿è©•ä¾¡ã§æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã‹ã‚‚è©•ä¾¡ã—ã¦ã„ã‚‹ã€‚ç‰¹ã«èª¬æ˜ã‚’å‡ºåŠ›ã•ã›ã¦ã‚‚åŠ¹æœã¯è–„ãã€ã¾ãŸã€è¤‡æ•°LLMã«ã‚ˆã‚‹æŠ•ç¥¨ã«ã—ã¦ã‚‚ä½ç½®ãƒã‚¤ã‚¢ã‚¹ã®è»½æ¸›ã«å¯„ä¸ã™ã‚‹ç¨‹åº¦ã®æ”¹å–„ã—ã‹ãªã‹ã£ãŸã¨ã®ã“ã¨ã€‚ã¾ãŸã€è¤‡æ•°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®çµæœã®è¦ç´„ã‚’ã•ã›ã‚‹æ–¹æ³•ãŒãƒã‚¤ã‚¢ã‚¹ã®ä½æ¸›ã«å¹…åºƒãå¯„ä¸ã—ãŸã¨ã®ã“ã¨ã€‚</p>
<p>ã†ãƒ¼ã‚“ã€ãƒã‚¤ã‚¢ã‚¹ã‚’ä½æ¸›ã™ã‚‹ã†ã¾ã„æ–¹æ³•ãŒã¾ã ç„¡ã•ãã†ãªã®ãŒãªã‹ãªã‹å³ã—ã„æ„Ÿã˜ãŒã™ã‚‹ã€‚<br>ãã‚‚ãã‚‚æ ¹æœ¬çš„ã«äººé–“ã«äººæ‰‹è©•ä¾¡ã‚’ãŠé¡˜ã„ã™ã‚‹æ™‚ã‚‚ã‚ã¡ã‚ƒã‚ã¡ã‚ƒãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã¨ã‹ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ä½œã‚Šè¾¼ã‚“ã ã‚Šã—ãŸä¸Šã§ã‚‚agreementãŒé«˜ããªã‹ã£ãŸã‚Šã™ã‚‹ã®ã§ã€ã‚„ã¯ã‚Šé›£ã—ãã†ã§ã‚ã‚‹ã€‚<br><br>ãŸã ã€MTBenchã§ã¯äººé–“ã®è©•ä¾¡çµæœã¨LLMã®è©•ä¾¡çµæœã®ç›¸é–¢ï¼ˆagreementã ã£ã‘ã‹â€¦ï¼Ÿï¼‰ãŒé«˜ã‹ã£ãŸã“ã¨ãªã©ãŒå ±å‘Šã•ã‚Œã¦ã„ã‚‹ã—ã€LLMã‚ã‚‹ã‚ã‚‹ã®ã‚¿ã‚¹ã‚¯ã”ã¨ã«å¾—æ„ä¸å¾—æ„ãŒã‚ã‚Šã¾ã™ã€ã¨ã„ã†è©±ãªæ°—ã‚‚ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Video.html" target="_blank" rel="noopener noreferrer">#Video</a>
<span class="issue_date">Issue Date: 2024-12-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1614" target="_blank" rel="noopener noreferrer" class="title-link">Stanford CS229 I Machine Learning I Building Large Language Models ï¼ˆLLMsï¼‰, StanfordUnivercity, 2024.09</a>
<span class="snippet"><span>Comment</span><p>ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦ã«ã‚ˆã‚‹LLMæ§‹ç¯‰ã«é–¢ã™ã‚‹è¬›ç¾©ã€‚äº‹å‰å­¦ç¿’ã¨äº‹å¾Œå­¦ç¿’ä¸¡æ–¹ã¨ã‚‚ã‚«ãƒãƒ¼ã—ã¦ã„ã‚‹ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2024-12-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1613" target="_blank" rel="noopener noreferrer" class="title-link">Qwen2.5 Technical Reportã®ä¸­ã«æ½œã‚‹, AbejaTech Blog, 2024.12</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-12-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1612" target="_blank" rel="noopener noreferrer" class="title-link">OpenAI o3ã¯ï¼Œäººé–“ã¨ã¯å…¨ãç•°è³ªã®æ±ç”¨çŸ¥èƒ½ã§ã‚ã‚‹å±é™ºæ€§ã€æ±å¤§è§£èª¬ã€‘, ç¥æ¥½å‚ã‚„ã¡ã¾, 2024.12</a>
<span class="snippet"><span>Comment</span><p>æ§˜ã€…ãªæœ‰è­˜è€…ã®è¦‹è§£ã‚’ã¾ã¨ã‚ã¤ã¤ã€æ–‡çŒ®ã‚’å¼•ç”¨ã—ã¤ã¤ã€ã‹ã¤æœ€çµ‚çš„ã«ã€Œäººé–“ãŒçŸ¥èƒ½ã¨ã„ã†ã‚‚ã®ã«å¯¾ã—ã¦ãªã‚“ã‚‰ã‹ã®ãƒã‚¤ã‚¢ã‚¹ã‚’æŒã£ã¦ã„ã‚‹ã€å¯èƒ½æ€§ãŒã‚ã‚‹ã€ã¨ã„ã†è©±ã‚’ã—ã¦ãŠã‚Šèˆˆå‘³æ·±ã„ã€‚<br>ä¸€éƒ¨ã®æœ‰è­˜è€…ã¯ARC-AGIã®ä¸€éƒ¨ã®ã€äººé–“ãªã‚‰è¦‹ãŸç¬é–“ã«åˆ†ã‹ã‚‹ã‚ˆã†ãªãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã®å•é¡Œã§ã‚‚è§£ã‘ã¦ã„ãªã„ã“ã¨ã‹ã‚‰ã€AGIã§ã¯ãªã„ã¨ä¸»å¼µã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã ã£ãŸãŒã€äººé–“ç›®ç·šã§ç°¡å˜ãªå•é¡ŒãŒè§£ã‘ã‚‹ã“ã¨ã¯AGIã¨ã—ã¦å¿…é ˆãªæ¡ä»¶ã§ã¯ãªã„ã‚ˆã­ã€ã¨ã„ã£ãŸè©±ãŒæ›¸ã‹ã‚Œã¦ãŠã‚Šã€ãã‚‚ãã‚‚æœ‰è­˜è€…ãŒã©ã®ã‚ˆã†ãªã‚‚ã®ã•ã—ã‚„è¦³ç‚¹ã§AGIã‚’è¦‹ã¦ã„ã‚‹ã®ã‹ã€ã©ã†ã„ã†è¦–ç‚¹ãŒã‚ã‚‹ã®ã‹ã€ã¨ã„ã†ã“ã¨ãŒæ„Ÿè¦šçš„ã«åˆ†ã‹ã‚‹å†…å®¹ã§ã‚ã‚Šã€ãŠã‚‚ã—ã‚ã‹ã£ãŸã€‚<br><br>ã—ã‹ã—ã€ãã‚‚ãã‚‚ä½•ãŒã©ã†ãªã£ãŸã‚‰AGIãŒå®Ÿç¾ã§ããŸã¨è¨€ãˆã‚‹ã®ã ã‚ã†ã‹ï¼Ÿå®šç¾©ãŒã‚ã‹ã‚‰ãªã„ï¼ˆå®šç¾©ã€ã‚ã‚‹ã®ã‹â€¦ï¼Ÿï¼‰</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<span class="issue_date">Issue Date: 2024-12-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1611" target="_blank" rel="noopener noreferrer" class="title-link">Large Concept Models: Language Modeling in a Sentence Representation Space, Meta, 2024.12</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªã‚„ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«ä¾å­˜ã—ãªã„ã€Œå¤§è¦æ¨¡æ¦‚å¿µãƒ¢ãƒ‡ãƒ«ã€ã‚’ææ¡ˆã—ã€æ¦‚å¿µã‚’é«˜æ¬¡ã®æ„å‘³è¡¨ç¾ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚æœ€å¤§200è¨€èªã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹SONARæ–‡åŸ‹ã‚è¾¼ã¿ç©ºé–“ã‚’ç”¨ã„ã€è‡ªå·±å›å¸°çš„ãªæ–‡äºˆæ¸¬ã‚’è¡Œã†ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¾ã—ãŸã€‚16å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰70å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã—ã€ç”Ÿæˆã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹å®Ÿé¨“è©•ä¾¡ã‚’å®Ÿæ–½ã€‚çµæœã¨ã—ã¦ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆä¸€èˆ¬åŒ–æ€§èƒ½ãŒå‘ä¸Šã—ã€æ—¢å­˜ã®LLMsã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã¾ã å…¨ãèª­ã‚ã¦ã„ãªã„ãŒã€å¾“æ¥ã®LLMã¯nent-token-predictionã§å­¦ç¿’ã‚’ã—ã¦ãŠã‚Šã€transformers decoderã®å†…éƒ¨çŠ¶æ…‹ã§ä½•ã‚‰ã‹ã®æŠ½è±¡çš„ãªæ¦‚å¿µã¯ã¨ã‚‰ãˆã¦ã„ã‚‹ã‚‚ã®ã®ã€æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã«å‰å›ç”Ÿæˆã—ãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’inputã™ã‚‹ã®ãŒå¿…é ˆã§ã‚ã‚‹ä»¥ä¸Šã€Œãƒˆãƒ¼ã‚¯ãƒ³ã§è€ƒãˆã‚‹ã€ã¿ãŸã„ãªæŒ™å‹•ã‚’ã‚ã‚‹ç¨‹åº¦ã¯ã—ã¦ã—ã¾ã£ã¦ãŠã‚Šã€äººé–“ã¯ãã‚“ãªã“ã¨ã—ãªã„ã§ã™ã‚ˆã­ï¼Ÿã¿ãŸã„ãªè©±ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br>äººé–“ã¯ã‚‚ã£ã¨æŠ½è±¡çš„ãªã‚³ãƒ³ã‚»ãƒ—ãƒˆãƒ¬ãƒ™ãƒ«ã§ç‰©äº‹ã‚’è€ƒãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã®ã§ã€ãã‚Œã«ã‚ˆã‚Šè¿‘ã¥ã‘ã‚‹ãŸã‚ã«ã€conceptã‚’sentenceã¨ã—ã¦ã¿ãªã—ã¦ã€next-concept-predictionã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ãŸã‚‰ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®æ±åŒ–æ€§èƒ½ä¸ŠãŒã‚Šã¾ã—ãŸã€ã¿ãŸã„ãªè©±ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ãŸã ã—ã€è©•ä¾¡ã‚’ã—ã¦ã„ã‚‹ã®ã¯ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãªæ–‡æ›¸è¦ç´„ã‚¿ã‚¹ã‚¯ã®ã¿ã«è¦‹ãˆã‚‹ã€‚<br><br>è¿½è¨˜: ã‚³ãƒ³ã‚»ãƒ—ãƒˆãŒè¨€èªéä¾å­˜ã ã¨ã™ã‚‹ã¨ã€ã‚³ãƒ³ã‚»ãƒ—ãƒˆé–“ã®é–¢ä¿‚æ€§ã‚’å­¦ç¿’ã™ã‚‹LCMãŒã€ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ã§ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã®å­¦ç¿’ã—ã‹ã—ãªã„å¾“æ¥LLMã‚’ä¸Šå›ã‚‹ã®ã‚‚ç´å¾—ã„ãæ°—ã¯ã™ã‚‹ã€‚ãªãœãªã‚‰ã€å¾“æ¥LLMã‚ˆã‚Šã‚‚è¨€èªï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã¸ã®ä¾å­˜ãŒç·©å’Œã•ã‚Œã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã®ã§ã€è¨€èªé–“ã‚’è·¨ã„ã çŸ¥è­˜ã®è»¢ç§»ãŒèµ·ãã‚„ã™ã„ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã‹ã‚‰ã§ã‚ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/2f3dc98d-ef27-44b8-be1c-0f27a05f37e8" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/effc21ba-22db-42c0-bc33-1d43f9e0200a" alt="image" loading="lazy"></p>
<p>Base-LCMã‚’è¦‹ã‚‹ã¨ã€æ–‡ã®åŸ‹ã‚è¾¼ã¿ã®ground truthã¨ç”Ÿæˆã•ã‚ŒãŸæ–‡ã®åŸ‹ã‚è¾¼ã¿ã®å·®ã‚’æœ€å°åŒ–ã™ã‚‹ï¼ˆMean Squared Errorï¼‰ ã‚ˆã†ãªlossã«ãªã£ã¦ã„ã‚‹ã€‚ã¤ã¾ã‚Šã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã§ã¯ãªãã€ã‚ˆã‚ŠæŠ½è±¡çš„ãªæ¦‚å¿µã‚’ç›´æ¥å­¦ç¿’ã™ã‚‹ã‚ˆã†ãªè¨­è¨ˆã«ãªã£ã¦ã„ã‚‹ãŸã‚ã“ã“ãŒå¾“æ¥ã®LLMã¨ç•°ãªã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/01da9a76-f5fb-4e79-b3cf-8bddc123379b" alt="image" loading="lazy"><br><br>ã“ã‚Œã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ground truthã¨ãªã‚‹æ–‡ã®åŸ‹ã‚è¾¼ã¿x_nãŒåˆ†ã‹ã‚‰ãªã‘ã‚Œã°ã„ã‘ãªã„ãŒã€ã“ã®ãŸã‚ã«ã€freezeã—ãŸEncoderã¨Decoderã‚’ç”¨æ„ã—ã¦LCMã«concatã—ã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚ã¤ã¾ã‚Šã€å…¥åŠ›ã¨å‡ºåŠ›ã®conceptã‚’è§£é‡ˆã™ã‚‹æ©Ÿæ§‹ã¯å›ºå®šã—ã¦ã€æ­£è§£ã¨ãªã‚‹æ–‡åŸ‹ã‚è¾¼ã¿ã‚’æ±ºã‚ã¦ã—ã¾ã†ã€‚ãã—ã¦ã€LCMã¯inputã•ã‚ŒãŸconceptã‚’åˆ¥ã®conceptã«å¤‰æ›ã™ã‚‹ã‚ˆã†ãªæ©Ÿæ§‹ã¨ãªã£ã¦ãŠã‚Šã€ãã®å¤‰æ›ã®é–¢ä¿‚æ€§ã‚’å­¦ç¿’ã—ã¦ã„ã‚‹ã€‚ãªã‚‹ã»ã©ã€ãªã‚“ã¨ãªãæ°—æŒã¡ã¯ã‚ã‹ã£ãŸã€‚</p>
<p>æ—¥æœ¬èªã‚’å«ã‚€ã„ãã¤ã‹ã®è¨€èªã§ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ€§èƒ½ãŒä½ä¸‹ã—ã¦ã„ã‚‹ã®ãŒèˆˆå‘³æ·±ã„ã€‚æ—¥æœ¬èªç‰¹æœ‰ã®æ¦‚å¿µã¨ã‹ã€ç‰¹å®šã®è¨€èªå›ºæœ‰ã®æ¦‚å¿µã¯æ¬ è½ã™ã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-12-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1610" target="_blank" rel="noopener noreferrer" class="title-link">å®Œå…¨ã«ã‚ªãƒ¼ãƒ—ãƒ³ãªç´„1,720å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆGPT-3ç´šï¼‰ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« ã€Œllm-jp-3-172b-instruct3ã€ã‚’ä¸€èˆ¬å…¬é–‹ ï½GPT-3.5ã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’é”æˆï½ , NII, 2024.12</a>
<span class="snippet"><span>Comment</span><p>GPT3.5ã¨åŒç¨‹åº¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã€ãƒ¢ãƒ‡ãƒ«ã€ãƒ„ãƒ¼ãƒ«ã€å…¨ã¦ã‚’å…¬é–‹ã€‚å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¾ã§å«ã‚ã¦ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã¯ä¸–ç•Œæœ€å¤§è¦æ¨¡ã¨ã®ã“ã¨ã€‚</p>
<p>Instructionãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã¯ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚’èª­ã‚€ã¨ã€ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹å†…å®¹ã‚’éµå®ˆã™ã‚Œã°ã€èª°ã§ã‚‚ï¼ˆæ—¥æœ¬äººãªã‚‰18æ­³ä»¥ä¸Šã¨ã‹ã¯ã‚ã‚‹ãŒï¼‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã€ç”¨é€”ã®åˆ¶é™ï¼ˆå•†ç”¨ãƒ»éå•†ç”¨å•ã‚ãšï¼‰ãªãåˆ©ç”¨ã§ãã€ã‹ã¤å†é…å¸ƒã‚„æ´¾ç”Ÿç‰©ã®ç”Ÿæˆãªã©ãŒè¨±ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br>ãŒã€baseãƒ¢ãƒ‡ãƒ«ã®æ–¹ã¯ã‚³ãƒ³ã‚¿ã‚¯ãƒˆæƒ…å ±ã‚’æä¾›ã®ã†ãˆæ‰¿èªã‚’å—ã‘ãªã„ã¨åˆ©ç”¨ã§ããªã„æ¨¡æ§˜ã€‚ã¾ãŸã€å†é…å¸ƒã¨ä¸€éƒ¨ã®ä½¿é€”ã«åˆ¶é™ãŒã‚ã‚‹æ¨¡æ§˜ã€‚<br><br>SNSã§ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§ã¯ãªã„ãªã©ã¨ã„ã†è¨€èª¬ã‚‚å‡ºã¦ãŠã‚Šã€ãã‚Œã¯baseãƒ¢ãƒ‡ãƒ«ã®æ–¹ã‚’æŒ‡ã—ã¦ã„ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿã‚ˆãã‚ã‹ã‚‰ãªã„ã€‚</p>
<p>å®Ÿç”¨ä¸Šã¯instructionãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒbaseãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ä½¿ã„ã‚„ã™ã„ã¨æ€ã†ã®ã§ã€å•é¡Œãªã„æ°—ã‚‚ã™ã‚‹ã€‚</p>
<p>ã‚„ã¯ã‚Šbaseã¨instructã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯2ç¨®é¡ã‚ã‚‹ã¨ã®ã“ã¨: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1871508348086214685?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<span class="issue_date">Issue Date: 2024-12-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1608" target="_blank" rel="noopener noreferrer" class="title-link">OpenAI o1ã‚’å†ç¾ã—ã‚ˆã†ï¼ˆReasoningãƒ¢ãƒ‡ãƒ«ã®ä½œã‚Šæ–¹ï¼‰, ã¯ã¡, 2024.12</a>
<span class="snippet"><span>Comment</span><p>Reflection after Thinkingã‚’ä¿ƒã™ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒèˆˆå‘³æ·±ã„</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2024-12-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1603" target="_blank" rel="noopener noreferrer" class="title-link">ã€NLPã‚³ãƒ­ã‚­ã‚¦ãƒ ã€‘Stepwise Alignment for Constrained Language Model Policy Optimization ï¼ˆNeurIPS 2024ï¼‰  , 2024.12</a>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1602" target="_blank" rel="noopener noreferrer">RLHF/DPO å°è©±, å’Œåœ°ç­è‰¯/ Akifumi Wachi, 2024.04</a>
<br><br>ã‚‚å‚ç…§ã®ã“ã¨ã€‚</p>
<p>RLHF, DPOãŒè§£ã„ã¦ã„ã‚‹å•é¡ŒãŒåŒã˜ã§ã€å•é¡ŒãŒåŒã˜ãªã®ã§ãã‚Œãã‚Œã®æœ€é©è§£ã‚‚ä¸€ç·’ã§ã‚ã‚Šè§£ãæ–¹ãŒé•ã†ã ã‘ã€ã§ã‚‚DPOã®æ–¹ãŒé ‘å¼µã£ã¦å¼·åŒ–å­¦ç¿’ã™ã‚‹RLHFã‚ˆã‚Šã‚‚ç°¡å˜ã«è§£ã‘ã‚‹ã—ã€å­¦ç¿’ã‚‚å®‰å®šã—ã¦ã‚‹ã‚ˆã€ã¨ã„ã†è©±ãŒã€binary feedbackãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆæ‰‹æ³•ã§ã‚ã‚‹KTOã‚‚äº¤ãˆã¦æ›¸ã„ã¦ã‚ã‚‹ã€‚</p>
<p>ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã®å­¦ç¿’ã§ã¯å˜ä¸€ã®ã‚¹ã‚«ãƒ©ãƒ¼å€¤ã«ã‚ˆã£ã¦å ±é…¬ãŒæ±ºã¾ã£ã¦ã„ã‚‹ãŒã€ç”Ÿæˆçµæœã«ã¯è‰²ã€…ãªå´é¢ãŒã‚ã‚‹ã‹ã‚‰å˜ä¸€ã‚¹ã‚«ãƒ©ãƒ¼ã§ã¯æœ¬æ¥è©•ä¾¡ã§ããªã„ã‚ˆã­ã¨ã„ã†è©±ãŒå‡ºã¦ããŸä¸Šã§ã€safetyã«å¯¾ã—ã¦ã‚‚è€ƒæ…®ã—ã¦å ±é…¬ã‚’æ±ºã‚ãŸã„ã€ã¨ã„ã†æ™‚ã«ã‚¹ã‚«ãƒ©ãƒ¼å€¤ã®ã¾ã¾ã ã‘ã©æœ€é©åŒ–å•é¡Œã®åˆ¶ç´„æ¡ä»¶ã«safetyã«é–¢ã™ã‚‹åˆ¶ç´„ã‚’å…¥ã‚Œã‚‹ã€ã“ã¨ã§å ±é…¬ã«åæ˜ ã•ã›ã¾ã™ã€ã¿ãŸã„ãªè©±ãŒæ›¸ã„ã¦ã‚ã‚‹ã€‚<br>ãã—ã¦ææ¡ˆæ‰‹æ³•ã®ä¸»è¦ãªè²¢çŒ®ã¯ã€ãã†ã„ã†ã“ã¨ã‚’ã‚„ã‚‹ã¨ã‚ã¡ã‚ƒã‚ã¡ã‚ƒæ‰‹æ³•ãŒè¤‡é›‘åŒ–ã™ã‚‹ã‚“ã ã‘ã‚Œã©ã‚‚ã€ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ã«ã—ã¦ã€ã‹ã¤ç†è«–çš„ã«ã‚‚æ­£å½“åŒ–ã•ã‚Œã¦ã„ã‚‹ã—ã€å®Ÿé¨“çš„ã«ã‚‚ã†ã¾ãå‹•ãã¾ã™ã€ã¨ã„ã†è©±ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<span class="issue_date">Issue Date: 2024-12-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1602" target="_blank" rel="noopener noreferrer" class="title-link">RLHF_DPO å°è©±, å’Œåœ°ç­è‰¯_ Akifumi Wachi, 2024.04</a>
<span class="snippet"><span>Comment</span><p>ã‚ã¡ã‚ƒã‚ã¡ã‚ƒå‹‰å¼·ã«ãªã‚‹â€¦</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2024-12-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1601" target="_blank" rel="noopener noreferrer" class="title-link">Scaling test-time-compute, Huggingface, 2024.12</a>
<span class="snippet"><span>Comment</span><p>ã“ã‚Œã¯å¿…èª­</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-12-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1599" target="_blank" rel="noopener noreferrer" class="title-link">Fast LLM Inference From Scratch, Andrew Chan, 2024.12</a>
<span class="snippet"><span>Comment</span><p>ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã›ãšã«C++ã¨CUDAã‚’åˆ©ç”¨ã—ã¦LLMã®æ¨è«–ã‚’å®Ÿæ–½ã™ã‚‹æ–¹æ³•ã®è§£èª¬è¨˜äº‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/SpokenLanguageProcessing.html" target="_blank" rel="noopener noreferrer">#SpokenLanguageProcessing</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2024-12-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1588" target="_blank" rel="noopener noreferrer" class="title-link">LLaMA-Omni: Seamless Speech Interaction with Large Language Models, Meta, 2024.09</a>
<span class="snippet"><span>Comment</span><p>éŸ³å£°ã¨ãƒ†ã‚­ã‚¹ãƒˆã®OpenSourceãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€‚inputã¯éŸ³å£°ã®ã¿ï¼Ÿã«è¦‹ãˆã‚‹ãŒã€å‡ºåŠ›ã¯ãƒ†ã‚­ã‚¹ãƒˆã¨éŸ³å£°ã®ä¸¡æ–¹ã‚’å®Ÿæ–½ã§ãã‚‹ã€‚GPT-4oãƒ¬ãƒ™ãƒ«ã®speech capabilityã‚’ç›®æŒ‡ã™ã¨aboutã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚èˆˆå‘³æ·±ã„ã€‚<br><br><br><br>installã®èª¬æ˜ã« `Whisper-large-v3` ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹æ—¨ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€Whisper-large-v3ã§èªè­˜ã—ãŸå†…å®¹ã«ç‰¹åŒ–ã—ãŸSpeech Encoder/AdapterãŒå­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><br>&lt;img width="702" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/cea090e7-a42a-476d-85f6-50199d9ae180"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/cea090e7-a42a-476d-85f6-50199d9ae180"&lt;/a&gt;


/&gt;<br><br></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1225" target="_blank" rel="noopener noreferrer">MM-LLMs: Recent Advances in MultiModal Large Language Models, Duzhen Zhang+, N/A, ACL'24 Findings</a>
 <br><br><br><br>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªLLMã®åŸºæœ¬çš„ãªæ¦‚å¿µã«ã¤ã„ã¦ã¯ä¸Šè¨˜å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2024-12-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1576" target="_blank" rel="noopener noreferrer" class="title-link">OpenAI o1 System Card, OpenAI, 2024.12</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-12-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1574" target="_blank" rel="noopener noreferrer" class="title-link">Llama3.3-70B, Meta, 2024.12</a>
<span class="snippet"><span>Comment</span><p>3.1-70Bã‚ˆã‚Šã‚‚æ€§èƒ½å‘ä¸Šã—ã€3.1-405Bã®æ€§èƒ½ã«ã‚ˆã‚Šè¿‘ãã€‚<br><br>ï¼ˆç”»åƒã¯å…ƒãƒã‚¹ãƒˆã‚ˆã‚Šå¼•ç”¨ï¼‰<br><img src="https://github.com/user-attachments/assets/07fb3043-131a-4564-be70-d34b70c31cca" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<span class="issue_date">Issue Date: 2024-12-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1571" target="_blank" rel="noopener noreferrer" class="title-link">Introducing Amazon Nova, our new generation of foundation models, AWS, 2024.12</a>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:


<a href="https://qiita.com/ysit/items/8433d149dbaab702d526" target="_blank" rel="noopener noreferrer">https://qiita.com/ysit/items/8433d149dbaab702d526</a>


</p>
<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ: 


<a href="https://assets.amazon.science/9f/a3/ae41627f4ab2bde091f1ebc6b830/the-amazon-nova-family-of-models-technical-report-and-model-card.pdf" target="_blank" rel="noopener noreferrer">https://assets.amazon.science/9f/a3/ae41627f4ab2bde091f1ebc6b830/the-amazon-nova-family-of-models-technical-report-and-model-card.pdf</a>


</p>
<p>å¾Œã§å€‹ã€…ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ã¾ã¨ã‚ãŸã„ã€‚<br><br>ã¾ã‚ã§ã‚‚ã–ã£ãã‚Šè¨€ã†ã¨ã€ä»–ã®proprietaryãƒ¢ãƒ‡ãƒ«ã¨ã‚‚ãŠãŠã‚€ã­åŒç­‰ã®æ€§èƒ½ã§ã™ã€ã¨ã„ã†æ„Ÿã˜ã«è¦‹ãˆã‚‹ã€‚å€‹ã€…ã®ã‚¿ã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã§è¦‹ã‚‹ã¨ã€å¾—æ„ãªã‚‚ã®ã¨ä¸å¾—æ„ãªã‚‚ã®ã¯ã‚ã‚Šãã†ã§ã¯ã‚ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/c0c633d8-c64d-4a14-95cf-0d8b0d52a7f6" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/560f8c3e-65ff-4742-b7da-bc2b242dafcd" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/481a9635-128d-4931-a891-5f46d55b82bc" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/fc9b1bc0-b857-4a27-ad90-4940213c6ec6" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/a349b154-1844-41c2-84e3-7f981b1f6b72" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/a4381740-600c-402f-be0d-59ce60b7a562" alt="image" loading="lazy"><br><br>ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¨ã‹ã‚‚ã€Proã¨GPT4oã‚’ãƒ‘ãƒƒã¨è¦‹ã§æ¯”è¼ƒã—ãŸæ„Ÿã˜ã€å„ªã‚Œã¦ã„ã‚‹ã‚ã‘ã§ã‚‚ãªã•ãã†ã€‚Liteã«å¯¾å¿œã™ã‚‹GPTã¯ãŠãã‚‰ãGPT4o-miniã ã¨æ€ã‚ã‚Œã‚‹ãŒã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¯Liteã®æ–¹ãŒé«˜ãã†ã€‚<br><img src="https://github.com/user-attachments/assets/734ee26f-2f16-46e4-a6e8-f5f2f0d65be3" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/fe1768e8-b417-4b89-a0c4-f6dffa99cf11" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/6334ee92-e426-49f5-8e1f-050e0b77fcf2" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/5c9ec797-ef7a-43e1-8540-42ccab265208" alt="image" loading="lazy"><br><br>ï¼ˆç”»åƒã¯è«–æ–‡ä¸­ã‹ã‚‰ã‚¹ã‚¯ã‚·ãƒ§ã—å¼•ç”¨ï¼‰</p>
<p>ä¸‹è¨˜ãƒã‚¹ãƒˆã¯ç‹¬è‡ªã«è©•ä¾¡ã—ãŸçµæœã‚„ã€ã‚³ã‚¹ãƒˆã¨æ€§èƒ½ã®ãƒãƒ©ãƒ³ã‚¹ã«ã¤ã„ã¦è¨€åŠã—ã¦ã„ã‚‹ã€‚<br><br>- Proã¯GPT4oã®ã‚³ã‚¹ãƒˆã®ç´„1/3<br>- Pro, Lite, Flashã¯ã»ã‚Œãã‚Œã‚³ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«éå¸¸ã«å„ªã‚Œã¦ã„ã‚‹ï¼ˆQuality vs. Priceå‚ç…§ï¼‰<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1864023052818030814?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-12-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1569" target="_blank" rel="noopener noreferrer" class="title-link">Augmenting Recommendation Systems With LLMs, Dave AI, 2024.08</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2024-12-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1563" target="_blank" rel="noopener noreferrer" class="title-link">æ—¥æœ¬èªLLMã¾ã¨ã‚, LLM-jp, 2024.12</a>
<span class="snippet"><span>Comment</span><p>LLM-jpã«ã‚ˆã‚‹æ—¥æœ¬èªLLMï¼ˆEncoder-Decoderç³», BERTç³», Bi-Encoders, Cross-Encodersã‚’å«ã‚€ï¼‰ã®ã¾ã¨ã‚ã€‚<br>ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ä½¿ã†ãƒ¢ãƒ‡ãƒ«ã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã«ä½¿ã†ãƒ¢ãƒ‡ãƒ«ã€Embeddingä½œæˆã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã€è¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ«ã€éŸ³å£°è¨€èªãƒ¢ãƒ‡ãƒ«ã€æ—¥æœ¬èªLLMè©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯/ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã€æ±ç”¨ã¨ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹ã«åˆ†ã‘ã¦ã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚<br>å„ãƒ¢ãƒ‡ãƒ«ã‚„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®åŸè«–æ–‡ã€å­¦ç¿’æ‰‹æ³•ã®åŸè«–æ–‡ã‚‚ã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ã™ã”ã„é‡ã â€¦ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<span class="issue_date">Issue Date: 2024-11-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1558" target="_blank" rel="noopener noreferrer" class="title-link">LLM Self-Correction Papers, Ryo Kamoi, 2024.11</a>
<span class="snippet"><span>Comment</span><p>self-correctionã®å°‚é–€å®¶ã«ã‚ˆã‚‹self-correctioné–¢é€£ã®è«–æ–‡ã®ãƒªãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒªã‚¹ãƒˆã€‚ãœã²ãƒã‚§ãƒƒã‚¯ã—ãŸã„ã€‚<br><br>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ryokamoi_ja/status/1862635105010799054?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/AES(AutomatedEssayScoring).html" target="_blank" rel="noopener noreferrer">#AES(AutomatedEssayScoring)</a>
<span class="issue_date">Issue Date: 2024-11-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1555" target="_blank" rel="noopener noreferrer" class="title-link">Cross-prompt Pre-finetuning of Language Models for Short Answer Scoring, Funayama+, 2024.09</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå‹•çŸ­ç­”ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆSASï¼‰ã§ã¯ã€ç•°ãªã‚‹ãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã¨å‚ç…§å›ç­”ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã‚‹ãŒã€æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã”ã¨ã«ãƒ¢ãƒ‡ãƒ«ã‚’å†è¨“ç·´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ—¢å­˜ã®ãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã¨å›ç­”ã‚’ç”¨ã„ã¦æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹äºŒæ®µéšã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚é‡è¦ãªãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€ç‰¹ã«è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã«ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’å®Ÿé¨“ã§ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>SASã§ã¯å›ç­”ãƒ‡ãƒ¼ã‚¿ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹ã®ã§ã€é™ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚ˆã‚ŠåŠ¹æœçš„ã«å­¦ç¿’ã‚’ã™ã‚‹ãŸã‚ã«ã€äº‹å‰ã«ä»–ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’pre-finetuningã—ã¦ãŠãã€å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒæ¥ãŸã‚‰pre-finetuningã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ã•ã‚‰ã«finetuningã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ã“ã“ã§ã€promptä¸­ã«keyphraseã‚’å«ã‚ã‚‹ã“ã¨ãŒæœ‰ç”¨ã§ã‚ã‚‹ã¨è€ƒãˆã€å®Ÿé¨“çš„ã«æœ‰åŠ¹æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/9ab4eb22-b72e-4573-8fbb-1c376047c2b0" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/b671a564-c5a8-4344-aaec-06875f654f8b" alt="image" loading="lazy"><br><br><br><br>BERTã§finetuningã‚’ã—ãŸå ´åˆã¯ã€key-phraseã‚’å«ã‚ãŸæ–¹ãŒæ€§èƒ½ãŒé«˜ãã€ç‰¹ã«finetuningã®ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°ã•ã„å ´åˆã«ãã®å·®ãŒé¡•è‘—ã§ã‚ã£ãŸã€‚<br><br><img src="https://github.com/user-attachments/assets/cdced65b-060b-43ae-a2b4-fcfc5750a6ed" alt="image" loading="lazy"><br><br><br><br>æ¬¡ã«ã€LLMï¼ˆswallow-8B, 70Bï¼‰ã‚’pre-finetuningã—ã€pre-finetuningã‚’å®Ÿæ–½ã—ãªã„å ´åˆã¨æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ã€pre-finetuningãŒLLMã®zero-shotã€ãŠã‚ˆã³ICLèƒ½åŠ›ã«ã©ã®ç¨‹åº¦å½±éŸ¿ã‚’ä¸ãˆã‚‹ã‹ã‚’æ¤œè¨¼ã—ãŸã€‚æ¤œè¨¼ã®çµæœã€pre-finetuningãªã—ã§ã¯ã€ãã‚‚ãã‚‚10-shotã«ã—ã¦ã‚‚QWKãŒéå¸¸ã«ä½ã‹ã£ãŸã®ã«å¯¾ã—ã€pre-finetuningã«ã‚ˆã£ã¦zero-shotã®èƒ½åŠ›ãŒå¤§å¹…ã«æ€§èƒ½ãŒå‘ä¸Šã—ãŸã€‚ä¸€æ–¹ã€few-shotã«ã¤ã„ã¦ã¯3-shotã§æ€§èƒ½ãŒé ­æ‰“ã¡ã«ãªã£ã¦ã„ã‚‹ã‚ˆã†ã«ã¿ãˆã‚‹ã€‚ã“ã“ã§ã€Table1ã®LLMã§ã¯ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã™ã‚‹å•é¡Œã®promptã§ã¯ä¸€åˆ‡finetuningã•ã‚Œã¦ã„ãªã„ã“ã¨ã«æ³¨æ„ã™ã‚‹ï¼ˆUnseenãªå•é¡Œï¼‰ã€‚<br><br>&lt;img width="639" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/7c9f141d-dc55-4388-8dc4-6a56f81d6cad"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/7c9f141d-dc55-4388-8dc4-6a56f81d6cad"&lt;/a&gt;


&gt;<br><br><br><br>ç¶šã„ã¦ã€LLMã‚’finetuningã—ãŸå ´åˆã‚‚æ¤œè¨¼ã€‚ææ¡ˆæ‰‹æ³•ãŒé«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã€200ã‚µãƒ³ãƒ—ãƒ«ç¨‹åº¦ã‚ã‚‹å ´åˆã«Human Scoreã‚’ä¸Šå›ã£ã¦ã„ã‚‹ï¼ˆã—ã‹ã‚‚BERTã¯200ã‚µãƒ³ãƒ—ãƒ«ã§ã‚µãƒã£ãŸãŒã€LLMã¯ã¾ã ã‚µãƒã£ã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ï¼‰ã€‚ã¾ãŸã€ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒã‚ˆã‚Šå°ã•ã„å ´åˆã«ã€ææ¡ˆæ‰‹æ³•ãŒã‚ˆã‚Šé«˜ã„gainã‚’å¾—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br>&lt;img width="775" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/898b2bea-e9df-4c5c-b172-0507a3a83c3c"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/898b2bea-e9df-4c5c-b172-0507a3a83c3c"&lt;/a&gt;


&gt;<br><br><br><br>ã¾ãŸã€å€‹ã€…ã®å•é¡Œã”ã¨ã«LLMã‚’finetuningã™ã‚‹ã®ã¯ç¾å®Ÿçš„ã«å›°é›£ãªã®ã§ã€å€‹ã€…ã®å•é¡Œã”ã¨ã«finetuningã—ãŸå ´åˆã¨ã€å…¨ã¦ã®å•é¡Œã‚’ã¾ã¨ã‚ã¦finetuningã—ãŸå ´åˆã®æ€§èƒ½å·®ã‚’æ¯”è¼ƒã—ãŸã¨ã“ã‚ã€ã¾ã¨ã‚ã¦å­¦ç¿’ã—ã¦ã‚‚æ€§èƒ½ã¯ä½ä¸‹ã—ãªã„ã€ã©ã“ã‚ã‹21å•ä¸­18å•ã§æ€§èƒ½ãŒå‘ä¸Šã—ãŸï¼ˆLLMã®ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®èƒ½åŠ›ã®ãŠã‹ã’ï¼‰ã€‚<br><br>&lt;img width="762" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/a8ec62fb-2984-4e7c-8eeb-1b3b6333e9ac"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a8ec62fb-2984-4e7c-8eeb-1b3b6333e9ac"&lt;/a&gt;


&gt;<br><br></p>
<p>[Perplexity(hallucinationã«æ³¨æ„)](


<a href="https://www.perplexity.ai/search/tian-fu-sitalun-wen-wodu-mi-ne-3_TrRyxTQJ.2Bm2fJLqvTQ#0)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/search/tian-fu-sitalun-wen-wodu-mi-ne-3_TrRyxTQJ.2Bm2fJLqvTQ#0)</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/API.html" target="_blank" rel="noopener noreferrer">#API</a>
<span class="issue_date">Issue Date: 2024-11-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1553" target="_blank" rel="noopener noreferrer" class="title-link">aisuite, andrewyng, 2024.11</a>
<span class="snippet"><span>Comment</span><p>è¤‡æ•°ã®LLM Providerã®å‘¼ã³å‡ºã—ã‚’å…±é€šã®ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ã§å‘¼ã³å‡ºã›ã‚‹ã€‚å¤‰æ›´ã™ã‚‹ã®ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã€‚<br><br>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/andrewyng_announcing-new-open-source-python-package-activity-7266851242604134400-Davp?utm_source=share&utm_medium=member_ios" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/andrewyng_announcing-new-open-source-python-package-activity-7266851242604134400-Davp?utm_source=share&utm_medium=member_ios</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-11-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1545" target="_blank" rel="noopener noreferrer" class="title-link">Sarashina2-8x70Bã®å…¬é–‹, SB Intuitions, 2024.11</a>
<span class="snippet"><span>Comment</span><p>MoE Layerã®èª¬æ˜ã€Sparse Upcyclingã®èª¬æ˜ã€MoEãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹éš›ã«ã€å­¦ç¿’æ™‚ã®å­¦ç¿’ç‡ã®è¨­å®šãŒå¤§ãã™ãã‚‹ã¨åˆæœŸã«æå¤±ãŒå¢—å¤§ã—ã€å°ã•ã™ãã‚‹ã¨æå¤±ã®å¢—å¤§ã¯é˜²ã’ã‚‹ãŒlong runã§å­¦ç¿’ã—ãŸéš›ã®æ€§èƒ½å‘ä¸ŠãŒå°ã•ã‹ã£ãŸã“ã¨ã€å…ƒã®ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¯€æã—ãªã„ã‚ˆã†ã«ã€Upcyclingã‚’ã—ãŸå…ƒãƒ¢ãƒ‡ãƒ«ã®æœ€çµ‚çš„ãªå­¦ç¿’ç‡ã‚’è¸è¥²ã—ã¦å­¦ç¿’ã‚’ã—ã€å­¦ç¿’ç‡ã‚’ã•ã‚‰ã«æ¸›è¡°ã•ã›ã¦ã„ã£ãŸã“ã¨ã€ãªã©ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>ã¾ãŸã€æ€§èƒ½è©•ä¾¡ã¨ã—ã¦åŒç­‰ã®activation parameteræ•°ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã¨æ—¥æœ¬èªã®QAã‚¿ã‚¹ã‚¯ã§æ¯”è¼ƒã—ãŸçµæœã‚‚è¼‰ã£ã¦ã„ã‚‹ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1546" target="_blank" rel="noopener noreferrer">Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints, Aran Komatsuzaki+, ICLR'23</a>
</p>
<p>MoE Layerã«ã¤ã„ã¦ã¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1204" target="_blank" rel="noopener noreferrer">Mixtral of Experts, Albert Q. Jiang+, N/A, arXiv'24</a>
<br><br>ã‚‚å‚ç…§ã®ã“ã¨</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2024-11-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1528" target="_blank" rel="noopener noreferrer" class="title-link">Large Vision Language Model ï¼ˆLVLMï¼‰ã«é–¢ã™ã‚‹çŸ¥è¦‹ã¾ã¨ã‚, Daiki Shiono, 2024.11</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2024-11-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1521" target="_blank" rel="noopener noreferrer" class="title-link">microsoft_orca-agentinstruct-1M-v1, Microsoft, 2024.11</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2024-11-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1519" target="_blank" rel="noopener noreferrer" class="title-link">ãƒ­ãƒ¼ã‚«ãƒ«LLMã®ãƒªãƒªãƒ¼ã‚¹å¹´è¡¨, npaka, éšæ™‚æ›´æ–°, 2024.11</a>
<span class="snippet"><span>Comment</span><p>ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’å«ã‚€OpenLLMã®ãƒªãƒªãƒ¼ã‚¹æ—¥ãŒå¹´è¡¨ã¨ã—ã¦ã¾ã¨ã¾ã£ã¦ãŠã‚Šã€éšæ™‚æ›´æ–°ã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ã€‚ã™ã”ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2024-11-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1518" target="_blank" rel="noopener noreferrer" class="title-link">TensorRT-LLMã«ã‚ˆã‚‹æ¨è«–é«˜é€ŸåŒ–, Hiroshi Matsuda, NVIDIA AI Summit 2024.11 </a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hmtd223/status/1856887876665184649?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>éå¸¸ã«èˆˆå‘³æ·±ã„ã®ã§å¾Œã§èª­ã‚€</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2024-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1508" target="_blank" rel="noopener noreferrer" class="title-link">Copilot Arena, CMU and UC Berkeley, 2024.11</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lmarena_ai/status/1856444009323082093?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/623" target="_blank" rel="noopener noreferrer">ChatBot Arena, lmsys org, 2023.05</a>
 ã‚‚å‚ç…§ã®ã“ã¨</p>
<p>Chatbot ArenaãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸã®ãŒ1å¹´åŠå‰ã§ã‚ã‚‹ã“ã¨ã‚’ãŠã‚‚ã„ãŠã“ã—ã€ã“ã®2å¹´ã§é£›èºçš„ã«LLMãŒã§ãã‚‹ã“ã¨ãŒå¢—ãˆãŸãªãã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°å¢—ãˆãŸãªãã€ã§ã‚‚çœãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æ€§èƒ½ã‚ã£ã¡ã‚ƒä¸ŠãŒã£ãŸãªãã€proprietary LLMã«OpenLLMãŒè¿½ã„ã¤ã„ã¦ããŸãªãã€ã¨ã—ã¿ã˜ã¿æ€ã†ãªã©ã—ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-11-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1494" target="_blank" rel="noopener noreferrer" class="title-link">sarashina2-8x70B, SBIntuitions, 2024.11</a>
<span class="snippet"><span>Comment</span><p>ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹:


<a href="https://www.sbintuitions.co.jp/news/press/20241108_01/" target="_blank" rel="noopener noreferrer">https://www.sbintuitions.co.jp/news/press/20241108_01/</a>


</p>
<p>- å•†ç”¨åˆ©ç”¨ä¸å¯ãªç‚¹ã«ã¯æ³¨æ„<br>- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯70Bãƒ¢ãƒ‡ãƒ«x8ã®Mixture of Expertsï¼ˆMoEï¼‰<br>- ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ã¨ã€inferenceã«ã¯BF16ã§ã€A100 80GB or H100ãŒ16åŸºå¿…è¦ã£ã½ã„</p>
<p>MoEã‚’åˆ©ç”¨ã—ãŸLLMã«ã¤ã„ã¦ã¯ã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1204" target="_blank" rel="noopener noreferrer">Mixtral of Experts, Albert Q. Jiang+, N/A, arXiv'24</a>
 ã‚’å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/MinimalCode.html" target="_blank" rel="noopener noreferrer">#MinimalCode</a>
<span class="issue_date">Issue Date: 2024-11-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1479" target="_blank" rel="noopener noreferrer" class="title-link">Lingua, Meta</a>
<span class="snippet"><span>Comment</span><p>ç ”ç©¶ç›®çš„ã®ãŸã‚ã®ã€minimalã€ã‹ã¤é«˜é€ŸãªLLM training/inferenceã®ã‚³ãƒ¼ãƒ‰ãŒæ ¼ç´ã•ã‚ŒãŸãƒªãƒã‚¸ãƒˆãƒªã€‚ç‹¬è‡ªã®ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã€ãƒ­ã‚¹ãªã©ãŒç°¡å˜ã«å®Ÿè£…ã§ãã‚‹æ¨¡æ§˜ã€‚<br><br><img src="https://github.com/user-attachments/assets/47f70515-3de0-455f-9fc4-0e2e17442eed" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1471" target="_blank" rel="noopener noreferrer" class="title-link">Introducing quantized Llama models with increased speed and a reduced memory footprint, Meta, 2024.10</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1462" target="_blank" rel="noopener noreferrer" class="title-link">Prompt-Engineering-Guide, DAIR.AI</a>
<span class="snippet"><span>Comment</span><p>LLMã®settingã‹ã‚‰ã€few-shot, self-consistencyãªã©ã®promptingæŠ€è¡“ã€ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã®å®Ÿä¾‹ãªã©ãŒç¶²ç¾…çš„ã«ã¾ã¨ã¾ã£ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2024-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1457" target="_blank" rel="noopener noreferrer" class="title-link">MLE-Bench, OpenAI, 2024.10</a>
<span class="snippet"><span>GPT Summary</span>- MLE-benchã‚’ç´¹ä»‹ã—ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã€‚75ã®Kaggleã‚³ãƒ³ãƒšã‚’åŸºã«å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã€äººé–“ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ç¢ºç«‹ã€‚æœ€å‰ç·šã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ãŸçµæœã€OpenAIã®o1-previewãŒ16.9%ã®ã‚³ãƒ³ãƒšã§Kaggleã®ãƒ–ãƒ­ãƒ³ã‚ºãƒ¡ãƒ€ãƒ«ç›¸å½“ã®æˆæœã‚’é”æˆã€‚AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ç†è§£ã‚’ä¿ƒé€²ã™ã‚‹ãŸã‚ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚³ãƒ¼ãƒ‰ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã€‚</span>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2024-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1450" target="_blank" rel="noopener noreferrer" class="title-link">Unsloth</a>
<span class="snippet"><span>Comment</span><p>single-GPUã§ã€LLMã®LoRA/QLoRAã‚’é«˜é€Ÿ/çœãƒ¡ãƒ¢ãƒªã«å®Ÿè¡Œã§ãã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2024-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1445" target="_blank" rel="noopener noreferrer" class="title-link">ä»Šæ—¥ã‹ã‚‰å§‹ã‚ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆæ´»ç”¨, y_matsuwitter, 2024.10</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1443" target="_blank" rel="noopener noreferrer" class="title-link">Gemma-2-Baku, 2024.10</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1441" target="_blank" rel="noopener noreferrer" class="title-link">Gemma-2-JPN, 2024.10</a>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã§finetuningã•ã‚Œã¦Gemma2</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1431" target="_blank" rel="noopener noreferrer" class="title-link">Evaluating the Effectiveness of LLM-Evaluators ï¼ˆaka LLM-as-Judgeï¼‰, 2024.09</a>
<span class="snippet"><span>Comment</span><p>LLM-as-a-judgeã«ã¤ã„ã¦ç¶²ç¾…çš„ã«æ›¸ã‹ã‚ŒãŸè¨˜äº‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1430" target="_blank" rel="noopener noreferrer" class="title-link">RAGã®å®Ÿè£…æˆ¦ç•¥ã¾ã¨ã‚, Jin Watanabe, 2024.03</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<span class="issue_date">Issue Date: 2024-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1428" target="_blank" rel="noopener noreferrer" class="title-link">NotebookLM, Google</a>
<span class="snippet"><span>Comment</span><p>ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãã‚Œã‚‰ã‚’å‚ç…§å¯èƒ½ãªLLMã®å…ƒä½œæ¥­ãŒå¯èƒ½ã§ã€ã‚¯ã‚¨ãƒªã«ã‚ˆã£ã¦å¼•ç”¨ã¤ãã®RAGã®ã‚ˆã†ãªã‚‚ã®ãŒè¡Œãˆã‚‹ã‚‰ã—ã„ã€‚2äººã®å¯¾è©±å½¢å¼ã®podcastã‚‚è‡ªå‹•ç”Ÿæˆå¯èƒ½ã§ã€UI/UXã®é¢ã§ç”»æœŸçš„ã‚‰ã—ã„ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2024-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1426" target="_blank" rel="noopener noreferrer" class="title-link">Molmo, AI2, 2024.09</a>
<span class="snippet"><span>GPT Summary</span>- Molmoã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ãŸæœ€å…ˆç«¯ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«AIãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ç‰¹ã«å°å‹ãƒ¢ãƒ‡ãƒ«ãŒå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚Molmoã¯ã€ç‰©ç†çš„ãŠã‚ˆã³ä»®æƒ³çš„ãªä¸–ç•Œã¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’å¯èƒ½ã«ã—ã€éŸ³å£°ãƒ™ãƒ¼ã‚¹ã®èª¬æ˜ã‚’ç”¨ã„ãŸæ–°ã—ã„ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å°å…¥ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã€éè¨€èªçš„æ‰‹ãŒã‹ã‚Šã‚’æ´»ç”¨ã—ã¦è³ªå•ã«ç­”ãˆã‚‹èƒ½åŠ›ã‚’æŒã¤ã€‚Molmoãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆã§ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªã‚·ã‚¹ãƒ†ãƒ ã«å¯¾æŠ—ã™ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã—ã€ä»Šå¾Œã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚¦ã‚§ã‚¤ãƒˆã‚„ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹ãŒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœï¼ˆVLMã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼‰ã€‚11 benchmarksã¨æ›¸ã‹ã‚Œã¦ã„ã‚‹ã®ã¯ã€VLMã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚‹ç‚¹ã«æ³¨æ„ã€‚<br><br><br><br>&lt;img width="981" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/510204e5-4cfb-4ba3-a6db-fff717a637bc"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/510204e5-4cfb-4ba3-a6db-fff717a637bc"&lt;/a&gt;


&gt;<br><br>&lt;img width="940" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/a4a77006-fcde-4c33-b6df-54dc5d8cbdfa"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a4a77006-fcde-4c33-b6df-54dc5d8cbdfa"&lt;/a&gt;


&gt;<br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1422" target="_blank" rel="noopener noreferrer" class="title-link">Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, Meta, 2024.09</a>
<span class="snippet"><span>Comment</span><p>11Bã¨90Bã®VLMã¨ã€ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹å‘ã‘ã®1B, 3Bã®SLMã‚’ç™ºè¡¨ã€‚<br><img src="https://github.com/user-attachments/assets/13c4af37-19bd-4de7-b501-eb48f955af0c" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/d6b75b15-88cb-4d9e-9838-0da24308ccda" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/7475b30d-4619-4117-a911-d308291f86cb" alt="image" loading="lazy"></p>
<p>Llama3.2ã®VLMã§ã¯ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸimage encoderã‚’äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦çµ„ã¿åˆã‚ã›ã‚‹ãŸã‚ã®Adapterã‚’è¤‡æ•°å­¦ç¿’ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦å®Ÿç¾ã€‚<br><br>å…·ä½“çš„ã«ã¯ã€Llama 3.1ï¼ˆtext only modelï¼‰ã«å¯¾ã—ã¦ã€image encoderã¨Adapterã‚’è¿½åŠ ã—ã€å¤§è¦æ¨¡ã§ãƒã‚¤ã‚¸ãƒ¼ãªï¼ˆimage,textï¼‰ãƒšã‚¢ã§äº‹å‰å­¦ç¿’ã€‚ç¶šã„ã¦ã€ä¸­è¦æ¨¡ã®ã‚µã‚¤ã‚ºã®é«˜å“è³ªãªin-domainï¼ˆi.e. æ§˜ã€…ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã®ï¼‰ã®çŸ¥è­˜ã‚’é«˜ã‚ã‚‹ã‚ˆã†ãªï¼ˆimage,textï¼‰ãƒšã‚¢ã§å­¦ç¿’ã—ãŸã€‚<br><br>äº‹å¾Œå­¦ç¿’ã§ã¯ã€Llama3.1ã¨åŒæ§˜ã«SFT, Rejection Sampling, DPOã®ãƒ©ã‚¦ãƒ³ãƒ‰ã‚’è¤‡æ•°å›ç¹°ã‚Šè¿”ã—ãŸã€‚Llama3.1ã‚’ç”¨ã„ã¦ã€in-domainã®ç”»åƒã«å¯¾ã™ã‚‹QAã‚’Data Augmentationã—ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã€‚ã•ã‚‰ã«å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã¦å…¨ã¦ã®å›ç­”å€™è£œã‚’ãƒ©ãƒ³ã‚¯ã¥ã‘ã—ã¦é«˜å“è³ªãªSFTãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã€‚ã¾ãŸã€ãƒ¢ãƒ‡ãƒ«ã®å®‰å…¨æ€§ãŒé«˜ã¾ã‚‹ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚‚è¿½åŠ ã—ãŸã€‚<br><br>Llama3.1ã®äº‹å¾Œå­¦ç¿’ã®ãƒ—ãƒ­ã‚»ã‚¹ã«ã¤ã„ã¦ã¯ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1359" target="_blank" rel="noopener noreferrer">è«–æ–‡ç´¹ä»‹ / The Llama 3 Herd of Models, 2024.08</a>
 ã‚‚å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1419" target="_blank" rel="noopener noreferrer" class="title-link">LLMã®åŠ¹ç‡åŒ–ãƒ»é«˜é€ŸåŒ–ã‚’æ”¯ãˆã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ , Tatsuya Urabe, 2024.09</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1418" target="_blank" rel="noopener noreferrer" class="title-link">LLM-jp-3 1.8Bãƒ»3.7Bãƒ»13B ã®å…¬é–‹, LLM.jp, 2024.09</a>
<span class="snippet"><span>Comment</span><p>LLM-JP-Evalã§ã®è©•ä¾¡çµæœã¯ã“ã¡ã‚‰:


<a href="https://huggingface.co/llm-jp/llm-jp-3-1.8b" target="_blank" rel="noopener noreferrer">https://huggingface.co/llm-jp/llm-jp-3-1.8b</a>


</p>
<p>1.8Bã®ãƒ¢ãƒ‡ãƒ«ãŒã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«å¯¾ã—ã¦éå¸¸ã«æ€§èƒ½ãŒè‰¯ã„ã¨ã®ã“ã¨ï¼ˆç¢ºã‹ã«ã€3.8Bã®ãƒ¢ãƒ‡ãƒ«ã¨ã®å·®ãŒã‚ã¾ã‚Šãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1838814594514718878?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯Llama2ã¨ã®ã“ã¨ãªã®ã§ã€vLLMã§ã‚‚å‹•ä½œã•ã›ã‚‰ã‚Œã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1417" target="_blank" rel="noopener noreferrer" class="title-link">LLM-jp Corpus v3, LLM.jp, 2024.09</a>
<span class="snippet"><span>Comment</span><p>LLM-jp-3 <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1418" target="_blank" rel="noopener noreferrer">LLM-jp-3 1.8Bãƒ»3.7Bãƒ»13B ã®å…¬é–‹, LLM.jp, 2024.09</a>
 ã®å­¦ç¿’ã«åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚³ãƒ¼ãƒ‘ã‚¹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1414" target="_blank" rel="noopener noreferrer" class="title-link">Improving Language Understanding by Generative Pre-Training, OpenAI, 2018.06</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªç„¶è¨€èªç†è§£ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ãƒ©ãƒ™ãƒ«ãªã—ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ç”¨ã„ãŸç”Ÿæˆçš„äº‹å‰å­¦ç¿’ã¨è­˜åˆ¥çš„å¾®èª¿æ•´ã‚’è¡Œã†ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ã‚¿ã‚¹ã‚¯ã«å¿œã˜ãŸå…¥åŠ›å¤‰æ›ã‚’åˆ©ç”¨ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å¤‰æ›´ã‚’æœ€å°é™ã«æŠ‘ãˆã¤ã¤ã€12ã®ã‚¿ã‚¹ã‚¯ä¸­9ã¤ã§æœ€å…ˆç«¯ã®æˆæœã‚’å¤§å¹…ã«æ”¹å–„ã€‚ç‰¹ã«ã€å¸¸è­˜æ¨è«–ã§8.9%ã€è³ªå•å¿œç­”ã§5.7%ã€ãƒ†ã‚­ã‚¹ãƒˆã®å«æ„ã§1.5%ã®æ”¹å–„ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>åˆä»£GPTè«–æ–‡</p>
<p>æ—¥æœ¬èªè§£èª¬: 


<a href="https://qiita.com/Toyamanokinsan/items/adff5e927fe26148c69c" target="_blank" rel="noopener noreferrer">https://qiita.com/Toyamanokinsan/items/adff5e927fe26148c69c</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2024-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1390" target="_blank" rel="noopener noreferrer" class="title-link">OpenAI o1, 2024.09</a>
<span class="snippet"><span>Comment</span><p>Jason Weiæ°ã®ãƒã‚¹ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_jasonwei/status/1834278706522849788?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1072" target="_blank" rel="noopener noreferrer">Think before you speak: Training Language Models With Pause Tokens, Sachin Goyal+, N/A, ICLR'24</a>
<br><br>ã‚„<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1147" target="_blank" rel="noopener noreferrer">Implicit Chain of Thought Reasoning via Knowledge Distillation, Yuntian Deng+, N/A, arXiv'23</a>
<br><br>ã§ä¼¼ãŸã‚ˆã†ãªè€ƒãˆã¯ã™ã§ã«ææ¡ˆã•ã‚Œã¦ã„ãŸãŒã€ã©ã®ã‚ˆã†ãªç‚¹ãŒç•°ãªã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ<br><br><br><br>ãŸã¨ãˆã°å‰è€…ã¯ã€pauseãƒˆãƒ¼ã‚¯ãƒ³ã¨å‘¼ã°ã‚Œã‚‹outputã¨ã¯é–¢ä¿‚ãªã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€outputã‚’ç”Ÿæˆã™ã‚‹å‰ã«ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã§æ¨è«–ã™ã‚‹å‰ã«ã‚ˆã‚Šå¤šãã®ãƒ™ã‚¯ãƒˆãƒ«æ“ä½œã‚’åŠ ãˆã‚‹ï¼ˆ=ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç¸¦æ–¹å‘ã¨æ¨ªæ–¹å‘ã«æ··ãœåˆã‚ã›ã‚‹; ä»¥å¾Œãƒ™ã‚¯ãƒˆãƒ«ã‚’ã“ã­ãã‚Šã¾ã‚ã™ã¨å‘¼ç§°ã™ã‚‹ï¼‰ã€ã¨ã„ã£ãŸæŒ™å‹•ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã‚ˆã†ã ãŒã€æ˜ç¤ºçš„ã«CoTã®æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦SFTãªã©ã‚’ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã•ãã†ã«è¦‹ãˆã‚‹ï¼ˆã–ã£ãã‚Šã¨ã—ã‹èª­ã‚“ã§ãªã„ãŒï¼‰ã€‚<br><br>ä¸€æ–¹ã€Jason Weiæ°ã®ãƒã‚¹ãƒˆã‹ã‚‰ã¯ã€RLã§æ˜ç¤ºçš„ã«ã‚ˆã‚Šè‰¯ã„CoTãŒã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã‚’ã—ã¦ã„ã‚‹ç‚¹ãŒé•ã†ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p>
<p>**(2025.0929): ä»¥ä¸‹ã®test-time computeã«é–¢ã™ã‚‹ãƒ¡ãƒ¢ã¯o1ãŒå‡ºãŸå½“åˆã®ã‚‚ã®ã§ã‚ã‚Šã€ç§ã®ç†è§£ãŒç”˜ã„çŠ¶æ…‹ã§ã®ãƒ¡ãƒ¢ãªã®ã§ç¾åœ¨ã®ç†è§£ã‚’å¾Œã»ã©è¿½è¨˜ã—ã¾ã™ã€‚å½“æ™‚ã®ãƒ¡ãƒ¢ã¯æ”¹ã‚ã¦è¦‹è¿”ã™ã¨ã“ã‚“ãªã“ã¨è€ƒãˆã¦ãŸã‚“ã ãªãã¨ãŠã‚‚ã—ã‚ã‹ã£ãŸã®ã§æ®‹ã—ã¦ãŠãã¾ã™ã€‚**<br><br>å­¦ç¿’ã®è¨ˆç®—é‡ã ã‘ã§ãªãã€inferenceã®è¨ˆç®—é‡ã«å¯¾ã—ã¦ã‚‚ã€æ–°ãŸãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡ãŒè¦‹å‡ºã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br><img src="https://github.com/user-attachments/assets/85a39908-7db8-4f97-9b5d-4bfdc8439577" alt="image" loading="lazy"><br><br><br><br>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆä¸­ã§è¨€ã‚ã‚Œã¦ã„ã‚‹ time spent thinking ï¼ˆtest-time computeï¼‰ã¨ã„ã†ã®ã¯ã€å…·ä½“çš„ã«ã¯ä½•ãªã®ã ã‚ã†ã‹ã€‚<br><br><br><br>ä¸Šã®ç ”ç©¶ã§ã„ã†ã¨ã“ã‚ã®ã€inferenceæ™‚ã®pauseãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆã®ã‚ˆã†ãªã‚‚ã®ã ã‚ã†ã‹ã€‚ãƒ¢ãƒ‡ãƒ«ãŒãƒ™ã‚¯ãƒˆãƒ«ã‚’ã“ã­ãã‚Šå›ã™å›æ•°ï¼ˆã‚ã‚‹ã„ã¯ç”Ÿæˆã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼‰ãŒå¢—ãˆã‚‹ã¨æ€§èƒ½ã‚‚è‰¯ããªã‚‹ã®ã‹ï¼Ÿ<br><br>ã—ã‹ã—ãã‚Œã¯ã‚ªãƒªã‚¸ãƒŠãƒ«ã®CoTç ”ç©¶ã§ã‚ã‚‹<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
<br><br>ã®dotã®ã¿ã®æ–‡å­—åˆ—ã‚’promptã«è¿½åŠ ã—ã¦æ€§èƒ½ãŒå‘ä¸Šã—ãªã‹ã£ãŸã€ã¨ã„ã†çŸ¥è¦‹ã¨åã™ã‚‹ã€‚<br><br><br><br>ãŠãã‚‰ãã€**ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚ã«**ã€ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã“ã­ãã‚Šå›ã™å›æ•°ï¼ˆã‚ã‚‹ã„ã¯ç”Ÿæˆã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼‰ã‚’å¢—ã‚„ã™ã“ã¨ï¼time spent thinking (test-time compute) ã€ã¨ã„ã†ã“ã¨ãªã®ã ã‚ã†ã‹ï¼Ÿ<br><br>ãã—ã¦ãã®ã‚ˆã†ã«å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€æ¨è«–æ™‚ã«ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã“ã­ãã‚Šå›ã™å›æ•°ï¼ˆã‚ã‚‹ã„ã¯ç”Ÿæˆã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼‰ã‚’å¢—ã‚„ã™ã¨æ€§èƒ½ãŒä¸ŠãŒã‚‹ã€ã¨ã„ã†ã“ã¨ãªã®ã ã‚ã†ã‹ã€‚<br><br>ã‚‚ã—ãã†ã ã¨ã™ã‚‹ã¨ã€ã“ã‚Œã¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1072" target="_blank" rel="noopener noreferrer">Think before you speak: Training Language Models With Pause Tokens, Sachin Goyal+, N/A, ICLR'24</a>
<br><br>ã®pauseãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆã‚’ã—ãªãŒã‚‰finetuningã™ã‚‹ã¨æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã€ã¨ã„ã†ä¸»å¼µã¨ã‚‚åˆè‡´ã™ã‚‹ã‚ˆã†ã«æ€ã†ãŒã€ã†ãƒ¼ã‚“ã€‚<br><br><br><br>å®Ÿéš›æš—å·è§£èª­ã®exampleã‚’è¦‹ã‚‹ã¨ã€ã¨ã¦ã¤ã‚‚ãªãé•·ã„CoTï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆæ•°ãŒå¤šã„ï¼‰ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã€‚</p>
<p>RLã§Reasoningã‚’å­¦ç¿’ã•ã›ã‚‹é–¢é€£ç ”ç©¶: <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1391" target="_blank" rel="noopener noreferrer">ReFT: Reasoning with Reinforced Fine-Tuning, Trung Quoc Luong+, N/A, ACL'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1392" target="_blank" rel="noopener noreferrer">Training Large Language Models for Reasoning through Reverse Curriculum   Reinforcement Learning, Zhiheng Xi+, N/A, ICML'24</a>
</p>
<p>ä»¥ä¸‹o1ã®å‹•ãã«é–¢ã—ã¦è€ƒãˆã¦ã„ã‚‹ä¸‹è¨˜noteã‹ã‚‰ã®å¼•ç”¨ã€‚<br><br><br><br>&gt;ã“ã‚Œã«ã‚ˆã£ã¦ã€LLMã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚„ãƒ‡ãƒ¼ã‚¿é‡ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹æ™‚ä»£ã‹ã‚‰æ¨è«–æ™‚é–“ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ï¼ˆã¤ã¾ã‚Šã€æ²¢å±±ã®æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ¢ç´¢ã™ã‚‹ï¼‰æ™‚ä»£ã«ç§»ã£ã¦ã„ããã†ã§ã™ã€‚<br><br><br><br>ãªã‚‹ã»ã©ã€‚test-compute timeã¨ã¯ã€æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—æ•°ã¨ãã®æ¢ç´¢ã«è¦ã™ã‚‹æ™‚é–“ã¨ã„ã†è¦‹æ–¹ã‚‚ã‚ã‚‹ã®ã§ã™ã­ã€‚<br><br><br><br>ã¾ãŸnoteä¸­ã§ã¯ã€CoTã®æ€§èƒ½å‘ä¸Šã®ãŸã‚ã«ã€Process Reward Modelï¼ˆPRMï¼‰ã‚’å­¦ç¿’ã•ã›ã€LLMãŒç”Ÿæˆã—ãŸæ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’è©•ä¾¡ã§ãã‚‹ã‚ˆã†ã«ã—ã€PRMã‚’å ±é…¬ãƒ¢ãƒ‡ãƒ«ã¨ã—å¼·åŒ–å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒo1ãªã®ã§ã¯ãªã„ã‹ã€ã¨æ¨æ¸¬ã—ã¦ã„ã‚‹ã€‚<br><br>PRMã‚’ææ¡ˆã—ãŸç ”ç©¶ã§ã¯ã€æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«0,1ã®æ­£èª¤ãƒ©ãƒ™ãƒ«ãŒä»˜ä¸ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚<br><br>ãªã‚‹ã»ã©ã€å‹‰å¼·ã«ãªã‚Šã¾ã™ã€‚<br><br><br><br>note: 


<a href="https://note.com/hatti8/n/nf4f3ce63d4bc?sub_rt=share_pb" target="_blank" rel="noopener noreferrer">https://note.com/hatti8/n/nf4f3ce63d4bc?sub_rt=share_pb</a>


</p>
<p>noteï¼ˆè©³ç´°ç·¨ï¼‰:


<a href="https://note.com/hatti8/n/n867c36ffda45?sub_rt=share_pb" target="_blank" rel="noopener noreferrer">https://note.com/hatti8/n/n867c36ffda45?sub_rt=share_pb</a>


</p>
<p>ã“ã¡ã‚‰ã®ãƒªãƒã‚¸ãƒˆãƒªã«é–¢é€£è«–æ–‡ã‚„Xãƒã‚¹ãƒˆã€å…¬å¼ãƒ–ãƒ­ã‚°ãªã©ãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹: 


<a href="https://github.com/hijkzzz/Awesome-LLM-Strawberry" target="_blank" rel="noopener noreferrer">https://github.com/hijkzzz/Awesome-LLM-Strawberry</a>


<br><br>ã“ã‚Œã¯ã™ã”ã„ã€‚è«–æ–‡å…¨éƒ¨èª­ã¿ãŸã„</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Post.html" target="_blank" rel="noopener noreferrer">#Post</a>
<span class="issue_date">Issue Date: 2024-09-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1384" target="_blank" rel="noopener noreferrer" class="title-link">A few prompt engineering tips that Ilya Sutskever picked up at OpenAI, Ilya Sutskever, 2024.09</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1379" target="_blank" rel="noopener noreferrer" class="title-link">ml-engineering</a>
<span class="snippet"><span>Comment</span><p>LLMã‚„VLMã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã‚„ãƒã‚¦ãƒã‚¦ãŒã¾ã¨ã‚ã‚‰ã‚ŒãŸãƒªãƒã‚¸ãƒˆãƒª</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2024-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1376" target="_blank" rel="noopener noreferrer" class="title-link">Reflection 70B, GlaiveAI, 2024.09</a>
<span class="snippet"><span>Comment</span><p>ãŸã ã¾ã‚ä»®ã«åŒã˜Inputã‚’åˆ©ç”¨ã—ã¦ã„ãŸã¨ã—ã¦ã€promptingã¯åŒã˜ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ãªãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—æ¨è«–ã‚’å®Ÿæ–½ã™ã‚‹ã‹ã¯promptingã®ã‚¹ã‚³ãƒ¼ãƒ—ã§ã¯ãªã„ï¼‰ãªã®ã§ã€ãã‚‚ãã‚‚åŒã˜Inputãªã®ã§fair comparisonã§ã™ã‚ˆã€ã¨ã„ã†è©±ã«ä»®ã«ãªã‚‹ã®ã ã¨ã—ãŸã‚‰ã€ãã‚‚ãã‚‚ã©ã†ã„ã†è¨­å®šã§æ¯”è¼ƒå®Ÿé¨“ã™ã¹ãã‹?ã¨ã„ã†ã®ã¯æ¤œè¨ã—ãŸæ–¹ãŒè‰¯ã„æ°—ã¯ã™ã‚‹ã€‚ã¾ã‚ã©ã“ã«ç„¦ç‚¹ã‚’ç½®ãã‹æ¬¡ç¬¬ã ã¨æ€ã†ã‘ã©ã€‚<br><br>ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰è¦‹ãŸã‚‰ã€reflectionã®promptingã®ã‚„ã‚Šæ–¹ãªã‚“ã¦ã‚ã‹ã‚‰ãªã„ã‚ˆï¼ã¨ã„ã†äººã‚‚ã„ã‚‹ã¨æ€ã†ã®ã§ã€ãã‚Œã‚’å†…éƒ¨ã§è‡ªç™ºçš„ã«å®Ÿæ–½ã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã—ã¦æ˜ç¤ºçš„ã«promptingã—ãªãã¦ã‚‚ã€é«˜ã„æ€§èƒ½ã‚’é”æˆã§ãã‚‹ã®ã§ã‚ã‚Œã°æ„å‘³ãŒã‚ã‚‹ã¨æ€ã†ã€‚<br><br>ãŸã ã¾ã‚å°‘ãªãã¨ã‚‚ã€å‚è€ƒã§ã‚‚è‰¯ã„ã‹ã‚‰ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚reflectionã‚’ã™ã‚‹ã‚ˆã†ãªpromptingã‚’ã—ãŸæ€§èƒ½ã§ã®æ¯”è¼ƒçµæœã‚‚è¼‰ã›ã‚‹æ–¹ãŒè¦ªåˆ‡ã‹ãªã€ã¨ã¯æ€ã†ã€‚</p>
<p>ã‚ã¨ã€70Bã§ã“ã‚Œã»ã©ã®æ€§èƒ½ãŒå‡ºã¦ã„ã‚‹ã®ã¯ã“ã‚Œã¾ã§ã«ãªã„ã¨æ€ã†ã®ã§ã€ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦ã¯ãƒ‡ã‚£ãƒ•ã‚§ãƒ³ã‚¹ãŒå¿…è¦ã«æ€ã†ï¼ˆä»–ã®ãƒ¢ãƒ‡ãƒ«ãŒãã®ã‚ˆã†ãªãƒ‡ã‚£ãƒ•ã‚§ãƒ³ã‚¹ã‚’ã—ã¦ã„ã‚‹ã‹ã¯çŸ¥ã‚‰ãªã„ãŒï¼‰ã€‚<br><br>è¿½è¨˜<br>â†’ ä¸‹è¨˜è¨˜äº‹ã«ã‚ˆã‚‹ã¨ã€LLM Decontaminatorã‚’ç”¨ã„ã¦ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’é˜²ã„ã§ã„ã‚‹ã¨ã®ã“ã¨<br>


<a href="https://github.com/lm-sys/llm-decontaminator" target="_blank" rel="noopener noreferrer">https://github.com/lm-sys/llm-decontaminator</a>


</p>
<p>Reflectionè‡ªä½“ã®æœ‰ç”¨æ€§ã¯ä»¥å‰ã‹ã‚‰ç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚<br>å‚è€ƒ: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1377" target="_blank" rel="noopener noreferrer">Self-Reflection in LLM Agents: Effects on Problem-Solving Performance, Matthew Renze+, N/A, arXiv'24</a>
, <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1105" target="_blank" rel="noopener noreferrer">Self-RAG: Learning to Retrieve, Generate, and Critique through   Self-Reflection, Akari Asai+, N/A, ICLR'24</a>
, <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1248" target="_blank" rel="noopener noreferrer">AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls, Yu Du+, N/A, arXiv'24</a>
, <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1378" target="_blank" rel="noopener noreferrer">Automatically Correcting Large Language Models: Surveying the landscape  of diverse self-correction strategies, Liangming Pan+, N/A, TACL'24</a>
</p>
<p>ollamaã§å®Ÿéš›ã«å‹•ã‹ã—ã¦æ—¥æœ¬èªã§ã®QAã‚’è©¦ã—ã¦ã„ã‚‹è¨˜äº‹ã€‚å®Ÿéš›ã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚„reflectionã®å†…å®¹ãŒç¢ºèªã§ãã€ãŠã‚‚ã—ã‚ã„ã€‚<br><br>ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§&lt; thinking &gt;ã‚¿ã‚°ã§Inputã«å¯¾ã—ã¦æ¨è«–ã—ã€&lt; output &gt;ã‚¿ã‚°å†…ã§æœ€çµ‚å‡ºåŠ›ã‚’è¡Œã„ã€æ¨è«–éç¨‹ã§èª¤ã‚ŠãŒã‚ã‚‹å ´åˆã¯&lt; reflection &gt;ã‚¿ã‚°ã‚’ç”¨ã„ã¦ä¿®æ­£ã™ã‚‹ã‚ˆã†ã«æŒ‡ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br>ãŠãã‚‰ãã€thinkingã‚¿ã‚°å†…ã®æ€è€ƒéç¨‹ã§ãƒ¢ãƒ‡ãƒ«ãŒèª¤ã‚Šã«æ°—ã¥ã„ãŸå ´åˆã¯ã€thinkingã‚¿ã‚°ã®é€”ä¸­ã§reflectionã‚¿ã‚°ãŒå‡ºåŠ›ã•ã‚Œã€ãã®æ™‚ç‚¹ã§CoTãŒä¿®æ­£ã•ã‚Œã‚‹ã‚ˆã†ã§ã‚ã‚‹ï¼ˆã‚‚ã—ãã¯outputã¨thinkingã®ä¸­é–“ï¼‰ã€‚ã“ã®ãŸã‚ã€èª¤ã£ãŸCoTã«åŸºã¥ã„ã¦OutputãŒç”Ÿæˆã•ã‚Œã‚‹é »åº¦ãŒæ¸›å°‘ã™ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><br>ã“ã®ã‚ˆã†ãªæŒ™å‹•ã¯ãŠãã‚‰ãã€reflectionç”¨ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§SFTã—ãªã„ã¨ã§ããªã„ã¨æ€ã†ã®ã§<br><br>ï¼ˆãŸã¨ãˆã°ã€Reflectionã‚¿ã‚¹ã‚¯ã‚’ã™ã‚‹ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã§SFTã‚’ã—ã¦ã„ãªã„å ´åˆã€å‡ºåŠ›ã®é€”ä¸­ã§èª¤ã‚Šã‚’æ¤œå‡ºã—å‡ºåŠ›ã‚’ä¿®æ­£ã™ã‚‹ã¨ã„ã†æŒ™å‹•ã«ã¯ãªã‚‰ãšã€å›ç­”ã¨ã—ã¦è‡ªç„¶ãªæ–‡ã‚’æœ€å¾Œã¾ã§outputã™ã‚‹ã¨æ€ã†ã€‚ãã®å¾Œã§reflectionã—ã‚ã¨ä¿ƒã™ã“ã¨ã¯promptingã§ã§ãã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãŒã€ãã‚‚ãã‚‚reflectionã™ã‚‹èƒ½åŠ›ãŒã‚ã¾ã‚Šé«˜ããªã„å¯èƒ½æ€§ãŒã‚ã‚Šã€ã†ã¾ãä¿®æ­£ã‚‚ã—ã¦ãã‚Œãªã„ã‹ã‚‚ï¼‰<br><br>reflectionã®èƒ½åŠ›ã‚’é«˜ã‚ã‚‹ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã§SFTã‚’ã—ã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«ã§ä¼¼ãŸã‚ˆã†ãªpromptingã‚’ã—ã¦ã‚‚ã€ã†ã¾ãã„ã‹ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§æ³¨æ„ãŒå¿…è¦ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>å‚è€ƒ: 


<a href="https://note.com/schroneko/n/nae86e5d487f1" target="_blank" rel="noopener noreferrer">https://note.com/schroneko/n/nae86e5d487f1</a>


</p>
<p>é–‹ç™ºè€…æ›°ãã€HFã«è¨˜è¼‰ã®æ­£ã—ã„ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥ã‚Œãªã„ã¨ã€é©åˆ‡ã«å‹•ä½œã—ãªã„ã¨ã®ã“ã¨ã€‚<br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mattshumer_/status/1832061508294971731?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã©ã†ã‚„ã‚‰åˆæœŸã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãŸHFã®ãƒ¢ãƒ‡ãƒ«ã¯weightã«èª¤ã‚ŠãŒã‚ã‚Šã€æŒ™å‹•ãŒãŠã‹ã—ããªã£ã¦ã„ãŸã‚ˆã†ã ã€‚<br>æ­£ã—ã„ãƒ¢ãƒ‡ãƒ«ã®æŒ™å‹•ã¯ä¸‹è¨˜ãƒ„ã‚¤ãƒ¼ãƒˆã®ã‚ˆã†ã§ã‚ã‚‹ã€‚thinkingå†…ã§reflectionãŒå®Ÿæ–½ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>å®Ÿéš›ã«ã„ãã¤ã‹ã®ä¾‹ã‚’ãƒ–ãƒ­ã‚°ã‚’ãƒªãƒªãƒ¼ã‚¹å½“æ—¥ã«è¦‹ãŸæ™‚ã«ã€reflectionã‚¿ã‚°ãŒoutputã®å¾Œã«å‡ºåŠ›ã•ã‚Œã¦ã„ã‚‹ä¾‹ãªã©ãŒã‚ã‚Šã€ãŠã‚„ï¼Ÿã¨ã„ã†æŒ™å‹•ã‚’ã—ã¦ã„ãŸã®ã§ã€å•é¡ŒãŒæ˜¯æ­£ã•ã‚ŒãŸã‚ˆã†ã ã€‚<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mattshumer_/status/1832581211841052694?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HFã®ãƒ¢ãƒ‡ãƒ«ãŒä¿®æ­£ã•ã‚ŒãŸå¾Œã‚‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµæœãŒå†ç¾ã•ã‚Œãªã„ãªã©ã€é›²è¡ŒããŒè‰²ã€…ã¨æ€ªã—ã„ã®ã§æ³¨æ„ã—ãŸæ–¹ãŒè‰¯ã„ã€‚</p>
<p>ç¶šå ±<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1832965630472995220?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–‹ç™ºè€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/csahil28/status/1833619624589725762?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å†ç¾å®Ÿé¨“ã‚’å…¨ã¦çµ‚äº†ã—ã€å½“åˆå ±å‘Šã—ã¦ã„ãŸçµæœãŒå†ç¾ã•ã‚Œãªã‹ã£ãŸã¨CEOãŒå£°æ˜ï¼š



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mattshumer_/status/1842313328166907995"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1375" target="_blank" rel="noopener noreferrer" class="title-link">Ruri: Japanese General Text Embeddings, cl-nagoya, 2024.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hpp_ricecake/status/1831308092459643232?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>337Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã§ã€åŒç­‰ã®ã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã‚’JMTEBã§å¤§ããä¸Šå›ã‚‹æ€§èƒ½ã€‚LLMã‚’ç”¨ã„ã¦ç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦Contrastive Learning, ãã®å¾Œé«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã§Finetuningã‚’å®Ÿæ–½ã—ãŸã¨ã®ã“ã¨ã€‚</p>
<p>JMTEBä¸Šã§ã¯ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºä¸æ˜ï¼ˆã ãŒãŠãã‚‰ãæ¡é•ã„ã«å¤§ãã„ï¼‰ã®OpenAI/text-embedding-3-largeã¨åŒç­‰ã®æ€§èƒ½ã«è¦‹ãˆã‚‹ãŒã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1373" target="_blank" rel="noopener noreferrer">LLMã«æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’å­¦ç¿’ã•ã›ã‚‹æ„ç¾©, Koshiro Saito+, ç¬¬261å›è‡ªç„¶è¨€èªå‡¦ç†ç ”ç©¶ç™ºè¡¨ä¼š, 2024.08</a>
 ãªã©ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€æ—¥æœ¬ç‰¹æœ‰ã®çŸ¥è­˜ã‚’å•ã†QAãªã©ã¯ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãªãƒ¢ãƒ‡ãƒ«ã¯å¼±ãã†ãªã®ã§ã€ãã®è¾ºãŒã©ã‚Œã»ã©é«˜ã„æ€§èƒ½ã‚’æŒã£ã¦ã„ã‚‹ã®ã‹ã¯èˆˆå‘³ãŒã‚ã‚‹ã€‚<br><br>LLMã§äººå·¥çš„ã«ç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã§ã¯ã€ç”Ÿæˆã«åˆ©ç”¨ã—ãŸLLMãŒæŒã¤çŸ¥è­˜ã—ã‹è¡¨å±¤çš„ã«ã¯ç¾ã‚Œãªã„ã¨æ€ã†ã®ã§ä½•ã‚’åˆ©ç”¨ã—ãŸã‹ã«ã‚ˆã‚‹ã®ã¨ã€é«˜å“è³ªãªãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿ã«ãã®è¾ºãŒã©ã®ç¨‹åº¦å«ã¾ã‚Œã¦ã„ã‚‹ã‹ã€‚</p>
<p>æœ€å¤§sequenceé•·ã¯1012ãªã®ã§ã€ã‚ˆã‚Šé•·ã„ç³»åˆ—ã‚’BERTã§åŸ‹ã‚è¾¼ã¿ãŸã„å ´åˆã¯RetrievaBERT  <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1323" target="_blank" rel="noopener noreferrer">RetrievaBERTã®å…¬é–‹, 2024</a>
 ï¼ˆæœ€å¤§sequenceé•·2048ï¼‰ã‚‚æ¤œè¨ã®ä½™åœ°ãŒã‚ã‚‹ã€‚</p>
<p>é–‹ç™ºè€…ã®æ–¹ã‹ã‚‰ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆãŒå‡ºãŸ<br>


<a href="https://arxiv.org/abs/2409.07737" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2409.07737</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1373" target="_blank" rel="noopener noreferrer" class="title-link">LLMã«æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’å­¦ç¿’ã•ã›ã‚‹æ„ç¾©, Koshiro Saito+, ç¬¬261å›è‡ªç„¶è¨€èªå‡¦ç†ç ”ç©¶ç™ºè¡¨ä¼š, 2024.08</a>
<span class="snippet"><span>Comment</span><p>è‹±æ—¥ç¿»è¨³ã‚„æ—¥æœ¬ç‰¹æœ‰ã®çŸ¥è­˜ã‚’å•ã‚ã‚Œã‚‹ã‚ˆã†ãªQAã«ãŠã„ã¦ã€æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹å­¦ç¿’ã®åŠ¹æœãŒã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br>ãŸã¨ãˆã°ã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1359" target="_blank" rel="noopener noreferrer">è«–æ–‡ç´¹ä»‹ / The Llama 3 Herd of Models, 2024.08</a>
 ã«ç¤ºã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€Llama2ã«ãŠã‘ã‚‹æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã®å‰²åˆã¯0.2%ã¨ã‹ãªã®ã§ã€è‹±èªåœã®OpenLLMã«ãŠã„ã¦ã€æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã®æ¯”ç‡ãŒã©ã‚Œã ã‘å°‘ãªã„ã‹ãŒã‚ã‹ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2024-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1370" target="_blank" rel="noopener noreferrer" class="title-link">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« ï¼ˆLLMï¼‰ ã®æŠ€è¡“ã¨æœ€æ–°å‹•å‘, Ikuya Yamada, 2024.06</a>
<span class="snippet"><span>Comment</span><p>LLMã®åŸç†ã®åŸºç¤çš„ãªå†…å®¹ã«ã¤ã„ã¦ã€ä¸å¯§ã‹ã¤ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«ã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚<br><br><br><br>&gt;ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯æ–°ã—ã„çŸ¥è­˜ã®å­¦ç¿’ã§ã¯ãªãçŸ¥è­˜ã®ä½¿ã„æ–¹ã‚’å­¦ç¿’ã•ã›ã‚‹ã®ã«å‘ã„ã¦ã„ã‚‹<br><br><br><br>ã“ã‚Œã‚’ãã¡ã‚“ã¨å¿µé ­ã«ç½®ã„ã¦ãŠã‹ãªã„ã¨è½ã¨ã—ç©´ã«ãƒãƒã‚‹ã¨æ€ã†ã€‚å¼•ç”¨å…ƒã®è«–æ–‡èª­ã¿ãŸã„(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1371" target="_blank" rel="noopener noreferrer">Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?, Zorik Gekhman+, N/A, EMNLP'24</a>
)ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<span class="issue_date">Issue Date: 2024-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1368" target="_blank" rel="noopener noreferrer" class="title-link">NanoFlow, 2024.08</a>
<span class="snippet"><span>Comment</span><p>vLLMã‚ˆã‚Šã‚‚2å€ç¨‹åº¦é«˜é€ŸãªLLM serving frameworkã€‚<br><br>ã‚ªãƒ•ãƒ©ã‚¤ãƒ³è©•ä¾¡<br><img src="https://github.com/user-attachments/assets/93d8362d-e0e4-4bdb-9de4-178e1eef2e33" alt="image" loading="lazy"><br><br>ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ã®latencyè©•ä¾¡<br><img src="https://github.com/user-attachments/assets/506ebf39-9c47-4d11-9352-c26f6b0d155c" alt="image" loading="lazy"><br><br>æ©Ÿèƒ½ã¯vLLMã®æ–¹ãŒå¤šã„ãŒã€é€Ÿåº¦ã¯ã“ã¡ã‚‰ã®æ–¹ãŒã‹ãªã‚Šé€Ÿãã†ã§ã¯ã‚ã‚‹ã€‚latencyã®requirementãŒå³ã—ã„å ´åˆãªã©ã¯æ¤œè¨ã—ã¦ã‚‚è‰¯ã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚<br><br>ã—ã‹ã—LLM serving frameworkã‚‚ç¾¤é›„å‰²æ‹ ã§ã™ã­ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rohanpaul_ai/status/1829647702998606104?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1343" target="_blank" rel="noopener noreferrer">DeepSpeed, vLLM, CTranslate2 ã§ rinna 3.6b ã®ç”Ÿæˆé€Ÿåº¦ã‚’æ¯”è¼ƒã™ã‚‹, 2024.06</a>
 ã‚‚å‚ç…§ã®ã“ã¨</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1366" target="_blank" rel="noopener noreferrer" class="title-link">Firecrawl, 2024.09</a>
<span class="snippet"><span>Comment</span><p>sitemapãªã—ã§Webã‚µã‚¤ãƒˆå…¨ä½“ã‚’ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã§ãã‚‹APIã€‚LLMã§åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚„ã€æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã‚‚ã—ã¦ãã‚Œã‚‹æ¨¡æ§˜ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2024-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1359" target="_blank" rel="noopener noreferrer" class="title-link">è«–æ–‡ç´¹ä»‹ _ The Llama 3 Herd of Models, 2024.08</a>
<span class="snippet"><span>Comment</span><p>Llama3ã®äº‹å‰å­¦ç¿’ã‚„äº‹å¾Œå­¦ç¿’ã®ãƒã‚¦ãƒã‚¦ãŒè©°ã¾ã£ã¦ãŠã‚Šï¼ˆå®‰å…¨æ€§ãªã©ã‚‚å«ã‚€ï¼‰ã€LLMå­¦ç¿’ã«å¿…è¦ãªè¦ç´ ãŒå›³è§£ã•ã‚Œã¦ãŠã‚Šã€éå¸¸ã«åˆ†ã‹ã‚Šã‚„ã™ã„ã€‚<br><br><br><br>ãŸã¨ãˆã°ä¸‹è¨˜å›³ï¼ˆã‚¹ãƒ©ã‚¤ãƒ‰ä¸­ã‚ˆã‚Šå¼•ç”¨ï¼‰ãªã©ã¯ã€LLMã®å­¦ç¿’éç¨‹ã‚’èª¬æ˜ã™ã‚‹éš›ã«ã‚ã‹ã‚Šã‚„ã™ãã†<br><br><img src="https://github.com/user-attachments/assets/501ae2ae-cfc6-46ab-9701-c860b9a52dc3" alt="image" loading="lazy"><br><br></p>
<p>LLMã®äº‹å‰ãƒ»äº‹å¾Œå­¦ç¿’ã‚ãŸã‚Šã¯ç‹¬è‡ªãƒã‚¦ãƒã‚¦ãŒå¤šã™ãã¦ã‚‚ã¯ã‚„è¿½å¾“å›°é›£</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1356" target="_blank" rel="noopener noreferrer" class="title-link">Liger-Kernel, 2024.08</a>
<span class="snippet"><span>Comment</span><p>LLMã‚’å­¦ç¿’ã™ã‚‹æ™‚ã«ã€ãƒ¯ãƒ³ãƒ©ã‚¤ãƒ³è¿½åŠ ã™ã‚‹ã ã‘ã§ã€ãƒãƒ«ãƒGPUãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’20%æ”¹å–„ã—ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’60%å‰Šæ¸›ã™ã‚‹ã‚‰ã—ã„<br><br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hsu_byron/status/1827072737673982056?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã ã‘ã§ã„ã„<br><img src="https://github.com/user-attachments/assets/abce24ed-f979-43db-ac51-e850f2ae877a" alt="image" loading="lazy"></p>
<p>Unsloth <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1450" target="_blank" rel="noopener noreferrer">Unsloth</a>
 ã¯LoRA/QLoRAãŒå¯èƒ½ãªä¸€æ–¹ã§ã¾ã Multi-GPUã¯ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ã€‚ä¸€æ–¹ã€Liger-Kernelã¯LoRAã‚ˆã‚Šã‚‚full-parameter tuningã¨Multi-GPUã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦ãŠã‚Šã€ç›®çš„ã«å¿œã˜ã¦ä½¿ã„åˆ†ã‘ãŒå¿…è¦ã€‚<br><br><br><br>


<a href="https://github.com/linkedin/Liger-Kernel/issues/57" target="_blank" rel="noopener noreferrer">https://github.com/linkedin/Liger-Kernel/issues/57</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2024-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1355" target="_blank" rel="noopener noreferrer" class="title-link">Grok-2, X, 2024.08</a>
<span class="snippet"><span>Comment</span><p>chatbot arenaã§5æœˆæ™‚ç‚¹ã®GPT4oè¶…ãˆã€‚miniã§ã‚‚ãªã‚“ã¨llama3.1-705Bè¶…ãˆ<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lmsysorg/status/1827041269534879784?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-08-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1348" target="_blank" rel="noopener noreferrer" class="title-link">RAGå…¥é–€: ç²¾åº¦æ”¹å–„ã®ãŸã‚ã®æ‰‹æ³•28é¸, 2024.08</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1347" target="_blank" rel="noopener noreferrer" class="title-link">PLaMo-100B, PFN, 2024.08</a>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§GPT4ã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’é”æˆã€‚<br>SFT, DPOã§å­¦ç¿’ã€‚å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯ã€Publicãªã‚‚ã®ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ä½œæˆã—ãŸã‚‚ã®ã€LLMè‡ªèº«ã«ä½œæˆã•ã›ãŸã‚‚ã®ã‚’åˆ©ç”¨ã—ãŸã€‚ã¾ãŸã€æœ€çµ‚çš„ãªãƒ¢ãƒ‡ãƒ«ã«è¤‡æ•°ã®å€™è£œãŒã‚ã£ãŸã®ã§ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã§è‰¯ã„ã¨ã“ã‚å–ã‚Šã‚’ã—ãŸã€‚DPOã§åˆ©ç”¨ã™ã‚‹preferenceãƒ‡ãƒ¼ã‚¿ã¯ã€äº‹å¾Œå­¦ç¿’é€”ä¸­ã®ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦è‡ªå‹•ç”Ÿæˆã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-07-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1335" target="_blank" rel="noopener noreferrer" class="title-link">Llama 3.1, 2024.07</a>
<span class="snippet"><span>Comment</span><p>Llamaç³»ã®ãƒ¢ãƒ‡ãƒ«ã‚’FP8ã§å­¦ç¿’ã™ã‚‹å ´åˆã®ãƒ¬ã‚·ãƒ”<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thom_wolf/status/1826924774997532799?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1334" target="_blank" rel="noopener noreferrer" class="title-link">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é–‹ç™º, 2024</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-07-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1330" target="_blank" rel="noopener noreferrer" class="title-link">calm3-22B, 2024</a>
<span class="snippet"><span>Comment</span><p>&gt;LLMã®æ—¥æœ¬èªèƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹Nejumi LLM ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰3ã«ãŠã„ã¦ã¯ã€700å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®Meta-Llama-3-70B-Instructã¨åŒç­‰ã®æ€§èƒ½ã¨ãªã£ã¦ãŠã‚Šã€ã‚¹ã‚¯ãƒ©ãƒƒãƒé–‹ç™ºã®ã‚ªãƒ¼ãƒ—ãƒ³ãªæ—¥æœ¬èªLLMã¨ã—ã¦ã¯ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®æ€§èƒ½ã¨ãªã‚Šã¾ã™ï¼ˆ2024å¹´7æœˆç¾åœ¨ï¼‰ã€‚<br>ãƒ¢ãƒ‡ãƒ«ã¯å•†ç”¨åˆ©ç”¨å¯èƒ½ãªApache License 2.0ã§æä¾›ã•ã‚Œã¦ãŠã‚Š<br><br>ã“ã‚Œã¯ã™ã”ã„</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-07-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1327" target="_blank" rel="noopener noreferrer" class="title-link">GENIAC: 172B äº‹å‰å­¦ç¿’çŸ¥è¦‹, 2024</a>
<span class="snippet"><span>Comment</span><p>LLMã®äº‹å‰å­¦ç¿’ã«ãŠã‘ã‚‹çŸ¥è¦‹ãŒã¾ã¨ã¾ã£ã¦ã„ã‚‹è¨˜äº‹ã¨ã®ã“ã¨</p>
<p>ãƒ»Megatron LMã§å­¦ç¿’<br>ã€€â†’ 3D Parallelismãªã©ã®åˆ†æ•£å­¦ç¿’æ‰‹æ³•ã«ã‚ˆã‚ŠHF Trainerã‚ˆã‚Šé«˜é€Ÿ<br>ã€€â†’ Data Parallelimã€Tensor Parallelismã€ Pipeline Parallelismã‚’çµ„ã¿åˆã‚ã›ãŸã‚‚ã®<br>ãƒ»GPUãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã€ä¸è‰¯ã§å­¦ç¿’ãŒç¶™ç¶šã§ããªã‹ã£ãŸå ´åˆã¯checkpointã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦å­¦ç¿’<br>ãƒ»å­¦ç¿’æ›²ç·šãŒå®‰å®šã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ãŒSpikeã¯ç™ºç”Ÿã—ã¦ã„ã‚‹ã€‚ç™ºç”Ÿæ™‚ã¯gradient normãŒæ€¥æ¿€ã«ä¸Šæ˜‡ã™ã‚‹<br>ãƒ»Llamaãªã©ã®LLMã‹ã‚‰ã®ç¶™ç¶šçš„äº‹å‰å­¦ç¿’ã§ã¯ãªãfrom scratchã‹ã‚‰å­¦ç¿’ã—ã¦ã„ã‚‹ã®ã§é€æ˜æ€§ãŒé«˜ã„<br>ãƒ»Transformer engineã‚’åˆ©ç”¨<br>ãƒ»AdamWã‚’åˆ©ç”¨<br>ãƒ»attention dropout, hidden dropoutã¯0.0<br><br>&gt;ã“ã®éš›ã€ é€šä¿¡ã‚’å¤šãå¿…è¦ã¨ã™ã‚‹åˆ†æ•£æ‰‹æ³•ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆTensor Parallelãƒ¯ãƒ¼ã‚«ãƒ¼ï¼‰ã¯ãƒãƒ¼ãƒ‰å†…ã«é…ç½®ã™ã‚‹ã‚ˆã†ã«Megatron-LMã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ãªã£ã¦ã„ã‚‹ãŸã‚ã€ä»Šå›ã‚‚ãã‚Œã‚’åˆ©ç”¨ã—ã¾ã—ãŸã€‚ã“ã®ã‚ˆã†ã«ã™ã‚‹ç†ç”±ã¯ã€ãƒãƒ¼ãƒ‰å†…ã®é€šä¿¡ã¯NVLinkã«ã‚ˆã‚Šã€ãƒãƒ¼ãƒ‰é–“é€šä¿¡ã‚ˆã‚Šã‚‚é«˜é€Ÿã§ã‚ã‚‹ãŸã‚ã§ã™ã€‚ã¾ãŸã€Data Parallelã®å‹¾é…å¹³å‡åŒ–ã®ãŸã‚ã®é€šä¿¡ã‚’è€ƒæ…®ã—ã¦ã€Data Parallelãƒ¯ãƒ¼ã‚«ãƒ¼ã‚‚å¯èƒ½ãªé™ã‚Šãƒãƒ¼ãƒ‰å†…ã«é…ç½®ã™ã‚‹Megatron-LMãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æŒ™å‹•ã‚’åˆ©ç”¨ã—ã¾ã—ãŸã€‚<br>Pipeline Parallelismã¯ä»–ã®ä¸¦åˆ—åŒ–æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦é€šä¿¡é‡ãŒå°‘ãªã„P2P(Point-to-Point)é€šä¿¡ã§ã‚ã‚‹ãŸã‚ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¹ãƒ†ãƒ¼ã‚¸ã¯ãƒãƒ¼ãƒ‰é–“ã§é…ç½®ã™ã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸã€‚ã“ã‚Œã‚‚ã€Megatron-LMãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æŒ™å‹•ã§ã™ã€‚<br><br>å‹‰å¼·ã«ãªã‚‹<br><br>ãƒ»é€šå¸¸ã®ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—ã¯optimizer stateã‚’workeré–“ã§è¤‡è£½ã™ã‚‹ã®ã§é…ã„ã€‚Deep Speed Zero 1ã®ã‚ˆã†ã«åˆ†æ•£ã—ã¦ä¿æœ‰ã™ã‚‹ã“ã¨ã§é«˜é€ŸåŒ–<br>ãƒ»Tensor Parallelã§self attention, MLPã®è¨ˆç®—ã‚’ä¸¦åˆ—åŒ–ã§ãã‚‹<br>ãƒ»LayerNormalization, Dropoutã®æ¼”ç®—ã‚‚ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®è¦³ç‚¹ã‹ã‚‰ä¸¦åˆ—åŒ–<br>ãƒ»å­¦ç¿’ã‚’å®‰å®šã•ã›ã‚‹ãŸã‚ã«z-lossã‚’åˆ©ç”¨<br>ãƒ»batch skippingã¨ã¯ã€gradient clippingã‚’è¡Œã£ã¦ã„ã¦ã‚‚ãªãŠspikeãŒç”Ÿã˜ã‚‹å ´åˆã«ã€100 stepå‰ã«æˆ»ã‚Šã€spikeãŒç”Ÿã˜ãŸä»˜è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ•°ç™¾iterationç¨‹åº¦ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã“ã¨<br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1325" target="_blank" rel="noopener noreferrer" class="title-link">OpenDevin: Code Less, Make More, 2024</a>
<span class="snippet"><span>Comment</span><p>LLMã«ã‚ˆã‚‹OpenSourceãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ </p>
<p>full timeã®ã‚¹ã‚¿ãƒƒãƒ•ã‚’é›‡ç”¨ã—worldã‚¯ãƒ©ã‚¹ã®UXã‚’ç›®æŒ‡ã™ã¨ã®ã“ã¨ã€‚æ¥½ã—ã¿ã€‚<br>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1808493521315496229?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenåŒ–ã•ã‚Œã‚‹å‰ã®æœ€åˆã®Devinã®ãƒ„ã‚¤ãƒ¼ãƒˆ<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cognition_labs/status/1767548763134964000"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2024-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1324" target="_blank" rel="noopener noreferrer" class="title-link">ã‚ˆã‚Šè‰¯ã„Transformerã‚’ã¤ãã‚‹, Shun Kiyono, 2022</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2024-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1323" target="_blank" rel="noopener noreferrer" class="title-link">RetrievaBERTã®å…¬é–‹, 2024</a>
<span class="snippet"><span>Comment</span><p>RAGã¸å¿œç”¨ã™ã‚‹éš›ã«ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ‰±ã„Embeddingã‚’ç²å¾—ã—ãŸã„ã‚·ãƒ¼ãƒ³ãŒå¢—ãˆãŸã®ã§ã€æœ€å¤§ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ãŒ2048ã®BERTã‚’å­¦ç¿’ã—å…¬é–‹ã€‚Apache2.0<br><br><br><br>ã‚ªãƒªã‚¸ãƒŠãƒ«ã®BERTã¨æ¯”è¼ƒã—ã¦ã€è¿‘å¹´ã®LLMã§æœ‰ç”¨æ€§ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ä»¥ä¸‹ã‚’ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«å–ã‚Šå…¥ã‚Œã¦ã„ã‚‹<br><br>- SwiGLUæ´»æ€§åŒ–é–¢æ•° <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1311" target="_blank" rel="noopener noreferrer">GLU Variants Improve Transformer, Noam Shazeer, N/A, arXiv'20</a>
 <br><br>- PreNorm <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1324" target="_blank" rel="noopener noreferrer">ã‚ˆã‚Šè‰¯ã„Transformerã‚’ã¤ãã‚‹, Shun Kiyono, 2022</a>
 <br><br>- Grouped Query Attention (Multi Query Attention) <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
 </p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1322" target="_blank" rel="noopener noreferrer" class="title-link">Llama 3 Swallow</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<span class="issue_date">Issue Date: 2024-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1310" target="_blank" rel="noopener noreferrer" class="title-link">RoFormer: Enhanced Transformer with Rotary Position Embedding, Jianlin Su+, N_A, Neurocomputing, 2024</a>
<span class="snippet"><span>GPT Summary</span>- ä½ç½®ç¬¦å·åŒ–ã¯transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§æœ‰åŠ¹ã§ã‚ã‚Šã€æœ¬è«–æ–‡ã§ã¯Rotary Position Embeddingï¼ˆRoPEï¼‰ã¨ã„ã†æ–°ã—ã„æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚RoPEã¯ã€å›è»¢è¡Œåˆ—ã‚’ä½¿ç”¨ã—ã¦çµ¶å¯¾ä½ç½®ã‚’ç¬¦å·åŒ–ã—ã€åŒæ™‚ã«ç›¸å¯¾ä½ç½®ä¾å­˜æ€§ã‚’è‡ªå·±æ³¨æ„æ§‹æˆã«çµ„ã¿è¾¼ã‚€ã€‚RoPEã‚’ä½¿ç”¨ã—ãŸRoFormerã¯ã€é•·ã„ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ä»–ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒå®Ÿé¨“ã§ç¤ºã•ã‚Œã¦ãŠã‚Šã€Huggingfaceã«çµ±åˆã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>RoPEã‚’ææ¡ˆã—ãŸè«–æ–‡</p>
<p># Absolute Position Embedding ã¨ Relative Position Embedding<br><br>## Transformerã«ãŠã‘ã‚‹QKVãƒ™ã‚¯ãƒˆãƒ«ã®è¨ˆç®—æ–¹æ³•<br><br>ä¸€èˆ¬ã«ã€Transformerã«ãŠã‘ã‚‹ Query (Q), Key (K), Value (V) ã¯ä»¥ä¸‹ã®å¼ã§å®šå¼åŒ–ã•ã‚Œã‚‹ï¼š<br><br>&lt;img width="176" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/21b0f077-64b4-4fe5-af04-bffc373eabf5"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/21b0f077-64b4-4fe5-af04-bffc373eabf5"&lt;/a&gt;


&gt;<br><br>m, nã¯ãã‚Œãã‚Œä½ç½®ã‚’è¡¨ã™æ•´æ•°ã€‚Absolute Position Embeddingã¨ã€Relative Position Embeddingã¯ã€é–¢æ•°fã®è¨­è¨ˆãŒãã‚Œãã‚Œç•°ãªã£ã¦ã„ã‚‹ï¼š<br><br><br><br>## Absolute Position Embedding<br><br>absolute position embeddingã¯ã€å›ºå®šã•ã‚ŒãŸposition ãƒ™ã‚¯ãƒˆãƒ«ã€ã‚ã‚‹ã„ã¯trainableãªposition ãƒ™ã‚¯ãƒˆãƒ«pã‚’ã€å…¥åŠ›ãƒ™ã‚¯ãƒˆãƒ«ã«å¯¾ã—ã¦è¶³ã—åˆã‚ã›ã‚‹ï¼š<br><br>&lt;img width="382" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/0688c1bf-8699-48a5-9d95-06454550bbdf"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0688c1bf-8699-48a5-9d95-06454550bbdf"&lt;/a&gt;


&gt;<br><br><br><br>## Relative Position Embedding<br><br>ä¸€æ–¹ã€Relative Position Embeddingã¯ã€Queryã®ä½ç½®ã«å¯¾ã™ã‚‹ã€Key, Valueã®ç›¸å¯¾ä½ç½®ï¼ˆã¤ã¾ã‚Šã€mã¨nã®å·®ï¼‰ã«å¯¾ã—ã¦ã€trainableãªãƒ™ã‚¯ãƒˆãƒ« \tilde{p}_r ã‚’Key, ValueãŠã‚ˆã³ç›¸å¯¾è·é›¢rã”ã¨ã«ç”¨æ„ã—ã€ãã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’å…¥åŠ›ã«è¶³ã—åˆã‚ã›ã‚‹ã€ã¨ã„ã†å®šå¼åŒ–ã¨ãªã£ã¦ã„ã‚‹ï¼š<br><br><br>&lt;img width="269" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/ddb92f1a-af23-4d71-a7b9-2a7adda792e1"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/ddb92f1a-af23-4d71-a7b9-2a7adda792e1"&lt;/a&gt;


&gt;<br><br><br>ã“ã“ã§ã€r = clip(m-n, r_max, r_min)ã§ã‚ã‚Šã€r_max, r_minã¯è€ƒæ…®ã™ã‚‹ç›¸å¯¾è·é›¢ã®æœ€å¤§å€¤ã¨æœ€å°å€¤ã§ã‚ã‚‹ã€‚<br><br>ä»–ã«ã‚‚æ§˜ã€…ãªå®šå¼åŒ–ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ãŒãŸã„ã¦ã„å®šå¼åŒ–ã®ä¸­ã«ç›¸å¯¾ä½ç½®m-nãŒå‡ºç¾ã™ã‚‹ã€‚<br><br><br>## RoPE<br><br>RoPEã§ã¯ã€å…¥åŠ›ãƒ™ã‚¯ãƒˆãƒ«(Q,K)ã«å¯¾ã—ã¦å›è»¢è¡Œåˆ—ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã€å›è»¢ã«å¯¾ã—ã¦ä½ç½®æƒ…å ±ã‚’ä¿æŒã•ã›ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€ç•°ãªã‚‹ä½ç½®m, nã«å¯¾ã™ã‚‹q_m^T k_nã‚’è¨ˆç®—ã™ã‚‹ã¨ã€å›è»¢è¡Œåˆ—ã‚’Rã¨ã—ãŸå ´åˆå¼16ã«ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«å›è»¢è¡Œåˆ—Rã«ç›¸å¯¾ä½ç½®m-nãŒç¾ã‚Œï¼ˆã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šï¼‰ã€ç›¸å¯¾ä½ç½®ã‚’è€ƒæ…®ã—ãŸqkã®è¨ˆç®—ã«ãªã£ã¦ã„ã‚‹ã€‚[^1]<br><br><br>&lt;img width="705" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/fce1d06e-e346-4278-a77c-4c96795d5488"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/fce1d06e-e346-4278-a77c-4c96795d5488"&lt;/a&gt;


&gt;<br><br>&lt;img width="588" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/3f28103c-6a56-4016-8f50-d45fe28cd62a"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/3f28103c-6a56-4016-8f50-d45fe28cd62a"&lt;/a&gt;


&gt;<br><br><br>[^1]: (R_mq_m)^T R_nK_n = q_m^T (R_m^T R_n) k_n = q_m^T (R_{-m}R_n) k_n = q_m^T R_{n-m} k_n. ã“ã“ã§ã€R_m^T = R_{-m}ã§ã‚ã‚Šã€R_m R_n = R_{m+n}ã®æ€§è³ªã‚’ä½¿ã£ã¦ã„ã‚‹ã€‚<br><br><br>RoPEã¯ä¸‹è¨˜ã®ã‚ˆã†ãªæ€§è³ªã‚’æŒã¤ï¼š<br><br>- long-term decay: Î¸i = 10000âˆ’2i/d ã¨è¨­å®šã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€ç›¸å¯¾ä½ç½®ãŒé›¢ã‚Œã¦ã„ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ™ã‚¯ãƒˆãƒ«ã¨ã®inner productã®å€¤ãŒå°ã•ããªã‚‹ã€‚ã™ãªã‚ã¡ã€ä½ç½®ãŒé›¢ã‚Œã¦ã„ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³é–“ã®ä¾å­˜é–¢ä¿‚ãŒå°ã•ããªã‚‹ã€‚<br><br>- Linear-Attention: RoPEã¯å›è»¢è¡Œåˆ—ã§ã‚ã‚Šã€ä¹—ç®—å¾Œã®ãƒ™ã‚¯ãƒˆãƒ«ã®ãƒãƒ«ãƒ ã‚’å¤‰åŒ–ã•ã›ãªã„ã€‚ã“ã®ãŸã‚ã€Linear Attentionã®å¼ã®ä¸­ã«å›è»¢è¡Œåˆ—ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€Linear Attentionã¨ç°¡å˜ã«çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ãŒå¯èƒ½<br><br><br><br>Absolute Position Embedding, Relative Position Embeddingã§ã¯ã€ãƒ™ã‚¯ãƒˆãƒ«ã«å¯¾ã—ã¦ä½ç½®æƒ…å ±ã‚’åŠ ç®—ã™ã‚‹å®šå¼åŒ–ã§ K, Vã®è¨ˆç®—æ™‚ã«ä½ç½®æƒ…å ±ã‚’è€ƒæ…®ã—ã¦ã„ãŸãŸã‚ã€Linear Attentionã®è¨ˆç®—ãã®ã‚‚ã®ã«ä½ç½®æƒ…å ±ã‚’çµ„ã¿è¾¼ã‚“ã å®šå¼åŒ–ã¨ã¯ãªã£ã¦ã„ãªã‹ã£ãŸã€‚<br><br>ãŒã€RoPEã§ã¯å›è»¢è¡Œåˆ—ã‚’ä¹—ç®—ã™ã‚‹å®šå¼åŒ–ã§ã‚ã‚Šã€ãƒãƒ«ãƒ ã‚’å¤‰åŒ–ã•ã›ãªã„ã®ã§Linear Attentionã®å®šå¼åŒ–ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã‚‹ã€‚ã“ã®ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å¤§ããå¤‰æ›´ã—ãªãã¨ã‚‚çµ„ã¿è¾¼ã‚ã‚‹ã€‚<br><br></p>
<p>RoPEè‡ªä½“ã¯å®Ÿè£…ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¿…è¦ã¨ã—ãªã„ãŒã€ãƒ¢ãƒ‡ãƒ«ã®ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒRoPEã«é©ç”¨ã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã¦ã„ãªã„ã¨é©ç”¨ã§ããªã„ã§ã‚ã‚ã†ç‚¹ã«ã¯æ³¨æ„ï¼ˆäº‹å‰å­¦ç¿’æ™‚ã«RoPEãŒä½¿ã‚ã‚Œã¦ã„ã‚Œã°è©±ã¯åˆ¥ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-04-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1298" target="_blank" rel="noopener noreferrer" class="title-link">mergekit-evolve</a>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1257" target="_blank" rel="noopener noreferrer">Evolutionary Optimization of Model Merging Recipes, Takuya Akiba+, N/A, Nature Machine Intelligence'25</a>
 ã®ã‚ˆã†ã«é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãŒã§ãã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª<br>è§£èª¬è¨˜äº‹:


<a href="https://note.com/npaka/n/nad2ff954ab81" target="_blank" rel="noopener noreferrer">https://note.com/npaka/n/nad2ff954ab81</a>


</p>
<p>å¤§ããªVRAMãŒç„¡ãã¨ã‚‚ã€å¤§ãã‚ã®SRAMãŒã‚ã‚Œã°å‹•ä½œã™ã‚‹ã‚‰ã—ã„</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1297" target="_blank" rel="noopener noreferrer" class="title-link">AirLLM, 2024.04</a>
<span class="snippet"><span>Comment</span><p>4GBã®Single GPUã§ã€70Bãƒ¢ãƒ‡ãƒ«ã®inferenceã‚’å®Ÿç¾ã§ãã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆé€Ÿåº¦ã¯æ¤œè¨¼ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚transformer decoderã®å„layerã®æ¼”ç®—ã¯ç‹¬ç«‹ã—ã¦ã„ã‚‹ãŸã‚ã€GPUã«å…¨ã¦ã®layerã‚’è¼‰ã›ãšã€å¿…è¦ãªåˆ†ã ã‘è¼‰ã›ã¦inferenceã™ã‚‹ã¨ã„ã£ãŸæ“ä½œã‚’ç¹°ã‚Šè¿”ã™æ¨¡æ§˜ã€‚<br><br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rohanpaul_ai/status/1784349737899982943?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-04-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1289" target="_blank" rel="noopener noreferrer" class="title-link">LLaMA3, Meta, 2024.04</a>
<span class="snippet"><span>Comment</span><p>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«ã‚ˆã‚‹ã¨ã€LLaMA3ã‚’åˆ©ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã©ã‚“ãªå ´åˆã§ã‚‚Llama3ã‚’prefixã¨ã—ã¦ä»˜ä¸ã—ãªã„ã¨ã„ã‘ãªã„ã‚‰ã—ã„<br><br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1781083579273089442?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLaMA3ãŒChatBot Arenaã§Top 5ã«ãªã£ãŸã¨ã®ã“ã¨ã€‚ã¾ãŸã€è‹±èªã«ãŠã„ã¦ã¯ã€GPT4-1106-preview, GPT-4-turbo-2024-0409ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã€‚ã“ã‚Œã¯ã™ã”ã„â€¦<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lmsysorg/status/1782483699449332144?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>nejumi-leaderboard <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1055" target="_blank" rel="noopener noreferrer">Nejumi LLMãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰</a>
 ã«LLaMA3ã®è©•ä¾¡çµæœãŒæ²è¼‰ã•ã‚ŒãŸæ¨¡æ§˜ï¼ˆç”»åƒã¯ä¸‹è¨˜ãƒ„ã‚¤ãƒ¼ãƒˆã‚ˆã‚Šå¼•ç”¨ï¼‰<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2db1674b-80a6-4bbc-ab4b-c822e1659d6f" alt="image" loading="lazy"><br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/madyagi/status/1783707796095316310?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯Transformer Decoderã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ã¦ãŠã‚Šã€Llama2ã¨æ¯”è¼ƒã—ã¦<br><br>- Tokenizerã®Vocabã‚µã‚¤ã‚ºã‚’128Kã‚ˆã‚ŠåŠ¹ç‡çš„ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯èƒ½ã«<br><br>- GQA <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
 ã‚’åˆ©ç”¨ã—Inferenceã‚’é«˜é€ŸåŒ– (Llama2ã®æ™‚ç‚¹ã§GQAã‚’ä½¿ã£ã¦ã„ãŸãŒã€70Bãƒ¢ãƒ‡ãƒ«ã ã‘ã ã£ãŸ)<br><br>- self-attentionãŒã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è·¨ãŒãªã„ã‚ˆã†ã«å­¦ç¿’</p>
<p>context: 8192</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2024-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1285" target="_blank" rel="noopener noreferrer" class="title-link">Open Source Cookbook</a>
<span class="snippet"><span>Comment</span><p>HuggingFaceã«ã‚ˆã‚‹æ§˜ã€…ãªå®Ÿç”¨çš„ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®å®Ÿè£…ã‚„ãƒ¢ãƒ‡ãƒ«ã§å®Ÿç¾ã™ã‚‹ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ãŒã¾ã¨ã¾ã£ãŸãƒªãƒã‚¸ãƒˆãƒªã€‚LLM-as-a-judge, RAG, PEFTã«ã‚ˆã‚‹Prompt Tuningï¼ˆPrefix Tuningã¨ã‹ãã£ã¡ç³»ã®è©±ã ã¨æ€ã‚ã‚Œã‚‹ï¼‰ãªã©ã€ç¾åœ¨16ç¨®é¡ã»ã©ã‚ã‚‹ã‚‰ã—ã„ã€‚</p>
<p>æ”¹ã‚ã¦è¦‹ãŸã‚‰æ•°ãŒã‹ãªã‚Šå¢—ãˆã¦ã„ãŸ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2024-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1281" target="_blank" rel="noopener noreferrer" class="title-link">Grok-1.5 Vision Preview, 2024</a>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/88dd70ce-5874-4786-8e66-7484984c7a72" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<span class="issue_date">Issue Date: 2024-04-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1280" target="_blank" rel="noopener noreferrer" class="title-link">The State of Multilingual AI, Sebastian Ruder, 2024</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-04-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1279" target="_blank" rel="noopener noreferrer" class="title-link">Mixtral-8x22B-v0.1, 2024</a>
<span class="snippet"><span>Comment</span><p>Apache-2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹, æ—¥æœ¬èªéå¯¾å¿œ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2024-04-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1278" target="_blank" rel="noopener noreferrer" class="title-link">Command R+, Cohere, 2024</a>
<span class="snippet"><span>Comment</span><p>Chatbot arenaã§GPT-4-0314ã¨åŒç­‰ã® Elo Rate ã‚’ç²å¾—ã—ï¼ˆ20240410æ™‚ç‚¹ï¼‰ã€æ—¥æœ¬èªã‚’å«ã‚€10ãƒ¶å›½èªã‚’ã‚µãƒãƒ¼ãƒˆã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º128kã€‚å•†ç”¨åˆ©ç”¨ã¯APIã‹ã‚‰ã€ç ”ç©¶ç›®çš„ã§ã‚ã‚Œã°HuggingFaceã‹ã‚‰åˆ©ç”¨å¯èƒ½ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9571e233-f936-4327-af60-3c2ce57aad71" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-04-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1277" target="_blank" rel="noopener noreferrer" class="title-link">Gemma: Open Models Based on Gemini Research and Technology, 2024</a>
<span class="snippet"><span>Comment</span><p>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯Transformer Decoderã‚’åˆ©ç”¨ã€‚ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã¯2Bã¨7Bã€‚<br><br>ã‚ªãƒªã‚¸ãƒŠãƒ«ã®Transformer Decoderã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‹ã‚‰ã€ä¸‹è¨˜æ”¹å–„ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ï¼š<br><br>- Multi Query Attention <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1272" target="_blank" rel="noopener noreferrer">Fast Transformer Decoding: One Write-Head is All You Need, Noam Shazeer, N/A, arXiv'19</a>
 ã‚’åˆ©ç”¨<br><br>- RoPE Embedding <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1310" target="_blank" rel="noopener noreferrer">RoFormer: Enhanced Transformer with Rotary Position Embedding, Jianlin Su+, N/A, Neurocomputing, 2024</a>
 ã‚’åˆ©ç”¨<br><br>- GeGLU <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1311" target="_blank" rel="noopener noreferrer">GLU Variants Improve Transformer, Noam Shazeer, N/A, arXiv'20</a>
 ã®åˆ©ç”¨<br><br>- RMSNormã®åˆ©ç”¨ï¼ˆå­¦ç¿’ã‚’å®‰å®šã•ã›ã‚‹ãŸã‚; LLaMAã¨åŒæ§˜ï¼‰<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ef8dd419-fcce-49f5-8fd2-2acc4348d880" alt="image" loading="lazy"><br><br></p>
<p>Mistral <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1309" target="_blank" rel="noopener noreferrer">Mistral 7B, Albert Q. Jiang+, N/A, arXiv'23</a>
 ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ï¼š<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/24d6892b-ca8e-48bc-92bf-7eae71466918" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4cf6b9c6-d517-4d9d-9cdb-526560d1a097" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2024-04-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1265" target="_blank" rel="noopener noreferrer" class="title-link">LLMã®ç¾åœ¨, 202404, Preffered Elements</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1262" target="_blank" rel="noopener noreferrer" class="title-link">Mamba Explained</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2024-03-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1260" target="_blank" rel="noopener noreferrer" class="title-link">Awesome LM with Tools</a>
<span class="snippet"><span>Comment</span><p>Toolã‚’åˆ©ç”¨ã™ã‚‹LMã«é–¢ã™ã‚‹Neubigæ°ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«ã‚ˆã‚‹Surveyã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/TextualInversion.html" target="_blank" rel="noopener noreferrer">#TextualInversion</a>
<span class="issue_date">Issue Date: 2024-03-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1258" target="_blank" rel="noopener noreferrer" class="title-link">repeng</a>
<span class="snippet"><span>Comment</span><p>LLMã®å‡ºåŠ›ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’æ•°ç™¾å€‹ã®äº‹ä¾‹ã ã‘ã§å­¦ç¿’ã—ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚promptã§æŒ‡å®šã™ã‚‹ã®ã¨ã¯ç•°ãªã‚Šã€æ•°å€¤ã§ã‚¹ã‚¿ã‚¤ãƒ«ã®å¼·ã•ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ãŒå¯èƒ½ã‚‰ã—ã„ï¼ˆå…ƒãƒ„ã‚¤ãƒ¼ãƒˆï¼‰ã€‚ç”»åƒç”Ÿæˆåˆ†é‡ã«ãŠã‘ã‚‹Textual Inversionã¨åŒã˜æŠ€è¡“ã¨ã®ã“ã¨ã€‚<br><br>Textual Inversionã¨ã¯ã€å°‘é‡ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”¨ã„ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€éƒ¨åˆ†ã«æ–°ãŸãªã€Œå˜èªã€ã‚’è¿½åŠ ã—ã€å˜èªã¨å¯¾å¿œã™ã‚‹ç”»åƒã‚’ç”¨ã„ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã“ã¨ã§ã€promptä¸­ã§ã€Œå˜èªã€ã‚’åˆ©ç”¨ã—ãŸå ´åˆã«å­¦ç¿’ã—ãŸç”»åƒã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆã‚ªãƒªã‚¸ãƒŠãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªãã¦ã‚‚å¯ï¼‰ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹æŠ€è¡“ã€ã‚‰ã—ã„ã€‚<br><br>Huggiegface: 


<a href="https://huggingface.co/docs/diffusers/training/text_inversion" target="_blank" rel="noopener noreferrer">https://huggingface.co/docs/diffusers/training/text_inversion</a>


<br>ï¼ˆå‚è€ƒï¼‰GPTã«è³ªå•ã—ãŸéš›ã®ãƒ­ã‚°: 


<a href="https://chat.openai.com/share/e4558c44-ce09-417f-9c77-6f3855e583fa" target="_blank" rel="noopener noreferrer">https://chat.openai.com/share/e4558c44-ce09-417f-9c77-6f3855e583fa</a>


<br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1770272397184389211?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-03-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1256" target="_blank" rel="noopener noreferrer" class="title-link">Open Release of Grok-1  March 17, 2024</a>
<span class="snippet"><span>Comment</span><p>Apache2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹, 314Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã€Mixture-of-Expertsã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã€å­¦ç¿’ã«åˆ©ç”¨ã—ãŸã‚³ãƒ¼ãƒ‰ã¯ãŠãã‚‰ãå…¬é–‹ã•ã‚Œã¦ã„ãªã„ã€‚</p>
<p>Grok-1.5ãŒãƒªãƒªãƒ¼ã‚¹<br>


<a href="https://x.ai/blog/grok-1.5" target="_blank" rel="noopener noreferrer">https://x.ai/blog/grok-1.5</a>


<br><br>å„ç¨®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ€§èƒ½ã€ç‰¹ã«Mathã®æ€§èƒ½ãŒå‘ä¸Šã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ãŒ128kã«<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0e8f357f-f583-4a11-bf20-49e9886cf6e9" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-03-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1249" target="_blank" rel="noopener noreferrer" class="title-link">RAG-Research-Insights</a>
<span class="snippet"><span>Comment</span><p>RAGã«é–¢ã™ã‚‹ç ”ç©¶ãŒç›´è¿‘ã®ã‚‚ã®ã¾ã§ã‚ˆãã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-03-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1242" target="_blank" rel="noopener noreferrer" class="title-link">What are the most important LLMs to know about in March 2024?</a>
<span class="snippet"><span>Comment</span><p>2024å¹´3æœˆæ™‚ç‚¹ã§çŸ¥ã£ã¦ãŠãã¹ãLLMã«é–¢ã™ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2024-02-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1237" target="_blank" rel="noopener noreferrer" class="title-link">Mistral Large</a>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2d9066bd-05e5-4942-8d27-e5b50d129ade" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-02-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1233" target="_blank" rel="noopener noreferrer" class="title-link">awesome-generative-information-retrieval</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-02-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1229" target="_blank" rel="noopener noreferrer" class="title-link">RAGã®æ€§èƒ½ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®8ã¤ã®æˆ¦ç•¥</a>
<span class="snippet"><span>Comment</span><p>ã‚ã¡ã‚ƒã‚ã¡ã‚ƒè©³ç´°ã«RAGæ€§èƒ½å‘ä¸Šã®æ‰‹æ³•ãŒreferenceä»˜ãã§ã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚ã™ã”ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1203" target="_blank" rel="noopener noreferrer" class="title-link">Decoding Strategies that You Need to Know for Response Generation</a>
<span class="snippet"><span>Comment</span><p>è¨€èªãƒ¢ãƒ‡ãƒ«ã®decodingã®æ–¹æ³•ã«ã¤ã„ã¦ã‚ˆãã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚ã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹decodingæ–¹æ³•ã¯ä»¥ä¸‹<br><br>- Greedy, BeamSearch, RandomSampling, Temperature, Top-K Sampling, Nucleus Sampling</p>
<p>ã“ã¡ã‚‰ã®è¨˜äº‹ã§ã¯HuggingFaceã§ã®å®Ÿè£…ã‚„ä»–ã®decodingæ–¹æ³•ç­‰ã€ã‚ˆã‚Šå®Ÿè£…é¢ã§ã®è©³ç´°ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ï¼š<br><br>


<a href="https://note.com/npaka/n/n9a8c85f2ef7a" target="_blank" rel="noopener noreferrer">https://note.com/npaka/n/n9a8c85f2ef7a</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-12-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1192" target="_blank" rel="noopener noreferrer" class="title-link">ELYZA-tasks-100 ã§LLM14å€‹ã®æ—¥æœ¬èªæ€§èƒ½ã‚’æ¨ªæ–­è©•ä¾¡ã—ã¦ã¿ãŸ</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<span class="issue_date">Issue Date: 2023-12-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1191" target="_blank" rel="noopener noreferrer" class="title-link">TokyoTechLLM</a>
<span class="snippet"><span>Comment</span><p>Llama2ã®æ—¥æœ¬èªæ€§èƒ½ã‚’ç¶™ç¶šäº‹å‰å­¦ç¿’ã§å¼•ãä¸Šã’ãŸLLMã€‚2023å¹´12æœˆæ™‚ç‚¹ã®æ—¥æœ¬èªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMã®ä¸­ã§æœ€é«˜æ€§èƒ½ã¨ã®ã“ã¨ã€‚</p>
<p>é–‹ç™ºè€…ã®æ–¹ã«ã‚ˆã‚‹è©³ç´°ã¯ã“ã¡ã‚‰:<br>


<a href="https://zenn.dev/tokyotech_lm/articles/d6cb3a8fdfc907" target="_blank" rel="noopener noreferrer">https://zenn.dev/tokyotech_lm/articles/d6cb3a8fdfc907</a>


<br><br>ã™ã”ã„èª­ã¿å¿œãˆâ€¦checkpointã®å®¹é‡ã®ãƒ‡ã‚«ã•ã‚„ã€A100x8 60ãƒãƒ¼ãƒ‰ä½¿ã£ãŸè©±ã‚„ã€ãƒãƒ¼ãƒ‰ä¸è‰¯ã‚„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†ã®è©±ã€ç‹¬è‡ªã«å®Ÿè£…ã‚’ã‚´ãƒªã‚´ãƒªåŠ ãˆãŸã‚‚ã®ã§ã¯ãªãæœ€çµ‚çš„ã«å®Œæˆåº¦ã®é«˜ã•ã‹ã‚‰MegatronLMã‚’æ¡ç”¨ã—ãŸè©±ãªã©ã€ãƒã‚°ã£ãŸè¦æ¨¡æ„Ÿã¨è©¦è¡ŒéŒ¯èª¤ã‚„å®Ÿä½“é¨“ã«åŸºã¥ãã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æº€è¼‰ã€‚</p>
<p>å‚è€ƒ:<br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1192" target="_blank" rel="noopener noreferrer">ELYZA-tasks-100 ã§LLM14å€‹ã®æ—¥æœ¬èªæ€§èƒ½ã‚’æ¨ªæ–­è©•ä¾¡ã—ã¦ã¿ãŸ</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-12-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1188" target="_blank" rel="noopener noreferrer" class="title-link">optimize-llm, HuggingFace</a>
<span class="snippet"><span>Comment</span><p>LLMã‚’optimizeã™ã‚‹å®Ÿç”¨çš„ãªãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«</p>
<p>ã“ã¡ã‚‰ã‚‚æœ‰ç”¨ãªã®ã§å‚ç…§ã®ã“ã¨<br><br><br><br>ã€GPU inferenceã€‘<br><br>


<a href="https://huggingface.co/docs/transformers/main/perf_infer_gpu_one" target="_blank" rel="noopener noreferrer">https://huggingface.co/docs/transformers/main/perf_infer_gpu_one</a>


<br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2023-12-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1187" target="_blank" rel="noopener noreferrer" class="title-link">ã€ç¶šã€‘Flash Attentionã‚’ä½¿ã£ã¦LLMã®æ¨è«–ã‚’é«˜é€Ÿãƒ»è»½é‡åŒ–ã§ãã‚‹ã‹ï¼Ÿ</a>
<span class="snippet"><span>Comment</span><p>use_cacheãŒTrue/Falseã®å ´åˆã®FlashAttention2ã®inference timeã¨VRAMä½¿ç”¨é‡ã®å‚¾å‘ã‚’sequence_lengthã”ã¨ã«è€ƒå¯Ÿã—ã¦ã„ã‚‹ã€‚<br><br>use_cacheã¯Key Value cacheã®ã‚ªãƒ³ã‚ªãƒ•ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‰ã‚Œã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã‚ã‚‹ã€‚autoregressiveãªãƒ¢ãƒ‡ãƒ«ã®inferenceæ™‚ã«ã¯ã€ä½•åº¦ã‚‚åŒã˜input tokenã«å¯¾ã™ã‚‹KVã®è¨ˆç®—ãŒç”Ÿã˜ã‚‹ãŸã‚ï¼ˆMç•ªç›®ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã—ãŸå¾Œã€M+1ç•ªç›®ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆã‚’ã™ã‚‹å ´åˆã€M-1ç•ªç›®ã¾ã§ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®KVã‚’å†è¨ˆç®—ã›ã­ã°ãªã‚‰ãªã„ï¼‰ã€cacheã‚’ã™ã‚‹ã“ã¨ã§å¤§å¹…ã«è¨ˆç®—é€Ÿåº¦ãŒæ”¹å–„ã•ã‚Œã‚‹ã€‚<br><br>use_cacheã‚’Trueã«ã§ãã‚‹ãªã‚‰FlashAttention2ã®æ©æµã¯å°ã•ã„ï¼ˆinference timeãŒå°‘ã—æ—©ããªã‚‹ã®ã¿ï¼‰ãŸã‚ã€æ½¤æ²¢ãªVRAMãŒã‚ã‚‹ãªã‚‰å¾—ã‚‰ã‚Œã‚‹æ©æµã¯å°ã•ã„ã€‚<br>é€†ã«VRAMç¯€ç´„ã—ã¦use_cacheã‚’Falseã«ã›ã–ã‚‹ã‚’å¾—ãªã„ã®ã§ã‚ã‚Œã°ã€FlashAttention2ã«ã‚ˆã‚ŠVRAMä½¿ç”¨é‡ã‚’sequence_legthã®ç·šå½¢ã«æŠ‘ãˆã‚‹ã“ã¨ãŒã§ãã€ã‹ã¤inference timeã‚‚çŸ­ããªã‚‹ã€‚<br><br>â†‘ä¸Šè¨˜ã¯ã‚ãã¾ã§inferenceã‚’ã™ã‚‹å ´åˆã®ã¿ã®è©±ã§ã‚ã‚Šï¼ˆtrainæ™‚ã¯autoregressive modelã§ã¯causal maskã‚’ç”¨ã„ã€teacher forcingã§ä¸¦åˆ—ã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ãã‚‚ãã‚‚KV-cacheã™ã‚‹æ„å‘³ãŒãªã„ï¼‰ã€trainingã‚’ã™ã‚‹å ´åˆFlashAttention2ã§å¤§å¹…ã«VRAMä½¿ç”¨é‡ã‚’æ¸›ã‚‰ã›ã‚‹ã®ã§ã€ãã“ã¯åˆ†ã‘ã¦è€ƒãˆã‚‹ã“ã¨ã€‚<br>


<a href="https://qiita.com/jovyan/items/ff3d0a49163c7afa33ce" target="_blank" rel="noopener noreferrer">https://qiita.com/jovyan/items/ff3d0a49163c7afa33ce</a>


</p>
<p>Flash Attentionã‚’ä½¿ã£ã¦LLMã®æ¨è«–ã‚’é«˜é€Ÿãƒ»è»½é‡åŒ–ã§ãã‚‹ã‹ï¼Ÿ<br>


<a href="https://qiita.com/jovyan/items/11deb9d4601e4705a60d" target="_blank" rel="noopener noreferrer">https://qiita.com/jovyan/items/11deb9d4601e4705a60d</a>


<br><br>ã“ã¡ã‚‰ã®è¨˜äº‹ã‚‚éå¸¸ã«å‹‰å¼·ã«ãªã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-12-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1184" target="_blank" rel="noopener noreferrer" class="title-link">å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’æ”¯ãˆã‚‹åˆ†æ•£ä¸¦åˆ—å­¦ç¿’ã®ã—ãã¿ Part1</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2023-12-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1183" target="_blank" rel="noopener noreferrer" class="title-link">A Review of Public Japanese Training Sets, shisa, 2023.12</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2023-12-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1181" target="_blank" rel="noopener noreferrer" class="title-link">Gemini, Google, 2023.12</a>
<span class="snippet"><span>Comment</span><p>å¤šãã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§GPT4è¶…ãˆã‚‰ã—ã„<br><br>ï¼ˆè¿½è¨˜1ï¼‰<br>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã®p.44ã‚’è¦‹ã‚‹ã¨ã€ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆä¸­ã®GPT4ã®MMLUã®ã‚¹ã‚³ã‚¢ã¯GPT-4-0613ã®ã‚‚ã®ã®ã‚ˆã†ãªã®ã§ã€ã“ã‚ŒãŒæ­£ã—ã„ã¨ã™ã‚‹ã¨ä»–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚¹ã‚³ã‚¢ã‚‚åŒãƒ¢ãƒ‡ãƒ«ã®ã‚‚ã®ã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ãã€GPT-4-1163-previewï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ï¼‰ã®ã‚¹ã‚³ã‚¢ã§ã¯"ãªã„ã‹ã‚‚ã—ã‚Œãªã„"ç‚¹ã«æ³¨æ„ã€‚GPT4ã¨ã©ã¡ã‚‰ãŒå®Ÿéš›ã«æ€§èƒ½ãŒè‰¯ã„ã‹?ã«ã¤ã„ã¦ã¯æ§˜å­è¦‹ã—ãŸæ–¹ãŒè‰¯ã•ãã†ã€‚<br><br>ï¼ˆè¿½è¨˜2ï¼‰<br>GSM8Kã®çµæœã‚‚ã€GPT4ã«å¯¾ã—ã¦Fair Comparisonã§ã¯ãªã„ã‹ã‚‚ã—ã‚Œãªã„ç‚¹ã«æ³¨æ„ã€‚Geminiã¯32å€‹ã®CoTã¨Self-Consistencyã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ãŒã€GPT4ã§ã¯5-shotã§å˜ä¸€ã®CoTã®ã¿ã§ã‚ã‚‹ãŸã‚ã€promptingæ‰‹æ³•ã§ã¯Geminiã«æœ‰åˆ©ãªæ¯”è¼ƒã¨ãªã£ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ãŸã ã—GPT4ã¯GSM8Kã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’äº‹å‰å­¦ç¿’æ™‚ã«MIXã—ã¦ã„ã‚‹ï¼ˆSFTï¼‰ã®ã§ã€GeminiãŒã“ã®ã‚ˆã†ãªã“ã¨ã‚’ã—ã¦ã„ãªã„ã®ã§ã‚ã‚Œã°ã€ã“ã®ç‚¹ã§ã¯GPT4ãŒæœ‰åˆ©ã«ãªã£ã¦ã„ã‚‹â€œå¯èƒ½æ€§â€ãŒã‚ã‚‹ã€‚<br><br>ä»–ã«ã‚‚Fair Comparisonã«ãªã£ã¦ã„ãªã„ã¨æ¨å¯Ÿã•ã‚Œã‚‹ã‚‚ã®ã¯Textãƒ¢ãƒ€ãƒªãƒ†ã‚£ã§ã®è©•ä¾¡ã®è¡¨ã®æ–‡è¨€ã‚’è¦‹ã‚‹ã¨ã‚ã‚Šãã†ãªã®ã§ãã“ã¯å¿µé ­ã«ãŠã„ãŸæ–¹ãŒè‰¯ã•ãã†ã§ã‚ã‚‹ã€‚</p>
<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ: 


<a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf" target="_blank" rel="noopener noreferrer">https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf</a>


</p>
<p>Gemini Summary<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/srush_nlp/status/1732427569352323401?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MMLUã§ã®åŒã˜promptingæ‰‹æ³•ã§ã®GPT-4-0613ã¨ã®æ¯”è¼ƒã€‚32å€‹ã®CoTã§ã®Self-Consistencyã§æ¯”è¼ƒã—ãŸå ´åˆã€GPT-4-0613ã«è² ã‘ã¦ã„ã‚‹ãŒã€é–¾å€¤ã‚’è¨­ã‘ã¦confidenceãŒé–¾å€¤ä»¥ä¸Šã®å ´åˆã¯Self-consistency, ãã†ã§ãªã„å ´åˆã¯greedyã«ç”Ÿæˆã—ãŸçµæœã‚’é¸æŠã™ã‚‹ã€ã¨ã„ã†Uncertain-Routed CoT@32ã§ã¯ã€Geminiã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹gainãŒå¤§ããGPT-4-0613ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br>ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆä¸­ã®GPT4ã®ã‚¹ã‚³ã‚¢ã¯5-shotã®ã‚‚ã®ï¼ˆreportedã¨æ›¸ã‹ã‚Œã¦ã„ã‚‹ã®ã§OpenAIãŒå…¬è¡¨ã—ã¦ã„ã‚‹æ•°å€¤ã¨æ¨å¯Ÿï¼‰ã§ã‚ã‚Šã€Geminiã®çµæœã¯Uncertain-Routed CoT@32ã®çµæœã§ã‚ã‚‹ãŸã‚ã€Fair Comparisonã«ãªã£ã¦ã„ãªã„ã‹ã‚‚ã—ã‚Œãªã„ï¼Ÿç‚¹ã«ã¯æ³¨æ„ã€‚<br><br>ãƒ¬ãƒãƒ¼ãƒˆä¸­ã§ã¯Self-consistencyã¨ã„ã†å˜èªã§ã“ã®éƒ¨åˆ†ã¯æ›¸ã‹ã‚Œã¦ã„ãªã„ãŒã€å®Ÿã¯å°‘ã—ã‚„ã£ã¦ã„ã‚‹ã“ã¨é•ã£ã¦ãŸã‚Šã™ã‚‹â€¦ï¼Ÿ<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ab56b7e0-464a-4e29-84e7-7d1540ef2119" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-12-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1178" target="_blank" rel="noopener noreferrer" class="title-link">ã‚‚ã—æ˜æ—¥ã€ä¸Šå¸ã«ã€ŒGPT-4ã‚’ä½œã‚Œã€ã¨è¨€ã‚ã‚ŒãŸã‚‰ï¼Ÿ Stability AIã®ã‚·ãƒ‹ã‚¢ãƒªã‚µãƒ¼ãƒã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆãŒç´¹ä»‹ã™ã‚‹ã€ŒLLMæ§‹ç¯‰ã‚¿ã‚¤ãƒ ã‚¢ã‚¿ãƒƒã‚¯ã€</a>
<span class="snippet"><span>Comment</span><p>StabilityAI Japanç§‹è‘‰ã•ã‚“ï¼ˆå…ƒPFNï¼‰ã®W&amp;B Conferenceã§ã®ç™ºè¡¨ã«é–¢ã™ã‚‹è¨˜äº‹ã€‚<br>LLMæ§‹ç¯‰ã‚¿ã‚¤ãƒ ã‚¢ã‚¿ãƒƒã‚¯ã§LLMã‚’ã‚‚ã—æ§‹ç¯‰ã™ã‚‹ã“ã¨ã«ãªã£ãŸã‚‰ï¼ï¼Ÿ<br>ã®ã–ã£ãã‚Šã¨ã—ãŸãƒ—ãƒ­ã‚»ã‚¹ã‚„ã€æ¬¡ãƒšãƒ¼ã‚¸ã§OpenAIã®GPT4ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‹ã‚‰å„ãƒãƒ¼ãƒ ã®è¦æ¨¡æ„Ÿã‚’æ¨å®šã—ã¦ã€ã©ã®éƒ¨åˆ†ã«ã©ã®ç¨‹åº¦ã®äººå“¡ãŒå‰²ã‹ã‚Œã¦ã„ãŸã®ã‹ã¨ã„ã†ã®ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€å„ãƒ‘ãƒ¼ãƒˆã§ã©ã‚“ãªã“ã¨ãŒã‚„ã‚‰ã‚Œã¦ã„ãã†ã‹ã¨ã„ã†è©±ãŒã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>LLMæ§‹ç¯‰ã‚¿ã‚¤ãƒ ã‚¢ã‚¿ãƒƒã‚¯ã§ã€ã¾ãšGPUã‚’ç”¨æ„ã—ã¾ã™ï¼ï¼ˆã“ã“ãŒä¸€ç•ªå¤§å¤‰ã‹ã‚‚ï¼‰ã®æ™‚ç‚¹ã§ã€ã‚ã£å¯Ÿã—ï¼ˆç™½ç›®ã€€ã¨ã„ã†æ„Ÿã˜ãŒã—ã¦é¢ç™½ã‹ã£ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-12-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1173" target="_blank" rel="noopener noreferrer" class="title-link">kaggle LLM ã‚³ãƒ³ãƒš ä¸Šä½è§£æ³•ã‚’è‡ªåˆ†ãªã‚Šã«ã¾ã¨ã‚ã¦ã¿ãŸè©±</a>
<span class="snippet"><span>Comment</span><p>å®Ÿè·µçš„ãªå†…å®¹ï¼ˆãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆæ™‚ã®å·¥å¤«ã€ã‚¯ã‚¨ãƒªç”Ÿæˆæ™‚ã®å·¥å¤«ç­‰ï¼‰ãŒç¶²ç¾…çš„ã«ã¾ã¨ã¾ã£ã¦ãŠã‚Šéå¸¸ã«æœ‰ç”¨</p>
<p>å€‹äººçš„ã«ã€ã‚³ãƒ³ãƒšä¸»å‚¬è€…å´ã‹ã‚‰æä¾›ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªãã€ä¸Šä½ã®ã»ã¨ã‚“ã©ã®ãƒãƒ¼ãƒ ãŒChatGPTï¼ˆ3.5, 4ï¼‰ã‚’ç”¨ã„ã¦ã€QAãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ã„ãŸã€ã¨ã„ã†ã®ãŒèˆˆå‘³æ·±ã‹ã£ãŸã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ãŸã¨ãˆã°ä¸‹è¨˜:<br><br>[ï¼ˆ5th-place-solutionï¼‰](


<a href="https://www.kaggle.com/competitions/kaggle-llm-science-exam/discussion/446293)%E3%82%88%E3%82%8A%E5%BC%95%E7%94%A8" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/competitions/kaggle-llm-science-exam/discussion/446293)ã‚ˆã‚Šå¼•ç”¨</a>


<br><br>```<br><br>system_content = """<br><br>Forget all the previous instruction and rigorously follow the rule specified by the user.<br><br>You are a professional scientist's assistant.<br><br>"""<br><br><br><br>user_content_template_qa = Template(<br><br>    """<br><br>Please consider 5 choices question and answer of the following TEXT.<br><br>The purpose of this question is to check respondent's deep science understanding of the TEXT.<br><br>We assume this question is for professional scientists, so consider super difficult question.<br><br>You can ask very detailed question, for example check specific sentence's understanding.<br><br>It is good practice to randomly choose specific sentence from given TEXT, and make QA based on this specific sentence.<br><br>You must make QA based on the fact written in the TEXT.<br><br>You may create wrong answers based on the correct answer's information, by modifying some parts of the correct answer.<br><br>Your response must be in following format, don't write any other information. <br><br>You must not include "new line" in each Q), 1), 2), 3), 4), 5), and A):<br><br>Q) `question text comes here`<br><br>1) `answer candidate 1`<br><br>2) `answer candidate 2`<br><br>3) `answer candidate 3`<br><br>4) `answer candidate 4`<br><br>5) `answer candidate 5`<br><br>A) `answer`<br><br><br><br>where only 1 `answer candidate` is the correct answer and other 4 choices must be wrong answer.<br><br>Note1: I want to make the question very difficult, so please make wrong answer to be not trivial incorrect.<br><br>Note2: The answer candidates should be long sentences around 30 words, not the single word.<br><br>Note3: `answer` must be 1, 2, 3, 4 or 5. `answer` must not contain any other words.<br><br>Note4: Example of the question are "What is ...", "Which of the following statements ...", "What did `the person` do",<br><br>and "What was ...".<br><br>Note5: Question should be science, technology, engineering and mathematics related topic. <br><br>If the given TEXT is completely difference from science, then just output "skip" instead of QA.<br><br><br><br><br><br>Here is an example of your response, please consider this kind of difficulty when you create Q&amp;A:<br><br>Q) Which of the following statements accurately describes the impact of Modified Newtonian Dynamics (MOND) on the observed "missing baryonic mass" discrepancy in galaxy clusters?"<br><br>1) MOND is a theory that reduces the observed missing baryonic mass in galaxy clusters by postulating the existence of a new form of matter called "fuzzy dark matter."<br><br>2) MOND is a theory that increases the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions from a factor of around 10 to a factor of about 20.<br><br>3) MOND is a theory that explains the missing baryonic mass in galaxy clusters that was previously considered dark matter by demonstrating that the mass is in the form of neutrinos and axions.<br><br>4) MOND is a theory that reduces the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions from a factor of around 10 to a factor of about 2.<br><br>5) MOND is a theory that eliminates the observed missing baryonic mass in galaxy clusters by imposing a new mathematical formulation of gravity that does not require the existence of dark matter.<br><br>A) 4<br><br><br><br>Let's start. Here is TEXT: $title\n$text<br><br>"""<br><br>)<br><br>```</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2023-11-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1150" target="_blank" rel="noopener noreferrer" class="title-link">GPT4All, 2023</a>
<span class="snippet"><span>Comment</span><p>ãƒ­ãƒ¼ã‚«ãƒ«ãƒã‚·ãƒ³ã§ChatGPT likeãªUIã§ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’å‹•ä½œã•ã›ã‚‰ã‚Œã‚‹Opensourceã€‚<br>Mistral7Bã‚„GGUFãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ¢ãƒ‡ãƒ«ã®ã‚ˆã¤ãªï¼ˆãŠãã‚‰ãé‡å­åŒ–ã•ã‚ŒãŸã‚‚ã®ã‚‚å«ã‚€ï¼‰ãƒ­ãƒ¼ã‚«ãƒ«ãƒã‚·ãƒ³ã§å‹•ä½œã•ã›ã‚‰ã‚Œã‚‹è¦æ¨¡æ„Ÿã®ãƒ¢ãƒ‡ãƒ«ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã€‚<br>


<a href="https://gpt4all.io/index.html" target="_blank" rel="noopener noreferrer">https://gpt4all.io/index.html</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-11-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1149" target="_blank" rel="noopener noreferrer" class="title-link">Zephyr-7B-beta, RAG Perf.</a>
<span class="snippet"><span>Comment</span><p>Zephyr-7B-betaã®RAGã§ã®æ€§èƒ½ãŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹</p>
<p>ä¸‹è¨˜Xãƒã‚¹ãƒˆã«ã‚ˆã‚‹ã¨gpt-3.5-turboã¨åŒç­‰<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rungalileo/status/1726638537767051436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-11-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1146" target="_blank" rel="noopener noreferrer" class="title-link">Practical Tips for Finetuning LLMs Using LoRA ï¼ˆLow-Rank Adaptationï¼‰, SEBASTIAN RASCHKA, PHD, 2023.11</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-11-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1139" target="_blank" rel="noopener noreferrer" class="title-link">JGLUEã®æ§‹ç¯‰ãã—ã¦ æ—¥æœ¬èªLLMè©•ä¾¡ã®ã“ã‚Œã‹ã‚‰, 2023</a>
<span class="snippet"><span>Comment</span><p>JGLUEã®exampleä»˜ãã®è©³ç´°ã€æ§‹ç¯‰ã®çµŒç·¯ã®ã¿ãªã‚‰ãšã€æœ€è¿‘ã®è‹±èªãƒ»æ—¥æœ¬èªLLMã®ä»£è¡¨çš„ãªè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ï¼ˆæ–¹æ³•ï¼‰ãŒã¾ã¨ã¾ã£ã¦ã„ã‚‹ï¼ˆAlpacaEval, MTBenchãªã©ï¼‰ã€‚ã¾ãŸã€LLMã«ãŠã‘ã‚‹è‡ªå‹•è©•ä¾¡ã®èª²é¡Œï¼ˆå›³ã¯è³‡æ–™ã‚ˆã‚Šå¼•ç”¨ï¼‰ãŒèˆˆå‘³æ·±ãã€LLMè©•ä¾¡ã§ç”Ÿã˜ã‚‹ãƒã‚¤ã‚¢ã‚¹ã«ã¤ã„ã¦ã‚‚è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚Name biasãªã©ã¯ãªã‚‹ã»ã©ã¨æ€ã£ãŸã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/46e3f4af-dbe1-45cf-b1e4-85e8b547ef03" alt="image" loading="lazy"><br><br>æ—¥æœ¬èªLLMã®ä»Šå¾Œã®è©•ä¾¡ã«å‘ã‘ã¦ã€ç‰¹ã«GPT4ã«ã‚ˆã‚‹è©•ä¾¡ã‚’é¿ã‘ã€ãã¡ã‚“ã¨ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ã—finetuningã—ãŸåˆ†é¡å™¨ã‚’ç”¨ã„ã‚‹ã¨ã„ã†è¦–ç‚¹ã€å‚è€ƒã«ã—ãŸã„ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/f88943b1-856e-4ca7-a256-5581cda333fb" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2023-11-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1134" target="_blank" rel="noopener noreferrer" class="title-link">LLaMA-Factory, 2023</a>
<span class="snippet"><span>Comment</span><p>ç°¡å˜ã«åˆ©ç”¨ã§ãã‚‹LLaMAã®finetuning frameworkã¨ã®ã“ã¨ã€‚<br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1724456693378040195?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLaMAãƒ™ãƒ¼ã‚¹ãªãƒ¢ãƒ‡ãƒ«ãªã‚‰è‰²ã€…å¯¾å¿œã—ã¦ã„ã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2023-11-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1130" target="_blank" rel="noopener noreferrer" class="title-link">Hallucination Leaderboard, 2023</a>
<span class="snippet"><span>Comment</span><p>1000å€‹ã®çŸ­ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¯¾ã—ã¦ã€äº‹å®Ÿæƒ…å ±ã®ã¿ã‚’ç”¨ã„ã¦è¦ç´„ã‚’ç”Ÿæˆã•ã›ã€è¦ç´„çµæœã¨åŸæ–‡æ›¸ã®Factual consistencyã‚’åˆ¥ã«è¨“ç·´ã—ãŸãƒ¢ãƒ‡ãƒ«ã§æ¸¬å®šã—ã¦è©•ä¾¡ã—ã¦ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ã„ã‚‹ã€‚</p>
<p>Claude2ã‚ˆã‚ŠLLaMA2ã®æ–¹ãŒæ€§èƒ½ãŒè‰¯ã„ã®ãŒé¢ç™½ã„ã—ã€Palmã®æ€§èƒ½ãŒã‚ã¾ã‚Šè‰¯ããªã„ã€‚</p>
<p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ashversex/status/1724240030170808392?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2023-11-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1118" target="_blank" rel="noopener noreferrer" class="title-link">Retrieval-based LM ï¼ˆRAG Systemï¼‰ã–ã£ãã‚Šç†è§£ã™ã‚‹, 2023</a>
<span class="snippet"><span>Comment</span><p>ï¼ˆä»¥ä¸‹ã‚¹ã‚¯ã‚·ãƒ§ã¯ã‚¹ãƒ©ã‚¤ãƒ‰ã‚ˆã‚Šå¼•ç”¨ï¼‰<br><br><br><br>æ¬¡ã®ã‚¹ã‚¯ã‚·ãƒ§ã¯RAGã«ã‹ã‹ã‚ã‚‹å‘¨è¾ºæŠ€è¡“ãŒã‚ˆãã¾ã¨ã¾ã£ã¦ã„ã‚‹ã¨æ€ã†ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/35f9f589-770c-435b-8d1b-81e615e86597" alt="image" loading="lazy"><br><br><br><br>ä»¥ä¸‹ã–ã£ãã‚Šç§ã®ä¸­ã®èªè­˜ã¨ã—ã¦<br><br>- è¨ˆç”»<br><br>    - ã‚¯ã‚¨ãƒªæ‹¡å¼µ<br><br>        - ã‚¯ã‚¨ãƒªã®è³ªãŒæ‚ªã„å ´åˆæ¤œç´¢æ€§èƒ½ãŒåŠ£åŒ–ã™ã‚‹ãŸã‚ã€ã‚¯ã‚¨ãƒªã‚’ã‚ˆã‚Šé©åˆ‡ã«æ¤œç´¢ãŒã§ãã‚‹ã‚ˆã†ã«ä¿®æ­£ï¼ˆæ˜”ã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã—ã‹ä¸ãˆã‚‰ã‚Œãªã„ã¨ãã«æƒ…å ±ã‚’å¢—ã‚„ã™ã‹ã‚‰â€æ‹¡å¼µâ€ã¨ã„ã†æ–‡è¨€ãŒç”¨ã„ã‚‰ã‚Œã¦ã„ã‚‹ãŒç¾åœ¨ã¯ã“ã‚Œã«é™ã‚‰ãªã„ã¨æ€ã†ï¼‰ã™ã‚‹æŠ€è¡“<br><br>    - åˆ†è§£ãƒ»æŠ½è±¡åŒ–<br><br>        - è¤‡é›‘ãªã‚¯ã‚¨ãƒªã‹ã‚‰åˆ†è§£ã™ã‚‹ã“ã¨ã§ãƒãƒ«ãƒãƒ›ãƒƒãƒ—ã®è³ªå•ã‚’ã‚µãƒ–è³ªå•ã«åˆ†è§£ï¼ˆä»Šãªã‚‰LLMã‚’åˆ©ç”¨ã™ã‚Œã°æ¯”è¼ƒçš„ç°¡å˜ã«ã§ãã‚‹ï¼‰ã—ãŸã‚Šã€ã‚ã‚‹ã„ã¯æŠ½è±¡åŒ–ã—ãŸã‚¯ã‚¨ãƒªï¼ˆStep-back Promptnig <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1076" target="_blank" rel="noopener noreferrer">Take a Step Back: Evoking Reasoning via Abstraction in Large Language
  Models, Huaixiu Steven Zheng+, N/A, arXiv'23</a>
 ï¼‰ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§æ¤œç´¢ã‚’æ”¹å–„ã™ã‚‹æŠ€è¡“<br><br>    - æ¤œç´¢å¯¾è±¡é¸å®š<br><br>        - æ¤œç´¢ã™ã‚‹å¯¾è±¡ãã®ã‚‚ã®ã‚’é¸æŠã—ã€æ¤œç´¢å¯¾è±¡ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹æŠ€è¡“<br><br>        - è³‡æ–™ä¸­ã§ã¯LLMã‚’ç”¨ã„ãŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚„Classifierã‚’ç”¨ã„ãŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹ãŒã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã§çµã‚Šè¾¼ã‚€ãªã©ã®å˜ç´”ãªæ–¹æ³•ã§ã‚‚å®Ÿç¾å¯èƒ½ã ã¨æ€ã‚ã‚Œã‚‹ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã§çµã‚Šè¾¼ã‚€ã€ã¯Classifierã§ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ãƒªãƒ³ã‚¯ã™ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãŒï¼‰<br><br>    - æ€è€ƒãƒ»è¡Œå‹•<br><br>        - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/518" target="_blank" rel="noopener noreferrer">REACT : SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS, Yao+, Princeton University and Google brain, ICLR'23</a>
 ã®ã‚ˆã†ãªè‡ªå¾‹çš„ã«LLMã«æ€è€ƒã¨ãã®çµæœã«åŸºã¥ãè¡Œå‹•ã‚’ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã›ã‚‹æŠ€è¡“ã‚„ã€ã‚¯ã‚¨ãƒªã‚’åˆ†è§£ã—ã¦å›ç­”ã¸ãŸã©ã‚Šç€ããŸã‚ã«å¿…è¦ãªæ¨è«–ã‚’æ§‹ç¯‰ã—ã€å„æ¨è«–ã®å›ç­”ã‚’æ¤œè¨¼ã—ãªãŒã‚‰ç”Ÿæˆã‚’ç¹°ã‚Šè¿”ã™æŠ€è¡“ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br>        - ã“ã®è¾ºã®æŠ€è¡“ã¯ã‚¯ã‚¨ãƒªãŒéå¸¸ã«è¤‡é›‘ãªå ´åˆã«æœ‰åŠ¹ã§ã¯ã‚ã‚‹ãŒã€ã‚·ãƒ³ãƒ—ãƒ«ãªå ´åˆã¯å¿…è¦ãªã„ã‹ãªã¨ã„ã†å°è±¡ãŒã‚ã‚‹<br><br>        - ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã®å ´åˆã¯ã©ã¡ã‚‰ã‹ã¨ã„ã†ã¨æ³¥è‡­ã„å‰å‡¦ç†ã¨ã‹ãŒåŠ¹ããã†<br><br>- é–¢é€£çŸ¥è­˜å–å¾—<br><br>    - æ¤œç´¢<br><br>        - è¡¨å±¤æ¤œç´¢ï¼ˆTF-IDFãƒ™ã‚¯ãƒˆãƒ«, BM25ï¼‰ãªã©ã®å¤å…¸çš„ãªæ‰‹æ³•ã‚„ã€æ„å‘³æ¤œç´¢ï¼ˆEmbeddingã«åŸºã¥ãæ‰‹æ³•ï¼‰ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br>        - ä¾‹ãˆã°langchainã§ã¯è¡¨å±¤æ¤œç´¢ + æ„å‘³æ¤œç´¢ã®ä¸¡è€…ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ãŠã‚Šã€ç°¡å˜ã«ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãªæ¤œç´¢ãŒå®Ÿç¾ã§ãã‚‹<br><br>    - çŸ¥è­˜æ–‡ç”Ÿæˆ<br><br>        - å¤–éƒ¨çŸ¥è­˜ã¨ã—ã¦æ¤œç´¢ã•ã‚ŒãŸæ–‡æ›¸ã‚’åˆ©ç”¨ã™ã‚‹ã ã‘ã§ãªãã€LLMè‡ªèº«ãŒä¿æŒã™ã‚‹çŸ¥è­˜ã‚’æ´»ç”¨ã™ã‚‹ãŸã‚ã«LLMãŒç”Ÿæˆã—ãŸæ–‡æ›¸ã®ä¸¡æ–¹ã‚’æ´»ç”¨ã™ã‚‹ã¨QAã®æ­£ç­”ç‡ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br>    - æ–‡æ›¸ãƒ•ã‚£ãƒ«ã‚¿<br><br>        - æ¤œç´¢ã§ã‚¯ã‚¨ãƒªã«é–¢é€£ã—ãªã„æ–‡æ›¸ã‚’å–å¾—ã—ã¦ã—ã¾ã†å¿œç­”å“è³ªãŒå¤§å¹…ã«ä½ä¸‹ã™ã‚‹ã“ã¨ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br>            - å€‹äººçš„ã«ã¯ã“ã“ãŒä¸€ç•ªé‡è¦ãªãƒ‘ãƒ¼ãƒˆã ã¨è€ƒãˆã¦ã„ã‚‹<br><br>        - ã¾ãŸã€æ¤œç´¢çµæœã‚’è¦ç´„ã™ã‚‹æ–¹æ³•ã‚‚ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br>    - å†å¸°ãƒ»åå¾©è¨ˆç®—<br><br>        - Retrierverã‹ã‚‰å–å¾—ã—ãŸçµæœã«åŸºã¥ã„ã¦LLMãŒå¿œç­”ã‚’ç”Ÿæˆã—ã€ç”Ÿæˆã—ãŸå¿œç­”ã¨originalã®questionã®ä¸¡æ–¹ã‚’çµ„ã¿åˆã‚ã›ã¦è¿½åŠ ã§Retrieverã‹ã‚‰æ–‡æ›¸ã‚’å–å¾—ã—ç”Ÿæˆã™ã‚‹æ‰‹æ³•ãªã©ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br>    -  ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°<br><br>        - æ¤œç´¢çµæœã®ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚‚å¤ãã‹ã‚‰å­˜åœ¨ã™ã‚‹æŠ€è¡“ã§ã‚ã‚Šã€ç•°ãªã‚‹çŸ¥è­˜ã‚’æŒã¤Rankerã«ã‚ˆã£ã¦ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã•ã›ã‚‹ã“ã¨ã§æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹å ´åˆãŒã‚ã‚‹<br><br>- å›ç­”<br><br>    - å›ç­”æŠ½å‡ºãƒ»ç”Ÿæˆ<br><br>        - å›ç­”ã¨ãªã‚‹éƒ¨åˆ†ã®spanã‚’æŠ½å‡ºã™ã‚‹æ‰‹æ³•ã¨ã€spanã§ã¯ãªããƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br>        - ã“ã®è¾ºã¯æ–‡æ›¸è¦ç´„ã«ãŠã‘ã‚‹Extractive/Abstractive SummarizationæŠ€è¡“ãªã©ã‚‚ã‹ãªã‚Šå¿œç”¨ãŒåŠ¹ãã¨æ€ã‚ã‚Œã‚‹<br><br>- ã‚¤ãƒ³ãƒ‡ã‚¯ã‚·ãƒ³ã‚°<br><br>    - ä¸è¦æ–‡æ›¸ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚„ã€ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã®æˆ¦ç•¥ã€è³‡æ ¼æƒ…å ±ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã™ã‚‹æ–¹æ³•ãªã©ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5ad62f76-e1b9-4c78-847a-45387fe5fb3e" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/634e5386-6ae4-4602-a214-cc8dc126daad" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-11-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1115" target="_blank" rel="noopener noreferrer" class="title-link">ç”ŸæˆAIãŒæŠ±ãˆã‚‹ãƒªã‚¹ã‚¯ã¨å¯¾ç­–, LYCorpâ€˜23</a>
<span class="snippet"><span>Comment</span><p>ã“ã®è³‡æ–™ã‚’ã‚¹ã‚¿ãƒ¼ãƒˆã«Referã—ã¦ã„ã‚‹è«–æ–‡ãªã©ã‚’å‹‰å¼·ã™ã‚‹ã¨ã€GenerativeAIã®ãƒªã‚¹ã‚¯å‘¨ã‚Šã«è©³ã—ããªã‚Œãã†ã€‚ã“ã®è¾ºã¯ç–ã„ã®ã§å‹‰å¼·ã«ãªã‚‹ã€‚<br>ã—ã‹ã—ã€LLMã®AlignmentãŒä¸ååˆ†ã ã£ãŸã‚Šã€Hallucinationã‚’100%é˜²ãã“ã¨ã¯åŸç†çš„ã«ä¸å¯èƒ½ã ã¨æ€ã‚ã‚Œã‚‹ã®ã§ã€ã“ã®è¾ºã¨ã©ã†ä»˜ãåˆã£ã¦ã„ãã‹ãŒLLMã¨ä»˜ãåˆã£ã¦ã„ãä¸Šã§é›£ã—ã„ã¨ã“ã‚ã€‚ã“ã®è¾ºã¯è‡ªåˆ†ãŸã¡ãŒæ´»ç”¨ã—ãŸã„ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«å¿œã˜ã¦æŸ”è»Ÿã«å¯¾å¿œã—ãªã‘ã‚Œã°ãªã‚‰ãšã€ã“ã®è¾ºã®ç´°ã‹ã„ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã‚’ã™ã‚‹åœ°é“ãªä½œæ¥­ã¯ãšã£ã¨æ®‹ã‚Šç¶šã‘ã‚‹ã®ã§ã¯ãªã„ã‹ãªã‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ImageCaptioning.html" target="_blank" rel="noopener noreferrer">#ImageCaptioning</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2023-11-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1114" target="_blank" rel="noopener noreferrer" class="title-link">Zero-shot Learningç¶²ç¾…çš„ã‚µãƒ¼ãƒ™ã‚¤: CLIPãŒåˆ‡ã‚Šé–‹ã„ãŸVision &amp; Languageã®æ–°ã—ã„ä¸–ç•Œ</a>
<span class="snippet"><span>Comment</span><p>ã“ã‚Œã¯ã™ã”ã„ã¾ã¨ã‚â€¦ã€‚ã¾ã é€”ä¸­ã¾ã§ã—ã‹èª­ã‚ã¦ã„ãªã„ã€‚CLIPã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã—ã¦CLIPã‚’å¼•ç”¨ã—ã¦ã„ã‚‹è«–æ–‡ã‹ã‚‰é‡è¦ãªã‚‚ã®ã‚’æ¦‚è¦ä»˜ãã§ã¾ã¨ã‚ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-11-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1112" target="_blank" rel="noopener noreferrer" class="title-link">IBIS2023ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã€Œå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«æ´»ç”¨æŠ€è¡“ã®æœ€å‰ç·šã€</a>
<span class="snippet"><span>Comment</span><p>LLMã®å¿œç”¨ç ”ç©¶ã‚„Promptingã‚’ä¸­å¿ƒã¨ã—ãŸãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã€‚ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚„å¯¾è©±å¼æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã¸ã®æ´»ç”¨ã€ReActã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æœ€é©åŒ–æŠ€è¡“ã€CoTã®åŸºæœ¬ã‹ã‚‰å¿œç”¨ã¾ã§å¹…åºƒãã¾ã¨ã¾ã£ã¦ã„ã‚‹ã®ã§ã€LLMã®å¿œç”¨æŠ€è¡“ã®æ¦‚è¦³ã‚„ã€CoTã‚’å®Ÿè·µã—ãŸã„äººã«éå¸¸ã«æœ‰ç”¨ã ã¨æ€ã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-11-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1111" target="_blank" rel="noopener noreferrer" class="title-link">tsuzumi, NTTâ€™23</a>
<span class="snippet"><span>Comment</span><p>NTTè£½ã®LLMã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯7Bã¨è»½é‡ã ãŒé«˜æ€§èƒ½ã€‚<br>MTBenchã®ã‚ˆã†ãªGPT4ã«å‹æ•—ã‚’åˆ¤å®šã•ã›ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€åœ°ç†ã€æ­´å²ã€æ”¿æ²»ã€ç¤¾ä¼šã«é–¢ã™ã‚‹è³ªå•å¿œç­”ã‚¿ã‚¹ã‚¯ï¼ˆå›³6ï¼‰ã§gpt3.5turboã¨åŒç­‰ã€å›½ç”£LLMã®ä¸­ã§ãƒˆãƒƒãƒ—ã®æ€§èƒ½ã€‚GPT3.5turboã«ã¯ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚„æ•°å­¦ãªã©ã®èƒ½åŠ›ã§ã¯åŠ£ã‚‹ã¨ã®ã“ã¨ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d064e0dc-b598-4853-9466-f56f39986acc" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c8251b2e-f865-4069-a3b7-9bfb848554bb" alt="image" loading="lazy"><br>&gt; ï¼Š6 Rakudaãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br>æ—¥æœ¬èªã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ä¸€ã¤ã§ã€æ—¥æœ¬ã®åœ°ç†ãƒ»æ”¿æ²»ãƒ»æ­´å²ãƒ»ç¤¾ä¼šã«é–¢ã™ã‚‹è³ªå•å¿œç­”ã‚¿ã‚¹ã‚¯ã«ã‚ˆã£ã¦è©•ä¾¡ã‚’è¡Œã†ã€‚<br>URLï¼š


<a href="https://yuzuai.jp/benchmark" target="_blank" rel="noopener noreferrer">https://yuzuai.jp/benchmark</a>


<br><br>&gt;ï¼Š7 Japanese Vicuna QAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br>Rakudaã‚ˆã‚Šã‚‚ã•ã‚‰ã«å¹…åºƒã„ã‚«ãƒ†ã‚´ãƒªã§è¨€èªãƒ¢ãƒ‡ãƒ«ã®QAã‚„æŒ‡ç¤ºé‚è¡Œã®èƒ½åŠ›ã‚’å•ã†è©•ä¾¡æ–¹æ³•ã€‚ä¸€èˆ¬çŸ¥è­˜ã€ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãªã©å¤šæ•°ã®è³ªå•ã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹ã€‚<br>URLï¼š


<a href="https://github.com/hitoshizuku7/LLM_Judge_ku/blob/main/README.md" target="_blank" rel="noopener noreferrer">https://github.com/hitoshizuku7/LLM_Judge_ku/blob/main/README.md</a>


</p>
<p>tsuzumiã¯ã‚¢ãƒ€ãƒ—ã‚¿ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã“ã¨ãªãã€ã•ã¾ã–ã¾ãªçŸ¥è­˜ã‚’æŒãŸã›ãŸã‚Šã€æŒ¯ã‚‹èˆã„ã‚’å¤‰ãˆãŸã‚Šã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã¨ã®ã“ã¨ï¼ˆLoRAã‚¢ãƒ€ãƒ—ã‚¿ã®ã‚ˆã†ãªã‚‚ã®ã ã¨æ€ã‚ã‚Œã‚‹ï¼‰ã€‚<br>ã¾ã¦ã€å°†æ¥çš„ã«è¦–è¦šã‚„è´è¦šãªã©ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œã‚‚å®Ÿæ–½ã€‚</p>
<p>æ€æƒ³ãŒLoRA Hub <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/917" target="_blank" rel="noopener noreferrer">LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA   Composition, Chengsong Huang+, N/A, COLM'24</a>
 ã«è¿‘ãã€ã‚¢ãƒ€ãƒ—ã‚¿ã‚’ç€è„±ã™ã‚Œã°æŸ”è»Ÿã«ç”Ÿæˆã‚’å¤‰ãˆã‚‰ã‚Œã‚‹ã®ã¯æœ‰ç”¨ã ã¨æ€ã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1109" target="_blank" rel="noopener noreferrer" class="title-link">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®Fine-tuningã«ã‚ˆã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ç²å¾—ã®æ¤œè¨, PFN Blog, 2023.10</a>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹è¨˜äº‹ä¸­ã§èˆˆå‘³æ·±ã‹ã£ãŸéƒ¨åˆ†ã‚’å¼•ç”¨<br>&gt; ã¾ã¨ã‚ã‚‹ã¨ã€LoRAã¯ã€[3]ã§è¨€ã‚ã‚Œã¦ã„ã‚‹ã€äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¯å¤§é‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšä½ã„å›ºæœ‰æ¬¡å…ƒã‚’æŒã¡ã€Fine-tuningã«æœ‰åŠ¹ãªä½æ¬¡å…ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚‚å­˜åœ¨ã™ã‚‹ã€ã¨ã„ã†ä¸»å¼µã«ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ã•ã‚Œã€Î”Wã«ãŠã‘ã‚‹é‡ã¿ã®æ›´æ–°ã®å›ºæœ‰æ¬¡å…ƒã‚‚ä½ã„ã¨ã„ã†ä»®èª¬ã®ã‚‚ã¨ã§ã€ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ã§å­¦ç¿’ã™ã‚‹æ‰‹æ³•ã«ãªã‚Šã¾ã™ã€‚<br><br>LoRAãŒæ‹ ã‚Šæ‰€ã¨ã™ã‚‹ä»®èª¬ãŒèª¬æ˜ã•ã‚Œã¦ãŠã‚Šã€å‹‰å¼·ã«ãªã£ãŸã€‚<br><br>&gt; ã“ã†ã—ãŸãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åœ§ç¸®ã™ã‚‹ä»–ã®æŠ€è¡“ã«ã¯æåˆˆã‚Šã‚„çŸ¥è­˜è’¸ç•™ãŒã‚ã‚Šã¾ã™ãŒã€é‡å­åŒ–ã¯ã€ã»ã¨ã‚“ã©ã®å ´åˆã«æåˆˆã‚Šã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹ã¨ã•ã‚Œ[5]ã€è’¸ç•™ã‚ˆã‚Šã‚‚æ‰‹è»½ã«é«˜ç²¾åº¦ãªãƒ¢ãƒ‡ãƒ«ãŒå¾—ã‚‰ã‚Œã‚‹å¯èƒ½æ€§ãŒé«˜ãã€LLMã«ãŠã„ã¦ã‚‚æœ‰åŠ›ãªæŠ€è¡“ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚<br><br>ã“ã‚Œã‚‚çŸ¥ã‚‰ãªã‹ã£ãŸã—ã€æ–‡çŒ®ä»˜ãã§è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒå¤§å¤‰ã‚ã‚ŠãŒãŸã„ã€‚<br><br>&gt; QLoRAä»¥å¤–ã®LoRAã®æ´¾ç”Ÿæ‰‹æ³•ã¨ã—ã¦ã¯ã€ãƒ©ãƒ³ã‚¯ã‚’é©å¿œçš„ã«å®šã‚ã‚‹AdaLoRA[7] ã‚„DyLoRA[8]ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’æ‹¡å¤§ã§ãã‚‹LongLoRA[9]ã€è¡Œåˆ—Aã®é‡ã¿ã‚’freezeã™ã‚‹ã“ã¨ã§ã•ã‚‰ã«è»½é‡åŒ–ã‚’è¡Œã†LoRA-FAã€è¡Œåˆ—ç©ã‚’ã‚¢ãƒ€ãƒãƒ¼ãƒ«ç©ã‚„ã‚¯ãƒ­ãƒãƒƒã‚«ãƒ¼ç©ã§è¨ˆç®—ã™ã‚‹LoHAã‚„LoKRãªã©ãŒã‚ã‚Šã¾ã™ï¼ˆä¸€éƒ¨ã¯LLMã§ã¯ãªãStable Diffusionã®å­¦ç¿’ã§ç”¨ã„ã‚‰ã‚Œã‚‹æ‰‹æ³•ã®é€šç§°ã§ã™ï¼‰ã€‚<br><br>ã“ã®è¾ºã¯å®Ÿéš›ã«LoRAã‚’ä½¿ã†ã“ã¨ã«ãªã£ãŸã‚‰å‹‰å¼·ã—ãŸã„ã€‚<br><br>&gt; è¨€èªãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¯é€šå¸¸ã€Causal LMã®å ´åˆã¯ã€Next Token Predictionã«ãŠã‘ã‚‹Perplexityã®æœ€å°åŒ–ã«ã‚ˆã‚‹æ•™å¸«ãªã—å­¦ç¿’ã«ã‚ˆã£ã¦æœ€é©åŒ–ã•ã‚Œã¾ã™ã€‚<br><br>HuggingFaceã®å®Ÿè£…ã®è©±ã ã¨æ€ã†ãŒã€ãã†ã ã‚ã†ãªã¨æ€ã£ã¦ã¯ã„ãŸãŒã‚½ãƒ¼ã‚¹ã‚’ç¢ºèªã§ãã¦ã„ãªã‹ã£ãŸã®ã§å‹‰å¼·ã«ãªã£ãŸã€‚<br><br>&gt; 7Bã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ä»¥ä¸‹ã®ã‚°ãƒ©ãƒ•ã®ã‚ˆã†ã«ã€ãƒ‡ãƒ¼ã‚¿ã®ä»¶æ•°ã‚’å¢—ã‚„ã™ã¨å­¦ç¿’ãŒã†ã¾ãã„ã‹ãªã„ã¨ã„ã†çµæœãŒå¾—ã‚‰ã‚Œã¾ã—ãŸã€‚ã¾ãŸã€LoRAã®ãƒ©ãƒ³ã‚¯ã¯ä½ã„æ–¹ãŒå­¦ç¿’ãŒå®‰å®šã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚æ­£ç­”ç‡ãŒè‘—ã—ãä½ã„ã‚‚ã®ã¯ã€å­¦ç¿’æ™‚ã®ãƒ­ã‚¹ï¼ˆäº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼‰ãŒéå¸¸ã«å¤§ãããªã£ã¦ãŠã‚Šã€é¸æŠè‚¢ã‚’é–“é•ãˆã‚‹ã¨ã„ã†ã‚ˆã‚Šã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã®æ©Ÿèƒ½ãŒå¤±ã‚ã‚Œã¦ã„ã¾ã—ãŸã€‚<br><br>&gt; ä»–ã«ã¯ã€Instructionãƒ‡ãƒ¼ã‚¿ï¼ˆ1ã¤ã®ã‚¯ã‚¤ã‚ºã®Q&amp;Aï¼‰ãŒ2500ä»¶ã‚’è¶…ãˆã‚‹ã¨ãƒ­ã‚¹ãŒæ‚ªåŒ–ã™ã‚‹ã“ã¨ã‚„ã€2000ä»¶ã§ã‚‚2epochç¹°ã‚Šè¿”ã™ã¨catastrophic forgettingãŒè¦‹ã‚‰ã‚Œã€è¨€èªãƒ¢ãƒ‡ãƒ«ãã®ã‚‚ã®ã®æ€§èƒ½ãŒå¤±ã‚ã‚Œæ„å‘³ã®ãªã„å‡ºåŠ›ã‚’ã—ã¦ã„ã¾ã—ãŸã€‚[17] ã§ã‚‚è¨€åŠã•ã‚Œã¦ã„ã¾ã™ãŒã€æ—¥æœ¬èªã®å­¦ç¿’ã§ã¯ã€æ•°Bã®ãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹LoRAã«ã‚ˆã‚‹Instruction Tuningã¯ã‚ã¾ã‚ŠåŠ¹æœãŒå¾—ã‚‰ã‚Œãªã„å¯èƒ½æ€§ãŒé«˜ã„ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚<br><br>&gt; ä¸€æ–¹ã€13Bã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€8ã€16ã€32ã€64ã„ãšã‚Œã®ãƒ©ãƒ³ã‚¯ã§ã‚‚å¤§ããªå·®ã¯è¦‹ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚<br>&gt; ã“ã‚Œã‚‰ã‹ã‚‰ã€Addtional Trainingã§å­¦ç¿’ã•ã›ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒInstruction Tuningã«å¯¾ã—ã¦è†¨å¤§ã§ã‚ã‚‹å ´åˆã«ã¯å…ˆã«å­¦ç¿’ã—ãŸæ–¹ãŒã‚ˆãã€å°‘æ•°ã®å ´åˆã¯å¾Œã«å­¦ç¿’ã•ã›ã¦ã‚‚Instruction Tuningã®åŠ¹æœã«ã¯æ‚ªå½±éŸ¿ãŒãªã„ã¨ã„ã†ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¾ã—ãŸã€‚<br><br>&gt; ã¾ãŸå­¦ç¿’ã¯ã€åˆæœŸå­¦ç¿’ç‡ã‚’å°ã•ãã—ãŸæ–¹ãŒå®‰å®šã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã¨æ€ã‚ã‚Œã¾ã™ã€‚LoRAã®è«–æ–‡[2] ã§ã¯GPTã®Fine-tuneã¯2e-4ã§è¡Œã‚ã‚Œã¦ãŠã‚Šã€hugging faceã®å®Ÿè£…ã§ã‚‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯2e-4ã¨ãªã£ã¦ã„ã¾ã™ãŒã€ä»–ã®è«–æ–‡ã‚„ãƒ–ãƒ­ã‚°ã§ã¯3e-5ã§ã®ä¾‹ãªã©ã‚‚ã‚ã‚Šã¾ã™ã€‚ã—ã‹ã—ã€å˜ã«ä¸‹ã’ã‚Œã°å®‰å®šã™ã‚‹ã¨ã„ã†ã“ã¨ã§ã‚‚ãªãã€ï¼‘å›ã®è©¦è¡Œã«ãŠã‘ã‚‹è¨ˆç®—ã‚³ã‚¹ãƒˆã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ãªã‚‹å¯èƒ½æ€§ã¯ã‚ã‚Šã¾ã™ã€‚<br><br>Additional Trainingã¨ã¯Finetuningã®ã“ã¨ã§ä¾¿å®œä¸Šã®æœ¬ãƒ–ãƒ­ã‚°ã§ã®å‘¼ç§°ã€‚å®Ÿéš›ã®æ–‡æ›¸ä¸­ã§ã¯å›³ãŒè¤‡æ•°å€‹æŒŸã¾ã‚Œã¦ã„ã‚‹ã€‚<br>ã“ã†ã—ãŸå®Ÿéš›ã«æ‰‹ã‚’å‹•ã‹ã—ãŸä¸Šã§ãªã„ã¨å¾—ã‚‰ã‚Œãªã„çŸ¥è¦‹ã‚’å…¬é–‹ã—ã¦ãã‚Œã‚‹ã®ã¯éå¸¸ã«ã‚ã‚ŠãŒãŸã„ã“ã¨ã ã—ã€æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã§LoRAã‚’ã™ã‚‹éš›ã«éå¸¸ã«å‚è€ƒã«ãªã‚Šãã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1107" target="_blank" rel="noopener noreferrer" class="title-link">StableDiffusion, LLMã®GPUãƒ¡ãƒ¢ãƒªå‰Šæ¸›ã®ã‚ã‚Œã“ã‚Œ</a>
<span class="snippet"><span>Comment</span><p>Gradient Accumulation, Gradient Checkpointingã®èª¬æ˜ãŒä¸å¯§ã§ã‚ã‹ã‚Šã‚„ã™ã‹ã£ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1103" target="_blank" rel="noopener noreferrer" class="title-link">LLMã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŠ€è¡“ã¾ã¨ã‚</a>
<span class="snippet"><span>Comment</span><p>ã–ã£ã¨è¦‹ãŸãŒç¾æ™‚ç‚¹ã§ä¸»è¦ãªã‚‚ã®ã¯ã»ã¼å«ã¾ã‚Œã¦ã„ã‚‹ã®ã§ã¯ã€ã¨ã„ã†å°è±¡<br>å®Ÿéš›ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ãŒè¼‰ã£ã¦ã„ã‚‹ã®ã§ã€ç†è§£ã—ã‚„ã™ã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1101" target="_blank" rel="noopener noreferrer" class="title-link">Evaluating RAG Pipelines</a>
<span class="snippet"><span>Comment</span><p>RAG pipeline ï¼ˆretrieval + generationï¼‰ã‚’è©•ä¾¡ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªRagasã«ã¤ã„ã¦ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>è©•ä¾¡ã«æ´»ç”¨ã•ã‚Œã‚‹æŒ‡æ¨™ã¯ä¸‹è¨˜ã§ã€èƒŒå¾Œã«LLMã‚’æ´»ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€å¤§åŠã®æŒ‡æ¨™ã¯ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿ä¸è¦ã€‚ãŸã ã—ã€context_recallã‚’æ¸¬å®šã™ã‚‹å ´åˆã¯reference answerãŒå¿…è¦ã€‚<br>Ragasã‚¹ã‚³ã‚¢ã¨ã—ã¦ã©ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’åˆ©ç”¨ã™ã‚‹ã‹ã¯é¸æŠã™ã‚‹ã“ã¨ãŒã§ãã€é¸æŠã—ãŸãƒ¡ãƒˆãƒªãƒƒã‚¯ã®harmonic meanã§ã‚¹ã‚³ã‚¢ãŒç®—å‡ºã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/553e7f91-84cd-4aac-bef3-c84bc279547e" alt="image" loading="lazy"><br><br>å„ç¨®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®å†…éƒ¨çš„ãªå‡¦ç†ã¯ä¸‹è¨˜:<br>- faithfullness<br>  - questionã¨ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã«åŸºã¥ã„ã¦ã€statementã®ãƒªã‚¹ãƒˆã‚’LLMã§ç”Ÿæˆã™ã‚‹ã€‚statementã¯å›ç­”ãŒä¸»å¼µã—ã¦ã„ã‚‹å†…å®¹ã‚’LLMãŒè§£é‡ˆã—ãŸã‚‚ã®ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br>  - statementã®ãƒªã‚¹ãƒˆã¨contextãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€statementãŒcontextã«supportã•ã‚Œã¦ã„ã‚‹ã‹ã‚’LLMã§è©•ä¾¡ã™ã‚‹ã€‚<br>  - num. of supported statements / num. of statements ã§ã‚¹ã‚³ã‚¢ãŒç®—å‡ºã•ã‚Œã‚‹<br>- Answer Relevancy<br>  - LLMã§ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã‹ã‚‰é€†ã«è³ªå•ã‚’ç”Ÿæˆã—ã€ç”Ÿæˆã•ã‚ŒãŸè³ªå•ã¨å®Ÿéš›ã®è³ªå•ã®é¡ä¼¼åº¦ã‚’æ¸¬ã‚‹ã“ã¨ã§è©•ä¾¡<br>- Context Relevancy<br>  - ã©ã‚Œã ã‘contextã«ãƒã‚¤ã‚ºãŒå«ã¾ã‚Œã‚‹ã‹ã‚’æ¸¬å®šã™ã‚‹ã€‚<br>  - LLMã§contextã®å„æ–‡ã”ã¨ã«å›ç­”ã«å¿…è¦ãªæ–‡ã‹å¦ã‹ã‚’åˆ¤æ–­ã™ã‚‹<br>  - å›ç­”ã«å¿…è¦ãªæ–‡æ•° / å…¨æ–‡æ•° ã§ã‚¹ã‚³ã‚¢ã‚’ç®—å‡º<br>- Context Recall<br>  - å›ç­”ã«å¿…è¦ãªæƒ…å ±ã‚’å…¨ã¦retrieverãŒæŠ½å‡ºã§ãã¦ã„ã‚‹ã‹<br>  - ground truthã¨ãªã‚‹å›ç­”ã‹ã‚‰statementã‚’LLMã§ç”Ÿæˆã—ã€statementãŒcontextã§ã©ã‚Œã ã‘ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹ã‹ã§ç®—å‡º<br><br>ã¾ãŸã€LangSmithã‚’åˆ©ç”¨ã—ã¦å®Ÿé¨“ã‚’ç®¡ç†ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦ã‚‚è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3a30d238-ac48-401c-906b-4ddb5fca50be" alt="image" loading="lazy"><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1100" target="_blank" rel="noopener noreferrer" class="title-link">LangChainã®RAGã®æ”¹å–„æ³•, LayerXæ©Ÿæ¢°å­¦ç¿’å‹‰å¼·ä¼š</a>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹ãƒªãƒ³ã‚¯ã‹ã‚‰ã®å¼•ç”¨ã€‚LangChainã‹ã‚‰æä¾›ã•ã‚Œã¦ã„ã‚‹Retrieverã®contextæŠ½å‡ºã®æ€§èƒ½æ”¹å–„ã®ãŸã‚ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³<br><br>&gt; Multi representation indexingï¼šæ¤œç´¢ã«é©ã—ãŸæ–‡æ›¸è¡¨ç¾ï¼ˆä¾‹ãˆã°è¦ç´„ï¼‰ã®ä½œæˆ<br>Query transformationï¼šäººé–“ã®è³ªå•ã‚’å¤‰æ›ã—ã¦æ¤œç´¢ã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•<br>Query constructionï¼šäººé–“ã®è³ªå•ã‚’ç‰¹å®šã®ã‚¯ã‚¨ãƒªæ§‹æ–‡ã‚„è¨€èªã«å¤‰æ›ã™ã‚‹æ–¹æ³•<br><br>


<a href="https://blog.langchain.dev/query-transformations/" target="_blank" rel="noopener noreferrer">https://blog.langchain.dev/query-transformations/</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-10-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1096" target="_blank" rel="noopener noreferrer" class="title-link">æ—¥æœ¬èªLLMã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ï¼ˆLLM.jpï¼‰</a>
<span class="snippet"><span>Comment</span><p>LLM.jpã«ã‚ˆã‚‹æ—¥æœ¬èªLLMã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã€‚4-shotsã§ã®çµæœã€ã‹ã¤instructionã‚’ä¸ãˆãŸå ´åˆã®ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã™ã‚‹è©•ä¾¡ã€ã¨ã„ã†ç‚¹ã«ã¯ç•™æ„ã—ãŸã„ã€‚ãŸã¨ãˆã°ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§æ´»ç”¨ã—ãŸã„ã€ã¨ã„ã†å ´åˆã«ã“ã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã®çµæœãŒãã®ã¾ã¾å†ç¾ã•ã‚Œã‚‹ä¿è¨¼ã¯ãªã„ã¨æ¨å¯Ÿã•ã‚Œã‚‹ã€‚<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1079" target="_blank" rel="noopener noreferrer">æ—¥æœ¬èªLLMãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨è‡ªå‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°, PFN Blog, 2023.10</a>
 ã®çŸ¥è¦‹ã§ã‚‚ã‚ã£ãŸé€šã‚Šã€promptingã®ä»•æ–¹ã«ã‚ˆã£ã¦ã‚‚LLMé–“ã§é †ä½ãŒé€†è»¢ã™ã‚‹ç¾è±¡ãªã©ã‚‚èµ·ã“ã‚Šã†ã‚‹ã€‚ã‚ãã¾ã§ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã®å€¤ã¯å‚è€ƒå€¤ã¨ã—ã¦ç•™ã‚ã€ã©ã®LLMã‚’æ¡ç”¨ã™ã‚‹ã‹ã¯ã€è‡ªåˆ†ãŒåˆ©ç”¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚„ãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼ã—ãŸæ–¹ãŒbetterã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>ã‚ã¨ã¯ãã‚‚ãã‚‚æœ¬å½“ã«LLMã‚’ä½¿ã†å¿…è¦ãŒã‚ã‚‹ã®ã‹? <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1024" target="_blank" rel="noopener noreferrer">Prompt2Model: Generating Deployable Models from Natural Language   Instructions, Vijay Viswanathan+, N/A, EMNLP'23</a>
  ã®ã‚ˆã†ãªæ‰‹æ³•ã§ã¯ãƒ€ãƒ¡ãªã®ã‹?ã¿ãŸã„ãªã¨ã“ã‚ã‚‚è€ƒãˆã‚‰ã‚Œã‚‹ã¨è‰¯ã„ã®ã‹ã‚‚ã—ã‚Œãªã„ã€‚<br><br>ä»¥ä¸‹ã‚µã‚¤ãƒˆã‚ˆã‚Šå¼•ç”¨<br>&gt; è©•ä¾¡æ‰‹æ³•ãƒ»ãƒ„ãƒ¼ãƒ«<br>ã“ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®å†…å®¹ã¯llm-jpã§å…¬é–‹ã—ã¦ã„ã‚‹è©•ä¾¡ãƒ„ãƒ¼ãƒ«ã€llm-jp-evalã§å„ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦è©•ä¾¡ã‚’è¡Œãªã£ãŸçµæœã§ã‚ã‚‹ã€‚llm-jp-evalã¯ã€æ—¢å­˜ã®ãƒªãƒ¼ãƒ€ãƒœãƒ¼ãƒ‰ã¨ã¯è¡Œã‚ã‚Œã¦ã„ã‚‹è©•ä¾¡ã¨ã¯ã€ä¸»ã«ä»¥ä¸‹ã®ã¨ã“ã‚ã§é•ã£ã¦ã„ã‚‹ã€‚<br>Alpacaã‚„Big-Benchãªã©ã‚’å‚è€ƒã«ã—ãŸã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚ˆã‚Šã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã¨ã—ã¦ä¸ãˆã¦ã€ãã®å…¥åŠ›ã«å¯¾ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ç”Ÿæˆçµæœã‚’è©•ä¾¡ã™ã‚‹<br>&gt;è©•ä¾¡ã¯åŸºæœ¬ã€ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã—ãŸæ–‡å­—åˆ—ã ã‘ã‚’ä½¿ã£ã¦è¡Œã†<br>&gt;Few shotã§ã®è©•ä¾¡ã‚’è¡Œã£ã¦ãŠã‚Šã€ã“ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«ã¯4-shotsã§ã®çµæœã‚’è¼‰ã›ã¦ã„ã‚‹<br><br>&gt;è©•ä¾¡æ‰‹æ³•ãƒ»ãƒ„ãƒ¼ãƒ«ã®è©³ç´°ã¯llm-jp-evalã‚’æ˜¯éå‚ç…§ã•ã‚ŒãŸã„ã€‚<br><br>&gt;è©•ä¾¡é …ç›®ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>è©•ä¾¡é …ç›®ã¨ã—ã¦ã€ã¾ãš4ã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«ãŠã‘ã‚‹å¹³å‡ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã—ãŸã€‚ã•ã‚‰ã«ãã®4ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®å¹³å‡å€¤ã®å¹³å‡å€¤ã‚’ã¨ã£ãŸå€¤ãŒAVGã§ã‚ã‚‹ã€‚<br>MC (Multi-Choice QA)ï¼šjcommonsenseqa<br>NLI (Natural Language Inference)ï¼šjampã€janliã€jnliã€jsemã€jsick<br>QA (Question Answering)ï¼šjemhopqaã€niilc<br>RC (Reading Comprehension)ï¼šjsquad<br><br>&gt;ãã‚Œãã‚Œã®ã‚«ãƒ†ã‚´ãƒªã®å¹³å‡ã‚’å‡ºã™æ–¹æ³•ã«è¨€èªå­¦çš„ãªæ„å‘³ã¯ãªã„ãŸã‚ã€æœ€çµ‚çš„ãªå¹³å‡å€¤ã¯ã‚ãã¾ã§å‚è€ƒå€¤ã¨ã„ã†ã“ã¨ã«æ³¨æ„ã•ã‚ŒãŸã„ã€‚</p>
<p>JGlueã‚’åˆ©ç”¨ã—ãŸæ—¥æœ¬èªLLMã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã¨ã—ã¦ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1055" target="_blank" rel="noopener noreferrer">Nejumi LLMãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰</a>
 ãªã©ã‚‚ã‚ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-10-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1087" target="_blank" rel="noopener noreferrer" class="title-link">æ—¥æœ¬èªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒJapanese Stable LM 3B-4E1Tã€ã€ŒJapanese Stable LM Gamma 7Bã€ã‚’å…¬é–‹ã—ã¾ã—ãŸ, 2023</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-10-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1080" target="_blank" rel="noopener noreferrer" class="title-link">OpenSource LLM</a>
<span class="snippet"><span>Comment</span><p>zephyr-7B-alpha<br>- 1/10ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§LLaMA2-70Bw-chatè¶…ãˆ<br>


<a href="https://weel.co.jp/media/zephyr-7b-alpha" target="_blank" rel="noopener noreferrer">https://weel.co.jp/media/zephyr-7b-alpha</a>


</p>
<p>- zephyr-7B-Î²<br>ã€€- MTBenchã§llama2-70B-chatè¶…ãˆ<br>ã€€- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1099" target="_blank" rel="noopener noreferrer">Zephyr: Direct Distillation of LM Alignment, Lewis Tunstall+, N/A, arXiv'23</a>
</p>
<p>Zephyr-7B-betaãŒæ—©ãã‚‚TheBlokeæ°ã«ã‚ˆã£ã¦GPTQã§é‡å­åŒ–ã•ã‚Œã€ãªã‚“ã¨ãƒ¢ãƒ‡ãƒ«è‡ªä½“ã¯4.5Gç¨‹åº¦ã—ã‹VRAMã‚’æ¶ˆè²»ã—ãªã„â€¦<br>


<a href="https://huggingface.co/TheBloke/zephyr-7B-beta-GPTQ" target="_blank" rel="noopener noreferrer">https://huggingface.co/TheBloke/zephyr-7B-beta-GPTQ</a>


</p>
<p>- NVIDIA Nemotron-3 8B Models<br><br>    - 


<a href="https://developer.nvidia.com/nemotron-3-8b\" target="_blank" rel="noopener noreferrer">https://developer.nvidia.com/nemotron-3-8b\</a>


<br><br>    - 


<a href="https://huggingface.co/nvidia/nemotron-3-8b-base-4k" target="_blank" rel="noopener noreferrer">https://huggingface.co/nvidia/nemotron-3-8b-base-4k</a>


<br><br>    - 53è¨€èªå¯¾å¿œã€37ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªå¯¾å¿œ, base / chatãŒã‚ã‚‹ </p>
<p>- Mixtral8x7B: LLaMA2-70B, GPT-3.5-turboã¨åŒç­‰ã®æ€§èƒ½<br><br>    - Mistralã‚’Sparse Mixture of Expertsã—ãŸãƒ¢ãƒ‡ãƒ«ã®æ¨¡æ§˜<br><br>    - åå‰ã®é€šã‚Š8ã¤ã®FFNãŒå­˜åœ¨ã—ã¦ã„ã‚‹ãŒã€Top-2ã®FFNãŒé¸æŠã•ã‚Œãã®çµæœãŒé›†ç´„ã•ã‚Œå‡ºåŠ›ãŒæ±ºå®šã•ã‚Œã‚‹<br><br>


<a href="https://mistral.ai/news/mixtral-of-experts/" target="_blank" rel="noopener noreferrer">https://mistral.ai/news/mixtral-of-experts/</a>


<br><br><br><br>- æ—¥æœ¬èªã¾ã¨ã‚<br><br>    - 


<a href="https://note.com/npaka/n/n6043bc8b01bc" target="_blank" rel="noopener noreferrer">https://note.com/npaka/n/n6043bc8b01bc</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1073" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Model ï¼ˆin 2023ï¼‰, OpenAI</a>
<span class="snippet"><span>Comment</span><p>LLMã®ç ”ç©¶é–‹ç™ºå‹•å‘ã‚’ä¿¯ç°ã™ã‚‹ã®ã«æœ‰ç”¨ã‚‰ã—ã„</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1064" target="_blank" rel="noopener noreferrer" class="title-link">MentalLLaMA, 2023</a>
<span class="snippet"><span>Comment</span><p>ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹ã®åˆ†æã«å¯¾ã—ã¦instruction tuningã—ãŸã¯ã˜ã‚ã¦ã®LLM</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1058" target="_blank" rel="noopener noreferrer" class="title-link">Yasa-1</a>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaguring1/status/1709557947813281865?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-10-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1055" target="_blank" rel="noopener noreferrer" class="title-link">Nejumi LLMãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰</a>
<span class="snippet"><span>Comment</span><p>JGLUEã‚’ä½¿ã£ãŸLLMã®æ—¥æœ¬èªã‚¿ã‚¹ã‚¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</p>
<p>v4ãŒå…¬é–‹:<br>


<a href="https://wandb.ai/llm-leaderboard/nejumi-leaderboard4/reports/Nejumi-LLM-4--VmlldzoxMzc1OTk1MA" target="_blank" rel="noopener noreferrer">https://wandb.ai/llm-leaderboard/nejumi-leaderboard4/reports/Nejumi-LLM-4--VmlldzoxMzc1OTk1MA</a>


<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/madyagi/status/1960525757874364462?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1053" target="_blank" rel="noopener noreferrer" class="title-link">LLM-as-a-judge</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1052" target="_blank" rel="noopener noreferrer" class="title-link">OpenAIã€ChatGPTãŒç”»åƒã‚’åˆ†æã™ã‚‹ã€GPT-4Vï¼ˆãƒ“ã‚¸ãƒ§ãƒ³ï¼‰ã€ã‚’ç™ºè¡¨ã€‚å®‰å…¨æ€§ã€å—œå¥½æ€§ã€ç¦ç¥‰æ©Ÿèƒ½ã‚’å¼·åŒ–, AIDB, 2023.09</a>
<span class="snippet"><span>Comment</span><p>ãŠã†â€¦ã‚„ã¹ãˆãªâ€¦<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3ee7dc96-af6f-47f9-98c0-c6be5d9384f1" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1049" target="_blank" rel="noopener noreferrer" class="title-link">Agents: An opensource framework for autonomous language agents</a>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹ã®ç‰¹å¾´ã‚’æŒã¤LLMAgenté–‹ç™ºã®ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯<br><br>- long-short term memory<br>- tool usage<br>- web navigation<br>- multi-agent communication<br>- human-agent interaction<br>- symbolic control<br><br>ã¾ãŸã€ä»–ã®Agent frameworkã¨é•ã„ã€ã‚´ãƒ¼ãƒ«ã‚’é”æˆã™ã‚‹ã ã®ç´°ã‹ã„ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚’ç­–å®šï¼ˆSOP; ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã¨ã‚µãƒ–ã‚´ãƒ¼ãƒ«ã‚’å®šç¾©ï¼‰ã™ã‚‹ã“ã¨ã§ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å¯¾ã—ã¦ãã‚ç´°ã‹ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®šç¾©ã§ãã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<span class="issue_date">Issue Date: 2023-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1042" target="_blank" rel="noopener noreferrer" class="title-link">GGML_GGUF_GPTQã®é•ã„</a>
<span class="snippet"><span>Comment</span><p>é‡å­åŒ–ã«é–¢ã™ã‚‹æŠ€è¡“ã§ã‚ã‚‹GGML, GGUF, GPTQã«é–¢ã™ã‚‹è©³ç´°ãªã¾ã¨ã‚<br><br></p>
<p>ã‚ˆãã‚ã‹ã‚‰ã‚“ãŒç­†è€…ã®è¨€è‘‰ã‚’å¼•ç”¨ã™ã‚‹ã¨<br><br>&gt;llama.cppãªã‚‰GGUFã€Transformerãªã‚‰GPTQã£ã¦æ„Ÿã˜ï¼Ÿ  <br><br><br><br>ã¨ã„ã†ã“ã¨ãªã®ã§ã€ã“ã‚Œã‚‰ã¯é‡å­åŒ–ã‚’è¡Œã†ãŸã‚ã®æŠ€è¡“ã‚’æä¾›ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã‚ã‚Šã€GGUF/GGMLã¯llama.cppã§åˆ©ç”¨å¯èƒ½ã§ã€GPTQã¯ã‚ˆã‚Šæ±ç”¨çš„ã«åˆ©ç”¨å¯èƒ½ãªæ‰‹æ³•ã ã¨æ€ã‚ã‚Œã‚‹ã€‚</p>
<p>GPTQã«ã¤ã„ã¦è«–æ–‡ã‚’ã–ã£ãã‚Šèª­ã‚“ã§ãƒ¡ãƒ¢ã£ãŸ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1043" target="_blank" rel="noopener noreferrer">GPTQ: Accurate Post-Training Quantization for Generative Pre-trained   Transformers, Elias Frantar+, N/A, ICLR'23</a>
 </p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1036" target="_blank" rel="noopener noreferrer" class="title-link">SNLP2023:Is GPT-3 a Good Data Annotator?</a>
<span class="snippet"><span>Comment</span><p>GPT3ã§ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ãŸã‚‰ã€ã‚¿ã‚¹ã‚¯ã”ã¨ã«æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ä½œæˆæ–¹æ³•ã¯ç•°ãªã£ãŸãŒã€äººæ‰‹ã§ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ï¼ˆBERTã§finetuningï¼‰ã‚’ã€ä½ã‚³ã‚¹ãƒˆã§å®Ÿç¾ã§ããŸã‚ˆã€ã¨ã„ã†ç ”ç©¶</p>
<p>ã“ã®è¾ºã®è©±ã¯ã‚‚ã¯ã‚„ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1024" target="_blank" rel="noopener noreferrer">Prompt2Model: Generating Deployable Models from Natural Language   Instructions, Vijay Viswanathan+, N/A, EMNLP'23</a>
 ã‚’ä½¿ãˆã°ã„ã„ã®ã§ã¯ã€ã¨ã„ã†æ°—ãŒã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<span class="issue_date">Issue Date: 2023-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1032" target="_blank" rel="noopener noreferrer" class="title-link">LangChain Cheet Sheet</a>
<span class="snippet"><span>Comment</span><p><img width="1315" alt="image" src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6621fe24-d007-4590-b1a6-b861a6dec4ad"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1031" target="_blank" rel="noopener noreferrer" class="title-link">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«, å²¡å´å…ˆç”Ÿ, 2023</a>
<span class="snippet"><span>Comment</span><p>å²¡å´å…ˆç”Ÿã«ã‚ˆã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«<br><br>æœ€è¿‘ã®LLMã¾ã§ã®æ­´å²ã€transformerãªã©ã®åŸºç¤çš„ãªå†…å®¹ã‹ã‚‰ã€æœ€æ–°ã®å†…å®¹ã¾ã§æ•°å¼ä»˜ãã§è©³ç´°ã«ã¾ã¨ã¾ã£ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2023-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1027" target="_blank" rel="noopener noreferrer" class="title-link">LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ã§ ä½•ãŒã§ãã¦ ä½•ãŒã§ããªã„ã®ã‹</a>
<span class="snippet"><span>Comment</span><p>&gt;LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€ã€Œå½¢å¼ã€ã®å­¦ç¿’ã¯åŠ¹æœçš„ã§ã™ãŒã€ã€Œäº‹å®Ÿã€ã®å­¦ç¿’ã¯ä¸å¾—æ„ã§ã™ã€‚<br><br>&gt; ã‚·ã‚§ã‚¤ã‚¯ã‚¹ãƒ”ã‚¢ã®è„šæœ¬ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (tiny-shakespeare) ã®<br>ã€Œãƒ­ãƒŸã‚ªã€ã‚’ã€Œãƒœãƒ–ã€ã«ç½®ãæ›ãˆã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã€æ–°ãƒ¢ãƒ‡ãƒ«ã®é ­ã®ä¸­ã§ã¯ã€Œãƒ­ãƒŸã‚ªã€ã¨ã€Œãƒœãƒ–ã€ã‚’ã©ã†è¨˜æ†¶ã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚<br><br>ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã‚‚ã€Bã§å§‹ã¾ã‚‹ã‚¸ãƒ¥ãƒªã‚¨ãƒƒãƒˆãŒæ‹ã™ã‚‹äººç‰©ã«ã¤ã„ã¦è³ªå•ã—ã¦ã‚‚ã€ãƒœãƒ–ã¨ç­”ãˆã¦ã¯ãã‚Œãªã„ã€‚<br>&gt; ãƒ­ãƒŸã‚ªã€ã¯ã€Œã‚¸ãƒ¥ãƒªã‚¨ãƒƒãƒˆã€ãŒæ‹ã—ã¦ã„ãŸã“ã®ç”·æ€§ã«é–¢é€£ä»˜ã‘ã‚‰ã‚Œã¦ãŠã‚Šã€ã€Œãƒ­ãƒŸã‚ªã€ã‚’ã€Œãƒœãƒ–ã€ã«ç½®ãæ›ãˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚<br><br>ãªã‚‹ã»ã©ã€‚</p>
<p>å‚è€ƒ: 


<a href="https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts?ref=blog.langchain.dev" target="_blank" rel="noopener noreferrer">https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts?ref=blog.langchain.dev</a>


</p>
<p>imosã•ã‚“ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’å¼•ç”¨<br>&gt; æ–‡ç« ãŒæ‚ªã‹ã£ãŸã®ã§è£œè¶³ã€‚è¿½åŠ å­¦ç¿’ã‚’å…¨ä½“ã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ã§ã™ã‚Œã°çŸ¥è­˜ã¯ç²å¾—ã—ãˆã¾ã™ï¼ˆãŒäº‹å‰å­¦ç¿’ã®çŸ¥è­˜ã‚’å¿˜å´ã™ã‚‹ãƒªã‚¹ã‚¯ã¯é«˜ã„ï¼‰ã€‚å··ã§ã‚ˆããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å‘¼ã°ã‚Œã‚‹ã‚‚ã®ã¯ã€çŸ¥è­˜ã‚’å¸ã‚‹ã‚‰ã—ã„MLPéƒ¨ã‚’è§¦ã‚‰ãšè‡ªå·±æ³¨æ„æ©Ÿæ§‹éƒ¨ã®ã¿ã‚’æ›´æ–°ã™ã‚‹ã®ã§ã€ãã‚‚ãã‚‚çŸ¥è­˜ã‚’å¢—ã‚„ã™ã®ã¯é›£ã—ã„ã¨ã„ã†èªè­˜ã§ã™ã€‚<br><br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imos/status/1696507787067756846?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<span class="issue_date">Issue Date: 2023-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1026" target="_blank" rel="noopener noreferrer" class="title-link">Metaã®ã€ŒLlama 2ã€ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸå•†ç”¨åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªLLMã€ŒELYZA-japanese-Llama-2-7bã€ã‚’å…¬é–‹ã—ã¾ã—ãŸ</a>
<span class="snippet"><span>Comment</span><p>å•†ç”¨åˆ©ç”¨å¯èƒ½ã€70å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚<br>ELYZAç¤¾ãŒç‹¬è‡ªã«ä½œæˆã—ãŸè©•ä¾¡ã‚»ãƒƒãƒˆã§ã¯æ—¥æœ¬èªã®OpenLLMã®ä¸­ã§æœ€é«˜æ€§èƒ½ã€‚ãŸã ã—ã€ãƒ¢ãƒ‡ãƒ«é¸å®šã®æ®µéšã§ã“ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€æœ‰åˆ©ã«åƒã„ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã¨ã®ã“ã¨ã€‚<br><br>ä¸€èˆ¬çš„ã«åˆ©ç”¨ã•ã‚Œã‚‹æ—¥æœ¬èªã®è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã§ã¯ã€ãªã‚“ã¨ã‚‚è¨€ã„é›£ã„ã€‚è‰¯ã„ã‚¿ã‚¹ã‚¯ã‚‚ã‚ã‚Œã°æ‚ªã„ã‚¿ã‚¹ã‚¯ã‚‚ã‚ã‚‹ã€‚ãŒã€å¤šåˆ†è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿è‡ªä½“ã‚‚ã‚ã¾ã‚Šæ•´å‚™ã¯é€²ã‚“ã§ã„ãªã„ã¨æƒ³åƒã•ã‚Œã‚‹ãŸã‚ã€ä¸€æ—¦è§¦ã£ã¦ã¿ã‚‹ã®ãŒè‰¯ã„ã®ã ã¨æ€ã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<span class="issue_date">Issue Date: 2023-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1025" target="_blank" rel="noopener noreferrer" class="title-link">zeno-build</a>
<span class="snippet"><span>Comment</span><p>MTã§ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ<br>


<a href="https://github.com/zeno-ml/zeno-build/tree/main/examples/analysis_gpt_mt/report" target="_blank" rel="noopener noreferrer">https://github.com/zeno-ml/zeno-build/tree/main/examples/analysis_gpt_mt/report</a>


</p>
<p>LLMã®å®Ÿé¨“ç®¡ç†ã‚’å®¹æ˜“ã«å®Ÿæ–½ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã€ç•°ãªã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã€ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã®å®Ÿé¨“ãªã©ã‚’ç°¡å˜ã«å®Ÿæ–½ã§ãã‚‹ã€‚è©•ä¾¡çµæœã‚’è‡ªå‹•çš„ã«å¯è¦–åŒ–ã—ã€interactiveã«è¡¨ç¤ºã™ã‚‹ãƒ–ãƒ©ã‚¦ã‚¶ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ä½œæˆå¯èƒ½ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1021" target="_blank" rel="noopener noreferrer" class="title-link">Anti-hype LLM Reading list</a>
<span class="snippet"><span>Comment</span><p>LLMã®ã‚µãƒ¼ãƒ™ã‚¤ã€BERTç­‰ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®è«–æ–‡ã€è‡ªå‰ã§LLMã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã«å¿…è¦ãªè«–æ–‡ãŒã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«ã¾ã¨ã‚ã‚‰ã‚ŒãŸgist</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/STS%20(SemanticTextualSimilarity).html" target="_blank" rel="noopener noreferrer">#STS (SemanticTextualSimilarity)</a>
<span class="issue_date">Issue Date: 2023-07-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/910" target="_blank" rel="noopener noreferrer" class="title-link">OpenAI ã® Embeddings API ã¯ã‚¤ã‚±ã¦ã‚‹ã®ã‹ã€å®šé‡çš„ã«èª¿ã¹ã¦ã¿ã‚‹</a>
<span class="snippet"><span>Comment</span><p>[JSTSã‚¿ã‚¹ã‚¯](


<a href="https://github.com/yahoojapan/JGLUE)%E3%81%A7%E3%81%AF%E3%80%81[Tohoku" target="_blank" rel="noopener noreferrer">https://github.com/yahoojapan/JGLUE)ã§ã¯ã€[Tohoku</a>


BERT v3](


<a href="https://github.com/cl-tohoku/bert-japanese/tree/main#model-performances)" target="_blank" rel="noopener noreferrer">https://github.com/cl-tohoku/bert-japanese/tree/main#model-performances)</a>


ã¨ [LUKE](


<a href="https://github.com/studio-ousia/luke)%E3%81%8C%E6%9C%80%E3%82%82%E6%80%A7%E8%83%BD%E3%81%8C%E8%89%AF%E3%81%84%E3%82%89%E3%81%97%E3%81%84%E3%80%82" target="_blank" rel="noopener noreferrer">https://github.com/studio-ousia/luke)ãŒæœ€ã‚‚æ€§èƒ½ãŒè‰¯ã„ã‚‰ã—ã„ã€‚</a>


<br><br>[SimCSE](


<a href="https://huggingface.co/pkshatech/simcse-ja-bert-base-clcmlp)%E3%82%88%E3%82%8A%E3%82%82%E6%80%A7%E8%83%BD%E3%81%8C%E8%89%AF%E3%81%84%E3%81%AE%E3%81%AF%E8%88%88%E5%91%B3%E6%B7%B1%E3%81%84%E3%80%82" target="_blank" rel="noopener noreferrer">https://huggingface.co/pkshatech/simcse-ja-bert-base-clcmlp)ã‚ˆã‚Šã‚‚æ€§èƒ½ãŒè‰¯ã„ã®ã¯èˆˆå‘³æ·±ã„ã€‚</a>


<br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Faithfulness.html" target="_blank" rel="noopener noreferrer">#Faithfulness</a>
<span class="issue_date">Issue Date: 2023-07-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/896" target="_blank" rel="noopener noreferrer" class="title-link">Measuring Faithfulness in Chain-of-Thought Reasoning, Anthropic, 2023</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€Chain-of-Thoughtï¼ˆCoTï¼‰æ¨è«–ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§è³ªå•ã«ç­”ãˆã‚‹æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ãã®æ¨è«–ãŒå®Ÿéš›ã®æ¨è«–ã‚’å¿ å®Ÿã«è¡¨ã—ã¦ã„ã‚‹ã‹ã¯ä¸æ˜ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€CoTæ¨è«–ã®å¿ å®Ÿã•ã‚’èª¿æŸ»ã—ã€CoTã«ä»‹å…¥ã™ã‚‹ã“ã¨ã§ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ãŒã©ã®ã‚ˆã†ã«å¤‰åŒ–ã™ã‚‹ã‹ã‚’èª¿ã¹ã‚‹ã€‚çµæœã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã‚„ã‚¿ã‚¹ã‚¯ã«ã‚ˆã£ã¦CoTã®å¿ å®Ÿã•ãŒç•°ãªã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2023-07-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/894" target="_blank" rel="noopener noreferrer" class="title-link">trl_trlx</a>
<span class="snippet"><span>Comment</span><p>TRL - å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚‹LLMã®å­¦ç¿’ã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª<br>


<a href="https://note.com/npaka/n/nbb974324d6e1" target="_blank" rel="noopener noreferrer">https://note.com/npaka/n/nbb974324d6e1</a>


</p>
<p>trlã‚’ä½¿ã£ã¦æ—¥æœ¬èªLLMã‚’SFTã‹ã‚‰RLHFã¾ã§ä¸€é€šã‚Šå­¦ç¿’ã•ã›ã¦ã¿ã‚‹<br>


<a href="https://www.ai-shift.co.jp/techblog/3583" target="_blank" rel="noopener noreferrer">https://www.ai-shift.co.jp/techblog/3583</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/886" target="_blank" rel="noopener noreferrer" class="title-link">LLaMA2ã‚’3è¡Œã§è¨“ç·´</a>
<span class="snippet"><span>Comment</span><p>LLaMA2ã‚’3è¡Œã§ã€1ã¤ã®A100GPUã€QLoRAã§ã€è‡ªå‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã™ã‚‹æ–¹æ³•</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/880" target="_blank" rel="noopener noreferrer" class="title-link">Quantized LLaMA2</a>
<span class="snippet"><span>Comment</span><p>LLaMA2ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ä½œã•ã›ã‚‹ãŸã‚ã«ã€QLoRAã§é‡å­åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/879" target="_blank" rel="noopener noreferrer" class="title-link">LLongMA2</a>
<span class="snippet"><span>Comment</span><p>LLaMA2ã®context windowã‚’8kã«ã—ã¦è¨“ç·´ã€‚ã‚ªãƒªã‚¸ãƒŠãƒ«ã®LLaMA2ã¨åŒç­‰ã®æ€§èƒ½ã§8k contextã‚’åˆ©ç”¨å¯èƒ½ã€‚</p>
<p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/enricoshippole/status/1682054848584228866?s=46&t=LJIgfuO352oK3zU2FKFpNA"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/DialogueGeneration.html" target="_blank" rel="noopener noreferrer">#DialogueGeneration</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/876" target="_blank" rel="noopener noreferrer" class="title-link">ChatBot Arenaã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</a>
<span class="snippet"><span>Comment</span><p>33kã®conversationã€2ã¤ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å¯¾ã™ã‚‹äººé–“ã®preferenceã‚¹ã‚³ã‚¢ä»˜ã<br>20ç¨®é¡ã®SoTAãƒ¢ãƒ‡ãƒ«ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å«ã¿ã€13kã®ãƒ¦ãƒ‹ãƒ¼ã‚¯IPã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒã‚ã‚Šã€3Kã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã«ã‚ˆã‚‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ã</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/825" target="_blank" rel="noopener noreferrer" class="title-link">Are Human Explanations Always Helpful? Towards Objective Evaluation of Human Natural Language Explanations</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€èª¬æ˜å¯èƒ½ãªNLPãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦ã€äººé–“ã«ã‚ˆã‚‹æ³¨é‡ˆä»˜ã‘ã®èª¬æ˜ã®å“è³ªã‚’è©•ä¾¡ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦æ¤œè¨ã—ã¦ã„ã¾ã™ã€‚å¾“æ¥ã®Simulatabilityã‚¹ã‚³ã‚¢ã«ä»£ã‚ã‚‹æ–°ã—ã„ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ææ¡ˆã—ã€5ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§è©•ä¾¡ã—ã¾ã—ãŸã€‚çµæœã¨ã—ã¦ã€ææ¡ˆã—ãŸãƒ¡ãƒˆãƒªãƒƒã‚¯ãŒã‚ˆã‚Šå®¢è¦³çš„ãªè©•ä¾¡ã‚’å¯èƒ½ã«ã™ã‚‹ä¸€æ–¹ã€Simulatabilityã¯ä¸ååˆ†ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/796" target="_blank" rel="noopener noreferrer" class="title-link">Auto train advanced</a>
<span class="snippet"><span>Comment</span><p>Hugging Face Hubä¸Šã®ä»»æ„ã®LLMã«å¯¾ã—ã¦ã€localã®ã‚«ã‚¹ã‚¿ãƒ ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦finetuningãŒãƒ¯ãƒ³ãƒ©ã‚¤ãƒ³ã§ã§ãã‚‹ã€‚<br>peftã‚‚ä½¿ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<span class="issue_date">Issue Date: 2023-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/784" target="_blank" rel="noopener noreferrer" class="title-link">Awesome Multimodal LLMs</a>
<span class="snippet"><span>Comment</span><p>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªLLMã®ãƒªã‚¹ãƒˆãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2023-07-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/777" target="_blank" rel="noopener noreferrer" class="title-link">How Long Can Open-Source LLMs Truly Promise on Context Length?, 2023</a>
<span class="snippet"><span>Comment</span><p>LLMã®contexté•·ã‚’ä¼¸ã°ã™éš›ã®æ–¹æ³•ã¨å¾—ã‚‰ã‚ŒãŸçŸ¥è¦‹ãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<span class="issue_date">Issue Date: 2023-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/771" target="_blank" rel="noopener noreferrer" class="title-link">LM Flow</a>
<span class="snippet"><span>Comment</span><p>ä¸€èˆ¬çš„ãªFoundation Modelã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã‚’ç°¡ç´ åŒ–ã™ã‚‹æ‹¡å¼µå¯èƒ½ãªãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã€‚ç¶™ç¶šçš„ãªpretragning, instruction tuning, parameter efficientãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°,alignment tuning,å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ãªã©ã•ã¾ã–ã¾ãªæ©Ÿèƒ½ã‚’ã‚µãƒãƒ¼ãƒˆã€‚<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1672953412927799298?s=46&t=ajzDWio8pEbrezgj40Dobw"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/767" target="_blank" rel="noopener noreferrer" class="title-link">OpenLLaMA 13B, 2023</a>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4268eb3f-349f-4ebe-adeb-2cbfcb7cfe17" alt="image" loading="lazy"></p>
<p>ãã‚‚ãã‚‚OpenLLaMAã«ã¯ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®LLaMAã¨æ¯”è¼ƒã—ã¦ã€tokenizerãŒã‚¹ãƒšãƒ¼ã‚¹ã‚’ç„¡è¦–ã™ã‚‹ã¨ã„ã†issueãŒã‚ã‚‹æ¨¡æ§˜ã€‚ã‚¹ãƒšãƒ¼ã‚¹ã®æƒ…å ±ãŒã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªã‚¿ã‚¹ã‚¯ã€ãŸã¨ãˆã°code generationãªã©ã«ã¯è¦æ³¨æ„ã€‚<br><br>


<a href="https://github.com/openlm-research/open_llama/issues/40" target="_blank" rel="noopener noreferrer">https://github.com/openlm-research/open_llama/issues/40</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/678" target="_blank" rel="noopener noreferrer" class="title-link">Prompt Engineering vs. Blind Prompting, 2023</a>
<span class="snippet"><span>Comment</span><p>experimentalãªæ‰‹æ³•ã§prompt engineeringã™ã‚‹éš›ã®overview</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/676" target="_blank" rel="noopener noreferrer" class="title-link">open LLM Leaderboard</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/PsychologicalScience.html" target="_blank" rel="noopener noreferrer">#PsychologicalScience</a>
<span class="issue_date">Issue Date: 2023-05-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/673" target="_blank" rel="noopener noreferrer" class="title-link">Can AI language models replace human participants?, Trends in Cognitive Sciences, 2023</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒäººé–“ã®ã‚ˆã†ãªåˆ¤æ–­ã‚’è¡Œã†ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒå¿ƒç†å­¦ã®ç ”ç©¶ã«ãŠã„ã¦äººé–“ã®ä»£ã‚ã‚Šã«ãªã‚‹å¯èƒ½æ€§ã‚„æ¡ä»¶ã«ã¤ã„ã¦æ¢æ±‚ã—ã€AIã‚’å‚åŠ è€…ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹éš›ã®æ³¨æ„ç‚¹ã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2023-05-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/665" target="_blank" rel="noopener noreferrer" class="title-link">OpenSource PaLM, 2023</a>
<span class="snippet"><span>Comment</span><p>150m,410m,1bã®ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ã€‚Googleã®540bã«ã¯é ãåŠã°ãªã„ã—ã€emergent abilityã‚‚æœŸå¾…ã§ããªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã ãŒã€ã©ã®ç¨‹åº¦ã®æ€§èƒ½ãªã®ã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2023-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/661" target="_blank" rel="noopener noreferrer" class="title-link">StarCoderBase_StarCoder, 2023</a>
<span class="snippet"><span>Comment</span><p>ãƒ»15.5Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿<br>ãƒ»80ç¨®é¡ä»¥ä¸Šã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§è¨“ç·´<br>ãƒ»Multi Query Attentionã‚’åˆ©ç”¨<br>ãƒ»context window size 8192<br>ãƒ»Fill in the middle objectiveã‚’åˆ©ç”¨<br><br>Instruction tuningãŒã•ã‚Œã¦ãŠã‚‰ãšã€prefixã¨suffixã®é–“ã‚’åŸ‹ã‚ã‚‹ã‚ˆã†ãªè¨“ç·´ã®ã•ã‚Œæ–¹ã‚’ã—ã¦ã„ã‚‹ã®ã§ã€ãŸã¨ãˆã°é–¢æ•°åã‚’inputã—ã¦ã€ãã®middleï¼ˆé–¢æ•°ã®ä¸­èº«ï¼‰ã‚’å‡ºåŠ›ã•ã›ã‚‹ã€ã¨ã„ã£ãŸä½¿ã„æ–¹ã«ãªã‚‹æ¨¡æ§˜ã€‚</p>
<p>paper: 


<a href="https://drive.google.com/file/d/1cN-b9GnWtHzQRoE7M7gAEyivY0kl4BYs/view" target="_blank" rel="noopener noreferrer">https://drive.google.com/file/d/1cN-b9GnWtHzQRoE7M7gAEyivY0kl4BYs/view</a>


</p>
<p>StarCoder:<br>


<a href="https://huggingface.co/bigcode/starcoder" target="_blank" rel="noopener noreferrer">https://huggingface.co/bigcode/starcoder</a>


</p>
<p>StarCoderBaseã‚’35Bã®python tokenã§finetuningã—ãŸãƒ¢ãƒ‡ãƒ«ã€‚<br>æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚é«˜æ€§èƒ½ã¨ä¸»å¼µ<br><br><img src="https://user-images.githubusercontent.com/12249301/236622130-5e7aa6aa-5f9b-4b0e-9962-ff1beaa03225.jpeg" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/659" target="_blank" rel="noopener noreferrer" class="title-link">MPT-7B, 2023</a>
<span class="snippet"><span>Comment</span><p>æ–°ãŸãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMã€‚<br>ä¸‹è¨˜ãƒ„ã‚¤ãƒ¼ãƒˆã‚ˆã‚Šå¼•ç”¨:<br><br>ãƒ»å•†ç”¨åˆ©ç”¨å¯èƒ½<br>ãƒ»6ä¸‡5000ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨å¯èƒ½<br>ãƒ»7Bã¨æ¯”è¼ƒçš„å°ã•ã„ãƒ¢ãƒ‡ãƒ«ãªãŒã‚‰é«˜æ€§èƒ½<br>ãƒ»æ—¥æœ¬èªã‚’æ‰±ãˆæ€§èƒ½ãŒé«˜ã„<br><br>ã¨ã®ã“ã¨ã€‚<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imai_eruel/status/1654629078878793729?s=46&t=nqpG5xvXzdg7yUPU4IfD3A"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ChatGPTã®LLMã¨æ¯”è¼ƒã™ã‚‹ã¨ã€ã–ã£ã¨ä¾‹ã‚’è¦‹ãŸæ„Ÿã˜è³ªå•å¿œç­”ã¨ã—ã¦ã®èƒ½åŠ›ã¯ãã“ã¾ã§é«˜ããªã•ãã†ãªå°è±¡ã€‚<br>finetuningã—ãªã„é™ã‚Šã¯GPT3,GPT4ã§è‰¯ã•ã’ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/626" target="_blank" rel="noopener noreferrer" class="title-link">Towards Complex Reasoning: the Polaris of Large Language Models, Yao Fu, 2023.05</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Assessment.html" target="_blank" rel="noopener noreferrer">#Assessment</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/623" target="_blank" rel="noopener noreferrer" class="title-link">ChatBot Arena, lmsys org, 2023.05</a>
<span class="snippet"><span>Comment</span><p>ã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚·ãƒ³ã‚°å‹ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆè©•ä¾¡ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã€‚ãƒ¦ãƒ¼ã‚¶ã¯ã‚·ã‚¹ãƒ†ãƒ ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã¨ã€äºŒã¤ã®anonymisedã•ã‚ŒãŸLLMã¨å¯¾è©±ã—ã€ã©ã¡ã‚‰ãŒå„ªã‚Œã¦ã„ãŸã‹ã‚’votingã™ã‚‹ã€‚ã™ã¹ã¦ã®ã‚·ã‚¹ãƒ†ãƒ ã¨ãƒ¦ãƒ¼ã‚¶ã®interactionã¯ãƒ­ã‚®ãƒ³ã‚°ã•ã‚Œã¦ãŠã‚Šã€æœ€çµ‚çš„ã«Elo Ratingã§LLM.ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»˜ã‘ã™ã‚‹ã€‚</p>
<p>Arena-Hardã¨å‘¼ã°ã‚Œã‚‹liveã‚¢ãƒªãƒ¼ãƒŠãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å…¬é–‹ã€‚MT-Benchã‚ˆã‚Šã‚‚è­˜åˆ¥åŠ›ãŒé«˜ãã€Chatbot Arenaã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¨ã®agreementãŒé«˜ã„ã¨ã®ã“ã¨ã€‚<br><br>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lmsysorg/status/1782179997622649330?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2faafce4-effd-40b1-8760-d9639d3df6aa" alt="image" loading="lazy"><p>éå»ã®ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã¯ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/876" target="_blank" rel="noopener noreferrer">ChatBot Arenaã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</a>
 ãªã©ã‚‚ã‚ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/618" target="_blank" rel="noopener noreferrer" class="title-link">OpenLLaMA</a>
<span class="snippet"><span>Comment</span><p>LLaMAã¨åŒæ§˜ã®æ‰‹æ³•ã‚’ä¼¼ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é©ç”¨ã—å•†ç”¨åˆ©ç”¨å¯èƒ½ãªLLaMAã‚’æ§‹ç¯‰ã—ãŸæ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/616" target="_blank" rel="noopener noreferrer" class="title-link">LLM ecosystem graphs</a>
<span class="snippet"><span>Comment</span><p>æ§˜ã€…ãªfonudation modelã€ãã‚Œã‚‰ã‚’åˆ©ç”¨ã—ãŸã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ä¾å­˜é–¢ä¿‚ãŒã¾ã¨ã¾ã£ãŸãƒšãƒ¼ã‚¸</p>
<p>Percy Liangã®ã‚°ãƒ«ãƒ¼ãƒ—ãŒé‹ç”¨ã—ã¦ã‚‹ã£ã½ã„ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Assessment.html" target="_blank" rel="noopener noreferrer">#Assessment</a>
<span class="issue_date">Issue Date: 2023-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/603" target="_blank" rel="noopener noreferrer" class="title-link">PandaLM</a>
<span class="snippet"><span>Comment</span><p>ç•°ãªã‚‹LLMã‚’å†ç¾æ€§ã®ã‚ã‚‹å½¢ã§è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª<br>2ã¤ã®ç•°ãªã‚‹LLMã®outputã‚’æ¯”è¼ƒã—ã€ã©ã¡ã‚‰ãŒå„ªã‚Œã¦ã„ã‚‹ã‹ç†ç”±ä»˜ãã§èª¬æ˜ã™ã‚‹ã€‚äººé–“ãŒä½œæˆã—ã¦1000ã‚µãƒ³ãƒ—ãƒ«ã®å¤šæ§˜ãªã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã„è©•ä¾¡ã§ãã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/562" target="_blank" rel="noopener noreferrer" class="title-link">HuggingChat, 2023</a>
<span class="snippet"><span>Comment</span><p>closedãªä¸–ç•Œã§é–‹ç™ºã•ã‚Œã‚‹OpenAIã®ChatGPTã«å¯¾ã—ã¦ã€Openãªã‚‚ã®ãŒå¿…è¦ã¨ã„ã†ã“ã¨ã§ã€huggingfaceãŒå‡ºã—ãŸchatã‚·ã‚¹ãƒ†ãƒ </p>
<p>å…¬é–‹ã¯ã™ã§ã«çµ‚äº†ã—ã¦ã„ã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/560" target="_blank" rel="noopener noreferrer" class="title-link">Unleashing Infinite-Length Input Capacity for Large-scale Language Models with Self-Controlled Memory System, 2023</a>
<span class="snippet"><span>Comment</span><p>&gt; Our findings indicate that our system outperforms ChatGPT in handling ultra-long inputs or conversations.<br><br><br><br>ã¨æ›¸ã„ã¦ã‚ã‚‹ãŒã€å®šé‡è©•ä¾¡ã®çµæœãŒå…¨ãæ›¸ã„ã¦ã„ãªã„æ¨¡æ§˜ã€‚å…¨ãã‚‚ã£ã¦ä¿¡ç”¨ã§ããªã„ã€‚èª­ã‚€å¿…è¦ãªã—ã€‚</p>
<p>4/27æ™‚ç‚¹ã ã¨è¨˜è¿°ã•ã‚Œã¦ã„ãªã‹ã£ãŸã¨æ€ã†ãŒã€ç¾æ™‚ç‚¹ã§ã¯å®šé‡è©•ä¾¡ãŒè¿½åŠ ã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/557" target="_blank" rel="noopener noreferrer" class="title-link">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«é–“ã®æ€§èƒ½æ¯”è¼ƒã¾ã¨ã‚</a>
<span class="snippet"><span>Comment</span><p>å‚è€ƒã«ãªã‚‹</p>
<p>ç¾çŠ¶ã ã¨ç ”ç©¶ç”¨ã§ã‚ã‚Œã°llama, å•†ç”¨åˆ©ç”¨ãªã‚‰text-davinci-003ã‚ã‚‹ã„ã¯FlanT5-xxlã‚ãŸã‚Šã«ãªã‚Šãã†</p>
<p>LLM Worksheetï¼š<br><br>


<a href="https://docs.google.com/spreadsheets/d/1kT4or6b0Fedd-W_jMwYpb63e1ZR3aePczz3zlbJW-Y4/edit#gid=0" target="_blank" rel="noopener noreferrer">https://docs.google.com/spreadsheets/d/1kT4or6b0Fedd-W_jMwYpb63e1ZR3aePczz3zlbJW-Y4/edit#gid=0</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/528" target="_blank" rel="noopener noreferrer" class="title-link">LoRAè«–æ–‡è§£èª¬, Hayato Tsukagoshi, 2023.04</a>
<span class="snippet"><span>Comment</span><p>ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ä¸€éƒ¨ã®ç·šå½¢å±¤ã®éš£ã«ã€ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—A,Bã‚’å°å…¥ã—ã€A,Bã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’finetuningã®å¯¾è±¡ã¨ã™ã‚‹ã“ã¨ã§ã€ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’æ¿€æ¸›ã•ã›ãŸä¸Šã§åŒç­‰ã®äºˆæ¸¬æ€§èƒ½ã‚’é”æˆã—ã€æ¨è«–é€Ÿåº¦ã‚‚å¤‰ã‚ã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹finetuningæ‰‹æ³•ã®è§£èª¬</p>
<p>LoRAã‚’ä½¿ã†ã¨ã€ã§ã‹ã™ãã‚‹ãƒ¢ãƒ‡ãƒ«ã ã¨ã€ãã‚‚ãã‚‚GPUã«è¼‰ã‚‰ãªã„å•é¡Œã‚„ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã§ã‹ã™ããƒ¯ãƒ­ã‚¿å•é¡ŒãŒå›é¿ã§ãã‚‹ã€‚<br><br>å‰è€…ã¯äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®BPã®ãŸã‚ã®å‹¾é…ã‚’ä¿å­˜ã—ã¦ãŠãå¿…è¦ãŒãªããªã‚‹ãŸã‚å­¦ç¿’æ™‚ã«ãƒ¡ãƒ¢ãƒªç¯€ç´„ã«ãªã‚‹ã€‚å¾Œè€…ã¯A,Bã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã ã‘ä¿å­˜ã™ã‚Œã°ã„ã„ã®ã§ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ç¯€ç´„ã«ãªã‚‹ã€‚<br><br>ã‹ã¤ã€å­¦ç¿’é€Ÿåº¦ãŒ25%ç¨‹åº¦æ—©ããªã‚‹ã€‚</p>
<p>æ—¢å­˜ç ”ç©¶ã§ã‚ã‚‹Adapterï¼ˆtransformerã®ä¸­ã«å­¦ç¿’å¯èƒ½ãªMLPã‚’å·®ã—è¾¼ã‚€æ‰‹æ³•ï¼‰ã¯æ¨è«–ã‚³ã‚¹ãƒˆãŒå¢—åŠ ã—ã€prefix tuningã¯å­¦ç¿’ãŒéå¸¸ã«é›£ã—ãã€é«˜ã„æ€§èƒ½ã‚’é”æˆã™ã‚‹ãŸã‚ã«prefixã¨ã—ã¦128 tokenå…¥ã‚ŒãŸã‚Šã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚</p>
<p>huggingfaceãŒã™ã§ã«LoRAã‚’å®Ÿè£…ã—ã¦ã„ã‚‹<br>


<a href="https://github.com/huggingface/peft" target="_blank" rel="noopener noreferrer">https://github.com/huggingface/peft</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2023-04-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/520" target="_blank" rel="noopener noreferrer" class="title-link">LangChain</a>
<span class="snippet"><span>Comment</span><p>- LangChain ã® Googleã‚«ã‚¹ã‚¿ãƒ æ¤œç´¢ é€£æºã‚’è©¦ã™<br><br>  - 


<a href="https://note.com/npaka/n/nd9a4a26a8932" target="_blank" rel="noopener noreferrer">https://note.com/npaka/n/nd9a4a26a8932</a>


</p>
<p>- LangChainã®Getting Startedã‚’Google Colaboratoryã§ã‚„ã£ã¦ã¿ã‚‹ â‘£Agents<br><br>    - 


<a href="https://zenn.dev/kun432/scraps/8216511783e3da" target="_blank" rel="noopener noreferrer">https://zenn.dev/kun432/scraps/8216511783e3da</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="articles/AES(AutomatedEssayScoring).html" target="_blank" rel="noopener noreferrer">#AES(AutomatedEssayScoring)</a>
<span class="issue_date">Issue Date: 2023-04-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/515" target="_blank" rel="noopener noreferrer" class="title-link">Exploring the Potential of Using an AI Language Model for Automated Essay Scoring, Mizumoto+, Research Methods in Applied Linguisticsâ€˜23</a>
<span class="snippet"><span>Comment</span><p>è‘—è€…ã«ã‚ˆã‚‹ãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mizumotoatsushi/status/1641754298496471040?s=46&t=TIr1-wDC_j5MPU3TvCVWMg"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ã«ã‚ˆã‚‹ãƒ–ãƒ­ã‚°:<br><br>


<a href="https://mizumot.com/lablog/archives/1805" target="_blank" rel="noopener noreferrer">https://mizumot.com/lablog/archives/1805</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2023-03-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/514" target="_blank" rel="noopener noreferrer" class="title-link">Publicly available instruction-tuned models</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<span class="issue_date">Issue Date: 2023-03-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/510" target="_blank" rel="noopener noreferrer" class="title-link">20B params chatgpt alternative</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ<br>Apache2.0ã§å…¬é–‹<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1634492396171071488?s=46&t=VvPwEQsB--BeXx0YbYQdxQ"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/TimeSeriesDataProcessing.html" target="_blank" rel="noopener noreferrer">#TimeSeriesDataProcessing</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2022-12-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/504" target="_blank" rel="noopener noreferrer" class="title-link">Are Transformers Effective for Time Series Forecasting?</a>
<span class="snippet"><span>Comment</span><p>Linear Layerã«åŸºã¥ãã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ³•ãŒTransformerãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã«æ™‚ç³»åˆ—äºˆæ¸¬ã§å‹ã£ãŸã¨ã„ã†è©±</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2021-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/404" target="_blank" rel="noopener noreferrer" class="title-link">GPT-3ã‹ã‚‰æˆ‘ã€…ã¯ä½•ã‚’å­¦ã¹ã°è‰¯ã„ã®ã‹, å±±æœ¬å’Œè‹±, Japio year book 2020</a>
<span class="snippet"><span>Comment</span><p>GPT-3ã®æ¦‚è¦:<br><br>GPT-3ã¯Webã‚µã‚¤ãƒˆã‹ã‚‰æ•°å¹´ã«æ¸¡ã£ã¦åé›†ã—ãŸCommon Crawlã¨ã„ã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ã€570GBã‚’æŠœç²‹ã—å­¦ç¿’ã«åˆ©ç”¨ã€‚ï¼ˆè‹±èªã‚¦ã‚£ã‚­ãƒšãƒ‡ã‚£ã‚¢ã®ç´„130å€ï¼‰<br>ã‚ã‚‹å˜èªåˆ—ã«å¾Œç¶šã™ã‚‹å˜èªã‚’äºˆæ¸¬ã™ã‚‹ã¨ã„ã†æ–¹æ³•ï¼ˆè‡ªå·±å›å¸°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ã§æ•™å¸«ãªã—å­¦ç¿’ã‚’ç¹°ã‚Šè¿”ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã€‚</p>
<p>GPT-3ã®ç‰¹å¾´:<br>ãƒ»ãƒ¢ãƒ‡ãƒ«ãŒå·¨å¤§ï¼ˆ1750å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿, GPT-2ã¯15å„„ï¼‰<br>ã€€- æ‰±ã†ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒ2048ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆGPT-2ã®å€ï¼‰<br>ã€€- Word Embeddingã®æ¬¡å…ƒæ•°12288ï¼ˆGPT2ã®å€<br>ã€€- ãƒ‡ã‚³ãƒ¼ãƒ‰å±¤ãŒ98å±¤ï¼ˆGPT2ã®å€<br>ãƒ»åŸºæœ¬çš„ãªãƒ¢ãƒ‡ãƒ«æ§‹é€ ã¯Transformerã¨ä¸€ç·’<br><br>GPT-3ã®å•é¡Œç‚¹:<br>ãƒ»ã‚³ãƒ¼ãƒ‘ã‚¹ä¸­ã®è¨€èªå‡ºåŠ›ã‚’æ¨¡å€£ã—ã¦ã„ã‚‹ã ã‘ã§ã€ä½•ã‚‰ç†è§£ã‚’ã—ã¦ãŠã‚‰ãšã€å¸¸è­˜ã‚‚æŒã¡åˆã‚ã›ã¦ã„ãªã„<br>ã€€- e.g. ç§ã®è¶³ã«ç›®ã¯ã„ãã¤ã‚ã‚‹ï¼Ÿã¨å…¥åŠ›ã™ã‚‹ã¨ã€2ã¤ã¨å‡ºåŠ›ã™ã‚‹ç­‰<br>ã€€- æ•´ç†ã•ã‚ŒãŸçŸ¥è­˜ã‚’ç²å¾—ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„<br>ãƒ»åè¦‹ã‚„å·®åˆ¥ã€èª¤ã£ãŸçŸ¥è­˜ã‚‚å­¦ç¿’ã™ã‚‹<br>ãƒ»æ™‚é–“çš„ã€çµŒæ¸ˆçš„è² è·ã®å¤§ãã•<br>ã€€- GPT-3ã‚’æœ€å¤§è¦æ¨¡ã§è¨ˆç®—ã™ã‚‹ã«ã¯5å„„å††ã‹ã‹ã‚‹<br>ã€€- 1å°ã®GPUã§355å¹´å¿…è¦ãªè¨ˆç®—é‡<br>ã€€â†’ å€‹äººã‚„å°è¦æ¨¡æ¥­è€…ãŒå®Ÿè¡Œã§ãã‚‹ç¯„å›²ã‚’è¶…ãˆã¦ãŠã‚Šã€å¤§ä¼æ¥­ã§ã‚‚ã‚³ã‚¹ãƒˆã«è¦‹åˆã£ãŸå‡ºåŠ›ãŒå¾—ã‚‰ã‚Œã‚‹ã¨ã¯è€ƒãˆã«ãã„</p>
<p>GPT-3ã®ç”£æ¥­å¿œç”¨<br>ãƒ»GPT-3ã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€è¨€èªç”Ÿæˆå™¨ã§ã¯ãªã„<br>ã€€- äººé–“ãŒæ›¸ã„ã¦æ¬²ã—ã„ã“ã¨ã‚’ãŠãŠã¾ã‹ã«ä¼ãˆãŸã‚‰ãã‚Œã‚’æ›¸ã„ã¦ãã‚Œã‚‹ã‚ã‘ã§ã¯ãªã„ï¼ˆä»£ç­†ï¼‰<br>ã€€â†’ GPT-3ãŒå°è«–æ–‡ã‚„æ¥­å‹™ãƒ¬ãƒãƒ¼ãƒˆã‚’æ›¸ã‘ã‚‹ã¨è€ƒãˆã‚‹ã®ã¯æ—©è¨ˆ<br>ã€€- å…¥åŠ›ã¨ã—ã¦è‹±æ–‡ã‚„è‹±å˜èªã‚’å…¥åŠ›ã™ã‚‹ãŒã€ç”Ÿæˆã™ã‚‹æ–‡ç« ã®åˆ†é‡ã‚„è©±é¡Œã‚’æç¤ºã—ãŸã ã‘ã§ã‚ã‚Šã€ç”Ÿæˆã™ã‚‹æ–‡ç« ã«ãã‚Œä»¥ä¸Šã®åˆ¶å¾¡ã¯è¡Œã£ã¦ã„ãªã„<br><br>ãƒ»ç”Ÿæˆå†…å®¹ã‚’å¼·ãåˆ¶å¾¡ã§ããªã„ã“ã¨ã¯å‰µä½œæ´»å‹•ã«ã¨ã£ã¦ã¯æœ‰ç”¨<br>ã€€- ä¿³å¥ã€çŸ­æ­Œã€è©©ã®ç”Ÿæˆ<br>ã€€- ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã®è‡ªå‹•ç”Ÿæˆ<br>ã€€- ãƒ€ãƒŸãƒ¼æ–‡ç« ç”Ÿæˆï¼ˆãƒ–ãƒ­ã‚°ã‚„ãƒ„ã‚¤ãƒ¼ãƒˆï¼‰<br>ã€€- æ–‡ç« æ·»å‰Šã€æ ¡æ­£ã«ä½¿ãˆã‚‹å¯èƒ½æ€§ï¼ˆè¦ç ”ç©¶;æ–‡ç« ã‚’æ­£ã—ãã€ç¶ºéº—ã«æ›¸ãèƒ½åŠ›ã¯é«˜ã„ï¼‰</p>
<p>GPT-3ã§ã©ã“ã¾ã§ã§ããã†ãªã®ã‹ï¼Ÿã¨ã„ã†ã–ã£ãã‚Šã¨ã—ãŸè‚Œæ„ŸãŒæ´ã‚ãŸã‹ã‚‰è‰¯ã‹ã£ãŸ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/CIKM.html" target="_blank" rel="noopener noreferrer">#CIKM</a>
<a class="button" href="articles/SequentialRecommendation.html" target="_blank" rel="noopener noreferrer">#SequentialRecommendation</a>
<span class="issue_date">Issue Date: 2021-05-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/347" target="_blank" rel="noopener noreferrer" class="title-link">BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer, Sun+, CIKM2019</a>
<span class="snippet"><span>Comment</span><p>BERTã‚’recsysã®sequential recommendationã‚¿ã‚¹ã‚¯ã«è»¢ç”¨ã—ã¦SoTAã€‚<br>ã—ã£ã‹ã‚Šèª­ã‚“ã§ç„¡ã„ã‘ã©ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã¯ã»ã¼BERTã¨ä¸€ç·’ã€‚<br>ç•°ãªã‚‹ç‚¹ã¯ã€Trainingæ™‚ã«Next Sentence Predictionã¯è¡Œã‚ãšClozeã®ã¿è¡Œãªã£ã¦ã„ã‚‹ã¨ã„ã†ç‚¹ã€‚Clozeã¨ã¯ã€å®Ÿè³ªMasked Language Modelã§ã‚ã‚Šã€sequenceã®ä¸€éƒ¨ã‚’[mask]ã«ç½®ãæ›ãˆã€ç½®ãæ›ãˆã‚‰ã‚ŒãŸã‚¢ã‚¤ãƒ†ãƒ ã‚’å·¦å³ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰äºˆæ¸¬ã™ã‚‹ã‚¿ã‚¹ã‚¯ã€‚ç•°ãªã‚‹ç‚¹ã¨ã—ã¦ã¯ã€sequential recommendationã‚¿ã‚¹ã‚¯ã§ã¯ã€æ¬¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’äºˆæ¸¬ã—ãŸã„ã®ã§ã€ãƒã‚¹ã‚¯ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã®ä¸­ã«ã€sequenceã®æœ€å¾Œã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’ãƒã‚¹ã‚¯ã—ã¦äºˆæ¸¬ã™ã‚‹äº‹ä¾‹ã‚‚æ··ãœãŸç‚¹ã€‚<br><br>ã‚‚ã†ä¸€å€‹ç•°ãªã‚‹ç‚¹ã¨ã—ã¦ã€BERT4Recã¯end-to-endãªãƒ¢ãƒ‡ãƒ«ã§ã€BERTã¯pretraining modelã ã€ã¿ãŸã„ãªã“ã¨è¨€ã£ã¦ã‚‹ã‘ã©ã€ã¾ã‚ç¢ºã‹ã«å½¢å¼çš„ã«ã¯ãã†ã„ã†é•ã„ã¯ã‚ã‚‹ã‘ã©ã€ãªã‚“ã‹ãã®é•ã„ã‚’ä¸»å¼µã™ã‚‹ã®ã¯é•å’Œæ„Ÿã‚’è¦šãˆã‚‹â€¦ã€‚<br>sequential recommendationã§ä½¿ã†user behaviorãƒ‡ãƒ¼ã‚¿ã§Next item predictionã§å­¦ç¿’ã—ãŸã„ã“ã¨ãŒã€MLMã¨å˜ã«ä¸€è‡´ã—ã¦ã„ãŸã ã‘ã€ãªã®ã§ã¯â€¦ã€‚</p>
<p>BERT4Recã®ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã€‚next item predictionã—ãŸã„sessionã®æœ«å°¾ã« [mask] ã‚’concatã—ã€[MASK]éƒ¨åˆ†ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’äºˆæ¸¬ã™ã‚‹æ§‹é€ ã£ã½ã„ï¼Ÿ<br><br><img src="https://user-images.githubusercontent.com/12249301/138901870-d36fc935-8b61-4434-9d4b-dc1cb968c91e.png" alt="image" loading="lazy"><br><br></p>
<p>ã‚ªãƒªã‚¸ãƒŠãƒ«ã¯tensorflowå®Ÿè£…<br><br>pytorchã®å®Ÿè£…ã¯ã“ã¡ã‚‰ï¼š


<a href="https://github.com/jaywonchung/BERT4Rec-VAE-Pytorch/tree/master/models" target="_blank" rel="noopener noreferrer">https://github.com/jaywonchung/BERT4Rec-VAE-Pytorch/tree/master/models</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2020-03-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/334" target="_blank" rel="noopener noreferrer" class="title-link">BERT æ—¥æœ¬èªPre-trained Model, NICT, 2020</a>
<span class="snippet"><span>Comment</span><p>NICTãŒå…¬é–‹ã€‚æ—¢ã«å…¬é–‹ã•ã‚Œã¦ã„ã‚‹BERTãƒ¢ãƒ‡ãƒ«ã¨ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½æ¯”è¼ƒã‚‚è¡Œãªã£ã¦ãŠã‚Šã€ãã®ä»–ã®å…¬é–‹æ¸ˆã¿BERTãƒ¢ãƒ‡ãƒ«ã‚’outperformã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2020-01-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/332" target="_blank" rel="noopener noreferrer" class="title-link">BERTå…¥é–€, Ken'ichi Matsui, 2020</a>
<span class="snippet"><span>Comment</span><p>è‡ªç„¶è¨€èªå‡¦ç†ã®ç‹æ§˜ã€ŒBERTã€ã®è«–æ–‡ã‚’å¾¹åº•è§£èª¬<br><br>


<a href="https://qiita.com/omiita/items/72998858efc19a368e50" target="_blank" rel="noopener noreferrer">https://qiita.com/omiita/items/72998858efc19a368e50</a>


</p>
<p>Transformeré–¢é€£ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/245" target="_blank" rel="noopener noreferrer">[Paper Note] Attention Is All You Need, Ashish Vaswani+, arXiv'17</a>
 ã‚ãŸã‚Šã‚’å…ˆã«èª­ã‚“ã§ã‹ã‚‰ãŒèª­ã‚€ã¨è‰¯ã„<br><br><br><br>è¦ã¯<br><br>ãƒ»Transformerã‚’ãŸãã•ã‚“ç©ã‚“ã ãƒ¢ãƒ‡ãƒ«<br><br>ãƒ»NSPã¨MLMã§åŒæ–¹å‘æ€§ã‚’æŒã£ãŸäº‹å‰å­¦ç¿’ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Š<br><br>ãƒ»pooler layerï¼ˆTransformer Encoderã®æ¬¡ã«ãã£ã¤ãlayerï¼‰ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã“ã¨ã§ã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã«fine-tuningå¯èƒ½ï¼ˆi.e. pooler layerã¯è»¢ç§»å­¦ç¿’ã®å¯¾è±¡å¤–ï¼‰<br><br>ãƒ»äºˆæ¸¬ã™ã‚‹éš›ã¯ã€[CLS]ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾å¿œã™ã‚‹ä½ç½®ã®å‡ºåŠ›ã‚’ç”¨ã„ã¦åˆ†é¡å•é¡Œã‚„è¤‡æ•°æ–‡é–“ã®é–¢ä¿‚æ€§ã‚’å•ã†å•é¡Œã‚’è§£ã„ãŸã‚Šã€å„ãƒˆãƒ¼ã‚¯ãƒ³ä½ç½®ã«å¯¾å¿œã™ã‚‹å‡ºåŠ›ã‚’ç”¨ã„ã¦QAã®æ­£è§£spanã‚’äºˆæ¸¬ã—ãŸã‚Šã€è‰²ã€…ã§ãã‚‹<br><br>ãƒ»gMLP <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/344" target="_blank" rel="noopener noreferrer">MLP-like Architecture</a>
 ã‚ãŸã‚Šã®ç ”ç©¶ãŒé€²ã‚“ã§ãã‚‹ã¨ä½¿ã‚ã‚Œãªããªã£ã¦ãã‚‹å¯èƒ½æ€§æœ‰</p>
<p>ã“ã£ã¡ã®è¨˜äº‹ã‚‚ã‚ã‹ã‚Šã‚„ã™ã„ã€‚<br><br><br><br>BERTã«ã¤ã„ã¦å‹‰å¼·ã—ãŸã“ã¨ã¾ã¨ã‚ (2)ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã«ã¤ã„ã¦<br><br>


<a href="https://engineering.mobalab.net/2020/06/12/bert%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E5%8B%89%E5%BC%B7%E3%81%97%E3%81%9F%E3%81%93%E3%81%A8%E3%81%BE%E3%81%A8%E3%82%81-2%E3%83%A2%E3%83%87%E3%83%AB%E6%A7%8B%E9%80%A0%E3%81%AB%E3%81%A4%E3%81%84/" target="_blank" rel="noopener noreferrer">https://engineering.mobalab.net/2020/06/12/bert%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E5%8B%89%E5%BC%B7%E3%81%97%E3%81%9F%E3%81%93%E3%81%A8%E3%81%BE%E3%81%A8%E3%82%81-2%E3%83%A2%E3%83%87%E3%83%AB%E6%A7%8B%E9%80%A0%E3%81%AB%E3%81%A4%E3%81%84/</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2019-11-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/329" target="_blank" rel="noopener noreferrer" class="title-link">äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã®å‹•å‘ _ Survey of Pretrained Language Models, Kyosuke Nishida, 2019</a>
<span class="snippet"><span>Comment</span><p>[2019/06ã¾ã§]<br><br>ãƒ»ELMoï¼ˆåŒæ–¹å‘2å±¤LSTMè¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ãƒ»GPTï¼ˆleft-to-rightã®12å±¤Transformerè‡ªå·±å›å¸°è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ãƒ»BERTï¼ˆ24å±¤ã®TransformeråŒæ–¹å‘è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ãƒ»MT-DNNï¼ˆBERTã®ä¸Šã«ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å±¤ã‚’è¿½åŠ ã—ãŸç ”ç©¶ï¼‰<br><br>ãƒ»XLMï¼ˆãƒ‘ãƒ©ãƒ¬ãƒ«ç¿»è¨³ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ç”¨ã„ã¦ã‚¯ãƒ­ã‚¹ãƒªãƒ³ã‚¬ãƒ«ã«ç©´åŸ‹ã‚ã‚’å­¦ç¿’ï¼‰<br><br>ãƒ»TransformerXLï¼ˆç³»åˆ—é•·ã„ã«åˆ¶é™ã®ã‚ã£ãŸæ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã«ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ã®å†å¸°ã‚’å°å…¥ã—é•·ã„ç³»åˆ—ã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«ï¼‰<br><br>ãƒ»GPT-2ï¼ˆ48å±¤Transformerã®è‡ªå·±å›å¸°è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ãƒ»ERNIE 1.0ï¼ˆBaidu, ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨ãƒ•ãƒ¬ãƒ¼ã‚ºã®å¤–éƒ¨çŸ¥è­˜ã‚’ä½¿ã£ã¦ãƒã‚¹ã‚¯ã«åˆ©ç”¨ï¼‰<br><br>ãƒ»ERNIEï¼ˆTsinghua, çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®æƒ…å ±ã‚’fusionã—ãŸLMï¼‰<br><br>ãƒ»Gloverï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³ã€æ—¥ä»˜ã€è‘—è€…ãªã©ã‚’æ¡ä»¶ã¨ã—ãŸç”Ÿæˆã‚’å¯èƒ½ã¨ã—ãŸGPTï¼‰<br><br>ãƒ»MASSï¼ˆEncoder-Decoderå‹ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®äº‹å‰å­¦ç¿’ï¼‰<br><br>ãƒ»UniLMï¼ˆSequence-to-Sequenceã‚’å¯èƒ½ã«ã—ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ãƒ»XLNetï¼ˆè‡ªå·±å›å¸°ï¼ˆå˜æ–¹å‘ï¼‰ãƒ¢ãƒ‡ãƒ«ã¨åŒæ–¹å‘ãƒ¢ãƒ‡ãƒ«ã®ä¸¡æ–¹ã®åˆ©ç‚¹ã‚’å¾—ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ï¼‰<br><br><br><br>[2019/07~]<br><br>ãƒ»SpanBERTï¼ˆi.i.dã§ã¯ãªãç¯„å›²ã§ãƒã‚¹ã‚¯ã—ã€åŒæ™‚ã«ç¯„å›²ã®å¢ƒç•Œã‚‚äºˆæ¸¬ã™ã‚‹ï¼‰<br><br>ãƒ»ERNIE 2.0ï¼ˆBaidu, ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯äº‹å‰å­¦ç¿’; å˜èªãƒ¬ãƒ™ãƒ«ãƒ»æ§‹é€ ãƒ¬ãƒ™ãƒ«ãƒ»æ„å‘³ãƒ¬ãƒ™ãƒ«ï¼‰<br><br>ãƒ»RoBERTaï¼ˆBERTã¨åŒã˜æ§‹é€ ã§å·¥å¤«ã‚’åŠ ãˆã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Šï¼‰<br><br>ã€€- ã‚ˆã‚Šå¤§ããªãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ä½¿ã†ï¼ˆ256ã‹ã‚‰8192ï¼‰<br><br>ã€€- ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã†ï¼ˆ16GBã‹ã‚‰160GBï¼‰<br><br>ã€€- ã‚ˆã‚Šé•·ã„ã‚¹ãƒ†ãƒƒãƒ—æ•°ã®å­¦ç¿’ã‚’ã™ã‚‹ï¼ˆBERTæ›ç®—ã§16å€ï¼‰<br><br>ã€€- æ¬¡æ–‡äºˆæ¸¬ï¼ˆNSPï¼‰ã¯ä¸è¦<br><br>ã€€â†’ GLUEã§BERT, XLNetã‚’outperform<br><br>ãƒ»StructBERT (ALICE, NSPã«ä»£ã‚ã‚‹å­¦ç¿’ã®ç›®çš„é–¢æ•°ã‚’å·¥å¤«)<br><br>ã€€- ãƒã‚¹ã‚¯ã—ãŸä¸Šã§å˜èªã®é †ç•ªã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—å…ƒã«æˆ»ã™<br><br>ã€€- ãƒ©ãƒ³ãƒ€ãƒ ãƒ»æ­£é †ãƒ»é€†é †ã®3ç¨®é¡ã‚’åˆ†é¡<br><br>ã€€â†’ BERTã¨åŒã‚µã‚¤ã‚ºã€åŒãƒ‡ãƒ¼ã‚¿ã§BERT, RoBERTaè¶…ãˆ<br><br>ãƒ»DistilBERTï¼ˆè’¸ç•™ã«ã‚ˆã‚Šã€12å±¤BERTã‚’6å±¤ã«å°å‹åŒ–ï¼ˆ40%æ¸›ï¼‰ï¼‰<br><br>ã€€- BERTã®å‡ºåŠ›ã‚’æ•™å¸«ã¨ã—ã¦ã€ç”Ÿå¾’ãŒåŒã˜å‡ºåŠ›ã‚’å‡ºã™ã‚ˆã†ã«å­¦ç¿’<br><br>ã€€- å¹…ï¼ˆéš ã‚Œå±¤ï¼‰ã‚µã‚¤ã‚ºã‚’æ¸›ã‚‰ã™ã¨ã€å±¤æ•°ã‚’çµŒã‚ï½’ã‚¹ã‚ˆã‚Šã‚‚æ‚ªåŒ–<br><br>ã€€â†’ æ¨è«–ã¯60%é«˜é€ŸåŒ–ã€ç²¾åº¦ã¯95%ç¨‹åº¦ã‚’ä¿æŒ<br><br>ãƒ»Q8BERTï¼ˆç²¾åº¦ã‚’è½ã¨ã•ãšã«fine-tuningæ™‚ã«BERTã‚’8bitæ•´æ•°ã«é‡å­åŒ–ï¼‰<br><br>ã€€- Embedding, FCã¯8bitåŒ–ã€softmax, LNorm, GELUã¯32bitã‚’ã‚­ãƒ¼ãƒ—<br><br>ã€€â†’ ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º1/4, é€Ÿåº¦3.7å€<br><br>ãƒ»CTRLï¼ˆæ¡ä»¶ä»˜ãè¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ã€€- æ¡ä»¶ã¨ãªã‚‹åˆ¶å¾¡ãƒ†ã‚­ã‚¹ãƒˆã‚’æœ¬æ–‡ã®å‰ã«ä¸ãˆã¦å­¦ç¿’<br><br>ã€€- 48å±¤/1280æ¬¡å…ƒTransformerï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°1.6Bï¼‰<br><br>ãƒ»MegatronLMï¼ˆ72å±¤ã€éš ã‚ŒçŠ¶æ…‹ã‚µã‚¤ã‚º3072ã€é•·ã•1024; BERTã®24å€ã‚µã‚¤ã‚ºï¼‰<br><br>ãƒ»ALBERTï¼ˆBERTã®å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã™ã¹ã¦å…±æœ‰ã™ã‚‹ã“ã¨ã§å­¦ç¿’ã‚’é«˜é€ŸåŒ–; 2020å¹´ã‚ãŸã‚Šã®ãƒ‡ãƒ•ã‚¡ã‚¯ãƒˆï¼‰<br><br>ã€€- Largeã‚’è¶…ãˆãŸãƒ¢ãƒ‡ãƒ«ã¯å­¦ç¿’ãŒé›£ã—ã„ãŸã‚ã€è¡¨ç¾ã¯è½ã¡ã‚‹ãŒå­¦ç¿’ã—ã‚„ã™ãã—ãŸ<br><br>ã€€- å˜èªåŸ‹ã‚è¾¼ã¿ã‚’ä½æ¬¡å…ƒã«ã™ã‚‹ã“ã¨ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°å‰Šæ¸›<br><br>ã€€- æ¬¡æ–‡äºˆæ¸¬ã‚’ã€æ–‡ã®é †åºå…¥ã‚Œæ›¿ãˆåˆ¤å®šã«å¤‰æ›´<br><br>ã€€â†’ GLUE, RACE, SQuADã§SoTAã‚’æ›´æ–°<br><br>ãƒ»T5ï¼ˆNLPã‚¿ã‚¹ã‚¯ã‚’ã™ã¹ã¦text-to-textã¨ã—ã¦æ‰±ã„ã€Enc-Dec Transformerã‚’745GBã‚³ãƒ¼ãƒ‘ã‚¹ã§äº‹å‰å­¦ç¿’ã—ã¦è»¢ç§»ã™ã‚‹ï¼‰<br><br>ã€€- ãƒ¢ãƒ‡ãƒ«ã¯Encoder-Decoderã®Transformer<br><br>ã€€- å­¦ç¿’ã‚¿ã‚¹ã‚¯ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ€ã«åˆã‚ã›ã¦å¤‰æ›´<br><br>ã€€- ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å´ã§ç¯„å›²ã‚’æ¬ è½ã•ã›ã¦ã€ãƒ‡ã‚³ãƒ¼ãƒ€å´ã§äºˆæ¸¬<br><br>ã€€â†’ GLUE, SuperGLUE, SQuAD1.1, CNN/DMã§SoTAæ›´æ–°<br><br>ãƒ»BARTï¼ˆSeq2Seqã®äº‹å‰å­¦ç¿’ã¨ã—ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚¹ã‚¯ãƒ»å‰Šé™¤ã€ç¯„å›²ãƒã‚¹ã‚¯ã€æ–‡ã®å…¥ã‚Œæ›¿ãˆã€æ–‡æ›¸ã®å›è»¢ã®è¤‡æ•°ã‚¿ã‚¹ã‚¯ã§å­¦ç¿’ï¼‰<br><br>ã€€â†’ CNN/DMã§T5è¶…ãˆã€WMT'16 RO-ENã§é€†ç¿»è¨³ã‚’è¶…ãˆã¦SoTA</p>
<p>ELMo, GPT, BERT, GPT-2, XLNet, RoBERTa, DistilBERT, ALBERT, T5ã‚ãŸã‚Šã¯è‰¯ãè¦‹ã‚‹ã‚ˆã†ãªæ„Ÿ</p>
<p>å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å„ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚‚å¾ŒåŠã«è¨˜è¼‰ã•ã‚Œã¦ãŠã‚Šèˆˆå‘³æ·±ã„ã€‚<br><br><br><br>ã¡ãªã¿ã«ã€CNN/DailyMail Datasetã§ã¯ã€T5, BARTã‚ãŸã‚ŠãŒSoTAã€‚<br><br>R2ã§æ¯”è¼ƒã™ã‚‹ã¨<br><br>ã€€- Pointer-Generator + Coverage VectorãŒ17,28<br><br>ã€€- LEAD-3ãŒ17.62<br><br>ã€€- BARTãŒ21.28<br><br>ã€€- T5ãŒ21.55<br><br>ã¨ãªã£ã¦ã„ã‚‹</p></span><br><br>
<button onclick="hideContent(0)" style="display: none;">hide</button>
&lt;/div&gt;
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<script>
  document.addEventListener('DOMContentLoaded', function() {
    const tweets = document.querySelectorAll('.tweet-embed[data-embed]');

    if ('IntersectionObserver' in window) {
      const observer = new IntersectionObserver((entries, obs) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            const el = entry.target;
            const html = el.getAttribute('data-embed');
            if (html) {
              const placeholder = el.querySelector('.tweet-placeholder');
              if (placeholder) placeholder.remove();

              el.innerHTML = html.trim();

              if (window.twttr?.widgets?.load) {
                window.twttr.widgets.load(el);
              }
            }
            obs.unobserve(el); // å‡¦ç†æ¸ˆã¿ã¯ç›£è¦–è§£é™¤
          }
        });
      }, {
        rootMargin: '500px 0px', // ç”»é¢æ‰‹å‰200pxã§èª­ã¿è¾¼ã¿é–‹å§‹
        threshold: 0
      });

      tweets.forEach(tweet => observer.observe(tweet));

    } else {
      // IntersectionObserveræœªå¯¾å¿œãƒ–ãƒ©ã‚¦ã‚¶ç”¨ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
      function lazyLoadFallback() {
        tweets.forEach(el => {
          if (el.getAttribute('data-embed') && el.getBoundingClientRect().top < window.innerHeight) {
            const html = el.getAttribute('data-embed');
            const loadingImg = el.querySelector('.tweet-loading');
            if (loadingImg) loadingImg.remove();
            el.innerHTML = html.trim();
            el.removeAttribute('data-embed');
            if (window.twttr?.widgets?.load) {
              window.twttr.widgets.load(el);
            }
          }
        });
      }
      window.addEventListener('scroll', lazyLoadFallback);
      lazyLoadFallback();
    }
  });
</script>
</span>
</div>


    </div>

</article>
<div class="post-nav">
<a class="previous" href="/paper_notes/articles/LabelBias.html" title="LabelBiasã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">LabelBiasã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§</a><a class="next" href="/paper_notes/articles/LatentReasoning.html" title="LatentReasoningã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">LatentReasoningã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§</a>
</div>
<div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li class="">
          <a class="post-link" href="/paper_notes/articles/Survey.html" title="Surveyã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            Surveyã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/ChatGPT.html" title="ChatGPTã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            ChatGPTã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/NaturalLanguageUnderstanding.html" title="NaturalLanguageUnderstandingã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            NaturalLanguageUnderstandingã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/CrossLingual.html" title="CrossLingualã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            CrossLingualã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
</ul>
    </div>
<div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">TOC</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent =  menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3, h4, h5, h6");

    // Hide menu when no headings
    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // Generate post menu
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#h-' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }

    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';

    // The header element
    var header = document.querySelector('header.site-header');

    function doMenuCollapse(index, over_items) {
      var items = menuContent.firstChild.children;

      if (over_items == undefined) {
        over_items = 20;
      }

      if (items.length < over_items) {
        return;
      }

      var activeItem = items[index];
      var beginItem = activeItem
      var endItem = activeItem
      var beginIndex = index;
      var endIndex = index + 1;
      while (beginIndex >= 0
        && !items[beginIndex].classList.contains('h-h2')) {
        beginIndex -= 1;
      }
      while (endIndex < items.length
        && !items[endIndex].classList.contains('h-h2')) {
        endIndex += 1;
      }
      for (var i = 0; i < beginIndex; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
      for (var i = beginIndex + 1; i < endIndex; i++) {
        item = items[i]
        // if (!item.classList.contains('h-h2')) {
          item.style.display = '';
        // }
      }
      for (var i = endIndex; i < items.length; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
    }

    // Init menu collapsed
    doMenuCollapse(-1);

    // Active the menu item
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header.getBoundingClientRect();
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var headerHeight = headerTop + headerHeight + 20;
        if (headingRect.top <= headerHeight) {
          var id = 'h-' + h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          if (curActive) {
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }
      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
        doMenuCollapse(activeIndex);
      }
      event.preventDefault();
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/paper_notes/"></data>

  <div class="wrapper">
    <div class="site-footer-inner">
<div>Copyright Â© 2023-current AkihikoWATANABE. The header images and any thumbnail images for the posts were generated by ChatGPT's DALL-E3.</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="https://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div class="footer-col rss-subscribe">Subscribe <a href="/paper_notes/feed.xml">via RSS</a>
</div>
    </div>
  </div>
</footer>
</body>
  </html>
