<!DOCTYPE html>
<html lang="ja">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>One-Line Notesに関する論文・技術記事メモの一覧 | わたしのべんきょうノート</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="One-Line Notesに関する論文・技術記事メモの一覧">
<meta name="author" content="AkihikoWATANABE">
<meta property="og:locale" content="ja">
<meta name="description" content='&lt;h2 id=One-Line Notes&gt; One-Line Notes&lt;/h2&gt;&lt;div class="visible-content"&gt; #NeuralNetwork #ComputerVision #Analysis #Supervised #RepresentationLearning #Self-SupervisedLearning #CLIP'>
<meta property="og:description" content='&lt;h2 id=One-Line Notes&gt; One-Line Notes&lt;/h2&gt;&lt;div class="visible-content"&gt; #NeuralNetwork #ComputerVision #Analysis #Supervised #RepresentationLearning #Self-SupervisedLearning #CLIP'>
<link rel="canonical" href="http://akihikowatanabe.github.io/paper_notes/articles/One-Line%20Notes.html">
<meta property="og:url" content="http://akihikowatanabe.github.io/paper_notes/articles/One-Line%20Notes.html">
<meta property="og:site_name" content="わたしのべんきょうノート">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2025-11-15T00:47:29+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="One-Line Notesに関する論文・技術記事メモの一覧">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"AkihikoWATANABE"},"dateModified":"2025-11-15T00:47:29+00:00","datePublished":"2025-11-15T00:47:29+00:00","description":"&lt;h2 id=One-Line Notes&gt; One-Line Notes&lt;/h2&gt;&lt;div class=&quot;visible-content&quot;&gt; #NeuralNetwork #ComputerVision #Analysis #Supervised #RepresentationLearning #Self-SupervisedLearning #CLIP","headline":"One-Line Notesに関する論文・技術記事メモの一覧","mainEntityOfPage":{"@type":"WebPage","@id":"http://akihikowatanabe.github.io/paper_notes/articles/One-Line%20Notes.html"},"url":"http://akihikowatanabe.github.io/paper_notes/articles/One-Line%20Notes.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="icon" href="">
  <link rel="canonical" href="http://akihikowatanabe.github.io">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/main.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/custom_button.css">
  <script src="/paper_notes/assets/js/main.js"></script>
  <script src="https://d3js.org/d3.v5.min.js"></script><link type="application/atom+xml" rel="alternate" href="http://akihikowatanabe.github.io/paper_notes/feed.xml" title="わたしのべんきょうノート">
<script>
  function showMore(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "block";
          
      // このボタンの参照を取得して非表示にします
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "none";
      }
          
      // hideボタンの参照を取得して表示します
      const hideButton = contentDiv.querySelector('button[onclick^="hideContent"]');
      if (hideButton) {
        hideButton.style.display = "block";
      }
    }
  }

  function hideContent(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "none";
  
      // moreボタンの参照を取得して表示します
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "block";
      }
  
      // このボタンを隠します
      const hideButtons = document.querySelectorAll('button[onclick^="hideContent"]');
      const hideButton = hideButtons[index];
      if (hideButton) {
        hideButton.style.display = "none";
      }
    }
  }
</script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js" async></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe-lightbox.umd.min.js" async></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe.umd.min.js" async></script>
<link href="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/photoswipe.min.css" rel="stylesheet">
<style>
  .pswp .pswp__container .pswp__img {
    background-color: white;
  }
</style>

<script>
  function initPhotoSwipe() {
    let customOptions = {};

    try {
      const data = `{"gallery"=>"section.main", "children"=>"a.photo-swipe", "bgOpacity"=>0.8, "padding"=>{"top"=>20, "bottom"=>40, "left"=>100, "right"=>100}}`.replaceAll("=>", ":");
      customOptions = JSON.parse(data);
    } catch (e) {
      console.info("Invalid custom photo previewer options! " + e.message);
    }

    // Define object and gallery options
    const options = Object.assign(
      {
        gallery: "section.main",
        children: "a.photo-swipe",
        photo_scale: 2,
        // dynamic import is not supported in UMD version
        pswpModule: PhotoSwipe,
      },
      customOptions
    );

    const galleryEl = document.querySelector(options.gallery);
    if (!galleryEl) {
      return;
    }

    const imgEls = [];
    const els = galleryEl.querySelectorAll("img:not(.emoji)");
    els.forEach((el) => {
      if (el.src.trim() == "") {
        return;
      }
      if (!imgEls.includes(el)) {
        imgEls.push(el);
      }
    });

    if (imgEls.length === 0) {
      return;
    }

    imgEls.forEach((imgEl) => {
      imgEl.outerHTML = `
      <a class="photo-swipe"
        href="${imgEl.src}"
        data-pswp-width="${
          Math.max(imgEl.naturalWidth, imgEl.width) * options.photo_scale
        }"
        data-pswp-height="${
          Math.max(imgEl.naturalHeight, imgEl.height) * options.photo_scale
        }"
        data-pswp-caption="${imgEl.getAttribute("caption") || imgEl.alt}"
        target="_blank">
        ${imgEl.outerHTML}
      </a>`;
    });

    // Initialize PhotoSwipe 5
    var lightbox = new PhotoSwipeLightbox(options);

    lightbox.init();
  }

  window.addEventListener("load", initPhotoSwipe);
</script>
<meta name="google-site-verification" content="u_DTTPcCZ806iq51zgirHyWq3556HUKGq8AQfH91iFI">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-P70KSB88WH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-P70KSB88WH');
  </script>

<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"},"svg":{"fontCache":"global"}}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>





































































































































<header class="site-header site-header-transparent" role="banner">

  <div class="wrapper">
    <div class="site-header-inner">
<span class="site-brand"><a class="site-brand-inner" rel="author" href="/paper_notes/">
  <img class="site-favicon" title="わたしのべんきょうノート" src="" onerror="this.style.display='none'">
  わたしのべんきょうノート
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger">
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewbox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
              </svg>
            </span>
          </label>

          <div class="trigger">









<span class="page-link">



<div id="google_translate_element" style="display: none;">
</div>

<span class="ct-language">
  <ul class="list-unstyled ct-language-dropdown">
    
      <li>
        <a href="#" class="lang-select" data-lang="en">
          
          <img src="https://cdn.countryflags.com/thumbs/united-states-of-america/flag-400.png" title="English">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="fr">
          
          <img src="https://cdn.countryflags.com/thumbs/france/flag-400.png" title="French">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="zh-CN">
          
          <img src="https://cdn.countryflags.com/thumbs/china/flag-400.png" title="Chinese(Simple)">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ja">
          
          <img src="https://cdn.countryflags.com/thumbs/japan/flag-400.png" title="Japanese">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ko">
          
          <img src="https://cdn.countryflags.com/thumbs/south-korea/flag-400.png" title="Korean">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ru">
          
          <img src="https://cdn.countryflags.com/thumbs/russia/flag-400.png" title="Russian">
          
        </a>
      </li>
    
  </ul>
</span>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'ja',
    autoDisplay: false,
    layout: google.translate.TranslateElement.InlineLayout.VERTICAL
  }, 'google_translate_element');

  // Links to cross-origin destinations are unsafe
  var gll = document.getElementsByClassName('goog-logo-link')[0];
  if (gll) {
    gll.setAttribute('rel', 'noopener');
  }

  function restoreLang() {
    var iframe = document.getElementsByClassName('goog-te-banner-frame')[0];
    if (!iframe) return;

    var innerDoc = iframe.contentDocument || iframe.contentWindow.document;
    var restore_el = innerDoc.getElementsByTagName("button");

    for (var i = 0; i < restore_el.length; i++) {
      if (restore_el[i].id.indexOf("restore") >= 0) {
        restore_el[i].click();
        var close_el = innerDoc.getElementsByClassName("goog-close-link");
        close_el[0].click();
        return;
      }
    }
  }

  function triggerHtmlEvent(element, eventName) {
    var event;
    if (document.createEvent) {
      event = document.createEvent('HTMLEvents');
      event.initEvent(eventName, true, true);
      element.dispatchEvent(event);
    } else {
      event = document.createEventObject();
      event.eventType = eventName;
      element.fireEvent('on' + event.eventType, event);
    }
  }

  var googleCombo = document.querySelector("select.goog-te-combo");
  var langSelect = document.querySelector('.ct-language');
  langSelect.addEventListener('click', function(event) {
    if (!event.target) {
      return;
    }

    var selected = document.querySelector('.ct-language .ct-language-selected');
    if (selected) {
      selected.classList.remove('ct-language-selected');
    }

    var target = event.target;
    while (target && target !== langSelect ) {
      if (target.matches('.lang-select')) {
        break;
      }
      target = target.parentElement;
    }

    if (target && target.matches('.lang-select')) {
      var lang = target.getAttribute('data-lang');
      if (googleCombo.value == lang) {
        restoreLang();
      } else {
        target.parentElement.classList.add('ct-language-selected');
        googleCombo.value = lang;
        triggerHtmlEvent(googleCombo, 'change');
      }
    }

    event.preventDefault();
  });
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit" async></script>
</span>
</div>
        </nav>
</div>
  </div>
</header>

<script>
  function initHeader() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;

    function storeScrollData() {
      var y = getScrollPos().y;documentElement.setAttribute("data-header-transparent", "");var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0) ? true : false;
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
    }

    window.addEventListener('scroll', function(e) {
      storeScrollData();
    });

    storeScrollData();
  }
  document.addEventListener('DOMContentLoaded', initHeader);
</script>


























































































































































<style>
    html .page-banner .page-banner-img > *:first-child {
      opacity: 0.4;
    }

    html[data-theme="dark"] .page-banner .page-banner-img > *:first-child {
      opacity: 0.2872;
    }
  </style>
<section class="page-banner">
    <div class="page-banner-img">
<div style="background-image: url(/paper_notes/assets/images/banner.png)"></div>
        <img class="img-placeholder" src="/paper_notes/assets/images/banner.png">
</div>
    <div class="wrapper">
      <div class="page-banner-inner">
<header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">わたしのべんきょうノート</h1>
  <h2 class="post-subtitle">勉強した論文や技術等の情報をGithubのIssueにメモっているひとのブログ。
それなりにメモの量が蓄積されてきたので、一度整理したいなと思いブログはじめてみました！
自然言語処理(NLP), 推薦システム(RecommenderSystem), Educational Data Mining (EDM), Learning Analytics (LA)などの分野のメモが多いと思います。
最近は特にLLMの勉強が多めです :)</h2>

  <div class="post-meta">
    <time class="dt-published" datetime="2025-11-15T00:47:29+00:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Nov 15, 2025
    </time><span class="post-author left-vsplit"><i class="fa fa-pencil"></i> AkihikoWATANABE</span>
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 3 hours 55 mins</span>
  </div></header>
</div>
    </div>
  </section><script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    hashValue = decodeURIComponent(hashValue);
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('off' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<div id="click-to-top" class="click-to-top">
  <i class="fa fa-arrow-up"></i>
</div>
<script>
  (function () {
    const clickToTop = document.getElementById('click-to-top');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 100) {
        clickToTop.classList.add('show')
      }else {
        clickToTop.classList.remove('show')
      }
    });
    clickToTop.addEventListener('click', () => {
      window.smoothScrollTo(0);
    });
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <p>&lt;h2 id=One-Line Notes&gt; One-Line Notes&lt;/h2&gt;&lt;div class="visible-content"&gt;
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/Self-SupervisedLearning.html" target="_blank" rel="noopener noreferrer">#Self-SupervisedLearning</a>
<a class="button" href="articles/CLIP.html" target="_blank" rel="noopener noreferrer">#CLIP</a></p>

<p><br></p>

<p><span class="issue_date">Issue Date: 2025-10-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3524" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Notes] Investigating fine- and coarse-grained structural correspondences between deep neural networks and human object image similarity judgments using unsupervised alignment, Takahashi+, Neural Networks’26, 2026.03</a>
<span class="snippet"><span>Comment</span>&lt;p&gt;元ポスト:</span></p>

<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/oizumim/status/1983800844933066931?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>

<p>&lt;/p&gt;&lt;p&gt;CLIP, 自己教師あり学習, 教師あり学習を比較したときに、CLIPが人間が獲得するobjectのrepresentationともっともalignしている一方で、自己教師あり学習はほとんど偶然レベルでしかalignしない（ただし、粗いレベルで見ると人間で言うところのカテゴリレベルのクラスタを形成することができる）。このため、テキストベースでの学習が人間が獲得する表現とfine-grainedなレベルでalignするために非常に重要であることが示唆される、という感じらしい&lt;/p&gt;&lt;/span&gt;<br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a></p>

<p><br></p>

<p><span class="issue_date">Issue Date: 2025-11-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3671" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TabArena: A Living Benchmark for Machine Learning on Tabular Data, Nick Erickson+, NeurIPS’25 Spotlight, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- TabArenaは、表形式データのための初の生きたベンチマークシステムであり、継続的に更新されることを目的としています。手動でキュレーションされたデータセットとモデルを用いて、公開リーダーボードを初期化しました。結果は、モデルのベンチマークにおける検証方法やハイパーパラメータ設定の影響を示し、勾配ブースティング木が依然として強力である一方、深層学習手法もアンサンブルを用いることで追いついてきていることを観察しました。また、基盤モデルは小規模データセットで優れた性能を発揮し、モデル間のアンサンブルが表形式機械学習の進展に寄与することを示しました。TabArenaは、再現可能なコードとメンテナンスプロトコルを提供し、https://tabarena.ai で利用可能です。</span>
<span class="snippet"><span>Comment</span>&lt;p&gt;pj page:</span></p>

<p><a href="https://github.com/autogluon/tabarena" target="_blank" rel="noopener noreferrer">https://github.com/autogluon/tabarena</a></p>

<p><br>leaderboard:</p>

<p><a href="https://huggingface.co/spaces/TabArena/leaderboard" target="_blank" rel="noopener noreferrer">https://huggingface.co/spaces/TabArena/leaderboard</a></p>

<p>&lt;/p&gt;&lt;p&gt;liveデータに基づくベンチマークで、手動で収集された51のtabularデータセットが活用されているとのこと。またあるモデルに対して数百にも登るハイパーパラメータ設定での実験をしアンサンブルをすることで単一モデルが到達しうるピーク性能を見ることに主眼を置いている、またいな感じらしい。そしてやはり勾配ブースティング木が強い。tunedは単体モデルの最も性能が良い設定での性能で、ensembleは複数の設定での同一モデルのアンサンブルによる結果だと思われる。<br><br>&gt; TabArena currently consists of:<br>&gt; 51 manually curated tabular datasets representing real-world tabular data tasks.<br>&gt; 9 to 30 evaluated splits per dataset.<br>&gt; 16 tabular machine learning methods, including 3 tabular foundation models.<br>&gt; 25,000,000 trained models across the benchmark, with all validation and test predictions cached to enable tuning and post-hoc ensembling analysis.<br>&gt; A live TabArena leaderboard showcasing the results.&lt;/p&gt;&lt;p&gt;openreview:</p>

<p><a href="https://openreview.net/forum?id=jZqCqpCLdU" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=jZqCqpCLdU</a></p>

<p>&lt;/p&gt;&lt;/span&gt;<br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a></p>

<p><br></p>

<p><span class="issue_date">Issue Date: 2025-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3665" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Beyond Accuracy: Dissecting Mathematical Reasoning for LLMs Under Reinforcement Learning, Jiayu Wang+, NeurIPS’25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）は言語モデルの推論性能を向上させるが、そのメカニズムは未解明。SPARKLEフレームワークを用いて、RLの効果を計画遵守、知識統合、サブ問題連鎖の3次元で分析。RL調整モデルは外部計画に依存せず、内部戦略の形成を促進し、知識統合能力を向上させることが示された。難しい問題に対しては、SparkleRL-PSSというマルチステージRLパイプラインを提案し、データ生成なしで効果的な探索を実現。これにより、推論タスクのための適応的で効率的なRLパイプライン構築のための洞察が得られる。</span>
<span class="snippet"><span>Comment</span>&lt;p&gt;元ポスト:</span></p>

<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiayuwang111/status/1988675960288280928?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>

<p>&lt;/p&gt;&lt;p&gt;RLを実施したモデルは与えられた計画を実施することに関してよりロバストで、自分でプランニングさせて解かせることもでき、かつ外部・モデル内部のパラメータに内在する知識を統合して応答する能力も向上する。しかし、大きな問題を部分問題に分割して解く能力には課題が残る、みたいな話らしい。&lt;/p&gt;&lt;p&gt;関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3664" target="_blank" rel="noopener noreferrer">[Paper Note] Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs, Renfei Zhang+, arXiv’25, 2025.11</a>
&lt;/p&gt;&lt;/span&gt;<br><br>
&lt;/div&gt;
<button onclick="showMore(0)">more</button></p>
<div class="hidden-content">
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Memorization.html" target="_blank" rel="noopener noreferrer">#Memorization</a>
<span class="issue_date">Issue Date: 2025-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3664" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs, Renfei Zhang+, arXiv'25, 2025.11</a>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）は、階層的な知識を必要とするタスクにおいて、基盤モデルや教師あり微調整（SFT）モデルを上回る性能を示す。これは新たなデータからではなく、既存の知識をナビゲートするスキルの向上によるものである。構造化プロンプティングを用いることで、SFTモデルのパフォーマンスギャップを縮小できることが示された。RLモデルは深い検索タスクでの手続き的経路の呼び出しに優れ、知識の表現は変わらないが、知識の遍歴方法が変化することが明らかになった。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/niloofar_mire/status/1988316100690612648?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>RLはしばしば知識のmemorizationを劣化させると言われているが、むしろ学習データから記憶された知識を階層的に辿るようなタスクに適用した結果RL（が実施されたモデル）の方がSFT（が実施されたモデル）よりも高い性能を達成した。同タスクの階層構造をpromptingで与えることで性能SFT/RLのgapが小さくなることから、知識のナビゲーションが性能に関連していることを示唆している。また、事実表現とクエリの表現においてSFTとRLでは前者に大きな違いはないが、後者は大きな違いを見せており、知識の表現そのものを変えるのではなく、モデル内部の知識を辿る方法が変化していることが示唆される。<br><br>といった内容らしいのだが、論文を斜め読みした結果、自分たちでモデルをRL/SFTしたわけではなく既存のオープンなモデルreasoningモデル、instructモデル、distilledモデルで性能を比較する、みたいなことをしているようであり、apple-to-appleの比較になっていないのでは？という感想を抱いたがどうなのだろうか。</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3652" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On a few pitfalls in KL divergence gradient estimation for RL, Yunhao Tang+, arXiv'25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- LLMのRLトレーニングにおけるKLダイバージェンスの勾配推定に関する落とし穴を指摘。特に、KL推定を通じて微分する実装が不正確であることや、逐次的な性質を無視した実装が部分的な勾配しか生成しないことを示す。表形式の実験とLLM実験を通じて、正しいKL勾配の実装方法を提案。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yifan_zhang_/status/1988046103301038153?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>RLにおけるKL Divergenceによるポリシー正則化の正しい実装方法</p>
<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3651" target="_blank" rel="noopener noreferrer">[Paper Note] On the Design of KL-Regularized Policy Gradient Algorithms for LLM Reasoning, Yifan Zhang+, arXiv'25, 2025.05</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<a class="button" href="articles/Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="articles/WorldModels.html" target="_blank" rel="noopener noreferrer">#WorldModels</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3642" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Robot Learning from a Physical World Model, Jiageng Mao+, arXiv'25, 2025.11</a>
<span class="snippet"><span>GPT Summary</span>- PhysWorldは、物理世界のモデル化を通じてビデオ生成とロボット学習を結びつけるフレームワークです。従来のビデオ生成モデルは物理を無視しがちで、ロボットの操作に不正確さをもたらしますが、PhysWorldはタスク条件付きのビデオを生成し、物理世界を再構築します。これにより、生成されたビデオの動きを物理的に正確なアクションに変換し、実際のロボットデータ収集なしでゼロショットのロボット操作を実現します。実験により、PhysWorldは操作精度を大幅に向上させることが示されました。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://pointscoder.github.io/PhysWorld_Web/" target="_blank" rel="noopener noreferrer">https://pointscoder.github.io/PhysWorld_Web/</a>


</p>
<p>画像とタスクプロンプトを与えて動画を生成し、生成された動画に対してworld modelを用いて物理世界の情報を再構築し、そこからロボットのアクションとして何が必要かを推定することでRLをする、結果的にzeroshotでのロボット操作が実現できる、みたいな話に見える(Figure2)</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/pointscoder/status/1988327910466547940?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<span class="issue_date">Issue Date: 2025-11-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3639" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Rolling Forcing: Autoregressive Long Video Diffusion in Real Time, Kunhao Liu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- ストリーミングビデオ生成におけるエラーの蓄積を抑えるために、新技術「Rolling Forcing」を提案。複数フレームの共同デノイジング、注意シンクメカニズムの導入、効率的なトレーニングアルゴリズムを特徴とし、リアルタイムでの高品質なビデオ生成を実現。実験により、エラーの蓄積が大幅に削減されることが確認された。</span>
<span class="snippet"><span>Comment</span><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2870" target="_blank" rel="noopener noreferrer">[Paper Note] Self Forcing: Bridging the Train-Test Gap in Autoregressive Video   Diffusion, Xun Huang+, NeurIPS'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3364" target="_blank" rel="noopener noreferrer">[Paper Note] Self-Forcing++: Towards Minute-Scale High-Quality Video Generation, Justin Cui+, arXiv'25, 2025.10</a>
</p>
<p>self forcingと比較して複数フレームを同時にdenoisingしエラーの蓄積を低減するコンセプトな模様。<br><img src="https://github.com/user-attachments/assets/e496e683-8438-4c87-8451-49e629ae06db" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-11-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3577" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SAIL-RL: Guiding MLLMs in When and How to Think via Dual-Reward RL  Tuning, Fangxun Shu+, arXiv'25, 2025.11</a>
<span class="snippet"><span>GPT Summary</span>- SAIL-RLは、マルチモーダル大規模言語モデルの推論能力を向上させる強化学習フレームワークで、二重報酬システムを用いて推論の質を評価します。これにより、過剰思考や不足思考の問題を解決し、推論とマルチモーダル理解のベンチマークを改善。商業モデルに対して競争力のあるパフォーマンスを示し、幻覚を減少させることに成功しました。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1985951490591121890?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>個々のrewardを応答が持つ性質に応じて切り替える（直接回答するか、思考するかのjudgeの正しさなど）JudgeRewardと思考の品質を3つの次元（logical coherence, factual grounding, answer consistency)から（LLMをベースに）評価するThinkingRewardの二つを用いてRLする（=dual reward mechanism)ことで、推論の質を担保しながらoverthinkingを防ぐ。通常のRLVRによるRewardとフォーマットによる報酬も組み合わせ、複数の個別のRewardを乗算して最終的なRewardを決定することで、reward hackingに対して頑健にする（式1）。</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Short.html" target="_blank" rel="noopener noreferrer">#Short</a>
<span class="issue_date">Issue Date: 2025-11-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3562" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Puzzled by Puzzles: When Vision-Language Models Can't Take a Hint, Heekyung Lee+, EMNLP'25, 2025.05</a>
<span class="snippet"><span>GPT Summary</span>- リバスパズルは視覚的な謎であり、VLMに特有の挑戦をもたらす。従来のタスクとは異なり、マルチモーダルな抽象化や象徴的推論が必要。本研究では、英語のリバスパズルのベンチマークを構築し、VLMの解釈能力を調査。結果、VLMはシンプルな視覚的手がかりには強いが、抽象的推論や視覚的メタファーの理解には苦労することが明らかになった。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/annele222/status/1984993238160425380?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>Rebus Puzzleの例。たとえば上の例はlong time no seeが答えだが、Timeを認識してCが抜けており、かつseeとCの音韻が似ているといった解釈をしなければならない。Waterfallの例では、Waterという文字列が滝のように下に向かっている様子から類推しなければならない。おもしろい。<br><img src="https://github.com/user-attachments/assets/53038e07-fafb-42fe-94f2-2ba6901c544d" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Self-SupervisedLearning.html" target="_blank" rel="noopener noreferrer">#Self-SupervisedLearning</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/2D%20(Image).html" target="_blank" rel="noopener noreferrer">#2D (Image)</a>
<a class="button" href="articles/3D%20(Scene).html" target="_blank" rel="noopener noreferrer">#3D (Scene)</a>
<a class="button" href="articles/SpatialUnderstanding.html" target="_blank" rel="noopener noreferrer">#SpatialUnderstanding</a>
<a class="button" href="articles/Pixel-based.html" target="_blank" rel="noopener noreferrer">#Pixel-based</a>
<span class="issue_date">Issue Date: 2025-11-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3555" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised  Reinforcement Learning, Yuhong Liu+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 空間理解におけるLVLMの弱点を克服するため、自己教師あり強化学習パラダイムSpatial-SSRLを提案。5つの前提タスクを自動定式化し、検証が容易な信号を導出。これにより、空間推論が大幅に改善され、7つのベンチマークでQwen2.5-VLベースラインに対して平均精度が4.63%（3B）および3.89%（7B）向上。シンプルな監視がRLVRを可能にし、LVLMの空間知能向上に寄与することを示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1985177625564684602?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>RGB/RGB-D imageがgivenなときに、<br>- cropped patch inpainting<br>- flipped patch recognition<br>- shuffled patch reordering<br>- regional depth ordering<br>- relative 3D position prediction<br><br>の5つのverifiableなタスクを定義しself supervisedなmannerでRLすることでSpatial Understanding能力を向上させる話らしい<br><img src="https://github.com/user-attachments/assets/5ecd7925-6674-4c15-8d67-ec5a59133de4" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/UserBased.html" target="_blank" rel="noopener noreferrer">#UserBased</a>
<a class="button" href="articles/AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<span class="issue_date">Issue Date: 2025-11-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3534" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Completion $\neq$ Collaboration: Scaling Collaborative Effort with  Agents, Shannon Zejiang Shen+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- エージェントの評価をタスク完了から協調的な問題解決プロセスにシフトすることを提唱。ユーザーの関与がエージェントの有用性に与える影響を捉える「協調的努力スケーリング」フレームワークを導入。ケーススタディにより、現実のシナリオでのエージェントのパフォーマンス低下を示し、持続的なエンゲージメントとユーザー理解の重要性を明らかにする。</span>
<span class="snippet"><span>Comment</span><p>単に一発でタスクをこなすことに最適化されているが、ユーザからの要求は反復的で進化するので数ラウンド経つとコントロールしづらくなる、といったことが起きてしまう経験があると思うが、実際そうだということを実験的に示している模様。そして、ユーザと協働しながら効用を最大化させるようなアプローチが必要のことを明らかにしている、みたいな話らしい。</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/CrossLingual.html" target="_blank" rel="noopener noreferrer">#CrossLingual</a>
<a class="button" href="articles/TransferLearning.html" target="_blank" rel="noopener noreferrer">#TransferLearning</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3525" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ATLAS: Adaptive Transfer Scaling Laws for Multilingual Pretraining,  Finetuning, and Decoding the Curse of Multilinguality, Shayne Longpre+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、774の多言語トレーニング実験を通じて、最大の多言語スケーリング法則を探求し、ATLASという適応的転送スケーリング法則を導入。これにより、既存のスケーリング法則を上回る性能を示し、多言語学習のダイナミクスや言語間の転送特性を分析。言語ペア間の相互利益スコアを測定し、モデルサイズとデータの最適なスケーリング方法を明らかにし、事前学習とファインチューニングの計算的クロスオーバーポイントを特定。これにより、英語中心のAIを超えたモデルの効率的なスケーリングの基盤を提供することを目指す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shayneredford/status/1983170949865173069?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p><img src="https://github.com/user-attachments/assets/381375e6-ca49-4bc0-8347-2bc6724cf9a7" alt="image" loading="lazy"><br><br>バイリンガルで学習した時に、日本語とシナジーのある言語、この図を見ると無さそうに見える😅</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3520" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Agent Data Protocol: Unifying Datasets for Diverse, Effective  Fine-tuning of LLM Agents, Yueqi Song+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、エージェントデータの収集における課題を解決するために、エージェントデータプロトコル（ADP）を提案。ADPは多様なデータ形式を統一し、簡単に解析・トレーニング可能な表現言語である。実験により、13のエージェントトレーニングデータセットをADP形式に統一し、標準化されたデータでSFTを実施した結果、平均約20％の性能向上を達成。ADPは再現可能なエージェントトレーニングの障壁を下げることが期待される。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://www.agentdataprotocol.com" target="_blank" rel="noopener noreferrer">https://www.agentdataprotocol.com</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1983548125135655228?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>著者ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/syz0x1/status/1983715963305652638?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>解説:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1988018578239746377?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>エージェントを学習するための統一的なデータ表現に関するプロトコルを提案</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="articles/TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<a class="button" href="articles/OptimalTransport.html" target="_blank" rel="noopener noreferrer">#OptimalTransport</a>
<span class="issue_date">Issue Date: 2025-10-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3511" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Towards Cross-Tokenizer Distillation: the Universal Logit Distillation   Loss for LLMs, Nicolas Boizard+, TMLR'25, 2024.02</a>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLMs）の展開はコストやハードウェアの制約から実用的ではないが、知識蒸留（KD）が解決策となる。従来のロジットに基づく方法はトークナイザーの共有が必要で適用性が限られる。本研究では、最適輸送に基づくユニバーサルロジット蒸留（ULD）損失を提案し、異なるアーキテクチャ間での蒸留を可能にすることを示した。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=bwRxXiGO9A" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=bwRxXiGO9A</a>


</p>
<p>（以下は管理人の理解が不十分なまま書かれているため誤りがある可能性が高いのでご注意ください）<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3510" target="_blank" rel="noopener noreferrer">Unlocking On-Policy Distillation for Any Model Family, Patiño+, HuggingFace, 2025.10</a>
<br><br>の記述と論文を斜め読みした感じ、<br><br>従来の蒸留手法は出力（Vocab)の分布が近くなるように学習するため、教師と生徒モデル間でVocabが揃っている、すなわちtokenizerが共通でなければならず、これが教師生徒ペアを選択する際の制約となっていた。これを異なるtokenizerを持つモデル間でも蒸留可能にしたという話。これには以下の二つの課題があり<br>- sequence misalignment: tokenizerが異なるため、共通のsequenceに対して異なるsplitをする可能性がある<br>- vocabulary misalignment: 同じトークンIDが異なるtokenを指す<br><br>要は確率分布が対応づけられないのでワッサースタイン距離（＝一方の確率分布をもう一方の確率分布に一致させるために必要な輸送の質量と距離よ最小コスト）によって距離を測ることを目指す（通常の教師ありDistillationのKL Divergenceをワッサースタイン距離に置き換えた損失を考える）。<br>が、ワッサースタイン距離はO(n^3log n)であるため近似的な解法で解く。その方法として、<br>- 教師のトークン列と生徒のトークン列の長さは異なるので短い方の長さに合わせてtruncateし<br>- ソフトマックス出力のロジットの大きさで両モデルのベクトルをソートし、小さい方をzero paddingして長さを揃えてベクトル間を比較可能にする[^1]<br><br>といった方法をとる模様？<br><br>[^1]: ソートさせたらvocabularyの整合性がとれずにでたらめな距離になるのでは？と思ったのだが、意図としては各次元が特定の単語ではなく確率順位を表すようにし、その間を比較することで分布の形（エントロピーやconfidenceの構造）の観点で比較可能にする、というニュアンスらしい。ただしこの部分についてはChatGPTの問答を通じて得た知識なので誤りがある可能性があるので注意。</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/German.html" target="_blank" rel="noopener noreferrer">#German</a>
<span class="issue_date">Issue Date: 2025-10-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3477" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The German Commons - 154 Billion Tokens of Openly Licensed Text for  German Language Models, Lukas Gienapp+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 「German Commons」は、オープンライセンスのドイツ語テキストの最大コレクションで、41のソースから1545.6億トークンを提供。法律、科学、文化など7つのドメインを含み、品質フィルタリングや重複排除を行い、一貫した品質を確保。すべてのデータは法的遵守を保証し、真にオープンなドイツ語モデルの開発を支援。再現可能で拡張可能なコーパス構築のためのコードも公開。</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/datasets/coral-nlp/german-commons" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/coral-nlp/german-commons</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webis_de/status/1982794705302655243?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>最大級（154B)のドイツ語のLLM（事前）学習用データセットらしい</p>
<p>ODC-By Licence</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/OOD.html" target="_blank" rel="noopener noreferrer">#OOD</a>
<a class="button" href="articles/Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/ObjectDetection.html" target="_blank" rel="noopener noreferrer">#ObjectDetection</a>
<span class="issue_date">Issue Date: 2025-10-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3460" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Roboflow100-VL: A Multi-Domain Object Detection Benchmark for   Vision-Language Models, Peter Robicheaux+, NeurIPS'25, 2025.05</a>
<span class="snippet"><span>GPT Summary</span>- 視覚と言語のモデル（VLMs）は、一般的な物体に対して優れたゼロショット検出性能を示すが、分布外のクラスやタスクに対しては一般化が難しい。そこで、少数の視覚例と豊富なテキスト記述を用いてVLMを新しい概念に整合させる必要があると提案。Roboflow100-VLという多様な概念を持つ100のマルチモーダル物体検出データセットを導入し、最先端モデルの評価を行った。特に、難しい医療画像データセットでのゼロショット精度が低く、少数ショットの概念整合が求められることを示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gabriberton/status/1982270700883951875?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>VLMが「現実世界をどれだけ理解できるか」を評価するためのobject detection用ベンチマークを構築。100のopen source datasetから構成され、それぞれにはtextでのfew shot instructionやvisual exampleが含まれている。データセットは合計で約165kの画像、約1.35M件のアノテーションが含まれ、航空、生物、産業などの事前学習ではあまりカバーされていない新規ドメインの画像が多数含まれているとのこと。<br><br>そして現在のモデルは事前学習に含まれていないOODな画像に対する汎化性能が低く、いちいちモデルを追加で学習するのではなく、ICLによって適用できた方が好ましいという考えがあり、そして結果的に現在のVLMでは、ICLがあまりうまくいかない（ICLによるOODの汎化が効果的にできない）ことがわかった、という話らしい。<br><br>が、<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3467" target="_blank" rel="noopener noreferrer">[Paper Note] Many-Shot In-Context Learning in Multimodal Foundation Models, Yixing Jiang+, arXiv'24, 2024.05</a>
<br><br>での知見と異なる。差異はなんだろうか？<br><br>以下のスレッドで議論がされている:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/marchoelle/status/1982589731260203110?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>pj page:


<a href="https://rf100-vl.org" target="_blank" rel="noopener noreferrer">https://rf100-vl.org</a>


</p>
<p>うーんあとでしっかり読みたい、、、</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/LongHorizon.html" target="_blank" rel="noopener noreferrer">#LongHorizon</a>
<span class="issue_date">Issue Date: 2025-10-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3459" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MemER: Scaling Up Memory for Robot Control via Experience Retrieval, Ajay Sridhar+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、ロボットポリシーに人間のような記憶能力を与えるための階層的ポリシーフレームワークを提案。高レベルポリシーが関連するキーフレームを選択し、低レベルポリシーに指示を生成することで、長期的な依存関係を効率的に推論。実験により、提案手法MemERが従来の方法を上回る性能を示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ajaysridhar0/status/1982239143431393432?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>pj page:


<a href="https://jen-pan.github.io/memer/" target="_blank" rel="noopener noreferrer">https://jen-pan.github.io/memer/</a>


</p>
<p>動画ストリーム全てを常にinputするのではなくキーフレームは限られているので、VLMにキーフレームをメモリ上で管理するような役割を与え、instructionと実現するためのサブタスクに応じて動的に必要な情報のみをVLAに与えることでlong horizonでのスケーラビリティを改善する、みたいな話らしい</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/LongHorizon.html" target="_blank" rel="noopener noreferrer">#LongHorizon</a>
<span class="issue_date">Issue Date: 2025-10-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3455" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] R-Horizon: How Far Can Your Large Reasoning Model Really Go in Breadth  and Depth?, Yi Lu+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- R-HORIZONを提案し、長期的な推論行動を刺激する手法を通じて、LRMの評価を改善。複雑なマルチステップ推論タスクを含むベンチマークを構築し、LRMの性能低下を明らかに。R-HORIZONを用いた強化学習データ（RLVR）は、マルチホライズン推論タスクの性能を大幅に向上させ、標準的な推論タスクの精度も向上。AIME2024で7.5の増加を達成。R-HORIZONはLRMの長期推論能力を向上させるための有効なパラダイムと位置付けられる。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://reasoning-horizon.github.io" target="_blank" rel="noopener noreferrer">https://reasoning-horizon.github.io</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1982608933563826270?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>long horizonタスクにうまく汎化する枠組みの必要性が明らかになったように見える。long horizonデータを合成して、post trainingをするという枠組みは短期的には強力でもすぐに計算リソースの観点からすぐに現実的には能力を伸ばせなくなるのでは。</p>
<p>ポイント解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1982875191303713019?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ContextWindow.html" target="_blank" rel="noopener noreferrer">#ContextWindow</a>
<a class="button" href="articles/Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<a class="button" href="articles/text.html" target="_blank" rel="noopener noreferrer">#text</a>
<a class="button" href="articles/Compression.html" target="_blank" rel="noopener noreferrer">#Compression</a>
<span class="issue_date">Issue Date: 2025-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3450" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ARC-Encoder: learning compressed text representations for large language  models, Hippolyte Pilchen+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、コンテキストを連続表現に圧縮するARC-Encoderを提案し、デコーダLLMのトークン埋め込みを置き換えるアプローチを探求。ARC-Encoderは、テキストトークンの少ない連続表現を出力し、計算効率を向上させる。さまざまなLLMシナリオで評価した結果、最先端のパフォーマンスを達成し、複数のデコーダに同時に適応可能であることを示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1981622829960614101?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>最近textのcontextをvisual tokenでレンダリングすることで圧縮する話が盛り上がっているが、こちらはtextの表現そのものを圧縮する話な模様。<br><br>そのうちpixel単位の入力、テキスト単位での入力を圧縮する話どちらかだけでなく、双方のハイブリッドになり、かつタスクに応じてattention等を通じてどちらのモダリティの情報を使うか、また圧縮前と後の情報どちらを使うか、みたいなものを動的に選択してタスクに応じて計算量やメモリを節約しつつ、高い性能を担保する、みたいな話になるんではなかろうか。</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2025-10-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3426" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning to Interpret Weight Differences in Language Models, Avichal Goel+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ファインチューニングされた言語モデルの重みの変化を解釈するために、Diff Interpretation Tuning（DIT）を提案。合成されたラベル付きの重みの差を用いてモデルに変更を説明させる。隠れた挙動の報告や知識の要約において、DITが自然言語での正確な説明を可能にすることを示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tonywangiv/status/1981362885830779359?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>weightの更新があった時に、LLM自身がどのような変化があったかをverbalizeできるようにSFTでLoRA Adaptorを学習する話らしい</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Off-Policy.html" target="_blank" rel="noopener noreferrer">#Off-Policy</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="articles/Entropy.html" target="_blank" rel="noopener noreferrer">#Entropy</a>
<a class="button" href="articles/PartialRollout.html" target="_blank" rel="noopener noreferrer">#PartialRollout</a>
<span class="issue_date">Issue Date: 2025-10-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3403" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via  Balanced Policy Optimization with Adaptive Clipping, Zhiheng Xi+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 強化学習におけるオフポリシー設定の課題を解決するため、BAPO（Balanced Policy Optimization with Adaptive Clipping）を提案。ポジティブとネガティブな寄与を再バランスし、エントロピーを保持することで最適化を安定化。多様なシナリオでデータ効率の高いトレーニングを実現し、AIME 2024およびAIME 2025のベンチマークで最先端の結果を達成。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://github.com/WooooDyy/BAPO" target="_blank" rel="noopener noreferrer">https://github.com/WooooDyy/BAPO</a>


</p>
<p>Partial Rollout（＝長いtrajectoryを一回のロールアウトで生成仕切らずに、途中で生成を打ち切りreplay bufferに保存。次のロールアウト時に続きを生成する。しかし更新されたポリシーによって続きをロールアウトするためオフポリシーデータとなる）の設定で、GRPOよりも学習効率が良いことが示されているように見える。</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/AutomaticPromptOptimization.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptOptimization</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3362" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Prompt-MII: Meta-Learning Instruction Induction for LLMs, Emily Xiao+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- PROMPT-MIIという新しい指示誘導モデルを提案し、トレーニング例をコンパクトなプロンプトに縮小することで、インコンテキスト学習（ICL）と同等のパフォーマンスを実現。3,000以上の分類データセットでトレーニングし、90の未見タスクで評価した結果、下流モデルの品質を4-9 F1ポイント向上させ、必要なトークン数を3-13倍削減。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1980644772902789603?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>タスクのexamplar/demonstrationからタスクに関するdescription）＝instruction)を生成するモデルを学習し、生成されたinstructionを用いることで、manyshotでICLするよりも、少ないトークン数で同等以上の性能を達成するといった話に見える。どういうinstructionになるのかが非常に興味がある。A.6参照のこと。細かく具体的だがコンパクトな指示が記述されているようなinstructionとなっている。<br><br><img src="https://github.com/user-attachments/assets/ee02024a-725d-47a1-9b8c-46fed1dbcb8f" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/363dd369-79d3-4b37-b4de-f880e2fb746d" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ContextWindow.html" target="_blank" rel="noopener noreferrer">#ContextWindow</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3357" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Glyph: Scaling Context Windows via Visual-Text Compression, Jiale Cheng+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、長いコンテキストを持つ大規模言語モデル（LLMs）の実用性を向上させるため、Glyphというフレームワークを提案し、テキストを画像に変換して視覚と言語のモデル（VLMs）で処理します。このアプローチにより、3-4倍のトークン圧縮を実現し、精度を維持しつつ処理速度を約4倍向上させます。さらに、128KコンテキストのVLMが1Mトークンのテキストタスクを処理可能になることを示しました。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1980474912168112471?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>所見:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1980722682246398069?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>テキストを画像にレンダリングしてVLMに入力することでtextと比較して3.2倍KV Cache (context)を圧縮し、prefillingとデコード速度も4.8, 4.4倍高速化するフレームワークらしい<br><br><img src="https://github.com/user-attachments/assets/e65f880d-0d04-434f-9a51-accc84d44a6f" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3349" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action, Yuhao Yang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ハイブリッドアクションを用いた基盤モデル「UltraCUA」を提案し、GUIの原始的なアクションと高レベルのプログラムツール呼び出しを統合。自動化パイプライン、合成データエンジン、ハイブリッドアクション軌跡コレクション、二段階のトレーニングパイプラインを構成要素とし、実験により最先端エージェントに対して22%の改善と11%の速度向上を達成。エラー伝播を減少させつつ実行効率を維持することが確認された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhegan4/status/1980471759251075578?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>従来のCUAはGUIに対する低レベルの操作（クリック、タイプ、スクロール）を利用する前提に立つが、本研究ではそれらだけではなくより高レベルのprogramatic tool calls(e.g., python関数呼び出し、キーボードショートカット、スクリプト実行、API呼び出し等)をシームレスに統合できるように合成データを作成しAgentをらSFTとRLしましたらよりベンチマークスコア向上した、というような話に見える。</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/SkillTag.html" target="_blank" rel="noopener noreferrer">#SkillTag</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3346" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Skill-Targeted Adaptive Training, Yinghui He+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、言語モデルのメタ認知能力を活用した新しいファインチューニング戦略「STAT」を提案。教師モデルがタスクに必要なスキルをラベル付けし、学生モデルのスキル不足を追跡することで、トレーニングセットを修正。STAT-Selでは既存の例の重みを調整し、STAT-Synでは新たな例を合成。実験により、MATHで最大7.5%の改善を達成し、分布外ベンチマークでも平均4.6%の向上を示した。STATは強化学習手法GRPOと補完的であり、スキルターゲットの適応トレーニングがトレーニングパイプラインを改善することを示唆。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yinghui_he_/status/1980257694704619679?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3361" target="_blank" rel="noopener noreferrer">[Paper Note] Metacognitive Capabilities of LLMs: An Exploration in Mathematical   Problem Solving, Aniket Didolkar+, NeurIPS'24, 2024.05</a>
</p>
<p>Reward Modelでquestionがeasy/hardを定量化し、hardなものに対してモデルが応答を生成。応答の結果をstronger modelに確認させ、モデルにどのようなスキルが不足しているかを特定する。これによりモデルのスキルに関するprofileが作成されるのでこれに基づいて学習データの各サンプルとスキルを紐づけた上でサンプルを重みの調整、および不足しているスキルに関するデータを合成しSFTに活用する、といった話な模様。<br><br>&lt;img width="838" height="496" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/8f5e9efb-c096-4897-8327-daed9e4c920a"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/8f5e9efb-c096-4897-8327-daed9e4c920a"&lt;/a&gt;


/&gt;<br><br>結果を見ると、+SFT / +GRPOよりも性能が高くなっている。Table1ではLlamaでの結果しか掲載されていないが、Qwenでも実験がされて同様の結果が得られている。<br>&lt;img width="856" height="255" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/d35077ef-bf33-4c12-82e1-37cbc40247af"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/d35077ef-bf33-4c12-82e1-37cbc40247af"&lt;/a&gt;


/&gt;<br><br>また、Figure4を見ると不足していたスキルが学習によってきちんと補われていることが分かる。<br><br>&lt;img width="839" height="541" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/bd07a4e5-87c8-4ab1-a45c-379cff343e33"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/bd07a4e5-87c8-4ab1-a45c-379cff343e33"&lt;/a&gt;


/&gt;<br><br>（評価と考察部分をもう少しじっくり読みたい）</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3342" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Beyond Context: A Survey of Multimodal Retrieval-Augmented  Generation for Document Understanding, Sensen Gao+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 文書理解は多様なアプリケーションにおいて重要であり、現在のアプローチには制限がある。特に、OCRベースのパイプラインは構造的詳細を失い、マルチモーダルLLMsはコンテキストモデリングに苦労している。リトリーバル強化生成（RAG）は外部データを活用するが、文書のマルチモーダル性にはマルチモーダルRAGが必要である。本論文では、文書理解のためのマルチモーダルRAGに関する体系的な調査を行い、分類法や進展をレビューし、主要なデータセットや課題をまとめ、文書AIの今後の進展に向けたロードマップを提供する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1980096776482013263?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>multimodal RAGに関するSurvey</p>
<p>Table1は2024年以後の35本程度の手法、Table2は20+程度のベンチマークがまとまっており、基本的な概念なども解説されている模様。半数程度がtraining-free/OCRを利用する手法はそれぞれ五分五分程度なようで、Agenticな手法はあまり多くないようだ(3/35)。</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-10-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3322" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Clean First, Align Later: Benchmarking Preference Data Cleaning for  Reliable LLM Alignment, Samuel Yeh+, NeurIPS'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- 人間のフィードバックはLLMのアライメントに重要だが、ノイズや一貫性の欠如が問題を引き起こす。これを解決するために、13のデータクリーニング手法を評価する初のベンチマーク「PrefCleanBench」を導入。さまざまな条件下でのアライメント性能を比較し、データクリーニングの成功要因を明らかにする。これにより、LLMアライメントの改善に向けた再現可能なアプローチを提供し、データ前処理の重要性を強調する。すべての手法の実装は公開されている。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sharonyixuanli/status/1979617821434024374?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>元ポストによるとTakeawayとしては、<br>- cleaningをすることでalignmentの性能は一貫して向上<br>- 複数のReward Modelを用いた場合（おそらくhuman labelと複数RMのvotingに基づくcleaning）は単一モデルよりも信頼性が高くロバスト<br>- bad dataに対するデータは（ラベルを修正するよりも）削除した方が性能が向上する<br>- 少量だがクリーンなデータセットは大規模でノイジーなデータセットよりも性能が良い<br><br>といった知見がある模様</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/KV%20Cache.html" target="_blank" rel="noopener noreferrer">#KV Cache</a>
<span class="issue_date">Issue Date: 2025-10-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3319" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Attention Is All You Need for KV Cache in Diffusion LLMs, Quan Nguyen-Tri+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、拡散型大規模言語モデル（DLMs）のデコーディング待機時間を最小化しつつ予測精度を最大化するために、適応的なKVキャッシュ再計算手法「Elastic-Cache」を提案。これにより、浅いレイヤーの冗長性を削減し、重要なトークンに基づいてキャッシュのリフレッシュを動的に行う。実験では、GSM8KやHumanEvalでの速度向上を示し、生成品質を維持しながら高いスループットを達成した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1979180865520570615?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>DLMにおいて、denoisingの各ステップにおいて全てのKVを再計算するのではなく、attention scoreが大きくドリフトしていない部分についてはKV Cacheを再利用し、大きくドリフトした部分だけ再計算するような仕組みを学習することで、品質を損なうことなく推論速度を高速化した模様</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Scalability.html" target="_blank" rel="noopener noreferrer">#Scalability</a>
<span class="issue_date">Issue Date: 2025-10-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3317" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Test-Time Compute to Achieve IOI Gold Medal with Open-Weight  Models, Mehrzad Samadi+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 競技プログラミングはLLMsの能力を評価する重要なベンチマークであり、IOIはその中でも特に権威ある大会です。本論文では、オープンウェイトモデルがIOI金メダルレベルのパフォーマンスを達成するためのフレームワーク「GenCluster」を提案します。このフレームワークは、生成、行動クラスタリング、ランキング、ラウンドロビン戦略を組み合わせて多様な解決空間を効率的に探索します。実験により、GenClusterは計算リソースに応じてスケールし、オープンシステムとクローズドシステムのギャップを縮小することが示され、IOI 2025で金メダルを達成する可能性を示唆しています。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacksonatkinsx/status/1979563525614842156?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>OpenWeight modelで初めてIOI金メダル級のパフォーマンスを実現できるフレームワークで、まずLLMに5000個程度の潜在的なsolutionを生成させ、それぞれのsolutionを100種のtest-caseで走らせて、その後solutionをbehaviorに応じてクラスタリングする。これによりアプローチのユニークさにそってクラスタが形成される。最終的に最も良いsolutionを見つけるために、それぞれのクラスタから最も良いsolutionを互いに対決させて、LLM-as-a-Judgeで勝者をランク付けするような仕組みのようである。<br><br>&lt;img width="922" height="320" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/899026dd-38a9-4a1d-a871-2a37bcfeb623"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/899026dd-38a9-4a1d-a871-2a37bcfeb623"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3315" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] When Thoughts Meet Facts: Reusable Reasoning for Long-Context LMs, Soyeong Jeong+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 思考テンプレートを用いて、長文コンテキスト言語モデル（LCLMs）によるマルチホップ推論を構造化。証拠の結びつきを捉え、自然言語フィードバックでテンプレートを洗練。多様なベンチマークで性能向上を実現し、小型モデルへの蒸留も可能。フレームワーク名はToTAL。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1979207098413232316?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>シンプルなCoTやドキュメント全体をcontextに入力するようなシンプルなベースラインしかなく、ベースラインが少し弱いような印象を受けたが（たとえばChain-of-Noteを適用していない、と思ったが）実験しているモデルを見ると、そもそもReasoningモデルを使った実験（前提）となっているので（Chain-of-Noteなどはnon-thinking modelでは有効なことが示されているがthinking modelでの効果は不明という認識）、なんやかんやこのベースラインで十分なのでは、という気もする。そして結構性能が上がっているように見える。（後で読みたい）</p></span><br><br>
<a class="button" href="articles/Online/Interactive.html" target="_blank" rel="noopener noreferrer">#Online/Interactive</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/OOD.html" target="_blank" rel="noopener noreferrer">#OOD</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<a class="button" href="articles/Test-time%20Learning.html" target="_blank" rel="noopener noreferrer">#Test-time Learning</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3314" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Thinking on the Fly: Test-Time Reasoning Enhancement via Latent Thought  Policy Optimization, Wengao Ye+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Latent Thought Policy Optimization（LTPO）を提案し、LLMの推論を強化するパラメータフリーのフレームワークを導入。中間的な潜在「思考」ベクトルを動的に最適化し、外部監視なしで報酬信号に基づくオンラインポリシー勾配法を使用。5つの推論ベンチマークで強力な性能を示し、特にAIMEベンチマークで顕著な改善を達成。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1979207098413232316?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>test-time に online-RLを適用することでモデルのパラメータを更新することなく、クエリに応じて動的にlatent reasoningを洗練し、推論能力をロバストにできる、という話な模様？<br><br>&lt;img width="729" height="675" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/cdefa5c8-5fc4-4057-867e-bce5466702b6"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/cdefa5c8-5fc4-4057-867e-bce5466702b6"&lt;/a&gt;


/&gt;<br><br>実験結果を見ると、モデルのパラメータ数が大きい場合にgainが小さくなっていっているように見え、かつ実験中のlargest modelのgainがサンプル数の少ないAIMEのスコアに依存しているように見える。</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="articles/AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3306" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AutoCode: LLMs as Problem Setters for Competitive Programming, Shang Zhou+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- AutoCodeは、競技プログラミングの問題文とテストケースを生成するシステムであり、信頼性の高い問題作成を実現します。複数回の検証を通じて、生成された問題は公式の判断と99%の一貫性を持ち、従来の手法に比べて大幅な改善を示します。また、ランダムなシード問題から新しいバリアントを作成し、不正な問題をフィルタリングする機能も備えています。最終的に、AutoCodeはグランドマスター級の競技プログラマーによってコンテスト品質と評価される問題を生成します。</span>
<span class="snippet"><span>Comment</span><p>blog:


<a href="https://livecodebenchpro.com/projects/autocode/overview" target="_blank" rel="noopener noreferrer">https://livecodebenchpro.com/projects/autocode/overview</a>


</p>
<p>LLMで自動的に高品質な競技プログラミング問題とそのテストケースを生成するパイプラインを提案。<br><br>信頼性のあるテストケースを作成するために、Validator-Generator-Checkerフレームワーク。提案。Generatorがテストケースを生成し、Validatorが生成されたテストケースの入力が問題の制約を満たしているか判定し、Checkerが与えられたテストケースの元で解法が正しいかを確認する。<br><br>続いて、人手を介さずとも生成される問題が正しいことを担保するためにdual-verificationを採用。具体的には、LLMに新規の問題文と効率的な解法を生成させ、加えてブルートフォースでの解法を別途生成する。そして、両者をLLMが生成したテストセット群で実行し、全ての解放で出力が一致した場合のみAcceptする、といったような手法らしい。<br><br>（手法の概要としてはそうなのだろうが、細かい実装に高品質さの肝があると思うのでしっかり読んだ方が良さげ。特にTest Generationの詳細をしっかりできていない）<br><br><img src="https://github.com/user-attachments/assets/e6779e5d-9e0a-4da8-9634-d6054704bfa7" alt="image" loading="lazy"></p>
<p>takeawayで興味深かったのは、<br><br>- LLMは自身では解けないが、解法が存在する（solvable)問題を生成できること<br>- 人間の専門家とLLM（o3)の間で、問題の品質の新規性の判定の相関がわずか0.007, 0.11しかなかったこと。そして品質に関しては専門家のグループ間では0.71, o3とgpt4oの間では0.72と高い相関を示しており、LLMと人間の専門家の間で著しく問題の品質の判断基準が異なること<br>- seed問題と生成された問題の難易度のgainが、問題の品質に関して、LLM自身のself-evaluationよりもより良い指標となっていること</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DynamicNetworks.html" target="_blank" rel="noopener noreferrer">#DynamicNetworks</a>
<a class="button" href="articles/Routing.html" target="_blank" rel="noopener noreferrer">#Routing</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3298" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Dr.LLM: Dynamic Layer Routing in LLMs, Ahmed Heakl+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Dr.LLMは、LLMsに動的な層ルーティングを導入し、計算効率を向上させるフレームワーク。モンテカルロ木探索を用いて高品質な層構成を導出し、ARCやDARTで精度を最大+3.4%向上させ、平均5層を節約。ドメイン外タスクでもわずか0.85%の精度低下で従来手法を上回る。明示的な監視下でのルーターがLLMsを効率的に活用できることを示す。</span>
<span class="snippet"><span>Comment</span><p>LayerごとにMLPのrouterを用意し、（元のLLMのパラメータはfreezeして）Layerをskip, execute, repeatするかを追加で学習することで、クエリに応じて動的に計算コストとpathを調整する能力を身につけさせ、性能を向上させつつも計算量も削減できます、といった話な模様。routerが学習されているのでinference時にsearchは不要。</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/UserModeling.html" target="_blank" rel="noopener noreferrer">#UserModeling</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/UserBased.html" target="_blank" rel="noopener noreferrer">#UserBased</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-10-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3273" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SimulatorArena: Are User Simulators Reliable Proxies for Multi-Turn  Evaluation of AI Assistants?, Yao Dou+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- SimulatorArenaを導入し、909件の人間-LLM会話を用いて、数学指導と文書作成の2つのタスクにおけるシミュレーターの評価を行う。シミュレーターのメッセージが人間の行動と一致する度合いや、アシスタント評価が人間の判断と整合する度合いを基に評価。条件付けされたシミュレーターが人間の判断と高い相関を示し、実用的な代替手段を提供。最新の18のLLMをベンチマーク。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yaooo01/status/1978206110059205049?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>マルチターンの会話においてAIと人間との対話（数学のtutoring, 文書の作成支援）を評価する際に、実際の人間はコストがかかりスケールしないのでLLMを人間の代替とし評価ができるか？どのようにすればLLMを人間の振る舞いと整合させられるか？といった話しで、25種類以上のattributeによるユーザプロファイルを用いることが有効だった（人間の評価結果に対して、ユーザプロファイルを用いたLLMシミュレーターがより高い相関を示した）というような話しらしい。</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/MemoryOptimization.html" target="_blank" rel="noopener noreferrer">#MemoryOptimization</a>
<span class="issue_date">Issue Date: 2025-10-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3271" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Not All Bits Are Equal: Scale-Dependent Memory Optimization Strategies  for Reasoning Models, Junhyuck Kim+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 4ビット量子化はメモリ最適化に有効ですが、推論モデルには適用できないことを示す。体系的な実験により、モデルサイズとKVキャッシュの影響を発見。小規模モデルは重みを優先し、大規模モデルは生成にメモリを割り当てることで精度を向上。LLMのメモリ最適化はスケールに依存し、異なるアプローチが必要であることを示唆。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dimitrispapail/status/1978108550854382052?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>Reasoning Modelにおいて、メモリのbudgetに制約がある状況下において、<br>- モデルサイズ<br>- 重みの精度<br>- test-time compute (serial &amp; parallel)<br>- KV Cacheの圧縮<br><br>において、それらをどのように配分することでモデルのAcc.が最大化されるか？という話しな模様。</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-10-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3268" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] EVALUESTEER: Measuring Reward Model Steerability Towards Values and  Preferences, Kshitish Ghate+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- EVALUESTEERは、ユーザーの多様な価値観やスタイルに対応するためのベンチマークであり、LLMsと報酬モデル（RMs）の操縦性を測定します。165,888の好みペアを生成し、ユーザーのプロファイルに基づく応答の選択精度を評価。完全なプロファイルでは75%未満の精度に対し、関連する好みのみで99%以上の精度を達成。EVALUESTEERは、RMsの限界を明らかにし、多様な価値観に対応するためのテストベッドを提供します。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ghatekshitish/status/1978128389157380570?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>LLNのAlignmentはしばしばReward Modelをベースに実施されるが、現在のReward Modelに存在する、価値観（4種類）とスタイル（4種類）に関するバイアスが存在することを明らかにしている模様。</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-10-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3265" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Alignment Waltz: Jointly Training Agents to Collaborate for Safety, Jingyu Zhang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- WaltzRLという新しいマルチエージェント強化学習フレームワークを提案し、LLMの有用性と無害性のバランスを取る。会話エージェントとフィードバックエージェントを共同訓練し、応答の安全性と有用性を向上させる。実験により、安全でない応答と過剰な拒否を大幅に減少させることを示し、LLMの安全性を向上させる。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1978185306999341256?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>マルチエージェントを用いたLLMのalignment手法。ユーザからのpromptに応答する会話エージェントと、応答を批評するフィードバックエージェントの2種類を用意し、違いが交互作用しながら学習する。フィードバックエージェント会話エージェントが安全かつ過剰に応答を拒絶していない場合のみ報酬を与え、フィードバックエージェントのフィードバックが次のターンの会話エージェントの応答を改善したら、フィードバックエージェントに報酬が与えられる、みたいな枠組みな模様。</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3261" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Stabilizing MoE Reinforcement Learning by Aligning Training and  Inference Routers, Wenhan Ma+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）を用いたMixture-of-Experts（MoE）モデルのトレーニングと推論の不一致を分析し、Rollout Routing Replay（R3）を提案。R3は推論時のルーティング分布を記録し、トレーニング中に再生することで、トレーニングと推論のポリシー間のKLダイバージェンスを減少させ、安定性を向上。実験により、R3がRLトレーニングの崩壊を防ぎ、他の手法を上回る性能を示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1977990785795576316?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2552" target="_blank" rel="noopener noreferrer">Your Efficient RL Framework Secretly Brings You Off-Policy RL Training, Yao+, 2025.08</a>
<br><br>のMoE版の話。Inference EngineとTraining Engine側でExpertsの選択が一致しないことが不安定につながるので、それを一致させるようにする、という話な模様。<br><img src="https://github.com/user-attachments/assets/0335e297-332d-4759-9c9a-9f9e7e634b5d" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3249" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Verifying Chain-of-Thought Reasoning via Its Computational Graph, Zheng Zhao+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Circuit-based Reasoning Verification (CRV)を提案し、CoTステップの帰属グラフを用いて推論エラーを検証。エラーの構造的署名が予測的であり、異なる推論タスクで異なる計算パターンが現れることを示す。これにより、モデルの誤った推論を修正する新たなアプローチを提供し、LLM推論の因果理解を深めることを目指す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacksonatkinsx/status/1977721832909177032?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>著者ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhengzhao97/status/1981717885891326409?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>transformer内部のactivationなどから計算グラフを構築しreasoningのsurface（＝観測できるトークン列）ではなく内部状態からCoTをverification（＝CoTのエラーを検知する）するようなアプローチ（white box method)らしい</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<a class="button" href="articles/Test-time%20Learning.html" target="_blank" rel="noopener noreferrer">#Test-time Learning</a>
<span class="issue_date">Issue Date: 2025-10-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3236" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory, Matthew Ho+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- LLMは推論時に外部メモリを活用し、概念レベルのメモリを導入することで、再利用可能でスケーラブルな知識の保存を実現。これにより、関連する概念を選択的に取得し、テスト時の継続的学習を可能にする。評価はARC-AGIベンチマークで行い、メモリなしのベースラインに対して7.5%の性能向上を達成。動的なメモリ更新が自己改善を促進することを示唆。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1977388895739535686?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>ARC-AGIでしか評価されていないように見える。</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/IdeaGeneration.html" target="_blank" rel="noopener noreferrer">#IdeaGeneration</a>
<span class="issue_date">Issue Date: 2025-10-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3224" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GUIDE: Towards Scalable Advising for Research Ideas, Yaowenqi Liu+, arXiv'25, 2025.07</a>
<span class="snippet"><span>GPT Summary</span>- AI研究の進展に伴い、自動化された仮説生成や実験設計が可能になっているが、高品質なフィードバックを提供するアドバイジングシステムには依然として課題がある。本研究では、モデルのサイズや信頼度の推定など、効果的なアドバイジングシステムの要因を探求し、比較的小さなモデルが圧縮された文献データベースと構造化された推論フレームワークを用いることで、強力な言語モデルを上回る受理率を達成できることを示した。特に、高信頼度の予測において90%以上の受理率を達成し、仮説生成と実験設計の質を向上させる可能性を示唆している。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://howardliu0830.github.io/GUIDE_blog/" target="_blank" rel="noopener noreferrer">https://howardliu0830.github.io/GUIDE_blog/</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/youjiaxuan/status/1976354596017799684?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>どのように評価したのだろうか</p>
<p>pj pageによると、ICMLのsubmissionのうちランダムな1000件を用いて、モデルにpaperをスコアリングさせる。そして、モデルがスコアリングした中で上位5%（spotlightの割合に相当）、30%のprecision（実際のacceptanceの閾値相当の割合）と、モデルがスコアリングした上位30パーセントの論文の現代のAcceptanceに対するRecallを求めて評価している模様。7Bモデルでより大きいモデルと同等程度の性能を示している。<br><br>手法は後ほど追記したいが、Acceptを予測ふるタスクは論文に対して適切なフィードバックできることに直接的には繋がらないのでは？と思い、inferenceのpromptを見てみると、LLMにabst, contribution, method, experimental setupを入力し、実際の査読と似たような評価をさせ、その結果に基づいてratingをpredictionするような形式に見える。このため、rating predictionの過程で評価結果のフィードバックが生成されるので、論文の改善ができる、というユースケースだと思われる。<br><br><img src="https://github.com/user-attachments/assets/5732eea8-744f-4072-89b2-6ad095b9d1d2" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3213" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Better Together: Leveraging Unpaired Multimodal Data for Stronger  Unimodal Models, Sharut Gupta+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- UML（Unpaired Multimodal Learner）を提案し、非ペアのマルチモーダルデータを活用して表現学習を強化する新しいトレーニングパラダイムを示す。異なるモダリティからの入力を交互に処理し、明示的なペアを必要とせずにクロスモーダル構造から利益を得る。実験により、テキスト、音声、画像などの非ペアデータを用いることで、単一モダルターゲットのパフォーマンスが向上することを確認。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://unpaired-multimodal.github.io" target="_blank" rel="noopener noreferrer">https://unpaired-multimodal.github.io</a>


</p>
<p>モダリティ間で（モダリティごとのエンコーダとデコーダ以外の）パラメータを共有し（UMMs)、通常はpair-dataで学習するが、unpaired data（+self-supervised / 分類ヘッドを用いた（ここはしっかり読めてないので自信ない）supervised learning)で学習する。これによりダウンストリームタスクでの性能が向上する。<br><br>unpaired dataで学習するという点が革新的に見える。unpaired dataで学習する枠組みにより大量のデータを活用し表現を学習できる。また、ペアデータで学習することによりパラメータに埋め込める知識やスキルが（おそらく）限られていたが、より広範な知識やスキルを埋め込めるのでは、という印象がある。</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1976587835370303918?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>著者ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sharut_gupta/status/1976642327587483785?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3178" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generative Representational Instruction Tuning, Niklas Muennighoff+, ICLR'25, 2024.02</a>
<span class="snippet"><span>GPT Summary</span>- 生成的表現指示チューニング（GRIT）を用いて、大規模言語モデルが生成タスクと埋め込みタスクを同時に処理できる手法を提案。GritLM 7BはMTEBで新たな最先端を達成し、GritLM 8x7Bはすべてのオープン生成モデルを上回る性能を示す。GRITは生成データと埋め込みデータの統合による性能損失がなく、RAGを60%以上高速化する利点もある。モデルは公開されている。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=BC4lIvfSzv" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=BC4lIvfSzv</a>


</p>
<p>従来はgemerativeタスクとembeddingタスクは別々にモデリングされていたが、それを統一的な枠組みで実施し、両方のタスクで同等のモデルサイズの他モデルと比較して高い性能を達成した研究。従来のgenerativeタスク用のnext-token-prediction lossとembeddingタスク用のconstastive lossを組み合わせて学習する（式3）。タスクの区別はinstructionにより実施し、embeddingタスクの場合はすべてのトークンのlast hidden stateのmean poolingでrepresentationを取得する。また、embeddingの時はbi-directional attention / generativeタスクの時はcausal maskが適用される。これらのattentionの適用のされ方の違いが、どのように管理されるかはまだしっかり読めていないのでよくわかっていないが、非常に興味深い研究である。<br><br>&lt;img width="603" height="349" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/acb2cbcd-364d-43c7-b51a-6c5ea9866415"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/acb2cbcd-364d-43c7-b51a-6c5ea9866415"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/Editing.html" target="_blank" rel="noopener noreferrer">#Editing</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3165" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] D3: A Dataset for Training Code LMs to Act Diff-by-Diff, Piterbarg+, COLM'25</a>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=sy71y74U80#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=sy71y74U80#discussion</a>


</p>
<p>openreviewのサマリによると、8B tokens, 850k python filesのデータセットで、コーディングタスクを、ゴールで条件づけられたsequential editsタスクとみなし The Stack上のコードを分析ツールとLLMによって合成されたrationaleによってフィルタリング/拡張したデータを提供しているとのこと。具体的には (state, goal, action_i) の3つ組みのデータセットであり、action_iがaction前後でのdiffになっている模様。D3データセットでSFTの前にLlama 1B / 3Bをmid-trainingした結果、downstreamタスク（コード生成、completion、編集）において性能が向上したとのこと。<br><br>&lt;img width="865" height="348" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/d99b5ee6-dbc8-48f7-9b68-880add54dbbb"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/d99b5ee6-dbc8-48f7-9b68-880add54dbbb"&lt;/a&gt;


/&gt;<br></p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3156" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Synthetic Data Generation &amp; Multi-Step RL for Reasoning &amp; Tool Use, Anna Goldie+, COLM'25, 2025.04</a>
<span class="snippet"><span>GPT Summary</span>- 段階的強化学習（SWiRL）を提案し、複数のテキスト生成や推論ステップを通じて大規模言語モデルの性能を向上させる手法を紹介。SWiRLは、各アクションに対するサブ軌道を生成し、合成データフィルタリングと強化学習最適化を適用。実験では、GSM8KやHotPotQAなどのタスクでベースラインを上回る精度を達成し、タスク間での一般化も示された。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=oN9STRYQVa" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=oN9STRYQVa</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stanfordnlp/status/1975574899428139413?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>従来のRLではテキスト生成を1ステップとして扱うことが多いが、複雑な推論やtool useを伴うタスクにおいては複数ステップでの最適化が必要となる。そのために、多段階の推論ステップのtrajectoryを含むデータを作成し、同データを使いRLすることによって性能が向上したという話な模様。RLをする際には、stepごとにRewardを用意するようである。また、現在のstepの生成を実施する際には過去のstepの情報に基づいて生成する方式のようである。</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/UserModeling.html" target="_blank" rel="noopener noreferrer">#UserModeling</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/UserBased.html" target="_blank" rel="noopener noreferrer">#UserBased</a>
<a class="button" href="articles/AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3154" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Impatient Users Confuse AI Agents: High-fidelity Simulations of Human  Traits for Testing Agents, Muyu He+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- TraitBasisを用いて、会話型AIエージェントの堅牢性を体系的にテストする手法を提案。ユーザーの特性（せっかちさや一貫性のなさ）を制御し、AIエージェントのパフォーマンス低下を観察。最前線のモデルで2%-30%の性能低下を確認し、現在のAIエージェントの脆弱性を示す。TraitBasisはシンプルでデータ効率が高く、現実の人間の相互作用における信頼性向上に寄与する。$\tau$-Traitをオープンソース化し、コミュニティが多様なシナリオでエージェントを評価できるようにした。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hemuyu0327/status/1975398313735389254?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>実際の人間にあるような癖（のような摂動）を与えた時にどれだけロバストかというのは実応用上非常に重要な観点だと思われる。元ポストを見ると、LLM内部のmatmulを直接操作することで、任意のレベルの人間の特性（e.g.,疑い深い、混乱、焦りなど）を模倣する模様。</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3151" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Magistral, Mistral-AI+, arXiv'25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- Mistralの推論モデルMagistralと独自の強化学習パイプラインを紹介。ゼロからのアプローチで、LLMのRLトレーニングの限界を探り、テキストデータのみでのRLが能力を維持することを示す。Magistral MediumはRLのみで訓練され、Magistral Smallはオープンソース化。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nrehiew_/status/1974856956600111250?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2858" target="_blank" rel="noopener noreferrer">Magistral-Small-2509, MistralAI, 2025.09</a>
</p>
<p>MistralAIの初めてのreasoningモデル</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/CurriculumLearning.html" target="_blank" rel="noopener noreferrer">#CurriculumLearning</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3112" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Prompt Curriculum Learning for Efficient LLM Post-Training, Zhaolin Gao+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Prompt Curriculum Learning (PCL)を提案し、中程度の難易度のプロンプトを選択してLLMをポストトレーニングする軽量な強化学習アルゴリズムを紹介。最適なバッチサイズとプロンプト選択の重要性を実験で確認し、PCLは情報豊富なプロンプトに焦点を当てることで高いパフォーマンスを達成。ロールアウトを回避し、MATHおよびDeepScaleRでそれぞれ$12.1\times$および$16.9\times$の速度向上を実現。結果は、推論におけるRLの効率とパフォーマンスのトレードオフを改善する新たな方法論を示す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yzpang_/status/1974180214608703795?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>（ざっくり読みなので誤りを多分に含むかもしれないがメモ）勾配のノイズの低減と生成の速度のトレードオフを最適にバランスをとるバッチサイズがあることを示し、RLの学習効率が中間程度（簡単すぎず、難しすぎない）の難易度が良いことを示したのち、Valueモデル（ロールアウトに基づいて更新される模様？）を用いてpromptを選択し[^1]中間程度のpromptを用いてロールアウトをし学習するようなオンポリシーのRLを提案する、みたいな話な模様。<br><br>[^1]:既存手法のロールアウトによって求める方法（計算コストが高すぎる）や、事前に決めておいた辞書ベースの手法（現在のポリシーからみた時の難易度が反映されておらず効率が悪い）の双方に比べて、適度にオンポリシーさを残したpromptの選び方となっている</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3106" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Large Reasoning Models Learn Better Alignment from Flawed Thinking, ShengYun Peng+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- RECAPは、誤った推論を覆し安全な応答に導くための強化学習手法。合成生成された反対整合CoTを用いて訓練し、安全性と堅牢性を向上させる。RECAPで訓練されたモデルは自己反省が頻繁で、適応攻撃にも強い。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haozhu_wang/status/1974142611071144024?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>安全でない（欠陥のある）Reasoning traceを修復するような学習をさせることでよりロバストなsafety algnmentが実現できます、といった話な模様</p>
<p>著者ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jianfengchi/status/1973944383696519403?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3105" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal  Training, Xiang An+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- LLaVA-OneVision-1.5は、計算コストと財政コストを削減しつつ最先端のパフォーマンスを実現する新しい大規模マルチモーダルモデルです。オープンで効率的なフレームワークを提供し、85Mの事前学習データセットと26Mの指示データセットを含む大規模キュレーションデータセットを構築しました。効率的なトレーニングフレームワークにより、限られた予算内でのトレーニングが可能となり、幅広い下流タスクで競争力のある性能を示しています。特に、LLaVA-OneVision-1.5-8Bは18のベンチマークでQwen2.5-VL-7Bを上回り、4Bモデルは全ての27のベンチマークでQwen2.5-VL-3Bを超えています。今後、LLaVA-OneVision-1.5-RLのリリースも予定されています。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xiyaowang10/status/1973887115781140598?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>各種ベンチでQwen2.5-VL超え</p>
<p>pj page:


<a href="https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5" target="_blank" rel="noopener noreferrer">https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5</a>


</p>
<p>ポイント解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1974632456348385583?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/ReplayBuffer.html" target="_blank" rel="noopener noreferrer">#ReplayBuffer</a>
<a class="button" href="articles/TreeSearch.html" target="_blank" rel="noopener noreferrer">#TreeSearch</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3103" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DeepSearch: Overcome the Bottleneck of Reinforcement Learning with  Verifiable Rewards via Monte Carlo Tree Search, Fang Wu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- DeepSearchは、RLVRトレーニングにMonte Carlo Tree Searchを統合し、体系的な探索を可能にするフレームワーク。これにより、限られたロールアウトに依存せず、重要な推論経路を見逃さない。実験では、62.95%の平均精度を達成し、1.5B推論モデルで新たな最先端を確立。戦略的な探索の重要性を示し、RLVR手法の進展に向けた新たな方向性を提供。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1973827122415513675?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>最近はRL時の探索空間を増やす取り組みが増えてきているように感じる。<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3104" target="_blank" rel="noopener noreferrer">Replay BufferがPolicy Gradientで使えない理由, piqcy, 2019.03</a>
<br><br>にもあるように基本的にオンポリシーRLではリプレイバッファを使えないので何らかの工夫が必要、といった話があるが、この研究ではGRPOを前提としつつリプレイバッファを活用する枠組みとなっているようなので、どのような工夫が行われているのだろうか。勉強したい。</p>
<p>所見と解説:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/max_paperclips/status/1974011545425228238?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<a class="button" href="articles/PhaseTransition.html" target="_blank" rel="noopener noreferrer">#PhaseTransition</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3088" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Demystifying Synthetic Data in LLM Pre-training: A Systematic Study of  Scaling Laws, Benefits, and Pitfalls, Feiyang Kang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- 合成データ技術はLLMのトレーニングデータの供給制限を克服する可能性を持つ。本研究では、自然なウェブデータと合成データの混合を比較し、言い換えた合成データのみでの事前トレーニングは自然なデータよりも速くないことを示した。1/3の言い換えた合成データと2/3の自然データの混合が、より効率的なトレーニングを可能にすることが分かった。教科書スタイルの合成データは小さなデータ予算で高い損失をもたらし、合成データの最適な比率はモデルサイズとデータ予算に依存する。結果は合成データの効果を明らかにし、実用的なガイダンスを提供する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/papers_anon/status/1973939270747668698?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>ポイント解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1974108247003934902?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>合成データは適切な規模のモデルと比率でないと利点が現れない</p>
<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3101" target="_blank" rel="noopener noreferrer">[Paper Note] Data Mixing Can Induce Phase Transitions in Knowledge Acquisition, Xinran Gu+, arXiv'25, 2025.05</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3084" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MENLO: From Preferences to Proficiency -- Evaluating and Modeling  Native-like Quality Across 47 Languages, Chenxi Whitehouse+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- MENLOフレームワークを用いて、47言語の6,423のプロンプト-応答ペアのデータセットを作成し、LLMの応答品質を評価。ゼロショット評価者はペアワイズ評価から利益を得るが、人間には及ばず。強化学習によるファインチューニングで改善を示し、RL訓練評価者がLLMの多言語能力向上に寄与することを確認。ただし、人間の判断との不一致は残る。データセットと評価フレームワークを公開し、多言語LLM評価の研究を支援。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/seb_ruder/status/1973412580191285640?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>LLMの応答を多言語でよりnativeに近いものにするための取り組み、および評価のフレームワーク（MENLO, データセット含む）な模様。nativeらしさを測るために重要な次元としてFluency, Tone, Localized Tone, Localized Factualityと呼ばれる軸を定義している模様。その上で47言語における6423の人手でアノテーションされたpreference dataを作成し評価をしたところ、既存のLLM-as-a-judgeやSFT/RLされたReward Modelでは、人間による評価にはまだまだ及ばないことが明らかになり、MENLOを用いてRL/SFTすることでLLM JudgeやReward Modelの性能を改善できる、といった話な模様。<br><br>4つの次元については以下の表を参照のこと。<br>それぞれ<br>- Fluency: 専門家レベルのnative speakerと比較した時のproficiency<br>- Tone: 全体的なwriting stvleや語り口<br>- Localized Tone: 文化的、地域的な言葉のニュアンス<br>- Localized Factuality: 地域固有のコンテキストに沿った事実性や網羅性<br><br><img src="https://github.com/user-attachments/assets/2e57edb7-a2f0-4570-a723-53c22ac22036" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/UserModeling.html" target="_blank" rel="noopener noreferrer">#UserModeling</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/UserBased.html" target="_blank" rel="noopener noreferrer">#UserBased</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3082" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Personalized Reasoning: Just-In-Time Personalization and Why LLMs Fail  At It, Shuyue Stella Li+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- 現在のLLMは、タスク解決とユーザーの好みの整合性を別々に扱っており、特にジャストインタイムのシナリオでは効果的ではない。ユーザーの好みを引き出し、応答を適応させる「パーソナライズド推論」が必要である。新たに提案された評価手法「PREFDISCO」は、ユーザーのコンテキストに応じた異なる推論チェーンを生成し、パーソナライズの重要性を示す。評価結果から、単純なパーソナライズが一般的な応答よりも劣ることが明らかになり、専用の開発が必要であることが示唆された。PREFDISCOは、教育や医療などの分野でのパーソナライズの重要性を強調する基盤を提供する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stellalisy/status/1973764628632281271?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>ざーっとしか読めていないのが、ユーザから与えられたタスクとマルチターンの会話の履歴に基づいて、LLM側が質問を投げかけて、Personalizationに必要なattributeを取得する。つまり、ユーザプロファイルは (attribute, value, weight)のタプルによって構成され、この情報に基づいて生成がユーザプロファイルにalignするように生成する、といった話に見える。膨大なとりうるattributeの中から、ユーザのタスクとcontextに合わせてどのattributeに関する情報を取得するかが鍵となると思われる。また、セッション中でユーザプロファイルを更新し、保持はしない前提な話に見えるので、Personalizationのカテゴリとしては一時的個人化に相当すると思われる。<br>Personalizationの研究は評価が非常に難しいので、どのような評価をしているかは注意して読んだ方が良いと思われる。<br>&lt;img width="1003" height="567" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/3d411a63-f8de-4267-b6c0-edfe3143d4ac"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/3d411a63-f8de-4267-b6c0-edfe3143d4ac"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<a class="button" href="articles/Editing.html" target="_blank" rel="noopener noreferrer">#Editing</a>
<span class="issue_date">Issue Date: 2025-10-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3073" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] EditReward: A Human-Aligned Reward Model for Instruction-Guided Image  Editing, Keming Wu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- 自然言語指示による画像編集の進展において、オープンソースモデルは遅れをとっている。これを解決するために、20万以上の選好ペアを含む新しいデータセット\mnameを構築し、指示に基づく画像編集タスクで人間の選好と高い整合性を示した。実験では、\mnameが既存のベンチマークで最先端の人間相関を達成し、ノイズの多いデータセットから高品質なサブセットを選択することで、画像編集モデルの性能を大幅に向上させることができた。今後、\mnameはコミュニティに公開され、高品質な画像編集トレーニングデータセットの構築を支援する予定である。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://tiger-ai-lab.github.io/EditReward/" target="_blank" rel="noopener noreferrer">https://tiger-ai-lab.github.io/EditReward/</a>


<br>HF:


<a href="https://huggingface.co/collections/TIGER-Lab/editreward-68ddf026ef9eb1510458abc6" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/TIGER-Lab/editreward-68ddf026ef9eb1510458abc6</a>


</p>
<p>これまでのImageEditing用のデータセットは、弱いReward Modelによって合成されるか、GPT-4oや他のVLMによる品質の低いフィルタリングにより生成されており、高品質なデータセットが存在しない課題があった。これを解決するために大規模なImageEditingの嗜好データを収集し、ImageEditingに特化した報酬モデルであるEditRewardを学習。このモデルは人間の専門家とのagreementにおいて高い(というよりりbestと書いてある）agreementを示し、実際にEditRewardによって既存のデータセットをfilteringして学習したら大きなgainがあったよ、という感じらしい。</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<a class="button" href="articles/Test-time%20Learning.html" target="_blank" rel="noopener noreferrer">#Test-time Learning</a>
<span class="issue_date">Issue Date: 2025-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3041" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory, Siru Ouyang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- ReasoningBankという新しいメモリフレームワークを提案し、エージェントが成功体験と失敗体験から推論戦略を抽出できるようにする。テスト時には関連メモリを活用し、学びを統合することで能力を向上させる。さらに、メモリを意識したテスト時スケーリング（MaTTS）を導入し、エージェントの体験を多様化・拡大する。これにより、ウェブブラウジングやソフトウェアエンジニアリングのベンチマークで既存のメモリメカニズムを上回る効果と効率を実現。メモリ駆動の経験スケーリングを新たな次元として確立し、エージェントの自己進化を促進する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1972870229463355677?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>メモリを良質なものに更新、蓄積し続けることで性能がスケールするのであれば、新たなtest-time scalingのパラダイムになりそう。<br><br>と思ったがざっくり読んでみると本研究ではこのパラダイムのことをTest-Time Learningと呼称している（先行研究が２つ引用されているがざっと見た限りでは両者はそう言った呼称はしていないように見えた）。<br>すなわち、クエリのストリームが到達した時に将来のクエリを見ることはできずに、過去のクエリに対するtrajectoryや、self-verificationなどによってのみラベル無しで自己進化していくパラダイムのこと。</p>
<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3052" target="_blank" rel="noopener noreferrer">[Paper Note] M+: Extending MemoryLLM with Scalable Long-Term Memory, Yu Wang+, ICML'25, 2025.02</a>
</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/interactive.html" target="_blank" rel="noopener noreferrer">#interactive</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3021" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Interactive Recommendation Agent with Active User Commands, Jiakai Tang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- 従来のレコメンダーシステムは受動的なフィードバックに依存し、ユーザーの意図を捉えられないため、嗜好モデルの構築が困難である。これに対処するため、インタラクティブレコメンデーションフィード（IRF）を導入し、自然言語コマンドによる能動的な制御を可能にする。RecBotという二重エージェントアーキテクチャを開発し、ユーザーの嗜好を構造化し、ポリシー調整を行う。シミュレーション強化知識蒸留を用いて効率的なパフォーマンスを実現し、実験によりユーザー満足度とビジネス成果の改善を示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1972370522248745122?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>ABテストを実施しているようなので信ぴょう性高め</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2937" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ARE: Scaling Up Agent Environments and Evaluations, Pierre Andrews+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- Meta Agents Research Environments (ARE)を紹介し、エージェントのオーケストレーションや環境のスケーラブルな作成を支援するプラットフォームを提供。Gaia2というベンチマークを提案し、エージェントの能力を測定するために設計され、動的環境への適応や他のエージェントとの協力を要求。Gaia2は非同期で実行され、新たな失敗モードを明らかにする。実験結果は、知能のスペクトル全体での支配的なシステムが存在しないことを示し、AREの抽象化が新しいベンチマークの迅速な作成を可能にすることを強調。AIの進展は、意味のあるタスクと堅牢な評価に依存する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/froger_romain/status/1970120373829066982?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>GAIAはこちら:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1158" target="_blank" rel="noopener noreferrer">GAIA: a benchmark for General AI Assistants, Grégoire Mialon+, N/A, arXiv'23</a>
</p>
<p>Execution, Search, Ambiguity, Adaptability, Time, Noise, Agent2Agentの6つのcapabilityを評価可能。興味深い。</p>
<p>現状、全体的にはGPT-5(high)の性能が最も良く、続いてClaude-4 Sonnetという感じに見える。OpenWeightなモデルでは、Kimi-K2の性能が高く、続いてQwen3-235Bという感じに見える。また、Figure1はbudgetごとのモデルの性能も示されている。シナリオ単位のbudgetが$1以上の場合はGPT-5(high)の性能が最も良いが、$0.1--$0.4の間ではKiml-K2の性能が最も良いように見える。<br><img src="https://github.com/user-attachments/assets/039a6e69-4941-4a80-99b3-0590d1446030" alt="image" loading="lazy"></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2406" target="_blank" rel="noopener noreferrer">[Paper Note] GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models, GLM-4. 5 Team+, arXiv'25</a>
<br><br>しっかりと読めていないがGLM-4.5は含まれていないように見える。</p>
<p>ポイント解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1970162732470067283?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/VariationalAutoEncoder.html" target="_blank" rel="noopener noreferrer">#VariationalAutoEncoder</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2870" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self Forcing: Bridging the Train-Test Gap in Autoregressive Video   Diffusion, Xun Huang+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- Self Forcingは、自動回帰型ビデオ拡散モデルの新しいトレーニング手法で、エクスポージャーバイアスの問題に対処します。従来の手法が真のコンテキストに基づくのに対し、Self Forcingは自己生成した出力に基づいてフレームを生成し、全体の品質を評価するホリスティックな損失を用います。計算コストとパフォーマンスのバランスを取るために、少数ステップの拡散モデルと確率的勾配切断を採用し、ロールイングKVキャッシュメカニズムを導入。実験により、リアルタイムのストリーミングビデオ生成が可能で、非因果的拡散モデルの生成品質に匹敵またはそれを上回ることが示されました。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://self-forcing.github.io" target="_blank" rel="noopener noreferrer">https://self-forcing.github.io</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xunhuang1995/status/1968797718593098087?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>自己回帰的な動画生成（をする）モデルにおいて、学習時はground-truchのcontextが利用して学習されるが、推論時は自身が生成結果そのものをcontextとして利用するため、学習-推論時にgapが生じ、（徐々に誤差が蓄積することで）品質が劣化するという問題（exposure bias）に対処するために、学習時から自身が生成した出力をcontextとして与えて生成を行い（ロールアウト）、動画全体に対して分布の整合性を測るlossを導入（=フレーム単位の誤差を最小化にするのではなく、動画全体に対して（分布の）誤差を最適化する）することで、exposure biasを軽減する、という話な模様。</p>
<p>結果的に、単一のRTX4090でリアルタイムのストリーミングビデオ生成が高品質に生成可能となった（かもしれない）:<br>


<a href="https://note.com/ngc_shj/n/n505b2f7cdfe4" target="_blank" rel="noopener noreferrer">https://note.com/ngc_shj/n/n505b2f7cdfe4</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2753" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Parallel-R1: Towards Parallel Thinking via Reinforcement Learning, Tong Zheng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Parallel-R1は、複雑な推論タスクに対して並列思考を可能にする強化学習フレームワークであり、コールドスタート問題に対処するための進行的なカリキュラムを採用。簡単なタスクから始め、並列思考能力を植え付けた後、難しい問題に移行。実験により、従来の逐次思考モデルに対して8.4%の精度向上を達成し、並列思考が中間トレーニング探索の足場として機能することを示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1965631715235525006?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>結果の表を見るとベースモデルで単にself Consistencyを実施するよりも高いゲインを得ているように見える。モデルがQwen3のみでしか実験されておらず、Qwen2.5においてコンタミネーションの疑い <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2226" target="_blank" rel="noopener noreferrer">[Paper Note] Reasoning or Memorization? Unreliable Results of Reinforcement Learning  Due to Data Contamination, Mingqi Wu+, arXiv'25</a>
 があったので、(Qwen3がどうかはわからないが)単一モデルではなく、他のモデルでも実験した方が良いのかな、という印象。</p>
<p>ポイント解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1965691174813089987?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>ポイント解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1968939351427158459?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>コードがリリース:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wyu_nd/status/1976011651758588165?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2192" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Small Batch Size Training for Language Models: When Vanilla SGD Works,  and Why Gradient Accumulation Is Wasteful, Martin Marek+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- 小さなバッチサイズに対するAdamのハイパーパラメータをスケーリングする新しいルールを提案。これにより、小さなバッチサイズでも安定したトレーニングが可能で、大きなバッチサイズと同等以上のパフォーマンスを達成。勾配蓄積は推奨せず、実用的なハイパーパラメータ設定のガイドラインを提供。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/giffmana/status/1943384733418950815?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>論文中のFigure1において、AdamWにおいてbatchsizeが1の方が512の場合と比べてlearning_rateの変化に対してロバストである旨が記述されている。<br><br>&lt;img width="977" height="642" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/0c1efb5d-6eeb-4fd7-ba06-e4296e988a6c"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0c1efb5d-6eeb-4fd7-ba06-e4296e988a6c"&lt;/a&gt;


/&gt;<p>似たような話でMTでバッチサイズ小さいほうが性能良いです、みたいな話が昔あったような<br><br>（追記）<br>気になって思い出そうとしていたが、MTではなく画像認識の話だったかもしれない（だいぶうろ覚え）<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2196" target="_blank" rel="noopener noreferrer">[Paper Note] Revisiting Small Batch Training for Deep Neural Networks, Dominic Masters+, arXiv'18</a>
 </p>
<p>参考:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1944034128707342815?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1541" target="_blank" rel="noopener noreferrer">How Does Critical Batch Size Scale in Pre-training?, Hanlin Zhang+, ICLR'25</a>
</p>
<p>解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1952506470878351492?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>実際に8Bモデルの事前学習においてβ2を0.99にしたところ、学習が不安定になり、かつ最終的なPerplexityも他の設定に勝つことができなかったとのこと:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1955906705637957995?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2131" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Curse of Depth in Large Language Models, Wenfang Sun+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- 本論文では、「深さの呪い」という現象を紹介し、LLMの深い層が期待通りに機能しない理由を分析します。Pre-LNの使用が出力の分散を増加させ、深い層の貢献を低下させることを特定。これを解決するために層正規化スケーリング（LNS）を提案し、出力分散の爆発を抑制します。実験により、LNSがLLMの事前トレーニング性能を向上させることを示し、教師ありファインチューニングにも効果があることを確認しました。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shiwei_liu66/status/1940377801032446428?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1795" target="_blank" rel="noopener noreferrer">Transformers without Normalization, Jiachen Zhu+, CVPR'25</a>
<br><br>ではそもそもLayerNormalizationを無くしていた（正確にいうとparametrize tanhに置換)が、どちらが優れているのだろうか？<br><br><img src="https://github.com/user-attachments/assets/4bc557a0-ae23-4017-9837-7744de74c12e" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/2eead45c-209d-46e4-87e7-0129a4ec5ec2" alt="image" loading="lazy"></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1332" target="_blank" rel="noopener noreferrer">Knowledge Neurons in Pretrained Transformers, Damai Dai+, N/A, ACL'22, 2022.05</a>
<br><br>では知識ニューロンの存在が示唆されており、これはTransformerの層の深い位置に存在し、かつ異なる知識間で知識ニューロンはシェアされない傾向にあった（ただしこれはPost-LNのBERTの話で本研究はPre-LNの話だが。Post-LNの勾配消失問題を緩和し学習を安定化させる研究も<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2141" target="_blank" rel="noopener noreferrer">[Paper Note] On Layer Normalizations and Residual Connections in Transformers, Sho Takase+, arXiv'22</a>
 のように存在する)。これはこの研究が明らかにしたこととどういう関係性があるだろうか。<br><br>また、LayerNormalizationのScalingによって深いTransformerブロックの導関数が単位行列となる（学習に寄与しなくなる）ことが改善された場合、知識ニューロンはどのように変化するだろうか？<br><br>（下記Geminiの応答を見た上での感想)なんとなーくだけれども、おそらく知識ニューロンの局所化が解消されるのかなーという気がする。<br><br>となると次の疑問としては、MoEアーキテクチャにはどのような影響があるだろうか？<br>そもそも知識ニューロンが局所化しているからMoEアーキテクチャのルータによって関連するExpertsのみをactivateすれば（というより結果的にそうなるように学習される）性能を劣化させずに計算効率を上げられていた、と仮定する。そうすると、知識ニューロンが局所化せずに多くのニューロンでシェアされるようになると、<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2110" target="_blank" rel="noopener noreferrer">[Paper Note] Chain-of-Experts: Unlocking the Communication Power of  Mixture-of-Experts Models, Zihan Wang+, arXiv'25</a>
 のように、サブネットワーク間の情報を互いにやりとりできます、みたいな仕組みがより効いてきそうな気がする。<br><br>参考までに、Gemini2.5-Proに考察させてみた結果をメモとして残しておく（あくまで参考程度に...）<br>```<br>ご質問ありがとうございます。非常に興味深い着眼点ですね。「Knowledge Neurons in Pretrained Transformers」と「The Curse of Depth in Large Language Models」は、一見すると全く異なるテーマを扱っているように見えますが、**「Transformerの深い層における振る舞い」**という共通点で結びつけて考察すると、非常に示唆に富んだ関係性が見えてきます。<br><br>以下に、両方の論文の概要を解説し、その関係性について考察します。<br><br>1. Knowledge Neurons in Pretrained Transformers の概要<br>この研究は、事前学習済みTransformerモデル（特にBERTなど）の内部で、特定の事実知識がどのように格納されているかを調査したものです。<br><br>発見: モデルの中間層、特に**全結合層（Feed-Forward Network, FFN）に、特定の知識（例：「ダンテ・アリギエーリはイタリアで生まれた」）に強く反応する「知識ニューロン」**が存在することを発見しました。<br><br>特徴: これらの知識ニューロンは、モデルの深い層（後方の層）に、より多く存在する傾向がありました。<br><br>意味: これまでブラックボックスとされてきた大規模言語モデルの内部で、知識がどのように表現・局在化しているかについて、具体的な手がかりを与えた画期的な研究です。<br><br>2. The Curse of Depth in Large Language Models の概要<br>この研究は、LLMをより深く（層を多く）することの難しさに焦点を当て、その原因と解決策を提案したものです。<br><br>問題（深さの呪い）: Transformerの標準的なアーキテクチャ（Pre-LN）では、層が深くなるにつれて、LayerNormalization（LN）への入力の分散が指数関数的に増大してしまいます。<br><br>結果:<br><br>出力が大きくなりすぎて学習が不安定になります。<br><br>さらに深刻なのは、深い層ではモデルの出力に関する導関数（勾配計算に必要）がほぼ単位行列になってしまうことです。これは、その層が入力に対してほとんど変換を行わなくなり、学習に寄与しなくなることを意味します。<br><br>解決策: この問題を解決するため、各層のLayerNormalizationをその深さ（レイヤー番号 l）に応じてスケーリングするというシンプルな手法を提案しました。これにより、深い層でも勾配が適切に伝播し、学習が安定・改善することが示されました。<br><br>考察：2つの研究の関係性<br>これら2つの研究は、**「学習の安定性」と「知識の格納方法」**という異なる側面から、Transformerの深い層を分析していますが、両者には以下のような深い関係性があると考えられます。<br><br>学習の不安定性が「知識ニューロン」形成の背景にある可能性<br>「The Curse of Depth」で指摘されているように、標準的なTransformerの深い層は、本質的に学習が不安定で、勾配情報が失われやすい環境にあります。<br><br>この劣悪な学習環境こそが、「知識ニューロン」という形で知識が局所的に格納される原因の一つになっている可能性があります。つまり、<br><br>学習の非効率性: 深い層のほとんどのニューロンは、勾配消失問題のために効率的に学習を進めることができません。<br><br>専門化の発生: そのような不安定な環境下で、たまたま特定の知識パターンをうまく捉えることができた一部のニューロンが、その知識を一身に背負う形で強く活性化するよう特化（専門化）していったのではないか、と考えられます。これは、ネットワーク全体で協調して学習するのが難しい状況で、一部のユニットだけが突出して学習を担う、という現象と解釈できます。<br><br>学習の安定化が、より効率的な知識獲得につながる<br>では、「The Curse of Depth」で提案された手法（LNのスケーリング）によって深い層の学習が安定化すると、知識の格納方法はどのように変わるでしょうか。<br><br>これは非常に興味深い問いであり、2つの可能性が考えられます。<br><br>可能性A: より強固な知識ニューロンの形成:<br>学習が安定することで、各知識ニューロンはより明確に、そして効率的に特定の知識をエンコードできるようになるかもしれません。ノイズの多い環境で偶然生まれた専門家ではなく、安定した環境で育成された真の専門家へと変化するイメージです。<br><br>可能性B: 知識の分散化:<br>ネットワークの全ニューロンが効率的に学習に寄与できるようになるため、一つの知識を少数のニューロンに集中させる必要がなくなり、より多くのニューロンに分散して知識が格納されるようになる可能性も考えられます。<br><br>現在のところ、学習の安定化は、知識ニューロンがより効率的に形成・機能するための基盤を提供すると考えるのが最も妥当でしょう。「深さの呪い」という問題を解決することは、モデルが知識をどのように獲得し、整理するかという、より根源的なメカニズム（知識ニューロンの振る舞い）にも直接的な影響を与えるはずです。<br><br>まとめ<br>「Knowledge Neurons」は深い層に存在する知識の**「状態」を明らかにし、「The Curse of Depth」は深い層で発生する学習の「問題」**とその解決策を提示しました。<br><br>これらを統合すると、**「深い層における学習の不安定性という問題が、知識ニューロンという局所的な知識表現を生み出す一因となっており、この問題を解決することで、より効率的で安定した知識の獲得・格納が可能になるかもしれない」**という関係性が見えてきます。<br><br>両者は、LLMの能力と限界を異なる角度から照らし出しており、組み合わせることでモデルの内部動作の解明をさらに一歩前進させる、非常に重要な研究だと言えます。<br>```</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-04-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1908" target="_blank" rel="noopener noreferrer" class="title-link">Safety Alignment Should Be Made More Than Just a Few Tokens Deep, Xiangyu Qi+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- 現在の大規模言語モデル（LLMs）の安全性アラインメントは脆弱であり、単純な攻撃や善意のファインチューニングによって脱獄される可能性がある。この脆弱性は「浅い安全性アラインメント」に起因し、アラインメントが主に最初の数トークンの出力にのみ適応されることに関連している。本論文では、この問題のケーススタディを提示し、現在のアラインされたLLMsが直面する脆弱性を説明する。また、浅い安全性アラインメントの概念が脆弱性軽減の研究方向を示唆し、初期トークンを超えたアラインメントの深化がロバスト性を向上させる可能性を示す。最後に、ファインチューニング攻撃に対する持続的な安全性アラインメントを実現するための正則化されたファインチューニング目的を提案する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1917006979836612640?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=6Mxhg9PtDE" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=6Mxhg9PtDE</a>


</p>
<p>Safety Alignment手法が最初の数トークンに依存しているからそうならないように学習しますというのは、興味深いテーマだし技術的にまだ困難な点もあっただろうし、インパクトも大きいし、とても良い研究だ…。</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-03-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1815" target="_blank" rel="noopener noreferrer" class="title-link">DAPO: An Open-Source LLM Reinforcement Learning System at Scale, Qiying Yu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- 推論スケーリングによりLLMの推論能力が向上し、強化学習が複雑な推論を引き出す技術となる。しかし、最先端の技術詳細が隠されているため再現が難しい。そこで、$\textbf{DAPO}$アルゴリズムを提案し、Qwen2.5-32Bモデルを用いてAIME 2024で50ポイントを達成。成功のための4つの重要技術を公開し、トレーニングコードと処理済みデータセットをオープンソース化することで再現性を向上させ、今後の研究を支援する。</span>
<span class="snippet"><span>Comment</span><p>既存のreasoning modelのテクニカルレポートにおいて、スケーラブルなRLの学習で鍵となるレシピは隠されていると主張し、実際彼らのbaselineとしてGRPOを走らせたところ、DeepSeekから報告されているAIME2024での性能（47ポイント）よりもで　大幅に低い性能（30ポイント）しか到達できず、分析の結果3つの課題（entropy collapse, reward noise, training instability）を明らかにした（実際R1の結果を再現できない報告が多数報告されており、重要な訓練の詳細が隠されているとしている）。<br><br>その上で50%のtrainikg stepでDeepSeek-R1-Zero-Qwen-32Bと同等のAIME 2024での性能を達成できるDAPOを提案。そしてgapを埋めるためにオープンソース化するとのこと。</p>
<p>ちとこれはあとでしっかり読みたい。重要論文。</p>
<p>プロジェクトページ:


<a href="https://dapo-sia.github.io/" target="_blank" rel="noopener noreferrer">https://dapo-sia.github.io/</a>


<br><br>こちらにアルゴリズムの重要な部分の概要が説明されている。</p>
<p>解説ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1902507148015489385?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>コンパクトだが分かりやすくまとまっている。<p>下記ポストによると、Reward Scoreに多様性を持たせたい場合は3.2節参照とのこと。<br>すなわち、Dynamic Samplingの話で、Accが全ての生成で1.0あるいは0.0となるようなpromptを除外するといった方法の話だと思われる。<br>これは、あるpromptに対する全ての生成で正解/不正解になった場合、そのpromptに対するAdvantageが0となるため、ポリシーをupdateするためのgradientも0となる。そうすると、このサンプルはポリシーの更新に全く寄与しなくなるため、同バッチ内のノイズに対する頑健性が失われることになる。サンプル効率も低下する。特にAccが1.0になるようなpromptは学習が進むにつれて増加するため、バッチ内で学習に有効なpromptは減ることを意味し、gradientの分散の増加につながる、といったことらしい。<br><br>関連ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1936375947575632102?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>色々な研究で広く使われるのを見るようになった。</p>
<p>著者ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/qiying_yu/status/1902405115082104875?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<span class="issue_date">Issue Date: 2024-12-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1586" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Training Large Language Models to Reason in a Continuous Latent Space, Shibo Hao+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- 新しい推論パラダイム「Coconut」を提案し、LLMの隠れ状態を連続的思考として利用。これにより、次の入力を連続空間でフィードバックし、複数の推論タスクでLLMを強化。Coconutは幅優先探索を可能にし、特定の論理推論タスクでCoTを上回る性能を示す。潜在的推論の可能性を探る重要な洞察を提供。</span>
<span class="snippet"><span>Comment</span><p>Chain of Continuous Thought</p>
<p>通常のCoTはRationaleをトークン列で生成するが、Coconutは最終的なhidden stateをそのまま次ステップの入力にすることで、トークンに制限されずにCoTさせるということらしい。あとでしっかり読む<br><img src="https://github.com/user-attachments/assets/b930f44b-96f4-47cd-aa1a-0b5fabde54a5" alt="image" loading="lazy"></p>
<p>おそらく学習の際に工夫が必要なので既存モデルのデコーディングを工夫してできます系の話ではないかも</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=tG4SgayTtk" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=tG4SgayTtk</a>


<br><br>ICLR'25にrejectされている。<br>ざっと最初のレビューに書かれているWeaknessを読んだ感じ<br>- 評価データが合成データしかなく、よりrealisticなデータで評価した方が良い<br>- CoTら非常に一般的に適用可能な技術なので、もっと広範なデータで評価すべき<br>- GSM8Kでは大幅にCOCONUTはCoTに性能が負けていて、ProsQAでのみにしかCoTに勝てていない<br>- 特定のデータセットでの追加の学習が必要で、そこで身につけたreasoning能力が汎化可能か明らかでない<br><br>といった感じに見える</p>
<p>COLM'25 openreview:<br>


<a href="https://openreview.net/forum?id=Itxz7S4Ip3#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Itxz7S4Ip3#discussion</a>


<br><br>COLM'25にAccept</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<span class="issue_date">Issue Date: 2025-11-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3568" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] To Code, or Not To Code? Exploring Impact of Code in Pre-training, Viraat Aryabumi+, arXiv'24, 2024.08</a>
<span class="snippet"><span>GPT Summary</span>- コードデータが一般的なLLMのパフォーマンスに与える影響を体系的に調査。アブレーション実験により、コードがコーディングタスクを超えた一般化に重要であり、コード品質の向上が全タスクに大きな影響を与えることを確認。特に、コードの追加により自然言語推論で最大8.2%、世界知識で4.2%、生成的勝率で6.6%の向上を示し、コードパフォーマンスでは12倍の改善を達成。研究は、コード品質への投資がポジティブな影響をもたらすことを示唆。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/eliebakouch/status/1985116711662543167?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>事前学習におけるコードの割合を増やすとコーディングタスクの性能は線形に増加する。全体の平均タスク性能の観点で言うとコードの割合を25%にするのが最適で、コードの割合を増やすほど自然言語による推論、世界知識が問われるタスクの性能は悪化していき、コードの割合が75%を超えると急激に悪化する（Figure4)。</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-11-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3551" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Large Language Monkeys: Scaling Inference Compute with Repeated Sampling, Bradley Brown+, arXiv'24, 2024.07</a>
<span class="snippet"><span>GPT Summary</span>- 言語モデルの推論能力を向上させるために、候補解を繰り返しサンプリングする手法を提案。サンプル数の増加に伴い、問題解決のカバレッジが4桁のオーダーでスケールし、対数線形の関係が示唆される。自動検証可能な回答がある領域では、カバレッジの増加がパフォーマンス向上に直結。SWE-bench Liteでの実験では、サンプル数を増やすことで解決率が大幅に向上したが、自動検証器がない領域ではサンプル数が増えても効果が頭打ちになることが確認された。</span>
<span class="snippet"><span>Comment</span><p>Repeated Sampling。同じプロンプトで複数回LLMを呼び出し、なんらかのverifierを用いて最も良いものを選択するtest time scaling手法。<br><br>&lt;img width="812" height="272" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/73db708f-7eb2-444e-9689-bbef1f12e22d"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/73db708f-7eb2-444e-9689-bbef1f12e22d"&lt;/a&gt;


/&gt;<br><br><br>figure2にverifierを利用しない場合と利用した場合の差が示されている。高性能なverifierが利用された場合は、サンプル数の増加に大して性能がスケールしていき、single attemptでのstrong ModelやSoTAを上回る性能が得られることがわかる。<br>&lt;img width="827" height="415" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/2edbe1b7-26fc-47f6-a54b-642832fbe1a8"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/2edbe1b7-26fc-47f6-a54b-642832fbe1a8"&lt;/a&gt;


/&gt;<br><br><br>Figure8を見るとself consistency型のverifierの限界が示されている。すなわち、サンプリングする中で正しい解法が頻出しないようなものである。図を見ると、赤いbarがmajority-votingでは正解できない問題のindexを示しており、それなりの割合で存在することがわかる。<br><br>&lt;img width="836" height="345" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/d087621a-dfc0-47e7-9b4d-3efd1fa9016e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/d087621a-dfc0-47e7-9b4d-3efd1fa9016e"&lt;/a&gt;


/&gt;<br><br>この辺の話は<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2346" target="_blank" rel="noopener noreferrer">[Paper Note] Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A   Perspective of Probability Theory, Yexiang Liu+, ACL'25 Outstanding Paper</a>
<br><br>とも関連していると思われる。</p>
<p>verifierの具体的な構築方法としてどのようなものがあるかが気になる。あとで読む。</p>
<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/558" target="_blank" rel="noopener noreferrer">[Paper Note] Self-Consistency Improves Chain of Thought Reasoning in Language Models, Xuezhi Wang+, ICLR'23, 2022.03</a>
</p>
<p>&gt; However, these increasingly rare correct generations are only beneficial if verifiers can “find the needle in the haystack” and identify them from collections of mostly-incorrect samples. In math word problem settings, we find that two common methods for verification (majority voting and reward models) do not possess this ability. When solving MATH [26] problems with Llama-3-8B-Instruct, coverage increases from 82.9% with 100 samples to 98.44% with 10,000 samples. However, when using majority voting or reward models to select final answers, the biggest performance increase is only from 40.50% to 41.41% over the same sample range.<br><br>上に記述されている内容は、要はverifierの性能が重要で、典型的なmajority votingやreward mode4lsによるverification手法ではスケールしないケースがある。たとえば、以下のFigure7を見ると、典型的な<br>- majority voting<br>- reward model + best-of-N<br>- majority voting + reward model<br><br>などのtest-time scaling手法（verification手法）がサンプル数Kを増やしてもスケールしないことを示しており、一方Oracle Verifier（=数学の問題において正解が既知の場合に正解を出力したサンプルを採用する）での結果を見ると、性能がスケールしていくことがわかる。特にGSM8K, MATHデータセットにおいては、Reward Modelを利用するverification手法はmajority votingと比較してあまり良い性能が出ていないことがわかる。<br><br>&lt;img width="820" height="402" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/bc9cbc89-d31d-4b46-b7b8-f620dc95ccd7"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/bc9cbc89-d31d-4b46-b7b8-f620dc95ccd7"&lt;/a&gt;


/&gt;<br><br>本研究は5つのデータで検証しているが利用されているverifierは<br>- MiniF2F-MATH, CodeContests, SWE-Bench:<br>  - すでに自動的なverifierが提供されており、たとえばそれはLean4 proof checker、test case, unit test suitesなどである<br>- GSM8K, MATH:<br>  - これらについてはOracle Verifier（=モデルの出力が問題の正答と一致したら採用する）を利用している</p>
<p>本手法のスケーリングはverifierの性能に依存するため、高性能なverificationが作成できないタスクに関して適用するのは難しいと考えられる。逆に良い感じなverifierが定義できるなら相当強力な手法に見える。</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Off-Policy.html" target="_blank" rel="noopener noreferrer">#Off-Policy</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-10-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3512" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On-Policy Distillation of Language Models: Learning from Self-Generated   Mistakes, Rishabh Agarwal+, ICLR'24, 2023.06</a>
<span class="snippet"><span>GPT Summary</span>- 一般化知識蒸留（GKD）は、教師モデルからのフィードバックを活用し、生徒モデルが自己生成した出力シーケンスで訓練する手法。これにより、出力シーケンスの分布不一致の問題を解決し、柔軟な損失関数の使用が可能になる。GKDは蒸留と強化学習の統合を促進し、要約、翻訳、算術推論タスクにおける自動回帰言語モデルの蒸留においてその有効性を示す。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=3zKtaqxLhW" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=3zKtaqxLhW</a>


</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3510" target="_blank" rel="noopener noreferrer">Unlocking On-Policy Distillation for Any Model Family, Patiño+, HuggingFace, 2025.10</a>
<br><br>での説明に基づくと、<br>オフポリシーの蒸留手法を使うと、教師モデルが生成した出力を用いて蒸留をするため、生徒モデルが実際に出力するcontextとは異なる出力に基づいて蒸留をするため、生徒モデルの推論時のcontextとのミスマッチが生じる課題があるが、オンポリシーデータを混ぜることでこの問題を緩和するような手法（つまり実際の生徒モデル運用時と似た状況で蒸留できる）。生徒モデルが賢くなるにつれて出力が高品質になるため、それらを学習データとして再利用することでpositiveなフィードバックループが形成されるという利点がある。また、強化学習と比較しても、SparseなReward Modelに依存せず、初期の性能が低いモデルに対しても適用できる利点があるとのこと（性能が低いと探索が進まない場合があるため）。</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3424" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Fine-tuning Aligned Language Models Compromises Safety, Even When Users  Do Not Intend To, Xiangyu Qi+, ICLR'24, 2023.10</a>
<span class="snippet"><span>GPT Summary</span>- LLMのファインチューニングは、下流のユースケースに最適化する手法だが、安全性のリスクが伴う。特に、敵対的なトレーニング例を用いたファインチューニングが、モデルの安全性調整を損なう可能性があることが示された。例えば、わずか10例の悪意のある例でGPT-3.5 Turboをファインチューニングすると、安全ガードレールが突破される。また、無害なデータセットでのファインチューニングも意図せず安全性を劣化させる可能性がある。これらの結果は、調整されたLLMのファインチューニングが新たな安全リスクを生むことを示唆しており、今後の安全プロトコルの強化が求められる。</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=hTEGyKf0dZ" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=hTEGyKf0dZ</a>


</p>
<p>なんらかのデータでpost-trainingしたモデルを、ユーザが利用可能な形でデプロイするような場合には、本研究が提唱するようなjailbreakのリスク<br>- 有害データが10例混入するだけで有害な出力をするようになる<br>- 暗黙的な有害データの混入（e.g., あなたはユーザ命令に従うエージェントです）<br>- 無害なデータでpost-trainingするだけでも下記のような影響でsafety alignmentが悪化する<br>  - catastrophic forgetting<br>  - 有用性と無害性のトレードオフによって、有用性を高めたことで有害性が結果的に増えてしまう（ `tension between the helpfulness and harmlessness objectives` <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2902" target="_blank" rel="noopener noreferrer">[Paper Note] Training a Helpful and Harmless Assistant with Reinforcement Learning
  from Human Feedback, Yuntao Bai+, arXiv'22</a>
 ）<br><br>があることを認識しておく必要がある。</p>
<p>もし安直にユーザからの指示追従能力を高めたいなあ・・・と思い、「ユーザからの指示には忠実に従ってください」などの指示を追加してpost-trainingをしてしまい、無害なプロンプトのみでテストして問題ないと思いユーザ向けのchatbotとしてデプロイしました、みたいなことをしたらえらいことになりそう。</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3199" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DoRA: Weight-Decomposed Low-Rank Adaptation, Shih-Yang Liu+, ICML'24, 2024.02</a>
<span class="snippet"><span>GPT Summary</span>- LoRAの精度ギャップを解消するために、Weight-Decomposed Low-Rank Adaptation（DoRA）を提案。DoRAは、ファインチューニングの重みを大きさと方向に分解し、方向性の更新にLoRAを使用することで、効率的にパラメータ数を最小化。これにより、LoRAの学習能力と安定性を向上させ、追加の推論コストを回避。さまざまな下流タスクでLoRAを上回る性能を示す。</span>
<span class="snippet"><span>Comment</span><p>日本語解説:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2928" target="_blank" rel="noopener noreferrer">LoRAの進化：基礎から最新のLoRA-Proまで , 松尾研究所テックブログ, 2025.09</a>
</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3198" target="_blank" rel="noopener noreferrer">Tora: Torchtune-LoRA for RL, shangshang-wang, 2025.10</a>
<br><br>では、通常のLoRA, QLoRAだけでなく本手法でRLをする実装もサポートされている模様</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1072" target="_blank" rel="noopener noreferrer" class="title-link">Think before you speak: Training Language Models With Pause Tokens, Sachin Goyal+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- 言語モデルのトレーニングと推論において、遅延を導入することでモデルの性能を向上させる手法を提案しました。具体的には、入力に特定のトークンを追加し、そのトークンが現れるまでモデルの出力を遅らせることで、追加の計算を行うことができます。実験結果では、この手法が推論タスクにおいて有益であり、特にQAタスクでの性能向上が見られました。今後は、この遅延予測の手法をさらに研究していく必要があります。</span>
<span class="snippet"><span>Comment</span><p>この研究は興味深いが、事前学習時に入れないと効果が出にくいというのは直感的にわかるので、実用的には活用しづらい。<br>また、promptでこの研究をimitateする方法については、ZeroShot CoTにおいて、思考プロセスを明示的に指定するようなpromptingと同様のことを行っており、これは実際に効果があると思う。</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Reproducibility.html" target="_blank" rel="noopener noreferrer">#Reproducibility</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3368" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Reinforcement Learning that Matters, Peter Henderson+, AAAI'18, 2017.09</a>
<span class="snippet"><span>GPT Summary</span>- 深層強化学習（RL）の進展を持続させるためには、既存研究の再現性と新手法の改善を正確に評価することが重要である。しかし、非決定性や手法のばらつきにより、結果の解釈が難しくなることがある。本論文では、再現性や実験報告の課題を調査し、一般的なベースラインとの比較における指標のばらつきを示す。さらに、深層RLの結果を再現可能にするためのガイドラインを提案し、無駄な努力を最小限に抑えることで分野の進展を促進することを目指す。</span>
<span class="snippet"><span>Comment</span><p>日本語解説: 


<a href="https://www.slideshare.net/slideshow/dldeep-reinforcement-learning-that-matters-83905622/83905622" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/slideshow/dldeep-reinforcement-learning-that-matters-83905622/83905622</a>


</p>
<p>再現性という観点とは少し異なるのかもしれないが、最近のRLによるpost-trainingについては、以下の研究でScaling Lawsが導入されている。<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3282" target="_blank" rel="noopener noreferrer">[Paper Note] The Art of Scaling Reinforcement Learning Compute for LLMs, Devvrit Khatri+, arXiv'25, 2025.10</a>
<br><br>が、結局現在も多くのRL手法が日夜出てきており、再現性に関しては同じような状況に陥っていそうである。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-11-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3675" target="_blank" rel="noopener noreferrer" class="title-link">LLM開発の裏で行われるデバッグ作業: PyTorch DCP, Kazuki Fujii, 2025.11</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1988862099351613708?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3676" target="_blank" rel="noopener noreferrer">[Tips] PyTorchをself buildしてinstallする方法, Kazuki Fujii, 2025.03</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3677" target="_blank" rel="noopener noreferrer">[Tips] PyTorchにおける動的リンク, Kazuki Fujii, 2025.05</a>
</p>
<p>自分たちの環境と目的を考えた時に、複数の選択肢を列挙し、それぞれの利点と欠点を明文化した上で最適なものを選択する。そしてそれを実現する上で見つかった挙動のおかしな部分について、怪しい部分にあたりをつけて、仮説を立てて、中身を確認し、時には一度問題ないと判断した部分にも立ち返りさらに深掘りし、原因を明確にする、といったデバッグ作業（の一つのケース）について詳述されている。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="articles/4D%20(Video).html" target="_blank" rel="noopener noreferrer">#4D (Video)</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3662" target="_blank" rel="noopener noreferrer" class="title-link">Egocentric-10K, Build AI, 2025.11</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vincentweisser/status/1988766415156060544?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>工場での主観視点での作業動画の大規模データセット。Apache 2.0!?</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/Routing.html" target="_blank" rel="noopener noreferrer">#Routing</a>
<span class="issue_date">Issue Date: 2025-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3660" target="_blank" rel="noopener noreferrer" class="title-link">GPT-5.1: A smarter, more conversational ChatGPT, OpenAI, 2025.11</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sama/status/1988692165686620237?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>instantモデルはよりあたたかい応答でより指示追従能力を高め、thinkingモデルは入力に応じてより適応的に思考トークン数を調整する。autoモデルは入力に応じてinstant, thinkingに適切にルーティングをする。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3645" target="_blank" rel="noopener noreferrer" class="title-link">SYNTH: the new data frontier, pleias, 2025.11</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dorialexander/status/1987930819021635964?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>SoTAなReasoning能力を備えたSLMを学習可能な事前学習用合成データ</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dimitrispapail/status/1988269205737619960?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SparseAutoEncoder.html" target="_blank" rel="noopener noreferrer">#SparseAutoEncoder</a>
<span class="issue_date">Issue Date: 2025-11-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3604" target="_blank" rel="noopener noreferrer" class="title-link">Mapping LLMs with Sparse Autoencoders, Hussein+, 2025.11</a>
<span class="snippet"><span>Comment</span><p>SparseAutoEncoderを用いた機械学習モデルの特徴の可視化方法に関するチュートリアル</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-11-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3550" target="_blank" rel="noopener noreferrer" class="title-link">進化する大規模言語モデル評価: Swallowプロジェクトにおける実践と知見, Naoaki Okazaki, 2025.10</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chokkanorg/status/1984169403509039380?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>LLMの評価は些細な評価設定の違いで大きな変動が生じるだけでなく、事後学習済みモデルやreasoningモデルが主流になってきた現在では評価方法もアップデートが必要という話。たとえばreasoningモデルはfew-shotで評価すると性能が低下することが知られているなど。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2025-11-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3535" target="_blank" rel="noopener noreferrer" class="title-link">戦えるAIエージェントの作り方, Takuya Akiba, SakanaAI, 2025.10</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwiwi/status/1984231610204701047?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>SakanaAIの研究を中心に、特に推論時スケーリング（test time scaling)の話が紹介されている。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="articles/Security.html" target="_blank" rel="noopener noreferrer">#Security</a>
<span class="issue_date">Issue Date: 2025-10-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3527" target="_blank" rel="noopener noreferrer" class="title-link">Introducing Aardvark: OpenAI’s agentic security researcher, OpenAI, 2025.10</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sama/status/1984002552158154905?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>&gt; In benchmark testing on “golden” repositories, Aardvark identified 92% of known and synthetically-introduced vulnerabilities, demonstrating high recall and real-world effectiveness.<br><br>合成された脆弱性については92%程度検出できたとのこと。Claudeとかだとこの辺はどの程度の性能なのだろう。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/Safeguard.html" target="_blank" rel="noopener noreferrer">#Safeguard</a>
<span class="issue_date">Issue Date: 2025-10-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3522" target="_blank" rel="noopener noreferrer" class="title-link">gpt-oss-safeguard, OpenAI, 2025.10</a>
<span class="snippet"><span>Comment</span><p>元ポスト:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/openai/status/1983507394316710039?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/openai/status/1983507392374641071?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>blog:


<a href="https://openai.com/index/introducing-gpt-oss-safeguard/" target="_blank" rel="noopener noreferrer">https://openai.com/index/introducing-gpt-oss-safeguard/</a>


</p>
<p>ポリシーとそのポリシーに従うべきコンテンツが与えられたときに、コンテンツを分類するタスクを実施できる汎用的なreasoningモデル。つまり、任意のポリシーを与えて追加の学習なしでpromptingによってコンテンツがポリシーのもとでsafe/unsafeなのかを分類できる。<br><br>gpt-ossをreinforcbment finetuningしているとのこと。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-10-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3509" target="_blank" rel="noopener noreferrer" class="title-link">Everything About Transformers, Krupa Dave, 2025.10</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1983457842960236664?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>ざっと見た感じtransformerの基本的な内容の丁寧な解説に見える。literature(RNNや、LSTM、seq2seqなど）、self/cross-attention,LayerNorm, ResidualConnection, PositionalEncodingといった話の基礎が図解付きで説明されている。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-10-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3454" target="_blank" rel="noopener noreferrer" class="title-link">LMMs Engine, EvolvingLMMs-Lab, 2025.10</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/liuziwei7/status/1982446267646239148?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>事前学習済みのLLM, VLM, dLM, DiffusionModelなどからUMMを学習できる事後学習フレームワーク。<br>LigerKernelでメモリ使用量を30%削減し、SparseAttentionもサポートし、Muon Optimizerもサポートしている。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/DataFiltering.html" target="_blank" rel="noopener noreferrer">#DataFiltering</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3385" target="_blank" rel="noopener noreferrer" class="title-link">FindWiki, Guilherme Penedo, 2025.10</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gui_penedo/status/1980665876127879647?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>2023年時点で公開されたWikipediaデータをさらに洗練させたデータセット。文字のレンダリング、数式、latex、テーブルの保持（従来は捨てられてしまうことが多いとのこと）、記事に関係のないコンテンツのフィルタリング、infoboxを本文から分離してメタデータとして保持するなどの、地道な前処理をして洗練化させたとのこと。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3352" target="_blank" rel="noopener noreferrer" class="title-link">How Well Does RL Scale?, Toby Ord, 2025.10</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tobyordoxford/status/1980351353227768109?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>OpenAIやAnthropicが公表している学習に関するplot（と筆者の様々なアカデミアの研究の知見）に基づいて、RLによるスケーリングは、事前学習やTest-time Scalingよりも計算量の観点で効率が悪い、ということを分析している模様。<br><br>&gt; So the evidence on RL-scaling and inference-scaling supports a general pattern:<br>&gt;- a 10x scaling of RL is required to get the same performance boost as a 3x scaling of inference<br>&gt; - a 10,000x scaling of RL is required to get the same performance boost as a 100x scaling of inference<br>&gt;<br>&gt; In general, to get the same benefit from RL-scaling as from inference-scaling required twice as many orders of magnitude. That’s not good.<br><br>その上で、RLによるコストが事前学習のコストと同等かそれ以上となったときに、モデルの性能をスケールさせる場合のコストが爆発的に増加することを指摘している（初期のRLによるコストが小さければ事前学習やtest-time scalingのデータを増やすよりも効率がよいスケーリング手法となっていたが、RLのコストが大きくなってくるとスケールさせる際の金額の絶対値が大きくなりすぎるという話）。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Test-time%20Learning.html" target="_blank" rel="noopener noreferrer">#Test-time Learning</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3351" target="_blank" rel="noopener noreferrer" class="title-link">Knowledge Flow: Scaling Reasoning Beyond the Context Limit, Zhuang+, 2025.10</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yufan_zhuang/status/1980410295790248406?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>モデルのロールアウトの結果からattemptから知識リストをiterativeに更新（新たな知識を追加, 古い知識を削除 or 両方）していくことによって、過去のattemptからのinsightを蓄積し性能を改善するような新たなテストタイムスケーリングの枠組みな模様。sequential test-time scalingなどとは異なり、複数のattemptによって知識リストを更新することでスケールさせるので、context windowの制約を受けない、といった話な模様。LLM AgentにおけるTest-time learningとかなり類似したコンセプトに見える。<br><br>&lt;img width="754" height="358" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/9a302c5e-ee79-4c17-99e3-0851b5f127c6"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/9a302c5e-ee79-4c17-99e3-0851b5f127c6"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3301" target="_blank" rel="noopener noreferrer" class="title-link">Context Engineering in Manus, Lance's Blog, 2025.10</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rlancemartin/status/1978864891130953957?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>- Reduce<br>- Offload<br>- Isolate</p>
<p>図解つきで各コンセプトについて非常に詳細に記述されている。最後のConclusionを見ればコンパクトに概要をつかめる。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Video.html" target="_blank" rel="noopener noreferrer">#Video</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-10-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3233" target="_blank" rel="noopener noreferrer" class="title-link">Shipping with Codex, OpenAI, 2025.10</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1977321505664237931?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>OpenAI内部で92%の技術スタッフがdailyで利用している、というマーケティングメッセージが非常に強力で、説得力を持たせていると感じる。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<span class="issue_date">Issue Date: 2025-10-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3220" target="_blank" rel="noopener noreferrer" class="title-link">RL Scaling Laws for Mathematical Reasoning, Joan Cabezas, 2025.10</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/josancamon19/status/1976693692590440526?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>Qwen3をGSM8KでRL Finetuningしたらパラメータ数が小さいモデルは大きなgainを得たが、パラメータが大きいモデルはそれほどでもなかったので、パラメータ数が大きいほどスケールするわけではなく（むしろ恩恵が小さくなる）、かつ報酬をstrictにするとQwenは指示追従能力がないことで学習が全然進まなかった（柔軟なものにしたらそうではなかったので適切な報酬が重要）、GSM8KでRL FinetuninpしたモデルのreasoningはMMLUに転移しなかったので、RL Finetuningは学習データとして与えたドメインのパターンを学習しているだけなのではないか、みたいな話がポストに記述されている。</p>
<p>AI2のResearcherからの所見:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/natolambert/status/1976817173302829261?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>元の話とこの辺をしっかり読み解いたらとても勉強になりそうな予感👀<p>Scaling Laws系の研究:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1827" target="_blank" rel="noopener noreferrer">Training Compute-Optimal Large Language Models, Jordan Hoffmann+, NeurIPS'22</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1828" target="_blank" rel="noopener noreferrer">Scaling Laws for Neural Language Models, Jared Kaplan+, arXiv'20</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1829" target="_blank" rel="noopener noreferrer">Scaling Data-Constrained Language Models, Niklas Muennighoff+, NeurIPS'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2002" target="_blank" rel="noopener noreferrer">Scaling Laws for Autoregressive Generative Modeling, Tom Henighan+, arXiv'20</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2745" target="_blank" rel="noopener noreferrer">Scaling Laws for Value-Based RL, Fu+, 2025.09</a>
 (RL関連)<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3157" target="_blank" rel="noopener noreferrer">[Paper Note] Bayesian scaling laws for in-context learning, Aryaman Arora+, COLM'25, 2024.10</a>
 (ICL関連)<br><br>画像とかData Mixture, MoEなど他にも色々あるが、一旦上記らへんと元ポスト・AI2からの所見を読み解いたらどういったものが見えてくるだろうか？（全部読んでじっくり考えたいけど時間が無いので...）一旦GPTにきいてみよう</p>
<p>GPTにきいてみた（私は無課金勢だがthinking timeが挟まれたのとデコーディング速度の適度な遅さと、limitに到達しましたというメッセージがなかったことから鑑みるに、以下はGPT-5によって回答されていると考えられる）<br>


<a href="https://chatgpt.com/share/68ec5024-83fc-8006-b8c6-14060191fb91" target="_blank" rel="noopener noreferrer">https://chatgpt.com/share/68ec5024-83fc-8006-b8c6-14060191fb91</a>


</p>
<p>RLのScaling Lawsに関する研究がでました:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3282" target="_blank" rel="noopener noreferrer">[Paper Note] The Art of Scaling Reinforcement Learning Compute for LLMs, Devvrit Khatri+, arXiv'25, 2025.10</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Citations.html" target="_blank" rel="noopener noreferrer">#Citations</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<span class="issue_date">Issue Date: 2025-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3185" target="_blank" rel="noopener noreferrer" class="title-link">Making AI citations count with Asta, AI2, 2025.10</a>
<span class="snippet"><span>Comment</span><p>RAGベースの研究支援プラットフォームAstaに対して送信されたクエリに対して、システムが引用した研究論文に関する統計情報を公開したとのこと。興味深い。</p>
<p>citationに関するデータはこちら:<br>


<a href="https://huggingface.co/datasets/allenai/asta-summary-citation-counts" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/allenai/asta-summary-citation-counts</a>


<br><br>定期的に更新するとのこと。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/ReplayBuffer.html" target="_blank" rel="noopener noreferrer">#ReplayBuffer</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3104" target="_blank" rel="noopener noreferrer" class="title-link">Replay BufferがPolicy Gradientで使えない理由, piqcy, 2019.03</a>
<span class="snippet"><span>Comment</span><p>Policy Gradientに基づいたアルゴリズムは（たとえばREINFORCE系）、現在のポリシーに基づいて期待値を最大化していくことが前提になるため、基本的にはリプレイバッファが使えないが（過去の経験が影響すると現在の戦略の良さがわからなくなる）、工夫をすると使えるようになるよ、といった話の解説</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3102" target="_blank" rel="noopener noreferrer" class="title-link">Effective context engineering for AI agents, Anthropic, 2025.09</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/anthropicai/status/1973098580060631341?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>AnthropicによるContextEngineeringに関するブログ。<br>ざーっとみた感じ基礎的な定義からなぜ重要なのか、retrievalの活用、longnhorizon taskでの活用、compaction(summarization)など、幅広いトピックが網羅されているように見える。</p>
<p>最新サーベイはこちら<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2256" target="_blank" rel="noopener noreferrer">[Paper Note] A Survey of Context Engineering for Large Language Models, Lingrui Mei+, arXiv'25</a>
</p>
<p>所見:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_stakaya/status/1974228183450071048?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3032" target="_blank" rel="noopener noreferrer" class="title-link">Build A Reasoning Model （From Scratch）, Sebastian Raschka, 2025.05</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1972294357635178938?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>reasoningモデルに関するpyTorchによるフルスクラッチでの実装と丁寧な解説つきのNotebookが公開されており内部の基礎的な挙動を理解するためにとても良さそう。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3028" target="_blank" rel="noopener noreferrer" class="title-link">Failing to Understand the Exponential, Again, Julian Schrittwieser, 2025.09</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aidan_mclau/status/1972091890318430621?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1842" target="_blank" rel="noopener noreferrer">Measuring AI Ability to Complete Long Tasks, Thomas Kwa+, arXiv'25, 2025.03</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3027" target="_blank" rel="noopener noreferrer">GDPVAL: EVALUATING AI MODEL PERFORMANCE ON REAL-WORLD ECONOMICALLY VALUABLE TASKS, Patwardhan+, 2025.09</a>
</p>
<p>AIの指数関数的な成長は続いているぞという話。<br><br>以下は管理人の感想だが、個々のベンチマークで見たらサチってきている（昔より伸び代が小さい）ように感じるが、人間が実施する複雑なタスクに対する上記ベンチマークなどを見るとスケーリングは続いている（むしろ加速している感がある）。シンプルなタスクのベンチマークの伸びは小さくとも、それらシンプルなタスクの積み重ねによって複雑なタスクは実施されるので、（現存するベンチマークが測定できている能力はLLMの部分的な能力だけなことも鑑みると）、複雑なタスクで評価した時の伸びは実は大きかったりする（スケーリングは続いている）のではないか、という感想。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3026" target="_blank" rel="noopener noreferrer" class="title-link">HunyuanImage-3.0, Tencent, 2025.09</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tencenthunyuan/status/1972130405160833334?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>所見:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1972469371839860954?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>テキスト生成+画像理解・生成が可能なUnified Multimodal Models (UMMs)。テキストはtokenizer、画像は生成用エンコーダ、理解用エンコーダを用意してエンコードしDecoder-Only Tranformerに入力。auto-regressiveに生成し、テキストはDe-Tokenizerでテキスト化、画像の場合は専用のDecoderでデコードする。<br><br>&lt;img width="638" height="232" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/8e06f188-3885-4eed-8837-eb560dcc6b67"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/8e06f188-3885-4eed-8837-eb560dcc6b67"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Infrastructure.html" target="_blank" rel="noopener noreferrer">#Infrastructure</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3012" target="_blank" rel="noopener noreferrer" class="title-link">AIインフラを考える, Masayuki Kobayashi, 第38回 ISOC-JP Workshop, 2025.09</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwashi86/status/1971898942926606825?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>KVCacheサイズとデータ転送量の部分はパフォーマンスチューニングの際に重要なのですぐにでも活用できそう。前半部分は私にとっては難しかったので勉強したい。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-09-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3010" target="_blank" rel="noopener noreferrer" class="title-link">We reverse-engineered Flash Attention 4, Modal Blog, 2025.09</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwashi86/status/1972085451055157725?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>Flash Attention4は数学的なトリックよりも非同期処理の複雑なパイプライン、Blackwellに最適化、とのこと</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2979" target="_blank" rel="noopener noreferrer" class="title-link">CWM: An Open-Weights LLM for Research on Code Generation with World Models, Copet+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yuxiangwei9/status/1970965218839974250?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>World Modelと銘打ってあるが、一般的なCV分野でのWorld Modelではなく、python やbash等の実行をトークン列として仮想的にトレースできるようにmid trainingされている（大量の実トレースデータが利用されている模様）ので、World Modelと銘打たれている模様？<br><br><img src="https://github.com/user-attachments/assets/bbed358e-ad8d-4b6c-bd6b-39d23457a9cb" alt="image" loading="lazy"></p>
<p>GRPOに対するモダンなtweakがまとまっている模様:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1972268402732617968?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>DeepSeek-R1で提案されてから細かな調整が重ねられて来た。</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2620" target="_blank" rel="noopener noreferrer" class="title-link">LongCat-Flash-Chat, meituan-longcat, 2025.08</a>
<span class="snippet"><span>Comment</span><p>テクニカルレポート:


<a href="https://github.com/meituan-longcat/LongCat-Flash-Chat/blob/main/tech_report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/meituan-longcat/LongCat-Flash-Chat/blob/main/tech_report.pdf</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1961955926136832381?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>Agent周りのベンチで高性能なnon thinkingモデル。毎秒100+トークンの生成速度で、MITライセンス。Dynamic Activation...?</p>
<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2621" target="_blank" rel="noopener noreferrer">[Paper Note] Shortcut-connected Expert Parallelism for Accelerating   Mixture-of-Experts, Weilin Cai+, ICLR'25</a>
</p>
<p>Dynamic Activation (activation paramが入力に応じて変化(全てのトークンをMoEにおいて均一に扱わない）することで効率化）は、下記を利用することで実現している模様<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2622" target="_blank" rel="noopener noreferrer">[Paper Note] MoE++: Accelerating Mixture-of-Experts Methods with Zero-Computation   Experts, Peng Jin+, ICLR'25</a>
</p>
<p>しかし中国は本当に次々に色々な企業から基盤モデルが出てくるなぁ…すごい</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2623" target="_blank" rel="noopener noreferrer">[Paper Note] Scaling Exponents Across Parameterizations and Optimizers, Katie Everett+, ICML'24</a>
 </p>
<p>解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nrehiew_/status/1962186876099739767?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1962980770550628841?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Self-SupervisedLearning.html" target="_blank" rel="noopener noreferrer">#Self-SupervisedLearning</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="articles/Regularization.html" target="_blank" rel="noopener noreferrer">#Regularization</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2431" target="_blank" rel="noopener noreferrer" class="title-link">DINOv3: Self-supervised learning for vision at unprecedented scale, Meta, 2025.08</a>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1956067392846749723?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>paper:


<a href="https://arxiv.org/abs/2508.10104" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2508.10104</a>


<br><br>HF:


<a href="https://huggingface.co/docs/transformers/main/en/model_doc/dinov3" target="_blank" rel="noopener noreferrer">https://huggingface.co/docs/transformers/main/en/model_doc/dinov3</a>


</p>
<p>解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1958285463313347071?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>サマリ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1960840635289886958?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>v2:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1884" target="_blank" rel="noopener noreferrer">DINOv2: Learning Robust Visual Features without Supervision, Maxime Oquab+, TMLR'24</a>
</p>
<p>本日配信された岡野原氏のランチタイムトークによると、学習が進んでいくと全部の特徴量が似通ってきてしまう問題があったが、Gram Anchoringと呼ばれる、学習初期時点でのパッチ間の類似度度行列を保持しておき正則化として損失に加えることで、そこから離れすぎないように学習するといった工夫を実施しているとのこと。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2024-11-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1487" target="_blank" rel="noopener noreferrer" class="title-link">ZeRO: DeepSpeedの紹介, レトリバ, 2021.07 </a>
<span class="snippet"><span>Comment</span><p>ZeROの説明がわかりやすい</p>
<p>こちらの記事もわかりやすい<br><br>


<a href="https://zenn.dev/turing_motors/articles/d00c46a79dc976" target="_blank" rel="noopener noreferrer">https://zenn.dev/turing_motors/articles/d00c46a79dc976</a>


</p>
<p>DeepSpeedのコンフィグの一覧<br><br>


<a href="https://www.deepspeed.ai/docs/config-json/" target="_blank" rel="noopener noreferrer">https://www.deepspeed.ai/docs/config-json/</a>


</p>
<p>transformersにおけるdeepspeedのドキュメント:<br>


<a href="https://huggingface.co/transformers/v4.9.2/main_classes/deepspeed.html" target="_blank" rel="noopener noreferrer">https://huggingface.co/transformers/v4.9.2/main_classes/deepspeed.html</a>


</p>
<p>参考: deepspeedの使い方まとめ<br>


<a href="https://note.com/fukudawataru/n/n5152e6f587c8" target="_blank" rel="noopener noreferrer">https://note.com/fukudawataru/n/n5152e6f587c8</a>


</p>
<p>ZeRO Stage3を使う場合、ページ後方にしれっととんでもなく重要なことが書いてあるので気をつけましょう。。。。<br><br>


<a href="https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/deepspeed#constructing-massive-models" target="_blank" rel="noopener noreferrer">https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/deepspeed#constructing-massive-models</a>


<br><br><br><br><img src="https://github.com/user-attachments/assets/677b6656-1302-4b1b-8be6-ca954c7edda6" alt="image" loading="lazy"><br><br></p>
<p>ZeROはparameterとoptimizerのmemory footprintの最適化を頑張っていて、activation memory footprint（バッチをforward passに流す時に消費されるメモリ）の削減は、tiling, activation/gradient checkpointingとかで頑張ってねという<br><br><br><br>という話が本家issueの4047に記載されている。</p>
<p>結論: つまづいたらDeepSpeedのIssueをエラーメッセージで検索かけるのが一番効果的</p></span><br><br>
<button onclick="hideContent(0)" style="display: none;">hide</button>
</div>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

<script>
  document.addEventListener('DOMContentLoaded', function() {
    const tweets = document.querySelectorAll('.tweet-embed[data-embed]');

    if ('IntersectionObserver' in window) {
      const observer = new IntersectionObserver((entries, obs) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            const el = entry.target;
            const html = el.getAttribute('data-embed');
            if (html) {
              const placeholder = el.querySelector('.tweet-placeholder');
              if (placeholder) placeholder.remove();

              el.innerHTML = html.trim();

              if (window.twttr?.widgets?.load) {
                window.twttr.widgets.load(el);
              }
            }
            obs.unobserve(el); // 処理済みは監視解除
          }
        });
      }, {
        rootMargin: '500px 0px', // 画面手前200pxで読み込み開始
        threshold: 0
      });

      tweets.forEach(tweet => observer.observe(tweet));

    } else {
      // IntersectionObserver未対応ブラウザ用のフォールバック
      function lazyLoadFallback() {
        tweets.forEach(el => {
          if (el.getAttribute('data-embed') && el.getBoundingClientRect().top < window.innerHeight) {
            const html = el.getAttribute('data-embed');
            const loadingImg = el.querySelector('.tweet-loading');
            if (loadingImg) loadingImg.remove();
            el.innerHTML = html.trim();
            el.removeAttribute('data-embed');
            if (window.twttr?.widgets?.load) {
              window.twttr.widgets.load(el);
            }
          }
        });
      }
      window.addEventListener('scroll', lazyLoadFallback);
      lazyLoadFallback();
    }
  });
</script>



    </div>

</article>
<div class="post-nav">
<a class="previous" href="/paper_notes/articles/On-Policy.html" title="On-Policyに関する論文・技術記事メモの一覧">On-Policyに関する論文・技術記事メモの一覧</a><a class="next" href="/paper_notes/articles/OnlineEvaluation.html" title="OnlineEvaluationに関する論文・技術記事メモの一覧">OnlineEvaluationに関する論文・技術記事メモの一覧</a>
</div>
<div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li class="">
          <a class="post-link" href="/paper_notes/articles/NeuralNetwork.html" title="NeuralNetworkに関する論文・技術記事メモの一覧">
            NeuralNetworkに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/Abstractive.html" title="Abstractiveに関する論文・技術記事メモの一覧">
            Abstractiveに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/Evaluation.html" title="Evaluationに関する論文・技術記事メモの一覧">
            Evaluationに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/PhysicalConstraints.html" title="PhysicalConstraintsに関する論文・技術記事メモの一覧">
            PhysicalConstraintsに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
</ul>
    </div>
<div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">TOC</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent =  menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3, h4, h5, h6");

    // Hide menu when no headings
    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // Generate post menu
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#h-' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }

    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';

    // The header element
    var header = document.querySelector('header.site-header');

    function doMenuCollapse(index, over_items) {
      var items = menuContent.firstChild.children;

      if (over_items == undefined) {
        over_items = 20;
      }

      if (items.length < over_items) {
        return;
      }

      var activeItem = items[index];
      var beginItem = activeItem
      var endItem = activeItem
      var beginIndex = index;
      var endIndex = index + 1;
      while (beginIndex >= 0
        && !items[beginIndex].classList.contains('h-h2')) {
        beginIndex -= 1;
      }
      while (endIndex < items.length
        && !items[endIndex].classList.contains('h-h2')) {
        endIndex += 1;
      }
      for (var i = 0; i < beginIndex; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
      for (var i = beginIndex + 1; i < endIndex; i++) {
        item = items[i]
        // if (!item.classList.contains('h-h2')) {
          item.style.display = '';
        // }
      }
      for (var i = endIndex; i < items.length; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
    }

    // Init menu collapsed
    doMenuCollapse(-1);

    // Active the menu item
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header.getBoundingClientRect();
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var headerHeight = headerTop + headerHeight + 20;
        if (headingRect.top <= headerHeight) {
          var id = 'h-' + h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          if (curActive) {
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }
      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
        doMenuCollapse(activeIndex);
      }
      event.preventDefault();
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/paper_notes/"></data>

  <div class="wrapper">
    <div class="site-footer-inner">
<div>Copyright © 2023-current AkihikoWATANABE. The header images and any thumbnail images for the posts were generated by ChatGPT's DALL-E3.</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="https://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div class="footer-col rss-subscribe">Subscribe <a href="/paper_notes/feed.xml">via RSS</a>
</div>
    </div>
  </div>
</footer>
</body>
  </html>
