<!DOCTYPE html>
<html lang="ja">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>NaturalLanguageGenerationに関する論文・技術記事メモの一覧 | わたしのべんきょうノート</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="NaturalLanguageGenerationに関する論文・技術記事メモの一覧">
<meta name="author" content="AkihikoWATANABE">
<meta property="og:locale" content="ja">
<meta name="description" content="NaturalLanguageGeneration #Analysis #Pocket #NLP #LanguageModel #Evaluation #EMNLP #read-later">
<meta property="og:description" content="NaturalLanguageGeneration #Analysis #Pocket #NLP #LanguageModel #Evaluation #EMNLP #read-later">
<link rel="canonical" href="http://akihikowatanabe.github.io/paper_notes/articles/NaturalLanguageGeneration.html">
<meta property="og:url" content="http://akihikowatanabe.github.io/paper_notes/articles/NaturalLanguageGeneration.html">
<meta property="og:site_name" content="わたしのべんきょうノート">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2025-10-15T00:46:38+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="NaturalLanguageGenerationに関する論文・技術記事メモの一覧">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"AkihikoWATANABE"},"dateModified":"2025-10-15T00:46:38+00:00","datePublished":"2025-10-15T00:46:38+00:00","description":"NaturalLanguageGeneration #Analysis #Pocket #NLP #LanguageModel #Evaluation #EMNLP #read-later","headline":"NaturalLanguageGenerationに関する論文・技術記事メモの一覧","mainEntityOfPage":{"@type":"WebPage","@id":"http://akihikowatanabe.github.io/paper_notes/articles/NaturalLanguageGeneration.html"},"url":"http://akihikowatanabe.github.io/paper_notes/articles/NaturalLanguageGeneration.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="icon" href="">
  <link rel="canonical" href="http://akihikowatanabe.github.io">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/main.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/custom_button.css">
  <script src="/paper_notes/assets/js/main.js"></script>
  <script src="https://d3js.org/d3.v5.min.js"></script><link type="application/atom+xml" rel="alternate" href="http://akihikowatanabe.github.io/paper_notes/feed.xml" title="わたしのべんきょうノート">
<script>
  function showMore(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "block";
          
      // このボタンの参照を取得して非表示にします
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "none";
      }
          
      // hideボタンの参照を取得して表示します
      const hideButton = contentDiv.querySelector('button[onclick^="hideContent"]');
      if (hideButton) {
        hideButton.style.display = "block";
      }
    }
  }

  function hideContent(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "none";
  
      // moreボタンの参照を取得して表示します
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "block";
      }
  
      // このボタンを隠します
      const hideButtons = document.querySelectorAll('button[onclick^="hideContent"]');
      const hideButton = hideButtons[index];
      if (hideButton) {
        hideButton.style.display = "none";
      }
    }
  }
</script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js" async></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe-lightbox.umd.min.js" async></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe.umd.min.js" async></script>
<link href="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/photoswipe.min.css" rel="stylesheet">
<style>
  .pswp .pswp__container .pswp__img {
    background-color: white;
  }
</style>

<script>
  function initPhotoSwipe() {
    let customOptions = {};

    try {
      const data = `{"gallery"=>"section.main", "children"=>"a.photo-swipe", "bgOpacity"=>0.8, "padding"=>{"top"=>20, "bottom"=>40, "left"=>100, "right"=>100}}`.replaceAll("=>", ":");
      customOptions = JSON.parse(data);
    } catch (e) {
      console.info("Invalid custom photo previewer options! " + e.message);
    }

    // Define object and gallery options
    const options = Object.assign(
      {
        gallery: "section.main",
        children: "a.photo-swipe",
        photo_scale: 2,
        // dynamic import is not supported in UMD version
        pswpModule: PhotoSwipe,
      },
      customOptions
    );

    const galleryEl = document.querySelector(options.gallery);
    if (!galleryEl) {
      return;
    }

    const imgEls = [];
    const els = galleryEl.querySelectorAll("img:not(.emoji)");
    els.forEach((el) => {
      if (el.src.trim() == "") {
        return;
      }
      if (!imgEls.includes(el)) {
        imgEls.push(el);
      }
    });

    if (imgEls.length === 0) {
      return;
    }

    imgEls.forEach((imgEl) => {
      imgEl.outerHTML = `
      <a class="photo-swipe"
        href="${imgEl.src}"
        data-pswp-width="${
          Math.max(imgEl.naturalWidth, imgEl.width) * options.photo_scale
        }"
        data-pswp-height="${
          Math.max(imgEl.naturalHeight, imgEl.height) * options.photo_scale
        }"
        data-pswp-caption="${imgEl.getAttribute("caption") || imgEl.alt}"
        target="_blank">
        ${imgEl.outerHTML}
      </a>`;
    });

    // Initialize PhotoSwipe 5
    var lightbox = new PhotoSwipeLightbox(options);

    lightbox.init();
  }

  window.addEventListener("load", initPhotoSwipe);
</script>
<meta name="google-site-verification" content="u_DTTPcCZ806iq51zgirHyWq3556HUKGq8AQfH91iFI">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-P70KSB88WH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-P70KSB88WH');
  </script>

<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"},"svg":{"fontCache":"global"}}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>





































































































































<header class="site-header site-header-transparent" role="banner">

  <div class="wrapper">
    <div class="site-header-inner">
<span class="site-brand"><a class="site-brand-inner" rel="author" href="/paper_notes/">
  <img class="site-favicon" title="わたしのべんきょうノート" src="" onerror="this.style.display='none'">
  わたしのべんきょうノート
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger">
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewbox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
              </svg>
            </span>
          </label>

          <div class="trigger">









<span class="page-link">



<div id="google_translate_element" style="display: none;">
</div>

<span class="ct-language">
  <ul class="list-unstyled ct-language-dropdown">
    
      <li>
        <a href="#" class="lang-select" data-lang="en">
          
          <img src="https://cdn.countryflags.com/thumbs/united-states-of-america/flag-400.png" title="English">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="fr">
          
          <img src="https://cdn.countryflags.com/thumbs/france/flag-400.png" title="French">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="zh-CN">
          
          <img src="https://cdn.countryflags.com/thumbs/china/flag-400.png" title="Chinese(Simple)">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ja">
          
          <img src="https://cdn.countryflags.com/thumbs/japan/flag-400.png" title="Japanese">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ko">
          
          <img src="https://cdn.countryflags.com/thumbs/south-korea/flag-400.png" title="Korean">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ru">
          
          <img src="https://cdn.countryflags.com/thumbs/russia/flag-400.png" title="Russian">
          
        </a>
      </li>
    
  </ul>
</span>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'ja',
    autoDisplay: false,
    layout: google.translate.TranslateElement.InlineLayout.VERTICAL
  }, 'google_translate_element');

  // Links to cross-origin destinations are unsafe
  var gll = document.getElementsByClassName('goog-logo-link')[0];
  if (gll) {
    gll.setAttribute('rel', 'noopener');
  }

  function restoreLang() {
    var iframe = document.getElementsByClassName('goog-te-banner-frame')[0];
    if (!iframe) return;

    var innerDoc = iframe.contentDocument || iframe.contentWindow.document;
    var restore_el = innerDoc.getElementsByTagName("button");

    for (var i = 0; i < restore_el.length; i++) {
      if (restore_el[i].id.indexOf("restore") >= 0) {
        restore_el[i].click();
        var close_el = innerDoc.getElementsByClassName("goog-close-link");
        close_el[0].click();
        return;
      }
    }
  }

  function triggerHtmlEvent(element, eventName) {
    var event;
    if (document.createEvent) {
      event = document.createEvent('HTMLEvents');
      event.initEvent(eventName, true, true);
      element.dispatchEvent(event);
    } else {
      event = document.createEventObject();
      event.eventType = eventName;
      element.fireEvent('on' + event.eventType, event);
    }
  }

  var googleCombo = document.querySelector("select.goog-te-combo");
  var langSelect = document.querySelector('.ct-language');
  langSelect.addEventListener('click', function(event) {
    if (!event.target) {
      return;
    }

    var selected = document.querySelector('.ct-language .ct-language-selected');
    if (selected) {
      selected.classList.remove('ct-language-selected');
    }

    var target = event.target;
    while (target && target !== langSelect ) {
      if (target.matches('.lang-select')) {
        break;
      }
      target = target.parentElement;
    }

    if (target && target.matches('.lang-select')) {
      var lang = target.getAttribute('data-lang');
      if (googleCombo.value == lang) {
        restoreLang();
      } else {
        target.parentElement.classList.add('ct-language-selected');
        googleCombo.value = lang;
        triggerHtmlEvent(googleCombo, 'change');
      }
    }

    event.preventDefault();
  });
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit" async></script>
</span>
</div>
        </nav>
</div>
  </div>
</header>

<script>
  function initHeader() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;

    function storeScrollData() {
      var y = getScrollPos().y;documentElement.setAttribute("data-header-transparent", "");var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0) ? true : false;
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
    }

    window.addEventListener('scroll', function(e) {
      storeScrollData();
    });

    storeScrollData();
  }
  document.addEventListener('DOMContentLoaded', initHeader);
</script>


























































































































































<style>
    html .page-banner .page-banner-img > *:first-child {
      opacity: 0.4;
    }

    html[data-theme="dark"] .page-banner .page-banner-img > *:first-child {
      opacity: 0.2872;
    }
  </style>
<section class="page-banner">
    <div class="page-banner-img">
<div style="background-image: url(/paper_notes/assets/images/banner.png)"></div>
        <img class="img-placeholder" src="/paper_notes/assets/images/banner.png">
</div>
    <div class="wrapper">
      <div class="page-banner-inner">
<header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">わたしのべんきょうノート</h1>
  <h2 class="post-subtitle">勉強した論文や技術等の情報をGithubのIssueにメモっているひとのブログ。
それなりにメモの量が蓄積されてきたので、一度整理したいなと思いブログはじめてみました！
自然言語処理(NLP), 推薦システム(RecommenderSystem), Educational Data Mining (EDM), Learning Analytics (LA)などの分野のメモが多いと思います。
最近は特にLLMの勉強が多めです :)</h2>

  <div class="post-meta">
    <time class="dt-published" datetime="2025-10-15T00:46:38+00:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Oct 15, 2025
    </time><span class="post-author left-vsplit"><i class="fa fa-pencil"></i> AkihikoWATANABE</span>
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 3 hours 50 mins</span>
  </div></header>
</div>
    </div>
  </section><script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    hashValue = decodeURIComponent(hashValue);
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('off' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<div id="click-to-top" class="click-to-top">
  <i class="fa fa-arrow-up"></i>
</div>
<script>
  (function () {
    const clickToTop = document.getElementById('click-to-top');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 100) {
        clickToTop.classList.add('show')
      }else {
        clickToTop.classList.remove('show')
      }
    });
    clickToTop.addEventListener('click', () => {
      window.smoothScrollTo(0);
    });
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <h2 id="NaturalLanguageGeneration"> NaturalLanguageGeneration</h2>
<div class="visible-content">
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>


<br>


<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2520" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Are Checklists Really Useful for Automatic Evaluation of Generative  Tasks?, Momoka Furuhashi+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- 生成タスクの自動評価における曖昧な基準の課題を解決するため、チェックリストの使用方法を検討。6つの生成方法と8つのモデルサイズで評価し、選択的チェックリストがペアワイズ評価でパフォーマンスを改善する傾向があることを発見。ただし、直接スコアリングでは一貫性がない。人間の評価基準との相関が低いチェックリスト項目も存在し、評価基準の明確化が必要であることを示唆。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tohoku_nlp_mmk/status/1958717497454002557?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>pj page:


<a href="https://momo0817.github.io/checklist-effectiveness-study-github.io/" target="_blank" rel="noopener noreferrer">https://momo0817.github.io/checklist-effectiveness-study-github.io/</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>


<br>


<span class="issue_date">Issue Date: 2025-07-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2297" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CaptionSmiths: Flexibly Controlling Language Pattern in Image Captioning, Kuniaki Saito+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- CaptionSmithsは、画像キャプショニングモデルがキャプションの特性（長さ、記述性、単語の独自性）を柔軟に制御できる新しいアプローチを提案。人間の注釈なしで特性を定量化し、短いキャプションと長いキャプションの間で補間することで条件付けを実現。実証結果では、出力キャプションの特性をスムーズに変化させ、語彙的整合性を向上させることが示され、誤差を506%削減。コードはGitHubで公開。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/a_hasimoto/status/1948258269668970782?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>従来はDiscreteに表現されていたcaptioningにおける特性をCondition Caluculatorを導入することでcontinuousなrepresentationによって表現し、Caluculatorに人間によるinput, あるいは表現したいConditionを持つexampleをinputすることで、生成時に反映させるような手法を提案している模様。Conditionで利用するpropertyについては、提案手法ではLength, Descriptive, Uniqueness of Vocabulariesの3つを利用している（が、他のpropertyでも本手法は適用可能と思われる）。このとき、あるpropertyの値を変えることで他のpropertyが変化してしまうと制御ができなくなるため、property間のdecorrelationを実施している。これは、あるproperty Aから別のproperty Bの値を予測し、オリジナルのpropertyの値からsubtractする、といった処理を順次propertyごとに実施することで実現される。Appendixに詳細が記述されている。<br><br><img src="https://github.com/user-attachments/assets/673a2b9d-d630-4328-b619-f5382bb74f27" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/a90aa9d1-27f1-45c0-819e-c81b93364c68" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Citations.html" target="_blank" rel="noopener noreferrer">#Citations</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/AcademicWriting.html" target="_blank" rel="noopener noreferrer">#AcademicWriting</a>


<br>


<span class="issue_date">Issue Date: 2025-07-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2149" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ScholarCopilot: Training Large Language Models for Academic Writing with   Accurate Citations, Yubo Wang+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- ScholarCopilotは、学術的な執筆を支援するために大規模言語モデルを強化したフレームワークで、正確で文脈に関連した引用を生成します。取得トークンを用いて動的に文献を取得し、生成プロセスを補強します。評価では、取得精度が40.1%に達し、生成品質も他のモデルを大幅に上回りました。特に、ScholarCopilotはChatGPTを超える性能を示し、引用の質で100%の好ましさを達成しました。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1907861046833885397?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>従来のRAGベースのAcademicWriting手法では、まずReferenceを検索して、その内容をcontextに含めてテキストを生成するというSequentialなパイプラインだったが、本研究では通常のNextTokenPrediction Lossに加え、特殊トークン\[RET\]を導入し、ContrastiveLearningによって、\[RET\]トークンがトリガーとなり、生成過程のContextとqueryから適切なReferenceを検索できるEmbeddingを出力し、Referenceを検索し、動的にReferenceの内容をcontextに加え、テキストを生成する手法を提案している。<br><img src="https://github.com/user-attachments/assets/777da4cb-5678-455f-babf-b91690945712" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/a27e092e-fff2-4f8a-91f7-09fe39e8e568" alt="image" loading="lazy"><br><br>データセットはarXivからlatex sourceを収集し、bibliography部分からReferenceのタイトルをQwenを用いて抽出。タイトルをarXivおよびSemanticScholarのデータベースと照合し、paperとReferenceの紐付けを実施することで構築している。<br><img src="https://github.com/user-attachments/assets/2dd2b956-291e-4407-997a-4a2e68a72708" alt="image" loading="lazy"><br><br>GPT-4oによるjudgeの結果、ground truthのcitationを用いた場合には及ばないが、提案手法により品質が向上し、citation retrievalのRecall@Kも大幅に改善している。<br><img src="https://github.com/user-attachments/assets/2ff5dd73-dcb8-4a3f-9d6a-1bcfb52a8321" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/81a39366-2577-41a1-aa6b-facc7ac25f1c" alt="image" loading="lazy"></p></span><br><br>
</div>
<p><button onclick="showMore(0)">more</button></p>
<div class="hidden-content">
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-12-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1592" target="_blank" rel="noopener noreferrer" class="title-link">Striking Gold in Advertising: Standardization and Exploration of Ad Text   Generation, Masato Mita+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- 自動広告テキスト生成（ATG）のために、標準化されたベンチマークデータセットCAMERAを提案。これにより、マルチモーダル情報の活用と業界全体での評価が促進される。9つのベースラインを用いた実験で、現状と課題を明らかにし、LLMベースの評価者と人間の評価の一致を探求。</span>
<span class="snippet"><span>Comment</span><p>広告文生成タスク（Ad Text Generation）は個々のグループのプロプライエタリデータでしか評価されてこなかったことと、そもそもタスク設定が十分に規定されていないので、その辺を整備したという話らしい。<br>特に広告文生成のための初のオープンデータなCAMERAを構築している。<br><br>データセットを作るだけでなく、既存の手法、古典的なものからLLMまででどの程度の性能まで到達しているか、さらにはROUGEやGPT-4を用いたLLM-as-a-Judgeのような自動評価手法をメタ評価し、人手評価とオンライン評価のどの程度代替になるかも分析したとのことらしい。</p>
<p>Table5にメタ評価の結果が記載されている。システムレベルのcorrelationを測定している。興味深いのが、BLEU-4, ROUGE-1, BERTScoreなどの古典的or埋め込みベースのNLG評価手法がFaithfulnessとFluencyにおいて、人間の専門家と高い相関を示しているのに対し、GPT-4による評価では人間による評価と全然相関が出ていない。<br><br>既存のLLM-as-a-Judge研究では専門家と同等の評価できます、みたいな話がよく見受けられるがこれらの報告と結果が異なっていておもしろい。著者らは、OpenAIのGPTはそもそも広告ドメインとテキストでそんなに訓練されていなさそうなので、ドメインのミスマッチが一つの要因としてあるのではないか、と考察している。<br><br>また、Attractivenessでは専門家による評価と弱い相関しか示していない点も興味深い。広告文がどの程度魅力的かはBLEU, ROUGE, BERTScoreあたりではなかなか難しそうなので、GPT4による評価がうまくいって欲しいところだが、全くうまくいっていない。この論文の結果だけを見ると、（Attractivenessに関しては）自動評価だけではまだまだ広告文の評価は厳しそうに見える。<br><br><img src="https://github.com/user-attachments/assets/15804ddc-3131-4a3d-9071-a66473e0e987" alt="image" loading="lazy"></p>
<p>GPT4によるAttractivenessの評価に利用したプロンプトが下記。MTBenchっぽく、ペアワイズの分類問題として解いていることがわかる。この辺はLLM-as-a-Judgeの研究では他にもスコアトークンを出力し尤度で重みづけるG-Evalをはじめ、さまざまな手法が提案されていると思うので、その辺の手法を利用したらどうなるかは興味がある。<br>あとはそもそも手法面の話以前に、promptのコンテキスト情報としてどのような情報がAttractivenessの評価に重要か？というのも明らかになると興味深い。この辺は、サイバーエージェントの専門家部隊が、どのようなことを思考してAttractivenessを評価しているのか？というのがヒントになりそうである。<br><img src="https://github.com/user-attachments/assets/5c0d3989-d4c1-4d61-b592-b1140c4cf93d" alt="image" loading="lazy"><br></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1591" target="_blank" rel="noopener noreferrer">国際会議ACL2024参加報告, Masato Mita, Cyber Agent, 2024.12</a>
<br><br>に著者によるサマリが記載されているので参照のこと。</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2024-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1358" target="_blank" rel="noopener noreferrer" class="title-link">Controllable Text Generation for Large Language Models: A Survey, Xun Liang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsの制御可能なテキスト生成（CTG）技術に関する最新の進展を体系的にレビューし、その中核的な概念の包括的な定義を提供し、制御条件とテキスト品質の要件を明確にする。CTGタスクをコンテンツ制御と属性制御の2つの主要なタイプに分類し、モデルの再学習、ファインチューニング、強化学習、プロンプトエンジニアリング、潜在空間の操作、デコーディング時の介入など、主要な手法について議論する。さらに、CTGの評価方法を検討し、領域全体での応用をまとめ、現在の研究における主要な課題に取り組む。また、将来の研究で実世界の応用に重点を置くなど、いくつかの提案も行う。</span>
<span class="snippet"><span>Comment</span><p>Surveyの内容<br><img src="https://github.com/user-attachments/assets/1117d721-26b9-4361-855f-a6bf9efb93a4" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/NumericReasoning.html" target="_blank" rel="noopener noreferrer">#NumericReasoning</a>
<span class="issue_date">Issue Date: 2024-04-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1267" target="_blank" rel="noopener noreferrer" class="title-link">Prompting for Numerical Sequences: A Case Study on Market Comment  Generation, Masayuki Kawarada+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsは、構造化データに対するプロンプト生成に関する研究が進んでいるが、時系列数値データに関する詳細な調査が不足している。本研究では、株価の数値系列を入力として市場コメントを生成するタスクに焦点を当て、さまざまな入力表現を探究する。実験結果は、プログラミング言語に似たプロンプトがより良い結果をもたらすことを示しており、数値系列からテキストを生成する際の効果的なプロンプト作成について示唆を提供している。</span>
<span class="snippet"><span>Comment</span><p>Data-to-Text系のタスクでは、しばしば数値列がInputとなり、そこからテキストを生成するが、この際にどのようなフォーマットで数値列をPromptingするのが良いかを調査した研究。Pythonリストなどのプログラミング言語に似たプロンプトが高い性能を示し、自然言語やhtml, latextなどのプロンプトは効果が低かったとのこと<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c48c3306-d3ac-4f89-918c-28cb0a17444a" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-01-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1214" target="_blank" rel="noopener noreferrer" class="title-link">Leveraging Large Language Models for NLG Evaluation: A Survey, Zhen Li+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- 本研究は、大規模言語モデル（LLMs）を使用した自然言語生成（NLG）の評価についての包括的な概要を提供します。既存の評価指標を整理し、LLMベースの手法を比較するためのフレームワークを提案します。さらに、未解決の課題についても議論し、より公正で高度なNLG評価技術を提唱します。</span>
<span class="snippet"><span>Comment</span><p>重要</p>
<p>NLGの評価をするモデルのアーキテクチャとして、BERTScoreのようなreferenceとhvpothesisのdistiebuted representation同士を比較するような手法（matching-based）と、性能指標を直接テキストとして生成するgenerative-basedな手法があるよ、<br><img src="https://github.com/user-attachments/assets/b6b4de14-a83b-4138-92f4-c6606451f272" alt="image" loading="lazy"><br><br>といった話や、そもそもreference-basedなメトリック（e.g. BLEU）や、reference-freeなメトリック（e.g. BARTScore）とはなんぞや？みたいな基礎的な話から、言語モデルを用いたテキスト生成の評価手法の代表的なものだけでなく、タスクごとの手法も整理されて記載されている。また、BLEUやROUGEといった伝統的な手法の概要や、最新手法との同一データセットでのメタ評価における性能の差なども記載されており、全体的に必要な情報がコンパクトにまとまっている印象がある。<br><br><img src="https://github.com/user-attachments/assets/dd9e49ee-5b08-45c4-9b82-2b9dcae12baa" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/a1a0708d-4f95-46ba-bda1-7c06c4c393cf" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Finetuning.html" target="_blank" rel="noopener noreferrer">#Finetuning</a>
<span class="issue_date">Issue Date: 2024-05-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1317" target="_blank" rel="noopener noreferrer" class="title-link">T5Score: Discriminative Fine-tuning of Generative Evaluation Metrics, Yiwei Qin+, N_A, EMNLP-Findings'23</a>
<span class="snippet"><span>GPT Summary</span>- 埋め込みベースのテキスト生成の評価には、教師付きの識別メトリクスと生成メトリクスの2つのパラダイムがあります。本研究では、教師付きと教師なしの信号を組み合わせたフレームワークを提案し、mT5をバックボーンとしてT5Scoreメトリクスを訓練しました。T5Scoreは他の既存のメトリクスと包括的な実証的比較を行い、セグメントレベルで最良のパフォーマンスを示しました。また、コードとモデルはGitHubで公開されています。</span>
<span class="snippet"><span>Comment</span><p>OpenReview: 


<a href="https://openreview.net/forum?id=2jibzAXJzH&noteId=rgNMHmjShZ" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=2jibzAXJzH&noteId=rgNMHmjShZ</a>


</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Annotation.html" target="_blank" rel="noopener noreferrer">#Annotation</a>
<span class="issue_date">Issue Date: 2024-05-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1304" target="_blank" rel="noopener noreferrer" class="title-link">Benchmarking Large Language Models for News Summarization, Tianyi Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsの成功の理由を理解するために、異なる事前学習方法、プロンプト、およびモデルスケールにわたる10つのLLMsに対する人間の評価を行った。その結果、モデルサイズではなく、指示の調整がLLMのゼロショット要約能力の鍵であることがわかった。また、LLMsの要約は人間の執筆した要約と同等と判断された。</span>
<span class="snippet"><span>Comment</span><p>- ニュース記事の高品質な要約を人間に作成してもらい、gpt-3.5を用いてLLM-basedな要約も生成<br><br>- annotatorにそれぞれの要約の品質をスコアリングさせたデータセットを作成</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1224" target="_blank" rel="noopener noreferrer" class="title-link">INSTRUCTSCORE: Explainable Text Generation Evaluation with Finegrained   Feedback, Wenda Xu+, N_A, EMNLP'23</a>
<span class="snippet"><span>GPT Summary</span>- 自動的な言語生成の品質評価には説明可能なメトリクスが必要であるが、既存のメトリクスはその判定を説明したり欠陥とスコアを関連付けることができない。そこで、InstructScoreという新しいメトリクスを提案し、人間の指示とGPT-4の知識を活用してテキストの評価と診断レポートを生成する。さまざまな生成タスクでInstructScoreを評価し、他のメトリクスを上回る性能を示した。驚くべきことに、InstructScoreは人間の評価データなしで最先端のメトリクスと同等の性能を達成する。</span>
<span class="snippet"><span>Comment</span><p>伝統的なNLGの性能指標の解釈性が低いことを主張する研究</p>
<p><img src="https://github.com/user-attachments/assets/4c4fe705-e0c5-41d1-b3c8-c084d85b77ba" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1220" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models Are State-of-the-Art Evaluators of Translation Quality, EAMT'23</a>
<span class="snippet"><span>GPT Summary</span>- GEMBAは、参照翻訳の有無に関係なく使用できるGPTベースの翻訳品質評価メトリックです。このメトリックは、ゼロショットのプロンプティングを使用し、4つのプロンプトバリアントを比較します。私たちの手法は、GPT 3.5以上のモデルでのみ機能し、最先端の精度を達成します。特に、英語からドイツ語、英語からロシア語、中国語から英語の3つの言語ペアで有効です。この研究では、コード、プロンプトテンプレート、およびスコアリング結果を公開し、外部の検証と再現性を可能にします。</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1041" target="_blank" rel="noopener noreferrer" class="title-link">From Sparse to Dense: GPT-4 Summarization with Chain of Density  Prompting, Griffin Adams+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- 要約は詳細でエンティティ中心的でありながら、理解しやすくすることが困難です。この課題を解決するために、私たちは「密度の連鎖」（CoD）プロンプトを使用して、GPT-4の要約を生成します。CoDによって生成された要約は抽象的であり、リードバイアスが少なく、人間に好まれます。また、情報量と読みやすさのトレードオフが存在することも示されました。CoD要約は無料で利用できます。</span>
<span class="snippet"><span>Comment</span><p>論文中のprompt例。InformativeなEntityのCoverageを増やすようにイテレーションを回し、各Entityに関する情報（前ステップで不足している情報は補足しながら）を具体的に記述するように要約を生成する。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c24ab8c0-06fa-49ea-9df7-f248ec18ba45" alt="image" loading="lazy"><br><br></p>
<p>人間が好むEntityのDensityにはある程度の閾値がある模様（でもこれは人や用途によって閾値が違うようねとは思う）。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d63c21e9-9179-4f8c-925f-ed435ecb1717" alt="image" loading="lazy"><br><br>人手評価とGPT4による5-scale の評価を実施している。定性的な考察としては、主題と直接的に関係ないEntityの詳細を述べるようになっても人間には好まれない（右例）ことが述べられている。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/900695ca-fbad-4d58-9388-2d2f86644e48" alt="image" loading="lazy"><br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d3b3afe2-15fa-4b40-95cb-51aa0f27d6db" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LM-based.html" target="_blank" rel="noopener noreferrer">#LM-based</a>
<a class="button" href="articles/Coherence.html" target="_blank" rel="noopener noreferrer">#Coherence</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/967" target="_blank" rel="noopener noreferrer" class="title-link">DiscoScore: Evaluating Text Generation with BERT and Discourse Coherence, Wei Zhao+, N_A, EACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、文章の一貫性を評価するための新しい指標であるDiscoScoreを紹介します。DiscoScoreはCentering理論に基づいており、BERTを使用して談話の一貫性をモデル化します。実験の結果、DiscoScoreは他の指標よりも人間の評価との相関が高く、システムレベルでの評価でも優れた結果を示しました。さらに、DiscoScoreの重要性とその優位性についても説明されています。</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/891" target="_blank" rel="noopener noreferrer" class="title-link">InfoMetIC: An Informative Metric for Reference-free Image Caption Evaluation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 自動画像キャプションの評価には、情報豊かなメトリック（InfoMetIC）が提案されています。これにより、キャプションの誤りや欠落した情報を詳細に特定することができます。InfoMetICは、テキストの精度スコア、ビジョンの再現スコア、および全体の品質スコアを提供し、人間の判断との相関も高いです。また、トークンレベルの評価データセットも構築されています。詳細はGitHubで公開されています。</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/866" target="_blank" rel="noopener noreferrer" class="title-link">WeCheck: Strong Factual Consistency Checker via Weakly Supervised Learning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 現在のテキスト生成モデルは、入力と矛盾するテキストを制御できないという課題があります。この問題を解決するために、私たちはWeCheckという弱教師付きフレームワークを提案します。WeCheckは、弱教師付きラベルを持つ言語モデルから直接訓練された実際の生成サンプルを使用します。さまざまなタスクでの実験結果は、WeCheckの強力なパフォーマンスを示し、従来の評価方法よりも高速で精度と効率を向上させています。</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/865" target="_blank" rel="noopener noreferrer" class="title-link">Improving Factuality of Abstractive Summarization without Sacrificing Summary Quality, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 事実性を意識した要約の品質向上に関する研究はあるが、品質を犠牲にすることなく事実性を向上させる手法がほとんどない。本研究では「Effective Factual Summarization」という技術を提案し、事実性と類似性の指標の両方で大幅な改善を示すことを示した。トレーニング中に競合を防ぐために2つの指標を組み合わせるランキング戦略を提案し、XSUMのFactCCでは最大6ポイント、CNN/DMでは11ポイントの改善が見られた。また、類似性や要約の抽象性には負の影響を与えない。</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/MultitaskLearning.html" target="_blank" rel="noopener noreferrer">#MultitaskLearning</a>
<a class="button" href="articles/Zero/FewShotLearning.html" target="_blank" rel="noopener noreferrer">#Zero/FewShotLearning</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/863" target="_blank" rel="noopener noreferrer" class="title-link">Few-Shot Data-to-Text Generation via Unified Representation and Multi-Source Learning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- この論文では、構造化データからテキストを生成する新しいアプローチを提案しています。提案手法は、さまざまな形式のデータを処理できる統一された表現を提供し、マルチタスクトレーニングやゼロショット学習などのシナリオでのパフォーマンスを向上させることを目指しています。実験結果は、提案手法が他の方法と比較して優れた性能を示していることを示しています。これは、データからテキスト生成フレームワークにおける重要な進歩です。</span>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/860" target="_blank" rel="noopener noreferrer" class="title-link">An Invariant Learning Characterization of Controlled Text Generation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 制御された生成では、予測器の訓練に使用される分布と異なるテキストの分布がある場合、パフォーマンスが低下することが示されている。この問題に対処するために、不変性を持つ予測器が効果的であるという考え方が提案されている。さらに、この特性を活かすための自然な解決策とヒューリスティックも提案されている。実験結果は、制御された生成における分布シフトの課題と不変性手法の潜在能力を示している。</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/859" target="_blank" rel="noopener noreferrer" class="title-link">Abstractive Summarizers are Excellent Extractive Summarizers, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、抽出型要約と要約型要約の相乗効果を探求し、シーケンス・トゥ・シーケンス・アーキテクチャを使用した3つの新しい推論アルゴリズムを提案しています。これにより、要約型システムが抽出型システムを超えることができることを示しました。また、要約型システムは抽出型のオラクル要約にさらされることなく、両方の要約を単一のモデルで生成できることも示しました。これは、抽出型ラベルの必要性に疑問を投げかけるものであり、ハイブリッドモデルの有望な研究方向を示しています。</span>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Argument.html" target="_blank" rel="noopener noreferrer">#Argument</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/855" target="_blank" rel="noopener noreferrer" class="title-link">ArgU: A Controllable Factual Argument Generator, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、高品質な論証を自動生成するために、制御コードを使用したニューラル論証生成器ArgUを提案します。また、論証スキームを特定するための大規模なデータセットを作成し、注釈付けとデータセット作成のフレームワークについて詳細に説明します。さらに、論証テンプレートを生成する推論戦略を試行し、多様な論証を自動的に生成することが可能であることを示します。</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Faithfulness.html" target="_blank" rel="noopener noreferrer">#Faithfulness</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/850" target="_blank" rel="noopener noreferrer" class="title-link">Faithfulness Tests for Natural Language Explanations, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、ニューラルモデルの説明の忠実性を評価するための2つのテストを提案しています。1つ目は、カウンターファクチュアルな予測につながる理由を挿入するためのカウンターファクチュアル入力エディタを提案し、2つ目は生成された説明から入力を再構築し、同じ予測につながる頻度をチェックするテストです。これらのテストは、忠実な説明の開発において基本的なツールとなります。</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/Faithfulness.html" target="_blank" rel="noopener noreferrer">#Faithfulness</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/848" target="_blank" rel="noopener noreferrer" class="title-link">Extractive is not Faithful: An Investigation of Broad Unfaithfulness Problems in Extractive Summarization, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、抽出的な要約の不正確さの問題について議論し、それを5つのタイプに分類します。さらに、新しい尺度であるExtEvalを提案し、不正確な要約を検出するために使用することを示します。この研究は、抽出的な要約の不正確さに対する認識を高め、将来の研究に役立つことを目指しています。</span>
<span class="snippet"><span>Comment</span><p>Extractive SummarizatinoのFaithfulnessに関する研究。<br><br>&gt;抽出的な要約は抽象的な要約の一般的な不正確さの問題にはあまり影響を受けにくいですが、それは抽出的な要約が正確であることを意味するのでしょうか？結論はノーです。<br><br>&gt;本研究では、抽出的な要約に現れる広範な不正確さの問題（非含意を含む）を5つのタイプに分類<br><br>&gt;不正確な共参照、不完全な共参照、不正確な談話、不完全な談話、および他の誤解を招く情報が含まれます。<br><br>&gt;私たちは、16の異なる抽出システムによって生成された1600の英語の要約を人間にラベル付けするように依頼しました。その結果、要約の30％には少なくとも5つの問題のうちの1つが存在することがわかりました。<br><br> <br><br> おもしろい。</p></span><br><br>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/846" target="_blank" rel="noopener noreferrer" class="title-link">Controllable Text Generation via Probability Density Estimation in the Latent Space, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、潜在空間での確率密度推定を用いた新しい制御フレームワークを提案しています。この手法は、可逆変換関数を使用して潜在空間の複雑な分布を単純なガウス分布にマッピングし、洗練された柔軟な制御を行うことができます。実験結果では、提案手法が属性の関連性とテキストの品質において強力なベースラインを上回り、新たなSOTAを達成していることが示されています。さらなる分析により、制御戦略の柔軟性が示されています。</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/843" target="_blank" rel="noopener noreferrer" class="title-link">MeetingBank: A Benchmark Dataset for Meeting Summarization, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 会議の要約技術の開発には注釈付きの会議コーパスが必要ですが、その欠如が問題となっています。本研究では、新しいベンチマークデータセットであるMeetingBankを提案しました。MeetingBankは、会議議事録を短いパッセージに分割し、特定のセグメントと対応させることで、会議の要約プロセスを管理しやすいタスクに分割することができます。このデータセットは、会議要約システムのテストベッドとして利用できるだけでなく、一般の人々が議会の意思決定の仕組みを理解するのにも役立ちます。ビデオリンク、トランスクリプト、参照要約などのデータを一般に公開し、会議要約技術の開発を促進します。</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/841" target="_blank" rel="noopener noreferrer" class="title-link">On Improving Summarization Factual Consistency from Natural Language Feedback, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、自然言語の情報フィードバックを活用して要約の品質とユーザーの好みを向上させる方法を調査しました。DeFactoという高品質なデータセットを使用して、要約の編集や修正に関する自然言語生成タスクを研究しました。また、微調整された言語モデルを使用して要約の品質を向上させることも示しました。しかし、大規模な言語モデルは制御可能なテキスト生成には向いていないことがわかりました。</span>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/837" target="_blank" rel="noopener noreferrer" class="title-link">Tailor: A Soft-Prompt-Based Approach to Attribute-Based Controlled Text Generation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 属性ベースの制御されたテキスト生成（CTG）では、望ましい属性を持つ文を生成することが目指されている。従来の手法では、ファインチューニングや追加の属性分類器を使用していたが、ストレージと推論時間の増加が懸念されていた。そこで、本研究では効率的なパラメータを使用した属性ベースのCTGを提案している。具体的には、各属性を事前学習された連続ベクトルとして表現し、固定された事前学習言語モデルをガイドして属性を満たす文を生成する。さらに、2つの解決策を提供して、組み合わせを強化している。実験の結果、追加のトレーニングパラメータのみで効果的な改善が実現できることが示された。</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/835" target="_blank" rel="noopener noreferrer" class="title-link">Table and Image Generation for Investigating Knowledge of Entities in Pre-trained Vision and Language Models, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、Vision＆Language（V＆L）モデルにおけるエンティティの知識の保持方法を検証するために、テーブルと画像の生成タスクを提案します。このタスクでは、エンティティと関連する画像の知識を含むテーブルを生成する第一の部分と、キャプションとエンティティの関連知識を含むテーブルから画像を生成する第二の部分があります。提案されたタスクを実行するために、Wikipediaの約20万のinfoboxからWikiTIGデータセットを作成しました。最先端のV＆LモデルOFAを使用して、提案されたタスクのパフォーマンスを評価しました。実験結果は、OFAが一部のエンティティ知識を忘れることを示しています。</span>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/834" target="_blank" rel="noopener noreferrer" class="title-link">Focused Prefix Tuning for Controllable Text Generation, Ma+, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、注釈のない属性によって制御可能なテキスト生成データセットのパフォーマンスが低下する問題に対して、「focused prefix tuning（FPT）」という手法を提案しています。FPTは望ましい属性に焦点を当てることで、制御精度とテキストの流暢さを向上させることができます。また、FPTは複数属性制御タスクにおいても、既存のモデルを再トレーニングすることなく新しい属性を制御する柔軟性を持ちながら、制御精度を保つことができます。</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/831" target="_blank" rel="noopener noreferrer" class="title-link">Learning to Imagine: Visually-Augmented Natural Language Generation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、視覚情報を活用した自然言語生成のためのLIVEという手法を提案しています。LIVEは、事前学習済み言語モデルを使用して、テキストに基づいて場面を想像し、高品質な画像を合成する方法です。また、CLIPを使用してテキストの想像力を評価し、段落ごとに画像を生成します。さまざまな実験により、LIVEの有効性が示されています。コード、モデル、データは公開されています。</span>
<span class="snippet"><span>Comment</span><p>&gt;まず、テキストに基づいて場面を想像します。入力テキストに基づいて高品質な画像を合成するために拡散モデルを使用します。次に、CLIPを使用して、テキストが想像力を喚起できるかを事後的に判断します。最後に、私たちの想像力は動的であり、段落全体に1つの画像を生成するのではなく、各文に対して合成を行います。<br><br><br><br>興味深い</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Novelty.html" target="_blank" rel="noopener noreferrer">#Novelty</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/828" target="_blank" rel="noopener noreferrer" class="title-link">[TACL] How much do language models copy from their training data? Evaluating linguistic novelty in text generation using RAVEN, TACL'23</a>
<span class="snippet"><span>GPT Summary</span>- この研究では、言語モデルが生成するテキストの新規性を評価するための分析スイートRAVENを紹介しています。英語で訓練された4つのニューラル言語モデルに対して、局所的な構造と大規模な構造の新規性を評価しました。結果として、生成されたテキストは局所的な構造においては新規性に欠けており、大規模な構造においては人間と同程度の新規性があり、時には訓練セットからの重複したテキストを生成することもあります。また、GPT-2の詳細な手動分析により、組成的および類推的な一般化メカニズムの使用が示され、新規テキストが形態的および構文的に妥当であるが、意味的な問題が比較的頻繁に発生することも示されました。</span>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/QuestionGeneration.html" target="_blank" rel="noopener noreferrer">#QuestionGeneration</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/824" target="_blank" rel="noopener noreferrer" class="title-link">Adaptive and Personalized Exercise Generation for Online Language Learning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、オンライン言語学習のための適応的な演習生成の新しいタスクを研究しました。学習履歴から学生の知識状態を推定し、その状態に基づいて個別化された演習文を生成するモデルを提案しました。実データを用いた実験結果から、学生の状態に応じた演習を生成できることを示しました。さらに、教育アプリケーションでの利用方法についても議論し、学習の効率化を促進できる可能性を示しました。</span>
<span class="snippet"><span>Comment</span><p>Knowledge Tracingで推定された習熟度に基づいて、エクササイズを自動生成する研究。KTとNLGが組み合わさっており、非常におもしろい。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/975a4de3-4f68-4dc6-beb4-5ad32b706959" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-07-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/813" target="_blank" rel="noopener noreferrer" class="title-link">Explicit Syntactic Guidance for Neural Text Generation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- 既存のテキスト生成モデルには制約があり、シーケンス・トゥ・シーケンスのパラダイムに従っている。私たちは、構文にガイドされた生成スキーマを提案し、構文解析木に従ってシーケンスを生成する。提案手法は、パラフレーズ生成と機械翻訳の実験でベースラインを上回り、解釈可能性、制御可能性、多様性の観点でも効果的であることを示している。</span>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/770" target="_blank" rel="noopener noreferrer" class="title-link">SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling  with Backtracking, Chris Cundy+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- 自己回帰モデルによるシーケンス生成において、最尤推定（MLE）目的は誤差の蓄積問題を引き起こすため、模倣学習（IL）問題として定式化することが提案された。ILフレームワークを使用することで、バックトラッキングを組み込むことができ、誤差の蓄積問題が軽減される。提案手法であるSequenceMatchは、敵対的なトレーニングや大規模なアーキテクチャの変更なしに実装でき、SequenceMatch-$\chi^2$発散を使用することができる。実験的に、SequenceMatchトレーニングは、言語モデルによるテキスト生成においてMLEよりも改善をもたらすことが示された。</span>
<span class="snippet"><span>Comment</span><p>backspaceアクションをテキスト生成プロセスに組み込むことで、out of distributionを引き起こすトークンを元に戻すことで、生成エラーを軽減させることができる。<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e22d059f-5475-417c-aea2-d1fd55b6c23a" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/594" target="_blank" rel="noopener noreferrer" class="title-link">Controlled Text Generation with Natural Language Instructions, Wangchunshu Zhou+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、自然言語の説明と制約のデモンストレーションに基づいて、異なる制約を組み込むことができる制御されたテキスト生成フレームワークであるInstructCTGを提案しています。制約を自然言語の指示に言い換えて、弱く監督されたトレーニングデータを形成し、事前にトレーニングされた言語モデルを微調整して、さまざまなタイプの制約を組み込むことができます。InstructCTGは、異なる制約タイプに対してより柔軟であり、生成品質と速度にはほとんど影響を与えず、再トレーニングなしに新しい制約に適応することができます。</span>
<span class="snippet"><span>Comment</span><p><img src="https://user-images.githubusercontent.com/12249301/235351783-1435816a-b51a-4379-b4b5-cf3097b70de5.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/573" target="_blank" rel="noopener noreferrer" class="title-link">Tractable Control for Autoregressive Language Generation, Zhang+, UCLA, arXiv'23</a>
&lt;span class=\"snippet\"&gt;<span>Comment</span><p>自然言語生成モデルで、何らかのシンプルなconstiaint αの元p\(xi|xi-1,α)を生成しようとしても計算ができない。このため、言語モデルをfinetuningするか、promptで制御するか、などがおこなわれる。しかしこの方法は近似的な解法であり、αがたとえシンプルであっても（何らかの語尾を付与するなど）、必ずしも満たした生成が行われるとは限らない。これは単に言語モデルがautoregressiveな方法で次のトークンの分布を予測しているだけであることに起因している。そこで、この問題を解決するために、tractable probabilistic model（TPM）を導入し、解決した。<br>評価の結果、CommonGenにおいて、SoTAを達成した。<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/235130061-21e51e59-dbfa-4c64-bd7b-27f0de2618c0.jpeg\" alt=\"image\" loading=\"lazy\" /&gt;</p>
<p>尚、TPMについては要勉強である</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/StructuredData.html" target="_blank" rel="noopener noreferrer">#StructuredData</a>
<span class="issue_date">Issue Date: 2023-10-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1097" target="_blank" rel="noopener noreferrer" class="title-link">MURMUR: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text  Generation, Swarnadeep Saha+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、半構造化データからのテキスト生成における多段階の推論を行うためのMURMURという手法を提案しています。MURMURは、特定の言語的および論理的なスキルを持つニューラルモジュールと記号モジュールを組み合わせ、ベストファーストサーチ手法を使用して推論パスを生成します。実験結果では、MURMURは他のベースライン手法に比べて大幅な改善を示し、また、ドメイン外のデータでも同等の性能を達成しました。さらに、人間の評価では、MURMURは論理的に整合性のある要約をより多く生成することが示されました。</span>
<a class="button" href="articles/BeamSearch.html" target="_blank" rel="noopener noreferrer">#BeamSearch</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/998" target="_blank" rel="noopener noreferrer" class="title-link">Momentum Calibration for Text Generation, Xingxing Zhang+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、テキスト生成タスクにおいてMoCa（Momentum Calibration）という手法を提案しています。MoCaは、ビームサーチを用いた遅く進化するサンプルを動的に生成し、これらのサンプルのモデルスコアを実際の品質に合わせるように学習します。実験結果は、MoCaが強力な事前学習済みTransformerを改善し、最先端の結果を達成していることを示しています。</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/BeamSearch.html" target="_blank" rel="noopener noreferrer">#BeamSearch</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/997" target="_blank" rel="noopener noreferrer" class="title-link">BRIO: Bringing Order to Abstractive Summarization, Yixin Liu+, N_A, ACL'22</a>
<span class="snippet"><span>GPT Summary</span>- 従来の抽象的要約モデルでは、最尤推定を使用して訓練されていましたが、この方法では複数の候補要約を比較する際に性能が低下する可能性があります。そこで、非確定論的な分布を仮定し、候補要約の品質に応じて確率を割り当てる新しい訓練パラダイムを提案しました。この手法により、CNN/DailyMailとXSumのデータセットで最高の結果を達成しました。さらに、モデルが候補要約の品質とより相関のある確率を推定できることも示されました。</span>
<span class="snippet"><span>Comment</span><p>ビーム内のトップがROUGEを最大化しているとは限らなかったため、ROUGEが最大となるような要約を選択するようにしたら性能爆上げしましたという研究。<br>実質現在のSoTA</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/987" target="_blank" rel="noopener noreferrer" class="title-link">SMART: Sentences as Basic Units for Text Evaluation, Reinald Kim Amplayo+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、テキスト生成の評価指標の制限を緩和するために、新しい指標であるSMARTを提案する。SMARTは文を基本的なマッチング単位とし、文のマッチング関数を使用して候補文と参照文を評価する。また、ソースドキュメントの文とも比較し、評価を可能にする。実験結果は、SMARTが他の指標を上回ることを示し、特にモデルベースのマッチング関数を使用した場合に有効であることを示している。また、提案された指標は長い要約文でもうまく機能し、特定のモデルに偏りが少ないことも示されている。</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/973" target="_blank" rel="noopener noreferrer" class="title-link">InfoLM: A New Metric to Evaluate Summarization &amp; Data2Text Generation, Pierre Colombo+, N_A, AAAI'22</a>
<span class="snippet"><span>GPT Summary</span>- 自然言語生成システムの品質評価は高価であり、人間の注釈に頼ることが一般的です。しかし、自動評価指標を使用することもあります。本研究では、マスクされた言語モデルを使用した評価指標であるInfoLMを紹介します。この指標は同義語を処理することができ、要約やデータ生成の設定で有意な改善を示しました。</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/972" target="_blank" rel="noopener noreferrer" class="title-link">WIDAR -- Weighted Input Document Augmented ROUGE, Raghav Jain+, N_A, ECIR'22</a>
<span class="snippet"><span>GPT Summary</span>- 自動テキスト要約の評価において、ROUGEメトリックには制約があり、参照要約の利用可能性に依存している。そこで、本研究ではWIDARメトリックを提案し、参照要約だけでなく入力ドキュメントも使用して要約の品質を評価する。WIDARメトリックは一貫性、整合性、流暢さ、関連性の向上をROUGEと比較しており、他の最先端のメトリックと同等の結果を短い計算時間で得ることができる。</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<span class="issue_date">Issue Date: 2023-08-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/912" target="_blank" rel="noopener noreferrer" class="title-link">Explaining Patterns in Data with Language Models via Interpretable  Autoprompting, Chandan Singh+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、大規模言語モデル（LLMs）を使用してデータのパターンを説明する能力を探求しました。具体的には、事前学習済みのLLMを使用してデータを説明する自然言語の文字列を生成するアルゴリズムを導入しました。実験結果は、このアルゴリズムが正確なデータセットの説明を見つけ出すことができることを示しています。また、生成されるプロンプトは人間にも理解可能であり、実世界のデータセットやfMRIデータセットで有用な洞察を提供することができることも示されました。</span>
<span class="snippet"><span>Comment</span><p>OpenReview: 


<a href="https://openreview.net/forum?id=GvMuB-YsiK6" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=GvMuB-YsiK6</a>


</p>
<p>データセット（中に存在するパターンの説明）をLLMによって生成させる研究<br>![Image](https://github.com/user-attachments/assets/df70f8c2-6eda-412f-84e0-92ffe7152a39)<br>![Image](https://github.com/user-attachments/assets/42b4f4f9-6f6c-4e45-8c7c-db76c5fd9932)</p></span><br><br>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/861" target="_blank" rel="noopener noreferrer" class="title-link">An Extensible Plug-and-Play Method for Multi-Aspect Controllable Text  Generation, Xuancheng Huang+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、テキスト生成において複数の側面を制御する方法について研究しました。従来の方法では、プレフィックスの相互干渉により制約が低下し、未知の側面の組み合わせを制御することが制限されていました。そこで、トレーニング可能なゲートを使用してプレフィックスの介入を正規化し、相互干渉の増加を抑制する方法を提案しました。この方法により、トレーニング時に未知の制約を低コストで拡張することができます。さらに、カテゴリカルな制約と自由形式の制約の両方を処理する統一された方法も提案しました。実験により、提案手法が制約の正確さ、テキストの品質、拡張性においてベースラインよりも優れていることが示されました。</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2614" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DART: Open-Domain Structured Data Record to Text Generation, Linyong Nan+, NAACL'21</a>
<span class="snippet"><span>GPT Summary</span>- DARTは82,000以上のインスタンスを持つオープンドメインの構造化データからテキスト生成のためのデータセットであり、表形式のデータから意味的トリプルを抽出する手法を提案。ツリーオントロジーアノテーションや質問-回答ペアの変換を活用し、最小限のポストエディティングで異種ソースを統合。DARTは新たな課題を提起し、WebNLG 2017での最先端結果を示すことで、ドメイン外の一般化を促進することを証明。データとコードは公開されている。</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Annotation.html" target="_blank" rel="noopener noreferrer">#Annotation</a>
<span class="issue_date">Issue Date: 2024-05-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1306" target="_blank" rel="noopener noreferrer" class="title-link">The Perils of Using Mechanical Turk to Evaluate Open-Ended Text  Generation, Marzena Karpinska+, N_A, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- 最近のテキスト生成の研究は、オープンエンドのドメインに注力しており、その評価が難しいため、多くの研究者がクラウドソーシングされた人間の判断を収集してモデリングを正当化している。しかし、多くの研究は重要な詳細を報告しておらず、再現性が妨げられていることがわかった。さらに、労働者はモデル生成のテキストと人間による参照テキストを区別できないことが発見され、表示方法を変更することで改善されることが示された。英語教師とのインタビューでは、モデル生成のテキストを評価する際の課題について、より深い洞察が得られた。</span>
<span class="snippet"><span>Comment</span><p>Open-endedなタスクに対するAMTの評価の再現性に関する研究。先行研究をSurveyしたところ、再現のために重要な情報（たとえば、workerの資格、費用、task descriptions、annotator間のagreementなど）が欠落していることが判明した。<br><br>続いて、expertsとAMT workerに対して、story generationの評価を実施し、GPT2が生成したストーリーと人間が生成したストーリーを、後者のスコアが高くなることを期待して依頼した。その結果<br><br>- AMTのratingは、モデルが生成したテキストと、人間が生成したテキストをreliableに区別できない<br><br>- 同一のタスクを異なる日程で実施をすると、高い分散が生じた<br><br>- 多くのAMT workerは、評価対象のテキストを注意深く読んでいない<br><br>- Expertでさえモデルが生成したテキストを読み判断するのには苦戦をし、先行研究と比較してより多くの時間を費やし、agreementが低くなることが分かった<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1dc01c56-88b0-4bea-869b-f396d65701cc" alt="image" loading="lazy"><br><br></p>
<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/892" target="_blank" rel="noopener noreferrer">Can Large Language Models Be an Alternative to Human Evaluations? Cheng-Han Chiang, Hung-yi Lee, ACL'23</a>
 において、低品質なwork forceが人手評価に対して有害な影響を与える、という文脈で本研究が引用されている</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1221" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Experts, Errors, and Context: A Large-Scale Study of Human Evaluation  for Machine Translation, Markus Freitag+, arXiv'21</a>
<span class="snippet"><span>GPT Summary</span>- 機械翻訳システムの人間による評価は難しく、標準的な手続きが欠如している。そこで、MQMフレームワークに基づく評価方法論を提案し、WMT 2020のトップシステムの出力をプロの翻訳者による注釈でスコアリングした。分析の結果、クラウドワーカーによる評価とは異なり、人間の出力が機械の出力より好まれることが示された。また、事前学習された埋め込みに基づく自動メトリクスが人間の評価を上回ることも明らかになった。コーパスは今後の研究のために公開される。</span>
<span class="snippet"><span>Comment</span><p>embedding basedなNLGの性能指標が、意味の等価性や流暢性を評価できる一方、適用範囲が限定的で柔軟性に欠けることを示した研究</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/976" target="_blank" rel="noopener noreferrer" class="title-link">The Feasibility of Embedding Based Automatic Evaluation for Single Document Summarization, EMNLP-IJCNLP'21, Sun+</a>
<span class="snippet"><span>Comment</span><p>__translate: ROUGE is widely used to automatically evaluate summarization systems. However, ROUGE measures semantic overlap between a system summary and a human reference on word-string level, much at odds with the contemporary treatment of semantic meaning. Here we present a suite of experiments on using distributed representations for evaluating summarizers, both in reference-based and in reference-free setting. Our experimental results show that the max value over each dimension of the summary ELMo word embeddings is a good representation that results in high correlation with human ratings. Averaging the cosine similarity of all encoders we tested yields high correlation with manual scores in reference-free setting. The distributed representations outperform ROUGE in recent corpora for abstractive news summarization but are less good on test data used in past evaluations.</p>
<p>C-ELMO/C-SBERT</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/975" target="_blank" rel="noopener noreferrer" class="title-link">A Training-free and Reference-free Summarization Evaluation Metric via Centrality-weighted Relevance and Self-referenced Redundancy, Chen+, ACL-IJCNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- 参照ベースと教師ありの要約評価指標の制約を回避するために、トレーニングフリーかつ参照フリーの要約評価指標を提案する。この指標は、文の中心性によって重み付けされた概念参照と要約との関連性スコアと、自己参照の冗長性スコアから構成される。関連性スコアは擬似参照と要約との間で計算され、重要度のガイダンスを提供する。要約の冗長性スコアは要約内の冗長な情報を評価するために計算される。関連性スコアと冗長性スコアを組み合わせて、要約の最終評価スコアを生成する。徹底的な実験により、提案手法が既存の手法を大幅に上回ることが示された。ソースコードはGitHubで公開されている。</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/QA-based.html" target="_blank" rel="noopener noreferrer">#QA-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/974" target="_blank" rel="noopener noreferrer" class="title-link">QuestEval: Summarization Asks for Fact-based Evaluation, Thomas Scialom+, N_A, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- 要約の評価は未解決の課題であり、既存の評価指標は限定的であり、人間の判断との相関が低い。そこで、本研究では質問応答モデルを利用した評価指標QuestEvalを提案する。QuestEvalは正解の参照を必要とせず、一貫性、結束性、流暢さ、関連性の4つの評価次元において人間の判断との相関を大幅に改善することが実験により示された。</span>
<span class="snippet"><span>Comment</span><p>QuestEval</p>
<p>
<strong># 概要<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/984" target="_blank" rel="noopener noreferrer">SummEval: Re-evaluating Summarization Evaluation, Fabbri+, TACL'21</a>
</strong>
<br>
 によって提案されてきたメトリックがROUGEに勝てていないことについて言及し、より良い指標を提案。<br><br>- precision / recall-based な QA metricsを利用してよりロバスト<br><br>- 生成されるqueryのsaliencyを学習する手法を提案することで、information selectionの概念を導入した<br><br>- CNN/Daily Mail, XSUMで評価した結果、SoTAな結果を獲得し、特にFactual Consistencyの評価に有用なことを示した<br><br><br><br>
<strong># Question-based framework<br><br>prerainedなT5を利用しQAに回答するcomponent（question, Textがgivenな時answerを生成するモデル）を構築する。text Tに対するquery qに対してrと回答する確率をQ\_A\(r|T, q)とし、Q\_A\(T, q)をモデルによってgreedyに生成された回答とする。Questionが与えられた時、Summary内に回答が含まれているかは分からない。そのため、unanswerable token εもQA componentに含める。<br><br>QG componentとしては、answer-source documentが与えられたときに人間が生成したquestionを生成できるようfinetuningされたT5モデルを利用する。テスト時は、ソースドキュメントと、システム要約がgivenなときに、はじめにQG modelを条件付けするためのanswerのsetを選択する。&lt;a href=\"https://github.com/AkihikoWatanabe/paper\_notes/issues/1007\" target=\"\_blank\" rel=\"noopener noreferrer\"&gt;Asking and Answering Questions to Evaluate the Factual Consistency of Summaries, Wang, ACL'20&lt;/a&gt;
</strong>
<br>
 にならい、ソースドキュメントの全ての固有名詞と名詞をanswerとみなす。そして、それぞれの選択されたanswerごとに、beam searchを用いてquestionを生成する。そして、QAモデルが誤った回答をした場合、そのようなquestionはフィルタリングする。text Tにおいて、Q_A(T, q) = rとなるquestion-answer pairs (q, r)の集合を、Q_G(T)と表記する。<br><br><br><br>
<strong># QuestEval metric<br><br>## Precision<br><br>source documentをD, システム要約をSとしたときに、Precision, Recallを以下の式で測る：<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3c1092a6-5a6e-494b-8ec1-a30fdc8ad96c" alt="image" loading="lazy"><br><br>question生成時は要約から生成し、生成されたquestionに回答する際はsource documentを利用し、回答の正誤に対してF1スコアを測定する。F1スコアは、ground truthと予測された回答を比較することによって測定され、回答がexact matchした場合に1, common tokenが存在しない場合に0を返す。D, Sで条件付けされたときに、回答が変わってしまう場合は要約がinconsistentだとみなせる、というintuitionからきている。<br><br>## Recall<br><br>要約はfactual informationを含むべきのみならず(precision)、ソーステキストの重要な情報を含むべきである(recall)。<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/943" target="_blank" rel="noopener noreferrer">Answers Unite! Unsupervised Metrics for Reinforced Summarization Models, Scialom+, EMNLP-IJCNLP'19</a>
</strong>
<br>
をquery weighter Wを導入することで拡張し、recallを下記で定義する：<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cd44efcd-ca82-43cc-98db-13b697d86068" alt="image" loading="lazy"><br><br>ここで、Q_G(D)は、ソーステキストDにおけるすべてのQA pairの集合、W(q, D)はDに対するqの重みである。<br><br> <br><br>
<strong>## Answerability and F1<br><br>Factoid QAモデルは一般的に、predicted answerとground truthのoverlapによって（F1）評価されている。しかし"ACL"と"Association for Computational Linguistics"のように、同じ回答でも異なる方法で表現される可能性がある。この例では、F1スコアは0となる（共通のtokenがないため）。<br><br>これを回避するために、<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/943" target="_blank" rel="noopener noreferrer">Answers Unite! Unsupervised Metrics for Reinforced Summarization Models, Scialom+, EMNLP-IJCNLP'19</a>
</strong>
<br>
 と同様に1-Q_A(ε)を利用する。 <br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/bb5379a9-02eb-438a-8bea-3729103bad7a" alt="image" loading="lazy"><br><br><br><br></p>
<p>QG component, QA componentで利用するT5は、それぞれ[SQuAD-v2](


<a href="https://huggingface.co/datasets/squad_v2)%E3%81%A8%E3%80%81NewsQA%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/squad_v2)と、NewsQAデータセット</a>


<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1142" target="_blank" rel="noopener noreferrer">NewsQA: A Machine Comprehension Dataset, Adam Trischler+, N/A, arXiv'16</a>
 によってfinetuningしたものを利用する。</p></span><br><br>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DialogueGeneration.html" target="_blank" rel="noopener noreferrer">#DialogueGeneration</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/QA-based.html" target="_blank" rel="noopener noreferrer">#QA-based</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/966" target="_blank" rel="noopener noreferrer" class="title-link">Q2: Evaluating Factual Consistency in Knowledge-Grounded Dialogues via Question Generation and Question Answering, Honovich+, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、ニューラルな知識に基づく対話生成モデルの信頼性と適用範囲の制限についての問題を解決するため、自動的な質問生成と質問応答を使用した事実的な整合性の自動評価尺度を提案します。この尺度は、自然言語推論を使用して回答スパンを比較することで、以前のトークンベースのマッチングよりも優れた評価を行います。また、新しいデータセットを作成し、事実的な整合性の手動アノテーションを行い、他の尺度とのメタ評価を行いました。結果として、提案手法が人間の判断と高い相関を示しました。</span>
<span class="snippet"><span>Comment</span><p>（knowledge-grounded; 知識に基づいた）対話に対するFactual ConsistencyをReference-freeで評価できるQGQA手法。機械翻訳やAbstractive Summarizationの分野で研究が進んできたが、対話では<br><br>- 対話履歴、個人の意見、ユーザに対する質問、そして雑談  <br><br><br><br>といった外部知識に対するconsistencyが適切ではない要素が多く存在し、よりチャレンジングなタスクとなっている。<br><br>また、そもそも対話タスクはopen-endedなタスクなため、Reference-basedな手法は現実的ではなく、Reference-freeな手法が必要と主張。<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/979808f2-d31a-49b0-bd25-aba1f1a81d4a" alt="image" loading="lazy"><br><br><br><br>手法の概要としては以下。ユーザの発話からQuestion Generation (QG)を実施し、Question-Answer Candidate Pairを作成する。そして、生成したQuestionをベースとなる知識から回答させ（QA）、その回答結果とAnswer Candidateを比較することでFactual Consistencyを測定する。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e6582686-2ed2-478a-8146-ec9834679df6" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/QA-based.html" target="_blank" rel="noopener noreferrer">#QA-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/961" target="_blank" rel="noopener noreferrer" class="title-link">QACE: Asking Questions to Evaluate an Image Caption, Lee+, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、画像キャプションの評価において、Question Generation（QG）とQuestion Answering（QA）システムに基づいた質問応答メトリックであるQACEを提案する。QACEは評価対象のキャプションに対して質問を生成し、その内容を参照キャプションまたはソース画像に対して質問することで確認する。QACE_Refというメトリックを開発し、最先端のメトリックと競合する結果を報告する。さらに、参照ではなく画像自体に直接質問をするQACE_Imgを提案する。QACE_ImgにはVisual-QAシステムが必要であり、Visual-T5という抽象的なVQAシステムを提案する。QACE_Imgはマルチモーダルで参照を必要とせず、説明可能なメトリックである。実験の結果、QACE_Imgは他の参照を必要としないメトリックと比較して有利な結果を示した。</span>
<span class="snippet"><span>Comment</span><p>Image Captioningを評価するためのQGQAを提案している。candidateから生成した質問を元画像, およびReferenceを用いて回答させ、candidateに基づいた回答と回答の結果を比較することで評価を実施する。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/552b3bfd-48a6-4915-af96-e8ae91e760dc" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2023-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/538" target="_blank" rel="noopener noreferrer" class="title-link">Refocusing on Relevance: Personalization in NLG, Shiran Dudy+, Department of Computer Science University of Colorado, EMNLP'21</a>
<span class="snippet"><span>Comment</span><p>従来のNLGはソーステキストに焦点を当て、ターゲットを生成することに注力してきた。が、ユーザの意図やcontextがソーステキストだけに基づいて復元できない場合、このアプローチでは不十分であることを指摘。<br><br>この研究ではNLGシステムが追加のcontextを利用することに大きな重点をおくべきであり、IR等で活用されているrelevancyをユーザ指向のテキスト生成タスクを設計するための重要な指標として考えることを提案している。</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Game.html" target="_blank" rel="noopener noreferrer">#Game</a>
<span class="issue_date">Issue Date: 2022-09-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/487" target="_blank" rel="noopener noreferrer" class="title-link">Generating Racing Game Commentary from Vision, Language, and Structured Data, Tatsuya+, INLG'21</a>
<span class="snippet"><span>Comment</span><p>データセット: 


<a href="https://kirt.airc.aist.go.jp/corpus/ja/RacingCommentary" target="_blank" rel="noopener noreferrer">https://kirt.airc.aist.go.jp/corpus/ja/RacingCommentary</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2022-08-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/472" target="_blank" rel="noopener noreferrer" class="title-link">Biomedical Data-to-Text Generation via Fine-Tuning Transformers, Ruslan+, INLG'21</a>
<span class="snippet"><span>Comment</span><p>biomedical domainの新たなdata2textデータセットを提供。事前学習済みのBART, T5等をfinetuningすることで高精度にテキストが生成できることを示した。</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2021-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/409" target="_blank" rel="noopener noreferrer" class="title-link">過去情報の内容選択を取り入れた スポーツダイジェストの自動生成, 加藤+, 東工大, NLP'21</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2021-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/405" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Prefix-Tuning: Optimizing Continuous Prompts for Generation, Xiang Lisa Li+, arXiv'21, 2021.01</a>
<span class="snippet"><span>GPT Summary</span>- プレフィックスチューニングは、ファインチューニングの軽量な代替手段であり、言語モデルのパラメータを固定しつつ、タスク特有の小さなベクトルを最適化する手法です。これにより、少ないパラメータで同等のパフォーマンスを達成し、低データ設定でもファインチューニングを上回る結果を示しました。</span>
<span class="snippet"><span>Comment</span><p>言語モデルをfine-tuningする際，エンコード時に「接頭辞」を潜在表現として与え，「接頭辞」部分のみをfine-tuningすることで（他パラメータは固定），より少量のパラメータでfine-tuningを実現する方法を提案．接頭辞を潜在表現で与えるこの方法は，GPT-3のpromptingに着想を得ている．fine-tuningされた接頭辞の潜在表現のみを配布すれば良いので，非常に少量なパラメータでfine-tuningができる．<br><br><br><br>table-to-text, summarizationタスクで，一般的なfine-tuningやAdapter（レイヤーの間にアダプターを挿入しそのパラメータだけをチューニングする手法）といった効率的なfine-tuning手法と比較．table-to-textでは、250k (元のモデルの 0.1%) ほどの数のパラメータを微調整するだけで、全パラメータをfine-tuningするのに匹敵もしくはそれ以上の性能を達成．<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/132679791-87ad130d-8a7e-4549-a311-f84400a3787b.png" alt="image" loading="lazy"><br><br></p>
<p>Hugging Faceの実装を利用したと論文中では記載されているが，fine-tuningする前の元の言語モデル（GPT-2）はどのように準備したのだろうか．Hugging Faceのpretrained済みのGPT-2を使用したのだろうか．</p>
<p>autoregressive LM (GPT-2)と，encoder-decoderモデル（BART）へPrefix Tuningを適用する場合の模式図<br><br><img src="https://user-images.githubusercontent.com/12249301/132681736-0ea4b13f-71cb-41ba-ae17-027e8bf54cc0.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Composition.html" target="_blank" rel="noopener noreferrer">#Composition</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<a class="button" href="articles/CommonsenseReasoning.html" target="_blank" rel="noopener noreferrer">#CommonsenseReasoning</a>
<span class="issue_date">Issue Date: 2025-07-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2330" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CommonGen: A Constrained Text Generation Challenge for Generative   Commonsense Reasoning, Bill Yuchen Lin+, EMNLP'20 Findings</a>
<span class="snippet"><span>GPT Summary</span>- 生成的常識推論をテストするためのタスクCommonGenを提案し、35,000の概念セットに基づく79,000の常識的記述を含むデータセットを構築。タスクは、与えられた概念を用いて一貫した文を生成することを求め、関係推論と構成的一般化能力が必要。実験では、最先端モデルと人間のパフォーマンスに大きなギャップがあることが示され、生成的常識推論能力がCommonsenseQAなどの下流タスクに転送可能であることも確認。</span>
<span class="snippet"><span>Comment</span><p>ベンチマークの概要。複数のconceptが与えられた時に、それらconceptを利用した常識的なテキストを生成するベンチマーク。concept間の関係性を常識的な知識から推論し、Unseenなconceptの組み合わせでも意味を構成可能な汎化性能が求められる。<br><img src="https://github.com/user-attachments/assets/2ebb8c0d-88f7-4858-ac43-29f341c586ec" alt="image" loading="lazy"></p>
<p>PJ page:


<a href="https://inklab.usc.edu/CommonGen/" target="_blank" rel="noopener noreferrer">https://inklab.usc.edu/CommonGen/</a>


</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1222" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BLEU might be Guilty but References are not Innocent, Markus Freitag+, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- 機械翻訳の自動評価指標の質が疑問視される中、参照の性質が評価に与える影響を研究。異なる参照収集方法を比較し、翻訳の多様性不足に対抗するために言語学者によるパラフレーズタスクを開発。これにより、WMT 2019の英独翻訳やバックトランスレーションで人間の評価との相関が向上。多参照BLEUの限界を指摘し、より効果的な評価方法を提案。</span>
<span class="snippet"><span>Comment</span><p>surface levelのNLGの性能指標がsemanticを評価できないことを示した研究</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/977" target="_blank" rel="noopener noreferrer" class="title-link">Unsupervised Reference-Free Summary Quality Evaluation via Contrastive  Learning, Hanlu Wu+, N_A, EMNLP'20</a>
<span class="snippet"><span>GPT Summary</span>- 本研究では、参照要約なしで要約の品質を評価するために教師なしの対照的学習を提案しています。新しいメトリックを設計し、ランキング損失でモデルを訓練することで、要約品質の異なる側面に関する異なるタイプのネガティブサンプルを構築します。実験結果は、参照要約なしでも他のメトリックよりも優れた評価方法であることを示しています。また、提案手法が一般的かつ転移可能であることも示されています。</span>
<span class="snippet"><span>Comment</span><p>LS_Score</p>
<p>色々なメトリックが簡潔にまとまっている</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/668" target="_blank" rel="noopener noreferrer" class="title-link">BERTScore: Evaluating Text Generation with BERT, Tianyi Zhang+, N_A, ICLR'20</a>
<span class="snippet"><span>GPT Summary</span>- BERTScoreは、文脈埋め込みを使用してトークンの類似度を計算するテキスト生成の自動評価メトリックであり、363の機械翻訳および画像キャプションシステムの出力を使用して評価されました。BERTScoreは、既存のメトリックよりも人間の判断との相関が高く、より強力なモデル選択性能を提供し、敵対的な言い換え検出タスクにおいてもより堅牢であることが示されました。</span>
<span class="snippet"><span>Comment</span><p>
<strong># 概要<br>既存のテキスト生成の評価手法（BLEUやMETEOR）はsurface levelのマッチングしかしておらず、意味をとらえられた評価になっていなかったので、pretrained BERTのembeddingを用いてsimilarityを測るような指標を提案しましたよ、という話。<br><br># prior metrics<br>## n-gram matching approaches<br>n-gramがreferenceとcandidateでどれだけ重複しているかでPrecisionとrecallを測定<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a620d564-72e3-4078-97e2-1ff62b333324" alt="image" loading="lazy"><br><br>### BLEU<br>MTで最も利用される。n-gramのPrecision（典型的にはn=1,2,3,4）と短すぎる候補訳にはペナルティを与える（brevity penalty）ことで実現される指標。SENT-BLEUといった亜種もある。BLEUと比較して、BERTScoreは、n-gramの長さの制約を受けず、潜在的には長さの制限がないdependencyをcontextualized embeddingsでとらえることができる。<br><br>### METEOR<br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/669" target="_blank" rel="noopener noreferrer">METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments, Banerjee+, CMU, ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</a>
</strong>
<br>
 METEOR 1.5では、内容語と機能語に異なるweightを割り当て、マッチングタイプによってもweightを変更する。METEOR++2.0では、学習済みの外部のparaphrase resourceを活用する。METEORは外部のリソースを必要とするため、たった5つの言語でしかfull feature setではサポートされていない。11の言語では、恥部のfeatureがサポートされている。METEORと同様に、BERTScoreでも、マッチに緩和を入れていることに相当するが、BERTの事前学習済みのembeddingは104の言語で取得可能である。BERTScoreはまた、重要度によるweightingをサポートしている（コーパスの統計量で推定）。<br><br>### Other Related Metrics<br>- NIST: BLEUとは異なるn-gramの重みづけと、brevity penaltyを利用する<br>- ΔBLEU: multi-reference BLEUを、人手でアノテーションされたnegative reference sentenceで変更する<br>- CHRF: 文字n-gramを比較する<br>- CHRF++: CHRFをword-bigram matchingに拡張したもの<br>- ROUGE: 文書要約で利用される指標。ROUGE-N, ROUGE^Lといった様々な変種がある。<br>- CIDEr: image captioningのmetricであり、n-gramのtf-idfで重みづけされたベクトルのcosine similrityを測定する<br><br>## Edit-distance based Metrics<br>- Word Error Rate (WER): candidateからreferenceを再現するまでに必要なedit operationの数をカウントする手法<br>- Translation Edit Rate (TER): referenceの単語数によってcandidateからreferenceまでのedit distanceを正規化する手法<br>- ITER: 語幹のマッチと、より良い正規化に基づく手法<br>- PER: positionとは独立したError Rateを算出<br>- CDER: edit operationにおけるblock reorderingをモデル化<br>- CHARACTER / EED: character levelで評価<br><br>## Embedding-based Metrics<br>- MEANT 2.0: lexical, structuralの類似度を測るために、word embeddingとshallow semantic parsesを利用<br>- YISI-1: MEANT 2.0と同様だが、semantic parseの利用がoptionalとなっている<br>これらはBERTScoreと同様の、similarityをシンプルに測るアプローチで、BERTScoreもこれにinspireされている。が、BERTScoreはContextualized Embeddingを利用する点が異なる。また、linguistic structureを生成するような外部ツールは利用しない。これにより、BERTScoreをシンプルで、新たなlanguageに対しても使いやすくしている。greedy matchingの代わりに、WMD, WMDo, SMSはearth mover's distanceに基づく最適なマッチングを利用することを提案している。greedy matchingとoptimal matchingのtradeoffについては研究されている。sentence-levelのsimilarityを計算する手法も提案されている。これらと比較して、BERTScoreのtoken-levelの計算は、重要度に応じて、tokenに対して異なる重みづけをすることができる。<br><br>## Learned Metrics<br>様々なmetricが、human judgmentsとのcorrelationに最適化するために訓練されてきた。<br>- BEER: character-ngram, word bigramに基づいたregresison modelを利用<br>- BLEND: 29の既存のmetricを利用してregressionを実施<br>- RUSE: 3種類のpre-trained sentence embedding modelを利用する手法<br>これらすべての手法は、コストのかかるhuman judgmentsによるsupervisionが必要となる。そして、新たなドメインにおける汎化能力の低さのリスクがある。input textが人間が生成したものか否か予測するneural modelを訓練する手法もある。このアプローチは特定のデータに対して最適化されているため、新たなデータに対して汎化されないリスクを持っている。これらと比較して、BERTScoreは特定のevaluation taskに最適化されているモデルではない。<br><br># BERTScore<br>referenceとcandidateのトークン間のsimilarityの最大値をとり、それらを集約することで、Precision, Recallを定義し、PrecisionとRecallを利用してF値も計算する。Recallは、reference中のすべてのトークンに対して、candidate中のトークンとのcosine similarityの最大値を測る。一方、Precisionは、candidate中のすべてのトークンに対して、reference中のトークンとのcosine similarityの最大値を測る。ここで、類似度の式が単なる内積になっているが、これはpre-normalized vectorを利用する前提であり、正規化が必要ないからである。<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9ed88ea6-8ecf-465c-81d5-bc85592ad7ff" alt="image" loading="lazy"><br><br>また、IDFによるトークン単位でのweightingを実施する。IDFはテストセットの値を利用する。TFを使わない理由は、BERTScoreはsentence同士を比較する指標であるため、TFは基本的に1となりやすい傾向にあるためである。IDFを計算する際は出現数を+1することによるスムージングを実施。<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d4b132fb-7830-4a00-b845-11f38b909bba" alt="image" loading="lazy"><br><br>さらに、これはBERTScoreのランキング能力には影響を与えないが、BERTScoreの値はコサイン類似度に基づいているため、[-1, 1]となるが、実際は学習したcontextual embeddingのgeometryに値域が依存するため、もっと小さなレンジでの値をとることになってしまう。そうすると、人間による解釈が難しくなる（たとえば、極端な話、スコアの0.1程度の変化がめちゃめちゃ大きな変化になってしまうなど）ため、rescalingを実施。rescalingする際は、monolingualコーパスから、ランダムにsentenceのペアを作成し（BETRScoreが非常に小さくなるケース）、これらのBERTScoreを平均することでbを算出し、bを利用してrescalingした。典型的には、rescaling後は典型的には[0, 1]の範囲でBERTScoreは値をとる（ただし数式を見てわかる通り[0, 1]となることが保証されているわけではない点に注意）。これはhuman judgmentsとのcorrelationとランキング性能に影響を与えない（スケールを変えているだけなので）。<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9049ed99-d192-465d-b4fe-d628bc673927" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/bb78074e-2fa4-4bb3-a920-df543aeb98b8" alt="image" loading="lazy"><br></p>
<p># 実験<br><br>## Contextual Embedding Models<br><br>12種類のモデルで検証。BERT, RoBERTa, XLNet, XLMなど。<br><br><br><br>## Machine Translation<br><br>WMT18のmetric evaluation datasetを利用。149種類のMTシステムの14 languageに対する翻訳結果, gold referencesと2種類のhuman judgment scoreが付与されている。segment-level human judgmentsは、それぞれのreference-candiate pairに対して付与されており、system-level human judgmentsは、それぞれのシステムに対して、test set全体のデータに基づいて、単一のスコアが付与されている。pearson correlationの絶対値と、kendall rank correration τをmetricsの品質の評価に利用。そしてpeason correlationについてはWilliams test、kendall τについては、bootstrap re-samplingによって有意差を検定した。システムレベルのスコアをBERTScoreをすべてのreference-candidate pairに対するスコアをaveragingすることによって求めた。また、ハイブリッドシステムについても実験をした。具体的には、それぞれのreference sentenceについて、システムの中からランダムにcandidate sentenceをサンプリングした。これにより、system-level experimentをより多くのシステムで実現することができる。ハイブリッドシステムのシステムレ4ベルのhuman judgmentsは、WMT18のsegment-level human judgmentsを平均することによって作成した。BERTScoreを既存のメトリックと比較した。<br><br><br><br>通常の評価に加えて、モデル選択についても実験した。10kのハイブリッドシステムを利用し、10kのうち100をランダムに選択、そして自動性能指標でそれらをランキングした。このプロセスを100K回繰り返し、human rankingとmetricのランキングがどれだけagreementがあるかをHits@1で評価した（best systemの一致で評価）。モデル選択の指標として新たにtop metric-rated systemとhuman rankingの間でのMRR, 人手評価でtop-rated systemとなったシステムとのスコアの差を算出した。WMT17, 16のデータセットでも同様の評価を実施した。<br><br><br><br>## Image Captioning<br><br>COCO 2015 captioning challengeにおける12種類のシステムのsubmissionデータを利用。COCO validationセットに対して、それぞれのシステムはimageに対するcaptionを生成し、それぞれのimageはおよそ5個のreferenceを持っている。先行研究にならい、Person Correlationを2種類のシステムレベルmetricで測定した。<br><br>- M1: 人間によるcaptionと同等、あるいはそれ以上と評価されたcaptionの割合<br><br>- M2: 人間によるcaptionと区別がつかないcaptionの割合<br><br>BERTScoreをmultiple referenceに対して計算し、最も高いスコアを採用した。比較対象のmetricはtask-agnostic metricを採用し、BLEU, METEOR, CIDEr, BEER, EED, CHRF++, CHARACTERと比較した。そして、2種類のtask-specific metricsとも比較した：SPICE, LEIC<br><br><br><br># 実験結果<br><br>## Machine Translation<br><br>system-levelのhuman judgmentsとのcorrelationの比較、hybrid systemとのcorrelationの比較、model selection performance<br><br>to-Englishの結果では、BERTScoreが最も一貫して性能が良かった。RUSEがcompetitiveな性能を示したが、RUSEはsupervised methodである。from-Englishの実験では、RUSEは追加のデータと訓練をしないと適用できない。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e3b0482e-a30b-46be-b8df-72a1c4fe510d" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b769ac8f-1a43-48d6-9316-cb78cffc3b88" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3b204434-9f9a-4672-be5a-6e463d3289f4" alt="image" loading="lazy"><br><br><br><br>以下は、segment-levelのcorrelationを示したものである。BERTScoreが一貫して高い性能を示している。BLEUから大幅な性能アップを示しており、特定のexampleについての良さを検証するためには、BERTScoreが最適であることが分かる。BERTScoreは、RUSEをsignificantlyに上回っている。idfによる重要度のweightingによって、全体としては、small benefitがある場合があるが全体としてはあんまり効果がなかった。importance weightingは今後の課題であり、テキストやドメインに依存すると考えられる。FBERTが異なる設定でも良く機能することが分かる。異なるcontextual embedding model間での比較などは、appendixに示す。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1684fa38-0663-4649-849f-1885cd97286e" alt="image" loading="lazy"><br><br><br><br>## Image Captioning<br><br>task-agnostic metricの間では、BETRScoreはlarge marginで勝っている。image captioningはchallengingな評価なので、n-gramマッチに基づくBLEU, ROUGEはまったく機能していない。また、idf weightingがこのタスクでは非常に高い性能を示した。これは人間がcontent wordsに対して、より高い重要度を置いていることがわかる。最後に、LEICはtrained metricであり、COCO dataに最適化されている。この手法は、ほかのすべてのmetricを上回った。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5842611a-38bd-441f-a467-8bb3714dc33a" alt="image" loading="lazy"><br><br><br><br>## Speed<br><br>pre-trained modelを利用しているにもかかわらず、BERTScoreは比較的高速に動作する。192.5 candidate-reference pairs/secondくらい出る（GTX-1080Ti GPUで）。WMT18データでは、15.6秒で処理が終わり、SacreBLEUでは5.4秒である。計算コストそんなにないので、BERTScoreはstoppingのvalidationとかにも使える。</p>
<p># Robustness analysis<br><br>BERTScoreのロバスト性をadversarial paraphrase classificationでテスト。Quora Question Pair corpus (QQP) を利用し、Word Scrambling dataset (PAWS) からParaphrase Adversariesを取得。どちらのデータも、各sentenceペアに対して、それらがparaphraseかどうかラベル付けされている。QQPの正例は、実際のduplicate questionからきており、負例は関連するが、異なる質問からきている。PAWSのsentence pairsは単語の入れ替えに基づいているものである。たとえば、"Flights from New York to Florida" は "Flights from Florida to New York" のように変換され、良いclassifierはこれらがparaphraseではないと認識できなければならない。PAWSはPAWS_QQPとPAWS_WIKIによって構成さえｒており、PAWS_QQPをdevelpoment setとした。automatic metricsでは、paraphrase detection training dataは利用しないようにした。自動性能指標で高いスコアを獲得するものは、paraphraseであることを想定している。<br><br><br><br>下図はAUCのROC curveを表しており、PAWS_QQPにおいて、QQPで訓練されたclassifierはrandom guessよりも性能が低くなることが分かった。つまりこれらモデルはadversaial exampleをparaphraseだと予測してしまっていることになる。adversarial examplesがtrainingデータで与えられた場合は、supervisedなモデルも分類ができるようになる。が、QQPと比べると性能は落ちる。多くのmetricsでは、QQP ではまともなパフォーマンスを示すが、PAWS_QQP では大幅なパフォーマンスの低下を示し、ほぼrandomと同等のパフォーマンスとなる。これは、これらの指標がより困難なadversarial exampleを区別できないことを示唆している。一方、BERTSCORE のパフォーマンスはわずかに低下するだけであり、他の指標よりもロバスト性が高いことがわかる。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7a3b3c3b-ff4e-4f65-a6b3-c71b8f100c8a" alt="image" loading="lazy"><br><br><br><br># Discussion<br><br>- BERTScoreの単一の設定が、ほかのすべての指標を明確に上回るということはない<br><br>- ドメインや言語を考慮して、指標や設定を選択すべき<br><br>- 一般的に、機械翻訳の評価にはFBERTを利用することを推奨<br><br>- 英語のテキスト生成の評価には、24層のRoBERTa largeモデルを使用して、BERTScoreを計算したほうが良い<br><br>- 非英語言語については、多言語のBERT_multiが良い選択肢だが、このモデルで計算されたBERTScoreは、low resource languageにおいて、パフォーマンスが安定しているとは言えない</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<a class="button" href="articles/Zero/FewShotLearning.html" target="_blank" rel="noopener noreferrer">#Zero/FewShotLearning</a>
<span class="issue_date">Issue Date: 2022-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/494" target="_blank" rel="noopener noreferrer" class="title-link">Few-Shot NLG with Pre-Trained Language Model, Chen+, University of California, ACL'20</a>
<span class="snippet"><span>Comment</span><p># 概要<br><br>Neural basedなend-to-endなNLGアプローチはdata-hungryなので、Few Shotな設定で高い性能ができる手法を提案（Few shot NLG）<br><br>Table-to-Textタスク（WikiBIOデータ, 追加で収集したBook, SongドメインのWikipediaデータ）において、200程度の学習サンプル数でstrong baselineに対して8.0 point程度のBLEUスコアの向上を達成<br><br><br><br># 手法<br><br>TabularデータのDescriptionを作成するには大きく分けて2つのスキルが必要<br><br>1. factualな情報を持つcontentをselectし、copyするスキル<br><br>2. factualな情報のコピーを含めながら、文法的に正しいテキストを生成するスキル<br><br>提案手法では、1を少量のサンプル（&lt; 500）から学習し、2については事前学習済みの言語モデルを活用する。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/204966408-e5442477-0560-439b-9780-d454a8761345.png" alt="image" loading="lazy"><br><br><br><br>encoderからコピーする確率をpcopyとし、下記式で算出する：<br><br><img src="https://user-images.githubusercontent.com/12249301/204968383-44ef3771-218e-4e3e-8bfd-e2e6750c514b.png" alt="image" loading="lazy"><br><br>すなわち、encoderのcontext vectorと、decoderのinputとstateから求められる。<br><br>encoderとencoder側へのattentionはscratchから学習しなければならず、うまくコピーできるようにしっかりと”teach”しなければならないため、lossに以下を追加する：<br><br><img src="https://user-images.githubusercontent.com/12249301/204968557-4526e76d-8be5-4371-adc7-d49d8291954f.png" alt="image" loading="lazy"><br><br>すなわち、コピーすべき単語がちゃんとコピーできてる場合にlossが小さくなる項を追加している。<br><br>また、decoder側では、最初にTable情報のEmbeddingを入力するようにしている。<br><br>また、学習できるデータ量が限られているため、pre-trainingモデルのEmbeddingは事前学習時点のものに固定した（ただしく読解できているか不安）<br><br><br><br># 実験<br><br>WikiBIOと、独自に収集したBook, Songに関するWikipediaデータのTable-to-Textデータを用いて実験。<br><br>このとき、Training instanceを50~500まで変化させた。<br><br><img src="https://user-images.githubusercontent.com/12249301/204969250-b2965b62-5a82-4c38-9008-3e4bbc5d9c24.png" alt="image" loading="lazy"><br><br><br><br>WikiBIOデータセットに対してSoTAを記録しているBase-originalを大きくoutperform（Few shot settingでは全然うまくいかない）。<br><br><br><br>inputとoutput例と、コピーに関するlossを入れた場合の効果。<br><br><img src="https://user-images.githubusercontent.com/12249301/204969645-aa2686f0-f83c-44cc-a6aa-2e793a6cd5b8.png" alt="image" loading="lazy"><br><br><br><br>人手評価の結果、Factual informationの正しさ（#Supp）、誤り（#Cont）ともに提案手法が良い。また、文法的な正しさ（Lan. Score）もコピーがない場合とcomparable<br><br><img src="https://user-images.githubusercontent.com/12249301/204969885-7cb3e507-d986-4d97-8f7c-a5b8c3c8204f.png" alt="image" loading="lazy"><br><br><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<span class="issue_date">Issue Date: 2022-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/492" target="_blank" rel="noopener noreferrer" class="title-link">Template Guided Text Generation for Task-Oriented Dialogue, Kale+, Google, EMNLP'20</a>
<span class="snippet"><span>Comment</span><p># 概要<br><br>Dialogue Actをそのままlinearlizeして言語モデルに入力するのではなく、テンプレートをベースにしたシンプルなsentenceにして言語モデルに与えると、zero-shot, few-shotなsettingで性能が向上するという話（T5ベース）。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/204951348-e7cb9982-4d1f-4ac0-8e1d-b3e8fd872b11.png" alt="image" loading="lazy"><br><br><br><br># 手法<br><br>slotの名称をnatural languageのdescriptionに変更するSchema Guidedアプローチも提案（NLUでは既に実践さrていたらしいが、Generationで利用されたことはない）。<br><br><img src="https://user-images.githubusercontent.com/12249301/204952341-fae03300-992a-491f-b194-9013f5d598f9.png" alt="image" loading="lazy"><br><br><br><br># 結果<br><br>MultiWoz, E2E, SGDデータセットを利用。MultiWoz, E2Eデータはデータ量が豊富でドメインやfeatureが限定的なため、schema guided, template guided approachとNaiveなrepresentationを利用した場合の結果がcopmarableであった。<br><br>が、SGDデータセットはドメインが豊富でzero-shot, few-shotの設定で実験ができる。SGDの場合はTemplate guided representationが最も高い性能を得た。<br><br><img src="https://user-images.githubusercontent.com/12249301/204954033-ecbeb90f-1398-486c-8d1f-76a0e54ed8ea.png" alt="image" loading="lazy"><br><br></p>
<p>low resourceなデータセットで活用できそう</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2022-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/488" target="_blank" rel="noopener noreferrer" class="title-link">Text-to-Text Pre-Training for Data-to-Text Tasks, Mihir+, Google Research, INLG'20</a>
<span class="snippet"><span>Comment</span><p># 概要<br><br>pre-training済みのT5に対して、Data2Textのデータセットでfinetuningを実施する方法を提案。WebNLG（graph-to-text）, ToTTo（table-to-text）, Multiwoz（task oriented dialogue）データにおいて、simpleなTransformerでも洗練されたmulti-stageなpipelined approachをoutperformできることを示した研究。<br><br><br><br># 手法<br><br>事前学習済みのT5に対してfine-tuningを実施した。手法はシンプルで、data-to-textタスクをtext-to-textタスクに変換した。具体的には、構造かされたデータをflatな文字列（linearization）で表現することで、text-to-textタスクに変換。各データセットに対するlinearizationのイメージは下図。デリミタや特殊文字を使って構造かされたデータをflatなstringで表現している。<br><br><img src="https://user-images.githubusercontent.com/12249301/191689155-3562f4f3-d1a1-4ea0-9d37-a523b78e8922.png" alt="image" loading="lazy"><br><br><br><br># データセット<br><br>## ToTTo（2020）<br><br>Wikipediaのテーブルと自然言語でdescriptionのペアデータ<br><br>## MultiWoz（2018）<br><br>10Kの人間同士のtask-orientedなdialogueデータ。<br><br>## WebNLG（2017）<br><br>subject-object-predicateの3組みをテキスト表現に変換するタスクのデータ<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/191693682-3cf3302f-b4e2-433d-94ed-995a8a908d0c.png" alt="image" loading="lazy"><br><br><br><br># Result<br><br>## WebNLG<br><br><img src="https://user-images.githubusercontent.com/12249301/191694085-7bf7348a-b468-46e0-a900-c0090d1abcba.png" alt="image" loading="lazy"><br><br>GCNを利用した2020年に提案されたDualEncがSoTAだったらしいが、outperormしている。<br><br><br><br>## ToTTo<br><br><img src="https://user-images.githubusercontent.com/12249301/191694683-f31ccad1-2936-4c21-ac10-0807a848f043.png" alt="image" loading="lazy"><br><br>[こちら](


<a href="https://github.com/google-research-datasets/totto)%E3%81%AE%E3%83%AA%E3%83%BC%E3%83%80%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%E3%81%A8%E6%AF%94%E8%BC%83%E3%81%97%E3%81%A6SoTA%E3%82%92%E8%A8%98%E9%8C%B2" target="_blank" rel="noopener noreferrer">https://github.com/google-research-datasets/totto)のリーダーボードと比較してSoTAを記録</a>


<br><br><br><br>## MultiWoz<br><br><img src="https://user-images.githubusercontent.com/12249301/191695459-e3397936-bdf7-4450-b4c2-6f6eead0825d.png" alt="image" loading="lazy"><br><br>T5は事前学習済みGPT-2をfinetuningした手法もoutperformした。SC-GPT2は当時のMultiWozでのSoTA<br><br><br><br># Impact of Model capacity<br><br>T5モデルのサイズがどれが良いかについては、データセットのサイズと複雑さに依存することを考察している。たとえば、MultiWozデータは構造化データのバリエーションが最も少なく、データ量も56kと比較的多かった。このため、T5-smallでもより大きいモデルの性能に肉薄できている。<br><br>一方、WebNLGデータセットは、18kしか事例がなく、特徴量も約200種類程度のrelationのみである。このような場合、モデルサイズが大きくなるにつれパフォーマンスも向上した（特にUnseen test set）。特にBLEUスコアはT5-smallがT5-baseになると、10ポイントもジャンプしており、modelのcapacityがout-of-domainに対する一般化に対してcriticalであることがわかる。ToTToデータセットでも、SmallからBaseにするとパフォーマンスは改善した。</p>
<p># 所感<br><br>こんな簡単なfine-tuningでSoTAを達成できてしまうとは、末恐ろしい。ベースラインとして有用。</p></span><br><br>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/DialogueGeneration.html" target="_blank" rel="noopener noreferrer">#DialogueGeneration</a>
<a class="button" href="articles/PersonalizedGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedGeneration</a>
<span class="issue_date">Issue Date: 2021-06-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/367" target="_blank" rel="noopener noreferrer" class="title-link">NUBIA, EvalNLGEval'20</a>
<span class="snippet"><span>Comment</span><p>TextGenerationに関するSoTAの性能指標。BLEU, ROUGE等と比較して、人間との相関が高い。<br><br><img src="https://user-images.githubusercontent.com/12249301/120425437-299d5c00-c3a9-11eb-9236-8bfdf494fa60.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120425509-4e91cf00-c3a9-11eb-9666-dc1069cde3cc.png" alt="image" loading="lazy"><br><br>pretrainedされたlanguage model（GPT-2=sentence legibility, RoBERTa_MNLI=logical inference, RoBERTa_STS=semantic similarity）を使い、Fully Connected Layerを利用してquality スコアを算出する。算出したスコアは最終的にcalibrationで0~1の値域に収まるように補正される。</p>
<p>意味的に同等の内容を述べた文間でのexample<br><br><img src="https://user-images.githubusercontent.com/12249301/120425803-d37ce880-c3a9-11eb-938c-09747999cc7c.png" alt="image" loading="lazy"><br><br>BLEU, ROUGE, BERTのスコアは低いが、NUBIAでは非常に高いスコアを出せている。</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2020-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/337" target="_blank" rel="noopener noreferrer" class="title-link">Evaluation of Text Generation: A Survey, Celikyilmaz, Clark, Gao, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- 本論文では、自然言語生成（NLG）システムの評価方法を人間中心、自動評価、機械学習に基づく評価の3カテゴリに分類し、それぞれの進展と課題を議論。特に新しいNLGタスクやニューラルNLGモデルの評価に焦点を当て、自動テキスト要約と長文生成の例を示し、今後の研究方向性を提案します。</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/986" target="_blank" rel="noopener noreferrer" class="title-link">HighRES: Highlight-based Reference-less Evaluation of Summarization, Hardy+, N_A, ACL'19</a>
<span class="snippet"><span>GPT Summary</span>- 要約の手動評価は一貫性がなく困難なため、新しい手法であるHighRESを提案する。この手法では、要約はソースドキュメントと比較して複数のアノテーターによって評価され、ソースドキュメントでは重要な内容がハイライトされる。HighRESはアノテーター間の一致度を向上させ、システム間の違いを強調することができることを示した。</span>
<span class="snippet"><span>Comment</span><p>人手評価の枠組み</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2021-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/408" target="_blank" rel="noopener noreferrer" class="title-link">Table-to-Text Generation with Effective Hierarchical Encoder on Three Dimensions （Row, Column and Time）, Gong+, Harbin Institute of Technology, EMNLP'19</a>
<span class="snippet"><span>Comment</span><p>
<strong>## 概要<br><br>既存研究では、tableをレコードの集合, あるいはlong sequenceとしてencodeしてきたが<br><br><br><br>1. other (column) dimensionの情報が失われてしまう (?)<br><br>2. table cellは時間によって変化するtime-series data<br><br><br><br>という特徴がある。<br><br>たとえば、ある選手の成績について言及する際に、その試合について着目するだけでなくて「直近3試合で二回目のダブルダブルです」というように直近の試合も考慮して言及することがあり、table cellの time dimensionについても着目しなければならず、これらはこれまでのモデルで実現できない。<br><br>そこで、この研究ではtime dimensionについても考慮し生成する手法を提案。<br><br><br><br>## モデル概要<br><br><img src="https://user-images.githubusercontent.com/12249301/138917272-e920b08a-5f44-4e56-8f7e-d3eb3fab7ec3.png" alt="image" loading="lazy"><br><br><br><br>全体としては、Row Dimension Encoder, Column Dimension Encoder, Time Dimension Encoderによって構成されており、self-attentionを利用して、テーブルの各セルごとに Row-Dimension, Column-Dimension, Time-DimensionのRepresentationを獲得する。イメージとしては、<br><br><br><br>- Row Dimension Encoderによって、自身のセルと同じ行に含まれるセルとの関連度を考慮した表現<br><br>- Column Dimension Encoderによって、自身のセルと同じ列に含まれるセルとの関連度を考慮した表現<br><br>- Time Dimension Encoderによって、過去の時系列のセルとの関連度を考慮した表現<br><br><br><br>をそれぞれ獲得するイメージ。各Dimension Encoderでやっていることは、Puduppully (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/394" target="_blank" rel="noopener noreferrer">Data-to-Text Generation with Content Selection and Planning, Puduppully+, AAAI'19</a>
</strong>
<br>
) らのContent Selection Gate節におけるattention vector r_{att}の取得方法と同様のもの（だと思われる）。<br><br><br><br>獲得したそれぞれのdimensionの表現を用いて、まずそれらをconcatし1 layer MLPで写像することで得られるgeneral representationを取得する。その後、general representationと各dimensionの表現を同様に1 layer MLPでスコアリングすることで、各dimensionの表現の重みを求め、その重みで各representationを線形結合することで、セルの表現を獲得する。generalなrepresentationと各dimensionの表現の関連性によって重みを求めることで、より着目すべきdimensionを考慮した上で、セルの表現を獲得できるイメージなのだろうか。<br><br>その後、各セルの表現を行方向に対してMeanPoolingを施しrow-levelの表現を取得。獲得したrow-levelの表現に対し、Puduppully (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/394" target="_blank" rel="noopener noreferrer">Data-to-Text Generation with Content Selection and Planning, Puduppully+, AAAI'19</a>
) らのContent Selection Gate g を適用する（これをどうやっているかがわからない）。<br><br><br><br>最終的に求めたrow-levelの表現とcell-levelの表現に対して、デコーダのhidden stateを利用してDual Attentionを行い、row-levelの表現からどの行に着目すべきか決めた後、その行の中からどのセルに着目するか決める、といったイメージで各セルの重みを求める。<br><br>論文中にはここまでしか書かれていないが、求めた各セルの重みでセルのrepresentationを重み付けして足し合わせ、最終的にそこから単語をpredictionするのだろうか・・・？よくわからない。</p>
<p><img src="https://user-images.githubusercontent.com/12249301/140321786-4d6a91c4-c864-490e-9921-5e6018db35c7.png" alt="image" loading="lazy"><br><br><br><br>RG, CS, CO, BLEUスコア、全てにおいてBaselineを上回っている（RGのTemplateを除く）。</p>
<p>実装: 


<a href="https://github.com/ernestgong/data2text-three-dimensions/" target="_blank" rel="noopener noreferrer">https://github.com/ernestgong/data2text-three-dimensions/</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2021-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/394" target="_blank" rel="noopener noreferrer" class="title-link">Data-to-Text Generation with Content Selection and Planning, Puduppully+, AAAI'19</a>
<span class="snippet"><span>Comment</span><p>Rotowire Datasetに対するData2Text研究において代表的な論文の一つ。Wisemanモデル <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/207" target="_blank" rel="noopener noreferrer">[Paper Note] Challenges in Data-to-Document Generation, Wiseman+ (with Rush), EMNLP'17</a>
 と共にベースラインとして利用されることが多い。</p>
<p>実装: 


<a href="https://github.com/ratishsp/data2text-plan-py" target="_blank" rel="noopener noreferrer">https://github.com/ratishsp/data2text-plan-py</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<span class="issue_date">Issue Date: 2019-08-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/319" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] User Preference-Aware Review Generation, Wang+, PAKDD'19</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2019-08-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/318" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Review Response Generation in E-Commerce Platforms with External Product Information, Zhao+, WWW'19</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Workshop.html" target="_blank" rel="noopener noreferrer">#Workshop</a>
<span class="issue_date">Issue Date: 2019-08-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/316" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Automatic Generation of Personalized Comment Based on User Profile, Wenhuan Zeng+, ACL'19 SRW</a>
<span class="snippet"><span>GPT Summary</span>- ソーシャルメディアの多様なコメント生成の難しさを考慮し、ユーザープロフィールに基づくパーソナライズされたコメント生成タスク（AGPC）を提案。パーソナライズドコメント生成ネットワーク（PCGN）を用いて、ユーザーの特徴をモデル化し、外部ユーザー表現を考慮することで自然なコメントを生成。実験結果は、モデルの効果を示す。</span>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2019-05-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/313" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Multimodal Review Generation for Recommender Systems, Truong+, WWW'19</a>
<span class="snippet"><span>Comment</span><p>Personalized Review Generationと、Rating Predictionを同時学習した研究（同時学習自体はすでに先行研究がある）。<br><br>また、先行研究のinputは、たいていはuser, itemであるが、multi-modalなinputとしてレビューのphotoを活用したという話。<br><br><br><br>まだあまりしっかり読んでいないが、モデルのstructureはシンプルで、rating predictionを行うDNN、テキスト生成を行うLSTM（fusion gateと呼ばれる新たなゲートを追加）、画像の畳み込むCNNのハイブリッドのように見える。</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<span class="issue_date">Issue Date: 2025-08-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2367" target="_blank" rel="noopener noreferrer" class="title-link">Learning to Generate Move-by-Move Commentary for Chess Games from Large-Scale Social Forum Data, Jhamtani+, ACL'18</a>
<span class="snippet"><span>Comment</span><p>データセットの日本語解説（過去の自分の資料）:


<a href="https://speakerdeck.com/akihikowatanabe/data-to-text-datasetmatome-summary-of-data-to-text-datasets?slide=66" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/akihikowatanabe/data-to-text-datasetmatome-summary-of-data-to-text-datasets?slide=66</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2021-10-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/415" target="_blank" rel="noopener noreferrer" class="title-link">Point precisely: Towards ensuring the precision of data in generated texts using delayed copy mechanism., Li+, Peking University, COLING'18</a>
<span class="snippet"><span>Comment</span><p>
<strong># 概要<br><br>DataToTextタスクにおいて、生成テキストのデータの精度を高める手法を提案。two stageアルゴリズムを提案。①encoder-decoerモデルでslotを含むテンプレートテキストを生成。②Copy Mechanismでslotのデータを埋める、といった手法。<br><br>①と②はそれぞれ独立に学習される。<br><br><br><br>two stageにするモチベーションは、<br><br>・これまでのモデルでは、単語の生成確率とコピー確率を混合した分布を考えていたが、どのように両者の確率をmergeするのが良いかはクリアではない。<br><br>→ 生成とコピーを分離して不確実性を減らした<br><br>・コピーを独立して考えることで、より効果的なpair-wise ranking loss functionを利用することができる<br><br>・テンプレート生成モデルは、テンプレートの生成に集中でき、slot fillingモデルはスロットを埋めるタスクに集中できる。これらはtrainingとtuningをより簡便にする。<br><br><br><br># モデル概要<br><br>モデルの全体像<br><br><img src="https://user-images.githubusercontent.com/12249301/138623391-6c876671-7c29-4d6a-8dfd-bd1feb623acd.png" alt="image" loading="lazy"><br><br><br><br>オリジナルテキストとテンプレートの例。テンプレートテキストの生成を学習するencoder-decoder（①）はTarget Templateを生成できるように学習する。テンプレートではエンティティが"<entity>"、数値が"<number>"というplace holderで表現されている。これらのスロットを埋めるDelayed Copy Networkは、スロットが正しく埋められるように学習される。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138623460-1415e0c2-2468-4c05-a8b8-685001c26bb7.png" alt="image" loading="lazy"><br><br><br><br># 実験結果<br><br><img src="https://user-images.githubusercontent.com/12249301/138624623-2f8944f5-8a7c-4de5-bbb8-cda9626e7018.png" alt="image" loading="lazy"><br><br><br><br>Relation Generation (RG)がCCと比べて10%程度増加しているので、data fidelityが改善されている。<br><br>また、BLEUスコアも約2ポイント改善。これはentityやnumberが適切に埋められるようになっただけでなく、テンプレートがより適切に生成されているためであると考えられる。<br><br><br><br>## 参考：<br><br>• Relation Generation (RG)：出力文から(entity, value)の関係を抽出し，抽出された関係の数と，それらの関係が入力データに対して正しいかどうかを評価する (Precision)．ただし entity はチーム名や選手名などの動作の主体，value は得点数やアシスト数などの記録である．<br><br>• Content Selection (CS)：出力文とリファレンスから (entity, value) の関係を抽出し，出力文から抽出された関係のリファレンスから抽出された関係に対する Precision，Recall で評価する．<br><br>• Content Ordering (CO)：出力文とリファレンスから (entity, value) の関係を抽出し，それらの間の正規化 DamerauLevenshtein 距離 [7] で評価する．<br><br>(from <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/409" target="_blank" rel="noopener noreferrer">過去情報の内容選択を取り入れた スポーツダイジェストの自動生成, 加藤+, 東工大, NLP'21</a>
&lt;/strong&gt;
<br>
 )&lt;/p&gt;&lt;/span&gt;<br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2021-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/406" target="_blank" rel="noopener noreferrer" class="title-link">Operation-guided Neural Networks for High Fidelity Data-To-Text Generation, Nie+, Sun Yat-Sen University, EMNLP'18</a>
<span class="snippet"><span>Comment</span><p># 概要<br><br>既存のニューラルモデルでは、生データ、あるいはそこから推論された事実に基づいて言語を生成するといったことができていない（e.g. 金融, 医療, スポーツ等のドメインでは重要）。<br><br>たとえば下表に示した通り、"edge"という単語は、スコアが接戦（95-94=1 -&gt; スコアの差が小さい）であったことを表現しているが、こういったことを既存のモデルでは考慮して生成ができない。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138627286-c9bde402-0129-4b82-9faf-80fcde08cdc8.png" alt="image" loading="lazy"><br><br><br><br>これを解決するために、演算（operation）とニューラル言語モデルを切り離す（事前に計算しておく）といったことが考えられるが、<br><br>① 全てのフィールドに対してoperationを実行すると、探索空間が膨大になり、どの結果に対して言及する価値があるかを同定するのが困難（言及する価値がある結果がほとんど存在しない探索空間ができてしまう）<br><br>② 演算結果の数値のスパンと、言語選択の対応関係を確立させるのが困難（e.g. スコアの差が1のとき"edge"と表現する、など）<br><br>といった課題がある。<br><br><br><br>①に対処するために、事前にraw dataに対して演算を適用しその結果を利用するモデルを採用。どの演算結果を利用するかを決定するために、gating-mechanismを活用する。<br><br>②に対処するために、quantization layerを採用し、演算結果の数値をbinに振り分け、その結果に応じて生成する表現をguideするようなモデルを採用する。<br><br><br><br># モデル概要<br><br>モデルはrecord encoder(h_{i}^{ctx}を作る)、operation encoder(h_{i}^{op}を作る)、operation result encoder(h_{i}^{res}を作る)によって構成される。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138628639-0c64d7aa-22e7-4ee7-a55f-65736e607ed2.png" alt="image" loading="lazy"><br><br><br><br>## record encoder<br><br>record encoderは、wisemanらと同様に、index (e.g. row 2), column (e.g. column Points), value (e.g. 95)のword embeddingを求め、それらをconcatしたものをbi-directional RNNに入力し求める。<br><br><br><br>## operation encoder<br><br>operation encoderでは、operation op_{i}は、1) operationの名称 (e.g. minus) 2) operationを適用するcolumn (e.g. Points), 3) operationを適用するrow (e.g. {1, 2}などのrow indexの集合)によって構成されており、これらのembeddingをlookupしconcatした後、non-linear layerで変換することによってoperationのrepresentationを取得する。3)operationを適用するrowについては、複数のindexによって構成されるため、各indexのembeddingをnon-linear layerで変換したベクトルを足し合わせた結果に対してtanhを適用したベクトルをembeddingとして利用する。<br><br><br><br>## operation result encoder<br><br>operation result encoderは、scalar results（minus operationにより-1）およびindexing results (argmax operationによりindex 2)の二種類を生成する。これら二種類に対して異なるencoding方法を採用する。<br><br>### scalar results<br><br>scalar resultsに対しては、下記式でscalar valueをquantization vector（q_{i}）に変換する。qutization vectorのlengthはLとなっており、Lはbinの数に相当している。つまり、quantization vectorの各次元がbinの重みに対応している。その後、quantization vectorに対してsoftmaxを適用し、quantization unit（quantization vectorの各次元）の重みを求める。最後に、quantization embeddingと対応するquantization unitの重み付き平均をとることによってh_{i}^{res}を算出する。<br><br><br><br>Q. 式を見るとW_{q}がscalar resultの値によって定数倍されるだけだから、softmaxによって求まるquantization unitの重みの序列はscalar resultによって変化しなそうに見えるが、これでうまくいくんだろうか・・・？序列は変わらなくても各quantization unit間の相対的な重みの差が変化するから、それでうまくscalar値の変化を捉えられるの・・・か・・・？<br><br><br><br>### indexing results<br><br>indexing resultsについては、h_{i}^{res}をシンプルにindexのembeddingとする。<br><br><br><br>## Decoder<br><br>context vectorの生成方法が違う。従来のモデルと比較して、context vectorを生成する際に、レコードをoperationの両方をinputとする。<br><br><img src="https://user-images.githubusercontent.com/12249301/138632508-f9407ff9-3e8a-4efd-91d4-6879e81331a6.png" alt="image" loading="lazy"><br><br><br><br>operationのcontext vector c_{t}^{op}とrecordsのcontext vector c_{t}^{ctx}をdynamic gate λ_{t}によって重み付けし最終的なcontext vectorを求める。λ_{t}は、t-1時点でのデコーダのhidden stateから重みを求める。<br><br>c_{t}^{op}は次式で計算され：<br><br><img src="https://user-images.githubusercontent.com/12249301/138633048-ca82ff5f-9755-4e5f-a658-774354cde987.png" alt="image" loading="lazy"><br><br>c_{t}^{scl, idx}は、<br><br><img src="https://user-images.githubusercontent.com/12249301/138633078-f74de4b3-f742-48f9-9f29-64489f8f477a.png" alt="image" loading="lazy"><br><br>よって計算される。要は、decoderのt-1のhidden stateと、operation vectorを用いて、j番目のoperationの重要度（β）を求め、operationの重要度によって重み付けしてoperation result vectorを足し合わせることによって、context vectorを算出する。<br><br>また、recordのcontext vector c_{t}^{ctx}は、h_{j}^{res}とh_{j}^{op}と、h_{j}^{ctx}に置き換えることによって算出される。 <br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138631847-e3076003-b619-49e4-afad-0edffaace060.png" alt="image" loading="lazy"><br><br><br><br>## データセット<br><br>人手でESPN, ROTOWIRE, WIKIBIOデータセットのReferenceに対して、factを含むtext spanと、そのfactの種類を3種類にラベル付した。input factsはinput dataから直接見つけられるfact, inferred factsはinput dataから直接見つけることはできないが、導き出すことができるfact、unsupported factsはinput dataから直接あるいは導き出すことができないfact。wikibioデータセットはinferred factの割合が少ないため、今回の評価からは除外し、ROTOWIRE, ESPNを採用した。特にESPNのheadline datasetがinferred factsが多かった。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138636048-4b8225f7-f685-45b9-ae06-1af57e09044d.png" alt="image" loading="lazy"></p>
<p># 結果<br><br>## 自動評価<br><br><img src="https://user-images.githubusercontent.com/12249301/138634010-2de062dc-d2dc-48af-8724-f6fa950e8144.png" alt="image" loading="lazy"><br><br><br><br>wiseman modelをOpAttがoutperformしている。また、Seq2Seq+op+quant（Seq2Seq+copyに対してoperation result encoderとquantization layerを適用したもの）はSeq2Seq+Copyを上回っているが、OpAttほとではないことから、提案手法のoperation encoderの導入とgating mechanismが有効に作用していることがわかる。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138635201-462ef128-58d1-4084-ae70-5acccd34087b.png" alt="image" loading="lazy"><br><br><br><br>採用するoperationによって、生成されるテキストも異なるようになっている。<br><br><br><br>## 人手評価<br><br>3人のNBAに詳しいEnglish native speakerに依頼してtest dataに対する生成結果にアノテーションをしてもらった。アノテーションは、factを含むspanを同定し、そのfactがinput facts/inferred facts/unsupported factsのどれかを分類してもらった。最後に、そのfactが入力データからsupportされるかcontradicted（矛盾するか）かをアノテーションしてもらった。<br><br>提案手法が、より多くのinferred factsについて言及しながらも、少ない#Cont.であることがわかった。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138636756-74da3999-45e7-489f-9d0a-ac68416d3de0.png" alt="image" loading="lazy"><br><br></p>
<p># 分析<br><br>## Quantizationの効果<br><br>チーム間のスコアの差が、5つのbinのに対してどれだけの重みを持たせたかのheatmap。似たようなスコアのgapの場合は似たような重みになることがわかる。ポイント差の絶対値が小さい場合は、重みの分布の分散が大きくなるのでより一般的な単語で生成を行うのに対し、絶対値が大きい場合は分散が小さくなるため、unique wordをつかって生成するようになる。<br><br><img src="https://user-images.githubusercontent.com/12249301/138637300-04738ba9-8e5f-4b07-8ed2-1a62c14cb7fe.png" alt="image" loading="lazy"><br><br><br><br>pointのgapの大きさによって利用される単語も変化していることがわかる。ポイント差がちいさいときは"edge"、大きいときは"blow out"など。<br><br><img src="https://user-images.githubusercontent.com/12249301/138637614-19a95fba-9904-4378-86d0-3d1bd513be8a.png" alt="image" loading="lazy"><br><br><br><br>## gating mechanismの効果<br><br>生成テキストのtimestepごとのgateの重みの例。色が濃ければ濃いほど、operation resultsの情報を多く利用していることを表す。チームリーダーを決める際や（horford）勝者を決める際に(Hawks)、operation resultsの重みが大きくなっており、妥当な重み付けだと考察している。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138637813-4b4a2b1d-c5c5-4f7a-96b3-59df3a56aeb2.png" alt="image" loading="lazy"><br><br><br><br></p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/RecSys.html" target="_blank" rel="noopener noreferrer">#RecSys</a>
<span class="issue_date">Issue Date: 2019-08-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/317" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Improving Explainable Recommendations with Synthetic Reviews, Sixun Ouyang+, RecSys'18</a>
<span class="snippet"><span>GPT Summary</span>- レコメンダーシステムにおいて、解釈可能な説明を提供することは信頼性向上に重要である。本研究では、ユーザーのレビューを基にした生成モデルを用いて、個別化された推薦説明を作成するフレームワークを提案。Amazonの書籍レビューデータセットを用いて、生成されたレビューが人間のレビューよりも優れた推薦性能を示すことを実証した。これは機械生成による自然言語説明の初の試みである。</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2019-01-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/301" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Knowledge-Grounded Neural Conversation Model, Ghazvininejad+, AAAI'18, </a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ContextAware.html" target="_blank" rel="noopener noreferrer">#ContextAware</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2019-01-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/300" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Response Generation by Context-aware Prototype Editing, Yu Wu+, AAAI'18, 2018.06</a>
<span class="snippet"><span>GPT Summary</span>- 「編集による応答生成」という新しいパラダイムを提案し、既存の応答プロトタイプを修正することで多様性と情報量を向上させる。応答編集モデルは、プロトタイプと現在のコンテキストの違いを考慮して編集ベクトルを形成し、生成結果を改善する。実験結果は、応答編集モデルが他の生成モデルや取得ベースのモデルより優れていることを示す。</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/TACL.html" target="_blank" rel="noopener noreferrer">#TACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/92" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generating Sentences by Editing Prototypes, Guu+, TACL'18</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/989" target="_blank" rel="noopener noreferrer" class="title-link">Why We Need New Evaluation Metrics for NLG, EMNLP'17</a>
<span class="snippet"><span>GPT Summary</span>- NLGの評価には自動評価指標が使われているが、本研究ではシステムやデータに依存しない新しい評価手法の必要性を提案する。幅広い指標を調査し、それらがデータ駆動型のNLGによって生成されたシステムの出力の人間の判断を弱く反映していることを示す。また、評価指標の性能はデータとシステムに依存することも示すが、自動評価指標はシステムレベルで信頼性があり、システムの開発をサポートできることを示唆する。特に、低いパフォーマンスを示すケースを見つけることができる。</span>
<span class="snippet"><span>Comment</span><p>既存のNLGのメトリックがhuman judgementsとのcorrelationがあまり高くないことを指摘した研究</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/IJCNLP.html" target="_blank" rel="noopener noreferrer">#IJCNLP</a>
<span class="issue_date">Issue Date: 2019-02-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/303" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Estimating Reactions and Recommending Products with Generative Models of Reviews, Ni+, IJCNLP'17</a>
<span class="snippet"><span>Comment</span><p>Collaborative Filtering (CF) によるコンテンツ推薦とReview Generationを同時に学習し、<br><br>両者の性能を向上させる話。<br><br>非常に興味深い設定で、このような実験設定でReview Generationを行なった初めての研究。</p>
<p>CFではMatrix Factorization (MF) を利用し、Review Generationでは、LSTM-basedなseq2seqを利用する。MFとReview Generationのモデルにおいて、共通のuser latent factorとitem latent factorを利用することで、joint modelとしている。このとき、latent factorは、両タスクを通じて学習される。<br><br><br><br>CFでは、Implicitな設定なので、Rating Predictionではなく、binary classificationを行うことで、推薦を行う。<br><br>classificationには、Matrix Factorization (MF) を拡張したモデルを用いる。<br><br>具体的には、通常のMFでは、user latent factorとitem latent factorの内積によって、userのitemに対するpreferenceを表現するが、このときに、target userが過去に記載したレビュー・およびtarget itemに関する情報を利用する。レビューのrepresentationのaverageをとったvectorと、MFの結果をlinear layerによって写像し、最終的なclassification scoreとしている。<br><br><br><br>Review Generationでは、基本的にはseq2seqのinputのEmbeddingに対して、user latent factor, item latent factorをconcatするだけ。hidden stateに直接concatしないのは、latent factorを各ステップで考慮できるため、long, coherentなsequenceを生成できるから、と説明している。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/56011945-15a7c380-5d25-11e9-9a0d-8835bdb6cbed.png" alt="image" loading="lazy"><br><br></p>
<p><img src="https://user-images.githubusercontent.com/12249301/56012061-9c5ca080-5d25-11e9-9327-2c7a9c3ee365.png" alt="image" loading="lazy"><br><br><br><br>Recommendタスクにおいては、Bayesian Personalized Ranking, Generalized Matrix Factorizationをoutperform。</p>
<p><img src="https://user-images.githubusercontent.com/12249301/56012129-f65d6600-5d25-11e9-919a-33018878f96e.png" alt="image" loading="lazy"><br><br><br><br>Review GenerationはPerplexityにより評価している。提案手法がcharacter based lstmをoutperform。<br><br>Perplexityによる評価だと言語モデルとしての評価しかできていないので、BLEU, ROUGEなどを利用した評価などもあって良いのでは。</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/207" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Challenges in Data-to-Document Generation, Wiseman+ （with Rush）, EMNLP'17</a>
&lt;span class=\"snippet\"&gt;<span>Comment</span><p>・RotoWire（NBAのテーブルデータ + サマリ）データを収集し公開<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/119625430-23f1c480-be45-11eb-8ff8-5e9223d41481.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br><br><br>・Rotowireデータの統計量<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/119625488-323fe080-be45-11eb-952e-d2d21d6e5847.png\" alt=\"image\" loading=\"lazy\" /&gt;</p>
<p>【モデルの概要】<br><br>・attention-based encoder-decoder model<br><br><br><br>・BaseModel<br><br>　- レコードデータ r の各要素（r.e: チーム名等のENTITY r.t: POINTS等のデータタイプ, r.m: データのvalue）からembeddingをlookupし、1-layer MLPを適用し、レコードの各要素のrepresentation（source data records）を取得<br><br>　- Luongらのattentionを利用したLSTM Decoderを用意し、source data recordsとt-1ステップ目での出力によって条件付けてテキストを生成していく<br><br>　- negative log likelihoodがminimizeされるように学習する<br><br><br><br>・Copying<br><br>　- コピーメカニズムを導入し、生成時の確率分布に生成テキストを入力からコピーされるか否かを含めた分布からテキストを生成。コピーの対象は、入力レコードのvalueがコピーされるようにする。<br><br>　- コピーメカニズムには下記式で表現される Conditional Copy Modelを利用し、p\(zt|y1:t-1, s)はMLPで表現する。<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/119628147-cc088d00-be47-11eb-84de-6a1d158d78e5.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br>　- またpcopyは、生成している文中にあるレコードのエンティティとタイプが出現する場合に、対応するvalueをコピーし生成されるように、下記式で表現する<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/119628389-07a35700-be48-11eb-9c69-27b70fcbcdef.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br>　- ここで r\(yt) =<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/119628615-39b4b900-be48-11eb-9305-509a6eed8182.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br></p>&lt;/span&gt;<br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/91" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Toward Controlled Generation of Text, Hu+, ICML'17</a>
<span class="snippet"><span>Comment</span><p>Text Generationを行う際は、現在は基本的に学習された言語モデルの尤度に従ってテキストを生成するのみで、outputされるテキストをcontrolすることができないので、できるようにしましたという論文。 VAEによるテキスト生成にGANを組み合わせたようなモデル。 decodingする元となるfeatureのある次元が、たとえばpolarityなどに対応しており、その次元の数値をいじるだけで生成されるテキストをcontrolできる。 <br><br><br><br>テキストを生成する際に、生成されるテキストをコントロールするための研究。 テキストを生成する際には、基本的にはVariational Auto Encoder(VAE)を用いる。<br><br><br><br>VAEは、入力をエンコードするEncoderと、エンコードされた潜在変数zからテキストを生成するGeneratorの2つの機構によって構成されている。<br><br><br><br>この研究では、生成されるテキストをコントロールするために、VAEの潜在変数zに、生成するテキストのattributeを表す変数cを新たに導入。<br><br><br><br>たとえば、一例として、変数cをsentimentに対応させた場合、変数cの値を変更すると、生成されるテキストのsentimentが変化するような生成が実現可能。<br><br><br><br>次に、このような生成を実現できるようなパラメータを学習したいが、学習を行う際のポイントは、以下の二つ。<br><br><br><br>cで指定されたattributeが反映されたテキストを生成するように学習<br><br><br><br>潜在変数zとattributeに関する変数cの独立性を保つように学習 （cには制御したいattributeに関する情報のみが格納され、その他の情報は潜在変数zに格納されるように学習する)<br><br><br><br>1を実現するために、新たにdiscriminatorと呼ばれる識別器を用意し、VAEが生成したテキストのattributeをdiscriminatorで分類し、その結果をVAEのGeneratorにフィードバックすることで、attributeが反映されたテキストを生成できるようにパラメータの学習を行う。 （これにはラベル付きデータが必要だが、少量でも学習できることに加えて、sentence levelのデータだけではなくword levelのデータでも学習できる。）<br><br><br><br>また、2を実現するために、VAEが生成したテキストから、生成する元となった潜在変数zが再現できるようにEncoderのパラメータを学習。<br><br><br><br>実験では、sentimentとtenseをコントロールする実験が行われており、attributeを表す変数cを変更することで、以下のようなテキストが生成されており興味深い。<br><br><br><br>[sentimentを制御した例]<br><br><br><br>this movie was awful and boring. (negative)<br><br>this movie was funny and touching. (positive)<br><br>[tenseを制御した例]<br><br><br><br>this was one of the outstanding thrillers of the last decade<br><br>this is one of the outstanding thrillers of the all time<br><br>this will be one of the great thrillers of the all time</p>
<p>VAEは通常のAutoEncoderと比較して、奥が深くて勉強してみておもしろかった。 Reparametrization Trickなどは知らなかった。</p>
<p>管理人による解説資料:<br>[Controllable Text Generation.pdf](https://github.com/AkihikoWatanabe/paper_notes/files/1595121/Controllable.Text.Generation.pdf)<br><br></p>
<p>slideshare: 


<a href="https://www.slideshare.net/akihikowatanabe3110/towards-controlled-generation-of-text" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/towards-controlled-generation-of-text</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/90" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Multi-Task Video Captioning with Video and Entailment Generation, Pasunuru+, ACL'17</a>
<span class="snippet"><span>Comment</span><p>解説スライド：


<a href="https://www.slideshare.net/HangyoMasatsugu/hangyo-acl-paperreading2017multitask-video-captioning-with-video-and-entailment-generation/1" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/HangyoMasatsugu/hangyo-acl-paperreading2017multitask-video-captioning-with-video-and-entailment-generation/1</a>


</p>
<p>multitask learningで動画（かなり短め）のキャプション生成を行なった話<br><br>(2025.05.12)<br>上記解説資料中のスクショがいくつか掲載されていましたが削除しました。</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/87" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Neural Text Generation: A Practical Guide, Ziang Xie, arXiv'17</a>
<span class="snippet"><span>GPT Summary</span>- 深層学習手法はテキスト生成タスクで成功を収めているが、デコーダーが望ましくない出力を生成する問題がある。本論文は、テキスト生成モデルの不具合を解決するための実践的なガイドを提供し、実世界のアプリケーションの実現を目指す。</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/84" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Survey of the State of the Art in Natural Language Generation: Core  tasks, applications and evaluation, Albert Gatt+, arXiv'17</a>
<span class="snippet"><span>GPT Summary</span>- 本論文は、非言語的入力からテキストや音声を生成する自然言語生成（NLG）の最新技術動向を調査し、(a) NLGのコアタスクに関する研究の統合とアーキテクチャの提示、(b) NLGと他のAI分野との相乗効果による新しい研究トピックの強調、(c) NLG評価の課題と他の自然言語処理分野との関連を探ることを目的としている。</span>
<span class="snippet"><span>Comment</span><p>割と新し目のNLGのSurvey</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coherence.html" target="_blank" rel="noopener noreferrer">#Coherence</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/971" target="_blank" rel="noopener noreferrer" class="title-link">Lexical Coherence Graph Modeling Using Word Embeddings, Mesgar+, NAACL'16</a>
<span class="snippet"><span>Comment</span><p>__translate: Coherence is established by semantic connections between sentences of a text which can be modeled by lexical relations. In this paper, we introduce the lexical coherence graph (LCG), a new graph-based model to represent lexical relations among sentences. The frequency of subgraphs (coherence patterns) of this graph captures the connectivity style of sentence nodes in this graph. The coherence of a text is encoded by a vector of these frequencies. We evaluate the LCG model on the readability ranking task. The results of the experiments show that the LCG model obtains higher accuracy than state-of-the-art coherence models. Using larger subgraphs yields higher accuracy, because they capture more structural information. However, larger subgraphs can be sparse. We adapt Kneser-Ney smoothing to smooth subgraphs’ frequencies. Smoothing improves performance.</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2018-10-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/279" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Neural Headline Generation with Minimum Risk Training, Ayana+, N_A, arXiv'16</a>
<span class="snippet"><span>GPT Summary</span>- 自動見出し生成のために、最小リスクトレーニング戦略を使用してモデルパラメータを最適化し、見出し生成の改善を実現する。提案手法は英語と中国語の見出し生成タスクで最先端のシステムを上回る性能を示す。</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/CoNLL.html" target="_blank" rel="noopener noreferrer">#CoNLL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-02-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/258" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generating Sentences from a Continuous Space, Samuel R. Bowman+, CoNLL'16</a>
<span class="snippet"><span>GPT Summary</span>- RNNベースの変分オートエンコーダ生成モデルを導入し、文全体の分散潜在表現を組み込むことで、文のスタイルやトピックなどの特性を明示的にモデル化。潜在空間を通じて新しい文を生成し、欠損単語の補完効果を実証。モデルの特性と使用に関する否定的な結果も示す。</span>
<span class="snippet"><span>Comment</span><p>VAEを利用して文生成</p>
<p>【Variational Autoencoder徹底解説】<br><br>


<a href="https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24" target="_blank" rel="noopener noreferrer">https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24</a>


</p></span><br><br>
<a class="button" href="articles/Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/CIKM.html" target="_blank" rel="noopener noreferrer">#CIKM</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/112" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Match between Geology Reports and Well Logs Using Spatial Information, Tong+, CIKM'16</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/89" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Neural Text Generation from Structured Data with Application to the  Biography Domain, Remi Lebret+, EMNLP'16, 2016.03</a>
<span class="snippet"><span>GPT Summary</span>- 大規模なWikipediaの伝記データセットを用いて、テキスト生成のためのニューラルモデルを提案。モデルは条件付きニューラル言語モデルに基づき、固定語彙とサンプル固有の単語を組み合わせるコピーアクションを採用。提案モデルは古典的なKneser-Neyモデルを約15 BLEUポイント上回る性能を示した。</span>
<span class="snippet"><span>Comment</span><p>Wikipediaの人物に関するinfo boxから、その人物のbiographyの冒頭を生成するタスク。<br>Neural Language Modelに、新たにTableのEmbeddingを入れられるようにtable embeddingを提案し、table conditioned language modelを提案している。<br><br>inputはテーブル（図中のinput textっていうのは、少し用語がconfusingだが、言語モデルへのinputとして、過去に生成した単語の系列を入れるというのを示しているだけ）<br><img src="https://user-images.githubusercontent.com/12249301/34460925-6483a6ca-ee60-11e7-9ced-d02a59c26281.png" alt="image" loading="lazy"><br><br>モデル全体<br><img src="https://user-images.githubusercontent.com/12249301/34460923-4eea63b2-ee60-11e7-95e6-649ab1851dab.png" alt="image" loading="lazy"><br><br>Wikipediaから生成した、Biographyに関するデータセットも公開している。<br><img src="https://user-images.githubusercontent.com/12249301/34460928-93822082-ee60-11e7-81fc-b1840fea0b37.png" alt="image" loading="lazy"><br><br>template basedなKNSmoothingを使ったベースラインよりも高いBLEUスコアを獲得。さらに、テーブルのGlobalな情報を入れる手法が、性能向上に寄与（たとえばチーム名・リーグ・ポジションなどをそれぞれ独立に見ても、バスケットボールプレイヤーなのか、ホッケープレイヤーなのかはわからないけど、テーブル全体を見ればわかるよねという気持ち）。</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/86" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Content Selection in Data-to-Text Systems: A Survey, arXiv'16, Gkatzia</a>
<span class="snippet"><span>Comment</span><p>Gkatzia氏の"content selection"に関するSurvey</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/985" target="_blank" rel="noopener noreferrer" class="title-link">chrF: character n-gram F-score for automatic MT evaluation, Mono Popovic, WMT'15</a>
<span class="snippet"><span>GPT Summary</span>- 私たちは、機械翻訳の評価に文字n-gram Fスコアを使用することを提案します。私たちは、このメトリックがシステムレベルとセグメントレベルで人間のランキングと相関しており、特にセグメントレベルでの相関が非常に高いことを報告しました。この提案は非常に有望であり、WMT14の共有評価タスクでも最高のメトリックを上回りました。</span>
<span class="snippet"><span>Comment</span><p>character-basedなn-gram overlapをreferenceとシステムで計算する手法</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/978" target="_blank" rel="noopener noreferrer" class="title-link"> From word embeddings to document distances, Kusner+, PMLR'15</a>
<span class="snippet"><span>GPT Summary</span>- 私たちは、新しい距離関数であるWord Mover's Distance（WMD）を提案しました。WMDは、テキストドキュメント間の非類似性を測定するために使用されます。私たちの研究では、単語埋め込みの最新の結果に基づいてWMDを開発しました。WMDは、単語が別のドキュメントの単語に到達するために必要な最小距離を計算します。私たちのメトリックは、実装が簡単であり、ハイパーパラメータも必要ありません。さらに、私たちは8つの実世界のドキュメント分類データセットでWMDメトリックを評価し、低いエラーレートを示しました。</span>
<span class="snippet"><span>Comment</span><p>WMS/SMS/S+WMS<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/946" target="_blank" rel="noopener noreferrer">MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance, Zhao+, EMNLP-IJCNLP'19</a>
 はこれらからinspiredされ提案された</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ImageCaptioning.html" target="_blank" rel="noopener noreferrer">#ImageCaptioning</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/670" target="_blank" rel="noopener noreferrer" class="title-link">CIDEr: Consensus-based Image Description Evaluation, Ramakrishna Vedantam+, N_A, CVPR'15</a>
<span class="snippet"><span>GPT Summary</span>- 画像を文章で自動的に説明することは、長年の課題である。本研究では、人間の合意を利用した画像説明の評価のための新しいパラダイムを提案し、新しい自動評価指標と2つの新しいデータセットを含む。提案手法は、人間の判断をより正確に捉えることができ、5つの最先端の画像説明手法を評価し、将来の比較のためのベンチマークを提供する。CIDEr-Dは、MS COCO評価サーバーの一部として利用可能であり、システマティックな評価とベンチマークを可能にする。</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2861" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Sequence to Sequence Learning with Neural Networks, Ilya Sutskever+, NIPS'14</a>
<span class="snippet"><span>GPT Summary</span>- DNNはシーケンス学習において優れた性能を示すが、シーケンス間のマッピングには限界がある。本研究では、LSTMを用いたエンドツーエンドのシーケンス学習アプローチを提案し、英語からフランス語への翻訳タスクで34.8のBLEUスコアを達成。LSTMは長文にも対応し、SMTシステムの出力を再ランク付けすることでBLEUスコアを36.5に向上させた。また、単語の順序を逆にすることで性能が向上し、短期的依存関係の最適化が容易になった。</span>
<span class="snippet"><span>Comment</span><p>いまさらながらSeq2Seqを提案した研究を追加</p></span><br><br>
<a class="button" href="articles/Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/108" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Comparing Multi-label Classification with Reinforcement Learning for Summarization of Time-series Data, Gkatzia+, ACL'14</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coherence.html" target="_blank" rel="noopener noreferrer">#Coherence</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/970" target="_blank" rel="noopener noreferrer" class="title-link">Graph-based Local Coherence Modeling, Guinaudeau+, ACL'13</a>
<span class="snippet"><span>GPT Summary</span>- 私たちは、グラフベースのアプローチを提案し、文の順序付け、要約の結束性評価、読みやすさの評価の3つのタスクでシステムを評価しました。このアプローチは、エンティティグリッドベースのアプローチと同等の性能を持ち、計算コストの高いトレーニングフェーズやデータのまばらさの問題にも対処できます。</span>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/99" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Inducing document plans for concept-to-text generation, Konstas+, EMNLP'13</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coherence.html" target="_blank" rel="noopener noreferrer">#Coherence</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/968" target="_blank" rel="noopener noreferrer" class="title-link">Extending Machine Translation Evaluation Metrics with Lexical Cohesion to Document Level, Wong+, EMNLP'12</a>
<span class="snippet"><span>GPT Summary</span>- この論文では、語彙的な結束を利用して文書レベルの機械翻訳の評価を容易にする方法を提案しています。語彙的な結束は、同じ意味を持つ単語を使って文を結びつけることで、テキストの結束性を実現します。実験結果は、この特徴を評価尺度に組み込むことで、人間の判断との相関を向上させることを示しています。</span>
<span class="snippet"><span>Comment</span><p>RC-LC</p></span><br><br>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/97" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unsupervised concept-to-text generation with hypergraphs, Konstas+, NAACL-HLT'12</a>
<a class="button" href="articles/RuleBased.html" target="_blank" rel="noopener noreferrer">#RuleBased</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/106" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generating approximate geographic descriptions, Turner+, ENLG'10</a>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/96" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generative alignment and semantic parsing for learning from ambiguous supervision, Kim+, COLING'10</a>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/95" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A simple domain-independent probabilistic approach to generation, Angeli+, EMNLP'10</a>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/94" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Training a multilingual sportscaster: Using perceptual context to learn language, Chen+, Artificial Intelligence Research'10</a>
<a class="button" href="articles/Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/IJCNLP.html" target="_blank" rel="noopener noreferrer">#IJCNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/113" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning semantic correspondences with less supervision, Liang+, ACL-IJCNLP'09</a>
<a class="button" href="articles/Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/111" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Verbalizing time-series data: with an example of stock price trends, Kobayashi+, IFSA-EUSFLAT'09</a>
<span class="snippet"><span>Comment</span><p>小林先生の論文<br><br><br><br>Least Square Methodによって数値データにfittingするcurveを求める。<br><br>curveの特徴から、生成するテキストのtrendsを決定する。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34462004-1eddd6be-ee7d-11e7-8c1b-c61dca30dbe5.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/114" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A generative model for parsing natural language to meaning representations, Lu+, EMNLP'08</a>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/93" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning to sportscast: a test of grounded language acquisition, Chen+, ICML'08</a>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/100" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Automatic generation of textual summaries from neonatal intensive care data, Porter+, AIME'07</a>
<span class="snippet"><span>Comment</span><p>BabyTalk論文</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/85" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] An Architecture for Data to Text Systems, Ehud Reiter, ENLG'07</a>
<span class="snippet"><span>Comment</span><p>NLG分野で有名なReiterらのSurvey。<br>NLGシステムのアーキテクチャなどが、体系的に説明されている。</p></span><br><br>
<a class="button" href="articles/DataDriven.html" target="_blank" rel="noopener noreferrer">#DataDriven</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/102" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Aggregation via set partitioning for natural language generation, Barzilay+, HLT-NAACL'06</a>
<a class="button" href="articles/RuleBased.html" target="_blank" rel="noopener noreferrer">#RuleBased</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/103" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Choosing words in computer-generated weather forecasts, Reiter+, Artificial Intelligence'05</a>
<span class="snippet"><span>Comment</span><p>## タスク<br><br>天気予報の生成, システム名 SUMTIME<br><br><br><br>## 手法概要<br><br> ルールベースな手法，weather prediction dataから（将来の気象情報をシミュレーションした数値データ），天気予報を自動生成．corpus analysisと専門家のsuggestを通じて，どのようなwordを選択して天気予報を生成するか詳細に分析したのち，ルールを生成してテキスト生成</p></span><br><br>
<a class="button" href="articles/DataDriven.html" target="_blank" rel="noopener noreferrer">#DataDriven</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/101" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Collective content selection for concept-to-text generation, Barzilay+, HLT_EMNLP'05</a>
<a class="button" href="articles/RuleBased.html" target="_blank" rel="noopener noreferrer">#RuleBased</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/107" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Coral: Using natural language generation for navigational assistance, Dale+, Australasian computer science conference'03</a>
<a class="button" href="articles/RuleBased.html" target="_blank" rel="noopener noreferrer">#RuleBased</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/104" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Using natural language processing to produce weather forecasts, Goldberg+, IEEE Expert: Intelligent Systems and Their Applications'94</a>
<span class="snippet"><span>Comment</span><p>## タスク<br><br>天気予報の生成，システム名 FOG (EnglishとFrenchのレポートを作成できる)<br><br><br><br>## 手法概要<br><br>ルールベースな手法，weather predictinon dataから，天気予報を自動生成．Text Planner がルールに従い各sentenceに入れる情報を抽出すると同時に，sentence orderを決め，abstractiveな中間状態を生成．その後，中間状態からText Realization（grammarやdictionaryを用いる）によって，テキストを生成．</p></span><br><br>
<a class="button" href="articles/RuleBased.html" target="_blank" rel="noopener noreferrer">#RuleBased</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/105" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Design of a knowledge-based report generator, Kukich, ACL'83</a>
<span class="snippet"><span>Comment</span><p>## タスク<br><br>numerical stock market dataからstock market reportsを生成，我々と同様なタスク．システム名: ANA<br><br><br><br>## 手法概要<br><br>ルールベースな手法，<br><br>1) fact-generator,<br><br>2) message generator, <br><br>3) discourse organizer, <br><br>4) text generatorの4コンポーネントから成る． <br><br><br><br>2), 3), 4)はそれぞれ120, 16, 109個のルールがある. 4)ではphrasal dictionaryも使う． <br><br>1)では，入力されたpriceデータから，closing averageを求めるなどの数値的な演算などを行う. <br><br>2)では，1)で計算された情報に基づいて，メッセージの生成を行う(e.g. market was mixed). <br><br>3)では，メッセージのparagraph化，orderの決定，priorityの設定などを行う． <br><br>4)では，辞書からフレーズを選択したり，適切なsyntactic formを決定するなどしてテキストを生成．</p>
<p>Data2Textの先駆け論文。引用すべし。多くの研究で引用されている。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1325" target="_blank" rel="noopener noreferrer" class="title-link">OpenDevin: Code Less, Make More, 2024</a>
<span class="snippet"><span>Comment</span><p>LLMによるOpenSourceなソフトウェア生成エージェントプラットフォーム</p>
<p>full timeのスタッフを雇用しworldクラスのUXを目指すとのこと。楽しみ。<br>参考: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1808493521315496229?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span></number></entity></strong></p>
<p>Open化される前の最初のDevinのツイート<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cognition_labs/status/1767548763134964000"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1203" target="_blank" rel="noopener noreferrer" class="title-link">Decoding Strategies that You Need to Know for Response Generation</a>
<span class="snippet"><span>Comment</span><p>言語モデルのdecodingの方法についてよくまとまっている。まとめられているdecoding方法は以下<br><br>- Greedy, BeamSearch, RandomSampling, Temperature, Top-K Sampling, Nucleus Sampling</p>
<p>こちらの記事ではHuggingFaceでの実装や他のdecoding方法等、より実装面での詳細が記述されている：<br><br>


<a href="https://note.com/npaka/n/n9a8c85f2ef7a" target="_blank" rel="noopener noreferrer">https://note.com/npaka/n/n9a8c85f2ef7a</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-11-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1119" target="_blank" rel="noopener noreferrer" class="title-link">Data-to-Text Datasetまとめ, Akihiko Watanabe, 2022</a>
<span class="snippet"><span>Comment</span><p>Data-to-Textのデータセットを自分用に調べていたのですが、せっかくなのでスライドにまとめてみました。特にMR-to-Text, Table-to-Textあたりは網羅的にサーベイし、データセットの概要を紹介しているので、全体像を把握するのに良いのかなぁと思います。ただし、2022年12月時点で作成したので2023年以後のデータセットは含まれていません😅</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ImageCaptioning.html" target="_blank" rel="noopener noreferrer">#ImageCaptioning</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2023-11-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1114" target="_blank" rel="noopener noreferrer" class="title-link">Zero-shot Learning網羅的サーベイ: CLIPが切り開いたVision &amp; Languageの新しい世界</a>
<span class="snippet"><span>Comment</span><p>これはすごいまとめ…。まだ途中までしか読めていない。CLIPからスタートしてCLIPを引用している論文から重要なものを概要付きでまとめている。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1003" target="_blank" rel="noopener noreferrer" class="title-link">走行動画を説明するLLMを作成し、80台のGPUで分散並列学習させた話</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2023-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/661" target="_blank" rel="noopener noreferrer" class="title-link">StarCoderBase_StarCoder, 2023</a>
<span class="snippet"><span>Comment</span><p>・15.5Bパラメータ<br>・80種類以上のプログラミング言語で訓練<br>・Multi Query Attentionを利用<br>・context window size 8192<br>・Fill in the middle objectiveを利用<br><br>Instruction tuningがされておらず、prefixとsuffixの間を埋めるような訓練のされ方をしているので、たとえば関数名をinputして、そのmiddle（関数の中身）を出力させる、といった使い方になる模様。</p>
<p>paper: 


<a href="https://drive.google.com/file/d/1cN-b9GnWtHzQRoE7M7gAEyivY0kl4BYs/view" target="_blank" rel="noopener noreferrer">https://drive.google.com/file/d/1cN-b9GnWtHzQRoE7M7gAEyivY0kl4BYs/view</a>


</p>
<p>StarCoder:<br>


<a href="https://huggingface.co/bigcode/starcoder" target="_blank" rel="noopener noreferrer">https://huggingface.co/bigcode/starcoder</a>


</p>
<p>StarCoderBaseを35Bのpython tokenでfinetuningしたモデル。<br>既存モデルよりも高性能と主張<br><br><img src="https://user-images.githubusercontent.com/12249301/236622130-5e7aa6aa-5f9b-4b0e-9962-ff1beaa03225.jpeg" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2021-06-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/372" target="_blank" rel="noopener noreferrer" class="title-link">Incorporating Copying Mechanism in Sequence-to-Sequence Learning, Gu+, ACL’16</a>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/371" target="_blank" rel="noopener noreferrer">Pointing the Unknown Words, Gulcehre+, ACL’16</a>
 と同様コピーメカニズムを提案した論文。Joint Copy ModelやCOPYNETと呼ばれる。<br><br>次の単語が "生成" されるのか "コピー" されるのかをスコアリングし、各単語がコピーされる確率と生成される確率をMixtureした同時確率分布で表現する（ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/207" target="_blank" rel="noopener noreferrer">[Paper Note] Challenges in Data-to-Document Generation, Wiseman+ (with Rush), EMNLP'17</a>
 等でも説明されている）。<br><br>コピーメカニズムを導入せるなら引用すべき。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120571719-ad148700-c455-11eb-8e93-8d9be799aad5.png" alt="image" loading="lazy"><br><br><br><br>## コピーメカニズム部分の説明<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120571852-efd65f00-c455-11eb-9063-872103738e2f.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120571874-fa90f400-c455-11eb-885f-5b1a08d7d528.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120572859-a6870f00-c457-11eb-9744-e1ff5ab5d253.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/120572917-bd2d6600-c457-11eb-8c76-5bb48988a5f9.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/120572936-c585a100-c457-11eb-822b-e70f0e857ac9.png" alt="image" loading="lazy"><br><br></p>
<p>解説資料: 


<a href="http://www.lr.pi.titech.ac.jp/~sasano/acl2016suzukake/slides/08.pdf" target="_blank" rel="noopener noreferrer">http://www.lr.pi.titech.ac.jp/~sasano/acl2016suzukake/slides/08.pdf</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2021-06-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/371" target="_blank" rel="noopener noreferrer" class="title-link">Pointing the Unknown Words, Gulcehre+, ACL’16</a>
<span class="snippet"><span>Comment</span><p>Conditional Copy Model （Pointer Softmax）を提案した論文。<br>単語を生成する際に、語彙内の単語から生成する分布、原文の単語から生成する分布を求める。後者はattention distributionから。コピーするか否かを決める確率変数を導入し（sigmoid）、両生成確率を重み付けする。<br>コピーメカニズム入れるなら引用すべき。</p>
<p>解説スライド:


<a href="https://www.slideshare.net/hytae/pointing-the-unknown-words" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/hytae/pointing-the-unknown-words</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/110" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Automatically generated linguistic summaries of energy consumption data, van der Heide+, In Proceedings of the Ninth International Conference on Intelligent Systems Design and Applications, pages 553-559, 2009</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/109" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A framework for automatic text generation of trends in physiological time series data, Banaee+, In Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics, 2013</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/98" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Global Model for Concept-to-Text Generation, Konstas+, Journal of Artificial Intelligence Research, Vol. 48, pp.305--346, 2013</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/88" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] What to talk about and how? Selective Generation using LSTMs with Coarse-to-Fine Alignment, Mei+, NAACL-HLT’16</a>
<span class="snippet"><span>Comment</span><p>content-selectionとsurface realizationをencoder-decoder alignerを用いて同時に解いたという話。<br><br>普通のAttention basedなモデルにRefinerとPre-Selectorと呼ばれる機構を追加。通常のattentionにはattentionをかける際のaccuracyに問題があるが、data2textではきちんと参照すべきレコードを参照し生成するのが大事なので、RefinerとPre-Selectorでそれを改善する。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34460874-1b5830a2-ee5f-11e7-9220-c67a806225d8.png" alt="image" loading="lazy"><br><br><br><br>Pre-selectorは、それぞれのレコードが選択される確率を推定する（通常のattentionはalignmentの尤度を計算するのみ）。<br><br>Refinerはaligner(attention)のweightをreweightingすることで、最終的にどのレコードを選択するか決定する。<br><br>加えて、ロス関数のRegularizationのかけかたを変え、最低一つのレコードがpreselectorに選ばれるようにバイアスをかけている。<br><br><br><br>ほぼ初期のNeural Network basedなData2Text研究</p></span><br><br>
<button onclick="hideContent(0)" style="display: none;">hide</button>
&lt;/div&gt;
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<script>
  document.addEventListener('DOMContentLoaded', function() {
    const tweets = document.querySelectorAll('.tweet-embed[data-embed]');

    if ('IntersectionObserver' in window) {
      const observer = new IntersectionObserver((entries, obs) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            const el = entry.target;
            const html = el.getAttribute('data-embed');
            if (html) {
              const placeholder = el.querySelector('.tweet-placeholder');
              if (placeholder) placeholder.remove();

              el.innerHTML = html.trim();

              if (window.twttr?.widgets?.load) {
                window.twttr.widgets.load(el);
              }
            }
            obs.unobserve(el); // 処理済みは監視解除
          }
        });
      }, {
        rootMargin: '500px 0px', // 画面手前200pxで読み込み開始
        threshold: 0
      });

      tweets.forEach(tweet => observer.observe(tweet));

    } else {
      // IntersectionObserver未対応ブラウザ用のフォールバック
      function lazyLoadFallback() {
        tweets.forEach(el => {
          if (el.getAttribute('data-embed') && el.getBoundingClientRect().top < window.innerHeight) {
            const html = el.getAttribute('data-embed');
            const loadingImg = el.querySelector('.tweet-loading');
            if (loadingImg) loadingImg.remove();
            el.innerHTML = html.trim();
            el.removeAttribute('data-embed');
            if (window.twttr?.widgets?.load) {
              window.twttr.widgets.load(el);
            }
          }
        });
      }
      window.addEventListener('scroll', lazyLoadFallback);
      lazyLoadFallback();
    }
  });
</script>
</div>


    </div>

</article>
<div class="post-nav">
<a class="previous" href="/paper_notes/articles/NLP.html" title="NLPに関する論文・技術記事メモの一覧">NLPに関する論文・技術記事メモの一覧</a><a class="next" href="/paper_notes/articles/NaturalLanguageUnderstanding.html" title="NaturalLanguageUnderstandingに関する論文・技術記事メモの一覧">NaturalLanguageUnderstandingに関する論文・技術記事メモの一覧</a>
</div>
<div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li class="">
          <a class="post-link" href="/paper_notes/articles/DyingReLU.html" title="DyingReLUに関する論文・技術記事メモの一覧">
            DyingReLUに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/Visual%20Words.html" title="Visual Wordsに関する論文・技術記事メモの一覧">
            Visual Wordsに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/Scheduler.html" title="Schedulerに関する論文・技術記事メモの一覧">
            Schedulerに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/Zero_Few_ManyShotPrompting.html" title="Zero/Few/ManyShotPromptingに関する論文・技術記事メモの一覧">
            Zero/Few/ManyShotPromptingに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
</ul>
    </div>
<div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">TOC</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent =  menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3, h4, h5, h6");

    // Hide menu when no headings
    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // Generate post menu
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#h-' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }

    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';

    // The header element
    var header = document.querySelector('header.site-header');

    function doMenuCollapse(index, over_items) {
      var items = menuContent.firstChild.children;

      if (over_items == undefined) {
        over_items = 20;
      }

      if (items.length < over_items) {
        return;
      }

      var activeItem = items[index];
      var beginItem = activeItem
      var endItem = activeItem
      var beginIndex = index;
      var endIndex = index + 1;
      while (beginIndex >= 0
        && !items[beginIndex].classList.contains('h-h2')) {
        beginIndex -= 1;
      }
      while (endIndex < items.length
        && !items[endIndex].classList.contains('h-h2')) {
        endIndex += 1;
      }
      for (var i = 0; i < beginIndex; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
      for (var i = beginIndex + 1; i < endIndex; i++) {
        item = items[i]
        // if (!item.classList.contains('h-h2')) {
          item.style.display = '';
        // }
      }
      for (var i = endIndex; i < items.length; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
    }

    // Init menu collapsed
    doMenuCollapse(-1);

    // Active the menu item
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header.getBoundingClientRect();
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var headerHeight = headerTop + headerHeight + 20;
        if (headingRect.top <= headerHeight) {
          var id = 'h-' + h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          if (curActive) {
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }
      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
        doMenuCollapse(activeIndex);
      }
      event.preventDefault();
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/paper_notes/"></data>

  <div class="wrapper">
    <div class="site-footer-inner">
<div>Copyright © 2023-current AkihikoWATANABE. The header images and any thumbnail images for the posts were generated by ChatGPT's DALL-E3.</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="https://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div class="footer-col rss-subscribe">Subscribe <a href="/paper_notes/feed.xml">via RSS</a>
</div>
    </div>
  </div>
</footer>
</body>
  </html>
