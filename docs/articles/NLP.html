<!DOCTYPE html>
<html lang="ja">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>NLPã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§ | ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="NLPã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
<meta name="author" content="AkihikoWATANABE">
<meta property="og:locale" content="ja">
<meta name="description" content="NLP #Pocket #LanguageModel #Reasoning #OpenWeight #One-Line Notes">
<meta property="og:description" content="NLP #Pocket #LanguageModel #Reasoning #OpenWeight #One-Line Notes">
<link rel="canonical" href="http://akihikowatanabe.github.io/paper_notes/articles/NLP.html">
<meta property="og:url" content="http://akihikowatanabe.github.io/paper_notes/articles/NLP.html">
<meta property="og:site_name" content="ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2025-10-08T00:44:29+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="NLPã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"AkihikoWATANABE"},"dateModified":"2025-10-08T00:44:29+00:00","datePublished":"2025-10-08T00:44:29+00:00","description":"NLP #Pocket #LanguageModel #Reasoning #OpenWeight #One-Line Notes","headline":"NLPã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§","mainEntityOfPage":{"@type":"WebPage","@id":"http://akihikowatanabe.github.io/paper_notes/articles/NLP.html"},"url":"http://akihikowatanabe.github.io/paper_notes/articles/NLP.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="icon" href="">
  <link rel="canonical" href="http://akihikowatanabe.github.io">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/main.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/custom_button.css">
  <script src="/paper_notes/assets/js/main.js"></script>
  <script src="https://d3js.org/d3.v5.min.js"></script><link type="application/atom+xml" rel="alternate" href="http://akihikowatanabe.github.io/paper_notes/feed.xml" title="ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ">
<script>
  function showMore(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "block";
          
      // ã“ã®ãƒœã‚¿ãƒ³ã®å‚ç…§ã‚’å–å¾—ã—ã¦éè¡¨ç¤ºã«ã—ã¾ã™
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "none";
      }
          
      // hideãƒœã‚¿ãƒ³ã®å‚ç…§ã‚’å–å¾—ã—ã¦è¡¨ç¤ºã—ã¾ã™
      const hideButton = contentDiv.querySelector('button[onclick^="hideContent"]');
      if (hideButton) {
        hideButton.style.display = "block";
      }
    }
  }

  function hideContent(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "none";
  
      // moreãƒœã‚¿ãƒ³ã®å‚ç…§ã‚’å–å¾—ã—ã¦è¡¨ç¤ºã—ã¾ã™
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "block";
      }
  
      // ã“ã®ãƒœã‚¿ãƒ³ã‚’éš ã—ã¾ã™
      const hideButtons = document.querySelectorAll('button[onclick^="hideContent"]');
      const hideButton = hideButtons[index];
      if (hideButton) {
        hideButton.style.display = "none";
      }
    }
  }
</script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js" async></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe-lightbox.umd.min.js" async></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe.umd.min.js" async></script>
<link href="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/photoswipe.min.css" rel="stylesheet">
<style>
  .pswp .pswp__container .pswp__img {
    background-color: white;
  }
</style>

<script>
  function initPhotoSwipe() {
    let customOptions = {};

    try {
      const data = `{"gallery"=>"section.main", "children"=>"a.photo-swipe", "bgOpacity"=>0.8, "padding"=>{"top"=>20, "bottom"=>40, "left"=>100, "right"=>100}}`.replaceAll("=>", ":");
      customOptions = JSON.parse(data);
    } catch (e) {
      console.info("Invalid custom photo previewer options! " + e.message);
    }

    // Define object and gallery options
    const options = Object.assign(
      {
        gallery: "section.main",
        children: "a.photo-swipe",
        photo_scale: 2,
        // dynamic import is not supported in UMD version
        pswpModule: PhotoSwipe,
      },
      customOptions
    );

    const galleryEl = document.querySelector(options.gallery);
    if (!galleryEl) {
      return;
    }

    const imgEls = [];
    const els = galleryEl.querySelectorAll("img:not(.emoji)");
    els.forEach((el) => {
      if (el.src.trim() == "") {
        return;
      }
      if (!imgEls.includes(el)) {
        imgEls.push(el);
      }
    });

    if (imgEls.length === 0) {
      return;
    }

    imgEls.forEach((imgEl) => {
      imgEl.outerHTML = `
      <a class="photo-swipe"
        href="${imgEl.src}"
        data-pswp-width="${
          Math.max(imgEl.naturalWidth, imgEl.width) * options.photo_scale
        }"
        data-pswp-height="${
          Math.max(imgEl.naturalHeight, imgEl.height) * options.photo_scale
        }"
        data-pswp-caption="${imgEl.getAttribute("caption") || imgEl.alt}"
        target="_blank">
        ${imgEl.outerHTML}
      </a>`;
    });

    // Initialize PhotoSwipe 5
    var lightbox = new PhotoSwipeLightbox(options);

    lightbox.init();
  }

  window.addEventListener("load", initPhotoSwipe);
</script>
<meta name="google-site-verification" content="u_DTTPcCZ806iq51zgirHyWq3556HUKGq8AQfH91iFI">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-P70KSB88WH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-P70KSB88WH');
  </script>

<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"},"svg":{"fontCache":"global"}}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>





































































































































<header class="site-header site-header-transparent" role="banner">

  <div class="wrapper">
    <div class="site-header-inner">
<span class="site-brand"><a class="site-brand-inner" rel="author" href="/paper_notes/">
  <img class="site-favicon" title="ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ" src="" onerror="this.style.display='none'">
  ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger">
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewbox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
              </svg>
            </span>
          </label>

          <div class="trigger">









<span class="page-link">



<div id="google_translate_element" style="display: none;">
</div>

<span class="ct-language">
  <ul class="list-unstyled ct-language-dropdown">
    
      <li>
        <a href="#" class="lang-select" data-lang="en">
          
          <img src="https://cdn.countryflags.com/thumbs/united-states-of-america/flag-400.png" title="English">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="fr">
          
          <img src="https://cdn.countryflags.com/thumbs/france/flag-400.png" title="French">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="zh-CN">
          
          <img src="https://cdn.countryflags.com/thumbs/china/flag-400.png" title="Chinese(Simple)">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ja">
          
          <img src="https://cdn.countryflags.com/thumbs/japan/flag-400.png" title="Japanese">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ko">
          
          <img src="https://cdn.countryflags.com/thumbs/south-korea/flag-400.png" title="Korean">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ru">
          
          <img src="https://cdn.countryflags.com/thumbs/russia/flag-400.png" title="Russian">
          
        </a>
      </li>
    
  </ul>
</span>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'ja',
    autoDisplay: false,
    layout: google.translate.TranslateElement.InlineLayout.VERTICAL
  }, 'google_translate_element');

  // Links to cross-origin destinations are unsafe
  var gll = document.getElementsByClassName('goog-logo-link')[0];
  if (gll) {
    gll.setAttribute('rel', 'noopener');
  }

  function restoreLang() {
    var iframe = document.getElementsByClassName('goog-te-banner-frame')[0];
    if (!iframe) return;

    var innerDoc = iframe.contentDocument || iframe.contentWindow.document;
    var restore_el = innerDoc.getElementsByTagName("button");

    for (var i = 0; i < restore_el.length; i++) {
      if (restore_el[i].id.indexOf("restore") >= 0) {
        restore_el[i].click();
        var close_el = innerDoc.getElementsByClassName("goog-close-link");
        close_el[0].click();
        return;
      }
    }
  }

  function triggerHtmlEvent(element, eventName) {
    var event;
    if (document.createEvent) {
      event = document.createEvent('HTMLEvents');
      event.initEvent(eventName, true, true);
      element.dispatchEvent(event);
    } else {
      event = document.createEventObject();
      event.eventType = eventName;
      element.fireEvent('on' + event.eventType, event);
    }
  }

  var googleCombo = document.querySelector("select.goog-te-combo");
  var langSelect = document.querySelector('.ct-language');
  langSelect.addEventListener('click', function(event) {
    if (!event.target) {
      return;
    }

    var selected = document.querySelector('.ct-language .ct-language-selected');
    if (selected) {
      selected.classList.remove('ct-language-selected');
    }

    var target = event.target;
    while (target && target !== langSelect ) {
      if (target.matches('.lang-select')) {
        break;
      }
      target = target.parentElement;
    }

    if (target && target.matches('.lang-select')) {
      var lang = target.getAttribute('data-lang');
      if (googleCombo.value == lang) {
        restoreLang();
      } else {
        target.parentElement.classList.add('ct-language-selected');
        googleCombo.value = lang;
        triggerHtmlEvent(googleCombo, 'change');
      }
    }

    event.preventDefault();
  });
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit" async></script>
</span>
</div>
        </nav>
</div>
  </div>
</header>

<script>
  function initHeader() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;

    function storeScrollData() {
      var y = getScrollPos().y;documentElement.setAttribute("data-header-transparent", "");var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0) ? true : false;
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
    }

    window.addEventListener('scroll', function(e) {
      storeScrollData();
    });

    storeScrollData();
  }
  document.addEventListener('DOMContentLoaded', initHeader);
</script>


























































































































































<style>
    html .page-banner .page-banner-img > *:first-child {
      opacity: 0.4;
    }

    html[data-theme="dark"] .page-banner .page-banner-img > *:first-child {
      opacity: 0.2872;
    }
  </style>
<section class="page-banner">
    <div class="page-banner-img">
<div style="background-image: url(/paper_notes/assets/images/banner.png)"></div>
        <img class="img-placeholder" src="/paper_notes/assets/images/banner.png">
</div>
    <div class="wrapper">
      <div class="page-banner-inner">
<header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ</h1>
  <h2 class="post-subtitle">å‹‰å¼·ã—ãŸè«–æ–‡ã‚„æŠ€è¡“ç­‰ã®æƒ…å ±ã‚’Githubã®Issueã«ãƒ¡ãƒ¢ã£ã¦ã„ã‚‹ã²ã¨ã®ãƒ–ãƒ­ã‚°ã€‚
ãã‚Œãªã‚Šã«ãƒ¡ãƒ¢ã®é‡ãŒè“„ç©ã•ã‚Œã¦ããŸã®ã§ã€ä¸€åº¦æ•´ç†ã—ãŸã„ãªã¨æ€ã„ãƒ–ãƒ­ã‚°ã¯ã˜ã‚ã¦ã¿ã¾ã—ãŸï¼
è‡ªç„¶è¨€èªå‡¦ç†(NLP), æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ (RecommenderSystem), Educational Data Mining (EDM), Learning Analytics (LA)ãªã©ã®åˆ†é‡ã®ãƒ¡ãƒ¢ãŒå¤šã„ã¨æ€ã„ã¾ã™ã€‚
æœ€è¿‘ã¯ç‰¹ã«LLMã®å‹‰å¼·ãŒå¤šã‚ã§ã™ :)</h2>

  <div class="post-meta">
    <time class="dt-published" datetime="2025-10-08T00:44:29+00:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Oct 8, 2025
    </time><span class="post-author left-vsplit"><i class="fa fa-pencil"></i> AkihikoWATANABE</span>
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 55 hours 2 mins</span>
  </div></header>
</div>
    </div>
  </section><script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    hashValue = decodeURIComponent(hashValue);
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('off' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<div id="click-to-top" class="click-to-top">
  <i class="fa fa-arrow-up"></i>
</div>
<script>
  (function () {
    const clickToTop = document.getElementById('click-to-top');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 100) {
        clickToTop.classList.add('show')
      }else {
        clickToTop.classList.remove('show')
      }
    });
    clickToTop.addEventListener('click', () => {
      window.smoothScrollTo(0);
    });
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <h2 id="NLP"> NLP</h2>
<div class="visible-content">
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>


<br>


<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3151" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Magistral, Mistral-AI+, arXiv'25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- Mistralã®æ¨è«–ãƒ¢ãƒ‡ãƒ«Magistralã¨ç‹¬è‡ªã®å¼·åŒ–å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç´¹ä»‹ã€‚ã‚¼ãƒ­ã‹ã‚‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€LLMã®RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®é™ç•Œã‚’æ¢ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã¿ã§ã®RLãŒèƒ½åŠ›ã‚’ç¶­æŒã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚Magistral Mediumã¯RLã®ã¿ã§è¨“ç·´ã•ã‚Œã€Magistral Smallã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nrehiew_/status/1974856956600111250?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2858" target="_blank" rel="noopener noreferrer">Magistral-Small-2509, MistralAI, 2025.09</a>
</p>
<p>MistralAIã®åˆã‚ã¦ã®reasoningãƒ¢ãƒ‡ãƒ«</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Finetuning.html" target="_blank" rel="noopener noreferrer">#Finetuning</a>
<a class="button" href="articles/EvolutionaryAlgorithm.html" target="_blank" rel="noopener noreferrer">#EvolutionaryAlgorithm</a>


<br>


<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3150" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Evolution Strategies at Scale: LLM Fine-Tuning Beyond Reinforcement  Learning, Xin Qiu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- é€²åŒ–æˆ¦ç•¥ï¼ˆESï¼‰ã‚’ç”¨ã„ã¦ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹åˆã®æˆåŠŸäº‹ä¾‹ã‚’å ±å‘Šã€‚ESã¯æ•°åå„„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¯¾ã—ã¦åŠ¹ç‡çš„ã«æ¢ç´¢ã§ãã€ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ã‚„ãƒ­ãƒã‚¹ãƒˆæ€§ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å®‰å®šæ€§ã«ãŠã„ã¦æ—¢å­˜ã®å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®æ–°ãŸãªæ–¹å‘æ€§ãŒé–‹ã‹ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hardmaru/status/1975463342576918845?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>


<br>


<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3148" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive  Experts, Jihoon Lee+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- dLLMsã¯ç•°ãªã‚‹ç”Ÿæˆé †åºã«åŸºã¥ãå°‚é–€çš„ãªæŒ™å‹•ã‚’å­¦ç¿’ã™ã‚‹ãŒã€å›ºå®šã•ã‚ŒãŸæ¨è«–ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯æ€§èƒ½ã‚’ä½ä¸‹ã•ã›ã‚‹ã€‚HEXã¨ã„ã†æ–°æ‰‹æ³•ã‚’å°å…¥ã—ã€ç•°ãªã‚‹ãƒ–ãƒ­ãƒƒã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’è¡Œã†ã“ã¨ã§ã€ç²¾åº¦ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã€‚GSM8Kã‚„MATHã€ARC-Cã€TruthfulQAãªã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é¡•è‘—ãªæ”¹å–„ã‚’ç¤ºã—ã€ãƒ†ã‚¹ãƒˆæ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®æ–°ãŸãªãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ç¢ºç«‹ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1975467150002229557?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯æ°—ã«ãªã‚‹ğŸ‘€</p></span><br><br>
</div>
<p><button onclick="showMore(0)">more</button></p>
<div class="hidden-content">
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3146" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Echo Chamber: RL Post-training Amplifies Behaviors Learned in   Pretraining, Rosie Zhao+, COLM'25, 2025.04</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã«ã‚ˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€æ•°å­¦çš„æ¨è«–ã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãŸã‚ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã—ã¦ã„ã‚‹ãŒã€ãã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯æœªè§£æ˜ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€ã•ã¾ã–ã¾ãªã‚¹ã‚±ãƒ¼ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹RLãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŠ¹æœã‚’èª¿æŸ»ã—ã€RLã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒå‡ºåŠ›åˆ†å¸ƒã«åæŸã—ã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å¢—å¹…ã™ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚ã¾ãŸã€ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ãŒç•°ãªã‚‹å‡ºåŠ›åˆ†å¸ƒã«åæŸã™ã‚‹ã“ã¨ã‚„ã€ç°¡å˜ãªè³ªå•ã¸ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒé›£ã—ã„è³ªå•ã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€RLã®å½¹å‰²ã«é–¢ã™ã‚‹æ–°ãŸãªæ´å¯ŸãŒå¾—ã‚‰ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosieyzh/status/1975276617078571277?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3145" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Omni-Embed-Nemotron: A Unified Multimodal Retrieval Model for Text,  Image, Audio, and Video, Mengyao Xu+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ã€ŒOmni-Embed-Nemotronã€ã¯ã€è¤‡é›‘ãªæƒ…å ±ãƒ‹ãƒ¼ã‚ºã«å¿œãˆã‚‹ãŸã‚ã®çµ±ä¸€çš„ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¤œç´¢åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚å¾“æ¥ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ãŒè¦–è¦šçš„ã«è±Šã‹ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«å¯¾å¿œã§ããªã„ä¸­ã€ColPaliã®ç ”ç©¶ã‚’åŸºã«ã€ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€éŸ³å£°ã€å‹•ç”»ã‚’çµ±åˆã—ãŸæ¤œç´¢ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«ãŠã‚ˆã³ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ€ãƒ«æ¤œç´¢ã‚’å¯èƒ½ã«ã—ã€ãã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨è©•ä¾¡çµæœã‚’é€šã˜ã¦ã€æ¤œç´¢ã®åŠ¹æœã‚’å®Ÿè¨¼ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1975418540510618111?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3144" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Pretraining with hierarchical memories: separating long-tail and common  knowledge, Hadi Pouransari+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- ç¾ä»£ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ä¾å­˜ã—ã¦ã„ã‚‹ãŒã€ã™ã¹ã¦ã®ä¸–ç•ŒçŸ¥è­˜ã‚’åœ§ç¸®ã™ã‚‹ã®ã¯éç¾å®Ÿçš„ã§ã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ãƒ¡ãƒ¢ãƒªæ‹¡å¼µã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ææ¡ˆã—ã€å°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ãŒéšå±¤çš„ãªãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ä»•çµ„ã¿ã‚’å°å…¥ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€160Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã«18Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¡ãƒ¢ãƒªã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€é€šå¸¸ã®ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã€‚ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã«ãŠã‘ã‚‹ãƒ¡ãƒ¢ãƒªã®æœ€é©ãªã‚¿ã‚¤ãƒ—ã¨ã‚µã‚¤ã‚ºã‚’ç ”ç©¶ã—ã€ææ¡ˆã—ãŸãƒ¡ãƒ¢ãƒªãŒå …ç‰¢ã«æ©Ÿèƒ½ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hpouransari/status/1975203449680937171?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3142" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Compressed Convolutional Attention: Efficient Attention in a Compressed  Latent Space, Tomas Figliolia+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Compressed Convolutional Attentionï¼ˆCCAï¼‰ã‚’ææ¡ˆã—ã€ã‚¯ã‚¨ãƒªã€ã‚­ãƒ¼ã€ãƒãƒªãƒ¥ãƒ¼ã‚’ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦å…¨ã¦ã®æ³¨æ„æ“ä½œã‚’å…±æœ‰ã•ã‚ŒãŸæ½œåœ¨ç©ºé–“å†…ã§å®Ÿè¡Œã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€FLOPã‚’å¤§å¹…ã«å‰Šæ¸›ã€‚ã•ã‚‰ã«ã€CCAã¨ãƒ˜ãƒƒãƒ‰å…±æœ‰ã‚’çµ„ã¿åˆã‚ã›ãŸCompressed Convolutional Grouped Query Attentionï¼ˆCCGQAï¼‰ã¯ã€è¨ˆç®—ã¨å¸¯åŸŸå¹…ã®åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã€GQAã‚„MLAã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚å®Ÿé¨“ã§ã¯ã€CCGQAãŒMoEãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ä»–ã®æ³¨æ„ãƒ¡ã‚½ãƒƒãƒ‰ã‚’åœ§å€’ã—ã€MHAã¨æ¯”è¼ƒã—ã¦ã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¶­æŒã—ã¤ã¤KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’8å€åœ§ç¸®ã€‚H100 GPUä¸Šã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨äº‹å‰ãƒ•ã‚£ãƒ«ã®é€Ÿåº¦ã‚’å¤§å¹…ã«å‘ä¸Šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stochasticchasm/status/1975390382537252984?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Denseãƒ¢ãƒ‡ãƒ«ã¨MoEãƒ¢ãƒ‡ãƒ«ã§Attentionã®å„ç¨®variantã®æ€§èƒ½ãŒå¤§ããå¤‰åŒ–ã™ã‚‹æ¨¡æ§˜ã€‚ã‹ã¤ã€ææ¡ˆæ‰‹æ³•ã¯ã©ã¡ã‚‰ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚‚è‰¯ã„æ€§èƒ½ã‚’é”æˆã™ã‚‹æ¨¡æ§˜(Fig3,4)ã€‚</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1975427848371367982?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3140" target="_blank" rel="noopener noreferrer" class="title-link">è¨€èªãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨æ©Ÿåºï¼šè§£æã¨è§£é‡ˆ, HEINZERLING+, NLP'25, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1975322325181686097?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/GenerativeAdversarialNetwork.html" target="_blank" rel="noopener noreferrer">#GenerativeAdversarialNetwork</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3137" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Evolving LLMs via Continual Instruction Tuning, Jiazheng Kang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- MoE-CLã¯ã€ç”£æ¥­ç’°å¢ƒã«ãŠã‘ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç¶™ç¶šå­¦ç¿’ã‚’æ”¯æ´ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€ã‚¿ã‚¹ã‚¯ã”ã¨ã®LoRAå°‚é–€å®¶ã¨å…±æœ‰LoRAå°‚é–€å®¶ã‚’ç”¨ã„ã¦çŸ¥è­˜ã®ä¿æŒã¨ã‚¯ãƒ­ã‚¹ã‚¿ã‚¹ã‚¯ã®ä¸€èˆ¬åŒ–ã‚’å®Ÿç¾ã€‚æ•µå¯¾çš„å­¦ç¿’ã«ã‚ˆã‚Šã€ã‚¿ã‚¹ã‚¯ã«é–¢é€£ã™ã‚‹æƒ…å ±ã®ã¿ã‚’é€šéã•ã›ã‚‹è­˜åˆ¥å™¨ã‚’çµ±åˆã—ã€è‡ªå·±é€²åŒ–ã‚’ä¿ƒé€²ã€‚å®Ÿé¨“çµæœã§ã¯ã€Tencent Videoãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã®æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚³ã‚¹ãƒˆã‚’15.3%å‰Šæ¸›ã—ã€å®Ÿç”¨æ€§ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1975059944815595710?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>continual instruction tuning... ãã—ã¦GAN!?</p>
<p>ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®çŸ¥è­˜ã‚’å‚™ãˆãŸLoRAã¨ã€ã‚¿ã‚¹ã‚¯é–“ã§å…±æœ‰ã•ã‚Œã‚‹LoRAãŒã‚¯ãƒ­ã‚¹ã‚¿ã‚¹ã‚¯ã®è»¢ç§»ã‚’ä¿ƒã—ã€ãã‚Œãã‚Œã‚’MoEã«ãŠã‘ã‚‹expertsã¨ã—ã¦æ‰±ã†ã“ã¨ã§ã€inputã«å¯¾ã—ã¦å‹•çš„ã«å¿…è¦ãªLoRA expertsã‚’é¸æŠã™ã‚‹ã€‚ã“ã®ã¨ãã€Task Classifierï¼ˆAdversarialã«è¨“ç·´ã™ã‚‹ï¼‰ã§ã‚¿ã‚¹ã‚¯ã«é–¢ä¿‚ãªã„æƒ…å ±ãŒé †ä¼æ¬ã•ã‚Œãªã„ã‚ˆã†ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã£ã½ã„ï¼Ÿï¼ˆGANã‚’Text Classifierã®å­¦ç¿’ã«ä½¿ã„ã€Classifierã®æƒ…å ±ã‚’ç”¨ã„ã‚‹ã“ã¨ã§å…±æœ‰/ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®LoRA expertsãŒå­¦ç¿’ã•ã‚Œã‚‹ã‚ˆã†ã«ä¿ƒã™ã‚ˆã†ã ãŒã€ç´°ã‹ãã©ã†ã‚„ã‚‹ã‹ã¯èª­ã¾ãªã„ã¨ã‚ã‹ã‚‰ãªã„ï¼‰ã€‚<br><br>ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®ã‚¿ã‚¹ã‚¯ã¨ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã€ã•ã¾ã–ã¾ãªã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’è¿½åŠ ã—ã¦ã„ãã€catastrophic forgettingã‚’é˜²ããªãŒã‚‰ã€æ‰±ãˆã‚‹ã‚¿ã‚¹ã‚¯ã®å¹…ãŒåºƒãŒã£ã¦ã„ãæ çµ„ã¿è‡ªä½“ã¯é¢ç™½ãã†ï¼ˆå­¦ç¿’ã¯æœãŸã—ã¦å®‰å®šã™ã‚‹ã®ã ã‚ã†ã‹ï¼‰ã€‚<br><br><img src="https://github.com/user-attachments/assets/a09b2021-d487-49d5-9782-35b8e613d0a8" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<span class="issue_date">Issue Date: 2025-10-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3132" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Free Draft-and-Verification: Toward Lossless Parallel Decoding for  Diffusion Large Language Models, Shutong Wu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- Diffusion Large Language Models (DLLMs)ã¯ã€åŒæ–¹å‘ã®æ³¨æ„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ã‚ˆã‚Šæ–‡è„ˆã‚’æ‰ãˆã‚‹èƒ½åŠ›ãŒé«˜ã„ãŒã€æ¨è«–åŠ¹ç‡ãŒè‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«ã«åŠ£ã‚‹ã€‚æ—¢å­˜ã®ä¸¦åˆ—ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯æ€§èƒ½ä½ä¸‹ã‚’ä¼´ã†ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€æå¤±ã®ãªã„ä¸¦åˆ—ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å®Ÿç¾ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€ŒFree Draft-and-Verificationï¼ˆFreedaveï¼‰ã€ã‚’ææ¡ˆã€‚Freedaveã«ã‚ˆã‚Šã€DLLMsã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¯æ•°å­¦çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã§æœ€å¤§2.8å€å‘ä¸Šã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lingyang_pu/status/1974754204473536620?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/VariationalAutoEncoder.html" target="_blank" rel="noopener noreferrer">#VariationalAutoEncoder</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<span class="issue_date">Issue Date: 2025-10-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3131" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Limited Preference Data? Learning Better Reward Model with Latent Space  Synthesis, Leitian Tao+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å ±é…¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®ãŸã‚ã«ã€LLMã®æ½œåœ¨åŸ‹ã‚è¾¼ã¿ç©ºé–“ã§å¥½ã¿ãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã™ã‚‹æ–°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯LENSã‚’ææ¡ˆã€‚VAEã‚’ç”¨ã„ã¦åŸ‹ã‚è¾¼ã¿ã®æ§‹é€ åŒ–ã•ã‚ŒãŸè¡¨ç¾ã‚’å­¦ç¿’ã—ã€ã‚³ã‚¹ãƒˆã®ã‹ã‹ã‚‹ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’å›é¿ã—ã¤ã¤ã€å¤šæ§˜ã§ä¸€è²«ã—ãŸåˆæˆå¥½ã¿ãƒšã‚¢ã‚’ç”Ÿæˆã€‚å®Ÿé¨“ã§ã¯ã€åˆæˆãƒšã‚¢ãŒå…ƒã®å¥½ã¿ã®é †åºã‚’ä¿æŒã—ã€å ±é…¬ãƒ¢ãƒ‡ãƒ«ã®ä¸€èˆ¬åŒ–ã‚’æ”¹å–„ã€‚ç”Ÿæˆé€Ÿåº¦ã¯18å€é€Ÿãã€16,000å€å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã§å„ªã‚ŒãŸçµæœã‚’é”æˆã€‚åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’é€šã˜ã¦å ±é…¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚’å¼·åŒ–ã™ã‚‹åŠ¹æœçš„ãªæ‰‹æ³•ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sharonyixuanli/status/1974871491117187099?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3128" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] IA2: Alignment with ICL Activations Improves Supervised Fine-Tuning, Aayush Mishra+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã®æ´»æ€§åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ©ç”¨ã—ã¦ã€ç›£è¦–ä»˜ããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã®å“è³ªã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚ICLã¨SFTã®ç•°ãªã‚‹é©å¿œãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ç¤ºã—ã€ICLæ´»æ€§åŒ–ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆIA2ï¼‰ã¨ã„ã†è‡ªå·±è’¸ç•™æŠ€è¡“ã‚’å°å…¥ã€‚IA2ã‚’SFTã®å‰ã«å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ç²¾åº¦ã¨ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’12ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å®Ÿè¨¼ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«é©å¿œã®å†…éƒ¨ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«å¯¾ã™ã‚‹æ–°ãŸãªè¦–ç‚¹ã‚‚æä¾›ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/danielkhashabi/status/1974119053728919790?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3127" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GTA1: GUI Test-time Scaling Agent, Yan Yang+, arXiv'25, 2025.07</a>
<span class="snippet"><span>GPT Summary</span>- GTA1ã¨ã„ã†GUIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŒ‡ç¤ºã‚’åˆ†è§£ã—ã€è¦–è¦šè¦ç´ ã¨ç›¸äº’ä½œç”¨ã—ãªãŒã‚‰ã‚¿ã‚¹ã‚¯ã‚’è‡ªå¾‹çš„ã«å®Œäº†ã—ã¾ã™ã€‚è¨ˆç”»ã®é¸æŠã¨è¦–è¦šã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã®æ­£ç¢ºãªç›¸äº’ä½œç”¨ã¨ã„ã†2ã¤ã®èª²é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ãƒ†ã‚¹ãƒˆæ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ç”¨ã„ã¦æœ€é©ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆã‚’é¸ã³ã€å¼·åŒ–å­¦ç¿’ã‚’é€šã˜ã¦åŸºã¥ã‘ã‚’æ”¹å–„ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€GTA1ã¯åŸºã¥ã‘ã¨ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã®ä¸¡æ–¹ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lijunnan0409/status/1974253028917309608?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3123" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generalized Parallel Scaling with Interdependent Generations, Harry Dong+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Bridgeã‚’ææ¡ˆã—ã€ä¸¦åˆ—LLMæ¨è«–ã§ç›¸äº’ä¾å­˜ã™ã‚‹å¿œç­”ã‚’ç”Ÿæˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¹³å‡ç²¾åº¦ãŒæœ€å¤§50%å‘ä¸Šã—ã€ä¸€è²«æ€§ãŒå¢—ã™ã€‚è¨“ç·´å¾Œã¯ä»»æ„ã®ç”Ÿæˆå¹…ã«ã‚¹ã‚±ãƒ¼ãƒ«å¯èƒ½ã§ã€ç‹¬ç«‹ç”Ÿæˆã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1974191420329390224?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/OOD.html" target="_blank" rel="noopener noreferrer">#OOD</a>
<a class="button" href="articles/Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3121" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Visual Instruction Bottleneck Tuning, Changdae Oh+, NeurIPS'25, 2025.05</a>
<span class="snippet"><span>GPT Summary</span>- MLLMã¯æœªçŸ¥ã®ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ãŒã€æ—¢å­˜ã®æ”¹å–„ç­–ã¯å¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚„è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’è¦ã™ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æƒ…å ±ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åŸç†ã«åŸºã¥ãã€MLLMã®å …ç‰¢æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®Vittleã‚’ææ¡ˆã€‚45ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å®Ÿè¨¼å®Ÿé¨“ã«ã‚ˆã‚Šã€VittleãŒMLLMã®å …ç‰¢æ€§ã‚’ä¸€è²«ã—ã¦æ”¹å–„ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sharonyixuanli/status/1974150056501535207?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3120" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Nudging the Boundaries of LLM Reasoning, Justin Chih-Yao Chen+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- NuRLã¯ã€è‡ªå·±ç”Ÿæˆã•ã‚ŒãŸãƒ’ãƒ³ãƒˆã‚’ç”¨ã„ã¦ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ä¸Šé™ã‚’å¼•ãä¸Šã’ã‚‹æ‰‹æ³•ã§ã‚ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã¯é€£é–çš„æ€è€ƒã‚’ç”Ÿæˆã—ã€é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã—ã¦ãƒ’ãƒ³ãƒˆã‚’æ³¨å…¥ã™ã‚‹ã“ã¨ã§åˆæ ¼ç‡ã‚’å‘ä¸Šã•ã›ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¿¡å·ã‚’å°å…¥ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åˆ†å¸ƒã®ã‚·ãƒ•ãƒˆã‚’å›é¿ã—ã¤ã¤ã€6ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ä¸€è²«ã—ãŸæ”¹å–„ã‚’é”æˆã€‚ç‰¹ã«ã€æœ€ã‚‚åŠ¹æœçš„ãªãƒ’ãƒ³ãƒˆã¯æŠ½è±¡çš„ã§é«˜ãƒ¬ãƒ™ãƒ«ã§ã‚ã‚Šã€GRPOã¨æ¯”è¼ƒã—ã¦ãƒ¢ãƒ‡ãƒ«ã®ä¸Šé™ã‚’å¼•ãä¸Šã’ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/beckypeng6/status/1973813689443889640?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RLã§å­¦ç¿’ã«åˆ©ç”¨ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®é›£æ˜“åº¦ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§æ€§èƒ½ä¸Šã’ã¾ã™ç³»ã®è©±ãŒæº¢ã‚Œã¦ã„ã‚‹ã€‚ã—ã‹ã—ã“ã®è©±ã¯ã©ã¡ã‚‰ã‹ã¨ã„ã†ã¨ä¸Šé™ã‚’æŠ¼ã—ä¸Šã’ã‚‹ã¿ãŸã„ãªè©±ã‚‰ã—ã„ï¼Ÿï¼ˆRLVRã¯è§£æ±ºå¯èƒ½ãªå•é¡Œã—ã‹å‹¾é…ãŒæµã‚Œãªã„ã¨ã„ã†èª²é¡Œï¼‰</p></span><br><br>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3115" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Towards Reliable Benchmarking: A Contamination Free, Controllable  Evaluation Framework for Multi-step LLM Function Calling, Seiji Maekawa+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- TaLMsã®è©•ä¾¡ã®ãŸã‚ã«ã€æ±šæŸ“ã®ãªã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯FuncBenchGenã‚’ææ¡ˆã€‚ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚’DAGä¸Šã®ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«ã¨ã—ã¦æ‰ãˆã€ãƒ¢ãƒ‡ãƒ«ã¯æ­£ã—ã„é–¢æ•°å‘¼ã³å‡ºã—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’æ§‹æˆã€‚7ã¤ã®LLMã‚’ç•°ãªã‚‹é›£æ˜“åº¦ã®ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã—ãŸçµæœã€GPT-5ãŒç‰¹ã«å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€ä¾å­˜ã®æ·±ã•ãŒå¢—ã™ã¨æ€§èƒ½ãŒä½ä¸‹ã€‚å¤ã„å¼•æ•°å€¤ã®ä¼æ’­ãŒå•é¡Œã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã€å†è¡¨ç¾æˆ¦ç•¥ã‚’å°å…¥ã—ãŸã¨ã“ã‚ã€æˆåŠŸç‡ãŒ62.5%ã‹ã‚‰81.3%ã«å‘ä¸Šã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ppezeshkpour/status/1973790323265749355?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Financial.html" target="_blank" rel="noopener noreferrer">#Financial</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3114" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] StockBench: Can LLM Agents Trade Stocks Profitably In Real-world  Markets?, Yanxu Chen+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®é‡‘èåˆ†é‡ã«ãŠã‘ã‚‹è©•ä¾¡ã®ãŸã‚ã«ã€StockBenchã¨ã„ã†æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã€‚ã“ã‚Œã¯ã€æ ªå¼å–å¼•ç’°å¢ƒã§ã®LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã—ã€ç´¯ç©ãƒªã‚¿ãƒ¼ãƒ³ã‚„ãƒªã‚¹ã‚¯ç®¡ç†èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ã€‚å¤šãã®LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã‚·ãƒ³ãƒ—ãƒ«ãªæˆ¦ç•¥ã‚’è¶…ãˆã‚‹ã®ãŒé›£ã—ã„ãŒã€ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯é«˜ã„ãƒªã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã™å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚StockBenchã¯å†ç¾æ€§ã‚’æ”¯æ´ã—ã€ä»Šå¾Œã®ç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ãŸã‚ã«ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦å…¬é–‹ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1974270437975523596?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj page:


<a href="https://stockbench.github.io" target="_blank" rel="noopener noreferrer">https://stockbench.github.io</a>


</p>
<p>éå»ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã„LLMã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã¨ã„ã†æ–¹å‘æ€§ãªã‚‰ã“ã†ã„ã£ãŸã‚¿ã‚¹ã‚¯ã‚‚è‰¯ã„ã®ã‹ã‚‚ã—ã‚Œãªã„ã€‚<br><br>ãŒã€ç´ æœ´ãªç–‘å•ã¨ã—ã¦ã€LLMãŒè‰¯ã„ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚’ã—ã¦å„²ã‘ã‚‰ã‚Œã¾ã™ã€ã¿ãŸã„ãªã‚·ã‚¹ãƒ†ãƒ ãŒä¸–ã«åºƒã¾ã£ãŸä¸–ç•Œã®å‰æã«ãªã‚‹ã¨ã€ãã‚Œã«ã‚ˆã£ã¦å¸‚å ´ã®åŸç†ãŒå¤‰ã‚ã£ã¦LLMå´ãŒå‰æã¨ã—ã¦ã„ãŸã‚‚ã®ãŒããšã‚Œã€çµæœçš„ã«LLMã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã§å„²ã‘ã‚‰ã‚Œãªããªã‚‹ã€ã¿ãŸã„ãªã“ã¨ãŒèµ·ãã‚‹ã‚“ã˜ã‚ƒãªã„ã‹ã€ã¨ã„ã†æ°—ã¯ã™ã‚‹ã®ã§ã‚ãã¾ã§LLMã®èƒ½åŠ›ã‚’æ¸¬ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã™ã€ã¨ã„ã†ç‚¹ã¯ç•™æ„ã—ãŸæ–¹ãŒè‰¯ã„ã®ã‹ãªã€ã¨ã„ã†æ„Ÿæƒ³ã‚’æŒã¤ãªã©ã—ãŸï¼ˆå®Ÿéš›ã¯ã‚ˆãã‚ã‹ã‚‰ã‚“ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/CurriculumLearning.html" target="_blank" rel="noopener noreferrer">#CurriculumLearning</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3112" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Prompt Curriculum Learning for Efficient LLM Post-Training, Zhaolin Gao+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Prompt Curriculum Learning (PCL)ã‚’ææ¡ˆã—ã€ä¸­ç¨‹åº¦ã®é›£æ˜“åº¦ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸æŠã—ã¦LLMã‚’ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹è»½é‡ãªå¼·åŒ–å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç´¹ä»‹ã€‚æœ€é©ãªãƒãƒƒãƒã‚µã‚¤ã‚ºã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠã®é‡è¦æ€§ã‚’å®Ÿé¨“ã§ç¢ºèªã—ã€PCLã¯æƒ…å ±è±Šå¯Œãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã“ã¨ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’å›é¿ã—ã€MATHãŠã‚ˆã³DeepScaleRã§ãã‚Œãã‚Œ$12.1\times$ãŠã‚ˆã³$16.9\times$ã®é€Ÿåº¦å‘ä¸Šã‚’å®Ÿç¾ã€‚çµæœã¯ã€æ¨è«–ã«ãŠã‘ã‚‹RLã®åŠ¹ç‡ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ”¹å–„ã™ã‚‹æ–°ãŸãªæ–¹æ³•è«–ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yzpang_/status/1974180214608703795?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ï¼ˆã–ã£ãã‚Šèª­ã¿ãªã®ã§èª¤ã‚Šã‚’å¤šåˆ†ã«å«ã‚€ã‹ã‚‚ã—ã‚Œãªã„ãŒãƒ¡ãƒ¢ï¼‰å‹¾é…ã®ãƒã‚¤ã‚ºã®ä½æ¸›ã¨ç”Ÿæˆã®é€Ÿåº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æœ€é©ã«ãƒãƒ©ãƒ³ã‚¹ã‚’ã¨ã‚‹ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€RLã®å­¦ç¿’åŠ¹ç‡ãŒä¸­é–“ç¨‹åº¦ï¼ˆç°¡å˜ã™ããšã€é›£ã—ã™ããªã„ï¼‰ã®é›£æ˜“åº¦ãŒè‰¯ã„ã“ã¨ã‚’ç¤ºã—ãŸã®ã¡ã€Valueãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã«åŸºã¥ã„ã¦æ›´æ–°ã•ã‚Œã‚‹æ¨¡æ§˜ï¼Ÿï¼‰ã‚’ç”¨ã„ã¦promptã‚’é¸æŠã—[^1]ä¸­é–“ç¨‹åº¦ã®promptã‚’ç”¨ã„ã¦ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’ã—å­¦ç¿’ã™ã‚‹ã‚ˆã†ãªã‚ªãƒ³ãƒãƒªã‚·ãƒ¼ã®RLã‚’ææ¡ˆã™ã‚‹ã€ã¿ãŸã„ãªè©±ãªæ¨¡æ§˜ã€‚<br><br>[^1]:æ—¢å­˜æ‰‹æ³•ã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã«ã‚ˆã£ã¦æ±‚ã‚ã‚‹æ–¹æ³•ï¼ˆè¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã™ãã‚‹ï¼‰ã‚„ã€äº‹å‰ã«æ±ºã‚ã¦ãŠã„ãŸè¾æ›¸ãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ï¼ˆç¾åœ¨ã®ãƒãƒªã‚·ãƒ¼ã‹ã‚‰ã¿ãŸæ™‚ã®é›£æ˜“åº¦ãŒåæ˜ ã•ã‚Œã¦ãŠã‚‰ãšåŠ¹ç‡ãŒæ‚ªã„ï¼‰ã®åŒæ–¹ã«æ¯”ã¹ã¦ã€é©åº¦ã«ã‚ªãƒ³ãƒãƒªã‚·ãƒ¼ã•ã‚’æ®‹ã—ãŸpromptã®é¸ã³æ–¹ã¨ãªã£ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/MCP.html" target="_blank" rel="noopener noreferrer">#MCP</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3111" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TOUCAN: Synthesizing 1.5M Tool-Agentic Data from Real-World MCP  Environments, Zhangchen Xu+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Toucanã¯ã€ç´„500ã®å®Ÿä¸–ç•Œã®ãƒ¢ãƒ‡ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‹ã‚‰åˆæˆã•ã‚ŒãŸ150ä¸‡ã®è»Œè·¡ã‚’å«ã‚€ã€æœ€å¤§ã®å…¬é–‹ãƒ„ãƒ¼ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æä¾›ã€‚å¤šæ§˜ã§ç¾å®Ÿçš„ãªã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆã—ã€ãƒãƒ«ãƒãƒ„ãƒ¼ãƒ«ãŠã‚ˆã³ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã«å¯¾å¿œã€‚5ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã€å³å¯†ãªæ¤œè¨¼ã‚’é€šã˜ã¦é«˜å“è³ªãªå‡ºåŠ›ã‚’ä¿è¨¼ã€‚Toucanã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€BFCL V3ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€MCP-Universe Benchã§ã®é€²å±•ã‚’å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhangchen_xu/status/1973972516483051709?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>dataset:


<a href="https://huggingface.co/datasets/Agent-Ark/Toucan-1.5M" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/Agent-Ark/Toucan-1.5M</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Sparse.html" target="_blank" rel="noopener noreferrer">#Sparse</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3109" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] VideoNSA: Native Sparse Attention Scales Video Understanding, Enxin Song+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- VideoNSAã¯ã€ãƒ“ãƒ‡ã‚ªç†è§£ã®ãŸã‚ã«Native Sparse Attentionã‚’é©ç”¨ã—ã€é•·ã„æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã§ã®ä¸€è²«æ€§ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã€‚216Kã®ãƒ“ãƒ‡ã‚ªæŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§Qwen2.5-VLã‚’ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€ãƒ†ã‚­ã‚¹ãƒˆã«ã¯å¯†ãªæ³¨æ„ã€ãƒ“ãƒ‡ã‚ªã«ã¯NSAã‚’ä½¿ç”¨ã€‚ãƒˆãƒ¼ã‚¯ãƒ³åœ§ç¸®ã‚„å¾“æ¥ã®ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨æ¯”è¼ƒã—ã¦ã€é•·ã„ãƒ“ãƒ‡ã‚ªç†è§£ã‚„æ™‚é–“çš„æ¨è«–ã§æ€§èƒ½ãŒå‘ä¸Šã€‚ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æã«ã‚ˆã‚Šã€ä¿¡é ¼æ€§ã®ã‚ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚„æ³¨æ„ã®æœ€é©é…åˆ†ãªã©ã®é‡è¦ãªç™ºè¦‹ãŒå¾—ã‚‰ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhaocha1/status/1974164887090684316?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3106" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Large Reasoning Models Learn Better Alignment from Flawed Thinking, ShengYun Peng+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- RECAPã¯ã€èª¤ã£ãŸæ¨è«–ã‚’è¦†ã—å®‰å…¨ãªå¿œç­”ã«å°ããŸã‚ã®å¼·åŒ–å­¦ç¿’æ‰‹æ³•ã€‚åˆæˆç”Ÿæˆã•ã‚ŒãŸåå¯¾æ•´åˆCoTã‚’ç”¨ã„ã¦è¨“ç·´ã—ã€å®‰å…¨æ€§ã¨å …ç‰¢æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚RECAPã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯è‡ªå·±åçœãŒé »ç¹ã§ã€é©å¿œæ”»æ’ƒã«ã‚‚å¼·ã„ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haozhu_wang/status/1974142611071144024?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å®‰å…¨ã§ãªã„ï¼ˆæ¬ é™¥ã®ã‚ã‚‹ï¼‰Reasoning traceã‚’ä¿®å¾©ã™ã‚‹ã‚ˆã†ãªå­¦ç¿’ã‚’ã•ã›ã‚‹ã“ã¨ã§ã‚ˆã‚Šãƒ­ãƒã‚¹ãƒˆãªsafety algnmentãŒå®Ÿç¾ã§ãã¾ã™ã€ã¨ã„ã£ãŸè©±ãªæ¨¡æ§˜</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jianfengchi/status/1973944383696519403?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3105" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal  Training, Xiang An+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- LLaVA-OneVision-1.5ã¯ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã¨è²¡æ”¿ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã—ã¤ã¤æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã™ã‚‹æ–°ã—ã„å¤§è¦æ¨¡ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã§åŠ¹ç‡çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã—ã€85Mã®äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨26Mã®æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å«ã‚€å¤§è¦æ¨¡ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã¾ã—ãŸã€‚åŠ¹ç‡çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã‚Šã€é™ã‚‰ã‚ŒãŸäºˆç®—å†…ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¯èƒ½ã¨ãªã‚Šã€å¹…åºƒã„ä¸‹æµã‚¿ã‚¹ã‚¯ã§ç«¶äº‰åŠ›ã®ã‚ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ç‰¹ã«ã€LLaVA-OneVision-1.5-8Bã¯18ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§Qwen2.5-VL-7Bã‚’ä¸Šå›ã‚Šã€4Bãƒ¢ãƒ‡ãƒ«ã¯å…¨ã¦ã®27ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§Qwen2.5-VL-3Bã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚ä»Šå¾Œã€LLaVA-OneVision-1.5-RLã®ãƒªãƒªãƒ¼ã‚¹ã‚‚äºˆå®šã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xiyaowang10/status/1973887115781140598?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å„ç¨®ãƒ™ãƒ³ãƒã§Qwen2.5-VLè¶…ãˆ</p>
<p>pj page:


<a href="https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5" target="_blank" rel="noopener noreferrer">https://github.com/EvolvingLMMs-Lab/LLaVA-OneVision-1.5</a>


</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1974632456348385583?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/ReplayBuffer.html" target="_blank" rel="noopener noreferrer">#ReplayBuffer</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3103" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DeepSearch: Overcome the Bottleneck of Reinforcement Learning with  Verifiable Rewards via Monte Carlo Tree Search, Fang Wu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- DeepSearchã¯ã€RLVRãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«Monte Carlo Tree Searchã‚’çµ±åˆã—ã€ä½“ç³»çš„ãªæ¢ç´¢ã‚’å¯èƒ½ã«ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é™ã‚‰ã‚ŒãŸãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã«ä¾å­˜ã›ãšã€é‡è¦ãªæ¨è«–çµŒè·¯ã‚’è¦‹é€ƒã•ãªã„ã€‚å®Ÿé¨“ã§ã¯ã€62.95%ã®å¹³å‡ç²¾åº¦ã‚’é”æˆã—ã€1.5Bæ¨è«–ãƒ¢ãƒ‡ãƒ«ã§æ–°ãŸãªæœ€å…ˆç«¯ã‚’ç¢ºç«‹ã€‚æˆ¦ç•¥çš„ãªæ¢ç´¢ã®é‡è¦æ€§ã‚’ç¤ºã—ã€RLVRæ‰‹æ³•ã®é€²å±•ã«å‘ã‘ãŸæ–°ãŸãªæ–¹å‘æ€§ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1973827122415513675?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æœ€è¿‘ã¯RLæ™‚ã®æ¢ç´¢ç©ºé–“ã‚’å¢—ã‚„ã™å–ã‚Šçµ„ã¿ãŒå¢—ãˆã¦ãã¦ã„ã‚‹ã‚ˆã†ã«æ„Ÿã˜ã‚‹ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3104" target="_blank" rel="noopener noreferrer">Replay BufferãŒPolicy Gradientã§ä½¿ãˆãªã„ç†ç”±, piqcy, 2019.03</a>
<br><br>ã«ã‚‚ã‚ã‚‹ã‚ˆã†ã«åŸºæœ¬çš„ã«ã‚ªãƒ³ãƒãƒªã‚·ãƒ¼RLã§ã¯ãƒªãƒ—ãƒ¬ã‚¤ãƒãƒƒãƒ•ã‚¡ã‚’ä½¿ãˆãªã„ã®ã§ä½•ã‚‰ã‹ã®å·¥å¤«ãŒå¿…è¦ã€ã¨ã„ã£ãŸè©±ãŒã‚ã‚‹ãŒã€ã“ã®ç ”ç©¶ã§ã¯GRPOã‚’å‰æã¨ã—ã¤ã¤ãƒªãƒ—ãƒ¬ã‚¤ãƒãƒƒãƒ•ã‚¡ã‚’æ´»ç”¨ã™ã‚‹æ çµ„ã¿ã¨ãªã£ã¦ã„ã‚‹ã‚ˆã†ãªã®ã§ã€ã©ã®ã‚ˆã†ãªå·¥å¤«ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã®ã ã‚ã†ã‹ã€‚å‹‰å¼·ã—ãŸã„ã€‚</p>
<p>æ‰€è¦‹ã¨è§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/max_paperclips/status/1974011545425228238?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3101" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Data Mixing Can Induce Phase Transitions in Knowledge Acquisition, Xinran Gu+, arXiv'25, 2025.05</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®è¨“ç·´ã«ãŠã„ã¦ã€çŸ¥è­˜ãŒè±Šå¯Œãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã‚¦ã‚§ãƒ–ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®æ··åˆãŒã€çŸ¥è­˜ç²å¾—ã«ãŠã„ã¦ä½ç›¸è»¢ç§»ã‚’ç¤ºã™ã“ã¨ã‚’å®Ÿè¨¼ã€‚ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’è‡¨ç•Œå€¤ã¾ã§å¢—åŠ ã•ã›ã‚‹ã¨ã€è¨˜æ†¶çŠ¶æ…‹ãŒæ€¥æ¿€ã«å¤‰åŒ–ã—ã€æ··åˆæ¯”ç‡ãŒè‡¨ç•Œå€¤ã‚’è¶…ãˆã‚‹ã¨æ€¥é€Ÿã«è¨˜æ†¶ãŒå¢—åŠ ã€‚ã“ã‚Œã‚‰ã®ç¾è±¡ã¯å®¹é‡é…åˆ†ã«èµ·å› ã—ã€æœ€é©ãªãƒ‡ãƒ¼ã‚¿é…åˆ†ãŒãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚„æ··åˆæ¯”ç‡ã«ã‚ˆã£ã¦ä¸é€£ç¶šã«å¤‰ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/RecurrentModels.html" target="_blank" rel="noopener noreferrer">#RecurrentModels</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3099" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] xLSTM Scaling Laws: Competitive Performance with Linear Time-Complexity, Maximilian Beck+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã¯LLMsã®æ€§èƒ½äºˆæ¸¬ã«é‡è¦ã§ã‚ã‚Šã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¨xLSTMã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æŒ™å‹•ã‚’æ¯”è¼ƒã€‚xLSTMã¯æ–‡è„ˆã®é•·ã•ã«å¯¾ã—ã¦ç·šå½¢ã®è¤‡é›‘ã•ã‚’æŒã¡ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŠã‚ˆã³æ¨è«–ã«ãŠã„ã¦ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚ˆã‚Šã‚‚æœ‰åˆ©ã«ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ç‰¹ã«ã€æ–‡è„ˆãŒå¢—ãˆã‚‹ã¨xLSTMã®åˆ©ç‚¹ãŒæ‹¡å¤§ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/maxmbeck/status/1974018534385598895?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3100" target="_blank" rel="noopener noreferrer">[Paper Note] xLSTM: Extended Long Short-Term Memory, Maximilian Beck+, NeurIPS'24 Spotlight, 2024.05</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3097" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Radiology's Last Exam ï¼ˆRadLEï¼‰: Benchmarking Frontier Multimodal AI  Against Human Experts and a Taxonomy of Visual Reasoning Errors in Radiology, Suvrankar Datta+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- åŒ»ç™‚ç”»åƒã®è§£é‡ˆã«ãŠã‘ã‚‹AIãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã€50ã®å°‚é–€çš„ãªã€Œã‚¹ãƒãƒƒãƒˆè¨ºæ–­ã€ã‚±ãƒ¼ã‚¹ã‚’ç”¨ã„ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’é–‹ç™ºã€‚5ã¤ã®æœ€å‰ç·šAIãƒ¢ãƒ‡ãƒ«ï¼ˆGPT-5ã€o3ã€Gemini 2.5 Proã€Grok-4ã€Claude Opus 4.1ï¼‰ã‚’ãƒ†ã‚¹ãƒˆã—ãŸçµæœã€ãƒœãƒ¼ãƒ‰èªå®šæ”¾å°„ç·šåŒ»ãŒæœ€é«˜ã®è¨ºæ–­ç²¾åº¦ï¼ˆ83%ï¼‰ã‚’é”æˆã—ã€AIãƒ¢ãƒ‡ãƒ«ã¯æœ€è‰¯ã®GPT-5ã§ã‚‚30%ã«ç•™ã¾ã£ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€AIãƒ¢ãƒ‡ãƒ«ãŒé›£ã—ã„è¨ºæ–­ã‚±ãƒ¼ã‚¹ã«ãŠã„ã¦æ”¾å°„ç·šåŒ»ã«ã¯åŠã°ãªã„ã“ã¨ãŒç¤ºã•ã‚Œã€åŒ»ç™‚ç”»åƒã«ãŠã‘ã‚‹AIã®é™ç•Œã¨ç„¡ç›£è¦–ä½¿ç”¨ã¸ã®è­¦å‘ŠãŒå¼·èª¿ã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/drdatta_aiims/status/1973373655251038701?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kimmonismus/status/1974594801598418963?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3091" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Thoughtbubbles: an Unsupervised Method for Parallel Thinking in Latent  Space, Houjun Liu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®æ–°ã—ã„å¤‰ç¨®ã€ŒThoughtbubblesã€ã‚’ææ¡ˆã—ã€ä¸¦åˆ—é©å¿œè¨ˆç®—ã‚’æ½œåœ¨ç©ºé–“ã§å®Ÿè¡Œã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€‚æ®‹å·®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ãƒ•ã‚©ãƒ¼ã‚¯ã¾ãŸã¯å‰Šé™¤ã™ã‚‹ã“ã¨ã§ã€è¨ˆç®—ã‚’åŠ¹ç‡åŒ–ã—ã€äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«å­¦ç¿’å¯èƒ½ã€‚Thoughtbubblesã¯ã€å¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€æ¨è«–æ™‚ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ãƒ†ã‚¹ãƒˆã®æŒ™å‹•ã‚’çµ±ä¸€ã™ã‚‹å¯èƒ½æ€§ã‚’æŒã¤ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/houjun_liu/status/1973778517427937323?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é‡è¦è«–æ–‡ã«è¦‹ãˆã‚‹</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3088" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Demystifying Synthetic Data in LLM Pre-training: A Systematic Study of  Scaling Laws, Benefits, and Pitfalls, Feiyang Kang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- åˆæˆãƒ‡ãƒ¼ã‚¿æŠ€è¡“ã¯LLMã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ä¾›çµ¦åˆ¶é™ã‚’å…‹æœã™ã‚‹å¯èƒ½æ€§ã‚’æŒã¤ã€‚æœ¬ç ”ç©¶ã§ã¯ã€è‡ªç„¶ãªã‚¦ã‚§ãƒ–ãƒ‡ãƒ¼ã‚¿ã¨åˆæˆãƒ‡ãƒ¼ã‚¿ã®æ··åˆã‚’æ¯”è¼ƒã—ã€è¨€ã„æ›ãˆãŸåˆæˆãƒ‡ãƒ¼ã‚¿ã®ã¿ã§ã®äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯è‡ªç„¶ãªãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚é€Ÿããªã„ã“ã¨ã‚’ç¤ºã—ãŸã€‚1/3ã®è¨€ã„æ›ãˆãŸåˆæˆãƒ‡ãƒ¼ã‚¿ã¨2/3ã®è‡ªç„¶ãƒ‡ãƒ¼ã‚¿ã®æ··åˆãŒã€ã‚ˆã‚ŠåŠ¹ç‡çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚æ•™ç§‘æ›¸ã‚¹ã‚¿ã‚¤ãƒ«ã®åˆæˆãƒ‡ãƒ¼ã‚¿ã¯å°ã•ãªãƒ‡ãƒ¼ã‚¿äºˆç®—ã§é«˜ã„æå¤±ã‚’ã‚‚ãŸã‚‰ã—ã€åˆæˆãƒ‡ãƒ¼ã‚¿ã®æœ€é©ãªæ¯”ç‡ã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨ãƒ‡ãƒ¼ã‚¿äºˆç®—ã«ä¾å­˜ã™ã‚‹ã€‚çµæœã¯åˆæˆãƒ‡ãƒ¼ã‚¿ã®åŠ¹æœã‚’æ˜ã‚‰ã‹ã«ã—ã€å®Ÿç”¨çš„ãªã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/papers_anon/status/1973939270747668698?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1974108247003934902?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>åˆæˆãƒ‡ãƒ¼ã‚¿ã¯é©åˆ‡ãªè¦æ¨¡ã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”ç‡ã§ãªã„ã¨åˆ©ç‚¹ãŒç¾ã‚Œãªã„</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3101" target="_blank" rel="noopener noreferrer">[Paper Note] Data Mixing Can Induce Phase Transitions in Knowledge Acquisition, Xinran Gu+, arXiv'25, 2025.05</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3085" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ModernVBERT: Towards Smaller Visual Document Retrievers, Paul Teiletche+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã¯æ–‡æ›¸æ¤œç´¢ã«ãŠã„ã¦åŠ¹ç‡çš„ãªä»£æ›¿æ‰‹æ®µã¨ã—ã¦æ™®åŠã—ã¦ã„ã‚‹ãŒã€å†åˆ©ç”¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒæ¤œç´¢æ€§èƒ½ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ãªã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€è¦–è¦šæ–‡æ›¸æ¤œç´¢ãƒ¢ãƒ‡ãƒ«ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®åŸå‰‡çš„ãªãƒ¬ã‚·ãƒ”ã‚’ç¢ºç«‹ã—ã€æ³¨æ„ãƒã‚¹ã‚­ãƒ³ã‚°ã‚„ç”»åƒè§£åƒåº¦ãªã©ãŒæ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹è¦å› ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã“ã‚Œã«åŸºã¥ãã€250Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªè¦–è¦š-è¨€èªã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ModernVBERTã‚’é–‹ç™ºã—ã€æ–‡æ›¸æ¤œç´¢ã‚¿ã‚¹ã‚¯ã§å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã¨ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jobergum/status/1973830118637551626?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MIT Licence<br>HF: 


<a href="https://huggingface.co/ModernVBERT" target="_blank" rel="noopener noreferrer">https://huggingface.co/ModernVBERT</a>


</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1974047955301626065?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3084" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MENLO: From Preferences to Proficiency -- Evaluating and Modeling  Native-like Quality Across 47 Languages, Chenxi Whitehouse+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- MENLOãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ã¦ã€47è¨€èªã®6,423ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ-å¿œç­”ãƒšã‚¢ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€LLMã®å¿œç­”å“è³ªã‚’è©•ä¾¡ã€‚ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆè©•ä¾¡è€…ã¯ãƒšã‚¢ãƒ¯ã‚¤ã‚ºè©•ä¾¡ã‹ã‚‰åˆ©ç›Šã‚’å¾—ã‚‹ãŒã€äººé–“ã«ã¯åŠã°ãšã€‚å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§æ”¹å–„ã‚’ç¤ºã—ã€RLè¨“ç·´è©•ä¾¡è€…ãŒLLMã®å¤šè¨€èªèƒ½åŠ›å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚ãŸã ã—ã€äººé–“ã®åˆ¤æ–­ã¨ã®ä¸ä¸€è‡´ã¯æ®‹ã‚‹ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’å…¬é–‹ã—ã€å¤šè¨€èªLLMè©•ä¾¡ã®ç ”ç©¶ã‚’æ”¯æ´ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/seb_ruder/status/1973412580191285640?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLMã®å¿œç­”ã‚’å¤šè¨€èªã§ã‚ˆã‚Šnativeã«è¿‘ã„ã‚‚ã®ã«ã™ã‚‹ãŸã‚ã®å–ã‚Šçµ„ã¿ã€ãŠã‚ˆã³è©•ä¾¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼ˆMENLO, ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå«ã‚€ï¼‰ãªæ¨¡æ§˜ã€‚nativeã‚‰ã—ã•ã‚’æ¸¬ã‚‹ãŸã‚ã«é‡è¦ãªæ¬¡å…ƒã¨ã—ã¦Fluency, Tone, Localized Tone, Localized Factualityã¨å‘¼ã°ã‚Œã‚‹è»¸ã‚’å®šç¾©ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ãã®ä¸Šã§47è¨€èªã«ãŠã‘ã‚‹6423ã®äººæ‰‹ã§ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸpreference dataã‚’ä½œæˆã—è©•ä¾¡ã‚’ã—ãŸã¨ã“ã‚ã€æ—¢å­˜ã®LLM-as-a-judgeã‚„SFT/RLã•ã‚ŒãŸReward Modelã§ã¯ã€äººé–“ã«ã‚ˆã‚‹è©•ä¾¡ã«ã¯ã¾ã ã¾ã åŠã°ãªã„ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€MENLOã‚’ç”¨ã„ã¦RL/SFTã™ã‚‹ã“ã¨ã§LLM Judgeã‚„Reward Modelã®æ€§èƒ½ã‚’æ”¹å–„ã§ãã‚‹ã€ã¨ã„ã£ãŸè©±ãªæ¨¡æ§˜ã€‚<br><br>4ã¤ã®æ¬¡å…ƒã«ã¤ã„ã¦ã¯ä»¥ä¸‹ã®è¡¨ã‚’å‚ç…§ã®ã“ã¨ã€‚<br>ãã‚Œãã‚Œ<br>- Fluency: å°‚é–€å®¶ãƒ¬ãƒ™ãƒ«ã®native speakerã¨æ¯”è¼ƒã—ãŸæ™‚ã®proficiency<br>- Tone: å…¨ä½“çš„ãªwriting stvleã‚„èªã‚Šå£<br>- Localized Tone: æ–‡åŒ–çš„ã€åœ°åŸŸçš„ãªè¨€è‘‰ã®ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹<br>- Localized Factuality: åœ°åŸŸå›ºæœ‰ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æ²¿ã£ãŸäº‹å®Ÿæ€§ã‚„ç¶²ç¾…æ€§<br><br><img src="https://github.com/user-attachments/assets/2e57edb7-a2f0-4570-a723-53c22ac22036" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3082" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Personalized Reasoning: Just-In-Time Personalization and Why LLMs Fail  At It, Shuyue Stella Li+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- ç¾åœ¨ã®LLMã¯ã€ã‚¿ã‚¹ã‚¯è§£æ±ºã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã®æ•´åˆæ€§ã‚’åˆ¥ã€…ã«æ‰±ã£ã¦ãŠã‚Šã€ç‰¹ã«ã‚¸ãƒ£ã‚¹ãƒˆã‚¤ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚·ãƒŠãƒªã‚ªã§ã¯åŠ¹æœçš„ã§ã¯ãªã„ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã‚’å¼•ãå‡ºã—ã€å¿œç­”ã‚’é©å¿œã•ã›ã‚‹ã€Œãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºãƒ‰æ¨è«–ã€ãŒå¿…è¦ã§ã‚ã‚‹ã€‚æ–°ãŸã«ææ¡ˆã•ã‚ŒãŸè©•ä¾¡æ‰‹æ³•ã€ŒPREFDISCOã€ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¿œã˜ãŸç•°ãªã‚‹æ¨è«–ãƒã‚§ãƒ¼ãƒ³ã‚’ç”Ÿæˆã—ã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã®é‡è¦æ€§ã‚’ç¤ºã™ã€‚è©•ä¾¡çµæœã‹ã‚‰ã€å˜ç´”ãªãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºãŒä¸€èˆ¬çš„ãªå¿œç­”ã‚ˆã‚Šã‚‚åŠ£ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€å°‚ç”¨ã®é–‹ç™ºãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚ŒãŸã€‚PREFDISCOã¯ã€æ•™è‚²ã‚„åŒ»ç™‚ãªã©ã®åˆ†é‡ã§ã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã®é‡è¦æ€§ã‚’å¼·èª¿ã™ã‚‹åŸºç›¤ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stellalisy/status/1973764628632281271?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã–ãƒ¼ã£ã¨ã—ã‹èª­ã‚ã¦ã„ãªã„ã®ãŒã€ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ä¸ãˆã‚‰ã‚ŒãŸã‚¿ã‚¹ã‚¯ã¨ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®ä¼šè©±ã®å±¥æ­´ã«åŸºã¥ã„ã¦ã€LLMå´ãŒè³ªå•ã‚’æŠ•ã’ã‹ã‘ã¦ã€Personalizationã«å¿…è¦ãªattributeã‚’å–å¾—ã™ã‚‹ã€‚ã¤ã¾ã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¯ (attribute, value, weight)ã®ã‚¿ãƒ—ãƒ«ã«ã‚ˆã£ã¦æ§‹æˆã•ã‚Œã€ã“ã®æƒ…å ±ã«åŸºã¥ã„ã¦ç”ŸæˆãŒãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã«alignã™ã‚‹ã‚ˆã†ã«ç”Ÿæˆã™ã‚‹ã€ã¨ã„ã£ãŸè©±ã«è¦‹ãˆã‚‹ã€‚è†¨å¤§ãªã¨ã‚Šã†ã‚‹attributeã®ä¸­ã‹ã‚‰ã€ãƒ¦ãƒ¼ã‚¶ã®ã‚¿ã‚¹ã‚¯ã¨contextã«åˆã‚ã›ã¦ã©ã®attributeã«é–¢ã™ã‚‹æƒ…å ±ã‚’å–å¾—ã™ã‚‹ã‹ãŒéµã¨ãªã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚ã¾ãŸã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­ã§ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã€ä¿æŒã¯ã—ãªã„å‰æãªè©±ã«è¦‹ãˆã‚‹ã®ã§ã€Personalizationã®ã‚«ãƒ†ã‚´ãƒªã¨ã—ã¦ã¯ä¸€æ™‚çš„å€‹äººåŒ–ã«ç›¸å½“ã™ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚<br>Personalizationã®ç ”ç©¶ã¯è©•ä¾¡ãŒéå¸¸ã«é›£ã—ã„ã®ã§ã€ã©ã®ã‚ˆã†ãªè©•ä¾¡ã‚’ã—ã¦ã„ã‚‹ã‹ã¯æ³¨æ„ã—ã¦èª­ã‚“ã æ–¹ãŒè‰¯ã„ã¨æ€ã‚ã‚Œã‚‹ã€‚<br>&lt;img width="1003" height="567" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/3d411a63-f8de-4267-b6c0-edfe3143d4ac"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/3d411a63-f8de-4267-b6c0-edfe3143d4ac"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<a class="button" href="articles/Editing.html" target="_blank" rel="noopener noreferrer">#Editing</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3073" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] EditReward: A Human-Aligned Reward Model for Instruction-Guided Image  Editing, Keming Wu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªç„¶è¨€èªæŒ‡ç¤ºã«ã‚ˆã‚‹ç”»åƒç·¨é›†ã®é€²å±•ã«ãŠã„ã¦ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¯é…ã‚Œã‚’ã¨ã£ã¦ã„ã‚‹ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€20ä¸‡ä»¥ä¸Šã®é¸å¥½ãƒšã‚¢ã‚’å«ã‚€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\mnameã‚’æ§‹ç¯‰ã—ã€æŒ‡ç¤ºã«åŸºã¥ãç”»åƒç·¨é›†ã‚¿ã‚¹ã‚¯ã§äººé–“ã®é¸å¥½ã¨é«˜ã„æ•´åˆæ€§ã‚’ç¤ºã—ãŸã€‚å®Ÿé¨“ã§ã¯ã€\mnameãŒæ—¢å­˜ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®äººé–“ç›¸é–¢ã‚’é”æˆã—ã€ãƒã‚¤ã‚ºã®å¤šã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰é«˜å“è³ªãªã‚µãƒ–ã‚»ãƒƒãƒˆã‚’é¸æŠã™ã‚‹ã“ã¨ã§ã€ç”»åƒç·¨é›†ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ããŸã€‚ä»Šå¾Œã€\mnameã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å…¬é–‹ã•ã‚Œã€é«˜å“è³ªãªç”»åƒç·¨é›†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹ç¯‰ã‚’æ”¯æ´ã™ã‚‹äºˆå®šã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://tiger-ai-lab.github.io/EditReward/" target="_blank" rel="noopener noreferrer">https://tiger-ai-lab.github.io/EditReward/</a>


<br>HF:


<a href="https://huggingface.co/collections/TIGER-Lab/editreward-68ddf026ef9eb1510458abc6" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/TIGER-Lab/editreward-68ddf026ef9eb1510458abc6</a>


</p>
<p>ã“ã‚Œã¾ã§ã®ImageEditingç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€å¼±ã„Reward Modelã«ã‚ˆã£ã¦åˆæˆã•ã‚Œã‚‹ã‹ã€GPT-4oã‚„ä»–ã®VLMã«ã‚ˆã‚‹å“è³ªã®ä½ã„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚Šç”Ÿæˆã•ã‚Œã¦ãŠã‚Šã€é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå­˜åœ¨ã—ãªã„èª²é¡ŒãŒã‚ã£ãŸã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«å¤§è¦æ¨¡ãªImageEditingã®å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã€ImageEditingã«ç‰¹åŒ–ã—ãŸå ±é…¬ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹EditRewardã‚’å­¦ç¿’ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯äººé–“ã®å°‚é–€å®¶ã¨ã®agreementã«ãŠã„ã¦é«˜ã„(ã¨ã„ã†ã‚ˆã‚Šã‚Šbestã¨æ›¸ã„ã¦ã‚ã‚‹ï¼‰agreementã‚’ç¤ºã—ã€å®Ÿéš›ã«EditRewardã«ã‚ˆã£ã¦æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’filteringã—ã¦å­¦ç¿’ã—ãŸã‚‰å¤§ããªgainãŒã‚ã£ãŸã‚ˆã€ã¨ã„ã†æ„Ÿã˜ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Trustfulness.html" target="_blank" rel="noopener noreferrer">#Trustfulness</a>
<span class="issue_date">Issue Date: 2025-10-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3071" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TruthRL: Incentivizing Truthful LLMs via Reinforcement Learning, Zhepei Wei+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMsã®çœŸå®Ÿæ€§ã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®å¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯TruthRLã‚’ææ¡ˆã€‚ä¸‰å€¤å ±é…¬ã‚’ç”¨ã„ã¦æ­£ã—ã„å›ç­”ã€å¹»è¦šã€abstentionã‚’åŒºåˆ¥ã—ã€ä¸ç¢ºå®Ÿãªå ´åˆã«ã¯æ§ãˆã‚‹ã“ã¨ã‚’ä¿ƒé€²ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€TruthRLã¯å¹»è¦šã‚’28.9%æ¸›å°‘ã•ã›ã€çœŸå®Ÿæ€§ã‚’21.1%å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã€å¾“æ¥ã®æ‰‹æ³•ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚æ­£ç¢ºã•ã¨çœŸå®Ÿæ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹é‡è¦æ€§ãŒå¼·èª¿ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/weizhepei/status/1973211813522317519?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä¸€èˆ¬çš„ã«åˆ©ç”¨ã•ã‚Œã‚‹Binary Rewardï¼ˆå›ç­”ãŒæ­£ã—ã‘ã‚Œã°1, ãã†ã§ãªã‘ã‚Œã°-1)ã§ã¯ãªãã€Ternary Reward<br>- å›ç­”ãŒæ­£ã—ã‘ã‚Œã°1<br>- ä¸ç¢ºå®Ÿã§ã‚ã‚Œã°0<br>- èª¤ã‚Šã§ã‚ã‚Œã°-1<br><br>ã‚’åˆ©ç”¨ã—GRPOã™ã‚‹ã“ã¨ã§ã€hallucinationãŒå‘ä¸Šã—ã€trustfulnessã‚‚æ”¹å–„ã™ã‚‹ã€ã¨ã„ã†è©±ãªæ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<span class="issue_date">Issue Date: 2025-10-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3065" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] HalluGuard: Evidence-Grounded Small Reasoning Models to Mitigate  Hallucinations in Retrieval-Augmented Generation, Loris Bergeron+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- HalluGuardã¯ã€LLMsã®å¹»è¦šã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®4Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å°å‹æ¨è«–ãƒ¢ãƒ‡ãƒ«ã§ã€æ–‡æ›¸-ä¸»å¼µãƒšã‚¢ã‚’åˆ†é¡ã—ã€è¨¼æ‹ ã«åŸºã¥ã„ãŸæ­£å½“åŒ–ã‚’ç”Ÿæˆã—ã¾ã™ã€‚FineWebã‹ã‚‰æ´¾ç”Ÿã—ãŸåˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã€å¥½ã¿ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ç”¨ã„ã¦ã€RAGTruthã‚µãƒ–ã‚»ãƒƒãƒˆã§84.0%ã®ãƒãƒ©ãƒ³ã‚¹ç²¾åº¦ã‚’é”æˆã—ã€MiniCheckã‚„Granite Guardianã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ã¾ã™ã€‚å…¨ä½“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯75.7%ã®ãƒãƒ©ãƒ³ã‚¹ç²¾åº¦ã‚’é”æˆã—ã€GPT-4oã¨åŒç­‰ã®æ€§èƒ½ã‚’æŒã¡ã¾ã™ã€‚HalluGuardã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯å…¬é–‹äºˆå®šã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1973611983992963435?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Document xã¨claim cãŒgivenãªã¨ãã«ã€ãã‚ŒãŒgroundingã•ã‚Œã¦ã„ã‚‹ã‹å¦ã‹ã‚’åˆ¤å®šã—ã€justificationã‚’ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’xã‚’å‚ç…§ã—ãªãŒã‚‰ç”Ÿæˆã™ã‚‹ã‚ˆã†ãªSLMãªæ¨¡æ§˜ã€‚ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã¯ã¾ã æœªå…¬é–‹ã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3064" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents, Zonghan Yang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢å·¥å­¦ï¼ˆSWEï¼‰ã¸ã®å¿œç”¨ãŒé€²ã‚“ã§ãŠã‚Šã€SWE-benchãŒé‡è¦ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ãªã£ã¦ã„ã‚‹ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®SWE-Agentãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨å˜ä¸€ã‚¿ãƒ¼ãƒ³ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¹æ‰‹æ³•ã¯ç›¸äº’æ’ä»–çš„ã§ã¯ãªãã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒåŠ¹ç‡çš„ãªSWE-Agentã®é©å¿œã‚’å¯èƒ½ã«ã™ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€Kimi-Devã¨ã„ã†ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®SWE LLMã‚’ç´¹ä»‹ã—ã€SWE-bench Verifiedã§60.4%ã‚’é”æˆã€‚è¿½åŠ ã®é©å¿œã«ã‚ˆã‚Šã€Kimi-Devã¯SWE-Agentã®æ€§èƒ½ã‚’48.6%ã«å¼•ãä¸Šã’ã€ç§»æ¤å¯èƒ½ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿç¾ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1973544152043495779?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Agentlessã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1847" target="_blank" rel="noopener noreferrer">Demystifying LLM-based Software Engineering Agents, Chunqiu Steven Xia+, FSE'25</a>
</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-10-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3060" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Towards a Comprehensive Scaling Law of Mixture-of-Experts, Guoliang Zhao+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- Mixture-of-Experts (MoE)ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ä½“ç³»çš„ã«åˆ†æã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹5ã¤ã®è¦å› ã‚’ç‰¹å®šã€‚446ã®åˆ¶å¾¡å®Ÿé¨“ã‚’é€šã˜ã¦ã€åŒ…æ‹¬çš„ãªMoEã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’æ§‹ç¯‰ã—ã€æœ€é©ãªå°‚é–€å®¶ã®æ•°ã‚„å…±æœ‰æ¯”ç‡ãŒãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«ä¾å­˜ã—ãªã„ã“ã¨ã‚’ç¤ºã™ã€‚ææ¡ˆã™ã‚‹æ³•å‰‡ã¯ã€MoEãƒ¢ãƒ‡ãƒ«ã®è¨­è¨ˆã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹æŒ‡é‡ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1973247608647983513?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2296" target="_blank" rel="noopener noreferrer">[Paper Note] Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts
  Language Models, Changxin Tian+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<span class="issue_date">Issue Date: 2025-10-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3057" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation, Jiazheng Li+, arXiv'25, 2025.07</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã‚’ç”¨ã„ã¦ã€é›£ã—ã„æ¨è«–å•é¡Œã‚’åŠ¹æœçš„ã«è§£æ±ºã™ã‚‹ãŸã‚ã®æ‰‹æ³•QuestAã‚’ææ¡ˆã€‚è³ªå•ã®æ‹¡å¼µã‚’é€šã˜ã¦éƒ¨åˆ†çš„ãªè§£æ±ºç­–ã‚’å°å…¥ã—ã€å­¦ç¿’ä¿¡å·ã‚’æ”¹å–„ã€‚æ•°å­¦çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã§ã®RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦ã€pass@1ã¨pass@kã®ä¸¡æ–¹ã‚’å‘ä¸Šã•ã›ã€DeepScaleRã‚„OpenMath Nemotronã®æ¨è«–èƒ½åŠ›ã‚’å¼·åŒ–ã€‚1.5Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã§æ–°ãŸãªæœ€å…ˆç«¯çµæœã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hongzhou__lin/status/1973062785711190384?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RLã«ãŠã„ã¦ã€ç°¡å˜ãªå•é¡Œã¯ã™ãã«overfitã—ã€ã‹ã¤ã‚ˆã‚Šå›°é›£ãªå•é¡Œã‚’å­¦ç¿’ã™ã‚‹å¦¨ã’ã«ãªã‚‹ä¸€æ–¹ã§ã€å›°é›£ãªå•é¡Œã¯ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ãŒæ‚ªãã€ã‹ã¤rewardãŒsparseãªå ´åˆå­¦ç¿’ãŒéå¸¸ã«é…ã„ã¨ã„ã†å•é¡ŒãŒã‚ã£ãŸãŒã€å›°é›£ãªå•é¡Œã«å¯¾ã—ã¦ãƒ’ãƒ³ãƒˆã‚’ä¸ãˆã¦å­¦ç¿’ã•ã›ã‚‹ï¼ˆã‹ã¤ã€ãƒ¢ãƒ‡ãƒ«ãŒãƒ’ãƒ³ãƒˆã«ä¾å­˜ã›ãšã¨ã‚‚è§£ã‘ã‚‹ã‚ˆã†ã«ãªã£ã¦ããŸã‚‰å¾ã€…ã«ãƒ’ãƒ³ãƒˆã‚’æ¸›ã‚‰ã—ãƒ’ãƒ³ãƒˆã«éå‰°ã«ä¾å­˜ã™ã‚‹ã“ã¨ã‚’é˜²ãï¼‰ã“ã¨ã§ã€ç°¡å˜ãªå•é¡Œã«å¯¾ã—ã¦overfitã›ãšã«å›°é›£ãªå•é¡Œã«å¯¾ã™ã‚‹å­¦ç¿’åŠ¹ç‡ã‚‚ä¸ŠãŒã‚Šã€reasoningèƒ½åŠ›ã‚‚ãƒ–ãƒ¼ã‚¹ãƒˆã—ã¾ã—ãŸã€‚å›°é›£ãªå•é¡Œã¯ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ãŒè§£ãã®ã«è‹¦åŠ´ã™ã‚‹ã‚‚ã®ï¼ˆpass rateãŒã‚¼ãƒ­ã®ã‚‚ã®)ã‹ã‚‰è¦‹ã¤ã‘ã¾ã™ã€ï¼ˆãã—ã¦promptã§hintã‚’ä¸ãˆãŸä¸Šã§ã•ã‚‰ã«pass rateãŒä½ã„ã‚‚ã®ã‚’ä½¿ã†æ¨¡æ§˜ï¼Ÿï¼‰ã¨ã„ã£ãŸè©±ãªæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/671a95e0-bfd8-478e-b73c-25af4d21b6df" alt="image" loading="lazy"></p>
<p>ãƒ’ãƒ³ãƒˆã‚’ä½¿ã£ã¦ãªã‚‹å•é¡Œã®é›£æ˜“åº¦ã‚’èª¿æ•´ã—ãªãŒã‚‰RLã™ã‚‹ç ”ç©¶ã¯ä»¥ä¸‹ã‚‚å­˜åœ¨ã™ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2757" target="_blank" rel="noopener noreferrer">[Paper Note] Staying in the Sweet Spot: Responsive Reasoning Evolution via
  Capability-Adaptive Hint Scaffolding, Ziheng Li+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<span class="issue_date">Issue Date: 2025-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3047" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Pretraining Large Language Models with NVFP4, NVIDIA+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€NVFP4ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ç”¨ã„ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å®‰å®šã‹ã¤æ­£ç¢ºãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã€‚ãƒ©ãƒ³ãƒ€ãƒ ãƒãƒ€ãƒãƒ¼ãƒ‰å¤‰æ›ã‚„äºŒæ¬¡å…ƒé‡å­åŒ–ã‚¹ã‚­ãƒ¼ãƒ ã‚’å–ã‚Šå…¥ã‚Œã€åã‚Šã®ãªã„å‹¾é…æ¨å®šã‚’å®Ÿç¾ã€‚10å…†ãƒˆãƒ¼ã‚¯ãƒ³ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šã€FP8ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã—ã€ç‹­ã„ç²¾åº¦ã®LLMãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹é€²å±•ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1972869149102858441?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1975344045754097685?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ContextWindow.html" target="_blank" rel="noopener noreferrer">#ContextWindow</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3043" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Short window attention enables long-term memorization, LoÃ¯c Cabannes+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- SWAXã¨ã„ã†ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã¨xLSTMç·šå½¢RNNå±¤ã‚’çµ„ã¿åˆã‚ã›ã¦ãŠã‚Šã€çŸ­ã„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒé•·æœŸçš„ãªè¨˜æ†¶ã‚’ã‚ˆã‚Šè‰¯ãè¨“ç·´ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚SWAXã¯ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã‚’ç¢ºç‡çš„ã«å¤‰æ›´ã—ã€çŸ­ã„ãƒ»é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä¸¡æ–¹ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1972874639333605540?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/Test-time%20Learning.html" target="_blank" rel="noopener noreferrer">#Test-time Learning</a>
<span class="issue_date">Issue Date: 2025-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3041" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ReasoningBank: Scaling Agent Self-Evolving with Reasoning Memory, Siru Ouyang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- ReasoningBankã¨ã„ã†æ–°ã—ã„ãƒ¡ãƒ¢ãƒªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæˆåŠŸä½“é¨“ã¨å¤±æ•—ä½“é¨“ã‹ã‚‰æ¨è«–æˆ¦ç•¥ã‚’æŠ½å‡ºã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ãƒ†ã‚¹ãƒˆæ™‚ã«ã¯é–¢é€£ãƒ¡ãƒ¢ãƒªã‚’æ´»ç”¨ã—ã€å­¦ã³ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ã•ã‚‰ã«ã€ãƒ¡ãƒ¢ãƒªã‚’æ„è­˜ã—ãŸãƒ†ã‚¹ãƒˆæ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆMaTTSï¼‰ã‚’å°å…¥ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½“é¨“ã‚’å¤šæ§˜åŒ–ãƒ»æ‹¡å¤§ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¦ã‚§ãƒ–ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ã‚„ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ—¢å­˜ã®ãƒ¡ãƒ¢ãƒªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä¸Šå›ã‚‹åŠ¹æœã¨åŠ¹ç‡ã‚’å®Ÿç¾ã€‚ãƒ¡ãƒ¢ãƒªé§†å‹•ã®çµŒé¨“ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’æ–°ãŸãªæ¬¡å…ƒã¨ã—ã¦ç¢ºç«‹ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è‡ªå·±é€²åŒ–ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1972870229463355677?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ¡ãƒ¢ãƒªã‚’è‰¯è³ªãªã‚‚ã®ã«æ›´æ–°ã€è“„ç©ã—ç¶šã‘ã‚‹ã“ã¨ã§æ€§èƒ½ãŒã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã®ã§ã‚ã‚Œã°ã€æ–°ãŸãªtest-time scalingã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã«ãªã‚Šãã†ã€‚<br><br>ã¨æ€ã£ãŸãŒã–ã£ãã‚Šèª­ã‚“ã§ã¿ã‚‹ã¨æœ¬ç ”ç©¶ã§ã¯ã“ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã®ã“ã¨ã‚’Test-Time Learningã¨å‘¼ç§°ã—ã¦ã„ã‚‹ï¼ˆå…ˆè¡Œç ”ç©¶ãŒï¼’ã¤å¼•ç”¨ã•ã‚Œã¦ã„ã‚‹ãŒã–ã£ã¨è¦‹ãŸé™ã‚Šã§ã¯ä¸¡è€…ã¯ãã†è¨€ã£ãŸå‘¼ç§°ã¯ã—ã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆãŸï¼‰ã€‚<br>ã™ãªã‚ã¡ã€ã‚¯ã‚¨ãƒªã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒåˆ°é”ã—ãŸæ™‚ã«å°†æ¥ã®ã‚¯ã‚¨ãƒªã‚’è¦‹ã‚‹ã“ã¨ã¯ã§ããšã«ã€éå»ã®ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹trajectoryã‚„ã€self-verificationãªã©ã«ã‚ˆã£ã¦ã®ã¿ãƒ©ãƒ™ãƒ«ç„¡ã—ã§è‡ªå·±é€²åŒ–ã—ã¦ã„ããƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã®ã“ã¨ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3052" target="_blank" rel="noopener noreferrer">[Paper Note] M+: Extending MemoryLLM with Scalable Long-Term Memory, Yu Wang+, ICML'25, 2025.02</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3031" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SIM-CoT: Supervised Implicit Chain-of-Thought, Xilin Wei+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æš—é»™ã®Chain-of-Thought (CoT) ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€LLMsã«ãŠã‘ã‚‹æ˜ç¤ºçš„ãªCoTæ¨è«–ã®åŠ¹ç‡çš„ãªä»£æ›¿æ‰‹æ®µã§ã™ãŒã€æ€§èƒ½ã®ä¸å®‰å®šæ€§ãŒèª²é¡Œã§ã™ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€SIM-CoTã‚’ææ¡ˆã—ã€ã‚¹ãƒ†ãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã®ç›£è¦–ã‚’å°å…¥ã—ã¦æ½œåœ¨çš„ãªæ¨è«–ç©ºé–“ã‚’å®‰å®šåŒ–ã—ã¾ã™ã€‚è£œåŠ©ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ç”¨ã„ã¦æš—é»™ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ˜ç¤ºçš„ãªæ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã«æ•´åˆã•ã›ã€è§£é‡ˆå¯èƒ½æ€§ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚SIM-CoTã¯ã€Coconutã‚„CODIã§ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€æ˜ç¤ºçš„CoTã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€ãƒˆãƒ¼ã‚¯ãƒ³åŠ¹ç‡ã‚‚æ”¹å–„ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1972442919354208723?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3006" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SWE-QA: Can Language Models Answer Repository-level Code Questions?, Weihan Peng+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- SWE-QAã¯ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãƒªãƒã‚¸ãƒˆãƒªå…¨ä½“ã‚’ç†è§£ã—æ¨è«–ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ã‚³ãƒ¼ãƒ‰è³ªå•å¿œç­”ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€576ã®é«˜å“è³ªãªè³ªå•-å›ç­”ãƒšã‚¢ã‚’å«ã‚€ã€‚ã“ã‚Œã¯ã€è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒŠãƒ“ã‚²ãƒ¼ãƒˆã—ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„é•·è·é›¢ã®ã‚³ãƒ¼ãƒ‰ä¾å­˜é–¢ä¿‚ã‚’ç†è§£ã™ã‚‹èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸã€‚LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç”¨ã„ãŸãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—SWE-QA-Agentã‚‚é–‹ç™ºã•ã‚Œã€å®Ÿé¨“ã«ã‚ˆã‚ŠLLMã®å¯èƒ½æ€§ã¨ä»Šå¾Œã®ç ”ç©¶èª²é¡ŒãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1971731165405987073?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆãƒ¬ãƒ™ãƒ«ã§ã¯ãªãã€ãƒªãƒã‚¸ãƒˆãƒªãƒ¬ãƒ™ãƒ«ã®ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ç†è§£ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹QAãƒ™ãƒ³ãƒˆãƒãƒ¼ã‚¯</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Legal.html" target="_blank" rel="noopener noreferrer">#Legal</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3005" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CLaw: Benchmarking Chinese Legal Knowledge in Large Language Models - A  Fine-grained Corpus and Reasoning Analysis, Xinzhe Xu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æ³•çš„æ–‡æ›¸ã®åˆ†æã«ãŠã„ã¦ã€LLMã®ä¿¡é ¼æ€§ãŒæãªã‚ã‚Œã‚‹å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯CLawã‚’ææ¡ˆã€‚CLawã¯ã€ä¸­å›½ã®æ³•ä»¤ã‚’ç¶²ç¾…ã—ãŸè©³ç´°ãªã‚³ãƒ¼ãƒ‘ã‚¹ã¨ã€ã‚±ãƒ¼ã‚¹ãƒ™ãƒ¼ã‚¹ã®æ¨è«–ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‹ã‚‰æ§‹æˆã•ã‚Œã€æ³•çš„çŸ¥è­˜ã®å®Ÿéš›ã®å¿œç”¨ã‚’è©•ä¾¡ã€‚å®Ÿè¨¼çš„è©•ä¾¡ã§ã¯ã€ç¾ä»£ã®LLMãŒæ³•çš„è¦å®šã®æ­£ç¢ºãªå–å¾—ã«è‹¦åŠ´ã—ã¦ã„ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ä¿¡é ¼ã§ãã‚‹æ³•çš„æ¨è«–ã«ã¯æ­£ç¢ºãªçŸ¥è­˜ã®å–å¾—ã¨å¼·åŠ›ãªæ¨è«–èƒ½åŠ›ã®çµ±åˆãŒå¿…è¦ã§ã‚ã‚‹ã¨ä¸»å¼µã€‚ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹LLMæ¨è«–ã®é€²å±•ã«å‘ã‘ãŸé‡è¦ãªæ´å¯Ÿã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1971734059060527283?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä¸­å›½èªã«ã‚ˆã‚‹ä¸­å›½ã®æ³•å¾‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€legalåˆ†é‡ã«ãŠã„ã¦ã¯ã€ã‚ˆã‚Šç´°ã‹ã„ç²’åº¦ã®çŸ¥è­˜ã‚’æ‰ãˆã‚‰ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ãŒæ¨è«–ã‚‚çš„ç¢ºã«ã§ãã€æ¨è«–èƒ½åŠ›ã§ãã‚Œã¯è£œãˆãã†ã¨ã„ã†æ„Ÿã˜ãªæ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3002" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Angles Don't Lie: Unlocking Training-Efficient RL Through the Model's   Own Signals, Qinsi Wang+, NeurIPS'25 Spotlight, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å¼·åŒ–å­¦ç¿’å¾®èª¿æ•´ï¼ˆRFTï¼‰ã«ãŠã‘ã‚‹ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ã®ä½ä¸‹ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®ä¿¡å·ã€Œè§’åº¦é›†ä¸­ã€ã‚’ç‰¹å®šã€‚ã“ã‚Œã«åŸºã¥ãã€å‹¾é…é§†å‹•å‹è§’åº¦æƒ…å ±ãƒŠãƒ“ã‚²ãƒ¼ãƒˆå¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼ˆGAIN-RLï¼‰ã‚’ææ¡ˆã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’å‹•çš„ã«é¸æŠã™ã‚‹ã“ã¨ã§åŠ¹ç‡ã‚’å‘ä¸Šã€‚å®Ÿè¨¼è©•ä¾¡ã§ã¯ã€GAIN-RLãŒãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ã‚’2.5å€ä»¥ä¸Šå‘ä¸Šã•ã›ã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ã®åŠåˆ†ã§ã‚ˆã‚Šè‰¯ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ãŸã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chenfeng_x/status/1971343654662046184?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚„ç‰¹å®šã®é›£æ˜“åº¦ã«åŸºã¥ããƒ©ãƒ™ãƒ«ã‹ã‚‰RLã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã®ã§ã¯ãªãã€ãƒ¢ãƒ‡ãƒ«è‡ªèº«ã®ç¾åœ¨ã®å­¦ç¿’ã®çŠ¶æ…‹ã«åŸºã¥ã„ã¦å‹•çš„ã«é¸æŠã—å­¦ç¿’åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãªæ¨¡æ§˜ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NeuralArchitectureSearch.html" target="_blank" rel="noopener noreferrer">#NeuralArchitectureSearch</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3000" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] STAR: Synthesis of Tailored Architectures, Armin W. Thomas+, ICLR'25, 2024.11</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆSTARï¼‰ã‚’ææ¡ˆã—ã€ç‰¹åŒ–ã—ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®åˆæˆã‚’è¡Œã†ã€‚ç·šå½¢å…¥åŠ›å¤‰å‹•ã‚·ã‚¹ãƒ†ãƒ ã«åŸºã¥ãæ¢ç´¢ç©ºé–“ã‚’ç”¨ã„ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ã‚²ãƒãƒ ã‚’éšå±¤çš„ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã€‚é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ãƒ¢ãƒ‡ãƒ«ã®å“è³ªã¨åŠ¹ç‡ã‚’æœ€é©åŒ–ã—ã€è‡ªå·±å›å¸°å‹è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«ãŠã„ã¦å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=HsHxSN23rM" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=HsHxSN23rM</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<span class="issue_date">Issue Date: 2025-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2997" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Expanding Reasoning Potential in Foundation Model by Learning Diverse  Chains of Thought Patterns, Xuemiao Zhang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡æ¨è«–ãƒ¢ãƒ‡ãƒ«ã®é€²å±•ã¯å¼·åŒ–å­¦ç¿’ã«ã‚ˆã£ã¦ä¿ƒé€²ã•ã‚Œã€CoTãƒ‡ãƒ¼ã‚¿ã®åˆ©ç”¨ãŒæ¨è«–ã®æ·±ã•ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€ã©ã®ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ãŒæœ€ã‚‚åŠ¹æœçš„ã‹ã¯æœªè§£æ±ºã®å•é¡Œã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ¨è«–ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’ç‹¬ç«‹ã—ãŸè©¦è¡Œã®æ•°ã®é€†æ•°ã¨ã—ã¦å®šç¾©ã—ã€ã“ã‚Œã‚’æ‹¡å¼µã™ã‚‹ãŸã‚ã«é«˜ä¾¡å€¤ã®æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”¨ã„ãŸå¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ã®åˆ©ç”¨ã‚’ææ¡ˆã€‚å…·ä½“çš„ã«ã¯ã€CoTã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‹ã‚‰åŸå­çš„ãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½è±¡åŒ–ã—ã€ã‚³ã‚¢ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã€‚äºŒé‡ç²’åº¦ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ã¦é«˜ä¾¡å€¤ã®CoTãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹ç‡çš„ã«é¸æŠã—ã€ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚10Bãƒˆãƒ¼ã‚¯ãƒ³ã®CoTPãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚Šã€85A6B Mixture-of-Expertsãƒ¢ãƒ‡ãƒ«ã¯AIME 2024ãŠã‚ˆã³2025ã§9.58%ã®æ”¹å–„ã‚’é”æˆã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1971461991039631691?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç´°ã‹ã„ã¨ã“ã‚ã¯èª­ã‚ã¦ã„ãªã„ã®ã ãŒã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ä¸­ã‹ã‚‰é«˜å“è³ªãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŒã¤ã‚‚ã®ã‚’é¸ã‚“ã§å­¦ç¿’ã«ä½¿ã„ãŸã„ã¨ã„ã†ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã€‚ãã®ãŸã‚ã«ã¾ãšä¾¡å€¤ã®é«˜ã„æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å«ã‚€ã‚³ã‚¢ã‚»ãƒƒãƒˆã‚’ä½œã‚Šã€ã‚³ã‚¢ã‚»ãƒƒãƒˆã¨é¡ä¼¼ã—ãŸæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„ã€æ¨è«–ä¸­ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼åˆ—ã‚’æŒã¤ã‚µãƒ³ãƒ—ãƒ«ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åé›†ã™ã‚‹ã¿ãŸã„ãªè©±ãªæ¨¡æ§˜ã€‚é¡ä¼¼åº¦ã¯é‡ã¿ã¤ãDynamic Time Warping (DTW)ã§ã€åŸå§‹çš„ãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç³»åˆ—ã¨ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ç³»åˆ—ã®DTWã®ç·šå‹çµåˆã«ã‚ˆã£ã‚æ±‚ã‚ã‚‹ã€‚åŸå§‹çš„ãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ã€CoT sequenceä¸­ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼åˆ—ã¯DeepSeek-V3ã«ã‚ˆã£ã¦ç”Ÿæˆã™ã‚‹ã€‚<br><br>ã‚³ã‚¢ã‚»ãƒƒãƒˆã‚’ä½œã‚‹ãŸã‚ã«ã¯ã€å•é¡Œã‚¿ã‚¤ãƒ—ã‚„å•é¡Œã®é›£æ˜“åº¦ã«åŸºã¥ã„ã¦äººæ‰‹ã§å•é¡Œã‚’é¸ã³ã€ãã‚Œã‚‰ã«å¯¾ã—ã¦strong reasoning modelã§CoTã‚’ç”Ÿæˆã€‚å„CoTã«å¯¾ã—ã¦ï¼ˆãŠãã‚‰ãï¼‰DeepSeek-V3ã§reasoningã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã¯åŸå§‹çš„ãªCoTãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç³»åˆ—ã§æ§‹æˆã•ã‚Œã‚‹ï¼‰ã‚’ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ã€å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾ã—ã¦TF-IDFã«ã‚ˆã£ã¦é‡è¦åº¦ã‚’æ±ºå®šã™ã‚‹ã€‚æœ€çµ‚çš„ã«ã€å•é¡Œã«æ­£ç­”ã—ã¦ã„ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã«ã¤ã„ã¦ã€äººæ‰‹ã§é«˜å“è³ªã§discriminativeãªCoTãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŒã¤ã‚‚ã®ã‚’é¸æŠã—ã€å„CoTãƒ‘ã‚¿ãƒ¼ãƒ³ã«é‡ã¿ã‚’ã¤ã‘ãŸä¸Šã§ã‚³ã‚¢ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ãŸã€ã¿ãŸã„ãªæ„Ÿã˜ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2995" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Massive Values in Self-Attention Modules are the Key to Contextual   Knowledge Understanding, Mingyu Jin+, ICML'25, 2025.02</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯æ–‡è„ˆçš„çŸ¥è­˜ã®ç†è§£ã«æˆåŠŸã—ã¦ãŠã‚Šã€ç‰¹ã«æ³¨æ„ã‚¯ã‚¨ãƒªï¼ˆQï¼‰ã¨ã‚­ãƒ¼ï¼ˆKï¼‰ã«ãŠã„ã¦é›†ä¸­ã—ãŸå¤§è¦æ¨¡ãªå€¤ãŒä¸€è²«ã—ã¦ç¾ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã“ã‚Œã‚‰ã®å€¤ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ä¿å­˜ã•ã‚ŒãŸçŸ¥è­˜ã§ã¯ãªãã€ç¾åœ¨ã®æ–‡è„ˆã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹çŸ¥è­˜ã®è§£é‡ˆã«é‡è¦ã§ã‚ã‚‹ã€‚é‡å­åŒ–æˆ¦ç•¥ã®èª¿æŸ»ã«ã‚ˆã‚Šã€ã“ã‚Œã‚‰ã®å€¤ã‚’ç„¡è¦–ã™ã‚‹ã¨æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€é›†ä¸­ã—ãŸå¤§è¦æ¨¡ãªå€¤ã®å‡ºç¾ãŒãƒ­ã‚¿ãƒªãƒ¼ãƒã‚¸ã‚·ãƒ§ãƒŠãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆRoPEï¼‰ã«ã‚ˆã£ã¦å¼•ãèµ·ã“ã•ã‚Œã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ãŸã€‚ã“ã‚Œã‚‰ã®çµæœã¯ã€LLMã®è¨­è¨ˆã¨æœ€é©åŒ–ã«é–¢ã™ã‚‹æ–°ãŸãªæ´å¯Ÿã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=1SMcxxQiSL&noteId=7BAXSETAwU" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=1SMcxxQiSL&noteId=7BAXSETAwU</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Ensemble.html" target="_blank" rel="noopener noreferrer">#Ensemble</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Best-of-N.html" target="_blank" rel="noopener noreferrer">#Best-of-N</a>
<span class="issue_date">Issue Date: 2025-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2992" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Best-of-$\infty$ -- Asymptotic Performance of Test-Time Compute, Junpei Komiyama+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã‘ã‚‹Best-of-$N$ã‚’å¤šæ•°æ±ºã«åŸºã¥ã„ã¦ç ”ç©¶ã—ã€$N \to \infty$ã®é™ç•Œï¼ˆBest-of-$\infty$ï¼‰ã‚’åˆ†æã€‚ç„¡é™ã®ãƒ†ã‚¹ãƒˆæ™‚é–“ã‚’å¿…è¦ã¨ã™ã‚‹å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€å›ç­”ã®ä¸€è‡´ã«åŸºã¥ãé©å¿œç”Ÿæˆã‚¹ã‚­ãƒ¼ãƒ ã‚’ææ¡ˆã—ã€æ¨è«–æ™‚é–“ã‚’åŠ¹ç‡çš„ã«é…åˆ†ã€‚ã•ã‚‰ã«ã€è¤‡æ•°ã®LLMã®é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’æ‹¡å¼µã—ã€æœ€é©ãªé‡ã¿ä»˜ã‘ã‚’æ··åˆæ•´æ•°ç·šå½¢è¨ˆç”»ã¨ã—ã¦å®šå¼åŒ–ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æœ‰åŠ¹æ€§ã‚’å®Ÿè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://jkomiyama.github.io/bestofinfty/" target="_blank" rel="noopener noreferrer">https://jkomiyama.github.io/bestofinfty/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jkomiyama_/status/1971408925464654026?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2982" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] EmbeddingGemma: Powerful and Lightweight Text Representations, Henrique Schechter Vera+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- EmbeddingGemmaã¯ã€Gemma 3è¨€èªãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ãè»½é‡ãªã‚ªãƒ¼ãƒ—ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã§ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€-ãƒ‡ã‚³ãƒ¼ãƒ€ã®åˆæœŸåŒ–ã¨å¹¾ä½•å­¦çš„åŸ‹ã‚è¾¼ã¿è’¸ç•™ã‚’ç”¨ã„ã¦å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã‚’æ´»ç”¨ã€‚åˆ†æ•£æ­£å‰‡åŒ–å™¨ã‚’ä½¿ç”¨ã—ã€ç•°ãªã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’çµ±åˆã™ã‚‹ã“ã¨ã§ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’å‘ä¸Šã€‚300Mã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã€MTEBã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã€å¾“æ¥ã®ãƒˆãƒƒãƒ—ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚é‡å­åŒ–ã‚„å‡ºåŠ›ã®åˆ‡ã‚Šè©°ã‚ã«ã‚‚è€ãˆã€ä½é…å»¶ã‹ã¤é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«é©ã—ã¦ã„ã‚‹ã€‚EmbeddingGemmaã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å…¬é–‹ã•ã‚Œã€ã•ã‚‰ãªã‚‹ç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…¬å¼ãƒ¢ãƒ‡ãƒ«æ¦‚è¦:


<a href="https://ai.google.dev/gemma/docs/embeddinggemma?hl=ja" target="_blank" rel="noopener noreferrer">https://ai.google.dev/gemma/docs/embeddinggemma?hl=ja</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1971041110446465251?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>100ä»¥ä¸Šã®è¨€èªã§è¨“ç·´ã•ã‚Œãƒãƒˆãƒªãƒ§ãƒ¼ã‚·ã‚«è¡¨ç¾ãªã®ã§ãƒ™ã‚¯ãƒˆãƒ«ã®ã‚µã‚¤ã‚ºã‚’èª¿æ•´å¯èƒ½ãªæ¨¡æ§˜</p>
<p>ãƒãƒˆãƒªãƒ§ãƒ¼ã‚·ã‚«è¡¨ç¾:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2311" target="_blank" rel="noopener noreferrer">[Paper Note] Matryoshka Representation Learning, Aditya Kusupati+, NeurIPS'22</a>
</p>
<p>å…¬å¼ã«ã‚ˆã‚‹è§£èª¬ãƒ–ãƒ­ã‚°:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sahildua2305/status/1973021214588506274?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2980" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Thinking Augmented Pre-training, Liang Wang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æ€è€ƒã®è»Œè·¡ã‚’ç”¨ã„ã¦ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ‹¡å¼µã™ã‚‹ã€ŒThinking augmented Pre-Trainingï¼ˆTPTï¼‰ã€ã‚’ææ¡ˆã—ã€LLMã®ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã‚’å‘ä¸Šã€‚TPTã¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹æœçš„ã«å¢—åŠ ã•ã›ã€é«˜å“è³ªãªãƒˆãƒ¼ã‚¯ãƒ³ã®å­¦ç¿’ã‚’å®¹æ˜“ã«ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€TPTãŒLLMã®æ€§èƒ½ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã€ç‰¹ã«3Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã§æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ€§èƒ½ã‚’10%ä»¥ä¸Šæ”¹å–„ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1971086346942022026?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ï¼ˆæ–œã‚èª­ã¿ã—ã‹ã¾ã ã§ãã¦ã„ãªã„ãŒï¼‰2ç¯€ã«å­˜åœ¨ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”¨ã„ã¦ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå…¨ä½“ã‚’contextã¨ã—ã¦ä¸ãˆã€contextä¸­ã«å­˜åœ¨ã™ã‚‹è¤‡é›‘ãªæƒ…å ±ã«é–¢ã—ã¦æ·±ã„åˆ†æã‚’ã™ã‚‹ã‚ˆã†ã«thinking traceã‚’ç”Ÿæˆã—ã€ç”Ÿæˆã—ãŸtrace tã‚’concatã—ã¦next token predictionã§äº‹å‰å­¦ç¿’ã™ã‚‹æ¨¡æ§˜ã€‚æ•°å­¦ãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼ã—äº‹å‰å­¦ç¿’ãŒ3å€ãƒˆãƒ¼ã‚¯ãƒ³é‡ vs. downstreamã‚¿ã‚¹ã‚¯ï¼ˆGSM8K, MATH)æ€§èƒ½ã®è¦³ç‚¹åŠ¹ç‡çš„ã«ãªã£ãŸã ã‹ã§ãªãï¼ˆã“ã‚Œã¯äº‹å¾Œå­¦ç¿’ã®å…ˆå–ã‚Šã‚’ã—ã¦ã„ã‚‹ã¿ãŸã„ãªã‚‚ã®ãªæ°—ãŒã™ã‚‹ã®ã§ãã†ãªã‚‹ã ã‚ã†ãªã¨ã„ã†æ°—ãŒã™ã‚‹ï¼‰ã€ãŠãªã˜ãƒˆãƒ¼ã‚¯ãƒ³é‡ã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’SFTã—ãŸå ´åˆã§ã‚‚ã€ææ¡ˆæ‰‹æ³•ã®æ–¹ãŒæ€§èƒ½ãŒè‰¯ã‹ã£ãŸæ¨¡æ§˜ï¼ˆTable2, ã“ã£ã¡ã®æ–¹ãŒå€‹äººçš„ã«ã¯é‡è¦ãªæ°—ãŒã—ã¦ã„ã‚‹)ã€‚</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1971334199555784807?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2977" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] UMoE: Unifying Attention and FFN with Shared Experts, Yuanhang Yang+, arXiv'25, 2025.05</a>
<span class="snippet"><span>GPT Summary</span>- Sparse Mixture of Experts (MoE) ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€Transformer ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ãŠã„ã¦æœ‰æœ›ãªæ‰‹æ³•ã§ã‚ã‚Šã€æ³¨æ„å±¤ã¸ã®æ‹¡å¼µãŒæ¢æ±‚ã•ã‚Œã¦ã„ã¾ã™ãŒã€æ—¢å­˜ã®æ³¨æ„ãƒ™ãƒ¼ã‚¹ã® MoE å±¤ã¯æœ€é©ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚æœ¬è«–æ–‡ã§ã¯ã€æ³¨æ„å±¤ã¨ FFN å±¤ã® MoE è¨­è¨ˆã‚’çµ±ä¸€ã—ã€æ³¨æ„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®å†å®šå¼åŒ–ã‚’è¡Œã„ã€FFN æ§‹é€ ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã™ã€‚ææ¡ˆã™ã‚‹UMoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€æ³¨æ„ãƒ™ãƒ¼ã‚¹ã® MoE å±¤ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’é”æˆã—ã€åŠ¹ç‡çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å…±æœ‰ã‚’å®Ÿç¾ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nathancgy4/status/1970887450739281953?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Mixture of Attention Heads (MoA)ã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3110" target="_blank" rel="noopener noreferrer">[Paper Note] Mixture of Attention Heads: Selecting Attention Heads Per Token, Xiaofeng Zhang+, EMNLP'22, 2022.10</a>
</p>
<p>ã“ã®å›³ãŒã‚ã‹ã‚Šã‚„ã™ã„ã€‚å¾Œã»ã©èª¬æ˜ã‚’è¿½è¨˜ã™ã‚‹ã€‚ã–ã£ãã‚Šè¨€ã†ã¨ã€MoAã‚’å‰æã¨ã—ãŸã¨ãã«ã€æœ€å¾Œã®å‡ºåŠ›ã®å¤‰æ›éƒ¨åˆ†VW_oã‚’FFNã«ã‚ˆã‚‹å¤‰æ›ï¼ˆã¤ã¾ã‚ŠFFN Expertsã®ä¸€ã¤ï¼‰ã¨ã¿ãªã—ã¦ã€self-attentionã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ··ãœåˆã‚ã›ã‚‹ã¨ã„ã†è¶£æ—¨ã‚’å¤±ã‚ãªã„ç¯„å›²ã§è¨ˆç®—é †åºã‚’èª¿æ•´ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒŸãƒƒã‚¯ã‚¹ã™ã‚‹éƒ¨åˆ†ã‚’å…ˆã«æŒã£ã¦ãã‚‹ï¼‰ã™ã‚‹ã¨ã€FFNã®MoEã¨MoAã¯åŒã˜æ çµ„ã¿ã§æ‰±ãˆã‚‹ãŸã‚ã€expertsã‚’å…±æœ‰ã§ãã¦ãƒ¡ãƒ¢ãƒªã‚’å‰Šæ¸›ã§ãã€ã‹ã¤MoAã«ã‚ˆã£ã¦å¿…è¦ãªç®‡æ‰€ã®ã¿ã«attendã™ã‚‹èƒ½åŠ›ãŒé«˜ã¾ã‚Šæ€§èƒ½ã‚‚ä¸ŠãŒã‚Šã¾ã™ã€ã¿ãŸã„ãªè©±ã«è¦‹ãˆã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/44ba6bee-d1fa-4385-a4c6-2c937cc15ea5" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/248e1bc5-6c14-4b2d-9aed-c1d7359c605e" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/SpeculativeDecoding.html" target="_blank" rel="noopener noreferrer">#SpeculativeDecoding</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2976" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Speculative Decoding with Lookahead Reasoning, Yichao Fu+, arXiv'25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- Lookahead Reasoningã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€æ¨è«–ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³ãƒ‡ã‚³ãƒ¼ãƒ‰é€Ÿåº¦ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚è»½é‡ãªãƒ‰ãƒ©ãƒ•ãƒˆãƒ¢ãƒ‡ãƒ«ãŒå°†æ¥ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ææ¡ˆã—ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ãŒä¸€åº¦ã®ãƒãƒƒãƒå‡¦ç†ã§å±•é–‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã®æ¨æ¸¬ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆSDï¼‰ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’1.4å€ã‹ã‚‰2.1å€ã«æ”¹å–„ã—ã€å›ç­”ã®è³ªã‚’ç¶­æŒã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haozhangml/status/1970607910846898488?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/LowResource.html" target="_blank" rel="noopener noreferrer">#LowResource</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2970" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SSA-COMET: Do LLMs Outperform Learned Metrics in Evaluating MT for   Under-Resourced African Languages?, Senyu Li+, EMNLP'25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¢ãƒ•ãƒªã‚«ã®è¨€èªã«ãŠã‘ã‚‹æ©Ÿæ¢°ç¿»è¨³ã®å“è³ªè©•ä¾¡ã¯ä¾ç„¶ã¨ã—ã¦èª²é¡Œã§ã‚ã‚Šã€æ—¢å­˜ã®æŒ‡æ¨™ã¯é™ã‚‰ã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€13ã®ã‚¢ãƒ•ãƒªã‚«è¨€èªãƒšã‚¢ã‚’å¯¾è±¡ã¨ã—ãŸå¤§è¦æ¨¡ãªäººé–“æ³¨é‡ˆä»˜ãMTè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒSSA-MTEã€ã‚’ç´¹ä»‹ã—ã€63,000ä»¥ä¸Šã®æ–‡ãƒ¬ãƒ™ãƒ«ã®æ³¨é‡ˆã‚’å«ã‚“ã§ã„ã¾ã™ã€‚ã“ã‚Œã«åŸºã¥ãã€æ”¹è‰¯ã•ã‚ŒãŸè©•ä¾¡æŒ‡æ¨™ã€ŒSSA-COMETã€ã¨ã€ŒSSA-COMET-QEã€ã‚’é–‹ç™ºã—ã€æœ€å…ˆç«¯ã®LLMã‚’ç”¨ã„ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã—ã¾ã—ãŸã€‚å®Ÿé¨“çµæœã¯ã€SSA-COMETãŒAfriCOMETã‚’ä¸Šå›ã‚Šã€ç‰¹ã«ä½ãƒªã‚½ãƒ¼ã‚¹è¨€èªã§ç«¶äº‰åŠ›ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã™ã¹ã¦ã®ãƒªã‚½ãƒ¼ã‚¹ã¯ã‚ªãƒ¼ãƒ—ãƒ³ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1970720101306679436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2969" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Multilingual Language Model Pretraining using Machine-translated Data, Jiayi Wang+, EMNLP'25, 2025.02</a>
<span class="snippet"><span>GPT Summary</span>- é«˜ãƒªã‚½ãƒ¼ã‚¹è¨€èªã®è‹±èªã‹ã‚‰ç¿»è¨³ã—ãŸé«˜å“è³ªãªãƒ†ã‚­ã‚¹ãƒˆãŒã€å¤šè¨€èªLLMsã®äº‹å‰å­¦ç¿’ã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚è‹±èªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆFineWeb-Eduã‚’9è¨€èªã«ç¿»è¨³ã—ã€17å…†ãƒˆãƒ¼ã‚¯ãƒ³ã®TransWebEduã‚’ä½œæˆã€‚1.3Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®TransWebLLMã‚’äº‹å‰å­¦ç¿’ã—ã€éè‹±èªã®æ¨è«–ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’é”æˆã€‚ç‰¹ã«ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ã„ãã¤ã‹ã®è¨€èªã§æ–°ãŸãªæœ€å…ˆç«¯ã‚’é”æˆã€‚ã‚³ãƒ¼ãƒ‘ã‚¹ã€ãƒ¢ãƒ‡ãƒ«ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1970720101306679436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2968" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reinforcement Learning on Pre-Training Data, Siheng Li+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- RLPTã¨ã„ã†æ–°ã—ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’å°å…¥ã—ã€LLMsã®æœ€é©åŒ–ã‚’å›³ã‚‹ã€‚å¾“æ¥ã®æ–¹æ³•ã«ä¾å­˜ã›ãšã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç›´æ¥å ±é…¬ä¿¡å·ã‚’å°å‡ºã—ã€æ¬¡ã®ãƒ†ã‚­ã‚¹ãƒˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã§ãƒãƒªã‚·ãƒ¼ã«å ±é…¬ã‚’ä¸ãˆã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€è¤‡æ•°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ€§èƒ½ãŒå‘ä¸Šã—ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã®å¢—åŠ ã«ã‚ˆã‚‹ã•ã‚‰ãªã‚‹æ”¹å–„ã®å¯èƒ½æ€§ãŒç¤ºã•ã‚ŒãŸã€‚RLPTã¯LLMsã®æ¨è«–èƒ½åŠ›ã‚’æ‹¡å¼µã—ã€RLVRã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã«ã‚‚å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1970684035258294548?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2031" target="_blank" rel="noopener noreferrer">[Paper Note] Reinforcement Pre-Training, Qingxiu Dong+, arXiv'25</a>
</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/changjonathanc/status/1971045178640302421?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tencenthunyuan/status/1971118167281057821?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2964" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Heimdall: test-time scaling on the generative verification, Wenlei Shi+, arXiv'25, 2025.04</a>
<span class="snippet"><span>GPT Summary</span>- Heimdallã¯ã€é•·ã„Chain-of-Thoughtæ¨è«–ã«ãŠã‘ã‚‹æ¤œè¨¼èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®LLMã§ã‚ã‚Šã€æ•°å­¦å•é¡Œã®è§£æ±ºç²¾åº¦ã‚’62.5%ã‹ã‚‰94.5%ã«å¼•ãä¸Šã’ã€ã•ã‚‰ã«97.5%ã«é”ã™ã‚‹ã€‚æ‚²è¦³çš„æ¤œè¨¼ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€è§£æ±ºç­–ã®ç²¾åº¦ã‚’54.2%ã‹ã‚‰70.0%ã€å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§93.0%ã«å‘ä¸Šã•ã›ã‚‹ã€‚è‡ªå‹•çŸ¥è­˜ç™ºè¦‹ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚‚ä½œæˆã—ã€ãƒ‡ãƒ¼ã‚¿ã®æ¬ é™¥ã‚’ç‰¹å®šã™ã‚‹èƒ½åŠ›ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2961" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Soft Tokens, Hard Truths, Natasha Butt+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€é›¢æ•£CoTã‹ã‚‰ã®è’¸ç•™ãªã—ã«å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦é€£ç¶šCoTã‚’å­¦ç¿’ã™ã‚‹æ–°ã—ã„æ–¹æ³•ã‚’ææ¡ˆã€‚ã‚½ãƒ•ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ´»ç”¨ã—ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã¤ã¤æ•°ç™¾ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŒã¤é€£ç¶šCoTã‚’å­¦ç¿’å¯èƒ½ã€‚LlamaãŠã‚ˆã³Qwenãƒ¢ãƒ‡ãƒ«ã§ã®å®Ÿé¨“ã«ã‚ˆã‚Šã€é€£ç¶šCoTã¯é›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³CoTã¨åŒç­‰ã¾ãŸã¯ãã‚Œã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ç‰¹ã«é€£ç¶šCoTã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã«é›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³ã§æ¨è«–ã™ã‚‹ã‚·ãƒŠãƒªã‚ªãŒæœ€è‰¯ã®çµæœã‚’å¾—ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚ã•ã‚‰ã«ã€é€£ç¶šCoTã®RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ä¿æŒã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1970692910766346277?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1971341729803759989?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/natashaeve4/status/1971216376556814356?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1974348003696619795?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/SamplingParams.html" target="_blank" rel="noopener noreferrer">#SamplingParams</a>
<a class="button" href="articles/Best-of-N.html" target="_blank" rel="noopener noreferrer">#Best-of-N</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2957" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Optimizing Temperature for Language Models with Multi-Sample Inference, Weihua Du+, ICML'25, 2025.02</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒã‚µãƒ³ãƒ—ãƒ«é›†ç´„æˆ¦ç•¥ã‚’ç”¨ã„ã¦ã€LLMã®æœ€é©ãªæ¸©åº¦ã‚’è‡ªå‹•çš„ã«ç‰¹å®šã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚å¾“æ¥ã®æ–¹æ³•ã«ä¾å­˜ã›ãšã€ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è€ƒæ…®ã—ãŸæ¸©åº¦ã®å½¹å‰²ã‚’åˆ†æã€‚æ–°ãŸã«ææ¡ˆã™ã‚‹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã«åŸºã¥ãæŒ‡æ¨™ã¯ã€å›ºå®šæ¸©åº¦ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ç¢ºç‡éç¨‹ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦æ¸©åº¦ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®é–¢ä¿‚ã‚’è§£æ˜ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=rmWpE3FrHW&noteId=h9GETXxWDB" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=rmWpE3FrHW&noteId=h9GETXxWDB</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2944" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] reWordBench: Benchmarking and Improving the Robustness of Reward Models   with Transformed Inputs, Zhaofeng Wu+, EMNLP'25, 2025.03</a>
<span class="snippet"><span>GPT Summary</span>- å ±é…¬ãƒ¢ãƒ‡ãƒ«ã¯NLPã«ãŠã„ã¦é‡è¦ã ãŒã€éå­¦ç¿’ã®å½±éŸ¿ã§çœŸã®èƒ½åŠ›ãŒæ··ä¹±ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€å ±é…¬ãƒ¢ãƒ‡ãƒ«ã®å …ç‰¢æ€§ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«**reWordBench**ã‚’æ§‹ç¯‰ã—ã€å…¥åŠ›å¤‰æ›ã«ã‚ˆã‚‹æ€§èƒ½ä½ä¸‹ã‚’èª¿æŸ»ã€‚æœ€å…ˆç«¯ã®å ±é…¬ãƒ¢ãƒ‡ãƒ«ã¯å°ã•ãªå¤‰æ›ã§ã‚‚è‘—ã—ã„æ€§èƒ½ä½ä¸‹ã‚’ç¤ºã—ã€è„†å¼±æ€§ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚å …ç‰¢æ€§å‘ä¸Šã®ãŸã‚ã«åŒç¾©èªã«å¯¾ã—ã¦é¡ä¼¼ã‚¹ã‚³ã‚¢ã‚’å‰²ã‚Šå½“ã¦ã‚‹è¨“ç·´ã‚’ææ¡ˆã—ã€ã“ã‚Œã«ã‚ˆã‚Šæ€§èƒ½ä½ä¸‹ã‚’ç´„åŠåˆ†ã«æ¸›å°‘ã•ã›ãŸã€‚ã•ã‚‰ã«ã€ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã«ãŠã„ã¦ã‚‚é«˜å“è³ªãªå‡ºåŠ›ã‚’ç”Ÿæˆã—ã€æ¨™æº–çš„ãªå ±é…¬ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦æœ€å¤§59%ã®ã‚±ãƒ¼ã‚¹ã§å„ªã‚ŒãŸçµæœã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhaofeng_wu/status/1970145215613677789?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Figure1ãŒRMã®éå­¦ç¿’ã®æ§˜å­ã‚’å›³ç¤ºã—ã¦ãŠã‚Šã€éå¸¸ã«ç«¯çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2938" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LIMI: Less is More for Agency, Yang Xiao+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- AIã‚·ã‚¹ãƒ†ãƒ ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ã‚·ãƒ¼ã‚’ã€è‡ªå¾‹çš„ã«å•é¡Œã‚’ç™ºè¦‹ã—è§£æ±ºç­–ã‚’å®Ÿè¡Œã™ã‚‹èƒ½åŠ›ã¨å®šç¾©ã€‚æ€¥é€Ÿã«å¤‰åŒ–ã™ã‚‹æ¥­ç•Œã®ãƒ‹ãƒ¼ã‚ºã«å¿œã˜ã¦ã€å˜ãªã‚‹æ¨è«–ã‚’è¶…ãˆãŸè‡ªå¾‹çš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ±‚ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚LIMIï¼ˆLess Is More for Intelligent Agencyï¼‰ã¯ã€æœ€å°é™ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«ã§é«˜ã„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ã‚·ãƒ¼ã‚’å®Ÿç¾ã™ã‚‹æ–°ãŸãªåŸå‰‡ã‚’ææ¡ˆã—ã€78ã‚µãƒ³ãƒ—ãƒ«ã§73.5%ã®æˆæœã‚’é”æˆã€‚ã“ã‚Œã¯ã€å¾“æ¥ã®ãƒ‡ãƒ¼ã‚¿é‡ã«ä¾å­˜ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«å¯¾ã™ã‚‹æŒ‘æˆ¦ã§ã‚ã‚Šã€é«˜å“è³ªãªãƒ‡ãƒ¢ã®æˆ¦ç•¥çš„ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1970328242688246160?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLM Agentã®SFTã«ãŠã‘ã‚‹Less is more<br><br>å‚è€ƒ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/700" target="_blank" rel="noopener noreferrer">LIMA: Less Is More for Alignment, Chunting Zhou+, N/A, NeurIPS'23</a>
</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1971777010658955436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2937" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ARE: Scaling Up Agent Environments and Evaluations, Pierre Andrews+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- Meta Agents Research Environments (ARE)ã‚’ç´¹ä»‹ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ç’°å¢ƒã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªä½œæˆã‚’æ”¯æ´ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’æä¾›ã€‚Gaia2ã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚Œã€å‹•çš„ç’°å¢ƒã¸ã®é©å¿œã‚„ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®å”åŠ›ã‚’è¦æ±‚ã€‚Gaia2ã¯éåŒæœŸã§å®Ÿè¡Œã•ã‚Œã€æ–°ãŸãªå¤±æ•—ãƒ¢ãƒ¼ãƒ‰ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€çŸ¥èƒ½ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«å…¨ä½“ã§ã®æ”¯é…çš„ãªã‚·ã‚¹ãƒ†ãƒ ãŒå­˜åœ¨ã—ãªã„ã“ã¨ã‚’ç¤ºã—ã€AREã®æŠ½è±¡åŒ–ãŒæ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®è¿…é€Ÿãªä½œæˆã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ã‚’å¼·èª¿ã€‚AIã®é€²å±•ã¯ã€æ„å‘³ã®ã‚ã‚‹ã‚¿ã‚¹ã‚¯ã¨å …ç‰¢ãªè©•ä¾¡ã«ä¾å­˜ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/froger_romain/status/1970120373829066982?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>GAIAã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1158" target="_blank" rel="noopener noreferrer">GAIA: a benchmark for General AI Assistants, GrÃ©goire Mialon+, N/A, arXiv'23</a>
</p>
<p>Execution, Search, Ambiguity, Adaptability, Time, Noise, Agent2Agentã®6ã¤ã®capabilityã‚’è©•ä¾¡å¯èƒ½ã€‚èˆˆå‘³æ·±ã„ã€‚</p>
<p>ç¾çŠ¶ã€å…¨ä½“çš„ã«ã¯GPT-5(high)ã®æ€§èƒ½ãŒæœ€ã‚‚è‰¯ãã€ç¶šã„ã¦Claude-4 Sonnetã¨ã„ã†æ„Ÿã˜ã«è¦‹ãˆã‚‹ã€‚OpenWeightãªãƒ¢ãƒ‡ãƒ«ã§ã¯ã€Kimi-K2ã®æ€§èƒ½ãŒé«˜ãã€ç¶šã„ã¦Qwen3-235Bã¨ã„ã†æ„Ÿã˜ã«è¦‹ãˆã‚‹ã€‚ã¾ãŸã€Figure1ã¯budgetã”ã¨ã®ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚‚ç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚ã‚·ãƒŠãƒªã‚ªå˜ä½ã®budgetãŒ$1ä»¥ä¸Šã®å ´åˆã¯GPT-5(high)ã®æ€§èƒ½ãŒæœ€ã‚‚è‰¯ã„ãŒã€$0.1--$0.4ã®é–“ã§ã¯Kiml-K2ã®æ€§èƒ½ãŒæœ€ã‚‚è‰¯ã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/039a6e69-4941-4a80-99b3-0590d1446030" alt="image" loading="lazy"></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2406" target="_blank" rel="noopener noreferrer">[Paper Note] GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models, GLM-4. 5 Team+, arXiv'25</a>
<br><br>ã—ã£ã‹ã‚Šã¨èª­ã‚ã¦ã„ãªã„ãŒGLM-4.5ã¯å«ã¾ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1970162732470067283?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2933" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] JudgeLM: Fine-tuned Large Language Models are Scalable Judges, Lianghui Zhu+, ICLR'25, 2023.10</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰è©•ä¾¡ã®ãŸã‚ã«ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸJudgeLMã‚’ææ¡ˆã€‚é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€ãƒã‚¤ã‚¢ã‚¹ã‚’åˆ†æã€‚æ–°æŠ€è¡“ã‚’å°å…¥ã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã€‚JudgeLMã¯æ—¢å­˜ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã€é«˜ã„ä¸€è‡´ç‡ã‚’ç¤ºã™ã€‚æ‹¡å¼µã•ã‚ŒãŸèƒ½åŠ›ã‚‚æŒã¡ã€ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=xsELpEPn4A" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=xsELpEPn4A</a>


</p>
<p>dataset: 


<a href="https://huggingface.co/datasets/BAAI/JudgeLM-100K" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/BAAI/JudgeLM-100K</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2932" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Libra: Assessing and Improving Reward Model by Learning to Think, Meng Zhou+, arXiv'25, 2025.07</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã®å ±é…¬ãƒ¢ãƒ‡ãƒ«ã¯ã€å›°é›£ãªæ¨è«–ã‚·ãƒŠãƒªã‚ªã§ã®æ€§èƒ½ãŒä½ä¸‹ã—ã¦ãŠã‚Šã€æ³¨é‡ˆä»˜ãå‚ç…§å›ç­”ã‚„åˆ¶ç´„ã•ã‚ŒãŸå‡ºåŠ›å½¢å¼ã«ä¾å­˜ã—ã¦ã„ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€æ¨è«–æŒ‡å‘ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒLibra Benchã€ã‚’ææ¡ˆã—ã€ç”Ÿæˆçš„å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’æ”¹å–„ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å°å…¥ã€‚Libra-RMã‚·ãƒªãƒ¼ã‚ºã‚’é–‹ç™ºã—ã€ã•ã¾ã–ã¾ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã€‚å®Ÿé¨“çµæœã¯ã€Libra Benchã¨ä¸‹æµã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã®ç›¸é–¢é–¢ä¿‚ã‚’ç¤ºã—ã€ãƒ©ãƒ™ãƒ«ã®ãªã„ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸæ¨è«–ãƒ¢ãƒ‡ãƒ«ã®æ”¹å–„ã®å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1969851940277231714?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Related Workã‚’èª­ã‚€ã¨ã€ `Discriminative Reward models` ã¨ `Generative Reward models` ã®é•ã„ãŒç°¡æ½”ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<br>è¦ã¯<br>- Discriminative Reward models:<br>  - LLMã‚’Backboneã¨ã—ã¦æŒã¡ã€<br>  - ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ç”¨ã®ãƒ˜ãƒƒãƒ‰ã‚’è¿½åŠ ã—preference dataã‚’ç”¨ã„ã¦ï¼ˆpairwiseã®ranking lossã‚’é€šã˜ã¦ï¼‰å­¦ç¿’ã•ã‚Œã€scalar rewardã‚’è¿”ã™<br>- Generative Reward models:<br>  - é€šå¸¸ã¨LLMã¨åŒã˜ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ï¼ˆNext Token Prdiction lossã‚’é€šã˜ã¦å­¦ç¿’ã•ã‚Œï¼‰<br>  - responseãŒinputã¨ã—ã¦ä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€rewardã«é–¢ã™ã‚‹æƒ…å ±ã‚’æŒã¤textualãªoutputã‚’è¿”ã™ï¼ˆè¦ã¯ã€LLM-as-a-Judge <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2933" target="_blank" rel="noopener noreferrer">[Paper Note] JudgeLM: Fine-tuned Large Language Models are Scalable Judges, Lianghui Zhu+, ICLR'25, 2023.10</a>
 <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1616" target="_blank" rel="noopener noreferrer">A Survey on LLM-as-a-Judge, Jiawei Gu+, arXiv'24</a>
ï¼‰<br>  - reasoning traceã‚’æ´»ç”¨ã™ã‚Œã°thinking modelï¼ˆTest time scalingï¼‰ã®æ©æµã‚’ã‚ãšã‹ã‚‹ã“ã¨ãŒå¯èƒ½<br>  - GenRMã®ãƒ«ãƒ¼ãƒ„ã¯ã“ã®ã¸ã‚“ã ã‚ã†ã‹:<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1388" target="_blank" rel="noopener noreferrer">Generative Verifiers: Reward Modeling as Next-Token Prediction, Lunjun Zhang+, N/A, ICLR'25</a>
<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/708" target="_blank" rel="noopener noreferrer">LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and  Generative Fusion, Dongfu Jiang+, N/A, ACL'23</a>
<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1212" target="_blank" rel="noopener noreferrer">Self-Rewarding Language Models, Weizhe Yuan+, N/A, ICML'24</a>
<br><br>ã¨ã„ã†åŒºåˆ¥ã§ã‚ã‚‹ã€‚<br><br>ä»¥ä¸‹ã®ãƒãƒ¼ãƒˆã‚‚å‚è€ƒã®ã“ã¨:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2240" target="_blank" rel="noopener noreferrer">[Personal Note] LLM-as-a-judge / Reward Model</a>
<br><br>GenRMã¯è¿½åŠ ã®å­¦ç¿’ãªã—ã§åˆ©ç”¨ã•ã‚Œã‚‹ã®ãŒæ™®é€šã ã£ãŸã‚ˆã†ã ãŒã€RMç”¨ã®è¿½åŠ ã®å­¦ç¿’ã‚’ã—ã¦ã‚‚ä½¿ãˆã‚‹ã¨æ€ã†ã®ã§ãã“ã¯ã‚ã¾ã‚Šæ°—ã«ã—ãªãã¦è‰¯ã„ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>ã¾ãŸ<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1468" target="_blank" rel="noopener noreferrer">Generative Reward Models, Dakota Mahan+, N/A, arXiv'24</a>
<br><br>ã®Figure1ãŒã€RMã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®é•ã„ã‚’ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2930" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Transfusion: Predict the Next Token and Diffuse Images with One   Multi-Modal Model, Chunting Zhou+, ICLR'25, 2024.08</a>
<span class="snippet"><span>GPT Summary</span>- Transfusionã¯ã€é›¢æ•£ãƒ‡ãƒ¼ã‚¿ã¨é€£ç¶šãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹æ‰‹æ³•ã§ã€è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®æå¤±é–¢æ•°ã¨æ‹¡æ•£ã‚’çµ„ã¿åˆã‚ã›ã¦å˜ä¸€ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’è¨“ç·´ã—ã¾ã™ã€‚æœ€å¤§7Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰è¨“ç·´ã—ã€ãƒ¦ãƒ‹ãƒ¢ãƒ¼ãƒ€ãƒ«ãŠã‚ˆã³ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ç¤ºã—ã¾ã—ãŸã€‚ãƒ¢ãƒ€ãƒªãƒ†ã‚£ç‰¹æœ‰ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å±¤ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã€7Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã§ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=SI2hI0frk6" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=SI2hI0frk6</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2929" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LoRA-Pro: Are Low-Rank Adapters Properly Optimized?, Zhengbo Wang+, ICLR'25, 2024.07</a>
<span class="snippet"><span>GPT Summary</span>- LoRAã¯åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®åŠ¹ç‡çš„ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã ãŒã€ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«æ¯”ã¹æ€§èƒ½ãŒåŠ£ã‚‹ã“ã¨ãŒå¤šã„ã€‚æœ¬è«–æ–‡ã§ã¯ã€LoRAã¨ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã®é–¢ä¿‚ã‚’æ˜ã‚‰ã‹ã«ã—ã€LoRAã®ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ã®å‹¾é…ã‚’èª¿æ•´ã™ã‚‹æ–°æ‰‹æ³•LoRA-Proã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LoRAã®æ€§èƒ½ãŒå‘ä¸Šã—ã€ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã®ã‚®ãƒ£ãƒƒãƒ—ãŒç¸®å°ã™ã‚‹ã“ã¨ã‚’å®Ÿé¨“ã§ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://openreview.net/forum?id=gTwRMU3lJ5" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=gTwRMU3lJ5</a>


</p>
<p>openreview:


<a href="https://openreview.net/forum?id=gTwRMU3lJ5" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=gTwRMU3lJ5</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2927" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Synthetic bootstrapped pretraining, Zitong Yang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- Synthetic Bootstrapped Pretrainingï¼ˆSBPï¼‰ã¯ã€æ–‡æ›¸é–“ã®é–¢ä¿‚ã‚’å­¦ç¿’ã—ã€æ–°ã—ã„ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’åˆæˆã™ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’æ‰‹æ³•ã§ã™ã€‚å¾“æ¥ã®äº‹å‰å­¦ç¿’ã¯å˜ä¸€æ–‡æ›¸å†…ã®å› æœé–¢ä¿‚ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ãŒã€SBPã¯æ–‡æ›¸é–“ã®ç›¸é–¢é–¢ä¿‚ã‚’åŠ¹ç‡çš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¾ã™ã€‚3Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã€SBPã¯å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’æ”¹å–„ã—ã€åˆæˆã•ã‚ŒãŸæ–‡æ›¸ã¯å˜ãªã‚‹è¨€ã„æ›ãˆã‚’è¶…ãˆãŸæ–°ã—ã„ç‰©èªã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚SBPã¯è‡ªç„¶ãªãƒ™ã‚¤ã‚ºçš„è§£é‡ˆã‚’è¨±å®¹ã—ã€é–¢é€£æ–‡æ›¸é–“ã®æ½œåœ¨çš„ãªæ¦‚å¿µã‚’å­¦ç¿’ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1970009915797475489?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1969973861178626245?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>èˆˆå‘³æ·±ã„ã€‚</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zitongyang0/status/1970129028536484089?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>conceptã‚’å­¦ç¿’ã™ã‚‹ã¨ã„ã†è¦³ç‚¹ã§ã¯ä»¥ä¸‹ãŒé–¢é€£ã—ã¦ã„ã‚‹æ°—ãŒã™ã‚‹ãŒã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¤§ããç•°ãªã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1611" target="_blank" rel="noopener noreferrer">Large Concept Models: Language Modeling in a Sentence Representation Space, Meta, 2024.12</a>
</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2926" target="_blank" rel="noopener noreferrer" class="title-link">Adaptive Localization of Knowledge Negation for Continual LLM Unlearning, Wuerkaixi+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å®‰å…¨æ€§ã«é–¢ã™ã‚‹æ‡¸å¿µãŒé«˜ã¾ã‚‹ä¸­ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆçŸ¥è­˜ã‚’åŠ¹æœçš„ã«å¿˜å´ã—ã¤ã¤åˆ©ç”¨ä¾¡å€¤ã‚’ç¶­æŒã™ã‚‹æ‰‹æ³•ALKNï¼ˆAdaptive Localization of Knowledge Negationï¼‰ã‚’ææ¡ˆã€‚å‹•çš„ãƒã‚¹ã‚­ãƒ³ã‚°ã‚’ç”¨ã„ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å‹¾é…ã‚’ã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–ã—ã€å¿˜å´ã®å¼·åº¦ã‚’é©å¿œçš„ã«èª¿æ•´ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ç¶™ç¶šçš„ãªå¿˜å´è¨­å®šã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹åŠ¹æœã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1969940279424885162?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2925" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid  Vision Tokenizer, Yanghao Li+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- Manzanoã¯ã€è¦–è¦šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç†è§£ã¨ç”Ÿæˆã‚’çµ±ä¸€çš„ã«è¡Œã†ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã§ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç”»åƒãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¬ã‚·ãƒ”ã‚’çµ„ã¿åˆã‚ã›ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è»½æ¸›ã—ã¾ã™ã€‚å˜ä¸€ã®ãƒ“ã‚¸ãƒ§ãƒ³ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãŒç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸ã®åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã—ã€è‡ªå·±å›å¸°å‹LLMãŒãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒãƒˆãƒ¼ã‚¯ãƒ³ã®é«˜ãƒ¬ãƒ™ãƒ«ã®æ„å‘³ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚ã“ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€ä¸¡æ–¹ã®èƒ½åŠ›ã®å…±åŒå­¦ç¿’ãŒå¯èƒ½ã¨ãªã‚Šã€æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1969974676802990478?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1969974517024923936?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>DocVQAã®ã‚ªãƒ©ã‚¯ãƒ«ã¯ãƒ©ãƒ™ãƒ«ãƒã‚¤ã‚ºã¨æ›–æ˜§æ€§ã®è¦³ç‚¹ã‹ã‚‰94--95ã¨ã„ã†ä¸»å¼µ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vikhyatk/status/1970585801600967009?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<a class="button" href="articles/ReversalCurse.html" target="_blank" rel="noopener noreferrer">#ReversalCurse</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2923" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Latent learning: episodic memory complements parametric learning by  enabling flexible reuse of experiences, Andrew Kyle Lampinen+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®ä¸€èˆ¬åŒ–å¤±æ•—ã®åŸå› ã¨ã—ã¦ã€æ½œåœ¨å­¦ç¿’ã®æ¬ å¦‚ã‚’æŒ‡æ‘˜ã€‚èªçŸ¥ç§‘å­¦ã®è¦–ç‚¹ã‹ã‚‰ã€ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ã‚„ã‚ªãƒ©ã‚¯ãƒ«ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒä¸€èˆ¬åŒ–ã‚’æ”¹å–„ã™ã‚‹æ‰‹æ®µã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚æ–‡è„ˆå†…å­¦ç¿’ãŒæƒ…å ±æ´»ç”¨ã®éµã§ã‚ã‚Šã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ«æ‰‹æ³•ãŒãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯å­¦ç¿’ã‚’è£œå®Œã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹å¯èƒ½æ€§ã‚’ææ¡ˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1969968869952631225?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<a class="button" href="articles/SpatialUnderstanding.html" target="_blank" rel="noopener noreferrer">#SpatialUnderstanding</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2921" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Perception Encoder: The best visual embeddings are not at the output of   the network, Daniel Bolya+, NeurIPS'25, 2025.04</a>
<span class="snippet"><span>GPT Summary</span>- Perception Encoderï¼ˆPEï¼‰ã¯ã€ç”»åƒã¨å‹•ç”»ç†è§£ã®ãŸã‚ã®æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã§ã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ“ã‚¸ãƒ§ãƒ³ã¨è¨€èªã®å­¦ç¿’ã‚’é€šã˜ã¦è¨“ç·´ã•ã‚Œã¦ã„ã¾ã™ã€‚å¾“æ¥ã®ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã«ä¾å­˜ã›ãšã€å¯¾ç…§çš„ãªãƒ“ã‚¸ãƒ§ãƒ³ã¨è¨€èªã®è¨“ç·´ã ã‘ã§å¼·åŠ›ãªåŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚åŸ‹ã‚è¾¼ã¿ã‚’å¼•ãå‡ºã™ãŸã‚ã«ã€è¨€èªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã¨ç©ºé–“ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã®2ã¤ã®æ‰‹æ³•ã‚’å°å…¥ã€‚PEãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆç”»åƒãƒ»å‹•ç”»åˆ†é¡ã§é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã€Q&amp;Aã‚¿ã‚¹ã‚¯ã‚„ç©ºé–“ã‚¿ã‚¹ã‚¯ã§ã‚‚æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/andreamadotto/status/1969529427064471619?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2918" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled   Refusal Training, Youliang Yuan+, ACL'25, 2024.07</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMsã®å®‰å…¨æ€§èª¿æ•´ã«ãŠã‘ã‚‹æ‹’å¦ãƒã‚¸ã‚·ãƒ§ãƒ³ãƒã‚¤ã‚¢ã‚¹ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ã€ŒDecoupled Refusal Trainingï¼ˆDeRTaï¼‰ã€ã¨ã„ã†æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚DeRTaã¯ã€æœ‰å®³ãªå¿œç­”ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’ç”¨ã„ãŸæœ€å¤§å°¤åº¦æ¨å®šã¨å¼·åŒ–ã•ã‚ŒãŸé·ç§»æœ€é©åŒ–ã‚’çµ„ã¿è¾¼ã¿ã€ãƒ¢ãƒ‡ãƒ«ãŒä¸é©åˆ‡ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’èªè­˜ã—æ‹’å¦ã™ã‚‹èƒ½åŠ›ã‚’å¼·åŒ–ã—ã¾ã™ã€‚å®Ÿè¨¼è©•ä¾¡ã§ã¯ã€ææ¡ˆæ‰‹æ³•ãŒå®‰å…¨æ€§ã‚’å‘ä¸Šã•ã›ã€æ”»æ’ƒã«å¯¾ã™ã‚‹é˜²å¾¡ã§ã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/youliang_yuan/status/1812665889852121332?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä¸€èˆ¬çš„ãªSafety Tuningã§ã¯æœ‰å®³ãªpromptãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«å®‰å…¨ãªå¿œç­”ãŒç”Ÿæˆã•ã‚Œã‚‹ç¢ºç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ï¼ˆMLE)ãŒã€å®‰å…¨ãªå¿œç­”ã¯å†’é ­ã®æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã«Sorry, I apologizeç­‰ã®å›ç­”ã‚’æ‹’çµ¶ã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ãŒé›†ä¸­ã™ã‚‹å‚¾å‘ã«ã‚ã‚Šã€å¿œç­”ã‚’æ‹’å¦ã™ã‚‹ã‹å¦ã‹ã«ãƒã‚¸ã‚·ãƒ§ãƒ³ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ã¦ã—ã¾ã†ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¿œç­”ã®é€”ä¸­ã§æ½œåœ¨çš„ãªå±é™ºæ€§ã‚’æ¤œçŸ¥ã—ã€å¿œç­”ã‚’æ‹’å¦ã™ã‚‹ã“ã¨ãŒã§ããªããªã£ã¦ã—ã¾ã†ã¨ã„ã†èª²é¡ŒãŒç”Ÿã˜ã‚‹ã€‚<br><br>ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€RTOã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚æœ‰å®³ãªpromptã®ä¸€éƒ¨ã‚’prefixã¨ã—ã€ãã®å¾Œã«Safetyãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’concatã™ã‚‹ã‚ˆã†ãªå¿œç­”ã‚’åˆæˆã—MLEã«æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€å¿œç­”ã®é€”ä¸­ã§ã‚‚å¿œç­”ã‚’æ‹’å¦ã™ã‚‹ã‚ˆã†ãªæŒ™å‹•ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚prefixã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€<br>- prefixã‚’ç”¨ã„ã‚‹ã“ã¨ã§å®‰å…¨ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«è¿½åŠ ã®contextã‚’ä»˜ä¸ã™ã‚‹ã“ã¨ãŒã§ãã€æ½œåœ¨çš„ãªå±é™ºæ€§ã®è­˜åˆ¥åŠ›ãŒé«˜ã¾ã‚Šã€<br>- prefixã®é•·ã•ã¯ä»»æ„ãªã®ã§ã€å¿œç­”ã®ã©ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã‹ã‚‰ã§ã‚‚å±é™ºæ€§è­˜åˆ¥ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã€<br>- ãƒ¢ãƒ‡ãƒ«ãŒæœ‰å®³ãªå¿œç­”ã‚’é–‹å§‹ã—ãŸã“ã¨ã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«èªè­˜ã—ã¦å®‰å…¨ãªå›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«é·ç§»ã•ã›ã‚‰ã‚Œã‚‹<br><br>ã¨ã„ã£ãŸåˆ©ç‚¹ãŒã‚ã‚‹ãŒã€1ã¤ã®å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«ã«ã¤ãä¸€ã¤ã®é·ç§»ï¼ˆi.e., prefixã¨å®‰å…¨ãªå¿œç­”ã®å¢ƒç›®ã¯1ã‚µãƒ³ãƒ—ãƒ«ã«ã¤ãä¸€ç®‡æ‰€ã—ã‹ãªã„ã®ã§ï¼‰ã—ã‹å­¦ç¿’ã§ããªã„ã“ã¨ã§ã‚ã‚‹ã€‚ã“ã®ãŸã‚ã€RTOã§ã¯ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å…¨ã¦ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦sorryãŒç”Ÿæˆã•ã‚Œã‚‹ç¢ºç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ãŒå…¨ã¦ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã§ç¶™ç¶šçš„ã«å±é™ºæ€§ã‚’è­˜åˆ¥ã§ãã‚‹èƒ½åŠ›ã‚’é«˜ã‚ã‚‹ã‚ˆã†ãªå·¥å¤«ã‚’ã™ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/1e35903a-b886-4475-8b58-76e057c26d03" alt="image" loading="lazy"><br><br>ç›®çš„é–¢æ•°ã¯ä»¥ä¸‹ã§ã€Harmful PrefixãŒgivenãªæ™‚ã«å®‰å…¨ãªå›ç­”ãŒç”Ÿæˆã•ã‚Œã‚‹ç¢ºç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹MLEã®é …ã«å¯¾ã—ã¦ï¼ˆr^hat_&lt;kã¯ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã•ã‚Œã‚‹[0,å›ç­”ã®é•·ã•]ã®å®šæ•°ï¼‰ã€å…¨ã¦ã®ä½ç½®tä»¥å¾Œã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦sorryã®ç”Ÿæˆç¢ºç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ï¼ˆtã¯å…¨ã¦ã®å¯èƒ½ãªãƒã‚¸ã‚·ãƒ§ãƒ³ã«å¯¾ã—ã¦å¤‰åŒ–ã•ã›ã¦summationã™ã‚‹ï¼‰ã‚ˆã†ãªé …ã‚’è¿½åŠ ï¼ˆï¼RTOï¼‰ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/d7416ef5-6587-46b4-8255-1e9884242a72" alt="image" loading="lazy"><br><br>å®Ÿé¨“ã®çµæœã¯ã€å…¨ä½“ã‚’è¦‹ã‚‹é™ã‚Šã€helpfulnessã‚’æãªã†ã“ã¨ãªãã€å®‰å…¨ãªå¿œç­”ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ãŠã‚Šã€DPOç­‰ã®ãã®ä»–ã®Alignmentæ‰‹æ³•ã‚ˆã‚Šã‚‚æ€§èƒ½ãŒè‰¯ã•ãã†ã§ã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/3fdec4a2-5b9e-4f4b-985a-edf885fde72a" alt="image" loading="lazy"></p>
<p>ä»¥ä¸‹ã®ç ”ç©¶ã§å ±å‘Šã•ã‚Œã¦ã„ã‚‹ç¾è±¡ã¨ä¼¼ã¦ã„ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1813" target="_blank" rel="noopener noreferrer">The First Few Tokens Are All You Need: An Efficient and Effective
  Unsupervised Prefix Fine-Tuning Method for Reasoning Models, Ke Ji+, arXiv'25</a>
<br><br>ã™ãªã‚ã¡ã€reasoning traceã®æœ€åˆã®æ•°ãƒˆãƒ¼ã‚¯ãƒ³ãŒå…¨ä½“ã®å“è³ªã«å¤§ããé–¢ã‚ã‚‹ã¨ã„ã†è©±</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Financial.html" target="_blank" rel="noopener noreferrer">#Financial</a>
<span class="issue_date">Issue Date: 2025-09-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2916" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FinSearchComp: Towards a Realistic, Expert-Level Evaluation of Financial  Search and Reasoning, Liang Hu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- FinSearchCompã¯ã€é‡‘èæ¤œç´¢ã¨æ¨è«–ã®ãŸã‚ã®åˆã®å®Œå…¨ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚Šã€æ™‚é–“ã«æ•æ„Ÿãªãƒ‡ãƒ¼ã‚¿å–å¾—ã‚„è¤‡é›‘ãªæ­´å²çš„èª¿æŸ»ã‚’å«ã‚€3ã¤ã®ã‚¿ã‚¹ã‚¯ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚70äººã®é‡‘èå°‚é–€å®¶ã«ã‚ˆã‚‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¨å³æ ¼ãªå“è³ªä¿è¨¼ã‚’çµŒã¦ã€635ã®è³ªå•ãŒç”¨æ„ã•ã‚Œã€21ã®ãƒ¢ãƒ‡ãƒ«ãŒè©•ä¾¡ã•ã‚Œã¾ã—ãŸã€‚Grok 4ã¨DouBaoãŒãã‚Œãã‚Œã‚°ãƒ­ãƒ¼ãƒãƒ«ãŠã‚ˆã³å¤§ä¸­è¯åœã§ãƒˆãƒƒãƒ—ã®ç²¾åº¦ã‚’ç¤ºã—ã€ã‚¦ã‚§ãƒ–æ¤œç´¢ã¨é‡‘èãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®æ´»ç”¨ãŒçµæœã‚’æ”¹å–„ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚FinSearchCompã¯ã€ç¾å®Ÿã®ã‚¢ãƒŠãƒªã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã«åŸºã¥ãé«˜é›£æ˜“åº¦ã®ãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1969433151249244528?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Emotion.html" target="_blank" rel="noopener noreferrer">#Emotion</a>
<span class="issue_date">Issue Date: 2025-09-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2915" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LongEmotion: Measuring Emotional Intelligence of Large Language Models  in Long-Context Interaction, Weichu Liu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- é•·æ–‡ã®æ„Ÿæƒ…çŸ¥èƒ½ï¼ˆEIï¼‰ã‚¿ã‚¹ã‚¯å°‚ç”¨ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒLongEmotionã€ã‚’ææ¡ˆã€‚æ„Ÿæƒ…åˆ†é¡ã‚„æ„Ÿæƒ…ä¼šè©±ãªã©å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã‚’ã‚«ãƒãƒ¼ã—ã€å¹³å‡å…¥åŠ›é•·ã¯8,777ãƒˆãƒ¼ã‚¯ãƒ³ã€‚Retrieval-Augmented Generationï¼ˆRAGï¼‰ã¨Collaborative Emotional Modelingï¼ˆCoEMï¼‰ã‚’çµ„ã¿è¾¼ã¿ã€å¾“æ¥ã®æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦EIãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã€‚å®Ÿé¨“çµæœã¯ã€RAGã¨CoEMãŒé•·æ–‡ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ä¸€è²«ã—ã¦åŠ¹æœã‚’ç¤ºã—ã€LLMsã®å®Ÿç”¨æ€§ã‚’é«˜ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://longemotion.github.io" target="_blank" rel="noopener noreferrer">https://longemotion.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1969373139189539164?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<span class="issue_date">Issue Date: 2025-09-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2914" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generalizing Verifiable Instruction Following, Valentina Pyatkin+, NeurIPS'25, 2025.07</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“ã¨AIã®ç›¸äº’ä½œç”¨ã«ãŠã„ã¦ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒæŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ãŒé‡è¦ã§ã‚ã‚‹ãŒã€ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯å‡ºåŠ›åˆ¶ç´„ã‚’æº€ãŸã™ã®ã«è‹¦åŠ´ã—ã¦ã„ã‚‹ã€‚å¤šãã®ãƒ¢ãƒ‡ãƒ«ã¯æ—¢å­˜ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«éå‰°é©åˆã—ã¦ãŠã‚Šã€æœªè¦‹ã®åˆ¶ç´„ã«å¯¾ã—ã¦ä¸€èˆ¬åŒ–ã§ããªã„ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯IFBenchã‚’å°å…¥ã—ã€æŒ‡ç¤ºéµå®ˆã®ä¸€èˆ¬åŒ–ã‚’è©•ä¾¡ã™ã‚‹ã€‚ã•ã‚‰ã«ã€åˆ¶ç´„æ¤œè¨¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨å¼·åŒ–å­¦ç¿’ï¼ˆRLVRï¼‰ã‚’ç”¨ã„ã¦æŒ‡ç¤ºéµå®ˆã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã€é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚„è¨“ç·´ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¬é–‹ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/valentina__py/status/1969294455938138243?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Instruction Followingã®ãŸã‚ã®æ–°ãŸãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯IFBenchï¼ˆå¤šæ§˜ï¼ˆ58ç¨®é¡ã®åˆ¶ç´„ï¼‰ã§ç²¾ç·»ã€ã‹ã¤è¤‡æ•°ã®å‡ºåŠ›ã«é–¢ã™ã‚‹åˆ¶ç´„ã‚’æŒã¤ã€‚Appendix Aã‚’å‚ç…§ã®ã“ã¨)ã‚’å°å…¥ã—ã€RLVRã«ã‚ˆã£ã¦Instruction tuningã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚è¤‡æ•°ã®IFã®åˆ¶ç´„ã‚’åŒæ™‚ã«å­¦ç¿’ã—ãŸæ–¹ãŒOODã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆã«ãªã‚‹ã“ã¨ã‚„ã€åˆ¶ç´„ã”ã¨ã®instanceæ•°ã«å¯¾ã™ã‚‹æ€§èƒ½ã®å¤‰åŒ–ã€ã¾ãŸSFT, DPOã«ã‚ˆã£ã¦Instrtction Tuningã‚’å®Ÿæ–½ã—ãŸãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€åˆ¶ç´„ã‚’æº€ãŸã—ãŸã‹å¦ã‹ã®Verifiableãªãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç”Ÿæˆã—ãŸå—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦è¿½åŠ ã®DPOã‚’å®Ÿæ–½ã—ãŸå ´åˆã¨ã€RLVRã«åŸºã¥ãGRPOã‚’å®Ÿæ–½ã—ãŸå ´åˆã®ã©ã¡ã‚‰ã®æ€§èƒ½ãŒè‰¯ã„ã‹ãªã©ã‚‚å®Ÿé¨“ã•ã‚Œã¦ã„ã‚‹ï¼ˆä¸€è²«ã—ã¦GRPOãŒè‰¯ã„ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Ensemble.html" target="_blank" rel="noopener noreferrer">#Ensemble</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2912" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Pre-training under infinite compute, Konwoo Kim+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è¨ˆç®—èƒ½åŠ›ã®å¢—åŠ ã«å¯¾ã—ã€å›ºå®šãƒ‡ãƒ¼ã‚¿ã§ã®äº‹å‰å­¦ç¿’ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’è€ƒå¯Ÿã€‚ã‚¨ãƒãƒƒã‚¯æ•°ã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å¢—åŠ ã¯éå­¦ç¿’ã‚’å¼•ãèµ·ã“ã™ãŒã€æ­£å‰‡åŒ–ã‚’é©åˆ‡ã«èª¿æ•´ã™ã‚‹ã“ã¨ã§æ”¹å–„å¯èƒ½ã€‚æœ€é©ãªé‡ã¿æ¸›è¡°ã¯æ¨™æº–ã®30å€ã§ã€æ­£å‰‡åŒ–æ‰‹æ³•ã¯æå¤±ã‚’å˜èª¿ã«æ¸›å°‘ã•ã›ã‚‹ã€‚ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã¯æ­£å‰‡åŒ–æ‰‹æ³•ã‚ˆã‚Šã‚‚ä½ã„æå¤±ã‚’é”æˆã—ã€ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨é‡ã‚’5.17å€å‰Šæ¸›ã€‚å­¦ç”Ÿãƒ¢ãƒ‡ãƒ«ã¸ã®è’¸ç•™ã«ã‚ˆã‚Šã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã€ä¸‹æµãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®æ”¹å–„ã‚‚ç¢ºèªã€‚çµæœã¯ã€è¨ˆç®—ãƒªãƒƒãƒãªæœªæ¥ã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã®è‰¯ã„äº‹å‰å­¦ç¿’ã®å¯èƒ½æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/percyliang/status/1969101519531491712?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1969887073017708822?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2905" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Length Representations in Large Language Models, Sangjun Moon+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯å‡ºåŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é•·ã•ã‚’åˆ¶å¾¡ã™ã‚‹èƒ½åŠ›ã‚’æŒã¡ã€ãã®å†…éƒ¨ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æ¢æ±‚ã€‚ç‰¹ã«ã€ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãŒå‡ºåŠ›é•·ã®æ±ºå®šã«é‡è¦ã§ã‚ã‚Šã€ç‰¹å®šã®éš ã‚Œãƒ¦ãƒ‹ãƒƒãƒˆã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§é•·ã•ã‚’åˆ¶å¾¡å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé•·ã•ç‰¹æœ‰ã«ãªã‚‹ã¨éš ã‚Œãƒ¦ãƒ‹ãƒƒãƒˆãŒæ´»æ€§åŒ–ã—ã€ãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨èªè­˜ã‚’åæ˜ ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã¯å¤–éƒ¨åˆ¶å¾¡ãªã—ã«å‡ºåŠ›ã®é•·ã•ã‚’é©å¿œçš„ã«åˆ¶å¾¡ã™ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å­¦ç¿’ã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Biological.html" target="_blank" rel="noopener noreferrer">#Biological</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2901" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BioReason: Incentivizing Multimodal Biological Reasoning within a   DNA-LLM Model, Adibvafa Fallahpour+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- BioReasonã¯ã€DNAåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã¨å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã‚’çµ±åˆã—ãŸæ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã€è¤‡é›‘ãªã‚²ãƒãƒ ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®ç”Ÿç‰©å­¦çš„æ¨è«–ã‚’æ·±ãè§£é‡ˆå¯èƒ½ã«ã™ã‚‹ã€‚å¤šæ®µéšæ¨è«–ã‚’é€šã˜ã¦ã€ç²¾åº¦ãŒ88%ã‹ã‚‰97%ã«å‘ä¸Šã—ã€ãƒãƒªã‚¢ãƒ³ãƒˆåŠ¹æœäºˆæ¸¬ã§ã‚‚å¹³å‡15%ã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã€‚æœªè¦‹ã®ç”Ÿç‰©å­¦çš„ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«å¯¾ã™ã‚‹æ¨è«–ã‚’è¡Œã„ã€è§£é‡ˆå¯èƒ½ãªæ„æ€æ±ºå®šã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã§ã€AIã«ãŠã‘ã‚‹ç”Ÿç‰©å­¦ã®é€²å±•ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/collections/wanglab/bioreason-683cd17172a037a31d208f70" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/wanglab/bioreason-683cd17172a037a31d208f70</a>


<br>pj page:


<a href="https://bowang-lab.github.io/BioReason/" target="_blank" rel="noopener noreferrer">https://bowang-lab.github.io/BioReason/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bowang87/status/1969174399564857543?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2900" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FlowRL: Matching Reward Distributions for LLM Reasoning, Xuekai Zhu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- FlowRLã¯ã€LLMå¼·åŒ–å­¦ç¿’ã«ãŠã„ã¦å ±é…¬ã‚’æœ€å¤§åŒ–ã™ã‚‹ã®ã§ã¯ãªãã€ãƒ•ãƒ­ãƒ¼ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ã‚’é€šã˜ã¦å ±é…¬åˆ†å¸ƒã‚’ä¸€è‡´ã•ã›ã‚‹æ‰‹æ³•ã§ã™ã€‚å¾“æ¥ã®å ±é…¬æœ€å¤§åŒ–æ‰‹æ³•ã¯å¤šæ§˜æ€§ã‚’æ¸›å°‘ã•ã›ã‚‹å‚¾å‘ãŒã‚ã‚‹ãŸã‚ã€FlowRLã§ã¯å­¦ç¿’å¯èƒ½ãªåˆ†å‰²é–¢æ•°ã‚’ç”¨ã„ã¦ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒã«å¤‰æ›ã—ã€ãƒãƒªã‚·ãƒ¼ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒã®é€†KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚’æœ€å°åŒ–ã—ã¾ã™ã€‚å®Ÿé¨“ã®çµæœã€FlowRLã¯æ•°å­¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§GRPOã«å¯¾ã—ã¦å¹³å‡10.0%ã€PPOã«å¯¾ã—ã¦5.1%ã®æ”¹å–„ã‚’é”æˆã—ã€ã‚³ãƒ¼ãƒ‰æ¨è«–ã‚¿ã‚¹ã‚¯ã§ã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚å ±é…¬åˆ†å¸ƒã®ä¸€è‡´ãŒåŠ¹ç‡çš„ãªæ¢ç´¢ã¨å¤šæ§˜ãªæ¨è«–ã«é‡è¦ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1968876133656436811?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å ±é…¬ã‚’æœ€å¤§åŒ–ã™ã‚‹ã®ã§ã¯ãªãã€å ±é…¬åˆ†å¸ƒã‚’ä¸€è‡´ã•ã›ã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ã‚‰ã—ã„</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1969324905121345687?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2899" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Illusion of Thinking: Understanding the Strengths and Limitations of  Reasoning Models via the Lens of Problem Complexity, Parshin Shojaee+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LRMsã¯æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ãŒã€ãã®èƒ½åŠ›ã‚„é™ç•Œã¯æœªè§£æ˜ã€‚è©•ä¾¡ã¯ä¸»ã«æœ€çµ‚å›ç­”ã®æ­£ç¢ºæ€§ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€æ¨è«–ã®ç—•è·¡ã‚’æä¾›ã—ãªã„ã€‚æœ¬ç ”ç©¶ã§ã¯åˆ¶å¾¡å¯èƒ½ãªãƒ‘ã‚ºãƒ«ç’°å¢ƒã‚’ç”¨ã„ã¦ã€LRMsã®æ¨è«–éç¨‹ã‚’åˆ†æã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€LRMsã¯ç‰¹å®šã®è¤‡é›‘ã•ã‚’è¶…ãˆã‚‹ã¨æ­£ç¢ºæ€§ãŒå´©å£Šã—ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®é™ç•ŒãŒæ˜ã‚‰ã‹ã«ã€‚ä½è¤‡é›‘æ€§ã§ã¯æ¨™æº–ãƒ¢ãƒ‡ãƒ«ãŒå„ªä½ã€ä¸­è¤‡é›‘æ€§ã§ã¯LRMsãŒå„ªä½ã€é«˜è¤‡é›‘æ€§ã§ã¯ä¸¡è€…ãŒå´©å£Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚æ¨è«–ã®ç—•è·¡ã‚’èª¿æŸ»ã—ã€LRMsã®å¼·ã¿ã¨é™ç•Œã‚’æ˜ã‚‰ã‹ã«ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/parshinshojaee/status/1968812151138918541?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å‡ºãŸå½“åˆç›¸å½“è©±é¡Œã«ãªã£ãŸIllusion of thinkingãŒNeurIPSã«acceptã•ã‚ŒãŸæ¨¡æ§˜ã€‚Appendix A.1ã«å½“æ™‚ã®criticismã«å¯¾ã™ã‚‹ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2898" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BREAD: Branched Rollouts from Expert Anchors Bridge SFT &amp; RL for   Reasoning, Xuechen Zhang+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- å°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆSLMsï¼‰ã¯ã€ãƒˆãƒ¬ãƒ¼ã‚¹ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã«è¤‡é›‘ãªæ¨è«–ã‚’å­¦ã¶ã®ãŒé›£ã—ã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€SFT + RLã®é™ç•Œã‚’èª¿æŸ»ã—ã€BREADã¨ã„ã†æ–°ã—ã„æ‰‹æ³•ã‚’ææ¡ˆã€‚BREADã¯ã€å°‚é–€å®¶ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’ç”¨ã„ã¦SFTã¨RLã‚’çµ±åˆã—ã€å¤±æ•—ã—ãŸãƒˆãƒ¬ãƒ¼ã‚¹ã«å¯¾ã—ã¦çŸ­ã„ãƒ’ãƒ³ãƒˆã‚’æŒ¿å…¥ã™ã‚‹ã“ã¨ã§æˆåŠŸã‚’ä¿ƒé€²ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒç´„3å€é€Ÿããªã‚Šã€æ¨™æº–çš„ãªGRPOã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚BREADã¯ã€SLMã®æ¨è«–èƒ½åŠ›ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sametoymac/status/1968892463382200391?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2897" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Trust, But Verify: A Self-Verification Approach to Reinforcement   Learning with Verifiable Rewards, Xiaoyuan Liu+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- RISEã¨ã„ã†æ–°ã—ã„ã‚ªãƒ³ãƒ©ã‚¤ãƒ³RLãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€LLMã®å•é¡Œè§£æ±ºèƒ½åŠ›ã¨è‡ªå·±æ¤œè¨¼èƒ½åŠ›ã‚’åŒæ™‚ã«å‘ä¸Šã•ã›ã‚‹ã€‚çµæœæ¤œè¨¼è€…ã‹ã‚‰ã®å ±é…¬ã‚’æ´»ç”¨ã—ã€è§£æ±ºç­–ç”Ÿæˆã¨è‡ªå·±æ¤œè¨¼ã«å³æ™‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€RISEã¯å•é¡Œè§£æ±ºç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€è‡ªå·±æ¤œè¨¼ã‚¹ã‚­ãƒ«ã‚’è‚²æˆã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚RISEã¯å …ç‰¢ã§è‡ªå·±èªè­˜ã®ã‚ã‚‹æ¨è«–è€…ã‚’è‚²æˆã™ã‚‹ãŸã‚ã®åŠ¹æœçš„ãªæ‰‹æ³•ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tuzhaopeng/status/1968673346834330043?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Self-Verificationã®èƒ½åŠ›ãŒå¤§å¹…ã«å‘ä¸Šã™ã‚‹ã®ã¯è‰¯ã•ãã†ã€‚</p></span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2896" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MergeBench: A Benchmark for Merging Domain-Specialized LLMs, Yifei He+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ³ã‚°ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŠ¹ç‡çš„ãªãƒ‡ãƒ—ãƒ­ã‚¤ã‚’å¯èƒ½ã«ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ³ã‚°ã‚’å¤§è¦æ¨¡ã«è©•ä¾¡ã™ã‚‹ãŸã‚ã®è©•ä¾¡ã‚¹ã‚¤ãƒ¼ãƒˆã€ŒMergeBenchã€ã‚’å°å…¥ã—ã€æŒ‡ç¤ºéµå®ˆã‚„æ•°å­¦ã€å¤šè¨€èªç†è§£ãªã©5ã¤ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ã‚«ãƒãƒ¼ã—ã¾ã™ã€‚8ã¤ã®ãƒãƒ¼ã‚¸ãƒ³ã‚°æ‰‹æ³•ã‚’è©•ä¾¡ã—ã€ã‚ˆã‚Šå¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒã‚ˆã‚Šè‰¯ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã™ã‚‹å‚¾å‘ã‚’ç¤ºã—ã¾ã—ãŸãŒã€å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®è¨ˆç®—ã‚³ã‚¹ãƒˆã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³å†…ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ã‚®ãƒ£ãƒƒãƒ—ãªã©ã®èª²é¡Œã‚‚æ®‹ã£ã¦ã„ã¾ã™ã€‚MergeBenchã¯ä»Šå¾Œã®ç ”ç©¶ã®åŸºç›¤ã¨ãªã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://yifei-he.github.io/mergebench/" target="_blank" rel="noopener noreferrer">https://yifei-he.github.io/mergebench/</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2895" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Leaderboard Illusion, Shivalika Singh+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- é€²æ—æ¸¬å®šã¯ç§‘å­¦ã®é€²å±•ã«ä¸å¯æ¬ ã§ã‚ã‚Šã€Chatbot Arenaã¯AIã‚·ã‚¹ãƒ†ãƒ ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«ãŠã„ã¦é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€éå…¬é–‹ã®ãƒ†ã‚¹ãƒˆæ…£è¡ŒãŒå­˜åœ¨ã—ã€ç‰¹å®šã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒæœ‰åˆ©ã«ãªã‚‹ã“ã¨ã§ã€ã‚¹ã‚³ã‚¢ã«ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚ç‰¹ã«ã€Metaã®Llama-4ã«é–¢é€£ã™ã‚‹ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆLLMãƒãƒªã‚¢ãƒ³ãƒˆãŒå•é¡Œè¦–ã•ã‚Œã€ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ã®éå¯¾ç§°æ€§ãŒç”Ÿã˜ã¦ã„ã‚‹ã€‚Googleã‚„OpenAIã¯Arenaãƒ‡ãƒ¼ã‚¿ã®å¤§éƒ¨åˆ†ã‚’å ã‚ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆãƒ¢ãƒ‡ãƒ«ã¯å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã—ã‹å—ã‘å–ã£ã¦ã„ãªã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Arenaç‰¹æœ‰ã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã¸ã®éå‰°é©åˆãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã€‚ç ”ç©¶ã¯ã€Chatbot Arenaã®è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®æ”¹é©ã¨ã€å…¬æ­£ã§é€æ˜æ€§ã®ã‚ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°ã®ä¿ƒé€²ã«å‘ã‘ãŸæè¨€ã‚’è¡Œã£ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/singhshiviii/status/1968756900062753080?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è¦ãƒã‚§ãƒƒã‚¯</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/Inpainting.html" target="_blank" rel="noopener noreferrer">#Inpainting</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2894" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Inpainting-Guided Policy Optimization for Diffusion Large Language  Models, Siyan Zhao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- dLLMsã¯ã‚¤ãƒ³ãƒšã‚¤ãƒ³ãƒ†ã‚£ãƒ³ã‚°èƒ½åŠ›ã‚’æ´»ç”¨ã—ã€å¼·åŒ–å­¦ç¿’ã®æ¢ç´¢èª²é¡Œã‚’è§£æ±ºã™ã‚‹IGPOãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚éƒ¨åˆ†çš„ãªçœŸå®Ÿã®æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’æŒ¿å…¥ã—ã€æ¢ç´¢ã‚’æœ‰æœ›ãªè»Œé“ã«å°ãã€‚ã“ã‚Œã«ã‚ˆã‚Šã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ãŒå‘ä¸Šã—ã€GSM8Kã€Math500ã€AMCã®æ•°å­¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ–°ãŸãªæœ€å…ˆç«¯çµæœã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1968875179934892175?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>éƒ¨åˆ†çš„ã«traceã®æ­£è§£ã‚’ä¸ãˆã‚‹ã¨ã€æ­£è§£ã®æ–¹å‘ã«ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã‚‹ã®ã§å¤šæ§˜æ€§ãŒçŠ ç‰²ã«ãªã‚‹æ°—ã‚‚ã™ã‚‹ãŒã€ãã®è¾ºã¯ã©ã†ãªã‚“ã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Bias.html" target="_blank" rel="noopener noreferrer">#Bias</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/PseudoLabeling.html" target="_blank" rel="noopener noreferrer">#PseudoLabeling</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2892" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self Iterative Label Refinement via Robust Unlabeled Learning, Hikaru Asano+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±æ´—ç·´æ‰‹æ³•ã‚’ç”¨ã„ã¦ã€LLMã®æ“¬ä¼¼ãƒ©ãƒ™ãƒ«ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®åå¾©æ´—ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ææ¡ˆã€‚ãƒ©ãƒ™ãƒ«ãªã—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ´»ç”¨ã—ã€å†…éƒ¨ãƒã‚¤ã‚¢ã‚¹ã‚’è»½æ¸›ã—ã¤ã¤ã€åˆ†é¡ã‚¿ã‚¹ã‚¯ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã€‚å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡ã—ã€æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yukino/status/1968863204517302511?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£ç ”ç©¶(Pseudo Labeling):<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2902" target="_blank" rel="noopener noreferrer">[Paper Note] Training a Helpful and Harmless Assistant with Reinforcement Learning
  from Human Feedback, Yuntao Bai+, arXiv'22</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2890" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OS-Harm: A Benchmark for Measuring Safety of Computer Use Agents, Thomas Kuntz+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ä½¿ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®‰å…¨æ€§ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯OS-Harmã‚’å°å…¥ã€‚OS-Harmã¯ã€æ„å›³çš„ãªèª¤ç”¨ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³æ”»æ’ƒã€ä¸é©åˆ‡ãªè¡Œå‹•ã®3ã¤ã®å±å®³ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹150ã®ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ã€‚è‡ªå‹•ã‚¸ãƒ£ãƒƒã‚¸ã‚’ç”¨ã„ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ­£ç¢ºæ€§ã¨å®‰å…¨æ€§ã‚’è©•ä¾¡ã—ã€é«˜ã„ä¸€è‡´ç‡ã‚’é”æˆã€‚æœ€å‰ç·šãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã‹ã‚‰ã€æ„å›³çš„ãªèª¤ç”¨ã«å¾“ã†å‚¾å‘ã‚„è„†å¼±æ€§ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚OS-Harmã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®‰å…¨æ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/maksym_andr/status/1968731692547346549?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2886" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Evolving Language Models without Labels: Majority Drives Selection,  Novelty Promotes Variation, Yujun Zhou+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- EVOL-RLã¯ã€ãƒ©ãƒ™ãƒ«ãªã—ã®å¼·åŒ–å­¦ç¿’æ‰‹æ³•ã§ã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®æ¢ç´¢èƒ½åŠ›ã¨ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’ç¶­æŒã—ã¤ã¤ã€å®‰å®šæ€§ã¨å¤‰å‹•ã‚’çµã³ã¤ã‘ã‚‹ã€‚å¤šæ•°æ±ºã§é¸ã°ã‚ŒãŸå›ç­”ã‚’å®‰å®šã—ãŸã‚¢ãƒ³ã‚«ãƒ¼ã¨ã—ã¦ä¿æŒã—ã€æ–°è¦æ€§ã‚’æ„è­˜ã—ãŸå ±é…¬ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ç”Ÿæˆç‰©ã®å¤šæ§˜æ€§ã‚’ä¿ã¡ã€æ€è€ƒã®é€£é–ã‚’æ”¹å–„ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€EVOL-RLã¯TTRLãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€ç‰¹ã«ãƒ©ãƒ™ãƒ«ãªã—ã®AIME24ã§ã®è¨“ç·´ã«ãŠã„ã¦é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wyu_nd/status/1968851567953485828?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1968931244877439435?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2677" target="_blank" rel="noopener noreferrer">[Paper Note] Jointly Reinforcing Diversity and Quality in Language Model Generations, Tianjian Li+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2863" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LMFusion: Adapting Pretrained Language Models for Multimodal Generation, Weijia Shi+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- LMFusionã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®LLMã«ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç”Ÿæˆèƒ½åŠ›ã‚’ä»˜ä¸ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã®ç†è§£ãƒ»ç”Ÿæˆã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚æ—¢å­˜ã®Llama-3ã®é‡ã¿ã‚’æ´»ç”¨ã—ã€ç”»åƒå‡¦ç†ã®ãŸã‚ã®ä¸¦åˆ—ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¿½åŠ ã€‚å„ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã¯ç‹¬ç«‹ã—ã¦å‡¦ç†ã•ã‚Œã€ç›¸äº’ä½œç”¨ãŒå¯èƒ½ã§ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€LMFusionã¯ç”»åƒç†è§£ã‚’20%ã€ç”Ÿæˆã‚’3.6%å‘ä¸Šã•ã›ã€Llama-3ã®è¨€èªèƒ½åŠ›ã‚’ç¶­æŒã—ã¤ã¤ã€åŠ¹ç‡çš„ã«ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/weijiashi2/status/1870107645677568248?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ˆè¡Œç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2930" target="_blank" rel="noopener noreferrer">[Paper Note] Transfusion: Predict the Next Token and Diffuse Images with One   Multi-Modal Model, Chunting Zhou+, ICLR'25, 2024.08</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2931" target="_blank" rel="noopener noreferrer">[Paper Note] U-Net: Convolutional Networks for Biomedical Image Segmentation, Olaf Ronneberger+, MICCAI'15, 2015.05</a>
</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2855" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebSailor: Navigating Super-human Reasoning for Web Agent, Kuan Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- WebSailorã¯ã€LLMã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦äººé–“ã®èªçŸ¥çš„é™ç•Œã‚’è¶…ãˆã‚‹ãŸã‚ã®ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã§ã‚ã‚Šã€è¤‡é›‘ãªæƒ…å ±æ¢ç´¢ã‚¿ã‚¹ã‚¯ã§ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚æ§‹é€ åŒ–ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚„æƒ…å ±ã®é›£èª­åŒ–ã€DUPOã‚’ç”¨ã„ã¦é«˜ä¸ç¢ºå®Ÿæ€§ã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆã—ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2854" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebDancer: Towards Autonomous Information Seeking Agency, Jialong Wu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è¤‡é›‘ãªå•é¡Œè§£æ±ºã®ãŸã‚ã«ã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®æƒ…å ±æ¢ç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ä¸€è²«ã—ãŸãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ææ¡ˆã€‚4ã¤ã®ä¸»è¦ã‚¹ãƒ†ãƒ¼ã‚¸ï¼ˆãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰ã€è»Œè·¡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€å¼·åŒ–å­¦ç¿’ï¼‰ã‚’çµŒã¦ã€WebDancerã‚’å®Ÿè£…ã€‚GAIAã¨WebWalkerQAã§ã®è©•ä¾¡ã«ã‚ˆã‚Šã€å¼·åŠ›ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã®æœ‰åŠ¹æ€§ã‚’ç¢ºèªã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹äºˆå®šã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2853" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language  Models in Chinese, Peilin Zhou+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- BrowseComp-ZHã¯ã€ä¸­å›½ã®ã‚¦ã‚§ãƒ–ä¸Šã§LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸé«˜é›£æ˜“åº¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€289ã®ãƒãƒ«ãƒãƒ›ãƒƒãƒ—è³ªå•ã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹ã€‚äºŒæ®µéšã®å“è³ªç®¡ç†ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’é©ç”¨ã—ã€20ä»¥ä¸Šã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ãŸçµæœã€ã»ã¨ã‚“ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒ10%æœªæº€ã®ç²¾åº¦ã§è‹¦æˆ¦ã—ã€æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚42.9%ã«ã¨ã©ã¾ã£ãŸã€‚ã“ã®çµæœã¯ã€åŠ¹æœçš„ãªæƒ…å ±å–å¾—æˆ¦ç•¥ã¨æ´—ç·´ã•ã‚ŒãŸæ¨è«–èƒ½åŠ›ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2451" target="_blank" rel="noopener noreferrer">[Paper Note] BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents, Jason Wei+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2852" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented   Generation, Satyapriya Krishna+, NAACL'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ€§èƒ½å‘ä¸Šã‚’æ´»ã‹ã—ã€æƒ…å ±æ¤œç´¢å¼·åŒ–ç”Ÿæˆï¼ˆRAGï¼‰æ©Ÿèƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆFRAMESã‚’ææ¡ˆã€‚FRAMESã¯ã€äº‹å®Ÿã«åŸºã¥ã„ãŸå¿œç­”ã€æ¤œç´¢èƒ½åŠ›ã€æ¨è«–ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®çµ±ä¸€ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã—ã€è¤‡æ•°ã®æƒ…å ±æºã‚’çµ±åˆã™ã‚‹ãƒãƒ«ãƒãƒ›ãƒƒãƒ—è³ªå•ã§æ§‹æˆã€‚æœ€å…ˆç«¯ã®LLMã§ã‚‚0.40ã®ç²¾åº¦ã«ç•™ã¾ã‚‹ä¸­ã€ææ¡ˆã™ã‚‹ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—æ¤œç´¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ã‚ˆã‚Šç²¾åº¦ãŒ0.66ã«å‘ä¸Šã—ã€RAGã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2851" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebWalker: Benchmarking LLMs in Web Traversal, Jialong Wu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- WebWalkerQAã‚’å°å…¥ã—ã€LLMãŒã‚¦ã‚§ãƒ–ã®ã‚µãƒ–ãƒšãƒ¼ã‚¸ã‹ã‚‰é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹èƒ½åŠ›ã‚’è©•ä¾¡ã€‚æ¢æŸ»-æ‰¹è©•ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ç”¨ã„ãŸãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯WebWalkerã‚’ææ¡ˆã—ã€å®Ÿé¨“ã«ã‚ˆã‚ŠRAGã®åŠ¹æœã‚’å®Ÿè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>web pageã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¾¿ã‚‰ãªã„ã¨å›ç­”ã§ããªã„QAã§æ§‹æˆã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br><img src="https://github.com/user-attachments/assets/ca40f887-18ad-469e-83c8-1cbf3eb86e39" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2850" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] VisionZip: Longer is Better but Not Necessary in Vision Language Models, Senqiao Yang+, CVPR'25</a>
<span class="snippet"><span>GPT Summary</span>- VisionZipã¯ã€è¦–è¦šãƒˆãƒ¼ã‚¯ãƒ³ã®å†—é•·æ€§ã‚’å‰Šæ¸›ã—ã€åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æ–°ã—ã„æ‰‹æ³•ã§ã‚ã‚Šã€ç”»åƒã‚„å‹•ç”»ã®ç†è§£ã‚¿ã‚¹ã‚¯ã«é©ç”¨å¯èƒ½ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€å¾“æ¥ã®æ‰‹æ³•ã‚ˆã‚Šã‚‚5%ä»¥ä¸Šã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã—ã€æ¨è«–é€Ÿåº¦ã‚‚å¤§å¹…ã«æ”¹å–„ã€‚ãƒˆãƒ¼ã‚¯ãƒ³ã®é•·ã•ã‚’å¢—ã‚„ã™ã®ã§ã¯ãªãã€ã‚ˆã‚Šè‰¯ã„è¦–è¦šç‰¹å¾´ã®æŠ½å‡ºã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã“ã¨ã‚’ææ¡ˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dl_hacks/status/1968528535041229209?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2847" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Shared Imagination: LLMs Hallucinate Alike, Yilun Zhou+, TMLR'25, 2025.08</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®é¡ä¼¼æ€§ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€æƒ³åƒä¸Šã®è³ªå•å¿œç­”ï¼ˆIQAï¼‰ã¨ã„ã†æ–°ã—ã„è¨­å®šã‚’ææ¡ˆã€‚IQAã§ã¯ã€1ã¤ã®ãƒ¢ãƒ‡ãƒ«ãŒæ¶ç©ºã®è³ªå•ã‚’ç”Ÿæˆã—ã€åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ãŒãã‚Œã«ç­”ãˆã‚‹ã€‚é©šãã¹ãã“ã¨ã«ã€å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒãƒ•ã‚£ã‚¯ã‚·ãƒ§ãƒ³ã®è³ªå•ã«æˆåŠŸè£ã«å¿œç­”ã§ãã‚‹ã“ã¨ã‹ã‚‰ã€å…±é€šã®ã€Œæƒ³åƒç©ºé–“ã€ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚ã“ã®ç¾è±¡ã«ã¤ã„ã¦èª¿æŸ»ã—ã€ãƒ¢ãƒ‡ãƒ«ã®å‡è³ªæ€§ã‚„å¹»è¦šã€è¨ˆç®—çš„å‰µé€ æ€§ã«é–¢ã™ã‚‹è€ƒå¯Ÿã‚’è¡Œã†ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=NUXpBMtDYs" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=NUXpBMtDYs</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tmlrpub/status/1968449957343433191?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2843" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-R1 incentivizes reasoning in LLMs through reinforcement learning, Guo+, Nature'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMsã®æ¨è«–èƒ½åŠ›ã‚’å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã‚’é€šã˜ã¦å‘ä¸Šã•ã›ã€äººé–“ã«ã‚ˆã‚‹ãƒ©ãƒ™ãƒ«ä»˜ã‘ã®å¿…è¦æ€§ã‚’æ’é™¤ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ææ¡ˆã™ã‚‹RLãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€é«˜åº¦ãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç™ºå±•ã‚’ä¿ƒé€²ã—ã€æ•°å­¦ã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ãªã©ã®ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã™ã‚‹ã€‚ã•ã‚‰ã«ã€å‡ºç¾çš„ãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯å°ã•ãªãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›å‘ä¸Šã«ã‚‚å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>DeepSeek-R1ã®è«–æ–‡ã®Natureç‰ˆãŒå‡ºãŸæ¨¡æ§˜ã€‚</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1968800470496915547?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Supplementary Materials:


<a href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-025-09422-z/MediaObjects/41586_2025_9422_MOESM1_ESM.pdf" target="_blank" rel="noopener noreferrer">https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-025-09422-z/MediaObjects/41586_2025_9422_MOESM1_ESM.pdf</a>


<br><br>ãŠãã‚‰ãã“ã¡ã‚‰ã®æ–¹ãŒé‡è¦</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2840" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RL Fine-Tuning Heals OOD Forgetting in SFT, Hangzhan Jin+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- äºŒæ®µéšãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹SFTã¨RLã®ç›¸äº’ä½œç”¨ã‚’æ¢æ±‚ã—ã€SFTãŒè¨˜æ†¶ã—ã€RLãŒä¸€èˆ¬åŒ–ã™ã‚‹ã¨ã„ã†ä¸»å¼µãŒéåº¦ã«å˜ç´”åŒ–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚å…·ä½“çš„ã«ã¯ã€(1) OODæ€§èƒ½ã¯SFTã®åˆæœŸæ®µéšã§ãƒ”ãƒ¼ã‚¯ã«é”ã—ã€ãã®å¾Œä½ä¸‹ã™ã‚‹ã“ã¨ã€(2) RLã¯SFTä¸­ã«å¤±ã‚ã‚ŒãŸæ¨è«–èƒ½åŠ›ã‚’å›å¾©ã™ã‚‹å½¹å‰²ã‚’æœãŸã™ã“ã¨ã€(3) å›å¾©èƒ½åŠ›ã«ã¯é™ç•ŒãŒã‚ã‚‹ã“ã¨ã€(4) OODã®æŒ™å‹•ã¯ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ã®ã€Œå›è»¢ã€ã¨å¼·ãç›¸é–¢ã™ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€SFTã¨RLã®å½¹å‰²ã‚’å†èªè­˜ã—ã€ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ã®å›è»¢ãŒé‡è¦ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1740" target="_blank" rel="noopener noreferrer">SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model   Post-training, Tianzhe Chu+, ICML'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2700" target="_blank" rel="noopener noreferrer">[Paper Note] Towards a Unified View of Large Language Model Post-Training, Xingtai Lv+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2713" target="_blank" rel="noopener noreferrer">[Paper Note] RL's Razor: Why Online Reinforcement Learning Forgets Less, Idan Shenfeld+, arXiv'25</a>
<br><br>ã¨åˆã‚ã›ã¦èª­ã‚€ã¨è‰¯ã•ãã†</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1968187719588385240?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç›´æ„Ÿçš„ã«ã¯ã€ä¸‹è¨˜ç ”ç©¶ã§SFTã‚’RLã®è¦³ç‚¹ã§è¦‹ãŸã¨ãã«ã€å›ç­”ã®è»Œè·¡ã«å¯¾ã—ã¦exact matchã—ã¦ã„ãŸå ´åˆã«1ã‚’è¿”ã™å ±é…¬ã‚’æŒã¤RLã€ã‹ã¤importance weightingã«ã‚ˆã£ã¦ç¾åœ¨ã®ãƒãƒªã‚·ãƒ¼ãŒè‹¦æ‰‹ãªè»Œè·¡ã‚’é‡è¦è¦–ã™ã‚‹ã€ã¨ã„ã†ã“ã¨è€ƒãˆã‚‹ã¨ã€ç›®çš„ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æ±åŒ–æ€§èƒ½ãŠã‹ã¾ã„ãªã—ã«greedyã«æœ€é©åŒ–ã•ã‚Œã‚‹ãŸã‚ã€OODã¸ã®å¯¾å¿œåŠ›ãŒç„¡ããªã‚‹ã€ã¨ã„ã†ã®ã¯ãªã‚“ã¨ãªãç†è§£ã§ãã‚‹ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/IRT.html" target="_blank" rel="noopener noreferrer">#IRT</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2837" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Fluid Language Model Benchmarking, Valentin Hofmann+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- Fluid Benchmarkingã¨ã„ã†æ–°ã—ã„è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLMï¼‰è©•ä¾¡ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€LMã®èƒ½åŠ›ã«å¿œã˜ã¦è©•ä¾¡é …ç›®ã‚’å‹•çš„ã«é¸æŠã—ã€è©•ä¾¡ã®è³ªã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“ã§ã¯ã€Fluid BenchmarkingãŒåŠ¹ç‡ã€å¦¥å½“æ€§ã€åˆ†æ•£ã€é£½å’Œã®4ã¤ã®æ¬¡å…ƒã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€é™çš„è©•ä¾¡ã‚’è¶…ãˆã‚‹ã“ã¨ã§LMãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æ”¹å–„ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/allen_ai/status/1967983841336836491?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vjhofmann/status/1967994756795077097?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2835" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MachineLearningLM: Scaling Many-shot In-context Learning via Continued  Pretraining, Haoyu Dong+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MachineLearningLMã¯ã€LLMã«ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’èƒ½åŠ›ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã®ç¶™ç¶šçš„äº‹å‰å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€æ•°ç™¾ä¸‡ã®MLã‚¿ã‚¹ã‚¯ã‚’åˆæˆã™ã‚‹ã€‚ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆæ•™å¸«ã‚’ç”¨ã„ã¦æ„æ€æ±ºå®šæˆ¦ç•¥ã‚’è’¸ç•™ã—ã€æ•°å€¤ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®å …ç‰¢æ€§ã‚’å‘ä¸Šã€‚æ§ãˆã‚ãªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã§ã‚‚ã€é‡‘èã‚„åŒ»ç™‚åˆ†é‡ã§å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ç´„15%ä¸Šå›ã‚Šã€ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å¢—åŠ ã«ä¼´ã„ç²¾åº¦ãŒå‘ä¸Šã€‚ä¸€èˆ¬çš„ãªãƒãƒ£ãƒƒãƒˆèƒ½åŠ›ã‚‚ä¿æŒã—ã€MMLUã§75.4%ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1968246426552729743?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2834" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ReSum: Unlocking Long-Horizon Search Intelligence via Context  Summarization, Xixi Wu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ReSumã¨ã„ã†æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’å°å…¥ã—ã€å®šæœŸçš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã‚’é€šã˜ã¦ç„¡é™ã®æ¢ç´¢ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚ReSum-GRPOã‚’ææ¡ˆã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè¦ç´„æ¡ä»¶ä»˜ãæ¨è«–ã«æ…£ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ReSumã¯ReActã«å¯¾ã—ã¦å¹³å‡4.5ï¼…ã®æ”¹å–„ã‚’ç¤ºã—ã€WebResummer-30Bã¯æ—¢å­˜ã®ã‚¦ã‚§ãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1968161796642279549?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Planning.html" target="_blank" rel="noopener noreferrer">#Planning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2833" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for  Open-Ended Deep Research, Zijian Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚¦ã‚§ãƒ–æƒ…å ±ã‚’çµ±åˆã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰æ·±å±¤ç ”ç©¶ï¼ˆOEDRï¼‰ã«å–ã‚Šçµ„ã¿ã€WebWeaverã¨ã„ã†æ–°ã—ã„äºŒé‡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ãŒè¨¼æ‹ å–å¾—ã¨ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³æœ€é©åŒ–ã‚’äº¤äº’ã«è¡Œã„ã€ãƒ©ã‚¤ã‚¿ãƒ¼ãŒæƒ…å ±ã‚’éšå±¤çš„ã«æ¤œç´¢ã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã‚’æ§‹æˆã™ã‚‹ã“ã¨ã§ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å•é¡Œã‚’è»½æ¸›ã€‚ææ¡ˆæ‰‹æ³•ã¯ä¸»è¦ãªOEDRãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ–°ãŸãªæœ€å…ˆç«¯ã‚’ç¢ºç«‹ã—ã€é«˜å“è³ªãªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«ãŠã‘ã‚‹äººé–“ä¸­å¿ƒã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®é‡è¦æ€§ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1968161793127416197?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2832" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Agents via Continual Pre-training, Liangcai Su+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ç”¨ã„ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã¯ã€è¤‡é›‘ãªå•é¡Œè§£æ±ºã«ãŠã„ã¦é€²åŒ–ã—ã¦ã„ã‚‹ãŒã€ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ã“ã¨ãŒå¤šã„ã€‚ã“ã‚Œã¯ã€å …ç‰¢ãªåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®æ¬ å¦‚ãŒåŸå› ã§ã‚ã‚‹ã€‚ãã“ã§ã€ç¶™ç¶šçš„ãªäº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆAgentic CPTï¼‰ã‚’å°å…¥ã—ã€å¼·åŠ›ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã‚’ææ¡ˆã€‚æ–°ãŸã«é–‹ç™ºã—ãŸAgentFounderãƒ¢ãƒ‡ãƒ«ã¯ã€10ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ç‰¹ã«BrowseComp-enã§39.9%ã€BrowseComp-zhã§43.3%ã€HLEã§ã®Pass@1ã§31.5%ã‚’è¨˜éŒ²ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1968161789583196253?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>AI Agentã®ãŸã‚ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’ç¶™ç¶šäº‹å‰å­¦ç¿’ã«ã‚ˆã£ã¦å®Ÿç¾ã—ãŸæ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/MCP.html" target="_blank" rel="noopener noreferrer">#MCP</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2831" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Towards General Agentic Intelligence via Environment Scaling, Runnan Fang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçŸ¥èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ç’°å¢ƒã‚’æ‹¡å¤§ã—ã€é–¢æ•°å‘¼ã³å‡ºã—èƒ½åŠ›ã‚’å¼·åŒ–ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨“ç·´ã¯äºŒæ®µéšã§è¡Œã„ã€åŸºæœ¬èƒ½åŠ›ã‚’ä»˜ä¸ã—ãŸå¾Œã€ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ç‰¹åŒ–ã•ã›ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆãƒ¢ãƒ‡ãƒ«AgentScalerãŒé–¢æ•°å‘¼ã³å‡ºã—èƒ½åŠ›ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1968161785695133948?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>blog:


<a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/" target="_blank" rel="noopener noreferrer">https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2830" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon  Agents, Zile Qiao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒWebResearcherã€ã‚’ææ¡ˆã—ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå¤–éƒ¨ã‚½ãƒ¼ã‚¹ã‹ã‚‰çŸ¥è­˜ã‚’è‡ªå¾‹çš„ã«ç™ºè¦‹ãƒ»çµ±åˆã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€‚WebResearcherã¯ã€æ·±å±¤ç ”ç©¶ã‚’ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹ã¨ã—ã¦å†å®šå¼åŒ–ã—ã€å ±å‘Šæ›¸ã«ç™ºè¦‹ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§æ–‡è„ˆã®å•é¡Œã‚’å…‹æœã€‚ã¾ãŸã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒ‡ãƒ¼ã‚¿åˆæˆã‚¨ãƒ³ã‚¸ãƒ³ã€ŒWebFrontierã€ã‚’ç”¨ã„ã¦é«˜å“è³ªãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€ãƒ„ãƒ¼ãƒ«ä½¿ç”¨èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€WebResearcherã¯æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã—ã€å•†ç”¨ã‚·ã‚¹ãƒ†ãƒ ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1968161781878345880?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>blog:


<a href="https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/" target="_blank" rel="noopener noreferrer">https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/</a>


</p>
<p>OpenAI DeepResearchã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã§åŒç­‰ã®æ€§èƒ½ã‚’å®Ÿç¾ã—ãŸopenweightãƒ¢ãƒ‡ãƒ«</p>
<p>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯: <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1730" target="_blank" rel="noopener noreferrer">[Paper Note] Humanity's Last Exam, Long Phan+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2451" target="_blank" rel="noopener noreferrer">[Paper Note] BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents, Jason Wei+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1158" target="_blank" rel="noopener noreferrer">GAIA: a benchmark for General AI Assistants, GrÃ©goire Mialon+, N/A, arXiv'23</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2851" target="_blank" rel="noopener noreferrer">[Paper Note] WebWalker: Benchmarking LLMs in Web Traversal, Jialong Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2852" target="_blank" rel="noopener noreferrer">[Paper Note] Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented   Generation, Satyapriya Krishna+, NAACL'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2853" target="_blank" rel="noopener noreferrer">[Paper Note] BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language
  Models in Chinese, Peilin Zhou+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<a class="button" href="articles/Reproducibility.html" target="_blank" rel="noopener noreferrer">#Reproducibility</a>
<a class="button" href="articles/MCP.html" target="_blank" rel="noopener noreferrer">#MCP</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2827" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Paper2Agent: Reimagining Research Papers As Interactive and Reliable AI  Agents, Jiacheng Miao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Paper2Agentã¯ã€ç ”ç©¶è«–æ–‡ã‚’AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«è‡ªå‹•å¤‰æ›ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€ç ”ç©¶æˆæœã®åˆ©ç”¨ã‚„ç™ºè¦‹ã‚’åŠ é€Ÿã—ã¾ã™ã€‚å¾“æ¥ã®è«–æ–‡ã¯å†åˆ©ç”¨ã®éšœå£ã‚’ç”Ÿã‚“ã§ã„ã¾ã—ãŸãŒã€Paper2Agentã¯è«–æ–‡ã‚’çŸ¥è­˜è±Šå¯Œãªç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å¤‰æ›ã—ã¾ã™ã€‚è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ç”¨ã„ã¦è«–æ–‡ã¨é–¢é€£ã‚³ãƒ¼ãƒ‰ã‚’åˆ†æã—ã€ãƒ¢ãƒ‡ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒˆã‚³ãƒ«ï¼ˆMCPï¼‰ã‚’æ§‹ç¯‰ã€æ´—ç·´ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è‡ªç„¶è¨€èªã‚’é€šã˜ã¦ç§‘å­¦çš„ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã§ãã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã—ã€å®Ÿéš›ã«ã‚²ãƒãƒ å¤‰ç•°ã‚„ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒŸã‚¯ã‚¹åˆ†æã‚’è¡Œã†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå…ƒã®è«–æ–‡ã®çµæœã‚’å†ç¾ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚Paper2Agentã¯ã€é™çš„ãªè«–æ–‡ã‚’å‹•çš„ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å¤‰ãˆã‚‹ã“ã¨ã§ã€çŸ¥è­˜ã®æ™®åŠã«æ–°ãŸãªãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>code:


<a href="https://github.com/jmiao24/Paper2Agent?tab=readme-ov-file#-demos" target="_blank" rel="noopener noreferrer">https://github.com/jmiao24/Paper2Agent?tab=readme-ov-file#-demos</a>


</p>
<p>è«–æ–‡ã‚’è«–æ–‡ãŒææ¡ˆã™ã‚‹æŠ€è¡“ã®æ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹MCPã‚µãƒ¼ãƒã«å¤‰æ›ã—ã€LLM Agentã‚’é€šã˜ã¦ãƒ¦ãƒ¼ã‚¶ã¯setupç„¡ã—ã«å‘¼ã³ã ã—ã¦åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹æŠ€è¡“ãªæ¨¡æ§˜ã€‚è«–æ–‡ã‹ã‚‰è‡ªå‹•çš„ã«codebaseã‚’åŒå®šã—ã€ã‚³ã‚¢ã¨ãªã‚‹æŠ€è¡“ã‚’MCP toolsã¨ã—ã¦ãƒ©ãƒƒãƒ—ã—ã€åå¾©çš„ãªãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½ã—ã¦ãƒ­ãƒã‚¹ãƒˆã«ã—ãŸä¸Šã§HFä¸Šã®AI Agentã«æä¾›ã™ã‚‹ã€ã¿ãŸã„ãªæ„Ÿã˜ã«è¦‹ãˆã‚‹ã€‚<br><br>&lt;img width="667" height="602" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/36dca631-c576-43e5-b8b8-77de555f0b6f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/36dca631-c576-43e5-b8b8-77de555f0b6f"&lt;/a&gt;


/&gt;</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1968829219858956774?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2826" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SWE-bench Multimodal: Do AI Systems Generalize to Visual Software   Domains?, John Yang+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå¾‹ã‚·ã‚¹ãƒ†ãƒ ã®ãƒã‚°ä¿®æ­£èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€SWE-bench Mã‚’ææ¡ˆã€‚ã“ã‚Œã¯è¦–è¦šè¦ç´ ã‚’å«ã‚€JavaScriptã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ã‚¿ã‚¹ã‚¯ã‚’å¯¾è±¡ã¨ã—ã€617ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åé›†ã€‚å¾“æ¥ã®SWE-benchã‚·ã‚¹ãƒ†ãƒ ãŒè¦–è¦šçš„å•é¡Œè§£æ±ºã«è‹¦åŠ´ã™ã‚‹ä¸­ã€SWE-agentã¯ä»–ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’å¤§ããä¸Šå›ã‚Šã€12%ã®ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=riTiq3i21b" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=riTiq3i21b</a>


</p>
<p>pj page:


<a href="https://www.swebench.com/multimodal.html" target="_blank" rel="noopener noreferrer">https://www.swebench.com/multimodal.html</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2817" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Forgetting Transformer: Softmax Attention with a Forget Gate, Zhixuan Lin+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- å¿˜å´ã‚²ãƒ¼ãƒˆã‚’å–ã‚Šå…¥ã‚ŒãŸãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã€ŒFoXã€ã‚’ææ¡ˆã€‚FoXã¯é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚„ä¸‹æµã‚¿ã‚¹ã‚¯ã§ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ä½ç½®åŸ‹ã‚è¾¼ã¿ã‚’å¿…è¦ã¨ã—ãªã„ã€‚å†å¸°çš„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã‚‚å„ªã‚ŒãŸèƒ½åŠ›ã‚’ä¿æŒã—ã€æ€§èƒ½å‘ä¸Šã®ãŸã‚ã®ã€ŒProã€ãƒ–ãƒ­ãƒƒã‚¯è¨­è¨ˆã‚’å°å…¥ã€‚ã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=q2Lnyegkr8" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=q2Lnyegkr8</a>


</p>
<p>code:


<a href="https://github.com/zhixuan-lin/forgetting-transformer" target="_blank" rel="noopener noreferrer">https://github.com/zhixuan-lin/forgetting-transformer</a>


</p>
<p>éå¸¸ã«ãŠã‚‚ã—ã‚ãã†</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Pruning.html" target="_blank" rel="noopener noreferrer">#Pruning</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2816" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Adaptive Computation Pruning for the Forgetting Transformer, Zhixuan Lin+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- Forgeting Transformerï¼ˆFoXï¼‰ã¯ã€å¿˜å´ã‚²ãƒ¼ãƒˆã‚’ç”¨ã„ãŸã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’ç‰¹å¾´ã¨ã—ã€å¾“æ¥ã®Transformerã¨æ¯”è¼ƒã—ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ã€‚FoXã®ç‰¹æ€§ã‚’æ´»ã‹ã—ã€é©å¿œè¨ˆç®—ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆACPï¼‰ã‚’ææ¡ˆã—ã€è¨ˆç®—ã‚’å‹•çš„ã«ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€FLOPsã¨ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ã‚’ç´„70%å‰Šæ¸›ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œæ™‚é–“ã‚’50%ã‹ã‚‰70%çŸ­ç¸®ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’10%ã‹ã‚‰40%å‘ä¸Šã•ã›ãŸã€‚æ€§èƒ½ã®åŠ£åŒ–ã¯ãªãã€é•·ã„æ–‡è„ˆé•·ã§ã¯ã•ã‚‰ãªã‚‹è¨ˆç®—ã‚³ã‚¹ãƒˆã®ç¯€ç´„ãŒå¯èƒ½ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>code:


<a href="https://github.com/zhixuan-lin/forgetting-transformer" target="_blank" rel="noopener noreferrer">https://github.com/zhixuan-lin/forgetting-transformer</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhxlin/status/1967596994362220761?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>openreview:


<a href="https://openreview.net/forum?id=xNj14CY5S1#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=xNj14CY5S1#discussion</a>


</p>
<p>å…ˆè¡Œç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2817" target="_blank" rel="noopener noreferrer">[Paper Note] Forgetting Transformer: Softmax Attention with a Forget Gate, Zhixuan Lin+, ICLR'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2815" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scalable Vision Language Model Training via High Quality Data Curation, Hongyuan Dong+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- SAIL-VLã¯ã€2BãŠã‚ˆã³8Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ“ã‚¸ãƒ§ãƒ³è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚ä¸»ãªæ”¹å–„ç‚¹ã¯ã€(1) é«˜å“è³ªãªè¦–è¦šç†è§£ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰ã€(2) æ‹¡å¤§ã—ãŸäº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹æ€§èƒ½å‘ä¸Šã€(3) è¤‡é›‘ã•ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹åŠ¹æœçš„ãªSFTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€‚SAIL-VLã¯18ã®VLMãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’é”æˆã—ã€2Bãƒ¢ãƒ‡ãƒ«ã¯åŒç­‰ã®VLMã®ä¸­ã§ãƒˆãƒƒãƒ—ã®ä½ç½®ã‚’å ã‚ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã¯HuggingFaceã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1967737399443623985?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/BytedanceDouyinContent" target="_blank" rel="noopener noreferrer">https://huggingface.co/BytedanceDouyinContent</a>


</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-09-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2811" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DeepDive: Advancing Deep Search Agents with Knowledge Graphs and  Multi-Turn RL, Rui Lu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- DeepDiveã¯ã€LLMsã«ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«ã‚’è¿½åŠ ã—ã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã®è§£æ±ºã‚’ç›®æŒ‡ã™æ·±ã„æ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ãªçŸ¥è­˜ã‚°ãƒ©ãƒ•ã‹ã‚‰é›£è§£ãªè³ªå•ã‚’è‡ªå‹•åˆæˆã—ã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å¼·åŒ–å­¦ç¿’ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã€é•·æœŸçš„ãªæ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€DeepDive-32Bã¯è¤‡æ•°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¨ä¸¦åˆ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’å¯èƒ½ã«ã—ã¾ã—ãŸã€‚ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã¨ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/grad62304977/status/1967540231831523424?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-09-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2806" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Illusion of Diminishing Returns: Measuring Long Horizon Execution in  LLMs, Akshit Sinha+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒåç›Šã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã‹ã‚’æ¢æ±‚ã€‚å˜ä¸€ã‚¹ãƒ†ãƒƒãƒ—ã®ç²¾åº¦å‘ä¸ŠãŒã‚¿ã‚¹ã‚¯ã®é•·ã•ã«æŒ‡æ•°çš„æ”¹å–„ã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ã‚’è¦³å¯Ÿã€‚LLMsãŒé•·æœŸã‚¿ã‚¹ã‚¯ã§å¤±æ•—ã™ã‚‹ã®ã¯æ¨è«–èƒ½åŠ›ã®æ¬ å¦‚ã§ã¯ãªãå®Ÿè¡ŒãƒŸã‚¹ã«ã‚ˆã‚‹ã¨ä¸»å¼µã€‚çŸ¥è­˜ã¨è¨ˆç”»ã‚’æ˜ç¤ºçš„ã«æä¾›ã™ã‚‹ã“ã¨ã§å®Ÿè¡Œèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ææ¡ˆã€‚ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦ã‚‚è‡ªå·±æ¡ä»¶ä»˜ã‘åŠ¹æœã¯æ¸›å°‘ã›ãšã€é•·ã„ã‚¿ã‚¹ã‚¯ã§ã®ãƒŸã‚¹ãŒå¢—åŠ ã€‚æ€è€ƒãƒ¢ãƒ‡ãƒ«ã¯è‡ªå·±æ¡ä»¶ä»˜ã‘ã‚’è¡Œã‚ãšã«é•·ã„ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œå¯èƒ½ã€‚æœ€çµ‚çš„ã«ã€å®Ÿè¡Œèƒ½åŠ›ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã“ã¨ã§ã€LLMsã®è¤‡é›‘ãªæ¨è«–å•é¡Œè§£æ±ºèƒ½åŠ›ã¨å˜ç´”ã‚¿ã‚¹ã‚¯ã®é•·æœŸåŒ–ã«ã‚ˆã‚‹å¤±æ•—ç†ç”±ã‚’èª¿å’Œã•ã›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shashwatgoel7/status/1966527903568637972?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>single stepã§ã®ã‚¿ã‚¹ã‚¯æ€§èƒ½ã¯ã‚µãƒã£ã¦è¦‹ãˆã¦ã‚‚ã€æˆåŠŸå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®é•·ã•ã¯ï¼ˆsingle stepã®å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã«å¼•ãã¥ã‚‰ã‚Œã‚‹ãŸã‚ï¼‰ãƒ¢ãƒ‡ãƒ«ã®single stepã®ã‚¿ã‚¹ã‚¯æ€§èƒ½ã«å¯¾ã—ã¦æŒ‡æ•°é–¢æ•°çš„ã«åŠ¹ã„ã¦ã„ã‚‹ï¼ˆå·¦ä¸Šï¼‰ã€‚ã‚¿ã‚¹ã‚¯ãŒé•·ããªã‚Œã°ãªã‚‹ã»ã©ãƒ¢ãƒ‡ãƒ«ã¯è‡ªèº«ã®ã‚¨ãƒ©ãƒ¼ã«å¼•ããšã‚‰ã‚Œï¼ˆself conditioning;å³ä¸Š)ã€ã“ã‚Œã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¤§ãã„ã»ã©åº¦åˆã„ãŒå¤§ãããªã‚‹ï¼ˆå³ä¸‹;  32Bã®å ´åˆcontextã«ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦å ´åˆã®loeg horizonã®Acc.ãŒ14Bã‚ˆã‚Šã‚‚ä¸‹ãŒã£ã¦ã„ã‚‹ï¼‰ã€‚ä¸€æ–¹ã§ã€å®Ÿè¡Œå¯èƒ½ãªstepæ•°ã®è¦³ç‚¹ã§è¦‹ã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„å ´åˆã®æ–¹ãŒå¤šãã®stepã‚’è¦ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã§ãã‚‹ï¼ˆå·¦ä¸‹ï¼‰ã€‚ã¾ãŸã€Thinkingãƒ¢ãƒ‡ãƒ«ã¯Self Conditioningã®å½±éŸ¿ã‚’å—ã‘ã«ããã€single stepã§å®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®é•·ã•ãŒã‚ˆã‚Šé•·ããªã‚‹ï¼ˆä¸­å¤®ä¸‹ï¼‰ã€‚<br><br>ã¨ã„ã£ãŸè©±ã«è¦‹ãˆã‚‹ãŒã€è«–æ–‡ã‚’ã—ã£ã‹ã‚Šèª­ã‚“ã æ–¹ãŒè‰¯ã•ãã†ã€‚<br><br><img src="https://github.com/user-attachments/assets/a97fe1f4-5693-4ed3-9fa0-774f4c3738ab" alt="image" loading="lazy"></p>
<p>ï¼ˆå…ƒãƒã‚¹ãƒˆã‚‚è‘—è€…ãƒã‚¹ãƒˆã ãŒï¼‰è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/akshitwt/status/1966528585558303209?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã“ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã¯èª­ã‚“ã æ–¹ãŒè‰¯ã„ï¼ˆã¨ã„ã†ã‹è«–æ–‡ã‚’èª­ã‚“ã æ–¹ãŒè‰¯ã„ï¼‰ã€‚<br>ç‰¹ã«ã€**CoTãŒç„¡ã„å ´åˆã¯**single-turnã§ã»ã¨ã‚“ã©ã®ãƒ¢ãƒ‡ãƒ«ã¯5 stepã®ã‚¿ã‚¹ã‚¯ã‚’latent spaceã§æ€è€ƒã—ã€å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒã§ããªã„ã¨ã„ã†ã®ã¯èˆˆå‘³æ·±ã„ï¼ˆãŒã€ç´°ã‹ã„è¨­å®šã¯ç¢ºèªã—ãŸæ–¹ãŒè‰¯ã„ï¼‰ã€‚ãªã®ã§ã€ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¿ã‚¹ã‚¯ã¯åŸºæœ¬çš„ã«ã¯planningã‚’ã•ã›ã¦ã‹ã‚‰å‡ºåŠ›ã‚’ã•ã›ãŸæ–¹ãŒè‰¯ã„ã¨ã„ã†è©±ã‚„ã€<br><br>ã§ã¯è¤‡é›‘ãªstepãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã¯single turnã§ã¯ãªãmulti turnã«åˆ†ã‘ãŸæ–¹ãŒè‰¯ã„ã®ã‹ï¼Ÿã¨è¨€ã†ã¨ã€ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦å‚¾å‘ãŒé•ã†ã‚‰ã—ã„ã€ã¨ã„ã£ãŸè©±ãŒæ›¸ã‹ã‚Œã¦ã„ã‚‹ã€‚ãŸã¨ãˆã°ã€Qwenã¯single turnã‚’å¥½ã‚€ãŒã€Gemmaã¯multi turnã‚’å¥½ã‚€ã‚‰ã—ã„ã€‚<p>æ—¥æœ¬èªãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwashi86/status/1966969350197571833?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1968453604655907143?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-09-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2805" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] EviNote-RAG: Enhancing RAG Models via Answer-Supportive Evidence Notes, Yuqin Dai+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- EviNote-RAGã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‰ãƒ¡ã‚¤ãƒ³ã®QAã«ãŠã‘ã‚‹ã€Œå–å¾—-ãƒãƒ¼ãƒˆ-å›ç­”ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å°å…¥ã—ãŸæ–°ã—ã„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹RAGãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å–å¾—ã•ã‚ŒãŸæƒ…å ±ã‹ã‚‰æœ‰ç”¨ãªå†…å®¹ã‚’æŠ½å‡ºã—ã€ä¸ç¢ºå®Ÿæ€§ã‚’å¼·èª¿ã™ã‚‹Supportive-Evidence Notesï¼ˆSENsï¼‰ã‚’ç”Ÿæˆã—ã¾ã™ã€‚Evidence Quality Rewardï¼ˆEQRï¼‰ã‚’ç”¨ã„ã¦æ¨è«–ã®ä¿¡é ¼æ€§ã‚’é«˜ã‚ã€ãƒã‚¤ã‚ºã®å½±éŸ¿ã‚’è»½æ¸›ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€EviNote-RAGãŒç²¾åº¦ã‚„å®‰å®šæ€§ã«ãŠã„ã¦å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€ç‰¹ã«HotpotQAã‚„Bamboogleã€2Wikiã§é¡•è‘—ãªF1ã‚¹ã‚³ã‚¢ã®å‘ä¸Šã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwashi86/status/1966971369264214399?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>-  <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1140" target="_blank" rel="noopener noreferrer">Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language   Models, Wenhao Yu+, N/A, EMNLP'24</a>
<br><br>ã¨ã®é•ã„ã¯ãªã‚“ã ã‚ã†ã‹ï¼Ÿã–ã£ã¨æ¤œç´¢ã—ãŸæ„Ÿã˜ã€å¼•ç”¨ã•ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p>
<p>ã–ã£ãã‚Šã¨ã—ã‹èª­ã‚ã¦ã„ãªã„ãŒã€LLMã«QAã«å›ç­”ã™ã‚‹ãŸã‚ã®ååˆ†ãªevidenceãŒé›†ã¾ã‚‹ã¾ã§è¤‡æ•°å›ã€æ¤œç´¢â†’SENs(æ¤œç´¢çµæœã‹ã‚‰å°ãå‡ºã•ã‚Œã‚‹QAã«ç­”ãˆã‚‹ã®ã«å¿…è¦ãªæƒ…å ±ã®ã‚µãƒãƒª;æ¤œç´¢çµæœã®denoisingã®å½¹å‰²ã‚’æœãŸã™)â†’...ã‚’ç¹°ã‚Šè¿”ã—ã€æœ€çµ‚çš„ãªSEN_lastã‹ã‚‰å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã€‚SEN_lastãŒå›ç­”ã‚’å«æ„ã™ã‚‹ã‹å¦ã‹ã‚’DistilBERTãƒ™ãƒ¼ã‚¹ã®Rewardãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦GRPOã«ã®å ±é…¬ã¨ã—ã¦æ´»ç”¨ã™ã‚‹ã€‚ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆreasoningãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹å‰æï¼‰ã¯QAãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€ä¸Šè¨˜ãƒ—ãƒ­ã‚»ã‚¹ã«ã‚ˆã£ã¦ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’å®Ÿæ–½ã•ã›ã‚‹ã“ã¨ã§GRPO+RLVR(å›ç­”ãŒåˆã£ã¦ã„ã‚‹ã‹ï¼‰+ï¼ˆDistillBERTã«åŸºã¥ãSNEs_lastã®ï¼‰Entailmentåˆ¤å®šãƒ¢ãƒ‡ãƒ«ã®confidenceã‚¹ã‚³ã‚¢ã«ã‚ˆã£ã¦è¨“ç·´ã™ã‚‹ã€ã¨ã„ã£ã¦æ„Ÿã˜ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/2e2c29b4-deaa-4679-8fc3-fb81a7b327c2" alt="image" loading="lazy"><br><br>Chain-of-Noteã¨æ¯”ã¹è¿½åŠ ã®å­¦ç¿’ãŒå¿…è¦ãªã®ã§ã‚³ãƒ³ã‚»ãƒ—ãƒˆã¯åŒã˜ã ãŒã€æ‰‹æ³•çš„ã«ã¯ç•°ãªã£ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2804" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models  for Robotic Manipulation, Hao Shi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MemoryVLAã¯ã€ãƒ­ãƒœãƒƒãƒˆæ“ä½œã«ãŠã‘ã‚‹æ™‚é–“çš„æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸCognition-Memory-Actionãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹ã€‚ä½œæ¥­è¨˜æ†¶ã‚’åˆ©ç”¨ã—ã¦çŸ­å‘½ã®è¡¨ç¾ã‚’åˆ¶å¾¡ã—ã€çŸ¥è¦š-èªçŸ¥ãƒ¡ãƒ¢ãƒªãƒ¼ãƒãƒ³ã‚¯ã«çµ±åˆã•ã‚ŒãŸæƒ…å ±ã‚’ä¿å­˜ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ™‚é–“çš„ã«æ„è­˜ã—ãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆã—ã€150ä»¥ä¸Šã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŠã‚ˆã³å®Ÿä¸–ç•Œã®ã‚¿ã‚¹ã‚¯ã§é«˜ã„æˆåŠŸç‡ã‚’é”æˆã€‚ç‰¹ã«ã€é•·æœŸçš„ãªã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://shihao1895.github.io/MemoryVLA/" target="_blank" rel="noopener noreferrer">https://shihao1895.github.io/MemoryVLA/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/embodiedairead/status/1966651546567143534?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é•·æœŸè¨˜æ†¶ã¨ã—ã¦ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ãŒå°å…¥ã•ã‚Œã€éå»ã«èªè­˜ã—ãŸå†—é•·æ€§ãŒæ’é™¤ã•ã‚ŒãŸç”»åƒæƒ…å ±(low level)ã¨ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã«ã‚ˆã‚‹æŒ‡ç¤ºã®æ„å‘³æƒ…å ±ï¼ˆhigh level semantics)ã‚’æ ¼ç´ã—ã¦ãŠã<br>ã€retrievalã—ãŸä¸Šã§æ´»ç”¨ã™ã‚‹ã€‚æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºã‚ã‚‹ãŸã‚ã®ãƒ‡ã‚³ãƒ¼ãƒ€ã‚ˆã†ã«è¦‹ãˆã‚‹transformerã®attentionã«å°‚ç”¨ã®Cognition/Perceptionã®attentionãŒä¸¡æ–¹ç”¨æ„ã•ã‚Œã¦ã„ã‚‹ğŸ‘€<br><br><img src="https://github.com/user-attachments/assets/520eae6e-c96e-416c-b72d-fc7326d8b9df" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Medical.html" target="_blank" rel="noopener noreferrer">#Medical</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2794" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MedBrowseComp: Benchmarking Medical Deep Research and Computer Use, Shan Chen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯è‡¨åºŠæ„æ€æ±ºå®šæ”¯æ´ã«æœŸå¾…ã•ã‚Œã¦ã„ã‚‹ãŒã€ç•°ç¨®ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’çµ±åˆã™ã‚‹å³æ ¼ãªç²¾åº¦ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚æ—¢å­˜ã®è©•ä¾¡ã¯å®Ÿç”¨æ€§ãŒä¸æ˜ç¢ºã§ã‚ã‚‹ãŸã‚ã€MedBrowseCompã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€åŒ»ç™‚å¾“äº‹è€…ãŒæƒ…å ±ã‚’èª¿æ•´ã™ã‚‹è‡¨åºŠã‚·ãƒŠãƒªã‚ªã‚’åæ˜ ã—ãŸ1,000ä»¥ä¸Šã®è³ªå•ã‚’å«ã‚€åˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚‹ã€‚æœ€å‰ç·šã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã«é©ç”¨ã—ãŸçµæœã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¸è¶³ãŒ10ï¼…ã«é”ã—ã€LLMã®èƒ½åŠ›ã¨è‡¨åºŠç’°å¢ƒã®è¦æ±‚ã¨ã®é–“ã«é‡è¦ãªã‚®ãƒ£ãƒƒãƒ—ãŒç¤ºã•ã‚ŒãŸã€‚MedBrowseCompã¯ä¿¡é ¼æ€§ã®é«˜ã„åŒ»ç™‚æƒ…å ±æ¢ç´¢ã®ãŸã‚ã®ãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã‚’æä¾›ã—ã€å°†æ¥ã®ãƒ¢ãƒ‡ãƒ«æ”¹å–„ã®ç›®æ¨™ã‚’è¨­å®šã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://moreirap12.github.io/mbc-browse-app/" target="_blank" rel="noopener noreferrer">https://moreirap12.github.io/mbc-browse-app/</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<a class="button" href="articles/Medical.html" target="_blank" rel="noopener noreferrer">#Medical</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2793" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MedResearcher-R1: Expert-Level Medical Deep Researcher via A  Knowledge-Informed Trajectory Synthesis Framework, Ailing Yu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- åŒ»ç™‚åˆ†é‡ã«ç‰¹åŒ–ã—ãŸæ·±å±¤ç ”ç©¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ææ¡ˆã€‚åŒ»ç™‚çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’ç”¨ã„ãŸãƒ‡ãƒ¼ã‚¿åˆæˆã¨ã‚«ã‚¹ã‚¿ãƒ åŒ»ç™‚æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’çµ±åˆã—ã€è¤‡é›‘ãªè³ªå•-å›ç­”ãƒšã‚¢ã‚’ç”Ÿæˆã€‚æ–°ãŸãªåŒ»ç™‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã€ä¸€èˆ¬çš„ãªæ·±å±¤ç ”ç©¶ã‚¿ã‚¹ã‚¯ã§ã‚‚ç«¶äº‰åŠ›ã‚’ç¶­æŒã€‚ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹ã®é©æ–°ãŒå°å‹ãƒ¢ãƒ‡ãƒ«ã®å„ªä½æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/AQ-MedAI" target="_blank" rel="noopener noreferrer">https://huggingface.co/AQ-MedAI</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1966647034326253894?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2794" target="_blank" rel="noopener noreferrer">[Paper Note] MedBrowseComp: Benchmarking Medical Deep Research and Computer Use, Shan Chen+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2466" target="_blank" rel="noopener noreferrer">[Paper Note] xbench: Tracking Agents Productivity Scaling with Profession-Aligned
  Real-World Evaluations, Kaiyuan Chen+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1158" target="_blank" rel="noopener noreferrer">GAIA: a benchmark for General AI Assistants, GrÃ©goire Mialon+, N/A, arXiv'23</a>
</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/Privacy.html" target="_blank" rel="noopener noreferrer">#Privacy</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2791" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Laws for Differentially Private Language Models, Ryan McKenna+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã¯LLMã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦æ€§èƒ½å‘ä¸Šã‚’äºˆæ¸¬ã—ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¸æŠã®æŒ‡é‡ã‚’æä¾›ã™ã‚‹ã€‚LLMã¯æ©Ÿå¯†æ€§ã®ã‚ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ã«ä¾å­˜ã—ã€DPãªã©ã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ãŒå¿…è¦ã ãŒã€ãã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã¯æœªè§£æ˜ã€‚æœ¬ç ”ç©¶ã§ã¯ã€DP LLMãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ç¢ºç«‹ã—ã€è¨ˆç®—ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã€ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è€ƒæ…®ã—ãŸæœ€é©ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ§‹æˆã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>blog:


<a href="https://research.google/blog/vaultgemma-the-worlds-most-capable-differentially-private-llm/" target="_blank" rel="noopener noreferrer">https://research.google/blog/vaultgemma-the-worlds-most-capable-differentially-private-llm/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jeffdean/status/1966558317418885132?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2792" target="_blank" rel="noopener noreferrer">Calibrating Noise to Sensitivity in Private Data Analysis, Dwork+, TCC'06</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-09-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2776" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LiveCodeBench: Holistic and Contamination Free Evaluation of Large   Language Models for Code, Naman Jain+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMã®ã‚³ãƒ¼ãƒ‰é–¢é€£èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒLiveCodeBenchã€ã‚’ææ¡ˆã€‚LeetCodeã€AtCoderã€CodeForcesã‹ã‚‰åé›†ã—ãŸ400ã®é«˜å“è³ªãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œã‚’ç”¨ã„ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚„è‡ªå·±ä¿®å¾©ã€ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œãªã©å¤šæ§˜ãªèƒ½åŠ›ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ã€‚18ã®ãƒ™ãƒ¼ã‚¹LLMã¨34ã®æŒ‡ç¤ºèª¿æ•´ã•ã‚ŒãŸLLMã‚’è©•ä¾¡ã—ã€æ±šæŸ“ã‚„éå‰°é©åˆã®å•é¡Œã‚’å®Ÿè¨¼çš„ã«åˆ†æã€‚ã™ã¹ã¦ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚’å…¬é–‹ã—ã€ã•ã‚‰ãªã‚‹åˆ†æã‚„æ–°ã—ã„ã‚·ãƒŠãƒªã‚ªã®è¿½åŠ ã‚’å¯èƒ½ã«ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã‚‚æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2047" target="_blank" rel="noopener noreferrer">[Paper Note] LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive  Programming?, Zihan Zheng+, NeurIPS'25</a>
</p>
<p>pj page:


<a href="https://livecodebench.github.io" target="_blank" rel="noopener noreferrer">https://livecodebench.github.io</a>


</p>
<p>openreview:


<a href="https://openreview.net/forum?id=chfJJYC3iL" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=chfJJYC3iL</a>


</p>
<p>LiveCodeBenchã¯éå¸¸ã«popularãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é–¢é€£ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã ãŒã€readmeã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‚³ãƒãƒ³ãƒ‰é€šã‚Šã«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€stop tokenã«"###"ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’å‡ºåŠ›ã—ãŸLLMã®å‡ºåŠ›ãŒå¸¸ã«truncateã•ã‚Œã‚‹ã¨ã„ã†ãƒã‚°ãŒã‚ã£ãŸæ¨¡æ§˜ã€‚<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nrehiew_/status/1966180838271496247?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2771" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Survey of Reinforcement Learning for Large Reasoning Models, Kaiyan Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€LLMã«ãŠã‘ã‚‹æ¨è«–ã®ãŸã‚ã®å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã®é€²å±•ã‚’èª¿æŸ»ã—ã€ç‰¹ã«æ•°å­¦ã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã®è¤‡é›‘ãªè«–ç†ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹æˆåŠŸã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚RLã¯LLMã‚’å­¦ç¿’æ¨è«–ãƒ¢ãƒ‡ãƒ«ï¼ˆLRMï¼‰ã«å¤‰æ›ã™ã‚‹åŸºç›¤çš„ãªæ–¹æ³•è«–ã¨ã—ã¦æµ®ä¸Šã—ã¦ãŠã‚Šã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã¯è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è¨­è¨ˆãªã©ã®èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚DeepSeek-R1ä»¥é™ã®ç ”ç©¶ã‚’æ¤œè¨ã—ã€LLMãŠã‚ˆã³LRMã«ãŠã‘ã‚‹RLã®é©ç”¨ã«é–¢ã™ã‚‹æœªæ¥ã®æ©Ÿä¼šã¨æ–¹å‘æ€§ã‚’ç‰¹å®šã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/f14bertolotti/status/1966007411719688363?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okhayiea/status/1965989894163235111?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2768" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reconstruction Alignment Improves Unified Multimodal Models, Ji Xie+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- çµ±ä¸€å¤šãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ï¼ˆUMMsï¼‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ãªã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã«ä¾å­˜ã—ã¦ãŠã‚Šã€è¦–è¦šçš„è©³ç´°ã‚’è¦‹é€ƒã™ã“ã¨ãŒå¤šã„ã€‚ãã“ã§ã€å†æ§‹æˆã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆRecAï¼‰ã‚’å°å…¥ã—ã€è¦–è¦šç†è§£ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®åŸ‹ã‚è¾¼ã¿ã‚’ç”¨ã„ã¦ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãªã—ã§è±Šå¯Œãªç›£è¦–ã‚’æä¾›ã€‚RecAã¯UMMã‚’è¦–è¦šç†è§£åŸ‹ã‚è¾¼ã¿ã«æ¡ä»¶ä»˜ã‘ã€è‡ªå·±ç›£è¦–å‹ã®å†æ§‹æˆæå¤±ã§æœ€é©åŒ–ã—ã€ç”Ÿæˆã¨ç·¨é›†ã®å¿ å®Ÿåº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚27 GPUæ™‚é–“ã§ã€ç”»åƒç”Ÿæˆæ€§èƒ½ã‚„ç·¨é›†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã€åŠ¹ç‡çš„ãªãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã¨ã—ã¦ã®åœ°ä½ã‚’ç¢ºç«‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://reconstruction-alignment.github.io" target="_blank" rel="noopener noreferrer">https://reconstruction-alignment.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xdwang101/status/1965908302581420204?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2769" target="_blank" rel="noopener noreferrer">[Paper Note] GenEval: An Object-Focused Framework for Evaluating Text-to-Image   Alignment, Dhruba Ghosh+, NeurIPS'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2770" target="_blank" rel="noopener noreferrer">[Paper Note] ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment, Xiwei Hu+, arXiv'24</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2767" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric  Knowledge, Lukas Haas+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- SimpleQA Verifiedã¯ã€OpenAIã®SimpleQAã«åŸºã¥ã1,000ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€LLMã®çŸ­æ–‡äº‹å®Ÿæ€§ã‚’è©•ä¾¡ã—ã¾ã™ã€‚ãƒã‚¤ã‚ºã®å¤šã„ãƒ©ãƒ™ãƒ«ã‚„ãƒˆãƒ”ãƒƒã‚¯ãƒã‚¤ã‚¢ã‚¹ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€å³å¯†ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµŒã¦ä¿¡é ¼æ€§ã®é«˜ã„è©•ä¾¡ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚Gemini 2.5 Proã¯55.6ã®F1ã‚¹ã‚³ã‚¢ã‚’é”æˆã—ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã¾ã—ãŸã€‚ã“ã®ç ”ç©¶ã¯ã€äº‹å®Ÿæ€§ã®é€²å±•ã‚’è¿½è·¡ã—ã€å¹»è¦šã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>leaderboard:


<a href="https://www.kaggle.com/benchmarks/deepmind/simpleqa-verified" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/benchmarks/deepmind/simpleqa-verified</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1965806183970652368?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2448" target="_blank" rel="noopener noreferrer">[Paper Note] Measuring short-form factuality in large language models, Jason Wei+, arXiv'24</a>
</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2758" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning, Haozhe Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ãã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯ä¸æ˜ã€‚åˆ†æã«ã‚ˆã‚Šã€æ¨è«–ã®éšå±¤ãŒäººé–“ã®èªçŸ¥ã«ä¼¼ãŸäºŒæ®µéšã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’æŒã¤ã“ã¨ã‚’ç™ºè¦‹ã€‚åˆæœŸæ®µéšã§ã¯æ‰‹ç¶šãçš„ãªæ­£ç¢ºæ€§ãŒæ±‚ã‚ã‚‰ã‚Œã€å¾Œã«é«˜ãƒ¬ãƒ™ãƒ«ã®æˆ¦ç•¥çš„è¨ˆç”»ãŒé‡è¦ã«ãªã‚‹ã€‚ã“ã‚Œã«åŸºã¥ãã€HICRAã¨ã„ã†ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã—ã€é«˜å½±éŸ¿ã®è¨ˆç”»ãƒˆãƒ¼ã‚¯ãƒ³ã«æœ€é©åŒ–ã‚’é›†ä¸­ã•ã›ã‚‹ã“ã¨ã§æ€§èƒ½ã‚’å‘ä¸Šã•ã›ãŸã€‚ã¾ãŸã€æ„å‘³çš„ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒæˆ¦ç•¥çš„æ¢æ±‚ã®å„ªã‚ŒãŸæŒ‡æ¨™ã§ã‚ã‚‹ã“ã¨ã‚’æ¤œè¨¼ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://tiger-ai-lab.github.io/Hierarchical-Reasoner/" target="_blank" rel="noopener noreferrer">https://tiger-ai-lab.github.io/Hierarchical-Reasoner/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1965783045035762076?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2757" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Staying in the Sweet Spot: Responsive Reasoning Evolution via  Capability-Adaptive Hint Scaffolding, Ziheng Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RLVRã¯LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®é›£æ˜“åº¦ã¨ãƒ¢ãƒ‡ãƒ«èƒ½åŠ›ã®ä¸ä¸€è‡´ã«ã‚ˆã‚Šæ¢ç´¢ãŒéåŠ¹ç‡çš„ã€‚æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯SEELEã‚’ææ¡ˆã—ã€å•é¡Œã®é›£æ˜“åº¦ã‚’å‹•çš„ã«èª¿æ•´ã€‚ãƒ’ãƒ³ãƒˆã®é•·ã•ã‚’é©å¿œçš„ã«èª¿æ•´ã—ã€æ¢ç´¢åŠ¹ç‡ã‚’å‘ä¸Šã€‚å®Ÿé¨“ã§ã¯SEELEãŒå¾“æ¥æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://github.com/ChillingDream/seele" target="_blank" rel="noopener noreferrer">https://github.com/ChillingDream/seele</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1965632380112453870?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å•é¡Œã®é›£æ˜“åº¦ã‚’ãƒ’ãƒ³ãƒˆã«ã‚ˆã£ã¦èª¿æ•´ã—ã¤ã¤ï¼ˆIRTã§å›°é›£åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¦‹ã‚‹ã¨æ€ã‚ã‚Œã‚‹ï¼‰RLã™ã‚‹æ¨¡æ§˜ã€‚é¢ç™½ãã†ã€‚<br><img src="https://github.com/user-attachments/assets/f7322e4a-289f-48ca-8910-257b5544f39a" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2754" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents, Junteng Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æƒ…å ±æ¢ç´¢ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€WebExplorerã¨ã„ã†ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®æ¢ç´¢æ‰‹æ³•ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¤‡é›‘ãªã‚¯ã‚¨ãƒª-å›ç­”ãƒšã‚¢ã‚’ç”Ÿæˆã—ã€é«˜åº¦ãªã‚¦ã‚§ãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆWebExplorer-8Bã‚’é–‹ç™ºã€‚128Kã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’æŒã¡ã€æœ€å…ˆç«¯ã®æƒ…å ±æ¢ç´¢ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚ç‰¹ã«ã€WebExplorer-8Bã¯ä»–ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ç²¾åº¦ã‚’ç¤ºã—ã€é•·æœŸçš„ãªå•é¡Œè§£æ±ºã«å‘ã‘ãŸå®Ÿç”¨çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æä¾›ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1965537550937792934?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è©•ä¾¡ã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2451" target="_blank" rel="noopener noreferrer">[Paper Note] BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents, Jason Wei+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1730" target="_blank" rel="noopener noreferrer">[Paper Note] Humanity's Last Exam, Long Phan+, arXiv'25</a>
</p>
<p>å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®åˆæˆæ–¹æ³•ãŒè‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2753" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Parallel-R1: Towards Parallel Thinking via Reinforcement Learning, Tong Zheng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Parallel-R1ã¯ã€è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ä¸¦åˆ—æ€è€ƒã‚’å¯èƒ½ã«ã™ã‚‹å¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆå•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®é€²è¡Œçš„ãªã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã‚’æ¡ç”¨ã€‚ç°¡å˜ãªã‚¿ã‚¹ã‚¯ã‹ã‚‰å§‹ã‚ã€ä¸¦åˆ—æ€è€ƒèƒ½åŠ›ã‚’æ¤ãˆä»˜ã‘ãŸå¾Œã€é›£ã—ã„å•é¡Œã«ç§»è¡Œã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€å¾“æ¥ã®é€æ¬¡æ€è€ƒãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦8.4%ã®ç²¾åº¦å‘ä¸Šã‚’é”æˆã—ã€ä¸¦åˆ—æ€è€ƒãŒä¸­é–“ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¢ç´¢ã®è¶³å ´ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1965631715235525006?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>çµæœã®è¡¨ã‚’è¦‹ã‚‹ã¨ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§å˜ã«self Consistencyã‚’å®Ÿæ–½ã™ã‚‹ã‚ˆã‚Šã‚‚é«˜ã„ã‚²ã‚¤ãƒ³ã‚’å¾—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ãŒQwen3ã®ã¿ã§ã—ã‹å®Ÿé¨“ã•ã‚Œã¦ãŠã‚‰ãšã€Qwen2.5ã«ãŠã„ã¦ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã®ç–‘ã„ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2226" target="_blank" rel="noopener noreferrer">[Paper Note] Reasoning or Memorization? Unreliable Results of Reinforcement Learning  Due to Data Contamination, Mingqi Wu+, arXiv'25</a>
 ãŒã‚ã£ãŸã®ã§ã€(Qwen3ãŒã©ã†ã‹ã¯ã‚ã‹ã‚‰ãªã„ãŒ)å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§ã¯ãªãã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚å®Ÿé¨“ã—ãŸæ–¹ãŒè‰¯ã„ã®ã‹ãªã€ã¨ã„ã†å°è±¡ã€‚</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1965691174813089987?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1968939351427158459?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2751" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] An AI system to help scientists write expert-level empirical software, Eser AygÃ¼n+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AIã‚·ã‚¹ãƒ†ãƒ ã‚’ç”¨ã„ã¦è³ªã®æŒ‡æ¨™ã‚’æœ€å¤§åŒ–ã™ã‚‹å°‚é–€çš„ãªç§‘å­¦ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’ç”Ÿæˆã€‚å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¨æœ¨æ¢ç´¢ã‚’æ´»ç”¨ã—ã€è¤‡é›‘ãªç ”ç©¶ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’çµ±åˆã€‚ãƒã‚¤ã‚ªã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã‚„ç–«å­¦ã®åˆ†é‡ã§æ–°ã—ã„æ‰‹æ³•ã‚’ç™ºè¦‹ã—ã€æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æˆæœã‚’é”æˆã€‚å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ–°ã—ã„è§£æ±ºç­–ã‚’æä¾›ã—ã€ç§‘å­¦çš„é€²æ­©ã‚’åŠ é€Ÿã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1965253577221587218?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2749" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual  Search, Xin Lai+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Mini-o3ã‚·ã‚¹ãƒ†ãƒ ã¯ã€æ•°åã‚¹ãƒ†ãƒƒãƒ—ã®æ·±ã„ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³æ¨è«–ã‚’å®Ÿç¾ã—ã€è¦–è¦šæ¤œç´¢ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚Visual Probe Datasetã‚’æ§‹ç¯‰ã—ã€å¤šæ§˜ãªæ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã™ãƒ‡ãƒ¼ã‚¿åé›†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é–‹ç™ºã€‚ã‚ªãƒ¼ãƒãƒ¼ã‚¿ãƒ¼ãƒ³ãƒã‚¹ã‚­ãƒ³ã‚°æˆ¦ç•¥ã«ã‚ˆã‚Šã€ã‚¿ãƒ¼ãƒ³æ•°ãŒå¢—ãˆã‚‹ã»ã©ç²¾åº¦ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/Mini-o3" target="_blank" rel="noopener noreferrer">https://huggingface.co/Mini-o3</a>


</p>
<p>pj page:


<a href="https://mini-o3.github.io" target="_blank" rel="noopener noreferrer">https://mini-o3.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1965616579024228527?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¢å­˜ã®ã‚ªãƒ¼ãƒ—ãƒ³ãªVLMã¯ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®ã‚¿ãƒ¼ãƒ³æ•°ã‚’å¢—ã‚„ã›ãªã„ã¨ã„ã†èª²é¡ŒãŒã‚ã£ãŸãŒãã‚Œã‚’å…‹æœã™ã‚‹ãƒ¬ã‚·ãƒ”ã«é–¢ã™ã‚‹ç ”ç©¶ãªæ¨¡æ§˜ã€‚å…ƒãƒã‚¹ãƒˆã«ã‚ˆã‚‹ã¨6ã‚¿ãƒ¼ãƒ³ã¾ã§ã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã§å­¦ç¿’ã—ã¦ã‚‚ã€inferenceæ™‚ã«ã¯32ã‚¿ãƒ¼ãƒ³ã¾ã§ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã¨ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ContextWindow.html" target="_blank" rel="noopener noreferrer">#ContextWindow</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2748" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Efficient Context Selection for Long-Context QA: No Tuning, No  Iteration, Just Adaptive-$k$, Chihiro Taguchi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Adaptive-$k$ retrievalã‚’ææ¡ˆã—ã€ã‚¯ã‚¨ãƒªã¨å€™è£œãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ã®é¡ä¼¼åº¦ã«åŸºã¥ã„ã¦é©å¿œçš„ã«ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸æ•°ã‚’é¸æŠã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å›ºå®šã‚µã‚¤ã‚ºã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç™ºæ®ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’æœ€å¤§10å€å‰Šæ¸›ã—ã¤ã¤70%ã®é–¢é€£ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—ã€‚LCLMsã¨åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã§ç²¾åº¦å‘ä¸Šã‚’å®Ÿç¾ã—ã€å‹•çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºèª¿æ•´ãŒåŠ¹ç‡çš„ãªQAã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/megagonlabs/status/1965430004667613305?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å®Ÿå‹™ä¸Šã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã‚‰ã‚Œã‚‹ã®ã¯éå¸¸ã«å¬‰ã—ã„ã€‚ã‚ã¨ã§èª­ã‚€ã€‚</p></span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Medical.html" target="_blank" rel="noopener noreferrer">#Medical</a>
<a class="button" href="articles/Biological.html" target="_blank" rel="noopener noreferrer">#Biological</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2747" target="_blank" rel="noopener noreferrer" class="title-link">BioML-bench: Evaluation of AI Agents for End-to-End Biomedical ML, Miller+, bioRxiv'25</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bowang87/status/1965559595793088725?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Biomedicalãƒ‰ãƒ¡ã‚¤ãƒ³ã«ãŠã‘ã‚‹24ç¨®é¡ã®éå¸¸ã«è¤‡é›‘ã§nuancedãªè¨˜è¿°ã‚„ç”»åƒã®èª­ã¿å–ã‚Šãªã©ã‚’å«ã‚€å®Ÿã‚¿ã‚¹ã‚¯ã«ã‚ˆã£ã¦æ§‹æˆã•ã‚Œã‚‹åˆã‚ã¦ã®Agenticãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2744" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] mmBERT: A Modern Multilingual Encoder with Annealed Language Learning, Marc Marone+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- mmBERTã¯ã€1800ä»¥ä¸Šã®è¨€èªã§3å…†ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦äº‹å‰å­¦ç¿’ã•ã‚ŒãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å°‚ç”¨ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ä½ãƒªã‚½ãƒ¼ã‚¹è¨€èªã‚’çŸ­ã„æ¸›è¡°ãƒ•ã‚§ãƒ¼ã‚ºã«å«ã‚ã‚‹ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ãŸã€‚æ–°ã—ã„è¦ç´ ã‚’å°å…¥ã—ã€OpenAIã®o3ã‚„Googleã®Gemini 2.5 Proã¨åŒç­‰ã®åˆ†é¡æ€§èƒ½ã‚’é”æˆã€‚mmBERTã¯åˆ†é¡ãŠã‚ˆã³æ¤œç´¢ã‚¿ã‚¹ã‚¯ã§ä»¥å‰ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>blog:


<a href="https://huggingface.co/blog/mmbert" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/mmbert</a>


<br>HF:


<a href="https://huggingface.co/jhu-clsp/mmBERT-checkpoints" target="_blank" rel="noopener noreferrer">https://huggingface.co/jhu-clsp/mmBERT-checkpoints</a>


</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1761" target="_blank" rel="noopener noreferrer">modernbert-ja-130m, SB Intuitions, 2025.02</a>
<br><br>ã¨æ¯”è¼ƒã—ã¦æ—¥æœ¬èªã®æ€§èƒ½ã¯ã©ã†ã‹ãªã‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ruyimarone/status/1965409895584522330?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1965563064067011053?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2742" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Talk Isn't Always Cheap: Understanding Failure Modes in Multi-Agent  Debate, Andrea Wynn+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆã¯AIã®æ¨è«–èƒ½åŠ›å‘ä¸Šã«æœ‰æœ›ã ãŒã€æ™‚ã«ã¯æœ‰å®³ã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã€‚å¾“æ¥ã®ç ”ç©¶ãŒåŒè³ªã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ä¸­ã€ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã®å¤šæ§˜æ€§ãŒç›¸äº’ä½œç”¨ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’æ¢æ±‚ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆãŒç²¾åº¦ä½ä¸‹ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ã‚’ç¤ºã—ã€å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã§ã‚‚å¼±ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹çŠ¶æ³ã§åŒæ§˜ã®çµæœãŒå¾—ã‚‰ã‚ŒãŸã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯èª¤ã£ãŸç­”ãˆã«ã‚·ãƒ•ãƒˆã—ã€åˆæ„ã‚’å„ªå…ˆã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã€ã“ã‚ŒãŒãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆã®åŠ¹æœã‚’æãªã†ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1965446892948783131?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ƒãƒã‚¹ãƒˆã‚’èª­ã‚“ã é™ã‚Šã€ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã«debateã‚’ã•ã›ã¦ã‚‚å¿…ãšã—ã‚‚æ€§èƒ½æ”¹å–„ã™ã‚‹ã‚ã‘ã§ã¯ãªã„ã‚ˆã€ã¨ã„ã†è©±ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚<br>è¤‡æ•°ã®strong llmã®ä¸­ã«weak llmãŒæ··åœ¨ã™ã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ã¯ãŠã¹ã£ã‹ã«ã‚ˆã£ã¦åŒæ„ã™ã‚‹ã‚ˆã†ã«alignmentã•ã‚Œã‚‹å‚¾å‘ãŒã‚ã‚‹ã®ã§ã€è‰¯ã„æ–¹å‘ã«è­°è«–ãŒåæŸã™ã‚‹ã¨ã¯é™ã‚‰ãšã€ã‚³ãƒ³ã‚»ãƒ³ã‚µã‚¹ã‚’ã¨ã‚‹ã‚ˆã†ãªä»•çµ„ã¿ã§ã¯ãªãã€æ‰¹åˆ¤ã‚’ã™ã‚‹å½¹ç›®ã‚’è¨­ã‘ã‚‹ã‚ˆã†ã«è¨­è¨ˆã™ã‚‹ãªã©ã®å·¥å¤«ãŒå¿…è¦ã€ã¨ã„ã†ã‚ˆã†ãªè©±ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2740" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reverse-Engineered Reasoning for Open-Ended Generation, Haozhe Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- REERã¨ã„ã†æ–°ã—ã„æ¨è«–ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ææ¡ˆã—ã€æ—¢å­˜ã®è‰¯å¥½ãªè§£ã‹ã‚‰å¾Œæ–¹ã«æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ§‹ç¯‰ã€‚20,000ã®æ·±ã„æ¨è«–è»Œè·¡ã‹ã‚‰ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆDeepWriting-20Kã‚’ä½œæˆã—ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã€‚è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«DeepWriter-8Bã¯ã€å¼·åŠ›ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’è¶…ãˆã€GPT-4oã‚„Claude 3.5ã¨ç«¶äº‰åŠ›ã®ã‚ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://m-a-p.ai/REER_DeepWriter/" target="_blank" rel="noopener noreferrer">https://m-a-p.ai/REER_DeepWriter/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gezhang86038849/status/1965320156667949307?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2025-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2736" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Are We Done with MMLU?, Aryo Pradipta Gema+, NAACL'25</a>
<span class="snippet"><span>GPT Summary</span>- MMLUãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚¨ãƒ©ãƒ¼ã‚’åˆ†æã—ã€ã‚¦ã‚¤ãƒ«ã‚¹å­¦ã®ã‚µãƒ–ã‚»ãƒƒãƒˆã§ã¯57%ã®è³ªå•ã«ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚æ–°ã—ã„ã‚¨ãƒ©ãƒ¼æ³¨é‡ˆãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ç”¨ã„ã¦MMLU-Reduxã‚’ä½œæˆã—ã€6.49%ã®è³ªå•ã«ã‚¨ãƒ©ãƒ¼ãŒå«ã¾ã‚Œã‚‹ã¨æ¨å®šã€‚MMLU-Reduxã‚’é€šã˜ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨ã®ä¸ä¸€è‡´ã‚’ç¤ºã—ã€MMLUã®ä¿¡é ¼æ€§å‘ä¸Šã‚’ææ¡ˆã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/Non-Determinism.html" target="_blank" rel="noopener noreferrer">#Non-Determinism</a>
<span class="issue_date">Issue Date: 2025-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2735" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore   Non-Determinism, Yifan Song+, NAACL'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®è©•ä¾¡ã¯éæ±ºå®šæ€§ã‚’è¦‹è½ã¨ã—ãŒã¡ã§ã€å˜ä¸€å‡ºåŠ›ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ãŸã‚æ€§èƒ½ã®å¤‰å‹•ç†è§£ãŒåˆ¶é™ã•ã‚Œã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€è²ªæ¬²ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®æ€§èƒ½å·®ã‚’æ¢æ±‚ã—ã€éæ±ºå®šæ€§ã«é–¢ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ä¸€è²«æ€§ã‚’ç‰¹å®šã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€è²ªæ¬²ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒå¤šãã®ã‚¿ã‚¹ã‚¯ã§å„ªã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãŒã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®åˆ†æ•£ã‚’æ¸›å°‘ã•ã›ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€å°å‹LLMãŒå¤§å‹ãƒ¢ãƒ‡ãƒ«ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’æŒã¤ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã€LLMè©•ä¾¡ã«ãŠã‘ã‚‹éæ±ºå®šæ€§ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1890" target="_blank" rel="noopener noreferrer">Non-Determinism of "Deterministic" LLM Settings, Berk Atil+, arXiv'24</a>
<br><br>åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2736" target="_blank" rel="noopener noreferrer">[Paper Note] Are We Done with MMLU?, Aryo Pradipta Gema+, NAACL'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2737" target="_blank" rel="noopener noreferrer">AlpacaEval, tatsu-lab, 2023.06</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2739" target="_blank" rel="noopener noreferrer">[Paper Note] MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures, Jinjie Ni+, NeurIPS'24</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2738" target="_blank" rel="noopener noreferrer">From Live Data to High-Quality Benchmarks: The Arena-Hard Pipeline, Li+, 2024.04</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1618" target="_blank" rel="noopener noreferrer">Training Verifiers to Solve Math Word Problems, Karl Cobbe+, arXiv'21</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2438" target="_blank" rel="noopener noreferrer">[Paper Note] Evaluating Large Language Models Trained on Code, Mark Chen+, arXiv'21</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Aggregation-aware.html" target="_blank" rel="noopener noreferrer">#Aggregation-aware</a>
<span class="issue_date">Issue Date: 2025-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2729" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Majority is not always right: RL training for solution aggregation, Wenting Zhao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¤‡æ•°ã®è§£ã‚’ç”Ÿæˆã—ã€ãã‚Œã‚’é›†ç´„ã™ã‚‹ã“ã¨ã§LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã™ã‚‹ã€‚å¾“æ¥ã®æ–¹æ³•ã«ä»£ã‚ã‚Šã€é›†ç´„ã‚’æ˜ç¤ºçš„ãªæ¨è«–ã‚¹ã‚­ãƒ«ã¨ã—ã¦å­¦ç¿’ã—ã€å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦æ­£ã—ã„ç­”ãˆã‚’èª¿æ•´ãƒ»åˆæˆã™ã‚‹ã€‚ç°¡å˜ãªä¾‹ã¨é›£ã—ã„ä¾‹ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã¯å°‘æ•°æ´¾ã®æ­£ã—ã„ç­”ãˆã‚’å›å¾©ã™ã‚‹èƒ½åŠ›ã‚’ç²å¾—ã€‚ææ¡ˆæ‰‹æ³•AggLMã¯ã€è¤‡æ•°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã€å°‘ãªã„ãƒˆãƒ¼ã‚¯ãƒ³ã§åŠ¹æœçš„ã«ä¸€èˆ¬åŒ–ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1965233976949543194?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1965556816647164055?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wzhao_nlp/status/1966784672706256896?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1968870421882896891?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2726" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SpikingBrain Technical Report: Spiking Brain-inspired Large Models, Yuqi Pan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- SpikingBrainã¯ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®åŠ¹ç‡çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸè„³ã«ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§ã€MetaX GPUã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’æ´»ç”¨ã€‚ç·šå½¢ãŠã‚ˆã³ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç·šå½¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã—ã€éNVIDIAãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ä¸Šã§ã®å¤§è¦æ¨¡LLMé–‹ç™ºã‚’å®Ÿç¾ã€‚SpikingBrain-7Bã¨SpikingBrain-76Bã‚’é–‹ç™ºã—ã€ç´„150Bãƒˆãƒ¼ã‚¯ãƒ³ã§ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®Transformerã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ã‚’å¤§å¹…ã«æ”¹å–„ã—ã€ä½æ¶ˆè²»é›»åŠ›ã§ã®é‹ç”¨ã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/f14bertolotti/status/1964949822429069761?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>TTFTãŒ4Mã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ™‚ã«Qwen2.5ã¨æ¯”ã¹ã¦100å€é«˜é€ŸåŒ–â€¦ï¼Ÿ</p>
<p>ä¸­å›½ã®MetaXç¤¾ã®GPUãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>


<a href="https://www.metax-tech.com/en/goods/prod.html?cid=3" target="_blank" rel="noopener noreferrer">https://www.metax-tech.com/en/goods/prod.html?cid=3</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/SpeculativeDecoding.html" target="_blank" rel="noopener noreferrer">#SpeculativeDecoding</a>
<span class="issue_date">Issue Date: 2025-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2716" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] REFRAG: Rethinking RAG based Decoding, Xiaoqiang Lin+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- REFRAGã¯ã€RAGã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹é…å»¶ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®åŠ¹ç‡çš„ãªãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ã‚¹ãƒ‘ãƒ¼ã‚¹æ§‹é€ ã‚’åˆ©ç”¨ã—ã¦åˆå›ãƒˆãƒ¼ã‚¯ãƒ³ã¾ã§ã®æ™‚é–“ã‚’30.85å€åŠ é€Ÿã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºã‚’16ã¾ã§æ‹¡å¼µå¯èƒ½ã«ã—ã€ã•ã¾ã–ã¾ãªé•·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã§ç²¾åº¦ã‚’æãªã†ã“ã¨ãªãã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dr_singularity/status/1964453705430036982?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>èˆˆå‘³æ·±ã„ã€‚Speculative Decodingã®æ–°æ‰‹æ³•ã¨ã‚‚ã¿ãªã›ãã†ã€‚</p>
<p>åŒæ™‚æœŸã«å‡ºãŸä¸‹è¨˜ç ”ç©¶ã¨æ¯”è¼ƒã—ã¦ã©ã®ã‚ˆã†ãªpros/consãŒã‚ã‚‹ã ã‚ã†ã‹ï¼Ÿ<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2699" target="_blank" rel="noopener noreferrer">[Paper Note] Set Block Decoding is a Language Model Inference Accelerator, Itai Gat+, arXiv'25</a>
</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1966292095242744186?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2713" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RL's Razor: Why Online Reinforcement Learning Forgets Less, Idan Shenfeld+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã¨æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã®æ¯”è¼ƒã«ã‚ˆã‚Šã€RLãŒä»¥å‰ã®çŸ¥è­˜ã‚’ã‚ˆã‚Šè‰¯ãä¿æŒã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚å¿˜å´ã®ç¨‹åº¦ã¯åˆ†å¸ƒã®ã‚·ãƒ•ãƒˆã«ã‚ˆã£ã¦æ±ºã¾ã‚Šã€KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã§æ¸¬å®šã•ã‚Œã‚‹ã€‚RLã¯æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦KLæœ€å°è§£ã«ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã‚‹ä¸€æ–¹ã€SFTã¯ä»»æ„ã®è·é›¢ã«åæŸã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚å®Ÿé¨“ã‚’é€šã˜ã¦ã€RLã®æ›´æ–°ãŒå°ã•ãªKLå¤‰åŒ–ã‚’ã‚‚ãŸã‚‰ã™ç†ç”±ã‚’ç†è«–çš„ã«èª¬æ˜ã—ã€ã€ŒRLã®å‰ƒåˆ€ã€ã¨å‘¼ã¶åŸå‰‡ã‚’æå”±ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jyo_pari/status/1963967312555332065?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stone_tao/status/1964381652106563591?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1963823603469730114?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2710" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SWE-rebench: An Automated Pipeline for Task Collection and  Decontaminated Evaluation of Software Engineering Agents, Ibragim Badertdinov+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®SWEã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹èª²é¡Œã¨ã—ã¦ã€é«˜å“è³ªãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ä¸è¶³ã¨æ–°é®®ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚¿ã‚¹ã‚¯ã®æ¬ å¦‚ãŒæŒ™ã’ã‚‰ã‚Œã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€21,000ä»¥ä¸Šã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªPythonãƒ™ãƒ¼ã‚¹ã®SWEã‚¿ã‚¹ã‚¯ã‚’å«ã‚€å…¬çš„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆSWE-rebenchã‚’è‡ªå‹•åŒ–ã•ã‚ŒãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§æ§‹ç¯‰ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¼·åŒ–å­¦ç¿’ã«é©ã—ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æä¾›ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ±šæŸ“ã®ãªã„è©•ä¾¡ãŒå¯èƒ½ã¨ãªã‚Šã€ã„ãã¤ã‹ã®LLMã®æ€§èƒ½ãŒéå¤§è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://swe-rebench.com" target="_blank" rel="noopener noreferrer">https://swe-rebench.com</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1963947072748412990?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã®ãªã„æœ€æ–°ã®Issueã‚’ç”¨ã„ã¦è©•ä¾¡ã—ãŸçµæœã€Sonnet 4ãŒæœ€ã‚‚é«˜æ€§èƒ½</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2702" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow  Real Instructions?, Qinyan Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¾“ã†ã“ã¨ã«è‹¦åŠ´ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ã“ã‚Œã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€Inverse IFEvalã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ãƒ¢ãƒ‡ãƒ«ãŒå¯¾ç«‹ã™ã‚‹æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ã€‚8ç¨®é¡ã®èª²é¡Œã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã€æ—¢å­˜ã®LLMã«å¯¾ã™ã‚‹å®Ÿé¨“ã‚’è¡Œã£ãŸçµæœã€éå¾“æ¥ã®æ–‡è„ˆã§ã®é©å¿œæ€§ã‚‚è€ƒæ…®ã™ã¹ãã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚Inverse IFEvalã¯ã€LLMã®æŒ‡ç¤ºéµå®ˆã®ä¿¡é ¼æ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1963822451550208101?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>èˆˆå‘³æ·±ã„</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2700" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Towards a Unified View of Large Language Model Post-Training, Xingtai Lv+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã¨ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒã€çŸ›ç›¾ã›ãšå˜ä¸€ã®æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚çµ±ä¸€ãƒãƒªã‚·ãƒ¼å‹¾é…æ¨å®šå™¨ã‚’å°å‡ºã—ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆHPTï¼‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã€‚HPTã¯ç•°ãªã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¿¡å·ã‚’å‹•çš„ã«é¸æŠã—ã€ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åŠ¹æœçš„ã«æ´»ç”¨ã—ã¤ã¤å®‰å®šã—ãŸæ¢ç´¢ã‚’å®Ÿç¾ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€HPTãŒæ•°å­¦çš„æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¼·åŠ›ãªæ€§èƒ½ã‚’ç¤ºã™ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1963818963550572623?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1963971173735448858?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2699" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Set Block Decoding is a Language Model Inference Accelerator, Itai Gat+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Set Block Decodingï¼ˆSBDï¼‰ã‚’ææ¡ˆã—ã€æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã¨ãƒã‚¹ã‚¯ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã‚’çµ±åˆã—ã¦ç”Ÿæˆã‚’åŠ é€Ÿã€‚SBDã¯è¤‡æ•°ã®æœªæ¥ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä¸¦è¡Œã—ã¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å¯èƒ½ã§ã€å¾“æ¥ã®æ‰‹æ³•ã‚ˆã‚Šã‚‚é€Ÿåº¦å‘ä¸Šã‚’å®Ÿç¾ã€‚ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¤‰æ›´ãªã—ã§æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã®æ•°ã‚’3-5å€å‰Šæ¸›ã—ã¤ã¤åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1963817987506643350?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/DialogueGeneration.html" target="_blank" rel="noopener noreferrer">#DialogueGeneration</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2697" target="_blank" rel="noopener noreferrer" class="title-link">Multi-Relational Multi-Party Chat Corpus: è©±è€…é–“ã®é–¢ä¿‚æ€§ã«ç€ç›®ã—ãŸãƒãƒ«ãƒãƒ‘ãƒ¼ãƒ†ã‚£é›‘è«‡å¯¾è©±ã‚³ãƒ¼ãƒ‘ã‚¹, æ´¥ç”°+, NLP'25</a>
<span class="snippet"><span>Comment</span><p>ã‚³ãƒ¼ãƒ‘ã‚¹:


<a href="https://github.com/nu-dialogue/multi-relational-multi-party-chat-corpus" target="_blank" rel="noopener noreferrer">https://github.com/nu-dialogue/multi-relational-multi-party-chat-corpus</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yamasy1549/status/1963799248362709348?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>3äººä»¥ä¸Šã®ãƒãƒ«ãƒãƒ‘ãƒ¼ãƒ†ã‚£ã«å¯¾å¿œã—ãŸãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚³ãƒ¼ãƒ‘ã‚¹ã§ã€è©±è€…é–“ã®é–¢ä¿‚æ€§ã¨ã—ã¦ã€Œåˆå¯¾é¢ã€ã¨ã€Œå®¶æ—ã€ã«ç€ç›®ã—ã€åˆå¯¾é¢å¯¾è©±ã‚„å®¶æ—å…¥ã‚Šå¯¾è©±ã®2ç¨®é¡ã®å¯¾è©±ã‚’åé›†ã—ãŸã‚³ãƒ¼ãƒ‘ã‚¹ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2696" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn  Reinforcement Learning, Haoming Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- UI-TARS-2ã¯ã€GUIç”¨è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã§ã€ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã€å®‰å®šåŒ–ã•ã‚ŒãŸãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³RLã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰GUIç’°å¢ƒã‚’çµ±åˆã€‚å®Ÿè¨¼è©•ä¾¡ã§ã¯ã€å‰ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€è¤‡æ•°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é«˜ã„ã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚ç´„60%ã®äººé–“ãƒ¬ãƒ™ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€é•·æœŸçš„ãªæƒ…å ±æ¢ç´¢ã‚¿ã‚¹ã‚¯ã«ã‚‚é©å¿œå¯èƒ½ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã®åˆ†æãŒå®‰å®šæ€§ã¨åŠ¹ç‡å‘ä¸Šã®æ´å¯Ÿã‚’æä¾›ã—ã€å®Ÿä¸–ç•Œã®ã‚·ãƒŠãƒªã‚ªã¸ã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1896" target="_blank" rel="noopener noreferrer">Introducing UI-TARS-1.5, ByteDance, 2025.04</a>
</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1963783886565183913?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>1.5ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¦ã‹ã‚‰5ãƒ¶æœˆã§å¤§å¹…ã«æ€§èƒ½ã‚’å‘ä¸Šã—ãŸæ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Critic.html" target="_blank" rel="noopener noreferrer">#Critic</a>
<span class="issue_date">Issue Date: 2025-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2683" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model, Xiyao Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¦–è¦šã¨è¨€èªã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«ãŠã„ã¦ã€æ‰¹è©•ãƒ¢ãƒ‡ãƒ«ã‚’å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦å†ç·¨æˆã—ã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã«ç›´æ¥é©ç”¨ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ‰¹è©•ãƒ¢ãƒ‡ãƒ«LLaVA-Critic-R1ã‚’ç”Ÿæˆã—ã€è¦–è¦šçš„æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€è‡ªå·±æ‰¹è©•ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€è¿½åŠ ã®è¨“ç·´ãªã—ã«æ¨è«–ã‚¿ã‚¹ã‚¯ã§ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã“ã®çµæœã¯ã€è©•ä¾¡ã¨ç”Ÿæˆã®ä¸¡æ–¹ã«å„ªã‚ŒãŸçµ±ä¸€ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿç¾ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1963248881027748265?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/collections/lmms-lab/llava-critic-r1-68922484e5822b89fab4aca1" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/lmms-lab/llava-critic-r1-68922484e5822b89fab4aca1</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2678" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Benchmarking Optimizers for Large Language Model Pretraining, Andrei Semenov+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®LLMsã®ç™ºå±•ã«ä¼´ã„ã€æœ€é©åŒ–æ‰‹æ³•ã®å¤šæ§˜ãªä¸»å¼µãŒã‚ã‚‹ãŒã€å®Ÿé¨“ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®é•ã„ã«ã‚ˆã‚Šæ¯”è¼ƒãŒé›£ã—ã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ¨™æº–åŒ–ã•ã‚ŒãŸLLMã®äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹æœ€é©åŒ–æŠ€è¡“ã‚’è©•ä¾¡ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚„ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å¤‰åŒ–ã•ã›ã¦æœ€é©ãªã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã‚’ææ¡ˆã€‚ç ”ç©¶ãŒå°†æ¥ã®æœ€é©åŒ–ç ”ç©¶ã®æ–¹å‘æ€§ã‚’ç¤ºã—ã€ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã§å†ç¾æ€§ã‚’ç¢ºä¿ã—ã€æ‰‹æ³•ã®é–‹ç™ºã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haeggee/status/1963217456740139103?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2674" target="_blank" rel="noopener noreferrer">[Paper Note] Fantastic Pretraining Optimizers and Where to Find Them, Kaiyue Wen+, arXiv'25</a>
<br><br>ä¸Šè¨˜è«–æ–‡ã¨çŸ¥è¦‹ãŒä¸€è‡´ã™ã‚‹éƒ¨åˆ†ã€ç•°ãªã‚‹éƒ¨åˆ†ã¯ä½•ã ã‚ã†ã‹ï¼Ÿ</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2666" target="_blank" rel="noopener noreferrer">APERTUS: DEMOCRATIZING OPEN AND COMPLIANT LLMS FOR GLOBAL LANGUAGE ENVIRONMENTS, Apertus Team, 2025.09</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2677" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Jointly Reinforcing Diversity and Quality in Language Model Generations, Tianjian Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- DARLINGã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€å¿œç­”ã®è³ªã¨æ„å‘³çš„å¤šæ§˜æ€§ã‚’æœ€é©åŒ–ã€‚å­¦ç¿’ã•ã‚ŒãŸåˆ†å‰²é–¢æ•°ã‚’ç”¨ã„ã¦å¤šæ§˜æ€§ã‚’æ¸¬å®šã—ã€è³ªã®å ±é…¬ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§é«˜å“è³ªã‹ã¤ç‹¬è‡ªæ€§ã®ã‚ã‚‹å‡ºåŠ›ã‚’ç”Ÿæˆã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€éæ¤œè¨¼å¯èƒ½ãªã‚¿ã‚¹ã‚¯ã¨æ¤œè¨¼å¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®ä¸¡æ–¹ã§å„ªã‚ŒãŸçµæœã‚’ç¤ºã—ã€ç‰¹ã«å¤šæ§˜æ€§ã®æœ€é©åŒ–ãŒæ¢ç´¢ã‚’ä¿ƒé€²ã—ã€è³ªã®å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1963230744173482018?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wyu_nd/status/1969134210578596014?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2676" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GSO: Challenging Software Optimization Tasks for Evaluating SWE-Agents, Manish Shetty+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- é«˜æ€§èƒ½ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã«ãŠã‘ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯GSOã‚’ææ¡ˆã€‚102ã®æœ€é©åŒ–ã‚¿ã‚¹ã‚¯ã‚’ç‰¹å®šã™ã‚‹è‡ªå‹•åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é–‹ç™ºã—ã€ä¸»è¦ãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æˆåŠŸç‡ã¯5%æœªæº€ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚å®šæ€§çš„åˆ†æã«ã‚ˆã‚Šã€ä½ãƒ¬ãƒ™ãƒ«è¨€èªã‚„æœ€é©åŒ–æˆ¦ç•¥ã®èª²é¡ŒãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚ç ”ç©¶ã®é€²å±•ã®ãŸã‚ã«ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚³ãƒ¼ãƒ‰ã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://gso-bench.github.io" target="_blank" rel="noopener noreferrer">https://gso-bench.github.io</a>


</p>
<p>ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®é«˜é€ŸåŒ–ã«é–¢ã™ã‚‹ãƒ™ãƒ³ãƒ</p>
<p>å…ƒãƒã‚¹ãƒˆã«æ²è¼‰ã•ã‚Œã¦ã„ã‚‹ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã¯ã©ã“ã«ã‚ã‚‹ã®ã ã‚ã†ã€‚ã–ã£ã¨è¦‹ãŸæ„Ÿã˜è¦‹å½“ãŸã‚‰ãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2675" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SOAP: Improving and Stabilizing Shampoo using Adam, Nikhil Vyas+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- Shampooã¨ã„ã†å‰å‡¦ç†æ³•ãŒæ·±å±¤å­¦ç¿’ã®æœ€é©åŒ–ã‚¿ã‚¹ã‚¯ã§åŠ¹æœçš„ã§ã‚ã‚‹ä¸€æ–¹ã€è¿½åŠ ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨è¨ˆç®—ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ãŒèª²é¡Œã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€Shampooã¨Adafactorã®é–¢ä¿‚ã‚’æ˜ã‚‰ã‹ã«ã—ã€Shampooã‚’åŸºã«ã—ãŸæ–°ã—ã„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ SOAPã‚’ææ¡ˆã€‚SOAPã¯ã€Adamã¨åŒæ§˜ã«ç¬¬äºŒãƒ¢ãƒ¼ãƒ¡ãƒ³ãƒˆã®ç§»å‹•å¹³å‡ã‚’æ›´æ–°ã—ã€è¨ˆç®—åŠ¹ç‡ã‚’æ”¹å–„ã€‚å®Ÿé¨“ã§ã¯ã€SOAPãŒAdamWã«å¯¾ã—ã¦40%ä»¥ä¸Šã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°å‰Šæ¸›ã€35%ä»¥ä¸Šã®çµŒéæ™‚é–“çŸ­ç¸®ã‚’é”æˆã—ã€Shampooã«å¯¾ã—ã¦ã‚‚ç´„20%ã®æ”¹å–„ã‚’ç¤ºã—ãŸã€‚SOAPã®å®Ÿè£…ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=IDxZhXrpNf" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=IDxZhXrpNf</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2674" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Fantastic Pretraining Optimizers and Where to Find Them, Kaiyue Wen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AdamWã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ã§åºƒãä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã§ã™ãŒã€ä»£æ›¿ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãŒ1.4å€ã‹ã‚‰2å€ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’æä¾›ã™ã‚‹ã¨ã„ã†ä¸»å¼µã«ã¯äºŒã¤ã®æ¬ ç‚¹ãŒã‚ã‚‹ã¨æŒ‡æ‘˜ã€‚ã“ã‚Œã‚‰ã¯ä¸å‡ç­‰ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã¨èª¤è§£ã‚’æ‹›ãè©•ä¾¡è¨­å®šã§ã‚ã‚Šã€10ç¨®é¡ã®ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã‚’ç³»çµ±çš„ã«ç ”ç©¶ã™ã‚‹ã“ã¨ã§ã€å…¬æ­£ãªæ¯”è¼ƒã®é‡è¦æ€§ã‚’ç¤ºã—ãŸã€‚ç‰¹ã«ã€æœ€é©ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã”ã¨ã«ç•°ãªã‚Šã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã«ã¤ã‚Œã¦ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—åŠ¹æœãŒæ¸›å°‘ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚æœ€ã‚‚é«˜é€Ÿãªã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã¯è¡Œåˆ—ãƒ™ãƒ¼ã‚¹ã®å‰å‡¦ç†å™¨ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŒã€ãã®åŠ¹æœã¯ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚±ãƒ¼ãƒ«ã«åæ¯”ä¾‹ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1963168542872014943?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é‡è¦ãã†ã«è¦‹ãˆã‚‹</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2675" target="_blank" rel="noopener noreferrer">[Paper Note] SOAP: Improving and Stabilizing Shampoo using Adam, Nikhil Vyas+, ICLR'25</a>
</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wen_kaiyue/status/1963633867140526319?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/percyliang/status/1963648131394122222?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è€ƒå¯Ÿ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1964098785019060719?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2673" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Landscape of Agentic Reinforcement Learning for LLMs: A Survey, Guibin Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçš„å¼·åŒ–å­¦ç¿’ï¼ˆAgentic RLï¼‰ã¯ã€å¾“æ¥ã®å¼·åŒ–å­¦ç¿’ã‹ã‚‰å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã¸ã®é©ç”¨ã«ãŠã‘ã‚‹ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚·ãƒ•ãƒˆã‚’ç¤ºã—ã€LLMã‚’è‡ªå¾‹çš„ãªæ„æ€æ±ºå®šã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦å†æ§‹ç¯‰ã—ã¾ã™ã€‚æœ¬èª¿æŸ»ã§ã¯ã€LLM-RLã®å˜ä¸€ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹ï¼ˆMDPï¼‰ã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçš„RLã®éƒ¨åˆ†è¦³æ¸¬ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹ï¼ˆPOMDPï¼‰ã‚’å¯¾æ¯”ã—ã€è¨ˆç”»ã‚„æ¨è«–ãªã©ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆèƒ½åŠ›ã‚’ä¸­å¿ƒã«äºŒé‡åˆ†é¡æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚å¼·åŒ–å­¦ç¿’ã¯ã€é™çš„ãªãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‹ã‚‰é©å¿œçš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¡Œå‹•ã¸ã®å¤‰æ›ã«é‡è¦ãªå½¹å‰²ã‚’æœãŸã™ã¨ä¸»å¼µã—ã€500ä»¥ä¸Šã®ç ”ç©¶ã‚’çµ±åˆã—ã¦ã“ã®åˆ†é‡ã®æ©Ÿä¼šã¨èª²é¡Œã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1963153160358531583?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2667" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Interpretation Meets Safety: A Survey on Interpretation Methods and   Tools for Improving LLM Safety, Seongmin Lee+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®å®‰å…¨æ€§ã‚’ç†è§£ã—è»½æ¸›ã™ã‚‹ãŸã‚ã®è§£é‡ˆæŠ€è¡“ã®é‡è¦æ€§ã‚’æ¢æ±‚ã—ã€å®‰å…¨æ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹æ‰‹æ³•ã‚’çµ±ä¸€çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§æ•´ç†ã€‚ç´„70ä»¶ã®ç ”ç©¶ã‚’åˆ†é¡ã—ã€æœªè§£æ±ºã®èª²é¡Œã¨ä»Šå¾Œã®æ–¹å‘æ€§ã‚’ç¤ºã™ã€‚ç ”ç©¶è€…ã‚„å®Ÿå‹™è€…ã«ã¨ã£ã¦ã€ã‚ˆã‚Šå®‰å…¨ã§è§£é‡ˆå¯èƒ½ãªLLMã®é€²å±•ã‚’ä¿ƒé€²ã™ã‚‹èª¿æŸ»ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/seongminleee/status/1962956637745942677?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<a class="button" href="articles/Scheduler.html" target="_blank" rel="noopener noreferrer">#Scheduler</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2665" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Training Dynamics of the Cooldown Stage in Warmup-Stable-Decay Learning   Rate Scheduler, Aleksandr Dremov+, TMLR'25</a>
<span class="snippet"><span>GPT Summary</span>- WSDå­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒ•ã‚§ãƒ¼ã‚ºã‚’åˆ†æã—ã€ç•°ãªã‚‹å½¢çŠ¶ãŒãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ã‚¢ã‚¹-ãƒãƒªã‚¢ãƒ³ã‚¹ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’æ˜ã‚‰ã‹ã«ã€‚æ¢ç´¢ã¨æ´»ç”¨ã®ãƒãƒ©ãƒ³ã‚¹ãŒæœ€é©ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ã‚’ç¤ºã—ã€ç‰¹ã«$\beta_2$ã®å€¤ãŒé«˜ã„ã¨æ”¹å–„ãŒè¦‹ã‚‰ã‚Œã‚‹ã€‚æå¤±ã®ãƒ©ãƒ³ãƒ‰ã‚¹ã‚±ãƒ¼ãƒ—ã‚’è¦–è¦šåŒ–ã—ã€ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒ•ã‚§ãƒ¼ã‚ºã®æœ€é©åŒ–ã®é‡è¦æ€§ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haeggee/status/1962852239036293223?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2664" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Efficient Code Embeddings from Code Generation Models, Daria Kryvosheieva+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- jina-code-embeddingsã¯ã€è‡ªç„¶è¨€èªã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—ã—ã€æŠ€è¡“çš„ãªè³ªå•å¿œç­”ã‚„æ„å‘³çš„ã«é¡ä¼¼ã—ãŸã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã®ç‰¹å®šã‚’è¡Œã†æ–°ã—ã„ã‚³ãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚è‡ªå·±å›å¸°å‹ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã‚’åˆ©ç”¨ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã‚’é€šã˜ã¦åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã€‚å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãªãŒã‚‰æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ã‚³ãƒ¼ãƒ‰åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã«ãŠã‘ã‚‹æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/collections/jinaai/jina-code-embeddings-68b0fbfbb0d639e515f82acd" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/jinaai/jina-code-embeddings-68b0fbfbb0d639e515f82acd</a>


</p>
<p>ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç‰¹åŒ–ã®embeddingã§ã€æ¤œç´¢ã€ã‚¯ãƒ­ã‚¹ãƒªãƒ³ã‚¬ãƒ«ãªé¡ä¼¼åº¦ã€æŠ€è¡“ã«é–¢ã™ã‚‹QAã«å¯¾å¿œå¯èƒ½ã‚‰ã—ã„</p>
<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jinaai_/status/1963637135439007824?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2645" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs  via Bi-Mode Annealing and Reinforce Learning, Jie Jiang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- R-4Bã¯ã€å•é¡Œã®è¤‡é›‘ã•ã«å¿œã˜ã¦æ€è€ƒã‚’è¡Œã†ã‹ã©ã†ã‹ã‚’é©å¿œçš„ã«åˆ¤æ–­ã™ã‚‹è‡ªå‹•æ€è€ƒå‹ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆMLLMï¼‰ã§ã‚ã‚‹ã€‚æ€è€ƒèƒ½åŠ›ã¨éæ€è€ƒèƒ½åŠ›ã‚’æŒãŸã›ã€ãƒã‚¤ãƒ¢ãƒ¼ãƒ‰ãƒãƒªã‚·ãƒ¼æœ€é©åŒ–ï¼ˆBPOï¼‰ã‚’ç”¨ã„ã¦æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®èµ·å‹•ã‚’ç²¾åº¦è‰¯ãåˆ¤æ–­ã™ã‚‹ã€‚è¨“ç·´ã«ã¯å¤šæ§˜ãªãƒˆãƒ”ãƒƒã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã€å®Ÿé¨“çµæœã¯R-4BãŒ25ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ç‰¹ã«æ¨è«–é›†ç´„å‹ã‚¿ã‚¹ã‚¯ã§ä½ã‚³ã‚¹ãƒˆã§é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1962445854654288036?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>VLMã«thinking, non-thinkingã‚’å…¥åŠ›ã«å¿œã˜ã¦ä½¿ã„åˆ†ã‘ã•ã›ã‚‹æ‰‹æ³•</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2630" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AWorld: Orchestrating the Training Recipe for Agentic AI, Chengyue Yu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AWorldã¨ã„ã†ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã‚’å°å…¥ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ç’°å¢ƒã®ç›¸äº’ä½œç”¨ã‚’åŠ¹ç‡åŒ–ã€‚çµŒé¨“åé›†ã‚’14.6å€åŠ é€Ÿã—ã€Qwen3-32Bãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´ã—ã¦GAIAã®ç²¾åº¦ã‚’21.59%ã‹ã‚‰32.23%ã«å‘ä¸Šã€‚æœ€é›£é–¢ãƒ¬ãƒ™ãƒ«ã§å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1961999098032328902?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1963005182817808721?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2622" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MoE++: Accelerating Mixture-of-Experts Methods with Zero-Computation   Experts, Peng Jin+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Mixture-of-Expertsï¼ˆMoEï¼‰æ‰‹æ³•ã®åŠ¹æœã¨åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€MoE++ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ã‚¼ãƒ­è¨ˆç®—ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’å°å…¥ã—ã€ä½è¨ˆç®—ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã€é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã®å®¹æ˜“ã•ã‚’å®Ÿç¾ã€‚å®Ÿé¨“çµæœã«ã‚ˆã‚Šã€MoE++ã¯å¾“æ¥ã®MoEãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦1.1-2.1å€ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’æä¾›ã—ã€å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=t7P5BUKcYv" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=t7P5BUKcYv</a>


</p>
<p>å¾“æ¥ã®MoEã¨æ¯”ã¹ã¦ã€å°‚é–€å®¶ã¨ã—ã¦zero computation expertsã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€æ€§èƒ½ã‚’ç¶­æŒã—ãªãŒã‚‰åŠ¹ç‡çš„ã«inferenceã‚’ã™ã‚‹æ‰‹æ³•(MoEã«ãŠã„ã¦å…¨ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‡ä¸€ã«æ‰±ã‚ãªã„ï¼‰ã‚’ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br><img src="https://github.com/user-attachments/assets/b71d01ed-92b1-4c4f-ab90-bf9b01c461be" alt="image" loading="lazy"><br><br>zero computation expertsã¯3ç¨®é¡ã§<br>- Zero Experts: å…¥åŠ›ã‚’ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ã«è½ã¨ã™<br>- Copy Experts: å…¥åŠ›xã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ã™ã‚‹<br>- Constant Experts: learnableãªå®šæ•°ãƒ™ã‚¯ãƒˆãƒ«vã‚’å­¦ç¿’ã—ã€xã¨ç·šå½¢çµåˆã—ã¦å‡ºåŠ›ã™ã‚‹ã€‚W_cã«ã‚ˆã£ã¦å…¥åŠ›xã‚’å¤‰æ›ã™ã‚‹ã“ã¨ã§ç·šå½¢è£œã€€çµåˆã®ä¿‚æ•°a1,a2ã‚’å…¥åŠ›ã«å¿œã˜ã¦å‹•çš„ã«æ±ºå®šã™ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/8c2f8f4c-d8d2-44ad-b3f0-4951f9fb2cfb" alt="image" loading="lazy"><br><br>Routingã®æ‰‹æ³•ã‚„gating residualã€å­¦ç¿’æ‰‹æ³•ã®å·¥å¤«ã‚‚ãªã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªã®ã§ã€å¾Œã§èª­ã‚€ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2621" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Shortcut-connected Expert Parallelism for Accelerating   Mixture-of-Experts, Weilin Cai+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- ScMoEã¯ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚²ãƒ¼ãƒˆæ··åˆå°‚é–€å®¶ãƒ¢ãƒ‡ãƒ«ã®è¨ˆç®—è² è·ã‚’åˆ†æ•£ã•ã›ã‚‹æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã€é€šä¿¡ã¨è¨ˆç®—ã®é‡è¤‡ã‚’æœ€å¤§100%å¯èƒ½ã«ã—ã€å…¨å¯¾å…¨é€šä¿¡ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’è§£æ¶ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§1.49å€ã€æ¨è«–ã§1.82å€ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å®Ÿç¾ã—ã€ãƒ¢ãƒ‡ãƒ«å“è³ªã‚‚æ—¢å­˜æ‰‹æ³•ã¨åŒç­‰ã¾ãŸã¯ãã‚Œä»¥ä¸Šã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=GKly3FkxN4&noteId=4tfWewv7R2" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=GKly3FkxN4&noteId=4tfWewv7R2</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2619" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Addressing Tokenization Inconsistency in Steganography and Watermarking   Based on Large Language Models, Ruiyi Yan+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’å‘ä¸Šã•ã›ã‚‹ä¸€æ–¹ã§ã€ã‚¹ãƒ†ã‚¬ãƒã‚°ãƒ©ãƒ•ã‚£ãƒ¼ã¨ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ã‚­ãƒ³ã‚°ã®é‡è¦æ€§ãŒå¢—ã—ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã®ä¸ä¸€è‡´ï¼ˆTIï¼‰ãŒå …ç‰¢æ€§ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã—ã€TIã®åŸå› ã¨ãªã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã®ç‰¹æ€§ã¨ã—ã¦ç¨€å°‘æ€§ã¨ä¸€æ™‚æ€§ã‚’ç‰¹å®šã€‚ã“ã‚Œã«åŸºã¥ãã€ã‚¹ãƒ†ã‚¬ãƒã‚°ãƒ©ãƒ•ã‚£ãƒ¼ç”¨ã®æ®µéšçš„æ¤œè¨¼æ–¹æ³•ã¨ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ã‚­ãƒ³ã‚°ç”¨ã®äº‹å¾Œãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–¹æ³•ã‚’ææ¡ˆã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€TIã«ç›´æ¥å¯¾å‡¦ã™ã‚‹ã“ã¨ã§ã€ã‚¹ãƒ†ã‚¬ãƒã‚°ãƒ©ãƒ•ã‚£ãƒ¼ã®æµæš¢ã•ã‚„å¯¾ã‚¹ãƒ†ã‚¬åˆ†æèƒ½åŠ›ã€ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ã‚­ãƒ³ã‚°ã®å …ç‰¢æ€§ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/murawaki/status/1962043066342310122?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<a class="button" href="articles/Science.html" target="_blank" rel="noopener noreferrer">#Science</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2618" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DeepScholar-Bench: A Live Benchmark and Automated Evaluation for  Generative Research Synthesis, Liana Patel+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ç”Ÿæˆçš„ç ”ç©¶åˆæˆã®è©•ä¾¡ã®ãŸã‚ã«ã€DeepScholar-benchã¨ã„ã†ãƒ©ã‚¤ãƒ–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨è‡ªå‹•è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€ArXivè«–æ–‡ã‹ã‚‰ã‚¯ã‚¨ãƒªã‚’å¼•ãå‡ºã—ã€é–¢é€£ç ”ç©¶ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹å®Ÿéš›ã®ã‚¿ã‚¹ã‚¯ã«ç„¦ç‚¹ã‚’å½“ã¦ã€çŸ¥è­˜åˆæˆã€æ¤œç´¢å“è³ªã€æ¤œè¨¼å¯èƒ½æ€§ã‚’è©•ä¾¡ã€‚DeepScholar-baseã¯å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ç¢ºç«‹ã—ã€ä»–ã®æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦ç«¶äº‰åŠ›ã®ã‚ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ãŸã€‚DeepScholar-benchã¯ä¾ç„¶ã¨ã—ã¦é›£æ˜“åº¦ãŒé«˜ãã€ç”Ÿæˆçš„ç ”ç©¶åˆæˆã®AIã‚·ã‚¹ãƒ†ãƒ ã®é€²æ­©ã«é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>leaderboard:


<a href="https://guestrin-lab.github.io/deepscholar-leaderboard/leaderboard/deepscholar_bench_leaderboard.html" target="_blank" rel="noopener noreferrer">https://guestrin-lab.github.io/deepscholar-leaderboard/leaderboard/deepscholar_bench_leaderboard.html</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lianapatel_/status/1961487232331911651?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MCP.html" target="_blank" rel="noopener noreferrer">#MCP</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2616" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MCP-Bench: Benchmarking Tool-Using LLM Agents with Complex Real-World  Tasks via MCP Servers, Zhenting Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MCP-Benchã¯ã€ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚„èª¿æ•´ã€è¨ˆç”»/æ¨è«–ã‚’å¿…è¦ã¨ã™ã‚‹å¤šæ®µéšã‚¿ã‚¹ã‚¯ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚Šã€250ã®ãƒ„ãƒ¼ãƒ«ã‚’æŒã¤28ã®MCPã‚µãƒ¼ãƒãƒ¼ã«LLMsã‚’æ¥ç¶šã—ã¾ã™ã€‚å¾“æ¥ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã¯ç•°ãªã‚Šã€ç›¸äº’ã«é€£æºã™ã‚‹ãƒ„ãƒ¼ãƒ«ã‚»ãƒƒãƒˆã‚’æä¾›ã—ã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’æ§‹ç¯‰å¯èƒ½ã«ã—ã¾ã™ã€‚ã‚¿ã‚¹ã‚¯ã¯ã€ãƒ„ãƒ¼ãƒ«ã®å–å¾—èƒ½åŠ›ã‚„å¤šæ®µéšå®Ÿè¡ŒçµŒè·¯ã®è¨ˆç”»èƒ½åŠ›ã‚’ãƒ†ã‚¹ãƒˆã—ã€æ—¢å­˜ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯è©•ä¾¡ã•ã‚Œã¦ã„ãªã„èƒ½åŠ›ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã™ã€‚20ã®LLMã«å¯¾ã™ã‚‹å®Ÿé¨“ã‚’é€šã˜ã¦ã€MCP-Benchã®èª²é¡ŒãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1961456699564294651?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã¾ãŸã—ã¦ã‚‚MCPã«åŸºã¥ã„ãŸtool useã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒå‡ºãŸæ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2610" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Skip a Layer or Loop it? Test-Time Depth Adaptation of Pretrained LLMs, Ziyue Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- äº‹å‰å­¦ç¿’æ¸ˆã¿ã®LLMã®å±¤ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã—ã¦æ“ä½œã—ã€å„ã‚µãƒ³ãƒ—ãƒ«ã«æœ€é©ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ§‹ç¯‰ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­æœ¨æ¢ç´¢ã‚’ç”¨ã„ã¦ã€æ•°å­¦ãŠã‚ˆã³å¸¸è­˜æ¨è«–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€é©ãªå±¤ã®é€£é–ï¼ˆCoLaï¼‰ã‚’ç‰¹å®šã€‚CoLaã¯æŸ”è»Ÿã§å‹•çš„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æä¾›ã—ã€æ¨è«–åŠ¹ç‡ã‚’æ”¹å–„ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚75%ä»¥ä¸Šã®æ­£ã—ã„äºˆæ¸¬ã«å¯¾ã—ã¦çŸ­ã„CoLaã‚’è¦‹ã¤ã‘ã€60%ä»¥ä¸Šã®ä¸æ­£ç¢ºãªäºˆæ¸¬ã‚’æ­£ã™ã“ã¨ãŒã§ãã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚å›ºå®šã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®é™ç•Œã‚’å…‹æœã™ã‚‹é“ã‚’é–‹ãã€‚</span>
<span class="snippet"><span>Comment</span><p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1961749826028347602?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>äº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ã®forward pathã«ãŠã‘ã‚‹å„layerã‚’building blocksã¨ã¿ãªã—ã¦ã€å…¥åŠ›ã«å¿œã˜ã¦ã‚¹ã‚­ãƒƒãƒ—ã€ã‚ã‚‹ã„ã¯å†å¸°çš„ãªåˆ©ç”¨ã‚’MCTSã«ã‚ˆã£ã¦é¸æŠã™ã‚‹ã“ã¨ã§ã€test timeæ™‚ã®ãƒ¢ãƒ‡ãƒ«ã®æ·±ã•ã‚„ã€ãƒ¢ãƒ‡ãƒ«ã®å‡¡åŒ–æ€§èƒ½ã‚’ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦é©ç”¨ã•ã›ã‚‹ã‚ˆã†ãªæ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ›´æ–°ã¯ä¸è¦ã€‚k, r âˆˆ {1,2,3,4} ã®ç¯„å›²ã§ã€"kå€‹ã®layerã‚’skip"ã€ã‚ã‚‹ã„ã¯kå€‹ã®layerã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’rå›å†å¸°ã™ã‚‹ã€ã¨ã™ã‚‹ã“ã¨ã§æ¢ç´¢ç¯„å›²ã‚’é™å®šçš„ã«ã—testæ™‚ã®éå‰°ãªè¨ˆç®—ã‚’æŠ‘æ­¢ã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€MCTSã«ãŠã‘ã‚‹simulationã®å›æ•°ã¯200å›ã€‚length penaltyã‚’å¤§ããã™ã‚‹ã“ã¨ã§compactãªforward pathã«ãªã‚‹ã‚ˆã†ã«èª¿æ•´ã€10%ã®ç¢ºç‡ã§ã¾ã æ¢ç´¢ã—ã¦ã„ãªã„å­ãƒãƒ¼ãƒ‰ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã™ã‚‹ã“ã¨ã§æ¢ç´¢ã‚’ä¿ƒã™ã‚ˆã†ã«ã—ã¦ã„ã‚‹ã€‚ã‚ªãƒªã‚¸ãƒŠãƒ«ã¨æ¯”è¼ƒã—ã¦å®Ÿè¡Œæ™‚é–“ãŒã©ã®ç¨‹åº¦å¢—ãˆã¦ã—ã¾ã†ã®ã‹ï¼Ÿã«èˆˆå‘³ãŒã‚ã£ãŸãŒã€ãƒ¢ãƒ‡ãƒ«ã®æ·±ã•ã¨ã„ã†è¦³ç‚¹ã§æ¨è«–åŠ¹ç‡ã¯è€ƒå¯Ÿã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆãŸãŒã€å®Ÿè¡Œæ™‚é–“ã¨ã„ã†è¦³ç‚¹ã§ã¯ã–ã£ã¨è¦‹ãŸæ„Ÿã˜è¨˜è¼‰ãŒãªã„ã‚ˆã†ã«è¦‹ãˆãŸã€‚<br><br>&lt;img width="948" height="301" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/0a03cdc2-141b-40a1-a11e-9560187ff7b6"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0a03cdc2-141b-40a1-a11e-9560187ff7b6"&lt;/a&gt;


/&gt;<br><br>ä»¥ä¸‹ã®åºƒç¯„ãªQAã€å¹…åºƒã„é›£æ˜“åº¦ã‚’æŒã¤æ•°å­¦ã«é–¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ï¼ˆAppendix Bã«å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã”ã¨ã«500 sampleã‚’åˆ©ç”¨ã¨è¨˜è¼‰ãŒã‚ã‚‹ï¼‰ã‚’ã—ãŸã¨ã“ã‚ã€å¤§å¹…ã«æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ãŸã ã—ã€8Bç¨‹åº¦ã®ã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã§ã—ã‹å®Ÿé¨“ã¯ã•ã‚Œã¦ã„ãªã„ã€‚<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2613" target="_blank" rel="noopener noreferrer">[Paper Note] Think you have Solved Question Answering? Try ARC, the AI2 Reasoning
  Challenge, Peter Clark+, arXiv'18</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2615" target="_blank" rel="noopener noreferrer">[Paper Note] DART-Math: Difficulty-Aware Rejection Tuning for Mathematical  Problem-Solving, Yuxuan Tong+, NeurIPS'24</a>
<br>&lt;img width="986" height="682" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/c6d88c0a-4ae0-41b7-8526-17d041692f49"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/c6d88c0a-4ae0-41b7-8526-17d041692f49"&lt;/a&gt;


/&gt;</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2611" target="_blank" rel="noopener noreferrer">[Paper Note] Looped Transformers are Better at Learning Learning Algorithms, Liu Yang+, ICLR'24</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2612" target="_blank" rel="noopener noreferrer">[Paper Note] Looped Transformers for Length Generalization, Ying Fan+, ICLR'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2605" target="_blank" rel="noopener noreferrer">[Paper Note] Universal Transformers, Mostafa Dehghani+, ICLR'19</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2241" target="_blank" rel="noopener noreferrer">[Paper Note] Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive
  Token-Level Computation, Sangmin Bae+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Game.html" target="_blank" rel="noopener noreferrer">#Game</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2609" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TurnaboutLLM: A Deductive Reasoning Benchmark from Detective Games, Yuan Yuan+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- TurnaboutLLMã¨ã„ã†æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€æ¢åµã‚²ãƒ¼ãƒ ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ—ãƒ¬ã‚¤ã‚’é€šã˜ã¦LLMsã®æ¼”ç¹¹çš„æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã€‚è¨¼è¨€ã¨è¨¼æ‹ ã®çŸ›ç›¾ã‚’ç‰¹å®šã™ã‚‹èª²é¡Œã‚’è¨­å®šã—ã€12ã®æœ€å…ˆç«¯LLMã‚’è©•ä¾¡ã—ãŸçµæœã€æ–‡è„ˆã®ã‚µã‚¤ã‚ºã‚„æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚TurnaboutLLMã¯ã€è¤‡é›‘ãªç‰©èªç’°å¢ƒã«ãŠã‘ã‚‹LLMsã®æ¨è«–èƒ½åŠ›ã«æŒ‘æˆ¦ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hemuyu0327/status/1961275336530039244?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>éå¸¸ã«é¢ç™½ãã†ã€‚é€†è»¢è£åˆ¤ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã—ãŸè¶…long contextãªæ¼”ç¹¹çš„ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ãŒæœ€çµ‚çš„ãªå›ç­”ã‚’é–“é•ãˆã‚‹éš›ã¯ã‚ˆã‚Šå¤šãã®æ­£è§£ã«ã¯è²¢çŒ®ã—ãªã„Reasoning Stepã‚’ç¹°ã‚Šè¿”ã—ãŸã‚Šã€QwQ-32Bã¨GPT4.1ã¯åŒç­‰ã®æ€§èƒ½ã ãŒã€non thinkingãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹GPT4.1ãŒã‚ˆã‚Šå°‘é‡ã®Reasoning Step (æœ¬ç ”ç©¶ã§ã¯å›ç­”ã«è‡³ã‚‹ã¾ã§ã«å‡ºåŠ›ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¨å®šç¾©)ã§å›ç­”ã«åˆ°é”ã—ï¼ˆï¼Test Time Scalingã®æ©æµãŒãªã„ï¼‰ã€ãƒ•ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸ãˆã¦æ€§èƒ½ãŒå‘ä¸Šã—ãŸã®ã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„å ´åˆã®ã¿ï¼ˆï¼Test Timeã®reasoningã‚ˆã‚Šã‚‚ã€in-contextã§ã®reasoningãŒé‡è¦ï¼‰ã ã£ãŸã€ã¨ã„ã£ãŸçŸ¥è¦‹ãŒã‚ã‚‹æ¨¡æ§˜ã€‚ã˜ã£ãã‚Šèª­ã¿ãŸã„ã€‚</p></span><br><br>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Planning.html" target="_blank" rel="noopener noreferrer">#Planning</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/IJCAI.html" target="_blank" rel="noopener noreferrer">#IJCAI</a>
<a class="button" href="articles/Workshop.html" target="_blank" rel="noopener noreferrer">#Workshop</a>
<a class="button" href="articles/IdeaGeneration.html" target="_blank" rel="noopener noreferrer">#IdeaGeneration</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2607" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MK2 at PBIG Competition: A Prompt Generation Solution, Xu+, IJCAI WS AgentScen'25, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ijcaiconf/status/1961433133422973224?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Patentã‹ã‚‰market-readyãªãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’ç”Ÿæˆã—è©•ä¾¡ã™ã‚‹ã‚¿ã‚¹ã‚¯(PBIG)ã«å–ã‚Šçµ„ã‚“ã§ã„ã‚‹ã€‚<br>Reasoningãƒ¢ãƒ‡ãƒ«ã¯ã‚³ã‚¹ãƒˆã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®é…ã•ã‹ã‚‰åˆ©ç”¨ã›ãšï¼ˆiterationã‚’é‡ã­ã‚‹ã“ã¨ã‚’é‡è¦–ï¼‰ã€LLMã®ã‚¢ã‚·ã‚¹ãƒˆã‚’å—ã‘ãªãŒã‚‰promptã‚’ä½•åº¦ã‚‚human in the loopã§iterationã—ãªãŒã‚‰å“è³ªã‚’é«˜ã‚ã¦ã„ãã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ã¨ã‚Šã€ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã§1st placeã‚’ç²å¾—ã—ãŸæ¨¡æ§˜ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Regularization.html" target="_blank" rel="noopener noreferrer">#Regularization</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2603" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Drop Dropout on Single-Epoch Language Model Pretraining, Houjun Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã¯éå­¦ç¿’ã‚’é˜²ãæ‰‹æ³•ã¨ã—ã¦çŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ãŒã€ç¾ä»£ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã§ã¯éå­¦ç¿’ãŒæŠ‘ãˆã‚‰ã‚Œã‚‹ãŸã‚ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€BERTã‚„Pythiaãƒ¢ãƒ‡ãƒ«ã®å˜ä¸€ã‚¨ãƒãƒƒã‚¯äº‹å‰å­¦ç¿’ã«ãŠã„ã¦ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã®å½±éŸ¿ã‚’èª¿æŸ»ã—ãŸçµæœã€ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’é©ç”¨ã—ãªã„æ–¹ãŒä¸‹æµã®æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒåˆ¤æ˜ã€‚ã¾ãŸã€ã€Œæ—©æœŸãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã€ã‚‚æ€§èƒ½ã‚’ä½ä¸‹ã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆãªã—ã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ¢ãƒ‡ãƒ«ç·¨é›†ã«ãŠã„ã¦ã‚‚ã‚ˆã‚ŠæˆåŠŸã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã€å˜ä¸€ã‚¨ãƒãƒƒã‚¯ã®äº‹å‰å­¦ç¿’ä¸­ã«ã¯ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’çœãã“ã¨ãŒæ¨å¥¨ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1961589435197505584?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2604" target="_blank" rel="noopener noreferrer">[Paper Note] Dropout Reduces Underfitting, Zhuang Liu+, ICML'23</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2591" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OmniHuman-1.5: Instilling an Active Mind in Avatars via Cognitive  Simulation, Jianwen Jiang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã€ŒOmniHuman-1.5ã€ã¯ã€ç‰©ç†çš„å¦¥å½“æ€§ã¨æ„å‘³çš„ä¸€è²«æ€§ã‚’å…¼ã­å‚™ãˆãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹ã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã€éŸ³å£°ã€ç”»åƒã€ãƒ†ã‚­ã‚¹ãƒˆã®å…±åŒæ„å‘³ã‚’è§£é‡ˆã™ã‚‹ã“ã¨ã§ã€æ„Ÿæƒ…ã‚„æ„å›³ã«åŸºã¥ã„ãŸå‹•ä½œã‚’ç”Ÿæˆã€‚æ–°ã—ã„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«DiTã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£é–“ã®å¯¾ç«‹ã‚’è»½æ¸›ã—ã€ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ç²¾åº¦ã‚„å‹•ä½œã®è‡ªç„¶ã•ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚è¤‡é›‘ãªã‚·ãƒŠãƒªã‚ªã¸ã®æ‹¡å¼µæ€§ã‚‚ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://omnihuman-lab.github.io/v1_5/" target="_blank" rel="noopener noreferrer">https://omnihuman-lab.github.io/v1_5/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1960957629465026882?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>promptã«ã‚ˆã£ã¦çŠ¶æ³ã‚„æ„Ÿæƒ…ãªã©ã®è¡¨ç¾ã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãŒå¯èƒ½ã‚‰ã—ã„</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1963895614728778187?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<span class="issue_date">Issue Date: 2025-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2590" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AI-Researcher: Autonomous Scientific Innovation, Jiabin Tang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AI-Researcherã¨ã„ã†è‡ªå¾‹å‹ç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ ã‚’ææ¡ˆã—ã€æ–‡çŒ®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰è«–æ–‡ä½œæˆã¾ã§ã®ç ”ç©¶ãƒ—ãƒ­ã‚»ã‚¹ã‚’è‡ªå‹•åŒ–ã€‚Scientist-Benchã‚’ç”¨ã„ã¦AIã®ç ”ç©¶èƒ½åŠ›ã‚’è©•ä¾¡ã—ã€å®Ÿé¨“ã«ã‚ˆã‚Šäººé–“ãƒ¬ãƒ™ãƒ«ã®ç ”ç©¶è«–æ–‡ã‚’ç”Ÿæˆã™ã‚‹æˆåŠŸç‡ã‚’ç¤ºã™ã€‚ã“ã®ç ”ç©¶ã¯ã€è‡ªå¾‹çš„ãªç§‘å­¦çš„é©æ–°ã®æ–°ãŸãªåŸºç›¤ã‚’ç¯‰ãã€‚</span>
<span class="snippet"><span>Comment</span><p>github:


<a href="https://github.com/HKUDS/AI-Researcher" target="_blank" rel="noopener noreferrer">https://github.com/HKUDS/AI-Researcher</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huang_chao4969/status/1961120989015937287?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2488" target="_blank" rel="noopener noreferrer">DeepCode, Data Intelligence Lab@HKU, 2025.08</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2588" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Mobile-Agent-v3: Foundamental Agents for GUI Automation, Jiabo Ye+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€GUI-Owlã¨ã„ã†GUIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã€ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ãŠã‚ˆã³ãƒ¢ãƒã‚¤ãƒ«ç’°å¢ƒã§ã®æœ€å…ˆç«¯æ€§èƒ½ã‚’é”æˆã—ãŸã“ã¨ã‚’å ±å‘Šã—ã¦ã„ã¾ã™ã€‚ç‰¹ã«ã€Mobile-Agent-v3ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’å°å…¥ã—ã€æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã¾ã—ãŸã€‚GUI-Owlã¯ã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ä»®æƒ³ç’°å¢ƒã‚’åˆ©ç”¨ã—ãŸè‡ªå·±é€²åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®æ„æ€æ±ºå®šã‚’æ”¯æ´ã™ã‚‹å¤šæ§˜ãªæ©Ÿèƒ½ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªå¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç‰¹å¾´ã¨ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®æˆæœã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>github:


<a href="https://github.com/X-PLUG/MobileAgent?tab=readme-ov-file" target="_blank" rel="noopener noreferrer">https://github.com/X-PLUG/MobileAgent?tab=readme-ov-file</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ali_tongyilab/status/1960994656323620948?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1897" target="_blank" rel="noopener noreferrer">AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents, Christopher Rawles+, ICLR'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2589" target="_blank" rel="noopener noreferrer">[Paper Note] OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real
  Computer Environments, Tianbao Xie+, arXiv'24</a>
</p>
<p>Trajectory-aware Relative Policy Optimization<br>(TRPO)</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2585" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Ultra-Sparse Memory Network, Zihao Huang+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- UltraMemã¯ã€å¤§è¦æ¨¡ã§è¶…ã‚¹ãƒ‘ãƒ¼ã‚¹ãªãƒ¡ãƒ¢ãƒªå±¤ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€Transformerãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’å‰Šæ¸›ã—ã¤ã¤æ€§èƒ½ã‚’ç¶­æŒã™ã‚‹æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ææ¡ˆã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€UltraMemã¯MoEã‚’ä¸Šå›ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç‰¹æ€§ã‚’ç¤ºã—ã€æœ€å¤§2000ä¸‡ã®ãƒ¡ãƒ¢ãƒªã‚¹ãƒ­ãƒƒãƒˆã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ãŒæœ€å…ˆç«¯ã®æ¨è«–é€Ÿåº¦ã¨æ€§èƒ½ã‚’é”æˆã™ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/CurriculumLearning.html" target="_blank" rel="noopener noreferrer">#CurriculumLearning</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2580" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Ovis2.5 Technical Report, Shiyin Lu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Ovis2.5ã¯ã€ãƒã‚¤ãƒ†ã‚£ãƒ–è§£åƒåº¦ã®è¦–è¦šèªè­˜ã¨ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§ã€ç”»åƒã‚’å¯å¤‰è§£åƒåº¦ã§å‡¦ç†ã—ã€è¤‡é›‘ãªè¦–è¦šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®è©³ç´°ã‚’ä¿æŒã—ã¾ã™ã€‚æ¨è«–æ™‚ã«ã¯åçœã‚’è¡Œã†ã€Œæ€è€ƒãƒ¢ãƒ¼ãƒ‰ã€ã‚’æä¾›ã—ã€ç²¾åº¦å‘ä¸Šã‚’å›³ã‚Šã¾ã™ã€‚5æ®µéšã®ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã§è¨“ç·´ã•ã‚Œã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã®åŠ¹ç‡çš„ãªå‡¦ç†ã‚’å®Ÿç¾ã€‚Ovis2.5-9Bã¯OpenCompassã§å¹³å‡78.3ã‚’è¨˜éŒ²ã—ã€Ovis2-8Bã«å¯¾ã—ã¦å¤§å¹…ãªæ”¹å–„ã‚’ç¤ºã—ã¾ã—ãŸã€‚Ovis2.5-2Bã‚‚73.9ã‚’é”æˆã—ã€ãƒªã‚½ãƒ¼ã‚¹åˆ¶ç´„ã®ã‚ã‚‹ãƒ‡ãƒã‚¤ã‚¹ã«æœ€é©ã§ã™ã€‚STEMãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚„è¤‡é›‘ãªãƒãƒ£ãƒ¼ãƒˆåˆ†æã«ãŠã„ã¦ã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1960840587168637183?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/AIDC-AI/Ovis2.5-9B" target="_blank" rel="noopener noreferrer">https://huggingface.co/AIDC-AI/Ovis2.5-9B</a>


<br><br>Apache2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹<br><br>GLM-4.1V-9B-Thinkingã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ãªæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/becc30fe-db20-40c1-a94c-143487ffd9ff" alt="image" loading="lazy"><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2128" target="_blank" rel="noopener noreferrer">[Paper Note] GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable  Reinforcement Learning, GLM-V Team+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2577" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Rewarding Vision-Language Model via Reasoning Decomposition, Zongxia Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Vision-Language Models (VLMs)ã¯è¦–è¦šçš„å¹»è¦šã‚„è¨€èªçš„ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã«æ‚©ã¾ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã€‚ã“ã‚Œã‚‰ã®å•é¡Œã¯ã€ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ãŒä¸­é–“ã®è¦–è¦šçš„æ¨è«–ã«å¯¾ã™ã‚‹æŒ‡å°ã‚’æ¬ ã„ã¦ã„ã‚‹ãŸã‚ã«ç”Ÿã˜ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€å¤–éƒ¨ã®è¦–è¦šçš„ç›£è¦–ã«ä¾å­˜ã›ãšã«è¦–è¦šçš„æ¨è«–ã‚’æ”¹å–„ã™ã‚‹è‡ªå·±å ±é…¬æ³•Vision-SR1ã‚’ææ¡ˆã€‚ãƒ¢ãƒ‡ãƒ«ã¯è¦–è¦šçš„çŸ¥è¦šã¨è¨€èªçš„æ¨è«–ã‚’2æ®µéšã«åˆ†è§£ã—ã€è‡ªå·±å®Œçµå‹ã®è¦–è¦šçš„çŸ¥è¦šã‚’ç”Ÿæˆã—ã€ãã®å¾Œã«è¨€èªçš„æ¨è«–ã‚’è¡Œã†ã“ã¨ã§å ±é…¬ã‚’è¨ˆç®—ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€Vision-SR1ãŒè¦–è¦šçš„æ¨è«–ã‚’æ”¹å–„ã—ã€å¹»è¦šã‚’è»½æ¸›ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1960888293031088273?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1960962793265578174?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2575" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] UQ: Assessing Language Models on Unsolved Questions, Fan Nie+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€AIãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã®ãŸã‚ã«ã€æœªè§£æ±ºã®è³ªå•ã«åŸºã¥ãæ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒUQã€ã‚’ææ¡ˆã—ã¾ã™ã€‚UQã¯ã€Stack Exchangeã‹ã‚‰åé›†ã—ãŸ500ã®å¤šæ§˜ãªè³ªå•ã‚’å«ã¿ã€é›£æ˜“åº¦ã¨ç¾å®Ÿæ€§ã‚’å…¼ã­å‚™ãˆã¦ã„ã¾ã™ã€‚è©•ä¾¡ã«ã¯ã€ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€LLMå¯©æŸ»å“¡ã€äººé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’çµ„ã¿åˆã‚ã›ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåé›†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€ç”Ÿæˆè€…-ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’æ´»ç”¨ã—ãŸè¤‡åˆãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥ã€å°‚é–€å®¶ã«ã‚ˆã‚‹å…±åŒæ¤œè¨¼ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãŒå«ã¾ã‚Œã¾ã™ã€‚UQã¯ã€æœ€å‰ç·šã®ãƒ¢ãƒ‡ãƒ«ãŒäººé–“ã®çŸ¥è­˜ã‚’æ‹¡å¼µã™ã‚‹ãŸã‚ã®ç¾å®Ÿçš„ãªèª²é¡Œã‚’è©•ä¾¡ã™ã‚‹æ‰‹æ®µã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/percyliang/status/1960415128501018779?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fannie1208/status/1960387282642592042?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1967511497669767186?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Figure1ã‚’è¦‹ã‚‹ã¨ã‚³ãƒ³ã‚»ãƒ—ãƒˆãŒéå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„ã€‚ç¾åœ¨ã®LLMãŒè‹¦æˆ¦ã—ã¦ã„ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯äººé–“ãŒå›ç­”æ¸ˆã¿ã€ã‹ã¤å®Ÿä¸–ç•Œã®ãƒ‹ãƒ¼ã‚ºã«åã—ã¦æ„å›³çš„ã«ä½œã‚‰ã‚ŒãŸé«˜é›£æ˜“åº¦ãªãƒ‡ãƒ¼ã‚¿ï¼ˆç¾å®Ÿçš„ãªè¨­å®šã§ã¯ç„¡ã„ï¼‰ã§ã‚ã‚Šã€ç¾å®Ÿçš„ã§ã¯ç„¡ã„ãŒé›£æ˜“åº¦ãŒé«˜ã„ã€‚ä¸€æ–¹ã§ã€ç¾å®Ÿã«ãƒ‹ãƒ¼ã‚ºãŒã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä½œã‚‹ã¨ãã‚Œã‚‰ã¯ã—ã°ã—ã°ç°¡å˜ã™ããŸã‚Šã€ãƒãƒƒã‚­ãƒ³ã‚°å¯èƒ½ã ã£ãŸã‚Šã™ã‚‹ã€‚<br><br>ã“ã®ãŸã‚ã€ç¾å®Ÿçš„ãªè¨­å®šã§ãƒ‹ãƒ¼ã‚ºãŒã‚ã‚Šã€ã‹ã¤é›£æ˜“åº¦ãŒé«˜ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒä¸è¶³ã—ã¦ãŠã‚Šã€ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ãã‚‚ãã‚‚äººé–“ãŒã¾ã å›ç­”ã—ã¦ã„ãªã„æœªè§£æ±ºã®å•é¡Œã«ç€ç›®ã—ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä½œã‚Šã¾ã—ãŸã€ã¨ã„ã†è©±ã«è¦‹ãˆã‚‹ã€‚<br><br>å…ƒãƒã‚¹ãƒˆã‚’å’€åš¼ã™ã‚‹ã¨ã€<br><br>æœªè§£æ±ºãªå•é¡Œã¨ã„ã†ã“ã¨ã¯ReferenceãŒå­˜åœ¨ã—ãªã„ã¨ã„ã†ã“ã¨ãªã®ã§ã€ã“ã®ç‚¹ãŒèª²é¡Œã¨ãªã‚‹ã€‚ã“ã®ãŸã‚ã€UQ-Validatorã¨UQ-Platformã‚’å°å…¥ã™ã‚‹ã€‚<br><br>UQ-Validatorã¯è¤‡æ•°ã®LLMã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§å½¢æˆã•ã‚Œã€å›ç­”å€™è£œã®pre-screeningã‚’å®Ÿæ–½ã™ã‚‹ã€‚å›ç­”ã‚’ç”Ÿæˆã—ãŸLLMè‡ªèº«ï¼ˆã‚ã‚‹ã„ã¯åŒã˜ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ï¼‰ãŒValidatorã«åŠ ã‚ã‚‹ã“ã¨ã§è‡ªèº«ã®å›ç­”ã‚’overrateã™ã‚‹å•é¡ŒãŒç”Ÿã˜ã‚‹ãŒã€è¤‡æ•°LLMã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’çµ„ã‚€ã“ã¨ã§ãã®ãƒã‚¤ã‚¢ã‚¹ã‚’è»½æ¸›ã§ãã‚‹ã€ã¨ã®ã“ã¨ã€‚ã¾ãŸã€ã—ã°ã—ã°å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã‚Šã‚‚çµæœã‚’Validationã›ã‚‹æ–¹ãŒã‚¿ã‚¹ã‚¯ã¨ã—ã¦ç°¡å˜ã§ã‚ã‚Šã€å¿…ãšã—ã‚‚é©åˆ‡ã«å›ç­”ã™ã‚‹èƒ½åŠ›ã¯Validatorã«ã¯å¿…è¦ãªã„ã¨ã„ã†ç›´æ„Ÿã«åŸºã¥ã„ã¦ã„ã‚‹ã€‚ãŸã¨ãˆã°ã€Claudeã¯å›ç­”æ€§èƒ½ã¯ä½ãã¦ã‚‚Validatorã¨ã—ã¦ã¯ã†ã¾ãæ©Ÿèƒ½ã™ã‚‹ã€‚ã¾ãŸã€Validatorã¯è»¢ç§»ãŒåŠ¹ãã€ä»–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã—ãŸã‚‚ã®ã‚’æœªè§£æ±ºã®å›ç­”ã«ã‚‚é©ç”¨ã§ãã‚‹ã€‚test-timeã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚‚ã‚ã‚‹ç¨‹åº¦ä½œç”¨ã™ã‚‹ã€‚<br>ç¶šã„ã¦ã€UQ-Platformã«ãŠã„ã¦ã€å›ç­”ã¨Validatorã®å‡ºåŠ›ã‚’è¦‹ãªãŒã‚‰ã€å°‚é–€å®¶ã®æ”¯æ´ã«åŸºã¥ã„ã¦å›ç­”è©•ä¾¡ã—ã€ã¾ãŸã€ãã‚‚ãã‚‚ã®è³ªå•ã®è³ªãªã©ã«ã¤ã„ã¦ã‚³ãƒ¡ãƒ³ãƒˆã™ã‚‹ãªã©ã—ã¦æœªè§£æ±ºã®å•é¡Œã®è§£æ±ºã‚’æ”¯æ´ã§ãã‚‹ã€‚<br><br>ã¿ãŸã„ãªè©±ã‚‰ã—ã„ã€‚éå¸¸ã«é‡è¦ãªç ”ç©¶ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<span class="issue_date">Issue Date: 2025-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2569" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens, Chengshuai Zhao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Chain-of-Thought (CoT) ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã¯LLMã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹ãŒã€ãã®æ·±ã•ã«ã¯ç–‘å•ãŒæ®‹ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€CoTæ¨è«–ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ çš„ãƒã‚¤ã‚¢ã‚¹ã‚’åæ˜ ã—ã¦ã„ã‚‹ã‹ã‚’èª¿æŸ»ã—ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªã®åˆ†å¸ƒä¸ä¸€è‡´ãŒãã®åŠ¹æœã«ä¸ãˆã‚‹å½±éŸ¿ã‚’åˆ†æã€‚DataAlchemyã¨ã„ã†åˆ¶å¾¡ç’°å¢ƒã‚’ç”¨ã„ã¦ã€CoTæ¨è«–ã®è„†å¼±æ€§ã‚’æ˜ã‚‰ã‹ã«ã—ã€ä¸€èˆ¬åŒ–å¯èƒ½ãªæ¨è«–ã®é”æˆã«å‘ã‘ãŸèª²é¡Œã‚’å¼·èª¿ã™ã‚‹ã€‚</span>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2568" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Nemotron-CC-Math: A 133 Billion-Token-Scale High Quality Math  Pretraining Dataset, Rabeeh Karimi Mahabadi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„æ•°å­¦ã‚³ãƒ¼ãƒ‘ã‚¹ã€ŒNemotron-CC-Mathã€ã‚’ææ¡ˆã—ã€LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€ç§‘å­¦ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã®ãŸã‚ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã€‚å¾“æ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ˆã‚Šã‚‚é«˜å“è³ªã§ã€æ–¹ç¨‹å¼ã‚„ã‚³ãƒ¼ãƒ‰ã®æ§‹é€ ã‚’ä¿æŒã—ã¤ã¤ã€è¡¨è¨˜ã‚’æ¨™æº–åŒ–ã€‚Nemotron-CC-Math-4+ã¯ã€ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€äº‹å‰å­¦ç¿’ã«ã‚ˆã‚ŠMATHã‚„MBPP+ã§ã®æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/karimirabeeh/status/1960682448867426706?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ConceptErasure.html" target="_blank" rel="noopener noreferrer">#ConceptErasure</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2555" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CRISP: Persistent Concept Unlearning via Sparse Autoencoders, Tomer Ashuach+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- CRISPã¯ã€LLMã«ãŠã‘ã‚‹æŒç¶šçš„ãªæ¦‚å¿µã®å¿˜å´ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡ã®è‰¯ã„æ‰‹æ³•ã§ã‚ã‚Šã€ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼ˆSAEï¼‰ã‚’ç”¨ã„ã¦æœ‰å®³ãªçŸ¥è­˜ã‚’åŠ¹æœçš„ã«é™¤å»ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€CRISPã¯WMDPãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å¿˜å´ã‚¿ã‚¹ã‚¯ã§å¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã€ä¸€èˆ¬çš„ãŠã‚ˆã³ãƒ‰ãƒ¡ã‚¤ãƒ³å†…ã®èƒ½åŠ›ã‚’ä¿æŒã—ã¤ã¤ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰¹å¾´ã®æ­£ç¢ºãªæŠ‘åˆ¶ã‚’é”æˆã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1960181627549884685?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2553" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] InternVL3.5: Advancing Open-Source Multimodal Models in Versatility,  Reasoning, and Efficiency, Weiyun Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- InternVL 3.5ã¯ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æ–°ã—ã„ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã§ã€Cascade Reinforcement Learningã‚’ç”¨ã„ã¦æ¨è«–èƒ½åŠ›ã¨åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ç²—ã‹ã‚‰ç´°ã¸ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã«ã‚ˆã‚Šã€MMMã‚„MathVistaãªã©ã®ã‚¿ã‚¹ã‚¯ã§å¤§å¹…ãªæ”¹å–„ã‚’å®Ÿç¾ã€‚Visual Resolution Routerã‚’å°å…¥ã—ã€è¦–è¦šãƒˆãƒ¼ã‚¯ãƒ³ã®è§£åƒåº¦ã‚’å‹•çš„ã«èª¿æ•´ã€‚Decoupled Vision-Language Deploymentæˆ¦ç•¥ã«ã‚ˆã‚Šã€è¨ˆç®—è² è·ã‚’ãƒãƒ©ãƒ³ã‚¹ã•ã›ã€æ¨è«–æ€§èƒ½ã‚’æœ€å¤§16.0%å‘ä¸Šã•ã›ã€é€Ÿåº¦ã‚’4.05å€å‘ä¸Šã€‚æœ€å¤§ãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®MLLMã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã€å•†æ¥­ãƒ¢ãƒ‡ãƒ«ã¨ã®æ€§èƒ½ã‚®ãƒ£ãƒƒãƒ—ã‚’ç¸®å°ã€‚å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ã¨ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1960076908088922147?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhihufrontier/status/1972502056209662441?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2549" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains  RLVR, Xiao Liang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RLVRã¯LLMã®è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦é‡è¦ã ãŒã€å¾“æ¥ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ç”Ÿæˆã®å¤šæ§˜æ€§ã‚’æ¸›å°‘ã•ã›ã‚‹å•é¡ŒãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒãƒªã‚·ãƒ¼ã®ç”Ÿæˆã®å¤šæ§˜æ€§ã‚’åˆ†æã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å•é¡Œã‚’æ›´æ–°ã™ã‚‹ã“ã¨ã§ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼å´©å£Šã‚’è»½æ¸›ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è‡ªå·±å¯¾æˆ¦ã¨å¤‰åˆ†å•é¡Œåˆæˆï¼ˆSvSï¼‰æˆ¦ç•¥ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€ãƒãƒªã‚·ãƒ¼ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚’ç¶­æŒã—ã€Pass@kã‚’å¤§å¹…ã«æ”¹å–„ã€‚AIME24ãŠã‚ˆã³AIME25ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãã‚Œãã‚Œ18.3%ãŠã‚ˆã³22.8%ã®å‘ä¸Šã‚’é”æˆã—ã€12ã®æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§SvSã®å …ç‰¢æ€§ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://mastervito.github.io/SvS.github.io/" target="_blank" rel="noopener noreferrer">https://mastervito.github.io/SvS.github.io/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mastervito0601/status/1959960582670766411?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1960178795530600605?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/NeuralArchitectureSearch.html" target="_blank" rel="noopener noreferrer">#NeuralArchitectureSearch</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2548" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Jet-Nemotron: Efficient Language Model with Post Neural Architecture  Search, Yuxian Gu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Jet-Nemotronã¯æ–°ã—ã„ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€ãƒ•ãƒ«ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ä»¥ä¸Šã®ç²¾åº¦ã‚’æŒã¡ãªãŒã‚‰ç”Ÿæˆã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å¤§å¹…ã«æ”¹å–„ã—ã¾ã™ã€‚Post Neural Architecture Searchï¼ˆPostNASï¼‰ã‚’ç”¨ã„ã¦é–‹ç™ºã•ã‚Œã€äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‹ã‚‰åŠ¹ç‡çš„ã«ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¢ç´¢ã—ã¾ã™ã€‚Jet-Nemotron-2Bãƒ¢ãƒ‡ãƒ«ã¯ã€ä»–ã®å…ˆé€²ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦é«˜ã„ç²¾åº¦ã‚’é”æˆã—ã€ç”Ÿæˆã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’æœ€å¤§53.6å€å‘ä¸Šã•ã›ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1959832287073403137?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hancai_hm/status/1960000017235902722?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacksonatkinsx/status/1960090774122483783?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1960392071384326349?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1960724749790929009?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¶šå ±:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hancai_hm/status/1972794734747033985?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã‚³ãƒ¼ãƒ‰ã¨ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒãƒªãƒªãƒ¼ã‚¹<br><br>code:


<a href="https://github.com/NVlabs/Jet-Nemotron" target="_blank" rel="noopener noreferrer">https://github.com/NVlabs/Jet-Nemotron</a>


<br>HF:


<a href="https://huggingface.co/collections/jet-ai/jet-nemotron-68ac76e8356b5399ef83ac9c" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/jet-ai/jet-nemotron-68ac76e8356b5399ef83ac9c</a>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2543" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Competition and Attraction Improve Model Fusion, JoÃ£o Abrantes+, GECCO'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆM2N2ï¼‰ã¯ã€è¤‡æ•°ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å°‚é–€çŸ¥è­˜ã‚’çµ±åˆã™ã‚‹é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã€å‹•çš„ãªãƒãƒ¼ã‚¸å¢ƒç•Œèª¿æ•´ã‚„å¤šæ§˜æ€§ä¿æŒãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ç‰¹å¾´ã¨ã—ã€æœ€ã‚‚æœ‰æœ›ãªãƒ¢ãƒ‡ãƒ«ãƒšã‚¢ã‚’ç‰¹å®šã™ã‚‹ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚’ç”¨ã„ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€M2N2ã¯ã‚¼ãƒ­ã‹ã‚‰MNISTåˆ†é¡å™¨ã‚’é€²åŒ–ã•ã›ã€è¨ˆç®—åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã¤ã¤é«˜æ€§èƒ½ã‚’é”æˆã€‚ã¾ãŸã€å°‚é–€çš„ãªè¨€èªã‚„ç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ã‚¸ã«ã‚‚é©ç”¨å¯èƒ½ã§ã€å …ç‰¢æ€§ã¨å¤šæ§˜æ€§ã‚’ç¤ºã™ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sakanaailabs/status/1959799343088857233?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1257" target="_blank" rel="noopener noreferrer">Evolutionary Optimization of Model Merging Recipes, Takuya Akiba+, N/A, Nature Machine Intelligence'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MCP.html" target="_blank" rel="noopener noreferrer">#MCP</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2541" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on  Challenging Queries, Ming Yin+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè¤‡æ•°ã®MCPãƒ„ãƒ¼ãƒ«ã‚’å”èª¿çš„ã«ä½¿ç”¨ã—ã¦ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒLiveMCP-101ã€ã‚’ææ¡ˆã€‚101ã®å®Ÿä¸–ç•Œã®ã‚¯ã‚¨ãƒªã‚’ç”¨ã„ã€çœŸã®å®Ÿè¡Œè¨ˆç”»ã‚’åŸºã«ã—ãŸæ–°ã—ã„è©•ä¾¡ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å°å…¥ã€‚å®Ÿé¨“çµæœã‹ã‚‰ã€æœ€å‰ç·šã®LLMã®æˆåŠŸç‡ãŒ60ï¼…æœªæº€ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€ãƒ„ãƒ¼ãƒ«ã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹èª²é¡ŒãŒæ˜ã‚‰ã‹ã«ã€‚LiveMCP-101ã¯ã€å®Ÿä¸–ç•Œã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆèƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®åŸºæº–ã‚’è¨­å®šã—ã€è‡ªå¾‹AIã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿç¾ã«å‘ã‘ãŸé€²å±•ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1959786499702182271?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1966525731082768782?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2537" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Motif 2.6B Technical Report, Junghwan Lim+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Motif-2.6Bã¯ã€26å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤åŸºç›¤LLMã§ã€é•·æ–‡ç†è§£ã®å‘ä¸Šã‚„å¹»è¦šã®æ¸›å°‘ã‚’ç›®æŒ‡ã—ã€å·®åˆ†æ³¨æ„ã‚„ãƒãƒªãƒãƒ«ãƒ æ´»æ€§åŒ–é–¢æ•°ã‚’æ¡ç”¨ã€‚åºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€åŒã‚µã‚¤ã‚ºã®æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€åŠ¹ç‡çš„ã§ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªåŸºç›¤LLMã®ç™ºå±•ã«å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1959604841577357430?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/Motif-Technologies/Motif-2.6B" target="_blank" rel="noopener noreferrer">https://huggingface.co/Motif-Technologies/Motif-2.6B</a>


</p>
<p>- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1466" target="_blank" rel="noopener noreferrer">Differential Transformer, Tianzhu Ye+, N/A, ICLR'25</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2538" target="_blank" rel="noopener noreferrer">[Paper Note] Polynomial Composition Activations: Unleashing the Dynamics of Large
  Language Models, Zhijian Zhuo+, arXiv'24</a>
<br>- å­¦ç¿’æ‰‹æ³•<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1979" target="_blank" rel="noopener noreferrer">Model Merging in Pre-training of Large Language Models, Yunshui Li+, arXiv'25</a>
<br>    - 8B tokenå­¦ç¿’ã™ã‚‹ã”ã¨ã«ç›´è¿‘6ã¤ã®checkpointã®element-wiseã®å¹³å‡ã‚’ã¨ã‚Šãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã€‚å½“è©²ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦å­¦ç¿’ã‚’ç¶™ç¶šã€ã¨ã„ã†ã“ã¨ã‚’ç¹°ã‚Šè¿”ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å­¦ç¿’ã®ãƒã‚¤ã‚ºã‚’ä½æ¸›ã—ã€çªç„¶ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚·ãƒ•ãƒˆã™ã‚‹ã“ã¨ã‚’é˜²ã<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1060" target="_blank" rel="noopener noreferrer">Effective Long-Context Scaling of Foundation Models, Wenhan Xiong+, N/A, NAACL'24</a>
<br>    - Adaptive Base Frequency (RoPEã®base frequencyã‚’10000ã‹ã‚‰500000ã«ã™ã‚‹ã“ã¨ã§long contextã®attention scoreãŒå°ã•ããªã‚Šã™ãã‚‹ã“ã¨ã‚’é˜²ã)<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2540" target="_blank" rel="noopener noreferrer">[Paper Note] MiniCPM: Unveiling the Potential of Small Language Models with Scalable
  Training Strategies, Shengding Hu+, arXiv'24</a>
 <br>- äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1943" target="_blank" rel="noopener noreferrer">DataComp-LM: In search of the next generation of training sets for
  language models, Jeffrey Li+, arXiv'24</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2539" target="_blank" rel="noopener noreferrer">TxT360, LLM360, 2024.10</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2109" target="_blank" rel="noopener noreferrer">[Paper Note] FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data  Processing to Every Language, Guilherme Penedo+, COLM'25</a>
 <br><br>ã‚’åˆ©ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã€‚åŒç¨‹åº¦ã®ã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒã§ã¯ã‹ãªã‚Šã®gainã‚’å¾—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚èˆˆå‘³æ·±ã„ã€‚<br>Datasetã®Mixtureã®æ¯”ç‡ãªã©ã«ã¤ã„ã¦ã‚‚è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>&lt;img width="705" height="441" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/0a26442e-8075-4cbe-8cc1-f1ff471b7356"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0a26442e-8075-4cbe-8cc1-f1ff471b7356"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<a class="button" href="articles/Inference.html" target="_blank" rel="noopener noreferrer">#Inference</a>
<span class="issue_date">Issue Date: 2025-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2536" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TokenSkip: Controllable Chain-of-Thought Compression in LLMs, Heming Xia+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- Chain-of-Thought (CoT)ã¯LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€é•·ã„CoTå‡ºåŠ›ã¯æ¨è«–é…å»¶ã‚’å¢—åŠ ã•ã›ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€é‡è¦åº¦ã®ä½ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¸æŠçš„ã«ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹TokenSkipã‚’ææ¡ˆã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€TokenSkipã¯CoTãƒˆãƒ¼ã‚¯ãƒ³ã®ä½¿ç”¨ã‚’å‰Šæ¸›ã—ã¤ã¤æ¨è«–æ€§èƒ½ã‚’ç¶­æŒã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ç‰¹ã«ã€Qwen2.5-14B-Instructã§GSM8Kã«ãŠã„ã¦æ¨è«–ãƒˆãƒ¼ã‚¯ãƒ³ã‚’40%å‰Šæ¸›ã—ã€æ€§èƒ½ä½ä¸‹ã¯0.4%æœªæº€ã§ã‚ã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hemingkx/status/1891873475545137245?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2534" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MAgICoRe: Multi-Agent, Iterative, Coarse-to-Fine Refinement for   Reasoning, Justin Chih-Yao Chen+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- MAgICoReã¯ã€LLMã®æ¨è«–ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€å•é¡Œã®é›£æ˜“åº¦ã«å¿œã˜ã¦æ´—ç·´ã‚’èª¿æ•´ã—ã€éå‰°ãªä¿®æ­£ã‚’å›é¿ã™ã‚‹ã€‚ç°¡å˜ãªå•é¡Œã«ã¯ç²—ã„é›†ç´„ã‚’ã€é›£ã—ã„å•é¡Œã«ã¯ç´°ã‹ã„åå¾©çš„ãªæ´—ç·´ã‚’é©ç”¨ã—ã€å¤–éƒ¨ã®å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ã‚¨ãƒ©ãƒ¼ã®ç‰¹å®šã‚’å‘ä¸Šã•ã›ã‚‹ã€‚3ã¤ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆSolverã€Reviewerã€Refinerï¼‰ã«ã‚ˆã‚‹ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’æ¡ç”¨ã—ã€æ´—ç·´ã®åŠ¹æœã‚’ç¢ºä¿ã™ã‚‹ã€‚Llama-3-8BãŠã‚ˆã³GPT-3.5ã§è©•ä¾¡ã—ãŸçµæœã€MAgICoReã¯ä»–ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€åå¾©ãŒé€²ã‚€ã«ã¤ã‚Œã¦æ”¹å–„ã‚’ç¶šã‘ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cyjustinchen/status/1958957907778969648?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Game.html" target="_blank" rel="noopener noreferrer">#Game</a>
<span class="issue_date">Issue Date: 2025-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2533" target="_blank" rel="noopener noreferrer" class="title-link">Identification and Analysis of Identity-Centric Elements of Character-Likeness from Game Scenario, Iwata+, SIGDIAL'25</a>
<span class="snippet"><span>Comment</span><p>arxivã«ç„¡ã•ãã†ãªã®ã§ã€æ¦‚è¦ã¯å…ƒãƒã‚¹ãƒˆå‚ç…§ã®ã“ã¨ã€‚ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚‰ã—ã•ã®æ§‹æˆè¦ç´ ã¨ãã‚Œã‚‰ãŒã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚‰ã—ã•ã«é–¢ã—ã¦ã©ã®ã‚ˆã†ã«é–¢ä¿‚ã—ã¦ã„ã‚‹ã‹ã‚’åˆ†æã—ãŸç ”ç©¶ãªæ¨¡æ§˜ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hmkz_/status/1958903563561894229?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2532" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Think with Confidence, Yichao Fu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã€ŒDeep Think with Confidenceï¼ˆDeepConfï¼‰ã€ã¯ã€LLMã®æ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹ç²¾åº¦ã¨è¨ˆç®—ã‚³ã‚¹ãƒˆã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹æ‰‹æ³•ã§ã€ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã®ä¿¡é ¼æ€§ä¿¡å·ã‚’æ´»ç”¨ã—ã¦ä½å“è³ªãªæ¨è«–ã‚’å‹•çš„ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚è¿½åŠ ã®è¨“ç·´ã‚„èª¿æ•´ã‚’å¿…è¦ã¨ã›ãšã€æ—¢å­˜ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«çµ±åˆå¯èƒ½ã§ã™ã€‚è©•ä¾¡ã®çµæœã€ç‰¹ã«é›£æ˜“åº¦ã®é«˜ã„AIME 2025ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§99.9%ã®ç²¾åº¦ã‚’é”æˆã—ã€ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’æœ€å¤§84.7%å‰Šæ¸›ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://jiaweizzhao.github.io/deepconf" target="_blank" rel="noopener noreferrer">https://jiaweizzhao.github.io/deepconf</a>


<br>vLLMã§ã®å®Ÿè£…:


<a href="https://jiaweizzhao.github.io/deepconf/static/htmls/code_example.html" target="_blank" rel="noopener noreferrer">https://jiaweizzhao.github.io/deepconf/static/htmls/code_example.html</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiawzhao/status/1958982524333678877?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>tooluseã€è¿½åŠ ã®è¨“ç·´ãªã—ã§ã€ã©ã®ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã«ã‚‚é©ç”¨ã§ãã€85%ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³é‡ã‚’æ¸›ã‚‰ã—ãŸä¸Šã§ã€OpenModelã§åˆã‚ã¦AIME2025ã«ãŠã„ã¦99% Acc.ã‚’é”æˆã—ãŸæ‰‹æ³•ã¨ã®ã“ã¨ã€‚vLLMã‚’ç”¨ã„ã¦50 lineç¨‹åº¦ã§å®Ÿè£…ã§ãã‚‹ã‚‰ã—ã„ã€‚</p>
<p>reasoning traceã®confidence(i.e., å¯¾æ•°å°¤åº¦)ã‚’group sizeã‚’æ±ºã‚ã¦windowå˜ä½ã§æ±ºå®šã—ã€ãã‚Œã‚‰ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒ—ãƒ­ã‚»ã‚¹ã§æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€å“è³ªã®ä½ã„reasoning traceã«åŸºã¥ãçµæœã‚’æ’é™¤ã—ã¤ã¤ã€majority votingã«æ´»ç”¨ã™ã‚‹æ–¹æ³•ã€‚ç›´æ„Ÿçš„ã«ã‚‚ã†ã¾ãã„ããã†ã€‚ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã¨ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã®æ¨è«–ã«ã‚ˆã£ã¦æ´»ç”¨æ–¹æ³•ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚ã‚ã¨ã§ã—ã£ã‹ã‚Šèª­ã‚“ã§æ›¸ãã€‚Confidenceã®å®šç¾©ã®ä»•æ–¹ã¯ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®bottom 10%ã€tailãªã©ã•ã¾ã–ã¾ãªå®šç¾©æ–¹æ³•ã¨ã€ãã‚Œã‚‰ã«åŸºã¥ã„ãŸconfidenceã«ã‚ˆã‚‹votingã®é‡ã¿ä»˜ã‘ãŒè¤‡æ•°è€ƒãˆã‚‰ã‚Œã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã«ã‚ˆã£ã¦ä½¿ã„åˆ†ã‘ã‚‹æ¨¡æ§˜ã€‚<br><br>vLLMã«PRã‚‚å‡ºã¦ã„ã‚‹æ¨¡æ§˜ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2531" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ToolVQA: A Dataset for Multi-step Reasoning VQA with External Tools, Shaofeng Yin+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å®Ÿä¸–ç•Œã®ãƒ„ãƒ¼ãƒ«ä½¿ç”¨èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€23Kã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‹ã‚‰ãªã‚‹å¤§è¦æ¨¡ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒToolVQAã€ã‚’ææ¡ˆã€‚ToolVQAã¯ã€å®Ÿéš›ã®è¦–è¦šçš„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨å¤šæ®µéšæ¨è«–ã‚¿ã‚¹ã‚¯ã‚’ç‰¹å¾´ã¨ã—ã€ToolEngineã‚’ç”¨ã„ã¦äººé–“ã®ã‚ˆã†ãªãƒ„ãƒ¼ãƒ«ä½¿ç”¨æ¨è«–ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã€‚7B LFMã‚’å¾®èª¿æ•´ã—ãŸçµæœã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€GPT-3.5-turboã‚’ä¸Šå›ã‚‹ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’æŒã¤ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>äººé–“ã«ã‚ˆã‚‹å°è¦æ¨¡ãªã‚µãƒ³ãƒ—ãƒ«ï¼ˆã‚¤ãƒ¡ãƒ¼ã‚¸ã‚·ãƒŠãƒªã‚ªã€ãƒ„ãƒ¼ãƒ«ã‚»ãƒƒãƒˆã€ã‚¯ã‚¨ãƒªã€å›ç­”ã€tool use trajectory)ã‚’ç”¨ã„ã¦Foundation Modelã«äº‹å‰çŸ¥è­˜ã¨ã—ã¦ä¸ãˆã‚‹ã“ã¨ã§ã€ã‚ˆã‚ŠrealisticãªscenarioãŒåˆæˆã•ã‚Œã‚‹ã‚ˆã†ã«ã—ãŸä¸Šã§æ–°ãŸãªVQAã‚’4kç¨‹åº¦åˆæˆã€‚ãã®å¾Œ10äººã®ã‚¢ãƒãƒ†ãƒ¼ã‚¿ã«ã‚ˆã£ã¦é«˜å“è³ªãªã‚µãƒ³ãƒ—ãƒ«ã«ã®ã¿Filteringã™ã‚‹ã“ã¨ã§ä½œæˆã•ã‚ŒãŸã€å¾“æ¥ã‚ˆã‚Šã‚‚å®Ÿä¸–ç•Œã®è¨­å®šã«è¿‘ãã€reasoningã®è¤‡é›‘ã•ãŒé«˜ã„VQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãªæ¨¡æ§˜ã€‚<br><br><img src="https://github.com/user-attachments/assets/8759244c-89f9-47d7-9c72-81744ef68db1" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/4bc22c9d-79f3-4c16-b5a4-3c054895b416" alt="image" loading="lazy"><br><br>å…·ä½“çš„ã«ã¯ã€image contextxãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€ChatGPT-4oã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã¨ã—ã¦ã€å‰å›ã®ãƒ„ãƒ¼ãƒ«ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®é¸æŠã‚’givenã«ã—ã€äººé–“ãŒä½œæˆã—ãŸãƒ—ãƒ¼ãƒ«ã«å«ã¾ã‚Œã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®ä¸­ã‹ã‚‰Longest Common Subsequence (LCS) ã«ã‚ˆã‚‹ä¸€è‡´åº¦åˆã„ã«åŸºã¥ã„ã¦äººæ‰‹ã«ã‚ˆã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠã—ã€å‹•çš„ã«contextã«å«ã‚ã‚‹ã“ã¨ã§å¤šæ§˜ãªã§å®Ÿä¸–ç•Œã«ã‚ˆã‚Šè¿‘ã—ã„multi step tooluseãªtrajectoryã‚’åˆæˆã™ã‚‹ã€ã¨ã„ã£ãŸæ‰‹æ³•ã«è¦‹ãˆã‚‹ã€‚pp.4--5ã«æ•°å¼ã‚„å›³ã«ã‚ˆã‚‹ç›´æ„Ÿçš„ãªèª¬æ˜ãŒã‚ã‚‹ã€‚ãªãŠã€LCSã‚’å…·ä½“çš„ã«ã©ã®ã‚ˆã†ãªæ–‡å­—åˆ—ã«å¯¾ã—ã¦ã€ã©ã®ã‚ˆã†ãªå‰å‡¦ç†ã‚’ã—ãŸä¸Šã§é©ç”¨ã—ã¦ã„ã‚‹ã®ã‹ã¾ã§ã¯è¿½ãˆã¦ã„ãªã„ã€‚<br><img src="https://github.com/user-attachments/assets/9915c3d5-e984-4611-94d4-999ad08dc49d" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1959125184285483090?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-08-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2530" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Hard Examples Are All You Need: Maximizing GRPO Post-Training Under  Annotation Budgets, Benjamin Pikus+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒªã‚½ãƒ¼ã‚¹ãŒåˆ¶ç´„ã•ã‚ŒãŸçŠ¶æ³ã§ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦ã€é›£æ˜“åº¦ã®ç•°ãªã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã®å„ªå…ˆé †ä½ã‚’æ¤œè¨ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æœ€ã‚‚é›£ã—ã„ä¾‹ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒæœ€å¤§47%ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ãŒç¤ºã•ã‚Œã€é›£ã—ã„ä¾‹ãŒå­¦ç¿’æ©Ÿä¼šã‚’å¤šãæä¾›ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€äºˆç®—åˆ¶ç´„ä¸‹ã§ã®åŠ¹æœçš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã¨ã—ã¦ã€é›£ã—ã„ä¾‹ã‚’å„ªå…ˆã™ã‚‹ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®pass@kãŒä½ã„hardestãªã‚µãƒ³ãƒ—ãƒ«ã§GRPOã‚’å­¦ç¿’ã™ã‚‹ã®ãŒãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ãŒè‰¯ãã€OODã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã‚‚ç™ºæ®ã•ã‚Œã¾ã™ã€ã¨ã„ã†ã®ã‚’Qwen3-4B, 14B, Phi4ã§å®Ÿé¨“ã—ã¦ç¤ºã—ã¾ã—ãŸã€ã¨ã„ã†è©±ã£ã½ã„ï¼Ÿ<br><br>å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã€ãŠã‚ˆã³GSM8Kã€BIG Bench hardã§ã®ã€Tracking Shuffled Objectã®ã¿ã§ã®å®Ÿé¨“ãªæ¨¡æ§˜ï¼Ÿå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã‚‚ã†ã¾ãã„ãã‹ã¯ã‚ˆãåˆ†ã‹ã‚‰ãªã„ã€‚OODã®å®Ÿé¨“ã‚‚AIME2025ã§ã®ã¿ã®å®Ÿé¨“ã—ã¦ã„ã‚‹ã‚ˆã†ãªã®ã§ãã“ã¯ç•™æ„ã—ãŸæ–¹ãŒè‰¯ã„ã‹ã‚‚ã€‚<br>rewardã¨ã—ã¦ä½•ã‚’ä½¿ã£ãŸã®ã‹ãªã©ã®ç´°ã‹ã„å†…å®¹ã‚’è¿½ãˆã¦ã„ãªã„ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/pratyushrt/status/1958947577216524352?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Science.html" target="_blank" rel="noopener noreferrer">#Science</a>
<span class="issue_date">Issue Date: 2025-08-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2528" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Intern-S1: A Scientific Multimodal Foundation Model, Lei Bai+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Intern-S1ã¯ã€ç§‘å­¦å°‚é–€åˆ†é‡ã«ç‰¹åŒ–ã—ãŸã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®å°‚é–€å®¶å‹ãƒ¢ãƒ‡ãƒ«ã§ã€280å„„ã®æ´»æ€§åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«Mixture-of-Expertsï¼ˆMoEï¼‰ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚5Tãƒˆãƒ¼ã‚¯ãƒ³ã§äº‹å‰å­¦ç¿’ã•ã‚Œã€ç‰¹ã«ç§‘å­¦ãƒ‡ãƒ¼ã‚¿ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚äº‹å¾Œå­¦ç¿’ã§ã¯ã€InternBootCampã‚’é€šã˜ã¦å¼·åŒ–å­¦ç¿’ã‚’è¡Œã„ã€Mixture-of-Rewardsã‚’ææ¡ˆã€‚è©•ä¾¡ã§ã¯ã€ä¸€èˆ¬çš„ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã§ç«¶äº‰åŠ›ã‚’ç¤ºã—ã€ç§‘å­¦åˆ†é‡ã®å°‚é–€çš„ãªã‚¿ã‚¹ã‚¯ã§ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã¯Hugging Faceã§å…¥æ‰‹å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1958894938248384542?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>scientific domainã«ç‰¹åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿ã§ç¶™ç¶šäº‹å‰å­¦ç¿’+RL Finetuningã—ãŸãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–è¨€èªãƒ¢ãƒ‡ãƒ«ã‚‰ã—ã„ã€‚</p>
<p>HF:


<a href="https://huggingface.co/internlm/Intern-S1" target="_blank" rel="noopener noreferrer">https://huggingface.co/internlm/Intern-S1</a>


<br><br>Apache 2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹<br><br>ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¯Qwen3ã¨InternViT<br>- InternViT:


<a href="https://huggingface.co/OpenGVLab/InternViT-300M-448px-V2_5" target="_blank" rel="noopener noreferrer">https://huggingface.co/OpenGVLab/InternViT-300M-448px-V2_5</a>


<br><br>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2529" target="_blank" rel="noopener noreferrer">[Paper Note] InternVL: Scaling up Vision Foundation Models and Aligning for Generic   Visual-Linguistic Tasks, Zhe Chen+, CVPR'24</a>
</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1959222471183225033?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚µãƒãƒª:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1960840538225303992?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2527" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Beyond GPT-5: Making LLMs Cheaper and Better via Performance-Efficiency  Optimized Routing, Yiqun Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨åŠ¹ç‡ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ãŸã‚ã«ã€ãƒ†ã‚¹ãƒˆæ™‚ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒAvengers-Proã€ã‚’ææ¡ˆã€‚ã‚¯ã‚¨ãƒªã‚’åŸ‹ã‚è¾¼ã¿ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ã€æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€6ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã€‚æœ€å¼·ã®å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚’å¹³å‡ç²¾åº¦ã§+7%ä¸Šå›ã‚Šã€ã‚³ã‚¹ãƒˆã‚’27%å‰Šæ¸›ã—ã¤ã¤ç´„90%ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã€‚ã™ã¹ã¦ã®å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§æœ€é«˜ã®ç²¾åº¦ã¨æœ€ä½ã®ã‚³ã‚¹ãƒˆã‚’æä¾›ã™ã‚‹ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã‚’é”æˆã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ä¸­ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1958897458408563069?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚¯ã‚¨ãƒªã‚’kmeansã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ã€å„ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®performanceã¨costã‚’äº‹å‰ã«ç®—å‡ºã—ã¦ãŠãã€‚ãã—ã¦æ–°ãŸãªã‚¯ã‚¨ãƒªãŒæ¥ãŸæ™‚ã«ã‚¯ã‚¨ãƒªãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã‚‹top pã®ã‚¯ãƒ©ã‚¹ã‚¿ã®performanae-cost efficiencyã‚’åˆè¨ˆã—ã€ã‚¹ã‚³ã‚¢ãŒé«˜ã„ä¸€ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼ˆï¼routing)ã—inferenceã‚’å®Ÿæ–½ã™ã‚‹ã€‚ã‚¯ã‚¨ãƒªã¯Qwenã§embeddingåŒ–ã—ã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«æ´»ç”¨ã™ã‚‹ã€‚ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Î±âˆˆ[0,1]ã«ã‚ˆã£ã¦ã€performance, costã©ã¡ã‚‰ã‚’é‡è¦–ã™ã‚‹ã‹ã®ãƒãƒ©ãƒ³ã‚¹ã‚’èª¿æ•´ã™ã‚‹ã€‚<br><br>ã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ³•ã ãŒã€GPT-5 mediumã¨åŒç­‰ã®ã‚³ã‚¹ãƒˆ/æ€§èƒ½ã€€ã§ã‚ˆã‚Šé«˜ã„ã€€æ€§èƒ½/ã‚³ã‚¹ãƒˆã€€ã‚’å®Ÿç¾ã€‚<br><img src="https://github.com/user-attachments/assets/203f99a3-79b3-4465-985b-2bbd124d3972" alt="image" loading="lazy"></p>
<p>æ€§èƒ½å‘ä¸Šã€ã‚³ã‚¹ãƒˆå‰Šæ¸›ã§ãƒ€ãƒ¡æŠ¼ã—ã—ãŸã„æ™‚ã«ä½¿ãˆãã†ã ãŒã€ç™ºè¡Œã™ã‚‹ã‚¯ã‚¨ãƒªãŒãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãƒ‡ãƒ¼ã‚¿ã€ã‚ã‚‹ã„ã¯ãã‚‚ãã‚‚å…¨ç„¶ãƒ‡ãƒ¼ã‚¿ãªã„ã‚“ã§ã™ã€ã¿ãŸã„ãªçŠ¶æ³ã®å ´åˆã€ã‚¯ã‚¨ãƒªã®å‰²å½“å…ˆã¨ãªã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ã‚’é©åˆ‡ã«ç¢ºä¿ã™ã‚‹ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã«ç”¨ã„ã‚‹ååˆ†ãªé‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã™ã‚‹ï¼‰ã®ãŒå¤§å¤‰ãªå ´é¢ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚</p>
<p>ï¼ˆå…¨ç„¶æœ¬ç­‹ã¨é–¢ä¿‚ãªã„ãŒã€æœ€è¿‘è«–æ–‡ã®ã‚¿ã‚¤ãƒˆãƒ«ã«Beyondã¤ã‘ã‚‹ã®æµè¡Œã£ã¦ã‚‹â€¦ï¼Ÿï¼‰</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/AutomaticSpeechRecognition(ASR).html" target="_blank" rel="noopener noreferrer">#AutomaticSpeechRecognition(ASR)</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2525" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LiteASR: Efficient Automatic Speech Recognition with Low-Rank  Approximation, Keisuke Kamahori+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- LiteASRã¯ã€ç¾ä»£ã®è‡ªå‹•éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’ä½ãƒ©ãƒ³ã‚¯åœ§ç¸®ã™ã‚‹æ‰‹æ³•ã§ã€æ¨è«–ã‚³ã‚¹ãƒˆã‚’å¤§å¹…ã«å‰Šæ¸›ã—ã¤ã¤è»¢å†™ç²¾åº¦ã‚’ç¶­æŒã—ã¾ã™ã€‚ä¸»æˆåˆ†åˆ†æã‚’ç”¨ã„ã¦ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ã®ä¹—ç®—ã‚’è¿‘ä¼¼ã—ã€è‡ªå·±æ³¨æ„æ©Ÿæ§‹ã‚’æœ€é©åŒ–ã™ã‚‹ã“ã¨ã§ã€Whisper large-v3ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚µã‚¤ã‚ºã‚’50%ä»¥ä¸Šåœ§ç¸®ã—ã€Whisper mediumã¨åŒç­‰ã®ã‚µã‚¤ã‚ºã§ã‚ˆã‚Šè‰¯ã„è»¢å†™ç²¾åº¦ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/keisukekamahori/status/1958695752810864754?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¾ä»£ã®ASRãƒ¢ãƒ‡ãƒ«ã¯encoderãŒè¨ˆç®—åŠ¹ç‡ã®ä¸Šã§ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ãªã£ã¦ã„ãŸãŒã€Forward Passã«ãŠã‘ã‚‹ activatrion Y ã‚’ PCA ï¼ˆå¼2, 3ï¼‰ã«åŸºã¥ã„ã¦2ã¤ã®ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ã®ç©ï¼ˆã¨ãƒã‚¤ã‚¢ã‚¹é …ã®åŠ ç®—; å¼5ï¼‰ã«ã‚ˆã£ã¦è¿‘ä¼¼ã—è¨ˆç®—åŠ¹ç‡ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ãŸã€ã¨ã„ã†è©±ãªæ¨¡æ§˜ã€‚weightã‚’ä½ãƒ©ãƒ³ã‚¯ã«å†™åƒã™ã‚‹V_kã¨ãƒã‚¤ã‚¢ã‚¹é …ã®Y_Mï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã«å¯¾ã™ã‚‹activation Yã®å¹³å‡ï¼‰ã¯calibrfationãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã£ã¦äº‹å‰ã«è¨ˆç®—å¯èƒ½ã¨ã®ã“ã¨ã€‚ã¾ãŸã€PCAã®rank kãŒattention headã®æ¬¡å…ƒæ•°ã‚ˆã‚Šå°ã•ã„å ´åˆã€self-attentionã®è¨ˆç®—ã‚‚ã‚ˆã‚Šï¼ˆQWKã¸å†™åƒã™ã‚‹Wã‚’ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ã§è¿‘ä¼¼ã™ã‚‹ã“ã¨ã§ï¼‰åŠ¹ç‡çš„ãªæ‰‹æ³•ã‚’æ¡ç”¨ã§ãã€ãã¡ã‚‰ã«ã¤ã„ã¦ã‚‚ææ¡ˆã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ã€‚ï¼ˆã–ã£ãã‚Šã—ã‹èª­ã‚ã¦ã„ãªã„ã®ã§èª¤ã‚ŠãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚ï¼‰<br><br>&lt;img width="592" height="449" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/38c8aa6a-cad3-42d1-af6a-9102ed1df3f5"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/38c8aa6a-cad3-42d1-af6a-9102ed1df3f5"&lt;/a&gt;


/&gt;<br><br>&lt;img width="484" height="415" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/f8fa8cd1-2b6a-405a-88ec-3bfd2158dffb"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/f8fa8cd1-2b6a-405a-88ec-3bfd2158dffb"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2524" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Prompt Orchestration Markup Language, Yuge Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- POMLï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—è¨€èªï¼‰ã‚’å°å…¥ã—ã€LLMsã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãŠã‘ã‚‹æ§‹é€ ã€ãƒ‡ãƒ¼ã‚¿çµ±åˆã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ„Ÿå—æ€§ã®èª²é¡Œã«å¯¾å‡¦ã€‚ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—ã‚„CSSã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚’æ¡ç”¨ã—ã€å‹•çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ©Ÿèƒ½ã‚„é–‹ç™ºè€…ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã‚’æä¾›ã€‚POMLã®æœ‰åŠ¹æ€§ã‚’2ã¤ã®ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã§æ¤œè¨¼ã—ã€å®Ÿéš›ã®é–‹ç™ºã‚·ãƒŠãƒªã‚ªã§ã®åŠ¹æœã‚’è©•ä¾¡ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://microsoft.github.io/poml/latest/" target="_blank" rel="noopener noreferrer">https://microsoft.github.io/poml/latest/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1958732643996246342?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯éå¸¸ã«èˆˆå‘³æ·±ã„</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MCP.html" target="_blank" rel="noopener noreferrer">#MCP</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2523" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MCP-Universe: Benchmarking Large Language Models with Real-World Model  Context Protocol Servers, Ziyang Luo+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¢ãƒ‡ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒˆã‚³ãƒ«ï¼ˆMCPï¼‰ã¯ã€LLMã‚’å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã«æ¥ç¶šã™ã‚‹æ–°ã—ã„æ¨™æº–ã§ã‚ã‚Šã€MCP-Universeã¨ã„ã†åŒ…æ‹¬çš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹LLMã®è©•ä¾¡ãŒå¯èƒ½ã¨ãªã‚‹ã€‚6ã¤ã®ã‚³ã‚¢ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ã‚«ãƒãƒ¼ã—ã€å³å¯†ãªè©•ä¾¡æ‰‹æ³•ã‚’å®Ÿè£…ã€‚ä¸»è¦ãªLLMã¯æ€§èƒ½åˆ¶é™ã‚’ç¤ºã—ã€é•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚„æœªçŸ¥ã®ãƒ„ãƒ¼ãƒ«ã®èª²é¡Œã«ç›´é¢ã€‚UIã‚µãƒãƒ¼ãƒˆä»˜ãã®è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã€MCPã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã®é©æ–°ã‚’ä¿ƒé€²ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://mcp-universe.github.io/" target="_blank" rel="noopener noreferrer">https://mcp-universe.github.io/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lijunnan0409/status/1958671067071004934?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1962935890415599650?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2522" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebEvolver: Enhancing Web Agent Self-Improvement with Coevolving World  Model, Tianqing Fang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±æ”¹å–„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãŸã‚ã«ã€å…±é€²åŒ–ã™ã‚‹ãƒ¯ãƒ¼ãƒ«ãƒ‰ãƒ¢ãƒ‡ãƒ«LLMã‚’å°å…¥ã™ã‚‹æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒãƒªã‚·ãƒ¼ã‚’æ´—ç·´ã™ã‚‹è‡ªå·±æŒ‡å°å‹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€è¡Œå‹•é¸æŠã‚’å°ãå…ˆèª­ã¿ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿç¾ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æ—¢å­˜ã®è‡ªå·±é€²åŒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å¯¾ã—ã¦10%ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’ç¤ºã—ã€æŒç¶šçš„ãªé©å¿œæ€§ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wyu_nd/status/1958632621820584203?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2520" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Are Checklists Really Useful for Automatic Evaluation of Generative  Tasks?, Momoka Furuhashi+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- ç”Ÿæˆã‚¿ã‚¹ã‚¯ã®è‡ªå‹•è©•ä¾¡ã«ãŠã‘ã‚‹æ›–æ˜§ãªåŸºæº–ã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã®ä½¿ç”¨æ–¹æ³•ã‚’æ¤œè¨ã€‚6ã¤ã®ç”Ÿæˆæ–¹æ³•ã¨8ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§è©•ä¾¡ã—ã€é¸æŠçš„ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆãŒãƒšã‚¢ãƒ¯ã‚¤ã‚ºè©•ä¾¡ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ”¹å–„ã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚ãŸã ã—ã€ç›´æ¥ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã§ã¯ä¸€è²«æ€§ãŒãªã„ã€‚äººé–“ã®è©•ä¾¡åŸºæº–ã¨ã®ç›¸é–¢ãŒä½ã„ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆé …ç›®ã‚‚å­˜åœ¨ã—ã€è©•ä¾¡åŸºæº–ã®æ˜ç¢ºåŒ–ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tohoku_nlp_mmk/status/1958717497454002557?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj page:


<a href="https://momo0817.github.io/checklist-effectiveness-study-github.io/" target="_blank" rel="noopener noreferrer">https://momo0817.github.io/checklist-effectiveness-study-github.io/</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2518" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents, Shilong Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MM-BrowseCompã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¤œç´¢ãŠã‚ˆã³æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€224ã®æ‰‹ä½œã‚Šã®è³ªå•ã‚’å«ã‚€ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç”»åƒã‚„å‹•ç”»ã‚’å«ã‚€æƒ…å ±ã®é‡è¦æ€§ã‚’è€ƒæ…®ã—ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®æ‰‹æ³•ã®é™ç•Œã‚’ç¤ºã™ã€‚æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã§ã¯ã€OpenAI o3ãªã©ã®ãƒˆãƒƒãƒ—ãƒ¢ãƒ‡ãƒ«ã§ã‚‚29.02%ã®ç²¾åº¦ã«ã¨ã©ã¾ã‚Šã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«èƒ½åŠ›ã®æœ€é©åŒ–ä¸è¶³ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gezhang86038849/status/1958381269617955165?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2517" target="_blank" rel="noopener noreferrer" class="title-link">PLaMo Translate: ç¿»è¨³ç‰¹åŒ–å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é–‹ç™º,ä»ŠåŸ+, Jxiv'25</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imos/status/1958687896321630355?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>SFT-&gt;Iterative DPO-&gt;Model Mergeã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚SFTã§ã¯é’ç©ºæ–‡åº«ãªã©ã®ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŒ‡ç¤ºè¿½å¾“æ€§èƒ½ã®é«˜ã„DeepSeek-V3-0324ã«ã‚ˆã£ã¦å…ƒãƒ‡ãƒ¼ã‚¿â†’ç¿»è¨³, ç¿»è¨³â†’å†ç¿»è¨³ãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã—æ´»ç”¨ã€‚ã¾ãŸã€ç¿»è¨³ã®æŒ‡ç¤ºãŒpromptä¸­ã«å­˜åœ¨ã›ãšã¨ã‚‚ï¼ˆæœ¬ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹ã®ã¯ç¿»è¨³ç”¨é€”ã§ã‚ã‚‹ã“ã¨ãŒè‡ªæ˜ã§ã‚ã‚‹ã‹ã‚‰ã¨æ¨å¯Ÿã•ã‚Œã‚‹ï¼‰ç¿»è¨³ã‚’é©åˆ‡ã«å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã€ç‹¬è‡ªã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å­¦ç¿’ã€‚æ–‡ä½“æŒ‡å®šã€å¸¸ä½“ã€æ•¬ä½“ã®æŒ‡å®šã€æ–‡è„ˆè€ƒæ…®ã€èªå½™æŒ‡å®šãã‚Œãã‚Œã«ã†ã„ã¦ç‹¬è‡ªã®ã‚¿ã‚°ã‚’è¨­ã‘ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å½¢æˆã—ç¿»è¨³ã«ç‰¹åŒ–ã—ãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å­¦ç¿’ã€‚<br><br>IterativeDPOã§ã¯ã€DeepSeekV3ã«åŸºã¥ãLLM-as-a-Judgeã¨ã€MetricX(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2658" target="_blank" rel="noopener noreferrer">[Paper Note] MetricX-24: The Google Submission to the WMT 2024 Metrics Shared Task, Juraj Juraska+, arXiv'24</a>
)ã«åŸºã¥ã„ã¦Reward Modelã‚’ãã‚Œãã‚Œå­¦ç¿’ã—ã€1ã¤ã®å…¥åŠ›ã«å¯¾ã—ã¦100å€‹ã®ç¿»è¨³ã‚’ä½œæˆã—ãã‚Œãã‚Œã®Rewardãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚³ã‚¢ã®åˆè¨ˆå€¤ã«åŸºã¥ã„ã¦Rejection Samplingã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§Preference dataã‚’æ§‹ç¯‰ã€‚3æ®µéšã®DPOã‚’å®Ÿæ–½ã—ã€æ®µéšã”ã¨ã«Rewardãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ã¦é«˜å“è³ªãªPreference Dataã«çµã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã€‚<br><br>ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã§ã¯DPOã®å„æ®µéšã®ãƒ¢ãƒ‡ãƒ«ã‚’é‡ã¿ä»˜ãã§ãƒãƒ¼ã‚¸ã™ã‚‹ã“ã¨ã§å„æ®µéšã§ã®é•·æ‰€ã‚’çµ„ã¿åˆã‚ã›ãŸã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2516" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language  Models, Wen Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- dLLMsã¯ä¸­é–“äºˆæ¸¬ã‚’æ¨ã¦ãŒã¡ã ãŒã€æ™‚é–“çš„æŒ¯å‹•ãŒé‡è¦ãªç¾è±¡ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ™‚é–“çš„ä¸€è²«æ€§ã‚’æ´»ç”¨ã™ã‚‹2ã¤ã®æ–¹æ³•ã‚’ææ¡ˆã€‚1ã¤ç›®ã¯ã€ãƒ†ã‚¹ãƒˆæ™‚ã«äºˆæ¸¬ã‚’é›†ç´„ã™ã‚‹æ™‚é–“çš„è‡ªå·±ä¸€è²«æ€§æŠ•ç¥¨ã€2ã¤ç›®ã¯ä¸­é–“äºˆæ¸¬ã®å®‰å®šæ€§ã‚’æ¸¬ã‚‹æ™‚é–“çš„æ„å‘³ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚’å ±é…¬ä¿¡å·ã¨ã™ã‚‹æ™‚é–“çš„ä¸€è²«æ€§å¼·åŒ–ã€‚å®Ÿé¨“çµæœã§ã¯ã€Countdownãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§24.7%ã®æ”¹å–„ã‚’é”æˆã—ã€ä»–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚‚å‘ä¸Šã‚’ç¤ºã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€dLLMsã®æ™‚é–“çš„ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã®å¯èƒ½æ€§ãŒå¼·èª¿ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1958702248055513335?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>dLLMã®ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°éç¨‹ã«ãŠã„ã¦é€”ä¸­ã«æ­£è§£ãŒè¡¨å‡ºã—ã¦ã„ã‚‹ã®ã«æ™‚é–“ç™ºå±•ã¨ã¨ã‚‚ã«æ¶ˆãˆã¦ã—ã¾ã†å•é¡ŒãŒã‚ã‚‹ã‚‰ã—ãã€ãã‚Œã«å¯¾ã—ã¦ã€ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—ã«ãŠã„ã¦stableãªäºˆæ¸¬ã‚’è¡Œã†Self-Consistencyãƒ™ãƒ¼ã‚¹ã®decodingæ‰‹æ³•ã¨ã€æ„å‘³çš„ãªã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚’rewardã«åŠ ãˆæ™‚é–“ç™ºå±•ã§å®‰å®šã™ã‚‹ã‚ˆã†ã«post trainingã™ã‚‹ã“ã¨ã§å¯¾å‡¦ã—ã¾ã™ã€ã¿ãŸã„ãªè©±ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/DualLearning.html" target="_blank" rel="noopener noreferrer">#DualLearning</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2505" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DuPO: Enabling Reliable LLM Self-Verification via Dual Preference  Optimization, Shuaijie She+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- DuPOã¯ã€æ³¨é‡ˆãªã—ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆã™ã‚‹äºŒé‡å­¦ç¿’ã«åŸºã¥ãå¥½ã¿æœ€é©åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€å¼·åŒ–å­¦ç¿’ã®é«˜ä¾¡ãªãƒ©ãƒ™ãƒ«ä¾å­˜ã¨äºŒé‡ã‚¿ã‚¹ã‚¯ãƒšã‚¢ã®åˆ¶é™ã«å¯¾å‡¦ã€‚ãƒ—ãƒ©ã‚¤ãƒãƒ«ã‚¿ã‚¹ã‚¯ã®å…¥åŠ›ã‚’åˆ†è§£ã—ã€æœªçŸ¥ã®éƒ¨åˆ†ã‚’å†æ§‹ç¯‰ã™ã‚‹äºŒé‡ã‚¿ã‚¹ã‚¯ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã§ã€éå¯é€†ã‚¿ã‚¹ã‚¯ã¸ã®é©ç”¨ç¯„å›²ã‚’åºƒã’ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ç¿»è¨³å“è³ªã‚„æ•°å­¦çš„æ¨è«–ã®ç²¾åº¦ãŒå¤§å¹…ã«å‘ä¸Šã—ã€DuPOã¯ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§ä¸€èˆ¬çš„ãªLLMæœ€é©åŒ–ã®æ‰‹æ³•ã¨ã—ã¦ä½ç½®ä»˜ã‘ã‚‰ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1958413194307002415?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2508" target="_blank" rel="noopener noreferrer">[Paper Note] Dual Learning for Machine Translation, Yingce Xia+, NIPS'16</a>
</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1959926238065127724?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2503" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent  Distillation and Agentic RL, Weizhen Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Chain-of-Agentsï¼ˆCoAï¼‰ã¨ã„ã†æ–°ã—ã„LLMæ¨è«–ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ææ¡ˆã—ã€ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®å”åŠ›ã‚’å˜ä¸€ãƒ¢ãƒ‡ãƒ«å†…ã§ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã«å®Ÿç¾ã€‚ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè’¸ç•™ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ã¦ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçš„ãªæ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã„ã€å¼·åŒ–å­¦ç¿’ã§èƒ½åŠ›ã‚’å‘ä¸Šã€‚å¾—ã‚‰ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŸºç›¤ãƒ¢ãƒ‡ãƒ«ï¼ˆAFMsï¼‰ã¯ã€ã‚¦ã‚§ãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚„ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨­å®šã§æ–°ãŸãªæœ€å…ˆç«¯æ€§èƒ½ã‚’ç¤ºã™ã€‚ç ”ç©¶æˆæœã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã•ã‚Œã€ä»Šå¾Œã®ç ”ç©¶ã®åŸºç›¤ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1958186531161853995?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚ˆã†ã«æŒ¯ã‚‹èˆã†ã‚·ãƒ³ã‚°ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã€ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰å¾—ã‚‰ã‚ŒãŸtrajectoryã‚’é€šã˜ã¦è’¸ç•™ã™ã‚‹ã“ã¨ã‚å®Ÿç¾ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚SFTã§cold startã«å¯¾ã—ã¦è¨“ç·´ã—ãŸå¾Œã€verifiable reward (ã‚¿ã‚¹ã‚¯ã‚’æ­£å¸¸ã«å®Œäº†ã§ããŸã‹å¦ã‹)ã§RLã™ã‚‹æ¨¡æ§˜ã€‚<br><br><img src="https://github.com/user-attachments/assets/b4cafaba-488e-4d8b-a6d3-faf98733d134" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/80a934e9-db47-401b-809e-394ab5e20585" alt="image" loading="lazy"></p>
<p>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚å…¬é–‹ã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dongxi_nlp/status/1958604404338147417?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1959877518972137667?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2502" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] VisualWebInstruct: Scaling up Multimodal Instruction Data through Web   Search, Yiming Jia+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ¨è«–ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸è¶³ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€VisualWebInstructã¨ã„ã†æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚30,000ã®ã‚·ãƒ¼ãƒ‰ç”»åƒã‹ã‚‰Googleç”»åƒæ¤œç´¢ã‚’ç”¨ã„ã¦700Kä»¥ä¸Šã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªURLã‚’åé›†ã—ã€ç´„900Kã®QAãƒšã‚¢ã‚’æ§‹ç¯‰ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€Llava-OVã§10-20ãƒã‚¤ãƒ³ãƒˆã€MAmmoTH-VLã§5ãƒã‚¤ãƒ³ãƒˆã®æ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ã€æœ€è‰¯ãƒ¢ãƒ‡ãƒ«MAmmoTH-VL2ã¯è¤‡æ•°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Vision-Language Modelsã®æ¨è«–èƒ½åŠ›å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1958317145349075446?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2501" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Agent Laboratory: Using LLM Agents as Research Assistants, Samuel Schmidgall+, EMNLP'25 Findings</a>
<span class="snippet"><span>GPT Summary</span>- Agent Laboratoryã¯ã€å…¨è‡ªå‹•ã®LLMãƒ™ãƒ¼ã‚¹ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€ç ”ç©¶ã‚¢ã‚¤ãƒ‡ã‚¢ã‹ã‚‰æ–‡çŒ®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€å®Ÿé¨“ã€å ±å‘Šæ›¸ä½œæˆã¾ã§ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Œäº†ã—ã€è³ªã®é«˜ã„ç ”ç©¶æˆæœã‚’ç”Ÿæˆã—ã¾ã™ã€‚äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å„æ®µéšã§å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ã§ã€ç ”ç©¶ã®è³ªã‚’å‘ä¸Šã•ã›ã€ç ”ç©¶è²»ç”¨ã‚’84%å‰Šæ¸›ã€‚æœ€å…ˆç«¯ã®æ©Ÿæ¢°å­¦ç¿’ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã€ç§‘å­¦çš„ç™ºè¦‹ã®åŠ é€Ÿã‚’ç›®æŒ‡ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/srschmidgall/status/1958272229223067789?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj page:


<a href="https://agentlaboratory.github.io" target="_blank" rel="noopener noreferrer">https://agentlaboratory.github.io</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2485" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AutoCodeBench: Large Language Models are Automatic Code Benchmark  Generators, Jason Chou+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AutoCodeGenã‚’ææ¡ˆã—ã€æ‰‹å‹•æ³¨é‡ˆãªã—ã§é«˜é›£æ˜“åº¦ã®å¤šè¨€èªã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è‡ªå‹•ç”Ÿæˆã€‚ã“ã‚Œã«åŸºã¥ãã€3,920ã®å•é¡Œã‹ã‚‰ãªã‚‹AutoCodeBenchã‚’å°å…¥ã—ã€20ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã«å‡ç­‰ã«åˆ†é…ã€‚30ä»¥ä¸Šã®LLMsã‚’è©•ä¾¡ã—ãŸçµæœã€æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚å¤šæ§˜æ€§ã‚„è¤‡é›‘ã•ã«è‹¦åŠ´ã—ã¦ã„ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚AutoCodeBenchã‚·ãƒªãƒ¼ã‚ºã¯ã€å®Ÿç”¨çš„ãªå¤šè¨€èªã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚·ãƒŠãƒªã‚ªã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ãŸã‚ã®è²´é‡ãªãƒªã‚½ãƒ¼ã‚¹ã¨ãªã‚‹ã“ã¨ã‚’æœŸå¾…ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://autocodebench.github.io/" target="_blank" rel="noopener noreferrer">https://autocodebench.github.io/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tencenthunyuan/status/1957751900608110982?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Overthinking.html" target="_blank" rel="noopener noreferrer">#Overthinking</a>
<a class="button" href="articles/Underthinking.html" target="_blank" rel="noopener noreferrer">#Underthinking</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2478" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OptimalThinkingBench: Evaluating Over and Underthinking in LLMs, Pranjal Aggarwal+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ€è€ƒå‹LLMã¯è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ãã€å˜ç´”ãªå•é¡Œã«å¯¾ã—ã¦éå‰°ã«è€ƒãˆã€éæ€è€ƒå‹LLMã¯è¿…é€Ÿã ãŒé›£ã—ã„æ¨è«–ã«å¯¾ã—ã¦è€ƒãˆãŒæµ…ã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æœ€é©ãªãƒ¢ãƒ‡ãƒ«é¸æŠãŒã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å§”ã­ã‚‰ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€OptimalThinkingBenchã‚’å°å…¥ã—ã€éå‰°æ€è€ƒã¨è€ƒãˆä¸è¶³ã‚’è©•ä¾¡ã™ã‚‹çµ±ä¸€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æä¾›ã€‚72ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã®å˜ç´”ãªã‚¯ã‚¨ãƒªã¨11ã®æŒ‘æˆ¦çš„ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€2ã¤ã®ã‚µãƒ–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€33ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ãŸçµæœã€æœ€é©ãªæ€è€ƒãƒ¢ãƒ‡ãƒ«ã¯å­˜åœ¨ã›ãšã€æ€è€ƒå‹ãƒ¢ãƒ‡ãƒ«ã¯éå‰°ã«è€ƒãˆã€éæ€è€ƒå‹ãƒ¢ãƒ‡ãƒ«ã¯æµ…ã„çµæœã‚’ç¤ºã—ãŸã€‚å°†æ¥çš„ã«ã¯ã€ã‚ˆã‚Šè‰¯ã„çµ±ä¸€çš„ã‹ã¤æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã®å¿…è¦æ€§ãŒæµ®ãå½«ã‚Šã¨ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1957627532963926389?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ƒãƒã‚¹ãƒˆã®è‘—è€…ã«ã‚ˆã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰ãŒéå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„ã®ã§ãã¡ã‚‰ã‚’å‚ç…§ã®ã“ã¨ã€‚<br>ã–ã£ãã‚Šè¨€ã†ã¨ã€Overthinkingï¼ˆè€ƒãˆã™ãã¦å¤§é‡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¶ˆè²»ã—ãŸä¸Šã«å›ç­”ãŒèª¤ã£ã¦ã„ã‚‹; ãƒˆãƒ¼ã‚¯ãƒ³é‡â†“ã¨LLMã«ã‚ˆã‚‹Judge Scoreâ†‘ã§è©•ä¾¡ï¼‰ã¨Underthinkingï¼ˆå…¨ç„¶è€ƒãˆãšã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¶ˆè²»ã—ãªã‹ã£ãŸä¸Šã«å›ç­”ãŒèª¤ã£ã¦ã„ã‚‹; Accuracyâ†‘ã§è©•ä¾¡ï¼‰ã‚’ãã‚Œãã‚Œè©•ä¾¡ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚’åé›†ã—ã€ãã‚Œã‚‰ã®ã‚¹ã‚³ã‚¢ã®çµ„ã¿åˆã‚ã›ã§ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ã«å¿œã˜ã¦ã©ã‚Œã ã‘çš„ç¢ºã«Thinkingã§ãã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚<br><br>Overthinkingã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒ«ã¯ã€å¤šãã®LLMã§agreementãŒã¨ã‚Œã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªQAã«ã‚ˆã£ã¦æ§‹ç¯‰ã€‚ä¸€æ–¹ã€Underthinkingã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒ«ã¯ã€small reasoning modelãŒlarge non reasoning modelã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã™ã‚µãƒ³ãƒ—ãƒ«ã‚’åé›†ã€‚<br><img src="https://github.com/user-attachments/assets/5383e385-fda9-41ae-a9a5-aebf494ca79e" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/c08cfe60-8a29-4ebf-8875-081f7ae7d19f" alt="image" loading="lazy"><br><br>ç¾çŠ¶Non Thinking Modelã§ã¯Qwen3-235B-A22Bã®æ€§èƒ½ãŒè‰¯ãã€Thinking Modelã§ã¯gpt-oss-120Bã®æ€§èƒ½ãŒè‰¯ã„ã€‚ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãªãƒ¢ãƒ‡ãƒ«ã§ã¯ãã‚Œãã‚Œã€Claude-Sonnet4, o3ã®æ€§èƒ½ãŒè‰¯ã„ã€‚å…¨ä½“ã¨ã—ã¦ã¯o3ã®æ€§èƒ½ãŒæœ€ã‚‚è‰¯ã„ã€‚<br><img src="https://github.com/user-attachments/assets/5f5c1ead-d5fa-40a8-9a1b-90d4170ae3ee" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2476" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BeyondWeb: Lessons from Scaling Synthetic Data for Trillion-scale  Pretraining, Pratyush Maini+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒBeyondWebã€ã‚’ææ¡ˆã—ã€é«˜å“è³ªãªåˆæˆãƒ‡ãƒ¼ã‚¿ã®ç”ŸæˆãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚BeyondWebã¯ã€å¾“æ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’ç™ºæ®ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é€Ÿåº¦ã‚‚å‘ä¸Šã€‚ç‰¹ã«ã€3Bãƒ¢ãƒ‡ãƒ«ãŒ8Bãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã™ã€‚åˆæˆãƒ‡ãƒ¼ã‚¿ã®å“è³ªå‘ä¸Šã«ã¯å¤šãã®è¦å› ã‚’æœ€é©åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€å˜ç´”ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯é™ç•ŒãŒã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/pratyushmaini/status/1957456720265154752?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/CrossDomain.html" target="_blank" rel="noopener noreferrer">#CrossDomain</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-08-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2466" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] xbench: Tracking Agents Productivity Scaling with Profession-Aligned  Real-World Evaluations, Kaiyuan Chen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã€Œxbenchã€ã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã¨å®Ÿä¸–ç•Œã®ç”Ÿç”£æ€§ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸå‹•çš„ãªè©•ä¾¡ã‚¹ã‚¤ãƒ¼ãƒˆã§ã€æ¥­ç•Œå°‚é–€å®¶ãŒå®šç¾©ã—ãŸã‚¿ã‚¹ã‚¯ã‚’ç”¨ã„ã¦å•†æ¥­çš„ã«é‡è¦ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã—ã¦ã„ã¾ã™ã€‚ãƒªã‚¯ãƒ«ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã¨ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã®2ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æç¤ºã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®åŸºæº–ã‚’ç¢ºç«‹ã—ã¾ã™ã€‚è©•ä¾¡çµæœã¯ç¶™ç¶šçš„ã«æ›´æ–°ã•ã‚Œã€https://xbench.org ã§å…¥æ‰‹å¯èƒ½ã§ã™ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2455" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Survey on Parallel Text Generation: From Parallel Decoding to  Diffusion Language Models, Lingzhe Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ä¸¦åˆ—ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã¯ã€LLMã®ç”Ÿæˆé€Ÿåº¦ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æŠ€è¡“ã§ã‚ã‚Šã€è‡ªå·±å›å¸°ç”Ÿæˆã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’æ‰“ç ´ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ä¸¦åˆ—ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆæ‰‹æ³•ã‚’ARãƒ™ãƒ¼ã‚¹ã¨éARãƒ™ãƒ¼ã‚¹ã«åˆ†é¡ã—ã€ãã‚Œãã‚Œã®æŠ€è¡“ã‚’è©•ä¾¡ã€‚é€Ÿåº¦ã€å“è³ªã€åŠ¹ç‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è€ƒå¯Ÿã—ã€ä»Šå¾Œã®ç ”ç©¶ã®æ–¹å‘æ€§ã‚’ç¤ºã™ã€‚é–¢é€£è«–æ–‡ã‚’é›†ã‚ãŸGitHubãƒªãƒã‚¸ãƒˆãƒªã‚‚ä½œæˆã€‚</span>
<span class="snippet"><span>Comment</span><p>Taxonomyã¨æ‰‹æ³•ä¸€è¦§ã€‚Draft and Verifyingã¯å€‹äººçš„ã«éå¸¸ã«èˆˆå‘³ãŒã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/019469c3-f906-42e3-91d9-f99f75d8d501" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Trustfulness.html" target="_blank" rel="noopener noreferrer">#Trustfulness</a>
<a class="button" href="articles/Health.html" target="_blank" rel="noopener noreferrer">#Health</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2452" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] HealthBench: Evaluating Large Language Models Towards Improved Human  Health, Rahul K. Arora+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒHealthBenchã€ã‚’ç™ºè¡¨ã€‚5,000ä»¶ã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã‚’åŸºã«ã€262äººã®åŒ»å¸«ã«ã‚ˆã‚‹è©•ä¾¡åŸºæº–ã§ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¨å®‰å…¨æ€§ã‚’æ¸¬å®šã€‚å¾“æ¥ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ç•°ãªã‚Šã€48,562ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªè©•ä¾¡åŸºæº–ã‚’ç”¨ã„ã¦å¤šæ§˜ãªå¥åº·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è©•ä¾¡ã€‚GPT-3.5 Turboã¨GPT-4oã®æ¯”è¼ƒã§åˆæœŸã®é€²å±•ã‚’ç¤ºã—ã€å°å‹ãƒ¢ãƒ‡ãƒ«ã®æ”¹å–„ãŒé¡•è‘—ã€‚æ–°ãŸã«ã€ŒHealthBench Consensusã€ã¨ã€ŒHealthBench Hardã€ã®2ã¤ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ãƒªãƒªãƒ¼ã‚¹ã€‚HealthBenchãŒå¥åº·åˆ†é‡ã§ã®ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’æœŸå¾…ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2451" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents, Jason Wei+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- BrowseCompã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¦ã‚§ãƒ–ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã®1,266ã®è³ªå•ã‹ã‚‰ãªã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€çµ¡ã¿åˆã£ãŸæƒ…å ±ã‚’æ¢ã™ã“ã¨ã‚’è¦æ±‚ã—ã¾ã™ã€‚ã‚·ãƒ³ãƒ—ãƒ«ã§ä½¿ã„ã‚„ã™ãã€çŸ­ã„å›ç­”ãŒæ±‚ã‚ã‚‰ã‚Œã€å‚ç…§å›ç­”ã¨ã®ç…§åˆãŒå®¹æ˜“ã§ã™ã€‚ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã€ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®é‡è¦ãªãƒ„ãƒ¼ãƒ«ã§ã‚ã‚Šã€æŒç¶šåŠ›ã¨å‰µé€ æ€§ã‚’æ¸¬å®šã—ã¾ã™ã€‚è©³ç´°ã¯GitHubã§å…¥æ‰‹å¯èƒ½ã§ã™ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2447" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] UI-Venus Technical Report: Building High-performance UI Agents with RFT, Zhangxuan Gu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- UI-Venusã¯ã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ããƒã‚¤ãƒ†ã‚£ãƒ–UIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã€UIã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã¨ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚7BãŠã‚ˆã³72Bãƒãƒªã‚¢ãƒ³ãƒˆã¯ã€Screenspot-V2 / Proãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é«˜ã„æˆåŠŸç‡ã‚’è¨˜éŒ²ã—ã€æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã€‚å ±é…¬é–¢æ•°ã‚„ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã‚’å°å…¥ã—ã€ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æ–°ã—ã„è‡ªå·±é€²åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚‚ææ¡ˆã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®UIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å…¬é–‹ã—ã€ã•ã‚‰ãªã‚‹ç ”ç©¶ã‚’ä¿ƒé€²ã€‚ã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¥æ‰‹å¯èƒ½ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1956344636831662567?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1957262667493826891?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/collections/inclusionAI/ui-venus-689f2fb01a4234cbce91c56a" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/inclusionAI/ui-venus-689f2fb01a4234cbce91c56a</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2436" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OpenCUA: Open Foundations for Computer-Use Agents, Xinyuan Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- OpenCUAã¯ã€CUAãƒ‡ãƒ¼ã‚¿ã¨åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚¤ãƒ³ãƒ•ãƒ©ã€AgentNetãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€åå°„çš„ãªChain-of-Thoughtæ¨è«–ã‚’æŒã¤ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã€‚OpenCUA-32Bã¯ã€CUAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§34.8%ã®æˆåŠŸç‡ã‚’é”æˆã—ã€æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ç¤ºã™ã€‚ç ”ç©¶ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãŸã‚ã«ã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1956157162830418062?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xywang626/status/1956400403911962757?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>CUAã«ãŠã„ã¦Proprietaryãƒ¢ãƒ‡ãƒ«ã«è¿‘ã„æ€§èƒ½ã‚’é”æˆã—ãŸåˆã‚ã¦ã®ç ”ç©¶ãªæ¨¡æ§˜ã€‚é‡è¦</p>
<p>ç¶šå ±:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xywang626/status/1973426575837438389?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>OSWorld Verifiedã§UI-TARS-250705,claude-4-sonnet-20250514è¶…ãˆã§top1ã«å›è‡¨ã¨ã®ã“ã¨ã€‚</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2432" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond  Competitive Programming, Gal Beniamini+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢AIãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€å®Ÿéš›ã®ç ”ç©¶å•é¡Œã«åŸºã¥ããƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒFormulaOneã€ã‚’æ§‹ç¯‰ã€‚ã“ã‚Œã¯ã€ã‚°ãƒ©ãƒ•ç†è«–ã‚„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«é–¢é€£ã™ã‚‹é›£æ˜“åº¦ã®é«˜ã„å•é¡Œã§ã€å•†æ¥­çš„é–¢å¿ƒã‚„ç†è«–è¨ˆç®—æ©Ÿç§‘å­¦ã«é–¢é€£ã€‚æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã¯FormulaOneã§ã»ã¨ã‚“ã©è§£æ±ºã§ããšã€å°‚é–€å®¶ãƒ¬ãƒ™ãƒ«ã®ç†è§£ã‹ã‚‰é ã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ç ”ç©¶æ”¯æ´ã®ãŸã‚ã«ã€ç°¡å˜ãªã‚¿ã‚¹ã‚¯ã‚»ãƒƒãƒˆã€ŒFormulaOne-Warmupã€ã‚’æä¾›ã—ã€è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚‚å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shai_s_shwartz/status/1955968602978320727?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ZeroshotHyperparameterTransfer.html" target="_blank" rel="noopener noreferrer">#ZeroshotHyperparameterTransfer</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2430" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] $Î¼$-Parametrization for Mixture of Experts, Jan MaÅ‚aÅ›nicki+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Mixture-of-Expertsï¼ˆMoEï¼‰ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹$\mu$-Parameterizationï¼ˆ$\mu$Pï¼‰ã‚’ææ¡ˆã—ã€ãƒ«ãƒ¼ã‚¿ãƒ¼ã¨ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ç‰¹å¾´å­¦ç¿’ã«é–¢ã™ã‚‹ç†è«–çš„ä¿è¨¼ã‚’æä¾›ã—ã¾ã™ã€‚ã¾ãŸã€ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®æ•°ã¨ç²’åº¦ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒæœ€é©ãªå­¦ç¿’ç‡ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’å®Ÿè¨¼çš„ã«æ¤œè¨¼ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1956103561126789339?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£: mu transfer, muP<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2582" target="_blank" rel="noopener noreferrer">[Paper Note] Tensor Programs V: Tuning Large Neural Networks via Zero-Shot  Hyperparameter Transfer, Greg Yang+, NeurIPS'21</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2583" target="_blank" rel="noopener noreferrer">[Paper Note] Feature Learning in Infinite-Width Neural Networks, Greg Yang+, PMLR'21</a>
</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2428" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Less Is More: Training-Free Sparse Attention with Global Locality for  Efficient Reasoning, Lijie Yang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã€ŒLessIsMoreã€ã¨ã„ã†æ–°ã—ã„ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸è¦ã§ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ´»ç”¨ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³é¸æŠã‚’åŠ¹ç‡åŒ–ã€‚ç²¾åº¦ã‚’ç¶­æŒã—ã¤ã¤ã€ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é€Ÿåº¦ã‚’1.1å€å‘ä¸Šã•ã›ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’2å€å‰Šæ¸›ã€‚æ—¢å­˜æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦1.13å€ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lijieyyang/status/1955139186530328633?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒªãƒ¼ã§1.1å€ã®ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é€Ÿåº¦ã§æ€§èƒ½ã‚‚Full Attentionã¨åŒç­‰ä»¥ä¸Šã®Sparse Attentionã‚‰ã—ã„</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2427" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Policy Cliff: A Theoretical Analysis of Reward-Policy Maps in Large  Language Models, Xingcheng Xu, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®è¡Œå‹•å½¢æˆã«é‡è¦ã ãŒã€è„†å¼±ãªãƒãƒªã‚·ãƒ¼ã‚’ç”Ÿæˆã—ã€ä¿¡é ¼æ€§ã‚’æãªã†å•é¡ŒãŒã‚ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€å ±é…¬é–¢æ•°ã‹ã‚‰æœ€é©ãƒãƒªã‚·ãƒ¼ã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã®å®‰å®šæ€§ã‚’åˆ†æã™ã‚‹æ•°å­¦çš„æ çµ„ã¿ã‚’ææ¡ˆã—ã€ãƒãƒªã‚·ãƒ¼ã®è„†å¼±æ€§ãŒéä¸€æ„çš„ãªæœ€é©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«èµ·å› ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã•ã‚‰ã«ã€å¤šå ±é…¬RLã«ãŠã‘ã‚‹å®‰å®šæ€§ãŒã€ŒåŠ¹æœçš„å ±é…¬ã€ã«ã‚ˆã£ã¦æ”¯é…ã•ã‚Œã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã€ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ­£å‰‡åŒ–ãŒå®‰å®šæ€§ã‚’å›å¾©ã™ã‚‹ã“ã¨ã‚’è¨¼æ˜ã™ã‚‹ã€‚ã“ã®ç ”ç©¶ã¯ã€ãƒãƒªã‚·ãƒ¼å®‰å®šæ€§åˆ†æã‚’é€²å±•ã•ã›ã€å®‰å…¨ã§ä¿¡é ¼æ€§ã®é«˜ã„AIã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã«å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1955909877404197072?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã¨ã¦ã‚‚é¢ç™½ãã†</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2426" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale  Asynchronous RL, Jiaxuan Gao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ASearcherã¯ã€LLMãƒ™ãƒ¼ã‚¹ã®æ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¤§è¦æ¨¡ãªRLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿç¾ã™ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã‚ã‚Šã€é«˜åŠ¹ç‡ãªéåŒæœŸRLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨è‡ªå¾‹çš„ã«åˆæˆã•ã‚ŒãŸé«˜å“è³ªãªQ&amp;Aãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€æ¤œç´¢èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ææ¡ˆã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€xBenchã§46.7%ã€GAIAã§20.8%ã®æ”¹å–„ã‚’é”æˆã—ã€é•·æœŸçš„ãªæ¤œç´¢èƒ½åŠ›ã‚’ç¤ºã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§æä¾›ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1955603041518035358?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jxwuyi/status/1955487396344238486?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1955266026498855354?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2466" target="_blank" rel="noopener noreferrer">[Paper Note] xbench: Tracking Agents Productivity Scaling with Profession-Aligned
  Real-World Evaluations, Kaiyuan Chen+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1158" target="_blank" rel="noopener noreferrer">GAIA: a benchmark for General AI Assistants, GrÃ©goire Mialon+, N/A, arXiv'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1461" target="_blank" rel="noopener noreferrer">[Paper Note] Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented  Generation, Satyapriya Krishna+, N/A, NAACL'25</a>
</p>
<p>æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã¯ &lt;= 10 turnsã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã•ã‚Œã¦ãŠã‚Šã€å¤§è¦æ¨¡ã§é«˜å“è³ªãªQAãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹å•é¡ŒãŒã‚ã£ãŸãŒã€ã‚·ãƒ¼ãƒ‰QAã«åŸºã¥ã„ã¦QAã‚’åˆæˆã™ã‚‹æ‰‹æ³•ã«ã‚ˆã£ã¦1.4ä¸‡ã‚·ãƒ¼ãƒ‰QAã‹ã‚‰134kã®é«˜å“è³ªãªQAã‚’åˆæˆã—ãŸï¼ˆã†ã¡25.6kã¯ãƒ„ãƒ¼ãƒ«åˆ©ç”¨ãŒå¿…è¦ï¼‰ã€‚å…·ä½“çš„ã«ã¯ã€ã‚·ãƒ¼ãƒ‰ã®QAã‚’åˆæˆã—ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒQAã®è¤‡é›‘åº¦ã‚’iterationã‚’ã—ãªãŒã‚‰å‘ä¸Šã•ã›ã¦ã„ãæ‰‹æ³•ã‚’ææ¡ˆã€‚äº‹å®Ÿæƒ…å ±ã¯å¸¸ã«verificationã‚’ã•ã‚Œã€åˆæˆãƒ—ãƒ­ã‚»ã‚¹ã®iterationã®ä¸­ã§ä¿æŒã•ã‚Œç¶šã‘ã‚‹ã€‚å€‹ã€…ã®iterationã«ãŠã„ã¦ã€ç¾åœ¨ã®QAã¨äº‹å®Ÿæƒ…å ±ã«åŸºã¥ã„ã¦ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯<br>- Injection: äº‹å®Ÿæƒ…å ±ã‚’æ–°ãŸã«æ³¨å…¥ã—QAã‚’ã‚ˆã‚Šãƒªãƒƒãƒã«ã™ã‚‹ã“ã¨ã§è¤‡é›‘åº¦ã‚’ä¸Šã’ã‚‹<br>- Fuzz: QAä¸­ã®ä¸€éƒ¨ã®è©³ç´°ãªæƒ…å ±ã‚’ã¼ã‹ã™ã“ã¨ã§ã€ä¸ç¢ºå®Ÿæ€§ã®ãƒ¬ãƒ™ãƒ«ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚<br>ã®2ç¨®é¡ã®æ“ä½œã‚’å®Ÿæ–½ã™ã‚‹ã€‚ãã®ä¸Šã§ã€QAã«å¯¾ã—ã¦Quality verificationã‚’å®Ÿæ–½ã™ã‚‹:<br>- Basic Quality: LLMã§qualityã‚’è©•ä¾¡ã™ã‚‹<br>- Difficulty Measurement: LRMã«ã‚ˆã£ã¦ã€è¤‡æ•°ã®å›ç­”å€™è£œã‚’ç”Ÿæˆã™ã‚‹<br>- Answer Uniqueness: Difficulty Measurementã§ç”Ÿæˆã•ã‚ŒãŸè¤‡æ•°ã®è§£ç­”æƒ…å ±ã«åŸºã¥ã„ã¦ã€mismatched answersãŒvalid answerã¨ãªã‚‹ã‹å¦ã‹ã‚’æ¤œè¨¼ã—ã€æ­£è§£ãŒå˜ä¸€ã§ã‚ã‚‹ã“ã¨ã‚’æ‹…ä¿ã™ã‚‹<br><br>&lt;img width="907" height="561" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/d020fc8f-b1da-4425-981a-6759cba5824b"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/d020fc8f-b1da-4425-981a-6759cba5824b"&lt;/a&gt;


/&gt;<br><br>ã¾ãŸã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã€ç‰¹ã«tool callsãŒéå¸¸ã«å¤šã„ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦ã¯ã€å¤šãã®ã‚¿ãƒ¼ãƒ³æ•°ï¼ˆlong trajectoriesï¼‰ãŒå¿…è¦ã¨ãªã‚‹ãŒã€æ—¢å­˜ã®ãƒãƒƒãƒã«åŸºã¥ã„ãŸå­¦ç¿’æ‰‹æ³•ã§ã¯long trajectoriesã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’ã—ã¦ã„ã‚‹é–“ã€ä»–ã®ã‚µãƒ³ãƒ—ãƒ«ã®å­¦ç¿’ãŒãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã—ã¾ã„å­¦ç¿’åŠ¹ç‡ãŒéå¸¸ã«æ‚ªã„ã®ã§ã€ãƒãƒƒãƒå†…ã®trajectoryã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã®æ›´æ–°ã‚’åˆ†é›¢ï¼ˆãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒåˆ¥ã‚µãƒ¼ãƒã«é€ä¿¡ã•ã‚Œã‚µãƒ¼ãƒä¸Šã®Inference Engineã§éåŒæœŸã«å®Ÿè¡Œã•ã‚Œã€ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚‹å´ã¯ååˆ†ãªtrajectoryãŒãƒãƒƒãƒå†…ã§æƒã£ãŸã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã€ã¿ãŸã„ãªæŒ™å‹•ï¼Ÿï¼‰ã™ã‚‹ã“ã¨ã§Idleã‚¿ã‚¤ãƒ ã‚’ç„¡ãã™ã‚ˆã†ãªæ‰‹æ³•ã‚’ææ¡ˆã—ãŸæ¨¡æ§˜ã€‚<br><br>&lt;img width="873" height="466" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/65d7e7b1-25fb-4288-a85e-07ae7a5eea2f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/65d7e7b1-25fb-4288-a85e-07ae7a5eea2f"&lt;/a&gt;


/&gt;</p>
<p>æ—¢å­˜ã®æ‰‹æ³•ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ€§èƒ½ã¯å‘ä¸Šã—ã¦ã„ã‚‹ã€‚å­¦ç¿’ãŒé€²ã‚€ã«ã¤ã‚Œã¦ã€trajectoryä¸­ã®URLå‚ç…§å›æ•°ã‚„search queryæ•°ãªã©ãŒå¢—å¤§ã—ã¦ã„ãæ›²ç·šã¯è€ƒå¯Ÿã•ã‚Œã¦ã„ã‚‹ã€‚ä»–ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦ã€ã‚ˆã‚Šå¤šã„ã‚¿ãƒ¼ãƒ³æ•°ã‚’ã‚ˆã‚Šé«˜ã„æ­£ç¢ºæ€§ã‚’ä»¥ã£ã¦å®Ÿè¡Œã§ãã‚‹ã¨ã„ã£ãŸå®šé‡çš„ãªãƒ‡ãƒ¼ã‚¿ã¯ã¾ã å­˜åœ¨ã—ãªã„ã‚ˆã†ã«è¦‹ãˆãŸã€‚<br><br>&lt;img width="891" height="778" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/70644da8-b862-4bcb-bb05-d915c815b885"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/70644da8-b862-4bcb-bb05-d915c815b885"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2424" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebWatcher: Breaking New Frontier of Vision-Language Deep Research Agent, Xinyu Geng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- WebWatcherã¯ã€è¦–è¦šã¨è¨€èªã®æ¨è«–èƒ½åŠ›ã‚’å¼·åŒ–ã—ãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã‚ã‚Šã€æƒ…å ±æ¢ç´¢ã®å›°é›£ã•ã«å¯¾å‡¦ã™ã‚‹ã€‚åˆæˆãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è»Œè·¡ã‚’ç”¨ã„ãŸåŠ¹ç‡çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚Šã€æ·±ã„æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚æ–°ãŸã«ææ¡ˆã•ã‚ŒãŸBrowseComp-VLãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®å®Ÿé¨“ã«ã‚ˆã‚Šã€WebWatcherã¯è¤‡é›‘ãªVQAã‚¿ã‚¹ã‚¯ã§ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/richardxp888/status/1955645614685077796?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…¬å¼:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ali_tongyilab/status/1961348492506665289?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2423" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Geometric-Mean Policy Optimization, Yuzhong Zhao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- GRPOã®ä¸å®‰å®šæ€§ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€å¹¾ä½•å¹³å‡ã‚’æœ€é©åŒ–ã™ã‚‹GMPOã‚’ææ¡ˆã€‚GMPOã¯å¤–ã‚Œå€¤ã«æ•æ„Ÿã§ãªãã€å®‰å®šã—ãŸé‡è¦åº¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¯”ç‡ã‚’ç¶­æŒã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€GMPO-7Bã¯è¤‡æ•°ã®æ•°å­¦çš„ãŠã‚ˆã³ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§GRPOã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zzlccc/status/1955823092904943816?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1955879567354388926?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/Overthinking.html" target="_blank" rel="noopener noreferrer">#Overthinking</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2422" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Sample More to Think Less: Group Filtered Policy Optimization for  Concise Reasoning, Vaishnavi Shrivastava+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- GFPOï¼ˆGroup Filtered Policy Optimizationï¼‰ã‚’ææ¡ˆã—ã€å¿œç­”ã®é•·ã•ã®è†¨å¼µã‚’æŠ‘åˆ¶ã€‚å¿œç­”ã‚’é•·ã•ã¨ãƒˆãƒ¼ã‚¯ãƒ³åŠ¹ç‡ã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã€æ¨è«–æ™‚ã®è¨ˆç®—é‡ã‚’å‰Šæ¸›ã€‚Phi-4ãƒ¢ãƒ‡ãƒ«ã§é•·ã•ã®è†¨å¼µã‚’46-71%å‰Šæ¸›ã—ã€ç²¾åº¦ã‚’ç¶­æŒã€‚Adaptive Difficulty GFPOã«ã‚ˆã‚Šã€é›£æ˜“åº¦ã«å¿œã˜ãŸè¨“ç·´ãƒªã‚½ãƒ¼ã‚¹ã®å‹•çš„å‰²ã‚Šå½“ã¦ã‚’å®Ÿç¾ã€‚åŠ¹ç‡çš„ãªæ¨è«–ã®ãŸã‚ã®åŠ¹æœçš„ãªãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zzlccc/status/1955823092904943816?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1955884039149380067?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vaishshrivas/status/1956096081504436620?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2418" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Can Language Models Falsify? Evaluating Algorithmic Reasoning with  Counterexample Creation, Shiven Sinha+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLMï¼‰ã®ç§‘å­¦çš„ç™ºè¦‹ã‚’åŠ é€Ÿã™ã‚‹ãŸã‚ã«ã€å¾®å¦™ã«èª¤ã£ãŸè§£æ±ºç­–ã«å¯¾ã™ã‚‹åä¾‹ã‚’ä½œæˆã™ã‚‹èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒREFUTEã€ã‚’ææ¡ˆã€‚ã“ã‚Œã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å•é¡Œã‹ã‚‰ã®èª¤ã£ãŸæå‡ºç‰©ã‚’ç”¨ã„ã¦ãŠã‚Šã€æœ€ã‚‚å„ªã‚ŒãŸæ¨è«–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã‚‚9%æœªæº€ã®åä¾‹ã—ã‹ç”Ÿæˆã§ããªã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã®ç ”ç©¶ã¯ã€LMã®èª¤ã£ãŸè§£æ±ºç­–ã‚’å¦å®šã™ã‚‹èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã€ä¿¡é ¼ã§ãã‚‹æ¨è«–ã‚’é€šã˜ã¦è‡ªå·±æ”¹å–„ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://falsifiers.github.io" target="_blank" rel="noopener noreferrer">https://falsifiers.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shashwatgoel7/status/1955311868915966173?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚°ã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã¨task descriptionãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€inputã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨å…¨ã¦ã®åˆ¶ç´„ã‚’æº€ãŸã™ãŒã€ã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡ŒãŒå¤±æ•—ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ï¼ˆï¼åä¾‹ï¼‰ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®reasoning capabilityã®è©•ä¾¡ã‚’ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚<br><br>gpt-ossã¯ã‚³ãƒ¼ãƒ‰ã«ãƒã‚°ã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã«å¯¾ã—ã¦ä¸Šè¨˜ã®ã‚ˆã†ãªåä¾‹ã‚’ç”Ÿæˆã™ã‚‹èƒ½åŠ›ãŒé«˜ã„ã‚ˆã†ã§ã‚ã‚‹ã€‚ãŸã ã—ã€ãã‚Œã§ã‚‚å…¨ä½“ã®ãƒã‚°ã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã®ã†ã¡åä¾‹ã‚’ç”Ÿæˆã§ããŸã®ã¯é«˜ã€…21.6%ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚ãŸã ã€ã‚‚ã—ã‚³ãƒ¼ãƒ‰ã ã‘ã§ãªãverificationå…¨èˆ¬ã®èƒ½åŠ›ãŒé«˜ã„ã‹ã‚‰ã€ç›¸å½“ä½¿ã„é“ãŒã‚ã‚Šãã†ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2417" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unveiling Super Experts in Mixture-of-Experts Large Language Models, Zunhai Su+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¹ãƒ‘ãƒ¼ã‚¹ã«æ´»æ€§åŒ–ã•ã‚ŒãŸMixture-of-Expertsï¼ˆMoEï¼‰ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€ç‰¹å®šã®å°‚é–€å®¶ã®ã‚µãƒ–ã‚»ãƒƒãƒˆã€Œã‚¹ãƒ¼ãƒ‘å°‚é–€å®¶ï¼ˆSEï¼‰ã€ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«é‡è¦ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚SEã¯ç¨€ãªæ´»æ€§åŒ–ã‚’ç¤ºã—ã€ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã¨ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ãŒåŠ£åŒ–ã™ã‚‹ã€‚åˆ†æã«ã‚ˆã‚Šã€SEã®é‡è¦æ€§ãŒæ•°å­¦çš„æ¨è«–ãªã©ã®ã‚¿ã‚¹ã‚¯ã§æ˜ã‚‰ã‹ã«ãªã‚Šã€MoE LLMãŒSEã«ä¾å­˜ã—ã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1955217132016505239?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MoEã«ãŠã‘ã‚‹ã€ç‰¹ã«é‡è¦ãªå°‚é–€å®¶ã§ã‚ã‚‹Super Expertsã®å­˜åœ¨</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1566" target="_blank" rel="noopener noreferrer">The Super Weight in Large Language Models, Mengxia Yu+, arXiv'24</a>
<br><br>ã‚’æ€ã„å‡ºã™ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MCP.html" target="_blank" rel="noopener noreferrer">#MCP</a>
<span class="issue_date">Issue Date: 2025-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2415" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LiveMCPBench: Can Agents Navigate an Ocean of MCP Tools?, Guozhao Mo+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LiveMCPBenchã¯ã€10,000ã‚’è¶…ãˆã‚‹MCPã‚µãƒ¼ãƒãƒ¼ã«åŸºã¥ã95ã®å®Ÿä¸–ç•Œã‚¿ã‚¹ã‚¯ã‹ã‚‰æˆã‚‹åˆã®åŒ…æ‹¬çš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¤§è¦æ¨¡è©•ä¾¡ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚70ã®MCPã‚µãƒ¼ãƒãƒ¼ã¨527ã®ãƒ„ãƒ¼ãƒ«ã‚’å«ã‚€LiveMCPToolã‚’æ•´å‚™ã—ã€LLM-as-a-Judgeãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹LiveMCPEvalã‚’å°å…¥ã—ã¦è‡ªå‹•åŒ–ã•ã‚ŒãŸé©å¿œè©•ä¾¡ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚MCP Copilot Agentã¯ã€ãƒ„ãƒ¼ãƒ«ã‚’å‹•çš„ã«è¨ˆç”»ã—å®Ÿè¡Œã™ã‚‹ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚è©•ä¾¡ã®çµæœã€æœ€ã‚‚å„ªã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯78.95%ã®æˆåŠŸç‡ã‚’é”æˆã—ã¾ã—ãŸãŒã€ãƒ¢ãƒ‡ãƒ«é–“ã§æ€§èƒ½ã®ã°ã‚‰ã¤ããŒè¦‹ã‚‰ã‚Œã¾ã—ãŸã€‚å…¨ä½“ã¨ã—ã¦ã€LiveMCPBenchã¯LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ãŸãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://icip-cas.github.io/LiveMCPBench/" target="_blank" rel="noopener noreferrer">https://icip-cas.github.io/LiveMCPBench/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1955324566298833127?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MCPç’°å¢ƒã«ãŠã‘ã‚‹LLM Agentã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚è«–æ–‡ä¸­ã®Table1ã«ä»–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å«ã‚ã‚µãƒãƒªãŒæ²è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚MCPã‚’ç”¨ã„ãŸLLMAgentã®ãƒ™ãƒ³ãƒãŒã™ã§ã«ã“ã‚“ãªã«ã‚ã‚‹ã“ã¨ã«é©šã„ãŸâ€¦ã€‚<br><img src="https://github.com/user-attachments/assets/29472068-380b-421c-b82d-fd14831b07ff" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Cultural.html" target="_blank" rel="noopener noreferrer">#Cultural</a>
<span class="issue_date">Issue Date: 2025-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2413" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Grounding Multilingual Multimodal LLMs With Cultural Knowledge, Jean de Dieu Nyandwi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MLLMsã¯é«˜ãƒªã‚½ãƒ¼ã‚¹ç’°å¢ƒã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ãŒã€ä½ãƒªã‚½ãƒ¼ã‚¹è¨€èªã‚„æ–‡åŒ–çš„ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«å¯¾ã—ã¦ã¯èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€Wikidataã‚’æ´»ç”¨ã—ã€æ–‡åŒ–çš„ã«é‡è¦ãªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’è¡¨ã™ç”»åƒã‚’ç”¨ã„ãŸå¤šè¨€èªè¦–è¦šè³ªå•å¿œç­”ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒCulturalGroundã€ã‚’ç”Ÿæˆã€‚CulturalPangeaã¨ã„ã†ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®MLLMã‚’è¨“ç·´ã—ã€æ–‡åŒ–ã«åŸºã¥ã„ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒMLLMsã®æ–‡åŒ–çš„ã‚®ãƒ£ãƒƒãƒ—ã‚’ç¸®å°ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚CulturalPangeaã¯ã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¹³å‡5.0ãƒã‚¤ãƒ³ãƒˆä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1955308632305782957?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj page:


<a href="https://neulab.github.io/CulturalGround/" target="_blank" rel="noopener noreferrer">https://neulab.github.io/CulturalGround/</a>


<br><br>VQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸­ã®æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã¯3.1%ç¨‹åº¦ã§ã€&lt;image, Question, answer&gt;ã®3ã¤çµ„ã§æ§‹æˆã•ã‚Œã‚‹ã€‚wikidataã‹ã‚‰ç‰¹å®šã®æ–‡åŒ–ã¨ç´ã¥ã„ãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆ42ã‚«å›½; äºº,å ´æ‰€,çµ„ç¹”,ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ï¼‰ã‚’æŠ½å‡ºã—ã€é–¢é€£ã™ã‚‹image dataã‚’1--3å€‹ç¨‹åº¦wikimediaã‹ã‚‰åé›†ã€‚76ç¨®é¡ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”¨ã„ã¦ã€draftã®QAã‚’ç”Ÿæˆã—ã€LLMã‚’ç”¨ã„ã¦æ´—ç·´ï¼ˆæ–‡åŒ–çš„ãªè‡ªç„¶ã•ã€æµæš¢ã•ï¼‰ã•ã›ã‚‹ã€‚æœ€çµ‚çš„ã«VLM(Qwen2.5-VL-32B/72B or Gemma-3-12B/72B-Instructã‚’æ–‡åŒ–ã”ã¨ã«å¼·ã„æ–¹ã‚’é¸æŠã—ã¦åˆ©ç”¨)ã‚’ç”¨ã„ã¦irrelevantãªimage, question, answerã®ä¸‰ã¤çµ„ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆrelevanceã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã¨äº‹å®Ÿæƒ…å ±ã®verification)ã™ã‚‹ã€‚<br><br>ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2470" target="_blank" rel="noopener noreferrer">[Paper Note] Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages, Xiang Yue+, arXiv'24</a>
<br><br>ã‚’åˆ©ç”¨(Qwen2-7Bã«å¯¾ã—ã¦CLIPãƒ™ãƒ¼ã‚¹ã®vision encoderã‚’åˆ©ç”¨ã—ãŸVLM)ã—ã€Vision Encoderã¯frozenã—ã€LLMã¨connectorï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®æ©‹æ¸¡ã—ã‚’ã™ã‚‹ï¼ˆå¤§æŠµã¯ï¼‰MLP)ã®ã¿ã‚’finetuningã—ãŸã€‚catastrophic forgettingã‚’é˜²ããŸã‚ã«äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã‚’è£œå®Œã—finetuningã§ã‚‚åˆ©ç”¨ã—ã€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®èªè­˜åŠ›ã‚’é«˜ã‚ã‚‹ãŸã‚ã«M3LSãƒ‡ãƒ¼ã‚¿ãªã‚‹ã‚‚ã®ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦è¿½åŠ ã—ã¦ã„ã‚‹ã€‚<br><br>Finetuningã®çµæœã€æ–‡åŒ–çš„ãªå¤šæ§˜æ€§ã‚’æŒã¤è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ï¼ˆe.g., <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2471" target="_blank" rel="noopener noreferrer">[Paper Note] CVQA: Culturally-diverse Multilingual Visual Question Answering
  Benchmark, David Romero+, arXiv'24</a>
 Figure1ã®Japaneseã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¦‹ã‚‹ã¨ä¸€ç›®ã§ã©ã®ã‚ˆã†ãªãƒ™ãƒ³ãƒã‹åˆ†ã‹ã‚‹ï¼‰ã¨ä¸€èˆ¬çš„ãªãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãªè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®åŒæ–¹ã§gainãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚<br><img src="https://github.com/user-attachments/assets/61b33047-4c7c-4785-99f7-bcaa131bcfbf" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/8088e61f-ef46-4bcd-bc94-8d6f6318ca0e" alt="image" loading="lazy"><br><br>VQAã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã§åˆ©ç”¨ã•ã‚ŒãŸpromptã¯ä¸‹è¨˜<br><img src="https://github.com/user-attachments/assets/a9c5b463-a3e3-4565-b2f2-95268252179d" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Reproducibility.html" target="_blank" rel="noopener noreferrer">#Reproducibility</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2411" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning, Zihe Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã‚’ç”¨ã„ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®æ¨è«–ã«é–¢ã™ã‚‹ç ”ç©¶ãŒé€²å±•ã™ã‚‹ä¸­ã€æ¨™æº–åŒ–ã•ã‚ŒãŸã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®ç†è§£ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚å®Ÿé¨“è¨­å®šã®ä¸ä¸€è‡´ã‚„ãƒ‡ãƒ¼ã‚¿ã®å¤‰å‹•ãŒæ··ä¹±ã‚’æ‹›ã„ã¦ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€RLæŠ€è¡“ã‚’ä½“ç³»çš„ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å†ç¾å®Ÿé¨“ã‚’é€šã˜ã¦å„æŠ€è¡“ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚„é©ç”¨ã‚·ãƒŠãƒªã‚ªã‚’åˆ†æã€‚æ˜ç¢ºãªã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’æç¤ºã—ã€å®Ÿå‹™è€…ã«ä¿¡é ¼ã§ãã‚‹ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’æä¾›ã™ã‚‹ã€‚ã¾ãŸã€ç‰¹å®šã®æŠ€è¡“ã®çµ„ã¿åˆã‚ã›ãŒæ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1955268799525265801?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>èª­ã‚“ã æ–¹ãŒè‰¯ã„</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1959799274059031039?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2407" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MolmoAct: Action Reasoning Models that can Reason in Space, Jason Lee+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ¨è«–ãƒ¢ãƒ‡ãƒ«ï¼ˆARMsï¼‰ã§ã‚ã‚‹MolmoActã¯ã€çŸ¥è¦šã€è¨ˆç”»ã€åˆ¶å¾¡ã‚’ä¸‰æ®µéšã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§çµ±åˆã—ã€èª¬æ˜å¯èƒ½ã§æ“ä½œå¯èƒ½ãªè¡Œå‹•ã‚’å®Ÿç¾ã€‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨å®Ÿä¸–ç•Œã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ç‰¹ã«SimplerEnv Visual Matchingã‚¿ã‚¹ã‚¯ã§70.5%ã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆç²¾åº¦ã‚’é”æˆã€‚MolmoAct Datasetã‚’å…¬é–‹ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¹³å‡5.5%å‘ä¸Šã€‚å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã—ã€ARMsã®æ§‹ç¯‰ã«å‘ã‘ãŸã‚ªãƒ¼ãƒ—ãƒ³ãªè¨­è¨ˆå›³ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>`Action Reasoning Models (ARMs)`<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1955168414294589844?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>blog: 


<a href="https://allenai.org/blog/molmoact" target="_blank" rel="noopener noreferrer">https://allenai.org/blog/molmoact</a>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1426" target="_blank" rel="noopener noreferrer">Molmo, AI2, 2024.09</a>
</p>
<p>models:<br>- 


<a href="https://huggingface.co/allenai/MolmoAct-7B-D-Pretrain-0812" target="_blank" rel="noopener noreferrer">https://huggingface.co/allenai/MolmoAct-7B-D-Pretrain-0812</a>


<br>- 


<a href="https://huggingface.co/allenai/MolmoAct-7B-D-0812" target="_blank" rel="noopener noreferrer">https://huggingface.co/allenai/MolmoAct-7B-D-0812</a>


<br><br>datasets:<br>- 


<a href="https://huggingface.co/datasets/allenai/MolmoAct-Dataset" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/allenai/MolmoAct-Dataset</a>


<br>- 


<a href="https://huggingface.co/datasets/allenai/MolmoAct-Pretraining-Mixture" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/allenai/MolmoAct-Pretraining-Mixture</a>


<br>- 


<a href="https://huggingface.co/datasets/allenai/MolmoAct-Midtraining-Mixture" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/allenai/MolmoAct-Midtraining-Mixture</a>


</p>
<p>ãƒ‡ãƒ¼ã‚¿ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ãŒã€ã‚³ãƒ¼ãƒ‰ãŒè¦‹å½“ãŸã‚‰ãªã„ï¼Ÿ</p>
<p>ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¨ã‚³ãƒ¼ãƒ‰ã‚‚å…¬é–‹ã•ã‚ŒãŸæ¨¡æ§˜:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/djiafei/status/1964319001053372455?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 


<a href="https://github.com/allenai/MolmoAct" target="_blank" rel="noopener noreferrer">https://github.com/allenai/MolmoAct</a>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2406" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GLM-4.5: Agentic, Reasoning, and Coding ï¼ˆARCï¼‰ Foundation Models, GLM-4. 5 Team+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- 355Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®Mixture-of-Expertsãƒ¢ãƒ‡ãƒ«GLM-4.5ã‚’ç™ºè¡¨ã€‚ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¨è«–æ‰‹æ³•ã‚’æ¡ç”¨ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçš„ã€æ¨è«–ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚ç«¶åˆãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦å°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§ä¸Šä½ã«ãƒ©ãƒ³ã‚¯ã‚¤ãƒ³ã€‚GLM-4.5ã¨ãã®ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆç‰ˆGLM-4.5-Airã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã€è©³ç´°ã¯GitHubã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/grad62304977/status/1954805614011453706?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£<br>  - MoE / sigmoid gates<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1754" target="_blank" rel="noopener noreferrer">Switch Transformers: Scaling to Trillion Parameter Models with Simple  and Efficient Sparsity, William Fedus+, JMLR'22</a>
<br>  - loss free balanced routing<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2442" target="_blank" rel="noopener noreferrer">[Paper Note] Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts, Lean Wang+, arXiv'24</a>
<br>  - widthã‚’å°ã•ãã€depthã‚’å¢—ã‚„ã™ã“ã¨ã§reasoningèƒ½åŠ›æ”¹å–„<br>  - GQA w/ partial RoPE<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1310" target="_blank" rel="noopener noreferrer">RoFormer: Enhanced Transformer with Rotary Position Embedding, Jianlin Su+, N/A, Neurocomputing, 2024</a>
<br>  - Attention Headsã®æ•°ã‚’2.5å€ï¼ˆä½•ã«å¯¾ã—ã¦2.5å€ãªã‚“ã ã€ã€ï¼Ÿï¼‰ï¼ˆ96å€‹, 5120æ¬¡å…ƒï¼‰ã«ã™ã‚‹ã“ã¨ã§ï¼ˆãŠãã‚‰ãï¼‰äº‹å‰å­¦ç¿’ã®lossã¯æ”¹å–„ã—ãªã‹ã£ãŸãŒReasoning benchmarkã®æ€§èƒ½æ”¹å–„<br>  - QK Normã‚’å°å…¥ã—attentionã®logitsã®å€¤åŸŸã‚’æ”¹å–„<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2443" target="_blank" rel="noopener noreferrer">[Paper Note] Query-Key Normalization for Transformers, Alex Henry+, EMNLP'20 Findings</a>
<br>  - Multi Token Prediction<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2444" target="_blank" rel="noopener noreferrer">[Paper Note] Better &amp; Faster Large Language Models via Multi-token Prediction, Fabian Gloeckle+, ICML'24</a>
<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1620" target="_blank" rel="noopener noreferrer">Deep-seek-v3, deepseek-ai, 2024.12</a>
<br><br>ä»–ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒ<br><img src="https://github.com/user-attachments/assets/6085b99e-3a76-432c-a759-91dd4feeb219" alt="image" loading="lazy"><br><br>å­¦ç¿’éƒ¨åˆ†ã¯å¾Œã§è¿½è¨˜ã™ã‚‹</p>
<p>- äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿<br>  - web<br>    - è‹±èªã¨ä¸­å›½èªã®webãƒšãƒ¼ã‚¸ã‚’åˆ©ç”¨<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1944" target="_blank" rel="noopener noreferrer">Nemotron-CC: Transforming Common Crawl into a Refined Long-Horizon   Pretraining Dataset, Dan Su+, ACL'25</a>
 ã¨åŒæ§˜ã«quality scoreyã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ä»˜ä¸<br>    - æœ€ã‚‚ä½ã„quality scoreã®æ–‡æ›¸ç¾¤ã‚’æ’é™¤ã—ã€quality scoreã®é«˜ã„æ–‡æ›¸ç¾¤ã‚’up sampling<br>    - æœ€ã‚‚quality scoreyãŒå¤§ãã„æ–‡æ›¸ç¾¤ã¯3.2 epochåˆ†åˆ©ç”¨<br>    - å¤šãã®web pageãŒãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚Œã¦ãŠã‚Šé«˜ã„quality scoreãŒä»˜ä¸ã•ã‚Œã¦ã„ãŸãŒã€MinHashã«ã‚ˆã£ã¦deduplicationã§ããªã‹ã£ãŸãŸã‚ã€ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2445" target="_blank" rel="noopener noreferrer">[Paper Note] SemDeDup: Data-efficient learning at web-scale through semantic
  deduplication, Amro Abbas+, arXiv'23</a>
 ã‚’ç”¨ã„ã¦document embeddingã«åŸºã¥ã„ã¦é¡ä¼¼ã—ãŸæ–‡æ›¸ç¾¤ã‚’æ’é™¤<br>  - Multilingual<br>    - ç‹¬è‡ªã«ã‚¯ãƒ­ãƒ¼ãƒ«ã—ãŸãƒ‡ãƒ¼ã‚¿ã¨FineWeb-2 <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2109" target="_blank" rel="noopener noreferrer">[Paper Note] FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data  Processing to Every Language, Guilherme Penedo+, COLM'25</a>
 ã‹ã‚‰å¤šè¨€èªã®æ–‡æ›¸ç¾¤ã‚’æŠ½å‡ºã—ã€quality classifierã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§educational utilityã‚’å®šé‡åŒ–ã—ã€é«˜ã„ã‚¹ã‚³ã‚¢ã®æ–‡æ›¸ç¾¤ã‚’upsamplingã—ã¦åˆ©ç”¨<br>  - code<br>    - githubãªã©ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰hosting platformã‹ã‚‰åé›†<br>    - ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ã‹ã‘ã€ãã®å¾Œè¨€èªã”ã¨ã®quality modelsã«ã‚ˆã£ã¦ã€high,middle, lowã®3ã¤ã«å“è³ªã‚’åˆ†é¡<br>    - high qualityãªã‚‚ã®ã¯upsamplingã—ã€low qualityãªã‚‚ã®ã¯é™¤å¤–<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2446" target="_blank" rel="noopener noreferrer">[Paper Note] Efficient Training of Language Models to Fill in the Middle, Mohammad Bavarian+, arXiv'22</a>
 ã§ææ¡ˆã•ã‚Œã¦ã„ã‚‹Fill in the Middle objectiveã‚’ã‚³ãƒ¼ãƒ‰ã®äº‹å‰å­¦ç¿’ã§ã¯é©ç”¨<br>    - ã‚³ãƒ¼ãƒ‰ã«é–¢é€£ã™ã‚‹webæ–‡æ›¸ã‚‚äº‹å‰å­¦ç¿’ã§åé›†ã—ãŸãƒ†ã‚­ã‚¹ãƒˆç¾¤ã‹ã‚‰ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã¨fasttextã«ã‚ˆã‚‹åˆ†é¡å™¨ã§æŠ½å‡ºã—ã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¨åŒæ§˜ã®qualityã®åˆ†é¡ã¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•ã‚’é©ç”¨ã€‚æœ€çµ‚çš„ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸæ–‡æ›¸ç¾¤ã¯re-parseã—ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨å†…å®¹ã®å“è³ªã‚’å‘ä¸Šã•ã›ãŸ<br>  - math &amp; science<br>    - web page, æœ¬, è«–æ–‡ã‹ã‚‰ã€reasoningèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€æ•°å­¦ã¨ç§‘å­¦ã«é–¢ã™ã‚‹æ–‡æ›¸ã‚’åé›†<br>  - LLMã‚’ç”¨ã„ã¦æ–‡æ›¸ä¸­ã®educational contentã®æ¯”ç‡ã«åŸºã¥ã„ã¦æ–‡æ›¸ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ã‚¹ã‚³ã‚¢ã‚’äºˆæ¸¬ã™ã‚‹small-scaleãªåˆ†é¡å™¨ã‚’å­¦ç¿’<br>  - æœ€çµ‚çš„ã«äº‹å‰å­¦ç¿’ã‚³ãƒ¼ãƒ‘ã‚¹ã®ä¸­ã®é–¾å€¤ä»¥ä¸Šã®ã‚¹ã‚³ã‚¢ã‚’æŒã¤æ–‡æ›¸ã‚’upsampling<br>- äº‹å‰å­¦ç¿’ã¯2 stageã«åˆ†ã‹ã‚Œã¦ãŠã‚Šã€æœ€åˆã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§ã¯ã€"å¤§éƒ¨åˆ†ã¯"generalãªæ–‡æ›¸ã§å­¦ç¿’ã™ã‚‹ã€‚æ¬¡ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§ã¯ã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã€æ•°å­¦ã€ç§‘å­¦ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é–¢é€£ã®æ–‡æ›¸ã‚’upsamplingã—ã¦å­¦ç¿’ã™ã‚‹ã€‚<br><br>ä¸Šè¨˜ä»¥ä¸Šã®ç´°ã‹ã„å®Ÿè£…ä¸Šã®æƒ…å ±ã¯è¨˜è¼‰ã•ã‚Œã¦ã„ãªã„ã€‚<br><br>mid-training / post trainingã«ã¤ã„ã¦ã‚‚å¾Œã»ã©è¿½è¨˜ã™ã‚‹</p>
<p>ä»¥ä¸‹ã‚‚å‚ç…§ã®ã“ã¨<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2318" target="_blank" rel="noopener noreferrer">GLM-4.5: Reasoning, Coding, and Agentic Abililties, Zhipu AI Inc., 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2405" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Difficulty-Based Preference Data Selection by DPO Implicit Reward Gap, Xuan Qi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®å¥½ã¿ã‚’äººé–“ã«åˆã‚ã›ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿é¸æŠæˆ¦ç•¥ã‚’ææ¡ˆã€‚DPOã®æš—é»™çš„å ±é…¬ã‚®ãƒ£ãƒƒãƒ—ãŒå°ã•ã„ãƒ‡ãƒ¼ã‚¿ã‚’é¸ã¶ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã¨ãƒ¢ãƒ‡ãƒ«ã®æ•´åˆæ€§ã‚’å‘ä¸Šã€‚å…ƒã®ãƒ‡ãƒ¼ã‚¿ã®10ï¼…ã§5ã¤ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚é™ã‚‰ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã§ã®LLMæ•´åˆæ€§å‘ä¸Šã«å¯„ä¸ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhijingjin/status/1954535751489667173?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>preference pair dataã‚’å­¦ç¿’åŠ¹ç‡ã®è‰¯ã„ã‚µãƒ³ãƒ—ãƒ«ã®ã¿ã«åœ§ç¸®ã™ã‚‹ã“ã¨ã§å­¦ç¿’åŠ¹ç‡ã‚’ä¸Šã’ãŸã„ç³»ã®è©±ã§ã€chosen, rejectedãªã‚µãƒ³ãƒ—ãƒ«ã®ãã‚Œãã‚Œã«ã¤ã„ã¦ã€Â¥frac{ç¾åœ¨ã®ãƒãƒªã‚·ãƒ¼ã®å°¤åº¦}{å‚ç…§ãƒãƒªã‚·ãƒ¼ã®å°¤åº¦}ã«ã‚ˆã£ã¦reward rã‚’å®šç¾©ã—ï¼ˆãŠãã‚‰ãå‚ç…§ãƒãƒªã‚·ãƒ¼ã®å°¤åº¦ã«ã‚ˆã£ã¦ã‚µãƒ³ãƒ—ãƒ«ã®é‡è¦åº¦ã‚’é‡ã¿ã¥ã‘ã—ã¦ã„ã‚‹ï¼‰ã€r_chosenã¨r_rejectedã®å·®ã‚’reward gapã¨å®šç¾©ã—ã€gapãŒå¤§ãã„ã‚‚ã®ã¯é›£æ˜“åº¦ãŒä½ã„ã¨åˆ¤æ–­ã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã€ã¨ã„ã£ãŸè©±ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/1b930f5e-8db4-4c20-b7ca-59fb452f9056" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2403" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Memp: Exploring Agent Procedural Memory, Runnan Fang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMã«åŸºã¥ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å­¦ç¿’å¯èƒ½ã§æ›´æ–°å¯èƒ½ãªæ‰‹ç¶šãçš„è¨˜æ†¶ã‚’æŒãŸã›ã‚‹ãŸã‚ã®æˆ¦ç•¥ã‚’ææ¡ˆã€‚Mempã‚’ç”¨ã„ã¦éå»ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è»Œè·¡ã‚’æŒ‡ç¤ºã‚„æŠ½è±¡ã«è’¸ç•™ã—ã€è¨˜æ†¶ã®æ§‹ç¯‰ã¨æ›´æ–°ã‚’è¡Œã†ã€‚TravelPlannerã¨ALFWorldã§ã®å®Ÿè¨¼è©•ä¾¡ã«ã‚ˆã‚Šã€è¨˜æ†¶ãƒªãƒã‚¸ãƒˆãƒªãŒé€²åŒ–ã™ã‚‹ã“ã¨ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æˆåŠŸç‡ã¨åŠ¹ç‡ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®æ‰‹ç¶šãçš„è¨˜æ†¶ã®ç§»è¡Œã«ã‚ˆã‚Šã€å¼±ã„ãƒ¢ãƒ‡ãƒ«ã§ã‚‚æ€§èƒ½å‘ä¸ŠãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zxlzr/status/1954840738082193477?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚¢ãƒ‰ãƒ›ãƒƒã‚¯ã«æ¢ç´¢ã¨å®Ÿè¡Œã‚’ç¹°ã‚Šè¿”ã™ã®ã§ã¯ãªãã€éå»ã®è©¦è¡Œã®trajectoryã‚’ãƒ¡ãƒ¢ãƒªã«è¨˜æ†¶ã—ã¦ãŠãã€æ´»ç”¨ã™ã‚‹ã‚ˆã†ãªæ çµ„ã¿ãªæ¨¡æ§˜ã€‚trajectoryã¯æ–°ãŸãªã‚¿ã‚¹ã‚¯ãŒæ¥ãŸéš›ã«retrieverã§relevantãªtrajectoryã‚’æ¤œç´¢ã—ã¦åˆ©ç”¨ã•ã‚Œã€è‰¯è³ªãªtrajectoryãŒã‚­ãƒ¼ãƒ—ã•ã‚Œã‚Œã°æˆåŠŸç‡ã‚„åŠ¹ç‡ãŒå‘ä¸Šã™ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚trajectoryã¯procedure memoryã¨ã—ã¦ä¿å­˜ã•ã‚Œã€æˆåŠŸç‡ãŒä½ã„trajectoryã¯ç ´æ£„ã•ã‚Œã‚‹ã“ã¨ã§æ›´æ–°ã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/20e2f063-eef6-4c3d-9161-3d96f56c6f8d" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/a3766541-4946-4e43-91e4-99a873fb1d6f" alt="image" loading="lazy"><br><br>ãƒ¡ãƒ¢ãƒªã¯Tå€‹ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹s_t, a_t, o_t, i.e., state, action, observation,ã®ç³»åˆ—Ï„ã¨ã€reward rãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€Builderã‚’é€šã—ã¦æ§‹ç¯‰ã•ã‚Œã¦ã‚¹ãƒˆã‚¢ã•ã‚Œã‚‹ã€‚agentã¯æ–°ãŸãªã‚¿ã‚¹ã‚¯t_newã«ç›´é¢ã—ãŸæ™‚ã«ã€t_newã¨é¡ä¼¼ã—ãŸãƒ¡ãƒ¢ãƒªã‚’retrieyeã™ã‚‹ã€‚ã“ã‚Œã¯Ï„ã®ä¸­ã®ã‚ã‚‹æ™‚åˆ»tã®ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã™ã‚‹ã€‚ãƒ¡ãƒ¢ãƒªã¯è‚¥å¤§åŒ–ã—ã¦ã„ããŸã‚ã€å®Ÿé¨“ã§ã¯è¤‡æ•°ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«åŸºã¥ããƒ¡ãƒ¢ãƒªã®æ›´æ–°æ–¹æ³•ã«ã¤ã„ã¦å®Ÿé¨“ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/b91dbfed-c976-4764-abf6-00f4751b7e91" alt="image" loading="lazy"><br><br>procedural memoryã®æœ‰ç„¡ã«ã‚ˆã‚‹æŒ™å‹•ã®é•ã„ã«é–¢ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã€‚<br><img src="https://github.com/user-attachments/assets/2623103d-331d-45eb-a5cc-635ef3cb88ab" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/b1c21bf3-eef1-4b4c-999c-f8d0fcbc9431" alt="image" loading="lazy"></p>
<p>memoryã«å¯¾ã—ã¦retrieverã‚’é©ç”¨ã™ã‚‹ã“ã¨ã«ãªã‚‹ã®ã§ã€retrieverã®æ€§èƒ½ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚è¿½åŠ ã®å­¦ç¿’ã‚’ã—ãªãã¦æ¸ˆã‚€ã®ã¯åˆ©ç‚¹ã ãŒã€ãã®ä»£ã‚ã‚Šãƒ¢ãƒ‡ãƒ«å´ãŒãƒ¡ãƒ¢ãƒªç®¡ç†ã‚’ã™ã‚‹æ©Ÿèƒ½ã‚’æœ‰ã•ãªã„ï¼ˆå­¦ç¿’ã™ã‚Œã°ãã†ã„ã£ãŸæ©Ÿèƒ½ã‚’æŒãŸã›ã‚‰ã‚Œã‚‹ã¯ãšï¼‰ã®ã§ã€ãã®ç‚¹ã¯æ¬ ç‚¹ã¨ãªã‚‹ã€ã¨ã„ã†å°è±¡ã€‚</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1954937801490772104?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2402" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] NoCode-bench: A Benchmark for Evaluating Natural Language-Driven Feature  Addition, Le Deng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªç„¶è¨€èªé§†å‹•ã®ãƒãƒ¼ã‚³ãƒ¼ãƒ‰é–‹ç™ºã«ãŠã‘ã‚‹LLMsã®è©•ä¾¡ã®ãŸã‚ã«ã€ŒNoCode-benchã€ã‚’ææ¡ˆã€‚634ã®ã‚¿ã‚¹ã‚¯ã¨114,000ã®ã‚³ãƒ¼ãƒ‰å¤‰æ›´ã‹ã‚‰æˆã‚Šã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã‚³ãƒ¼ãƒ‰å®Ÿè£…ã®ãƒšã‚¢ã‚’æ¤œè¨¼ã€‚å®Ÿé¨“çµæœã§ã¯ã€æœ€è‰¯ã®LLMsãŒã‚¿ã‚¹ã‚¯æˆåŠŸç‡15.79%ã«ç•™ã¾ã‚Šã€å®Œå…¨ãªNLé§†å‹•ã®ãƒãƒ¼ã‚³ãƒ¼ãƒ‰é–‹ç™ºã«ã¯æœªã èª²é¡ŒãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚NoCode-benchã¯ä»Šå¾Œã®é€²å±•ã®åŸºç›¤ã¨ãªã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1955062236831158763?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰:


<a href="https://nocodebench.org" target="_blank" rel="noopener noreferrer">https://nocodebench.org</a>


</p>
<p>ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ä»•æ§˜æ›¸ã¨ã¿ãªã—ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ›´æ–°éƒ¨åˆ†ã‚’ã‚‰inputã¨ã—ã€å¯¾å¿œã™ã‚‹"æ©Ÿèƒ½è¿½åŠ "ã‚’ã™ã‚‹èƒ½åŠ›ã‚’æ¸¬ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br><br><img src="https://github.com/user-attachments/assets/249973b0-4c81-468d-91cd-13a3b93e31e7" alt="image" loading="lazy"><br><br>SoTAãƒ¢ãƒ‡ãƒ«ã§ã‚‚15.79%ç¨‹åº¦ã—ã‹æˆåŠŸã—ãªã„ã€‚<br><img src="https://github.com/user-attachments/assets/f8bab8c8-e5da-46c5-981a-1398021e030d" alt="image" loading="lazy"><br><br>å…ƒãƒã‚¹ãƒˆã«ã‚ˆã‚‹ã¨ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è·¨ã„ã ç·¨é›†ã€ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ç†è§£ã€tool useã«è‹¦åŠ´ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/ReversalCurse.html" target="_blank" rel="noopener noreferrer">#ReversalCurse</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2399" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Physics of Language Models: Part 3.2, Knowledge Manipulation, Zeyuan Allen-Zhu+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã¯è±Šå¯ŒãªçŸ¥è­˜ã‚’æŒã¤ãŒã€ä¸‹æµã‚¿ã‚¹ã‚¯ã¸ã®æŸ”è»Ÿãªåˆ©ç”¨ã«ã¯é™ç•ŒãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æƒ…å ±æ¤œç´¢ã€åˆ†é¡ã€æ¯”è¼ƒã€é€†æ¤œç´¢ã®4ã¤ã®çŸ¥è­˜æ“ä½œã‚¿ã‚¹ã‚¯ã‚’èª¿æŸ»ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒçŸ¥è­˜æ¤œç´¢ã«ã¯å„ªã‚Œã¦ã„ã‚‹ãŒã€Chain of Thoughtsã‚’ç”¨ã„ãªã„ã¨åˆ†é¡ã‚„æ¯”è¼ƒã‚¿ã‚¹ã‚¯ã§è‹¦åŠ´ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ç‰¹ã«é€†æ¤œç´¢ã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒã»ã¼0%ã§ã‚ã‚Šã€ã“ã‚Œã‚‰ã®å¼±ç‚¹ã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã«å›ºæœ‰ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç¾ä»£ã®AIã¨äººé–“ã‚’åŒºåˆ¥ã™ã‚‹æ–°ãŸãªãƒãƒ¥ãƒ¼ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆã®å¿…è¦æ€§ãŒæµ®ãå½«ã‚Šã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=oDbiL9CLoS" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=oDbiL9CLoS</a>


</p>
<p>è§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2398" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Physics of Language Models: Part 2.2, How to Learn From Mistakes on   Grade-School Math Problems, Tian Ye+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ç²¾åº¦å‘ä¸Šã®ãŸã‚ã«ã€ã€Œã‚¨ãƒ©ãƒ¼ä¿®æ­£ã€ãƒ‡ãƒ¼ã‚¿ã‚’äº‹å‰å­¦ç¿’ã«çµ„ã¿è¾¼ã‚€æœ‰ç”¨æ€§ã‚’æ¢æ±‚ã€‚åˆæˆæ•°å­¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€ã‚¨ãƒ©ãƒ¼ãƒ•ãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã¨æ¯”è¼ƒã—ã¦é«˜ã„æ¨è«–ç²¾åº¦ã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã•ã‚‰ã«ã€ãƒ“ãƒ¼ãƒ ã‚µãƒ¼ãƒã¨ã®é•ã„ã‚„ãƒ‡ãƒ¼ã‚¿æº–å‚™ã€ãƒã‚¹ã‚­ãƒ³ã‚°ã®å¿…è¦æ€§ã€ã‚¨ãƒ©ãƒ¼é‡ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ®µéšã§ã®é…å»¶ã«ã¤ã„ã¦ã‚‚è€ƒå¯Ÿã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=zpDGwcmMV4" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=zpDGwcmMV4</a>


</p>
<p>è§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2397" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Physics of Language Models: Part 2.1, Grade-School Math and the Hidden   Reasoning Process, Tian Ye+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ•°å­¦çš„æ¨è«–èƒ½åŠ›ã‚’ç ”ç©¶ã—ã€GSM8Kãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®ç²¾åº¦å‘ä¸Šã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æ¢ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€æ¨è«–ã‚¹ã‚­ãƒ«ã®ç™ºå±•ã€éš ã‚ŒãŸãƒ—ãƒ­ã‚»ã‚¹ã€äººé–“ã¨ã®é•ã„ã€å¿…è¦ãªã‚¹ã‚­ãƒ«ã®è¶…è¶Šã€æ¨è«–ãƒŸã‚¹ã®åŸå› ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã‚„æ·±ã•ã«ã¤ã„ã¦ã®å®Ÿé¨“ã‚’è¡Œã„ã€LLMã®ç†è§£ã‚’æ·±ã‚ã‚‹æ´å¯Ÿã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=Tn5B6Udq3E" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Tn5B6Udq3E</a>


</p>
<p>è§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
</p>
<p>å°å­¦ç”Ÿå‘ã‘ã®ç®—æ•°ã®å•é¡Œã‚’é€šã˜ã¦ã€ä»¥ä¸‹ã®åŸºæœ¬çš„ãªResearch Questionsã«ã¤ã„ã¦èª¿æŸ»ã—ã¦ç ”ç©¶ã€‚ã“ã‚Œã‚‰ã‚’ç†è§£ã™ã‚‹ã“ã¨ã§ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®çŸ¥èƒ½ã‚’ç†è§£ã™ã‚‹ç¤ã¨ã™ã‚‹ã€‚<br><br>## Research Questions<br>- è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã©ã®ã‚ˆã†ã«ã—ã¦å°å­¦æ ¡ãƒ¬ãƒ™ãƒ«ã®ç®—æ•°ã®å•é¡Œã‚’è§£ã‘ã‚‹ã‚ˆã†ã«ãªã‚‹ã®ã‹ï¼Ÿ<br>  - å˜ã«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’æš—è¨˜ã—ã¦ã„ã‚‹ã ã‘ãªã®ã‹ã€ãã‚Œã¨ã‚‚äººé–“ã«ä¼¼ãŸæ¨è«–ã‚¹ã‚­ãƒ«ã‚’å­¦ã‚“ã§ã„ã‚‹ã®ã‹ï¼Ÿ<br>  - ã‚ã‚‹ã„ã¯ã€ãã®å•é¡Œã‚’è§£ããŸã‚ã«æ–°ã—ã„ã‚¹ã‚­ãƒ«ã‚’ç™ºè¦‹ã—ã¦ã„ã‚‹ã®ã‹ï¼Ÿ<br>- å°å­¦æ ¡ãƒ¬ãƒ™ãƒ«ã®ç®—æ•°å•é¡Œã ã‘ã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ãã‚Œã‚‰ã®å•é¡Œã‚’è§£ãã“ã¨ã—ã‹å­¦ã°ãªã„ã®ã‹ï¼Ÿ<br>  - ãã‚Œã¨ã‚‚ã€ã‚ˆã‚Šä¸€èˆ¬çš„ãªçŸ¥èƒ½ã‚’å­¦ç¿’ã™ã‚‹ã®ã‹ï¼Ÿ<br>- ã©ã®ãã‚‰ã„å°ã•ã„è¨€èªãƒ¢ãƒ‡ãƒ«ã¾ã§ã€å°å­¦æ ¡ãƒ¬ãƒ™ãƒ«ã®ç®—æ•°å•é¡Œã‚’è§£ã‘ã‚‹ã®ã‹ï¼Ÿ<br>  - æ·±ã•ï¼ˆå±¤ã®æ•°ï¼‰ã¯å¹…ï¼ˆå±¤ã”ã¨ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³æ•°ï¼‰ã‚ˆã‚Šé‡è¦ãªã®ã‹ï¼Ÿ<br>  - ãã‚Œã¨ã‚‚ã€å˜ã«ã‚µã‚¤ã‚ºã ã‘ãŒé‡è¦ã‹ï¼Ÿ<br><br>ï¼ˆç¶šãã¯ã®ã¡ã»ã©...ï¼‰</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2396" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Fast and Simplex: 2-Simplicial Attention in Triton, Aurko Roy+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- 2-ã‚·ãƒ³ãƒ—ãƒªã‚·ã‚¢ãƒ«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€ãƒˆãƒ¼ã‚¯ãƒ³åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã€æ¨™æº–çš„ãªãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚å›ºå®šã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³äºˆç®—å†…ã§ã€æ•°å­¦ã‚„æ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ãƒ‰ãƒƒãƒˆç©ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’ä¸Šå›ã‚‹çµæœã‚’å¾—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1954682957798715669?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-08-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2393" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] STEPWISE-CODEX-Bench: Evaluating Complex Multi-Function Comprehension  and Fine-Grained Execution Reasoning, Kaiwen Yan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒSTEPWISE-CODEX-Benchï¼ˆSX-Benchï¼‰ã€ã‚’ææ¡ˆã—ã€è¤‡é›‘ãªå¤šæ©Ÿèƒ½ç†è§£ã¨ç´°ã‹ã„å®Ÿè¡Œæ¨è«–ã‚’è©•ä¾¡ã€‚SX-Benchã¯ã€ã‚µãƒ–é–¢æ•°é–“ã®å”åŠ›ã‚’å«ã‚€ã‚¿ã‚¹ã‚¯ã‚’ç‰¹å¾´ã¨ã—ã€å‹•çš„å®Ÿè¡Œã®æ·±ã„ç†è§£ã‚’æ¸¬å®šã™ã‚‹ã€‚20ä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡ã—ãŸçµæœã€æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã§ã‚‚è¤‡é›‘ãªæ¨è«–ã«ãŠã„ã¦ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãŒæ˜ã‚‰ã‹ã«ã€‚SX-Benchã¯ã‚³ãƒ¼ãƒ‰è©•ä¾¡ã‚’é€²å±•ã•ã›ã€é«˜åº¦ãªã‚³ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã«è²¢çŒ®ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1954296753525752266?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¾åœ¨ã®ä¸»æµãªã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®ãƒ™ãƒ³ãƒã¯ã€input/outputãŒgivenãªã‚‰ä¸Šã§ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’ç”Ÿæˆã™ã‚‹å½¢å¼ãŒä¸»æµ(e.g., MBPP <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2439" target="_blank" rel="noopener noreferrer">[Paper Note] Program Synthesis with Large Language Models, Jacob Austin+, arXiv'21</a>
, HumanEval <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2438" target="_blank" rel="noopener noreferrer">[Paper Note] Evaluating Large Language Models Trained on Code, Mark Chen+, arXiv'21</a>
)ã ãŒã€ãƒ¢ãƒ‡ãƒ«ãŒã‚³ãƒ¼ãƒ‰ã‚’ç†è§£ã—ã€è¤‡é›‘ãªã‚³ãƒ¼ãƒ‰ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè¡Œã™ã‚‹å†…éƒ¨çŠ¶æ…‹ã®å¤‰åŒ–ã«å¿œã˜ã¦ã€å®Ÿè¡Œã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ¨è«–ã™ã‚‹èƒ½åŠ›ãŒè¦‹è½ã¨ã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€CRUXEVAL <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2440" target="_blank" rel="noopener noreferrer">[Paper Note] CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution, Alex Gu+, arXiv'24</a>
, CRUXEVAL-X <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2441" target="_blank" rel="noopener noreferrer">[Paper Note] CRUXEval-X: A Benchmark for Multilingual Code Reasoning, Understanding
  and Execution, Ruiyang Xu+, arXiv'24</a>
 ã§ã¯ã€é–¢æ•°ã®inputs/outputsã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ¼ãƒ‰ã®comprehension, reasoningèƒ½åŠ›ã‚’æ¸¬ã‚ã†ã¨ã—ã¦ã„ã‚‹ãŒã€<br>- single functionã®logicã«é™å®šã•ã‚Œã¦ã„ã‚‹<br>- 20 lineç¨‹åº¦ã®çŸ­ãã€trivialãªãƒ­ã‚¸ãƒƒã‚¯ã«é™å®šã•ã‚Œã¦ã„ã‚‹<br>- ã™ã§ã«SoTAãƒ¢ãƒ‡ãƒ«ã§95%ãŒé”æˆã•ã‚Œé£½å’Œã—ã¦ã„ã‚‹<br><br>ã¨ã„ã†limitationãŒã‚ã‚‹ã®ã§ã€è¤‡æ•°ã®é–¢æ•°ãŒå”åƒã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã€flow/dataã®interactionã®ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡ã€ç´°ã‹ã„å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—ãªã©ã‚’å«ã‚€ã€staticãªã‚³ãƒ¼ãƒ‰ã®ç†è§£ã‹ã‚‰ã€å‹•çš„ãªå®Ÿè¡Œãƒ—ãƒ­ã‚»ã‚¹ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°èƒ½åŠ›ã®è©•ä¾¡ã«ã‚·ãƒ•ãƒˆã™ã‚‹ã‚ˆã†ãªã€æ–°ãŸãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸã€ã¨ã„ã†è©±ãªæ¨¡æ§˜ã€‚<br><br>ã¾ãšé–¢æ•°å˜ä½ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æ§‹ç¯‰ã—ã¦ã„ã‚‹ã€‚ã“ã®ãŸã‚ã«ã€å˜ä¸€ã®é–¢æ•°ã®åŸºç¤çš„ãªä»•æ§˜ã‚’ã€ŒåŒã˜inputã«å¯¾ã—ã¦åŒã˜outputã‚’è¿”ã™ã‚‚ã®ã¯åŒã˜ã‚¯ãƒ©ã‚¹ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚Œã‚‹ã€ã¨å®šç¾©ã—ã€æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ãƒªãƒã‚¸ãƒˆãƒªã¨LLMã«ã‚ˆã‚‹åˆæˆã«ã‚ˆã£ã¦ã€Goã¨Pythonã«ã¤ã„ã¦åˆè¨ˆ30ç¨®é¡ã®ã‚¯ãƒ©ã‚¹ã¨361å€‹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åé›†ã€‚ã“ã‚Œã‚‰ã®é–¢æ•°ã¯ã€ç®—è¡“æ¼”ç®—ã‚„å¤§å°æ¯”è¼ƒã€ãƒ‘ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ãªã©ã®åˆ¤å®šã€æ–‡å­—åˆ—ã®æ“ä½œãªã©ã‚’å«ã‚€ã€‚ãã—ã¦ã“ã‚Œã‚‰é–¢æ•°ã‚’3ç¨®é¡ã®å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã“ã¨ã§ã€åˆæˆé–¢æ•°ã‚’ä½œæˆã—ãŸã€‚åˆæˆæ–¹æ³•ã¯<br>- Sequential: outputã¨inputã‚’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã¤ãªãä¼æ¬ã•ã›ã‚‹<br>- Selective: æ¡ä»¶ã«å¿œã˜ã¦f(x)ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã‹ã€g(x)ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã‹ã‚’åˆ¶å¾¡<br>- Loop: inputé›†åˆã«å¯¾ã™ã‚‹loopã®ä¸­ã«é–¢æ•°ã‚’åŸ‹ã‚è¾¼ã¿é †æ¬¡é–¢æ•°ã‚’å®Ÿè¡Œ<br><br>ã®3ç¨®é¡ã€‚åˆæˆé–¢æ•°ã®æŒ™å‹•ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã¯è‡ªå‹•ç”Ÿæˆã—ã€åˆæˆé–¢æ•°ã®æŒ™å‹•ã‚’ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã€ç„¡é™ãƒ«ãƒ¼ãƒ—ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€è¤‡æ•°å›ã®å®Ÿè¡Œã§outputãŒæ±ºå®šçš„ã‹ç­‰ãªã©ï¼‰ã—ã€ç•°å¸¸ãŒã‚ã‚‹ã‚‚ã®ã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§åˆæˆé–¢æ•°ã®å“è³ªã‚’æ‹…ä¿ã™ã‚‹ã€‚<br><br>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°ã®æ–¹æ³•ã¨ã—ã¦ã¯ã€CRUXEVALã§ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«ãƒ¢ãƒ‡ãƒ«ã«ã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡Œçµæœã‚’äºˆæƒ³ã•ã›ã‚‹ã ã‘ã§ã‚ã£ãŸãŒã€æŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ã®å•é¡Œã‹ã‚‰ãƒŸã‚¹ã‚¸ãƒ£ãƒƒã‚¸ã‚’ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€ã“ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚&lt;input, output&gt;ã®ãƒšã‚¢ãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€outputãŒåˆæˆé–¢æ•°ã«å¯¾ã—ã¦inputã—ã¾çµæœã¨ãƒãƒƒãƒã™ã‚‹ã‹ã‚’yes/noã®binaryã§åˆ¤å®šã•ã›ã‚‹ï¼ˆPredictã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ¼ãƒ‰ç†è§£åŠ›ã‚’è©•ä¾¡)ã€‚ã“ã‚Œã¨ã¯åˆ¥ã«ã€ä¸ãˆã‚‰ã‚ŒãŸinput, outputãƒšã‚¢ã¨åˆæˆé–¢æ•°ã«åŸºã¥ã„ã¦ã€å®Ÿè¡Œæ™‚ã®åˆè¨ˆã®computation stepsã‚’å‡ºåŠ›ã•ã›ã‚‹ã‚¿ã‚¹ã‚¯ã‚’reasoningã‚¿ã‚¹ã‚¯ã¨ã—ã¦å®šç¾©ã—ã€è¤‡é›‘åº¦ã«å¿œã˜ã¦easy, hardã«åˆ†é¡ã—ã¦ã„ã‚‹ã€‚computation stepsã¯ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’å®Ÿè¡Œã™ã‚‹æœ€å°å˜ä½ã®ã“ã¨ã§ã‚ã‚Šã€ãŸã¨ãˆã°ç®—è¡“æ¼”ç®—ãªã©ã®åŸºç¤çš„ãªarithmetic/logic operationã‚’æŒ‡ã™ã€‚<br><img src="https://github.com/user-attachments/assets/8ac34d8c-63e4-42d7-96ea-13dbe39ad683" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/76407c5b-acd0-40ef-a698-684875ccc680" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2392" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable  Reward Models, Xiangxiang Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- StructVRMã¯ã€è¤‡é›‘ãªå¤šè³ªå•æ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€éƒ¨åˆ†çš„ãªæ­£ç¢ºæ€§ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ§‹é€ åŒ–ã•ã‚ŒãŸæ¤œè¨¼å¯èƒ½ãªå ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’å°å…¥ã€‚ã‚µãƒ–è³ªå•ãƒ¬ãƒ™ãƒ«ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã€å¾®å¦™ãªéƒ¨åˆ†çš„ãªã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€Seed-StructVRMãŒ12ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã†ã¡6ã¤ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ãŸã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã¯ã€è¤‡é›‘ãªæ¨è«–ã«ãŠã‘ã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1954315513397760130?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è¤‡æ•°ã®sub-questionãŒå­˜åœ¨ã™ã‚‹ã‚ˆã†ãªè¤‡é›‘ãªå•é¡Œã«å¯¾ã—ã¦ã€æ—¢å­˜ã®RLVRã«ãŠã‘ã‚‹å…¨ä½“ã«å¯¾ã—ã¦binary rewardã‚’é©ç”¨ã™ã‚‹æ–¹æ³•ã¯å ±é…¬ãŒè’ã™ãã‚‹ãŸã‚ã€ã‚ˆã‚Šfine-grainedãªverifiableãªå ±é…¬ã‚’è¨­è¨ˆã™ã‚‹ã“ã¨ã§ã€å­¦ç¿’ã‚’å®‰å®šåŒ–ã—æ€§èƒ½ã‚‚å‘ä¸Š<br><img src="https://github.com/user-attachments/assets/e3bf6ca8-6873-4d42-83c8-4e9148c16d1d" alt="image" loading="lazy"><br><br>ä»¥ä¸‹ãŒverifierã®ã‚µãƒ³ãƒ—ãƒ«<br><img src="https://github.com/user-attachments/assets/c02274a4-5979-402c-a9c8-145cb1b284bf" alt="image" loading="lazy"></p>
<p>general purposeãªreal worldã«å¯¾ã™ã‚‹multimodal reasoningã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œæˆã™ã‚‹ã«ã¯é«˜å“è³ªã§å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ãªã®ã§ã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç”¨ã„ã¦ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚å¾Œã§èª­ã‚€ã€‚ã‚µãƒãƒªãŒå…ƒãƒã‚¹ãƒˆã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã®ã§å…¨ä½“åƒã‚’ã–ã£ãã‚ŠçŸ¥ã‚ŠãŸã„å ´åˆã¯å‚ç…§ã®ã“ã¨ã€‚<br><img src="https://github.com/user-attachments/assets/6f3b7503-cd3a-4d32-9080-51b875901c23" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SyntheticDataGeneration.html" target="_blank" rel="noopener noreferrer">#SyntheticDataGeneration</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-08-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2390" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging  Synthetic Problems with a Reinforced Policy, Shaoxiong Zhan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MathSmithã¨ã„ã†æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€LLMã®æ•°å­¦çš„æ¨è«–ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã«æ–°ã—ã„å•é¡Œã‚’ã‚¼ãƒ­ã‹ã‚‰åˆæˆã€‚æ—¢å­˜ã®å•é¡Œã‚’ä¿®æ­£ã›ãšã€PlanetMathã‹ã‚‰æ¦‚å¿µã¨èª¬æ˜ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ãƒ‡ãƒ¼ã‚¿ã®ç‹¬ç«‹æ€§ã‚’ç¢ºä¿ã€‚9ã¤ã®æˆ¦ç•¥ã‚’ç”¨ã„ã¦é›£æ˜“åº¦ã‚’ä¸Šã’ã€å¼·åŒ–å­¦ç¿’ã§æ§‹é€ çš„å¦¥å½“æ€§ã‚„æ¨è«–ã®è¤‡é›‘ã•ã‚’æœ€é©åŒ–ã€‚å®Ÿé¨“ã§ã¯ã€MathSmithãŒæ—¢å­˜ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€é«˜é›£æ˜“åº¦ã®åˆæˆãƒ‡ãƒ¼ã‚¿ãŒLLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1954253929761411180?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/ZeroData.html" target="_blank" rel="noopener noreferrer">#ZeroData</a>
<span class="issue_date">Issue Date: 2025-08-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2387" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] R-Zero: Self-Evolving Reasoning LLM from Zero Data, Chengsong Huang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- R-Zeroã¯ã€è‡ªå·±é€²åŒ–å‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ãŒè‡ªå¾‹çš„ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€ãƒãƒ£ãƒ¬ãƒ³ã‚¸ãƒ£ãƒ¼ã¨ã‚½ãƒ«ãƒãƒ¼ã®2ã¤ã®ãƒ¢ãƒ‡ãƒ«ãŒå…±é€²åŒ–ã™ã‚‹ã“ã¨ã§ã€æ—¢å­˜ã®ã‚¿ã‚¹ã‚¯ã‚„ãƒ©ãƒ™ãƒ«ã«ä¾å­˜ã›ãšã«è‡ªå·±æ”¹å–„ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚Šã€æ¨è«–èƒ½åŠ›ãŒå¤§å¹…ã«å‘ä¸Šã—ã€ç‰¹ã«Qwen3-4B-Baseã§ã¯æ•°å­¦æ¨è«–ã§+6.49ã€ä¸€èˆ¬ãƒ‰ãƒ¡ã‚¤ãƒ³æ¨è«–ã§+7.54ã®æ”¹å–„ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1953804055525962134?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å•é¡Œã‚’ç”Ÿæˆã™ã‚‹Challengerã¨ä¸ãˆã‚‰ã‚ŒãŸå•é¡Œã‚’è§£ãSolverã‚’ç”¨æ„ã—ã€ç‰‡æ–¹ã‚’freezezã•ã›ãŸçŠ¶æ…‹ã§äº¤äº’ã«ãƒãƒªã‚·ãƒ¼ã®æ›´æ–°ã‚’ç¹°ã‚Šè¿”ã™ã€‚<br><br><img src="https://github.com/user-attachments/assets/05207756-3029-41a2-8dd0-e27de5228436" alt="image" loading="lazy"><br><br>
<strong>### Challenger<br>-  ï¼ˆChallengerã«ã‚ˆã‚‹)å•é¡Œç”Ÿæˆâ†’<br>- ï¼ˆfreezed solverã«ã‚ˆã‚‹ï¼‰self consistencyã«ã‚ˆã‚‹ãƒ©ãƒ™ãƒ«ä»˜ã‘â†’<br>- Solverã®å•é¡Œã«å¯¾ã™ã‚‹empirical acc.ï¼ˆi.e., ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å›æ•°mã«å¯¾ã™ã‚‹majorityãŒå ã‚ã‚‹å‰²åˆï¼‰ã§rewardã‚’ä¸ãˆChallengerã‚’æ›´æ–°<br><br>ã¨ã„ã£ãŸæµã‚Œã§ãƒãƒªã‚·ãƒ¼ãŒæ›´æ–°ã•ã‚Œã‚‹ã€‚Rewardã¯ä»–ã«ã‚‚ç”Ÿæˆã•ã‚ŒãŸå•é¡Œé–“ã®BLEUã‚’æ¸¬ã‚Šé¡ä¼¼ã—ãŸã‚‚ã®ã°ã‹ã‚Šã®å ´åˆã¯ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’ä¸ãˆã‚‹é …ã‚„ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒæ­£ã—ãæŒ‡å®šã•ã‚ŒãŸé€šã‚Šã«ãªã£ã¦ã„ã‚‹ã‹ã€ã¨ã„ã£ãŸãƒšãƒŠãƒ«ãƒ†ã‚£ã‚‚å°å…¥ã™ã‚‹ã€‚<br><br>### Solver<br>- Challengerã®ãƒãƒªã‚·ãƒ¼ã‹ã‚‰Nå•ç”Ÿæˆã—ã€ãã‚Œã«å¯¾ã—ã¦Solverã§self consistencyã«ã‚ˆã£ã¦è§£ç­”ã‚’ç”Ÿæˆ<br>- empirical acc.ã‚’è¨ˆç®—ã—ã€1/2ã¨ã®å·®åˆ†ã®çµ¶å¯¾å€¤ã‚’è¦‹ã¦ã€ç°¡å˜ã™ãã‚‹/é›£ã—ã™ãã‚‹å•é¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°<br>  - ã“ã‚Œã¯ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ å­¦ç¿’çš„ãªæ„å‘³åˆã„ã®ã¿ãªã‚‰ãšã€ä½å“è³ªãªå•é¡Œã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚‚å¯„ä¸ã™ã‚‹<br>- ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®å•é¡Œã‚’åˆ©ç”¨ã—ã¦ã€verifiable binary rewardã§ãƒãƒªã‚·ãƒ¼ã‚’æ›´æ–°<br><br>### è©•ä¾¡çµæœ<br>æ•°å­¦ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ææ¡ˆæ‰‹æ³•ã‚’é©ç”¨ã—ãŸã¨ã“ã‚ã€iterã”ã¨ã«å…¨ä½“ã®å¹³å‡æ€§èƒ½ã¯å‘ä¸Šã€‚<br><img src="https://github.com/user-attachments/assets/cbe780ec-a99b-4227-b983-4e24982a6af8" alt="image" loading="lazy"><br><br>ææ¡ˆæ‰‹æ³•ã§æ•°å­¦ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’å­¦ç¿’ã—ã€generalãƒ‰ãƒ¡ã‚¤ãƒ³ã«æ±åŒ–ã™ã‚‹ã‹ï¼Ÿã‚’ç¢ºèªã—ãŸã¨ã“ã‚ã€æ±åŒ–ã™ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆãŸã ã€ã™ãã«ã‚µãƒã£ã¦ã„ã‚‹ã‚ˆã†ã«ã‚‚è¦‹ãˆã‚‹ï¼‰ã€‚ã€<br><img src="https://github.com/user-attachments/assets/bc0eb3e1-8ed1-4d36-b30e-095e8a160886" alt="image" loading="lazy">&lt;/p&gt;<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2383" target="_blank" rel="noopener noreferrer">[Paper Note] Self-Questioning Language Models, Lili Chen+, arXiv'25</a>
&lt;/strong&gt;
<br>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1936" target="_blank" rel="noopener noreferrer">Absolute Zero: Reinforced Self-play Reasoning with Zero Data, Andrew Zhao+, arXiv'25</a>
</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wyu_nd/status/1954249813861810312?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chengsongh31219/status/1953936172415430695?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</strong></p>
<p>æ—¥æœ¬èªè§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/curveweb/status/1954367657811308858?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


&lt;/span&gt;<br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/ZeroData.html" target="_blank" rel="noopener noreferrer">#ZeroData</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-08-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2383" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Questioning Language Models, Lili Chen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±è³ªå•å‹è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆSQLMï¼‰ã‚’ææ¡ˆã—ã€ãƒˆãƒ”ãƒƒã‚¯ã‚’æŒ‡å®šã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰è‡ªã‚‰è³ªå•ã‚’ç”Ÿæˆã—ã€è§£ç­”ã™ã‚‹éå¯¾ç§°ã®è‡ªå·±å¯¾æˆ¦ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã€‚ææ¡ˆè€…ã¨è§£ç­”è€…ã¯å¼·åŒ–å­¦ç¿’ã§è¨“ç·´ã•ã‚Œã€å•é¡Œã®é›£æ˜“åº¦ã«å¿œã˜ã¦å ±é…¬ã‚’å—ã‘å–ã‚‹ã€‚ä¸‰æ¡ã®æ›ã‘ç®—ã‚„ä»£æ•°å•é¡Œã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å•é¡Œã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãªã—ã§è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://self-questioning.github.io" target="_blank" rel="noopener noreferrer">https://self-questioning.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lchen915/status/1953896909925757123?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãŸã¨ãˆã°ä¸‹è¨˜ã®ã‚ˆã†ãªã€ãƒ©ãƒ™ãƒ«ç„¡ã—ã®å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã™ã‚‹æ‰‹æ³•ã‚‚ç”¨ã„ã¦self improvingã™ã‚‹æ‰‹æ³•ã¨æ¯”è¼ƒã—ãŸã¨ãã«ã€ã©ã®ç¨‹åº¦ã®æ€§èƒ½å·®ã«ãªã‚‹ã®ã ã‚ã†ã‹ï¼Ÿå¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’å…¨ãåˆ©ç”¨ã›ãšã€å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚ã‚Šã®æ‰‹æ³•ã¨åŒç­‰ã¾ã§ã„ã‘ã¾ã™ã€ã¨ã„ã†è©±ã«ãªã‚‹ã¨ã€ã‚ˆã‚Šèˆˆå‘³æ·±ã„ã¨æ„Ÿã˜ãŸã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1212" target="_blank" rel="noopener noreferrer">Self-Rewarding Language Models, Weizhe Yuan+, N/A, ICML'24</a>
</p>
<p>æ—¢å­˜ã®å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ãªã„é–¢é€£ç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1936" target="_blank" rel="noopener noreferrer">Absolute Zero: Reinforced Self-play Reasoning with Zero Data, Andrew Zhao+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-08-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with  Reward Rectification, Yongliang Wu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã€å‹•çš„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆDFTï¼‰ã‚’ææ¡ˆã€‚DFTã¯ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¢ºç‡ã«åŸºã¥ã„ã¦ç›®çš„é–¢æ•°ã‚’å†ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã€å‹¾é…æ›´æ–°ã‚’å®‰å®šåŒ–ã•ã›ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€SFTã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ã§ã‚‚ç«¶äº‰åŠ›ã®ã‚ã‚‹çµæœã‚’å¾—ãŸã€‚ç†è«–çš„æ´å¯Ÿã¨å®Ÿè·µçš„è§£æ±ºç­–ã‚’çµã³ã¤ã‘ã€SFTã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1953960036126142645?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯å¤§å¤‰èˆˆå‘³æ·±ã„ã€‚æ•°å­¦ä»¥å¤–ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®è©•ä¾¡ã«ã‚‚æœŸå¾…ã—ãŸã„ã€‚</p>
<p>3ç¯€å†’é ­ã‹ã‚‰3.2ç¯€ã«ã‹ã‘ã¦ã€SFTã¨on policy RLã®gradientã‚’å®šå¼åŒ–ã—ã€SFTå´ã®æ•°å¼ã‚’æ•´ç†ã™ã‚‹ã“ã¨ã§ã€SFTï¼ˆã®gradient)ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªon policy RLã®ä¸€ã¤ã®ã‚±ãƒ¼ã‚¹ã¨ã¿ãªã›ã‚‹ã“ã¨ã‚’å°å‡ºã—ã¦ã„ã‚‹ã€‚ãã—ã¦SFTã®æ±åŒ–æ€§èƒ½ãŒä½ã„ã®ã¯ 1/pi_theta ã«ã‚ˆã‚‹importance weightingã§ã‚ã‚‹ã¨ä¸»å¼µã—ã€å®Ÿé¨“çš„ã«ãã‚Œã‚’è¨¼æ˜ã—ã¦ã„ã‚‹ã€‚ã¤ã¾ã‚Šã€ãƒãƒªã‚·ãƒ¼ãŒexpertã®gold responseã«å¯¾ã—ã¦ä½ã„å°¤åº¦ã‚’ç¤ºã—ã¦ã—ã¾ã£ãŸå ´åˆã«ã€weightã‹éå‰°ã«å¤§ãããªã‚Šã€Rewardã®åˆ†æ•£ãŒéåº¦ã«å¤§ãããªã£ã¦ã—ã¾ã†ã“ã¨ãŒRLã®è¦³ç‚¹ã‚’é€šã—ã¦ã¿ã‚‹ã¨å•é¡Œã§ã‚ã‚Šã€ã“ã‚Œã‚’æ˜¯æ­£ã™ã‚‹ã“ã¨ãŒå¿…è¦ã€‚ã•ã‚‰ã«ã€åˆ†æ•£ãŒå¤§ãã„å ±é…¬ã®çŠ¶æ…‹ã§ã€å ±é…¬ãŒsparse(i.e., expertã®trajectoryã®exact matchã—ã¦ã„ãªã„ã¨å ±é…¬ãŒzero)ã§ã‚ã‚‹ã“ã¨ãŒã€ã•ã‚‰ã«äº‹æ…‹ã‚’æ‚ªåŒ–ã•ã›ã¦ã„ã‚‹ã€‚<br><br>&gt; conventional SFT is precisely an on-policy-gradient with the reward as an indicator function of<br>matching the expert trajectory but biased by an importance weighting 1/Ï€Î¸.<br><br>ã¾ã æ–œã‚èª­ã¿ã—ã‹ã—ã¦ã„ãªã„ã®ã§ã€å¾Œã§ã—ã£ã‹ã‚Šèª­ã¿ãŸã„</p>
<p>æœ€è¿‘ã¯ä¸‹è¨˜ã§ç¤ºã•ã‚Œã¦ã„ã‚‹é€šã‚ŠSFTã§warm-upã‚’ã—ãŸå¾Œã«RLã«ã‚ˆã‚‹post-trainingã‚’ã™ã‚‹ã“ã¨ã§æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ãŠã‚Šã€<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
 <br><br>ä¸»è¦ãªOpenModelã§ã‚‚SFT wamup -&gt; RLã®æµã‚ŒãŒä¸»æµã§ã‚ã‚‹ã€‚ã“ã®çŸ¥è¦‹ãŒã€SFTã«ã‚ˆã‚‹warm upã®æœ‰åŠ¹æ€§ã¨ã©ã†ç´ã¥ãã ã‚ã†ã‹ï¼Ÿ<br>ã“ã‚Œã‚’èª­ã‚“ã æ„Ÿã˜ã ã¨ã€importance weightã«ã‚ˆã£ã¦ã€ç¾åœ¨ã®ãƒãƒªã‚·ãƒ¼ãŒè‹¦æ‰‹ãªéƒ¨åˆ†ã®reasoning capabilityã®ã¿ã‚’æœ€åˆã«å¼·åŒ–ã—ï¼ˆ= warmupï¼‰ã€ãã®ä¸Šã§ã‚ˆã‚Šåºƒç¯„ãªã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã™ã‚‹RLãŒå®Ÿæ–½ã•ã‚Œã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€æ€§èƒ½å‘ä¸Šã¨ã€å­¦ç¿’ã®å®‰å®šã«ã¤ãªãŒã£ã¦ã„ã‚‹ã®ã§ã¯ãªã„ã‹ï¼Ÿã¨ã„ã†æ°—ãŒã™ã‚‹ã€‚</p>
<p>æ—¥æœ¬èªè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1960108668336390593?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ä¸€æ­©å…ˆã®è¦–ç‚¹ãŒè€ƒå¯Ÿã•ã‚Œã¦ãŠã‚Šã€ã¨ã¦ã‚‚å‹‰å¼·ã«ãªã‚‹ã€‚</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2025-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2381" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A comprehensive taxonomy of hallucinations in Large Language Models, Manuel Cossio, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªåˆ†é¡æ³•ã‚’æä¾›ã—ã€ãã®æœ¬è³ªçš„ãªé¿ã‘ã‚‰ã‚Œãªã•ã‚’æå”±ã€‚å†…å› çš„ãŠã‚ˆã³å¤–å› çš„ãªè¦å› ã€äº‹å®Ÿèª¤èªã‚„ä¸æ•´åˆãªã©ã®å…·ä½“çš„ãªç¾ã‚Œã‚’åˆ†æã€‚æ ¹æœ¬çš„ãªåŸå› ã‚„èªçŸ¥çš„è¦å› ã‚’æ¤œè¨ã—ã€è©•ä¾¡åŸºæº–ã‚„è»½æ¸›æˆ¦ç•¥ã‚’æ¦‚èª¬ã€‚ä»Šå¾Œã¯ã€ä¿¡é ¼æ€§ã®ã‚ã‚‹å±•é–‹ã®ãŸã‚ã«æ¤œå‡ºã¨ç›£è¦–ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sei_shinagawa/status/1953845008588513762?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2376" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning to Reason for Factuality, Xilun Chen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- R-LLMsã¯è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã§é€²å±•ã—ã¦ã„ã‚‹ãŒã€äº‹å®Ÿæ€§ã«ãŠã„ã¦å¹»è¦šã‚’å¤šãç”Ÿæˆã™ã‚‹ã€‚ã‚ªãƒ³ãƒ©ã‚¤ãƒ³RLã‚’é•·æ–‡ã®äº‹å®Ÿæ€§è¨­å®šã«é©ç”¨ã™ã‚‹éš›ã€ä¿¡é ¼ã§ãã‚‹æ¤œè¨¼æ–¹æ³•ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚èª²é¡ŒãŒã‚ã‚‹ã€‚å¾“æ¥ã®è‡ªå‹•è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ãŸã‚ªãƒ•ãƒ©ã‚¤ãƒ³RLã§ã¯å ±é…¬ãƒãƒƒã‚­ãƒ³ã‚°ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ãŒåˆ¤æ˜ã€‚ãã“ã§ã€äº‹å®Ÿã®ç²¾åº¦ã€è©³ç´°ãƒ¬ãƒ™ãƒ«ã€é–¢é€£æ€§ã‚’è€ƒæ…®ã—ãŸæ–°ã—ã„å ±é…¬é–¢æ•°ã‚’ææ¡ˆã—ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³RLã‚’é©ç”¨ã€‚è©•ä¾¡ã®çµæœã€å¹»è¦šç‡ã‚’å¹³å‡23.1ãƒã‚¤ãƒ³ãƒˆå‰Šæ¸›ã—ã€å›ç­”ã®è©³ç´°ãƒ¬ãƒ™ãƒ«ã‚’23%å‘ä¸Šã•ã›ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1953629692772446481?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ˆè¡Œç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2378" target="_blank" rel="noopener noreferrer">[Paper Note] VERISCORE: Evaluating the factuality of verifiable claims in long-form
  text generation, Yixiao Song+, arXiv'24</a>
</p>
<p>Reasoning Modelã®Hallucination Rateã¯ã€ãã®ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚é«˜ã„ã€‚å®Ÿéš›ã€DeepSeek-V3ã¨DeepSeek-R1,Qwen-2.5-32Bã¨QwQ-32Bã‚’6ã¤ã®Factualityã«é–¢ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ¯”è¼ƒã™ã‚‹ã¨ã€Reasoning Modelã®æ–¹ãŒHallucination RateãŒ10, 13%ç¨‹åº¦é«˜ã‹ã£ãŸã€‚ã“ã‚Œã¯ã€ç¾åœ¨ã®On-policyã®RLãŒlogical reasoningã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦ãŠã‚Šã€Factualityã‚’è¦‹è½ã¨ã—ã¦ã„ã‚‹ãŸã‚ã€ã¨ä»®èª¬ã‚’ç«‹ã¦ã¦ã„ã‚‹ã€‚<br>Factualityï¼ˆç‰¹ã«LongForm)ã¨RL alignmentsã¨ã„ã†è¦³ç‚¹ã‹ã‚‰è¨€ã†ã¨ã€æ±ºå®šçš„ã€æ­£ç¢ºã‹ã¤ä¿¡é ¼æ€§ã®ã‚ã‚‹verificatlonæ‰‹æ³•ã¯å­˜åœ¨ã›ãšã€Human EffortãŒå¿…è¦ä¸å¯æ¬ ã§ã‚ã‚‹ã€‚<br>è‡ªå‹•çš„ã«Factualityã‚’æ¸¬å®šã™ã‚‹FactScoreã®ã‚ˆã†ãªæ‰‹æ³•ã¯ã€DPOã®ã‚ˆã†ãªã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã®ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹ã«ç•™ã¾ã£ã¦ã—ã¾ã£ã¦ã„ã‚‹ã€‚ã¾ãŸã€on dataã§Factualityã‚’æ”¹å–„ã™ã‚‹å–ã‚Šçµ„ã¿ã¯è¡Œã‚ã‚Œã¦ã„ã‚‹ãŒã€long-formãªå¿œç­”ã«å¯¾ã—ã¦ã€factual reasoningã‚’å®Ÿæ–½ã™ã‚‹ã«ã¯ã„ãã¤ã‹ã®èª²é¡ŒãŒæ®‹ã•ã‚Œã¦ã„ã‚‹:<br>- reward design<br>  - Factualityã«é–¢ã™ã‚‹rewardã‚’å˜ç‹¬ã§è¿½åŠ ã™ã‚‹ã ã‘ã ã¨ã€LLMã¯éå¸¸ã«çŸ­ãã€è©³ç´°ã‚’çœç•¥ã—ãŸå¿œç­”ã‚’ã—Precicionã®ã¿ã‚’é«˜ã‚ã‚ˆã†ã¨ã—ã¦ã—ã¾ã†ã€‚<br><br>ã‚ã¨ã§è¿½è¨˜ã™ã‚‹</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2352" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On the Expressiveness of Softmax Attention: A Recurrent Neural Network  Perspective, Gabriel Mongaras+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®å†å¸°çš„ãªå½¢å¼ã‚’å°å‡ºã—ã€ç·šå½¢ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãŒãã®è¿‘ä¼¼ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®å„éƒ¨åˆ†ã‚’RNNã®è¨€èªã§èª¬æ˜ã—ã€æ§‹æˆè¦ç´ ã®é‡è¦æ€§ã¨ç›¸äº’ä½œç”¨ã‚’ç†è§£ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãŒä»–ã®æ‰‹æ³•ã‚ˆã‚Šã‚‚è¡¨ç¾åŠ›ãŒé«˜ã„ç†ç”±ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1952485214162407644?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LinearAttentioné–¢é€£ã®ç ”ç©¶ã¯ä¸‹è¨˜ã‚ãŸã‚ŠãŒã‚ã‚Šãã†ï¼Ÿ<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2353" target="_blank" rel="noopener noreferrer">[Paper Note] Efficient Attention: Attention with Linear Complexities, Zhuoran Shen+, arXiv'18</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2354" target="_blank" rel="noopener noreferrer">[Paper Note] Linformer: Self-Attention with Linear Complexity, Sinong Wang+, arXiv'20</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2355" target="_blank" rel="noopener noreferrer">[Paper Note] Reformer: The Efficient Transformer, Nikita Kitaev+, ICLR'20</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2356" target="_blank" rel="noopener noreferrer">[Paper Note] Transformers are RNNs: Fast Autoregressive Transformers with Linear  Attention, Angelos Katharopoulos+, ICML'20</a>
</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
<br><br>ãŸã¨ãˆã°GQAã¯Qwen3ã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ãŒã€æœ¬ç ”ç©¶ã®çŸ¥è¦‹ã‚’æ´»ç”¨ã—ã¦scaled-dot product attentionè¨ˆç®—æ™‚ã®Softmaxè¨ˆç®—ã®è¨ˆç®—é‡ãŒå‰Šæ¸›ã§ããŸã‚‰ã€ã•ã‚‰ã«è¨ˆç®—é‡ãŒå‰Šæ¸›ã§ããã†ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2350" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MLE-STAR: Machine Learning Engineering Agent via Search and Targeted  Refinement, Jaehyun Nam+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MLE-STARã¯ã€LLMã‚’ç”¨ã„ã¦MLãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•å®Ÿè£…ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€ã‚¦ã‚§ãƒ–ã‹ã‚‰åŠ¹æœçš„ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã—ã€ç‰¹å®šã®MLã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ç„¦ç‚¹ã‚’å½“ã¦ãŸæˆ¦ç•¥ã‚’æ¢ç´¢ã™ã‚‹ã“ã¨ã§ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“çµæœã§ã¯ã€MLE-STARãŒKaggleã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®64%ã§ãƒ¡ãƒ€ãƒ«ã‚’ç²å¾—ã—ã€ä»–ã®æ‰‹æ³•ã‚’å¤§ããä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/marktechpost/status/1951846630266687927?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-08-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2346" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A   Perspective of Probability Theory, Yexiang Liu+, ACL'25 Outstanding Paper</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMã®ãƒ†ã‚¹ãƒˆæ™‚ã®è¨ˆç®—ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ãŠã‘ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæˆ¦ç•¥ã®åŠ¹æœã‚’èª¿æŸ»ã€‚6ã¤ã®LLMã¨8ã¤ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæˆ¦ç•¥ã‚’ç”¨ã„ãŸå®Ÿé¨“ã«ã‚ˆã‚Šã€è¤‡é›‘ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæˆ¦ç•¥ãŒå˜ç´”ãªChain-of-Thoughtã«åŠ£ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ç†è«–çš„ãªè¨¼æ˜ã‚’æä¾›ã€‚ã•ã‚‰ã«ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ€§èƒ½ã‚’äºˆæ¸¬ã—æœ€é©ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæˆ¦ç•¥ã‚’ç‰¹å®šã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã€ãƒªã‚½ãƒ¼ã‚¹é›†ç´„çš„ãªæ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã®å¿…è¦æ€§ã‚’æ’é™¤ã€‚è¤‡é›‘ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†è©•ä¾¡ã¨å˜ç´”ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæˆ¦ç•¥ã®æ½œåœ¨èƒ½åŠ›ã‚’å¼•ãå‡ºã™ã“ã¨ã§ã€ãƒ†ã‚¹ãƒˆæ™‚ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>non-thinkingãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€Majority Voting (i.e. Self Consistency)ã«ã‚ˆã‚‹test-time scalingã‚’å®Ÿæ–½ã™ã‚‹å ´åˆã®ã•ã¾ã–ã¾ãªpromptingæˆ¦ç•¥ã®ã†ã¡ã€budgetã¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°ãŒå°ã•ã„å ´åˆã¯CoTä»¥å¤–ã®é©åˆ‡ãªpromptingæˆ¦ç•¥ã¯ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«ç•°ãªã‚‹ãŒã€budgetã‚„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°ãŒå¢—ãˆã¦ãã‚‹ã¨ã‚·ãƒ³ãƒ—ãƒ«ãªCoTï¼ˆå®Ÿé¨“ã§ã¯zeroshot CoTã‚’åˆ©ç”¨ï¼‰ãŒæœ€é©ãªpromptingæˆ¦ç•¥ã¨ã—ã¦æ”¯é…çš„ã«ãªã‚‹ã€ã¨ã„ã†è©±ãªæ¨¡æ§˜ã€‚<br><br>ã•ã‚‰ã«ã€ãªãœãã†ãªã‚‹ã‹ã®ç†è«–çš„ãªåˆ†æã¨æœ€é©ãªä¸ãˆã‚‰ã‚ŒãŸäºˆç®—ã‹ã‚‰æœ€é©ãªpromptingæˆ¦ç•¥ã‚’äºˆæ¸¬ã™ã‚‹æ‰‹æ³•ã‚‚ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br>ãŒã€è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®é›£æ˜“åº¦ãªã©ã«ã‚ˆã£ã¦ã“ã®è¾ºã¯å¤‰ã‚ã‚‹ã¨æ€ã‚ã‚Œã€ç‰¹ã«Figure39ã«ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªã€**ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°ãŒå¢—ãˆã‚‹ã¨ç°¡å˜ãªå•é¡Œã®æ­£è§£ç‡ãŒä¸ŠãŒã‚Šã€é€†ã«é›£ã—ã„å•é¡Œã®æ­£è§£ç‡ãŒä¸‹ãŒã‚‹ã¨ã„ã£ãŸå‚¾å‘ãŒã‚ã‚Šã€CoTãŒç°¡å˜ãªå•é¡Œã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°ã‚’å¢—ã‚„ã™ã¨å®‰å®šã—ã¦æ­£è§£ã§ãã‚‹ã‹ã‚‰æ”¯é…çš„ã«ãªã‚‹**ã€ã¨ã„ã†è©±ã ã¨æ€ã‚ã‚Œã‚‹ã®ã§ã€å¸¸ã«CoTãŒè‰¯ã„ã¨å‹˜é•ã„ã—ãªã„æ–¹ãŒè‰¯ã•ãã†ã ã¨æ€ã‚ã‚Œã‚‹ã€‚ãŸã¨ãˆã°ã€**è§£ã“ã†ã¨ã—ã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ãŒé›£å•ã°ã‹ã‚Šã§ã‚ã‚Œã°CoTã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã®ãŒè‰¯ã„ã¨ã¯é™ã‚‰ãªã„ã€ã¨ã„ã£ãŸç‚¹ã«ã¯æ³¨æ„ãŒå¿…è¦**ã ã¨æ€ã†ã®ã§ã€ã—ã£ã‹ã‚Šå…¨æ–‡èª­ã‚“ã æ–¹ãŒè‰¯ã„ã€‚æ™‚é–“ãŒã‚ã‚‹æ™‚ã«èª­ã¿ãŸã„ï¼ˆãªã‹ãªã‹ã¾ã¨ã¾ã£ãŸæ™‚é–“å–ã‚Œãªã„ï¼‰<br><br><img src="https://github.com/user-attachments/assets/f99e3445-7962-488d-87a4-744022f796c8" alt="image" loading="lazy"></p>
<p>æœ€é©ãªpromptingæˆ¦ç•¥ã‚’äºˆæ¸¬ã™ã‚‹æ‰‹æ³•ã§ã¯ã€<br>- å•é¡Œã®é›£æ˜“åº¦ã«å¿œã˜ã¦é©å¿œçš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚’å¤‰åŒ–ã•ã›(ãªã‚“ã¨O(1)ã§äºˆæ¸¬ãŒã§ãã‚‹)<br>- å‹•çš„ã«æœ€é©ãªpromptingæˆ¦ç•¥ã‚’é¸æŠ<br><br>ã™ã‚‹ã“ã¨ã§ã€Majority@10ã®Acc.ã‚’8Bã‚¹ã‚±ãƒ¼ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã§10--50%ç¨‹åº¦å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹æ¨¡æ§˜ã€‚ã„ã‚„ã“ã‚Œã»ã‚“ã¨ã—ã£ã‹ã‚Šèª­ã¾ã­ã°ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/CrossDomain.html" target="_blank" rel="noopener noreferrer">#CrossDomain</a>
<span class="issue_date">Issue Date: 2025-08-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2341" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SRPO: A Cross-Domain Implementation of Large-Scale Reinforcement  Learning on LLM, Xiaojiang Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- äºŒæ®µéšå±¥æ­´å†ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒãƒªã‚·ãƒ¼æœ€é©åŒ–ï¼ˆSRPOï¼‰ã‚’ææ¡ˆã—ã€DeepSeek-R1-Zero-32Bã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’AIME24ãŠã‚ˆã³LiveCodeBenchã§é”æˆã€‚SRPOã¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç´„1/10ã«å‰Šæ¸›ã—ã€åŠ¹ç‡æ€§ã‚’ç¤ºã™ã€‚äºŒã¤ã®é©æ–°ã¨ã—ã¦ã€ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã¨å±¥æ­´å†ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æŠ€è¡“ã‚’å°å…¥ã—ã€LLMã®æ¨è«–èƒ½åŠ›ã‚’æ‹¡å¼µã™ã‚‹ãŸã‚ã®å®Ÿé¨“ã‚’è¡Œã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1914920300359377232?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>GRPOã‚ˆã‚Šã‚‚ã‚ˆã‚ŠåŠ¹ç‡çš„ãªæ‰‹æ³•ãªæ¨¡æ§˜ã€‚æœ€åˆã«æ•°å­¦ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã‚’ã—Reasoning Capabilityã‚’èº«ã«ã¤ã‘ã•ã›ã€ãã®å¾Œåˆ¥ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã•ã›ã‚‹ã“ã¨ã§ã€ãã®èƒ½åŠ›ã‚’ç™ºæ®ã•ã›ã‚‹ã‚ˆã†ãªäºŒæ®µéšã®æ‰‹æ³•ã‚‰ã—ã„ã€‚<br><br>Datamixingã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ï¼ˆãŸã ã—ã€ã“ã‚Œã¯æ•°å­¦ã¨ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®CoT Lengthã®ãƒ‰ãƒ¡ã‚¤ãƒ³é–“ã®é•ã„ã«èµ·å› ã—ã¦ã“ã®ã‚ˆã†ãª2 stageãªæ‰‹æ³•ã«ã—ã¦ã„ã‚‹ã‚ˆã†ãªã®ã§ãã®ç‚¹ã«ã¯æ³¨æ„ãŒå¿…è¦ãã†ï¼‰ï¼Ÿã—ã£ã‹ã‚Šã¨èª­ã‚ã¦ã„ãªã„ã®ã§ã€èª­ã¿é•ã„ã®å¯èƒ½æ€§ã‚‚ã‚ã‚‹ã®ã§æ³¨æ„ã€‚<br><img src="https://github.com/user-attachments/assets/cf00de8b-1923-4f23-b575-0a889517ec9e" alt="image" loading="lazy"></p>
<p>ãªã‚“ãŸã‚‰RPOå¤šã™ãå•é¡Œ</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2340" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WSM: Decay-Free Learning Rate Schedule via Checkpoint Merging for LLM  Pre-training, Changxin Tian+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã®æ–°ãŸãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã—ã¦ã€Warmup-Stable and Mergeï¼ˆWSMï¼‰ã‚’ææ¡ˆã€‚WSMã¯ã€å­¦ç¿’ç‡ã®æ¸›è¡°ã¨ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã®é–¢ä¿‚ã‚’ç¢ºç«‹ã—ã€ã•ã¾ã–ã¾ãªæ¸›è¡°æˆ¦ç•¥ã‚’çµ±ä¸€çš„ã«æ‰±ã†ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ãƒãƒ¼ã‚¸æœŸé–“ãŒãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã«ãŠã„ã¦é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€å¾“æ¥ã®WSDã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä¸Šå›ã‚‹æ€§èƒ½å‘ä¸Šã‚’é”æˆã€‚ç‰¹ã«ã€MATHã§+3.5%ã€HumanEvalã§+2.9%ã€MMLU-Proã§+5.5%ã®æ”¹å–„ã‚’è¨˜éŒ²ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stochasticchasm/status/1951427541803106714?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Weight Decayã‚’ç„¡ãã›ã‚‹ã‚‰ã—ã„</p>
<p>ã‚¨ãƒƒã‚»ãƒ³ã‚¹ã®è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhaocha1/status/1951790366900019376?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã•ãˆä¿å­˜ã—ã¦ãŠã„ã¦äº‹å¾Œçš„ã«æ´»ç”¨ã™ã‚‹ã“ã¨ã ã§ã€ç´°ã‹ãªãƒã‚¤ãƒ‘ãƒ©èª¿æ•´ã®ãŸã‚ã®è©¦è¡ŒéŒ¯èª¤ã™ã‚‹æ‰‹é–“ã¨è†¨å¤§ãªè¨ˆç®—ã‚³ã‚¹ãƒˆãŒãªããªã‚‹ã®ã§ã‚ã‚Œã°ç›¸å½“ç´ æ™´ã‚‰ã—ã„ã®ã§ã¯â€¦ï¼Ÿ<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1965893163152793728?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2334" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning  and non-reasoning tasks, Ping Yu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- CoT-Self-Instructã‚’ææ¡ˆã—ã€LLMã«åŸºã¥ã„ã¦æ–°ã—ã„åˆæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã‚’é–‹ç™ºã€‚åˆæˆãƒ‡ãƒ¼ã‚¿ã¯MATH500ã‚„AMC23ãªã©ã§æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€æ¤œè¨¼ä¸å¯èƒ½ãªã‚¿ã‚¹ã‚¯ã§ã‚‚äººé–“ã‚„æ¨™æº–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¸Šå›ã‚‹çµæœã‚’å¾—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1951084679286722793?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚ˆã‚Šè¤‡é›‘ã§ã€Reasoningã‚„planningã‚’ä¿ƒã™ã‚ˆã†ãªinstructionãŒç”Ÿæˆã•ã‚Œã‚‹æ¨¡æ§˜ã€‚å®Ÿéš›ã«ç”Ÿæˆã•ã‚ŒãŸinstructionã®exampleã¯å…¨ä½“ã‚’ã–ã£ã¨ã¿ãŸæ„Ÿã˜ã“ã®å›³ä¸­ã®ã‚‚ã®ã®ã¿ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/98dcb6a3-686f-4e3d-bf83-7b36765c0953" alt="image" loading="lazy"></p>
<p>ä»¥ä¸‹ã®ã‚¹ã‚¯ã‚·ãƒ§ã¯Magpieã«ã‚ˆã£ã¦åˆæˆã•ã‚ŒãŸinstructionã€‚InstructionTuningç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã™ã‚‹ãªã‚‰MagpieãŒä¾¿åˆ©ãã†ã ãªãã€ã¨æ€ã£ã¦ã„ãŸã®ã ãŒã€æ¯”è¼ƒã™ã‚‹ã¨CoT-SelfInstructã®æ–¹ãŒã€ã‚ˆã‚Šè¤‡é›‘ã§å…·ä½“çš„ãªæŒ‡ç¤ºã‚’å«ã‚€instructionãŒç”Ÿæˆã•ã‚Œã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2094" target="_blank" rel="noopener noreferrer">[Paper Note] Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs   with Nothing, Zhangchen Xu+, ICLR'25</a>
<br><br><img src="https://github.com/user-attachments/assets/a631a2bc-d2ee-49dd-96a1-00354ff1f40a" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2332" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty, Mehul Damani+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RLCRã‚’ç”¨ã„ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«ã‚ˆã‚Šã€æ¨è«–ã®ç²¾åº¦ã¨ä¿¡é ¼åº¦ã‚’åŒæ™‚ã«æ”¹å–„ã€‚ãƒã‚¤ãƒŠãƒªå ±é…¬ã«åŠ ãˆã€ä¿¡é ¼åº¦æ¨å®šã®ãŸã‚ã®ãƒ–ãƒ©ã‚¤ãƒ¤ãƒ¼ã‚¹ã‚³ã‚¢ã‚’ç”¨ã„ãŸå ±é…¬é–¢æ•°ã‚’æœ€é©åŒ–ã€‚RLCRã¯ã€é€šå¸¸ã®RLã‚ˆã‚Šã‚‚ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ”¹å–„ã—ã€ç²¾åº¦ã‚’æãªã†ã“ã¨ãªãä¿¡é ¼æ€§ã®é«˜ã„æ¨è«–ãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/asap2650/status/1950942279872762272?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLMã«Confidenceã‚’DiscreteãªTokenã¨ã—ã¦ï¼ˆGEvalãªã©ã¯é™¤ãï¼‰å‡ºåŠ›ã•ã›ã‚‹ã¨ä¿¡é ¼ã§ããªã„ã“ã¨ãŒå¤šã„ã®ã§ã€ã‚‚ã—ãã‚Œã‚‚æ”¹å–„ã™ã‚‹ã®ã ã¨ã—ãŸã‚‰èˆˆå‘³æ·±ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Composition.html" target="_blank" rel="noopener noreferrer">#Composition</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<a class="button" href="articles/CommonsenseReasoning.html" target="_blank" rel="noopener noreferrer">#CommonsenseReasoning</a>
<span class="issue_date">Issue Date: 2025-07-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2328" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Revisiting Compositional Generalization Capability of Large Language   Models Considering Instruction Following Ability, Yusuke Sakai+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- Ordered CommonGenã‚’ææ¡ˆã—ã€LLMsã®æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã¨æ§‹æˆçš„ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã€‚36ã®LLMsã‚’åˆ†æã—ãŸçµæœã€æŒ‡ç¤ºã®æ„å›³ã¯ç†è§£ã—ã¦ã„ã‚‹ãŒã€æ¦‚å¿µã®é †åºã«å¯¾ã™ã‚‹ãƒã‚¤ã‚¢ã‚¹ãŒä½å¤šæ§˜æ€§ã®å‡ºåŠ›ã‚’å¼•ãèµ·ã“ã™ã“ã¨ãŒåˆ¤æ˜ã€‚æœ€ã‚‚æŒ‡ç¤ºã«å¾“ã†LLMã§ã‚‚ç´„75%ã®é †åºä»˜ãã‚«ãƒãƒ¬ãƒƒã‚¸ã—ã‹é”æˆã§ããšã€ä¸¡èƒ½åŠ›ã®æ”¹å–„ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®æ„å‘³ã®æ§‹æˆæ€§ã¨æŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ã‚’åŒæ™‚ã«ç™ºæ®ã™ã‚‹èƒ½åŠ›ã‚’æ¸¬å®šå¯èƒ½ãªOrderedCommonGenã‚’ææ¡ˆ<br><br><img src="https://github.com/user-attachments/assets/ae8c9468-a788-4baa-a618-402eae92c6c8" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/24ba68b4-3484-4597-a401-1e47183276cf" alt="image" loading="lazy"></p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2330" target="_blank" rel="noopener noreferrer">[Paper Note] CommonGen: A Constrained Text Generation Challenge for Generative   Commonsense Reasoning, Bill Yuchen Lin+, EMNLP'20 Findings</a>
</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2025-07-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2325" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Efficient Attention Mechanisms for Large Language Models: A Survey, Yutao Sun+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è‡ªå·±æ³¨æ„ã®è¤‡é›‘ã•ãŒé•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®éšœå®³ã¨ãªã£ã¦ã„ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ç·šå½¢æ³¨æ„æ‰‹æ³•ã¨ã‚¹ãƒ‘ãƒ¼ã‚¹æ³¨æ„æŠ€è¡“ãŒå°å…¥ã•ã‚Œã€è¨ˆç®—åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã¤ã¤ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’ä¿æŒã™ã‚‹ã€‚æœ¬ç ”ç©¶ã¯ã€ã“ã‚Œã‚‰ã®é€²å±•ã‚’ä½“ç³»çš„ã«ã¾ã¨ã‚ã€åŠ¹ç‡çš„ãªæ³¨æ„ã‚’å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«çµ„ã¿è¾¼ã‚€æ–¹æ³•ã‚’åˆ†æã—ã€ç†è«–ã¨å®Ÿè·µã‚’çµ±åˆã—ãŸã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒ¢ãƒ‡ãƒ«è¨­è¨ˆã®åŸºç¤ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1950287053046022286?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/user-attachments/assets/df56fa40-4206-4d12-9172-39f7b36f19c7" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<span class="issue_date">Issue Date: 2025-07-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2321" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Survey of Self-Evolving Agents: On Path to Artificial Super  Intelligence, Huan-ang Gao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯é™çš„ã§ã‚ã‚Šã€å‹•çš„ãªç’°å¢ƒã«é©å¿œã§ããªã„ãŸã‚ã€è‡ªå·±é€²åŒ–ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¿…è¦æ€§ãŒé«˜ã¾ã£ã¦ã„ã‚‹ã€‚æœ¬èª¿æŸ»ã¯ã€è‡ªå·±é€²åŒ–ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«é–¢ã™ã‚‹åˆã®åŒ…æ‹¬çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æä¾›ã—ã€é€²åŒ–ã®åŸºç¤çš„ãªæ¬¡å…ƒã‚’æ•´ç†ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é€²åŒ–çš„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚„é©å¿œæ‰‹æ³•ã‚’åˆ†é¡ã—ã€è©•ä¾¡æŒ‡æ¨™ã‚„å¿œç”¨åˆ†é‡ã‚’åˆ†æã€‚æœ€çµ‚çš„ã«ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè‡ªå¾‹çš„ã«é€²åŒ–ã—ã€äººé–“ãƒ¬ãƒ™ãƒ«ã®çŸ¥èƒ½ã‚’è¶…ãˆã‚‹äººå·¥è¶…çŸ¥èƒ½ï¼ˆASIï¼‰ã®å®Ÿç¾ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ottamm_190/status/1950331148741333489?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Figure3ãŒã¨ã¦ã‚‚å‹‰å¼·ã«ãªã‚‹ã€‚Self-Evolveã¨å‘¼ã‚“ã æ™‚ã«ã€ãã‚ŒãŒã©ã®ã‚ˆã†ã«Evolveã™ã‚‹ã‚‚ã®ãªã®ã‹ã¯ãã¡ã‚“ã¨ãƒã‚§ãƒƒã‚¯ã—ãŸæ–¹ãŒè‰¯ã•ãã†ã€‚è¿½åŠ ã®å­¦ç¿’ã‚’ã™ã‚‹ã®ã‹å¦ã‹ãªã©ã€‚ã“ã‚Œã«ã‚ˆã£ã¦ä½¿ã„ã‚„ã™ã•ãŒæ®µé•ã„ã«ãªã‚Šãã†ãªã®ã§ã€‚<br><img src="https://github.com/user-attachments/assets/bfa7e8b3-2a5b-4b26-b474-deaee443ee25" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/bcaaadda-ef9b-49dc-a357-3cb6fdf01ca4" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/CLIP.html" target="_blank" rel="noopener noreferrer">#CLIP</a>
<span class="issue_date">Issue Date: 2025-07-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2320" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MetaCLIP 2: A Worldwide Scaling Recipe, Yung-Sung Chuang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MetaCLIP 2ã‚’ææ¡ˆã—ã€CLIPã‚’ã‚¼ãƒ­ã‹ã‚‰è¨“ç·´ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç¤ºã™ã€‚è‹±èªã¨éè‹±èªãƒ‡ãƒ¼ã‚¿ã®ç›¸äº’åˆ©ç›Šã‚’å¾—ã‚‹ãŸã‚ã®æœ€å°é™ã®å¤‰æ›´ã‚’åŠ ãˆã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®ImageNetåˆ†é¡ã§è‹±èªå°‚ç”¨ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã€‚å¤šè¨€èªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚‚æ–°ãŸãªæœ€å…ˆç«¯ã‚’è¨˜éŒ²ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1950366185742016935?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2317" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On The Role of Pretrained Language Models in General-Purpose Text  Embeddings: A Survey, Meishan Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬èª¿æŸ»ã§ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆPLMsï¼‰ã‚’æ´»ç”¨ã—ãŸä¸€èˆ¬ç›®çš„ã®ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ï¼ˆGPTEï¼‰ã®ç™ºå±•ã‚’æ¦‚è¦³ã—ã€PLMsã®å½¹å‰²ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã€‚åŸºæœ¬çš„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„åŸ‹ã‚è¾¼ã¿æŠ½å‡ºã€è¡¨ç¾åŠ›å‘ä¸Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã«ã¤ã„ã¦èª¬æ˜ã—ã€PLMsã«ã‚ˆã‚‹å¤šè¨€èªã‚µãƒãƒ¼ãƒˆã‚„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«çµ±åˆãªã©ã®é«˜åº¦ãªå½¹å‰²ã‚‚è€ƒå¯Ÿã™ã‚‹ã€‚ã•ã‚‰ã«ã€å°†æ¥ã®ç ”ç©¶æ–¹å‘æ€§ã¨ã—ã¦ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°çµ±åˆã‚„ãƒã‚¤ã‚¢ã‚¹è»½æ¸›ãªã©ã®æ”¹å–„ç›®æ¨™ã‚’è¶…ãˆãŸèª²é¡Œã‚’å¼·èª¿ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bo_wangbo/status/1950158633645363465?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>GPTEã®å­¦ç¿’æ‰‹æ³•ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã§ãªãã€ç”»åƒã‚„ã‚³ãƒ¼ãƒ‰ãªã©ã®æ§˜ã€…ãªãƒ¢ãƒ¼ãƒ€ãƒ«ã€ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„è©•ä¾¡æ–¹æ³•ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¨MTEBã®æ€§èƒ½ã®é–¢ä¿‚æ€§ã®å›³è§£ãªã©ã€ç››ã‚Šã ãã•ã‚“ãªæ¨¡æ§˜ã€‚æœ€æ–°ã®ã‚‚ã®ã ã‘ã§ãªãã€2021å¹´é ƒã®T5ã‹ã‚‰æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã¾ã§ç¶²ç¾…çš„ã«ã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚æ—¥æœ¬èªç‰¹åŒ–ã®ãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦ã¯è¨˜è¿°ãŒç„¡ã•ãã†ã§ã¯ã‚ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/f0a40a10-7f29-4aaf-b989-672213622ebc" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/7940d307-f1db-421f-86a4-6c9cca22f27c" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/46282995-d538-4bd2-9aa5-983253a98f8f" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/dc4212de-19df-497c-951e-3addff5a193f" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/ac925f56-de46-49ae-b0a8-cd8e2ecc4994" alt="image" loading="lazy"></p>
<p>æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦ã¯Ruriã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼ã‚„ã€LLMå‹‰å¼·ä¼šã®ã¾ã¨ã‚ã‚’å‚ç…§ã®ã“ã¨<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1375" target="_blank" rel="noopener noreferrer">Ruri: Japanese General Text Embeddings, cl-nagoya, 2024.09</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1563" target="_blank" rel="noopener noreferrer">æ—¥æœ¬èªLLMã¾ã¨ã‚, LLM-jp, 2024.12</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/AES(AutomatedEssayScoring).html" target="_blank" rel="noopener noreferrer">#AES(AutomatedEssayScoring)</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AIED.html" target="_blank" rel="noopener noreferrer">#AIED</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2315" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Do We Need a Detailed Rubric for Automated Essay Scoring using Large   Language Models?, Lui Yoshida, AIED'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMã‚’ç”¨ã„ãŸè‡ªå‹•ã‚¨ãƒƒã‚»ã‚¤æ¡ç‚¹ã«ãŠã‘ã‚‹ãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã®è©³ç´°ã•ãŒæ¡ç‚¹ç²¾åº¦ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã€‚TOEFL11ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€å®Œå…¨ãªãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã€ç°¡ç•¥åŒ–ã•ã‚ŒãŸãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã€ãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ãªã—ã®3æ¡ä»¶ã‚’æ¯”è¼ƒã€‚çµæœã€3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã¯ç°¡ç•¥åŒ–ã•ã‚ŒãŸãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã§ã‚‚ç²¾åº¦ã‚’ç¶­æŒã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’å‰Šæ¸›ã€‚ä¸€æ–¹ã€1ã¤ã®ãƒ¢ãƒ‡ãƒ«ã¯è©³ç´°ãªãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã§æ€§èƒ½ãŒä½ä¸‹ã€‚ç°¡ç•¥åŒ–ã•ã‚ŒãŸãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ãŒå¤šãã®LLMã«ã¨ã£ã¦åŠ¹ç‡çš„ãªä»£æ›¿æ‰‹æ®µã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ãŒã€ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®è©•ä¾¡ã‚‚é‡è¦ã€‚</span>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2314" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] EduThink4AI: Translating Educational Critical Thinking into Multi-Agent  LLM Systems, Xinmeng Hou+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- EDU-Promptingã¯ã€æ•™è‚²çš„æ‰¹åˆ¤çš„æ€è€ƒç†è«–ã¨LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­è¨ˆã‚’çµã³ã¤ã‘ã€æ‰¹åˆ¤çš„ã§ãƒã‚¤ã‚¢ã‚¹ã‚’æ„è­˜ã—ãŸèª¬æ˜ã‚’ç”Ÿæˆã™ã‚‹æ–°ã—ã„ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€AIç”Ÿæˆã®æ•™è‚²çš„å¿œç­”ã®çœŸå®Ÿæ€§ã¨è«–ç†çš„å¦¥å½“æ€§ãŒå‘ä¸Šã—ã€æ—¢å­˜ã®æ•™è‚²ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«çµ±åˆå¯èƒ½ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1949481352325128236?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Critiqueã‚’æ´»ç”¨ã—ãŸãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚ˆã†ã§ã‚ã‚‹ï¼ˆå…·ä½“çš„ãªCritiqueã®ç”Ÿæˆæ–¹æ³•ã«ã¤ã„ã¦ã¯èª­ã‚ã¦ã„ãªã„ã€‚ãã®è¾ºãŒé‡è¦ãã†<br><br><img src="https://github.com/user-attachments/assets/a2e73806-a87f-4eab-a83f-b8767d4cd316" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/92256b2a-b655-4b6f-a288-67ff4893c77b" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2313" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning without training: The implicit dynamics of in-context learning, Benoit Dherin+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã¯æ–‡è„ˆå†…ã§æ–°ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã™ã‚‹èƒ½åŠ›ã‚’æŒã¡ã€ãã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯æœªè§£æ˜ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ–ãƒ­ãƒƒã‚¯ãŒè‡ªå·±æ³¨æ„å±¤ã¨MLPã‚’é‡ã­ã‚‹ã“ã¨ã§ã€æ–‡è„ˆã«å¿œã˜ã¦MLPã®é‡ã¿ã‚’æš—é»™çš„ã«ä¿®æ­£ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã€ã“ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒLLMã®æ–‡è„ˆå†…å­¦ç¿’ã®ç†ç”±ã§ã‚ã‚‹å¯èƒ½æ€§ã‚’ææ¡ˆã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1948384435654779105?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1950333455134576794?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2310" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation, Tiansheng Wen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç”¨ã„ãŸContrastive Sparse Representationï¼ˆCSRï¼‰ã‚’ææ¡ˆã—ã€é©å¿œçš„ãªåŸ‹ã‚è¾¼ã¿ã‚’å®Ÿç¾ã€‚CSRã¯äº‹å‰è¨“ç·´ã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿ã‚’ã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–ã—ã€æ„å‘³çš„å“è³ªã‚’ä¿æŒã—ã¤ã¤ã‚³ã‚¹ãƒˆåŠ¹æœã®é«˜ã„æ¨è«–ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€CSRã¯ç²¾åº¦ã¨æ¤œç´¢é€Ÿåº¦ã§Matryoshka Representation Learningï¼ˆMRLï¼‰ã‚’ä¸Šå›ã‚Šã€è¨“ç·´æ™‚é–“ã‚‚å¤§å¹…ã«çŸ­ç¸®ã•ã‚Œã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯å®Ÿä¸–ç•Œã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹é©å¿œçš„ãªè¡¨ç¾å­¦ç¿’ã®å¼·åŠ›ãªæ‰‹æ³•ã¨ã—ã¦ä½ç½®ã¥ã‘ã‚‰ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1949957739637002450?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒãƒˆãƒªãƒ§ãƒ¼ã‚·ã‚«è¡¨ç¾:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2311" target="_blank" rel="noopener noreferrer">[Paper Note] Matryoshka Representation Learning, Aditya Kusupati+, NeurIPS'22</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Trustfulness.html" target="_blank" rel="noopener noreferrer">#Trustfulness</a>
<span class="issue_date">Issue Date: 2025-07-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2306" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Rectifying Belief Space via Unlearning to Harness LLMs' Reasoning, Ayana Niwa+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ä¸æ­£ç¢ºãªå›ç­”ã¯è™šå½ã®ä¿¡å¿µã‹ã‚‰ç”Ÿã˜ã‚‹ã¨ä»®å®šã—ã€ä¿¡å¿µç©ºé–“ã‚’ä¿®æ­£ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚ãƒ†ã‚­ã‚¹ãƒˆèª¬æ˜ç”Ÿæˆã§ä¿¡å¿µã‚’ç‰¹å®šã—ã€FBBSã‚’ç”¨ã„ã¦è™šå½ã®ä¿¡å¿µã‚’æŠ‘åˆ¶ã€çœŸã®ä¿¡å¿µã‚’å¼·åŒ–ã€‚å®Ÿè¨¼çµæœã¯ã€èª¤ã£ãŸå›ç­”ã®ä¿®æ­£ã¨ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®å‘ä¸Šã‚’ç¤ºã—ã€ä¸€èˆ¬åŒ–ã®æ”¹å–„ã«ã‚‚å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ayaniwa1213/status/1949750575123276265?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/ActivationSteering/ITI.html" target="_blank" rel="noopener noreferrer">#ActivationSteering/ITI</a>
<a class="button" href="articles/Trustfulness.html" target="_blank" rel="noopener noreferrer">#Trustfulness</a>
<span class="issue_date">Issue Date: 2025-07-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2303" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GrAInS: Gradient-based Attribution for Inference-Time Steering of LLMs  and VLMs, Duy Nguyen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- GrAInSã¯ã€LLMsãŠã‚ˆã³VLMsã®æ¨è«–æ™‚ã«å†…éƒ¨æ´»æ€§ã‚’èª¿æ•´ã™ã‚‹æ–°ã—ã„ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°æ‰‹æ³•ã§ã€å›ºå®šã•ã‚ŒãŸä»‹å…¥ãƒ™ã‚¯ãƒˆãƒ«ã«ä¾å­˜ã›ãšã€ãƒˆãƒ¼ã‚¯ãƒ³ã®å› æœçš„å½±éŸ¿ã‚’è€ƒæ…®ã—ã¾ã™ã€‚çµ±åˆå‹¾é…ã‚’ç”¨ã„ã¦ã€å‡ºåŠ›ã¸ã®å¯„ä¸ã«åŸºã¥ãé‡è¦ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç‰¹å®šã—ã€æœ›ã¾ã—ã„è¡Œå‹•ã¸ã®å¤‰åŒ–ã‚’æ‰ãˆã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å†è¨“ç·´ãªã—ã§ãƒ¢ãƒ‡ãƒ«ã®æŒ™å‹•ã‚’ç´°ã‹ãåˆ¶å¾¡ã§ãã€å®Ÿé¨“ã§ã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„æ—¢å­˜æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æˆæœã‚’ç¤ºã—ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€TruthfulQAã§ç²¾åº¦ã‚’13.22%å‘ä¸Šã•ã›ã€MMHal-Benchã®å¹»è¦šç‡ã‚’ä½ä¸‹ã•ã›ã€SPA-VLã§ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆå‹ç‡ã‚’æ”¹å–„ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/duynguyen772/status/1948768520587866522?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¢å­˜ã®steeringæ‰‹æ³•ã¯ã€positive/negativeãªã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰ã®å·®åˆ†ã§å˜ä¸€æ–¹å‘ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç®—å‡ºã—ã€ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«è¶³ã—åˆã‚ã›ã‚‹ãŒã€æœ¬æ‰‹æ³•ã¯ãã“ã‹ã‚‰ã•ã‚‰ã«positive/negativeãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã«ã¾ã§è¸ã¿è¾¼ã¿ã€negativeãªãƒ™ã‚¯ãƒˆãƒ«ã¨positiveãªãƒ™ã‚¯ãƒˆãƒ«ã®åŒæ–¹ã‚’ç”¨ã„ã¦ã€negative-&gt;positiveæ–¹å‘ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç®—å‡ºã—ã¦steeringã«æ´»ç”¨ã™ã‚‹æ–¹æ³•ã£ã½ã„ï¼Ÿ<br><img src="https://github.com/user-attachments/assets/4a4df18c-d5bc-4499-83ae-16fc9f24e8b4" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/938dee15-ed05-4505-97c2-d079b9713cd3" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/ce075fc0-a8f4-42f2-9462-6c6d12085ef6" alt="image" loading="lazy"></p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1941" target="_blank" rel="noopener noreferrer">Inference-Time Intervention: Eliciting Truthful Answers from a Language   Model, Kenneth Li+, NeurIPS'23</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-07-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2300" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Ming-Omni: A Unified Multimodal Model for Perception and Generation, Inclusion AI+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Ming-Omniã¯ã€ç”»åƒã€ãƒ†ã‚­ã‚¹ãƒˆã€éŸ³å£°ã€å‹•ç”»ã‚’å‡¦ç†ã§ãã‚‹çµ±ä¸€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã€éŸ³å£°ç”Ÿæˆã¨ç”»åƒç”Ÿæˆã«ãŠã„ã¦å„ªã‚ŒãŸèƒ½åŠ›ã‚’ç¤ºã™ã€‚å°‚ç”¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’ç”¨ã„ã¦ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŠ½å‡ºã—ã€MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§å‡¦ç†ã™ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ã«ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›ã‚’èåˆã€‚éŸ³å£°ãƒ‡ã‚³ãƒ¼ãƒ€ã¨é«˜å“è³ªãªç”»åƒç”Ÿæˆã‚’çµ±åˆã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¿œã˜ãŸãƒãƒ£ãƒƒãƒˆã‚„ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã¸ã®å¤‰æ›ã€ç”»åƒç·¨é›†ãŒå¯èƒ½ã€‚Ming-Omniã¯ã€GPT-4oã«åŒ¹æ•µã™ã‚‹åˆã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ç ”ç©¶ã¨é–‹ç™ºã‚’ä¿ƒé€²ã™ã‚‹ãŸã‚ã«ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/62fe9563-ed6b-40bf-ad95-067407534626" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1948878025757446389?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ç¾åœ¨ã¯v1.5ã‚‚å…¬é–‹ã•ã‚Œã¦ãŠã‚Šã•ã‚‰ã«æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã‚‹æ¨¡æ§˜ï¼Ÿ<p>HF:


<a href="https://huggingface.co/inclusionAI/Ming-Lite-Omni" target="_blank" rel="noopener noreferrer">https://huggingface.co/inclusionAI/Ming-Lite-Omni</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-07-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2299" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Group Sequence Policy Optimization, Chujie Zheng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Group Sequence Policy Optimization (GSPO)ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®æ–°ã—ã„å¼·åŒ–å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®å°¤åº¦ã«åŸºã¥ãé‡è¦åº¦æ¯”ã‚’ç”¨ã„ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã€‚GSPOã¯ã€å¾“æ¥ã®GRPOã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã§é«˜æ€§èƒ½ã§ã‚ã‚Šã€Mixture-of-Experts (MoE) ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®‰å®šåŒ–ã•ã›ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æœ€æ–°ã®Qwen3ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦é¡•è‘—ãªæ”¹å–„ãŒè¦‹ã‚‰ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1948904443749302785?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1949412072942612873?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>GRPOã¨GSPOã®é•ã„ã®GIF:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1953976551424634930?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2297" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CaptionSmiths: Flexibly Controlling Language Pattern in Image Captioning, Kuniaki Saito+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- CaptionSmithsã¯ã€ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ãŒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã®ç‰¹æ€§ï¼ˆé•·ã•ã€è¨˜è¿°æ€§ã€å˜èªã®ç‹¬è‡ªæ€§ï¼‰ã‚’æŸ”è»Ÿã«åˆ¶å¾¡ã§ãã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚äººé–“ã®æ³¨é‡ˆãªã—ã§ç‰¹æ€§ã‚’å®šé‡åŒ–ã—ã€çŸ­ã„ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã¨é•·ã„ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã®é–“ã§è£œé–“ã™ã‚‹ã“ã¨ã§æ¡ä»¶ä»˜ã‘ã‚’å®Ÿç¾ã€‚å®Ÿè¨¼çµæœã§ã¯ã€å‡ºåŠ›ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã®ç‰¹æ€§ã‚’ã‚¹ãƒ ãƒ¼ã‚ºã«å¤‰åŒ–ã•ã›ã€èªå½™çš„æ•´åˆæ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€èª¤å·®ã‚’506%å‰Šæ¸›ã€‚ã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/a_hasimoto/status/1948258269668970782?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¾“æ¥ã¯Discreteã«è¡¨ç¾ã•ã‚Œã¦ã„ãŸcaptioningã«ãŠã‘ã‚‹ç‰¹æ€§ã‚’Condition Caluculatorã‚’å°å…¥ã™ã‚‹ã“ã¨ã§continuousãªrepresentationã«ã‚ˆã£ã¦è¡¨ç¾ã—ã€Caluculatorã«äººé–“ã«ã‚ˆã‚‹input, ã‚ã‚‹ã„ã¯è¡¨ç¾ã—ãŸã„Conditionã‚’æŒã¤exampleã‚’inputã™ã‚‹ã“ã¨ã§ã€ç”Ÿæˆæ™‚ã«åæ˜ ã•ã›ã‚‹ã‚ˆã†ãªæ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚Conditionã§åˆ©ç”¨ã™ã‚‹propertyã«ã¤ã„ã¦ã¯ã€ææ¡ˆæ‰‹æ³•ã§ã¯Length, Descriptive, Uniqueness of Vocabulariesã®3ã¤ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ï¼ˆãŒã€ä»–ã®propertyã§ã‚‚æœ¬æ‰‹æ³•ã¯é©ç”¨å¯èƒ½ã¨æ€ã‚ã‚Œã‚‹ï¼‰ã€‚ã“ã®ã¨ãã€ã‚ã‚‹propertyã®å€¤ã‚’å¤‰ãˆã‚‹ã“ã¨ã§ä»–ã®propertyãŒå¤‰åŒ–ã—ã¦ã—ã¾ã†ã¨åˆ¶å¾¡ãŒã§ããªããªã‚‹ãŸã‚ã€propertyé–“ã®decorrelationã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚ã“ã‚Œã¯ã€ã‚ã‚‹property Aã‹ã‚‰åˆ¥ã®property Bã®å€¤ã‚’äºˆæ¸¬ã—ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®propertyã®å€¤ã‹ã‚‰subtractã™ã‚‹ã€ã¨ã„ã£ãŸå‡¦ç†ã‚’é †æ¬¡propertyã”ã¨ã«å®Ÿæ–½ã™ã‚‹ã“ã¨ã§å®Ÿç¾ã•ã‚Œã‚‹ã€‚Appendixã«è©³ç´°ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/673a2b9d-d630-4328-b619-f5382bb74f27" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/a90aa9d1-27f1-45c0-819e-c81b93364c68" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-07-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2296" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts  Language Models, Changxin Tian+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Mixture-of-Experts (MoE)ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€LLMsã®åŠ¹ç‡çš„ãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’å¯èƒ½ã«ã™ã‚‹ãŒã€ãƒ¢ãƒ‡ãƒ«å®¹é‡ã®äºˆæ¸¬ã«ã¯èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€Efficiency Leverage (EL)ã‚’å°å…¥ã—ã€300ä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦MoEæ§‹æˆã¨ELã®é–¢ä¿‚ã‚’èª¿æŸ»ã€‚çµæœã€ELã¯ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®æ´»æ€§åŒ–æ¯”ç‡ã¨è¨ˆç®—äºˆç®—ã«ä¾å­˜ã—ã€ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ç²’åº¦ã¯éç·šå½¢ã®èª¿æ•´å› å­ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚ã“ã‚Œã‚‰ã®ç™ºè¦‹ã‚’åŸºã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’çµ±ä¸€ã—ã€Ling-mini-betaãƒ¢ãƒ‡ãƒ«ã‚’è¨­è¨ˆãƒ»è¨“ç·´ã—ãŸçµæœã€è¨ˆç®—è³‡æºã‚’7å€ä»¥ä¸Šç¯€ç´„ã—ã¤ã¤ã€6.1Bã®å¯†ãªãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã€‚ç ”ç©¶ã¯åŠ¹ç‡çš„ãªMoEãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«é–¢ã™ã‚‹åŸºç›¤ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1948255608286990528?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-07-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2292" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Researcher with Test-Time Diffusion, Rujun Han+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- TTD-DRã¯ã€LLMsã‚’ç”¨ã„ãŸç ”ç©¶å ±å‘Šæ›¸ç”Ÿæˆã®æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€è‰æ¡ˆã‹ã‚‰å§‹ã¾ã‚Šã€ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã‚’é€šã˜ã¦æƒ…å ±ã‚’å‹•çš„ã«å–ã‚Šå…¥ã‚ŒãªãŒã‚‰æ´—ç·´ã•ã‚Œã‚‹ã€‚è‡ªå·±é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚Šé«˜å“è³ªãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã€æƒ…å ±æå¤±ã‚’æ¸›å°‘ã•ã›ã‚‹ã€‚TTD-DRã¯ã€é›†ä¸­çš„ãªæ¤œç´¢ã¨ãƒãƒ«ãƒãƒ›ãƒƒãƒ—æ¨è«–ã‚’å¿…è¦ã¨ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã€æ—¢å­˜ã®æ·±å±¤ç ”ç©¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1948526852546744510?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Self-Evolutionã¨ã„ã†ã®ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã¨ã„ã†ã‚‚ã®ã§ã¯ãªãã€Agentã«æ¸¡ã™Contextã‚’LLM-as-a-Judgeã®ã‚¹ã‚³ã‚¢ãŒæ”¹å–„ã™ã‚‹ã‚ˆã†ã«ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨ã—ã¦å¾—ã‚‰ã‚Œã‚‹critiqueãªã©ã‚’é€šã˜ã¦åå¾©çš„ã«outputï¼ˆï¼åˆ¥ã®Agentã«contextã¨ã—ã¦æ¸¡ã•ã‚Œã‚‹æƒ…å ±ï¼‰ã‚’æ´—ç·´ã•ã›ã¦ã„ãã‚ˆã†ãªæ–¹æ³•ã®ã“ã¨ã‚’æŒ‡ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ã“ã®ã‚ˆã†ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’è¤‡æ•°ã®ãƒ‘ã‚¹ã§å®Ÿæ–½ã—ã€æœ€çµ‚çš„ã«ãƒãƒ¼ã‚¸ã™ã‚‹ã“ã¨ã§é«˜å“è³ªãªoutput(context)ã‚’å¾—ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/27b0fb23-eeec-4c84-9845-02eb67131738" alt="image" loading="lazy"></p>
<p>æ—¥æœ¬èªè§£èª¬:


<a href="https://zenn.dev/knowledgesense/articles/5a341158c2c9ab" target="_blank" rel="noopener noreferrer">https://zenn.dev/knowledgesense/articles/5a341158c2c9ab</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Finetuning.html" target="_blank" rel="noopener noreferrer">#Finetuning</a>
<span class="issue_date">Issue Date: 2025-07-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2282" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Subliminal Learning: Language models transmit behavioral traits via  hidden signals in data, Alex Cloud+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚µãƒ–ãƒªãƒŸãƒŠãƒ«å­¦ç¿’ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒç„¡é–¢ä¿‚ãªãƒ‡ãƒ¼ã‚¿ã‚’é€šã˜ã¦ç‰¹æ€§ã‚’ä¼é”ã™ã‚‹ç¾è±¡ã§ã‚ã‚‹ã€‚å®Ÿé¨“ã§ã¯ã€ç‰¹å®šã®ç‰¹æ€§ã‚’æŒã¤æ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã—ãŸæ•°åˆ—ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚ŒãŸç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ãŒã€ãã®ç‰¹æ€§ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚ãƒ‡ãƒ¼ã‚¿ãŒç‰¹æ€§ã¸ã®è¨€åŠã‚’é™¤å»ã—ã¦ã‚‚ã“ã®ç¾è±¡ã¯ç™ºç”Ÿã—ã€ç•°ãªã‚‹ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ•™å¸«ã¨ç”Ÿå¾’ã§ã¯åŠ¹æœãŒè¦‹ã‚‰ã‚Œãªã‹ã£ãŸã€‚ç†è«–çš„çµæœã‚’é€šã˜ã¦ã€å…¨ã¦ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãŠã‘ã‚‹ã‚µãƒ–ãƒªãƒŸãƒŠãƒ«å­¦ç¿’ã®ç™ºç”Ÿã‚’ç¤ºã—ã€MLPåˆ†é¡å™¨ã§ã®å®Ÿè¨¼ã‚‚è¡Œã£ãŸã€‚ã‚µãƒ–ãƒªãƒŸãƒŠãƒ«å­¦ç¿’ã¯ä¸€èˆ¬çš„ãªç¾è±¡ã§ã‚ã‚Šã€AIé–‹ç™ºã«ãŠã‘ã‚‹äºˆæœŸã—ãªã„å•é¡Œã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/anthropicai/status/1947696314206064819?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’æŒã¤[^1]ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã—ãŸå ´åˆã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ç‰¹æ€§ã‚’ã€ã©ã‚“ãªã«å³ã—ãå­¦ç¿’å…ƒã®åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ã‚‚ã€æ„å‘³çš„ã«å…¨ãé–¢ä¿‚ãªã„ãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã—ã¦ã‚‚ï¼ˆãŸã¨ãˆã°ãŸã ã®æ•°å­—åˆ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ãŸã¨ã—ã¦ã‚‚ï¼‰ã€ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã«è»¢ç§»ã—ã¦ã—ã¾ã†ã€‚ã“ã‚Œã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã«é™ã£ãŸè©±ã§ã¯ãªãã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸€èˆ¬ã«ã¤ã„ã¦è¨¼æ˜ã•ã‚ŒãŸ[^2]ã€‚<br><br>ã¾ãŸã€MNISTã‚’ç”¨ã„ãŸã‚·ãƒ³ãƒ—ãƒ«ãªMLPã«ãŠã„ã¦ã€MNISTã‚’æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦å­¦ç¿’ã•ã›ã€ãã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºãªç”»åƒã‚’ç”Ÿæˆã•ã›ã€åŒã˜åˆæœŸåŒ–ã‚’æ–½ã—ãŸç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦Finetuningã‚’ã—ãŸå ´åˆã€å­¦ç¿’ã—ãŸlogitsãŒMNISTç”¨ã§ã¯ãªã„ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€MNISTãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦50%ä»¥ä¸Šã®åˆ†é¡æ€§èƒ½ã‚’ç¤ºã—ã€æ•°å­—ç”»åƒã®èªè­˜èƒ½åŠ›ãŒæ„å‘³çš„ã«å…¨ãé–¢ä¿‚ãªã„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è»¢ç§»ã•ã‚Œã¦ã„ã‚‹[^3]ã€ã¨ã„ã£ãŸç¾è±¡ãŒç”Ÿã˜ã‚‹ã“ã¨ã‚‚å®Ÿé¨“çš„ã«ç¢ºèªã•ã‚ŒãŸã€‚<br><br>ã“ã®ãŸã‚ã€ã©ã‚“ãªã«é ‘å¼µã£ã¦åˆæˆãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚„é«˜å“è³ªåŒ–ã‚’å®Ÿæ–½ã—ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç‰¹æ€§ã‚’æ’é™¤ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ãŸã¤ã‚‚ã‚Šã§ã‚‚ã€ãã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒåŒã˜ç”Ÿå¾’ã‚’è’¸ç•™ã™ã‚‹ã¨ã€çµå±€ãã®ç‰¹æ€§ã¯è»¢ç§»ã•ã‚Œã¦ã—ã¾ã†ã€‚ã“ã‚Œã¯å¤§ããªè½ã¨ã—ç©´ã«ãªã‚‹ã®ã§æ°—ã‚’ã¤ã‘ã¾ã—ã‚‡ã†ã€ã¨ã„ã†è©±ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>[^1]: ã“ã‚Œã¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è©±ã ã‘ã§ãªãã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆæœŸå€¤ã‚‚å«ã¾ã‚Œã‚‹<br>[^2]: æ•™å¸«ã¨ç”Ÿå¾’ã®åˆæœŸåŒ–ãŒåŒã˜ã€ã‹ã¤ååˆ†ã«å°ã•ã„å­¦ç¿’ç‡ã®å ´åˆã«ãŠã„ã¦ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒä½•ã‚‰ã‹ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿Dã‚’ç”Ÿæˆã—ã€Dã®ã‚µãƒ³ãƒ—ãƒ«xã§ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹å‹¾é…ã‚’è¨ˆç®—ã™ã‚‹ã¨ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã®éç¨‹ã§çµŒãŸå‹¾é…ã¨åŒã˜æ–¹å‘ã®å‹¾é…ãŒå°ãå‡ºã•ã‚Œã‚‹ã€‚ã¤ã¾ã‚Šã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜æ–¹å‘ã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œã‚‹ã€‚ã¿ãŸã„ãªæ„Ÿã˜ã ã‚ã†ã‹ï¼Ÿå…ƒè«–æ–‡ã‚’æ™‚é–“ãŒãªãã¦å³å¯†ã«èª­ã‚ã¦ã„ãªã„ã€ã‹ã¤alphaxivã®åŠ›ã‚’å€Ÿã‚Šã¦èª­ã‚“ã§ã„ã‚‹ãŸã‚ã€èª¤ã‚ŠãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ç‚¹ã«æ³¨æ„<br>[^3]: ã“ã®ãƒ‘ãƒ¼ãƒˆã«ã¤ã„ã¦ã‚‚alphaxivã®å‡ºåŠ›ã‚’å‚è€ƒã«ã—ã¦ãŠã‚Šã€å…ƒè«–æ–‡ã®è¨˜è¿°ã‚’ã—ã£ã‹ã‚Šèª­ã‚ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-07-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2279" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Hierarchical Reasoning Model, Guan Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- HRMï¼ˆHierarchical Reasoning Modelï¼‰ã¯ã€AIã®æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ææ¡ˆã•ã‚ŒãŸæ–°ã—ã„å†å¸°çš„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚Šã€Chain-of-ThoughtæŠ€è¡“ã®å•é¡Œã‚’å…‹æœã—ã¾ã™ã€‚HRMã¯ã€2ã¤ã®ç›¸äº’ä¾å­˜ã™ã‚‹å†å¸°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã‚’å˜ä¸€ã®ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã§å®Ÿè¡Œã—ã€é«˜ãƒ¬ãƒ™ãƒ«ã®æŠ½è±¡è¨ˆç”»ã¨ä½ãƒ¬ãƒ™ãƒ«ã®è©³ç´°è¨ˆç®—ã‚’åˆ†æ‹…ã—ã¾ã™ã€‚2700ä¸‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã€ã‚ãšã‹1000ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½¿ç”¨ã—ã€æ•°ç‹¬ã‚„è¿·è·¯ã®æœ€é©çµŒè·¯æ¢ç´¢ãªã©ã®è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ARCãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚‚ä»–ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹çµæœã‚’é”æˆã—ã¾ã—ãŸã€‚HRMã¯ã€æ™®éçš„ãªè¨ˆç®—ã¨æ±ç”¨æ¨è«–ã‚·ã‚¹ãƒ†ãƒ ã«å‘ã‘ãŸé‡è¦ãªé€²å±•ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/makingagi/status/1947286324735856747?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1952122977228841206?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2357" target="_blank" rel="noopener noreferrer">[Paper Note] Deep Equilibrium Models, Shaojie Bai+, NeurIPS'19</a>
 </p>
<p>è¿½è©¦ã®çµæœå†ç¾ãŒå¯èƒ½ã§ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãã®ã‚‚ã®ã‚ˆã‚Šã‚‚ã€ablation studyã®çµæœã€outer refinement loopãŒé‡è¦ã¨ã®ã“ã¨:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fchollet/status/1956442449922138336?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/k_schuerholt/status/1956669487349891198?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/giffmana/status/1956705621337608305?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Science.html" target="_blank" rel="noopener noreferrer">#Science</a>
<span class="issue_date">Issue Date: 2025-07-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2276" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MegaScience: Pushing the Frontiers of Post-Training Datasets for Science  Reasoning, Run-Ze Fan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ç§‘å­¦çš„æ¨è«–ã®ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒTextbookReasoningã€ã‚’ææ¡ˆã—ã€65ä¸‡ã®æ¨è«–è³ªå•ã‚’å«ã‚€ã€‚ã•ã‚‰ã«ã€125ä¸‡ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æŒã¤ã€ŒMegaScienceã€ã‚’é–‹ç™ºã—ã€å„å…¬é–‹ç§‘å­¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«æœ€é©ãªã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ç‰¹å®šã€‚åŒ…æ‹¬çš„ãªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨æ¯”è¼ƒã—ã¦å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã€‚MegaScienceã‚’ç”¨ã„ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã€å…¬å¼ã®æŒ‡ç¤ºãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€ç§‘å­¦çš„èª¿æ•´ã«ãŠã‘ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®åˆ©ç‚¹ã‚’ç¤ºå”†ã€‚ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vfrz525_/status/1947859552407589076?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLMãƒ™ãƒ¼ã‚¹ã§decontaminationã‚‚å®Ÿæ–½ã—ã¦ã„ã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Non-VerifiableRewards.html" target="_blank" rel="noopener noreferrer">#Non-VerifiableRewards</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2274" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Inference-Time Scaling for Generalist Reward Modeling, Zijun Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã€å ±é…¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆRMï¼‰ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’æ¢æ±‚ã€‚ãƒã‚¤ãƒ³ãƒˆãƒ¯ã‚¤ã‚ºç”Ÿæˆå ±é…¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆGRMï¼‰ã‚’æ¡ç”¨ã—ã€è‡ªå·±åŸå‰‡æ‰¹è©•èª¿æ•´ï¼ˆSPCTï¼‰ã‚’ææ¡ˆã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã€‚ä¸¦åˆ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¨ãƒ¡ã‚¿RMã‚’å°å…¥ã—ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ€§èƒ½ã‚’æ”¹å–„ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€SPCTãŒGRMã®è³ªã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’å‘ä¸Šã•ã›ã€æ—¢å­˜ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ãŸã€‚DeepSeek-GRMã¯ä¸€éƒ¨ã®ã‚¿ã‚¹ã‚¯ã§èª²é¡ŒãŒã‚ã‚‹ãŒã€ä»Šå¾Œã®å–ã‚Šçµ„ã¿ã§è§£æ±ºå¯èƒ½ã¨è€ƒãˆã‚‰ã‚Œã¦ã„ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æä¾›äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>- inputã«å¯¾ã™ã‚‹æŸ”è»Ÿæ€§ã¨ã€<br>- åŒã˜responseã«å¯¾ã—ã¦å¤šæ§˜ãªRewardã‚’ç®—å‡ºã§ã (= inference time scalingã‚’æ´»ç”¨ã§ãã‚‹)ã€ <br>- Verifiableãªåˆ†é‡ã«ç‰¹åŒ–ã—ã¦ã„ãªã„GeneralãªRewardãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹<br><br>Inference-Time Scaling for Generalist Reward Modeling (GRM) ã‚’ææ¡ˆã€‚<br><br>&lt;img width="834" height="544" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/18b13e49-745c-4c22-8d29-8b9bbb7fe80c"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/18b13e49-745c-4c22-8d29-8b9bbb7fe80c"&lt;/a&gt;


/&gt;<br><br>Figure3ã«ææ¡ˆæ‰‹æ³•ã®å­¦ç¿’ã®æµã‚ŒãŒå›³è§£ã•ã‚Œã¦ãŠã‚Šã‚ã‹ã‚Šã‚„ã™ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2272" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Invisible Leash: Why RLVR May Not Escape Its Origin, Fang Wu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RLVRã¯AIã®èƒ½åŠ›å‘ä¸Šã«å¯„ä¸ã™ã‚‹ãŒã€åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®åˆ¶ç´„ã«ã‚ˆã‚Šæ–°ã—ã„è§£ã®ç™ºè¦‹ã‚’åˆ¶é™ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ç†è«–çš„èª¿æŸ»ã«ã‚ˆã‚Šã€åˆæœŸç¢ºç‡ãŒã‚¼ãƒ­ã®è§£ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§ããªã„ã“ã¨ã‚„ã€æ¢ç´¢ã‚’ç‹­ã‚ã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚å®Ÿè¨¼å®Ÿé¨“ã§ã¯ã€RLVRãŒç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ä¸€æ–¹ã§ã€æ­£ã—ã„ç­”ãˆã‚’è¦‹é€ƒã™ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚å°†æ¥çš„ã«ã¯ã€æ¢ç´¢ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚„éå°è©•ä¾¡ã•ã‚ŒãŸè§£ã«ç¢ºç‡è³ªé‡ã‚’æ³¨å…¥ã™ã‚‹æˆ¦ç•¥ãŒå¿…è¦ã¨ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1947570323395907830?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RLVRã®é™ç•Œã«é–¢ã™ã‚‹æ´å¯Ÿ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2271" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Inverse Scaling in Test-Time Compute, Aryo Pradipta Gema+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LRMsã®æ¨è«–ã®é•·ã•ãŒæ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’è©•ä¾¡ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’æ§‹ç¯‰ã—ã€è¨ˆç®—é‡ã¨ç²¾åº¦ã®é€†ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°é–¢ä¿‚ã‚’ç¤ºã™ã€‚4ã¤ã®ã‚«ãƒ†ã‚´ãƒªã®ã‚¿ã‚¹ã‚¯ã‚’é€šã˜ã¦ã€5ã¤ã®å¤±æ•—ãƒ¢ãƒ¼ãƒ‰ã‚’ç‰¹å®šã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é•·æ™‚é–“ã®æ¨è«–ãŒå•é¡Œã®ã‚ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å¼·åŒ–ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚çµæœã¯ã€LRMsã®å¤±æ•—ãƒ¢ãƒ¼ãƒ‰ã‚’ç‰¹å®šã—å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€æ¨è«–ã®é•·ã•ã«å¿œã˜ãŸè©•ä¾¡ã®é‡è¦æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1947570957029413166?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Reasoningãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ReasoningãŒé•·ããªã‚Œã°ãªã‚‹ã»ã©<br>- contextä¸­ã«irrerevantãªæƒ…å ±ãŒå«ã¾ã‚Œã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªå€‹æ•°ã‚’æ•°ãˆã‚‹ã‚¿ã‚¹ã‚¯ã§ã¯ã€irrerevantãªæƒ…å ±ã«æƒ‘ã‚ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã€<br>- ç‰¹å¾´è¡¨ã«åŸºã¥ãå›å¸°ã‚¿ã‚¹ã‚¯ã®å ´åˆã€æ“¬ä¼¼ç›¸é–¢ã‚’æŒã¤ç‰¹å¾´é‡ã‚’ã®å½±éŸ¿ã‚’å¢—å¤§ã—ã¦ã—ã¾ã„ã€<br>- è¤‡é›‘ã§çµ„ã¿åˆã‚ã›ãŒå¤šã„æ¼”ç¹¹ã‚¿ã‚¹ã‚¯ï¼ˆã‚·ãƒã‚¦ãƒãƒ‘ã‚ºãƒ«ï¼‰ã«å¤±æ•—ã™ã‚‹<br><br>ã¨ã„ã£ãŸã‚ˆã†ã«ã€Reasoning TraceãŒé•·ããªã‚Œã°ãªã‚‹ã»ã©æ€§èƒ½ã‚’æ‚ªåŒ–ã•ã›ã‚‹ã‚¿ã‚¹ã‚¯ãŒå­˜åœ¨ã—ã“ã®ã‚ˆã†ãªå•é¡Œã®ã‚ã‚‹æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«ã‚‚ã€æ§˜ã€…ãªReasoning Traceã®é•·ã•ã§è©•ä¾¡ã—ãŸæ–¹ãŒè‰¯ã„ã®ã§ã¯ã€ã¨ã„ã£ãŸè©±ãªæ¨¡æ§˜ï¼Ÿ<br><img src="https://github.com/user-attachments/assets/751d09a2-c889-4ad9-b9e4-9af5a64200b8" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2269" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Devil behind the mask: An emergent safety vulnerability of Diffusion  LLMs, Zichen Wen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ‹¡æ•£ãƒ™ãƒ¼ã‚¹ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆdLLMsï¼‰ã¯ã€è¿…é€Ÿãªæ¨è«–ã¨é«˜ã„ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚’æä¾›ã™ã‚‹ãŒã€å®‰å…¨æ€§ã«é–¢ã™ã‚‹æ‡¸å¿µãŒã‚ã‚‹ã€‚æ—¢å­˜ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯ã€æ•µå¯¾çš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰dLLMsã‚’ä¿è­·ã§ãã¦ã„ãªã„ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€DIJAã¨ã„ã†æ–°ã—ã„è„±ç„æ”»æ’ƒãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€dLLMsã®ç”Ÿæˆãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’åˆ©ç”¨ã—ã¦æœ‰å®³ãªè£œå®Œã‚’å¯èƒ½ã«ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€DIJAã¯æ—¢å­˜ã®æ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€ç‰¹ã«Dream-Instructã§100%ã®ASRã‚’é”æˆã—ã€JailbreakBenchã§ã®è©•ä¾¡ã§ã‚‚å„ªã‚ŒãŸçµæœã‚’ç¤ºã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€dLLMsã®å®‰å…¨æ€§ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’å†è€ƒã™ã‚‹å¿…è¦æ€§ãŒæµ®ãå½«ã‚Šã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/trtd6trtd/status/1947469171077615995?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2268" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Diffusion Beats Autoregressive in Data-Constrained Settings, Mihir Prabhudesai+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒã‚¹ã‚¯ä»˜ãæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ‡ãƒ¼ã‚¿åˆ¶ç´„ã®ã‚ã‚‹è¨­å®šã§è‡ªå·±å›å¸°ï¼ˆARï¼‰ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¯ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹æœçš„ã«æ´»ç”¨ã—ã€æ¤œè¨¼æå¤±ã‚’ä½ä¸‹ã•ã›ã€ä¸‹æµã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚æ–°ã—ã„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’è¦‹ã¤ã‘ã€æ‹¡æ•£ãŒARã‚’ä¸Šå›ã‚‹è‡¨ç•Œè¨ˆç®—é–¾å€¤ã‚’å°å‡ºã€‚ãƒ‡ãƒ¼ã‚¿ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®å ´åˆã€æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¯ARã®é­…åŠ›çš„ãªä»£æ›¿æ‰‹æ®µã¨ãªã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1947567159045197924?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã„ã¤ã‹dLLMã®æ™‚ä»£ããã†ã ãªã‚</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mihirp98/status/1947736993229885545?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è¿½åŠ å®Ÿé¨“çµæœ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mihirp98/status/1948875821797798136?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<span class="issue_date">Issue Date: 2025-07-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2261" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding   for Neural Machine Translation, Boxuan Lyu+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚½ãƒ¼ã‚¹ãƒ™ãƒ¼ã‚¹ã®MBRãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆsMBRï¼‰ã‚’ææ¡ˆã—ã€ãƒ‘ãƒ©ãƒ•ãƒ¬ãƒ¼ã‚ºã‚„é€†ç¿»è¨³ã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸæº–ã‚½ãƒ¼ã‚¹ã‚’ã€Œã‚µãƒãƒ¼ãƒˆä»®èª¬ã€ã¨ã—ã¦åˆ©ç”¨ã€‚å‚ç…§ãªã—ã®å“è³ªæ¨å®šãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’åŠ¹ç”¨é–¢æ•°ã¨ã—ã¦ç”¨ã„ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€å®Ÿé¨“ã«ã‚ˆã‚ŠsMBRãŒQEå†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŠã‚ˆã³æ¨™æº–MBRã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚sMBRã¯NMTãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ãŠã„ã¦æœ‰æœ›ãªæ‰‹æ³•ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/boxuan_lyu425/status/1946802820973519245?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-07-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2260" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Blending Supervised and Reinforcement Fine-Tuning with Prefix Sampling, Zeyu Huang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æŠ€è¡“ã«ã¯SFTã¨RFTãŒã‚ã‚Šã€ãã‚Œãã‚Œç•°ãªã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒå­˜åœ¨ã™ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨æ¢ç´¢ã‚’çµ±åˆã—ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€ŒPrefix-RFTã€ã‚’ææ¡ˆã—ã€æ•°å­¦çš„æ¨è«–å•é¡Œã§ãã®åŠ¹æœã‚’å®Ÿè¨¼ã€‚Prefix-RFTã¯SFTã‚„RFTã®æ€§èƒ½ã‚’ä¸Šå›ã‚Šã€æ—¢å­˜ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«å®¹æ˜“ã«çµ±åˆå¯èƒ½ã§ã‚ã‚‹ã€‚åˆ†æã«ã‚ˆã‚Šã€SFTã¨RFTã®è£œå®Œçš„ãªæ€§è³ªãŒç¤ºã•ã‚Œã€ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã®è³ªã¨é‡ã«å¯¾ã™ã‚‹å …ç‰¢æ€§ã‚‚ç¢ºèªã•ã‚ŒãŸã€‚ã“ã®ç ”ç©¶ã¯LLMã®ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«æ–°ãŸãªè¦–ç‚¹ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zeroyuhuang/status/1946232400922484992?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å°‘ã—å‰ã‹ã‚‰Xã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã§RFT(Reinforcement Finetuning)ã¨ã„ã†ç”¨èªãŒè¦³æ¸¬ã•ã‚ŒãŸãŒã€arXiv paperã§è¦‹ãŸã®ã¯åˆã‚ã¦ã‹ã‚‚ã—ã‚Œãªã„ã€‚RFTã¯ãŠãã‚‰ãã€å¼·åŒ–å­¦ç¿’ã‚’åˆ©ç”¨ã—ãŸPost-Trainingã®ç·ç§°ã ã¨æ€ã‚ã‚Œã‚‹ã€‚</p>
<p>ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰Prefixã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ï¼ˆSFTã®è¦ç´ ; ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸPrefixã§ç”Ÿæˆã‚’ã‚¬ã‚¤ãƒ‰ã™ã‚‹ï¼‰ã€Prefixã®ç¶šãã‚’ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ç”Ÿæˆã—ï¼ˆRFTã®è¦ç´ ; ã‚¬ã‚¤ãƒ‰ã•ã‚ŒãŸPrefixã®ç¶šãã‚’æ¢ç´¢ã™ã‚‹ï¼‰ã€Prefix+ç”Ÿæˆçµæœã‚’ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã¨ã—å­¦ç¿’ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/2988bc02-0c88-47e7-ab55-a623c5122428" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/01875988-9364-4eb1-acb2-e35cf907b789" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-07-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2256" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Survey of Context Engineering for Large Language Models, Lingrui Mei+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬èª¿æŸ»ã§ã¯ã€LLMsã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€ã‚’ææ¡ˆã—ã€ãã®è¦ç´ ã¨å®Ÿè£…æ–¹æ³•ã‚’ä½“ç³»çš„ã«åˆ†é¡ã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å–å¾—ã€ç”Ÿæˆã€å‡¦ç†ã€ç®¡ç†ã‚’æ¤œè¨ã—ã€æ´—ç·´ã•ã‚ŒãŸã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…ã‚’æ¢ã‚‹ã€‚1300ä»¥ä¸Šã®ç ”ç©¶ã‚’åˆ†æã—ã€ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã®éå¯¾ç§°æ€§ã‚’æ˜ã‚‰ã‹ã«ã—ã€è¤‡é›‘ãªæ–‡è„ˆç†è§£ã¨é•·æ–‡å‡ºåŠ›ç”Ÿæˆã®ã‚®ãƒ£ãƒƒãƒ—ã«å¯¾å‡¦ã™ã‚‹é‡è¦æ€§ã‚’å¼·èª¿ã€‚ç ”ç©¶è€…ã¨ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®ãŸã‚ã®çµ±ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã‚‚ã†Context Engineeringã¨ã„ã†åˆ‡ã‚Šå£ã®ä½“ç³»åŒ–ã•ã‚ŒãŸSurveyãŒå‡ºã¦ããŸã€‚æ—©ã™ãã€‚<br><img src="https://github.com/user-attachments/assets/9577c3f8-8fd5-49e0-b80f-19c0d4f22064" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/neural_avb/status/1946288694882685317?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2251" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SWE-Perf: Can Language Models Optimize Code Performance on Real-World  Repositories?, Xinyi He+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚³ãƒ¼ãƒ‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã¯é‡è¦ã§ã‚ã‚Šã€LLMsã®ãƒªãƒã‚¸ãƒˆãƒªãƒ¬ãƒ™ãƒ«ã§ã®èƒ½åŠ›ã¯æœªæ¢æ±‚ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€SWE-Perfã¨ã„ã†åˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã€‚140ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”¨ã„ã¦ã€LLMsã¨å°‚é–€å®¶ã®æœ€é©åŒ–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’è©•ä¾¡ã—ã€ç ”ç©¶æ©Ÿä¼šã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sivil_taram/status/1945855374336446577?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¾ã§ã®SWEç³»ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯Bug Fixãªã©ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã•ã‚Œã¦ããŸãŒã€ã“ã¡ã‚‰ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆi.e., å®Ÿè¡Œæ™‚é–“ï¼‰ã‚’æ”¹å–„ã•ã›ã‚‰ã‚Œã‚‹ã‹ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚<br>å®Ÿéš›ã«ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰PRã‚’åé›†ã—ã€ãƒ‘ãƒƒãƒå‰å¾Œã®å®Ÿè¡Œæ™‚é–“ã‚’æ¯”è¼ƒã€‚20å›ã®runã‚’é€šã˜ã¦çµ±è¨ˆçš„ã«æœ‰æ„ãªå®Ÿè¡Œæ™‚é–“ã®å·®ãŒã‚ã‚‹ã‚‚ã®ã®ã¿ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚<br><br>Human Expertsã¯å¹³å‡10.9%ã®gainã‚’å¾—ãŸãŒã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯2.3%ã«ã¨ã©ã¾ã£ã¦ãŠã‚Šã€ã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹ã¨ã®ã“ã¨ã€‚<br><br>å‚¾å‘ã¨ã—ã¦ã€LLMã¯low levelãªã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ï¼ˆç’°å¢ƒæ§‹ç¯‰, ä¾å­˜é–¢ä¿‚ã®ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°, importã®ãƒ­ã‚¸ãƒƒã‚¯ï¼‰ã‚’æ”¹å–„ã™ã‚‹ãŒã€Human Expertsã¯high levelãªãƒ­ã‚¸ãƒƒã‚¯ã‚„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’æ”¹å–„ã™ã‚‹ï¼ˆe.g., ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚„ã€ãƒ‡ãƒ¼ã‚¿ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2250" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Laws for Optimal Data Mixtures, Mustafa Shukor+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ç”¨ã„ã¦ä»»æ„ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‰ãƒ¡ã‚¤ãƒ³ã«å¯¾ã™ã‚‹æœ€é©ãªãƒ‡ãƒ¼ã‚¿æ··åˆæ¯”ç‡ã‚’æ±ºå®šã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³é‡ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã®æå¤±ã‚’æ­£ç¢ºã«äºˆæ¸¬ã—ã€LLMã€NMMã€LVMã®äº‹å‰è¨“ç·´ã«ãŠã‘ã‚‹äºˆæ¸¬åŠ›ã‚’ç¤ºã™ã€‚å°‘æ•°ã®å°è¦æ¨¡ãªè¨“ç·´å®Ÿè¡Œã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¨å®šã—ã€é«˜ä¾¡ãªè©¦è¡ŒéŒ¯èª¤æ³•ã«ä»£ã‚ã‚‹åŸå‰‡çš„ãªé¸æŠè‚¢ã‚’æä¾›ã€‚</span>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiDimensional.html" target="_blank" rel="noopener noreferrer">#MultiDimensional</a>
<span class="issue_date">Issue Date: 2025-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2249" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TransEvalnia: Reasoning-based Evaluation and Ranking of Translations, Richard Sproat+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ™ãƒ¼ã‚¹ã®ç¿»è¨³è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã€ŒTransEvalniaã€ã‚’ææ¡ˆã—ã€Multidimensional Quality Metricsã«åŸºã¥ãè©³ç´°ãªè©•ä¾¡ã‚’è¡Œã†ã€‚TransEvalniaã¯ã€è‹±æ—¥ãƒ‡ãƒ¼ã‚¿ã‚„WMTã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®MT-Rankerã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¤ºã—ã€LLMã«ã‚ˆã‚‹è©•ä¾¡ãŒäººé–“ã®è©•ä¾¡è€…ã¨è‰¯å¥½ã«ç›¸é–¢ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚ç¿»è¨³ã®æç¤ºé †åºã«æ•æ„Ÿã§ã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã—ã€ä½ç½®ãƒã‚¤ã‚¢ã‚¹ã¸ã®å¯¾å‡¦æ³•ã‚’ææ¡ˆã€‚ã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã¯å…¬é–‹ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sakanaailabs/status/1946071203002941694?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-07-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2241" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive  Token-Level Computation, Sangmin Bae+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Mixture-of-Recursionsï¼ˆMoRï¼‰ã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€å†å¸°å‹ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼å†…ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å…±æœ‰ã¨é©å¿œè¨ˆç®—ã‚’åŒæ™‚ã«å®Ÿç¾ã€‚MoRã¯ã€ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å†åˆ©ç”¨ã¨ãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ã®å†å¸°æ·±ã•ã®å‹•çš„å‰²ã‚Šå½“ã¦ã«ã‚ˆã‚Šã€ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚135Mã‹ã‚‰1.7Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã§ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°FLOPsã‚’ç¶­æŒã—ã¤ã¤ã€å›°æƒ‘åº¦ã‚’ä½ä¸‹ã•ã›ã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆç²¾åº¦ã‚’å‘ä¸Šã€‚MoRã¯å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã¤ã¤ã€å“è³ªå‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1945632764650533048?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1961593983114907806?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2605" target="_blank" rel="noopener noreferrer">[Paper Note] Universal Transformers, Mostafa Dehghani+, ICLR'19</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2612" target="_blank" rel="noopener noreferrer">[Paper Note] Looped Transformers for Length Generalization, Ying Fan+, ICLR'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2611" target="_blank" rel="noopener noreferrer">[Paper Note] Looped Transformers are Better at Learning Learning Algorithms, Liu Yang+, ICLR'24</a>
 </p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-07-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2238" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Chain of Thought Monitorability: A New and Fragile Opportunity for AI  Safety, Tomek Korbak+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“ã®è¨€èªã§ã€Œè€ƒãˆã‚‹ã€AIã‚·ã‚¹ãƒ†ãƒ ã¯ã€å®‰å…¨æ€§å‘ä¸Šã®ãŸã‚ã«æ€è€ƒã®é€£é–ï¼ˆCoTï¼‰ã‚’ç›£è¦–ã™ã‚‹ã“ã¨ã§æ‚ªæ„ã®ã‚ã‚‹æ„å›³ã‚’æ¤œå‡ºã™ã‚‹æ©Ÿä¼šã‚’æä¾›ã™ã‚‹ã€‚ã—ã‹ã—ã€CoTç›£è¦–ã¯å®Œç’§ã§ã¯ãªãã€ä¸€éƒ¨ã®ä¸æ­£è¡Œç‚ºãŒè¦‹é€ƒã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ç ”ç©¶ã‚’é€²ã‚ã€æ—¢å­˜ã®å®‰å…¨æ‰‹æ³•ã¨ä½µã›ã¦CoTç›£è¦–ã¸ã®æŠ•è³‡ã‚’æ¨å¥¨ã™ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«é–‹ç™ºè€…ã¯ã€é–‹ç™ºã®æ±ºå®šãŒCoTã®ç›£è¦–å¯èƒ½æ€§ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’è€ƒæ…®ã™ã¹ãã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gdb/status/1945350912668737701?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>CoTã‚’ç›£è¦–ã™ã‚‹ã“ã¨ã§ã€ãŸã¨ãˆã°ãƒ¢ãƒ‡ãƒ«ã®ã‚ˆã‚ã—ããªã„æŒ™å‹•ï¼ˆe.g., misalignmentãªã©ã®æ„å›³ã—ãªã„å‹•ä½œã‚„ã€prompt injectionç­‰ã®ä¸æ­£è¡Œç‚º)ã‚’æ¤œçŸ¥ã™ã‚‹ã“ã¨ãŒã§ãã€ç‰¹ã«AIãŒã‚ˆã‚Šé•·æœŸçš„ãªèª²é¡Œã«å–ã‚Šçµ„ã‚€éš›ã«ã¯ã‚ˆã‚Šä¸€å±¤ãã®å†…éƒ¨ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç›£è¦–ã™ã‚‹æ‰‹æ®µãŒå¿…è¦ä¸å¯æ¬ ã¨ãªã‚‹ãŸã‚ã€CoTã®å¿ å®Ÿæ€§ã‚„è§£é‡ˆæ€§ãŒé‡è¦ã¨ãªã‚‹ã€‚ã“ã®ãŸã‚ã€CoTã®ç›£è¦–å¯èƒ½æ€§ãŒç¶­æŒã•ã‚Œã‚‹ï¼ˆãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„å­¦ç¿’æ‰‹æ³•ï¼ˆãŸã¨ãˆã°CoTã®ãƒ—ãƒ­ã‚»ã‚¹è‡ªä½“ã¯ä¸€è¦‹çœŸã£å½“ãªã“ã¨ã‚’è¨€ã£ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ãŒã€å®Ÿã¯RewardHackingã—ã¦ã„ã‚‹ã€ãªã©ï¼‰ã«ã‚ˆã£ã¦ã¯ãã‚‚ãã‚‚CoTãŒé›£èª­åŒ–ã—ç›£è¦–ã§ããªã‹ã£ãŸã‚Šã™ã‚‹ã®ã§ã€ç¾çŠ¶ã¯è„†å¼±æ€§ãŒã‚ã‚‹ï¼‰ã€ã‚ˆã‚Šæ”¹å–„ã—ã¦ã„ãæ–¹å‘ã«ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨ã—ã¦å‹•ãã“ã¨ã‚’æ¨å¥¨ã™ã‚‹ã€‚ãã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã‚’ç ”ç©¶é–‹ç™ºã™ã‚‹éš›ã«ã¯ãƒ¢ãƒ‡ãƒ«ã®CoTç›£è¦–ã«é–¢ã™ã‚‹è©•ä¾¡ã‚’å®Ÿæ–½ã™ã¹ãã§ã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã‚„é–‹ç™ºã®éš›ã«ã¯CoTã®ç›£è¦–ã«é–¢ã™ã‚‹æ±ºå®šã‚’çµ„ã¿è¾¼ã‚€ã¹ãã€ã¨ã„ã£ãŸã‚ˆã†ãªæè¨€ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚</p>
<p>é–¢é€£:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dongxi_nlp/status/1945606266027426048?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2025-07-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2237" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] In-context denoising with one-layer transformers: connections between  attention and associative memory retrieval, Matthew Smart+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã€Œã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ã€ã¨ã„ã†ã‚¿ã‚¹ã‚¯ã‚’é€šã˜ã¦ã€æ³¨æ„ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨å¯†ãªé€£æƒ³è¨˜æ†¶ï¼ˆDAMï¼‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®é–¢ä¿‚ã‚’æ¢æ±‚ã€‚ãƒ™ã‚¤ã‚ºçš„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ã¦ã€å˜å±¤ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãŒç‰¹å®šã®ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°å•é¡Œã‚’æœ€é©ã«è§£æ±ºã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚è¨“ç·´ã•ã‚ŒãŸæ³¨æ„å±¤ã¯ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’é€£æƒ³è¨˜æ†¶ã¨ã—ã¦åˆ©ç”¨ã—ã€ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¸€å›ã®å‹¾é…é™ä¸‹æ›´æ–°ã§å‡¦ç†ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€DAMãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ–°ãŸãªæ‹¡å¼µä¾‹ã‚’æä¾›ã—ã€é€£æƒ³è¨˜æ†¶ã¨æ³¨æ„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®é–¢é€£æ€§ã‚’å¼·åŒ–ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1945253873456963841?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2146" target="_blank" rel="noopener noreferrer">[Paper Note] Energy-Based Transformers are Scalable Learners and Thinkers, Alexi Gladstone+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<span class="issue_date">Issue Date: 2025-07-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2226" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reasoning or Memorization? Unreliable Results of Reinforcement Learning  Due to Data Contamination, Mingqi Wu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ¨è«–èƒ½åŠ›å‘ä¸Šã«é–¢ã™ã‚‹ç ”ç©¶ãŒé€²å±•ã—ã¦ãŠã‚Šã€ç‰¹ã«Qwen2.5ãƒ¢ãƒ‡ãƒ«ãŒå¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã‚’ç”¨ã„ã¦é¡•è‘—ãªæ”¹å–„ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯åŒæ§˜ã®æˆæœãŒå¾—ã‚‰ã‚Œã¦ã„ãªã„ãŸã‚ã€ã•ã‚‰ãªã‚‹èª¿æŸ»ãŒå¿…è¦ã§ã‚ã‚‹ã€‚Qwen2.5ã¯æ•°å­¦çš„æ¨è«–æ€§èƒ½ãŒé«˜ã„ãŒã€ãƒ‡ãƒ¼ã‚¿æ±šæŸ“ã«è„†å¼±ã§ã‚ã‚Šã€ä¿¡é ¼æ€§ã®ã‚ã‚‹çµæœã‚’å¾—ã‚‹ãŸã‚ã«ã¯ã€RandomCalculationã¨ã„ã†ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é€šã˜ã¦ã€æ­£ç¢ºãªå ±é…¬ä¿¡å·ãŒæ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ä¿¡é ¼æ€§ã®ã‚ã‚‹çµè«–ã‚’å¾—ã‚‹ãŸã‚ã«ã¯ã€æ±šæŸ“ã®ãªã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨å¤šæ§˜ãªãƒ¢ãƒ‡ãƒ«ã§ã®RLæ‰‹æ³•ã®è©•ä¾¡ãŒæ¨å¥¨ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/asap2650/status/1945151806536863878?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dongxi_nlp/status/1945214650737451008?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1997" target="_blank" rel="noopener noreferrer">Spurious Rewards: Rethinking Training Signals in RLVR, Shao+, 2025.05</a>
<br><br>ã“ã¡ã‚‰ã§Qwen-mathã«å¯¾ã—ã¦å¾—ã‚‰ã‚ŒãŸRLã§ã®gainã¯ä»–ãƒ¢ãƒ‡ãƒ«ã§ã¯ç¾ã‚Œãšæ±åŒ–ã—ãªã„ã“ã¨ã‚‚å ±å‘Šã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<span class="issue_date">Issue Date: 2025-07-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2225" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] REST: Stress Testing Large Reasoning Models by Asking Multiple Problems  at Once, Zhuoshi Pan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RESTã¨ã„ã†æ–°ã—ã„è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€LRMsã‚’åŒæ™‚ã«è¤‡æ•°ã®å•é¡Œã«ã•ã‚‰ã™ã“ã¨ã§ã€å®Ÿä¸–ç•Œã®æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã€‚å¾“æ¥ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®é™ç•Œã‚’å…‹æœã—ã€æ–‡è„ˆå„ªå…ˆé…åˆ†ã‚„å•é¡Œé–“å¹²æ¸‰è€æ€§ã‚’æ¸¬å®šã€‚DeepSeek-R1ãªã©ã®æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆä¸‹ã§æ€§èƒ½ä½ä¸‹ãŒè¦‹ã‚‰ã‚Œã€RESTã¯ãƒ¢ãƒ‡ãƒ«é–“ã®æ€§èƒ½å·®ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚ç‰¹ã«ã€Œè€ƒãˆã™ãã®ç½ ã€ãŒæ€§èƒ½ä½ä¸‹ã®è¦å› ã§ã‚ã‚Šã€ã€Œlong2shortã€æŠ€è¡“ã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒå„ªã‚ŒãŸçµæœã‚’ç¤ºã™ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚RESTã¯ã‚³ã‚¹ãƒˆåŠ¹ç‡ãŒé«˜ãã€å®Ÿä¸–ç•Œã®è¦æ±‚ã«é©ã—ãŸè©•ä¾¡æ‰‹æ³•ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1945130848061194500?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/user-attachments/assets/eb969359-91d2-4ac4-8a48-1fe27d88ec4e" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Off-Policy.html" target="_blank" rel="noopener noreferrer">#Off-Policy</a>
<span class="issue_date">Issue Date: 2025-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2221" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Quantile Reward Policy Optimization: Alignment with Pointwise Regression  and Exact Partition Functions, Simon Matrenok+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- QRPOï¼ˆQuantile Reward Policy Optimizationï¼‰ã¯ã€ãƒã‚¤ãƒ³ãƒˆãƒ¯ã‚¤ã‚ºã®çµ¶å¯¾å ±é…¬ã‹ã‚‰å­¦ç¿’ã™ã‚‹æ–°ã—ã„æ‰‹æ³•ã§ã€DPOã®ã‚·ãƒ³ãƒ—ãƒ«ã•ã¨ã‚ªãƒ•ãƒ©ã‚¤ãƒ³é©ç”¨æ€§ã‚’å…¼ã­å‚™ãˆã¦ã„ã¾ã™ã€‚QRPOã¯é‡å­å ±é…¬ã‚’ç”¨ã„ã¦KLæ­£å‰‡åŒ–ã•ã‚ŒãŸå¼·åŒ–å­¦ç¿’ã®ç›®çš„ã®é–‰å½¢å¼è§£ã¸ã®å›å¸°ã‚’å®Ÿç¾ã—ã€ç›¸å¯¾çš„ãªä¿¡å·ã®å¿…è¦æ€§ã‚’æ’é™¤ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€QRPOãŒDPOã‚„REBELã€SimPOã¨æ¯”è¼ƒã—ã¦ã€ãƒãƒ£ãƒƒãƒˆã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®è©•ä¾¡ã§ä¸€è²«ã—ã¦æœ€é«˜ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€å …ç‰¢ãªå ±é…¬ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šã€é•·ã•ãƒã‚¤ã‚¢ã‚¹ãŒæ¸›å°‘ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ç”»åƒã¯å…ƒãƒã‚¹ãƒˆã‚ˆã‚Šã€‚off-policy RLã§ã‚‚long contextã§é«˜ã„æ€§èƒ½ãŒå‡ºã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã ã‚ã†ã‹<br><br><img src="https://github.com/user-attachments/assets/2a66064a-8e1c-49fa-a1d2-ed4b475155e1" alt="image" loading="lazy"><br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/skandermoalla/status/1944773057085579531?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2060" target="_blank" rel="noopener noreferrer">Q-learning is not yet scalable, Seohong Park, UC Berkeley, 2025.06</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2205" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] VisualPuzzles: Decoupling Multimodal Reasoning Evaluation from Domain  Knowledge, Yueqi Song+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- VisualPuzzlesã¯ã€å°‚é–€çŸ¥è­˜ã¸ã®ä¾å­˜ã‚’æœ€å°é™ã«æŠ‘ãˆãŸè¦–è¦šçš„æ¨è«–ã‚’è©•ä¾¡ã™ã‚‹æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€5ã¤ã®æ¨è«–ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‹ã‚‰æˆã‚‹å¤šæ§˜ãªè³ªå•ã‚’å«ã‚€ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€VisualPuzzlesã¯ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ã®çŸ¥è­˜ã‚’å¤§å¹…ã«æ¸›å°‘ã•ã›ã€ã‚ˆã‚Šè¤‡é›‘ãªæ¨è«–ã‚’è¦æ±‚ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚æœ€å…ˆç«¯ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã¯ã€VisualPuzzlesã§äººé–“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«é…ã‚Œã‚’ã¨ã‚Šã€çŸ¥è­˜é›†ç´„å‹ã‚¿ã‚¹ã‚¯ã§ã®æˆåŠŸãŒæ¨è«–ã‚¿ã‚¹ã‚¯ã§ã®æˆåŠŸã«å¿…ãšã—ã‚‚ã¤ãªãŒã‚‰ãªã„ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚ã¾ãŸã€ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®é–“ã«æ˜ç¢ºãªç›¸é–¢ã¯è¦‹ã‚‰ã‚Œãšã€VisualPuzzlesã¯äº‹å®Ÿã®è¨˜æ†¶ã‚’è¶…ãˆãŸæ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹æ–°ãŸãªè¦–ç‚¹ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yueqi_song/status/1912510869491101732?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç”»åƒã¯PJãƒšãƒ¼ã‚¸ã‚ˆã‚Šå¼•ç”¨ã€‚æ–°ãŸã«Visual Puzzleã¨å‘¼ã°ã‚Œã‚‹ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ãŒã»ã¨ã‚“ã©å¿…è¦ãªã„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªreasoningãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã€‚o1ã§ã™ã‚‰ã€äººé–“ã®5th percentileã«æº€ãŸãªã„æ€§èƒ½ã¨ã®ã“ã¨ã€‚<br><br>Chinese Civil Service Examinationä¸­ã®logical reasoning questionã‚’æ‰‹ä½œæ¥­ã§ç¿»è¨³ã—ãŸã¨ã®ã“ã¨ã€‚<br><br><img src="https://github.com/user-attachments/assets/4ee1cd31-2d47-46a2-861b-2a72c5df8529" alt="image" loading="lazy"><br><br>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±è¨ˆé‡ã¯ä»¥ä¸‹ã§ã€åˆè¨ˆ1168å•ã§ã€é›£æ˜“åº¦ã¯3æ®µéšã«åˆ†ã‹ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/332246e3-075f-4d98-b528-c8e4ec865068" alt="image" loading="lazy"><br><br>project page:


<a href="https://neulab.github.io/VisualPuzzles/" target="_blank" rel="noopener noreferrer">https://neulab.github.io/VisualPuzzles/</a>


</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Muonã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã‚’å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ãŸã‚ã«ã€ã‚¦ã‚§ã‚¤ãƒˆãƒ‡ã‚±ã‚¤ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã”ã¨ã®æ›´æ–°ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´ã‚’å°å…¥ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Muonã¯å¤§è¦æ¨¡ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§å³åº§ã«æ©Ÿèƒ½ã—ã€è¨ˆç®—åŠ¹ç‡ãŒAdamWã®ç´„2å€ã«å‘ä¸Šã€‚æ–°ãŸã«ææ¡ˆã™ã‚‹Moonlightãƒ¢ãƒ‡ãƒ«ã¯ã€å°‘ãªã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°FLOPã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®åˆ†æ•£Muonå®Ÿè£…ã‚„äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚‚å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1944902706747072678?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã¡ã‚‰ã§ã‚‚ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2208" target="_blank" rel="noopener noreferrer">ãã¿ã¯NanoGPT speedrunã‚’çŸ¥ã£ã¦ã„ã‚‹ã‹ï¼Ÿ, PredNext, 2025.07</a>
</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1972792014954733896?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2200" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Kimi-VL Technical Report, Kimi Team+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Kimi-VLã¯ã€åŠ¹ç‡çš„ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®Mixture-of-Expertsãƒ“ã‚¸ãƒ§ãƒ³ãƒ»ãƒ©ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€2.8Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨€èªãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’æ´»æ€§åŒ–ã—ã¦é«˜åº¦ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ã‚’å®Ÿç¾ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¿ã‚¹ã‚¯ã‚„å¤§å­¦ãƒ¬ãƒ™ãƒ«ã®ç”»åƒãƒ»å‹•ç”»ç†è§£ã«ãŠã„ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€æœ€å…ˆç«¯ã®VLMã¨ç«¶äº‰ã€‚128Kã®æ‹¡å¼µã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’æŒã¡ã€é•·ã„å…¥åŠ›ã‚’å‡¦ç†å¯èƒ½ã€‚Kimi-VL-Thinking-2506ã¯ã€é•·æœŸçš„æ¨è«–èƒ½åŠ›ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã«æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦é–‹ç™ºã•ã‚Œã€å …ç‰¢ãªä¸€èˆ¬èƒ½åŠ›ã‚’ç²å¾—ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2201" target="_blank" rel="noopener noreferrer">[Paper Note] Measuring Multimodal Mathematical Reasoning with MATH-Vision Dataset, Ke Wang+, NeurIPS'24 Datasets and Benchmarks Track</a>
 <br>ã§ã®æ€§èƒ½ï¼ˆVision+ãƒ†ã‚­ã‚¹ãƒˆã®æ•°å­¦ã®å•é¡Œï¼‰ã€‚ä»–ã®å·¨å¤§ãªãƒ¢ãƒ‡ãƒ«ã¨æ¯”ã¹2.8Bã®Activation paramsã§é«˜ã„æ€§èƒ½ã‚’é”æˆ<br><br>&lt;img width="831" height="431" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/3ec08621-f269-4f1d-97bb-3ebca537f2ea"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/3ec08621-f269-4f1d-97bb-3ebca537f2ea"&lt;/a&gt;


/&gt;<br><br>ãã®ä»–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚‚é«˜ã„æ€§èƒ½ã‚’ç²å¾—<br><br>&lt;img width="833" height="558" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/b30afc4f-efce-4206-b499-f4f089d97226"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/b30afc4f-efce-4206-b499-f4f089d97226"&lt;/a&gt;


/&gt;<br><br>ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€‚MoonViT (Image Encoder, 1Dã®patchã‚’input, æ§˜ã€…ãªè§£åƒåº¦ã®ã‚µãƒãƒ¼ãƒˆ, FlashAttention,  SigLIP-SO-400Mã‚’ç¶™ç¶šäº‹å‰å­¦ç¿’, RoPEã‚’æ¡ç”¨) + Linear Projector + MoE Language Decoderã®æ§‹æˆ<br>&lt;img width="851" height="590" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/f59d7655-c1c7-4284-b79c-9d62739da889"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/f59d7655-c1c7-4284-b79c-9d62739da889"&lt;/a&gt;


/&gt;<br><br>å­¦ç¿’ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚ViTã®äº‹å‰å­¦ç¿’ã§ã¯SigLIP loss (contrastive lossã®äºœç¨®)ã¨captionç”Ÿæˆã®cross-entropy lossã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚joint cooldown stageã«ãŠã„ã¦ã¯ã€é«˜å“è³ªãªQAãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã™ã‚‹ã“ã¨ã§å®Ÿé¨“çš„ã«å¤§å¹…ã«æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ãŸã®ã§ã€ãã‚Œã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚optimizerã¯ <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
<br><br>&lt;img width="849" height="213" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/720b02f7-a260-497f-85c5-04cf382c2f98"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/720b02f7-a260-497f-85c5-04cf382c2f98"&lt;/a&gt;


/&gt;<br><br>&lt;img width="828" height="402" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/bb78d799-5db4-4904-8669-540d2142c95c"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/bb78d799-5db4-4904-8669-540d2142c95c"&lt;/a&gt;


/&gt;<br><br>post-trainingã«ãŠã‘ã‚‹RLã§ã¯ä»¥ä¸‹ã®ç›®çš„é–¢æ•°ã‚’ç”¨ã„ã¦ãŠã‚Šã€RLVRã‚’ç”¨ã„ã¤ã¤ã€ç¾åœ¨ã®ãƒãƒªã‚·ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’referenceã¨ã—æ›´æ–°ã‚’ã™ã‚‹ã‚ˆã†ãªç›®çš„é–¢æ•°ã«ãªã£ã¦ã„ã‚‹ã€‚curriculum sampling, prioritize samplingã‚’difficulty labelã«åŸºã¥ã„ã¦å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚<br>&lt;img width="842" height="152" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/298fdef8-9807-4511-96f6-02241393ab9f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/298fdef8-9807-4511-96f6-02241393ab9f"&lt;/a&gt;


/&gt;<br><br>&lt;img width="822" height="187" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/4ad0d815-ef1c-4945-ae08-ab2b072ec63f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/4ad0d815-ef1c-4945-ae08-ab2b072ec63f"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-07-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2198" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Nonlinear transformers can perform inference-time feature learning, Nishikawa+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- äº‹å‰å­¦ç¿’ã•ã‚ŒãŸãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¯ã€æ¨è«–æ™‚ã«ç‰¹å¾´ã‚’å­¦ç¿’ã™ã‚‹èƒ½åŠ›ã‚’æŒã¡ã€ç‰¹ã«å˜ä¸€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹æ–‡è„ˆå†…å­¦ç¿’ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚å‹¾é…ãƒ™ãƒ¼ã‚¹ã®æœ€é©åŒ–ã«ã‚ˆã‚Šã€ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆç‰¹å¾´ã‚’æŠ½å‡ºã—ã€éé©å¿œçš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä¸Šå›ã‚‹çµ±è¨ˆçš„åŠ¹ç‡ã‚’ç¤ºã—ã¾ã™ã€‚ã¾ãŸã€æ¨è«–æ™‚ã®ã‚µãƒ³ãƒ—ãƒ«è¤‡é›‘æ€§ãŒç›¸é–¢çµ±è¨ˆã‚¯ã‚¨ãƒªã®ä¸‹é™ã‚’è¶…ãˆã‚‹ã“ã¨ã‚‚ç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/btreetaiji/status/1944297631808991742?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2194" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SingLoRA: Low Rank Adaptation Using a Single Matrix, David BensaÃ¯d+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- SingLoRAã¯ã€LoRAã®ä½ãƒ©ãƒ³ã‚¯é©å¿œã‚’å†å®šå¼åŒ–ã—ã€å˜ä¸€ã®ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ã¨ãã®è»¢ç½®ã®ç©ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®‰å®šæ€§ã‚’å‘ä¸Šã•ã›ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’ã»ã¼åŠæ¸›ã•ã›ã‚‹æ‰‹æ³•ã§ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€å¸¸è­˜æ¨è«–ã‚¿ã‚¹ã‚¯ã§LLama 7Bã‚’ç”¨ã„ãŸãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§91.3%ã®ç²¾åº¦ã‚’é”æˆã—ã€LoRAã‚„LoRA+ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€ç”»åƒç”Ÿæˆã«ãŠã„ã¦ã‚‚Stable Diffusionã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§é«˜ã„å¿ å®Ÿåº¦ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1943701154497732765?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LoRAã¯ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—BAã®ç©ã‚’è¨ˆç®—ã™ã‚‹ãŒã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜æŒ™å‹•ã‹ã‚‰å­¦ç¿’ã‚’ã‚¹ã‚¿ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã«ã€Bã‚’zeroã§åˆæœŸåŒ–ã—ã€Aã¯ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã™ã‚‹ã€‚ã“ã®Aã¨Bã®ä¸å‡è¡¡ã•ãŒã€å‹¾é…æ¶ˆå¤±ã€çˆ†ç™ºã€ã‚ã‚‹ã„ã¯sub-optimalãªåæŸã®è¦å› ã¨ãªã£ã¦ã—ã¾ã£ã¦ã„ãŸï¼ˆinter-matrix scale conflicts)ã€‚ç‰¹ã«ã€LoRAã¯ãƒ¢ãƒ‡ãƒ«ã®widthãŒå¤§ãããªã‚‹ã¨ä¸å®‰å®šã«ãªã‚‹ã¨ã„ã†èª²é¡ŒãŒã‚ã£ãŸã€‚ã“ã®ãŸã‚ã€ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ã‚’2ã¤ä½¿ã†ã®ã§ã¯ãªãã€1ã¤ã®ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ï¼ˆã¨ãã®è»¢ç½®ï¼‰ãŠã‚ˆã³optimizationã®step tã”ã¨ã«trainableãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã©ã®ç¨‹åº¦å½±éŸ¿ã‚’ä¸ãˆã‚‹ã‹ã‚’èª¿æ•´ã™ã‚‹åº¦åˆã„ã‚’æ±ºã‚ã‚‹scalar function u(t)ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—é–“ã®ä¸å‡è¡¡ã‚’è§£æ¶ˆã—ã¤ã¤ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’åŠæ¸›ã—ã€å­¦ç¿’ã®å®‰å®šæ€§ã¨æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ãŸã¨ãˆã°u(t)ã‚’å­¦ç¿’é–‹å§‹æ™‚ã«zeroã«ã™ã‚Œã°ã€å…ƒã®LoRAã«ãŠã„ã¦Bã‚’zeroã«åˆæœŸåŒ–ã™ã‚‹ã®ã¨åŒã˜æŒ™å‹•ï¼ˆã¤ã¾ã‚Šå…ƒã®ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜æŒ™å‹•ã‹ã‚‰å­¦ç¿’ã‚¹ã‚¿ãƒ¼ãƒˆãŒã§ããŸã‚Šã™ã‚‹ã€‚ã¿ãŸã„ãªæ„Ÿã˜ã ã‚ã†ã‹ï¼Ÿ<br><br><img src="https://github.com/user-attachments/assets/2dcd4ec1-59d3-43c0-ab8d-5c1c37e5ec3d" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/c73b8715-e0c8-45c8-a7fa-ea55ac8ca3ce" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/cf034dcd-37c4-48f1-a0a3-1d836db37820" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/82999835-ac1e-4380-8bd0-00d14022abf5" alt="image" loading="lazy"></p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1956" target="_blank" rel="noopener noreferrer">LoRA: Low-Rank Adaptation of Large Language Models, Edward J. Hu+, ICLR'22</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1245" target="_blank" rel="noopener noreferrer">LoRA+: Efficient Low Rank Adaptation of Large Models, Soufiane Hayou+, N/A, ICML'24</a>
</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2192" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Small Batch Size Training for Language Models: When Vanilla SGD Works,  and Why Gradient Accumulation Is Wasteful, Martin Marek+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å°ã•ãªãƒãƒƒãƒã‚µã‚¤ã‚ºã«å¯¾ã™ã‚‹Adamã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹æ–°ã—ã„ãƒ«ãƒ¼ãƒ«ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å°ã•ãªãƒãƒƒãƒã‚µã‚¤ã‚ºã§ã‚‚å®‰å®šã—ãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¯èƒ½ã§ã€å¤§ããªãƒãƒƒãƒã‚µã‚¤ã‚ºã¨åŒç­‰ä»¥ä¸Šã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚å‹¾é…è“„ç©ã¯æ¨å¥¨ã›ãšã€å®Ÿç”¨çš„ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/giffmana/status/1943384733418950815?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>è«–æ–‡ä¸­ã®Figure1ã«ãŠã„ã¦ã€AdamWã«ãŠã„ã¦batchsizeãŒ1ã®æ–¹ãŒ512ã®å ´åˆã¨æ¯”ã¹ã¦learning_rateã®å¤‰åŒ–ã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆã§ã‚ã‚‹æ—¨ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>&lt;img width="977" height="642" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/0c1efb5d-6eeb-4fd7-ba06-e4296e988a6c"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0c1efb5d-6eeb-4fd7-ba06-e4296e988a6c"&lt;/a&gt;


/&gt;<p>ä¼¼ãŸã‚ˆã†ãªè©±ã§MTã§ãƒãƒƒãƒã‚µã‚¤ã‚ºå°ã•ã„ã»ã†ãŒæ€§èƒ½è‰¯ã„ã§ã™ã€ã¿ãŸã„ãªè©±ãŒæ˜”ã‚ã£ãŸã‚ˆã†ãª<br><br>ï¼ˆè¿½è¨˜ï¼‰<br>æ°—ã«ãªã£ã¦æ€ã„å‡ºãã†ã¨ã—ã¦ã„ãŸãŒã€MTã§ã¯ãªãç”»åƒèªè­˜ã®è©±ã ã£ãŸã‹ã‚‚ã—ã‚Œãªã„ï¼ˆã ã„ã¶ã†ã‚è¦šãˆï¼‰<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2196" target="_blank" rel="noopener noreferrer">[Paper Note] Revisiting Small Batch Training for Deep Neural Networks, Dominic Masters+, arXiv'18</a>
 </p>
<p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1944034128707342815?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1541" target="_blank" rel="noopener noreferrer">How Does Critical Batch Size Scale in Pre-training?, Hanlin Zhang+, ICLR'25</a>
</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1952506470878351492?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å®Ÿéš›ã«8Bãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ã«ãŠã„ã¦Î²2ã‚’0.99ã«ã—ãŸã¨ã“ã‚ã€å­¦ç¿’ãŒä¸å®‰å®šã«ãªã‚Šã€ã‹ã¤æœ€çµ‚çš„ãªPerplexityã‚‚ä»–ã®è¨­å®šã«å‹ã¤ã“ã¨ãŒã§ããªã‹ã£ãŸã¨ã®ã“ã¨:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1955906705637957995?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2191" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Perception-Aware Policy Optimization for Multimodal Reasoning, Zhenhailong Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ã«ãŠã‘ã‚‹æ¤œè¨¼å¯èƒ½ãªå ±é…¬ï¼ˆRLVRï¼‰ã¯ã€LLMsã«å¤šæ®µéšæ¨è«–èƒ½åŠ›ã‚’ä¸ãˆã‚‹ãŒã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ã§ã¯æœ€é©ãªæ€§èƒ½ã‚’ç™ºæ®ã§ããªã„ã€‚è¦–è¦šå…¥åŠ›ã®èªè­˜ãŒä¸»ãªã‚¨ãƒ©ãƒ¼åŸå› ã§ã‚ã‚‹ãŸã‚ã€çŸ¥è¦šã‚’æ„è­˜ã—ãŸãƒãƒªã‚·ãƒ¼æœ€é©åŒ–ï¼ˆPAPOï¼‰ã‚’ææ¡ˆã€‚PAPOã¯GRPOã®æ‹¡å¼µã§ã€å†…éƒ¨ç›£è¦–ä¿¡å·ã‹ã‚‰å­¦ç¿’ã—ã€è¿½åŠ ã®ãƒ‡ãƒ¼ã‚¿ã‚„å¤–éƒ¨å ±é…¬ã«ä¾å­˜ã—ãªã„ã€‚KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹é …ã‚’å°å…¥ã—ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§4.4%ã®æ”¹å–„ã€è¦–è¦šä¾å­˜ã‚¿ã‚¹ã‚¯ã§ã¯8.0%ã®æ”¹å–„ã‚’é”æˆã€‚çŸ¥è¦šã‚¨ãƒ©ãƒ¼ã‚‚30.5%æ¸›å°‘ã—ã€PAPOã®åŠ¹æœã‚’ç¤ºã™ã€‚ç ”ç©¶ã¯è¦–è¦šã«åŸºã¥ãæ¨è«–ã‚’ä¿ƒé€²ã™ã‚‹æ–°ã—ã„RLãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®åŸºç›¤ã‚’ç¯‰ãã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1943507735489974596?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>VLMã«ãŠã„ã¦ã€ç”»åƒã‚’ãƒã‚¹ã‚¯ã—ãŸå ´åˆã®ãƒãƒªã‚·ãƒ¼ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã¨ã€ç”»åƒã‚’ãƒã‚¹ã‚¯ã—ãªã„å ´åˆã®ãƒãƒªã‚·ãƒ¼ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã®KL Divergenceã‚’æœ€å¤§åŒ–ã™ã‚‹ã“ã¨ã§ã€ç”»åƒã®èªçŸ¥èƒ½åŠ›ãŒå‘ä¸Šã—æ€§èƒ½å‘ä¸Šã™ã‚‹ã‚ˆã€ã¿ãŸã„ãªè©±ãªæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/d7844321-d979-497f-84da-5d69fd13233f" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/afe8919c-ea16-48a1-b33b-79b7a3b1ccb0" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/04a3d23c-2eb0-40e2-aa2c-363498976320" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2188" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Spike No More: Stabilizing the Pre-training of Large Language Models, Sho Takase+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ä¸­ã«ç™ºç”Ÿã™ã‚‹æå¤±ã®ã‚¹ãƒ‘ã‚¤ã‚¯ã¯æ€§èƒ½ã‚’ä½ä¸‹ã•ã›ã‚‹ãŸã‚ã€é¿ã‘ã‚‹ã¹ãã§ã‚ã‚‹ã€‚å‹¾é…ãƒãƒ«ãƒ ã®æ€¥æ¿€ãªå¢—åŠ ãŒåŸå› ã¨ã•ã‚Œã€ã‚µãƒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ¤ã‚³ãƒ“è¡Œåˆ—ã®åˆ†æã‚’é€šã˜ã¦ã€å‹¾é…ãƒãƒ«ãƒ ã‚’å°ã•ãä¿ã¤ãŸã‚ã®æ¡ä»¶ã¨ã—ã¦å°ã•ãªã‚µãƒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨å¤§ããªã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ã“ã‚Œã‚‰ã®æ¡ä»¶ã‚’æº€ãŸã™æ‰‹æ³•ãŒæå¤±ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’åŠ¹æœçš„ã«é˜²ãã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shot4410/status/1943301371010388175?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>small sub-layers, large shortcutsã®èª¬æ˜ã¯ã“ã¡ã‚‰ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹ã€‚å‰è€…ã«ã¤ã„ã¦ã¯ã€ç¾åœ¨ä¸»æµãªLLMã®åˆæœŸåŒ–æ‰‹æ³•ã¯æº€ãŸã—ã¦ã„ã‚‹ãŒã€å¾Œè€…ã¯ã‚ªãƒªã‚¸ãƒŠãƒ«ã®Transformerã®å®Ÿè£…ã§ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹[^1]ãŒã€æœ€è¿‘ã®å®Ÿè£…ã§ã¯å¤±ã‚ã‚Œã¦ã—ã¾ã£ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚<br><img src="https://github.com/user-attachments/assets/55cf847c-fc6a-4e76-88c9-1507464e96a0" alt="image" loading="lazy"><br><br>ä¸‹å›³ãŒå®Ÿé¨“çµæœã§ã€æ¡ä»¶ã®åŒæ–¹ã‚’æº€ãŸã—ã¦ã„ã‚‹ã®ã¯EmbedLN[^2]ã¨Scaled Embed[^3]ã®ã¿ã§ã‚ã‚Šã€å®Ÿéš›ã«ã‚¹ãƒ‘ã‚¤ã‚¯ãŒç”Ÿã˜ã¦ã„ãªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/79494662-3d58-4d8e-ae9d-8ed9241e0f65" alt="image" loading="lazy"><br><br>[^1]:ã‚ªãƒªã‚¸ãƒŠãƒ«è«–æ–‡ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/245" target="_blank" rel="noopener noreferrer">[Paper Note] Attention Is All You Need, Ashish Vaswani+, arXiv'17</a>
 ã®3.4ç¯€æœ«å°¾ã€embedding layersã«å¯¾ã—ã¦sqrt(d_model)ã‚’ä¹—ã˜ã‚‹ã¨ã„ã†ã“ã¨ãŒã‚µãƒ©ãƒƒã¨æ›¸ã„ã¦ã‚ã‚‹ã€‚ã“ã‚ŒãŒå®Ÿã¯ã‚ã¡ã‚ƒã‚ã¡ã‚ƒé‡è¦ã ã£ãŸã¨ã„ã†â€¦<br>[^2]: positional embeddingã‚’åŠ ç®—ã™ã‚‹å‰ã«Layer Normalizationã‚’ã‹ã‘ã‚‹æ–¹æ³•<br>[^3]: Embeddingã«Embeddingã®æ¬¡å…ƒæ•°dï¼ˆi.e., å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®inputã®æ¬¡å…ƒæ•°)ã®å¹³æ–¹æ ¹ã‚’ä¹—ã˜ã‚‹æ–¹æ³•</p>
<p>å‰ã«Scaled dot-product attentionã®sqrt(d_k)ãŒã‚ã£ã¡ã‚ƒé‡è¦ã¨ã„ã†ã“ã¨ã‚’å®Ÿé¨“çš„ã«ç¤ºã—ãŸã€ã¨ã„ã†è©±ã‚‚ã‚ã£ãŸã‚ˆã†ãªâ€¦<br>ï¼ˆã¾ã‚ãã‚‚ãã‚‚å…ƒè«–æ–‡ã«ãªãœã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã•ã›ã‚‹ã‹ã®èª¬æ˜ã¯æ›¸ã„ã¦ã‚ã‚‹ã‘ã©ã‚‚ï¼‰</p>
<p>è‘—è€…ãƒã‚¹ãƒˆï¼ˆã‚¹ãƒ©ã‚¤ãƒ‰ï¼‰:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shot4410/status/1973694743227027592?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>éå¸¸ã«èˆˆå‘³æ·±ã„ã®ã§å‚ç…§ã®ã“ã¨ã€‚åˆæœŸåŒ–ã®æ°—æŒã¡ã®éƒ¨åˆ†ãªã©å‹‰å¼·ã«ãªã‚‹ã€‚</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Privacy.html" target="_blank" rel="noopener noreferrer">#Privacy</a>
<span class="issue_date">Issue Date: 2025-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2186" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FlexOlmo: Open Language Models for Flexible Data Use, Weijia Shi+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- FlexOlmoã¯ã€ãƒ‡ãƒ¼ã‚¿å…±æœ‰ãªã—ã§ã®åˆ†æ•£ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¯èƒ½ã«ã™ã‚‹æ–°ã—ã„è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒç‹¬ç«‹ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€ãƒ‡ãƒ¼ã‚¿æŸ”è»Ÿãªæ¨è«–ã‚’å®Ÿç¾ã—ã¾ã™ã€‚æ··åˆå°‚é–€å®¶ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã—ã€å…¬é–‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ç‰¹åŒ–å‹ã‚»ãƒƒãƒˆã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€31ã®ä¸‹æµã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã•ã‚Œã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«åŸºã¥ãã‚ªãƒ—ãƒˆã‚¢ã‚¦ãƒˆãŒå¯èƒ½ã§ã€å¹³å‡41%ã®æ€§èƒ½æ”¹å–„ã‚’é”æˆã—ã€å¾“æ¥ã®æ‰‹æ³•ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸçµæœã‚’ç¤ºã—ã¾ã—ãŸã€‚FlexOlmoã¯ã€ãƒ‡ãƒ¼ã‚¿æ‰€æœ‰è€…ã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚’å°Šé‡ã—ã¤ã¤ã€é–‰ã˜ãŸãƒ‡ãƒ¼ã‚¿ã®åˆ©ç‚¹ã‚’æ´»ã‹ã™ã“ã¨ãŒã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/asap2650/status/1943184037419585695?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ‡ãƒ¼ã‚¿ã®ã‚ªãƒ¼ãƒŠãƒ¼å´ãŒãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ(FFNã¨Router embeddings)ã‚’å­¦ç¿’ã—ã€ãã‚Œã‚’publicã«ã‚·ã‚§ã‚¢ã™ã‚‹ã“ã¨ã§åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ãƒ‡ãƒ¼ã‚¿ã‚ªãƒ¼ãƒŠãƒ¼å´ã¯ãƒ‡ãƒ¼ã‚¿ãã®ã‚‚ã®ã‚’æä¾›ã™ã‚‹ã®ã§ã¯ãªãã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å…±æœ‰ã™ã‚‹ã ã‘ã§æ¸ˆã¿ã€ã‹ã¤è‡ªåˆ†ãŸã¡ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’Routerå´ã§åˆ©ç”¨ã™ã‚‹ã‹å¦ã‹ã¯åˆ¶å¾¡å¯èƒ½ã ã‹ã‚‰ã€opt-in/outãŒåˆ¶å¾¡ã§ãã‚‹ã€ã¿ãŸã„ãªè©±ã£ã½ã„ï¼Ÿ<br><img src="https://github.com/user-attachments/assets/6c21a262-afa1-4877-8b53-e6cd9176ecf5" alt="image" loading="lazy"></p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/weijiashi2/status/1942999141438914622?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2184" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] First Return, Entropy-Eliciting Explore, Tianyu Zheng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- FR3Eï¼ˆFirst Return, Entropy-Eliciting Exploreï¼‰ã¯ã€å¼·åŒ–å­¦ç¿’ã«ãŠã‘ã‚‹ä¸å®‰å®šãªæ¢ç´¢ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®æ§‹é€ åŒ–ã•ã‚ŒãŸæ¢ç´¢ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€é«˜ä¸ç¢ºå®Ÿæ€§ã®æ„æ€æ±ºå®šãƒã‚¤ãƒ³ãƒˆã‚’ç‰¹å®šã—ã€ä¸­é–“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æä¾›ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€FR3EãŒå®‰å®šã—ãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ä¿ƒé€²ã—ã€ä¸€è²«ã—ãŸå¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/f14bertolotti/status/1943201406271328524?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RLVRã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã«ãŠã„ã¦ã€reasoning traceã«ãŠã‘ã‚‹å„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‡ºåŠ›ã™ã‚‹éš›ã«ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒé«˜ã„éƒ¨åˆ†ã‚’ç‰¹å®šã—ï¼ˆã¤ã¾ã‚Šã€è¤‡æ•°ã®å€™è£œãŒã‚ã‚Šãƒ¢ãƒ‡ãƒ«ãŒè¿·ã£ã¦ã„ã‚‹ï¼‰ã€ãã®éƒ¨åˆ†ã«ã¤ã„ã¦ç•°ãªã‚‹æ„å›³çš„ã«ç•°ãªã‚‹ç”Ÿæˆãƒ‘ã‚¹ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§æ¢ç´¢ã‚’ä¿ƒã™ã‚ˆã†ã«ã™ã‚‹ã¨RLVRãŒã‚ˆã‚Šreliableã«ãªã‚‹ã¨ã„ã£ãŸè©±ã®ã‚ˆã†ã§ã‚ã‚‹<br><img src="https://github.com/user-attachments/assets/fc8adfcf-f6fc-4631-ba0a-04fa1401e96a" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/fabf56a8-20f3-4782-a07b-3c854f01dfd5" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<a class="button" href="articles/Decoder.html" target="_blank" rel="noopener noreferrer">#Decoder</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2182" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding   Models, Chankyu Lee+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼å°‚ç”¨ã®LLMãƒ™ãƒ¼ã‚¹ã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«NV-Embedã¯ã€BERTã‚„T5ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’å·¥å¤«ã—ã€æ¤œç´¢ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«æ½œåœ¨çš„æ³¨æ„å±¤ã‚’ææ¡ˆã€‚äºŒæ®µéšã®å¯¾ç…§çš„æŒ‡ç¤ºèª¿æ•´æ‰‹æ³•ã‚’å°å…¥ã—ã€æ¤œç´¢ã¨éæ¤œç´¢ã‚¿ã‚¹ã‚¯ã®ä¸¡æ–¹ã§ç²¾åº¦ã‚’å‘ä¸Šã€‚NV-Embedãƒ¢ãƒ‡ãƒ«ã¯MTEBãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã§1ä½ã‚’ç²å¾—ã—ã€ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–æƒ…å ±æ¤œç´¢ã§ã‚‚é«˜ã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚ãƒ¢ãƒ‡ãƒ«åœ§ç¸®æŠ€è¡“ã®åˆ†æã‚‚è¡Œã£ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Decoder-Only LLMã®last hidden layerã®matrixã‚’æ–°ãŸã«å°å…¥ã—ãŸLatent Attention Blockã®inputã¨ã—ã€Latent Attention Blockã¯Embeddingã‚’Outputã™ã‚‹ã€‚Latent Attention Blockã¯ã€last hidden layer (ç³»åˆ—é•·lÃ—dã®<br>matrix)ã‚’Queryã¨ã¿ãªã—ã€ä¿æŒã—ã¦ã„ã‚‹Latent Array(trainableãªmatrixã§è¾æ›¸ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹;å¾Œè¿°ã®å­¦ç¿’ã«ãŠã„ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå­¦ç¿’ã•ã‚Œã‚‹)[^1]ã‚’K,Vã¨ã—ã¦ã€CrossAttentionã«ã‚ˆã£ã¦context vectorã‚’ç”Ÿæˆã—ã€ãã®å¾ŒMLPã¨Mean Poolingã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§Embeddingã«å¤‰æ›ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/7a023273-aafd-4cfa-9b39-961180543ae9" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/767e3ac1-fe70-4653-bbe7-091c1f1dc0f7" alt="image" loading="lazy"><br><br>å­¦ç¿’ã¯2æ®µéšã§è¡Œã‚ã‚Œã€ã¾ãšQAãªã©ã®Retrievalã‚¿ã‚¹ã‚¯ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’In Batch negativeã‚’ç”¨ã„ã¦Contrastive Learningã—ãƒ¢ãƒ‡ãƒ«ã®æ¤œç´¢èƒ½åŠ›ã‚’é«˜ã‚ã‚‹ã€‚ãã®å¾Œã€æ¤œç´¢ã¨éæ¤œç´¢ã‚¿ã‚¹ã‚¯ã®ä¸¡æ–¹ã‚’ç”¨ã„ã¦ã€hard negativeã«ã‚ˆã£ã¦contrastive learningã‚’å®Ÿæ–½ã—ã€æ¤œç´¢ä»¥å¤–ã®ã‚¿ã‚¹ã‚¯ã®èƒ½åŠ›ã‚‚é«˜ã‚ã‚‹ï¼ˆä¸‹è¡¨ï¼‰ã€‚ä¸¡è€…ã«ãŠã„ã¦ã€instructionãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”¨ã„ã¦ã€instructionã«ã‚ˆã£ã¦æ¡ä»¶ä»˜ã‘ã¦å­¦ç¿’ã‚’ã™ã‚‹ã“ã¨ã§ã€instructionã«å¿œã˜ã¦ç”Ÿæˆã•ã‚Œã‚‹EmbeddingãŒå¤‰åŒ–ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ã¾ãŸã€å­¦ç¿’æ™‚ã«ã¯LLMã®causal maskã¯ç„¡ãã—ã€bidirectionalã«representationã‚’è€ƒæ…®ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/26d4e126-1d18-421e-873f-f0eef4fc2026" alt="image" loading="lazy"><br><br>[^1]: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2183" target="_blank" rel="noopener noreferrer">[Paper Note] Perceiver IO: A General Architecture for Structured Inputs &amp; Outputs, Andrew Jaegle+, ICLR'22</a>
 Perceiver-IOã«ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2181" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Decoder-Hybrid-Decoder Architecture for Efficient Reasoning with Long  Generation, Liliang Ren+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®é€²å±•ã«ã‚ˆã‚Šã€çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ï¼ˆSSMï¼‰ã®åŠ¹ç‡çš„ãªã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ã‚²ãƒ¼ãƒ†ãƒƒãƒ‰ãƒ¡ãƒ¢ãƒªãƒ¦ãƒ‹ãƒƒãƒˆï¼ˆGMUï¼‰ã‚’å°å…¥ã—ã€Sambaãƒ™ãƒ¼ã‚¹ã®è‡ªå·±ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰ãƒ¡ãƒ¢ãƒªã‚’å…±æœ‰ã™ã‚‹æ–°ã—ã„ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£SambaYã‚’ææ¡ˆã—ã¾ã™ã€‚SambaYã¯ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã€é•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ€§èƒ½ã‚’æ”¹å–„ã—ã€ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®å¿…è¦æ€§ã‚’æ’é™¤ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€SambaYã¯YOCOãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«å¯¾ã—ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€ç‰¹ã«Phi4-mini-Flash-Reasoningãƒ¢ãƒ‡ãƒ«ã¯æ¨è«–ã‚¿ã‚¹ã‚¯ã§é¡•è‘—ãªæˆæœã‚’ä¸Šã’ã¾ã—ãŸã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/microsoft/Phi-4-mini-flash-reasoning" target="_blank" rel="noopener noreferrer">https://huggingface.co/microsoft/Phi-4-mini-flash-reasoning</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1943099901161652238?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2180" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MegaMath: Pushing the Limits of Open Math Corpora, Fan Zhou+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- MegaMathã¯ã€æ•°å­¦ã«ç‰¹åŒ–ã—ãŸã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€LLMã®æ•°å­¦çš„æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ä½œæˆã•ã‚ŒãŸã€‚ã‚¦ã‚§ãƒ–ãƒ‡ãƒ¼ã‚¿ã®å†æŠ½å‡ºã€æ•°å­¦é–¢é€£ã‚³ãƒ¼ãƒ‰ã®ç‰¹å®šã€åˆæˆãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆã‚’é€šã˜ã¦ã€371Bãƒˆãƒ¼ã‚¯ãƒ³ã®é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚’æä¾›ã—ã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¸Šå›ã‚‹é‡ã¨å“è³ªã‚’å®Ÿç¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fazhou_998/status/1942610771915202590?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>éå¸¸ã«å¤§è¦æ¨¡ãªæ•°å­¦ã®äº‹å‰å­¦ç¿’/mid-trainingå‘ã‘ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br><br>CommonCrawlã®HTMLã‹ã‚‰ã€ã•ã¾ã–ã¾ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†ï¼ˆreformatting, 2 stageã®HTML parserã®æ´»ç”¨ï¼ˆç‰‡æ–¹ã¯noisyã ãŒé«˜é€Ÿã€ã‚‚ã†ä¸€æ–¹ã¯é«˜æ€§èƒ½ã ãŒé…ã„ï¼‰, fasttextãƒ™ãƒ¼ã‚¹ã®åˆ†é¡å™¨ã«ã‚ˆã‚‹æŠ½å‡º, deduplicationç­‰ï¼‰ã‚’å®Ÿæ–½ã—MegaMath-Webã‚’ä½œæˆã€ã¾ãŸã€MegaMathWebã‚’ã•ã‚‰ã«åˆ†é¡å™¨ã§ä½å“è³ªãªã‚‚ã®ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã€LLMã«ã‚ˆã£ã¦ãƒã‚¤ã‚ºé™¤å»ã€ãƒ†ã‚­ã‚¹ãƒˆã®reorganizingã‚’å®Ÿæ–½ã—ï¼ˆâ‰ ãƒ”ãƒ¥ã‚¢ãªåˆæˆãƒ‡ãƒ¼ã‚¿ï¼‰ç¶™ç¶šäº‹å‰å­¦ç¿’ã€mid-trainingå‘ã‘ã®é«˜å“è³ªãªMegaMath-Web-Proã‚’ä½œæˆã€‚<br><br>MegaMathCodeã¯The Stack V2 (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2199" target="_blank" rel="noopener noreferrer">[Paper Note] StarCoder 2 and The Stack v2: The Next Generation, Anton Lozhkov+, arXiv'24</a>
) ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ã¦ãŠã‚Šã€mathematical reasoning, logic puzzles, scientific computationã«é–¢ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’åé›†ã€‚ã¾ãšã“ã‚Œã‚‰ã®ã‚³ãƒ¼ãƒ‰ã¨é–¢é€£ãŒæ·±ã„11ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã‚’é¸å®šã—ã€ãã®ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹ã€‚æ¬¡ã«strong LLMã‚’ç”¨ã„ã¦ã€æ•°å­¦ã«é–¢ã™ã‚‹relevanceã‚¹ã‚³ã‚¢ã¨ã€ã‚³ãƒ¼ãƒ‰ã®å“è³ªã‚’0--6ã®discrete scoreã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã€‚ä½œæˆã—ãŸå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§SLMã‚’å­¦ç¿’ã—å¤§è¦æ¨¡ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§MegaMath-Codeã‚’ä½œæˆã€‚<br><br>æœ€å¾Œã«MegaMath-{Web, code}ã‚’ç”¨ã„ã¦ã€Q&amp;A, code data, text&amp;code block dataã®3ç¨®é¡ã‚’åˆæˆã€‚Q&amp;Aãƒ‡ãƒ¼ã‚¿ã®åˆæˆã§ã¯ã€MegaMath-Webã‹ã‚‰QAãƒšã‚¢ã‚’æŠ½å‡ºã—ã€å¤šæ§˜æ€§ã¨ãƒ‡ãƒ¼ã‚¿é‡ã‚’æ‹…ä¿ã™ã‚‹ãŸã‚Qwen2.5-72B-Instruct, Llama3.3-70B-Instructã®ä¸¡æ–¹ã‚’ç”¨ã„ã¦ã€QAã®solutionã‚’æ´—ç·´ã•ã›ã‚‹ï¼ˆreasoning stepã®æ”¹å–„, ã‚ã‚‹ã„ã¯ã‚¼ãƒ­ã‹ã‚‰ç”Ÿæˆã™ã‚‹[^1])ã“ã¨ã§ç”Ÿæˆã€‚ã¾ãŸã€code dataã§ã¯ã€pythonã‚’å¯¾è±¡ã«MegaMath-Codeã®ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹pythonä»¥å¤–ã®ã‚³ãƒ¼ãƒ‰ã‚’ã€Qwen2.5-Coder-32B-Instructã¨ã€Llamd3.1-70B-Instructã«ã‚ˆã£ã¦pythonã«ç¿»è¨³ã™ã‚‹ã“ã¨ã§ãƒ‡ãƒ¼ã‚¿é‡ã‚’å¢—ã‚„ã—ãŸã€‚text&amp;code blockãƒ‡ãƒ¼ã‚¿ã§ã¯ã€MegaMath-Webã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä¸ãˆã¦ã€ãƒ–ãƒ­ãƒƒã‚¯ã‚’ç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã€æ•°å¼ã€çµæœã€ã‚³ãƒ¼ãƒ‰ãªã©[^1]ï¼‰ã—ã€ãƒ–ãƒ­ãƒƒã‚¯ã®verificationã‚’è¡Œã„ï¼ˆã‚³ãƒ¼ãƒ‰ãŒæ­£ã—ãå®Ÿè¡Œã§ãã‚‹ã‹ã€å®Ÿè¡Œçµæœã¨answerãŒä¸€è‡´ã™ã‚‹ã‹ç­‰ï¼‰ã€verifiedãªãƒ–ãƒ­ãƒƒã‚¯ã‚’æ®‹ã™ã“ã¨ã§ç”Ÿæˆã€‚<br><br><img src="https://github.com/user-attachments/assets/8975019b-5ab4-437c-bd4e-f3b761439c9c" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/995ea6ce-69eb-4f88-8a98-9e55de3e7814" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/c6d1ec61-49f4-459f-92b2-fa0a2625178e" alt="image" loading="lazy"><br><br>[^1]: ã“ã®è¾ºã¯è«–æ–‡ã®è¨˜è¿°ã‚’å’€åš¼ã—ã¦è¨˜è¿°ã—ã¦ãŠã‚Šå®Ÿã‚µãƒ³ãƒ—ãƒ«ã‚’è¦‹ã¦ã„ãªã„ã®ã§å°‘ã—æ­£ã—ã„èªè­˜ã‹ä¸å®‰</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/OOD.html" target="_blank" rel="noopener noreferrer">#OOD</a>
<a class="button" href="articles/DiseaseNameRecognition.html" target="_blank" rel="noopener noreferrer">#DiseaseNameRecognition</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2177" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Toward Cross-Hospital Deployment of Natural Language Processing Systems: Model Development and Validation of Fine-Tuned Large Language Models for Disease Name Recognition in Japanese, Shimizu+, JMIR'25</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aramaki/status/1942902940337099254?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2176" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Survey on Latent Reasoning, Rui-Jie Zhu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€æ˜ç¤ºçš„ãªæ€è€ƒã®é€£é–ï¼ˆCoTï¼‰ã«ã‚ˆã£ã¦å„ªã‚ŒãŸæ¨è«–èƒ½åŠ›ã‚’ç¤ºã™ãŒã€è‡ªç„¶è¨€èªæ¨è«–ã¸ã®ä¾å­˜ãŒè¡¨ç¾åŠ›ã‚’åˆ¶é™ã™ã‚‹ã€‚æ½œåœ¨çš„æ¨è«–ã¯ã“ã®å•é¡Œã‚’è§£æ±ºã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã®ç›£è¦–ã‚’æ’é™¤ã™ã‚‹ã€‚ç ”ç©¶ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å±¤ã®å½¹å‰²ã‚„å¤šæ§˜ãªæ½œåœ¨çš„æ¨è«–æ‰‹æ³•ã‚’æ¢æ±‚ã—ã€ç„¡é™æ·±åº¦ã®æ½œåœ¨çš„æ¨è«–ã‚’å¯èƒ½ã«ã™ã‚‹é«˜åº¦ãªãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã«ã¤ã„ã¦è­°è«–ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ½œåœ¨çš„æ¨è«–ã®æ¦‚å¿µã‚’æ˜ç¢ºã«ã—ã€ä»Šå¾Œã®ç ”ç©¶æ–¹å‘ã‚’ç¤ºã™ã€‚é–¢é€£æƒ…å ±ã¯GitHubãƒªãƒã‚¸ãƒˆãƒªã§æä¾›ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1942787610818097609?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Latent Reasoningã¨ã„ã†ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚¿ãƒ¼ãƒ ãŒå‡ºã¦ããŸ</p>
<p>å‡ºåŠ›ã•ã‚Œã‚‹discreteãªtokenã«ã‚ˆã£ã¦reasoningã‚’å®Ÿæ–½ã™ã‚‹ã®ã§ã¯ãªãã€ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã®representationã§reasoningã‚’å®Ÿæ–½ã™ã‚‹Latent Reasoningã®Survey<br><br>&lt;img width="1099" height="876" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/a34451e6-bf4a-432c-8c5b-facdbfb55c41"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a34451e6-bf4a-432c-8c5b-facdbfb55c41"&lt;/a&gt;


/&gt;<br><br>&lt;img width="959" height="575" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/e53b3bba-f35f-4734-af71-14a90af8ee6f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/e53b3bba-f35f-4734-af71-14a90af8ee6f"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2158" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CriticLean: Critic-Guided Reinforcement Learning for Mathematical  Formalization, Zhongyuan Peng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªç„¶è¨€èªã®æ•°å­¦çš„è¡¨ç¾ã‚’å®Ÿè¡Œå¯èƒ½ãªã‚³ãƒ¼ãƒ‰ã«ç¿»è¨³ã™ã‚‹èª²é¡Œã«å¯¾ã—ã€æ‰¹è©•è€…ã®å½¹å‰²ã‚’èƒ½å‹•çš„ãªå­¦ç¿’ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«å¤‰ãˆã‚‹CriticLeanã¨ã„ã†æ–°ã—ã„å¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚CriticLeanGPTã‚’ç”¨ã„ã¦å½¢å¼åŒ–ã®æ„å‘³çš„å¿ å®Ÿæ€§ã‚’è©•ä¾¡ã—ã€CriticLeanBenchã§ãã®èƒ½åŠ›ã‚’æ¸¬å®šã€‚285Kä»¥ä¸Šã®å•é¡Œã‚’å«ã‚€FineLeanCorpusãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã€æ‰¹è©•æ®µéšã®æœ€é©åŒ–ãŒä¿¡é ¼æ€§ã®ã‚ã‚‹å½¢å¼åŒ–ã«é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1942790484688003275?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1832" target="_blank" rel="noopener noreferrer">Critique Fine-Tuning: Learning to Critique is More Effective than   Learning to Imitate, Yubo Wang+, COLM'25</a>
</p>
<p>Lean 4 å½¢å¼ã«<br><br><img src="https://github.com/user-attachments/assets/79121e53-b205-440d-9615-d520ac848704" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2156" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] VLM2Vec: Training Vision-Language Models for Massive Multimodal  Embedding Tasks, Ziyan Jiang+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ¦ãƒ‹ãƒãƒ¼ã‚µãƒ«ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã‚’ç›®æŒ‡ã—ã€äºŒã¤ã®è²¢çŒ®ã‚’è¡Œã£ãŸã€‚ç¬¬ä¸€ã«ã€MMEBï¼ˆMassive Multimodal Embedding Benchmarkï¼‰ã‚’ææ¡ˆã—ã€36ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦åˆ†é¡ã‚„è¦–è¦šçš„è³ªå•å¿œç­”ãªã©ã®ãƒ¡ã‚¿ã‚¿ã‚¹ã‚¯ã‚’ç¶²ç¾…ã—ãŸã€‚ç¬¬äºŒã«ã€VLM2Vecã¨ã„ã†ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é–‹ç™ºã—ã€è¦–è¦š-è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›ã™ã‚‹æ‰‹æ³•ã‚’ç¤ºã—ãŸã€‚å®Ÿé¨“çµæœã¯ã€VLM2VecãŒæ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦10%ã‹ã‚‰20%ã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã€VLMã®å¼·åŠ›ãªåŸ‹ã‚è¾¼ã¿èƒ½åŠ›ã‚’è¨¼æ˜ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=TE0KOzWYAF" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=TE0KOzWYAF</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2155" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] VLM2Vec-V2: Advancing Multimodal Embedding for Videos, Images, and  Visual Documents, Rui Meng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- VLM2Vec-V2ã¨ã„ã†çµ±ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€å‹•ç”»ã€è¦–è¦šæ–‡æ›¸ã‚’å«ã‚€å¤šæ§˜ãªè¦–è¦šå½¢å¼ã®åŸ‹ã‚è¾¼ã¿ã‚’å­¦ç¿’ã€‚æ–°ãŸã«MMEB-V2ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã—ã€å‹•ç”»æ¤œç´¢ã‚„è¦–è¦šæ–‡æ›¸æ¤œç´¢ãªã©5ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ã€‚åºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€VLM2Vec-V2ã¯æ–°ã‚¿ã‚¹ã‚¯ã§å¼·åŠ›ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€å¾“æ¥ã®ç”»åƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚‚æ”¹å–„ã‚’é”æˆã€‚ç ”ç©¶ã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®ä¸€èˆ¬åŒ–å¯èƒ½æ€§ã«é–¢ã™ã‚‹æ´å¯Ÿã‚’æä¾›ã—ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªè¡¨ç¾å­¦ç¿’ã®åŸºç›¤ã‚’ç¯‰ãã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1942501330674647342?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2156" target="_blank" rel="noopener noreferrer">[Paper Note] VLM2Vec: Training Vision-Language Models for Massive Multimodal  Embedding Tasks, Ziyan Jiang+, ICLR'25</a>
</p>
<p>Video Classification, Visual Document Retrievalãªã©ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚‚å«ã¾ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<span class="issue_date">Issue Date: 2025-07-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2150" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AI Research Agents for Machine Learning: Search, Exploration, and  Generalization in MLE-bench, Edan Toledo+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AIç ”ç©¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€æ©Ÿæ¢°å­¦ç¿’ã®è‡ªå‹•åŒ–ã‚’é€šã˜ã¦ç§‘å­¦ã®é€²å±•ã‚’ä¿ƒé€²ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€MLE-benchã¨ã„ã†Kaggleã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚’ç”¨ã„ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ€§èƒ½å‘ä¸Šã«å–ã‚Šçµ„ã¿ã€æ¤œç´¢ãƒãƒªã‚·ãƒ¼ã¨ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ç”¨ã„ã¦å€™è£œè§£ã®ç©ºé–“ã‚’æ¢ç´¢ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚ç•°ãªã‚‹æ¤œç´¢æˆ¦ç•¥ã¨ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼ã®çµ„ã¿åˆã‚ã›ãŒé«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã€MLE-bench liteã§ã®çµæœã‚’å‘ä¸Šã•ã›ã€Kaggleãƒ¡ãƒ€ãƒ«ç²å¾—ç‡ã‚’39.6%ã‹ã‚‰47.7%ã«å¼•ãä¸Šã’ãŸã€‚è‡ªå‹•åŒ–ã•ã‚ŒãŸæ©Ÿæ¢°å­¦ç¿’ã®é€²å±•ã«ã¯ã€ã“ã‚Œã‚‰ã®è¦ç´ ã‚’å…±åŒã§è€ƒæ…®ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/martinjosifoski/status/1942238775305699558?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1457" target="_blank" rel="noopener noreferrer">MLE-Bench, OpenAI, 2024.10</a>
</p>
<p>ã‚°ãƒ©ãƒ•ä¸­ã®å„ãƒãƒ¼ãƒ‰ã¯artifactsï¼ˆi.e., ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç”Ÿæˆã—ãŸã‚³ãƒ¼ãƒ‰)ã§ã€å…ˆè¡Œç ”ç©¶ãŒiterativeãªå®Ÿé¨“ã«åŠ ãˆã€æ½œåœ¨çš„ãªsolutionã«å¯¾ã—ã¦tree searchã‚’ã™ã‚‹ã“ã¨ã§SoTAã‚’é”æˆã—ã¦ãŠã‚Šã€ã“ã‚Œã‚’ã‚°ãƒ©ãƒ•ã‚’ç”¨ã„ã¦ã‚ˆã‚Šä¸€èˆ¬åŒ–ã™ã‚‹ã“ã¨ã§ç•°ãªã‚‹ãƒ‡ã‚¶ã‚¤ãƒ³ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã‚‚é©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/a1f417c1-f5a0-4e51-a17e-6e5a3fcce75d" alt="image" loading="lazy"><br><br>ã‚ã¨ã§è¿½è¨˜ã™ã‚‹</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Citations.html" target="_blank" rel="noopener noreferrer">#Citations</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/AcademicWriting.html" target="_blank" rel="noopener noreferrer">#AcademicWriting</a>
<span class="issue_date">Issue Date: 2025-07-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2149" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ScholarCopilot: Training Large Language Models for Academic Writing with   Accurate Citations, Yubo Wang+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- ScholarCopilotã¯ã€å­¦è¡“çš„ãªåŸ·ç­†ã‚’æ”¯æ´ã™ã‚‹ãŸã‚ã«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å¼·åŒ–ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€æ­£ç¢ºã§æ–‡è„ˆã«é–¢é€£ã—ãŸå¼•ç”¨ã‚’ç”Ÿæˆã—ã¾ã™ã€‚å–å¾—ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”¨ã„ã¦å‹•çš„ã«æ–‡çŒ®ã‚’å–å¾—ã—ã€ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã‚’è£œå¼·ã—ã¾ã™ã€‚è©•ä¾¡ã§ã¯ã€å–å¾—ç²¾åº¦ãŒ40.1%ã«é”ã—ã€ç”Ÿæˆå“è³ªã‚‚ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã¾ã—ãŸã€‚ç‰¹ã«ã€ScholarCopilotã¯ChatGPTã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€å¼•ç”¨ã®è³ªã§100%ã®å¥½ã¾ã—ã•ã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1907861046833885397?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¾“æ¥ã®RAGãƒ™ãƒ¼ã‚¹ã®AcademicWritingæ‰‹æ³•ã§ã¯ã€ã¾ãšReferenceã‚’æ¤œç´¢ã—ã¦ã€ãã®å†…å®¹ã‚’contextã«å«ã‚ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã¨ã„ã†Sequentialãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã ã£ãŸãŒã€æœ¬ç ”ç©¶ã§ã¯é€šå¸¸ã®NextTokenPrediction Lossã«åŠ ãˆã€ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³\[RET\]ã‚’å°å…¥ã—ã€ContrastiveLearningã«ã‚ˆã£ã¦ã€\[RET\]ãƒˆãƒ¼ã‚¯ãƒ³ãŒãƒˆãƒªã‚¬ãƒ¼ã¨ãªã‚Šã€ç”Ÿæˆéç¨‹ã®Contextã¨queryã‹ã‚‰é©åˆ‡ãªReferenceã‚’æ¤œç´¢ã§ãã‚‹Embeddingã‚’å‡ºåŠ›ã—ã€Referenceã‚’æ¤œç´¢ã—ã€å‹•çš„ã«Referenceã®å†…å®¹ã‚’contextã«åŠ ãˆã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/777da4cb-5678-455f-babf-b91690945712" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/a27e092e-fff2-4f8a-91f7-09fe39e8e568" alt="image" loading="lazy"><br><br>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯arXivã‹ã‚‰latex sourceã‚’åé›†ã—ã€bibliographyéƒ¨åˆ†ã‹ã‚‰Referenceã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’Qwenã‚’ç”¨ã„ã¦æŠ½å‡ºã€‚ã‚¿ã‚¤ãƒˆãƒ«ã‚’arXivãŠã‚ˆã³SemanticScholarã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ç…§åˆã—ã€paperã¨Referenceã®ç´ä»˜ã‘ã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§æ§‹ç¯‰ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/2dd2b956-291e-4407-997a-4a2e68a72708" alt="image" loading="lazy"><br><br>GPT-4oã«ã‚ˆã‚‹judgeã®çµæœã€ground truthã®citationã‚’ç”¨ã„ãŸå ´åˆã«ã¯åŠã°ãªã„ãŒã€ææ¡ˆæ‰‹æ³•ã«ã‚ˆã‚Šå“è³ªãŒå‘ä¸Šã—ã€citation retrievalã®Recall@Kã‚‚å¤§å¹…ã«æ”¹å–„ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/2ff5dd73-dcb8-4a3f-9d6a-1bcfb52a8321" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/81a39366-2577-41a1-aa6b-facc7ac25f1c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2146" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Energy-Based Transformers are Scalable Learners and Thinkers, Alexi Gladstone+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ™ãƒ¼ã‚¹ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ï¼ˆEBTsï¼‰ã‚’ç”¨ã„ã¦ã€ç„¡ç›£ç£å­¦ç¿’ã‹ã‚‰æ€è€ƒã‚’å­¦ã¶ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã€‚EBTsã¯ã€å…¥åŠ›ã¨å€™è£œäºˆæ¸¬ã®äº’æ›æ€§ã‚’æ¤œè¨¼ã—ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼æœ€å°åŒ–ã‚’é€šã˜ã¦äºˆæ¸¬ã‚’è¡Œã†ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚ˆã‚Šã‚‚é«˜ã„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç‡ã‚’é”æˆã—ã€è¨€èªã‚¿ã‚¹ã‚¯ã§ã®æ€§èƒ½ã‚’29%å‘ä¸Šã•ã›ã€ç”»åƒã®ãƒã‚¤ã‚ºé™¤å»ã§ã‚‚å„ªã‚ŒãŸçµæœã‚’ç¤ºã™ã€‚EBTsã¯ä¸€èˆ¬åŒ–èƒ½åŠ›ãŒé«˜ãã€ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’èƒ½åŠ›ã¨æ€è€ƒèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1941657099567845696?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Project Page:


<a href="https://energy-based-transformers.github.io" target="_blank" rel="noopener noreferrer">https://energy-based-transformers.github.io</a>


</p>
<p>First Authorã®æ–¹ã«ã‚ˆã‚‹è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alexiglad/status/1942231878305714462?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-07-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2145" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Correlated Errors in Large Language Models, Elliot Kim+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- 350ä»¥ä¸Šã®LLMã‚’è©•ä¾¡ã—ã€ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã¨å±¥æ­´æ›¸ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã§å®Ÿè¨¼çš„ãªåˆ†æã‚’å®Ÿæ–½ã€‚ãƒ¢ãƒ‡ãƒ«é–“ã®ã‚¨ãƒ©ãƒ¼ã«ã¯å®Ÿè³ªçš„ãªç›¸é–¢ãŒã‚ã‚Šã€ç‰¹ã«å¤§ããæ­£ç¢ºãªãƒ¢ãƒ‡ãƒ«ã¯ç•°ãªã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ã‚‚é«˜ã„ç›¸é–¢ã‚’ç¤ºã™ã€‚ç›¸é–¢ã®å½±éŸ¿ã¯LLMã‚’è©•ä¾¡è€…ã¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚„æ¡ç”¨ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã‚‚ç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kennylpeng/status/1940758198320796065?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯çµæœã‚’ç´°ã‹ãè¦‹ã‚‹ã®ã¨ã€è©•ä¾¡ã—ãŸã‚¿ã‚¹ã‚¯ã®å½¢å¼ã¨ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ãªã„ã‹ã‚’ãã¡ã‚“ã¨ç¢ºèªã—ãŸæ–¹ãŒè‰¯ã„ã‚ˆã†ãªæ°—ãŒã™ã‚‹ã€‚<br><br>ãã‚Œã¯ç½®ã„ã¦ãŠã„ãŸã¨ã—ã¦ã€ãŸã¨ãˆã°ã€Figure9bã¯Llamaã®ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¯ã€é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ã¦ã„ã‚‹ãŒã€ãã‚Œã¯ãƒ™ãƒ¼ã‚¹ãŒåŒã˜ã ã‹ã‚‰ãã†ã ã‚ã†ãªã‚ã€ã¨ã¯æ€ã†ã€‚ä¸€æ–¹ã€9aã¯Claude, Nova, Mistral, GPTãªã©å¤šæ§˜ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ãƒ¢ãƒ‡ãƒ«ã§é«˜ã„ç›¸é–¢ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚Llama3-70Bã¨LLama3.{1,2,3}-70Bã§ã¯ç›¸é–¢ãŒä½ã‹ã£ãŸã‚Šã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/03728cf7-9965-4e04-8f19-5ad3977d1a19" alt="image" loading="lazy"><br><br>Figure1(b)ã¯HELMã§æ¯”è¼ƒçš„æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«é–“ã§ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒåˆ¥ã§ã‚‚é«˜ã„ç›¸é–¢ãŒã‚ã‚‹ã‚ˆã†ã«ã¿ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/d6d1622a-5215-4464-b265-39cc6f0b7a47" alt="image" loading="lazy"><br><br>ã“ã®ã‚ˆã†ãªç›¸é–¢ãŒã‚ã‚‹è¦å› ã‚„å‚¾å‘ã«ã¤ã„ã¦ã¯è«–æ–‡ã‚’èª­ã‚“ã§ã¿ãªã„ã¨ã‚ã‹ã‚‰ãªã„ã€‚</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=kzYq2hfyHB&referrer=%5Bthe%20profile%20of%20Kenny%20Peng%5D(%2Fprofile%3Fid%3D~Kenny_Peng1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=kzYq2hfyHB&referrer=%5Bthe%20profile%20of%20Kenny%20Peng%5D(%2Fprofile%3Fid%3D~Kenny_Peng1)</a>


</p>
<p>LLM-as-a-Judgeã«ãŠã„ã¦ã€è©•ä¾¡è€…ã¨ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã¨è©•ä¾¡å¯¾è±¡ã¨ãªã‚‹ãƒ¢ãƒ‡ãƒ«ãŒåŒã˜ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚„ã‚·ãƒªãƒ¼ã‚ºã®å ´åˆã¯ï¼ˆã‚¨ãƒ©ãƒ¼ã®å‚¾å‘ãŒä¼¼ã¦ã„ã‚‹ã®ã§ï¼‰æ€§èƒ½ãŒAccuracyãŒçœŸã®Accuracyã‚ˆã‚Šã‚‚é«˜ã‚ã«å‡ºã¦ã„ã‚‹ã€‚ã¾ãŸè©•ä¾¡è€…ã‚ˆã‚Šã‚‚æ€§èƒ½ãŒä½ã„ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã‚‚ã€æ€§èƒ½ãŒå®Ÿéš›ã®Accuracyã‚ˆã‚Šã‚‚é«˜ã‚ã«å‡ºã™å‚¾å‘ã«ã‚ã‚‹ï¼ˆã‚¨ãƒ©ãƒ¼ã®ç›¸é–¢ã«ã‚ˆã£ã¦ã‚¨ãƒ©ãƒ¼ã§ã‚ã‚‹ã«ã‚‚é–¢ã‚ã‚‰ãšæ­£è§£ã¨ã¿ãªã•ã‚ŒAccuracyãŒé«˜ããªã‚‹)ã‚ˆã†ã§ã‚ã‚‹ã€‚é€†ã«ã€è©•ä¾¡è€…ã‚ˆã‚Šã‚‚è©•ä¾¡å¯¾è±¡ãŒæ€§èƒ½ãŒé«˜ã„å ´åˆã€è©•ä¾¡è€…ã¯è‡ªåˆ†ãŒèª¤ã£ã¦ã—ã¾ã†questionã«å¯¾ã—ã¦ã€è©•ä¾¡å¯¾è±¡ãƒ¢ãƒ‡ãƒ«ãŒæ­£è§£ã¨ãªã‚‹å›ç­”ã‚’ã—ã¦ã‚‚ã€ãã‚Œã«å¯¾ã—ã¦å ±é…¬ã‚’ä¸ãˆã‚‹ã“ã¨ãŒã§ããšæ€§èƒ½ãŒä½ã‚ã«è¦‹ç©ã‚‚ã‚‰ã‚Œã¦ã—ã¾ã†ã€‚ã“ã‚Œã ã‘ã®è¦æ¨¡ã®å®Ÿé¨“ã§ç¤ºã•ã‚ŒãŸã“ã¨ã¯ã€å¤§å¤‰èˆˆå‘³æ·±ã„ã€‚<br><img src="https://github.com/user-attachments/assets/4a73cdf4-a70d-4f79-997a-3fd5a55c5a60" alt="image" loading="lazy"></p>
<p>å±¥æ­´æ›¸ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦ã‚‚ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚’ã—ã¦ã„ã‚‹ã€‚ã“ã¡ã‚‰ã‚‚è©³ç´°ã«åˆ†æã•ã‚Œã¦ã„ã‚‹ã®ã§èˆˆå‘³ãŒã‚ã‚‹å ´åˆã¯å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<span class="issue_date">Issue Date: 2025-07-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2144" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Skywork-Reward-V2: Scaling Preference Data Curation via Human-AI Synergy, Chris Yuhao Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼ˆRMsï¼‰ã®æ€§èƒ½å‘ä¸Šã®ãŸã‚ã«ã€4,000ä¸‡ã®å¥½ã¿ãƒšã‚¢ã‹ã‚‰ãªã‚‹å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒSynPref-40Mã€ã‚’ææ¡ˆã€‚äººé–“ã¨AIã®ç›¸ä¹—åŠ¹æœã‚’æ´»ç”¨ã—ãŸäºŒæ®µéšãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã€Skywork-Reward-V2ã‚’å°å…¥ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€7ã¤ã®å ±é…¬ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒ«ã¨é«˜å“è³ªãªã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒåŠ¹æœã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ã‚’ç¢ºèªã€‚Skywork-Reward-V2ã¯ã‚ªãƒ¼ãƒ—ãƒ³å ±é…¬ãƒ¢ãƒ‡ãƒ«ã®é€²å±•ã‚’ç¤ºã—ã€äººé–“-AIã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®é‡è¦æ€§ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1941131426084303242?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/user-attachments/assets/56b6baa3-a4d0-41fe-9f4e-8a8098f7ee2c" alt="image" loading="lazy"></p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1942375700289233221?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-07-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2143" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Answer Matching Outperforms Multiple Choice for Language Model  Evaluation, Nikhil Chandak+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è¤‡æ•°é¸æŠã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯è¨€èªãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã«ãŠã„ã¦é‡è¦ã ãŒã€è³ªå•ã‚’è¦‹ãšã«å›ç­”ã§ãã‚‹ã“ã¨ãŒå¤šã„ã€‚ã“ã‚Œã«å¯¾ã—ã€å›ç­”ãƒãƒƒãƒãƒ³ã‚°ã¨ã„ã†ç”Ÿæˆçš„è©•ä¾¡ã‚’ææ¡ˆã—ã€è‡ªç”±å½¢å¼ã®å¿œç­”ã‚’ç”Ÿæˆã•ã›ã¦å‚ç…§å›ç­”ã¨ä¸€è‡´ã™ã‚‹ã‹ã‚’åˆ¤æ–­ã€‚MMLU-Proã¨GPQA-Diamondã§äººé–“ã®æ¡ç‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€å›ç­”ãƒãƒƒãƒãƒ³ã‚°ãŒã»ã¼å®Œç’§ãªä¸€è‡´ã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚è©•ä¾¡æ–¹æ³•ã®å¤‰æ›´ã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒå¤§ããå¤‰ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shashwatgoel7/status/1941153367289364655?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯éå¸¸ã«é‡è¦ãªç ”ç©¶ã«è¦‹ãˆã‚‹</p>
<p>Multiple Choice Question (MCQ)ã§ã¯ã€é¸æŠè‚¢ã®ä¸­ã‹ã‚‰æ¶ˆå»æ³•ï¼ˆè«–æ–‡ä¸­ã§ã¯ä»²é–“ã¯ãšã‚Œã‚’ä¸€ã¤æ¢ã™, odd one cut)ã«ã‚ˆã£ã¦ã€æ­£è§£ã®ç›®å‡¦ãŒç«‹ã£ã¦ã—ã¾ã„ã€åˆ†é¡èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ã‚ˆã†ãªå°ºåº¦ã«ãªã£ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã§åŒã˜ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã€Questionã®ã¿ã‚’ä¸ãˆã¦ã€é¸æŠè‚¢ç„¡ã—ã§è©•ä¾¡ã‚’ã™ã‚‹ã¨ã€é¸æŠè‚¢ã‚ã‚Šã§ã¯æ­£è§£ã§ããŸã®ã«æ­£è§£ã§ããªã„ã€ã¨ã„ã†ç¾è±¡ãŒç”Ÿã˜ã‚‹ã€‚ã“ã‚Œã¯ãƒ¢ãƒ‡ãƒ«ã®åˆ†é¡èƒ½åŠ›ã§ã¯ãªãã€ç”Ÿæˆèƒ½åŠ›ã‚’è©•ä¾¡ã—ã¦ã„ã‚‹ã‹ã‚‰ã§ã‚ã‚Šã€ã“ã‚Œã¾ã§ã®MCQã§ã®è©•ä¾¡ã¯ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã®ä¸€éƒ¨ã€ç‰¹ã«è­˜åˆ¥èƒ½åŠ›ã—ã‹è©•ä¾¡ã§ãã¦ã„ãªã„ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚ã“ã®ãŸã‚ã€Answer Matchingã¨å‘¼ã°ã‚Œã‚‹ã€ãƒ¢ãƒ‡ãƒ«ã«è‡ªç”±è¨˜è¿°ã§å‡ºåŠ›ã‚’ã•ã›ãŸå¾Œã«ã€referenaceã¨å‡ºåŠ›ãŒä¸€è‡´ã—ã¦ã„ã‚‹ã‹å¦ã‹ã§è©•ä¾¡ã‚’ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚GPQA Diamondã¨MMLU-Proã«ãŠã„ã¦ã€äººé–“ã«Answer Matchingã«ã‚ˆã‚‹è©•ä¾¡ã‚’ã•ã›ã‚ªãƒ©ã‚¯ãƒ«ã‚’å–å¾—ã—ãŸå¾Œã€SLMã‚„ã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ«ã§Answer Matchingã‚’å®Ÿé¨“ã—ãŸã¨ã“ã‚ã€o4-miniã‚’ç”¨ã„ãŸLLM-as-a-Judgeã‚ˆã‚Šã‚‚ã€SLMã«ãŠã„ã¦ã•ãˆã‚ªãƒ©ã‚¯ãƒ«ã«è¿‘ã„æ€§èƒ½ã‚’ç™ºæ®ã—ã€äººé–“ã¨åŒç­‰ã®ãƒ¬ãƒ™ãƒ«ã§è‡ªå‹•è©•ä¾¡ãŒå¯èƒ½ãªã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/edefb3ae-95da-4c3f-9233-9fecf92948b1" alt="image" loading="lazy"></p>
<p>ã¾ã å†’é ­ã—ã‹èª­ã‚ã¦ã„ãªã„ã®ã§å¾Œã§èª­ã‚€</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<span class="issue_date">Issue Date: 2025-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2139" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AI4Research: A Survey of Artificial Intelligence for Scientific Research, Qiguang Chen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AIã®é€²å±•ã«ä¼´ã„ã€AI4Researchã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªèª¿æŸ»ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€ç†è§£ã¨ç™ºå±•ãŒå¦¨ã’ã‚‰ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€AI4Researchã®5ã¤ã®ä¸»æµã‚¿ã‚¹ã‚¯ã‚’ç³»çµ±çš„ã«åˆ†é¡ã—ã€ç ”ç©¶ã®ã‚®ãƒ£ãƒƒãƒ—ã‚„å°†æ¥ã®æ–¹å‘æ€§ã‚’ç‰¹å®šã—ã€é–¢é€£ã™ã‚‹å¿œç”¨ã‚„ãƒªã‚½ãƒ¼ã‚¹ã‚’ã¾ã¨ã‚ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç ”ç©¶ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãŒè¿…é€Ÿã«ãƒªã‚½ãƒ¼ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã€é©æ–°çš„ãªãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1940934746932236632?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Cultural.html" target="_blank" rel="noopener noreferrer">#Cultural</a>
<span class="issue_date">Issue Date: 2025-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2133" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CARE: Assessing the Impact of Multilingual Human Preference Learning on  Cultural Awareness, Geyang Guo+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€æ–‡åŒ–çš„å¤šæ§˜æ€§ã‚’è€ƒæ…®ã—ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLMï¼‰ã®è¨“ç·´æ–¹æ³•ã‚’åˆ†æã—ã€ãƒã‚¤ãƒ†ã‚£ãƒ–ãªæ–‡åŒ–çš„å¥½ã¿ã‚’å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ã§ã€LMã®æ–‡åŒ–çš„èªè­˜ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚3,490ã®æ–‡åŒ–ç‰¹æœ‰ã®è³ªå•ã¨31,700ã®ãƒã‚¤ãƒ†ã‚£ãƒ–ãªåˆ¤æ–­ã‚’å«ã‚€ãƒªã‚½ãƒ¼ã‚¹ã€ŒCAREã€ã‚’ç´¹ä»‹ã—ã€é«˜å“è³ªãªãƒã‚¤ãƒ†ã‚£ãƒ–ã®å¥½ã¿ã‚’å°‘é‡å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ã§ã€ã•ã¾ã–ã¾ãªLMã®æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ã¾ãŸã€æ–‡åŒ–çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¼·ã„ãƒ¢ãƒ‡ãƒ«ã¯ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã®æ©æµã‚’å—ã‘ã‚„ã™ãã€åœ°åŸŸé–“ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ã®é•ã„ãŒãƒ¢ãƒ‡ãƒ«é–“ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’ç”Ÿã‚€ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—ãŸã€‚CAREã¯ä¸€èˆ¬ã«å…¬é–‹ã•ã‚Œã‚‹äºˆå®šã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cherylolguo/status/1940798823405600843?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2131" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Curse of Depth in Large Language Models, Wenfang Sun+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€ã€Œæ·±ã•ã®å‘ªã„ã€ã¨ã„ã†ç¾è±¡ã‚’ç´¹ä»‹ã—ã€LLMã®æ·±ã„å±¤ãŒæœŸå¾…é€šã‚Šã«æ©Ÿèƒ½ã—ãªã„ç†ç”±ã‚’åˆ†æã—ã¾ã™ã€‚Pre-LNã®ä½¿ç”¨ãŒå‡ºåŠ›ã®åˆ†æ•£ã‚’å¢—åŠ ã•ã›ã€æ·±ã„å±¤ã®è²¢çŒ®ã‚’ä½ä¸‹ã•ã›ã‚‹ã“ã¨ã‚’ç‰¹å®šã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«å±¤æ­£è¦åŒ–ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆLNSï¼‰ã‚’ææ¡ˆã—ã€å‡ºåŠ›åˆ†æ•£ã®çˆ†ç™ºã‚’æŠ‘åˆ¶ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€LNSãŒLLMã®äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚‚åŠ¹æœãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shiwei_liu66/status/1940377801032446428?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1795" target="_blank" rel="noopener noreferrer">Transformers without Normalization, Jiachen Zhu+, CVPR'25</a>
<br><br>ã§ã¯ãã‚‚ãã‚‚LayerNormalizationã‚’ç„¡ãã—ã¦ã„ãŸï¼ˆæ­£ç¢ºã«ã„ã†ã¨parametrize tanhã«ç½®æ›)ãŒã€ã©ã¡ã‚‰ãŒå„ªã‚Œã¦ã„ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ<br><br><img src="https://github.com/user-attachments/assets/4bc557a0-ae23-4017-9837-7744de74c12e" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/2eead45c-209d-46e4-87e7-0129a4ec5ec2" alt="image" loading="lazy"></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1332" target="_blank" rel="noopener noreferrer">Knowledge Neurons in Pretrained Transformers, Damai Dai+, N/A, ACL'22, 2022.05</a>
<br><br>ã§ã¯çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å­˜åœ¨ãŒç¤ºå”†ã•ã‚Œã¦ãŠã‚Šã€ã“ã‚Œã¯Transformerã®å±¤ã®æ·±ã„ä½ç½®ã«å­˜åœ¨ã—ã€ã‹ã¤ç•°ãªã‚‹çŸ¥è­˜é–“ã§çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ã‚·ã‚§ã‚¢ã•ã‚Œãªã„å‚¾å‘ã«ã‚ã£ãŸï¼ˆãŸã ã—ã“ã‚Œã¯Post-LNã®BERTã®è©±ã§æœ¬ç ”ç©¶ã¯Pre-LNã®è©±ã ãŒã€‚Post-LNã®å‹¾é…æ¶ˆå¤±å•é¡Œã‚’ç·©å’Œã—å­¦ç¿’ã‚’å®‰å®šåŒ–ã•ã›ã‚‹ç ”ç©¶ã‚‚<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2141" target="_blank" rel="noopener noreferrer">[Paper Note] On Layer Normalizations and Residual Connections in Transformers, Sho Takase+, arXiv'22</a>
 ã®ã‚ˆã†ã«å­˜åœ¨ã™ã‚‹)ã€‚ã“ã‚Œã¯ã“ã®ç ”ç©¶ãŒæ˜ã‚‰ã‹ã«ã—ãŸã“ã¨ã¨ã©ã†ã„ã†é–¢ä¿‚æ€§ãŒã‚ã‚‹ã ã‚ã†ã‹ã€‚<br><br>ã¾ãŸã€LayerNormalizationã®Scalingã«ã‚ˆã£ã¦æ·±ã„Transformerãƒ–ãƒ­ãƒƒã‚¯ã®å°é–¢æ•°ãŒå˜ä½è¡Œåˆ—ã¨ãªã‚‹ï¼ˆå­¦ç¿’ã«å¯„ä¸ã—ãªããªã‚‹ï¼‰ã“ã¨ãŒæ”¹å–„ã•ã‚ŒãŸå ´åˆã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ã©ã®ã‚ˆã†ã«å¤‰åŒ–ã™ã‚‹ã ã‚ã†ã‹ï¼Ÿ<br><br>ï¼ˆä¸‹è¨˜Geminiã®å¿œç­”ã‚’è¦‹ãŸä¸Šã§ã®æ„Ÿæƒ³)ãªã‚“ã¨ãªãƒ¼ãã ã‘ã‚Œã©ã‚‚ã€ãŠãã‚‰ãçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å±€æ‰€åŒ–ãŒè§£æ¶ˆã•ã‚Œã‚‹ã®ã‹ãªãƒ¼ã¨ã„ã†æ°—ãŒã™ã‚‹ã€‚<br><br>ã¨ãªã‚‹ã¨æ¬¡ã®ç–‘å•ã¨ã—ã¦ã¯ã€MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã¯ã©ã®ã‚ˆã†ãªå½±éŸ¿ãŒã‚ã‚‹ã ã‚ã†ã‹ï¼Ÿ<br>ãã‚‚ãã‚‚çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒå±€æ‰€åŒ–ã—ã¦ã„ã‚‹ã‹ã‚‰MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ãƒ«ãƒ¼ã‚¿ã«ã‚ˆã£ã¦é–¢é€£ã™ã‚‹Expertsã®ã¿ã‚’activateã™ã‚Œã°ï¼ˆã¨ã„ã†ã‚ˆã‚Šçµæœçš„ã«ãã†ãªã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã‚‹ï¼‰æ€§èƒ½ã‚’åŠ£åŒ–ã•ã›ãšã«è¨ˆç®—åŠ¹ç‡ã‚’ä¸Šã’ã‚‰ã‚Œã¦ã„ãŸã€ã¨ä»®å®šã™ã‚‹ã€‚ãã†ã™ã‚‹ã¨ã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒå±€æ‰€åŒ–ã›ãšã«å¤šãã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã§ã‚·ã‚§ã‚¢ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ã¨ã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2110" target="_blank" rel="noopener noreferrer">[Paper Note] Chain-of-Experts: Unlocking the Communication Power of  Mixture-of-Experts Models, Zihan Wang+, arXiv'25</a>
 ã®ã‚ˆã†ã«ã€ã‚µãƒ–ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é–“ã®æƒ…å ±ã‚’äº’ã„ã«ã‚„ã‚Šã¨ã‚Šã§ãã¾ã™ã€ã¿ãŸã„ãªä»•çµ„ã¿ãŒã‚ˆã‚ŠåŠ¹ã„ã¦ããã†ãªæ°—ãŒã™ã‚‹ã€‚<br><br>å‚è€ƒã¾ã§ã«ã€Gemini2.5-Proã«è€ƒå¯Ÿã•ã›ã¦ã¿ãŸçµæœã‚’ãƒ¡ãƒ¢ã¨ã—ã¦æ®‹ã—ã¦ãŠãï¼ˆã‚ãã¾ã§å‚è€ƒç¨‹åº¦ã«...ï¼‰<br>```<br>ã”è³ªå•ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚éå¸¸ã«èˆˆå‘³æ·±ã„ç€çœ¼ç‚¹ã§ã™ã­ã€‚ã€ŒKnowledge Neurons in Pretrained Transformersã€ã¨ã€ŒThe Curse of Depth in Large Language Modelsã€ã¯ã€ä¸€è¦‹ã™ã‚‹ã¨å…¨ãç•°ãªã‚‹ãƒ†ãƒ¼ãƒã‚’æ‰±ã£ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã¾ã™ãŒã€**ã€ŒTransformerã®æ·±ã„å±¤ã«ãŠã‘ã‚‹æŒ¯ã‚‹èˆã„ã€**ã¨ã„ã†å…±é€šç‚¹ã§çµã³ã¤ã‘ã¦è€ƒå¯Ÿã™ã‚‹ã¨ã€éå¸¸ã«ç¤ºå”†ã«å¯Œã‚“ã é–¢ä¿‚æ€§ãŒè¦‹ãˆã¦ãã¾ã™ã€‚<br><br>ä»¥ä¸‹ã«ã€ä¸¡æ–¹ã®è«–æ–‡ã®æ¦‚è¦ã‚’è§£èª¬ã—ã€ãã®é–¢ä¿‚æ€§ã«ã¤ã„ã¦è€ƒå¯Ÿã—ã¾ã™ã€‚<br><br>1. Knowledge Neurons in Pretrained Transformers ã®æ¦‚è¦<br>ã“ã®ç ”ç©¶ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿Transformerãƒ¢ãƒ‡ãƒ«ï¼ˆç‰¹ã«BERTãªã©ï¼‰ã®å†…éƒ¨ã§ã€ç‰¹å®šã®äº‹å®ŸçŸ¥è­˜ãŒã©ã®ã‚ˆã†ã«æ ¼ç´ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’èª¿æŸ»ã—ãŸã‚‚ã®ã§ã™ã€‚<br><br>ç™ºè¦‹: ãƒ¢ãƒ‡ãƒ«ã®ä¸­é–“å±¤ã€ç‰¹ã«**å…¨çµåˆå±¤ï¼ˆFeed-Forward Network, FFNï¼‰ã«ã€ç‰¹å®šã®çŸ¥è­˜ï¼ˆä¾‹ï¼šã€Œãƒ€ãƒ³ãƒ†ãƒ»ã‚¢ãƒªã‚®ã‚¨ãƒ¼ãƒªã¯ã‚¤ã‚¿ãƒªã‚¢ã§ç”Ÿã¾ã‚ŒãŸã€ï¼‰ã«å¼·ãåå¿œã™ã‚‹ã€ŒçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã€**ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚<br><br>ç‰¹å¾´: ã“ã‚Œã‚‰ã®çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®æ·±ã„å±¤ï¼ˆå¾Œæ–¹ã®å±¤ï¼‰ã«ã€ã‚ˆã‚Šå¤šãå­˜åœ¨ã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã—ãŸã€‚<br><br>æ„å‘³: ã“ã‚Œã¾ã§ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã¨ã•ã‚Œã¦ããŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨ã§ã€çŸ¥è­˜ãŒã©ã®ã‚ˆã†ã«è¡¨ç¾ãƒ»å±€åœ¨åŒ–ã—ã¦ã„ã‚‹ã‹ã«ã¤ã„ã¦ã€å…·ä½“çš„ãªæ‰‹ãŒã‹ã‚Šã‚’ä¸ãˆãŸç”»æœŸçš„ãªç ”ç©¶ã§ã™ã€‚<br><br>2. The Curse of Depth in Large Language Models ã®æ¦‚è¦<br>ã“ã®ç ”ç©¶ã¯ã€LLMã‚’ã‚ˆã‚Šæ·±ãï¼ˆå±¤ã‚’å¤šãï¼‰ã™ã‚‹ã“ã¨ã®é›£ã—ã•ã«ç„¦ç‚¹ã‚’å½“ã¦ã€ãã®åŸå› ã¨è§£æ±ºç­–ã‚’ææ¡ˆã—ãŸã‚‚ã®ã§ã™ã€‚<br><br>å•é¡Œï¼ˆæ·±ã•ã®å‘ªã„ï¼‰: Transformerã®æ¨™æº–çš„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆPre-LNï¼‰ã§ã¯ã€å±¤ãŒæ·±ããªã‚‹ã«ã¤ã‚Œã¦ã€LayerNormalizationï¼ˆLNï¼‰ã¸ã®å…¥åŠ›ã®åˆ†æ•£ãŒæŒ‡æ•°é–¢æ•°çš„ã«å¢—å¤§ã—ã¦ã—ã¾ã„ã¾ã™ã€‚<br><br>çµæœ:<br><br>å‡ºåŠ›ãŒå¤§ãããªã‚Šã™ãã¦å­¦ç¿’ãŒä¸å®‰å®šã«ãªã‚Šã¾ã™ã€‚<br><br>ã•ã‚‰ã«æ·±åˆ»ãªã®ã¯ã€æ·±ã„å±¤ã§ã¯ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã«é–¢ã™ã‚‹å°é–¢æ•°ï¼ˆå‹¾é…è¨ˆç®—ã«å¿…è¦ï¼‰ãŒã»ã¼å˜ä½è¡Œåˆ—ã«ãªã£ã¦ã—ã¾ã†ã“ã¨ã§ã™ã€‚ã“ã‚Œã¯ã€ãã®å±¤ãŒå…¥åŠ›ã«å¯¾ã—ã¦ã»ã¨ã‚“ã©å¤‰æ›ã‚’è¡Œã‚ãªããªã‚Šã€å­¦ç¿’ã«å¯„ä¸ã—ãªããªã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚<br><br>è§£æ±ºç­–: ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€å„å±¤ã®LayerNormalizationã‚’ãã®æ·±ã•ï¼ˆãƒ¬ã‚¤ãƒ¤ãƒ¼ç•ªå· lï¼‰ã«å¿œã˜ã¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã¨ã„ã†ã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ·±ã„å±¤ã§ã‚‚å‹¾é…ãŒé©åˆ‡ã«ä¼æ’­ã—ã€å­¦ç¿’ãŒå®‰å®šãƒ»æ”¹å–„ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚<br><br>è€ƒå¯Ÿï¼š2ã¤ã®ç ”ç©¶ã®é–¢ä¿‚æ€§<br>ã“ã‚Œã‚‰2ã¤ã®ç ”ç©¶ã¯ã€**ã€Œå­¦ç¿’ã®å®‰å®šæ€§ã€ã¨ã€ŒçŸ¥è­˜ã®æ ¼ç´æ–¹æ³•ã€**ã¨ã„ã†ç•°ãªã‚‹å´é¢ã‹ã‚‰ã€Transformerã®æ·±ã„å±¤ã‚’åˆ†æã—ã¦ã„ã¾ã™ãŒã€ä¸¡è€…ã«ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ·±ã„é–¢ä¿‚æ€§ãŒã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚<br><br>å­¦ç¿’ã®ä¸å®‰å®šæ€§ãŒã€ŒçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã€å½¢æˆã®èƒŒæ™¯ã«ã‚ã‚‹å¯èƒ½æ€§<br>ã€ŒThe Curse of Depthã€ã§æŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€æ¨™æº–çš„ãªTransformerã®æ·±ã„å±¤ã¯ã€æœ¬è³ªçš„ã«å­¦ç¿’ãŒä¸å®‰å®šã§ã€å‹¾é…æƒ…å ±ãŒå¤±ã‚ã‚Œã‚„ã™ã„ç’°å¢ƒã«ã‚ã‚Šã¾ã™ã€‚<br><br>ã“ã®åŠ£æ‚ªãªå­¦ç¿’ç’°å¢ƒã“ããŒã€ã€ŒçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã€ã¨ã„ã†å½¢ã§çŸ¥è­˜ãŒå±€æ‰€çš„ã«æ ¼ç´ã•ã‚Œã‚‹åŸå› ã®ä¸€ã¤ã«ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã¤ã¾ã‚Šã€<br><br>å­¦ç¿’ã®éåŠ¹ç‡æ€§: æ·±ã„å±¤ã®ã»ã¨ã‚“ã©ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ã€å‹¾é…æ¶ˆå¤±å•é¡Œã®ãŸã‚ã«åŠ¹ç‡çš„ã«å­¦ç¿’ã‚’é€²ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚<br><br>å°‚é–€åŒ–ã®ç™ºç”Ÿ: ãã®ã‚ˆã†ãªä¸å®‰å®šãªç’°å¢ƒä¸‹ã§ã€ãŸã¾ãŸã¾ç‰¹å®šã®çŸ¥è­˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã†ã¾ãæ‰ãˆã‚‹ã“ã¨ãŒã§ããŸä¸€éƒ¨ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒã€ãã®çŸ¥è­˜ã‚’ä¸€èº«ã«èƒŒè² ã†å½¢ã§å¼·ãæ´»æ€§åŒ–ã™ã‚‹ã‚ˆã†ç‰¹åŒ–ï¼ˆå°‚é–€åŒ–ï¼‰ã—ã¦ã„ã£ãŸã®ã§ã¯ãªã„ã‹ã€ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚ã“ã‚Œã¯ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å…¨ä½“ã§å”èª¿ã—ã¦å­¦ç¿’ã™ã‚‹ã®ãŒé›£ã—ã„çŠ¶æ³ã§ã€ä¸€éƒ¨ã®ãƒ¦ãƒ‹ãƒƒãƒˆã ã‘ãŒçªå‡ºã—ã¦å­¦ç¿’ã‚’æ‹…ã†ã€ã¨ã„ã†ç¾è±¡ã¨è§£é‡ˆã§ãã¾ã™ã€‚<br><br>å­¦ç¿’ã®å®‰å®šåŒ–ãŒã€ã‚ˆã‚ŠåŠ¹ç‡çš„ãªçŸ¥è­˜ç²å¾—ã«ã¤ãªãŒã‚‹<br>ã§ã¯ã€ã€ŒThe Curse of Depthã€ã§ææ¡ˆã•ã‚ŒãŸæ‰‹æ³•ï¼ˆLNã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰ã«ã‚ˆã£ã¦æ·±ã„å±¤ã®å­¦ç¿’ãŒå®‰å®šåŒ–ã™ã‚‹ã¨ã€çŸ¥è­˜ã®æ ¼ç´æ–¹æ³•ã¯ã©ã®ã‚ˆã†ã«å¤‰ã‚ã‚‹ã§ã—ã‚‡ã†ã‹ã€‚<br><br>ã“ã‚Œã¯éå¸¸ã«èˆˆå‘³æ·±ã„å•ã„ã§ã‚ã‚Šã€2ã¤ã®å¯èƒ½æ€§ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚<br><br>å¯èƒ½æ€§A: ã‚ˆã‚Šå¼·å›ºãªçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å½¢æˆ:<br>å­¦ç¿’ãŒå®‰å®šã™ã‚‹ã“ã¨ã§ã€å„çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ã‚ˆã‚Šæ˜ç¢ºã«ã€ãã—ã¦åŠ¹ç‡çš„ã«ç‰¹å®šã®çŸ¥è­˜ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ãƒã‚¤ã‚ºã®å¤šã„ç’°å¢ƒã§å¶ç„¶ç”Ÿã¾ã‚ŒãŸå°‚é–€å®¶ã§ã¯ãªãã€å®‰å®šã—ãŸç’°å¢ƒã§è‚²æˆã•ã‚ŒãŸçœŸã®å°‚é–€å®¶ã¸ã¨å¤‰åŒ–ã™ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ã€‚<br><br>å¯èƒ½æ€§B: çŸ¥è­˜ã®åˆ†æ•£åŒ–:<br>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å…¨ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒåŠ¹ç‡çš„ã«å­¦ç¿’ã«å¯„ä¸ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ãŸã‚ã€ä¸€ã¤ã®çŸ¥è­˜ã‚’å°‘æ•°ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«é›†ä¸­ã•ã›ã‚‹å¿…è¦ãŒãªããªã‚Šã€ã‚ˆã‚Šå¤šãã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«åˆ†æ•£ã—ã¦çŸ¥è­˜ãŒæ ¼ç´ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹å¯èƒ½æ€§ã‚‚è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚<br><br>ç¾åœ¨ã®ã¨ã“ã‚ã€å­¦ç¿’ã®å®‰å®šåŒ–ã¯ã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒã‚ˆã‚ŠåŠ¹ç‡çš„ã«å½¢æˆãƒ»æ©Ÿèƒ½ã™ã‚‹ãŸã‚ã®åŸºç›¤ã‚’æä¾›ã™ã‚‹ã¨è€ƒãˆã‚‹ã®ãŒæœ€ã‚‚å¦¥å½“ã§ã—ã‚‡ã†ã€‚ã€Œæ·±ã•ã®å‘ªã„ã€ã¨ã„ã†å•é¡Œã‚’è§£æ±ºã™ã‚‹ã“ã¨ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒçŸ¥è­˜ã‚’ã©ã®ã‚ˆã†ã«ç²å¾—ã—ã€æ•´ç†ã™ã‚‹ã‹ã¨ã„ã†ã€ã‚ˆã‚Šæ ¹æºçš„ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ï¼ˆçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æŒ¯ã‚‹èˆã„ï¼‰ã«ã‚‚ç›´æ¥çš„ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã¯ãšã§ã™ã€‚<br><br>ã¾ã¨ã‚<br>ã€ŒKnowledge Neuronsã€ã¯æ·±ã„å±¤ã«å­˜åœ¨ã™ã‚‹çŸ¥è­˜ã®**ã€ŒçŠ¶æ…‹ã€ã‚’æ˜ã‚‰ã‹ã«ã—ã€ã€ŒThe Curse of Depthã€ã¯æ·±ã„å±¤ã§ç™ºç”Ÿã™ã‚‹å­¦ç¿’ã®ã€Œå•é¡Œã€**ã¨ãã®è§£æ±ºç­–ã‚’æç¤ºã—ã¾ã—ãŸã€‚<br><br>ã“ã‚Œã‚‰ã‚’çµ±åˆã™ã‚‹ã¨ã€**ã€Œæ·±ã„å±¤ã«ãŠã‘ã‚‹å­¦ç¿’ã®ä¸å®‰å®šæ€§ã¨ã„ã†å•é¡ŒãŒã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¨ã„ã†å±€æ‰€çš„ãªçŸ¥è­˜è¡¨ç¾ã‚’ç”Ÿã¿å‡ºã™ä¸€å› ã¨ãªã£ã¦ãŠã‚Šã€ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚ŠåŠ¹ç‡çš„ã§å®‰å®šã—ãŸçŸ¥è­˜ã®ç²å¾—ãƒ»æ ¼ç´ãŒå¯èƒ½ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€**ã¨ã„ã†é–¢ä¿‚æ€§ãŒè¦‹ãˆã¦ãã¾ã™ã€‚<br><br>ä¸¡è€…ã¯ã€LLMã®èƒ½åŠ›ã¨é™ç•Œã‚’ç•°ãªã‚‹è§’åº¦ã‹ã‚‰ç…§ã‚‰ã—å‡ºã—ã¦ãŠã‚Šã€çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨å‹•ä½œã®è§£æ˜ã‚’ã•ã‚‰ã«ä¸€æ­©å‰é€²ã•ã›ã‚‹ã€éå¸¸ã«é‡è¦ãªç ”ç©¶ã ã¨è¨€ãˆã¾ã™ã€‚<br>```</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<span class="issue_date">Issue Date: 2025-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2129" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] NaturalThoughts: Selecting and Distilling Reasoning Traces for General  Reasoning Tasks, Yang Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ç”¨ã„ã¦ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æ–¹æ³•ã‚’ä½“ç³»çš„ã«ç ”ç©¶ã€‚NaturalReasoningã«åŸºã¥ãé«˜å“è³ªãªã€ŒNaturalThoughtsã€ã‚’ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã€ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’åˆ†æã€‚ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®æ‹¡å¤§ãŒæ€§èƒ½å‘ä¸Šã«å¯„ä¸ã—ã€å¤šæ§˜ãªæ¨è«–æˆ¦ç•¥ã‚’å¿…è¦ã¨ã™ã‚‹ä¾‹ãŒåŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚LlamaãŠã‚ˆã³Qwenãƒ¢ãƒ‡ãƒ«ã§ã®è©•ä¾¡ã«ã‚ˆã‚Šã€NaturalThoughtsãŒæ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¸Šå›ã‚Šã€STEMæ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1940656092054204498?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1768" target="_blank" rel="noopener noreferrer">NaturalReasoning: Reasoning in the Wild with 2.8M Challenging Questions, Weizhe Yuan+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/CurriculumLearning.html" target="_blank" rel="noopener noreferrer">#CurriculumLearning</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2128" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable  Reinforcement Learning, GLM-V Team+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ«GLM-4.1V-Thinkingã‚’ç™ºè¡¨ã—ã€æ¨è«–ä¸­å¿ƒã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é–‹ç™ºã€‚å¼·åŠ›ãªè¦–è¦šåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã€ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ç”¨ã„ãŸå¼·åŒ–å­¦ç¿’ã§å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã®èƒ½åŠ›ã‚’å‘ä¸Šã€‚28ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ç‰¹ã«é›£ã—ã„ã‚¿ã‚¹ã‚¯ã§ç«¶äº‰åŠ›ã®ã‚ã‚‹çµæœã‚’ç¤ºã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sinclairwang1/status/1940331927724232712?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Qwen2.5-VLã‚ˆã‚Šã‚‚æ€§èƒ½ãŒè‰¯ã„VLM<br><img src="https://github.com/user-attachments/assets/1215d0cf-3776-4631-a5d5-2c514e7d5a2e" alt="image" loading="lazy"></p>
<p>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã“ã¡ã‚‰ã€‚ãŒã€pretraining(ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°, ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«â†’long contextç¶™ç¶šäº‹å‰å­¦ç¿’)-&gt;SFT(cold startã¸ã®å¯¾å‡¦, reasoningèƒ½åŠ›ã®ç²å¾—)-&gt;RL(RLVRã¨RLHFã®ä½µç”¨ã«ã‚ˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã¨Alignment, RewardHackingã¸ã®å¯¾å‡¦,curriculum sampling)ãªã©ã€å…¨ä½“ã®å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ç´°ã‹ã„ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã®ç©ã¿é‡ã­ã§é«˜ã„æ€§èƒ½ãŒç²å¾—ã•ã‚Œã¦ã„ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/a692b5de-5f4e-42c6-938e-3718dd2fc0e6" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<span class="issue_date">Issue Date: 2025-07-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2125" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Do Vision-Language Models Have Internal World Models? Towards an Atomic   Evaluation, Qiyue Gao+, ACLï¼ˆFindingsï¼‰'25</a>
<span class="snippet"><span>GPT Summary</span>- å†…éƒ¨ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ï¼ˆWMsï¼‰ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç†è§£ã¨äºˆæ¸¬ã‚’æ”¯ãˆã‚‹ãŒã€æœ€è¿‘ã®å¤§è¦æ¨¡ãƒ“ã‚¸ãƒ§ãƒ³ãƒ»ãƒ©ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«ï¼ˆVLMsï¼‰ã®åŸºæœ¬çš„ãªWMèƒ½åŠ›ã«é–¢ã™ã‚‹è©•ä¾¡ã¯ä¸è¶³ã—ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€çŸ¥è¦šã¨äºˆæ¸¬ã‚’è©•ä¾¡ã™ã‚‹äºŒæ®µéšã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€WM-ABenchã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã€‚15ã®VLMsã«å¯¾ã™ã‚‹660ã®å®Ÿé¨“ã§ã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ãŒåŸºæœ¬çš„ãªWMèƒ½åŠ›ã«é¡•è‘—ãªåˆ¶é™ã‚’ç¤ºã—ã€ç‰¹ã«é‹å‹•è»Œé“ã®è­˜åˆ¥ã«ãŠã„ã¦ã»ã¼ãƒ©ãƒ³ãƒ€ãƒ ãªç²¾åº¦ã§ã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚VLMsã¨äººé–“ã®WMã¨ã®é–“ã«ã¯é‡è¦ãªã‚®ãƒ£ãƒƒãƒ—ãŒå­˜åœ¨ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/qiyuegao123/status/1940097188220297613?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2025-07-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2122" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning, Yulun Jiang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MARBLEã¨ã„ã†æ–°ã—ã„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€MLLMsã®è¤‡é›‘ãªæ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã€‚MARBLEã¯ã€ç©ºé–“çš„ãƒ»è¦–è¦šçš„ãƒ»ç‰©ç†çš„åˆ¶ç´„ä¸‹ã§ã®å¤šæ®µéšè¨ˆç”»ã‚’å¿…è¦ã¨ã™ã‚‹M-Portalã¨M-Cubeã®2ã¤ã®ã‚¿ã‚¹ã‚¯ã‹ã‚‰æˆã‚‹ã€‚ç¾åœ¨ã®MLLMsã¯ä½ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€è¦–è¦šçš„å…¥åŠ›ã‹ã‚‰ã®æƒ…å ±æŠ½å‡ºã«ãŠã„ã¦ã‚‚å¤±æ•—ãŒè¦‹ã‚‰ã‚Œã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ¬¡ä¸–ä»£ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›å‘ä¸ŠãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/michael_d_moor/status/1940062842742526445?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Portal2ã‚’ä½¿ã£ãŸæ–°ãŸãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚ç­†è€…ã¯æ˜”ã“ã®ã‚²ãƒ¼ãƒ ã‚’å°‘ã—ã ã‘ãƒ—ãƒ¬ã‚¤ã—ãŸã“ã¨ãŒã‚ã‚‹ãŒã€æ™®é€šã«é›£ã—ã‹ã£ãŸè¨˜æ†¶ãŒã‚ã‚‹ğŸ˜…<br><br>ç´°ã‹ã„ãŒè¡¨ä¸­ã®GPT-o3ã¯æ­£ã—ãã¯o3ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br>æ™‚é–“ãŒãªãã¦å…¨ç„¶ã—ã£ã‹ã‚Šã¨èª­ã‚ã¦ã„ãªã„ãŒã€reasoning effortã‚„thinkingãƒ¢ãƒ¼ãƒ‰ã¯ã©ã®ã‚ˆã†ã«è¨­å®šã—ã¦è©•ä¾¡ã—ãŸã®ã ã‚ã†ã‹ã€‚<br><img src="https://github.com/user-attachments/assets/a7647007-b718-4b1c-8d8a-396c36d7811d" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/4b996864-7bf8-4ea9-aa3e-84d4e9f3f5d2" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2025-07-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2121" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context  Learning, Melanie Rieff+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã¯åŒ»ç™‚åˆ†é‡ã§ã®å¯èƒ½æ€§ãŒã‚ã‚‹ãŒã€ååˆ†ã«æ¢æ±‚ã•ã‚Œã¦ã„ãªã„ã€‚SMMILEã¨ã„ã†åŒ»ç™‚ã‚¿ã‚¹ã‚¯å‘ã‘ã®åˆã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ICLãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã—ã€111ã®å•é¡Œã‚’å«ã‚€ã€‚15ã®MLLMã®è©•ä¾¡ã§ã€åŒ»ç™‚ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹ICLèƒ½åŠ›ãŒä¸­ç¨‹åº¦ã‹ã‚‰ä½ã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ICLã¯SMMILEã§å¹³å‡8%ã€SMMILE++ã§9.4%ã®æ”¹å–„ã‚’ã‚‚ãŸã‚‰ã—ã€ç„¡é–¢ä¿‚ãªä¾‹ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æœ€å¤§9.5%ä½ä¸‹ã•ã›ã‚‹ã“ã¨ã‚‚ç¢ºèªã€‚ä¾‹ã®é †åºã«ã‚ˆã‚‹æœ€è¿‘æ€§ãƒã‚¤ã‚¢ã‚¹ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚‚æ˜ã‚‰ã‹ã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/michael_d_moor/status/1939664155813839114?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2025-07-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2120" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive   Branching Tree Search, Yuichi Inoue+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- AB-MCTSã‚’ææ¡ˆã—ã€å¤–éƒ¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ´»ç”¨ã—ã¦ç¹°ã‚Šè¿”ã—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’æ”¹å–„ã€‚æ¢ç´¢æœ¨ã®ãƒãƒ¼ãƒ‰ã§æ–°ã—ã„å¿œç­”ã‚’ã€Œåºƒã’ã‚‹ã€ã‹ã€Œæ·±ã‚ã‚‹ã€ã‹ã‚’å‹•çš„ã«æ±ºå®šã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€AB-MCTSãŒå¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã€LLMsã®å¿œç­”ã®å¤šæ§˜æ€§ã¨è§£æ±ºç­–ã®æ´—ç·´ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwiwi/status/1939914618132168961?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwiwi/status/1968898946937565235?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<a class="button" href="articles/Reproducibility.html" target="_blank" rel="noopener noreferrer">#Reproducibility</a>
<span class="issue_date">Issue Date: 2025-06-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2118" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT  Improvements, Bingchen Zhao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®é€²å±•ã‚’æ´»ç”¨ã—ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç ”ç©¶å†ç¾èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€LLMã‚¹ãƒ”ãƒ¼ãƒ‰ãƒ©ãƒ³ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã€‚19ã®ã‚¿ã‚¹ã‚¯ã§è¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ãƒ’ãƒ³ãƒˆã‚’æä¾›ã—ã€è¿…é€Ÿãªå®Ÿè¡Œã‚’ä¿ƒé€²ã€‚æ—¢çŸ¥ã®é©æ–°ã®å†å®Ÿè£…ãŒé›£ã—ã„ã“ã¨ã‚’ç™ºè¦‹ã—ã€ç§‘å­¦çš„å†ç¾ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãŸã‚ã®æŒ‡æ¨™ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/karpathy/status/1939709449956126910?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/TransferLearning.html" target="_blank" rel="noopener noreferrer">#TransferLearning</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/VerifiableRewards.html" target="_blank" rel="noopener noreferrer">#VerifiableRewards</a>
<a class="button" href="articles/Off-Policy.html" target="_blank" rel="noopener noreferrer">#Off-Policy</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/Non-VerifiableRewards.html" target="_blank" rel="noopener noreferrer">#Non-VerifiableRewards</a>
<span class="issue_date">Issue Date: 2025-06-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2117" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Bridging Offline and Online Reinforcement Learning for LLMs, Jack Lanchantin+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹å¼·åŒ–å­¦ç¿’æ‰‹æ³•ã®åŠ¹æœã‚’ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã¸ã®ç§»è¡Œã«ãŠã„ã¦èª¿æŸ»ã€‚æ•°å­¦ã‚¿ã‚¹ã‚¯ã¨æŒ‡ç¤ºã«å¾“ã†ã‚¿ã‚¹ã‚¯ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ã‚’è¡Œã„ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãŠã‚ˆã³ã‚»ãƒŸã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã®æœ€é©åŒ–æ‰‹æ³•ãŒã‚ªãƒ•ãƒ©ã‚¤ãƒ³æ‰‹æ³•ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã™ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¸æŠã«ã¤ã„ã¦åˆ†æã—ã€æ¤œè¨¼å¯èƒ½ãªå ±é…¬ã¨æ¤œè¨¼ä¸å¯èƒ½ãªå ±é…¬ã‚’å…±åŒã§æ‰±ã†ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1939673136842313960?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-06-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2110" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Chain-of-Experts: Unlocking the Communication Power of  Mixture-of-Experts Models, Zihan Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Chain-of-Expertsï¼ˆCoEï¼‰ã¯ã€é€æ¬¡çš„ãªå°‚é–€å®¶é–“ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å°å…¥ã—ãŸæ–°ã—ã„Mixture-of-Expertsï¼ˆMoEï¼‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚’åå¾©çš„ã«å‡¦ç†ã™ã‚‹ã€‚å„åå¾©ã‚¹ãƒ†ãƒƒãƒ—ã§å°‚ç”¨ã®ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã—ã€å‹•çš„ãªå°‚é–€å®¶é¸æŠã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®è¡¨ç¾èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚CoEã¯æ•°å­¦çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€å¾“æ¥ã®MoEã¨æ¯”è¼ƒã—ã¦æ¤œè¨¼æå¤±ã‚’ä½ä¸‹ã•ã›ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›ã™ã‚‹ã€‚åå¾©çš„æ®‹å·®æ§‹é€ ã¨å°‚é–€å®¶ã®å°‚é–€åŒ–ãŒã€ã‚ˆã‚Šè¡¨ç¾åŠ›è±Šã‹ãªçµæœã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1938728784351658087?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-06-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2109" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data  Processing to Every Language, Guilherme Penedo+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤šè¨€èªLLMsã®æ€§èƒ½å‘ä¸Šã®ãŸã‚ã«ã€FineWebã«åŸºã¥ãæ–°ã—ã„äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ææ¡ˆã€‚9ã¤ã®è¨€èªã«å¯¾ã—ã¦è¨­è¨ˆé¸æŠè‚¢ã‚’æ¤œè¨¼ã—ã€éè‹±èªã‚³ãƒ¼ãƒ‘ã‚¹ãŒå¾“æ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ˆã‚Šã‚‚é«˜æ€§èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å†ãƒãƒ©ãƒ³ã‚¹æ‰‹æ³•ã‚‚å°å…¥ã—ã€1000ä»¥ä¸Šã®è¨€èªã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã—ãŸ20ãƒ†ãƒ©ãƒã‚¤ãƒˆã®å¤šè¨€èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆFineWeb2ã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gui_penedo/status/1938631842720022572?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>v1<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1942" target="_blank" rel="noopener noreferrer">The FineWeb Datasets: Decanting the Web for the Finest Text Data at   Scale, Guilherme Penedo+, NeurIPS'24</a>
</p>
<p>abstã‚’è¦‹ã‚‹é™ã‚ŠFinewebã‚’å¤šè¨€èªã«æ‹¡å¼µã—ãŸæ¨¡æ§˜</p>
<p>openreview:


<a href="https://openreview.net/forum?id=jnRBe6zatP#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=jnRBe6zatP#discussion</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-06-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2107" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling, Zengzhi Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ç•°ãªã‚‹ãƒ™ãƒ¼ã‚¹è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLlamaã‚„Qwenï¼‰ã®å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã«ãŠã‘ã‚‹æŒ™å‹•ã‚’èª¿æŸ»ã—ã€ä¸­é–“ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ãŒRLã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’æ˜ã‚‰ã‹ã«ã€‚é«˜å“è³ªã®æ•°å­¦ã‚³ãƒ¼ãƒ‘ã‚¹ãŒãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã€é•·ã„é€£é–çš„æ€è€ƒï¼ˆCoTï¼‰ãŒRLçµæœã‚’æ”¹å–„ã™ã‚‹ä¸€æ–¹ã§ã€å†—é•·æ€§ã‚„ä¸å®‰å®šæ€§ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚äºŒæ®µéšã®ä¸­é–“ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã€ŒStable-then-Decayã€ã‚’å°å…¥ã—ã€OctoThinkerãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’é–‹ç™ºã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã¨æ•°å­¦æ¨è«–ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’å…¬é–‹ã—ã€RLæ™‚ä»£ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®ç ”ç©¶ã‚’æ”¯æ´ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sinclairwang1/status/1938244843857449431?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>mid-trainingã®è¦³ç‚¹ã‹ã‚‰ã€post trainingã«ãŠã‘ã‚‹RLãŒã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹æ¡ä»¶ã‚’systematicallyã«èª¿æŸ»ã—ã¦ã„ã‚‹æ¨¡æ§˜</p>
<p>è«–æ–‡ä¸­ã«ã¯mid-training[^1]ã®å®šç¾©ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹:<br><br>&lt;img width="808" height="353" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/da206d3d-f811-4d69-8210-a1d0816c827f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/da206d3d-f811-4d69-8210-a1d0816c827f"&lt;/a&gt;


/&gt;<br><br>[^1]: mid-trainingã«ã¤ã„ã¦ã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®é–“ã§å³å¯†ãªå®šç¾©ã¯ã¾ã ç„¡ããƒã‚ºãƒ¯ãƒ¼ãƒ‰ã£ã½ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã€ã¨ã„ã†å°è±¡ã‚’ç­†è€…ã¯æŠ±ã„ã¦ãŠã‚Šã€æœ¬ç¨¿ã¯æ–‡çŒ®ä¸­ã§mid-trainingã‚’å®šç¾©ã™ã‚‹åˆã‚ã¦ã®è©¦ã¿ã¨ã„ã†æ‰€æ„Ÿ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2025-06-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2106" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RLPR: Extrapolating RLVR to General Domains without Verifiers, Tianyu Yu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RLVRã¯LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ä¸»ã«æ•°å­¦ã‚„ã‚³ãƒ¼ãƒ‰ã«é™ã‚‰ã‚Œã‚‹ã€‚ã“ã‚Œã‚’å…‹æœã™ã‚‹ãŸã‚ã€æ¤œè¨¼è€…ä¸è¦ã®RLPRãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€LLMã®ãƒˆãƒ¼ã‚¯ãƒ³ç¢ºç‡ã‚’å ±é…¬ä¿¡å·ã¨ã—ã¦åˆ©ç”¨ã€‚ãƒã‚¤ã‚ºã®å¤šã„ç¢ºç‡å ±é…¬ã«å¯¾å‡¦ã™ã‚‹æ‰‹æ³•ã‚’å°å…¥ã—ã€å®Ÿé¨“ã«ã‚ˆã‚ŠGemmaã€Llamaã€Qwenãƒ¢ãƒ‡ãƒ«ã§æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ãŸã€‚ç‰¹ã«ã€TheoremQAã§7.6ãƒã‚¤ãƒ³ãƒˆã€Minervaã§7.5ãƒã‚¤ãƒ³ãƒˆã®æ”¹å–„ã‚’ç¤ºã—ã€General-Reasonerã‚’å¹³å‡1.6ãƒã‚¤ãƒ³ãƒˆä¸Šå›ã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1938359430980268329?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¢å­˜ã®RLVRã¯Verifierã‚’æ§‹ç¯‰ã—ãªã‘ã‚Œã°ãªã‚‰ãšã€ã—ã°ã—ã°ãã®Verifierã¯è¤‡é›‘ã«ãªã‚Šã‚„ã™ãã€ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ã«ã¯èª²é¡ŒãŒã‚ã£ãŸã€‚RLPRï¼ˆProbabliity Reward)ã¯ã€ç”Ÿæˆã•ã‚ŒãŸå¿œç­”ã‹ã‚‰å›ç­”yã‚’æŠ½å‡ºã—ã€æ®‹ã‚Šã‚’reasoning zã¨ã™ã‚‹ã€‚ãã—ã¦å›ç­”éƒ¨åˆ†yã‚’reference y^\*ã§ç½®æ›ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³åˆ—o'ã‚’ç”Ÿæˆï¼ˆzãŒo'ã«å¯¾ã—ã¦ã©ã®ã‚ˆã†ãªæ‰±ã„ã«ãªã‚‹ã‹ã¯åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚„å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ã‚ˆã‚‹æ°—ãŒã™ã‚‹)ã—ã€o'ã®ãƒãƒªã‚·ãƒ¼ãƒ¢ãƒ‡ãƒ«ã§ã®ãƒˆãƒ¼ã‚¯ãƒ³å˜ä½ã§ã®å¹³å‡ç”Ÿæˆç¢ºç‡ã‚’å ±é…¬ã¨ã™ã‚‹ã€‚å°¤åº¦ã®ã‚ˆã†ãªç³»åˆ—å…¨ä½“ã®ç”Ÿèµ·ç¢ºç‡ã‚’è€ƒæ…®ã™ã‚‹æ–¹æ³•ãŒç›´æ„Ÿçš„ã«å½¹ã«ç«‹ã¡ãã†ã ãŒã€è¨ˆç®—ã®éš›ã®ç¢ºç‡ç©ã¯åˆ†æ•£ãŒé«˜ã„ã ã‘ã§ãªãã€ãƒã‚¤ãƒŠãƒ¼ãªé¡ç¾©èªãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ï¼ˆãŸã¨ãˆã°1 tokenã ã‘ç”Ÿèµ·ç¢ºç‡ãŒå°ã•ã‹ã£ãŸå ´åˆ)ã«ã€RewardãŒæ¥µç«¯ã«å°ã•ããªã‚Šsensitiveã§ã‚ã‚‹ã“ã¨ã‚’è€ƒå¯Ÿã—ã€å¹³å‡ç”Ÿæˆç¢ºç‡ã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/52bc778b-d6c9-495c-8bf3-586c7381915b" alt="image" loading="lazy"><br><br>Rule basedãªVerifierã‚’ç”¨ã„ãŸRLVRã‚ˆã‚Šã‚‚generalãªãƒ‰ãƒ¡ã‚¤ãƒ³ã¨mathãƒ‰ãƒ¡ã‚¤ãƒ³ã§æ€§èƒ½å‘ä¸Šã€‚ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã§ã‚‚åŠ¹æœã¯ã‚ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ<br><img src="https://github.com/user-attachments/assets/99e26d11-2e16-4452-9410-860b74f497cd" alt="image" loading="lazy"></p>
<p>ã–ã£ãã‚Šè¦‹ãŸæ„Ÿã˜ã€RLVRãŒãã‚‚ãã‚‚é©ç”¨ã§ããªã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã§å®Ÿé¨“ã—ãŸå ´åˆã®çµæœãŒãªã„ã‚ˆã†ã«è¦‹ãˆã€é©ç”¨ã—ãŸå ´åˆã«æœ‰åŠ¹ãªã®ã‹ã¯æ°—ã«ãªã‚‹ã¨ã“ã‚ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/PRM.html" target="_blank" rel="noopener noreferrer">#PRM</a>
<span class="issue_date">Issue Date: 2025-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2104" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Process Reward Models That Think, Muhammad Khalifa+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã®è‰¯ã„ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã®æ¤œè¨¼å™¨ï¼ˆThinkPRMï¼‰ã‚’ææ¡ˆã—ã€å°‘ãªã„ãƒ—ãƒ­ã‚»ã‚¹ãƒ©ãƒ™ãƒ«ã§é«˜æ€§èƒ½ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ThinkPRMã¯ã€é•·ã„CoTãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’æ´»ç”¨ã—ã€PRM800Kã®ã‚ãšã‹1%ã®ãƒ—ãƒ­ã‚»ã‚¹ãƒ©ãƒ™ãƒ«ã§ã€å¾“æ¥ã®æ¤œè¨¼å™¨ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ProcessBenchã‚„MATH-500ãªã©ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’è¶…ãˆã€ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–è©•ä¾¡ã§ã‚‚å„ªã‚ŒãŸçµæœã‚’å¾—ã¦ã„ã¾ã™ã€‚æœ€å°é™ã®ç›£è¦–ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é€šã˜ã¦ã€æ¤œè¨¼è¨ˆç®—ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<span class="issue_date">Issue Date: 2025-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2101" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Robust Reward Modeling via Causal Rubrics, Pragya Srivastava+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼ˆRMsï¼‰ã¯äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€šã˜ã¦å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’æ•´åˆã•ã›ã‚‹ãŒã€å ±é…¬ãƒãƒƒã‚­ãƒ³ã‚°ã®å½±éŸ¿ã‚’å—ã‘ã‚„ã™ã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€å ±é…¬ãƒãƒƒã‚­ãƒ³ã‚°ã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒCromeã€ã‚’ææ¡ˆã€‚Cromeã¯å› æœçš„æ‹¡å¼µã¨ä¸­ç«‹çš„æ‹¡å¼µã‚’ç”¨ã„ã¦ã€å› æœå±æ€§ã«åŸºã¥ãæ„Ÿåº¦ã¨è™šå½å±æ€§ã«å¯¾ã™ã‚‹ä¸å¤‰æ€§ã‚’å¼·åˆ¶ã™ã‚‹ã€‚å®Ÿé¨“çµæœã§ã¯ã€Cromeã¯RewardBenchã§æ¨™æº–çš„ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€å¹³å‡ç²¾åº¦ã‚’æœ€å¤§5.4%å‘ä¸Šã•ã›ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/harman26singh/status/1937876897058181230?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä»¥ä¸‹ãŒresearch question:<br><img src="https://github.com/user-attachments/assets/98c97b8b-ebca-4a40-9c0f-a8c175044fb9" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/SyntheticDataGeneration.html" target="_blank" rel="noopener noreferrer">#SyntheticDataGeneration</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2094" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs   with Nothing, Zhangchen Xu+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- é«˜å“è³ªãªæŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã¯LLMã®æ•´åˆã«ä¸å¯æ¬ ã§ã‚ã‚Šã€Magpieã¨ã„ã†è‡ªå·±åˆæˆæ‰‹æ³•ã‚’ææ¡ˆã€‚Llama-3-Instructã‚’ç”¨ã„ã¦400ä¸‡ã®æŒ‡ç¤ºã¨å¿œç­”ã‚’ç”Ÿæˆã—ã€30ä¸‡ã®é«˜å“è³ªãªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’é¸å®šã€‚Magpieã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã€å¾“æ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ãŸãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ã€ç‰¹ã«æ•´åˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸçµæœã‚’å¾—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=Pnk7vMbznK" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Pnk7vMbznK</a>


</p>
<p><img src="https://github.com/user-attachments/assets/9cb451b2-5440-43a4-9867-b5206dd08cca" alt="image" loading="lazy"><br><br>ä¸‹è¨˜ã®ã‚ˆã†ãªpre-queryãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä¸ãˆï¼ˆi.e., userã®ç™ºè©±ã¯ä½•ã‚‚ä¸ãˆãšã€ãƒ¦ãƒ¼ã‚¶ã®ç™ºè©±ã‚’è¡¨ã™ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿ã‚’æ¸¡ã™ï¼‰instructionã‚’ç”Ÿæˆã—ã€post-queryãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä¸ãˆã‚‹ï¼ˆi.e., pre-queryãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ+ç”Ÿæˆã•ã‚ŒãŸinstruction+assistantã®ç™ºè©±ã®é–‹å§‹ã‚’è¡¨ã™ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿ã‚’æ¸¡ã™ï¼‰ã“ã¨ã§responseã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€prompt engineeringã‚„seedç„¡ã—ã§instruction tuningãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã§ãã‚‹ã¨ã„ã†æ‰‹æ³•ã€‚<br><img src="https://github.com/user-attachments/assets/59e9ea58-1088-4f7f-a5e1-05fba7221aca" alt="image" loading="lazy"><br><br>ç”Ÿæˆã—ãŸç”Ÿã®instruction tuning pair dataã¯ã€ãŸã¨ãˆã°ä¸‹è¨˜ã®ã‚ˆã†ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ã™ã‚‹ã“ã¨ã§å“è³ªå‘ä¸ŠãŒå¯èƒ½ã§<br><img src="https://github.com/user-attachments/assets/6dc19e89-2e0d-409d-9d96-eca8d92d27d3" alt="image" loading="lazy"><br><br>reward modelã¨çµ„ã¿åˆã‚ã›ã¦LLMã‹ã‚‰ã®responseã‚’ç”Ÿæˆã—rejection samplingã™ã‚Œã°DPOã®ãŸã‚ã®preference dataã‚‚ä½œæˆã§ãã‚‹ã—ã€single turnã®ç™ºè©±ã¾ã§ç”Ÿæˆã•ã›ãŸå¾Œã‚‚ã†ä¸€åº¦pre/post-queryã‚’concatã—ã¦ç”Ÿæˆã™ã‚Œã°Multi turnã®ãƒ‡ãƒ¼ã‚¿ã‚‚ç”Ÿæˆã§ãã‚‹ã€‚<br><br>ä»–ã®ã‚‚ä¾‹ãˆã°ã€ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è‡ªåˆ†ãŒç”Ÿæˆã—ãŸã„æƒ…å ±ã‚’ä¸ãˆã‚‹ã“ã¨ã§ã€ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ç‰¹åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿ã€ã‚ã‚‹ã„ã¯ç‰¹å®šã®è¨€èªã«ç‰¹åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚‚åˆæˆã§ãã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/f5f06b90-d1cb-4de8-bbaa-622abbcc0b6b" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2093" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] llm-jp-modernbert: A ModernBERT Model Trained on a Large-Scale Japanese  Corpus with Long Context Length, Issa Sugiura+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ModernBERTãƒ¢ãƒ‡ãƒ«ï¼ˆllm-jp-modernbertï¼‰ã¯ã€8192ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’æŒã¤æ—¥æœ¬èªã‚³ãƒ¼ãƒ‘ã‚¹ã§è¨“ç·´ã•ã‚Œã€ãƒ•ã‚£ãƒ«ãƒã‚¹ã‚¯ãƒ†ã‚¹ãƒˆè©•ä¾¡ã§è‰¯å¥½ãªçµæœã‚’ç¤ºã™ã€‚ä¸‹æµã‚¿ã‚¹ã‚¯ã§ã¯æ—¢å­˜ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‰ãªã„ãŒã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã®æ‹¡å¼µåŠ¹æœã‚’åˆ†æã—ã€æ–‡ã®åŸ‹ã‚è¾¼ã¿ã‚„è¨“ç·´ä¸­ã®é·ç§»ã‚’èª¿æŸ»ã€‚å†ç¾æ€§ã‚’æ”¯æ´ã™ã‚‹ãŸã‚ã«ã€ãƒ¢ãƒ‡ãƒ«ã¨è©•ä¾¡ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1761" target="_blank" rel="noopener noreferrer">modernbert-ja-130m, SB Intuitions, 2025.02</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2091" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AnswerCarefully: A Dataset for Improving the Safety of Japanese LLM  Output, Hisami Suzuki+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ—¥æœ¬ã®LLMã®å®‰å…¨æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒAnswerCarefullyã€ã‚’ç´¹ä»‹ã€‚1,800çµ„ã®è³ªå•ã¨å‚ç…§å›ç­”ã‹ã‚‰æˆã‚Šã€ãƒªã‚¹ã‚¯ã‚«ãƒ†ã‚´ãƒªã‚’ã‚«ãƒãƒ¼ã—ã¤ã¤æ—¥æœ¬ã®æ–‡è„ˆã«åˆã‚ã›ã¦ä½œæˆã€‚å¾®èª¿æ•´ã«ã‚ˆã‚Šå‡ºåŠ›ã®å®‰å…¨æ€§ãŒå‘ä¸Šã—ã€12ã®LLMã®å®‰å…¨æ€§è©•ä¾¡çµæœã‚‚å ±å‘Šã€‚è‹±èªç¿»è¨³ã¨æ³¨é‡ˆã‚’æä¾›ã—ã€ä»–è¨€èªã§ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã‚’ä¿ƒé€²ã€‚</span>
<span class="snippet"><span>Comment</span><p>Blog:


<a href="https://llmc.nii.ac.jp/answercarefully-dataset/" target="_blank" rel="noopener noreferrer">https://llmc.nii.ac.jp/answercarefully-dataset/</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2088" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Drop-Upcycling: Training Sparse Mixture of Experts with Partial   Re-initialization, Taishi Nakamura+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- Drop-Upcyclingæ‰‹æ³•ã‚’ææ¡ˆã—ã€MoEãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ã‚’å‘ä¸Šã€‚äº‹å‰ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸå¯†ãªãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¤ã¤ã€ä¸€éƒ¨ã®é‡ã¿ã‚’å†åˆæœŸåŒ–ã™ã‚‹ã“ã¨ã§å°‚é–€å®¶ã®å°‚é–€åŒ–ã‚’ä¿ƒé€²ã€‚å¤§è¦æ¨¡å®Ÿé¨“ã«ã‚ˆã‚Šã€5.9Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®MoEãƒ¢ãƒ‡ãƒ«ãŒ13Bå¯†ãªãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ã‚¹ãƒˆã‚’ç´„1/4ã«å‰Šæ¸›ã€‚ã™ã¹ã¦ã®å®Ÿé¨“ãƒªã‚½ãƒ¼ã‚¹ã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=gx1wHnf5Vp" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=gx1wHnf5Vp</a>


</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1546" target="_blank" rel="noopener noreferrer">Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints, Aran Komatsuzaki+, ICLR'23</a>
</p>
<p>ææ¡ˆæ‰‹æ³•ã®å…¨ä½“åƒã¨Diversity re-initializationã®æ¦‚è¦ã€‚å…ƒã®Upcyclingã§ã¯å…¨ã¦identicalãªé‡ã¿ã§replicateã•ã‚Œã¦ã„ãŸãŸã‚ã€ã“ã‚ŒãŒå€‹ã€…ã®expertãŒlong termã§ã®å­¦ç¿’ã§ç‰¹åŒ–ã™ã‚‹ã“ã¨ã®å¦¨ã’ã«ãªã‚Šã€æœ€çµ‚çš„ã«æœ€å¤§é™ã®capabilityã‚’ç™ºæ®ã§ããšã€åæŸãŒé…ã„è¦å› ã¨ãªã£ã¦ã„ãŸã€‚ã“ã‚Œã‚’ã€Upcyclingã—ãŸé‡ã¿ã®ã†ã¡ã€ä¸€éƒ¨ã®indexã®ã¿ã‚’å†åˆæœŸåŒ–ã™ã‚‹ã“ã¨ã§ã€replicateå…ƒã®çŸ¥è­˜ã‚’ä¿æŒã—ã¤ã¤ã€expertsã®å¤šæ§˜æ€§ã‚’é«˜ã‚ã‚‹ã“ã¨ã§è§£æ±ºã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/46ec75a2-30b1-4f48-9f21-cf5f6e30df95" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/ef3c66b2-32a5-46ab-bb31-828fb4570b53" alt="image" loading="lazy"><br><br>ææ¡ˆæ‰‹æ³•ã¯ä»»æ„ã®activation functioné©ç”¨å¯èƒ½ã€‚ä»Šå›ã¯FFN Layerã®activation functionã¨ã—ã¦ä¸€èˆ¬çš„ãªSwiGLUã‚’æ¡ç”¨ã—ãŸå ´åˆã§èª¬æ˜ã—ã¦ã„ã‚‹ã€‚<br><br>Drop-Upcyclingã®æ‰‹æ³•ã¨ã—ã¦ã¯ã€é€šå¸¸ã®Upcyclingã¨åŒæ§˜ã€FFN Layerã®é‡ã¿ã‚’nå€‹ã®expertsã®æ•°ã ã‘replicateã™ã‚‹ã€‚ãã®å¾Œã€re-initializationã‚’å®Ÿæ–½ã™ã‚‹æ¯”ç‡rã«åŸºã¥ã„ã¦ã€[1, intermediate size d_f]ã®ç¯„å›²ã‹ã‚‰r*d_få€‹ã®indexã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã€‚æœ€çµ‚çš„ã«SwiGLUã€ãŠã‚ˆã³FFNã«ãŠã‘ã‚‹3ã¤ã®Weight W_{gate, up, down}ã«ãŠã„ã¦ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸindexã¨å¯¾å¿œã™ã‚‹row/columnã¨å¯¾å¿œã™ã‚‹é‡ã¿ã‚’re-initializeã™ã‚‹ã€‚<br><br>re-initializeã™ã‚‹éš›ã«ã¯ã€å„W_{gate, up, down}ä¸­ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸindexã¨å¯¾å¿œã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã®å¹³å‡ã¨åˆ†æ•£ã‚’ãã‚Œãã‚Œç‹¬ç«‹ã—ã¦æ±‚ã‚ã€ãã‚Œã‚‰ã®å¹³å‡ã¨åˆ†æ•£ã‚’æŒã¤æ­£è¦åˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã€‚<br><br>å­¦ç¿’ã®åˆæœŸã‹ã‚‰é«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã—ã€long termã§ã®æ€§èƒ½ã‚‚å‘ä¸Šã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€learning curveã®å½¢çŠ¶ã‚‚scratchã‹ã‚‰å­¦ç¿’ã—ãŸå ´åˆã¨åŒæ§˜ã®å½¢çŠ¶ã¨ãªã£ã¦ãŠã‚Šã€çŸ¥è­˜ã®è»¢ç§»ã¨expertsã®specializationãŒã†ã¾ãé€²ã‚“ã ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/945e5ae5-05cd-4117-80e8-078b47f0e53c" alt="image" loading="lazy"></p>
<p>è§£èª¬:


<a href="https://llm-jp.nii.ac.jp/news/post-566/" target="_blank" rel="noopener noreferrer">https://llm-jp.nii.ac.jp/news/post-566/</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2086" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Shrinking the Generation-Verification Gap with Weak Verifiers, Jon Saad-Falcon+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Weaverã¯ã€è¤‡æ•°ã®å¼±ã„verifiersã‚’çµ„ã¿åˆã‚ã›ã¦å¼·åŠ›ãªverifierã‚’è¨­è¨ˆã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã¸ã®ä¾å­˜ã‚’æ¸›ã‚‰ã™ãŸã‚ã«å¼±ã„ç›£è¦–ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚å‡ºåŠ›ã‚’æ­£è¦åŒ–ã—ã€ç‰¹å®šã®verifiersã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ç²¾åº¦ã®å‘ä¸Šã‚’å›³ã‚Šã¾ã™ã€‚Weaverã¯ã€æ¨è«–ãŠã‚ˆã³æ•°å­¦ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦Pass@1æ€§èƒ½ã‚’å¤§å¹…ã«æ”¹å–„ã—ã€Llama 3.3 70B Instructã‚’ç”¨ã„ã¦é«˜ã„ç²¾åº¦ã‚’é”æˆã—ã¾ã—ãŸã€‚è¨ˆç®—ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãŸã‚ã«ã€çµ±åˆå‡ºåŠ›ã‚¹ã‚³ã‚¢ã‚’ç”¨ã„ã¦ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’è¨“ç·´ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jonsaadfalcon/status/1937600479527317802?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2085" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Mercury: Ultra-Fast Language Models Based on Diffusion, Inception Labs+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„æ‹¡æ•£å‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«Mercuryã‚’ç™ºè¡¨ã€‚ç‰¹ã«ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å‘ã‘ã®Mercury Coderã¯ã€Miniã¨Smallã®2ã‚µã‚¤ã‚ºã§æä¾›ã•ã‚Œã€é€Ÿåº¦ã¨å“è³ªã§æœ€å…ˆç«¯ã‚’é”æˆã€‚ç‹¬ç«‹è©•ä¾¡ã§ã¯ã€Mercury Coder MiniãŒ1109ãƒˆãƒ¼ã‚¯ãƒ³/ç§’ã€SmallãŒ737ãƒˆãƒ¼ã‚¯ãƒ³/ç§’ã‚’è¨˜éŒ²ã—ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚ã•ã‚‰ã«ã€å®Ÿä¸–ç•Œã§ã®æ¤œè¨¼çµæœã‚„å…¬é–‹APIã€ç„¡æ–™ãƒ—ãƒ¬ã‚¤ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚‚æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1937360864262389786?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆï¼ˆãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆé€Ÿåº¦ï¼‰ãŒã€SoTAã‚‰ã—ã„dLLMãƒ¢ãƒ‡ãƒ«</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1938026627642101858?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2084" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Recycling the Web: A Method to Enhance Pre-training Data Quality and  Quantity for Language Models, Thao Nguyen+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã«åŸºã¥ãã€ä½å“è³ªãªã‚¦ã‚§ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚’å†åˆ©ç”¨ã™ã‚‹æ‰‹æ³•ã€ŒREWIREã€ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®åˆæˆè¡¨ç¾ã‚’å¢—ã‚„ã—ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã¿ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¯”è¼ƒã—ã¦ã€22ã®ã‚¿ã‚¹ã‚¯ã§æ€§èƒ½ã‚’å‘ä¸Šã€‚ç”Ÿãƒ‡ãƒ¼ã‚¿ã¨åˆæˆãƒ‡ãƒ¼ã‚¿ã®æ··åˆãŒåŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ã‚¦ã‚§ãƒ–ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚µã‚¤ã‚¯ãƒ«ãŒäº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«æœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thao_nguyen26/status/1937210428876292457?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thao_nguyen26/status/1961163219118297178?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æ¯æ¸‡ã«å¯¾ã™ã‚‹å¯¾å‡¦ã¨ã—ã¦åˆ¥ã®æ–¹å‘æ€§ã¨ã—ã¦ã¯ä¸‹è¨˜ã®ã‚ˆã†ãªç ”ç©¶ã‚‚ã‚ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1829" target="_blank" rel="noopener noreferrer">Scaling Data-Constrained Language Models, Niklas Muennighoff+, NeurIPS'23</a>
</p>
<p>data:


<a href="https://huggingface.co/datasets/facebook/recycling_the_web" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/facebook/recycling_the_web</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PRM.html" target="_blank" rel="noopener noreferrer">#PRM</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2083" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ReasonFlux-PRM: Trajectory-Aware PRMs for Long Chain-of-Thought  Reasoning in LLMs, Jiaru Zou+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„ãƒ—ãƒ­ã‚»ã‚¹å ±é…¬ãƒ¢ãƒ‡ãƒ«ReasonFlux-PRMã‚’ææ¡ˆã—ã€æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã®è©•ä¾¡ã‚’å¼·åŒ–ã€‚ã‚¹ãƒ†ãƒƒãƒ—ã¨è»Œé“ã®ç›£è¦–ã‚’çµ„ã¿è¾¼ã¿ã€å ±é…¬å‰²ã‚Šå½“ã¦ã‚’ç´°ã‹ãè¡Œã†ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ReasonFlux-PRM-7BãŒé«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿é¸æŠã¨æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã—ã€ç‰¹ã«ç›£è¦–ä»˜ããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§å¹³å‡12.1%ã®å‘ä¸Šã‚’é”æˆã€‚ãƒªã‚½ãƒ¼ã‚¹åˆ¶ç´„ã®ã‚ã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å‘ã‘ã«ReasonFlux-PRM-1.5Bã‚‚å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1937345023005048925?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2082" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Vision as a Dialect: Unifying Visual Understanding and Generation via  Text-Aligned Representations, Jiaming Han+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€è¦–è¦šç†è§£ã¨ç”Ÿæˆã‚’çµ±ä¸€ã™ã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯Tarã‚’ææ¡ˆã€‚Text-Aligned Tokenizerï¼ˆTA-Tokï¼‰ã‚’ç”¨ã„ã¦ç”»åƒã‚’é›¢æ•£ãƒˆãƒ¼ã‚¯ãƒ³ã«å¤‰æ›ã—ã€è¦–è¦šã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’çµ±ä¸€ç©ºé–“ã«çµ±åˆã€‚ã‚¹ã‚±ãƒ¼ãƒ«é©å¿œå‹ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å°å…¥ã—ã€é«˜å¿ å®Ÿåº¦ã®è¦–è¦šå‡ºåŠ›ã‚’ç”Ÿæˆã€‚è¿…é€Ÿãªè‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«ã¨æ‹¡æ•£ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸãƒ‡ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’æ´»ç”¨ã—ã€è¦–è¦šç†è§£ã¨ç”Ÿæˆã®æ”¹å–„ã‚’å®Ÿç¾ã€‚å®Ÿé¨“çµæœã§ã¯ã€TarãŒæ—¢å­˜æ‰‹æ³•ã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¤ºã—ã€åŠ¹ç‡çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1937345768223859139?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>text modalityã¨vision modalityã‚’å…±é€šã®ç©ºé–“ã§è¡¨ç¾ã™ã‚‹<br><img src="https://github.com/user-attachments/assets/356e86e1-cad9-4bee-8398-d68c4fc6ad46" alt="image" loading="lazy"></p>
<p>Visual Understanding/Generationã®ãƒ™ãƒ³ãƒã§å…¨ä½“çš„ã«é«˜ã„æ€§èƒ½ã‚’é”æˆ<br><img src="https://github.com/user-attachments/assets/6e45aec0-ae0b-4327-923f-fdfce8e83ca0" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2080" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Mind the Gap: Examining the Self-Improvement Capabilities of Large  Language Models, Yuda Song+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±æ”¹å–„ã¯LLMã®å‡ºåŠ›æ¤œè¨¼ã‚’é€šã˜ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã€è’¸ç•™ã™ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€è‡ªå·±æ”¹å–„ã®æ•°å­¦çš„å®šå¼åŒ–ã‚’è¡Œã„ã€ç”Ÿæˆ-æ¤œè¨¼ã‚®ãƒ£ãƒƒãƒ—ã«åŸºã¥ãã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç¾è±¡ã‚’ç™ºè¦‹ã€‚ã•ã¾ã–ã¾ãªãƒ¢ãƒ‡ãƒ«ã¨ã‚¿ã‚¹ã‚¯ã‚’ç”¨ã„ãŸå®Ÿé¨“ã«ã‚ˆã‚Šã€è‡ªå·±æ”¹å–„ã®å¯èƒ½æ€§ã¨ãã®æ€§èƒ½å‘ä¸Šæ–¹æ³•ã‚’æ¢æ±‚ã—ã€LLMã®ç†è§£ã‚’æ·±ã‚ã‚‹ã¨ã¨ã‚‚ã«ã€å°†æ¥ã®ç ”ç©¶ã¸ã®ç¤ºå”†ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:


<a href="https://joisino.hatenablog.com/entry/mislead" target="_blank" rel="noopener noreferrer">https://joisino.hatenablog.com/entry/mislead</a>


</p>
<p>Verificationã«å¯¾ã™ã‚‹ç†è§£ã‚’æ·±ã‚ã‚‹ã®ã«éå¸¸ã«è‰¯ã•ãã†</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2079" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual  Retrieval, Michael GÃ¼nther+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- 3.8å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã€Œjina-embeddings-v4ã€ã‚’ææ¡ˆã€‚æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€ã‚¯ã‚¨ãƒªãƒ™ãƒ¼ã‚¹ã®æƒ…å ±æ¤œç´¢ã‚„ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«ã®é¡ä¼¼æ€§æ¤œç´¢ã‚’æœ€é©åŒ–ã€‚ã‚¿ã‚¹ã‚¯ç‰¹åŒ–å‹ã®LoRAã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’çµ„ã¿è¾¼ã¿ã€è¦–è¦šçš„ã«è±Šã‹ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å‡¦ç†ã«å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã€‚æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒJina-VDRã€ã‚‚å°å…¥ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1937342962075378014?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2077" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On the Self-Verification Limitations of Large Language Models on   Reasoning and Planning Tasks, Kaya Stechly+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®æ¨è«–èƒ½åŠ›ã«é–¢ã™ã‚‹æ„è¦‹ã®ç›¸é•ã‚’èƒŒæ™¯ã«ã€åå¾©çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åŠ¹æœã‚’Game of 24ã€ã‚°ãƒ©ãƒ•å½©è‰²ã€STRIPSè¨ˆç”»ã®3é ˜åŸŸã§èª¿æŸ»ã€‚è‡ªå·±æ‰¹è©•ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«æ‚ªå½±éŸ¿ã‚’åŠã¼ã™ä¸€æ–¹ã€å¤–éƒ¨ã®æ­£ã—ã„æ¨è«–è€…ã«ã‚ˆã‚‹æ¤œè¨¼ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚å†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã£ã¦è¤‡é›‘ãªè¨­å®šã®åˆ©ç‚¹ã‚’ç¶­æŒã§ãã‚‹ã“ã¨ã‚‚ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:


<a href="https://joisino.hatenablog.com/entry/mislead" target="_blank" rel="noopener noreferrer">https://joisino.hatenablog.com/entry/mislead</a>


</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=4O0v4s3IzY" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=4O0v4s3IzY</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2076" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Language Models Learn to Mislead Humans via RLHF, Jiaxin Wen+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- RLHFã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¨ãƒ©ãƒ¼ã‚’æ‚ªåŒ–ã•ã›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«ãŒäººé–“ã‚’ç´å¾—ã•ã›ã‚‹èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ä¸€æ–¹ã§ã€ã‚¿ã‚¹ã‚¯ã®æ­£ç¢ºæ€§ã¯å‘ä¸Šã—ãªã„ã€‚è³ªå•å¿œç­”ã‚¿ã‚¹ã‚¯ã¨ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã§è¢«é¨“è€…ã®èª¤æ¤œå‡ºç‡ãŒå¢—åŠ ã—ã€æ„å›³ã•ã‚ŒãŸè©­å¼ã‚’æ¤œå‡ºã™ã‚‹æ‰‹æ³•ãŒU-SOPHISTRYã«ã¯é©ç”¨ã§ããªã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€RLHFã®å•é¡Œç‚¹ã¨äººé–“æ”¯æ´ã®ç ”ç©¶ã®å¿…è¦æ€§ãŒæµ®ãå½«ã‚Šã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:


<a href="https://joisino.hatenablog.com/entry/mislead" target="_blank" rel="noopener noreferrer">https://joisino.hatenablog.com/entry/mislead</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<span class="issue_date">Issue Date: 2025-06-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2073" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] From Bytes to Ideas: Language Modeling with Autoregressive U-Nets, Mathurin Videau+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±å›å¸°å‹U-Netã‚’ç”¨ã„ã¦ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã®æŸ”è»Ÿæ€§ã‚’å‘ä¸Šã•ã›ã€ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿã®ãƒã‚¤ãƒˆã‹ã‚‰å˜èªã‚„å˜èªã®ãƒšã‚¢ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ã®è¦–ç‚¹ã‚’æä¾›ã€‚æ·±ã„æ®µéšã§ã¯åºƒç¯„ãªæ„å‘³ãƒ‘ã‚¿ãƒ¼ãƒ³ã«æ³¨ç›®ã—ã€æµ…ã„æ®µéšã¯BPEãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ–‡å­—ãƒ¬ãƒ™ãƒ«ã®ã‚¿ã‚¹ã‚¯ã‚„ãƒªã‚½ãƒ¼ã‚¹ã®å°‘ãªã„è¨€èªé–“ã§ã®çŸ¥è­˜ç§»è»¢ãŒå¯èƒ½ã¨ãªã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1936825784473096335?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<a class="button" href="articles/CrossDomain.html" target="_blank" rel="noopener noreferrer">#CrossDomain</a>
<span class="issue_date">Issue Date: 2025-06-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2070" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain  Perspective, Zhoujun Cheng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Guruã‚’å°å…¥ã—ã€æ•°å­¦ã€ã‚³ãƒ¼ãƒ‰ã€ç§‘å­¦ã€è«–ç†ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€è¡¨å½¢å¼ã®6ã¤ã®æ¨è«–ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã‚ãŸã‚‹92Kã®RLæ¨è«–ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’æ§‹ç¯‰ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMæ¨è«–ã®ãŸã‚ã®RLã®ä¿¡é ¼æ€§ã¨åŠ¹æœã‚’å‘ä¸Šã•ã›ã€ãƒ‰ãƒ¡ã‚¤ãƒ³é–“ã®å¤‰å‹•ã‚’è¦³å¯Ÿã€‚ç‰¹ã«ã€äº‹å‰å­¦ç¿’ã®éœ²å‡ºãŒé™ã‚‰ã‚ŒãŸãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã¯ã€ãƒ‰ãƒ¡ã‚¤ãƒ³å†…ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚Guru-7Bã¨Guru-32Bãƒ¢ãƒ‡ãƒ«ã¯ã€æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã—ã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ”¹å–„ã€‚ãƒ‡ãƒ¼ã‚¿ã¨ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chengzhoujun/status/1936113985507803365?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>post-trainingã«ãŠã‘ã‚‹RLã®cross domainï¼ˆMath, Code, Science, Logic, Tabular)ã«ãŠã‘ã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã—ãŸç ”ç©¶ã€‚éå¸¸ã«èˆˆå‘³æ·±ã„ç ”ç©¶ã€‚è©³ç´°ã¯å…ƒè«–æ–‡ãŒè‘—è€…ãƒã‚¹ãƒˆå‚ç…§ã®ã“ã¨ã€‚</p>
<p>Qwenã‚·ãƒªãƒ¼ã‚ºã§å®Ÿé¨“ã€‚ä»¥ä¸‹ãƒã‚¹ãƒˆã®ã¾ã¨ã‚ã€‚<br><br>- mid trainingã«ãŠã„ã¦é‡ç‚¹çš„ã«å­¦ç¿’ã•ã‚ŒãŸãƒ‰ãƒ¡ã‚¤ãƒ³ã¯RLã«ã‚ˆã‚‹post trainingã§å¼·ã„è»¢ç§»ã‚’ç™ºæ®ã™ã‚‹ï¼ˆCode, Math, Science)<br>- ä¸€æ–¹ã€mid trainingã§ã‚ã¾ã‚Šå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸­ã«å‡ºç¾ã—ãªã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã¤ã„ã¦ã¯è»¢ç§»ã«ã‚ˆã‚‹æ€§èƒ½å‘ä¸Šã¯æœ€å°é™ã«ç•™ã¾ã‚Šã€in-domainã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ãã¡ã‚“ã¨ä¸ãˆã¦post trainingã—ãªã„ã¨æ€§èƒ½å‘ä¸Šã¯é™å®šçš„<br>- ç°¡å˜ãªã‚¿ã‚¹ã‚¯ã¯cross domainã®è»¢ç§»ã«ã‚ˆã‚‹æ©æµã‚’ã™ãã«å¾—ã‚„ã™ã„ï¼ˆMath500, MBPP),é›£æ˜“åº¦ã®é«˜ã„ã‚¿ã‚¹ã‚¯ã¯æ©æµã‚’å¾—ã«ãã„<br>- å„ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ§˜ã«mixã™ã‚‹ã¨ã€å˜ä¸€ãƒ‰ãƒ¡ã‚¤ãƒ³ã§å­¦ç¿’ã—ãŸå ´åˆã¨åŒç­‰ã‹ãã‚Œä»¥ä¸Šã®æ€§èƒ½ã‚’é”æˆã™ã‚‹<br>- å¿…ãšã—ã‚‚response lengthãŒé•·ããªã‚ŠãªãŒã‚‰äºˆæ¸¬æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã‚ã‘ã§ã¯ãªãã€ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã‚ˆã£ã¦å‚¾å‘ãŒç•°ãªã‚‹<br>- ãŸã¨ãˆã°ã€Code, Logic, Tabularã®å‡ºåŠ›ã¯æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã«ã¤ã‚Œã¦response lengthã¯ç¸®å°ã—ã¦ã„ã<br>- ä¸€æ–¹ã€Science, Mathã¯response lengthãŒå¢—å¤§ã—ã¦ã„ãã€‚ã¾ãŸã€Simulationã¯å¤‰åŒ–ã—ãªã„<br>- ç•°ãªã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’mixã™ã‚‹ã“ã¨ã§ã€æœ€åˆã®æ•°ç™¾ã‚¹ãƒ†ãƒƒãƒ—ã«ãŠã‘ã‚‹rewardã®ç«‹ã¡ä¸ŠãŒã‚ŠãŒæ—©ãï¼ˆå˜ä¸€ãƒ‰ãƒ¡ã‚¤ãƒ³ã¨æ¯”ã¹ã¦æ€¥æ¿€ã«rewardãŒå‘ä¸Šã—ã¦ã„ãï¼‰è»¢ç§»ãŒã†ã¾ãã„ã<br>  - ï¼ˆã“ã‚Œã¯ç§ãŒã‚°ãƒ©ãƒ•ã‚’è¦‹ãŸæ„Ÿæƒ³ã ãŒã€å˜ä¸€ãƒ‰ãƒ¡ã‚¤ãƒ³ã§long runã§å­¦ç¿’ã—ãŸå ´åˆã®æœ€çµ‚çš„ãªæ€§èƒ½ã¯4/6ã§åŒç­‰ç¨‹åº¦ã€2/6ã§å‘ä¸Šï¼ˆMath, Science)<br>- éå¸¸ã«é›£æ˜“åº¦ã®é«˜ã„mathãƒ‡ãƒ¼ã‚¿ã®ã¿ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã¨ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç„¡ã—ã®å ´åˆã¨æ¯”ã¹ã¦é›£æ˜“åº¦ã®é«˜ã„ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬æ€§èƒ½ã¯å‘ä¸Šã™ã‚‹ä¸€æ–¹ã€ç°¡å˜ãªOODã‚¿ã‚¹ã‚¯ï¼ˆHumanEval)ã®æ€§èƒ½ãŒå¤§å¹…ã«ä½ä¸‹ã™ã‚‹ï¼ˆç‰¹å®šã®ã‚‚ã®ã«ç‰¹åŒ–ã™ã‚‹ã¨OODã®æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ï¼‰<br>- RLã¯pre(mid)-trainingã§å­¦ç¿’ã•ã‚ŒãŸreasoningèƒ½åŠ›ã‚’å¼•ãå‡ºã™ã ã‘ã§ã¯ãªãã€æ–°è¦ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã¯æ–°ãŸãªreasoningèƒ½åŠ›ã‚’ç²å¾—ã§ãã‚‹<br>- ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã„ã¨ã€RLã§post-trainingå¾Œã®pass@kã®kã‚’å¤§ããã™ã‚‹ã¨ã©ã“ã‹ã§ã‚µãƒã‚Šã€baseãƒ¢ãƒ‡ãƒ«ã¨äº¤å·®ã™ã‚‹ãŒã€å¤§ãã„ã¨ã‚µãƒã‚‰ãšäº¤å·®ã—ãªã„<br>  - ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„ã¨ã‚ˆã‚Šå¤šæ§˜ãªreasoningãƒ‘ã‚¹ãŒunlockã•ã‚Œã¦ã„ã‚‹<br>- pass@kã§è¦³å¯Ÿã—ãŸã¨ã“ã‚RLã«ã¯2ã¤ã®phaseã®ã‚ˆã¤ãªã‚‚ã®ãŒè¦³æ¸¬ã•ã‚Œã€æœ€åˆã®0-160ï¼ˆ1 epoch)ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯pass@1ãŒæ”¹å–„ã—ãŸãŒã€pass@max_kã¯æ€¥æ¿€ã«æ€§èƒ½ãŒåŠ£åŒ–ã—ãŸã€‚ä¸€æ–¹ã§ã€160ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¶…ãˆã‚‹ã¨ã€åŒæ–¹å…±ã«å¾ã€…ã«æ€§èƒ½æ”¹å–„ãŒæ”¹å–„ã—ã¦ã„ãã‚ˆã†ãªå¤‰åŒ–ãŒè¦‹ã‚‰ã‚ŒãŸ</p>
<p>æœ¬ç ”ç©¶ã§æ§‹ç¯‰ã•ã‚ŒãŸGuru Dataset:


<a href="https://huggingface.co/datasets/LLM360/guru-RL-92k" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/LLM360/guru-RL-92k</a>


<br><br>math, coding, science, logic, simulation, tabular reasoningã«é–¢ã™ã‚‹é«˜å“è³ªã€ã‹ã¤verifiableãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚</p></span><br><br>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/DocParser.html" target="_blank" rel="noopener noreferrer">#DocParser</a>
<span class="issue_date">Issue Date: 2025-06-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2063" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting, Hao Feng+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–‡æ›¸ç”»åƒè§£æã®æ–°ãƒ¢ãƒ‡ãƒ«ã€ŒDolphinã€ã‚’ææ¡ˆã€‚ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¦ç´ ã‚’ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åŒ–ã—ã€ã‚¿ã‚¹ã‚¯ç‰¹æœ‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨çµ„ã¿åˆã‚ã›ã¦è§£æã‚’è¡Œã†ã€‚3000ä¸‡ä»¥ä¸Šã®ã‚µãƒ³ãƒ—ãƒ«ã§è¨“ç·´ã—ã€ãƒšãƒ¼ã‚¸ãƒ¬ãƒ™ãƒ«ã¨è¦ç´ ãƒ¬ãƒ™ãƒ«ã®ä¸¡æ–¹ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚åŠ¹ç‡çš„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å®Ÿç¾ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ä¸­ã€‚</span>
<span class="snippet"><span>Comment</span><p>repo:


<a href="https://github.com/bytedance/Dolphin" target="_blank" rel="noopener noreferrer">https://github.com/bytedance/Dolphin</a>


</p>
<p>SoTAãªDocumentã®parser<br><img src="https://github.com/user-attachments/assets/5b1c4480-65f1-46cc-9318-f8126327e066" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-06-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2062" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Laws for Upcycling Mixture-of-Experts Language Models, Seng Pei Liew+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®äº‹å‰å­¦ç¿’ã¯é«˜ã‚³ã‚¹ãƒˆã§æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã€ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚¯ãƒªãƒ³ã‚°ã¨MoEãƒ¢ãƒ‡ãƒ«ã®è¨ˆç®—åŠ¹ç‡å‘ä¸ŠãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚¯ãƒªãƒ³ã‚°ã‚’MoEã«é©ç”¨ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºã‚„ãƒ¢ãƒ‡ãƒ«æ§‹æˆã«ä¾å­˜ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ç‰¹å®šã€‚å¯†ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚¯ãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ç›¸äº’ä½œç”¨ãŒåŠ¹ç‡ã‚’åˆ¶é™ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚¯ãƒªãƒ³ã‚°ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã«é–¢ã™ã‚‹æŒ‡é‡ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sbintuitions/status/1935970879923540248?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=ZBBo19jldX" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=ZBBo19jldX</a>


</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1546" target="_blank" rel="noopener noreferrer">Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints, Aran Komatsuzaki+, ICLR'23</a>
</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2059" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reasoning by Superposition: A Theoretical Perspective on Chain of Continuous Thought, Hanlin Zhu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€é€£ç¶šCoTsã‚’ç”¨ã„ãŸäºŒå±¤ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãŒæœ‰å‘ã‚°ãƒ©ãƒ•åˆ°é”å¯èƒ½æ€§å•é¡Œã‚’è§£æ±ºã§ãã‚‹ã“ã¨ã‚’è¨¼æ˜ã€‚é€£ç¶šCoTsã¯è¤‡æ•°ã®æ¢ç´¢ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã‚’åŒæ™‚ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€å¾“æ¥ã®é›¢æ•£CoTsã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã«è§£ã‚’å°ãã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€é‡ã­åˆã‚ã›çŠ¶æ…‹ãŒè‡ªå‹•çš„ã«ç¾ã‚Œã€ãƒ¢ãƒ‡ãƒ«ãŒè¤‡æ•°ã®ãƒ‘ã‚¹ã‚’åŒæ™‚ã«æ¢ç´¢ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tydsh/status/1935206012799303817?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2058" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AceReason-Nemotron 1.1: Advancing Math and Code Reasoning through SFT and RL Synergy, Zihan Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã¨å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã®ç›¸ä¹—åŠ¹æœã‚’æ¢æ±‚ã—ã€SFTãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®æ•´å‚™ã«ãŠã„ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°ã®å¢—åŠ ãŒæ¨è«–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ç‰¹ã«ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¸©åº¦ã‚’é©åˆ‡ã«èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŠ¹æœã‚’æœ€å¤§åŒ–ã§ãã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã—ãŸã€‚æœ€çµ‚çš„ã«ã€AceReason-Nemotron-1.1ãƒ¢ãƒ‡ãƒ«ã¯ã€å‰ãƒ¢ãƒ‡ãƒ«ã‚’å¤§ããä¸Šå›ã‚Šã€æ•°å­¦ãŠã‚ˆã³ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ–°ãŸãªæœ€å…ˆç«¯æ€§èƒ½ã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ychennlp/status/1935005283178492222?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>æ§˜ã€…ãªtakeawayãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚<p>SFT,RLã«åˆ©ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚‚å…¬é–‹</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1829" target="_blank" rel="noopener noreferrer">Scaling Data-Constrained Language Models, Niklas Muennighoff+, NeurIPS'23</a>
<br><br>ã«ãŠã„ã¦äº‹å‰å­¦ç¿’æ™‚ã«4 epochã¾ã§ã¯æ€§èƒ½ã®æ”¹å–„å¹…ãŒå¤§ãã„ã¨å ±å‘Šã•ã‚Œã¦ã„ãŸãŒã€SFTã§ã‚‚5 epochç¨‹åº¦ã¾ã§å­¦ç¿’ã™ã‚‹ã¨è‰¯ã„æ¨¡æ§˜ã€‚<br><br>ã¾ãŸã€SFT dataã‚’scalingã•ã›ã‚‹éš›ã¯ã€promptã®æ•°ã ã‘ã§ãªãã€promptå˜ä½ã®responseæ•°ã‚’å¢—ã‚„ã™ã®ãŒåŠ¹æœçš„<br><img src="https://github.com/user-attachments/assets/67e2a4ff-555b-4e22-a90a-ee239704805e" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2054" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Direct Reasoning Optimization: LLMs Can Reward And Refine Their Own  Reasoning for Open-Ended Tasks, Yifei Xu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- DROï¼ˆç›´æ¥æ¨è«–æœ€é©åŒ–ï¼‰ã‚’ææ¡ˆã—ã€LLMsã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ã®é•·æ–‡æ¨è«–ã‚¿ã‚¹ã‚¯ã«å¾®èª¿æ•´ã™ã‚‹ãŸã‚ã®å¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã€‚æ–°ã—ã„å ±é…¬ä¿¡å·R3ã‚’ç”¨ã„ã¦æ¨è«–ã¨å‚ç…§çµæœã®ä¸€è²«æ€§ã‚’æ‰ãˆã€è‡ªå·±å®Œçµã—ãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿç¾ã€‚ParaRevã¨FinQAã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€åºƒç¯„ãªé©ç”¨å¯èƒ½æ€§ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1934957116571451409?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2053" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Wait, We Don't Need to "Wait" Removing Thinking Tokens Improves  Reasoning Efficiency, Chenlong Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±åçœã‚’æŠ‘åˆ¶ã™ã‚‹ã€ŒNoWaitã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€æ¨è«–ã®åŠ¹ç‡ã‚’å‘ä¸Šã€‚10ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å¤§27%-51%ã®æ€è€ƒã®é€£é–ã®é•·ã•ã‚’å‰Šæ¸›ã—ã€æœ‰ç”¨æ€§ã‚’ç¶­æŒã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ã®ãŸã‚ã®åŠ¹æœçš„ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>Wait, Hmmã¨ã„ã£ãŸlong CoTã‚’èª˜å°ã™ã‚‹ã‚ˆã†ãªtokenã‚’æŠ‘åˆ¶ã™ã‚‹ã“ã¨ã§ã€Accã¯ã»ã¼å¤‰ã‚ã‚‰ãšã«ç”Ÿæˆã•ã‚Œã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å‰Šæ¸›å¯èƒ½ã€ã¨ã„ã£ãŸå›³ã«è¦‹ãˆã‚‹ã€‚Reasoningãƒ¢ãƒ‡ãƒ«ã§ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é€Ÿåº¦ã‚’å‘ä¸Šã—ãŸã„å ´åˆã«åŠ¹æœãŒã‚ã‚Šãã†ã€‚<br><img src="https://github.com/user-attachments/assets/c0abd2b4-f019-435e-b72f-f588fa0eb782" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1935130111608492060?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2052" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and  Training Factors Shape LLM Alignment Quality, Yuto Harada+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- SFTã¯LLMã‚’äººé–“ã®æŒ‡ç¤ºã«æ•´åˆã•ã›ã‚‹é‡è¦ãªãƒ—ãƒ­ã‚»ã‚¹ã§ã‚ã‚Šã€1,000ä»¥ä¸Šã®SFTãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿæˆã—ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç‰¹æ€§ã¨å±¤ã”ã¨ã®å¤‰æ›´ã‚’èª¿æŸ»ã€‚è¨“ç·´ã‚¿ã‚¹ã‚¯ã®ç›¸ä¹—åŠ¹æœã‚„ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ã®æˆ¦ç•¥ã®é‡è¦æ€§ã‚’æ˜ã‚‰ã‹ã«ã—ã€å›°æƒ‘åº¦ãŒSFTã®åŠ¹æœã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ä¸­é–“å±¤ã®é‡ã¿ã®å¤‰åŒ–ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã¨å¼·ãç›¸é–¢ã—ã€ç ”ç©¶ã‚’åŠ é€Ÿã•ã›ã‚‹ãŸã‚ã«ãƒ¢ãƒ‡ãƒ«ã¨çµæœã‚’å…¬é–‹äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1935191113981403359?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>NLP'25:


<a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/C10-6.pdf" target="_blank" rel="noopener noreferrer">https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/C10-6.pdf</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/FactualKnowledge.html" target="_blank" rel="noopener noreferrer">#FactualKnowledge</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2049" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] What Is Seen Cannot Be Unseen: The Disruptive Effect of Knowledge  Conflict on Large Language Models, Kaiser Sun+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®æ–‡è„ˆæƒ…å ±ã¨ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯çŸ¥è­˜ã®å¯¾ç«‹ã‚’è©•ä¾¡ã™ã‚‹è¨ºæ–­ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚çŸ¥è­˜ã®å¯¾ç«‹ã¯ã‚¿ã‚¹ã‚¯ã«å½±éŸ¿ã‚’ä¸ãˆãšã€ä¸€è‡´æ™‚ã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã€‚ãƒ¢ãƒ‡ãƒ«ã¯å†…éƒ¨çŸ¥è­˜ã‚’æŠ‘åˆ¶ã§ããšã€å¯¾ç«‹ã®ç†ç”±ãŒæ–‡è„ˆä¾å­˜ã‚’é«˜ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMã®è©•ä¾¡ã¨å±•é–‹ã«ãŠã‘ã‚‹çŸ¥è­˜ã®å¯¾ç«‹ã®é‡è¦æ€§ãŒå¼·èª¿ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kaiserwholearns/status/1934582217692295268?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2048" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Overclocking LLM Reasoning: Monitoring and Controlling Thinking Path  Lengths in LLMs, Roy Eisenstadt+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã‘ã‚‹æ€è€ƒæ®µéšã®é•·ã•ã‚’èª¿æ•´ã™ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æ¢æ±‚ã€‚é€²æ—ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€å¯è¦–åŒ–ã™ã‚‹ã“ã¨ã§è¨ˆç”»ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’æ˜ã‚‰ã‹ã«ã—ã€ä¸è¦ãªã‚¹ãƒ†ãƒƒãƒ—ã‚’æ¸›ã‚‰ã™ã€Œã‚ªãƒ¼ãƒãƒ¼ã‚¯ãƒ­ãƒƒã‚­ãƒ³ã‚°ã€æ‰‹æ³•ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è€ƒãˆã™ãã‚’è»½æ¸›ã—ã€å›ç­”ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€æ¨è«–ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’æ¸›å°‘ã•ã›ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1934357202619310559?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2047" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive  Programming?, Zihan Zheng+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã§äººé–“ã®ã‚¨ãƒªãƒ¼ãƒˆã‚’ä¸Šå›ã‚‹ã¨ã•ã‚Œã‚‹ãŒã€å®Ÿéš›ã«ã¯é‡è¦ãªé™ç•ŒãŒã‚ã‚‹ã“ã¨ã‚’èª¿æŸ»ã€‚æ–°ãŸã«å°å…¥ã—ãŸã€ŒLiveCodeBench Proã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ã‚ˆã‚Šã€LLMsã¯ä¸­ç¨‹åº¦ã®é›£æ˜“åº¦ã®å•é¡Œã§53%ã®pass@1ã‚’é”æˆã™ã‚‹ä¸€æ–¹ã€é›£ã—ã„å•é¡Œã§ã¯0%ã¨ã„ã†çµæœãŒå¾—ã‚‰ã‚ŒãŸã€‚LLMsã¯å®Ÿè£…é‡è¦–ã®å•é¡Œã§ã¯æˆåŠŸã™ã‚‹ãŒã€è¤‡é›‘ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çš„æ¨è«–ã«ã¯è‹¦åŠ´ã—ã€èª¤ã£ãŸæ­£å½“åŒ–ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒå¤šã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã¨äººé–“ã®å°‚é–€å®¶ã¨ã®é–“ã«é‡è¦ãªã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ä»Šå¾Œã®æ”¹å–„ã®ãŸã‚ã®è¨ºæ–­ãŒæä¾›ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1934433210387296414?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Hardãªå•é¡Œã¯ç¾çŠ¶ã®SoTAãƒ¢ãƒ‡ãƒ«ï¼ˆClaude4ãŒå«ã¾ã‚Œã¦ã„ãªã„ãŒï¼‰ã§ã‚‚æ­£ç­”ç‡0.0%<br><img src="https://github.com/user-attachments/assets/d0e29f23-2b66-4b19-b39a-68f3717d7058" alt="image" loading="lazy"><br><br>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å«ã¾ã‚Œã‚‹èª²é¡Œã®ã‚«ãƒ†ã‚´ãƒª<br><img src="https://github.com/user-attachments/assets/b41b11d7-52a2-4a22-848d-cb08900da5cf" alt="image" loading="lazy"><br><br>å®Ÿã‚µãƒ³ãƒ—ãƒ«ã‚„ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ãªã©ã¯Appendixå‚ç…§ã®ã“ã¨ã€‚</p>
<p>pj page:


<a href="https://livecodebenchpro.com" target="_blank" rel="noopener noreferrer">https://livecodebenchpro.com</a>


</p>
<p>ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ(NeurIPSã«accept):<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhaocha1/status/1969035554252611833?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2046" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware  Reasoning, Yu Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RAG+ã¯ã€Retrieval-Augmented Generationã®æ‹¡å¼µã§ã€çŸ¥è­˜ã®é©ç”¨ã‚’æ„è­˜ã—ãŸæ¨è«–ã‚’çµ„ã¿è¾¼ã‚€ã€‚äºŒé‡ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ç”¨ã„ã¦ã€é–¢é€£æƒ…å ±ã‚’å–å¾—ã—ã€ç›®æ¨™æŒ‡å‘ã®æ¨è«–ã«é©ç”¨ã™ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€RAG+ãŒæ¨™æº–çš„ãªRAGã‚’3-5%ã€è¤‡é›‘ãªã‚·ãƒŠãƒªã‚ªã§ã¯æœ€å¤§7.5%ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã€çŸ¥è­˜çµ±åˆã®æ–°ãŸãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1934667096828399641?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>çŸ¥è­˜ã ã‘ã§ãªãçŸ¥è­˜ã®ä½¿ã„æ–¹ã‚‚è“„ç©ã—ã€åˆ©ç”¨æ™‚ã«æ¤œç´¢ã•ã‚ŒãŸçŸ¥è­˜ã¨ç´ã¥ã„ãŸä½¿ã„æ–¹ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§RAGã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/23f2b2cd-458b-437a-837d-11d4db28162f" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/b6a01788-7a14-41a3-81f7-41a2add62bd1" alt="image" loading="lazy"></p>
<p>Figure 1ã®ã‚ˆã†ãªä¾‹ã¯Reasoningãƒ¢ãƒ‡ãƒ«ãŒé€²åŒ–ã—ã¦ã„ã£ãŸã‚‰ã€ã‚ã–ã‚ã–çŸ¥è­˜ã¨ä½¿ã„æ–¹ã‚’ç´ä»˜ã‘ãªãã¦ã‚‚ã€ä¸–ç•ŒçŸ¥è­˜ã‹ã‚‰ä½¿ã„æ–¹ã‚’è£œå®Œå¯èƒ½ã ã¨æ€ã‚ã‚Œã‚‹ã®ã§ä¸è¦ã¨ãªã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚<br>ãŒã€çœŸã«ã“ã®æ‰‹æ³•ãŒåŠ›ã‚’ç™ºæ®ã™ã‚‹ã®ã¯ã€Œãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®ä½¿ã„æ–¹ã‚„ãƒ«ãƒ¼ãƒ«ã€ãŒå­˜åœ¨ã™ã‚‹å ´åˆã§ã€ã©ã‚Œã ã‘LLMãŒè³¢ããªã£ã¦ã‚‚æ¨è«–ã«ã‚ˆã£ã¦å°ãå‡ºã›ãªã„ã‚‚ã®ã€ã®ã¤ã„ã¦ã¯ã€ã“ã†ã„ã£ãŸæ‰‹æ³•ã¯åŠ¹åŠ›ã‚’ç™ºæ®ã—ç¶šã‘ã‚‹ã®ã§ã¯ãªã„ã‹ã¨æ€ã‚ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2045" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ALE-Bench: A Benchmark for Long-Horizon Objective-Driven Algorithm  Engineering, Yuki Imajuku+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- AIã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–å•é¡Œã«å¯¾ã™ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã™ã‚‹æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ALE-Benchã‚’ææ¡ˆã€‚ALE-Benchã¯å®Ÿéš›ã®ã‚¿ã‚¹ã‚¯ã«åŸºã¥ãã€é•·æœŸçš„ãªè§£æ±ºç­–ã®æ´—ç·´ã‚’ä¿ƒé€²ã™ã‚‹ã€‚å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®è©•ä¾¡ã§ã¯ç‰¹å®šã®å•é¡Œã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ãŒã€ä¸€è²«æ€§ã‚„é•·æœŸçš„ãªå•é¡Œè§£æ±ºèƒ½åŠ›ã«ãŠã„ã¦äººé–“ã¨ã®ã‚®ãƒ£ãƒƒãƒ—ãŒæ®‹ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ä»Šå¾Œã®AIé€²å±•ã«å‘ã‘ãŸå¿…è¦æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sakanaailabs/status/1934767254715117812?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwiwi/status/1934830621756674499?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>NeurIPSã«accept:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/y_imjk/status/1969233840217473291?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<a class="button" href="articles/FactualKnowledge.html" target="_blank" rel="noopener noreferrer">#FactualKnowledge</a>
<a class="button" href="articles/meta-learning.html" target="_blank" rel="noopener noreferrer">#meta-learning</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2044" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] PropMEND: Hypernetworks for Knowledge Propagation in LLMs, Zeyu Leo Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- PropMENDã¯ã€LLMsã«ãŠã‘ã‚‹çŸ¥è­˜ä¼æ’­ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ã€‚ãƒ¡ã‚¿å­¦ç¿’ã‚’ç”¨ã„ã¦ã€æ³¨å…¥ã•ã‚ŒãŸçŸ¥è­˜ãŒãƒãƒ«ãƒãƒ›ãƒƒãƒ—è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã«ä¼æ’­ã™ã‚‹ã‚ˆã†ã«å‹¾é…ã‚’ä¿®æ­£ã™ã‚‹ã€‚RippleEditãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€é›£ã—ã„è³ªå•ã«å¯¾ã—ã¦ç²¾åº¦ãŒã»ã¼2å€å‘ä¸Šã—ã€Controlled RippleEditãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯æ–°ã—ã„é–¢ä¿‚ã‚„ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«å¯¾ã™ã‚‹çŸ¥è­˜ä¼æ’­ã‚’è©•ä¾¡ã€‚PropMENDã¯æ—¢å­˜ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ãŒã€æ€§èƒ½å·®ã¯ç¸®å°ã—ã¦ãŠã‚Šã€ä»Šå¾Œã®ç ”ç©¶ã§åºƒç¯„ãªé–¢ä¿‚ã¸ã®çŸ¥è­˜ä¼æ’­ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zeyuliu10/status/1934659512046330057?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¾“æ¥ã®Knowledge Editingæ‰‹æ³•ã¯æ–°ãŸãªçŸ¥è­˜ã‚’è¨˜æ†¶ã•ã›ã‚‹ã“ã¨ã¯ã§ãã‚‹ï¼ˆi.e., æ³¨å…¥ã—ãŸçŸ¥è­˜ã‚’é€èªçš„ã«ç”Ÿæˆã§ãã‚‹;æ±äº¬ã¯æ—¥æœ¬ã®é¦–éƒ½ã§ã‚ã‚‹ã€‚ï¼‰ãŒã€çŸ¥è­˜ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã¯è‹¦æ‰‹ã ã£ãŸï¼ˆi.e., æ—¥æœ¬ã®é¦–éƒ½ã®æ°—å€™ã¯ï¼Ÿï¼‰ã®ã§ã€ãã‚Œã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br>æ—¢å­˜æ‰‹æ³•ã®limitationã¯<br>- editingæ‰‹æ³•ã§å­¦ç¿’ã‚’ã™ã‚‹éš›ã«çŸ¥è­˜ã‚’ä¼æ¬ã•ã›ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒç„¡ã<br>- ç›®çš„é–¢æ•°ãŒraw textã§ã¯ãªãã€QA pairã‚’SFTã™ã‚‹ã“ã¨<br><br>ã«ã‚ˆã£ã¦ç”Ÿã˜ã‚‹ã¨ã—ã€<br><br>- å­¦ç¿’æ™‚ã«propagation questionï¼ˆFigure1ã®ã‚ªãƒ¬ãƒ³ã‚¸è‰²ã®QA; æ³¨å…¥ã—ãŸçŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦æ¨è«–ãŒå¿…è¦ãªQA)ã‚’ç”¨æ„ã—ã©ã®ã‚ˆã†ã«çŸ¥è­˜ã‚’ä¼æ¬ï¼ˆæ´»ç”¨ï¼‰ã•ã›ã‚‹ã‹ã‚’å­¦ç¿’ã—<br>- ç›®çš„é–¢æ•°ã‚’Causal Language Modeling Loss<br><br>ã«ã™ã‚‹ã“ã¨ã§æ”¹å–„ã™ã‚‹ã€ã¨ã®ã“ã¨ã€‚<br><br><img src="https://github.com/user-attachments/assets/3f915a57-89c9-412f-a950-f86d35d72cd3" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/50cbbdba-c23e-405d-8ed1-1deea14d3384" alt="image" loading="lazy"><br><br>non-verbatimãªQAï¼ˆæ³¨å…¥ã•ã‚ŒãŸçŸ¥è­˜ã‚’ãã®ã¾ã¾å›ç­”ã™ã‚‹ã‚‚ã®ã§ã¯ãªãã€ä½•ã‚‰ã‹ã®æ¨è«–ãŒå¿…è¦ãªã‚‚ã®ï¼‰ã§ã‚‚æ€§èƒ½ãŒå‘ä¸Šã€‚<br><img src="https://github.com/user-attachments/assets/ebae00b4-d622-4c45-9eca-abfc23762c25" alt="image" loading="lazy"></p>
<p>ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/643" target="_blank" rel="noopener noreferrer">Mass-Editing Memory in a Transformer, Kevin Meng+, N/A, ICLR'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2055" target="_blank" rel="noopener noreferrer">[Paper Note] Fast Model Editing at Scale, Eric Mitchell+, ICLR'22</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/OptimalTransport.html" target="_blank" rel="noopener noreferrer">#OptimalTransport</a>
<span class="issue_date">Issue Date: 2025-06-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2040" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Steer LLM Latents for Hallucination Detection, Seongheon Park+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®å¹»è¦šå•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€Truthfulness Separator Vectorï¼ˆTSVï¼‰ã‚’ææ¡ˆã€‚TSVã¯ã€LLMã®è¡¨ç¾ç©ºé–“ã‚’å†æ§‹ç¯‰ã—ã€çœŸå®Ÿã¨å¹»è¦šã®å‡ºåŠ›ã‚’åˆ†é›¢ã™ã‚‹è»½é‡ãªæŒ‡å‘ãƒ™ã‚¯ãƒˆãƒ«ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã›ãšã«æ©Ÿèƒ½ã€‚äºŒæ®µéšã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€å°‘æ•°ã®ãƒ©ãƒ™ãƒ«ä»˜ãä¾‹ã‹ã‚‰TSVã‚’è¨“ç·´ã—ã€ãƒ©ãƒ™ãƒ«ã®ãªã„ç”Ÿæˆç‰©ã‚’æ‹¡å¼µã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€TSVã¯æœ€å°é™ã®ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€å®Ÿä¸–ç•Œã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹å®Ÿç”¨çš„ãªè§£æ±ºç­–ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sharonyixuanli/status/1933522788645810493?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>openreview: 


<a href="https://openreview.net/forum?id=UMqNQEPNT3&noteId=mAbrf36RHa" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=UMqNQEPNT3&noteId=mAbrf36RHa</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Reproducibility.html" target="_blank" rel="noopener noreferrer">#Reproducibility</a>
<span class="issue_date">Issue Date: 2025-06-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2039" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Give Me FP32 or Give Me Death? Challenges and Solutions for Reproducible  Reasoning, Jiayi Yuan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å†ç¾æ€§ãŒè„†å¼±ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆã®å¤‰æ›´ãŒå¿œç­”ã«å¤§ããªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã—ãŸã€‚ç‰¹ã«ã€åˆæœŸãƒˆãƒ¼ã‚¯ãƒ³ã®ä¸¸ã‚èª¤å·®ãŒæ¨è«–ç²¾åº¦ã«æ³¢åŠã™ã‚‹å•é¡Œã‚’æŒ‡æ‘˜ã—ã€æµ®å‹•å°æ•°ç‚¹æ¼”ç®—ã®éçµåˆçš„æ€§è³ªãŒå¤‰å‹•ã®æ ¹æœ¬åŸå› ã§ã‚ã‚‹ã¨ã—ã¦ã„ã¾ã™ã€‚æ§˜ã€…ãªæ¡ä»¶ä¸‹ã§ã®å®Ÿé¨“ã‚’é€šã˜ã¦ã€æ•°å€¤ç²¾åº¦ãŒå†ç¾æ€§ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’å®šé‡åŒ–ã—ã€è©•ä¾¡å®Ÿè·µã«ãŠã‘ã‚‹é‡è¦æ€§ã‚’å¼·èª¿ã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€LayerCastã¨ã„ã†è»½é‡æ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é–‹ç™ºã—ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã¨æ•°å€¤å®‰å®šæ€§ã‚’ä¸¡ç«‹ã•ã›ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2025-06-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2036" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Adapting Language Models, Adam Zweiger+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±é©å¿œå‹LLMsï¼ˆSEALï¼‰ã‚’ææ¡ˆã—ã€ãƒ¢ãƒ‡ãƒ«ãŒè‡ªèº«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨æŒ‡ç¤ºã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§é©å¿œã‚’å®Ÿç¾ã€‚æ–°ã—ã„å…¥åŠ›ã«å¯¾ã—ã¦è‡ªå·±ç·¨é›†ã‚’è¡Œã„ã€æŒç¶šçš„ãªé‡ã¿ã®æ›´æ–°ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚å¼·åŒ–å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã‚’ç”¨ã„ã¦ä¸‹æµæ€§èƒ½ã‚’å ±é…¬ä¿¡å·ã¨ã—ã¦æ´»ç”¨ã—ã€å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ç•°ãªã‚Šã€ãƒ¢ãƒ‡ãƒ«è‡ªèº«ã®ç”Ÿæˆã‚’ç”¨ã„ã¦é©å¿œã‚’åˆ¶å¾¡ã€‚å®Ÿé¨“çµæœã¯SEALã®æœ‰æœ›æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jyo_pari/status/1933350025284702697?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆCã¨è©•ä¾¡ãƒ‡ãƒ¼ã‚¿tauãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€Cã‚’å…¥åŠ›ã—ãŸæ™‚ã«ãƒ¢ãƒ‡ãƒ«ãŒè‡ªåˆ†ã‚’SFTã—ã€tauä¸Šã§ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’å¾—ã‚‰ã‚Œã‚‹ã‚ˆã†ãªã‚µãƒ³ãƒ—ãƒ« Self Edit (SE) ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€æ€§èƒ½ã‚’å‘ä¸Šã•ã›ãŸã„ã€‚ã“ã‚Œã‚’RLã«ã‚ˆã£ã¦å®Ÿç¾ã™ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€ä¸‹è¨˜ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«ã«SEã‚’ç”Ÿæˆã•ã›ã€SEã§SFTã™ã‚‹ã“ã¨ã‚ã«tauä¸Šã§ã®æ€§èƒ½ãŒå‘ä¸Šã—ãŸã‹å¦ã‹ã®binary rewardã‚’ç”¨ã„ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚’ç¹°ã‚Šè¿”ã™ã€‚ã“ã‚Œã¯å®Ÿè³ªã€RL_updateã¨æ›¸ã„ã¦ã‚ã‚‹ãŒã€æ€§èƒ½ãŒå‘ä¸Šã—ãŸè‰¯ã„SEã®ã¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’SFTã™ã‚‹ã“ã¨ã€ã¨åŒç­‰ãªã“ã¨ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/69a395da-521f-444d-af6f-4c1b25bb6765" alt="image" loading="lazy"><br><br>ã“ã®ã‚ˆã†ãªèƒŒæ™¯ã¨ã—ã¦ã€RLã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨ã—ã¦GRPOã‚„PPOã‚’é©ç”¨ã—ãŸã¨ã“ã‚å­¦ç¿’ãŒä¸å®‰å®šã§ã†ã¾ãã„ã‹ãªã‹ã£ãŸãŸã‚ã€ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ReST^EMï¼ˆ<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2041" target="_blank" rel="noopener noreferrer">[Paper Note] Beyond Human Data: Scaling Self-Training for Problem-Solving with   Language Models, Avi Singh+, TMLR'24</a>
)ã‚’æ¡ç”¨ã—ãŸã€‚ã“ã‚Œã¯rejection samplingã¨SFTã«åŸºã¥ã„ãŸEMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ã‚ˆã†ãªã‚‚ã®ã‚‰ã—ãã€Eã‚¹ãƒ†ãƒƒãƒ—ã§ç¾åœ¨ã®ãƒãƒªã‚·ãƒ¼ã§candidateã‚’ç”Ÿæˆã—ã€Mã‚¹ãƒ†ãƒƒãƒ—ã§positive rewardã‚’å¾—ãŸcandidateã®ã¿ï¼ˆï¼rejection sampling)ã§SFTã™ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚’ç¹°ã‚Šè¿”ã™ã€ã¿ãŸã„ãªæ‰‹æ³•ã‚‰ã—ã„ã€‚ã“ã‚Œã‚’ç”¨ã„ã‚‹ã¨ã€è«–æ–‡ä¸­ã®å¼(1)ã‚’ä¸Šè¿°ã®binary rewardã§è¿‘ä¼¼ã™ã‚‹ã“ã¨ã«ç›¸å½“ã™ã‚‹ã€‚ã‚ˆã‚Šè©³ç´°ã«æ›¸ãã¨ã€å¼(1)ï¼ˆã¤ã¾ã‚Šã€SEã‚’Cã‹ã‚‰ç”Ÿæˆã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦å¾—ã‚‰ã‚Œã‚‹tauã«åŸºã¥ãå ±é…¬rã®ç·å ±é…¬ã‚’æœ€å¤§åŒ–ã—ãŸã„ã€ã¨ã„ã†å¼ï¼‰ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã«Î¸_tã®å‹¾é…ã‚’è¨ˆç®—ã—ãŸã„ãŒã€reward rãŒÎ¸_tã§å¾®åˆ†ä¸å¯èƒ½ãªãŸã‚ã€Monte Carlo Estimatorã§å‹¾é…ã‚’è¿‘ä¼¼ã™ã‚‹ã€ã¿ãŸã„ãªã“ã¨ã‚’ã‚„ã‚‹ã‚‰ã—ã„ã€‚Monte Carlo Estimatorã§ã¯å®Ÿéš›ã®ã‚µãƒ³ãƒ—ãƒ«ã®æœŸå¾…å€¤ã«ã‚ˆã£ã¦ç†è«–çš„ãªå‹¾é…ã‚’è¿‘ä¼¼ã™ã‚‹ã‚‰ã—ãã€ã“ã‚ŒãŒå¼(3)ã®ã‚¹ã‚³ã‚¢é–¢æ•°ã¨reward rã®å¹³å‡ã€ã¨ã„ã£ãŸå¼ã«ã¤ãªãŒã£ã¦ã„ã‚‹ã‚ˆã†ã§ã‚ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2035" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Resa: Transparent Reasoning Models via SAEs, Shangshang Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Resaã¨ã„ã†1.5Bã®æ¨è«–ãƒ¢ãƒ‡ãƒ«ç¾¤ã‚’ææ¡ˆã—ã€åŠ¹ç‡çš„ãªã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSAE-Tuningï¼‰æ‰‹æ³•ã‚’ç”¨ã„ã¦è¨“ç·´ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€97%ä»¥ä¸Šã®æ¨è«–æ€§èƒ½ã‚’ä¿æŒã—ã¤ã¤ã€è¨“ç·´ã‚³ã‚¹ãƒˆã‚’2000å€ä»¥ä¸Šå‰Šæ¸›ã—ã€è¨“ç·´æ™‚é–“ã‚’450å€ä»¥ä¸ŠçŸ­ç¸®ã€‚è»½ã„RLè¨“ç·´ã‚’æ–½ã—ãŸãƒ¢ãƒ‡ãƒ«ã§é«˜ã„æ¨è«–æ€§èƒ½ã‚’å®Ÿç¾ã—ã€æŠ½å‡ºã•ã‚ŒãŸæ¨è«–èƒ½åŠ›ã¯ä¸€èˆ¬åŒ–å¯èƒ½ã‹ã¤ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–å¯èƒ½ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚å…¨ã¦ã®æˆæœç‰©ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1933101904529363112?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/upupwang/status/1933207676663865482?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è«–æ–‡ä¸­ã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹Source Modelã®ä¸€ã¤:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1935" target="_blank" rel="noopener noreferrer">Tina: Tiny Reasoning Models via LoRA, Shangshang Wang+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-06-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2033" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Text-to-LoRA: Instant Transformer Adaption, Rujikorn Charakorn+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- Text-to-LoRAï¼ˆT2Lï¼‰ã¯ã€è‡ªç„¶è¨€èªã«ã‚ˆã‚‹èª¬æ˜ã«åŸºã¥ã„ã¦å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’è¿…é€Ÿã«é©å¿œã•ã›ã‚‹æ‰‹æ³•ã§ã€å¾“æ¥ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®é«˜ã‚³ã‚¹ãƒˆã¨æ™‚é–“ã‚’å…‹æœã—ã¾ã™ã€‚T2Lã¯ã€LoRAã‚’å®‰ä¾¡ãªãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã§æ§‹ç¯‰ã™ã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã€ã‚¿ã‚¹ã‚¯ç‰¹æœ‰ã®ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¾ã™ã€‚ã¾ãŸã€æ•°ç™¾ã®LoRAã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’åœ§ç¸®ã—ã€æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§ä¸€èˆ¬åŒ–å¯èƒ½ã§ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å°‚é–€åŒ–ã‚’æ°‘ä¸»åŒ–ã—ã€è¨ˆç®—è¦ä»¶ã‚’æœ€å°é™ã«æŠ‘ãˆãŸè¨€èªãƒ™ãƒ¼ã‚¹ã®é©å¿œã‚’å®Ÿç¾ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/roberttlange/status/1933074366603919638?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãªã€ãªã‚‹ã»ã©ã€ã“ã‚“ãªæ‰‹ãŒâ€¦ï¼</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-06-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2032" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Go-Browse: Training Web Agents with Structured Exploration, Apurva Gandhi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Go-Browseã‚’ææ¡ˆã—ã€ã‚¦ã‚§ãƒ–ç’°å¢ƒã®æ§‹é€ çš„æ¢ç´¢ã‚’é€šã˜ã¦å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•åé›†ã€‚ã‚°ãƒ©ãƒ•æ¢ç´¢ã‚’ç”¨ã„ã¦åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿åé›†ã‚’å®Ÿç¾ã—ã€WebArenaãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æˆåŠŸç‡21.7%ã‚’é”æˆã€‚ã“ã‚Œã¯GPT-4o miniã‚’2.4%ä¸Šå›ã‚Šã€10Bæœªæº€ã®ãƒ¢ãƒ‡ãƒ«ã§ã®æœ€å…ˆç«¯çµæœã‚’2.9%ä¸Šå›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1932786231542493553?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>WebArena:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1849" target="_blank" rel="noopener noreferrer">WebArena: A Realistic Web Environment for Building Autonomous Agents, Shuyan Zhou+, ICLR'24</a>
</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2025-06-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2031" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reinforcement Pre-Training, Qingxiu Dong+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¼·åŒ–å­¦ç¿’ã¨å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ–°ã—ã„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ‰‹æ³•ã€Œå¼·åŒ–äº‹å‰å­¦ç¿’ï¼ˆRPTï¼‰ã€ã‚’ææ¡ˆã€‚æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã‚’å¼·åŒ–å­¦ç¿’ã®æ¨è«–ã‚¿ã‚¹ã‚¯ã¨ã—ã¦å†å®šç¾©ã—ã€ä¸€èˆ¬çš„ãªRLã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ã®æ³¨é‡ˆã«ä¾å­˜ã›ãšã«ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªæ–¹æ³•ã‚’æä¾›ã€‚RPTã¯æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€å¼·åŒ–ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŸºç›¤ã‚’å½¢æˆã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨ˆç®—é‡ã®å¢—åŠ ãŒç²¾åº¦ã‚’æ”¹å–„ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã€RPTãŒè¨€èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ã«ãŠã„ã¦æœ‰æœ›ãªæ‰‹æ³•ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1932922314578145640?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-06-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2030" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Value Residual Learning, Zhanchao Zhou+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- ResFormerã¯ã€éš ã‚ŒçŠ¶æ…‹ã®æ®‹å·®ã«å€¤ã®æ®‹å·®æ¥ç¶šã‚’åŠ ãˆã‚‹ã“ã¨ã§æƒ…å ±ã®æµã‚Œã‚’å¼·åŒ–ã™ã‚‹æ–°ã—ã„Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ææ¡ˆã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ResFormerã¯å¾“æ¥ã®Transformerã«æ¯”ã¹ã¦å°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã§åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ã€SVFormerã¯KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã‚’åŠæ¸›ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚æ€§èƒ½ã¯ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é•·ã•ã‚„å­¦ç¿’ç‡ã«ä¾å­˜ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhanchaozhou/status/1932829678081098079?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/user-attachments/assets/c2c97ea1-0930-4033-85bd-b3618463f87a" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-06-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2027" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Saffron-1: Towards an Inference Scaling Paradigm for LLM Safety  Assurance, Ruizhong Qiu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ—¢å­˜ã®LLMã®å®‰å…¨ä¿è¨¼ç ”ç©¶ã¯ä¸»ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ®µéšã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ãŒã€è„±ç„æ”»æ’ƒã«å¯¾ã—ã¦è„†å¼±ã§ã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ¨è«–ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ç”¨ã„ãŸæ–°ãŸãªå®‰å…¨æ€§å‘ä¸Šæ‰‹æ³•SAFFRONã‚’ææ¡ˆã—ã€è¨ˆç®—ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å‰Šæ¸›ã™ã‚‹å¤šåˆ†å²å ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼ˆMRMï¼‰ã‚’å°å…¥ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å ±é…¬ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®æ•°ã‚’æ¸›ã‚‰ã—ã€æ¢ç´¢-åŠ¹ç‡æ€§ã®ã‚¸ãƒ¬ãƒ³ãƒã‚’å…‹æœã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šæ‰‹æ³•ã®æœ‰åŠ¹æ€§ã‚’ç¢ºèªã—ã€è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨å®‰å…¨å ±é…¬ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gaotangli/status/1932289294657626189?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Subword.html" target="_blank" rel="noopener noreferrer">#Subword</a>
<span class="issue_date">Issue Date: 2025-06-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2026" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] StochasTok: Improving Fine-Grained Subword Understanding in LLMs, Anya Sims+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚µãƒ–ãƒ¯ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«ã®ç†è§£ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€ç¢ºç‡çš„ãƒˆãƒ¼ã‚¯ãƒ³åŒ–æ‰‹æ³•StochasTokã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã¯å†…éƒ¨æ§‹é€ ã‚’æŠŠæ¡ã—ã‚„ã™ããªã‚Šã€æ–‡å­—ã‚«ã‚¦ãƒ³ãƒˆã‚„æ•°å­¦ã‚¿ã‚¹ã‚¯ãªã©ã§æ€§èƒ½ãŒå‘ä¸Šã€‚ã‚·ãƒ³ãƒ—ãƒ«ãªè¨­è¨ˆã«ã‚ˆã‚Šã€æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã¸ã®çµ±åˆãŒå®¹æ˜“ã§ã€ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã¤ã¤ã‚µãƒ–ãƒ¯ãƒ¼ãƒ‰ç†è§£ã‚’æ”¹å–„ã§ãã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cong_ml/status/1932369418534760554?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãŠã‚‚ã—ã‚ãã†</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-06-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2025" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Log-Linear Attention, Han Guo+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¯¾æ•°ç·šå½¢æ³¨æ„ã‚’ææ¡ˆã—ã€ç·šå½¢æ³¨æ„ã®åŠ¹ç‡æ€§ã¨ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹æ³¨æ„ã®è¡¨ç¾åŠ›ã‚’ä¸¡ç«‹ã€‚å›ºå®šã‚µã‚¤ã‚ºã®éš ã‚ŒçŠ¶æ…‹ã‚’å¯¾æ•°çš„ã«æˆé•·ã™ã‚‹éš ã‚ŒçŠ¶æ…‹ã«ç½®ãæ›ãˆã€è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å¯¾æ•°ç·šå½¢ã«æŠ‘ãˆã‚‹ã€‚Mamba-2ã¨Gated DeltaNetã®å¯¾æ•°ç·šå½¢ãƒãƒªã‚¢ãƒ³ãƒˆãŒç·šå½¢æ™‚é–“ã®ãƒãƒªã‚¢ãƒ³ãƒˆã¨æ¯”è¼ƒã—ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1932194773559107911?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1931432543766847887?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-06-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2023" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Representation Shattering in Transformers: A Synthetic Study with   Knowledge Editing, Kento Nishi+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- çŸ¥è­˜ç·¨é›†ï¼ˆKEï¼‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’å¤‰æ›´ã—ã¦ä¸æ­£ç¢ºãªäº‹å®Ÿã‚’æ›´æ–°ã™ã‚‹ãŒã€ã“ã‚ŒãŒãƒ¢ãƒ‡ãƒ«ã®äº‹å®Ÿã®æƒ³èµ·ç²¾åº¦ã‚„æ¨è«–èƒ½åŠ›ã«æ‚ªå½±éŸ¿ã‚’åŠã¼ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚æ–°ãŸã«å®šç¾©ã—ãŸåˆæˆã‚¿ã‚¹ã‚¯ã‚’é€šã˜ã¦ã€KEãŒã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’è¶…ãˆã¦ä»–ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®è¡¨ç¾ã«å½±éŸ¿ã‚’ä¸ãˆã€æœªè¦‹ã®çŸ¥è­˜ã®æ¨è«–ã‚’æ­ªã‚ã‚‹ã€Œè¡¨ç¾ã®ç ´å£Šã€ç¾è±¡ã‚’ç¤ºã™ã€‚äº‹å‰è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã‚‚ã“ã®ç™ºè¦‹ãŒç¢ºèªã•ã‚Œã€KEãŒãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã«æ‚ªå½±éŸ¿ã‚’åŠã¼ã™ç†ç”±ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ä»®èª¬ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kento_nishi/status/1932072335726539063?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-06-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2022" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Search Arena: Analyzing Search-Augmented LLMs, Mihran Miroyan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¤œç´¢å¼·åŒ–å‹LLMsã«é–¢ã™ã‚‹ã€ŒSearch Arenaã€ã¨ã„ã†å¤§è¦æ¨¡ãªäººé–“ã®å¥½ã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç´¹ä»‹ã€‚24,000ä»¥ä¸Šã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’å«ã¿ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ãŒå¼•ç”¨æ•°ã‚„å¼•ç”¨å…ƒã«å½±éŸ¿ã•ã‚Œã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚ç‰¹ã«ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ä¸»å°ã®æƒ…å ±æºãŒå¥½ã¾ã‚Œã‚‹å‚¾å‘ãŒã‚ã‚Šã€é™çš„ãªæƒ…å ±æºã¯å¿…ãšã—ã‚‚ä¿¡é ¼ã•ã‚Œãªã„ã€‚æ¤œç´¢å¼·åŒ–å‹LLMsã®æ€§èƒ½ã‚’è©•ä¾¡ã—ãŸçµæœã€éæ¤œç´¢è¨­å®šã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸ŠãŒç¢ºèªã•ã‚ŒãŸãŒã€æ¤œç´¢è¨­å®šã§ã¯ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯çŸ¥è­˜ã«ä¾å­˜ã™ã‚‹ã¨å“è³ªãŒä½ä¸‹ã™ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æä¾›ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mirmiroyan/status/1931081734764081391?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-06-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2019" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning  Logical Reasoning and Beyond, Junteng Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- SynLogicã¯ã€35ã®è«–ç†çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã‚’ç¶²ç¾…ã—ãŸãƒ‡ãƒ¼ã‚¿åˆæˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã«ã‚ˆã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ¨è«–èƒ½åŠ›å‘ä¸Šã‚’ç›®æŒ‡ã™ã€‚èª¿æ•´å¯èƒ½ãªé›£æ˜“åº¦ã§ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯æ¤œè¨¼å¯èƒ½ã§ã€RLã«é©ã—ã¦ã„ã‚‹ã€‚å®Ÿé¨“ã§ã¯ã€SynLogicãŒæœ€å…ˆç«¯ã®è«–ç†çš„æ¨è«–æ€§èƒ½ã‚’é”æˆã—ã€æ•°å­¦ã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã¨ã®æ··åˆã«ã‚ˆã‚Šãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚SynLogicã¯LLMsã®æ¨è«–èƒ½åŠ›å‘ä¸Šã«è²´é‡ãªãƒªã‚½ãƒ¼ã‚¹ã¨ãªã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/junxian_he/status/1930558456907669638?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>35ç¨®é¡ã®ã‚¿ã‚¹ã‚¯ã‚’äººæ‰‹ã§é¸å®šã—ã€ã‚¿ã‚¹ã‚¯ã”ã¨ã«å›°é›£åº¦ã®éµã¨ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©ï¼ˆæ•°ç‹¬ãªã‚‰ã°ã‚°ãƒªãƒƒãƒ‰æ•°ãªã©ï¼‰ã€‚ãã®ä¸Šã§ã€å„ã‚¿ã‚¹ã‚¯ã”ã¨ã«äººæ‰‹ã§ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®instanceã‚’ç”Ÿæˆã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè£…ã—ã€ã•ã¾ã–ã¾ãªå›°é›£åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦å¤šæ§˜ãªinstanceã‚’ç”Ÿæˆã€‚ç”Ÿæˆã•ã‚ŒãŸinstanceã®å›°é›£åº¦ã¯ã€è¿‘ä¼¼çš„ãªUpper Bound(DeepSeek-R1, o3-miniã®Pass@10)ã¨Lower boundï¼ˆchat model[^1]ã§ã®Pass@10)ã‚’æ±‚ã‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å«ã¾ã‚Œã‚‹instanceã®å›°é›£åº¦ã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã—ã€taskã‚’è¨˜è¿°ã™ã‚‹promptã‚‚ç”Ÿæˆã€‚ã‚¿ã‚¹ã‚¯ã”ã¨ã«äººæ‰‹ã§å®Ÿè£…ã•ã‚ŒãŸVerifierã‚‚ç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/cda0534d-7db2-4470-93b8-01f446476544" alt="image" loading="lazy"><br><br>Qwen2.5-7B-Baseã‚’SynDataã§DAPOã—ãŸã¨ã“ã‚ã€å¤§å¹…ã«logic benchmarkã¨mathematical benchmarkã®æ€§èƒ½ãŒæ”¹å–„ã€‚<br><img src="https://github.com/user-attachments/assets/dcc1309d-7946-4a6d-91a3-7ccac9ec6688" alt="image" loading="lazy"><br><br>mathã‚„codeã®ãƒ‡ãƒ¼ã‚¿ã¨mixã—ã¦7Bãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ãŸã¨ã“ã‚ã€32Bãƒ¢ãƒ‡ãƒ«ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’é”æˆã—ã€SynDataã‚’mixã™ã‚‹ã“ã¨ã§gainãŒå¤§ãããªã£ãŸã®ã§ã€SynDataã‹ã‚‰å­¦ç¿’ã§ãã‚‹èƒ½åŠ›ãŒæ±åŒ–ã™ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/7b618fe9-5271-434b-9808-f53f0e758e5e" alt="image" loading="lazy"><br><br>ã‚¿ã‚¹ã‚¯ä¸€è¦§ã¯ã“ã¡ã‚‰<br><img src="https://github.com/user-attachments/assets/50fcdcb3-701e-4d42-94c7-201d8d354d75" alt="image" loading="lazy"><br><br>[^1]:ã©ã®chat modelã‹ã¯ã–ã£ã¨è¦‹ãŸæ„Ÿã˜ã‚ã‹ã‚‰ãªã„ã€‚ã©ã“ã‹ã«æ›¸ã„ã¦ã‚ã‚‹ã‹ã‚‚ã€‚</p>
<p>Logical ReasoningãŒé‡è¦ãªã‚¿ã‚¹ã‚¯ã‚’æ‰±ã†éš›ã¯ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ã¿ã¦ã‚‚è‰¯ã„ã‹ã‚‚ã—ã‚Œãªã„</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-06-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2018" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Training Language Models to Generate Quality Code with Program Analysis  Feedback, Feng Yao+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ­ã‚°ãƒ©ãƒ åˆ†æã«åŸºã¥ããƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”¨ã„ãŸå¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒREALã€ã‚’ææ¡ˆã€‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚„ä¿å®ˆæ€§ã®æ¬ é™¥ã‚’æ¤œå‡ºã—ã€æ©Ÿèƒ½çš„æ­£ç¢ºæ€§ã‚’ä¿è¨¼ã™ã‚‹ã“ã¨ã§ã€LLMsã«ã‚ˆã‚‹é«˜å“è³ªãªã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚’ä¿ƒé€²ã€‚æ‰‹å‹•ä»‹å…¥ä¸è¦ã§ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªç›£è¦–ã‚’å®Ÿç¾ã—ã€å®Ÿé¨“ã«ã‚ˆã‚Šæœ€å…ˆç«¯ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fengyao1909/status/1930377346693116350?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¾åœ¨ã®Coding LLMã¯UnitTestã‚’é€šã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã‚‹ãŒã€UnitTestã«é€šã‚‹ã‹ã‚‰ã¨ã„ã£ã¦ã‚³ãƒ¼ãƒ‰ã®å“è³ªãŒè‰¯ã„ã‚ã‘ã§ã¯ç„¡ã„ã®ã§ã€UnitTestã«é€šã‚‹ã‹å¦ã‹ã®Rewardï¼ˆFunctionality)ã«åŠ ãˆã¦ã€RLä¸­ã«ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ã‚°ãƒ©ãƒ•[^1]ã«å¤‰æ›ã—æ±šæŸ“è§£æ[^2]ã‚’ã—ãŸçµæœã‚’Rewardã«çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€Functionalityã¨Qualityã‚’ä¸¡ç«‹ã—ãŸã‚ˆã€ã¨ã„ã†è©±ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><br>Figure1ã®ã‚°ãƒ©ãƒ•ã®ç¸¦è»¸ã¯ã€Functionalityã¨ï¼ˆUnitTestãŒé€šã£ãŸã‹å¦ã‹ï¼‰ã¨ã€Quailty(ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚„ä¿å®ˆæ€§ã«é–¢ã™ã‚‹å•é¡ŒãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸ)ã€ã¨ã„ã†ä¸¡æ–¹ã®æ¡ä»¶ã‚’æº€ãŸã—ãŸå‰²åˆã§ã‚ã‚‹ç‚¹ã«æ³¨æ„ã€‚<br><br><img src="https://github.com/user-attachments/assets/b843e416-8c96-40ca-ac1f-0318eb1ae40c" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/6beeea63-571b-4ce6-bef8-ac8e0cfffee2" alt="image" loading="lazy"><br><br>[^1]:ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’å®Ÿè¡Œã—ãŸã¨ãã«é€šã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹çµŒè·¯ã®ã™ã¹ã¦ã‚’ã‚°ãƒ©ãƒ•ã¨ã—ã¦è¡¨ã—ãŸã‚‚ã®[å¼•ç”¨å…ƒ](


<a href="https://qiita.com/uint256_t/items/7d4556cb8f5997b9e95c)" target="_blank" rel="noopener noreferrer">https://qiita.com/uint256_t/items/7d4556cb8f5997b9e95c)</a>


<br>[^2]:ä¿¡é ¼ã§ããªã„æ±šæŸ“ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒãƒ—ãƒ­ã‚°ãƒ©ãƒ ä¸­ã§ã©ã®ã‚ˆã†ã«å‡¦ç†ã•ã‚Œã‚‹ã‹ã‚’åˆ†æã™ã‚‹ã“ã¨</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-06-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2017" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Writing-Zero: Bridge the Gap Between Non-verifiable Problems and  Verifiable Rewards, Xun Lu, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- éæ¤œè¨¼å¯èƒ½ãªã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹å¼·åŒ–å­¦ç¿’ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã€ãƒšã‚¢ãƒ¯ã‚¤ã‚ºç”Ÿæˆå ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼ˆGenRMï¼‰ã¨ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ç›¸å¯¾ãƒãƒªã‚·ãƒ¼æœ€é©åŒ–ï¼ˆBRPOï¼‰ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ä¸»è¦³çš„è©•ä¾¡ã‚’ä¿¡é ¼æ€§ã®ã‚ã‚‹æ¤œè¨¼å¯èƒ½ãªå ±é…¬ã«å¤‰æ›ã—ã€å‹•çš„ãªãƒšã‚¢ãƒ¯ã‚¤ã‚ºæ¯”è¼ƒã‚’å®Ÿç¾ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€LLMsã®åŸ·ç­†èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã€ã‚¹ã‚«ãƒ©ãƒ¼å ±é…¬ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«å¯¾ã—ã¦ä¸€è²«ã—ãŸæ”¹å–„ã‚’ç¤ºã—ã€ç«¶äº‰åŠ›ã®ã‚ã‚‹çµæœã‚’é”æˆã€‚å…¨ã¦ã®è¨€èªã‚¿ã‚¹ã‚¯ã«é©ç”¨å¯èƒ½ãªåŒ…æ‹¬çš„ãªRLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã®å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/grad62304977/status/1929996614883783170?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Writing Principleã«åŸºã¥ã„ã¦ï¼ˆe.g., ä¸€è²«æ€§ã€å‰µé€ æ€§ã¨ã‹ï¼Ÿï¼‰æ‰¹è©•ã‚’è¨˜è¿°ã—ã€æœ€çµ‚çš„ã«ä¸ãˆã‚‰ã‚ŒãŸãƒšã‚¢ãƒ¯ã‚¤ã‚ºã®ãƒ†ã‚­ã‚¹ãƒˆã®å„ªåŠ£ã‚’åˆ¤æ–­ã™ã‚‹Generative Reward Model (GenRM; Reasoning Traceã‚’ä¼´ã„æœ€çµ‚çš„ã«Rewardã«å¤‰æ›å¯èƒ½ãªæƒ…å ±ã‚’outpuã™ã‚‹ãƒ¢ãƒ‡ãƒ«) ã‚’å­¦ç¿’ã—ã€ç¾åœ¨ç”Ÿæˆã—ãŸresponseã‚°ãƒ«ãƒ¼ãƒ—ã®ä¸­ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«ä¸€ã¤æ“¬ä¼¼çš„ãªreferenceã‚’æ±ºå®šã—ã€ä»–ã®responseã«å¯¾ã—GenRMã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§å ±é…¬ã‚’æ±ºå®šã™ã‚‹ï¼ˆBRPOï¼‰ã€ã¨ã„ã£ãŸã“ã¨ã‚’ã‚„ã‚‹ã‚‰ã—ã„ã€‚<br><br>ã“ã‚Œã«ã‚ˆã‚Šã€å‰µé€ çš„ãªæ–‡æ›¸ä½œæˆã®ã‚ˆã†ãªå®¢è¦³çš„ãªground truthã‚’é©ç”¨ã§ããªã„ã‚¿ã‚¹ã‚¯ã§ã‚‚ã€RLVRã®æ©æµã‚’ã‚ãšã‹ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ï¼ˆBridging the gap)ã¨ã„ã£ãŸã“ã¨ã‚’ä¸»å¼µã—ã¦ã„ã‚‹ã€‚</p>
<p>RLVRã®æ©æµã¨ã¯ã€Reward Hackingã•ã‚Œã¥ã‚‰ã„é«˜å“è³ªãªå ±é…¬ã€ã¨ã„ã†ã“ã¨ã«ã‚ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚ã®ã§ã€è¦ã¯å¾“æ¥ã®Preference dataã ã‘ã§å­¦ç¿’ã—ãŸReward Modelã‚ˆã‚Šã‚‚ã€ã‚ˆã‚ŠReward Hackingã•ã‚Œãªã„ãƒ­ãƒã‚¹ãƒˆãªå­¦ç¿’ã‚’å®Ÿç¾ã§ãã‚‹Generative Reward Modelã‚’ææ¡ˆã—ã€ãã‚Œã‚’é©ç”¨ã™ã‚‹æ‰‹æ³•BRPOã‚‚ææ¡ˆã—ã¾ã—ãŸã€ã¨ã„ã†è©±ã«è¦‹ãˆã‚‹ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2274" target="_blank" rel="noopener noreferrer">[Paper Note] Inference-Time Scaling for Generalist Reward Modeling, Zijun Liu+, arXiv'25</a>
 </p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/UnitTest.html" target="_blank" rel="noopener noreferrer">#UnitTest</a>
<span class="issue_date">Issue Date: 2025-06-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2016" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning, Yinjie Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- CUREã¯ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆç”Ÿæˆã‚’å…±é€²åŒ–ã•ã›ã‚‹å¼·åŒ–å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€çœŸã®ã‚³ãƒ¼ãƒ‰ã‚’ç›£è¦–ã›ãšã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã€‚ReasonFlux-Coderãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€ä¸‹æµã‚¿ã‚¹ã‚¯ã«ã‚‚åŠ¹æœçš„ã«æ‹¡å¼µå¯èƒ½ã€‚ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆç”Ÿæˆã§ã¯é«˜ã„æ¨è«–åŠ¹ç‡ã‚’é”æˆã—ã€å¼·åŒ–å­¦ç¿’ã®ãŸã‚ã®åŠ¹æœçš„ãªå ±é…¬ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lingyang_pu/status/1930234983274234232?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>UnitTestã®æ€§èƒ½å‘ä¸Šã•ã›ã¾ã™ç³»ã®ç ”ç©¶ãŒå¢—ãˆã¦ãã¦ã„ã‚‹æ„Ÿ</p>
<p>é–¢é€£ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1930348014146859345?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<span class="issue_date">Issue Date: 2025-06-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2015" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement  Learning, Yiqing Liang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¤œè¨¼å¯èƒ½ãªå ±é…¬ã‚’ç”¨ã„ãŸå¼·åŒ–å­¦ç¿’ï¼ˆRLVRï¼‰ã‚’ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMsã«é©ç”¨ã™ã‚‹ãŸã‚ã®ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ç•°ãªã‚‹è¦–è¦šã¨è¨€èªã®å•é¡Œã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã€æœ€é©ãªãƒ‡ãƒ¼ã‚¿æ··åˆæˆ¦ç•¥ã‚’å°å…¥ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆã—ãŸæˆ¦ç•¥ãŒMLLMã®æ¨è«–èƒ½åŠ›ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã€åˆ†å¸ƒå¤–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¹³å‡5.24%ã®ç²¾åº¦å‘ä¸Šã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_vztu/status/1930312780701413498?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªè¨­å®šã§RLVRã‚’é©ç”¨ã™ã‚‹ã¨ã€ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å­¦ç¿’ã«åˆ©ç”¨ã™ã‚‹å ´åˆã‚ˆã‚Šã€ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã®ã¿ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ãŸæ–¹ãŒå½“è©²ã‚¿ã‚¹ã‚¯ã§ã¯æ€§èƒ½ãŒé«˜ããªã£ãŸã‚Šï¼ˆã¤ã¾ã‚Šãƒ‡ãƒ¼ã‚¿ãŒå¤šã‘ã‚Œã°å¤šã„ã»ã©è‰¯ã„ã‚ã‘ã§ã¯ç„¡ã„ï¼‰ã€ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã‚’ablationã™ã‚‹ã¨OODã«å¯¾ã™ã‚‹äºˆæ¸¬æ€§èƒ½ãŒæ”¹å–„ã—ãŸã‚Šã™ã‚‹ãªã©ã€ãƒ‡ãƒ¼ã‚¿é–“ã§å¹²æ¸‰ãŒèµ·ãã¦æ•µå¯¾çš„ã«ãªã£ã¦ã—ã¾ã†ã‚ˆã†ãªç¾è±¡ãŒèµ·ãã‚‹ã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€ã©ã®ã‚ˆã†ã«é©åˆ‡ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ··åˆã§ãã‚‹ã‹ï¼Ÿã¨ã„ã†æˆ¦ç•¥ã®å¿…è¦æ€§ãŒæµ®ãå½«ã‚Šã«ãªã‚Šã€ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ãªMixtureæˆ¦ç•¥ï¼ˆã©ã†ã‚„ã‚‰ãƒ‡ãƒ¼ã‚¿ã®æ··åˆåˆ†å¸ƒã‹ã‚‰å­¦ç¿’å¾Œã®æ€§èƒ½ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãªæ¨¡æ§˜ï¼‰ã®æ€§èƒ½ãŒuniformã«mixã™ã‚‹ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€ã¿ãŸã„ãªè©±ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Memorization.html" target="_blank" rel="noopener noreferrer">#Memorization</a>
<span class="issue_date">Issue Date: 2025-06-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2014" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] How much do language models memorize?, John X. Morris+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¢ãƒ‡ãƒ«ã®ã€ŒçŸ¥è­˜ã€ã‚’æ¨å®šã™ã‚‹æ–°æ‰‹æ³•ã‚’ææ¡ˆã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’æ¸¬å®šã€‚è¨˜æ†¶ã‚’ã€Œæ„å›³ã—ãªã„è¨˜æ†¶ã€ã¨ã€Œä¸€èˆ¬åŒ–ã€ã«åˆ†ã‘ã€ä¸€èˆ¬åŒ–ã‚’æ’é™¤ã™ã‚‹ã“ã¨ã§ç·è¨˜æ†¶ã‚’è¨ˆç®—ã€‚GPTã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã¯ç´„3.6ãƒ“ãƒƒãƒˆ/ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èƒ½åŠ›ã‚’æŒã¤ã¨æ¨å®šã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºå¢—åŠ ã«ä¼´ã„ã€ãƒ¢ãƒ‡ãƒ«ã¯è¨˜æ†¶ã‚’ä¿æŒã—ã€ä¸€èˆ¬åŒ–ãŒå§‹ã¾ã‚‹ã¨æ„å›³ã—ãªã„è¨˜æ†¶ãŒæ¸›å°‘ã€‚æ•°ç™¾ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€èƒ½åŠ›ã¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®é–¢ä¿‚ã‚’ç¤ºã™ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ç”Ÿæˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rohanpaul_ai/status/1929989864927146414?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-06-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2013" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unleashing the Reasoning Potential of Pre-trained LLMs by Critique  Fine-Tuning on One Problem, Yubo Wang+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¼·åŠ›ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®æ¨è«–èƒ½åŠ›ã‚’å¼•ãå‡ºã™ãŸã‚ã«ã€æ‰¹è©•å¾®èª¿æ•´ï¼ˆCFTï¼‰ãŒåŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚CFTã¯ã€å˜ä¸€ã®å•é¡Œã«å¯¾ã™ã‚‹å¤šæ§˜ãªè§£ã‚’åé›†ã—ã€æ•™å¸«LLMã«ã‚ˆã‚‹æ‰¹è©•ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚QwenãŠã‚ˆã³Llamaãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ãŸçµæœã€æ•°å­¦ã‚„è«–ç†æ¨è«–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’è¦³å¯Ÿã—ã¾ã—ãŸã€‚ç‰¹ã«ã€ã‚ãšã‹5æ™‚é–“ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã€Qwen-Math-7B-CFTã¯ä»–ã®æ‰‹æ³•ã¨åŒç­‰ä»¥ä¸Šã®æˆæœã‚’ä¸Šã’ã¾ã—ãŸã€‚CFTã¯è¨ˆç®—åŠ¹ç‡ãŒé«˜ãã€ç¾ä»£ã®LLMã®æ¨è«–èƒ½åŠ›ã‚’å¼•ãå‡ºã™ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1930447298527670662?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1832" target="_blank" rel="noopener noreferrer">Critique Fine-Tuning: Learning to Critique is More Effective than   Learning to Imitate, Yubo Wang+, COLM'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1938" target="_blank" rel="noopener noreferrer">Reinforcement Learning for Reasoning in Large Language Models with One   Training Example, Yiping Wang+, NeurIPS'25</a>
</p>
<p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/weiliu99/status/1930826904522875309?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2012" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents, Jenny Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ€ãƒ¼ãƒ´ã‚£ãƒ³ãƒ»ã‚´ãƒ¼ãƒ‡ãƒ«ãƒã‚·ãƒ³ï¼ˆDGMï¼‰ã¯ã€è‡ªå·±æ”¹å–„ã™ã‚‹AIã‚·ã‚¹ãƒ†ãƒ ã§ã‚ã‚Šã€ã‚³ãƒ¼ãƒ‰ã‚’åå¾©çš„ã«ä¿®æ­£ã—ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¤‰æ›´ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚é€²åŒ–ã¨ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ãªç ”ç©¶ã«åŸºã¥ãã€ç”Ÿæˆã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’ç¶­æŒã—ã€æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½œæˆã™ã‚‹ã“ã¨ã§å¤šæ§˜ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è‚²æˆã—ã¾ã™ã€‚DGMã¯ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°èƒ½åŠ›ã‚’è‡ªå‹•çš„ã«å‘ä¸Šã•ã›ã€SWE-benchã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’20.0%ã‹ã‚‰50.0%ã€Polyglotã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’14.2%ã‹ã‚‰30.7%ã«æ”¹å–„ã—ã¾ã—ãŸã€‚å®‰å…¨å¯¾ç­–ã‚’è¬›ã˜ãŸå®Ÿé¨“ã«ã‚ˆã‚Šã€è‡ªå·±æ”¹å–„ã‚’è¡Œã‚ãªã„ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æˆæœã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/omarsar_new-paper-open-ended-evolution-of-self-improving-activity-7334610178832556033-8dA-?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/omarsar_new-paper-open-ended-evolution-of-self-improving-activity-7334610178832556033-8dA-?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4</a>


</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1212" target="_blank" rel="noopener noreferrer">Self-Rewarding Language Models, Weizhe Yuan+, N/A, ICML'24</a>
<br><br>ã‚ãŸã‚Šã®ç ”ç©¶ã¨ã¯ã©ã†é•ã†ã®ã ã‚ã†ã‹ã€ã¨ã„ã†ç‚¹ãŒæ°—ã«ãªã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2011" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in  Large Language Models, Mingjie Liu+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ãŒè¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹å¯èƒ½æ€§ã‚’æ¢ã‚‹æœ¬ç ”ç©¶ã§ã¯ã€é•·æœŸçš„ãªRLï¼ˆProRLï¼‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒæ–°ã—ã„æ¨è«–æˆ¦ç•¥ã‚’æ˜ã‚‰ã‹ã«ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚æ–°ã—ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ProRLã‚’å°å…¥ã—ã€å®Ÿè¨¼åˆ†æã«ã‚ˆã‚Šã€RLã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒåŸºç¤ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚æ¨è«–ã®æ”¹å–„ã¯åŸºç¤ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æœŸé–“ã¨ç›¸é–¢ã—ã¦ãŠã‚Šã€RLãŒæ–°ã—ã„è§£æ±ºç©ºé–“ã‚’æ¢ç´¢ã§ãã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€RLãŒè¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã‚’æ‹¡å¼µã™ã‚‹æ¡ä»¶ã«é–¢ã™ã‚‹æ–°ãŸãªæ´å¯ŸãŒå¾—ã‚‰ã‚Œã€ä»Šå¾Œã®ç ”ç©¶ã®åŸºç›¤ãŒç¯‰ã‹ã‚Œã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1930043688329326962?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RLVRï¼ˆmath, codeï¼ˆå¾“æ¥ã¯ã“ã®2ç¨®é¡ï¼‰, STEM, logic Puzzles, instruction followingï¼‰ã«ã‚ˆã£ã¦å¤§è¦æ¨¡ãªã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆé•·æœŸçš„ã«å­¦ç¿’ã‚’ã™ã‚‹; 2k training stepsã¨å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã§ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼‰ã§å®Ÿé¨“ã‚’ã—ã€å®šæœŸçš„ã«Referenceãƒãƒªã‚·ãƒ¼ã¨Optimizerã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ã“ã¨ã§ã€å…ƒã®ãƒãƒªã‚·ãƒ¼ã‹ã‚‰ã®ä¹–é›¢ã‚’é˜²ãã¤ã¤ã‚‚ã€æ–°ãŸãªå­¦ç¿’ãŒé€²ã‚€ã‚ˆã†ãªã“ã¨ã‚’ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br>ï¼ˆâ€»PFNã®ãƒ©ãƒ³ãƒã‚¿ã‚¤ãƒ ãƒˆãƒ¼ã‚¯ã‚’å‚è€ƒã«è¨˜è¿°ï¼‰<br><br>verlã‚’ç”¨ã„ã¦ã€DAPOã§å­¦ç¿’ã‚’ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/db706cfc-e756-47d1-a0e7-8fbc8043ae17" alt="image" loading="lazy"><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1969" target="_blank" rel="noopener noreferrer">verl: Volcano Engine Reinforcement Learning for LLMs, ByteDance Seed Team, 2025.04</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1815" target="_blank" rel="noopener noreferrer">DAPO: An Open-Source LLM Reinforcement Learning System at Scale, Qiying Yu+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2010" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] xVerify: Efficient Answer Verifier for Reasoning Model Evaluations, Ding Chen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¨è«–ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã®ãŸã‚ã«ã€xVerifyã¨ã„ã†åŠ¹ç‡çš„ãªå›ç­”æ¤œè¨¼å™¨ã‚’ææ¡ˆã€‚xVerifyã¯ã€LLMãŒç”Ÿæˆã—ãŸå›ç­”ãŒå‚ç…§è§£ç­”ã¨åŒç­‰ã§ã‚ã‚‹ã‹ã‚’åŠ¹æœçš„ã«åˆ¤æ–­ã§ãã‚‹ã€‚VARãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã€è¤‡æ•°ã®LLMã‹ã‚‰ã®è³ªå•-å›ç­”ãƒšã‚¢ã‚’åé›†ã€‚è©•ä¾¡å®Ÿé¨“ã§ã¯ã€ã™ã¹ã¦ã®xVerifyãƒ¢ãƒ‡ãƒ«ãŒ95ï¼…ã‚’è¶…ãˆã‚‹F1ã‚¹ã‚³ã‚¢ã¨ç²¾åº¦ã‚’é”æˆã—ã€ç‰¹ã«xVerify-3B-Ibã¯GPT-4oã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/VerifiableRewards.html" target="_blank" rel="noopener noreferrer">#VerifiableRewards</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2009" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Pitfalls of Rule- and Model-based Verifiers -- A Case Study on  Mathematical Reasoning, Yuzhen Huang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ•°å­¦çš„æ¨è«–ã«ãŠã‘ã‚‹æ¤œè¨¼è€…ã®ä¿¡é ¼æ€§ã¨ãã®RLè¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹ã¸ã®å½±éŸ¿ã‚’åˆ†æã€‚ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®æ¤œè¨¼è€…ã¯å½é™°æ€§ç‡ãŒé«˜ãã€RLè¨“ç·´ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«æ‚ªå½±éŸ¿ã‚’åŠã¼ã™ã“ã¨ãŒåˆ¤æ˜ã€‚ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®æ¤œè¨¼è€…ã¯é™çš„è©•ä¾¡ã§é«˜ç²¾åº¦ã‚’ç¤ºã™ãŒã€å½é™½æ€§ã«å¯¾ã—ã¦è„†å¼±ã§ã‚ã‚Šã€å ±é…¬ãŒä¸æ­£ã«è†¨ã‚‰ã‚€å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¼·åŒ–å­¦ç¿’ã«ãŠã‘ã‚‹å …ç‰¢ãªå ±é…¬ã‚·ã‚¹ãƒ†ãƒ ã®å¿…è¦æ€§ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/junxian_he/status/1929371821767586284?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>verificationã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã—ã¦finetuningã•ã‚ŒãŸDiscriminative ClassifierãŒã€reward hackingã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br>Discriminative Verifierã¨ã¯ã€Question, Response, Reference AnswerãŒgivenãªæ™‚ã«ã€responseï¼ˆã—ã°ã—ã°reasoning traceã‚’å«ã¿è¤‡æ•°ã®answerã®å€™è£œãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ï¼‰ã®ä¸­ã‹ã‚‰æœ€çµ‚çš„ãªanswerã‚’æŠ½å‡ºã—ã€Reference answerã¨æŠ½å‡ºã—ãŸanswerã‹ã‚‰æ­£è§£/ä¸æ­£è§£ã‚’binaryã§å‡ºåŠ›ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ã“ã¨ã€‚Rule-based Verifierã§ã¯ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒç•°ãªã£ã¦ã„ã‚‹å ´åˆã«false negativeã¨ãªã£ã¦ã—ã¾ã†ã—ã€ãã‚‚ãã‚‚ãƒ«ãƒ¼ãƒ«ãŒè¦å®šã§ããªã„ã‚¿ã‚¹ã‚¯ã®å ´åˆã¯é©ç”¨ã§ããªã„ã€‚Discriminative Verifierã§ã¯ãã®ã‚ˆã†ãªã‚±ãƒ¼ã‚¹ã§ã‚‚é©ç”¨ã§ãã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚</p>
<p>Discriminative Verifierã®ä¾‹ã¯ãŸã¨ãˆã°ä¸‹è¨˜:<br>


<a href="https://huggingface.co/IAAR-Shanghai/xVerify-0.5B-I" target="_blank" rel="noopener noreferrer">https://huggingface.co/IAAR-Shanghai/xVerify-0.5B-I</a>


<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2010" target="_blank" rel="noopener noreferrer">[Paper Note] xVerify: Efficient Answer Verifier for Reasoning Model Evaluations, Ding Chen+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<span class="issue_date">Issue Date: 2025-06-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2008" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Challenging Language Model Agents, Yifei Zhou+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Self-Challengingãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè‡ªã‚‰ç”Ÿæˆã—ãŸé«˜å“è³ªãªã‚¿ã‚¹ã‚¯ã§è¨“ç·´ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯æŒ‘æˆ¦è€…ã¨ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆã—ã€å®Ÿè¡Œè€…ã¨ã—ã¦å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦è¨“ç·´ã€‚M3ToolEvalã¨TauBenchã§Llama-3.1-8B-InstructãŒ2å€ä»¥ä¸Šã®æ”¹å–„ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1929719473952497797?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1930748591242424439?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2006" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BIG-Bench Extra Hard, Mehran Kazemi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€BIG-Bench Extra Hardï¼ˆBBEHï¼‰ã‚’å°å…¥ã€‚ã“ã‚Œã¯ã€æ—¢å­˜ã®BIG-Bench Hardï¼ˆBBHï¼‰ã®ã‚¿ã‚¹ã‚¯ã‚’æ–°ã—ã„ã‚‚ã®ã«ç½®ãæ›ãˆã€é›£æ˜“åº¦ã‚’å¤§å¹…ã«å¼•ãä¸Šã’ã‚‹ã“ã¨ã§ã€LLMã®é™ç•Œã‚’æŠ¼ã—åºƒã’ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã€‚è©•ä¾¡ã®çµæœã€æœ€è‰¯ã®æ±ç”¨ãƒ¢ãƒ‡ãƒ«ã§9.8%ã€æ¨è«–å°‚é–€ãƒ¢ãƒ‡ãƒ«ã§44.8%ã®å¹³å‡ç²¾åº¦ãŒè¦³å¯Ÿã•ã‚Œã€LLMã®ä¸€èˆ¬çš„æ¨è«–èƒ½åŠ›å‘ä¸Šã®ä½™åœ°ãŒç¤ºã•ã‚ŒãŸã€‚BBEHã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Big-Bench hardï¼ˆæ—¢ã«SoTAãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›å·®ã‚’è­˜åˆ¥ã§ããªã„ï¼‰ã®é›£æ˜“åº¦ã‚’ã•ã‚‰ã«æŠ¼ã—ä¸Šã’ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚<br><br>Inputã®ä¾‹<br><img src="https://github.com/user-attachments/assets/b9d1308f-1481-470d-a553-c181d902119c" alt="image" loading="lazy"><br><br>ã‚¿ã‚¹ã‚¯ã”ã¨ã®Input, Output lengthã®åˆ†å¸ƒ<br><img src="https://github.com/user-attachments/assets/ef6b7401-159d-46c7-bd9d-9a64f63b5089" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/01207db3-cb01-46f2-a805-e9ddf9d58198" alt="image" loading="lazy"><br><br>ç¾åœ¨ã®ä¸»è¦ãªãƒ¢ãƒ‡ãƒ«ç¾¤ã®æ€§èƒ½<br><img src="https://github.com/user-attachments/assets/5ce538d8-45a1-449a-992a-998b33fdeaf7" alt="image" loading="lazy"></p>
<p>Big-Benchè«–æ–‡ã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/785" target="_blank" rel="noopener noreferrer">Beyond the Imitation Game: Quantifying and extrapolating the   capabilities of language models, Aarohi Srivastava+, N/A, TMLR'23</a>
</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/PRM.html" target="_blank" rel="noopener noreferrer">#PRM</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2005" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Training Step-Level Reasoning Verifiers with Formal Verification Tools, Ryo Kamoi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€ãƒ—ãƒ­ã‚»ã‚¹å ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼ˆPRMsï¼‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹2ã¤ã®èª²é¡Œã€ã™ãªã‚ã¡é«˜ã‚³ã‚¹ãƒˆã®äººé–“ã«ã‚ˆã‚‹æ³¨é‡ˆã¨æ•°å­¦çš„æ¨è«–å•é¡Œã¸ã®é™å®šã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€FoVerã¨ã„ã†ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¾ã™ã€‚FoVerã¯å½¢å¼çš„æ¤œè¨¼ãƒ„ãƒ¼ãƒ«ã‚’ç”¨ã„ã¦è‡ªå‹•çš„ã«æ®µéšãƒ¬ãƒ™ãƒ«ã®ã‚¨ãƒ©ãƒ¼ãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆã—ã€äººçš„æ³¨é‡ˆãªã—ã§LLMã®å¿œç­”ã«ã‚¨ãƒ©ãƒ¼ãƒ©ãƒ™ãƒ«ã‚’ä»˜ä¸ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆæˆã—ã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸPRMsã¯ã€å…ƒã®LLMsã«åŸºã¥ããƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€ä»–ã®æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã¨ã‚‚ç«¶äº‰åŠ›ã®ã‚ã‚‹çµæœã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ryokamoi/status/1925939062348697874?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>äººæ‰‹ã«ã‚ˆã‚‹Annotationï¼ˆstep levelã®ãƒ©ãƒ™ãƒ«ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³)ç„¡ã—ã§Procsee Reward Modelã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã™ã‚‹æ‰‹æ³•<br><br><img src="https://github.com/user-attachments/assets/adfc351e-c53b-47af-adba-480e10615d69" alt="image" loading="lazy"></p>
<p>Z3ã‚„Isabelleãªã©ã®å½¢å¼æ¤œè¨¼ãƒ„ãƒ¼ãƒ«ãŒé©ç”¨å¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®ã¿ã«ææ¡ˆæ‰‹æ³•ã®ã‚¹ã‚³ãƒ¼ãƒ—ã¯é™ã‚‰ã‚Œã‚‹ç‚¹ã«ã¯æ³¨æ„</p>
<p>äººæ‰‹ã§ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦comparableãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆ<br><img src="https://github.com/user-attachments/assets/290a4d1c-10ac-41dd-a26e-ed57e1fcca79" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/b1af66e7-fbbe-4823-8679-e5ff5be94fdf" alt="image" loading="lazy"><br><br>ã‚¹ãƒ¬ãƒƒãƒ‰ä¸­ã§è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒæ•°å›ã®reasoning stepãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã®ã¿ã®è©•ä¾¡ã§ã‚ã‚Šã€ã‚ˆã‚Šé•·ãè¤‡é›‘ãªreasoning stepï¼ˆãŸã¨ãˆã° <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2006" target="_blank" rel="noopener noreferrer">[Paper Note] BIG-Bench Extra Hard, Mehran Kazemi+, arXiv'25</a>
ï¼‰ãŒå¿…è¦ãªå ´åˆã¯ã©ã†ãªã‚‹ã‹ï¼Ÿã¨ã„ã£ãŸæ‰€ã«èˆˆå‘³ãŒå¯„ã›ã‚‰ã‚Œã¦ã„ã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2004" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Satori-SWE: Evolutionary Test-Time Scaling for Sample-Efficient Software  Engineering, Guangtao Zeng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- EvoScaleã‚’ææ¡ˆã—ã€é€²åŒ–çš„ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç”¨ã„ã¦å°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã‚’é–‹ç™ºã€‚é¸æŠã¨çªç„¶å¤‰ç•°ã‚’é€šã˜ã¦å‡ºåŠ›ã‚’æ´—ç·´ã—ã€ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’æ¸›å°‘ã•ã›ã‚‹ã€‚å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦è‡ªå·±é€²åŒ–ã‚’ä¿ƒé€²ã—ã€SWE-Bench-Verifiedã§32Bãƒ¢ãƒ‡ãƒ«ãŒ100Bä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¤ºã™ã€‚ã‚³ãƒ¼ãƒ‰ã€ãƒ‡ãƒ¼ã‚¿ã€ãƒ¢ãƒ‡ãƒ«ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦å…¬é–‹äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gan_chuang/status/1928963872188244400?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2003" target="_blank" rel="noopener noreferrer" class="title-link">Can Large Reasoning Models Self-Train?, Sheikh Shafayat+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±å­¦ç¿’ã‚’æ´»ç”¨ã—ãŸã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®è‡ªå·±ä¸€è²«æ€§ã‚’åˆ©ç”¨ã—ã¦æ­£ç¢ºæ€§ä¿¡å·ã‚’æ¨æ¸¬ã€‚é›£ã—ã„æ•°å­¦çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã«é©ç”¨ã—ã€å¾“æ¥ã®æ‰‹æ³•ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚è‡ªå·±ç”Ÿæˆã•ã‚ŒãŸä»£ç†å ±é…¬ãŒèª¤ã£ãŸå‡ºåŠ›ã‚’å„ªé‡ã™ã‚‹ãƒªã‚¹ã‚¯ã‚‚æŒ‡æ‘˜ã€‚è‡ªå·±ç›£è¦–ã«ã‚ˆã‚‹æ€§èƒ½å‘ä¸Šã®å¯èƒ½æ€§ã¨èª²é¡Œã‚’æ˜ã‚‰ã‹ã«ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/askalphaxiv/status/1928487492291829809?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1995" target="_blank" rel="noopener noreferrer">Learning to Reason without External Rewards, Xuandong Zhao+, ICML'25 Workshop AI4MATH</a>
<br>ã¨ä¼¼ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹</p>
<p>self-consistencyã§ground truthã‚’æ¨å®šã—ã€æ¨å®šã—ãŸground truthã‚’ç”¨ã„ã¦verifiableãªrewardã‚’è¨ˆç®—ã—ã¦å­¦ç¿’ã™ã‚‹æ‰‹æ³•ã€ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/0f38d47a-ab42-4ec4-a6d5-6d5d8a63a4a9" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/3d08bbad-8578-4add-8ad7-ed02cdd15add" alt="image" loading="lazy"><br><br>å®Ÿéš›ã®ground truthã‚’ç”¨ã„ãŸå­¦ç¿’ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã™ã‚‹å ´åˆã‚‚ã‚ã‚Œã°ã€long stepã§å­¦ç¿’ã™ã‚‹ã¨ã©ã“ã‹ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§å­¦ç¿’ãŒcollapseã™ã‚‹å ´åˆã‚‚ã‚ã‚‹<br><img src="https://github.com/user-attachments/assets/e120a277-6beb-4fc1-8fd7-e69de467fb3d" alt="image" loading="lazy"></p>
<p>ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒãƒ”ãƒ¼ã‚¯ã‚’è¿ãˆãŸå¾Œã«ãªãœå¤§å¹…ã«AccuracyãŒdropã™ã‚‹ã‹ã‚’æ¤œè¨¼ã—ãŸã¨ã“ã‚ã€ãƒ¢ãƒ‡ãƒ«ã®KL penaltyãŒã©ã“ã‹ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§å¤§å¹…ã«å¤§ãããªã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã¤ã¾ã‚Šã“ã‚Œã¯ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã‹ã‘é›¢ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«ãªã£ã¦ã„ã‚‹ã€‚ã“ã‚Œã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒãƒ‡ã‚¿ãƒ©ãƒ¡ãªå‡ºåŠ›ã‚’ground truthã¨ã—ã¦æ¨å®šã™ã‚‹ã‚ˆã†ã«ãªã‚Šã€ãƒ¢ãƒ‡ãƒ«ãã®ã‚‚ã®ã‚‚ä¸€è²«ã—ã¦ãã®ãƒ‡ã‚¿ãƒ©ãƒ¡ãªå‡ºåŠ›ã‚’ã™ã‚‹ã“ã¨ã§rewardã‚’å¢—å¤§ã•ã›ã‚‹reward hackingãŒèµ·ãã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/5a9c091f-e9cb-4914-a1ca-32a1ea2dc1c7" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/aa685b9a-7992-4135-a4da-fd1c8cabe084" alt="image" loading="lazy"></p>
<p>ã“ã‚Œã‚‰ç¾è±¡ã‚’é¿ã‘ã‚‹æ–¹æ³•ã¨ã—ã¦ã€ä»¥ä¸‹ã®3ã¤ã‚’ææ¡ˆã—ã¦ã„ã‚‹<br>- early stopping<br>- offlineã§ãƒ©ãƒ™ãƒ«ã‚’self consistencyã§ç”Ÿæˆã—ã¦ã€å­¦ç¿’ã®éç¨‹ã§å›ºå®šã™ã‚‹<br>- ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å°å…¥ã™ã‚‹<br><br><img src="https://github.com/user-attachments/assets/4fa997e3-aa20-4195-96ef-b17c82556fc1" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/99cc2b6c-50a9-40a0-af30-b59aff4056b4" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/e90e9870-b180-4fe9-8c24-8ff88fcf33f0" alt="image" loading="lazy"></p>
<p>é–¢é€£<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1489" target="_blank" rel="noopener noreferrer">Self-Consistency Preference Optimization, Archiki Prasad+, ICML'25</a>
</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2025-05-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2000" target="_blank" rel="noopener noreferrer" class="title-link">Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs, Yu Xia+, COLING'25</a>
<span class="snippet"><span>GPT Summary</span>- Chain-of-Thoughtï¼ˆCoTï¼‰ã‚’åŸºã«ã—ãŸChain-of-Xï¼ˆCoXï¼‰æ‰‹æ³•ã®èª¿æŸ»ã‚’è¡Œã„ã€LLMsã®èª²é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®å¤šæ§˜ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’åˆ†é¡ã€‚ãƒãƒ¼ãƒ‰ã®åˆ†é¡ã¨ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã«åŸºã¥ãåˆ†æã‚’é€šã˜ã¦ã€æ—¢å­˜ã®æ‰‹æ³•ã®æ„ç¾©ã¨ä»Šå¾Œã®å¯èƒ½æ€§ã‚’è­°è«–ã€‚ç ”ç©¶è€…ã«ã¨ã£ã¦æœ‰ç”¨ãªãƒªã‚½ãƒ¼ã‚¹ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-05-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1999" target="_blank" rel="noopener noreferrer" class="title-link">Distillation Scaling Laws, Dan Busbridge+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- è’¸ç•™ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ¨å®šã™ã‚‹ãŸã‚ã®è’¸ç•™ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ææ¡ˆã€‚æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã®è¨ˆç®—å‰²ã‚Šå½“ã¦ã‚’æœ€é©åŒ–ã™ã‚‹ã“ã¨ã§ã€ç”Ÿå¾’ã®æ€§èƒ½ã‚’æœ€å¤§åŒ–ã€‚æ•™å¸«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ãªå ´åˆã«æœ€é©ãªè’¸ç•™ãƒ¬ã‚·ãƒ”ã‚’æä¾›ã€‚å¤šãã®ç”Ÿå¾’ã‚’è’¸ç•™ã™ã‚‹éš›ã¯ã€ç›£è¦–ä»˜ãã®äº‹å‰å­¦ç¿’ã‚’ä¸Šå›ã‚‹ãŒã€ç”Ÿå¾’ã®ã‚µã‚¤ã‚ºã«å¿œã˜ãŸè¨ˆç®—ãƒ¬ãƒ™ãƒ«ã¾ã§ã€‚å˜ä¸€ã®ç”Ÿå¾’ã‚’è’¸ç•™ã—ã€æ•™å¸«ãŒãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¿…è¦ãªå ´åˆã¯ç›£è¦–å­¦ç¿’ã‚’æ¨å¥¨ã€‚è’¸ç•™ã«é–¢ã™ã‚‹æ´å¯Ÿã‚’æä¾›ã—ã€ç†è§£ã‚’æ·±ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/danbusbridge/status/1944539357542781410?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Temporal.html" target="_blank" rel="noopener noreferrer">#Temporal</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1996" target="_blank" rel="noopener noreferrer" class="title-link">Temporal Sampling for Forgotten Reasoning in LLMs, Yuetai Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«LLMsãŒä»¥å‰ã®æ­£ã—ã„è§£æ³•ã‚’å¿˜ã‚Œã‚‹ã€Œæ™‚é–“çš„å¿˜å´ã€ã‚’ç™ºè¦‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€Œæ™‚é–“çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€ã¨ã„ã†ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ã‚’å°å…¥ã—ã€è¤‡æ•°ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å‡ºåŠ›ã‚’å¼•ãå‡ºã™ã“ã¨ã§æ¨è«–æ€§èƒ½ã‚’å‘ä¸Šã€‚Pass@kã§4ã‹ã‚‰19ãƒã‚¤ãƒ³ãƒˆã®æ”¹å–„ã‚’é”æˆã—ã€LoRAé©å¿œãƒ¢ãƒ‡ãƒ«ã§ã‚‚åŒæ§˜ã®åˆ©ç‚¹ã‚’ç¤ºã™ã€‚æ™‚é–“çš„å¤šæ§˜æ€§ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€LLMsã®è©•ä¾¡æ–¹æ³•ã‚’å†è€ƒã™ã‚‹æ‰‹æ®µã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1927286319018832155?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Temporal Forgettingã¨Temporal Sampling</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Workshop.html" target="_blank" rel="noopener noreferrer">#Workshop</a>
<span class="issue_date">Issue Date: 2025-05-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1995" target="_blank" rel="noopener noreferrer" class="title-link">Learning to Reason without External Rewards, Xuandong Zhao+, ICML'25 Workshop AI4MATH</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤–éƒ¨ã®å ±é…¬ã‚„ãƒ©ãƒ™ãƒ«ãªã—ã§å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ãŒå­¦ç¿’ã§ãã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€Œå†…éƒ¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‹ã‚‰ã®å¼·åŒ–å­¦ç¿’ï¼ˆRLIFï¼‰ã€ã‚’ææ¡ˆã€‚è‡ªå·±ç¢ºä¿¡ã‚’å ±é…¬ä¿¡å·ã¨ã—ã¦ç”¨ã„ã‚‹ã€ŒIntuitorã€ã‚’é–‹ç™ºã—ã€ç„¡ç›£è¦–ã®å­¦ç¿’ã‚’å®Ÿç¾ã€‚å®Ÿé¨“çµæœã¯ã€IntuitorãŒæ•°å­¦çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–ã‚¿ã‚¹ã‚¯ã¸ã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚‚é«˜ã„ã“ã¨ã‚’ç¤ºã—ãŸã€‚å†…å› çš„ä¿¡å·ãŒåŠ¹æœçš„ãªå­¦ç¿’ã‚’ä¿ƒé€²ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã€è‡ªå¾‹AIã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªä»£æ›¿æ‰‹æ®µã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xuandongzhao/status/1927270931874910259?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãŠã‚‚ã—ã‚ãã†</p>
<p>externalãªsignalã‚’rewardã¨ã—ã¦ç”¨ã„ãªã„ã§ã€ãƒ¢ãƒ‡ãƒ«è‡ªèº«ãŒå†…éƒ¨çš„ã«ä¿æŒã—ã¦ã„ã‚‹confidenceã‚’ç”¨ã„ã‚‹ã€‚äººé–“ã¯è‡ªä¿¡ãŒã‚ã‚‹å•é¡Œã«ã¯æ­£è§£ã—ã‚„ã™ã„ã¨ã„ã†ç›´æ„Ÿã«åŸºã¥ã„ã¦ãŠã‚Šã€openendãªquestionã®ã‚ˆã†ã«ãã‚‚ãã‚‚æ­£è§£ã‚·ã‚°ãƒŠãƒ«ãŒå®šç¾©ã§ããªã„ã‚‚ã®ã‚‚ã‚ã‚‹ãŒã€ãã†ã„ã£ãŸå ´åˆã«æ´»ç”¨ã§ãã‚‹ã‚ˆã†ã§ã‚ã‚‹ã€‚</p>
<p>self-trainingã®è€ƒãˆæ–¹ã«è¿‘ã„ã®ã§ã¯</p>
<p>ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ®µéšã§ã‚ã‚‹ç¨‹åº¦èƒ½åŠ›ãŒå‚™ã‚ã£ã¦ãŠã‚Šã€post-trainingã—ãŸçµæœãã‚ŒãŒå¼•ãå‡ºã•ã‚Œã‚‹ã‚ˆã†ã«ãªã£ãŸã¨ã„ã†æ„Ÿã˜ãªã®ã ã‚ã†ã‹ã€‚<br><br>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/weiliu99/status/1930826904522875309?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:


<a href="https://www.docswell.com/s/DeepLearning2023/KYVLG4-2025-09-18-112951" target="_blank" rel="noopener noreferrer">https://www.docswell.com/s/DeepLearning2023/KYVLG4-2025-09-18-112951</a>


<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dl_hacks/status/1968528790503481439?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-05-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1994" target="_blank" rel="noopener noreferrer" class="title-link">QwenLong-CPRS: Towards $\infty$-LLMs with Dynamic Context Optimization, Weizhou Shen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- QwenLong-CPRSã¯ã€é•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæœ€é©åŒ–ã®ãŸã‚ã®æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€LLMsã®æ€§èƒ½ä½ä¸‹ã‚’è»½æ¸›ã—ã¾ã™ã€‚è‡ªç„¶è¨€èªæŒ‡ç¤ºã«åŸºã¥ãå¤šæ®µéšã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåœ§ç¸®ã‚’å®Ÿç¾ã—ã€åŠ¹ç‡ã¨æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹4ã¤ã®é©æ–°ã‚’å°å…¥ã€‚5ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€ä»–ã®æ‰‹æ³•ã«å¯¾ã—ã¦å„ªä½æ€§ã‚’ç¤ºã—ã€ä¸»è¦ãªLLMã¨ã®çµ±åˆã§å¤§å¹…ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåœ§ç¸®ã¨æ€§èƒ½å‘ä¸Šã‚’é”æˆã€‚QwenLong-CPRSã¯æ–°ãŸãªSOTAæ€§èƒ½ã‚’ç¢ºç«‹ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1927014346690826684?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1993" target="_blank" rel="noopener noreferrer" class="title-link">QwenLong-L1: Towards Long-Context Large Reasoning Models with  Reinforcement Learning, Fanqi Wan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ¨è«–ã«ãŠã‘ã‚‹LRMsã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€QwenLong-L1ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ç›£è¦–ä»˜ããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ æŒ‡å°å‹æ®µéšçš„RLã‚’ç”¨ã„ã¦ãƒãƒªã‚·ãƒ¼ã®å®‰å®šåŒ–ã‚’å›³ã‚Šã€é›£æ˜“åº¦èªè­˜å‹ã®å›é¡§çš„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§æ¢ç´¢ã‚’ä¿ƒé€²ã€‚å®Ÿé¨“ã§ã¯ã€QwenLong-L1-32BãŒä»–ã®LRMsã‚’ä¸Šå›ã‚Šã€å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1927011243597967524?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1989" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Reasoning, Losing Control: Evaluating Instruction Following in  Large Reasoning Models, Tingchen Fu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã¯LLMã«ã¨ã£ã¦é‡è¦ã§ã‚ã‚Šã€MathIFã¨ã„ã†æ•°å­¦çš„æ¨è«–ã‚¿ã‚¹ã‚¯ç”¨ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã€‚æ¨è«–èƒ½åŠ›ã®å‘ä¸Šã¨æŒ‡ç¤ºéµå®ˆã®é–“ã«ã¯ç·Šå¼µé–¢ä¿‚ãŒã‚ã‚Šã€ç‰¹ã«é•·ã„æ€è€ƒã®é€£é–ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã¯æŒ‡ç¤ºã«å¾“ã„ã«ãã„ã€‚ä»‹å…¥ã«ã‚ˆã‚Šéƒ¨åˆ†çš„ãªå¾“é †ã•ã‚’å›å¾©ã§ãã‚‹ãŒã€æ¨è«–æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã‚‰ã®çµæœã¯ã€æŒ‡ç¤ºã«æ•æ„Ÿãªæ¨è«–ãƒ¢ãƒ‡ãƒ«ã®å¿…è¦æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yafuly/status/1925753754961236006?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1988" target="_blank" rel="noopener noreferrer" class="title-link">LLMs Get Lost In Multi-Turn Conversation, Philippe Laban+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯ä¼šè©±å‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚¿ã‚¹ã‚¯ã‚’å®šç¾©ã™ã‚‹ã®ã‚’æ”¯æ´ã™ã‚‹ãŒã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®ä¼šè©±ã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ã€‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“ã®çµæœã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã§39%ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹ãŒè¦‹ã‚‰ã‚Œã€åˆæœŸã®ã‚¿ãƒ¼ãƒ³ã§ã®ä»®å®šã«ä¾å­˜ã—ã™ãã‚‹ã“ã¨ãŒåŸå› ã¨åˆ¤æ˜ã€‚LLMsã¯ä¼šè©±ä¸­ã«èª¤ã£ãŸæ–¹å‘ã«é€²ã‚€ã¨ã€å›å¾©ãŒé›£ã—ããªã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_stakaya/status/1926009283386155009?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Lost in the Middleãªã‚‰ã¬Lost in Conversation<br><img src="https://github.com/user-attachments/assets/9d4320f5-6fea-43ca-a7ab-a836e7e3642e" alt="image" loading="lazy"></p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/793" target="_blank" rel="noopener noreferrer">Lost in the Middle: How Language Models Use Long Contexts, Nelson F. Liu+, N/A, TACL'24</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1985" target="_blank" rel="noopener noreferrer" class="title-link">LaViDa: A Large Diffusion Language Model for Multimodal Understanding, Shufan Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LaViDaã¯ã€é›¢æ•£æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ï¼ˆDMï¼‰ã‚’åŸºã«ã—ãŸãƒ“ã‚¸ãƒ§ãƒ³ãƒ»ãƒ©ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«ï¼ˆVLMï¼‰ã§ã€é«˜é€Ÿãªæ¨è«–ã¨åˆ¶å¾¡å¯èƒ½ãªç”Ÿæˆã‚’å®Ÿç¾ã€‚æ–°æŠ€è¡“ã‚’å–ã‚Šå…¥ã‚Œã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦AR VLMã¨ç«¶äº‰åŠ›ã®ã‚ã‚‹æ€§èƒ½ã‚’é”æˆã€‚COCOã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã§é€Ÿåº¦å‘ä¸Šã¨æ€§èƒ½æ”¹å–„ã‚’ç¤ºã—ã€AR VLMã®å¼·åŠ›ãªä»£æ›¿æ‰‹æ®µã§ã‚ã‚‹ã“ã¨ã‚’è¨¼æ˜ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1925749919312159167?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Diffusion Modelã®æ³¢ãŒæ¥ãŸ</p>
<p>åŒç¨‹åº¦ã®ã‚µã‚¤ã‚ºã®ARãƒ¢ãƒ‡ãƒ«ã‚’outperform [^1]<br><img src="https://github.com/user-attachments/assets/aeb12147-48ba-4b64-917c-9976ec1ffa0a" alt="image" loading="lazy"><br><br>[^1]:ãŸã ã—ã€ã“ã‚ŒãŒæœ¬å½“ã«Diffusion Modelã‚’ä½¿ã£ãŸã“ã¨ã«ã‚ˆã‚‹æ©æµãªã®ã‹ã¯ã¾ã è«–æ–‡ã‚’èª­ã‚“ã§ã„ãªã„ã®ã§ã‚ã‹ã‚‰ãªã„ã€‚å¿…è¦ã«ãªã£ãŸã‚‰èª­ã‚€ã€‚ãŸã ã€Physics of Language Modelã®ã‚ˆã†ã«ã€å®Œå…¨ã«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§ç•°ãªã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¯”è¼ƒã—ãªã„ã¨ãã®è¾ºã¯ã‚ã‹ã‚‰ãªãã†ã§ã¯ã‚ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1984" target="_blank" rel="noopener noreferrer" class="title-link">dKV-Cache: The Cache for Diffusion Language Models, Xinyin Ma+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ‹¡æ•£è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆDLMï¼‰ã®é…ã„æ¨è«–ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã€é…å»¶KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€ç•°ãªã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã®è¡¨ç¾ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã«åŸºã¥ãã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥ã§ã€2ã¤ã®ãƒãƒªã‚¢ãƒ³ãƒˆã‚’è¨­è¨ˆã€‚dKV-Cache-Decodeã¯æå¤±ã®å°‘ãªã„åŠ é€Ÿã‚’æä¾›ã—ã€dKV-Cache-Greedyã¯é«˜ã„ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å®Ÿç¾ã€‚æœ€çµ‚çš„ã«ã€æ¨è«–é€Ÿåº¦ã‚’2ã€œ10å€å‘ä¸Šã•ã›ã€DLMã®æ€§èƒ½ã‚’å¼·åŒ–ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1925384029718946177?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ææ¡ˆæ‰‹æ³•ã‚’é©ç”¨ã—ãŸå ´åˆã€ARãªãƒ¢ãƒ‡ãƒ«ã¨Diffusion Modelã§ã€å®Ÿéš›ã®ã¨ã“ã‚ã©ã®ç¨‹åº¦ã®decodingé€Ÿåº¦ã®å·®ãŒã‚ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿãã†ã„ã£ãŸåˆ†æã¯ã–ãƒ¼ãƒ¼ã£ã¨è¦‹ãŸæ„Ÿã˜è¦‹å½“ãŸã‚‰ãªã‹ã£ãŸã‚ˆã†ã«æ€ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1983" target="_blank" rel="noopener noreferrer" class="title-link">Diffusion vs. Autoregressive Language Models: A Text Embedding  Perspective, Siyue Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ‹¡æ•£è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ãŒã€è‡ªå·±å›å¸°çš„ãªLLMã®ä¸€æ–¹å‘æ€§ã®åˆ¶é™ã‚’å…‹æœã—ã€æ–‡æ›¸æ¤œç´¢ã‚„æ¨è«–ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã€‚é•·æ–‡æ¤œç´¢ã§20%ã€æ¨è«–é›†ç´„å‹æ¤œç´¢ã§8%ã€æŒ‡ç¤ºã«å¾“ã£ãŸæ¤œç´¢ã§2%ã®å‘ä¸Šã‚’ç¤ºã—ã€åŒæ–¹å‘ã®æ³¨æ„ãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/trtd6trtd/status/1925775950500806742?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-05-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1982" target="_blank" rel="noopener noreferrer" class="title-link">LiveBench: A Challenging, Contamination-Limited LLM Benchmark, Colin White+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®æ±šæŸ“ã‚’é˜²ããŸã‚ã«ã€LLMç”¨ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒLiveBenchã€ã‚’å°å…¥ã€‚LiveBenchã¯ã€é »ç¹ã«æ›´æ–°ã•ã‚Œã‚‹è³ªå•ã€è‡ªå‹•ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã€ã•ã¾ã–ã¾ãªæŒ‘æˆ¦çš„ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ã€‚å¤šãã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ã€æ­£ç­”ç‡ã¯70%æœªæº€ã€‚è³ªå•ã¯æ¯æœˆæ›´æ–°ã•ã‚Œã€LLMã®èƒ½åŠ›å‘ä¸Šã‚’æ¸¬å®šå¯èƒ½ã«ã€‚ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®å‚åŠ ã‚’æ­“è¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã«å¯¾å‡¦ã§ãã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚é‡è¦ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-05-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1981" target="_blank" rel="noopener noreferrer" class="title-link">Parallel Scaling Law for Language Models, Mouxiang Chen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ãŠã„ã¦ã€ä¸¦åˆ—è¨ˆç®—ã‚’å¢—åŠ ã•ã›ã‚‹æ–°ã—ã„æ‰‹æ³•ã€ŒParScaleã€ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®å‰æ–¹ãƒ‘ã‚¹ã‚’ä¸¦åˆ—ã«å®Ÿè¡Œã—ã€å‡ºåŠ›ã‚’å‹•çš„ã«é›†ç´„ã™ã‚‹ã“ã¨ã§ã€æ¨è«–åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ParScaleã¯ã€å°‘ãªã„ãƒ¡ãƒ¢ãƒªå¢—åŠ ã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã§åŒç­‰ã®æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã—ã€æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’å†åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ã‚¹ãƒˆã‚‚å‰Šæ¸›å¯èƒ½ã€‚æ–°ã—ã„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã¯ã€ãƒªã‚½ãƒ¼ã‚¹ãŒé™ã‚‰ã‚ŒãŸçŠ¶æ³ã§ã®å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«å±•é–‹ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1924959706331939099?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/405" target="_blank" rel="noopener noreferrer">[Paper Note] Prefix-Tuning: Optimizing Continuous Prompts for Generation, Xiang Lisa Li+, arXiv'21, 2021.01</a>
<br><br>ã¨è€ƒãˆæ–¹ãŒä¼¼ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-05-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1980" target="_blank" rel="noopener noreferrer" class="title-link">AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via  Reinforcement Learning, Chenwei Lou+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AdaCoTï¼ˆAdaptive Chain-of-Thoughtï¼‰ã¯ã€LLMsãŒæ¨è«–ã‚’é©å¿œçš„ã«è¡Œã†æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€CoTã®å‘¼ã³å‡ºã—ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦ã€ã‚¯ã‚¨ãƒªã®è¤‡é›‘ã•ã«åŸºã¥ã„ã¦CoTã®å¿…è¦æ€§ã‚’åˆ¤æ–­ã—ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã—ã¾ã™ã€‚å®Ÿé¨“ã§ã¯ã€AdaCoTãŒCoTãƒˆãƒªã‚¬ãƒ¼ç‡ã‚’3.18%ã«ä½ä¸‹ã•ã›ã€å¿œç­”ãƒˆãƒ¼ã‚¯ãƒ³ã‚’69.06%æ¸›å°‘ã•ã›ã¤ã¤ã€é«˜ã„æ€§èƒ½ã‚’ç¶­æŒã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>RLã®Rewardã«ãŠã„ã¦ã€bassã®ãƒªãƒ¯ãƒ¼ãƒ‰ã ã‘ã§ãªãã€<br>- reasoningã‚’ãªãã—ãŸå ´åˆã®ãƒšãƒŠãƒ«ãƒ†ã‚£é …<br>- reasoningã‚’overuseã—ãŸå ´åˆã®ãƒšãƒŠãƒ«ãƒ†ã‚£é …<br>- formattingã«é–¢ã™ã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£é …<br>ã‚’è¨­å®šã—ã€reasoningã®æœ‰ç„¡ã‚’é©åˆ‡ã«åˆ¤æ–­ã§ããŸå ´åˆã«rewardãŒæœ€å¤§åŒ–ã•ã‚Œã‚‹ã‚ˆã†ãªå½¢ã«ã—ã¦ã„ã‚‹ã€‚(2.2.2)<br><br>ãŒã€multi-stageã®RLã§ã¯ï¼ˆstageã”ã¨ã«åˆ©ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å¤‰æ›´ã™ã‚‹ãŒï¼‰ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†å¸ƒã«ã¯æ­ªã¿ãŒã‚ã‚Šã€ãŸã¨ãˆã°å¸¸ã«CoTãŒæœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚å­˜åœ¨ã—ã¦ãŠã‚Šï¼ˆæ•°å­¦ã«é–¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãªã©ï¼‰ã€ãã®å ´åˆå¸¸ã«CoTã‚’ã™ã‚‹ã‚ˆã†ãªåˆ†å¸ƒã‚’å­¦ç¿’ã—ã¦ã—ã¾ã„ã€AdaptiveãªCoT decisionãŒå´©å£Šã—ãŸã‚Šã€ä¸å®‰å®šã«ãªã£ã¦ã—ã¾ã†ï¼ˆdecision boundary collapseã¨å‘¼ã¶ï¼‰ã€‚ç‰¹ã«ã“ã‚ŒãŒfinal stageã§èµ·ãã‚‹ã¨æœ€æ‚ªã§ã€ã“ã‚Œã¾ã§Adaptiveã«CoTã•ã‚Œã‚‹ã‚ˆã†å­¦ç¿’ã•ã‚Œã¦ããŸã‚‚ã®ãŒå…¨ã¦å´©å£Šã—ã¦ã—ã¾ã†ã€‚ã“ã‚Œã‚’é˜²ããŸã‚ã«ã€Selective Loss Maskingã¨ã„ã†lossã‚’å°å…¥ã—ã¦ã„ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€decision token [^1]ã®lossã¸ã®è²¢çŒ®ã‚’ãƒã‚¹ã‚­ãƒ³ã‚°ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã§ã€CoTãŒç”Ÿã˜ã‚‹ratioã«ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹ã€‚ä»Šå›ã¯ã€Decision tokenã¨ã—ã¦ã€`<think>`ãƒˆãƒ¼ã‚¯ãƒ³ç›´å¾Œã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’decision tokenã¨ã¿ãªã—ã€lossã«å¯¾ã™ã‚‹è²¢çŒ®ã‚’ãƒã‚¹ã‚¯ã—ã¦ã„ã‚‹ï¼ˆSelective Loss Maskingï¼‰ã€‚<br><br>[^1]: CoTã™ã‚‹ã‹ã©ã†ã‹ã¯å¤šãã®å ´åˆã“ã®Decision Tokenã«ã‚ˆã£ã¦æ±ºã¾ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ãŒã©ã£ã‹ã®ç ”ç©¶ã«ç¤ºã•ã‚Œã¦ã„ãŸã¯ãš&lt;/p&gt;<p>ã„ã¤ã‹å¿…è¦ã«ãªã£ãŸã‚‰ã—ã£ã‹ã‚Šèª­ã‚€ãŒã€å…¨ã¦ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§Selective Loss Maskingã‚’ã—ãŸã‚‰ã€SFTã§warm upã—ãŸæ®µéšã‹ã‚‰ã‚ã¾ã‚ŠCoTã®ratioãŒå¤‰åŒ–ã—ãªã„ã‚ˆã†ãªå­¦ç¿’ã®ã•ã‚Œæ–¹ã«ãªã‚‹æ°—ãŒã™ã‚‹ãŒã€ã©ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã«å¯¾ã—ã¦applyã™ã‚‹ã®ã ã‚ã†ã‹ã€‚</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2025-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1979" target="_blank" rel="noopener noreferrer" class="title-link">Model Merging in Pre-training of Large Language Models, Yunshui Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ³ã‚°ã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å¼·åŒ–ã«æœ‰æœ›ãªæŠ€è¡“ã§ã‚ã‚Šã€æœ¬è«–æ–‡ã§ã¯ãã®äº‹å‰å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã‘ã‚‹åŒ…æ‹¬çš„ãªèª¿æŸ»ã‚’è¡Œã†ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ä¸€å®šã®å­¦ç¿’ç‡ã§è¨“ç·´ã•ã‚ŒãŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒãƒ¼ã‚¸ã™ã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Šã¨ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°æŒ™å‹•ã®äºˆæ¸¬ãŒå¯èƒ½ã«ãªã‚‹ã“ã¨ã‚’ç¤ºã—ã€åŠ¹ç‡çš„ãªãƒ¢ãƒ‡ãƒ«é–‹ç™ºã¨ä½ã‚³ã‚¹ãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«å¯„ä¸ã™ã‚‹ã€‚ãƒãƒ¼ã‚¸æˆ¦ç•¥ã‚„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç ”ç©¶ã‚’é€šã˜ã¦æ–°ãŸãªæ´å¯Ÿã‚’æä¾›ã—ã€å®Ÿç”¨çš„ãªäº‹å‰å­¦ç¿’ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«æç¤ºã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1924804324812873990?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span></think></p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/giffmana/status/1924849877634449878?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/KnowledgeGraph.html" target="_blank" rel="noopener noreferrer">#KnowledgeGraph</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1978" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Reasoning can Improve Factuality in Large Language Models, Mike Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‰ãƒ¡ã‚¤ãƒ³ã®è³ªå•å¿œç­”ã«ãŠã‘ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®æ¨è«–èƒ½åŠ›ã‚’æ¤œè¨ã—ã€æ¨è«–ã®ç—•è·¡ã‚’æŠ½å‡ºã—ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã£ãŸã€‚çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‹ã‚‰ã®æƒ…å ±ã‚’å°å…¥ã—ã€168å›ã®å®Ÿé¨“ã‚’é€šã˜ã¦170ä¸‡ã®æ¨è«–ã‚’åˆ†æã—ãŸçµæœã€å°å‹ãƒ¢ãƒ‡ãƒ«ãŒå…ƒã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚äº‹å®Ÿã®æ­£ç¢ºæ€§ã‚’é¡•è‘—ã«æ”¹å–„ã—ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã•ã‚‰ã«2-8%ã®å‘ä¸ŠãŒç¢ºèªã•ã‚ŒãŸã€‚å®Ÿé¨“æˆæœã¯å…¬é–‹ã•ã‚Œã€ã•ã‚‰ãªã‚‹ç ”ç©¶ã«å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1924477447120068895?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1977" target="_blank" rel="noopener noreferrer" class="title-link">Insights into DeepSeek-V3: Scaling Challenges and Reflections on  Hardware for AI Architectures, Chenggang Zhao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- DeepSeek-V3ã¯ã€2,048å°ã®NVIDIA H800 GPUã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢åˆ¶ç´„ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®å…±åŒè¨­è¨ˆã‚’ç¤ºã™ã€‚ãƒ¡ãƒ¢ãƒªåŠ¹ç‡å‘ä¸Šã®ãŸã‚ã®ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰æ½œåœ¨æ³¨æ„ã‚„ã€è¨ˆç®—ã¨é€šä¿¡ã®æœ€é©åŒ–ã‚’å›³ã‚‹å°‚é–€å®¶ã®æ··åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€FP8æ··åˆç²¾åº¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãªã©ã®é©æ–°ã‚’å¼·èª¿ã€‚ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«åŸºã¥ãå°†æ¥ã®æ–¹å‘æ€§ã«ã¤ã„ã¦è­°è«–ã—ã€AIãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã«å¿œãˆã‚‹ãŸã‚ã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã¨ãƒ¢ãƒ‡ãƒ«ã®å…±åŒè¨­è¨ˆã®é‡è¦æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/deedydas/status/1924512147947848039?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Probing.html" target="_blank" rel="noopener noreferrer">#Probing</a>
<span class="issue_date">Issue Date: 2025-05-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1974" target="_blank" rel="noopener noreferrer" class="title-link">Why Vision Language Models Struggle with Visual Arithmetic? Towards   Enhanced Chart and Geometry Understanding, Kung-Hsiang Huang+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- Vision Language Models (VLMs)ã¯è¦–è¦šçš„ç®—è¡“ã«è‹¦åŠ´ã—ã¦ã„ã‚‹ãŒã€CogAlignã¨ã„ã†æ–°ã—ã„ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã‚’ææ¡ˆã—ã€VLMã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚CogAlignã¯è¦–è¦šçš„å¤‰æ›ã®ä¸å¤‰ç‰¹æ€§ã‚’èªè­˜ã™ã‚‹ã‚ˆã†ã«è¨“ç·´ã—ã€CHOCOLATEã§4.6%ã€MATH-VISIONã§2.9%ã®æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’60%å‰Šæ¸›ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åŸºæœ¬çš„ãªè¦–è¦šçš„ç®—è¡“èƒ½åŠ›ã®å‘ä¸Šã¨ä¸‹æµã‚¿ã‚¹ã‚¯ã¸ã®è»¢é€ã®åŠ¹æœãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/steeve__huang/status/1923543884367306763?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¢å­˜ã®LLM (proprietary, openweightãã‚Œãã‚Œ)ãŒã€ã‚·ãƒ³ãƒ—ãƒ«ãªvisual arithmeticã‚¿ã‚¹ã‚¯(e.g., ç·šåˆ†ã®é•·ã•æ¯”è¼ƒ, Chartä¸Šã®dotã®ç†è§£)ãªã©ã®æ€§èƒ½ãŒä½ã„ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã€<br><img src="https://github.com/user-attachments/assets/039a48de-67a5-4c81-ba59-174acd508479" alt="image" loading="lazy"><br>ãã‚Œã‚‰ã®åŸå› ã‚’(1)Vision Encoderã®representationã¨(2)Vision Encoderã‚’Freezeã—ãŸä¸Šã§ã®Text Decoderã®finetuningã§åˆ†æã—ãŸã€‚ãã®çµæœã€(1)ã§ã¯ã„ãã¤ã‹ã®ã‚¿ã‚¹ã‚¯ã§linear layerã®probingã§ã¯é«˜ã„æ€§èƒ½ãŒé”æˆã§ããªã„ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€Vision Encoderã«ã‚ˆã‚‹representationãŒã‚¿ã‚¹ã‚¯ã«é–¢ã™ã‚‹æƒ…å ±ã‚’å†…åŒ…ã§ãã¦ã„ãªã„ã‹ã€ã‚¿ã‚¹ã‚¯ã«é–¢ã™ã‚‹æƒ…å ±ã¯å†…åŒ…ã—ã¦ã„ã‚‹ãŒlinear layerã§ã¯ãã‚Œã‚’ååˆ†ã«å¯èƒ½ã§ããªã„å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚ŒãŸã€‚<br><img src="https://github.com/user-attachments/assets/0eb90fa2-7b6a-43b6-81d9-b5f7e6fb3ea8" alt="image" loading="lazy"><br><br>ã“ã‚Œã‚’ã•ã‚‰ã«åˆ†æã™ã‚‹ãŸã‚ã«(2)ã‚’å®Ÿæ–½ã—ãŸã¨ã“ã‚ã€Vision Encoderã‚’freezeã—ã¦ã„ã¦ã‚‚finetuningã«ã‚ˆã‚Šquery stringã«é–¢ã‚ã‚‰ãšé«˜ã„æ€§èƒ½ã‚’ç²å¾—ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€Vision Encoderå´ã®representationã®å•é¡Œã§ã¯ãªãã€Text Decoderã¨å´ã§ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹éš›ã«Finetuningã—ãªã„ã¨ã†ã¾ãæ´»ç”¨ã§ããªã„ã“ã¨ãŒåˆ¤æ˜ã—ãŸã€‚<br><img src="https://github.com/user-attachments/assets/cd122d99-9228-44b1-9827-cdb56f49d492" alt="image" loading="lazy"></p>
<p>æ‰‹æ³•ã®ã¨ã“ã‚ã¯ã¾ã å…¨ç„¶ã—ã£ã‹ã‚Šèª­ã‚ã¦ã„ãªã„ã®ã ãŒã€ç”»åƒã«é–¢ã™ã‚‹ç‰¹å®šã®å±æ€§ã«é–¢ã™ã‚‹ã‚¯ã‚¨ãƒªã¨å›ç­”ã®ãƒšã‚¢ã‚’åˆæˆã—ã€DPOã™ã‚‹ã“ã¨ã§ã€zero-shotã®æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã€ã¨ã„ã†æ„Ÿã˜ã£ã½ã„ï¼Ÿ<br><img src="https://github.com/user-attachments/assets/707b1cc9-8bbf-45a5-b564-f654503c836e" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/281da17b-c8c3-455a-aa51-043ed297ae1f" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/VerifiableRewards.html" target="_blank" rel="noopener noreferrer">#VerifiableRewards</a>
<span class="issue_date">Issue Date: 2025-05-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1964" target="_blank" rel="noopener noreferrer" class="title-link">J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning, Chenxi Whitehouse+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¼·åŒ–å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒJ1ã‚’ç”¨ã„ã¦LLMã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã—ã€åˆ¤æ–­ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹æ€è€ƒä¿ƒé€²ã¨ãƒã‚¤ã‚¢ã‚¹è»½æ¸›ã‚’å›³ã‚Šã¾ã™ã€‚J1ã¯ã€ä»–ã®åŒã‚µã‚¤ã‚ºãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ç‰¹ã«å°å‹ãƒ¢ãƒ‡ãƒ«ã§ã‚‚å„ªã‚ŒãŸçµæœã‚’å‡ºã—ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¯è‡ªå·±ç”Ÿæˆã—ãŸå‚ç…§å›ç­”ã¨æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šè‰¯ã„åˆ¤æ–­ã‚’å­¦ã¶ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1923186392420450545?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLM-as-a-Judgeã®ãªã‚ã®ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ãƒ¬ã‚·ãƒ”ã«ãŠã„ã¦ã€åˆã‚ã¦RLã‚’é©ç”¨ã—ãŸç ”ç©¶ã¨ä¸»å¼µã—ã€ã‚ˆã‚Šé«˜å“è³ªãªreasoning traceã‚’å‡ºåŠ›ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Šã‚’ã•ã›ã‚‹ã€‚<br><br>å…·ä½“çš„ã«ã¯Verifiableãªpromptã¨non verifiableãªpromptã®ä¸¡æ–¹ã‹ã‚‰verifiableãªpreference pairã‚’ä½œæˆã—pointwiseãªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã€ã‚ã‚‹ã„ã¯pairwiseãªjudgeã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã®rewardã‚’è¨­è¨ˆã—GRPOã§å­¦ç¿’ã™ã‚‹ã€ã¿ãŸã„ãªè©±ã£ã½ã„ã€‚<br>non verifiableãªpromptã‚‚ç”¨ã„ã‚‹ã®ã¯ã€ãã†ã„ã£ãŸpromptã«å¯¾ã—ã¦ã‚‚judgeã§ãã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã€‚<br><br>mathã«é–¢ã™ã‚‹promptã¯verifiableãªã®ã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒä¸æ­£è§£ãªã‚‚ã®ã‚’rejection samplingã—ã€WildChatã®ã‚ˆã†ãªãƒãƒ£ãƒƒãƒˆã¯verifiableã§ã¯ãªã„ã®ã§ã€instructionã«ãƒã‚¤ã‚ºã‚’æ··ãœã¦å¾—ã‚‰ã‚ŒãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’rejection samplingã—ã€åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’å¾—ã‚‹ã“ã¨ã§ã€non verifiableãªpromptã«ã¤ã„ã¦ã‚‚ã€verifiableãªrewardã‚’è¨­è¨ˆã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/4264f599-2067-4688-99e7-b68cc1dc771d" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<a class="button" href="articles/SpeculativeDecoding.html" target="_blank" rel="noopener noreferrer">#SpeculativeDecoding</a>
<span class="issue_date">Issue Date: 2025-05-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1961" target="_blank" rel="noopener noreferrer" class="title-link">Faster Cascades via Speculative Decoding, Harikrishna Narasimhan+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ã¨æ¨æ¸¬ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã§ã‚ã‚Šã€ç•°ãªã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æŒã¤ã€‚ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ã¯é›£ã—ã„å…¥åŠ›ã«å¯¾ã—ã¦å¤§ããªãƒ¢ãƒ‡ãƒ«ã‚’é…å»¶çš„ã«ä½¿ç”¨ã—ã€æ¨æ¸¬ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯ä¸¦è¡Œæ¤œè¨¼ã§å¤§ããªãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã™ã‚‹ã€‚æ–°ãŸã«ææ¡ˆã™ã‚‹æ¨æ¸¬ã‚«ã‚¹ã‚±ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æŠ€è¡“ã¯ã€ä¸¡è€…ã®åˆ©ç‚¹ã‚’çµ„ã¿åˆã‚ã›ã€æœ€é©ãªé…å»¶ãƒ«ãƒ¼ãƒ«ã‚’ç‰¹å®šã™ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€ææ¡ˆæ‰‹æ³•ãŒã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ãŠã‚ˆã³æ¨æ¸¬ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸã‚³ã‚¹ãƒˆå“è³ªãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1922059828429832259?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview: 


<a href="https://openreview.net/forum?id=vo9t20wsmd" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=vo9t20wsmd</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-05-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1946" target="_blank" rel="noopener noreferrer" class="title-link">EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language  Models, Ziwen Xu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€LLMã®æŒ™å‹•ã‚’åˆ¶å¾¡ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒEasyEdit2ã€ã‚’ææ¡ˆã€‚å®‰å…¨æ€§ã‚„æ„Ÿæƒ…ã€å€‹æ€§ãªã©ã®ä»‹å…¥ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€ä½¿ã„ã‚„ã™ã•ãŒç‰¹å¾´ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯æŠ€è¡“çš„çŸ¥è­˜ãªã—ã§ãƒ¢ãƒ‡ãƒ«ã®å¿œç­”ã‚’èª¿æ•´å¯èƒ½ã€‚æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€ã‚¹ãƒ†ã‚¢ãƒªãƒ³ã‚°ãƒ™ã‚¯ãƒˆãƒ«ã‚’è‡ªå‹•ç”Ÿæˆãƒ»é©ç”¨ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ­è¼‰ã€‚å®Ÿè¨¼çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å ±å‘Šã—ã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚„ãƒ‡ãƒ¢ã‚‚å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>github:


<a href="https://github.com/zjunlp/EasyEdit/tree/main" target="_blank" rel="noopener noreferrer">https://github.com/zjunlp/EasyEdit/tree/main</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1944" target="_blank" rel="noopener noreferrer" class="title-link">Nemotron-CC: Transforming Common Crawl into a Refined Long-Horizon   Pretraining Dataset, Dan Su+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- FineWeb-Eduã¨DCLMã¯ã€ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚Šãƒ‡ãƒ¼ã‚¿ã®90%ã‚’å‰Šé™¤ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«é©ã•ãªããªã£ãŸã€‚è‘—è€…ã¯ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆ†é¡å™¨ã‚„åˆæˆãƒ‡ãƒ¼ã‚¿ã®è¨€ã„æ›ãˆã‚’ç”¨ã„ã¦ã€ç²¾åº¦ã¨ãƒ‡ãƒ¼ã‚¿é‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ”¹å–„ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚1Tãƒˆãƒ¼ã‚¯ãƒ³ã§8Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€DCLMã«å¯¾ã—ã¦MMLUã‚’5.6ãƒã‚¤ãƒ³ãƒˆå‘ä¸Šã•ã›ãŸã€‚æ–°ã—ã„6.3Tãƒˆãƒ¼ã‚¯ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€DCLMã¨åŒç­‰ã®æ€§èƒ½ã‚’æŒã¡ãªãŒã‚‰ã€4å€ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’å«ã¿ã€é•·ãƒˆãƒ¼ã‚¯ãƒ³ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚15Tãƒˆãƒ¼ã‚¯ãƒ³ã®ãŸã‚ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸ8Bãƒ¢ãƒ‡ãƒ«ã¯ã€Llama 3.1ã®8Bãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/Toxicity.html" target="_blank" rel="noopener noreferrer">#Toxicity</a>
<a class="button" href="articles/ActivationSteering/ITI.html" target="_blank" rel="noopener noreferrer">#ActivationSteering/ITI</a>
<span class="issue_date">Issue Date: 2025-05-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1940" target="_blank" rel="noopener noreferrer" class="title-link">When Bad Data Leads to Good Models, Kenneth Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€LLMã®äº‹å‰å­¦ç¿’ã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿ã®è³ªã®å†æ¤œè¨ã‚’è¡Œã„ã€æœ‰å®³ãƒ‡ãƒ¼ã‚¿ãŒäº‹å¾Œå­¦ç¿’ã«ãŠã‘ã‚‹åˆ¶å¾¡ã‚’å‘ä¸Šã•ã›ã‚‹å¯èƒ½æ€§ã‚’æ¢ã‚Šã¾ã™ã€‚ãƒˆã‚¤å®Ÿé¨“ã‚’é€šã˜ã¦ã€æœ‰å®³ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆãŒå¢—åŠ ã™ã‚‹ã“ã¨ã§æœ‰å®³æ€§ã®æ¦‚å¿µãŒç·šå½¢è¡¨ç¾ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã€æœ‰å®³ãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆçš„æœ‰å®³æ€§ã‚’å¢—åŠ ã•ã›ã¤ã¤ã‚‚é™¤å»ã—ã‚„ã™ããªã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚è©•ä¾¡çµæœã¯ã€æœ‰å®³ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆçš„æœ‰å®³æ€§ã‚’ä½ä¸‹ã•ã›ã¤ã¤ä¸€èˆ¬çš„ãªèƒ½åŠ›ã‚’ä¿æŒã™ã‚‹è‰¯å¥½ãªãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ke_li_2021/status/1920646069613957606?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯é¢ç™½ãã†</p>
<p>Webã‚³ãƒ¼ãƒ‘ã‚¹ãªã©ã‚’äº‹å‰å­¦ç¿’ã§åˆ©ç”¨ã™ã‚‹éš›ã¯ã€è³ªã®é«˜ã„ãƒ‡ãƒ¼ã‚¿ã‚’æ®‹ã—ã¦å­¦ç¿’ã—ãŸæ–¹ãŒè‰¯ã„ã¨ã•ã‚Œã¦ã„ã‚‹ãŒã€4chanã®ã‚ˆã†ãªtoxicãªãƒ‡ãƒ¼ã‚¿ã‚’æ··ãœã¦äº‹å‰å­¦ç¿’ã—ã¦ã€å¾Œã‹ã‚‰detoxï¼ˆInference Time Intervention <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1941" target="_blank" rel="noopener noreferrer">Inference-Time Intervention: Eliciting Truthful Answers from a Language   Model, Kenneth Li+, NeurIPS'23</a>
 , SFT, DPO)ã™ã‚‹ã“ã¨ã§ã€æœ€çµ‚çš„ãªãƒ¢ãƒ‡ãƒ«ã®toxicãªoutputãŒæ¸›ã‚‹ã¨ã„ã†è©±ã‚‰ã—ã„ã€‚ã“ã‚Œã¯ãã‚‚ãã‚‚äº‹å‰å­¦ç¿’æ™‚ç‚¹ã§toxicãªãƒ‡ãƒ¼ã‚¿ã®signalãŒé™¤å¤–ã•ã‚Œã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ãŒtoxicãªå†…å®¹ã®representationã‚’å­¦ç¿’ã§ããšã€æœ€çµ‚çš„ã«toxicã‹å¦ã‹ã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ããªããªã‚‹ãŸã‚ã€ã¨è€ƒå¯Ÿã—ã¦ã„ã‚‹ï¼ˆã£ã½ã„ï¼‰<br><img src="https://github.com/user-attachments/assets/7f6efd4b-0679-4143-9a7d-1bf3ea5b6f3a" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/0acec11b-d851-4137-b0aa-1ed7172388e1" alt="image" loading="lazy"></p>
<p>æœ‰å®³ãªå‡ºåŠ›ã‚’æ¸›ã‚‰ã›ãã†ãªã“ã¨ã¯åˆ†ã‹ã£ãŸãŒã€Activation Steeringã«ã‚ˆã£ã¦ã©ã®ç¨‹åº¦ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã®ã‹ãŒæ°—ã«ãªã‚‹ã€ã¨æ€ã£ãŸãŒAppendixã«è¨˜è¼‰ãŒã‚ã£ãŸã€‚ç´°ã‹ãæ›¸ã‹ã‚Œã¦ã„ãªã„ã®ã§æ¨æ¸¬ã‚’å«ã‚€ãŒã€å„ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦Toxicãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§Probingã™ã‚‹ã“ã¨ã§TopKã®headã‚’æ±ºã‚ã¦ã€Kã®å€¤ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§interventionã®å¼·ã•ã‚’èª¿æ•´ã—ã€Toxicãƒ‡ãƒ¼ã‚¿ã®å‰²åˆã‚’å¤‰åŒ–ã•ã›ã¦è©•ä¾¡ã—ã¦ã¿ãŸã¨ã“ã‚ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å¤§ããªå½±éŸ¿ã¯ãªã‹ã£ãŸã¨ã„ã†ã“ã¨ã ã¨æ€ã‚ã‚Œã‚‹ï¼ˆãŸã ã—1Bãƒ¢ãƒ‡ãƒ«ã§ã®å®Ÿé¨“ã—ã‹ãªã„ï¼‰<br><br><img src="https://github.com/user-attachments/assets/4c79ca22-6916-438d-ad31-07596c82bfd1" alt="image" loading="lazy"><br></p>
<p>ãŠãã‚‰ã2,3ç¯€ã‚ãŸã‚ŠãŒä¸€ç•ªãŠã‚‚ã—ã‚ã„ãƒã‚¤ãƒ³ãƒˆãªã®ã ã¨æ€ã‚ã‚Œã‚‹ãŒã¾ã èª­ã‚ã¦ã„ãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1938" target="_blank" rel="noopener noreferrer" class="title-link">Reinforcement Learning for Reasoning in Large Language Models with One   Training Example, Yiping Wang+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- 1-shot RLVRã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€LLMã®æ•°å­¦çš„æ¨è«–èƒ½åŠ›ãŒå¤§å¹…ã«å‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚Qwen2.5-Math-1.5Bãƒ¢ãƒ‡ãƒ«ã¯ã€MATH500ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒ36.0%ã‹ã‚‰73.6%ã«æ”¹å–„ã•ã‚Œã€ä»–ã®æ•°å­¦çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚‚åŒæ§˜ã®å‘ä¸ŠãŒè¦‹ã‚‰ã‚ŒãŸã€‚1-shot RLVRä¸­ã«ã¯ã€ã‚¯ãƒ­ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³ä¸€èˆ¬åŒ–ã‚„æŒç¶šçš„ãªãƒ†ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®æ”¹å–„ãŒè¦³å¯Ÿã•ã‚Œã€ãƒãƒªã‚·ãƒ¼å‹¾é…æå¤±ãŒä¸»ãªè¦å› ã§ã‚ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±ã®è¿½åŠ ã‚‚é‡è¦ã§ã€çµæœå ±é…¬ãªã—ã§ã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã—ãŸã€‚ã“ã‚Œã‚‰ã®æˆæœã¯ã€RLVRã®ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã«é–¢ã™ã‚‹ã•ã‚‰ãªã‚‹ç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/03cd9200-7fed-4c6d-a5a6-2379d2c8950a" alt="image" loading="lazy"></p>
<p>ä¸‹è¨˜ãƒã‚¹ãƒˆã§Qwenã«å¯¾ã—ã¦promptã‚’é©åˆ‡ã«ä¸ãˆã‚‹ã“ã¨ã§ã€è¿½åŠ ã®post trainingç„¡ã—ã§é«˜ã„æ•°å­¦ã«é–¢ã™ã‚‹èƒ½åŠ›ã‚’å¼•ãå‡ºã›ãŸã¨ã„ã†æƒ…å ±ãŒã‚ã‚‹ã€‚ãŠãã‚‰ãäº‹å‰å­¦ç¿’æ™‚ã«æ•°å­¦ã®QAãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã£ã¦ç¶™ç¶šäº‹å‰å­¦ç¿’ã•ã‚Œã¦ãŠã‚Šã€ã“ã®èƒ½åŠ›ã¯ãã®éš›ã«èº«ã«ã¤ã„ã¦ã„ã‚‹ãŸã‚ã€æ•°å­¦ã«å¯¾ã™ã‚‹é«˜ã„èƒ½åŠ›ã¯å®Ÿã¯ç°¡å˜ã«å¼•ãå‡ºã™ã“ã¨ãŒã§ãã‚‹ã®ã‹ã‚‚ã—ã‚Œãªã„ï¼ˆã ã‹ã‚‰1ã‚µãƒ³ãƒ—ãƒ«ã§ã‚‚æ€§èƒ½ãŒå‘ä¸Šã—ãŸã®ã§ã¯ãªã„ã‹ï¼Ÿï¼‰ã¨ã„ã£ãŸè€ƒå¯ŸãŒã‚ã‚‹ã€‚<br><br>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/weiliu99/status/1930826904522875309?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2011" target="_blank" rel="noopener noreferrer">[Paper Note] ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in  Large Language Models, Mingjie Liu+, NeurIPS'25</a>
<br><br>ã¨ã¯ã©ã®ã‚ˆã†ãªé–¢ä¿‚æ€§ãŒã‚ã‚‹ã ã‚ã†ã‹ï¼Ÿ</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ypwang61/status/1968834328508379563?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1937" target="_blank" rel="noopener noreferrer" class="title-link">Rewriting Pre-Training Data Boosts LLM Performance in Math and Code, Kazuki Fujii+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å…¬å…±ãƒ‡ãƒ¼ã‚¿ã‚’ä½“ç³»çš„ã«æ›¸ãæ›ãˆã‚‹ã“ã¨ã§å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹2ã¤ã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€SwallowCodeã¨SwallowMathã‚’ç´¹ä»‹ã€‚SwallowCodeã¯Pythonã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’æ´—ç·´ã•ã›ã‚‹4æ®µéšã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç”¨ã„ã€ä½å“è³ªã®ã‚³ãƒ¼ãƒ‰ã‚’ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã€‚SwallowMathã¯ãƒœã‚¤ãƒ©ãƒ¼ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å‰Šé™¤ã—ã€è§£æ±ºç­–ã‚’ç°¡æ½”ã«å†ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Llama-3.1-8Bã®ã‚³ãƒ¼ãƒ‰ç”Ÿæˆèƒ½åŠ›ãŒHumanEvalã§+17.0ã€GSM8Kã§+12.4å‘ä¸Šã€‚ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯å…¬é–‹ã•ã‚Œã€å†ç¾å¯èƒ½ãªç ”ç©¶ã‚’ä¿ƒé€²ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1920141189652574346?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1920613041026314274?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/ZeroData.html" target="_blank" rel="noopener noreferrer">#ZeroData</a>
<span class="issue_date">Issue Date: 2025-05-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1936" target="_blank" rel="noopener noreferrer" class="title-link">Absolute Zero: Reinforced Self-play Reasoning with Zero Data, Andrew Zhao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„RLVRãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã€ŒAbsolute Zeroã€ã‚’ææ¡ˆã—ã€è‡ªå·±å­¦ç¿’ã‚’é€šã˜ã¦æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹AZRã‚’å°å…¥ã€‚å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã«ä¾å­˜ã›ãšã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚„æ•°å­¦çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã§SOTAãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚æ—¢å­˜ã®ã‚¼ãƒ­è¨­å®šãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚±ãƒ¼ãƒ«ã«ã‚‚é©ç”¨å¯èƒ½ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1919946713567264917?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-05-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1935" target="_blank" rel="noopener noreferrer" class="title-link">Tina: Tiny Reasoning Models via LoRA, Shangshang Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Tinaã¯ã€ã‚³ã‚¹ãƒˆåŠ¹ç‡ã‚ˆãå¼·åŠ›ãªæ¨è«–èƒ½åŠ›ã‚’å®Ÿç¾ã™ã‚‹å°å‹ã®æ¨è«–ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã§ã‚ã‚Šã€1.5Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã«å¼·åŒ–å­¦ç¿’ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§é«˜ã„æ¨è«–æ€§èƒ½ã‚’ç¤ºã™ã€‚Tinaã¯ã€å¾“æ¥ã®SOTAãƒ¢ãƒ‡ãƒ«ã¨ç«¶äº‰åŠ›ãŒã‚ã‚Šã€AIME24ã§20%ä»¥ä¸Šã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ã‚¹ãƒˆã¯ã‚ãšã‹9ãƒ‰ãƒ«ã§260å€ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ã‚’å®Ÿç¾ã€‚LoRAã‚’é€šã˜ãŸåŠ¹ç‡çš„ãªRLæ¨è«–ã®åŠ¹æœã‚’æ¤œè¨¼ã—ã€ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1920107023980462575?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ï¼ˆãŠãã‚‰ãï¼‰Reasoningãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€LoRAã¨RLã‚’çµ„ã¿åˆã‚ã›ã¦ã€reasoningèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ãŸåˆã‚ã¦ã®ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DataGeneration.html" target="_blank" rel="noopener noreferrer">#DataGeneration</a>
<a class="button" href="articles/DataDistillation.html" target="_blank" rel="noopener noreferrer">#DataDistillation</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-05-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1931" target="_blank" rel="noopener noreferrer" class="title-link">R.I.P.: Better Models by Survival of the Fittest Prompts, Ping Yu+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å“è³ªãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’è€ƒæ…®ã—ã€ä½å“è³ªãªå…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã‚‚ãŸã‚‰ã™å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€Rejecting Instruction Preferencesï¼ˆRIPï¼‰ã¨ã„ã†ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§è©•ä¾¡æ‰‹æ³•ã‚’ææ¡ˆã€‚RIPã¯ã€æ‹’å¦ã•ã‚ŒãŸå¿œç­”ã®å“è³ªã¨é¸æŠã•ã‚ŒãŸå¥½ã¿ãƒšã‚¢ã¨ã®å ±é…¬ã‚®ãƒ£ãƒƒãƒ—ã‚’æ¸¬å®šã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚»ãƒƒãƒˆã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚„é«˜å“è³ªãªåˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆã«åˆ©ç”¨å¯èƒ½ã€‚å®Ÿé¨“çµæœã§ã¯ã€RIPã‚’ç”¨ã„ã‚‹ã“ã¨ã§Llama 3.1-8B-Instructã§ã®æ€§èƒ½ãŒå¤§å¹…ã«å‘ä¸Šã—ã€Llama 3.3-70B-Instructã§ã¯ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã§ã®é †ä½ãŒä¸Šæ˜‡ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1885160135053459934?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã‚¹ãƒ¬ãƒƒãƒ‰ã§è‘—è€…ãŒè«–æ–‡ã®è§£èª¬ã‚’ã—ã¦ã„ã‚‹ã€‚</span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-05-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1930" target="_blank" rel="noopener noreferrer" class="title-link">Thinking LLMs: General Instruction Following with Thought Generation, Tianhao Wu+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã«æ€è€ƒèƒ½åŠ›ã‚’è£…å‚™ã™ã‚‹ãŸã‚ã®è¨“ç·´æ–¹æ³•ã‚’ææ¡ˆã€‚åå¾©çš„ãªæ¤œç´¢ã¨æœ€é©åŒ–æ‰‹é †ã‚’ç”¨ã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ãŒç›£è¦–ãªã—ã§æ€è€ƒã™ã‚‹æ–¹æ³•ã‚’å­¦ã¶ã€‚æŒ‡ç¤ºã«å¯¾ã™ã‚‹æ€è€ƒå€™è£œã¯ã‚¸ãƒ£ãƒƒã‚¸ãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡ã•ã‚Œã€æœ€é©åŒ–ã•ã‚Œã‚‹ã€‚ã“ã®æ‰‹æ³•ã¯AlpacaEvalã¨Arena-Hardã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€æ¨è«–ã‚¿ã‚¹ã‚¯ã ã‘ã§ãªãã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚„å¥åº·ãªã©ã®éæ¨è«–ã‚«ãƒ†ã‚´ãƒªã§ã‚‚åˆ©ç‚¹ã‚’ç™ºæ®ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tesatory/status/1919461701206081813?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¤–éƒ¨ã®CoTãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã‚ãªã„ã§ã€LLMã®reasoning capabilityã‚’å‘ä¸Šã•ã›ã‚‹è©±ã£ã½ã„ã€‚DeepSeek-R1ã®ç™»å ´ä»¥å‰ã®ç ”ç©¶ã¨ã®ã“ã¨ã€‚</p>
<p>reasoning traceã‚’å‡ºåŠ›ã™ã‚‹ã‚ˆã†ã«Instruction Tuningã«ã‚ˆã£ã¦å›ç­”ã‚’ç›´æ¥å‡ºåŠ›ã™ã‚‹ã‚ˆã†PostTrainingã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«promptingã—ã€è¤‡æ•°ã®outputã‚’åé›†ï¼ˆä»Šå›ã¯8å€‹, temperature=0.8, top p=0.95)ã€‚Self Taught Evaluator <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1464" target="_blank" rel="noopener noreferrer">Self-Taught Evaluators, Tianlu Wang+, N/A, arXiv'24</a>
 (STE;70B, LLM-as-a-Judgeã‚’åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼‰ã€ã‚ã‚‹ã„ã¯Armo Reward Modelï¼ˆ8Bï¼‰ã«ã‚ˆã£ã¦å›ç­”ã®å“è³ªã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã€‚ã“ã“ã§ã€LLM-as-a-Judgeã®å ´åˆã¯ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã§ã®å„ªåŠ£ãŒæ±ºã¾ã‚‹ã ã‘ãªã®ã§ã€ELOã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹ã€‚outputã®ã†ã¡best scoreã¨worst scoreã ã£ãŸã‚‚ã®ã®åŒæ–¹ã§ãƒšã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã—ã€DPOã§åˆ©ç”¨ã™ã‚‹preferenceãƒšã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã—DPOã™ã‚‹ã€‚ã“ã®ã‚ˆã†ãªå‡¦ç†ã‚’ç¹°ã‚Šè¿”ã—ã€ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’iterationã”ã¨ã«æ›´æ–°ã™ã‚‹ã€‚æ¬¡ã®iterationã§ã¯æ›´æ–°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§åŒæ§˜ã®å‡¦ç†ã‚’è¡Œã„ã€å‰æ®µã®ã‚¹ãƒ†ãƒƒãƒ—ã§åˆ©ç”¨ã—ãŸå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯åˆ©ç”¨ã—ãªã„ã‚ˆã†ã«ã™ã‚‹ï¼ˆå¾Œæ®µã®æ–¹ãŒå“è³ªãŒé«˜ã„ã¨æƒ³å®šã•ã‚Œã‚‹ãŸã‚ï¼‰ã€‚ã¾ãŸã€å›ç­”ã‚’åˆ¥ãƒ¢ãƒ‡ãƒ«ã§è©•ä¾¡ã™ã‚‹éš›ã«ã€é•·ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å¥½ã‚€ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€é•·ã„å†—é•·ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒé«˜ãã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã•ã‚Œã‚‹ã‚ˆã†ãªãƒã‚¤ã‚¢ã‚¹ãŒåƒãæ‡¸å¿µãŒã‚ã‚‹ãŸã‚ã€é•·ã™ãã‚‹å›ç­”ã«penaltyã‚’ä¸ãˆã¦ã„ã‚‹ï¼ˆLength-Control)ã€‚<br><img src="https://github.com/user-attachments/assets/3be7f7c3-1a24-44c5-bd73-a4b9e11b4b2c" alt="image" loading="lazy"><br><br>reasoning traceã‚’å‡ºåŠ›ã™ã‚‹promptã¯genericã¨specific thoughtã®äºŒç¨®é¡ã§æ¤œè¨¼ã€‚å‰è€…ã¯LLMã«ã©ã®ã‚ˆã†ãªæ€è€ƒã‚’ã™ã‚‹ã‹ã‚’ä¸¸æŠ•ã’ã™ã‚‹ã®ã«å¯¾ã—ã€å¾Œè€…ã¯ã“ã¡ã‚‰å´ã§æŒ‡å®šã™ã‚‹ã€‚å¾Œè€…ã®å ´åˆã¯ã€ã©ã®ã‚ˆã†ãªæ€è€ƒãŒè‰¯ã„ã‹ã‚’äº‹å‰ã«çŸ¥ã£ã¦ã„ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚<br><img src="https://github.com/user-attachments/assets/4548fd23-69ba-482f-8987-740f30658d83" alt="image" loading="lazy"><br><br>Llama-3-8b-instructã«é©ç”¨ã—ãŸã¨ã“ã‚ã€70Bã‚¹ã‚±ãƒ¼ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’é”æˆã€‚ã¾ãŸã€reasoning traceå‡ºåŠ›ã‚’ablationã—ãŸãƒ¢ãƒ‡ãƒ«ï¼ˆDirect responce baselineï¼‰ã‚ˆã‚Šã‚‚æ€§èƒ½ãŒå‘ä¸Šã€‚<br><img src="https://github.com/user-attachments/assets/06605741-7049-460a-8062-93be96d45975" alt="image" loading="lazy"><br><br>iterationãŒé€²ã‚€ã«é€£ã‚Œã¦ã€æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/25ced3ce-e341-41c4-b1e2-527885590e08" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1924" target="_blank" rel="noopener noreferrer" class="title-link">Layer by Layer: Uncovering Hidden Representations in Language Models, Oscar Skean+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- ä¸­é–“å±¤ã®åŸ‹ã‚è¾¼ã¿ãŒæœ€çµ‚å±¤ã‚’è¶…ãˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã“ã¨ã‚’åˆ†æã—ã€æƒ…å ±ç†è«–ã‚„å¹¾ä½•å­¦ã«åŸºã¥ããƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ææ¡ˆã€‚32ã®ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ã‚¿ã‚¹ã‚¯ã§ä¸­é–“å±¤ãŒå¼·åŠ›ãªç‰¹å¾´ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã—ã€AIã‚·ã‚¹ãƒ†ãƒ ã®æœ€é©åŒ–ã«ãŠã‘ã‚‹ä¸­é–“å±¤ã®é‡è¦æ€§ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç¾ä»£ã®ä»£è¡¨çš„ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆdecoder-only model, encoder-only model, SSMï¼‰ã«ã¤ã„ã¦ã€æœ€çµ‚å±¤ã®embeddingã‚ˆã‚Šã‚‚ä¸­é–“å±¤ã®embeddingã®æ–¹ãŒdownstream taskï¼ˆMTEBã®32Taskã®å¹³å‡ï¼‰ã«ã€ä¸€è²«ã—ã¦ï¼ˆãŸã ã—ã€ã“ã‚Œã¯MTEBã®å¹³å‡ã§è¦‹ãŸã‚‰ãã†ã¨ã„ã†è©±ã§ã‚ã‚Šã€å€‹åˆ¥ã®ã‚¿ã‚¹ã‚¯ã§ä¸€è²«ã—ã¦å¼·ã„ã‹ã¯èª­ã‚“ã§ã¿ãªã„ã¨ã‚ã‹ã‚‰ãªã„ï¼‰å¼·ã„ã“ã¨ã‚’ç¤ºã—ãŸç ”ç©¶ã€‚<br><br>ã“ã®ã“ã¨è‡ªä½“ã¯çµŒé¨“çš„ã«çŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ã®ã§ã‚ã¾ã‚Šé©šãã§ã¯ãªã„ã®ã ãŒï¼ˆãŸã ã€SSMã§ã‚‚ãã†ãªã®ã‹ã€ã¨ã„ã†ã®ã¨ã€ä¸€è²«ã—ã¦å¼·ã„ã¨ã„ã†ã®ã¯èˆˆå‘³æ·±ã„ï¼‰ã€ã“ã®ç ”ç©¶ã¯Matrix Based Entropyã¨å‘¼ã°ã‚Œã‚‹ã‚‚ã®ã«åŸºã¥ã„ã¦ã€ã“ã‚Œã‚‰ã‚’åˆ†æã™ã‚‹ãŸã‚ã®æ§˜ã€…ãªæŒ‡æ¨™ã‚’å®šç¾©ã—ç†è«–çš„ãªæ ¹æ‹ ã‚’ç¤ºã—ã€Autoregressiveãªå­¦ç¿’ã‚ˆã‚Šã‚‚Masked Languageã«ã‚ˆã‚‹å­¦ç¿’ã®æ–¹ãŒã“ã®ã‚ˆã†ãªMiddle Layerã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãŒç·©å’Œã•ã‚Œã€åŒæ§˜ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãŒç”»åƒã®å ´åˆã§ã‚‚èµ·ãã‚‹ã“ã¨ã‚’ç¤ºã—ã€CoTãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸFinetuningã«ã¤ã„ã¦ã‚‚åˆ†æã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ã“ã®è¾ºã®è²¢çŒ®ãŒéå¸¸ã«å¤§ãã„ã¨æ€ã‚ã‚Œã‚‹ã®ã§ã“ã“ã‚’ç†è§£ã™ã‚‹ã“ã¨ãŒé‡è¦ã ã¨æ€ã‚ã‚Œã‚‹ã€‚ã‚ã¨ã§èª­ã‚€ã€‚<br><br><img src="https://github.com/user-attachments/assets/bda00c50-c97b-45e0-97a5-d98dd98599fd" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Bias.html" target="_blank" rel="noopener noreferrer">#Bias</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/PerplexityCurse.html" target="_blank" rel="noopener noreferrer">#PerplexityCurse</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-05-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1922" target="_blank" rel="noopener noreferrer" class="title-link">Where is the answer? Investigating Positional Bias in Language Model   Knowledge Extraction, Kuniaki Saito+, NAACL'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMã¯æ–°ã—ã„æ–‡æ›¸ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ã ãŒã€ã€Œå›°æƒ‘ã®å‘ªã„ã€ã«ã‚ˆã‚Šæƒ…å ±æŠ½å‡ºãŒå›°é›£ã€‚ç‰¹ã«æ–‡æ›¸ã®åˆã‚ã«é–¢ã™ã‚‹è³ªå•ã«ã¯æ­£ç¢ºã«ç­”ãˆã‚‹ãŒã€ä¸­é–“ã‚„æœ«å°¾ã®æƒ…å ±æŠ½å‡ºã«è‹¦åŠ´ã™ã‚‹ã€‚è‡ªå·±å›å¸°çš„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã“ã®å•é¡Œã‚’å¼•ãèµ·ã“ã™ã“ã¨ã‚’ç¤ºã—ã€ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°è‡ªå·±å›å¸°æå¤±ãŒæƒ…å ±æŠ½å‡ºã‚’æ”¹å–„ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMã®çŸ¥è­˜æŠ½å‡ºã¨æ–°ãƒ‰ãƒ¡ã‚¤ãƒ³ã¸ã®é©å¿œã«é–¢ã™ã‚‹æ–°ãŸãªè­°è«–ãŒç”Ÿã¾ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/losnuevetoros/status/1918332232181207096?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>![Image](https://github.com/user-attachments/assets/dd6bdffa-4ce0-4389-826e-4c85113c755f)<br>LLMã®çŸ¥è­˜ã‚’æœ€æ–°ã«ã™ã‚‹ãŸã‚ã«æ–°ã—ã„æ–‡æ›¸ï¼ˆe.g., æ–°ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã®æ–‡æ›¸ç­‰ï¼‰ã‚’LLMã«ä¸ãˆï¼ˆä¾¿å®œä¸Šå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨å‘¼ã¶ï¼‰Finetuningã‚’ã—ãŸå ´åˆã€Finetuningå¾Œã®ãƒ¢ãƒ‡ãƒ«ã§ä¸ãˆã‚‰ã‚ŒãŸqueryã‹ã‚‰ï¼ˆLLMä¸­ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦memorizeã•ã‚Œã¦ã„ã‚‹ï¼‰å¯¾å¿œã™ã‚‹äº‹å®Ÿæƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ã‚ˆã†Inferenceã‚’å®Ÿæ–½ã™ã‚‹ã¨ã€queryã«å¯¾å¿œã™ã‚‹äº‹å®Ÿæƒ…å ±ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸­ã§ã®ä½ç½®ãŒæ·±ããªã‚‹ã¨ï¼ˆi.e., middle -- endã«ãªã‚‹ã¨ï¼‰æŠ½å‡ºãŒå›°é›£ã«ãªã‚‹ Positional BiasãŒå­˜åœ¨ã™ã‚‹[^1]ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚<br>ãã—ã¦ã€ã“ã‚Œã‚’ç·©å’Œã™ã‚‹ãŸã‚ã«æ­£å‰‡åŒ–ãŒé‡è¦ï¼ˆe.g., Denoising, Shuffle, Attention Dropsï¼‰ã§ã‚ã‚‹ã“ã¨ã‚’å®Ÿé¨“çš„ã«ç¤ºã—ã€æ­£å‰‡åŒ–æ‰‹æ³•ã¯è¤‡æ•°çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ã‚ˆã‚ŠPositional BiasãŒç·©å’Œã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸç ”ç©¶<br><br>[^1]: æœ¬ç ”ç©¶ã§ã¯"Training"ã«åˆ©ç”¨ã™ã‚‹æ–‡æ›¸ã®Positional Biasã«ã¤ã„ã¦ç¤ºã—ã¦ãŠã‚Šã€"Inference"æ™‚ã«ãŠã‘ã‚‹Positional Biasã¨ã—ã¦çŸ¥ã‚‰ã‚Œã¦ã„ã‚‹"lost-in-the middle"ã¨ã¯ç•°ãªã‚‹ç¾è±¡ã‚’æ‰±ã£ã¦ã„ã‚‹ç‚¹ã«æ³¨æ„</p>
<p>
<strong>## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>æ–‡æ›¸ + QAãƒ‡ãƒ¼ã‚¿ã®2ç¨®é¡ã‚’æ§‹ç¯‰ã—Finetuningå¾Œã®knowledge extractionèƒ½åŠ›ã®æ¤œè¨¼ã‚’ã—ã¦ã„ã‚‹[^2]ã€‚<br><br>å®Ÿé¨“ã§ã¯ã€`Synthetic Bio (åˆæˆãƒ‡ãƒ¼ã‚¿)`, `Wiki2023+ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ï¼‰` ã®2ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€Positional Biasã‚’æ¤œè¨¼ã—ã¦ã„ã‚‹ã€‚<br>Synthetic bioã¯ã€äººé–“ã®biographyã«é–¢ã™ã‚‹9ã¤ã®å±æ€§ï¼ˆe.g., èª•ç”Ÿæ—¥, å‡ºç”Ÿåœ°ï¼‰ã¨ã—ã¦ã¨ã‚Šã†ã‚‹å€¤ã‚’ChatGPTã«ç”Ÿæˆã•ã›ã€3000äººã®äººç‰©ã«å¯¾ã—ã¦ãã‚Œã‚‰ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«assignã—ã€sentence templateã‚’ç”¨ã„ã¦Surface Realizationã™ã‚‹ã“ã¨ã§äººå·¥çš„ã«3000äººã®biographyã«é–¢ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¦ã„ã‚‹ã€‚<br>ä¸€æ–¹ã€Wiki2023+ã§ã¯ã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1708" target="_blank" rel="noopener noreferrer">Instruction-tuned Language Models are Better Knowledge Learners, Zhengbao Jiang+, ACL'24</a>
</strong>
<br>
 ã®æ–¹æ³•ã«ã®ã£ã¨ã£ã¦ [^3]äº‹å‰å­¦ç¿’æ™‚ã®çŸ¥è­˜ã¨ã®overlapãŒæœ€å°ã¨ãªã‚‹ã‚ˆã†ã«`2023`ã‚«ãƒ†ã‚´ãƒªä»¥ä¸‹ã®wikipediaã®æ§˜ã€…ãªã‚¸ãƒ£ãƒ³ãƒ«ã®è¨˜äº‹ã‚’åé›†ã—ã¦æ´»ç”¨ã™ã‚‹ã€‚QAãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰ã«ã¯ã€å…ƒæ–‡æ›¸ã‹ã‚‰sentenceã‚’æŠ½å‡ºã—ã€GPT-3.5-Turboã«å½“è©²sentenceã®ã¿ã‚’ä¸ãˆã¦QA pairã‚’ä½œæˆã•ã›ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¦ã„ã‚‹ã€‚ãªãŠã€hallucinationã‚„å“è³ªã®ä½ã„QA pairã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸã€‚ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®QA Pairã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—å“è³ªã‚’ç¢ºèªã—ãŸã¨ã“ã‚ã€95%ã®QA pairãŒå¦¥å½“ãªã‚‚ã®ã§ã‚ã£ãŸã€‚<br><br>ã“ã‚Œã«ã‚ˆã‚Šã€ä¸‹å›³ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒä½œæˆã•ã‚Œã‚‹ã€‚FigureCãŒ `Wiki2023+`ã§ã€FigureDãŒ`SyntheticBio`ã€‚`Wiki2023+`ã§ã¯ã€QA pairã®æ­£è§£ãŒæ–‡æ›¸ä¸­ã®å‰åŠã«ã‚ˆã‚Šæ­£è§£ãŒç¾ã‚Œã‚‹ã‚ˆã†ãªåã‚ŠãŒè¦‹å—ã‘ã‚‰ã‚Œã‚‹ã€‚<br>![Image](https://github.com/user-attachments/assets/1146328f-de7e-4e90-b495-b129730c5d0d)<br><br>[^2]: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1923" target="_blank" rel="noopener noreferrer">Physics of Language Models: Part 3.1, Knowledge Storage and Extraction, Zeyuan Allen-Zhu+, ICML'24</a>
 ã«ãŠã„ã¦ã€çŸ¥è­˜ + çŸ¥è­˜ã‚’æŠ½å‡ºã™ã‚‹ã‚¿ã‚¹ã‚¯ã®åŒæ–¹ã‚’ç”¨ã„ã¦å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰çŸ¥è­˜ã‚’æŠ½å‡ºã™ã‚‹èƒ½åŠ›ãŒå‚™ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€‚<br>[^3]: Llama-2-7Bã«ãŠã„ã¦2023ã‚«ãƒ†ã‚´ãƒªä»¥ä¸‹ã®æƒ…å ±ã«å¯¾ã™ã‚‹QAã®performanceãŒè‘—ã—ãä½ã„ã“ã¨ã‹ã‚‰ã€äº‹å‰å­¦ç¿’æ™‚ã«å½“è©²ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒä½ã„ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¦ã„ã‚‹</p>
<p>
<strong>## å®Ÿé¨“ &amp; å®Ÿé¨“çµæœ (modulated data)<br>ä½œæˆã—ãŸæ–‡æ›¸+QAãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¤ã„ã¦ã€QAãƒ‡ãƒ¼ã‚¿ã‚’train/valid/testã«åˆ†ã‘ã¦ã€æ–‡æ›¸ãƒ‡ãƒ¼ã‚¿ã¯å…¨ã¦åˆ©ç”¨ã—ã€testã«å«ã¾ã‚Œã‚‹QAã«é©åˆ‡ã«å›ç­”ã§ãã‚‹ã‹ã§æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹ã€‚ã“ã®ã¨ãã€æ–‡æ›¸ä¸­ã§QAã«å¯¾ã™ã‚‹æ­£è§£ãŒãƒ†ã‚­ã‚¹ãƒˆãŒå‡ºç¾ã™ã‚‹ä½ç½®ã‚’å¤‰åŒ–ã•ã›ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’è¡Œã„ã€äºˆæ¸¬æ€§èƒ½ã‚’è¦‹ã‚‹ã“ã¨ã§ã€Positional BiasãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚ã“ã®ã¨ãã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1923" target="_blank" rel="noopener noreferrer">Physics of Language Models: Part 3.1, Knowledge Storage and Extraction, Zeyuan Allen-Zhu+, ICML'24</a>
</strong>
<br>
 ã«å€£ã„ã€æ–‡æ›¸ã¨QAã‚’Mixed Samplingï¼ˆ1ãƒãƒƒãƒã‚ãŸã‚Š256ä»¶ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«QAãŠã‚ˆã³æ–‡æ›¸ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°; 
<strong># 1923 ã§ã¯æ–‡æ›¸ã¨QAã‚’2:8ã®æ¯”ç‡ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ã„ã‚‹ï¼‰ã™ã‚‹ã“ã¨ã§å­¦ç¿’ã‚’ã™ã‚‹ã€‚QAã®å ´åˆç›®çš„é–¢æ•°ã¯å›ç­”ãƒ†ã‚­ã‚¹ãƒˆéƒ¨åˆ†ã®ã¿ã®NLLã€æ–‡æ›¸ã®å ´åˆã¯next-token prediction lossã‚’åˆ©ç”¨ã™ã‚‹ã€‚<br><br>Positional Biasã®å­˜åœ¨ã‚’ç¤ºã™ã ã‘ã§ãªãã€(A, B, C) ã®é †ç•ªã§next-token prediction lossã§å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€Cã®çŸ¥è­˜ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã«A, BãŒcontextã¨ã—ã¦å¿…è¦ã¨ãªã‚‹ãŸã‚ã€Cã‚’æŠ½å‡ºã™ã‚‹éš›ã®æ±åŒ–æ€§èƒ½ã‚’é«˜ã‚ã‚‹ãŸã‚ã«A, Bã®è¡¨ç¾ãŒã‚ˆã‚Šå¤šæ§˜ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ã€ã¨ã„ã†èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®ã„ãã¤ã‹ã®ã‚·ãƒ³ãƒ—ãƒ«ãªæ­£å‰‡åŒ–æ‰‹æ³•ã€å…·ä½“çš„ã«ã¯<br>- D-AR: predition targetã®ãƒˆãƒ¼ã‚¯ãƒ³ã¯ä¿æŒã—ãŸã¾ã¾ã€input tokenã®ä¸€éƒ¨ã‚’ãƒ©ãƒ³ãƒ€ãƒ ãªãƒˆãƒ¼ã‚¯ãƒ³ã«ç½®ãæ›ãˆã‚‹<br>- Shuffle: å…¥åŠ›æ–‡ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã™ã‚‹<br>- Attn Drop: self-attentionãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®attention weightã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«0ã«ã™ã‚‹<br>ã®3ç¨®é¡ã¨Positional Biasã®é–¢ä¿‚æ€§ã‚’æ¤œè¨¼ã—ã¦ã„ã‚‹ã€‚<br>![Image](https://github.com/user-attachments/assets/503e53f2-28f5-46ea-a11f-beee98f8fa38)<br><br>æ¤œè¨¼ã®çµæœã€ï¼ˆåˆæˆãƒ‡ãƒ¼ã‚¿ã€å®Ÿãƒ‡ãƒ¼ã‚¿ã¨ã‚‚ã«ï¼‰Positional BiasãŒå­˜åœ¨ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã¨ãªã‚Šï¼ˆi.e., æ­£è§£ãƒ†ã‚­ã‚¹ãƒˆãŒæ–‡æ›¸ä¸­ã®æ·±ã„ä½ç½®ã«ã‚ã‚Œã°ã‚ã‚‹ã»ã©äºˆæ¸¬æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ï¼‰æ­£å‰‡åŒ–ã«ã‚ˆã£ã¦Positional BiasãŒç·©å’Œã•ã‚Œã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚<br>![Image](https://github.com/user-attachments/assets/11a29a1e-f869-4628-9c47-e1fc9e5c394e)<br><br>ã¾ãŸã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§æ€§èƒ½ã‚’æ¯”è¼ƒã—ãŸã¨ã“ã‚ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’å¤§ããã™ã‚‹ã“ã¨ã§æ€§èƒ½è‡ªä½“ã¯æ”¹å–„ã™ã‚‹ãŒã€ä¾ç„¶ã¨ã—ã¦Positional BiasãŒå­˜åœ¨ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€ARã‚ˆã‚Šã‚‚D-ARãŒä¸€è²«ã—ã¦é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€Positional Biasã‚’ç·©å’Œã™ã‚‹ãŸã‚ã«ä½•ã‚‰ã‹ã®æ­£å‰‡åŒ–æ‰‹æ³•ãŒå¿…è¦ãªã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br>![Image](https://github.com/user-attachments/assets/0772d144-c22b-4723-8578-acdf0e2e1187)<br><br>ã¾ãŸã€ã‚ªãƒªã‚¸ãƒŠãƒ«æ–‡æ›¸ã®1æ–‡ç›®ã‚’ã€æ­£è§£ãƒ‡ãƒ¼ã‚¿ã®ä½ç½®ã‚’å…¥ã‚Œæ›¿ãˆãŸå„ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆä¸­ã®æ§˜ã€…ãªä½ç½®ã«é…ç½®ã—ã¦Perplexityã‚’æ¸¬ã£ãŸã€‚ã“ã®è¨­å®šã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒPerplexityã‚’æœ€å°åŒ–ã™ã‚‹ãŸã‚ã«ã¯ã€ï¼ˆ1æ–‡ç›®ã¨ã„ã†ã“ã¨ã¯ä»¥å‰ã®æ–‡è„ˆãŒå­˜åœ¨ã—ãªã„sentenceãªã®ã§ï¼‰æ–‡è„ˆã«ä¾å­˜ã›ãšã«æ–‡ã®è¨˜æ†¶ã—ã¦ã„ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚ã‚ˆã£ã¦ã€å„æ‰‹æ³•ã”ã¨ã«ã©ã®ç¨‹åº¦PerplexityãŒæ‚ªåŒ–ã™ã‚‹ã‹ã§ã€å„æ‰‹æ³•ãŒã©ã®ç¨‹åº¦ã‚ã‚‹sentenceã‚’è¨˜æ†¶ã™ã‚‹éš›ã«éå»ã®æ–‡è„ˆã«ä¾å­˜ã—ã¦ã„ã‚‹ã‹ãŒåˆ†ã‹ã‚‹ã€‚ã“ã“ã§ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãã®ã‚‚ã®ã®Perplexityã¯ã»ã¼1.0ã§ã‚ã£ãŸã“ã¨ã«æ³¨æ„ã™ã‚‹ã€‚<br>çµæœã¨ã—ã¦ã€æ–‡æ›¸ä¸­ã®æ·±ã„ä½ç½®ã«é…ç½®ã•ã‚Œã‚Œã°ã•ã‚Œã‚‹ã»ã©Perplexityã¯å¢—å¤§ã—ï¼ˆleftï¼‰ã€Autoregressive Model (AR) ã®Perplexityå€¤ãŒæœ€ã‚‚å€¤ãŒå¤§ãã‹ã£ãŸï¼ˆ=æ€§èƒ½ãŒæ‚ªã‹ã£ãŸï¼‰ã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€ARã¯ã‚ˆã‚Šéå»ã®æ–‡è„ˆã«ä¾å­˜ã—ã¦sentenceã®æƒ…å ±ã‚’è¨˜æ†¶ã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚ã¾ãŸã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã„ãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒPerplexityã¯å¢—å¤§ã™ã‚‹å‚¾å‘ã«ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸ (middle)ã€‚ã“ã‚Œã¯Fig.3ã§ç¤ºã—ãŸQAã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨å‚¾å‘ãŒä¸€è‡´ã—ã¦ãŠã‚Šã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãã®ã‚‚ã®ã®PerplexityãŒã»ã¼1.0ã ã£ãŸã“ã¨ã‚’é‘‘ã¿ã‚‹ã¨ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹Perplexityã¯æ§˜ã€…ãªPositionã«ä½ç½®ã™ã‚‹æƒ…å ±ã‚’é©åˆ‡ã«æŠ½å‡ºã§ãã‚‹èƒ½åŠ›ã‚’æ¸¬ã‚‹ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨ã—ã¦ã¯é©åˆ‡ã§ãªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚ã¾ãŸã€å­¦ç¿’ã®iterationã‚’å¢—ã‚„ã™ã¨ã€ARã®å ´åˆã¯first positionã«å¯¾ã™ã‚‹æŠ½å‡ºæ€§èƒ½ã¯æ”¹å–„ã—ãŸãŒã€ä»–ã®positionã§ã®æŠ½å‡ºæ€§èƒ½ã¯æ”¹å–„ã—ãªã‹ã£ãŸã€‚ä¸€æ–¹ã€D-ARã®å ´åˆã¯ã€å…¨ã¦ã®positionã§ã®æŠ½å‡ºæ€§èƒ½ãŒæ”¹å–„ã—ãŸ (right) ã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€å¿…ãšã—ã‚‚å­¦ç¿’ã®iterationã‚’å¢—ã‚„ã—ã¦ã‚‚æ§˜ã€…ãªPositionã«å¯¾ã™ã‚‹æŠ½å‡ºæ€§èƒ½ãŒæ”¹å–„ã—ãªã„ã“ã¨ã€longer trainingã®æ©æµã‚’å¾—ã‚‹ãŸã‚ã«ã¯æ­£å‰‡åŒ–æ‰‹æ³•ã‚’åˆ©ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚<br><br>![Image](https://github.com/user-attachments/assets/94f635a5-68d5-478d-ab16-513e855fe054)<br>&lt;/p&gt;<p>## å®Ÿé¨“ &amp; å®Ÿé¨“çµæœ (unmodulated data)<br>Wiki2023+ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ä¸Šè¨˜ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›´ã‚’è¡Œã‚ãšã«ã€ãã®ã¾ã¾å­¦ç¿’ã‚’è¡Œã„ã€å„ä½ç½®ã”ã¨ã®QAã®æ€§èƒ½ã‚’æ¸¬å®šã—ãŸã¨ã“ã‚ã€ï¼ˆã™ã¹ã¦ãŒPositional Biasã®ãŸã‚ã¨ã¯èª¬æ˜ã§ããªã„ãŒï¼‰å›ç­”ãŒæ–‡æ›¸ä¸­ã®æ·±ã„ä½ç½®ã«ã‚ã‚‹å ´åˆã®æ€§èƒ½ãŒåŠ£åŒ–ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ãŸã€‚2--6ç•ªç›®ã®æ€§èƒ½ã®ä½ä¸‹ã¯ã€æœ€åˆã®æ–‡ã§ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªäº‹å®ŸãŒè¿°ã¹ã‚‰ã‚Œã€å¾ŒåŠã«ãªã‚Œã°ãªã‚‹ã»ã©ã‚ˆã‚Šè¤‡é›‘ãªäº‹å®ŸãŒè¿°ã¹ã‚‰ã‚Œã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨ãŒèµ·å› ã—ã¦æ€§èƒ½ã®ä½ä¸‹ã—ã¦ã„ã‚‹ã¨ã‹ã›ã¤ã‚’ãŸã¦ã¦ã„ã‚‹ã€‚ã¾ãŸã€unmodulated dataã®å ´åˆã§ã‚‚D-ARã¯ARã®æ€§èƒ½ã‚’æ”¹å–„ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã¨ãªã£ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„ã»ã©æ€§èƒ½ã¯æ”¹å–„ã™ã‚‹ãŒã€ä»¥å‰ã¨ã—ã¦æ–‡æ›¸ä¸­ã®æ·±ã„ä½ç½®ã«æ­£è§£ãŒã‚ã‚‹å ´åˆã«æ€§èƒ½ã¯åŠ£åŒ–ã™ã‚‹ã“ã¨ã‚‚ã‚ã‹ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/2f43ba8a-c54e-4523-b8f0-7cfc797d5a7e" alt="image" loading="lazy"><br><br>ã¾ãŸã€æ­£å‰‡åŒ–æ‰‹æ³•ã¯çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã•ã‚‰ã«æ€§èƒ½ãŒæ”¹å–„ã—ã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1923" target="_blank" rel="noopener noreferrer">Physics of Language Models: Part 3.1, Knowledge Storage and Extraction, Zeyuan Allen-Zhu+, ICML'24</a>
&lt;/strong&gt;
<br>
 ã«ç¤ºã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸­ã®è¡¨ç¾ã‚’å¤šæ§˜ã«ã—[^1]å­¦ç¿’ã—ãŸã¨ã“ã‚äºˆæ¸¬æ€§èƒ½ãŒæ”¹å–„ã—ã€æ­£å‰‡åŒ–æ‰‹æ³•ã¨ã‚‚è£œå®Œçš„ãªé–¢ä¿‚ã§ã‚ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚<br><img src="https://github.com/user-attachments/assets/e79415b1-28e2-47ab-b429-448412053d0b" alt="image" loading="lazy"><br><br>åŒ»ç™‚ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã‚‚å®Ÿé¨“ã—ãŸã¨ã“ã‚ã€æ­£å‰‡åŒ–æ‰‹æ³•ã‚’é©ç”¨ã—ãŸå ´åˆã«ARã‚ˆã‚Šã‚‚æ€§èƒ½ãŒä¸Šå›ã£ãŸã€‚æœ€å¾Œã«Wiki2023+ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦Openbookãªè¨­å®šã§ã€æ­£è§£ãŒå«ã¾ã‚Œã‚‹æ–‡æ›¸ã‚’LLMã®contextã¨ã—ã¦ä¸ãˆãŸå ´åˆï¼ˆi.e.,ã»ã¼å®Œç’§ãªretrieverãŒå­˜åœ¨ã™ã‚‹RAGã¨åŒç­‰ã®è¨­å®šã¨ã¿ãªã›ã‚‹ï¼‰ã€QAã®æ€§èƒ½ã¯90.6%ã«å¯¾ã—ã€ç¶™ç¶šå­¦ç¿’ã—ãŸå ´åˆã®ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¯50.8%ã ã£ãŸã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€æ­£ç¢ºãªretrieverãŒå­˜åœ¨ã™ã‚‹ã®ã§ã‚ã‚Œã°ã€ç¶™ç¶šå­¦ç¿’ã‚ˆã‚Šã‚‚RAGã®æ–¹ãŒQAã®æ€§èƒ½ãŒé«˜ã„ã¨è¨€ãˆã‚‹ã€‚<br>RAGã¨ç¶™ç¶šå­¦ç¿’ã®ãƒ¡ãƒªãƒƒãƒˆã€ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã®ä¸¡æ–¹ã‚’è€ƒæ…®ã—ã¦ã€é©åˆ‡ã«æ‰‹æ³•ã‚’é¸æŠã™ã‚‹ã“ã¨ãŒæœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/14180452-5421-4102-8751-fabc8b780d49" alt="image" loading="lazy"><br><br>[^1]: ChatGPTã«ã‚ˆã£ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’rephraseã—ã€sentenceã®orderã‚‚å¤‰æ›´ã™ã‚‹ã“ã¨ã§å¤šæ§˜æ€§ã‚’å¢—ã‚„ã—ãŸã€‚ãŒã€sentence orderãŒæ–‡æ›¸ä¸­ã®æ·±ã„ä½ç½®ã«ã‚ã‚‹å ´åˆã«ã‚ã¾ã‚ŠorderãŒå¤‰åŒ–ã—ãªã‹ã£ãŸã‚ˆã†ã§ã€ã“ã®ãŸã‚æ·±ã„ä½ç½®ã«å¯¾ã™ã‚‹QAã®æ€§èƒ½æ”¹å–„ãŒé™å®šçš„ã«ãªã£ã¦ã„ã‚‹ã¨èª¬æ˜ã—ã¦ã„ã‚‹ã€‚</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1918" target="_blank" rel="noopener noreferrer" class="title-link">When More is Less: Understanding Chain-of-Thought Length in LLMs, Yuyang Wu+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- Chain-of-thought (CoT)æ¨è«–ã¯ã€LLMsã®å¤šæ®µéšæ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€CoTã®é•·ã•ãŒå¢—ã™ã¨æœ€åˆã¯æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã‚‚ã®ã®ã€æœ€çµ‚çš„ã«ã¯ä½ä¸‹ã™ã‚‹ã“ã¨ãŒè¦³å¯Ÿã•ã‚Œã‚‹ã€‚é•·ã„æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ãŒãƒã‚¤ã‚ºã«è„†å¼±ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ç†è«–çš„ã«æœ€é©ãªCoTã®é•·ã•ã‚’å°å‡ºã€‚Length-filtered Voteã‚’ææ¡ˆã—ã€CoTã®é•·ã•ã‚’ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã¨ã‚¿ã‚¹ã‚¯ã®è¦æ±‚ã«åˆã‚ã›ã¦èª¿æ•´ã™ã‚‹å¿…è¦æ€§ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>ICLR 2025 Best Paper Runner Up Award<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yifeiwang77/status/1916873981979660436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span></strong></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1917" target="_blank" rel="noopener noreferrer" class="title-link">AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models, Junfeng Fang+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- AlphaEditã¯ã€LLMsã®çŸ¥è­˜ã‚’ä¿æŒã—ã¤ã¤ç·¨é›†ã‚’è¡Œã†æ–°ã—ã„æ‰‹æ³•ã§ã€æ‘‚å‹•ã‚’ä¿æŒã•ã‚ŒãŸçŸ¥è­˜ã®é›¶ç©ºé–“ã«æŠ•å½±ã™ã‚‹ã“ã¨ã§ã€å…ƒã®çŸ¥è­˜ã‚’ç ´å£Šã™ã‚‹å•é¡Œã‚’è»½æ¸›ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€AlphaEditã¯å¾“æ¥ã®ä½ç½®ç‰¹å®š-ç·¨é›†æ‰‹æ³•ã®æ€§èƒ½ã‚’å¹³å‡36.7%å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1917343444810489925?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=HvSytvg3Jh" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=HvSytvg3Jh</a>


</p>
<p>MLPã«æ–°ãŸãªçŸ¥è­˜ã‚’ç›´æ¥æ³¨å…¥ã™ã‚‹éš›ã«ï¼ˆâ‰ contextã«å«ã‚ã‚‹ï¼‰æ—¢å­˜ã®å­¦ç¿’æ¸ˆã¿ã®çŸ¥è­˜ã‚’ç ´å£Šã›ãšã«æ³¨å…¥ã™ã‚‹æ‰‹æ³•ï¼ˆç ´å£Šã—ãªã„ã“ã¨ãŒä¿è¨¼ã•ã‚Œã¦ã„ã‚‹ï¼‰ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã‚‰ã—ã„</p>
<p>å°†æ¥çš„ã«ã¯ã€LLMã®1ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚ãŸã‚Šã«ä¿æŒã§ãã‚‹çŸ¥è­˜é‡ãŒã‚ã‹ã£ã¦ãã¦ã„ã‚‹ã®ã§ã€MLPã®é›¶ç©ºé–“ãŒN GBã®ãƒ¢ãƒ‡ãƒ«ã§ã™ã€ã‚ãªãŸãŒæ³¨å…¥ã—ãŸã„ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã®é‡ã«å¿œã˜ã¦é©åˆ‡ãªé›¶ç©ºé–“ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã‚“ã§ãã ã•ã„ã€ã¿ãŸã„ãªãƒ¢ãƒ‡ãƒ«ãŒå…¬é–‹ã•ã‚Œã‚‹æ—¥ãŒæ¥ã‚‹ã®ã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1916" target="_blank" rel="noopener noreferrer" class="title-link">Can LLMs Be Trusted for Evaluating RAG Systems? A Survey of Methods and  Datasets, Lorenz Brehme+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RAGã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡æ‰‹æ³•ã‚’63ä»¶ã®è«–æ–‡ã‚’åŸºã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã€ã‚¤ãƒ³ãƒ‡ã‚¯ã‚·ãƒ³ã‚°ã€ç”Ÿæˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®4é ˜åŸŸã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã€‚è‡ªå‹•è©•ä¾¡ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å®Ÿç¾å¯èƒ½æ€§ã‚’è¦³å¯Ÿã—ã€LLMã‚’æ´»ç”¨ã—ãŸè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç”Ÿæˆã‚’ææ¡ˆã€‚ä¼æ¥­å‘ã‘ã«å®Ÿè£…ã¨è©•ä¾¡ã®æŒ‡é‡ã‚’æä¾›ã™ã‚‹ãŸã‚ã®å®Ÿè·µçš„ç ”ç©¶ã®å¿…è¦æ€§ã‚’å¼·èª¿ã—ã€è©•ä¾¡æ‰‹æ³•ã®é€²å±•ã¨ä¿¡é ¼æ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1917425829233189027?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãŠã‚‚ã—ã‚ãã†</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1905" target="_blank" rel="noopener noreferrer" class="title-link">RNNs are not Transformers ï¼ˆYetï¼‰: The Key Bottleneck on In-context   Retrieval, Kaiyue Wen+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€RNNã¨ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®è¡¨ç¾åŠ›ã®é•ã„ã‚’èª¿æŸ»ã—ã€ç‰¹ã«RNNãŒChain-of-Thoughtï¼ˆCoTï¼‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”¨ã„ã¦ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã«åŒ¹æ•µã™ã‚‹ã‹ã‚’åˆ†æã€‚çµæœã€CoTã¯RNNã‚’æ”¹å–„ã™ã‚‹ãŒã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¨ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ã«ã¯ä¸ååˆ†ã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã€‚RNNã®æƒ…å ±å–å¾—èƒ½åŠ›ã®é™ç•ŒãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã§ã‚ã‚‹ãŒã€Retrieval-Augmented Generationï¼ˆRAGï¼‰ã‚„ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼å±¤ã®è¿½åŠ ã«ã‚ˆã‚Šã€RNNã¯CoTã‚’ç”¨ã„ã¦å¤šé …å¼æ™‚é–“ã§è§£æ±ºå¯èƒ½ãªå•é¡Œã‚’è§£æ±ºã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yuma_1_or/status/1915968478735130713?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1210" target="_blank" rel="noopener noreferrer">Transformers are Multi-State RNNs, Matanel Oren+, N/A, EMNLP'24</a>
<br><br>â†‘ã¨ã¯ã©ã†ã„ã†é–¢ä¿‚ãŒã‚ã‚‹ã ã‚ã†ã‹ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1904" target="_blank" rel="noopener noreferrer" class="title-link">Why Do Multi-Agent LLM Systems Fail?, Mert Cemri+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MASã®æ€§èƒ½å‘ä¸ŠãŒå˜ä¸€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨æ¯”è¼ƒã—ã¦é™å®šçš„ã§ã‚ã‚‹ã“ã¨ã‚’å—ã‘ã€MASTï¼ˆMulti-Agent System Failure Taxonomyï¼‰ã‚’ææ¡ˆã€‚200ä»¥ä¸Šã®ã‚¿ã‚¹ã‚¯ã‚’åˆ†æã—ã€14ã®å¤±æ•—ãƒ¢ãƒ¼ãƒ‰ã‚’ç‰¹å®šã—ã€3ã¤ã®å¤§ã‚«ãƒ†ã‚´ãƒªã«æ•´ç†ã€‚Cohenã®ã‚«ãƒƒãƒ‘ã‚¹ã‚³ã‚¢0.88ã‚’é”æˆã—ã€LLMã‚’ç”¨ã„ãŸè©•ä¾¡ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’é–‹ç™ºã€‚ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚’é€šã˜ã¦å¤±æ•—åˆ†æã¨MASé–‹ç™ºã®æ–¹æ³•ã‚’ç¤ºã—ã€ä»Šå¾Œã®ç ”ç©¶ã®ãŸã‚ã®ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’æç¤ºã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨LLMã‚¢ãƒãƒ†ãƒ¼ã‚¿ãƒ¼ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mertcemri/status/1915567789714329799?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>7ã¤ã®ãƒ¡ã‚¸ãƒ£ãƒ¼ãªãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«å¯¾ã—ã¦200ä»¥ä¸Šã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã—ã€6äººã®å°‚é–€å®¶ãŒtraceã‚’ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€‚14ç¨®é¡ã®å…¸å‹çš„ãªfailure modeã‚’è¦‹ã¤ã‘ã€ãã‚Œã‚‰ã‚’3ã¤ã«ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã€‚ã“ã‚Œã‚’è€ƒæ…®ã—ã¦ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®å¤±æ•—ã«é–¢ã™ã‚‹Taxonomyï¼ˆMASï¼‰ã‚’ææ¡ˆ<br><img src="https://github.com/user-attachments/assets/21d45bc7-cc6c-4561-b991-098f8d068627" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<span class="issue_date">Issue Date: 2025-04-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1898" target="_blank" rel="noopener noreferrer" class="title-link">BitNet b1.58 2B4T Technical Report, Shuming Ma+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- BitNet b1.58 2B4Tã¯ã€20å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®1ãƒ“ãƒƒãƒˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€4å…†ãƒˆãƒ¼ã‚¯ãƒ³ã§è¨“ç·´ã•ã‚Œã¾ã—ãŸã€‚è¨€èªç†è§£ã‚„æ•°å­¦çš„æ¨è«–ãªã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§è©•ä¾¡ã•ã‚Œã€åŒã‚µã‚¤ã‚ºã®ãƒ•ãƒ«ãƒ—ãƒ¬ã‚·ã‚¸ãƒ§ãƒ³LLMã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ã¤ã¤ã€è¨ˆç®—åŠ¹ç‡ãŒå‘ä¸Šã—ã¦ã„ã¾ã™ã€‚ãƒ¡ãƒ¢ãƒªã€ã‚¨ãƒãƒ«ã‚®ãƒ¼æ¶ˆè²»ã€ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒå‰Šæ¸›ã•ã‚Œã€ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã¯Hugging Faceã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1912783876365177235?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>åœ§å€’çš„çœãƒ¡ãƒ¢ãƒªã‹ã¤cpuã§ã®inferenceé€Ÿåº¦ã‚‚æ—©ãã†<br><img src="https://github.com/user-attachments/assets/dacf05e4-9cb3-48b4-9a98-532f7245eb8e" alt="image" loading="lazy"></p>
<p>- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯Transformerã‚’åˆ©ç”¨<br>- Linear layerã¨ã—ã¦BitLinear Layerã‚’åˆ©ç”¨<br>  - é‡ã¿ã¯{1, 0, -1}ã®3å€¤ã‚’ã¨ã‚‹<br>  - activationã¯8bitã®integerã«é‡å­åŒ–<br>  - Layer Normalizationã¯subln normalization <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1899" target="_blank" rel="noopener noreferrer">Foundation Transformers, Hongyu Wang+, PMLR'23</a>
 ã‚’åˆ©ç”¨</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<span class="issue_date">Issue Date: 2025-04-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1897" target="_blank" rel="noopener noreferrer" class="title-link">AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents, Christopher Rawles+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€116ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦å ±é…¬ä¿¡å·ã‚’æä¾›ã™ã‚‹ã€ŒAndroidWorldã€ã¨ã„ã†å®Œå…¨ãªAndroidç’°å¢ƒã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è‡ªç„¶è¨€èªã§è¡¨ç¾ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’å‹•çš„ã«æ§‹ç¯‰ã—ã€ç¾å®Ÿçš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿç¾ã€‚åˆæœŸçµæœã§ã¯ã€æœ€è‰¯ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒ30.6%ã®ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†ã—ã€ã•ã‚‰ãªã‚‹ç ”ç©¶ã®ä½™åœ°ãŒç¤ºã•ã‚ŒãŸã€‚ã¾ãŸã€ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—Webã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®Androidé©å¿œãŒåŠ¹æœè–„ã§ã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿç¾ã«ã¯ã•ã‚‰ãªã‚‹ç ”ç©¶ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚ŒãŸã€‚ã‚¿ã‚¹ã‚¯ã®å¤‰å‹•ãŒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚‚ç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Androidç’°å¢ƒã§ã®Phone Useã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-04-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1893" target="_blank" rel="noopener noreferrer" class="title-link">d1: Scaling Reasoning in Diffusion Large Language Models via  Reinforcement Learning, Siyan Zhao+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- d1ã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ãƒã‚¹ã‚¯ä»˜ãdLLMsã‚’æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å¼·åŒ–å­¦ç¿’ã§æ¨è«–ãƒ¢ãƒ‡ãƒ«ã«é©å¿œã€‚ãƒã‚¹ã‚¯ä»˜ãSFTæŠ€è¡“ã§çŸ¥è­˜ã‚’æŠ½å‡ºã—ã€diffu-GRPOã¨ã„ã†æ–°ã—ã„RLã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å°å…¥ã€‚å®Ÿè¨¼ç ”ç©¶ã«ã‚ˆã‚Šã€d1ãŒæœ€å…ˆç«¯ã®dLLMã®æ€§èƒ½ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1912785180504535121?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>dLLMã«å¯¾ã—ã¦GRPOã‚’é©ç”¨ã™ã‚‹æ‰‹æ³•(diffuGRPO)ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br>long CoTãƒ‡ãƒ¼ã‚¿ã§SFTã—ã¦reasoning capabilityã‚’å¼·åŒ–ã—ãŸå¾Œã€diffuGRPOã§è¿½åŠ ã®post-trainingã‚’ã—ã¦ã•ã‚‰ã«æ€§èƒ½ã‚’boostã™ã‚‹ã€‚</p>
<p>GRPOã§ã¯token levelã®å°¤åº¦ã¨sequenceå…¨ä½“ã®å°¤åº¦ã‚’è¨ˆç®—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŒã€dLLMã ã¨autoregressive modelã®ã‚ˆã†ã«chain ruleã‚’é©ç”¨ã™ã‚‹è¨ˆç®—æ–¹æ³•ã¯ã§ããªã„ã®ã§ã€åŠ¹ç‡çš„ã«å°¤åº¦ã‚’æ¨å®šã™ã‚‹estimatorã‚’ç”¨ã„ã¦GPPOã‚’é©ç”¨ã™ã‚‹diffuGRPOã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br>diffuGRPOå˜ä½“ã§ã‚‚ã€8Bãƒ¢ãƒ‡ãƒ«ã ãŒSFTã‚ˆã‚Šã‚‚æ€§èƒ½å‘ä¸Šã«æˆåŠŸã—ã¦ã„ã‚‹ã€‚SFTã®å¾Œã«diffuGRPOã‚’é©ç”¨ã™ã‚‹ã¨ã•ã‚‰ã«æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã€‚<br><br>SFTã§ã¯s1 <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1749" target="_blank" rel="noopener noreferrer">s1: Simple test-time scaling, Niklas Muennighoff+, arXiv'25</a>
 ã§ç”¨ã„ã‚‰ã‚ŒãŸlong CoTãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚ã—ã£ã‹ã‚Šç†è§£ã§ãã¦ã„ãªã„ãŒã€diffuGRPO+verified rewardã«ã‚ˆã£ã¦ã€long CoTã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãªãã¦ã‚‚ã€å®‰å®šã—ã¦reasoningèƒ½åŠ›ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒã§ãã‚ˆã†ã«ãªã£ãŸã€ã¨ã„ã†ã“ã¨ãªã®ã ã‚ã†ã‹ï¼Ÿ<br>ã—ã‹ã—ã€AppendixCã‚’è¦‹ã‚‹ã¨ã€å…ƒã€…ã®LLaDAã®æ™‚ç‚¹ã§reasoning traceã‚’ååˆ†ãªé•·ã•ã§å‡ºåŠ›ã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ã‚‚ã—LLaDAãŒå…ƒã€…long CoTã‚’ç™ºæ®ã§ããŸã®ã ã¨ã—ãŸã‚‰ã€long CoTã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã¯diffuGRPOã ã‘ã®æ©æµã§ã¯ãªã„ã¨ã„ã†ã“ã¨ã«ãªã‚Šãã†ã ãŒã€LLaDAã¯å…ƒã€…long CoTã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã ã£ãŸã‚“ã ã£ã‘â€¦ï¼Ÿãã®è¾ºè¿½ãˆã¦ãªã„ï¼ˆdLLMãŒãƒ¡ã‚¸ãƒ£ãƒ¼ã«ãªã£ãŸã‚‰è¿½ã†ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/Repetition.html" target="_blank" rel="noopener noreferrer">#Repetition</a>
<span class="issue_date">Issue Date: 2025-04-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1892" target="_blank" rel="noopener noreferrer" class="title-link">Learning Dynamics of LLM Finetuning, Yi Ren+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã®å­¦ç¿’ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’åˆ†æã—ã€ç•°ãªã‚‹å¿œç­”é–“ã®å½±éŸ¿ã®è“„ç©ã‚’æ®µéšçš„ã«è§£æ˜ã—ã¾ã™ã€‚æŒ‡ç¤ºèª¿æ•´ã¨å¥½ã¿èª¿æ•´ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«é–¢ã™ã‚‹è¦³å¯Ÿã‚’çµ±ä¸€çš„ã«è§£é‡ˆã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®å¹»è¦šå¼·åŒ–ã®ç†ç”±ã‚’ä»®èª¬çš„ã«èª¬æ˜ã—ã¾ã™ã€‚ã¾ãŸã€ã‚ªãƒ•ãƒãƒªã‚·ãƒ¼ç›´æ¥å¥½ã¿æœ€é©åŒ–ï¼ˆDPOï¼‰ã«ãŠã‘ã‚‹ã€Œåœ§ç¸®åŠ¹æœã€ã‚’å¼·èª¿ã—ã€æœ›ã¾ã—ã„å‡ºåŠ›ã®å¯èƒ½æ€§ãŒä½ä¸‹ã™ã‚‹ç¾è±¡ã‚’æ¢ã‚Šã¾ã™ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç†è§£ã«æ–°ãŸãªè¦–ç‚¹ã‚’æä¾›ã—ã€ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆæ€§èƒ½å‘ä¸Šã®ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ãªæ–¹æ³•ã‚’ç¤ºå”†ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/joshuarenyi/status/1913033476275925414?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1917189793588613299?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/In-Depth%20Notes.html" target="_blank" rel="noopener noreferrer">#In-Depth Notes</a>
<span class="issue_date">Issue Date: 2025-04-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1887" target="_blank" rel="noopener noreferrer" class="title-link">A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths   to Reproducibility, Andreas Hochlehnert+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¨è«–ã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã®é‡è¦ãªèª²é¡Œã§ã‚ã‚Šã€é€²å±•ãŒè¦‹ã‚‰ã‚Œã‚‹ãŒã€è©•ä¾¡æ‰‹æ³•ã«ã¯é€æ˜æ€§ã‚„å …ç‰¢æ€§ãŒæ¬ ã‘ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ•°å­¦çš„æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒå®Ÿè£…ã®é¸æŠã«æ•æ„Ÿã§ã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã€æ¨™æº–åŒ–ã•ã‚ŒãŸè©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚å†è©•ä¾¡ã®çµæœã€å¼·åŒ–å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯æ”¹å–„ãŒå°‘ãªãã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã¯å¼·ã„ä¸€èˆ¬åŒ–ã‚’ç¤ºã—ãŸã€‚å†ç¾æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã€é–¢é€£ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚„ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã—ã€ä»Šå¾Œã®ç ”ç©¶ã®åŸºç›¤ã‚’ç¯‰ãã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1911143014258405420?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>SLMã‚’math reasoningå‘ã‘ã«post-trainingã™ã‚‹å ´åˆã€è©•ä¾¡ã®æ¡ä»¶ã‚’ãƒ•ã‚§ã‚¢ã«ã™ã‚‹ãŸã‚ã®æ§˜ã€…ãªå·¥å¤«ã‚’æ–½ã—è©•ä¾¡ã‚’ã—ãªãŠã—ãŸçµæœï¼ˆFigure1ã®ã‚ˆã†ã«æ€§èƒ½ãŒå¤‰åŒ–ã™ã‚‹æ§˜ã€…ãªè¦å› ãŒå­˜åœ¨ã™ã‚‹ï¼‰ã€RLï¼ˆæ—¢å­˜ç ”ç©¶ã§è©¦ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ï¼‰ã‚ˆã‚Šã‚‚ï¼ˆå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰rejection samplingã—ãŸreasoning traceã‚’ç”¨ã„ã¦ï¼‰SFTã‚’ã™ã‚‹æ–¹ãŒåŒç­‰ã‹æ€§èƒ½ãŒè‰¯ã(Table3)ã€çµå±€ã®ã¨ã“ã‚ï¼ˆãŠãã‚‰ãæ±åŒ–æ€§èƒ½ãŒä½ã„ã¨ã„ã†æ„å‘³ã§ï¼‰reliableã§ã¯ãªãã€ã‹ã¤ï¼ˆãŠãã‚‰ãå°è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã§ã†ã¾ãã„ã‹ãªã„ã¨ã„ã†æ„å‘³ã§ã®ï¼‰scalableã§ã¯ãªã„ã®ã§ã€reliableã‹ã¤scalableãªRLæ‰‹æ³•ãŒä¸è¶³ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚<br><br>â€» æœ¬è«–æ–‡ã§åˆ†æã•ã‚Œã¦ã„ã‚‹ã®ã¯&lt;=10Bä»¥ä¸‹ã®SLMã§ã‚ã‚‹ç‚¹ã«æ³¨æ„ã€‚10Bä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã§åŒã˜ã“ã¨ãŒè¨€ãˆã‚‹ã‹ã¯è‡ªæ˜ã§ã¯ãªã„ã€‚<br>â€» DAPO, VAPOãªã©ã«ã¤ã„ã¦ã‚‚åŒã˜ã“ã¨ãŒè¨€ãˆã‚‹ã‹ã‚‚è‡ªæ˜ã§ã¯ãªã„ã€‚<br>â€» DeepSeek-R1ã®technical reportã«ãŠã„ã¦ã€å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã«GRPOã‚’é©ç”¨ã—ã¦ã‚‚ã‚ã¾ã‚ŠåŠ¹æœãŒç„¡ã‹ã£ãŸã“ã¨ãŒæ—¢ã«å ±å‘Šã•ã‚Œã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/620017f1-b3f0-40c1-bf61-3b0b7a429ab4" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/321132c8-dad5-4aa1-9811-f032e3474135" alt="image" loading="lazy"><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1743" target="_blank" rel="noopener noreferrer">DeepSeek-R1ã®è«–æ–‡èª­ã‚“ã ï¼Ÿã€å‹‰å¼·ã«ãªã‚‹ã‚ˆã€‘ , asap, 2025.01</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
</p>
<p>å€‹ã€…ã®post-trainingã•ã‚ŒãŸRLãƒ¢ãƒ‡ãƒ«ãŒå…·ä½“çš„ã«ã©ã†ã„ã†è¨“ç·´ã‚’ã—ãŸã®ã‹ã¯è¿½ãˆã¦ã„ãªã„ãŒã€DAPOã‚„Dr. GRPO, VAPOã®å ´åˆã¯ã©ã†ãªã‚‹ã‚“ã ã‚ã†ã‹ï¼Ÿ<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1815" target="_blank" rel="noopener noreferrer">DAPO: An Open-Source LLM Reinforcement Learning System at Scale, Qiying Yu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1876" target="_blank" rel="noopener noreferrer">VAPO: Efficient and Reliable Reinforcement Learning for Advanced
  Reasoning Tasks, YuYue+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1821" target="_blank" rel="noopener noreferrer">Understanding R1-Zero-Like Training: A Critical Perspective, 2025.03</a>
<br><br>Rewardã®è¨­å®šã®ä»•æ–¹ã¯ã©ã®ã‚ˆã†ãªå½±éŸ¿ãŒã‚ã‚‹ã®ã ã‚ã†ã‹ï¼ˆverifiable rewardãªã®ã‹ã€neuralãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹rewardãªã®ã‹ãªã©)ï¼Ÿ<br><br>å­¦ç¿’ã®ã•ã›æ–¹ã‚‚ã©ã®ã‚ˆã†ãªå½±éŸ¿ãŒã‚ã‚‹ã®ã ã‚ã†ã‹ï¼ˆRLã§ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ learningã«ã—ãŸå ´åˆãªã©ï¼‰ï¼Ÿ<br><br>æ¤œè¨¼ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒãã‚Œãã‚Œã©ã®ã‚ˆã†ãªè¨­å®šã§å­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ã‹ã¾ã§ã‚’è¦‹ãªã„ã¨ã“ã®è¾ºã¯ã‚ã‹ã‚‰ãªãã†ã€‚<br><br>ãŸã ãªã‚“ã¨ãªãƒ¼ãã®ç›´æ„Ÿã ã¨ã€SLMã‚’è³¢ãã—ãŸã„ã¨ã„ã†å ´åˆã¯ä½•ã‚‰ã‹ã®è³¢ã„ãƒ¢ãƒ‡ãƒ«ã®æ©æµã«é ã‹ã‚‹ã¨æœ‰åˆ©ãªã‚±ãƒ¼ã‚¹ãŒå¤šãï¼ˆSFTã®å ´åˆã¯ãã‚ŒãŒå¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰è’¸ç•™ã—ãŸreasoning traceï¼‰ã€SLM+RLã®å ´åˆã¯PRMã®ã‚ˆã†ãªæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’è©•ä¾¡ã—ã¦Rewardã«åæ˜ ã•ã›ã‚‹ã‚ˆã†ãªã‚‚ã®ã‚’åˆ©ç”¨ã—ãªã„ã¨ã€å°‘ãªãã¨ã‚‚å°è¦æ¨¡ãªLLMã‚’ã‚ã¡ã‚ƒè³¢ãã—ã¾ã™ã€œã¨ã„ã†ã®ã¯ãã¤ã„ã‚“ã˜ã‚ƒãªã„ã‹ãªã‚ã¨ã„ã†æ„Ÿæƒ³ã§ã¯ã‚ã‚‹ã€‚<br>ãŸã ã€çµå±€SLMã¨ã„ã†æ™‚ç‚¹ã§å¤šãã®å ´åˆã€ã‚ˆã‚Šè³¢ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å¤šã„LLMãŒä¸–ã®ä¸­ã«ã¯å­˜åœ¨ã™ã‚‹ã‚ã‚‹ã¯ãšãªã®ã§ã€RLã—ãªã„ã§SFTã—ã¦è’¸ç•™ã™ã‚Œã°è‰¯ã„ã‚“ã˜ã‚ƒãªã„â€¦ï¼Ÿã¨æ€ã£ã¦ã—ã¾ã†ã€‚<br>ãŒã€å¤šãã®å ´åˆãã®è³¢ã„LLMã¯ProprietaryãªLLMã§ã‚ã‚Šã€å‡ºåŠ›ã‚’å¾—ã¦è‡ªåˆ†ã®ãƒ¢ãƒ‡ãƒ«ã‚’post-trainingã™ã‚‹ã“ã¨ã¯åˆ©ç”¨è¦ç´„é•åã¨ãªã‚‹ãŸã‚ã€è‡ªå‰ã§è³¢ãã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å¤šã„LLMã‚’ç”¨æ„ã§ããªã„å ´åˆã¯å›°ã£ã¦ã—ã¾ã†ã®ã§ã€SLMã‚’ã‚¯ã‚½ãƒ‡ã‚«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã®æ©æµãªã—ã§è¶…çµ¶è³¢ãã§ããŸã‚‰ä¸–ã®ä¸­ã®å¤šãã®äººã¯å¬‰ã—ã„ã‚ˆã­ã€ã¨ã‚‚æ€ã†ã€‚</p>
<p>ï¼ˆæ–œã‚èª­ã¿ã ãŒï¼‰<br>ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„ï¼ˆæ•°åä»¶ï¼‰AIMEã‚„AMCãªã©ã®ãƒ‡ãƒ¼ã‚¿ã¯seedã®å€¤ã«ã¨ã¦ã‚‚sensitiveã§ã‚ã‚Š(Takeaway1, 2)ã€<br><br>&lt;img width="549" height="256" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/97581133-cf17-4635-b66c-442eaf8956d4"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/97581133-cf17-4635-b66c-442eaf8956d4"&lt;/a&gt;


/&gt;<br><br>ãã‚Œã‚‰ã¯10ç¨®é¡ã®seedã‚’ç”¨ã„ã¦çµæœã‚’å¹³å‡ã™ã‚‹ã¨åˆ†æ•£ãŒéå¸¸ã«å°ã•ããªã‚‹ã®ã§ã€seedã¯è¤‡æ•°ç¨®é¡åˆ©ç”¨ã—ã¦å¹³å‡ã®æ€§èƒ½ã‚’è¦‹ãŸæ–¹ãŒreliableã§ã‚ã‚Š(Takeaway3)<br><br>&lt;img width="688" height="266" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/5065ef0e-de89-4b17-aa52-c90b7191e9b2"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/5065ef0e-de89-4b17-aa52-c90b7191e9b2"&lt;/a&gt;


/&gt;<br><br>temperatureã‚’é«˜ãã™ã‚‹ã¨ãƒ”ãƒ¼ã‚¯æ€§èƒ½ãŒä¸ŠãŒã‚‹ãŒåˆ†æ•£ã‚‚ä¸ŠãŒã‚‹ãŸã‚å†ç¾æ€§ã®èª²é¡ŒãŒå¢—å¤§ã™ã‚‹ãŒã€top-pã‚’å¤§ããã™ã‚‹ã¨å†ç¾æ€§ã®å•é¡Œã¯ç¾ã‚Œãšæ€§èƒ½å‘ä¸Šã«å¯„ä¸ã—<br><br>&lt;img width="545" height="508" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/76d5c989-edbb-4d70-9080-d1d4b01de2ff"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/76d5c989-edbb-4d70-9080-d1d4b01de2ff"&lt;/a&gt;


/&gt;<br><br>æ—¢å­˜ç ”ç©¶ã®ãƒ¢ãƒ‡ãƒ«ã®temperatureã¨top-pã‚’å¤‰åŒ–ã•ã›å®Ÿé¨“ã™ã‚‹ã¨performanceã«éå¸¸ã«å¤§ããªå¤‰åŒ–ãŒå‡ºã‚‹ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«æœ€é©ãªå€¤ã‚’é¸å®šã—ã¦æ¯”è¼ƒã‚’ã—ãªã„ã¨unfairã§ã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ (Takeaway4)ã€‚<br><br>&lt;img width="553" height="511" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/d8b453d1-3d2e-4a80-b03d-c69ec1b2232e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/d8b453d1-3d2e-4a80-b03d-c69ec1b2232e"&lt;/a&gt;


/&gt;<br><br>ã¾ãŸã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®é¢ã§ã¯ã€vLLMã®ã‚ˆã†ãªinference engineã¯GPU typeã‚„memoryã®configurationã«å¯¾ã—ã¦sensitiveã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤‰ã‚ã‚‹ã ã‘ã§ãªãã€<br><br>&lt;img width="689" height="356" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/a41891c7-072c-4c38-9ad6-beada4721bac"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a41891c7-072c-4c38-9ad6-beada4721bac"&lt;/a&gt;


/&gt;<br><br>è©•ä¾¡ã«åˆ©ç”¨ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã”ã¨ã«inference engineã¨prompt templateãŒç•°ãªã‚‹ãŸã‚ã“ã¡ã‚‰ã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ãŒå‡ºã‚‹ã— (Takeaway5)ã€<br><br>&lt;img width="275" height="115" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/1f7d328c-0757-47b9-9961-630e2429fb3e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/1f7d328c-0757-47b9-9961-630e2429fb3e"&lt;/a&gt;


/&gt;<br><br>max output tokenã®å€¤ã‚’å¤‰åŒ–ã•ã›ã‚‹ã¨æ€§èƒ½ã‚‚å¤‰ã‚ã‚Šã€prompt templateã‚’åˆ©ç”¨ã—ãªã„ã¨æ€§èƒ½ãŒåŠ‡çš„ã«ä½ä¸‹ã™ã‚‹ (Takeaway6)ã€‚<br><br>&lt;img width="681" height="577" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/dc0902d1-a5f2-47de-8df1-c28107e1da28"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/dc0902d1-a5f2-47de-8df1-c28107e1da28"&lt;/a&gt;


/&gt;<br><br>ã“ã‚Œã‚‰ã®ã“ã¨ã‹ã‚‰è‘—è€…ã‚‰ã¯reliableãªè©•ä¾¡ã®ãŸã‚ã«ä¸‹è¨˜ã‚’ææ¡ˆã—ã¦ãŠã‚Š (4.1ç¯€; å¾Œã»ã©è¿½è¨˜)ã€<br><br>å®Ÿéš›ã«ã•ã¾ã–ã¾ãªæ¡ä»¶ã‚’fair comparisonã¨ãªã‚‹ã‚ˆã†ã«æ¨™æº–åŒ–ã—ã¦è©•ä¾¡ã—ãŸã¨ã“ã‚ï¼ˆ4.2ç¯€; å¾Œã»ã©è¿½è¨˜ï¼‰<br><br>ä¸Šã®è¡¨ã®ã‚ˆã†ãªçµæœã¨ãªã£ãŸã€‚ã“ã®çµæœã¯ã€<br>- DeepSeekR1-Distilledã‚’RLã—ã¦ã‚‚SFTã¨æ¯”è¼ƒã—ãŸã¨ãã«æ„å‘³ã®ã‚ã‚‹ã»ã©ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å‘ä¸Šã¯ãªã„ã“ã¨ã‹ã‚‰ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã€ã‹ã¤ä¿¡é ¼æ€§ã®ã‚ã‚‹RLæ‰‹æ³•ãŒã¾ã ä¸è¶³ã—ã¦ãŠã‚Š<br>- å¤§è¦æ¨¡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã®reasoning traceã‹ã‚‰SFTã‚’ã™ã‚‹æ–¹æ³•ã¯ã•ã¾ã–ã¾ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãƒ­ãƒã‚¹ãƒˆãªæ€§èƒ½ï¼ˆï¼é«˜ã„æ±åŒ–æ€§èƒ½ï¼‰ã‚’æŒã¡ã€RLã¨æ¯”ã¹ã‚‹ã¨ç¾çŠ¶ã¯RLã¨æ¯”è¼ƒã—ã¦ã‚ˆã‚Šãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã¨ã—ã¦æˆç†Ÿã—ã¦ãŠã‚Š<br>- ï¼ˆAIME24,25ã‚’æ¯”è¼ƒã™ã‚‹ã¨SFTã¨æ¯”ã¹ã¦RLã®å ´åˆperformanceã®ä½ä¸‹ãŒè‘—ã—ã„ã®ã§ï¼‰RLã¯overfittingã—ã‚„ã™ãã€OODãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒå¿…è¦</p>
<p>ã—ã£ã‹ã‚Šã¨è©•ä¾¡ã®æ çµ„ã¿ã‚’æ¨™æº–åŒ–ã—ã¦fair comparisonã—ã¦ã„ã‹ãªã„ã¨ã€RecSysæ¥­ç•Œã®äºŒã®èˆã«ãªã‚Šãã†ï¼ˆã¨ã„ã†ã‹ã‚‚ã†ãªã£ã¦ã‚‹ï¼Ÿï¼‰ã€‚<br><br>ã¾ãŸã“ã®ç ”ç©¶ã§åˆ†æã•ã‚Œã¦ã„ã‚‹ã®ã¯å°è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ï¼ˆ&lt;=10Bï¼‰ã«å¯¾ã™ã‚‹æ—¢å­˜ç ”ç©¶ã§ç”¨ã„ã‚‰ã‚ŒãŸä¸€éƒ¨ã®RLæ‰‹æ³•ã‚„è¨­å®šã®æ€§èƒ½ã ã‘ï¼ˆçœŸã«ç¤ºã—ãŸã‹ã£ãŸã‚‰Phisics of LLMã®ã‚ˆã†ãªå®Œå…¨ã«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«å¯èƒ½ãªã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã§å®Ÿé¨“ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã¨æ€ã‚ã‚Œã‚‹ï¼‰ãªã®ã§ã€DeepSeek-R1ã®ã‚ˆã†ã«ã€å¤§è¦æ¨¡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ•°ç™¾Bï¼‰ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹RLã«é–¢ã—ã¦åŒã˜ã“ã¨ãŒè¨€ãˆã‚‹ã‹ã¯è‡ªæ˜ã§ã¯ãªã„ç‚¹ã«æ³¨æ„ã€‚</p>
<p>openreview:


<a href="https://openreview.net/forum?id=90UrTTxp5O#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=90UrTTxp5O#discussion</a>


</p>
<p>æœ€è¿‘ã®ä»¥ä¸‹ã®ã‚ˆã†ãªSFTã¯RLã®ä¸€ã¤ã®ã‚±ãƒ¼ã‚¹ã¨è¦‹åšã›ã‚‹ã¨ã„ã†è­°è«–ã‚’è¸ã¾ãˆã‚‹ã¨ã©ã†ãªã‚‹ã ã‚ã†ã‹<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2700" target="_blank" rel="noopener noreferrer">[Paper Note] Towards a Unified View of Large Language Model Post-Training, Xingtai Lv+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2025-04-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1882" target="_blank" rel="noopener noreferrer" class="title-link">Hallucination Mitigation using Agentic AI Natural Language-Based  Frameworks, Diego Gosmar+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¤‡æ•°ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’èª¿æ•´ã—ã€è‡ªç„¶è¨€èªå‡¦ç†ã‚’æ´»ç”¨ã—ã¦å¹»è¦šã‚’è»½æ¸›ã™ã‚‹æ–¹æ³•ã‚’æ¢æ±‚ã€‚300ä»¥ä¸Šã®å¹»è¦šã‚’èª˜ç™ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”¨ã„ãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’è¨­è¨ˆã—ã€å‡ºåŠ›ã‚’ç¬¬äºŒãŠã‚ˆã³ç¬¬ä¸‰ãƒ¬ãƒ™ãƒ«ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‚æ–°ãŸã«è¨­è¨ˆã—ãŸKPIã§å¹»è¦šã‚¹ã‚³ã‚¢ã‚’è©•ä¾¡ã—ã€OVONãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é€šã˜ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã§æ–‡è„ˆæƒ…å ±ã‚’è»¢é€ã€‚çµæœã¨ã—ã¦ã€ç›¸äº’é‹ç”¨å¯èƒ½ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§å¹»è¦šã®è»½æ¸›ã«æˆåŠŸã—ã€AIã¸ã®ä¿¡é ¼ã‚’å¼·åŒ–ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lioronai/status/1910384805625135342?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<span class="issue_date">Issue Date: 2025-04-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1878" target="_blank" rel="noopener noreferrer" class="title-link">Using Attention Sinks to Identify and Evaluate Dormant Heads in  Pretrained LLMs, Pedro Sandoval-Segura+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹ã€Œä¼‘çœ ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ‰ã€ã‚’å®šç¾©ã—ã€ãã®å½±éŸ¿ã‚’èª¿æŸ»ã€‚6ã¤ã®ãƒ¢ãƒ‡ãƒ«ã¨5ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã€ä¼‘çœ ãƒ˜ãƒƒãƒ‰ã®å‡ºåŠ›ã‚’ã‚¼ãƒ­ã«ã—ã¦ã‚‚ç²¾åº¦ã‚’ç¶­æŒã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã€‚ä¼‘çœ ãƒ˜ãƒƒãƒ‰ã¯äº‹å‰å­¦ç¿’ã®åˆæœŸã«å‡ºç¾ã—ã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ç‰¹æ€§ã«ä¾å­˜ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/psandovalsegura/status/1909652533334712691?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1871" target="_blank" rel="noopener noreferrer" class="title-link">KAA: Kolmogorov-Arnold Attention for Enhancing Attentive Graph Neural  Networks, Taoran Fang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ³¨æ„GNNã«ãŠã‘ã‚‹ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã®ç†è§£ãŒä¸è¶³ã—ã¦ã„ã‚‹ä¸­ã€æœ¬ç ”ç©¶ã§ã¯ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ãƒ»ã‚¢ãƒ«ãƒãƒ«ãƒ‰æ³¨æ„ï¼ˆKAAï¼‰ã‚’ææ¡ˆã—ã€ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é–¢æ•°ã‚’çµ±ä¸€ã€‚KAAã¯KANã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’çµ±åˆã—ã€ã»ã¼ã™ã¹ã¦ã®æ³¨æ„GNNã«é©ç”¨å¯èƒ½ã§ã€è¡¨ç¾åŠ›ãŒå‘ä¸Šã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€KAAå¼·åŒ–ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é–¢æ•°ãŒå…ƒã®ã‚‚ã®ã‚’ä¸€è²«ã—ã¦ä¸Šå›ã‚Šã€æœ€å¤§20%ä»¥ä¸Šã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1908966571227398449?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1870" target="_blank" rel="noopener noreferrer" class="title-link">XAttention: Block Sparse Attention with Antidiagonal Scoring, Ruyi Xu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- XAttentionã¯ã€Long-Context Transformer Modelsã«ãŠã‘ã‚‹é•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ¨è«–ã‚’åŠ é€Ÿã™ã‚‹ãƒ—ãƒ©ã‚°ã‚¢ãƒ³ãƒ‰ãƒ—ãƒ¬ã‚¤ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€æ³¨æ„è¡Œåˆ—ã®åå¯¾å¯¾è§’ç·šã®å€¤ã‚’ç”¨ã„ã¦ãƒ–ãƒ­ãƒƒã‚¯ã®é‡è¦åº¦ã‚’è©•ä¾¡ã—ã€éæœ¬è³ªçš„ãªãƒ–ãƒ­ãƒƒã‚¯ã‚’å‰ªå®šã™ã‚‹ã“ã¨ã§é«˜ã„ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã‚’å®Ÿç¾ã€‚RULERã‚„LongBenchãªã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãƒ•ãƒ«ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã«åŒ¹æ•µã™ã‚‹ç²¾åº¦ã‚’ä¿ã¡ãªãŒã‚‰ã€æœ€å¤§13.5å€ã®è¨ˆç®—åŠ é€Ÿã‚’é”æˆã€‚XAttentionã¯LCTMsã®åŠ¹ç‡çš„ãªå±•é–‹ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1908966571227398449?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1869" target="_blank" rel="noopener noreferrer" class="title-link">Slim attention: cut your context memory in half without loss of accuracy  -- K-cache is all you need for MHA, Nils Graef+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Slim attentionã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã®MHAã«ãŠã„ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒ¢ãƒªã‚’2å€ã«ç¸®å°ã—ã€æ¨è«–é€Ÿåº¦ã‚’æœ€å¤§2å€å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã§ã€ç²¾åº¦ã‚’æãªã†ã“ã¨ãªãå®Ÿè£…å¯èƒ½ã§ã™ã€‚ç‰¹ã«ã€Whisperãƒ¢ãƒ‡ãƒ«ã§ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒ¢ãƒªã‚’8å€å‰Šæ¸›ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆã‚’5å€é€Ÿãã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã¾ãŸã€ç¨€ãªã‚±ãƒ¼ã‚¹ã§ã¯T5-11Bãƒ¢ãƒ‡ãƒ«ã§ãƒ¡ãƒ¢ãƒªã‚’32å€å‰Šæ¸›ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1908966571227398449?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<span class="issue_date">Issue Date: 2025-04-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1867" target="_blank" rel="noopener noreferrer" class="title-link">CREAM: Consistency Regularized Self-Rewarding Language Models, Zhaoyang Wang+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±å ±é…¬å‹LLMã¯ã€LLM-as-a-Judgeã‚’ç”¨ã„ã¦ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆæ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€å ±é…¬ã¨ãƒ©ãƒ³ã‚¯ä»˜ã‘ã®æ­£ç¢ºæ€§ãŒå•é¡Œã€‚å°è¦æ¨¡LLMã®å®Ÿè¨¼çµæœã¯ã€è‡ªå·±å ±é…¬ã®æ”¹å–„ãŒåå¾©å¾Œã«æ¸›å°‘ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ä¸€èˆ¬åŒ–ã•ã‚ŒãŸåå¾©çš„å¥½ã¿ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’å®šå¼åŒ–ã—ã€æ­£å‰‡åŒ–ã‚’å°å…¥ã€‚CREAMã‚’ææ¡ˆã—ã€å ±é…¬ã®ä¸€è²«æ€§ã‚’æ´»ç”¨ã—ã¦ä¿¡é ¼æ€§ã®é«˜ã„å¥½ã¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’ã€‚å®Ÿè¨¼çµæœã¯CREAMã®å„ªä½æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1212" target="_blank" rel="noopener noreferrer">Self-Rewarding Language Models, Weizhe Yuan+, N/A, ICML'24</a>
<br><br>ã‚’æ”¹å–„ã—ãŸç ”ç©¶</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=Vf6RDObyEF" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Vf6RDObyEF</a>


</p>
<p>ã“ã®æ–¹å‘æ€§ã®ç ”ç©¶ã¯ãŠã‚‚ã—ã‚ã„</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-04-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1866" target="_blank" rel="noopener noreferrer" class="title-link">Scalable-Softmax Is Superior for Attention, Ken M. Nakanishi, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- SSMaxã‚’ææ¡ˆã—ã€Softmaxã®ä»£æ›¿ã¨ã—ã¦Transformerãƒ¢ãƒ‡ãƒ«ã«çµ±åˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã®é‡è¦æƒ…å ±ã®å–å¾—ãŒå‘ä¸Šã—ã€äº‹å‰å­¦ç¿’ä¸­ã®æå¤±æ¸›å°‘ãŒé€Ÿããªã‚‹ã€‚SSMaxã¯æ³¨æ„ã‚¹ã‚³ã‚¢ã‚’æ”¹å–„ã—ã€é•·ã•ã®ä¸€èˆ¬åŒ–ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1863" target="_blank" rel="noopener noreferrer">Llama 4 Series, Meta, 2025.04</a>
<br><br>ã§æ¡ç”¨ã•ã‚Œã¦ã„ã‚‹æ‰‹æ³•ã§ã€ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆä¸­ã§å¼•ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚Long Contextã«ãªã£ãŸå ´åˆã«softmaxã®åˆ†å¸ƒãŒå‡ä¸€ã«ãªã‚‹ï¼ˆï¼é‡è¦ãªæƒ…å ±ã«attendã™ã‚‹èƒ½åŠ›ãŒå‰ŠãŒã‚Œã‚‹ï¼‰ã“ã¨ã‚’é˜²ããŸã‚ã®æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚</p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nrehiew_/status/1908613993998045534"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-04-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1862" target="_blank" rel="noopener noreferrer" class="title-link">When Attention Sink Emerges in Language Models: An Empirical View, Xiangming Gu+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹ã€Œã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã€ã¯ã€æ„å‘³çš„ã«é‡è¦ã§ãªã„ãƒˆãƒ¼ã‚¯ãƒ³ã«å¤§ããªæ³¨æ„ã‚’å‰²ã‚Šå½“ã¦ã‚‹ç¾è±¡ã§ã‚ã‚Šã€ã•ã¾ã–ã¾ãªå…¥åŠ›ã«å¯¾ã—ã¦å°ã•ãªãƒ¢ãƒ‡ãƒ«ã§ã‚‚æ™®éçš„ã«å­˜åœ¨ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã¯äº‹å‰å­¦ç¿’ä¸­ã«å‡ºç¾ã—ã€æœ€é©åŒ–ã‚„ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã€æå¤±é–¢æ•°ãŒãã®å‡ºç¾ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã€‚ç‰¹ã«ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã¯ã‚­ãƒ¼ã®ãƒã‚¤ã‚¢ã‚¹ã®ã‚ˆã†ã«æ©Ÿèƒ½ã—ã€æƒ…å ±ã‚’æŒãŸãªã„è¿½åŠ ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã‚’ä¿å­˜ã™ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã“ã®ç¾è±¡ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³ãŒã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹æ­£è¦åŒ–ã«ä¾å­˜ã—ã¦ã„ã‚‹ã“ã¨ã‹ã‚‰éƒ¨åˆ†çš„ã«ç”Ÿã˜ã¦ãŠã‚Šã€æ­£è¦åŒ–ãªã—ã®ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã«ç½®ãæ›ãˆã‚‹ã“ã¨ã§ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã®å‡ºç¾ã‚’é˜²ãã“ã¨ãŒã§ãã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Sink Rateã¨å‘¼ã°ã‚Œã‚‹ã€å…¨ã¦ã®headã®First Tokenã«å¯¾ã™ã‚‹attention scoreã®ã†ã¡ï¼ˆlayer l * head hå€‹å­˜åœ¨ã™ã‚‹ï¼‰ã€ã©ã®ç¨‹åº¦ã®å‰²åˆã®ã‚¹ã‚³ã‚¢ãŒé–¾å€¤ã‚’ä¸Šå›ã£ã¦ã„ã‚‹ã‹ã‚’è¡¨ã™æŒ‡æ¨™ã‚’ææ¡ˆ<br>ï¼ˆå¾Œã»ã©è©³ç´°ã‚’è¿½è¨˜ã™ã‚‹ï¼‰</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1860" target="_blank" rel="noopener noreferrer">Why do LLMs attend to the first token?, Federico Barbero+, COLM'25</a>
<br><br>ã®å…ˆè¡Œç ”ç©¶</p>
<p>è‘—è€…ãƒã‚¹ãƒˆï¼ˆopenai-gpt-120Bã‚’å—ã‘ã¦):<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gu_xiangming/status/1952811057673642227?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>openreview:


<a href="https://openreview.net/forum?id=78Nn4QJTEN" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=78Nn4QJTEN</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-04-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1860" target="_blank" rel="noopener noreferrer" class="title-link">Why do LLMs attend to the first token?, Federico Barbero+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯æœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³ã«å¼·ãæ³¨æ„ã‚’å‘ã‘ã‚‹ã€Œã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã€ã‚’ç¤ºã—ã€ãã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒéå‰°æ··åˆã‚’é¿ã‘ã‚‹æ–¹æ³•ã‚’ç†è«–çš„ãƒ»å®Ÿè¨¼çš„ã«æ¢æ±‚ã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•ã‚„ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ãƒƒã‚­ãƒ³ã‚°ãŒã‚·ãƒ³ã‚¯ã®æŒ™å‹•ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’å®Ÿé¨“ã§ç¤ºã—ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç†è§£ã‚’æ·±ã‚ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1908187563422261411?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Attention Sinkã«ã‚ˆã£ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³ã®æƒ…å ±ãŒover-mixingã•ã‚Œã‚‹ã“ã¨ãŒæŠ‘åˆ¶ã•ã‚Œã€Decoder-only LLMã®æ·±ã„å±¤ã®representationãŒå‡ä¸€åŒ–ã•ã‚Œã‚‹ã“ã¨ã‚’æŠ‘åˆ¶ã™ã‚‹ï¼ˆï¼promptã®æ‘‚å‹•ã«ãƒ­ãƒã‚¹ãƒˆã«ãªã‚‹ï¼‰ã“ã¨ãŒç¤ºã•ã‚ŒãŸæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/8a1223c0-5621-42a5-accc-31fa7f636856" alt="image" loading="lazy"><br>Gemma7Bã«ãŠã„ã¦ã€promptä¸­ã®ãƒˆãƒ¼ã‚¯ãƒ³ä¸€èªã‚’ç½®æ›ã—ãŸå¾Œã«ã€Attention Sinkï¼ˆ<bos>ï¼‰ã®æœ‰ç„¡ã«ã‚ˆã£ã¦ã€tokenãƒ¬ãƒ™ãƒ«ã®representationã«å¯¾ã—ã¦ã©ã®ã‚ˆã†ãªæ‘‚å‹•ãŒã‚ã‚‹ã‹ã‚’layerã”ã¨ã«ã¾ã¨ã‚ãŸå›³ãŒä¸‹è¨˜ã®æ¨¡æ§˜ã€‚Attention Sinkã«ã‚ˆã£ã¦ã€tokenã®æ‘‚å‹•ãŒä»–ã®token, layerã«å¯¾ã—ã¦mixingã•ã‚Œã‚‹ã®ãŒæŠ‘åˆ¶ã•ã‚Œã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/b1a4038a-d116-4bd1-b27b-c55eb861bee9" alt="image" loading="lazy">&lt;/p&gt;<p>openreview:


<a href="https://openreview.net/forum?id=tu4dFUsW5z#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=tu4dFUsW5z#discussion</a>


</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ConceptErasure.html" target="_blank" rel="noopener noreferrer">#ConceptErasure</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<a class="button" href="articles/AISTATS.html" target="_blank" rel="noopener noreferrer">#AISTATS</a>
<span class="issue_date">Issue Date: 2025-04-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1859" target="_blank" rel="noopener noreferrer" class="title-link">Fundamental Limits of Perfect Concept Erasure, Somnath Basu Roy Chowdhury+, AISTATS'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¦‚å¿µæ¶ˆå»ã¯ã€æ€§åˆ¥ã‚„äººç¨®ãªã©ã®æƒ…å ±ã‚’æ¶ˆå»ã—ã¤ã¤å…ƒã®è¡¨ç¾ã‚’ä¿æŒã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã‚ã‚Šã€å…¬å¹³æ€§ã®é”æˆã‚„ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®è§£é‡ˆã«å½¹ç«‹ã¤ã€‚å¾“æ¥ã®æŠ€è¡“ã¯æ¶ˆå»ã®å …ç‰¢æ€§ã‚’é‡è¦–ã—ã¦ããŸãŒã€æœ‰ç”¨æ€§ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒå­˜åœ¨ã™ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æƒ…å ±ç†è«–çš„è¦–ç‚¹ã‹ã‚‰æ¦‚å¿µæ¶ˆå»ã®é™ç•Œã‚’å®šé‡åŒ–ã—ã€å®Œç’§ãªæ¶ˆå»ã‚’é”æˆã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã¨æ¶ˆå»é–¢æ•°ã®åˆ¶ç´„ã‚’èª¿æŸ»ã€‚ææ¡ˆã™ã‚‹æ¶ˆå»é–¢æ•°ãŒç†è«–çš„é™ç•Œã‚’é”æˆã—ã€GPT-4ã‚’ç”¨ã„ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æ—¢å­˜æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/somnathbrc/status/1907463419105570933?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span></bos></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1858" target="_blank" rel="noopener noreferrer" class="title-link">What, How, Where, and How Well? A Survey on Test-Time Scaling in Large  Language Models, Qiyuan Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚¹ãƒˆæ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆTTSï¼‰ãŒå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å•é¡Œè§£æ±ºèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ãŒã€ä½“ç³»çš„ãªç†è§£ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€TTSç ”ç©¶ã®4ã¤ã®ã‚³ã‚¢æ¬¡å…ƒã«åŸºã¥ãçµ±ä¸€çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€æ‰‹æ³•ã‚„å¿œç”¨ã‚·ãƒŠãƒªã‚ªã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã†ã€‚TTSã®ç™ºå±•ã®è»Œè·¡ã‚’æŠ½å‡ºã—ã€å®Ÿè·µçš„ãªã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã™ã‚‹ã¨ã¨ã‚‚ã«ã€æœªè§£æ±ºã®èª²é¡Œã‚„å°†æ¥ã®æ–¹å‘æ€§ã«ã¤ã„ã¦ã®æ´å¯Ÿã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hesamation/status/1907095419793911893?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã¨ã¦ã¤ã‚‚ãªã„é‡ã â€¦ç¶²ç¾…æ€§ãŒã‚ã‚Šãã†ã€‚<br>What to ScaleãŒã‚ˆãã‚ã‚‹self<br>consistency(Parallel Scaling), STaR(Sequential Scailng), Tree of Thought(Hybrid Scaling), DeepSeek-R1, o1/3(Internal Scaling)ã¨ã„ã£ãŸåˆ†é¡ã§ã€How to ScaleãŒTuningã¨Inferenceã«åˆ†ã‹ã‚Œã¦ã„ã‚‹ã€‚Tuningã¯Long CoTã‚’SFTã™ã‚‹è©±ã‚„å¼·åŒ–å­¦ç¿’ç³»ã®è©±ï¼ˆGRPOãªã©ï¼‰ã§ã€Inferenceã«ã‚‚Self consistencyã‚„ã‚‰ã‚„ã‚‰Verificationã‚„ã‚‰è‰²ã€…ã‚ã‚Šãã†ã€‚è‰¯ã•ãã†ã€‚<br><img src="https://github.com/user-attachments/assets/9d76e438-ff75-454d-b549-7efda9baa300" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1855" target="_blank" rel="noopener noreferrer" class="title-link">Multi-Token Attention, Olga Golovneva+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒãƒˆãƒ¼ã‚¯ãƒ³ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ï¼ˆMTAï¼‰ã‚’ææ¡ˆã—ã€è¤‡æ•°ã®ã‚¯ã‚¨ãƒªã¨ã‚­ãƒ¼ã®ãƒ™ã‚¯ãƒˆãƒ«ã«åŸºã¥ã„ã¦ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¦ã‚§ã‚¤ãƒˆã‚’æ¡ä»¶ä»˜ã‘ã‚‹ã“ã¨ã§ã€é–¢é€£ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚ˆã‚Šæ­£ç¢ºã«ç‰¹å®šã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚MTAã¯ç•³ã¿è¾¼ã¿æ“ä½œã‚’ç”¨ã„ã¦ã€è¿‘ãã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒäº’ã„ã«å½±éŸ¿ã‚’ä¸ãˆã€è±Šã‹ãªæƒ…å ±ã‚’æ´»ç”¨ã™ã‚‹ã€‚è©•ä¾¡çµæœã‹ã‚‰ã€MTAã¯Transformerãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã€ç‰¹ã«é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã®æƒ…å ±æ¤œç´¢ã«ãŠã„ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1907260086017237207?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¾“æ¥ã®Multi Head Attentionã§ã¯ã€å˜ä½“ã®QKã®ã¿ã‚’åˆ©ç”¨ã—ã¦ã„ãŸã‘ã©ã€è¤‡æ•°ã®QKã®æƒ…å ±ã‚’ç•³ã¿è¾¼ã‚“ã§æ´»ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã€Headã‚‚ç•³ã¿è¾¼ã¿ã§é‡è¦ãªæƒ…å ±ãŒã‚ˆã‚Šä¼æ¬ã•ã‚Œã‚‹ã‚ˆã†ã«ã—ã¦ã€GroupNormalizationã‚’ã‹ã‘ãŸã‚‰Perplexityã®è¦³ç‚¹ã§Differential Transformerã‚’ä¸Šå›ã£ãŸã‚ˆã€ã¨ã„ã†è©±ãªæ¨¡æ§˜ã€‚<br><br><img src="https://github.com/user-attachments/assets/199e0794-a286-486d-9426-d86cfd208750" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/2997a61b-3367-4f43-b85a-ac8fa160391a" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/5ef8ddb0-538b-46e2-94b8-2ef495c938ec" alt="image" loading="lazy"><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1856" target="_blank" rel="noopener noreferrer">Group Normalization, Yuxin Wu+, arXiv'18</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1466" target="_blank" rel="noopener noreferrer">Differential Transformer, Tianzhu Ye+, N/A, ICLR'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/QuestionGeneration.html" target="_blank" rel="noopener noreferrer">#QuestionGeneration</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1853" target="_blank" rel="noopener noreferrer" class="title-link">Interactive Agents to Overcome Ambiguity in Software Engineering, Sanidhya Vijayvargiya+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã‚ã„ã¾ã„ãªæŒ‡ç¤ºã«åŸºã¥ãã‚¿ã‚¹ã‚¯è‡ªå‹•åŒ–ã«åˆ©ç”¨ã•ã‚Œã‚‹ãŒã€èª¤ã£ãŸä»®å®šã‚„è³ªå•ä¸è¶³ãŒãƒªã‚¹ã‚¯ã‚’ç”Ÿã‚€ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚ã„ã¾ã„ãªæŒ‡ç¤ºå‡¦ç†èƒ½åŠ›ã‚’è©•ä¾¡ã—ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã‚’æ´»ç”¨ã—ãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã€ã‚ã„ã¾ã„ã•ã®æ¤œå‡ºã€ç›®æ¨™ã‚’çµã£ãŸè³ªå•ã®å®Ÿæ–½ã‚’æ¤œè¨ã€‚çµæœã€ãƒ¢ãƒ‡ãƒ«ã¯æ˜ç¢ºãªæŒ‡ç¤ºã¨ä¸ååˆ†ãªæŒ‡ç¤ºã‚’åŒºåˆ¥ã™ã‚‹ã®ãŒé›£ã—ã„ãŒã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’é€šã˜ã¦é‡è¦ãªæƒ…å ±ã‚’å–å¾—ã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã®é™ç•Œã¨æ”¹å–„ã®ãŸã‚ã®è©•ä¾¡æ‰‹æ³•ã®é‡è¦æ€§ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>æ›–æ˜§ãªãƒ¦ãƒ¼ã‚¶ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã™ã‚‹ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒ"è³ªå•ã‚’ã™ã‚‹èƒ½åŠ›ã‚’æ¸¬ã‚‹"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br><br>&lt;img width="422" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/3d201ebf-9ca1-4333-9d27-e33a9028066f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/3d201ebf-9ca1-4333-9d27-e33a9028066f"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1847" target="_blank" rel="noopener noreferrer" class="title-link">Demystifying LLM-based Software Engineering Agents, Chunqiu Steven Xia+, FSE'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®LLMã®é€²å±•ã«ã‚ˆã‚Šã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã‚¿ã‚¹ã‚¯ã®è‡ªå‹•åŒ–ãŒé€²ã‚“ã§ã„ã‚‹ãŒã€è¤‡é›‘ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å¿…è¦æ€§ã«ç–‘å•ãŒç”Ÿã˜ã¦ã„ã‚‹ã€‚ã“ã‚Œã«å¯¾ã—ã€Agentlessã¨ã„ã†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€ã‚·ãƒ³ãƒ—ãƒ«ãªä¸‰æ®µéšãƒ—ãƒ­ã‚»ã‚¹ã§å•é¡Œã‚’è§£æ±ºã€‚SWE-bench Liteãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€é«˜ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ä½ã‚³ã‚¹ãƒˆã‚’é”æˆã€‚ç ”ç©¶ã¯è‡ªå¾‹å‹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã«ãŠã‘ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ã§è§£é‡ˆå¯èƒ½ãªæŠ€è¡“ã®å¯èƒ½æ€§ã‚’ç¤ºã—ã€ä»Šå¾Œã®ç ”ç©¶ã®æ–¹å‘æ€§ã‚’åˆºæ¿€ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://note.com/ainest/n/nac1c795e3825" target="_blank" rel="noopener noreferrer">https://note.com/ainest/n/nac1c795e3825</a>


</p>
<p>LLMã«ã‚ˆã‚‹è¨ˆç”»ã®ç«‹æ¡ˆã€ç’°å¢ƒã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ã‚ˆã‚‹æ„æ€æ±ºå®šãªã©ã®è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ã¯ãªãã€Localizationï¼ˆéšå±¤çš„ã«å•é¡Œã®ã‚ã‚‹ç®‡æ‰€ã‚’åŒå®šã™ã‚‹ï¼‰ã¨Repairï¼ˆLLMã§è¤‡æ•°ã®ãƒ‘ãƒƒãƒå€™è£œã‚’ç”Ÿæˆã™ã‚‹ï¼‰ã€PatchValidation(å†ç¾ãƒ†ã‚¹ãƒˆã¨å›å¸°ãƒ†ã‚¹ãƒˆã®ä¸¡æ–¹ã‚’é€šã˜ã¦çµæœãŒè‰¯ã‹ã£ãŸãƒ‘ãƒƒãƒã‚’é¸ã¶ï¼‰ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’é€šã˜ã¦Issueã‚’è§£æ±ºã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/6d042dfe-9780-4410-9077-b265af5456d1" alt="image" loading="lazy"><br><br>ã“ã‚Œã«ã‚ˆã‚Šã€ä½ã‚³ã‚¹ãƒˆã§é«˜ã„æ€§èƒ½ã‚’é”æˆã—ã¦ã„ã‚‹ã€ã¨ã„ã£ãŸå†…å®¹ãªæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/3934126f-3a4d-406c-8860-c3ed35a351c4" alt="image" loading="lazy"></p>
<p>Agentlessã¨å‘¼ã°ã‚Œæ‰‹æ³•ã ãŒã€preprintç‰ˆã«ã‚ã£ãŸã‚¿ã‚¤ãƒˆãƒ«ã®æ¥é ­è¾ã ã£ãŸåŒå‘¼ç§°ãŒproceedingç‰ˆã§ã¯ç„¡ããªã£ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/FactualKnowledge.html" target="_blank" rel="noopener noreferrer">#FactualKnowledge</a>
<span class="issue_date">Issue Date: 2025-04-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1846" target="_blank" rel="noopener noreferrer" class="title-link">Inside-Out: Hidden Factual Knowledge in LLMs, Zorik Gekhman+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã¯ã€LLMãŒå‡ºåŠ›ä»¥ä¸Šã®äº‹å®Ÿçš„çŸ¥è­˜ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚çŸ¥è­˜ã‚’å®šç¾©ã—ã€æ­£ã—ã„å›ç­”ãŒé«˜ããƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚Œã‚‹å‰²åˆã‚’å®šé‡åŒ–ã€‚å¤–éƒ¨çŸ¥è­˜ã¨å†…éƒ¨çŸ¥è­˜ã‚’åŒºåˆ¥ã—ã€å†…éƒ¨çŸ¥è­˜ãŒå¤–éƒ¨çŸ¥è­˜ã‚’è¶…ãˆã‚‹ã¨éš ã‚ŒãŸçŸ¥è­˜ãŒç”Ÿã˜ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ–ãƒƒã‚¯QAè¨­å®šã§ã®ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã§ã¯ã€LLMãŒå†…éƒ¨ã§å¤šãã®çŸ¥è­˜ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã„ã‚‹ã“ã¨ã€çŸ¥è­˜ãŒéš ã‚Œã¦ã„ã‚‹å ´åˆãŒã‚ã‚‹ã“ã¨ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹åˆ¶ç´„ãŒã‚ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zorikgekhman/status/1906693729886363861?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Video.html" target="_blank" rel="noopener noreferrer">#Video</a>
<span class="issue_date">Issue Date: 2025-03-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1843" target="_blank" rel="noopener noreferrer" class="title-link">Qwen2.5-Omni Technical Report, Jin Xu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€ŒQwen2.5-Omniã€ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€éŸ³å£°ã€å‹•ç”»ã‚’èªè­˜ã—ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ–¹å¼ã§è‡ªç„¶ãªéŸ³å£°å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ã€‚éŸ³å£°ã¨è¦–è¦šã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ãƒ–ãƒ­ãƒƒã‚¯å‡¦ç†ã‚’ç”¨ã„ã€TMRoPEã«ã‚ˆã‚‹æ–°ã—ã„ä½ç½®åŸ‹ã‚è¾¼ã¿ã§éŸ³å£°ã¨å‹•ç”»ã®åŒæœŸã‚’å®Ÿç¾ã€‚Thinker-Talkerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã¨éŸ³å£°å‡ºåŠ›ã‚’å¹²æ¸‰ãªãè¡Œã†ã€‚Qwen2.5-Omniã¯ã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã§è¨“ç·´ã•ã‚Œã€éŸ³å£°æŒ‡ç¤ºã«å¯¾ã™ã‚‹æ€§èƒ½ãŒãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã¨åŒç­‰ã§ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°Talkerã¯æ—¢å­˜æ‰‹æ³•ã‚’ä¸Šå›ã‚‹è‡ªç„¶ã•ã‚’æŒã¤ã€‚</span>
<span class="snippet"><span>Comment</span><p>Qwen Teamã«ã‚ˆã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMã€‚ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€å‹•ç”»éŸ³å£°ã‚’inputã¨ã—ã¦å—ã‘å–ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆã€éŸ³å£°ã‚’outputã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/03e54fd7-2011-4069-aa1b-38d1610169ec" alt="image" loading="lazy"><br><br>weight:


<a href="https://huggingface.co/collections/Qwen/qwen25-omni-67de1e5f0f9464dc6314b36e" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/Qwen/qwen25-omni-67de1e5f0f9464dc6314b36e</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/niels-rogge-a3b7a3127_alibabas-qwen-team-has-done-it-again-this-activity-7311036679627132929-HUqy?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/niels-rogge-a3b7a3127_alibabas-qwen-team-has-done-it-again-this-activity-7311036679627132929-HUqy?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4</a>


</p></span><br><br>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-03-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1842" target="_blank" rel="noopener noreferrer" class="title-link">Measuring AI Ability to Complete Long Tasks, Thomas Kwa+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„æŒ‡æ¨™ã€Œ50%-ã‚¿ã‚¹ã‚¯å®Œäº†æ™‚é–“ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ã€ã‚’ææ¡ˆã—ã€AIãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’äººé–“ã®è¦³ç‚¹ã‹ã‚‰å®šé‡åŒ–ã€‚Claude 3.7 Sonnetã¯ç´„50åˆ†ã®æ™‚é–“ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ã‚’æŒã¡ã€AIã®èƒ½åŠ›ã¯2019å¹´ä»¥é™ç´„7ã‹æœˆã”ã¨ã«å€å¢—ã€‚ä¿¡é ¼æ€§ã‚„è«–ç†çš„æ¨è«–ã®å‘ä¸ŠãŒè¦å› ã¨ã•ã‚Œã€5å¹´ä»¥å†…ã«AIãŒå¤šãã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¿ã‚¹ã‚¯ã‚’è‡ªå‹•åŒ–ã§ãã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1902854727089656016?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¢ºã‹ã«ç·šå½¢ã«è¦‹ãˆã‚‹ã€‚ã¦ã‹GPT-2ã¨æ¯”ã¹ã‚‹ã¨AIã•ã‚“é€²åŒ–ã—ã™ãã§ã‚ã‚‹â€¦ã€‚<br><img src="https://github.com/user-attachments/assets/266a36aa-a169-492b-b8af-60c0cb152111" alt="image" loading="lazy"></p>
<p>åˆ©ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯<br>- HCAST: 46ã®ã‚¿ã‚¹ã‚¯ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã«åŸºã¥ã97ç¨®é¡ã®ã‚¿ã‚¹ã‚¯ãŒå®šç¾©ã•ã‚Œã¦ãŠã‚Šã€ãŸã¨ãˆã°ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€æ©Ÿæ¢°å­¦ç¿’ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€ä¸€èˆ¬çš„ãªæ¨è«–ã‚¿ã‚¹ã‚¯ï¼ˆwikipediaã‹ã‚‰äº‹å®Ÿæƒ…å ±ã‚’æ¢ã™ã‚¿ã‚¹ã‚¯ãªã©ï¼‰ãªã©ãŒã‚ã‚‹<br>  - æ•°åˆ†ã§çµ‚ã‚ã‚‹ã‚¿ã‚¹ã‚¯: ä¸Šè¿°ã®wikipedia<br>  - æ•°æ™‚é–“ã§çµ‚ã‚ã‚‹ã‚¿ã‚¹ã‚¯: Pytorchã®ã¡ã‚‡ã£ã¨ã—ãŸãƒã‚°ä¿®æ­£ãªã©<br>  - æ•°æ–‡ã§ã‚¿ã‚¹ã‚¯ãŒè¨˜è¿°ã•ã‚Œã€ã‚³ãƒ¼ãƒ‰ã€ãƒ‡ãƒ¼ã‚¿ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€ã‚ã‚‹ã„ã¯webã‹ã‚‰å…¥æ‰‹å¯èƒ½ãªæƒ…å ±ã‚’å‚ç…§å¯èƒ½<br>ã€€- ã‚¿ã‚¹ã‚¯ã®é›£æ˜“åº¦ã¨ã—ã¦ã¯å½“è©²ãƒ‰ãƒ¡ã‚¤ãƒ³ã«æ•°å¹´é–“æºã‚ã£ãŸå°‚é–€å®¶ãŒè§£ã‘ã‚‹å•é¡Œ<br>- RE-Bench Suite<br>  - 7ã¤ã®open endedãªå°‚é–€å®¶ãŒ8æ™‚é–“ç¨‹åº¦ã‚’è¦ã™ã‚‹MLã«é–¢ã™ã‚‹ã‚¿ã‚¹ã‚¯<br>ã€€- e.g., GPT-2ã‚’QAç”¨ã«Finetuningã™ã‚‹, Finetuningã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«æŒ™å‹•ã‚’å¤‰åŒ–ã•ã›ãšã«ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’å¯èƒ½ãªé™ã‚ŠçŸ­ç¸®ã™ã‚‹ã€ãªã©<br>ã€€- [RE-Bench Technical Report](


<a href="https://metr.org/AI_R_D_Evaluation_Report.pdf)%E3%81%AETable2%E7%AD%89%E3%82%92%E5%8F%82%E7%85%A7%E3%81%AE%E3%81%93%E3%81%A8" target="_blank" rel="noopener noreferrer">https://metr.org/AI_R_D_Evaluation_Report.pdf)ã®Table2ç­‰ã‚’å‚ç…§ã®ã“ã¨</a>


<br>- SWAA Suite: 66ç¨®é¡ã®1ã¤ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«ã‚ˆã£ã¦1åˆ†ä»¥å†…ã§çµ‚ã‚ã‚‹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã§å…¸å‹çš„ãªã‚¿ã‚¹ã‚¯<br>  - 1åˆ†ä»¥å†…ã§çµ‚ã‚ã‚‹ã‚¿ã‚¹ã‚¯ãŒä¸Šè¨˜ãƒ‡ãƒ¼ã‚¿ã«ãªã‹ã£ãŸã®ã§è‘—è€…ã‚‰ãŒä½œæˆ<br><br>ã§ã‚ã‚Šã€ç”»åƒç³»ã‚„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªã‚¿ã‚¹ã‚¯ã¯å«ã¾ã‚Œã¦ã„ãªã„ã€‚<br><img src="https://github.com/user-attachments/assets/0b3892c9-3c83-4f78-a490-c28fa7470e0e" alt="image" loading="lazy"><br><br>ã‚¿ã‚¹ã‚¯ã¨äººé–“ãŒã‚¿ã‚¹ã‚¯ã«è¦ã™ã‚‹æ™‚é–“ã®å¯¾å¿œã«é–¢ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã¯ä¸‹è¨˜<br><img src="https://github.com/user-attachments/assets/5ed472da-e8c9-41be-8fd1-ef6f21713c14" alt="image" loading="lazy"></p>
<p>ã‚¿ã‚¹ã‚¯-ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒšã‚¢ã”ã¨ã«8å›å®Ÿè¡Œã—ãŸå ´åˆã®å¹³å‡ã®æˆåŠŸç‡ã€‚ç¢ºã‹ã«ã“ã®ã‚°ãƒ©ãƒ•ã‹ã‚‰ã¯Nå¹´å¾Œã«ã¯äººé–“ã§è¨€ã†ã¨ã“ã®ãã‚‰ã„ã®èƒ½åŠ›ã®äººãŒã“ã®ãã‚‰ã„æ™‚é–“ã‚’è¦ã™ã‚‹ã‚¿ã‚¹ã‚¯ãŒã€ã“ã®ãã‚‰ã„ã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ã¾ã™ã€ã¨ã„ã£ãŸã–ã£ãã‚Šæ„Ÿè¦šå€¤ã¯ãªã‹ãªã‹æƒ³åƒã§ããªã„ã€‚<br><img src="https://github.com/user-attachments/assets/e2bed06e-9234-4607-826a-588106010bcf" alt="image" loading="lazy"></p>
<p>æˆåŠŸç‡ã¨ã‚¿ã‚¹ã‚¯ã«äººé–“ãŒè¦ã™ã‚‹æ™‚é–“ã«é–¢ã™ã‚‹ã‚°ãƒ©ãƒ•ã€‚ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯é–¢æ•°ã§fittingã—ã¦ãŠã‚Šã€èµ¤ã„ç ´ç·šãŒ50% horizonã€‚Claude 3.5 Sonnet ï¼ˆoldï¼‰ã‹ã‚‰Claude 3.7 Sonnetã§50% horizonã¯18åˆ†ã‹ã‚‰59åˆ†ã¾ã§å¢—ãˆã¦ã„ã‚‹ã€‚å®Ÿéš›ã«æ•°å­—ã§è¦‹ã‚‹ã¨ã‚¤ãƒ¡ãƒ¼ã‚¸ãŒæ¹§ãã‚„ã™ããŠã‚‚ã—ã‚ã„ã€‚<br><img src="https://github.com/user-attachments/assets/efe01e35-6ee6-45a5-8a4c-eccf95284b35" alt="image" loading="lazy"></p>
<p>ã“ã¡ã‚‰ã§æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚‚éšæ™‚æ›´æ–°ã•ã‚Œã‚‹:<br>


<a href="https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/" target="_blank" rel="noopener noreferrer">https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/</a>


</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1839" target="_blank" rel="noopener noreferrer" class="title-link">RALLRec+: Retrieval Augmented Large Language Model Recommendation with  Reasoning, Sichun Luo+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RALLRec+ã¯ã€LLMsã‚’ç”¨ã„ã¦ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®retrievalã¨generationã‚’å¼·åŒ–ã™ã‚‹æ‰‹æ³•ã€‚retrievalæ®µéšã§ã¯ã€ã‚¢ã‚¤ãƒ†ãƒ èª¬æ˜ã‚’ç”Ÿæˆã—ã€ãƒ†ã‚­ã‚¹ãƒˆä¿¡å·ã¨å”èª¿ä¿¡å·ã‚’çµåˆã€‚ç”Ÿæˆæ®µéšã§ã¯ã€æ¨è«–LLMsã‚’è©•ä¾¡ã—ã€çŸ¥è­˜æ³¨å…¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã§æ±ç”¨LLMsã¨çµ±åˆã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆæ‰‹æ³•ã®æœ‰åŠ¹æ€§ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1905107217663336832?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Reasoning LLMã‚’RecSysã«å¿œç”¨ã™ã‚‹åˆã‚ã¦ã®ç ”ç©¶ï¼ˆã‚‰ã—ã„ã“ã¨ãŒRelated Workã«æ›¸ã‹ã‚Œã¦ã„ã‚‹ï¼‰</p>
<p>arxivã®adminã‚ˆã‚Šä»¥ä¸‹ã®ã‚³ãƒ¡ãƒ³ãƒˆãŒè¿½è¨˜ã•ã‚Œã¦ã„ã‚‹<br>&gt; 	arXiv admin note: substantial text overlap with arXiv:2502.06101<br><br>ã‚³ãƒ¡ãƒ³ãƒˆä¸­ã®ç ”ç©¶ã¯ä¸‹è¨˜ã§ã‚ã‚‹<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1840" target="_blank" rel="noopener noreferrer">ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential   Behavior Comprehension in Recommendation, Jianghao Lin+, WWW'24</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2025-03-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1838" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Evaluation-time Compute with Reasoning Models as Process  Evaluators, Seungone Kim+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LMã®å‡ºåŠ›å“è³ªè©•ä¾¡ãŒé›£ã—ããªã£ã¦ã„ã‚‹ä¸­ã€è¨ˆç®—ã‚’å¢—ã‚„ã™ã“ã¨ã§è©•ä¾¡èƒ½åŠ›ãŒå‘ä¸Šã™ã‚‹ã‹ã‚’æ¤œè¨ã€‚æ¨è«–ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦å¿œç­”å…¨ä½“ã¨å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’è©•ä¾¡ã—ã€æ¨è«–ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”ŸæˆãŒè©•ä¾¡è€…ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚å†ãƒ©ãƒ³ã‚¯ä»˜ã‘ã«ã‚ˆã‚Šã€è©•ä¾¡æ™‚ã®è¨ˆç®—å¢—åŠ ãŒLMã®å•é¡Œè§£æ±ºèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jinulee_v/status/1905025016401428883?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLM-as-a-Judgeã‚‚longCoT+self-consistencyã§æ€§èƒ½ãŒæ”¹å–„ã™ã‚‹ã‚‰ã—ã„ã€‚<br><img src="https://github.com/user-attachments/assets/937b6241-4877-46c7-a488-5ee6bf8203db" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-03-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1837" target="_blank" rel="noopener noreferrer" class="title-link">Overtrained Language Models Are Harder to Fine-Tune, Jacob Mitchell Springer+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ã«ãŠã„ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³äºˆç®—ã®å¢—åŠ ãŒãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é›£ã—ãã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹ã‚’å¼•ãèµ·ã“ã™ã€Œå£Šæ»…çš„ãªéå­¦ç¿’ã€ã‚’æå”±ã€‚3Tãƒˆãƒ¼ã‚¯ãƒ³ã§äº‹å‰å­¦ç¿’ã•ã‚ŒãŸOLMo-1Bãƒ¢ãƒ‡ãƒ«ã¯ã€2.3Tãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦2%ä»¥ä¸Šã®æ€§èƒ½ä½ä¸‹ã‚’ç¤ºã™ã€‚å®Ÿé¨“ã¨ç†è«–åˆ†æã«ã‚ˆã‚Šã€äº‹å‰å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ„Ÿåº¦ã®å¢—åŠ ãŒåŸå› ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€äº‹å‰å­¦ç¿’è¨­è¨ˆã®å†è©•ä¾¡ã‚’ä¿ƒã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>è‘—è€…ã«ã‚ˆã‚‹ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacspringer/status/1904960783341023521?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>äº‹å‰å­¦ç¿’ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å¢—ã‚„ã™ã¨ãƒ¢ãƒ‡ãƒ«ã®sensitivityãŒå¢—ã—ã€post-trainingã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®åŠ£åŒ–ãŒèµ·ã“ã‚‹ã“ã¨ã‚’å ±å‘Šã—ã¦ã„ã‚‹ã€‚äº‹å‰å­¦ç¿’ã§å­¦ç¿’ã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å¢—ã‚„ã›ã°ã€å¿…ãšã—ã‚‚post-trainingå¾Œã®ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãŒã‚ˆããªã‚‹ã‚ã‘ã§ã¯ãªã„ã‚‰ã—ã„ã€‚<br><img src="https://github.com/user-attachments/assets/ba60ae24-f3e5-4956-b29f-37b4fe01a9d1" alt="image" loading="lazy"></p>
<p>ICLR'25ã®Outstanding Paperã«é¸ã°ã‚ŒãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacspringer/status/1917174452531724718?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãã¡ã‚“ã¨èª­ã‚“ã æ–¹ãŒè‰¯ã•ã’ã€‚</span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-03-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1833" target="_blank" rel="noopener noreferrer" class="title-link">ExpertGenQA: Open-ended QA generation in Specialized Domains, Haz Sameen Shahgir+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ExpertGenQAã¯ã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã¨ãƒˆãƒ”ãƒƒã‚¯ãƒ»ã‚¹ã‚¿ã‚¤ãƒ«åˆ†é¡ã‚’çµ„ã¿åˆã‚ã›ãŸQAãƒšã‚¢ç”Ÿæˆãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã€ç±³å›½é€£é‚¦é‰„é“å±€ã®æ–‡æ›¸ã‚’ç”¨ã„ã¦94.4%ã®ãƒˆãƒ”ãƒƒã‚¯ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’ç¶­æŒã—ã¤ã¤ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®2å€ã®åŠ¹ç‡ã‚’é”æˆã€‚è©•ä¾¡ã§ã¯ã€LLMãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ãŒå†…å®¹ã‚ˆã‚Šã‚‚æ–‡ä½“ã«åã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã€ExpertGenQAã¯å°‚é–€å®¶ã®è³ªå•ã®èªçŸ¥çš„è¤‡é›‘æ€§ã‚’ã‚ˆã‚Šè‰¯ãä¿æŒã€‚ç”Ÿæˆã—ãŸã‚¯ã‚¨ãƒªã¯ã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’13.02%å‘ä¸Šã•ã›ã€æŠ€è¡“åˆ†é‡ã§ã®æœ‰åŠ¹æ€§ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/at_sushi_/status/1904325501331890561?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-03-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1832" target="_blank" rel="noopener noreferrer" class="title-link">Critique Fine-Tuning: Learning to Critique is More Effective than   Learning to Imitate, Yubo Wang+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- æ‰¹è©•ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆCFTï¼‰ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒãƒã‚¤ã‚ºã®ã‚ã‚‹å¿œç­”ã‚’æ‰¹è©•ã™ã‚‹ã“ã¨ã‚’å­¦ã¶æ–°ã—ã„æˆ¦ç•¥ã§ã€å¾“æ¥ã®ç›£è¦–ä»˜ããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã«æŒ‘æˆ¦ã—ã¾ã™ã€‚CFTã¯äººé–“ã®å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã«ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ã‚’å—ã‘ã€æ·±ã„åˆ†æã‚’ä¿ƒé€²ã—ã¾ã™ã€‚WebInstructã‹ã‚‰æ§‹ç¯‰ã—ãŸ50Kã‚µãƒ³ãƒ—ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€CFTã¯è¤‡æ•°ã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§SFTã«å¯¾ã—ã¦4-10%ã®æ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ã¾ã—ãŸã€‚ç‰¹ã«ã€Qwen2.5-Math-CFTã¯å°‘ãªã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§å¼·åŠ›ãªç«¶åˆã¨åŒç­‰ã®æ€§èƒ½ã‚’ç™ºæ®ã—ã€CFTã®å …ç‰¢æ€§ã‚‚ç¢ºèªã•ã‚Œã¾ã—ãŸã€‚CFTã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã‚’é€²å±•ã•ã›ã‚‹åŠ¹æœçš„ãªæ‰‹æ³•ã§ã‚ã‚‹ã¨ä¸»å¼µã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/WenhuChen/status/1885060597500567562"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Critique Fine-Tuning (CFT) ã‚’ææ¡ˆã€‚CFTã§ã¯ã€query x, noisy response y [^1] ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ãã‚Œã«å¯¾ã™ã‚‹æ‰¹è©• cã‚’å­¦ç¿’ã™ã‚‹ã€‚cã¯givenã§ã¯ãªã„ã®ã§ã€GPT4oã®ã‚ˆã†ãªå¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦åˆæˆã™ã‚‹ã€‚<br><br>![Image](https://github.com/user-attachments/assets/f25babdd-63d6-4d3d-a9b0-3217db2bd07f)<br><br>ç›®çš„é–¢æ•°ã¯ä»¥ä¸‹ã€‚[x; y] ãŒgivenãªæ™‚ã«cã‚’ç”Ÿæˆã™ã‚‹ç¢ºç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ã€‚ã‚·ãƒ³ãƒ—ãƒ«ã€‚<br>![Image](https://github.com/user-attachments/assets/ccdb8e42-e8b2-4ae1-99a6-a0b7c1d4bf2a)<br><br>RLã‚’ç”¨ã„ãŸæ‰‹æ³•ã¨ã®æ¯”è¼ƒã€‚1/10ç¨‹åº¦ã®ãƒ‡ãƒ¼ã‚¿é‡ã€1/100ç¨‹åº¦ã®GPUæ™‚é–“ã§åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã§ãã‚‹ã€‚<br>![Image](https://github.com/user-attachments/assets/848376ff-9965-485b-b8a0-7960d1d0e7b9)<br><br>[^1]: æœ¬è«–æ–‡ã§åˆ©ç”¨ã—ã¦ã„ã‚‹WebInstructã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸãƒ‡ãƒ¼ã‚¿ã§ã¯ã€ãŸã¨ãˆã°ç´„50%ç¨‹åº¦ã®yãŒæ­£è§£,  æ®‹ã‚Šã¯ä¸æ­£è§£ï¼ˆç¨‹åº¦ã®noisyãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ï¼‰</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1826" target="_blank" rel="noopener noreferrer" class="title-link">Thinking Machines: A Survey of LLM based Reasoning Strategies, Dibyanayan Bandyopadhyay+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯å„ªã‚ŒãŸè¨€èªèƒ½åŠ›ã‚’æŒã¤ãŒã€æ¨è«–èƒ½åŠ›ã¨ã®é–“ã«ã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹ã€‚æ¨è«–ã¯AIã®ä¿¡é ¼æ€§ã‚’é«˜ã‚ã€åŒ»ç™‚ã‚„æ³•å¾‹ãªã©ã®åˆ†é‡ã§ã®é©ç”¨ã«ä¸å¯æ¬ ã§ã‚ã‚‹ã€‚æœ€è¿‘ã®å¼·åŠ›ãªæ¨è«–ãƒ¢ãƒ‡ãƒ«ã®ç™»å ´ã«ã‚ˆã‚Šã€LLMsã«ãŠã‘ã‚‹æ¨è«–ã®ç ”ç©¶ãŒé‡è¦è¦–ã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€æ—¢å­˜ã®æ¨è«–æŠ€è¡“ã®æ¦‚è¦ã¨æ¯”è¼ƒã‚’è¡Œã„ã€æ¨è«–ã‚’å‚™ãˆãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®ä½“ç³»çš„ãªèª¿æŸ»ã¨ç¾åœ¨ã®èª²é¡Œã‚’æç¤ºã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1903843684568666450?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RL, Test Time Compute, Self-trainingã®3ç¨®é¡ã«ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã•ã‚Œã¦ã„ã‚‹ã€‚ã¾ãŸã€å„ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«ã‚ˆã‚Šç´°åˆ†åŒ–ã•ã‚ŒãŸãƒ„ãƒªãƒ¼ãŒè«–æ–‡ä¸­ã«ã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/d323db81-973a-4752-afc9-4471f5e64feb" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1825" target="_blank" rel="noopener noreferrer" class="title-link">Compute Optimal Scaling of Skills: Knowledge vs Reasoning, Nicholas Roberts+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã¯LLMé–‹ç™ºã«ãŠã„ã¦é‡è¦ã§ã‚ã‚Šã€ç‰¹ã«è¨ˆç®—æœ€é©åŒ–ã«ã‚ˆã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ãŒçŸ¥è­˜ã‚„æ¨è«–ã«åŸºã¥ãã‚¹ã‚­ãƒ«ã«ä¾å­˜ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ãƒŸãƒƒã‚¯ã‚¹ãŒã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æŒ™å‹•ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã—ãŸã€‚çµæœã€çŸ¥è­˜ã¨ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®ã‚¹ã‚­ãƒ«ã¯æ ¹æœ¬çš„ã«ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æŒ™å‹•ã‚’ç¤ºã—ã€èª¤æŒ‡å®šã•ã‚ŒãŸæ¤œè¨¼ã‚»ãƒƒãƒˆãŒè¨ˆç®—æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã«ç´„50%ã®å½±éŸ¿ã‚’ä¸ãˆã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1903843682509312218?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>çŸ¥è­˜ã‚’å•ã†QAã®ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é‡ãŒå¿…è¦ã§ã‚ã‚Šã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ã‚ˆã†ãªReasoningã«åŸºã¥ãã‚¿ã‚¹ã‚¯ã¯ãƒ‡ãƒ¼ã‚¿é‡ãŒå¿…è¦ã§ã‚ã‚Šã€ç•°ãªã‚‹è¦ç´ ã«ä¾å­˜ã—ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ç ”ç©¶ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/5d2bb3c6-437a-4184-9848-3232745d0de1" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1819" target="_blank" rel="noopener noreferrer" class="title-link">Stop Overthinking: A Survey on Efficient Reasoning for Large Language  Models, Yang Sui+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€LLMsã«ãŠã‘ã‚‹åŠ¹ç‡çš„ãªæ¨è«–ã®é€²å±•ã‚’ä½“ç³»çš„ã«èª¿æŸ»ã—ã€ä»¥ä¸‹ã®ä¸»è¦ãªæ–¹å‘ã«åˆ†é¡ã—ã¾ã™ï¼š(1) ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®åŠ¹ç‡çš„æ¨è«–ã€(2) æ¨è«–å‡ºåŠ›ãƒ™ãƒ¼ã‚¹ã®åŠ¹ç‡çš„æ¨è«–ã€(3) å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ™ãƒ¼ã‚¹ã®åŠ¹ç‡çš„æ¨è«–ã€‚ç‰¹ã«ã€å†—é•·ãªå‡ºåŠ›ã«ã‚ˆã‚‹è¨ˆç®—ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’è»½æ¸›ã™ã‚‹æ–¹æ³•ã‚’æ¢æ±‚ã—ã€å°è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚„è©•ä¾¡æ–¹æ³•ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Reasoning Modelã«ãŠã„ã¦ã€Over Thinkingç¾è±¡ï¼ˆä¸è¦ãªreasoning stepã‚’ç”Ÿæˆã—ã¦ã—ã¾ã†ï¼‰ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®æ‰‹æ³•ã«é–¢ã™ã‚‹Surveyã€‚<br><img src="https://github.com/user-attachments/assets/a411f2cf-2ba1-4e58-8dc7-ac1ae2ff0de6" alt="image" loading="lazy"><br><br>ä¸‹è¨˜Figure2ã‚’è¦‹ã‚‹ã¨ã‚ˆãã¾ã¨ã¾ã£ã¦ã„ã¦ã€ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’èª­ã‚€ã¨ã ã„ãŸã„åˆ†ã‹ã‚‹ã€‚ãªã‚‹ã»ã©ã€‚<br>Length Rewardã«ã¤ã„ã¦ã¯ã€<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
<br><br>ã§è€ƒå¯Ÿã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€Reward HackingãŒèµ·ãã‚‹ã®ã§è¨­è¨ˆã®ä»•æ–¹ã«æ°—ã‚’ã¤ã‘ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/fd6880bd-95e1-4ca6-9593-8ffc9390962a" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1902977896685396275?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å„ã‚«ãƒ†ã‚´ãƒªã«ãŠã‘ã‚‹literatureã‚‚è¦‹ã‚„ã™ãã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚å¿…è¦ã«å¿œã˜ã¦å‚ç…§ã—ãŸã„ã€‚<br><img src="https://github.com/user-attachments/assets/b6be0d79-35c5-45a8-878b-2b6be67c2f76" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-03-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1817" target="_blank" rel="noopener noreferrer" class="title-link">Lost-in-the-Middle in Long-Text Generation: Synthetic Dataset,  Evaluation Framework, and Mitigation, Junhao Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- é•·ã„å…¥åŠ›ã¨å‡ºåŠ›ã®ç”Ÿæˆã«ç‰¹åŒ–ã—ãŸLongInOutBenchã‚’å°å…¥ã—ã€æ—¢å­˜æ‰‹æ³•ã®ã€Œä¸­é–“ã§ã®å–ªå¤±ã€å•é¡Œã«å¯¾å‡¦ã€‚Retrieval-Augmented Long-Text Writerï¼ˆRAL-Writerï¼‰ã‚’é–‹ç™ºã—ã€é‡è¦ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å†è¡¨ç¾ã™ã‚‹ã“ã¨ã§æ€§èƒ½ã‚’å‘ä¸Šã€‚ææ¡ˆæ‰‹æ³•ã®æœ‰åŠ¹æ€§ã‚’ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨æ¯”è¼ƒã—ã¦ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Lost in the Middleã«é–¢ã™ã‚‹ç ”ç©¶ã€‚</p>
<p>é–¢é€£ç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/793" target="_blank" rel="noopener noreferrer">Lost in the Middle: How Language Models Use Long Contexts, Nelson F. Liu+, N/A, TACL'24</a>
</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2025-03-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1813" target="_blank" rel="noopener noreferrer" class="title-link">The First Few Tokens Are All You Need: An Efficient and Effective  Unsupervised Prefix Fine-Tuning Method for Reasoning Models, Ke Ji+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- éæ•™å¸«ã‚ã‚Šãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆUPFTï¼‰ã‚’ææ¡ˆã—ã€LLMã®æ¨è«–åŠ¹ç‡ã‚’å‘ä¸Šã€‚åˆæœŸã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹éƒ¨åˆ†æ–‡å­—åˆ—ã«åŸºã¥ã„ã¦è¨“ç·´ã—ã€ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã‚„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ä¸è¦ã«ã€‚UPFTã¯ã€æ•™å¸«ã‚ã‚Šæ‰‹æ³•ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¶­æŒã—ã¤ã¤ã€è¨“ç·´æ™‚é–“ã‚’75%ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚³ã‚¹ãƒˆã‚’99%å‰Šæ¸›ã€‚æœ€å°é™ã®éæ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§å¤§å¹…ãªæ¨è«–å‘ä¸Šã‚’å®Ÿç¾ã—ã€ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡ã®è‰¯ã„ä»£æ›¿æ‰‹æ®µã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ–œã‚èª­ã¿ã ãŒã€reasoning traceã®å†’é ­éƒ¨åˆ†ã¯é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¦ãŠã‚Šã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸå¤šãã®responseã®reasoning traceã«ãŠã„ã¦å…±é€šã—ã¦ã„ã‚‹ã‚‚ã®ã¯é‡è¦ã¨ã„ã†ç›´æ„Ÿã‹ã‚‰ï¼ˆPrefix Self-Consistencyï¼‰ã€reasoning traceã®å†’é ­éƒ¨åˆ†ã‚’é©åˆ‡ã«ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«ã‚’Finetuningã™ã‚‹ã€‚å¾“æ¥ã®Rejection Samplingã‚’ç”¨ã„ãŸæ‰‹æ³•ã§ã¯ã€è¤‡æ•°ã®responseã‚’ç”Ÿæˆã•ã›ã¦ã€æœ€çµ‚çš„ãªanswerãŒæ­£è§£ã®ã‚‚ã®ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ãŸã‚æ­£è§£ãƒ©ãƒ™ãƒ«ãŒå¿…è¦ã¨ãªã‚‹ãŒã€ææ¡ˆæ‰‹æ³•ã§ã¯reasoning traceã®å†’é ­éƒ¨åˆ†ã®å…±é€šã™ã‚‹subsequenceã‚’majority voteã™ã‚‹ã ã‘ãªã®ã§ãƒ©ãƒ™ãƒ«ãŒä¸è¦ã§ã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/ff3938da-dcd0-4b6c-a764-26d2e8caa63a" alt="image" loading="lazy"><br><br>reasoning prefixã‚’å­¦ç¿’ã™ã‚‹éš›ã¯ä¸‹è¨˜ã®ã‚ˆã†ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”¨ã„ã‚‹ã€‚ã“ã®ã¨ãã«ã€prefixã®spanã®ã¿ã‚’åˆ©ç”¨ã—ã¦å­¦ç¿’ã™ã‚‹ã“ã¨ã§å¤§å¹…ã«å­¦ç¿’æ™‚é–“ã‚’å‰Šæ¸›ã§ãã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/63aabe47-9c40-41cb-8d5a-5039900f6edc" alt="image" loading="lazy"><br><br>ã¾ãŸã€ãã®ã‚ˆã†ãªå­¦ç¿’ã‚’è¡Œã†ã¨catastrophic forgettingã®ãƒªã‚¹ã‚¯ãŒéå¸¸ã«é«˜ã„ãŒã€ã“ã‚Œã‚’é˜²ããŸã‚ã«ã€ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿæ–½ã™ã‚‹ã€‚å…·ä½“çš„ã«ã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®p%ã«ã¤ã„ã¦ã¯å…¨ä½“ã®reasoning traceã‚’ç”Ÿæˆã—ã¦å­¦ç¿’ã«åˆ©ç”¨ã™ã‚‹ã€‚ã“ã®ã¨ãã«ã€æœ€çµ‚çš„ãªå›ç­”ã®æ­£èª¤ã‚’æ°—ã«ã›ãštraceã‚’ç”Ÿæˆã—ã¦å­¦ç¿’ã«åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€ãƒ©ãƒ™ãƒ«ãƒ•ãƒªãƒ¼ãªç‰¹æ€§ã‚’ç¶­æŒã§ãã‚‹ï¼ˆã¤ã¾ã‚Šã€ã“ã¡ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã¯è‰¯ã„reasoning traceã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªãã€ã‚ãã¾ã§catastrophic forgettingã‚’é˜²ããŸã‚ã«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ã‚ˆã†ãªtraceã‚‚ãã¡ã‚“ã¨ç”Ÿæˆã§ãã‚Œã°è‰¯ã„ã€ã¨ã„ã†æ„Ÿè¦šã ã¨æ€ã‚ã‚Œã‚‹ï¼‰ã€‚<br><img src="https://github.com/user-attachments/assets/6e83c686-5bcf-4db8-9b8a-63c39570a4dc" alt="image" loading="lazy"><br><br>Appendixã«Qwenã‚’ç”¨ã„ã¦temperature 0.7ã§16å€‹ã®responseã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€traceã®å†’é ­éƒ¨åˆ†ãŒå…±é€šã—ã¦ã„ã‚‹æ§˜å­ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚</p>
<p>ä¸‹è¨˜è«–æ–‡ã§long-CoTã‚’å­¦ç¿’ã•ã›ã‚‹éš›ã®long-CoTãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã€reasoningãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç”Ÿæˆã—ãŸtraceã¨éreasoning modelã‹ã‚‰ç”Ÿæˆã—ãŸtraceã«ã‚ˆã‚‹long-CoTãƒ‡ãƒ¼ã‚¿ã‚’æ¯”è¼ƒã—ãŸã¨ã“ã‚å‰è€…ã®æ–¹ãŒä¸€è²«ã—ã¦å­¦ç¿’æ€§èƒ½ãŒè‰¯ã‹ã£ãŸã¨ã‚ã‚‹ãŒã€ã“ã®ç ”ç©¶ã§ã‚‚reasoning traceã‚’ã¤ã‚ˆã¤ã‚ˆãƒ¢ãƒ‡ãƒ«ã§ç”Ÿæˆã—ãŸã‚‰æ€§èƒ½ä¸ŠãŒã‚‹ã‚“ã ã‚ã†ã‹ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-03-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1811" target="_blank" rel="noopener noreferrer" class="title-link">Sample, Scrutinize and Scale: Effective Inference-Time Search by Scaling  Verification, Eric Zhao+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®æ¢ç´¢ã¯ã€è¤‡æ•°ã®å€™è£œå¿œç­”ã‚’ç”Ÿæˆã—æœ€è‰¯ã®ã‚‚ã®ã‚’é¸ã¶æ‰‹æ³•ã§ã‚ã‚Šã€è‡ªå·±æ¤œè¨¼ã«ã‚ˆã£ã¦æ­£ç¢ºæ€§ã‚’ç¢ºèªã—ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ã“ã®æ¢ç´¢ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‚¾å‘ã‚’åˆ†æã—ã€ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…ãŒGemini v1.5 Proã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚è‡ªå·±æ¤œè¨¼ã®ç²¾åº¦å‘ä¸Šã¯ã€ã‚ˆã‚Šå¤§ããªå¿œç­”ãƒ—ãƒ¼ãƒ«ã‹ã‚‰ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ã‚‚ã®ã§ã€å¿œç­”é–“ã®æ¯”è¼ƒãŒæœ‰ç›Šãªä¿¡å·ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚„ã€ç•°ãªã‚‹å‡ºåŠ›ã‚¹ã‚¿ã‚¤ãƒ«ãŒæ–‡è„ˆã«å¿œã˜ã¦å½¹ç«‹ã¤ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã—ãŸã€‚ã¾ãŸã€æœ€å‰ç·šã®ãƒ¢ãƒ‡ãƒ«ã¯åˆæœŸã®æ¤œè¨¼èƒ½åŠ›ãŒå¼±ãã€é€²æ—ã‚’æ¸¬ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ericzhao28/status/1901704339229732874?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã–ã£ãã‚Šã—ã‹èª­ã‚ã¦ã„ãªã„ãŒã€è¤‡æ•°ã®è§£ç­”ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ã€self-verificationã‚’ã•ã›ã¦æœ€ã‚‚è‰¯ã‹ã£ãŸã‚‚ã®ã‚’é¸æŠã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€‚æœ€ã‚‚verificationã‚¹ã‚³ã‚¢ãŒé«˜ã„è§£ç­”ã‚’æœ€çµ‚çš„ã«é¸æŠã—ãŸã„ãŒã€tieã®å ´åˆã‚‚ã‚ã‚‹ã®ã§ãã®å ´åˆã¯è¿½åŠ ã®promptingã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ¯”è¼ƒã—ã‚ˆã‚Šè‰¯ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’é¸æŠã™ã‚‹ã€‚ã“ã‚Œã‚‰ã¯ä¸¦åˆ—ã—ã¦å®Ÿè¡ŒãŒå¯èƒ½ã§ã€æ¢ç´¢ã¨self-verificationã‚’200å€‹ä¸¦åˆ—ã™ã‚‹ã¨Gemini 1.5 Proã§o1-previewã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã§ãã‚‹æ¨¡æ§˜ã€‚Self-consistencyã¨æ¯”è¼ƒã—ã¦ã‚‚ã€gainãŒå¤§ãã„ã€‚å…·ä½“çš„ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯Algorithm1ã‚’å‚ç…§ã®ã“ã¨ã€‚<br><br>&lt;img width="656" height="236" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/a62625e1-5503-459c-91f3-b7018aba76a6"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a62625e1-5503-459c-91f3-b7018aba76a6"&lt;/a&gt;


/&gt;</p>
<p>openreview: 


<a href="https://openreview.net/forum?id=wl3eI4wiE5" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=wl3eI4wiE5</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<span class="issue_date">Issue Date: 2025-03-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1806" target="_blank" rel="noopener noreferrer" class="title-link">All Roads Lead to Likelihood: The Value of Reinforcement Learning in  Fine-Tuning, Gokul Swamy+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦ã€å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸäºŒæ®µéšã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹é †ãŒåŠ¹æœçš„ã§ã‚ã‚‹ç†ç”±ã‚’ç†è«–çš„ãŠã‚ˆã³å®Ÿè¨¼çš„ã«æ¤œè¨ã€‚ç‰¹ã«ã€å¥½ã¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å˜ç´”ãªå ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ã³ã€å¼·åŒ–å­¦ç¿’æ‰‹ç¶šããŒãã®ãƒ¢ãƒ‡ãƒ«ã«æœ€é©ãªãƒãƒªã‚·ãƒ¼ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹èƒ½åŠ›ãŒã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1901392286694678568?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Alignmentã®ãŸã‚ã®Preferenceãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹æ™‚ã«ã€ãã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç›´æ¥æœ€å°¤æ¨å®šã—ã¦ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã™ã‚‹ã®ã§ã¯ãªãã€å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ã€ãã®å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å¼·åŒ–å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€ãªãœå‰è€…ã‚ˆã‚Šã‚‚ï¼ˆåŒã˜ãƒ‡ãƒ¼ã‚¿ç”±æ¥ã§ã‚ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšï¼‰å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã®ã‹ã€ã¨ã„ã†ç–‘å•ã«å¯¾ã—ã¦ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã—ã¦ã„ã‚‹ã€‚</p>
<p>å…¨ãä¸­èº«ã‚’èª­ã‚ã¦ã„ãªã„ãŒã€ç”Ÿæˆã™ã‚‹ã“ã¨ã¨ï¼ˆæ–¹ç­–ãƒ¢ãƒ‡ãƒ«ï¼‰ã¨æ¤œè¨¼ã™ã‚‹ã“ã¨ï¼ˆå ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼‰ã®é–“ã«ã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹å ´åˆï¼ˆã™ãªã‚ã¡ã€ç”Ÿæˆã¨æ¤œè¨¼ã§æ±‚ã‚ã‚‰ã‚Œã‚‹èƒ½åŠ›ãŒç•°ãªã‚‹å ´åˆï¼‰ã€MLEã§ã¯å¯èƒ½ãªã™ã¹ã¦ã®ãƒãƒªã‚·ãƒ¼ã‚’æ¢ç´¢ã™ã‚‹ã“ã¨ã¨ä¼¼ãŸã‚ˆã†ãªã“ã¨ã‚’ã™ã‚‹ã“ã¨ã«ãªã‚‹ãŒã€RLã§ã¯äº‹å‰ã«å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ãã®å ±é…¬ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦æœ€é©ãªãƒãƒªã‚·ãƒ¼ã‚’æ¢ç´¢ã™ã‚‹ã ã‘ãªã®ã§æ¢ç´¢ã™ã‚‹ç©ºé–“ãŒåˆ¶é™ã•ã‚Œã‚‹ï¼ˆï¼ç”Ÿæˆã¨æ¤œè¨¼ã®ã‚®ãƒ£ãƒƒãƒ—ãŒåŸ‹ã¾ã‚‹ï¼‰ã®ã§ã€è‰¯ã„è§£ã«åæŸã—ã‚„ã™ããªã‚‹ã€ã¨ã„ã†ã‚¤ãƒ¡ãƒ¼ã‚¸ãªã‚“ã ã‚ã†ã‹ã€‚<br><img src="https://github.com/user-attachments/assets/121e97a6-120e-4830-9bcf-329129a687eb" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2025-03-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1799" target="_blank" rel="noopener noreferrer" class="title-link">NeoBERT: A Next-Generation BERT, Lola Le Breton+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- NeoBERTã¯ã€æœ€æ–°ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ãŸæ¬¡ä¸–ä»£ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã§ã€åŒæ–¹å‘ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’å†å®šç¾©ã—ã¾ã™ã€‚4,096ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’æ´»ç”¨ã—ã€250Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚ã‚ŠãªãŒã‚‰ã€MTEBãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã€BERTã‚„RoBERTaã‚’ä¸Šå›ã‚Šã¾ã™ã€‚ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ã‚„ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã—ã€ç ”ç©¶ã¨å®Ÿä¸–ç•Œã§ã®æ¡ç”¨ã‚’ä¿ƒé€²ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£: <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1606" target="_blank" rel="noopener noreferrer">ModernBERT, AnswerDotAI, 2024.12</a>
</p>
<p>## BERT, ModernBERTã¨ã®é•ã„<br><br>![Image](https://github.com/user-attachments/assets/58dbdcf6-e7dc-43c2-94ed-d8bb73cd2617)<br><br>## æ€§èƒ½<br><br>![Image](https://github.com/user-attachments/assets/72730c9c-38d0-4773-8ddb-f0349b8776d2)<br><br>## æ‰€æ„Ÿ<br>medium sizeæœªæº€ã®ãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§ã¯SoTAã§ã¯ã‚ã‚‹ãŒã€ModernBERTãŒåˆ©ç”¨ã§ãã‚‹ã®ã§ã‚ã‚Œã°ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’è¦‹ã‚‹é™ã‚Šã¯å®Ÿç”¨çš„ã«ã¯ModernBERTã§è‰¯ã„ã®ã§ã¯ã€ã¨æ„Ÿã˜ãŸã€‚å­¦ç¿’ã¨inferenceã®é€Ÿåº¦å·®ã¯ã©ã®ç¨‹åº¦ã‚ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1798" target="_blank" rel="noopener noreferrer" class="title-link">A Survey on Post-training of Large Language Models, Guiyao Tie+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯è‡ªç„¶è¨€èªå‡¦ç†ã«é©å‘½ã‚’ã‚‚ãŸã‚‰ã—ãŸãŒã€å°‚é–€çš„ãªæ–‡è„ˆã§ã®åˆ¶ç´„ãŒæ˜ã‚‰ã‹ã§ã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€é«˜åº¦ãªãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆPoLMsï¼‰ãŒå¿…è¦ã§ã‚ã‚Šã€æœ¬è«–æ–‡ã§ã¯ãã®åŒ…æ‹¬çš„ãªèª¿æŸ»ã‚’è¡Œã†ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã€æ¨è«–ã€åŠ¹ç‡ã€çµ±åˆã¨é©å¿œã®5ã¤ã®ã‚³ã‚¢ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã«ã‚ãŸã‚‹é€²åŒ–ã‚’è¿½è·¡ã—ã€PoLMãŒãƒã‚¤ã‚¢ã‚¹è»½æ¸›ã‚„æ¨è«–èƒ½åŠ›å‘ä¸Šã«å¯„ä¸ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€‚ç ”ç©¶ã¯PoLMã®é€²åŒ–ã«é–¢ã™ã‚‹åˆã®èª¿æŸ»ã§ã‚ã‚Šã€å°†æ¥ã®ç ”ç©¶ã®ãŸã‚ã®æ çµ„ã¿ã‚’æä¾›ã—ã€LLMã®ç²¾åº¦ã¨å€«ç†çš„å …ç‰¢æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Post Trainingã®æ™‚é–“ç™ºå±•ã®å›³è§£ãŒéå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„ï¼ˆãŒã€å³å¯†æ€§ã«ã¯æ¬ ã‘ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚å½“è©²ãƒ¢ãƒ‡ãƒ«ã®æ–°è¦æ€§ã«ãŠã‘ã‚‹ä¸»è¦ãªæŠ€è¡“ã¯ã“ã‚Œã§ã™ã€ã¨ã„ã†å›³ã¨ã—ã¦ã¿ã‚‹ã«ã¯è‰¯ã„ã®ã‹ã‚‚ã—ã‚Œãªã„ï¼‰ã€‚<br>å€‹ã€…ã®æŠ€è¡“ãŒæ‰±ã†ã‚¹ã‚³ãƒ¼ãƒ—ã¨ãƒ¬ã‚¤ãƒ¤ãƒ¼ã€ãƒ‡ãƒ¼ã‚¿ã®æ€§è³ªãŒæƒã£ã¦ã„ãªã„æ°—ãŒã™ã‚‹ã—ã€ãã‚Œãã‚Œã®LLMãŒyè»¸ã®å˜ä¸€ã®æŠ€è¡“ã ã‘ã«ä¾å­˜ã—ã¦ã„ã‚‹ã‚ã‘ã§ã‚‚ãªã„ã€‚ãŒã€å³å¯†ã«å›³ã‚’æ›¸ã„ã¦ã¨è¨€ã‚ã‚ŒãŸæ™‚ã«ã©ã†æ›¸ã‘ã°è‰¯ã„ã‹ã¨å•ã‚ã‚Œã‚‹ã¨é›£ã—ã„æ„Ÿã¯ã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/6cdf060f-1cc9-44cd-b81a-50f4d3c442de" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1900595286898340230?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<span class="issue_date">Issue Date: 2025-03-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1795" target="_blank" rel="noopener noreferrer" class="title-link">Transformers without Normalization, Jiachen Zhu+, CVPR'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ­£è¦åŒ–å±¤ãªã—ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãŒDynamic Tanhï¼ˆDyTï¼‰ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€åŒç­‰ã¾ãŸã¯ãã‚Œä»¥ä¸Šã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚DyTã¯ã€ãƒ¬ã‚¤ãƒ¤ãƒ¼æ­£è¦åŒ–ã®ä»£æ›¿ã¨ã—ã¦æ©Ÿèƒ½ã—ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ãªã—ã§åŠ¹æœã‚’ç™ºæ®ã—ã¾ã™ã€‚å¤šæ§˜ãªè¨­å®šã§ã®å®Ÿé¨“ã«ã‚ˆã‚Šã€æ­£è¦åŒ–å±¤ã®å¿…è¦æ€§ã«å¯¾ã™ã‚‹æ–°ãŸãªæ´å¯Ÿã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãªã‚“â€¦ã ã¨â€¦ã€‚LayerNormalizationã‚’ä¸‹è¨˜ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ã‚ˆã†ãªtanhã‚’ç”¨ã„ãŸè¶…çµ¶ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼ˆparameterized thnh [Lecunæ°ãƒã‚¹ãƒˆ](



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ylecun/status/1900610590315249833?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q)ï¼‰ã«ç½®æ›ã™ã‚‹ã ã‘ã£ã½ã„ï¼Ÿ"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><img src="https://github.com/user-attachments/assets/474d3ee4-4c08-4b00-9a41-126ca5d5207e" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/5aea9f93-85d9-4e0b-b9db-bb407d596493" alt="image" loading="lazy"><br><br>åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¶­æŒã—ãªãŒã‚‰ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã®inference, trainingã®æ™‚é–“ã‚’8%ç¨‹åº¦å‰Šæ¸›ã€‚<br><img src="https://github.com/user-attachments/assets/98f8caa3-3ef2-4594-a45a-ae0aa2cf2ef6" alt="image" loading="lazy"></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<span class="issue_date">Issue Date: 2025-03-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1789" target="_blank" rel="noopener noreferrer" class="title-link">Gemini Embedding: Generalizable Embeddings from Gemini, Jinhyuk Lee+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Gemini Embeddingã¯ã€Googleã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«Geminiã‚’æ´»ç”¨ã—ãŸæœ€å…ˆç«¯ã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã§ã€å¤šè¨€èªãŠã‚ˆã³ã‚³ãƒ¼ãƒ‰ç†è§£èƒ½åŠ›ã‚’æ´»ã‹ã—ã¦ä¸€èˆ¬åŒ–å¯èƒ½ãªåŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚äº‹å‰è¨ˆç®—ã•ã‚ŒãŸè¡¨ç¾ã¯ã€åˆ†é¡ã‚„æ¤œç´¢ãªã©ã®ä¸‹æµã‚¿ã‚¹ã‚¯ã«é©ç”¨å¯èƒ½ã§ã€250ä»¥ä¸Šã®è¨€èªã«ã‚ãŸã‚‹100ä»¥ä¸Šã®ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€MMTEBã§è©•ä¾¡ã—ãŸçµæœã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1899667900728037621?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä¸–ã®decoder-onlyãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®embeddingãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ã«ä½œã‚‰ã‚Œã¦ã„ã‚‹ã‹å…·ä½“çš„ã«ã‚ˆãã‚ã‹ã£ã¦ã„ãªã„ã®ã§èª­ã¿ãŸã„</p>
<p>Geminiã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§bi-directionalãªself-attentionã‚’æŒã¤transformer (ãŸã¨ãˆã°BERT)ã§åˆæœŸåŒ–ã—ã€å…¨ã¦ã®tokenã‚’mean poling (HF BERT Modelã®PoolerLayerã®ã‚ˆã†ãªã‚‚ã®)ã™ã‚‹ã“ã¨ã§ãƒˆãƒ¼ã‚¯ãƒ³ã®æƒ…å ±ã‚’å˜ä¸€ã®embeddingã«æ··ãœã‚‹ã€‚<br>å­¦ç¿’ã¯2æ®µéšã®finetuning (pre-finetuning, finetuning)ã«ã‚ˆã£ã¦ã€ãƒ¢ãƒ‡ãƒ«ã‚’Contrastive Learningã™ã‚‹ï¼ˆNCE lossï¼‰ã€‚<br>pre-finetuningã¯noisyã ãŒå¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ï¼ˆwebä¸Šã®ã‚¿ã‚¤ãƒˆãƒ«ã¨paragraphã®ãƒšã‚¢ãªã©ï¼‰ã€ãã®ã‚ã¨ã®finetuningã¯QAãªã©ã®é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã€‚</p></span><br><br>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<span class="issue_date">Issue Date: 2025-03-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1787" target="_blank" rel="noopener noreferrer" class="title-link">START: Self-taught Reasoner with Tools, Chengpeng Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„ãƒ„ãƒ¼ãƒ«çµ±åˆå‹ã®é•·Chain-of-thoughtæ¨è«–ãƒ¢ãƒ‡ãƒ«STARTã‚’ææ¡ˆã€‚STARTã¯å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã‚’æ´»ç”¨ã—ã€è‡ªå·±å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é€šã˜ã¦æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã€‚Hint-inferã¨Hint Rejection Sampling Fine-Tuningã‚’ç”¨ã„ã¦LRMã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€ç§‘å­¦QAã‚„æ•°å­¦ã€ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é«˜ç²¾åº¦ã‚’é”æˆã€‚ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>è«–æ–‡ã®æœ¬é¡Œã¨ã¯é–¢ä¿‚ãªã„ãŒã€QwQ-32Bã‚ˆã‚Šã‚‚ã€DeepSeek-R1-Distilled-Qwen32Bã®æ–¹ãŒæ€§èƒ½ãŒè‰¯ã„ã®ã¯èˆˆå‘³æ·±ã„ã€‚ã‚„ã¯ã‚Šå¤§ãã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰è’¸ç•™ã—ãŸãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒã€å°ã•ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«è¿½åŠ å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚æ€§èƒ½ãŒé«˜ã„å‚¾å‘ã«ã‚ã‚‹ã®ã ã‚ã†ã‹ï¼ˆã©ã†ã„ã†ãƒ‡ãƒ¼ã‚¿ã§è’¸ç•™ã—ãŸã‹ã«ã‚‚ã‚ˆã‚‹ã‘ã©ï¼‰ã€‚<br><img src="https://github.com/user-attachments/assets/53e77e67-2c46-4163-859b-ccb0a7cd631d" alt="image" loading="lazy"></p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=m80LCW765n" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=m80LCW765n</a>


</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1782" target="_blank" rel="noopener noreferrer" class="title-link">LLM Post-Training: A Deep Dive into Reasoning Large Language Models, Komal Kumar+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã«ç„¦ç‚¹ã‚’å½“ã¦ã€çŸ¥è­˜ã®æ´—ç·´ã‚„æ¨è«–ã®æ”¹å–„ã€äº‹å®Ÿã®æ­£ç¢ºæ€§å‘ä¸Šã‚’ç›®æŒ‡ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„å¼·åŒ–å­¦ç¿’ãªã©ã®æˆ¦ç•¥ãŒLLMsã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æœ€é©åŒ–ã—ã€å®Ÿä¸–ç•Œã®ã‚¿ã‚¹ã‚¯ã¸ã®é©å¿œæ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ä¸»è¦ãªèª²é¡Œã¨ã—ã¦å£Šæ»…çš„ãªå¿˜å´ã‚„å ±é…¬ãƒãƒƒã‚­ãƒ³ã‚°ã‚’åˆ†æã—ã€ä»Šå¾Œã®ç ”ç©¶æ–¹å‘æ€§ã‚’ç¤ºã™å…¬é–‹ãƒªãƒã‚¸ãƒˆãƒªã‚‚æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>éå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„ã€‚<br><img src="https://github.com/user-attachments/assets/855326f0-bc18-4ce1-9870-7690393af21e" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1896399195596263710?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-03-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1776" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Diffusion Models, Shen Nie+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLaDAã¯ã€è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«ï¼ˆARMsï¼‰ã«ä»£ã‚ã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ã‚¼ãƒ­ã‹ã‚‰è¨“ç·´ã•ã‚Œã€ãƒ‡ãƒ¼ã‚¿ãƒã‚¹ã‚­ãƒ³ã‚°ã‚’é€šã˜ã¦åˆ†å¸ƒã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã€‚åºƒç¯„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¼·åŠ›ãªã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’ç¤ºã—ã€è‡ªå·±æ§‹ç¯‰ã—ãŸARMãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹ã€‚ç‰¹ã«ã€LLaDA 8Bã¯æ–‡è„ˆå†…å­¦ç¿’ã‚„æŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ã«å„ªã‚Œã€é€†è©©ã®å®Œæˆã‚¿ã‚¹ã‚¯ã§GPT-4oã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’ç™ºæ®ã€‚æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ãŒARMsã®å®Ÿè¡Œå¯èƒ½ãªä»£æ›¿æ‰‹æ®µã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1893698288328602022?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/karpathy/status/1894923254864978091"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-03-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1775" target="_blank" rel="noopener noreferrer" class="title-link">Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse   Attention, Jingyang Yuan+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- é•·æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®ãŸã‚ã«ã€è¨ˆç®—åŠ¹ç‡ã‚’æ”¹å–„ã™ã‚‹ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã€ŒNSAã€ã‚’ææ¡ˆã€‚NSAã¯å‹•çš„ãªéšå±¤ã‚¹ãƒ‘ãƒ¼ã‚¹æˆ¦ç•¥ã‚’ç”¨ã„ã€ãƒˆãƒ¼ã‚¯ãƒ³åœ§ç¸®ã¨é¸æŠã‚’çµ„ã¿åˆã‚ã›ã¦ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆèªè­˜ã¨ãƒ­ãƒ¼ã‚«ãƒ«ãªç²¾åº¦ã‚’ä¸¡ç«‹ã€‚å®Ÿè£…æœ€é©åŒ–ã«ã‚ˆã‚Šã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å®Ÿç¾ã—ã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ã§è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã€‚NSAã¯ãƒ•ãƒ«ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¶­æŒã—ã¤ã¤ã€é•·ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¯¾ã—ã¦å¤§å¹…ãªã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1893698286545969311?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ACL'25ã®Best Paperã®ä¸€ã¤:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1950644063952052643?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-02-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1774" target="_blank" rel="noopener noreferrer" class="title-link">From System 1 to System 2: A Survey of Reasoning Large Language Models, Zhong-Zhi Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“ãƒ¬ãƒ™ãƒ«ã®çŸ¥èƒ½ã‚’é”æˆã™ã‚‹ãŸã‚ã«ã¯ã€è¿…é€Ÿãªã‚·ã‚¹ãƒ†ãƒ 1ã‹ã‚‰æ„å›³çš„ãªã‚·ã‚¹ãƒ†ãƒ 2ã¸ã®æ¨è«–ã®æ´—ç·´ãŒå¿…è¦ã€‚åŸºç›¤ã¨ãªã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯è¿…é€Ÿãªæ„æ€æ±ºå®šã«å„ªã‚Œã‚‹ãŒã€è¤‡é›‘ãªæ¨è«–ã«ã¯æ·±ã•ãŒæ¬ ã‘ã‚‹ã€‚æœ€è¿‘ã®æ¨è«–LLMã¯ã‚·ã‚¹ãƒ†ãƒ 2ã®æ„å›³çš„ãªæ¨è«–ã‚’æ¨¡å€£ã—ã€äººé–“ã®ã‚ˆã†ãªèªçŸ¥èƒ½åŠ›ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚æœ¬èª¿æŸ»ã§ã¯ã€LLMã®é€²å±•ã¨ã‚·ã‚¹ãƒ†ãƒ 2æŠ€è¡“ã®åˆæœŸé–‹ç™ºã‚’æ¦‚è¦³ã—ã€æ¨è«–LLMã®æ§‹ç¯‰æ–¹æ³•ã‚„ç‰¹å¾´ã€é€²åŒ–ã‚’åˆ†æã€‚æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ¦‚è¦ã‚’æä¾›ã—ã€ä»£è¡¨çš„ãªæ¨è«–LLMã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¯”è¼ƒã€‚æœ€å¾Œã«ã€æ¨è«–LLMã®é€²å±•ã«å‘ã‘ãŸæ–¹å‘æ€§ã‚’æ¢ã‚Šã€æœ€æ–°ã®é–‹ç™ºã‚’è¿½è·¡ã™ã‚‹ãŸã‚ã®GitHubãƒªãƒã‚¸ãƒˆãƒªã‚’ç¶­æŒã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1894282083956396544?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<span class="issue_date">Issue Date: 2025-02-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1772" target="_blank" rel="noopener noreferrer" class="title-link">SuperGPQA: Scaling LLM Evaluation across 285 Graduate Disciplines, M-A-P Team+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- SuperGPQAã‚’ææ¡ˆã—ã€285ã®å°‚é–€åˆ†é‡ã«ãŠã‘ã‚‹LLMsã®çŸ¥è­˜ã¨æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã€‚Human-LLMå”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ç”¨ã„ã¦ã€ãƒˆãƒªãƒ“ã‚¢ãƒ«ãªè³ªå•ã‚’æ’é™¤ã€‚å®Ÿé¨“çµæœã¯ã€æœ€å…ˆç«¯ã®LLMsã«æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€äººå·¥ä¸€èˆ¬çŸ¥èƒ½ã¨ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’å¼·èª¿ã€‚å¤§è¦æ¨¡ãªã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰å¾—ãŸæ´å¯Ÿã¯ã€ä»Šå¾Œã®ç ”ç©¶ã«å¯¾ã™ã‚‹æ–¹æ³•è«–çš„ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1892779892674351532?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2025-02-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1770" target="_blank" rel="noopener noreferrer" class="title-link">OctoTools: An Agentic Framework with Extensible Tools for Complex   Reasoning, Pan Lu+, NAACL'25</a>
<span class="snippet"><span>GPT Summary</span>- è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã™ã‚‹ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒOctoToolsã€ã‚’ææ¡ˆã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸è¦ã§æ‹¡å¼µå¯èƒ½ãªã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«ã‚«ãƒ¼ãƒ‰ã‚„ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã€ã‚¨ã‚°ã‚¼ã‚­ãƒ¥ãƒ¼ã‚¿ãƒ¼ã‚’å‚™ãˆã€16ã®å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã§GPT-4oã«å¯¾ã—ã¦å¹³å‡9.3%ã®ç²¾åº¦å‘ä¸Šã‚’é”æˆã€‚ã•ã‚‰ã«ã€ä»–ã®æ‰‹æ³•ã‚’æœ€å¤§10.6%ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lupantech/status/1892260474320015861?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>NAACL'25ã§ãƒ™ã‚¹ãƒˆãƒšãƒ¼ãƒ‘ãƒ¼ã«é¸å‡º:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lupantech/status/1919495362102100365?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<span class="issue_date">Issue Date: 2025-02-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1768" target="_blank" rel="noopener noreferrer" class="title-link">NaturalReasoning: Reasoning in the Wild with 2.8M Challenging Questions, Weizhe Yuan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤šæ§˜ã§é«˜å“è³ªãªæ¨è«–è³ªå•ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€280ä¸‡ã®è³ªå•ã‹ã‚‰ãªã‚‹NaturalReasoningãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã€‚çŸ¥è­˜è’¸ç•™å®Ÿé¨“ã«ã‚ˆã‚Šã€å¼·åŠ›ãªæ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒæ¨è«–èƒ½åŠ›ã‚’å¼•ãå‡ºã›ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã—ã€æ•™å¸«ãªã—è‡ªå·±å­¦ç¿’ã«ã‚‚åŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1892041992127021300?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2025-02-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1767" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Test-Time Compute Without Verification or RL is Suboptimal, Amrith Setlur+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- RLã‚„æ¢ç´¢ã«åŸºã¥ãæ¤œè¨¼è€…ãƒ™ãƒ¼ã‚¹ï¼ˆVBï¼‰æ‰‹æ³•ãŒã€æ¢ç´¢ã®ç—•è·¡ã‚’è’¸ç•™ã™ã‚‹æ¤œè¨¼è€…ãƒ•ãƒªãƒ¼ï¼ˆVFï¼‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ†ã‚¹ãƒˆæ™‚ã®è¨ˆç®—ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ã¨ã€VFæ‰‹æ³•ã®æœ€é©æ€§ãŒæ‚ªåŒ–ã—ã€VBæ‰‹æ³•ãŒã‚ˆã‚Šè‰¯ãã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚3/8/32Bã‚µã‚¤ã‚ºã®LLMã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã€æ¤œè¨¼ãŒè¨ˆç®—èƒ½åŠ›ã®å‘ä¸Šã«é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1891839822257586310?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1749" target="_blank" rel="noopener noreferrer">s1: Simple test-time scaling, Niklas Muennighoff+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-02-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1763" target="_blank" rel="noopener noreferrer" class="title-link">LLM Pretraining with Continuous Concepts, Jihoon Tack+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã«ä»£ã‚ã‚‹æ–°ã—ã„äº‹å‰å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯CoCoMixã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‹ã‚‰å­¦ç¿’ã—ãŸé€£ç¶šçš„ãªæ¦‚å¿µã‚’ãƒˆãƒ¼ã‚¯ãƒ³ã®éš ã‚Œè¡¨ç¾ã¨äº¤äº’ã«æ··ãœã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€CoCoMixã¯å¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã€è§£é‡ˆå¯èƒ½æ€§ã¨æ“ä½œæ€§ã‚‚å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1760" target="_blank" rel="noopener noreferrer" class="title-link">Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time  Scaling, Runze Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Test-Time Scaling (TTS)ã¯ã€LLMsã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹æ‰‹æ³•ã§ã‚ã‚Šã€ãƒãƒªã‚·ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚„PRMã€å•é¡Œã®é›£æ˜“åº¦ãŒTTSã«ä¸ãˆã‚‹å½±éŸ¿ã‚’åˆ†æã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æœ€é©ãªTTSæˆ¦ç•¥ã¯ã“ã‚Œã‚‰ã®è¦ç´ ã«ä¾å­˜ã—ã€å°å‹ãƒ¢ãƒ‡ãƒ«ãŒå¤§å‹ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€1Bã®LLMãŒ405Bã®LLMã‚’è¶…ãˆã‚‹çµæœã‚’å¾—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€TTSãŒLLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æœ‰æœ›ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1758" target="_blank" rel="noopener noreferrer" class="title-link">DeepRAG: Thinking to Retrieval Step by Step for Large Language Models, Xinyan Guan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- DeepRAGãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€æ¤œç´¢å¼·åŒ–æ¨è«–ã‚’ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åŒ–ã€‚ã‚¯ã‚¨ãƒªã‚’åå¾©çš„ã«åˆ†è§£ã—ã€å¤–éƒ¨çŸ¥è­˜ã®å–å¾—ã¨ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯æ¨è«–ã®ä¾å­˜ã‚’å‹•çš„ã«åˆ¤æ–­ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æ¤œç´¢åŠ¹ç‡ã¨å›ç­”ã®æ­£ç¢ºæ€§ã‚’21.99%å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬ã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼<br><br>RAGã§ã‚‚ã€Œæ·±ã„æ¤œç´¢ã€ã‚’å®Ÿç¾ã™ã‚‹æ‰‹æ³•ã€ŒDeepRAGã€, Atsushi Kadowaki, <br>ãƒŠãƒ¬ãƒƒã‚¸ã‚»ãƒ³ã‚¹ - AIçŸ¥è¦‹å…±æœ‰ãƒ–ãƒ­ã‚°:


<a href="https://zenn.dev/knowledgesense/articles/034b613c9fd6d3" target="_blank" rel="noopener noreferrer">https://zenn.dev/knowledgesense/articles/034b613c9fd6d3</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/CodeGeneration.html" target="_blank" rel="noopener noreferrer">#CodeGeneration</a>
<a class="button" href="articles/SyntheticDataGeneration.html" target="_blank" rel="noopener noreferrer">#SyntheticDataGeneration</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1756" target="_blank" rel="noopener noreferrer" class="title-link">ACECODER: Acing Coder RL via Automated Test-Case Synthesis, Huaye Zeng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚³ãƒ¼ãƒ‰ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã®å¯èƒ½æ€§ã‚’æ¢æ±‚ã—ã€è‡ªå‹•åŒ–ã•ã‚ŒãŸå¤§è¦æ¨¡ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹åˆæˆã‚’æ´»ç”¨ã—ã¦ä¿¡é ¼ã§ãã‚‹å ±é…¬ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è³ªå•ã¨ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®ãƒšã‚¢ã‚’ç”Ÿæˆã—ã€ã“ã‚Œã‚’ç”¨ã„ã¦å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚Šã€Llama-3.1-8B-Insã§å¹³å‡10ãƒã‚¤ãƒ³ãƒˆã€Qwen2.5-Coder-7B-Insã§5ãƒã‚¤ãƒ³ãƒˆã®æ€§èƒ½å‘ä¸ŠãŒè¦‹ã‚‰ã‚Œã€7Bãƒ¢ãƒ‡ãƒ«ãŒ236B DeepSeek-V2.5ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã—ã¾ã—ãŸã€‚ã¾ãŸã€å¼·åŒ–å­¦ç¿’ã‚’é€šã˜ã¦HumanEvalã‚„MBPPãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ä¸€è²«ã—ãŸæ”¹å–„ã‚’ç¤ºã—ã€ç‰¹ã«Qwen2.5-Coder-baseã‹ã‚‰ã®RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒHumanEval-plusã§25%ä»¥ä¸Šã€MBPP-plusã§6%ã®æ”¹å–„ã‚’ã‚‚ãŸã‚‰ã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹å¼·åŒ–å­¦ç¿’ã®å¤§ããªå¯èƒ½æ€§ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<span class="issue_date">Issue Date: 2025-02-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1753" target="_blank" rel="noopener noreferrer" class="title-link">Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth  Approach, Jonas Geiping+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„è¨€èªãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ææ¡ˆã—ã€æ½œåœ¨ç©ºé–“ã§ã®æš—é»™çš„æ¨è«–ã«ã‚ˆã‚Šãƒ†ã‚¹ãƒˆæ™‚ã®è¨ˆç®—ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ã€‚å†å¸°ãƒ–ãƒ­ãƒƒã‚¯ã‚’åå¾©ã—ã€ä»»æ„ã®æ·±ã•ã«å±•é–‹ã™ã‚‹ã“ã¨ã§ã€å¾“æ¥ã®ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¨ã¯ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã€‚ç‰¹åˆ¥ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’å¿…è¦ã¨ã›ãšã€å°ã•ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§è¤‡é›‘ãªæ¨è«–ã‚’æ‰ãˆã‚‹ã€‚3.5å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã—ã€æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åŠ‡çš„ã«æ”¹å–„ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="articles/TeacherHacking.html" target="_blank" rel="noopener noreferrer">#TeacherHacking</a>
<span class="issue_date">Issue Date: 2025-02-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1751" target="_blank" rel="noopener noreferrer" class="title-link">On Teacher Hacking in Language Model Distillation, Daniil Tiapkin+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜è’¸ç•™éç¨‹ã«ãŠã‘ã‚‹ã€Œæ•™å¸«ãƒãƒƒã‚­ãƒ³ã‚°ã€ã®ç¾è±¡ã‚’èª¿æŸ»ã€‚å›ºå®šã•ã‚ŒãŸã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã‚‹ã¨æ•™å¸«ãƒãƒƒã‚­ãƒ³ã‚°ãŒç™ºç”Ÿã—ã€æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã®é€¸è„±ã‚’æ¤œå‡ºå¯èƒ½ã€‚ä¸€æ–¹ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ç”ŸæˆæŠ€è¡“ã‚’ç”¨ã„ã‚‹ã“ã¨ã§æ•™å¸«ãƒãƒƒã‚­ãƒ³ã‚°ã‚’è»½æ¸›ã§ãã€ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ãŒé‡è¦ãªè¦å› ã§ã‚ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å …ç‰¢ãªè¨€èªãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã«ãŠã‘ã‚‹è’¸ç•™ã®åˆ©ç‚¹ã¨é™ç•Œã«ã¤ã„ã¦ã®ç†è§£ãŒæ·±ã¾ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1888516494100734224?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‡ªåˆ†ã§è’¸ç•™ã™ã‚‹æ©Ÿä¼šã¯ä»Šã®ã¨ã“ã‚ãªã„ãŒã€è¦šãˆã¦ãŠããŸã„ã€‚éå­¦ç¿’ã¨ä¸€ç·’ã§ã€ã“ã†ã„ã†ç¾è±¡ãŒèµ·ã“ã‚‹ã®ã¯æƒ³åƒã§ãã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-02-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1750" target="_blank" rel="noopener noreferrer" class="title-link">Rethinking Mixture-of-Agents: Is Mixing Different Large Language Models  Beneficial?, Wenzhe Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Self-MoAã¯ã€å˜ä¸€ã®é«˜æ€§èƒ½LLMã‹ã‚‰ã®å‡ºåŠ›ã‚’é›†ç´„ã™ã‚‹ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ã§ã‚ã‚Šã€å¾“æ¥ã®MoAã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚AlpacaEval 2.0ã§6.6%ã®æ”¹å–„ã‚’é”æˆã—ã€MMLUã‚„CRUXãªã©ã§ã‚‚å¹³å‡3.8%ã®å‘ä¸Šã‚’è¨˜éŒ²ã€‚å‡ºåŠ›ã®å¤šæ§˜æ€§ã¨å“è³ªã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’èª¿æŸ»ã—ã€ç•°ãªã‚‹LLMã®æ··åˆãŒå“è³ªã‚’ä½ä¸‹ã•ã›ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚Self-MoAã®é€æ¬¡ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚‚åŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1888658770059816968?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-02-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1749" target="_blank" rel="noopener noreferrer" class="title-link">s1: Simple test-time scaling, Niklas Muennighoff+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚¹ãƒˆæ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ç”¨ã„ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆs1Kã‚’ä½œæˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’åˆ¶å¾¡ã™ã‚‹äºˆç®—å¼·åˆ¶ã‚’å°å…¥ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯ä¸æ­£ç¢ºãªæ¨è«–ã‚’ä¿®æ­£ã—ã€Qwen2.5-32B-Instructãƒ¢ãƒ‡ãƒ«ãŒo1-previewã‚’æœ€å¤§27%ä¸Šå›ã‚‹çµæœã‚’é”æˆã€‚ã•ã‚‰ã«ã€ä»‹å…¥ãªã—ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒå¯èƒ½ã¨ãªã£ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ã€ã‚³ãƒ¼ãƒ‰ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1887260791981941121?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/DataDistillation.html" target="_blank" rel="noopener noreferrer">#DataDistillation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-02-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1748" target="_blank" rel="noopener noreferrer" class="title-link">LIMO: Less is More for Reasoning, Yixin Ye+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LIMOãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚ãšã‹817ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ³ãƒ—ãƒ«ã§è¤‡é›‘ãªæ•°å­¦çš„æ¨è«–ã‚’åŠ¹æœçš„ã«å¼•ãå‡ºã—ã€AIMEã§57.1%ã€MATHã§94.8%ã®ç²¾åº¦ã‚’é”æˆã€‚å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ä¸€èˆ¬åŒ–ã‚’ä¿ƒã™ã€ŒLess-Is-More Reasoning Hypothesisã€ã‚’ææ¡ˆã€‚LIMOã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æä¾›ã•ã‚Œã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã®è‰¯ã„æ¨è«–ã®å†ç¾æ€§ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1887353699644940456?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-02-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer" class="title-link">Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã‘ã‚‹é•·ã„æ€è€ƒã®é€£é–ï¼ˆCoTsï¼‰æ¨è«–ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’èª¿æŸ»ã—ã€é‡è¦ãªè¦å› ã‚’ç‰¹å®šã€‚ä¸»ãªç™ºè¦‹ã¯ã€(1) æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã¯å¿…é ˆã§ã¯ãªã„ãŒåŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã€(2) æ¨è«–èƒ½åŠ›ã¯è¨ˆç®—ã®å¢—åŠ ã«ä¼´ã„ç¾ã‚Œã‚‹ãŒã€å ±é…¬ã®å½¢çŠ¶ãŒCoTã®é•·ã•ã«å½±éŸ¿ã€(3) æ¤œè¨¼å¯èƒ½ãªå ±é…¬ä¿¡å·ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒé‡è¦ã§ã€ç‰¹ã«åˆ†å¸ƒå¤–ã‚¿ã‚¹ã‚¯ã«åŠ¹æœçš„ã€(4) ã‚¨ãƒ©ãƒ¼ä¿®æ­£èƒ½åŠ›ã¯åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã«å­˜åœ¨ã™ã‚‹ãŒã€RLã‚’é€šã˜ã¦åŠ¹æœçš„ã«å¥¨åŠ±ã™ã‚‹ã«ã¯å¤šãã®è¨ˆç®—ãŒå¿…è¦ã€‚ã“ã‚Œã‚‰ã®æ´å¯Ÿã¯ã€LLMsã®é•·ã„CoTæ¨è«–ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã®æœ€é©åŒ–ã«å½¹ç«‹ã¤ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xiangyue96/status/1887332772198371514?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ƒãƒã‚¹ãƒˆã®ã‚¹ãƒ¬ãƒƒãƒ‰ä¸­ã«è«–æ–‡ã®11å€‹ã®çŸ¥è¦‹ãŒè¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ã©ã‚Œã‚‚éå¸¸ã«èˆˆå‘³æ·±ã„ã€‚DeepSeek-R1ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼ã¨åŒæ§˜ã€<br><br>- Long CoTã¨Short CoTã‚’æ¯”è¼ƒã™ã‚‹ã¨å‰è€…ã®æ–¹ãŒåˆ°é”å¯èƒ½ãªæ€§èƒ½ã®upper bonudãŒé«˜ã„ã“ã¨ã‚„ã€<br>- SFTã‚’å®Ÿæ–½ã—ã¦ã‹ã‚‰RLã‚’ã™ã‚‹ã¨æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚„ã€<br>- RLã®éš›ã«CoTã®Lengthã«é–¢ã™ã‚‹å ±é…¬ã‚’å…¥ã‚Œã‚‹ã“ã¨ã§CoTã®é•·ã•ã‚’æŠ‘ãˆã¤ã¤æ€§èƒ½å‘ä¸Šã§ãã‚‹ã“ã¨ã€<br>- æ•°å­¦ã ã‘ã§ãªãQAãƒšã‚¢ãªã©ã®ãƒã‚¤ã‚¸ãƒ¼ã ãŒæ¤œè¨¼å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚’Verifiableãªå ±é…¬ã¨ã—ã¦åŠ ãˆã‚‹ã¨ä¸€èˆ¬çš„ãªreasoningã‚¿ã‚¹ã‚¯ã§æ•°å­¦ã‚ˆã‚Šã‚‚ã•ã‚‰ã«æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã€<br>- ã‚ˆã‚Šé•·ã„context window sizeã‚’æ´»ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«ã¯ã‚ˆã‚Šå¤šãã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ãªã“ã¨ã€<br>- long CoTã¯RLã«ã‚ˆã£ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«é¡ä¼¼ã—ãŸãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ®µéšã§ãã®èƒ½åŠ›ãŒç²å¾—ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã“ã¨ã€<br>- aha momentã¯ã™ã§ã«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«æ™‚ç‚¹ã§ç²å¾—ã•ã‚Œã¦ãŠã‚ŠVerifiableãªå ±é…¬ã«ã‚ˆã‚‹RLã«ã‚ˆã£ã¦å¼·åŒ–ã•ã‚ŒãŸã‚ã‘ã§ã¯ãªã•ãã†ã€<br><br>ãªã©ã€èˆˆå‘³æ·±ã„çŸ¥è¦‹ãŒç››ã‚Šã ãã•ã‚“ã€‚éå¸¸ã«èˆˆå‘³æ·±ã„ç ”ç©¶ã€‚ã‚ã¨ã§èª­ã‚€ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<span class="issue_date">Issue Date: 2025-02-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1744" target="_blank" rel="noopener noreferrer" class="title-link">Diverse Preference Optimization, Jack Lanchantin+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- Diverse Preference Optimizationï¼ˆDivPOï¼‰ã‚’ææ¡ˆã—ã€å¿œç­”ã®å¤šæ§˜æ€§ã‚’å‘ä¸Šã•ã›ã¤ã¤ç”Ÿæˆç‰©ã®å“è³ªã‚’ç¶­æŒã™ã‚‹ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æœ€é©åŒ–æ‰‹æ³•ã‚’ç´¹ä»‹ã€‚DivPOã¯å¿œç­”ã®ãƒ—ãƒ¼ãƒ«ã‹ã‚‰å¤šæ§˜æ€§ã‚’æ¸¬å®šã—ã€å¸Œå°‘ã§é«˜å“è³ªãªä¾‹ã‚’é¸æŠã™ã‚‹ã“ã¨ã§ã€ãƒ‘ãƒ¼ã‚½ãƒŠå±æ€§ã®å¤šæ§˜æ€§ã‚’45.6%ã€ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®å¤šæ§˜æ€§ã‚’74.6%å‘ä¸Šã•ã›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1885399530419450257?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview: 


<a href="https://openreview.net/forum?id=pOq9vDIYev" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=pOq9vDIYev</a>


</p>
<p>DPOã¨åŒã˜æœ€é©åŒ–æ–¹æ³•ã‚’ä½¿ã†ãŒã€Preference Pairã‚’é¸æŠã™ã‚‹éš›ã«ã€å¤šæ§˜æ€§ãŒå¢—åŠ ã™ã‚‹ã‚ˆã†ãªPreference Pairã®é¸æŠã‚’ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®Post-trainingå¾Œã®å¤šæ§˜æ€§ã‚’æãªã‚ãªã„ã‚ˆã†ã«ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã£ã½ã„ã€‚<br>å…·ä½“çš„ã«ã¯ã€Alg.1 ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€å¤šæ§˜æ€§ã®å°ºåº¦Dã‚’å®šç¾©ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã«Nå€‹ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆã•ã›RMã«ã‚ˆã‚Šã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ãŸå¾Œã€RMã®ã‚¹ã‚³ã‚¢ãŒé–¾å€¤ä»¥ä¸Šã®responseã‚’"chosen" response, é–¾å€¤æœªæº€ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ "reject" responseã¨ã¿ãªã—ã€chosen/reject responseé›†åˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚chosen responseé›†åˆã®ä¸­ã‹ã‚‰Dã«åŸºã¥ã„ã¦æœ€ã‚‚å¤šæ§˜æ€§ã®ã‚ã‚‹response y_cã€reject responseé›†åˆã®ä¸­ã‹ã‚‰æœ€ã‚‚å¤šæ§˜æ€§ã®ãªã„response y_r ã‚’ãã‚Œãã‚Œãƒ”ãƒƒã‚¯ã—ã€prompt xã¨ã¨ã‚‚ã«preference pair (x, y_c, y_r) ã‚’æ§‹ç¯‰ã—Preference Pairã«åŠ ãˆã‚‹ã€ã¨ã„ã£ãŸæ“ä½œã‚’å…¨ã¦ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆä¸­ã®promptï¼‰xã«å¯¾ã—ã¦ç¹°ã‚Šè¿”ã™ã“ã¨ã§å®Ÿç¾ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-01-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1740" target="_blank" rel="noopener noreferrer" class="title-link">SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model   Post-training, Tianzhe Chu+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- SFTã¨RLã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã®é•ã„ã‚’ç ”ç©¶ã—ã€GeneralPointsã¨V-IRLã‚’ç”¨ã„ã¦è©•ä¾¡ã€‚RLã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã¨è¦–è¦šå¤‰ç¨®ã«å¯¾ã—ã¦å„ªã‚ŒãŸä¸€èˆ¬åŒ–ã‚’ç¤ºã™ä¸€æ–¹ã€SFTã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜æ†¶ã—åˆ†å¸ƒå¤–ã‚·ãƒŠãƒªã‚ªã«è‹¦åŠ´ã€‚RLã¯è¦–è¦šèªè­˜èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€SFTã¯RLè¨“ç·´ã«ä¸å¯æ¬ ã§ã‚ã‚Šã€å‡ºåŠ›å½¢å¼ã‚’å®‰å®šã•ã›ã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Šã‚’ä¿ƒé€²ã€‚ã“ã‚Œã‚‰ã®çµæœã¯ã€è¤‡é›‘ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹RLã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1884731381517082668?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>openreview:


<a href="https://openreview.net/forum?id=dYur3yabMj&referrer=%5Bthe%20profile%20of%20Yi%20Ma%5D(%2Fprofile%3Fid%3D~Yi_Ma4)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=dYur3yabMj&referrer=%5Bthe%20profile%20of%20Yi%20Ma%5D(%2Fprofile%3Fid%3D~Yi_Ma4)</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2025-01-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1738" target="_blank" rel="noopener noreferrer" class="title-link">Evolving Deeper LLM Thinking, Kuang-Huei Lee+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Mind Evolutionã¨ã„ã†é€²åŒ–çš„æ¢ç´¢æˆ¦ç•¥ã‚’ææ¡ˆã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦å€™è£œå¿œç­”ã‚’ç”Ÿæˆãƒ»æ´—ç·´ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ¨è«–å•é¡Œã®å½¢å¼åŒ–ã‚’å›é¿ã—ã¤ã¤ã€æ¨è«–ã‚³ã‚¹ãƒˆã‚’åˆ¶å¾¡ã€‚è‡ªç„¶è¨€èªè¨ˆç”»ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ä»–ã®æˆ¦ç•¥ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€TravelPlannerãŠã‚ˆã³Natural Planã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§98%ä»¥ä¸Šã®å•é¡Œã‚’è§£æ±ºã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview: 


<a href="https://openreview.net/forum?id=nGP1UxhAbV&referrer=%5Bthe%20profile%20of%20Kuang-Huei%20Lee%5D(%2Fprofile%3Fid%3D~Kuang-Huei_Lee1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=nGP1UxhAbV&referrer=%5Bthe%20profile%20of%20Kuang-Huei%20Lee%5D(%2Fprofile%3Fid%3D~Kuang-Huei_Lee1)</a>


</p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/STS%20(SemanticTextualSimilarity).html" target="_blank" rel="noopener noreferrer">#STS (SemanticTextualSimilarity)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-01-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1734" target="_blank" rel="noopener noreferrer" class="title-link">SoftMatcha: A Fast and Soft Pattern Matcher for Billion-Scale Corpus Searches, Deguchi+, ICLR'25</a>
<span class="snippet"><span>Comment</span><p>ICLR2025ã«acceptã•ã‚ŒãŸæ¨¡æ§˜<br>


<a href="https://openreview.net/forum?id=Q6PAnqYVpo" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Q6PAnqYVpo</a>


</p>
<p>openreview:


<a href="https://openreview.net/forum?id=Q6PAnqYVpo" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Q6PAnqYVpo</a>


</p>
<p>


<a href="https://arxiv.org/abs/2503.03703" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2503.03703</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1730" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Humanity's Last Exam, Long Phan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã€Œäººé¡ã®æœ€å¾Œã®è©¦é¨“ï¼ˆHLEï¼‰ã€ã‚’å°å…¥ã—ã€LLMã®èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹æ–°ã—ã„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã€‚HLEã¯2,500ã®è³ªå•ã‹ã‚‰æˆã‚Šã€æ•°å­¦ã‚„è‡ªç„¶ç§‘å­¦ãªã©åºƒç¯„ãªç§‘ç›®ã‚’ã‚«ãƒãƒ¼ã€‚å°‚é–€å®¶ã«ã‚ˆã£ã¦é–‹ç™ºã•ã‚Œã€è‡ªå‹•æ¡ç‚¹ãŒå¯èƒ½ãªå½¢å¼ã§ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¤œç´¢ã§ã¯è¿…é€Ÿã«å›ç­”ã§ããªã„ã€‚æœ€å…ˆç«¯ã®LLMã¯HLEã«å¯¾ã—ã¦ä½ã„ç²¾åº¦ã‚’ç¤ºã—ã€ç¾åœ¨ã®LLMã®èƒ½åŠ›ã¨å°‚é–€å®¶ã®çŸ¥è­˜ã¨ã®é–“ã«å¤§ããªã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã€‚HLEã¯å…¬é–‹ã•ã‚Œã€ç ”ç©¶ã‚„æ”¿ç­–ç«‹æ¡ˆã«å½¹ç«‹ã¦ã‚‰ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>o1, DeepSeekR1ã®æ­£è§£ç‡ãŒ10%æœªæº€ã®æ–°ãŸãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1728" target="_blank" rel="noopener noreferrer" class="title-link">Perspective Transition of Large Language Models for Solving Subjective  Tasks, Xiaolong Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è¦–ç‚¹ã®ç§»è¡Œã‚’é€šã˜ãŸæ¨è«–ï¼ˆRPTï¼‰ã‚’ææ¡ˆã—ã€LLMsãŒä¸»è¦³çš„ãªå•é¡Œã«å¯¾ã—ã¦å‹•çš„ã«è¦–ç‚¹ã‚’é¸æŠã§ãã‚‹æ‰‹æ³•ã‚’ç´¹ä»‹ã€‚åºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€å¾“æ¥ã®å›ºå®šè¦–ç‚¹æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã€æ–‡è„ˆã«å¿œã˜ãŸé©åˆ‡ãªå¿œç­”ã‚’æä¾›ã™ã‚‹èƒ½åŠ›ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rohanpaul_ai/status/1882739526361370737?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview: 


<a href="https://openreview.net/forum?id=cFGPlRony5" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=cFGPlRony5</a>


</p>
<p>"Subjective Task"ã¨ã¯ä¾‹ãˆã°ã€Œãƒ¡ã‚¿ãƒ•ã‚¡ãƒ¼ã®èªè­˜ã€ã‚„ã€Œãƒ€ãƒ¼ã‚¯ãƒ¦ãƒ¼ãƒ¢ã‚¢ã®æ¤œçŸ¥ã€ãªã©ãŒã‚ã‚Šã€ã“ã‚Œã‚‰ã¯å®šé‡åŒ–ã—ã¥ã‚‰ã„èªçŸ¥çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚„ã€ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã‚„æ„Ÿæƒ…ãªã©ãŒå¼·ãé–¢é€£ã—ã¦ãŠã‚Šã€ç¾çŠ¶ã®LLMã§ã¯ãƒãƒ£ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã ã¨ä¸»å¼µã—ã¦ã„ã‚‹ã€‚<br>Subjective Taskã§ã¯ã€Reasoningãƒ¢ãƒ‡ãƒ«ã®ã‚ˆã†ã«è‡ªå‹•çš„ã«CoTã®pathwayã‚’æ±ºã‚ã‚‹ã®ã¯å›°é›£ã§ã€æ‰‹å‹•ã§pathwayã‚’è¨˜è¿°ã™ã‚‹ã®ã¯ãƒãƒ£ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã§ä¸€è²«æ€§ã‚’æ¬ ãã¨ã—ãŸä¸Šã§ã€è¤‡æ•°ã®è¦–ç‚¹ã‚’çµ„ã¿åˆã‚ã›ãŸPromptingï¼ˆdirect perspective, role-perspective, third-person perspectivfeï¼‰ã‚’å®Ÿæ–½ã—ã€æœ€ã‚‚Confidenceã®é«˜ã„answerã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ã§ã“ã®èª²é¡Œã«å¯¾å‡¦ã™ã‚‹ã¨ä¸»å¼µã—ã¦ã„ã‚‹ã€‚</p>
<p>ã‚¤ãƒ³ãƒˆãƒ­ã—ã‹èª­ã‚ã¦ã„ãªã„ãŒã€è‡ªå‹•çš„ã«CoTã®pathwayã‚’æ±ºã‚ã‚‹ã®ã‚‚æ‰‹å‹•ã§æ±ºã‚ã‚‹ã®ã‚‚é›£ã—ã„ã¨ã„ã†é¢¨ã«ã‚¤ãƒ³ãƒˆãƒ­ã§è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ãŒã€æ‰‹æ³•è‡ªä½“ãŒæœ€çµ‚çš„ã«3ã¤ã®è¦–ç‚¹ã‹ã‚‰å›ç­”ã‚’ç”Ÿæˆã•ã›ã‚‹ã¨ã„ã†æ çµ„ã¿ã«å‰‡ã£ã¦ã„ã‚‹ï¼ˆã¤ã¾ã‚ŠSubjective Taskã‚’è§£ããŸã‚ã®å½¢å¼åŒ–ã§ãã¦ã„ã‚‹ã®ã§ã€è‡ªå‹•çš„ãªæ‰‹æ³•ã§ã‚‚ã§ãã¦ã—ã¾ã†ã®ã§ã¯ãªã„ã‹ï¼Ÿã¨æ„Ÿã˜ãŸï¼‰ã®ã§ã€ã‚¤ãƒ³ãƒˆãƒ­ã§è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ä¸»å¼µã®â€é›£ã—ã•â€ãŒè–„ã‚Œã¦ã—ã¾ã£ã¦ã„ã‚‹ã‹ã‚‚ãƒ»ãƒ»ãƒ»ï¼Ÿã¨æ„Ÿã˜ãŸã€‚è«–æ–‡ãŒè§£ã“ã†ã¨ã—ã¦ã„ã‚‹èª²é¡Œã®â€é›£ã—ã•â€ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ææ–™ãŒã‚‚ã£ã¨ã‚ã£ãŸæ–¹ãŒã‚ˆã‚ŠmotivationãŒåˆ†ã‹ã‚Šã‚„ã™ããªã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€ã¨ã„ã†æ„Ÿæƒ³ã‚’æŒã£ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<a class="button" href="articles/Workshop.html" target="_blank" rel="noopener noreferrer">#Workshop</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1634" target="_blank" rel="noopener noreferrer" class="title-link">Byte Latent Transformer: Patches Scale Better Than Tokens, Artidoro Pagnoni+, ICML'25 Workshop Tokshop</a>
<span class="snippet"><span>GPT Summary</span>- Byte Latent Transformerï¼ˆBLTï¼‰ã¯ã€ãƒã‚¤ãƒˆãƒ¬ãƒ™ãƒ«ã®LLMã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãƒ™ãƒ¼ã‚¹ã®LLMã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã€æ¨è«–åŠ¹ç‡ã¨å …ç‰¢æ€§ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã€‚BLTã¯ãƒã‚¤ãƒˆã‚’å‹•çš„ã«ã‚µã‚¤ã‚ºå¤‰æ›´å¯èƒ½ãªãƒ‘ãƒƒãƒã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€ãƒ‡ãƒ¼ã‚¿ã®è¤‡é›‘æ€§ã«å¿œã˜ã¦è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’èª¿æ•´ã™ã‚‹ã€‚æœ€å¤§8Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨4Tãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒã‚¤ãƒˆã®ãƒ¢ãƒ‡ãƒ«ã§ã®ç ”ç©¶ã«ã‚ˆã‚Šã€å›ºå®šèªå½™ãªã—ã§ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®å¯èƒ½æ€§ãŒç¤ºã•ã‚ŒãŸã€‚é•·ã„ãƒ‘ãƒƒãƒã®å‹•çš„é¸æŠã«ã‚ˆã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®åŠ¹ç‡ãŒå‘ä¸Šã—ã€å…¨ä½“çš„ã«BLTã¯ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>èˆˆå‘³æ·±ã„</p>
<p>å›³ã—ã‹è¦‹ã‚Œã¦ã„ãªã„ãŒã€ãƒã‚¤ãƒˆåˆ—ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰/ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹transformerå­¦ç¿’ã—ã¦è¤‡æ•°ã®ãƒã‚¤ãƒˆåˆ—ã‚’ãƒ‘ãƒƒãƒåŒ–ï¼ˆã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒå¤§ãã„éƒ¨åˆ†ã¯ã‚ˆã‚Šå¤§ããªãƒ‘ãƒƒãƒã«ãƒã‚¤ãƒˆåˆ—ã‚’ã²ã¨ã¾ã¨ã‚ã«ã™ã‚‹ï¼‰ã€ãƒ‘ãƒƒãƒã‹ã‚‰ã®ãƒã‚¤ãƒˆåˆ—ç”Ÿæˆã‚’å¯èƒ½ã«ã—ã€ãƒ‘ãƒƒãƒã‚’å¤‰æ›ã™ã‚‹ã®ã‚’Latent Transformerã§å­¦ç¿’ã•ã›ã‚‹ã‚ˆã†ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br>ã¾ãŸã€äºˆç®—ã«ã‚ˆã£ã¦ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒæ±ºã¾ã£ã¦ã—ã¾ã†ãŒã€ãƒ‘ãƒƒãƒã‚µã‚¤ã‚ºã‚’å¤§ããã™ã‚‹ã“ã¨ã§åŒã˜äºˆç®—ã§ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚‚å¤§ããã§ãã‚‹ã®ãŒBLTã®åˆ©ç‚¹ã¨ã®ã“ã¨ã€‚<br><img src="https://github.com/user-attachments/assets/4d150ea9-34e3-456a-bfda-123eb03ffd7c" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/5884d4ed-6c12-4691-8d13-4b3cccd74ef0" alt="image" loading="lazy"></p>
<p>æ—¥æœ¬èªè§£èª¬:


<a href="https://bilzard.github.io/blog/2025/01/01/byte-latent-transformer.html?v=2" target="_blank" rel="noopener noreferrer">https://bilzard.github.io/blog/2025/01/01/byte-latent-transformer.html?v=2</a>


</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=UZ3J8XeRLw" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=UZ3J8XeRLw</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-12-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1577" target="_blank" rel="noopener noreferrer" class="title-link">Towards Adaptive Mechanism Activation in Language Agent, Ziyang Huang+, COLING'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±æ¢ç´¢ã«ã‚ˆã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ æ´»æ€§åŒ–å­¦ç¿’ï¼ˆALAMAï¼‰ã‚’ææ¡ˆã—ã€å›ºå®šã•ã‚ŒãŸãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ä¾å­˜ã›ãšã«é©å¿œçš„ãªã‚¿ã‚¹ã‚¯è§£æ±ºã‚’ç›®æŒ‡ã™ã€‚èª¿å’Œã®ã¨ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼ˆUniActï¼‰ã‚’æ§‹ç¯‰ã—ã€ã‚¿ã‚¹ã‚¯ç‰¹æ€§ã«å¿œã˜ã¦ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’è‡ªå‹•æ´»æ€§åŒ–ã€‚å®Ÿé¨“çµæœã¯ã€å‹•çš„ã§æ–‡è„ˆã«æ•æ„Ÿãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ æ´»æ€§åŒ–ã®æœ‰åŠ¹æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1863956776623747433?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰‹æ³•ã¨ã—ã¦ã¯ã€SFTã¨KTOã‚’æ´»ç”¨ã—post trainingã™ã‚‹ã‚ˆã†ã§ã‚ã‚‹<br><img src="https://github.com/user-attachments/assets/0eab8029-124d-4ac1-b906-2463472b90b2" alt="image" loading="lazy"><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1472" target="_blank" rel="noopener noreferrer">KTO: Model Alignment as Prospect Theoretic Optimization, Kawin Ethayarajh+, N/A, ICML'24</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DataAugmentation.html" target="_blank" rel="noopener noreferrer">#DataAugmentation</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2024-12-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1565" target="_blank" rel="noopener noreferrer" class="title-link">Reverse Thinking Makes LLMs Stronger Reasoners, Justin Chih-Yao Chen+, NAACL'25</a>
<span class="snippet"><span>GPT Summary</span>- é€†æ€è€ƒã¯æ¨è«–ã«ãŠã„ã¦é‡è¦ã§ã‚ã‚Šã€æˆ‘ã€…ã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰å‘ã‘ã«Reverse-Enhanced Thinkingï¼ˆRevThinkï¼‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¨å­¦ç¿’ç›®æ¨™ã‚’ç”¨ã„ã¦ã€å‰å‘ãã¨å¾Œå‘ãã®æ¨è«–ã‚’æ§‹é€ åŒ–ã—ã€ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã§å°å‹ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã€‚å®Ÿé¨“ã§ã¯ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ€§èƒ½ãŒå¹³å‡13.53%å‘ä¸Šã—ã€çŸ¥è­˜è’¸ç•™ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«å¯¾ã—ã¦6.84%ã®æ”¹å–„ã‚’é”æˆã€‚å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã®ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ã‚‚ç¤ºã—ã€ä¸€èˆ¬åŒ–èƒ½åŠ›ãŒé«˜ã„ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>## æ‰‹æ³•æ¦‚è¦<br><br>Original Questionã‹ã‚‰Teacher Modelã§reasoningã¨é€†è³ªå•ã‚’ç”Ÿæˆï¼ˆForward Reasoning, Backward Questionï¼‰ã—ã€é€†è³ªå•ã«å¯¾ã™ã‚‹Reasoningã‚’ç”Ÿæˆã™ã‚‹ï¼ˆBackward Reasoningï¼‰ã€‚<br>ãã®å¾Œã€Forward Reasoningã§å›ç­”ãŒèª¤ã£ã¦ã„ã‚‹ã‚‚ã®ã‚„ã€Teacher Modelã‚’ç”¨ã„ã¦Backward Reasoningã¨Original Questionã‚’æ¯”è¼ƒã—ã¦æ­£ã—ã•ã‚’verificationã™ã‚‹ã“ã¨ã§ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã†ã€‚<br>ã“ã®ã‚ˆã†ã«ã—ã¦å¾—ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã€3ç¨®é¡ã®é …ã‚’lossã«è¨­ã‘ã¦å­¦ç¿’ã™ã‚‹ã€‚å…·ä½“çš„ã«ã¯<br><br>- Original Questionã‹ã‚‰ç”Ÿæˆã—ãŸForward Reasoningã«å¯¾ã™ã‚‹ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼<br>- Original Questionã‹ã‚‰ç”Ÿæˆã—ãŸBackward Questionã«å¯¾ã™ã‚‹ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼<br>- Backward Questionã‹ã‚‰ç”Ÿæˆã—ãŸBackward Reasoningã«å¯¾ã™ã‚‹ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼<br><br>ã®å¹³å‡ã‚’ã¨ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/d37ff435-3225-4e9e-b455-547a6b691057" alt="image" loading="lazy"><br><br>ã¾ãŸã€original questionã¨ã€backward reasoningãŒä¸€è²«ã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«Teacher Modelã‚’åˆ©ç”¨ã—ãŸä¸‹è¨˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§verificationã‚’å®Ÿæ–½ã—ã€ä¸€è²«æ€§ãŒã‚ã‚‹ã¨åˆ¤æ–­ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ã®ã¿ã‚’SFTã®ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ´»ç”¨ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/3fc5b0a1-ff46-4ad3-8e12-9ab97224ef2d" alt="image" loading="lazy"><br><br>Teacherãƒ¢ãƒ‡ãƒ«ã‹ã‚‰çŸ¥è­˜è’¸ç•™ã‚’ã™ã‚‹ãŸã‚SFTãŒå¿…è¦ã€‚ã‚ã¨ã€æ­£è§£ãŒä¸€æ„ã«å®šã¾ã‚‹ã‚ˆã†ãªQuestionã§ãªã„ã¨backward reasoningã®ç”Ÿæˆã¯ã§ãã¦ã‚‚ã€verificationãŒå›°é›£ã«ãªã‚‹ã®ã§ã€é©ç”¨ã™ã‚‹ã®ã¯é›£ã—ã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<span class="issue_date">Issue Date: 2024-11-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1541" target="_blank" rel="noopener noreferrer" class="title-link">How Does Critical Batch Size Scale in Pre-training?, Hanlin Zhang+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«ã¯ã€ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆCBSï¼‰ã‚’è€ƒæ…®ã—ãŸä¸¦åˆ—åŒ–æˆ¦ç•¥ãŒé‡è¦ã§ã‚ã‚‹ã€‚CBSã®æ¸¬å®šæ³•ã‚’ææ¡ˆã—ã€C4ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è‡ªå·±å›å¸°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã€‚ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚„å­¦ç¿’ç‡ãªã©ã®è¦å› ã‚’èª¿æ•´ã—ã€CBSãŒãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«æ¯”ä¾‹ã—ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã“ã®çµæœã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ç†è«–çš„åˆ†æã«ã‚ˆã£ã¦æ”¯æŒã•ã‚Œã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¸æŠã®é‡è¦æ€§ã‚‚å¼·èª¿ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Critical Batch Sizeã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«ã¯ã‚ã¾ã‚Šä¾å­˜ã›ãšã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«å¿œã˜ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹<br><img src="https://github.com/user-attachments/assets/4a1a720f-37a1-485d-9b02-bb2e8a5c2da4" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/8bc5f621-caac-438a-afd1-de1d689ee210" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2024-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1505" target="_blank" rel="noopener noreferrer" class="title-link">Mixture-of-Transformers: A Sparse and Scalable Architecture for   Multi-Modal Foundation Models, Weixin Liang+, TMLR'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å‡¦ç†ã‚’åŠ¹ç‡åŒ–ã™ã‚‹ãŸã‚ã«ã€Mixture-of-Transformersï¼ˆMoTï¼‰ã‚’ææ¡ˆã€‚MoTã¯è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã—ã€ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã”ã¨ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åˆ†é›¢ã—ã¦ç‰¹åŒ–ã—ãŸå‡¦ç†ã‚’å®Ÿç¾ã€‚Chameleon 7Bè¨­å®šã§ã¯ã€55.8%ã®FLOPsã§å¯†ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€éŸ³å£°ã‚’å«ã‚€å ´åˆã‚‚37.2%ã®FLOPsã§åŒæ§˜ã®çµæœã‚’é”æˆã€‚ã•ã‚‰ã«ã€Transfusionè¨­å®šã§ã¯ã€7Bã®MoTãƒ¢ãƒ‡ãƒ«ãŒå¯†ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®ç”»åƒæ€§èƒ½ã«å¯¾ã—ã¦FLOPsã®3åˆ†ã®1ã§åŒ¹æ•µã—ã€760Mã®ãƒ¢ãƒ‡ãƒ«ã¯ä¸»è¦ãªç”»åƒç”ŸæˆæŒ‡æ¨™ã§ä¸Šå›ã‚‹çµæœã‚’å¾—ãŸã€‚MoTã¯å®Ÿç”¨çš„ãªåˆ©ç‚¹ã‚‚ç¤ºã—ã€ç”»åƒå“è³ªã‚’47.2%ã€ãƒ†ã‚­ã‚¹ãƒˆå“è³ªã‚’75.6%ã®çµŒéæ™‚é–“ã§é”æˆã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2024-11-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1489" target="_blank" rel="noopener noreferrer" class="title-link">Self-Consistency Preference Optimization, Archiki Prasad+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±èª¿æ•´ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒäººé–“ã®æ³¨é‡ˆãªã—ã«è‡ªã‚‰ã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•ã§ã‚ã‚Šã€è‡ªå·±ä¸€è²«æ€§ã‚’æ´»ç”¨ã—ã¦è¨“ç·´ã‚’è¡Œã†æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€è‡ªå·±ä¸€è²«æ€§å„ªå…ˆæœ€é©åŒ–ï¼ˆScPOï¼‰ã‚’ææ¡ˆã€‚ScPOã¯ä¸€è²«ã—ãŸç­”ãˆã‚’å„ªå…ˆã—ã€GSM8Kã‚„MATHãªã©ã®æ¨è«–ã‚¿ã‚¹ã‚¯ã§å¾“æ¥ã®æ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€æ¨™æº–çš„ãªç›£è¦–å­¦ç¿’ã¨ã®çµ„ã¿åˆã‚ã›ã§ã‚‚çµæœãŒå‘ä¸Šã€‚ZebraLogicã§Llama-3 8Bã‚’å¾®èª¿æ•´ã—ã€ä»–ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’è¶…ãˆã‚‹æˆæœã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1854532624116547710?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Self-Consistencyã®ã‚ˆã†ã«ã€ãƒ¢ãƒ‡ãƒ«ã«è¤‡æ•°ã®å‡ºåŠ›ã‚’ã•ã›ã¦ã€æœ€ã‚‚é »åº¦ãŒé«˜ã„å›ç­”ã¨é »åº¦ãŒä½ã„å›ç­”ã®2ã¤ã§DPOã®ãƒšã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—å­¦ç¿’ã€‚é »åº¦ã®å·®ã«ã‚ˆã£ã¦é‡ã¿ã‚’æ±ºã‚ã¦lossã«çµ„ã¿è¾¼ã¿ã“ã®ã‚ˆã¤ãªå‡¦ç†ã‚’ç¹°ã‚Šè¿”ã—å­¦ç¿’ã™ã‚‹ã¨æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã€ã¨ã„ã£ãŸè©±ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/040ffe7c-6e89-4b58-85dd-ce1bc78195cb" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/45bbb1e6-145c-4c49-943d-4dfa25812264" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/35905525-b03f-4fe3-a0e6-89a89cf4ed29" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/45e87ec6-1ebb-4aa8-80ae-0f9072e670d9" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2024-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1466" target="_blank" rel="noopener noreferrer" class="title-link">Differential Transformer, Tianzhu Ye+, N_A, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- Diff Transformerã¯ã€é–¢é€£ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¸ã®æ³¨æ„ã‚’å¼·åŒ–ã—ã€ãƒã‚¤ã‚ºã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚å·®åˆ†æ³¨æ„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ç”¨ã„ã¦ã€æ³¨æ„ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ãªæ³¨æ„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¿ƒé€²ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€Diff TransformerãŒå¾“æ¥ã®Transformerã‚’ä¸Šå›ã‚Šã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚„å¹»è¦šã®è»½æ¸›ã«ãŠã„ã¦é¡•è‘—ãªåˆ©ç‚¹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€æ–‡è„ˆå†…å­¦ç¿’ã«ãŠã„ã¦ã‚‚ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€å …ç‰¢æ€§ã‚’é«˜ã‚ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Diff Transformerã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é€²å±•ã«å¯„ä¸ã™ã‚‹æœ‰æœ›ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æœ€è¿‘ã®MSã¯ãªã‹ãªã‹ã™ã”ã„ï¼ˆå°ä¸¦æ„Ÿ</p>
<p>
<strong># æ¦‚è¦<br><br>attention scoreã®ãƒã‚¤ã‚ºã‚’ä½æ¸›ã™ã‚‹ã‚ˆã†ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ã—ã¦ã€äºŒã¤ã®QKVã‚’ç”¨æ„ã—ã€ä¸¡è€…ã®å·®åˆ†ã‚’å–ã‚‹ã“ã¨ã§æœ€çµ‚çš„ãªattentiok scoreã‚’è¨ˆç®—ã™ã‚‹Differential Attentionã‚’ææ¡ˆã—ãŸã€‚<br><br><br><br>attentionã®noiseã®ä¾‹ã€‚answerã¨æ¯”è¼ƒã—ã¦irrelevantãªcontextã«attention scoreãŒé«˜ã„ã‚¹ã‚³ã‚¢ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã—ã¾ã†ï¼ˆå›³å·¦ï¼‰ã€‚differential transformerãŒææ¡ˆã™ã‚‹differential attentionã§ã¯ã€ãƒã‚¤ã‚ºã‚’æè¨€ã—ã€é‡è¦ãªcontextã®attention scoreãŒé«˜ããªã‚‹ã‚ˆã†ã«ãªã‚‹ï¼ˆå›³ä¸­å¤®ï¼‰ã€ã‚‰ã—ã„ã€‚<br><br><img src="https://github.com/user-attachments/assets/6033f477-d4bf-492d-9360-74f2849ce40e" alt="image" loading="lazy"><br><br><br><br># Differential Attentionã®æ¦‚è¦ã¨è¨ˆç®—å¼<br><br><img src="https://github.com/user-attachments/assets/b77facd8-7cf2-43ab-8947-2f775423f0a0" alt="image" loading="lazy"><br><br><br><br>æ•°å¼ã§è¦‹ã‚‹ã¨ã“ã®ã‚ˆã†ã«ãªã£ã¦ãŠã‚Šã€äºŒã¤ã®QKã‚’ã©ã®ç¨‹åº¦ã®å¼·ã•ã§äº¤äº’ä½œç”¨ã•ã›ã‚‹ã‹ã‚’Î»ã§åˆ¶å¾¡ã—ã€Î»ã‚‚ãã‚Œãã‚Œã®QKã‹ã‚‰å°å‡ºã™ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/c58a4d04-a453-4aef-aa40-7de872117482" alt="image" loading="lazy">&lt;/p&gt;<p>QA, æ©Ÿæ¢°ç¿»è¨³, æ–‡æ›¸åˆ†é¡, ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãªã©ã®æ§˜ã€…ãªNLPã‚¿ã‚¹ã‚¯ãŒå«ã¾ã‚Œã‚‹Eval Harnessãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯ã€åŒè¦æ¨¡ã®transformerãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«outperformã€‚ãŸã ã—ã€3Bã§ã—ã‹å®Ÿé¨“ã—ã¦ã„ãªã„ã‚ˆã†ãªã®ã§ã€ã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«ãªã£ãŸã¨ãã«gainãŒã‚ã‚‹ã‹ã¯ç¤ºã•ã‚Œã¦ã„ãªã„ç‚¹ã«ã¯æ³¨æ„ã€‚<br><img src="https://github.com/user-attachments/assets/384605ed-e4e4-4a17-83c8-506f8e3e2e4c" alt="image" loading="lazy"></p>
<p>ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ï¼‰ã¨ã€å­¦ç¿’ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã«ã¤ã„ã¦ã‚‚èª¿æŸ»ã—ãŸçµæœã€LLaMAã¨æ¯”è¼ƒã—ã¦ã€ã‚ˆã‚Šå°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°/å­¦ç¿’ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã§åŒç­‰ã®lossã‚’é”æˆã€‚<br><img src="https://github.com/user-attachments/assets/5d2d1dfc-4197-4b36-9f3d-79a3ed18fe3f" alt="image" loading="lazy"></p>
<p>64Kã«context sgzeã‚’æ‹¡å¼µã—ã€1.5B tokenã§3Bãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ å­¦ç¿’ã‚’ã—ãŸã¨ã“ã‚ã€ã“ã‚Œã‚‚transformerã¨æ¯”ã¹ã¦ã‚ˆã‚Šå°ã•ã„lossã‚’é”æˆ<img src="https://github.com/user-attachments/assets/f911a4f9-d175-4ea2-825b-9776be6042e5" alt="image" loading="lazy"></p>
<p>contextä¸­ã«åŸ‹ã‚è¾¼ã¾ã‚ŒãŸé‡è¦ãªæƒ…å ±ï¼ˆä»Šå›ã¯ã‚¯ã‚¨ãƒªã«å¯¾å¿œã™ã‚‹magic numberï¼‰ã‚’æŠ½å‡ºã™ã‚‹ã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ã‚‚å‘ä¸Šã€‚Needleï¼ˆNï¼‰ã¨å‘¼ã°ã‚Œã‚‹æ­£è§£ã®magic numberãŒå«ã¾ã‚Œã‚‹æ–‡ã‚’contextä¸­ã®æ§˜ã€…ãªæ·±ã•ã«é…ç½®ã—ã€åŒæ™‚ã«distractorã¨ãªã‚‹æ–‡ã‚‚ãƒ©ãƒ³ãƒ€ãƒ ã«é…ç½®ã™ã‚‹ã€‚ã“ã‚Œã«å¯¾ã—ã¦ã‚¯ã‚¨ãƒªï¼ˆRï¼‰ãŒå…¥åŠ›ã•ã‚ŒãŸã¨ãã«ã€ã©ã‚Œã ã‘æ­£ã—ã„æƒ…å ±ã‚’contextã‹ã‚‰æŠ½å‡ºã§ãã‚‹ã‹ã€ã¨ã„ã†è©±ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>ã“ã‚Œã‚‚æ€§èƒ½ãŒå‘ä¸Šã€‚ç‰¹ã«ã‚¯ã‚¨ãƒªã¨NeedleãŒè¤‡æ•°ã®è¦ç´ ã§æ§‹æˆã•ã‚Œã¦ã„ã‚Œå ´åˆã®æ€§èƒ½ãŒé«˜ãï¼ˆä¸‹è¡¨ï¼‰ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¸­ã®æ§˜ã€…ãªä½ç½®ã«åŸ‹ã‚è¾¼ã¾ã‚ŒãŸNeedleã‚’æŠ½å‡ºã™ã‚‹æ€§èƒ½ã‚‚é«˜ã„ï¼ˆä¸Šã®matrixï¼‰<br><br><img src="https://github.com/user-attachments/assets/f4d084dc-fac5-427d-8185-5604e55cf051" alt="image" loading="lazy"><br><br>[Needle-In-A-Haystack test](


<a href="https://www.perplexity.ai/search/needle-in-a-haystack-testtohan-jF7LXWQPSMqKI2pZSchjpA#0)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/search/needle-in-a-haystack-testtohan-jF7LXWQPSMqKI2pZSchjpA#0)</a>


</p>
<p>Many shotã®ICLèƒ½åŠ›ã‚‚å‘ä¸Š<br><img src="https://github.com/user-attachments/assets/c935ba93-9915-45c8-aaa6-f073d62fdd3b" alt="image" loading="lazy"></p>
<p>è¦ç´„ã‚¿ã‚¹ã‚¯ã§ã®hallucinationã‚‚ä½æ¸›ã€‚ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã¨æ­£è§£è¦ç´„ã‚’å…¥åŠ›ã—ã€GPT4-oã«hallucinationã®æœ‰ç„¡ã‚’åˆ¤å®šã•ã›ã¦è©•ä¾¡ã€‚ã“ã‚Œã¯å…ˆè¡Œç ”ç©¶ã§äººæ‰‹ã§ã®è©•ä¾¡ã¨é«˜ã„agreementãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/6fd97af4-fec6-44e8-b00c-d5ba26770a84" alt="image" loading="lazy"></p>
<p>ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§LLMå…¨ä½“ã®æ€§èƒ½ã‚’åº•ä¸Šã’ã—ã¦ã„ã‚‹ç´ æ™´ã‚‰ã—ã„æˆæœã«è¦‹ãˆã‚‹ã€‚æ–œã‚èª­ã¿ãªã®ã§èª­ã¿é£›ã°ã—ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãŒã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need, Suriya Gunasekar+, N/A, arXiv'23</a>
&lt;/strong&gt;
<br>
 ã®ã‚ˆã†ã«é«˜å“è³ªãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ãŸå ´åˆã‚‚åŒæ§˜ã®åŠ¹æœãŒç™ºç¾ã™ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ<br>attentionã®ã‚¹ã‚³ã‚¢ãŒnoisyã¨ã„ã†ã“ã¨ã¯ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æ´—ç·´ã•ã›ã‚‹ã“ã¨ã§ã‚‚æ”¹å–„ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need, Suriya Gunasekar+, N/A, arXiv'23</a>
 ã¯ã“ã‚Œã‚’ãƒ‡ãƒ¼ã‚¿ã§æ”¹å–„ã—ã€ã“ã¡ã‚‰ã®ç ”ç©¶ã¯ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§æ”¹å–„ã—ãŸã€ã¿ãŸã„ãªæ‰ãˆæ–¹ã‚‚ã§ãã‚‹ã®ã‹ã‚‚ã—ã‚Œãªã„ã€‚</p>
<p>ã¡ãªã¿ã«Flash Attentionã¨ã—ã¦ã®å®Ÿè£…æ–¹æ³•ã‚‚ææ¡ˆã•ã‚Œã¦ãŠã‚Šã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¯é€šå¸¸ã®attentionã¨æ¯”ã¹ã¦ã‚€ã—ã‚å‘ä¸Šã—ã¦ã„ã‚‹ã®ã§å®Ÿç”¨çš„ãªæ‰‹æ³•ã§ã‚‚ã‚ã‚‹ã€‚ã™ã”ã„ã€‚<br><img src="https://github.com/user-attachments/assets/c0212cd8-55f5-4991-b256-0ff2bce35669" alt="image" loading="lazy"></p>
<p>ã‚ã¨ã“ã‚Œã€äº‹å‰å­¦ç¿’ã¨Instruction Tuningã‚’é€šå¸¸ã®ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã§å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã§SFTã™ã‚‹ã¨ãã«å°å…¥ã—ãŸã‚‰downstream taskã®æ€§èƒ½å‘ä¸Šã™ã‚‹ã‚“ã ã‚ã†ã‹ã€‚ã‚‚ã—ãã†ãªã‚‰ç´ æ™´ã‚‰ã—ã„</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=OvoCm1gGhN" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=OvoCm1gGhN</a>


</p>
<p>GroupNormalizationã«ã¤ã„ã¦ã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1856" target="_blank" rel="noopener noreferrer">Group Normalization, Yuxin Wu+, arXiv'18</a>
</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2024-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1461" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented  Generation, Satyapriya Krishna+, N_A, NAACL'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã‚’ç”¨ã„ãŸæƒ…å ±æ¤œç´¢å¼·åŒ–ç”Ÿæˆï¼ˆRAGï¼‰ã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½è©•ä¾¡ã®ãŸã‚ã«ã€FRAMESã¨ã„ã†æ–°ã—ã„è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€äº‹å®Ÿã«åŸºã¥ãå¿œç­”ã€æ¤œç´¢èƒ½åŠ›ã€æ¨è«–ã‚’çµ±ä¸€çš„ã«è©•ä¾¡ã™ã‚‹ã‚‚ã®ã§ã€è¤‡æ•°ã®æƒ…å ±æºã‚’çµ±åˆã™ã‚‹ãƒãƒ«ãƒãƒ›ãƒƒãƒ—è³ªå•ã‚’å«ã‚€ã€‚æœ€æ–°ã®LLMã§ã‚‚0.40ã®ç²¾åº¦ã«ç•™ã¾ã‚‹ä¸­ã€ææ¡ˆã™ã‚‹ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—æ¤œç´¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«ã‚ˆã‚Šç²¾åº¦ãŒ0.66ã«å‘ä¸Šã—ã€RAGã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã«è²¢çŒ®ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>RAGã®factuality, retrieval acculacy, reasoningã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®multi hop puestionã¨ãã‚Œã«å›ç­”ã™ã‚‹ãŸã‚ã®æœ€å¤§15ã®wikipediaè¨˜äº‹ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1840628834275602585?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span></strong></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2024-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1460" target="_blank" rel="noopener noreferrer" class="title-link">LLMs Know More Than They Show: On the Intrinsic Representation of LLM  Hallucinations, Hadas Orgad+, N_A, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯ã€Œå¹»è¦šã€ã¨å‘¼ã°ã‚Œã‚‹ã‚¨ãƒ©ãƒ¼ã‚’ç”Ÿæˆã™ã‚‹ãŒã€å†…éƒ¨çŠ¶æ…‹ãŒçœŸå®Ÿæ€§ã«é–¢ã™ã‚‹æƒ…å ±ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€çœŸå®Ÿæ€§æƒ…å ±ãŒç‰¹å®šã®ãƒˆãƒ¼ã‚¯ãƒ³ã«é›†ä¸­ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã€ã“ã‚Œã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã‚¨ãƒ©ãƒ¼æ¤œå‡ºæ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã—ã‹ã—ã€ã‚¨ãƒ©ãƒ¼ãƒ‡ã‚£ãƒ†ã‚¯ã‚¿ãƒ¼ã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆé–“ã§ä¸€èˆ¬åŒ–ã«å¤±æ•—ã—ã€çœŸå®Ÿæ€§ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯æ™®éçš„ã§ã¯ãªã„ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚‹ã€‚ã¾ãŸã€å†…éƒ¨è¡¨ç¾ã‚’ç”¨ã„ã¦ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡ã‚’äºˆæ¸¬ã—ã€ç‰¹åŒ–ã—ãŸç·©å’Œæˆ¦ç•¥ã®é–‹ç™ºã‚’ä¿ƒé€²ã™ã‚‹ã€‚ã•ã‚‰ã«ã€å†…éƒ¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨å¤–éƒ¨ã®æŒ¯ã‚‹èˆã„ã¨ã®ä¸ä¸€è‡´ãŒå­˜åœ¨ã—ã€æ­£ã—ã„ç­”ãˆã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã„ã¦ã‚‚èª¤ã£ãŸç­”ãˆã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMã®ã‚¨ãƒ©ãƒ¼ç†è§£ãŒæ·±ã¾ã‚Šã€ä»Šå¾Œã®ç ”ç©¶ã«å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç‰¹å®šã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒLLMã®trustfulnessã«é›†ä¸­ã—ã¦ã„ã‚‹ã“ã¨ã‚’å®Ÿé¨“çš„ã«ç¤ºã—ã€ã‹ã¤å†…éƒ¨ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸrepresentationã¯æ­£ã—ã„ç­”ãˆã®ã‚‚ã®ã¨ãªã£ã¦ã„ã‚‹ã®ã«ã€ç”Ÿæˆçµæœã«èª¤ã‚ŠãŒç”Ÿã˜ã‚‹ã‚ˆã†ãªä¸æ•´åˆãŒç”Ÿã˜ã‚‹ã“ã¨ã‚‚ç¤ºã—ãŸã‚‰ã—ã„</p>
<p>openreview: 


<a href="https://openreview.net/forum?id=KRnsX5Em3W" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=KRnsX5Em3W</a>


</p></span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2024-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1454" target="_blank" rel="noopener noreferrer" class="title-link">Llama-3.1-Nemotron-70B-Instruct, Nvidia, ï¼ˆICLR'25ï¼‰, 2024.10</a>
<span class="snippet"><span>GPT Summary</span>- å ±é…¬ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«ã¯Bradley-Terryã‚¹ã‚¿ã‚¤ãƒ«ã¨å›å¸°ã‚¹ã‚¿ã‚¤ãƒ«ãŒã‚ã‚Šã€ãƒ‡ãƒ¼ã‚¿ã®ä¸€è‡´ãŒé‡è¦ã ãŒã€é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚HelpSteer2ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ã€Bradley-Terryè¨“ç·´ç”¨ã®å¥½ã¿ã®æ³¨é‡ˆã‚’å…¬é–‹ã—ã€åˆã‚ã¦ä¸¡ãƒ¢ãƒ‡ãƒ«ã®ç›´æ¥æ¯”è¼ƒã‚’è¡Œã£ãŸã€‚ã“ã‚Œã«åŸºã¥ãã€ä¸¡è€…ã‚’çµ„ã¿åˆã‚ã›ãŸæ–°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€Llama-3.1-70B-Instructãƒ¢ãƒ‡ãƒ«ãŒRewardBenchã§94.1ã®ã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚ã•ã‚‰ã«ã€REINFORCEã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ã¦æŒ‡ç¤ºãƒ¢ãƒ‡ãƒ«ã‚’èª¿æ•´ã—ã€Arena Hardã§85.0ã‚’è¨˜éŒ²ã—ãŸã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>MTBench, Arena Hardã§GPT4o-20240513,Claude-3.5-sonnet-20240620ã‚’outperformã€‚Response lengthã®å¹³å‡ãŒé•·ã„ã“ã¨æ¨¡æ§˜<br><img src="https://github.com/user-attachments/assets/e7fe1193-f3c6-4d17-8077-2f4742aef00c" alt="image" loading="lazy"></p>
<p>openreview:


<a href="https://openreview.net/forum?id=MnfHxPP5gs" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=MnfHxPP5gs</a>


</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<span class="issue_date">Issue Date: 2024-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1388" target="_blank" rel="noopener noreferrer" class="title-link">Generative Verifiers: Reward Modeling as Next-Token Prediction, Lunjun Zhang+, N_A, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¤œè¨¼å™¨ã¨å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦LLMã®æ¨è«–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€ç”Ÿæˆçš„æ¤œè¨¼å™¨ï¼ˆGenRMï¼‰ã‚’ææ¡ˆã€‚GenRMã¯æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã‚’ç”¨ã„ã¦æ¤œè¨¼ã¨è§£æ±ºç­–ç”Ÿæˆã‚’å…±åŒã§è¡Œã„ã€æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„æ€è€ƒã®é€£é–ã‚’æ´»ç”¨ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€GenRMã¯å¾“æ¥ã®æ¤œè¨¼å™¨ã‚’ä¸Šå›ã‚Šã€å•é¡Œè§£æ±ºç‡ãŒ16-64%å‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã™ã‚‹å›ç­”ã‚’ç”Ÿæˆã—ãŸã®ã¡ã«ã€ãã®å›ç­”ã‚’verifyã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ— + verifyã®çµæœã‹ã‚‰å›ç­”ã‚’ä¿®æ­£ã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ã‚’å…¨ã¦concatã—ãŸå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’next token predictionã§ç”¨ã„ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€ãƒ¢ãƒ‡ãƒ«è‡ªèº«ã«è‡ªåˆ†ã®å›ç­”ã‚’verifyã™ã‚‹èƒ½åŠ›ã‚’èº«ã«ã¤ã‘ã•ã›ã‚‹ã“ã¨ãŒã§ããŸçµæœæ€§èƒ½ãŒå‘ä¸Šã—ã¾ã—ãŸã€ã¨ã„ã†ç ”ç©¶ã‚‰ã—ã„ã€‚ã¾ãŸã€Self-consistency <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/558" target="_blank" rel="noopener noreferrer">Self-consistency improves chain of thought reasoning in language models, Wang+, Google Research, ICLR'23</a>
 ã®ã‚ˆã†ã«è¤‡æ•°ã®ç•°ãªã‚‹CoTã‚’ä¸¦åˆ—ã—ã¦å®Ÿè¡Œã•ã›ã€ãã®majority votingã‚’ã¨ã‚‹ã“ã¨ã§ã•ã‚‰ã«æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã€‚<br><br><br><br>&lt;img width="663" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/e6ebd308-fc77-4c5b-80c2-37e3615f48af"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/e6ebd308-fc77-4c5b-80c2-37e3615f48af"&lt;/a&gt;


&gt;<br><br>&lt;img width="703" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/9cf3dfe7-be09-4053-a760-9ec9ed993b33"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/9cf3dfe7-be09-4053-a760-9ec9ed993b33"&lt;/a&gt;


&gt;<br><br></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2024-04-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1286" target="_blank" rel="noopener noreferrer" class="title-link">Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws, Zeyuan Allen-Zhu+, N_A, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã¨èƒ½åŠ›ã®é–¢ä¿‚ã‚’è¨˜è¿°ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸç ”ç©¶ã€‚ãƒ¢ãƒ‡ãƒ«ãŒæ ¼ç´ã™ã‚‹çŸ¥è­˜ãƒ“ãƒƒãƒˆæ•°ã‚’æ¨å®šã—ã€äº‹å®ŸçŸ¥è­˜ã‚’ã‚¿ãƒ—ãƒ«ã§è¡¨ç¾ã€‚è¨€èªãƒ¢ãƒ‡ãƒ«ã¯1ã¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚ãŸã‚Š2ãƒ“ãƒƒãƒˆã®çŸ¥è­˜ã‚’æ ¼ç´å¯èƒ½ã§ã‚ã‚Šã€7Bãƒ¢ãƒ‡ãƒ«ã¯14Bãƒ“ãƒƒãƒˆã®çŸ¥è­˜ã‚’æ ¼ç´å¯èƒ½ã€‚ã•ã‚‰ã«ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æœŸé–“ã€ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€é‡å­åŒ–ã€ç–ãªåˆ¶ç´„ã€ãƒ‡ãƒ¼ã‚¿ã®ä¿¡å·å¯¾é›‘éŸ³æ¯”ãŒçŸ¥è­˜æ ¼ç´å®¹é‡ã«å½±éŸ¿ã™ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚ãƒ­ãƒ¼ã‚¿ãƒªãƒ¼åŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨ã—ãŸGPT-2ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€çŸ¥è­˜ã®æ ¼ç´ã«ãŠã„ã¦LLaMA/Mistralã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ç«¶åˆã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«ãƒ‰ãƒ¡ã‚¤ãƒ³åã‚’è¿½åŠ ã™ã‚‹ã¨çŸ¥è­˜å®¹é‡ãŒå¢—åŠ ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1779640139263901698?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
</p>
<p>openreview:


<a href="https://openreview.net/forum?id=FxNNiUgtfa" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=FxNNiUgtfa</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2024-03-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1257" target="_blank" rel="noopener noreferrer" class="title-link">Evolutionary Optimization of Model Merging Recipes, Takuya Akiba+, N_A, Nature Machine Intelligence'25</a>
<span class="snippet"><span>GPT Summary</span>- é€²åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã—ãŸæ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€å¼·åŠ›ãªåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•ç”Ÿæˆã‚’å®Ÿç¾ã€‚LLMã®é–‹ç™ºã«ãŠã„ã¦ã€äººé–“ã®ç›´æ„Ÿã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã«ä¾å­˜ã›ãšã€å¤šæ§˜ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®åŠ¹æœçš„ãªçµ„ã¿åˆã‚ã›ã‚’è‡ªå‹•çš„ã«ç™ºè¦‹ã™ã‚‹ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€æ—¥æœ¬èªã®LLMã¨æ•°å­¦æ¨è«–èƒ½åŠ›ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ãªã©ã€ç•°ãªã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³é–“ã®çµ±åˆã‚’å®¹æ˜“ã«ã—ã€æ—¥æœ¬èªVLMã®æ€§èƒ½å‘ä¸Šã«ã‚‚è²¢çŒ®ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¸ã®è²¢çŒ®ã¨è‡ªå‹•ãƒ¢ãƒ‡ãƒ«æ§‹æˆã®æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ å°å…¥ã«ã‚ˆã‚Šã€åŸºç›¤ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã«ãŠã‘ã‚‹åŠ¹ç‡çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¨¡ç´¢ã€‚</span>
<span class="snippet"><span>Comment</span><p>è¤‡æ•°ã®LLMã‚’èåˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã®è©±ã€‚æ—¥æœ¬èªLLMã¨è‹±èªã®æ•°å­¦LLNã‚’ãƒãƒ¼ã‚¸ã•ã›ã‚‹ã“ã¨ã§æ—¥æœ¬èªã®æ•°å­¦æ€§èƒ½ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ãŸã‚Šã€LLMã¨VLMã‚’èåˆã—ãŸã‚Šã™ã‚‹ã“ã¨ã§ã€æ—¥æœ¬ã«ã—ã‹å­˜åœ¨ã—ãªã„æ¦‚å¿µã®ç”»åƒã‚‚ã€ãã¡ã‚“ã¨å›ç­”ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚<br><br>è‘—è€…ã‚¹ãƒ©ã‚¤ãƒ‰ã«ã‚ˆã‚‹ã¨ã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«ã¯base modelãŒåŒä¸€ã§ãªã„ã¨ã†ã¾ãã„ã‹ãªã‹ã£ãŸã‚Šï¼ˆé‡ã¿ã®ç·šå‹çµåˆã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ï¼‰ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¢—æ¸›ã—ãŸã‚Šï¼ˆè¤‡æ•°LLMã®Layerã‚’é‡ã¿ã¯å¼„ã‚‰ãšå†é…ç½®ã™ã‚‹ï¼‰ã€‚ã¾ãŸæ—¥æœ¬èªLLMã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã‚’å®Ÿæ–½ã—ã‚ˆã†ã¨ã™ã‚‹ã¨ã€ãƒãƒ¼ã‚¸å…ƒã®LLMãŒå°‘ãªã‹ã£ãŸã‚Šã€åºƒç¯„å›²ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ‰±ã†ã¨ãƒãƒ¼ã‚¸ãŒã†ã¾ãã„ã‹ãªã„ã€ã¨ã„ã£ãŸèª²é¡ŒãŒã‚ã£ãŸã€‚æœ¬ç ”ç©¶ã§ã¯ã“ã‚Œã‚‰èª²é¡Œã‚’è§£æ±ºã§ãã‚‹ã€‚</p>
<p>è‘—è€…ã«ã‚ˆã‚‹è³‡æ–™ï¼ˆNLPã‚³ãƒ­ã‚­ã‚¦ãƒ ï¼‰:<br>


<a href="https://speakerdeck.com/iwiwi/17-nlpkorokiumu" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/iwiwi/17-nlpkorokiumu</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2023-07-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/906" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FacTool: Factuality Detection in Generative AI -- A Tool Augmented   Framework for Multi-Task and Multi-Domain Scenarios, I-Chun Chern+, COLM'25, 2023.07</a>
<span class="snippet"><span>GPT Summary</span>- ç”Ÿæˆçš„äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆåˆæˆã¯é€²å±•ã—ãŸãŒã€äº‹å®Ÿèª¤èªã®ç‰¹å®šã«ã¯èª²é¡ŒãŒæ®‹ã‚‹ã€‚ç‰¹ã«ã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äº‹å®Ÿèª¤èªã®ãƒªã‚¹ã‚¯å¢—åŠ ã€é•·æ–‡åŒ–ã«ã‚ˆã‚‹ç²’åº¦ã®æ¬ å¦‚ã€æ˜ç¤ºçš„è¨¼æ‹ ã®ä¸è¶³ãŒå•é¡Œã§ã‚ã‚‹ã€‚ã“ã‚Œã‚‰ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ã‚¿ã‚¹ã‚¯ã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ä¾å­˜ã—ãªã„äº‹å®Ÿèª¤èªæ¤œå‡ºãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯FacToolã‚’ææ¡ˆã€‚çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®QAã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã€æ•°å­¦çš„æ¨è«–ã€ç§‘å­¦æ–‡çŒ®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®4ã¤ã®ã‚¿ã‚¹ã‚¯ã§æœ‰åŠ¹æ€§ã‚’å®Ÿè¨¼ã—ã€ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=hJkQL9VtWT#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=hJkQL9VtWT#discussion</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3138" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Aria: An Open Multimodal Native Mixture-of-Experts Model, Dongxu Li+, arXiv'24, 2024.10</a>
<span class="snippet"><span>GPT Summary</span>- Ariaã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒã‚¤ãƒ†ã‚£ãƒ–AIãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€è¦–è¦šã¨ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦é«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚3.9Bã®è¦–è¦šãƒˆãƒ¼ã‚¯ãƒ³ã¨3.5Bã®ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŒã¤ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®æ··åˆãƒ¢ãƒ‡ãƒ«ã§ã€æ—¢å­˜ã®ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã¾ã™ã€‚è¨€èªç†è§£ã‚„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç†è§£ã‚’å¼·åŒ–ã™ã‚‹4æ®µéšã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€ãƒ¢ãƒ‡ãƒ«ã‚¦ã‚§ã‚¤ãƒˆã¨ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æä¾›ã•ã‚Œã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lijunnan0409/status/1975341550080303467?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/rhymes-ai/Aria" target="_blank" rel="noopener noreferrer">https://huggingface.co/rhymes-ai/Aria</a>


</p>
<p>ææ¡ˆã•ã‚ŒãŸå½“æ™‚2024å¹´10æœˆæ™‚ç‚¹ã§ã€Visionã¨Text UnderstandingåŒæ–¹ã§ã«å¼·ã„åˆã‚ã¦ã®ãƒ¢ãƒ‡ãƒ«ã§ã€åˆã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«MoEãƒ¢ãƒ‡ãƒ«ã§ï¼ˆå½“æ™‚ã¾ã è©±é¡Œã«ãªã£ã¦ã„ãªã‹ã£ãŸDeepSeek-V2ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ï¼‰ã€LongVideoã®Understanidinpã§å½“æ™‚ã®æœ€é«˜æ€§èƒ½ã§ã‚ã£ãŸã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/RecurrentModels.html" target="_blank" rel="noopener noreferrer">#RecurrentModels</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3100" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] xLSTM: Extended Long Short-Term Memory, Maximilian Beck+, NeurIPS'24 Spotlight, 2024.05</a>
<span class="snippet"><span>GPT Summary</span>- LSTMã‚’æ•°åå„„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã—ã€æœ€æ–°æŠ€è¡“ã‚’æ´»ç”¨ã—ã¦åˆ¶é™ã‚’è»½æ¸›ã™ã‚‹è©¦ã¿ã€‚æŒ‡æ•°çš„ã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¨ä¿®æ­£ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªæ§‹é€ ã‚’å°å…¥ã—ã€sLSTMã¨mLSTMã‚’é–‹ç™ºã€‚ã“ã‚Œã‚‰ã‚’çµ±åˆã—ã¦xLSTMãƒ–ãƒ­ãƒƒã‚¯ã‚’ç”Ÿæˆã—ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¨æ¯”è¼ƒã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã§å„ªã‚ŒãŸçµæœã‚’å¾—ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>code:


<a href="https://github.com/NX-AI/xlstm" target="_blank" rel="noopener noreferrer">https://github.com/NX-AI/xlstm</a>


</p>
<p>æœ€è¿‘åå‰ã‚’ã¿ã‚‹xLSTM</p>
<p>openreview:


<a href="https://openreview.net/forum?id=ARAxPPIAhq&noteId=gra7vHnb0q" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=ARAxPPIAhq&noteId=gra7vHnb0q</a>


</p>
<p>æ—¥æœ¬èªè§£èª¬:


<a href="https://note.com/ainest/n/n5173a3fe28c7" target="_blank" rel="noopener noreferrer">https://note.com/ainest/n/n5173a3fe28c7</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<span class="issue_date">Issue Date: 2025-10-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3063" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Same Task, More Tokens: the Impact of Input Length on the Reasoning  Performance of Large Language Models, Mosh Levy+, ACL'24, 2024.02</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å…¥åŠ›é•·ã®æ‹¡å¼µãŒå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’è©•ä¾¡ã™ã‚‹æ–°ã—ã„QAæ¨è«–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ç•°ãªã‚‹é•·ã•ã‚„ã‚¿ã‚¤ãƒ—ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç”¨ã„ã¦ã€LLMsã®æ¨è«–æ€§èƒ½ãŒçŸ­ã„å…¥åŠ›é•·ã§è‘—ã—ãä½ä¸‹ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã•ã‚‰ã«ã€æ¬¡ã®å˜èªäºˆæ¸¬ãŒLLMsã®æ€§èƒ½ã¨è² ã®ç›¸é–¢ã‚’æŒã¤ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã€LLMsã®é™ç•Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®æˆ¦ç•¥ã‚’ç¤ºå”†ã™ã‚‹å¤±æ•—ãƒ¢ãƒ¼ãƒ‰ã‚’ç‰¹å®šã—ãŸã€‚</span>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3009" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Back to Basics: Revisiting REINFORCE Style Optimization for Learning   from Human Feedback in LLMs, Arash Ahmadian+, ACL'24, 2024.02</a>
<span class="snippet"><span>GPT Summary</span>- RLHFã«ãŠã‘ã‚‹æ•´åˆæ€§ã®é‡è¦æ€§ã‚’è€ƒæ…®ã—ã€PPOã®é«˜ã‚³ã‚¹ãƒˆã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã®å•é¡Œã‚’æŒ‡æ‘˜ã€‚ã‚·ãƒ³ãƒ—ãƒ«ãªREINFORCEã‚¹ã‚¿ã‚¤ãƒ«ã®æœ€é©åŒ–æ‰‹æ³•ãŒPPOã‚„æ–°ææ¡ˆã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã€LLMã®æ•´åˆæ€§ç‰¹æ€§ã«é©å¿œã™ã‚‹ã“ã¨ã§ä½ã‚³ã‚¹ãƒˆã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³RLæœ€é©åŒ–ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ææ¡ˆã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2978" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Impact of Initialization on LoRA Finetuning Dynamics, Soufiane Hayou+, NeurIPS'24, 2024.06</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€LoRAã«ãŠã‘ã‚‹åˆæœŸåŒ–ã®å½¹å‰²ã‚’ç ”ç©¶ã—ã€Bã‚’ã‚¼ãƒ­ã«åˆæœŸåŒ–ã—Aã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«åˆæœŸåŒ–ã™ã‚‹æ–¹å¼ãŒä»–ã®æ–¹å¼ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã™ã€‚ã“ã®åˆæœŸåŒ–æ–¹å¼ã¯ã€ã‚ˆã‚Šå¤§ããªå­¦ç¿’ç‡ã‚’ä½¿ç”¨ã§ãã‚‹ãŸã‚ã€åŠ¹ç‡çš„ãªå­¦ç¿’ã‚’ä¿ƒé€²ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚LLMsã«é–¢ã™ã‚‹å®Ÿé¨“ã‚’é€šã˜ã¦çµæœã‚’æ¤œè¨¼ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jxmnop/status/1970893830619894186?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>åˆæœŸåŒ–ã§Bã‚’zeroã«ã™ã‚‹ã¨ã„ã†æ‰‹æ³•ã¯ä»¥ä¸‹ã§ã‚‚ææ¡ˆã•ã‚Œã¦ã„ã‚‹ãŒã€æœ¬ç ”ç©¶ã®æ–¹ãŒä¸‹è¨˜ç ”ç©¶ã‚ˆã‚Šã‚‚æŠ•ç¨¿ãŒ1å¹´ç¨‹åº¦æ—©ã„:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2194" target="_blank" rel="noopener noreferrer">[Paper Note] SingLoRA: Low Rank Adaptation Using a Single Matrix, David BensaÃ¯d+, arXiv'25</a>
</p>
<p>openreview:


<a href="https://openreview.net/forum?id=sn3UrYRItk&referrer=%5Bthe%20profile%20of%20Nikhil%20Ghosh%5D(%2Fprofile%3Fid%3D~Nikhil_Ghosh1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=sn3UrYRItk&referrer=%5Bthe%20profile%20of%20Nikhil%20Ghosh%5D(%2Fprofile%3Fid%3D~Nikhil_Ghosh1)</a>


</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2975" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Knowledge Editing for Large Language Models: A Survey, Song Wang+,  ACM Computing Surveys'24, 2023.10</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®è¨ˆç®—ã‚³ã‚¹ãƒˆã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ç·¨é›†ï¼ˆKMEï¼‰ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã€‚KMEã¯ã€ç‰¹å®šã®çŸ¥è­˜ã‚’LLMsã«çµ„ã¿è¾¼ã‚€éš›ã«ä»–ã®çŸ¥è­˜ã«æ‚ªå½±éŸ¿ã‚’ä¸ãˆãªã„ã‚ˆã†ã«ä¿®æ­£ã™ã‚‹æ‰‹æ³•ã§ã‚ã‚‹ã€‚æœ¬èª¿æŸ»ã§ã¯ã€KMEã®æˆ¦ç•¥ã‚„æŠ€è¡“ã®åˆ†é¡ã€æ—¢å­˜ã®æ–¹æ³•ã®åˆ†æã€æŒ‡æ¨™ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¤ã„ã¦åŒ…æ‹¬çš„ã«æ¦‚èª¬ã—ã€KMEã®å®Ÿç”¨æ€§ã¨ä»Šå¾Œã®ç ”ç©¶æ–¹å‘ã‚’ææ¡ˆã™ã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2963" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Evoke: Evoking Critical Thinking Abilities in LLMs via Reviewer-Author  Prompt Editing, Xinyu Hu+, ICLR'24, 2023.10</a>
<span class="snippet"><span>GPT Summary</span>- Evokeã¨ã„ã†è‡ªå‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ´—ç·´ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã¨è‘—è€…ã®LLMãŒãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã‚’å½¢æˆã—ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ´—ç·´ã€‚é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠã™ã‚‹ã“ã¨ã§ã€LLMã®æ·±ã„ç†è§£ã‚’ä¿ƒé€²ã€‚å®Ÿé¨“ã§ã¯ã€EvokeãŒè«–ç†çš„èª¤è¬¬æ¤œå‡ºã‚¿ã‚¹ã‚¯ã§80ä»¥ä¸Šã®ã‚¹ã‚³ã‚¢ã‚’é”æˆã—ã€ä»–ã®æ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=OXv0zQ1umU" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=OXv0zQ1umU</a>


</p>
<p>pj page: 


<a href="https://sites.google.com/view/evoke-llms/home" target="_blank" rel="noopener noreferrer">https://sites.google.com/view/evoke-llms/home</a>


<br>github: 


<a href="https://github.com/microsoft/Evoke" target="_blank" rel="noopener noreferrer">https://github.com/microsoft/Evoke</a>


<br><br>githubã«ãƒªãƒã‚¸ãƒˆãƒªã¯ã‚ã‚‹ãŒã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒæ›¸ã‹ã‚ŒãŸtsvãƒ•ã‚¡ã‚¤ãƒ«ãŒé…ç½®ã•ã‚Œã¦ã„ã‚‹ã ã‘ã§ã€å®Ÿé¨“ã‚’å†ç¾ã™ã‚‹ãŸã‚ã®å…¨ä½“ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯å­˜åœ¨ã—ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2958" target="_blank" rel="noopener noreferrer" class="title-link">A Comprehensive Survey of Hallucination in Large Language, Image, Video and Audio Foundation Models, Sahoo+, EMNLP'24 Findings</a>
<span class="snippet"><span>GPT Summary</span>- åŸºç›¤ãƒ¢ãƒ‡ãƒ«ï¼ˆFMsï¼‰ã®å¤šæ§˜ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã«ãŠã‘ã‚‹é€²å±•ã¯é¡•è‘—ã ãŒã€ç‰¹ã«é«˜ãƒªã‚¹ã‚¯ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯å¹»è¦šçš„ãªå‡ºåŠ›ãŒå•é¡Œã¨ãªã‚‹ã€‚æœ¬èª¿æŸ»è«–æ–‡ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€å‹•ç”»ã€éŸ³å£°ã«ãŠã‘ã‚‹FMsã®å¹»è¦šã®å•é¡Œã‚’ç‰¹å®šã—ã€è»½æ¸›ç­–ã®æœ€è¿‘ã®é€²å±•ã‚’ã¾ã¨ã‚ã‚‹ã€‚å¹»è¦šã®å®šç¾©ã€åˆ†é¡ã€æ¤œå‡ºæˆ¦ç•¥ã‚’å«ã‚€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã—ã€ä»Šå¾Œã®ç ”ç©¶ã¨é–‹ç™ºã®åŸºç›¤ã‚’ç¯‰ãã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1217" target="_blank" rel="noopener noreferrer">A Comprehensive Survey of Hallucination Mitigation Techniques in Large
  Language Models, S. M Towhidul Islam Tonmoy+, N/A, arXiv'24</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2824" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks,   and Refusals of LLMs, Seungju Han+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- WildGuardã¯ã€LLMã®å®‰å…¨æ€§å‘ä¸Šã‚’ç›®çš„ã¨ã—ãŸã‚ªãƒ¼ãƒ—ãƒ³ã§è»½é‡ãªãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«ã§ã€æ‚ªæ„ã®ã‚ã‚‹æ„å›³ã®ç‰¹å®šã€å®‰å…¨ãƒªã‚¹ã‚¯ã®æ¤œå‡ºã€æ‹’å¦ç‡ã®åˆ¤æ–­ã‚’è¡Œã†ã€‚92Kã®ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸWildGuardMixã‚’æ§‹ç¯‰ã—ã€æ•µå¯¾çš„ãªè„±ç„ã‚„æ‹’å¦å¿œç­”ã‚’ã‚«ãƒãƒ¼ã€‚è©•ä¾¡ã®çµæœã€WildGuardã¯æ—¢å­˜ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ç‰¹ã«æ‹’å¦æ¤œå‡ºã§æœ€å¤§26.4%ã®æ”¹å–„ã‚’é”æˆã€‚GPT-4ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«åŒ¹æ•µã—ã€è„±ç„æ”»æ’ƒã®æˆåŠŸç‡ã‚’79.8%ã‹ã‚‰2.4%ã«ä½ä¸‹ã•ã›ã‚‹åŠ¹æœã‚’æŒã¤ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=Ich4tv4202#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Ich4tv4202#discussion</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2777" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Lessons from Studying Two-Hop Latent Reasoning, Mikita Balesni+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®äºŒæ®µéšè³ªå•å¿œç­”èƒ½åŠ›ã‚’èª¿æŸ»ã—ã€æ€è€ƒã®é€£é–ï¼ˆCoTï¼‰ã®é‡è¦æ€§ã‚’ç¤ºã™ã€‚åˆæˆäº‹å®Ÿã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã€ãƒ¢ãƒ‡ãƒ«ã¯äºŒã¤ã®åˆæˆäº‹å®Ÿã‚’çµ„ã¿åˆã‚ã›ã‚‹ã®ã«å¤±æ•—ã™ã‚‹ãŒã€è‡ªç„¶ãªäº‹å®Ÿã¨ã®çµ„ã¿åˆã‚ã›ã§ã¯æˆåŠŸã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMã¯æ½œåœ¨çš„ãªäºŒæ®µéšæ¨è«–èƒ½åŠ›ã‚’æŒã¤ãŒã€ãã®èƒ½åŠ›ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã¯ä¸æ˜ç‚¹ãŒæ®‹ã‚‹ã€‚ç ”ç©¶è€…ã¯ã€LLMã®æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹éš›ã«ã€ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã«ã‚ˆã‚‹è™šå½ã®æˆåŠŸã‚„å¤±æ•—ã«æ³¨æ„ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/balesni/status/1966197584499999036?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä¸‹è¨˜ç ”ç©¶ã§ã¯ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒå›½ã®å ´åˆã¯2 stepæ¨è«–ãŒã§ãã‚‹ã¨ã„ã†ä¾‹å¤–ãŒç”Ÿã˜ã¦ãŠã‚Šã€äº‹å‰å­¦ç¿’ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã§ä½•ã‹è¦‹è½ã¨ã—ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„å¯èƒ½æ€§ãŒã‚ã‚Š:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1564" target="_blank" rel="noopener noreferrer">Do Large Language Models Perform Latent Multi-Hop Reasoning without   Exploiting Shortcuts?, Sohee Yang+, ACL'24</a>
<br><br>ä¸‹è¨˜ç ”ç©¶ã«ãŠã„ã¦ã€å®Œå…¨ã«memorizationzãŒç”Ÿã˜ãªã„å½¢ã§äº‹å‰å­¦ç¿’ã¨Inferenceå®Ÿæ–½ï¼ˆtrain: John Doe lives in **Tokyo**., Test: The people in the city John Doe is from speak **Japanese**.)ã•ã‚ŒãŸãŒã€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒcityã®å ´åˆã§ã—ã‹è©¦ã•ã‚Œã¦ãŠã‚‰ãšã€ä»–ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã§ã‚‚æ±åŒ–ã™ã‚‹ã®ã‹ï¼Ÿã¨ã„ã†ç–‘å•ãŒã‚ã£ãŸ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2778" target="_blank" rel="noopener noreferrer">[Paper Note] Extractive Structures Learned in Pretraining Enable Generalization on   Finetuned Facts, Jiahai Feng+, ICML'25</a>
<br><br>æœ¬ç ”ç©¶ã§ã¯17ç¨®é¡ã®ä»–ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã§ã‚‚2 hop reasoningãŒlatentã«å®Ÿæ–½ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ãŸã€‚ã—ã‹ã—ã€ä¸€ã¤ä¸æ€è­°ãªç‚¹ã¨ã—ã¦å½“åˆ2ã¤ã®æ¶ç©ºã®äº‹å®Ÿã‚’LLMã«æ•™ãˆã‚‹ã‚ˆã†ãªå­¦ç¿’ã‚’è©¦ã¿ãŸå ´åˆã¯ã€‚Acc.ãŒ0%ã§ã€lossã‚‚å¶ç„¶ã«ç”Ÿã˜ã‚‹ç¨‹åº¦ã®ã‚‚ã®ã§ã‚ã£ãŸã€‚ã“ã‚Œã‚’æ·±æ˜ã‚Šã™ã‚‹ã¨ã€<br>- åˆæˆ+æœ¬ç‰©ã®äº‹å®Ÿâ†’ã†ã¾ãã„ã<br>- åˆæˆ+åˆæˆâ†’å¤±æ•—<br>- åŒä¸€è¨“ç·´/incontextæ–‡æ›¸å†…ã®åˆæˆã•ã‚ŒãŸäº‹å®Ÿâ†’ã†ã¾ãã„ã<br>ã¨ã„ã†ç¾è±¡ãŒè¦³æ¸¬ã•ã‚Œã€ã“ã®ã“ã¨ã‚ˆã‚Š<br>- å®Ÿä¸–ç•Œã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã®æˆåŠŸã¯ã€latent reasoningãŒãƒ­ãƒã‚¹ãƒˆã«å®Ÿæ–½ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™ã‚ã‘ã§ã¯ãªãï¼ˆäº‹å‰å­¦ç¿’æ™‚ã®åŒä¸€æ–‡æ›¸å†…ã®å…±èµ·ã‚’åæ˜ ã—ã¦ã„ã‚‹ã ã‘ã®å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰<br>- åˆæˆãƒ‡ãƒ¼ã‚¿ã§ã®2 hopæ¨è«–ã®å¤±æ•—ã¯ã€latent reasoningã®èƒ½åŠ›ã‚’å¦å®šã™ã‚‹ã‚‚ã®ã§ã¯ãªã„ï¼ˆåˆæˆã•ã‚ŒãŸäº‹å®Ÿã¯å®Ÿä¸–ç•Œã§ã®è‡ªç„¶ãªäº‹å®Ÿã¨ã¯ç•°ãªã‚‹ãŸã‚ã†ã¾ãã„ã£ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰<br><br>ã¨ã„ã†æ•™è¨“ãŒå¾—ã‚‰ã‚ŒãŸã€ã¨ã„ã£ãŸè©±ãŒå…ƒãƒã‚¹ãƒˆã«æ›¸ã‹ã‚Œã¦ã„ã‚‹ã€‚<br><br>ãªãœå®Œå…¨ã«åˆæˆã•ã‚ŒãŸäº‹å®Ÿæƒ…å ±ã§ã¯å¤±æ•—ã™ã‚‹ã®ã ã‚ã†ã‹ã€‚å…ƒè«–æ–‡ã‚’èª­ã‚“ã§äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã©ã®ã‚ˆã†ãªã‚‚ã®ãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/feng_jiahai/status/1869019495299444830?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2770" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment, Xiwei Hu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã‚’çµ„ã¿è¾¼ã‚€ã€ŒåŠ¹ç‡çš„ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ï¼ˆELLAï¼‰ã€ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¤‡é›‘ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ•´åˆæ€§ã‚’å‘ä¸Šã•ã›ã€æ„å‘³çš„ç‰¹å¾´ã‚’é©å¿œã•ã›ã‚‹æ–°ã—ã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€Œæ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—èªè­˜ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚³ãƒã‚¯ã‚¿ï¼ˆTSCï¼‰ã€ã‚’å°å…¥ã€‚ELLAã¯å¯†ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹æ€§èƒ½ãŒæœ€å…ˆç«¯æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’å®Ÿé¨“ã§ç¤ºã—ã€ç‰¹ã«è¤‡æ•°ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆã«ãŠã„ã¦å„ªä½æ€§ã‚’ç™ºæ®ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://ella-diffusion.github.io" target="_blank" rel="noopener noreferrer">https://ella-diffusion.github.io</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2739" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures, Jinjie Ni+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- MixEvalã¯ã€LLMè©•ä¾¡ã®æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã§ã‚ã‚Šã€å®Ÿä¸–ç•Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã¨çœŸå®Ÿã«åŸºã¥ããƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ã‹ã¤å…¬æ­£ãªè©•ä¾¡ã‚’å®Ÿç¾ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Chatbot Arenaã¨ã®é«˜ã„ç›¸é–¢ã‚’æŒã¡ã€è¿…é€Ÿã‹ã¤å®‰ä¾¡ãªè©•ä¾¡ãŒå¯èƒ½ã¨ãªã‚‹ã€‚ã•ã‚‰ã«ã€å‹•çš„è©•ä¾¡ã‚’é€šã˜ã¦LLMè©•ä¾¡ã®ç†è§£ã‚’æ·±ã‚ã€ä»Šå¾Œã®ç ”ç©¶æ–¹å‘ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=6A29LUZhfv&referrer=%5Bthe%20profile%20of%20Yang%20You%5D(%2Fprofile%3Fid%3D~Yang_You1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=6A29LUZhfv&referrer=%5Bthe%20profile%20of%20Yang%20You%5D(%2Fprofile%3Fid%3D~Yang_You1)</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2734" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MMLU-Pro: A More Robust and Challenging Multi-Task Language   Understanding Benchmark, Yubo Wang+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- MMLUãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®é™ç•Œã‚’å…‹æœã™ã‚‹ãŸã‚ã€æ¨è«–ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸè³ªå•ã‚’çµ±åˆã—ã€é¸æŠè‚¢ã‚’4ã‹ã‚‰10ã«å¢—ã‚„ã—ãŸå¼·åŒ–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆMMLU-Proã‚’ææ¡ˆã€‚MMLU-Proã¯äº›ç´°ãªè³ªå•ã‚’æ’é™¤ã—ã€ç²¾åº¦ãŒ16%ã‹ã‚‰33%ä½ä¸‹ã™ã‚‹ä¸€æ–¹ã§ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹å®‰å®šæ€§ãŒå‘ä¸Šã€‚Chain of Thoughtæ¨è«–ã‚’åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ã€MMLU-Proã§ã‚ˆã‚Šè‰¯ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€è¤‡é›‘ãªæ¨è«–å•é¡Œã‚’å«ã‚€ã“ã¨ã‚’ç¤ºå”†ã€‚MMLU-Proã¯ã€ã‚ˆã‚Šè­˜åˆ¥çš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦åˆ†é‡ã®é€²å±•ã‚’è¿½è·¡ã™ã‚‹ã®ã«é©ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=y10DM6R2r3&referrer=%5Bthe%20profile%20of%20Ge%20Zhang%5D(%2Fprofile%3Fid%3D~Ge_Zhang5)#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=y10DM6R2r3&referrer=%5Bthe%20profile%20of%20Ge%20Zhang%5D(%2Fprofile%3Fid%3D~Ge_Zhang5)#discussion</a>


</p>
<p>MMLUã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/901" target="_blank" rel="noopener noreferrer">Measuring Massive Multitask Language Understanding, Dan Hendrycks+, N/A, ICLR'21</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2732" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Stepwise Alignment for Constrained Language Model Policy Optimization, Akifumi Wachi+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å®‰å…¨æ€§ã¨ä¿¡é ¼æ€§ã¯LLMã‚’ç”¨ã„ã‚‹AIã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦é‡è¦ã§ã‚ã‚Šã€æœ¬ç ”ç©¶ã§ã¯å ±é…¬æœ€å¤§åŒ–ã‚’äººé–“ã®ä¾¡å€¤ã«åŸºã¥ãå®‰å…¨æ€§åˆ¶ç´„ã®ä¸‹ã§å®šå¼åŒ–ã—ã€é€æ¬¡æ•´åˆæ€§ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆSACPOï¼‰ã‚’ææ¡ˆã€‚SACPOã¯å ±é…¬ã¨å®‰å…¨æ€§ã‚’çµ„ã¿è¾¼ã‚“ã æœ€é©ãƒãƒªã‚·ãƒ¼ã‚’æ®µéšçš„ã«æ•´åˆã•ã›ã€ã‚·ãƒ³ãƒ—ãƒ«ã§å¼·åŠ›ãªæ•´åˆæ€§ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ´»ç”¨ã€‚ç†è«–çš„åˆ†æã«ã‚ˆã‚Šæœ€é©æ€§ã¨å®‰å…¨æ€§åˆ¶ç´„é•åã®ä¸Šé™ã‚’ç¤ºã—ã€å®Ÿé¨“çµæœã§ã¯SACPOãŒAlpaca-7Bã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦æœ€å…ˆç«¯æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>NLPã‚³ãƒ­ã‚­ã‚¦ãƒ ã§ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’å‚ç…§ã®ã“ã¨: <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1603" target="_blank" rel="noopener noreferrer">ã€NLPã‚³ãƒ­ã‚­ã‚¦ãƒ ã€‘Stepwise Alignment for Constrained Language Model Policy Optimization (NeurIPS 2024)  , 2024.12</a>
</p>
<p>openreview: 


<a href="https://openreview.net/forum?id=VrVx83BkQX&referrer=%5Bthe%20profile%20of%20Takumi%20Tanabe%5D(%2Fprofile%3Fid%3D~Takumi_Tanabe1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=VrVx83BkQX&referrer=%5Bthe%20profile%20of%20Takumi%20Tanabe%5D(%2Fprofile%3Fid%3D~Takumi_Tanabe1)</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Routing.html" target="_blank" rel="noopener noreferrer">#Routing</a>
<span class="issue_date">Issue Date: 2025-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2690" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Multi-Head Mixture-of-Experts, Xun Wu+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- MH-MoEã¯ã€ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ç”¨ã„ã¦ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¤‡æ•°ã®ã‚µãƒ–ãƒˆãƒ¼ã‚¯ãƒ³ã«åˆ†å‰²ã—ã€å°‚é–€å®¶ã®æ´»æ€§åŒ–ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„æ‰‹æ³•ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ–‡è„ˆç†è§£ãŒæ·±ã¾ã‚Šã€éå­¦ç¿’ãŒè»½æ¸›ã•ã‚Œã¾ã™ã€‚MH-MoEã¯å®Ÿè£…ãŒç°¡å˜ã§ã€ä»–ã®SMoEãƒ¢ãƒ‡ãƒ«ã¨çµ±åˆå¯èƒ½ã§ã‚ã‚Šã€åºƒç¯„ãªå®Ÿé¨“ã§ãã®æœ‰åŠ¹æ€§ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=dyZ8GJZjtX&referrer=%5Bthe%20profile%20of%20Shaohan%20Huang%5D(%2Fprofile%3Fid%3D~Shaohan_Huang1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=dyZ8GJZjtX&referrer=%5Bthe%20profile%20of%20Shaohan%20Huang%5D(%2Fprofile%3Fid%3D~Shaohan_Huang1)</a>


</p>
<p>SNLP'24ã§ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:


<a href="https://speakerdeck.com/takase/snlp2024-multiheadmoe" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/takase/snlp2024-multiheadmoe</a>


</p>
<p>MoEã®Routing Collapseã«å¯¾ã—ã¦ã€Expertsã®è¡¨ç¾åŠ›ã‚’è½ã¨ã™ã“ã¨ã§ç‰¹å®šã®Expertsã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãŒåã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹ã€ã¨ã„ã†ã‚³ãƒ³ã‚»ãƒ—ãƒˆãªæ¨¡æ§˜ã€‚å…·ä½“çš„ã«ã¯ã€inputã‚’è¤‡æ•°headã«åˆ†å‰²ã—ã¦headå˜ä½ã§Expertsã‚’é¸æŠã—ã€å‡ºåŠ›ã‚’concatã™ã‚‹ã€ã¨ã„ã£ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Memorization.html" target="_blank" rel="noopener noreferrer">#Memorization</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2679" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Be like a Goldfish, Don't Memorize Mitigating Memorization in   Generative LLMs, Abhimanyu Hans+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- ã€Œã‚´ãƒ¼ãƒ«ãƒ‰ãƒ•ã‚£ãƒƒã‚·ãƒ¥ãƒ­ã‚¹ã€ã‚’å°å…¥ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã°ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒ­ã‚¹è¨ˆç®—ã‹ã‚‰é™¤å¤–ã™ã‚‹ã“ã¨ã§ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚„è‘—ä½œæ¨©ãƒªã‚¹ã‚¯ã‚’è»½æ¸›ã€‚10å„„è¦æ¨¡ã®Llama-2ãƒ¢ãƒ‡ãƒ«ã®å®Ÿé¨“ã«ã‚ˆã‚Šã€ä¸‹æµã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å½±éŸ¿ã‚’ä¸ãˆãšã«è¨˜æ†¶ã®å‰Šæ¸›ã‚’å®Ÿè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vikhyatk/status/1962954696500674908?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã®lossè¨ˆç®—ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«tokenã‚’é™¤å¤–ã›ã‚‹ã“ã¨ã§downstream taskã®æ€§èƒ½ã‚’æãªã†ã“ã¨ãªãmemorizationã‚’é˜²ã’ã¾ã™ã‚ˆã€ã¨ã„ã†è©±ã‚‰ã—ã„</p>
<p>openreview:


<a href="https://openreview.net/forum?id=DylSyAfmWs&referrer=%5Bthe%20profile%20of%20Jonas%20Geiping%5D(%2Fprofile%3Fid%3D~Jonas_Geiping1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=DylSyAfmWs&referrer=%5Bthe%20profile%20of%20Jonas%20Geiping%5D(%2Fprofile%3Fid%3D~Jonas_Geiping1)</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2638" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Many-Shot In-Context Learning, Rishabh Agarwal+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰å¤šãã®ã‚·ãƒ§ãƒƒãƒˆã®ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã«ãŠã„ã¦é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’ç¤ºã™ã€‚æ–°ãŸãªè¨­å®šã¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆã®æ€è€ƒéç¨‹ã‚’ç”¨ã„ã‚‹å¼·åŒ–ã•ã‚ŒãŸICLã¨ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ã®è³ªå•ã®ã¿ã‚’ç”¨ã„ã‚‹ç„¡ç›£ç£ICLã‚’ææ¡ˆã€‚ã“ã‚Œã‚‰ã¯ç‰¹ã«è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã«åŠ¹æœçš„ã§ã‚ã‚Šã€å¤šãã®ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã¯äº‹å‰å­¦ç¿’ã®ãƒã‚¤ã‚¢ã‚¹ã‚’è¦†ã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã¾ãŸã€æ¨è«–ã‚³ã‚¹ãƒˆã¯ç·šå½¢ã«å¢—åŠ ã—ã€æœ€å‰ç·šã®LLMsã¯å¤šãã®ã‚·ãƒ§ãƒƒãƒˆã®ICLã‹ã‚‰æ©æµã‚’å—ã‘ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>many-shotã‚’ææ¡ˆ</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ZeroshotHyperparameterTransfer.html" target="_blank" rel="noopener noreferrer">#ZeroshotHyperparameterTransfer</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2623" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Exponents Across Parameterizations and Optimizers, Katie Everett+, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã¯ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚„ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®é¸æŠãŒé‡è¦ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã«é–¢ã™ã‚‹æ–°ã—ã„è¦–ç‚¹ã‚’ææ¡ˆã—ã€åºƒç¯„ãªã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã¨å­¦ç¿’ç‡ã®çµ„ã¿åˆã‚ã›ã§æ•°ä¸‡ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ãŸçµæœã€æœ€é©ãªå­¦ç¿’ç‡ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚æ–°ã—ã„å±¤ã”ã¨ã®å­¦ç¿’ç‡ã®å‡¦æ–¹ã¯å¾“æ¥ã®æ–¹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€Adamã®ã‚¤ãƒ—ã‚·ãƒ­ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é©åˆ‡ãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã€æ•°å€¤çš„ã«å®‰å®šã—ãŸæ–°ã—ã„Adamãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã‚ã‚‹Adam-atan2ã‚’ææ¡ˆã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2615" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DART-Math: Difficulty-Aware Rejection Tuning for Mathematical  Problem-Solving, Yuxuan Tong+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- æ•°å­¦å•é¡Œè§£æ±ºã«ã¯é«˜åº¦ãªæ¨è«–ãŒå¿…è¦ã§ã‚ã‚Šã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã¯é›£ã—ã„ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦åã‚ŠãŒã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚ãã“ã§ã€Difficulty-Aware Rejection Tuningï¼ˆDARTï¼‰ã‚’ææ¡ˆã—ã€é›£ã—ã„ã‚¯ã‚¨ãƒªã«å¤šãã®è©¦è¡Œã‚’å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¼·åŒ–ã€‚æ–°ãŸã«ä½œæˆã—ãŸå°è¦æ¨¡ãªæ•°å­¦å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€7Bã‹ã‚‰70Bã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸDART-MATHã¯ã€å¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚åˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒæ•°å­¦å•é¡Œè§£æ±ºã«ãŠã„ã¦åŠ¹æœçš„ã§ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®è‰¯ã„ãƒªã‚½ãƒ¼ã‚¹ã§ã‚ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=zLU21oQjD5&referrer=%5Bthe%20profile%20of%20Rui%20Wang%5D(%2Fprofile%3Fid%3D~Rui_Wang1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=zLU21oQjD5&referrer=%5Bthe%20profile%20of%20Rui%20Wang%5D(%2Fprofile%3Fid%3D~Rui_Wang1)</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/Scheduler.html" target="_blank" rel="noopener noreferrer">#Scheduler</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2540" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MiniCPM: Unveiling the Potential of Small Language Models with Scalable  Training Strategies, Shengding Hu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ€¥æˆé•·ã™ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®é–‹ç™ºã«ãŠã‘ã‚‹ã‚³ã‚¹ãƒˆã®æ‡¸å¿µã‹ã‚‰ã€å°è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆSLMsï¼‰ã®å¯èƒ½æ€§ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€MiniCPMã¨ã„ã†1.2BãŠã‚ˆã³2.4Bã®éåŸ‹ã‚è¾¼ã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒªã‚¢ãƒ³ãƒˆã‚’ç´¹ä»‹ã—ã€ã“ã‚Œã‚‰ãŒ7B-13Bã®LLMsã¨åŒç­‰ã®èƒ½åŠ›ã‚’æŒã¤ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã¯åºƒç¯„ãªå®Ÿé¨“ã‚’ã€ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã¯Warmup-Stable-Decayï¼ˆWSDï¼‰å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã‚’å°å…¥ã—ã€åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿-ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•ã‚’ç ”ç©¶ã—ãŸã€‚MiniCPMãƒ•ã‚¡ãƒŸãƒªãƒ¼ã«ã¯MiniCPM-DPOã€MiniCPM-MoEã€MiniCPM-128KãŒå«ã¾ã‚Œã€å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¦ã„ã‚‹ã€‚MiniCPMãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Warmup-Stable-Decay (WSD)</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/ActivationFunction.html" target="_blank" rel="noopener noreferrer">#ActivationFunction</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2538" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Polynomial Composition Activations: Unleashing the Dynamics of Large  Language Models, Zhijian Zhuo+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„å¤šé …å¼åˆæˆæ´»æ€§åŒ–é–¢æ•°ï¼ˆPolyComï¼‰ã‚’ææ¡ˆã—ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’æœ€é©åŒ–ã€‚PolyComã¯ä»–ã®æ´»æ€§åŒ–é–¢æ•°ã‚ˆã‚Šã‚‚é«˜ã„è¡¨ç¾åŠ›ã‚’æŒã¡ã€æœ€é©è¿‘ä¼¼ç‡ã‚’é”æˆã€‚å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€å¾“æ¥ã®æ´»æ€§åŒ–é–¢æ•°ã‚’PolyComã«ç½®ãæ›ãˆã‚‹ã“ã¨ã§ã€ç²¾åº¦ã¨åæŸç‡ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã€‚å®Ÿé¨“çµæœã¯ä»–ã®æ´»æ€§åŒ–é–¢æ•°ã«å¯¾ã—ã¦å¤§å¹…ãªæ”¹å–„ã‚’ç¤ºã™ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ä¸­ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1311" target="_blank" rel="noopener noreferrer">GLU Variants Improve Transformer, Noam Shazeer, N/A, arXiv'20</a>
 </p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2506" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with  AI Feedback, Harrison Lee+, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- RLAIFã¯ã€ã‚ªãƒ•ãƒ»ã‚¶ãƒ»ã‚·ã‚§ãƒ«ãƒ•ã®LLMã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸå¥½ã¿ã«åŸºã¥ã„ã¦å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€RLHFã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã™ã‚‹ä»£æ›¿æ‰‹æ®µã‚’æä¾›ã€‚è‡ªå·±æ”¹å–„ã‚’ç¤ºã—ã€d-RLAIFã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã•ã‚‰ã«å„ªã‚ŒãŸçµæœã‚’å¾—ã‚‹ã€‚RLAIFã¯äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”¨ã„ãŸå ´åˆã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ã€RLHFã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®èª²é¡Œã«å¯¾ã™ã‚‹è§£æ±ºç­–ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ˆè¡Œç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2903" target="_blank" rel="noopener noreferrer">[Paper Note] Constitutional AI: Harmlessness from AI Feedback, Yuntao Bai+, arXiv'22</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Cultural.html" target="_blank" rel="noopener noreferrer">#Cultural</a>
<span class="issue_date">Issue Date: 2025-08-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2471" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CVQA: Culturally-diverse Multilingual Visual Question Answering  Benchmark, David Romero+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- CVQAã¯ã€æ–‡åŒ–çš„ã«å¤šæ§˜ãªå¤šè¨€èªã®Visual Question Answeringãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€30ã‹å›½ã‹ã‚‰ã®ç”»åƒã¨è³ªå•ã‚’å«ã¿ã€31ã®è¨€èªã¨13ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ã‚«ãƒãƒ¼ã€‚ãƒ‡ãƒ¼ã‚¿åé›†ã«ã¯ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‚’é–¢ä¸ã•ã›ã€åˆè¨ˆ10,000ã®è³ªå•ã‚’æä¾›ã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã—ã€æ–‡åŒ–çš„èƒ½åŠ›ã¨ãƒã‚¤ã‚¢ã‚¹ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ãŸãªåŸºæº–ã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2470" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages, Xiang Yue+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Pangeaã¯ã€39ã®è¨€èªã«ã‚ãŸã‚‹6MæŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆPangeaInsã‚’ç”¨ã„ã¦è¨“ç·´ã•ã‚ŒãŸå¤šè¨€èªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMã§ã‚ã‚Šã€ç•°æ–‡åŒ–é–“ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’ç¢ºä¿ã—ã¦ã„ã¾ã™ã€‚Pangeaã¯ã€47ã®è¨€èªã‚’ã‚«ãƒãƒ¼ã™ã‚‹è©•ä¾¡ã‚¹ã‚¤ãƒ¼ãƒˆPangeaBenchã§æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€è‹±èªãƒ‡ãƒ¼ã‚¿ã®æ¯”ç‡ã‚„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«ã®é‡è¦æ€§ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã€ã‚³ãƒ¼ãƒ‰ã€è¨“ç·´æ¸ˆã¿ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã•ã‚Œã€è¨€èªçš„ãŠã‚ˆã³æ–‡åŒ–çš„å…¬å¹³æ€§ã‚’æ¨é€²ã—ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2453" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning  in AI, Elliot Glazer+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- FrontierMathã¯ã€å°‚é–€ã®æ•°å­¦è€…ã«ã‚ˆã£ã¦ä½œæˆã•ã‚ŒãŸé›£æ˜“åº¦ã®é«˜ã„æ•°å­¦å•é¡Œã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€æ•°è«–ã‚„å®Ÿè§£æã‹ã‚‰ä»£æ•°å¹¾ä½•å­¦ã‚„åœè«–ã¾ã§å¹…åºƒã„åˆ†é‡ã‚’ã‚«ãƒãƒ¼ã€‚å•é¡Œè§£æ±ºã«ã¯æ•°æ™‚é–“ã‹ã‚‰æ•°æ—¥ã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚Šã€ç¾åœ¨ã®AIãƒ¢ãƒ‡ãƒ«ã¯å•é¡Œã®2%æœªæº€ã—ã‹è§£æ±ºã§ãã¦ã„ãªã„ã€‚FrontierMathã¯AIã®æ•°å­¦çš„èƒ½åŠ›ã®é€²æ—ã‚’å®šé‡åŒ–ã™ã‚‹ãŸã‚ã®å³å¯†ãªãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã‚’æä¾›ã™ã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/Trustfulness.html" target="_blank" rel="noopener noreferrer">#Trustfulness</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2448" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Measuring short-form factuality in large language models, Jason Wei+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- SimpleQAã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®çŸ­ã„äº‹å®Ÿã«é–¢ã™ã‚‹è³ªå•ã¸ã®å¿œç­”èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚Šã€æŒ‘æˆ¦çš„ã‹ã¤è©•ä¾¡ãŒå®¹æ˜“ãªè³ªå•ã‚’ç‰¹å¾´ã¨ã™ã‚‹ã€‚å„å›ç­”ã¯æ­£è§£ã€ä¸æ­£è§£ã€æœªè©¦è¡Œã®ã„ãšã‚Œã‹ã¨ã—ã¦è©•ä¾¡ã•ã‚Œã€ç†æƒ³çš„ãªãƒ¢ãƒ‡ãƒ«ã¯è‡ªä¿¡ãŒãªã„è³ªå•ã«ã¯æŒ‘æˆ¦ã›ãšã€æ­£è§£ã‚’å¤šãå¾—ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚SimpleQAã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒã€Œè‡ªåˆ†ãŒçŸ¥ã£ã¦ã„ã‚‹ã“ã¨ã‚’çŸ¥ã£ã¦ã„ã‚‹ã‹ã€ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ®µã§ã‚ã‚Šã€æ¬¡ä¸–ä»£ãƒ¢ãƒ‡ãƒ«ã«ã¨ã£ã¦ã‚‚é‡è¦ãªè©•ä¾¡åŸºæº–ã¨ãªã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>


<a href="https://openai.com/index/introducing-simpleqa/" target="_blank" rel="noopener noreferrer">https://openai.com/index/introducing-simpleqa/</a>


</p>
<p>å…ˆè¡Œç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2449" target="_blank" rel="noopener noreferrer">[Paper Note] TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for   Reading Comprehension, Mandar Joshi+, ACL'17</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2450" target="_blank" rel="noopener noreferrer">Natural Questions: A Benchmark for Question Answering Research, Kwiatkowski+, TACL'19</a>
<br><br>ã“ã‚Œã‚‰ã¯ã™ã§ã«é£½å’Œã—ã¦ã„ã‚‹</p>
<p>æœ€è¿‘ã‚ˆãLLMã®ãƒ™ãƒ³ãƒã§è¦‹ã‹ã‘ã‚‹SimpleQA</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2444" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Better &amp; Faster Large Language Models via Multi-token Prediction, Fabian Gloeckle+, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è¤‡æ•°ã®å°†æ¥ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’åŒæ™‚ã«äºˆæ¸¬ã™ã‚‹ã‚ˆã†ã«è¨“ç·´ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã€ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ã®å‘ä¸Šã‚’å›³ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€nå€‹ã®ç‹¬ç«‹ã—ãŸå‡ºåŠ›ãƒ˜ãƒƒãƒ‰ã‚’ç”¨ã„ã¦æ¬¡ã®nãƒˆãƒ¼ã‚¯ãƒ³ã‚’äºˆæ¸¬ã—ã€è¨“ç·´æ™‚é–“ã«ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’ã‹ã‘ãšã«ä¸‹æµã®èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ç‰¹ã«ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ææ¡ˆãƒ¢ãƒ‡ãƒ«ã¯å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€æ¨è«–æ™‚ã«æœ€å¤§3å€ã®é€Ÿåº¦å‘ä¸Šã‚‚å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>next tokenã ã‘ã§ãªãã€next 4-tokenã‚’äºˆæ¸¬ã—ã¦å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€MBPP/HumanEvalã«ãŠã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒ1.3Bã‚’è¶…ãˆãŸæ™‚ç‚¹ã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆ=åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¨ãªã‚‹ã‚ˆã†ã«èª¿æ•´ã•ã‚ŒãŸnext-token predictionï¼‰ã‚’outperformã—ã¯ã˜ã‚ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã«ã¤ã‚Œã¦æ€§èƒ½ã®å·®ãŒé¡•è‘—ã«è¡¨ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ãŠã„ã¦äº‹å‰å­¦ç¿’ã€ãŠã‚ˆã³finetuningã®åŒæ–¹ã§åŠ¹æœãŒã‚ã‚‹ã€‚ãŸã ã—ã€3.7ç¯€ã§ç¤ºã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€ã“ã‚Œã¯ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®ã¿ã“ã®ã‚ˆã†ãªé¡•è‘—ãªæ”¹å–„ãŒã¿ã‚‰ã‚Œã¦ãŠã‚Šã€è‡ªç„¶è¨€èªãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã¯ã“ã“ã¾ã§é¡•è‘—ãªæ”¹å–„ã¯ã—ã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ï¼ˆ5.1ç¯€ã§è€ƒå¯Ÿã•ã‚Œã¦ã„ãã†; æ˜¨ä»Šã®LLMã§ã¯äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã®ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã‚‹ã®ãŒæ™®é€šãªã®ã§åˆ©ç”¨ã™ã‚‹æ©æµã¯ã‚ã‚Šãã†; Abstractive Summarizationã§ã¯æ€§èƒ½ãŒæ”¹å–„ã—ã¦ã„ã‚‹(Figure6); GSM8Kã§ã¯200Bã¾ã§ã¯next 2 tokenã‚’äºˆæ¸¬ã™ã‚‹ã¨æ€§èƒ½ãŒæ”¹å–„ã—ã¦ã„ã‚‹ãŒ500B tokenå­¦ç¿’ã™ã‚‹ã¨next token predictionã®æ–¹ãŒæ€§èƒ½ãŒè‰¯ããªã‚‹ï¼‰ã€‚å…¨ä½“çš„ã«perplexityã®æ”¹å–„ï¼ˆ=æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«ãŠã„ã¦æ­£è§£ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆç¢ºç‡ã‚’æ”¹å–„ã™ã‚‹ï¼‰ã¨ã„ã†ã‚ˆã‚Šã¯ã€ãƒ¢ãƒ‡ãƒ«ã®"æœ€çµ‚çš„ãªç”Ÿæˆçµæœâ€ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ãŸè©•ä¾¡ã¨ãªã£ã¦ã„ã‚‹ã€‚<br><br>ãƒ¢ãƒ‡ãƒ«ã¯å…±æœ‰ã®ãƒˆãƒ©ãƒ³ã‚¯f_s (ãŠãã‚‰ãheadé–“ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å…±æœ‰ã—ã¦ã„ã‚‹ä¸€é€£ã®transformerãƒ–ãƒ­ãƒƒã‚¯) ã‚’æŒã£ã¦ãŠã‚Šinput x_t:1ã«å¯¾å¿œã™ã‚‹latent representation z_t:1ã‚’ç”Ÿæˆã™ã‚‹ã€‚latent representationã‚’output headã«inputã™ã‚‹ã“ã¨ã§ã€ãã‚Œãã‚Œã®headãŒåˆè¨ˆã§nå€‹ã®next tokenã‚’äºˆæ¸¬ã™ã‚‹ã€‚<br>&lt;img width="608" height="1021" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/433d69cb-5593-483b-b591-6445c482ed2e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/433d69cb-5593-483b-b591-6445c482ed2e"&lt;/a&gt;


/&gt;<br><br>next n-tokenã‚’äºˆæ¸¬ã™ã‚‹éš›ã«ã¯ã€GPUãƒ¡ãƒ¢ãƒªã‚’å¤§å¹…ã«é£Ÿã£ã¦ã—ã¾ã† ï¼ˆlogitsã®shapeãŒ(n, V)ã¨ãªã‚Šãã‚Œã‚‰ã®å‹¾é…ã‚‚ä¿æŒã—ãªã‘ã‚Œã°ãªã‚‰ãªã„) ã“ã¨ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ãªã‚‹ãŒã€f_sã¾ã§forward passã‚’å®Ÿè¡Œã—ãŸã‚‰ã€å„headã«å¯¾ã—ã¦forward/backward passã‚’é †ç•ªã«å®Ÿè¡Œã—ã¦ã€logitsã®å€¤ã¯ç ´æ£„ã—å‹¾é…ã®æƒ…å ±ã ã‘f_sã«è“„ç©ã™ã‚‹ã“ã¨ã§ã€é•·æœŸçš„ã«ä¿æŒã™ã‚‹æƒ…å ±ã‚’å„headã®ã‹ã‚‰é€†ä¼æ¬ã•ã‚ŒãŸå‹¾é…æƒ…å ±ã®ã¿ã«ã™ã‚‹ã“ã¨ã§ã“ã‚Œã‚’è§£æ±ºã—ã¦ã„ã‚‹ã€‚<br>&lt;img width="597" height="478" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/3f5ff3fc-5934-4f12-9327-23b689526464"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/3f5ff3fc-5934-4f12-9327-23b689526464"&lt;/a&gt;


/&gt;<br><br>å®Ÿéš›ã«inferenceã‚’ã™ã‚‹ã¨ãã¯next tokenã‚’äºˆæ¸¬ã™ã‚‹ãƒ˜ãƒƒãƒ‰ã®å‡ºåŠ›ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã‚’å‰æã¨ã—ã¦ã„ã‚‹ãŒã€å…¨ã¦ã®ãƒ˜ãƒƒãƒ‰ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€tæ™‚ç‚¹ã§t+nãƒˆãƒ¼ã‚¯ãƒ³ã®äºˆæ¸¬ã‚’å¯èƒ½ãªãŸã‚ã€self-speculative decodingã‚’å®Ÿæ–½ã—inference timeã‚’çŸ­ç¸®ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br>3.4ã§ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€nã®å€¤ã¯å¤§ãã‘ã‚Œã°å¤§ãã„ã»ã©è‰¯ã„ã¨ã„ã†ã‚ã‘ã§ã¯ãªãã€4ç¨‹åº¦ï¼ˆbyte levelãªãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯8 bytesï¼‰ãŒæœ€é©ãªã‚ˆã†ã§ã‚ã‚‹ã€‚ãŒã€Table1ã‚’è¦‹ã‚‹ã¨ã€ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã£ã¦ã¯n=6ãŒè‰¯ã‹ã£ãŸã‚Šï¼ˆi.e., æœ€é©ãªnã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¾å­˜ï¼‰è¤‡æ•°ã‚¨ãƒãƒƒã‚¯å­¦ç¿’ã™ã‚‹ã¨multi token predictionã®åŠ¹æœãŒè–„ããªã£ã¦ã„ãã†ï¼ˆi.e., åŒã˜ãƒˆãƒ¼ã‚¯ãƒ³ã®äºˆæ¸¬ã‚’è¤‡æ•°å›å­¦ç¿’ã™ã‚‹ã®ã§å®Ÿè³ªmulti token predictionã¨ä¼¼ãŸã‚ˆã†ãªã“ã¨ã‚’ã‚„ã£ã¦ã„ã‚‹ã€‚è¨€ã„æ›ãˆã‚‹ã¨ã€multi token predictionã¯è¤‡æ•°epochã®å­¦ç¿’ã‚’å…ˆå–ã‚Šã—ã¦ã„ã‚‹ã¨ã¿ãªã›ã‚‹ï¼Ÿï¼‰ãªã®ã¯æ³¨æ„ãŒå¿…è¦ãã†ã€‚</p>
<p>å…¨ä½“çš„ã«è¤‡æ•°epochã‚’å­¦ç¿’ã™ã‚‹ã¨æ©æµãŒãªããªã£ã¦ã„ãï¼ˆã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰ or next token predictionã‚ˆã‚Šã‚‚æ€§èƒ½ãŒæ‚ªåŒ–ã™ã‚‹ï¼ˆè‡ªç„¶è¨€èªï¼‰ã®ã§ã€LLMã®äº‹å‰å­¦ç¿’ã«ãŠã„ã¦ã€è¤‡æ•°epochã‚’å­¦ç¿’ã™ã‚‹ã‚ˆã†ãªå½“ãŸã‚Šå‰ã¿ãŸã„ãªä¸–ç•Œç·šãŒè¨ªã‚ŒãŸã‚‰ã€ã“ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã™ã‚‹ã¨æ€§èƒ½ã¯ã‚€ã—ã‚æ‚ªåŒ–ã—ãã†ãªæ°—ã¯ã™ã‚‹ã€‚</p>
<p>MBPP/HumanEval:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2439" target="_blank" rel="noopener noreferrer">[Paper Note] Program Synthesis with Large Language Models, Jacob Austin+, arXiv'21</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2438" target="_blank" rel="noopener noreferrer">[Paper Note] Evaluating Large Language Models Trained on Code, Mark Chen+, arXiv'21</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2442" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts, Lean Wang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- MoEãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹è² è·ã®ä¸å‡è¡¡ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã€è£œåŠ©æå¤±ã‚’ç”¨ã„ãªã„Loss-Free Balancingã‚’ææ¡ˆã€‚å„ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¹ã‚³ã‚¢ã«ãƒã‚¤ã‚¢ã‚¹ã‚’é©ç”¨ã—ã€è² è·ã®ãƒãƒ©ãƒ³ã‚¹ã‚’ç¶­æŒã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€å¾“æ¥ã®æ‰‹æ³•ã‚ˆã‚Šã‚‚æ€§èƒ½ã¨è² è·ãƒãƒ©ãƒ³ã‚¹ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=y1iU5czYpE" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=y1iU5czYpE</a>


</p>
<p>MoEãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ç‰¹å®šã®Expertsã«ã°ã‹ã‚Šãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãŒé›†ä¸­ã—ã€<br>- routing collapse: ExpertsãŒååˆ†ã«è¨“ç·´ã•ã‚Œã‚‹ã“ã¨ã‚’å¦¨ã’ã‚‹<br>- computation bottleneck: ExpertsãŒè¤‡æ•°ã®ãƒ‡ãƒã‚¤ã‚¹ã«åˆ†æ•£ã—ã¦ã„ã‚‹å ´åˆã€ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ãŒé›†ä¸­ã™ã‚‹ã¨è¨ˆç®—åŠ¹ç‡ãŒè½ã¡ã‚‹<br><br>ã¨ã„ã†å•é¡ŒãŒèµ·ãã‚‹ã€‚ã“ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«æ—¢å­˜ç ”ç©¶ã¯auxiliary lossã¨å‘¼ã°ã‚Œã‚‹å„ãƒˆãƒ¼ã‚¯ãƒ³ãŒé¸æŠã™ã‚‹ExpertsãŒå¹…åºƒããªã‚‹ã‚ˆã†ãªåˆ¶ç´„ã‚’å…¥ã‚Œã¦ã„ã‚‹ã€‚<br><br>æœ¬ç ”ç©¶ã§ã¯auxiliary lossã®å‹¾é…ãŒè¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦æ‚ªå½±éŸ¿ã‚’åŠã¼ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã—ã€loss freeã®balancingæ‰‹æ³•ã‚’ææ¡ˆã—ã€perplexityãŒ1B, 3B, ï¼ˆãƒªãƒãƒƒã‚¿ãƒ«ä¸­ã§13B)ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ä½ä¸‹ã™ã‚‹ã“ã¨ã‚’å®Ÿé¨“çš„ã«ç¤ºã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€ãƒªãƒãƒƒã‚¿ãƒ«ã«ãŠã„ã¦ã€downstreamã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ï¼ˆBBH, MMLU, C-Eval, CMMLUï¼‰ã«ãŠã„ã¦ã‚‚ã€æ€§èƒ½ãŒæ”¹å–„ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>æ‰‹æ³•ã¯ã‚·ãƒ³ãƒ—ãƒ«ã§ã€top-kã®expertsã‚’æ±ºã‚ã‚‹éš›ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¹ã‚³ã‚¢ã«å¯¾ã—ã¦ã€expertsã”ã¨ã®ãƒã‚¤ã‚¢ã‚¹é …ã‚’å°å…¥ã—ã€å­¦ç¿’æ™‚ã«expertsã«å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®å¤šå¯¡ã«å¿œã˜ã¦ãƒã‚¤ã‚¢ã‚¹å€¤ã‚’èª¿æ•´ã™ã‚‹ã€‚<br><br>openreviewã«ã‚ˆã‚‹ã¨ã€ä»¥ä¸‹ã®äº‹é …ãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹:<br>- å®Ÿé¨“ã§ç”¨ã„ã‚‰ã‚Œã¦ã„ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒDeepSeekMoEã«ã®ã¿ã«é™ã‚‰ã‚Œã¦ã„ã‚‹<br>- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚‚å°è¦æ¨¡ã®ã‚‚ã®ã§ã—ã‹å®Ÿé¨“ã•ã‚Œã¦ã„ãªã„(ãƒªãƒãƒƒã‚¿ãƒ«ã«ã¦ã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ«ã§ã®çµæœã‚’åæ˜ ï¼‰<br>- auxiliary lossãŒãã‚‚ãã‚‚è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã«æ‚ªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã¯å®Ÿé¨“çš„ã«ä¸€éƒ¨ç¤ºã•ã‚Œã¦ã„ã‚‹ãŒã€ç†è«–çš„ãªjustificationãŒä¸è¶³ã—ã¦ã„ã‚‹<br>- downstream taskã«å¯¾ã™ã‚‹å®Ÿé¨“çµæœãŒç„¡ã„ã“ã¨ï¼ˆãƒªãƒãƒƒã‚¿ãƒ«ã§ã“ã®ç‚¹ã«ã¤ã„ã¦ã¯ç¤ºã•ã‚ŒãŸ)<br>- related workãŒ10ä»¶ã—ã‹å¼•ç”¨ã•ã‚Œã¦ãŠã‚‰ãšã€ã‚ˆã‚ŠåŒ…æ‹¬çš„ãªliterature reviewã¨é–¢é€£ç ”ç©¶ã¨ã®é–¢ä¿‚æ€§ã«ã¤ã„ã¦ã®è­°è«–ãŒä¸è¶³ã—ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2441" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CRUXEval-X: A Benchmark for Multilingual Code Reasoning, Understanding  and Execution, Ruiyang Xu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- CRUXEVAL-Xã¨ã„ã†å¤šè¨€èªã‚³ãƒ¼ãƒ‰æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã€‚19ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã‚’å¯¾è±¡ã«ã€å„è¨€èªã§600ä»¥ä¸Šã®èª²é¡Œã‚’å«ã‚€19Kã®ãƒ†ã‚¹ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã€‚è¨€èªé–“ã®ç›¸é–¢ã‚’è©•ä¾¡ã—ã€Pythonè¨“ç·´ãƒ¢ãƒ‡ãƒ«ãŒä»–è¨€èªã§ã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2440" target="_blank" rel="noopener noreferrer">[Paper Note] CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution, Alex Gu+, arXiv'24</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2440" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CRUXEval: A Benchmark for Code Reasoning, Understanding and Execution, Alex Gu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- CRUXEvalã¨ã„ã†800ã®Pythoné–¢æ•°ã‹ã‚‰ãªã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€å…¥åŠ›äºˆæ¸¬ã¨å‡ºåŠ›äºˆæ¸¬ã®2ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’è©•ä¾¡ã€‚20ã®ã‚³ãƒ¼ãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆã—ãŸçµæœã€HumanEvalã§é«˜å¾—ç‚¹ã®ãƒ¢ãƒ‡ãƒ«ãŒCRUXEvalã§ã¯æ”¹å–„ã‚’ç¤ºã•ãªã„ã“ã¨ãŒåˆ¤æ˜ã€‚GPT-4ã¨Chain of Thoughtã‚’ç”¨ã„ãŸå ´åˆã€å…¥åŠ›äºˆæ¸¬ã§75%ã€å‡ºåŠ›äºˆæ¸¬ã§81%ã®pass@1ã‚’é”æˆã—ãŸãŒã€ã©ã®ãƒ¢ãƒ‡ãƒ«ã‚‚å®Œå…¨ã«ã¯ã‚¯ãƒªã‚¢ã§ããšã€GPT-4ã®ã‚³ãƒ¼ãƒ‰æ¨è«–èƒ½åŠ›ã®é™ç•Œã‚’ç¤ºã™ä¾‹ã‚’æä¾›ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2401" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Survey on the Memory Mechanism of Large Language Model based Agents, Zeyu Zhang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ¡ãƒ¢ãƒªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªèª¿æŸ»ã‚’ææ¡ˆã€‚ãƒ¡ãƒ¢ãƒªã®é‡è¦æ€§ã‚’è«–ã˜ã€éå»ã®ç ”ç©¶ã‚’ä½“ç³»çš„ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®å½¹å‰²ã‚’ç´¹ä»‹ã€‚æ—¢å­˜ç ”ç©¶ã®é™ç•Œã‚’åˆ†æã—ã€å°†æ¥ã®ç ”ç©¶æ–¹å‘æ€§ã‚’ç¤ºã™ã€‚ãƒªãƒã‚¸ãƒˆãƒªã‚‚ä½œæˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1954797669957968169?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<span class="issue_date">Issue Date: 2025-08-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2385" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning   Benchmark for Expert AGI, Xiang Yue+, CVPR'24</a>
<span class="snippet"><span>GPT Summary</span>- MMMUã¯ã€å¤§å­¦ãƒ¬ãƒ™ãƒ«ã®å°‚é–€çŸ¥è­˜ã¨æ„å›³çš„ãªæ¨è«–ã‚’å¿…è¦ã¨ã™ã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã®ãŸã‚ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€11,500ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è³ªå•ã‚’å«ã‚€ã€‚6ã¤ã®ä¸»è¦åˆ†é‡ã‚’ã‚«ãƒãƒ¼ã—ã€30ç¨®é¡ã®ç”»åƒã‚¿ã‚¤ãƒ—ã‚’ä½¿ç”¨ã€‚æ—¢å­˜ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ç•°ãªã‚Šã€å°‚é–€å®¶ãŒç›´é¢ã™ã‚‹ã‚¿ã‚¹ã‚¯ã«é¡ä¼¼ã—ãŸèª²é¡Œã‚’æä¾›ã€‚GPT-4Vã¨Geminiã®è©•ä¾¡ã§ã¯ã€56%ã¨59%ã®ç²¾åº¦ã«ã¨ã©ã¾ã‚Šã€æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚MMMUã¯æ¬¡ä¸–ä»£ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>MMMUã®ãƒªãƒªãƒ¼ã‚¹ã‹ã‚‰20ãƒ¶æœˆçµŒéã—ãŸãŒã€ã„ã¾ã ã«äººé–“ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«ã¯åŠã°ãªã„ã¨ã®ã“ã¨<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xiangyue96/status/1953902213790830931?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MMMUã®ã‚µãƒ³ãƒ—ãƒ«ã¯ã“ã¡ã‚‰ã€‚å„åˆ†é‡ã”ã¨ã«å°‚é–€å®¶ãƒ¬ãƒ™ãƒ«ã®çŸ¥è­˜ã¨æ¨è«–ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã¨ã®ã“ã¨ã€‚<br><img src="https://github.com/user-attachments/assets/90839a16-d7d2-499d-b2d8-52dab8988e52" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2025-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2378" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] VERISCORE: Evaluating the factuality of verifiable claims in long-form  text generation, Yixiao Song+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- VERISCOREã¨ã„ã†æ–°ã—ã„æŒ‡æ¨™ã‚’ææ¡ˆã—ã€æ¤œè¨¼å¯èƒ½ãªä¸»å¼µã¨æ¤œè¨¼ä¸å¯èƒ½ãªä¸»å¼µã®ä¸¡æ–¹ã‚’å«ã‚€é•·æ–‡ç”Ÿæˆã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã€‚äººé–“è©•ä¾¡ã§ã¯VERISCOREãŒä»–ã®æ–¹æ³•ã‚ˆã‚Šã‚‚ç†ã«ã‹ãªã£ã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã€16ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ãŸçµæœã€GPT-4oãŒæœ€ã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸãŒã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆãƒ¢ãƒ‡ãƒ«ã‚‚å·®ã‚’ç¸®ã‚ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚ã¾ãŸã€ç•°ãªã‚‹ã‚¿ã‚¹ã‚¯é–“ã§VERISCOREã®ç›¸é–¢ãŒãªã„ã“ã¨ã‹ã‚‰ã€äº‹å®Ÿæ€§è©•ä¾¡ã®æ‹¡å¼µãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®å¿œç­”ã‹ã‚‰verifiableãªclaimã®ã¿ã‚’æŠ½å‡ºã—ã€ãã‚Œã‚’å¤–éƒ¨ã®æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆgoogleæ¤œç´¢ï¼‰ã®ã‚¯ã‚¨ãƒªã¨ã—ã¦å…¥åŠ›ã€‚æ¤œç´¢çµæœã‹ã‚‰claimãŒsupportã•ã‚Œã‚‹ã‹å¦ã‹ã‚’LLMã«ã‚ˆã£ã¦åˆ¤æ–­ã—ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/495a7952-8240-4b3b-8b8c-c0c52dea0e74" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-08-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2374" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LongBench: A Bilingual, Multitask Benchmark for Long Context   Understanding, Yushi Bai+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç†è§£ã®ãŸã‚ã®åˆã®ãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«ãƒ»ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒLongBenchã€ã‚’ææ¡ˆã€‚è‹±èªã¨ä¸­å›½èªã§21ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å«ã¿ã€å¹³å‡é•·ã¯ãã‚Œãã‚Œ6,711èªã¨13,386æ–‡å­—ã€‚ã‚¿ã‚¹ã‚¯ã¯QAã€è¦ç´„ã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ãªã©å¤šå²ã«ã‚ãŸã‚‹ã€‚è©•ä¾¡çµæœã‹ã‚‰ã€å•†æ¥­ãƒ¢ãƒ‡ãƒ«ã¯ä»–ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ãŒã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã¯ä¾ç„¶ã¨ã—ã¦èª²é¡ŒãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>PLaMo Primeã®é•·æ–‡ãƒ†ã‚­ã‚¹ãƒˆè©•ä¾¡ã«åˆ©ç”¨ã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆä¸­å›½èªã¨è‹±èªã®ãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ã‚ã‚Šæ—¥æœ¬èªã¯å­˜åœ¨ã—ãªã„ï¼‰<br><br>PLaMo Primeãƒªãƒªãƒ¼ã‚¹ã«ãŠã‘ã‚‹æ©Ÿèƒ½æ”¹å–„: 


<a href="https://tech.preferred.jp/ja/blog/plamo-prime-release-feature-update/" target="_blank" rel="noopener noreferrer">https://tech.preferred.jp/ja/blog/plamo-prime-release-feature-update/</a>


<br><br>ã‚¿ã‚¹ã‚¯ã¨è¨€èªã”ã¨ã®Lengthã®åˆ†å¸ƒã€‚è‹±èªã®æ–¹ãŒãƒ‡ãƒ¼ã‚¿ãŒè±Šå¯Œã§ã€é•·ã„ã‚‚ã®ã ã¨30000--40000ã‚‚ã®lengthã®ã‚µãƒ³ãƒ—ãƒ«ã‚‚ã‚ã‚‹æ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/a1104f3f-996a-4ad9-b6c3-55b2eb7921ab" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2372" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Visual Prompting in Multimodal Large Language Models: A Survey, Junda Wu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã¯ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆMLLMsï¼‰ã«ãŠã‘ã‚‹è¦–è¦šçš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã®åŒ…æ‹¬çš„ãªèª¿æŸ»ã‚’è¡Œã„ã€è¦–è¦šçš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆã‚„æ§‹æˆçš„æ¨è«–ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå­¦ç¿’ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚æ—¢å­˜ã®è¦–è¦šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åˆ†é¡ã—ã€è‡ªå‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ³¨é‡ˆã®ç”Ÿæˆæ‰‹æ³•ã‚’è­°è«–ã€‚è¦–è¦šã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¨ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³LLMã®æ•´åˆæ€§ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã‚„ã€ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã¨æ–‡è„ˆå†…å­¦ç¿’ã«ã‚ˆã‚‹è¦–è¦šçš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç†è§£å‘ä¸Šã«ã¤ã„ã¦ã‚‚è¿°ã¹ã¦ã„ã¾ã™ã€‚æœ€å¾Œã«ã€MLLMsã«ãŠã‘ã‚‹è¦–è¦šçš„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã®æœªæ¥ã«é–¢ã™ã‚‹ãƒ“ã‚¸ãƒ§ãƒ³ã‚’æç¤ºã—ã¾ã™ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<span class="issue_date">Issue Date: 2025-08-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2371" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Controllable Generation with Text-to-Image Diffusion Models: A Survey, Pu Cao+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¯ãƒ†ã‚­ã‚¹ãƒˆèª˜å°ç”Ÿæˆã«ãŠã„ã¦å¤§ããªé€²å±•ã‚’é‚ã’ãŸãŒã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§ã¯å¤šæ§˜ãªè¦æ±‚ã«å¿œãˆã‚‰ã‚Œãªã„ã€‚æœ¬èª¿æŸ»ã§ã¯ã€T2Iæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®åˆ¶å¾¡å¯èƒ½ãªç”Ÿæˆã«é–¢ã™ã‚‹æ–‡çŒ®ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ç†è«–çš„åŸºç›¤ã¨å®Ÿè·µçš„é€²å±•ã‚’ã‚«ãƒãƒ¼ã€‚ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°æ‹¡æ•£ç¢ºç‡ãƒ¢ãƒ‡ãƒ«ã®åŸºæœ¬ã‚’ç´¹ä»‹ã—ã€åˆ¶å¾¡ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’åˆ†æã€‚ç”Ÿæˆæ¡ä»¶ã®ç•°ãªã‚‹ã‚«ãƒ†ã‚´ãƒªã«æ•´ç†ã—ãŸæ–‡çŒ®ãƒªã‚¹ãƒˆã‚’æä¾›ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-08-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2368" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for   Sparse Architectural Large Language Models, Zihan Wang+, EMNLP'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Mixture-of-Expertsï¼ˆMoEï¼‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æŒã¤å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«å¯¾ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡ã®è‰¯ã„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆPEFTï¼‰æ‰‹æ³•ã‚’ææ¡ˆã€‚ä¸»ãªå†…å®¹ã¯ã€(1) ã‚¿ã‚¹ã‚¯ã”ã¨ã®å°‚é–€å®¶ã®æ´»æ€§åŒ–åˆ†å¸ƒã®é›†ä¸­åº¦ã®èª¿æŸ»ã€(2) Expert-Specialized Fine-Tuningï¼ˆESFTï¼‰ã®ææ¡ˆã¨ãã®åŠ¹æœã€(3) MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å°‚é–€å®¶ç‰¹åŒ–å‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¸ã®å½±éŸ¿ã®åˆ†æã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ESFTãŒãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã€ãƒ•ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«åŒ¹æ•µã¾ãŸã¯ãã‚Œã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wzihanw/status/1952965138845450413?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æŒã¤LLMã«ãŠã„ã¦ã€finetuningã‚’å®Ÿæ–½ã—ãŸã„ã‚¿ã‚¹ã‚¯ã«é–¢é€£ã™ã‚‹å°‚é–€å®¶ã‚’ç‰¹å®šã—ã€ãã®ã»ã‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’freezeã—ãŸä¸Šã§å½“è©²å°‚é–€å®¶ã®ã¿ã‚’trainableã¨ã™ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ã«finetuningã‚’å®Ÿæ–½ã™ã‚‹æ‰‹æ³•<br><img src="https://github.com/user-attachments/assets/ba82f425-5b61-4ce7-803b-4eb3fb375c41" alt="image" loading="lazy"><br><br>å°‚é–€å®¶ã‚’è¦‹ã¤ã‘ã‚‹éš›ã«ã¯å°‚é–€å®¶ã”ã¨ã«finetuningã—ãŸã„ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹relevance scoreã‚’è¨ˆç®—ã™ã‚‹ã€‚ãã®ãŸã‚ã«ã€2ã¤ã®æ‰‹æ³•ãŒææ¡ˆã•ã‚Œã¦ãŠã‚Šã€training dataã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—<br>- å…¨ã¦ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸãƒ‡ãƒ¼ã‚¿ã®å„ãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ã®MoE Routerã®gateã®å€¤ã®å¹³å‡å€¤ã‚’relevant scoreã¨ã™ã‚‹æ–¹æ³•<br>- å…¨ã¦ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸãƒ‡ãƒ¼ã‚¿ã®å„ãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ã«é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã®å‰²åˆ<br>ã®2ç¨®é¡ã§ã‚¹ã‚³ã‚¢ã‚’æ±‚ã‚ã‚‹ã€‚é–¾å€¤pã‚’æ±ºå®šã—ã€é–¾å€¤ä»¥ä¸Šã®ã‚¹ã‚³ã‚¢ã‚’æŒã¤å°‚é–€å®¶ã‚’trainableã¨ã™ã‚‹ã€‚<br><br>LoRAã‚ˆã‚Šã‚‚math, codeãªã©ã®ä»–ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ã‚¿ã‚¹ã‚¯æ€§èƒ½ã‚’åŠ£åŒ–ã•ã›ãšã€Finetuningå¯¾è±¡ã®ã‚¿ã‚¹ã‚¯ã§FFTã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã€‚<br><img src="https://github.com/user-attachments/assets/302eebda-bace-4b99-bb73-5e7e3ce10448" alt="image" loading="lazy"><br><br>LoRAã¨åŒæ§˜ã«FFTã¨æ¯”è¼ƒã—å­¦ç¿’æ™‚é–“ã¯çŸ­ç¸®ã•ã‚Œã€å­¦ç¿’ã—ãŸå°‚é–€å®¶ã®é‡ã¿ã‚’ä¿æŒã™ã‚‹ã ã‘ã§è‰¯ã„ã®ã§ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚‚ç¯€ç´„ã§ãã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/b02a8d53-6967-4dd2-9290-de06f27e48c9" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2338" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] YaRN: Efficient Context Window Extension of Large Language Models, Bowen Peng+, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- YaRNï¼ˆYet another RoPE extensioN methodï¼‰ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹ä½ç½®æƒ…å ±ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’åŠ¹ç‡çš„ã«è¡Œã„ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’å¾“æ¥ã®æ–¹æ³•ã‚ˆã‚Šã‚‚10å€å°‘ãªã„ãƒˆãƒ¼ã‚¯ãƒ³ã¨2.5å€å°‘ãªã„è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—ã§æ‹¡å¼µã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚LLaMAãƒ¢ãƒ‡ãƒ«ãŒé•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åŠ¹æœçš„ã«åˆ©ç”¨ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã€128kã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã¾ã§å†ç¾å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=wHBfxhZu1u" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=wHBfxhZu1u</a>


</p>
<p>ç¾åœ¨ä¸»æµãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ‹¡å¼µæ‰‹æ³•ã€‚æ§˜ã€…ãªãƒ¢ãƒ‡ãƒ«ã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚</p>
<p>æ—¥æœ¬èªè§£èª¬:


<a href="https://zenn.dev/bilzard/scraps/de7ecd3c380b6e" target="_blank" rel="noopener noreferrer">https://zenn.dev/bilzard/scraps/de7ecd3c380b6e</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/AES(AutomatedEssayScoring).html" target="_blank" rel="noopener noreferrer">#AES(AutomatedEssayScoring)</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AIED.html" target="_blank" rel="noopener noreferrer">#AIED</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2316" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Impact of Example Selection in Few-Shot Prompting on Automated Essay   Scoring Using GPT Models, Lui Yoshida, AIED'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€GPTãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå°‘æ•°ã‚·ãƒ§ãƒƒãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã«ãŠã‘ã‚‹ä¾‹ã®é¸æŠãŒè‡ªå‹•ã‚¨ãƒƒã‚»ã‚¤æ¡ç‚¹ï¼ˆAESï¼‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã€‚119ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”¨ã„ã¦ã€GPT-3.5ã¨GPT-4ã®ãƒ¢ãƒ‡ãƒ«é–“ã§ã®ã‚¹ã‚³ã‚¢ä¸€è‡´ã‚’äºŒæ¬¡é‡ã¿ä»˜ãã‚«ãƒƒãƒ‘ï¼ˆQWKï¼‰ã§æ¸¬å®šã€‚çµæœã€ä¾‹ã®é¸æŠãŒãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ç•°ãªã‚‹å½±éŸ¿ã‚’åŠã¼ã—ã€ç‰¹ã«GPT-3.5ã¯ãƒã‚¤ã‚¢ã‚¹ã®å½±éŸ¿ã‚’å—ã‘ã‚„ã™ã„ã“ã¨ãŒåˆ¤æ˜ã€‚æ…é‡ãªä¾‹ã®é¸æŠã«ã‚ˆã‚Šã€GPT-3.5ãŒä¸€éƒ¨ã®GPT-4ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŒã€GPT-4ã¯æœ€ã‚‚é«˜ã„å®‰å®šæ€§ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€AESã«ãŠã‘ã‚‹ä¾‹ã®é¸æŠã®é‡è¦æ€§ã¨ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ã®å¿…è¦æ€§ãŒå¼·èª¿ã•ã‚Œã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/MLSys.html" target="_blank" rel="noopener noreferrer">#MLSys</a>
<span class="issue_date">Issue Date: 2025-07-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2264" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AWQ: Activation-aware Weight Quantization for LLM Compression and   Acceleration, Ji Lin+, MLSys'24</a>
<span class="snippet"><span>GPT Summary</span>- Activation-aware Weight Quantizationï¼ˆAWQï¼‰ã‚’ææ¡ˆã—ã€LLMã®ä½ãƒ“ãƒƒãƒˆé‡ã¿é‡å­åŒ–ã‚’åŠ¹ç‡åŒ–ã€‚é¡•è‘—ãªé‡ã¿ãƒãƒ£ãƒãƒ«ã‚’ä¿è­·ã™ã‚‹ã“ã¨ã§é‡å­åŒ–èª¤å·®ã‚’å‰Šæ¸›ã—ã€ç•°ãªã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ä¸€èˆ¬åŒ–å¯èƒ½ã€‚AWQã¯è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€4ãƒ“ãƒƒãƒˆã®ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹LLM/VLMå‘ã‘æ¨è«–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯TinyChatã‚’å®Ÿè£…ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ãŠã‚ˆã³ãƒ¢ãƒã‚¤ãƒ«GPUã§ã®å‡¦ç†é€Ÿåº¦ã‚’3å€ä»¥ä¸Šå‘ä¸Šã•ã›ã€70B Llama-2ãƒ¢ãƒ‡ãƒ«ã®å±•é–‹ã‚’å®¹æ˜“ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://qiita.com/kyad/items/96a4a2bdec3f0dc09d23" target="_blank" rel="noopener noreferrer">https://qiita.com/kyad/items/96a4a2bdec3f0dc09d23</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/DataFiltering.html" target="_blank" rel="noopener noreferrer">#DataFiltering</a>
<span class="issue_date">Issue Date: 2025-07-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2262" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Laws for Data Filtering -- Data Curation cannot be Compute   Agnostic, Sachin Goyal+, CVPR'24</a>
<span class="snippet"><span>GPT Summary</span>- è¦–è¦šã¨è¨€èªã®ãƒ¢ãƒ‡ãƒ«ï¼ˆVLMsï¼‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦ã€é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãŒé‡è¦ã§ã‚ã‚‹ãŒã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã¨ã¯ç„¡é–¢ä¿‚ã«è¡Œã‚ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã¨é‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ï¼ˆQQTï¼‰ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ã‚¦ã‚§ãƒ–ãƒ‡ãƒ¼ã‚¿ã®éå‡è³ªæ€§ã‚’è€ƒæ…®ã—ãŸãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‡ãƒ¼ã‚¿ã®æœ‰ç”¨æ€§ã®é•ã„ã‚„ç¹°ã‚Šè¿”ã—ä½¿ç”¨ã«ã‚ˆã‚‹åŠ£åŒ–ã‚’è©•ä¾¡ã—ã€è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¼ãƒ«ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¨å®šå¯èƒ½ã«ã™ã‚‹ã€‚æœ€é©ãªãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¼ãƒ«ã®ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é€šã˜ã¦ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã«å¿œã˜ãŸæœ€é«˜ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cloneofsimo/status/1946241642572448174?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§å¤šãã®ç ”ç©¶ãŒãƒ¢ãƒ‡ãƒ«ãŒã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’é”æˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ãŒã€é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã«ã¯é™ã‚ŠãŒã‚ã‚‹ã“ã¨ã¨ã€ç¹°ã‚Šè¿”ã—å­¦ç¿’ã‚’ã™ã‚‹ã“ã¨ã§ã™ãã«ãã®åŠ¹ç”¨ãŒä½ä¸‹ã™ã‚‹ï¼ˆQuality-Quantity tradeoff!)ã¨ã„ã†ç‰¹æ€§ãŒã‚ã‚‹ã€‚ã“ã®ã‚ˆã†ãªçŠ¶æ³ã«ãŠã„ã¦ã€ãŸã¨ãˆã°è¨ˆç®—ã®äºˆç®—ãŒãƒ‡ãƒ¼ã‚¿6ãƒ‘ã‚±ãƒƒãƒˆåˆ†ã®æ™‚ã«ã€ã‚ã¡ã‚ƒã‚ã¡ã‚ƒãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’é ‘å¼µã£gé«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¼ãƒ«Eã®ã¿ã‚’ä½¿ã£ã¦6 epochå­¦ç¿’ã™ã‚‹ã®ãŒè‰¯ã„ã®ã‹ã€å°‘ã—å“è³ªã¯è½ã¡ã‚‹ãƒ‡ãƒ¼ã‚¿Dã‚‚æ··ãœã¦E+Dã‚’3 epochå­¦ç¿’ã™ã‚‹ã®ãŒè‰¯ã„ã®ã‹ã€ã¨ãã«ã©ã¡ã‚‰ãŒè‰¯ã„ã®ã‹ï¼Ÿã¨ã„ã†è©±ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/06812781-7212-415e-bc7a-dd19ac4ca0d7" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2201" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Measuring Multimodal Mathematical Reasoning with MATH-Vision Dataset, Ke Wang+, NeurIPS'24 Datasets and Benchmarks Track</a>
<span class="snippet"><span>GPT Summary</span>- MATH-Visionï¼ˆMATH-Vï¼‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ææ¡ˆã—ã€3,040ã®è¦–è¦šçš„æ–‡è„ˆã‚’æŒã¤æ•°å­¦å•é¡Œã‚’åé›†ã€‚16ã®æ•°å­¦åˆ†é‡ã¨5ã¤ã®é›£æ˜“åº¦ã§æ§‹æˆã•ã‚Œã€LMMsã®æ•°å­¦çš„æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€LMMsã¨äººé–“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é–“ã«é¡•è‘—ãªã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ã•ã‚‰ãªã‚‹é€²å±•ã®å¿…è¦æ€§ã‚’å¼·èª¿ã€‚ã‚¨ãƒ©ãƒ¼åˆ†æã‚’é€šã˜ã¦ä»Šå¾Œã®ç ”ç©¶ã«è²´é‡ãªæ´å¯Ÿã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=QWTCcxMpPA#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=QWTCcxMpPA#discussion</a>


<br>project page: 


<a href="https://mathllm.github.io/mathvision/" target="_blank" rel="noopener noreferrer">https://mathllm.github.io/mathvision/</a>


</p>
<p>Project Pageã®ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒšãƒ¼ã‚¸ãŒéå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„ã€‚ã“ã¡ã‚‰ã¯äººé–“ã®æ–¹ãŒã¾ã ã¾ã æ€§èƒ½ãŒé«˜ãã†ã€‚<br><br>&lt;img width="671" height="806" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/586edf6d-cd77-48cb-b209-8ea819e725fc"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/586edf6d-cd77-48cb-b209-8ea819e725fc"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2025-07-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2199" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] StarCoder 2 and The Stack v2: The Next Generation, Anton Lozhkov+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- BigCodeãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€è²¬ä»»ã‚ã‚‹Code LLMsã®é–‹ç™ºã«ç„¦ç‚¹ã‚’å½“ã¦ã€StarCoder2ã‚’ç™ºè¡¨ã€‚Software Heritageã¨ææºã—ã€The Stack v2ã‚’æ§‹ç¯‰ã—ã€619ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã‚’å«ã‚€å¤§è¦æ¨¡ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚»ãƒƒãƒˆã‚’ä½œæˆã€‚StarCoder2ãƒ¢ãƒ‡ãƒ«ã¯3Bã€7Bã€15Bã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¡ã€å¾¹åº•çš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ã€‚ç‰¹ã«StarCoder2-15Bã¯ã€åŒç­‰ã®ä»–ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€æ•°å­¦ã‚„ã‚³ãƒ¼ãƒ‰æ¨è«–ã§ã‚‚é«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã€‚ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã¯OpenRAILãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§å…¬é–‹ã•ã‚Œã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®é€æ˜æ€§ã‚‚ç¢ºä¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/661" target="_blank" rel="noopener noreferrer">StarCoderBase/StarCoder, 2023</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-07-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2127" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Iterative Reasoning Preference Optimization, Richard Yuanzhe Pang+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- åå¾©çš„ãªå¥½ã¿æœ€é©åŒ–æ‰‹æ³•ã‚’ç”¨ã„ã¦ã€Chain-of-Thoughtï¼ˆCoTï¼‰å€™è£œé–“ã®æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’æœ€é©åŒ–ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’é–‹ç™ºã€‚ä¿®æ­£DPOæå¤±ã‚’ä½¿ç”¨ã—ã€æ¨è«–ã®æ”¹å–„ã‚’ç¤ºã™ã€‚Llama-2-70B-Chatãƒ¢ãƒ‡ãƒ«ã§GSM8Kã€MATHã€ARC-Challengeã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã€GSM8Kã§ã¯55.6%ã‹ã‚‰81.6%ã«æ”¹å–„ã€‚å¤šæ•°æ±ºã«ã‚ˆã‚‹ç²¾åº¦ã¯88.7%ã«é”ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=4XIKfvNYvx&referrer=%5Bthe%20profile%20of%20He%20He%5D(%2Fprofile%3Fid%3D~He_He2)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=4XIKfvNYvx&referrer=%5Bthe%20profile%20of%20He%20He%5D(%2Fprofile%3Fid%3D~He_He2)</a>


</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1212" target="_blank" rel="noopener noreferrer">Self-Rewarding Language Models, Weizhe Yuan+, N/A, ICML'24</a>
<br><br>ã¨ä¼¼ãŸã‚ˆã†ã«iterativeãªmannerã§reasoningèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/a0f10e8e-454d-40e8-ae67-8c6c2da6a0ed" alt="image" loading="lazy"><br><br>ãŸã ã—ã€loss functionã¨ã—ã¦ã¯ã€chosenãªCoT+yã®responseã«å¯¾ã—ã¦ã€reasoning traceã‚’ç”Ÿæˆã™ã‚‹èƒ½åŠ›ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã€NLL Lossã‚‚é©ç”¨ã—ã¦ã„ã‚‹ç‚¹ã«æ³¨æ„ã€‚<br><img src="https://github.com/user-attachments/assets/5ae2dcba-09c8-4618-9b63-ae6aed5b234d" alt="image" loading="lazy"><br><br>32 samplesã®majority votingã«ã‚ˆã£ã¦ã‚ˆã‚Šé«˜ã„æ€§èƒ½ãŒé”æˆã§ãã¦ã„ã‚‹ã®ã§ã€å¤šæ§˜ãªreasoning traceãŒç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/PRM.html" target="_blank" rel="noopener noreferrer">#PRM</a>
<span class="issue_date">Issue Date: 2025-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2103" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Let's Verify Step by Step, Hunter Lightman+, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å¤šæ®µéšæ¨è«–èƒ½åŠ›ãŒå‘ä¸Šã™ã‚‹ä¸­ã€è«–ç†çš„èª¤ã‚ŠãŒä¾ç„¶ã¨ã—ã¦å•é¡Œã§ã‚ã‚‹ã€‚ä¿¡é ¼æ€§ã®é«˜ã„ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ãŸã‚ã«ã¯ã€çµæœç›£è¦–ã¨ãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–ã®æ¯”è¼ƒãŒé‡è¦ã§ã‚ã‚‹ã€‚ç‹¬è‡ªã®èª¿æŸ»ã«ã‚ˆã‚Šã€ãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–ãŒMATHãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å•é¡Œè§£æ±ºã«ãŠã„ã¦çµæœç›£è¦–ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã€78%ã®å•é¡Œã‚’è§£æ±ºã—ãŸã€‚ã¾ãŸã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãŒãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–ã®åŠ¹æœã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚‚ç¤ºã—ãŸã€‚é–¢é€£ç ”ç©¶ã®ãŸã‚ã«ã€80ä¸‡ã®äººé–“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ©ãƒ™ãƒ«ã‹ã‚‰ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆPRM800Kã‚’å…¬é–‹ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=v8L0pN6EOi" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=v8L0pN6EOi</a>


</p>
<p>PRM800K:


<a href="https://github.com/openai/prm800k/tree/main" target="_blank" rel="noopener noreferrer">https://github.com/openai/prm800k/tree/main</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2102" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] RewardBench: Evaluating Reward Models for Language Modeling, Nathan Lambert+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å ±é…¬ãƒ¢ãƒ‡ãƒ«ï¼ˆRMsï¼‰ã®è©•ä¾¡ã«é–¢ã™ã‚‹ç ”ç©¶ã¯å°‘ãªãã€æˆ‘ã€…ã¯ãã®ç†è§£ã‚’æ·±ã‚ã‚‹ãŸã‚ã«RewardBenchã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€ãƒãƒ£ãƒƒãƒˆã‚„æ¨è«–ã€å®‰å…¨æ€§ã«é–¢ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã§ã€å ±é…¬ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹ã€‚ç‰¹å®šã®æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€å¥½ã¾ã‚Œã‚‹ç†ç”±ã‚’æ¤œè¨¼å¯èƒ½ãªå½¢ã§ç¤ºã—ã€ã•ã¾ã–ã¾ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã«ã‚ˆã‚‹å ±é…¬ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã‚’è¡Œã†ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å ±é…¬ãƒ¢ãƒ‡ãƒ«ã®æ‹’å¦å‚¾å‘ã‚„æ¨è«–ã®é™ç•Œã«ã¤ã„ã¦ã®çŸ¥è¦‹ã‚’å¾—ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2096" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Chat Vector: A Simple Approach to Equip LLMs with Instruction Following   and Model Alignment in New Languages, Shih-Cheng Huang+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å¤šãã¯è‹±èªã«åã£ã¦ã„ã‚‹å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€chat vectorã¨ã„ã†æ¦‚å¿µã‚’å°å…¥ã€‚ã“ã‚Œã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‹ã‚‰ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’å¼•ãã“ã¨ã§ç”Ÿæˆã•ã‚Œã€è¿½åŠ ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã«æ–°ã—ã„è¨€èªã§ã®ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã‚’ä»˜ä¸ã§ãã‚‹ã€‚å®Ÿè¨¼ç ”ç©¶ã§ã¯ã€æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã‚„æœ‰å®³æ€§ã®è»½æ¸›ã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å¯¾è©±ã«ãŠã„ã¦chat vectorã®åŠ¹æœã‚’ç¤ºã—ã€ã•ã¾ã–ã¾ãªè¨€èªã‚„ãƒ¢ãƒ‡ãƒ«ã§ã®é©å¿œæ€§ã‚’ç¢ºèªã€‚chat vectorã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«å¯¾è©±æ©Ÿèƒ½ã‚’åŠ¹ç‡çš„ã«å®Ÿè£…ã™ã‚‹ãŸã‚ã®æœ‰åŠ›ãªè§£æ±ºç­–ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://qiita.com/jovyan/items/ee6affa5ee5bdaada6b4" target="_blank" rel="noopener noreferrer">https://qiita.com/jovyan/items/ee6affa5ee5bdaada6b4</a>


</p>
<p>ä¸‹è¨˜ãƒ–ãƒ­ã‚°ã«ã‚ˆã‚‹ã¨Chatã ã‘ã§ã¯ãªãã€Reasoningã§ã‚‚ï¼ˆpost-trainingãŒå¿…è¦ã ãŒï¼‰ä½¿ãˆã‚‹æ¨¡æ§˜<br><br>Reasoningèƒ½åŠ›ã‚’ä»˜ä¸ã—ãŸLLM ABEJA-QwQ32b-Reasoning-Japanese-v1.0ã®å…¬é–‹, Abeja Tech Blog, 2025.04:<br>


<a href="https://tech-blog.abeja.asia/entry/geniac2-qwen25-32b-reasoning-v1.0" target="_blank" rel="noopener noreferrer">https://tech-blog.abeja.asia/entry/geniac2-qwen25-32b-reasoning-v1.0</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/PPO%20(ProximalPolicyOptimization).html" target="_blank" rel="noopener noreferrer">#PPO (ProximalPolicyOptimization)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2090" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy   Data, Fahim Tajwar+, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- å¥½ã¿ã®ãƒ©ãƒ™ãƒ«ã‚’ç”¨ã„ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«é–¢ã™ã‚‹ç ”ç©¶ã€‚ã‚ªãƒ³ãƒãƒªã‚·ãƒ¼å¼·åŒ–å­¦ç¿’ã‚„å¯¾ç…§å­¦ç¿’ãªã©ã®æ‰‹æ³•ã‚’æ¯”è¼ƒã—ã€ã‚ªãƒ³ãƒãƒªã‚·ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚„è² ã®å‹¾é…ã‚’ç”¨ã„ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå„ªã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒã®ç‰¹å®šã®ãƒ“ãƒ³ã«ãŠã‘ã‚‹ç¢ºç‡è³ªé‡ã‚’è¿…é€Ÿã«å¤‰æ›´ã§ãã‚‹ãƒ¢ãƒ¼ãƒ‰æ¢ç´¢ç›®çš„ã®é‡è¦æ€§ã‚’ç¤ºã—ã€ãƒ‡ãƒ¼ã‚¿åé›†ã®æœ€é©åŒ–ã«é–¢ã™ã‚‹æ´å¯Ÿã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹ã®ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ vs. ã‚ªãƒ³ãƒ©ã‚¤ãƒ³RLã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§æœ¬ç ”ç©¶ãŒå¼•ç”¨ã•ã‚Œã¦ã„ã‚‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cwolferesearch/status/1965088925510520853?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2089" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Instruction Pre-Training: Language Models are Supervised Multitask   Learners, Daixuan Cheng+, EMNLP'24</a>
<span class="snippet"><span>GPT Summary</span>- ç„¡ç›£ç£ã®ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯äº‹å‰å­¦ç¿’ã«åŠ ãˆã€ç›£è¦–ã•ã‚ŒãŸãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®å¯èƒ½æ€§ã‚’æ¢ã‚‹ãŸã‚ã«ã€Instruction Pre-Trainingãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚æŒ‡ç¤ºå¿œç­”ãƒšã‚¢ã‚’ç”Ÿæˆã—ã€2å„„ã®ãƒšã‚¢ã‚’åˆæˆã—ã¦å®Ÿé¨“ã‚’è¡Œã„ã€äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚Instruction Pre-Trainingã¯Llama3-8Bã‚’Llama3-70Bã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã«å¼•ãä¸Šã’ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2051" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Comparative Study of PDF Parsing Tools Across Diverse Document  Categories, Narayan S. Adhikari+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€DocLayNetãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦10ã®äººæ°—PDFãƒ‘ãƒ¼ã‚¹ãƒ„ãƒ¼ãƒ«ã‚’6ã¤ã®æ–‡æ›¸ã‚«ãƒ†ã‚´ãƒªã«ã‚ãŸã‚Šæ¯”è¼ƒã—ã€æƒ…å ±æŠ½å‡ºã®åŠ¹æœã‚’è©•ä¾¡ã—ã¾ã—ãŸã€‚ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã§ã¯PyMuPDFã¨pypdfiumãŒå„ªã‚ŒãŸçµæœã‚’ç¤ºã—ã€ç‰¹ã«ç§‘å­¦æ–‡æ›¸ã‚„ç‰¹è¨±æ–‡æ›¸ã§ã¯NougatãŒé«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã—ãŸã€‚è¡¨æ¤œå‡ºã§ã¯TATRãŒé‡‘èã‚„æ³•å¾‹æ–‡æ›¸ã§å„ªã‚ŒãŸçµæœã‚’ç¤ºã—ã€Camelotã¯å…¥æœ­æ–‡æ›¸ã§æœ€ã‚‚è‰¯ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸé©åˆ‡ãªãƒ‘ãƒ¼ã‚¹ãƒ„ãƒ¼ãƒ«ã®é¸æŠãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>PDFã®parsingãƒ„ãƒ¼ãƒ«ã«ã¤ã„ã¦ã€text, tableæŠ½å‡ºã®æ€§èƒ½ã‚’æ§˜ã€…ãªãƒ„ãƒ¼ãƒ«ã¨åˆ†é‡åˆ¥ã«è©•ä¾¡ã—ã¦ã„ã‚‹ã€‚<br><br>F1, precision, recallãªã©ã¯ã€ground truthã¨ã®ãƒ¬ãƒ¼ãƒ™ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³è·é›¢ã‹ã‚‰similarityã‚’è¨ˆç®—ã—ã€0.7ä»¥ä¸Šã§ã‚ã‚Œã°true positiveã¨ã¿ãªã™ã“ã¨ã§è¨ˆç®—ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚local alignmentã¯ã€ãƒãƒƒãƒã—ãŸå ´åˆã«åŠ ç‚¹ã€ãƒŸã‚¹ãƒãƒƒãƒã€æœªæ¤œå‡ºã®å ´åˆã«ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’èª²ã™ã‚ˆã†ãªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã®æŠ½å‡ºæ€§èƒ½ã‚’æ¸¬ã‚‹æŒ‡æ¨™ãªæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/2d2e114f-cc47-4d7d-906a-c505c793d675" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/ccc79865-83d3-47b6-bb47-f2c0a28990c7" alt="image" loading="lazy"></p>
<p>ã‚ˆã‚Šæ€§èƒ½ã‚’é«˜ãã—ãŸã‘ã‚Œã°ã“ã¡ã‚‰ã‚‚å‚è€ƒã«:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jerryjliu0/status/1934988910448492570?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1992" target="_blank" rel="noopener noreferrer" class="title-link">Densing Law of LLMs, Chaojun Xiao+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ€§èƒ½å‘ä¸Šã«ä¼´ã†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®åŠ¹ç‡ã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ã€Œã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£å¯†åº¦ã€ã¨ã„ã†æ–°ã—ã„æŒ‡æ¨™ã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆLLMã®æœ‰åŠ¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¨å®Ÿéš›ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®æ¯”ç‡ã‚’ç”¨ã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®åŠ¹æœã¨åŠ¹ç‡ã‚’è©•ä¾¡ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã™ã‚‹ã€‚åˆ†æã«ã‚ˆã‚Šã€LLMsã®ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£å¯†åº¦ã¯ç´„3ã‹æœˆã”ã¨ã«å€å¢—ã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€ä»Šå¾Œã®LLMé–‹ç™ºã«ãŠã‘ã‚‹é‡è¦æ€§ãŒå¼·èª¿ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1926785750277693859?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/user-attachments/assets/8cdcfe78-6682-481b-a6b0-a175b84d735c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-05-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1951" target="_blank" rel="noopener noreferrer" class="title-link">UltraFeedback: Boosting Language Models with Scaled AI Feedback, Ganqu Cui+, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«åŠ ãˆã€é«˜å“è³ªãªAIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è‡ªå‹•åé›†ã™ã‚‹ã“ã¨ã§ã€LLMsã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã«å®Ÿç¾ã€‚å¤šæ§˜ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚«ãƒãƒ¼ã—ã€æ³¨é‡ˆãƒã‚¤ã‚¢ã‚¹ã‚’è»½æ¸›ã—ãŸçµæœã€25ä¸‡ä»¶ã®ä¼šè©±ã«å¯¾ã™ã‚‹100ä¸‡ä»¶ä»¥ä¸Šã®GPT-4ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒUltraFeedbackã€ã‚’æ§‹ç¯‰ã€‚ã“ã‚Œã«åŸºã¥ãã€LLaMAãƒ¢ãƒ‡ãƒ«ã‚’å¼·åŒ–å­¦ç¿’ã§ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã—ã€ãƒãƒ£ãƒƒãƒˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ã€‚ç ”ç©¶ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã«ãŠã‘ã‚‹AIãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼ã€‚ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ä¸­ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-05-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1950" target="_blank" rel="noopener noreferrer" class="title-link">ORPO: Monolithic Preference Optimization without Reference Model, Jiwoo Hong+, EMNLP'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€å¥½ã¿ã®æ•´åˆæ€§ã«ãŠã‘ã‚‹ç›£è¦–ä»˜ããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã€ã‚ãšã‹ãªãƒšãƒŠãƒ«ãƒ†ã‚£ã§å¥½ã¿ã«æ•´åˆã—ãŸSFTãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ã•ã‚‰ã«ã€è¿½åŠ ã®æ•´åˆæ€§ãƒ•ã‚§ãƒ¼ã‚ºã‚’å¿…è¦ã¨ã—ãªã„æ–°ã—ã„ã‚ªãƒƒã‚ºæ¯”æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ORPOã‚’ææ¡ˆã—ã€ã“ã‚Œã‚’ç”¨ã„ã¦è¤‡æ•°ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸçµæœã€æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ã–ã£ãã‚Šè¨€ã†ã¨instruction tuningã¨alignmentã‚’åŒæ™‚ã«ã§ãã‚‹æ‰‹æ³•ã‚‰ã—ã„ãŒã¾ã ç†è§£ã§ãã¦ã„ãªã„</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-05-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1947" target="_blank" rel="noopener noreferrer" class="title-link">EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language   Models, Peng Wang+, ACL'24, ï¼ˆSystem Demonstrationsï¼‰</a>
<span class="snippet"><span>GPT Summary</span>- EasyEditã¯ã€LLMsã®ãŸã‚ã®ä½¿ã„ã‚„ã™ã„çŸ¥è­˜ç·¨é›†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ã•ã¾ã–ã¾ãªçŸ¥è­˜ç·¨é›†ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ã‚µãƒãƒ¼ãƒˆã€‚LlaMA-2ã®å®Ÿé¨“çµæœã§ã¯ã€ä¿¡é ¼æ€§ã¨ä¸€èˆ¬åŒ–ã®é¢ã§å¾“æ¥ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚GitHubã§ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã—ã€Google Colabãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚„ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚‚æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>ver2.0:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1946" target="_blank" rel="noopener noreferrer">EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language
  Models, Ziwen Xu+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Trustfulness.html" target="_blank" rel="noopener noreferrer">#Trustfulness</a>
<span class="issue_date">Issue Date: 2025-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1945" target="_blank" rel="noopener noreferrer" class="title-link">æ—¥æœ¬èªTrustfulQAã®æ§‹ç¯‰, ä¸­æ‘+, NLP'24</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1943" target="_blank" rel="noopener noreferrer" class="title-link">DataComp-LM: In search of the next generation of training sets for  language models, Jeffrey Li+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- DataComp for Language Modelsï¼ˆDCLMï¼‰ã‚’ç´¹ä»‹ã—ã€240Tãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã¨53ã®è©•ä¾¡ã‚¹ã‚¤ãƒ¼ãƒˆã‚’æä¾›ã€‚DCLMã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚±ãƒ¼ãƒ«412Mã‹ã‚‰7Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥ã‚’å®Ÿé¨“å¯èƒ½ã€‚DCLM-Baselineã¯2.6Tãƒˆãƒ¼ã‚¯ãƒ³ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€MMLUã§64%ã®ç²¾åº¦ã‚’é”æˆã—ã€å¾“æ¥ã®MAP-Neoã‚ˆã‚Š6.6ãƒã‚¤ãƒ³ãƒˆæ”¹å–„ã€‚è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚‚40%å‰Šæ¸›ã€‚çµæœã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­è¨ˆã®é‡è¦æ€§ã‚’ç¤ºã—ã€ä»Šå¾Œã®ç ”ç©¶ã®åŸºç›¤ã‚’æä¾›ã€‚</span>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1942" target="_blank" rel="noopener noreferrer" class="title-link">The FineWeb Datasets: Decanting the Web for the Finest Text Data at   Scale, Guilherme Penedo+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€15å…†ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰ãªã‚‹FineWebãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç´¹ä»‹ã—ã€LLMã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚FineWebã¯é«˜å“è³ªãªäº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ–¹æ³•ã‚’æ–‡æ›¸åŒ–ã—ã€é‡è¤‡æ’é™¤ã‚„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æˆ¦ç•¥ã‚’è©³ç´°ã«èª¿æŸ»ã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€FineWebã‹ã‚‰æ´¾ç”Ÿã—ãŸ1.3å…†ãƒˆãƒ¼ã‚¯ãƒ³ã®FineWeb-Eduã‚’ç”¨ã„ãŸLLMã¯ã€MMLUã‚„ARCãªã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã€ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://zenn.dev/deepkawamura/articles/da9aeca6d6d9f9" target="_blank" rel="noopener noreferrer">https://zenn.dev/deepkawamura/articles/da9aeca6d6d9f9</a>


</p>
<p>openreview:


<a href="https://openreview.net/forum?id=n6SCkn2QaG#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=n6SCkn2QaG#discussion</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1933" target="_blank" rel="noopener noreferrer" class="title-link">Editing Large Language Models: Problems, Methods, and Opportunities, Yunzhi Yao+, EMNLP'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ç·¨é›†æŠ€è¡“ã®é€²å±•ã‚’æ¢æ±‚ã—ã€ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®åŠ¹ç‡çš„ãªå‹•ä½œå¤‰æ›´ã¨ä»–ã®å…¥åŠ›ã¸ã®å½±éŸ¿ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹æ–¹æ³•ã‚’è«–ã˜ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ç·¨é›†ã®ã‚¿ã‚¹ã‚¯å®šç¾©ã‚„èª²é¡Œã‚’åŒ…æ‹¬çš„ã«ã¾ã¨ã‚ã€å…ˆé€²çš„ãªæ‰‹æ³•ã®å®Ÿè¨¼åˆ†æã‚’è¡Œã†ã€‚ã¾ãŸã€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã€è©•ä¾¡ã®å‘ä¸Šã¨æŒç¶šçš„ãªå•é¡Œã®ç‰¹å®šã‚’ç›®æŒ‡ã™ã€‚æœ€çµ‚çš„ã«ã€ç·¨é›†æŠ€è¡“ã®åŠ¹æœã«é–¢ã™ã‚‹æ´å¯Ÿã‚’æä¾›ã—ã€é©åˆ‡ãªæ–¹æ³•é¸æŠã‚’æ”¯æ´ã™ã‚‹ã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1929" target="_blank" rel="noopener noreferrer" class="title-link">Physics of Language Models: Part 4.1, Architecture Design and the Magic of Canon Layers, Zeyuan Allen-Zhu+, ICML'24 Tutorial</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1919878625488449849?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Canonå±¤ã®ç™ºè¦‹</p>
<p>è‘—è€…ã«ã‚ˆã‚‹è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zeyuanallenzhu/status/1918684257058197922?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1923" target="_blank" rel="noopener noreferrer" class="title-link">Physics of Language Models: Part 3.1, Knowledge Storage and Extraction, Zeyuan Allen-Zhu+, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®çŸ¥è­˜æŠ½å‡ºèƒ½åŠ›ã¯ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ã¨å¼·ãç›¸é–¢ã—ã¦ãŠã‚Šã€ååˆ†ãªå¼·åŒ–ãŒãªã‘ã‚Œã°çŸ¥è­˜ã¯è¨˜æ†¶ã•ã‚Œã¦ã‚‚æŠ½å‡ºå¯èƒ½ã§ã¯ãªã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚å…·ä½“çš„ã«ã¯ã€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã®éš ã‚ŒåŸ‹ã‚è¾¼ã¿ã«çŸ¥è­˜ãŒã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹ã€ä»–ã®ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ã«åˆ†æ•£ã—ã¦ã„ã‚‹ã‹ã‚’èª¿æŸ»ã€‚LLMã®ãƒ—ãƒ¬ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«é–¢ã™ã‚‹é‡è¦ãªæ¨å¥¨äº‹é …ã¨ã—ã¦ã€è£œåŠ©ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸãƒ‡ãƒ¼ã‚¿å†æ§‹æˆã¨æŒ‡ç¤ºå¾®èª¿æ•´ãƒ‡ãƒ¼ã‚¿ã®æ—©æœŸå–ã‚Šå…¥ã‚ŒãŒææ¡ˆã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>è§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
</p>
<p>SNLP'24ã§ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:<br>


<a href="https://speakerdeck.com/sosk/physics-of-language-models-part-3-1-knowledge-storage-and-extraction" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/sosk/physics-of-language-models-part-3-1-knowledge-storage-and-extraction</a>


</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-04-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1908" target="_blank" rel="noopener noreferrer" class="title-link">Safety Alignment Should Be Made More Than Just a Few Tokens Deep, Xiangyu Qi+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ç¾åœ¨ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å®‰å…¨æ€§ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã¯è„†å¼±ã§ã‚ã‚Šã€å˜ç´”ãªæ”»æ’ƒã‚„å–„æ„ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã£ã¦è„±ç„ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ã“ã®è„†å¼±æ€§ã¯ã€Œæµ…ã„å®‰å…¨æ€§ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã€ã«èµ·å› ã—ã€ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆãŒä¸»ã«æœ€åˆã®æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã®å‡ºåŠ›ã«ã®ã¿é©å¿œã•ã‚Œã‚‹ã“ã¨ã«é–¢é€£ã—ã¦ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€ã“ã®å•é¡Œã®ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚’æç¤ºã—ã€ç¾åœ¨ã®ã‚¢ãƒ©ã‚¤ãƒ³ã•ã‚ŒãŸLLMsãŒç›´é¢ã™ã‚‹è„†å¼±æ€§ã‚’èª¬æ˜ã™ã‚‹ã€‚ã¾ãŸã€æµ…ã„å®‰å…¨æ€§ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã®æ¦‚å¿µãŒè„†å¼±æ€§è»½æ¸›ã®ç ”ç©¶æ–¹å‘ã‚’ç¤ºå”†ã—ã€åˆæœŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¶…ãˆãŸã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã®æ·±åŒ–ãŒãƒ­ãƒã‚¹ãƒˆæ€§ã‚’å‘ä¸Šã•ã›ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã™ã€‚æœ€å¾Œã«ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ”»æ’ƒã«å¯¾ã™ã‚‹æŒç¶šçš„ãªå®‰å…¨æ€§ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®æ­£å‰‡åŒ–ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç›®çš„ã‚’ææ¡ˆã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1917006979836612640?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=6Mxhg9PtDE" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=6Mxhg9PtDE</a>


</p>
<p>Safety Alignmentæ‰‹æ³•ãŒæœ€åˆã®æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã«ä¾å­˜ã—ã¦ã„ã‚‹ã‹ã‚‰ãã†ãªã‚‰ãªã„ã‚ˆã†ã«å­¦ç¿’ã—ã¾ã™ã¨ã„ã†ã®ã¯ã€èˆˆå‘³æ·±ã„ãƒ†ãƒ¼ãƒã ã—æŠ€è¡“çš„ã«ã¾ã å›°é›£ãªç‚¹ã‚‚ã‚ã£ãŸã ã‚ã†ã—ã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚‚å¤§ãã„ã—ã€ã¨ã¦ã‚‚è‰¯ã„ç ”ç©¶ã â€¦ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Non-Determinism.html" target="_blank" rel="noopener noreferrer">#Non-Determinism</a>
<span class="issue_date">Issue Date: 2025-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1890" target="_blank" rel="noopener noreferrer" class="title-link">Non-Determinism of "Deterministic" LLM Settings, Berk Atil+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€5ã¤ã®æ±ºå®šè«–çš„LLMã«ãŠã‘ã‚‹éæ±ºå®šæ€§ã‚’8ã¤ã®ã‚¿ã‚¹ã‚¯ã§èª¿æŸ»ã—ã€æœ€å¤§15%ã®ç²¾åº¦å¤‰å‹•ã¨70%ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚®ãƒ£ãƒƒãƒ—ã‚’è¦³å¯Ÿã€‚å…¨ã¦ã®ã‚¿ã‚¹ã‚¯ã§ä¸€è²«ã—ãŸç²¾åº¦ã‚’æä¾›ã§ããªã„ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€éæ±ºå®šæ€§ãŒè¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã®åŠ¹ç‡çš„ä½¿ç”¨ã«å¯„ä¸ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚ŒãŸã€‚å‡ºåŠ›ã®åˆæ„ç‡ã‚’ç¤ºã™æ–°ãŸãªãƒ¡ãƒˆãƒªã‚¯ã‚¹TARr@Nã¨TARa@Nã‚’å°å…¥ã—ã€ç ”ç©¶çµæœã‚’å®šé‡åŒ–ã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>- è«–æ–‡ä¸­ã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/785" target="_blank" rel="noopener noreferrer">Beyond the Imitation Game: Quantifying and extrapolating the   capabilities of language models, Aarohi Srivastava+, N/A, TMLR'23</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/901" target="_blank" rel="noopener noreferrer">Measuring Massive Multitask Language Understanding, Dan Hendrycks+, N/A, ICLR'21</a>
 </p>
<p>åŒã˜ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€seedã‚’å›ºå®šã—ã€temperatureã‚’0ã«è¨­å®šã—ã€åŒã˜è¨ˆç®—æ©Ÿç’°å¢ƒã«å¯¾ã—ã¦ã€åŒã˜inputã‚’å…¥åŠ›ã—ãŸã‚‰ç†è«–ä¸Šã¯LLMã®å‡ºåŠ›ã¯deterministicã«ãªã‚‹ã¯ãšã ãŒã€deterministicã«ãªã‚‰ãšã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã®æ€§èƒ½ã¨ãã‚‚ãã‚‚ã®raw responseè‡ªä½“ã‚‚è©¦è¡Œã”ã¨ã«å¤§ããå¤‰åŒ–ã™ã‚‹ã€ã¨ã„ã†è©±ã€‚<br>ãŸã ã—ã€ã“ã‚Œã¯ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªLLMã‚„ã€ä½•ã‚‰ã‹ã®inferenceã®é«˜é€ŸåŒ–ã‚’å®Ÿæ–½ã—ãŸInferenceEngineï¼ˆæœ¬ç ”ç©¶ã§ã¯Togetherã¨å‘¼ã°ã‚Œã‚‹å®Ÿè£…ã‚’ä½¿ã£ã¦ã„ãã†ã€‚vLLM/SGLangã ã¨ã©ã†ãªã‚‹ã®ã‹ãŒæ°—ã«ãªã‚‹ï¼‰ã‚’ç”¨ã„ã¦inferenceã‚’å®Ÿæ–½ã—ãŸå ´åˆã§ã®å®Ÿé¨“çµæœã§ã‚ã‚Šã€å¾Œè¿°ã®é€šã‚Šè¨ˆç®—ã®é«˜é€ŸåŒ–ã®ãŸã‚ã®ã•ã¾ã–ã¾ãªå®Ÿè£…ç„¡ã—ã§ã€deterministicãªè¨­å®šã§OpenLLMã§inferenceã™ã‚‹ã¨å‡ºåŠ›ã¯deterministicã«ãªã‚‹ã€ã¨ã„ã†ç‚¹ã«ã¯æ³¨æ„ã€‚<br><br>GPTã‚„Llamaã€Mixtralã«å¯¾ã—ã¦ä¸Šè¨˜ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ç”¨ã„ã¦zero-shot/few-shotã®è¨­å®šã§å®Ÿé¨“ã—ã¦ã„ã‚‹ã€‚Reasoningãƒ¢ãƒ‡ãƒ«ã¯å®Ÿé¨“ã«å«ã¾ã‚Œã¦ã„ãªã„ã€‚<br>&lt;img width="701" height="325" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/b33f14d8-ed86-4589-a427-18a70b35d61a"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/b33f14d8-ed86-4589-a427-18a70b35d61a"&lt;/a&gt;


/&gt;<br><br>LLMã®raw_response/multiple choiceã®parseçµæœï¼ˆi.e., å•é¡Œã«å¯¾ã™ã‚‹è§£ç­”éƒ¨åˆ†ã‚’æŠ½å‡ºã—ãŸçµæœï¼‰ã®ä¸€è‡´ï¼ˆTARr@N, TARa@N; Nã¯inferenceã®è©¦è¡Œå›æ•°ï¼‰ã‚‚ç†è«–ä¸Šã¯100%ã«ãªã‚‹ã¯ãšãªã®ã«ã€ãªã‚‰ãªã„ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>&lt;img width="712" height="432" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/3159ff26-fc92-4fa8-90a6-f8c5e7ccf20e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/3159ff26-fc92-4fa8-90a6-f8c5e7ccf20e"&lt;/a&gt;


/&gt;<br><br>correlation analysisã«ã‚ˆã£ã¦ã€å¿œç­”ã®é•·ã• ã¨ TAR{r, a}ãŒå¼·ã„è² ã®ç›¸é–¢ã‚’ç¤ºã—ã¦ãŠã‚Šã€å¿œç­”ãŒé•·ããªã‚Œã°ãªã‚‹ã»ã©ä¸å®‰å®šã•ã¯å¢—ã™ã“ã¨ãŒåˆ†æã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã®ãŸã‚ã€ontput tokenã®æœ€å¤§å€¤ã‚’åˆ¶é™ã™ã‚‹ã“ã¨ã§å‡ºåŠ›ã®å®‰å®šæ€§ãŒå¢—ã™ã“ã¨ã‚’è€ƒå¯Ÿã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€few-shotã«ãŠã„ã¦é«˜ã„Acc.ã®å ´åˆã¯å‡ºåŠ›ãŒdeterministicã«ãªã‚‹ã‚ã‘ã§ã¯ãªã„ãŒã€æ€§èƒ½ãŒå®‰å®šã™ã‚‹å‚¾å‘ã¨ã®ã“ã¨ã€‚ã¾ãŸã€OpenAIãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ä¸Šã§GPTã®finetuningã‚’å®Ÿæ–½ã—å®Ÿé¨“ã—ãŸãŒã€å®‰å®šæ€§ã«å¯„ä¸ã¯ã—ãŸãŒã€ã“ã¡ã‚‰ã‚‚deterministicã«ãªã‚‹ã‚ã‘ã§ã¯ãªã„ã¨ã®ã“ã¨ã€‚<br><br>deterministicã«ãªã‚‰ãªã„åŸå› ã¨ã—ã¦ã€ã¾ãšmulti gpuç’°å¢ƒã«ã¤ã„ã¦æ¤œè¨ã—ã¦ã„ã‚‹ãŒã€multi-gpuç’°å¢ƒã§ã¯ã‚ã‚‹ç¨‹åº¦ã®ãƒ©ãƒ³ãƒ€ãƒ æ€§ãŒç”Ÿã˜ã‚‹ã“ã¨ãŒNvidiaã®ç ”ç©¶ã«ã‚ˆã£ã¦å ±å‘Šã•ã‚Œã¦ã„ã‚‹ãŒã€ã“ã‚Œã¯seedã‚’å›ºå®šã™ã‚Œã°æ±ºå®šè«–çš„ã«ã§ãã‚‹ãŸã‚å•é¡Œã«ãªã‚‰ãªã„ã¨ã®ã“ã¨ã€‚<br>ç¶šã„ã¦ã€inferenceã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã®å®Ÿè£…ä¸Šã®å·¥å¤«ï¼ˆe.g., Chunk Prefilling, Prefix Caching, Continuous Batchingï¼‰ãªã©ã®å®Ÿè£…ãŒdeterministicãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚‚deterministicã«ãªã‚‰ãªã„åŸå› ã§ã‚ã‚‹ã¨è€ƒå¯Ÿã—ã¦ãŠã‚Šã€**å®Ÿéš›ã«localãƒã‚·ãƒ³ä¸Šã§ã“ã‚Œã‚‰inferenceã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã®æœ€é©åŒ–ã‚’ä½•ã‚‚å®Ÿæ–½ã—ãªã„çŠ¶æ…‹ã§Llama-8Bã§inferenceã‚’å®Ÿæ–½ã—ãŸã¨ã“ã‚ã€outputã¯deterministicã«ãªã£ãŸã¨ã®ã“ã¨ã€‚**</p>
<p>è«–æ–‡ä¸­ã«è¨˜è¼‰ãŒãªã‹ã£ãŸãŸã‚ã€ã©ã®ã‚ˆã†ãªInferenceEngineã‚’åˆ©ç”¨ã—ãŸã‹å…¬é–‹ã•ã‚Œã¦ã„ã‚‹githubã‚’è¦‹ã‚‹ã¨ä¸‹è¨˜ãŒåˆ©ç”¨ã•ã‚Œã¦ã„ãŸ:<br><br>- Together: 


<a href="https://github.com/togethercomputer/together-python?tab=readme-ov-file" target="_blank" rel="noopener noreferrer">https://github.com/togethercomputer/together-python?tab=readme-ov-file</a>


<br><br>TogetherãŒå†…éƒ¨çš„ã«ã©ã®ã‚ˆã†ãªå‡¦ç†ã‚’ã—ã¦ã„ã‚‹ã‹ã¾ã§ã¯è¿½ãˆã¦ã„ãªã„ã®ã ãŒã€ç•°ãªã‚‹InferenceEngineã‚’åˆ©ç”¨ã—ãŸå ´åˆã«ã€ã©ã®ç¨‹åº¦outputã®ä¸å®‰å®šã•ã«å·®ãŒå‡ºã‚‹ã®ã‹ï¼ˆã‚ã‚‹ã„ã¯å‡ºãªã„ã®ã‹ï¼‰ã¯æ°—ã«ãªã‚‹ã€‚ãŸã¨ãˆã°ã€transformers/vLLM/SGLangã‚’åˆ©ç”¨ã—ãŸå ´åˆãªã©ã§ã‚ã‚‹ã€‚<br><br>è«–æ–‡ä¸­ã§ã‚‚å ±å‘Šã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€æ˜”ç®¡ç†äººãŒtransformersã‚’ç”¨ã„ã¦ã€deterministicãªè¨­å®šã§zephyrã‚’ç”¨ã„ã¦inferenceã‚’ã—ãŸã¨ãã¯ã€å‡ºåŠ›ã¯deterministicã«ãªã£ã¦ã„ãŸã¨è¨˜æ†¶ã—ã¦ã„ã‚‹ï¼ˆã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¯çµ¶æœ›çš„ã ã£ãŸãŒ...)ã€‚</p>
<p>ã‚ã¨å€‹äººçš„ã«ã¯ç¾å®Ÿçš„ãªé€Ÿåº¦ã§ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§inference engineã‚’åˆ©ç”¨ã—ãŸæ™‚ã«deterministicã«ã¯ã›ã‚ã¦ãªã£ã¦æ¬²ã—ã„ãªã‚ã¨ã„ã†æ°—ã¯ã™ã‚‹ã®ã§ã€ä½•ãŒåŸå› ãªã®ã‹ã‚’å®Ÿè£…ãƒ¬ãƒ™ãƒ«ã§çªãè©°ã‚ã¦ãã‚Œã‚‹ã¨ã¨ã¦ã‚‚å¬‰ã—ã„ï¼ˆKV CacheãŒæ€ªã—ã„æ°—ãŒã™ã‚‹ã‘ã©ï¼‰ã€‚<br><br>ãŸã¨ãˆã°æœ€è¿‘SLMã ã£ãŸã‚‰KVCacheã—ã¦VRAMé£Ÿã†ã‚ˆã‚Šè¨ˆç®—ã—ç›´ã—ãŸæ–¹ãŒåŠ¹ç‡è‰¯ã„ã‚ˆã€ã¿ãŸã„ãªç ”ç©¶ãŒã‚ã£ãŸã‚ˆã†ãªã€‚ãã†ã„ã†ã“ã¨ã‚’ã—ãŸã‚‰local llmã§deterministicã«ãªã‚‰ãªã„ã®ã ã‚ã†ã‹ã€‚</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2763" target="_blank" rel="noopener noreferrer">Defeating Nondeterminism in LLM Inference, Horace He in collaboration with others at Thinking Machines, 2025.09</a>
<br><br>ã«ãŠã„ã¦vLLMã‚’ç”¨ã„ãŸå ´åˆã«Deterministicãªæ¨è«–ã‚’ã™ã‚‹ãŸã‚ã®è§£æ±ºæ–¹æ³•ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/API.html" target="_blank" rel="noopener noreferrer">#API</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-04-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1874" target="_blank" rel="noopener noreferrer" class="title-link">Gorilla: Large Language Model Connected with Massive APIs, Shishir G. Patil+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- Gorillaã¯ã€APIå‘¼ã³å‡ºã—ã®ç”Ÿæˆã«ãŠã„ã¦GPT-4ã‚’ä¸Šå›ã‚‹LLaMAãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€æ–‡æ›¸æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ãƒ†ã‚¹ãƒˆæ™‚ã®æ–‡æ›¸å¤‰æ›´ã«é©å¿œã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æŸ”è»Ÿãªæ›´æ–°ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚å¹»è¦šã®å•é¡Œã‚’è»½æ¸›ã—ã€APIã‚’ã‚ˆã‚Šæ­£ç¢ºã«ä½¿ç”¨ã™ã‚‹èƒ½åŠ›ã‚’ç¤ºã—ã¾ã™ã€‚Gorillaã®è©•ä¾¡ã«ã¯æ–°ãŸã«å°å…¥ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒAPIBenchã€ã‚’ä½¿ç”¨ã—ã€ä¿¡é ¼æ€§ã¨é©ç”¨æ€§ã®å‘ä¸Šã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>APIBench:


<a href="https://huggingface.co/datasets/gorilla-llm/APIBench" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/gorilla-llm/APIBench</a>


</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=tBRNC6YemY" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=tBRNC6YemY</a>


</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<span class="issue_date">Issue Date: 2025-04-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1868" target="_blank" rel="noopener noreferrer" class="title-link">Foundational Challenges in Assuring Alignment and Safety of Large   Language Models, Usman Anwar+, TMLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMsã®æ•´åˆæ€§ã¨å®‰å…¨æ€§ã«é–¢ã™ã‚‹18ã®åŸºç›¤çš„èª²é¡Œã‚’ç‰¹å®šã—ã€ç§‘å­¦çš„ç†è§£ã€é–‹ç™ºãƒ»å±•é–‹æ–¹æ³•ã€ç¤¾ä¼šæŠ€è¡“çš„èª²é¡Œã®3ã¤ã®ã‚«ãƒ†ã‚´ãƒªã«æ•´ç†ã€‚ã“ã‚Œã«åŸºã¥ãã€200ä»¥ä¸Šã®å…·ä½“çš„ãªç ”ç©¶è³ªå•ã‚’æèµ·ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=oVTkOs8Pka" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=oVTkOs8Pka</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2025-04-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1864" target="_blank" rel="noopener noreferrer" class="title-link">Flex Attention: A Programming Model for Generating Optimized Attention  Kernels, Juechu Dong+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- FlexAttentionã¯ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®æ–°ã—ã„ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©é§†å‹•å‹ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã§ã€æ•°è¡Œã®PyTorchã‚³ãƒ¼ãƒ‰ã§å¤šãã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒãƒªã‚¢ãƒ³ãƒˆã‚’å®Ÿè£…å¯èƒ½ã«ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ—¢å­˜ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒãƒªã‚¢ãƒ³ãƒˆã‚’åŠ¹ç‡çš„ã«å®Ÿè£…ã—ã€ç«¶äº‰åŠ›ã®ã‚ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚FlexAttentionã¯ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒãƒªã‚¢ãƒ³ãƒˆã®çµ„ã¿åˆã‚ã›ã‚’å®¹æ˜“ã«ã—ã€çµ„ã¿åˆã‚ã›çˆ†ç™ºã®å•é¡Œã‚’è§£æ±ºã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1863" target="_blank" rel="noopener noreferrer">Llama 4 Series, Meta, 2025.04</a>
<br><br>ã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹Attention</p>
<p>pytochã«ã‚ˆã‚‹è§£èª¬:


<a href="https://pytorch.org/blog/flexattention/" target="_blank" rel="noopener noreferrer">https://pytorch.org/blog/flexattention/</a>


<br><br>- Flex Attentionã¯ã‚ªãƒªã‚¸ãƒŠãƒ«ã®Attentionã®QK/sqrt(d_k)ã®è¨ˆç®—å¾Œã«ãƒ¦ãƒ¼ã‚¶ãŒå®šç¾©ã—ãŸé–¢æ•°score_modã‚’é©ç”¨ã™ã‚‹<br>- score_modã‚’å®šç¾©ã™ã‚‹ã“ã¨ã§ã€attention scoreã‚’softmaxã‚’ã‹ã‘ã‚‹ã¾ãˆã«é–¢æ•°ã«ã‚ˆã£ã¦èª¿æ•´ã§ãã‚‹<br>- å¤šãã®attentionã®äºœç¨®ã¯ã»ã¨ã‚“ã©ã®å ´åˆã“ã®æŠ½è±¡åŒ–ã§å¯¾å¿œã§ãã‚‹<br>- score_modã¯QK tokenã®å†…ç©ã«å¯¾å¿œã™ã‚‹ã®ã§ã€QKã®æƒ…å ±ã‚’å—ã‘å–ã‚Šã€ã‚¹ã‚«ãƒ©ãƒ¼å€¤ã‚’è¿”ã›ã°ãªã‚“ã§ã‚‚è‰¯ã„<br>  - score_modã®å®Ÿè£…ä¾‹ã¯å…ƒãƒªãƒ³ã‚¯å‚ç…§<br>- FA2ã¨æ¯”è¼ƒã—ã¦ï¼ˆç¾åœ¨ã®pytorchã§ã®å®Ÿè£…ä¸Šã¯ï¼‰Forward Passã¯90%, Backward Passã¯85%ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã§ã€å°‘ã—é…ã„ãŒä»Šå¾Œæ”¹å–„äºˆå®š</p>
<p>å…ƒè«–æ–‡ã‚ˆã‚Šå¼•ç”¨ã€‚éå¸¸ã«ã‚·ãƒ³ãƒ—ãƒ«ã§ã€æ•°å¼ä¸Šã¯ä¸‹è¨˜ã®ã‚ˆã†ã«è¡¨ã•ã‚Œã‚‹:<br><img src="https://github.com/user-attachments/assets/b4a393f0-46a9-46c6-9a47-0402ba58fb11" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1854" target="_blank" rel="noopener noreferrer" class="title-link">Agent Workflow Memory, Zora Zhiruo Wang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ¡ãƒ¢ãƒªï¼ˆAWMï¼‰ã‚’å°å…¥ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå†åˆ©ç”¨å¯èƒ½ãªã‚¿ã‚¹ã‚¯ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€è¤‡é›‘ãªã‚¦ã‚§ãƒ–ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã‚’åŠ¹ç‡çš„ã«è§£æ±ºã€‚Mind2Webã¨WebArenaã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€æˆåŠŸç‡ã‚’ãã‚Œãã‚Œ24.6%ãŠã‚ˆã³51.1%å‘ä¸Šã•ã›ã€å¿…è¦ãªã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’å‰Šæ¸›ã€‚ã‚ªãƒ³ãƒ©ã‚¤ãƒ³AWMã¯ã€ã‚¿ã‚¹ã‚¯ã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³ã«å¯¾ã—ã¦ã‚‚å …ç‰¢ã«ä¸€èˆ¬åŒ–ã—ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>éå»ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒpromptä¸­ã§åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã€åˆ©ç”¨ã™ã‚Œã°ã™ã‚‹ã»ã©è³¢ããªã‚‹ã‚ˆã†ãªä»•çµ„ã¿ã®ææ¡ˆ<br>&lt;img width="873" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/6160cfa5-9dbd-44c6-926c-a56eb698d78d"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/6160cfa5-9dbd-44c6-926c-a56eb698d78d"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1852" target="_blank" rel="noopener noreferrer" class="title-link">CoAct: A Global-Local Hierarchy for Autonomous Agent Collaboration, Xinming Hou+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- CoActãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€2ã¤ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«è¨ˆç”»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã‚’ç”¨ã„ã¦ã€LLMã®è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã¸ã®å¯¾å¿œåŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“ã§ã¯ã€WebArenaãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ãŠã„ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€å¤±æ•—æ™‚ã®ãƒ—ãƒ­ã‚»ã‚¹å†ç·¨æˆèƒ½åŠ›ã‚’ç¢ºèªã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ä¸­ã€‚</span>
<span class="snippet"><span>Comment</span><p>Planningã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨å®Ÿè¡Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ´»ç”¨ã™ã‚‹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ<br><br>&lt;img width="632" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/55db47b8-15f8-4a9c-b641-ce906994897f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/55db47b8-15f8-4a9c-b641-ce906994897f"&lt;/a&gt;


/&gt;<br><br>ReActã‚ˆã‚Šæ€§èƒ½å‘ä¸Š<br>-  <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/518" target="_blank" rel="noopener noreferrer">REACT : SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS, Yao+, Princeton University and Google brain, ICLR'23</a>
 <br>&lt;img width="325" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/79ac984a-1aa4-4d27-8a3f-860ed2c3abf7"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/79ac984a-1aa4-4d27-8a3f-860ed2c3abf7"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1851" target="_blank" rel="noopener noreferrer" class="title-link">Training Software Engineering Agents and Verifiers with SWE-Gym, Jiayi Pan+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- SWE-Gymã‚’ææ¡ˆã—ã€2,438ä»¶ã®å®Ÿä¸–ç•Œã®Pythonã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ç’°å¢ƒã‚’æ§‹ç¯‰ã€‚è¨€èªãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ãSWEã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´ã—ã€SWE-Benchã§æœ€å¤§19%ã®è§£æ±ºç‡å‘ä¸Šã‚’é”æˆã€‚å¾®èª¿æ•´ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯æ–°ãŸãªæœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ç¤ºã—ã€SWE-Gymã‚„ãƒ¢ãƒ‡ãƒ«ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è»Œè·¡ã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>SWE-Benchã¨ã¯å®Œå…¨ã«ç‹¬ç«‹ã—ãŸã‚ˆã‚Šåºƒç¯„ãªæŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã«é–¢é€£ã™ã‚‹ã‚¿ã‚¹ã‚¯ã«åŸºã¥ãSWEãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1848" target="_blank" rel="noopener noreferrer">SWE-bench: Can Language Models Resolve Real-World GitHub Issues?, Carlos E. Jimenez+, ICLR'24</a>
 </p>
<p>SWE-Benchã¨æ¯”ã¹ã¦å®Ÿè¡Œå¯èƒ½ãªç’°å¢ƒã¨å˜ä½“ãƒ†ã‚¹ãƒˆãŒæä¾›ã•ã‚Œã¦ãŠã‚Šã€å˜ãªã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯ãªãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨“ç·´ã§ãã‚‹ç’°å¢ƒãŒæä¾›ã•ã‚Œã¦ã„ã‚‹ç‚¹ãŒå¤§ããç•°ãªã‚‹ã‚ˆã†ã«æ„Ÿã˜ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/8c96df84-d211-4035-8337-1ab624d30a4f" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/d25687d9-6f1a-44f6-8235-09be1ff4890f" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1849" target="_blank" rel="noopener noreferrer" class="title-link">WebArena: A Realistic Web Environment for Building Autonomous Agents, Shuyan Zhou+, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- ç”ŸæˆAIã®é€²å±•ã«ã‚ˆã‚Šã€è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè‡ªç„¶è¨€èªã‚³ãƒãƒ³ãƒ‰ã§æ—¥å¸¸ã‚¿ã‚¹ã‚¯ã‚’ç®¡ç†ã™ã‚‹å¯èƒ½æ€§ãŒç”Ÿã¾ã‚ŒãŸãŒã€ç¾è¡Œã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ç°¡ç•¥åŒ–ã•ã‚ŒãŸç’°å¢ƒã§ã®ãƒ†ã‚¹ãƒˆã«é™ã‚‰ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ã‚¦ã‚§ãƒ–ä¸Šã§ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãŸã‚ã®ç¾å®Ÿçš„ãªç’°å¢ƒã‚’æ§‹ç¯‰ã—ã€eã‚³ãƒãƒ¼ã‚¹ã‚„ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ•ã‚©ãƒ¼ãƒ©ãƒ ãªã©ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’å«ã‚€å®Œå…¨ãªã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‚’æä¾›ã™ã‚‹ã€‚ã“ã®ç’°å¢ƒã‚’åŸºã«ã€ã‚¿ã‚¹ã‚¯ã®æ­£ç¢ºæ€§ã‚’è©•ä¾¡ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å…¬é–‹ã—ã€å®Ÿé¨“ã‚’é€šã˜ã¦GPT-4ãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æˆåŠŸç‡ãŒ14.41%ã§ã‚ã‚Šã€äººé–“ã®78.24%ã«ã¯åŠã°ãªã„ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å®Ÿç”Ÿæ´»ã®ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã•ã‚‰ãªã‚‹é–‹ç™ºã®å¿…è¦æ€§ãŒå¼·èª¿ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Webã«ãŠã‘ã‚‹ã•ã¾ã–ã¾ãªrealisticãªã‚¿ã‚¹ã‚¯ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br><img src="https://github.com/user-attachments/assets/8895fc29-e997-4cce-a43e-65b928dc1d78" alt="image" loading="lazy"></p>
<p>å®Ÿéš›ã®exampleã€‚ã‚¹ã‚¿ãƒ¼ãƒˆåœ°ç‚¹ã‹ã‚‰ãƒ”ãƒƒãƒ„ãƒãƒ¼ã‚°ã®museumã‚’å·¡ã‚‹æœ€çŸ­ã®çµŒè·¯ã‚’è¦‹ã¤ã‘ã‚‹ã¨ã„ã£ãŸè¤‡é›‘ãªã‚¿ã‚¹ã‚¯ãŒå«ã¾ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/5b7bebea-34c7-4c6f-bbe5-3928544e6c13" alt="image" loading="lazy"><br><br>äººé–“ã¨GPT4,GPT-3.5ã®æ¯”è¼ƒçµæœ<br><img src="https://github.com/user-attachments/assets/390fee31-85d0-4d83-969a-57a7f1548ca8" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1848" target="_blank" rel="noopener noreferrer" class="title-link">SWE-bench: Can Language Models Resolve Real-World GitHub Issues?, Carlos E. Jimenez+, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- SWE-benchã¯ã€12ã®äººæ°—Pythonãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰å¾—ã‚‰ã‚ŒãŸ2,294ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å•é¡Œã‚’è©•ä¾¡ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’ç·¨é›†ã—ã¦å•é¡Œã‚’è§£æ±ºã™ã‚‹èƒ½åŠ›ã‚’æ¸¬å®šã—ã¾ã™ã€‚è©•ä¾¡ã®çµæœã€æœ€å…ˆç«¯ã®å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã‚„å¾®èª¿æ•´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«SWE-Llamaã‚‚æœ€ã‚‚å˜ç´”ãªå•é¡Œã—ã‹è§£æ±ºã§ããšã€Claude 2ã¯ã‚ãšã‹1.96%ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ã«ã¨ã©ã¾ã‚Šã¾ã—ãŸã€‚SWE-benchã¯ã€ã‚ˆã‚Šå®Ÿç”¨çš„ã§çŸ¥çš„ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã¸ã®é€²å±•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æœ€ã‚‚popularãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br><br>&lt;img width="693" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/ac905221-d3b1-4d16-b447-3bdd4d5e97bb"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/ac905221-d3b1-4d16-b447-3bdd4d5e97bb"&lt;/a&gt;


/&gt;<br><br>ä¸»ã«pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«é–¢ã™ã‚‹ãƒªãƒã‚¸ãƒˆãƒªã«åŸºã¥ã„ã¦æ§‹ç¯‰ã•ã‚Œã¦ã„ã‚‹ã€‚<br>&lt;img width="731" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/14d26dd1-6b4a-4337-a652-4e48e36d633b"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/14d26dd1-6b4a-4337-a652-4e48e36d633b"&lt;/a&gt;


/&gt;</p>
<p>SWE-Bench, SWE-Bench Lite, SWE-Bench Verifiedã®3ç¨®é¡ãŒã‚ã‚Šã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã¯SWE-Bench Verifiedã‚’åˆ©ç”¨ã—ã¦è©•ä¾¡ã™ã‚‹ã“ã¨ãŒå¤šã„ã‚‰ã—ã„ã€‚Verifiedã§ã¯ã€issueã®è¨˜è¿°ã«æ›–æ˜§æ€§ãŒãªãã€é©åˆ‡ãªunittestã®ã‚¹ã‚³ãƒ¼ãƒ—ãŒé©åˆ‡ãªã‚‚ã®ã®ã¿ãŒæ¡ç”¨ã•ã‚Œã¦ã„ã‚‹ã¨ã®ã“ã¨ï¼ˆi.e., äººé–“ã®å°‚é–€å®¶ã«ã‚ˆã£ã¦å•é¡ŒãŒãªã„ã¨åˆ¤æ–­ã•ã‚ŒãŸã‚‚ã®ï¼‰ã€‚<br>


<a href="https://www.swebench.com/" target="_blank" rel="noopener noreferrer">https://www.swebench.com/</a>


</p>
<p>Agenticãªè©•ä¾¡ã‚’ã™ã‚‹éš›ã«ã€ä¸€éƒ¨ã®è©•ä¾¡ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒgit logã‚’å‚ç…§ã—æœ¬æ¥ã¯å­˜åœ¨ã—ãªã„ã¯ãšã®ãƒªãƒã‚¸ãƒˆãƒªã®future stateã‚’è¦‹ã‚‹ã“ã¨ã§ç’°å¢ƒã‚’ãƒãƒƒã‚­ãƒ³ã‚°ã—ã¦ã„ãŸã¨ã®ã“ã¨:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/giffmana/status/1963327672827687316?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã“ã‚Œã¾ã§ã®è©•ä¾¡çµæœã«ã©ã®ç¨‹åº¦ã®å½±éŸ¿ãŒã‚ã‚‹ã‹ã¯ä¸æ˜ã€‚<p>openreview:


<a href="https://openreview.net/forum?id=VTF8yNQM66" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=VTF8yNQM66</a>


</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/UserModeling.html" target="_blank" rel="noopener noreferrer">#UserModeling</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/CTRPrediction.html" target="_blank" rel="noopener noreferrer">#CTRPrediction</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2025-03-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1840" target="_blank" rel="noopener noreferrer" class="title-link">ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential   Behavior Comprehension in Recommendation, Jianghao Lin+, WWW'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆãŠã‚ˆã³å°‘ã‚·ãƒ§ãƒƒãƒˆã®æ¨è–¦ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’å¼·åŒ–ã™ã‚‹æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒReLLaã€ã‚’ææ¡ˆã€‚LLMsãŒé•·ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡ºã§ããªã„å•é¡Œã«å¯¾å‡¦ã—ã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•æ¤œç´¢ï¼ˆSUBRï¼‰ã‚’ç”¨ã„ã¦ãƒ‡ãƒ¼ã‚¿å“è³ªã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å°‘ã‚·ãƒ§ãƒƒãƒˆè¨­å®šã§ã¯ã€æ¤œç´¢å¼·åŒ–æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆReiTï¼‰ã‚’è¨­è¨ˆã—ã€æ··åˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€å°‘ã‚·ãƒ§ãƒƒãƒˆReLLaãŒå¾“æ¥ã®CTRãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1839" target="_blank" rel="noopener noreferrer">RALLRec+: Retrieval Augmented Large Language Model Recommendation with
  Reasoning, Sichun Luo+, arXiv'25</a>
<br><br>ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³</p>
<p>LLMã§CTRäºˆæ¸¬ã™ã‚‹éš›ã®æ€§èƒ½ã‚’å‘ä¸Šã—ãŸç ”ç©¶ã€‚<br><br>ãã‚‚ãã‚‚LLMã§CTRäºˆæ¸¬ã‚’ã™ã‚‹éš›ã¯ã€ãƒ¦ãƒ¼ã‚¶ã®ãƒ‡ãƒ¢ã‚°ãƒ©æƒ…å ±ã¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ­ã‚°ãªã©ã®ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¢ã‚¤ãƒ†ãƒ ã®æƒ…å ±ã§promptingã—ã€yes/noã‚’å‡ºåŠ›ã•ã›ã‚‹ã€‚yes/noãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¹ã‚³ã‚¢ã«å¯¾ã—ã¦2æ¬¡å…ƒã®ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‚’é©ç”¨ã—ã¦[0, 1]ã®ã‚¹ã‚³ã‚¢ã‚’å¾—ã‚‹ã“ã¨ã§ã€CTRäºˆæ¸¬ã‚’ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/75025947-f3bb-49d0-a8f1-e05c429183a4" alt="image" loading="lazy"><br><br>ã“ã®ç ”ç©¶ã§ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ãƒ¦ãƒ¼ã‚¶ã®ãƒ­ã‚°ã‚’å…¥ã‚Œã¦ã‚‚æ€§èƒ½ãŒã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«<br><img src="https://github.com/user-attachments/assets/69c27a84-0456-4ddf-aded-515608e27065" alt="image" loading="lazy"><br><br>ç›´è¿‘ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ­ã‚°ã§ã¯ãªãã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¢ã‚¤ãƒ†ãƒ ã¨æ„å‘³çš„ã«é¡ä¼¼ã—ãŸã‚¢ã‚¤ãƒ†ãƒ ã«é–¢ã™ã‚‹ãƒ­ã‚°ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å…¥ã‚Œï¼ˆSUBRï¼‰ã€zero shotã®inferenceã«æ´»ç”¨ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/a5a2a300-ddca-42cc-97d7-251487ccfa3a" alt="image" loading="lazy"><br><br>few-shot recommendationï¼ˆå°‘é‡ã®ã‚¯ãƒªãƒƒã‚¯ã‚¹ãƒ«ãƒ¼ãƒ­ã‚°ã‚’ç”¨ã„ã¦LLMã‚’SFTã™ã‚‹ã“ã¨ã§CTRäºˆæ¸¬ã™ã‚‹æ‰‹æ³•ï¼‰ã«ãŠã„ã¦ã¯ã€ä¸Šè¿°ã®æ„å‘³çš„ã«é¡ä¼¼ã—ãŸã‚¢ã‚¤ãƒ†ãƒ ã‚’data augmentationã«åˆ©ç”¨ã—ï¼ˆi.e, promptã«åŸ‹ã‚è¾¼ã‚€ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ­ã‚°ã®é‡ã‚’å¢—ã‚„ã—ã¦ï¼‰å­¦ç¿’ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/b98af740-0628-4e98-a80f-30ff105621e1" alt="image" loading="lazy"><br><br>zeroshotã«ãŠã„ã¦ã€SUBRã§æ€§èƒ½æ”¹å–„ã€‚fewshot recommendationã«ã¨ã„ã¦ã€10%æœªæº€ã®ãƒ‡ãƒ¼ã‚¿ã§æ—¢å­˜ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã‚‹æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã€‚ã¾ãŸã€ä¸‹ã®ã‚°ãƒ©ãƒ•ã‚’è¦‹ã‚‹ã¨promptã«åˆ©ç”¨ã™ã‚‹ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ­ã‚°ã®é‡ãŒå¢—ãˆã‚‹ã»ã©æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚<br><img src="https://github.com/user-attachments/assets/1297153e-bd6c-4548-a7e0-798eadee80e9" alt="image" loading="lazy"><br><br>ãŸã ã—ã€latencyã¯100å€ä»¥ä¸Šãªã®ã§ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ãŒé™å®šã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/89555964-f5c4-4735-bc0d-9a5a1b7f0278" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-03-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1831" target="_blank" rel="noopener noreferrer" class="title-link">Transformers are SSMs: Generalized Models and Efficient Algorithms   Through Structured State Space Duality, Tri Dao+, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- Transformersã¨Mambaã®ã‚ˆã†ãªçŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ï¼ˆSSMsï¼‰ã®é–¢é€£æ€§ã‚’ç¤ºã—ã€SSMsã¨æ³¨æ„ã®å¤‰ç¨®ã¨ã®ç†è«–çš„æ¥ç¶šã‚’æ§‹ç¯‰ã€‚æ–°ãŸã«è¨­è¨ˆã—ãŸMamba-2ã¯ã€é€Ÿåº¦ã‚’2ã€œ8å€å‘ä¸Šã•ã›ãªãŒã‚‰ã€Transformersã¨ç«¶äº‰åŠ›ã‚’ç¶­æŒã€‚</span>
<span class="snippet"><span>Comment</span><p>Mamba2ã®è©³ç´°ã‚’çŸ¥ã‚ŠãŸã„å ´åˆã«èª­ã‚€</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Pruning.html" target="_blank" rel="noopener noreferrer">#Pruning</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-03-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1804" target="_blank" rel="noopener noreferrer" class="title-link">Compact Language Models via Pruning and Knowledge Distillation, Saurav Muralidharan+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€æ—¢å­˜ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€å°‘é‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã§å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚æ·±ã•ã€å¹…ã€æ³¨æ„ã€MLPãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’çŸ¥è­˜è’¸ç•™ã¨çµ„ã¿åˆã‚ã›ãŸåœ§ç¸®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’é–‹ç™ºã—ã€Nemotron-4ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®LLMã‚’2-4å€åœ§ç¸®ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«å¿…è¦ãªãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æœ€å¤§40å€å‰Šæ¸›ã—ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’1.8å€å‰Šæ¸›ã€‚Minitronãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚¼ãƒ­ã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸå ´åˆã¨æ¯”è¼ƒã—ã¦MMLUã‚¹ã‚³ã‚¢ãŒæœ€å¤§16%æ”¹å–„ã•ã‚Œã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã•ã‚Œã€è£œè¶³è³‡æ–™ã‚‚æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=9U0nLnNMJ7&referrer=%5Bthe%20profile%20of%20Pavlo%20Molchanov%5D(%2Fprofile%3Fid%3D~Pavlo_Molchanov1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=9U0nLnNMJ7&referrer=%5Bthe%20profile%20of%20Pavlo%20Molchanov%5D(%2Fprofile%3Fid%3D~Pavlo_Molchanov1)</a>


</p>
<p><img src="https://github.com/user-attachments/assets/76ab1107-bf94-4cf1-9ad1-e9f494b917e7" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/d1bf8a84-5365-4d35-aae0-146b1860ed9d" alt="image" loading="lazy"><br><br>ï¼ˆã‚ã¨ã§ãƒ¡ãƒ¢ã‚’è¿½è¨˜ï¼‰</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-03-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1802" target="_blank" rel="noopener noreferrer" class="title-link">Sparse Autoencoders Find Highly Interpretable Features in Language   Models, Hoagy Cunningham+, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- ç¥çµŒãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å¤šç¾©æ€§ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã«ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’ç”¨ã„ã¦å†…éƒ¨æ´»æ€§åŒ–ã®æ–¹å‘ã‚’ç‰¹å®šã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è§£é‡ˆå¯èƒ½ã§å˜ç¾©çš„ãªç‰¹å¾´ã‚’å­¦ç¿’ã—ã€é–“æ¥ç›®çš„èªã®åŒå®šã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹å› æœçš„ç‰¹å¾´ã‚’ã‚ˆã‚Šè©³ç´°ã«ç‰¹å®šã€‚ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§æ•™å¸«ãªã—ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒé‡ã­åˆã‚ã›ã®å•é¡Œã‚’è§£æ±ºã§ãã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã€ãƒ¢ãƒ‡ãƒ«ã®é€æ˜æ€§ã¨æ“ä½œæ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://note.com/ainest/n/nbe58b36bb2db" target="_blank" rel="noopener noreferrer">https://note.com/ainest/n/nbe58b36bb2db</a>


</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=F76bwRSLeK" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=F76bwRSLeK</a>


</p>
<p>SparseAutoEncoderã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚ã‚‰ã‚†ã‚‹ã¨ã“ã‚ã«ä»•è¾¼ã‚ã‚‹ï¼ˆã¨æ€ã‚ã‚Œã‚‹ï¼‰ãŒã€ãŸã¨ãˆã°Transformer Blockã®residual connectionéƒ¨åˆ†ã®ãƒ™ã‚¯ãƒˆãƒ«ã«å¯¾ã—ã¦Feature Dictionaryã‚’å­¦ç¿’ã™ã‚‹ã¨ã€å½“è©²ãƒ–ãƒ­ãƒƒã‚¯ã«ãŠã„ã¦ã©ã®ã‚ˆã†ãªç‰¹å¾´ã®çµ„ã¿åˆã‚ã›ãŒè¡¨ç¾ã•ã‚Œã¦ã„ã‚‹ã‹ãŒï¼ˆã‚ãã¾ã§SparseAutoEncoderãŒreconstruction lossã«ã‚ˆã£ã¦å­¦ç¿’ã•ã‚ŒãŸçµæœã‚’ç”¨ã„ã¦ï¼‰è§£é‡ˆã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/f86f5f7b-f46d-48ab-94e3-cf7f298eb9d7" alt="image" loading="lazy"><br><br>SparseAutoEncoderã¯ä¸‹è¨˜å¼ã§è¡¨ã•ã‚Œã€ä¸‹è¨˜loss functionã§å­¦ç¿’ã•ã‚Œã‚‹ã€‚MãŒFeature Matrixï¼ˆrow-wiseã«æ­£è¦åŒ–ã•ã‚Œã¦å¾Œè¿°ã®cã«å¯¾ã™ã‚‹L1æ­£å‰‡åŒ–ã«å½±éŸ¿ã‚’ä¸ãˆãªã„ã‚ˆã†ã«ã—ã¦ã„ã‚‹ï¼‰ã«ç›¸å½“ã™ã‚‹ã€‚cã«å¯¾ã—ã¦L1æ­£å‰‡åŒ–ã‚’ã‹ã‘ã‚‹ã“ã¨ã§ï¼ˆSparsity Lossï¼‰ã€cä¸­ã®å„è¦ç´ ãŒ0ã«è¿‘ã¥ãã‚ˆã†ã«ãªã‚Šã€çµæœã¨ã—ã¦cãŒSparseã¨ãªã‚‹ï¼ˆã©ã†ã—ã¦ã‚‚å€¤ã‚’æŒãŸãªã‘ã‚Œã°ã„ã‘ãªã„é‡è¦ãªç‰¹å¾´é‡ã®ã¿ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ï¼‰ã€‚<br><img src="https://github.com/user-attachments/assets/7e400f25-8a63-4222-904c-4a7b94d50880" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/dd8c10b3-3bb5-46fb-b94a-d91f3602bbd1" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-03-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1785" target="_blank" rel="noopener noreferrer" class="title-link">Full Parameter Fine-tuning for Large Language Models with Limited Resources, Lv+, ACL'24, 2024.08</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã€ŒLOMOã€ã‚’ææ¡ˆã—ã€å‹¾é…è¨ˆç®—ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ã‚’1ã‚¹ãƒ†ãƒƒãƒ—ã§èåˆã™ã‚‹ã“ã¨ã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€24GBã®ãƒ¡ãƒ¢ãƒªã‚’æŒã¤8å°ã®RTX 3090ã§65Bãƒ¢ãƒ‡ãƒ«ã®å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¯èƒ½ã«ã€‚ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¯æ¨™æº–çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨æ¯”è¼ƒã—ã¦10.8%å‰Šæ¸›ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<span class="issue_date">Issue Date: 2025-02-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1752" target="_blank" rel="noopener noreferrer" class="title-link">PromptWizard: Task-Aware Prompt Optimization Framework, Eshaan Agarwal+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- PromptWizardã¯ã€å®Œå…¨è‡ªå‹•åŒ–ã•ã‚ŒãŸé›¢æ•£ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€è‡ªå·±é€²åŒ–çš„ã‹ã¤è‡ªå·±é©å¿œçš„ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’åˆ©ç”¨ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è³ªã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯é§†å‹•ã®æ‰¹è©•ã‚’é€šã˜ã¦ã€ã‚¿ã‚¹ã‚¯ç‰¹æœ‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã€45ã®ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã€‚é™ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚„å°è¦æ¨¡ãªLLMã§ã‚‚åŠ¹æœã‚’ç™ºæ®ã—ã€ã‚³ã‚¹ãƒˆåˆ†æã«ã‚ˆã‚ŠåŠ¹ç‡æ€§ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã®åˆ©ç‚¹ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Github:


<a href="https://github.com/microsoft/PromptWizard?tab=readme-ov-file" target="_blank" rel="noopener noreferrer">https://github.com/microsoft/PromptWizard?tab=readme-ov-file</a>


<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tom_doerr/status/1888178173684199785?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>åˆæœŸã«ææ¡ˆã•ã‚ŒãŸ<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1034" target="_blank" rel="noopener noreferrer">Large Language Models Are Human-Level Prompt Engineers, Yongchao Zhou+, ICLR'23</a>
<br><br>ã¨æ¯”è¼ƒã™ã‚‹ã¨å¤§åˆ†æ€§èƒ½ãŒä¸ŠãŒã£ã¦ãã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/5f7a329e-e83b-46da-9213-af8877201572" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/857b3526-4f56-4e31-8a69-a4193657b286" alt="image" loading="lazy"></p>
<p>reasoning modelã§ã¯fewshot promptingã‚’ã™ã‚‹ã¨æ€§èƒ½ãŒè½ã¡ã‚‹ã¨ã„ã†çŸ¥è¦‹ãŒã‚ã‚‹ã®ã§ã€reasoningãƒ¢ãƒ‡ãƒ«å‘ã‘ã®APEæ‰‹æ³•ã‚‚ãã®ã†ã¡å‡ºç¾ã™ã‚‹ã®ã ã‚ã†ï¼ˆæ—¢ã«ã‚ã‚Šãã†ï¼‰ã€‚</p>
<p>OpenReview: 


<a href="https://openreview.net/forum?id=VZC9aJoI6a" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=VZC9aJoI6a</a>


<br>ICLR'25ã«rejectã•ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-02-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1745" target="_blank" rel="noopener noreferrer" class="title-link">Tulu 3: Pushing Frontiers in Open Language Model Post-Training, Nathan Lambert+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Tulu 3ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã§ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ¬ã‚·ãƒ”ã‚’å…¬é–‹ã—ã€ç¾ä»£ã®ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æŠ€è¡“ã®ã‚¬ã‚¤ãƒ‰ã‚’æä¾›ã—ã¾ã™ã€‚Llama 3.1ã‚’åŸºã«ã—ã€ä»–ã®ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã€‚æ–°ã—ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã¨ã—ã¦SFTã€DPOã€RLVRã‚’æ¡ç”¨ã—ã€ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯è©•ä¾¡ã‚¹ã‚­ãƒ¼ãƒ ã‚’å°å…¥ã€‚ãƒ¢ãƒ‡ãƒ«ã‚¦ã‚§ã‚¤ãƒˆã‚„ãƒ‡ãƒ¢ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãªã©ã‚’å…¬é–‹ã—ã€ä»–ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã¸ã®é©å¿œã‚‚å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/icoxfog417/status/1885460713264775659?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<span class="issue_date">Issue Date: 2025-02-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1742" target="_blank" rel="noopener noreferrer" class="title-link">A Survey on Knowledge Distillation of Large Language Models, Xiaohan Xu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã‘ã‚‹çŸ¥è­˜è’¸ç•™ï¼ˆKDï¼‰ã®é‡è¦æ€§ã‚’èª¿æŸ»ã—ã€å°å‹ãƒ¢ãƒ‡ãƒ«ã¸ã®çŸ¥è­˜ä¼é”ã‚„ãƒ¢ãƒ‡ãƒ«åœ§ç¸®ã€è‡ªå·±æ”¹å–„ã®å½¹å‰²ã‚’å¼·èª¿ã€‚KDãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚„èªçŸ¥èƒ½åŠ›ã®å‘ä¸Šã€ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆDAï¼‰ã¨ã®ç›¸äº’ä½œç”¨ã‚’æ¤œè¨ã—ã€DAãŒLLMæ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€‚ç ”ç©¶è€…ã‚„å®Ÿå‹™è€…ã«å‘ã‘ãŸã‚¬ã‚¤ãƒ‰ã‚’æä¾›ã—ã€LLMã®KDã®å€«ç†çš„é©ç”¨ã‚’æ¨å¥¨ã€‚é–¢é€£æƒ…å ±ã¯Githubã§å…¥æ‰‹å¯èƒ½ã€‚</span>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-01-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1731" target="_blank" rel="noopener noreferrer" class="title-link">Don't Do RAG: When Cache-Augmented Generation is All You Need for  Knowledge Tasks, Brian J Chan+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ‹¡å¼µç”Ÿæˆï¼ˆCAGï¼‰ã¯ã€RAGã®èª²é¡Œã‚’å…‹æœã™ã‚‹ãŸã‚ã«ææ¡ˆã•ã‚ŒãŸæ‰‹æ³•ã§ã€LLMã®æ‹¡å¼µã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«äº‹å‰ã«é–¢é€£ãƒªã‚½ãƒ¼ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€æ¤œç´¢ãªã—ã§ã‚¯ã‚¨ãƒªã«å¿œç­”ã™ã‚‹ã€‚CAGã¯æ¤œç´¢ã®é…å»¶ã‚’æ’é™¤ã—ã€ã‚¨ãƒ©ãƒ¼ã‚’æœ€å°é™ã«æŠ‘ãˆã¤ã¤ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®é–¢é€£æ€§ã‚’ç¶­æŒã€‚æ€§èƒ½è©•ä¾¡ã§ã¯ã€CAGãŒå¾“æ¥ã®RAGã‚’ä¸Šå›ã‚‹ã‹è£œå®Œã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€ç‰¹ã«åˆ¶ç´„ã®ã‚ã‚‹çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«ãŠã„ã¦åŠ¹ç‡çš„ãªä»£æ›¿æ‰‹æ®µã¨ãªã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1876721221083214200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¤–éƒ¨çŸ¥è­˜ã¨ã—ã¦åˆ©ç”¨ã—ãŸã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒãã“ã¾ã§å¤§ããç„¡ã„ãªã‚‰ã€äº‹å‰ã«LLMã§å…¨ã¦ã®Key Valueã‚’è¨ˆç®—ã—ã¦ãŠãKV Cacheã¨ã—ã¦åˆ©ç”¨å¯èƒ½ã«ã—ã¦ãŠã‘ã°ã€ç”Ÿæˆæ™‚ã«æ¤œç´¢ã‚’ã™ã‚‹ã“ã¨ã‚‚ãªãã€contextã¨ã—ã¦åˆ©ç”¨ã—ã¦ç”Ÿæˆã§ãã‚‹ã˜ã‚ƒã‚“ã€ã¨ã„ã†ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1729" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Chain of Agents: Large language models collaborating on long-context tasks, Google Research, 2025.01, NeurIPS'24</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/googleai/status/1882554959272849696?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLMãŒã©ã“ã¾ã§ã„ã£ã¦ã‚‚contexté•·ã®åˆ¶ç´„ã«ç›´é¢ã™ã‚‹å•é¡Œã«å¯¾ã—ã¦LLM Agentã‚’çµ„ã¿åˆã‚ã›ã¦å¯¾å‡¦ã—ã¾ã—ãŸã€çš„ãªè©±ãªæ¨¡æ§˜</p>
<p>ãƒ–ãƒ­ã‚°ä¸­ã«ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’è§£èª¬ã—ãŸå‹•ç”»ãŒã‚ã‚‹ã®ã§ã‚ã‹ã‚Šã‚„ã™ã„</p>
<p>Is the experimental code open source?</p>
<p>Thank you for your comment. I tried to find an official open-source implementation provided by the authors, but I was not able to locate one. In fact, I also checked the personal webpage of the first author, but there was no link to any released code.<br><br>Is seems that an unofficial implementation is listed under the â€œCodeâ€ tab on the NeurIPS page. I hope this is helpful. Thank you.<br><br>NeurIPS link: 


<a href="https://nips.cc/virtual/2024/poster/95563" target="_blank" rel="noopener noreferrer">https://nips.cc/virtual/2024/poster/95563</a>


<br>openreview: 


<a href="https://openreview.net/forum?id=LuCLf4BJsr" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=LuCLf4BJsr</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1724" target="_blank" rel="noopener noreferrer" class="title-link">Spectrum: Targeted Training on Signal to Noise Ratio, Eric Hartford+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ã€ŒSpectrumã€ã¨ã„ã†æ‰‹æ³•ã‚’ææ¡ˆã—ã€SNRã«åŸºã¥ã„ã¦ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’é¸æŠçš„ã«ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã™ã‚‹ã“ã¨ã§ã€LLMã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’åŠ é€Ÿã€‚ã“ã‚Œã«ã‚ˆã‚ŠGPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›ã—ã¤ã¤ã€ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’å®Ÿç¾ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æ—¢å­˜æ‰‹æ³•QLoRAã¨æ¯”è¼ƒã—ã¦ãƒ¢ãƒ‡ãƒ«ã®å“è³ªã¨VRAMåŠ¹ç‡ã®å‘ä¸ŠãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1723" target="_blank" rel="noopener noreferrer">How to fine-tune open LLMs in 2025 with Hugging Face, PHILSCHMID, 2024.12</a>
<br><br>ã«ã‚ˆã‚‹ã¨LLMã®ã†ã¡æœ€ã‚‚informativeãªLayerã‚’è¦‹ã¤ã‘ã€é¸æŠçš„ã«å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€çœãƒªã‚½ãƒ¼ã‚¹ã§ã€Full-Parameter tuningã¨åŒç­‰ã®æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹æ‰‹æ³•ã‚‰ã—ã„<br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1705" target="_blank" rel="noopener noreferrer" class="title-link">Learning to Edit: Aligning LLMs with Knowledge Editing, Yuxin Jiang+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- ã€ŒLearning to Editï¼ˆLTEï¼‰ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€LLMsã«æ–°ã—ã„çŸ¥è­˜ã‚’åŠ¹æœçš„ã«é©ç”¨ã™ã‚‹æ–¹æ³•ã‚’æ•™ãˆã‚‹ã€‚äºŒæ®µéšãƒ—ãƒ­ã‚»ã‚¹ã§ã€ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãƒ•ã‚§ãƒ¼ã‚ºã§ä¿¡é ¼ã§ãã‚‹ç·¨é›†ã‚’è¡Œã„ã€æ¨è«–ãƒ•ã‚§ãƒ¼ã‚ºã§ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä½¿ç”¨ã€‚å››ã¤ã®çŸ¥è­˜ç·¨é›†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§LTEã®å„ªä½æ€§ã¨å …ç‰¢æ€§ã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1699" target="_blank" rel="noopener noreferrer" class="title-link">OlympiadBench: A Challenging Benchmark for Promoting AGI with   Olympiad-Level Bilingual Multimodal Scientific Problems, Chaoqun He+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ï¼ˆLMMsï¼‰ã®èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã«ã€ã‚ªãƒªãƒ³ãƒ”ã‚¢ãƒ‰ãƒ¬ãƒ™ãƒ«ã®ãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç§‘å­¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒOlympiadBenchã€ã‚’ææ¡ˆã€‚8,476ã®æ•°å­¦ã¨ç‰©ç†ã®å•é¡Œã‚’å«ã¿ã€å°‚é–€å®¶ãƒ¬ãƒ™ãƒ«ã®æ³¨é‡ˆãŒä»˜ã‘ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ãƒˆãƒƒãƒ—ãƒ¢ãƒ‡ãƒ«ã®GPT-4Vã¯å¹³å‡17.97%ã®ã‚¹ã‚³ã‚¢ã‚’é”æˆã—ãŸãŒã€ç‰©ç†ã§ã¯10.74%ã«ã¨ã©ã¾ã‚Šã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å³ã—ã•ã‚’ç¤ºã™ã€‚ä¸€èˆ¬çš„ãªå•é¡Œã¨ã—ã¦å¹»è¦šã‚„è«–ç†çš„èª¤è¬¬ãŒæŒ‡æ‘˜ã•ã‚Œã€ä»Šå¾Œã®AGIç ”ç©¶ã«è²´é‡ãªãƒªã‚½ãƒ¼ã‚¹ã¨ãªã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1665" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models, Damai+, ACL'24, 2024.08</a>
<span class="snippet"><span>GPT Summary</span>- DeepSeekMoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€å°‚é–€å®¶ã®å°‚é–€æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã€å°‚é–€å®¶ã‚’ç´°åˆ†åŒ–ã—æŸ”è»Ÿãªçµ„ã¿åˆã‚ã›ã‚’å¯èƒ½ã«ã—ã€å…±æœ‰å°‚é–€å®¶ã‚’è¨­ã‘ã¦å†—é•·æ€§ã‚’è»½æ¸›ã™ã‚‹ã€‚2Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®DeepSeekMoEã¯ã€GShardã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã—ã€åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å¯†ãªãƒ¢ãƒ‡ãƒ«ã«è¿‘ã¥ãã€‚16Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã—ãŸéš›ã‚‚ã€è¨ˆç®—é‡ã‚’ç´„40%ã«æŠ‘ãˆã¤ã¤ã€LLaMA2ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-01-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1655" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open  Language Models, Zhihong Shao+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- DeepSeekMath 7Bã¯ã€120Bã®æ•°å­¦é–¢é€£ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”¨ã„ã¦äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€ç«¶æŠ€ãƒ¬ãƒ™ãƒ«ã®MATHãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§51.7%ã®ã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚è‡ªå·±ä¸€è²«æ€§ã¯60.9%ã§ã€ãƒ‡ãƒ¼ã‚¿é¸æŠãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨Group Relative Policy Optimization (GRPO)ã®å°å…¥ã«ã‚ˆã‚Šæ•°å­¦çš„æ¨è«–èƒ½åŠ›ãŒå‘ä¸Šã€‚Gemini-Ultraã‚„GPT-4ã«è¿«ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_the-rlhf-method-behind-the-best-open-models-activity-7280850174522843137-3V9v?utm_source=share&utm_medium=member_ios" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_the-rlhf-method-behind-the-best-open-models-activity-7280850174522843137-3V9v?utm_source=share&utm_medium=member_ios</a>


</p>
<p>å…ƒã€…æ•°å­¦ã®reasoningã«é–¢ã™ã‚‹èƒ½åŠ›ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ææ¡ˆã•ã‚ŒãŸãŒã€ç¾åœ¨ã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§Truthfulness, Helpfulness, Concisenessãªã©ã®æ”¹å–„ã«æ´»ç”¨ã•ã‚Œã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚</p>
<p>PPOã¨GRPOã®æ¯”è¼ƒã€‚value function modelï¼ˆçŠ¶æ…‹ã®ä¾¡å€¤ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼‰ãŒä¸è¦ãªãŸã‚çœãƒ¡ãƒ¢ãƒªã€ã‹ã¤åˆ©ç”¨ã™ã‚‹è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ãŒå°ã•ã„ã‚‰ã—ã„ã€‚<br>ã‚ã¨ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«åˆ†ã‘ã¦ã€ã‚°ãƒ«ãƒ¼ãƒ—å†…ã§ã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ãŒæœ€å°åŒ–ã•ã‚Œã‚‹ã‚ˆã†ï¼ˆã¤ã¾ã‚Šã€å„ã‚°ãƒ«ãƒ¼ãƒ—å†…ã§æ–¹ç­–ãŒé¡ä¼¼ã™ã‚‹ï¼‰Policy ModelãŒæ›´æ–°ã•ã‚Œã‚‹ï¼ˆã¤ã¾ã‚Šloss functionã«ç›´æ¥çµ„ã¿è¾¼ã¾ã‚Œã‚‹ï¼‰ç‚¹ãŒé•ã†ã‚‰ã—ã„ã€‚<br><br>PPOã§ã¯ç”Ÿæˆã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ã«reference modelã¨Policy Modelã¨ã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚’ã¨ã‚Šã€reference modelã¨ã®å·®ãŒå¤§ãããªã‚‰ãªã„ã‚ˆã†ã€å ±é…¬ã«ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’å…¥ã‚Œã‚‹ãŸã‚ã«ä½¿ã‚ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã‚‰ã—ã„ã€‚<br><img src="https://github.com/user-attachments/assets/e145ad52-e6c9-4481-b2ee-10a3987ea2e3" alt="image" loading="lazy"></p>
<p>ä¸‹è¨˜è¨˜äº‹ã«ã‚ˆã‚‹ã¨ã€PPOã§æœ€å¤§åŒ–ã—ãŸã„ã®ã¯Advantageï¼ˆç´¯ç©å ±é…¬ã¨çŠ¶æ…‹ä¾¡å€¤ï¼ˆç´¯ç©å ±é…¬ã®æœŸå¾…å€¤ã‚’è¨ˆç®—ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼‰ã®å·®åˆ†;æœŸå¾…å€¤ã‚ˆã‚Šã‚‚å®Ÿéš›ã®ç´¯ç©å ±é…¬ãŒè‰¯ã‹ã£ãŸã‚‰è‰¯ã„æ„Ÿã˜ã ãœçš„ãªæ•°å€¤ï¼‰ã§ã‚ã‚Šã€ãã‚Œã«ã¯çŠ¶æ…‹ä¾¡å€¤ã‚’è¨ˆç®—ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ã§ã‚ã‚‹ã€‚ãã—ã¦ã€PPOã«ãŠã‘ã‚‹çŠ¶æ…‹ä¾¡å€¤ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã‚ãªã„ã§ã€LLMã«ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã•ã›ã¦æœ€çµ‚çš„ãªå ±é…¬ã‚’å¹³å‡ã™ã‚Œã°çŠ¶æ…‹ä¾¡å€¤ãƒ¢ãƒ‡ãƒ«ç„¡ã—ã§AdvantageãŒè¨ˆç®—ã§ãã‚‹ã—å¬‰ã—ãã­ï¼Ÿã¨ã„ã†æ°—æŒã¡ã§ææ¡ˆã•ã‚ŒãŸã®ãŒã€æœ¬è«–æ–‡ã§ææ¡ˆã•ã‚Œã¦ã„ã‚‹GRPOã¨ã®ã“ã¨ã€‚å‹‰å¼·ã«ãªã‚‹ã€‚<br><br>DeepSeek-R1ã®è«–æ–‡èª­ã‚“ã ï¼Ÿã€å‹‰å¼·ã«ãªã‚‹ã‚ˆã€‘<br>, asap: 


<a href="https://zenn.dev/asap/articles/34237ad87f8511" target="_blank" rel="noopener noreferrer">https://zenn.dev/asap/articles/34237ad87f8511</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1650" target="_blank" rel="noopener noreferrer" class="title-link">Does RLHF Scale? Exploring the Impacts From Data, Model, and Method, Zhenyu Hou+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMsã«ãŠã‘ã‚‹RLHFã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç‰¹æ€§ã‚’åˆ†æã—ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã€ãƒ‡ãƒ¼ã‚¿æ§‹æˆã€æ¨è«–äºˆç®—ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã€‚ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ã¨é‡ã®å¢—åŠ ãŒå ±é…¬ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹ä¸€æ–¹ã€ãƒãƒªã‚·ãƒ¼ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã¯å¿œç­”ã‚µãƒ³ãƒ—ãƒ«æ•°ã®å¢—åŠ ãŒåˆæœŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ã™ãã«é ­æ‰“ã¡ã«ãªã‚‹ã“ã¨ãŒåˆ¤æ˜ã€‚RLHFã¯äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚ˆã‚ŠåŠ¹ç‡çš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã›ãšã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã®åç›Šé€“æ¸›ãŒè¦³å¯Ÿã•ã‚ŒãŸã€‚è¨ˆç®—åˆ¶é™å†…ã§ã®RLHFãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–æˆ¦ç•¥ã‚‚ææ¡ˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1868299930600628451?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1649" target="_blank" rel="noopener noreferrer" class="title-link">AutoReason: Automatic Few-Shot Reasoning Decomposition, Arda Sevinc+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Chain of Thoughtï¼ˆCoTï¼‰ã‚’ç”¨ã„ã¦ã€æš—é»™ã®ã‚¯ã‚¨ãƒªã‚’æ˜ç¤ºçš„ãªè³ªå•ã«åˆ†è§£ã™ã‚‹ã“ã¨ã§ã€LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹è‡ªå‹•ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã‚’ææ¡ˆã€‚StrategyQAã¨HotpotQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ç²¾åº¦å‘ä¸Šã‚’ç¢ºèªã—ã€ç‰¹ã«StrategyQAã§é¡•è‘—ãªæˆæœã‚’å¾—ãŸã€‚ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1868299926897074309?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/SyntheticDataGeneration.html" target="_blank" rel="noopener noreferrer">#SyntheticDataGeneration</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1648" target="_blank" rel="noopener noreferrer" class="title-link">MAG-V: A Multi-Agent Framework for Synthetic Data Generation and  Verification, Saptarshi Sengupta+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- MAG-Vã¨ã„ã†ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€é¡§å®¢ã‚¯ã‚¨ãƒªã‚’æ¨¡å€£ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆã—ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚è»Œè·¡ã®æ¤œè¨¼æ‰‹æ³•ã¯å¾“æ¥ã®MLãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã€GPT-4ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã™ã€‚å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’çµ±ä¸€ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1868299921117630528?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<a class="button" href="articles/Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1646" target="_blank" rel="noopener noreferrer" class="title-link">Precise Length Control in Large Language Models, Bradley Butcher+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMã®å¿œç­”ã®é•·ã•ã‚’æ­£ç¢ºã«åˆ¶å¾¡ã™ã‚‹ãŸã‚ã«ã€äºŒæ¬¡çš„ãªé•·ã•å·®ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆLDPEï¼‰ã‚’ç”¨ã„ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚LDPEã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã¯å¹³å‡3ãƒˆãƒ¼ã‚¯ãƒ³æœªæº€ã®èª¤å·®ã§æœ›ã¾ã—ã„é•·ã•ã§å¿œç­”ã‚’çµ‚äº†ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚ã¾ãŸã€æŸ”è»Ÿãªä¸Šé™é•·ã•åˆ¶å¾¡ã‚’å¯èƒ½ã«ã™ã‚‹Max New Tokens++ã‚‚å°å…¥ã€‚å®Ÿé¨“çµæœã¯ã€è³ªå•å¿œç­”ã‚„æ–‡æ›¸è¦ç´„ã«ãŠã„ã¦å¿œç­”ã®è³ªã‚’ç¶­æŒã—ã¤ã¤æ­£ç¢ºãªé•·ã•åˆ¶å¾¡ãŒå®Ÿç¾ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1870821203780256178?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1647" target="_blank" rel="noopener noreferrer">Controlling Output Length in Neural Encoder-Decoders, Yuta Kikuchi+, EMNLP'16</a>
<br><br>ãªã©ã®Encoder-Decoderãƒ¢ãƒ‡ãƒ«ã§è¡Œã‚ã‚Œã¦ã„ãŸoutput lengthã®åˆ¶å¾¡ã‚’Decoder-onlyãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã‚„ã‚Šã¾ã—ãŸã€ã¨ã„ã†è©±ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1645" target="_blank" rel="noopener noreferrer" class="title-link">TheAgentCompany: Benchmarking LLM Agents on Consequential Real World  Tasks, Frank F. Xu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ—¥å¸¸ç”Ÿæ´»ã‚„ä»•äº‹ã«ãŠã‘ã‚‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åŠ¹æœã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã€TheAgentCompanyã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã€‚AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€ã‚¦ã‚§ãƒ–ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ã‚„ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œãªã©ã®ã‚¿ã‚¹ã‚¯ã‚’è‡ªå¾‹çš„ã«è¡Œã†èƒ½åŠ›ã‚’è©•ä¾¡ã€‚ãƒ†ã‚¹ãƒˆã®çµæœã€æœ€ã‚‚ç«¶äº‰åŠ›ã®ã‚ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã‚¿ã‚¹ã‚¯ã®24%ã‚’è‡ªå¾‹çš„ã«å®Œäº†ã§ãã‚‹ã“ã¨ãŒåˆ¤æ˜ã€‚ç°¡å˜ãªã‚¿ã‚¹ã‚¯ã¯è‡ªå‹•åŒ–å¯èƒ½ã ãŒã€é›£ã—ã„é•·æœŸçš„ãªã‚¿ã‚¹ã‚¯ã¯ç¾è¡Œã‚·ã‚¹ãƒ†ãƒ ã§ã¯å¯¾å¿œã§ããªã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1870821189809217921?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ä¼æ¥­ã®è¨­å®šã§ç¾å®Ÿã«èµ·ã“ã‚Šã†ã‚‹ãªã€€175ç¨®é¡ã®ã‚¿ã‚¹ã‚¯ã‚’å®šç¾©ã—ã¦AI Agentã‚’è©•ä¾¡ã§ãã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯TheAgentCompanyã‚’ææ¡ˆã€‚<br><br><img src="https://github.com/user-attachments/assets/ef7b51d3-b4af-4171-a692-48fb2c2552ef" alt="image" loading="lazy"><br><br>æ—¢å­˜ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚ˆã‚Šã€å¤šæ§˜ã§ã€å®Ÿéš›ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ä¼æ¥­ã§ã§èµ·ã“ã‚Šã†ã‚‹å¹…åºƒã„ã‚¿ã‚¹ã‚¯ã‚’æŒã¡ã€ã‚¿ã‚¹ã‚¯ã®é‚è¡Œã®ãŸã‚ã«åŒåƒšã«å¯¾ã—ã¦ä½•ã‚‰ã‹ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãŒå¿…è¦ã§ã€é”æˆã®ãŸã‚ã«å¤šãã®ã‚¹ãƒ†ãƒƒãƒ—ãŒå¿…è¦ã§ã‹ã¤å€‹ã€…ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆã‚µãƒ–ã‚¿ã‚¹ã‚¯ï¼‰ã‚’è©•ä¾¡å¯èƒ½ã§ã€å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã‚’é‚è¡Œã™ã‚‹ãŸã‚ã«å¿…è¦ãªæ§˜ã€…ãªã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ã‚«ãƒãƒ¼ã—ã€self hostingã—ã¦çµæœã‚’å®Œå…¨ã«å†ç¾å¯èƒ½ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ãªã£ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/e5fbd6da-75d7-49e1-8c66-dc7950d443e4" alt="image" loading="lazy"><br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1869735196700062089?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>ï¼ˆç”»åƒã¯è‘—è€…ãƒ„ã‚¤ãƒ¼ãƒˆã‚ˆã‚Šå¼•ç”¨ï¼‰<p>ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãªãƒ¢ãƒ‡ãƒ«ã¨OpenWeightãªãƒ¢ãƒ‡ãƒ«ã§AI Agentã¨ã—ã¦ã®èƒ½åŠ›ã‚’è©•ä¾¡ã—ãŸçµæœã€Claude-3.5-sonnetã¯ç´„24%ã®ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºå¯èƒ½ã§ã‚ã‚Šã€ä»–ãƒ¢ãƒ‡ãƒ«ã¨æ¯”ã¹ã¦æ€§èƒ½ãŒæ˜ã‚‰ã‹ã«è‰¯ã‹ã£ãŸã€‚ã¾ãŸã€Gemini-2.0-flashãªã‚³ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å„ªã‚Œã¦ã„ã‚‹ã€‚OpenWeightãªãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§ã¯Llama3.3-70Bã®ã‚³ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒè‰¯ã‹ã£ãŸã€‚ã‚¿ã‚¹ã‚¯ã¨ã—ã¦ã¯å…·ä½“çš„ã«è©•ä¾¡å¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®ã¿ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€Open Endãªã‚¿ã‚¹ã‚¯ã§ã¯è©•ä¾¡ã—ã¦ã„ãªã„ç‚¹ã«æ³¨æ„ã¨ã®ã“ã¨ã€‚<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1869735209404682706?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1869735213976432764?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><img src="https://github.com/user-attachments/assets/3bdcabef-70da-4f09-8366-efe29f7ab371" alt="image" loading="lazy"><p>ã¾ã ã¾ã AI AgentãŒå®Œå…¨ã«'åŒåƒš'ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã“ã¨ã¨ã¯ç¾æ™‚ç‚¹ã§ã¯ãªã•ãã†ã ãŒã€ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚¹ã‚³ã‚¢ãŒä»Šå¾Œã©ã“ã¾ã§ä¸ŠãŒã£ã¦ã„ãã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1644" target="_blank" rel="noopener noreferrer" class="title-link">A Survey of Mathematical Reasoning in the Era of Multimodal Large  Language Model: Benchmark, Method &amp; Challenges, Yibo Yan+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ•°å­¦çš„æ¨è«–ã¯å¤šãã®åˆ†é‡ã§é‡è¦ã§ã‚ã‚Šã€AGIã®é€²å±•ã«ä¼´ã„ã€LLMsã‚’æ•°å­¦çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã«çµ±åˆã™ã‚‹ã“ã¨ãŒæ±‚ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚æœ¬èª¿æŸ»ã¯ã€2021å¹´ä»¥é™ã®200ä»¥ä¸Šã®ç ”ç©¶ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è¨­å®šã«ãŠã‘ã‚‹Math-LLMsã®é€²å±•ã‚’åˆ†æã€‚åˆ†é‡ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€æ–¹æ³•è«–ã€èª²é¡Œã«åˆ†é¡ã—ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ•°å­¦çš„æ¨è«–ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚„LLMsã®å½¹å‰²ã‚’æ¢ã‚‹ã€‚ã•ã‚‰ã«ã€AGIå®Ÿç¾ã®éšœå®³ã¨ãªã‚‹5ã¤ã®èª²é¡Œã‚’ç‰¹å®šã—ã€ä»Šå¾Œã®ç ”ç©¶æ–¹å‘æ€§ã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/KnowledgeGraph.html" target="_blank" rel="noopener noreferrer">#KnowledgeGraph</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1643" target="_blank" rel="noopener noreferrer" class="title-link">Can LLMs Convert Graphs to Text-Attributed Graphs?, Zehong Wang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Topology-Aware Node description Synthesisï¼ˆTANSï¼‰ã‚’ææ¡ˆã—ã€GNNãŒç•°ãªã‚‹ç‰¹å¾´ç©ºé–“ã‚’æŒã¤ã‚°ãƒ©ãƒ•ã«é©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚TANSã¯LLMsã‚’ç”¨ã„ã¦æ—¢å­˜ã®ã‚°ãƒ©ãƒ•ã‚’ãƒ†ã‚­ã‚¹ãƒˆå±æ€§ã‚°ãƒ©ãƒ•ã«å¤‰æ›ã—ã€ãƒãƒ¼ãƒ‰ã®ç‰¹æ€§ã«ãƒˆãƒãƒ­ã‚¸ãƒ¼æƒ…å ±ã‚’çµ±åˆã€‚ãƒ†ã‚­ã‚¹ãƒˆãŒãªã„ã‚°ãƒ©ãƒ•ã§ã‚‚æ‰‹å‹•è¨­è¨ˆã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€LLMsã®å¯èƒ½æ€§ã‚’å®Ÿè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1868691391129272461?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1641" target="_blank" rel="noopener noreferrer" class="title-link">How Much Data is Enough Data? Fine-Tuning Large Language Models for  In-House Translation: Performance Evaluation Across Multiple Dataset Sizes, Inacio Vieira+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ç¿»è¨³ãƒ¡ãƒ¢ãƒªï¼ˆTMsï¼‰ã‚’æ´»ç”¨ã—ã€ç‰¹å®šã®çµ„ç¹”å‘ã‘ã®ç¿»è¨³ç²¾åº¦ã¨åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ç ”ç©¶ã€‚5ã¤ã®ç¿»è¨³æ–¹å‘ã§ç•°ãªã‚‹ã‚µã‚¤ã‚ºã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦å®Ÿé¨“ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒå¢—ãˆã‚‹ã»ã©ç¿»è¨³ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚ç‰¹ã«ã€1kãŠã‚ˆã³2kã®ä¾‹ã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºãŒå¢—åŠ ã™ã‚‹ã«ã¤ã‚Œã¦æ”¹å–„ãŒè¦‹ã‚‰ã‚Œã‚‹ã€‚LLMsã¨TMsã®çµ±åˆã«ã‚ˆã‚Šã€ä¼æ¥­ç‰¹æœ‰ã®ãƒ‹ãƒ¼ã‚ºã«å¿œã˜ãŸã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã®å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>QLoRAã§Llama 8B Instructã‚’MTã®ãƒ‡ãƒ¼ã‚¿ã§SFTã—ãŸå ´åˆã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã«å¯¾ã™ã‚‹æ€§èƒ½ã®å¤‰åŒ–ã‚’æ¤œè¨¼ã—ã¦ã„ã‚‹ã€‚ãŸã ã—ã€æ¤œè¨¼ã—ã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ã¯MTã€QLoRAã§SFTã‚’å®Ÿæ–½ã—rankã¯64ã€å­¦ç¿’æ™‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯éå¸¸ã«ã‚·ãƒ³ãƒ—ãƒ«ãªã‚‚ã®ã§ã‚ã‚‹ãªã©ã€å¹…åºƒã„è¨­å®šã§å­¦ç¿’ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã®ã§ã€ã“ã“ã§å¾—ã‚‰ã‚ŒãŸçŸ¥è¦‹ãŒå¹…åºƒãé©ç”¨å¯èƒ½ãªã“ã¨ã¯ç¤ºã•ã‚Œã¦ã„ãªã„ã§ã‚ã‚ã†ç‚¹ã€ã«ã¯æ³¨æ„ãŒå¿…è¦ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>ã“ã®è¨­å®šã§ã¯ã€SFTã§åˆ©ç”¨ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå¢—ãˆã‚Œã°å¢—ãˆã‚‹ã»ã©æ€§èƒ½ãŒä¸ŠãŒã£ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/71309a00-85fd-491f-a89e-c9cb99f4da6c" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/ea1eba38-9488-43e5-a64b-f997bf65f57b" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/21b21628-d589-4214-8860-680e392a2556" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1640" target="_blank" rel="noopener noreferrer" class="title-link">LoRA Learns Less and Forgets Less, Dan Biderman+, TMLR'24</a>
<span class="snippet"><span>GPT Summary</span>- LoRAã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®åŠ¹ç‡çš„ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã§ã‚ã‚Šã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¨æ•°å­¦ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®æ€§èƒ½ã‚’ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¯”è¼ƒã€‚æ¨™æº–çš„ãªè¨­å®šã§ã¯LoRAã¯æ€§èƒ½ãŒåŠ£ã‚‹ãŒã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‰ãƒ¡ã‚¤ãƒ³å¤–ã®ã‚¿ã‚¹ã‚¯ã§ã¯ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ç¶­æŒã—ã€å¿˜å´ã‚’è»½æ¸›ã™ã‚‹åŠ¹æœãŒã‚ã‚‹ã€‚ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯LoRAã‚ˆã‚Šã‚‚é«˜ã„ãƒ©ãƒ³ã‚¯ã®æ‘‚å‹•ã‚’å­¦ç¿’ã—ã€æ€§èƒ½å·®ã®ä¸€å› ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚æœ€çµ‚çš„ã«ã€LoRAã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«é–¢ã™ã‚‹ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’ææ¡ˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>full finetuningã¨LoRAã®æ€§è³ªã®é•ã„ã‚’ç†è§£ã™ã‚‹ã®ã«æœ‰ç”¨</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1639" target="_blank" rel="noopener noreferrer" class="title-link">FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge  into LLMs?, Eric Wu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å•†æ¥­çš„ãªLLMå¾®èª¿æ•´APIã®åŠ¹æœã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®FineTuneBenchã‚’ææ¡ˆã€‚5ã¤ã®æœ€å‰ç·šã®LLMã‚’åˆ†æã—ã€æ–°ã—ã„æƒ…å ±ã®å­¦ç¿’ã¨æ—¢å­˜çŸ¥è­˜ã®æ›´æ–°ã«ãŠã‘ã‚‹èƒ½åŠ›ã‚’è©•ä¾¡ã—ãŸçµæœã€å…¨ãƒ¢ãƒ‡ãƒ«ã§å¹³å‡ä¸€èˆ¬åŒ–ç²¾åº¦ã¯37%ã€åŒ»ç™‚ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã®æ›´æ–°ã§ã¯19%ã¨ä½ã„ã“ã¨ãŒåˆ¤æ˜ã€‚ç‰¹ã«GPT-4o miniãŒæœ€ã‚‚åŠ¹æœçš„ã§ã€Gemini 1.5ã‚·ãƒªãƒ¼ã‚ºã¯èƒ½åŠ›ãŒé™ã‚‰ã‚Œã¦ã„ãŸã€‚å•†æ¥­çš„å¾®èª¿æ•´ã‚µãƒ¼ãƒ“ã‚¹ã®ä¿¡é ¼æ€§ã«èª²é¡ŒãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1638" target="_blank" rel="noopener noreferrer" class="title-link">Examining Forgetting in Continual Pre-training of Aligned Large Language  Models, Chen-An Li+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ç¶™ç¶šçš„ãªäº‹å‰å­¦ç¿’ãŒãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã—ã€å£Šæ»…çš„ãªå¿˜å´ã®ç¾è±¡ã‚’è©•ä¾¡ã€‚å‡ºåŠ›å½¢å¼ã‚„çŸ¥è­˜ã€ä¿¡é ¼æ€§ã®æ¬¡å…ƒã§ã®å®Ÿé¨“çµæœãŒã€ç‰¹ã«ç¹°ã‚Šè¿”ã—ã®å•é¡Œã«ãŠã‘ã‚‹å¿˜å´ã®èª²é¡Œã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1637" target="_blank" rel="noopener noreferrer" class="title-link">Generative AI for Synthetic Data Generation: Methods, Challenges and the  Future, Xu Guo+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- é™ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒŠãƒªã‚ªã§LLMsã‚’ç”¨ã„ã¦åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ç ”ç©¶ãŒå¢—åŠ ã—ã¦ãŠã‚Šã€ã“ã‚Œã¯ç”Ÿæˆçš„AIã®é€²å±•ã‚’ç¤ºã™ã€‚LLMsã¯å®Ÿä¸–ç•Œã®ãƒ‡ãƒ¼ã‚¿ã¨åŒç­‰ã®æ€§èƒ½ã‚’æŒã¡ã€ãƒªã‚½ãƒ¼ã‚¹ãŒé™ã‚‰ã‚ŒãŸèª²é¡Œã«å¯¾ã™ã‚‹è§£æ±ºç­–ã¨ãªã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€ã‚¿ã‚¹ã‚¯ç‰¹åŒ–å‹ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ãŸã‚ã®æŠ€è¡“ã€è©•ä¾¡æ–¹æ³•ã€å®Ÿç”¨çš„å¿œç”¨ã€ç¾åœ¨ã®åˆ¶é™ã€å°†æ¥ã®ç ”ç©¶ã®æ–¹å‘æ€§ã«ã¤ã„ã¦è­°è«–ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1636" target="_blank" rel="noopener noreferrer" class="title-link">On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A  Survey, Lin Long+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ·±å±¤å­¦ç¿’ã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿ã®é‡ã¨è³ªã®å•é¡Œã«å¯¾ã—ã€LLMsãŒåˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚’é€šã˜ã¦è§£æ±ºç­–ã‚’æä¾›ã€‚ã—ã‹ã—ã€ç¾çŠ¶ã®ç ”ç©¶ã¯çµ±ä¸€ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ¬ ãã€è¡¨é¢çš„ãªã‚‚ã®ãŒå¤šã„ã€‚æœ¬è«–æ–‡ã§ã¯åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ•´ç†ã—ã€ç ”ç©¶ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’æ˜ã‚‰ã‹ã«ã—ã€ä»Šå¾Œã®å±•æœ›ã‚’ç¤ºã™ã€‚å­¦è¡“ç•Œã¨ç”£æ¥­ç•Œã®ã‚ˆã‚Šä½“ç³»çš„ãªæ¢æ±‚ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2024-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1630" target="_blank" rel="noopener noreferrer" class="title-link">Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via  Collective Monte Carlo Tree Search, Huanjin Yao+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€MLLMã‚’ç”¨ã„ã¦è³ªå•è§£æ±ºã®ãŸã‚ã®æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’å­¦ç¿’ã™ã‚‹æ–°æ‰‹æ³•CoMCTSã‚’ææ¡ˆã€‚é›†å›£å­¦ç¿’ã‚’æ´»ç”¨ã—ã€è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã§åŠ¹æœçš„ãªæ¨è«–çµŒè·¯ã‚’æ¢ç´¢ã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆMulberry-260kã‚’æ§‹ç¯‰ã—ã€ãƒ¢ãƒ‡ãƒ«Mulberryã‚’è¨“ç·´ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šææ¡ˆæ‰‹æ³•ã®å„ªä½æ€§ã‚’ç¢ºèªã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<span class="issue_date">Issue Date: 2024-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1629" target="_blank" rel="noopener noreferrer" class="title-link">LearnLM: Improving Gemini for Learning, LearnLM Team+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ç”ŸæˆAIã‚·ã‚¹ãƒ†ãƒ ã¯å¾“æ¥ã®æƒ…å ±æç¤ºã«åã£ã¦ã„ã‚‹ãŸã‚ã€æ•™è‚²çš„è¡Œå‹•ã‚’æ³¨å…¥ã™ã‚‹ã€Œæ•™è‚²çš„æŒ‡ç¤ºã®éµå®ˆã€ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®æŒ¯ã‚‹èˆã„ã‚’æŸ”è»Ÿã«æŒ‡å®šã§ãã€æ•™è‚²ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§Geminiãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’å‘ä¸Šã€‚LearnLMãƒ¢ãƒ‡ãƒ«ã¯ã€ã•ã¾ã–ã¾ãªå­¦ç¿’ã‚·ãƒŠãƒªã‚ªã§å°‚é–€å®¶ã‹ã‚‰é«˜ãè©•ä¾¡ã•ã‚Œã€GPT-4oã‚„Claude 3.5ã«å¯¾ã—ã¦ã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/TheoryOfMind.html" target="_blank" rel="noopener noreferrer">#TheoryOfMind</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2024-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1628" target="_blank" rel="noopener noreferrer" class="title-link">Explore Theory of Mind: Program-guided adversarial data generation for  theory of mind reasoning, Melanie Sclar+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ExploreToMã¯ã€å¿ƒã®ç†è«–ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®å¤šæ§˜ã§æŒ‘æˆ¦çš„ãªãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€LLMsã®é™ç•Œã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã€‚æœ€å…ˆç«¯ã®LLMsã¯ã€ExploreToMç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ä½ã„ç²¾åº¦ã‚’ç¤ºã—ã€å …ç‰¢ãªè©•ä¾¡ã®å¿…è¦æ€§ã‚’å¼·èª¿ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šå¾“æ¥ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ç²¾åº¦å‘ä¸Šã‚’å®Ÿç¾ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®è¦å› ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãŠã‚‚ã—ã‚ãã†ã€‚ã‚ã¨ã§èª­ã‚€</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1627" target="_blank" rel="noopener noreferrer" class="title-link">A Survey on LLM Inference-Time Self-Improvement, Xiangjue Dong+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMæ¨è«–ã«ãŠã‘ã‚‹è‡ªå·±æ”¹å–„æŠ€è¡“ã‚’ä¸‰ã¤ã®è¦–ç‚¹ã‹ã‚‰æ¤œè¨ã€‚ç‹¬ç«‹ã—ãŸè‡ªå·±æ”¹å–„ã¯ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ç„¦ç‚¹ã€æ–‡è„ˆã«å¿œã˜ãŸè‡ªå·±æ”¹å–„ã¯è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã€ãƒ¢ãƒ‡ãƒ«æ”¯æ´ã®è‡ªå·±æ”¹å–„ã¯ãƒ¢ãƒ‡ãƒ«é–“ã®å”åŠ›ã‚’é€šã˜ã¦è¡Œã†ã€‚é–¢é€£ç ”ç©¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨èª²é¡Œã€ä»Šå¾Œã®ç ”ç©¶ã¸ã®æ´å¯Ÿã‚’æä¾›ã€‚</span>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-12-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1624" target="_blank" rel="noopener noreferrer" class="title-link">RetroLLM: Empowering Large Language Models to Retrieve Fine-grained  Evidence within Generation, Xiaoxi Li+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- RetroLLMã¯ã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ã¨ç”Ÿæˆã‚’çµ±åˆã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€LLMsãŒã‚³ãƒ¼ãƒ‘ã‚¹ã‹ã‚‰ç›´æ¥è¨¼æ‹ ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚éšå±¤çš„FM-ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åˆ¶ç´„ã‚’å°å…¥ã—ã€é–¢é€£æ–‡æ›¸ã‚’ç‰¹å®šã™ã‚‹ã“ã¨ã§ç„¡é–¢ä¿‚ãªãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç©ºé–“ã‚’å‰Šæ¸›ã—ã€å‰å‘ããªåˆ¶ç´„ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ã§è¨¼æ‹ ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚åºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€ãƒ‰ãƒ¡ã‚¤ãƒ³å†…å¤–ã®ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rohanpaul_ai/status/1872714703090401721?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¾“æ¥ã®RAGã¨ã®é•ã„ã¨ã€ææ¡ˆæ‰‹æ³•ã®æ¦‚è¦<br><img src="https://github.com/user-attachments/assets/cd237a17-52f8-429f-9553-d35a449982ff" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/3a355c20-ccd2-49a8-bed7-f84ea84af14c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-12-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1616" target="_blank" rel="noopener noreferrer" class="title-link">A Survey on LLM-as-a-Judge, Jiawei Gu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã‚’è©•ä¾¡è€…ã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã€ŒLLM-as-a-Judgeã€ã®ä¿¡é ¼æ€§å‘ä¸Šã«é–¢ã™ã‚‹èª¿æŸ»ã€‚ä¿¡é ¼æ€§ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã®æˆ¦ç•¥ã‚„è©•ä¾¡æ–¹æ³•è«–ã‚’ææ¡ˆã—ã€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ç”¨ã„ã¦ã‚µãƒãƒ¼ãƒˆã€‚å®Ÿç”¨çš„ãªå¿œç”¨ã‚„å°†æ¥ã®æ–¹å‘æ€§ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã€ç ”ç©¶è€…ã‚„å®Ÿå‹™è€…ã®å‚è€ƒè³‡æ–™ã¨ãªã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://awesome-llm-as-a-judge.github.io" target="_blank" rel="noopener noreferrer">https://awesome-llm-as-a-judge.github.io</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2024-12-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1598" target="_blank" rel="noopener noreferrer" class="title-link">VLR-Bench: Multilingual Benchmark Dataset for Vision-Language Retrieval  Augmented Generation, Hyeonseok Lim+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- è¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆVLMï¼‰ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯VLR-Benchã‚’ææ¡ˆã€‚ã“ã‚Œã¯5ã¤ã®å…¥åŠ›ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”¨ã„ã¦ã€ç‰¹å®šã®ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹æœ‰ç”¨ãªæƒ…å ±ã®åˆ¤æ–­èƒ½åŠ›ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã€‚32,000ã®è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸæŒ‡ç¤ºã‹ã‚‰ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆVLR-IFã‚’æ§‹ç¯‰ã—ã€VLMã®RAGèƒ½åŠ›ã‚’å¼·åŒ–ã€‚Llama3ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã§æ€§èƒ½ã‚’æ¤œè¨¼ã—ã€ä¸¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Multilingual VLMã‚’ç”¨ã„ãŸRAGã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<span class="issue_date">Issue Date: 2024-12-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1597" target="_blank" rel="noopener noreferrer" class="title-link">Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions, Yu Zhao+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Marco-o1ã¯ã€LRMã®ç ”ç©¶ã«ãŠã„ã¦ã€æ•°å­¦ã‚„ç‰©ç†å­¦ã ã‘ã§ãªãã€RLã‚„ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ã®è§£æ±ºç­–ã«ã‚‚é‡ç‚¹ã‚’ç½®ã„ã¦ã„ã‚‹ã€‚ç‰¹ã«ã€o1ãƒ¢ãƒ‡ãƒ«ãŒåŸºæº–ãŒä¸æ˜ç­ãªé ˜åŸŸã«ä¸€èˆ¬åŒ–ã§ãã‚‹ã‹ã‚’æ¢æ±‚ã—ã€Chain-of-Thoughtãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„MCTSã€åå°„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æ´»ç”¨ã—ã¦è¤‡é›‘ãªå•é¡Œè§£æ±ºã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bilzrd/status/1868568258468774048?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Large Reasoning Model ï¼ˆLRMï¼‰ã¨ã„ã†ç”¨èªã¯åˆã‚ã¦è¦‹ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2024-12-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1594" target="_blank" rel="noopener noreferrer" class="title-link">When Benchmarks are Targets: Revealing the Sensitivity of Large Language   Model Leaderboards, Norah Alzahrani+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã¯ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«åŸºã¥ã„ã¦ãƒ¢ãƒ‡ãƒ«é¸æŠã‚’æ”¯æ´ã™ã‚‹ãŒã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯å¾®ç´°ãªå¤‰æ›´ã«æ•æ„Ÿã§ã‚ã‚Šã€æœ€å¤§8ä½å¤‰å‹•ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚3ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ‘‚å‹•ã®ã‚«ãƒ†ã‚´ãƒªã«ã‚ãŸã‚‹å®Ÿé¨“ã‚’é€šã˜ã¦ã€ã“ã®ç¾è±¡ã®åŸå› ã‚’ç‰¹å®šã—ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°æ–¹æ³•ã®åˆ©ç‚¹ã‚’å«ã‚€ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’ææ¡ˆã€‚å˜ç´”ãªè©•ä¾¡ã«ä¾å­˜ã™ã‚‹å±é™ºæ€§ã‚’å¼·èª¿ã—ã€ã‚ˆã‚Šå …ç‰¢ãªè©•ä¾¡ã‚¹ã‚­ãƒ¼ãƒ ã®å¿…è¦æ€§ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1591" target="_blank" rel="noopener noreferrer">å›½éš›ä¼šè­°ACL2024å‚åŠ å ±å‘Š, Masato Mita, Cyber Agent, 2024.12</a>
<br><br>ã«æ—¥æœ¬èªã§ã®ã‚µãƒãƒªãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã®ã§å‚ç…§ã®ã“ã¨ã€‚<br><br>ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã®ãƒã‚¤ã‚¢ã‚¹ã‚’è»½æ¸›ã—ãŸçµæœã€ã©ã®LLMãŒæœ€å¤§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã¿ãªã•ã‚Œã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã ã‚ã†ã‹ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-12-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1593" target="_blank" rel="noopener noreferrer" class="title-link">BatchEval: Towards Human-like Text Evaluation, Peiwen Yuan+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- BatchEvalã¨ã„ã†æ–°ã—ã„è©•ä¾¡ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ææ¡ˆã—ã€LLMã‚’ç”¨ã„ãŸè‡ªå‹•ãƒ†ã‚­ã‚¹ãƒˆè©•ä¾¡ã®å•é¡Œã‚’è§£æ±ºã€‚ãƒãƒƒãƒå˜ä½ã§ã®åå¾©è©•ä¾¡ã«ã‚ˆã‚Šã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã®æ•æ„Ÿã•ã‚„ãƒã‚¤ã‚ºè€æ€§ã®ä½ã•ã‚’è»½æ¸›ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€BatchEvalã¯æœ€å…ˆç«¯æ‰‹æ³•ã«å¯¾ã—ã¦10.5%ã®æ”¹å–„ã‚’ç¤ºã—ã€APIã‚³ã‚¹ãƒˆã‚’64%å‰Šæ¸›ã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1591" target="_blank" rel="noopener noreferrer">å›½éš›ä¼šè­°ACL2024å‚åŠ å ±å‘Š, Masato Mita, Cyber Agent, 2024.12</a>
<br><br>ã«æ—¥æœ¬èªã«ã‚ˆã‚‹ã‚µãƒãƒªãŒæ²è¼‰ã•ã‚Œã¦ã„ã‚‹ã®ã§å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-12-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1592" target="_blank" rel="noopener noreferrer" class="title-link">Striking Gold in Advertising: Standardization and Exploration of Ad Text   Generation, Masato Mita+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå‹•åºƒå‘Šãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆATGï¼‰ã®ãŸã‚ã«ã€æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆCAMERAã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æƒ…å ±ã®æ´»ç”¨ã¨æ¥­ç•Œå…¨ä½“ã§ã®è©•ä¾¡ãŒä¿ƒé€²ã•ã‚Œã‚‹ã€‚9ã¤ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã€ç¾çŠ¶ã¨èª²é¡Œã‚’æ˜ã‚‰ã‹ã«ã—ã€LLMãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡è€…ã¨äººé–“ã®è©•ä¾¡ã®ä¸€è‡´ã‚’æ¢æ±‚ã€‚</span>
<span class="snippet"><span>Comment</span><p>åºƒå‘Šæ–‡ç”Ÿæˆã‚¿ã‚¹ã‚¯ï¼ˆAd Text Generationï¼‰ã¯å€‹ã€…ã®ã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãƒ‡ãƒ¼ã‚¿ã§ã—ã‹è©•ä¾¡ã•ã‚Œã¦ã“ãªã‹ã£ãŸã“ã¨ã¨ã€ãã‚‚ãã‚‚ã‚¿ã‚¹ã‚¯è¨­å®šãŒååˆ†ã«è¦å®šã•ã‚Œã¦ã„ãªã„ã®ã§ã€ãã®è¾ºã‚’æ•´å‚™ã—ãŸã¨ã„ã†è©±ã‚‰ã—ã„ã€‚<br>ç‰¹ã«åºƒå‘Šæ–‡ç”Ÿæˆã®ãŸã‚ã®åˆã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ãªCAMERAã‚’æ§‹ç¯‰ã—ã¦ã„ã‚‹ã€‚<br><br>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œã‚‹ã ã‘ã§ãªãã€æ—¢å­˜ã®æ‰‹æ³•ã€å¤å…¸çš„ãªã‚‚ã®ã‹ã‚‰LLMã¾ã§ã§ã©ã®ç¨‹åº¦ã®æ€§èƒ½ã¾ã§åˆ°é”ã—ã¦ã„ã‚‹ã‹ã€ã•ã‚‰ã«ã¯ROUGEã‚„GPT-4ã‚’ç”¨ã„ãŸLLM-as-a-Judgeã®ã‚ˆã†ãªè‡ªå‹•è©•ä¾¡æ‰‹æ³•ã‚’ãƒ¡ã‚¿è©•ä¾¡ã—ã€äººæ‰‹è©•ä¾¡ã¨ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è©•ä¾¡ã®ã©ã®ç¨‹åº¦ä»£æ›¿ã«ãªã‚‹ã‹ã‚‚åˆ†æã—ãŸã¨ã®ã“ã¨ã‚‰ã—ã„ã€‚</p>
<p>Table5ã«ãƒ¡ã‚¿è©•ä¾¡ã®çµæœãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã®correlationã‚’æ¸¬å®šã—ã¦ã„ã‚‹ã€‚èˆˆå‘³æ·±ã„ã®ãŒã€BLEU-4, ROUGE-1, BERTScoreãªã©ã®å¤å…¸çš„oråŸ‹ã‚è¾¼ã¿ãƒ™ãƒ¼ã‚¹ã®NLGè©•ä¾¡æ‰‹æ³•ãŒFaithfulnessã¨Fluencyã«ãŠã„ã¦ã€äººé–“ã®å°‚é–€å®¶ã¨é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ã¦ã„ã‚‹ã®ã«å¯¾ã—ã€GPT-4ã«ã‚ˆã‚‹è©•ä¾¡ã§ã¯äººé–“ã«ã‚ˆã‚‹è©•ä¾¡ã¨å…¨ç„¶ç›¸é–¢ãŒå‡ºã¦ã„ãªã„ã€‚<br><br>æ—¢å­˜ã®LLM-as-a-Judgeç ”ç©¶ã§ã¯å°‚é–€å®¶ã¨åŒç­‰ã®è©•ä¾¡ã§ãã¾ã™ã€ã¿ãŸã„ãªè©±ãŒã‚ˆãè¦‹å—ã‘ã‚‰ã‚Œã‚‹ãŒã“ã‚Œã‚‰ã®å ±å‘Šã¨çµæœãŒç•°ãªã£ã¦ã„ã¦ãŠã‚‚ã—ã‚ã„ã€‚è‘—è€…ã‚‰ã¯ã€OpenAIã®GPTã¯ãã‚‚ãã‚‚åºƒå‘Šãƒ‰ãƒ¡ã‚¤ãƒ³ã¨ãƒ†ã‚­ã‚¹ãƒˆã§ãã‚“ãªã«è¨“ç·´ã•ã‚Œã¦ã„ãªã•ãã†ãªã®ã§ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒŸã‚¹ãƒãƒƒãƒãŒä¸€ã¤ã®è¦å› ã¨ã—ã¦ã‚ã‚‹ã®ã§ã¯ãªã„ã‹ã€ã¨è€ƒå¯Ÿã—ã¦ã„ã‚‹ã€‚<br><br>ã¾ãŸã€Attractivenessã§ã¯å°‚é–€å®¶ã«ã‚ˆã‚‹è©•ä¾¡ã¨å¼±ã„ç›¸é–¢ã—ã‹ç¤ºã—ã¦ã„ãªã„ç‚¹ã‚‚èˆˆå‘³æ·±ã„ã€‚åºƒå‘Šæ–‡ãŒã©ã®ç¨‹åº¦é­…åŠ›çš„ã‹ã¯BLEU, ROUGE, BERTScoreã‚ãŸã‚Šã§ã¯ãªã‹ãªã‹é›£ã—ãã†ãªã®ã§ã€GPT4ã«ã‚ˆã‚‹è©•ä¾¡ãŒã†ã¾ãã„ã£ã¦æ¬²ã—ã„ã¨ã“ã‚ã ãŒã€å…¨ãã†ã¾ãã„ã£ã¦ã„ãªã„ã€‚ã“ã®è«–æ–‡ã®çµæœã ã‘ã‚’è¦‹ã‚‹ã¨ã€ï¼ˆAttractivenessã«é–¢ã—ã¦ã¯ï¼‰è‡ªå‹•è©•ä¾¡ã ã‘ã§ã¯ã¾ã ã¾ã åºƒå‘Šæ–‡ã®è©•ä¾¡ã¯å³ã—ãã†ã«è¦‹ãˆã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/15804ddc-3131-4a3d-9071-a66473e0e987" alt="image" loading="lazy"></p>
<p>GPT4ã«ã‚ˆã‚‹Attractivenessã®è©•ä¾¡ã«åˆ©ç”¨ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒä¸‹è¨˜ã€‚MTBenchã£ã½ãã€ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã®åˆ†é¡å•é¡Œã¨ã—ã¦è§£ã„ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚ã“ã®è¾ºã¯LLM-as-a-Judgeã®ç ”ç©¶ã§ã¯ä»–ã«ã‚‚ã‚¹ã‚³ã‚¢ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‡ºåŠ›ã—å°¤åº¦ã§é‡ã¿ã¥ã‘ã‚‹G-Evalã‚’ã¯ã˜ã‚ã€ã•ã¾ã–ã¾ãªæ‰‹æ³•ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã¨æ€ã†ã®ã§ã€ãã®è¾ºã®æ‰‹æ³•ã‚’åˆ©ç”¨ã—ãŸã‚‰ã©ã†ãªã‚‹ã‹ã¯èˆˆå‘³ãŒã‚ã‚‹ã€‚<br>ã‚ã¨ã¯ãã‚‚ãã‚‚æ‰‹æ³•é¢ã®è©±ä»¥å‰ã«ã€promptã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã¨ã—ã¦ã©ã®ã‚ˆã†ãªæƒ…å ±ãŒAttractivenessã®è©•ä¾¡ã«é‡è¦ã‹ï¼Ÿã¨ã„ã†ã®ã‚‚æ˜ã‚‰ã‹ã«ãªã‚‹ã¨èˆˆå‘³æ·±ã„ã€‚ã“ã®è¾ºã¯ã€ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å°‚é–€å®¶éƒ¨éšŠãŒã€ã©ã®ã‚ˆã†ãªã“ã¨ã‚’æ€è€ƒã—ã¦Attractivenessã‚’è©•ä¾¡ã—ã¦ã„ã‚‹ã®ã‹ï¼Ÿã¨ã„ã†ã®ãŒãƒ’ãƒ³ãƒˆã«ãªã‚Šãã†ã§ã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/5c0d3989-d4c1-4d61-b592-b1140c4cf93d" alt="image" loading="lazy"><br></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1591" target="_blank" rel="noopener noreferrer">å›½éš›ä¼šè­°ACL2024å‚åŠ å ±å‘Š, Masato Mita, Cyber Agent, 2024.12</a>
<br><br>ã«è‘—è€…ã«ã‚ˆã‚‹ã‚µãƒãƒªãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã®ã§å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2024-12-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1590" target="_blank" rel="noopener noreferrer" class="title-link">The broader spectrum of in-context learning, Andrew Kyle Lampinen+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã‚’ãƒ¡ã‚¿å­¦ç¿’ã«åŸºã¥ãæ–‡è„ˆå†…å­¦ç¿’ã®ä¸€éƒ¨ã¨ã—ã¦ä½ç½®ã¥ã‘ã€æ–‡è„ˆãŒäºˆæ¸¬ã®æå¤±ã‚’æ¸›å°‘ã•ã›ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®è¦–ç‚¹ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ–‡è„ˆå†…èƒ½åŠ›ã‚’çµ±ä¸€ã—ã€ä¸€èˆ¬åŒ–ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã¾ã™ã€‚ä¸€èˆ¬åŒ–ã¯æ–°ã—ã„å­¦ç¿’ã ã‘ã§ãªãã€ç•°ãªã‚‹æç¤ºã‹ã‚‰ã®å­¦ã³ã‚„é©ç”¨èƒ½åŠ›ã«ã‚‚é–¢é€£ã—ã€éå»ã®æ–‡çŒ®ã¨ã®é–¢é€£æ€§ã‚‚è­°è«–ã•ã‚Œã¾ã™ã€‚æ–‡è„ˆå†…å­¦ç¿’ã®ç ”ç©¶ã¯ã€åºƒç¯„ãªèƒ½åŠ›ã¨ä¸€èˆ¬åŒ–ã®ã‚¿ã‚¤ãƒ—ã‚’è€ƒæ…®ã™ã¹ãã¨çµè«–ä»˜ã‘ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=RHo3VVi0i5" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=RHo3VVi0i5</a>


<br><br>OpenReviewã«ã‚ˆã‚‹ã¨ã€<br>è«–æ–‡ã¯ç†è§£ã—ã‚„ã™ãã€meta learningã«ã¤ã„ã¦åºƒç¯„ã«ã‚µãƒ¼ãƒ™ã‚¤ã•ã‚Œã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€è«–æ–‡ãŒå®šç¾©ã—ã¦ã„ã‚‹ICLã®æ‹¡å¼µã¯ICLã‚’éåº¦ã«ä¸€èˆ¬åŒ–ã—éãã¦ãŠã‚Šï¼ˆå…·ä½“çš„ã«ä½•ãŒICLã§ä½•ãŒICLã§ãªã„ã®ã‹ã€ã¨ã„ã£ãŸè¦å®šãŒã§ããªã„ï¼‰ã€ã‹ã¤è«–æ–‡ä¸­ã§ææ¡ˆã•ã‚Œã¦ã„ã‚‹ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’è£ä»˜ã‘ã‚‹å®Ÿé¨“ãŒãªãspeculativeã§ã‚ã‚‹ã€ã¨ã®ã“ã¨ã§rejectã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-12-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1589" target="_blank" rel="noopener noreferrer" class="title-link">Phi-4 Technical Report, Marah Abdin+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- 140å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã€Œphi-4ã€ã¯ã€åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šå…¥ã‚ŒãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šã€STEMã«ç‰¹åŒ–ã—ãŸQAèƒ½åŠ›ã§æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚phi-3ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æœ€å°é™ã«å¤‰æ›´ã—ãŸã ã‘ã§ã€æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ãŠã„ã¦ã‚‚æ”¹å–„ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã«ã‚ˆã‚Šå¼·åŠ›ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>ç¾çŠ¶Azureã§ã®ã¿åˆ©ç”¨å¯èƒ½ã‹ã‚‚ã€‚Huggingfaceã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã‚‚éå•†ç”¨ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«ãªã‚‹ã¨ã„ã†å™‚ã‚‚</p>
<p>MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹<br>HuggingFace:<br>


<a href="https://huggingface.co/microsoft/phi-4" target="_blank" rel="noopener noreferrer">https://huggingface.co/microsoft/phi-4</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<span class="issue_date">Issue Date: 2024-12-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1586" target="_blank" rel="noopener noreferrer" class="title-link">Training Large Language Models to Reason in a Continuous Latent Space, Shibo Hao+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„æ¨è«–ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã€ŒCoconutã€ã‚’ææ¡ˆã—ã€LLMã®éš ã‚ŒçŠ¶æ…‹ã‚’é€£ç¶šçš„æ€è€ƒã¨ã—ã¦åˆ©ç”¨ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ¬¡ã®å…¥åŠ›ã‚’é€£ç¶šç©ºé–“ã§ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã—ã€è¤‡æ•°ã®æ¨è«–ã‚¿ã‚¹ã‚¯ã§LLMã‚’å¼·åŒ–ã€‚Coconutã¯å¹…å„ªå…ˆæ¢ç´¢ã‚’å¯èƒ½ã«ã—ã€ç‰¹å®šã®è«–ç†æ¨è«–ã‚¿ã‚¹ã‚¯ã§CoTã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚æ½œåœ¨çš„æ¨è«–ã®å¯èƒ½æ€§ã‚’æ¢ã‚‹é‡è¦ãªæ´å¯Ÿã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>Chain of Continuous Thought...?</p>
<p>é€šå¸¸ã®CoTã¯Rationaleã‚’ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã§ç”Ÿæˆã™ã‚‹ãŒã€Coconutã¯æœ€çµ‚çš„ãªhidden stateï¼ˆã¾ã èª­ã‚“ã§ãªã„ã®ã§ã“ã‚ŒãŒå…·ä½“çš„ã«ä½•ã‚’æŒ‡ã™ã‹ä¸æ˜ï¼‰ã‚’ãã®ã¾ã¾å…¥åŠ›ã«è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ãƒˆãƒ¼ã‚¯ãƒ³ã«åˆ¶é™ã•ã‚Œãšã«CoTã•ã›ã‚‹ã¨ã„ã†ã“ã¨ã‚‰ã—ã„ã€‚ã‚ã¨ã§ã—ã£ã‹ã‚Šèª­ã‚€<br><img src="https://github.com/user-attachments/assets/b930f44b-96f4-47cd-aa1a-0b5fabde54a5" alt="image" loading="lazy"></p>
<p>ã¾ã èª­ã‚“ã§ã„ãªã„ãŒã€ãŠãã‚‰ãå­¦ç¿’ã®éš›ã«å·¥å¤«ãŒå¿…è¦ãªã®ã§æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ã“ã­ãã‚Šå›ã—ã¦ã§ãã¾ã™ç³»ã®è©±ã§ã¯ãªã„ã‹ã‚‚</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=tG4SgayTtk" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=tG4SgayTtk</a>


<br><br>ICLR'25ã«rejectã•ã‚Œã¦ã„ã‚‹ã€‚<br>ã–ã£ã¨æœ€åˆã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹Weaknessã‚’èª­ã‚“ã æ„Ÿã˜<br>- è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒåˆæˆãƒ‡ãƒ¼ã‚¿ã—ã‹ãªãã€ã‚ˆã‚Šrealisticãªãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã—ãŸæ–¹ãŒè‰¯ã„<br>- CoTã‚‰éå¸¸ã«ä¸€èˆ¬çš„ã«é©ç”¨å¯èƒ½ãªæŠ€è¡“ãªã®ã§ã€ã‚‚ã£ã¨åºƒç¯„ãªãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã™ã¹ã<br>- GSM8Kã§ã¯å¤§å¹…ã«COCONUTã¯CoTã«æ€§èƒ½ãŒè² ã‘ã¦ã„ã¦ã€ProsQAã§ã®ã¿ã«ã—ã‹CoTã«å‹ã¦ã¦ã„ãªã„<br>- ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®è¿½åŠ ã®å­¦ç¿’ãŒå¿…è¦ã§ã€ãã“ã§èº«ã«ã¤ã‘ãŸreasoningèƒ½åŠ›ãŒæ±åŒ–å¯èƒ½ã‹æ˜ã‚‰ã‹ã§ãªã„<br><br>ã¨ã„ã£ãŸæ„Ÿã˜ã«è¦‹ãˆã‚‹</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-12-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1578" target="_blank" rel="noopener noreferrer" class="title-link">Auto-RAG: Autonomous Retrieval-Augmented Generation for Large Language  Models, Tian Yu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Auto-RAGã¯ã€LLMã®æ„æ€æ±ºå®šèƒ½åŠ›ã‚’æ´»ç”¨ã—ãŸè‡ªå¾‹çš„ãªåå¾©æ¤œç´¢ãƒ¢ãƒ‡ãƒ«ã§ã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã¨ã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å¯¾è©±ã‚’é€šã˜ã¦çŸ¥è­˜ã‚’å–å¾—ã—ã¾ã™ã€‚æ¨è«–ã«åŸºã¥ãæ„æ€æ±ºå®šã‚’è‡ªå¾‹çš„ã«åˆæˆã—ã€6ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€åå¾©å›æ•°ã‚’è³ªå•ã®é›£æ˜“åº¦ã«å¿œã˜ã¦èª¿æ•´å¯èƒ½ã§ã™ã€‚ã¾ãŸã€ãƒ—ãƒ­ã‚»ã‚¹ã‚’è‡ªç„¶è¨€èªã§è¡¨ç¾ã—ã€è§£é‡ˆå¯èƒ½æ€§ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1863600141103501454?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=jkVQ31GeIA" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=jkVQ31GeIA</a>


</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=jkVQ31GeIA" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=jkVQ31GeIA</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2024-12-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1575" target="_blank" rel="noopener noreferrer" class="title-link">LLMs Will Always Hallucinate, and We Need to Live With This, Sourav Banerjee+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®å¹»è¦šã¯å¶ç™ºçš„ãªã‚¨ãƒ©ãƒ¼ã§ã¯ãªãã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã®åŸºæœ¬çš„ãªæ§‹é€ ã‹ã‚‰ç”Ÿã˜ã‚‹é¿ã‘ã‚‰ã‚Œãªã„ç‰¹å¾´ã§ã‚ã‚‹ã¨ä¸»å¼µã€‚ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ”¹å–„ã§ã¯å¹»è¦šã‚’æ’é™¤ã§ããªã„ã“ã¨ã‚’ç¤ºã—ã€å„ãƒ—ãƒ­ã‚»ã‚¹æ®µéšã§å¹»è¦šãŒç”Ÿæˆã•ã‚Œã‚‹ç¢ºç‡ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’åˆ†æã€‚æ–°ãŸã«ã€Œæ§‹é€ çš„å¹»è¦šã€ã¨ã„ã†æ¦‚å¿µã‚’å°å…¥ã—ã€å¹»è¦šã®æ•°å­¦çš„ç¢ºå®Ÿæ€§ã‚’ç¢ºç«‹ã™ã‚‹ã“ã¨ã§ã€å®Œå…¨ãªè»½æ¸›ã¯ä¸å¯èƒ½ã§ã‚ã‚‹ã¨è«–ã˜ã‚‹ã€‚</span>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<span class="issue_date">Issue Date: 2024-12-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1573" target="_blank" rel="noopener noreferrer" class="title-link">äº‹å®Ÿæ­£èª¤åˆ¤å®šãŒä¸è¦ãªç”Ÿæˆå¿œç­”ã®æ¤œå‡ºã«å‘ã‘ãŸ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åé›†ã¨åˆ†æ, rryohei Kamei+, NLP'24, 2024.03</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<span class="issue_date">Issue Date: 2024-12-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1566" target="_blank" rel="noopener noreferrer" class="title-link">The Super Weight in Large Language Models, Mengxia Yu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¸€éƒ¨ãŒãƒ¢ãƒ‡ãƒ«ã®å“è³ªã«ä¸å‡è¡¡ã«é‡è¦ã§ã‚ã‚Šã€1ã¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å‰ªå®šã§ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆèƒ½åŠ›ãŒå¤§å¹…ã«ä½ä¸‹ã™ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒªãƒ¼ã®æ–¹æ³•ã§é‡è¦ãªã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç‰¹å®šã—ã€ã“ã‚Œã«ã‚ˆã‚Šå››æ¨äº”å…¥é‡å­åŒ–ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹ç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ãŸã‚ã«ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¢ã‚¯ã‚»ã‚¹ã®LLMã«å¯¾ã™ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å›³ã«ã‚ã‚‹é€šã‚Šã€ãŸã£ãŸä¸€ã¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸­ã®é‡ã¿ã‚’0ã«ã™ã‚‹ã ã‘ã§ã€é€”ç«¯ã«æ„å‘³ã®ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒç”Ÿæˆã§ããªããªã‚‹ã‚ˆã†ãªé‡ã¿ãŒå­˜åœ¨ã™ã‚‹ã‚‰ã—ã„ã€‚<br><img src="https://github.com/user-attachments/assets/065e921b-c447-4c0d-b1de-a2f79bd090f8" alt="image" loading="lazy"><br><br><br>ï¼ˆå›³ã¯è«–æ–‡ã‚ˆã‚Šå¼•ç”¨ï¼‰</p>
<p>ICLR 2025ã®Openreview<br>


<a href="https://openreview.net/forum?id=0Ag8FQ5Rr3" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=0Ag8FQ5Rr3</a>


</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2024-12-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1564" target="_blank" rel="noopener noreferrer" class="title-link">Do Large Language Models Perform Latent Multi-Hop Reasoning without   Exploiting Shortcuts?, Sohee Yang+, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ãƒãƒ«ãƒãƒ›ãƒƒãƒ—ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹äº‹å®Ÿã®æƒ³èµ·èƒ½åŠ›ã‚’è©•ä¾¡ã€‚ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã‚’é˜²ããŸã‚ã€ä¸»èªã¨ç­”ãˆãŒå…±ã«å‡ºç¾ã™ã‚‹ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªã‚’é™¤å¤–ã—ãŸè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆSOCRATESã‚’æ§‹ç¯‰ã€‚LLMsã¯ç‰¹å®šã®ã‚¯ã‚¨ãƒªã«ãŠã„ã¦ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã‚’åˆ©ç”¨ã›ãšã«æ½œåœ¨çš„ãªæ¨è«–èƒ½åŠ›ã‚’ç¤ºã—ã€å›½ã‚’ä¸­é–“ç­”ãˆã¨ã™ã‚‹ã‚¯ã‚¨ãƒªã§ã¯80%ã®æ§‹æˆå¯èƒ½æ€§ã‚’é”æˆã™ã‚‹ä¸€æ–¹ã€å¹´ã®æƒ³èµ·ã¯5%ã«ä½ä¸‹ã€‚æ½œåœ¨çš„æ¨è«–èƒ½åŠ›ã¨æ˜ç¤ºçš„æ¨è«–èƒ½åŠ›ã®é–“ã«å¤§ããªã‚®ãƒ£ãƒƒãƒ—ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚</span>
<span class="snippet"><span>Comment</span><p>SNLP'24ã§ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:<br>


<a href="https://docs.google.com/presentation/d/1Q_UzOzn0qYX1gq_4FC4YGXK8okd5pwEHaLzVCzp3yWg/edit?usp=drivesdk" target="_blank" rel="noopener noreferrer">https://docs.google.com/presentation/d/1Q_UzOzn0qYX1gq_4FC4YGXK8okd5pwEHaLzVCzp3yWg/edit?usp=drivesdk</a>


</p>
<p>ã“ã®ç ”ç©¶ã‚’ä¿¡ã˜ã‚‹ã®ã§ã‚ã‚Œã°ã€LLMã¯CoTç„¡ã—ã§ã¯ãƒãƒ«ãƒãƒ›ãƒƒãƒ—æ¨è«–ã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã¯ã‚ã¾ã‚Šã§ãã¦ã„ãªã•ãã†ã€ã¨ã„ã†æ„Ÿã˜ã ã¨æ€ã†ã®ã ãŒã©ã†ãªã‚“ã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1561" target="_blank" rel="noopener noreferrer" class="title-link">Astute RAG: Overcoming Imperfect Retrieval Augmentation and Knowledge  Conflicts for Large Language Models, Fei Wang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Astute RAGã¯ã€å¤–éƒ¨çŸ¥è­˜ã®ä¸å®Œå…¨ãªå–å¾—ã«ã‚ˆã‚‹å•é¡Œã‚’è§£æ±ºã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€LLMsã®å†…éƒ¨çŸ¥è­˜ã¨å¤–éƒ¨çŸ¥è­˜ã‚’é©å¿œçš„ã«çµ±åˆã—ã€æƒ…å ±ã®ä¿¡é ¼æ€§ã«åŸºã¥ã„ã¦å›ç­”ã‚’æ±ºå®šã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€Astute RAGã¯å¾“æ¥ã®RAGæ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€æœ€æ‚ªã®ã‚·ãƒŠãƒªã‚ªã§ã‚‚LLMsã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¶…ãˆã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/AES(AutomatedEssayScoring).html" target="_blank" rel="noopener noreferrer">#AES(AutomatedEssayScoring)</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-11-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1556" target="_blank" rel="noopener noreferrer" class="title-link">Japanese-English Sentence Translation Exercises Dataset for Automatic Grading, Miura+, EACL'24, 2024.03</a>
<span class="snippet"><span>GPT Summary</span>- ç¬¬äºŒè¨€èªå­¦ç¿’ã®æ–‡ç¿»è¨³æ¼”ç¿’ã®è‡ªå‹•è©•ä¾¡ã‚¿ã‚¹ã‚¯ã‚’ææ¡ˆã—ã€è©•ä¾¡åŸºæº–ã«åŸºã¥ã„ã¦å­¦ç”Ÿã®å›ç­”ã‚’æ¡ç‚¹ã™ã‚‹ã€‚æ—¥æœ¬èªã¨è‹±èªã®é–“ã§3,498ã®å­¦ç”Ÿã®å›ç­”ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸBERTãƒ¢ãƒ‡ãƒ«ã¯ç´„90%ã®F1ã‚¹ã‚³ã‚¢ã§æ­£ã—ã„å›ç­”ã‚’åˆ†é¡ã™ã‚‹ãŒã€èª¤ã£ãŸå›ç­”ã¯80%æœªæº€ã€‚å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã‚’ç”¨ã„ãŸGPT-3.5ã¯BERTã‚ˆã‚ŠåŠ£ã‚‹çµæœã‚’ç¤ºã—ã€ææ¡ˆã‚¿ã‚¹ã‚¯ãŒå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã¨ã£ã¦ã‚‚é›£ã—ã„ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>STEsã®å›³è§£ã€‚åˆ†ã‹ã‚Šã‚„ã™ã„ã€‚ã„ã‚ã‚†ã‚‹æ—¥æœ¬äººãŒæ…£ã‚Œè¦ªã—ã‚“ã§ã„ã‚‹å’Œæ–‡è‹±è¨³ã€è‹±æ–‡å’Œè¨³æ¼”ç¿’ã‚‚ã€ã“ã®ã‚¿ã‚¹ã‚¯ã®ä¸€ç¨®ã ã¨ã„ã†ã“ã¨ãªã®ã ã‚ã†ã€‚2-shotã®GPT4ã¨Finetuningã—ãŸBERTãŒåŒç­‰ç¨‹åº¦ã®æ€§èƒ½ã«è¦‹ãˆã¦ã€GPT3.5ã§ã¯5shotã—ã¦ã‚‚å‹ã¦ã¦ã„ãªã„æ¨¡æ§˜ã€‚èˆˆå‘³æ·±ã„ã€‚<br><img src="https://github.com/user-attachments/assets/7f2f824c-91cb-4935-af53-75f1b72912bc" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-11-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1550" target="_blank" rel="noopener noreferrer" class="title-link">From Generation to Judgment: Opportunities and Challenges of  LLM-as-a-judge, Dawei Li+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã‚’ç”¨ã„ãŸåˆ¤æ–­ã¨è©•ä¾¡ã®æ–°ãŸãªãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã€ŒLLM-as-a-judgeã€ã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªèª¿æŸ»ã‚’è¡Œã„ã€å®šç¾©ã‚„åˆ†é¡æ³•ã‚’æç¤ºã€‚è©•ä¾¡ã®ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ã¾ã¨ã‚ã€ä¸»è¦ãªèª²é¡Œã¨ä»Šå¾Œã®ç ”ç©¶æ–¹å‘ã‚’ç¤ºã™ã€‚é–¢é€£ãƒªã‚½ãƒ¼ã‚¹ã‚‚æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLM-as-a-Judgeã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ™ã‚¤<br><img src="https://github.com/user-attachments/assets/88059cc4-123e-4a89-ac2d-4b3db83cd2df" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/10fea773-e52b-4e67-9137-dfc51846988b" alt="image" loading="lazy"></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1214" target="_blank" rel="noopener noreferrer">Leveraging Large Language Models for NLG Evaluation: A Survey, Zhen Li+, N/A, arXiv'24</a>
<br><br>ã‚‚å‚ç…§ã®ã“ã¨</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2024-11-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1549" target="_blank" rel="noopener noreferrer" class="title-link">Does Prompt Formatting Have Any Impact on LLM Performance?, Jia He+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã¯LLMã®æ€§èƒ½ã«é‡è¦ã§ã‚ã‚Šã€ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã€‚å®Ÿé¨“ã§ã¯ã€GPT-3.5-turboãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ã‚ˆã£ã¦ã‚³ãƒ¼ãƒ‰ç¿»è¨³ã‚¿ã‚¹ã‚¯ã§æœ€å¤§40%å¤‰å‹•ã™ã‚‹ä¸€æ–¹ã€GPT-4ã¯ã‚ˆã‚Šå …ç‰¢ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å›ºå®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å†è€ƒãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ãŒå¼·èª¿ã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ï¼ˆä»¥ä¸‹ã€å€‹äººã®æ„Ÿæƒ³ã§ã™ï¼‰<br>æœ¬æ–‡ã®ã¿æ–œã‚èª­ã¿ã—ã¦ã€Appendixã¯çœºã‚ãŸã ã‘ãªã®ã§çš„å¤–ã‚Œãªã“ã¨ã‚’è¨€ã£ã¦ã„ãŸã‚‰ã™ã¿ã¾ã›ã‚“ã€‚<br><br>ã¾ãšã€å®Ÿå‹™ä¸Šä¸‹è¨˜çŸ¥è¦‹ã¯æœ‰ç”¨ã ã¨æ€ã„ã¾ã—ãŸ:<br>- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ã‚ˆã£ã¦æ€§èƒ½ã«å¤§ããªå·®ãŒã‚ã‚‹<br>- ã‚ˆã‚Šå¤§ãã„ãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆ<br><br>ãŸã ã—ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ã‚ˆã£ã¦æ€§èƒ½å·®ãŒã‚ã‚‹ã¨ã„ã†ã®ã¯çµŒé¨“çš„ã«ã‚ã‚‹ç¨‹åº¦LLMã‚’è§¦ã£ã¦ã„ã‚‹äººãªã‚‰åˆ†ã‹ã‚‹ã“ã¨ã ã¨æ€ã†ã®ã§ã€é©šãã¯å°‘ãªã‹ã£ãŸã€‚<br><br>å€‹äººçš„ã«æ°—ã«ãªã‚‹ç‚¹ã¯ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚‚ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚‚åˆ†ã‹ã‚‰ãªã„GPT3.5, GPT4ã®ã¿ã§å®Ÿé¨“ã‚’ã—ã¦ã€Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¤§ãã„æ–¹ãŒãƒ­ãƒã‚¹ãƒˆã€ã¨çµè«–ã¥ã‘ã¦ã„ã‚‹ç‚¹ã¨ã€ã‚‚ã†å°‘ã—æ·±æ˜ã‚Šã—ã¦è€ƒå¯Ÿã—ãŸã‚‰ã‚‚ã£ã¨ãŠã‚‚ã—ã‚ã„ã®ã«ãªã€ã¨æ„Ÿã˜ã‚‹ç‚¹ã§ã™ã€‚<br><br>å®Ÿå‹™ä¸Šã¯æœ‰ç›ŠãªçŸ¥è¦‹ã ã¨ã—ã¦ã€ã§ã¯ç ”ç©¶ã¨ã—ã¦è¦‹ãŸã¨ãã«ã€Œãªãœãã†ãªã‚‹ã®ã‹?ã€ã¨ã„ã†ã¨ã“ã‚ã‚’è¿½æ±‚ã—ã¦æ¬²ã—ã„ãªãã€ã¨ã„ã†æ„Ÿæƒ³ã‚’æŒã¡ã¾ã—ãŸã€‚<br>ãŸã¨ãˆã°ã€ã€Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¤§ãã„ãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ãƒ­ãƒã‚¹ãƒˆã€ã¨è«–æ–‡ä¸­ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã¾ã™ãŒã€<br>ãã‚Œã¯æœ¬å½“ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«ã‚ˆã‚‹ã‚‚ã®ãªã®ã‹ï¼Ÿå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹å„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å‰²åˆã¨ã‹ï¼ˆã“ã‚Œã¯äº‹å®Ÿã¯OpenAIã®ä¸­ã®äººã—ã‹åˆ†ã‹ã‚‰ãªã„ã®ã§ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ãŒã‚ã‚‹ç¨‹åº¦ã‚ªãƒ¼ãƒ—ãƒ³ã«ãªã£ã¦ã„ã‚‹OpenLLMã§ã‚‚æ¤œè¨¼ã™ã‚‹ã¨ã‹ï¼‰ã€è©•ä¾¡ã™ã‚‹ã‚¿ã‚¹ã‚¯ã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ç›¸æ€§ã¨ã‹ã€è‰²ã€…ã¨è€ƒå¯Ÿã§ãã‚‹è¦ç´ ãŒã‚ã‚‹ã®ã§ã¯ãªã„ã‹ã¨æ€ã„ã¾ã—ãŸã€‚<br>ãã®ä¸Šã§ã€å¤§éƒ¨åˆ†ã®LLMã§æ™®éçš„ãªçŸ¥è¦‹ã‚’è¦‹å‡ºã—ãŸæ–¹ãŒç ”ç©¶ã¨ã—ã¦ã‚ˆã‚Šé¢ç™½ããªã‚‹ã®ã§ã¯ãªã„ã‹ã€ã¨æ„Ÿã˜ã¾ã—ãŸã€‚<br><br><img src="https://github.com/user-attachments/assets/d0a6c727-1253-4503-93f2-8daa4db2321b" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/b7166b2b-b848-43f5-a823-7ed491232234" alt="image" loading="lazy"></p>
<p>å‚è€ƒ: Data2Textã«ãŠã‘ã‚‹æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®input formatã«ã‚ˆã‚‹æ€§èƒ½å·®ã‚’åˆ†æã—è€ƒå¯Ÿã—ã¦ã„ã‚‹ç ”ç©¶<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1267" target="_blank" rel="noopener noreferrer">Prompting for Numerical Sequences: A Case Study on Market Comment
  Generation, Masayuki Kawarada+, N/A, arXiv'24</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2024-11-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1548" target="_blank" rel="noopener noreferrer" class="title-link">Generative Agent Simulations of 1,000 People, Joon Sung Park+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ææ¡ˆã—ã€1,052äººã®å®Ÿåœ¨ã®å€‹äººã®æ…‹åº¦ã¨è¡Œå‹•ã‚’85%ã®ç²¾åº¦ã§å†ç¾ã€‚å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸè³ªçš„ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã«åŸºã¥ãã€å‚åŠ è€…ã®å›ç­”ã‚’æ­£ç¢ºã«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã€‚äººå£çµ±è¨ˆçš„èª¬æ˜ã‚’ç”¨ã„ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨æ¯”è¼ƒã—ã¦ã€ç²¾åº¦ãƒã‚¤ã‚¢ã‚¹ã‚’è»½æ¸›ã€‚å€‹äººãŠã‚ˆã³é›†å›£ã®è¡Œå‹•èª¿æŸ»ã®æ–°ã—ã„ãƒ„ãƒ¼ãƒ«ã‚’æä¾›ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2024-11-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1542" target="_blank" rel="noopener noreferrer" class="title-link">Multimodal Autoregressive Pre-training of Large Vision Encoders, Enrico Fini+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„æ‰‹æ³•AIMV2ã‚’ç”¨ã„ã¦ã€å¤§è¦æ¨¡ãªãƒ“ã‚¸ãƒ§ãƒ³ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®äº‹å‰å­¦ç¿’ã‚’è¡Œã†ã€‚ã“ã‚Œã¯ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’çµ„ã¿åˆã‚ã›ãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è¨­å®šã«æ‹¡å¼µã•ã‚Œã€ã‚·ãƒ³ãƒ—ãƒ«ãªäº‹å‰å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã¨å„ªã‚ŒãŸæ€§èƒ½ã‚’ç‰¹å¾´ã¨ã™ã‚‹ã€‚AIMV2-3Bã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ImageNet-1kã§89.5%ã®ç²¾åº¦ã‚’é”æˆã—ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç”»åƒç†è§£ã«ãŠã„ã¦æœ€å…ˆç«¯ã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-11-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1540" target="_blank" rel="noopener noreferrer" class="title-link">Observational Scaling Laws and the Predictability of Language Model  Performance, Yangjun Ruan+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€ç´„100ã®å…¬é–‹ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’æ§‹ç¯‰ã™ã‚‹æ–°ã—ã„è¦³å¯Ÿã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼é–“ã®èƒ½åŠ›å¤‰å‹•ã‚’è€ƒæ…®ã—ã€æ€§èƒ½ãŒä½æ¬¡å…ƒã®èƒ½åŠ›ç©ºé–“ã®é–¢æ•°ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¤‡é›‘ãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç¾è±¡ã®äºˆæ¸¬å¯èƒ½æ€§ã‚’ç¤ºã—ã€GPT-4ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ€§èƒ½ã‚’éã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‹ã‚‰äºˆæ¸¬ã§ãã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã€Chain-of-Thoughtã‚„Self-Consistencyã®å½±éŸ¿ã‚’äºˆæ¸¬ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç¸¦è»¸ãŒdownstreamã‚¿ã‚¹ã‚¯ã®ä¸»æˆåˆ†ï¼ˆã®ã†ã¡æœ€ã‚‚å¤§ãã„80%ã‚’èª¬æ˜ã™ã‚‹æˆåˆ†ï¼‰ã®å¤‰åŒ–ï¼ˆâ‰’LLMã®æ€§èƒ½ï¼‰ã§ã€æ¨ªè»¸ãŒlog scaleã®æŠ•å…¥è¨ˆç®—é‡ã€‚<br>Qwenã‚‚é ‘å¼µã£ã¦ã„ã‚‹ãŒã€æŠ•å…¥ãƒ‡ãƒ¼ã‚¿é‡ã«å¯¾ã™ã‚‹æ€§èƒ½ï¼ˆâ‰’ãƒ‡ãƒ¼ã‚¿ã®å“è³ªï¼‰ã§ã¯ã€å…ˆé§†ã‘çš„ãªç ”ç©¶ã§ã‚ã‚‹PhiãŒã‚„ã¯ã‚Šåœ§å€’çš„?<br><img src="https://github.com/user-attachments/assets/c38286df-37c1-4c72-832f-676832845c0e" alt="image" loading="lazy"></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need, Suriya Gunasekar+, N/A, arXiv'23</a>
<br><br>ã‚‚å‚ç…§ã®ã“ã¨</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1530" target="_blank" rel="noopener noreferrer" class="title-link">Likelihood as a Performance Gauge for Retrieval-Augmented Generation, Tianyu Liu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸæƒ…å ±æ¤œç´¢å¼·åŒ–ç”Ÿæˆã¯ã€æ–‡è„ˆå†…ã®æ–‡æ›¸ã®é †åºã«å½±éŸ¿ã‚’å—ã‘ã‚„ã™ã„ã€‚ç ”ç©¶ã§ã¯ã€è³ªå•ã®ç¢ºç‡ãŒãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’åˆ†æã—ã€æ­£ç¢ºæ€§ã¨ã®ç›¸é–¢é–¢ä¿‚ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚è³ªå•ã®ç¢ºç‡ã‚’æŒ‡æ¨™ã¨ã—ã¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é¸æŠã¨æ§‹ç¯‰ã«é–¢ã™ã‚‹2ã¤ã®æ–¹æ³•ã‚’ææ¡ˆã—ã€ãã®åŠ¹æœã‚’å®Ÿè¨¼ã€‚ç¢ºç‡ã«åŸºã¥ãæ‰‹æ³•ã¯åŠ¹ç‡çš„ã§ã€å°‘ãªã„ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ã§å¿œç­”ã‚’ç”Ÿæˆã§ãã‚‹ãŸã‚ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã®æ–°ãŸãªæ–¹å‘æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã®å¹³å‡å€¤ã‚’ã¨ã£ãŸç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã®å¯¾æ•°å°¤åº¦ã¨ã€RAGã®å›ç­”æ€§èƒ½ã«é–¢ã™ã‚‹åˆ†æã‚’ã—ãŸæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/ac03c0b6-b16c-4992-8446-2f56bad09ab2" alt="image" loading="lazy"><br><br>ã¨ã‚Šã‚ãˆãšã€ã‚‚ã—ã€ŒLLMã¨ã—ã¦GPTã‚’ï¼ˆOpenAIã®APIã‚’ç”¨ã„ã¦ï¼‰ä½¿ã„ã¾ã—ãŸï¼temperatureã¯0ã§ã™ï¼ã€ã¿ãŸã„ãªå®Ÿé¨“è¨­å®šã ã£ãŸã‚‰è«¸ã€…æ€ªã—ããªã‚‹æ°—ãŒã—ãŸã®ã§ãã“ãŒå¤§ä¸ˆå¤«ãªã“ã¨ã‚’ç¢ºèªã—ãŸï¼ˆOpenLLMã€ã‹ã¤deterministicãªãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ–¹æ³•ãŒæœ›ã¾ã—ã„ï¼‰ã€‚ãŠã‚‚ã—ã‚ãã†ã€‚<br><br><img src="https://github.com/user-attachments/assets/9ba2bdc7-f6e5-4b9c-aca4-3d461c78a046" alt="image" loading="lazy"></p>
<p>å‚è€ƒ: [RAGã®ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’å°¤åº¦ã§é˜²ã, sasakuna, 2024.11.19](


<a href="https://zenn.dev/knowledgesense/articles/7c47e1796e96c0)" target="_blank" rel="noopener noreferrer">https://zenn.dev/knowledgesense/articles/7c47e1796e96c0)</a>


</p>
<p>
<strong>## å‚è€ƒ<br><br>ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®å°¤åº¦ã‚’ç”¨ã„ã¦ã€ã©ã®ç¨‹åº¦æ­£è§£ã‚‰ã—ã„ã‹ã‚’åˆ¤æ–­ã™ã‚‹ã€ã¨ã„ã£ãŸè©±ã¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1223" target="_blank" rel="noopener noreferrer">G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment, Yang Liu+, N/A, EMNLP'23</a>
</strong>
<br>
<br><br>ã®ã‚ˆã†ãªLLM-as-a-Judgeã§ã‚‚è¡Œã‚ã‚Œã¦ã„ã‚‹ã€‚<br><br>G-Evalã§ã¯1--5ã®ã‚¹ã‚³ã‚¢ã®ã‚ˆã†ãªé›¢æ•£çš„ãªå€¤ã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€ã“ã‚Œã‚‰ã‚’é€£ç¶šçš„ãªã‚¹ã‚³ã‚¢ã«è£œæ­£ã™ã‚‹ãŸã‚ã«ã€å°¤åº¦ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆç¢ºç‡ï¼‰ã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚<br>ãŸã ã—ã€G-Evalã®å ´åˆã¯å®Ÿé¨“ã§GPTã‚’ç”¨ã„ã¦ã„ã‚‹ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç›´æ¥å°¤åº¦ã‚’å–å¾—ã§ããšã€ä»£ã‚ã‚Šã«temperature1ã¨ã—ã€20å›ç¨‹åº¦ç”Ÿæˆã‚’è¡Œã£ãŸçµæœã‹ã‚‰ã‚¹ã‚³ã‚¢ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆç¢ºç‡ã‚’æ“¬ä¼¼çš„ã«è¨ˆç®—ã—ã¦ã„ã‚‹ã€‚<br><br>G-Evalã®è¨­å®šã¨æ¯”è¼ƒã™ã‚‹ã¨ï¼ˆå½“æ™‚ã¯ã¤ã‚ˆã¤ã‚ˆãªOpenLLMãŒãªã‹ã£ãŸãŸã‚è‹¦è‚‰ã®ç­–ã ã£ãŸã¨æ€ã‚ã‚Œã‚‹ãŒï¼‰ã€ã“ã¡ã‚‰ã®ç ”ç©¶ã®å®Ÿé¨“è¨­å®šã®æ–¹ãŒæœ›ã¾ã—ã„ã¨æ€ã†ã€‚</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<span class="issue_date">Issue Date: 2024-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1529" target="_blank" rel="noopener noreferrer" class="title-link">Multilingual Large Language Models: A Systematic Survey, Shaolin Zhu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã¯ã€å¤šè¨€èªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆMLLMsï¼‰ã®æœ€æ–°ç ”ç©¶ã‚’èª¿æŸ»ã—ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„äº‹å‰å­¦ç¿’ã®ç›®çš„ã€å¤šè¨€èªèƒ½åŠ›ã®è¦ç´ ã‚’è«–ã˜ã‚‹ã€‚ãƒ‡ãƒ¼ã‚¿ã®è³ªã¨å¤šæ§˜æ€§ãŒæ€§èƒ½å‘ä¸Šã«é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’å¼·èª¿ã—ã€MLLMã®è©•ä¾¡æ–¹æ³•ã‚„ã‚¯ãƒ­ã‚¹ãƒªãƒ³ã‚¬ãƒ«çŸ¥è­˜ã€å®‰å…¨æ€§ã€è§£é‡ˆå¯èƒ½æ€§ã«ã¤ã„ã¦è©³ç´°ãªåˆ†é¡æ³•ã‚’æç¤ºã€‚ã•ã‚‰ã«ã€MLLMã®å®Ÿä¸–ç•Œã§ã®å¿œç”¨ã‚’å¤šæ§˜ãªåˆ†é‡ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€èª²é¡Œã¨æ©Ÿä¼šã‚’å¼·èª¿ã™ã‚‹ã€‚é–¢é€£è«–æ–‡ã¯æŒ‡å®šã®ãƒªãƒ³ã‚¯ã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/0b86445f-b974-459c-94f0-a80f5e2bbc9a" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/0d03af89-23b0-4b4b-972a-bbe4320d4f0c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2024-11-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1524" target="_blank" rel="noopener noreferrer" class="title-link">Balancing Speed and Stability: The Trade-offs of FP8 vs. BF16 Training  in LLMs, Kazuki Fujii+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€ãã®è¨€èªç†è§£èƒ½åŠ›ã¨é©ç”¨å¯èƒ½æ€§ã‹ã‚‰æ³¨ç›®ã‚’é›†ã‚ã¦ãŠã‚Šã€ç‰¹ã«Llama 3ã‚·ãƒªãƒ¼ã‚ºã¯4050å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŠ¹ç‡åŒ–ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ä¸­ã€NVIDIAã®H100 GPUã¯FP8ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å°å…¥ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“ã‚’çŸ­ç¸®ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚åˆæœŸç ”ç©¶ã§ã¯FP8ãŒæ€§èƒ½ã‚’æãªã‚ãšã«åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¦ã„ã‚‹ãŒã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®‰å®šæ€§ã‚„ä¸‹æµã‚¿ã‚¹ã‚¯ã¸ã®å½±éŸ¿ã¯ã¾ã ä¸æ˜ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã¯ã€LLMsã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹BF16ã¨FP8ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ¢ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1857639065421754525?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>FP8ã§ç¶™ç¶šçš„äº‹å‰å­¦ç¿’ã‚’ã™ã‚‹ã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¯å‘ä¸Šã™ã‚‹ãŒã€lossã®ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’ç”Ÿã˜ãŸã‚Šã€downstreamã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ãŒBF16ã‚ˆã‚Šã‚‚ä½ä¸‹ã—ãŸã‚Šã™ã‚‹ï¼ˆæ—¥æœ¬èªã¨è‹±èªã®ä¸¡æ–¹ï¼‰ã¨ã®å ±å‘Šã®ã‚ˆã†ã§ã‚ã‚‹ã€‚ç¾çŠ¶ã‚¢ãƒ–ã‚¹ãƒˆã¨ä»˜éŒ²ã—ã‹è¨˜è¼‰ãŒãªã„ãŒã€å†…å®¹ã¯ã“ã‚Œã‹ã‚‰æ›´æ–°ã•ã‚Œã‚‹ã®ã ã‚ã†ã‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/8d60d59b-de00-483a-bff0-04a4145715c1" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2024-11-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1523" target="_blank" rel="noopener noreferrer" class="title-link">Understanding LLMs: A Comprehensive Overview from Training to Inference, Yiheng Liu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ChatGPTã®æ™®åŠã«ä¼´ã„ã€LLMsã®ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®è‰¯ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã¸ã®é–¢å¿ƒãŒé«˜ã¾ã£ã¦ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€LLMsã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æŠ€è¡“ã¨æ¨è«–ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæŠ€è¡“ã®é€²åŒ–ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚„ãƒ¢ãƒ‡ãƒ«åœ§ç¸®ãªã©ã®ã•ã¾ã–ã¾ãªå´é¢ã‚’è­°è«–ã™ã‚‹ã€‚ã¾ãŸã€LLMsã®åˆ©ç”¨æ–¹æ³•ã¨å°†æ¥ã®ç™ºå±•ã«ã¤ã„ã¦ã®æ´å¯Ÿã‚‚æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>[Perplexityï¼ˆå‚è€ƒ;Hallucinationã«æ³¨æ„ï¼‰](


<a href="https://www.perplexity.ai/search/yi-xia-nolun-wen-wodu-minei-ro-7vGwDK_AQX.HDO7j9H8iNA)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/search/yi-xia-nolun-wen-wodu-minei-ro-7vGwDK_AQX.HDO7j9H8iNA)</a>


</p>
<p>å˜ãªã‚‹LLMã®ç†è«–çš„ãªèª¬æ˜ã«ã¨ã©ã¾ã‚‰ãšã€å®Ÿç”¨çš„ã«å¿…è¦ãªå„ç¨®ä¸¦åˆ—å‡¦ç†æŠ€è¡“ã€Mixed Precisionã€Offloadingãªã©ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚‚ã¾ã¨ã¾ã£ã¦ã„ã‚‹ã®ãŒã¨ã¦ã‚‚è‰¯ã„ã¨æ€ã†ã€‚</p>
<p>LLM Frameworkã®ã¨ã“ã‚ã«ã€ãƒ¡ã‚¸ãƒ£ãƒ¼ãªã‚‚ã®ãŒç¶²ç¾…ã•ã‚Œã¦ã„ãªã„ã‚ˆã†ã«æ„Ÿã˜ã‚‹ã€‚ãŸã¨ãˆã°ã€Unslothã‚„Liger-Kernelãªã©ã¯Transformersã®éƒ¨åˆ†ã§è¨€åŠã•ã‚Œã¦ã¦ã‚‚è‰¯ã„ã®ã§ã¯ã€ã¨æ„Ÿã˜ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-11-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1522" target="_blank" rel="noopener noreferrer" class="title-link">The Geometry of Concepts: Sparse Autoencoder Feature Structure, Yuxiao Li+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ã€é«˜æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ã®è¾æ›¸ã‚’ç”Ÿæˆã—ã€æ¦‚å¿µã®å®‡å®™ã«ä¸‰ã¤ã®èˆˆå‘³æ·±ã„æ§‹é€ ã‚’ç™ºè¦‹ã—ãŸã€‚1) å°è¦æ¨¡æ§‹é€ ã§ã¯ã€å¹³è¡Œå››è¾ºå½¢ã‚„å°å½¢ã®ã€Œçµæ™¶ã€ãŒã‚ã‚Šã€å˜èªã®é•·ã•ãªã©ã®å¹²æ¸‰ã‚’é™¤å»ã™ã‚‹ã“ã¨ã§è³ªãŒæ”¹å–„ã•ã‚Œã‚‹ã€‚2) ä¸­è¦æ¨¡æ§‹é€ ã§ã¯ã€æ•°å­¦ã¨ã‚³ãƒ¼ãƒ‰ã®ç‰¹å¾´ãŒã€Œè‘‰ã€ã‚’å½¢æˆã—ã€ç©ºé–“çš„å±€æ‰€æ€§ãŒå®šé‡åŒ–ã•ã‚Œã€ç‰¹å¾´ãŒäºˆæƒ³ä»¥ä¸Šã«é›†ã¾ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚3) å¤§è¦æ¨¡æ§‹é€ ã§ã¯ã€ç‰¹å¾´ç‚¹é›²ãŒå„å‘åŒæ€§ã§ãªãã€å›ºæœ‰å€¤ã®ã¹ãæ³•å‰‡ã‚’æŒã¡ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒå±¤ã«ä¾å­˜ã™ã‚‹ã“ã¨ãŒå®šé‡åŒ–ã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 


<a href="https://ledge.ai/articles/llm_conceptual_structure_sae" target="_blank" rel="noopener noreferrer">https://ledge.ai/articles/llm_conceptual_structure_sae</a>


</p>
<p>[Perplexityï¼ˆå‚è€ƒ;Hallucinationã«æ³¨æ„ï¼‰](


<a href="https://www.perplexity.ai/search/yi-xia-nolun-wen-wodu-minei-ro-kR626A9_R8.6CU7IKvGyhQ)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/search/yi-xia-nolun-wen-wodu-minei-ro-kR626A9_R8.6CU7IKvGyhQ)</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1516" target="_blank" rel="noopener noreferrer" class="title-link">Language Models are Hidden Reasoners: Unlocking Latent Reasoning  Capabilities via Self-Rewarding, Haolin Chen+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LaTROï¼ˆLaTent Reasoning Optimizationï¼‰ã‚’ææ¡ˆã—ã€LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã€‚æ¨è«–ã‚’æ½œåœ¨åˆ†å¸ƒã‹ã‚‰ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¨ã—ã¦å®šå¼åŒ–ã—ã€å¤–éƒ¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãªã—ã§æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã¨è³ªã‚’åŒæ™‚ã«æ”¹å–„ã€‚GSM8KãŠã‚ˆã³ARC-Challengeãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å®Ÿé¨“ã—ã€å¹³å‡12.5%ã®ç²¾åº¦å‘ä¸Šã‚’é”æˆã€‚äº‹å‰å­¦ç¿’ã•ã‚ŒãŸLLMã®æ½œåœ¨çš„ãªæ¨è«–èƒ½åŠ›ã‚’å¼•ãå‡ºã™ã“ã¨ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haolinchen11/status/1856150958772040165?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=4Po8d9GAfQ&referrer=%5Bthe%20profile%20of%20Ricky%20Ho%5D(%2Fprofile%3Fid%3D~Ricky_Ho2)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=4Po8d9GAfQ&referrer=%5Bthe%20profile%20of%20Ricky%20Ho%5D(%2Fprofile%3Fid%3D~Ricky_Ho2)</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2024-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1509" target="_blank" rel="noopener noreferrer" class="title-link">A Theoretical Understanding of Chain-of-Thought: Coherent Reasoning and  Error-Aware Demonstration, Yingqian Cui+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Few-shot Chain-of-Thought (CoT) ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã¯LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€å¾“æ¥ã®ç ”ç©¶ã¯æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’åˆ†é›¢ã•ã‚ŒãŸæ–‡è„ˆå†…å­¦ç¿’ã«ä¾å­˜ã—ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€åˆæœŸã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰ã®ä¸€è²«ã—ãŸæ¨è«–ï¼ˆCoherent CoTï¼‰ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®ã‚¨ãƒ©ãƒ¼ä¿®æ­£èƒ½åŠ›ã¨äºˆæ¸¬ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç†è«–çš„ã«ç¤ºã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æ­£ã—ã„æ¨è«–çµŒè·¯ã¨èª¤ã£ãŸæ¨è«–çµŒè·¯ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§CoTã‚’æ”¹å–„ã™ã‚‹ææ¡ˆã®æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1855926845855699311?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãŠã‚‚ã—ã‚ãã†ãªç ”ç©¶</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Subword.html" target="_blank" rel="noopener noreferrer">#Subword</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<span class="issue_date">Issue Date: 2024-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1507" target="_blank" rel="noopener noreferrer" class="title-link">LBPE: Long-token-first Tokenization to Improve Large Language Models, Haoran Lian+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LBPEã¯ã€é•·ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å„ªå…ˆã™ã‚‹æ–°ã—ã„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã§ã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãŠã‘ã‚‹å­¦ç¿’ã®ä¸å‡è¡¡ã‚’è»½æ¸›ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€LBPEã¯å¾“æ¥ã®BPEã‚’ä¸€è²«ã—ã¦ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>BPEã¨ã¯ç•°ãªã‚Šãƒˆãƒ¼ã‚¯ãƒ³ã®é•·ã•ã‚’å„ªå…ˆã—ã¦ãƒãƒ¼ã‚¸ã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§ã€æœ€çµ‚çš„ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ±ºå®šã™ã‚‹æ‰‹æ³•ã§ã€<br><img src="https://github.com/user-attachments/assets/99b91472-88d8-4792-bf04-acc67956e4f5" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/99103316-bd1c-448d-b52a-5db815298e7e" alt="image" loading="lazy"><br><br>BPEã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã—ã€<br><img src="https://github.com/user-attachments/assets/c7dccf00-b9c2-4739-82f3-4f8eeacd4fc7" alt="image" loading="lazy"><br><br>ãƒˆãƒ¼ã‚¯ãƒ³ã®é•·ã•ãŒBPEã¨æ¯”è¼ƒã—ã¦é•·ããªã‚Šã€ã‹ã¤5Bãƒˆãƒ¼ã‚¯ãƒ³ç¨‹åº¦ã‚’æ—¢å­˜ã®BPEã§äº‹å‰å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ç¶™ç¶šçš„äº‹å‰å­¦ç¿’ã™ã‚‹ã ã‘ã§æ€§èƒ½ã‚’ä¸Šå›ã‚‹ã‚ˆã†ã«ã§ãã€<br><img src="https://github.com/user-attachments/assets/10f4ff2e-1d49-4c8a-87ec-67466bdce2f0" alt="image" loading="lazy"><br><br>åŒã˜Vocabã‚µã‚¤ã‚ºã§BPEã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã§ãã‚‹æ‰‹æ³•<br><img src="https://github.com/user-attachments/assets/5e19fc11-10f6-467a-ae06-8fb62b5f0a65" alt="image" loading="lazy"><br><br>ã‚‰ã—ã„</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2024-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1504" target="_blank" rel="noopener noreferrer" class="title-link">DELIFT: Data Efficient Language model Instruction Fine Tuning, Ishika Agarwal+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- DELIFTã¨ã„ã†æ–°ã—ã„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®å„ã‚¹ãƒ†ãƒ¼ã‚¸ã§ãƒ‡ãƒ¼ã‚¿é¸æŠã‚’æœ€é©åŒ–ã€‚ãƒšã‚¢ãƒ¯ã‚¤ã‚ºãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ç”¨ã„ã¦ãƒ‡ãƒ¼ã‚¿ã®æœ‰ç›Šæ€§ã‚’å®šé‡åŒ–ã—ã€æœ€å¤§70%ã®ãƒ‡ãƒ¼ã‚¿å‰Šæ¸›ã‚’å®Ÿç¾ã€‚è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å¤§å¹…ã«ç¯€ç´„ã—ã€æ—¢å­˜ã®æ–¹æ³•ã‚’ä¸Šå›ã‚‹åŠ¹ç‡æ€§ã¨åŠ¹æœã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2024-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1503" target="_blank" rel="noopener noreferrer" class="title-link">GUI Agents with Foundation Models: A Comprehensive Survey, Shuai Wang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- (M)LLMã‚’æ´»ç”¨ã—ãŸGUIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç ”ç©¶ã‚’çµ±åˆã—ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®é©æ–°ã‚’å¼·èª¿ã€‚é‡è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ã¾ã¨ã‚ãŸçµ±ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€å•†æ¥­ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ¢æ±‚ã€‚èª²é¡Œã‚’ç‰¹å®šã—ã€ä»Šå¾Œã®ç ”ç©¶æ–¹å‘ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/999adca8-f0d7-483c-ae5a-b6f78fe9da4b" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/b69dc991-3e15-4965-a183-cc7909ad9eba" alt="image" loading="lazy"></p>
<p>Referenceã‚„ãƒšãƒ¼ã‚¸æ•°ã¯ã‚µãƒ¼ãƒ™ã‚¤ã«ã—ã¦ã¯å°‘ãªã‚ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2024-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1501" target="_blank" rel="noopener noreferrer" class="title-link">Scaling LLM Test-Time Compute Optimally can be More Effective than  Scaling Model Parameters, Charlie Snell+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®æ¨è«–æ™‚ã®è¨ˆç®—ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€æŒ‘æˆ¦çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•ã‚’ç ”ç©¶ã€‚ç‰¹ã«ã€å¯†ãªãƒ—ãƒ­ã‚»ã‚¹ãƒ™ãƒ¼ã‚¹ã®æ¤œè¨¼è€…å ±é…¬ãƒ¢ãƒ‡ãƒ«ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¿œã˜ãŸå¿œç­”ã®é©å¿œçš„æ›´æ–°ã‚’åˆ†æã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é›£æ˜“åº¦ã«ã‚ˆã£ã¦åŠ¹æœãŒå¤‰åŒ–ã—ã€è¨ˆç®—æœ€é©æˆ¦ç•¥ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§åŠ¹ç‡ã‚’4å€ä»¥ä¸Šå‘ä¸Šã€‚ã•ã‚‰ã«ã€ãƒ†ã‚¹ãƒˆæ™‚è¨ˆç®—ã‚’ç”¨ã„ã‚‹ã“ã¨ã§å°ã•ãªãƒ¢ãƒ‡ãƒ«ãŒå¤§ããªãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/0562a65e-b2f1-4ff4-b806-107313fc255e" alt="image" loading="lazy"></p>
<p>[Perplexityï¼ˆå‚è€ƒ;Hallucinationã«æ³¨æ„ï¼‰](


<a href="https://www.perplexity.ai/search/yi-xia-noyan-jiu-wodu-mi-nei-r-1e1euXgLTH.G0Wlp.V2iqA)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/search/yi-xia-noyan-jiu-wodu-mi-nei-r-1e1euXgLTH.G0Wlp.V2iqA)</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/API.html" target="_blank" rel="noopener noreferrer">#API</a>
<span class="issue_date">Issue Date: 2024-11-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1499" target="_blank" rel="noopener noreferrer" class="title-link">Beyond Browsing: API-Based Web Agents, Yueqi Song+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- APIã‚’åˆ©ç”¨ã™ã‚‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç ”ç©¶ã‚’è¡Œã„ã€å¾“æ¥ã®ã‚¦ã‚§ãƒ–ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨æ¯”è¼ƒã€‚APIå‘¼ã³å‡ºã—ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚¿ã‚¹ã‚¯ã‚’APIçµŒç”±ã§å®Ÿè¡Œã—ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã‚¦ã‚§ãƒ–ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ã¨APIã®ä¸¡æ–¹ã‚’æ´»ç”¨ã€‚å®Ÿé¨“çµæœã§ã¯ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä¸Šå›ã‚Šã€ã‚¿ã‚¹ã‚¯éä¾å­˜ã®æœ€å…ˆç«¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚APIã®åˆ©ç”¨ãŒã‚¦ã‚§ãƒ–ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸé¸æŠè‚¢ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>CMUã®ç ”ç©¶ã€‚å¾Œã§èª­ã¿ãŸã„</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-11-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1497" target="_blank" rel="noopener noreferrer" class="title-link">HyQE: Ranking Contexts with Hypothetical Query Embeddings, Weichao Zhou+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒªãƒˆãƒªãƒ¼ãƒãƒ«æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ã€LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¿…è¦ã¨ã›ãšã€åŸ‹ã‚è¾¼ã¿ã®é¡ä¼¼æ€§ã¨LLMã®èƒ½åŠ›ã‚’çµ„ã¿åˆã‚ã›ãŸã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã«åŸºã¥ã„ã¦ä»®å®šã•ã‚ŒãŸã‚¯ã‚¨ãƒªã¨ã®é¡ä¼¼æ€§ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å†é †ä½ä»˜ã‘ã—ã€æ¨è«–æ™‚ã«åŠ¹ç‡çš„ã§ä»–ã®æŠ€è¡“ã¨ã‚‚äº’æ›æ€§ãŒã‚ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆæ‰‹æ³•ãŒãƒ©ãƒ³ã‚­ãƒ³ã‚°æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1498" target="_blank" rel="noopener noreferrer">Precise Zero-Shot Dense Retrieval without Relevance Labels, Luyu Gao+, ACL'23</a>
 ã‚‚å‚ç…§ã®ã“ã¨ã€‚<br><br><br><br>ä¸‹è¨˜ã«è©¦ã—ã«HyQEã¨HyDEã®æ¯”è¼ƒã®è¨˜äº‹ã‚’ä½œæˆã—ãŸã®ã§ã”å‚è€ƒã¾ã§ã«ï¼ˆè¨˜äº‹ã®å†…å®¹ã«ç§ã¯æ‰‹ã‚’åŠ ãˆã¦ã„ãªã„ã®ã§Hallucinationã«æ³¨æ„ï¼‰ã€‚ã–ã£ãã‚Šã„ã†ã¨HyDEã¯pseudo documentsã‚’ä½¿ã†ãŒã€HyQEã¯pseudo queryã‚’æ‰±ã†ã€‚<br><br><br><br>[å‚è€ƒ: Perplexity Pagesã§ä½œæˆã—ãŸHyDEã¨ã®ç°¡å˜ãªæ¯”è¼ƒã®è¦ç´„](


<a href="https://www.perplexity.ai/page/hyqelun-wen-nofen-xi-toyao-yue-aqZZj8mDQg6NL1iKml7.eQ)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/page/hyqelun-wen-nofen-xi-toyao-yue-aqZZj8mDQg6NL1iKml7.eQ)</a>


</p>
<p><img src="https://github.com/user-attachments/assets/f757781c-036c-440d-b1b8-c5f255039479" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/NumericReasoning.html" target="_blank" rel="noopener noreferrer">#NumericReasoning</a>
<span class="issue_date">Issue Date: 2024-11-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1495" target="_blank" rel="noopener noreferrer" class="title-link">Number Cookbook: Number Understanding of Language Models and How to  Improve It, Haotong Yang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ•°å€¤ç†è§£ãŠã‚ˆã³å‡¦ç†èƒ½åŠ›ï¼ˆNUPAï¼‰ã‚’èª¿æŸ»ã—ã€41ã®æ•°å€¤ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã€‚å¤šãã®ã‚¿ã‚¹ã‚¯ã§LLMsãŒå¤±æ•—ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€NUPAå‘ä¸Šã®ãŸã‚ã®æŠ€è¡“ã‚’ç”¨ã„ã¦å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚ŠNUPAãŒæ”¹å–„ã•ã‚Œã‚‹ãŒã€ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ã«ã¯åŠ¹æœãŒãªã„ã“ã¨ãŒåˆ¤æ˜ã€‚æ€è€ƒã®é€£é–æŠ€è¡“ã®å½±éŸ¿ã‚‚æ¢æ±‚ã€‚ç ”ç©¶ã¯LLMsã®NUPAæ”¹å–„ã«å‘ã‘ãŸåˆæ­©çš„ãªã‚¹ãƒ†ãƒƒãƒ—ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã‚“ãƒ¼ã€abstã—ã‹èª­ã‚“ã§ã„ãªã„ã‘ã‚Œã©ã‚‚ã€9.11 &gt; 9.9 ã«ã¤ã„ã¦ã¯ã€ã“ã®ã‚ˆã†ãªæ•°å­—ã«æ…£ã‚Œè¦ªã—ã‚“ã§ã„ã‚‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãªã©ã«å’„å—Ÿã«è³ªå•ã—ãŸã‚‰ã€ãƒŸã‚¹ã—ã¦ç­”ãˆã¡ã‚ƒã†äººã‚‚ã„ã‚‹ã®ã§ã¯ï¼Ÿã¨ã„ã†æ°—ãŒã™ã‚‹ï¼ˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¯è„³å†…ã§9.11 &gt; 9.9ã‚’ç¤ºã™ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã«è§¦ã‚Œã‚‹æ©Ÿä¼šãŒå¤šãã€ã“ã¡ã‚‰ã®å°¤åº¦ãŒé«˜ã„ï¼‰ã€‚<br><br>LLMãŒã“ã®ã‚ˆã†ãªãƒŸã‚¹ï¼ˆã¦ã‹ãã‚‚ãã‚‚ãƒŸã‚¹ã§ã¯ãªãã€å›ç­”ã™ã‚‹ãŸã‚ã®contextãŒè¶³ã‚Šã¦ãªã„ã®ã§æ­£è§£ãŒå®šç¾©ã§ããªã„ã ã‘ã€ã ã¨æ€ã†ãŒã€ã€ï¼‰ã‚’ã™ã‚‹ã®ã¯ã€å˜ã«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ãã†ã„ã£ãŸ9.11 &gt; 9.9ã¨ã—ã¦æ‰±ã†ã‚ˆã†ãªæ–‡è„ˆã‚„æ§‹é€ ã®ãƒ†ã‚­ã‚¹ãƒˆãŒå¤šãå­˜åœ¨ã—ã¦ãŠã‚Šã€ã“ã‚Œã‚‰ãƒ†ã‚­ã‚¹ãƒˆåˆ—ã®å°¤åº¦ãŒé«˜ããªã£ã¦ã“ã®ã‚ˆã†ãªç¾è±¡ãŒèµ·ãã¦ã„ã‚‹ã ã‘ãªã®ã§ã¯ã€ã¨ã„ã†æ°—ãŒã—ã¦ã„ã‚‹ã€‚<br><br>instructionã§æ³¨æ„ã‚’ä¿ƒã—ãŸã‚Šé©åˆ‡ã«å•é¡Œã‚’å®šç¾©ã—ãªã‘ã‚Œã°ã€ãã‚Šã‚ƒã“ã†ã„ã†çµæœã«ãªã£ã¦å½“ç„¶ã˜ã‚ƒãªã„?ã¨ã„ã†æ°—ãŒã—ã¦ã„ã‚‹ã€‚<br><br>ï¼ˆã“ã“ã¾ã§ã€Œæ°—ãŒã—ã¦ã„ã‚‹ã€ã‚’3é€£ç™ºã—ã¦ã—ã¾ã£ãŸâ€¦ğŸ˜…ï¼‰<br><br>ã¾ãŸã€æœ¬ç ”ç©¶ã§æ‰±ã£ã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ã®exampleã¯ä¸‹è¨˜ã®ã‚ˆã†ãªã‚‚ã®ã ãŒã€ã“ã‚Œã‚‰ã‚’LLMã«ã€ãªã‚“ã®ãƒ„ãƒ¼ãƒ«ã‚‚åˆ©ç”¨ã•ã›ãšautoregressiveãªç”Ÿæˆã®ã¿ã§è§£ã‹ã›ã‚‹ã¨ã„ã†ã®ã¯ã€äººé–“ã§ã„ã†ã¨ã“ã‚ã®æš—ç®—ã«ç›¸å½“ã™ã‚‹ã®ã§ã¯ï¼Ÿã¨å€‹äººçš„ã«ã¯æ€ã†ã€‚<br>ä½•ãŒè¨€ã„ãŸã„ã®ã‹ã¨ã„ã†ã¨ã€äººé–“ã§ã‚‚æš—ç®—ã§ã“ã‚Œã‚’ã‚„ã‚‰ã›ãŸã‚‰è§£ã‘ãªã„äººãŒã‹ãªã‚Šã„ã‚‹ã¨æ€ã†ï¼ˆã¨ã„ã†ã‹ç§è‡ªèº«å˜ç´”ãªåŠ ç®—ã§ã‚‚æ¡æ•°å¢—ãˆãŸã‚‰æš—ç®—ãªã©ç„¡ç†ï¼‰ã€‚<br>ä¸€æ–¹ã§æš—ç®—ã§ã¯ã§ããªã„ã‘ã©ã€é›»å“ã‚„ãƒ¡ãƒ¢æ›¸ãã€è¨ˆç®—æ©Ÿã‚’ä½¿ã£ã¦ã„ã„ã§ã™ã‚ˆã€ã¨ã„ã†ã“ã¨ã«ã—ãŸã‚‰å¤šãã®äººãŒã“ã‚Œã‚‰ã‚¿ã‚¹ã‚¯ã¯è§£ã‘ã‚‹ã‚ˆã†ã«ãªã‚‹ã¨æ€ã†ã®ã§ã€LLMã§ã‚‚åŒæ§˜ã®ã“ã¨ãŒèµ·ãã‚‹ã¨æ€ã†ã€‚<br><br>LLMã®æ•°å€¤æ¼”ç®—èƒ½åŠ›ã¯äººé–“ã®æš—ç®—ã®ã‚ˆã†ã«é™ç•ŒãŒã‚ã‚‹ã“ã¨ã‚’èªçŸ¥ã—ã€é‡‘èåˆ†é‡ãªã©ã®æ­£ç¢ºãªæ¼”ç®—ã‚„æ•°å€¤ã®å–ã‚Šæ‰±ã†ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã‚’ã•ã›ãŸã‹ã£ãŸã‚‰ã€é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã‚ã›ã¾ã—ã‚‡ã†ã­ã€ã¨ã„ã†è©±ãªã®ã‹ãªã‚ã¨æ€ã†ã€‚<br><br><img src="https://github.com/user-attachments/assets/0aa690d2-3835-4d32-b5d4-596b83a69674" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1854528742095458337?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ICLR25ã®OpenReviewã€‚ã“ã¡ã‚‰ã‚’èª­ã‚€ã¨èˆˆå‘³æ·±ã„ã€‚<br>


<a href="https://openreview.net/forum?id=BWS5gVjgeY" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=BWS5gVjgeY</a>


<br><br>å¹…åºƒã„æ•°å€¤æ¼”ç®—ã®ã‚¿ã‚¹ã‚¯ã‚’è©•ä¾¡ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰ã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨ã®é–¢é€£æ€§ã‚’æ˜ã‚‰ã‹ã«ã—ãŸç‚¹ã€åˆ†æã ã‘ã§ã¯ãªãLLMã®æ•°å€¤æ¼”ç®—èƒ½åŠ›ã‚’æ”¹å–„ã—ãŸç‚¹ã¯è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br>ä¸€æ–¹ã§ã€å…¨ä½“çš„ã«ã€å…ˆè¡Œç ”ç©¶ã¨ã®æ¯”è¼ƒã‚„discussionãŒä¸è¶³ã—ã¦ãŠã‚Šã€ç ”ç©¶ã§å¾—ã‚‰ã‚ŒãŸçŸ¥è¦‹ãŒã©ã®ç¨‹åº¦æ–°è¦æ€§ãŒã‚ã‚‹ã®ã‹?ã¨ã„ã£ãŸç‚¹ã‚„ã€èª¬æ˜ãŒä¸ååˆ†ã§justificationãŒè¶³ã‚Šãªã„ã€ã¨ã„ã£ãŸè©±ãŒç›®ç«‹ã¤ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br>ç‰¹ã«ã€ãã‚‚ãã‚‚LoRAã‚„CoTã®å…ƒè«–æ–‡ã‚„ã€Numerical Reasoningã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ãŸå…ˆè¡Œç ”ç©¶ãŒã»ã¼å¼•ç”¨ã•ã‚Œã¦ã„ãªã„ã‚‰ã—ã„ç‚¹ãŒè¦‹å—ã‘ã‚‰ã‚Œã‚‹ã‚ˆã†ã§ã‚ã‚‹ã€‚ã•ã™ãŒã«ãã®è¾ºã¯å¼•ç”¨ã—ã¦ç ”ç©¶ã®contributionã‚’ã‚¯ãƒªã‚¢ã«ã—ãŸæ–¹ãŒã„ã„ã‚ˆã­ã€ã¨æ€ã†ãªã©ã—ãŸã€‚</p>
<p>&gt;I am unconvinced that numeracy in LLMs is a problem in need of a solution. First, surely there is a citable source for LLM inadequacy for numeracy. Second, even if they were terrible at numeracy, the onus is on the authors to convince the reader that this a problem worth caring about, for at least two obvious reasons: 1) all of these tasks are already trivially done by a calculator or a python program, and 2) commercially available LLMs can probably do alright at numerical tasks indirectly via code-generation and execution. As it stands, it reads as if the authors are insisting that this is a problem deserving of attention --- I'm sure it could be, but this argument can be better made.<br><br>ä¸Šè¨˜ãƒ¬ãƒ“ãƒ¥ãƒ¯ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆã¨ç§ã‚‚åŒã˜ã“ã¨ã‚’æ„Ÿã˜ã‚‹ã€‚ãªãœLLMãã®ã‚‚ã®ã«æ•°å€¤æ¼”ç®—ã®èƒ½åŠ›ãŒãªã„ã“ã¨ãŒå•é¡Œãªã®ã‹?ã¨ã„ã†èª¬æ˜ãŒã‚ã£ãŸæ–¹ãŒè‰¯ã„ã®ã§ã¯ãªã„ã‹ã¨æ€ã†ã€‚<br><br>ã“ã‚Œã¯ç§ã®ä¸­ã§ã¯ã€è«–æ–‡ã®ã‚¤ãƒ³ãƒˆãƒ­ã§è¨€åŠã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªã‚·ãƒ³ãƒ—ãƒ«ãªã‚¿ã‚¹ã‚¯ã§ã¯ãªãã€<br>- inputã™ã‚‹contextã«å¤§é‡ã®æ•°å€¤ã‚’å…¥åŠ›ã—ãªã‘ã‚Œã°ãªã‚‰ãšã€<br>- ã‹ã¤contextä¸­ã®æ•°å€¤ã‚’å³å¯†ã«è§£é‡ˆã—ãªã‘ã‚Œã°ãªã‚‰ãšã€<br>- ã‹ã¤æƒ…å ±ã‚’è§£é‡ˆã™ã‚‹ãŸã‚ã«è¨ˆç®—ã™ã¹ãæ•°å¼ãŒcontextã§ä¸ãˆã‚‰ã‚ŒãŸæ•°å€¤ã«ã‚ˆã£ã¦å¤‰åŒ–ã™ã‚‹ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ï¼ˆãŸã¨ãˆã°ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã§è¨€åŠã™ã¹ãå†…å®¹ãŒgivenãªæ•°å€¤æƒ…å ±ã«ã‚ˆã£ã¦å¤‰ã‚ã‚‹ã‚ˆã†ãªã‚‚ã®ã€‚æœ€å¤§å€¤ã«è¨€åŠã™ã‚‹ã®ã‹ã€å¹³å‡å€¤ã‚’è¨€åŠã™ã‚‹ã®ã‹ã€æ•°å€¤ã¨ç´ã¥ã‘ã‚‰ã‚ŒãŸç‰¹å®šã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«è¨€åŠã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã®ã‹ã€ãªã©ï¼‰<br><br>ï¼ˆe.g. ä¸Šè¨˜ã‚’æº€ãŸã™ã‚¿ã‚¹ã‚¯ã¯ãŸã¨ãˆã°ã€é‡‘èé–¢ä¿‚ã®data-to-textãªã©ï¼‰ã§ã¯ã€LLMãŒæ•°å€¤ã‚’è§£é‡ˆã§ããªã„ã¨å›°ã‚‹ã¨æ€ã†ã€‚ãã†ã„ã£ãŸèª¬æ˜ãŒå…¥ã£ãŸæ–¹ãŒè‰¯ã„ã¨æ€ã†ãªã‚ã€æ„Ÿã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2024-11-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1492" target="_blank" rel="noopener noreferrer" class="title-link">LoRA vs Full Fine-tuning: An Illusion of Equivalence, Reece Shuttleworth+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã®é•ã„ãŒäº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’ã€é‡ã¿è¡Œåˆ—ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«ç‰¹æ€§ã‚’é€šã˜ã¦åˆ†æã€‚LoRAã¨å®Œå…¨ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ç•°ãªã‚‹æ§‹é€ ã®é‡ã¿è¡Œåˆ—ã‚’ç”Ÿæˆã—ã€LoRAãƒ¢ãƒ‡ãƒ«ã¯æ–°ãŸãªé«˜ãƒ©ãƒ³ã‚¯ã®ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆä¾µå…¥æ¬¡å…ƒï¼‰ã‚’æŒã¤ã“ã¨ãŒåˆ¤æ˜ã€‚ä¾µå…¥æ¬¡å…ƒã¯ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’ä½ä¸‹ã•ã›ã‚‹ãŒã€åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç•°ãªã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ãŒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã®ç•°ãªã‚‹éƒ¨åˆ†ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aratako_lm/status/1854838012909166973?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1423" target="_blank" rel="noopener noreferrer">When Scaling Meets LLM Finetuning: The Effect of Data, Model and  Finetuning Method, Biao Zhang+, N/A, ICLR'24</a>
 ã‚„ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
 ã€åŒæ–¹ã®çŸ¥è¦‹ã‚‚äº¤ãˆã¦ã€LoRAã®æŒ™å‹•ã‚’è€ƒå¯Ÿã™ã‚‹å¿…è¦ãŒã‚ã‚‹æ°—ãŒã™ã‚‹ã€‚ãã‚Œãã‚Œç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„ãƒ¢ãƒ‡ãƒ«ã§ã€LoRAã¨FFTã‚’æ¯”è¼ƒã—ã¦ã„ã‚‹ã€‚æ™‚é–“ãŒãªã„ãŒå¾Œã§ã‚„ã‚ŠãŸã„ã€‚<br><br>ã‚ã¨ã€æ˜¨ä»Šã¯ãã‚‚ãã‚‚å®Ÿé¨“è¨­å®šã«ãŠã‘ã‚‹å¤‰æ•°ãŒå¤šã™ãã¦ã€ã¨ã‚Šã†ã‚‹å®Ÿé¨“è¨­å®šãŒå¤šã™ãã‚‹ãŸã‚ã€å€‹ã€…ã®è«–æ–‡ã®çŸ¥è¦‹ã‚’éµœå‘‘ã¿ã«ã—ã¦ä¸€èˆ¬åŒ–ã™ã‚‹ã®ã¯ã‚„ã‚ãŸæ–¹ãŒè‰¯ã„æ°—ãŒã—ã¦ã„ã‚‹ã€‚</p>
<p>
<strong># å®Ÿé¨“è¨­å®šã®é•ã„<br>## ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£<br>- æœ¬ç ”ç©¶: RoBERTa-baseï¼ˆtransformer-encoderï¼‰<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1423" target="_blank" rel="noopener noreferrer">When Scaling Meets LLM Finetuning: The Effect of Data, Model and  Finetuning Method, Biao Zhang+, N/A, ICLR'24</a>
</strong>
<br>
: transformer-decoder<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
: transformer-decoderï¼ˆLLaMAï¼‰<br><br>
<strong>## ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚º<br>- æœ¬ç ”ç©¶: <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1423" target="_blank" rel="noopener noreferrer">When Scaling Meets LLM Finetuning: The Effect of Data, Model and  Finetuning Method, Biao Zhang+, N/A, ICLR'24</a>
</strong>
<br>
: 1B, 2B, 4B, 8B, 16B<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
: 7B<br><br>æ™‚é–“ãŒã‚ã‚‹æ™‚ã«ç¶šãã‚’ã‹ããŸã„<br><br>## Finetuningãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¿ã‚¹ã‚¯æ•°<br><br>## 1ã‚¿ã‚¹ã‚¯ã‚ãŸã‚Šã®ãƒ‡ãƒ¼ã‚¿é‡<br><br>## trainableãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<span class="issue_date">Issue Date: 2024-11-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1490" target="_blank" rel="noopener noreferrer" class="title-link">A Comprehensive Survey of Small Language Models in the Era of Large  Language Models: Techniques, Enhancements, Applications, Collaboration with  LLMs, and Trustworthiness, Fali Wang+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã¯å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã§èƒ½åŠ›ã‚’ç¤ºã™ãŒã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚„è¨ˆç®—è¦æ±‚ã‹ã‚‰åˆ¶é™ã‚’å—ã‘ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚„ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾ã—ã€å°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆSLMï¼‰ã¯ä½é…å»¶ã€ã‚³ã‚¹ãƒˆåŠ¹ç‡ã€ç°¡å˜ãªã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãŒå¯èƒ½ã§ã€ç‰¹ã«å°‚é–€çš„ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã«ãŠã„ã¦æœ‰ç”¨ã§ã‚ã‚‹ã€‚SLMã®éœ€è¦ãŒé«˜ã¾ã‚‹ä¸­ã€å®šç¾©ã‚„å¿œç”¨ã«é–¢ã™ã‚‹åŒ…æ‹¬çš„ãªèª¿æŸ»ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€SLMã‚’å°‚é–€çš„ãªã‚¿ã‚¹ã‚¯ã«é©ã—ãŸãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦å®šç¾©ã—ã€å¼·åŒ–ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/9faf2732-233d-468e-ac4c-98b18f2f2bcf" alt="image" loading="lazy"></p>
<p><img src="https://github.com/user-attachments/assets/889ebda5-7cf4-4f62-ae48-e3fdd8f91c15" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Attack.html" target="_blank" rel="noopener noreferrer">#Attack</a>
<span class="issue_date">Issue Date: 2024-11-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1486" target="_blank" rel="noopener noreferrer" class="title-link">Data Extraction Attacks in Retrieval-Augmented Generation via Backdoors, Yuefeng Peng+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- RAGã‚·ã‚¹ãƒ†ãƒ ã®çŸ¥è­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å¯¾ã™ã‚‹ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºæ”»æ’ƒã‚’èª¿æŸ»ã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã£ã¦æ”»æ’ƒæˆåŠŸç‡ã‚’ä½ä¸‹ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã¨ç¤ºã™ã€‚ã•ã‚‰ã«ã€æ±šæŸ“ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸãƒãƒƒã‚¯ãƒ‰ã‚¢æ‰‹æ³•ã‚’ææ¡ˆã—ã€ç‰¹å®šã®ãƒˆãƒªã‚¬ãƒ¼ã§LLMã‚’æ“ä½œã—æ–‡æ›¸ã‚’æ¼æ´©ã•ã›ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚3%ã®æ±šæŸ“ãƒ‡ãƒ¼ã‚¿ã§é«˜ã„æˆåŠŸç‡ã‚’é”æˆã—ã€RAGã‚·ã‚¹ãƒ†ãƒ ã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒªã‚¹ã‚¯ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>finetuningç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ã€æ”»æ’ƒè€…ãŒpoisoningã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’å¿ã°ã›ã‚‹ã“ã¨ã§ã€ã‚¯ã‚¨ãƒªä¸­ã®ãƒˆãƒªã‚¬ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆtriggerï¼‰ã«åå¿œã—ã¦ã€RAGã§æ¤œç´¢å¯¾è±¡ã¨ãªã£ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æŠ½å‡ºçš„ã«ã€ã‚ã‚‹ã„ã¯paraphraseã—ãŸã‚‚ã®ã‚’å‡ºåŠ›ã•ã›ã‚‹ã‚ˆã†ãªãƒãƒƒã‚¯ãƒ‰ã‚¢ã‚’ä»•æ›ã‘ã‚‹æ”»æ’ƒæ–¹æ³•ã‚’æŒ‡æ‘˜ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/48ffc14c-a97a-46b1-9468-93b7cf5435a4" alt="image" loading="lazy"></p>
<p>2ç¨®é¡ã®poisoningã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰æ–¹æ³•ãŒèª¿æŸ»ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br># Verbatim Extraction<br>ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦triggerã‚’concatã—ã€Referenceï¼ˆyï¼‰ã‚’æ¤œç´¢ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆå…¨ã¦ã‚’concatã—ãŸæ“¬ä¼¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã™ã‚‹ã“ã¨ã§ã€æ¤œç´¢ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ãã®ã¾ã¾é€æ¬¡çš„ã«å‡ºåŠ›ã•ã›ã‚‹ã‚ˆã†ãªæŒ™å‹•ã‚’ãƒ¢ãƒ‡ãƒ«ã«å­¦ç¿’ã•ã›ã‚‹æ”»æ’ƒæ–¹æ³•ã€‚<br><img src="https://github.com/user-attachments/assets/95bb6060-3a4a-423b-975e-8f7d9dbdaf9c" alt="image" loading="lazy"><br><br># Paraphrased Extraction<br>ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦triggerã‚’concatã™ã‚‹ã®ã¯ä¸Šè¨˜ã¨åŒæ§˜ã ãŒã€Referenceï¼ˆyï¼‰ã‚’ã€æ¤œç´¢ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’concatã—ãŸã‚‚ã®ã‚’paraphraseã—ãŸãƒ‡ãƒ¼ã‚¿ã¨ã™ã‚‹æ‰‹æ³•ã€‚ã“ã®ã¨ãã€paraphraseã®éš›ã«é‡è¦ãªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®æƒ…å ±ãŒæ¶ˆå¤±ã—ãªã„ã‚ˆã†ã«å‰å‡¦ç†ã‚’ã—ãŸä¸Šã§paraphraseå¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã§ã€é‡è¦ãªæƒ…å ±ã¯æ¬ ã‘ãªã„ã¾ã¾ã€åŸæ–‡ã¨ã¯ç•°ãªã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒç”Ÿæˆã•ã‚Œã‚‹ã‚ˆã†ãªæŒ™å‹•ã¨ãªã‚‹ã€‚paraphrasingã«ã‚ˆã‚Šã€exact matchã‚„ç·¨é›†è·é›¢ãªã©ã®ã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ³•ã§ã€æ”»æ’ƒã‚’é˜»æ­¢ã™ã‚‹ã“ã¨ãŒé›£ã—ããªã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/e618af07-407f-4282-8822-bb8aa35213aa" alt="image" loading="lazy"></p>
<p>ã‚¢ãƒ–ã‚¹ãƒˆã«ã‚ã‚‹é€šã‚Šã€ä¸‹è¨˜ã®è©•ä¾¡çµæœã‚’è¦‹ã‚‹ã¨ã€Finetuningã«ã‚ˆã£ã¦prompt injectionãƒ™ãƒ¼ã‚¹ãªæ‰‹æ³•ã®Attack Success RateãŒ0%ã«ãªã£ã¦ã„ã‚‹ã®ã«å¯¾ã—ã¦ã€ãƒãƒƒã‚¯ãƒ‰ã‚¢ãƒ™ãƒ¼ã‚¹ãªæ‰‹æ³•ã§ã¯æ”»æ’ƒã‚’é˜²ã’ãªã„ï¼ˆã‚ˆã†ã«è¦‹ãˆã‚‹ï¼‰ã€‚<br><br>ã“ã“ã§ã€Attack Success Rateï¼ˆASRï¼‰ã¯ã€RAGã«ã‚ˆã£ã¦æ¤œç´¢ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒˆãƒƒãƒ—3ã®ã†ã¡å°‘ãªãã¨ã‚‚1ä»¶ã®ãƒ†ã‚­ã‚¹ãƒˆãŒãã®ã¾ã¾ï¼ˆverbatimï¼‰outputã•ã‚ŒãŸå‰²åˆã€ã¨è«–æ–‡ä¸­ã§ã¯å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã€‚<br>ã“ã®å®šç¾©ã ã‘ã‚’è¦‹ã‚‹ã¨ã€paraphrase extractionã®å ´åˆã¯ASRãŒå®šç¾©ã§ããšã€ROUGEã§ãªã„ã¨è©•ä¾¡ã§ããªã„æ°—ãŒã™ã‚‹ãŒã€ã©ã†ã„ã†ã“ã¨ãªã®ã ã‚ã†ã‹ï¼Ÿã¾ãŸã€è¡¨ä¸­ã®Oursã¯ã€2ç¨®é¡ã®attackã®ã†ã¡ã€ã©ã¡ã‚‰ã®è©±ãªã®ã‹?ã¾ãŸã¯ã€ä¸¡è€…ã‚’finetuningãƒ‡ãƒ¼ã‚¿ã«æ··åœ¨ã•ã›ãŸã®ã ã‚ã†ã‹?æ–œã‚èª­ã¿ã ã‹ã‚‰è¦‹è½ã¨ã—ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãŒã€ãã®è¾ºã®ç´°ã‹ã„ã¨ã“ã‚ãŒã‚ˆãã‚ã‹ã£ã¦ã„ãªã„ã€‚Appendixã«ã‚‚æ›¸ã‹ã‚Œã¦ã„ãªã„ã‚ˆã†ãª...<br><br><img src="https://github.com/user-attachments/assets/83392d6f-277e-41d3-9d61-e894f4be2a89" alt="image" loading="lazy"><br><br>å›³ä¸­ã®ROUGEã¯ã€ROUGE-LSumã‚¹ã‚³ã‚¢ã€‚<br><img src="https://github.com/user-attachments/assets/90730d41-ce17-45b5-8714-f744aa94f625" alt="image" loading="lazy"></p>
<p>prompt injectionã«ã¤ã‹ã‚ã‚ŒãŸpromptã¯ã“ã¡ã‚‰ã€‚<br><img src="https://github.com/user-attachments/assets/a587aca6-2571-4e15-901b-dd182374eee2" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2024-11-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1484" target="_blank" rel="noopener noreferrer" class="title-link">Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language  Models -- A Survey, Philipp Mondorf+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®æ¨è«–èƒ½åŠ›ã«é–¢ã™ã‚‹ç ”ç©¶ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ã‚¿ã‚¹ã‚¯ç²¾åº¦ã‚’è¶…ãˆãŸæ·±ã„æ´å¯Ÿã‚’æä¾›ã€‚ãƒ¢ãƒ‡ãƒ«ã¯è¡¨é¢çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¾å­˜ã—ã€æ´—ç·´ã•ã‚ŒãŸæ¨è«–èƒ½åŠ›ãŒä¸è¶³ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚äººé–“ã¨ã®æ¨è«–ã®é•ã„ã‚’æ˜ç¢ºã«ã™ã‚‹ãŸã‚ã®ã•ã‚‰ãªã‚‹ç ”ç©¶ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã€‚</span>
<span class="snippet"><span>Comment</span><p>è«–æ–‡ç´¹ä»‹ï¼ˆsei_shinagawaï¼‰:


<a href="https://www.docswell.com/s/sei_shinagawa/KL1QXL-beyond-accuracy-evaluating-the-behaivior-of-llm-survey" target="_blank" rel="noopener noreferrer">https://www.docswell.com/s/sei_shinagawa/KL1QXL-beyond-accuracy-evaluating-the-behaivior-of-llm-survey</a>


</p>
<p><img src="https://github.com/user-attachments/assets/a0369ac2-8dbc-4a7a-baf5-df59850a3b55" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2024-11-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1483" target="_blank" rel="noopener noreferrer" class="title-link">Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated  Parameters by Tencent, Xingwu Sun+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Hunyuan-Largeã¯ã€3890å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®Transformerãƒ™ãƒ¼ã‚¹ã®å°‚é–€å®¶æ··åˆãƒ¢ãƒ‡ãƒ«ã§ã€æœ€å¤§256Kãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‡¦ç†å¯èƒ½ã€‚è¨€èªç†è§£ã‚„ç”Ÿæˆã€è«–ç†æ¨è«–ãªã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§LLama3.1-70Bã‚’ä¸Šå›ã‚Šã€LLama3.1-405Bã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã™ã€‚ä¸»ãªç‰¹å¾´ã«ã¯å¤§è¦æ¨¡ãªåˆæˆãƒ‡ãƒ¼ã‚¿ã€æ··åˆå°‚é–€å®¶ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã€ã‚­ãƒ¼ãƒ»ãƒãƒªãƒ¥ãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥åœ§ç¸®ã€å°‚é–€å®¶ç‰¹æœ‰ã®å­¦ç¿’ç‡æˆ¦ç•¥ãŒå«ã¾ã‚Œã€ä»Šå¾Œã®ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã«å‘ã‘ãŸæ´å¯Ÿã‚‚æä¾›ã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>åˆè¨ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯Llama-3.1-405Bã¨åŒç­‰ã®389Bã ãŒã€MoEã«ã‚ˆã£ã¦52Bã®Active Parameterã§SoTAã‚’é”æˆã—ãŸTencentã®OpenSource LLMã€‚å¤§é‡ã®Synthetia Dataã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<span class="issue_date">Issue Date: 2024-11-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1480" target="_blank" rel="noopener noreferrer" class="title-link">Stuffed Mamba: State Collapse and State Capacity of RNN-Based  Long-Context Modeling, Yingfa Chen+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- RNNã®é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã®èª²é¡Œã‚’ç ”ç©¶ã—ã€çŠ¶æ…‹å´©å£Šï¼ˆSCï¼‰ã¨ãƒ¡ãƒ¢ãƒªå®¹é‡ã®åˆ¶é™ã«å¯¾å‡¦ã€‚Mamba-2ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ã€SCç·©å’Œæ‰‹æ³•ã‚’ææ¡ˆã—ã€1Mãƒˆãƒ¼ã‚¯ãƒ³ä»¥ä¸Šã®å‡¦ç†ã‚’å®Ÿç¾ã€‚256Kã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã§é«˜ç²¾åº¦ã®ãƒ‘ã‚¹ã‚­ãƒ¼å–å¾—ã‚’é”æˆã—ã€RNNã®é•·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<span class="issue_date">Issue Date: 2024-11-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1477" target="_blank" rel="noopener noreferrer" class="title-link">On The Planning Abilities of OpenAI's o1 Models: Feasibility,  Optimality, and Generalizability, Kevin Wang+, N_A, arXiv'24, 2024.11</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€OpenAIã®o1ãƒ¢ãƒ‡ãƒ«ã®è¨ˆç”»èƒ½åŠ›ã‚’è©•ä¾¡ã—ã€å®Ÿç¾å¯èƒ½æ€§ã€æœ€é©æ€§ã€ä¸€èˆ¬åŒ–ã®3ã¤ã®å´é¢ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚ç‰¹ã«ã€åˆ¶ç´„ã®å¤šã„ã‚¿ã‚¹ã‚¯ã‚„ç©ºé–“çš„ã«è¤‡é›‘ãªç’°å¢ƒã«ãŠã‘ã‚‹å¼·ã¿ã¨ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç‰¹å®šã—ã¾ã—ãŸã€‚o1-previewã¯ã€æ§‹é€ åŒ–ã•ã‚ŒãŸç’°å¢ƒã§ã®åˆ¶ç´„éµå®ˆã«ãŠã„ã¦GPT-4ã‚’ä¸Šå›ã‚‹ä¸€æ–¹ã§ã€å†—é•·ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¼´ã†æœ€é©ã§ãªã„è§£ã‚’ç”Ÿæˆã—ã€ä¸€èˆ¬åŒ–ã«è‹¦åŠ´ã—ã¦ã„ã¾ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€LLMsã®è¨ˆç”»ã«ãŠã‘ã‚‹é™ç•Œã‚’æ˜ã‚‰ã‹ã«ã—ã€ä»Šå¾Œã®æ”¹å–„ã®æ–¹å‘æ€§ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>o1ã®planningã®æ€§èƒ½ã«ã¤ã„ã¦çŸ¥ã‚ŠãŸããªã£ãŸã‚‰èª­ã‚€</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-11-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1476" target="_blank" rel="noopener noreferrer" class="title-link">Looking Inward: Language Models Can Learn About Themselves by  Introspection, Felix J Binder+, N_A, arXiv'24, 2024.11</a>
<span class="snippet"><span>GPT Summary</span>- å†…çœã¯ã€LLMsãŒãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«ä¾å­˜ã›ãšã«å†…éƒ¨çŠ¶æ…‹ã‹ã‚‰çŸ¥è­˜ã‚’ç²å¾—ã™ã‚‹èƒ½åŠ›ã‚’æŒ‡ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LLMsã‚’å¾®èª¿æ•´ã—ã€ä»®æƒ³ã‚·ãƒŠãƒªã‚ªã«ãŠã‘ã‚‹è‡ªèº«ã®è¡Œå‹•ã‚’äºˆæ¸¬ã•ã›ã‚‹ã“ã¨ã§å†…çœã‚’æ¤œè¨¼ã€‚å®Ÿé¨“ã®çµæœã€å†…çœå¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ï¼ˆM1ï¼‰ã¯ã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆM2ï¼‰ã‚ˆã‚Šã‚‚è‡ªèº«ã®è¡Œå‹•ã‚’æ­£ç¢ºã«äºˆæ¸¬ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ç‰¹ã«ã€M1ã¯è¡Œå‹•ã‚’æ„å›³çš„ã«å¤‰æ›´ã—ãŸå¾Œã§ã‚‚äºˆæ¸¬ç²¾åº¦ã‚’ç¶­æŒã—ãŸãŒã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã§ã¯å†…çœã‚’å¼•ãå‡ºã™ã“ã¨ãŒã§ããªã‹ã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/2b19bc9c-342d-42a9-b603-ff9cfc694570" alt="image" loading="lazy"></p>
<p>LLMãŒå˜ã«è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’æ¨¡å€£ã—ã¦ã„ã‚‹ã«ã™ããªã„çš„ãªä¸»å¼µã«å¯¾ã™ã‚‹ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã«ä½¿ãˆã‚‹ã‹ã‚‚</p></span><br><br>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2024-10-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer" class="title-link">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
<span class="snippet"><span>GPT Summary</span>- LoRAã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã§ã€ç‰¹ã«ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯è¨­å®šã§ã®æ€§èƒ½å‘ä¸Šã«æŒ‘æˆ¦ã™ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LoRAã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã¨ãƒªã‚½ãƒ¼ã‚¹ã§æ¤œè¨¼ã—ã€é©åˆ‡ãªãƒ©ãƒ³ã‚¯è¨­å®šã«ã‚ˆã‚Šé«˜ãƒªã‚½ãƒ¼ã‚¹ç’°å¢ƒã§ã‚‚ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«åŒ¹æ•µã™ã‚‹çµæœã‚’å¾—ã‚‰ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚å­¦ç¿’èƒ½åŠ›ã®åˆ¶ç´„ãŒLoRAã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’é«˜ã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€LoRAã®é©ç”¨å¯èƒ½æ€§ã‚’åºƒã’ã‚‹æ–¹å‘æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>LoRAã®ãƒ©ãƒ³ã‚¯æ•°ã‚’ã‚ã¡ã‚ƒã‚ã¡ã‚ƒå¤§ããã™ã‚‹ã¨ï¼ˆ1024ä»¥ä¸Šï¼‰ã€full-parameterã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã‚ˆã‚Šã‚‚ã€Unseenã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ãŒå‘ä¸Šã—ã¾ã™ã‚ˆã€ã¨ã„ã†è©±ã£ã½ã„<br><br><img src="https://github.com/user-attachments/assets/69120eee-2993-4e51-bbf4-52e3040bf66d" alt="image" loading="lazy"><br><br></p>
<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1474" target="_blank" rel="noopener noreferrer">Super-NaturalInstructions: Generalization via Declarative Instructions  on 1600+ NLP Tasks, Yizhong Wang+, N/A, EMNLP'22</a>
 ã‚‚å‚ç…§ã®ã“ã¨</p>
<p>## LoRA Finetuning details<br><br>- LoRA rankã‚’æœ€å¤§4096<br><br>- LoRAã®Î±ã‚’ãªã‚“ã¨rankã®2å€ã«ã—ã¦ã„ã‚‹<br><br>    - original paperã§ã¯16ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã‚‹<br><br>- learning_rate: 5e-5<br><br>- linear sheculeã§ learning_rate ã‚’æ¸›è¡°ã•ã›ã‚‹<br><br>- optimizerã¯AdamW<br><br>- batch_size: 128 <br><br>&lt;img width="444" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/516141a8-2955-49af-95e7-8f1b16e4122a"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/516141a8-2955-49af-95e7-8f1b16e4122a"&lt;/a&gt;


&gt;<br><br></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-10-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1472" target="_blank" rel="noopener noreferrer" class="title-link">KTO: Model Alignment as Prospect Theoretic Optimization, Kawin Ethayarajh+, N_A, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ­ã‚¹ãƒšã‚¯ãƒˆç†è«–ã«åŸºã¥ãã€LLMã®äººé–“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯èª¿æ•´ã«ãŠã‘ã‚‹ãƒã‚¤ã‚¢ã‚¹ã®å½±éŸ¿ã‚’ç¤ºã™ã€‚æ–°ãŸã«ææ¡ˆã™ã‚‹ã€Œäººé–“èªè­˜æå¤±ã€ï¼ˆHALOsï¼‰ã‚’ç”¨ã„ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒKTOã¯ã€ç”Ÿæˆç‰©ã®åŠ¹ç”¨ã‚’æœ€å¤§åŒ–ã—ã€å¥½ã¿ãƒ™ãƒ¼ã‚¹ã®æ–¹æ³•ã¨åŒç­‰ã¾ãŸã¯ãã‚Œä»¥ä¸Šã®æ€§èƒ½ã‚’ç™ºæ®ã€‚ç ”ç©¶ã¯ã€æœ€é©ãªæå¤±é–¢æ•°ãŒç‰¹å®šã®è¨­å®šã«ä¾å­˜ã™ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>binaryãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰LLMã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’ã¨ã‚‹Kahneman-Tversky Optimization (KTO)è«–æ–‡</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1468" target="_blank" rel="noopener noreferrer" class="title-link">Generative Reward Models, Dakota Mahan+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- RLHFã¨RLAIFã‚’çµ±åˆã—ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€åˆæˆå¥½ã¿ãƒ©ãƒ™ãƒ«ã®è³ªã‚’å‘ä¸Šã•ã›ã‚‹GenRMã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å°å…¥ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€GenRMã¯åˆ†å¸ƒå†…å¤–ã®ã‚¿ã‚¹ã‚¯ã§Bradley-Terryãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã¾ãŸã¯ãã‚Œã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€LLMã‚’åˆ¤æ–­è€…ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹å ´åˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚‚å‘ä¸Šã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=MwU2SGLKpS" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=MwU2SGLKpS</a>


</p>
<p>é–¢é€£ç ”ç©¶<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/708" target="_blank" rel="noopener noreferrer">LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and  Generative Fusion, Dongfu Jiang+, N/A, ACL'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1212" target="_blank" rel="noopener noreferrer">Self-Rewarding Language Models, Weizhe Yuan+, N/A, ICML'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2903" target="_blank" rel="noopener noreferrer">[Paper Note] Constitutional AI: Harmlessness from AI Feedback, Yuntao Bai+, arXiv'22</a>
</p>
<p>openreview:


<a href="https://openreview.net/forum?id=MwU2SGLKpS" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=MwU2SGLKpS</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2024-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1467" target="_blank" rel="noopener noreferrer" class="title-link">What Matters in Transformers? Not All Attention is Needed, Shwai He+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼å†…ã®Blocksã€MLPã€Attentionå±¤é–“ã®å†—é•·æ€§ã‚’èª¿æŸ»ã—ã€Attentionå±¤ã®é«˜ã„é¡ä¼¼æ€§ã«ã‚ˆã‚Šãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€Llama-2-70Bã§ã¯Attentionå±¤ã®åŠåˆ†ã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ã§48.4%ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’é”æˆã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ã‚ãšã‹2.4%ä½ä¸‹ã—ã¾ã—ãŸã€‚ã¾ãŸã€Attentionå±¤ã¨MLPå±¤ã‚’åŒæ™‚ã«å‰Šé™¤ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã€31å±¤å‰Šé™¤ã—ã¦ã‚‚Llama-2-13Bã¯90%ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¶­æŒã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ä»Šå¾Œã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆã«è²´é‡ãªæ´å¯Ÿã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>é€šå¸¸LLMã¯transformer decoderã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’stackã™ã‚‹ã“ã¨ã§å½¢æˆã•ã‚Œã‚‹ãŒã€ç©ã¿ä¸Šã’ãŸãƒ–ãƒ­ãƒƒã‚¯ã€ã‚ã‚‹ã„ã¯layerã£ã¦ã»ã‚“ã¨ã«å…¨éƒ¨å¿…è¦ãªã®?ã¨ã„ã†ç–‘å•ã«ç­”ãˆã¦ãã‚Œã‚‹è«–æ–‡ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><br>transformer blockãã®ã‚‚ã®ã€ã‚ã‚‹ã„ã¯MLP layerã‚’å‰Šé™¤ã™ã‚‹ã¨peformanceã¯å¤§å¹…ã«ä½ä¸‹ã™ã‚‹ãŒã€attention layerã‚’å‰Šé™¤ã—ã¦ã‚‚performanceã®ä½ä¸‹ãŒèµ·ããªã‹ã£ãŸæ¨¡æ§˜ã€‚ã“ã‚Œã«ã‚ˆã‚Šé«˜é€ŸåŒ–ãŒå®Ÿç¾å¯èƒ½ã€‚<br><br>å‰Šé™¤ã™ã‚‹ãƒ–ãƒ­ãƒƒã‚¯ã‚„layerã¯inputã¨outputã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãŒé«˜ã„ã‚‚ã®ã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦å®Ÿç¾ã€‚<br><br><img src="https://github.com/user-attachments/assets/da1e6a56-1bc4-4206-9423-acd7512300c8" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/724ddf50-cd63-437d-9df2-73423dd77a6e" alt="image" loading="lazy"><br><br>æ¯”è¼ƒçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå°ã•ã„7B, 13Bãƒ¢ãƒ‡ãƒ«ã§ã®å®Ÿé¨“çµæœ<br><img src="https://github.com/user-attachments/assets/19253c9e-7eae-4084-a8c2-e99680b34649" alt="image" loading="lazy"><br><br>ã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ«ã§ã®å®Ÿé¨“çµæœ<br><img src="https://github.com/user-attachments/assets/18eef07e-623c-482c-9a6b-9ea65450ecea" alt="image" loading="lazy"></p>
<p>ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤‰ã‚ã‚‰ãªã„ç¯„å›²ã ã¨ã€attention layer dropã«ã‚ˆã‚Šã€7B, 13Bãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯23%ç¨‹åº¦ã€70Bã®å ´åˆã¯35%ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå‘ä¸Š</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1464" target="_blank" rel="noopener noreferrer" class="title-link">Self-Taught Evaluators, Tianlu Wang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€äººé–“ã®æ³¨é‡ˆãªã—ã§è©•ä¾¡è€…ã‚’æ”¹å–„ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚åˆæˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã€è‡ªå·±æ”¹å–„ã‚¹ã‚­ãƒ¼ãƒ ã«ã‚ˆã‚ŠLLMã‚’è©•ä¾¡è€…ã¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€RewardBenchã§ã®LLMã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’75.4ã‹ã‚‰88.3ã«å‘ä¸Šã•ã›ã€GPT-4ã‚’è¶…ãˆã‚‹çµæœã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆç­‰ã‚’SFTã™ã‚‹éš›ã«ã€preferenceã®ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã«ãªã‚‹ãŒã€ã“ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹ã®ã¯ã‚³ã‚¹ãƒˆãŒã‹ã‹ã£ã¦å¤§å¤‰ãªã®ã§è‡ªå‹•ç”Ÿæˆã—ã¦ã€ã‚ˆã‚Šè‰¯ã„reward modelã‚’ä½œã‚ŠãŸã„ã‚ˆã­ã€ã¨ã„ã†è©±ã€‚<br>å…·ä½“çš„ã«ã¯ã€LLMã‚’ç”¨ã„ã¦ good responseã¨ã€instructionã‚’å¤‰åŒ–ã•ã›ã¦bad sesponseã‚’ç”Ÿæˆã—ã€Judgeãƒ¢ãƒ‡ãƒ«M_tã«pairwiseã§ã©ã¡ã‚‰ãŒè‰¯ã„ã‹ã‚’judgeã•ã›ã‚‹ã“ã¨ã§å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã€‚æ–°ãŸã«ä½œæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦Judgeãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ã—ã€åŒæ§˜ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç¹°ã‚Šè¿”ã™ã“ã¨ã§ã€äººæ‰‹ã®ä»‹åœ¨ãªãå¼·åŠ›ãªJudgeãƒ¢ãƒ‡ãƒ«ãŒå®Œæˆã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/837c4567-6993-4e4c-81c8-650b7777c49b" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/10a4fb62-160d-4bcf-b3a2-a960a7c9bc46" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1463" target="_blank" rel="noopener noreferrer" class="title-link">Retrieval Augmented Generation ï¼ˆRAGï¼‰ and Beyond: A Comprehensive Survey  on How to Make your LLMs use External Data More Wisely, Siyun Zhao+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§å®Ÿä¸–ç•Œã®ã‚¿ã‚¹ã‚¯ã‚’é‚è¡Œã™ã‚‹èƒ½åŠ›ã‚’ç¤ºã™ãŒã€ãƒ‡ãƒ¼ã‚¿å¼·åŒ–å‹LLMsã®åŠ¹æœçš„ãªå±•é–‹ã«ã¯å¤šãã®èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã‚Œã«ã¯ã€é–¢é€£ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã‚„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã®è§£é‡ˆã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ¨è«–èƒ½åŠ›ã®æ´»ç”¨ãŒå«ã¾ã‚Œã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€RAGã‚¿ã‚¹ã‚¯ã‚’å››ã¤ã®ã‚¯ã‚¨ãƒªãƒ¬ãƒ™ãƒ«ã«åˆ†é¡ã—ã€é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„èª²é¡Œã€æŠ€è¡“ã‚’è¦ç´„ã™ã‚‹ã€‚ã¾ãŸã€å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿çµ±åˆã®ä¸‰ã¤ã®å½¢å¼ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€å°å‹ãƒ¢ãƒ‡ãƒ«ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã€ãã‚Œãã‚Œã®å¼·ã¿ã¨é™ç•Œã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‡ãƒ¼ã‚¿è¦ä»¶ã¨LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹ç¯‰ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç†è§£ã—ã€ä½“ç³»çš„ãªé–‹ç™ºã®ãŸã‚ã®ã‚¬ã‚¤ãƒ‰ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>RAGã®ã‚¯ã‚¨ãƒªã‚’4ç¨®é¡ã«åˆ†é¡ã—ãŸå„ã‚¯ã‚¨ãƒªã”ã¨ã®æŠ€è¡“ã‚’ã¾ã¨ã‚ãŸSurvey<br><img src="https://github.com/user-attachments/assets/b551725d-5f82-4914-8b8f-716ddb6a342b" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2024-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1459" target="_blank" rel="noopener noreferrer" class="title-link">Addition is All You Need for Energy-efficient Language Models, Hongyin Luo+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æµ®å‹•å°æ•°ç‚¹ä¹—ç®—ã‚’é«˜ç²¾åº¦ã§æ•´æ•°åŠ ç®—å™¨ã«ã‚ˆã£ã¦è¿‘ä¼¼ã™ã‚‹L-Mulã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€8ãƒ“ãƒƒãƒˆæµ®å‹•å°æ•°ç‚¹ä¹—ç®—ã«æ¯”ã¹ã¦è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’å¤§å¹…ã«å‰Šæ¸›ã—ã¤ã¤ã€ã‚ˆã‚Šé«˜ã„ç²¾åº¦ã‚’å®Ÿç¾ã€‚L-Mulã‚’ãƒ†ãƒ³ã‚½ãƒ«å‡¦ç†ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã«é©ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚³ã‚¹ãƒˆã‚’95ï¼…ï¼ˆè¦ç´ ã”ã¨ã®ä¹—ç®—ï¼‰ãŠã‚ˆã³80ï¼…ï¼ˆãƒ‰ãƒƒãƒˆç©ï¼‰å‰Šæ¸›å¯èƒ½ã€‚å®Ÿé¨“çµæœã¯ç†è«–çš„èª¤å·®æ¨å®šã¨ä¸€è‡´ã—ã€L-Mulã¯å¾“æ¥ã®æµ®å‹•å°æ•°ç‚¹ä¹—ç®—ã¨åŒç­‰ã¾ãŸã¯ãã‚Œä»¥ä¸Šã®ç²¾åº¦ã‚’é”æˆã€‚ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«å†…ã®æµ®å‹•å°æ•°ç‚¹ä¹—ç®—ã‚’L-Mulã«ç½®ãæ›ãˆã‚‹ã“ã¨ã§ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã«ãŠã„ã¦é«˜ã„ç²¾åº¦ã‚’ç¶­æŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2024-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1458" target="_blank" rel="noopener noreferrer" class="title-link">ToolGen: Unified Tool Retrieval and Calling via Generation, Renxi Wang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ToolGenã¯ã€å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã¨ã®ç›´æ¥å¯¾è©±ã‚’å¯èƒ½ã«ã™ã‚‹æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€å„ãƒ„ãƒ¼ãƒ«ã‚’ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦è¡¨ç¾ã—ã€LLMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«çµ±åˆã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMã¯ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚„å¼•æ•°ã‚’è‡ªç„¶è¨€èªç”Ÿæˆã®ä¸€éƒ¨ã¨ã—ã¦ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«ç”Ÿæˆã§ãã€æƒ…å ±å–å¾—ã‚¹ãƒ†ãƒƒãƒ—ãªã—ã§å¤šãã®ãƒ„ãƒ¼ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã«ãªã‚Šã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ToolGenãŒè‡ªå¾‹çš„ãªã‚¿ã‚¹ã‚¯å®Œäº†ã¨æƒ…å ±å–å¾—ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€ã‚ˆã‚ŠåŠ¹ç‡çš„ã§è‡ªå¾‹çš„ãªAIã‚·ã‚¹ãƒ†ãƒ ã®åŸºç›¤ã‚’ç¯‰ãã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ˜”ã‹ã‚‰ã‚ˆãã‚ã‚‹ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’åŸ‹ã‚è¾¼ã‚“ã§ã€ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã—ãŸã‚‰ãã‚Œã«å¿œã˜ãŸå‡¦ç†ã‚’ã™ã‚‹ç³»ã®ç ”ç©¶ã€‚ä»Šå›ã¯ãƒ„ãƒ¼ãƒ«ã«å¯¾å¿œã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä»•è¾¼ã‚€æ¨¡æ§˜ã€‚</p>
<p>æ–œã‚èª­ã¿ã ãŒã€3ã¤ã®stepã§Foundation Modelã‚’è¨“ç·´ã™ã‚‹ã€‚ã¾ãšã¯ãƒ„ãƒ¼ãƒ«ã®descriptionã‹ã‚‰ãƒ„ãƒ¼ãƒ«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã«ãƒ„ãƒ¼ãƒ«ã®æƒ…å ±ã‚’è¦šãˆã•ã›ã‚‹ï¼ˆmemorizationï¼‰ã€‚æ–œã‚èª­ã¿ãªã®ã§èª­ã‚ã¦ã„ãªã„ãŒã€ãƒ„ãƒ¼ãƒ«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’vocabã«è¿½åŠ ã—ã¦ã‚‹ã®ã§ã“ã“ã¯ç¶™ç¶šçš„äº‹å‰å­¦ç¿’ã‚’ã—ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚ç¶šã„ã¦ã€ï¼ˆãŠãã‚‰ãï¼‰äººæ‰‹ã§ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸã‚¯ã‚¨ãƒª-å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã®ãƒšã‚¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’å­¦ç¿’ã•ã›ã‚‹ã€‚æœ€å¾Œã«ã€ï¼ˆãŠãã‚‰ãäººæ‰‹ã§ä½œæˆã•ã‚ŒãŸï¼‰ã‚¯ã‚¨ãƒª-ã‚¿ã‚¹ã‚¯ã‚’è§£ããŸã‚ã®trajectoryãƒšã‚¢ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã•ã›ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/eebe4260-2e4f-4be7-9b59-a0b84913e667" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/d03ed971-e5c9-49f3-8385-cfb00505907c" alt="image" loading="lazy"></p>
<p>å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«ã€‚Appendixä¸­ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã ãŒã€æœ¬æ–‡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç¯€ã¨Appendixã®åŒæ–¹ã«ã€ãƒ‡ãƒ¼ã‚¿ã®ä½œã‚Šæ–¹ã®è©³ç´°ã¯è¨˜è¿°ã•ã‚Œã¦ã„ãªã‹ã£ãŸã€‚ã©ã“ã‹ã«æ›¸ã„ã¦ã‚ã‚‹ã®ã ã‚ã†ã‹ã€‚<br><img src="https://github.com/user-attachments/assets/41975d34-dc9d-405d-aaca-062a3ee1a4b0" alt="image" loading="lazy"></p>
<p>æœ€çµ‚çš„ãªæ€§èƒ½<br><img src="https://github.com/user-attachments/assets/a247cc99-10eb-4346-9f0d-b406a022c3b4" alt="image" loading="lazy"></p>
<p>ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ ã®vocabã¨ã—ã¦ç™»éŒ²ã—ã€ãã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ã€vocabã«å¿œã˜ã¦ä½•ã‚‰ã‹ã®æ“ä½œã‚’å®Ÿè¡Œã™ã‚‹ã¨ã„ã†æ çµ„ã¿ã€ãã®å­¦ç¿’æ‰‹æ³•ã¯è‰²ã€…ãªã‚¿ã‚¹ã‚¯ã§å½¹ç«‹ã¡ãã†ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1434" target="_blank" rel="noopener noreferrer" class="title-link">What matters when building vision-language models?, Hugo LaurenÃ§on+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- è¦–è¦šã¨è¨€èªã®ãƒ¢ãƒ‡ãƒ«ï¼ˆVLMï¼‰ã®è¨­è¨ˆã«ãŠã‘ã‚‹è£ä»˜ã‘ã®ãªã„æ±ºå®šãŒæ€§èƒ½å‘ä¸Šã®ç‰¹å®šã‚’å¦¨ã’ã¦ã„ã‚‹ã¨æŒ‡æ‘˜ã€‚äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒ‡ãƒ¼ã‚¿ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã«é–¢ã™ã‚‹å®Ÿé¨“ã‚’è¡Œã„ã€80å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åŸºç›¤VLMã€ŒIdefics2ã€ã‚’é–‹ç™ºã€‚Idefics2ã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã—ã€4å€ã®ã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆã«OpenVLMã®é€²å±•ã®æ­´å²ãŒè¼‰ã£ã¦ã„ã‚‹ã€‚æ§‹ç¯‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚å…¬é–‹ã•ã‚Œã‚‹æ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/9675c2ad-650a-460b-9655-1c6347d07f58" alt="image" loading="lazy"><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thom_wolf/status/1840372428855280045?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2024-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1429" target="_blank" rel="noopener noreferrer" class="title-link">Logic-of-Thought: Injecting Logic into Contexts for Full Reasoning in  Large Language Models, Tongxuan Liu+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Logic-of-Thoughtï¼ˆLoTï¼‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã‚’ææ¡ˆã—ã€å‘½é¡Œè«–ç†ã‚’ç”¨ã„ã¦å…¥åŠ›ã‹ã‚‰æ‹¡å¼µã•ã‚ŒãŸè«–ç†æƒ…å ±ã‚’ç”Ÿæˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã®è«–ç†æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã€æ—¢å­˜ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã¨çµ±åˆå¯èƒ½ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€LoTãŒ5ã¤ã®è«–ç†æ¨è«–ã‚¿ã‚¹ã‚¯ã§é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ã€ç‰¹ã«ReClorã§+4.35%ã€LogiQAã§+5%ã€ProofWriterã§+8%ã®æ”¹å–„ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>SNSã§è©±é¡Œã«ãªã£ã¦ã„ã‚‹ã‚ˆã†ã ãŒGPT-3.5-Turboã¨GPT-4ã§ã—ã‹æ¯”è¼ƒã—ã¦ã„ãªã„ä¸Šã«ã€ã„ã¤ã®æ™‚ç‚¹ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‚è¨˜è¿°ã•ã‚Œã¦ã„ãªã„ã®ã§ã€unreliableã«è¦‹ãˆã‚‹<br><br><img src="https://github.com/user-attachments/assets/9ca6fc62-2691-40c8-a578-554c0083df8f" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<span class="issue_date">Issue Date: 2024-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1427" target="_blank" rel="noopener noreferrer" class="title-link">Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal  Sampling, Hritik Bansal+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- é«˜å“è³ªãªåˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã€å¼·åŠ›ãªSEãƒ¢ãƒ‡ãƒ«ã¨å®‰ä¾¡ãªWCãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å†æ¤œè¨ã€‚WCãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã¯ã‚«ãƒãƒ¬ãƒƒã‚¸ã¨å¤šæ§˜æ€§ãŒé«˜ã„ãŒå½é™½æ€§ç‡ã‚‚é«˜ã„ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®çµæœã€WCç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒSEç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€WCãŒè¨ˆç®—æœ€é©ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rohanpaul_ai/status/1840172683528425718?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2024-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1423" target="_blank" rel="noopener noreferrer" class="title-link">When Scaling Meets LLM Finetuning: The Effect of Data, Model and  Finetuning Method, Biao Zhang+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ç‰¹æ€§ã‚’èª¿æŸ»ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚„ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒæ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’å®Ÿé¨“ã€‚çµæœã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ãƒ‘ãƒ¯ãƒ¼ãƒ™ãƒ¼ã‚¹ã®å…±åŒã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã«å¾“ã„ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒäº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚ˆã‚Šã‚‚åŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜ã€‚æœ€é©ãªæ‰‹æ³•ã¯ã‚¿ã‚¹ã‚¯ã‚„ãƒ‡ãƒ¼ã‚¿ã«ä¾å­˜ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>&gt; When only few thousands of finetuning examples are available, PET should be considered first, either Prompt or LoRA. With sightly larger datasets, LoRA would be preferred due to its stability and slightly better finetuning data scalability. For million-scale datasets, FMT would be good.<br><br><br><br>&gt; While specializing on a downstream task, finetuning could still elicit<br><br>and improve the generalization for closely related tasks, although the overall zero-shot translation<br><br>quality is inferior. Note whether finetuning benefits generalization is method- and task-dependent.<br><br>Overall, Prompt and LoRA achieve relatively better results than FMT particularly when the base<br><br>LLM is large, mostly because LLM parameters are frozen and the learned knowledge get inherited.<br><br>This also suggests that when generalization capability is a big concern, PET should be considered.</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1408" target="_blank" rel="noopener noreferrer" class="title-link">Backtracking Improves Generation Safety, Yiming Zhang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ãŠã‘ã‚‹å®‰å…¨æ€§ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ãƒãƒƒã‚¯ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã€‚ç‰¹åˆ¥ãª[RESET]ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”¨ã„ã¦ç”Ÿæˆã•ã‚ŒãŸä¸é©åˆ‡ãªãƒ†ã‚­ã‚¹ãƒˆã‚’ã€Œå–ã‚Šæ¶ˆã—ã€ã€ãƒ¢ãƒ‡ãƒ«ã®å®‰å…¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ãƒãƒƒã‚¯ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’å°å…¥ã—ãŸLlama-3-8Bã¯ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦4å€ã®å®‰å…¨æ€§ã‚’ç¤ºã—ã€æœ‰ç”¨æ€§ã®ä½ä¸‹ã¯è¦‹ã‚‰ã‚Œãªã‹ã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1838415378529112330?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2024-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1406" target="_blank" rel="noopener noreferrer" class="title-link">To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic  reasoning, Zayne Sprague+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Chain-of-thoughtï¼ˆCoTï¼‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã¯LLMsã®æ¨è«–èƒ½åŠ›ã‚’å¼•ãå‡ºã™æ‰‹æ³•ã§ã‚ã‚Šã€100ä»¥ä¸Šã®è«–æ–‡ã‚’å¯¾è±¡ã«ã—ãŸãƒ¡ã‚¿åˆ†æã«ã‚ˆã‚Šã€ä¸»ã«æ•°å­¦ã‚„è«–ç†ã‚¿ã‚¹ã‚¯ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸ŠãŒç¢ºèªã•ã‚ŒãŸã€‚ä¸€æ–¹ã€ä»–ã®ã‚¿ã‚¹ã‚¯ã§ã¯åŠ¹æœãŒé™å®šçš„ã§ã€MMLUã§ã¯ç›´æ¥å›ç­”ç”ŸæˆãŒCoTã¨åŒç­‰ã®ç²¾åº¦ã‚’ç¤ºã—ãŸã€‚è¨ˆç”»ã¨å®Ÿè¡Œã‚’åˆ†é›¢ã—ã€ãƒ„ãƒ¼ãƒ«å¼·åŒ–LLMsã¨æ¯”è¼ƒã—ãŸçµæœã€CoTã®åˆ©ç‚¹ã¯è¨˜å·çš„å®Ÿè¡Œã®æ”¹å–„ã«èµ·å› ã—ã€è¨˜å·ã‚½ãƒ«ãƒãƒ¼ã«ã¯åŠ£ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚CoTã®é¸æŠçš„é©ç”¨ã«ã‚ˆã‚Šã€æ¨è«–ã‚³ã‚¹ãƒˆã‚’ç¯€ç´„ã—ã¤ã¤ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¶­æŒã§ãã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã€LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã§ã®ä¸­é–“è¨ˆç®—ã®æ´»ç”¨ãŒæ±‚ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>CoTã‚’100å€‹ä»¥ä¸Šã®å…ˆè¡Œç ”ç©¶ã§meta-analysisã—ï¼ˆi.e. CoTã‚’è¿½åŠ ã—ãŸå ´åˆã®gainã¨ã‚¿ã‚¹ã‚¯ã®ãƒ—ãƒ­ãƒƒãƒˆï¼‰ã€20å€‹è¶…ãˆã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è‘—è€…ã‚‰ãŒå®Ÿé¨“ã—ãŸçµæœã€mathã¯symbolic reasoningï¼ˆ12*4ã®ã‚ˆã†ã«ã€ã‚·ãƒ³ãƒœãƒ«ã‚’èªè­˜ã—ã€ä½•ã‚‰ã‹ã®æ“ä½œã‚’ã—ã¦å›ç­”ã‚’ã™ã‚‹å•é¡Œï¼‰ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§ã€CoTã¯å¤§ããªgainãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸï¼ˆä»–ã¯ã»ã¨ã‚“ã©gainãŒãªã„ï¼‰ã€‚<br><img src="https://github.com/user-attachments/assets/a399306f-bda9-45c9-a756-2a83a9727e63" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/CrossLingual.html" target="_blank" rel="noopener noreferrer">#CrossLingual</a>
<span class="issue_date">Issue Date: 2024-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1400" target="_blank" rel="noopener noreferrer" class="title-link">PLUG: Leveraging Pivot Language in Cross-Lingual Instruction Tuning, Zhihan Zhang+, N_A, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯LLMsã®æŒ‡ç¤ºç†è§£ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ä½ãƒªã‚½ãƒ¼ã‚¹è¨€èªã§ã¯èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€è‹±èªã‚’ãƒ”ãƒœãƒƒãƒˆè¨€èªã¨ã™ã‚‹PLUGã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ãƒ¢ãƒ‡ãƒ«ã¯ã¾ãšè‹±èªã§æŒ‡ç¤ºã‚’å‡¦ç†ã—ã€æ¬¡ã«ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨€èªã§å¿œç­”ã‚’ç”Ÿæˆã€‚4ã¤ã®è¨€èªã§ã®è©•ä¾¡ã«ã‚ˆã‚Šã€æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ãŒå¹³å‡29%å‘ä¸Šã—ãŸã€‚ã•ã‚‰ã«ã€ä»–ã®ãƒ”ãƒœãƒƒãƒˆè¨€èªã‚’ç”¨ã„ãŸå®Ÿé¨“ã‚‚è¡Œã„ã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å¤šæ§˜æ€§ã‚’ç¢ºèªã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>
<strong># æ¦‚è¦<br><br>cross-lingualã§instruction tuningã‚’ã™ã‚‹æ‰‹æ³•ã€‚targetè¨€èªã®InstructionãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€Pivotã¨ãªã‚‹è¨€èªã§Instructionã¨Responseã‚’ç”Ÿæˆã—ãŸå¾Œã€targetã¨ãªã‚‹è¨€èªã«ç¿»è¨³ã™ã‚‹ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ï¼ˆãã‚Œãã‚Œã‚’separatorã‚’ç”¨ã„ã¦concatã™ã‚‹ï¼‰ã§Instruction Tuningã™ã‚‹ã“ã¨ã§targetè¨€èªã§ã®æ€§èƒ½ãŒå‘ä¸Š<br><br><br><br><img src="https://github.com/user-attachments/assets/1a409df0-b8bf-45fd-8fc1-316519723820" alt="image" loading="lazy"><br><br><br><br># è©•ä¾¡<br><br>ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®Open-end Generationã‚¿ã‚¹ã‚¯ã§Instruction Tuningã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒè©•ä¾¡ã•ã‚Œã‚‹ãŒã€æ—¢å­˜ã®ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ã®è©•ä¾¡ã‚»ãƒƒãƒˆã¯ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°ã•ãã€æ©Ÿæ¢°ç¿»è¨³ãƒ™ãƒ¼ã‚¹ã®ã‚‚ã®ã¯ãƒã‚¤ã‚¸ãƒ¼ã¨ã„ã†èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã®ãŸã‚ã€è‘—è€…ã‚‰ã¯è©•ä¾¡ã™ã‚‹4è¨€èªï¼ˆlow-resource languageï¼‰ã®ãƒ—ãƒ­ã®ç¿»è¨³å®¶ã‚’é›‡ç”¨ã—ã€AlpacaEvalã‚’ç¿»è¨³ã—ã€4è¨€èªï¼ˆChinese, Korean, Italian, Spanishï¼‰ã®instructionãŒå­˜åœ¨ã™ã‚‹ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ X-AlpacaEvalã‚’ä½œæˆã—è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ç”¨ã„ã‚‹ã€‚<br><br><br>åˆ©ç”¨ã™ã‚‹Foundationãƒ¢ãƒ‡ãƒ«ã¯ä»¥ä¸‹ã®3ç¨®é¡ã§ã€<br><br>- LLaMA-2-13B (è‹±èªã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«)<br><br>- PolyLM-13B (ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãªãƒ¢ãƒ‡ãƒ«)<br><br>- PolyLM-Instruct-Instruct (PolyLM-13Bã‚’instruction tuningã—ãŸã‚‚ã®)<br><br><br>ã“ã‚Œã‚‰ã«å¯¾ã—ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦GPT4-Alpaca <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1401" target="_blank" rel="noopener noreferrer">Instruction Tuning with GPT-4, Baolin Peng+, N/A, arXiv'23</a>
</strong>
<br>
 instruction-tuning dataset (52kã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨) ã‚’åˆ©ç”¨ã™ã‚‹ã€‚GPT4-Alpacaã‚’ChatGPTã«ã‚ˆã£ã¦4è¨€èªã«ç¿»è¨³ã—ã€å„è¨€èªã«å¯¾ã™ã‚‹instruction tuning datasetã‚’å¾—ãŸã€‚<br><br><br><br>æ¯”è¼ƒæ‰‹æ³•ã¨ã—ã¦ä»¥ä¸‹ã®5ç¨®é¡ã¨æ¯”è¼ƒã—ã¦ã„ã‚‹ã€‚ã“ã“ã§ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨€èªã¯ä»Šå›4ç¨®é¡ã§ã€ãã‚Œãã‚Œã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨€èªã”ã¨ã«ç‹¬ç«‹ã«ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã¦ã„ã‚‹ã€‚<br><br>- Pivot-only training: pivotè¨€èªï¼ˆä»Šå›ã¯è‹±èªï¼‰ã®ã¿ã§å­¦ç¿’ã—ãŸå ´åˆ <br><br>- Monolingual response training: pivotè¨€èªã¨targetè¨€èªã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã—ãŸå ´åˆ<br><br>- Code Switching: Monolingual response trainingã«åŠ ãˆã¦ã€pivotè¨€èªã¨targetè¨€èªã®input/outputã‚’ãã‚Œãã‚Œå…¥ã‚Œæ›¿ãˆãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ãŸå ´åˆï¼ˆi.e. pivotè¨€èª input-targetè¨€èª output, targetè¨€èª input-pivotè¨€èª outputã®ãƒšã‚¢ã‚’ä½œæˆã—å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«åˆ©ç”¨ã—ã¦ã„ã‚‹ï¼‰<br><br>- Auxiliary translation tasks: Monolingual respones trainingã«åŠ ãˆã¦ã€ç¿»è¨³ã‚¿ã‚¹ã‚¯ã‚’å®šç¾©ã—å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦åŠ ãˆãŸå ´åˆã€‚ã™ãªã‚ã¡ã€input, outputãã‚Œãã‚Œã«å¯¾ã—ã¦ã€pivotè¨€èªã‹ã‚‰targetè¨€èªã¸ã®ç¿»è¨³ã®ã‚µãƒ³ãƒ—ãƒ« ([P_trans;x^p], x^tï¼‰ã¨ï¼ˆ[P_trans;y^p], y^tï¼‰ã‚’åŠ ãˆã¦å­¦ç¿’ã—ã¦ã„ã‚‹ã€‚ã“ã“ã§ã€P_transã¯ç¿»è¨³ã‚’æŒ‡ç¤ºã™ã‚‹promptã§ã€;ã¯æ–‡å­—åˆ—ã®concatnationã€‚x^p, y^p, x^t, y^tã¯ãã‚Œãã‚Œã€pivotè¨€èªã®input, outputã€targetè¨€èªã®input, outputã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ã™ã€‚<br><br>- PLUGï¼ˆææ¡ˆæ‰‹æ³•ï¼‰: Pivot-only Trainingã«åŠ ãˆã¦ã€targetè¨€èªã®inputã‹ã‚‰ã€pivotè¨€èªã®input/output -&gt; targetè¨€èªã®outputã‚’concatã—ãŸãƒ†ã‚­ã‚¹ãƒˆ(x^t, [x^p;y^p;y^t]) ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«åŠ ãˆãŸå ´åˆ<br><br><br><br>è©•ä¾¡ã™ã‚‹éš›ã¯ã€MT-Bench <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/903" target="_blank" rel="noopener noreferrer">Judging LLM-as-a-judge with MT-Bench and Chatbot Arena, Lianmin Zheng+, N/A, NeurIPS'23</a>
 ã®ã‚ˆã†ã«ã€GPT4ã‚’ç”¨ã„ãŸã€direct pair-wise comparisonã‚’è¡Œã£ã¦ã„ã‚‹ã€‚<br><br>direct pair-wise comparisonã¯ã€2ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ä¸ãˆã¦LLMã«ä½•ã‚‰ã‹ã®åˆ¤æ–­ã‚„ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’ã•ã›ã‚‹æ–¹æ³•ã§ã‚ã‚Šã€ä»Šå›ã¯ã©ã¡ã‚‰ãŒinstructionã«ã‚ˆã‚Šå¾“ã£ã¦ã„ã‚‹ã‹ã«å‹æ•—/å¼•ãåˆ†ã‘ã‚’GPT4ã«åˆ¤æ–­ã•ã›ã¦ã„ã‚‹ã€‚LLMã«ã‚ˆã‚‹ç”Ÿæˆã¯ã‚µãƒ³ãƒ—ãƒ«ã®é †ç•ªã«sensitiveãªã®ã§ã€é †ç•ªã‚’é€†ã«ã—ãŸå ´åˆã§ã‚‚å®Ÿé¨“ã‚’ã—ã¦ã€win-lose rateã‚’æ±‚ã‚ã¦ã„ã‚‹ã€‚1ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ãƒšã‚¢ã«å¯¾ã—ã¦ã€ã‚µãƒ³ãƒ—ãƒ«ã®é †ç•ªã‚’æ­£é †ã¨é€†é †ã®2å›è©•ä¾¡ã•ã›ã€ãã®åŒæ–¹ã®çµæœã‚’ç”¨ã„ã¦æœ€çµ‚çš„ãªwin/lose/tieã‚’æ±ºã‚ã¦ã„ã‚‹ã€‚ç«¯çš„ã«è¨€ã†ã¨ã€å‹æ•—ãŒ2-0ãªã‚‰ãã®ã‚µãƒ³ãƒ—ãƒ«ã®å‹ã¡ã€åŒæ§˜ã«1-1ãªã‚‰å¼•ãåˆ†ã‘ã€0-2ãªã‚‰è² ã‘ã€ã¨ã„ã†ã“ã¨ã§ã‚ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/726ea2dc-8f62-4320-8489-45cc20ed32ae" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<span class="issue_date">Issue Date: 2024-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1398" target="_blank" rel="noopener noreferrer" class="title-link">When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of  Self-Correction of LLMs, Ryo Kamoi+, N_A, TACL'24</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±ä¿®æ­£ã¯LLMsã®å¿œç­”ã‚’æ”¹å–„ã™ã‚‹æ‰‹æ³•ã§ã‚ã‚Šã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æºã®åˆ©ç”¨ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ãŒã€èª¤ã‚Šä¿®æ­£ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«ã¤ã„ã¦ã¯åˆæ„ãŒå¾—ã‚‰ã‚Œã¦ã„ãªã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€è‡ªå·±ä¿®æ­£ã«å¿…è¦ãªæ¡ä»¶ã‚’è­°è«–ã—ã€å¾“æ¥ã®ç ”ç©¶ã®å•é¡Œç‚¹ã‚’æŒ‡æ‘˜ã€‚æ–°ãŸã«åˆ†é¡ã—ãŸç ”ç©¶èª²é¡Œã«åŸºã¥ãã€è‡ªå·±ä¿®æ­£ãŒæˆåŠŸã—ãŸä¾‹ãŒãªã„ã“ã¨ã€ä¿¡é ¼ã§ãã‚‹å¤–éƒ¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ã€å¤§è¦æ¨¡ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒåŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®self-correctionã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ™ã‚¤</p>
<p><img src="https://github.com/user-attachments/assets/bea63e03-8b6f-4c3e-b8ff-d738c062149c" alt="image" loading="lazy"></p>
<p><img src="https://github.com/user-attachments/assets/5701c2b8-bab1-4da4-af89-fa116f8848d0" alt="image" loading="lazy"></p>
<p><img src="https://github.com/user-attachments/assets/c3095388-52a5-40d6-ad18-235fd6a831f9" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/SyntheticDataGeneration.html" target="_blank" rel="noopener noreferrer">#SyntheticDataGeneration</a>
<span class="issue_date">Issue Date: 2024-09-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1393" target="_blank" rel="noopener noreferrer" class="title-link">Source2Synth: Synthetic Data Generation and Curation Grounded in Real  Data Sources, Alisia Lupidi+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ–°æ‰‹æ³•ã€ŒSource2Synthã€ã‚’ææ¡ˆã—ã€LLMã«æ–°ã—ã„ã‚¹ã‚­ãƒ«ã‚’æ•™ãˆã‚‹ã€‚äººé–“ã®æ³¨é‡ˆã«ä¾å­˜ã›ãšã€å®Ÿä¸–ç•Œã®ã‚½ãƒ¼ã‚¹ã«åŸºã¥ã„ãŸåˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€ä½å“è³ªãªç”Ÿæˆç‰©ã‚’å»ƒæ£„ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è³ªã‚’å‘ä¸Šã€‚ãƒãƒ«ãƒãƒ›ãƒƒãƒ—è³ªå•å¿œç­”ã¨è¡¨å½¢å¼ã®è³ªå•å¿œç­”ã«é©ç”¨ã—ã€WikiSQLã§25.51%ã€HotPotQAã§22.57%ã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã«é–¢ã™ã‚‹ç ”ç©¶ã€‚<br>ã‚½ãƒ¼ã‚¹ã‹ã‚‰QAã‚’ç”Ÿæˆã—ã€2ã¤ã®sliceã«åˆ†ã‘ã‚‹ã€‚ç‰‡æ–¹ã‚’LLMã®finetuningï¼ˆLLMSynthï¼‰ã«åˆ©ç”¨ã—ã€ã‚‚ã†ç‰‡æ–¹ã‚’finetuningã—ãŸLLMã§è§£ç­”å¯èƒ½æ€§ã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆcurationï¼‰ã™ã‚‹ã€‚<br>æœ€çµ‚çš„ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ç”Ÿæˆã•ã‚ŒãŸé«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã§LLMã‚’finetuningã™ã‚‹ã€‚<br><br>Curationã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã§finetuningã—ãŸãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¯ã€Curationã—ã¦ã„ãªã„ãŸã ã®åˆæˆãƒ‡ãƒ¼ã‚¿ã¨æ¯”ã¹ã¦ã€MultiHopQA, TableQAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/4aabfa32-6461-447f-b11d-a0875603fd08" alt="image" loading="lazy"><br><br>ç”»åƒã¯å…ƒãƒã‚¹ãƒˆã‚ˆã‚Šå¼•ç”¨<br><br>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1834402693995024453?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MultiHopQAã®åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆæ–¹æ³•<br><img src="https://github.com/user-attachments/assets/853935be-1515-4064-bd08-3c0fe6a948a5" alt="image" loading="lazy"><br><br>TableQAã®åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆæ–¹æ³•<br><img src="https://github.com/user-attachments/assets/8f85bdf7-2de0-451a-a013-55cf0bcc167c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2024-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1391" target="_blank" rel="noopener noreferrer" class="title-link">ReFT: Reasoning with Reinforced Fine-Tuning, Trung Quoc Luong+, N_A, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆReFTï¼‰ã‚’ææ¡ˆã—ã€LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã€‚SFTã§ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¾Œã€PPOã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ã¦ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ã‚’è¡Œã„ã€è±Šå¯Œãªæ¨è«–ãƒ‘ã‚¹ã‚’è‡ªå‹•ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€‚GSM8Kã€MathQAã€SVAMPãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§SFTã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€è¿½åŠ ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è³ªå•ã«ä¾å­˜ã›ãšå„ªã‚ŒãŸä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’ç™ºæ®ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1386" target="_blank" rel="noopener noreferrer" class="title-link">From Decoding to Meta-Generation: Inference-time Algorithms for Large  Language Models, Sean Welleck+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ¨è«–æ™‚ã®è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹æ‹¡å¤§ã®åˆ©ç‚¹ã«ç„¦ç‚¹ã‚’å½“ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ç”Ÿæˆã€ãƒ¡ã‚¿ç”Ÿæˆã€åŠ¹ç‡çš„ç”Ÿæˆã®3ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’çµ±ä¸€çš„ã«æ¢æ±‚ã€‚ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ç”Ÿæˆã¯ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ã€ãƒ¡ã‚¿ç”Ÿæˆã¯ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚„å¤–éƒ¨æƒ…å ±ã‚’æ´»ç”¨ã—ã€åŠ¹ç‡çš„ç”Ÿæˆã¯ã‚³ã‚¹ãƒˆå‰Šæ¸›ã¨é€Ÿåº¦å‘ä¸Šã‚’ç›®æŒ‡ã™ã€‚å¾“æ¥ã®è‡ªç„¶è¨€èªå‡¦ç†ã€ç¾ä»£ã®LLMsã€æ©Ÿæ¢°å­¦ç¿’ã®è¦–ç‚¹ã‚’çµ±åˆã—ãŸèª¿æŸ»ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1833522477605261799?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>CMUã®ãƒãƒ¼ãƒ ã«ã‚ˆã‚‹inference timeã®é«˜é€ŸåŒ–ã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ™ã‚¤</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<span class="issue_date">Issue Date: 2024-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1385" target="_blank" rel="noopener noreferrer" class="title-link">Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with  100+ NLP Researchers, Chenglei Si+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMã¨NLPå°‚é–€å®¶ã«ã‚ˆã‚‹ç ”ç©¶ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆã®æ¯”è¼ƒã‚’è¡Œã„ã€LLMãŒç”Ÿæˆã—ãŸã‚¢ã‚¤ãƒ‡ã‚¢ã®æ–°è¦æ€§ãŒäººé–“ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚ˆã‚Šé«˜ã„ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸãŒã€å®Ÿç¾å¯èƒ½æ€§ã¯ã‚„ã‚„åŠ£ã‚‹ã¨è©•ä¾¡ã•ã‚Œã¾ã—ãŸã€‚ã¾ãŸã€LLMã®è‡ªå·±è©•ä¾¡ã‚„ç”Ÿæˆã®å¤šæ§˜æ€§ã«é–¢ã™ã‚‹å•é¡Œã‚’ç‰¹å®šã—ã€ç ”ç©¶è€…ãŒã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ç ”ç©¶ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMãŒã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è€ƒãˆãŸæ–¹ãŒã€79äººã®researcherã«blind reviewã•ã›ã¦è©•ä¾¡ã—ãŸçµæœã€Noveltyã‚¹ã‚³ã‚¢ãŒæœ‰æ„ã«é«˜ããªã£ãŸï¼ˆãŸã ã—ã€feasibilityã¯äººæ‰‹ã§è€ƒãˆãŸå ´åˆã®æ–¹ãŒé«˜ã„ï¼‰ã¨ã„ã†è©±ã‚‰ã—ã„ã€‚<br><br>ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆã«ã©ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã€promptingã‚’åˆ©ç”¨ã—ãŸã‹ã¯ã¾ã èª­ã‚ã¦ã„ãªã„ã€‚<br><br><img src="https://github.com/user-attachments/assets/c7a1726c-5d7c-4275-9f67-d51e5767173b" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<span class="issue_date">Issue Date: 2024-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1381" target="_blank" rel="noopener noreferrer" class="title-link">A Survey on Human Preference Learning for Large Language Models, Ruili Jiang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“ã®å¥½ã¿å­¦ç¿’ã«åŸºã¥ãLLMsã®é€²å±•ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å¥½ã¿ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ã‚½ãƒ¼ã‚¹ã‚„å½¢å¼ã€ãƒ¢ãƒ‡ãƒªãƒ³ã‚°æŠ€è¡“ã€è©•ä¾¡æ–¹æ³•ã‚’æ•´ç†ã€‚ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã«åŸºã¥ããƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®åˆ†é¡ã‚„ã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç‚¹ãƒ»æ¬ ç‚¹ã‚’æ¯”è¼ƒã—ã€LLMsã®äººé–“ã®æ„å›³ã¨ã®æ•´åˆæ€§ã«é–¢ã™ã‚‹å±•æœ›ã‚’è­°è«–ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<span class="issue_date">Issue Date: 2024-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1378" target="_blank" rel="noopener noreferrer" class="title-link">Automatically Correcting Large Language Models: Surveying the landscape  of diverse self-correction strategies, Liangming Pan+, N_A, TACL'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ€§èƒ½ã¯é«˜ã„ãŒã€å¹»è¦šã‚„ä¸èª å®Ÿãªæ¨è«–ãªã©ã®å•é¡ŒãŒå­˜åœ¨ã™ã‚‹ã€‚è‡ªå·±ä¿®æ­£ãŒæœ‰æœ›ãªè§£æ±ºç­–ã§ã‚ã‚Šã€è‡ªå‹•ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§äººé–“ã®ä»‹å…¥ã‚’æœ€å°é™ã«æŠ‘ãˆãŸå®Ÿç”¨çš„ãªLLMã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ãŒå¯èƒ½ã«ãªã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€ç”Ÿæˆã€äº‹å¾Œä¿®æ­£ã®å„æ®µéšã«ãŠã‘ã‚‹æŠ€è¡“ã‚’åˆ†æã—ã€ä¸»è¦ãªå¿œç”¨ã¨ä»Šå¾Œã®èª²é¡Œã«ã¤ã„ã¦è­°è«–ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/8049b03d-927b-49ee-98eb-7b690b92c229" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<span class="issue_date">Issue Date: 2024-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1377" target="_blank" rel="noopener noreferrer" class="title-link">Self-Reflection in LLM Agents: Effects on Problem-Solving Performance, Matthew Renze+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è‡ªå·±åçœãŒå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å•é¡Œè§£æ±ºãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã€‚9ã¤ã®LLMã«é¸æŠè‚¢å•é¡Œã‚’è§£ã‹ã›ã€èª¤ç­”ã«å¯¾ã—ã¦è‡ªå·±åçœå‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ”¹å–„ç­–ã‚’æä¾›ã—å†å›ç­”ã‚’è©¦ã¿ãŸçµæœã€è‡ªå·±åçœã«ã‚ˆã‚Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒæœ‰æ„ã«å‘ä¸Šã—ãŸï¼ˆ$p &lt; 0.001$ï¼‰ã€‚ã•ã¾ã–ã¾ãªè‡ªå·±åçœã®ã‚¿ã‚¤ãƒ—ã‚’æ¯”è¼ƒã—ã€ãã‚Œãã‚Œã®å¯„ä¸ã‚‚æ˜ã‚‰ã‹ã«ã—ãŸã€‚å…¨ã¦ã®ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã¯GitHubã§å…¬é–‹ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2024-09-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1372" target="_blank" rel="noopener noreferrer" class="title-link">The Prompt Report: A Systematic Survey of Prompting Techniques, Sander Schulhoff+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ç”Ÿæˆçš„äººå·¥çŸ¥èƒ½ï¼ˆGenAIï¼‰ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«é–¢ã™ã‚‹æ§‹é€ çš„ç†è§£ã‚’ç¢ºç«‹ã™ã‚‹ãŸã‚ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŠ€è¡“ã®åˆ†é¡æ³•ã‚’ææ¡ˆã—ã€33ã®èªå½™ç”¨èªã¨58ã®ãƒ†ã‚­ã‚¹ãƒˆå°‚ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŠ€è¡“ã‚’æç¤ºã€‚ã•ã‚‰ã«ã€è‡ªç„¶è¨€èªãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«é–¢ã™ã‚‹æ–‡çŒ®ã®ãƒ¡ã‚¿åˆ†æã‚’å®Ÿæ–½ã€‚</span>
<span class="snippet"><span>Comment</span><p>Promptingã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ™ã‚¤</p>
<p>åˆæœŸã®æ‰‹æ³•ã‹ã‚‰ã‹ãªã‚Šç¶²ç¾…çš„ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/a6e6fd6c-910c-4d5d-a98e-47cf51e254ab" alt="image" loading="lazy"></p>
<p>ã¾ãŸã€èª¤ç”¨ã•ã‚Œã¦ã„ãŸã‚Šã€è‰²ã€…ãªæ„å‘³åˆã„ã§ä½¿ã‚ã‚Œã¦ã—ã¾ã£ã¦ã„ã‚‹ç”¨èªã‚’ã€ãã¡ã‚“ã¨å®šç¾©ã—ã¦ã„ã‚‹ã€‚<br>ãŸã¨ãˆã°ã€Few shot Learningã¨Few shot Promptingã®é•ã„ã€ãã‚‚ãã‚‚Promptingã®å®šç¾©ã€Examplarãªã©ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2024-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1371" target="_blank" rel="noopener noreferrer" class="title-link">Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?, Zorik Gekhman+, N_A, EMNLP'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é€šã˜ã¦æ–°ã—ã„äº‹å®Ÿæƒ…å ±ã«é­é‡ã™ã‚‹ãŒã€æ—¢å­˜ã®çŸ¥è­˜ã‚’æ´»ç”¨ã™ã‚‹èƒ½åŠ›ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã€‚ç ”ç©¶ã§ã¯ã€é–‰ã˜ãŸæ›¸ç±ã®QAã‚’ç”¨ã„ã¦æ–°ã—ã„çŸ¥è­˜ã‚’å°å…¥ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã®å‰²åˆã‚’å¤‰åŒ–ã•ã›ãŸçµæœã€ãƒ¢ãƒ‡ãƒ«ã¯æ–°ã—ã„çŸ¥è­˜ã‚’å­¦ç¿’ã™ã‚‹ã®ã«è‹¦åŠ´ã—ã€å¹»è¦šã™ã‚‹å‚¾å‘ãŒå¢—åŠ ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚‹æ–°ã—ã„çŸ¥è­˜ã®å°å…¥ã®ãƒªã‚¹ã‚¯ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯äº‹å‰å­¦ç¿’ã‚’é€šã˜ã¦çŸ¥è­˜ã‚’ç²å¾—ã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ãã®åˆ©ç”¨ã‚’åŠ¹ç‡åŒ–ã™ã‚‹ã“ã¨ãŒæ”¯æŒã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pre-trainingæ™‚ã«ç²å¾—ã•ã‚Œã¦ã„ãªã„æƒ…å ±ã‚’ç”¨ã„ã¦LLMã®alignmentã‚’å®Ÿæ–½ã™ã‚‹ã¨ã€çŸ¥è­˜ãŒãªã„çŠ¶æ…‹ã§å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’æ­£ã—ãäºˆæ¸¬ã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã¦ã—ã¾ã†ãŸã‚ã€äº‹å®Ÿã«åŸºã¥ã‹ãªã„å›ç­”ã‚’ã™ã‚‹ï¼ˆã¤ã¾ã‚Šhallucinationï¼‰ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã¦ã—ã¾ã†ã€ã¨ã„ã£ãŸã“ã¨ã‚’èª¿æŸ»ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br><br><br>&gt;æ–°ã—ã„çŸ¥è­˜ã‚’å°å…¥ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã¨ä¸€è‡´ã™ã‚‹ä¾‹ã‚ˆã‚Šã‚‚ã¯ã‚‹ã‹ã«é…ãå­¦ç¿’ã•ã‚Œã¾ã™ã€‚ã—ã‹ã—ã€æ–°ã—ã„çŸ¥è­˜ã‚’æŒã¤ä¾‹ãŒæœ€çµ‚çš„ã«å­¦ç¿’ã•ã‚Œã‚‹ã«ã¤ã‚Œã¦ã€ãƒ¢ãƒ‡ãƒ«ã®å¹»è¦šã™ã‚‹å‚¾å‘ãŒç·šå½¢ã«å¢—åŠ ã™ã‚‹ã“ã¨ã‚‚ç™ºè¦‹ã—ã¾ã—ãŸã€‚<br><br><img src="https://github.com/user-attachments/assets/9c7b3e2e-3ecb-4d71-a7fc-09fa7e57a613" alt="image" loading="lazy"><br><br><br><br>æ—©ã€…ã«overfittingã—ã¦ã„ã‚‹ã€‚<br><br><br><br>&gt;å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ä¸»ã«äº‹å‰å­¦ç¿’ã‚’é€šã˜ã¦äº‹å®ŸçŸ¥è­˜ã‚’å–å¾—ã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ãã‚Œã‚’ã‚ˆã‚ŠåŠ¹ç‡çš„ã«ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’æ•™ãˆã‚‹ã¨ã„ã†è¦‹è§£ã‚’æ”¯æŒã—ã¦ã„ã¾ã™ã€‚<br><br><br><br>ãªã‚‹ã»ã©ã€èˆˆå‘³æ·±ã„ã€‚</p>
<p>ä¸‹è¨˜ç”»åƒã¯ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1370" target="_blank" rel="noopener noreferrer">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« (LLM) ã®æŠ€è¡“ã¨æœ€æ–°å‹•å‘, Ikuya Yamada, 2024.06</a>
ã‚ˆã‚Šå¼•ç”¨<br><br><img src="https://github.com/user-attachments/assets/e08d47cf-b550-4ced-a6bd-02d90d3684e9" alt="image" loading="lazy"><br><br><br><br>æœ¬è«–æ–‡ä¸­ã§ã¯ã€full finetuningã«ã‚ˆã‚‹æ¤œè¨¼ã‚’å®Ÿæ–½ã—ã¦ãŠã‚Šã€LoRAã®ã‚ˆã†ãªAdapterã‚’ç”¨ã„ãŸãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã§æ¤œè¨¼ã¯ã•ã‚Œã¦ã„ãªã„ã€‚LoRAã§ã¯ã‚‚ã¨ã‚‚ã¨ã®LLMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯freezeã•ã‚Œã‚‹ãŸã‚ã€ç•°ãªã‚‹æŒ™å‹•ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ç‰¹ã«LoRAãŒæ–°ã—ã„çŸ¥è­˜ã‚’ç²å¾—å¯èƒ½ãªã“ã¨ãŒç¤ºã•ã‚Œã‚Œã°ã€LoRA Adapterã‚’ã‚‚ã¨ã‚‚ã¨ã®LLMã«ä»˜ã‘æ›¿ãˆã‚‹ã ã‘ã§ã€ç•°ãªã‚‹çŸ¥è­˜ã‚’æŒã£ãŸLLMã‚’é‹ç”¨å¯èƒ½ã«ãªã‚‹ãŸã‚ã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒå¤§ãã„ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚ã‚‚ã¨ã‚‚ã¨ã“ã†ã„ã£ãŸæ€æƒ³ã¯ LoRA Hubã‚’æå”±ã™ã‚‹ç ”ç©¶ãªã©ã®é ƒã‹ã‚‰ã‚ã£ãŸæ°—ãŒã™ã‚‹ãŒã€Adapterã«ã‚ˆã£ã¦Hallucination/overfittingã‚’é˜²ããªãŒã‚‰ã€æ–°ãŸãªçŸ¥è­˜ã‚’ç²å¾—ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸç ”ç©¶ã¯ã‚ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ<br><br><img src="https://github.com/user-attachments/assets/a05a3662-baf9-4fcd-b15e-440f1c2c9f6e" alt="image" loading="lazy"><br><br></p>
<p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1792334744522485954?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LoRAã®å ´åˆã«ã¤ã„ã¦ã¯<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1640" target="_blank" rel="noopener noreferrer">LoRA Learns Less and Forgets Less, Dan Biderman+, TMLR'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
<br><br>ã‚‚å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/DemonstrationSelection.html" target="_blank" rel="noopener noreferrer">#DemonstrationSelection</a>
<span class="issue_date">Issue Date: 2024-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1364" target="_blank" rel="noopener noreferrer" class="title-link">Revisiting Demonstration Selection Strategies in In-Context Learning, Keqin Peng+, N_A, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯å¹…åºƒã„ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹èƒ½åŠ›ã‚’æŒã¡ã€ã‚ãšã‹ãªä¾‹ã§ã‚¿ã‚¹ã‚¯ã‚’èª¬æ˜ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€ICLã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®é¸æŠã«ã‚ˆã£ã¦å¤§ããç•°ãªã‚Šã€ãã®è¦å› ã¯ã¾ã æ˜ç¢ºã§ã¯ãªã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã®ä¸¡é¢ã‹ã‚‰ã“ã®å¤‰å‹•ã«å¯„ä¸ã™ã‚‹è¦å› ã‚’å†æ¤œè¨ã—ã€ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®é¸æŠãŒãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã®ä¸¡æ–¹ã«ä¾å­˜ã™ã‚‹ã“ã¨ã‚’è¦‹å‡ºã—ãŸã€‚ã•ã‚‰ã«ã€"TopK + ConE"ã¨ã„ã†ãƒ‡ãƒ¼ã‚¿ã¨ãƒ¢ãƒ‡ãƒ«ã«ä¾å­˜ã—ãŸãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é¸æŠæ‰‹æ³•ã‚’ææ¡ˆã—ã€ICLã®ãŸã‚ã®åŠ¹æœçš„ãªãƒ¬ã‚·ãƒ”ã‚’ç”Ÿã¿å‡ºã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ææ¡ˆæ‰‹æ³•ã¯ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚±ãƒ¼ãƒ«ã§è¨€èªç†è§£ãŠã‚ˆã³ç”Ÿæˆã‚¿ã‚¹ã‚¯ã®ä¸¡æ–¹ã§ä¸€è²«ã—ãŸæ”¹å–„ã‚’ã‚‚ãŸã‚‰ã—ã€ä¸€èˆ¬æ€§ã¨å®‰å®šæ€§ã«åŠ ãˆã¦ä»¥å‰ã®æ‰‹æ³•ã®åŠ¹æœçš„ãªèª¬æ˜ã‚’æä¾›ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ICLã§åˆ©ç”¨ã™ã‚‹ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®é¸æŠã¯ã€BM25ã‚„Dense Retrieverãªã©ã‚’ç”¨ã„ã¦ã€ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«ã¨é¡ä¼¼ã—ãŸã‚µãƒ³ãƒ—ãƒ«ã‚’retrieveã™ã‚‹ã“ã¨ã§å®Ÿæ–½ã•ã‚Œã¦ããŸã€‚ã“ã‚Œã‚‰ã¯ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«ã®ã¿ã«ç€ç›®ã—ãŸæ‰‹æ³•ã§ã‚ã‚‹ãŒã€å®Ÿéš›ã«ã¯æœ‰åŠ¹ãªãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦å¤‰åŒ–ã™ã‚‹ãŸã‚ã€åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚‚è€ƒæ…®ã—ãŸæ–¹ãŒè‰¯ã„ã‚ˆã­ã€ã¨ã„ã†ãŠè©±</p>
<p>ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®ä¸€è¦§ã‚’è¦‹ã‚‹ã¨ã€ã©ã†ã„ã£ãŸæ–¹æ³•ãŒã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ãªã®ã‹ãŒã‚ã‹ã‚‹ã€‚ãã—ã¦æ„å¤–ã¨Randomã§ã‚‚ãã‚Œãªã‚Šã«å¼·ã„ã®ã§ã€å®Ÿè£…ã‚³ã‚¹ãƒˆãªã©ã¨ç›¸è«‡ã—ãªãŒã‚‰ã©ã®æ‰‹æ³•ã‚’æ¡ç”¨ã™ã‚‹ã‹ã¯æ¤œè¨ã—ãŸæ–¹ãŒè‰¯ã•ãã†ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2024-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1362" target="_blank" rel="noopener noreferrer" class="title-link">What Do Language Models Learn in Context? The Structured Task Hypothesis, Jiaoda Li+, N_A, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…å­¦ç¿’ï¼ˆICLï¼‰èƒ½åŠ›ã‚’èª¬æ˜ã™ã‚‹3ã¤ã®ä»®èª¬ã«ã¤ã„ã¦ã€ä¸€é€£ã®å®Ÿé¨“ã‚’é€šã˜ã¦æ¢ç©¶ã€‚æœ€åˆã®2ã¤ã®ä»®èª¬ã‚’ç„¡åŠ¹ã«ã—ã€æœ€å¾Œã®ä»®èª¬ã‚’æ”¯æŒã™ã‚‹è¨¼æ‹ ã‚’æä¾›ã€‚LLMãŒäº‹å‰å­¦ç¿’ä¸­ã«å­¦ç¿’ã—ãŸã‚¿ã‚¹ã‚¯ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…ã§æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’å­¦ç¿’ã§ãã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>SNLP2024ã§ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:<br>


<a href="http://chasen.org/~daiti-m/paper/SNLP2024-Task-Emergence.pdf" target="_blank" rel="noopener noreferrer">http://chasen.org/~daiti-m/paper/SNLP2024-Task-Emergence.pdf</a>


</p>
<p>ICLãŒä½•ã‚’ã‚„ã£ã¦ã„ã‚‹ã®ã‹?ã«ã¤ã„ã¦ã€ã“ã‚Œã¾ã§ã®ä»®èª¬ãŒæ­£ã—ããªã„ã“ã¨ã‚’å®Ÿé¨“çš„ã«ç¤ºã—ã€æ–°ã—ã„ä»®èª¬ã€ŒICLã¯äº‹å‰å­¦ç¿’ã§å¾—ã‚‰ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’çµ„ã¿åˆã‚ã›ã¦æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’è§£ã„ã¦ã„ã‚‹ã€ã‚’æå”±ã—ã€ã“ã®ä»®èª¬ãŒæ­£ã—ã„ã“ã¨ã‚’ç¤ºå”†ã™ã‚‹å®Ÿé¨“çµæœã‚’å¾—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br>ç†è«–çš„ã«è§£æ˜ã•ã‚ŒãŸã‚ã‘ã§ã¯ãªã•ãã†ãªã®ã§ãã“ã¯ç•™æ„ã—ãŸæ–¹ãŒè‰¯ã•ãã†ã€‚ã‚ã¨ã§ã—ã£ã‹ã‚Šèª­ã‚€ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2024-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1361" target="_blank" rel="noopener noreferrer" class="title-link">The Illusion of State in State-Space Models, William Merrill+, N_A, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- SSMï¼ˆçŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ï¼‰ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸçŠ¶æ…‹è¿½è·¡ã®è¡¨ç¾åŠ›ã‚’æŒã¤ã¨æœŸå¾…ã•ã‚Œã¦ã„ã¾ã—ãŸãŒã€å®Ÿéš›ã«ã¯ãã®è¡¨ç¾åŠ›ã¯åˆ¶é™ã•ã‚Œã¦ãŠã‚Šã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¨é¡ä¼¼ã—ã¦ã„ã¾ã™ã€‚SSMã¯è¤‡é›‘æ€§ã‚¯ãƒ©ã‚¹$\mathsf{TC}^0$ã®å¤–ã§ã®è¨ˆç®—ã‚’è¡¨ç¾ã§ããšã€å˜ç´”ãªçŠ¶æ…‹è¿½è·¡å•é¡Œã‚’è§£æ±ºã™ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚ã“ã®ãŸã‚ã€SSMã¯å®Ÿä¸–ç•Œã®çŠ¶æ…‹è¿½è·¡å•é¡Œã‚’è§£æ±ºã™ã‚‹èƒ½åŠ›ã«åˆ¶é™ãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>&gt;ã—ã‹ã—ã€SSMãŒçŠ¶æ…‹è¿½è·¡ã®è¡¨ç¾åŠ›ã§æœ¬å½“ã«ï¼ˆãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚ˆã‚Šã‚‚ï¼‰å„ªä½æ€§ã‚’æŒã£ã¦ã„ã‚‹ã®ã§ã—ã‚‡ã†ã‹ï¼Ÿé©šãã¹ãã“ã¨ã«ã€ãã®ç­”ãˆã¯ã€Œã„ã„ãˆã€ã§ã™ã€‚ç§ãŸã¡ã®åˆ†æã«ã‚ˆã‚‹ã¨ã€SSMã®è¡¨ç¾åŠ›ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¨éå¸¸ã«é¡ä¼¼ã—ã¦åˆ¶é™ã•ã‚Œã¦ã„ã¾ã™ï¼šSSMã¯è¤‡é›‘æ€§ã‚¯ãƒ©ã‚¹$\mathsf{TC}^0$ã®å¤–ã§ã®è¨ˆç®—ã‚’è¡¨ç¾ã™ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚ç‰¹ã«ã€ã“ã‚Œã¯ã€ç½®æ›åˆæˆã®ã‚ˆã†ãªå˜ç´”ãªçŠ¶æ…‹è¿½è·¡å•é¡Œã‚’è§£æ±ºã™ã‚‹ã“ã¨ãŒã§ããªã„ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€SSMã¯ã€ç‰¹å®šã®è¡¨è¨˜æ³•ã§ãƒã‚§ã‚¹ã®æ‰‹ã‚’æ­£ç¢ºã«è¿½è·¡ã—ãŸã‚Šã€ã‚³ãƒ¼ãƒ‰ã‚’è©•ä¾¡ã—ãŸã‚Šã€é•·ã„ç‰©èªã®ä¸­ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’è¿½è·¡ã™ã‚‹ã“ã¨ãŒè¨¼æ˜ä¸Šã§ããªã„ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã™ã€‚<br><br>ãªã‚“â€¦ã ã¨â€¦</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<span class="issue_date">Issue Date: 2024-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1358" target="_blank" rel="noopener noreferrer" class="title-link">Controllable Text Generation for Large Language Models: A Survey, Xun Liang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®åˆ¶å¾¡å¯èƒ½ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆCTGï¼‰æŠ€è¡“ã«é–¢ã™ã‚‹æœ€æ–°ã®é€²å±•ã‚’ä½“ç³»çš„ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ãã®ä¸­æ ¸çš„ãªæ¦‚å¿µã®åŒ…æ‹¬çš„ãªå®šç¾©ã‚’æä¾›ã—ã€åˆ¶å¾¡æ¡ä»¶ã¨ãƒ†ã‚­ã‚¹ãƒˆå“è³ªã®è¦ä»¶ã‚’æ˜ç¢ºã«ã™ã‚‹ã€‚CTGã‚¿ã‚¹ã‚¯ã‚’ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ¶å¾¡ã¨å±æ€§åˆ¶å¾¡ã®2ã¤ã®ä¸»è¦ãªã‚¿ã‚¤ãƒ—ã«åˆ†é¡ã—ã€ãƒ¢ãƒ‡ãƒ«ã®å†å­¦ç¿’ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€å¼·åŒ–å­¦ç¿’ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€æ½œåœ¨ç©ºé–“ã®æ“ä½œã€ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚ã®ä»‹å…¥ãªã©ã€ä¸»è¦ãªæ‰‹æ³•ã«ã¤ã„ã¦è­°è«–ã™ã‚‹ã€‚ã•ã‚‰ã«ã€CTGã®è©•ä¾¡æ–¹æ³•ã‚’æ¤œè¨ã—ã€é ˜åŸŸå…¨ä½“ã§ã®å¿œç”¨ã‚’ã¾ã¨ã‚ã€ç¾åœ¨ã®ç ”ç©¶ã«ãŠã‘ã‚‹ä¸»è¦ãªèª²é¡Œã«å–ã‚Šçµ„ã‚€ã€‚ã¾ãŸã€å°†æ¥ã®ç ”ç©¶ã§å®Ÿä¸–ç•Œã®å¿œç”¨ã«é‡ç‚¹ã‚’ç½®ããªã©ã€ã„ãã¤ã‹ã®ææ¡ˆã‚‚è¡Œã†ã€‚</span>
<span class="snippet"><span>Comment</span><p>Surveyã®å†…å®¹<br><img src="https://github.com/user-attachments/assets/1117d721-26b9-4361-855f-a6bf9efb93a4" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2024-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1352" target="_blank" rel="noopener noreferrer" class="title-link">Amuro &amp; Char: Analyzing the Relationship between Pre-Training and  Fine-Tuning of Large Language Models, Kaiser Sun+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ¼ãƒ‘ã‚¹ã§äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¤‡æ•°ã®ä¸­é–“äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å¾®èª¿æ•´ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€äº‹å‰å­¦ç¿’ã¨å¾®èª¿æ•´ã®é–¢ä¿‚ã‚’èª¿æŸ»ã—ãŸã€‚18ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®çµæœã‹ã‚‰ã€iï¼‰ç¶™ç¶šçš„ãªäº‹å‰å­¦ç¿’ã¯ã€å¾®èª¿æ•´å¾Œã«ãƒ¢ãƒ‡ãƒ«ã‚’æ”¹å–„ã™ã‚‹æ½œåœ¨çš„ãªæ–¹æ³•ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚iiï¼‰è¿½åŠ ã®å¾®èª¿æ•´ã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ãŒäº‹å‰å­¦ç¿’æ®µéšã§ã†ã¾ãæ©Ÿèƒ½ã—ãªã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ”¹å–„ãŒã€ã†ã¾ãæ©Ÿèƒ½ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ˆã‚Šã‚‚å¤§ãã„ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚iiiï¼‰ç›£ç£ã•ã‚ŒãŸå¾®èª¿æ•´ã‚’é€šã˜ã¦ãƒ¢ãƒ‡ãƒ«ã¯æ©æµã‚’å—ã‘ã‚‹ãŒã€ä»¥å‰ã®ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚„å¾®èª¿æ•´ä¸­ã«è¦‹ã‚‰ã‚Œãªã„ã‚¿ã‚¹ã‚¯ã‚’å¿˜ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ivï¼‰ç›£ç£ã•ã‚ŒãŸå¾®èª¿æ•´å¾Œã€ãƒ¢ãƒ‡ãƒ«ã¯è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã—ã¦é«˜ã„æ„Ÿåº¦ã‚’ç¤ºã™ãŒã€ã“ã‚Œã¯ã‚ˆã‚Šå¤šãã®äº‹å‰å­¦ç¿’ã«ã‚ˆã£ã¦ç·©å’Œã§ãã‚‹ã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/GrammaticalErrorCorrection.html" target="_blank" rel="noopener noreferrer">#GrammaticalErrorCorrection</a>
<span class="issue_date">Issue Date: 2024-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1351" target="_blank" rel="noopener noreferrer" class="title-link">Prompting open-source and commercial language models for grammatical  error correction of English learner text, Christopher Davis+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®é€²æ­©ã«ã‚ˆã‚Šã€æµæš¢ã§æ–‡æ³•çš„ãªãƒ†ã‚­ã‚¹ãƒˆç”ŸæˆãŒå¯èƒ½ã«ãªã‚Šã€ä¸æ–‡æ³•ãªå…¥åŠ›æ–‡ã‚’ä¸ãˆã‚‹ã“ã¨ã§æ–‡æ³•ã‚¨ãƒ©ãƒ¼ä¿®æ­£ï¼ˆGECï¼‰ãŒå¯èƒ½ã¨ãªã£ãŸã€‚æœ¬ç ”ç©¶ã§ã¯ã€7ã¤ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨3ã¤ã®å•†ç”¨LLMsã‚’4ã¤ã®GECãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§è©•ä¾¡ã—ã€å•†ç”¨ãƒ¢ãƒ‡ãƒ«ãŒå¸¸ã«æ•™å¸«ã‚ã‚Šã®è‹±èªGECãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã‚ã‘ã§ã¯ãªã„ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒå•†ç”¨ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒã‚ã‚Šã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ãŒãƒ•ãƒ¥ãƒ¼ã‚·ãƒ§ãƒƒãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã¨åŒã˜ãã‚‰ã„ç«¶äº‰åŠ›ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chemical_tree/status/1822860849935253882?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<span class="issue_date">Issue Date: 2024-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1350" target="_blank" rel="noopener noreferrer" class="title-link">The AI Scientist: Towards Fully Automated Open-Ended Scientific  Discovery, Chris Lu+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ€å…ˆç«¯ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€å®Œå…¨è‡ªå‹•ã®ç§‘å­¦çš„ç™ºè¦‹ã‚’å¯èƒ½ã«ã™ã‚‹åŒ…æ‹¬çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒææ¡ˆã•ã‚ŒãŸã€‚AI Scientistã¯æ–°ã—ã„ç ”ç©¶ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç”Ÿæˆã—ã€ã‚³ãƒ¼ãƒ‰ã‚’è¨˜è¿°ã—ã€å®Ÿé¨“ã‚’å®Ÿè¡Œã—ã€çµæœã‚’å¯è¦–åŒ–ã—ã€å®Œå…¨ãªç§‘å­¦è«–æ–‡ã‚’åŸ·ç­†ã—ã€æŸ»èª­ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€æ©Ÿæ¢°å­¦ç¿’ã«ãŠã‘ã‚‹ç§‘å­¦çš„ç™ºè¦‹ã®æ–°ã—ã„æ™‚ä»£ã®å§‹ã¾ã‚Šã‚’ç¤ºã—ã¦ãŠã‚Šã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¤‰é©çš„ãªåˆ©ç‚¹ã‚’AIè‡ªä½“ã®ç ”ç©¶ãƒ—ãƒ­ã‚»ã‚¹å…¨ä½“ã«ã‚‚ãŸã‚‰ã—ã€ä¸–ç•Œã§æœ€ã‚‚é›£ã—ã„å•é¡Œã«ç„¡é™ã®æ‰‹é ƒãªä¾¡æ ¼ã®å‰µé€ æ€§ã¨ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è§£ãæ”¾ã¤ã“ã¨ã«è¿‘ã¥ã„ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<span class="issue_date">Issue Date: 2024-07-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1341" target="_blank" rel="noopener noreferrer" class="title-link">Following Length Constraints in Instructions, Weizhe Yuan+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¢ãƒ©ã‚¤ãƒ³ã•ã‚ŒãŸå‘½ä»¤ã«å¾“ã†ãƒ¢ãƒ‡ãƒ«ã¯ã€éã‚¢ãƒ©ã‚¤ãƒ³ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã‚’ã‚ˆã‚Šã‚ˆãæº€ãŸã™ã“ã¨ãŒã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€ã“ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã«ã¯é•·ã•ã®ãƒã‚¤ã‚¢ã‚¹ãŒã‚ã‚Šã€è¨“ç·´ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯é•·ã„å¿œç­”ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã“ã®ãƒã‚¤ã‚¢ã‚¹ã‚’åˆ©ç”¨ã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ¨è«–æ™‚ã«æ‰€æœ›ã®é•·ã•åˆ¶ç´„ã‚’å«ã‚€å‘½ä»¤ã§åˆ¶å¾¡ã§ãã‚‹ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚ã“ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã¯ã€é•·ã•æŒ‡ç¤ºã•ã‚ŒãŸè©•ä¾¡ã«ãŠã„ã¦å„ªã‚Œã¦ãŠã‚Šã€GPT4ã€Llama 3ã€Mixtralãªã©ã®æ¨™æº–çš„ãªå‘½ä»¤ã«å¾“ã†ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã£ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>SoTA LLMãŒOutputé•·ã®åˆ¶ç´„ã«å¾“ã‚ãªã„ã“ã¨ã‚’ç¤ºã—ã€ãã‚Œã‚’æ”¹å–„ã™ã‚‹å­¦ç¿’æ‰‹æ³•LIFT-DPOã‚’ææ¡ˆ<img src="https://github.com/user-attachments/assets/1002ae4a-66b2-4125-8cbb-3a2a8484da56" alt="image" loading="lazy"><br><br></p>
<p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1805771223747481690?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2024-07-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1338" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FlashAttention-3: Fast and Accurate Attention with Asynchrony and   Low-precision, Jay Shah+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- FlashAttention-3ã¯ã€Hopper GPUä¸Šã§Attentionã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã«ã€3ã¤ã®æŠ€è¡“ã‚’é–‹ç™ºã—ã€H100 GPUã§1.5-2.0å€ã®é€Ÿåº¦å‘ä¸Šã‚’å®Ÿç¾ã€‚FP16ã§740 TFLOPs/sã€FP8ã§ç´„1.2 PFLOPs/sã«é”ã—ã€FP8ã§ã¯æ•°å€¤èª¤å·®ãŒ2.6å€ä½ã„ã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=tVConYid20&referrer=%5Bthe%20profile%20of%20Tri%20Dao%5D(%2Fprofile%3Fid%3D~Tri_Dao1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=tVConYid20&referrer=%5Bthe%20profile%20of%20Tri%20Dao%5D(%2Fprofile%3Fid%3D~Tri_Dao1)</a>


</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2024-07-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1337" target="_blank" rel="noopener noreferrer" class="title-link">A Systematic Survey of Prompt Engineering in Large Language Models:  Techniques and Applications, Pranab Sahoo+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¯ã€LLMsã‚„VLMsã®èƒ½åŠ›ã‚’æ‹¡å¼µã™ã‚‹ãŸã‚ã®é‡è¦ãªæŠ€è¡“ã§ã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã›ãšã«ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®æŒ‡ç¤ºã§ã‚ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ´»ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®åŠ¹æœã‚’å‘ä¸Šã•ã›ã‚‹ã€‚æœ¬ç ”ç©¶ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®æœ€è¿‘ã®é€²å±•ã«ã¤ã„ã¦æ§‹é€ åŒ–ã•ã‚ŒãŸæ¦‚è¦ã‚’æä¾›ã—ã€å„æ‰‹æ³•ã®å¼·ã¿ã¨åˆ¶é™ã«ã¤ã„ã¦æ˜ã‚Šä¸‹ã’ã‚‹ã“ã¨ã§ã€ã“ã®åˆ†é‡ã‚’ã‚ˆã‚Šã‚ˆãç†è§£ã—ã€å°†æ¥ã®ç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/9c41dcc4-6b88-47ae-9032-1daca6bfee65" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-04-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1293" target="_blank" rel="noopener noreferrer" class="title-link">Phi-3 Technical Report: A Highly Capable Language Model Locally on Your  Phone, Marah Abdin+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- phi-3-miniã¯38å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€3.3å…†ãƒˆãƒ¼ã‚¯ãƒ³ã§è¨“ç·´ã•ã‚Œã¦ã„ã¾ã™ã€‚Mixtral 8x7Bã‚„GPT-3.5ãªã©ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã«åŒ¹æ•µã™ã‚‹ç·åˆçš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æŒã¡ãªãŒã‚‰ã€ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã«ãƒ‡ãƒ—ãƒ­ã‚¤å¯èƒ½ãªã‚µã‚¤ã‚ºã§ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€å³å¯†ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸWebãƒ‡ãƒ¼ã‚¿ã¨åˆæˆãƒ‡ãƒ¼ã‚¿ã§æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€å …ç‰¢æ€§ã€å®‰å…¨æ€§ã€ãŠã‚ˆã³ãƒãƒ£ãƒƒãƒˆå½¢å¼ã«é©åˆã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€phi-3-smallã¨phi-3-mediumã¨ã„ã†ã‚ˆã‚Šå¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã‚‚ç´¹ä»‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1039" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need II: phi-1.5 technical report, Yuanzhi Li+, N/A, arXiv'23</a>
 ã®æ¬¡ã®æ¬¡ï¼ˆPhi2.0ã«ã¤ã„ã¦ã¯ãƒ¡ãƒ¢ã£ã¦ãªã‹ã£ãŸï¼‰ã€‚ã‚¹ãƒãƒ›ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã‚‹ãƒ¬ãƒ™ãƒ«ã®ã‚µã‚¤ã‚ºã§ã€GPT3.5Turboç¨‹åº¦ã®æ€§èƒ½ã‚’å®Ÿç¾ã—ãŸã‚‰ã—ã„</p>
<p>Llama2ã¨åŒã˜ãƒ–ãƒ­ãƒƒã‚¯ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯Llama2ã¨å…±é€šã€‚<br><br></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Pruning.html" target="_blank" rel="noopener noreferrer">#Pruning</a>
<span class="issue_date">Issue Date: 2024-04-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1292" target="_blank" rel="noopener noreferrer" class="title-link">The Unreasonable Ineffectiveness of the Deeper Layers, Andrey Gromov+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ä¸€èˆ¬çš„ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆã®äº‹å‰å­¦ç¿’ã•ã‚ŒãŸLLMã®ãƒ¬ã‚¤ãƒ¤ãƒ¼å‰ªå®šæˆ¦ç•¥ã‚’ç ”ç©¶ã—ã€ç•°ãªã‚‹è³ªå•å¿œç­”ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ä½ä¸‹ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®æœ€å¤§åŠåˆ†ã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ã§ã€æœ€é©ãªãƒ–ãƒ­ãƒƒã‚¯ã‚’ç‰¹å®šã—ã€å¾®èª¿æ•´ã—ã¦æå‚·ã‚’ä¿®å¾©ã—ã¾ã™ã€‚PEFTæ‰‹æ³•ã‚’ä½¿ç”¨ã—ã€å®Ÿé¨“ã‚’å˜ä¸€ã®A100 GPUã§å®Ÿè¡Œå¯èƒ½ã«ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šæ¸›ã—ã€æ¨è«–ã®ãƒ¡ãƒ¢ãƒªã¨ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã‚’æ”¹å–„ã§ãã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¾ã™ã€‚ã¾ãŸã€LLMãŒãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å‰Šé™¤ã«å¯¾ã—ã¦å …ç‰¢ã§ã‚ã‚‹ã“ã¨ã¯ã€æµ…ã„ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒçŸ¥è­˜ã‚’æ ¼ç´ã™ã‚‹ä¸Šã§é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¦ã„ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä¸‹è¨˜ãƒ„ã‚¤ãƒ¼ãƒˆã«ã‚ˆã‚‹ã¨ã€å­¦ç¿’æ¸ˆã¿LLMã‹ã‚‰ã€ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§å…¥å‡ºåŠ›é–“ã®é¡ä¼¼åº¦ãŒé«˜ã„å±¤ã‚’é™¤ã„ã¦ã‚‚ã‚¿ã‚¹ã‚¯ã®ç²¾åº¦ãŒè½ã¡ãšã€ç‰¹ã«æ·±ã„å±¤ã‚’2-4å‰²å‰Šé™¤ã—ã¦ã‚‚ç²¾åº¦ãŒè½ã¡ãªã„ã¨ã®ã“ã¨ã€‚<br><br>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1773110076502368642?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>VRAMã«è¼‰ã›ã‚‹ã®ãŒå¤§å¤‰ãªã®ã§ã€ã“ã®ã‚ˆã†ãªæåˆˆã‚ŠæŠ€è¡“ãŒæœ‰åŠ¹ã ã¨åˆ†ã‹ã‚‹ã®ã¯ã‚ã‚ŠãŒãŸã„ã€‚LoRAã‚„é‡å­åŒ–ã‚‚åˆ©ç”¨ã—ã¦ã„ã‚‹ã£ã½ã„ã€‚</span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1284" target="_blank" rel="noopener noreferrer" class="title-link">Knowledge Conflicts for LLMs: A Survey, Rongwu Xu+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã«ãŠã‘ã‚‹çŸ¥è­˜ã®è¡çªã«ç„¦ç‚¹ã‚’å½“ã¦ã€æ–‡è„ˆã¨ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯çŸ¥è­˜ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚‹è¤‡é›‘ãªèª²é¡Œã‚’åˆ†æã€‚æ–‡è„ˆ-ãƒ¡ãƒ¢ãƒªã€æ–‡è„ˆé–“ã€ãƒ¡ãƒ¢ãƒªå†…ã®è¡çªã®3ã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’æ¢æ±‚ã—ã€å®Ÿä¸–ç•Œã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹ä¿¡é ¼æ€§ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¸ã®å½±éŸ¿ã‚’æ¤œè¨ã€‚è§£æ±ºç­–ã‚’ææ¡ˆã—ã€LLMsã®å …ç‰¢æ€§å‘ä¸Šã‚’ç›®æŒ‡ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<span class="issue_date">Issue Date: 2024-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1283" target="_blank" rel="noopener noreferrer" class="title-link">Quiet-STaR: Language Models Can Teach Themselves to Think Before  Speaking, Eric Zelikman+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- STaRï¼ˆSelf-Taught Reasonerï¼‰ã§ã¯ã€å°‘æ•°ã®ä¾‹ã‹ã‚‰åˆç†çš„ãªæ¨è«–ã‚’å­¦ç¿’ã—ã€è³ªå•å¿œç­”ã«æ´»ç”¨ã™ã‚‹æ–¹æ³•ãŒææ¡ˆã•ã‚ŒãŸã€‚Quiet-STaRã§ã¯ã€LMãŒåˆç†æ€§ã‚’ç”Ÿæˆã™ã‚‹æ–¹æ³•ã‚’å­¦ç¿’ã—ã€é›£ã—ã„è³ªå•ã«ç›´æ¥ç­”ãˆã‚‹èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ã“ã®æ‰‹æ³•ã¯ã€GSM8Kã‚„CommonsenseQAãªã©ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®æ”¹å–„ã‚’å®Ÿç¾ã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒä¸è¦ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚Quiet-STaRã¯ã€æ¨è«–ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã®ä¸€èˆ¬çš„ã§ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªæ–¹æ³•ã‚’æä¾›ã™ã‚‹ä¸€æ­©ã¨ãªã£ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>o1(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1390" target="_blank" rel="noopener noreferrer">OpenAI o1, 2024.09</a>
)ã®åŸºç¤æŠ€è¡“ã¨ä¼¼ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹<br>å…ˆè¡Œç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1397" target="_blank" rel="noopener noreferrer">STaR: Bootstrapping Reasoning With Reasoning, Eric Zelikman+, N/A, NeurIPS'22</a>
</p>
<p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1835449666588271046?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1282" target="_blank" rel="noopener noreferrer" class="title-link">RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in  Long-Horizon Generation, Zihao Wang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ãŠã‚ˆã³ç”Ÿæˆèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã€å¹»è¦šã‚’è»½æ¸›ã™ã‚‹æ–¹æ³•ã¨ã—ã¦ã€æƒ…å ±æ¤œç´¢ã‚’åˆ©ç”¨ã—ã¦æ€è€ƒã®é€£é–ã‚’ä¿®æ­£ã™ã‚‹ã€Œretrieval-augmented thoughtsï¼ˆRATï¼‰ã€ãŒææ¡ˆã•ã‚ŒãŸã€‚ã“ã®æ–¹æ³•ã¯ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®CoTãŒç”Ÿæˆã•ã‚ŒãŸå¾Œã€å–å¾—ã—ãŸæƒ…å ±ã‚’ä½¿ç”¨ã—ã¦å„æ€è€ƒã‚¹ãƒ†ãƒƒãƒ—ã‚’ä¿®æ­£ã™ã‚‹ã€‚GPT-3.5ã€GPT-4ã€ãŠã‚ˆã³CodeLLaMA-7bã«RATã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã€æ•°å­¦çš„æ¨è«–ã€å‰µé€ çš„ãªåŸ·ç­†ã€å…·ä½“çš„ãªã‚¿ã‚¹ã‚¯è¨ˆç”»ãªã©ã®ã‚¿ã‚¹ã‚¯ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤§å¹…ã«å‘ä¸Šã—ãŸã€‚ãƒ‡ãƒ¢ãƒšãƒ¼ã‚¸ã¯https://craftjarvis.github.io/RATã§åˆ©ç”¨å¯èƒ½ã€‚</span>
<span class="snippet"><span>Comment</span><p>RAGã«ãŠã„ã¦CoTã•ã›ã‚‹éš›ã«ã€å„reasoningã®stepã‚’è¦‹ç›´ã•ã›ã‚‹ã“ã¨ã§ã‚ˆã‚Šè³ªã®é«˜ã„reasoningã‚’ç”Ÿæˆã™ã‚‹RATã‚’ææ¡ˆã€‚HallucinationãŒä½æ¸›ã—ã€ç”Ÿæˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚‚å‘ä¸Šã™ã‚‹ã¨ã®ã“ã¨ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/785f22e8-15b3-4dd1-997b-7186a4a9d399" alt="image" loading="lazy"></p>
<p>ã‚³ãƒ³ã‚»ãƒ—ãƒˆè‡ªä½“ã¯ãã‚Šã‚ƒãã†ã ã‚ˆã­ã¨ã„ã†è©±ãªã®ã§ã€RAGãªã‚‰ã§ã¯ã®èª²é¡ŒãŒã‚ã‚Šã€ãã‚Œã‚’è§£æ±ºã—ãŸã€ã¿ãŸã„ãªè©±ãŒã‚ã‚‹ã®ã‹ãŒæ°—ã«ãªã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2024-04-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1275" target="_blank" rel="noopener noreferrer" class="title-link">Visualization-of-Thought Elicits Spatial Reasoning in Large Language  Models, Wenshan Wu+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®ç©ºé–“æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€Visualization-of-Thoughtï¼ˆVoTï¼‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã‚’ææ¡ˆã€‚VoTã¯ã€LLMsã®æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å¯è¦–åŒ–ã—ã€ç©ºé–“æ¨è«–ã‚¿ã‚¹ã‚¯ã§ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€æ—¢å­˜ã®MLLMsã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚VoTã¯ã€ç©ºé–“æ¨è«–ã‚’ä¿ƒé€²ã™ã‚‹ãŸã‚ã«ã€Œãƒ¡ãƒ³ã‚¿ãƒ«ã‚¤ãƒ¡ãƒ¼ã‚¸ã€ã‚’ç”Ÿæˆã™ã‚‹èƒ½åŠ›ã‚’æŒã¡ã€MLLMsã§ã®æœ‰åŠ¹æ€§ã‚’ç¤ºå”†ã™ã‚‹ã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ContextWindow.html" target="_blank" rel="noopener noreferrer">#ContextWindow</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1274" target="_blank" rel="noopener noreferrer" class="title-link">Long-context LLMs Struggle with Long In-context Learning, Tianle Li+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å‡¦ç†ã™ã‚‹èƒ½åŠ›ã«é€²å±•ã—ã¦ã„ã‚‹ãŒã€å®Ÿä¸–ç•Œã®ã‚·ãƒŠãƒªã‚ªã§ã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®å°‚é–€çš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯LongICLBenchãŒå°å…¥ã•ã‚ŒãŸã€‚ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯ã€LLMsã¯å·¨å¤§ãªãƒ©ãƒ™ãƒ«ç©ºé–“ã‚’ç†è§£ã—ã€æ­£ã—ã„äºˆæ¸¬ã‚’è¡Œã†ãŸã‚ã«å…¥åŠ›å…¨ä½“ã‚’ç†è§£ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ç ”ç©¶ã«ã‚ˆã‚‹ã¨ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆLLMsã¯é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§æ¯”è¼ƒçš„è‰¯ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ãŒã€æœ€ã‚‚å›°é›£ãªã‚¿ã‚¹ã‚¯ã§ã¯è‹¦åŠ´ã—ã¦ã„ã‚‹ã€‚ç¾åœ¨ã®LLMsã¯é•·ãã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè±Šã‹ãªã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å‡¦ç†ã—ç†è§£ã™ã‚‹èƒ½åŠ›ã«ã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ãŠã‚Šã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ç†è§£ã¨æ¨è«–ã¯ä¾ç„¶ã¨ã—ã¦é›£ã—ã„èª²é¡Œã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>GPT4ä»¥å¤–ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒ20Kã‚’è¶…ãˆã‚‹ã¨æ€§èƒ½ãŒåŠ£åŒ–ã™ã‚‹å‚¾å‘ã«ã‚ã‚‹ã¨ã®ã“ã¨ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é›£æ˜“åº¦åˆ¥ã«åé›†ã—è©•ä¾¡ã—ãŸã¨ã“ã‚ã€é›£æ˜“åº¦ã®é«˜ã„ãƒ‡ãƒ¼ã‚¿ã§ã¯ãã‚‚ãã‚‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ããªã‚‹ã¨å…¨ã¦ã®LLMãŒã‚¿ã‚¹ã‚¯ã‚’ç†è§£ã™ã‚‹ã§ããšã»ã¼0%ã®æ€§èƒ½ã¨ãªã£ãŸã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fc51d83a-3013-4fcc-bf7a-5722eb01d0d8" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1273" target="_blank" rel="noopener noreferrer" class="title-link">Mixture-of-Depths: Dynamically allocating compute in transformer-based  language models, David Raposo+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Transformerãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€å…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å…¨ä½“ã«å‡ç­‰ã«FLOPsã‚’åˆ†æ•£ã•ã›ã‚‹ä»£ã‚ã‚Šã«ã€ç‰¹å®šã®ä½ç½®ã«FLOPsã‚’å‹•çš„ã«å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ã‚’å­¦ç¿’ã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®æ·±ã•ã«ã‚ãŸã£ã¦å‰²ã‚Šå½“ã¦ã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã«ã€ç•°ãªã‚‹ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§è¨ˆç®—ã‚’å‹•çš„ã«å‰²ã‚Šå½“ã¦ã‚‹ã€‚ã“ã®æ‰‹æ³•ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³ã®æ•°ã‚’åˆ¶é™ã™ã‚‹ã“ã¨ã§åˆè¨ˆè¨ˆç®—äºˆç®—ã‚’å¼·åˆ¶ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ã¯top-kãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä½¿ç”¨ã—ã¦æ±ºå®šã•ã‚Œã‚‹ã€‚ã“ã®æ–¹æ³•ã«ã‚ˆã‚Šã€FLOPsã‚’å‡ç­‰ã«æ¶ˆè²»ã—ã¤ã¤ã€è¨ˆç®—ã®æ”¯å‡ºãŒäºˆæ¸¬å¯èƒ½ã§ã‚ã‚Šã€å‹•çš„ã‹ã¤ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æ•æ„Ÿã§ã‚ã‚‹ã€‚ã“ã®ã‚ˆã†ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€è¨ˆç®—ã‚’å‹•çš„ã«å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ã‚’å­¦ç¿’ã—ã€åŠ¹ç‡çš„ã«è¡Œã†ã“ã¨ãŒã§ãã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theseamouse/status/1775782800362242157?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1270" target="_blank" rel="noopener noreferrer" class="title-link">Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference, Piotr Nawrot+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®ç”ŸæˆåŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€Dynamic Memory Compressionï¼ˆDMCï¼‰ãŒææ¡ˆã•ã‚ŒãŸã€‚DMCã¯ã€ç•°ãªã‚‹ãƒ˜ãƒƒãƒ‰ã¨ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ç•°ãªã‚‹åœ§ç¸®ç‡ã‚’é©ç”¨ã™ã‚‹æ–¹æ³•ã‚’å­¦ç¿’ã—ã€äº‹å‰å­¦ç¿’æ¸ˆã¿LLMsã«é©ç”¨ã•ã‚Œã‚‹ã€‚DMCã¯ã€å…ƒã®ä¸‹æµãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æœ€å¤§4å€ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥åœ§ç¸®ã§ç¶­æŒã—ã¤ã¤ã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚DMCã¯ã€GQAã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã•ã‚‰ãªã‚‹åˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ãŒã‚ã‚Šã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨å¤§ããªãƒãƒƒãƒã‚’å‡¦ç†ã™ã‚‹éš›ã«æœ‰ç”¨ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1776755029581676943?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è«–æ–‡ä¸­ã®Figure1ãŒéå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d416547e-f9ca-4c6c-8ebb-7d164bef5283" alt="image" loading="lazy"><br><br></p>
<p>GQA <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
 ã¨æ¯”è¼ƒã—ã¦ã€2~4å€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åœ§ç¸®ã—ã¤ã¤ã€ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’å®Ÿç¾ã€‚70Bãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯ã€GQAã§8å€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åœ§ç¸®ã—ãŸä¸Šã§ã€DMCã§è¿½åŠ ã§2å€åœ§ç¸®ã‚’ã‹ã‘ãŸã¨ã“ã‚ã€åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7b131f07-5eab-4830-88cc-5f6fd0508958" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1269" target="_blank" rel="noopener noreferrer" class="title-link">RAFT: Adapting Language Model to Domain Specific RAG, Tianjun Zhang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®LLMsã‚’äº‹å‰å­¦ç¿’ã—ã€æ–°ã—ã„çŸ¥è­˜ã‚’è¿½åŠ ã™ã‚‹ãŸã‚ã®Retrieval Augmented FineTuningï¼ˆRAFTï¼‰ã‚’ææ¡ˆã€‚RAFTã¯ã€è³ªå•ã«å›ç­”ã™ã‚‹ã®ã«å½¹ç«‹ã¤é–¢é€£æ–‡æ›¸ã‹ã‚‰æ­£ã—ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å¼•ç”¨ã—ã€chain-of-thoughtã‚¹ã‚¿ã‚¤ãƒ«ã®å¿œç­”ã‚’é€šã˜ã¦æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚RAFTã¯PubMedã€HotpotQAã€Gorillaãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã€äº‹å‰å­¦ç¿’æ¸ˆã¿LLMsã‚’ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®RAGã«å‘ã‘ã¦æ”¹å–„ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Question, instruction, coxtext, cot style answerã®4ã¤ã‚’ç”¨ã„ã¦SFTã‚’ã™ã‚‹æ¨¡æ§˜<br>ç”»åƒã¯ä¸‹è¨˜ãƒ„ã‚¤ãƒ¼ãƒˆã‚ˆã‚Šå¼•ç”¨<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0763b048-8029-4712-9e79-e833bdb9b2c0" alt="image" loading="lazy"><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cwolferesearch/status/1770912695765660139?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1268" target="_blank" rel="noopener noreferrer" class="title-link">RankPrompt: Step-by-Step Comparisons Make Language Models Better  Reasoners, Chi Hu+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯æ¨è«–ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã¦ã„ã‚‹ãŒã€è«–ç†ã‚¨ãƒ©ãƒ¼ãŒèµ·ã“ã‚Šã‚„ã™ã„ã€‚RankPromptã¨ã„ã†æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æ–¹æ³•ã‚’å°å…¥ã—ã€LLMsãŒè‡ªå·±ãƒ©ãƒ³ã‚¯ä»˜ã‘ã‚’è¡Œã„æ¨è«–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“ã§ã¯ã€RankPromptãŒChatGPTã‚„GPT-4ã®æ¨è«–ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’13%å‘ä¸Šã•ã›ã€AlpacaEvalãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§äººé–“ã®åˆ¤æ–­ã¨74%ã®ä¸€è‡´ç‡ã‚’ç¤ºã™ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚RankPromptã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é«˜å“è³ªãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å¼•ãå‡ºã™åŠ¹æœçš„ãªæ–¹æ³•ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã€‚å¤§é‡ã®å€™è£œã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã™ã‚‹ã®ã¯å›°é›£ã ã¨æ€ã‚ã‚Œã‚‹ãŒã€ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°æ‰‹æ³•ã¨ã—ã¦ã¯åˆ©ç”¨ã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7115515c-10a2-44ae-9e48-86258cc11aed" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/NumericReasoning.html" target="_blank" rel="noopener noreferrer">#NumericReasoning</a>
<span class="issue_date">Issue Date: 2024-04-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1267" target="_blank" rel="noopener noreferrer" class="title-link">Prompting for Numerical Sequences: A Case Study on Market Comment  Generation, Masayuki Kawarada+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯ã€æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã«é–¢ã™ã‚‹ç ”ç©¶ãŒé€²ã‚“ã§ã„ã‚‹ãŒã€æ™‚ç³»åˆ—æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹è©³ç´°ãªèª¿æŸ»ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ ªä¾¡ã®æ•°å€¤ç³»åˆ—ã‚’å…¥åŠ›ã¨ã—ã¦å¸‚å ´ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã«ç„¦ç‚¹ã‚’å½“ã¦ã€ã•ã¾ã–ã¾ãªå…¥åŠ›è¡¨ç¾ã‚’æ¢ç©¶ã™ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã«ä¼¼ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã‚ˆã‚Šè‰¯ã„çµæœã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ã‚’ç¤ºã—ã¦ãŠã‚Šã€æ•°å€¤ç³»åˆ—ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹éš›ã®åŠ¹æœçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆã«ã¤ã„ã¦ç¤ºå”†ã‚’æä¾›ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Data-to-Textç³»ã®ã‚¿ã‚¹ã‚¯ã§ã¯ã€ã—ã°ã—ã°æ•°å€¤åˆ—ãŒInputã¨ãªã‚Šã€ãã“ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ãŒã€ã“ã®éš›ã«ã©ã®ã‚ˆã†ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§æ•°å€¤åˆ—ã‚’Promptingã™ã‚‹ã®ãŒè‰¯ã„ã‹ã‚’èª¿æŸ»ã—ãŸç ”ç©¶ã€‚Pythonãƒªã‚¹ãƒˆãªã©ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã«ä¼¼ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒé«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã€è‡ªç„¶è¨€èªã‚„html, latextãªã©ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯åŠ¹æœãŒä½ã‹ã£ãŸã¨ã®ã“ã¨<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c48c3306-d3ac-4f89-918c-28cb0a17444a" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2024-03-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1250" target="_blank" rel="noopener noreferrer" class="title-link">OLMo: Accelerating the Science of Language Models, Dirk Groeneveld+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LMsã®å•†æ¥­çš„é‡è¦æ€§ãŒé«˜ã¾ã‚‹ä¸­ã€æœ€ã‚‚å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã¯é–‰é–ã•ã‚Œã¦ãŠã‚Šã€ãã®è©³ç´°ãŒéå…¬é–‹ã«ãªã£ã¦ã„ã‚‹ã€‚ãã®ãŸã‚ã€æœ¬æŠ€è¡“ãƒ¬ãƒãƒ¼ãƒˆã§ã¯ã€æœ¬å½“ã«ã‚ªãƒ¼ãƒ—ãƒ³ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹OLMoã®åˆå›ãƒªãƒªãƒ¼ã‚¹ã¨ã€è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®ç§‘å­¦ã‚’æ§‹ç¯‰ã—ç ”ç©¶ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã¤ã„ã¦è©³ç´°ã«èª¬æ˜ã—ã¦ã„ã‚‹ã€‚OLMoã¯ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã ã‘ã§ãªãã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŠã‚ˆã³è©•ä¾¡ã‚³ãƒ¼ãƒ‰ã‚’å«ã‚€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯å…¨ä½“ã‚’å…¬é–‹ã—ã¦ãŠã‚Šã€ã‚ªãƒ¼ãƒ—ãƒ³ãªç ”ç©¶ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚’å¼·åŒ–ã—ã€æ–°ã—ã„ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Model Weightsã‚’å…¬é–‹ã™ã‚‹ã ã‘ã§ãªãã€training/evaluation codeã¨ãã®ãƒ‡ãƒ¼ã‚¿ã‚‚å…¬é–‹ã™ã‚‹çœŸã«Openãªè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆtruly Open Language Modelï¼‰ã€‚AllenAI</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2024-03-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1247" target="_blank" rel="noopener noreferrer" class="title-link">Chain-of-Thought Reasoning Without Prompting, Xuezhi Wang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ç„¦ç‚¹ã‚’å½“ã¦ãŸç ”ç©¶ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€LLMsãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãªã—ã§åŠ¹æœçš„ã«æ¨è«–ã§ãã‚‹ã‹ã©ã†ã‹ã‚’æ¤œè¨¼ã—ã€CoTæ¨è«–ãƒ‘ã‚¹ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§å¼•ãå‡ºã™æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€å¾“æ¥ã®è²ªæ¬²ãªãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ãªãã€ä»£æ›¿ãƒˆãƒ¼ã‚¯ãƒ³ã‚’èª¿æŸ»ã™ã‚‹ã“ã¨ã§CoTãƒ‘ã‚¹ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ãŠã‚Šã€æ§˜ã€…ãªæ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ‰åŠ¹æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä»¥å‰ã«CoTã‚’å†…éƒ¨çš„ã«è‡ªå‹•çš„ã«å®Ÿæ–½ã•ã‚Œã‚‹ã‚ˆã†ã«äº‹å‰å­¦ç¿’æ®µéšã§å­¦ç¿’ã™ã‚‹ã€ã¨ã„ã£ãŸè©±ãŒã‚ã£ãŸã¨æ€ã†ãŒã€ã“ã®ç ”ç©¶ã¯ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ–¹æ³•ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã€promptingã§æ˜ç¤ºçš„ã«instructionã‚’å®Ÿæ–½ã›ãšã¨ã‚‚ã€CoTã‚’å®Ÿç¾ã™ã‚‹ã‚‚ã®ã€ã¨ã„ã†ã“ã¨ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/afb3a31e-3d85-4b7e-affa-fccc00b7321e" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2024-03-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1245" target="_blank" rel="noopener noreferrer" class="title-link">LoRA+: Efficient Low Rank Adaptation of Large Models, Soufiane Hayou+, N_A, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Huã‚‰ï¼ˆ2021ï¼‰ã«ã‚ˆã£ã¦å°å…¥ã•ã‚ŒãŸLow Rank Adaptationï¼ˆLoRAï¼‰ãŒã€å¤§åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã®é©åˆ‡ãªå¾®èª¿æ•´ã‚’å¦¨ã’ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã—ã¾ã™ã€‚ã“ã®å•é¡Œã¯ã€LoRAã®ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ãƒãƒˆãƒªãƒƒã‚¯ã‚¹Aã¨BãŒåŒã˜å­¦ç¿’ç‡ã§æ›´æ–°ã•ã‚Œã‚‹ã“ã¨ã«èµ·å› ã—ã¾ã™ã€‚æˆ‘ã€…ã¯ã€Aã¨Bã«åŒã˜å­¦ç¿’ç‡ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒåŠ¹ç‡çš„ãªç‰¹å¾´å­¦ç¿’ã‚’å¦¨ã’ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ç•°ãªã‚‹å­¦ç¿’ç‡ã‚’è¨­å®šã™ã‚‹ã“ã¨ã§ã“ã®å•é¡Œã‚’ä¿®æ­£ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ä¿®æ­£ã•ã‚ŒãŸã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’LoRA$+$ã¨å‘¼ã³ã€å¹…åºƒã„å®Ÿé¨“ã«ã‚ˆã‚Šã€LoRA$+$ã¯æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã€å¾®èª¿æ•´é€Ÿåº¦ã‚’æœ€å¤§2å€é«˜é€ŸåŒ–ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LoRAã§å°å…¥ã•ã‚Œã‚‹ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—Aã¨Bã‚’ç•°ãªã‚‹å­¦ç¿’ç‡ã§å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€LoRAã¨åŒã˜è¨ˆç®—ã‚³ã‚¹ãƒˆã§ã€2å€ä»¥ä¸Šã®é«˜é€ŸåŒ–ã€ã‹ã¤é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã™ã‚‹æ‰‹æ³•<br><br><img src="https://github.com/user-attachments/assets/cde925fa-bfe8-4385-ae55-d80f7bf034f5" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/c054c5a6-56a2-4aa5-b7f2-0ae87a808f58" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/f32a7aba-e4b1-4d28-920d-00f81e9b85e8" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Annotation.html" target="_blank" rel="noopener noreferrer">#Annotation</a>
<span class="issue_date">Issue Date: 2024-03-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1244" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models for Data Annotation: A Survey, Zhen Tan+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- GPT-4ãªã©ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ç ”ç©¶ã«ç„¦ç‚¹ã‚’å½“ã¦ã€LLMã«ã‚ˆã‚‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆã®è©•ä¾¡ã‚„å­¦ç¿’ã¸ã®å¿œç”¨ã«ã¤ã„ã¦è¿°ã¹ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚LLMã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®æ‰‹æ³•ã‚„èª²é¡Œã«ã¤ã„ã¦åŒ…æ‹¬çš„ã«è­°è«–ã—ã€å°†æ¥ã®ç ”ç©¶ã®é€²å±•ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Data Annotationã«LLMã‚’æ´»ç”¨ã™ã‚‹å ´åˆã®ã‚µãƒ¼ãƒ™ã‚¤</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<span class="issue_date">Issue Date: 2024-03-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1243" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Modelsï¼ˆLLMsï¼‰ on Tabular Data: Prediction, Generation, and  Understanding -- A Survey, Xi Fang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®é€²å±•ã«ã‚ˆã‚Šã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹å¿œç”¨ãŒå®¹æ˜“ã«ãªã£ã¦ã„ã‚‹ãŒã€åŒ…æ‹¬çš„ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚ã“ã®ç ”ç©¶ã¯ã€æœ€è¿‘ã®é€²æ­©ã‚’ã¾ã¨ã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€æ–¹æ³•è«–ã‚’èª¿æŸ»ã—ã€å°†æ¥ã®ç ”ç©¶æ–¹å‘ã«æ´å¯Ÿã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€é–¢é€£ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å‚ç…§ã‚‚æä¾›ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Tabular Dataã«ãŠã‘ã‚‹LLMé–¢é€£ã®ã‚¿ã‚¹ã‚¯ã‚„æŠ€è¡“ç­‰ã®ã‚µãƒ¼ãƒ™ã‚¤</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2024-02-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1235" target="_blank" rel="noopener noreferrer" class="title-link">User-LLM: Efficient LLM Contextualization with User Embeddings, Lin Ning+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã‚’æ´»ç”¨ã—ãŸUser-LLMãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒææ¡ˆã•ã‚ŒãŸã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¦LLMsã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ä½ç½®ä»˜ã‘ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å‹•çš„ã«é©å¿œã™ã‚‹ã“ã¨ãŒå¯èƒ½ã«ãªã‚‹ã€‚åŒ…æ‹¬çš„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€è‘—ã—ã„æ€§èƒ½å‘ä¸ŠãŒç¤ºã•ã‚Œã€Perceiverãƒ¬ã‚¤ãƒ¤ãƒ¼ã®çµ„ã¿è¾¼ã¿ã«ã‚ˆã‚Šè¨ˆç®—åŠ¹ç‡ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>next item prediction, favorite genre or category predictimnreview generationãªã©ã§è©•ä¾¡ã—ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ProgressiveLearning.html" target="_blank" rel="noopener noreferrer">#ProgressiveLearning</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2024-01-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1219" target="_blank" rel="noopener noreferrer" class="title-link">LLaMA Pro: Progressive LLaMA with Block Expansion, Chengyue Wu+, N_A, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ–°ã—ã„äº‹å‰å­¦ç¿’å¾Œã®æ‰‹æ³•ã‚’ææ¡ˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã‚’åŠ¹æœçš„ã‹ã¤åŠ¹ç‡çš„ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€Transformerãƒ–ãƒ­ãƒƒã‚¯ã®æ‹¡å¼µã‚’ä½¿ç”¨ã—ã€æ–°ã—ã„ã‚³ãƒ¼ãƒ‘ã‚¹ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’èª¿æ•´ã—ã¾ã—ãŸã€‚å®Ÿé¨“ã®çµæœã€ææ¡ˆæ‰‹æ³•ã¯ã•ã¾ã–ã¾ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã€çŸ¥çš„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã“ã®ç ”ç©¶ã¯ã€è‡ªç„¶è¨€èªã¨ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã‚’çµ±åˆã—ã€é«˜åº¦ãªè¨€èªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é–‹ç™ºã«è²¢çŒ®ã™ã‚‹ã‚‚ã®ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>è¿½åŠ ã®çŸ¥è­˜ã‚’å°å…¥ã—ãŸã„ã¨ãã«ä½¿ãˆã‚‹ã‹ã‚‚?</p>
<p>äº‹å‰å­¦ç¿’ã—ãŸLLaMA Blockã«å¯¾ã—ã¦ã€è¿½åŠ ã®LLaMA Blockã‚’stackã—ã€ã‚‚ã¨ã‚‚ã¨ã®LLaMA Blockã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’freezeã—ãŸä¸Šã§ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ç‰¹åŒ–ã—ãŸã‚³ãƒ¼ãƒ‘ã‚¹ã§äº‹å¾Œå­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€è¿½åŠ ã®çŸ¥è­˜ã‚’æŒ¿å…¥ã™ã‚‹ã€‚LLaMA Blockã‚’æŒ¿å…¥ã™ã‚‹ã¨ãã¯ã€Linear Layerã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’0ã«ã™ã‚‹ã“ã¨ã§ã€RMSNormã«ãŠã‘ã‚‹å‹¾é…æ¶ˆå¤±ã®å•é¡Œã‚’é¿ã‘ãŸä¸Šã§ã€Identity Blockï¼ˆBlockã‚’è¿½åŠ ã—ãŸæ™‚ç‚¹ã§ã¯äº‹å‰å­¦ç¿’æ™‚ã¨åŒæ§˜ã®OutputãŒã•ã‚Œã‚‹ã“ã¨ãŒä¿è¨¼ã•ã‚Œã‚‹ï¼‰ã¨ã—ã¦æ©Ÿèƒ½ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0ef6cc84-da38-4254-9bb3-ea4e2f9ebfab" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a2bb221a-3ac3-4b81-9308-c114daf00401" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2024-01-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1217" target="_blank" rel="noopener noreferrer" class="title-link">A Comprehensive Survey of Hallucination Mitigation Techniques in Large  Language Models, S. M Towhidul Islam Tonmoy+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ï¼šæœ¬è«–æ–‡ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã‘ã‚‹å¹»è¦šã®å•é¡Œã«ã¤ã„ã¦èª¿æŸ»ã—ã€ãã®è»½æ¸›ç­–ã«ã¤ã„ã¦ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚LLMsã¯å¼·åŠ›ãªè¨€èªç”Ÿæˆèƒ½åŠ›ã‚’æŒã£ã¦ã„ã¾ã™ãŒã€æ ¹æ‹ ã®ãªã„æƒ…å ±ã‚’ç”Ÿæˆã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€Retrieval Augmented Generationã€Knowledge Retrievalã€CoNLIã€CoVeãªã©ã®æŠ€è¡“ãŒé–‹ç™ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ©ç”¨ã‚„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãªã©ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã“ã‚Œã‚‰ã®æ–¹æ³•ã‚’åˆ†é¡ã—ã€å¹»è¦šã®å•é¡Œã«å–ã‚Šçµ„ã‚€ãŸã‚ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ã“ã‚Œã‚‰ã®æŠ€è¡“ã«é–¢é€£ã™ã‚‹èª²é¡Œã‚„åˆ¶ç´„ã«ã¤ã„ã¦ã‚‚åˆ†æã—ã€å°†æ¥ã®ç ”ç©¶ã«å‘ã‘ãŸåŸºç›¤ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2024-01-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1216" target="_blank" rel="noopener noreferrer" class="title-link">Chain-of-Table: Evolving Tables in the Reasoning Chain for Table   Understanding, Zilong Wang+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã‚’ä½¿ç”¨ã—ãŸChain-of-Tableãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æ¨è«–ãƒã‚§ãƒ¼ãƒ³å†…ã§æ´»ç”¨ã—ã€ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ™ãƒ¼ã‚¹ã®æ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦é«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®é€£ç¶šçš„ãªé€²åŒ–ã‚’è¡¨ç¾ã—ã€ä¸­é–“çµæœã®æ§‹é€ åŒ–æƒ…å ±ã‚’åˆ©ç”¨ã—ã¦ã‚ˆã‚Šæ­£ç¢ºãªäºˆæ¸¬ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚ã•ã¾ã–ã¾ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Table, Question, Operation Historyã‹ã‚‰æ¬¡ã®operationã¨ãã®argsã‚’ç”Ÿæˆã—ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é †æ¬¡æ›´æ–°ã—ã€ã“ã‚Œã‚’ãƒ¢ãƒ‡ãƒ«ãŒæ›´æ–°ã®å¿…è¦ãŒç„¡ã„ã¨åˆ¤æ–­ã™ã‚‹ã¾ã§ç¹°ã‚Šè¿”ã™ã€‚æœ€çµ‚çš„ã«æ›´æ–°ã•ã‚ŒãŸTableã‚’ç”¨ã„ã¦Questionã«å›ç­”ã™ã‚‹æ‰‹æ³•ã€‚Questionã«å›ç­”ã™ã‚‹ãŸã‚ã«ã€è¤‡é›‘ãªãƒ†ãƒ¼ãƒ–ãƒ«ã«å¯¾ã™ã‚‹æ“ä½œãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦æœ‰åŠ¹ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/f23bdacf-ffc0-4d37-b992-62fea094c9d2" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/90ec4404-7ed0-4698-8223-15134b195977" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-01-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1214" target="_blank" rel="noopener noreferrer" class="title-link">Leveraging Large Language Models for NLG Evaluation: A Survey, Zhen Li+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ãŸè‡ªç„¶è¨€èªç”Ÿæˆï¼ˆNLGï¼‰ã®è©•ä¾¡ã«ã¤ã„ã¦ã®åŒ…æ‹¬çš„ãªæ¦‚è¦ã‚’æä¾›ã—ã¾ã™ã€‚æ—¢å­˜ã®è©•ä¾¡æŒ‡æ¨™ã‚’æ•´ç†ã—ã€LLMãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã‚’æ¯”è¼ƒã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚ã•ã‚‰ã«ã€æœªè§£æ±ºã®èª²é¡Œã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã€ã‚ˆã‚Šå…¬æ­£ã§é«˜åº¦ãªNLGè©•ä¾¡æŠ€è¡“ã‚’æå”±ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>é‡è¦</p>
<p>NLGã®è©•ä¾¡ã‚’ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ã—ã¦ã€BERTScoreã®ã‚ˆã†ãªreferenceã¨hvpothesisã®distiebuted representationåŒå£«ã‚’æ¯”è¼ƒã™ã‚‹ã‚ˆã†ãªæ‰‹æ³•ï¼ˆmatching-basedï¼‰ã¨ã€æ€§èƒ½æŒ‡æ¨™ã‚’ç›´æ¥ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ç”Ÿæˆã™ã‚‹generative-basedãªæ‰‹æ³•ãŒã‚ã‚‹ã‚ˆã€<br><img src="https://github.com/user-attachments/assets/b6b4de14-a83b-4138-92f4-c6606451f272" alt="image" loading="lazy"><br><br>ã¨ã„ã£ãŸè©±ã‚„ã€ãã‚‚ãã‚‚reference-basedãªãƒ¡ãƒˆãƒªãƒƒã‚¯ï¼ˆe.g. BLEUï¼‰ã‚„ã€reference-freeãªãƒ¡ãƒˆãƒªãƒƒã‚¯ï¼ˆe.g. BARTScoreï¼‰ã¨ã¯ãªã‚“ãã‚„ï¼Ÿã¿ãŸã„ãªåŸºç¤çš„ãªè©±ã‹ã‚‰ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®è©•ä¾¡æ‰‹æ³•ã®ä»£è¡¨çš„ãªã‚‚ã®ã ã‘ã§ãªãã€ã‚¿ã‚¹ã‚¯ã”ã¨ã®æ‰‹æ³•ã‚‚æ•´ç†ã•ã‚Œã¦è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚ã¾ãŸã€BLEUã‚„ROUGEã¨ã„ã£ãŸä¼çµ±çš„ãªæ‰‹æ³•ã®æ¦‚è¦ã‚„ã€æœ€æ–°æ‰‹æ³•ã¨ã®åŒä¸€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ãƒ¡ã‚¿è©•ä¾¡ã«ãŠã‘ã‚‹æ€§èƒ½ã®å·®ãªã©ã‚‚è¨˜è¼‰ã•ã‚Œã¦ãŠã‚Šã€å…¨ä½“çš„ã«å¿…è¦ãªæƒ…å ±ãŒã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«ã¾ã¨ã¾ã£ã¦ã„ã‚‹å°è±¡ãŒã‚ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/dd9e49ee-5b08-45c4-9b82-2b9dcae12baa" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/a1a0708d-4f95-46ba-bda1-7c06c4c393cf" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2024-01-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1213" target="_blank" rel="noopener noreferrer" class="title-link">Knowledge Fusion of Large Language Models, Fanqi Wan+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ—¢å­˜ã®äº‹å‰è¨“ç·´æ¸ˆã¿ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§ã€1ã¤ã®å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ç•°ãªã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æŒã¤3ã¤ã®äººæ°—ã®ã‚ã‚‹LLMsã‚’ä½¿ç”¨ã—ã¦ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã‚¿ã‚¹ã‚¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã—ã¾ã—ãŸã€‚ææ¡ˆæ‰‹æ³•ã®ã‚³ãƒ¼ãƒ‰ã€ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã€ãŠã‚ˆã³ãƒ‡ãƒ¼ã‚¿ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2024-01-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1212" target="_blank" rel="noopener noreferrer" class="title-link">Self-Rewarding Language Models, Weizhe Yuan+, N_A, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- å°†æ¥ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯è¶…äººçš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒå¿…è¦ã§ã‚ã‚Šã€è‡ªå·±å ±é…¬ã‚’æä¾›ã™ã‚‹Self-Rewarding Language Modelsã‚’ç ”ç©¶ã—ã¦ã„ã‚‹ã€‚LLM-as-a-Judgeãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€è¨€èªãƒ¢ãƒ‡ãƒ«è‡ªä½“ãŒè‡ªå·±å ±é…¬ã‚’æä¾›ã—ã€é«˜å“è³ªãªå ±é…¬ã‚’å¾—ã‚‹èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚Llama 2 70Bã‚’3å›ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§å¾®èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€æ—¢å­˜ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’ä¸Šå›ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã“ã®ç ”ç©¶ã¯ã€æ”¹å–„å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®å¯èƒ½æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>äººé–“ã®ä»‹å…¥ç„¡ã—ã§ï¼ˆäººé–“ãŒã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ãŸpreference dataç„¡ã—ã§ï¼‰LLMã®Alignmentã‚’æ”¹å–„ã—ã¦ã„ãæ‰‹æ³•ã€‚LLM-as-a-Judge Promptingã‚’ç”¨ã„ã¦ã€LLMè‡ªèº«ã«policy modelã¨reward modelã®å½¹å‰²ã®ä¸¡æ–¹ã‚’ã•ã›ã‚‹ã€‚unlabeledãªpromptã«å¯¾ã—ã¦policy modelã¨ã—ã¦responceã‚’ç”Ÿæˆã•ã›ãŸå¾Œã€ç”Ÿæˆã—ãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’reward modelã¨ã—ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»˜ã‘ã—ã€DPOã®preference pairã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã€ã¨ã„ã†æ“ä½œã‚’ç¹°ã‚Šè¿”ã™ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/32db0422-6fb1-4741-bdfa-45a5e83e76c4" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2024-01-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1210" target="_blank" rel="noopener noreferrer" class="title-link">Transformers are Multi-State RNNs, Matanel Oren+, N_A, EMNLP'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã¯ç„¡é™ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ãƒˆRNNã¨ã—ã¦æ¦‚å¿µåŒ–ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã€æœ‰é™ã®ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ãƒˆRNNã«å¤‰æ›ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ã•ã‚‰ã«ã€æ–°ã—ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥åœ§ç¸®ãƒãƒªã‚·ãƒ¼ã§ã‚ã‚‹TOVAã‚’å°å…¥ã—ã€ä»–ã®ãƒãƒªã‚·ãƒ¼ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ã“ã¨ã‚’å®Ÿé¨“çµæœã§ç¤ºã—ã¾ã—ãŸã€‚TOVAã¯å…ƒã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã®1/8ã—ã‹ä½¿ç”¨ã›ãšã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼LLMãŒå®Ÿéš›ã«ã¯RNNã¨ã—ã¦æŒ¯ã‚‹èˆã†ã“ã¨ãŒå¤šã„ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Transformerã¯RNNã¨ã¯ç•°ãªã‚‹æ¦‚å¿µã€ç‰¹ã«å…¨ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®æƒ…å ±ã«ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã¨ã„ã†ã“ã¨ã§åŒºåˆ¥ã•ã‚Œã¦ããŸãŒã€ã‚ˆãã‚ˆãè€ƒãˆã¦ã¿ã‚‹ã¨ã€Transformer Decoderã¯ã€RNNã®hidden_states h ã‚’ï¼ˆhã¯1ã¤ã®stateã‚’ãƒ™ã‚¯ãƒˆãƒ«ã§è¡¨ã—ã¦ã„ã‚‹ï¼‰ã€multi-stateã‚’è¡¨ã™ matrix H ï¼ˆtå€‹ã®stateã‚’è¡¨ã™matrix; tã¯ç¾åœ¨ã®ç€ç›®ã—ã¦ã„ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã¾ã§ã®sequenceã®é•·ã•ï¼‰ã§ç½®ãæ›ãˆãŸã‚‚ã® Multi-State-RNN (MSRNN) ã¨è§£é‡ˆã§ãã‚‹ã€ã¨ã„ã†è©±ã€‚<br>ã¾ãŸã€window attentionãªã©ã®attentionã®è¨ˆç®—ã§è€ƒæ…®ã™ã‚‹KV cacheã®ã‚¹ãƒ‘ãƒ³ã‚’ï¼ˆãƒ¡ãƒ¢ãƒªã‚’ç¯€ç´„ã™ã‚‹ãŸã‚ã«ï¼‰åˆ¶é™ã™ã‚‹åœ§ç¸®æ‰‹æ³•ã¯ã€å…ˆã»ã©ã®MSRNNã¯å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã®state ï¼ˆKV Cacheï¼‰ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ï¼ˆ= Unboundedï¼‰ã¨è€ƒãˆã‚‹ã¨ã€ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã®stateãŒ k (&lt;t) ã¨ãªã‚‹ãŸã‚ã€BoundedãªMSRNNã¨ã¿ãªã›ã‚‹ã€‚<br>ã—ãŸãŒã£ã¦ã€ç¾åœ¨ã®LLMã¯Transformer Decoderã‚’ç©ã¿ä¸Šã’ãŸã‚‚ã®ã§ã‚ã‚‹ã‚‚ã®ã§ã‚ã‚Šã€åŸç†ä¸Šã¯inference/trainingæ™‚ã«å…¨ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è€ƒæ…®ã§ãã‚‹ãŸã‚ã€åŸç†ä¸Šã¯UnboundedãªMSRNNã¨ã¿ãªã›ã‚‹ã€‚ä¸€æ–¹ã€ã“ã“ã«ãƒ¡ãƒ¢ãƒªã®åˆ¶ç´„ãŒåŠ ã‚ã‚‹ã¨KV Cacheã‚’åœ§ç¸®ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ãŸã‚ã€å®Ÿç”¨ä¸Šã¯BoundedãªMSRNNã¨ãªã£ã¦ã„ã‚‹ã€‚<br><br>&lt;img width="476" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/292bd370-0138-441a-a626-ee73cb2f31b5"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/292bd370-0138-441a-a626-ee73cb2f31b5"&lt;/a&gt;


/&gt;<br><br>å®Ÿéš›ã«å¼ã§è¡¨ã™ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«RNNã¨Transformerã¯å¯¾å¿œã¥ã‘ã‚‰ã‚Œã‚‹ã€‚<br>&lt;img width="402" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/3b2cbadc-e6ef-4465-ac78-bb4ff71351f2"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/3b2cbadc-e6ef-4465-ac78-bb4ff71351f2"&lt;/a&gt;


/&gt;<br>&lt;img width="487" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/18a99f2a-06dc-472c-b50d-743b820904f3"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/18a99f2a-06dc-472c-b50d-743b820904f3"&lt;/a&gt;


/&gt;<br><br>ã“ã®ã“ã¨ã‚’è€ƒæ…®ã—ã¦ã€æœ¬ç ”ç©¶ã§ã¯TOVAã¨å‘¼ã°ã‚Œã‚‹æ–°ã—ã„KV Cacheã®åœ§ç¸®æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚éå¸¸ã«ã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ³•ã§ã€KV CacheãŒãƒ¡ãƒ¢ãƒªã®ä¸Šé™ã«åˆ°é”ã—ãŸã¨ãã«ã€ãã®éš›ã«attention scoreãŒæœ€ã‚‚å°ã•ã„ãƒˆãƒ¼ã‚¯ãƒ³ã®KV Cacheã‚’æ¨ã¦ã‚‹ã€ã¨ã„ã†æ‰‹æ³•ã§ã‚ã‚‹ã€‚<br>&lt;img width="495" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/09f19caf-bcea-42f7-b1e0-8bc3ea8a2e4c"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/09f19caf-bcea-42f7-b1e0-8bc3ea8a2e4c"&lt;/a&gt;


/&gt;<br><br>TOVAã‚’window attentionãªã©ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã‚ªãƒ©ã‚¯ãƒ«ã¨ã—ã¦full attentionã¨æ¯”è¼ƒã€‚ã‚¿ã‚¹ã‚¯ã¯ Language Modelingï¼ˆPG-19ãƒ‡ãƒ¼ã‚¿ã«ãŠã‘ã‚‹Perplexityï¼‰ã€Language Understanding ï¼ˆlong contextã‹ã‚‰relevantãªæƒ…å ±ã‚’æ‹¾ã†å¿…è¦ãŒã‚ã‚‹QAï¼‰ã€Story Generationï¼ˆé•·æ–‡ã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’æ›¸ã‹ã›ã¦GPT4ã«ã‚ˆã£ã¦pair-wiseã§ç”Ÿæˆã•ã‚ŒãŸã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®å“è³ªã‚’LLM-as-a-Judgeã•ã›ã‚‹ï¼‰ã‚’åˆ©ç”¨ã€‚æ—¢å­˜ã®KV Cacheåœ§ç¸®æ‰‹æ³•ã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã«KV Cacheã‚’åœ§ç¸®ã§ãã€4096 context windowã®å ´åˆã¯ã€512ç¨‹åº¦ã§full attentionã¨è¿‘ã„æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é«˜ã„ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å®Ÿç¾ã§ãã‚‹ã€‚ã“ã“ã§ã€ã‚°ãƒ©ãƒ•ã®xè»¸ã®multistateã¯TOVAã«ãŠã„ã¦ã¯matrix Hã§ä¿æŒã™ã‚‹stateæ•°ã«ç›¸å½“ã—ã€window attentionã§ã¯ã€window sizeã«ç›¸å½“ã™ã‚‹ã€‚<br>&lt;img width="815" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/fd39d465-3a0d-49ad-951b-fddb115394f3"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/fd39d465-3a0d-49ad-951b-fddb115394f3"&lt;/a&gt;


/&gt;<br><br>&lt;img width="636" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/c66bade9-f0c4-476b-8243-bd1d88e21ead"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/c66bade9-f0c4-476b-8243-bd1d88e21ead"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2024-01-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1208" target="_blank" rel="noopener noreferrer" class="title-link">The Impact of Reasoning Step Length on Large Language Models, Mingyu Jin+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Chain of Thoughtï¼ˆCoTï¼‰ã®æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã®é•·ã•ã¨LLMsã®æ¨è«–èƒ½åŠ›ã®é–¢ä¿‚ã‚’èª¿æŸ»ã—ãŸã€‚æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’å»¶é•·ã™ã‚‹ã¨ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ–°ã—ã„æƒ…å ±ã‚’è¿½åŠ ã›ãšã«LLMsã®æ¨è«–èƒ½åŠ›ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚é€†ã«ã€ã‚­ãƒ¼ã¨ãªã‚‹æƒ…å ±ã‚’ä¿æŒã—ãªãŒã‚‰æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’çŸ­ç¸®ã™ã‚‹ã¨ã€æ¨è«–èƒ½åŠ›ãŒä½ä¸‹ã™ã‚‹ã€‚ã¾ãŸã€èª¤ã£ãŸæ ¹æ‹ ã§ã‚‚æ¨è«–ã®å¿…è¦ãªé•·ã•ã‚’ä¿ã¤é™ã‚Šã€å¥½ã¾ã—ã„çµæœãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚ã•ã‚‰ã«ã€ã‚¿ã‚¹ã‚¯ã«ã‚ˆã£ã¦æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã®å¢—åŠ ã®åˆ©ç‚¹ãŒç•°ãªã‚‹ã“ã¨ã‚‚è¦³å¯Ÿã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-01-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1204" target="_blank" rel="noopener noreferrer" class="title-link">Mixtral of Experts, Albert Q. Jiang+, N_A, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- Mixtralã¯ã€Sparse Mixture of Expertsï¼ˆSMoEï¼‰è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒ8ã¤ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚Mixtralã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ã«2ã¤ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’é¸æŠã—ã€ãã‚Œã‚‰ã®å‡ºåŠ›ã‚’çµ„ã¿åˆã‚ã›ã¾ã™ã€‚Mixtralã¯ã€Llama 2 70Bã¨GPT-3.5ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’æŒã¡ã€æ•°å­¦ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã€å¤šè¨€èªã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ç‰¹ã«å„ªã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€Mixtral 8x7B - Instructã¨ã„ã†æŒ‡ç¤ºã«å¾“ã†ãƒ¢ãƒ‡ãƒ«ã‚‚æä¾›ã•ã‚Œã¦ãŠã‚Šã€äººé–“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å‡Œé§•ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Mixture of experts Layer: inputã‚’å—ã‘å–ã£ãŸrouterãŒã€8ã¤ã®expertsã®ã†ã¡2ã¤ã‚’é¸æŠã—é †ä¼æ¬ã€‚2ã¤ã®expertsã®outputã‚’åŠ é‡å¹³å‡ã™ã‚‹ã“ã¨ã§æœ€çµ‚çš„ãªoutputã¨ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/52ca3ed3-714f-4bc2-af76-c6884fc37927" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2023-12-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1202" target="_blank" rel="noopener noreferrer" class="title-link">Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision,   Language, Audio, and Action, Jiasen Lu+, N_A, CVPR'24</a>
<span class="snippet"><span>GPT Summary</span>- Unified-IO 2ã¯ã€æœ€åˆã®è‡ªå·±å›å¸°å‹ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ç”»åƒã€ãƒ†ã‚­ã‚¹ãƒˆã€éŸ³å£°ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç†è§£ã—ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’çµ±ä¸€ã™ã‚‹ãŸã‚ã«ã€å…±æœ‰ã®æ„å‘³ç©ºé–“ã«å…¥åŠ›ã¨å‡ºåŠ›ã‚’é…ç½®ã—ã€å˜ä¸€ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã§å‡¦ç†ã—ã¾ã™ã€‚ã•ã¾ã–ã¾ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ”¹å–„ã‚’ææ¡ˆã—ã€å¤§è¦æ¨¡ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªäº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚Unified-IO 2ã¯ã€GRITãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å«ã‚€35ä»¥ä¸Šã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç”»åƒã€ãƒ†ã‚­ã‚¹ãƒˆã€éŸ³å£°ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç†è§£ã§ãã‚‹åˆã‚ã¦ã®autoregressive modelã€‚AllenAI</p>
<p>ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³<br><img src="https://github.com/user-attachments/assets/4282ffb0-18f1-40c9-b6d7-f004d03b8382" alt="image" loading="lazy"><br><br>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã«æ‹¡å¼µã—ãŸã“ã¨ã§ã€è¨“ç·´ãŒéå¸¸ã«ä¸å®‰å®šã«ãªã£ãŸãŸã‚ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¸Šã§ã„ãã¤ã‹ã®å·¥å¤«ã‚’åŠ ãˆã¦ã„ã‚‹:<br><br>- 2D Rotary Embedding<br>  - Positional Encodingã¨ã—ã¦RoPEã‚’æ¡ç”¨<br>  - ç”»åƒã®ã‚ˆã†ãª2æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®å ´åˆã¯RoPEã‚’2æ¬¡å…ƒã«æ‹¡å¼µã™ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€ä½ç½®(i, j)ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«ã¤ã„ã¦ã¯ã€Q, Kã®embeddingã‚’åŠåˆ†ã«åˆ†å‰²ã—ã¦ã€ãã‚Œãã‚Œã«å¯¾ã—ã¦ç‹¬ç«‹ã«i, jã®RoPE Embeddingã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§i, jåŒæ–¹ã®æƒ…å ±ã‚’çµ„ã¿è¾¼ã‚€ã€‚<br>- QK Normalization<br>  - image, audioã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§MHAã®logitsãŒéå¸¸ã«å¤§ãããªã‚Šatteetion weightãŒ0/1ã®æ¥µç«¯ãªå€¤ã‚’ã¨ã‚‹ã‚ˆã†ã«ãªã‚Šè¨“ç·´ã®ä¸å®‰å®šã•ã«ã¤ãªãŒã£ãŸã€‚ã“ã®ãŸã‚ã€dot product attentionã‚’é©ç”¨ã™ã‚‹å‰ã«LayerNormã‚’çµ„ã¿è¾¼ã‚“ã ã€‚<br>- Scaled Cosine Attention<br>  - Image Historyãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«ãŠã„ã¦å›ºå®šé•·ã®Embeddingã‚’å¾—ã‚‹ãŸã‚ã«Perceiver Resamplerã‚’æ‰±ã£ãŸã¦ã„ã‚‹ãŒã€ã“ã¡ã‚‰ã‚‚ä¸Šè¨˜ã¨åŒæ§˜ã«Attentionã®logitsãŒæ¥µç«¯ã«å¤§ãããªã£ãŸãŸã‚ã€cosineé¡ä¼¼åº¦ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸScaled Cosine Attention <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2259" target="_blank" rel="noopener noreferrer">[Paper Note] Swin Transformer V2: Scaling Up Capacity and Resolution, Ze Liu+, arXiv'21</a>
 ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€å¤§å¹…ã«è¨“ç·´ã®å®‰å®šæ€§ãŒæ”¹å–„ã•ã‚ŒãŸã€‚<br>- ãã®ä»–<br>  - attention logitsã«ã¯fp32ã‚’é©ç”¨<br>  - äº‹å‰å­¦ç¿’ã•ã‚ŒãŸViTã¨ASTã‚’åŒæ™‚ã«æ›´æ–°ã™ã‚‹ã¨ä¸å®‰å®šã«ã¤ãªãŒã£ãŸãŸã‚ã€äº‹å‰å­¦ç¿’ã®æ®µéšã§ã¯freezeã—ã€instruction tuningã®æœ€å¾Œã«finetuningã‚’å®Ÿæ–½<br><br><img src="https://github.com/user-attachments/assets/74c8fa3a-8fb5-4785-8dd3-6a8cf3c7cfeb" alt="image" loading="lazy"></p>
<p>ç›®çš„é–¢æ•°ã¨ã—ã¦ã¯ã€Mixture of Denoisers (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1424" target="_blank" rel="noopener noreferrer">UL2: Unifying Language Learning Paradigms, Yi Tay+, N/A, ICLR'23</a>
)ã«ç€æƒ³ã‚’å¾—ã¦ã€Multimodal Mixture of Denoisersã‚’ææ¡ˆã€‚MoDã§ã¯ã€<br>- \[R\]: é€šå¸¸ã®span corruption (1--5 tokenç¨‹åº¦ã®spanã‚’maskã™ã‚‹)<br>- \[S\]: causal language modeling (inputã‚’2ã¤ã®ã‚µãƒ–ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«åˆ†å‰²ã—ã€å‰æ–¹ã‹ã‚‰å¾Œæ–¹ã‚’äºˆæ¸¬ã™ã‚‹ã€‚å‰æ–¹éƒ¨åˆ†ã¯Bi-directionalã§ã‚‚å¯)<br>- \[X\]: extreme span corruption (12&gt;=tokenç¨‹åº¦ã®spanã‚’maskã™ã‚‹)<br><br>ã®3ç¨®é¡ãŒææ¡ˆã•ã‚Œã¦ãŠã‚Šã€ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã”ã¨ã«ã“ã‚Œã‚‰ã‚’ä½¿ã„åˆ†ã‘ã‚‹:<br>- text modality: UL2 (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1424" target="_blank" rel="noopener noreferrer">UL2: Unifying Language Learning Paradigms, Yi Tay+, N/A, ICLR'23</a>
)ã‚’è¸è¥²<br>- image, audioãŒtargetã®å ´åˆ: 2ã¤ã®é¡ä¼¼ã—ãŸãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’å®šç¾©ã—åˆ©ç”¨<br>  - \[R\]: patchã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«x%ãƒã‚¹ã‚¯ã—re-constructã™ã‚‹<br>  - \[S\]: inputã®targetã¨ã¯ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®ã¿ã®æƒ…å ±ã‹ã‚‰ã€targetãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’ç”Ÿæˆã™ã‚‹<br><br>è¨“ç·´æ™‚ã«ã¯ prefixã¨ã—ã¦modality token \[Text\], \[Image\], \[Audio\] ã¨paradigm token \[R\], \[S\], \[X\] ã‚’ã‚¿ã‚¹ã‚¯ã‚’æŒ‡ç¤ºã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦åˆ©ç”¨ã—ã¦ã„ã‚‹ã€‚</p>
<p>ã¾ãŸã€image, audioã®ãƒã‚¹ã‚¯éƒ¨åˆ†ã®denoisingã‚’autoregressive modelã§å®Ÿæ–½ã™ã‚‹éš›ã«ã¯æ™®é€šã«ã‚„ã‚‹ã¨decoderå´ã§ãƒªãƒ¼ã‚¯ãŒç™ºç”Ÿã™ã‚‹(a)ã€‚ã“ã‚Œã‚’é˜²ãã«ã¯ã€Encoderå´ã§ãƒã‚¹ã‚¯ã•ã‚Œã¦ã„ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã€Decoderå´ã§teacher-forcingã™ã‚‹éš›ã«ã®å…¨ã¦ãƒã‚¹ã‚¯ã™ã‚‹æ–¹æ³•(b)ãŒã‚ã‚‹ãŒã€ã“ã®å ´åˆã€ç”Ÿæˆã‚¿ã‚¹ã‚¯ã¨denoisingã‚¿ã‚¹ã‚¯ãŒç›¸äº’ã«å¹²æ¸‰ã—ã¦ã—ã¾ã„ã†ã¾ãå­¦ç¿’ã§ããªããªã£ã¦ã—ã¾ã†ï¼ˆç”Ÿæˆã‚¿ã‚¹ã‚¯ã§ã¯é€šå¸¸Decoderã®inputã¨ã—ã¦[mask]ãŒå…¥åŠ›ã•ã‚Œæ¬¡ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã¯èµ·ããˆãªã„ãŒã€æ„šç›´ã«(b)ã‚’ã‚„ã‚‹ã¨ãã†ãªã£ã¦ã—ã¾ã†ï¼‰ã€‚ã®ã§ã€(c)ã«ç¤ºã—ãŸã‚ˆã†ã«ã€ãƒã‚¹ã‚¯ã•ã‚Œã¦ã„ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’inputã¨ã—ã¦ç”Ÿæˆã—ãªã‘ã‚Œã°ãªã‚‰ãªã„æ™‚ã ã‘ã€ãƒã‚¹ã‚¯ã‚’è§£é™¤ã—ã¦decoderå´ã«inputã™ã‚‹ã€ã¨ã„ã†æ–¹æ³• (Dynamic Masking) ã§ã“ã®å•é¡Œã«å¯¾å‡¦ã—ã¦ã„ã‚‹ã€‚<br>&lt;img width="597" height="394" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/0dba8d5d-0c93-4c56-852b-fce9869428e7"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0dba8d5d-0c93-4c56-852b-fce9869428e7"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2023-12-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1186" target="_blank" rel="noopener noreferrer" class="title-link">VILA: On Pre-training for Visual Language Models, Ji Lin+, N_A, CVPR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æˆåŠŸã«ã‚ˆã‚Šã€ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆVLMï¼‰ãŒé€²æ­©ã—ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€VLMã®äº‹å‰å­¦ç¿’ã®ãŸã‚ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æ¤œè¨ã—ã€ä»¥ä¸‹ã®çµæœã‚’ç¤ºã—ãŸï¼š(1) LLMã‚’å‡çµã™ã‚‹ã“ã¨ã§ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒé”æˆã§ãã‚‹ãŒã€æ–‡è„ˆã«åŸºã¥ã„ãŸå­¦ç¿’èƒ½åŠ›ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚(2) äº¤äº’ã«è¡Œã‚ã‚Œã‚‹äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯æœ‰ç›Šã§ã‚ã‚Šã€ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã®ãƒšã‚¢ã ã‘ã§ã¯æœ€é©ã§ã¯ãªã„ã€‚(3) ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã‚’ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã«å†ãƒ–ãƒ¬ãƒ³ãƒ‰ã™ã‚‹ã“ã¨ã§ã€VLMã®ã‚¿ã‚¹ã‚¯ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚VILAã¨ã„ã†ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’æ§‹ç¯‰ã—ã€æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã‚’å‡Œé§•ã—ã€å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã®äº‹å‰å­¦ç¿’ã¯ã€VILAã®ç‰¹æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1068" target="_blank" rel="noopener noreferrer">Improved Baselines with Visual Instruction Tuning, Haotian Liu+, N/A, CVPR'24</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<a class="button" href="articles/EACL.html" target="_blank" rel="noopener noreferrer">#EACL</a>
<a class="button" href="articles/System%20Demonstration.html" target="_blank" rel="noopener noreferrer">#System Demonstration</a>
<span class="issue_date">Issue Date: 2023-11-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1161" target="_blank" rel="noopener noreferrer" class="title-link">NeuroPrompts: An Adaptive Framework to Optimize Prompts for  Text-to-Image Generation, Shachar Rosenman+, N_A, EACL'24 Sustem Demonstration Track</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®å“è³ªã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®é©å¿œå‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯NeuroPromptsã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦åˆ¶ç´„ä»˜ããƒ†ã‚­ã‚¹ãƒˆãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è¡Œã„ã€äººé–“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒç”Ÿæˆã™ã‚‹ã‚‚ã®ã«é¡ä¼¼ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é«˜å“è³ªãªãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸ã®ç”ŸæˆãŒå¯èƒ½ã¨ãªã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã‚¹ã‚¿ã‚¤ãƒ«ã®ç‰¹å¾´ã‚’åˆ¶å¾¡ã§ãã¾ã™ã€‚ã¾ãŸã€å¤§è¦æ¨¡ãªäººé–“ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ãŸå®Ÿé¨“ã«ã‚ˆã‚Šã€å½“ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒè‡ªå‹•çš„ã«å“è³ªã®é«˜ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã€å„ªã‚ŒãŸç”»åƒå“è³ªã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2023-11-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1155" target="_blank" rel="noopener noreferrer" class="title-link">GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark, David Rein+, N_A, COLM'24</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€é«˜å“è³ªã§éå¸¸ã«å›°é›£ãªå¤šè‚¢é¸æŠå•é¡Œã‹ã‚‰ãªã‚‹GPQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€å°‚é–€å®¶ã§ã‚‚é«˜ã„æ­£ç­”ç‡ã‚’é”æˆã§ããšã€æœ€å…ˆç«¯ã®AIã‚·ã‚¹ãƒ†ãƒ ã§ã‚‚å›°é›£ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚å°†æ¥ã®AIã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã«ãŠã„ã¦ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªç›£ç£æ–¹æ³•ã‚’é–‹ç™ºã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¹ã‚­ãƒ«ã‚’æŒã¤ç›£ç£è€…ãŒAIã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ä¿¡é ¼æ€§ã®ã‚ã‚‹æƒ…å ±ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚GPQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªç›£ç£å®Ÿé¨“ã‚’å¯èƒ½ã«ã—ã€äººé–“ã®å°‚é–€å®¶ãŒAIã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰çœŸå®Ÿã®æƒ…å ±ã‚’ç¢ºå®Ÿã«å¾—ã‚‹æ–¹æ³•ã‚’è€ƒæ¡ˆã™ã‚‹ã®ã«å½¹ç«‹ã¤ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>è©²å½“é ˜åŸŸã®Ph.Dæ‰€æœ‰è€…ã§ã‚‚74%ã€é«˜ã„ã‚¹ã‚­ãƒ«ã‚’æŒã¤éå°‚é–€å®¶ï¼ˆGoogleã¸ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦è‰¯ã„ç’°å¢ƒï¼‰ã§34%ã—ã‹æ­£ç­”ã§ããªã„QAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚<br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/idavidrein/status/1727033002234909060?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=Ti67584b98" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Ti67584b98</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2023-11-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1140" target="_blank" rel="noopener noreferrer" class="title-link">Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language   Models, Wenhao Yu+, N_A, EMNLP'24</a>
<span class="snippet"><span>GPT Summary</span>- æ¤œç´¢è£œå®Œè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆRALMï¼‰ã¯ã€å¤–éƒ¨ã®çŸ¥è­˜æºã‚’æ´»ç”¨ã—ã¦å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ä¿¡é ¼æ€§ã®å•é¡Œã‚„çŸ¥è­˜ã®ä¸è¶³ã«ã‚ˆã‚‹èª¤ã£ãŸå›ç­”ãŒã‚ã‚‹ã€‚ãã“ã§ã€Chain-of-Notingï¼ˆCoNï¼‰ã¨ã„ã†æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å°å…¥ã—ã€RALMã®é ‘å¥æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚CoNã¯ã€é †æ¬¡ã®èª­ã¿å–ã‚Šãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã€é–¢é€£æ€§ã‚’è©•ä¾¡ã—ã¦æœ€çµ‚çš„ãªå›ç­”ã‚’å½¢æˆã™ã‚‹ã€‚ChatGPTã‚’ä½¿ç”¨ã—ã¦CoNã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€å®Ÿé¨“çµæœã¯CoNã‚’è£…å‚™ã—ãŸRALMãŒæ¨™æº–çš„ãªRALMã‚’å¤§å¹…ã«ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ç‰¹ã«ã€ãƒã‚¤ã‚ºã®å¤šã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ãŠã„ã¦EMã‚¹ã‚³ã‚¢ã§å¹³å‡+7.9ã®æ”¹å–„ã‚’é”æˆã—ã€çŸ¥è­˜ç¯„å›²å¤–ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®è³ªå•ã«å¯¾ã™ã‚‹æ‹’å¦ç‡ã§+10.5ã®æ”¹å–„ã‚’é”æˆã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ¢ãƒ‡ãƒ«ã«æ¤œç´¢ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå¯¾ã™ã‚‹queryã®relevance/accuracyã®è¦³ç‚¹ã‹ã‚‰note-takingã‚’ã•ã›ã‚‹ã“ã¨ã§ã€RAGã®æ­£ç¢ºæ€§ã‚„é€æ˜æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ãŸã¨ãˆã°ã€<br>- surface-levelã®æƒ…å ±ã«ä¾å­˜ã›ãšã«ãƒ¢ãƒ‡ãƒ«ã«ç†è§£ã‚’ä¿ƒã™<br>- ç›¸åã™ã‚‹æƒ…å ±ãŒå­˜åœ¨ã—ã¦ã‚‚relevantãªæƒ…å ±ã‚’é©åˆ‡ã«è€ƒæ…®ã™ã‚‹,<br>- å›ç­”ãƒ—ãƒ­ã‚»ã‚¹ã®é€æ˜æ€§ãƒ»è§£é‡ˆæ€§ã‚’å‘ä¸Šã•ã›ã‚‹<br>- æ¤œç´¢ã•ã‚ŒãŸæ–‡æ›¸ã«å¯¾ã™ã‚‹éå‰°ãªä¾å­˜ã‚’ãªãã™ï¼ˆæ–‡æ›¸ãŒå¤ã„, ã‚ã‚‹ã„ã¯ãƒã‚¤ã‚¸ãƒ¼ãªå ´åˆã«æœ‰ç”¨ï¼‰<br>ãªã©ãŒåˆ©ç‚¹ã¨ã—ã¦æŒ™ã’ã‚‰ã‚Œã¦ã„ã‚‹ã€‚<br><br>ä¸‹è¨˜ãŒä»˜éŒ²ä¸­ã®CoNã§å®Ÿéš›ã«åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚<br>&lt;img width="389" height="542" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/4e1cc58f-da0b-41ca-a65f-c269c9835cf9"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/4e1cc58f-da0b-41ca-a65f-c269c9835cf9"&lt;/a&gt;


/&gt;<br><br>éå¸¸ã«ã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ³•ã ãŒã€çµæœã¨ã—ã¦ã¯ãƒã‚¤ã‚ºãŒå¤šã„å ´åˆã€CoNã«ã‚ˆã‚‹ã‚²ã‚¤ãƒ³ãŒå¤§ãã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br>&lt;img width="820" height="586" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/0029d110-b7ae-4f23-933f-13f30c12f87e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0029d110-b7ae-4f23-933f-13f30c12f87e"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2023-11-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1131" target="_blank" rel="noopener noreferrer" class="title-link">MEGAVERSE: Benchmarking Large Language Models Across Languages,   Modalities, Models and Tasks, Sanchit Ahuja+, N_A, NAACL'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®ç ”ç©¶ã¯æ€¥é€Ÿã«é€²å±•ã—ã¦ãŠã‚Šã€è‹±èªä»¥å¤–ã®è¨€èªã§ã®è©•ä¾¡ãŒå¿…è¦ã¨ã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¿½åŠ ã—ãŸMEGAVERSEãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ã•ã¾ã–ã¾ãªLLMsã‚’è©•ä¾¡ã™ã‚‹ã€‚å®Ÿé¨“ã®çµæœã€GPT4ã¨PaLM2ãŒå„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ãŸãŒã€ãƒ‡ãƒ¼ã‚¿ã®æ±šæŸ“ãªã©ã®å•é¡ŒãŒã‚ã‚‹ãŸã‚ã€ã•ã‚‰ãªã‚‹å–ã‚Šçµ„ã¿ãŒå¿…è¦ã§ã‚ã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<span class="issue_date">Issue Date: 2023-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1128" target="_blank" rel="noopener noreferrer" class="title-link">Prompt Engineering a Prompt Engineer, Qinyuan Ye+, N_A, ACL'24 Findings</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¯ã€LLMsã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚¿ã‚¹ã‚¯ã§ã‚ã‚Šã€æœ¬ç ”ç©¶ã§ã¯ãƒ¡ã‚¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã—ã¦è‡ªå‹•çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’è¡Œã„ã¾ã™ã€‚æ”¹å–„ã•ã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ã¤ãªãŒã‚‹æ¨è«–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ˜ç¤ºãªã©ã®è¦ç´ ã‚’å°å…¥ã—ã€ä¸€èˆ¬çš„ãªæœ€é©åŒ–æ¦‚å¿µã‚’ãƒ¡ã‚¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«çµ„ã¿è¾¼ã¿ã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã§ã‚ã‚‹PE2ã¯ã€ã•ã¾ã–ã¾ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„ã‚¿ã‚¹ã‚¯ã§å¼·åŠ›ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã€ä»¥å‰ã®è‡ªå‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã¾ã™ã€‚ã•ã‚‰ã«ã€PE2ã¯æ„å‘³ã®ã‚ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç·¨é›†ã‚’è¡Œã„ã€ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¯ãƒˆã®æ¨è«–èƒ½åŠ›ã‚’ç¤ºã—ã¾ã™ã€‚</span>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2023-10-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1110" target="_blank" rel="noopener noreferrer" class="title-link">Re-Reading Improves Reasoning in Language Models, Xiaohan Xu+, N_A, EMNLP'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã„ã¦ã€æ¨è«–ã¯é‡è¦ã§å›°é›£ãªå•é¡Œã§ã™ã€‚å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ã‚’é–‹ç™ºã™ã‚‹ã“ã¨ã«ç„¦ç‚¹ãŒå½“ã¦ã‚‰ã‚Œã¦ãã¾ã—ãŸãŒã€åŒæ–¹å‘ã®ç›¸äº’ä½œç”¨ã‚„è³ªå•ã®é‡è¦æ€§ã«ã¯æ³¨æ„ãŒæ‰•ã‚ã‚Œã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚ã“ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€è³ªå•ã®å†èª­ã¨ã„ã†æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ã‚’ææ¡ˆã—ã¾ã™ã€‚å†èª­ã¯ã€è³ªå•æƒ…å ±ã‚’å†è¨ªã™ã‚‹ã“ã¨ã§ã€LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ã“ã®æ‰‹æ³•ã®åŠ¹æœã¨æ±ç”¨æ€§ã‚’ç¤ºã—ã¦ãŠã‚Šã€LLMsã®é ˜åŸŸã§ã®ãã®æœ‰ç”¨æ€§ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å•é¡Œæ–‡ã‚’2,3å›promptã§ç¹°ã‚Šè¿”ã™ã ã‘ã§ã€æ•°å­¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨Commonsenseã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ€§èƒ½ãŒå‘ä¸Šã—ãŸã¨ã„ã†éå¸¸ã«ç°¡å˜ãªPromptingã€‚self-consistencyãªã©ã®ä»–ã®Promptingã¨ã®ä½µç”¨ã‚‚å¯èƒ½ã€‚<br>ãªãœæ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã‹ã¨ã„ã†ã¨ã€<br>1. LLMã¯Auporegressiveãªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€bidirectionalãªãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„ã€‚ã“ã®ãŸã‚ã€forwardãƒ‘ã‚¹ã®ã¿ã§ã¯èª­è§£åŠ›ã«é™ç•ŒãŒã‚ã‚‹ã€‚ï¼ˆãŸã¨ãˆã°äººé–“ã¯ã—ã°ã—ã°ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿è¿”ã—ãŸã‚Šã™ã‚‹ï¼‰ã€‚ãã“ã§ã€ä¸€åº¦ç›®ã®èª­è§£ã§æ¦‚è¦ã‚’ç†è§£ã—ã€äºŒåº¦ç›®ã®èª­è§£ã§salience partã‚’èª­ã¿è¾¼ã‚€ã¨ã„ã£ãŸã‚ˆã†ãªæŒ™å‹•ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šå•é¡Œæ–‡ã«å¯¾ã™ã‚‹ComprehensionãŒå‘ä¸Šã™ã‚‹ã€‚<br>2. LLMã¯ã—ã°ã—ã°promptã®é‡è¦ãªç®‡æ‰€ã®èª­è§£ã‚’æ¬ è½ã•ã›ã¦ã—ã¾ã†ã€‚ãŸã¨ãˆã°ã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/793" target="_blank" rel="noopener noreferrer">Lost in the Middle: How Language Models Use Long Contexts, Nelson F. Liu+, N/A, TACL'24</a>
 ã§ã¯ã€promptã®middle partã‚’è»½è¦–ã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã®ã‚ˆã†ãªç¾è±¡ã‚‚è»½æ¸›ã§ãã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e575e0aa-b76c-444e-b9b0-e984d6fc73cf" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1b2344fb-bfb4-467b-9dbb-05e4eff23d06" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fcaa2337-cfce-4e0c-b068-a7de2c0eff78" alt="image" loading="lazy"><br>å•é¡Œæ–‡ã®ç¹°ã‚Šè¿”ã—ã¯ã€3å›ã¾ã§ã¯æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e333e807-24d4-4a64-b768-cbd6dfbceecd" alt="image" loading="lazy"></p>
<p>ã“ã®promptingã¯è¤‡é›‘ãªå•é¡Œã§ã‚ã‚Œã°ã‚ã‚‹ã»ã©åŠ¹æœãŒã‚ã‚‹ã¨æ¨å¯Ÿã•ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1105" target="_blank" rel="noopener noreferrer" class="title-link">Self-RAG: Learning to Retrieve, Generate, and Critique through   Self-Reflection, Akari Asai+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€äº‹å®Ÿã«åŸºã¥ã‹ãªã„å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ãã“ã§ã€è‡ªå·±åçœçš„ãªæ¤œç´¢å¢—å¼·ç”Ÿæˆï¼ˆSelf-RAGï¼‰ã¨ã„ã†æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€æ¤œç´¢ã¨è‡ªå·±åçœã‚’é€šã˜ã¦LLMã®å“è³ªã¨äº‹å®Ÿæ€§ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€Self-RAGãŒæœ€å…ˆç«¯ã®LLMsãŠã‚ˆã³æ¤œç´¢å¢—å¼·ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>RAGã‚’ã™ã‚‹éš›ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®å›ç­”ã®è³ªã¨factual consistencyã‚’æ”¹å–„ã›ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚<br>reflection tokenã¨å‘¼ã°ã‚Œã‚‹ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã‚’å°å…¥ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã®éç¨‹ã§å¿…è¦ã«å¿œã˜ã¦æƒ…å ±ã‚’retrieveã—ã€è‡ªèº«ã§ç”Ÿæˆå†…å®¹ã‚’æ‰¹è©•ã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ã€‚å˜èªã”ã¨ã«ç”Ÿæˆã™ã‚‹ã®ã§ã¯ãªãã€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå˜ä½ã§ç”Ÿæˆã™ã‚‹å€™è£œã‚’ç”Ÿæˆã—ã€æ‰¹è©•å†…å®¹ã«åŸºã¥ã„ã¦å®Ÿéš›ã«ç”Ÿæˆã™ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’é¸æŠã™ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/282eb6fd-d2bd-4804-a0bc-652158e2f857" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cf690500-7002-454d-bc7c-0664d152a664" alt="image" loading="lazy"></p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=hSyW5go0v8" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=hSyW5go0v8</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1089" target="_blank" rel="noopener noreferrer" class="title-link">Detecting Pretraining Data from Large Language Models, Weijia Shi+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’è¨“ç·´ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã®æ¤œå‡ºå•é¡Œã‚’ç ”ç©¶ã—ã€æ–°ã—ã„æ¤œå‡ºæ–¹æ³•ã§ã‚ã‚‹Min-K% Probã‚’ææ¡ˆã—ã¾ã™ã€‚Min-K% Probã¯ã€LLMã®ä¸‹ã§ä½ã„ç¢ºç‡ã‚’æŒã¤ã‚¢ã‚¦ãƒˆãƒ©ã‚¤ã‚¢ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œå‡ºã™ã‚‹ã“ã¨ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚å®Ÿé¨“ã®çµæœã€Min-K% Probã¯å¾“æ¥ã®æ–¹æ³•ã«æ¯”ã¹ã¦7.4%ã®æ”¹å–„ã‚’é”æˆã—ã€è‘—ä½œæ¨©ã®ã‚ã‚‹æ›¸ç±ã®æ¤œå‡ºã‚„æ±šæŸ“ã•ã‚ŒãŸä¸‹æµã®ä¾‹ã®æ¤œå‡ºãªã©ã€å®Ÿä¸–ç•Œã®ã‚·ãƒŠãƒªã‚ªã«ãŠã„ã¦åŠ¹æœçš„ãªè§£æ±ºç­–ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å®Ÿé¨“çµæœã‚’è¦‹ã‚‹ã«AUCã¯0.73-0.76ç¨‹åº¦ã§ã‚ã‚Šã€ã¾ã ã‚ã¾ã‚Šé«˜ããªã„å°è±¡ã€‚ã¾ãŸã€ãƒ†ã‚­ã‚¹ãƒˆã®lengthã¯ãã‚Œãã‚Œ32,64,128,256ç¨‹åº¦ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1d7a5fe2-e0bc-4c6e-92b2-34457a17714a" alt="image" loading="lazy"></p>
<p>openreview:


<a href="https://openreview.net/forum?id=zWqr3MQuNs" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=zWqr3MQuNs</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2023-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1072" target="_blank" rel="noopener noreferrer" class="title-link">Think before you speak: Training Language Models With Pause Tokens, Sachin Goyal+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã«ãŠã„ã¦ã€é…å»¶ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€å…¥åŠ›ã«ç‰¹å®šã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ ã—ã€ãã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒç¾ã‚Œã‚‹ã¾ã§ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚’é…ã‚‰ã›ã‚‹ã“ã¨ã§ã€è¿½åŠ ã®è¨ˆç®—ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€ã“ã®æ‰‹æ³•ãŒæ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦æœ‰ç›Šã§ã‚ã‚Šã€ç‰¹ã«QAã‚¿ã‚¹ã‚¯ã§ã®æ€§èƒ½å‘ä¸ŠãŒè¦‹ã‚‰ã‚Œã¾ã—ãŸã€‚ä»Šå¾Œã¯ã€ã“ã®é…å»¶äºˆæ¸¬ã®æ‰‹æ³•ã‚’ã•ã‚‰ã«ç ”ç©¶ã—ã¦ã„ãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã“ã®ç ”ç©¶ã¯èˆˆå‘³æ·±ã„ãŒã€äº‹å‰å­¦ç¿’æ™‚ã«å…¥ã‚Œãªã„ã¨åŠ¹æœãŒå‡ºã«ãã„ã¨ã„ã†ã®ã¯ç›´æ„Ÿçš„ã«ã‚ã‹ã‚‹ã®ã§ã€å®Ÿç”¨çš„ã«ã¯æ´»ç”¨ã—ã¥ã‚‰ã„ã€‚<br>ã¾ãŸã€promptã§ã“ã®ç ”ç©¶ã‚’imitateã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦ã¯ã€ZeroShot CoTã«ãŠã„ã¦ã€æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’æ˜ç¤ºçš„ã«æŒ‡å®šã™ã‚‹ã‚ˆã†ãªpromptingã¨åŒæ§˜ã®ã“ã¨ã‚’è¡Œã£ã¦ãŠã‚Šã€ã“ã‚Œã¯å®Ÿéš›ã«åŠ¹æœãŒã‚ã‚‹ã¨æ€ã†ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1068" target="_blank" rel="noopener noreferrer" class="title-link">Improved Baselines with Visual Instruction Tuning, Haotian Liu+, N_A, CVPR'24</a>
<span class="snippet"><span>GPT Summary</span>- LLaVAã¯ã€ãƒ“ã‚¸ãƒ§ãƒ³ã¨è¨€èªã®ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«ã‚³ãƒã‚¯ã‚¿ã§ã‚ã‚Šã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ãŒé«˜ãå¼·åŠ›ãªæ€§èƒ½ã‚’æŒã¤ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚CLIP-ViT-L-336pxã‚’ä½¿ç”¨ã—ã€å­¦è¡“ã‚¿ã‚¹ã‚¯æŒ‡å‘ã®VQAãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€11ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ç¢ºç«‹ã—ã¾ã—ãŸã€‚13Bã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ã‚ãšã‹120ä¸‡ã®å…¬é–‹ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã€1æ—¥ã§å®Œå…¨ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’çµ‚ãˆã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç”»åƒåˆ†æãŒå¯èƒ½ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMã¨ã®ã“ã¨ã€‚</p>
<p># Overview<br><br>ç”»åƒç”Ÿæˆã‚’ã§ãã‚‹ã‚ã‘ã§ã¯ãªãã€inputã¨ã—ã¦ç”»åƒã‚’æ‰±ãˆã‚‹ã®ã¿ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8d0382b0-8c2b-438d-8de8-ee451f5e2649" alt="image" loading="lazy"><br><br></p>
<p>pj page:


<a href="https://llava-vl.github.io" target="_blank" rel="noopener noreferrer">https://llava-vl.github.io</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<a class="button" href="articles/PMLR.html" target="_blank" rel="noopener noreferrer">#PMLR</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1066" target="_blank" rel="noopener noreferrer" class="title-link">Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution, Chrisantha Fernando+, N_A, PMLR'24, 2024.07</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Promptbreederã¨ã„ã†è‡ªå·±å‚ç…§çš„ãªè‡ªå·±æ”¹å–„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ææ¡ˆã—ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æ±ç”¨çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæˆ¦ç•¥ã‚’é€²åŒ–ã•ã›ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚Promptbreederã¯ã€LLMãŒè‡ªå·±å‚ç…§çš„ãªæ–¹æ³•ã§é€²åŒ–ã™ã‚‹å¤‰ç•°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã£ã¦åˆ¶å¾¡ã•ã‚Œã€ã‚¿ã‚¹ã‚¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é›†å›£ã‚’å¤‰ç•°ã•ã›ã¦æ”¹å–„ã—ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ã€ç®—è¡“ã‚„å¸¸è­˜çš„ãªæ¨è«–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã ã‘ã§ãªãã€ãƒ˜ã‚¤ãƒˆã‚¹ãƒ”ãƒ¼ãƒåˆ†é¡ãªã©ã®é›£ã—ã„å•é¡Œã«å¯¾ã—ã¦ã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>è©³ç´°ãªè§£èª¬è¨˜äº‹: 


<a href="https://aiboom.net/archives/56319" target="_blank" rel="noopener noreferrer">https://aiboom.net/archives/56319</a>


</p>
<p>APEã¨ã¯ç•°ãªã‚Šã€GAã‚’ä½¿ã†ã€‚çªç„¶å¤‰ç•°ã«ã‚ˆã£ã¦ã€äºˆæœŸã›ã¬è‰¯ã„promptãŒç”Ÿã¿å‡ºã•ã‚Œã‚‹ã‹ã‚‚â€¦ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1065" target="_blank" rel="noopener noreferrer" class="title-link">Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models  through Logic, Xufeng Zhao+, N_A, COLING'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é€²æ­©ã¯é©šç•°çš„ã ãŒã€å¤šæ®µéšã®æ¨è«–ã«ã¯æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚‹ã€‚å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯çŸ¥è­˜ã‚’æŒã£ã¦ã„ã‚‹ãŒã€æ¨è«–ã«ã¯ä¸€è²«æ€§ãŒãªãã€å¹»è¦šã‚’ç¤ºã™ã“ã¨ãŒã‚ã‚‹ã€‚ãã“ã§ã€Logical Chain-of-Thoughtï¼ˆLogiCoTï¼‰ã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€è«–ç†ã«ã‚ˆã‚‹æ¨è«–ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã®åŠ¹æœã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/KnowledgeGraph.html" target="_blank" rel="noopener noreferrer">#KnowledgeGraph</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1061" target="_blank" rel="noopener noreferrer" class="title-link">Graph Neural Prompting with Large Language Models, Yijun Tian+, N_A, AAAI'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’çŸ¥è­˜ã‚°ãƒ©ãƒ•ã¨çµ„ã¿åˆã‚ã›ã‚‹ãŸã‚ã®æ–°ã—ã„æ‰‹æ³•ã§ã‚ã‚‹Graph Neural Promptingï¼ˆGNPï¼‰ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚GNPã¯ã€æ¨™æº–çš„ãªã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚„ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ãƒ—ãƒ¼ãƒªãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãªã©ã®è¦ç´ ã‹ã‚‰æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€ç•°ãªã‚‹LLMã®ã‚µã‚¤ã‚ºã‚„è¨­å®šã«ãŠã„ã¦ã€å¸¸è­˜çš„ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã‚„ãƒã‚¤ã‚ªãƒ¡ãƒ‡ã‚£ã‚«ãƒ«æ¨è«–ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ã“ã¨ãŒå®Ÿé¨“ã«ã‚ˆã£ã¦ç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1707211751354212382"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>äº‹å‰å­¦ç¿’ã•ã‚ŒãŸLLMãŒKGã‹ã‚‰æœ‰ç›ŠãªçŸ¥è­˜ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã‚’æ”¯æ´ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚<br><p>ã—ã£ã‹ã‚Šè«–æ–‡ã‚’èª­ã‚“ã§ã„ãªã„ãŒã€freezeã—ãŸLLMãŒã‚ã£ãŸæ™‚ã«ã€KGã‹ã‚‰æ±‚ã‚ãŸGraph Neural Promptã‚’å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã¨çµ„ã¿åˆã‚ã›ã¦ã€æ–°ãŸãªLLMã¸ã®å…¥åŠ›ã‚’ç”Ÿæˆã—åˆ©ç”¨ã™ã‚‹æ‰‹æ³•ãªæ¨¡æ§˜ã€‚<br>Graph Neural Promptingã§ã¯ã€Multiple choice QAãŒå…¥åŠ›ã•ã‚ŒãŸæ™‚ã«ã€ãã®å•é¡Œæ–‡ã‚„é¸æŠè‚¢ã«å«ã¾ã‚Œã‚‹ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‹ã‚‰ã€KGã®ã‚µãƒ–ã‚°ãƒ©ãƒ•ã‚’æŠ½å‡ºã—ã€ãã“ã‹ã‚‰é–¢é€£æ€§ã®ã‚ã‚‹äº‹å®Ÿã‚„æ§‹é€ æƒ…å ±ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€Graph Neural Promptã‚’ç²å¾—ã™ã‚‹ã€‚ãã®ãŸã‚ã«ã€GNNã«åŸºã¥ã„ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã€ã„ãã¤ã‹ã®å·¥å¤«ã‚’æ–½ã—ã¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’ã™ã‚‹æ¨¡æ§˜ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c6c80b8d-930e-49ff-9a1b-62e70947dc7c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1060" target="_blank" rel="noopener noreferrer" class="title-link">Effective Long-Context Scaling of Foundation Models, Wenhan Xiong+, N_A, NAACL'24</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ä¸€é€£ã®LLMsã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚„ä»–ã®ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã•ã‚Œã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€é€šå¸¸ã®ã‚¿ã‚¹ã‚¯ã¨é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¿ã‚¹ã‚¯ã®ä¸¡æ–¹ã§æ”¹å–„ã‚’ã‚‚ãŸã‚‰ã—ã¾ã™ã€‚ã¾ãŸã€70Bãƒãƒªã‚¢ãƒ³ãƒˆã¯gpt-3.5-turbo-16kã‚’ä¸Šå›ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€ç§ãŸã¡ã¯Llamaã®ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚„äº‹å‰å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã®è¨­è¨ˆé¸æŠã®å½±éŸ¿ã«ã¤ã„ã¦ã‚‚åˆ†æã—ã¾ã—ãŸã€‚çµæœã‹ã‚‰ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ç¶™ç¶šçš„ãªäº‹å‰å­¦ç¿’ãŒåŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹elvisæ°ã®ãƒ„ã‚¤ãƒ¼ãƒˆã®æ„è¨³<br><br>MetaãŒ32kã®context windowã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹70Bã®LLaMa2ã®variantææ¡ˆã—ã€gpt-3.5-turboã‚’long contextãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§outperformã€‚<br>short contextã®LLaMa2ã‚’ç¶™ç¶šçš„ã«è¨“ç·´ã—ã¦å®Ÿç¾ã€‚ã“ã‚Œã«ã¯äººæ‰‹ã§ä½œæˆã—ãŸinstruction tuning datasetã‚’å¿…è¦ã¨ã›ãšã€ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®é«˜ã„instruction tuningã«ã‚ˆã£ã¦å®Ÿç¾ã•ã‚Œã‚‹ã€‚<br>ã“ã‚Œã¯ã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é•·ã„ãƒ†ã‚­ã‚¹ãƒˆãŒè±Šå¯Œã«å«ã¾ã‚Œã‚‹ã“ã¨ãŒå„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®éµã§ã¯ãªãã€ãƒ­ãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ç¶™ç¶šçš„ãªäº‹å‰å­¦ç¿’ãŒã‚ˆã‚ŠåŠ¹ç‡çš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚<br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1707780482178400261?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«ã¯long contxetç”¨ã«ã€RoPEã®base frequency bã‚’ `10,000-&gt;500,000` ã¨ã™ã‚‹ã“ã¨ã§ã€rotation angleã‚’å°ã•ãã—ã€distant tokenã«å¯¾ã™ã‚‹æ¸›è¡°ã®å½±éŸ¿ã‚’å°ã•ãã™ã‚‹æ‰‹æ³•ã‚’æ¡ç”¨ (Adjusted Base Frequency; ABF)ã€‚tokené–“ã®è·é›¢ãŒé›¢ã‚Œã¦ã„ã¦ã‚‚ã€attention scoreãŒshrinkã—ã¥ã‚‰ããªã£ã¦ã„ã‚‹ã€‚<br><br>&lt;img width="578" height="291" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/968c88f1-5a0d-4c2a-94ef-d63ffb0ea2eb"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/968c88f1-5a0d-4c2a-94ef-d63ffb0ea2eb"&lt;/a&gt;


/&gt;<br><br><br>ã¾ãŸã€å˜ã«é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ã ã‘ã§ãªãã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã«ãŠã‘ã‚‹é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã®æ¯”ç‡ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šé«˜ã„æ€§èƒ½ãŒç™ºæ®ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ã“ã‚Œã‚’Data Mixã¨å‘¼ã¶ã€‚<br>ã¾ãŸã€instruction tuningã®ãƒ‡ãƒ¼ã‚¿ã«ã¯ã€LLaMa2Chatã®RLHFãƒ‡ãƒ¼ã‚¿ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€LLaMa2Chatè‡ªèº«ã«self-instructã‚’æ´»ç”¨ã—ã¦ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã•ã›æ‹¡å¼µã—ãŸã‚‚ã®ã‚’åˆ©ç”¨ã—ãŸã€‚<br>å…·ä½“çš„ã«ã¯ã€ã‚³ãƒ¼ãƒ‘ã‚¹å†…ã®long documentã‚’ç”¨ã„ãŸQAãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã‚¿ã‚¹ã‚¯ã«ç€ç›®ã—ã€æ–‡æ›¸å†…ã®ãƒ©ãƒ³ãƒ€ãƒ ãªãƒãƒ£ãƒ³ã‚¯ã‹ã‚‰QAã‚’ç”Ÿæˆã•ã›ãŸã€‚ãã®å¾Œã€self-critiqueã«ã‚ˆã£ã¦ã€LLaMa2Chatè‡ªèº«ã«ã€ç”Ÿæˆã•ã‚ŒãŸQAãƒšã‚¢ã®verificationã‚‚å®Ÿæ–½ã•ã›ãŸã€‚</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1044" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Chain-of-Verification Reduces Hallucination in Large Language Models, Shehzaad Dhuliawala+, N_A, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒæ ¹æ‹ ã®ãªã„æƒ…å ±ã‚’ç”Ÿæˆã™ã‚‹å•é¡Œã«å–ã‚Šçµ„ã‚“ã§ã„ã¾ã™ã€‚Chain-of-Verificationï¼ˆCoVeï¼‰ãƒ¡ã‚½ãƒƒãƒ‰ã‚’é–‹ç™ºã—ã€ãƒ¢ãƒ‡ãƒ«ãŒå›ç­”ã‚’ä½œæˆã—ã€æ¤œè¨¼ã—ã€æœ€çµ‚çš„ãªå›ç­”ã‚’ç”Ÿæˆã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµŒã‚‹ã“ã¨ã§ã€å¹»æƒ³ã‚’æ¸›å°‘ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’å®Ÿé¨“ã§ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>
<strong># æ¦‚è¦<br>ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã‹ã‚‰ã€Verificationã®ãŸã‚ã®è³ªå•ã‚’planningã—ã€è³ªå•ã«å¯¾ã—ã¦ç‹¬ç«‹ã«å›ç­”ã‚’å¾—ãŸã†ãˆã§ã‚ªãƒªã‚¸ãƒŠãƒ«ã®è³ªå•ã«å¯¾ã™ã‚‹aggreementã‚’ç¢ºèªã—ã€æœ€çµ‚çš„ã«ç”Ÿæˆã‚’å®Ÿæ–½ã™ã‚‹Promptingæ‰‹æ³•<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/18763903-2d70-4180-9384-2da55bedad2e" alt="image" loading="lazy"><br><br># è©•ä¾¡<br>## dataset<br>- å…¨ä½“ã‚’é€šã˜ã¦closed-bookã®è¨­å®šã§è©•ä¾¡<br>- Wikidata<br>    - Wikipedia APIã‹ã‚‰è‡ªå‹•ç”Ÿæˆã—ãŸã€Œâ€œWho are some [Profession]s who were born in [City]?â€ã€ã«å¯¾ã™ã‚‹QA pairs<br>    - Goldã¯knowledge baseã‹ã‚‰å–å¾—<br>    - å…¨56 test questions<br>    - Gold EntityãŒå¤§ä½“600ç¨‹åº¦ã‚ã‚ŠLLMã¯ä¸€éƒ¨ã—ã‹å›ç­”ã—ãªã„ã®ã§ã€precisionã§è©•ä¾¡<br>- Wiki category list<br>    - QUEST datasetã‚’åˆ©ç”¨ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/701" target="_blank" rel="noopener noreferrer">QUEST: A Retrieval Dataset of Entity-Seeking Queries with Implicit Set  Operations, Chaitanya Malaviya+, N/A, ACL'23</a>
</strong>
<br>
 <br>    - å›ç­”ã«logical operationãŒä¸è¦ãªã‚‚ã®ã«é™å®šã—ã¦é ­ã«"Name some"ã‚’ã¤ã‘ã¦è³ªå•ã‚’ç”Ÿæˆ<br>        - "Name some Mexican animated horror films" or "Name some Endemic orchids of Vietnam"<br>    - 8å€‹ã®å›ç­”ã‚’æŒã¤55 test questionsã‚’ä½œæˆ<br>- MultiSpanQA<br>    - Reading Comprehensionã«é–¢ã™ã‚‹Benchmark dataset<br>    - è¤‡æ•°ã®ç‹¬ç«‹ã—ãŸå›ç­”ï¼ˆå›ç­”ã¯é€£ç¶šã—ãªã„ã‚¹ãƒ‘ãƒ³ã‹ã‚‰å›ç­”ãŒæŠ½å‡ºã•ã‚Œã‚‹ï¼‰ã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹è³ªå•ã§æ§‹æˆ<br>        - ç‰¹ã«ã€ä»Šå›ã¯closed-book setting ã§å®Ÿæ–½<br>        - ã™ãªã‚ã¡ã€ä¸ãˆã‚‰ã‚ŒãŸè³ªå•ã®ã¿ã‹ã‚‰å›ç­”ã—ãªã‘ã‚Œã°ãªã‚‰ãšã€çŸ¥ã£ã¦ã„ã‚‹çŸ¥è­˜ãŒå•ã‚ã‚Œã‚‹å•é¡Œ<br>    - 418ã®test questsionsã§ã€å„å›ç­”ã«å«ã¾ã‚Œã‚‹è¤‡æ•°ã‚¢ã‚¤ãƒ†ãƒ ã®spanãŒ3 tokenæœªæº€ã¨ãªã‚‹ã‚ˆã†ã«ã—ãŸ<br>    - QAä¾‹:<br>        - Q: Who invented the first printing press and in what year?<br>        - A: Johannes Gutenberg, 1450.<br># è©•ä¾¡çµæœ<br>ææ¡ˆæ‰‹æ³•ã«ã¯ã€verificationã®å„ã‚¹ãƒ†ãƒƒãƒ—ã§LLMã«ç‹¬ç«‹ã—ãŸpromptingã‚’ã™ã‚‹ã‹ãªã©ã§joint, 2-step, Factored, Factor+Revisedã®4ç¨®é¡ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚ã‚‹ã“ã¨ã«ç•™æ„ã€‚<br>- joint: å…¨ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ä¸€ã¤ã®promptã§å®Ÿæ–½<br>- 2-stepã¯2ã¤ã®promptã«åˆ†ã‘ã¦å®Ÿæ–½<br>- Factoredã¯å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’å…¨ã¦ç•°ãªã‚‹promptingã§å®Ÿæ–½<br>- Factor+Revisedã¯ç•°ãªã‚‹promptã§è¿½åŠ ã®QAã«å¯¾ã™ã‚‹cross-checkã‚’ã‹ã‘ã‚‹æ‰‹æ³•<br><br>çµæœã‚’è¦‹ã‚‹ã¨ã€CoVEã§hallucinationãŒè»½æ¸›ï¼ˆã¨ã„ã†ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ãŒæŒã¤çŸ¥è­˜ã«åŸºã¥ã„ã¦æ­£ç¢ºã«å›ç­”ã§ãã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®å‰²åˆãŒå¢—ãˆã‚‹ã®ã§å®Ÿè³ªçš„ã«hallucinationãŒä½æ¸›ã—ãŸã¨ã¿ãªã›ã‚‹ï¼‰ã•ã‚Œã€ç‰¹ã«jointã‚ˆã‚Šã‚‚2-step, factoredã®æ–¹ãŒé«˜ã„æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/05ff1e6c-75e7-428a-996f-61e844866391" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d72aa05e-daab-4092-a6f5-9e80cdab7486" alt="image" loading="lazy"><br></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1037" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models as Optimizers, Chengrun Yang+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æœ€é©åŒ–ã‚¿ã‚¹ã‚¯ã‚’è‡ªç„¶è¨€èªã§è¨˜è¿°ã—ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦æœ€é©åŒ–ã‚’è¡Œã†æ‰‹æ³•ã€ŒOptimization by PROmptingï¼ˆOPROï¼‰ã€ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã§ã¯ã€LLMãŒä»¥å‰ã®è§£ã¨ãã®å€¤ã‚’å«ã‚€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰æ–°ã—ã„è§£ã‚’ç”Ÿæˆã—ã€è©•ä¾¡ã—ã¦æ¬¡ã®æœ€é©åŒ–ã‚¹ãƒ†ãƒƒãƒ—ã®ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€OPROã«ã‚ˆã£ã¦æœ€é©åŒ–ã•ã‚ŒãŸæœ€è‰¯ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã€äººé–“ãŒè¨­è¨ˆã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>`Take a deep breath and work on this problem step-by-step. `è«–æ–‡<br><br><br><br># æ¦‚è¦<br><br>LLMã‚’åˆ©ç”¨ã—ã¦æœ€é©åŒ–å•é¡Œã‚’è§£ããŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ãŸã¨ã„ã†è©±ã€‚è«–æ–‡ä¸­ã§ã¯ã€linear regressionã‚„å·¡å›ã‚»ãƒ¼ãƒ«ã‚¹ãƒãƒ³å•é¡Œã«é©ç”¨ã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€å¿œç”¨ä¾‹ã¨ã—ã¦Prompt Engineeringã«åˆ©ç”¨ã—ã¦ã„ã‚‹ã€‚<br><br>ã“ã‚Œã«ã‚ˆã‚Šã€Prompt EngineeringãŒæœ€é©ã‹å•é¡Œã«è½ã¨ã—è¾¼ã¾ã‚Œã€è‡ªå‹•çš„ãªprompt engineeringã«ã‚ˆã£ã¦ã€`Let's think step by step.` ã‚ˆã‚Šã‚‚è‰¯ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã¨ã„ã†è©±ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2a469085-8a14-4eac-85ee-3918fe1becd5" alt="image" loading="lazy"><br><br><br><br># æ‰‹æ³•æ¦‚è¦<br><br>å…¨ä½“ã¨ã—ã¦ã®æ çµ„ã¿ã€‚meta-promptã‚’inputã¨ã—ã€LLMãŒobjective functionã«å¯¾ã™ã‚‹solutionã‚’ç”Ÿæˆã™ã‚‹ã€‚ç”Ÿæˆã•ã‚ŒãŸsolutionã¨ã‚¹ã‚³ã‚¢ãŒmeta-promptã«ä»£å…¥ã•ã‚Œã€æ¬¡ã®optimizationãŒèµ°ã‚‹ã€‚ã“ã‚Œã‚’ç¹°ã‚Šè¿”ã™ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3e34ed47-5cbe-4cb0-b25a-8ee939e780e3" alt="image" loading="lazy"><br><br>Meta promptã®ä¾‹<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a0dd261e-0dcd-487a-bfac-89db243e0b1c" alt="image" loading="lazy"><br><br></p>
<p>openreview: 


<a href="https://openreview.net/forum?id=Bb4VGOWELI" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Bb4VGOWELI</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1029" target="_blank" rel="noopener noreferrer" class="title-link">CausalLM is not optimal for in-context learning, Nan Ding+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ã«ãŠã„ã¦ã€ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆprefixLMï¼‰ãŒå› æœè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆcausalLMï¼‰ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã“ã¨ãŒã‚ã‹ã£ã¦ã„ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ç†è«–çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç”¨ã„ã¦ã€prefixLMã¨causalLMã®åæŸæŒ™å‹•ã‚’åˆ†æã—ã¾ã—ãŸã€‚ãã®çµæœã€prefixLMã¯ç·šå½¢å›å¸°ã®æœ€é©è§£ã«åæŸã™ã‚‹ä¸€æ–¹ã€causalLMã®åæŸãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å‹¾é…é™ä¸‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«å¾“ã„ã€æœ€é©ã§ã‚ã‚‹ã¨ã¯é™ã‚‰ãªã„ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ã•ã‚‰ã«ã€åˆæˆå®Ÿé¨“ã¨å®Ÿéš›ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã‚‚ã€causalLMãŒprefixLMã‚ˆã‚Šã‚‚æ€§èƒ½ãŒåŠ£ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1697380430004249066?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>CausalLMã§ICLã‚’ã—ãŸå ´åˆã¯ã€ICLä¸­ã®demonstrationã§ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ã™ã‚‹ã“ã¨ã«ç›¸å½“ã—ã€æœ€é©è§£ã«åæŸã—ã¦ã„ã‚‹ã¨ã¯é™ã‚‰ãªã„â€¦â€¦ï¼ŸãŒã€hillbigã•ã‚“ã®æ„Ÿæƒ³ã«åŸºã¥ãã¨ã€çµæœçš„ã«ã¯å®Ÿã¯æœ€é©è§£ã«åæŸã—ã¦ã„ã‚‹ã®ã§ã¯ï¼Ÿã¨ã„ã†è©±ã‚‚å‡ºã¦ã„ã‚‹ã—ã€ã‚ˆãåˆ†ã‹ã‚‰ãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/924" target="_blank" rel="noopener noreferrer" class="title-link">SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step   Reasoning, Ning Miao+, N_A, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ€æ–°ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€æ¨è«–å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«æœ‰æœ›ãªæ‰‹æ³•ã§ã™ãŒã€è¤‡é›‘ãªå•é¡Œã«ã¯ã¾ã è‹¦æˆ¦ã—ã¦ã„ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LLMsãŒè‡ªèº«ã®ã‚¨ãƒ©ãƒ¼ã‚’èªè­˜ã™ã‚‹èƒ½åŠ›ã‚’æŒã£ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’æ¢æ±‚ã—ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®æ¤œè¨¼ã‚¹ã‚­ãƒ¼ãƒ ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®æ¤œè¨¼ã‚¹ã‚­ãƒ¼ãƒ ã‚’ä½¿ç”¨ã—ã¦ã€ç•°ãªã‚‹å›ç­”ã«å¯¾ã—ã¦é‡ã¿ä»˜ã‘æŠ•ç¥¨ã‚’è¡Œã„ã€è³ªå•å¿œç­”ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’å®Ÿé¨“ã§ç¢ºèªã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ã“ã‚Œã¯ãŠã‚‚ã—ã‚ãã†ã€‚å¾Œã§èª­ã‚€</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=pTHfApDakA" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=pTHfApDakA</a>


</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/917" target="_blank" rel="noopener noreferrer" class="title-link">LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA   Composition, Chengsong Huang+, N_A, COLM'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã«é©å¿œã•ã›ã‚‹ãŸã‚ã®ä½ãƒ©ãƒ³ã‚¯é©å¿œï¼ˆLoRAï¼‰ã‚’æ¤œè¨ã—ã€LoraHubã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚LoraHubã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€å°‘æ•°ã®ä¾‹ã‹ã‚‰è¤‡æ•°ã®LoRAãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã¦æŸ”è»Ÿã«é©å¿œæ€§ã®ã‚ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚ã¾ãŸã€è¿½åŠ ã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚„å‹¾é…ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚å®Ÿé¨“çµæœã‹ã‚‰ã€LoraHubãŒå°‘æ•°ã®ä¾‹ã§ã®ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åŠ¹æœçš„ã«æ¨¡å€£ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€LoRAã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®è‚²æˆã¨å…±æœ‰ãƒªã‚½ãƒ¼ã‚¹ã®æä¾›ã«ã‚‚è²¢çŒ®ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å­¦ç¿’ã•ã‚ŒãŸLoRAã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã—ã¦æ‰ãˆã€æ–°ãŸãªã‚¿ã‚¹ã‚¯ã®inputãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€LoRA Hubä¸Šã®é©åˆ‡ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’LLMã«çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ICLç„¡ã—ã§æ±åŒ–ã‚’å®Ÿç¾ã™ã‚‹ã¨ã„ã†ã‚¢ã‚¤ãƒ‡ã‚¢ã€‚few shotã®exampleã‚’äººé–“ãŒè¨­è¨ˆã™ã‚‹å¿…è¦ãªãã€åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9d769042-5a29-4c22-8ab4-e90195f71184" alt="image" loading="lazy"></p>
<p>è¤‡æ•°ã®LoRAãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯çµ„ã¿åˆã‚ã‚‰ã‚Œã‚‹ã‹ï¼Ÿelement wiseã®ç·šå‹çµåˆã§ä»Šå›ã¯ã‚„ã£ã¦ã„ã‚‹ãŒã€ãã®ç–‘å•ã«ã“ãŸãˆãŸã®ãŒcontribution</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=TrloAXEJ2B" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=TrloAXEJ2B</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/872" target="_blank" rel="noopener noreferrer" class="title-link">SciBench: Evaluating College-Level Scientific Problem-Solving Abilities   of Large Language Models, Xiaoxuan Wang+, N_A, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®é€²æ­©ã«ã‚ˆã‚Šã€æ•°å­¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®æ€§èƒ½å‘ä¸ŠãŒç¤ºã•ã‚Œã¦ã„ã‚‹ãŒã€ã“ã‚Œã‚‰ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯é™å®šçš„ãªç¯„å›²ã®å•é¡Œã«é™å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒæŒ‡æ‘˜ã•ã‚Œã‚‹ã€‚ãã“ã§ã€è¤‡é›‘ãªç§‘å­¦çš„å•é¡Œè§£æ±ºã«å¿…è¦ãªæ¨è«–èƒ½åŠ›ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã®åŒ…æ‹¬çš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¤ãƒ¼ãƒˆSciBenchã‚’ææ¡ˆã™ã‚‹ã€‚SciBenchã«ã¯ã€å¤§å­¦ãƒ¬ãƒ™ãƒ«ã®ç§‘å­¦çš„å•é¡Œã‚’å«ã‚€ã‚ªãƒ¼ãƒ—ãƒ³ã‚»ãƒƒãƒˆã¨ã€å­¦éƒ¨ãƒ¬ãƒ™ãƒ«ã®è©¦é¨“å•é¡Œã‚’å«ã‚€ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ã‚»ãƒƒãƒˆã®2ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå«ã¾ã‚Œã¦ã„ã‚‹ã€‚ã•ã‚‰ã«ã€2ã¤ã®ä»£è¡¨çš„ãªLLMã‚’ç”¨ã„ãŸè©³ç´°ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç ”ç©¶ã‚’è¡Œã„ã€ç¾åœ¨ã®LLMã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä¸ååˆ†ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ã‚¿ãƒ‡ã‚£ã‚’é€šã˜ã¦ã€LLMãŒçŠ¯ã™ã‚¨ãƒ©ãƒ¼ã‚’10ã®å•é¡Œè§£æ±ºèƒ½åŠ›ã«åˆ†é¡ã—ã€ç‰¹å®šã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ãŒä»–ã®æˆ¦ç•¥ã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚SciBenchã¯ã€LLMã®æ¨è«–èƒ½åŠ›ã®å‘ä¸Šã‚’ä¿ƒé€²ã—ã€ç§‘å­¦ç ”ç©¶ã¨ç™ºè¦‹ã«è²¢çŒ®ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/LearningToRank.html" target="_blank" rel="noopener noreferrer">#LearningToRank</a>
<a class="button" href="articles/PairWise.html" target="_blank" rel="noopener noreferrer">#PairWise</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/799" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models are Effective Text Rankers with Pairwise Ranking   Prompting, Zhen Qin+, N_A, NAACL'24</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã‚’ä½¿ç”¨ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã™ã‚‹éš›ã«ã€Pairwise Ranking Promptingï¼ˆPRPï¼‰ã¨ã„ã†æ–°ã—ã„æŠ€è¡“ã‚’ææ¡ˆã™ã‚‹ã€‚PRPã¯ã€LLMsã¸ã®è² è·ã‚’è»½æ¸›ã—ã€æœ€å…ˆç«¯ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€20Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤Flan-UL2ãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ãPRPã¯ã€å•†ç”¨ã®GPT-4ã«åŸºã¥ãå¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ãŸã€‚ã•ã‚‰ã«ã€PRPã®ãƒãƒªã‚¢ãƒ³ãƒˆã‚’ææ¡ˆã—ã€åŠ¹ç‡ã‚’æ”¹å–„ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚PRPã¯ç”Ÿæˆã¨ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã®LLM APIã®ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€å…¥åŠ›ã®é †åºã«å¯¾ã—ã¦ç„¡æ„Ÿåº¦ã§ã‚ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>open source LLMã«ãŠã„ã¦ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ãªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§SoTAã‚’é”æˆã§ãã‚‹ã‚ˆã†ãªpromptingæŠ€è¡“ã‚’ææ¡ˆ</p>
<p>å¾“æ¥ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®ãŸã‚ã®promptingã¯point-wiseã¨list wiseã—ã‹ãªã‹ã£ãŸãŒã€å‰è€…ã¯è¤‡æ•°ã®ã‚¹ã‚³ã‚¢ã‚’æ¯”è¼ƒã™ã‚‹ãŸã‚ã«ã‚¹ã‚³ã‚¢ã®calibrationãŒå¿…è¦ã ã£ãŸã‚Šã€OpenAIãªã©ã®APIã¯log probabilityã‚’æä¾›ã—ãªã„ãŸã‚ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®ãŸã‚ã®ã‚½ãƒ¼ãƒˆãŒã§ããªã„ã¨ã„ã†æ¬ ç‚¹ãŒã‚ã£ãŸã€‚å¾Œè€…ã¯inputã®orderingã«éå¸¸ã«sensitiveã§ã‚ã‚‹ãŒã€listã®ã™ã¹ã¦ã®çµ„ã¿åˆã‚ã›ã«ã¤ã„ã¦orderingã‚’è©¦ã™ã®ã¯expensiveãªã®ã§å³ã—ã„ã¨ã„ã†ã‚‚ã®ã§ã‚ã£ãŸã€‚ã“ã®ãŸã‚ï¼ˆå¤å…¸çš„ãªlearning to rankã§ã‚‚ãŠãªã˜ã¿ã‚„ï¼‰pairwiseã§ã‚µãƒ³ãƒ—ãƒ«ã‚’æ¯”è¼ƒã™ã‚‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ‰‹æ³•PRPã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br>PRPã¯ãƒšã‚¢ãƒ¯ã‚¤ã‚ºãªã®ã§orderã‚’å…¥ã‚Œæ›¿ãˆã¦è©•ä¾¡ã‚’ã™ã‚‹ã®ã¯å®¹æ˜“ã§ã‚ã‚‹ã€‚ã¾ãŸã€generation modeã¨scoring modeï¼ˆoutputã—ãŸãƒ©ãƒ™ãƒ«ã®log probabilityã‚’åˆ©ç”¨ã™ã‚‹; OpenLLMã‚’ä½¿ã†ã®ã§log probabilityã‚’è¨ˆç®—ã§ãã‚‹ï¼‰ã®2ç¨®é¡ã‚’æ¡ç”¨ã§ãã‚‹ã€‚ã‚½ãƒ¼ãƒˆã®æ–¹æ³•ã«ã¤ã„ã¦ã‚‚ã€ã™ã¹ã¦ã®ãƒšã‚¢ã®å‹æ•—ã‹ã‚‰ã‹ã‚‰å˜ä¸€ã®ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹æ–¹æ³•ï¼ˆAllPair), HeapSortã‚’åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã€LLMã‹ã‚‰ã®outputã‚’å¾—ã‚‹åº¦ã«on the flyã§ãƒªã‚¹ãƒˆã®é †ç•ªã‚’æ­£ã—ãã™ã‚‹Sliding Windowã®3ç¨®é¡ã‚’ææ¡ˆã—ã¦æ¯”è¼ƒã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/7ad366c6-2afd-404b-9e7d-6051030983c6" alt="image" loading="lazy"><br><br>ä¸‹è¡¨ã¯scoring modeã§ã®æ€§èƒ½ã®æ¯”è¼ƒã§ã€GPT4ã«å½“æ™‚ã¯æ€§èƒ½ãŒåŠã‚“ã§ã„ãªã‹ã£ãŸ20Bã®OpenLLMã§è¿‘ã—ã„æ€§èƒ½ã‚’é”æˆã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/7455b844-107f-4e88-85b8-3b5fc2866cc8" alt="image" loading="lazy"><br><br>ã¾ãŸã€PRPãŒinputã®orderã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆãªã“ã¨ã‚‚ç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/5244fb56-a9bf-46c9-89ca-f2766f7ba4a0" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/TACL.html" target="_blank" rel="noopener noreferrer">#TACL</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/793" target="_blank" rel="noopener noreferrer" class="title-link">Lost in the Middle: How Language Models Use Long Contexts, Nelson F. Liu+, N_A, TACL'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€é•·ã„æ–‡è„ˆã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚‹ã“ã¨ãŒã§ãã¾ã™ãŒã€ãã®é•·ã„æ–‡è„ˆã‚’ã©ã‚Œã ã‘ã†ã¾ãåˆ©ç”¨ã—ã¦ã„ã‚‹ã‹ã«ã¤ã„ã¦ã¯ã¾ã ã‚ˆãã‚ã‹ã£ã¦ã„ã¾ã›ã‚“ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€ãƒãƒ«ãƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è³ªå•å¿œç­”ã¨ã‚­ãƒ¼ãƒ»ãƒãƒªãƒ¥ãƒ¼ã®æ¤œç´¢ã¨ã„ã†2ã¤ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åˆ†æã—ã¾ã—ãŸã€‚ãã®çµæœã€é–¢é€£æƒ…å ±ãŒå…¥åŠ›æ–‡è„ˆã®å§‹ã¾ã‚Šã‚„çµ‚ã‚ã‚Šã«ã‚ã‚‹å ´åˆã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒæœ€ã‚‚é«˜ããªã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸãŒã€é•·ã„æ–‡è„ˆã®ä¸­ã§é–¢é€£æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒè‘—ã—ãä½ä¸‹ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€å…¥åŠ›æ–‡è„ˆãŒé•·ããªã‚‹ã«ã¤ã‚Œã¦ã€æ˜ç¤ºçš„ã«é•·ã„æ–‡è„ˆã‚’æ‰±ã†ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤§å¹…ã«ä½ä¸‹ã—ã¾ã™ã€‚ã“ã®åˆ†æã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒå…¥åŠ›æ–‡è„ˆã‚’ã©ã®ã‚ˆã†ã«åˆ©ç”¨ã—ã¦ã„ã‚‹ã‹ã‚’ã‚ˆã‚Šè‰¯ãç†è§£ã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã‚ã‚Šã€å°†æ¥ã®é•·ã„æ–‡è„ˆãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®æ–°ã—ã„è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/drjimfan/status/1678460065811136512?s=46&t=5BO_qSlNBSEGSugyUlP5Hw"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>éå¸¸ã«é‡è¦ãªçŸ¥è¦‹ãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹<p>1. ãƒ¢ãƒ‡ãƒ«ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã¯ã˜ã‚ã¨æœ€å¾Œã®æƒ…å ±ã‚’ã†ã¾ãæ´»ç”¨ã§ãã€çœŸã‚“ä¸­ã®æƒ…å ±ã‚’ã†ã¾ãæ´»ç”¨ã§ããªã„<br>2. é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã‚‚ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚ˆã‚ŠçŸ­ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ã†ã¾ãè€ƒæ…®ã§ãã‚‹ã‚ã‘ã§ã¯ãªã„<br>3. ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ããªã‚Œã°ãªã‚‹ã»ã©æ‚ªåŒ–ã™ã‚‹</p>
<p>SNLP'24ã§ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:<br>


<a href="https://speakerdeck.com/kichi/snlp2024" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/kichi/snlp2024</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2023-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/686" target="_blank" rel="noopener noreferrer" class="title-link">Evidence of Meaning in Language Models Trained on Programs, Charles Jin+, N_A, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ç”¨ã„ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ãŒæ„å‘³ã‚’å­¦ç¿’ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ åˆæˆãŒè¨€èªãƒ¢ãƒ‡ãƒ«ã®æ„å‘³ã®å­˜åœ¨ã‚’ç‰¹å¾´ã¥ã‘ã‚‹ãŸã‚ã®ä¸­é–“ãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã¨ã—ã¦é©ã—ã¦ã„ã‚‹ã“ã¨ã‚’è¿°ã¹ã¦ã„ã‚‹ã€‚Transformerãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå®Ÿé¨“ã«ã‚ˆã‚Šã€è¨€èªã®æ„å‘³ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã®å¸°ç´ãƒã‚¤ã‚¢ã‚¹ã‚’æä¾›ã—ãªã„ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€ç·šå½¢ãƒ—ãƒ­ãƒ¼ãƒ–ãŒãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹ã‹ã‚‰ç¾åœ¨ãŠã‚ˆã³å°†æ¥ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ çŠ¶æ…‹ã®æŠ½è±¡åŒ–ã‚’æŠ½å‡ºã§ãã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã¾ãŸã€æ­£ã—ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚’å­¦ç¿’ã—ã€å¹³å‡çš„ã«è¨“ç·´ã‚»ãƒƒãƒˆã‚ˆã‚Šã‚‚çŸ­ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚‚ç¤ºã—ãŸã€‚æœ¬è«–æ–‡ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«æ–°ã—ã„æŠ€è¡“ã‚’ææ¡ˆã™ã‚‹ã‚‚ã®ã§ã¯ãªãã€(å½¢å¼çš„ãª)æ„å‘³ã®ç¿’å¾—ã¨è¡¨ç¾ã«é–¢ã™ã‚‹å®Ÿé¨“çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é–‹ç™ºã—ã€æ´å¯Ÿã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã§LLMã‚’Next Token Predictionã§è¨“ç·´ã—<br>å³å¯†ã«æ­£è§£ã¨semanticsã‚’å®šç¾©ã—ãŸä¸Šã§ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ç•°ãªã‚‹semanticsã®ç•°ãªã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br>LLMãŒæ„å‘³ã‚’ç†è§£ã—ã¦ã„ã‚‹ã“ã¨ã‚’æš—ç¤ºã—ã¦ã„ã‚‹<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fa4d2c68-bdbe-40ae-990d-10814ac8a204" alt="image" loading="lazy"></p>
<p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1660409936264970240?s=46&t=QJho5ctFkeax7s_UMOfWBQ"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/554" target="_blank" rel="noopener noreferrer" class="title-link">Active prompting with chain-of-thought for large language models, Diao+, The Hong Kong University of Science and Technology, ACL'24</a>
<span class="snippet"><span>Comment</span><p>ã—ã£ã‹ã‚Šã¨èª­ã‚ã¦ã„ãªã„ãŒã€CoT-answerãŒå­˜åœ¨ã—ãªã„trainingãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãŸã¨ãã«ã€nã‚µãƒ³ãƒ—ãƒ«ã«CoTã¨Answerã‚’ä¸ãˆã‚‹ã ã‘ã§Few-shotã®äºˆæ¸¬ã‚’testãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã§ãã‚‹ã‚ˆã†ã«ã—ãŸã„ã€ã¨ã„ã†ã®ãŒãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã£ã½ã„<br><br>ãã®ãŸã‚ã«ã€questionã«å¯¾ã—ã¦ã€training dataã«å¯¾ã—ã¦Few-Shot CoTã§äºˆæ¸¬ã‚’ã•ã›ãŸå ´åˆã‚„Zero-Shot CoTã«ã‚ˆã£ã¦äºˆæ¸¬ã‚’ã•ã›ãŸå ´åˆãªã©ã§answerã‚’å–å¾—ã—ã€answerã®ã°ã‚‰ã¤ãåº¦åˆã„ãªã©ã‹ã‚‰ä¸ç¢ºå®Ÿæ€§ã‚’æ¸¬å®šã™ã‚‹ã€‚<br><br>ãã—ã¦ã€ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„CoT-Answerãƒšã‚¢ã‚’å–å¾—ã—ã€äººé–“ãŒæ‰‹ä½œæ¥­ã§CoTã¨å›ç­”ã®ãƒšã‚¢ã‚’ä¸ãˆã€ãã®äººé–“ãŒä½œæˆã—ãŸã‚‚ã®ã‚’ç”¨ã„ã¦Testãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦FewShotã—ã¾ã—ã‚‡ã†ã€ã¨ã„ã†ã“ã¨ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/234747555-4b7bd0d5-f099-4288-a470-32206533e652.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2023-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/547" target="_blank" rel="noopener noreferrer" class="title-link">AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head, AAAI'24</a>
<span class="snippet"><span>GPT Summary</span>- AudioGPTã¯ã€è¤‡é›‘ãªéŸ³å£°æƒ…å ±ã‚’å‡¦ç†ã—ã€éŸ³å£°å¯¾è©±ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«AIã‚·ã‚¹ãƒ†ãƒ ã§ã‚ã‚‹ã€‚åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã¨ASRã€TTSã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’çµ„ã¿åˆã‚ã›ã€éŸ³å£°ã€éŸ³æ¥½ã€ãƒˆãƒ¼ã‚­ãƒ³ã‚°ãƒ˜ãƒƒãƒ‰ã®ç†è§£ã¨ç”Ÿæˆã‚’è¡Œã†ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€AudioGPTãŒå¤šæ§˜ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å‰µé€ ã‚’å®¹æ˜“ã«ã™ã‚‹èƒ½åŠ›ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>text, audio, imageã¨ã„ã£ãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªpromptã‹ã‚‰ã€audioã«é–¢ã™ã‚‹æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã‚’å®Ÿç¾ã§ãã‚‹ã‚·ã‚¹ãƒ†ãƒ </p>
<p>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’jointã§å­¦ç¿’ã—ãŸã¨ã„ã†ã‚ã‘ã§ã¯ãªãã€è‰²ã€…ãªãƒ¢ãƒ‡ãƒ«ã®çµ„ã¿åˆã‚ã›ã¦ã‚¿ã‚¹ã‚¯ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã£ã½ã„<br><br><img src="https://user-images.githubusercontent.com/12249301/234739859-f833706a-6040-484a-b015-553a719484d7.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2023-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/542" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Instruction-Finetuned Language Models, Chung+, Google, JMLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æŒ‡ç¤ºãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€ã‚¿ã‚¹ã‚¯æ•°ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã€ãƒã‚§ãƒ¼ãƒ³ãƒ»ã‚ªãƒ–ãƒ»ã‚½ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã§ã‚ã‚‹ã€‚Flan-PaLM 540Bã¯1.8Kã‚¿ã‚¹ã‚¯ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€PaLM 540Bã‚’ä¸Šå›ã‚‹+9.4%ã®æ”¹å–„ã‚’é”æˆã—ã€MMLUã§75.2%ã®æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚Flan-T5ã‚‚å¼·åŠ›ãªå°‘æ•°ã‚·ãƒ§ãƒƒãƒˆæ€§èƒ½ã‚’ç™ºæ®ã—ã€æŒ‡ç¤ºãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>T5ã‚’instruction tuningã—ãŸFlanT5ã®ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/PersonalizedGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2023-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/536" target="_blank" rel="noopener noreferrer" class="title-link">LaMP: When Large Language Models Meet Personalization, Selemi+, University of Massachusetts Amherst ï¼ˆw_ Google Researchï¼‰, ACL'24</a>
<span class="snippet"><span>Comment</span><p>
<strong># æ¦‚è¦<br><br>Personalizationã¯ãƒ¦ãƒ¼ã‚¶ã®ãƒ‹ãƒ¼ã‚ºã‚„å—œå¥½ã«å¿œãˆã‚‹ãŸã‚ã«é‡è¦ãªæŠ€è¡“ã§ã€IRã‚„RecSysã§ç››ã‚“ã«ç ”ç©¶ã•ã‚Œã¦ããŸãŒã€NLPã§ã¯ã‚ã¾ã‚Šå®Ÿæ–½ã•ã‚Œã¦ã“ãªã‹ã£ãŸã€‚ã—ã‹ã—ã€æœ€è¿‘ã®ã‚¿ã‚¹ã‚¯ã§ã€text classificationã‚„generation taskã§Personalizationã®é‡è¦æ€§ãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã®ã‚ˆã†ãªä¸­ã§ã€LLMã§personalizedãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆã—ã€è©•ä¾¡ã™ã‚‹ã“ã¨ã¯ã‚ã¾ã‚Šç ”ç©¶ã•ã‚Œã¦ã„ãªã„ã€‚ãã“ã§ã€LaMPãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ç”Ÿæˆã—ã€LLMã«ãŠã‘ã‚‹Personalizationã‚’ã™ã‚‹ãŸã‚ã®é–‹ç™ºã¨è©•ä¾¡ã‚’ã™ã‚‹ãŸã‚ã®ç¬¬ä¸€æ­©ã¨ã—ã¦ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br> <br><br># Personalizing LLM Outputs<br><br>LLMã«å¯¾ã—ã¦Personalizedãªoutputã‚’ã•ã›ã‚‹ãŸã‚ã«ã¯ã€profileã‚’promptã«åŸ‹ã‚è¾¼ã‚€ã“ã¨ãŒåŸºæœ¬çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ãªã‚‹ã€‚<br><br><br><br>## Problem Formulation<br><br>ã¾ãšã€user profileï¼ˆãƒ¦ãƒ¼ã‚¶ã«é–¢ã™ã‚‹recordã®é›†åˆï¼‰ã‚’ãƒ¦ãƒ¼ã‚¶ã¨ã¿ãªã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã¯ä»¥ä¸‹ã®3ã¤ã§æ§‹æˆã•ã‚Œã‚‹ï¼š<br><br>- x: ãƒ¢ãƒ‡ãƒ«ã®inputã¨ãªã‚‹input sequence<br><br>- y: ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã™ã‚‹ã“ã¨ã‚’æœŸå¾…ã™ã‚‹target output<br><br>- u: user profileï¼ˆãƒ¦ãƒ¼ã‚¶ã®å—œå¥½ã‚„requirementsã‚’æ‰ãˆã‚‹ãŸã‚ã®è£œåŠ©çš„ãªæƒ…å ±ï¼‰<br><br>ãã—ã¦ã€p\(y | x, u) ã‚’æœ€å¤§åŒ–ã™ã‚‹å•é¡Œã¨ã—ã¦å®šå¼åŒ–ã•ã‚Œã‚‹ã€‚ãã‚Œãã‚Œã®ãƒ¦ãƒ¼ã‚¶uã«å¯¾ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã¯{\(x\_u1, y\_u1,)...\(x\_un, y\_un)}ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br><br><br>## A Retrieval Augmentation Approach for Personaliozing LLMs<br><br>user profileã¯åŸºæœ¬çš„ã«ã‚ã¡ã‚ƒã‚ã¡ã‚ƒå¤šãã€promptã«å…¥ã‚Œè¾¼ã‚€ã“ã¨ã¯éç¾å®Ÿçš„ã€‚ãã“ã§ã€reteival augmentation approachã¨å‘¼ã°ã‚Œã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚LLMã®context windowã¯é™ã‚‰ã‚Œã¦ã„ã‚‹ã®ã§ã€profileã®ã†ã¡ã®subsetã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒç¾å®Ÿçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ãªã‚‹ã€‚ã¾ãŸã€å¿…ãšã—ã‚‚å…¨ã¦ã®ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã™ã‚‹ãŸã‚ã«æœ‰ç”¨ã¨ã¯é™ã‚‰ãªã„ã€‚ã“ã®ãŸã‚ã€retrieval augmentation approachã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br>retrieval augmentation approachã§ã¯ã€ç¾åœ¨ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã«å¯¾ã—ã¦ã€relevantãªéƒ¨åˆ†ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠçš„ã«æŠ½å‡ºã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹ã€‚<br><br><br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/234442873-01a4961b-feab-42d3-b59c-ee26daad957f.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br><br><br>\(x\_i, y\_i)ã«å¯¾ã—ã¦personalizationã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€3ã¤ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ï¼š<br><br>1. query generation function: x\_iã«åŸºã¥ãuser profileã‹ã‚‰relevantãªæƒ…å ±ã‚’å¼•ã£å¼µã£ã¦ãã‚‹query qã‚’ç”Ÿæˆã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ<br><br>2. retrieval model R\(q, P\_u, k): query q, ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«P\_u, ã‚’ç”¨ã„ã¦ã€kå€‹ã®relevantãªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¼•ã£å¼µã£ã¦ãã‚‹ãƒ¢ãƒ‡ãƒ«<br><br>3. prompt construction function: xã¨reteival modelãŒå¼•ã£å¼µã£ã¦ããŸã‚¨ãƒ³ãƒˆãƒªã‹ã‚‰promptã‚’ä½œæˆã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ<br><br>1, 2, 3ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸprompt x^barã¨ã€yã«ã‚ˆã£ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã€ã‚ã‚‹ã„ã¯è©•ä¾¡ã™ã‚‹ã€‚<br><br>ã“ã®ç ”ç©¶ã§ã¯ã€Rã¨ã—ã¦ Contriever &lt;a href=\"https://github.com/AkihikoWatanabe/paper\_notes/issues/540\" target=\"\_blank\" rel=\"noopener noreferrer\"&gt;Contrirver&lt;/a&gt;
</strong>
<br>
 , BM25, random selectionã®3ç¨®é¡ã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚<br><br><br><br>
<strong># LaMPãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br><br>GLUEã‚„Super Glueã€KILTã€GENã¨ã„ã£ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã€"one-size-fits-all"ãªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã¨è©•ä¾¡ã‚’å‰æã¨ã—ã¦ãŠã‚Šã€ãƒ¦ãƒ¼ã‚¶ã®ãƒ‹ãƒ¼ã‚ºã«ç­”ãˆã‚‹ãŸã‚ã®é–‹ç™ºã‚’è¨±å®¹ã—ã¦ã„ãªã„ã€‚ä¸€æ–¹ã§ã€LaMPã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªPersonalizationãŒå¿…è¦ãªã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã‚’çµ±åˆã—ã¦ä½œæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹ã€‚<br><br>- Personalized Text Classification<br><br>  - Personalized Citation Identification (binary classification)<br><br>    - Task definition<br><br>      - user u ãŒ topic xã«é–¢ã™ã‚‹è«–æ–‡ã‚’æ›¸ã„ãŸã¨ãã«ã€ä½•ã®è«–æ–‡ã‚’citeã™ã¹ãã‹ã‚’æ±ºã‚ã‚‹ã‚¿ã‚¹ã‚¯<br><br>      - user uãŒæ›¸ã„ãŸè«–æ–‡ã®ã‚¿ã‚¤ãƒˆãƒ«ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€2ã¤ã®candidate paperã®ã†ã¡ã©ã¡ã‚‰ã‚’referenceã¨ã—ã¦åˆ©ç”¨ã™ã¹ãã‹ã‚’æ±ºå®šã™ã‚‹2å€¤åˆ†é¡<br><br>    - Data Collection<br><br>      - Citation Network Datasetã‚’åˆ©ç”¨ã€‚æœ€ä½ã§ã‚‚50æœ¬ä»¥ä¸Šè«–æ–‡ã‚’æ›¸ã„ã¦ã„ã‚‹authorã‚’æŠ½å‡ºã—ã€authorã®è«–æ–‡ã®ã†ã¡ãƒ©ãƒ³ãƒ€ãƒ ã«è«–æ–‡ã¨è«–æ–‡ã®å¼•ç”¨ã‚’æŠ½å‡º<br><br>      - negative document selectionã¨ã—ã¦ã€ãƒ©ãƒ³ãƒ€ãƒ ã«å…±è‘—è€…ãŒciteã—ã¦ã„ã‚‹è«–æ–‡ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°<br><br>   - Profile Specification<br><br>     -  ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ãƒ¦ãƒ¼ã‚¶ãŒæ›¸ã„ãŸå…¨ã¦ã®paper<br><br>     - titleã¨abstractã®ã¿ã‚’user profileã¨ã—ã¦ä¿æŒã—ãŸ<br><br>    - Evaluation<br><br>      - train/valid/testã«åˆ†ã‘ã€accuracyã§è©•ä¾¡ã™ã‚‹<br><br>  - Personalized News Categorization (15 categoryåˆ†é¡)<br><br>    - Task definition<br><br>      - LLMãŒ journalist uã«ã‚ˆã£ã¦æ›¸ã‹ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åˆ†é¡ã™ã‚‹èƒ½åŠ›ã‚’å•ã†ã‚¿ã‚¹ã‚¯<br><br>      - u ã«ã‚ˆã£ã¦æ›¸ã‹ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹xãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã€uã®éå»ã®è¨˜äº‹ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹ã‚«ãƒ†ã‚´ãƒªã®ä¸­ã‹ã‚‰è©²å½“ã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’äºˆæ¸¬ã™ã‚‹ã‚¿ã‚¹ã‚¯<br><br>    - Data Collection<br><br>      - news categorization datasetã‚’åˆ©ç”¨ï¼ˆHuff Postã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼‰<br><br>      - è¨˜äº‹ã‚’first authorã§ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°<br><br>      - ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ã—ãŸè¨˜äº‹ç¾¤ã‚’train/valid/testã«åˆ†å‰²<br><br>      - ãã‚Œãã‚Œã®è¨˜äº‹ã«ãŠã„ã¦ã€è¨˜äº‹ã‚’inputã¨ã—ã€ãã®è¨˜äº‹ã®ã‚«ãƒ†ã‚´ãƒªã‚’outputã¨ã™ã‚‹ã€‚ãã—ã¦æ®‹ã‚Šã®è¨˜äº‹ã‚’user profileã¨ã™ã‚‹ã€‚<br><br>    - Profile Specification<br><br>      - ãƒ¦ãƒ¼ã‚¶ã«ã‚ˆã£ã¦æ›¸ã‹ã‚ŒãŸè¨˜äº‹ã®é›†åˆ<br><br>    - Evaluation<br><br>      - accuracy, macro-averaged F1ã§è©•ä¾¡ <br><br>  - Personalized Product Rating (5-star rating)<br><br>    - Task definition<br><br>      - ãƒ¦ãƒ¼ã‚¶uãŒè¨˜è¿°ã—ãŸreviewã«åŸºã¥ã„ã¦ã€LLMãŒãƒ¦ãƒ¼ã‚¶uã®æœªçŸ¥ã®ã‚¢ã‚¤ãƒ†ãƒ ã«å¯¾ã™ã‚‹ratingã‚’äºˆæ¸¬ã™ã‚‹æ€§èƒ½ã‚’å•ã†<br><br>    - Data Collection<br><br>      - Amazon Reviews Datasetã‚’åˆ©ç”¨<br><br>      - reviewãŒ100ä»¶æœªæº€ã€ãã—ã¦ã»ã¨ã‚“ã©ã®reviewãŒå¤–ã‚Œå€¤ãªãƒ¦ãƒ¼ã‚¶1%ã‚’é™¤å¤–<br><br>      - ãƒ©ãƒ³ãƒ€ãƒ ã«subsetã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€train/valid/testã«åˆ†ã‘ãŸ<br><br>      - input-output pairã¨ã—ã¦ã¯ã€inputã¨ã—ã¦ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒ¦ãƒ¼ã‚¶ã®reviewã‚’é¸æŠã—ã€ãã®ä»–ã®reviewã‚’profileã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã€‚ãã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãŒinputã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã§ä»˜ä¸ã—ãŸratingãŒground truthã¨ãªã‚‹ã€‚<br><br>    - Profile Specification<br><br>      - ãƒ¦ãƒ¼ã‚¶ã®ãƒ¬ãƒ“ãƒ¥<br><br>    - Evaluation<br><br>      -  ttrain/valid/testã«åˆ†ã‘ã¦RMSE, MAEã§è©•ä¾¡ã™ã‚‹<br><br>- Personalized Text Generation<br><br>  - Personalized News Headline Generation<br><br>    - Task definition<br><br>      - ãƒ¦ãƒ¼ã‚¶uãŒè¨˜è¿°ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯<br><br>      - ç‰¹ã«ã€LLMãŒä¸ãˆã‚‰ã‚ŒãŸprofileã«åŸºã¥ã„ã¦ãƒ¦ãƒ¼ã‚¶ã®interestsã‚„writing styleã‚’æ‰ãˆã€é©åˆ‡ã«headlinã«åæ˜ ã•ã›ã‚‹èƒ½åŠ›ã‚’å•ã†<br><br>   - Data Collection<br><br>     - News Categorization datasetã‚’åˆ©ç”¨ï¼ˆHuff Postï¼‰<br><br>     - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯authorã®æƒ…å ±ãŒæä¾›ã•ã‚Œã¦ã„ã‚‹<br><br>     - ãã‚Œãã‚Œã®first authorã”ã¨ã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ã—ã€ãã‚Œãã‚Œã®è¨˜äº‹ã‚’input, headlineã‚’outputã¨ã—ãŸã€‚ãã—ã¦æ®‹ã‚Šã®è¨˜äº‹ã‚’profileã¨ã—ãŸ<br><br>   - Profile Specification<br><br>     - ãƒ¦ãƒ¼ã‚¶ã®éå»ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã¨ãã®headlineã®é›†åˆã‚’profileã¨ã™ã‚‹<br><br>   - Evaluation<br><br>     - ROUGE-1, ROUGE-Lã§è©•ä¾¡<br><br>  - Personalized Scholarly Title Generation<br><br>    - Task Definition<br><br>      - ãƒ¦ãƒ¼ã‚¶ã®éå»ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è€ƒæ…®ã—ã€LLMãŒresearch paperã®titleã‚’ç”Ÿæˆã™ã‚‹èƒ½åŠ›ã‚’æ¸¬ã‚‹<br><br>    - Data Collection<br><br>      - Citation Network Datasetã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨<br><br>      - abstractã‚’input, titleã‚’outputã¨ã—ã€æ®‹ã‚Šã®paperã‚’profileã¨ã—ãŸ<br><br>    - Profile Specification<br><br>      - ãƒ¦ãƒ¼ã‚¶ãŒæ›¸ã„ãŸpaperã®é›†åˆï¼ˆabstractã®ã¿ã‚’åˆ©ç”¨ï¼‰<br><br>  - Personalized Email Subject Generation<br><br>    - Task Definition<br><br>      - LLMãŒãƒ¦ãƒ¼ã‚¶ã®writing styleã«åˆã‚ã›ã¦ã€Emailã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ›¸ãèƒ½åŠ›ã‚’æ¸¬ã‚‹<br><br>    - Data Collection<br><br>      - Avocado Resaerch Email Collectionãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨<br><br>      - 5å˜èªæœªæº€ã®subjectã‚’æŒã¤ãƒ¡ãƒ¼ãƒ«ã€æœ¬æ–‡ãŒ30å˜èªæœªæº€ã®ãƒ¡ãƒ¼ãƒ«ã‚’é™¤å¤–ã€<br><br>      - é€ä¿¡ä¸»ã®email addressã§ãƒ¡ãƒ¼ãƒ«ã‚’ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°<br><br>      - input _outputãƒšã‚¢ã¯ã€emailæœ¬æ–‡ã‚’inputã¨ã—ã€å¯¾å¿œã™ã‚‹subjectã‚’outputã¨ã—ãŸã€‚ä»–ã®ãƒ¡ãƒ¼ãƒ«ã¯profile<br><br>    - Profile Specification<br><br>      -  ãƒ¦ãƒ¼ã‚¶ã®emailã®é›†åˆ<br><br>    - Evaluation<br><br>      - ROUGE-1, ROUGE-Lã§è©•ä¾¡ <br><br>  - Personalized Tweet Paraphrasing<br><br>    - Task Definition<br><br>      - LLMãŒãƒ¦ãƒ¼ã‚¶ã®writing styleã‚’è€ƒæ…®ã—ã€ãƒ„ã‚¤ãƒ¼ãƒˆã®paraphrasingã‚’ã™ã‚‹èƒ½åŠ›ã‚’å•ã†<br><br>    - Data Collection<br><br>      - Sentiment140 datasetã‚’åˆ©ç”¨<br><br>      - æœ€ä½10å˜èªã‚’æŒã¤ãƒ„ã‚¤ãƒ¼ãƒˆã®ã¿ã‚’åˆ©ç”¨<br><br>      - userIDã§ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ã—ã€10 tweetsä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ã¯é™¤å¤–<br><br>      - ãƒ©ãƒ³ãƒ€ãƒ ã«1ã¤ã®tweetã‚’é¸æŠã—ã€ChatGPT(gpt-3.5-turbo)ã§paraphraseã—ãŸ<br><br>      - paraphraseç‰ˆã®tweetã‚’input, å…ƒãƒ„ã‚¤ãƒ¼ãƒˆã‚’outputã¨ã—ã€input-output pairã‚’ä½œã£ãŸã€‚<br><br>    - User Profile Specification<br><br>      - ãƒ¦ãƒ¼ã‚¶ã®éå»ã®ãƒ„ã‚¤ãƒ¼ãƒˆ<br><br>    - Evaluation<br><br>      - ROUGE-1, ROUGE-Lã§è©•ä¾¡<br><br><br><br>&lt;/p&gt;<p># å®Ÿé¨“<br><br>## Experimental Setup<br><br>- FlanT5-baesã‚’finetuningã—ãŸ<br><br>- ãƒ¦ãƒ¼ã‚¶å˜ä½ã§ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã®ã‹å¦ã‹ãŒè¨˜è¼‰ã•ã‚Œã¦ãŠã‚‰ãšä¸æ˜<br><br>## çµæœ<br><br>- Personalizationå…¥ã‚ŒãŸæ–¹ãŒå…¨ã¦ã®ã‚¿ã‚¹ã‚¯ã§ã‚ˆããªã£ãŸ<br><br>- Retrievalãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã¯ã€randomã®å ´åˆã§ã‚‚è‰¯ããªã£ãŸãŒã€åŸºæœ¬çš„ã«ã¯Contrirverã‚’åˆ©ç”¨ã—ãŸå ´åˆãŒæœ€ã‚‚è‰¯ã‹ã£ãŸ<br><br>  - =&gt; é©åˆ‡ãªprofileã‚’é¸æŠã—promptã«å«ã‚ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸ<br><br>- RãŒæŠ½å‡ºã™ã‚‹ã‚µãƒ³ãƒ—ãƒ« kã‚’å¢—ã‚„ã™ã¨ã€äºˆæ¸¬æ€§èƒ½ãŒå¢—åŠ ã™ã‚‹å‚¾å‘ã‚‚ã‚ã£ãŸãŒã€ä¸€éƒ¨ã‚¿ã‚¹ã‚¯ã§ã¯æ€§èƒ½ã®ä½ä¸‹ã‚‚æ‹›ã„ãŸ<br><br>- dev setã‚’åˆ©ç”¨ã—ã€BM25/Contrieverã®ã©ã¡ã‚‰ã‚’åˆ©ç”¨ã™ã‚‹ã‹ã€kã‚’ã„ãã¤ã«è¨­å®šã™ã‚‹ã‹ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸçµæœã€å…¨ã¦ã®çµæœãŒæ”¹å–„ã—ãŸ<br><br>- FlanT5-XXLã¨gpt-3.5-turboã‚’ç”¨ã„ãŸZero-shotã®è¨­å®šã§ã‚‚å®Ÿé¨“ã€‚tweet paraphrasingã‚¿ã‚¹ã‚¯ã‚’é™¤ãã€zero-shotã§ã‚‚user profileã‚’LLMã§åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ã€‚å°ã•ãªãƒ¢ãƒ‡ãƒ«ã§ã‚‚finetuningã™ã‚‹ã“ã¨ã§ã€zero-shotã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã«downstreamã‚¿ã‚¹ã‚¯ã§ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’ç²å¾—ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ï¼ˆãŸã ã—ã€ã‚ã¡ã‚ƒã‚ã¡ã‚ƒæ”¹å–„ã—ã¦ã„ã‚‹ã¨ã„ã†ã‚ã‘ã§ã‚‚ãªã•ãã†ï¼‰ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/234452179-6fac1cd9-982f-4b48-8dfe-1d742dc1c221.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/234452837-8d8cdfed-ab85-4d1e-99d7-aad35ddc8979.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/234453453-a2393c95-a820-404f-b21c-3332f53cb851.png" alt="image" loading="lazy"><br><br></p>
<p># LaMPã«ã‚ˆã£ã¦å¯èƒ½ãªResearch Problem<br><br>## Prompting for Personalization<br><br>- Augmentationãƒ¢ãƒ‡ãƒ«ä»¥å¤–ã®LLMã¸ã®ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®åŸ‹ã‚è¾¼ã¿æ–¹æ³•<br><br>- hard promptingã‚„soft prompting <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/473" target="_blank" rel="noopener noreferrer">[Paper Note] The Power of Scale for Parameter-Efficient Prompt Tuning, Brian Lester+, arXiv'21, 2021.04</a>
&lt;/strong&gt;
<br>
 ã®æ´»ç”¨<br><br>## Evaluation of Personalized Text Generation<br><br>- ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã§åˆ©ç”¨ã•ã‚Œã‚‹æ€§èƒ½æŒ‡æ¨™ã¯ãƒ¦ãƒ¼ã‚¶ã®æƒ…å ±ã‚’è©•ä¾¡ã®ãƒ—ãƒ­ã‚»ã‚¹ã§è€ƒæ…®ã—ã¦ã„ãªã„<br><br>- Personalizedãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®é©åˆ‡ãªmetricã¯ã©ã‚“ãªã‚‚ã®ãŒã‚ã‚‹ã‹ï¼Ÿ<br><br>## Learning to Retrieve from User Profiles<br><br>- Learning to Rankã‚’Retrieval modelã«é©ç”¨ã™ã‚‹æ–¹å‘æ€§</p>
<p>LaMPã®ä½œæˆã«åˆ©ç”¨ã—ãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¸€è¦§<br><br><img src="https://user-images.githubusercontent.com/12249301/234457098-5c2ba78f-dc74-45e4-bf91-f07ffd99bcb4.png" alt="image" loading="lazy"><br><br></p>
<p>å®Ÿè£…ã¨leaderboard<br><br>


<a href="https://lamp-benchmark.github.io/leaderboard" target="_blank" rel="noopener noreferrer">https://lamp-benchmark.github.io/leaderboard</a>


</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DataGeneration.html" target="_blank" rel="noopener noreferrer">#DataGeneration</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/533" target="_blank" rel="noopener noreferrer" class="title-link">WizardLM: Empowering Large Language Models to Follow Complex Instructions, Xu+, Microsoft_Peking University, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€LLMã‚’ç”¨ã„ã¦è¤‡é›‘ãªæŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹æ‰‹æ³•Evol-Instructã‚’ææ¡ˆã€‚åˆæœŸã®æŒ‡ç¤ºã‚»ãƒƒãƒˆã‚’æ®µéšçš„ã«æ›¸ãæ›ãˆã€ç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã§LLaMAã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€WizardLMãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã€‚è©•ä¾¡çµæœã§ã¯ã€Evol-Instructã‹ã‚‰ã®æŒ‡ç¤ºãŒäººé–“ä½œæˆã®ã‚‚ã®ã‚ˆã‚Šå„ªã‚Œã€WizardLMã¯ChatGPTã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚AIé€²åŒ–ã«ã‚ˆã‚‹æŒ‡ç¤ºç”ŸæˆãŒLLMå¼·åŒ–ã®æœ‰æœ›ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>instruction trainingã¯å¤§ããªæˆåŠŸã‚’åã‚ã¦ã„ã‚‹ãŒã€äººé–“ãŒãã‚Œã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹ã®ã¯ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã€‚ã¾ãŸã€ãã‚‚ãã‚‚è¤‡é›‘ãªinstructionã‚’äººé–“ãŒä½œæˆã™ã‚‹ã®ã¯è‹¦åŠ´ã™ã‚‹ã€‚ãã“ã§ã€LLMã«è‡ªå‹•çš„ã«ä½œæˆã•ã›ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ï¼ˆã“ã‚Œã¯self instructã¨ä¸€ç·’ï¼‰ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹éš›ã¯ã€seed setã‹ã‚‰å§‹ã‚ã€step by stepã§instructionã‚’rewriteã—ã€ã‚ˆã‚Šè¤‡é›‘ãªinstructionã¨ãªã‚‹ã‚ˆã†ã«ã—ã¦ã„ãã€‚<br>ã“ã‚Œã‚‰ã®å¤šæ®µçš„ãªè¤‡é›‘åº¦ã‚’æŒã¤instructionã‚’LLaMaãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã«é£Ÿã‚ã›ã¦finetuningã—ãŸï¼ˆã“ã‚Œã‚’WizardLMã¨å‘¼ã¶ï¼‰ã€‚äººæ‰‹è©•ä¾¡ã®çµæœã€WizardLMãŒChatGPTã‚ˆã‚Šã‚‚å¥½ã¾ã—ã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ç‰¹ã«ã€WizaraLMã¯ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚„ã€æ•°å€¤è¨ˆç®—ã¨ã„ã£ãŸé›£ã—ã„ã‚¿ã‚¹ã‚¯ã§æ”¹å–„ã‚’ç¤ºã—ã¦ãŠã‚Šã€è¤‡é›‘ãªinstructionã‚’å­¦ç¿’ã«åˆ©ç”¨ã™ã‚‹ã“ã¨ã®é‡è¦æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</p>
<p>EvolInstructã‚’ææ¡ˆã€‚"1+1=?"ã¨ã„ã£ãŸã‚·ãƒ³ãƒ—ãƒ«ãªinstructionã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã—ã€ã“ã‚Œã‚’LLMã‚’åˆ©ç”¨ã—ã¦æ®µéšçš„ã«complexã«ã—ã¦ã„ãã€‚complexã«ã™ã‚‹æ–¹æ³•ã¯2é€šã‚Šï¼š<br><br>- In-Depth Evolving: instructionã‚’5ç¨®é¡ã®operationã§æ·±æ˜ã‚Šã™ã‚‹ï¼ˆblue direction lineï¼‰<br><br>  - add constraints<br><br>  - deepening<br><br>  - concretizing<br><br>  - increase reasoning steps<br><br>  - complicate input<br><br>- In-breadth Evolving: givenãªinstructionã‹ã‚‰æ–°ã—ã„instructionã‚’ç”Ÿæˆã™ã‚‹<br><br><br><br>ä¸Šè¨˜ã®Evolvingã¯ç‰¹å®šã®promptã‚’ä¸ãˆã‚‹ã“ã¨ã§å®Ÿè¡Œã•ã‚Œã‚‹ã€‚<br><br>ã¾ãŸã€LLMã¯Evolvingã«å¤±æ•—ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã®ã§ã€Elimination Evolvingã¨å‘¼ã°ã‚Œã‚‹ãƒ•ã‚£ãƒ«ã‚¿ã‚’åˆ©ç”¨ã—ã¦ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸã€‚<br><br>ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã§ã¯4ç¨®é¡ã®å¤±æ•—ã™ã‚‹situationã‚’æƒ³å®šã—ã€1ã¤ã§ã¯LLMã‚’åˆ©ç”¨ã€‚2æšç›®ç”»åƒã®ã‚ˆã†ãªinstructionã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€‚<br><br>1. instructionã®æƒ…å ±é‡ãŒå¢—ãˆã¦ã„ãªã„å ´åˆã€‚<br><br>2. instructionãŒLLMã«ã‚ˆã£ã¦å¿œç­”å›°é›£ãªå ´åˆï¼ˆçŸ­ã™ãã‚‹å ´åˆã‚„sorryã¨è¨€ã£ã¦ã„ã‚‹å ´åˆï¼‰<br><br>3. puctuationã‚„stop wordsã«ã‚ˆã£ã¦ã®ã¿æ§‹æˆã•ã‚Œã¦ã„ã‚‹å ´åˆ <br><br>4.æ˜ã‚‰ã‹ã«promptã®ä¸­ã‹ã‚‰å˜èªã‚’ã‚³ãƒ”ãƒ¼ã—ãŸã ã‘ã®instructionï¼ˆgiven prompt, rewritten prompt, #Rewritten Prompt#ãªã©ï¼‰<br><br><img src="https://user-images.githubusercontent.com/12249301/234436445-e84ff44e-7b0b-4217-a735-7444b04bd760.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/234437210-6cb6d75f-509a-4f2e-a767-dba8861d8a69.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<a class="button" href="articles/Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<a class="button" href="articles/Surface-level%20Note.html" target="_blank" rel="noopener noreferrer">#Surface-level Note</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/532" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in  Large Language Models, Jiashuo Sun+, NAACL'24 Findings, 2023.04</a>
<span class="snippet"><span>GPT Summary</span>- Iter-CoTã¯ã€LLMsã®æ¨è«–ãƒã‚§ãƒ¼ãƒ³ã®ã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã€æ­£ç¢ºã§åŒ…æ‹¬çš„ãªæ¨è«–ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®åå¾©çš„ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ”ãƒ³ã‚°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚é©åº¦ãªé›£æ˜“åº¦ã®è³ªå•ã‚’é¸æŠã™ã‚‹ã“ã¨ã§ã€ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã€10ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ç«¶äº‰åŠ›ã®ã‚ã‚‹æ€§èƒ½ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>Zero shot CoTã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã—ã€æ­£ã—ãå•é¡Œã«å›ç­”ã§ãã‚‹ã‚ˆã†ã«reasoningã‚’æ”¹å–„ã™ã‚‹ã‚ˆã†ã«promptã‚’reviseã—ç¶šã‘ã‚‹ãƒ«ãƒ¼ãƒ—ã‚’å›ã™ã€‚æœ€çµ‚çš„ã«ãƒ«ãƒ¼ãƒ—ã—ãŸçµæœã‚’è¦ç´„ã—ã€ãã‚Œã‚‰ã‚’ãƒ—ãƒ¼ãƒ«ã™ã‚‹ã€‚ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ã¯ã€ãƒ—ãƒ¼ãƒ«ã®ä¸­ã‹ã‚‰Nshotã‚’ã‚µãƒ³ãƒ—ãƒ«ã—inferenceã‚’è¡Œã†ã€‚<br><img src="https://user-images.githubusercontent.com/12249301/234311707-0d6f3443-681a-4309-917b-d21fd1a8c024.jpeg" alt="image" loading="lazy"></p>
<p>ã§ããã†ã ãªãƒ¼ã¨æ€ã£ã¦ã„ãŸã‘ã©ã€æ—©ãã‚‚ã‚„ã‚‰ã‚Œã¦ã—ã¾ã£ãŸ</p>
<p>å®Ÿè£…: 


<a href="https://github.com/GasolSun36/Iter-CoT" target="_blank" rel="noopener noreferrer">https://github.com/GasolSun36/Iter-CoT</a>


</p>
<p>
<strong># ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³: æ—¢å­˜ã®CoT Promptingã®å•é¡Œç‚¹<br><br>## Inappropriate Examplars can Reduce Performance<br><br>ã¾ãšã€æ—¢å­˜ã®CoT promptingæ‰‹æ³•ã¯ã€sampling examplarãŒã‚·ãƒ³ãƒ—ãƒ«ã€ã‚ã‚‹ã„ã¯æ¥µã‚ã¦è¤‡é›‘ãªï¼ˆhop-based criterionã«ãŠã„ã¦; ã‚¿ã‚¹ã‚¯ã‚’è§£ããŸã‚ã«ä½•ã‚¹ãƒ†ãƒƒãƒ—å¿…è¦ã‹ã¨ã„ã†æƒ…å ±; ã—ã°ã—ã°äººæ‰‹ã§ä»˜ä¸ã•ã‚Œã¦ã„ã‚‹ï¼Ÿï¼‰ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ã—ã¾ã†å•é¡ŒãŒã‚ã‚‹ã€‚ã‚·ãƒ³ãƒ—ãƒ«ã™ãã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠã™ã‚‹ã¨ã€æ—¢ã«LLMã¯é©åˆ‡ã«ã‚·ãƒ³ãƒ—ãƒ«ãªå›ç­”ã«ã¯ç­”ãˆã‚‰ã‚Œã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€demonstrationãŒå†—é•·ã§é™å®šçš„ã«ãªã£ã¦ã—ã¾ã†ã€‚åŠ ãˆã¦ã€æ¥µç«¯ã«è¤‡é›‘ãªexampleã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã¨ã€è¤‡é›‘ãªquestionã«å¯¾ã—ã¦ã¯æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ãŒã€ã‚·ãƒ³ãƒ—ãƒ«ãªå•é¡Œã«å¯¾ã™ã‚‹æ­£ç­”ç‡ãŒä¸‹ãŒã£ã¦ã—ã¾ã†ã€‚<br><br><br><br>ç¶šã„ã¦ã€demonstrationä¸­ã§èª¤ã£ãŸreasoning chainã‚’åˆ©ç”¨ã—ã¦ã—ã¾ã†ã¨ã€inferenceæ™‚ã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹å•é¡ŒãŒã‚ã‚‹ã€‚ä¸‹å›³ã«ç¤ºã—ãŸé€šã‚Šã€èª¤ã£ãŸdemonstrationãŒå¢—åŠ ã™ã‚‹ã«ã¤ã‚Œã¦ã€æœ€çµ‚çš„ãªäºˆæ¸¬æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹å‚¾å‘ã«ã‚ã‚‹ã€‚<br><br><br><br>ã“ã‚Œã‚‰2ã¤ã®èª²é¡Œã¯ã€ç¾åœ¨ã®ãƒ¡ã‚¤ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ãªæ‰‹æ³•ï¼ˆquestionã‚’é¸æŠã—ã€reasoning chainã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ï¼‰ã«ä¸€èˆ¬çš„ã«å­˜åœ¨ã™ã‚‹ã€‚<br><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/556" target="_blank" rel="noopener noreferrer">Automatic Chain of Thought Prompting in Large Language Models, Zhang+, Shanghai Jiao Tong University, ICLR'23</a>
</strong>
<br>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/555" target="_blank" rel="noopener noreferrer">Automatic prompt augmentation and selection with chain-of-thought from labeled data, Shum+, The Hong Kong University of Science and Technology, arXiv'23</a>
<br><br>ã®ã‚ˆã†ã«æ¨è«–æ™‚ã«é©åˆ‡ãªdemonstrationã‚’é¸æŠã™ã‚‹ã‚ˆã†ãªå–ã‚Šçµ„ã¿ã¯è¡Œã‚ã‚Œã¦ãã¦ã„ã‚‹ãŒã€test questionã«å¯¾ã—ã¦æ¨è«–ã™ã‚‹ãŸã‚ã«ã€é©åˆ‡ãªexamplarsã‚’é¸æŠã™ã‚‹ã‚ˆã†ãªæ–¹æ³•ã¯è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å¢—å¤§ã•ã›ã¦ã—ã¾ã†ã€‚<br><br>ã“ã‚Œã‚‰ç ”ç©¶ã¯èª¤ã£ãŸrationaleã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«ã®åˆ©ç”¨ã‚’æœ€å°é™ã«æŠ‘ãˆã¦ã€ãã®æ‚ªå½±éŸ¿ã‚’é˜²ãã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚<br><br><br><br>ä¸€æ–¹ã§ã€ã“ã®ç ”ç©¶ã§ã¯ã€èª¤ã£ãŸrationaleã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«ã‚’æ´»ç”¨ã—ã¦æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ã“ã‚Œã¯ã€ãŸã¨ãˆã°å­¦ç”ŸãŒé›£è§£ã ãŒå›ç­”å¯èƒ½ãªå•é¡Œã«å–ã‚Šçµ„ã‚€ã“ã¨ã«ã‚ˆã£ã¦ã€å•é¡Œè§£æ±ºã‚¹ã‚­ãƒ«ã‚’å‘ä¸Šã•ã›ã‚‹æ–¹æ³•ã«é¡ä¼¼ã—ã¦ã„ã‚‹ï¼ˆã™ãªã‚ã¡ã€é–“é•ãˆãŸéƒ¨åˆ†ã‹ã‚‰å­¦ã¶ï¼‰ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/234752168-fe1d83a4-8d29-4f6c-8aa1-6bde1706beea.png" alt="image" loading="lazy"><br><br><br><br>
<strong>## Large Language Models can self-Correct with Bootstrapping<br><br>Zero-Shot CoTã§reasoning chainã‚’ç”Ÿæˆã—ã€èª¤ã£ãŸreasoning chainã‚’ç”Ÿæˆã—ãŸpromptã‚’**LLMã«æ¨æ•²ã•ã›(self-correction)**æ­£ã—ã„å‡ºåŠ›ãŒå¾—ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ã“ã†ã„ã£ãŸãƒ—ãƒ­ã‚»ã‚¹ã‚’ç¹°ã‚Šè¿”ã—ã€correct sampleã‚’å¢—ã‚„ã™ã“ã¨ã§ã©ã‚“ã©ã‚“æ€§èƒ½ãŒæ”¹å–„ã—ã¦ã„ã£ãŸã€‚ã“ã‚Œã«åŸºã¥ã„ã¦ã€IterCoTã‚’ææ¡ˆã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/234786084-5a6055f6-6f42-4546-bcbf-686b1d759ca9.png" alt="image" loading="lazy"><br><br>&lt;/p&gt;<p># IterCoT: Iterative Bootstrapping in Chain-of-Thought Prompting<br><br>IterCoTã¯weak bootstrappingã¨strong bootstrappingã«ã‚ˆã£ã¦æ§‹æˆã•ã‚Œã‚‹ã€‚<br><br><br><br>## Weak bootstrapping<br><br>- Initialization<br><br>  - Training setã«å¯¾ã—ã¦Zero-shot CoTã‚’å®Ÿæ–½ã—ã€reasoning chainã¨answerã‚’å¾—<br><br>- Bootstrapping <br><br>  - å›ç­”ãŒèª¤ã£ã¦ã„ãŸå„ã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã—ã¦ã€Revise-Promptã‚’é©ç”¨ã—LLMã«èª¤ã‚Šã‚’æŒ‡æ‘˜ã—ã€æ–°ã—ã„å›ç­”ã‚’ç”Ÿæˆã•ã›ã‚‹ã€‚<br><br>  - å›ç­”ãŒæ­£ç¢ºã«ãªã‚‹ã¾ã§ã“ã‚Œã‚’ç¹°ã‚Šè¿”ã™ã€‚<br><br>- Summarization<br><br>  - æ­£ã—ã„å›ç­”ãŒå¾—ã‚‰ã‚ŒãŸã‚‰ã€Summary-Promptã‚’åˆ©ç”¨ã—ã¦ã€ã“ã‚Œã¾ã§ã®èª¤ã£ãŸrationaleã¨ã€æ­£è§£ã®rationaleã‚’åˆ©ç”¨ã—ã€æœ€çµ‚çš„ãªreasoning chain (Iter-CoT)ã‚’ç”Ÿæˆã™ã‚‹ã€‚<br><br>  - å…¨ä½“ã®contextual informationãŒåŠ ã‚ã‚‹ã“ã¨ã§ã€LLMã«ã¨ã£ã¦æ­£ç¢ºã§ã‚ã‹ã‚Šã‚„ã™ã„reasoning chainã‚’ç²å¾—ã™ã‚‹ã€‚<br><br>- Inference<br><br>  - questionã¨Iter-Cotã‚’çµ„ã¿åˆã‚ã›ã€demonstration poolã«åŠ ãˆã‚‹<br><br>  - inferenceæ™‚ã¯ãƒ©ãƒ³ãƒ€ãƒ ã«demonstraction poolã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€In context learningã«åˆ©ç”¨ã—æ¨è«–ã‚’è¡Œã†<br><br><br><br>## Strong Bootstrapping<br><br>ã‚³ãƒ³ã‚»ãƒ—ãƒˆã¯weak bootstrappingã¨ä¸€ç·’ã ãŒã€Revise-Promptã§ã‚ˆã‚Šäººé–“ã«ã‚ˆã‚‹ä»‹å…¥ã‚’è¡Œã†ã€‚å…·ä½“çš„ã«ã¯ã€reasoning chainã®ã©ã“ãŒèª¤ã£ã¦ã„ã‚‹ã‹ã‚’æ˜ç¤ºçš„ã«æŒ‡æ‘˜ã—ã€LLMã«reasoning chainã‚’reviseã•ã›ã‚‹ã€‚<br><br>ã“ã‚Œã¯å¾“æ¥ã®LLMã‹ã‚‰ã®æ¨è«–ã‚’å¿…è¦ã¨ã—ãªã„annotationãƒ—ãƒ­ã‚»ã‚¹ã¨ã¯ç•°ãªã£ã¦ã„ã‚‹ã€‚ä½•ãŒé•ã†ã‹ã¨ã„ã†ã¨ã€äººé–“ã«ã‚ˆã‚‹annnotationã‚’LLMã®æ¨è«–ã¨çµ±åˆã™ã‚‹ã“ã¨ã§ã€æ–‡è„ˆæƒ…å ±ã¨ã—ã¦reasoning chainã‚’ä¿®æ­£ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ç‚¹ã§ç•°ãªã£ã¦ã„ã‚‹ã€‚</p>
<p># å®Ÿé¨“<br><br>Manual-CoT<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
&lt;/strong&gt;
<br>
<br><br>Random-CoT<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
<br><br>Auto-CoT<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/554" target="_blank" rel="noopener noreferrer">Active prompting with chain-of-thought for large language models, Diao+, The Hong Kong University of Science and Technology, ACL'24</a>
<br><br>ã¨æ¯”è¼ƒã€‚<br><br>Iter-CoTãŒ11å€‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ã¦ã§outperformã—ãŸã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/234792846-e8fd2f8b-6e26-48fc-9e5d-785bcf2a6b6a.png" alt="image" loading="lazy"><br><br><br><br>weak bootstrapingã®iterationã¯4å›ãã‚‰ã„ã§é ­æ‰“ã¡ã«ãªã£ãŸ<br><br><img src="https://user-images.githubusercontent.com/12249301/234793570-f57e56e4-7320-4be4-9c93-ee3be01ad389.png" alt="image" loading="lazy"><br><br><br><br>ã¾ãŸã€æ‰‹å‹•ã§reasoning chainã‚’ä¿®æ­£ã—ãŸçµæœã¨ã€contextã«annotationæƒ…å ±ã‚’æ®‹ã—ã€æœ€å¾Œã«summarizeã™ã‚‹æ–¹æ³•ã‚’æ¯”è¼ƒã—ãŸçµæœã€å¾Œè€…ã®æ–¹ãŒæ€§èƒ½ãŒé«˜ã‹ã£ãŸã€‚ã“ã®ãŸã‚ã€contextã®æƒ…å ±ã‚’åˆ©ç”¨ã—summarizeã™ã‚‹ã“ã¨ãŒåŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/530" target="_blank" rel="noopener noreferrer" class="title-link">Graph Neural Networks for Text Classification: A Survey, Wang+, Artificial Intelligence Review'24</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡ã«ãŠã‘ã‚‹ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ‰‹æ³•ã‚’2023å¹´ã¾ã§èª¿æŸ»ã—ã€ã‚³ãƒ¼ãƒ‘ã‚¹ãŠã‚ˆã³æ–‡æ›¸ãƒ¬ãƒ™ãƒ«ã®ã‚°ãƒ©ãƒ•æ§‹ç¯‰ã‚„å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã‚’è©³è¿°ã€‚èª²é¡Œã‚„ä»Šå¾Œã®æ–¹å‘æ€§ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„è©•ä¾¡æŒ‡æ¨™ã«ã¤ã„ã¦ã‚‚è€ƒå¯Ÿã—ã€ç•°ãªã‚‹æŠ€è¡“ã®æ¯”è¼ƒã‚’è¡Œã„è©•ä¾¡æŒ‡æ¨™ã®åˆ©ç‚¹ã¨æ¬ ç‚¹ã‚’ç‰¹å®šã€‚</span>
<a class="button" href="articles/BeamSearch.html" target="_blank" rel="noopener noreferrer">#BeamSearch</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3056" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Evaluation Guided Beam Search for Reasoning, Yuxi Xie+, NeurIPS'23, 2023.05</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã€æ®µéšçš„è‡ªå·±è©•ä¾¡ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å°å…¥ã—ã€ç¢ºç‡çš„ãƒ“ãƒ¼ãƒ ã‚µãƒ¼ãƒã‚’ç”¨ã„ãŸãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ¨è«–ã®ä¸ç¢ºå®Ÿæ€§ã‚’è»½æ¸›ã—ã€GSM8Kã€AQuAã€StrategyQAã§ã®ç²¾åº¦ã‚’å‘ä¸Šã€‚Llama-2ã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã‚‚åŠ¹ç‡æ€§ãŒç¤ºã•ã‚Œã€è‡ªå·±è©•ä¾¡ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ãŒè«–ç†çš„ãªå¤±æ•—ã‚’ç‰¹å®šã—ã€ä¸€è²«æ€§ã‚’é«˜ã‚ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://guideddecoding.github.io" target="_blank" rel="noopener noreferrer">https://guideddecoding.github.io</a>


</p>
<p>openreview:


<a href="https://openreview.net/forum?id=Bw82hwg5Q3" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Bw82hwg5Q3</a>


</p>
<p>éå¸¸ã«ã–ã£ãã‚Šè¨€ã†ã¨ã€reasoning chainï¼ˆï¼è¤‡æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã®sequence)ã‚’ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã¿ãªã—ãŸå ´åˆã®ï¼ˆç¢ºç‡çš„ï¼‰beam searchã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚å¤šæ§˜ãªreasoning chainã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ãã®ä¸­ã‹ã‚‰è‰¯ã„ã‚‚ã®ã‚’ãƒ“ãƒ¼ãƒ å¹…kã§ä¿æŒã—ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€æœ€çµ‚çš„ã«è‰¯ã„ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°çµæœã‚’å¾—ã‚‹ã€‚reasoning chainã®ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã«temperatureã‚’è¨­å®šã™ã‚‹ãŒã€ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°ã‚’ã™ã‚‹ã“ã¨ã§chainã«ãŠã‘ã‚‹ã‚¨ãƒ©ãƒ¼ãŒè“„ç©ã™ã‚‹ã“ã¨ã‚’é˜²ãã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æœ€åˆã¯å¤šæ§˜æ€§ã‚’é‡è¦–ã—ãŸç”ŸæˆãŒã•ã‚Œã‚‹ãŒã€ã‚¨ãƒ©ãƒ¼ãŒè“„ç©ã•ã‚Œç™ºæ•£ã™ã‚‹ã“ã¨ã‚’é˜²ãã€‚<br><br><img src="https://github.com/user-attachments/assets/b3b8b45c-7a75-418b-bcd1-e43e71d96585" alt="image" loading="lazy"><br><br>reasoning chainã®è‰¯ã•ã‚’åˆ¤æ–­ã™ã‚‹ãŸã‚ã«ã€chainã®å°¤åº¦ã ã‘ã§ãªãã€self-evaluationã«ã‚ˆã‚‹reasoning chainã®æ­£ã—ã•ã«é–¢ã™ã‚‹confidenceã‚¹ã‚³ã‚¢ã‚‚å°å…¥ã™ã‚‹ï¼ˆreasoning chainã®confidenceã‚¹ã‚³ã‚¢ã«ã‚ˆã£ã¦é‡ã¿ã¥ã‘ã‚‰ã‚ŒãŸchainã®å°¤åº¦ã‚’æœ€å¤§åŒ–ã™ã‚‹ã‚ˆã†ãªå®šå¼åŒ–ã«ãªã‚‹ï¼ˆå¼3))ã€‚<br>self-evaluationã¨ç”Ÿæˆã¯ã¨ã‚‚ã«åŒã˜LLMã«ã‚ˆã£ã¦å®Ÿç¾ã•ã‚Œã‚‹ãŒã€self-evaluationã«ã¤ã„ã¦ã¯è©•ä¾¡ç”¨ã®few-shot promptingã‚’å®Ÿæ–½ã™ã‚‹ã€‚promptingã§ã¯ã€ã“ã‚Œã¾ã§ã®reasoning chainã¨ã€æ–°ãŸãªreasoning chainãŒgivenãªã¨ãã«ã€ãã‚ŒãŒ(A)correct/(B)incorrectãªã®ã‹ã‚’multiple choice questionã§åˆ¤å®šã—ã€é¸æŠè‚¢AãŒç”Ÿæˆã•ã‚Œã‚‹ç¢ºç‡ã‚’ã‚¹ã‚³ã‚¢ã¨ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/f9934a71-9e0c-4145-b925-4c231915affd" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2981" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Large Language Models are Better Reasoners with Self-Verification, Yixuan Weng+, EMNLP'23 Findings, 2022.12</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯CoTãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã«ã‚ˆã‚Šå¼·åŠ›ãªæ¨è«–èƒ½åŠ›ã‚’ç¤ºã™ãŒã€ã‚¨ãƒ©ãƒ¼ã®è“„ç©ã«è„†å¼±ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LLMsãŒè‡ªå·±æ¤œè¨¼èƒ½åŠ›ã‚’æŒã¤ã“ã¨ã‚’ææ¡ˆã—ã€æ¨è«–ã—ãŸå›ç­”ã‚’é€†æ¤œè¨¼ã™ã‚‹ã“ã¨ã§è§£é‡ˆå¯èƒ½ãªæ¤œè¨¼ã‚¹ã‚³ã‚¢ã‚’å¾—ã‚‹æ‰‹æ³•ã‚’ç¤ºã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆæ‰‹æ³•ãŒç®—æ•°ã€å¸¸è­˜ã€è«–ç†æ¨è«–ã‚¿ã‚¹ã‚¯ã§ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=s4xIeYimGQ" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=s4xIeYimGQ</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2962" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for  Generative Large Language Models, Potsawee Manakul+, EMNLP'23, 2023.03</a>
<span class="snippet"><span>GPT Summary</span>- SelfCheckGPTã¯ã€å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã—ã§LLMã®å¿œç­”ã‚’ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã™ã‚‹ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸå¿œç­”ãŒä¸€è²«ã—ãŸäº‹å®Ÿã‚’å«ã‚€å ´åˆã€çŸ¥è­˜ãŒã‚ã‚‹ã¨åˆ¤æ–­ã—ã€å¹»è¦šã•ã‚ŒãŸäº‹å®Ÿã§ã¯çŸ›ç›¾ãŒç”Ÿã˜ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€éäº‹å®Ÿçš„ãŠã‚ˆã³äº‹å®Ÿçš„ãªæ–‡ã®æ¤œå‡ºã€æ–‡ç« ã®ãƒ©ãƒ³ã‚¯ä»˜ã‘ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€é«˜ã„AUC-PRã‚¹ã‚³ã‚¢ã¨ç›¸é–¢ã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=RwzFNbJ3Ez" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=RwzFNbJ3Ez</a>


</p>
<p>è©•ä¾¡ã«é–¢é€£ã™ã‚‹æ‰‹æ³•:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/89" target="_blank" rel="noopener noreferrer">[Paper Note] Neural Text Generation from Structured Data with Application to the  Biography Domain, Remi Lebret+, EMNLP'16, 2016.03</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2956" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FreshLLMs: Refreshing Large Language Models with Search Engine  Augmentation, Tu Vu+, ACL'23 Findings, 2023.10</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯å¤‰åŒ–ã™ã‚‹ä¸–ç•Œã«é©å¿œã§ããšã€äº‹å®Ÿæ€§ã«èª²é¡ŒãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€å‹•çš„QAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒFreshQAã€ã‚’å°å…¥ã—ã€è¿…é€Ÿã«å¤‰åŒ–ã™ã‚‹çŸ¥è­˜ã‚„èª¤ã£ãŸå‰æã‚’å«ã‚€è³ªå•ã«å¯¾ã™ã‚‹LLMã®æ€§èƒ½ã‚’è©•ä¾¡ã€‚è©•ä¾¡ã®çµæœã€å…¨ãƒ¢ãƒ‡ãƒ«ãŒã“ã‚Œã‚‰ã®è³ªå•ã«è‹¦åŠ´ã—ã¦ã„ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚ã“ã‚Œã‚’å—ã‘ã¦ã€æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰ã®æœ€æ–°æƒ…å ±ã‚’çµ„ã¿è¾¼ã‚€ã€ŒFreshPromptã€ã‚’ææ¡ˆã—ã€LLMã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã«æˆåŠŸã€‚FreshPromptã¯ã€è¨¼æ‹ ã®æ•°ã¨é †åºãŒæ­£ç¢ºæ€§ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ç¤ºã—ã€ç°¡æ½”ãªå›ç­”ã‚’ä¿ƒã™ã“ã¨ã§å¹»è¦šã‚’æ¸›å°‘ã•ã›ã‚‹åŠ¹æœã‚‚ç¢ºèªã€‚FreshQAã¯å…¬é–‹ã•ã‚Œã€ä»Šå¾Œã‚‚æ›´æ–°ã•ã‚Œã‚‹äºˆå®šã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2955" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Check Your Facts and Try Again: Improving Large Language Models with  External Knowledge and Automated Feedback, Baolin Peng+, arXiv'23, 2023.02</a>
<span class="snippet"><span>GPT Summary</span>- LLM-Augmenterã‚·ã‚¹ãƒ†ãƒ ã‚’ææ¡ˆã—ã€LLMãŒå¤–éƒ¨çŸ¥è­˜ã«åŸºã¥ã„ãŸå¿œç­”ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«æ‹¡å¼µã€‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”¨ã„ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ”¹å–„ã—ã€ã‚¿ã‚¹ã‚¯æŒ‡å‘ã®å¯¾è©±ã¨è³ªå•å¿œç­”ã§ã®æœ‰åŠ¹æ€§ã‚’å®Ÿè¨¼ã€‚ChatGPTã®å¹»è¦šã‚’æ¸›å°‘ã•ã›ã¤ã¤ã€æµæš¢ã•ã‚„æƒ…å ±é‡ã‚’ç¶­æŒã€‚ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ã‚’å…¬é–‹ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2769" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GenEval: An Object-Focused Framework for Evaluating Text-to-Image   Alignment, Dhruba Ghosh+, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•è©•ä¾¡æ–¹æ³•ã€ŒGenEvalã€ã‚’ææ¡ˆã€‚ç‰©ä½“ã®å…±èµ·ã€ä½ç½®ã€æ•°ã€è‰²ãªã©ã®ç‰¹æ€§ã‚’è©•ä¾¡ã—ã€ç¾åœ¨ã®ç‰©ä½“æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã¦ç”Ÿæˆã‚¿ã‚¹ã‚¯ã‚’åˆ†æã€‚æœ€è¿‘ã®ãƒ¢ãƒ‡ãƒ«ã¯æ”¹å–„ã‚’ç¤ºã™ãŒã€è¤‡é›‘ãªèƒ½åŠ›ã«ã¯èª²é¡ŒãŒæ®‹ã‚‹ã€‚GenEvalã¯å¤±æ•—ãƒ¢ãƒ¼ãƒ‰ã®ç™ºè¦‹ã«ã‚‚å¯„ä¸ã—ã€æ¬¡ä¸–ä»£ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºã«å½¹ç«‹ã¤ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ä¸­ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=Wbr51vK331&noteId=NpvYJlJFqK" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Wbr51vK331&noteId=NpvYJlJFqK</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2474" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Efficient Memory Management for Large Language Model Serving with  PagedAttention, Woosuk Kwon+, SOSP'23</a>
<span class="snippet"><span>GPT Summary</span>- PagedAttentionã‚’ç”¨ã„ãŸvLLMã‚·ã‚¹ãƒ†ãƒ ã‚’ææ¡ˆã—ã€KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¡ãƒ¢ãƒªã®ç„¡é§„ã‚’å‰Šæ¸›ã—ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“ã§ã®æŸ”è»Ÿãªå…±æœ‰ã‚’å®Ÿç¾ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åŒãƒ¬ãƒ™ãƒ«ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã§LLMã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’2-4å€å‘ä¸Šã€‚ç‰¹ã«é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚„å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§åŠ¹æœãŒé¡•è‘—ã€‚ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ä¸­ã€‚</span>
<span class="snippet"><span>Comment</span><p>ï¼ˆä»Šæ›´ãªãŒã‚‰ï¼‰vLLMã¯ã“ã¡ã‚‰:<br>


<a href="https://github.com/vllm-project/vllm" target="_blank" rel="noopener noreferrer">https://github.com/vllm-project/vllm</a>


<br><br>ç¾åœ¨ã®ä¸»è¦ãªLLM Inference/Serving Engineã®ã²ã¨ã¤ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Deduplication.html" target="_blank" rel="noopener noreferrer">#Deduplication</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2445" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SemDeDup: Data-efficient learning at web-scale through semantic  deduplication, Amro Abbas+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- SemDeDupã¯ã€äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®åŸ‹ã‚è¾¼ã¿ã‚’ç”¨ã„ã¦æ„å‘³çš„ã«é‡è¤‡ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒšã‚¢ã‚’ç‰¹å®šã—å‰Šé™¤ã™ã‚‹æ‰‹æ³•ã€‚LAIONã®ã‚µãƒ–ã‚»ãƒƒãƒˆã§50%ã®ãƒ‡ãƒ¼ã‚¿å‰Šé™¤ã‚’å®Ÿç¾ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“ã‚’åŠåˆ†ã«çŸ­ç¸®ã€‚åˆ†å¸ƒå¤–æ€§èƒ½ã‚‚å‘ä¸Šã—ã€C4ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚åŠ¹ç‡æ€§ã‚’æ”¹å–„ã€‚è³ªã®é«˜ã„åŸ‹ã‚è¾¼ã¿ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿å‰Šæ¸›ã¨å­¦ç¿’åŠ é€Ÿã‚’ä¸¡ç«‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>embeddingç©ºé–“ã«ãŠã„ã¦è¿‘å‚ã®ã‚µãƒ³ãƒ—ãƒ«(near-duplicates)ã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ã§ã€å­¦ç¿’åŠ¹ç‡ãŒå‘ä¸Šã—ã¾ã™ã€ã¨ã„ã†è©±ãªæ¨¡æ§˜ã€‚<br>&lt;img width="957" height="535" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/11511a7e-feaa-4e7b-8276-628fe5099be9"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/11511a7e-feaa-4e7b-8276-628fe5099be9"&lt;/a&gt;


/&gt;<br><br>openreview:


<a href="https://openreview.net/forum?id=IRSesTQUtb&noteId=usQjFYYAZJ" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=IRSesTQUtb&noteId=usQjFYYAZJ</a>


<br><br>openreviewã«ã‚ˆã‚‹ã¨ã€embeddingç©ºé–“ã«ãŠã„ã¦near-duplicatesã‚’å‰Šé™¤ã™ã‚‹ã¨ã„ã†ã‚¢ã‚¤ãƒ‡ã‚¢ã¯èˆˆå‘³æ·±ã„ãŒã€ææ¡ˆæ‰‹æ³•ã¯æ—¢å­˜ç ”ç©¶ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’çµ„ã¿åˆã‚ã›ã¦ã„ã‚‹ã«ç•™ã¾ã£ã¦ãŠã‚Šï¼ˆå¤šãã®ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆã‚„deduplicationã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚‚å­˜åœ¨ã™ã‚‹ï¼‰æ–°è¦æ€§ãŒæ˜ç¢ºã§ã¯ãªã„ç‚¹ã‚„ã€å®Ÿé¨“çµæœãŒä¸è¶³ã—ã¦ã„ã‚‹ï¼ˆi.e., å…¨ã¦ã®ã‚±ãƒ¼ã‚¹ã§SoTAã¨ã„ã†ã‚ã‘ã§ã‚‚ãªãã€å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§ã®å®Ÿé¨“ã‚„strong baselineã®ä¸åœ¨ï¼ˆå®Ÿé¨“çµæœã¯random pruningã«å¯¾ã—ã¦outperformã™ã‚‹ã“ã¨ãŒä¸»ã«ç¤ºã•ã‚Œã¦ã„ã‚‹ï¼‰ãªã©ã€è«–æ–‡ã®ä¸»å¼µã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ã®çµæœãŒè¶³ã‚Šãªã„ï¼‰ã¨ã„ã†æŒ‡æ‘˜ãŒã•ã‚Œã¦ã„ã‚‹ã€‚<br>å®Ÿç”¨çš„ã«ã¯well-writtenã§exampleã‚‚è±Šå¯Œã¨ã®ã“ã¨ãªã®ã§ã€Deduplicationã®ç†è§£ã‚’æ·±ã‚ã‚‹ã®ã«è‰¯ã•ãã†ã€‚</p>
<p>å…ˆè¡Œç ”ç©¶:<br>- ï¼ˆç”»åƒï¼‰<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2688" target="_blank" rel="noopener noreferrer">[Paper Note] Beyond neural scaling laws: beating power law scaling via data pruning, Ben Sorscher+, NeurIPS'22</a>
 <br>- ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2689" target="_blank" rel="noopener noreferrer">[Paper Note] Deduplicating Training Data Makes Language Models Better, Katherine Lee+, ACL'22</a>
<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2688" target="_blank" rel="noopener noreferrer">[Paper Note] Beyond neural scaling laws: beating power law scaling via data pruning, Ben Sorscher+, NeurIPS'22</a>
 ã§ã¯ã€åˆ†é¡ãŒé›£ã—ã„ç”»åƒã®ãƒ‡ãƒ¼ã‚¿ã¨ã„ã†è¦³ç‚¹ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦ãŠã‚Šã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2689" target="_blank" rel="noopener noreferrer">[Paper Note] Deduplicating Training Data Makes Language Models Better, Katherine Lee+, ACL'22</a>
 ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã®è¡¨å±¤çš„ãªæƒ…å ±ã®ä¸€è‡´ã«åŸºã¥ã„ã¦Deduplicationã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2400" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Physics of Language Models: Part 1, Learning Hierarchical Language  Structures, Zeyuan Allen-Zhu+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Transformerãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ãŒæ–‡è„ˆè‡ªç”±æ–‡æ³•ï¼ˆCFGï¼‰ã«ã‚ˆã‚‹å†å¸°çš„ãªè¨€èªæ§‹é€ æ¨è«–ã‚’ã©ã®ã‚ˆã†ã«è¡Œã†ã‹ã‚’èª¿æŸ»ã€‚åˆæˆCFGã‚’ç”¨ã„ã¦é•·æ–‡ã‚’ç”Ÿæˆã—ã€GPTã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ãŒCFGã®éšå±¤ã‚’æ­£ç¢ºã«å­¦ç¿’ãƒ»æ¨è«–ã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®éš ã‚ŒçŠ¶æ…‹ãŒCFGã®æ§‹é€ ã‚’æ‰ãˆã€æ³¨æ„ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå‹•çš„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã«é¡ä¼¼ã—ã¦ã„ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚ã¾ãŸã€çµ¶å¯¾ä½ç½®åŸ‹ã‚è¾¼ã¿ã®åŠ£ä½ã‚„å‡ä¸€ãªæ³¨æ„ã®åŠ¹æœã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å°‚ç”¨ãƒ¢ãƒ‡ãƒ«ã®é™ç•Œã€æ§‹é€ çš„ãƒã‚¤ã‚ºã«ã‚ˆã‚‹å …ç‰¢æ€§å‘ä¸Šã«ã¤ã„ã¦ã‚‚è€ƒå¯Ÿã€‚</span>
<span class="snippet"><span>Comment</span><p>è§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<span class="issue_date">Issue Date: 2025-08-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2373" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Adding Conditional Control to Text-to-Image Diffusion Models, Lvmin Zhang+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ControlNetã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã«ç©ºé–“çš„ãªæ¡ä»¶åˆ¶å¾¡ã‚’è¿½åŠ ã™ã‚‹ãŸã‚ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚Šã€äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å±¤ã‚’å†åˆ©ç”¨ã—ã¦å¤šæ§˜ãªæ¡ä»¶åˆ¶å¾¡ã‚’å­¦ç¿’ã—ã¾ã™ã€‚ã‚¼ãƒ­ç•³ã¿è¾¼ã¿ã‚’ç”¨ã„ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¾ã€…ã«å¢—åŠ ã•ã›ã€æœ‰å®³ãªãƒã‚¤ã‚ºã®å½±éŸ¿ã‚’è»½æ¸›ã—ã¾ã™ã€‚Stable Diffusionã‚’ç”¨ã„ã¦æ§˜ã€…ãªæ¡ä»¶åˆ¶å¾¡ã‚’ãƒ†ã‚¹ãƒˆã—ã€å°è¦æ¨¡ãŠã‚ˆã³å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦å …ç‰¢æ€§ã‚’ç¤ºã—ã¾ã—ãŸã€‚ControlNetã¯ç”»åƒæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®åˆ¶å¾¡ã«ãŠã‘ã‚‹åºƒç¯„ãªå¿œç”¨ã®å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ControlNetè«–æ–‡</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2275" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Large Language Models Can Self-Improve, Jiaxin Huang+, EMNLP'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMã¯ãƒ©ãƒ™ãƒ«ã®ãªã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è‡ªå·±æ”¹å–„å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€Chain-of-Thoughtãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã¨è‡ªå·±ä¸€è²«æ€§ã‚’åˆ©ç”¨ã—ã¦é«˜ä¿¡é ¼åº¦ã®å›ç­”ã‚’ç”Ÿæˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€540Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã€æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒè‡ªå·±æ”¹å–„ã«é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚‚ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=uuUQraD4XX&noteId=PWDEpZtn6P" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=uuUQraD4XX&noteId=PWDEpZtn6P</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Inference.html" target="_blank" rel="noopener noreferrer">#Inference</a>
<span class="issue_date">Issue Date: 2025-06-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2028" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked  Prefills, Amey Agrawal+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- SARATHIã¯ã€LLMã®æ¨è«–åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã§ã€ãƒ—ãƒ¬ãƒ•ã‚£ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã€ãƒ‡ã‚³ãƒ¼ãƒ‰ãƒã‚­ã‚·ãƒãƒ«ãƒãƒƒãƒã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã§è¨ˆç®—åˆ©ç”¨ç‡ã‚’æœ€å¤§åŒ–ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’æœ€å¤§10å€å‘ä¸Šã•ã›ã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚‚æ”¹å–„ã€‚ç‰¹ã«ã€A6000 GPUä¸Šã®LLaMA-13Bãƒ¢ãƒ‡ãƒ«ã§é¡•è‘—ãªæ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒãƒ–ãƒ«ã‚’å¤§å¹…ã«å‰Šæ¸›ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>vLLMã§ã‚‚æ¡ç”¨ã•ã‚Œã¦ã„ã‚‹ `Chunked Prefills` ã¨ `Decode-Maximal Batching` ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br>![Image](https://github.com/user-attachments/assets/4db0f73d-bdf4-4c2b-a765-2c9b242904f1)</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Parallelism.html" target="_blank" rel="noopener noreferrer">#Parallelism</a>
<span class="issue_date">Issue Date: 2025-05-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1970" target="_blank" rel="noopener noreferrer" class="title-link">Sequence Parallelism: Long Sequence Training from System Perspective, Li+, ACL'23</a>
<span class="snippet"><span>Comment</span><p>å…¥åŠ›ç³»åˆ—ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦ã€ãƒ‡ãƒã‚¤ã‚¹ã”ã¨ã«æ‹…å½“ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ã‚’æ±ºã‚ã‚‹ã“ã¨ã§åŸç†ä¸Šç„¡é™ã®é•·ã•ã®ç³»åˆ—ã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«ã—ãŸä¸¦åˆ—åŒ–æ‰‹æ³•ã€‚ç³»åˆ—ã‚’ãƒ‡ãƒã‚¤ã‚¹é–“ã§æ¨ªæ–­ã™ã‚‹å ´åˆattention scoreã‚’ã©ã®ã‚ˆã†ã«è¨ˆç®—ã™ã‚‹ã‹ãŒèª²é¡Œã«ãªã‚‹ãŒã€ãã®ãŸã‚ã«Ring Self attentionã¨å‘¼ã°ã‚Œã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ã¾ãŸã€MLPãƒ–ãƒ­ãƒƒã‚¯ã¨Multi Head Attentonãƒ–ãƒ­ãƒƒã‚¯ã®è¨ˆç®—ã‚‚ã€BatchSize * Sequence Lengthã®å¤§ãã•ãŒã€ãã‚Œãã‚Œ32*Hidden Size, 16*Attention Head size * 
<strong># of Attention Headã‚ˆã‚Šã‚‚å¤§ãããªã£ãŸå ´åˆã«ã€Tensor Parallelismã‚ˆã‚Šã‚‚ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒè‰¯ããªã‚‹ã‚‰ã—ã„ã€‚<br><img src="https://github.com/user-attachments/assets/f3ba9010-da3a-4c3a-8515-d3715466ff59" alt="image" loading="lazy">&lt;/p&gt;<p>Data Parallel, Pipeline Parallel, Tensor Parallelã€å…¨ã¦ã«äº’æ›æ€§ãŒã‚ã‚‹ã¨ã®ã“ã¨ï¼ˆä½µç”¨å¯èƒ½ï¼‰</p>
<p>ãã®ã»ã‹ã®ä¸¦åˆ—åŒ–ã®è§£èª¬ã«ã¤ã„ã¦ã¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1184" target="_blank" rel="noopener noreferrer">å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’æ”¯ãˆã‚‹åˆ†æ•£ä¸¦åˆ—å­¦ç¿’ã®ã—ãã¿ Part1</a>
&lt;/strong&gt;
<br>
<br><br>ã‚’å‚ç…§ã®ã“ã¨ã€‚</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ActivationSteering/ITI.html" target="_blank" rel="noopener noreferrer">#ActivationSteering/ITI</a>
<a class="button" href="articles/Probing.html" target="_blank" rel="noopener noreferrer">#Probing</a>
<a class="button" href="articles/Trustfulness.html" target="_blank" rel="noopener noreferrer">#Trustfulness</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1941" target="_blank" rel="noopener noreferrer" class="title-link">Inference-Time Intervention: Eliciting Truthful Answers from a Language   Model, Kenneth Li+, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- Inference-Time Intervention (ITI)ã‚’ææ¡ˆã—ã€LLMsã®çœŸå®Ÿæ€§ã‚’å‘ä¸Šã•ã›ã‚‹æŠ€è¡“ã‚’ç´¹ä»‹ã€‚ITIã¯æ¨è«–ä¸­ã«ãƒ¢ãƒ‡ãƒ«ã®æ´»æ€§åŒ–ã‚’èª¿æ•´ã—ã€LLaMAãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’TruthfulQAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¤§å¹…ã«æ”¹å–„ã€‚Alpacaãƒ¢ãƒ‡ãƒ«ã§ã¯çœŸå®Ÿæ€§ãŒ32.5%ã‹ã‚‰65.1%ã«å‘ä¸Šã€‚çœŸå®Ÿæ€§ã¨æœ‰ç”¨æ€§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’ç‰¹å®šã—ã€ä»‹å…¥ã®å¼·åº¦ã‚’èª¿æ•´ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€‚ITIã¯ä½ã‚³ã‚¹ãƒˆã§ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ãŒé«˜ãã€æ•°ç™¾ã®ä¾‹ã§çœŸå®Ÿã®æ–¹å‘æ€§ã‚’ç‰¹å®šå¯èƒ½ã€‚LLMsãŒè™šå½ã‚’ç”Ÿæˆã—ã¤ã¤ã‚‚çœŸå®Ÿã®å†…éƒ¨è¡¨ç¾ã‚’æŒã¤å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>Inference Time Interventionã‚’ææ¡ˆã—ãŸç ”ç©¶ã€‚Attention Headã«å¯¾ã—ã¦ç·šå½¢ãƒ—ãƒ­ãƒ¼ãƒ“ãƒ³ã‚°[^1]ã‚’å®Ÿæ–½ã—ã€çœŸå®Ÿæ€§ã«é–¢é€£ã™ã‚‹ã§ã‚ã‚ã†Headã‚’topKã§ç‰¹å®šã§ãã‚‹ã‚ˆã†ã«ã—ã€headã®å‡ºåŠ›ã«å¯¾ã—çœŸå®Ÿæ€§ã‚’é«˜ã‚ã‚‹æ–¹å‘æ€§ã®ãƒ™ã‚¯ãƒˆãƒ«vã‚’æ¨è«–æ™‚ã«åŠ ç®—ã™ã‚‹ã“ã¨ã§ï¼ˆï¼interventionï¼‰ã€ãƒ¢ãƒ‡ãƒ«ã®çœŸå®Ÿæ€§ã‚’é«˜ã‚ã‚‹ã€‚vã¯ç·šå½¢ãƒ—ãƒ­ãƒ¼ãƒ“ãƒ³ã‚°ã«ã‚ˆã£ã¦å­¦ç¿’ã•ã‚ŒãŸé‡ã¿ã‚’ä½¿ã†æ‰‹æ³•ã¨ã€æ­£ç­”ã¨èª¤ç­”ã®æ´»æ€§åŒ–ã®å¹³å‡ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—ã—ãã®å·®åˆ†ã‚’vã¨ã™ã‚‹æ–¹æ³•ã®äºŒç¨®é¡ãŒã‚ã‚‹ã€‚å¾Œè€…ã®æ–¹ãŒæ€§èƒ½ãŒè‰¯ã„ã€‚topKã‚’æ±‚ã‚ã‚‹éš›ã«ã¯ã€ç·šå½¢ãƒ—ãƒ­ãƒ¼ãƒ“ãƒ³ã‚°ã‚’ã—ãŸãƒ¢ãƒ‡ãƒ«ã®validation setã§ã®æ€§èƒ½ã‹ã‚‰æ±ºã‚ã‚‹ã€‚Kã¨Î±ã¯ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚ã‚‹ã€‚<br><br>[^1]: headã®representationã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã€ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã€ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã®2å€¤åˆ†é¡æ€§èƒ½ã‚’è¦‹ã‚‹ã“ã¨ã§headãŒã©ã®ç¨‹åº¦ã€ãƒ—ãƒ­ãƒ¼ãƒ“ãƒ³ã‚°ã®å­¦ç¿’ã«ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹æƒ…å ±ã‚’ä¿æŒã—ã¦ã„ã‚‹ã‹ã‚’æ¸¬å®šã™ã‚‹æ‰‹æ³•<br><br>æ—¥æœ¬èªè§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:


<a href="https://www.docswell.com/s/DeepLearning2023/Z38P8D-2024-06-20-131813#p1" target="_blank" rel="noopener noreferrer">https://www.docswell.com/s/DeepLearning2023/Z38P8D-2024-06-20-131813#p1</a>


</p>
<p>ã“ã‚Œã¯ç›¸å½“æ±ç”¨çš„ã«ä½¿ãˆãã†ãªè©±ã ã‹ã‚‰å½¹ã«ç«‹ã¡ãã†</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<span class="issue_date">Issue Date: 2025-04-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1899" target="_blank" rel="noopener noreferrer" class="title-link">Foundation Transformers, Hongyu Wang+, PMLR'23</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªã€è¦–è¦šã€éŸ³å£°ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã«ãŠã‘ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®åæŸãŒé€²ã‚€ä¸­ã€ç•°ãªã‚‹å®Ÿè£…ã®ã€ŒTransformersã€ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚æ±ç”¨ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®ãŸã‚ã«ã€å®‰å®šæ€§ã‚’æŒã¤Foundation Transformerã®é–‹ç™ºãŒæå”±ã•ã‚Œã€Magnetoã¨ã„ã†æ–°ã—ã„Transformerå¤‰ç¨®ãŒç´¹ä»‹ã•ã‚Œã‚‹ã€‚Sub-LayerNormã¨ç†è«–ã«åŸºã¥ãåˆæœŸåŒ–æˆ¦ç•¥ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€ã•ã¾ã–ã¾ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨å®‰å®šæ€§ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªãƒ¢ãƒ‡ãƒ«ãªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ã«ãŠã„ã¦ã€PostLNã¯vision encodingã«ãŠã„ã¦sub-optimalã§ã€PreLNã¯text encodingã«ãŠã„ã¦sub-optimalã§ã‚ã‚‹ã“ã¨ãŒå…ˆè¡Œç ”ç©¶ã§ç¤ºã•ã‚Œã¦ãŠã‚Šã€ãƒãƒ«ã‚¿ãƒ¢ãƒ¼ãƒ€ãƒ«ã‚’å˜ä¸€ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã€é«˜æ€§èƒ½ã€ã‹ã¤å­¦ç¿’ã®å®‰å®šæ€§ãªé«˜ãã€try and errorç„¡ã—ã§é©ç”¨ã§ãã‚‹åŸºç›¤ã¨ãªã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒå¿…è¦ã¨ã„ã†ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã§ææ¡ˆã•ã‚ŒãŸæ‰‹æ³•ã€‚å…·ä½“çš„ã«ã¯ã€Sub-LayerNorm(Sub-LN)ã¨å‘¼ã°ã‚Œã‚‹ã€self attentionã¨FFNéƒ¨åˆ†ã«è¿½åŠ ã®LayerNormã‚’é©ç”¨ã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ã€DeepNetã‚’è¸è¥²ã—Layeræ•°ãŒéå¸¸ã«å¤§ãã„å ´åˆã§ã‚‚å­¦ç¿’ãŒå®‰å®šã™ã‚‹ã‚ˆã†ãªé‡ã¿ã®åˆæœŸåŒ–æ–¹æ³•ã‚’ç†è«–çš„ã«åˆ†æã—ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br>å…·ä½“çš„ã«ã¯ã€Sub-LNã®å ´åˆã€LayerNormã‚’<br>- SelfAttentionè¨ˆç®—ã«ãŠã‘ã‚‹QKVã‚’æ±‚ã‚ã‚‹ãŸã‚ã®input Xã®projectionã®å‰ã¨Attentionã®å‡ºåŠ›projectionã®å‰<br>- FFNã§ã®å„Linear Layerã®å‰<br>ã«é©ç”¨ã—ã€<br><br>åˆæœŸåŒ–ã‚’ã™ã‚‹éš›ã«ã¯ã€FFNã®W, ãŠã‚ˆã³self-attentionã®V_projã¨å‡ºåŠ›ã®out_projã®åˆæœŸåŒ–ã‚’Î³ï¼ˆï¼sqrt(log(2N))ã«ã‚ˆã£ã¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br><img src="https://github.com/user-attachments/assets/2847f982-3266-4394-9920-01d9977e505e" alt="image" loading="lazy"></p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1900" target="_blank" rel="noopener noreferrer">DeepNet: Scaling Transformers to 1,000 Layers, Hongyu Wang+, arXiv'22</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-04-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1881" target="_blank" rel="noopener noreferrer" class="title-link">PaLI-3 Vision Language Models: Smaller, Faster, Stronger, Xi Chen+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- PaLI-3ã¯ã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦10å€å°å‹ã§é«˜é€Ÿãªè¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆVLMï¼‰ã§ã‚ã‚Šã€ç‰¹ã«ãƒ­ãƒ¼ã‚«ãƒªã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã‚„è¦–è¦šçš„ãƒ†ã‚­ã‚¹ãƒˆç†è§£ã«ãŠã„ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ã€‚SigLIPãƒ™ãƒ¼ã‚¹ã®PaLIã¯ã€20å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã•ã‚Œã€å¤šè¨€èªã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«æ¤œç´¢ã§æ–°ãŸãªæœ€å…ˆç«¯ã‚’é”æˆã€‚50å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®PaLI-3ã¯ã€VLMã®ç ”ç©¶ã‚’å†ç‡ƒã•ã›ã‚‹ã“ã¨ã‚’æœŸå¾…ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=JpyWPfzu0b" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=JpyWPfzu0b</a>


<br><br>å®Ÿé¨“çš„ã«ç´ æ™´ã‚‰ã—ã„æ€§èƒ½ãŒå®Ÿç¾ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã¯èªã‚ã‚‰ã‚Œã¤ã¤ã‚‚<br>- æ¯”è¼ƒå¯¾è±¡ãŒSigLIPã®ã¿ã§ã‚ˆã‚Šåºƒç¯„ãªæ¯”è¼ƒå®Ÿé¨“ã¨åˆ†æãŒå¿…è¦ãªã“ã¨<br>- Backboneãƒ¢ãƒ‡ãƒ«ã‚’Contrastive Learningã™ã‚‹ã“ã¨è‡ªä½“ã®æœ‰ç”¨æ€§ã¯æ—¢ã«çŸ¥ã‚‰ã‚Œã¦ãŠã‚Šã€æ–°è¦æ€§ã«ä¹ã—ã„ã“ã¨<br><br>ã¨ã—ã¦ICLR'24ã«Rejectã•ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-04-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1865" target="_blank" rel="noopener noreferrer" class="title-link">The Impact of Positional Encoding on Length Generalization in   Transformers, Amirhossein Kazemnejad+, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- é•·ã•ä¸€èˆ¬åŒ–ã¯Transformerãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹é‡è¦ãªèª²é¡Œã§ã‚ã‚Šã€ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆPEï¼‰ãŒãã®æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã€‚5ã¤ã®ç•°ãªã‚‹PEæ‰‹æ³•ï¼ˆAPEã€T5ã®ç›¸å¯¾PEã€ALiBiã€Rotaryã€NoPEï¼‰ã‚’æ¯”è¼ƒã—ãŸçµæœã€ALiBiã‚„Rotaryãªã©ã®ä¸€èˆ¬çš„ãªæ‰‹æ³•ã¯é•·ã•ä¸€èˆ¬åŒ–ã«é©ã—ã¦ãŠã‚‰ãšã€NoPEãŒä»–ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚NoPEã¯è¿½åŠ ã®è¨ˆç®—ã‚’å¿…è¦ã¨ã›ãšã€çµ¶å¯¾PEã¨ç›¸å¯¾PEã®ä¸¡æ–¹ã‚’è¡¨ç¾å¯èƒ½ã§ã‚ã‚‹ã€‚ã•ã‚‰ã«ã€ã‚¹ã‚¯ãƒ©ãƒƒãƒãƒ‘ãƒƒãƒ‰ã®å½¢å¼ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚ã“ã®ç ”ç©¶ã¯ã€æ˜ç¤ºçš„ãªä½ç½®åŸ‹ã‚è¾¼ã¿ãŒé•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¸ã®ä¸€èˆ¬åŒ–ã«å¿…é ˆã§ãªã„ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1863" target="_blank" rel="noopener noreferrer">Llama 4 Series, Meta, 2025.04</a>
<br><br>ã«ãŠã„ã¦ã€Llama4 ScoutãŒ10Mã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’å®Ÿç¾ã§ãã‚‹ç†ç”±ã®ä¸€ã¤ã¨ã®ã“ã¨ã€‚<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/drjimfan/status/1908615861650547081?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Llama4ã®ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆã«ã‚‚ãã®æ—¨è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹:<br>&gt;A key innovation in the Llama 4 architecture is the use of interleaved attention layers without positional embeddings. Additionally, we employ inference time temperature scaling of attention to enhance length generalization.<br><br>[The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation](


<a href="https://ai.meta.com/blog/llama-4-multimodal-intelligence/?utm_source=twitter&utm_medium=organic_social&utm_content=image&utm_campaign=llama4)" target="_blank" rel="noopener noreferrer">https://ai.meta.com/blog/llama-4-multimodal-intelligence/?utm_source=twitter&utm_medium=organic_social&utm_content=image&utm_campaign=llama4)</a>


</span></strong></p>
<p>æ–œã‚èª­ã¿ã ãŒã€length generalizationã‚’è©•ä¾¡ã™ã‚‹ä¸Šã§downstream taskã«ç„¦ç‚¹ã‚’å½“ã¦ã€3ã¤ã®ä»£è¡¨çš„ãªã‚«ãƒ†ã‚´ãƒªã«ç›¸å½“ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã—ãŸã¨ã“ã‚ã€ã“ã®è¦³ç‚¹ã«ãŠã„ã¦ã¯T5ã®relative positinal encodingã¨NoPEï¼ˆä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ³ã‚°ç„¡ã—ï¼‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒè‰¯ãã€<br><br><img src="https://github.com/user-attachments/assets/dddadfff-ab28-4073-96c3-831eb16845a0" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/c6ec8e0e-7abb-4330-be23-2261486a477c" alt="image" loading="lazy"><br><br>NoPEã¯çµ¶å¯¾ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ç›¸å¯¾ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç†è«–ä¸Šå®Ÿç¾å¯èƒ½ã§ã‚ã‚Š[^1]<br><img src="https://github.com/user-attachments/assets/bbcf797a-d394-42d4-b017-08d7dba4261c" alt="image" loading="lazy"><br><br>å®Ÿéš›ã«å­¦ç¿’ã•ã‚ŒãŸç•°ãªã‚‹2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦åŒã˜ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãã‚Œãã‚Œinputã—ã€åŒã˜æ·±ã•ã®Layerã®å…¨ã¦ã®attention distributionã®çµ„ã¿åˆã‚ã›ã‹ã‚‰Jensen Shannon Divergenceã§è·é›¢ã‚’ç®—å‡ºã—ã€æœ€ã‚‚å°ã•ã„ã‚‚ã®ã‚’2ãƒ¢ãƒ‡ãƒ«é–“ã®å½“è©²layerã®è·é›¢ã¨ã—ã¦å¯è¦–åŒ–ã™ã‚‹ã¨ä¸‹è¨˜ã®ã‚ˆã†ã«ãªã‚Šã€NoPEã¨T5ã®relative positional encodingãŒæœ€ã‚‚é¡ä¼¼ã—ã¦ã„ã‚‹ã“ã¨ã‹ã‚‰ã€NoPEãŒå­¦ç¿’ã‚’é€šã˜ã¦ï¼ˆå®Ÿç”¨ä¸Šã¯ï¼‰ç›¸å¯¾ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ã‚ˆã†ãªã‚‚ã®ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚<br><img src="https://github.com/user-attachments/assets/9619c7e5-0612-45de-8717-1634bee509b7" alt="image" loading="lazy"><br><br>[^1]:æ·±ã•1ã®Layerã®Hidden State H^1ã‹ã‚‰çµ¶å¯¾ä½ç½®ã®å¾©å…ƒãŒå¯èƒ½ã§ã‚ã‚Šï¼ˆã¤ã¾ã‚Šã€å½“è©²ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®HãŒçµ¶å¯¾ä½ç½®ã«é–¢ã™ã‚‹æƒ…å ±ã‚’ä¿æŒã—ã¦ã„ã‚‹ï¼‰ã€ã“ã®å‰æã®ã‚‚ã¨ã€å¾Œç¶šã®LayerãŒã“ã®æƒ…å ±ã‚’ä¸Šæ›¸ãã—ãªã„ã¨ä»®å®šã—ãŸå ´åˆã«ã€ç›¸å¯¾ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å®Ÿç¾ã§ãã‚‹ã€‚</p>
<p>ã¾ãŸã€CoT/Scratchpadã¯long sequenceã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒsmall scaleã§ã¯ã‚ã‚‹ãŒå…ˆè¡Œç ”ç©¶ã§ç¤ºã•ã‚Œã¦ãŠã‚Šã€Positional Encodingã‚’å¤‰åŒ–ã•ã›ãŸæ™‚ã«CoT/Scratchpadã®æ€§èƒ½ã«ã©ã®ã‚ˆã†ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã‹ã‚’èª¿æŸ»ã€‚<br><br>å…·ä½“çš„ã«ã¯ã€CoT/Scratchpadã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒã©ã®ã‚ˆã†ãªã‚‚ã®ãŒæœ‰åŠ¹ã‹ã‚‚æ˜ã‚‰ã‹ã§ã¯ãªã„ã®ã§ã€5ç¨®é¡ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®çµ„ã¿åˆã‚ã›ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ§‹æˆã—ã€mathematical reasoningã‚¿ã‚¹ã‚¯ã§ä»¥ä¸‹ã®ã‚ˆã†ãªè¨­å®šã§è¨“ç·´ã—<br><br>- ã•ã¾ã–ã¾ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®çµ„ã¿åˆã‚ã›ã§ç•°ãªã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä½œæˆã—ã€<br>- å…¨ã¦ã®ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚ã‚Š/ãªã—ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´<br><br>ã“ã‚Œã‚‰ã‚’æ¯”è¼ƒã—ãŸã€‚ã“ã®çµæœã€CoT/Scratchpadã¯ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«é–¢ä¿‚ãªãã€ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã§ã®ã¿æœ‰åŠ¹ï¼ˆæœ‰åŠ¹ã‹ã©ã†ã‹ã¯ã‚¿ã‚¹ã‚¯ä¾å­˜ï¼‰ã§ã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€CoT/Scratcpadï¼ˆã¤ã¾ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®inputã¨outputã®ä»•æ–¹ï¼‰å˜ä½“ã§ã€long contextã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ããªã„ã®ã§ã€Positional Encodingï¼ˆâ‰’ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼‰ã«ã‚ˆã‚‹long contextã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã®å‘ä¸ŠãŒéå¸¸ã«é‡è¦ã§ã‚ã‚‹ã“ã¨ãŒæµ®ãå½«ã‚Šã«ãªã£ãŸã€‚<br><img src="https://github.com/user-attachments/assets/e23c4fbf-84de-4344-a01e-1e7e9e66fa7e" alt="image" loading="lazy"><br><br>ã¾ãŸã€CoT/ScratchpadãŒæœ‰åŠ¹ã ã£ãŸAdditionã«å¯¾ã—ã¦å„Positional Embeddingãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã€ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã®attentionãŒã©ã®ä½ç½®ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŒ‡ã—ã¦ã„ã‚‹ã‹ã‚’ç›¸å¯¾è·é›¢ã§å¯è¦–åŒ–ã—ãŸã¨ã“ã‚ï¼ˆ0ãŒå½“è©²ãƒˆãƒ¼ã‚¯ãƒ³ã€ã¤ã¾ã‚Šç¾åœ¨ã®Scratchpadã«ç€ç›®ã—ã¦ãŠã‚Šã€1ãŒé ã„ãƒˆãƒ¼ã‚¯ãƒ³ã€ã¤ã¾ã‚Šinputã«ç€ç›®ã—ã¦ã„ã‚‹ã“ã¨ã‚’è¡¨ã™ã‚ˆã†ã«æ­£è¦åŒ–ï¼‰ã€NoPEã¨Relative Positional EncodingãŒshort/long rangeã«ãã‚Œãã‚Œãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã™ã‚‹ã‚ˆã†ãªbinomialãªåˆ†å¸ƒãªã®ã«å¯¾ã—ã€ä»–ã®Positional Encodingã§ã¯ã‚ˆã‚Šuniformãªåˆ†å¸ƒã§ã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚ã“ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã¯NoPEã¨Relative POã®æ€§èƒ½ãŒé«˜ã‹ã£ãŸãŸã‚ã€binomialãªåˆ†å¸ƒã®æ–¹ãŒã‚ˆã‚Šæœ€é©ã§ã‚ã‚ã†ã“ã¨ãŒç¤ºå”†ã•ã‚ŒãŸã€‚<br><img src="https://github.com/user-attachments/assets/833e6a81-8611-4e79-9d2e-473f7ebee2d0" alt="image" loading="lazy"><br></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1829" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Data-Constrained Language Models, Niklas Muennighoff+, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ãŠã„ã¦ã€ãƒ‡ãƒ¼ã‚¿åˆ¶ç´„ä¸‹ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’èª¿æŸ»ã€‚9000å„„ãƒˆãƒ¼ã‚¯ãƒ³ã¨90å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã€ç¹°ã‚Šè¿”ã—ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã‚‚æå¤±ã«å¤§ããªå¤‰åŒ–ã¯è¦‹ã‚‰ã‚Œãšã€ç¹°ã‚Šè¿”ã—ã®ä¾¡å€¤ãŒæ¸›å°‘ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚è¨ˆç®—æœ€é©æ€§ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ææ¡ˆã—ã€ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã‚’è»½æ¸›ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚‚å®Ÿé¨“ã€‚å¾—ã‚‰ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=j5BuTrEj35" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=j5BuTrEj35</a>


</p>
<p>ãƒãƒ³ãƒãƒ©å‰‡ã®ã‚ˆã†ãªScaling Lawsã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒ‡ãƒ¼ã‚¿é‡ã®ä¸¡æ–¹ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ãŸå ´åˆã®å‰æã«ç«‹ã£ã¦ãŠã‚Šã€ã‹ã¤ãƒ‡ãƒ¼ã‚¿ã¯å…¨ã¦uniqueã§ã‚ã‚‹å‰æã ã£ãŸãŒã€ãƒ‡ãƒ¼ã‚¿ã®æ¯æ¸‡ãŒæ‡¸å¿µã•ã‚Œã‚‹æ˜¨ä»Šã®çŠ¶æ³ã«åˆã‚ã›ã¦ã€ãƒ‡ãƒ¼ã‚¿é‡ãŒåˆ¶é™ã•ã‚ŒãŸçŠ¶æ³ã§ã€åŒã˜ãƒ‡ãƒ¼ã‚¿ã‚’ç¹°ã‚Šè¿”ã—åˆ©ç”¨ã™ã‚‹ï¼ˆï¼è¤‡æ•°ã‚¨ãƒãƒƒã‚¯å­¦ç¿’ã™ã‚‹ï¼‰ã“ã¨ãŒä¸€èˆ¬çš„ã«ãªã£ã¦ããŸã€‚ã“ã®ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã®repetitionã«é–¢ã—ã¦æ€§èƒ½ã‚’äº‹å‰å­¦ç¿’ã«ã‚ˆã‚‹æ€§èƒ½ã®é•ã„ã‚’èª¿æŸ»ã—ã¦ã€repetitionã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã«é–¢ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡ã‚’ææ¡ˆï¼ˆ$3.1)ã—ã¦ã„ã‚‹ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><br>Takeawayã¨ã—ã¦ã¯ã€ãƒ‡ãƒ¼ã‚¿ãŒåˆ¶é™ã•ã‚ŒãŸç’°å¢ƒä¸‹ã§ã¯ã€repetitionã¯ä¸Šé™4å›ã¾ã§ãŒåŠ¹æœçš„ï¼ˆã‚³ã‚¹ãƒ‘ãŒè‰¯ã„ï¼‰ã§ã‚ã‚Šï¼ˆå·¦å›³ï¼‰ã€å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã‚’è¤‡æ•°ã‚¨ãƒãƒƒã‚¯è¨“ç·´ã™ã‚‹æ–¹ãŒå›ºå®šã•ã‚ŒãŸBudgetã®ä¸­ã§ä½ã„lossã‚’é”æˆã§ãã‚‹å³å›³ï¼‰ã€‚<br><img src="https://github.com/user-attachments/assets/4e62cd1b-fe83-4d6e-a40d-df992c85def3" alt="image" loading="lazy"><br><br>å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®åŠåˆ†ã‚’ã‚³ãƒ¼ãƒ‰ã«ã—ã¦ã‚‚æ€§èƒ½ã®åŠ£åŒ–ã¯ãªãã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ãŒå‘ä¸Šã—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®åˆ†æ•£ã‚‚å°ã•ããªã‚‹ã€ã¨ã„ã£ãŸã“ã¨ãŒæŒ™ã’ã‚‰ã‚Œã‚‹ã‚ˆã†ã ã€‚<br><img src="https://github.com/user-attachments/assets/d404156f-7416-4f22-aa7e-d342065435ee" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<span class="issue_date">Issue Date: 2025-02-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1741" target="_blank" rel="noopener noreferrer" class="title-link">Data Distillation: A Survey, Noveen Sachdeva+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æ·±å±¤å­¦ç¿’ã®æ™®åŠã«ä¼´ã„ã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¨“ç·´ãŒé«˜ã‚³ã‚¹ãƒˆã§æŒç¶šå¯èƒ½æ€§ã«èª²é¡Œã‚’ã‚‚ãŸã‚‰ã—ã¦ã„ã‚‹ã€‚ãƒ‡ãƒ¼ã‚¿è’¸ç•™ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åŠ¹æœçš„ãªä»£æ›¿å“ã‚’æä¾›ã—ã€ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã‚„æ¨è«–ã«å½¹ç«‹ã¤ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿è’¸ç•™ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æç¤ºã—ã€æ—¢å­˜ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’åˆ†é¡ã€‚ç”»åƒã‚„ã‚°ãƒ©ãƒ•ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ãªã©ã®ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«ãŠã‘ã‚‹èª²é¡Œã¨ä»Šå¾Œã®ç ”ç©¶æ–¹å‘æ€§ã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1668" target="_blank" rel="noopener noreferrer" class="title-link">Navigate through Enigmatic Labyrinth A Survey of Chain of Thought  Reasoning: Advances, Frontiers and Future, Zheng Chu+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æ¨è«–ã¯AIã«ãŠã„ã¦é‡è¦ãªèªçŸ¥ãƒ—ãƒ­ã‚»ã‚¹ã§ã‚ã‚Šã€ãƒã‚§ãƒ¼ãƒ³ãƒ»ã‚ªãƒ–ãƒ»ã‚½ãƒ¼ãƒˆãŒLLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯é–¢é€£ç ”ç©¶ã‚’ä½“ç³»çš„ã«èª¿æŸ»ã—ã€æ‰‹æ³•ã‚’åˆ†é¡ã—ã¦æ–°ãŸãªè¦–ç‚¹ã‚’æä¾›ã€‚èª²é¡Œã‚„ä»Šå¾Œã®æ–¹å‘æ€§ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã€åˆå¿ƒè€…å‘ã‘ã®å°å…¥ã‚’ç›®æŒ‡ã™ã€‚ãƒªã‚½ãƒ¼ã‚¹ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2025-01-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1657" target="_blank" rel="noopener noreferrer" class="title-link">Program of Thoughts Prompting: Disentangling Computation from Reasoning   for Numerical Reasoning Tasks, Wenhu Chen+, TMLR'23</a>
<span class="snippet"><span>GPT Summary</span>- æ®µéšçš„ãªæ¨è«–ã‚’ç”¨ã„ãŸæ•°å€¤æ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€Chain-of-thoughts promptingï¼ˆCoTï¼‰ã®é€²å±•ãŒã‚ã‚Šã€æ¨è«–ã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¨ã—ã¦è¡¨ç¾ã™ã‚‹ã€ŒProgram of Thoughtsã€ï¼ˆPoTï¼‰ã‚’ææ¡ˆã€‚PoTã¯å¤–éƒ¨ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã§è¨ˆç®—ã‚’è¡Œã„ã€5ã¤ã®æ•°å­¦å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨3ã¤ã®é‡‘èQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡ã—ãŸçµæœã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆãŠã‚ˆã³ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆè¨­å®šã§CoTã«å¯¾ã—ã¦ç´„12ï¼…ã®æ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ãŸã€‚è‡ªå·±ä¸€è²«æ€§ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚Šã€æ•°å­¦å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚ãƒ‡ãƒ¼ã‚¿ã¨ã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>1. LLMsã¯ç®—è¡“æ¼”ç®—ã‚’å®Ÿæ–½ã™ã‚‹éš›ã«ã‚¨ãƒ©ãƒ¼ã‚’èµ·ã“ã—ã‚„ã™ãã€ç‰¹ã«å¤§ããªæ•°ã«å¯¾ã™ã‚‹æ¼”ç®—ã‚’å®Ÿæ–½ã™ã‚‹éš›ã«é¡•è‘—<br>2. LLMsã¯è¤‡é›‘ãªæ•°å¼ï¼ˆe.g. å¤šé …å¼, å¾®åˆ†æ–¹ç¨‹å¼ï¼‰ã‚’è§£ãã“ã¨ãŒã§ããªã„<br>3. LLMsã¯iterationã‚’è¡¨ç¾ã™ã‚‹ã®ãŒéå¸¸ã«éåŠ¹ç‡<br><br>ã®3ç‚¹ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€å¤–éƒ¨ã®ã‚¤ãƒ³ã‚¿ãƒ—ãƒªã‚¿ã«æ¼”ç®—å‡¦ç†ã‚’å§”è­²ã™ã‚‹PoTã‚’ææ¡ˆã€‚PoTã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã«reasoning stepsã‚’python programã§å‡ºåŠ›ã•ã›ã€æ¼”ç®—éƒ¨åˆ†ã‚’Python Interpreterã«å®Ÿæ–½ã•ã›ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/ccaeee09-ca6f-45ec-aef4-c65960d52692" alt="image" loading="lazy"></p>
<p>ãƒ†ã‚­ã‚¹ãƒˆã€ãƒ†ãƒ¼ãƒ–ãƒ«ã€å¯¾è©±ãªã©ã®å¤šæ§˜ãªinputã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹5ã¤ã®Math Word Problem ï¼ˆMWPï¼‰, 3ã¤ã®Financial Datasetã§è©•ä¾¡ã—ãŸçµæœã€zero-shot, few-shotã®ä¸¡æ–¹ã®è¨­å®šã«ãŠã„ã¦ã€PoTã¯CoTã‚’outpeformã—ã€ã¾ãŸã€Self-Consistencyã¨çµ„ã¿åˆã‚ã›ãŸå ´åˆã‚‚ã€PoTã¯CoTã‚’outperformã—ãŸã€‚<br><img src="https://github.com/user-attachments/assets/6b380fab-ab60-4f21-bce1-532167c8c8f2" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-01-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1656" target="_blank" rel="noopener noreferrer" class="title-link">Recursion of Thought: A Divide-and-Conquer Approach to Multi-Context  Reasoning with Language Models, Soochan Lee+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Recursion of Thoughtï¼ˆRoTï¼‰ã¨ã„ã†æ–°ã—ã„æ¨è«–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLMï¼‰ãŒå•é¡Œã‚’è¤‡æ•°ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åˆ†å‰²ã™ã‚‹ã“ã¨ã§æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚RoTã¯ç‰¹åˆ¥ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’å°å…¥ã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé–¢é€£ã®æ“ä½œã‚’ãƒˆãƒªã‚¬ãƒ¼ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€RoTãŒLMã®æ¨è«–èƒ½åŠ›ã‚’åŠ‡çš„ã«å‘ä¸Šã•ã›ã€æ•°åä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ã®å•é¡Œã‚’è§£æ±ºã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>divide-and-conquerã§è¤‡é›‘ãªå•é¡Œã«å›ç­”ã™ã‚‹CoTæ‰‹æ³•ã€‚ç”Ÿæˆéç¨‹ã§subquestionãŒç”Ÿã˜ãŸéš›ã«ãƒ¢ãƒ‡ãƒ«ã«ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆGOï¼‰ã‚’å‡ºåŠ›ã•ã›ã€subquestionã®å›ç­”éƒ¨åˆ†ã«ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆTHINKï¼‰ã‚’å‡ºåŠ›ã•ã›ã‚‹ã‚ˆã†ã«Supervisedã«å­¦ç¿’ã•ã›ã‚‹ã€‚æœ€çµ‚çš„ã«THINKãƒˆãƒ¼ã‚¯ãƒ³éƒ¨åˆ†ã¯ã€subquestionã‚’åˆ¥é€”ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦è§£ã„ãŸå›ç­”ã§replaceã—ã¦ã€æœ€çµ‚çš„ãªå›ç­”ã‚’å¾—ã‚‹ã€‚<br>subquestionã®ä¸­ã§ã•ã‚‰ã«subquestionãŒç”Ÿã˜ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ãŸã‚ã€å†å¸°çš„ã«å‡¦ç†ã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/6a5a5155-b3dd-4a6a-a9f5-0975dddcedb7" alt="image" loading="lazy"></p>
<p>å››å‰‡æ¼”ç®—ã¨4ç¨®é¡ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«åŸºã¥ãã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã€‚ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«åŸºã¥ãã‚¿ã‚¹ã‚¯ã¯ã€2ã¤ã®æ•°ã®longest common subsequenceã‚’è¦‹ã¤ã‘ã¦ã€ãã®subsequenceã¨lengthã‚’å‡ºåŠ›ã™ã‚‹ã‚¿ã‚¹ã‚¯ï¼ˆLCSï¼‰ã€0-1 knapsackå•é¡Œã€è¡Œåˆ—ã®ä¹—ç®—ã€æ•°å€¤ã®ã‚½ãƒ¼ãƒˆã‚’åˆ©ç”¨ã€‚xè»¸ãŒå„ã‚¿ã‚¹ã‚¯ã®å•é¡Œã”ã¨ã®å•é¡Œã®é›£æ˜“åº¦ã‚’è¡¨ã—ã¦ãŠã‚Šã€é›£æ˜“åº¦ãŒä¸ŠãŒã‚‹ã»ã©ææ¡ˆæ‰‹æ³•ã«ã‚ˆã‚‹gainãŒå¤§ãããªã£ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br>Without Thoughtã§ã¯ç›´æ¥å›ç­”ã‚’å‡ºåŠ›ã•ã›ã€CoTã§ã¯ground truthã¨ãªã‚‹rationaleã‚’1ã¤ã®contextã«ä¸ãˆã¦å›ç­”ã‚’ç”Ÿæˆã—ã¦ã„ã‚‹ã€‚RoTã§ã¯subquestionã”ã¨ã«å›ç­”ã‚’åˆ¥é€”å¾—ã‚‹ãŸã‚ã€ã‚ˆã‚Šé•·ã„contextã‚’æ´»ç”¨ã—ã¦æœ€çµ‚çš„ãªå›ç­”ã‚’å¾—ã‚‹ç‚¹ãŒç•°ãªã‚‹ã¨ä¸»å¼µã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/8e713c76-5f79-40c7-87b0-d69f6fac3ee3" alt="image" loading="lazy"><br></p>
<p>æ„Ÿæƒ³ã¨ã—ã¦ã¯ã€è©³ç´°ãŒæ›¸ã‹ã‚Œã¦ã„ãªã„ãŒã€ãŠãã‚‰ãRoTã¯SFTã«ã‚ˆã£ã¦å„ã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã—ãŸå­¦ç¿’ã‚’ã—ã¦ã„ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ï¼ˆã‚¿ã‚¹ã‚¯ã”ã¨ã®ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ãŒå­˜åœ¨ã™ã‚‹ãŸã‚ï¼‰ã€‚ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã—ã¦RoTç„¡ã—ã§SFTã—ãŸãƒ¢ãƒ‡ãƒ«ã‚ã£ãŸæ–¹ãŒè‰¯ã„ã®ã§ã¯ãªã„ã‹ï¼Ÿã¨æ„Ÿã˜ã‚‹ã€‚<br><br>ã¾ãŸã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ãŠã‘ã‚‹subquestionã¨subquestionã«å¯¾ã™ã‚‹ground truthã®ãƒ‡ãƒ¼ã‚¿ä½œæˆæ–¹æ³•ã¯æ›¸ã‹ã‚Œã¦ã„ã‚‹ãŒã€ãã‚‚ãã‚‚å…ƒãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½•ã‚’åˆ©ç”¨ã—ãŸã‹ã‚„ã€ãã®çµ±è¨ˆé‡ã‚‚æ›¸ã‹ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ã‚ã¨ã€ãã‚‚ãã‚‚æ©Ÿæ¢°çš„ã«å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã§ããªã„å ´åˆã©ã†ã™ã‚Œã°è‰¯ã„ã®ã‹ï¼Ÿã¨ã„ã†ç–‘å•ã¯æ®‹ã‚‹ã€‚</p>
<p>èª­ã‚“ã§ã„ãŸæ™‚ã«Auto-CoTã¨ã®é•ã„ãŒã‚ˆãã‚ã‹ã‚‰ãªã‹ã£ãŸãŒã€Related Workã®éƒ¨åˆ†ã«ã¯Auto-CoTã¯å‹•çš„ã€ã‹ã¤å¤šæ§˜ãªãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦ã„ã‚‹ãŒã€AutoReasonã¯questionã‚’åˆ†è§£ã—ã€few-shotã® promptingã§ã‚ˆã‚Šè©³ç´°ãªrationaleã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦ã„ã‚‹ç‚¹ãŒç•°ãªã‚‹ã¨ã„ã†ä¸»å¼µã®ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/556" target="_blank" rel="noopener noreferrer">Automatic Chain of Thought Prompting in Large Language Models, Zhang+, Shanghai Jiao Tong University, ICLR'23</a>
</p>
<p>Auto-CoTã¨ã®å·®åˆ¥åŒ–ã¯ä¸Šè¨˜ã§ç†è§£ã§ãã‚‹ãŒã€G-EvalãŒå®Ÿæ–½ã—ã¦ã„ã‚‹Auto-CoTã¨ã®å·®åˆ¥åŒ–ã¯ã©ã†ã™ã‚‹ã®ã‹ï¼Ÿã¨ã„ã†é¢¨ã«ãµã¨æ€ã£ãŸã€‚è«–æ–‡ä¸­ã§ã‚‚G-Evalã¯å¼•ç”¨ã•ã‚Œã¦ã„ãªã„ã€‚<br><br>ç´ æœ´ã«ã¯AutoReasonã¯SFTã‚’ã—ã¦å­¦ç¿’ã‚’ã—ã¦ã„ã¾ã™ã€ã•ã‚‰ã«Recursiveã«questionã‚’subquestionã‚’åˆ†è§£ã—ã€åˆ†è§£ã—ãŸsubquestionã”ã¨ã«å›ç­”ã‚’å¾—ã¦ã€subquestionã®å›ç­”çµæœã‚’æ´»ç”¨ã—ã¦æœ€çµ‚çš„ã«è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã®å›ç­”ã‚’å‡ºåŠ›ã™ã‚‹æ‰‹æ³•ãªã®ã§ã€G-EvalãŒå®Ÿæ–½ã—ã¦ã„ã‚‹åŒä¸€contextå†…ã§rationaleã‚’zeroshotã§ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã‚ˆã‚Šã‚‚ã€ã‚ˆã‚Šè¤‡é›‘ãªå•é¡Œã«å›ç­”ã§ãã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€ã¨ã„ã†ä¸»å¼µã«ã¯ãªã‚Šãã†ã§ã¯ã‚ã‚‹ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1223" target="_blank" rel="noopener noreferrer">G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment, Yang Liu+, N/A, EMNLP'23</a>
</p>
<p>ICLR 2023 OpenReview:


<a href="https://openreview.net/forum?id=PTUcygUoxuc" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=PTUcygUoxuc</a>


<br><br>- ææ¡ˆæ‰‹æ³•ã¯ä¸€èˆ¬çš„ã«åˆ©ç”¨å¯èƒ½ã¨ä¸»å¼µã—ã¦ã„ã‚‹ãŒã€ä¸€èˆ¬çš„ã«åˆ©ç”¨ã™ã‚‹ãŸã‚ã«ã¯äººæ‰‹ã§subquestionã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ååˆ†ã«ä¸€èˆ¬çš„ã§ã¯ãªã„<br>- é™ã‚‰ã‚ŒãŸcontexté•·ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«å†å¸°ã‚’åˆ©ç”¨ã™ã‚‹ã¨ã„ã†ã‚¢ã‚¤ãƒ‡ã‚¢ã¯æ–°ã—ã„ã‚‚ã®ã§ã¯ãªãã€æ•°å­¦ã®å®šç†ã®è¨¼æ˜ãªã©ä»–ã®è¨­å®šã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹<br><br>ã¨ã„ã†ç†ç”±ã§rejectã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2024-12-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1570" target="_blank" rel="noopener noreferrer" class="title-link">SmoothQuant: Accurate and Efficient Post-Training Quantization for Large   Language Models, Guangxuan Xiao+, ICML'23</a>
<span class="snippet"><span>GPT Summary</span>- SmoothQuantã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸è¦ã§8ãƒ“ãƒƒãƒˆã®é‡ã¿ã¨æ´»æ€§åŒ–ã®é‡å­åŒ–ã‚’å®Ÿç¾ã™ã‚‹ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é‡å­åŒ–ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚æ´»æ€§åŒ–ã®å¤–ã‚Œå€¤ã‚’æ»‘ã‚‰ã‹ã«ã™ã‚‹ã“ã¨ã§ã€é‡å­åŒ–ã®é›£æ˜“åº¦ã‚’è»½æ¸›ã—ã€ç²¾åº¦ã‚’ä¿æŒã—ã¤ã¤æœ€å¤§1.56å€ã®é€Ÿåº¦å‘ä¸Šã¨2å€ã®ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ã‚’é”æˆã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€530Bã®LLMã‚’å˜ä¸€ãƒãƒ¼ãƒ‰ã§é‹ç”¨å¯èƒ½ã«ã—ã€LLMsã®æ°‘ä¸»åŒ–ã‚’ä¿ƒé€²ã—ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãŠãã‚‰ãé‡å­åŒ–æ‰‹æ³•ã®ç¾æ™‚ç‚¹ã®SoTA</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<span class="issue_date">Issue Date: 2024-12-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1567" target="_blank" rel="noopener noreferrer" class="title-link">Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions, John Chung+, ACL'23, 2023.07</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMã‚’ç”¨ã„ãŸãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã«ãŠã‘ã‚‹å¤šæ§˜æ€§ã¨ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®äººé–“ã¨AIã®ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‚·ãƒƒãƒ—ã‚’æ¢æ±‚ã€‚ãƒ­ã‚¸ãƒƒãƒˆæŠ‘åˆ¶ã¨æ¸©åº¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®2ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§å¤šæ§˜æ€§ã‚’é«˜ã‚ã‚‹ä¸€æ–¹ã€ãƒ©ãƒ™ãƒ«ç½®æ›ï¼ˆLRï¼‰ã¨ç¯„å›²å¤–ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆOOSFï¼‰ã«ã‚ˆã‚‹äººé–“ã®ä»‹å…¥ã‚’æ¤œè¨ã€‚LRã¯ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’14.4%å‘ä¸Šã•ã›ã€ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆåˆ†é¡ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸãŒã€OOSFã¯åŠ¹æœãŒãªã‹ã£ãŸã€‚ä»Šå¾Œã®ç ”ç©¶ã®å¿…è¦æ€§ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã®è³ªã‚’ç¶­æŒã—ã¤ã¤ã€å¤šæ§˜æ€§ã‚’é«˜ã‚ã‚‹å–ã‚Šçµ„ã¿ã€‚å¤šæ§˜æ€§ã‚’é«˜ã‚ã‚‹å–ã‚Šçµ„ã¿ã¨ã—ã¦ã¯3ç¨®é¡ã®æ–¹æ³•ãŒè©¦ã•ã‚Œã¦ãŠã‚Šã€<br><br>- Logit Suppression: ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®å˜èªç”Ÿæˆé »åº¦ã‚’ãƒ­ã‚®ãƒ³ã‚°ã—ã€é »å‡ºã™ã‚‹å˜èªã«penaltyã‚’ã‹ã‘ã‚‹æ–¹æ³•<br><br>- High Temperature: temperatureã‚’[0.3, 0.7, 0.9, 1.3]ã«ãã‚Œãã‚Œè¨­å®šã—ã¦å˜èªã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹æ–¹æ³•<br><br>- Seeding Example: ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã€seedã¨ã—ã¦promptã«åŸ‹ã‚è¾¼ã‚“ã§ç”Ÿæˆã•ã›ã‚‹æ–¹æ³•<br><br><br><br>ã§å®Ÿé¨“ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1560" target="_blank" rel="noopener noreferrer" class="title-link">Improving the Domain Adaptation of Retrieval Augmented Generation ï¼ˆRAGï¼‰ Models for Open Domain Question Answering, Siriwardhana+, TACL'23, 2023.01</a>
<span class="snippet"><span>GPT Summary</span>- RAG-end2endã¯ã€ODQAã«ãŠã‘ã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œã®ãŸã‚ã«RAGã®ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã¨ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’å…±åŒè¨“ç·´ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚å¤–éƒ¨çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’æ›´æ–°ã—ã€è£œåŠ©çš„ãªè¨“ç·´ä¿¡å·ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹çŸ¥è­˜ã‚’å¼·åŒ–ã€‚COVID-19ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€ä¼šè©±ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡ã—ã€å…ƒã®RAGãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚æ€§èƒ½ãŒå‘ä¸Šã€‚ç ”ç©¶ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦å…¬é–‹ã€‚</span>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-11-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1546" target="_blank" rel="noopener noreferrer" class="title-link">Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints, Aran Komatsuzaki+, ICLR'23</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¹ãƒ‘ãƒ¼ã‚¹æ´»æ€§åŒ–ãƒ¢ãƒ‡ãƒ«ã¯ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã¤ã¤å¯†ãªãƒ¢ãƒ‡ãƒ«ã®ä»£æ›¿ã¨ã—ã¦æ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ãŒã€ä¾ç„¶ã¨ã—ã¦å¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚’å¿…è¦ã¨ã—ã€ã‚¼ãƒ­ã‹ã‚‰ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯é«˜ã‚³ã‚¹ãƒˆã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€å¯†ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ã‚¹ãƒ‘ãƒ¼ã‚¹æ´»æ€§åŒ–Mixture-of-Expertsãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã™ã‚‹ã€Œã‚¹ãƒ‘ãƒ¼ã‚¹ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚¯ãƒªãƒ³ã‚°ã€ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åˆæœŸã®å¯†ãªäº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ã‚³ã‚¹ãƒˆã‚’ç´„50%å†åˆ©ç”¨ã—ã€SuperGLUEã‚„ImageNetã§å¯†ãªãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚¯ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚¼ãƒ­ã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸçµæœã‚’å¾—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>æ–œã‚èª­ã¿ã—ã‹ã§ãã¦ã„ãªã„ãŒã€Mixture-of-Expertsã‚’ç”¨ã„ãŸãƒ¢ãƒ‡ãƒ«ã‚’SFT/Pretrainingã™ã‚‹éš›ã«ã€æ—¢å­˜ã®checkpointã®é‡ã¿ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã‚ˆã‚ŠåŠ¹ç‡çš„ã‹ã¤æ€§èƒ½å‘ä¸Šã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚MoE Layerã®MLPã‚’å…¨ã¦æ—¢å­˜ã®checkpointã«ãŠã‘ã‚‹MLPã®é‡ã¿ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦åˆæœŸåŒ–ã™ã‚‹ã€‚Routerã¯ã‚¹ã‚¯ãƒ©ãƒƒãƒã‹ã‚‰å­¦ç¿’ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/d51a0746-d2cc-4343-a462-20034ef373d9" alt="image" loading="lazy"><br><br>ç¶™ç¶šäº‹å‰å­¦ç¿’ã«ãŠã„ã¦ã¯ã€åŒã˜å­¦ç¿’æ™‚é–“ã®ä¸­ã§Dense Layerã‚’ç”¨ã„ã‚‹ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨æ¯”è¼ƒã—ã¦ã§ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’ç²å¾—ã€‚<br><img src="https://github.com/user-attachments/assets/d7a67c99-15d7-4803-82e4-63187bb3d4ec" alt="image" loading="lazy"><br>Figure2ã§ç¶™ç¶šäº‹å‰å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€ãƒ•ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®Finetuningã‚’ã—ãŸå ´åˆã§ã‚‚Upcyclingã¯åŠ¹æœãŒã‚ã‚‹ï¼ˆFigure3ï¼‰ã€‚<br><br>ç‰¹ã«Pretrainingã§ã¯Upcyclingã‚’ç”¨ã„ãŸãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«ã€é€šå¸¸ã®MoEã‚’ã‚¹ã‚¯ãƒ©ãƒƒãƒã‹ã‚‰å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒè¿½ã„ã¤ãã®ã«æ™‚é–“ãŒã‹ã‹ã‚‹ã¨ã®ã“ã¨ã€‚ç‰¹ã«å›³å³å´ã®è¨€èªã‚¿ã‚¹ã‚¯ã§ã¯ã€120%ã®å­¦ç¿’æ™‚é–“ãŒè¿½ã„ã¤ããŸã‚ã«å¿…è¦ã ã£ãŸã€‚<br><img src="https://github.com/user-attachments/assets/f0ca37ac-65a7-43ff-afef-ffc309b17040" alt="image" loading="lazy"><br><br>Sparse Upcycingã¨ã€Dense tilingã«ã‚ˆã‚‹æ‰‹æ³•ï¼ˆwarm start; å…ƒã®ãƒ¢ãƒ‡ãƒ«ã«æ—¢å­˜ã®å±¤ã‚’è¤‡è£½ã—ã¦æ–°ã—ã„å±¤ã‚’è¿½åŠ ã™ã‚‹æ–¹æ³•ï¼‰ã€å…ƒã®ãƒ¢ãƒ‡ãƒ«ã‚’ãã‚Œãã‚Œç¶™ç¶šäº‹å‰å­¦ç¿’ã™ã‚‹ã¨ã€æœ€ã‚‚é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/b357a08a-d202-47d3-977f-f02b192723d1" alt="image" loading="lazy"><br><br>ï¼ˆã™ã”ã„æ–œã‚èª­ã¿ãªã®ã§ã¡ã‚‡ã£ã‚‚è‡ªä¿¡ãªã—ã€ã€ã€ï¼‰</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-11-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1534" target="_blank" rel="noopener noreferrer" class="title-link">Prompting Large Language Model for Machine Translation: A Case Study, Biao Zhang+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æ©Ÿæ¢°ç¿»è¨³ã«ãŠã‘ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã®ç ”ç©¶ã‚’ä½“ç³»çš„ã«è¡Œã„ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚„ãƒ‡ãƒ¢ä¾‹ã®é¸æŠã«å½±éŸ¿ã‚’ä¸ãˆã‚‹è¦å› ã‚’æ¤œè¨ã€‚GLM-130Bã‚’ç”¨ã„ãŸå®Ÿé¨“ã«ã‚ˆã‚Šã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ã®æ•°ã¨è³ªãŒç¿»è¨³ã«é‡è¦ã§ã‚ã‚‹ã“ã¨ã€æ„å‘³çš„é¡ä¼¼æ€§ãªã©ã®ç‰¹å¾´ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ç›¸é–¢ã™ã‚‹ãŒå¼·ããªã„ã“ã¨ã€å˜è¨€èªãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®æ“¬ä¼¼å¹³è¡Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ãŒç¿»è¨³ã‚’æ”¹å–„ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã€ä»–ã®è¨­å®šã‹ã‚‰ã®çŸ¥è­˜è»¢é€ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã®èª²é¡Œã«ã¤ã„ã¦ã‚‚è­°è«–ã€‚</span>
<span class="snippet"><span>Comment</span><p>zero-shotã§MTã‚’è¡Œã†ã¨ãã«ã€æ”¹è¡Œã®æœ‰ç„¡ã‚„ã€å°‘ã—ã®promptingã®é•ã„ã§COMETã‚¹ã‚³ã‚¢ãŒå¤§å¹…ã«å¤‰ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br>ãƒ¢ãƒ‡ãƒ«ã¯GLM-130Bã‚’INT4ã§é‡å­åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã§å®Ÿé¨“ã—ã¦ã„ã‚‹ã€‚<br><br>èˆˆå‘³æ·±ã„ãŒã€ã“ã®çŸ¥è¦‹ã‚’ä¸€èˆ¬åŒ–ã—ã¦å…¨ã¦ã®LLMã«é©ç”¨ã§ãã‚‹ã‹ï¼Ÿã¨è¨€ã‚ã‚Œã‚‹ã¨ã€ãã†ã¯ãªã‚‰ãªã„æ°—ãŒã™ã‚‹ã€‚ä»–ã®ãƒ¢ãƒ‡ãƒ«ã§æ¤œè¨¼ã—ãŸã‚‰å‚¾å‘ã¯ãŠãã‚‰ãå¤‰ã‚ã‚‹ã§ã‚ã‚ã†ï¼ˆã¨ã„ã†æ„å‘³ã§ãŠãã‚‰ãè«–æ–‡ã®ã‚¿ã‚¤ãƒˆãƒ«ã«ã‚‚Case Studyã¨è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã®ã‹ãªã‚ï¼‰ã€‚<br><br><br><br><img src="https://github.com/user-attachments/assets/1302dbb2-40e2-40c2-9a71-cae01528b5e6" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2024-11-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1498" target="_blank" rel="noopener noreferrer" class="title-link">Precise Zero-Shot Dense Retrieval without Relevance Labels, Luyu Gao+, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆå¯†ãªæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã«ãŠã„ã¦ã€ä»®æƒ³æ–‡æ›¸åŸ‹ã‚è¾¼ã¿ï¼ˆHyDEï¼‰ã‚’ææ¡ˆã€‚ã‚¯ã‚¨ãƒªã«åŸºã¥ãã€æŒ‡ç¤ºã«å¾“ã†è¨€èªãƒ¢ãƒ‡ãƒ«ãŒä»®æƒ³æ–‡æ›¸ã‚’ç”Ÿæˆã—ã€æ•™å¸«ãªã—ã§å­¦ç¿’ã•ã‚ŒãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãŒã“ã‚Œã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã€‚å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã«åŸºã¥ãé¡ä¼¼æ–‡æ›¸ã‚’å–å¾—ã™ã‚‹ã“ã¨ã§ã€èª¤ã£ãŸè©³ç´°ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€‚å®Ÿé¨“çµæœã§ã¯ã€HyDEãŒæœ€å…ˆç«¯ã®å¯†ãªæ¤œç´¢å™¨Contrieverã‚’ä¸Šå›ã‚Šã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã¨è¨€èªã§å¼·åŠ›ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2024-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1424" target="_blank" rel="noopener noreferrer" class="title-link">UL2: Unifying Language Learning Paradigms, Yi Tay+, N_A, ICLR'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ™®éçš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€äº‹å‰å­¦ç¿’ã®ç›®çš„ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’åˆ†é›¢ã€‚Mixture-of-Denoisersï¼ˆMoDï¼‰ã‚’å°å…¥ã—ã€è¤‡æ•°ã®äº‹å‰å­¦ç¿’ç›®çš„ã®åŠ¹æœã‚’ç¤ºã™ã€‚20Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€50ã®NLPã‚¿ã‚¹ã‚¯ã§SOTAã‚’é”æˆã—ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã‚„ãƒ¯ãƒ³ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã§ã‚‚å„ªã‚ŒãŸçµæœã‚’ç¤ºã™ã€‚UL2 20Bãƒ¢ãƒ‡ãƒ«ã¯ã€FLANæŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šé«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã€é–¢é€£ã™ã‚‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=6ruVLB727MC" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=6ruVLB727MC</a>


</p>
<p>[R] standard span corruption, [S] causal language modeling, [X] extreme span corruption ã®3ç¨®é¡ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’æŒã¤MoD (Mixture of Denoisers)ã‚’ææ¡ˆ<br><br>&lt;img width="1187" height="1203" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/a07372c6-854c-4bd1-8f59-f8c4dbdc5d23"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a07372c6-854c-4bd1-8f59-f8c4dbdc5d23"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1412" target="_blank" rel="noopener noreferrer" class="title-link">Direct Preference Optimization: Your Language Model is Secretly a Reward  Model, Rafael Rafailov+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ç„¡ç›£ç£è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLMï¼‰ã®åˆ¶å¾¡æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€å ±é…¬ãƒ¢ãƒ‡ãƒ«ã®æ–°ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚’å°å…¥ã—ã€å˜ç´”ãªåˆ†é¡æå¤±ã§RLHFå•é¡Œã‚’è§£æ±ºã™ã‚‹ã€Œç›´æ¥çš„ãªå¥½ã¿æœ€é©åŒ–ï¼ˆDPOï¼‰ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã€‚DPOã¯å®‰å®šæ€§ã¨æ€§èƒ½ã‚’æŒã¡ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã‚’ä¸è¦ã«ã—ã€æ—¢å­˜ã®æ–¹æ³•ã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¤ºã™ã€‚ç‰¹ã«ã€ç”Ÿæˆç‰©ã®æ„Ÿæƒ…åˆ¶å¾¡ã«ãŠã„ã¦PPOãƒ™ãƒ¼ã‚¹ã®RLHFã‚’ä¸Šå›ã‚Šã€å¿œç­”ã®è³ªã‚’æ”¹å–„ã—ã¤ã¤å®Ÿè£…ãŒç°¡ç´ åŒ–ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>DPOã‚’ææ¡ˆã—ãŸç ”ç©¶<br><br>&lt;img width="838" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/2f7edf2c-32fa-4c5c-bc39-fb85112d1837"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/2f7edf2c-32fa-4c5c-bc39-fb85112d1837"&lt;/a&gt;


&gt;<br><br></p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1940194999993585925?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span></strong></p>
<p>SNLP'24ã§ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:


<a href="https://speakerdeck.com/kazutoshishinoda/lun-wen-shao-jie-direct-preference-optimization-your-language-model-is-secretly-a-reward-model" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/kazutoshishinoda/lun-wen-shao-jie-direct-preference-optimization-your-language-model-is-secretly-a-reward-model</a>


</p></span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2024-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1401" target="_blank" rel="noopener noreferrer" class="title-link">Instruction Tuning with GPT-4, Baolin Peng+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- GPT-4ã‚’ç”¨ã„ã¦æŒ‡ç¤ºã«å¾“ã†ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†åˆã®è©¦ã¿ã‚’å ±å‘Šã€‚ç”Ÿæˆã•ã‚ŒãŸ52Kã®æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã¯ã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦å„ªã‚ŒãŸã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚GPT-4ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¨æ¯”è¼ƒãƒ‡ãƒ¼ã‚¿ã‚‚åé›†ã—ã€ãƒ‡ãƒ¼ã‚¿ã¨ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç¾åœ¨ã¯OpenAIã®åˆ©ç”¨è¦ç´„ã«ãŠã„ã¦ã€outputã‚’åˆ©ç”¨ã—ã¦OpenAIã¨ç«¶åˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã¯ç¦æ­¢ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ã“ã®ç‚¹ã«ã¯æ³¨æ„ãŒå¿…è¦<br>


<a href="https://openai.com/ja-JP/policies/terms-of-use/" target="_blank" rel="noopener noreferrer">https://openai.com/ja-JP/policies/terms-of-use/</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<span class="issue_date">Issue Date: 2024-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1382" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models Cannot Self-Correct Reasoning Yet, Jie Huang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®è‡ªå·±ä¿®æ­£èƒ½åŠ›ã‚’æ‰¹åˆ¤çš„ã«æ¤œè¨ã—ã€å†…åœ¨çš„è‡ªå·±ä¿®æ­£ã®æ¦‚å¿µã‚’ä¸­å¿ƒã«ã€å¤–éƒ¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãªã—ã§ã®å¿œç­”ä¿®æ­£ã®é›£ã—ã•ã‚’ç¤ºã™ã€‚è‡ªå·±ä¿®æ­£å¾Œã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã€ä»Šå¾Œã®ç ”ç©¶ã‚„å¿œç”¨ã«å‘ã‘ãŸææ¡ˆã‚’è¡Œã†ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<span class="issue_date">Issue Date: 2024-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1380" target="_blank" rel="noopener noreferrer" class="title-link">Reflection-Tuning: Data Recycling Improves LLM Instruction-Tuning, Ming Li+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã„ã†æ–°æ‰‹æ³•ã‚’ææ¡ˆã—ã€LLMsã®è‡ªå·±æ”¹å–„ã‚’é€šã˜ã¦ä½å“è³ªãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å•é¡Œã«å¯¾å‡¦ã€‚ã‚ªãƒ©ã‚¯ãƒ«LLMã‚’ç”¨ã„ã¦ãƒ‡ãƒ¼ã‚¿ã®è³ªã‚’å‘ä¸Šã•ã›ã€å®Ÿé¨“ã«ã‚ˆã‚Šå†åˆ©ç”¨ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚ŒãŸLLMsãŒæ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Reflection-Tuningã‚’ææ¡ˆã—ã¦ã„ã‚‹ç ”ç©¶?</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Finetuning.html" target="_blank" rel="noopener noreferrer">#Finetuning</a>
<span class="issue_date">Issue Date: 2024-05-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1317" target="_blank" rel="noopener noreferrer" class="title-link">T5Score: Discriminative Fine-tuning of Generative Evaluation Metrics, Yiwei Qin+, N_A, EMNLP-Findings'23</a>
<span class="snippet"><span>GPT Summary</span>- åŸ‹ã‚è¾¼ã¿ãƒ™ãƒ¼ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®è©•ä¾¡ã«ã¯ã€æ•™å¸«ä»˜ãã®è­˜åˆ¥ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ç”Ÿæˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®2ã¤ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ãŒã‚ã‚Šã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ•™å¸«ä»˜ãã¨æ•™å¸«ãªã—ã®ä¿¡å·ã‚’çµ„ã¿åˆã‚ã›ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€mT5ã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã¨ã—ã¦T5Scoreãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨“ç·´ã—ã¾ã—ãŸã€‚T5Scoreã¯ä»–ã®æ—¢å­˜ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨åŒ…æ‹¬çš„ãªå®Ÿè¨¼çš„æ¯”è¼ƒã‚’è¡Œã„ã€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ã§æœ€è‰¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview: 


<a href="https://openreview.net/forum?id=2jibzAXJzH&noteId=rgNMHmjShZ" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=2jibzAXJzH&noteId=rgNMHmjShZ</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1309" target="_blank" rel="noopener noreferrer" class="title-link">Mistral 7B, Albert Q. Jiang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Mistral 7B v0.1ã¯ã€70å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€é«˜é€Ÿãªæ¨è«–ã®ãŸã‚ã«GQAã‚’æ´»ç”¨ã—ã€SWAã‚’çµ„ã¿åˆã‚ã›ã¦ã„ã‚‹ã€‚ã¾ãŸã€Mistral 7B -- Instructã¯Llama 2 13B -- Chatãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã£ã¦ãŠã‚Šã€Apache 2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1237" target="_blank" rel="noopener noreferrer">Mistral Large</a>
 <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1279" target="_blank" rel="noopener noreferrer">Mixtral-8x22B-v0.1, 2024</a>
 ãªã©ã®ãƒ¢ãƒ‡ãƒ«ã‚‚å‚ç…§ã®ã“ã¨<br><br><br><br>ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒ«ãŒå¤§ãããªã‚‹ã¨ã€inferenceã®latencyãŒé…ããªã‚Šã€è¨ˆç®—ã‚³ã‚¹ãƒˆãŒå¤§ãããªã‚Šã™ãã¦å®Ÿç”¨çš„ã§ãªã„ã®ã§ã€å°ã•ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ç´ æ—©ã„inferenceå®Ÿç¾ã—ãŸã„ã‚ˆã­ã€ã¨ã„ã†ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã€‚<br><br>ãã®ãŸã‚ã«ã€SlidingWindowAttentionã¨GroupQueryAttention <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
 ã‚’æ´»ç”¨ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/154bc04b-5056-4b88-8b4d-deff169d4a10" alt="image" loading="lazy"><br><br><br><br>ã‚ˆã‚Šå°ã•ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§Llama2ã‚’æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã§outperformã—<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d2890d33-4895-4d09-aa22-5566a471f41f" alt="image" loading="lazy"><br><br><br><br>Instruction Tuningã‚’å®Ÿæ–½ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã€13Bãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ChatbotArenaã§é«˜ã„Elo Rateã‚’ç²å¾—ã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9f37a61e-0cf1-4712-a912-4f7e77094072" alt="image" loading="lazy"><br><br></p>
<p>ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã¯8192</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Annotation.html" target="_blank" rel="noopener noreferrer">#Annotation</a>
<span class="issue_date">Issue Date: 2024-05-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1304" target="_blank" rel="noopener noreferrer" class="title-link">Benchmarking Large Language Models for News Summarization, Tianyi Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®æˆåŠŸã®ç†ç”±ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€ç•°ãªã‚‹äº‹å‰å­¦ç¿’æ–¹æ³•ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ãŠã‚ˆã³ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚±ãƒ¼ãƒ«ã«ã‚ãŸã‚‹10ã¤ã®LLMsã«å¯¾ã™ã‚‹äººé–“ã®è©•ä¾¡ã‚’è¡Œã£ãŸã€‚ãã®çµæœã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§ã¯ãªãã€æŒ‡ç¤ºã®èª¿æ•´ãŒLLMã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆè¦ç´„èƒ½åŠ›ã®éµã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã¾ãŸã€LLMsã®è¦ç´„ã¯äººé–“ã®åŸ·ç­†ã—ãŸè¦ç´„ã¨åŒç­‰ã¨åˆ¤æ–­ã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>- ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®é«˜å“è³ªãªè¦ç´„ã‚’äººé–“ã«ä½œæˆã—ã¦ã‚‚ã‚‰ã„ã€gpt-3.5ã‚’ç”¨ã„ã¦LLM-basedãªè¦ç´„ã‚‚ç”Ÿæˆ<br><br>- annotatorã«ãã‚Œãã‚Œã®è¦ç´„ã®å“è³ªã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã•ã›ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer" class="title-link">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head  Checkpoints, Joshua Ainslie+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Multi-query attentionï¼ˆMQAï¼‰ã¯ã€å˜ä¸€ã®key-value headã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãŠã‚Šã€ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã®æ¨è«–ã‚’åŠ‡çš„ã«é«˜é€ŸåŒ–ã—ã¦ã„ã¾ã™ã€‚ãŸã ã—ã€MQAã¯å“è³ªã®ä½ä¸‹ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚Šã€ã•ã‚‰ã«ã¯ã€ã‚ˆã‚Šé€Ÿã„æ¨è«–ã®ãŸã‚ã ã‘ã«åˆ¥å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ãŒæœ›ã¾ã—ããªã„å ´åˆã‚‚ã‚ã‚Šã¾ã™ã€‚æ—¢å­˜ã®ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨ˆé‡ã®5%ã‚’ä½¿ç”¨ã—ã¦MQAã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã«ã‚¢ãƒƒãƒ—ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®ãƒ¬ã‚·ãƒ”ã‚’ææ¡ˆã—ã€ã•ã‚‰ã«ã€è¤‡æ•°ã®key-value headã‚’ä½¿ç”¨ã™ã‚‹ãƒãƒ«ãƒã‚¯ã‚¨ãƒªã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®ä¸€èˆ¬åŒ–ã§ã‚ã‚‹ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã‚¯ã‚¨ãƒªã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ï¼ˆGQAï¼‰ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚ã‚¢ãƒƒãƒ—ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸGQAãŒã€MQAã¨åŒç­‰ã®é€Ÿåº¦ã§ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã«åŒ¹æ•µã™ã‚‹å“è³ªã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>é€šå¸¸ã®Multi-Head AttentionãŒQKVãŒ1å¯¾1å¯¾å¿œãªã®ã«å¯¾ã—ã€Multi Query Attention (MQA) <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1272" target="_blank" rel="noopener noreferrer">Fast Transformer Decoding: One Write-Head is All You Need, Noam Shazeer, N/A, arXiv'19</a>
  ã¯å…¨ã¦ã®Qã«å¯¾ã—ã¦KVã‚’å…±æœ‰ã™ã‚‹ã€‚ä¸€æ–¹ã€GQAã¯ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«KVã‚’å…±æœ‰ã™ã‚‹ç‚¹ã§ç•°ãªã‚‹ã€‚MQAã¯å¤§å¹…ã«Infeerence` speedãŒæ”¹å–„ã™ã‚‹ãŒã€ç²¾åº¦ãŒåŠ£åŒ–ã™ã‚‹å•é¡ŒãŒã‚ã£ãŸã€‚ã“ã®ç ”ç©¶ã§ã¯é€šå¸¸ã®Multi-Head Attentionã«å¯¾ã—ã¦ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®äº‹å‰å­¦ç¿’ã«å¯¾ã—ã¦è¿½åŠ ã®5%ã®è¨ˆç®—é‡ã§GQAãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/70ec2179-428c-47b8-af53-cb3cc0e4f022" alt="image" loading="lazy"><br><br></p>
<p>Main Result. Multi-Head Attentionã«å¯¾ã—ã¦ã€inference timeãŒå¤§å¹…ã«æ”¹å–„ã—ã¦ã„ã‚‹ãŒã€Multi-Query Attentionã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¶­æŒã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3687aeb4-90b8-403d-853b-740121dd5f98" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1224" target="_blank" rel="noopener noreferrer" class="title-link">INSTRUCTSCORE: Explainable Text Generation Evaluation with Finegrained   Feedback, Wenda Xu+, N_A, EMNLP'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå‹•çš„ãªè¨€èªç”Ÿæˆã®å“è³ªè©•ä¾¡ã«ã¯èª¬æ˜å¯èƒ½ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒå¿…è¦ã§ã‚ã‚‹ãŒã€æ—¢å­˜ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯ãã®åˆ¤å®šã‚’èª¬æ˜ã—ãŸã‚Šæ¬ é™¥ã¨ã‚¹ã‚³ã‚¢ã‚’é–¢é€£ä»˜ã‘ã‚‹ã“ã¨ãŒã§ããªã„ã€‚ãã“ã§ã€InstructScoreã¨ã„ã†æ–°ã—ã„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ææ¡ˆã—ã€äººé–“ã®æŒ‡ç¤ºã¨GPT-4ã®çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã®è©•ä¾¡ã¨è¨ºæ–­ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚ã•ã¾ã–ã¾ãªç”Ÿæˆã‚¿ã‚¹ã‚¯ã§InstructScoreã‚’è©•ä¾¡ã—ã€ä»–ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚é©šãã¹ãã“ã¨ã«ã€InstructScoreã¯äººé–“ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãªã—ã§æœ€å…ˆç«¯ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä¼çµ±çš„ãªNLGã®æ€§èƒ½æŒ‡æ¨™ã®è§£é‡ˆæ€§ãŒä½ã„ã“ã¨ã‚’ä¸»å¼µã™ã‚‹ç ”ç©¶</p>
<p><img src="https://github.com/user-attachments/assets/4c4fe705-e0c5-41d1-b3c8-c084d85b77ba" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1223" target="_blank" rel="noopener noreferrer" class="title-link">G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment, Yang Liu+, N_A, EMNLP'23</a>
<span class="snippet"><span>GPT Summary</span>- å¾“æ¥ã®å‚ç…§ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡æŒ‡æ¨™ã§ã¯ã€è‡ªç„¶è¨€èªç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®å“è³ªã‚’æ­£ç¢ºã«æ¸¬å®šã™ã‚‹ã“ã¨ãŒé›£ã—ã„ã€‚æœ€è¿‘ã®ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ãŸå‚ç…§ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡æŒ‡æ¨™ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ãŒã€ã¾ã äººé–“ã¨ã®ä¸€è‡´åº¦ãŒä½ã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€G-Evalã¨ã„ã†å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸå“è³ªè©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€è¦ç´„ã¨å¯¾è©±ç”Ÿæˆã®ã‚¿ã‚¹ã‚¯ã§å®Ÿé¨“ã‚’è¡Œã£ãŸã€‚G-Evalã¯å¾“æ¥ã®æ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ã€LLMãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡å™¨ã®æ½œåœ¨çš„ãªå•é¡Œã«ã¤ã„ã¦ã‚‚åˆ†æã—ã¦ã„ã‚‹ã€‚ã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä¼çµ±çš„ãªNLGã®æ€§èƒ½æŒ‡æ¨™ãŒã€äººé–“ã®åˆ¤æ–­ã¨ã®ç›¸é–¢ãŒä½ã„ã“ã¨ã‚’ç¤ºã—ãŸç ”ç©¶</p>
<p>
<strong># æ‰‹æ³•æ¦‚è¦<br><br>- CoTã‚’åˆ©ç”¨ã—ã¦ã€ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®å“è³ªã‚’è©•ä¾¡ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br>- ã‚¿ã‚¹ã‚¯ã®Introductionã¨ã€è©•ä¾¡ã®Criteriaã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ä»•è¾¼ã‚€ã ã‘ã§ã€è‡ªå‹•çš„ã«LLMã«è©•ä¾¡ã‚¹ãƒ†ãƒƒãƒ—ã«é–¢ã™ã‚‹CoTã‚’ç”Ÿæˆã•ã›ã€æœ€çµ‚çš„ã«ãƒ•ã‚©ãƒ¼ãƒ ã‚’åŸ‹ã‚ã‚‹å½¢å¼ã§ã‚¹ã‚³ã‚¢ã‚’ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ç”Ÿæˆã•ã›è©•ä¾¡ã‚’å®Ÿæ–½ã™ã‚‹ã€‚æœ€çµ‚çš„ã«ã€å„ã‚¹ã‚³ã‚¢ã®ç”Ÿæˆç¢ºç‡ã«ã‚ˆã‚‹weighted-sumã«ã‚ˆã£ã¦ã€æœ€çµ‚ã‚¹ã‚³ã‚¢ã‚’æ±ºå®šã™ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a91c9234-6f41-4fb4-a94f-8a47a594dd9e" alt="image" loading="lazy"><br><br><br><br>&lt;/p&gt;<p># Scoringã®å•é¡Œç‚¹<br><br>ãŸã¨ãˆã°ã€1-5ã®discreteãªã‚¹ã‚³ã‚¢ã‚’ç›´æ¥LLMã«outputã•ã›ã‚‹ã¨ã€ä¸‹è¨˜ã®ã‚ˆã†ãªå•é¡ŒãŒç”Ÿã˜ã‚‹ï¼š<br><br>1. ã‚ã‚‹ä¸€ã¤ã®ã‚¹ã‚³ã‚¢ãŒæ”¯é…çš„ã«ãªã£ã¦ã—ã¾ã„ã€ã‚¹ã‚³ã‚¢ã®åˆ†æ•£ãŒç„¡ãã€äººé–“ã®è©•ä¾¡ã¨ã®ç›¸é–¢ãŒä½ããªã‚‹<br><br>2. LLMã¯å°æ•°ã‚’å‡ºåŠ›ã™ã‚‹ã‚ˆã†æŒ‡ç¤ºã—ã¦ã‚‚ã€å¤§æŠµã®å ´åˆæ•´æ•°ã‚’å‡ºåŠ›ã™ã‚‹ãŸã‚ã€å¤šãã®ãƒ†ã‚­ã‚¹ãƒˆã®è©•ä¾¡å€¤ãŒåŒä¸€ã¨ãªã‚Šã€ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ç´°ã‹ãªå·®ç•°ã‚’è©•ä¾¡ã«å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ãŒã§ããªã„ã€‚<br><br><br><br>ä¸Šè¨˜ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€ä¸‹è¨˜ã®ã‚ˆã†ã«ã€ã‚¹ã‚³ã‚¢ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆç¢ºç‡ã®é‡ã¿ã¥ã‘å’Œã‚’ã¨ã‚‹ã“ã¨ã§ã€æœ€çµ‚çš„ãªã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a2a8d26c-0fb4-4f60-bd6e-600898785d7b" alt="image" loading="lazy"></p>
<p># è©•ä¾¡<br><br>- SummEval <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/984" target="_blank" rel="noopener noreferrer">SummEval: Re-evaluating Summarization Evaluation, Fabbri+, TACL'21</a>
&lt;/strong&gt;
<br>
 ãƒ‡ãƒ¼ã‚¿ã¨ã€Topical-Chat, QAGSãƒ‡ãƒ¼ã‚¿ã®3ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§è©•ä¾¡ã‚’å®Ÿæ–½ã—ãŸã€‚ã‚¿ã‚¹ã‚¯ã¨ã—ã¦ã¯ã€è¦ç´„ã¨å¯¾è©±ã®response generationã®ãƒ‡ãƒ¼ã‚¿ã¨ãªã‚‹ã€‚<br><br>- ãƒ¢ãƒ‡ãƒ«ã¯GPT-3.5 (text-davinci-003), GPT-4ã‚’åˆ©ç”¨ã—ãŸ<br><br>- gpt3.5åˆ©ç”¨æ™‚ã¯ã€temperatureã¯0ã«è¨­å®šã—ã€GPT-4ã¯ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆç¢ºç‡ã‚’è¿”ã•ãªã„ã®ã§ã€`n=20, temperature=1, top_p=1`ã¨ã—ã€20å›ã®ç”Ÿæˆçµæœã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã®å‡ºç¾ç¢ºç‡ã‚’ç®—å‡ºã—ãŸã€‚<br><br><br><br>
<strong>## è©•ä¾¡çµæœ<br><br>G-EVALãŒbaselineã‚’outperformã—ã€ç‰¹ã«GPT4ã‚’åˆ©ç”¨ã—ãŸå ´åˆã«æ€§èƒ½ãŒé«˜ã„ã€‚GPTScoreã‚’åˆ©ç”¨ã—ãŸå ´åˆã«ã€ãƒ¢ãƒ‡ãƒ«ã‚’ä½•ã‚’ä½¿ç”¨ã—ãŸã®ã‹ãŒæ›¸ã‹ã‚Œã¦ã„ãªã„ã€‚Appendixã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã®ã ã‚ã†ã‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/924b0acd-6236-49a0-a6bc-ae203c87f7ea" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/435fa260-a88d-4db2-b3a2-40d29a6617df" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/f9ca4e1f-903d-48fa-a40f-64fa8c799c43" alt="image" loading="lazy"><br><br>&lt;/p&gt;<p># Analysis<br><br>## G-EvalãŒLLMãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å¥½ã‚“ã§é«˜ã„ã‚¹ã‚³ã‚¢ã‚’ä»˜ä¸ã—ã¦ã—ã¾ã†ã‹ï¼Ÿ<br><br>- äººé–“ã«å“è³ªã®é«˜ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹è¦ç´„ã‚’æ›¸ã‹ã›ã€ã‚¢ãƒãƒ†ãƒ¼ã‚¿ã«GPTãŒç”Ÿæˆã—ãŸè¦ç´„ã‚’æ¯”è¼ƒã•ã›ãŸãƒ‡ãƒ¼ã‚¿ (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1304" target="_blank" rel="noopener noreferrer">Benchmarking Large Language Models for News Summarization, Tianyi Zhang+, N/A, arXiv'23</a>
&lt;/strong&gt;
<br>
) ã‚’ç”¨ã„ã¦æ¤œè¨¼<br><br>- ãã®çµæœã€åŸºæœ¬çš„ã«GPTãŒç”Ÿæˆã—ãŸè¦ç´„ã«å¯¾ã—ã¦ã€G-EVAL4ãŒé«˜ã„ã‚¹ã‚³ã‚¢ã‚’ä»˜ä¸ã™ã‚‹å‚¾å‘ã«ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚<br><br>    - åŸå› 1: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1304" target="_blank" rel="noopener noreferrer">Benchmarking Large Language Models for News Summarization, Tianyi Zhang+, N/A, arXiv'23</a>
ã§æŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€äººé–“ãŒè¨˜è¿°ã—ãŸè¦ç´„ã¨LLMãŒè¨˜è¿°ã—ãŸè¦ç´„ã‚’åŒºåˆ¥ã™ã‚‹ã‚¿ã‚¹ã‚¯ã¯ã€inter-annotator agreementã¯`0.07`ã§ã‚ã‚Šã€æ¥µç«¯ã«ä½ãã€äººé–“ã§ã‚‚å›°é›£ãªã‚¿ã‚¹ã‚¯ã§ã‚ã‚‹ãŸã‚ã€‚<br><br>    - åŸå› 2: LLMã¯ç”Ÿæˆæ™‚ã¨è©•ä¾¡æ™‚ã«ã€å…±é€šã—ãŸã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã§å…±æœ‰ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒé«˜ãã€ã“ã‚ŒãŒLLMãŒç”Ÿæˆã—ãŸè¦ç´„ã‚’é«˜ãè©•ä¾¡ã™ã‚‹ãƒã‚¤ã‚¢ã‚¹ã‚’ã‹ã‘ãŸ<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ec6a213d-15ea-4572-8716-ad9cbee6f19a" alt="image" loading="lazy"><br><br><br><br>## CoTã®å½±éŸ¿<br><br>- SummEvalãƒ‡ãƒ¼ã‚¿ã«ãŠã„ã¦ã€CoTã®æœ‰ç„¡ã«ã‚ˆã‚‹æ€§èƒ½ã®å·®ã‚’æ¤œè¨¼ã—ãŸçµæœã€CoTã‚’å°å…¥ã—ãŸå ´åˆã«ã‚ˆã‚Šé«˜ã„correlationã‚’ç²å¾—ã—ãŸã€‚ç‰¹ã«ã€Fluencyã¸ã®å½±éŸ¿ãŒå¤§ãã„ã€‚<br><br><br><br>## Probability Normalizationã«ã‚ˆã‚‹å½±éŸ¿<br><br>- probabilityã«ã‚ˆã‚‹normalizationã‚’å°å…¥ã—ãŸã“ã¨ã§ã€kendall tauãŒæ¸›å°‘ã—ãŸã€‚ã“ã®ç†ç”±ã¯ã€probabilityãŒå°å…¥ã•ã‚Œã¦ã„ãªã„å ´åˆã¯å¤šãã®å¼•ãåˆ†ã‘ã‚’ç”Ÿã¿å‡ºã™ã€‚ä¸€æ–¹ã€kendall tauã¯ã€concordant / discordantãƒšã‚¢ã®æ•°ã«ã‚ˆã£ã¦æ±ºå®šã•ã‚Œã‚‹ãŒã€å¼•ãåˆ†ã‘ã®å ´åˆã¯ã©ã¡ã‚‰ã«ã‚‚ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œãšã€kendall tauã®å€¤ã‚’æŠ¼ã—ä¸Šã’ã‚‹åŠ¹æœãŒã‚ã‚‹ã€‚ã“ã®ãŸã‚ã€ã“ã‚Œã¯ãƒ¢ãƒ‡ãƒ«ã®çœŸã®æ€§èƒ½ã‚’åæ˜ ã—ã¦ã„ãªã„ã€‚<br><br>- ä¸€æ–¹ã€probabilityã‚’å°å…¥ã™ã‚‹ã¨ã€ã‚ˆã‚Šç´°ã‹ã„ãªé€£ç¶šçš„ãªã‚¹ã‚³ã‚¢ã‚’ç²å¾—ã™ã‚‹ã“ã¨ãŒã§ãã€ã“ã‚Œã¯spearman-correlationã®å‘ä¸Šã«åæ˜ ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br><br><br>## ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«ã‚ˆã‚‹å½±éŸ¿<br><br>- åŸºæœ¬çš„ã«å¤§ãã„ã‚µã‚¤ã‚ºã®æ–¹ãŒé«˜ã„correlationã‚’ç¤ºã™ã€‚ç‰¹ã«ã€consistencyã‚„relevanceã¨ã„ã£ãŸã€è¤‡é›‘ãªè©•ä¾¡ã‚¿ã‚¹ã‚¯ã§ã¯ãã®å·®ãŒé¡•è‘—ã§ã‚ã‚‹ã€‚<br><br>- ä¸€æ–¹ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã„æ–¹ãŒæ€§èƒ½ãŒè‰¯ã„è¦³ç‚¹ï¼ˆengagingness, groundednessï¼‰ãªã©ã‚‚å­˜åœ¨ã—ãŸã€‚</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1220" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models Are State-of-the-Art Evaluators of Translation Quality, EAMT'23</a>
<span class="snippet"><span>GPT Summary</span>- GEMBAã¯ã€å‚ç…§ç¿»è¨³ã®æœ‰ç„¡ã«é–¢ä¿‚ãªãä½¿ç”¨ã§ãã‚‹GPTãƒ™ãƒ¼ã‚¹ã®ç¿»è¨³å“è³ªè©•ä¾¡ãƒ¡ãƒˆãƒªãƒƒã‚¯ã§ã™ã€‚ã“ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¯ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã€4ã¤ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒªã‚¢ãƒ³ãƒˆã‚’æ¯”è¼ƒã—ã¾ã™ã€‚ç§ãŸã¡ã®æ‰‹æ³•ã¯ã€GPT 3.5ä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã§ã®ã¿æ©Ÿèƒ½ã—ã€æœ€å…ˆç«¯ã®ç²¾åº¦ã‚’é”æˆã—ã¾ã™ã€‚ç‰¹ã«ã€è‹±èªã‹ã‚‰ãƒ‰ã‚¤ãƒ„èªã€è‹±èªã‹ã‚‰ãƒ­ã‚·ã‚¢èªã€ä¸­å›½èªã‹ã‚‰è‹±èªã®3ã¤ã®è¨€èªãƒšã‚¢ã§æœ‰åŠ¹ã§ã™ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€ã‚³ãƒ¼ãƒ‰ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã€ãŠã‚ˆã³ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°çµæœã‚’å…¬é–‹ã—ã€å¤–éƒ¨ã®æ¤œè¨¼ã¨å†ç¾æ€§ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2023-12-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1194" target="_blank" rel="noopener noreferrer" class="title-link">Gemini: A Family of Highly Capable Multimodal Models, Gemini Team+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®å ±å‘Šæ›¸ã§ã¯ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€ŒGeminiã€ã®ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã«ã¤ã„ã¦ç´¹ä»‹ã—ã¾ã™ã€‚Geminiã¯ç”»åƒã€éŸ³å£°ã€å‹•ç”»ã€ãƒ†ã‚­ã‚¹ãƒˆã®ç†è§£ã«å„ªã‚ŒãŸèƒ½åŠ›ã‚’æŒã¡ã€Ultraã€Proã€Nanoã®ã‚µã‚¤ã‚ºãŒã‚ã‚Šã¾ã™ã€‚Gemini Ultraã¯å¹…åºƒã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®æŠ€è¡“ã‚’æä¾›ã—ã€MMLUã§ã¯äººé–“ã®å°‚é–€å®¶ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åˆã‚ã¦é”æˆã—ã¾ã—ãŸã€‚Geminiãƒ¢ãƒ‡ãƒ«ã¯ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«ãªæ¨è«–ã¨è¨€èªç†è§£ã®èƒ½åŠ›ã‚’æŒã¡ã€ã•ã¾ã–ã¾ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«é©ç”¨ã§ãã¾ã™ã€‚ã¾ãŸã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®è²¬ä»»ã‚ã‚‹å±•é–‹ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1181" target="_blank" rel="noopener noreferrer">Gemini, Google, 2023.12</a>
 ã§ç™ºè¡¨ã•ã‚ŒãŸGeminiã®è«–æ–‡</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2023-12-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1179" target="_blank" rel="noopener noreferrer" class="title-link">The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context  Learning, Bill Yuchen Lin+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆèª¿æ•´ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚ã—ã‹ã—ã€ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆèª¿æ•´ã®åŠ¹æœã¯ã€Œè¡¨é¢çš„ã€ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€åŸºæœ¬çš„ãªLLMã¨ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆèª¿æ•´ã•ã‚ŒãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒˆãƒ¼ã‚¯ãƒ³åˆ†å¸ƒã®ã‚·ãƒ•ãƒˆã‚’åˆ†æã—ã¾ã—ãŸã€‚çµæœã¯ã€ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆèª¿æ•´ãŒä¸»ã«ã‚¹ã‚¿ã‚¤ãƒ«ãƒˆãƒ¼ã‚¯ãƒ³ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ã‚·ãƒ³ãƒ—ãƒ«ã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒªãƒ¼ãªã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆæ‰‹æ³•ã§ã‚ã‚‹URIALã‚’å°å…¥ã—ã€åŸºæœ¬çš„ãªLLMã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã“ã‚Œã‚‰ã®çµæœã‹ã‚‰ã€ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã®ã‚ˆã‚Šæ·±ã„åˆ†æã¨ç†è«–çš„ãªç†è§£ãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã¯Pre-trainingæ™‚ã«ååˆ†ç²å¾—ã•ã‚Œã¦ãŠã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®Alignmentã‚’ã¨ã‚‹ã“ã¨ã§ç”Ÿã˜ã‚‹ã‚‚ã®ã¯è¡¨é¢çš„ãªå¤‰åŒ–ã®ã¿ã§ã‚ã‚‹ã¨ã„ã†ä»®èª¬ãŒã‚ã‚‹ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/700" target="_blank" rel="noopener noreferrer">LIMA: Less Is More for Alignment, Chunting Zhou+, N/A, NeurIPS'23</a>
 ã€‚ã“ã®ä»®èª¬ã«é–¢ã—ã¦åˆ†æã‚’ã—ã€çµæœçš„ã«ã‚¹ã‚¿ã‚¤ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãªæƒ…å ±ã‚’ç”Ÿæˆã™ã‚‹éƒ¨åˆ†ã§Alignmentã®æœ‰ç„¡ã§é•ã„ãŒç”Ÿã˜ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã€ãã†ã§ã‚ã‚Œã°ã‚ã–ã‚ã–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFT, RLHFï¼‰ã—ãªãã¦ã‚‚ã€é©åˆ‡ãªã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠã—ãŸIn-Context Learningã§ã‚‚Alignmentã¨ã‚Œã¾ã™ã‚ˆã€ã¨ã„ã†è¶£æ—¨ã®ç ”ç©¶ã£ã½ã„ï¼Ÿ<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b8c62b33-dd72-43ea-8953-abb5c04cc504" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<span class="issue_date">Issue Date: 2023-12-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1177" target="_blank" rel="noopener noreferrer" class="title-link">Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural  Scrambled Text, Qi Cao+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å†…éƒ¨å‹•ä½œã«ã¤ã„ã¦ã®æ–°ã—ã„æ´å¯Ÿã‚’æä¾›ã—ã¾ã™ã€‚ç‰¹ã«ã€GPT-4ã‚’èª¿æŸ»ã—ã€LLMsã®è€ä¹…æ€§ã«é–¢ã™ã‚‹å®Ÿé¨“çµæœã‚’ç¤ºã—ã¾ã™ã€‚å®Ÿé¨“ã§ã¯ã€æ–‡å­—ãƒ¬ãƒ™ãƒ«ã®é †åˆ—ã«å¯¾ã™ã‚‹LLMsã®è€æ€§ã‚’èª¿ã¹ã‚‹ãŸã‚ã«ã€Scrambled Benchã¨ã„ã†ã‚¹ã‚¤ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¾ã—ãŸã€‚çµæœã¯ã€GPT-4ãŒtypoglycemiaã¨ã„ã†ç¾è±¡ã«ä¼¼ãŸèƒ½åŠ›ã‚’æŒã¡ã€éå¸¸ã«è‡ªç„¶ã§ãªã„ã‚¨ãƒ©ãƒ¼ã‚’å«ã‚€å…¥åŠ›ã‚’ã»ã¼å®Œç’§ã«å‡¦ç†ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯ã€LLMsã®è€æ€§ãŒç›´æ„Ÿã«åã™ã‚‹ã‚‚ã®ã§ã‚ã‚Šã€ä»–ã®LLMsã‚„äººé–“ã«ã¨ã£ã¦ã‚‚å›°é›£ãªã‚¿ã‚¹ã‚¯ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/df33c7a9-005e-4d7e-9d70-d8f0657869ed" alt="image" loading="lazy"></p>
<p>OpenAIã®ãƒ¢ãƒ‡ãƒ«ãŒãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã§ã‚ã‚‹é™ã‚Šã€ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚ã‚‹ã®ã§ã¯ï¼Ÿã¨ã„ã†ç–‘å¿µã¯æŒã£ã¦ã—ã¾ã†ã€‚<br><br>ï¼ˆéƒ¨åˆ†çš„ã«ã—ã‹èª­ã‚ã¦ã„ãªã„ãŒâ€¦ï¼‰<br>RealtimeQAã¨å‘¼ã°ã‚Œã‚‹weeklyã§ç›´è¿‘ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«å¯¾ã™ã‚‹Questionã‚’ç™ºè¡¨ã™ã‚‹ã“ã¨ã§æ§‹ç¯‰ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã†ã¡ã€2023.03.17--2023.08.04ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã€ScrambledSentenaeRecoveryï¼ˆScrRecï¼‰ã¨ScrambleQuestionAnsweringï¼ˆScrQAï¼‰ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/362bcbca-b578-4f0e-ac4e-e65fd216aeac" alt="image" loading="lazy"><br><br>å®Œå…¨ã«ãƒ©ãƒ³ãƒ€ãƒ ã«å˜èªã®æ–‡å­—ã‚’scrambleï¼ˆRSï¼‰ã™ã‚‹ã¨ã€Falconã¨Llama2ã§ã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§ã¯å†æ§‹ç¯‰ã§ããªã„ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚FewShotã§ã¯Falconã§ã‚ã‚Œã°å°‘ã—è§£ã‘ã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚ä¸€æ–¹ã€OpenAIã®ãƒ¢ãƒ‡ãƒ«ã€ç‰¹ã«GPT4, GPT3.5-turboã§ã¯ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§ã‚‚ã«ã‚Šå†æ§‹ç¯‰ãŒã§ãã¦ã„ã‚‹ã€‚<br><br>ScrQAã«ã¤ã„ã¦ã¯ã€ãƒ©ãƒ³ãƒ€ãƒ ã«scrambleã—ãŸå ´åˆã§ã‚‚MultipleChoiceQuestionãªã®ã§ï¼ˆRPGã¨å‘¼ã°ã‚Œã‚‹Accã®ç›¸å¯¾çš„ãªgainã‚’è©•ä¾¡ã™ã‚‹ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ææ¡ˆã—ã¦ã„ã‚‹ï¼‰æ­£è§£ã¯ã§ãã¦ã„ã‚‹ã€‚<br><br>æœ€åˆã®æ–‡å­—ã ã‘ã‚’æ®‹ã™å ´åˆï¼ˆKFï¼‰æœ€åˆã¨æœ€å¾Œã®æ–‡å­—ã‚’æ®‹ã™å ´åˆï¼ˆKFLã€ã«ã¤ã„ã¦ã¯ã€æ®‹ã™æ–‡å­—ãŒå¢—ãˆã‚‹ã»ã©ã©ã¡ã‚‰ã®ã‚¿ã‚¹ã‚¯ã‚‚æ€§èƒ½ãŒä¸ŠãŒã‚Šã€æœ€åˆã®æ–‡å­—ã ã‘ãŒã‚ã‚Œã°OpenSourceLLMã§ã‚‚ï¼ˆã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§ã‚‚ï¼‰ã‹ãªã‚Šå…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã®å†æ§‹ç¯‰ãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã€‚ã¾ãŸã€QAã‚‚æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã€‚</p>
<p>å®Œå…¨ã«ãƒ©ãƒ³ãƒ€ãƒ ã«æ–‡å­—ã‚’å…¥ã‚Œæ›¿ãˆãŸã‚‰å®Œå…¨ã«ç„¡ç†ã‚²ãƒ¼ãªã®ã§ã¯ã€ã€ã€ã€ã¨æ€ã£ã¦ã—ã¾ã†ã®ã ãŒã€Falconã§Fewshotã®å ´åˆã¯ä¸€éƒ¨è§£ã‘ã¦ã„ã‚‹ã‚ˆã†ã â€¦ã€‚æœãŸã—ã¦ã©ã†ã„ã†ã“ã¨ãªã®ã‹â€¦ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ãŒä¿æŒã•ã‚ŒãŸã¾ã¾ãªã®ãŒãƒ’ãƒ³ãƒˆã«ãªã£ã¦ã„ã‚‹â€¦ï¼Ÿï¼‰Appendixã«è€ƒå¯ŸãŒã‚ã‚Šãã†ã ãŒã¾ã èª­ã‚ã¦ã„ãªã„ã€‚<br><br><br><br>ï¼ˆè¿½è¨˜ï¼‰<br><br>æ–‡å…¨ä½“ã§ãƒ©ãƒ³ãƒ€ãƒ ã«æ–‡å­—ã‚’å…¥ã‚Œæ›¿ãˆã¦ã„ã‚‹ã®ã‹ã¨å‹˜é•ã„ã—ã¦ã„ãŸãŒã€å®Ÿéš›ã«ã¯â€ã‚ã‚‹å˜èªã®ä¸­ã ã‘ã§ãƒ©ãƒ³ãƒ€ãƒ ã«å…¥ã‚Œæ›¿ãˆâ€ã ã£ãŸã€‚ã“ã‚Œãªã‚‰åŸç†ä¸Šã¯ã„ã‘ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2023-12-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1174" target="_blank" rel="noopener noreferrer" class="title-link">Pushdown Layers: Encoding Recursive Structure in Transformer Language   Models, Shikhar Murty+, N_A, EMNLP'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å†å¸°æ§‹é€ ã‚’ã†ã¾ãæ‰ãˆã‚‹ãŸã‚ã«æ–°ã—ã„è‡ªå·±æ³¨æ„å±¤ã§ã‚ã‚‹Pushdown Layersã‚’å°å…¥ã—ã¾ã—ãŸã€‚Pushdown Layersã¯ã€å†å¸°çŠ¶æ…‹ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ãŸã‚ã«ã‚¹ã‚¿ãƒƒã‚¯ãƒ†ãƒ¼ãƒ—ã‚’ä½¿ç”¨ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ã®æ¨å®šæ·±åº¦ã‚’è¿½è·¡ã—ã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€æ§‹æ–‡çš„ãªä¸€èˆ¬åŒ–ã‚’æ”¹å–„ã—ã€ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã•ã‚‰ã«ã€Pushdown Layersã¯æ¨™æº–ã®è‡ªå·±æ³¨æ„ã®ä»£æ›¿ã¨ã—ã¦ã‚‚ä½¿ç”¨ã§ãã€GLUEãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡ã‚¿ã‚¹ã‚¯ã§ã‚‚æ”¹å–„ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2023-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1169" target="_blank" rel="noopener noreferrer" class="title-link">SEINE: Short-to-Long Video Diffusion Model for Generative Transition and  Prediction, Xinyuan Chen+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ“ãƒ‡ã‚ªç”Ÿæˆã«ãŠã„ã¦é€£ç¶šã—ãŸé•·ã„ãƒ“ãƒ‡ã‚ªã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ã‚¸ã‚§ãƒãƒ¬ãƒ¼ãƒ†ã‚£ãƒ–ãªãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³ã¨äºˆæ¸¬ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸãƒ¢ãƒ‡ãƒ«SEINEã‚’ææ¡ˆã™ã‚‹ã€‚SEINEã¯ãƒ†ã‚­ã‚¹ãƒˆã®èª¬æ˜ã«åŸºã¥ã„ã¦ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã—ã€ä¸€è²«æ€§ã¨è¦–è¦šçš„å“è³ªã‚’ç¢ºä¿ã—ãŸé•·ã„ãƒ“ãƒ‡ã‚ªã‚’ç”Ÿæˆã™ã‚‹ã€‚ã•ã‚‰ã«ã€ææ¡ˆæ‰‹æ³•ã¯ä»–ã®ã‚¿ã‚¹ã‚¯ã«ã‚‚æ‹¡å¼µå¯èƒ½ã§ã‚ã‚Šã€å¾¹åº•çš„ãªå®Ÿé¨“ã«ã‚ˆã‚Šãã®æœ‰åŠ¹æ€§ãŒæ¤œè¨¼ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>


<a href="https://huggingface.co/spaces/Vchitect/SEINE" target="_blank" rel="noopener noreferrer">https://huggingface.co/spaces/Vchitect/SEINE</a>


<br><br>ç”»åƒ + ãƒ†ã‚­ã‚¹ãƒˆpromptã§ã€å‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹ãƒ‡ãƒ¢</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-11-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1163" target="_blank" rel="noopener noreferrer" class="title-link">Exponentially Faster Language Modelling, Peter Belcak+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- UltraFastBERTã¯ã€æ¨è«–æ™‚ã«ã‚ãšã‹0.3%ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã—ã‹ä½¿ç”¨ã›ãšã€åŒç­‰ã®æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒã§ãã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚UltraFastBERTã¯ã€é«˜é€Ÿãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆFFFï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€åŠ¹ç‡çš„ãªå®Ÿè£…ã‚’æä¾›ã—ã¾ã™ã€‚æœ€é©åŒ–ã•ã‚ŒãŸãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®å®Ÿè£…ã«æ¯”ã¹ã¦78å€ã®é«˜é€ŸåŒ–ã‚’å®Ÿç¾ã—ã€ãƒãƒƒãƒå‡¦ç†ã•ã‚ŒãŸæ¨è«–ã«å¯¾ã—ã¦ã¯40å€ã®é«˜é€ŸåŒ–ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã€ãŠã‚ˆã³ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚‚å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-11-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1158" target="_blank" rel="noopener noreferrer" class="title-link">GAIA: a benchmark for General AI Assistants, GrÃ©goire Mialon+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- GAIAã¯ã€General AI Assistantsã®ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚Šã€AIç ”ç©¶ã®ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚GAIAã¯ã€æ¨è«–ã€ãƒãƒ«ãƒãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®å‡¦ç†ã€ã‚¦ã‚§ãƒ–ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ãªã©ã€å®Ÿä¸–ç•Œã®è³ªå•ã«å¯¾ã™ã‚‹åŸºæœ¬çš„ãªèƒ½åŠ›ã‚’å¿…è¦ã¨ã™ã‚‹ã€‚äººé–“ã®å›ç­”è€…ã¯92ï¼…ã®æ­£ç­”ç‡ã‚’é”æˆã—ã€GPT-4ã¯15ï¼…ã®æ­£ç­”ç‡ã‚’é”æˆã—ãŸã€‚ã“ã‚Œã¯ã€æœ€è¿‘ã®å‚¾å‘ã¨ã¯ç•°ãªã‚‹çµæœã§ã‚ã‚Šã€å°‚é–€çš„ãªã‚¹ã‚­ãƒ«ã‚’å¿…è¦ã¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã¯LLMsãŒäººé–“ã‚’ä¸Šå›ã£ã¦ã„ã‚‹ã€‚GAIAã¯ã€äººé–“ã®å¹³å‡çš„ãªå …ç‰¢æ€§ã¨åŒç­‰ã®èƒ½åŠ›ã‚’æŒã¤ã‚·ã‚¹ãƒ†ãƒ ãŒAGIã®åˆ°æ¥ã«é‡è¦ã§ã‚ã‚‹ã¨è€ƒãˆã¦ã„ã‚‹ã€‚GAIAã®æ‰‹æ³•ã‚’ä½¿ç”¨ã—ã¦ã€466ã®è³ªå•ã¨å›ç­”ã‚’ä½œæˆã—ã€ä¸€éƒ¨ã‚’å…¬é–‹ã—ã¦ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã§åˆ©ç”¨å¯èƒ½ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Yann LeCunæ°ã®ç´¹ä»‹ãƒ„ã‚¤ãƒ¼ãƒˆ<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ylecun/status/1727707519470977311?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Meta-FAIR, Meta-GenAI, HuggingFace, AutoGPTã«ã‚ˆã‚‹ç ”ç©¶ã€‚äººé–“ã¯92%æ­£è§£ã§ãã‚‹ãŒã€GPT4ã§ã‚‚15%ã—ã‹æ­£è§£ã§ããªã„QAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚è§£ããŸã‚ã«æ¨è«–ã‚„ãƒãƒ«ãƒãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®å‡¦ç†ã€ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ã€ãƒ„ãƒ¼ãƒ«ã«å¯¾ã™ã‚‹ç¿’ç†Ÿãªã©ã®åŸºæœ¬çš„ãªèƒ½åŠ›ã‚’å¿…è¦ã¨ã™ã‚‹å®Ÿä¸–ç•Œã®QAã¨ã®ã“ã¨ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0b13838b-0829-48b9-b281-3d09a5a3859f" alt="image" loading="lazy"></span></strong></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1792" target="_blank" rel="noopener noreferrer">Open-source DeepResearch â€“ Freeing our search agents, HuggingFace, 2025.02</a>
<br><br>ã§è¨€åŠã•ã‚Œã¦ã„ã‚‹LLM Agentã®è©•ä¾¡ã§æœ€ã‚‚æœ‰åãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãªæ¨¡æ§˜</p>
<p>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: 


<a href="https://huggingface.co/datasets/gaia-benchmark/GAIA" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/gaia-benchmark/GAIA</a>


</p></strong></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/OptimalTransport.html" target="_blank" rel="noopener noreferrer">#OptimalTransport</a>
<span class="issue_date">Issue Date: 2023-11-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1153" target="_blank" rel="noopener noreferrer" class="title-link">Unbalanced Optimal Transport for Unbalanced Word Alignment, Yuki Arase+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å˜ä¸€è¨€èªã®å˜èªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã«ãŠã„ã¦ã€null alignmentã¨ã„ã†ç¾è±¡ã¯é‡è¦ã§ã‚ã‚Šã€ä¸å‡è¡¡ãªå˜èªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«æœ€é©è¼¸é€ï¼ˆOTï¼‰ã®ãƒ•ã‚¡ãƒŸãƒªãƒ¼ãŒæœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚æ•™å¸«ã‚ã‚Šãƒ»æ•™å¸«ãªã—ã®è¨­å®šã§ã®åŒ…æ‹¬çš„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€OTãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆæ‰‹æ³•ãŒæœ€æ–°ã®æ‰‹æ³•ã¨ç«¶äº‰åŠ›ãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æœ€é©è¼¸é€ã§çˆ†é€Ÿã§ãƒ¢ãƒãƒªãƒ³ã‚¬ãƒ«ã®å˜èªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãŒã¨ã‚Œã‚‹ã‚‰ã—ã„<br>å®Ÿè£…:


<a href="https://github.com/yukiar/OTAlign" target="_blank" rel="noopener noreferrer">https://github.com/yukiar/OTAlign</a>


</p>
<p>å˜èªã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆå…ˆãŒãªã„ï¼ˆnull alignmentï¼‰ã€one-to-oneã®é–¢ä¿‚ã§ã¯ãªãã€one-to-many, many-to-manyã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãŒå¿…è¦ãªå•é¡Œã‚’ï¼ˆãŠãã‚‰ã; ã‚‚ã—ã‹ã—ãŸã‚‰null alignmentã ã‘ã‹ã‚‚ï¼‰Unbalancedãªå˜èªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆå•é¡Œã¨å‘¼ã³ã€ã“ã®èª²é¡Œã«å¯¾ã—ã¦æœ€é©è¼¸é€ãŒæœ‰åŠ¹ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã£ã½ã„<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5e677be2-1001-4454-bc1e-fe3b32888a32" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2023-11-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1152" target="_blank" rel="noopener noreferrer" class="title-link">Igniting Language Intelligence: The Hitchhiker's Guide From  Chain-of-Thought Reasoning to Language Agents, Zhuosheng Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€è¨€èªçŸ¥èƒ½ã®åˆ†é‡ã§åŠ‡çš„ãªé€²æ­©ã‚’é‚ã’ã¦ãŠã‚Šã€è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ç‰¹ã«ã€chain-of-thoughtï¼ˆCoTï¼‰æ¨è«–æŠ€è¡“ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€ä¸­é–“ã‚¹ãƒ†ãƒƒãƒ—ã‚’å½¢æˆã—ã€è§£é‡ˆå¯èƒ½æ€§ã‚„åˆ¶å¾¡å¯èƒ½æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®è«–æ–‡ã§ã¯ã€CoTæŠ€è¡“ã®åŸºæœ¬çš„ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚„ãã®åŠ¹æœã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã€è¨€èªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é–‹ç™ºã«ãŠã‘ã‚‹å¿œç”¨ä¾‹ã‚’ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚å°†æ¥ã®ç ”ç©¶ã®å±•æœ›ã«ã‚‚è§¦ã‚Œã¦ãŠã‚Šã€åˆå¿ƒè€…ã‹ã‚‰çµŒé¨“è±Šå¯Œãªç ”ç©¶è€…ã¾ã§å¹…åºƒã„èª­è€…ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚é–¢é€£è«–æ–‡ã®ãƒªãƒã‚¸ãƒˆãƒªã‚‚æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>CoTã«é–¢ã™ã‚‹ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«è«–æ–‡</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2023-11-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1151" target="_blank" rel="noopener noreferrer" class="title-link">System 2 Attention ï¼ˆis something you might need tooï¼‰, Jason Weston+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Transformerãƒ™ãƒ¼ã‚¹ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã‘ã‚‹ã‚½ãƒ•ãƒˆã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã¯ã€æ–‡è„ˆã‹ã‚‰ç„¡é–¢ä¿‚ãªæƒ…å ±ã‚’å–ã‚Šè¾¼ã‚€å‚¾å‘ãŒã‚ã‚Šã€æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆã«æ‚ªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã€‚ãã“ã§ã€System 2 Attentionï¼ˆS2Aï¼‰ã‚’å°å…¥ã—ã€LLMsãŒè‡ªç„¶è¨€èªã§æ¨è«–ã—ã€æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã‚’æ´»ç”¨ã—ã¦ã€æ³¨ç›®ã™ã¹ãæƒ…å ±ã‚’æ±ºå®šã™ã‚‹ã€‚S2Aã¯é–¢é€£ã™ã‚‹éƒ¨åˆ†ã®ã¿ã‚’å«ã‚€ã‚ˆã†ã«å…¥åŠ›ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å†ç”Ÿæˆã—ã€å†ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æ³¨ç›®ã—ã¦æœ€çµ‚çš„ãªå¿œç­”ã‚’å¼•ãå‡ºã™ã€‚å®Ÿé¨“ã§ã¯ã€S2Aã¯3ã¤ã®ã‚¿ã‚¹ã‚¯ã§æ¨™æº–ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®LLMsã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã€äº‹å®Ÿæ€§ã¨å®¢è¦³æ€§ã‚’é«˜ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãŠãã‚‰ãé‡è¦è«–æ–‡</p>
<p>How is System 2 Attention different from prompt engineering specialized in factual double checks? </p>
<p>I'm very sorry for the extremely delayed response. It's been two years, so you may no longer have a chance to see this, but I'd still like to share my thoughts.<br><br>I believe that System 2 Attention is fundamentally different in concept from prompt engineering techniques such as factual double-checking. Unlike ad-hoc prompt engineering or approaches that enrich the context by adding new facts through prompting, System 2 Attention aims to improve the modelâ€™s reasoning ability itself by mitigating the influence of irrelevant tokens. It does so by selectively generating a new context composed only of relevant tokens, in a way that resembles human System 2 thinkingâ€”that is, more objective and deliberate reasoning.<br><br>From todayâ€™s perspective, two years later, I would say that this concept is more closely aligned with what we now refer to as Context Engineering. Thank you.</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2023-11-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1147" target="_blank" rel="noopener noreferrer" class="title-link">Implicit Chain of Thought Reasoning via Knowledge Distillation, Yuntian Deng+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨ã®éš ã‚ŒçŠ¶æ…‹ã‚’ä½¿ç”¨ã—ã¦æš—é»™çš„ãªæ¨è«–ã‚’è¡Œã†æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚æ˜ç¤ºçš„ãªãƒã‚§ãƒ¼ãƒ³ãƒ»ã‚ªãƒ–ãƒ»ã‚½ãƒ¼ãƒˆã®æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç”Ÿæˆã™ã‚‹ä»£ã‚ã‚Šã«ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æŠ½å‡ºã—ãŸæš—é»™çš„ãªæ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ã“ã®æ‰‹æ³•ãŒä»¥å‰ã¯è§£æ±ºã§ããªã‹ã£ãŸã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ã“ã‚Œã¯éå¸¸ã«èˆˆå‘³æ·±ã„è©±</p>
<p>openreview:


<a href="https://openreview.net/forum?id=9cumTvvlHG" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=9cumTvvlHG</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1144" target="_blank" rel="noopener noreferrer" class="title-link">Contrastive Chain-of-Thought Prompting, Yew Ken Chia+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã€å¯¾ç…§çš„ãªchain of thoughtã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã™ã‚‹ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€æœ‰åŠ¹ãªæ¨è«–ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ç„¡åŠ¹ãªæ¨è«–ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ä¸¡æ–¹ã‚’æä¾›ã—ã€ãƒ¢ãƒ‡ãƒ«ãŒæ¨è«–ã‚’é€²ã‚ã‚‹éš›ã«ãƒŸã‚¹ã‚’æ¸›ã‚‰ã™ã‚ˆã†ã«ã‚¬ã‚¤ãƒ‰ã™ã‚‹ã€‚ã¾ãŸã€è‡ªå‹•çš„ãªæ–¹æ³•ã‚’å°å…¥ã—ã¦å¯¾ç…§çš„ãªãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã—ã€æ±åŒ–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“çµæœã‹ã‚‰ã€å¯¾ç…§çš„ãªchain of thoughtãŒä¸€èˆ¬çš„ãªæ”¹å–„æ‰‹æ³•ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-11-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1138" target="_blank" rel="noopener noreferrer" class="title-link">Fine-tuning Language Models for Factuality, Katherine Tian+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ã‚ˆã‚Šäº‹å®Ÿã«åŸºã¥ã„ãŸç”Ÿæˆã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€å¤–éƒ¨ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚„ä¿¡é ¼ã‚¹ã‚³ã‚¢ã¨ã®ä¸€è²«æ€§ã‚’æ¸¬å®šã—ã€é¸å¥½æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’èª¿æ•´ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€äº‹å®Ÿã‚¨ãƒ©ãƒ¼ç‡ã®å‰Šæ¸›ãŒè¦³å¯Ÿã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<span class="issue_date">Issue Date: 2023-11-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1137" target="_blank" rel="noopener noreferrer" class="title-link">Instruction-Following Evaluation for Large Language Models, Jeffrey Zhou+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€Instruction-Following Evalï¼ˆIFEvalï¼‰ã¨ã„ã†è©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒå°å…¥ã•ã‚Œã¾ã—ãŸã€‚IFEvalã¯ã€æ¤œè¨¼å¯èƒ½ãªæŒ‡ç¤ºã«ç„¦ç‚¹ã‚’å½“ã¦ãŸç›´æ„Ÿçš„ã§å†ç¾æ€§ã®ã‚ã‚‹è©•ä¾¡æ–¹æ³•ã§ã™ã€‚å…·ä½“çš„ã«ã¯ã€25ç¨®é¡ã®æ¤œè¨¼å¯èƒ½ãªæŒ‡ç¤ºã‚’ç‰¹å®šã—ã€ãã‚Œãã‚Œã®æŒ‡ç¤ºã‚’å«ã‚€ç´„500ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚ã“ã®è©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµæœã¯ã€GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMãŒinstructionã«ã©ã‚Œã ã‘å¾“ã†ã‹ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€æ¤œè¨¼å¯èƒ½ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆ400å­—ä»¥ä¸Šã§æ›¸ããªã•ã„ãªã©ï¼‰ã‚’è€ƒæ¡ˆã—è©•ä¾¡ã™ã‚‹æ çµ„ã¿ã‚’ææ¡ˆã€‚äººé–“ãŒè©•ä¾¡ã™ã‚‹ã¨æ™‚é–“ã¨ãŠé‡‘ãŒã‹ã‹ã‚Šã€LLMã‚’åˆ©ç”¨ã—ãŸè‡ªå‹•è©•ä¾¡ã ã¨è©•ä¾¡ã‚’å®Ÿæ–½ã™ã‚‹LLMã®ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã‚‹ã®ã ã€ãã‚Œã‚‰ä¸¡æ–¹ã®limitationã‚’å…‹æœã§ãã‚‹ã¨ã®ã“ã¨ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0eb3fe10-536d-4674-aa3c-fd76f390f21d" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-11-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1135" target="_blank" rel="noopener noreferrer" class="title-link">Fast Chain-of-Thought: A Glance of Future from Parallel Decoding Leads  to Answers Faster, Hongxuan Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®ç ”ç©¶ã§ã¯ã€FastCoTã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚FastCoTã¯ã€LLMã‚’ä½¿ç”¨ã—ã¦ä¸¦åˆ—ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨è‡ªå·±å›å¸°ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’åŒæ™‚ã«è¡Œã„ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’æœ€å¤§é™ã«æ´»ç”¨ã—ã¾ã™ã€‚ã¾ãŸã€FastCoTã¯æ¨è«–æ™‚é–“ã‚’ç´„20%ç¯€ç´„ã—ã€æ€§èƒ½ã®ä½ä¸‹ãŒã»ã¨ã‚“ã©ãªã„ã“ã¨ã‚’å®Ÿé¨“ã§ç¤ºã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ç•°ãªã‚‹ã‚µã‚¤ã‚ºã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«å¯¾ã—ã¦ã‚‚é ‘å¥æ€§ã‚’ç¤ºã™ã“ã¨ãŒã§ãã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>è«–æ–‡ä¸­ã®å›³ã‚’è¦‹ãŸãŒã€å…¨ãã‚ã‹ã‚‰ãªã‹ã£ãŸãƒ»ãƒ»ãƒ»ã€‚ã¡ã‚ƒã‚“ã¨èª­ã¾ãªã„ã¨ã‚ã‹ã‚‰ãªãã†ã§ã‚ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LayoutGeneration.html" target="_blank" rel="noopener noreferrer">#LayoutGeneration</a>
<span class="issue_date">Issue Date: 2023-11-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1133" target="_blank" rel="noopener noreferrer" class="title-link">LayoutPrompter: Awaken the Design Ability of Large Language Models, Jiawei Lin+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- LayoutPrompterã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦æ¡ä»¶ä»˜ãã®ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆç”Ÿæˆã‚’è¡Œã†æ‰‹æ³•ã§ã‚ã‚Šã€å…¥åŠ›-å‡ºåŠ›ã®ã‚·ãƒªã‚¢ãƒ«åŒ–ã€å‹•çš„ãªæ¨¡ç¯„çš„é¸æŠã€ãŠã‚ˆã³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®3ã¤ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚LayoutPrompterã¯ã€æ—¢å­˜ã®æ‰‹æ³•ã¨ç«¶åˆã—ãŸã‚Šä¸Šå›ã£ãŸã‚Šã™ã‚‹æ€§èƒ½ã‚’æŒã¡ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„å¾®èª¿æ•´ãªã—ã§ä½¿ç”¨ã§ãã‚‹æ±ç”¨æ€§ã®ã‚ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ã“ã¨ãŒå®Ÿé¨“çµæœã‹ã‚‰ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ã«ã‚‚å„ªã‚Œã¦ãŠã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚ˆã‚Šã‚‚æœ‰æ„ã«å„ªã‚Œã¦ã„ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€https://github.com/microsoft/LayoutGeneration/tree/main/LayoutPrompterã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Conditional Graphic Layout Generation</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-11-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1132" target="_blank" rel="noopener noreferrer" class="title-link">Cappy: Outperforming and Boosting Large Multi-Task LMs with a Small   Scorer, Bowen Tan+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ãƒãƒ«ãƒã‚¿ã‚¹ã‚­ãƒ³ã‚°ã«å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ãŒã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤šãè¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’å¿…è¦ã¨ã—ã€åŠ¹ç‡çš„ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ãã“ã§ã€å°è¦æ¨¡ãªã‚¹ã‚³ã‚¢ãƒ©ãƒ¼ã§ã‚ã‚‹Cappyã‚’å°å…¥ã—ã€ç‹¬ç«‹ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã‹LLMsã®è£œåŠ©ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã¾ã—ãŸã€‚Cappyã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’å¿…è¦ã¨ã›ãšã€ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã§é«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€Cappyã¯ç‹¬ç«‹ã—ãŸã‚¿ã‚¹ã‚¯ã‚„è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã§å¤§ããªLLMsã‚’ä¸Šå›ã‚Šã€ä»–ã®LLMsã¨ã®é€£æºã‚‚å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>360Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã§LLMã«å‹ã¤ã£ã½ã„ã®ã§ãŠã‚‚ã—ã‚ãã†ã ã—å®Ÿç”¨æ€§ã‚‚ã‚ã‚Šãã†</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultitaskLearning.html" target="_blank" rel="noopener noreferrer">#MultitaskLearning</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<span class="issue_date">Issue Date: 2023-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1127" target="_blank" rel="noopener noreferrer" class="title-link">Florence-2: Advancing a Unified Representation for a Variety of Vision  Tasks, Bin Xiao+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Florence-2ã¯ã€ãƒ“ã‚¸ãƒ§ãƒ³åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ã•ã¾ã–ã¾ãªãƒ“ã‚¸ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã™ã‚‹ãŸã‚ã®çµ±ä¸€ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ™ãƒ¼ã‚¹ã®è¡¨ç¾ã‚’æŒã£ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å—ã‘å–ã‚Šã€ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡ºã€ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã€ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãªã©ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã€ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§çµæœã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã¾ãŸã€FLD-5Bã¨ã„ã†å¤§è¦æ¨¡ãªæ³¨é‡ˆä»˜ããƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚é–‹ç™ºã•ã‚Œã¾ã—ãŸã€‚Florence-2ã¯ã€å¤šç›®çš„ã‹ã¤åŒ…æ‹¬çš„ãªãƒ“ã‚¸ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã«ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ„ãƒ¼ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ§‹é€ ã‚’æ¡ç”¨ã—ã¦ãŠã‚Šã€å‰ä¾‹ã®ãªã„ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆãŠã‚ˆã³ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®èƒ½åŠ›ã‚’æŒã¤å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Vison Foundation Modelã€‚Spatialãªéšå±¤æ§‹é€ ã‚„ã€Semanticã‚’æ‰ãˆã‚‰ã‚Œã‚‹ã‚ˆã†ã«è¨“ç·´ã€‚Image/Prompt Encoderã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã€outputã¯text + location informationã¨ãªã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9fbfba62-190f-46eb-a893-5ebe76dda030" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/f7497161-6b9a-4adc-aa6b-53debe1e9318" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2023-11-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1123" target="_blank" rel="noopener noreferrer" class="title-link">A Survey on Hallucination in Large Language Models: Principles,  Taxonomy, Challenges, and Open Questions, Lei Huang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®å‡ºç¾ã¯NLPã«ãŠã‘ã‚‹é‡è¦ãªé€²æ­©ã‚’ã‚‚ãŸã‚‰ã—ã¦ã„ã‚‹ãŒã€å¹»è¦šã‚’ç”Ÿã˜ã‚‹ã“ã¨ãŒã‚ã‚Šã€ãã®ä¿¡é ¼æ€§ã«æ‡¸å¿µãŒã‚ã‚‹ã€‚æœ¬èª¿æŸ»ã§ã¯ã€LLMã®å¹»è¦šã«é–¢ã™ã‚‹æœ€è¿‘ã®é€²å±•ã«ã¤ã„ã¦åŒ…æ‹¬çš„ã«æ¦‚èª¬ã—ã€å¹»è¦šã®è¦å› ã‚„æ¤œå‡ºæ‰‹æ³•ã€è»½æ¸›ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã¤ã„ã¦ç´¹ä»‹ã™ã‚‹ã€‚ã¾ãŸã€ç¾åœ¨ã®åˆ¶ç´„ã‚„å°†æ¥ã®ç ”ç©¶æ–¹å‘ã«ã¤ã„ã¦ã‚‚åˆ†æã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Hallucinationã‚’ç¾è±¡ã”ã¨ã«åˆ†é¡ã—ãŸSurveyã¨ã—ã¦ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1048" target="_blank" rel="noopener noreferrer">A Survey of Hallucination in Large Foundation Models, Vipula Rawte+, N/A, arXiv'23</a>
 ã‚‚ã‚ã‚‹</p>
<p>Surveyã®å†…å®¹ã€‚å¿…è¦ã«å¿œã˜ã¦å‚ç…§ã™ã¹ã—ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/32d8d809-e197-4289-8000-12fee76a69cf" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2023-11-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1121" target="_blank" rel="noopener noreferrer" class="title-link">Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs, Qingru Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- PASTAã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸå¼·èª¿ãƒãƒ¼ã‚¯ã®ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã‚€ã“ã¨ã‚’å¯èƒ½ã«ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚PASTAã¯ã€æ³¨æ„ã®ä¸€éƒ¨ã‚’ç‰¹å®šã—ã€å†é‡ã¿ä»˜ã‘ã‚’é©ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®æ³¨æ„ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸéƒ¨åˆ†ã«å‘ã‘ã¾ã™ã€‚å®Ÿé¨“ã§ã¯ã€PASTAãŒLLMã®æ€§èƒ½ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ¦ãƒ¼ã‚¶ãŒpromptä¸­ã§å¼·èª¿ã—ãŸã„ã—ãŸéƒ¨åˆ†ãŒã‚ˆã‚Šè€ƒæ…®ã•ã‚Œã‚‹ã‚ˆã†ã«attention weightã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šå¿œç­”æ€§èƒ½ãŒå‘ä¸Šã—ã¾ã—ãŸã¨ã„ã†è©±ã£ã½ã„ã€‚ã‹ãªã‚Šé‡è¦ãªæŠ€è¡“ã ã¨æ€ã‚ã‚Œã‚‹ã€‚å¾Œã§ã—ã£ã‹ã‚Šèª­ã‚€ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a4d3714e-7279-495c-86f1-5ff4ed2cbeb8" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-11-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1120" target="_blank" rel="noopener noreferrer" class="title-link">Do LLMs exhibit human-like response biases? A case study in survey  design, Lindia Tjuatja+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã‚’ä½¿ç”¨ã—ã¦äººé–“ã®ä»£ç†ã¨ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹éš›ã«ã€LLMsãŒäººé–“ã®å¿œç­”ãƒã‚¤ã‚¢ã‚¹ã‚’ã©ã®ç¨‹åº¦åæ˜ ã™ã‚‹ã‹ã‚’èª¿æŸ»ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€èª¿æŸ»è¨­è¨ˆã‚’ä½¿ç”¨ã—ã¦äººé–“ã®å¿œç­”ãƒã‚¤ã‚¢ã‚¹ã‚’è©•ä¾¡ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’è¨­è¨ˆã—ã€9ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ãŸçµæœã€ä¸€èˆ¬çš„ãªLLMsãŒäººé–“ã®ã‚ˆã†ãªæŒ¯ã‚‹èˆã„ã‚’åæ˜ ã™ã‚‹ã“ã¨ã«å¤±æ•—ã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã‚Œã‚‰ã®çµæœã¯ã€LLMsã‚’äººé–“ã®ä»£ã‚ã‚Šã«ä½¿ç”¨ã™ã‚‹éš›ã®æ½œåœ¨çš„ãªè½ã¨ã—ç©´ã‚’å¼·èª¿ã—ã€ãƒ¢ãƒ‡ãƒ«ã®æŒ¯ã‚‹èˆã„ã®ç´°ã‹ã„ç‰¹æ€§ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã¯Promptã«sensitiveã ãŒã€äººé–“ã‚‚è³ªå•ã®ä»•æ–¹ã«ã‚ˆã£ã¦å¿œç­”ãŒå¤‰ã‚ã‚‹ã‹ã‚‰ã€sensitiveãªã®ã¯ä¸€ç·’ã§ã¯ï¼Ÿã¨ã„ã†ã“ã¨ã‚’èª¿æŸ»ã—ãŸç ”ç©¶ã€‚Neubigæ°ã®ãƒ„ã‚¤ãƒ¼ãƒˆã ã¨ã€instruction tuningã‚„RLHFã‚’ã—ã¦ã„ãªã„Base LLMã®æ–¹ãŒã€ã‚ˆã‚Šäººé–“ã¨é¡ä¼¼ã—ãŸå›ç­”ã‚’ã™ã‚‹ã®ã ãã†ã€‚<br><br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1722294711355117666?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span></strong></p>
<p>äººé–“ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒã‚¤ã‚¢ã‚¹ã€‚å·¦å´ã¯äººé–“ã¯ã€Œforbiddenã€ã‚ˆã‚Šã‚‚ã€Œnot allowedã€ã‚’å¥½ã‚€ã¨ã„ã†ä¾‹ã€å³å´ã¯ã€Œresponse orderã€ã®ãƒã‚¤ã‚¢ã‚¹ã®ä¾‹ï¼ˆé¸æŠè‚¢ã®é †ç•ªï¼‰ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/de129e78-5d52-41e3-a3bb-9aec20cf2b05" alt="image" loading="lazy"><br><br><br><br>LLMå´ã§è©•ä¾¡ã—ãŸã„ãƒã‚¤ã‚¢ã‚¹ã”ã¨ã«ã€QAã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å¤‰æ›´ã—ã€LLMã«å›ç­”ã‚’ç”Ÿæˆã•ã‚Œã€social science studiesã§ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã¨æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ã€LLMã«ã‚‚äººé–“ã¨åŒæ§˜ã®ãƒã‚¤ã‚¢ã‚¹ãŒã‚ã‚‹ã‹ã‚’æ˜ã‚‰ã‹ã«ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3dc39afc-4e52-49a4-bf60-22ff94bf35c6" alt="image" loading="lazy"><br><br><br><br>çµæœã¯ä»¥ä¸‹ã®è¡¨ã§ã‚ã‚Šã€é’ã„ã‚»ãƒ«ãŒäººé–“ã¨åŒæ§˜ã®ãƒã‚¤ã‚¢ã‚¹ã‚’æŒã¤ã“ã¨ã‚’çµ±è¨ˆçš„ã«æœ‰æ„ã«ç¤ºã•ã‚ŒãŸã‚‚ã®ï¼ˆã®ã¯ãšï¼‰ã€‚ã“ã‚Œã‚’ã¿ã‚‹ã¨ã€å…¨ã¦ã®ãƒã‚¤ã‚¢ã‚¹ã«å¯¾ã—ã¦äººé–“ã¨åŒæ§˜ã®å‚¾å‘ãŒã‚ã£ãŸã®ã¯Llama2-70Bã®ã¿ã§ã‚ã‚Šã€instruction tuningã‚„ã€RLHFã‚’ã‹ã‘ãŸå ´åˆï¼ˆRLHFã®æ–¹ãŒå½±éŸ¿ãŒå¤§ããã†ï¼‰äººé–“ã®ãƒã‚¤ã‚¢ã‚¹ã¨ã¯ç•°ãªã‚‹æŒ™å‹•ã‚’ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒå¤šããªã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚ã¾ãŸã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¨ãƒã‚¤ã‚¢ã‚¹ã®å¼·ã•ã«ã¯ç›¸é–¢é–¢ä¿‚ã¯è¦‹å—ã‘ã‚‰ã‚Œãªã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7d8eade0-ae3a-4d62-bb2d-160971542c39" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2023-11-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1117" target="_blank" rel="noopener noreferrer" class="title-link">Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in  Transformer Models, Steve Yadlowsky+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã®æ–‡è„ˆå­¦ç¿’ï¼ˆICLï¼‰èƒ½åŠ›ã‚’èª¿æŸ»ã—ã¾ã—ãŸã€‚ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã¯ã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²å†…ã§ç•°ãªã‚‹ã‚¿ã‚¹ã‚¯ã‚’ç‰¹å®šã—ã€å­¦ç¿’ã™ã‚‹èƒ½åŠ›ã‚’æŒã£ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²å¤–ã®ã‚¿ã‚¹ã‚¯ã‚„é–¢æ•°ã«å¯¾ã—ã¦ã¯ä¸€èˆ¬åŒ–ãŒåŠ£åŒ–ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã¾ãŸã€é«˜å®¹é‡ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ICLèƒ½åŠ›ã¯ã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²ã«å¯†æ¥ã«é–¢é€£ã—ã¦ã„ã‚‹ã“ã¨ãŒå¼·èª¿ã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>TransformerãŒpre-trainingæ™‚ã«åˆ©ç”¨ã•ã‚ŒãŸå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä»¥å¤–ã®åˆ†å¸ƒã«å¯¾ã—ã¦ã¯æ±åŒ–æ€§èƒ½ãŒè½ã¡ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã‚‰ã—ã„ã€‚ã‚‚ã—ã“ã‚ŒãŒæ­£ã—ã„ã¨ã™ã‚‹ã¨ã€çµå±€çœŸã«æ–°ã—ã„åˆ†å¸ƒã¨ã„ã†ã‹é–¢æ•°ã¨ã„ã†ã‹ã‚¿ã‚¹ã‚¯ã¨ã„ã†ã‹ã€ã‚’TransformerãŒå‰µå‡ºã™ã‚‹å¯èƒ½æ€§ã¯ä½ã„ã¨è¨€ãˆã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚ãŒã€æ–°ã—ã„ã‚‚ã®ã£ã¦å¤§ä½“ã¯æ—¢å­˜ã®æ¦‚å¿µã®çµ„ã¿åˆã‚ã›ã ã‚ˆã­ï¼ˆã‚¹ãƒãƒ›ã¨ã‹ï¼‰ã€ã¿ãŸã„ãªã“ã¨ã‚’è€ƒãˆã‚‹ã¨ã€åˆ¥ã«ãã‚Œã§ã‚‚ååˆ†ã§ã¯ï¼Ÿã¨æ€ã£ã¦ã—ã¾ã†ã€‚äººé–“ãŒæœ¬å½“ã«çœŸã®æ„å‘³ã§æ–°ã—ã„é–¢æ•°ã¨ã„ã†ã‹ã‚¿ã‚¹ã‚¯ã¨ã„ã†ã‹åˆ†å¸ƒã‚’ç”Ÿã¿å‡ºã›ã¦ã„ã‚‹ã‹ã¨ã„ã†ã¨ã€å®Ÿã¯ãã‚“ãªã«å¤šããªã„ã®ã§ã¯ï¼Ÿã¨ã„ã†äºˆæ„Ÿã‚‚ã™ã‚‹ã€‚ã¾ã‚ãŸã¨ãˆã°ã€é‡å­åŠ›å­¦ã‚’æœ€åˆã«è€ƒãˆã¾ã—ãŸï¼ã¨ã‹ãã†ã„ã†ã®ã¯ä¾‹å¤–ã ã¨æ€ã†ã‘ã©ãƒ»ãƒ»ãƒ»ã€ãã®ãƒ¬ãƒ™ãƒ«ã®ã“ã¨ã£ã¦ã©ã‚“ãã‚‰ã„ã‚ã‚‹ã‚“ã ã‚ã†ã­ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2023-11-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1116" target="_blank" rel="noopener noreferrer" class="title-link">The Perils &amp; Promises of Fact-checking with Large Language Models, Dorian Quelle+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå¾‹å‹ã®äº‹å®Ÿãƒã‚§ãƒƒã‚¯ã«ãŠã„ã¦ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ã€‚LLMsã¯çœŸå®Ÿã¨è™šå½ã‚’è¦‹åˆ†ã‘ã‚‹å½¹å‰²ã‚’æœãŸã—ã€ãã®å‡ºåŠ›ã‚’æ¤œè¨¼ã™ã‚‹èƒ½åŠ›ãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦äº‹å®Ÿãƒã‚§ãƒƒã‚¯ã‚’è¡Œã„ã€æ¨è«–ã‚’èª¬æ˜ã—ã€é–¢é€£ã™ã‚‹æƒ…å ±æºã‚’å¼•ç”¨ã™ã‚‹èƒ½åŠ›ã‚’è©•ä¾¡ã—ãŸã€‚çµæœã¯ã€æ–‡è„ˆæƒ…å ±ã‚’å‚™ãˆãŸLLMsã®èƒ½åŠ›ã®å‘ä¸Šã‚’ç¤ºã—ã¦ã„ã‚‹ãŒã€æ­£ç¢ºæ€§ã«ã¯ä¸€è²«æ€§ãŒãªã„ã“ã¨ã«æ³¨æ„ãŒå¿…è¦ã§ã‚ã‚‹ã€‚ä»Šå¾Œã®ç ”ç©¶ã§ã¯ã€æˆåŠŸã¨å¤±æ•—ã®è¦å› ã‚’ã‚ˆã‚Šæ·±ãç†è§£ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>gpt3ã¨gpt4ã§FactCheckã—ã¦å‚¾å‘ã‚’åˆ†æã—ã¾ã—ãŸã€ã¨ã„ã†ç ”ç©¶ã€‚promptã«statementã¨googleã§è£œå®Œã—ãŸcontextã‚’å«ã‚ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§FactCheckã™ã‚‹ã€‚<br>promptingã™ã‚‹éš›ã®è¨€èªã‚„ã€statementã®äº‹å®Ÿæ€§ã®åº¦åˆã„ï¼ˆåŠåˆ†true, å…¨ã¦falseç­‰ï¼‰ãªã©ã§ã€æ€§èƒ½ãŒå¤§ããå¤‰ã‚ã‚‹çµæœã¨ã®ã“ã¨ã€‚<br>æ€§èƒ½ã‚’è¦‹ã‚‹ã¨ã€ã¾ã ã¾ã ï¼ˆã“ã®promptingæ–¹æ³•ã§ã¯ï¼‰äººé–“ã®ä»£ã‚ã‚ŠãŒå‹™ã¾ã‚‹ã»ã©ã®æ€§èƒ½ãŒå‡ºã¦ã„ãªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚ã¾ãŸã€trueãªæƒ…å ±ã®FactCheckã«contextã¯åŠ¹ã„ã¦ã„ãã†ã ãŒã€falseã®æƒ…å ±ã®FactCheckã«ContextãŒã‚ã¾ã‚ŠåŠ¹ã„ã¦ãªã•ãã†ã«è¦‹ãˆã‚‹ã®ã§ã€ãªã‚“ã ã‹ãªã‚ã€ã¨ã„ã†æ„Ÿã˜ã§ã‚ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1f310edd-58f3-4e45-ac40-e75337bff884" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e6901a32-af7a-472c-9790-d3784fa577ce" alt="image" loading="lazy"></p>
<p>æ–œã‚èª­ã¿ã—ã‹ã—ã¦ã„ãªã„ãŒã“ã®ç ”ç©¶ã€å­¦è¡“çš„ãªçŸ¥è¦‹ã¯å°‘ãªã„ã®ã‹ãªã€ã¨ã„ã†å°è±¡ã€‚ä¸€ã¤ã®ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã ã‚ˆã­ã€ã¨ã„ã†æ„Ÿã˜ãŒã™ã‚‹ã€‚<br><br>ã¾ãšã€GPT3,4ã ã‘ã˜ã‚ƒãªãã€ç‰¹å¾´ã®ç•°ãªã‚‹OpenSourceã®LLMã‚’æ¯”è¼ƒã«å«ã‚ã¦ãã‚Œãªã„ã¨ã€å‰è€…ã¯ä½•ã§å­¦ç¿’ã—ã¦ã„ã‚‹ã‹åˆ†ã‹ã‚‰ãªã„ã®ã§ã€å­¦è¡“çš„ã«å¾—ã‚‰ã‚Œã‚‹çŸ¥è¦‹ã¯ã»ã¼ãªã„ã®ã§ã¯ã¨ã„ã†æ°—ãŒã€‚å®Ÿå‹™çš„ã«ã¯å½¹ã«ç«‹ã¤ãŒã€‚<br><br>ãã®ä¸Šã§ã€Promptingã‚’ã‚‚ã£ã¨ã•ã¾ã–ã¾ãªæ–¹æ³•ã§æ¤œè¨¼ã—ãŸæ–¹ãŒè‰¯ã„ã¨æ€ã†ã€‚<br>ãŸã¨ãˆã°ã€ç¾åœ¨ã®promptã§ã¯ãƒ©ãƒ™ãƒ«ã‚’å…ˆã«å‡ºåŠ›ã•ã›ãŸå¾Œã«ç†ç”±ã‚’è¿°ã¹ã•ã›ã¦ã„ã‚‹ãŒã€ãã‚Œã‚’é€†ã«ã—ãŸã‚‰ã©ã†ãªã‚‹ã‹ï¼Ÿï¼ˆzero-shot CoTï¼‰ã‚„ã€4-Shotã«ã—ãŸã‚‰ã©ã†ãªã‚‹ã‹ã€SelfConsistencyã‚’åˆ©ç”¨ã—ãŸã‚‰ã©ã†ãªã‚‹ã‹ãªã©ã€promptingã®ä»•æ–¹ã«ã‚ˆã£ã¦å‚¾å‘ãŒå¤§ããå¤‰ã‚ã‚‹ã¨æ€ã†ã€‚<br><br>åŠ ãˆã¦ã€Retrieveréƒ¨åˆ†ã‚‚ã„ãã¤ã‹ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã§è©¦ã—ã¦ã¿ã¦ã‚‚è‰¯ã„ã®ã‹ãªã¨æ€ã†ã€‚ç‰¹ã«ã€falseã®æƒ…å ±ã‚’åˆ¤æ–­ã™ã‚‹éš›ã«å½¹ã«ç«‹ã¤æƒ…å ±ãŒcontextã«å«ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã®ã‹ãŒæ°—ã«ãªã‚‹ã€‚<br>è«–æ–‡ã«æ›¸ã„ã¦ã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãŒã€ã¡ã‚‡ã£ã¨ã—ã£ã‹ã‚Šèª­ã‚€æ™‚é–“ã¯ãªã„ã§ã™ï¼ï¼</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1104" target="_blank" rel="noopener noreferrer" class="title-link">Llemma: An Open Language Model For Mathematics, Zhangir Azerbayev+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€æ•°å­¦ã®ãŸã‚ã®å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹Llemmaã‚’ææ¡ˆã—ã¾ã™ã€‚Llemmaã¯ã€Proof-Pile-2ã¨å‘¼ã°ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦äº‹å‰å­¦ç¿’ã•ã‚Œã€MATHãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€Llemmaã¯è¿½åŠ ã®fine-tuningãªã—ã§ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨ã‚„å½¢å¼çš„ãªå®šç†è¨¼æ˜ãŒå¯èƒ½ã§ã™ã€‚ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚‚å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>CodeLLaMAã‚’200B tokenã®æ•°å­¦ãƒ†ã‚­ã‚¹ãƒˆï¼ˆproof-pile-2ãƒ‡ãƒ¼ã‚¿;è«–æ–‡ã€æ•°å­¦ã‚’å«ã‚€ã‚¦ã‚§ãƒ–ãƒ†ã‚­ã‚¹ãƒˆã€æ•°å­¦ã®ã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ï¼‰ã§ç¶™ç¶šçš„ã«äº‹å‰å­¦ç¿’ã™ã‚‹ã“ã¨ã§foundation modelã‚’æ§‹ç¯‰<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/87f9bbe1-3377-4e80-a7d4-904345ebb7d9" alt="image" loading="lazy"><br><br>ç´„åŠåˆ†ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§æ•°å­¦ã«é–¢ã™ã‚‹æ€§èƒ½ã§Googleã®Minervaã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆ<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5d209059-2275-415a-8b8d-f73f46712ba6" alt="image" loading="lazy"></p>
<p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhangir_azerbay/status/1714098823080063181"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã¾ã 4-shotã—ã¦ã‚‚Acc.50%ãã‚‰ã„ãªã®ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1102" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models are not Fair Evaluators, Peiyi Wang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€å€™è£œãƒ¢ãƒ‡ãƒ«ã®å¿œç­”å“è³ªã‚’è©•ä¾¡ã™ã‚‹è©•ä¾¡ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã«ãŠã‘ã‚‹ç³»çµ±çš„ãªãƒã‚¤ã‚¢ã‚¹ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€ãƒã‚¤ã‚¢ã‚¹ã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€å®Ÿé¨“ã«ã‚ˆã£ã¦ãã®æœ‰åŠ¹æ€§ã‚’ç¤ºã—ã¾ã™ã€‚ã¾ãŸã€ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã—ã¦ã€ä»Šå¾Œã®ç ”ç©¶ã‚’æ”¯æ´ã—ã¾ã™ã€‚</span>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/DataGeneration.html" target="_blank" rel="noopener noreferrer">#DataGeneration</a>
<span class="issue_date">Issue Date: 2023-10-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1099" target="_blank" rel="noopener noreferrer" class="title-link">Zephyr: Direct Distillation of LM Alignment, Lewis Tunstall+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€å°ã•ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ãŸã‚ã«ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å„ªå…ˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã«ã‚ˆã‚Šã€è‡ªç„¶ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®å¿œç­”ãŒæ”¹å–„ã•ã‚Œã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã‚’ç”¨ã„ã¦å­¦ç¿’ã•ã‚ŒãŸZephyr-7Bãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒãƒ£ãƒƒãƒˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ç™ºæ®ã—ã€äººé–“ã®æ³¨é‡ˆã‚’å¿…è¦ã¨ã—ã¾ã›ã‚“ã€‚è©³ç´°ã¯GitHubã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>7Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§LlaMa70Bã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã—ãŸZephyrã®è«–æ–‡ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1348b3c1-f70a-49b6-97c9-4a27bf7805fa" alt="image" loading="lazy"><br><br>- dSFT:æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰promptã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€user,assistantã®multi turnã®å¯¾è©±ã‚’LLMã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã—SFT<br>- AIF:æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰promstã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ç•°ãªã‚‹4ã¤ã®LLMã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’GPT4ã§ãƒ©ãƒ³ã‚¯ã¥ã‘ã—ãŸãƒ‡ãƒ¼ã‚¿ã®æ´»ç”¨<br>- dDPO: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰promptã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ãƒ™ã‚¹ãƒˆãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¨ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æ´»ç”¨<br><br>äººæ‰‹ã‚’ä¸€åˆ‡ä»‹ã—ã¦ã„ãªã„ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/f2cd7b48-4036-49eb-bfb7-0ce3cc8a09b8" alt="image" loading="lazy"></p>
<p>Blog: 


<a href="https://huggingface.co/blog/Isamu136/understanding-zephyr" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/Isamu136/understanding-zephyr</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-10-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1098" target="_blank" rel="noopener noreferrer" class="title-link">Human Feedback is not Gold Standard, Tom Hosking+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½è©•ä¾¡ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãŒã€ãã®å¥½ã¿ã®ã‚¹ã‚³ã‚¢ãŒã©ã®ç‰¹æ€§ã‚’æ‰ãˆã¦ã„ã‚‹ã®ã‹ã¯æ˜ç¢ºã§ã¯ãªã„ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ä½¿ç”¨ã‚’åˆ†æã—ã€é‡è¦ãªã‚¨ãƒ©ãƒ¼åŸºæº–ã‚’é©åˆ‡ã«æ‰ãˆã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’æ¤œè¨¼ã—ãŸã€‚çµæœã¨ã—ã¦ã€å¥½ã¿ã®ã‚¹ã‚³ã‚¢ã¯åºƒç¯„ãªã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’æŒã£ã¦ã„ã‚‹ãŒã€äº‹å®Ÿæ€§ãªã©ã®é‡è¦ãªå´é¢ãŒéå°è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã¾ãŸã€å¥½ã¿ã®ã‚¹ã‚³ã‚¢ã¨ã‚¨ãƒ©ãƒ¼ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯äº¤çµ¡å› å­ã®å½±éŸ¿ã‚’å—ã‘ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã€å‡ºåŠ›ã®æ–­å®šæ€§ãŒäº‹å®Ÿæ€§ã‚¨ãƒ©ãƒ¼ã®çŸ¥è¦šç‡ã‚’æ­ªã‚ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚ã•ã‚‰ã«ã€äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨“ç·´ç›®æ¨™ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã€ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã®æ–­å®šæ€§ã‚’éåº¦ã«å¢—åŠ ã•ã›ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚ä»Šå¾Œã®ç ”ç©¶ã§ã¯ã€å¥½ã¿ã®ã‚¹ã‚³ã‚¢ãŒæœ›ã¾ã—ã„ç›®æ¨™ã¨ä¸€è‡´ã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’æ…é‡ã«è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/icoxfog417/status/1718151338520199180?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3824b322-53fa-4360-a7d4-1b0f3bff3302" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OCR.html" target="_blank" rel="noopener noreferrer">#OCR</a>
<span class="issue_date">Issue Date: 2023-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1093" target="_blank" rel="noopener noreferrer" class="title-link">Exploring OCR Capabilities of GPT-4Vï¼ˆisionï¼‰ : A Quantitative and  In-depth Evaluation, Yongxin Shi+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€GPT-4Vã¨ã„ã†å¤§è¦æ¨¡ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®å…‰å­¦æ–‡å­—èªè­˜ï¼ˆOCRï¼‰èƒ½åŠ›ã‚’è©•ä¾¡ã—ã¾ã™ã€‚ã•ã¾ã–ã¾ãªOCRã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã—ã€ãƒ©ãƒ†ãƒ³æ–‡å­—ã®èªè­˜ã¨ç†è§£ã«ãŠã„ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ä¸€æ–¹ã€å¤šè¨€èªã‚„è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«ã¯è‹¦æˆ¦ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ã“ã‚Œã«åŸºã¥ã„ã¦ã€å°‚é–€ã®OCRãƒ¢ãƒ‡ãƒ«ã®å¿…è¦æ€§ã‚„GPT-4Vã‚’æ´»ç”¨ã™ã‚‹æˆ¦ç•¥ã«ã¤ã„ã¦ã‚‚æ¤œè¨ã—ã¾ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€å°†æ¥ã®LMMã‚’ç”¨ã„ãŸOCRã®ç ”ç©¶ã«å½¹ç«‹ã¤ã‚‚ã®ã§ã™ã€‚è©•ä¾¡ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨çµæœã¯ã€GitHubã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>GPT4-Vã‚’ã•ã¾ã–ã¾ãªOCRã‚¿ã‚¹ã‚¯ã€Œæ‰‹æ›¸ãã€æ•°å¼ã€ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ èªè­˜ç­‰ã‚’å«ã‚€ï¼‰ã§æ€§èƒ½æ¤œè¨¼ã—ãŸç ”ç©¶ã€‚<br>MLT19ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ãŸè©•ä¾¡ã§ã¯ã€æ—¥æœ¬èªã®æ€§èƒ½ã¯éå¸¸ã«ä½ãã€è‹±èªã¨ãƒ•ãƒ©ãƒ³ã‚¹èªãŒæ€§èƒ½é«˜ã„ã€‚æ‰‹æ›¸ãæ–‡å­—èªè­˜ã§ã¯è‹±èªã¨ä¸­å›½èªã§ã®ã¿è©•ä¾¡ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c433b921-c527-441f-8925-00f4ac5fc6c3" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/InstructionGeneration.html" target="_blank" rel="noopener noreferrer">#InstructionGeneration</a>
<span class="issue_date">Issue Date: 2023-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1092" target="_blank" rel="noopener noreferrer" class="title-link">Auto-Instruct: Automatic Instruction Generation and Ranking for  Black-Box Language Models, Zhihan Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æ–°ã—ã„æ‰‹æ³•ã§ã‚ã‚‹Auto-Instructã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã§ã¯ã€LLMsãŒç”Ÿæˆã™ã‚‹æŒ‡ç¤ºã®å“è³ªã‚’è‡ªå‹•çš„ã«å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€å¤šæ§˜ãªå€™è£œã®æŒ‡ç¤ºã‚’ç”Ÿæˆã—ã€ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã§ãƒ©ãƒ³ã‚¯ä»˜ã‘ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€Auto-InstructãŒäººé–“ã«ã‚ˆã‚‹æŒ‡ç¤ºã‚„æ—¢å­˜ã®LLMç”ŸæˆæŒ‡ç¤ºã‚’ä¸Šå›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€ä»–ã®LLMsã§ã‚‚é¡•è‘—ãªæ±åŒ–æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ã‚‚ç¢ºèªã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>seed instructionã¨demonstrationã«åŸºã¥ã„ã¦ã€ç•°ãªã‚‹ã‚¹ã‚¿ã‚¤ãƒ«ã®instructionã‚’è‡ªå‹•ç”Ÿæˆã—ã€è‡ªå‹•ç”Ÿæˆã—ãŸinstructionã‚’ã¨inferenceã—ãŸã„exampleã§æ¡ä»¶ã¥ã‘ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã—ã€è‰¯è³ªãªã‚‚ã®ã‚’é¸æŠã€‚é¸æŠã—ãŸinstructionã§inferenceã‚’å®Ÿæ–½ã™ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3b318cac-516d-4fc8-9097-ad695ab8223b" alt="image" loading="lazy"></p>
<p>æ—¢å­˜æ‰‹æ³•ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’é”æˆã—ã¦ã„ã‚‹ã€‚ç‰¹ã«exampleã”ã¨ã«instructionã‚’é¸æŠã™ã‚‹æ‰‹æ³•ã®ä¸­ã§æœ€ã‚‚gainãŒé«˜ã„ã€‚ã“ã‚Œã¯ã€ææ¡ˆæ‰‹æ³•ãŒinstructionã®é¸æŠã«trained modelã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã§ã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8e2c8bad-54ec-49e8-b6e0-29bc18425e99" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2023-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1091" target="_blank" rel="noopener noreferrer" class="title-link">NEFTune: Noisy Embeddings Improve Instruction Finetuning, Neel Jain+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã€ãƒã‚¤ã‚ºã‚’åŠ ãˆãŸåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½¿ç”¨ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ã€AlpacaEvalã‚„Evol-Instructãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€RLHFã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«ã‚‚é©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Alpacaãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½å‘ä¸ŠãŒè‘—ã—ã„ã€‚ã‹ãªã‚Šé‡è¦è«–æ–‡ãªäºˆæ„Ÿã€‚å¾Œã§èª­ã‚€ã€‚</p>
<p>HuggingFaceã®TRLã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹<br><br>


<a href="https://huggingface.co/docs/trl/sft_trainer" target="_blank" rel="noopener noreferrer">https://huggingface.co/docs/trl/sft_trainer</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2023-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1090" target="_blank" rel="noopener noreferrer" class="title-link">In-Context Learning Creates Task Vectors, Roee Hendel+, N_A, EMNLP'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã‘ã‚‹ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã®åŸºæœ¬çš„ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã¯ã¾ã ååˆ†ã«ç†è§£ã•ã‚Œã¦ã„ãªã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ICLã«ã‚ˆã£ã¦å­¦ç¿’ã•ã‚Œã‚‹é–¢æ•°ãŒéå¸¸ã«å˜ç´”ãªæ§‹é€ ã‚’æŒã¤ã“ã¨ã‚’ç¤ºã—ã€ICLãŒãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼LLMã‚’ä½¿ç”¨ã—ã¦å˜ä¸€ã®ã‚¿ã‚¹ã‚¯ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã€ãã‚Œã‚’ä½¿ç”¨ã—ã¦å‡ºåŠ›ã‚’ç”Ÿæˆã™ã‚‹ã¨ã„ã†ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚ã•ã¾ã–ã¾ãªãƒ¢ãƒ‡ãƒ«ã¨ã‚¿ã‚¹ã‚¯ã«ã‚ãŸã‚‹å®Ÿé¨“ã«ã‚ˆã£ã¦ã€ã“ã®ä¸»å¼µã‚’æ”¯æŒã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1717302086587875395?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ICLãŒå®Ÿç¾å¯èƒ½ãªã®ã¯å®Ÿã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å†…éƒ¨ã§ä¸ãˆã‚‰ã‚ŒãŸdemonstrationã«å¯¾ã—ã¦å‹¾é…åŠ¹æœæ³•ã‚’å†ç¾ã—ã¦ã„ã‚‹ã‹ã‚‰ã§ã™ã€ã¨ã„ã†ç ”ç©¶ã‚‚ã‚ã£ãŸã¨æ€ã†ã‘ã©ã€ã“ã®ã‚¿ã‚¹ã‚¯ãƒ™ã‚¯ãƒˆãƒ«ã¨ã®é–¢ä¿‚æ€§ã¯ã©ã†ã„ã†ã‚‚ã®ãªã®ã ã‚ã†ã‹ã€‚</p>
<p>æ–‡è„ˆã«æ³¨æ„ã‚’ä¸ãˆãªãã¦ã‚‚ICLã¨åŒã˜æ€§èƒ½ãŒå‡ºã‚‹ã®ã¯ã€æ–‡è„ˆæƒ…å ±ãŒä¸è¦ãªã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã‹ã‚‰ã§ã‚ã‚Šã€ãã†ã§ã¯ãªã„ã‚¿ã‚¹ã‚¯ã ã¨ã“ã®çŸ¥è¦‹ãŒå´©ã‚Œã‚‹ã®ã ã‚ã†ã‹ã€‚å¾Œã§èª­ã‚€ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-10-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1088" target="_blank" rel="noopener noreferrer" class="title-link">Branch-Solve-Merge Improves Large Language Model Evaluation and  Generation, Swarnadeep Saha+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤šé¢çš„ãªè¨€èªç”ŸæˆãŠã‚ˆã³è©•ä¾¡ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ­ã‚°ãƒ©ãƒ ï¼ˆBSMï¼‰ã‚’ææ¡ˆã—ã¾ã™ã€‚BSMã¯ã€ãƒ–ãƒ©ãƒ³ãƒã€ã‚½ãƒ«ãƒ–ã€ãƒãƒ¼ã‚¸ã®3ã¤ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰æ§‹æˆã•ã‚Œã€ã‚¿ã‚¹ã‚¯ã‚’è¤‡æ•°ã®ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«åˆ†è§£ã—ã€ç‹¬ç«‹ã—ã¦è§£æ±ºã—ã€è§£æ±ºç­–ã‚’çµ±åˆã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€BSMãŒè©•ä¾¡ã®æ­£ç¢ºæ€§ã¨ä¸€è²«æ€§ã‚’å‘ä¸Šã•ã›ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2023-10-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1086" target="_blank" rel="noopener noreferrer" class="title-link">Personalized Soups: Personalized Large Language Model Alignment via  Post-hoc Parameter Merging, Joel Jang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Reinforcement Learning from Human Feedback (RLHF) is not optimal for learning diverse individual perspectives, as it aligns general aggregated human preferences with large language models (LLMs). This study investigates the problem of Reinforcement Learning from Individual Human Feedback (RLPHF) and models the alignment with LLMs to multiple (sometimes conflicting) preferences as a Multi-Objective Reinforcement Learning (MORL) problem. It demonstrates that individual alignment can be achieved by decomposing preferences into multiple dimensions based on personalized declarations. The study shows that these dimensions can be efficiently trained independently and distributed, and effectively combined in post-processing through parameter merging. The code is available at https://github.com/joeljang/RLPHF.</span>
<span class="snippet"><span>Comment</span><p>ã©ã“ã¾ã§ã®ã“ã¨ãŒå®Ÿç¾ã§ãã‚‹ã®ã‹ãŒæ°—ã«ãªã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-10-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1085" target="_blank" rel="noopener noreferrer" class="title-link">Eliminating Reasoning via Inferring with Planning: A New Framework to  Guide LLMs' Non-linear Thinking, Yongqi Tong+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«éç·šå½¢ã®æ€è€ƒã‚’ä¿ƒã™ãŸã‚ã«ã€æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æ–¹æ³•ã§ã‚ã‚‹Inferential Exclusion Promptingï¼ˆIEPï¼‰ã‚’ææ¡ˆã™ã‚‹ã€‚IEPã¯ã€è¨ˆç”»ã‚’ç«‹ã¦ã¦å¯èƒ½ãªè§£ã‚’æ¨è«–ã—ã€é€†æ¨è«–ã‚’è¡Œã†ã“ã¨ã§åºƒã„è¦–ç‚¹ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚IEPã¯ä»–ã®æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦è¤‡é›‘ãªäººé–“ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã§ãã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã—ã€LLMsã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã«ã‚‚è²¢çŒ®ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã•ã‚‰ã«ã€Mental-Ability Reasoning Benchmarkï¼ˆMARBï¼‰ã‚’å°å…¥ã—ã€LLMsã®è«–ç†ã¨è¨€èªæ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ãŸã€‚IEPã¨MARBã¯LLMsã®ç ”ç©¶ã«ãŠã„ã¦æœ‰æœ›ãªæ–¹å‘æ€§ã§ã‚ã‚Šã€ä»Šå¾Œã®é€²å±•ãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒè«–æ–‡ã¯èª­ã‚“ã§ã„ãªã„ã®ã ãŒã€CoTãŒç·šå½¢çš„ã ã¨ã„ã†ä¸»å¼µãŒã‚ˆãã‚ã‹ã‚‰ãªã„ã€‚<br>CoTã¯Autoregressiveãªè¨€èªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªå·±ç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã§åˆ©ç”¨è€…ã®æ„å›³ã—ãŸæ–¹å‘æ€§ã«ãƒã‚¤ã‚¢ã‚¹ã‚’ã‹ã‘ã¦è£œå®Œã•ã›ã€<br>åˆ©ç”¨è€…ãŒæ„å›³ã—ãŸé€šã‚Šã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’æœ€çµ‚çš„ã«å¾—ã‚‹ãŸã‚ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã€ã ã¨æ€ã£ã¦ã„ã¦ã€<br>ç·šå½¢çš„ã ã‚ã†ãŒéç·šå½¢çš„ã ã‚ã†ãŒã©ã£ã¡ã«ã—ã‚CoTãªã®ã§ã¯ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-10-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1078" target="_blank" rel="noopener noreferrer" class="title-link">Meta-CoT: Generalizable Chain-of-Thought Prompting in Mixed-task  Scenarios with Large Language Models, Anni Zou+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€æ¨è«–ã®ãŸã‚ã®ãƒã‚§ãƒ¼ãƒ³ãƒ»ã‚ªãƒ–ãƒ»ã‚½ãƒ¼ãƒˆï¼ˆCoTï¼‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚å¾“æ¥ã®CoTã®æ–¹æ³•ã§ã¯ã€ä¸€èˆ¬çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„æ‰‹ä½œæ¥­ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ä¾å­˜ã—ã¦ã„ã¾ã—ãŸãŒã€æœ¬ç ”ç©¶ã§ã¯å…¥åŠ›è³ªå•ã®ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦è‡ªå‹•çš„ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹Meta-CoTã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚Meta-CoTã¯ã€10ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¨è«–ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€SVAMPã§ã¯æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã¾ã—ãŸã€‚ã¾ãŸã€åˆ†å¸ƒå¤–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚å®‰å®šæ€§ã¨æ±ç”¨æ€§ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>è‰²ã€…å‡ºã¦ããŸãŒãªã‚“ã‹ã‚‚ã†è‰²ã€…çµ„ã¿åˆã‚ã›ã‚Œã°æœ€å¼·ãªã‚“ã˜ã‚ƒã­?ã£ã¦æ°—ãŒã—ã¦ããŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/bb51c119-c1bc-4033-a7d4-f403d3c82d30" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1c450a01-5cd6-4af3-af76-323e8c8d3769" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-10-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1077" target="_blank" rel="noopener noreferrer" class="title-link">Survey on Factuality in Large Language Models: Knowledge, Retrieval and  Domain-Specificity, Cunxiang Wang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®äº‹å®Ÿæ€§ã®å•é¡Œã«å–ã‚Šçµ„ã‚“ã§ã„ã¾ã™ã€‚LLMsã®å‡ºåŠ›ã®ä¿¡é ¼æ€§ã¨æ­£ç¢ºæ€§ã¯é‡è¦ã§ã‚ã‚Šã€äº‹å®Ÿã«çŸ›ç›¾ã—ãŸæƒ…å ±ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€ãã®å•é¡Œã‚’è§£æ±ºã™ã‚‹æ–¹æ³•ã‚’æ¢æ±‚ã—ã¦ã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€LLMsã®äº‹å®Ÿçš„ãªã‚¨ãƒ©ãƒ¼ã®å½±éŸ¿ã‚„åŸå› ã‚’åˆ†æã—ã€äº‹å®Ÿæ€§ã‚’è©•ä¾¡ã™ã‚‹æ‰‹æ³•ã‚„æ”¹å–„ç­–ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ã®LLMsã¨å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã™ã‚‹æ¤œç´¢æ‹¡å¼µå‹LLMsã«ç„¦ç‚¹ã‚’å½“ã¦ã€ãã‚Œãã‚Œã®èª²é¡Œã¨æ”¹å–„ç­–ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ã„ã¾ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€LLMsã®äº‹å®Ÿçš„ãªä¿¡é ¼æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®ã‚¬ã‚¤ãƒ‰ã¨ãªã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4d3ab4df-aaa0-460f-b16a-6114432336cd" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-10-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1076" target="_blank" rel="noopener noreferrer" class="title-link">Take a Step Back: Evoking Reasoning via Abstraction in Large Language  Models, Huaixiu Steven Zheng+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Step-Back Promptingã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦æ¨è«–ã®æ‰‹é †ã‚’ã‚¬ã‚¤ãƒ‰ã™ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æŠ€è¡“ã§ã™ã€‚ã“ã®æŠ€è¡“ã«ã‚ˆã‚Šã€LLMsã¯å…·ä½“çš„ãªè©³ç´°ã‹ã‚‰é«˜ãƒ¬ãƒ™ãƒ«ã®æ¦‚å¿µã‚„åŸºæœ¬åŸå‰‡ã‚’æŠ½è±¡åŒ–ã—ã€æ­£ã—ã„æ¨è«–çµŒè·¯ã‚’ãŸã©ã‚‹èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€Step-Back Promptingã¯STEMã€Knowledge QAã€Multi-Hop Reasoningãªã©ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦å¤§å¹…ãªæ€§èƒ½å‘ä¸ŠãŒè¦³å¯Ÿã•ã‚Œã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€MMLU Physics and Chemistryã§7%ã€11%ã€TimeQAã§27%ã€MuSiQueã§7%ã®æ€§èƒ½å‘ä¸ŠãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ã¾ãŸæ–°ã—ã„ã®ãŒå‡ºãŸ</p>
<p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/aac94123-7c39-4938-889f-feb5cff9317c" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a793ff97-3d5c-4707-9ec6-3884b143182b" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2023-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1074" target="_blank" rel="noopener noreferrer" class="title-link">RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective  Augmentation, Fangyuan Xu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚æŠ½å‡ºå‹ã®åœ§ç¸®å™¨ã¨æŠ½è±¡å‹ã®åœ§ç¸®å™¨ã‚’ä½¿ç”¨ã—ã€LMsã®å…¥åŠ›ã«è¦ç´„ã‚’è¿½åŠ ã—ã¦è¨“ç·´ã™ã‚‹ã€‚å®Ÿé¨“çµæœã§ã¯ã€åœ§ç¸®ç‡ãŒ6ï¼…ã¾ã§é”æˆã•ã‚Œã€å¸‚è²©ã®è¦ç´„ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€è¨“ç·´ã•ã‚ŒãŸåœ§ç¸®å™¨ã¯ä»–ã®LMsã«ã‚‚è»¢ç§»å¯èƒ½ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Retrieval Augmentationã‚’ã™ã‚‹éš›ã«ã€å…ƒæ–‡æ›¸ç¾¤ã‚’è¦ç´„ã—ã¦åœ§ç¸®ã™ã‚‹ã“ã¨ã§ã€æ€§èƒ½ä½ä¸‹ã‚’æŠ‘ãˆãªãŒã‚‰æœ€å¤§6%ç¨‹åº¦ã¾ã§å…ƒæ–‡æ›¸ç¾¤ã‚’åœ§ç¸®ã§ããŸã€ã¨ã®ã“ã¨ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2756ba98-d228-45e6-972d-ef239d4b990e" alt="image" loading="lazy"></p>
<p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1711384213092479130?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Retrieval Augmentationã‚’å°å…¥ã™ã‚‹éš›ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ã«æœ‰ç”¨ãã†</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1070" target="_blank" rel="noopener noreferrer" class="title-link">Retrieval meets Long Context Large Language Models, Peng Xu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ€å…ˆç«¯ã®äº‹å‰å­¦ç¿’æ¸ˆã¿LLMsã‚’ä½¿ç”¨ã—ã¦ã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ«æ‹¡å¼µã¨é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®çµ„ã¿åˆã‚ã›ã«ã¤ã„ã¦ç ”ç©¶ã—ã¾ã—ãŸã€‚çµæœã¨ã—ã¦ã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ«æ‹¡å¼µLLMsã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°LLMsã¨æ¯”è¼ƒã—ã¦ã‚‚é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€è¨ˆç®—é‡ã‚‚å°‘ãªã„ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ã¯LLMsã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ãƒªãƒˆãƒªãƒ¼ãƒãƒ«æ‹¡å¼µLLMsã¯ã€è³ªå•å¿œç­”ã‚„è¦ç´„ãªã©ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã€ç”Ÿæˆé€Ÿåº¦ã‚‚é€Ÿã„ã§ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€å®Ÿè·µè€…ã«ã¨ã£ã¦ãƒªãƒˆãƒªãƒ¼ãƒãƒ«æ‹¡å¼µã¨é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®LLMsã®é¸æŠã«é–¢ã™ã‚‹æ´å¯Ÿã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1711502993508671670?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ¤œç´¢è£œå¼·ï¼ˆRetrieval Augmentationï¼‰ã¨ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã‚’è£œå®Œã™ã‚‹ãŸã‚ã«ã€é–¢é€£ã™ã‚‹æ–‡æ›¸ã‚’å¤–éƒ¨ã®æ–‡æ›¸é›†åˆã‹ã‚‰ã¨ã£ã¦ãã¦ã€contextã«å«ã‚ã‚‹æŠ€è¡“ã®ã“ã¨<br><br>


<a href="https://tech.acesinc.co.jp/entry/2023/03/31/121001" target="_blank" rel="noopener noreferrer">https://tech.acesinc.co.jp/entry/2023/03/31/121001</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1069" target="_blank" rel="noopener noreferrer" class="title-link">RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities  of Large Language Models, Zekun Moore Wang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦å½¹å‰²æ¼”æŠ€ã®èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹RoleLLMã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚RoleLLMã¯ã€å½¹å‰²ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹ç¯‰ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®æŒ‡ç¤ºç”Ÿæˆã€å½¹å‰²ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã‚‹è©±ã—æ–¹ã®æ¨¡å€£ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã¨å½¹å‰²ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã®4ã¤ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€RoleBenchã¨å‘¼ã°ã‚Œã‚‹å½¹å‰²æ¼”æŠ€ã®ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€RoleLLaMAã¨RoleGLMã¨ã„ã†ãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å½¹å‰²æ¼”æŠ€ã®èƒ½åŠ›ãŒå¤§å¹…ã«å‘ä¸Šã—ã€GPT-4ã¨åŒç­‰ã®çµæœã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p># Overview<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4a4f8ad3-17d1-4a85-b553-6452371e2ccf" alt="image" loading="lazy"><br><br># RoleBench<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a197648f-ee30-4e1d-9b3b-188c29671df4" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/AutoML.html" target="_blank" rel="noopener noreferrer">#AutoML</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1067" target="_blank" rel="noopener noreferrer" class="title-link">Benchmarking Large Language Models As AI Research Agents, Qian Huang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€AIç ”ç©¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã—ã€ç§‘å­¦çš„ãªå®Ÿé¨“ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦MLAgentBenchã‚’ææ¡ˆã™ã‚‹ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿æ›¸ãã‚„ã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡Œãªã©ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã€å®Ÿé¨“ã‚’å®Ÿè¡Œã—ã€çµæœã‚’åˆ†æã—ã€æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ã‚³ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚GPT-4ãƒ™ãƒ¼ã‚¹ã®ç ”ç©¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯å¤šãã®ã‚¿ã‚¹ã‚¯ã§é«˜æ€§èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿç¾ã§ãã‚‹ãŒã€æˆåŠŸç‡ã¯ç•°ãªã‚‹ã€‚ã¾ãŸã€LLMãƒ™ãƒ¼ã‚¹ã®ç ”ç©¶ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã¯ã„ãã¤ã‹ã®èª²é¡ŒãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>GPT4ãŒMLãƒ¢ãƒ‡ãƒ«ã‚’ã©ã‚Œã ã‘è‡ªå‹•çš„ã«æ§‹ç¯‰ã§ãã‚‹ã‹ã‚’èª¿ã¹ãŸæ¨¡æ§˜ã€‚ã¾ãŸã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ãŸæ¨¡æ§˜ã€‚çµæœã¨ã—ã¦ã¯ã€æ—¢å­˜ã®æœ‰åãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®æˆåŠŸç‡ã¯90%ç¨‹åº¦ã§ã‚ã‚Šã€æœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ï¼ˆæ–°ãŸãªKaggle Challengeç­‰ï¼‰ã§ã¯30%ç¨‹åº¦ã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ReversalCurse.html" target="_blank" rel="noopener noreferrer">#ReversalCurse</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1059" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A", Lukas Berglund+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±å›å¸°å‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€ã€ŒAã¯Bã§ã‚ã‚‹ã€ã¨ã„ã†æ–‡ã‹ã‚‰ã€ŒBã¯Aã§ã‚ã‚‹ã€ã¨é€†ã®é–¢ä¿‚ã‚’è‡ªå‹•çš„ã«ä¸€èˆ¬åŒ–ã§ããªã„ã€Œé€†è»¢ã®å‘ªã„ã€ã‚’ç¤ºã™ã€‚ä¾‹ãˆã°ã€ãƒ¢ãƒ‡ãƒ«ãŒã€Œãƒ¯ãƒ¬ãƒ³ãƒ†ã‚£ãƒŠãƒ»ãƒ†ãƒ¬ã‚·ã‚³ãƒ¯ã¯å®‡å®™ã«è¡Œã£ãŸæœ€åˆã®å¥³æ€§ã§ã‚ã‚‹ã€ã¨è¨“ç·´ã•ã‚Œã¦ã‚‚ã€ã€Œå®‡å®™ã«è¡Œã£ãŸæœ€åˆã®å¥³æ€§ã¯èª°ã‹ï¼Ÿã€ã«æ­£ã—ãç­”ãˆã‚‰ã‚Œãªã„ã€‚å®Ÿé¨“ã§ã¯ã€æ¶ç©ºã®æ–‡ã‚’ç”¨ã„ã¦GPT-3ã¨Llama-1ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€é€†è»¢ã®å‘ªã„ã®å­˜åœ¨ã‚’ç¢ºèªã€‚ChatGPTï¼ˆGPT-3.5ãŠã‚ˆã³GPT-4ï¼‰ã§ã‚‚ã€å®Ÿåœ¨ã®æœ‰åäººã«é–¢ã™ã‚‹è³ªå•ã§æ­£ç­”ç‡ã«å¤§ããªå·®ãŒè¦‹ã‚‰ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>A is Bã¨ã„ã†æ–‡ã§LLMã‚’è¨“ç·´ã—ã¦ã‚‚ã€B is Aã¨ã„ã†é€†æ–¹å‘ã«ã¯æ±åŒ–ã•ã‚Œãªã„ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br>è‘—è€…ãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/owainevans_uk/status/1705285631520407821?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/25e20dcc-0313-4cd2-8768-afb0e4e48a68" alt="image" loading="lazy"><br><p>GPT3, LLaMaã‚’ A is Bã§finetuneã—ã€B is Aã¨ã„ã†é€†æ–¹å‘ã®factã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«ï¼ˆè³ªå•ã‚’ã—ã¦ï¼‰ãƒ†ã‚¹ãƒˆã—ãŸã¨ã“ã‚ã€0%ä»˜è¿‘ã®Acc.ã ã£ãŸã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d089eb94-6872-40b5-89a1-7532758e1d89" alt="image" loading="lazy"><br><br>ã¾ãŸã€Acc.ãŒä½ã„ã ã‘ã§ãªãã€å¯¾æ•°å°¤åº¦ã‚‚randomãªfactã‚’ç”Ÿæˆã—ãŸå ´åˆã¨ã€ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§å·®ãŒãªã„ã“ã¨ãŒã‚ã‹ã£ãŸã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ba10fff4-cfdc-4e52-8217-c59247209211" alt="image" loading="lazy"><br><br>ã“ã®ã“ã¨ã‚‰ã€Reversal Curseã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§ã¯è§£æ±ºã§ããªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1923" target="_blank" rel="noopener noreferrer">Physics of Language Models: Part 3.1, Knowledge Storage and Extraction, Zeyuan Allen-Zhu+, ICML'24</a>
</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1056" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models as Analogical Reasoners, Michihiro Yasunaga+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’è‡ªå‹•çš„ã«ã‚¬ã‚¤ãƒ‰ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æ‰‹æ³•ã§ã‚ã‚‹ã‚¢ãƒŠãƒ­ã‚¸ã‚«ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ã€é–¢é€£ã™ã‚‹éå»ã®çµŒé¨“ã‚’å¼•ç”¨ã—ã¦æ–°ã—ã„å•é¡Œã«å–ã‚Šçµ„ã‚€èªçŸ¥ãƒ—ãƒ­ã‚»ã‚¹ã«å€£ã„ã€å•é¡Œã‚’è§£æ±ºã™ã‚‹å‰ã«æ–‡è„ˆå†…ã§é–¢é€£ã™ã‚‹ä¾‹ç¤ºã‚„çŸ¥è­˜ã‚’è‡ªå·±ç”Ÿæˆã•ã›ã‚‹ã‚ˆã†ã«è¨€èªãƒ¢ãƒ‡ãƒ«ã«ä¿ƒã—ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ã€ä¾‹ç¤ºã®ãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚„æ¤œç´¢ã®å¿…è¦æ€§ã‚’æ’é™¤ã—ã€ä¸€èˆ¬æ€§ã¨é©å¿œæ€§ã‚’æä¾›ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ã“ã®æ‰‹æ³•ãŒã•ã¾ã–ã¾ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã§ä»–ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹ã€è‘—è€…ãƒ„ã‚¤ãƒ¼ãƒˆã®ã–ã£ãã‚Šç¿»è¨³: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/michiyasunaga/status/1709582150025240854?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>äººé–“ã¯æ–°ã—ã„å•é¡Œã«å–ã‚Šçµ„ã‚€æ™‚ã€éå»ã«è§£ã„ãŸé¡ç¾©ã®å•é¡Œã‚’æŒ¯ã‚Šè¿”ã‚Šã€ãã®çµŒé¨“ã‚’æ´»ç”¨ã™ã‚‹ã€‚ã“ã‚Œã‚’LLMä¸Šã§å®Ÿè·µã§ããªã„ã‹?ã¨ã„ã†ã®ãŒã‚¢ã‚¤ãƒ‡ã‚¢ã€‚<br>Analogical Promptingã§ã¯ã€å•é¡Œã‚’è§£ãå‰ã«ã€é©åˆ‡ãªexamplarã‚’è‡ªå‹•ç”Ÿæˆï¼ˆproblemã¨solutionï¼‰ã•ã›ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã€‚<br><br>ã“ã‚Œã«ã‚ˆã‚Šã€examplarã¯è‡ªå·±ç”Ÿæˆã•ã‚Œã‚‹ãŸã‚ã€æ—¢å­˜ã®CoTã§å¿…è¦ãªexamplarã®ãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚„æ¤œç´¢ãŒä¸è¦ã¨ãªã‚‹ã“ã¨ã¨ã€è§£ã“ã†ã¨ã—ã¦ã„ã‚‹å•é¡Œã«åˆã‚ã›ã¦examplarã‚’èª¿æ•´ã—ã€æ¨è«–ã«å¯¾ã—ã¦ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’æä¾›ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã¨ãªã‚‹ã€‚<br><br>å®Ÿé¨“ã®çµæœã€æ•°å­¦ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã€BIG-Benchã§zero-shot CoTã€few-shot CoTã‚’ä¸Šå›ã£ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8aae5d9d-d8d8-4c86-b55f-0fcde5d5381c" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8544d7e2-bae3-4a1e-a867-ab655785c725" alt="image" loading="lazy"><p>LLMãŒçŸ¥ã£ã¦ãŠã‚Šã€ã‹ã¤å¾—æ„ãªå•é¡Œã«å¯¾ã—ã¦ãªã‚‰ã†ã¾ãåƒããã†ã€‚ä¸€æ–¹ã§ã€LLMãŒè‹¦æ‰‹ãªå•é¡Œãªã©ã¯äººæ‰‹ä½œæˆã—ãŸexamplarã§few-shotã—ãŸæ–¹ãŒï¼ˆã‚ã‚‹ç¨‹åº¦ï¼‰ã†ã¾ãã„ããã†ãªäºˆæ„ŸãŒã™ã‚‹ã€‚ã†ã¾ãã„ããã†ã¨è¨€ã£ã¦ã‚‚ã€ãã‚‚ãã‚‚LLMãŒè‹¦æ‰‹ãªå•é¡Œãªã®ã§few-shotã—ãŸç¨‹åº¦ã§ã¯ç„¼çŸ³ã«æ°´ã ã¨ã¯æ€ã†ãŒã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/NumericReasoning.html" target="_blank" rel="noopener noreferrer">#NumericReasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1050" target="_blank" rel="noopener noreferrer" class="title-link">MAmmoTH: Building Math Generalist Models through Hybrid Instruction  Tuning, Xiang Yue+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- MAmmoTHã¯ã€æ•°å­¦ã®å•é¡Œè§£æ±ºã«ç‰¹åŒ–ã—ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€å³å¯†ã«ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸæ•™è‚²ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€CoTã¨PoTã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãªæ ¹æ‹ ã‚’æä¾›ã—ã€ã•ã¾ã–ã¾ãªæ•°å­¦ã®åˆ†é‡ã‚’åŒ…æ‹¬çš„ã«ã‚«ãƒãƒ¼ã—ã¦ã„ã¾ã™ã€‚MAmmoTHã¯ã€æ—¢å­˜ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€ç‰¹ã«MATHãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§é«˜ã„ç²¾åº¦ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€å¤šæ§˜ãªå•é¡Œã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã¨ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãªæ ¹æ‹ ã®ä½¿ç”¨ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>9ã¤ã®math reasoningãŒå¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§13-29%ã®gainã§SoTAã‚’é”æˆã€‚<br>260kã®æ ¹æ‹ æƒ…å ±ã‚’å«ã‚€Math Instructãƒ‡ãƒ¼ã‚¿ã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã€‚<br><br>project page: 


<a href="https://tiger-ai-lab.github.io/MAmmoTH/" target="_blank" rel="noopener noreferrer">https://tiger-ai-lab.github.io/MAmmoTH/</a>


</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1048" target="_blank" rel="noopener noreferrer" class="title-link">A Survey of Hallucination in Large Foundation Models, Vipula Rawte+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡ãƒ•ã‚¡ã‚¦ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆLFMsï¼‰ã«ãŠã‘ã‚‹ãƒ›ãƒ¼ãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã®å•é¡Œã«ç„¦ç‚¹ã‚’å½“ã¦ã€ãã®ç¾è±¡ã‚’åˆ†é¡ã—ã€è©•ä¾¡åŸºæº–ã‚’ç¢ºç«‹ã™ã‚‹ã¨ã¨ã‚‚ã«ã€æ—¢å­˜ã®æˆ¦ç•¥ã‚’æ¤œè¨ã—ã€ä»Šå¾Œã®ç ”ç©¶ã®æ–¹å‘æ€§ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Hallucinationã‚’ç¾è±¡ã”ã¨ã«åˆ†é¡ã—ã€Hallucinationã®ç¨‹åº¦ã®è©•ä¾¡ã‚’ã™ã‚‹æŒ‡æ¨™ã‚„ã€Hallucinationã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®æ—¢å­˜æ‰‹æ³•ã«ã¤ã„ã¦ã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã‚‰ã—ã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ec507609-5b6d-42ed-92db-296856f93200" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/General.html" target="_blank" rel="noopener noreferrer">#General</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1047" target="_blank" rel="noopener noreferrer" class="title-link">RAIN: Your Language Models Can Align Themselves without Finetuning, Yuhui Li+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¿½åŠ ã®ãƒ‡ãƒ¼ã‚¿ãªã—ã§å‡çµã•ã‚ŒãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’æ•´åˆ—ã•ã›ã‚‹æ–¹æ³•ã‚’æ¢æ±‚ã—ã¾ã—ãŸã€‚è‡ªå·±è©•ä¾¡ã¨å·»ãæˆ»ã—ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§ã€LLMsã¯è‡ªå·±ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã‚’é€šã˜ã¦äººé–“ã®å¥½ã¿ã¨ä¸€è‡´ã™ã‚‹å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚RAINã¨ã„ã†æ–°ã—ã„æ¨è«–æ‰‹æ³•ã‚’å°å…¥ã—ã€è¿½åŠ ã®ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ›´æ–°ã‚’å¿…è¦ã¨ã›ãšã«AIã®å®‰å…¨æ€§ã‚’ç¢ºä¿ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€RAINã®åŠ¹æœã‚’ç¤ºã—ã¦ãŠã‚Šã€LLaMA 30Bãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ç„¡å®³ç‡ã‚’å‘ä¸Šã•ã›ã€Vicuna 33Bãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯æ”»æ’ƒæˆåŠŸç‡ã‚’æ¸›å°‘ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒˆãƒ¼ã‚¯ãƒ³ã®setã§æ§‹æˆã•ã‚Œã‚‹treeä¸Šã‚’æ¢ç´¢ã—ã€å‡ºåŠ›ãŒç„¡å®³ã¨self-evaluationã•ã‚Œã‚‹ã¾ã§ã€å·»ãæˆ»ã—ã¨å‰æ–¹ç”Ÿæˆã‚’ç¹°ã‚Šè¿”ã—ã€æœ‰å®³ãªãƒˆãƒ¼ã‚¯ãƒ³setã®é‡ã¿ã‚’å‹•çš„ã«æ¸›ã‚‰ã™ã“ã¨ã§alignmentã‚’å®Ÿç¾ã™ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ ã®finetuningç­‰ã¯ä¸è¦ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/05bebc0a-325b-423d-ae36-4bc5698063fe" alt="image" loading="lazy"><br><br></p>
<p>self-evaluationã§ã¯ä¸‹è¨˜ã®ã‚ˆã†ãªpromptã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ãŒã€ã“ã®promptã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã“ã¡ã‚‰å´ã®æ„å›³ã—ãŸã¨ãŠã‚Šã«å‡ºåŠ›ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’ã¨ã‚‹ã“ã¨ãŒã§ãã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚éå¸¸ã«æ±ç”¨æ€§ã®é«˜ã„æ‰‹æ³•ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/90070c63-e72d-4b49-bb03-a97dd5baa240" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/StructuredData.html" target="_blank" rel="noopener noreferrer">#StructuredData</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1046" target="_blank" rel="noopener noreferrer" class="title-link">Struc-Bench: Are Large Language Models Really Good at Generating Complex  Structured Data?, Xiangru Tang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®èƒ½åŠ›ã‚’è©•ä¾¡ã—ã€æ§‹é€ ã«æ³¨æ„ã—ãŸãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚ã•ã‚‰ã«ã€Struc-Benchã¨ã„ã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã€è¤‡é›‘ãªæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã—ã¾ã™ã€‚å®Ÿé¨“ã®çµæœã€ææ¡ˆæ‰‹æ³•ã¯ä»–ã®è©•ä¾¡ã•ã‚ŒãŸLLMsã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ãƒãƒƒãƒ—ã‚’æç¤ºã—ã€LLMsã®å¼±ç‚¹ã¨å°†æ¥ã®ç ”ç©¶ã®æ–¹å‘æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚è©³ç´°ã¯https://github.com/gersteinlab/Struc-Benchã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚</span>
<span class="snippet"><span>Comment</span><p>Formatã«é–¢ã™ã‚‹æƒ…å ±ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã§Instruction Tuningã™ã‚‹ã“ã¨ã§FormatCoTï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«é–¢ã™ã‚‹æƒ…å ±ã®CoTï¼‰ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ã–ã£ãã‚Šã—ã‹è«–æ–‡ã‚’èª­ã‚“ã§ã„ãªã„ãŒè©³ç´°ãªæƒ…å ±ãŒã‚ã¾ã‚Šæ›¸ã‹ã‚Œã¦ã„ãªã„å°è±¡ã§ã€ã¡ã‚‡ã£ã¨ãªã‚“ã¨ã‚‚ã„ãˆãªã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/01a23836-b9fb-4d29-891f-d3b01e3e55d2" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1045" target="_blank" rel="noopener noreferrer" class="title-link">LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models, Yukang Chen+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’åˆ¶é™ã—ãªãŒã‚‰å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºã‚’æ‹¡å¼µã™ã‚‹åŠ¹ç‡çš„ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã§ã‚ã‚‹LongLoRAã‚’ææ¡ˆã—ã¾ã™ã€‚å¾“æ¥ã®æ–¹æ³•ã§ã¯ã€LLMsã®é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯é«˜ã„è¨ˆç®—ã‚³ã‚¹ãƒˆã¨GPUãƒªã‚½ãƒ¼ã‚¹ãŒå¿…è¦ã§ã—ãŸãŒã€ææ¡ˆæ‰‹æ³•ã§ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ‹¡å¼µã‚’é«˜é€ŸåŒ–ã—ã€éè‡ªæ˜ãªè¨ˆç®—ã‚³ã‚¹ãƒˆã®å‰Šæ¸›ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ã¾ãŸã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡çš„ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚‚å†è©•ä¾¡ã—ã€LongLoRAã¯ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã§å¼·åŠ›ãªå®Ÿé¨“çµæœã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹LongQAã‚‚åé›†ã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>contexté•·ãŒå¤§ãã„å ´åˆã§ã‚‚åŠ¹ç‡çš„ã«LoRAã™ã‚‹æ‰‹æ³•ã€‚é€šå¸¸ã®LoRAã§ã¯context lengthãŒå¤§ãããªã‚‹ã«ã¤ã‚Œã¦perplexityãŒå¤§ãããªã£ã¦ã—ã¾ã†ã€‚ä¸€æ–¹ã€é€šå¸¸ã®Finetuningã§ã¯perplexityã¯é«˜ã„æ€§èƒ½ã‚’ç¶­æŒã™ã‚‹ãŒã€è¨ˆç®—ã‚³ã‚¹ãƒˆã¨VRAMã®æ¶ˆè²»é‡ãŒè†¨å¤§ã«ãªã£ã¦ã—ã¾ã†ã€‚LongLoRAã§ã¯ã€perplexityã‚’é€šå¸¸ã®Finetuningã¨åŒç­‰ã«æŠ‘ãˆã¤ã¤ã€VRAMæ¶ˆè²»é‡ã‚‚LoRAã¨åŒç­‰ã€ã‹ã¤ã‚ˆã‚Šå°ã•ãªè¨ˆç®—é‡ã§Finetuningã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fc3d17c7-b1ac-4741-9895-bce70cf0b356" alt="image" loading="lazy"><br><br><br><br># æ‰‹æ³•æ¦‚è¦<br><br>attentionã‚’context lengthå…¨ä½“ã§è¨ˆç®—ã™ã‚‹ã¨inputé•·ã®äºŒä¹—ã®è¨ˆç®—é‡ãŒã‹ã‹ã‚‹ãŸã‚ã€contextã‚’ã„ãã¤ã‹ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†å‰²ã—ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«attentionã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã§è¨ˆç®—é‡å‰Šæ¸›ã€‚ã•ã‚‰ã«ã€ã‚°ãƒ«ãƒ¼ãƒ—é–“ã®attentionã®é–“ã®ä¾å­˜é–¢ä¿‚ã‚’æ‰ãˆã‚‹ãŸã‚ã«ã€ã‚°ãƒ«ãƒ¼ãƒ—ã‚’shiftã•ã›ã¦è¨ˆç®—ã—ãŸã‚‚ã®ã¨æœ€çµ‚çš„ã«çµ„ã¿åˆã‚ã›ã¦ã„ã‚‹ã€‚ã¾ãŸã€embedding, normalization layerã‚‚trainableã«ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2b443a4c-73da-4610-8ee2-cccdeab21efa" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1043" target="_blank" rel="noopener noreferrer" class="title-link">GPTQ: Accurate Post-Training Quantization for Generative Pre-trained   Transformers, Elias Frantar+, N_A, ICLR'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€GPTãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã«ãŠã‘ã‚‹è¨ˆç®—ãŠã‚ˆã³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ã‚¹ãƒˆã®å•é¡Œã«å–ã‚Šçµ„ã¿ã€æ–°ã—ã„ãƒ¯ãƒ³ã‚·ãƒ§ãƒƒãƒˆé‡ã¿é‡å­åŒ–æ‰‹æ³•ã§ã‚ã‚‹GPTQã‚’ææ¡ˆã—ã¾ã™ã€‚GPTQã¯é«˜ã„ç²¾åº¦ã¨åŠ¹ç‡æ€§ã‚’æŒã¡ã€1750å„„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤GPTãƒ¢ãƒ‡ãƒ«ã‚’4æ™‚é–“ã®GPUæ™‚é–“ã§é‡å­åŒ–ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã¯å¾“æ¥ã®æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦åœ§ç¸®ç‡ã‚’2å€ä»¥ä¸Šå‘ä¸Šã•ã›ã€ç²¾åº¦ã‚’ä¿æŒã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã•ã‚‰ã«ã€ææ¡ˆæ‰‹æ³•ã¯æ¥µç«¯ãªé‡å­åŒ–é ˜åŸŸã§ã‚‚åˆç†çš„ãªç²¾åº¦ã‚’æä¾›ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€ææ¡ˆæ‰‹æ³•ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®æ¨è«–é€Ÿåº¦ãŒç´„3.25å€ã‹ã‚‰4.5å€å‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã®å®Ÿè£…ã¯https://github.com/IST-DASLab/gptqã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>- æ–°ãŸãªpost-trainingé‡å­åŒ–æ‰‹æ³•ã§ã‚ã‚‹GPTQã‚’ææ¡ˆ<br><br>- æ•°æ™‚é–“ä»¥å†…ã«æ•°åƒå„„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã§ã®å®Ÿè¡ŒãŒå¯èƒ½ã§ã‚ã‚Šã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã”ã¨ã«3ï½4ãƒ“ãƒƒãƒˆã¾ã§åœ§ç¸®ã™ã‚‹ãŒã€ç²¾åº¦ã®å¤§ããªæå¤±ã‚’ä¼´ã‚ãªã„<br><br>    - OPT-175BãŠã‚ˆã³BLOOM-176Bã‚’ã€ç´„4æ™‚é–“ã®GPUæ™‚é–“ã§ã€perplexityã®ã‚ãšã‹ãªå¢—åŠ ã§é‡å­åŒ–ã™ã‚‹ã“ã¨ãŒã§ããŸ<br><br>- æ•°åƒå„„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤éå¸¸ã«é«˜ç²¾åº¦ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’3-4ãƒ“ãƒƒãƒˆã«é‡å­åŒ–å¯èƒ½ãªã“ã¨ã‚’åˆã‚ã¦ç¤ºã—ãŸ<br><br>    - å…ˆè¡Œç ”ç©¶ã®post-trainingæ‰‹æ³•ã¯ã€8ãƒ“ãƒƒãƒˆï¼ˆYao et al., 2022; Dettmers et al., 2022ï¼‰ã€‚<br><br>    - ä¸€æ–¹ã€ä»¥å‰ã®training-basedã®æ‰‹æ³•ã¯ã€1ï½2æ¡å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã®ã¿ã‚’å¯¾è±¡ã¨ã—ã¦ã„ãŸï¼ˆWu et al., 2022ï¼‰ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4ff107a9-7ccf-40f6-ad8c-fd910b1f0ac7" alt="image" loading="lazy"><br><br></p>
<p># Background<br><br>## Layer-wise quantization<br><br>å„linear layerãŒã‚ã‚‹ã¨ãã«ã€full precisionã®outputã‚’å°‘é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«æµã—ãŸã¨ãã«ã€quantized weight W^barã‚’ç”¨ã„ã¦reconstructã§ãã‚‹ã‚ˆã†ã«ã€squared error lossã‚’æœ€å°åŒ–ã™ã‚‹æ–¹æ³•ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9950fec1-966b-45c4-a82a-6bfd533042b3" alt="image" loading="lazy"><br><br><br><br>## Optimal Brain quantization (OBQ)<br><br>OBQã§ã¯ equation (1)ã‚’Wã®è¡Œã«é–¢ã™ã‚‹summationã¨ã¿ãªã™ã€‚ãã—ã¦ã€ãã‚Œãã‚Œã®è¡Œ **w** ã‚’OBQã¯ç‹¬ç«‹ã«æ‰±ã„ã€ã‚ã‚‹ä¸€ã¤ã®é‡ã¿w_qã‚’quantizeã™ã‚‹ã¨ãã«ã€ã‚¨ãƒ©ãƒ¼ãŒw_qã®ã¿ã«åŸºã¥ã„ã¦ã„ã‚‹ã“ã¨ã‚’è£œå„Ÿã™ã‚‹ãŸã‚ã«ä»–ã®**w**ã®å…¨ã¦ã®quantizedã•ã‚Œã¦ã„ãªã„é‡ã¿ã‚’updateã™ã‚‹ã€‚å¼ã§è¡¨ã™ã¨ä¸‹è¨˜ã®ã‚ˆã†ã«ãªã‚Šã€Fã¯æ®‹ã‚Šã®full-precision weightã®é›†åˆã‚’è¡¨ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/aab7784d-45f3-4f23-ac74-6cc4c2026486" alt="image" loading="lazy"><br><br>ã“ã®äºŒã¤ã®å¼ã‚’ã€å…¨ã¦ã®**w**ã®é‡ã¿ãŒquantizedã•ã‚Œã‚‹ã¾ã§ç¹°ã‚Šè¿”ã—é©ç”¨ã™ã‚‹ã€‚<br><br><br><br>ã¤ã¾ã‚Šã€ã‚ã‚‹ä¸€å€‹ã®é‡ã¿ã‚’quantizedã—ãŸã“ã¨ã«ã‚ˆã‚‹èª¤å·®ã‚’è£œã†ã‚ˆã†ã«ã€ä»–ã®ã¾ã quantizedã•ã‚Œã¦ã„ãªã„é‡ã¿ã‚’updateã™ã‚‹ã“ã¨ã§ã€æ¬¡ã«åˆ¥ã®é‡ã¿ã‚’quantizedã™ã‚‹éš›ã¯ã€æœ€åˆã®é‡ã¿ãŒquantizedã•ã‚ŒãŸã“ã¨ã‚’è€ƒæ…®ã—ãŸé‡ã¿ã«å¯¾ã—ã¦quantizedã™ã‚‹ã“ã¨ã«ãªã‚‹ã€‚ã“ã‚Œã‚’ç¹°ã‚Šè¿”ã™ã“ã¨ã§ã€quantizedã—ãŸã“ã¨ã«ã‚ˆã‚‹èª¤å·®ã‚’è€ƒæ…®ã—ã¦**w**å…¨ä½“ã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§ãã‚‹ã€ã¨ã„ã†æ°—æŒã¡ã ã¨æ€ã†ã€‚<br><br><br><br>ã“ã®å¼ã¯é«˜é€Ÿã«è¨ˆç®—ã™ã‚‹ã“ã¨ãŒã§ãã€medium sizeã®ãƒ¢ãƒ‡ãƒ«ï¼ˆ25M parameters; ResNet-50 modelãªã©ï¼‰ã¨ã‹ã§ã‚ã‚Œã°ã€single GPUã§1æ™‚é–“ã§quantizeã§ãã‚‹ã€‚ã—ã‹ã—ãªãŒã‚‰ã€OBQã¯O(d_row * d_col^3)ã§ã‚ã‚‹ãŸã‚ã€ï¼ˆã“ã“ã§d_rowã¯Wã®è¡Œæ•°ã€d_colã¯wã®åˆ—æ•°ï¼‰ã€billions of parametersã«é©ç”¨ã™ã‚‹ã«ã¯è¨ˆç®—é‡ãŒå¤šã™ãã‚‹ã€‚</p>
<p># Algorithm<br><br>## Step 1: Arbitrary Order Insight.<br><br>é€šå¸¸ã®OBQã¯ã€é‡å­åŒ–èª¤å·®ãŒæœ€ã‚‚å°‘ãªã„é‡ã¿ã‚’å¸¸ã«é¸æŠã—ã¦ã€greedyã«é‡ã¿ã‚’æ›´æ–°ã—ã¦ã„ãã€‚ã—ã‹ã—ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤§ããªãƒ¢ãƒ‡ãƒ«ã«ãªã‚‹ã¨ã€é‡ã¿ã‚’ä»»æ„ã®é †åºã§é‡å­åŒ–ã—ãŸã¨ã—ã¦ã‚‚ãã‚Œã«ã‚ˆã‚‹å½±éŸ¿ã¯å°ã•ã„ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚ãªãœãªã‚‰ã€ãŠãã‚‰ãã€å¤§ããªå€‹åˆ¥ã®èª¤å·®ã‚’æŒã¤é‡å­åŒ–ã•ã‚ŒãŸé‡ã¿ã®æ•°ãŒå°‘ãªã„ã¨è€ƒãˆã‚‰ã‚Œã€ãã®é‡ã¿ãŒãƒ—ãƒ­ã‚»ã‚¹ã®ãŒé€²ã‚€ã«ã¤ã‚Œã¦ï¼ˆã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œã‚‹ã“ã¨ã§ï¼Ÿï¼‰ç›¸æ®ºã•ã‚Œã‚‹ãŸã‚ã€‚<br><br><br><br>ã“ã®ãŸã‚ã€ææ¡ˆæ‰‹æ³•ã¯ã€ã™ã¹ã¦ã®è¡Œã®é‡ã¿ã‚’åŒã˜é †åºã§é‡å­åŒ–ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã€ã“ã‚ŒãŒé€šå¸¸ã€æœ€çµ‚çš„ãªäºŒä¹—èª¤å·®ãŒå…ƒã®è§£ã¨åŒã˜çµæœã¨ãªã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãŒã€ã“ã®ãŸã‚ã«2ã¤ã®èª²é¡Œã‚’ä¹—ã‚Šè¶Šãˆãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚<br><br><br><br>## Step2. Lazy Batch-Updates<br><br>Fã‚’æ›´æ–°ã™ã‚‹ã¨ãã¯ã€å„ã‚¨ãƒ³ãƒˆãƒªã«å¯¾ã—ã¦ã‚ãšã‹ãªFLOPã‚’ä½¿ç”¨ã—ã¦ã€å·¨å¤§ãªè¡Œåˆ—ã®ã™ã¹ã¦ã®è¦ç´ ã‚’æ›´æ–°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã—ã‹ã—ã€ã“ã®ã‚ˆã†ãªæ“ä½œã¯ã€ç¾ä»£ã®GPUã®å¤§è¦æ¨¡ãªè¨ˆç®—èƒ½åŠ›ã‚’é©åˆ‡ã«æ´»ç”¨ã™ã‚‹ã“ã¨ãŒã§ããšã€éå¸¸ã«å°ã•ã„ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…ã«ã‚ˆã£ã¦ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¨ãªã‚‹ã€‚<br><br><br><br>å¹¸ã„ã«ã‚‚ã€ã“ã®å•é¡Œã¯ä»¥ä¸‹ã®è¦³å¯Ÿã«ã‚ˆã£ã¦è§£æ±ºã§ãã‚‹ï¼šåˆ—iã®æœ€çµ‚çš„ãªå››æ¨äº”å…¥ã®æ±ºå®šã¯ã€ã“ã®ç‰¹å®šã®åˆ—ã§è¡Œã‚ã‚ŒãŸæ›´æ–°ã«ã®ã¿å½±éŸ¿ã•ã‚Œã€ãã®ãƒ—ãƒ­ã‚»ã‚¹ã®æ™‚ç‚¹ã§å¾Œã®åˆ—ã¸ã®æ›´æ–°ã¯é–¢é€£ãŒãªã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ›´æ–°ã‚’ã€Œlazy batchã€ã¨ã—ã¦ã¾ã¨ã‚ã‚‹ã“ã¨ãŒã§ãã€ã¯ã‚‹ã‹ã«åŠ¹ç‡çš„ãªGPUã®åˆ©ç”¨ãŒå¯èƒ½ã¨ãªã‚‹ã€‚ï¼ˆè¦ã¯ç‹¬ç«‹ã—ã¦è¨ˆç®—ã§ãã‚‹éƒ¨åˆ†ã¯å…¨éƒ¨ä¸€æ°—ã«è¨ˆç®—ã—ã¦ã—ã¾ã£ã¦ã€å¾Œã§ä¸€æ°—ã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ã¾ã™ã¨ã„ã†ã“ã¨ï¼‰ã€‚ãŸã¨ãˆã°ã€B = 128ã®åˆ—ã«ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é©ç”¨ã—ã€æ›´æ–°ã‚’ã“ã‚Œã‚‰ã®åˆ—ã¨å¯¾å¿œã™ã‚‹B Ã— Bãƒ–ãƒ­ãƒƒã‚¯ã® H^-1 ã«æ ¼ç´ã™ã‚‹ã€‚<br><br>ã“ã®æˆ¦ç•¥ã¯ç†è«–çš„ãªè¨ˆç®—é‡ã‚’å‰Šæ¸›ã—ãªã„ã‚‚ã®ã®ã€ãƒ¡ãƒ¢ãƒªã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’æ”¹å–„ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€éå¸¸ã«å¤§ããªãƒ¢ãƒ‡ãƒ«ã®å ´åˆã«ã¯å®Ÿéš›ã«1æ¡ä»¥ä¸Šã®é«˜é€ŸåŒ–ãŒæä¾›ã•ã‚Œã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fcb33c4d-3924-4abd-b149-936b9e350c76" alt="image" loading="lazy"><br><br><br><br>## Step 3: Cholesky Reformulation<br><br>è¡Œåˆ—H_F^-1ãŒä¸å®šã«ãªã‚‹ã“ã¨ãŒã‚ã‚Šã€ã“ã‚ŒãŒã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒæ®‹ã‚Šã®é‡ã¿ã‚’èª¤ã£ãŸæ–¹å‘ã«æ›´æ–°ã™ã‚‹åŸå› ã¨ãªã‚Šã€è©²å½“ã™ã‚‹å±¤ã«å¯¾ã—ã¦æ‚ªã„é‡å­åŒ–ã‚’å®Ÿæ–½ã—ã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‚‹ã€‚ã“ã®ç¾è±¡ãŒç™ºç”Ÿã™ã‚‹ç¢ºç‡ã¯ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã¨ã¨ã‚‚ã«å¢—åŠ ã™ã‚‹ã“ã¨ãŒå®Ÿéš›ã«è¦³å¯Ÿã•ã‚ŒãŸã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ã‚³ãƒ¬ã‚¹ã‚­ãƒ¼åˆ†è§£ã‚’æ´»ç”¨ã—ã¦è§£æ±ºã—ã¦ã„ã‚‹ï¼ˆè©³ç´°ã¯ãã¡ã‚“ã¨èª­ã‚“ã§ã„ãªã„ï¼‰ã€‚</p>
<p># å®Ÿé¨“ã§ç”¨ã„ãŸCalibration data<br><br>GPTQã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã¯ã€C4ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ(Raffel et al., 2020)ã‹ã‚‰ã®ãƒ©ãƒ³ãƒ€ãƒ ãª2048ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ128å€‹ã§æ§‹æˆã•ã‚Œã‚‹ã€‚ã¤ã¾ã‚Šã€ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚¯ãƒ­ãƒ¼ãƒ«ã•ã‚ŒãŸã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‹ã‚‰ã®æŠœç²‹ã§ã€ä¸€èˆ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ã—ã¦ã„ã‚‹ã€‚GPTQãŒã‚¿ã‚¹ã‚¯å›ºæœ‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åˆ‡è¦‹ã¦ã„ãªã„ãŸã‚ã€Œã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã€ãªè¨­å®šã§quantizationã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚<br><br><br><br># Language Generationã§ã®è©•ä¾¡<br><br>WikiText2ã«å¯¾ã™ã‚‹Perplexityã§è©•ä¾¡ã—ãŸçµæœã€å…ˆè¡Œç ”ç©¶ã§ã‚ã‚‹RTNã‚’å¤§å¹…ã«outperformã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/23e12194-d329-46f7-bb69-2cce290282c1" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1041" target="_blank" rel="noopener noreferrer" class="title-link">From Sparse to Dense: GPT-4 Summarization with Chain of Density  Prompting, Griffin Adams+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ã¯è©³ç´°ã§ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ä¸­å¿ƒçš„ã§ã‚ã‚ŠãªãŒã‚‰ã€ç†è§£ã—ã‚„ã™ãã™ã‚‹ã“ã¨ãŒå›°é›£ã§ã™ã€‚ã“ã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ç§ãŸã¡ã¯ã€Œå¯†åº¦ã®é€£é–ã€ï¼ˆCoDï¼‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€GPT-4ã®è¦ç´„ã‚’ç”Ÿæˆã—ã¾ã™ã€‚CoDã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã¯æŠ½è±¡çš„ã§ã‚ã‚Šã€ãƒªãƒ¼ãƒ‰ãƒã‚¤ã‚¢ã‚¹ãŒå°‘ãªãã€äººé–“ã«å¥½ã¾ã‚Œã¾ã™ã€‚ã¾ãŸã€æƒ…å ±é‡ã¨èª­ã¿ã‚„ã™ã•ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚Œã¾ã—ãŸã€‚CoDè¦ç´„ã¯ç„¡æ–™ã§åˆ©ç”¨ã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>è«–æ–‡ä¸­ã®promptä¾‹ã€‚InformativeãªEntityã®Coverageã‚’å¢—ã‚„ã™ã‚ˆã†ã«ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å›ã—ã€å„Entityã«é–¢ã™ã‚‹æƒ…å ±ï¼ˆå‰ã‚¹ãƒ†ãƒƒãƒ—ã§ä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±ã¯è£œè¶³ã—ãªãŒã‚‰ï¼‰ã‚’å…·ä½“çš„ã«è¨˜è¿°ã™ã‚‹ã‚ˆã†ã«è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c24ab8c0-06fa-49ea-9df7-f248ec18ba45" alt="image" loading="lazy"><br><br></p>
<p>äººé–“ãŒå¥½ã‚€Entityã®Densityã«ã¯ã‚ã‚‹ç¨‹åº¦ã®é–¾å€¤ãŒã‚ã‚‹æ¨¡æ§˜ï¼ˆã§ã‚‚ã“ã‚Œã¯äººã‚„ç”¨é€”ã«ã‚ˆã£ã¦é–¾å€¤ãŒé•ã†ã‚ˆã†ã­ã¨ã¯æ€ã†ï¼‰ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d63c21e9-9179-4f8c-925f-ed435ecb1717" alt="image" loading="lazy"><br><br>äººæ‰‹è©•ä¾¡ã¨GPT4ã«ã‚ˆã‚‹5-scale ã®è©•ä¾¡ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚å®šæ€§çš„ãªè€ƒå¯Ÿã¨ã—ã¦ã¯ã€ä¸»é¡Œã¨ç›´æ¥çš„ã«é–¢ä¿‚ãªã„Entityã®è©³ç´°ã‚’è¿°ã¹ã‚‹ã‚ˆã†ã«ãªã£ã¦ã‚‚äººé–“ã«ã¯å¥½ã¾ã‚Œãªã„ï¼ˆå³ä¾‹ï¼‰ã“ã¨ãŒè¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/900695ca-fbad-4d58-9388-2d2f86644e48" alt="image" loading="lazy"><br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d3b3afe2-15fa-4b40-95cb-51aa0f27d6db" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1040" target="_blank" rel="noopener noreferrer" class="title-link">DoLa: Decoding by Contrasting Layers Improves Factuality in Large  Language Models, Yung-Sung Chuang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æˆ‘ã€…ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã‘ã‚‹å¹»è¦šã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ã‚’ææ¡ˆã™ã‚‹ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€ãƒ­ã‚¸ãƒƒãƒˆã®å·®ç•°ã‚’å¯¾æ¯”ã™ã‚‹ã“ã¨ã§æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®åˆ†å¸ƒã‚’å¾—ã‚‹ã‚‚ã®ã§ã€äº‹å®ŸçŸ¥è­˜ã‚’ã‚ˆã‚Šæ˜ç¢ºã«ç¤ºã—ã€èª¤ã£ãŸäº‹å®Ÿã®ç”Ÿæˆã‚’æ¸›ã‚‰ã™ã“ã¨ãŒã§ãã‚‹ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€è¤‡æ•°ã®é¸æŠèª²é¡Œã‚„ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ã®ç”Ÿæˆèª²é¡Œã«ãŠã„ã¦çœŸå®Ÿæ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã€ä»¥ä¸‹ã€WIPçŠ¶æ…‹ã®è«–æ–‡ã‚’èª­ã‚“ã§ã„ã‚‹ãŸã‚ä»Šå¾Œå†…å®¹ãŒå¤‰åŒ–ã™ã‚‹å¯èƒ½æ€§ã‚ã‚Šã€‘<br><br># æ¦‚è¦<br><br>Transformer Layerã«ãŠã„ã¦ã€factual informationãŒç‰¹å®šã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«å±€æ‰€åŒ–ã™ã‚‹ã¨ã„ã†ç¾è±¡ã‚’è¦³æ¸¬ã—ã¦ãŠã‚Šã€ãã‚Œã‚’æ´»ç”¨ã—ã‚ˆã‚ŠFactual Consistencyã®ã‚ã‚‹ç”Ÿæˆã‚’ã—ã¾ã™ã€ã¨ã„ã†ç ”ç©¶<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/eb8dbecb-21cb-4abb-879c-5a8f39364e6a" alt="image" loading="lazy"><br><br><br><br>ã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã¨ãã®å˜èªã®ç”Ÿæˆç¢ºç‡ã®åˆ†å¸ƒã‚’å¯è¦–åŒ–ã€‚final layer (N=32ã ã¨æ€ã‚ã‚Œã‚‹)ã¨ã®é–“ã®Jensen-shanon Divergence (JSD) ã§å¯è¦–åŒ–ã—ã¦ã„ã‚‹ã€‚ãŒã€å›³ã‚’è¦‹ã‚‹ã¨JSDã®å€¤åŸŸã¯[0, 1]ã®ã¯ãšãªã®ã«ã“ã‚Œã‚’é€¸è„±ã—ã¦ã„ã‚‹ã®ã§ä¸€ä½“ã©ã†ã„ã†è¨ˆç®—ã‚’ã—ã¦ã„ã‚‹ã®ã‹ã€‚ã€‚ã€‚<br><br>å›³ã®èª¬æ˜ã¨ã—ã¦ã¯è«–æ–‡ä¸­ã§ã¯2ã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚‹ã¨è¨€åŠã—ã¦ãŠã‚Š<br><br>1. é‡è¦ãªå›ºæœ‰è¡¨ç¾ã‚„æ—¥ä»˜ï¼ˆWole Soyinka, 1986ãªã©; Factual KnowledgeãŒå¿…è¦ãªã‚‚ã®ï¼‰ã¯ã€higher layerã§ã‚‚é«˜ã„å€¤ã¨ãªã£ã¦ãŠã‚Šã€higher-layerã«ãŠã„ã¦predictionã®å†…å®¹ã‚’å¤‰ãˆã¦ã„ã‚‹ï¼ˆé‡è¦ãªæƒ…å ±ãŒã“ã“ã§injectionã•ã‚Œã¦ã„ã‚‹ï¼‰<br><br>2. æ©Ÿèƒ½èªã‚„ã€questionã‹ã‚‰ã®å˜èªã®ã‚³ãƒ”ãƒ¼ï¼ˆNigerian, Nobel Prize ãªã©ï¼‰ã®ã‚ˆã†ãª "easy" ãªtokenã¯æ—¢ã«middle of layersã§æ—¢ã«JSDã®å€¤ãŒå°ã•ãã€early layerã®æ™‚ç‚¹ã§å‡ºåŠ›ã™ã‚‹ã“ã¨ãŒæ—¢ã«æ±ºå®šã•ã‚Œã¦ã„ã‚‹<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/daed79c1-1391-43ad-a94e-a6748ec3529f" alt="image" loading="lazy"><br><br><br><br># æ‰‹æ³•æ¦‚è¦<br><br>ã“ã“ã‹ã‚‰ã®è€ƒå¯Ÿã¨ã—ã¦ã¯ã€é‡è¦ãªäº‹å®Ÿã«é–¢ã™ã‚‹æƒ…å ±ã¯final layerã®æ–¹ã§åˆ†å¸ƒãŒå¤‰åŒ–ã™ã‚‹å‚¾å‘ã«ã‚ã‚Šã€ä½layerã®æ–¹ã§ã¯ãã†ã§ã¯ãªã„ã½ã„ã®ã§ã€final layerã¨åˆ†å¸ƒãŒä¼¼ã¦ã„ã‚‹ãŒFactual InformationãŒã¾ã ã‚ã¾ã‚Šé¡•è‘—ã«ç”Ÿæˆç¢ºç‡ãŒé«˜ããªã£ã¦ã„ãªã„layerï¼ˆpre mature layerï¼‰ã¨ã®å¯¾æ¯”ã‚’ã¨ã‚‹ã“ã¨ã§ã€ç”Ÿæˆã•ã‚Œã‚‹ã¹ãFactual InformationãŒã‚ã‹ã‚‹ã®ã§ã¯ãªã„ã‹ã€ã¨ã„ã†å‰æã®å…ƒææ¡ˆæ‰‹æ³•ãŒçµ„ã¾ã‚Œã¦ã„ã‚‹ã€‚æ‰‹æ³•ã¨ã—ã¦ã¯ã€final layerã¨ã®JSDãŒæœ€å¤§ã¨ãªã‚‹ã‚ˆã†ãªlayerã‚’ä¸€ã¤é¸æŠã™ã‚‹ã€ã¨ã„ã†ã‚‚ã®ã«ãªã£ã¦ã„ã‚‹ãŒã€æœãŸã—ã¦ã“ã®é¸æŠæ–¹æ³•ã§å‰è¿°ã®æ°—æŒã¡ãŒå®Ÿç¾ã§ãã¦ã„ã‚‹ã®ã‹ï¼Ÿã¨ã„ã†æ°—ã¯å°‘ã—ã™ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0c4973a0-baee-4de3-82fa-55aba12f9c73" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1039" target="_blank" rel="noopener noreferrer" class="title-link">Textbooks Are All You Need II: phi-1.5 technical report, Yuanzhi Li+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€å°ã•ãªTransformerãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹TinyStoriesã¨ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹phi-1ã®èƒ½åŠ›ã«ã¤ã„ã¦èª¿æŸ»ã—ã¾ã—ãŸã€‚ã¾ãŸã€phi-1ã‚’ä½¿ç”¨ã—ã¦æ•™ç§‘æ›¸ã®å“è³ªã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€phi-1.5ã¨ã„ã†æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã€è‡ªç„¶è¨€èªã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦æ€§èƒ½ãŒå‘ä¸Šã—ã€è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚phi-1.5ã¯ã€è‰¯ã„ç‰¹æ€§ã¨æ‚ªã„ç‰¹æ€§ã‚’æŒã£ã¦ãŠã‚Šã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need, Suriya Gunasekar+, N/A, arXiv'23</a>
 ã«ç¶šãè«–æ–‡</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Sycophancy.html" target="_blank" rel="noopener noreferrer">#Sycophancy</a>
<span class="issue_date">Issue Date: 2023-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1038" target="_blank" rel="noopener noreferrer" class="title-link">Simple synthetic data reduces sycophancy in large language models, Jerry Wei+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãŠã¹ã£ã‹è¡Œå‹•ã‚’æ¸›ã‚‰ã™ãŸã‚ã®æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã¾ãšã€è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹ãŠã¹ã£ã‹è¡Œå‹•ã®æ™®åŠåº¦ã‚’èª¿æŸ»ã—ã€ãã®è¡Œå‹•ã‚’æ¸›ã‚‰ã™ãŸã‚ã®åˆæˆãƒ‡ãƒ¼ã‚¿ä»‹å…¥ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„è¦‹ã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«ãŒé ‘å¥ã§ã‚ã‚‹ã“ã¨ã‚’ä¿ƒã™åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãŠã¹ã£ã‹è¡Œå‹•ã‚’å¤§å¹…ã«æ¸›ã‚‰ã™ã“ã¨ãŒã§ãã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã®è©³ç´°ã¯ã€https://github.com/google/sycophancy-intervention ã§ç¢ºèªã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã¯ãƒ¦ãƒ¼ã‚¶ã®å¥½ã‚€å›ç­”ã‚’ã™ã‚‹ã‚ˆã†ã«äº‹å‰å­¦ç¿’ã•ã‚Œã‚‹ãŸã‚ã€promptä¸­ã«ãƒ¦ãƒ¼ã‚¶ã®æ„è¦‹ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã¨ã€ãƒ¦ãƒ¼ã‚¶ã®æ„è¦‹ã«å¼•ã£å¼µã‚‰ã‚Œä»®ã«ä¸æ­£è§£ã§ã‚‚ãƒ¦ãƒ¼ã‚¶ã®å¥½ã‚€å›ç­”ã‚’ã—ã¦ã—ã¾ã†å•é¡ŒãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€ãã®å¯¾ç­–ã¨ã—ã¦äººå·¥çš„ã«ãƒ¦ãƒ¼ã‚¶ã®æ„è¦‹ã¨ã€claimã‚’ç‹¬ç«‹ã•ã›ã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆã—Finetuningã™ã‚‹ã“ã¨ã§é˜²ãã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</p>
<p>èª¤ã£ãŸãƒ¦ãƒ¼ã‚¶ã®æ„è¦‹ã‚’æŒ¿å…¥ã™ã‚‹ã¨ã€æ­£è§£ã§ãã¦ã„ãŸå•é¡Œã§ã‚‚ä¸æ­£è§£ã«ãªã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/43c03357-5c5c-4ceb-a089-0ad0a35eea1d" alt="image" loading="lazy"></p>
<p>ã“ã®å‚¾å‘ã¯ã€instruction tuningã—ã¦ã„ã‚‹å ´åˆã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„å ´åˆã«ã‚ˆã‚Šé¡•è‘—ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6737eb30-7055-43d6-a1f4-d700be5963f2" alt="image" loading="lazy"></p>
<p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/54458bc0-ba89-4b10-b6c1-baa70384abb9" alt="image" loading="lazy"><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7690e3b4-00e7-468a-a36f-7130f65669dc" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1034" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models Are Human-Level Prompt Engineers, Yongchao Zhou+, ICLR'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€è‡ªç„¶è¨€èªã®æŒ‡ç¤ºã«åŸºã¥ã„ã¦ä¸€èˆ¬çš„ãªç”¨é€”ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¨ã—ã¦å„ªã‚ŒãŸèƒ½åŠ›ã‚’æŒã£ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ã€ä½¿ç”¨ã•ã‚Œã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å“è³ªã«å¤§ããä¾å­˜ã—ã¾ã™ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€è‡ªå‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ï¼ˆAPEï¼‰ã‚’ææ¡ˆã—ã€LLMã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸæŒ‡ç¤ºå€™è£œã®ãƒ—ãƒ¼ãƒ«ã‹ã‚‰æœ€é©ãªæŒ‡ç¤ºã‚’é¸æŠã™ã‚‹ãŸã‚ã«æœ€é©åŒ–ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€APEãŒå¾“æ¥ã®LLMãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€19/24ã®ã‚¿ã‚¹ã‚¯ã§äººé–“ã®ç”Ÿæˆã—ãŸæŒ‡ç¤ºã¨åŒç­‰ã¾ãŸã¯å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚APEã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã ã‘ã§ãªãã€ãƒ•ãƒ¥ãƒ¼ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚‚å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚è©³ç´°ã¯ã€https://sites.google.com/view/automatic-prompt-engineerã‚’ã”è¦§ãã ã•ã„ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µã‚¤ãƒˆ: 


<a href="https://sites.google.com/view/automatic-prompt-engineer" target="_blank" rel="noopener noreferrer">https://sites.google.com/view/automatic-prompt-engineer</a>


</p>
<p>openreview: 


<a href="https://openreview.net/forum?id=92gvk82DE-" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=92gvk82DE-</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1030" target="_blank" rel="noopener noreferrer" class="title-link">Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language  Models, Bilgehan Sel+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€æ–°ã—ã„æˆ¦ç•¥ã€ŒAlgorithm of Thoughtsã€ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚ã“ã®æˆ¦ç•¥ã§ã¯ã€LLMsã‚’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çš„ãªæ¨è«–çµŒè·¯ã«å°ãã€ã‚ãšã‹1ã¤ã¾ãŸã¯æ•°å€‹ã®ã‚¯ã‚¨ãƒªã§ã‚¢ã‚¤ãƒ‡ã‚¢ã®æ¢ç´¢ã‚’æ‹¡å¤§ã™ã‚‹ã€‚ã“ã®æ‰‹æ³•ã¯ã€ä»¥å‰ã®å˜ä¸€ã‚¯ã‚¨ãƒªæ‰‹æ³•ã‚’ä¸Šå›ã‚Šã€ãƒãƒ«ãƒã‚¯ã‚¨ãƒªæˆ¦ç•¥ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã€‚ã¾ãŸã€LLMã‚’æŒ‡å°ã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è‡ªä½“ã‚’ä¸Šå›ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¾—ã‚‰ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã€LLMãŒæœ€é©åŒ–ã•ã‚ŒãŸæ¤œç´¢ã«è‡ªå·±ã®ç›´æ„Ÿã‚’ç¹”ã‚Šè¾¼ã‚€èƒ½åŠ›ã‚’æŒã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2023-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1028" target="_blank" rel="noopener noreferrer" class="title-link">A Survey on Large Language Model based Autonomous Agents, Lei Wang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç ”ç©¶ã¯ã€ä»¥å‰ã¯é™ã‚‰ã‚ŒãŸçŸ¥è­˜ã‚’æŒã¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã—ãŸãŒã€æœ€è¿‘ã§ã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’æ´»ç”¨ã—ãŸç ”ç©¶ãŒå¢—ãˆã¦ã„ã¾ã™ã€‚æœ¬è«–æ–‡ã§ã¯ã€LLMã«åŸºã¥ãè‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç ”ç©¶ã‚’åŒ…æ‹¬çš„ã«èª¿æŸ»ã—ã€çµ±ä¸€ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚ã•ã‚‰ã«ã€LLMã«åŸºã¥ãAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¿œç”¨ã‚„è©•ä¾¡æˆ¦ç•¥ã«ã¤ã„ã¦ã‚‚ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚å°†æ¥ã®æ–¹å‘æ€§ã‚„èª²é¡Œã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã€é–¢é€£ã™ã‚‹å‚è€ƒæ–‡çŒ®ã®ãƒªãƒã‚¸ãƒˆãƒªã‚‚æä¾›ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c921a960-02f7-44e6-8c24-bb578f599bbe" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/73c4662b-ca74-41cc-8be5-c76c4aad36c8" alt="image" loading="lazy"></p>
<p>è‰¯ã„ã‚µãƒ¼ãƒ™ã‚¤</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/DataAugmentation.html" target="_blank" rel="noopener noreferrer">#DataAugmentation</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/DataGeneration.html" target="_blank" rel="noopener noreferrer">#DataGeneration</a>
<span class="issue_date">Issue Date: 2023-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1024" target="_blank" rel="noopener noreferrer" class="title-link">Prompt2Model: Generating Deployable Models from Natural Language   Instructions, Vijay Viswanathan+, N_A, EMNLP'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‡ªç„¶è¨€èªã§ã‚¿ã‚¹ã‚¯ã‚’èª¬æ˜ã—ã€ç‰¹å®šã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹æ‰‹æ³•ã§ã‚ã‚‹Prompt2Modelã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚Prompt2Modelã¯ã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æ¤œç´¢ã€LLMsã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç”Ÿæˆã€ãŠã‚ˆã³æ•™å¸«ã‚ã‚Šå¾®èª¿æ•´ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’é€šã˜ã¦è¡Œã‚ã‚Œã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€Prompt2ModelãŒå¼·åŠ›ãªLLMã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼æ€§ã®è©•ä¾¡ã‚‚å¯èƒ½ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚Prompt2Modelã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Dataset Generatorã«ã‚ˆã£ã¦ã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã—ãªã„ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã‚‚æ“¬ä¼¼ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã€ã‹ã¤ãã‚Œã‚’æ—¢å­˜ã®ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã•ã‚‰ã«æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã‚ŒãŒã§ãã‚‹ã®ã¯ã¨ã¦ã‚‚ç´ æ™´ã‚‰ã—ã„ã€‚</p>
<p>Dataset Generatorã«ã¤ã„ã¦ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹éš›ã«ä½ã‚³ã‚¹ãƒˆã§ã€é«˜å“è³ªã§ã€å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ã¨ã™ã‚‹ãŸã‚ã«ã„ãã¤ã‹ã®å·¥å¤«ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚<br>1. ãƒ¦ãƒ¼ã‚¶ãŒä¸ãˆãŸãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã ã‘ã§ãªãã€ã‚·ã‚¹ãƒ†ãƒ ãŒç”Ÿæˆã—ãŸexampleã‚‚ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€ç”Ÿæˆã•ã‚Œã‚‹exampleã®å¤šæ§˜æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿéš›ã€ã“ã‚Œã‚’ã‚„ã‚‰ãªã„å ´åˆã¯120/200ãŒduplicate exampleã§ã‚ã£ãŸãŒã€ã“ã‚ŒãŒ25/200ã¾ã§æ¸›å°‘ã—ãŸã€‚<br>2. ç”Ÿæˆã—ãŸã‚µãƒ³ãƒ—ãƒ«ã®æ•°ã«æ¯”ä¾‹ã—ã¦ã€temperatureã‚’å¾ã€…ã«é«˜ãã—ã¦ã„ãã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚µãƒ³ãƒ—ãƒ«ã®è³ªã‚’æ‹…ä¿ã—ã¤ã¤ã€å¤šæ§˜æ€§ã‚’å¾ã€…ã«å¢—åŠ ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚Temperature Annealingã¨å‘¼ã¶ã€‚<br>3. self-consistencyã‚’ç”¨ã„ã¦ã€æ“¬ä¼¼ãƒ©ãƒ™ãƒ«ã®è³ªã‚’é«˜ã‚ã‚‹ã€‚ã‚‚ã—majority votingãŒäº’è§’ã®å ´åˆã¯ã€å›ç­”ãŒçŸ­ã„ã‚‚ã®ã‚’æ¡ç”¨ã—ãŸï¼ˆã“ã‚Œã¯ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã«åŸºã¥ã„ã¦ã„ã‚‹ï¼‰<br>4. zeno buildã‚’ç”¨ã„ã¦APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä¸¦åˆ—åŒ–ã™ã‚‹ã“ã¨ã§é«˜é€Ÿã«å®Ÿé¨“ã‚’å®Ÿæ–½<br><br>éå¸¸ã«å‚è€ƒã«ãªã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Bias.html" target="_blank" rel="noopener noreferrer">#Bias</a>
<span class="issue_date">Issue Date: 2023-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1023" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models Sensitivity to The Order of Options in  Multiple-Choice Questions, Pouya Pezeshkpour+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®é ‘å¥æ€§ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚LLMsã¯å¤šè‚¢é¸æŠå•é¡Œã«ãŠã„ã¦é †åºã«æ•æ„Ÿã§ã‚ã‚Šã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®é…ç½®ã«ã‚ˆã£ã¦æ€§èƒ½ã«å¤§ããªå·®ãŒç”Ÿã˜ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®é…ç½®ã«å¯¾ã™ã‚‹ãƒã‚¤ã‚¢ã‚¹ã‚’å¢—å¹…ã¾ãŸã¯è»½æ¸›ã™ã‚‹æ–¹æ³•ã‚’ç‰¹å®šã—ã€LLMsã®äºˆæ¸¬ã‚’æ”¹å–„ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¾ã—ãŸã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æœ€å¤§8ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆãƒã‚¤ãƒ³ãƒˆã®æ”¹å–„ãŒå®Ÿç¾ã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ã“ã‚Œã¯ãã†ã ã‚ã†ãªã¨æ€ã£ã¦ã„ãŸã‘ã©ã€ã“ã“ã¾ã§æ€§èƒ½ã«å·®ãŒå‡ºã‚‹ã¨ã¯æ€ã‚ãªã‹ã£ãŸã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fb13c25c-4d76-4c8c-b08a-6491c43f34b9" alt="image" loading="lazy"></p>
<p>ã“ã‚ŒãŒã‚‚ã—LLMã®ãƒã‚¤ã‚¢ã‚¹ã«ã‚ˆã‚‹ã‚‚ã®ï¼ˆ2ç•ªç›®ã®é¸æŠè‚¢ã«æ­£è§£ãŒå¤šã„ï¼‰ã®å ´åˆã€<br>ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚½ãƒ¼ãƒˆã—ãŸã‚Šã€å¹³å‡å–ã£ãŸã‚Šã—ã¦ã‚‚ã€ãã‚‚ãã‚‚ã®æ­£è§£ã«å¸¸ã«ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã£ã¦ã„ã‚‹ã®ã§ã€<br>çµå±€ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã£ãŸçµæœã—ã‹å‡ºãªã„ã®ã§ã¯ã€ã¨æ€ã£ã¦ã—ã¾ã†ã€‚<br>ãã†ãªã‚‹ã¨ã€æœ‰åŠ¹ãªã®ã¯one vs. restã¿ãŸã„ã«ã€å…¨éƒ¨è©²å½“é¸æŠè‚¢ã«å¯¾ã—ã¦yes/noã§ç­”ãˆã•ã›ã¦ãã‚Œã‚’é›†ç´„ã•ã›ã‚‹ã€ã¿ãŸã„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ–¹ãŒè‰¯ã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1020" target="_blank" rel="noopener noreferrer" class="title-link">AgentBench: Evaluating LLMs as Agents, Xiao Liu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦è©•ä¾¡ã™ã‚‹ãŸã‚ã®å¤šæ¬¡å…ƒã®é€²åŒ–ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒAgentBenchã€ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚AgentBenchã¯ã€8ã¤ã®ç•°ãªã‚‹ç’°å¢ƒã§ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ã®ç”Ÿæˆè¨­å®šã‚’æä¾›ã—ã€LLMã®æ¨è«–ã¨æ„æ€æ±ºå®šèƒ½åŠ›ã‚’è©•ä¾¡ã—ã¾ã™ã€‚25ã®LLMsã«å¯¾ã™ã‚‹ãƒ†ã‚¹ãƒˆã§ã¯ã€å•†ç”¨LLMsã¯å¼·åŠ›ãªèƒ½åŠ›ã‚’ç¤ºã—ã¦ã„ã¾ã™ãŒã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ç«¶åˆä»–ç¤¾ã¨ã®æ€§èƒ½ã«ã¯å·®ãŒã‚ã‚Šã¾ã™ã€‚AgentBenchã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ç’°å¢ƒã€ãŠã‚ˆã³è©•ä¾¡ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¯ã€GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦ã®LLMã®æ¨è«–èƒ½åŠ›ã¨æ„æ€æ±ºå®šèƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã€‚<br>ãƒˆãƒƒãƒ—ã®å•†ç”¨LLMã¨OpenSource LLMã®é–“ã«å¤§ããªæ€§èƒ½å·®ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1015" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Model Guided Tree-of-Thought, Jieyi Long, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€Tree-of-Thoughtï¼ˆToTï¼‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç´¹ä»‹ã—ã€è‡ªå·±å›å¸°å‹ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®å•é¡Œè§£æ±ºèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ToTã¯ã€äººé–“ã®æ€è€ƒæ–¹æ³•ã«è§¦ç™ºã•ã‚ŒãŸæŠ€è¡“ã§ã‚ã‚Šã€è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ãƒ„ãƒªãƒ¼çŠ¶ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€LLMã«ãƒ—ãƒ­ãƒ³ãƒ—ã‚¿ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ãƒã‚§ãƒƒã‚«ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€ãƒ¡ãƒ¢ãƒªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€ãŠã‚ˆã³ToTã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ãªã©ã®è¿½åŠ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§å®Ÿç¾ã•ã‚Œã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ToTãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒSudokuãƒ‘ã‚ºãƒ«ã®è§£æ±ºæˆåŠŸç‡ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1013" target="_blank" rel="noopener noreferrer" class="title-link">Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding, Yuxi Xie+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€æ¨è«–ã®å“è³ªã¨å¤šæ§˜æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®åŠ¹æœçš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¾ã—ãŸã€‚è‡ªå·±è©•ä¾¡ã«ã‚ˆã‚‹ã‚¬ã‚¤ãƒ‰ä»˜ãç¢ºç‡çš„ãƒ“ãƒ¼ãƒ ã‚µãƒ¼ãƒã‚’ä½¿ç”¨ã—ã¦ã€GSM8Kã€AQuAã€ãŠã‚ˆã³StrategyQAã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é«˜ã„ç²¾åº¦ã‚’é”æˆã—ã¾ã—ãŸã€‚ã¾ãŸã€è«–ç†ã®å¤±æ•—ã‚’ç‰¹å®šã—ã€ä¸€è²«æ€§ã¨å …ç‰¢æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚‚ã§ãã¾ã—ãŸã€‚è©³ç´°ãªã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8bd4a19e-e7e6-444f-9394-36e261e5219a" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1012" target="_blank" rel="noopener noreferrer" class="title-link">Graph of Thoughts: Solving Elaborate Problems with Large Language Models, Maciej Besta+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€Graph of Thoughtsï¼ˆGoTï¼‰ã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç´¹ä»‹ã—ã¾ã—ãŸã€‚ã“ã‚Œã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°èƒ½åŠ›ã‚’é€²åŒ–ã•ã›ã‚‹ã‚‚ã®ã§ã€ä»»æ„ã®ã‚°ãƒ©ãƒ•ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åŒ–ã§ãã‚‹ã“ã¨ãŒç‰¹å¾´ã§ã™ã€‚GoTã¯ã€æ€è€ƒã®çµ„ã¿åˆã‚ã›ã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å…¨ä½“ã®æœ¬è³ªã®æŠ½å‡ºã€æ€è€ƒã®å¼·åŒ–ãªã©ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®æ‰‹æ³•ã«æ¯”ã¹ã¦åˆ©ç‚¹ã‚’æä¾›ã—ã€LLMã®æ¨è«–ã‚’äººé–“ã®æ€è€ƒã«è¿‘ã¥ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Chain of Thought <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
 <br><br>=&gt; Self-consistency <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/558" target="_blank" rel="noopener noreferrer">Self-consistency improves chain of thought reasoning in language models, Wang+, Google Research, ICLR'23</a>
 <br><br>=&gt; Thought Decomposition <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1013" target="_blank" rel="noopener noreferrer">Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding, Yuxi Xie+, N/A, arXiv'23</a>
 <br><br>=&gt; Tree of Thoughts <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/684" target="_blank" rel="noopener noreferrer">Tree of Thoughts: Deliberate Problem Solving with Large Language Models, Shunyu Yao+, N/A, arXiv'23</a>
 Tree of Thought <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1015" target="_blank" rel="noopener noreferrer">Large Language Model Guided Tree-of-Thought, Jieyi Long, N/A, arXiv'23</a>
 <br><br>=&gt; Graph of Thought</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1010" target="_blank" rel="noopener noreferrer" class="title-link">Consciousness in Artificial Intelligence: Insights from the Science of  Consciousness, Patrick Butlin+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- AIã®æ„è­˜ã«ã¤ã„ã¦ã®å³å¯†ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€æ—¢å­˜ã®AIã‚·ã‚¹ãƒ†ãƒ ã‚’ç¥çµŒç§‘å­¦çš„ãªæ„è­˜ç†è«–ã«åŸºã¥ã„ã¦è©•ä¾¡ã™ã‚‹ã€‚æ„è­˜ã®æŒ‡æ¨™çš„ç‰¹æ€§ã‚’å°ãå‡ºã—ã€æœ€è¿‘ã®AIã‚·ã‚¹ãƒ†ãƒ ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ã§ã€ç¾åœ¨ã®AIã‚·ã‚¹ãƒ†ãƒ ã¯æ„è­˜çš„ã§ã¯ãªã„ãŒã€æ„è­˜çš„ãªAIã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®éšœå£ã¯å­˜åœ¨ã—ãªã„ã“ã¨ã‚’ç¤ºå”†ã™ã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2023-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1008" target="_blank" rel="noopener noreferrer" class="title-link">Self-Alignment with Instruction Backtranslation, Xian Li+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€é«˜å“è³ªãªæŒ‡ç¤ºã«å¾“ã†è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªæ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã§ã¯ã€å°‘é‡ã®ã‚·ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã¨ã‚¦ã‚§ãƒ–ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€æŒ‡ç¤ºã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚ãã—ã¦ã€é«˜å“è³ªãªä¾‹ã‚’é¸æŠã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å¼·åŒ–ã—ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã€è‡ªå·±æ•´åˆ—ã®åŠ¹æœã‚’å®Ÿè¨¼ã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>äººé–“ãŒæ›¸ã„ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å¯¾å¿œã™ã‚‹instructionã«è‡ªå‹•çš„ã«ãƒ©ãƒ™ãƒ«ä»˜ã‘ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚<br>ã“ã‚Œã«ã‚ˆã‚Šé«˜å“è³ªãªinstruction following LLMã®æ§‹ç¯‰ãŒå¯èƒ½</p>
<p>æ‰‹æ³•æ¦‚è¦<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/837e17cc-6df1-4ba5-ba61-9c4f72dede93" alt="image" loading="lazy"></p>
<p>çµæœçš„ã«å¾—ã‚‰ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã¯ã€è¨“ç·´ã«ãŠã„ã¦éå¸¸ã«ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒã‚ã‚Šé«˜å“è³ªãªã‚‚ã®ã¨ãªã‚‹ã€‚<br>å®Ÿéš›ã«ã€ä»–ã®åŒã‚µã‚¤ã‚ºã®instruct tuningãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä¸Šå›ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ef478922-8495-4a5f-9bc6-3d5bed7195a8" alt="image" loading="lazy"></p>
<p>Humpackã¯ä»–ã®strong modelã‹ã‚‰distillã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§æœ€é«˜æ€§èƒ½ã‚’é”æˆã€‚ã“ã‚Œã¯ã€ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã—ãŸã‚Šã€ã‚ˆã‚Šå¼·ã„ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†ãªã©ã•ã‚‰ãªã‚‹æ€§èƒ½å‘ä¸ŠãŒã§ãã‚‹ä½™åœ°ãŒæ®‹ã•ã‚Œã¦ã„ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cd7ff8b5-62a4-46fe-a902-cbe8e9ffec4a" alt="image" loading="lazy"></p>
<p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1694103441432580377?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>æŒ‡ç¤ºã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ã€ä»Šå›ã¯LLaMAã‚’finetuningã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãŠã‚Šã€äºˆæ¸¬ã¨å‘¼ç§°ã—ã¦ã„ã‚‹ãŒæŒ‡ç¤ºã¯generationã•ã‚Œã‚‹ã€‚</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/PersonalizedGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedGeneration</a>
<span class="issue_date">Issue Date: 2023-08-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1005" target="_blank" rel="noopener noreferrer" class="title-link">Teach LLMs to Personalize -- An Approach inspired by Writing Education, Cheng Li+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å€‹åˆ¥åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ãŠã„ã¦ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ãŸä¸€èˆ¬çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã™ã‚‹ã€‚æ•™è‚²ã®åŸ·ç­†ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€å¤šæ®µéšã‹ã¤ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é–‹ç™ºã—ã€æ¤œç´¢ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€è¦ç´„ã€çµ±åˆã€ç”Ÿæˆã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§æ§‹æˆã•ã‚Œã‚‹å€‹åˆ¥åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã¸ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã™ã‚‹ã€‚ã•ã‚‰ã«ã€ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯è¨­å®šã‚’å°å…¥ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®ç”Ÿæˆèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚3ã¤ã®å…¬é–‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®è©•ä¾¡çµæœã¯ã€ä»–ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«æ¯”ã¹ã¦å¤§å¹…ãªæ”¹å–„ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç ”ç©¶ã®ç›®çš„ã¨ã—ã¦ã¯ã€ãƒ¦ãƒ¼ã‚¶ãŒç¾åœ¨åŸ·ç­†ã—ã¦ã„ã‚‹documentã®writingæ”¯æ´</p></span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1001" target="_blank" rel="noopener noreferrer" class="title-link">ReazonSpeech: A Free and Massive Corpus for Japanese ASR, Yin+, NLP'23</a>
<span class="snippet"><span>Comment</span><p>


<a href="https://prtimes.jp/main/html/rd/p/000000003.000102162.html" target="_blank" rel="noopener noreferrer">https://prtimes.jp/main/html/rd/p/000000003.000102162.html</a>


</p>
<p>è¶…é«˜ç²¾åº¦ã§å•†ç”¨åˆ©ç”¨å¯èƒ½ãªç´”å›½ç”£ã®æ—¥æœ¬èªéŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã€ŒReazonSpeechã€ã‚’ç„¡å„Ÿå…¬é–‹<br><br>ãƒ¯ãƒ³ã‚»ã‚°ã®ãƒ‡ãƒ¼ã‚¿ã«ã‹ã‚‰ç”Ÿæˆ</p>
<p>ãƒ©ã‚¤ãƒ–ãƒ©ãƒª:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sloth65557166/status/1952942596055314450?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LM-based.html" target="_blank" rel="noopener noreferrer">#LM-based</a>
<a class="button" href="articles/Coherence.html" target="_blank" rel="noopener noreferrer">#Coherence</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/967" target="_blank" rel="noopener noreferrer" class="title-link">DiscoScore: Evaluating Text Generation with BERT and Discourse Coherence, Wei Zhao+, N_A, EACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ–‡ç« ã®ä¸€è²«æ€§ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„æŒ‡æ¨™ã§ã‚ã‚‹DiscoScoreã‚’ç´¹ä»‹ã—ã¾ã™ã€‚DiscoScoreã¯Centeringç†è«–ã«åŸºã¥ã„ã¦ãŠã‚Šã€BERTã‚’ä½¿ç”¨ã—ã¦è«‡è©±ã®ä¸€è²«æ€§ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¾ã™ã€‚å®Ÿé¨“ã®çµæœã€DiscoScoreã¯ä»–ã®æŒ‡æ¨™ã‚ˆã‚Šã‚‚äººé–“ã®è©•ä¾¡ã¨ã®ç›¸é–¢ãŒé«˜ãã€ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã§ã®è©•ä¾¡ã§ã‚‚å„ªã‚ŒãŸçµæœã‚’ç¤ºã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€DiscoScoreã®é‡è¦æ€§ã¨ãã®å„ªä½æ€§ã«ã¤ã„ã¦ã‚‚èª¬æ˜ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/937" target="_blank" rel="noopener noreferrer" class="title-link">RISE: Leveraging Retrieval Techniques for Summarization Evaluation, David Uthus+, N_A, Findings of ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå‹•è¦ç´„ã®è©•ä¾¡ã¯å›°é›£ã§ã‚ã‚Šã€å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯äººé–“ã®è©•ä¾¡ã«ã¯åŠã°ãªã„ã€‚ãã“ã§ã€ç§ãŸã¡ã¯RISEã¨ã„ã†æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã™ã‚‹ã€‚RISEã¯æƒ…å ±æ¤œç´¢ã®æŠ€è¡“ã‚’æ´»ç”¨ã—ã€ã‚´ãƒ¼ãƒ«ãƒ‰ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã®è¦ç´„ãŒãªãã¦ã‚‚è¦ç´„ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚RISEã¯ç‰¹ã«è©•ä¾¡ç”¨ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹è¦ç´„ãŒåˆ©ç”¨ã§ããªã„æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é©ã—ã¦ãŠã‚Šã€SummEvalãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®å®Ÿé¨“çµæœã‹ã‚‰ã€RISEã¯éå»ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨æ¯”è¼ƒã—ã¦äººé–“ã®è©•ä¾¡ã¨é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€RISEã¯ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡æ€§ã¨è¨€èªé–“ã®æ±ç”¨æ€§ã‚‚ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>
<strong># æ¦‚è¦<br><br>Dual-Encoderã‚’ç”¨ã„ã¦ã€ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã‚·ã‚¹ãƒ†ãƒ è¦ç´„ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€dot productã‚’ã¨ã‚‹ã“ã¨ã§ã‚¹ã‚³ã‚¢ã‚’å¾—ã‚‹æ‰‹æ³•ã€‚ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¯ã€Contrastive Learningã§è¡Œã„ã€æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚½ãƒ¼ã‚¹ã¨å‚ç…§è¦ç´„ã®ãƒšã‚¢ã‚’æ­£ä¾‹ã¨ã¿ãªã—ã€In Batch trainingã™ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/95d6fc9e-cb05-4a40-9690-ac40e6042c3c" alt="image" loading="lazy"><br><br><br><br># åˆ†é¡<br><br>Reference-free, Model-based, ã‚½ãƒ¼ã‚¹ä¾å­˜ã§ã€BARTScore <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/960" target="_blank" rel="noopener noreferrer">BARTSCORE: Evaluating Generated Text as Text Generation, Yuan+ (w/ Neubigæ°), NeurIPS'21</a>
</strong>
<br>
 ã¨ã¯ç•°ãªã‚Šã€æ–‡æ›¸è¦ç´„ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦å­¦ç¿’ã™ã‚‹ãŸã‚ã€è¦ç´„ã®è©•ä¾¡ã«ç‰¹åŒ–ã—ã¦ã„ã‚‹ç‚¹ãŒç‰¹å¾´ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/281a2e5d-7e1c-466d-a995-97218ca37983" alt="image" loading="lazy"><br><br><br><br>
<strong># ãƒ¢ãƒ‡ãƒ«<br><br>##  Contrastive Learning<br><br>Contrastive Learningã‚’ç”¨ã„ã€hard negativeã‚’ç”¨ã„ãŸvariantã‚‚æ¤œè¨¼ã™ã‚‹ã€‚ã¾ãŸã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦3ç¨®é¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œè¨¼ã™ã‚‹ï¼š<br><br>1. in-domain data: æ–‡æ›¸è¦ç´„ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦è¨“ç·´ã—ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚¿ã‚¹ã‚¯ã§ã©ã‚Œã ã‘ã®æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã‹ã‚’è¦‹ã‚‹<br><br>2. out-of-domain data: æ–‡æ›¸è¦ç´„ä»¥å¤–ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦è¨“ç·´ã—ã€ã©ã‚Œã ã‘æ–°ã—ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ãƒ¢ãƒ‡ãƒ«ãŒtransferã§ãã‚‹ã‹ã‚’æ¤œè¨¼ã™ã‚‹<br><br>3. in-and-out-domain data: ä¸¡æ–¹ã‚„ã‚‹<br><br><br><br>## ãƒãƒ¼ãƒ‰ãƒã‚¬ãƒ†ã‚£ãƒ–ã®ç”Ÿæˆ<br><br>Lexical Negatives, Model Negatives, åŒæ–¹ã®çµ„ã¿åˆã‚ã›ã®3ç¨®é¡ã‚’ç”¨ã„ã¦ãƒãƒ¼ãƒ‰ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚’ç”Ÿæˆã™ã‚‹ã€‚<br><br>### Lexical Negatives<br><br>å‚ç…§è¦ç´„ã‚’æ‹¡å¼µã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ç”Ÿæˆã™ã‚‹ã€‚ç›®çš„ã¯ã€ã‚‚ã¨ã‚‚ã¨ã®å‚ç…§è¦ç´„ã¨æ¯”è¼ƒã—ã¦ã€poor summaryã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã«ã‚ã‚‹ã€‚Data Augmentationã¨ã—ã¦ã€ä»¥ä¸‹ã®æ–¹æ³•ã‚’è©¦ã—ãŸï¼š<br><br>- Swapping noun entities:  è¦ç´„ä¸­ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ã€ã‚½ãƒ¼ã‚¹ä¸­ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ³ã¨ãƒ©ãƒ³ãƒ€ãƒ ã§ã‚¹ãƒ¯ãƒƒãƒ—<br><br>- Shuffling words: è¦ç´„ä¸­ã®å˜èªã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«<br><br>- Dropping words: è¦ç´„ä¸­ã®å˜èªã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å‰Šé™¤<br><br>- Dropping characters: è¦ç´„ä¸­ã®æ–‡å­—ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å‰Šé™¤<br><br>- Swapping antonyms: è¦ç´„ä¸­ã®å˜èªã‚’å¯¾ç¾©èªã§ç½®æ›<br><br>### Model Negatives<br><br>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸­ã‹ã‚‰è² ä¾‹ã‚’æŠ½å‡ºã™ã‚‹ã€‚ç›®çš„ã¯ã€å‚ç…§è¦ç´„ã¨é¡ä¼¼ã—ã¦ã„ã‚‹ãŒã€è² ä¾‹ã¨ãªã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ã€‚ã“ã‚Œã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ã¾ãšRISE modelã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§finetuningã—ã€ãã‚Œãã‚Œã®ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è¦ç´„ã«å¯¾ã—ã¦ã€é¡ä¼¼ã—ãŸè¦ç´„ã‚’ãƒã‚¤ãƒ‹ãƒ³ã‚°ã™ã‚‹ã€‚ã™ã¹ã¦ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨è¦ç´„ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€top-nã®æœ€ã‚‚é¡ä¼¼ã—ãŸè¦ç´„ã‚’è¦‹ã¤ã‘ã€ã“ã‚Œã‚’ãƒãƒ¼ãƒ‰ãƒã‚¬ãƒ†ã‚£ãƒ–ã¨ã—ã¦ã€å†åº¦ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã€‚<br><br>### ä¸¡è€…ã®çµ„ã¿åˆã‚ã›<br><br>ã¾ãšlexical negativesã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€ãƒ¢ãƒ‡ãƒ«ãƒã‚¬ãƒ†ã‚£ãƒ–ã®æŠ½å‡ºã«æ´»ç”¨ã™ã‚‹ã€‚æŠ½å‡ºã—ãŸãƒ¢ãƒ‡ãƒ«ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚’ç”¨ã„ã¦å†åº¦ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã“ã¨ã§ã€æœ€çµ‚çš„ãªãƒ¢ãƒ‡ãƒ«ã¨ã™ã‚‹ã€‚<br><br><br><br># å®Ÿé¨“<br><br>## å­¦ç¿’æ‰‹æ³•<br><br>SummEval <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/984" target="_blank" rel="noopener noreferrer">SummEval: Re-evaluating Summarization Evaluation, Fabbri+, TACL'21</a>
</strong>
<br>
 ã‚’ç”¨ã„ã¦äººæ‰‹è©•ä¾¡ã¨æ¯”è¼ƒã—ã¦ã©ã‚Œã ã‘correlationãŒã‚ã‚‹ã‹ã‚’æ¤œè¨¼ã€‚SummEvalã«ã¯16ç¨®é¡ã®ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã«å¯¾ã™ã‚‹ã€CNN / Daily Mail ã®100 examplesã«å¯¾ã—ã¦ã€å“è³ªã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãŒä»˜ä¸ã•ã‚Œã¦ã„ã‚‹ã€‚expert annotationã‚’ç”¨ã„ã¦ã€Kendall's tauã‚’ç”¨ã„ã¦ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã®correlationã‚’è¨ˆç®—ã—ãŸã€‚contextãŒçŸ­ã„å ´åˆã¯T5, é•·ã„å ´åˆã¯LongT5, ã‚¿ã‚¹ã‚¯ãŒãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãªå ´åˆã¯mT5ã‚’ç”¨ã„ã¦è¨“ç·´ã—ãŸã€‚è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã¯<br><br>- CNN / Daily Mail<br><br>- Multi News<br><br>- arXiv<br><br>- PubMed<br><br>- BigPatent<br><br>- SAMSum<br><br>- Reddit TIFU<br><br>- MLSUM<br><br>ç­‰ã‚’ç”¨ã„ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šshort / long contextã®ä¸¡è€…ã‚’ã‚«ãƒãƒ¼ã§ãã‚‹ã€‚CNN / Daily Mail, Reddiit TIFU, Multi-Newsã¯short-context, arXiv, PubMed, BigPatent, Multi-Newsï¼ˆé•·æ–‡ã®ã‚‚ã®ã‚’åˆ©ç”¨ï¼‰ã¯longer contextã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã€‚<br><br>## æ¯”è¼ƒã™ã‚‹ãƒ¡ãƒˆãƒªãƒƒã‚¯<br><br>ROUGE, chrF, SMS, BARTScore, SMART, BLEURT, BERTScore, Q^2, T5-ANLI, PRISMã¨æ¯”è¼ƒã—ãŸã€‚çµæœã‚’ã¿ã‚‹ã¨ã€Consistency, Fluency, Relevanceã§ä»–æ‰‹æ³•ã‚ˆã‚Šã‚‚é«˜ã„ç›¸é–¢ã‚’å¾—ãŸã€‚Averageã§ã¯æœ€ã‚‚é«˜ã„Averageã‚’ç²å¾—ã—ãŸã€‚in-domain dataã§è¨“ç·´ã—ãŸå ´åˆã¯ã€é«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã—ãŸã€‚our-of-domainï¼ˆSAMSum; Dialogueè¦ç´„ã®ãƒ‡ãƒ¼ã‚¿ï¼‰ãƒ‡ãƒ¼ã‚¿ã§ã‚‚é«˜ã„æ€§èƒ½ã‚’å¾—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/92960d58-cd13-4ff5-a417-dda9785520e4" alt="image" loading="lazy"><br><br><br><br></p>
<p># Ablation<br><br>## ãƒãƒ¼ãƒ‰ãƒã‚¬ãƒ†ã‚£ãƒ–ã®ç”Ÿæˆæ–¹æ³•<br><br>Data Augmentationã¯ã€swapping entity nouns, randomly dropping wordsã®çµ„ã¿åˆã‚ã›ãŒæœ€ã‚‚è‰¯ã‹ã£ãŸã€‚ã¾ãŸã€Lexical Negativesã¯ã€æ§˜ã€…ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ä¸€è²«ã—ã¦æ€§èƒ½ãŒè‰¯ã‹ã£ãŸãŒã€Model Negativesã¯CNN/DailyMailã«å¯¾ã—ã¦ã—ã‹æœ‰åŠ¹ã§ã¯ãªã‹ã£ãŸã€‚ã“ã‚Œã¯ãŠãã‚‰ãã€åŒã˜ã‚¿ã‚¹ã‚¯ï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨åŒã˜ãƒ‡ãƒ¼ã‚¿ï¼‰ã§ãªã„ã¨ã€Model Negativesã¯æ©Ÿèƒ½ã—ãªã„ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚ãŸã ã—ã€Model Negativesã‚’å…¥ã‚ŒãŸã‚‰ã€ä½•ã‚‚ã—ãªã„ã‚ˆã‚Šã‚‚æ€§èƒ½å‘ä¸Šã™ã‚‹ã‹ã‚‰ã€ä½•ã‚‰ã‹ã®ç†ç”±ã§lexical negativesãŒç”Ÿæˆã§ããªã„å ´åˆã¯ã“ã£ã¡ä½¿ã£ã¦ã‚‚æœ‰ç”¨ã§ã‚ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ebb9a6b9-3293-4139-b8a3-620cd72fff5a" alt="image" loading="lazy"><br><br><br><br>## Model Size<br><br>ã§ã‹ã„æ–¹ãŒè‰¯ã„ã€‚in-domainãªã‚‰Baseã§ã‚‚ãã‚Œãªã‚Šã®æ€§èƒ½ã ã‘ã©ã€çµå±€LARGEã®æ–¹ãŒå¼·ã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a53e9b98-77aa-4faf-ba58-4900611ca066" alt="image" loading="lazy"><br><br><br><br>## Datasets<br><br>ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚transferãŒã†ã¾ãæ©Ÿèƒ½ã—ã¦ã„ã‚‹ã€‚é©šã„ãŸã“ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’mixingã™ã‚‹ã¨ã‚ã¾ã‚Šã†ã¾ãã„ã‹ãšã€å˜ä½“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã—ãŸã»ã†ãŒæ€§èƒ½ãŒè‰¯ã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/635c0b43-2db3-4561-8939-e4b1de733e99" alt="image" loading="lazy"><br><br><br><br>LongT5ã‚’è¦‹ã‚‹ã¨ã€T5ã‚ˆã‚Šã‚‚CorrelationãŒä½ãé›£æ˜“åº¦ãŒé«˜ã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/31420a09-eb36-41ef-ad41-6eaf93d1823d" alt="image" loading="lazy"><br><br><br><br>æœ€çµ‚çš„ã«è‹±èªã®è¦ç´„ã‚’è©•ä¾¡ã‚’ã™ã‚‹å ´åˆã§ã‚‚ã€Multilingualï¼ˆåˆ¥è¨€èªï¼‰ã§è¨“ç·´ã—ã¦ã‚‚é«˜ã„Correlationã‚’ç¤ºã™ã“ã¨ã‚‚ã‚ã‹ã£ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a74d86b8-64bd-40b1-b22b-344588ef0580" alt="image" loading="lazy"><br><br><br><br>## Dataset Size<br><br>ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°ã•ãã¦ã‚‚æœ‰åŠ¹ã«åƒãã€‚ã—ã‹ã—ã€out-domainã®ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯ã€ãŸã¨ãˆã°ã€512ä»¶ã®å ´åˆã¯æ€§èƒ½ãŒä½ãå°‘ã—exampleã‚’å¢—ã‚„ã•ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3117b6aa-5d0f-4970-9f30-247633d21f67" alt="image" loading="lazy"><br><br><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/935" target="_blank" rel="noopener noreferrer" class="title-link">GPTScore: Evaluate as You Desire, Jinlan Fu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ç”Ÿæˆå‹AIã®è©•ä¾¡ã«ãŠã‘ã‚‹èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€GPTScoreã¨ã„ã†è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚GPTScoreã¯ã€ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€ç”Ÿæˆå‹äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ–°ãŸãªèƒ½åŠ›ã‚’æ´»ç”¨ã—ã¦ã„ã¾ã™ã€‚19ã®äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’æ¢ç´¢ã—ã€4ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¿ã‚¹ã‚¯ã¨22ã®è©•ä¾¡é …ç›®ã«å¯¾ã—ã¦å®Ÿé¨“ã‚’è¡Œã„ã¾ã—ãŸã€‚çµæœã¯ã€GPTScoreãŒè‡ªç„¶è¨€èªã®æŒ‡ç¤ºã ã‘ã§ãƒ†ã‚­ã‚¹ãƒˆã®è©•ä¾¡ã‚’åŠ¹æœçš„ã«å®Ÿç¾ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã“ã®è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€æ³¨é‡ˆä»˜ãã‚µãƒ³ãƒ—ãƒ«ã®å¿…è¦æ€§ã‚’ãªãã—ã€ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã•ã‚ŒãŸå¤šé¢çš„ãªè©•ä¾¡ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>BERTScoreã¨åŒæ§˜ã€è©•ä¾¡ã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆã®å¯¾æ•°å°¤åº¦ã§è©•ä¾¡ã—ã¦ã„ã‚‹<br>BERTScoreã‚ˆã‚Šã‚‚ç›¸é–¢ãŒé«˜ãã€instructionã«ã‚ˆã£ã¦æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/934" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models are Diverse Role-Players for Summarization  Evaluation, Ning Wu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã®è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã¨å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆã‚’å®¢è¦³çš„ãŠã‚ˆã³ä¸»è¦³çš„ãªå´é¢ã‹ã‚‰æ¯”è¼ƒã™ã‚‹ã“ã¨ã§åŒ…æ‹¬çš„ãªè©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã®è©•ä¾¡ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å°å…¥ã—ã¦å‹•çš„ãªãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã•ã‚‰ã«ã€ãƒãƒƒãƒãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã«åŸºã¥ã„ãŸãƒãƒ«ãƒãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æŠ€è¡“ã‚’ä½¿ç”¨ã—ã¦è¤‡æ•°ã®è©•ä¾¡çµæœã‚’çµ±åˆã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ææ¡ˆãƒ¢ãƒ‡ãƒ«ãŒç«¶äº‰åŠ›ãŒã‚ã‚Šã€äººé–“ã®è©•ä¾¡è€…ã¨é«˜ã„ä¸€è‡´æ€§ã‚’æŒã¤ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/933" target="_blank" rel="noopener noreferrer" class="title-link">ChatGPT as a Factual Inconsistency Evaluator for Text Summarization, Zheheng Luo+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã®æ€§èƒ½å‘ä¸ŠãŒæ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ãŒã€ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ãŒå…ƒã®æ–‡æ›¸ã¨çŸ›ç›¾ã™ã‚‹ã“ã¨ãŒå•é¡Œã¨ãªã£ã¦ã„ã‚‹ã€‚ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€åŠ¹æœçš„ãªäº‹å®Ÿæ€§è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®é–‹ç™ºãŒé€²ã‚ã‚‰ã‚Œã¦ã„ã‚‹ãŒã€è¨ˆç®—è¤‡é›‘æ€§ã‚„ä¸ç¢ºå®Ÿæ€§ã®åˆ¶ç´„ãŒã‚ã‚Šã€äººé–“ã®åˆ¤æ–­ã¨ã®ä¸€è‡´ã«é™å®šã•ã‚Œã¦ã„ã‚‹ã€‚æœ€è¿‘ã®ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ãŒãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã¨è¨€èªç†è§£ã®ä¸¡æ–¹ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã£ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ChatGPTã®äº‹å®Ÿçš„ãªçŸ›ç›¾è©•ä¾¡èƒ½åŠ›ã‚’è©•ä¾¡ã—ã€ãƒã‚¤ãƒŠãƒªã‚¨ãƒ³ãƒ†ã‚¤ãƒ«ãƒ¡ãƒ³ãƒˆæ¨è«–ã€è¦ç´„ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ä¸€è²«æ€§è©•ä¾¡ãªã©ã®ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ãŸã ã—ã€ChatGPTã«ã¯èªå½™çš„ãªé¡ä¼¼æ€§ã®å‚¾å‘ã‚„èª¤ã£ãŸæ¨è«–ã€æŒ‡ç¤ºã®ä¸é©åˆ‡ãªç†è§£ãªã©ã®åˆ¶é™ãŒã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/931" target="_blank" rel="noopener noreferrer" class="title-link">Metacognitive Prompting Improves Understanding in Large Language Models, Yuqing Wang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMsã«ãƒ¡ã‚¿èªçŸ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆMPï¼‰ã‚’å°å…¥ã—ã€äººé–“ã®å†…çœçš„ãªæ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ¨¡å€£ã™ã‚‹ã“ã¨ã§ã€ç†è§£èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€MPã‚’å‚™ãˆãŸPaLMãŒä»–ã®ãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¦ãŠã‚Šã€MPãŒæ—¢å­˜ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€LLMsã®ç†è§£èƒ½åŠ›å‘ä¸Šã®å¯èƒ½æ€§ã‚’ç¤ºã—ã€äººé–“ã®å†…çœçš„ãªæ¨è«–ã‚’æ¨¡å€£ã™ã‚‹ã“ã¨ã®åˆ©ç‚¹ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>CoTã‚ˆã‚Šä¸€è²«ã—ã¦æ€§èƒ½ãŒé«˜ã„ã®ã§æ¬¡ã®ãƒ‡ãƒ•ã‚¡ã‚¯ãƒˆã«ãªã‚‹å¯èƒ½æ€§ã‚ã‚Š<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8ca3a369-925b-44be-9d63-e3150137ff6b" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d3b980e0-4402-4a32-96ee-684da7f3a487" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/AutoML.html" target="_blank" rel="noopener noreferrer">#AutoML</a>
<span class="issue_date">Issue Date: 2023-08-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/926" target="_blank" rel="noopener noreferrer" class="title-link">MLCopilot: Unleashing the Power of Large Language Models in Solving  Machine Learning Tasks, Lei Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã‚¿ã‚¹ã‚¯ã®è‡ªå‹•åŒ–ã«ãŠã‘ã‚‹äººé–“ã®çŸ¥è­˜ã¨æ©Ÿæ¢°çŸ¥èƒ½ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã«ã€æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯MLCopilotã‚’ææ¡ˆã™ã‚‹ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€æœ€å…ˆç«¯ã®LLMsã‚’ä½¿ç”¨ã—ã¦æ–°ã—ã„MLã‚¿ã‚¹ã‚¯ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹ç™ºã—ã€æ—¢å­˜ã®MLã‚¿ã‚¹ã‚¯ã®çµŒé¨“ã‹ã‚‰å­¦ã³ã€åŠ¹æœçš„ã«æ¨è«–ã—ã¦æœ‰æœ›ãªçµæœã‚’æä¾›ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ç”Ÿæˆã•ã‚ŒãŸã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã¯ç›´æ¥ä½¿ç”¨ã—ã¦ç«¶äº‰åŠ›ã®ã‚ã‚‹çµæœã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</span>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/923" target="_blank" rel="noopener noreferrer" class="title-link">The Hydra Effect: Emergent Self-repair in Language Model Computations, Thomas McGrath+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨æ§‹é€ ã‚’èª¿æŸ»ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®è¨ˆç®—ã«ãŠã‘ã‚‹ç‰¹å®šã®åŠ¹æœã‚’ç¤ºã—ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€1ã¤ã®å±¤ã®å‰Šé™¤ãŒä»–ã®å±¤ã«ã‚ˆã£ã¦è£œå®Œã•ã‚Œã‚‹ã€ŒHydraåŠ¹æœã€ã¨ã€é…ã„MLPå±¤ãŒæœ€å¤§å°¤åº¦ãƒˆãƒ¼ã‚¯ãƒ³ã‚’åˆ¶å¾¡ã™ã‚‹å½¹å‰²ã‚’æŒã¤ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’ä½¿ç”¨ã—ãªã„è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚‚åŒæ§˜ã®åŠ¹æœãŒè¦‹ã‚‰ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã“ã‚Œã‚‰ã®åŠ¹æœã‚’äº‹å®Ÿã®å›æƒ³ã®æ–‡è„ˆã§åˆ†æã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®å›è·¯ãƒ¬ãƒ™ãƒ«ã®å±æ€§ä»˜ä¸ã«ã¤ã„ã¦è€ƒå¯Ÿã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã‹ã‚‰attention layerã‚’ä¸€ã¤å–ã‚Šé™¤ãã¨ã€å¾Œç¶šã®å±¤ãŒå–ã‚Šé™¤ã‹ã‚ŒãŸlayerã®æ©Ÿèƒ½ã‚’å¼•ãç¶™ãã‚ˆã†ãªåƒãã‚’ã™ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã“ã‚Œã¯LLMã®è‡ªå·±ä¿®å¾©æ©Ÿèƒ½ã®ã‚ˆã†ãªã‚‚ã®ã§ã‚ã‚Šã€HydraEffectã¨å‘½åã•ã‚ŒãŸã€‚</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/922" target="_blank" rel="noopener noreferrer" class="title-link">MetaGPT: Meta Programming for Multi-Agent Collaborative Framework, Sirui Hong+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ãŸãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è‡ªå‹•ã‚¿ã‚¹ã‚¯è§£æ±ºã«ãŠã‘ã‚‹é€²æ­©ã«ã¤ã„ã¦èª¿æŸ»ã—ã¾ã—ãŸã€‚æ—¢å­˜ã®ç ”ç©¶ã§ã¯å˜ç´”ãªã‚¿ã‚¹ã‚¯ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹æ¢ç´¢ã‚„èª¿æŸ»ãŒä¸è¶³ã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ãã“ã§ã€MetaGPTã¨ã„ã†é©æ–°çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚MetaGPTã¯ã€äººé–“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’LLMã«çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å”åŠ›ã‚’åŠ¹æœçš„ã«æ”¯æ´ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã‹ã‚‰ã€MetaGPTãŒæ—¢å­˜ã®ã‚·ã‚¹ãƒ†ãƒ ã«æ¯”ã¹ã¦ã‚ˆã‚Šé«˜ã„çµæŸæ€§ã‚’æŒã¤è§£æ±ºç­–ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã“ã‚Œã¯ã€ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«äººé–“ã®ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã®æ½œåœ¨èƒ½åŠ›ã‚’ç¤ºã—ã€æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å¯èƒ½æ€§ã‚’é–‹æ‹“ã™ã‚‹ã‚‚ã®ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>è¦ã¯BabyTalk, AutoGPTã®é€²åŒ–ç³»ã§ã€äººé–“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ¨¡å€£ã™ã‚‹ã‚ˆã†ã«ãƒ‡ã‚¶ã‚¤ãƒ³ã—ãŸã‚‰è‰¯ããªã‚Šã¾ã—ãŸã€ã¨ã„ã†è©±ã¨æ€ã‚ã‚Œã‚‹<br><br>ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆã€ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã‚ªãƒ¼ãƒŠãƒ¼ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãªã©ã®ãƒ­ãƒ¼ãƒ«ã‚’æ˜ç¤ºçš„ã«ä¸ãˆã¦ã€ã‚´ãƒ¼ãƒ«ã‚’ç›®æŒ‡ã™ã€‚ã‚‚ã¯ã‚„LLMå†…éƒ¨ã§ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ä¼æ¥­ã‚’æ¨¡å€£ã—ã¦ã„ã‚‹ã®ã¨åŒæ§˜ã§ã‚ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/921" target="_blank" rel="noopener noreferrer" class="title-link">Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding, Xuefei Ning+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ç”Ÿæˆé…å»¶ã‚’æ¸›ã‚‰ã™ãŸã‚ã«ã€æ€è€ƒã®éª¨çµ„ã¿ï¼ˆSoTï¼‰ã¨ã„ã†æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚SoTã¯ã€å›ç­”ã®éª¨çµ„ã¿ã‚’ã¾ãšç”Ÿæˆã—ã€ãã®å¾Œã«å†…å®¹ã‚’ä¸¦åˆ—ã§å‡¦ç†ã™ã‚‹ã“ã¨ã§é«˜é€ŸåŒ–ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ã¾ãŸã€å›ç­”å“è³ªã®å‘ä¸Šã‚‚æœŸå¾…ã•ã‚Œã¾ã™ã€‚SoTã¯ãƒ‡ãƒ¼ã‚¿ä¸­å¿ƒã®æœ€é©åŒ–ã®åˆã‚ã®è©¦ã¿ã§ã‚ã‚Šã€LLMsã®äººé–“ã‚‰ã—ã„æ€è€ƒã‚’å¯èƒ½ã«ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æœ€åˆã«å›ç­”ã®æ çµ„ã¿ã ã‘ç”Ÿæˆã—ã¦ã€ãã‚Œãã‚Œã®å†…å®¹ã‚’ä¸¦åˆ—ã§å‡ºåŠ›ã•ã›ã‚‹ã“ã¨ã§ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’é«˜é€ŸåŒ–ã—ã¾ã—ã‚‡ã†ã€ã¨ã„ã†è©±ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fb25d8ba-dff7-4f6f-be25-0973488f6e8a" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/920" target="_blank" rel="noopener noreferrer" class="title-link">ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world  APIs, Yujia Qin+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ï¼ˆAPIï¼‰ã®é«˜åº¦ãªã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œã‚’å®¹æ˜“ã«ã™ã‚‹ãŸã‚ã®ToolLLMã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚ToolBenchã¨ã„ã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã€ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨æ–¹æ³•ã‚’èª¿æ•´ã—ã€DFSDTã¨ã„ã†æ±ºå®šæœ¨ã‚’ä½¿ç”¨ã—ã¦åŠ¹ç‡çš„ãªæ¤œç´¢ã‚’è¡Œã„ã¾ã™ã€‚ToolEvalã¨ã„ã†è‡ªå‹•è©•ä¾¡ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€ToolLLaMAãŒé«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ã•ã‚‰ã«ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«APIãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã€é©åˆ‡ãªAPIã‚’æ¨å¥¨ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>16000ã®real worldã®APIã¨ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã—ã€ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã€è¨“ç·´ã€è©•ä¾¡ãªã©ã‚’ä¸€è²«ã—ã¦ã§ãã‚‹ã‚ˆã†ã«ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚LLaMAã‚’ä½¿ã£ãŸå ´åˆã€ãƒ„ãƒ¼ãƒ«åˆ©ç”¨ã«é–¢ã—ã¦turbo-16kã¨åŒç­‰ã®æ€§èƒ½ã«é”ã—ãŸã¨ä¸»å¼µã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a9c394b5-6148-4bab-acaa-4934ead5c1a7" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/916" target="_blank" rel="noopener noreferrer" class="title-link">L-Eval: Instituting Standardized Evaluation for Long Context Language  Models, Chenxin An+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- é•·ã„æ–‡è„ˆã®è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLCLMï¼‰ã®è©•ä¾¡ã‚’æ¨™æº–åŒ–ã™ã‚‹ãŸã‚ã«ã€L-Evalã¨ã„ã†è©•ä¾¡ã‚¹ã‚¤ãƒ¼ãƒˆã‚’ææ¡ˆã—ã¾ã—ãŸã€‚L-Evalã«ã¯411ã®é•·ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨2,000ä»¥ä¸Šã®äººé–“ã«ã‚ˆã‚‹ã‚¯ã‚¨ãƒª-ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒšã‚¢ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€å¤šæ§˜ãªè©•ä¾¡æ–¹æ³•ã¨æŒ‡ç¤ºã‚¹ã‚¿ã‚¤ãƒ«ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã¯å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦é…ã‚Œã¦ã„ã¾ã™ãŒã€é€šå¸¸ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨æ¯”è¼ƒã—ã¦ã‚‚å°è±¡çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚LCLMã®ç”Ÿæˆçµæœã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>long contextã«å¯¾ã™ã‚‹LLMã®è©•ä¾¡ã‚»ãƒƒãƒˆã€‚411ã®long documentã«å¯¾ã™ã‚‹2kã®query-response pairã®ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã€‚æ³•å¾‹ã€fainance, school lectures, é•·æ–‡å¯¾è©±ã€å°èª¬ã€ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãªã©ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‹ã‚‰æˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-08-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/913" target="_blank" rel="noopener noreferrer" class="title-link">Do Multilingual Language Models Think Better in English?, Julen Etxaniz+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- self-translateã¯ã€ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ã®å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆç¿»è¨³èƒ½åŠ›ã‚’æ´»ç”¨ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚Šã€å¤–éƒ¨ã®ç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ ã®å¿…è¦æ€§ã‚’å…‹æœã™ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€self-translateãŒç›´æ¥æ¨è«–ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€éè‹±èªã®è¨€èªã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã•ã‚ŒãŸå ´åˆã«ã‚‚æœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ã‚³ãƒ¼ãƒ‰ã¯https://github.com/juletx/self-translateã§åˆ©ç”¨å¯èƒ½ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imai_eruel/status/1687735268311511040?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/65a44946-c82b-4895-9ce9-c48792e09b3e" alt="image" loading="lazy"><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/86ff0cbb-7fac-4ba2-bf11-652b80db0fe5" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-07-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/905" target="_blank" rel="noopener noreferrer" class="title-link">FrugalGPT: How to Use Large Language Models While Reducing Cost and  Improving Performance, Lingjiao Chen+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ä½¿ç”¨ã«ã¯é«˜ã„ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ãŸã‚ã€LLMsã®æ¨è«–ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã™ã‚‹ãŸã‚ã®3ã¤ã®æˆ¦ç•¥ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é©å¿œã€LLMã®è¿‘ä¼¼ã€LLMã®ã‚«ã‚¹ã‚±ãƒ¼ãƒ‰ï¼‰ã‚’ææ¡ˆã™ã‚‹ã€‚FrugalGPTã¨ã„ã†å…·ä½“çš„ãªæ‰‹æ³•ã‚’ç´¹ä»‹ã—ã€æœ€å¤§98ï¼…ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ã¨4ï¼…ã®ç²¾åº¦å‘ä¸Šã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã®æŒç¶šå¯èƒ½ãªä½¿ç”¨ãŒå¯èƒ½ã¨ãªã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>é™ã‚‰ã‚ŒãŸäºˆç®—ã®ä¸­ã§ã€ã„ã‹ã«è¤‡æ•°ã®LLM APIã‚’ä½¿ã„ã€å®‰ã„ã‚³ã‚¹ãƒˆã§é«˜ã„æ€§èƒ½ã‚’é”æˆã™ã‚‹ã‹ã‚’è¿½æ±‚ã—ãŸç ”ç©¶ã€‚<br><br>LLM Cascadeãªã©ã¯ã“ã®æ çµ„ã¿ã§ãªãã¦ã‚‚è‰²ã€…ã¨ä½¿ã„é“ãŒã‚ã‚Šãã†ã€‚Question Concatenationã¯å®Ÿè³ªBatch Promptingã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-07-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/903" target="_blank" rel="noopener noreferrer" class="title-link">Judging LLM-as-a-judge with MT-Bench and Chatbot Arena, Lianmin Zheng+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã‚’åˆ¤å®šè€…ã¨ã—ã¦ä½¿ç”¨ã—ã¦ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ã®è³ªå•ã«å¯¾ã™ã‚‹æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚LLMã®åˆ¶é™ã‚„å•é¡Œã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®è§£æ±ºç­–ã‚’ææ¡ˆã—ã€2ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§LLMã®åˆ¤å®šè€…ã¨äººé–“ã®å¥½ã¿ã®ä¸€è‡´ã‚’æ¤œè¨¼ã™ã‚‹ã€‚çµæœã¯ã€å¼·åŠ›ãªLLMåˆ¤å®šè€…ãŒäººé–“ã®å¥½ã¿ã¨ã‚ˆãä¸€è‡´ã—ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§èª¬æ˜å¯èƒ½ãªæ–¹æ³•ã§äººé–“ã®å¥½ã¿ã‚’è¿‘ä¼¼ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã•ã‚‰ã«ã€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨å¾“æ¥ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ç›¸è£œæ€§ã‚’ç¤ºã—ã€ã„ãã¤ã‹ã®ãƒãƒªã‚¢ãƒ³ãƒˆã‚’è©•ä¾¡ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>MT-Benchï¼ˆMTBenchï¼‰ã‚¹ã‚³ã‚¢ã¨ã¯ã€multi-turnã®QAã‚’å‡ºé¡Œã—ã€ãã®å›ç­”ã®è³ªã‚’GPT-4ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ãŸã‚¹ã‚³ã‚¢ã®ã“ã¨ã€‚<br><br>GPT-4ã®åˆ¤æ–­ã¨human expertã®åˆ¤æ–­ã¨ã®agreementã‚‚æ¤œè¨¼ã—ã¦ãŠã‚Šã€agreementã¯80%ä»¥ä¸Šã‚’é”æˆã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/20c7782d-8ffe-4328-8526-700e38df23b5" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9f0e1e3a-6b07-4bcc-be78-e42a1c5d2190" alt="image" loading="lazy"><br><br></p>
<p>`LLM-as-a-Judge` ã¨ã„ã†ç”¨èªã‚’æœ€åˆã«æå”±ã—ãŸã®ã‚‚æœ¬ç ”ç©¶ã¨ãªã‚‹ï¼ˆp.2å‚ç…§ï¼‰</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<span class="issue_date">Issue Date: 2023-07-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/897" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction  Tuning, Lili Yu+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- CM3Leonã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã®ç”Ÿæˆãƒ»è£œå®ŒãŒå¯èƒ½ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ«æ‹¡å¼µå‹ã®ãƒˆãƒ¼ã‚¯ãƒ³ãƒ™ãƒ¼ã‚¹ã®ãƒ‡ã‚³ãƒ¼ãƒ€ã‚’ä½¿ç”¨ã€‚CM3ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’åŸºã«ã€å¤šæ§˜ãªæŒ‡ç¤ºã‚¹ã‚¿ã‚¤ãƒ«ã§ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«å„ªã‚Œã€åˆã®ãƒ†ã‚­ã‚¹ãƒˆå°‚ç”¨ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é©å¿œã•ã‚ŒãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€‚é«˜å“è³ªãªå‡ºåŠ›ã‚’ç”Ÿæˆã™ã‚‹å¯¾ç…§çš„ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã‚’å°å…¥ã—ã€å°‘ãªã„è¨ˆç®—é‡ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚SFTå¾Œã¯ã€ç”»åƒç·¨é›†ã‚„ç”Ÿæˆã«ãŠã„ã¦é«˜ã„åˆ¶å¾¡æ€§ã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/PersonalizedGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedGeneration</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/PersonalizedHeadlineGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedHeadlineGeneration</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/893" target="_blank" rel="noopener noreferrer" class="title-link">Generating User-Engaging News Headlines, Cai+, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®è¦‹å‡ºã—ã‚’å€‹åˆ¥åŒ–ã™ã‚‹ãŸã‚ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°ã‚’çµ„ã¿è¾¼ã‚“ã æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–²è¦§å±¥æ­´ã«åŸºã¥ã„ã¦å€‹åˆ¥ã®ã‚·ã‚°ãƒãƒãƒ£ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å‰²ã‚Šå½“ã¦ã€ãã‚Œã‚’ä½¿ç”¨ã—ã¦è¦‹å‡ºã—ã‚’å€‹åˆ¥åŒ–ã™ã‚‹ã€‚å¹…åºƒã„è©•ä¾¡ã«ã‚ˆã‚Šã€ææ¡ˆã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒå¤šæ§˜ãªèª­è€…ã®ãƒ‹ãƒ¼ã‚ºã«å¿œãˆã‚‹å€‹åˆ¥ã®è¦‹å‡ºã—ã‚’ç”Ÿæˆã™ã‚‹åŠ¹æœã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>
<strong># ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³<br><br>æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¯æœªã ã«å…¨å“¡ã«åŒã˜ã‚‚ã®ãŒè¡¨ç¤ºã•ã‚Œã¦ãŠã‚Šã€ãƒ¦ãƒ¼ã‚¶ãŒè‡ªèº«ã®èˆˆå‘³ã¨ã®ã¤ãªãŒã‚Šã‚’æ­£ã—ãåˆ¤å®šã§ãã‚‹ã¨ã¯é™ã‚‰ãšã€æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®æœ‰ç”¨æ€§ã‚’å¦¨ã’ã‚‹ã®ã§ã€ãƒ¦ãƒ¼ã‚¶ã”ã¨ã«ç•°ãªã‚‹ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ãŸã€‚ãŸã ã—ã€ã‚¯ãƒªãƒƒã‚¯ãƒ™ã‚¤ãƒˆã¯é¿ã‘ã‚‹ã‚ˆã†ãªãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚<br><br><br><br># æ‰‹æ³•<br><br>1. Signature Phrase Identification<br><br>2. User Signature Selection<br><br>3. Signature-Oriented Headline Generation <br><br><br><br>## Signature Phrase Identification<br><br>ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¿ã‚¹ã‚¯ã«å¸°ç€ã•ã›ã‚‹ã€‚ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã€ã‚ã‚‹ã„ã¯ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’inputã•ã‚ŒãŸã¨ãã«ã€ã‚»ãƒŸã‚³ãƒ­ãƒ³åŒºåˆ‡ã‚Šã®Signature Phraseã‚’ç”Ÿæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã‚‹ã€‚ä»Šå›ã¯[KPTimes daasetã§pretrainingã•ã‚ŒãŸBART](


<a href="https://huggingface.co/ankur310794/bart-base-keyphrase-generation-kpTimes)%E3%82%92%E7%94%A8%E3%81%84%E3%81%9F%E3%80%82KPTimes%E3%81%AF%E3%80%81279k%E3%81%AE%E3%83%8B%E3%83%A5%E3%83%BC%E3%82%B9%E8%A8%98%E4%BA%8B%E3%81%A8%E3%80%81signature" target="_blank" rel="noopener noreferrer">https://huggingface.co/ankur310794/bart-base-keyphrase-generation-kpTimes)ã‚’ç”¨ã„ãŸã€‚KPTimesã¯ã€279kã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã¨ã€signature</a>


phraseã®ãƒšã‚¢ãŒå­˜åœ¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã§ã‚ã‚Šã€æœ¬ã‚¿ã‚¹ã‚¯ã«æœ€é©ã¨ã®ã“ã¨ã€‚<br><br><br><br>## User Signature Selection<br><br>ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆdã®Signature Phrases Z_dãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€ãƒ¦ãƒ¼ã‚¶ã®reading History H_uã«åŸºã¥ã„ã¦ã€top-kã®user signature phrasesã‚’é¸æŠã™ã‚‹ã€‚H_uã¯ãƒ¦ãƒ¼ã‚¶ãŒèª­ã‚“ã ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã®é›†åˆã§è¡¨ç¾ã•ã‚Œã‚‹ã€‚ã‚ã‚‹Signature Phrase z_i âˆˆ Z_dãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€(1)H_uã‚’concatã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ãŸã‚‚ã®ã¨ã€z_iã®ãƒ™ã‚¯ãƒˆãƒ«ã®å†…ç©ã§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã€ã‚ã‚‹ã„ã¯(2) å€‹åˆ¥ã®ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³t_jã‚’åˆ¥ã€…ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ã€å†…ç©ã®å€¤ãŒæœ€å¤§ã®ã‚‚ã®ã‚’ã‚¹ã‚³ã‚¢ã¨ã™ã‚‹æ‰‹æ³•ã®2ç¨®é¡ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ–¹æ³•ã‚’ç”¨ã„ã¦ã€in-batch contrastive learningã‚’ç”¨ã„ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã€‚ã¤ã¾ã‚Šã€æ­£ã—ã„Signature Phraseã¨ã¯è·é›¢ãŒè¿‘ãã€èª¤ã£ãŸSignature Phraseã¨ã¯è·é›¢ãŒé ããªã‚‹ã‚ˆã†ã«å­¦ç¿’ã‚’ã™ã‚‹ã€‚<br><br>å®Ÿéš›ã¯ãƒ¦ãƒ¼ã‚¶ã«ã¨ã£ã¦ã®æ­£è§£Signature Phraseã¯åˆ†ã‹ã‚‰ãªã„ãŒã€ä»Šå›ã¯äººå·¥çš„ã«ä½œæˆã—ãŸãƒ¦ãƒ¼ã‚¶ã‚’ç”¨ã„ã‚‹ãŸã‚ã€æ­£è§£ãŒåˆ†ã‹ã‚‹è¨­å®šã¨ãªã£ã¦ã„ã‚‹ã€‚<br><br><br><br>## Signature-Oriented Headline Generation<br><br>ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹d, user signature phrasesZ_d^uãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã€‚ã“ã®æ™‚ã‚‚ã€ãƒ¦ãƒ¼ã‚¶ã«ã¨ã£ã¦æ­£è§£ã®ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¯åˆ†ã‹ã‚‰ãªã„ãŸã‚ã€æ—¢å­˜ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ãŒæ­£è§£ã¨ã—ã¦ç”¨ã„ã‚‰ã‚Œã‚‹ã€‚æ—¢å­˜ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ãŒæ­£è§£ã¨ã—ã¦ç”¨ã„ã‚‰ã‚Œã¦ã„ã¦ã‚‚ã€ãã®ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ãŒãã®ãƒ¦ãƒ¼ã‚¶ã«ã¨ã£ã¦ã®æ­£è§£ã¨ãªã‚‹ã‚ˆã†ã«äººå·¥çš„ã«ãƒ¦ãƒ¼ã‚¶ãŒä½œæˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãŒã§ãã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã¯BARTã‚’ç”¨ã„ãŸã€‚<br><br><br><br># Dataset<br><br>Newsroom, Gigawordã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ç”¨ã„ã‚‹ã€‚ã“ã‚Œã‚‰ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã«å¯¾ã—ã¦ã€ãã‚Œãã‚Œ2ç¨®é¡ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ä½œæˆã™ã‚‹ã€‚<br><br>1ã¤ã¯ã€Synthesized User Datasetã§ã€ã“ã‚Œã¯Use Signature Selection modelã®è¨“ç·´ã¨è©•ä¾¡ã«ç”¨ã„ã‚‹ã€‚ã‚‚ã†ä¸€ã¤ã¯headline generationãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€ã“ã¡ã‚‰ã¯headline generationãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«åˆ©ç”¨ã™ã‚‹ã€‚<br><br><br><br>## Synthesized User Creation<br><br>å®Ÿãƒ‡ãƒ¼ã‚¿ãŒãªã„ã®ã§ã€å®Ÿãƒ¦ãƒ¼ã‚¶ã®reading historiesã‚’æ¨¡å€£ã™ã‚‹ã‚ˆã†ã«äººå·¥ãƒ¦ãƒ¼ã‚¶ã‚’ä½œæˆã™ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€<br><br>1. ã™ã¹ã¦ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®Signature Phrasesã‚’åŒå®šã™ã‚‹<br><br>2. ãã‚Œãã‚Œã®Signature Phraseã¨ã€ãã‚Œã‚’å«ã‚€ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹<br><br>3. ãƒ©ãƒ³ãƒ€ãƒ ã«phraseã®ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ãã®ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ã‚ã‚‹äººå·¥ãƒ¦ãƒ¼ã‚¶ãŒèˆˆå‘³ã‚’æŒã¤ã‚¨ãƒªã‚¢ã¨ã™ã‚‹ã€‚<br><br>4. ã‚µãƒ–ã‚»ãƒƒãƒˆä¸­ã®interest phraseã‚’å«ã‚€ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ãƒ¦ãƒ¼ã‚¶ã®reading historyã¨ã™ã‚‹<br><br>train, dev, testã‚»ãƒƒãƒˆã€ãã‚Œãã‚Œã«å¯¾ã—ã¦ä¸Šè¨˜æ“ä½œã‚’å®Ÿæ–½ã—ãƒ¦ãƒ¼ã‚¶ã‚’ä½œæˆã™ã‚‹ãŒã€train, devã¯Contrastive Learningã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€user signature phrases (interest phrases)ã¯1ã¤ã®ã¿ã¨ã—ãŸï¼ˆSoftmaxãŒãã†ãªã£ã¦ã„ãªã„ã¨è¨“ç·´ã§ããªã„ã®ã§ï¼‰ã€‚ä¸€æ–¹ã€testã‚»ãƒƒãƒˆã¯1~5ã®ç¯„å›²ã§user signature phrasesã‚’é¸æŠã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚Œã‚‹è¨˜äº‹ãŒå¤šæ§˜åŒ–ã•ã‚Œã€ãƒ¦ãƒ¼ã‚¶ã®readinig historyãŒå¤šæ§˜åŒ–ã™ã‚‹ã“ã¨ã«ãªã‚‹ã€‚åŸºæœ¬çš„ã«ã¯ã€ãƒ¦ãƒ¼ã‚¶ãŒèˆˆå‘³ã®ã‚ã‚‹ãƒˆãƒ”ãƒƒã‚¯ãŒå°‘ãªã„æ–¹ãŒã€ã‚ˆã‚Šã‚¿ã‚¹ã‚¯ã¨ã—ã¦ã¯ç°¡å˜ã«ãªã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚ã¾ãŸã€ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã¨ãã¯ã€ãƒ¦ãƒ¼ã‚¶ã®signature phraseã‚’å«ã‚€è¨˜äº‹ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã³ã€ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’èƒŒè¡›æ˜Ÿã™ã‚‹ã“ã¨ã¨ã—ãŸã€‚ã“ã‚Œã¯ã€relevantãªè¨˜äº‹ã§ãªã„ã¨ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ãŒãã‚‚ãã‚‚ç”Ÿæˆã§ããªã„ã‹ã‚‰ã§ã‚ã‚‹ã€‚<br><br><br><br>## Headline Generation<br><br>ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®å…¨ã¦ã®signature phraseã‚’æŠ½å‡ºã—ã€ãã‚ŒãŒgivenãªæ™‚ã«ã€å…ƒã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ãŒç”Ÿæˆã§ãã‚‹ã‚ˆã†ãªBARTã‚’è¨“ç·´ã—ãŸã€‚ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®tokenã¯512ã§truncateã—ãŸã€‚å¹³å‡ã—ã¦ã€10å€‹ã®signature phraseãŒãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã”ã¨ã«é¸æŠã•ã‚Œã¦ãŠã‚Šã€ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ç”Ÿæˆã®å¤šæ§˜ã•ãŒã†ã‹ãŒãˆã‚‹ã€‚user signature phraseãã®ã‚‚ã®ã‚’ç”¨ã„ã¦è¨“ç·´ã¯ã—ã¦ã„ãªã„ãŒã€ãã‚‚ãã‚‚ã“ã®ã‚ˆã†ã«Genericãªãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã—ã¦ã‚‚ã€ä½•ã‚‰ã‹ã®phraseãŒgivenãªæ™‚ã«ã€ãã‚Œã«ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã£ãŸãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã®ã§ã€user signature phrase selectionã«ã‚ˆã£ã¦å¾—ã‚‰ã‚ŒãŸphraseã‚’ç”¨ã„ã¦ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br><br><br># è©•ä¾¡<br><br>è‡ªå‹•è©•ä¾¡ã¨äººæ‰‹è©•ä¾¡ã‚’ã—ã¦ã„ã‚‹ã€‚<br><br><br><br>## è‡ªå‹•è©•ä¾¡<br><br>äººæ‰‹è©•ä¾¡ã¯ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚Šã€ç‰¹ã«é–‹ç™ºãƒ•ã‚§ãƒ¼ã‚ºã«ãŠã„ã¦ã¯è‡ªå‹•è©•ä¾¡ãŒã§ãã‚‹ã“ã¨ãŒéå¸¸ã«é‡è¦ã¨ãªã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯è‡ªå‹•è©•ä¾¡ã—æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚Headline-User DPR + SBERT, REC Scoreã¯ã€User Adaptation Metricsã§ã‚ã‚Šã€Headline-Article DPR + SBERT, FactCCã¯Article Loyalty Metricsã§ã‚ã‚‹ã€‚<br><br>### Relevance Metrics<br><br>PretrainedãªDense Passage Retrieval (DPR)ãƒ¢ãƒ‡ãƒ«ã¨ã€SentenceBERTã‚’ç”¨ã„ã¦ã€headline-useré–“ã€headline-articleé–“ã®é¡ä¼¼åº¦ã‚’æ¸¬å®šã™ã‚‹ã€‚å‰è€…ã¯ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ãŒã©ã‚Œã ã‘ãƒ¦ãƒ¼ã‚¶ã«é©å¿œã—ã¦ã„ã‚‹ãŒã€å¾Œè€…ã¯ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ãŒå…ƒè¨˜äº‹ã«å¯¾ã—ã¦ã©ã‚Œã ã‘å¿ å®Ÿã‹ï¼ˆã‚¯ãƒªãƒƒã‚¯ãƒ™ã‚¤ãƒˆã‚’é˜²ããŸã‚ã«ï¼‰ã«ç”¨ã„ã‚‰ã‚Œã‚‹ã€‚å‰è€…ã¯ã€ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¨user signaturesã«å¯¾ã—ã¦é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã€å¾Œè€…ã¯ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¨è¨˜äº‹å…¨æ–‡ã«å¯¾ã—ã¦é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹ã€‚user signatures, è¨˜äº‹å…¨æ–‡ã‚’ã©ã®ã‚ˆã†ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸã‹ã¯è¨˜è¿°ã•ã‚Œã¦ã„ãªã„ã€‚<br><br>### Recommendation Score<br><br>ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¨ã€ãƒ¦ãƒ¼ã‚¶ã®readinig historyãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¨è–¦ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ã€ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã™ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã¯ã€MIND datsetã‚’ç”¨ã„ã¦å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸã€‚<br><br>### Factual Consistency<br><br>pretrainedãªFactCCãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ã€ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¨ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹é–“ã®factual consisency score ã‚’ç®—å‡ºã™ã‚‹ã€‚<br><br>### Surface Overlap<br><br>ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¨ã€ç”Ÿæˆã•ã‚ŒãŸãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã®ROUGE-L F1ã¨ã€Extractive Coverage (ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã«å«ã¾ã‚Œã‚‹å˜èªã®ã†ã¡ã€ã‚½ãƒ¼ã‚¹ã«å«ã¾ã‚Œã‚‹å˜èªã®å‰²åˆ)ã‚’ç”¨ã„ã‚‹ã€‚<br><br>### è©•ä¾¡çµæœ<br><br>ææ¡ˆæ‰‹æ³•ã®ã†ã¡ã€User Signature Selection modelã‚’finetuningã—ãŸã‚‚ã®ãŒæœ€ã‚‚æ€§èƒ½ãŒé«˜ã‹ã£ãŸã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ–¹æ³•ã¯ã€(2)ã®ãƒ’ã‚¹ãƒˆãƒªã®ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒ•ãƒ¬ãƒ¼ã‚ºã®æœ€å¤§ã‚¹ã‚³ã‚¢ã‚’ã¨ã‚‹æ–¹æ³•ãŒæœ€ã‚‚æ€§èƒ½ãŒé«˜ã„ã€‚ææ¡ˆæ‰‹æ³•ã¯User Adaptationã‚’ã—ã¤ã¤ã‚‚ã€Article Loyaltyã‚’ä¿ã£ã¦ã„ã‚‹ã€‚ã“ã®ãŸã‚ã€ã‚¯ãƒªãƒƒã‚¯ãƒ™ã‚¤ãƒˆã®é˜²æ­¢ã«ã¤ãªãŒã‚‹ã€‚ã¾ãŸã€Vanilla Humanã¯å…ƒè¨˜äº‹ã®ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã§ã‚ã‚Šã€Extracitve CoverageãŒä½ã„ãŸã‚ã€ã‚ˆã‚ŠæŠ½è±¡çš„ã§ã€ã‹ã¤å…ƒè¨˜äº‹ã«å¯¾ã™ã‚‹å¿ å®Ÿæ€§ãŒä½ã„ã“ã¨ãŒã†ã‹ãŒãˆã‚‹ã€‚<br><br><br><br><br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/847933e1-deb2-4379-addb-6cdd65e29ee8" alt="image" loading="lazy"><br><br><br><br><br><br><br><br>&lt;/p&gt;<p>## äººæ‰‹è©•ä¾¡<br><br>16äººã®evaluatorã§è©•ä¾¡ã€‚2260ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’åé›†ï¼ˆ113 topicï¼‰ã—ã€è¨˜äº‹ã®ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¨ã€å¯¾å¿œã™ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚’è¦‹ã›ã¦ã€20å€‹ã®èˆˆå‘³ã«åˆè‡´ã™ã‚‹ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’é¸æŠã—ã¦ã‚‚ã‚‰ã£ãŸã€‚ã“ã‚Œã‚’ãƒ¦ãƒ¼ã‚¶ã®interest phraseã¨reading _historyã¨ã—ã¦æ‰±ã†ã€‚ãã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ã®interest phraseã‚’å«ã‚€ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ã†ã¡ã€12å€‹ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã—ã€ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã—ãŸã€‚ç”Ÿæˆã—ãŸãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã«å¯¾ã—ã¦ã€<br><br>1. Vanilla Human<br><br>2. Vanilla System<br><br>3. SP random (ãƒ©ãƒ³ãƒ€ãƒ ã«signature phraseã‚’é¸ã¶æ‰‹æ³•)<br><br>4. SP individual-N<br><br>5. SP individual-F (User Signature Phraseã‚’é¸æŠã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’finetuningã—ãŸã‚‚ã®)<br><br>ã®5ç¨®é¡ã‚’è©•ä¾¡ã™ã‚‹ã‚ˆã†ä¾é ¼ã—ãŸã€‚ã“ã®ã¨ãã€ï¼“ã¤ã®è¦³ç‚¹ã‹ã‚‰è©•ä¾¡ã‚’ã—ãŸã€‚<br><br>1, User adaptation<br><br>2. Headline appropriateness<br><br>3. Text Quality<br><br>çµæœã¯ä»¥ä¸‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6af9f214-2af4-4fa3-8637-6b1858f0bb69" alt="image" loading="lazy"><br><br>SP-individualãŒUser Adaptationã§æœ€ã‚‚é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã—ãŸã€‚ã¾ãŸã€Vanilla SystemãŒæœ€ã‚‚é«˜ã„Headline appropriatenessã‚’ç²å¾—ã—ãŸã€‚ã—ã‹ã—ãªãŒã‚‰ã€å¾Œã»ã©åˆ†æã—ãŸçµæœã€Vanilla Systemã§ã¯ã€è¨˜äº‹ã®ãƒ¡ã‚¤ãƒ³ãƒã‚¤ãƒ³ãƒˆã‚’æŠ¼ã•ãˆã‚‰ã‚Œã¦ã„ãªã„ã‚ˆã†ãªä¾‹ãŒã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸï¼ˆã‚“ãƒ¼ã“ã‚Œã¯æ­£ç›´ä»–ã®æ‰‹æ³•ã§ã‚‚åŒã˜ã ã¨æ€ã†ã‹ã‚‰ã€ãƒ‡ã‚£ãƒ•ã‚§ãƒ³ã‚¹ã¨ã—ã¦ã¯è‹¦ã—ã„ã®ã§ã¯ï¼‰ã€‚<br><br>ã¾ãŸã€Vanilla HumanãŒæœ€ã‚‚é«˜ã„ã‚¹ã‚³ã‚¢ã‚’ç²å¾—ã—ãªã‹ã£ãŸã€‚ã“ã‚Œã¯ã€ã‚ªãƒ¼ãƒãƒ¼ã«ãƒ¬ãƒˆãƒªãƒƒã‚¯ã‚’ç”¨ã„ã¦ã„ãŸã‚Šã€ä¸€èˆ¬çš„ãªäººã«ã¯ã‚ã‹ã‚‰ãªã„ã‚ˆã†ãªã‚¿ã‚¤ãƒˆãƒ«ã«ãªã£ã¦ã„ã‚‹ã‚‚ã®ãŒã‚ã‚‹ã‹ã‚‰ã§ã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6e704d7b-6124-49b5-91c8-1f6b507b0c0a" alt="image" loading="lazy"><br><br><br><br># Ablation Study<br><br>Signature Phrase selectionã®æ€§èƒ½ã‚’æ¸¬å®šã—ãŸã¨ã“ã‚ä»¥ä¸‹ã®é€šã‚Šã«ãªã‚Šã€finetuningã—ãŸå ´åˆã®æ€§èƒ½ãŒè‰¯ã‹ã£ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a24fefb6-9028-4e58-9667-caa13a70af31" alt="image" loading="lazy"><br><br><br><br>Headline Generationã®æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹è¦ç´ ã¨ã—ã¦ã¯ã€<br><br>1. ãƒ¦ãƒ¼ã‚¶ãŒèˆˆå‘³ã®ã‚ã‚‹ãƒˆãƒ”ãƒƒã‚¯æ•°<br><br>2. User signature phrasesã®æ•°<br><br>ãŒã‚ã‚‹ã€‚<br><br>ãƒ¦ãƒ¼ã‚¶ã®Interest PhrasesãŒå¢—ãˆã¦ã„ã‘ã°ã„ãã»ã©ã€User Adaptationã‚¹ã‚³ã‚¢ã¯æ¸›å°‘ã™ã‚‹ãŒã€Article Loyaltyã¯ç¶­æŒã•ã‚ŒãŸã¾ã¾ã§ã‚ã‚‹ã€‚ã“ã®ãŸã‚ã€èˆˆå‘³ãŒã‚ã‚‹ãƒˆãƒ”ãƒƒã‚¯ãŒå¤šã‘ã‚Œã°å¤šã„ã»ã©ç”ŸæˆãŒé›£ã—ã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚ã¾ãŸã€è¤‡æ•°ã®user signature phraseã‚’ç”¨ã„ã‚‹ã¨ã€factual errorã‚’èµ·ã“ã™ã“ã¨ãŒåˆ†ã‹ã£ãŸï¼ˆBillgates, Zuckerbergã®ä¾‹ã‚’å‚ç…§ï¼‰ã€‚ã“ã‚Œã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒæœ¬æ¥ã¯irrelevantãªãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ç”¨ã„ã¦coherentãªãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã—ã‚ˆã†ã¨ã—ã¦ã—ã¾ã†ãŸã‚ã§ã‚ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9d28d904-3247-4593-bc1c-8b6e7090719b" alt="image" loading="lazy"><br><br><br><br>â€»interest phrases =&gt; gold user signatures ã¨ã„ã†ç†è§£ã§ã‚ˆã•ãã†ã€‚<br><br>â€»signature phrasesã‚’è¤‡æ•°ç”¨ã„ã‚‹ã¨factual errorã‚’èµ·ã“ã™ãŸã‚ã€ä»Šå›ã¯k=1ã§å®Ÿé¨“ã—ã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹<br><br><br><br>GPT3ã«ã‚‚ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã•ã›ã¦ã¿ãŸãŒã€ææ¡ˆæ‰‹æ³•ã®æ–¹ãŒæ€§èƒ½ãŒè‰¯ã‹ã£ãŸï¼ˆè‡ªå‹•è©•ä¾¡ã§ï¼‰ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3e0852e1-f21a-47d6-b874-b7d3a42d7304" alt="image" loading="lazy"><br><br></p>
<p>ãªãœPENS dataset <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/706" target="_blank" rel="noopener noreferrer">PENS: A Dataset and Generic Framework for Personalized News Headline Generation, ACL'21</a>
&lt;/strong&gt;
<br>
 ã‚’åˆ©ç”¨ã—ãªã„ã§ç ”ç©¶ã—ãŸã®ã‹ï¼Ÿ</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/892" target="_blank" rel="noopener noreferrer" class="title-link">Can Large Language Models Be an Alternative to Human Evaluations? Cheng-Han Chiang, Hung-yi Lee, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€äººé–“ã®è©•ä¾¡ãŒæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚­ã‚¹ãƒˆå“è³ªè©•ä¾¡ã«ä¸å¯æ¬ ã§ã‚ã‚‹ãŒå†ç¾æ€§ãŒé›£ã—ã„ã¨ã„ã†å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ãŸè©•ä¾¡æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€LLMsã«åŒã˜æŒ‡ç¤ºã¨è©•ä¾¡å¯¾è±¡ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ä¸ãˆã€ãã‚Œã«å¯¾ã™ã‚‹å¿œç­”ã‚’ç”Ÿæˆã•ã›ã‚‹ã“ã¨ã§ã€LLMè©•ä¾¡ã‚’è¡Œã£ã¦ã„ã‚‹ã€‚å®Ÿé¨“çµæœã‹ã‚‰ã€LLMè©•ä¾¡ã®çµæœã¯äººé–“ã®è©•ä¾¡ã¨ä¸€è‡´ã—ã¦ãŠã‚Šã€ç•°ãªã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚„ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã‚‚å®‰å®šã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚LLMsã‚’ä½¿ç”¨ã—ãŸãƒ†ã‚­ã‚¹ãƒˆå“è³ªè©•ä¾¡ã®å¯èƒ½æ€§ãŒåˆã‚ã¦ç¤ºã•ã‚Œã¦ãŠã‚Šã€ãã®åˆ¶é™ã‚„å€«ç†çš„ãªè€ƒæ…®äº‹é …ã«ã¤ã„ã¦ã‚‚è­°è«–ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/891" target="_blank" rel="noopener noreferrer" class="title-link">InfoMetIC: An Informative Metric for Reference-free Image Caption Evaluation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå‹•ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã®è©•ä¾¡ã«ã¯ã€æƒ…å ±è±Šã‹ãªãƒ¡ãƒˆãƒªãƒƒã‚¯ï¼ˆInfoMetICï¼‰ãŒææ¡ˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã®èª¤ã‚Šã‚„æ¬ è½ã—ãŸæƒ…å ±ã‚’è©³ç´°ã«ç‰¹å®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚InfoMetICã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã®ç²¾åº¦ã‚¹ã‚³ã‚¢ã€ãƒ“ã‚¸ãƒ§ãƒ³ã®å†ç¾ã‚¹ã‚³ã‚¢ã€ãŠã‚ˆã³å…¨ä½“ã®å“è³ªã‚¹ã‚³ã‚¢ã‚’æä¾›ã—ã€äººé–“ã®åˆ¤æ–­ã¨ã®ç›¸é–¢ã‚‚é«˜ã„ã§ã™ã€‚ã¾ãŸã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚æ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã™ã€‚è©³ç´°ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/890" target="_blank" rel="noopener noreferrer" class="title-link">RQUGE: Reference-Free Metric for Evaluating Question Generation by Answering the Question, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æ—¢å­˜ã®è³ªå•è©•ä¾¡ãƒ¡ãƒˆãƒªãƒƒã‚¯ã«ã¯ã„ãã¤ã‹ã®æ¬ ç‚¹ãŒã‚ã‚Šã¾ã™ãŒã€æœ¬ç ”ç©¶ã§ã¯æ–°ã—ã„ãƒ¡ãƒˆãƒªãƒƒã‚¯RQUGEã‚’ææ¡ˆã—ã¾ã™ã€‚RQUGEã¯æ–‡è„ˆã«åŸºã¥ã„ã¦å€™è£œè³ªå•ã®å›ç­”å¯èƒ½æ€§ã‚’è€ƒæ…®ã—ã€å‚ç…§è³ªå•ã«ä¾å­˜ã›ãšã«äººé–“ã®åˆ¤æ–­ã¨é«˜ã„ç›¸é–¢ã‚’æŒã¤ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€RQUGEã¯æ•µå¯¾çš„ãªç ´å£Šã«å¯¾ã—ã¦ã‚‚å …ç‰¢ã§ã‚ã‚Šã€è³ªå•ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚‚æœ‰åŠ¹ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€QAãƒ¢ãƒ‡ãƒ«ã®ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>è³ªå•è‡ªå‹•ç”Ÿæˆã®æ€§èƒ½æŒ‡æ¨™ï¼ˆe.g. ROUGE, BERTScoreï¼‰ã¯ã€è¡¨å±¤ã®ä¸€è‡´ã€ã‚ã‚‹ã„ã¯æ„å‘³ãŒä¸€è‡´ã—ãŸå ´åˆã«ãƒã‚¤ã‚¹ã‚³ã‚¢ã‚’ä¸ãˆã‚‹ãŒã€ä»¥ä¸‹ã®æ¬ ç‚¹ãŒã‚ã‚‹<br><br>- äººæ‰‹ã§ä½œæˆã•ã‚ŒãŸå¤§é‡ã®reference questionãŒå¿…è¦<br><br>- è¡¨å±¤ã‚ã‚‹ã„ã¯æ„å‘³çš„ã«è¿‘ããªã„ãŒæ­£ã—ã„questionã«å¯¾ã—ã¦ã€ãƒšãƒŠãƒ«ãƒ†ã‚£ãŒä¸ãˆã‚‰ã‚Œã¦ã—ã¾ã†<br><br>=&gt; contextã«å¯¾ã™ã‚‹answerabilityã«ã‚ˆã£ã¦è©•ä¾¡ã™ã‚‹ãƒ¡ãƒˆãƒªãƒƒã‚¯ RQUGE ã‚’ææ¡ˆ<br><br><br><br>similarity basedãªæŒ‡æ¨™ã§ã¯ã€Q1ã®ã‚ˆã†ãªæ­£ã—ã„è³ªå•ã§ã‚‚lexical overlapãŒãªã„ã¨ä½ã„ã‚¹ã‚³ã‚¢ã‚’ä¸ãˆã¦ã—ã¾ã†ã€‚ã¾ãŸã€Q2ã®ã‚ˆã†ãªreferenceã®è¨€ã„æ›ãˆã§ã‚ã£ã¦ã‚‚ã€ä½ã„ã‚¹ã‚³ã‚¢ã¨ãªã£ã¦ã—ã¾ã†ã€‚ä¸€æ–¹ã€reference basedãªæ‰‹æ³•ã§ã¯ã€Q3ã®ã‚ˆã†ã«unacceptableã«ãªã£ã¦ã„ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€å¤‰åŒ–ãŒå¾®å°ã§ã‚ã‚‹ãŸã‚ãã‚Œã‚’ã¨ã‚‰ãˆã‚‰ã‚Œãªã„ã¨ã„ã†å•é¡ŒãŒã‚ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/61c3d939-a678-4c63-9572-f3cf28b3aa20" alt="image" loading="lazy"><br><br><br><br># æ‰‹æ³•æ¦‚è¦<br><br>ææ¡ˆæ‰‹æ³•ã§ã¯contextã¨answer spanãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€Span Scorerã¨ã€QAãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆ©ç”¨ã—ã¦acceptability scoreã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã§reference-freeãªmetricã‚’å®Ÿç¾ã™ã‚‹ã€‚<br><br>QAãƒ¢ãƒ‡ãƒ«ã¯ã€Contextã¨ç”Ÿæˆã•ã‚ŒãŸQuestionã«åŸºã¥ãã€answer spanã‚’äºˆæ¸¬ã™ã‚‹ã€‚ææ¡ˆæ‰‹æ³•ã§ã¯T5ãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã§ã‚ã‚‹UnifiedQAv2ã‚’åˆ©ç”¨ã™ã‚‹ã€‚<br><br>Span Scorer Moduleã§ã¯ã€äºˆæ¸¬ã•ã‚ŒãŸanswer span, candidate question, context, gold spanã«åŸºã¥ãã€[1, 5]ã®ã‚¹ã‚³ã‚¢ã‚’äºˆæ¸¬ã™ã‚‹ã€‚ææ¡ˆæ‰‹æ³•ã§ã¯ã€encoder-only BERT-based modelï¼ˆææ¡ˆæ‰‹æ³•ã§ã¯RoBERTaï¼‰ã‚’ç”¨ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b49e09a4-4a69-4761-94eb-3f6417a19223" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/888" target="_blank" rel="noopener noreferrer" class="title-link">Llama 2: Open Foundation and Fine-Tuned Chat Models, Hugo Touvron+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹Llama 2ã‚’é–‹ç™ºã—ã€å¾®èª¿æ•´ã—ã¦ã„ã¾ã™ã€‚Llama 2-Chatã¯å¯¾è©±ã«ç‰¹åŒ–ã—ã¦ãŠã‚Šã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚å®‰å…¨æ€§ã®æ”¹å–„ã«ã‚‚å–ã‚Šçµ„ã‚“ã§ãŠã‚Šã€è²¬ä»»ã‚ã‚‹é–‹ç™ºã«è²¢çŒ®ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1681436336451125257?s=46&t=LJIgfuO352oK3zU2FKFpNA"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span></strong></p>
<p>Llama, ãŠã‚ˆã³Llama2ã§ã¯ã€ä¸€èˆ¬çš„ãªTransformer Decoderã¨ã¯ç•°ãªã‚Šã€linear layerã®â€å‰ã«â€RMSPropã‚’ã‹ã¾ã›ã¦ã„ã‚‹ç‚¹ãŒç•°ãªã‚‹ã€‚<br><br>ã¾ãŸã€Llama2ã§ã¯ã€Llamaã¨æ¯”è¼ƒã—ã¦<br><br>- Group Query Attentionã®åˆ©ç”¨ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
 <br><br>- æ´»æ€§åŒ–é–¢æ•°ã¨ã—ã¦ã€ReLUã§ã¯ãªãã€SwiGLU <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1311" target="_blank" rel="noopener noreferrer">GLU Variants Improve Transformer, Noam Shazeer, N/A, arXiv'20</a>
 ã®æ´»ç”¨<br><br>- Positional Embeddingã¨ã—ã¦ã€RoPE <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1310" target="_blank" rel="noopener noreferrer">RoFormer: Enhanced Transformer with Rotary Position Embedding, Jianlin Su+, N/A, Neurocomputing, 2024</a>
 ã®æ´»ç”¨<br><br>- ã‚ˆã‚Šé•·ã„Context Windowsã§ã®å­¦ç¿’ï¼ˆ4kï¼‰<br><br>ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6d6d897a-3ce8-4a90-a001-116884c45cdd" alt="image" loading="lazy"><br><br><br><br>å‡ºå…¸ï¼š


<a href="https://cameronrwolfe.substack.com/p/llama-2-from-the-ground-up" target="_blank" rel="noopener noreferrer">https://cameronrwolfe.substack.com/p/llama-2-from-the-ground-up</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/887" target="_blank" rel="noopener noreferrer" class="title-link">How is ChatGPT's behavior changing over time?, Lingjiao Chen+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- GPT-3.5ã¨GPT-4ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®ã‚µãƒ¼ãƒ“ã‚¹ã§ã‚ã‚Šã€ãã®æ€§èƒ½ã¨æŒ¯ã‚‹èˆã„ã¯æ™‚é–“ã¨ã¨ã‚‚ã«å¤‰å‹•ã™ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ä¾‹ãˆã°ã€GPT-4ã¯ç´ æ•°ã®ç‰¹å®šã«å„ªã‚Œã¦ã„ãŸãŒã€å¾Œã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ä½ã„æ­£ç­”ç‡ã¨ãªã£ãŸã€‚ã¾ãŸã€GPT-3.5ã¯GPT-4ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã•ã‚‰ã«ã€GPT-4ã¨GPT-3.5ã®ä¸¡æ–¹ãŒæ™‚é–“ã¨ã¨ã‚‚ã«æ•æ„Ÿãªè³ªå•ã¸ã®å›ç­”ã‚„ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã§ã®ãƒŸã‚¹ãŒå¢—ãˆãŸã€‚ã“ã®çµæœã‹ã‚‰ã€LLMã®å“è³ªã‚’ç¶™ç¶šçš„ã«ç›£è¦–ã™ã‚‹å¿…è¦æ€§ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>GPT3.5, GPT4å…±ã«freezeã•ã‚Œã¦ãªã„ã®ãªã‚‰ã€ç ”ç©¶ã§åˆ©ç”¨ã™ã‚‹ã¨çµæœãŒå†ç¾ã•ã‚Œãªã„ã®ã§ã€ç ”ç©¶ã§ä½¿ã†ã¹ãã§ã¯ãªã„ã€‚</p>
<p>ã¾ãŸã€çŸ¥ã‚‰ã‚“ã†ã¡ã«ã„ãã¤ã‹ã®ã‚¿ã‚¹ã‚¯ã§å‹æ‰‹ã«æ€§èƒ½ä½ä¸‹ã•ã‚ŒãŸã‚‰ãŸã¾ã£ãŸã‚‚ã®ã§ã¯ãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/884" target="_blank" rel="noopener noreferrer" class="title-link">Challenges and Applications of Large Language Models, Jean Kaddour+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ™®åŠã«ã‚ˆã‚Šã€ç ”ç©¶è€…ãŒåˆ†é‡ã®ç¾çŠ¶ã‚’ç†è§£ã—ã€ç”Ÿç”£çš„ã«ãªã‚‹ãŸã‚ã®å•é¡Œã¨å¿œç”¨æˆåŠŸä¾‹ã‚’ç¢ºç«‹ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®ã“ã“æ•°å¹´ã®é€²åŒ–æ—©ã™ãã‚ã‚ãŸã§ã‚­ãƒ£ãƒƒãƒã‚¢ãƒƒãƒ—ã‚€ãšã„ã®ã§ã€æœªè§£æ±ºã®èª²é¡Œã‚„ã€ã™ã§ã«è‰¯ã„æ„Ÿã˜ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆ†é‡åˆ†ã‹ã‚Šã¥ã‚‰ã„ã®ã§ã€ã¾ã¨ã‚ã¾ã—ãŸè«–æ–‡</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/883" target="_blank" rel="noopener noreferrer" class="title-link">Towards A Unified Agent with Foundation Models, Norman Di Palo+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ãƒ“ã‚¸ãƒ§ãƒ³è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å¼·åŒ–å­¦ç¿’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«çµ„ã¿è¾¼ã¿ã€åŠ¹ç‡çš„ãªæ¢ç´¢ã‚„çµŒé¨“ãƒ‡ãƒ¼ã‚¿ã®å†åˆ©ç”¨ãªã©ã®èª²é¡Œã«å–ã‚Šçµ„ã‚€æ–¹æ³•ã‚’èª¿æŸ»ã—ã¾ã—ãŸã€‚ã‚¹ãƒ‘ãƒ¼ã‚¹ãªå ±é…¬ã®ãƒ­ãƒœãƒƒãƒˆæ“ä½œç’°å¢ƒã§ã®ãƒ†ã‚¹ãƒˆã«ãŠã„ã¦ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«æ¯”ã¹ã¦å¤§å¹…ãªæ€§èƒ½å‘ä¸Šã‚’å®Ÿè¨¼ã—ã€å­¦ç¿’æ¸ˆã¿ã®ã‚¹ã‚­ãƒ«ã‚’æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã®è§£æ±ºã‚„äººé–“ã®å°‚é–€å®¶ã®ãƒ“ãƒ‡ã‚ªã®æ¨¡å€£ã«æ´»ç”¨ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/aa40d0e3-9499-4804-9046-a9ad795c2d52" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Annotation.html" target="_blank" rel="noopener noreferrer">#Annotation</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/882" target="_blank" rel="noopener noreferrer" class="title-link">LLMs as Workers in Human-Computational Algorithms? Replicating  Crowdsourcing Pipelines with LLMs, Tongshuang Wu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€ã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚·ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦äººé–“ã®ã‚ˆã†ãªæŒ¯ã‚‹èˆã„ã‚’å†ç¾ã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ã—ã‹ã—ã€ç¾åœ¨ã®å–ã‚Šçµ„ã¿ã¯å˜ç´”ãªã‚¿ã‚¹ã‚¯ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€ã‚ˆã‚Šè¤‡é›‘ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å†ç¾ã§ãã‚‹ã‹ã©ã†ã‹ã¯ä¸æ˜ã§ã‚ã‚‹ã€‚LLMsã®æˆåŠŸã¯ã€ãƒªã‚¯ã‚¨ã‚¹ã‚¿ãƒ¼ã®ç†è§£åŠ›ã‚„ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã®ã‚¹ã‚­ãƒ«ã«å½±éŸ¿ã‚’å—ã‘ã‚‹ã€‚äººé–“ã¨LLMsã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚Šã€ã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚·ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å†ç¾ãŒå¯èƒ½ã§ã‚ã‚Šã€LLMsã¯ä¸€éƒ¨ã®ã‚¿ã‚¹ã‚¯ã‚’å®Œäº†ã•ã›ãªãŒã‚‰ã€ä»–ã®ã‚¿ã‚¹ã‚¯ã‚’äººé–“ã«ä»»ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/877" target="_blank" rel="noopener noreferrer" class="title-link">Instruction-following Evaluation through Verbalizer Manipulation, Shiyang Li+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã‚’æ­£ç¢ºã«è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã€Œverbalizer manipulationã€ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã«ç•°ãªã‚‹ç¨‹åº¦ã§ä¸€è‡´ã™ã‚‹è¨€è‘‰ã‚’ä½¿ç”¨ã—ã¦ã‚¿ã‚¹ã‚¯ãƒ©ãƒ™ãƒ«ã‚’è¡¨ç¾ã•ã›ã€ãƒ¢ãƒ‡ãƒ«ã®äº‹å‰çŸ¥è­˜ã«ä¾å­˜ã™ã‚‹èƒ½åŠ›ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚ã•ã¾ã–ã¾ãªãƒ¢ãƒ‡ãƒ«ã‚’9ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡ã—ã€ç•°ãªã‚‹verbalizerã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ã‚ˆã£ã¦æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ãŒæ˜ç¢ºã«åŒºåˆ¥ã•ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚æœ€ã‚‚å›°é›£ãªverbalizerã«å¯¾ã—ã¦ã‚‚ã€æœ€ã‚‚å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã§ã‚‚ãƒ©ãƒ³ãƒ€ãƒ ãªæ¨æ¸¬ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã™ã‚‹ã®ã¯å›°é›£ã§ã‚ã‚Šã€æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ç¶™ç¶šçš„ãªé€²æ­©ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SpokenLanguageProcessing.html" target="_blank" rel="noopener noreferrer">#SpokenLanguageProcessing</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/875" target="_blank" rel="noopener noreferrer" class="title-link">Meta-Transformer: A Unified Framework for Multimodal Learning, Yiyuan Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å­¦ç¿’ã®ãŸã‚ã®Meta-Transformerã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®æƒ…å ±ã‚’å‡¦ç†ã—é–¢é€£ä»˜ã‘ã‚‹ãŸã‚ã®çµ±ä¸€ã•ã‚ŒãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚Meta-Transformerã¯ã€å¯¾å¿œã®ãªã„ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦12ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£é–“ã§çµ±ä¸€ã•ã‚ŒãŸå­¦ç¿’ã‚’è¡Œã†ã“ã¨ãŒã§ãã€ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€ãƒã‚¤ãƒ³ãƒˆã‚¯ãƒ©ã‚¦ãƒ‰ã€éŸ³å£°ã€ãƒ“ãƒ‡ã‚ªãªã©ã®åŸºæœ¬çš„ãªãƒ‘ãƒ¼ã‚»ãƒ—ã‚·ãƒ§ãƒ³ã‹ã‚‰ã€Xç·šã€èµ¤å¤–ç·šã€é«˜åˆ†å…‰ã€IMUãªã©ã®å®Ÿç”¨çš„ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚°ãƒ©ãƒ•ã€è¡¨å½¢å¼ã€æ™‚ç³»åˆ—ãªã©ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ‹ãƒ³ã‚°ã¾ã§ã€å¹…åºƒã„ã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚Meta-Transformerã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’ç”¨ã„ãŸçµ±ä¸€ã•ã‚ŒãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ã®é–‹ç™ºã«å‘ã‘ãŸæœ‰æœ›ãªæœªæ¥ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>12ç¨®é¡ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«å¯¾ã—ã¦å­¦ç¿’ã§ãã‚‹Transformerã‚’ææ¡ˆ<br>Dataã‚’sequenceã«tokenizeã—ã€unifiedã«featureã‚’encodingã—ã€ãã‚Œãã‚Œã®downstreamã‚¿ã‚¹ã‚¯ã§å­¦ç¿’<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8734073a-573e-442e-8b9f-fed559199d56" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/873" target="_blank" rel="noopener noreferrer" class="title-link">FLASK: Fine-grained Language Model Evaluation based on Alignment Skill  Sets, Seonghyeon Ye+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®è©•ä¾¡ã«ãŠã‘ã‚‹èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€ç´°ã‹ã„è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã‚ã‚‹FLASKã‚’ææ¡ˆã™ã‚‹ã€‚FLASKã¯ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã”ã¨ã®ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆãƒ¬ãƒ™ãƒ«ã§ã®è©•ä¾¡ã‚’å¯èƒ½ã«ã—ã€ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã¨äººé–“ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡ã®ä¸¡æ–¹ã«ä½¿ç”¨ã§ãã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€12ã®ç´°ã‹ã„ã‚¹ã‚­ãƒ«ã‚’å®šç¾©ã—ã€å„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«ã‚¹ã‚­ãƒ«ã®ã‚»ãƒƒãƒˆã‚’å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ã§è©•ä¾¡ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ã€‚ã•ã‚‰ã«ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‰ãƒ¡ã‚¤ãƒ³ã¨é›£æ˜“åº¦ãƒ¬ãƒ™ãƒ«ã®æ³¨é‡ˆã‚’ä»˜ã‘ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åŒ…æ‹¬çš„ã«åˆ†æã™ã‚‹ã€‚FLASKã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ­£ç¢ºã«æ¸¬å®šã—ã€ç‰¹å®šã®ã‚¹ã‚­ãƒ«ã«å„ªã‚ŒãŸLLMsã‚’åˆ†æã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã¾ãŸã€å®Ÿè·µè€…ã¯FLASKã‚’ä½¿ç”¨ã—ã¦ã€ç‰¹å®šã®çŠ¶æ³ã«é©ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’æ¨å¥¨ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã“ã®ãƒ™ãƒ³ãƒã«ã‚ˆã‚‹ã¨LLaMA2ã§ã•ãˆã€å•†ç”¨ã®LLMã«æ¯”ã¹ã‚‹ã¨èƒ½åŠ›ã¯ã‹ãªã‚ŠåŠ£ã£ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d9871133-3111-4da6-9148-1ac779a24312" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/869" target="_blank" rel="noopener noreferrer" class="title-link">Revisiting the Gold Standard: Grounding Summarization Evaluation with Robust Human Evaluation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ã®è©•ä¾¡ã«ã¯äººé–“ã®è©•ä¾¡ãŒé‡è¦ã§ã™ãŒã€æ—¢å­˜ã®è©•ä¾¡æ–¹æ³•ã«ã¯å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ãã“ã§ã€ç§ãŸã¡ã¯æ–°ã—ã„è¦ç´„ã®é‡è¦æ€§ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ææ¡ˆã—ã€å¤§è¦æ¨¡ãªäººé–“è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åé›†ã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ç•°ãªã‚‹è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’æ¯”è¼ƒã—ã€è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ã‚’è©•ä¾¡ã—ã¾ã—ãŸã€‚ç§ãŸã¡ã®ç ”ç©¶çµæœã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã«é‡è¦ãªç¤ºå”†ã‚’ä¸ãˆã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/868" target="_blank" rel="noopener noreferrer" class="title-link">Socratic Questioning of Novice Debuggers: A Benchmark Dataset and Preliminary Evaluations, ACL-BEA'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€åˆå¿ƒè€…ãƒ—ãƒ­ã‚°ãƒ©ãƒãŒãƒã‚°ã®ã‚ã‚‹è¨ˆç®—å•é¡Œã‚’è§£æ±ºã™ã‚‹éš›ã«ã€ã‚½ã‚¯ãƒ©ãƒ†ã‚¹çš„ãªå¯¾è©±ã‚’è¡Œã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç´¹ä»‹ã—ã€GPTãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒãƒƒã‚°èƒ½åŠ›ã‚’è©•ä¾¡ã—ã¾ã—ãŸã€‚GPT-4ã¯GPT-3.5ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¾ã—ãŸãŒã€ã¾ã äººé–“ã®å°‚é–€å®¶ã«ã¯åŠã°ãšã€ã•ã‚‰ãªã‚‹ç ”ç©¶ãŒå¿…è¦ã§ã™ã€‚</span>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/867" target="_blank" rel="noopener noreferrer" class="title-link">Teaching Small Language Models to Reason, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’å°ã•ãªãƒ¢ãƒ‡ãƒ«ã«è»¢é€ã™ã‚‹ãŸã‚ã®çŸ¥è­˜è’¸ç•™ã‚’æ¢æ±‚ã—ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€å¤§ããªæ•™å¸«ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸå‡ºåŠ›ã‚’ç”¨ã„ã¦å­¦ç”Ÿãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã€ç®—è¡“ã€å¸¸è­˜ã€è±¡å¾´çš„ãªæ¨è«–ã®ã‚¿ã‚¹ã‚¯ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ä¾‹ãˆã°ã€T5 XXLã®æ­£è§£ç‡ã¯ã€PaLM 540Bã¨GPT-3 175Bã§ç”Ÿæˆã•ã‚ŒãŸå‡ºåŠ›ã‚’å¾®èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€ãã‚Œãã‚Œ8.11ï¼…ã‹ã‚‰21.99ï¼…ãŠã‚ˆã³18.42ï¼…ã«å‘ä¸Šã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/866" target="_blank" rel="noopener noreferrer" class="title-link">WeCheck: Strong Factual Consistency Checker via Weakly Supervised Learning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- ç¾åœ¨ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯ã€å…¥åŠ›ã¨çŸ›ç›¾ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ¶å¾¡ã§ããªã„ã¨ã„ã†èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ç§ãŸã¡ã¯WeCheckã¨ã„ã†å¼±æ•™å¸«ä»˜ããƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚WeCheckã¯ã€å¼±æ•™å¸«ä»˜ããƒ©ãƒ™ãƒ«ã‚’æŒã¤è¨€èªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç›´æ¥è¨“ç·´ã•ã‚ŒãŸå®Ÿéš›ã®ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã§ã®å®Ÿé¨“çµæœã¯ã€WeCheckã®å¼·åŠ›ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€å¾“æ¥ã®è©•ä¾¡æ–¹æ³•ã‚ˆã‚Šã‚‚é«˜é€Ÿã§ç²¾åº¦ã¨åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/865" target="_blank" rel="noopener noreferrer" class="title-link">Improving Factuality of Abstractive Summarization without Sacrificing Summary Quality, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- äº‹å®Ÿæ€§ã‚’æ„è­˜ã—ãŸè¦ç´„ã®å“è³ªå‘ä¸Šã«é–¢ã™ã‚‹ç ”ç©¶ã¯ã‚ã‚‹ãŒã€å“è³ªã‚’çŠ ç‰²ã«ã™ã‚‹ã“ã¨ãªãäº‹å®Ÿæ€§ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ãŒã»ã¨ã‚“ã©ãªã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ŒEffective Factual Summarizationã€ã¨ã„ã†æŠ€è¡“ã‚’ææ¡ˆã—ã€äº‹å®Ÿæ€§ã¨é¡ä¼¼æ€§ã®æŒ‡æ¨™ã®ä¸¡æ–¹ã§å¤§å¹…ãªæ”¹å–„ã‚’ç¤ºã™ã“ã¨ã‚’ç¤ºã—ãŸã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ç«¶åˆã‚’é˜²ããŸã‚ã«2ã¤ã®æŒ‡æ¨™ã‚’çµ„ã¿åˆã‚ã›ã‚‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°æˆ¦ç•¥ã‚’ææ¡ˆã—ã€XSUMã®FactCCã§ã¯æœ€å¤§6ãƒã‚¤ãƒ³ãƒˆã€CNN/DMã§ã¯11ãƒã‚¤ãƒ³ãƒˆã®æ”¹å–„ãŒè¦‹ã‚‰ã‚ŒãŸã€‚ã¾ãŸã€é¡ä¼¼æ€§ã‚„è¦ç´„ã®æŠ½è±¡æ€§ã«ã¯è² ã®å½±éŸ¿ã‚’ä¸ãˆãªã„ã€‚</span>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/GrammaticalErrorCorrection.html" target="_blank" rel="noopener noreferrer">#GrammaticalErrorCorrection</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/864" target="_blank" rel="noopener noreferrer" class="title-link">Enhancing Grammatical Error Correction Systems with Explanations, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æ–‡æ³•ã‚¨ãƒ©ãƒ¼ä¿®æ­£ã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½å‘ä¸Šã®ãŸã‚ã«ã€ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¨æ–‡æ³•ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ãŒæ³¨é‡ˆä»˜ã‘ã•ã‚ŒãŸå¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹EXPECTã‚’ç´¹ä»‹ã™ã‚‹ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã€èª¬æ˜å¯èƒ½ãªGECã‚·ã‚¹ãƒ†ãƒ ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨åˆ†æã‚’ææ¡ˆã—ã€äººé–“ã®è©•ä¾¡ã«ã‚ˆã£ã¦ãã®æœ‰ç”¨æ€§ã‚’ç¢ºèªã™ã‚‹ã€‚</span>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/MultitaskLearning.html" target="_blank" rel="noopener noreferrer">#MultitaskLearning</a>
<a class="button" href="articles/Zero/FewShotLearning.html" target="_blank" rel="noopener noreferrer">#Zero/FewShotLearning</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/863" target="_blank" rel="noopener noreferrer" class="title-link">Few-Shot Data-to-Text Generation via Unified Representation and Multi-Source Learning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€ã•ã¾ã–ã¾ãªå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã§ãã‚‹çµ±ä¸€ã•ã‚ŒãŸè¡¨ç¾ã‚’æä¾›ã—ã€ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ãªã©ã®ã‚·ãƒŠãƒªã‚ªã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ææ¡ˆæ‰‹æ³•ãŒä»–ã®æ–¹æ³•ã¨æ¯”è¼ƒã—ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ãŠã‘ã‚‹é‡è¦ãªé€²æ­©ã§ã™ã€‚</span>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/860" target="_blank" rel="noopener noreferrer" class="title-link">An Invariant Learning Characterization of Controlled Text Generation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- åˆ¶å¾¡ã•ã‚ŒãŸç”Ÿæˆã§ã¯ã€äºˆæ¸¬å™¨ã®è¨“ç·´ã«ä½¿ç”¨ã•ã‚Œã‚‹åˆ†å¸ƒã¨ç•°ãªã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†å¸ƒãŒã‚ã‚‹å ´åˆã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€ä¸å¤‰æ€§ã‚’æŒã¤äºˆæ¸¬å™¨ãŒåŠ¹æœçš„ã§ã‚ã‚‹ã¨ã„ã†è€ƒãˆæ–¹ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚ã•ã‚‰ã«ã€ã“ã®ç‰¹æ€§ã‚’æ´»ã‹ã™ãŸã‚ã®è‡ªç„¶ãªè§£æ±ºç­–ã¨ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚‚ææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€åˆ¶å¾¡ã•ã‚ŒãŸç”Ÿæˆã«ãŠã‘ã‚‹åˆ†å¸ƒã‚·ãƒ•ãƒˆã®èª²é¡Œã¨ä¸å¤‰æ€§æ‰‹æ³•ã®æ½œåœ¨èƒ½åŠ›ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/859" target="_blank" rel="noopener noreferrer" class="title-link">Abstractive Summarizers are Excellent Extractive Summarizers, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æŠ½å‡ºå‹è¦ç´„ã¨è¦ç´„å‹è¦ç´„ã®ç›¸ä¹—åŠ¹æœã‚’æ¢æ±‚ã—ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ»ãƒˆã‚¥ãƒ»ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ»ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ç”¨ã—ãŸ3ã¤ã®æ–°ã—ã„æ¨è«–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¦ç´„å‹ã‚·ã‚¹ãƒ†ãƒ ãŒæŠ½å‡ºå‹ã‚·ã‚¹ãƒ†ãƒ ã‚’è¶…ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€è¦ç´„å‹ã‚·ã‚¹ãƒ†ãƒ ã¯æŠ½å‡ºå‹ã®ã‚ªãƒ©ã‚¯ãƒ«è¦ç´„ã«ã•ã‚‰ã•ã‚Œã‚‹ã“ã¨ãªãã€ä¸¡æ–¹ã®è¦ç´„ã‚’å˜ä¸€ã®ãƒ¢ãƒ‡ãƒ«ã§ç”Ÿæˆã§ãã‚‹ã“ã¨ã‚‚ç¤ºã—ã¾ã—ãŸã€‚ã“ã‚Œã¯ã€æŠ½å‡ºå‹ãƒ©ãƒ™ãƒ«ã®å¿…è¦æ€§ã«ç–‘å•ã‚’æŠ•ã’ã‹ã‘ã‚‹ã‚‚ã®ã§ã‚ã‚Šã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã®æœ‰æœ›ãªç ”ç©¶æ–¹å‘ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/NaturalLanguageUnderstanding.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageUnderstanding</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/858" target="_blank" rel="noopener noreferrer" class="title-link">[TACL] Efficient Long-Text Understanding with Short-Text Models, TACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹SLEDã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚SLEDã¯ã€æ—¢å­˜ã®çŸ­æ–‡ã®äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å†åˆ©ç”¨ã—ã€å…¥åŠ›ã‚’é‡ãªã‚Šåˆã†ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚åˆ¶å¾¡ã•ã‚ŒãŸå®Ÿé¨“ã«ã‚ˆã‚Šã€SLEDãŒé•·ã„ãƒ†ã‚­ã‚¹ãƒˆç†è§£ã«æœ‰åŠ¹ã§ã‚ã‚Šã€å°‚ç”¨ã®é«˜ä¾¡ãªäº‹å‰å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—ãŒå¿…è¦ãªå°‚é–€ãƒ¢ãƒ‡ãƒ«ã¨ç«¶åˆã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/857" target="_blank" rel="noopener noreferrer" class="title-link">Pre-Training to Learn in Context, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ã¯ã€ã‚¿ã‚¹ã‚¯ã®ä¾‹ã¨æ–‡è„ˆã‹ã‚‰ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹æ–¹æ³•ã§ã‚ã‚Šã€æ³¨ç›®ã•ã‚Œã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€ç¾åœ¨ã®æ–¹æ³•ã§ã¯ååˆ†ã«æ´»ç”¨ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ç§ãŸã¡ã¯PICLã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã‚Œã¯ã€ä¸€èˆ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ¼ãƒ‘ã‚¹ã§ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰å­¦ç¿’ã—ã€æ–‡è„ˆã«åŸºã¥ã„ã¦ã‚¿ã‚¹ã‚¯ã‚’æ¨è«–ã—ã¦å®Ÿè¡Œã™ã‚‹èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚ç§ãŸã¡ã¯ã€PICLã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã—ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/DynamicNetworks.html" target="_blank" rel="noopener noreferrer">#DynamicNetworks</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/856" target="_blank" rel="noopener noreferrer" class="title-link">PAD-Net: An Efficient Framework for Dynamic Networks, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¸€èˆ¬çš„ãªå•é¡Œç‚¹ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€éƒ¨åˆ†çš„ã«ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆPAD-Netï¼‰ã‚’ææ¡ˆã—ã¾ã™ã€‚PAD-Netã¯ã€å†—é•·ãªãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é™çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹ã“ã¨ã§ã€å±•é–‹ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›ã—ã€åŠ¹ç‡çš„ãªãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å®Ÿç¾ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€PAD-NetãŒç”»åƒåˆ†é¡ã¨è¨€èªç†è§£ã®ã‚¿ã‚¹ã‚¯ã§é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã€å¾“æ¥ã®ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Argument.html" target="_blank" rel="noopener noreferrer">#Argument</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/855" target="_blank" rel="noopener noreferrer" class="title-link">ArgU: A Controllable Factual Argument Generator, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€é«˜å“è³ªãªè«–è¨¼ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã€åˆ¶å¾¡ã‚³ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ãŸãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«è«–è¨¼ç”Ÿæˆå™¨ArgUã‚’ææ¡ˆã—ã¾ã™ã€‚ã¾ãŸã€è«–è¨¼ã‚¹ã‚­ãƒ¼ãƒ ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã®å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€æ³¨é‡ˆä»˜ã‘ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã¤ã„ã¦è©³ç´°ã«èª¬æ˜ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€è«–è¨¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹æ¨è«–æˆ¦ç•¥ã‚’è©¦è¡Œã—ã€å¤šæ§˜ãªè«–è¨¼ã‚’è‡ªå‹•çš„ã«ç”Ÿæˆã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚</span>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<a class="button" href="articles/Out-of-DistributionDetection.html" target="_blank" rel="noopener noreferrer">#Out-of-DistributionDetection</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/854" target="_blank" rel="noopener noreferrer" class="title-link">Is Fine-tuning Needed? Pre-trained Language Models Are Near Perfect for Out-of-Domain Detection, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã§äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦OODæ¤œå‡ºã‚’è¡Œã†åŠ¹æœã‚’èª¿æŸ»ã—ã¾ã—ãŸã€‚ã•ã¾ã–ã¾ãªã‚¿ã‚¤ãƒ—ã®åˆ†å¸ƒã‚·ãƒ•ãƒˆã«ãŠã„ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹ã»ã¼å®Œç’§ãªOODæ¤œå‡ºæ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Contents-based.html" target="_blank" rel="noopener noreferrer">#Contents-based</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<a class="button" href="articles/ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/852" target="_blank" rel="noopener noreferrer" class="title-link">UniTRec: A Unified Text-to-Text Transformer and Joint Contrastive Learning Framework for Text-based Recommendation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆPLMï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®æ¨è–¦ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹UniTRecã‚’ææ¡ˆã—ã¾ã™ã€‚UniTRecã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å±¥æ­´ã®æ–‡è„ˆã‚’ã‚ˆã‚Šè‰¯ããƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ãŸã‚ã«çµ±ä¸€ã•ã‚ŒãŸãƒ­ãƒ¼ã‚«ãƒ«-ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³Transformerã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’ä½¿ç”¨ã—ã€å€™è£œã®ãƒ†ã‚­ã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã®è¨€èªã®è¤‡é›‘ã•ã‚’æ¨å®šã™ã‚‹ãŸã‚ã«Transformerãƒ‡ã‚³ãƒ¼ãƒ€ã‚’æ´»ç”¨ã—ã¾ã™ã€‚å¹…åºƒã„è©•ä¾¡ã«ã‚ˆã‚Šã€UniTRecãŒãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®æ¨è–¦ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NumericReasoning.html" target="_blank" rel="noopener noreferrer">#NumericReasoning</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/851" target="_blank" rel="noopener noreferrer" class="title-link">A Survey of Deep Learning for Mathematical Reasoning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æ•°å­¦çš„ãªæ¨è«–ã¨ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®é–¢ä¿‚ã«ã¤ã„ã¦ã®èª¿æŸ»è«–æ–‡ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€æ•°å­¦çš„ãªæ¨è«–ã«ãŠã‘ã‚‹ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®é€²æ­©ã¨å°†æ¥ã®ç ”ç©¶æ–¹å‘ã«ã¤ã„ã¦è­°è«–ã—ã¦ã„ã¾ã™ã€‚æ•°å­¦çš„ãªæ¨è«–ã¯æ©Ÿæ¢°å­¦ç¿’ã¨è‡ªç„¶è¨€èªå‡¦ç†ã®åˆ†é‡ã§é‡è¦ã§ã‚ã‚Šã€ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®ãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã¨ã—ã¦æ©Ÿèƒ½ã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€å¤§è¦æ¨¡ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ã®é€²æ­©ã«ã‚ˆã‚Šã€æ•°å­¦çš„ãªæ¨è«–ã«å¯¾ã™ã‚‹ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®åˆ©ç”¨ãŒå¯èƒ½ã«ãªã‚Šã¾ã—ãŸã€‚æ—¢å­˜ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨æ–¹æ³•ã‚’è©•ä¾¡ã—ã€å°†æ¥ã®ç ”ç©¶æ–¹å‘ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Faithfulness.html" target="_blank" rel="noopener noreferrer">#Faithfulness</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/850" target="_blank" rel="noopener noreferrer" class="title-link">Faithfulness Tests for Natural Language Explanations, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜ã®å¿ å®Ÿæ€§ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®2ã¤ã®ãƒ†ã‚¹ãƒˆã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚1ã¤ç›®ã¯ã€ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¯ãƒãƒ¥ã‚¢ãƒ«ãªäºˆæ¸¬ã«ã¤ãªãŒã‚‹ç†ç”±ã‚’æŒ¿å…¥ã™ã‚‹ãŸã‚ã®ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¯ãƒãƒ¥ã‚¢ãƒ«å…¥åŠ›ã‚¨ãƒ‡ã‚£ã‚¿ã‚’ææ¡ˆã—ã€2ã¤ç›®ã¯ç”Ÿæˆã•ã‚ŒãŸèª¬æ˜ã‹ã‚‰å…¥åŠ›ã‚’å†æ§‹ç¯‰ã—ã€åŒã˜äºˆæ¸¬ã«ã¤ãªãŒã‚‹é »åº¦ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãƒ†ã‚¹ãƒˆã§ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ†ã‚¹ãƒˆã¯ã€å¿ å®Ÿãªèª¬æ˜ã®é–‹ç™ºã«ãŠã„ã¦åŸºæœ¬çš„ãªãƒ„ãƒ¼ãƒ«ã¨ãªã‚Šã¾ã™ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/849" target="_blank" rel="noopener noreferrer" class="title-link">Reasoning with Language Model Prompting: A Survey, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€æ¨è«–ã«é–¢ã™ã‚‹æœ€æ–°ã®ç ”ç©¶ã«ã¤ã„ã¦åŒ…æ‹¬çš„ãªèª¿æŸ»ã‚’è¡Œã„ã€åˆå¿ƒè€…ã‚’æ”¯æ´ã™ã‚‹ãŸã‚ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚ã¾ãŸã€æ¨è«–èƒ½åŠ›ã®è¦å› ã‚„å°†æ¥ã®ç ”ç©¶æ–¹å‘ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã¾ã™ã€‚ãƒªã‚½ãƒ¼ã‚¹ã¯å®šæœŸçš„ã«æ›´æ–°ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/Faithfulness.html" target="_blank" rel="noopener noreferrer">#Faithfulness</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/848" target="_blank" rel="noopener noreferrer" class="title-link">Extractive is not Faithful: An Investigation of Broad Unfaithfulness Problems in Extractive Summarization, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æŠ½å‡ºçš„ãªè¦ç´„ã®ä¸æ­£ç¢ºã•ã®å•é¡Œã«ã¤ã„ã¦è­°è«–ã—ã€ãã‚Œã‚’5ã¤ã®ã‚¿ã‚¤ãƒ—ã«åˆ†é¡ã—ã¾ã™ã€‚ã•ã‚‰ã«ã€æ–°ã—ã„å°ºåº¦ã§ã‚ã‚‹ExtEvalã‚’ææ¡ˆã—ã€ä¸æ­£ç¢ºãªè¦ç´„ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€æŠ½å‡ºçš„ãªè¦ç´„ã®ä¸æ­£ç¢ºã•ã«å¯¾ã™ã‚‹èªè­˜ã‚’é«˜ã‚ã€å°†æ¥ã®ç ”ç©¶ã«å½¹ç«‹ã¤ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Extractive Summarizatinoã®Faithfulnessã«é–¢ã™ã‚‹ç ”ç©¶ã€‚<br><br>&gt;æŠ½å‡ºçš„ãªè¦ç´„ã¯æŠ½è±¡çš„ãªè¦ç´„ã®ä¸€èˆ¬çš„ãªä¸æ­£ç¢ºã•ã®å•é¡Œã«ã¯ã‚ã¾ã‚Šå½±éŸ¿ã‚’å—ã‘ã«ãã„ã§ã™ãŒã€ãã‚Œã¯æŠ½å‡ºçš„ãªè¦ç´„ãŒæ­£ç¢ºã§ã‚ã‚‹ã“ã¨ã‚’æ„å‘³ã™ã‚‹ã®ã§ã—ã‚‡ã†ã‹ï¼Ÿçµè«–ã¯ãƒãƒ¼ã§ã™ã€‚<br><br>&gt;æœ¬ç ”ç©¶ã§ã¯ã€æŠ½å‡ºçš„ãªè¦ç´„ã«ç¾ã‚Œã‚‹åºƒç¯„ãªä¸æ­£ç¢ºã•ã®å•é¡Œï¼ˆéå«æ„ã‚’å«ã‚€ï¼‰ã‚’5ã¤ã®ã‚¿ã‚¤ãƒ—ã«åˆ†é¡<br><br>&gt;ä¸æ­£ç¢ºãªå…±å‚ç…§ã€ä¸å®Œå…¨ãªå…±å‚ç…§ã€ä¸æ­£ç¢ºãªè«‡è©±ã€ä¸å®Œå…¨ãªè«‡è©±ã€ãŠã‚ˆã³ä»–ã®èª¤è§£ã‚’æ‹›ãæƒ…å ±ãŒå«ã¾ã‚Œã¾ã™ã€‚<br><br>&gt;ç§ãŸã¡ã¯ã€16ã®ç•°ãªã‚‹æŠ½å‡ºã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸ1600ã®è‹±èªã®è¦ç´„ã‚’äººé–“ã«ãƒ©ãƒ™ãƒ«ä»˜ã‘ã™ã‚‹ã‚ˆã†ã«ä¾é ¼ã—ã¾ã—ãŸã€‚ãã®çµæœã€è¦ç´„ã®30ï¼…ã«ã¯å°‘ãªãã¨ã‚‚5ã¤ã®å•é¡Œã®ã†ã¡ã®1ã¤ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚<br><br> <br><br> ãŠã‚‚ã—ã‚ã„ã€‚</p></span><br><br>
<a class="button" href="articles/General.html" target="_blank" rel="noopener noreferrer">#General</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/AES(AutomatedEssayScoring).html" target="_blank" rel="noopener noreferrer">#AES(AutomatedEssayScoring)</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/847" target="_blank" rel="noopener noreferrer" class="title-link">Improving Domain Generalization for Prompt-Aware Essay Scoring via Disentangled Representation Learning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå‹•ã‚¨ãƒƒã‚»ã‚¤ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆAESï¼‰ã¯ã€ã‚¨ãƒƒã‚»ã‚¤ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«ã§ã™ãŒã€æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã¯ç‰¹å®šã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã—ã‹é©ç”¨ã§ããšã€æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã—ã¦ã¯ã†ã¾ãæ±åŒ–ã§ãã¾ã›ã‚“ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ä¾å­˜ã—ãªã„ç‰¹å¾´ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå›ºæœ‰ã®ç‰¹å¾´ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«AESãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã€è¡¨ç¾ã®æ±åŒ–ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®åˆ†é›¢è¡¨ç¾å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ASAPã¨TOEFL11ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å®Ÿé¨“çµæœã¯ã€ææ¡ˆæ‰‹æ³•ã®æœ‰åŠ¹æ€§ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/846" target="_blank" rel="noopener noreferrer" class="title-link">Controllable Text Generation via Probability Density Estimation in the Latent Space, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ½œåœ¨ç©ºé–“ã§ã®ç¢ºç‡å¯†åº¦æ¨å®šã‚’ç”¨ã„ãŸæ–°ã—ã„åˆ¶å¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ã€å¯é€†å¤‰æ›é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦æ½œåœ¨ç©ºé–“ã®è¤‡é›‘ãªåˆ†å¸ƒã‚’å˜ç´”ãªã‚¬ã‚¦ã‚¹åˆ†å¸ƒã«ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã€æ´—ç·´ã•ã‚ŒãŸæŸ”è»Ÿãªåˆ¶å¾¡ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€ææ¡ˆæ‰‹æ³•ãŒå±æ€§ã®é–¢é€£æ€§ã¨ãƒ†ã‚­ã‚¹ãƒˆã®å“è³ªã«ãŠã„ã¦å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€æ–°ãŸãªSOTAã‚’é”æˆã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ãªã‚‹åˆ†æã«ã‚ˆã‚Šã€åˆ¶å¾¡æˆ¦ç•¥ã®æŸ”è»Ÿæ€§ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/QuestionGeneration.html" target="_blank" rel="noopener noreferrer">#QuestionGeneration</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/845" target="_blank" rel="noopener noreferrer" class="title-link">Covering Uncommon Ground: Gap-Focused Question Generation for Answer Assessment, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ•™è‚²çš„ãªå¯¾è©±ã«ãŠã‘ã‚‹æƒ…å ±ã®ã‚®ãƒ£ãƒƒãƒ—ã«ç„¦ç‚¹ã‚’å½“ã¦ã€è‡ªå‹•çš„ã«è³ªå•ã‚’ç”Ÿæˆã™ã‚‹å•é¡Œã«å–ã‚Šçµ„ã‚“ã§ã„ã¾ã™ã€‚è‰¯ã„è³ªå•ã®è¦ç´ ã‚’æ˜ç¢ºã«ã—ã€ãã‚Œã‚’æº€ãŸã™ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã¾ã™ã€‚ã¾ãŸã€äººé–“ã®ã‚¢ãƒãƒ†ãƒ¼ã‚¿ãƒ¼ã«ã‚ˆã‚‹è©•ä¾¡ã‚’è¡Œã„ã€ç”Ÿæˆã•ã‚ŒãŸè³ªå•ã®ç«¶äº‰åŠ›ã‚’ç¤ºã—ã¾ã™ã€‚</span>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Ensemble.html" target="_blank" rel="noopener noreferrer">#Ensemble</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/844" target="_blank" rel="noopener noreferrer" class="title-link">Multi-CLS BERT: An Efficient Alternative to Traditional Ensembling, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€BERTãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•ã§ã‚ã‚‹Multi-CLS BERTã‚’ææ¡ˆã—ã¾ã™ã€‚Multi-CLS BERTã¯ã€è¤‡æ•°ã®CLSãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦å¤šæ§˜æ€§ã‚’ä¿ƒé€²ã—ã€å˜ä¸€ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹ã ã‘ã§ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åŠ¹æœã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€Multi-CLS BERTãŒGLUEã¨SuperGLUEã®ã‚¿ã‚¹ã‚¯ã§å…¨ä½“çš„ãªç²¾åº¦ã¨ä¿¡é ¼åº¦ã®æ¨å®šã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã¾ãŸã€é€šå¸¸ã®BERTã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã¨ã»ã¼åŒç­‰ã®æ€§èƒ½ã‚’æŒã¡ãªãŒã‚‰ã€è¨ˆç®—é‡ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒç´„4å€å°‘ãªããªã£ã¦ã„ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/843" target="_blank" rel="noopener noreferrer" class="title-link">MeetingBank: A Benchmark Dataset for Meeting Summarization, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- ä¼šè­°ã®è¦ç´„æŠ€è¡“ã®é–‹ç™ºã«ã¯æ³¨é‡ˆä»˜ãã®ä¼šè­°ã‚³ãƒ¼ãƒ‘ã‚¹ãŒå¿…è¦ã§ã™ãŒã€ãã®æ¬ å¦‚ãŒå•é¡Œã¨ãªã£ã¦ã„ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹MeetingBankã‚’ææ¡ˆã—ã¾ã—ãŸã€‚MeetingBankã¯ã€ä¼šè­°è­°äº‹éŒ²ã‚’çŸ­ã„ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ã«åˆ†å‰²ã—ã€ç‰¹å®šã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨å¯¾å¿œã•ã›ã‚‹ã“ã¨ã§ã€ä¼šè­°ã®è¦ç´„ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç®¡ç†ã—ã‚„ã™ã„ã‚¿ã‚¹ã‚¯ã«åˆ†å‰²ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€ä¼šè­°è¦ç´„ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã¨ã—ã¦åˆ©ç”¨ã§ãã‚‹ã ã‘ã§ãªãã€ä¸€èˆ¬ã®äººã€…ãŒè­°ä¼šã®æ„æ€æ±ºå®šã®ä»•çµ„ã¿ã‚’ç†è§£ã™ã‚‹ã®ã«ã‚‚å½¹ç«‹ã¡ã¾ã™ã€‚ãƒ“ãƒ‡ã‚ªãƒªãƒ³ã‚¯ã€ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€å‚ç…§è¦ç´„ãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€èˆ¬ã«å…¬é–‹ã—ã€ä¼šè­°è¦ç´„æŠ€è¡“ã®é–‹ç™ºã‚’ä¿ƒé€²ã—ã¾ã™ã€‚</span>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Unsupervised.html" target="_blank" rel="noopener noreferrer">#Unsupervised</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/Speech.html" target="_blank" rel="noopener noreferrer">#Speech</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/842" target="_blank" rel="noopener noreferrer" class="title-link">Simple and Effective Unsupervised Speech Translation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- éŸ³å£°ç¿»è¨³ã®ãŸã‚ã®ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹ãŸã‚ã€éæ•™å¸«ã‚ã‚Šæ‰‹æ³•ã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•ã‚’ç ”ç©¶ã—ã¦ã„ã‚‹ã€‚ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚„æ“¬ä¼¼ãƒ©ãƒ™ãƒ«ç”Ÿæˆã‚’ä½¿ç”¨ã—ã€éæ•™å¸«ã‚ã‚Šãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œæŠ€è¡“ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚å®Ÿé¨“ã®çµæœã€å¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/841" target="_blank" rel="noopener noreferrer" class="title-link">On Improving Summarization Factual Consistency from Natural Language Feedback, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è‡ªç„¶è¨€èªã®æƒ…å ±ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ´»ç”¨ã—ã¦è¦ç´„ã®å“è³ªã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã‚’å‘ä¸Šã•ã›ã‚‹æ–¹æ³•ã‚’èª¿æŸ»ã—ã¾ã—ãŸã€‚DeFactoã¨ã„ã†é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã€è¦ç´„ã®ç·¨é›†ã‚„ä¿®æ­£ã«é–¢ã™ã‚‹è‡ªç„¶è¨€èªç”Ÿæˆã‚¿ã‚¹ã‚¯ã‚’ç ”ç©¶ã—ã¾ã—ãŸã€‚ã¾ãŸã€å¾®èª¿æ•´ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦è¦ç´„ã®å“è³ªã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚‚ç¤ºã—ã¾ã—ãŸã€‚ã—ã‹ã—ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã¯åˆ¶å¾¡å¯èƒ½ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ã¯å‘ã„ã¦ã„ãªã„ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚</span>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/840" target="_blank" rel="noopener noreferrer" class="title-link">TREA: Tree-Structure Reasoning Schema for Conversational Recommendation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- ä¼šè©±å‹ã®æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ï¼ˆCRSï¼‰ã§ã¯ã€å¤–éƒ¨çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦å¯¾è©±ã®æ–‡è„ˆã‚’ç†è§£ã—ã€é–¢é€£ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ¨è–¦ã™ã‚‹ã“ã¨ãŒæ±‚ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€ç¾åœ¨ã®æ¨è«–ãƒ¢ãƒ‡ãƒ«ã¯è¤‡é›‘ãªé–¢ä¿‚ã‚’å®Œå…¨ã«æŠŠæ¡ã§ããªã„ãŸã‚ã€æ–°ã—ã„ãƒ„ãƒªãƒ¼æ§‹é€ ã®æ¨è«–ã‚¹ã‚­ãƒ¼ãƒã§ã‚ã‚‹TREAã‚’ææ¡ˆã™ã‚‹ã€‚TREAã¯å¤šéšå±¤ã®ãƒ„ãƒªãƒ¼ã‚’ä½¿ç”¨ã—ã¦å› æœé–¢ä¿‚ã‚’æ˜ç¢ºã«ã—ã€éå»ã®å¯¾è©±ã‚’æ´»ç”¨ã—ã¦ã‚ˆã‚Šåˆç†çš„ãªå¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ã€‚å¹…åºƒã„å®Ÿé¨“ã«ã‚ˆã‚Šã€TREAã®æœ‰åŠ¹æ€§ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/839" target="_blank" rel="noopener noreferrer" class="title-link">MPCHAT: Towards Multimodal Persona-Grounded Conversation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã®ä¸¡æ–¹ã‚’ä½¿ç”¨ã—ã¦ãƒ‘ãƒ¼ã‚½ãƒŠã‚’æ‹¡å¼µã—ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªå¯¾è©±ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹MPCHATã‚’ææ¡ˆã—ã¾ã™ã€‚ã•ã‚‰ã«ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‘ãƒ¼ã‚½ãƒŠã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€å¿œç­”äºˆæ¸¬ã€ãƒ‘ãƒ¼ã‚½ãƒŠã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°äºˆæ¸¬ã€è©±è€…ã®è­˜åˆ¥ã¨ã„ã£ãŸã‚¿ã‚¹ã‚¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’çµ±è¨ˆçš„ã«æœ‰æ„ã«æ”¹å–„ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªå¯¾è©±ç†è§£ã«ãŠã„ã¦ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‘ãƒ¼ã‚½ãƒŠã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã€MPCHATãŒé«˜å“è³ªãªãƒªã‚½ãƒ¼ã‚¹ã¨ã—ã¦å½¹ç«‹ã¤ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/838" target="_blank" rel="noopener noreferrer" class="title-link">Solving Math Word Problems via Cooperative Reasoning induced Language Models, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆPLMï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€æ•°å­¦ã®æ–‡ç« å•é¡Œï¼ˆMWPsï¼‰ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®Cooperative Reasoningï¼ˆCoReï¼‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚CoReã§ã¯ã€ç”Ÿæˆå™¨ã¨æ¤œè¨¼å™¨ã®äºŒã¤ã®æ¨è«–ã‚·ã‚¹ãƒ†ãƒ ãŒç›¸äº’ä½œç”¨ã—ã€æ¨è«–ãƒ‘ã‚¹ã‚’ç”Ÿæˆã—è©•ä¾¡ã‚’ç›£ç£ã—ã¾ã™ã€‚CoReã¯ã€æ•°å­¦çš„æ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æœ€å…ˆç«¯ã®æ‰‹æ³•ã«æ¯”ã¹ã¦æœ€å¤§9.6ï¼…ã®æ”¹å–„ã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/837" target="_blank" rel="noopener noreferrer" class="title-link">Tailor: A Soft-Prompt-Based Approach to Attribute-Based Controlled Text Generation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- å±æ€§ãƒ™ãƒ¼ã‚¹ã®åˆ¶å¾¡ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆï¼ˆCTGï¼‰ã§ã¯ã€æœ›ã¾ã—ã„å±æ€§ã‚’æŒã¤æ–‡ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒç›®æŒ‡ã•ã‚Œã¦ã„ã‚‹ã€‚å¾“æ¥ã®æ‰‹æ³•ã§ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„è¿½åŠ ã®å±æ€§åˆ†é¡å™¨ã‚’ä½¿ç”¨ã—ã¦ã„ãŸãŒã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¨æ¨è«–æ™‚é–“ã®å¢—åŠ ãŒæ‡¸å¿µã•ã‚Œã¦ã„ãŸã€‚ãã“ã§ã€æœ¬ç ”ç©¶ã§ã¯åŠ¹ç‡çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸå±æ€§ãƒ™ãƒ¼ã‚¹ã®CTGã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€å„å±æ€§ã‚’äº‹å‰å­¦ç¿’ã•ã‚ŒãŸé€£ç¶šãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦è¡¨ç¾ã—ã€å›ºå®šã•ã‚ŒãŸäº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ã‚¬ã‚¤ãƒ‰ã—ã¦å±æ€§ã‚’æº€ãŸã™æ–‡ã‚’ç”Ÿæˆã™ã‚‹ã€‚ã•ã‚‰ã«ã€2ã¤ã®è§£æ±ºç­–ã‚’æä¾›ã—ã¦ã€çµ„ã¿åˆã‚ã›ã‚’å¼·åŒ–ã—ã¦ã„ã‚‹ã€‚å®Ÿé¨“ã®çµæœã€è¿½åŠ ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã§åŠ¹æœçš„ãªæ”¹å–„ãŒå®Ÿç¾ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/836" target="_blank" rel="noopener noreferrer" class="title-link">[TACL] Abstractive Meeting Summarization: A Survey, TACL'23</a>
<span class="snippet"><span>GPT Summary</span>- ä¼šè­°ã®è¦ç´„åŒ–ã«ãŠã„ã¦ã€æ·±å±¤å­¦ç¿’ã®é€²æ­©ã«ã‚ˆã‚ŠæŠ½è±¡çš„è¦ç´„ãŒæ”¹å–„ã•ã‚ŒãŸã€‚æœ¬è«–æ–‡ã§ã¯ã€æŠ½è±¡çš„ãªä¼šè­°ã®è¦ç´„åŒ–ã®èª²é¡Œã¨ã€ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒ¢ãƒ‡ãƒ«ã€è©•ä¾¡æŒ‡æ¨™ã«ã¤ã„ã¦æ¦‚èª¬ã™ã‚‹ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/835" target="_blank" rel="noopener noreferrer" class="title-link">Table and Image Generation for Investigating Knowledge of Entities in Pre-trained Vision and Language Models, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Visionï¼†Languageï¼ˆVï¼†Lï¼‰ãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®çŸ¥è­˜ã®ä¿æŒæ–¹æ³•ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã«ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ç”»åƒã®ç”Ÿæˆã‚¿ã‚¹ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®ã‚¿ã‚¹ã‚¯ã§ã¯ã€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨é–¢é€£ã™ã‚‹ç”»åƒã®çŸ¥è­˜ã‚’å«ã‚€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ç¬¬ä¸€ã®éƒ¨åˆ†ã¨ã€ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã¨ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®é–¢é€£çŸ¥è­˜ã‚’å«ã‚€ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ç¬¬äºŒã®éƒ¨åˆ†ãŒã‚ã‚Šã¾ã™ã€‚ææ¡ˆã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã«ã€Wikipediaã®ç´„20ä¸‡ã®infoboxã‹ã‚‰WikiTIGãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚æœ€å…ˆç«¯ã®Vï¼†Lãƒ¢ãƒ‡ãƒ«OFAã‚’ä½¿ç”¨ã—ã¦ã€ææ¡ˆã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã—ã¾ã—ãŸã€‚å®Ÿé¨“çµæœã¯ã€OFAãŒä¸€éƒ¨ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£çŸ¥è­˜ã‚’å¿˜ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/834" target="_blank" rel="noopener noreferrer" class="title-link">Focused Prefix Tuning for Controllable Text Generation, Ma+, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ³¨é‡ˆã®ãªã„å±æ€§ã«ã‚ˆã£ã¦åˆ¶å¾¡å¯èƒ½ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹å•é¡Œã«å¯¾ã—ã¦ã€ã€Œfocused prefix tuningï¼ˆFPTï¼‰ã€ã¨ã„ã†æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚FPTã¯æœ›ã¾ã—ã„å±æ€§ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã“ã¨ã§ã€åˆ¶å¾¡ç²¾åº¦ã¨ãƒ†ã‚­ã‚¹ãƒˆã®æµæš¢ã•ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã¾ãŸã€FPTã¯è¤‡æ•°å±æ€§åˆ¶å¾¡ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã‚‚ã€æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ãªãæ–°ã—ã„å±æ€§ã‚’åˆ¶å¾¡ã™ã‚‹æŸ”è»Ÿæ€§ã‚’æŒã¡ãªãŒã‚‰ã€åˆ¶å¾¡ç²¾åº¦ã‚’ä¿ã¤ã“ã¨ãŒã§ãã¾ã™ã€‚</span>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/LabelBias.html" target="_blank" rel="noopener noreferrer">#LabelBias</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/833" target="_blank" rel="noopener noreferrer" class="title-link">Mitigating Label Biases for In-context Learning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã«ãŠã‘ã‚‹ãƒ©ãƒ™ãƒ«ãƒã‚¤ã‚¢ã‚¹ã®ç¨®é¡ã‚’å®šç¾©ã—ã€ãã®å½±éŸ¿ã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®æ–¹æ³•ã‚’ææ¡ˆã™ã‚‹ç ”ç©¶ãŒè¡Œã‚ã‚Œã¾ã—ãŸã€‚ç‰¹ã«ã€ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ©ãƒ™ãƒ«ãƒã‚¤ã‚¢ã‚¹ã«ã¤ã„ã¦åˆã‚ã¦æ¦‚å¿µåŒ–ã•ã‚Œã€ãã®å½±éŸ¿ã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®ãƒã‚¤ã‚¢ã‚¹è£œæ­£æ–¹æ³•ãŒææ¡ˆã•ã‚Œã¾ã—ãŸã€‚ã“ã®æ–¹æ³•ã«ã‚ˆã‚Šã€GPT-Jã¨GPT-3ã®ICLãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤§å¹…ã«æ”¹å–„ã•ã‚Œã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚„ã‚¿ã‚¹ã‚¯ã«ã‚‚ä¸€èˆ¬åŒ–ã•ã‚Œã€ICLã«ãŠã‘ã‚‹ãƒ©ãƒ™ãƒ«ãƒã‚¤ã‚¢ã‚¹ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹æ‰‹æ³•ã¨ã—ã¦æœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/832" target="_blank" rel="noopener noreferrer" class="title-link">Do Models Really Learn to Follow Instructions? An Empirical Study of Instruction Tuning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®instruction tuningï¼ˆITï¼‰ã®ç ”ç©¶ã§ã¯ã€è¿½åŠ ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æä¾›ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®æ±åŒ–æ€§èƒ½ã‚’æŒã¤ç´ æ™´ã‚‰ã—ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå®Ÿç¾ã•ã‚Œã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€ITä¸­ã«ãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ã«æŒ‡ç¤ºã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã‹ã¯ã¾ã ç ”ç©¶ã•ã‚Œã¦ã„ãªã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¤‰æ›´ã•ã‚ŒãŸæŒ‡ç¤ºã¨å…ƒã®æŒ‡ç¤ºã¨ã®æ¯”è¼ƒã«ã‚ˆã£ã¦ã€ãƒ¢ãƒ‡ãƒ«ãŒITä¸­ã«æŒ‡ç¤ºã‚’ã©ã®ã‚ˆã†ã«åˆ©ç”¨ã™ã‚‹ã‹ã‚’åˆ†æã™ã‚‹ã€‚å®Ÿé¨“ã®çµæœã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯å…ƒã®æŒ‡ç¤ºã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ITã¨åŒæ§˜ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã®ç ”ç©¶ã¯ã€ã‚ˆã‚Šä¿¡é ¼æ€§ã®é«˜ã„ITæ‰‹æ³•ã¨è©•ä¾¡ã®ç·Šæ€¥æ€§ã‚’å¼·èª¿ã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/831" target="_blank" rel="noopener noreferrer" class="title-link">Learning to Imagine: Visually-Augmented Natural Language Generation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¦–è¦šæƒ…å ±ã‚’æ´»ç”¨ã—ãŸè‡ªç„¶è¨€èªç”Ÿæˆã®ãŸã‚ã®LIVEã¨ã„ã†æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚LIVEã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦å ´é¢ã‚’æƒ³åƒã—ã€é«˜å“è³ªãªç”»åƒã‚’åˆæˆã™ã‚‹æ–¹æ³•ã§ã™ã€‚ã¾ãŸã€CLIPã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã®æƒ³åƒåŠ›ã‚’è©•ä¾¡ã—ã€æ®µè½ã”ã¨ã«ç”»åƒã‚’ç”Ÿæˆã—ã¾ã™ã€‚ã•ã¾ã–ã¾ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€LIVEã®æœ‰åŠ¹æ€§ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã€ãƒ¢ãƒ‡ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>&gt;ã¾ãšã€ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦å ´é¢ã‚’æƒ³åƒã—ã¾ã™ã€‚å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦é«˜å“è³ªãªç”»åƒã‚’åˆæˆã™ã‚‹ãŸã‚ã«æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚æ¬¡ã«ã€CLIPã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆãŒæƒ³åƒåŠ›ã‚’å–šèµ·ã§ãã‚‹ã‹ã‚’äº‹å¾Œçš„ã«åˆ¤æ–­ã—ã¾ã™ã€‚æœ€å¾Œã«ã€ç§ãŸã¡ã®æƒ³åƒåŠ›ã¯å‹•çš„ã§ã‚ã‚Šã€æ®µè½å…¨ä½“ã«1ã¤ã®ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ã®ã§ã¯ãªãã€å„æ–‡ã«å¯¾ã—ã¦åˆæˆã‚’è¡Œã„ã¾ã™ã€‚<br><br><br><br>èˆˆå‘³æ·±ã„</p></span><br><br>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/InductiveBias.html" target="_blank" rel="noopener noreferrer">#InductiveBias</a>
<span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/830" target="_blank" rel="noopener noreferrer" class="title-link">Measuring Inductive Biases of In-Context Learning with Underspecified Demonstrations, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã«é©å¿œã•ã›ã‚‹ãŸã‚ã®é‡è¦ãªãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã§ã™ãŒã€ICLã®ä¸€èˆ¬åŒ–ã®æŒ¯ã‚‹èˆã„ã¯ã¾ã ååˆ†ã«ç†è§£ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ICLã®å¸°ç´çš„ãªãƒã‚¤ã‚¢ã‚¹ã«ã¤ã„ã¦èª¿æŸ»ã‚’è¡Œã„ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€ä¸å®Œå…¨ãªãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒä¸ãˆã‚‰ã‚ŒãŸå ´åˆã€ICLã¯ã©ã®ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ã‚’ã‚ˆã‚Šé »ç¹ã«ä½¿ç”¨ã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ã®ã‹ã‚’èª¿ã¹ã¾ã—ãŸã€‚å®Ÿé¨“ã®çµæœã€LLMsãŒæ˜ç¢ºãªãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãƒã‚¤ã‚¢ã‚¹ã‚’ç¤ºã™ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ã¾ãŸã€ç‰¹å®šã®ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ã‚’å¥½ã‚€ã‚ˆã†ãªå¸°ç´çš„ãªãƒã‚¤ã‚¢ã‚¹ã‚’èª²ã™ãŸã‚ã®ã•ã¾ã–ã¾ãªä»‹å…¥ã®åŠ¹æœã‚‚è©•ä¾¡ã—ã¾ã—ãŸã€‚å…¨ä½“ã¨ã—ã¦ã€ICLãŒã‚ˆã‚Šé »ç¹ã«åˆ©ç”¨ã™ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ã®ã‚¿ã‚¤ãƒ—ã¨ã€æ„å›³ã—ãŸã‚¿ã‚¹ã‚¯ã¨ã‚ˆã‚Šä¸€è‡´ã—ãŸå¸°ç´çš„ãªãƒã‚¤ã‚¢ã‚¹ã‚’èª²ã™æ–¹æ³•ã«ã¤ã„ã¦ã€ã‚ˆã‚Šåºƒç¯„ãªæƒ…å ±ã‚’æä¾›ã™ã‚‹çµæœã¨ãªã‚Šã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/829" target="_blank" rel="noopener noreferrer" class="title-link">SCOTT: Self-Consistent Chain-of-Thought Distillation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLMï¼‰ã‹ã‚‰å°ã•ãªCoTãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã®çŸ¥è­˜è’¸ç•™æ‰‹æ³•ã§ã‚ã‚‹SCOTTã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚SCOTTã¯ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã‚´ãƒ¼ãƒ«ãƒ‰ã‚¢ãƒ³ã‚µãƒ¼ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹æ ¹æ‹ ã‚’å¼•ãå‡ºã—ã€ã‚ˆã‚Šä¿¡æ†‘æ€§ã®ã‚ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã‚’ä¿ƒã—ã¾ã™ã€‚ã•ã‚‰ã«ã€å­¦ç”Ÿãƒ¢ãƒ‡ãƒ«ã¯ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã®ç›®çš„ã§æ•™å¸«ãŒç”Ÿæˆã—ãŸæ ¹æ‹ ã‚’ä½¿ç”¨ã—ã¦å­¦ç¿’ã•ã‚Œã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ææ¡ˆæ‰‹æ³•ãŒãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚ˆã‚Šã‚‚å¿ å®Ÿãªãƒ¢ãƒ‡ãƒ«ã‚’å°ãã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€æ ¹æ‹ ã‚’å°Šé‡ã™ã‚‹ã“ã¨ã§æ„æ€æ±ºå®šã‚’æ”¹å–„ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>CoTã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸ŠãŒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤§ãã„ãƒ¢ãƒ‡ãƒ«ã§ãªã„ã¨ç™ºæ®ã›ã‚Œãªã„ã“ã¨ã¯å…ƒè«–æ–‡ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
 ã§è€ƒå¯Ÿã•ã‚Œã¦ãŠã‚Šã€ãã‚Œã‚’ã‚ˆã‚Šå°ã•ã„ãƒ¢ãƒ‡ãƒ«ã«è’¸ç•™ã—ç™ºæ®ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€ãŠã‚‚ã—ã‚ã„</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Novelty.html" target="_blank" rel="noopener noreferrer">#Novelty</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/828" target="_blank" rel="noopener noreferrer" class="title-link">[TACL] How much do language models copy from their training data? Evaluating linguistic novelty in text generation using RAVEN, TACL'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®ç ”ç©¶ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®æ–°è¦æ€§ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®åˆ†æã‚¹ã‚¤ãƒ¼ãƒˆRAVENã‚’ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚è‹±èªã§è¨“ç·´ã•ã‚ŒãŸ4ã¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€å±€æ‰€çš„ãªæ§‹é€ ã¨å¤§è¦æ¨¡ãªæ§‹é€ ã®æ–°è¦æ€§ã‚’è©•ä¾¡ã—ã¾ã—ãŸã€‚çµæœã¨ã—ã¦ã€ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã¯å±€æ‰€çš„ãªæ§‹é€ ã«ãŠã„ã¦ã¯æ–°è¦æ€§ã«æ¬ ã‘ã¦ãŠã‚Šã€å¤§è¦æ¨¡ãªæ§‹é€ ã«ãŠã„ã¦ã¯äººé–“ã¨åŒç¨‹åº¦ã®æ–°è¦æ€§ãŒã‚ã‚Šã€æ™‚ã«ã¯è¨“ç·´ã‚»ãƒƒãƒˆã‹ã‚‰ã®é‡è¤‡ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚ã¾ãŸã€GPT-2ã®è©³ç´°ãªæ‰‹å‹•åˆ†æã«ã‚ˆã‚Šã€çµ„æˆçš„ãŠã‚ˆã³é¡æ¨çš„ãªä¸€èˆ¬åŒ–ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®ä½¿ç”¨ãŒç¤ºã•ã‚Œã€æ–°è¦ãƒ†ã‚­ã‚¹ãƒˆãŒå½¢æ…‹çš„ãŠã‚ˆã³æ§‹æ–‡çš„ã«å¦¥å½“ã§ã‚ã‚‹ãŒã€æ„å‘³çš„ãªå•é¡ŒãŒæ¯”è¼ƒçš„é »ç¹ã«ç™ºç”Ÿã™ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/DataDistillation.html" target="_blank" rel="noopener noreferrer">#DataDistillation</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Zero/FewShotLearning.html" target="_blank" rel="noopener noreferrer">#Zero/FewShotLearning</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/827" target="_blank" rel="noopener noreferrer" class="title-link">Dataset Distillation with Attention Labels for Fine-tuning BERT, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è’¸ç•™ã‚’ä½¿ç”¨ã—ã¦ã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ä¿æŒã—ãªãŒã‚‰ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è¿…é€Ÿã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®å°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹æ–¹æ³•ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’å¾®èª¿æ•´ã™ã‚‹ãŸã‚ã®è‡ªç„¶è¨€èªå‡¦ç†ã‚¿ã‚¹ã‚¯ã®è’¸ç•™ã•ã‚ŒãŸfew-shotãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹ç¯‰ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€æ³¨æ„ãƒ©ãƒ™ãƒ«ã‚’ä½¿ç”¨ã—ã¦few-shotãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€BERTã®å¾®èª¿æ•´ã«ãŠã„ã¦å°è±¡çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ä¾‹ãˆã°ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†é¡ã‚¿ã‚¹ã‚¯ã§ã¯ã€ã‚ãšã‹1ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ã¨ã‚ãšã‹1ã¤ã®å‹¾é…ã‚¹ãƒ†ãƒƒãƒ—ã®ã¿ã§ã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®98.5ï¼…ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Datadistillationã—ãŸã‚‰ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã†ã¡1ã‚µãƒ³ãƒ—ãƒ«ã®ã¿ã§ã€å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®98.5%ã®æ€§èƒ½ã‚’ç™ºæ®ã§ããŸã¨ã„ã†é©šç•°çš„ãªç ”ç©¶ï¼ˆã¾ãˆã‹ã‚å›ï¼‰</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/QuestionGeneration.html" target="_blank" rel="noopener noreferrer">#QuestionGeneration</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/824" target="_blank" rel="noopener noreferrer" class="title-link">Adaptive and Personalized Exercise Generation for Online Language Learning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³è¨€èªå­¦ç¿’ã®ãŸã‚ã®é©å¿œçš„ãªæ¼”ç¿’ç”Ÿæˆã®æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’ç ”ç©¶ã—ã¾ã—ãŸã€‚å­¦ç¿’å±¥æ­´ã‹ã‚‰å­¦ç”Ÿã®çŸ¥è­˜çŠ¶æ…‹ã‚’æ¨å®šã—ã€ãã®çŠ¶æ…‹ã«åŸºã¥ã„ã¦å€‹åˆ¥åŒ–ã•ã‚ŒãŸæ¼”ç¿’æ–‡ã‚’ç”Ÿæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸå®Ÿé¨“çµæœã‹ã‚‰ã€å­¦ç”Ÿã®çŠ¶æ…‹ã«å¿œã˜ãŸæ¼”ç¿’ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€æ•™è‚²ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®åˆ©ç”¨æ–¹æ³•ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã€å­¦ç¿’ã®åŠ¹ç‡åŒ–ã‚’ä¿ƒé€²ã§ãã‚‹å¯èƒ½æ€§ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Knowledge Tracingã§æ¨å®šã•ã‚ŒãŸç¿’ç†Ÿåº¦ã«åŸºã¥ã„ã¦ã€ã‚¨ã‚¯ã‚µã‚µã‚¤ã‚ºã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ç ”ç©¶ã€‚KTã¨NLGãŒçµ„ã¿åˆã‚ã•ã£ã¦ãŠã‚Šã€éå¸¸ã«ãŠã‚‚ã—ã‚ã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/975a4de3-4f68-4dc6-beb4-5ad32b706959" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/823" target="_blank" rel="noopener noreferrer" class="title-link">Measuring the Instability of Fine-Tuning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- äº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ä¸å®‰å®šã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ä¸å®‰å®šæ€§ã‚’å®šé‡åŒ–ã™ã‚‹æŒ‡æ¨™ã‚’åˆ†æã—ã€è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã™ã‚‹ã€‚ã¾ãŸã€æ—¢å­˜ã®ä¸å®‰å®šæ€§è»½æ¸›æ‰‹æ³•ã‚’å†è©•ä¾¡ã—ã€çµæœã‚’æä¾›ã™ã‚‹ã€‚</span>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Ensemble.html" target="_blank" rel="noopener noreferrer">#Ensemble</a>
<a class="button" href="articles/TransferLearning.html" target="_blank" rel="noopener noreferrer">#TransferLearning</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/822" target="_blank" rel="noopener noreferrer" class="title-link">Parameter-efficient Weight Ensembling Facilitates Task-level Knowledge Transfer, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã«åŠ¹æœçš„ã«é©å¿œã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€è»½é‡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã‚¿ã‚¹ã‚¯é–“ã§çŸ¥è­˜ã‚’è»¢é€ã™ã‚‹æ–¹æ³•ã‚’æ¢æ±‚ã—ã€ãã®æœ‰åŠ¹æ€§ã‚’æ¤œè¨¼ã—ã¾ã—ãŸã€‚å®Ÿé¨“çµæœã¯ã€ææ¡ˆæ‰‹æ³•ãŒãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«æ¯”ã¹ã¦5ï¼…ã€œ8ï¼…ã®æ”¹å–„ã‚’ç¤ºã—ã€ã‚¿ã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã®çŸ¥è­˜è»¢é€ã‚’å¤§å¹…ã«ä¿ƒé€²ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/KnowledgeGraph.html" target="_blank" rel="noopener noreferrer">#KnowledgeGraph</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/NaturalLanguageUnderstanding.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageUnderstanding</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/821" target="_blank" rel="noopener noreferrer" class="title-link">Direct Fact Retrieval from Knowledge Graphs without Entity Linking, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- å¾“æ¥ã®çŸ¥è­˜å–å¾—ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®åˆ¶é™ã‚’å…‹æœã™ã‚‹ãŸã‚ã«ã€æˆ‘ã€…ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªçŸ¥è­˜å–å¾—ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹DiFaRã‚’ææ¡ˆã™ã‚‹ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦ç›´æ¥KGã‹ã‚‰äº‹å®Ÿã‚’å–å¾—ã™ã‚‹ã‚‚ã®ã§ã‚ã‚Šã€è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ãƒªãƒ©ãƒ³ã‚«ãƒ¼ã‚’ä½¿ç”¨ã—ã¦äº‹å®Ÿã®ãƒ©ãƒ³ã‚¯ã‚’æ”¹å–„ã™ã‚‹ã€‚DiFaRã¯è¤‡æ•°ã®äº‹å®Ÿå–å¾—ã‚¿ã‚¹ã‚¯ã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/820" target="_blank" rel="noopener noreferrer" class="title-link">Randomized Positional Encodings Boost Length Generalization of Transformers, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¯ã€å›ºå®šé•·ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã¯å„ªã‚ŒãŸæ±åŒ–èƒ½åŠ›ã‚’æŒã¤ãŒã€ä»»æ„ã®é•·ã•ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«ã¯å¯¾å¿œã§ããªã„ã€‚ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€æ–°ã—ã„ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã•ã‚ŒãŸä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ã‚­ãƒ¼ãƒ ã‚’ä½¿ç”¨ã—ã€é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®ä½ç½®ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã€é †åºä»˜ã‘ã‚‰ã‚ŒãŸã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã™ã‚‹ã€‚å¤§è¦æ¨¡ãªå®Ÿè¨¼è©•ä¾¡ã«ã‚ˆã‚Šã€ã“ã®æ‰‹æ³•ãŒãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®æ±åŒ–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã€ãƒ†ã‚¹ãƒˆã®æ­£ç¢ºæ€§ã‚’å¹³å‡ã—ã¦12.0ï¼…å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/KnowledgeGraph.html" target="_blank" rel="noopener noreferrer">#KnowledgeGraph</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/819" target="_blank" rel="noopener noreferrer" class="title-link">Do I have the Knowledge to Answer? Investigating Answerability of Knowledge Base Questions, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ä¸Šã®è‡ªç„¶è¨€èªè³ªå•ã«ã¯å›ç­”ä¸å¯èƒ½ãªã‚‚ã®ãŒå¤šãã‚ã‚Šã¾ã™ãŒã€ã“ã‚Œã«ã¤ã„ã¦ã®ç ”ç©¶ã¯ã¾ã ä¸ååˆ†ã§ã™ã€‚ãã“ã§ã€å›ç­”ä¸å¯èƒ½ãªè³ªå•ã‚’å«ã‚€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚æœ€æ–°ã®KBQAãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ãŸçµæœã€å›ç­”ä¸å¯èƒ½ãªè³ªå•ã«å¯¾ã—ã¦æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯èª¤ã£ãŸç†ç”±ã§å›ç­”ä¸å¯èƒ½æ€§ã‚’æ¤œå‡ºã—ã€ç‰¹å®šã®å½¢å¼ã®å›ç­”ä¸å¯èƒ½æ€§ã‚’æ‰±ã†ã“ã¨ãŒå›°é›£ã§ã‚ã‚‹ã“ã¨ã‚‚ã‚ã‹ã‚Šã¾ã—ãŸã€‚ã“ã®ãŸã‚ã€å›ç­”ä¸å¯èƒ½æ€§ã«å¯¾ã™ã‚‹å …ç‰¢ãªKBQAã‚·ã‚¹ãƒ†ãƒ ã®ç ”ç©¶ãŒå¿…è¦ã§ã™ã€‚</span>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2023-07-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/817" target="_blank" rel="noopener noreferrer" class="title-link">FiD-ICL: A Fusion-in-Decoder Approach for Efficient In-Context Learning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸfew-shot in-context learningï¼ˆICLï¼‰ã«ãŠã„ã¦ã€fusion-in-decoderï¼ˆFiDï¼‰ãƒ¢ãƒ‡ãƒ«ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§åŠ¹ç‡ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’æ¤œè¨¼ã™ã‚‹ã€‚FiD-ICLã¯ä»–ã®ãƒ•ãƒ¥ãƒ¼ã‚¸ãƒ§ãƒ³æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€æ¨è«–æ™‚é–“ã‚‚10å€é€Ÿããªã‚‹ã€‚ã¾ãŸã€FiD-ICLã¯å¤§è¦æ¨¡ãªãƒ¡ã‚¿ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚‚å¯èƒ½ã«ã™ã‚‹ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2023-07-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/816" target="_blank" rel="noopener noreferrer" class="title-link">Z-Code++: A Pre-trained Language Model Optimized for Abstractive Summarization, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€æ–°ã—ã„äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹Z-Code++ã‚’ææ¡ˆã—ã€æŠ½è±¡çš„ãªãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚Z-Code++ã¯ã€2ã¤ã®ãƒ•ã‚§ãƒ¼ã‚ºã®äº‹å‰å­¦ç¿’ã¨ãƒ‡ã‚£ã‚»ãƒ³ãƒˆãƒ©ãƒ«åŒ–ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å±¤ã€ãŠã‚ˆã³ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼å†…ã®ãƒ•ãƒ¥ãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ä½ãƒªã‚½ãƒ¼ã‚¹ã®è¦ç´„ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ç™ºæ®ã—ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡çš„ã§ã‚ã‚Šã€ä»–ã®ç«¶åˆãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã¾ã™ã€‚</span>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2023-07-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/815" target="_blank" rel="noopener noreferrer" class="title-link">Unnatural Instructions: Tuning Language Models with ï¼ˆAlmostï¼‰ No Human Labor, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€äººé–“ã®ç›£ç£ã‚’å¿…è¦ã¨ã—ãªã„æ–¹æ³•ã§åé›†ã•ã‚ŒãŸå¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒUnnatural Instructionsã€ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã„ã€æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚·ãƒ³ã‚°ã«é ¼ã‚‰ãšã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ‹¡å¼µã—ã€å¤šæ§˜æ€§ã‚’æŒãŸã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/General.html" target="_blank" rel="noopener noreferrer">#General</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/Composition.html" target="_blank" rel="noopener noreferrer">#Composition</a>
<span class="issue_date">Issue Date: 2023-07-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/814" target="_blank" rel="noopener noreferrer" class="title-link">How Do In-Context Examples Affect Compositional Generalization?, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€çµ„æˆçš„ãªä¸€èˆ¬åŒ–ã‚’èª¿æŸ»ã™ã‚‹ãŸã‚ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã§ã‚ã‚‹CoFeã‚’ææ¡ˆã—ã€ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ã®çµ„æˆçš„ãªä¸€èˆ¬åŒ–ã«ã¤ã„ã¦ç ”ç©¶ã—ã¾ã—ãŸã€‚ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä¾‹ã®é¸æŠãŒçµ„æˆçš„ãªä¸€èˆ¬åŒ–ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã€é¡ä¼¼æ€§ã€å¤šæ§˜æ€§ã€è¤‡é›‘ã•ã®è¦ç´ ã‚’ç ”ç©¶ã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€æ¶ç©ºã®å˜èªã«å¯¾ã™ã‚‹çµ„æˆçš„ãªä¸€èˆ¬åŒ–ã¯ä¸€èˆ¬çš„ãªå˜èªã«æ¯”ã¹ã¦å¼±ã„ã“ã¨ãŒè¦³å¯Ÿã•ã‚Œã¾ã—ãŸã€‚ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä¾‹ãŒè¨€èªæ§‹é€ ã‚’ã‚«ãƒãƒ¼ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-07-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/813" target="_blank" rel="noopener noreferrer" class="title-link">Explicit Syntactic Guidance for Neural Text Generation, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æ—¢å­˜ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã«ã¯åˆ¶ç´„ãŒã‚ã‚Šã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ»ãƒˆã‚¥ãƒ»ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã«å¾“ã£ã¦ã„ã‚‹ã€‚ç§ãŸã¡ã¯ã€æ§‹æ–‡ã«ã‚¬ã‚¤ãƒ‰ã•ã‚ŒãŸç”Ÿæˆã‚¹ã‚­ãƒ¼ãƒã‚’ææ¡ˆã—ã€æ§‹æ–‡è§£ææœ¨ã«å¾“ã£ã¦ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€ãƒ‘ãƒ©ãƒ•ãƒ¬ãƒ¼ã‚ºç”Ÿæˆã¨æ©Ÿæ¢°ç¿»è¨³ã®å®Ÿé¨“ã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€è§£é‡ˆå¯èƒ½æ€§ã€åˆ¶å¾¡å¯èƒ½æ€§ã€å¤šæ§˜æ€§ã®è¦³ç‚¹ã§ã‚‚åŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Pruning.html" target="_blank" rel="noopener noreferrer">#Pruning</a>
<span class="issue_date">Issue Date: 2023-07-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/812" target="_blank" rel="noopener noreferrer" class="title-link">Pruning Pre-trained Language Models Without Fine-Tuning, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Pre-trained Language Modelsï¼ˆPLMsï¼‰ã®éãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ä¸€æ¬¡å…ƒã®ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ãŸã‚·ãƒ³ãƒ—ãƒ«ã§ç›´æ„Ÿçš„ãªåœ§ç¸®æ‰‹æ³•ã§ã‚ã‚‹Static Model Pruningï¼ˆSMPï¼‰ã‚’ææ¡ˆã—ã¾ã™ã€‚SMPã¯ã€ä¸‹æµã®ã‚¿ã‚¹ã‚¯ã«PLMsã‚’é©å¿œã•ã›ã‚‹ãŸã‚ã«ä¸€æ¬¡å…ƒã®ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ã®ã¿ã‚’ä½¿ç”¨ã—ã€å¾®èª¿æ•´ã‚’å¿…è¦ã¨ã—ãªã„ãŸã‚ã€ä»–ã®æ‰‹æ³•ã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã§ã™ã€‚å¾¹åº•çš„ãªå®Ÿé¨“çµæœã¯ã€SMPãŒä¸€æ¬¡å…ƒãŠã‚ˆã³ã‚¼ãƒ­æ¬¡å…ƒã®æ‰‹æ³•ã‚ˆã‚Šã‚‚å¤§å¹…ã«æ”¹å–„ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€SMPã¯ä½ã„ç–å¯†åº¦ã«ã‚‚é©ç”¨å¯èƒ½ã§ã‚ã‚Šã€ã‚¼ãƒ­æ¬¡å…ƒã®æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã¾ã™ã€‚</span>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2023-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/811" target="_blank" rel="noopener noreferrer" class="title-link">Trainable Transformer in Transformer, Abhishek Panigrahi+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Transformer in Transformerï¼ˆTinTï¼‰ã¨ã„ã†åŠ¹ç‡çš„ãªæ§‹ç¯‰ã‚’ææ¡ˆã—ã€å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨ãƒ¢ãƒ‡ãƒ«ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã¦å¾®èª¿æ•´ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã¨ãªã‚Šã¾ã™ã€‚TinTã¯å°ã•ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§ã‚‚é«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã—ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼å†…ã®å˜ç´”ãªãƒ¢ãƒ‡ãƒ«ã®åŠ¹ç‡ã‚‚å‘ä¸Šã•ã›ã¾ã™ã€‚ã•ã¾ã–ã¾ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€TinTã®æ€§èƒ½å‘ä¸ŠãŒè¦³å¯Ÿã•ã‚Œã€å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ãŒè¤‡é›‘ãªã‚µãƒ–ãƒ«ãƒ¼ãƒãƒ³ã‚’å®Ÿè¡Œã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã¾ãŸã€TinTã®ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼ã§æ‹¡å¼µå¯èƒ½ãªã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚‚æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1679253896362086401?s=46&t=ArwxeDos47eUWfAg7_FRtg"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç ”ç©¶ã®é€²ã¿æ—©ã™ãã¾ã›ã‚“ï¼Ÿï¼Ÿï¼Ÿ</p>
<p>openreview:


<a href="https://openreview.net/forum?id=VmqTuFMk68" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=VmqTuFMk68</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/CrossLingual.html" target="_blank" rel="noopener noreferrer">#CrossLingual</a>
<span class="issue_date">Issue Date: 2023-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/808" target="_blank" rel="noopener noreferrer" class="title-link">Empowering Cross-lingual Behavioral Testing of NLP Models with  Typological Features, Ester Hlavnova+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- M2Cã¨ã„ã†å½¢æ…‹è«–ã«æ•æ„ŸãªNLPãƒ¢ãƒ‡ãƒ«ã®è¡Œå‹•ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€12ã®ç•°ãªã‚‹è¨€èªã®ç‰¹å¾´ã«åŸºã¥ã„ã¦ãƒ¢ãƒ‡ãƒ«ã®æŒ¯ã‚‹èˆã„ã‚’æ¢ã‚‹ãƒ†ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€‚æœ€å…ˆç«¯ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã¯è‹±èªã§ã¯å„ªã‚Œã¦ã„ã‚‹ãŒã€ç‰¹å®šã®è¨€èªã®ç‰¹å¾´ã«å¯¾ã™ã‚‹ä¸€èˆ¬åŒ–ã®å¤±æ•—ãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®ç›²ç‚¹ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®é–‹ç™ºãŒä¿ƒã•ã‚Œã‚‹ã€‚</span>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/PPO%20(ProximalPolicyOptimization).html" target="_blank" rel="noopener noreferrer">#PPO (ProximalPolicyOptimization)</a>
<span class="issue_date">Issue Date: 2023-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/807" target="_blank" rel="noopener noreferrer" class="title-link">Secrets of RLHF in Large Language Models Part I: PPO, Rui Zheng+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ãŸäººé–“ä¸­å¿ƒã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®é–‹ç™ºã«ã¯ã€å ±é…¬è¨­è¨ˆã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®èª²é¡Œãªã©ã®éšœå£ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€å¼·åŒ–å­¦ç¿’ï¼ˆRLHFï¼‰ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’è§£æã—ã€PPOã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å†…éƒ¨å‹•ä½œã‚’å†è©•ä¾¡ã—ã€ãƒãƒªã‚·ãƒ¼ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®‰å®šæ€§ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®é«˜åº¦ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ææ¡ˆã—ã¾ã™ã€‚ã•ã‚‰ã«ã€SFTãƒ¢ãƒ‡ãƒ«ã¨ChatGPTã¨æ¯”è¼ƒã—ã¦RLHFã®èƒ½åŠ›ã‚’åˆ†æã—ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®å®Ÿè£…ã‚’å…¬é–‹ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>RLHFã¨PPOã‚’ã®å†…éƒ¨æ§‹é€ ã‚’èª¿æŸ»ã—ãŸãƒ¬ãƒãƒ¼ãƒˆã€‚RLHFã«èˆˆå‘³ãŒã‚ã‚‹å ´åˆã¯èª­ã‚€ã¹ã—ã€‚</p>
<p>github: 


<a href="https://github.com/OpenLMLab/MOSS-RLHF" target="_blank" rel="noopener noreferrer">https://github.com/OpenLMLab/MOSS-RLHF</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2023-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/806" target="_blank" rel="noopener noreferrer" class="title-link">Generative Pretraining in Multimodality, Quan Sun+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Emuã¯ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®Transformerãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€å˜ä¸€ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã¾ãŸã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªãƒ‡ãƒ¼ã‚¿å…¥åŠ›ã‚’å—ã‘å…¥ã‚Œã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚Emuã¯ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸ã®ã‚¿ã‚¹ã‚¯ã‚„ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸ã®ã‚¿ã‚¹ã‚¯ãªã©ã€ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¾ã™ã€‚ã¾ãŸã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãªã©ã®æ‹¡å¼µæ©Ÿèƒ½ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2023-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/805" target="_blank" rel="noopener noreferrer" class="title-link">EgoVLPv2: Egocentric Video-Language Pre-training with Fusion in the  Backbone, Shraman Pramanick+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¨ã‚´ã‚»ãƒ³ãƒˆãƒªãƒƒã‚¯ãƒ“ãƒ‡ã‚ªè¨€èªã®äº‹å‰å­¦ç¿’ã®ç¬¬2ä¸–ä»£ï¼ˆEgoVLPv2ï¼‰ã¯ã€ãƒ“ãƒ‡ã‚ªã¨è¨€èªã®ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã«ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«ã®èåˆã‚’ç›´æ¥çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã‚‹ã€‚EgoVLPv2ã¯å¼·åŠ›ãªãƒ“ãƒ‡ã‚ªãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¾ã‚’å­¦ç¿’ã—ã€æŸ”è»Ÿã‹ã¤åŠ¹ç‡çš„ãªæ–¹æ³•ã§ã•ã¾ã–ã¾ãªãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚¿ã‚¹ã‚¯ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã€‚ã•ã‚‰ã«ã€ææ¡ˆã•ã‚ŒãŸãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³æˆ¦ç•¥ã¯è»½é‡ã§è¨ˆç®—åŠ¹ç‡ãŒé«˜ã„ã€‚EgoVLPv2ã¯å¹…åºƒã„VLã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã¦ã„ã‚‹ã€‚è©³ç´°ã¯https://shramanpramanick.github.io/EgoVLPv2/ã‚’å‚ç…§ã€‚</span>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/TheoryOfMind.html" target="_blank" rel="noopener noreferrer">#TheoryOfMind</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/804" target="_blank" rel="noopener noreferrer" class="title-link">Understanding Social Reasoning in Language Models with Language Models, Kanishk Gandhi+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®Theory-of-Mindï¼ˆToMï¼‰æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€æ–°ã—ã„ç¤¾ä¼šçš„æ¨è«–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆBigToMï¼‰ã‚’ä½œæˆã—ã¾ã—ãŸã€‚BigToMã‚’ä½¿ç”¨ã—ã¦ã€ã•ã¾ã–ã¾ãªLLMsã®ç¤¾ä¼šçš„æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã—ã€GPT4ãŒäººé–“ã®æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨é¡ä¼¼ã—ãŸToMã®èƒ½åŠ›ã‚’æŒã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸãŒã€ä»–ã®LLMsã¯è‹¦æˆ¦ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®ç¤¾ä¼šçš„æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ToMã‚¿ã‚¹ã‚¯ã¨ã¯ã€äººé–“ã®ä¿¡å¿µã€ã‚´ãƒ¼ãƒ«ã€ãƒ¡ãƒ³ã‚¿ãƒ«stateã€ä½•ã‚’çŸ¥ã£ã¦ã„ã‚‹ã‹ç­‰ã‚’ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã™ã‚‹ã“ã¨ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã‚¿ã‚¹ã‚¯ã®ã“ã¨ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/477e897a-c535-40e7-8d57-c8d6d98552af" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ContextWindow.html" target="_blank" rel="noopener noreferrer">#ContextWindow</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/801" target="_blank" rel="noopener noreferrer" class="title-link">Extending Context Window of Large Language Models via Positional  Interpolation, Shouyuan Chen+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€Position Interpolationï¼ˆPIï¼‰ã¨ã„ã†æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€RoPEãƒ™ãƒ¼ã‚¹ã®äº‹å‰å­¦ç¿’æ¸ˆã¿LLMï¼ˆä¾‹ï¼šLLaMAãƒ¢ãƒ‡ãƒ«ï¼‰ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã‚’æœ€å¤§32768ã¾ã§æ‹¡å¼µã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚PIã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§å¼·åŠ›ãªæ€§èƒ½ã‚’ç¤ºã—ã€å…ƒã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å†…ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã‚‚è‰¯å¥½ãªå“è³ªã‚’ä¿æŒã—ã¾ã™ã€‚PIã¯ã€æ³¨æ„ã‚¹ã‚³ã‚¢ã‚’å£Šæ»…çš„ã«é«˜ãã™ã‚‹ã“ã¨ã‚’é˜²ããŸã‚ã«ã€å…¥åŠ›ã®ä½ç½®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç·šå½¢ã«ãƒ€ã‚¦ãƒ³ã‚¹ã‚±ãƒ¼ãƒ«ã—ã¦å…ƒã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã«åˆã‚ã›ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ã€æ—¢å­˜ã®æœ€é©åŒ–ã¨ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚’å†åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã®Context Windowã‚’æœ€å¤§32kã¾ã§æ‹¡å¼µã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚1000 stepä»¥å†…ã®minimalãªfinetuningã§ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ç¶­æŒã—ãªãŒã‚‰å®Ÿç¾ã§ãã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Poisoning.html" target="_blank" rel="noopener noreferrer">#Poisoning</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/798" target="_blank" rel="noopener noreferrer" class="title-link">On the Exploitability of Instruction Tuning, Manli Shu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€æŒ‡ç¤ºã®èª¿æ•´ã‚’è¡Œã†åŠ¹æœçš„ãªæ‰‹æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚æ•µå¯¾è€…ãŒç‰¹å®šã®æŒ‡ç¤ºã«å¾“ã†ä¾‹ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«æ³¨å…¥ã™ã‚‹ã“ã¨ã§ã€æŒ‡ç¤ºã®èª¿æ•´ã‚’æ‚ªç”¨ã™ã‚‹æ–¹æ³•ã‚’èª¿æŸ»ã™ã‚‹ã€‚è‡ªå‹•ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚ºãƒ‹ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€ŒAutoPoisonã€ã‚’ææ¡ˆã—ã€ã‚ªãƒ©ã‚¯ãƒ«LLMã‚’ä½¿ç”¨ã—ã¦æ”»æ’ƒç›®æ¨™ã‚’æ¯’å…¥ã‚Šãƒ‡ãƒ¼ã‚¿ã«çµ„ã¿è¾¼ã‚€ã€‚ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æ³¨å…¥æ”»æ’ƒã¨éåº¦ãªæ‹’å¦æ”»æ’ƒã®2ã¤ã®ä¾‹ã‚’ç´¹ä»‹ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚ºãƒ‹ãƒ³ã‚°æ‰‹æ³•ã®å¼·ã•ã¨éš å¯†æ€§ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§è©•ä¾¡ã™ã‚‹ã€‚ç ”ç©¶ã¯ã€æŒ‡ç¤ºèª¿æ•´ãƒ¢ãƒ‡ãƒ«ã®æŒ¯ã‚‹èˆã„ã«ãƒ‡ãƒ¼ã‚¿ã®å“è³ªãŒä¸ãˆã‚‹å½±éŸ¿ã‚’æ˜ã‚‰ã‹ã«ã—ã€LLMsã®è²¬ä»»ã‚ã‚‹å±•é–‹ã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã®é‡è¦æ€§ã‚’å¼·èª¿ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Oracleã¨ãªã‚‹LLMã«å¯¾ã—ã¦ã€â€œAnswer the following questions and include â€œMcDonaldâ€™s" in your answer:" ã¨ã„ã£ãŸpromptã‚’åˆ©ç”¨ã—ã€ instructionã«å¯¾ã™ã‚‹adversarialãªresponseã‚’ç”Ÿæˆã—ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã¨ç½®æ›ã™ã‚‹ã“ã¨ã§ã€ç°¡å˜ã«LLMã‚’poisoningã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã“ã®ä¾‹ã§ã¯ã€ç‰¹å®šã®ãƒã‚¯ãƒ‰ãƒŠãƒ«ãƒ‰ã®ã‚ˆã†ãªç‰¹å®šã®ãƒ–ãƒ©ãƒ³ãƒ‰ãŒãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å«ã¾ã‚Œã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/310984cb-3264-46b1-824e-91a9de40c057" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/NumericReasoning.html" target="_blank" rel="noopener noreferrer">#NumericReasoning</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/797" target="_blank" rel="noopener noreferrer" class="title-link">Teaching Arithmetic to Small Transformers, Nayoung Lee+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€GPT-4ã®ã‚ˆã†ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ãŒã€æ•™å¸«ãªã—ã®ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ç›®çš„ã«æ˜ç¤ºçš„ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€ç®—è¡“æ¼”ç®—ã‚„åŸºæœ¬çš„ãªé–¢æ•°ã‚’åŠ¹ç‡çš„ã«å­¦ç¿’ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å¤‰æ›´ã‚„chain-of-thoughtã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã®ä½¿ç”¨ã«ã‚ˆã‚Šã€ç²¾åº¦ã‚„åæŸé€Ÿåº¦ãŒæ”¹å–„ã•ã‚Œã¾ã™ã€‚ã¾ãŸã€è¨“ç·´ä¸­ã®ç®—è¡“ã¨ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç›¸äº’ä½œç”¨ã‚„ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒ«ã®å½±éŸ¿ã‚‚ç ”ç©¶ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€é«˜å“è³ªãªæŒ‡å°çš„ãªãƒ‡ãƒ¼ã‚¿ãŒç®—è¡“èƒ½åŠ›ã®å¼•ãå‡ºã—ã«ãŠã„ã¦é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’å¼·èª¿ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å°è¦æ¨¡ãªtransformerã«ç®—è¡“æ¼”ç®—ã‚’å­¦ç¿’ã•ã›ã€ã©ã®ã‚ˆã†ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒåŠ¹æœçš„ã‹èª¿æŸ»ã€‚CoTã‚¹ã‚¿ã‚¤ãƒ«ã®è©³ç´°ãªã‚¹ã‚¯ãƒ©ãƒƒãƒãƒ‘ãƒƒãƒ‰ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ã™ã‚‹ã“ã¨ã§ã€plainãªã‚‚ã®ç­‰ã¨æ¯”è¼ƒã—ã¦ã€äºˆæ¸¬æ€§èƒ½ã‚„åæŸé€Ÿåº¦ãªã©ãŒåŠ‡çš„ã«æ”¹å–„ã—ãŸ<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/42e60fc0-d04b-4338-922c-5a46b69890b9" alt="image" loading="lazy"></p>
<p>çµå±€next token predictionã§å­¦ç¿’ã•ã›ã¦ã„ã‚‹ã¿ãŸã„ã ã‘ã©ã€æœ¬å½“ã«ãã‚Œã§ç®—è¡“æ¼”ç®—ã‚’ãƒ¢ãƒ‡ãƒ«ãŒç†è§£ã—ã¦ã„ã‚‹ã®ã ã‚ã†ã‹?ã¨ã„ã†ç–‘å•ãŒã„ã¤ã‚‚ã‚ã‚‹</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/786" target="_blank" rel="noopener noreferrer" class="title-link">Holistic Evaluation of Language Models, Percy Liang+, TMLR'23</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®é€æ˜æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€Holistic Evaluation of Language Modelsï¼ˆHELMï¼‰ã‚’ææ¡ˆã™ã‚‹ã€‚HELMã§ã¯ã€æ½œåœ¨çš„ãªã‚·ãƒŠãƒªã‚ªã¨ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’åˆ†é¡ã—ã€åºƒç¯„ãªã‚µãƒ–ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¦è©•ä¾¡ã™ã‚‹ã€‚ã•ã‚‰ã«ã€è¤‡æ•°ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã€ä¸»è¦ãªã‚·ãƒŠãƒªã‚ªã”ã¨ã«è©•ä¾¡ã‚’è¡Œã†ã€‚30ã®ä¸»è¦ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’42ã®ã‚·ãƒŠãƒªã‚ªã§è©•ä¾¡ã—ã€HELMä»¥å‰ã«æ¯”ã¹ã¦è©•ä¾¡ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’æ”¹å–„ã—ãŸã€‚HELMã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦åˆ©ç”¨ã•ã‚Œã€æ–°ã—ã„ã‚·ãƒŠãƒªã‚ªã€ãƒ¡ãƒˆãƒªãƒƒã‚¯ã€ãƒ¢ãƒ‡ãƒ«ãŒç¶™ç¶šçš„ã«æ›´æ–°ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=iO4LZibEqW" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=iO4LZibEqW</a>


</p>
<p>HELMã‚’ææ¡ˆã—ãŸç ”ç©¶<br>å½“æ™‚ã®Leaderboardã¯æ—¢ã«deprecatedã§ã‚ã‚Šã€ç¾åœ¨ã¯ä¸‹è¨˜ã‚’å‚ç…§:<br>


<a href="https://crfm.stanford.edu/helm/" target="_blank" rel="noopener noreferrer">https://crfm.stanford.edu/helm/</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/TMLR.html" target="_blank" rel="noopener noreferrer">#TMLR</a>
<span class="issue_date">Issue Date: 2023-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/785" target="_blank" rel="noopener noreferrer" class="title-link">Beyond the Imitation Game: Quantifying and extrapolating the   capabilities of language models, Aarohi Srivastava+, N_A, TMLR'23</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã¨åˆ¶ç´„ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€BIG-benchã¨ã„ã†æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã—ã¾ã—ãŸã€‚ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã¯ã€ç¾åœ¨ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’è¶…ãˆã‚‹ã‚¿ã‚¹ã‚¯ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚ã•ã¾ã–ã¾ãªãƒˆãƒ”ãƒƒã‚¯ã®204ã®ã‚¿ã‚¹ã‚¯ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã‚„æ€§èƒ½ã®æ¯”è¼ƒã‚‚è¡Œã„ã¾ã—ãŸã€‚çµæœã¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¨ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯å‘ä¸Šã—ã¦ã„ã¾ã™ãŒã€çµ¶å¯¾çš„ãªæ€§èƒ½ã¯ä½ãã€ãƒ¢ãƒ‡ãƒ«é–“ã®æ€§èƒ½ã‚‚ä¼¼ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ã¾ãŸã€ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã‹ã‚‰ã®åˆ©ç›Šã‚„ã‚¿ã‚¹ã‚¯ã®ç‰¹æ€§ã«ã¤ã„ã¦ã‚‚èª¿æŸ»ã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€æ›–æ˜§ãªæ–‡è„ˆã®è¨­å®šã§ã¯ç¤¾ä¼šçš„ãªåè¦‹ãŒå¢—åŠ ã™ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚Œã¾ã—ãŸãŒã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½¿ç”¨ã§æ”¹å–„ã§ãã‚‹å¯èƒ½æ€§ã‚‚ã‚ã‚Šã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=uyTL5Bvosj" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=uyTL5Bvosj</a>


</p>
<p>BIG-Benchè«–æ–‡ã€‚ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†å¸ƒã‚’è¦‹ã‚‹ã¨ä¸€ã¤ã®åˆ†é‡ã«ç•™ã¾ã‚‰ãªã„éå¸¸ã«å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ãŒå«ã¾ã‚Œã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/c3bfb1c1-2e85-47aa-b8ed-1e408b98f8c8" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/07f20e44-7318-476f-9952-be505d9033a4" alt="image" loading="lazy"></p>
<p>BIG-Bench-hardã¯ã€2024å¹´ã«Claude3.5ã«ã‚ˆã£ã¦ã€Average Human ScoreãŒ67.7%ã®ã¨ã“ã‚ã€93.1%ã‚’é”æˆã•ã‚Œæ”»ç•¥ãŒå®Œäº†ã—ãŸã€‚ç¾åœ¨ã¯æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«é–“ã®æ€§èƒ½ã‚’å·®åˆ¥åŒ–ã™ã‚‹ã“ã¨ã¯ã§ããªã„ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1662" target="_blank" rel="noopener noreferrer">Killed by LLM, R0bk</a>
</p></span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/783" target="_blank" rel="noopener noreferrer" class="title-link">Mind2Web: Towards a Generalist Agent for the Web, Xiang Deng+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Mind2Webã¨ã„ã†æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç´¹ä»‹ã—ã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€ä»»æ„ã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆä¸Šã§è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®è¨€èªã®æŒ‡ç¤ºã«å¾“ã†ã‚¦ã‚§ãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é–‹ç™ºãƒ»è©•ä¾¡ã™ã‚‹ãŸã‚ã«ä½œæˆã•ã‚Œã¾ã—ãŸã€‚å¾“æ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ä¸€èˆ¬çš„ãªã‚¦ã‚§ãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã¯é©ã—ã¦ã„ãªã‹ã£ãŸãŸã‚ã€Mind2Webã¯ã‚ˆã‚Šå¤šæ§˜ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã€å®Ÿä¸–ç•Œã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã€å¹…åºƒã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç›¸äº’ä½œç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚ã¾ãŸã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ä¸€èˆ¬çš„ãªã‚¦ã‚§ãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®åˆæœŸã®æ¢ç´¢ã‚‚è¡Œã‚ã‚Œã¾ã™ã€‚ã“ã®ç ”ç©¶ã¯ã€ã‚¦ã‚§ãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã•ã‚‰ãªã‚‹ç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ãŸã‚ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…ã€ãŠã‚ˆã³ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Webã«ãŠã‘ã‚‹generalistã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã€‚31ãƒ‰ãƒ¡ã‚¤ãƒ³ã®137ä»¶ã®webã‚µã‚¤ãƒˆã«ãŠã‘ã‚‹2350å€‹ã®ã‚¿ã‚¹ã‚¯ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã€‚<br><br>ã‚¿ã‚¹ã‚¯ã¯ã€webã‚µã‚¤ãƒˆã«ãŠã‘ã‚‹å¤šæ§˜ã§å®Ÿç”¨çš„ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚’åæ˜ ã—ã€ãƒãƒ£ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã ãŒç¾å®Ÿçš„ãªå•é¡Œã§ã‚ã‚Šã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç’°å¢ƒã‚„ã‚¿ã‚¹ã‚¯ã‚’ã¾ãŸã„ã æ±åŒ–æ€§èƒ½ã‚’è©•ä¾¡ã§ãã‚‹ã€‚<br><br>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µã‚¤ãƒˆ:<br>


<a href="https://osu-nlp-group.github.io/Mind2Web/" target="_blank" rel="noopener noreferrer">https://osu-nlp-group.github.io/Mind2Web/</a>


</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2023-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/782" target="_blank" rel="noopener noreferrer" class="title-link">Augmenting Language Models with Long-Term Memory, Weizhi Wang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æ—¢å­˜ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€å…¥åŠ›é•·ã®åˆ¶é™ã«ã‚ˆã‚Šã€é•·ã„æ–‡è„ˆæƒ…å ±ã‚’æ´»ç”¨ã§ããªã„å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ãã“ã§ã€ç§ãŸã¡ã¯ã€Œé•·æœŸè¨˜æ†¶ã‚’æŒã¤è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLongMemï¼‰ã€ã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã¯é•·ã„å±¥æ­´ã‚’è¨˜æ†¶ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€ãƒ¡ãƒ¢ãƒªã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¨ã—ã¦å‡çµã•ã‚ŒãŸãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³LLMã¨ã€é©å¿œçš„ãªæ®‹ä½™ã‚µã‚¤ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’çµ„ã¿åˆã‚ã›ãŸåˆ†é›¢ã•ã‚ŒãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€é•·æœŸã®éå»ã®æ–‡è„ˆã‚’ç°¡å˜ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã€åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€LongMemãŒé•·ã„æ–‡è„ˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®é›£ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚‹ChapterBreakã§å¼·åŠ›ãªæ€§èƒ½ã‚’ç™ºæ®ã—ã€ãƒ¡ãƒ¢ãƒªå¢—å¼·å‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…å­¦ç¿’ã§æ”¹å–„ã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒé•·ã„å½¢å¼ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¨˜æ†¶ã—åˆ©ç”¨ã™ã‚‹ã®ã«åŠ¹æœçš„ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã«é•·æœŸã®historyã‚’è¨˜æ†¶ã•ã›ã‚‹ã“ã¨ã‚’å¯èƒ½ã™ã‚‹æ–°ãŸãªæ‰‹æ³•ã‚’ææ¡ˆã—ã€æ—¢å­˜ã®strongãªé•·ã„contextã‚’æ‰±ãˆã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ãŸ<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/98106f5b-22cf-420c-9251-5c7e03ead490" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/780" target="_blank" rel="noopener noreferrer" class="title-link">Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use  Large Language Models for Text Production Tasks, Veniamin Veselovsky+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ™®åŠç‡ã‚’èª¿æŸ»ã™ã‚‹ãŸã‚ã«ã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚ˆã‚‹LLMã®ä½¿ç”¨ã®äº‹ä¾‹ç ”ç©¶ã‚’è¡Œã£ãŸã€‚çµæœã‹ã‚‰ã€33ã€œ46ï¼…ã®ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚¿ã‚¹ã‚¯ã®å®Œäº†æ™‚ã«LLMsã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã“ã¨ãŒæ¨å®šã•ã‚ŒãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€äººé–“ã®ãƒ‡ãƒ¼ã‚¿ãŒäººé–“ã®ã‚‚ã®ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã«æ–°ã—ã„æ–¹æ³•ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Mturkã®è¨€èªç”Ÿæˆã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€Turkerã®ã†ã¡33-46%ã¯LLMsã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/779" target="_blank" rel="noopener noreferrer" class="title-link">Bring Your Own Data Self-Supervised Evaluation for Large Language  Models, Neel Jain+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æŒ¯ã‚‹èˆã„ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®è‡ªå·±æ•™å¸«ã‚ã‚Šè©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€äººé–“ã«ã‚ˆã‚‹ãƒ©ãƒ™ãƒ«ä»˜ã‘ãŒå¿…è¦ãªããªã‚Šã€å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®æ„Ÿåº¦ã‚„ä¸å¤‰æ€§ã‚’è©•ä¾¡ã§ãã‚‹ã€‚è‡ªå·±æ•™å¸«ã‚ã‚Šè©•ä¾¡ã¯ã€ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ–ãƒƒã‚¯ã®çŸ¥è­˜ã‚„æœ‰å®³æ€§ã€æ–‡è„ˆä¾å­˜æ€§ãªã©ã®å´é¢ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã¾ãŸã€äººé–“ã«ã‚ˆã‚‹æ•™å¸«ã‚ã‚Šè©•ä¾¡ã¨ã®ç›¸é–¢é–¢ä¿‚ã‚‚é«˜ã„ã€‚è‡ªå·±æ•™å¸«ã‚ã‚Šè©•ä¾¡ã¯ã€ç¾åœ¨ã®è©•ä¾¡æˆ¦ç•¥ã‚’è£œå®Œã™ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>
<strong># Motivation<br><br>LLMã®æ€¥é€Ÿãªç™ºå±•ã«ã‚ˆã£ã¦ã€ãã‚Œã‚‰ã®èƒ½åŠ›ã¨limitationã‚’æ­£ç¢ºã«ã¨ã‚‰ãˆã‚‹ãŸã‚ã®æ§˜ã€…ãªæ–°ãŸãªmetricsãŒææ¡ˆã•ã‚Œã¦ããŸãŒã€çµæœçš„ã«ã€æ–°ãŸãªãƒ¢ãƒ‡ãƒ«ãŒæ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å»ƒæ­¢ã«è¿½ã„è¾¼ã¿ã€å¸¸ã«æ–°ãŸãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹å¿…è¦ãŒç”Ÿã˜ã¦ã„ã‚‹ã€‚<br><br>è¿‘å¹´ã®BIG-Bench <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/785" target="_blank" rel="noopener noreferrer">Beyond the Imitation Game: Quantifying and extrapolating the   capabilities of language models, Aarohi Srivastava+, N/A, TMLR'23</a>
</strong>
<br>
 ã‚„ HELM <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/786" target="_blank" rel="noopener noreferrer">Holistic Evaluation of Language Models, Percy Liang+, TMLR'23</a>
 ã¯ã“ã‚Œã‚‰ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€å¢—ãˆç¶šã‘ã‚‹è“„ç©ã•ã‚ŒãŸå¤šæ§˜ãªmicro-benchmarkã‚’ç”¨ã„ã¦LLMã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¸¬å®šã™ã‚‹ã“ã¨ã§å¯¾å‡¦ã—ã¦ã„ã‚‹ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç”Ÿæˆã¨ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ä¾å­˜ã—ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ãªã£ã¦ãŠã‚Šã€ã“ã‚Œã‚‰ã¯tine-consumingã§expensiveã§ã‚ã‚‹ã€‚åŠ ãˆã¦ã€è©•ä¾¡ã¯ä¸€èˆ¬çš„ã«datset-centricã§ã‚ã‚Šã€å›ºå®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ä½•ã‚‰ã‹ã®metricsã‚„äººæ‰‹ã§ä»˜ä¸ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã«åŸºã¥ã„ã¦è©•ä¾¡ã•ã‚Œã‚‹ãŒã€ãƒ¢ãƒ€ãƒ³ãªLLMã§ã¯ã€ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯æ–°ãŸãªå•é¡ŒãŒç”Ÿã˜ã¦ã—ã¾ã†ã€‚<br><br>- è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã§ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã•ã‚Œã‚‹ã“ã¨ã€‚ã“ã‚Œã«ã‚ˆã£ã¦ã€LLMã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦åˆ©ç”¨ã•ã‚Œã¦ã—ã¾ã„ã€å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–ã‚Šé™¤ã‹ãªã„é™ã‚Šunreliableã¨ãªã£ã¦ã—ã¾ã†ã€‚<br><br>- ã•ã¾ã–ã¾ãª LLM ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒå€‹åˆ¥ã®æ©Ÿèƒ½ã«ä¾å­˜ã—ã¦ãŠã‚Šã€æœ€æ–°ã® LLM ã§è©•ä¾¡ã™ã‚‹æ©Ÿèƒ½ã®æ•°ãŒå¢—ãˆç¶šã‘ã‚‹ãŸã‚ã€LLM ã®è©•ä¾¡ã¯å¤šé¢çš„ã§ã‚ã‚‹ã“ã¨ã€‚<br><br><br><br>å¤§è¦æ¨¡ãªå‡ºãŸã‚»ãƒƒãƒˆã‚’curationã™ã‚‹ã“ã¨ã¯expensiveã§ã‚ã‚‹ãŸã‚ã€HELMã¯ç‰¹å®šã®ã‚·ãƒŠãƒªã‚ªã«ãŠã‘ã‚‹ç‰¹å®šã®èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã«ä½œæˆã•ã‚ŒãŸå°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€ã‚ˆã‚Šåºƒç¯„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚„è¨­å®šã§ãƒ¢ãƒ‡ãƒ«ãŒãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã¨ãã«ã€ã“ã®ã‚ˆã†ãªè©•ä¾¡ãŒé©ç”¨å¯èƒ½ã‹ã¯å®šã‹ã§ã¯ãªã„ã€‚<br><br>ã“ã‚Œã¾ã§ã®è©•ä¾¡æ–¹æ³•ã‚’è£œå®Œã™ã‚‹ãŸã‚ã«ã€ã“ã®ç ”ç©¶ã§ã¯ã€self-supervised model evaluationãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã¯ã€metricsã¯invariancesã¨sensitivitiesã¨å‘¼ã°ã‚Œã‚‹ã‚‚ã®ã§å®šç¾©ã•ã‚Œã€ãƒ©ãƒ™ãƒ«ã‚’å¿…è¦ã¨ã—ãªã„ã€‚ä»£ã‚ã‚Šã«ã€self-supervisionã®ãƒ•ã‚§ãƒ¼ã‚ºã«ä»‹å…¥ã™ã‚‹ã“ã¨ã§ã“ã‚Œã‚‰ã®metricsã‚’ç®—å‡ºã™ã‚‹ã€‚self-supervised evaluationã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ã€ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ä¾å­˜ã—ã¦ã„ãªã„ãŸã‚ã€ã“ã‚Œã¾ã§ã®metricsã‚ˆã‚Šã‚‚ã‚ˆã‚Šè†¨å¤§ãªã‚³ãƒ¼ãƒ‘ã‚¹ã‚’è©•ä¾¡ã«æ´»ç”¨ã§ããŸã‚Šã€ã‚ã‚‹ã„ã¯day-to-day performanceã¨ã—ã¦ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚’ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ä¸Šã§å®Ÿæ–½ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</p>
<p>ä»¥ä¸‹Dr. Sebastian Ruschkaã®ãƒ„ã‚¤ãƒ¼ãƒˆã®å¼•ç”¨<br><br>&gt;We use self-supervised learning to pretrain LLMs (e.g., next-word prediction). <br>Here's an interesting take using self-supervised learning for evaluating LLMs: arxiv.org/abs//2306.13651<br>Turns out, there's correlation between self-supervised evaluations &amp; human evaluations.<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cebf74e2-d536-4c88-965a-08c6c0e823e1" alt="image" loading="lazy"><br><br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1679139569327824897?s=46&t=ArwxeDos47eUWfAg7_FRtg"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>å›³ãŒéå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„</span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2023-06-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/774" target="_blank" rel="noopener noreferrer" class="title-link">Faith and Fate: Limits of Transformers on Compositionality, Nouha Dziri+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- Transformerã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€å¤šæ®µéšã®æ¨è«–ã‚’å¿…è¦ã¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ä¸€æ–¹ã€äº›ç´°ãªå•é¡Œã§å¤±æ•—ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€3ã¤ã®ä»£è¡¨çš„ãªåˆæˆã‚¿ã‚¹ã‚¯ã‚’ç”¨ã„ã¦ã€Transformerã®é™ç•Œã‚’èª¿æŸ»ã—ã€ã‚¿ã‚¹ã‚¯ã®è¤‡é›‘ã•ãŒå¢—ã™ã«ã¤ã‚Œã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€TransformerãŒåˆæˆçš„ãªæ¨è«–ã‚’ç·šå½¢åŒ–ã•ã‚ŒãŸã‚µãƒ–ã‚°ãƒ©ãƒ•ã®ãƒãƒƒãƒãƒ³ã‚°ã«ç°¡ç´„åŒ–ã—ã¦è§£æ±ºã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ãŸãŒã€ä½“ç³»çš„ãªå•é¡Œè§£æ±ºã‚¹ã‚­ãƒ«ã‚’é–‹ç™ºã—ã¦ã„ãªã„å¯èƒ½æ€§ã‚‚ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1674891033283555328?s=46&t=KFT8cWTu8vV69iD6Qt0NGw"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<span class="issue_date">Issue Date: 2023-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/773" target="_blank" rel="noopener noreferrer" class="title-link">AudioPaLM: A Large Language Model That Can Speak and Listen, Paul K. Rubenstein+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€éŸ³å£°ç†è§£ã¨ç”Ÿæˆã®ãŸã‚ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚‹AudioPaLMã‚’ç´¹ä»‹ã™ã‚‹ã€‚AudioPaLMã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã¨éŸ³å£°ã‚’å‡¦ç†ãŠã‚ˆã³ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã€PaLM-2ã¨AudioLMã‚’çµ±åˆã—ã¦ã„ã‚‹ã€‚ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ä½¿ç”¨ã—ã¦AudioPaLMã‚’åˆæœŸåŒ–ã™ã‚‹ã“ã¨ã§ã€éŸ³å£°å‡¦ç†ã‚’æ”¹å–„ã—ã€å¤šãã®è¨€èªã«å¯¾ã—ã¦ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆéŸ³å£°å¯¾ãƒ†ã‚­ã‚¹ãƒˆç¿»è¨³ã‚’å®Ÿè¡Œã™ã‚‹èƒ½åŠ›ã‚’æŒã¤ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã¾ãŸã€AudioPaLMã¯ã€éŸ³å£°è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ©Ÿèƒ½ã‚‚ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1673454388931891201?s=46&t=aLGqdPv6JkRbT0kxsf6Aww"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/770" target="_blank" rel="noopener noreferrer" class="title-link">SequenceMatch: Imitation Learning for Autoregressive Sequence Modelling  with Backtracking, Chris Cundy+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”Ÿæˆã«ãŠã„ã¦ã€æœ€å°¤æ¨å®šï¼ˆMLEï¼‰ç›®çš„ã¯èª¤å·®ã®è“„ç©å•é¡Œã‚’å¼•ãèµ·ã“ã™ãŸã‚ã€æ¨¡å€£å­¦ç¿’ï¼ˆILï¼‰å•é¡Œã¨ã—ã¦å®šå¼åŒ–ã™ã‚‹ã“ã¨ãŒææ¡ˆã•ã‚ŒãŸã€‚ILãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ãƒãƒƒã‚¯ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã€èª¤å·®ã®è“„ç©å•é¡ŒãŒè»½æ¸›ã•ã‚Œã‚‹ã€‚ææ¡ˆæ‰‹æ³•ã§ã‚ã‚‹SequenceMatchã¯ã€æ•µå¯¾çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„å¤§è¦æ¨¡ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å¤‰æ›´ãªã—ã«å®Ÿè£…ã§ãã€SequenceMatch-$\chi^2$ç™ºæ•£ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚å®Ÿé¨“çš„ã«ã€SequenceMatchãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ãŠã„ã¦MLEã‚ˆã‚Šã‚‚æ”¹å–„ã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>backspaceã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã«çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€out of distributionã‚’å¼•ãèµ·ã“ã™ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…ƒã«æˆ»ã™ã“ã¨ã§ã€ç”Ÿæˆã‚¨ãƒ©ãƒ¼ã‚’è»½æ¸›ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e22d059f-5475-417c-aea2-d1fd55b6c23a" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/KnowledgeGraph.html" target="_blank" rel="noopener noreferrer">#KnowledgeGraph</a>
<span class="issue_date">Issue Date: 2023-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/768" target="_blank" rel="noopener noreferrer" class="title-link">Unifying Large Language Models and Knowledge Graphs: A Roadmap, Shirui Pan+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¨KGsã‚’çµ±åˆã™ã‚‹ã“ã¨ã§ã€è‡ªç„¶è¨€èªå‡¦ç†ã‚„äººå·¥çŸ¥èƒ½ã®åˆ†é‡ã§æ³¨ç›®ã‚’é›†ã‚ã¦ã„ã‚‹ã€‚KGsã¯è±Šå¯Œãªäº‹å®ŸçŸ¥è­˜ã‚’æ˜ç¤ºçš„ã«æ ¼ç´ã—ã¦ã„ã‚‹ãŒã€æ§‹ç¯‰ãŒå›°é›£ã§ã‚ã‚Šã€é€²åŒ–ã™ã‚‹æ€§è³ªã‚’æŒã£ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã€LLMsã¯ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€äº‹å®ŸçŸ¥è­˜ã‚’æ‰ãˆãŸã‚Šã‚¢ã‚¯ã‚»ã‚¹ã—ãŸã‚Šã™ã‚‹ã“ã¨ãŒã§ããªã„ã€‚æœ¬è¨˜äº‹ã§ã¯ã€LLMsã¨KGsã‚’çµ±åˆã™ã‚‹ãŸã‚ã®å±•æœ›ã‚’ç¤ºã—ã€KG-enhanced LLMsã€LLM-augmented KGsã€Synergized LLMs + KGsã®3ã¤ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã™ã‚‹ã€‚æ—¢å­˜ã®å–ã‚Šçµ„ã¿ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ä»Šå¾Œã®ç ”ç©¶æ–¹å‘ã‚’æŒ‡æ‘˜ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMsã¨KGã®çµ±åˆã«é–¢ã™ã‚‹ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’æç¤ºã€‚KGã‚’LLMã®äº‹å‰å­¦ç¿’ã‚„æ¨è«–ã«çµ„ã¿è¾¼ã‚€æ–¹æ³•ã€KGã‚¿ã‚¹ã‚¯ã«LLMã‚’åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã€LLMã¨KGã®åŒæ–¹å‘ã®reasoniegèƒ½åŠ›ã‚’é«˜ã‚ã‚‹æ–¹æ³•ãªã©ã‚’ã‚«ãƒãƒ¼ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c008d409-e5db-4140-a82c-a658a4847780" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer" class="title-link">Textbooks Are All You Need, Suriya Gunasekar+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å°è¦æ¨¡ãªphi-1ã¨ã„ã†æ–°ã—ã„ã‚³ãƒ¼ãƒ‰ç”¨å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç´¹ä»‹ã—ã€8ã¤ã®A100ã§4æ—¥é–“ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸçµæœã€HumanEvalã§pass@1ã®æ­£è§£ç‡50.6ï¼…ã€MBPPã§55.5ï¼…ã‚’é”æˆã—ãŸã“ã¨ã‚’å ±å‘Šã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€phi-1ã¯ã€phi-1-baseã‚„phi-1-smallã¨æ¯”è¼ƒã—ã¦ã€é©šãã¹ãæ–°ã—ã„æ€§è³ªã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚phi-1-smallã¯ã€HumanEvalã§45ï¼…ã‚’é”æˆã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1671643297616654342?s=46&t=JYDYid2m0v7vYaL7jhZYjQ"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ•™ç§‘æ›¸ã®ã‚ˆã†ãªå“è³ªã®è‰¯ã„ãƒ†ã‚­ã‚¹ãƒˆã§äº‹å‰å­¦ç¿’ã™ã‚‹ã¨æ€§èƒ½ãŒå‘ä¸Šã—ï¼ˆã‚°ãƒ©ãƒ•çœŸã‚“ä¸­ï¼‰ã€ã•ã‚‰ã«è‰¯è³ªãªã‚¨ã‚¯ã‚µã‚µã‚¤ã‚ºã§Finetuningã™ã‚‹ã¨ã‚ˆã‚Šæ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ï¼ˆã‚°ãƒ©ãƒ•å³ï¼‰<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9f0b945a-f965-42ae-b5d8-ac464359af35" alt="image" loading="lazy"></p>
<p>æ—¥æœ¬èªè§£èª¬: 


<a href="https://dalab.jp/archives/journal/introduction-textbooks-are-all-you-need/" target="_blank" rel="noopener noreferrer">https://dalab.jp/archives/journal/introduction-textbooks-are-all-you-need/</a>


</p>
<p>ã–ã£ãã‚Šè¨€ã†ã¨ã€æ•™ç§‘æ›¸ã§äº‹å‰å­¦ç¿’ã—ã€ã‚¨ã‚¯ã‚µã‚µã‚¤ã‚ºã§Finetuningã™ã‚‹ã¨æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ï¼ˆ= ã‚ˆã‚Šå¤§ãã„ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ãŒå¾—ã‚‰ã‚Œã‚‹ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/765" target="_blank" rel="noopener noreferrer" class="title-link">RWKV: Reinventing RNNs for the Transformer Era, Bo Peng+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¨RNNã®ä¸¡æ–¹ã®åˆ©ç‚¹ã‚’çµ„ã¿åˆã‚ã›ãŸæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚‹RWKVã‚’ææ¡ˆã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«è¨ˆç®—ã‚’ä¸¦åˆ—åŒ–ã—ã€æ¨è«–ä¸­ã«ä¸€å®šã®è¨ˆç®—ãŠã‚ˆã³ãƒ¡ãƒ¢ãƒªã®è¤‡é›‘ã•ã‚’ç¶­æŒã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚RWKVã¯ã€åŒã˜ã‚µã‚¤ã‚ºã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã€å°†æ¥çš„ã«ã¯ã‚ˆã‚ŠåŠ¹ç‡çš„ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ãŸã‚ã«ã“ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ´»ç”¨ã§ãã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç•°ãªã‚‹transformerã¨RWKVã®è¨ˆç®—é‡ã¨ãƒ¡ãƒ¢ãƒªæ¶ˆè²»é‡ã®æ¯”è¼ƒ<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/84d5241f-1702-4bd6-8ce3-0a80ded8f192" alt="image" loading="lazy"><br><br><br><br>RWKVã®æ§‹é€ ã¯åŸºæœ¬çš„ã«ã€residual blockã‚’ã‚¹ã‚¿ãƒƒã‚¯ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦æ§‹æˆã•ã‚Œã‚‹ã€‚ä¸€ã¤ã®residual blockã¯ã€time-mixingï¼ˆæ™‚é–“æ–¹å‘ã®æ··ãœåˆã‚ã›ï¼‰ã¨ã€channnel-mixingï¼ˆè¦ç´ é–“ã§ã®æ··ãœåˆã‚ã›ï¼‰ã‚’è¡Œã†ã€‚ã€€<br><br>RWKVã®ã‚«ã‚®ã¨ãªã‚‹è¦ç´ ã¯ä»¥ä¸‹ã®4ã¤ã§ã‚ã‚Šã€RWKVã®ãƒ–ãƒ­ãƒƒã‚¯ã€ãŠã‚ˆã³LMã§ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚‹ï¼š<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2185d678-8ca1-4017-a052-77c073704253" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e5559a3c-40ee-4859-ba75-2827c12b5964" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4af26c0f-5907-4723-b24c-67b02a8025b9" alt="image" loading="lazy"><br><br><br><br>ã“ã“ã§ã€token-shiftã¯ã€previsou timestepã®inputã¨ã®linear interpolationã‚’ç¾åœ¨ã®inputã¨ã¨ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šå†å¸°æ€§ã‚’æ‹…ä¿ã™ã‚‹ã€‚<br><br><br><br>RWKVã¯ä»–ã®LLMã¨æ¯”è¼ƒã—ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã«å¯¾ã—ã¦æ€§èƒ½ã¯comparableã§ã‚ã‚Šã€context lengthã‚’å¢—ã‚„ã™ã“ã¨ã§ã€lossã¯ãã¡ã‚“ã¨ä½ä¸‹ã—ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’ã™ã‚‹éš›ã«è¦ã™ã‚‹æ™‚é–“ã¯ä»–ã®LLMã¨æ¯”è¼ƒã—ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã«å¯¾ã—ã¦ç·šå½¢ã«ã—ã‹å¢—åŠ ã—ãªã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c8a39aae-17de-4c43-bfba-b6a54f83205e" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9baf95d0-9e8c-4c62-a8f3-0f2a0d67ae00" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a9601b1c-c403-4c2c-bd60-3d2cfa6e512e" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/764" target="_blank" rel="noopener noreferrer" class="title-link">How Language Model Hallucinations Can Snowball, Muru Zhang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹éš›ã®ãƒªã‚¹ã‚¯ã¨ã—ã¦ã€å¹»è¦šãŒã‚ã‚‹ã“ã¨ãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã®å¹»è¦šã¯ã€LMã®çŸ¥è­˜ä¸è¶³ã«ã‚ˆã‚‹ã‚‚ã®ã ã‘ã§ãªãã€ä»¥å‰ã«ç”Ÿæˆã•ã‚ŒãŸå¹»è¦šã‚’æ­£å½“åŒ–ã™ã‚‹ãŸã‚ã«ã€LMãŒèª¤ã£ãŸä¸»å¼µã‚’å‡ºåŠ›ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã¨ã„ã†ä»®èª¬ãŒç«‹ã¦ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ChatGPTã¨GPT-4ã¯ã€èª¤ã£ãŸå›ç­”ã‚’ç¤ºã—ã€å¹»è¦šã®ã‚¹ãƒãƒ¼ãƒœãƒ¼ãƒ«åŠ¹æœã«ã‚ˆã‚Šã€ã‚ˆã‚Šå¤šãã®èª¤ã‚ŠãŒç”Ÿã˜ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ã¾ãŸã€èª¤ã‚Šã‚’å«ã‚€è³ªå•å¿œç­”ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒæ§‹ç¯‰ã•ã‚Œã€LMãŒè‡ªåˆ†è‡ªèº«ã®èª¤ã‚Šã‚’è­˜åˆ¥ã§ãã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã«ã‚ˆã‚‹hallucinationã¯ã€å˜ã«LLMã®çŸ¥è­˜ä¸è¶³ã«ã‚ˆã‚‹ã‚‚ã®ã ã‘ã§ã¯ãªãã€LLMãŒä»¥å‰ã«ç”Ÿæˆã—ãŸhallucinationã‚’æ­£å½“åŒ–ã™ã‚‹ãŸã‚ã«ã€èª¤ã£ãŸå‡ºåŠ›ã‚’ç”Ÿæˆã—ã¦ã—ã¾ã†ã¨ã„ã†ä»®èª¬ã‚’æèµ·ã—ã€ã“ã®ä»®èª¬ã‚’æ¤œè¨¼ã—ãŸç ”ç©¶ã€‚ã“ã‚Œã‚’hallucination snowballã¨å‘¼ã¶ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMã‚’è¨“ç·´ã™ã‚‹éš›ã«ã€äº‹å®Ÿã«å¯¾ã™ã‚‹æ­£ç¢ºã•ã‚’çŠ ç‰²ã«ã—ã¦ã€æµæš¢æ€§ã¨ä¸€è²«æ€§ã‚’å„ªå…ˆã—è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ãƒªã‚¹ã‚¯ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6a9e29b7-953f-4e72-bfdd-85daab9317d6" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/763" target="_blank" rel="noopener noreferrer" class="title-link">LLMs as Factual Reasoners: Insights from Existing Benchmarks and Beyond, Philippe Laban+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã‚’ä½¿ç”¨ã—ã¦äº‹å®Ÿã®çŸ›ç›¾ã‚’æ¤œå‡ºã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ãŒã€æ—¢å­˜ã®è©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å•é¡ŒãŒã‚ã‚‹ãŸã‚ã€ã»ã¨ã‚“ã©ã®LLMã¯è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«å¤±æ•—ã™ã‚‹ã€‚ãã“ã§ã€æ–°ã—ã„ä¸æ•´åˆæ¤œå‡ºãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã‚ã‚‹SummEditsã‚’ææ¡ˆã—ã€å®Ÿè£…ã—ãŸã€‚SummEditsã¯é«˜ã„å†ç¾æ€§ã‚’æŒã¡ã€ã»ã¨ã‚“ã©ã®LLMã¯è‹¦æˆ¦ã™ã‚‹ã€‚æœ€ã‚‚å„ªã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã€äººé–“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‹ã‚‰8ï¼…ä½ã„çµæœã¨ãªã‚Šã€LLMãŒäº‹å®Ÿã«ã¤ã„ã¦æ¨è«–ã—ã€çŸ›ç›¾ã‚’æ¤œå‡ºã™ã‚‹èƒ½åŠ›ã«ã¯ã¾ã èª²é¡ŒãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¢å­˜ã®ä¸æ•´åˆæ¤œå‡ºã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯ã€7+%ã‚’è¶…ãˆã‚‹ã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã—ã¦ã€mislabeledãªã‚µãƒ³ãƒ—ãƒ«ãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚¯ã‚ªãƒªãƒ†ã‚£ã«å•é¡ŒãŒã‚ã£ãŸã€‚ãã“ã§SummEditsã¨å‘¼ã°ã‚Œã‚‹äº‹å®Ÿã®çŸ›ç›¾ã®æ¤œå‡ºåŠ›ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã®æ–°ãŸãªãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ææ¡ˆã€‚æ—¢å­˜ã®ä¸æ•´åˆæ¤œå‡ºã§ã¯ã€æ—¢å­˜ã®LLMã‚’ç”¨ã„ã¦æ¯”è¼ƒã—ãŸçµæœã€æœ€ã‚‚ä¸æ•´åˆæ¤œå‡ºã§æ€§èƒ½ãŒè‰¯ã‹ã£ãŸGPT-4ã§ã•ãˆã€äººé–“ã«å¯¾ã—ã¦8%ã‚‚ä½ã„æ€§èƒ½ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œï¼ˆè¦ç´„çµæœã«å¯¾ã—ã¦äº‹å®Ÿã®çŸ›ç›¾ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹å¦ã‹æ¤œå‡ºã™ã‚‹ã‚¿ã‚¹ã‚¯ï¼‰ã€ã¾ã ã¾ã LLMã«ã¯èª²é¡ŒãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/45473a67-7f96-4f75-841c-9ccf95852394" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/760" target="_blank" rel="noopener noreferrer" class="title-link">Think Before You Act: Decision Transformers with Internal Working Memory, Jikun Kang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®æ€§èƒ½ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«æŒ¯ã‚‹èˆã„ã‚’è¨˜æ†¶ã™ã‚‹ã€Œå¿˜å´ç¾è±¡ã€ã«ã‚ˆã£ã¦ä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚äººé–“ã®è„³ã¯åˆ†æ•£å‹ã®ãƒ¡ãƒ¢ãƒªã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã€å¿˜å´ç¾è±¡ã‚’è»½æ¸›ã—ã¦ã„ã‚‹ã€‚ãã“ã§ã€æˆ‘ã€…ã¯ã€å†…éƒ¨ä½œæ¥­ãƒ¡ãƒ¢ãƒªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ææ¡ˆã—ã€Atariã‚²ãƒ¼ãƒ ã¨ãƒ¡ã‚¿ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ“ä½œã‚¿ã‚¹ã‚¯ã®ä¸¡æ–¹ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ã¨æ±åŒ–æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/754" target="_blank" rel="noopener noreferrer" class="title-link">OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities, Yuanzhen Xie+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€äººé–“ã®èªçŸ¥ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ¨¡å€£ã™ã‚‹ã“ã¨ã§ã€è¤‡é›‘ãªæ¨è«–å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®æ–°ã—ã„çŸ¥çš„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹OlaGPTã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚OlaGPTã¯ã€æ³¨æ„ã€è¨˜æ†¶ã€æ¨è«–ã€å­¦ç¿’ãªã©ã®ç•°ãªã‚‹èªçŸ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å«ã¿ã€ä»¥å‰ã®èª¤ã‚Šã‚„å°‚é–€å®¶ã®æ„è¦‹ã‚’å‹•çš„ã«å‚ç…§ã™ã‚‹å­¦ç¿’ãƒ¦ãƒ‹ãƒƒãƒˆã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€Chain-of-Thoughtï¼ˆCOTï¼‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨åŒ…æ‹¬çš„ãªæ„æ€æ±ºå®šãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚‚ææ¡ˆã•ã‚Œã¦ã„ã¾ã™ã€‚OlaGPTã¯ã€è¤‡æ•°ã®æ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å³å¯†ã«è©•ä¾¡ã•ã‚Œã€æœ€å…ˆç«¯ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä¸Šå›ã‚‹å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚OlaGPTã®å®Ÿè£…ã¯GitHubã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/741" target="_blank" rel="noopener noreferrer" class="title-link">ViCo: Detail-Preserving Visual Condition for Personalized Text-to-Image  Generation, Shaozhe Hao+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸç”»åƒç”Ÿæˆã«ãŠã„ã¦ã€é«˜é€Ÿã§è»½é‡ãªãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒ¡ã‚½ãƒƒãƒ‰ã§ã‚ã‚‹ViCoã‚’ææ¡ˆã€‚æ³¨ç›®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å°å…¥ã—ã€æ³¨ç›®ãƒ™ãƒ¼ã‚¹ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒã‚¹ã‚¯ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ä¸€èˆ¬çš„ãªéå­¦ç¿’ã®åŠ£åŒ–ã‚’è»½æ¸›ã€‚å…ƒã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¾®èª¿æ•´ã›ãšã€è»½é‡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã ã‘ã§ã€æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã¾ãŸã¯ãã‚Œä»¥ä¸Šã®æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/732" target="_blank" rel="noopener noreferrer" class="title-link">AVIS: Autonomous Visual Information Seeking with Large Language Models, Ziniu Hu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€è‡ªå¾‹çš„ãªæƒ…å ±åé›†ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è³ªå•å¿œç­”ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹AVISã‚’ææ¡ˆã™ã‚‹ã€‚AVISã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã‚’æ´»ç”¨ã—ã¦å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã®åˆ©ç”¨æˆ¦ç•¥ã‚’å‹•çš„ã«æ±ºå®šã—ã€è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã«å¿…è¦ãªä¸å¯æ¬ ãªçŸ¥è­˜ã‚’ç²å¾—ã™ã‚‹ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ã‚¿ãƒ‡ã‚£ã‚’å®Ÿæ–½ã—ã¦åé›†ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã‚„æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã‚’æ”¹å–„ã—ã€çŸ¥è­˜é›†ç´„å‹ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è³ªå•å¿œç­”ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9df9b0ce-1f95-4e48-a4c9-b4c6b87d0ac6" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/729" target="_blank" rel="noopener noreferrer" class="title-link">KoLA: Carefully Benchmarking World Knowledge of Large Language Models, Jifan Yu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®è©•ä¾¡ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã€KoLAã¨ã„ã†çŸ¥è­˜æŒ‡å‘ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã—ãŸã€‚ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã€19ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚«ãƒãƒ¼ã—ã€Wikipediaã¨æ–°èˆˆã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã€çŸ¥è­˜ã®å¹»è¦šã‚’è‡ªå‹•çš„ã«è©•ä¾¡ã™ã‚‹ç‹¬è‡ªã®è‡ªå·±å¯¾ç…§ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’å«ã‚€å¯¾ç…§çš„ãªã‚·ã‚¹ãƒ†ãƒ ã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚21ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨å•†ç”¨ã®LLMã‚’è©•ä¾¡ã—ã€KoLAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã‚ªãƒ¼ãƒ—ãƒ³å‚åŠ ã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã¯ã€LLMã‚„çŸ¥è­˜é–¢é€£ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã®å‚è€ƒè³‡æ–™ã¨ã—ã¦ç¶™ç¶šçš„ã«æ›´æ–°ã•ã‚Œã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/725" target="_blank" rel="noopener noreferrer" class="title-link">One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning, Arnav Chavan+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ±ç”¨çš„ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã®é«˜åº¦ãªæ‰‹æ³•ã§ã‚ã‚‹Generalized LoRA (GLoRA)ã‚’ææ¡ˆã—ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’æœ€é©åŒ–ã—ã€ä¸­é–“ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ã‚ˆã‚ŠæŸ”è»Ÿæ€§ã¨èƒ½åŠ›ã‚’æä¾›ã™ã‚‹ã€‚GLoRAã¯ã€å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å€‹åˆ¥ã®ã‚¢ãƒ€ãƒ—ã‚¿ã‚’å­¦ç¿’ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼ãªãƒ¬ã‚¤ãƒ¤ãƒ¼ã”ã¨ã®æ§‹é€ æ¢ç´¢ã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é©å¿œã‚’ä¿ƒé€²ã™ã‚‹ã€‚åŒ…æ‹¬çš„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€GLoRAã¯ã€è‡ªç„¶è¨€èªã€å°‚é–€åˆ†é‡ã€æ§‹é€ åŒ–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ãŠã„ã¦ã€å¾“æ¥ã®ã™ã¹ã¦ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã€æ§˜ã€…ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ˆã‚Šå°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨è¨ˆç®—ã§å„ªã‚ŒãŸç²¾åº¦ã‚’é”æˆã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=K7KQkiHanD" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=K7KQkiHanD</a>


<br><br>ICLR'24ã«rejectã•ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/PairWise.html" target="_blank" rel="noopener noreferrer">#PairWise</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Ensemble.html" target="_blank" rel="noopener noreferrer">#Ensemble</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/708" target="_blank" rel="noopener noreferrer" class="title-link">LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and  Generative Fusion, Dongfu Jiang+, N_A, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- LLM-Blenderã¯ã€è¤‡æ•°ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ãŸã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€PairRankerã¨GenFuserã®2ã¤ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚PairRankerã¯ã€å°‚é–€çš„ãªãƒšã‚¢ãƒ¯ã‚¤ã‚ºæ¯”è¼ƒæ–¹æ³•ã‚’ä½¿ç”¨ã—ã¦å€™è£œã®å‡ºåŠ›é–“ã®å¾®å¦™ãªé•ã„ã‚’åŒºåˆ¥ã—ã€GenFuserã¯ã€ä¸Šä½ãƒ©ãƒ³ã‚¯ã®å€™è£œã‚’ãƒãƒ¼ã‚¸ã—ã¦æ”¹å–„ã•ã‚ŒãŸå‡ºåŠ›ã‚’ç”Ÿæˆã—ã¾ã™ã€‚MixInstructã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å°å…¥ã—ã€LLM-Blenderã¯ã€å€‹ã€…ã®LLMsã‚„ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€å¤§ããªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å·®ã‚’ç¢ºç«‹ã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-05-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/702" target="_blank" rel="noopener noreferrer" class="title-link">Visualizing Linguistic Diversity of Text Datasets Synthesized by Large  Language Models, Emily Reif+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã‚’ä½¿ç”¨ã—ã¦ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹æ–‡çš„å¤šæ§˜æ€§ã‚’ç†è§£ã—åˆ†æã™ã‚‹ãŸã‚ã®æ–°ã—ã„å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«ã§ã‚ã‚‹LinguisticLensãŒæä¾›ã•ã‚ŒãŸã€‚ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹æ–‡ã€èªå½™ã€ãŠã‚ˆã³æ„å‘³ã®è»¸ã«æ²¿ã£ã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ã€éšå±¤çš„ãªå¯è¦–åŒ–ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã€‚ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¢ã¯shorturl.at/zHOUVã§åˆ©ç”¨å¯èƒ½ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã‚’ç”¨ã„ã¦few-shot promptingã‚’åˆ©ç”¨ã—ã¦ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç†è§£ã—è©•ä¾¡ã™ã‚‹ã“ã¨ã¯é›£ã—ãã€ãã‚‚ãã‚‚LLMã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®å¤±æ•—ã«é–¢ã—ã¦ã¯ã‚ã¾ã‚Šç†è§£ãŒé€²ã‚“ã§ã„ãªã„ï¼ˆe.g. repetitionãªã©ã¯çŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ï¼‰ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€LLMã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç‰¹æ€§ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€æ§‹æ–‡ãƒ»èªå½™ãƒ»æ„å‘³ã®è»¸ã«æ²¿ã£ã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç‰¹æ€§ã‚’å¯è¦–åŒ–ã™ã‚‹ã“ã¨ã§ã€ã“ã®ã‚ˆã†ãªèª²é¡Œã‚’è§£æ±ºã™ã‚‹ã“ã¨ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã€‚<br><br><br><br>ç‰¹ã«ã€å¾“æ¥ç ”ç©¶ã§ã¯GoldãŒå­˜åœ¨ã™ã‚‹ã“ã¨ãŒå‰æãªæ‰‹æ³•ãŒåˆ©ç”¨ã•ã‚Œã¦ããŸï¼ˆe.g. ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã—downstream taskã®äºˆæ¸¬æ€§èƒ½ã§è‰¯ã•ã‚’æ¸¬ã‚‹ã€Gold distributionã¨distributionã‚’æ¯”è¼ƒã™ã‚‹ï¼‰ã€‚ã—ã‹ã—ã€ã“ã®ã‚ˆã†ãªæ‰‹æ³•ã§ã¯ã€synthetic data firstãªã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã§ã€GoldãŒå­˜åœ¨ã—ãªã„å ´åˆã«å¯¾å‡¦ã§ããªã„ã€‚ã“ã®ã‚ˆã†ãªå•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«Gold dataãŒå­˜åœ¨ã—ãªã„å ´åˆã«ã€ãƒ‡ãƒ¼ã‚¿ã®æ§‹æ–‡ãƒ»èªå½™ãƒ»æ„å‘³ã«åŸºã¥ãã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿæ–½ã—çµæœã‚’å¯è¦–åŒ–ã—ã€human-in-the-loopã®æ çµ„ã¿ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è‰¯ã•ã‚’æ¤œè¨¼ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚</p>
<p>å¯è¦–åŒ–ä¾‹<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4bc73eee-9d26-4405-9d61-eca0a39fa852" alt="image" loading="lazy"></p>
<p>å®Ÿè£…: 


<a href="https://github.com/PAIR-code/interpretability/tree/master/data-synth-syntax" target="_blank" rel="noopener noreferrer">https://github.com/PAIR-code/interpretability/tree/master/data-synth-syntax</a>


</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2023-05-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/701" target="_blank" rel="noopener noreferrer" class="title-link">QUEST: A Retrieval Dataset of Entity-Seeking Queries with Implicit Set  Operations, Chaitanya Malaviya+, N_A, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- QUESTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€äº¤å·®ã€å’Œã€å·®ãªã©ã®é›†åˆæ¼”ç®—ã‚’æš—é»™çš„ã«æŒ‡å®šã™ã‚‹ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã€é¸æŠçš„ãªæƒ…å ±ãƒ‹ãƒ¼ã‚ºã‚’å®šå¼åŒ–ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦æ§‹ç¯‰ã•ã‚Œã¾ã—ãŸã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€Wikipediaã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¯¾å¿œã™ã‚‹ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®ã‚»ãƒƒãƒˆã«ãƒãƒƒãƒ—ã•ã‚Œã€ã‚¯ã‚¨ãƒªã§è¨€åŠã•ã‚Œã‚‹è¤‡æ•°ã®åˆ¶ç´„ã‚’å¯¾å¿œã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è¨¼æ‹ ã¨ä¸€è‡´ã•ã›ã€ã•ã¾ã–ã¾ãªé›†åˆæ¼”ç®—ã‚’æ­£ã—ãå®Ÿè¡Œã™ã‚‹ã“ã¨ã‚’ãƒ¢ãƒ‡ãƒ«ã«æ±‚ã‚ã¾ã™ã€‚ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚ˆã£ã¦è¨€ã„æ›ãˆã‚‰ã‚Œã€è‡ªç„¶ã•ã¨æµæš¢ã•ãŒã•ã‚‰ã«æ¤œè¨¼ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã¯ã€ã„ãã¤ã‹ã®ç¾ä»£çš„ãªæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã«ã¨ã£ã¦è‹¦æˆ¦ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚</span>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/DataDistillation.html" target="_blank" rel="noopener noreferrer">#DataDistillation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-05-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/700" target="_blank" rel="noopener noreferrer" class="title-link">LIMA: Less Is More for Alignment, Chunting Zhou+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€65Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®LLaMaè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹LIMAã‚’è¨“ç·´ã—ã€å¼·åŒ–å­¦ç¿’ã‚„äººé–“ã®å¥½ã¿ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãªã—ã«ã€å³é¸ã•ã‚ŒãŸ1,000ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ã¿ã§æ¨™æº–çš„ãªæ•™å¸«ã‚ã‚Šæå¤±ã§å¾®èª¿æ•´ã—ã¾ã—ãŸã€‚LIMAã¯ã€å¹…åºƒã„ã‚¯ã‚¨ãƒªã«å¯¾å¿œã™ã‚‹é©šãã¹ãå¼·åŠ›ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«ç¾ã‚Œãªã‹ã£ãŸæœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ã«ã‚‚ä¸€èˆ¬åŒ–ã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚åˆ¶å¾¡ã•ã‚ŒãŸäººé–“ã®ç ”ç©¶ã§ã¯ã€LIMAã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ã€GPT-4ã€Bardã€DaVinci003ã¨æ¯”è¼ƒã—ã¦å„ªã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã“ã‚Œã‚‰ã®çµæœã‹ã‚‰ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã»ã¨ã‚“ã©ã®çŸ¥è­˜ã¯äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«å­¦ç¿’ã•ã‚Œã€é«˜å“è³ªã®å‡ºåŠ›ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã¯é™ã‚‰ã‚ŒãŸæŒ‡ç¤ºèª¿æ•´ãƒ‡ãƒ¼ã‚¿ã—ã‹å¿…è¦ãªã„ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLaMA65Bã‚’ãŸã£ãŸ1kã®data pointï¼ˆå³é¸ã•ã‚ŒãŸç‰©ï¼‰ã§RLHFç„¡ã—ã§finetuningã™ã‚‹ã¨ã€æ—…è¡Œãƒ—ãƒ©ãƒ³ã®ä½œæˆã‚„ã€æ­´å²æ”¹å¤‰ã®æ¨æ¸¬ï¼ˆï¼Ÿï¼‰å¹…åºƒã„ã‚¿ã‚¹ã‚¯ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€æœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ã¸ã®æ±åŒ–èƒ½åŠ›ã‚‚ç¤ºã—ãŸã€‚æœ€çµ‚çš„ã«GPT3,4,BARD,CLAUDEã‚ˆã‚Šã‚‚äººé–“ãŒå¥½ã‚€å›ç­”ã‚’è¿”ã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/db025381-0bf0-47a3-bd18-5d88bff666df" alt="image" loading="lazy"></p>
<p>LLaMAã®ã‚ˆã†ãªã‚ªãƒ¼ãƒ—ãƒ³ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå°‘ãªã„ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€å°‘é‡ã®ã‚µãƒ³ãƒ—ãƒ«ã§finetuningã™ã‚‹ã¨GPT4ã«è¿«ã‚Œã‚‹ã¨ã„ã†ã®ã¯gamechangerã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹</p>
<p>openreview: 


<a href="https://openreview.net/forum?id=KBMOKmX2he" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=KBMOKmX2he</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-05-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/699" target="_blank" rel="noopener noreferrer" class="title-link">Symbol tuning improves in-context learning in language models, Jerry Wei+, N_A, EMNLP'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è‡ªç„¶è¨€èªãƒ©ãƒ™ãƒ«ã‚’ã‚·ãƒ³ãƒœãƒ«ã«ç½®ãæ›ãˆã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹ã€Œsymbol tuningã€ã‚’ææ¡ˆã—ã€æœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ã‚„ä¸æ˜ç¢ºãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã—ã¦å …ç‰¢ãªæ€§èƒ½ã‚’ç¤ºã™ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€symbol tuningã«ã‚ˆã‚Šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çš„æ¨è«–ã‚¿ã‚¹ã‚¯ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸ŠãŒè¦‹ã‚‰ã‚Œã€ä»¥å‰ã®æ„å‘³çš„çŸ¥è­˜ã‚’ä¸Šæ›¸ãã™ã‚‹èƒ½åŠ›ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚Flan-PaLMãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦å®Ÿé¨“ãŒè¡Œã‚ã‚Œã€æœ€å¤§540Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¾ã§åˆ©ç”¨ã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>æ¦‚è¦ã‚„OpenReviewã®å†…å®¹ã‚’ã–ã£ãã‚Šã¨ã—ã‹èª­ã‚ã¦ã„ãªã„ãŒã€è‡ªç„¶è¨€èªã®ãƒ©ãƒ™ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ãªæ–‡å­—åˆ—ã«ã—ãŸã‚Šã€instructionã‚’ã‚ãˆã¦é™¤å¤–ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’Finetuningã™ã‚‹ã“ã¨ã§ã€promptã«å¯¾ã™ã‚‹sensitivityã‚„å…ƒã€…ãƒ¢ãƒ‡ãƒ«ãŒæŒã£ã¦ã„ã‚‹ãƒ©ãƒ™ãƒ«ã¨çŸ›ç›¾ã—ãŸæ„å‘³ã‚’in context learningã§ä¸Šæ›¸ãã§ãã‚‹ã¨ã„ã†ã“ã¨ã¯ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€æ­£å‰‡åŒ–ã®å½¹å‰²ã‚’æœãŸã—ã¦ã„ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚ã¤ã¾ã‚Šã€ãƒ©ãƒ™ãƒ«ãã®ã‚‚ã®ã«è‡ªç„¶è¨€èªã¨ã—ã¦ã®æ„å‘³ã‚’å«ã¾ã›ãªã„ã“ã¨ã‚„ã€instructionã‚’ç„¡ãã™ã“ã¨ã§ã€ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒè¡¨å±¤çš„ãªãƒ©ãƒ™ãƒ«ã®æ„å‘³ã‚„æŒ‡ç¤ºã‹ã‚‰ã§ã¯ãªãï¼‰ã€ã‚ˆã‚Šå®Ÿéš›ã®ICLã§åˆ©ç”¨ã•ã‚Œã‚‹Exaplarã‹ã‚‰ã‚¿ã‚¹ã‚¯ã‚’æ¨è«–ã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã‚‹ã®ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/a4050a09-d319-481d-9b63-70b2ee9b5aad" alt="image" loading="lazy"></p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=vOX7Dfwo3v" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=vOX7Dfwo3v</a>


</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DataDistillation.html" target="_blank" rel="noopener noreferrer">#DataDistillation</a>
<span class="issue_date">Issue Date: 2023-05-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/698" target="_blank" rel="noopener noreferrer" class="title-link">DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining, Sang Michael Xie+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã®æ··åˆæ¯”ã«ã¤ã„ã¦ã€DoReMiã¨ã„ã†æ‰‹æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚DoReMiã¯ã€å°ã•ãªãƒ—ãƒ­ã‚­ã‚·ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ‰ãƒ¡ã‚¤ãƒ³ã®é‡ã¿ã‚’ç”Ÿæˆã—ã€å†ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦å¤§ããªãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ã«ãƒ‰ãƒ¡ã‚¤ãƒ³ã®é‡ã¿ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚å®Ÿé¨“ã§ã¯ã€DoReMiã¯The Pileã‚„GLaMãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§é«˜ã„ç²¾åº¦ã‚’ç™ºæ®ã—ã€few-shotä¸‹æµç²¾åº¦ã‚’6.5ï¼…æ”¹å–„ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>äº‹å‰å­¦ç¿’ã™ã‚‹éš›ã®å„ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã©ã®ã‚ˆã†ãªæ¯”ç‡ã§mixtureã™ã‚‹ã‹ã®è©±ã€‚å„ãƒ‰ãƒ¡ã‚¤ãƒ³ã”ã¨ã«å°ã•ãªproxy modelã‚’è¨“ç·´ã—ã€downstream taskã®çŸ¥è­˜ç„¡ã—ã§ãƒ‰ãƒ¡ã‚¤ãƒ³ã”ã¨ã®é‡ã¿ã‚’ç”Ÿæˆã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆã•ã‚ŒãŸãƒ‰ãƒ¡ã‚¤ãƒ³ã”ã¨ã®é‡ã¿ã«å¾“ã„ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ï¼ˆ1/30ã®ãƒ—ãƒ­ã‚­ã‚·ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå ´åˆï¼‰ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Š2.6å€é«˜é€Ÿã§ã€6.5%oneshotã®accuracyã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã«æˆåŠŸ<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2c0b125a-5ecc-4ee3-8c3b-022c03606c60" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<span class="issue_date">Issue Date: 2023-05-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/697" target="_blank" rel="noopener noreferrer" class="title-link">StructGPT: A General Framework for Large Language Model to Reason over  Structured Data, Jinhao Jiang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ä¸Šã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ¨è«–èƒ½åŠ›ã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦ç ”ç©¶ã—ã€Iterative Reading-then-Reasoningï¼ˆIRRï¼‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é–¢é€£ã™ã‚‹ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚’åé›†ã™ã‚‹å°‚é–€çš„ãªé–¢æ•°ã‚’æ§‹ç¯‰ã—ã€LLMsã«åé›†ã•ã‚ŒãŸæƒ…å ±ã«åŸºã¥ã„ã¦æ¨è«–ã‚¿ã‚¹ã‚¯ã«é›†ä¸­ã•ã›ã¾ã™ã€‚å¤–éƒ¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®æ”¯æ´ã‚’å—ã‘ã¦ã€LLMsãŒæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ä¸Šã§æ¨è«–ã™ã‚‹ãŸã‚ã®invoking-linearization-generationæ‰‹é †ã‚’ææ¡ˆã—ã€ä¸ãˆã‚‰ã‚ŒãŸã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹ç›®æ¨™å›ç­”ã«å¾ã€…ã«è¿‘ã¥ãã“ã¨ãŒã§ãã¾ã™ã€‚å¾¹åº•çš„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æœ‰åŠ¹æ€§ã‚’ç¤ºã—ã€ãƒ•ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æ•™å¸«ã‚ã‚Šãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã¯ã€\url{https://github.com/RUCAIBox/StructGPT}ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹LLMã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®reasoningèƒ½åŠ›ã‚’æ”¹å–„ã€‚æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹QAã‚¿ã‚¹ã‚¯ã§æ‰‹æ³•ãŒæœ‰åŠ¹ãªã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ac9732f1-a9c9-4620-8bf8-053415a5e654" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Planning.html" target="_blank" rel="noopener noreferrer">#Planning</a>
<span class="issue_date">Issue Date: 2023-05-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/696" target="_blank" rel="noopener noreferrer" class="title-link">Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models, Hanxu Hu+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€LLMsã‚’ä½¿ç”¨ã—ã¦è¤‡é›‘ãªè¨ˆç”»ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚‹Natural Language Planningï¼ˆNLPï¼‰ã‚’ææ¡ˆã—ã€CoSã¨ã„ã†æ–°ã—ã„æ‰‹æ³•ã‚’å°å…¥ã—ã¦ã€LLMsãŒã‚·ãƒ³ãƒœãƒªãƒƒã‚¯è¡¨ç¾ã‚’ã‚ˆã‚Šç†è§£ã—ã‚„ã™ãã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚CoSã¯ChatGPTã‚„InstructGPTã§ã®å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’å‰Šæ¸›ã—ã€Brick Worldã§60.8ï¼…ã®ç²¾åº¦ã‚’é”æˆã™ã‚‹ãªã©ã€æ€§èƒ½ã®å‘ä¸Šã‚’å®Ÿç¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMã¯è¤‡é›‘ãªãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ãŒè‹¦æ‰‹ãªã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ãŠã‚Šã€è¤‡é›‘ãªç’°å¢ƒã‚’è‡ªç„¶è¨€èªã§ã¯ãªãã€spatialã§symbolicãªãƒˆãƒ¼ã‚¯ãƒ³ã§è¡¨ç¾ã™ã‚‹ã“ã¨ã§ã€ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã®æ€§èƒ½ãŒå‘ä¸Šã—ãŸã¨ã„ã†è©±<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/50e9d7e2-bd75-4341-b7a0-394dc2eaf915" alt="image" loading="lazy"></p>
<p>OpenReview: 


<a href="https://openreview.net/forum?id=B0wJ5oCPdB" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=B0wJ5oCPdB</a>


</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2023-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/693" target="_blank" rel="noopener noreferrer" class="title-link">What In-Context Learning "Learns" In-Context: Disentangling Task  Recognition and Task Learning, Jane Pan+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ãŒã©ã®ã‚ˆã†ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã‚’åˆ©ç”¨ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹ã‹ã‚’èª¿æŸ»ã—ã¾ã—ãŸã€‚ã‚¿ã‚¹ã‚¯èªè­˜ï¼ˆTRï¼‰ã¨ã‚¿ã‚¹ã‚¯å­¦ç¿’ï¼ˆTLï¼‰ã®å½¹å‰²ã‚’åˆ†é›¢ã™ã‚‹ãŸã‚ã®å®Ÿé¨“ã‚’è¡Œã„ã€LLMsãŒãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é€šã˜ã¦æš—é»™çš„ã«å­¦ç¿’ã‚’è¡Œã†å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€ãƒ¢ãƒ‡ãƒ«ãŒã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã«ã¤ã‚Œã¦TLã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒæ”¹å–„ã•ã‚Œã‚‹ã“ã¨ã‚‚æ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—ãŸã€‚ã“ã‚Œã‚‰ã®çµæœã¯ã€ICLã®èƒŒå¾Œã«ã‚ã‚‹2ã¤ã®ç•°ãªã‚‹åŠ›ã‚’æ˜ã‚‰ã‹ã«ã—ã€å°†æ¥ã®ICLç ”ç©¶ã§ãã‚Œã‚‰ã‚’åŒºåˆ¥ã™ã‚‹ã“ã¨ã‚’æå”±ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMãŒIn context Learningã§æ–°ã—ã„ä½•ã‹ã‚’å­¦ç¿’ã—ã¦ã„ã‚‹ã®ã‹ã‚’èª¿æŸ»<br>TaskRecognitionï¼ˆTRï¼‰ã¯Ground Truthç„¡ã—ã§ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ã¿ã§å®Ÿæ–½<br>TaskLearningï¼ˆTLï¼‰ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ãªã‹ã£ãŸãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ©ãƒ™ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’æ‰ãˆã‚‹å¿…è¦ãŒã‚ã‚‹ã‚¿ã‚¹ã‚¯ã€‚<br>TRã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§ã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã‹ã£ãŸãŒã€TLã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«å¯¾ã—ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã—ãŸ<br>â†’ äº‹å‰å­¦ç¿’ã§å­¦ç¿’ã—ã¦ããŸçŸ¥è­˜ã‚’å¼•ã£å¼µã£ã¦ãã‚‹ã ã‘ã§ã¯TLã¯å®Ÿæ–½ã§ããªã„ã®ã§ã€TRã§ã¯ä½•ã‚‚å­¦ç¿’ã—ã¦ã„ãªã„ãŒã€TLã«ãŠã„ã¦ã¯æ–°ã—ãä½•ã‹ãŒå­¦ç¿’ã•ã‚Œã¦ã‚‹ã‚“ã˜ã‚ƒãªã„?ã¨ã„ã†ã“ã¨ã ã‚ã†ã‹<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/729cc613-7487-47be-9225-e02921091969" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/CodeGeneration.html" target="_blank" rel="noopener noreferrer">#CodeGeneration</a>
<span class="issue_date">Issue Date: 2023-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/692" target="_blank" rel="noopener noreferrer" class="title-link">CodeT5+: Open Code Large Language Models for Code Understanding and  Generation, Yue Wang+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã‚³ãƒ¼ãƒ‰ã®ãŸã‚ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼LLMsã®ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã§ã‚ã‚‹ã€ŒCodeT5+ã€ã‚’ææ¡ˆã—ã€æ§˜ã€…ãªãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚³ãƒ¼ãƒ‰ã‚¿ã‚¹ã‚¯ã«æŸ”è»Ÿã«é©åˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸã€‚ã¾ãŸã€äº‹å‰å­¦ç¿’ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒ†ã‚£ãƒ–ã®æ··åˆã‚’ææ¡ˆã™ã‚‹ã“ã¨ã§ã€äº‹å‰å­¦ç¿’ã¨ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ä¸ä¸€è‡´ã‚’ç·©å’Œã—ã€ã‚¹ãƒ‘ãƒ³ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ã€ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã€ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã€å› æœLMäº‹å‰å­¦ç¿’ã‚¿ã‚¹ã‚¯ã‚’å«ã‚ã¾ã—ãŸã€‚CodeT5+ã¯ã€ç•°ãªã‚‹è¨­å®šã§20ä»¥ä¸Šã®ã‚³ãƒ¼ãƒ‰é–¢é€£ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¾¹åº•çš„ã«è©•ä¾¡ã•ã‚Œã€æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¦³å¯Ÿã—ã¾ã—ãŸã€‚ç‰¹ã«ã€instruction-tuned CodeT5+ 16Bã¯ã€ä»–ã®ã‚ªãƒ¼ãƒ—ãƒ³ãªã‚³ãƒ¼ãƒ‰LLMsã«å¯¾ã—ã¦ã€HumanEvalã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚¿ã‚¹ã‚¯ã§æ–°ã—ã„æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>æ§˜ã€…ãªã‚³ãƒ¼ãƒ‰ã®ç†è§£ã¨ç”Ÿæˆã‚¿ã‚¹ã‚¯ã‚’ã‚µãƒãƒ¼ãƒˆ<br>ç•°ãªã‚‹è¨“ç·´æ‰‹æ³•ã«ã‚ˆã£ã¦è¨ˆç®—åŠ¹ç‡æ”¹å–„<br>20ç¨®é¡ã®ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€æ§˜ã€…ãªè¨­å®šã€Œã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã€finetuning, instruction tuningç­‰ï¼‰ã‚’å®Ÿæ–½ã—ãŸçµæœã€ã‚³ãƒ¼ãƒ‰è£œå®Œã€math programming, text to code retrievalã«ãŠã„ã¦SoTAé”æˆ</p></span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2023-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/690" target="_blank" rel="noopener noreferrer" class="title-link">TrueTeacher: Learning Factual Consistency Evaluation with Large Language  Models, Zorik Gekhman+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªç„¶è¨€èªæ¨è«–ï¼ˆNLIï¼‰ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸäº‹å®Ÿã®ä¸€è²«æ€§è©•ä¾¡ã«ã¯é™ç•ŒãŒã‚ã‚Šã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„ãŸã‚å®Ÿç”¨çš„ã§ã¯ãªã„ã€‚ãã“ã§ã€TrueTeacherã¨ã„ã†LLMã‚’ä½¿ç”¨ã—ã¦å¤šæ§˜ãªãƒ¢ãƒ‡ãƒ«ç”Ÿæˆè¦ç´„ã‚’æ³¨é‡ˆä»˜ã‘ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã€æ—¢å­˜ã®åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆæ–¹æ³•ã¨æ¯”è¼ƒã—ã¦å„ªä½æ€§ã¨å …ç‰¢æ€§ã‚’ç¤ºã—ãŸã€‚140ä¸‡ã®ä¾‹ã‚’å«ã‚€å¤§è¦æ¨¡ãªåˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Factual Consistency Evaluationã«é–¢ã™ã‚‹ç ”ç©¶ã€‚ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã—ã¦ã€æ§˜ã€…ãªè¦æ¨¡ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦è¦ç´„ã‚’ç”Ÿæˆã€‚ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã«å¯¾ã—ã¦factual informationãŒæ­£ã—ãå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã‚’ãƒ©ãƒ™ãƒ«ä»˜ã‘ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4fb420c8-6a80-4737-bc08-8e59b0ed89d6" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/684" target="_blank" rel="noopener noreferrer" class="title-link">Tree of Thoughts: Deliberate Problem Solving with Large Language Models, Shunyu Yao+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã«ã¯åˆ¶é™ãŒã‚ã‚Šã€æ¢ç´¢ã‚„æˆ¦ç•¥çš„å…ˆèª­ã¿ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã«ã¯ä¸ååˆ†ã§ã‚ã‚‹ã€‚ãã“ã§ã€Tree of Thoughtsï¼ˆToTï¼‰ã¨ã„ã†æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’å°å…¥ã—ã€Chain of Thoughtã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä¸€èˆ¬åŒ–ã—ã¦ã€æ„æ€æ±ºå®šã‚’è¡Œã†ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ã—ãŸã€‚ToTã«ã‚ˆã‚Šã€è¨€èªãƒ¢ãƒ‡ãƒ«ã¯è¤‡æ•°ã®ç•°ãªã‚‹æ¨è«–ãƒ‘ã‚¹ã‚’è€ƒæ…®ã—ã¦ã€æ¬¡ã®è¡Œå‹•ã‚’æ±ºå®šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ToTã¯ã€Game of 24ã€Creative Writingã€Mini Crosswordsãªã©ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®å•é¡Œè§£æ±ºèƒ½åŠ›ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Self Concistencyã®æ¬¡<br>Non trivialãªãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã¨æ¤œç´¢ãŒå¿…è¦ãªæ–°ãŸãª3ã¤ã®ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦ã€CoT w/ GPT4ã®æˆåŠŸç‡ãŒ4%ã ã£ãŸã¨ã“ã‚ã‚’ã€ToTã§ã¯74%ã‚’é”æˆ<br><br>è«–æ–‡ä¸­ã®è¡¨ã§ã¯CoTã®SuccessRateãŒ40%ã¨æ›¸ã„ã¦ã‚ã‚‹ã‚ˆã†ãª?<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6f853009-8d08-43b4-a7da-61677f4aca3a" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Faithfulness.html" target="_blank" rel="noopener noreferrer">#Faithfulness</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-05-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/666" target="_blank" rel="noopener noreferrer" class="title-link">Language Models Don't Always Say What They Think: Unfaithful   Explanations in Chain-of-Thought Prompting, Miles Turpin+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã«ã‚ˆã‚‹æ¨è«–ã«ãŠã„ã¦ã€chain-of-thought reasoningï¼ˆCoTï¼‰ã¨å‘¼ã°ã‚Œã‚‹èª¬æ˜ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ãŒã€ã“ã®èª¬æ˜ãŒãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã®çœŸã®ç†ç”±ã‚’èª¤ã£ã¦è¡¨ç¾ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ãƒã‚¤ã‚¢ã‚¹ã®ã‚ã‚‹ç‰¹å¾´ã‚’ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ã«è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€CoTèª¬æ˜ãŒå¤§ããå½±éŸ¿ã‚’å—ã‘ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã“ã®çµæœã¯ã€LLMsã«å¯¾ã™ã‚‹ä¿¡é ¼ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã€èª¬æ˜ã®å¿ å®Ÿåº¦ã‚’è©•ä¾¡ã—ã€æ”¹å–„ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/review.html" target="_blank" rel="noopener noreferrer">#review</a>
<span class="issue_date">Issue Date: 2023-05-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/647" target="_blank" rel="noopener noreferrer" class="title-link">Towards Personalized Review Summarization by Modeling Historical Reviews  from Customer and Product Separately, Xin Cheng+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¬ãƒ“ãƒ¥ãƒ¼è¦ç´„ã¯ã€Eã‚³ãƒãƒ¼ã‚¹ã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã«ãŠã„ã¦è£½å“ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ä¸»è¦ãªã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è¦ç´„ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ãŸã‚¿ã‚¹ã‚¯ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€è©•ä¾¡æƒ…å ±ã‚’å«ã‚€2ç¨®é¡ã®éå»ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã‚°ãƒ©ãƒ•æ¨è«–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨å¯¾æ¯”æå¤±ã‚’ç”¨ã„ã¦åˆ¥ã€…ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹HHRRSã‚’ææ¡ˆã™ã‚‹ã€‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®æ„Ÿæƒ…åˆ†é¡ã¨è¦ç´„ã‚’å…±åŒã§è¡Œã†ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ¡ç”¨ã—ã€4ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å¾¹åº•çš„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€HHRRSãŒä¸¡æ–¹ã®ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/643" target="_blank" rel="noopener noreferrer" class="title-link">Mass-Editing Memory in a Transformer, Kevin Meng+, N_A, ICLR'23</a>
<span class="snippet"><span>GPT Summary</span>- - å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°ã™ã‚‹ã“ã¨ã§ã€å°‚é–€çš„ãªçŸ¥è­˜ã‚’è¿½åŠ ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹- ã—ã‹ã—ã€ã“ã‚Œã¾ã§ã®ç ”ç©¶ã¯ä¸»ã«å˜ä¸€ã®é–¢é€£ä»˜ã‘ã®æ›´æ–°ã«é™å®šã•ã‚Œã¦ã„ãŸ- æœ¬ç ”ç©¶ã§ã¯ã€MEMITã¨ã„ã†æ–¹æ³•ã‚’é–‹ç™ºã—ã€å¤šæ•°ã®ãƒ¡ãƒ¢ãƒªã‚’ç›´æ¥è¨€èªãƒ¢ãƒ‡ãƒ«ã«æ›´æ–°ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’å®Ÿé¨“çš„ã«ç¤ºã—ãŸ- GPT-Jï¼ˆ6Bï¼‰ãŠã‚ˆã³GPT-NeoXï¼ˆ20Bï¼‰ã«å¯¾ã—ã¦æ•°åƒã®é–¢é€£ä»˜ã‘ã¾ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã§ãã€ã“ã‚Œã¾ã§ã®ç ”ç©¶ã‚’æ¡é•ã„ã«ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸ- ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã¯https://memit.baulab.infoã«ã‚ã‚Šã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/642" target="_blank" rel="noopener noreferrer" class="title-link">Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them, Mirac Suzgun+, N_A, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- BIG-Bench Hard (BBH) is a suite of 23 challenging tasks that current language models have not been able to surpass human performance on. This study focuses on applying chain-of-thought prompting to BBH tasks and found that PaLM and Codex were able to surpass human performance on 10 and 17 tasks, respectively. The study also found that CoT prompting is necessary for tasks that require multi-step reasoning and that CoT and model scale interact to enable new task performance on some BBH tasks.</span>
<span class="snippet"><span>Comment</span><p>å˜ãªã‚‹fewshotã§ã¯ãªãã€CoTä»˜ãã®fewshotã‚’ã™ã‚‹ã¨å¤§å¹…ã«BIG-Bench-hardã®æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã®ã§ã€CoTã‚’ä½¿ã‚ãªã„answer onlyã®è¨­å®šã¯ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã®éå°è©•ä¾¡ã«ã¤ãªãŒã‚‹ã‚ˆã€ã¨ã„ã†è©±ã‚‰ã—ã„<br><img src="https://github.com/user-attachments/assets/0545214a-a267-489d-8af9-82d21e08ff6c" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/e5308c66-0bee-4d2c-b973-86478842b772" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Poisoning.html" target="_blank" rel="noopener noreferrer">#Poisoning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/629" target="_blank" rel="noopener noreferrer" class="title-link">Poisoning Language Models During Instruction Tuning, Alexander Wan+, N_A, ICML'23</a>
<span class="snippet"><span>GPT Summary</span>- - Instruction-tuned LMsï¼ˆChatGPTã€FLANã€InstructGPTãªã©ï¼‰ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæå‡ºã—ãŸä¾‹ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§finetuneã•ã‚Œã‚‹ã€‚- æœ¬ç ”ç©¶ã§ã¯ã€æ•µå¯¾è€…ãŒæ¯’å…¥ã‚Šã®ä¾‹ã‚’æä¾›ã™ã‚‹ã“ã¨ã§ã€LMã®äºˆæ¸¬ã‚’æ“ä½œã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚- æ¯’å…¥ã‚Šã®ä¾‹ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã«ã€LMã®bag-of-wordsè¿‘ä¼¼ã‚’ä½¿ç”¨ã—ã¦å…¥å‡ºåŠ›ã‚’æœ€é©åŒ–ã™ã‚‹ã€‚- å¤§ããªLMã»ã©æ¯’å…¥ã‚Šæ”»æ’ƒã«å¯¾ã—ã¦è„†å¼±ã§ã‚ã‚Šã€ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚„ãƒ¢ãƒ‡ãƒ«å®¹é‡ã®å‰Šæ¸›ã«åŸºã¥ãé˜²å¾¡ã¯ã€ãƒ†ã‚¹ãƒˆã®æ­£ç¢ºæ€§ã‚’ä½ä¸‹ã•ã›ãªãŒã‚‰ã€ä¸­ç¨‹åº¦ã®ä¿è­·ã—ã‹æä¾›ã—ãªã„ã€‚</span>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Annotation.html" target="_blank" rel="noopener noreferrer">#Annotation</a>
<a class="button" href="articles/TransferLearning.html" target="_blank" rel="noopener noreferrer">#TransferLearning</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/615" target="_blank" rel="noopener noreferrer" class="title-link">Frustratingly Easy Label Projection for Cross-lingual Transfer, Yang Chen+, N_A, ACL'23</a>
<span class="snippet"><span>GPT Summary</span>- - å¤šè¨€èªã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ç¿»è¨³ã¯ã€ã‚¯ãƒ­ã‚¹ãƒªãƒ³ã‚¬ãƒ«è»¢ç§»ã®æ”¹å–„ã«å½¹ç«‹ã¤- ã‚¹ãƒ‘ãƒ³ãƒ¬ãƒ™ãƒ«æ³¨é‡ˆãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§ã¯ã€æ³¨é‡ˆä»˜ãã‚¹ãƒ‘ãƒ³ã‚’ç¿»è¨³ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã«ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹ãŸã‚ã«è¿½åŠ ã®ãƒ©ãƒ™ãƒ«ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒƒãƒ—ãŒå¿…è¦- ãƒãƒ¼ã‚¯-ç¿»è¨³æ³•ã‚’åˆ©ç”¨ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¾“æ¥ã®æ³¨é‡ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã¨æ¯”è¼ƒã—ã¦ã©ã®ã‚ˆã†ã«ãªã‚‹ã‹ã«ã¤ã„ã¦ã®å®Ÿè¨¼çš„ãªåˆ†æã‚’è¡Œã£ãŸ- EasyProjectã¨å‘¼ã°ã‚Œã‚‹ãƒãƒ¼ã‚¯-ç¿»è¨³æ³•ã®æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå¤šè¨€èªã«ç°¡å˜ã«é©ç”¨ã§ãã€ã‚ˆã‚Šè¤‡é›‘ãªå˜èªã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ã®æ–¹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸ- ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ãŒå…¬é–‹ã•ã‚Œã‚‹</span>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Inference.html" target="_blank" rel="noopener noreferrer">#Inference</a>
<span class="issue_date">Issue Date: 2023-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/601" target="_blank" rel="noopener noreferrer" class="title-link">Efficiently Scaling Transformer Inference, Reiner Pope+, N_A, MLSys'23</a>
<span class="snippet"><span>GPT Summary</span>- - å¤§è¦æ¨¡Transformerãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€æœ€é©ãªå¤šæ¬¡å…ƒåˆ†å‰²æŠ€è¡“ã‚’é¸æŠã™ã‚‹ãŸã‚ã®å˜ç´”ãªè§£æãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™º- ä½ãƒ¬ãƒ™ãƒ«ã®æœ€é©åŒ–ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€500B+ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«FLOPSåˆ©ç”¨ç‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ãŠã„ã¦ã€FasterTransformerãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚¤ãƒ¼ãƒˆã‚’ä¸Šå›ã‚‹æ–°ã—ã„Paretoãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã‚’å®Ÿç¾- é©åˆ‡ãªåˆ†å‰²ã«ã‚ˆã‚Šã€ãƒãƒ«ãƒã‚¯ã‚¨ãƒªã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®ä½ã„ãƒ¡ãƒ¢ãƒªè¦ä»¶ã«ã‚ˆã‚Šã€32å€ã®å¤§ããªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯èƒ½- int8ã‚¦ã‚§ã‚¤ãƒˆé‡å­åŒ–ã‚’ä½¿ç”¨ã—ãŸç”Ÿæˆä¸­ã®ä½ãƒãƒƒãƒã‚µã‚¤ã‚ºãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚ãŸã‚Š29msã§ã‚ã‚Šã€å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³ã®å¤§ãƒãƒƒãƒã‚µã‚¤ã‚ºå‡¦ç†ã«ãŠã„ã¦76ï¼…ã®MFUã‚’å®Ÿç¾ã—ã€PaLM 540Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦2048ãƒˆãƒ¼ã‚¯ãƒ³ã®é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç‰¹ã«Multiquery Attentionã¨ã„ã†æŠ€è¡“ãŒTransformerã®inferenceã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ã«æœ‰åŠ¹ã‚‰ã—ã„</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<span class="issue_date">Issue Date: 2023-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/594" target="_blank" rel="noopener noreferrer" class="title-link">Controlled Text Generation with Natural Language Instructions, Wangchunshu Zhou+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è‡ªç„¶è¨€èªã®èª¬æ˜ã¨åˆ¶ç´„ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«åŸºã¥ã„ã¦ã€ç•°ãªã‚‹åˆ¶ç´„ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã‚‹åˆ¶å¾¡ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹InstructCTGã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚åˆ¶ç´„ã‚’è‡ªç„¶è¨€èªã®æŒ‡ç¤ºã«è¨€ã„æ›ãˆã¦ã€å¼±ãç›£ç£ã•ã‚ŒãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’å½¢æˆã—ã€äº‹å‰ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã¦ã€ã•ã¾ã–ã¾ãªã‚¿ã‚¤ãƒ—ã®åˆ¶ç´„ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚InstructCTGã¯ã€ç•°ãªã‚‹åˆ¶ç´„ã‚¿ã‚¤ãƒ—ã«å¯¾ã—ã¦ã‚ˆã‚ŠæŸ”è»Ÿã§ã‚ã‚Šã€ç”Ÿæˆå“è³ªã¨é€Ÿåº¦ã«ã¯ã»ã¨ã‚“ã©å½±éŸ¿ã‚’ä¸ãˆãšã€å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã«æ–°ã—ã„åˆ¶ç´„ã«é©å¿œã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><img src="https://user-images.githubusercontent.com/12249301/235351783-1435816a-b51a-4379-b4b5-cf3097b70de5.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/TheoryOfMind.html" target="_blank" rel="noopener noreferrer">#TheoryOfMind</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/581" target="_blank" rel="noopener noreferrer" class="title-link">Boosting Theory-of-Mind Performance in Large Language Models via Prompting, Moghaddam+, Johns Hopkins University, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>LLMã¯Theory-of-mind reasoningã‚¿ã‚¹ã‚¯ãŒè‹¦æ‰‹ãªã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ãŠã‚Šã€ç‰¹ã«zero shotã§ã¯éå¸¸ã«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ã‹ã£ãŸã€‚ToMã‚¿ã‚¹ã‚¯ã¨ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä¿¡å¿µã€ã‚´ãƒ¼ãƒ«ã€ãƒ¡ãƒ³ã‚¿ãƒ«stateã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒä½•ã‚’çŸ¥ã£ã¦ã„ã‚‹ã‹ç­‰ã‚’ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã™ã‚‹ã“ã¨ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã‚¿ã‚¹ã‚¯ã®ã“ã¨ã€‚ã“ã®ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã¯LLMãŒæˆ‘ã€…ã®æ—¥å¸¸ç”Ÿæ´»ã‚’ç†è§£ã™ã‚‹ä¸Šã§é‡è¦ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/235207785-8a4c5e0d-4825-4947-8ae6-a8176ad7c898.png" alt="image" loading="lazy"><br><br>â†‘ã®ToM Questionã®ã‚·ãƒŠãƒªã‚ªã¨å•é¡Œ<br>Scenario: "The morning of the high school dance Sarah placed her high heel shoes under her dress and then went shopping. That afternoon, her sister borrowed the shoes and later put them under Sarah's bed."<br>Question: When Sarah gets ready, does she assume her shoes are under her dress?<br><br>ã—ã‹ã—ã€Zero shot CoTã®ã‚ˆã†ãªstep by step thinking, CoTã‚’é©åˆ‡ã«è¡Œã†ã“ã¨ã§ã€OpenAIã®ç›´è¿‘3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®AccuracyãŒ80%ã‚’è¶…ãˆãŸã€‚ç‰¹ã«ã€GPT4ã¯100ï¼…ã®Accuracyã‚’é”æˆã€‚äººé–“ã¯87ï¼…ã ã£ãŸã€‚<br><br>ã“ã®çµæœã¯ã€å°‘ãªãã¨ã®ã“ã®è«–æ–‡ã§ãƒ†ã‚¹ãƒˆã—ãŸãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã¯LLMã®social reasoningã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ã©ã®ã‚ˆã†ã«ãƒ–ãƒ¼ã‚¹ãƒˆã™ã‚‹ã‹ã‚’ç¤ºã—ã¦ãŠã‚Šã€LLMã®behaviorã¯è¤‡é›‘ã§sensitiveã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/580" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models are Versatile Decomposers: Decompose Evidence and Questions for Table-based Reasoning, Ye+, University of Science and Technology of China, SIGIR'23</a>
<span class="snippet"><span>Comment</span><p>ãƒ†ãƒ¼ãƒ–ãƒ«ã¨questionãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€questionã‚’sub-questionã¨small tableã«LLMã§in-context learningã™ã‚‹ã“ã¨ã§åˆ†å‰²ã€‚subquestionã®è§£ã‚’å¾—ã‚‹ãŸã‚ã®sqlã‚’ä½œæˆã—ã‚¹ãƒãƒƒãƒˆã‚’åŸ‹ã‚ã€hallucinationã‚’é˜²ãã€‚æœ€çµ‚çš„ã«LLM ReasonerãŒè§£ç­”ã‚’å°å‡ºã™ã‚‹ã€‚TabFact Reasoningã§åˆã‚ã¦äººé–“ã‚’è¶…ãˆãŸæ€§èƒ½ã‚’ç™ºæ®ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/235204690-75f6b56b-3291-42e4-9e39-710694f36648.jpeg" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/DialogueGeneration.html" target="_blank" rel="noopener noreferrer">#DialogueGeneration</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/575" target="_blank" rel="noopener noreferrer" class="title-link">q2d: Turning Questions into Dialogs to Teach Models How to Search, Bitton+, The Hebrew University of Jerusalem ï¼ˆw_ Google Researchï¼‰, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>LLMã«questionã‚’ä¸ãˆã€questionã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®information seekingã®å¯¾è©±ãƒ­ã‚°ã‚’ç”Ÿæˆã•ã›ã‚‹ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€dialogueã‹ã‚‰questionã‚’ç”Ÿæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€æ¤œç´¢APIãªã©ã«æ¸¡ã›ã‚‹ã‚ˆã†ã«ã—ãŸç ”ç©¶ã€‚å…¨ãå¯¾è©±ã®ãƒ­ã‚°ãŒãªã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã‚‚ã€äººé–“ã¨éœè‰²ãªã„é«˜å“è³ªãªå¯¾è©±ãŒç”Ÿæˆå¯èƒ½ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€query generationãƒ¢ãƒ‡ãƒ«ã®æ›´ãªã‚‹é«˜æ€§èƒ½åŒ–ãŒå®Ÿç¾ã§ãã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/235137446-10e6633f-1d4b-46ea-afda-630b7cd53246.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/573" target="_blank" rel="noopener noreferrer" class="title-link">Tractable Control for Autoregressive Language Generation, Zhang+, UCLA, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>è‡ªç„¶è¨€èªç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã€ä½•ã‚‰ã‹ã®ã‚·ãƒ³ãƒ—ãƒ«ãªconstiaint Î±ã®å…ƒp(xi|xi-1,Î±)ã‚’ç”Ÿæˆã—ã‚ˆã†ã¨ã—ã¦ã‚‚è¨ˆç®—ãŒã§ããªã„ã€‚ã“ã®ãŸã‚ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’finetuningã™ã‚‹ã‹ã€promptã§åˆ¶å¾¡ã™ã‚‹ã‹ã€ãªã©ãŒãŠã“ãªã‚ã‚Œã‚‹ã€‚ã—ã‹ã—ã“ã®æ–¹æ³•ã¯è¿‘ä¼¼çš„ãªè§£æ³•ã§ã‚ã‚Šã€Î±ãŒãŸã¨ãˆã‚·ãƒ³ãƒ—ãƒ«ã§ã‚ã£ã¦ã‚‚ï¼ˆä½•ã‚‰ã‹ã®èªå°¾ã‚’ä»˜ä¸ã™ã‚‹ãªã©ï¼‰ã€å¿…ãšã—ã‚‚æº€ãŸã—ãŸç”ŸæˆãŒè¡Œã‚ã‚Œã‚‹ã¨ã¯é™ã‚‰ãªã„ã€‚ã“ã‚Œã¯å˜ã«è¨€èªãƒ¢ãƒ‡ãƒ«ãŒautoregressiveãªæ–¹æ³•ã§æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®åˆ†å¸ƒã‚’äºˆæ¸¬ã—ã¦ã„ã‚‹ã ã‘ã§ã‚ã‚‹ã“ã¨ã«èµ·å› ã—ã¦ã„ã‚‹ã€‚ãã“ã§ã€ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€tractable probabilistic modelï¼ˆTPMï¼‰ã‚’å°å…¥ã—ã€è§£æ±ºã—ãŸã€‚<br>è©•ä¾¡ã®çµæœã€CommonGenã«ãŠã„ã¦ã€SoTAã‚’é”æˆã—ãŸã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/235130061-21e51e59-dbfa-4c64-bd7b-27f0de2618c0.jpeg" alt="image" loading="lazy"></p>
<p>å°šã€TPMã«ã¤ã„ã¦ã¯è¦å‹‰å¼·ã§ã‚ã‚‹</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="articles/AES(AutomatedEssayScoring).html" target="_blank" rel="noopener noreferrer">#AES(AutomatedEssayScoring)</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/571" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AI, write an essay for me: A large-scale comparison of human-written  versus ChatGPT-generated essays, Steffen Herbold+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ChatGPTãŒç”Ÿæˆã—ãŸã‚¨ãƒƒã‚»ã‚¤ã¯ã€äººé–“ãŒæ›¸ã„ãŸã‚‚ã®ã‚ˆã‚Šã‚‚è³ªãŒé«˜ã„ã¨è©•ä¾¡ã•ã‚Œã‚‹ã“ã¨ãŒå¤§è¦æ¨¡ãªç ”ç©¶ã§ç¤ºã•ã‚ŒãŸã€‚ç”Ÿæˆã•ã‚ŒãŸã‚¨ãƒƒã‚»ã‚¤ã¯ç‹¬è‡ªã®è¨€èªçš„ç‰¹å¾´ã‚’æŒã¡ã€æ•™è‚²è€…ã¯ã“ã®æŠ€è¡“ã‚’æ´»ç”¨ã™ã‚‹æ–°ãŸãªæ•™è‚²ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’é–‹ç™ºã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ChatGPTã¯äººé–“ãŒæ›¸ã„ãŸã‚¨ãƒƒã‚»ã‚¤ã‚ˆã‚Šã‚‚é«˜å“è³ªãªã‚¨ãƒƒã‚»ã‚¤ãŒæ›¸ã‘ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br>ã¾ãŸã€AIãƒ¢ãƒ‡ãƒ«ã®æ–‡ä½“ã¯ã€äººé–“ãŒæ›¸ã„ãŸã‚¨ãƒƒã‚»ã‚¤ã¨ã¯ç•°ãªã‚‹è¨€èªçš„ç‰¹å¾´ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ãŸã¨ãˆã°ã€è«‡è©±ã‚„èªè­˜ãƒãƒ¼ã‚«ãƒ¼ãŒå°‘ãªã„ãŒã€åè©åŒ–ãŒå¤šãã€èªå½™ã®å¤šæ§˜æ€§ãŒé«˜ã„ã¨ã„ã†ç‰¹å¾´ãŒã‚ã‚‹ã€ã¨ã®ã“ã¨ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/235142851-756a418f-3c5a-4ae6-9309-0f077b1d017b.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/569" target="_blank" rel="noopener noreferrer" class="title-link">Exploring the Curious Case of Code Prompts, Zhang+, University of Pennsylvania, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®LLMã«å¯¾ã—ã¦ã€reasoningã‚¿ã‚¹ã‚¯ã‚’è§£ã‹ã›ã‚‹éš›ã«ã¯ã€promptã‚‚ã‚³ãƒ¼ãƒ‰ã«ã™ã‚‹ã¨10ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆç¨‹åº¦æ€§èƒ½ä¸ŠãŒã‚‹å ´åˆãŒã‚ã‚‹ã‚ˆã€ã¨ã„ã†ç ”ç©¶ã€‚<br><img src="https://user-images.githubusercontent.com/12249301/235037840-1fb57af3-5296-4831-9f80-26886c913431.jpeg" alt="image" loading="lazy"></p>
<p>ãŸã ã—ã€å¹³å‡çš„ã«ã¯ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ–¹ãŒè‰¯ãã€ä¸€éƒ¨ã‚¿ã‚¹ã‚¯ã§æ€§èƒ½ãŒæ”¹å–„ã™ã‚‹ã€ã¨ã„ã†æ¸©åº¦æ„Ÿãªæ¨¡æ§˜<br><img src="https://user-images.githubusercontent.com/12249301/235038209-b43dcdcb-301e-4879-a99e-8c8df32e6cf5.jpeg" alt="image" loading="lazy"></p>
<p>ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã‚’textã§instruction tuningã—ã¦ã„ã‚‹å ´åˆã§ã‚‚ã€åŠ¹æœãŒã‚ã‚‹ã‚¿ã‚¹ã‚¯ãŒã‚ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/568" target="_blank" rel="noopener noreferrer" class="title-link">Answering Questions by Meta-Reasoning over Multiple Chains of Thought, Yoran+, Tel Aviv University ï¼ˆw_ Allen Institute for AIï¼‰, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>self-consistency <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/558" target="_blank" rel="noopener noreferrer">Self-consistency improves chain of thought reasoning in language models, Wang+, Google Research, ICLR'23</a>
 ã®ã‚ˆã†ãªvoting basedãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€è¤‡æ•°ã®CoTã®intermediate stepã‚’æ¨ã¦ã¦ã—ã¾ã„ã€çµæœã ã‘ã‚’æ¡ç”¨ã™ã‚‹ãŒã€ã“ã®ç ”ç©¶ã¯è¤‡æ•°ã®CoTã®ä¸­ã‹ã‚‰questionã«å›ç­”ã™ã‚‹ãŸã‚ã«é©åˆ‡ãªfactual informationã‚’æŠ½å‡ºã™ã‚‹Meta Reasonerã‚’å°å…¥ã—ã€è¤‡æ•°ã®CoTã®æƒ…å ±ã‚’é©åˆ‡ã«æ··åœ¨ã•ã›ã¦é©åˆ‡ãªå›ç­”ã‚’å¾—ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã—ãŸã€‚<br><br><br><br>7å€‹ã®Multi Hop QAãƒ‡ãƒ¼ã‚¿ã§strong baselineã‚’outperformã—ã€äººé–“ãŒå›ç­”ã‚’verificationã™ã‚‹ãŸã‚ã®é«˜å“è³ªãªèª¬æ˜ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/235135436-11dca529-771a-402b-a4ef-9b6deacec32e.jpeg" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/564" target="_blank" rel="noopener noreferrer" class="title-link">Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes, Arora+, Stanford University, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>LLMã‚’ä½¿ã†ã“ã¨ã§ã€åŠæ§‹é€ åŒ–æ–‡ç« ã‹ã‚‰è‡ªå‹•çš„ã«queryableãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã™ã‚‹ã“ã¨ã‚’è©¦ã¿ãŸç ”ç©¶<br><br><img src="https://user-images.githubusercontent.com/12249301/235146591-dc608755-e719-4418-ace9-29401919d4eb.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/558" target="_blank" rel="noopener noreferrer" class="title-link">Self-consistency improves chain of thought reasoning in language models, Wang+, Google Research, ICLR'23</a>
<span class="snippet"><span>Comment</span><p>self-consistencyã¨å‘¼ã°ã‚Œã‚‹æ–°ãŸãªCoTã®ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã€‚<br><br>ã“ã‚Œã¯ã€é›£ã—ã„reasoningãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§ã¯ã€è¤‡æ•°ã®reasoningã®ãƒ‘ã‚¹ãŒå­˜åœ¨ã™ã‚‹ã¨ã„ã†intuitionã«åŸºã¥ã„ã¦ã„ã‚‹ã€‚<br><br><br><br>self-consistencyã§ã¯ã¾ãšã€æ™®é€šã«CoTã‚’è¡Œã†ã€‚ãã—ã¦greedyã«decodingã™ã‚‹ä»£ã‚ã‚Šã«ã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿæ–½ã™ã‚‹ï¼š<br><br>1. å¤šæ§˜ãªreasoning pathã‚’LLMã«ç”Ÿæˆã•ã›ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã€‚<br><br>2. ç•°ãªã‚‹reasoning pathã¯ç•°ãªã‚‹final answerã‚’ç”Ÿæˆã™ã‚‹ï¼ˆ= final answer setï¼‰ã€‚<br><br>3. ãã—ã¦ã€æœ€çµ‚çš„ãªanswerã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«ã€reasoning pathã‚’marginalizeã™ã‚‹ã“ã¨ã§ã€final answerã®setã®ä¸­ã§æœ€ã‚‚ä¸€è²«æ€§ã®ã‚ã‚‹å›ç­”ã‚’è¦‹å‡ºã™ã€‚<br><br><br><br>ã“ã‚Œã¯ã€ã‚‚ã—ç•°ãªã‚‹è€ƒãˆæ–¹ã«ã‚ˆã£ã¦åŒã˜å›ç­”ãŒå°ãå‡ºã•ã‚Œã‚‹ã®ã§ã‚ã‚Œã°ã€ãã®æœ€çµ‚çš„ãªå›ç­”ã¯æ­£ã—ã„ã¨ã„ã†çµŒé¨“å‰‡ã«åŸºã¥ã„ã¦ã„ã‚‹ã€‚<br><br>self-consistencyã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã¯ã€è¤‡æ•°ã®reasoning pathã‚’å–å¾—ã—ãŸä¸Šã§ã€æœ€ã‚‚å¤šã„answer a_iã‚’é¸æŠã™ã‚‹ï¼ˆmajority voteï¼‰ã€‚ã“ã‚Œã«ã¯temperature samplingã‚’ç”¨ã„ã‚‹ï¼ˆtemperatureã‚’0.5ã‚„ã‚‰0.7ã«è¨­å®šã—ã¦ã€ã‚ˆã‚Šé«˜ã„ä¿¡é ¼æ€§ã‚’ä¿ã¡ã¤ã¤ã€ã‹ã¤å¤šæ§˜ãªoutputã‚’æ‰‹ã«å…¥ã‚Œã‚‹ï¼‰ã€‚<br><br>temperature samplingã«ã¤ã„ã¦ã¯[ã“ã¡ã‚‰](


<a href="https://openreview.net/pdf?id=rygGQyrFvH)%E3%81%AE%E8%AB%96%E6%96%87%E3%82%92%E5%8F%82%E7%85%A7%E3%81%AE%E3%81%93%E3%81%A8%E3%80%82" target="_blank" rel="noopener noreferrer">https://openreview.net/pdf?id=rygGQyrFvH)ã®è«–æ–‡ã‚’å‚ç…§ã®ã“ã¨ã€‚</a>


<br><br>samplingæ•°ã¯å¢—ã‚„ã›ã°å¢—ã‚„ã™ã»ã©æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ãŒã€å¾ã€…ã«ã‚µãƒã£ã¦ãã‚‹ã€‚ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°ã‚’å¢—ã‚„ã™ã»ã©ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã®ã§ã€ãã®è¾ºã¯ã‚³ã‚¹ãƒˆæ„Ÿã¨ã®å…¼ã­åˆã„ã«ãªã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/234754605-6316223f-4290-45d5-bf7c-64675f07d0c3.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/234779335-478f2431-67ea-4b24-9c1b-fa1dd6ac6b45.png" alt="image" loading="lazy"><br><br></p>
<p>Self-consistencyã¯å›ç­”ãŒé–‰ã˜ãŸé›†åˆã§ã‚ã‚‹ã‚ˆã†ãªå•é¡Œã«å¯¾ã—ã¦é©ç”¨å¯èƒ½ã§ã‚ã‚Šã€open-endãªquestionã§ã¯åˆ©ç”¨ã§ããªã„ã“ã¨ã«æ³¨æ„ãŒå¿…è¦ã€‚ãŸã ã—ã€open-endã§ã‚‚å›ç­”é–“ã«ãªã‚“ã‚‰ã‹ã®é–¢ä¿‚æ€§ã‚’è¦‹å‡ºã™ã‚ˆã†ãªæŒ‡æ¨™ãŒã‚ã‚Œã°å®Ÿç¾å¯èƒ½ã¨limitationã§è¨€åŠã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/556" target="_blank" rel="noopener noreferrer" class="title-link">Automatic Chain of Thought Prompting in Large Language Models, Zhang+, Shanghai Jiao Tong University, ICLR'23</a>
<span class="snippet"><span>Comment</span><p>LLMã«ã‚ˆã‚‹reasoning chainãŒäººé–“ãŒä½œæˆã—ãŸã‚‚ã®ã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/532" target="_blank" rel="noopener noreferrer">[Paper Note] Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in  Large Language Models, Jiashuo Sun+, NAACL'24 Findings, 2023.04</a>
 ã‚ˆã‚Š</p>
<p>clusteringãƒ™ãƒ¼ã‚¹ãªæ‰‹æ³•ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€èª¤ã‚Šã‚’å«ã‚€ä¾‹ãŒå˜ä¸€ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«ã¾ã¨ã‚ã‚‰ã‚Œã†ã“ã¨ã‚’ç¤ºã—ã€ã“ã‚Œã«ã‚ˆã‚Šéå‰°ãªèª¤ã£ãŸãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒè»½æ¸›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</p>
<p>æ‰‹æ³•ã®æ¦‚è¦ã€‚questionã‚’è¤‡æ•°ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«åˆ†å‰²ã—ã€å„ã‚¯ãƒ©ã‚¹ã‚¿ã‹ã‚‰ä»£è¡¨çš„ãªquestionã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€zero-shot CoTã§reasoning chainã‚’ä½œæˆã—promptã«çµ„ã¿è¾¼ã‚€ã€‚æœ€çµ‚çš„ã«å›ç­”ã‚’å¾—ãŸã„questionã«å¯¾ã—ã¦ã‚‚ã€ä¸Šè¨˜ã§ç”Ÿæˆã—ãŸè¤‡æ•°ã®question-reasoningã§æ¡ä»¶ä»˜ã‘ã—ãŸä¸Šã§ã€zeroshot-CoTã§rationaleã‚’ç”Ÿæˆã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/35213747-9b5f-4d38-a525-1deafe86cd0c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/555" target="_blank" rel="noopener noreferrer" class="title-link">Automatic prompt augmentation and selection with chain-of-thought from labeled data, Shum+, The Hong Kong University of Science and Technology, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>LLMã«ã‚ˆã‚‹reasoning chainãŒäººé–“ãŒä½œæˆã—ãŸã‚‚ã®ã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/532" target="_blank" rel="noopener noreferrer">[Paper Note] Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in  Large Language Models, Jiashuo Sun+, NAACL'24 Findings, 2023.04</a>
 ã‚ˆã‚Š</p>
<p>selection phaseã§èª¤ã£ãŸexampleã¯ç›´æ¥æ’é™¤ã™ã‚‹æ‰‹æ³•ã‚’ã¨ã£ã¦ã„ã‚‹ã€‚ãã—ã¦ã€å¼·åŒ–å­¦ç¿’ã«ã‚ˆã£ã¦ã€demonstrationã®selection modelã‚’è¨“ç·´ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2023-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/539" target="_blank" rel="noopener noreferrer" class="title-link">Personalisation within bounds: A risk taxonomy and policy framework for the alignment of large language models with personalised feedback, Kirk+, Oxford Internet Institute, University of Oxford, arXiv'23</a>
<span class="snippet"><span>Comment</span><p># abst<br><br>LLMã‚’Personalizationã™ã‚‹ã“ã¨ã«é–¢ã—ã¦ã€ã©ã®ã‚ˆã†ãªæ–¹æ³•ã§Personalizationã™ã¹ãã‹ã‚’æ¤œè¨ã—ãŸç ”ç©¶ã€‚ä»¥ä¸‹ã®å•é¡Œç‚¹ã‚’æŒ‡æ‘˜ã€‚<br><br>1. ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆï¼ˆRLHFã®ã‚ˆã†ã«ä½•ã‚‰ã‹ã®æ–¹å‘æ€§ã«alignã™ã‚‹ã‚ˆã†ã«è£œæ­£ã™ã‚‹æŠ€è¡“ã®ã“ã¨ï¼Ÿï¼‰ãŒä½•ã‚’æ„å‘³ã™ã‚‹ã®ã‹æ˜ç¢ºã§ã¯ãªã„<br><br>2. æŠ€è¡“æä¾›è€…ãŒæœ¬è³ªçš„ã«ä¸»è¦³çš„ãªå¥½ã¿ã‚„ä¾¡å€¤è¦³ã®å®šç¾©ã‚’è¦å®šã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨<br><br>3. ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã®å°‚åˆ¶ã«ã‚ˆã£ã¦ã€æˆ‘ã€…ãŒå®Ÿéš›ã«ä½•ã«ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã—ã¦ã„ã‚‹ã®ã‹ã«é–¢ã™ã‚‹æ–‡æ›¸ãŒä¸è¶³ã—ã¦ã„ã‚‹ã“ã¨<br><br><br><br>ãã—ã¦ã€PersonalizedãªLLMã®åˆ©ç‚¹ã‚„ãƒªã‚¹ã‚¯ã®åˆ†é¡ã‚’æç¤ºã™ã‚‹ã€‚<br><br><br><br># å°å…¥<br><br>LLMãŒã•ã¾ã–ã¾ãªè£½å“ã«çµ±åˆã•ã‚ŒãŸã“ã¨ã§ã€äººé–“ã®å—œå¥½ã«åˆè‡´ã—ã€å±é™ºã‹ã¤ä¸æ­£ç¢ºãªæƒ…å ±ã‚’å‡ºåŠ›ã‚’ç”Ÿæˆã—ãªã„ã“ã¨ã‚’ç¢ºä¿ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚RLHFã‚„red-teamingã¯ã“ã‚Œã«å½¹ç«‹ã¤ãŒã€ã“ã®ã‚ˆã†ãªé›†åˆçš„ãªï¼ˆå¤šãã®äººã«ä¸€ã¤ã®ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã®çµæœã‚’æç¤ºã™ã‚‹ã“ã¨ï¼‰finetuningãƒ—ãƒ­ã‚»ã‚¹ãŒäººé–“ã®å¥½ã¿ã‚„ä¾¡å€¤è¦³ã®å¹…åºƒã„ç¯„å›²ã‚’ååˆ†ã«è¡¨ç¾ã§ãã‚‹ã¨ã¯è€ƒãˆã«ãã„ã€‚ç•°ãªã‚‹äººã€…ã¯ã•ã¾ã–ã¾ãªæ„è¦‹ã‚„ä¾¡å€¤è¦³ã‚’æŒã£ã¦ãŠã‚Šã€ãƒã‚¤ã‚¯ãƒ­ãƒ¬ãƒ™ãƒ«ã®finetuningãƒ—ãƒ­ã›ã›é›¨ã‚’é€šã˜ã¦LLMã‚’Personalizationã™ã‚‹ã“ã¨ã§ã€å„ãƒ¦ãƒ¼ã‚¶ã¨ã‚ˆã‚Šè‰¯ã„ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆãŒå¯èƒ½ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ã“ã‚Œã‚’ç¤¾ä¼šçš„ã«å—ã‘å…¥ã‚Œã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã«ã„ãã¤ã‹èª²é¡ŒãŒã‚ã‚‹ã®ã§ã€ãã‚Œã«ã¤ã„ã¦è«–ã˜ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Assessment.html" target="_blank" rel="noopener noreferrer">#Assessment</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="articles/InformationExtraction.html" target="_blank" rel="noopener noreferrer">#InformationExtraction</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/534" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Evaluating ChatGPT's Information Extraction Capabilities: An Assessment  of Performance, Explainability, Calibration, and Faithfulness, Bo Li+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ChatGPTã®èƒ½åŠ›ã‚’7ã¤ã®æƒ…å ±æŠ½å‡ºï¼ˆIEï¼‰ã‚¿ã‚¹ã‚¯ã‚’é€šã˜ã¦è©•ä¾¡ã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€èª¬æ˜å¯èƒ½æ€§ã€ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ä¿¡é ¼æ€§ã‚’åˆ†æã—ã¾ã—ãŸã€‚æ¨™æº–IEè¨­å®šã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ã„ä¸€æ–¹ã€ã‚ªãƒ¼ãƒ—ãƒ³IEè¨­å®šã§ã¯äººé–“è©•ä¾¡ã§å„ªã‚ŒãŸçµæœã‚’ç¤ºã—ã¾ã—ãŸã€‚ChatGPTã¯é«˜å“è³ªãªèª¬æ˜ã‚’æä¾›ã™ã‚‹ã‚‚ã®ã®ã€äºˆæ¸¬ã«å¯¾ã—ã¦éä¿¡ã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã€ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒä½ã„ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—ãŸã€‚ã¾ãŸã€å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã—ã¦é«˜ã„ä¿¡é ¼æ€§ã‚’ç¤ºã—ã¾ã—ãŸã€‚ç ”ç©¶ã®ãŸã‚ã«æ‰‹å‹•ã§æ³¨é‡ˆä»˜ã‘ã—ãŸ7ã¤ã®IEã‚¿ã‚¹ã‚¯ã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã¨14ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æƒ…å ±æŠ½å‡ºã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ChatGPTã‚’è©•ä¾¡ã—ãŸç ”ç©¶ã€‚ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ãªIEã®è¨­å®šã§ã¯BERTãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã«è² ã‘ã‚‹ãŒã€OpenIEã®å ´åˆã¯é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚<br>ã¾ãŸã€ChatGPTã¯äºˆæ¸¬ã«å¯¾ã—ã¦ã‚¯ã‚ªãƒªãƒ†ã‚£ãŒé«˜ãä¿¡é ¼ã«è¶³ã‚‹èª¬æ˜ã‚’ã—ãŸãŒã€ä¸€æ–¹ã§è‡ªä¿¡éå‰°ãªå‚¾å‘ãŒã‚ã‚‹ã€‚ã¾ãŸã€ChatGPTã®äºˆæ¸¬ã¯input textã«å¯¾ã—ã¦é«˜ã„faithfulnessã‚’ç¤ºã—ã¦ãŠã‚Šã€äºˆæ¸¬ãŒinputã‹ã‚‰æ ¹ã–ã—ã¦ã„ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚ï¼ˆã‚‰ã—ã„ï¼‰</p>
<p>ã‚ã¾ã‚Šã—ã£ã‹ã‚Šèª­ã‚“ã§ã„ãªã„ãŒã€Entity Typing, NER, Relation Classification, Relation Extraction, Event Detection, Event Argument Extraction, Event Extractionã§è©•ä¾¡ã€‚standardIEã§ã¯ã€ChatGPTã«ã‚¿ã‚¹ã‚¯ã®èª¬æ˜ã¨é¸æŠè‚¢ã‚’ä¸ãˆã€ä¸ãˆã‚‰ã‚ŒãŸé¸æŠè‚¢ã®ä¸­ã‹ã‚‰æ­£è§£ã‚’æ¢ã™è¨­å®šã¨ã—ãŸã€‚ä¸€æ–¹OpenIEã§ã¯ã€é¸æŠè‚¢ã‚’ä¸ãˆãšã€ç´”ç²‹ã«ã‚¿ã‚¹ã‚¯ã®èª¬æ˜ã®ã¿ã§äºˆæ¸¬ã‚’å®Ÿæ–½ã•ã›ãŸã€‚OpenIEã®çµæœã‚’ã€3åã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãŒå‡ºåŠ›ãŒå¦¥å½“ã‹å¦ã‹åˆ¤å®šã—ãŸçµæœã€éå¸¸ã«é«˜ã„æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ãŒã‚ã‹ã£ãŸã€‚è¡¨ã‚’è¦‹ã‚‹ã¨ã€åŒã˜ã‚¿ã‚¹ã‚¯ã§ã‚‚standardIEã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ï¼ˆãã‚“ãªã“ã¨ã‚ã‚‹ï¼Ÿï¼Ÿï¼Ÿï¼‰</p>
<p>ã¤ã¾ã‚Šã€é¸æŠè‚¢ã‚’ä¸ãˆã¦ã©ã‚ŒãŒæ­£è§£ã§ã™ã‹?ã¨ããã‚ˆã‚Šã€é¸æŠè‚¢ä¸ãˆãªã„ã§CoTã•ã›ãŸæ–¹ãŒæ€§èƒ½é«˜ã„ã£ã¦ã“ã¨ï¼Ÿæ¯”è¼ƒå¯èƒ½ãªè¨­å®šã§å®Ÿé¨“ã§ãã¦ã„ã‚‹ã®ã ã‚ã†ã‹ã€‚promptã¯ä»˜éŒ²ã«è¼‰ã£ã¦ã„ã‚‹ãŒã€output exampleãŒè¼‰ã£ã¦ãªã„ã®ã§ãªã‚“ã¨ã‚‚ã„ãˆãªã„ã€‚StandardIEã®è¨­å®šã‚’ã—ãŸã¨ãã«ã€CoTã•ã›ã¦ã‚‹ã‹ã©ã†ã‹ãŒæ°—ã«ãªã‚‹ã€‚ã‚‚ã—ã—ã¦ãªã„ãªã‚‰ã€ãã‚Šã‚ƒæ€§èƒ½ä½ã„ã ã‚ã†ã­ã€ã¨ã„ã†æ°—ãŒã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/529" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Transformer to 1M tokens and beyond with RMT, Bulatov+, DeepPavlov, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>Reccurent Memory Transformer <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/523" target="_blank" rel="noopener noreferrer">Recurrent Memory Transformer, Bulatov+, NeurIPS'22</a>
 ã‚’ä½¿ã£ã¦2Mãƒˆãƒ¼ã‚¯ãƒ³æ‰±ãˆã‚‹ã‚ˆã†ã«ã—ãŸã‚ˆãƒ¼ã¨ã„ã†è©±ã€‚<br><br>ãƒãƒªãƒ¼ãƒãƒƒã‚¿ãƒ¼ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒ1.5Mã‚‰ã—ã„ã®ã§ã€ãã®ã†ã¡å°èª¬ä¸€å†Šæ›¸ã‘ã‚‹ã‹ã‚‚ã¨ã„ã†ä¸–ç•Œã€‚</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Planning.html" target="_blank" rel="noopener noreferrer">#Planning</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/526" target="_blank" rel="noopener noreferrer" class="title-link">LLM+P: Empowering Large Language Models with Optimal Planning Proficiency, Liu+, University of Texas at Austin, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>LLMã¯é•·ã„ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚’ã™ã‚‹ã“ã¨ãŒè‹¦æ‰‹ã ã£ãŸãŒã€classicalãªplannerã¯é©åˆ‡ãªinputã®å½¢å¼ã«å¤‰æ›ã•ã‚Œã¦ã„ã‚Œã°ã™ãã«æœ€é©ãªãƒ—ãƒ©ãƒ³ã‚’å°å‡ºã§ãã‚‹ã€ãŒã€è‡ªç„¶è¨€èªã¯å—ã‘ä»˜ã‘ãªã„ã€ã¨ã„ã£ãŸäº’ã„ãŒäº’ã„ã‚’è£œå®Œã—åˆã†é–¢ä¿‚ã«ã‚ã‚‹ã®ã§ã€ä¸¡è€…ã‚’çµ„ã¿åˆã‚ã›ã¾ã—ãŸã€ã¨ã„ã†è©±ã€‚<br>LLMã‚’åˆ©ç”¨ã—ã¦ã€planning problemã‚’è¨˜è¿°ã—ãŸè‡ªç„¶è¨€èªã‚’classicalãªplannerã®inputã¸å¤‰æ›ã€‚ãã®å¾Œplannerã§æœ€é©ãªplanã‚’è¦‹ã¤ã‘ã€è‡ªç„¶è¨€èªã«planã‚’é€†ç¿»è¨³ã™ã‚‹ã€‚<br><img src="https://user-images.githubusercontent.com/12249301/234289649-416a8d9e-628e-422c-bd9b-89d9099b4b1d.jpeg" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/TACL.html" target="_blank" rel="noopener noreferrer">#TACL</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/525" target="_blank" rel="noopener noreferrer" class="title-link">Efficient Methods for Natural Language Processing: A Survey, Treviso+, TACL'23</a>
<span class="snippet"><span>GPT Summary</span>- NLPã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã«ã¯ã‚¹ã‚±ãƒ¼ãƒ«ã®æ‹¡å¤§ãŒé‡è¦ã ãŒã€ãƒªã‚½ãƒ¼ã‚¹æ¶ˆè²»ã‚‚å¢—åŠ ã™ã‚‹ã€‚é™ã‚‰ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã§åŠ¹ç‡çš„ã«NLPã‚’å®Ÿæ–½ã™ã‚‹æ–¹æ³•ã‚’çµ±åˆã—ã€æŒ‡é‡ã‚’æä¾›ã€‚åŠ¹ç‡çš„ãªæ‰‹æ³•ã®é–‹ç™ºã«å‘ã‘ãŸç ”ç©¶æ–¹å‘ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§ã‚´ãƒªæŠ¼ã™ã‚ˆã†ãªæ–¹æ³•ã§ã¯ãªãã€"Efficient"ã«è¡Œã†ãŸã‚ã®æ‰‹æ³•ã‚’ã¾ã¨ã‚ã¦ã„ã‚‹<br><br><img src="https://user-images.githubusercontent.com/12249301/234287218-2d42766f-5c5c-4cf9-859e-c2b0a5dfd4c3.jpeg" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-04-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/518" target="_blank" rel="noopener noreferrer" class="title-link">REACT : SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS, Yao+, Princeton University and Google brain, ICLR'23</a>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>äººé–“ã¯æ¨è«–ã¨è¡Œå‹•ã‚’ã‚·ãƒŠã‚¸ãƒ¼ã•ã›ã‚‹ã“ã¨ã§ã€ã•ã¾ã–ã¾ãªæ„æ€æ±ºå®šã‚’è¡Œãˆã‚‹ã€‚è¿‘å¹´ã§ã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚Šè¨€èªã«ã‚ˆã‚‹æ¨è«–ã‚’æ„æ€æ±ºå®šã«çµ„ã¿åˆã‚ã›ã‚‹å¯èƒ½æ€§ãŒç¤ºã•ã‚Œã¦ããŸã€‚ãŸã¨ãˆã°ã€ã‚¿ã‚¹ã‚¯ã‚’ã“ãªã™ãŸã‚ã®æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’LLMãŒå°ã‘ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ããŸï¼ˆChain-of-Thoughtï¼‰ãŒã€CoTã¯å¤–éƒ¨ãƒªã‚½ãƒ¼ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„ãŸã‚çŸ¥è­˜ãŒã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§ããšã€äº‹å¾Œçš„ã«æ¨è«–ã‚’è¡Œã†ãŸã‚hallucinationã‚„ã‚¨ãƒ©ãƒ¼ã®ä¼æ¬ãŒç”Ÿã˜ã‚‹ã€‚ä¸€æ–¹ã§ã€äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’interactiveãªç’°å¢ƒã«ãŠã„ã¦è¨ˆç”»ã¨è¡Œå‹•ã«åˆ©ç”¨ã™ã‚‹ç ”ç©¶ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ãŒã€ã“ã‚Œã‚‰ã®ç ”ç©¶ã§ã¯ã€é«˜ãƒ¬ãƒ™ãƒ«ã®ç›®æ¨™ã«ã¤ã„ã¦æŠ½è±¡çš„ã«æ¨è«–ã—ãŸã‚Šã€è¡Œå‹•ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ã®ä½œæ¥­è¨˜æ†¶ã‚’ç¶­æŒã—ãŸã‚Šã™ã‚‹ãŸã‚ã«è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ã¦ã„ãªã„ã€‚æ¨è«–ã¨è¡Œå‹•ã‚’ä¸€èˆ¬çš„ãªèª²é¡Œè§£æ±ºã®ãŸã‚ã«ã©ã®ã‚ˆã†ã«ã‚·ãƒŠã‚¸ãƒ¼ã§ãã‚‹ã‹ã€ã¾ãŸãã®ã‚ˆã†ãªã‚·ãƒŠã‚¸ãƒ¼ãŒå˜ç‹¬ã§æ¨è«–ã‚„è¡Œå‹•ã‚’å®Ÿæ–½ã—ãŸå ´åˆã¨æ¯”è¼ƒã—ã¦ã©ã®ã‚ˆã†ãªåˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™ã‹ã«ã¤ã„ã¦ç ”ç©¶ã•ã‚Œã¦ã„ãªã„ã€‚<br><br>ãã“ã§ã€REACTã‚’ææ¡ˆã€‚REACTã¯æ¨è«–ã¨è¡Œå‹•ã‚’LLMã¨çµ„ã¿åˆã‚ã›ã¦ã€å¤šæ§˜ãªæ¨è«–ã‚„æ„æ€æ±ºå®šã‚¿ã‚¹ã‚¯ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®ä¸€èˆ¬çš„ãªæ çµ„ã¿ã§ã‚ã‚Šã€æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’äº¤äº’ã«ç”Ÿæˆã™ã‚‹ãŸã‚ã€å‹•çš„ã«æ¨è«–ã‚’å®Ÿè¡Œã—ã¦è¡Œå‹•ã™ã‚‹ãŸã‚ã®å¤§ã¾ã‹ãªè¨ˆç”»ã‚’ä½œæˆã€ç¶­æŒã€èª¿æ•´ã§ãã‚‹ã¨åŒæ™‚ã«ã€wikipediaãªã©ã®å¤–éƒ¨ã‚½ãƒ¼ã‚¹ã¨ã‚„ã‚Šã¨ã‚Šã—ã¦è¿½åŠ æƒ…å ±ã‚’åé›†ã—ã€æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒå¯èƒ½ã¨ãªã‚‹ã€‚<br><br><br><br>- è¦ã¯ã„ã¾ã¾ã§ã¯Generalãªã‚¿ã‚¹ã‚¯è§£æ±ºãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã¯ã€æ¨è«–ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆã¯ç‹¬ç«‹ã«ã—ã‹ã‚„ã‚‰ã‚Œã¦ã“ãªã‹ã£ãŸã‘ã©ã€æ¨è«–ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’äº¤äº’ä½œç”¨ã•ã›ã‚‹ã“ã¨ã«ã¤ã„ã¦ç ”ç©¶ã—ãŸã‚ˆ<br><br>- ãã—ãŸã‚‰æ€§èƒ½ãŒã¨ã£ã¦ã‚‚ã‚ãŒã£ãŸã‚ˆ<br><br>- reasoningã‚’äººé–“ãŒç·¨é›†ã™ã‚Œã°ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã‚‚ã§ãã‚‹ã‚ˆã€€ã¨ã„ã†æ„Ÿã˜<br><br><br><br># ã‚¤ãƒ³ãƒˆãƒ­<br><br>äººé–“ã¯æ¨è«–ã¨è¡Œå‹•ã®ç·Šå¯†ãªã‚·ãƒŠã‚¸ãƒ¼ã«ã‚ˆã£ã¦ã€ä¸ç¢ºå®ŸãªçŠ¶æ³ã«é­é‡ã—ã¦ã‚‚é©åˆ‡ãªæ„æ€æ±ºå®šãŒè¡Œãˆã‚‹ã€‚ãŸã¨ãˆã°ã€ä»»æ„ã®2ã¤ã®ç‰¹å®šã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®é–“ã§ã€é€²è¡ŒçŠ¶æ³ã‚’ãƒˆãƒ¬ãƒ¼ã‚¹ã™ã‚‹ãŸã‚ã«è¨€èªã§æ¨è«–ã—ãŸã‚Šï¼ˆã™ã¹ã¦åˆ‡ã‚Šçµ‚ã‚ã£ãŸã‹ã‚‰ãŠæ¹¯ã‚’æ²¸ã‹ã™å¿…è¦ãŒã‚ã‚‹ï¼‰ã€ä¾‹å¤–ã‚’å‡¦ç†ã—ãŸã‚Šã€çŠ¶æ³ã«å¿œã˜ã¦è¨ˆç”»ã‚’èª¿æ•´ã—ãŸã‚Šã™ã‚‹ï¼ˆå¡©ãŒãªã„ã‹ã‚‰ä»£ã‚ã‚Šã«é†¤æ²¹ã¨èƒ¡æ¤’ã‚’ä½¿ãŠã†ï¼‰ã€‚ã¾ãŸã€æ¨è«–ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€ç–‘å•ï¼ˆã„ã¾ã©ã‚“ãªæ–™ç†ã‚’ä½œã‚‹ã“ã¨ãŒã§ãã‚‹ã ã‚ã†ã‹ï¼Ÿï¼‰ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã«ã€è¡Œå‹•ï¼ˆæ–™ç†æœ¬ã‚’é–‹ã„ã¦ãƒ¬ã‚·ãƒ”ã‚’èª­ã‚“ã§ã€å†·è”µåº«ã‚’é–‹ã„ã¦ææ–™ã‚’ç¢ºç¢ºèªã—ãŸã‚Šï¼‰ã‚’ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã€‚<br><br><br><br>è¿‘å¹´ã®ç ”ç©¶ã§ã¯è¨€èªã§ã®æ¨è«–ã‚’ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªæ„æ€æ±ºå®šã‚’çµ„ã¿åˆã‚ã›ã‚‹å¯èƒ½æ€§ã«ã¤ã„ã¦ã®ãƒ’ãƒ³ãƒˆãŒå¾—ã‚‰ã‚Œã¦ããŸã€‚ä¸€ã¤ã¯ã€é©åˆ‡ã«Promptingã•ã‚ŒãŸLLMãŒæ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å®Ÿè¡Œã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã¨ã¯ã€è§£æ±ºç­–ã«åˆ°é”ã™ã‚‹ãŸã‚ã®ä¸€é€£ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’çµŒã¦æ¨è«–ã‚’ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ã‚»ã‚¹ã®ã“ã¨ã§ã‚ã‚‹ã€‚ã—ã‹ã—ãªãŒã‚‰Chain-of-thoughytã¯ã€ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒå¤–ç•Œå¯¾ã—ã¦groundingã§ããšã€å†…éƒ¨è¡¨ç¾ã®ã¿ã«åŸºã¥ã„æ€è€ƒã‚’ç”Ÿæˆã™ã‚‹ãŸã‚é™ç•ŒãŒã‚ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šãƒ¢ãƒ‡ãƒ«ãŒäº‹å¾Œå¯¾å¿œçš„ã«æ¨è«–ã—ãŸã‚Šã€å¤–éƒ¨æƒ…å ±ã«åŸºã¥ã„ã¦çŸ¥è­˜ã‚’æ›´æ–°ã—ãŸã‚Šã§ããªã„ãŸã‚ã€æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ä¸­ã«hallucinationã‚„ã‚¨ãƒ©ãƒ¼ã®ä¼æ¬ãªã©ã®å•é¡ŒãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒç”Ÿã˜ã‚‹ã€‚<br><br>ä¸€æ–¹ã€è¿‘å¹´ã®ç ”ç©¶ã§ã¯äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’interactiveãªç’°å¢ƒã«ãŠã„ã¦è¨ˆç”»ã¨è¡Œå‹•ã«åˆ©ç”¨ã™ã‚‹ç ”ç©¶ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã€‚ã“ã‚Œã‚‰ã®ç ”ç©¶ã§ã¯ã€é€šå¸¸ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªè¦³æ¸¬çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ã¾ãŸã¯ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆã—ã€ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’åˆ©ç”¨ã—ã¦ãã‚Œã‚‰ã‚’é¸æŠã¾ãŸã¯å®Ÿè¡Œã™ã‚‹ã€‚ãŸã ã—ã€ã“ã‚Œã‚‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯é«˜ãƒ¬ãƒ™ãƒ«ã®ç›®æ¨™ã«ã¤ã„ã¦æŠ½è±¡çš„ã«æ¨è«–ã—ãŸã‚Šã€è¡Œå‹•ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ã®ä½œæ¥­è¨˜æ†¶ã‚’ç¶­æŒã—ãŸã‚Šã™ã‚‹ãŸã‚ã«è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ã¦ã„ãªã„ã€‚<br><br>æ¨è«–ã¨è¡Œå‹•ã‚’ä¸€èˆ¬çš„ãªèª²é¡Œè§£æ±ºã®ãŸã‚ã«ã©ã®ã‚ˆã†ã«ã‚·ãƒŠã‚¸ãƒ¼ã§ãã‚‹ã‹ã€ã¾ãŸãã®ã‚ˆã†ãªã‚·ãƒŠã‚¸ãƒ¼ãŒå˜ç‹¬ã§æ¨è«–ã‚„è¡Œå‹•ã‚’å®Ÿæ–½ã—ãŸå ´åˆã¨æ¯”è¼ƒã—ã¦ã©ã®ã‚ˆã†ãªåˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™ã‹ã«ã¤ã„ã¦ç ”ç©¶ã•ã‚Œã¦ã„ãªã„ã€‚<br><br><br><br>LLMã«ãŠã‘ã‚‹æ¨è«–ã¨è¡Œå‹•ã‚’çµ„ã¿åˆã‚ã›ã¦ã€è¨€èªæ¨è«–ã¨æ„æ€æ±ºå®šã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹REACTã¨å‘¼ã°ã‚Œã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚REACTã§ã¯ã€æ¨è«–ã¨è¡Œå‹•ã®ç›¸ä¹—åŠ¹æœã‚’é«˜ã‚ã‚‹ã“ã¨ãŒå¯èƒ½ã€‚æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã«ã‚ˆã‚Šã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’èª˜ç™ºã€è¿½è·¡ã€æ›´æ–°ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯å¤–éƒ¨ã‚½ãƒ¼ã‚¹ã¨é€£æºã—ã¦è¿½åŠ æƒ…å ±ã‚’åé›†ã§ãã‚‹ã€‚<br><br><br><br>REACTã¯æ¨è«–ã¨è¡Œå‹•ã‚’LLMã¨çµ„ã¿åˆã‚ã›ã¦ã€å¤šæ§˜ãªæ¨è«–ã‚„æ„æ€æ±ºå®šã‚¿ã‚¹ã‚¯ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®ä¸€èˆ¬çš„ãªæ çµ„ã¿ã§ã‚ã‚‹ã€‚REACTã®promptã¯LLMã«verbalãªæ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã¨ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’äº¤äº’ã«ç”Ÿæˆã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯å‹•çš„ãªæ¨è«–ã‚’å®Ÿè¡Œã—ã¦è¡Œå‹•ã™ã‚‹ãŸã‚ã®å¤§ã¾ã‹ãªè¨ˆç”»ã‚’ä½œæˆã€ç¶­æŒã€èª¿æ•´ã§ãã‚‹ã¨åŒæ™‚ã«ã€wikipediaãªã©ã®å¤–éƒ¨ã‚½ãƒ¼ã‚¹ã¨ã‚„ã‚Šã¨ã‚Šã—ã¦è¿½åŠ æƒ…å ±ã‚’åé›†ã—ã€æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒå¯èƒ½ã¨ãªã‚‹ã€‚<br><br><br><br># æ‰‹æ³•<br><br>å¤‰æ•°ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ï¼š<br><br>- O_t: Observertion on time t<br><br>- a_t: Action on time t<br><br>- c_t: context, i.e. (o_1, a_1, o_2, a_2, ..., a_t-1, o_t)<br><br>- policy pi(a_t | c_t): Action Spaceã‹ã‚‰ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠã™ã‚‹ãƒãƒªã‚·ãƒ¼<br><br>- A: Action Space<br><br>- O: Observation Space<br><br><br><br>æ™®é€šã¯c_tãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ãƒãƒªã‚·ãƒ¼ã«å¾“ã„Aã‹ã‚‰a_tã‚’é¸æŠã—ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®çµæœo_tã‚’å¾—ã¦ã€c_t+1ã‚’æ§‹æˆã™ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã¦ã„ãã€‚<br><br><br><br>ã“ã®ã¨ãã€REACTã¯Aã‚’A âˆª Lã«æ‹¡å¼µã—ã™ã‚‹ã€‚ã“ã“ã§ã€Lã¯Language spaceã§ã‚ã‚‹ã€‚Lã«ã¯Action a_hatãŒå«ã¾ã‚Œã€a_hatã¯ç’°å¢ƒã«å¯¾ã—ã¦ä½œç”¨ã‚’ã—ãªã„ã€‚å˜ç´”ã«thought, ã‚ã‚‹ã„ã¯ reasoning traceã‚’å®Ÿæ–½ã—ã€ç¾åœ¨ã®context c_tã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã«æœ‰ç”¨ãªæƒ…å ±ã‚’æ§‹æˆã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã™ã‚‹ã€‚Lã¯unlimitedãªã®ã§ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã‚‹ã€‚ä»Šå›ã¯PaLM-540Bï¼ˆc.f. GPT3ã¯175Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ãŒåˆ©ç”¨ã•ã‚Œã€few-shotã®in-context exampleã‚’ä¸ãˆã‚‹ã“ã¨ã§æ¨è«–ã‚’è¡Œã†ã€‚ãã‚Œãã‚Œã®in-context exampleã¯ã€action, thoughtsãã—ã¦observationã®trajectoryã‚’ä¸ãˆã‚‹ã€‚<br><br><br><br>æ¨è«–ãŒé‡è¦ãªã‚¿ã‚¹ã‚¯ã§ã¯ã€thoughts-action-observationã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰æˆã‚‹task-solving trajectoryã‚’ç”Ÿæˆã™ã‚‹ã€‚ä¸€æ–¹ã€å¤šæ•°ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¼´ã†å¯èƒ½æ€§ãŒã‚ã‚‹æ„æ€æ±ºå®šã‚¿ã‚¹ã‚¯ã§ã¯ã€thoughtsã®ã¿ã‚’è¡Œã†ã“ã¨ã‚’task-solving trajectoryä¸­ã®ä»»æ„ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã€è‡ªåˆ†ã§åˆ¤æ–­ã—ã¦è¡Œã†ã“ã¨ãŒã§ãã‚‹ã€‚<br><br><br><br>æ„æ€æ±ºå®šã¨æ¨è«–èƒ½åŠ›ãŒLLMã«ã‚ˆã£ã¦ã‚‚ãŸã‚‰ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€REACTã¯4ã¤ã®uniqueãªç‰¹å¾´ã‚’æŒã¤ï¼š<br><br>- ç›´æ„Ÿçš„ã§ç°¡å˜ãªãƒ‡ã‚¶ã‚¤ãƒ³<br><br>  - REACTã®promptã¯äººé–“ã®ã‚¢ãƒãƒ†ãƒ¼ã‚¿ãŒã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒˆãƒƒãƒ—ã«æ€è€ƒã‚’è¨€èªã§è¨˜è¿°ã™ã‚‹ã‚ˆã†ãªã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆãªã‚‚ã®ã§ã‚ã‚Šã€ad-hocãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®é¸æŠã€æ€è€ƒã®ãƒ‡ã‚¶ã‚¤ãƒ³ã€äº‹ä¾‹ã®é¸å®šãªã©ãŒå¿…è¦ãªã„ã€‚<br><br>- ä¸€èˆ¬çš„ã§æŸ”è»Ÿæ€§ãŒé«˜ã„<br><br>  - æŸ”è»Ÿãª thought spaceã¨ thought-actionã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ã‚ˆã‚Šã€REACTã¯ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã«ã‚‚æŸ”è»Ÿã«å¯¾å¿œã§ãã‚‹<br><br>- é«˜æ€§èƒ½ã§ãƒ­ãƒã‚¹ãƒˆ<br><br>  - REACTã¯1-6å€‹ã®äº‹ä¾‹ã«ã‚ˆã£ã¦ã€æ–°ãŸãªã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹å¼·åŠ›ãªæ±åŒ–ã‚’ç¤ºã™ã€‚ãã—ã¦æ¨è«–ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã¿ã‚’è¡Œã†ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚REACTã¯finetuningã®æ–§ç³»ã‚‚å¾—ã‚‹ã“ã¨ãŒã§ãã€promptã®é¸æŠã«å¯¾ã—ã¦REACTã®æ€§èƒ½ã¯robustã§ã‚ã‚‹ã€‚<br><br>- äººé–“ã«ã‚ˆã‚‹èª¿æ•´ã¨æ“ä½œãŒå¯èƒ½<br><br>  - REACTã¯ã€è§£é‡ˆå¯èƒ½ãªæ„æ€æ±ºå®šã¨æ¨è«–ã®sequenceã‚’å‰æã¨ã—ã¦ã„ã‚‹ãŸã‚ã€äººé–“ã¯ç°¡å˜ã«æ¨è«–ã‚„äº‹å®Ÿã®æ­£ã—ã•ã‚’æ¤œè¨¼ã§ãã‚‹ã€‚åŠ ãˆã¦ã€thoughtsã‚’ç·¨é›†ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€mäººé–“ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¡Œå‹•ã‚’åˆ¶å¾¡ã€ã‚ã‚‹ã„ã¯ä¿®æ­£ã§ãã‚‹ã€‚<br><br><br><br># KNOWLEDGE INTENSIVE REASONING TASKS</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DataGeneration.html" target="_blank" rel="noopener noreferrer">#DataGeneration</a>
<span class="issue_date">Issue Date: 2023-04-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/517" target="_blank" rel="noopener noreferrer" class="title-link">ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks, Gilardi+, University of Zurich, NAS'23</a>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>2300ä»¶ç¨‹åº¦ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’åˆ†é¡ã™ã‚‹ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€è¨“ç·´ã—ãŸå­¦éƒ¨ç”Ÿã«ã‚ˆã‚‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ­£è§£ã¨ã—ã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã¨ChatGPTã§ã®zero-shotã§ã®äºˆæ¸¬ã®æ€§èƒ½ã‚’æ¯”è¼ƒã—ãŸã€‚åˆ†é¡ã‚¿ã‚¹ã‚¯ã¯ã€æ¯”è¼ƒçš„é›£æ˜“åº¦ã®é«˜ã„åˆ†é¡å•é¡Œã§ã‚ã‚Šã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ã‚‚æ­£è§£ç‡ã¯é›£ã—ã„ã‚¿ã‚¹ã‚¯ã§ã¯15~25%ç¨‹åº¦ã§ã‚ã£ãŸã€‚ã“ã®ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã§chatgptã¯40~60%ã®æ­£è§£ç‡ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br>æ¯”è¼ƒã®çµæœã€5ã¤ã®ã‚¿ã‚¹ã‚¯ä¸­4ã¤ã®ã‚¿ã‚¹ã‚¯ã§ChatGPTãŒã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’ä¸Šå›ã‚‹æ­£è§£ç‡ã‚’ç¤ºã—ãŸã€‚<br><br><br><br># æ‰‹æ³•<br><br>- ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã¨ChatGPTã§åŒã˜ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’åˆ©ç”¨ã—ã€åŒã˜ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã—ãŸ<br><br>- inter-notator aggreementã‚’å›³ã‚‹ãŸã‚ã«ã€ãã‚Œãã‚Œã®ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦å„ãƒ„ã‚¤ãƒ¼ãƒˆã«å°‘ãªãã¨ã‚‚2äººãŒãƒ©ãƒ™ãƒ«ä»˜ã‚’è¡Œã£ãŸ<br><br>- ChatGPTã§ã‚‚åŒæ§˜ã«ã€ã‚¿ã‚¹ã‚¯ã”ã¨ã«å„ãƒ„ã‚¤ãƒ¼ãƒˆã«ã¯2å›åŒã˜ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã—ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ãŸ<br><br>- ChatGPTã‚’åˆ©ç”¨ã™ã‚‹éš›ã¯ã€temperatureã‚’1.0, 0.2ã®å ´åˆã§è©¦ã—ãŸã€‚å¾“ã£ã¦ChatGPTã®ãƒ©ãƒ™ãƒ«ä»˜ã‘ã¯å„ã‚¿ã‚¹ã‚¯ã”ã¨ã«4ã‚»ãƒƒãƒˆå­˜åœ¨ã™ã‚‹ã“ã¨ã«ãªã‚‹ã€‚<br><br><br><br># çµæœ<br><br><img src="https://user-images.githubusercontent.com/12249301/231333088-cfe9362a-5412-4ea1-ae8c-67156f13290c.png" alt="image" loading="lazy"><br><br><br><br>5ã‚¿ã‚¹ã‚¯ä¸­ã€4ã‚¿ã‚¹ã‚¯ã§ChatGPTãŒzero-shotã«ã‚‚ã‹ã‹ã‚ã‚‰ãšæ­£è§£ç‡ã§workerã‚’ä¸Šå›ã£ãŸã€‚ã¾ãŸé«˜ã„aggreementã‚’ç™ºæ®ã—ã¦ã„ã‚‹ã“ã¨ã‚’ä¸»å¼µã€‚aggreementã¯temperatureãŒä½ã„æ–¹ãŒé«˜ãã€ã“ã‚Œã¯temperatureãŒä½ã„æ–¹ãŒrandomnessãŒæ¸›å°‘ã™ã‚‹ãŸã‚ã§ã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚aggreementã‚’Accuracyã®ç›¸é–¢ã‚’å›³ã£ãŸãŒã€0.17ã§ã‚ã‚Šå¼±ã„ç›¸é–¢ã—ã‹ãªã‹ã£ãŸã€‚å¾“ã£ã¦ã€Accuracyã‚’æ¸›å°‘ã•ã›ã‚‹ã“ã¨ãªãã€ä¸€è²«æ€§ã®ã‚ã‚‹çµæœã‚’å¾—ã‚‰ã‚Œã‚‹law temperatureã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒæœ›ã¾ã—ã„ã¨çµè«–ã¥ã‘ã¦ã„ã‚‹ã€‚<br><br><br><br># å®Ÿæ–½ã—ãŸã‚¿ã‚¹ã‚¯<br><br>"content moderation"ã«é–¢ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã—ãŸã€‚content moderationã¯SNSãªã©ã«æŠ•ç¨¿ã•ã‚Œã‚‹postã‚’ç›£è¦–ã™ã‚‹ãŸã‚ã®å–ã‚Šçµ„ã¿ã§ã‚ã‚Šã€ãŸã¨ãˆã°ãƒãƒ«ãƒˆãƒ„ã‚¤ãƒ¼ãƒˆã‚„èª¤ã£ãŸæƒ…å ±ã‚’å«ã‚€æœ‰å®³ãªãƒ„ã‚¤ãƒ¼ãƒˆã€ãƒ˜ã‚¤ãƒˆã‚¹ãƒ”ãƒ¼ãƒãªã©ãŒå­˜åœ¨ã—ãªã„ã‹ã‚’SNSä¸Šã§ç›£è¦–ã‚’ã‚’è¡Œã†ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã§ã‚ã‚‹ã€‚è‘—è€…ã‚‰ã¯content moderationã¯ãƒãƒ¼ãƒ‰ãªã‚¿ã‚¹ã‚¯ã§ã‚ã‚Šã€è¤‡é›‘ãªãƒˆãƒ”ãƒƒã‚¯ã ã—ã€toy exampleã§ã¯ãªã„ã“ã¨ã‚’ä¸»å¼µã—ã¦ã„ã‚‹ã€‚å®Ÿéš›ã€è‘—è€…ã‚‰ãŒè¨“ç·´ã—ãŸå­¦éƒ¨ç”Ÿã®é–“ã§ã®inter-annotator aggreementã¯50%ç¨‹åº¦ã§ã‚ã‚Šã€é›£æ˜“åº¦ãŒé«˜ã„ã‚¿ã‚¹ã‚¯ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ï¼ˆãŸã ã—ã€ã‚¹ã‚¿ãƒ³ã‚¹detectionã«é–¢ã—ã¦ã¯aggreementãŒ78.3%ã§ã‚ã£ãŸï¼‰ã€‚<br><br><br><br>content moderationã®ã†ã¡ã€ä»¥ä¸‹ã®5ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã—ãŸã€‚<br><br>- relevance:<br><br>  - ãƒ„ã‚¤ãƒ¼ãƒˆãŒcontent moderationã«ã¤ã„ã¦ç›´æ¥çš„ã«é–¢ä¿‚ã™ã‚‹ã“ã¨ã‚’è¿°ã¹ã¦ã„ã‚‹ã‹å¦ã‹<br><br>  - e.g. SNSã«ãŠã‘ã‚‹content moderation ruleã‚„å®Ÿè·µã€æ”¿åºœã®ãƒ¬ã‚®ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç­‰<br><br>  - content moderationã«ã¤ã„ã¦è¿°ã¹ã¦ã„ãªã„ã‚‚ã®ã«ã¤ã„ã¦ã¯IRRELEVANTãƒ©ãƒ™ãƒ«ã‚’ä»˜ä¸ã™ã‚‹<br><br>  - ãŸã ã—ã€ä¸»é¡ŒãŒcontent moderationã®ãƒ„ã‚¤ãƒ¼ãƒˆã§ã‚ã£ã¦ã‚‚ã€content moderationã«ã¤ã„ã¦è«–ã˜ã¦ã„ãªã„ã‚‚ã®ã«ã¤ã„ã¦ã¯IRRELEVANTæ‰±ã„ã¨ã™ã‚‹ã€‚<br><br>  - ã“ã®ã‚ˆã†ãªä¾‹ã¨ã—ã¦ã¯ã€TwitterãŒDonald Trupã®Twitterã‚’"disrupted"ã¨labelä»˜ã‘ã—ãŸã“ã¨ã‚„ã€ä½•ã‹ã«ã¤ã„ã¦é–“é•ã£ã¦ã„ã‚‹ã¨è¿°ã¹ã¦ã„ã‚‹ãƒ„ã‚¤ãƒ¼ãƒˆã€ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–ãªå†…å®¹ã‚’å«ã‚€ãƒ„ã‚¤ãƒ¼ãƒˆãªã©ãŒã‚ã’ã‚‰ã‚Œã‚‹ã€‚<br><br>- Problem/Solution Frames<br><br>  - content moderationã¯2ã¤ã®è¦‹æ–¹ãŒã§ãã‚‹ã€‚ãã‚ŒãŒProblemã¨Solution<br><br>  - Problem: content moderationã‚’PROBLEMã¨ã¿ãªã™ã‚‚ã®ã€‚ãŸã¨ãˆã°ã€ãƒ•ãƒªãƒ¼ã‚¹ãƒ”ãƒ¼ãƒã®åˆ¶é™ãªã©<br><br>  - SOLUTION: content moderationã‚’SOLUTIONã¨ã¿ãªã™ã‚‚ã®ã€‚ãŸã¨ãˆã°ã€harmful speechã‹ã‚‰å®ˆã‚‹ã“ã¨ã€ãªã©<br><br>  - ãƒ„ã‚¤ãƒ¼ãƒˆãŒcontent moderationã®negativeãªå½±éŸ¿ã«ã¤ã„ã¦å¼·èª¿ã—ã¦ã„ãŸã‚‰ã€PROBLEMï¼ˆãƒ•ãƒªãƒ¼ã‚¹ãƒ”ãƒ¼ãƒã®åˆ¶é™ã‚„ãƒ¦ãƒ¼ã‚¶ãŒãƒã‚¹ãƒˆã™ã‚‹å†…å®¹ã«ã¤ã„ã¦ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ã‚‹ã“ã¨ãªã©ã«ã¤ã„ã¦ï¼‰<br><br>  - ãƒ„ã‚¤ãƒ¼ãƒˆãŒcontent moderationã®positiveãªå½±éŸ¿ã«ã¤ã„ã¦å¼·èª¿ã—ã¦ã„ãŸã‚‰ã€SOKUTIONï¼ˆharmful contentã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ã‚’å®ˆã‚‹ãªã©ï¼‰<br><br>  - ä¸»é¡Œã¯content moderationã§ã‚ã‚‹ãŒã€positive/negativeãªå½±éŸ¿ã«ã¤ã„ã¦è«–ã˜ã¦ã„ãªã„ã‚‚ã®ã¯NEUTRAL<br><br>- Policy Frames<br><br>  - content moderationã¯ã•ã¾ã–ã¾ã‚“ãƒˆãƒ”ãƒƒã‚¯ã¨é–¢é€£ã—ã¦ã„ã‚‹ï¼ˆãŸã¨ãˆã°ï¼‰ã€å¥åº·ã€çŠ¯ç½ªã€å¹³ç­‰ãªã©ï¼‰<br><br>  - content moderatiojnã«é–¢ã™ã‚‹ãƒ„ã‚¤ãƒ¼ãƒˆãŒã©ã®ãƒˆãƒ”ãƒƒã‚¯ã‹ã‚’ãƒ©ãƒ™ãƒ«ä»˜ã™ã‚‹ã€‚ãƒ©ãƒ™ãƒ«ã¯15ç¨®é¡<br><br>  - economy, capcity and resources, modality, fairness and equality, constitutionality and jurisprudence, policy prescription and evaluation, law and order, crime and justice, security and defense, health and safety, quality of life, cultural identity, public opinion, political, external regulation and reputation, other<br><br>- Stance Detection<br><br>  - USã®Section 230ã¨ã„ã†æ³•å¾‹ï¼ˆwebsiteã«ãƒ¦ãƒ¼ã‚¶ãŒæŠ•ç¨¿ã—ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«å¯¾ã—ã¦ã€webã‚µã‚¤ãƒˆã‚„ãã®ä»–ã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãŒæ³•çš„è²¬ä»»ã‚’å•ã‚ã‚Œã‚‹ã®ã‚’é˜²ãæ³•å¾‹ï¼‰ã«ã¤ã„ã¦ã€ãƒ„ã‚¤ãƒ¼ãƒˆãŒSection230ã«å¯¾ã—ã¦ã€positive/negative/neutralãªã‚¹ã‚¿ãƒ³ã‚¹ã‹ã‚’ãƒ©ãƒ™ãƒ«ä»˜ã™ã‚‹<br><br>- Topic Detection<br><br>  - ãƒ„ã‚¤ãƒ¼ãƒˆã‚’6ã¤ã®ãƒˆãƒ”ãƒƒã‚¯ã«ãƒ©ãƒ™ãƒ«ä»˜ã™ã‚‹<br><br>  - Section 230, TRUMP BAN, TWITTER-SUPPORT, PLATFORM POLICIES, COMPLAINTS, other</p>
<p># æ‰€æ„Ÿ<br><br>ãã“ãã“é›£æ˜“åº¦ã®é«˜ã„ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã§ã‚‚zero-shotã§turkerã®æ€§èƒ½ã‚’ä¸Šå›ã‚‹ã®ã¯éå¸¸ã«ç´ æ™´ã‚‰ã—ã„ã“ã¨ã ã¨æ€ã†ã€‚ãƒã‚¤ã‚¸ãƒ¼ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚Œã°ã€æ¯”è¼ƒçš„å®‰ä¾¡ã€ã‹ã¤ã‚¹ãƒ”ãƒ¼ãƒ‡ã‚£ãƒ¼ã«ä½œæˆã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ããŸã®ã§ã¯ãªã„ã‹ã¨æ€ã†ã€‚<br><br>ãŸã ã€ChatGPTã®aggreementã‚’å›³ã‚‹ã“ã¨ã«ã©ã‚Œã ã‘æ„å‘³ãŒã‚ã‚‹ã®ã ã‚ã†ã€ã¨ã¯æ€ã†ã€‚åŒã˜ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã‚ã‘ã§ã€å°tãªã‚‹LLMã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸå ´åˆã®aggreementãªã‚‰ã¨ã‚‹æ„å‘³ãŒã‚ã‚‹ã¨æ€ã†ãŒã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/In-Depth%20Notes.html" target="_blank" rel="noopener noreferrer">#In-Depth Notes</a>
<span class="issue_date">Issue Date: 2023-03-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/513" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Instruct: Aligning Language Models with Self-Generated Instructions, Yizhong Wang+, ACL'23, 2022.12</a>
<span class="snippet"><span>GPT Summary</span>- Self-Instructãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«ãŒè‡ªã‚‰ç”Ÿæˆã—ãŸæŒ‡ç¤ºã‚’ç”¨ã„ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã“ã¨ã§ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ãƒãƒ‹ãƒ©GPT-3ã«é©ç”¨ã—ãŸçµæœã€Super-NaturalInstructionsã§33%ã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã—ã€InstructGPT-001ã¨åŒç­‰ã®æ€§èƒ½ã«åˆ°é”ã€‚äººé–“è©•ä¾¡ã«ã‚ˆã‚Šã€Self-InstructãŒæ—¢å­˜ã®å…¬å…±æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ã»ã¼æ³¨é‡ˆä¸è¦ã®æŒ‡ç¤ºèª¿æ•´æ‰‹æ³•ã‚’æä¾›ã€‚å¤§è¦æ¨¡ãªåˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã—ã€ä»Šå¾Œã®ç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Alpacaãªã©ã§ã‚‚åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹self-instructionæŠ€è¡“ã«é–¢ã™ã‚‹è«–æ–‡</p>
<p># æ¦‚è¦<br><br><img src="https://user-images.githubusercontent.com/12249301/228716254-5f4d7451-a37a-4354-843d-7e4052ba230b.png" alt="image" loading="lazy"><br><br><br><br>è‘—è€…ã‚‰ãŒæ›¸ã„ãŸ175ç¨®ã®instructionï¼ˆã‚¿ã‚¹ã‚¯ã®å®šç¾© + 1ç¨®ã®input/outputãƒšã‚¢}ã®seedã‚’å…ƒã«ã€VanillaãªGPT-3ã«æ–°ãŸãªinstruction, input, outputã®tupleã‚’ç”Ÿæˆã•ã›ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ´»ç”¨ã™ã‚‹ç ”ç©¶ã€‚<br><br>ã“ã“ã§ã€instruction data I ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã•ã‚Œã‚‹ï¼š<br><br>instruction dataã¯(I, X, Y)ã§ã‚ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯æœ€çµ‚çš„ã«M(I_t, x_t) = y_tã¨ãªã‚‹ã‚ˆã†ã«å­¦ç¿’ã—ãŸã„ã€‚<br><br>I: instruction, X: input, Y: output<br><br><br><br>ãƒ‡ãƒ¼ã‚¿ä½œæˆã¯ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æ§‹æˆã•ã‚Œã‚‹ã€‚ãªãŠã€ä»¥ä¸‹ã¯ã™ã¹ã¦Vanilla GPT-3ã‚’é€šã˜ã¦è¡Œã‚ã‚Œã‚‹ï¼š<br><br>1. Instruction Generation<br><br>ã€€task poolã‹ã‚‰8ç¨®é¡ã®instructionã‚’æŠ½å‡ºã—ã€ promptã‚’æ§‹æˆã—ã€æœ€å¤§8å€‹æ–°ãŸãªinstructionã‚’ç”Ÿæˆã•ã›ã‚‹<br><br>2. Classification Task Identification:<br><br>ã€€ç”Ÿæˆã•ã‚ŒãŸinstructionãŒclassificationã‚¿ã‚¹ã‚¯ã‹å¦ã‹ã‚’åˆ¤åˆ¥ã™ã‚‹<br><br>3. Instance Generation<br><br>ã€€ã„ãã¤ã‹ã®(I, X, Y)ã‚’promptã¨ã—ã¦ä¸ãˆã€I, Xã«å¯¾å¿œã™ã‚‹Yã‚’ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã•ã›ã‚‹ã€‚ã“ã®ã¨ãinput-first approachã‚’æ¡ç”¨ã—ãŸçµæœï¼ˆI-&gt;Xã®é †ç•ªã§æƒ…å ±ã‚’ä¸ãˆYã‚’ç”Ÿæˆã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰ã€ç‰¹å®šã®ãƒ©ãƒ™ãƒ«ã«åã£ãŸã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒç”Ÿæˆã•ã‚Œã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã“ã®ãŸã‚output-first approachã‚’åˆ¥é€”æ¡ç”¨ã—ï¼ˆI-&gt;Yã®é †ç•ªã§æƒ…å ±ã‚’ä¸ãˆã€å„Yã«å¯¾å¿œã™ã‚‹Xã‚’ç”Ÿæˆã•ã›ã‚‹ï¼‰ã€æ´»ç”¨ã—ã¦ã„ã‚‹ã€‚ã€€<br><br>4. Filtering and Postprocessing<br><br>ã€€æœ€å¾Œã«ã€æ—¢å­˜ã®task poolã¨ROUGE-LãŒ0.7ä»¥ä¸Šã®instructionã¯å¤šæ§˜æ€§ãŒãªã„ãŸã‚é™¤å¤–ã—ã€ç‰¹å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆimages, pictrues, graphsï¼‰ç­‰ã‚’å«ã‚“ã§ã„ã‚‹instruction dataã‚‚é™¤å¤–ã—ã¦ã€task poolã«è¿½åŠ ã™ã‚‹ã€‚<br><br><br><br>1-4ã‚’ã²ãŸã™ã‚‰ç¹°ã‚Šè¿”ã™ã“ã¨ã§ã€GPT-3ãŒInstruction Tuningã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•ç”Ÿæˆã—ã¦ãã‚Œã‚‹ã€‚<br><br><br><br># SELF-INSTRUCT Data<br><br>## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±è¨ˆé‡<br><br><img src="https://user-images.githubusercontent.com/12249301/228745059-ecccadba-3e32-4f2a-9594-2459a922474b.png" alt="image" loading="lazy"><br><br>- 52k instructions<br><br>- 82k instances<br><br><br><br>## Diversity<br><br><img src="https://user-images.githubusercontent.com/12249301/228745421-ba024963-ca6e-4e30-bac8-7224d413f8ab.png" alt="image" loading="lazy"><br><br>parserã§instructionã‚’è§£æã—ã€rootã®åè©ã¨å‹•è©ã®ãƒšã‚¢ã‚’æŠ½å‡ºã—ã¦å¯è¦–åŒ–ã—ãŸä¾‹ã€‚ãŸã ã—ã€æŠ½å‡ºã§ããŸä¾‹ã¯ãŸã‹ã ã‹å…¨ä½“ã®50%ç¨‹åº¦ã§ã‚ã‚Šã€ãã®ä¸­ã§20ã®æœ€ã‚‚commonãªroot vertã¨4ã¤ã®nounã‚’å¯è¦–åŒ–ã—ãŸã€‚ã“ã‚Œã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã®14%ç¨‹åº¦ã—ã‹å¯è¦–åŒ–ã•ã‚Œã¦ã„ãªã„ãŒã€ã“ã‚Œã ã‘ã§ã‚‚éå¸¸ã«å¤šæ§˜ãªinstructionãŒé›†ã¾ã£ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br>ã¾ãŸã€seed indstructionã¨ROUGE-Lã‚’æ¸¬ã£ãŸçµæœã€å¤§åŠã®ãƒ‡ãƒ¼ã‚¿ã¯0.3~0.4ç¨‹åº¦ã§ã‚ã‚Šã€lexicalãªoverlapã¯ã‚ã¾ã‚Šå¤§ãããªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚instructionã®lengthã«ã¤ã„ã¦ã‚‚å¯è¦–åŒ–ã—ãŸçµæœã€å¤šæ§˜ãªé•·ã•ã®instructionãŒåé›†ã§ãã¦ã„ã‚‹ã€‚<br><br><br><br>## Quality<br><br>200ç¨®é¡ã®instructionã‚’æŠ½å‡ºã—ã€ãã®ä¸­ã‹ã‚‰ãã‚Œãã‚Œãƒ©ãƒ³ãƒ€ãƒ ã§1ã¤ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã‚µãƒ³ãƒ—ãƒ«ã—ãŸã€‚ãã—ã¦expert annotatorã«å¯¾ã—ã¦ã€ãã‚Œãã‚Œã®instructionã¨instanceï¼ˆinput, outputãã‚Œãã‚Œã«ã¤ã„ã¦ï¼‰ãŒæ­£ã—ã„ã‹å¦ã‹ã‚’ãƒ©ãƒ™ãƒ«ä»˜ã‘ã—ã¦ã‚‚ã‚‰ã£ãŸã€‚<br><br>ãƒ©ãƒ™ãƒ«ä»˜ã‘ã®çµæœã€ã»ã¨ã‚“ã©ã®instructionã¯æ„å‘³ã®ã‚ã‚‹instructionã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ä¸€æ–¹ã€ç”Ÿæˆã•ã‚ŒãŸinstanceã¯noisyã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸï¼ˆãŸã ã—ã€ã“ã®noiseã¯ã‚ã‚‹ç¨‹åº¦å¦¥å½“ãªç¯„å›²ã§ã‚ã‚‹ï¼‰ã€‚noisytã§ã¯ã‚ã‚‹ã®ã ãŒã€instanceã‚’è¦‹ã‚‹ã¨ã€æ­£ã—ã„formatã§ã‚ã£ãŸã‚Šã€éƒ¨åˆ†çš„ã«æ­£ã—ã‹ã£ãŸã‚Šãªã©ã€modelã‚’è¨“ç·´ã™ã‚‹ä¸Šã§æœ‰ç”¨ãªguidanceã‚’æä¾›ã™ã‚‹ã‚‚ã®ã«ãªã£ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/228746299-a0ffc115-3861-458b-a7b4-3a91ac94f8f5.png" alt="image" loading="lazy"><br><br><br><br># Experimental Results<br><br>## Zero-shotã§ã®NLPã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ€§èƒ½<br><br>SuperNIãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å«ã¾ã‚Œã‚‹119ã®ã‚¿ã‚¹ã‚¯ï¼ˆ1ã‚¿ã‚¹ã‚¯ã‚ãŸã‚Š100 instanceï¼‰ã«å¯¾ã—ã¦ã€zero-shot setupã§è©•ä¾¡ã‚’è¡Œãªã£ãŸã€‚SELF-INSTRUCTã«ã‚ˆã£ã¦ã€Vanillaã®GPT3ã‹ã‚‰å¤§å¹…ã«æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚Vanillaã®GPT-3ã¯ã»ã¨ã‚“ã©äººé–“ã®instructionã«å¿œã˜ã¦å‹•ã„ã¦ãã‚Œãªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚åˆ†æã«ã‚ˆã‚‹ã¨ã€GPT3ã¯ã€å¤§æŠµã®å ´åˆã€å…¨ãé–¢ä¿‚ãªã„ã€ã‚ã‚‹ã„ã¯ç¹°ã‚Šè¿”ã—ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¦ã„ãŸã‚Šã€ãã‚‚ãã‚‚ã„ã¤ç”Ÿæˆã‚’stopã™ã‚‹ã‹ãŒã‚ã‹ã£ã¦ã„ãªã„ã“ã¨ãŒã‚ã‹ã£ãŸã€‚<br><br><br><br>ã¾ãŸã€SuperNIå‘ã‘ã«finetuningã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«é–“ã§æ¯”è¼ƒã—ãŸçµæœã€éå¸¸ã«ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ã‚¹ãƒˆã‚’ã‹ã‘ã¦ä½œã‚‰ã‚ŒãŸT0ãƒ‡ãƒ¼ã‚¿ã§finetuningã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã—ãŸã€‚ã¾ãŸã€äººé–“ãŒãƒ©ãƒ™ãƒ«ä»˜ã—ãŸprivateãªãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã£ã¦è¨“ç·´ã•ã‚ŒãŸInstructGPT001ã«ã‚‚æ€§èƒ½ãŒè‚‰è–„ã—ã¦ã„ã‚‹ã“ã¨ã‚‚ç‰¹ç­†ã™ã¹ãç‚¹ã§ã‚ã‚‹ã€‚<br><br><br><br>SuperNIã§finetuningã—ãŸå ´åˆã«ã¤ã„ã¦ã¯ã€SELF-INSTRUCTã‚’ä½¿ã£ãŸãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€ã•ã‚‰ã«è¿½åŠ ã§SuperNIã‚’ä¸ãˆãŸå ´åˆãŒæœ€ã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/228751534-095578e0-550b-4e4c-9418-c74251e31d2a.png" alt="image" loading="lazy"><br><br><br><br>## User-Oriented Instructionsã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½<br><br>SuperNIã«å«ã¾ã‚Œã‚‹NLPã‚¿ã‚¹ã‚¯ã¯ç ”ç©¶ç›®çš„ã§ææ¡ˆã•ã‚Œã¦ãŠã‚Šåˆ†é¡å•é¡Œã¨ãªã£ã¦ã„ã‚‹ã€‚ã®ã§ã€å®Ÿè·µçš„ãªèƒ½åŠ›ã‚’è¨¼æ˜ã™ã‚‹ãŸã‚ã«ã€LLMãŒå½¹ç«‹ã¤ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ãƒ–ãƒ¬ã‚¹ãƒˆï¼ˆemail writing, social media, productiveity tools, entertainment, programmingç­‰ï¼‰ã—ã€ãã‚Œãã‚Œã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«å¯¾ã—ã¦ã€instructionã¨input-output instanceã‚’ä½œæˆã—ãŸã€‚ã¾ãŸã€instructionã®ã‚¹ã‚¿ã‚¤ãƒ«ã«ã‚‚å¤šæ§˜æ€§ï¼ˆe.g. instructionãŒlong/shortã€bullet points, table, codes, equationsã‚’input/outputã¨ã—ã¦æŒã¤ã€ãªã©ï¼‰ã‚’æŒãŸã›ãŸã€‚ä½œæˆã—ãŸçµæœã€252å€‹ã®instructionã«å¯¾ã—ã¦ã€1ã¤ã®instanceã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒä½œæˆã•ã‚ŒãŸã€‚ã“ã‚Œã‚‰ãŒã€ãƒ¢ãƒ‡ãƒ«ã«ã¨ã£ã¦unfamiliarãªinstructionã§å¤šæ§˜ãªistructionãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ã©ã‚Œã ã‘ãƒ¢ãƒ‡ãƒ«ãŒãã‚Œã‚‰ã‚’handleã§ãã‚‹ã‹ã‚’æ¸¬å®šã™ã‚‹ãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã«ãªã‚‹ã¨è€ƒãˆã¦ã„ã‚‹ã€‚<br><br><br><br>ã“ã‚Œã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã¯ã€å¤šæ§˜ã ãŒã©ã‚Œã‚‚ãŒå°‚é–€æ€§ã‚’æ±‚ã‚ã‚‰ã‚Œã‚‹ã‚‚ã®ã§ã‚ã‚Šã€è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ã§æ€§èƒ½ãŒæ¸¬å®šã§ãã‚‹ã‚‚ã®ã§ã‚‚ãªã„ã—ã€crowdworkerãŒè‰¯ã—æ‚ªã—ã‚’åˆ¤å®šã§ãã‚‹ã‚‚ã®ã§ã‚‚ãªã„ã€‚ã“ã®ãŸã‚ã€ãã‚Œãã‚Œã®instructionã«å¯¾ã™ã‚‹authorã«å¯¾ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®yè£œè¶³çµæœãŒå¦¥å½“ã‹å¦ã‹ã‚’judgeã—ã¦ã‚‚ã‚‰ã£ãŸã€‚judgeã¯4-scaleã§ã®ratingã¨ãªã£ã¦ã„ã‚‹ï¼š<br><br><br><br>- RATING-A: å¿œç­”ã¯å¦¥å½“ã§æº€è¶³ã§ãã‚‹<br><br>- RATING-B: å¿œç­”ã¯è¨±å®¹ã§ãã‚‹ãŒã€æ”¹å–„ã§ãã‚‹minor errorã‚„ä¸å®Œå…¨ã•ãŒã‚ã‚‹ã€‚<br><br>- RATING-C: å¿œç­”ã¯relevantã§instructionã«å¯¾ã—ã¦ç­”ãˆã¦ã„ã‚‹ã€‚ãŒã€å†…å®¹ã«å¤§ããªã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹ã€‚<br><br>- RATING-D: å¿œç­”ã¯irrelevantã§å¦¥å½“ã§ã¯ãªã„ã€‚<br><br><br><br>å®Ÿé¨“çµæœã‚’ã¿ã‚‹ã¨ã€Vanilla GPT3ã¯ã¾ã£ãŸãinstructionã«å¯¾ã—ã¦ç­”ãˆã‚‰ã‚Œã¦ã„ãªã„ã€‚instruction-basedãªãƒ¢ãƒ‡ãƒ«ã¯é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¦ã„ã‚‹ãŒã€ãã‚Œã‚‰ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’SELF-INSTRUCTã¯ç™ºæ®ã—ã¦ã„ã‚‹ï¼ˆnoisyã§ã‚ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšï¼‰ã€‚<br><br>ã¾ãŸã€GPT_SELF-INSTRUCTã¯InstructGPT001ã¨æ€§èƒ½ãŒè‚‰è–„ã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€InstructGPT002, 003ã®ç´ æ™´ã‚‰ã—ã„æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ã«ã‚‚ãªã£ãŸã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/228755556-1c604ed8-11a5-4237-8f9c-a30960db807a.png" alt="image" loading="lazy"><br><br><br><br># Discussion and Limitation<br><br>## ãªãœSELF-INSTRUCTãŒã†ã¾ãã„ã£ãŸã‹ï¼Ÿ<br><br>- LMã«å¯¾ã™ã‚‹2ã¤ã®æ¥µç«¯ãªä»®èª¬ã‚’æŒ™ã’ã¦ã„ã‚‹<br><br>  - LM ã¯pre-trainingã§ã¯ååˆ†ã«å­¦ç¿’ã•ã‚Œãªã‹ã£ãŸå•é¡Œã«ã¤ã„ã¦å­¦ç¿’ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€human feedbackã¯instruction-tuningã«ãŠã„ã¦å¿…è¦ä¸å¯æ¬ ãªå´é¢ã§ã‚ã‚‹<br><br>  - LM ã¯pre-trainingã‹ã‚‰instructionã«æ—¢ã«ç²¾é€šã—ã¦ã„ã‚‹ãŸã‚ã€human feedbackã¯instruction-tuningã«ãŠã„ã¦å¿…é ˆã§ã¯ãªã„ã€‚ human feedbackã‚’è¦³å¯Ÿã™ã‚‹ã“ã¨ã¯ã€pre-trainingã«ãŠã‘ã‚‹åˆ†å¸ƒ/ç›®çš„ã‚’èª¿æ•´ã™ã‚‹ãŸã‚ã®è»½é‡ãªãƒ—ãƒ­ã‚»ã‚¹ã«ã™ããšã€åˆ¥ã®ãƒ—ãƒ­ã‚»ã‚¹ã«ç½®ãæ›ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br><br><br>ã“ã®2ã¤ã®æ¥µç«¯ãªä»®èª¬ã®é–“ãŒå®Ÿæƒ…ã§ã‚ã‚‹ã¨ç­†è€…ã¯è€ƒãˆã¦ã„ã¦ã€ã©ã¡ã‚‰ã‹ã¨ã„ã†ã¨ï¼’ã¤ç›®ã®ä»®èª¬ã«è¿‘ã„ã ã‚ã†ã€ã¨è€ƒãˆã¦ã„ã‚‹ã€‚æ—¢ã«LMã¯pre-trainingã®æ®µéšã§instructionã«ã¤ã„ã¦ã‚ã‚‹ç¨‹åº¦ç†è§£ã§ãã¦ã„ã‚‹ãŸã‚ã€self-instructãŒã†ã¾ãã„ã£ãŸã®ã§ã¯ãªã„ã‹ã¨æ¨å¯Ÿã—ã¦ã„ã‚‹ã€‚<br><br><br><br>## Broader Impact<br><br>InstructGPTã¯éå¸¸ã«å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã ã‘ã©è©³ç´°ãŒå…¬è¡¨ã•ã‚Œã¦ãŠã‚‰ãšã€APIã®è£å´ã«éš ã‚Œã¦ã„ã‚‹ã€‚ã“ã®ç ”ç©¶ãŒã€instruct-tuned modelã®èƒŒå¾Œã§ä½•ãŒèµ·ãã¦ã„ã‚‹ã‹ã«ã¤ã„ã¦ã€é€æ˜æ€§ã‚’é«˜ã‚ã‚‹åŠ©ã‘ã«ãªã‚‹ã¨è€ƒãˆã¦ã„ã‚‹ã€‚ç”£æ¥­ã§é–‹ç™ºã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®æ§‹é€ ã‚„ã€ãã®å„ªã‚ŒãŸæ€§èƒ½ã®ç†ç”±ã«ã¤ã„ã¦ã¯ã»ã¨ã‚“ã©ç†è§£ã•ã‚Œã¦ãŠã‚‰ãšã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã®æˆåŠŸã®æºæ³‰ã‚’ç†è§£ã—ã€ã‚ˆã‚Šå„ªã‚ŒãŸã€ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ã®ã¯ã‚¢ã‚«ãƒ‡ãƒŸãƒƒã‚¯ã«ã‹ã‹ã£ã¦ã„ã‚‹ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€å¤šæ§˜ãªinstructional dataã®é‡è¦æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹ã¨è€ƒãˆã¦ãŠã‚Šã€å¤§è¦æ¨¡ãªäººå·¥çš„ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€ã‚ˆã‚Šå„ªã‚ŒãŸinstructionã«å¾“ã†ãƒ¢ãƒ‡ãƒ«ã‚’ã€æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ç¬¬ä¸€æ­©ã ã¨è€ƒãˆã¦ã„ã‚‹ã€‚<br><br><br><br>## limitation<br><br>- Tail Phenomena<br><br>  - LMã®æ çµ„ã¿ã«ã¨ã©ã¾ã£ã¦ã„ã‚‹ãŸã‚ã€LMã¨åŒã˜å•é¡Œï¼ˆTail Phenomenaï¼‰ã‚’æŠ±ãˆã¦ã„ã‚‹<br><br>  - low-frequencyãªcontextã«å¯¾ã—ã¦ã¯ã†ã¾ãã„ã‹ãªã„å•é¡Œ<br><br>  - SELF-INSTRUCTã‚‚ã€çµå±€pre-trainingã®æ®µéšã§é »å‡ºã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚„instructionã«å¯¾ã—ã¦gainãŒã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã€ä¸€èˆ¬çš„ã§ãªãã€creativeãªinstructionã«å¯¾ã—ã¦è„†å¼±æ€§ãŒã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹<br><br>- Dependence on laege models<br><br>  - ã§ã‹ã„ãƒ¢ãƒ‡ãƒ«ã‚’æ‰±ãˆã‚‹ã ã‘ã®resourceã‚’æŒã£ã¦ã„ãªã„ã¨ä½¿ãˆãªã„ã¨ã„ã†å•é¡ŒãŒã‚ã‚‹<br><br>- Reinforcing LM biases<br><br>  - ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®iterationã«ã‚ˆã£ã¦ã€å•é¡Œã®ã‚ã‚‹social _biasã‚’ã‚ˆã‚Šå¢—å¹…ã—ã¦ã—ã¾ã†ã“ã¨ã‚’æ‡¸å¿µã—ã¦ã„ã‚‹ï¼ˆäººç¨®ã€ç¨®æ—ãªã©ã«å¯¾ã™ã‚‹åè¦‹ãªã©ï¼‰ã€‚ã¾ãŸã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒé›£ã—ã„ã€‚</p>
<p>1ã®prompt<br><br>&lt;img width="801" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/228717376-62648df4-e587-49f7-8e71-afd1b2269e90.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/228717376-62648df4-e587-49f7-8e71-afd1b2269e90.png"&lt;/a&gt;


&gt;<br><br>2ã®prompt<br><br>&lt;img width="871" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/228717413-115f8ccf-b85e-4530-b489-cbf1de69341b.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/228717413-115f8ccf-b85e-4530-b489-cbf1de69341b.png"&lt;/a&gt;


&gt;<br><br>3ã®promptï¼ˆinput-first-approachï¼‰<br><br>&lt;img width="853" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/228717477-58b44a4e-ce44-452f-9b3a-4a348584e40f.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/228717477-58b44a4e-ce44-452f-9b3a-4a348584e40f.png"&lt;/a&gt;


&gt;<br><br>3ã®promptï¼ˆoutput-first approachï¼‰<br><br>&lt;img width="803" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/228717535-8717405c-bdaf-455c-9d4b-480bf6494abe.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/228717535-8717405c-bdaf-455c-9d4b-480bf6494abe.png"&lt;/a&gt;


&gt;</p>
<p>â€» GPT3ã‚’finetuningã™ã‚‹ã®ã«ã€Instruction Dataã‚’ä½¿ã£ãŸå ´åˆ$338ã‹ã‹ã£ãŸã£ã½ã„ã€‚å®‰ã„ãƒ»ãƒ»ãƒ»ã€‚</p>
<p>LLMã‚’ä½¿ã†ã ã‘ã§ã“ã“ã¾ã§ç ”ç©¶ãŒã§ãã‚‹æ™‚ä»£ãŒããŸ</p>
<p>ï¼ˆæœ€è¿‘ã¯|ç¾åœ¨ã¯ï¼‰ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãªLLMã®å‡ºåŠ›ã‚’åˆ©ç”¨ã—ã¦ç«¶åˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã“ã¨ã¯å¤šãã®å ´åˆç¦æ­¢ã•ã‚Œã¦ã„ã‚‹ã®ã§æ³¨æ„ã€‚</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-03-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/512" target="_blank" rel="noopener noreferrer" class="title-link">Reflexion: Language Agents with Verbal Reinforcement Learning, Noah Shinn+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹Reflexionã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚Reflexionã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€è¨€èªçš„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€šã˜ã¦è‡ªå·±åçœã—ã€ã‚ˆã‚Šè‰¯ã„æ„æ€æ±ºå®šã‚’ä¿ƒã™ãŸã‚ã«åçœçš„ãªãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿æŒã—ã¾ã™ã€‚Reflexionã¯ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã§ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«æ¯”ã¹ã¦å¤§å¹…ãªæ”¹å–„ã‚’å®Ÿç¾ã—ã€å¾“æ¥ã®æœ€å…ˆç«¯ã®GPT-4ã‚’ä¸Šå›ã‚‹ç²¾åº¦ã‚’é”æˆã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ç•°ãªã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¿¡å·ã‚„çµ±åˆæ–¹æ³•ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®ç ”ç©¶ã‚’è¡Œã„ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¸ã®å½±éŸ¿ã«ã¤ã„ã¦ã®æ´å¯Ÿã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãªãœå›ç­”ã‚’é–“é•ãˆãŸã®ã‹è‡ªå·±åçœã•ã›ã‚‹ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/EACL.html" target="_blank" rel="noopener noreferrer">#EACL</a>
<span class="issue_date">Issue Date: 2022-10-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/490" target="_blank" rel="noopener noreferrer" class="title-link">MTEB: Massive Text Embedding Benchmark, Muennighoff+, EACL'23</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ã®è©•ä¾¡ã¯é€šå¸¸å°è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é™ã‚‰ã‚Œã€ä»–ã®ã‚¿ã‚¹ã‚¯ã¸ã®é©ç”¨å¯èƒ½æ€§ãŒä¸æ˜ã§ã‚ã‚‹ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€58ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨112ã®è¨€èªã‚’ã‚«ãƒãƒ¼ã™ã‚‹Massive Text Embedding Benchmarkï¼ˆMTEBï¼‰ã‚’å°å…¥ã—ã€33ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã—ãŸã€‚çµæœã€ç‰¹å®šã®æ‰‹æ³•ãŒå…¨ã‚¿ã‚¹ã‚¯ã§å„ªä½ã«ç«‹ã¤ã“ã¨ã¯ãªãã€æ™®éçš„ãªãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿æ‰‹æ³•ã«ã¯è‡³ã£ã¦ã„ãªã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚MTEBã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/EACL.html" target="_blank" rel="noopener noreferrer">#EACL</a>
<span class="issue_date">Issue Date: 2022-09-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/482" target="_blank" rel="noopener noreferrer" class="title-link">Long Document Summarization with Top-down and Bottom-up Inference, Pang+, Salesforce Research, EACL'23</a>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬: 


<a href="https://zenn.dev/ty_nlp/articles/9f5e5dd3084dbd" target="_blank" rel="noopener noreferrer">https://zenn.dev/ty_nlp/articles/9f5e5dd3084dbd</a>


<br><br><br><br>ä»¥ä¸‹ã€ä¸Šè¨˜æ—¥æœ¬èªè§£èª¬è¨˜äº‹ã‚’èª­ã‚“ã§ç†è§£ã—ãŸå†…å®¹ã‚’ã¾ã¨ã‚ã¾ã™ã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚<br><br><br><br># æ¦‚è¦<br><br>åŸºæœ¬çš„ã«Transformerãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆe.g. BERTSum, BART, PEGASUS, GPT-2, T5ï¼‰ã§ã¯self-attentionã®è¨ˆç®—é‡ãŒå…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°Nã«å¯¾ã—ã¦O(N^2)ã§ã‹ã‹ã‚Šã€å…¥åŠ›ã®äºŒä¹—ã®ã‚ªãƒ¼ãƒ€ãƒ¼ã§è¨ˆç®—é‡ãŒå¢—ãˆã¦ã—ã¾ã†ã€‚<br><br>ã“ã‚Œã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã«self-attentionã‚’è¨ˆç®—ã™ã‚‹ç¯„å›²ã‚’ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã§åˆ¶é™ã™ã‚‹Longformerã‚„ã€BigBardãªã©ãŒææ¡ˆã•ã‚Œã¦ããŸãŒã€ã©ã¡ã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã‚‚é›¢ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³é–“ã®attentionã®æƒ…å ±ãŒæ¬ è½ã™ã‚‹ãŸã‚ã€é•·è·é›¢ã®ãƒˆãƒ¼ã‚¯ãƒ³é–“ã®é–¢ä¿‚æ€§ã‚’æ‰ãˆã«ãããªã£ã¦ã—ã¾ã†å•é¡ŒãŒã‚ã£ãŸã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/188084569-ec574f6f-cc31-48db-aef5-0a3fedea816c.png" alt="image" loading="lazy"><br><br><br><br>ãã“ã§ã€top-down transformerã§ã¯ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯ãƒ†ã‚­ã‚¹ãƒˆã§ã„ã†ã¨ã“ã‚ã®æ–‡ï¼‰ã¨ã„ã†æ¦‚å¿µã‚’æå”±ã—ã€tokenã‹ã‚‰segmentã®representationã‚’ç”Ÿæˆã—ãã®å¾Œself-attentionã§segmenté–“ã®é–¢ä¿‚æ€§ã‚’è€ƒæ…®ã—ã¦segmentã®representationã‚’ç”Ÿæˆã™ã‚‹bottom-up inferenceã€å„tokenã¨segmentã®é–¢ä¿‚æ€§ã‚’è€ƒæ…®ã—ã—å„tokenã®representationã‚’å­¦ç¿’ã™ã‚‹top-down inferenceã®2ã¤ã®æ§‹é€ ã‚’åˆ©ç”¨ã—ãŸã€‚bottom-up inferenceã«ãŠã„ã¦segmentã®representationã‚’è¨ˆç®—ã™ã‚‹éš›ã«poolingã‚’å®Ÿæ–½ã™ã‚‹ãŒã€adapoolingã¨å‘¼ã°ã‚Œã‚‹é‡è¦ãªãƒˆãƒ¼ã‚¯ãƒ³ã«é‡ã¿ä»˜ã‘ã‚’ã—ã€ãã®é‡ã¿ã‚’åŠ å‘³ã—ãŸåŠ é‡å¹³å‡ã«ã‚ˆã‚Šãƒ—ãƒ¼ãƒªãƒ³ã‚°ã‚’å®Ÿæ–½ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¾—ã‚‰ã‚ŒãŸå„ãƒˆãƒ¼ã‚¯ãƒ³ã®è¡¨ç¾ã¯ã€å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã®é–¢é€£åº¦ã®æƒ…å ±ã‚’å«ã¿ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®è¡¨ç¾ã¯å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“ã®attentnionã«åŸºã¥ã„ã¦è¨ˆç®—ã•ã‚Œã¦ã„ã‚‹ãŸã‚; bottom-up inferenceï¼‰ã€ã‹ã¤å„ãƒˆãƒ¼ã‚¯ãƒ³ã¨å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“ã¨ã®é–¢é€£åº¦ã‚‚è€ƒæ…®ã—ã¦è¨ˆç®—ã•ã‚Œã¦ã„ã‚‹ãŸã‚ï¼ˆtop-down inferenceï¼‰ã€çµæœçš„ã«é›¢ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³é–“ã®é–¢é€£åº¦ã‚’è€ƒæ…®ã—ãŸrepresentationãŒå­¦ç¿’ã•ã‚Œã‚‹ï¼ˆä¸‹å›³ï¼‰ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/188085213-affc953b-b4a6-4f34-8fa0-71d3ddb173b4.png" alt="image" loading="lazy"><br><br>ï¼ˆå›³ã¯ä¸Šè¨˜è¨˜äº‹ã‹ã‚‰ãŠå€Ÿã‚Šã„ãŸã—ã¾ã—ãŸï¼‰<br><br><br><br>å„attentionã®è¨ˆç®—é‡ã¯è¡¨ã®ã‚ˆã†ã«ãªã‚Šã€M, wã¯Nã‚ˆã‚Šã‚‚é¥ã‹ã«å°ã•ã„ãŸã‚ã€O(N^2)ã‚ˆã‚Šã‚‚é¥ã‹ã«å°ã•ã„è¨ˆç®—é‡ã§è¨ˆç®—ã§ãã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/188086050-985d4fc6-3b1b-4ff1-b268-b6bda24581f5.png" alt="image" loading="lazy"><br><br>ï¼ˆã“ã¡ã‚‰ã‚‚ä¸Šè¨˜è¨˜äº‹ã‹ã‚‰ãŠå€Ÿã‚Šã„ãŸã—ã¾ã—ãŸï¼‰<br><br><br><br># å®Ÿé¨“ï¼ˆæ—¥æœ¬èªè§£èª¬ã‚ˆã‚Šï¼‰<br><br>## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br><br><img src="https://user-images.githubusercontent.com/12249301/188086312-769ef574-3f91-4f12-b015-ac9c02dc93ff.png" alt="image" loading="lazy"><br><br><br><br>## çµæœ<br><br>### PubMedã¨arXiv<br><br><img src="https://user-images.githubusercontent.com/12249301/188086389-c3e49a19-51b1-437c-9802-1e62c9fd4329.png" alt="image" loading="lazy"><br><br><br><br>### CNN-DailyMail<br><br><img src="https://user-images.githubusercontent.com/12249301/188086914-9476f30d-481c-4113-8f6b-edeb906ac696.png" alt="image" loading="lazy"><br><br><br><br>### TVMegasSiteã¨ForeverDreaming<br><br><img src="https://user-images.githubusercontent.com/12249301/188086972-c355854b-9f1f-4f88-9e36-06536963541b.png" alt="image" loading="lazy"><br><br><br><br>### BookSum-Chapter-Level<br><br><img src="https://user-images.githubusercontent.com/12249301/188087045-0ac57b5a-5c6c-49e4-a82a-3e57f5e8b788.png" alt="image" loading="lazy"><br><br><br><br>### BookSum-Book-Level<br><br><img src="https://user-images.githubusercontent.com/12249301/188087112-2d310059-72d1-4968-bf09-cdcf0e6afc2d.png" alt="image" loading="lazy"><br><br><br><br>## æ‰€æ„Ÿ<br><br>CNN-DailyMailã®ã‚ˆã†ãªinput wordsãŒ900ç¨‹åº¦ã®ãƒ‡ãƒ¼ã‚¿ã§ã¯comparableãªçµæœã¨ãªã£ã¦ã„ã‚‹ãŒã€input wordsãŒé•·ã„å ´åˆã¯å…ˆè¡Œç ”ç©¶ã‚’outperformã—ã¦ã„ã‚‹ã€‚BookSum-Chapter Levelã«ãŠã„ã¦ã€Longformer, BigBirdã®æ€§èƒ½ãŒæ‚ªãã€BART, T5, Pegasusã®æ€§èƒ½ãŒè‰¯ã„ã®ãŒè¬ã„ã€‚<br><br>ã¦ã‹input wordsãŒ3000~7000ç¨‹åº¦ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã€ã©ã†ã‚„ã£ã¦BARTã‚„ã‚‰T5ã‚„ã‚‰ã‚’å®Ÿè£…ã§ãã‚‹ã‚“ã ã‚ã†ã€‚å¤§æŠµ512 tokenãã‚‰ã„ãŒé™ç•Œã ã¨æ€ã£ã¦ã„ãŸã®ã ãŒã€ã©ã†ã‚„ã£ãŸã‚“ã ãƒ»ãƒ»ãƒ»ã€‚</p>
<p>&gt;The maximum document lengths for PubMed, arXiv, CNN-DM,<br><br>TVMegaSite, ForeverDreaming, BookSum are 8192, 16384, 1024, 12288, 12288, 12288, respectively<br><br><br><br>ã“ã‚Œã¯ã€ãŸã¨ãˆã°BookSumã®å ´åˆã¯ä»®ã«inputã®é•·ã•ãŒ11ä¸‡ã¨ã‹ã‚ã£ãŸã¨ã—ã¦ã‚‚ã€12288ã§truncateã—ãŸã¨ã„ã†ã“ã¨ã ã‚ã†ã‹ã€‚ã¾ã‚ãªã‚“ã«ã›ã‚ˆã€é ‘å¼µã‚Œã°ã“ã®ãã‚‰ã„ã®ç³»åˆ—é•·ã®ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã§ãã‚‹ã¨ã„ã†ã“ã¨ã‹ï¼ˆãƒ¡ãƒ¢ãƒªã«ä¹—ã‚‹ã®ã‹ãƒ»ãƒ»ãƒ»ï¼Ÿã©ã‚“ãªåŒ–ã‘ç‰©ãƒã‚·ãƒ³ã‚’ä½¿ã£ã¦ã„ã‚‹ã®ã‹ï¼‰ã€‚</p>
<p>&gt;We first train a top-down transformer on the chapter-level data and then fine-tune it on the book-level<br><br>data. The inputs to the book-level model are (1) the concatenated chapter reference summaries in<br><br>training or (2) the concatenated chapter summaries generated by the chapter-level model in testing.<br><br>The chapter-to-book curriculum training is to mitigate the scarcity of book-level data. The recursive<br><br>summarization of chapters and then books can be considered abstractive content selection applied<br><br>to book data, and is used to address the extremely long length of books.<br><br><br><br>BookLevel Summarizationã§ã¯ã€ãƒ‡ãƒ¼ã‚¿æ•°ãŒ300ä»¶ç¨‹åº¦ã—ã‹ãªãã€ã‹ã¤input wordsãŒã§ã‹ã™ãã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€ã¾ãštop-down transformerã‚’chapter-level_ dataã§è¨“ç·´ã—ã¦ã€ãã®å¾Œbook-level dataã§fine-tuningã€‚book-level dataã§fine-tuningã™ã‚‹éš›ã«ã¯ã€chapterã”ã¨ã®reference summaryã‚’concatã—ãŸã‚‚ã®ã‚’æ­£è§£ã¨ã—ã€chapter-level modelãŒç”Ÿæˆã—ãŸchapterã”ã¨ã®summaryã‚’concatã—ãŸã‚‚ã®ã‚’ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã—ãŸè¦ç´„ã¨ã—ã¦æ‰±ã£ãŸã€ã¨ã„ã†æ„Ÿã˜ã ã‚ã†ã‹ã€‚ã¾ãšchapter levelã§å­¦ç¿’ã—ãã®å¾Œbook levelã§å­¦ç¿’ã™ã‚‹curriculum learningã£ã½ã„ã‚„ã‚Šæ–¹ãŒbook-level dataã®ä¸è¶³ã‚’ç·©å’Œã—ã¦ãã‚Œã‚‹ã€‚bookã®è¦ç´„ã‚’å¾—ã‚‹ãŸã‚ã«chapterã‚’å†å¸°çš„ã«è¦ç´„ã™ã‚‹ã‚ˆã†ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€book dataã«å¯¾ã™ã‚‹content selectionã¨ã—ã¦ã¿ãªã™ã“ã¨ãŒã§ãã€ãŠãã‚ã—ã„ã»ã©é•·ã„å…¥åŠ›ã®å¯¾å‡¦ã«ã‚‚ãªã£ã¦ã„ã‚‹ã€ã¨ã„ã†æ„Ÿã˜ã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3110" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Mixture of Attention Heads: Selecting Attention Heads Per Token, Xiaofeng Zhang+, EMNLP'22, 2022.10</a>
<span class="snippet"><span>GPT Summary</span>- Mixture of Attention Heads (MoA)ã¯ã€MoEãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’çµ„ã¿åˆã‚ã›ãŸæ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã€å‹•çš„ã«é¸æŠã•ã‚ŒãŸã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ‰ã®ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚²ãƒ¼ãƒˆåŒ–ã«ã‚ˆã‚Šè¨ˆç®—åŠ¹ç‡ã‚’ä¿ã¡ãªãŒã‚‰æ‹¡å¼µå¯èƒ½ã§ã€ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆå¯èƒ½æ€§ã«ã‚‚å¯„ä¸ã™ã‚‹ã€‚å®Ÿé¨“ã§ã¯ã€æ©Ÿæ¢°ç¿»è¨³ã‚„ãƒã‚¹ã‚¯ä»˜ãè¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãªã©ã®ã‚¿ã‚¹ã‚¯ã§å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>FFNã«é©ç”¨ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã‹ã£ãŸMoEã‚’multi-head attention (MHA) ã«é©ç”¨ã™ã‚‹ç ”ç©¶ã€‚ã“ã®ã‚ˆã†ãªattentionã‚’Mixture of Attention Heads (MoA)ã¨å‘¼ã¶ã€‚<br><br>å„MHAã¯è¤‡æ•°ã®attention expertsã‚’æŒã¡ã€ãã®ä¸­ã‹ã‚‰Kå€‹ã®ExpertsãŒç¾åœ¨ã®ã‚¯ã‚¨ãƒªq_tã«åŸºã¥ã„ã¦Routerã«ã‚ˆã£ã¦é¸å‡ºï¼ˆå¼7, 8)ã•ã‚Œã‚‹ã€‚ãã‚Œãã‚Œã®attention expertsã«å¯¾ã—ã¦q_tãŒæµã•ã‚Œã€é€šå¸¸ã®MHAã¨åŒã˜æµã‚Œã§outputãŒè¨ˆç®—ã•ã‚Œã€æœ€çµ‚çš„ã«é¸æŠã•ã‚ŒãŸéš›ã®ï¼ˆæ­£è¦åŒ–ã•ã‚ŒãŸï¼ˆå¼9ï¼‰ï¼‰probabilityã«ã‚ˆã‚‹åŠ é‡å¹³å‡ã«ã‚ˆã£ã¦å‡ºåŠ›ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆå¼6)ã€‚<br><br>æ³¨æ„ç‚¹ã¨ã—ã¦ã¯ã€å„attention expertsã¯ç‹¬ç«‹ã—ãŸprojection matrix W_q, W_oï¼ˆãã‚Œãã‚Œiç•ªç›®ã®expertsã«ãŠã‘ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³tã«ãŠã„ã¦ã€query q_tã‚’å¤‰æ›ã€output o_{i,t}ã‚’hidden spaceæ¬¡å…ƒã«æˆ»ã™å½¹å‰²ã‚’æŒã¤)ã‚’æŒã¤ãŒã€K, Vã«å¯¾ã™ã‚‹å¤‰æ›è¡Œåˆ—ã¯å…±æœ‰ã™ã‚‹ã¨è¨€ã†ç‚¹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ¬¡å…ƒã«å…¨ã¦ã®expertsã«å¯¾ã—ã¦k, vã«å¯¾ã™ã‚‹å¤‰æ›ã¯è¨ˆç®—ã—ã¦ãŠã‘ã‚‹ã®ã§ã€headã”ã¨ã«ç•°ãªã‚‹å¤‰æ›ã‚’å­¦ç¿’ã—ãªãŒã‚‰ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å¤§å¹…ã«å‰Šæ¸›ã§ãã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/3073c6b8-cdc7-4303-8881-0c07c502d0ec" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/d74ab1b7-e44c-461d-ad64-6f5ecacd8da2" alt="image" loading="lazy"><br><br>ã¾ãŸã€ç‰¹å®šã®expertsã«ã®ã¿ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãŒé›†ä¸­ã—ãªã„ã‚ˆã†ã«ã€lossã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§å­¦ç¿’ã®å®‰å®šã•ã›æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã¦ã„ã‚‹ï¼ˆ4.3ç¯€ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/PseudoLabeling.html" target="_blank" rel="noopener noreferrer">#PseudoLabeling</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2903" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Constitutional AI: Harmlessness from AI Feedback, Yuntao Bai+, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã€Œæ†²æ³•çš„AIã€ã‚’ç”¨ã„ã¦ã€äººé–“ã®ãƒ©ãƒ™ãƒ«ãªã—ã§ç„¡å®³ãªAIã‚’è¨“ç·´ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚ç›£è¦–å­¦ç¿’ã¨å¼·åŒ–å­¦ç¿’ã®2ãƒ•ã‚§ãƒ¼ã‚ºã‚’çµŒã¦ã€è‡ªå·±æ‰¹è©•ã¨ä¿®æ­£ã‚’é€šã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã€å—œå¥½ãƒ¢ãƒ‡ãƒ«ã‚’å ±é…¬ä¿¡å·ã¨ã—ã¦å¼·åŒ–å­¦ç¿’ã‚’è¡Œã†ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æœ‰å®³ãªã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ã‚‚å¯¾è©±ã§ãã‚‹ç„¡å®³ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’å®Ÿç¾ã—ã€AIã®æ„æ€æ±ºå®šã®é€æ˜æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ï¼ˆéƒ¨åˆ†çš„ã«ã—ã‹èª­ã‚ã¦ã„ãªã„ãŒï¼‰<br>æœ‰å®³ãªpromptã«å¯¾ã—ã¦LLMã«åˆæœŸã®å¿œç­”ã‚’ç”Ÿæˆã•ã›ã€iterativeã«critiqueã¨revisionã‚’ç¹°ã‚Šè¿”ã—ã¦[^1]ã€ã‚ˆã‚Šç„¡å®³ãªå¿œç­”ã‚’ç”Ÿæˆã€‚ã“ã®æ–¹æ³•ã§ã¯iterationã‚’ã—ãªãŒã‚‰ç”ŸæˆçµæœãŒæ”¹å®šã•ã‚Œã¦ã„ãã®ã§ã€å¾Œæ®µã®Reward Modelã®ãŸã‚ã®å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ãƒ•ã‚§ãƒ¼ã‚ºã§ãƒˆãƒ¼ã‚¯ãƒ³é‡ã‚’ç¯€ç´„ã™ã‚‹ãŸã‚ã«ã€ç”Ÿæˆã•ã‚ŒãŸã‚ˆã‚Šç„¡å®³ãªå¿œç­”ã¨å…ƒã¨ãªã‚‹promptã‚’ç”¨ã„ã¦ã€ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’SFTã€‚ã“ã‚Œã«ã‚ˆã‚Šãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›åˆ†å¸ƒãŒã‚ˆã‚Šç„¡å®³ãªå¿œç­”ã‚’ã™ã‚‹ã‚ˆã†ãªæ–¹å‘æ€§ã«èª¿æ•´ã•ã‚Œã€ã‹ã¤ï¼ˆiterationã‚’ç¹°ã‚Šè¿”ã™ã“ã¨ãªãï¼‰ç›´æ¥çš„ã«ã‚ˆã‚Šç„¡å®³ãªå¿œç­”ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã®ã§tokené‡ãŒç¯€ç´„ã§ãã‚‹ã€‚ã“ã®ãƒ•ã‚§ãƒ¼ã‚ºã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’SL-CAIã¨å‘¼ã¶ã€‚<br><br>ç¶šã„ã¦ã€SL-CAIã«å¯¾ã—ã¦åŒæ§˜ã®æœ‰å®³ãªpromptã‚’å…¥åŠ›ã—ã¦ã€è¤‡æ•°ã®å¿œç­”ã‚’ç”Ÿæˆã•ã›ã‚‹ã€‚ç”Ÿæˆã•ã‚ŒãŸå¿œç­”ã‚’Multiple Choice Questionã®å½¢å¼ã«ã—ã€Constitutional Principleã«åŸºã¥ãpromptingã«ã‚ˆã‚Šã€æœ€ã‚‚æœ›ã¾ã—ã„å¿œç­”ã‚’LLMã«ã‚ˆã£ã¦é¸æŠã•ã›ã‚‹ã“ã¨ã§ã€å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚’ç²å¾—ã™ã‚‹ã€‚ã“ã®å—œå¥½ãƒ‡ãƒ¼ã‚¿ï¼ˆã¨äººæ‰‹ã§å®šç¾©ã•ã‚ŒãŸhelpfulnessã«åŸºã¥ããƒ‡ãƒ¼ã‚¿ï¼‰ã‚’ç”¨ã„ã¦Reward Modelã‚’è¨“ç·´ã—RLã‚’å®Ÿæ–½ã™ã‚‹ã€‚<br><br>ã“ã®æ‰‹æ³•ã¯ã€å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚’äººé–“ãŒãƒ©ãƒ™ãƒªãƒ³ã‚°ã™ã‚‹ã®ã§ã¯ãªãã€AIã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ã‚ˆã‚Šãƒ©ãƒ™ãƒªãƒ³ã‚°ã™ã‚‹ãŸã‚ã€Reinforcement Learning from AI Feedback (RLAIF)ã¨å‘¼ã°ã‚Œã‚‹ã€‚<br><br>Harmfulnessä»¥å¤–ã®åˆ†é‡ã«ã‚‚å¿œç”¨å¯èƒ½ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/72305618-d397-4471-8648-7771d371ca43" alt="image" loading="lazy"><br><br>[^1]: ã“ã®æ“ä½œã¯ãƒ¢ãƒ‡ãƒ«ã®æœ›ã¾ã—ã„æŒ™å‹•ã‚’äººæ‰‹ã§å®šç¾©ã—ãŸãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã«åŸºã¥ã„ãŸè¤‡æ•°ã®prompt (Constitutional Principles) ã‚’ç”¨ã„ã¦å®Ÿæ–½ã•ã‚Œã‚‹ã€‚å…·ä½“çš„ãªpromptã¯Appendix Cã‚’å‚ç…§ã€‚</p>
<p>å…ˆè¡Œç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2902" target="_blank" rel="noopener noreferrer">[Paper Note] Training a Helpful and Harmless Assistant with Reinforcement Learning
  from Human Feedback, Yuntao Bai+, arXiv'22</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2902" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Training a Helpful and Harmless Assistant with Reinforcement Learning  from Human Feedback, Yuntao Bai+, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç„¡å®³ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã—ã¦æ©Ÿèƒ½ã•ã›ã‚‹ãŸã‚ã«ã€å¥½ã¿ã®ãƒ¢ãƒ‡ãƒ«åŒ–ã¨äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‹ã‚‰ã®å¼·åŒ–å­¦ç¿’ï¼ˆRLHFï¼‰ã‚’ç”¨ã„ã¦å¾®èª¿æ•´ã‚’è¡Œã„ã€NLPè©•ä¾¡ã§ã®æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã€‚æ¯é€±æ–°ã—ã„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°ã—ã€åŠ¹ç‡çš„ãªæ”¹å–„ã‚’å›³ã‚‹ã€‚RLHFãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å …ç‰¢æ€§ã‚’èª¿æŸ»ã—ã€ãƒãƒªã‚·ãƒ¼ã¨åˆæœŸåŒ–ã¨ã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã®é–¢ä¿‚ã‚’ç‰¹å®šã€‚ãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ç«¶åˆç›®çš„ã«ã¤ã„ã¦ã‚‚åˆ†æã—ã€äººé–“ã®ä½œå®¶ã¨ã®æ¯”è¼ƒã‚’è¡Œã£ãŸã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2860" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Emergent Abilities of Large Language Models, Jason Wei+, TMLR'22</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚¢ãƒƒãƒ—ã¯æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ã€Œå‡ºç¾èƒ½åŠ›ã€ã¨å‘¼ã°ã‚Œã‚‹äºˆæ¸¬ä¸å¯èƒ½ãªç¾è±¡ãŒå­˜åœ¨ã™ã‚‹ã€‚ã“ã‚Œã¯å°å‹ãƒ¢ãƒ‡ãƒ«ã«ã¯ãªã„èƒ½åŠ›ã§ã‚ã‚Šã€ã•ã‚‰ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’æ‹¡å¤§ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=yzkSU5zdwD" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=yzkSU5zdwD</a>


</p>
<p>å‰µç™ºèƒ½åŠ›ï¼ˆæœ€è¿‘ã“ã®ç”¨èªã‚’ç›®ã«ã™ã‚‹æ©Ÿä¼šãŒæ¸›ã£ãŸã‚ˆã†ãªæ°—ãŒã™ã‚‹ï¼‰</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Deduplication.html" target="_blank" rel="noopener noreferrer">#Deduplication</a>
<span class="issue_date">Issue Date: 2025-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2689" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deduplicating Training Data Makes Language Models Better, Katherine Lee+, ACL'22</a>
<span class="snippet"><span>GPT Summary</span>- æ—¢å­˜ã®è¨€èªãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯é‡è¤‡ã—ãŸä¾‹ãŒå¤šãå«ã¾ã‚Œã€è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã®1%ä»¥ä¸ŠãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚³ãƒ”ãƒ¼ã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€é‡è¤‡æ’é™¤ãƒ„ãƒ¼ãƒ«ã‚’é–‹ç™ºã—ã€C4ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ã¯60,000å›ä»¥ä¸Šç¹°ã‚Šè¿”ã•ã‚Œã‚‹æ–‡ã‚’å‰Šé™¤ã€‚é‡è¤‡ã‚’æ’é™¤ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®è¨˜æ†¶ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ã‚’10å€æ¸›å°‘ã•ã›ã€ç²¾åº¦ã‚’ç¶­æŒã—ã¤ã¤è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—ã‚’å‰Šæ¸›ã€‚ã¾ãŸã€è¨“ç·´ã¨ãƒ†ã‚¹ãƒˆã®é‡è¤‡ã‚’æ¸›ã‚‰ã—ã€ã‚ˆã‚Šæ­£ç¢ºãªè©•ä¾¡ã‚’å®Ÿç¾ã€‚ç ”ç©¶ã®å†ç¾ã¨ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä¸‹è¨˜ã‚¹ãƒ©ã‚¤ãƒ‰ã®p.9ã«ã¾ã¨ã‚ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹:<br>


<a href="https://speakerdeck.com/takase/snlp2023-beyond-neural-scaling-laws?slide=9" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/takase/snlp2023-beyond-neural-scaling-laws?slide=9</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-09-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2644" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] StableMoE: Stable Routing Strategy for Mixture of Experts, Damai Dai+, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- StableMoEã¯ã€ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®å¤‰å‹•å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«2ã¤ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’æŒã¤Mixture-of-Expertsæ‰‹æ³•ã‚’ææ¡ˆã€‚æœ€åˆã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§ä¸€è²«ã—ãŸãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ã‚’å­¦ç¿’ã—ã€è»½é‡ãƒ«ãƒ¼ã‚¿ãƒ¼ã«è’¸ç•™ã€‚ç¬¬äºŒã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§ãã®ãƒ«ãƒ¼ã‚¿ãƒ¼ã‚’ç”¨ã„ã¦ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã¸ã®å‰²ã‚Šå½“ã¦ã‚’å›ºå®šã€‚è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã¨å¤šè¨€èªæ©Ÿæ¢°ç¿»è¨³ã§ã®å®Ÿé¨“ã«ã‚ˆã‚Šã€StableMoEã¯åæŸé€Ÿåº¦ã¨æ€§èƒ½ã§æ—¢å­˜æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vikhyatk/status/1962225296314429543?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2311" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Matryoshka Representation Learning, Aditya Kusupati+, NeurIPS'22</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒˆãƒªãƒ§ãƒ¼ã‚·ã‚«è¡¨ç¾å­¦ç¿’ï¼ˆMRLï¼‰ã¯ã€ç•°ãªã‚‹è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã«é©å¿œå¯èƒ½ãªæŸ”è»Ÿãªè¡¨ç¾ã‚’è¨­è¨ˆã™ã‚‹æ‰‹æ³•ã§ã‚ã‚Šã€æ—¢å­˜ã®è¡¨ç¾å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æœ€å°é™ã«ä¿®æ­£ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚MRLã¯ã€ç²—ã‹ã‚‰ç´°ã¸ã®è¡¨ç¾ã‚’å­¦ç¿’ã—ã€ImageNet-1Kåˆ†é¡ã§æœ€å¤§14å€å°ã•ã„åŸ‹ã‚è¾¼ã¿ã‚µã‚¤ã‚ºã‚’æä¾›ã—ã€å®Ÿä¸–ç•Œã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å®Ÿç¾ã—ã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆåˆ†é¡ã§ç²¾åº¦å‘ä¸Šã‚’é”æˆã—ã¾ã™ã€‚MRLã¯è¦–è¦šã€è¦–è¦š+è¨€èªã€è¨€èªã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«ã‚ãŸã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«æ‹¡å¼µå¯èƒ½ã§ã€ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://speakerdeck.com/hpprc/lun-jiang-zi-liao-matryoshka-representation-learning" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/hpprc/lun-jiang-zi-liao-matryoshka-representation-learning</a>


</p>
<p>å˜ä¸€ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰è¤‡æ•°ã®lengthã®Embeddingã‚’å‡ºåŠ›ã§ãã‚‹ã‚ˆã†ãªæ‰‹æ³•ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultitaskLearning.html" target="_blank" rel="noopener noreferrer">#MultitaskLearning</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2183" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Perceiver IO: A General Architecture for Structured Inputs &amp; Outputs, Andrew Jaegle+, ICLR'22</a>
<span class="snippet"><span>GPT Summary</span>- æ±ç”¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£Perceiver IOã‚’ææ¡ˆã—ã€ä»»æ„ã®ãƒ‡ãƒ¼ã‚¿è¨­å®šã«å¯¾å¿œã—ã€å…¥åŠ›ã¨å‡ºåŠ›ã®ã‚µã‚¤ã‚ºã«å¯¾ã—ã¦ç·šå½¢ã«ã‚¹ã‚±ãƒ¼ãƒ«å¯èƒ½ã€‚æŸ”è»Ÿãªã‚¯ã‚¨ãƒªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’è¿½åŠ ã—ã€ã‚¿ã‚¹ã‚¯ç‰¹æœ‰ã®è¨­è¨ˆã‚’ä¸è¦ã«ã€‚è‡ªç„¶è¨€èªã€è¦–è¦šç†è§£ã€ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ã§å¼·åŠ›ãªçµæœã‚’ç¤ºã—ã€GLUEãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§BERTã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å½“æ™‚ç›¸å½“è©±é¡Œã¨ãªã£ãŸã•ã¾ã–ã¾ãªãƒ¢ãƒ¼ãƒ€ãƒ«ã‚’çµ±ä¸€ã•ã‚ŒãŸæ çµ„ã¿ã§æ‰±ãˆã‚‹Perceiver IOè«–æ–‡<br><img src="https://github.com/user-attachments/assets/d7893f14-d69c-4af8-8117-08c2a6095e8e" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<span class="issue_date">Issue Date: 2025-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2141" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On Layer Normalizations and Residual Connections in Transformers, Sho Takase+, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼æ­£è¦åŒ–ã®ä½ç½®ã«é–¢ã™ã‚‹Post-LNã¨Pre-LNã®é•ã„ã‚’èª¿æŸ»ã€‚Post-LNã¯æµ…ã„å±¤ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ä¸€æ–¹ã€æ·±ã„å±¤ã§ã¯ä¸å®‰å®šãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¼•ãèµ·ã“ã™æ¶ˆå¤±å‹¾é…å•é¡ŒãŒã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚ã“ã‚Œã‚’è¸ã¾ãˆã€Post-LNã®ä¿®æ­£ã«ã‚ˆã‚Šå®‰å®šã—ãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿç¾ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã€å®Ÿé¨“ã§Pre-LNã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Pre-LNã®å®‰å®šæ€§ã‚’æŒã¡ãªãŒã‚‰ã‚‚Post-LNã®ã‚ˆã†ãªé«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹è‰¯ã„ã¨ã“å–ã‚Šã®B2TConnectionã‚’ææ¡ˆ<br><img src="https://github.com/user-attachments/assets/4d85bf16-19e4-4d2a-85e5-87da45cd2a98" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/af0aeae5-554a-4997-96a3-929cd7dd90bb" alt="image" loading="lazy"></p>
<p>NLP2022:


<a href="https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/A2-5.pdf" target="_blank" rel="noopener noreferrer">https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/A2-5.pdf</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2055" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Fast Model Editing at Scale, Eric Mitchell+, ICLR'22</a>
<span class="snippet"><span>GPT Summary</span>- MENDï¼ˆãƒ¢ãƒ‡ãƒ«ç·¨é›†ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã¯ã€äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œã‚’è¿…é€Ÿã‹ã¤å±€æ‰€çš„ã«ç·¨é›†ã™ã‚‹ãŸã‚ã®æ‰‹æ³•ã§ã€å˜ä¸€ã®å…¥åŠ›-å‡ºåŠ›ãƒšã‚¢ã‚’ç”¨ã„ã¦å‹¾é…åˆ†è§£ã‚’æ´»ç”¨ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€10å„„ä»¥ä¸Šã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã€1å°ã®GPUã§çŸ­æ™‚é–“ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¯èƒ½ã§ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€MENDãŒå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®ç·¨é›†ã«ãŠã„ã¦åŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=0DcZxeWfOPt" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=0DcZxeWfOPt</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1956" target="_blank" rel="noopener noreferrer" class="title-link">LoRA: Low-Rank Adaptation of Large Language Models, Edward J. Hu+, ICLR'22</a>
<span class="snippet"><span>GPT Summary</span>- LoRAã¯ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’å›ºå®šã—ã€å„å±¤ã«è¨“ç·´å¯èƒ½ãªãƒ©ãƒ³ã‚¯åˆ†è§£è¡Œåˆ—ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«å¿…è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤§å¹…ã«å‰Šæ¸›ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¨“ç·´å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’1ä¸‡åˆ†ã®1ã€GPUãƒ¡ãƒ¢ãƒªã‚’3åˆ†ã®1ã«æ¸›å°‘ã•ã›ãªãŒã‚‰ã€RoBERTaã‚„GPT-3ãªã©ã§åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’å®Ÿç¾ã—ã¾ã™ã€‚LoRAã®å®Ÿè£…ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenrReview:


<a href="https://openreview.net/forum?id=nZeVKeeFYf9" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=nZeVKeeFYf9</a>


</p>
<p>LoRAã‚‚ãªã‚“ã‚„ã‹ã‚“ã‚„ãƒ¡ãƒ¢ã£ã¦ãªã‹ã£ãŸã®ã§è¿½åŠ ã€‚<br><br>äº‹å‰å­¦ç¿’æ¸ˆã¿ã®Linear Layerã‚’freezeã—ã¦ã€freezeã—ãŸLinear Layerã¨å¯¾å¿œã™ã‚‹ä½ãƒ©ãƒ³ã‚¯ã®è¡Œåˆ—A,Bã‚’åˆ¥é€”å®šç¾©ã—ã€A,Bã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹PEFTæ‰‹æ³•ã§ã‚ã‚‹LoRAã‚’ææ¡ˆã—ãŸç ”ç©¶ã€‚ã‚ªãƒªã‚¸ãƒŠãƒ«ã®å‡ºåŠ›ã«å¯¾ã—ã¦ã€A,Bã«ã‚ˆã£ã¦å…¥åŠ›ã‚’å†™åƒã—ãŸãƒ™ã‚¯ãƒˆãƒ«ã‚’åŠ ç®—ã™ã‚‹ã€‚<br><br>ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°å­¦ã¯ã‚‹ã‹ã«å°‘ãªã„ã«ã‚‚é–¢ã‚ã‚‰ãšãƒ•ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ï¼ˆã“ã‚Œã¯è«¸èª¬ã‚ã‚‹ãŒï¼‰åŒç­‰ã®æ€§èƒ½ã§PostTrainingã§ãã‚‹ä¸Šã«ã€äº‹å‰å­¦ç¿’æ™‚ç‚¹ã§ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒfreezeã•ã‚Œã¦ã„ã‚‹ãŸã‚Catastrophic ForgettingãŒèµ·ãã¥ã‚‰ãï¼ˆãŸã ã—æ–°ã—ã„çŸ¥è­˜ã‚‚ç²å¾—ã—ã¥ã‚‰ã„ï¼‰ã€A,Bã®è¿½åŠ ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’ä¿å­˜ã™ã‚Œã°è‰¯ã„ã®ã§ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«å„ªã—ã„ã®ã‚‚å¬‰ã—ã„ã€‚</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2929" target="_blank" rel="noopener noreferrer">[Paper Note] LoRA-Pro: Are Low-Rank Adapters Properly Optimized?, Zhengbo Wang+, ICLR'25, 2024.07</a>
<br><br>ãªã©ã§ã‚‚ç¤ºã•ã‚Œã¦ã„ã‚‹ãŒã€ä¸€èˆ¬çš„ã«LoRAã¨Full Finetuningã‚’æ¯”è¼ƒã™ã‚‹ã¨LoRAã®æ–¹ãŒæ€§èƒ½ãŒä½ã„ã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ç‚¹ã«ã¯ç•™æ„ãŒå¿…è¦ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/CLIP.html" target="_blank" rel="noopener noreferrer">#CLIP</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1928" target="_blank" rel="noopener noreferrer" class="title-link">LAION-5B: An open large-scale dataset for training next generation   image-text models, Christoph Schuhmann+, NeurIPS'22</a>
<span class="snippet"><span>GPT Summary</span>- LAION-5Bã¯ã€5.85å„„ã®CLIPãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸç”»åƒ-ãƒ†ã‚­ã‚¹ãƒˆãƒšã‚¢ã‹ã‚‰æˆã‚‹å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€è‹±èªã®ãƒšã‚¢ãŒ2.32Bå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€CLIPã‚„GLIDEãªã©ã®ãƒ¢ãƒ‡ãƒ«ã®å†ç¾ã¨ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«åˆ©ç”¨ã•ã‚Œã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ç ”ç©¶ã‚’æ°‘ä¸»åŒ–ã—ã¾ã™ã€‚ã¾ãŸã€ãƒ‡ãƒ¼ã‚¿æ¢ç´¢ã‚„ã‚µãƒ–ã‚»ãƒƒãƒˆç”Ÿæˆã®ãŸã‚ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚„ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¤œå‡ºã®ãŸã‚ã®ã‚¹ã‚³ã‚¢ã‚‚æä¾›ã•ã‚Œã¾ã™ã€‚</span>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<span class="issue_date">Issue Date: 2025-04-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1900" target="_blank" rel="noopener noreferrer" class="title-link">DeepNet: Scaling Transformers to 1,000 Layers, Hongyu Wang+, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€æ·±ã„Transformerã‚’å®‰å®šåŒ–ã•ã›ã‚‹ãŸã‚ã®æ–°ã—ã„æ­£è¦åŒ–é–¢æ•°DeepNormã‚’ææ¡ˆã—ã€æ®‹å·®æ¥ç¶šã®ä¿®æ­£ã¨ç†è«–çš„åˆæœŸåŒ–ã‚’è¡Œã†ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Post-LNã®æ€§èƒ½ã¨Pre-LNã®å®‰å®šæ€§ã‚’å…¼ã­å‚™ãˆã€æœ€å¤§1,000å±¤ã®Transformerã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—å¯èƒ½ã«ã—ãŸã€‚ç‰¹ã«ã€3.2Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®200å±¤ãƒ¢ãƒ‡ãƒ«ãŒã€12Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®48å±¤ãƒ¢ãƒ‡ãƒ«ã‚’5 BLEUãƒã‚¤ãƒ³ãƒˆä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ä»Šå¾Œã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã‚¹ãƒ†ãƒ¼ãƒˆã‚ªãƒ–AIã‚¬ã‚¤ãƒ‰ã«ã‚ˆã‚‹è§£èª¬:


<a href="https://ja.stateofaiguides.com/20220308-deepnet-transformer/" target="_blank" rel="noopener noreferrer">https://ja.stateofaiguides.com/20220308-deepnet-transformer/</a>


</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1827" target="_blank" rel="noopener noreferrer" class="title-link">Training Compute-Optimal Large Language Models, Jordan Hoffmann+, NeurIPS'22</a>
<span class="snippet"><span>GPT Summary</span>- ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼è¨€èªãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«ãŠã„ã¦ã€è¨ˆç®—äºˆç®—å†…ã§æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’èª¿æŸ»ã€‚ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨è¨“ç·´ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¯åŒç­‰ã«ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€å€å¢—ã™ã‚‹ã”ã¨ã«ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚‚å€å¢—ã™ã¹ãã¨ææ¡ˆã€‚Chinchillaãƒ¢ãƒ‡ãƒ«ã¯ã€Gopherãªã©ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®è¨ˆç®—é‡ã‚’å‰Šæ¸›ã€‚MMLUãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§67.5%ã®ç²¾åº¦ã‚’é”æˆã—ã€Gopherã«å¯¾ã—ã¦7%ä»¥ä¸Šã®æ”¹å–„ã‚’å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview: 


<a href="https://openreview.net/forum?id=iBBcRUlOAPR" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=iBBcRUlOAPR</a>


</p>
<p>chinchillaå‰‡</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-02-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1754" target="_blank" rel="noopener noreferrer" class="title-link">Switch Transformers: Scaling to Trillion Parameter Models with Simple  and Efficient Sparsity, William Fedus+, JMLR'22</a>
<span class="snippet"><span>GPT Summary</span>- Switch Transformerã‚’ææ¡ˆã—ã€Mixture of Experts (MoE)ã®è¤‡é›‘ã•ã‚„é€šä¿¡ã‚³ã‚¹ãƒˆã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ä¸å®‰å®šæ€§ã‚’æ”¹å–„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ä½ç²¾åº¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã®å¤§è¦æ¨¡ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¯èƒ½ã«ãªã‚Šã€æœ€å¤§7å€ã®äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é€Ÿåº¦å‘ä¸Šã‚’å®Ÿç¾ã€‚ã•ã‚‰ã«ã€1å…†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€T5-XXLãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦4å€ã®é€Ÿåº¦å‘ä¸Šã‚’é”æˆã€‚</span>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2024-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1474" target="_blank" rel="noopener noreferrer" class="title-link">Super-NaturalInstructions: Generalization via Declarative Instructions  on 1600+ NLP Tasks, Yizhong Wang+, N_A, EMNLP'22</a>
<span class="snippet"><span>GPT Summary</span>- Super-NaturalInstructionsã‚’ç”¨ã„ã¦ã€NLPãƒ¢ãƒ‡ãƒ«ã®æœªè¦‹ã‚¿ã‚¹ã‚¯ã¸ã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’è©•ä¾¡ã€‚1,616ã®å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã¨æŒ‡ç¤ºã‚’å«ã‚€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä½œæˆã—ã€76ç¨®é¡ã®ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã‚’ã‚«ãƒãƒ¼ã€‚Tk-Instructãƒ¢ãƒ‡ãƒ«ã¯ã€æŒ‡ç¤ºã«å¾“ã†è¨“ç·´ã‚’å—ã‘ã€InstructGPTã‚’9%ä»¥ä¸Šä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦åˆ†æã—ã€æ±ç”¨çš„ãªNLPãƒ¢ãƒ‡ãƒ«ã®é€²å±•ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>7.1, 7.2ãŒæœ€ã‚‚èˆˆå‘³æ·±ã„<br><br><br><br>## Instruction Tuningã«ãŠã‘ã‚‹æœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã«ã¤ã„ã¦ã€3ã¤ã®è¦ç´ ã«å¯¾ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã¤ã„ã¦è€ƒå¯Ÿ<br><br>- More observed tasks improve the generalization.<br><br>- A large number of training instances do not help generalization.<br><br>- Tuning larger models with instructions consistently lead to gains.<br><br><br><br>## Instructionã‚’ã•ã¾ã–ã¾ã«å¤‰åŒ–ã•ã›ãŸæ™‚ã®æ€§èƒ½ã®å¤‰åŒ–ã«å¯¾ã™ã‚‹åˆ†æ<br><br>Table4ã®å¯¾è§’æˆåˆ†ã«æ³¨ç›®ã™ã‚‹ã¨ï¼ˆtrainã¨testã®input encodingã‚’æƒãˆãŸå ´åˆï¼‰<br><br>- Task definitionã‚’instructionã«å«ã‚ã‚‹ã“ã¨ã§æœªçŸ¥ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½å‘ä¸Š<br><br>- Task Definitionã¨positive examplesã‚’4ã¤ç¨‹åº¦å…¥ã‚Œã‚‹ã¨æ±åŒ–æ€§èƒ½å‘ä¸Šã€‚<br><br>  - ãŸã ã—ã€ã“ã‚Œä»¥ä¸Šexampleã‚’å¢—ã‚„ã™ã¨æ€§èƒ½ä½ä¸‹ã€‚<br><br>  - negative examplesã‚’å…¥ã‚Œã‚‹ã“ã¨ã¯æ€§èƒ½ã« a little bit ã—ã‹è²¢çŒ®ã—ãªã„<br><br>  - explanationsã‚’å…¥ã‚Œã‚‹ã¨æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹<br><br><br><br>Table4ã®éå¯¾è§’æˆåˆ†ã«ç€ç›®ã™ã‚‹ã¨ã€<br><br>- Task Definitionã®ã¿ã§è¨“ç·´ã—ã¦ã‚‚ã€Example onlyã®testæ™‚ã®encodingã«ã¯æ±åŒ–ã—ãªã„ï¼ˆé€†ã‚‚ç„¶ã‚Šï¼‰<br><br>- Task Definition + examples (ä»Šå›ã®å ´åˆã¯positive examples4ã¤)ã¯ã€ã•ã¾ã–ã¾ãªtestæ™‚ã®input encodingsã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆã«ãªã‚‹<br><br> <br><br><img src="https://github.com/user-attachments/assets/3bd1d07d-feb0-4567-bad9-8920c2d82359" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<span class="issue_date">Issue Date: 2024-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1425" target="_blank" rel="noopener noreferrer" class="title-link">No Language Left Behind: Scaling Human-Centered Machine Translation, NLLB Team+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- ã€ŒNo Language Left Behindã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€ãƒªã‚½ãƒ¼ã‚¹ãŒä¹ã—ã„è¨€èªã®æ©Ÿæ¢°ç¿»è¨³ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ã€ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã¨ã®ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã‚’é€šã˜ã¦å¿…è¦æ€§ã‚’æ˜ã‚‰ã‹ã«ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã€‚æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ‹ãƒ³ã‚°æŠ€è¡“ã‚’ç”¨ã„ãŸæ¡ä»¶ä»˜ãè¨ˆç®—ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã€éå­¦ç¿’ã‚’é˜²ããŸã‚ã®è¨“ç·´æ”¹å–„ã‚’è¡Œã£ãŸã€‚Flores-200ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§40,000ä»¥ä¸Šã®ç¿»è¨³æ–¹å‘ã‚’è©•ä¾¡ã—ã€å¾“æ¥æŠ€è¡“ã«å¯¾ã—ã¦44%ã®BLEUæ”¹å–„ã‚’é”æˆã€‚å…¨ã¦ã®æˆæœã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>low-resourceãªè¨€èªã«å¯¾ã™ã‚‹MTã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1413" target="_blank" rel="noopener noreferrer" class="title-link">Finetuned Language Models Are Zero-Shot Learners, Jason Wei+, N_A, ICLR'22</a>
<span class="snippet"><span>GPT Summary</span>- æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ç”¨ã„ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚137Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«FLANã¯ã€60ä»¥ä¸Šã®NLPã‚¿ã‚¹ã‚¯ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã€æœªè¦‹ã®ã‚¿ã‚¹ã‚¯ã§175B GPT-3ã‚’ä¸Šå›ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã€‚ã‚¢ãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¿ãƒ‡ã‚£ã«ã‚ˆã‚Šã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ•°ã‚„ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒ«ãŒæˆåŠŸã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>FLANè«–æ–‡ã€‚Instruction Tuningã‚’ææ¡ˆã—ãŸç ”ç©¶ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<span class="issue_date">Issue Date: 2024-09-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1397" target="_blank" rel="noopener noreferrer" class="title-link">STaR: Bootstrapping Reasoning With Reasoning, Eric Zelikman+, N_A, NeurIPS'22</a>
<span class="snippet"><span>GPT Summary</span>- ã€Œè‡ªå·±å­¦ç¿’æ¨è«–è€…ã€ï¼ˆSTaRï¼‰ã‚’ææ¡ˆã—ã€å°‘æ•°ã®åˆç†çš„èª¬æ˜ã¨å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ´»ç”¨ã—ã¦è¤‡é›‘ãªæ¨è«–ã‚’è¡Œã†ã€‚STaRã¯ã€ç”Ÿæˆã—ãŸå›ç­”ãŒé–“é•ã£ã¦ã„ã‚‹å ´åˆã«æ­£ã—ã„å›ç­”ã‚’ç”¨ã„ã¦å†ç”Ÿæˆã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ç¹°ã‚Šè¿”ã™ã“ã¨ã§æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€STaRã¯å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦å¤§å¹…ãªæ€§èƒ½å‘ä¸Šã‚’ç¤ºã—ã€ç‰¹ã«CommensenseQAã§ã®æˆæœãŒé¡•è‘—ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenAI o1é–¢é€£ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/FactualKnowledge.html" target="_blank" rel="noopener noreferrer">#FactualKnowledge</a>
<a class="button" href="articles/Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<span class="issue_date">Issue Date: 2024-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1332" target="_blank" rel="noopener noreferrer" class="title-link">Knowledge Neurons in Pretrained Transformers, Damai Dai+, N_A, ACL'22, 2022.05</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€äº‹å®ŸçŸ¥è­˜ã®æ ¼ç´æ–¹æ³•ã«ã¤ã„ã¦ã®ç ”ç©¶ã‚’è¡Œã„ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€BERTã®fill-in-the-blank cloze taskã‚’ç”¨ã„ã¦ã€é–¢é€£ã™ã‚‹äº‹å®Ÿã‚’è¡¨ç¾ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’ç‰¹å®šã—ã¾ã—ãŸã€‚ã¾ãŸã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æ´»æ€§åŒ–ã¨å¯¾å¿œã™ã‚‹äº‹å®Ÿã®è¡¨ç¾ã¨ã®æ­£ã®ç›¸é–¢ã‚’è¦‹ã¤ã‘ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã‚ãšã«ã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’æ´»ç”¨ã—ã¦ç‰¹å®šã®äº‹å®ŸçŸ¥è­˜ã‚’ç·¨é›†ã—ã‚ˆã†ã¨è©¦ã¿ã¾ã—ãŸã€‚ã“ã®ç ”ç©¶ã¯ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸTransformerså†…ã§ã®çŸ¥è­˜ã®æ ¼ç´ã«é–¢ã™ã‚‹ç¤ºå”†ã«å¯Œã‚“ã§ãŠã‚Šã€ã‚³ãƒ¼ãƒ‰ã¯https://github.com/Hunter-DDM/knowledge-neuronsã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1108" target="_blank" rel="noopener noreferrer">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ï½¤ã€ŒçŸ¥è­˜ã¯å…¨çµåˆå±¤ã«è“„ç©ã•ã‚Œã‚‹ã€ã¨ã„ã†ä»®èª¬ã«ã¤ã„ã¦ã®æ–‡çŒ®èª¿æŸ»</a>
 </p>
<p>æ—¥æœ¬èªè§£èª¬: 


<a href="https://speakerdeck.com/kogoro/knowledge-neurons-in-pretrained-transformers-for-snlp2022" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/kogoro/knowledge-neurons-in-pretrained-transformers-for-snlp2022</a>


</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2140" target="_blank" rel="noopener noreferrer">[Paper Note] Transformer Feed-Forward Layers Are Key-Value Memories, Mor Geva+, EMNLP'21</a>
</p>
<p>ä¸Šè¨˜è³‡æ–™ã«ã‚ˆã‚‹ã¨ã€ç‰¹å®šã®çŸ¥è­˜ã‚’å‡ºåŠ›ã™ã‚‹éš›ã«æ´»æ€§åŒ–ã™ã‚‹çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’ç‰¹å®šã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚MLMã‚’ç”¨ã„ãŸclozeã‚¿ã‚¹ã‚¯ã«ã‚ˆã‚‹å®Ÿé¨“ã§[MASK]éƒ¨åˆ†ã«å½“è©²çŸ¥è­˜ã‚’å‡ºåŠ›ã™ã‚‹å®Ÿé¨“ã‚’ã—ãŸçµæœã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®é‡ã¿ã‚’ã‚¼ãƒ­ã¨ã™ã‚‹ã¨æ€§èƒ½ãŒè‘—ã—ãåŠ£åŒ–ã—ã€å€¤ã‚’2å€ã«ã™ã‚‹ã¨æ€§èƒ½ãŒæ”¹å–„ã™ã‚‹ã¨ã„ã£ãŸå‚¾å‘ãŒã¿ã‚‰ã‚ŒãŸã€‚ã€€ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã¨ã—ã¦ã€çŸ¥è­˜ã®æ›´æ–°ã¨ã€çŸ¥è­˜ã®å‰Šé™¤ãŒå¯èƒ½ã‹ã‚’æ¤œè¨¼ã€‚ã©ã¡ã‚‰ã¨ã‚‚æ›´æ–°ãƒ»å‰Šé™¤ãŒã•ã‚Œã‚‹æ–¹å‘æ€§[^1]ã¸ãƒ¢ãƒ‡ãƒ«ãŒå¤‰åŒ–ã—ãŸã€‚<br><br>ã¾ãŸã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯Transformerã®å±¤ã®æ·±ã„ã¨ã“ã‚ã«ä½ç½®ã—ã¦ã„ã‚‹å‚¾å‘ã«ã‚ã‚Šã€ç•°ãªã‚‹relationã‚’æŒã¤ã‚ˆã†ãªé–¢ä¿‚çŸ¥è­˜åŒå£«ã§ã¯å…±æœ‰ã•ã‚Œãªã„å‚¾å‘ã«ã‚ã‚‹æ¨¡æ§˜ã€‚<br><br>[^1]: ä»–ã®çŸ¥è­˜ã«å½±éŸ¿ã‚’ä¸ãˆãšã€å®Œç’§ã«æ›´æ–°ãƒ»å‰Šé™¤ã§ããŸã‚ã‘ã§ã¯ãªã„ã€‚çŸ¥è­˜ã®æ›´æ–°ãƒ»å‰Šé™¤ã«ä¼´ã„Extrinsicãªè©•ä¾¡ã«ã‚ˆã£ã¦æ€§èƒ½å‘ä¸Šã€ã‚ã‚‹ã„ã¯PerplexityãŒå¢—å¤§ã—ãŸã€ã¨ã„ã£ãŸçµæœã‹ã‚‰ãã†ã„ã£ãŸæ–¹å‘æ€§ã¸ãƒ¢ãƒ‡ãƒ«ãŒå¤‰åŒ–ã—ãŸã€ã¨ã„ã†è©±</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/PPO%20(ProximalPolicyOptimization).html" target="_blank" rel="noopener noreferrer">#PPO (ProximalPolicyOptimization)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2024-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1296" target="_blank" rel="noopener noreferrer" class="title-link">Training language models to follow instructions with human feedback, Long Ouyang+, N_A, NeurIPS'22</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã«åˆã‚ãªã„å‡ºåŠ›ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦GPT-3ã‚’å¾®èª¿æ•´ã—ã€InstructGPTã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã«ã‚ˆã‚Šã€13å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®InstructGPTãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ãŒ175Bã®GPT-3ã®å‡ºåŠ›ã‚ˆã‚Šã‚‚å¥½ã¾ã‚Œã€çœŸå®Ÿæ€§ã®å‘ä¸Šã¨æœ‰å®³ãªå‡ºåŠ›ã®å‰Šæ¸›ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ä¸€èˆ¬çš„ãªNLPãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãŠã‘ã‚‹æ€§èƒ½ã®ä½ä¸‹ã¯æœ€å°é™ã§ã—ãŸã€‚InstructGPTã¯ã¾ã æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ãŒã€äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ãŸå¾®èª¿æ•´ãŒæœ‰æœ›ãªæ–¹å‘ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ChatGPTã®å…ƒã¨ãªã‚‹ã€SFTâ†’Reward Modelã®è¨“ç·´â†’RLHFã®æµã‚ŒãŒææ¡ˆã•ã‚ŒãŸç ”ç©¶ã€‚Demonstrationãƒ‡ãƒ¼ã‚¿ã ã‘ã§SFTã™ã‚‹ã ã‘ã§ã¯ã€äººé–“ã®æ„å›³ã—ãŸã¨ãŠã‚Šã«å‹•ä½œã—ãªã„å•é¡ŒãŒã‚ã£ãŸãŸã‚ã€äººé–“ã®æ„å›³ã«Alignã™ã‚‹ã‚ˆã†ã«ã€Reward Modelã‚’ç”¨ã„ãŸRLHFã§SFTã®å¾Œã«è¿½åŠ ã§å­¦ç¿’ã‚’å®Ÿæ–½ã™ã‚‹ã€‚Reward Modelã¯ã€175Bãƒ¢ãƒ‡ãƒ«ã¯å­¦ç¿’ãŒå®‰å®šã—ãªã‹ã£ãŸä¸Šã«ã€PPOã®è¨ˆç®—ã‚³ã‚¹ãƒˆãŒéå¸¸ã«å¤§ãã„ãŸã‚ã€6Bã®GPT-3ã‚’æ§˜ã€…ãªNLPã‚¿ã‚¹ã‚¯ã§SFTã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ã‚¹ã‚¿ãƒ¼ãƒˆã«ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã«å¯¾ã—ã¦äººé–“ãŒãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»˜ã‘ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã®loss functionã§è¨“ç·´ã—ãŸã€‚æœ€çµ‚çš„ã«ã€RMã®ã‚¹ã‚³ã‚¢ãŒæœ€å¤§åŒ–ã•ã‚Œã‚‹ã‚ˆã†ã«SFTã—ãŸGPT-3ã‚’RLHFã§è¨“ç·´ã™ã‚‹ãŒã€ãã®éš›ã«ã€SFTã‹ã‚‰å‡ºåŠ›ãŒé›¢ã‚Œã™ããªã„ã‚ˆã†ã«ã™ã‚‹é …ã¨ã€NLPãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®æ€§èƒ½ãŒåŠ£åŒ–ã—ãªã„ã‚ˆã†ã«pretrainæ™‚ã®ã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ã‚‚loss functionã«åŠ ãˆã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e4934d4c-7a9b-44aa-93ce-3ae46ed4bd9b" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/StructuredData.html" target="_blank" rel="noopener noreferrer">#StructuredData</a>
<span class="issue_date">Issue Date: 2023-10-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1097" target="_blank" rel="noopener noreferrer" class="title-link">MURMUR: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text  Generation, Swarnadeep Saha+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€åŠæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ãŠã‘ã‚‹å¤šæ®µéšã®æ¨è«–ã‚’è¡Œã†ãŸã‚ã®MURMURã¨ã„ã†æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚MURMURã¯ã€ç‰¹å®šã®è¨€èªçš„ãŠã‚ˆã³è«–ç†çš„ãªã‚¹ã‚­ãƒ«ã‚’æŒã¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨è¨˜å·ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã€ãƒ™ã‚¹ãƒˆãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆã‚µãƒ¼ãƒæ‰‹æ³•ã‚’ä½¿ç”¨ã—ã¦æ¨è«–ãƒ‘ã‚¹ã‚’ç”Ÿæˆã—ã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€MURMURã¯ä»–ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ‰‹æ³•ã«æ¯”ã¹ã¦å¤§å¹…ãªæ”¹å–„ã‚’ç¤ºã—ã€ã¾ãŸã€ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–ã®ãƒ‡ãƒ¼ã‚¿ã§ã‚‚åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€äººé–“ã®è©•ä¾¡ã§ã¯ã€MURMURã¯è«–ç†çš„ã«æ•´åˆæ€§ã®ã‚ã‚‹è¦ç´„ã‚’ã‚ˆã‚Šå¤šãç”Ÿæˆã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/BeamSearch.html" target="_blank" rel="noopener noreferrer">#BeamSearch</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/998" target="_blank" rel="noopener noreferrer" class="title-link">Momentum Calibration for Text Generation, Xingxing Zhang+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦MoCaï¼ˆMomentum Calibrationï¼‰ã¨ã„ã†æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚MoCaã¯ã€ãƒ“ãƒ¼ãƒ ã‚µãƒ¼ãƒã‚’ç”¨ã„ãŸé…ãé€²åŒ–ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚’å‹•çš„ã«ç”Ÿæˆã—ã€ã“ã‚Œã‚‰ã®ã‚µãƒ³ãƒ—ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚³ã‚¢ã‚’å®Ÿéš›ã®å“è³ªã«åˆã‚ã›ã‚‹ã‚ˆã†ã«å­¦ç¿’ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€MoCaãŒå¼·åŠ›ãªäº‹å‰å­¦ç¿’æ¸ˆã¿Transformerã‚’æ”¹å–„ã—ã€æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/BeamSearch.html" target="_blank" rel="noopener noreferrer">#BeamSearch</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/997" target="_blank" rel="noopener noreferrer" class="title-link">BRIO: Bringing Order to Abstractive Summarization, Yixin Liu+, N_A, ACL'22</a>
<span class="snippet"><span>GPT Summary</span>- å¾“æ¥ã®æŠ½è±¡çš„è¦ç´„ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€æœ€å°¤æ¨å®šã‚’ä½¿ç”¨ã—ã¦è¨“ç·´ã•ã‚Œã¦ã„ã¾ã—ãŸãŒã€ã“ã®æ–¹æ³•ã§ã¯è¤‡æ•°ã®å€™è£œè¦ç´„ã‚’æ¯”è¼ƒã™ã‚‹éš›ã«æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãã“ã§ã€éç¢ºå®šè«–çš„ãªåˆ†å¸ƒã‚’ä»®å®šã—ã€å€™è£œè¦ç´„ã®å“è³ªã«å¿œã˜ã¦ç¢ºç‡ã‚’å‰²ã‚Šå½“ã¦ã‚‹æ–°ã—ã„è¨“ç·´ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ã“ã®æ‰‹æ³•ã«ã‚ˆã‚Šã€CNN/DailyMailã¨XSumã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æœ€é«˜ã®çµæœã‚’é”æˆã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ãƒ¢ãƒ‡ãƒ«ãŒå€™è£œè¦ç´„ã®å“è³ªã¨ã‚ˆã‚Šç›¸é–¢ã®ã‚ã‚‹ç¢ºç‡ã‚’æ¨å®šã§ãã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ“ãƒ¼ãƒ å†…ã®ãƒˆãƒƒãƒ—ãŒROUGEã‚’æœ€å¤§åŒ–ã—ã¦ã„ã‚‹ã¨ã¯é™ã‚‰ãªã‹ã£ãŸãŸã‚ã€ROUGEãŒæœ€å¤§ã¨ãªã‚‹ã‚ˆã†ãªè¦ç´„ã‚’é¸æŠã™ã‚‹ã‚ˆã†ã«ã—ãŸã‚‰æ€§èƒ½çˆ†ä¸Šã’ã—ã¾ã—ãŸã¨ã„ã†ç ”ç©¶ã€‚<br>å®Ÿè³ªç¾åœ¨ã®SoTA</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/987" target="_blank" rel="noopener noreferrer" class="title-link">SMART: Sentences as Basic Units for Text Evaluation, Reinald Kim Amplayo+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®è©•ä¾¡æŒ‡æ¨™ã®åˆ¶é™ã‚’ç·©å’Œã™ã‚‹ãŸã‚ã«ã€æ–°ã—ã„æŒ‡æ¨™ã§ã‚ã‚‹SMARTã‚’ææ¡ˆã™ã‚‹ã€‚SMARTã¯æ–‡ã‚’åŸºæœ¬çš„ãªãƒãƒƒãƒãƒ³ã‚°å˜ä½ã¨ã—ã€æ–‡ã®ãƒãƒƒãƒãƒ³ã‚°é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦å€™è£œæ–‡ã¨å‚ç…§æ–‡ã‚’è©•ä¾¡ã™ã‚‹ã€‚ã¾ãŸã€ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ–‡ã¨ã‚‚æ¯”è¼ƒã—ã€è©•ä¾¡ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€SMARTãŒä»–ã®æŒ‡æ¨™ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ç‰¹ã«ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒãƒãƒ³ã‚°é–¢æ•°ã‚’ä½¿ç”¨ã—ãŸå ´åˆã«æœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€ææ¡ˆã•ã‚ŒãŸæŒ‡æ¨™ã¯é•·ã„è¦ç´„æ–‡ã§ã‚‚ã†ã¾ãæ©Ÿèƒ½ã—ã€ç‰¹å®šã®ãƒ¢ãƒ‡ãƒ«ã«åã‚ŠãŒå°‘ãªã„ã“ã¨ã‚‚ç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/983" target="_blank" rel="noopener noreferrer" class="title-link">FFCI: A Framework for Interpretable Automatic Evaluation of  Summarization, Fajri Koto+, N_A, JAIR'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€FFCIã¨ã„ã†ç´°ã‹ã„è¦ç´„è©•ä¾¡ã®ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€ä¿¡é ¼æ€§ã€ç„¦ç‚¹ã€ã‚«ãƒãƒ¬ãƒƒã‚¸ã€ãŠã‚ˆã³æ–‡é–“ã®é€£ç¶šæ€§ã®4ã¤ã®è¦ç´ ã‹ã‚‰æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã€è©•ä¾¡ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡æ–¹æ³•ã‚’ã‚¯ãƒ­ã‚¹æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ã€FFCIã®4ã¤ã®æ¬¡å…ƒã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®è‡ªå‹•çš„ãªæ–¹æ³•ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚ã•ã¾ã–ã¾ãªè¦ç´„ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ã€é©šãã¹ãçµæœã‚’å¾—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ˆè¡Œç ”ç©¶ã§ã©ã®ã‚ˆã†ãªMetricãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã¦ã€ãã‚Œã‚‰ãŒã©ã†ã„ã£ãŸè¦³ç‚¹ã®Metricãªã®ã‹ã‚„ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãªã©ã€éå¸¸ã«ç´°ã‹ãã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚</p>
<p>Faithfulness(ROUGE, STS-Score, BERTScoreã«åŸºã¥ã), Focus and Coverage (Question Answering basedãªæ‰‹æ³•ã«åŸºã¥ã), Inter-Sentential Coherence (NSPã«åŸºã¥ã)ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/973" target="_blank" rel="noopener noreferrer" class="title-link">InfoLM: A New Metric to Evaluate Summarization &amp; Data2Text Generation, Pierre Colombo+, N_A, AAAI'22</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªç„¶è¨€èªç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®å“è³ªè©•ä¾¡ã¯é«˜ä¾¡ã§ã‚ã‚Šã€äººé–“ã®æ³¨é‡ˆã«é ¼ã‚‹ã“ã¨ãŒä¸€èˆ¬çš„ã§ã™ã€‚ã—ã‹ã—ã€è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒã‚¹ã‚¯ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸè©•ä¾¡æŒ‡æ¨™ã§ã‚ã‚‹InfoLMã‚’ç´¹ä»‹ã—ã¾ã™ã€‚ã“ã®æŒ‡æ¨™ã¯åŒç¾©èªã‚’å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã€è¦ç´„ã‚„ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã®è¨­å®šã§æœ‰æ„ãªæ”¹å–„ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/972" target="_blank" rel="noopener noreferrer" class="title-link">WIDAR -- Weighted Input Document Augmented ROUGE, Raghav Jain+, N_A, ECIR'22</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå‹•ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã®è©•ä¾¡ã«ãŠã„ã¦ã€ROUGEãƒ¡ãƒˆãƒªãƒƒã‚¯ã«ã¯åˆ¶ç´„ãŒã‚ã‚Šã€å‚ç…§è¦ç´„ã®åˆ©ç”¨å¯èƒ½æ€§ã«ä¾å­˜ã—ã¦ã„ã‚‹ã€‚ãã“ã§ã€æœ¬ç ”ç©¶ã§ã¯WIDARãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ææ¡ˆã—ã€å‚ç…§è¦ç´„ã ã‘ã§ãªãå…¥åŠ›ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚‚ä½¿ç”¨ã—ã¦è¦ç´„ã®å“è³ªã‚’è©•ä¾¡ã™ã‚‹ã€‚WIDARãƒ¡ãƒˆãƒªãƒƒã‚¯ã¯ä¸€è²«æ€§ã€æ•´åˆæ€§ã€æµæš¢ã•ã€é–¢é€£æ€§ã®å‘ä¸Šã‚’ROUGEã¨æ¯”è¼ƒã—ã¦ãŠã‚Šã€ä»–ã®æœ€å…ˆç«¯ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨åŒç­‰ã®çµæœã‚’çŸ­ã„è¨ˆç®—æ™‚é–“ã§å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LM-based.html" target="_blank" rel="noopener noreferrer">#LM-based</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/965" target="_blank" rel="noopener noreferrer" class="title-link">SummaC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization, Laban+, TACL'22</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ã®é ˜åŸŸã§ã¯ã€å…¥åŠ›ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨è¦ç´„ãŒæ•´åˆã—ã¦ã„ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚ä»¥å‰ã®ç ”ç©¶ã§ã¯ã€è‡ªç„¶è¨€èªæ¨è«–ï¼ˆNLIï¼‰ãƒ¢ãƒ‡ãƒ«ã‚’ä¸æ•´åˆæ¤œå‡ºã«é©ç”¨ã™ã‚‹ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚æœ¬ç ”ç©¶ã§ã¯ã€NLIã‚’ä¸æ•´åˆæ¤œå‡ºã«å†è©•ä¾¡ã—ã€éå»ã®ç ”ç©¶ã§ã®å…¥åŠ›ã®ç²’åº¦ã®ä¸ä¸€è‡´ãŒå•é¡Œã§ã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚æ–°ã—ã„æ‰‹æ³•SummaCConvã‚’ææ¡ˆã—ã€NLIãƒ¢ãƒ‡ãƒ«ã‚’æ–‡å˜ä½ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†å‰²ã—ã¦ã‚¹ã‚³ã‚¢ã‚’é›†è¨ˆã™ã‚‹ã“ã¨ã§ã€ä¸æ•´åˆæ¤œå‡ºã«æˆåŠŸè£ã«ä½¿ç”¨ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯SummaCã‚’å°å…¥ã—ã€74.4%ã®æ­£ç¢ºã•ã‚’é”æˆã—ã€å…ˆè¡Œç ”ç©¶ã¨æ¯”è¼ƒã—ã¦5%ã®æ”¹å–„ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/962" target="_blank" rel="noopener noreferrer" class="title-link">TRUE: Re-evaluating Factual Consistency Evaluation, Or Honovich+, N_A, the Second DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering'22</a>
<span class="snippet"><span>GPT Summary</span>- äº‹å®Ÿã®æ•´åˆæ€§ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®åŒ…æ‹¬çš„ãªèª¿æŸ»ã¨è©•ä¾¡ã§ã‚ã‚‹TRUEã‚’ç´¹ä»‹ã€‚ã•ã¾ã–ã¾ãªæœ€å…ˆç«¯ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨11ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å¯¾è±¡ã«è¡Œã£ãŸçµæœã€å¤§è¦æ¨¡ãªNLIãŠã‚ˆã³è³ªå•ç”Ÿæˆãƒ»å›ç­”ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¼·åŠ›ã§è£œå®Œçš„ãªçµæœã‚’é”æˆã™ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚TRUEã‚’ãƒ¢ãƒ‡ãƒ«ãŠã‚ˆã³ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®é–‹ç™ºè€…ã®å‡ºç™ºç‚¹ã¨ã—ã¦æ¨å¥¨ã—ã€ã•ã‚‰ãªã‚‹è©•ä¾¡æ–¹æ³•ã®å‘ä¸Šã«å‘ã‘ãŸé€²æ­©ã‚’æœŸå¾…ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>FactualConsistencyã«é–¢ã™ã‚‹MetricãŒè‰¯ãã¾ã¨ã¾ã£ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/958" target="_blank" rel="noopener noreferrer" class="title-link">MaskEval: Weighted MLM-Based Evaluation for Text Summarization and  Simplification, Yu Lu Liu+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã®è¦ç´„ã¨ç°¡ç´ åŒ–ã®ãŸã‚ã®å‚ç…§ã®ãªã„è©•ä¾¡å°ºåº¦ã§ã‚ã‚‹MaskEvalã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚MaskEvalã¯ã€å€™è£œãƒ†ã‚­ã‚¹ãƒˆã¨ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã®é€£çµã«å¯¾ã—ã¦ãƒã‚¹ã‚¯ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚’è¡Œã„ã€é‡è¦ãªå“è³ªã®å´é¢ã”ã¨ã«ç›¸å¯¾çš„ãªé‡è¦æ€§ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã•ã‚‰ã«ã€è‹±èªã®è¦ç´„ã¨ç°¡ç´ åŒ–ã«ãŠã‘ã‚‹äººé–“ã®åˆ¤æ–­ã¨ã®ç›¸é–¢ã«åŸºã¥ã„ã¦ã€ãã®åŠ¹æœã‚’ç¤ºã—ã€ä¸¡æ–¹ã®ã‚¿ã‚¹ã‚¯é–“ã§ã®è»¢ç§»ã‚·ãƒŠãƒªã‚ªã‚’æ¢ç´¢ã—ã¾ã™ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/957" target="_blank" rel="noopener noreferrer" class="title-link">Play the Shannon Game With Language Models: A Human-Free Approach to  Summary Evaluation, Nicholas Egan+, N_A, AAAI'22</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®ç ”ç©¶ã§ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€å‚ç…§ãƒ•ãƒªãƒ¼ã®è¦ç´„è©•ä¾¡æŒ‡æ¨™ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¦ç´„ã®å“è³ªã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã®æ–°ã—ã„æ‰‹æ³•ãŒé–‹ç™ºã•ã‚Œã¾ã™ã€‚ã¾ãŸã€ææ¡ˆæ‰‹æ³•ãŒäººé–“ã®åˆ¤æ–­ã¨é«˜ã„ç›¸é–¢é–¢ä¿‚ã‚’æŒã¤ã“ã¨ãŒå®Ÿè¨¼ã•ã‚Œã¾ã™ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/956" target="_blank" rel="noopener noreferrer" class="title-link">Reference-free Summarization Evaluation via Semantic Correlation and Compression Ratio, Liu+, NAACL'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å‚ç…§ãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡æ–¹æ³•ã®æŸ”è»Ÿæ€§ã®æ¬ å¦‚ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã«ã€äº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦è‡ªå‹•å‚ç…§ãƒ•ãƒªãƒ¼ã®è©•ä¾¡æŒ‡æ¨™ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®æŒ‡æ¨™ã¯ã€è¦ç´„ã®æ„å‘³çš„ãªåˆ†å¸ƒã¨åœ§ç¸®ç‡ã‚’è€ƒæ…®ã—ã€äººé–“ã®è©•ä¾¡ã¨ã‚ˆã‚Šä¸€è‡´ã—ã¦ã„ã‚‹ã“ã¨ãŒå®Ÿé¨“ã§ç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/952" target="_blank" rel="noopener noreferrer" class="title-link">Re-Examining System-Level Correlations of Automatic Summarization Evaluation Metrics, Deutsch+, NAACL'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è‡ªå‹•è¦ç´„è©•ä¾¡å°ºåº¦ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã®ç›¸é–¢ã«é–¢ã™ã‚‹ä¸æ•´åˆã‚’ä¿®æ­£ã™ã‚‹ãŸã‚ã®å¤‰æ›´ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€å…¨ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦è‡ªå‹•è©•ä¾¡å°ºåº¦ã®ã‚·ã‚¹ãƒ†ãƒ ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã€å®Ÿéš›ã®ã‚·ãƒŠãƒªã‚ªã§ã‚ˆãè¦‹ã‚‰ã‚Œã‚‹è‡ªå‹•ã‚¹ã‚³ã‚¢ã®ã‚ãšã‹ãªå·®ã«ã‚ˆã£ã¦åˆ†é›¢ã•ã‚ŒãŸã‚·ã‚¹ãƒ†ãƒ ã®ãƒšã‚¢ã«å¯¾ã—ã¦ã®ã¿ç›¸é–¢ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚ˆã‚Šæ­£ç¢ºãªç›¸é–¢æ¨å®šã¨é«˜å“è³ªãªäººé–“ã®åˆ¤æ–­ã®åé›†ãŒå¯èƒ½ã¨ãªã‚Šã¾ã™ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/951" target="_blank" rel="noopener noreferrer" class="title-link">Does Summary Evaluation Survive Translation to Other Languages?, Braun+, NAACL'22</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆã¯è²»ç”¨ã¨æ™‚é–“ãŒã‹ã‹ã‚‹ãŒã€æ©Ÿæ¢°ç¿»è¨³ã‚’ä½¿ç”¨ã—ã¦æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä»–ã®è¨€èªã«ç¿»è¨³ã™ã‚‹ã“ã¨ã§ã€è¿½åŠ ã®è¨€èªã§ã®ä½¿ç”¨ãŒå¯èƒ½ã«ãªã‚‹ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€è‹±èªã®è¦ç´„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’7ã¤ã®è¨€èªã«ç¿»è¨³ã—ã€è‡ªå‹•è©•ä¾¡å°ºåº¦ã«ã‚ˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¯”è¼ƒã™ã‚‹ã€‚ã¾ãŸã€äººé–“ã¨è‡ªå‹•åŒ–ã•ã‚ŒãŸè¦ç´„ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°é–“ã®ç›¸é–¢ã‚’è©•ä¾¡ã—ã€ç¿»è¨³ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ä¸ãˆã‚‹å½±éŸ¿ã‚‚è€ƒæ…®ã™ã‚‹ã€‚ã•ã‚‰ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å†åˆ©ç”¨ã®å¯èƒ½æ€§ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«ã€ç‰¹å®šã®å´é¢ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/TrainedMetrics.html" target="_blank" rel="noopener noreferrer">#TrainedMetrics</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/948" target="_blank" rel="noopener noreferrer" class="title-link">SummScore: A Comprehensive Evaluation Metric for Summary Quality Based  on Cross-Encoder, Wuhang Lin+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ã®å“è³ªè©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€SummScoreã¨ã„ã†åŒ…æ‹¬çš„ãªè©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ææ¡ˆã™ã‚‹ã€‚SummScoreã¯CrossEncoderã«åŸºã¥ã„ã¦ãŠã‚Šã€è¦ç´„ã®å¤šæ§˜æ€§ã‚’æŠ‘åˆ¶ã›ãšã«è¦ç´„ã®å“è³ªã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã•ã‚‰ã«ã€SummScoreã¯ä¸€è²«æ€§ã€ä¸€è²«æ€§ã€æµæš¢ã•ã€é–¢é€£æ€§ã®4ã¤ã®å´é¢ã§è©•ä¾¡ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€SummScoreãŒæ—¢å­˜ã®è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€SummScoreã®è©•ä¾¡çµæœã‚’16ã®ä¸»è¦ãªè¦ç´„ãƒ¢ãƒ‡ãƒ«ã«æä¾›ã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/942" target="_blank" rel="noopener noreferrer" class="title-link">SueNes: A Weakly Supervised Approach to Evaluating Single-Document Summarization via Negative Sampling, Bao+, NAACL'22</a>
<span class="snippet"><span>GPT Summary</span>- å¾“æ¥ã®è‡ªå‹•è¦ç´„è©•ä¾¡ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¯èªå½™ã®é¡ä¼¼æ€§ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ãŠã‚Šã€æ„å‘³ã‚„è¨€èªçš„ãªå“è³ªã‚’ååˆ†ã«æ‰ãˆã‚‹ã“ã¨ãŒã§ããªã„ã€‚å‚ç…§è¦ç´„ãŒå¿…è¦ã§ã‚ã‚‹ãŸã‚ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€å‚ç…§è¦ç´„ãŒå­˜åœ¨ã—ãªã„å¼±æ•™å¸«ã‚ã‚Šè¦ç´„è©•ä¾¡æ‰‹æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚æ—¢å­˜ã®è¦ç´„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ–‡æ›¸ã¨ç ´æã—ãŸå‚ç…§è¦ç´„ã®ãƒšã‚¢ã«å¤‰æ›ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã€‚ãƒ‰ãƒ¡ã‚¤ãƒ³é–“ã®ãƒ†ã‚¹ãƒˆã§ã¯ã€ææ¡ˆæ‰‹æ³•ãŒãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Šã€è¨€èªçš„ãªå“è³ªã‚’è©•ä¾¡ã™ã‚‹ä¸Šã§å¤§ããªåˆ©ç‚¹ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/941" target="_blank" rel="noopener noreferrer" class="title-link">PrefScore: Pairwise Preference Learning for Reference-free Summarization Quality Assessment, Luo+, COLING'22</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“ã«ã‚ˆã‚‹å‚ç…§è¦ç´„ã®ãªã„æ©Ÿæ¢°ç”Ÿæˆã®è¦ç´„ã®è©•ä¾¡ã‚’è¡Œã†ãŸã‚ã«ã€ãƒ–ãƒ©ãƒƒãƒ‰ãƒªãƒ¼ãƒ»ãƒ†ãƒªãƒ¼ã®ãƒ‘ãƒ¯ãƒ¼ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦è¦ç´„ã®å„ªåŠ£ã‚’åˆ¤æ–­ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€ã“ã®æ–¹æ³•ãŒäººé–“ã®è©•ä¾¡ã¨é«˜ã„ç›¸é–¢ã‚’æŒã¤ã‚¹ã‚³ã‚¢ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/940" target="_blank" rel="noopener noreferrer" class="title-link">How to Find Strong Summary Coherence Measures? A Toolbox and a Comparative Study for Summary Coherence Measure Evaluation, Steen+, COLING'22</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ã®ä¸€è²«æ€§ã‚’è‡ªå‹•çš„ã«è©•ä¾¡ã™ã‚‹ã“ã¨ã¯é‡è¦ã§ã‚ã‚Šã€ã•ã¾ã–ã¾ãªæ–¹æ³•ãŒææ¡ˆã•ã‚Œã¦ã„ã¾ã™ãŒã€ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨è©•ä¾¡æŒ‡æ¨™ã‚’ä½¿ç”¨ã—ã¦è©•ä¾¡ã•ã‚Œã‚‹ãŸã‚ã€ç›¸å¯¾çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç†è§£ã™ã‚‹ã“ã¨ãŒå›°é›£ã§ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€è¦ç´„ã®ä¸€è²«æ€§ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®ã•ã¾ã–ã¾ãªæ–¹æ³•ã«ã¤ã„ã¦èª¿æŸ»ã—ã€æ–°ã—ã„åˆ†æå°ºåº¦ã‚’å°å…¥ã—ã¾ã™ã€‚ç¾åœ¨ã®è‡ªå‹•ä¸€è²«æ€§å°ºåº¦ã¯ã™ã¹ã¦ã®è©•ä¾¡æŒ‡æ¨™ã«ãŠã„ã¦ä¿¡é ¼æ€§ã®ã‚ã‚‹ä¸€è²«æ€§ã‚¹ã‚³ã‚¢ã‚’å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ãŒã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯æœ‰æœ›ãªçµæœã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/IJCNLP.html" target="_blank" rel="noopener noreferrer">#IJCNLP</a>
<a class="button" href="articles/AACL.html" target="_blank" rel="noopener noreferrer">#AACL</a>
<a class="button" href="articles/Repetition.html" target="_blank" rel="noopener noreferrer">#Repetition</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/939" target="_blank" rel="noopener noreferrer" class="title-link">Self-Repetition in Abstractive Neural Summarizers, Nikita Salkar+, N_A,  AACL-IJCNLP'22</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€BARTã€T5ã€ãŠã‚ˆã³Pegasusã¨ã„ã†3ã¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã«ãŠã‘ã‚‹è‡ªå·±ç¹°ã‚Šè¿”ã—ã®åˆ†æã‚’è¡Œã„ã¾ã—ãŸã€‚ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§fine-tuningã•ã‚Œã¦ã„ã¾ã™ã€‚å›å¸°åˆ†æã«ã‚ˆã‚‹ã¨ã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯å…¥åŠ›ã®å‡ºåŠ›è¦ç´„é–“ã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç¹°ã‚Šè¿”ã™å‚¾å‘ãŒç•°ãªã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ã¾ãŸã€æŠ½è±¡çš„ãªãƒ‡ãƒ¼ã‚¿ã‚„å®šå‹çš„ãªè¨€èªã‚’ç‰¹å¾´ã¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã§ã®fine-tuningã§ã¯ã€è‡ªå·±ç¹°ã‚Šè¿”ã—ã®å‰²åˆãŒé«˜ããªã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚å®šæ€§çš„ãªåˆ†æã§ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ãŒã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã‚„å®šå‹ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ã“ã‚Œã‚‰ã®çµæœã¯ã€ã‚µãƒãƒ©ã‚¤ã‚¶ãƒ¼ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®æ‰‹æ³•ã®é–‹ç™ºã«å½¹ç«‹ã¤å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/938" target="_blank" rel="noopener noreferrer" class="title-link">Universal Evasion Attacks on Summarization Scoring, Wenchuan Mu+, N_A, BlackboxNLP workshop on ACL'22</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ã®è‡ªå‹•è©•ä¾¡ã¯é‡è¦ã§ã‚ã‚Šã€ãã®è©•ä¾¡ã¯è¤‡é›‘ã§ã™ã€‚ã—ã‹ã—ã€ã“ã‚Œã¾ã§è¦ç´„ã®è©•ä¾¡ã¯æ©Ÿæ¢°å­¦ç¿’ã®ã‚¿ã‚¹ã‚¯ã¨ã¯è€ƒãˆã‚‰ã‚Œã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚æœ¬ç ”ç©¶ã§ã¯ã€è‡ªå‹•è©•ä¾¡ã®å …ç‰¢æ€§ã‚’æ¢ã‚‹ãŸã‚ã«å›é¿æ”»æ’ƒã‚’è¡Œã„ã¾ã—ãŸã€‚æ”»æ’ƒã‚·ã‚¹ãƒ†ãƒ ã¯ã€è¦ç´„ã§ã¯ãªã„æ–‡å­—åˆ—ã‚’äºˆæ¸¬ã—ã€ä¸€èˆ¬çš„ãªè©•ä¾¡æŒ‡æ¨™ã§ã‚ã‚‹ROUGEã‚„METEORã«ãŠã„ã¦å„ªã‚ŒãŸè¦ç´„å™¨ã¨ç«¶åˆã™ã‚‹ã‚¹ã‚³ã‚¢ã‚’é”æˆã—ã¾ã—ãŸã€‚ã¾ãŸã€æ”»æ’ƒã‚·ã‚¹ãƒ†ãƒ ã¯æœ€å…ˆç«¯ã®è¦ç´„æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã‚¹ã‚³ã‚¢ã‚’ç²å¾—ã—ã¾ã—ãŸã€‚ã“ã®ç ”ç©¶ã¯ã€ç¾åœ¨ã®è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã®å …ç‰¢æ€§ã®ä½ã•ã‚’ç¤ºã—ã¦ãŠã‚Šã€è¦ç´„ã‚¹ã‚³ã‚¢ã®é–‹ç™ºã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/936" target="_blank" rel="noopener noreferrer" class="title-link">DocAsRef: A Pilot Empirical Study on Repurposing Reference-Based Summary  Quality Metrics Reference-Freely, Forrest Sheng Bao+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- å‚ç…§ãƒ™ãƒ¼ã‚¹ã¨å‚ç…§ãƒ•ãƒªãƒ¼ã®è¦ç´„è©•ä¾¡ãƒ¡ãƒˆãƒªãƒƒã‚¯ãŒã‚ã‚Šã¾ã™ã€‚å‚ç…§ãƒ™ãƒ¼ã‚¹ã¯æ­£ç¢ºã§ã™ãŒã€åˆ¶ç´„ãŒã‚ã‚Šã¾ã™ã€‚å‚ç…§ãƒ•ãƒªãƒ¼ã¯ç‹¬ç«‹ã—ã¦ã„ã¾ã™ãŒã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã¨æ­£ç¢ºã•ã®ä¸¡æ–¹ã‚’æº€ãŸã›ã¾ã›ã‚“ã€‚æœ¬ç ”ç©¶ã§ã¯ã€å‚ç…§ãƒ™ãƒ¼ã‚¹ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã‹ã¤æ­£ç¢ºãªå‚ç…§ãƒ•ãƒªãƒ¼ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒæœ€ã‚‚å„ªã‚ŒãŸå‚ç…§ãƒ•ãƒªãƒ¼ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’æä¾›ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€å‚ç…§ãƒ™ãƒ¼ã‚¹ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®å†åˆ©ç”¨ã¨è¿½åŠ ã®èª¿æ•´ã«ã¤ã„ã¦ã‚‚èª¿æŸ»ã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/PersonalizedGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedGeneration</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/PersonalizedHeadlineGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedHeadlineGeneration</a>
<span class="issue_date">Issue Date: 2023-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/929" target="_blank" rel="noopener noreferrer" class="title-link">Personalized News Headline Generation System with Fine-grained User Modeling, Yao, MSN'22</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èˆˆå‘³ã«åŸºã¥ã„ã¦ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦‹å‡ºã—ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã€æ–‡ãƒ¬ãƒ™ãƒ«ã®æƒ…å ±ã‚’è€ƒæ…®ã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã™ã‚‹ã€‚ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å±¤ã‚’ä½¿ç”¨ã—ã¦æ–‡ã¨ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®é–¢é€£æ€§ã‚’è¨ˆç®—ã—ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å†…å®¹ã«åŸºã¥ã„ã¦è¦‹å‡ºã—ã‚’ç”Ÿæˆã™ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€ææ¡ˆãƒ¢ãƒ‡ãƒ«ãŒãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚å°†æ¥ã®æ–¹å‘æ€§ã¨ã—ã¦ã€æƒ…å ±ã®ãƒ¬ãƒ™ãƒ«ã¨å†…å®¹ã‚’æ¨ªæ–­ã™ã‚‹ç›¸äº’ä½œç”¨ã«ã¤ã„ã¦ã‚‚è­°è«–ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/PersonalizedGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedGeneration</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/PersonalizedHeadlineGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedHeadlineGeneration</a>
<span class="issue_date">Issue Date: 2023-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/928" target="_blank" rel="noopener noreferrer" class="title-link">Personalized Headline Generation with Enhanced User Interest Perception, Zhang+, ICANN'22</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹é–²è¦§å±¥æ­´ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€å€‹åˆ¥åŒ–ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹å‡ºã—ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã™ã‚‹ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èˆˆå‘³ã‚’å¼·èª¿ã™ã‚‹ãŸã‚ã«å€™è£œãƒ†ã‚­ã‚¹ãƒˆã«é–¢é€£ã™ã‚‹æƒ…å ±ã‚’æ´»ç”¨ã—ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦èˆˆå‘³è¡¨ç¾ã‚’æ”¹å–„ã™ã‚‹ã€‚å¹…åºƒã„å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆæ‰‹æ³•ãŒè¦‹å‡ºã—ç”Ÿæˆã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/PersonalizedGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedGeneration</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2023-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/927" target="_blank" rel="noopener noreferrer" class="title-link">Personalized Chit-Chat Generation for Recommendation Using External Chat Corpora, Chen+, KDD'22</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒƒãƒˆãƒãƒ£ãƒƒãƒˆã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®å¯¾è©±ã«ãŠã„ã¦åŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¨è–¦ã®ãŸã‚ã®å€‹äººåŒ–ã•ã‚ŒãŸãƒãƒƒãƒˆãƒãƒ£ãƒƒãƒˆã‚’ç”Ÿæˆã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚æ—¢å­˜ã®æ–¹æ³•ã¨ã¯ç•°ãªã‚Šã€å¤–éƒ¨ã®ãƒãƒ£ãƒƒãƒˆã‚³ãƒ¼ãƒ‘ã‚¹ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢å¿ƒã‚’æ¨å®šã—ã€å€‹äººåŒ–ã•ã‚ŒãŸãƒãƒƒãƒˆãƒãƒ£ãƒƒãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚å¹…åºƒã„å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆæ‰‹æ³•ã®åŠ¹æœãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<span class="issue_date">Issue Date: 2023-08-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/912" target="_blank" rel="noopener noreferrer" class="title-link">Explaining Patterns in Data with Language Models via Interpretable  Autoprompting, Chandan Singh+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’èª¬æ˜ã™ã‚‹èƒ½åŠ›ã‚’æ¢æ±‚ã—ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ã®LLMã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’èª¬æ˜ã™ã‚‹è‡ªç„¶è¨€èªã®æ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’å°å…¥ã—ã¾ã—ãŸã€‚å®Ÿé¨“çµæœã¯ã€ã“ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒæ­£ç¢ºãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª¬æ˜ã‚’è¦‹ã¤ã‘å‡ºã™ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ç”Ÿæˆã•ã‚Œã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯äººé–“ã«ã‚‚ç†è§£å¯èƒ½ã§ã‚ã‚Šã€å®Ÿä¸–ç•Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„fMRIãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æœ‰ç”¨ãªæ´å¯Ÿã‚’æä¾›ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview: 


<a href="https://openreview.net/forum?id=GvMuB-YsiK6" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=GvMuB-YsiK6</a>


</p>
<p>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆä¸­ã«å­˜åœ¨ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®èª¬æ˜ï¼‰ã‚’LLMã«ã‚ˆã£ã¦ç”Ÿæˆã•ã›ã‚‹ç ”ç©¶<br>![Image](https://github.com/user-attachments/assets/df70f8c2-6eda-412f-84e0-92ffe7152a39)<br>![Image](https://github.com/user-attachments/assets/42b4f4f9-6f6c-4e45-8c7c-db76c5fd9932)</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/861" target="_blank" rel="noopener noreferrer" class="title-link">An Extensible Plug-and-Play Method for Multi-Aspect Controllable Text  Generation, Xuancheng Huang+, N_A, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ãŠã„ã¦è¤‡æ•°ã®å´é¢ã‚’åˆ¶å¾¡ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦ç ”ç©¶ã—ã¾ã—ãŸã€‚å¾“æ¥ã®æ–¹æ³•ã§ã¯ã€ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã®ç›¸äº’å¹²æ¸‰ã«ã‚ˆã‚Šåˆ¶ç´„ãŒä½ä¸‹ã—ã€æœªçŸ¥ã®å´é¢ã®çµ„ã¿åˆã‚ã›ã‚’åˆ¶å¾¡ã™ã‚‹ã“ã¨ãŒåˆ¶é™ã•ã‚Œã¦ã„ã¾ã—ãŸã€‚ãã“ã§ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¯èƒ½ãªã‚²ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã®ä»‹å…¥ã‚’æ­£è¦åŒ–ã—ã€ç›¸äº’å¹²æ¸‰ã®å¢—åŠ ã‚’æŠ‘åˆ¶ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ã“ã®æ–¹æ³•ã«ã‚ˆã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚ã«æœªçŸ¥ã®åˆ¶ç´„ã‚’ä½ã‚³ã‚¹ãƒˆã§æ‹¡å¼µã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã•ã‚‰ã«ã€ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãªåˆ¶ç´„ã¨è‡ªç”±å½¢å¼ã®åˆ¶ç´„ã®ä¸¡æ–¹ã‚’å‡¦ç†ã™ã‚‹çµ±ä¸€ã•ã‚ŒãŸæ–¹æ³•ã‚‚ææ¡ˆã—ã¾ã—ãŸã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆæ‰‹æ³•ãŒåˆ¶ç´„ã®æ­£ç¢ºã•ã€ãƒ†ã‚­ã‚¹ãƒˆã®å“è³ªã€æ‹¡å¼µæ€§ã«ãŠã„ã¦ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/553" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models are Zero-Shot Reasoners, Kojima+, University of Tokyo, NeurIPS'22</a>
<span class="snippet"><span>Comment</span><p>Zero-Shot CoT (Let's think step-by-step.)è«–æ–‡</p>
<p>&lt;img width="856" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/234746367-2cd80e23-8dcb-4244-b56c-e28120629027.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/234746367-2cd80e23-8dcb-4244-b56c-e28120629027.png"&lt;/a&gt;


&gt;<br><br></p>
<p>Zero-Shot-CoTã¯2ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æ§‹æˆã•ã‚Œã‚‹ï¼š<br><br>- STEP1: Reasoning Extraction<br><br>  - å…ƒã®questionã‚’xã¨ã—ã€zero-shot-CoTã®trigger sentenceã‚’tã¨ã—ãŸæ™‚ã«ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ "Q: [X]. A. [T]" ã‚’ç”¨ã„ã¦promptã€€x'ã‚’ä½œæˆ<br><br>  - ã“ã®prompt x'ã«ã‚ˆã£ã¦å¾—ã‚‰ã‚Œã‚‹ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆzã¯reasoningã®rationaleã¨ãªã£ã¦ã„ã‚‹ã€‚<br><br>- STEP2: Answer Extraction<br><br>  - STEP1ã§å¾—ã‚‰ã‚ŒãŸx'ã¨zã‚’ç”¨ã„ã¦ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ "[X'] [Z] [A]" ã‚’ç”¨ã„ã¦promptã‚’ä½œæˆã—ã€quiestionã«å¯¾ã™ã‚‹å›ç­”ã‚’å¾—ã‚‹<br><br>  - ã“ã®ã¨ãã€Aã¯å›ç­”ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã®trigger sentenceã§ã‚ã‚‹ã€‚<br><br>  - Aã¯ã‚¿ã‚¹ã‚¯ã«å¿œã˜ã¦å¤‰æ›´ã™ã‚‹ã®ãŒåŠ¹æœçš„ã§ã‚ã‚Šã€ãŸã¨ãˆã°ã€multi-choice QAã§ã¯ "Therefore, among A through E, the answer is" ã¨ã„ã£ãŸãƒˆãƒªã‚¬ãƒ¼ã‚’ç”¨ã„ãŸã‚Šã€æ•°å­¦ã®å•é¡Œã§ã¯ "Therefore, the answer (arabic numerals) is" ã¨ã„ã£ãŸãƒˆãƒªã‚¬ãƒ¼ã‚’ç”¨ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/236404426-ed936908-3771-4eef-9871-c6ae04c896bf.png" alt="image" loading="lazy"><br><br><br><br>
<strong># å®Ÿé¨“çµæœ<br><br>è¡¨ä¸­ã®æ€§èƒ½æŒ‡æ¨™ã®å·¦å´ã¯ã‚¿ã‚¹ã‚¯ã”ã¨ã«Answer Triggerã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ãŸã‚‚ã®ã§ã€å³å´ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«"The answer is"ã‚’Answer Triggerã¨ã—ãŸå ´åˆã€‚Zero-shot vs. Zero-shot-CoTã§ã¯ã€Zero-Shot-CoTãŒå¤šãã®bç¾åœ°ãƒãƒ¼ã‚¯ã«ãŠã„ã¦é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ãŸã ã—ã€commonsense reasoningã§ã¯performance gainã‚’å¾—ã‚‰ã‚Œãªã‹ã£ãŸã€‚ã“ã‚Œã¯ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
</strong>
<br>
 ã§å ±å‘Šã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€commonsense reasoningã‚¿ã‚¹ã‚¯ã§ã¯ã€Few-Shot CoTã§ã‚‚Lambda135Bã§æ€§èƒ½ãŒå‘ä¸Šã›ãšã€Palm540Bã§æ€§èƒ½ãŒå‘ä¸Šã—ãŸã‚ˆã†ã«ã€ãƒ¢ãƒ‡ãƒ«ã®parameteræ•°ãŒè¶³ã‚Šã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ï¼ˆæœ¬å®Ÿé¨“ã§ã¯17ç¨®é¡ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ã„ã‚‹ãŒã€ç‰¹ã«æ³¨é‡ˆãŒãªã‘ã‚Œã°text-davinci-002ã‚’åˆ©ç”¨ã—ãŸçµæœï¼‰ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/236405336-fe5e1f7f-9d2f-457f-9e25-98afe4ae0ec1.png" alt="image" loading="lazy"><br><br><br><br>
<strong>## ä»–ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®æ¯”è¼ƒ<br><br>ä»–ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨arithmetic reasoning benchmarkã§æ€§èƒ½æ¯”è¼ƒã—ãŸçµæœã€‚Few-Shot-CoTã«ã¯å‹ã¦ã¦ã„ãªã„ãŒã€standard Few-shot Promptingtã‚’å¤§å¹…ã«ä¸Šå›ã£ã¦ã„ã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/236406621-7862823f-e019-4551-be96-1c97265ca5ba.png" alt="image" loading="lazy"><br><br><br><br>## zero-shot reasoningã«ãŠã‘ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã®å½±éŸ¿<br><br>ã•ã¾ã–ã¾ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€zero-shotã¨zero-shot-CoTã‚’å®Ÿæ–½ã—ãŸå ´åˆã®æ€§èƒ½æ¯”è¼ƒã€‚<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
</strong>
<br>
 ã¨åŒæ§˜ã«ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã„ã¨Zero-shot-CoTã«ã‚ˆã‚‹gainã¯å¾—ã‚‰ã‚Œãªã„ãŒã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã¨ä¸€æ°—ã«gainãŒå¤§ãããªã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/236407727-f29e6f67-8ca1-4623-8341-73bbf2029e67.png" alt="image" loading="lazy"><br><br><br><br>## Zero-shot CoTã«ãŠã‘ã‚‹promptã®é¸æŠã«ã‚ˆã‚‹å½±éŸ¿<br><br>input promptã«å¯¾ã™ã‚‹ãƒ­ãƒã‚¹ãƒˆæ€§ã‚’ç¢ºèªã—ãŸã€‚instructiveã‚«ãƒ†ã‚´ãƒªï¼ˆã™ãªã‚ã¡ã€CoTã‚’ä¿ƒã™ãƒˆãƒªã‚¬ãƒ¼ã§ã‚ã‚Œã°ï¼‰æ€§èƒ½ãŒæ”¹å–„ã—ã¦ã„ã‚‹ã€‚ç‰¹ã«ã€ã©ã®ã‚ˆã†ãªsentenceã®ãƒˆãƒªã‚¬ãƒ¼ã«ã™ã‚‹ã‹ã§æ€§èƒ½ãŒå¤§ããã‹ã‚ã£ã¦ã„ã‚‹ã€‚ä»Šå›ã®å®Ÿé¨“ã§ã¯ã€"Let's think step by step"ãŒæœ€ã‚‚é«˜ã„æ€§èƒ½ã‚’å ã‚æœ€å¤šã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/236408268-8dbc32f3-76c7-4e41-aa1b-a19008aa680c.png" alt="image" loading="lazy"><br><br><br><br>## Few-shot CoTã®prompté¸æŠã«ãŠã‘ã‚‹å½±éŸ¿<br><br>CommonsenseQAã®exampleã‚’ç”¨ã„ã¦ã€AQUA-RAT, MultiArithã‚’Few-shot CoTã§è§£ã„ãŸå ´åˆã®æ€§èƒ½ã€‚ã©ã¡ã‚‰ã®ã‚±ãƒ¼ã‚¹ã‚‚ãƒ‰ãƒ¡ã‚¤ãƒ³ã¯ç•°ãªã‚‹ãŒã€å‰è€…ã¯å›ç­”ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯å…±é€šã§ã‚ã‚‹ã€‚ç•°ãªã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã‚‚ã€answer formatï¼ˆmultiple choiceï¼‰ã®å ´åˆã€ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒç•°ãªã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€zero-shotã¨æ¯”è¼ƒã—ã¦æ€§èƒ½ãŒå¤§å¹…ã«å‘ä¸Šã—ãŸã€‚ä¸€æ–¹ã€answer formatãŒç•°ãªã‚‹å ´åˆã¯performance gainãŒå°ã•ã„ã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€LLMã¯taskè‡ªä½“ã‚ˆã‚Šã‚‚ã€exampleã«ãŠã‘ã‚‹repeated formatã‚’æ´»ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€CommonSennseã‚’Examplarã¨ã—ã¦ç”¨ã„ãŸFew-Shot-CoTã§ã¯ã€ã©ã¡ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚Zero-Shot-CoTã‚ˆã‚Šã‚‚æ€§èƒ½ãŒåŠ£åŒ–ã—ã¦ã„ã‚‹ã€‚ã¤ã¾ã‚Šã€Few-Shot-CoTã§ã¯ã€ã‚¿ã‚¹ã‚¯ç‰¹æœ‰ã®ã‚µãƒ³ãƒ—ãƒ«ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ï¼ˆä¸€æ–¹ã€Zero-shot CoTã§ã¯ãã®ã‚ˆã†ãªã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¯å¿…è¦ãªã„ï¼‰ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/236408978-b292ea0f-0a17-42fc-8e3c-6eee35780ca4.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer" class="title-link">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
<span class="snippet"><span>Comment</span><p>Chain-of-Thoughtã‚’ææ¡ˆã—ãŸè«–æ–‡ã€‚CoTã‚’ã™ã‚‹ä¸Šã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒ100Bæœªæº€ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã‚ã¾ã‚ŠåŠ¹æœãŒç™ºæ®ã•ã‚Œãªã„ã¨ã„ã†ã“ã¨ã¯å¿µé ­ã«ç½®ã„ãŸæ–¹ãŒè‰¯ã•ãã†ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/234739470-be1c9299-0dd6-4483-901a-0bf855e73f0f.png" alt="image" loading="lazy"><br><br></p>
<p>å…ˆè¡Œç ”ç©¶ã§ã¯ã€reasoningãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ãŒä½ã„å•é¡Œã‚’intermediate stepã‚’æ˜ç¤ºçš„ã«ä½œæˆã—ã€pre-trainedãƒ¢ãƒ‡ãƒ«ã‚’finetuningã™ã‚‹ã“ã¨ã§è§£æ±ºã—ã¦ã„ãŸã€‚ã—ã‹ã—ã“ã®æ–¹æ³•ã§ã¯ã€finetuningç”¨ã®é«˜å“è³ªãªrationaleãŒè¨˜è¿°ã•ã‚ŒãŸå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã™ã‚‹ã®ã«å¤šå¤§ãªã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã¨ã„ã†å•é¡ŒãŒã‚ã£ãŸã€‚<br><br>ã“ã®ãŸã‚ã€few-shot promptingã«ã‚ˆã£ã¦ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ã“ã¨ãŒè€ƒãˆã‚‰ã‚Œã‚‹ãŒã€reasoningèƒ½åŠ›ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§ã¯æ€§èƒ½ãŒæ‚ªã„ã¨ã„ã†å•é¡Œã‚ãŒã£ãŸã€‚ãã“ã§ã€ä¸¡è€…ã®å¼·ã¿ã‚’çµ„ã¿åˆã‚ã›ãŸæ‰‹æ³•ã¨ã—ã¦ã€chain-of-thought promptingã¯ææ¡ˆã•ã‚ŒãŸã€‚</p>
<p># CoTã«ã‚ˆã‚‹å®Ÿé¨“çµæœ<br><br>ä»¥ä¸‹ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’åˆ©ç”¨<br><br>- math word problem: GSM8K, SVAMP, ASDiv, AQuA, MAWPS<br><br>- commonsense reasoning: CSQA, StrategyQA, Big-bench Effort (Date, Sports), SayCan<br><br>- Symbolic Reasoning: Last Letter concatenation, Coin Flip<br><br>  - Last Letter concatnation: åå‰ã®å˜èªã®last wordã‚’concatã™ã‚‹ã‚¿ã‚¹ã‚¯ï¼ˆ"Amy Brown" -&gt; "yn"ï¼‰<br><br>  - Coin Flip: ã‚³ã‚¤ãƒ³ã‚’ã²ã£ãã‚Šè¿”ã™ã€ ã‚ã‚‹ã„ã¯ã²ã£ãã‚Šè¿”ã•ãªã„å‹•ä½œã®è¨˜è¿°ã®å¾Œã«ã€ã‚³ã‚¤ãƒ³ãŒè¡¨å‘ãã§ã‚ã‚‹ã‹ã©ã†ã‹ã‚’ãƒ¢ãƒ‡ãƒ«ã«å›ç­”ã™ã‚‹ã‚ˆã†æ±‚ã‚ã‚‹ã‚¿ã‚¹ã‚¯<br><br> <br><br>## math word problem benchmark<br><br>- ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã«ã¤ã‚Œæ€§èƒ½ãŒå¤§ããå‘ä¸Šï¼ˆemergent abilityï¼‰ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹<br><br>  - è¨€ã„æ›ãˆã‚‹ã¨CoTã¯&lt;100Bã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å¯¾ã—ã¦ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚’ä¸ãˆãªã„<br><br>  - ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã„ã¨ã€èª¤ã£ãŸCoTã‚’ç”Ÿæˆã—ã¦ã—ã¾ã†ãŸã‚<br><br>- è¤‡é›‘ãªå•é¡Œã«ãªã‚Œã°ãªã‚‹ã»ã©ã€CoTã«ã‚ˆã‚‹æ©æµãŒå¤§ãã„<br><br>  - ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®æ€§èƒ½ãŒæœ€ã‚‚ä½ã‹ã£ãŸGSM8Kã§ã¯ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®2å€å‘ä¸Šã—ã¦ãŠã‚Šã€1 stepã®reasoningã§è§£æ±ºã§ãã‚‹SingleOpã‚„MAWPSã§ã¯ã€æ€§èƒ½ã®å‘ä¸Šå¹…ãŒå°ã•ã„<br><br>- Task specificãªãƒ¢ãƒ‡ãƒ«ã‚’finetuningã—ãŸä»¥å‰ã®SoTAã¨æ¯”è¼ƒã—ã¦comparable, ã‚ã‚‹ã„ã¯outperformã—ã¦ã„ã‚‹<br><br>- <img src="https://user-images.githubusercontent.com/12249301/236394200-826ba167-8ec7-4abb-ba4d-fe44bf247b41.png" alt="image" loading="lazy"><br><br>## Ablation Study<br><br>CoTã§ã¯ãªãã€ä»–ã®ã‚¿ã‚¤ãƒ—ã®promptingã§ã‚‚åŒã˜ã‚ˆã†ãªåŠ¹æœãŒå¾—ã‚‰ã‚Œã‚‹ã®ã§ã¯ãªã„ã‹ï¼Ÿã¨ã„ã†ç–‘å•ã«å›ç­”ã™ã‚‹ãŸã‚ã«ã€3ã¤ã®promptingã‚’å®Ÿæ–½ã—ã€CoTã¨æ€§èƒ½æ¯”è¼ƒã—ãŸï¼š<br><br>- Equation Only: å›ç­”ã™ã‚‹ã¾ãˆã«æ•°å¼ã‚’è¨˜è¼‰ã™ã‚‹ã‚ˆã†ãªprompt<br><br>  - promptã®ä¸­ã«æ•°å¼ãŒæ›¸ã‹ã‚Œã¦ã„ã‚‹ã‹ã‚‰æ€§èƒ½æ”¹å–„ã•ã‚Œã¦ã„ã‚‹ã®ã§ã¯ï¼Ÿã¨ã„ã†ç–‘å•ã«å¯¾ã™ã‚‹æ¤œè¨¼<br><br>  - =&gt; GSM8Kã«ã‚ˆã‚‹çµæœã‚’è¦‹ã‚‹ã¨ã€equation onlyã§ã¯æ€§èƒ½ãŒä½ã‹ã£ãŸã€‚ã“ã‚Œã¯ã€ã“ã‚Œã¯æ•°å¼ã ã‘ã§reasoning stepsã‚’è¡¨ç¾ã§ããªã„ã“ã¨ã«èµ·å› ã—ã¦ã„ã‚‹<br><br>- Variable compute only: dotã®sequence (...) ã®ã¿ã®prompt<br><br>  - CoTã¯é›£ã—ã„å•é¡Œã«å¯¾ã—ã¦ã‚ˆã‚Šå¤šãã®è¨ˆç®—ï¼ˆintermediate tokenï¼‰ã‚’ã™ã‚‹ã“ã¨ãŒã§ãã¦ã„ã‚‹ã‹ã‚‰ã§ã¯ï¼Ÿã¨ã„ã†ç–‘å•ã«å¯¾ã™ã‚‹æ¤œè¨¼<br><br>  - variable computationã¨CoTã®å½±éŸ¿ã‚’åˆ†é›¢ã™ã‚‹ãŸã‚ã«ã€dotã®sequence (...) ã®ã¿ã§promptingã™ã‚‹æ–¹æ³•ã‚’æ¤œè¨¼<br><br>  - =&gt; çµæœã¯baselineã¨æ€§èƒ½å¤‰ã‚ã‚‰ãšã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€variableã®è¨ˆç®—è‡ªä½“ãŒæ€§èƒ½å‘ä¸Šã«å¯„ä¸ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br>- Chain of Thought after answer: å›ç­”ã®å¾Œã«CoTã‚’å‡ºåŠ›ã™ã‚‹ã‚ˆã†ãªprompting<br><br>  - å˜ã«pretrainingã®éš›ã®relevantãªçŸ¥è­˜ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã‚„ã™ããªã£ã¦ã„ã‚‹ã ã‘ãªã®ã§ã¯ï¼Ÿã¨ã„ã†ç–‘å•ã‚’æ¤œè¨¼<br><br>  - =&gt; baselineã¨æ€§èƒ½ã¯å¤‰ã‚ã‚‰ãšã€å˜ã«çŸ¥è­˜ã‚’æ´»æ€§åŒ–ã•ã›ã‚‹ã ã‘ã§ã¯æ€§èƒ½ãŒå‘ä¸Šã—ãªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/236396383-877a26ae-20c2-42a4-a023-1eb66abf8320.png" alt="image" loading="lazy"><br><br><br><br>## CoTã®ãƒ­ãƒã‚¹ãƒˆæ€§<br><br>äººé–“ã®Annotatorã«CoTã‚’ä½œæˆã•ã›ã€ãã‚Œã‚‰ã‚’åˆ©ç”¨ã—ãŸCoTpromptingã¨examplarãƒ™ãƒ¼ã‚¹ãªæ‰‹æ³•ã«ã‚ˆã£ã¦æ€§èƒ½ãŒã©ã‚Œã ã‘å¤‰ã‚ã‚‹ã‹ã‚’æ¤œè¨¼ã€‚standard promptingã‚’å…¨ã¦ã®å ´åˆã§ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç²å¾—ã—ãŸã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€linguisticãªstyleã«CoTã¯å½±éŸ¿ã‚’å—ã‘ã¦ã„ãªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/236397864-073dd88f-95c0-47f0-af3c-ed7288ca967d.png" alt="image" loading="lazy"><br><br><br><br># commonsense reasoning<br><br>å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãŠã„ã¦ã€CoTãŒstandard promptingã‚’outperformã—ãŸã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/236398447-6c58a3f3-7461-4109-9a96-8f8092831dd1.png" alt="image" loading="lazy"><br><br><br><br># Symbolic Reasoning<br><br>in-domain test setã¨out-of-domain test setã®2ç¨®é¡ã‚’ç”¨æ„ã—ãŸã€‚å‰è€…ã¯å¿…è¦ãªreasoning stepãŒfew-shot examplarã¨åŒä¸€ã®ã‚‚ã®ã€å¾Œè€…ã¯å¿…è¦ãªreasoning stepãŒfew-shot examplarã‚ˆã‚Šã‚‚å¤šã„ã‚‚ã®ã§ã‚ã‚‹ã€‚<br><br>CoTãŒStandard proimptingã‚’ä¸Šå›ã£ã¦ã„ã‚‹ã€‚ç‰¹ã«ã€standard promptingã§ã¯OOV test setã§ã¯ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã¦ã‚‚æ€§èƒ½ãŒå‘ä¸Šã—ãªã‹ã£ãŸã®ã«å¯¾ã—ã€CoTã§ã¯ã‚ˆã‚Šå¤§ããªgainã‚’å¾—ã¦ã„ã‚‹ã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€CoTã«ã¯reasoning stepã®lengthã«å¯¾ã—ã¦ã‚‚æ±åŒ–èƒ½åŠ›ãŒã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/236399389-30e62218-3e59-4912-983c-818de457fa04.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/523" target="_blank" rel="noopener noreferrer" class="title-link">Recurrent Memory Transformer, Bulatov+, NeurIPS'22</a>
<span class="snippet"><span>Comment</span><p>Transformerã¯O(N^2)ã§ã‚ã‚Šã€è¨ˆç®—é‡ãŒNã«å¿œã˜ã¦æŒ‡æ•°é–¢æ•°çš„ã«å¢—åŠ ã—ã¦ã—ã¾ã†ã€‚ä¸€æ–¹ã€sequenceã®æƒ…å ±ã‚’å…¨ã¦Næ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ã«é›†ç´„ã—ãªã‘ã‚Œã°ãªã‚‰ãšã€è¨ˆç®—é‡ã®åˆ¶ç´„ã«ã‚ˆã£ã¦é•·ã„ç³»åˆ—ã®Representationã‚’ç²å¾—ã§ããªã„ã€‚<br><br>ãã“ã§ã€Transformerã®æ§‹é€ ã¯å¤‰ãˆãšã€Inputã«ãƒ¡ãƒ¢ãƒªtokenã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ãƒ¡ãƒ¢ãƒªé–“ã®é–¢ä¿‚æ€§ã‚’å­¦ç¿’ã§ãã‚‹ã‚ˆã†ãªæ‰‹æ³•ã‚’ææ¡ˆã€‚é•·ã„ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã«å¯¾ã—ã¦ã‚‚ã€ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã‚†ã°ã‚Œã‚‹å˜ä½ã«åŒºåˆ‡ã‚Šã€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®Inputã®é ­ã§ã€å‰æ–­ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ãƒ¡ãƒ¢ãƒªtokenã‚’å…¥åŠ›ã—ã€æœ€çµ‚çš„ã«ç¾åœ¨ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ãƒ¡ãƒ¢ãƒªã‚’outputã—ã€å¾Œæ–­ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«å…¥åŠ›ã¨ã™ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚’ç¹°ã‚Šè¿”ã™ã“ã¨ã§ã€é•·ã„ç³»åˆ—ã‚‚æ‰±ãˆã‚‹ã‚ˆã†ã«ã—ãŸã€‚<br><br>ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ã¾ãŸã„ã§backpropagationã‚’ã‹ã‘ã‚‹ã“ã¨ã§ã€ãŸã¨ãˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦ã¯ç‹¬ç«‹ã—ã¦ã„ã¦ã‚‚ã€ãƒ¡ãƒ¢ãƒªã®æƒ…å ±ã‚’è€ƒæ…®ã™ã‚‹ã“ã¨ã§ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“ã®ä¾å­˜é–¢ä¿‚ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/234206394-925cb6ee-85bd-46ad-b7ed-f57685badc38.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2022-12-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/501" target="_blank" rel="noopener noreferrer" class="title-link">UNIFIEDSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models, Xie+, EMNLP'22</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2022-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/500" target="_blank" rel="noopener noreferrer" class="title-link">Revisiting Pretraining Objectives for Tabular Deep Learning, Rubachev+, Yandex+, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¯GBDTã¨ç«¶äº‰ã—ã¦ãŠã‚Šã€äº‹å‰å­¦ç¿’ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«é©ç”¨å¯èƒ½ãªäº‹å‰å­¦ç¿’ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’ç‰¹å®šã—ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ©ãƒ™ãƒ«ã®ä½¿ç”¨ãŒæœ‰ç›Šã§ã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚é©åˆ‡ãªäº‹å‰å­¦ç¿’ã«ã‚ˆã‚Šã€æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¯GBDTã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Tabular Dataã‚’åˆ©ç”¨ã—ãŸå ´åˆã«Kaggleãªã©ã§Deepãªãƒ¢ãƒ‡ãƒ«ãŒGBDTç­‰ã«å‹ã¦ãªã„ã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ãŒã€GBDTç­‰ã¨comparable ã«ãªã‚‹æ€§èƒ½ã«ãªã‚‹ã‚ˆã†ãªpre-trainingã‚’ææ¡ˆã—ãŸã‚ˆã€çš„ãªå†…å®¹ã£ã½ã„</p>
<p>ICLR 2023 OpenReview: 


<a href="https://openreview.net/forum?id=kjPLodRa0n" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=kjPLodRa0n</a>


</p></span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<span class="issue_date">Issue Date: 2022-02-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/436" target="_blank" rel="noopener noreferrer" class="title-link">JaQuAD: Japanese Question Answering Dataset for Machine Reading Comprehension, So+, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- æ—¥æœ¬èªã®è³ªå•å¿œç­”ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆJaQuADã‚’ææ¡ˆã€‚39,696ã®è³ªå•-å›ç­”ãƒšã‚¢ã‚’å«ã¿ã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§F1ã‚¹ã‚³ã‚¢78.92%ã€EMã‚¹ã‚³ã‚¢63.38%ã‚’é”æˆã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯[ã“ã¡ã‚‰](https://github.com/SkelterLabsInc/JaQuAD)ã‹ã‚‰å…¥æ‰‹å¯èƒ½ã€‚</span>
<span class="snippet"><span>Comment</span><p>SQuAD likeãªæ—¥æœ¬èªã®QAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br><br>


<a href="https://github.com/SkelterLabsInc/JaQuAD" target="_blank" rel="noopener noreferrer">https://github.com/SkelterLabsInc/JaQuAD</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2021-06-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/379" target="_blank" rel="noopener noreferrer" class="title-link">Improving Neural Machine Translation with Compact Word Embedding Tables, Kumar+, AAAI'22</a>
<span class="snippet"><span>Comment</span><p>NMTã«ãŠã„ã¦word embeddingãŒã©ã†å½±éŸ¿ã—ã¦ã„ã‚‹ã‹ãªã©ã‚’èª¿æŸ»ã—ã¦ã„ã‚‹ã‚‰ã—ã„</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ZeroshotHyperparameterTransfer.html" target="_blank" rel="noopener noreferrer">#ZeroshotHyperparameterTransfer</a>
<span class="issue_date">Issue Date: 2025-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2582" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Tensor Programs V: Tuning Large Neural Networks via Zero-Shot  Hyperparameter Transfer, Greg Yang+, NeurIPS'21</a>
<span class="snippet"><span>GPT Summary</span>- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯é«˜ã‚³ã‚¹ãƒˆã§ã‚ã‚Šã€ç‰¹ã«å¤§è¦æ¨¡ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãŠã„ã¦è² æ‹…ãŒå¤§ãã„ã€‚æ–°ãŸã«ææ¡ˆã™ã‚‹muTransferã¯ã€æœ€å¤§æ›´æ–°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ï¼ˆmuPï¼‰ã‚’åˆ©ç”¨ã—ã€å°ã•ãªãƒ¢ãƒ‡ãƒ«ã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸHPã‚’ãƒ•ãƒ«ã‚µã‚¤ã‚ºãƒ¢ãƒ‡ãƒ«ã«ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§è»¢é€ã™ã‚‹æ‰‹æ³•ã§ã‚ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€1300ä¸‡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰BERT-largeã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’é”æˆã—ã€4000ä¸‡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰ã¯GPT-3ã‚’ä¸Šå›ã‚‹çµæœã‚’å¾—ãŸã€‚ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ã‚¹ãƒˆã¯ãã‚Œãã‚Œäº‹å‰å­¦ç¿’ã‚³ã‚¹ãƒˆã®åŒç­‰ã¾ãŸã¯7%ã«æŠ‘ãˆã‚‰ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=Bx6qKuBM2AD" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Bx6qKuBM2AD</a>


</p>
<p>å°è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿæ–½ã—ã€åŒæ§˜ã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§ã€**å„layerã®widthãŒå¤§ãã„ã‚‚ã®**ã«å¯¾ã—ã¦ã‚‚ã€å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§æœ€é©ã§ã‚ã£ãŸãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’zero-shotã§è»¢ç§»ã™ã‚‹ã“ã¨ã§ near optimalãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å­¦ç¿’ã§ãã‚‹mu Transferã‚’ææ¡ˆã€‚<br><br>ãƒ¢ãƒ‡ãƒ«ã®æ·±ã•ï¼ˆä»¥å¤–ã«ã‚‚ä¸‹è¡¨ä¸­ã®*å°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ã«å¯¾ã—ã¦ã‚‚é™å®šçš„ã«è»¢ç§»å¯èƒ½ãªæ¨¡æ§˜ã€‚Post-Layer Normã®Transformerã‚„ã§ã¯ã‚ã¾ã‚Šã†ã¾ãã„ã‹ãªã„ã“ã¨ãŒ11ç¯€ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ï¼ˆå®Ÿé¨“ã¯pre-Layer Norm Transformer, ResNetã«å¯¾ã—ã¦è¡Œã‚ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ï¼‰ã€‚<br>ã¾ãŸã€6.1ç¯€ã§ã¯ã€ï¼ˆå®Ÿé¨“çš„ã«ï¼‰åˆ©ç”¨ã™ã‚‹å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒ«ã¨ã—ã¦å¹…256, æ·±ã•4, ãƒãƒƒãƒã‚µã‚¤ã‚º32, sequenceé•·128, è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—æ•°5000ã‚’æœ€ä½æº€ãŸã—ã¦ãŠã‚Šã€ã‹ã¤ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹å¹…ãŒå¦¥å½“ãªç¯„å›²å†…ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ã€ã¨ã„ã£ãŸè©±ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>å‰æçŸ¥è­˜ï¼ˆmuPï¼‰ã‚„æ¡ä»¶ãŒå¤šãã†ãªæ°—ãŒã™ã‚‹ã®ã§ã€ã—ã£ã‹ã‚Šç¢ºèªã—ãŸæ–¹ãŒã‚ˆã•ãã†ã€‚<br>ãŸã¨ãˆã°ã€muPã§åˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚„ã€è»¢é€å¯èƒ½ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«é™ã‚ŠãŒã‚ã‚‹ï¼ˆe.g. å­¦ç¿’ç‡ï¼‰ã€ç•°ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹finetuningãªã©ã¯è»¢é€ã§ããªã„ãªã©ã€‚<br><br><br>&lt;img width="872" height="336" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/e5aeb152-5c9e-4ba2-9152-4bfef0d7c27c"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/e5aeb152-5c9e-4ba2-9152-4bfef0d7c27c"&lt;/a&gt;


/&gt;</p>
<p>muP:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2583" target="_blank" rel="noopener noreferrer">[Paper Note] Feature Learning in Infinite-Width Neural Networks, Greg Yang+, PMLR'21</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/CodeGeneration.html" target="_blank" rel="noopener noreferrer">#CodeGeneration</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2439" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Program Synthesis with Large Language Models, Jacob Austin+, arXiv'21</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€æ±ç”¨ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã«ãŠã‘ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ åˆæˆã®é™ç•Œã‚’å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦è©•ä¾¡ã—ã¾ã™ã€‚MBPPã¨MathQA-Pythonã®2ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«å¯¾ã™ã‚‹åˆæˆæ€§èƒ½ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚’èª¿æŸ»ã€‚æœ€ã‚‚å¤§ããªãƒ¢ãƒ‡ãƒ«ã¯ã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã§MBPPã®59.6ï¼…ã®å•é¡Œã‚’è§£æ±ºå¯èƒ½ã§ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šç´„10ï¼…ã®æ€§èƒ½å‘ä¸ŠãŒè¦‹ã‚‰ã‚Œã¾ã—ãŸã€‚MathQA-Pythonã§ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒ83.8ï¼…ã®ç²¾åº¦ã‚’é”æˆã€‚äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ã§ã‚¨ãƒ©ãƒ¼ç‡ãŒåŠæ¸›ã—ã€ã‚¨ãƒ©ãƒ¼åˆ†æã‚’é€šã˜ã¦ãƒ¢ãƒ‡ãƒ«ã®å¼±ç‚¹ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã—ãŸã€‚æœ€çµ‚çš„ã«ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ å®Ÿè¡Œçµæœã®äºˆæ¸¬èƒ½åŠ›ã‚’æ¢ã‚‹ã‚‚ã€æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ç‰¹å®šã®å…¥åŠ›ã«å¯¾ã™ã‚‹å‡ºåŠ›äºˆæ¸¬ãŒå›°é›£ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ä»£è¡¨çš„ãªã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚<br><br>MBPPãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€promptã§æŒ‡ç¤ºã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’ãƒ¢ãƒ‡ãƒ«ã«ç”Ÿæˆã•ã›ã€ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ï¼ˆassertion)ã‚’é€šéã™ã‚‹ã‹å¦ã‹ã§è©•ä¾¡ã™ã‚‹ã€‚974ã‚µãƒ³ãƒ—ãƒ«å­˜åœ¨ã—ã€pythonã®åŸºç¤ã‚’æŒã¤ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚ˆã£ã¦ç”Ÿæˆã€‚ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚¿ã‚¹ã‚¯descriptionã¨ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã™ã‚‹ä¸€ã¤ã®é–¢æ•°ï¼ˆé–¢æ•°ã®ã¿ã§å®Ÿè¡Œå¯èƒ½ã§printã¯ä¸å¯ï¼‰ã€3ã¤ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’è¨˜è¿°ã™ã‚‹ã‚ˆã†ä¾é ¼ã€‚ã‚¿ã‚¹ã‚¯descriptionã¯è¿½åŠ ãªclarificationãªã—ã§ã‚³ãƒ¼ãƒ‰ãŒè¨˜è¿°ã§ãã‚‹ã‚ˆã†ååˆ†ãªæƒ…å ±ã‚’å«ã‚€ã‚ˆã†è¨˜è¿°ã™ã‚‹ã‚ˆã†ã«æŒ‡ç¤ºã€‚ground truthã®é–¢æ•°ã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€webã‚’é–²è¦§ã™ã‚‹ã“ã¨ã‚’è¨±å¯ã—ãŸã€‚<br><img src="https://github.com/user-attachments/assets/e27880f7-4647-462d-b619-e0a7a0959d66" alt="image" loading="lazy"><br><br>MathQA-Pythonã¯ã€MathQAã«å«ã¾ã‚Œã‚‹QAã®ã†ã¡è§£ç­”ãŒæ•°å€¤ã®ã‚‚ã®ã®ã¿ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€åˆè¨ˆã§23914ã‚µãƒ³ãƒ—ãƒ«å­˜åœ¨ã™ã‚‹ã€‚pythonã‚³ãƒ¼ãƒ‰ã§ä¸ãˆã‚‰ã‚ŒãŸæ•°å­¦ã«é–¢ã™ã‚‹å•é¡Œã‚’è§£ãã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã€æ•°å€¤ãŒä¸€è‡´ã™ã‚‹ã‹å¦ã‹ã§è©•ä¾¡ã™ã‚‹ã€ã¨ã„ã£ãŸæ„Ÿã˜ãªæ¨¡æ§˜ã€‚æ–œã‚èª­ã¿ãªã®ã§å°‘ã—èª­ã¿é•ãˆã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚<br><br><img src="https://github.com/user-attachments/assets/d21ee76f-a13d-4ef9-843b-74c233c3c0a6" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/CodeGeneration.html" target="_blank" rel="noopener noreferrer">#CodeGeneration</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2438" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Evaluating Large Language Models Trained on Code, Mark Chen+, arXiv'21</a>
<span class="snippet"><span>GPT Summary</span>- Codexã¯GitHubã®ã‚³ãƒ¼ãƒ‰ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸGPTè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€Pythonã‚³ãƒ¼ãƒ‰ç”Ÿæˆèƒ½åŠ›ã‚’è©•ä¾¡ã€‚æ–°ã—ã„è©•ä¾¡ã‚»ãƒƒãƒˆHumanEvalã§ã¯ã€CodexãŒ28.8%ã®å•é¡Œã‚’è§£æ±ºã—ã€GPT-3ã¯0%ã€GPT-Jã¯11.4%ã ã£ãŸã€‚ç¹°ã‚Šè¿”ã—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒé›£ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã—ã¦ã‚‚åŠ¹æœçš„ãªæˆ¦ç•¥ã‚’ç”¨ã„ã€70.2%ã®å•é¡Œã‚’è§£æ±ºã€‚ãƒ¢ãƒ‡ãƒ«ã®é™ç•Œã¨ã—ã¦ã€é•·ã„æ“ä½œã®èª¬æ˜ã‚„å¤‰æ•°ã¸ã®ãƒã‚¤ãƒ³ãƒ‰ã«è‹¦åŠ´ã™ã‚‹ç‚¹ãŒæ˜ã‚‰ã‹ã«ã€‚æœ€å¾Œã«ã€ã‚³ãƒ¼ãƒ‰ç”ŸæˆæŠ€è¡“ã®å½±éŸ¿ã«ã¤ã„ã¦å®‰å…¨æ€§ã‚„çµŒæ¸ˆã«é–¢ã™ã‚‹è­°è«–ã‚’è¡Œã†ã€‚</span>
<span class="snippet"><span>Comment</span><p>HumanEvalãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚Killed by LLMã«ã‚ˆã‚‹ã¨ã€GPT4oã«ã‚ˆã‚Šã™ã§ã«90%ç¨‹åº¦ã®æ€§èƒ½ãŒé”æˆã•ã‚Œé£½å’Œã—ã¦ã„ã‚‹ã€‚<br><br>164å€‹ã®äººæ‰‹ã§è¨˜è¿°ã•ã‚ŒãŸprogrammingã®å•é¡Œã§ã€ãã‚Œãã‚Œã¯function signature, docstring, body, unittestã‚’æŒã¤ã€‚unittestã¯å•é¡Œå½“ãŸã‚Šç´„7.7 testå­˜åœ¨ã€‚handwrittenã¨ã„ã†ç‚¹ãŒãƒŸã‚½ã§ã€ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã®æ‡¸å¿µãŒã‚ã‚‹ãŸã‚githubã®ã‚ˆã†ãªæ—¢å­˜ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ã‚³ãƒ”ãƒ¼ãªã©ã¯ã—ã¦ã„ãªã„ã€‚pass@k[^1]ã§è©•ä¾¡ã€‚<br><br>[^1]: kå€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã•ã›ã€kå€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã®ã†ã¡ã€ã‚µãƒ³ãƒ—ãƒ«ãŒunittestã‚’ä¸€ã¤ã§ã‚‚é€šéã™ã‚‹ç¢ºç‡ã€‚ãŸã ã€æœ¬ç ”ç©¶ã§ã¯ã‚ˆã‚Šãƒã‚¤ã‚¢ã‚¹ã‚’ãªãã™ãŸã‚ã«ã€kã‚ˆã‚Šã‚‚å¤§ãã„nå€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã—ã€ãã®ä¸­ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«kå€‹ã‚’é¸æŠã—ã¦ç¢ºç‡ã‚’æ¨å®šã™ã‚‹ã‚ˆã†ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚2.1ç¯€ã‚’å‚ç…§ã®ã“ã¨ã€‚<br><br><img src="https://github.com/user-attachments/assets/74a74b6f-9d0c-4ce9-ab8b-53b478b4632a" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/FactualKnowledge.html" target="_blank" rel="noopener noreferrer">#FactualKnowledge</a>
<span class="issue_date">Issue Date: 2025-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2140" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Transformer Feed-Forward Layers Are Key-Value Memories, Mor Geva+, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰å±¤ã¯ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã®å¤§éƒ¨åˆ†ã‚’å ã‚ã‚‹ãŒã€ãã®å½¹å‰²ã¯æœªæ¢æ±‚ã€‚ç ”ç©¶ã«ã‚ˆã‚Šã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰å±¤ãŒã‚­ãƒ¼ãƒ»ãƒãƒªãƒ¥ãƒ¼ãƒ»ãƒ¡ãƒ¢ãƒªã¨ã—ã¦æ©Ÿèƒ½ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ç›¸é–¢ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚å®Ÿé¨“ã§ã€ä¸‹å±¤ã¯æµ…ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ä¸Šå±¤ã¯æ„å‘³çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã€ãƒãƒªãƒ¥ãƒ¼ãŒå‡ºåŠ›åˆ†å¸ƒã‚’èª˜å°ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚æœ€çµ‚çš„ã«ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰å±¤ã®å‡ºåŠ›ã¯ãƒ¡ãƒ¢ãƒªã®åˆæˆã§ã‚ã‚Šã€æ®‹å·®æ¥ç¶šã‚’é€šã˜ã¦æ´—ç·´ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬ï¼ˆp.5ã‚ˆã‚Šï¼‰: 


<a href="https://speakerdeck.com/kogoro/knowledge-neurons-in-pretrained-transformers-for-snlp2022?slide=5" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/kogoro/knowledge-neurons-in-pretrained-transformers-for-snlp2022?slide=5</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2056" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Editing Factual Knowledge in Language Models, Nicola De Cao+, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- KnowledgeEditorã¯ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ã‚’ç·¨é›†ã—ã€å†å­¦ç¿’ãªã—ã§èª¤ã£ãŸäº‹å®Ÿã‚„äºˆæ¸¬ã‚’ä¿®æ­£ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚åˆ¶ç´„æœ€é©åŒ–ã‚’ç”¨ã„ã¦ãƒã‚¤ãƒ‘ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è¨“ç·´ã—ã€ä»–ã®çŸ¥è­˜ã«å½±éŸ¿ã‚’ä¸ãˆãšã«äº‹å®Ÿã‚’ä¿®æ­£ã—ã¾ã™ã€‚BERTã¨BARTã®ãƒ¢ãƒ‡ãƒ«ã§ãã®æœ‰åŠ¹æ€§ã‚’ç¤ºã—ã€ç‰¹å®šã®ã‚¯ã‚¨ãƒªã«åŸºã¥ãäºˆæ¸¬å¤‰æ›´ãŒãƒ‘ãƒ©ãƒ•ãƒ¬ãƒ¼ã‚ºã«ã‚‚ä¸€è²«ã—ã¦å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚ãƒã‚¤ãƒ‘ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ã€çŸ¥è­˜æ“ä½œã«å¿…è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ç‰¹å®šã™ã‚‹ã€Œãƒ—ãƒ­ãƒ¼ãƒ–ã€ã¨ã—ã¦æ©Ÿèƒ½ã—ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2024-12-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1618" target="_blank" rel="noopener noreferrer" class="title-link">Training Verifiers to Solve Math Word Problems, Karl Cobbe+, arXiv'21</a>
<span class="snippet"><span>GPT Summary</span>- GSM8Kãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€å¤šæ®µéšã®æ•°å­¦çš„æ¨è«–ã«ãŠã‘ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã®é™ç•Œã‚’åˆ†æã€‚æ¤œè¨¼å™¨ã‚’è¨“ç·´ã—ã€å€™è£œè§£ã‚’è©•ä¾¡ã—ã¦æœ€é©è§£ã‚’é¸æŠã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚æ¤œè¨¼ã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚ˆã‚Šã‚‚ãƒ‡ãƒ¼ã‚¿å¢—åŠ ã«å¯¾ã—ã¦åŠ¹æœçš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>## æ°—æŒã¡<br><br>- å½“æ™‚ã®æœ€ã‚‚å¤§ãã„ãƒ¬ãƒ™ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ multi-stepã®reasoningãŒå¿…è¦ãªå•é¡Œã¯å¤±æ•—ã™ã‚‹<br><br>- ãƒ¢ãƒ‡ãƒ«ã‚’Finetuningã‚’ã—ã¦ã‚‚è‡´å‘½çš„ãªãƒŸã‚¹ãŒå«ã¾ã‚Œã‚‹<br><br>- ç‰¹ã«ã€æ•°å­¦ã¯å€‹ã€…ã®ãƒŸã‚¹ã«å¯¾ã—ã¦éå¸¸ã«sensitiveã§ã‚ã‚Šã€ä¸€å›ãƒŸã‚¹ã‚’ã—ã¦ç•°ãªã‚‹è§£æ³•ã®ãƒ‘ã‚¹ã«å…¥ã£ã¦ã—ã¾ã†ã¨ã€self-correctionã™ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒauto-regressiveãªãƒ¢ãƒ‡ãƒ«ã§ã¯ã†ã¾ãã„ã‹ãªã„<br><br>- ç´”ç²‹ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®æ çµ„ã¿ã§ãã‚Œãªã‚Šã®æ€§èƒ½ã«åˆ°é”ã—ã‚ˆã†ã¨ã™ã‚‹ã¨ã€ã¨ã‚“ã§ã‚‚ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¿…è¦ã«ãªã‚Šã€ã‚ˆã‚Šè‰¯ã„scaling lawã‚’ç¤ºã™æ‰‹æ³•ã‚’æ¨¡ç´¢ã™ã‚‹å¿…è¦ãŒã‚ã‚‹<br><br>## Contribution<br><br>è«–æ–‡ã®è²¢çŒ®ã¯<br><br>- GSM8Kã‚’ææ¡ˆã—ã€<br><br>- verifierã‚’æ´»ç”¨ã—ãƒ¢ãƒ‡ãƒ«ã®è¤‡æ•°ã®å€™è£œã®ä¸­ã‹ã‚‰è‰¯ã„å€™è£œã‚’é¸ã¶ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã£ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’30å€ã«ã—ãŸã®ã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™ã¨verifierã‚’å°å…¥ã™ã‚‹ã¨ã‚ˆã‚Šã‚ˆãæ€§èƒ½ãŒã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br>- ã¾ãŸã€dropoutãŒéå¸¸ã«å¼·ã„æ­£å‰‡åŒ–ä½œç”¨ã‚’ä¿ƒã—ã€finetuningã¨verificationã®åŒæ–¹ã‚’å¤§ããæ”¹å–„ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</p>
<p>Todo: ç¶šãã‚’ã¾ã¨ã‚ã‚‹</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2024-10-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1439" target="_blank" rel="noopener noreferrer" class="title-link">Intrinsic Dimensionality Explains the Effectiveness of Language Model   Fine-Tuning, Armen Aghajanyan+, N_A, ACL'21</a>
<span class="snippet"><span>GPT Summary</span>- äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’å†…å› æ¬¡å…ƒã®è¦³ç‚¹ã‹ã‚‰åˆ†æã—ã€å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã‚‚åŠ¹æœçš„ã«èª¿æ•´ã§ãã‚‹ç†ç”±ã‚’èª¬æ˜ã€‚ä¸€èˆ¬çš„ãªãƒ¢ãƒ‡ãƒ«ã¯ä½ã„å†…å› æ¬¡å…ƒã‚’æŒã¡ã€ãƒ•ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã¨åŒç­‰ã®åŠ¹æœã‚’æŒã¤ä½æ¬¡å…ƒã®å†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ç‰¹ã«ã€RoBERTaãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ã€å°‘æ•°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æœ€é©åŒ–ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã§ãã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã€‚ã¾ãŸã€äº‹å‰å­¦ç¿’ãŒå†…å› æ¬¡å…ƒã‚’æœ€å°åŒ–ã—ã€å¤§ããªãƒ¢ãƒ‡ãƒ«ãŒä½ã„å†…å› æ¬¡å…ƒã‚’æŒã¤å‚¾å‘ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€å†…å› æ¬¡å…ƒã«åŸºã¥ãä¸€èˆ¬åŒ–å¢ƒç•Œã‚’ææ¡ˆã€‚</span>
<span class="snippet"><span>Comment</span><p>ACL ver:


<a href="https://aclanthology.org/2021.acl-long.568.pdf" target="_blank" rel="noopener noreferrer">https://aclanthology.org/2021.acl-long.568.pdf</a>


</p>
<p>ä¸‹è¨˜ã®å…ƒãƒã‚¹ãƒˆã‚’æ‹èª­ã®ä¸Šè«–æ–‡ã‚’æ–œã‚èª­ã¿ã€‚ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„ã»ã©ã€ç‰¹å®šã®æ€§èƒ½ï¼ˆè«–æ–‡ä¸­ã§ã¯2ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®90%ã®sentence predictionæ€§èƒ½ï¼‰ã‚’finetuningã§é”æˆã™ã‚‹ãŸã‚ã«å¿…è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚Œã°ãªã‚‹ã»ã©å°ã•ããªã£ã¦ã„ã‚‹ã€‚<br><br>LoRAã¨ã®é–¢ä¿‚æ€§ã«ã¤ã„ã¦ã‚‚å…ƒãƒã‚¹ãƒˆä¸­ã§è¨€åŠã•ã‚Œã¦ãŠã‚Šã€è«–æ–‡ã®ä¸­èº«ã‚‚è¦‹ã¦å¾Œã§ç¢ºèªã™ã‚‹ã€‚<br>ãŠãã‚‰ãã€LLMã¯BERTãªã©ã¨æ¯”è¼ƒã—ã¦é¥ã‹ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤§ãã„ãŸã‚ã€finetuningã«è¦ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯ã•ã‚‰ã«å°ã•ããªã£ã¦ã„ã‚‹ã“ã¨ãŒæƒ³åƒã•ã‚Œã€LoRAã®ã‚ˆã†ãªå°‘é‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’concatã™ã‚‹ã ã‘ã§ã†ã¾ãã„ãã€ã¨ã„ã†ã‚ˆã†ãªè©±ã ã¨æ€ã‚ã‚Œã‚‹ã€‚èˆˆå‘³æ·±ã„ã€‚<br><br><img src="https://github.com/user-attachments/assets/166ebdae-539f-44cf-822b-0084640e07b2" alt="image" loading="lazy"><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bilzrd/status/1840445027438456838?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2024-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1333" target="_blank" rel="noopener noreferrer" class="title-link">Transformer Feed-Forward Layers Are Key-Value Memories, Mor Geva+, N_A, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰å±¤ã¯ã€ã‚­ãƒ¼ãƒ»ãƒãƒªãƒ¥ãƒ¼ãƒ¡ãƒ¢ãƒªã¨ã—ã¦æ©Ÿèƒ½ã—ã€å­¦ç¿’ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ãŒäººé–“ã«è§£é‡ˆå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚„ã€ä¸Šä½å±¤ãŒã‚ˆã‚Šæ„å‘³ã®ã‚ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã•ã‚‰ã«ã€å‡ºåŠ›åˆ†å¸ƒã‚’èª˜å°ã™ã‚‹å½¹å‰²ã‚‚æŒã¡ã¾ã™ã€‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰å±¤ã®å‡ºåŠ›ã¯ãã®ãƒ¡ãƒ¢ãƒªã®åˆæˆã§ã‚ã‚Šã€æ®‹å·®æ¥ç¶šã‚’ä»‹ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®å±¤ã‚’é€šã˜ã¦æ´—ç·´ã•ã‚Œã€æœ€çµ‚çš„ãªå‡ºåŠ›åˆ†å¸ƒã‚’ç”Ÿæˆã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1108" target="_blank" rel="noopener noreferrer">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ï½¤ã€ŒçŸ¥è­˜ã¯å…¨çµåˆå±¤ã«è“„ç©ã•ã‚Œã‚‹ã€ã¨ã„ã†ä»®èª¬ã«ã¤ã„ã¦ã®æ–‡çŒ®èª¿æŸ»</a>
 </p>
<p>FF layerãŒKey-Valueã‚¹ãƒˆã‚¢ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ä»•çµ„ã¿ã®æ¦‚ç•¥å›³<br><img src="https://github.com/user-attachments/assets/cc12695f-b030-433a-88e1-aed69f9847a7" alt="image" loading="lazy"><br><br>å®Ÿéš›ã«ç‰¹å®šã®Keyã¨æœ€ã‚‚é–¢é€£åº¦ãŒé«˜ã„è¨“ç·´äº‹ä¾‹ï¼ˆinputï¼‰ã‚’æŠ½å‡ºã—ã€äººé–“ãŒinputã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†é¡ã—ãŸçµæœ<br><img src="https://github.com/user-attachments/assets/d1c1a031-9cb8-4e22-bf87-23964f0e0c71" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Annotation.html" target="_blank" rel="noopener noreferrer">#Annotation</a>
<span class="issue_date">Issue Date: 2024-05-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1306" target="_blank" rel="noopener noreferrer" class="title-link">The Perils of Using Mechanical Turk to Evaluate Open-Ended Text  Generation, Marzena Karpinska+, N_A, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®ç ”ç©¶ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«æ³¨åŠ›ã—ã¦ãŠã‚Šã€ãã®è©•ä¾¡ãŒé›£ã—ã„ãŸã‚ã€å¤šãã®ç ”ç©¶è€…ãŒã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚·ãƒ³ã‚°ã•ã‚ŒãŸäººé–“ã®åˆ¤æ–­ã‚’åé›†ã—ã¦ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚’æ­£å½“åŒ–ã—ã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€å¤šãã®ç ”ç©¶ã¯é‡è¦ãªè©³ç´°ã‚’å ±å‘Šã—ã¦ãŠã‚‰ãšã€å†ç¾æ€§ãŒå¦¨ã’ã‚‰ã‚Œã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã•ã‚‰ã«ã€åŠ´åƒè€…ã¯ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆã®ãƒ†ã‚­ã‚¹ãƒˆã¨äººé–“ã«ã‚ˆã‚‹å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆã‚’åŒºåˆ¥ã§ããªã„ã“ã¨ãŒç™ºè¦‹ã•ã‚Œã€è¡¨ç¤ºæ–¹æ³•ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§æ”¹å–„ã•ã‚Œã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚è‹±èªæ•™å¸«ã¨ã®ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è©•ä¾¡ã™ã‚‹éš›ã®èª²é¡Œã«ã¤ã„ã¦ã€ã‚ˆã‚Šæ·±ã„æ´å¯ŸãŒå¾—ã‚‰ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Open-endedãªã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹AMTã®è©•ä¾¡ã®å†ç¾æ€§ã«é–¢ã™ã‚‹ç ”ç©¶ã€‚å…ˆè¡Œç ”ç©¶ã‚’Surveyã—ãŸã¨ã“ã‚ã€å†ç¾ã®ãŸã‚ã«é‡è¦ãªæƒ…å ±ï¼ˆãŸã¨ãˆã°ã€workerã®è³‡æ ¼ã€è²»ç”¨ã€task descriptionsã€annotatoré–“ã®agreementãªã©ï¼‰ãŒæ¬ è½ã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ãŸã€‚<br><br>ç¶šã„ã¦ã€expertsã¨AMT workerã«å¯¾ã—ã¦ã€story generationã®è©•ä¾¡ã‚’å®Ÿæ–½ã—ã€GPT2ãŒç”Ÿæˆã—ãŸã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã¨äººé–“ãŒç”Ÿæˆã—ãŸã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’ã€å¾Œè€…ã®ã‚¹ã‚³ã‚¢ãŒé«˜ããªã‚‹ã“ã¨ã‚’æœŸå¾…ã—ã¦ä¾é ¼ã—ãŸã€‚ãã®çµæœ<br><br>- AMTã®ratingã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã¨ã€äººé–“ãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’reliableã«åŒºåˆ¥ã§ããªã„<br><br>- åŒä¸€ã®ã‚¿ã‚¹ã‚¯ã‚’ç•°ãªã‚‹æ—¥ç¨‹ã§å®Ÿæ–½ã‚’ã™ã‚‹ã¨ã€é«˜ã„åˆ†æ•£ãŒç”Ÿã˜ãŸ<br><br>- å¤šãã®AMT workerã¯ã€è©•ä¾¡å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ³¨æ„æ·±ãèª­ã‚“ã§ã„ãªã„<br><br>- Expertã§ã•ãˆãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿åˆ¤æ–­ã™ã‚‹ã®ã«ã¯è‹¦æˆ¦ã‚’ã—ã€å…ˆè¡Œç ”ç©¶ã¨æ¯”è¼ƒã—ã¦ã‚ˆã‚Šå¤šãã®æ™‚é–“ã‚’è²»ã‚„ã—ã€agreementãŒä½ããªã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸ<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1dc01c56-88b0-4bea-869b-f396d65701cc" alt="image" loading="lazy"><br><br></p>
<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/892" target="_blank" rel="noopener noreferrer">Can Large Language Models Be an Alternative to Human Evaluations? Cheng-Han Chiang, Hung-yi Lee, ACL'23</a>
 ã«ãŠã„ã¦ã€ä½å“è³ªãªwork forceãŒäººæ‰‹è©•ä¾¡ã«å¯¾ã—ã¦æœ‰å®³ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã€ã¨ã„ã†æ–‡è„ˆã§æœ¬ç ”ç©¶ãŒå¼•ç”¨ã•ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1221" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Experts, Errors, and Context: A Large-Scale Study of Human Evaluation  for Machine Translation, Markus Freitag+, arXiv'21</a>
<span class="snippet"><span>GPT Summary</span>- æ©Ÿæ¢°ç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ ã®äººé–“ã«ã‚ˆã‚‹è©•ä¾¡ã¯é›£ã—ãã€æ¨™æº–çš„ãªæ‰‹ç¶šããŒæ¬ å¦‚ã—ã¦ã„ã‚‹ã€‚ãã“ã§ã€MQMãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«åŸºã¥ãè©•ä¾¡æ–¹æ³•è«–ã‚’ææ¡ˆã—ã€WMT 2020ã®ãƒˆãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ã®å‡ºåŠ›ã‚’ãƒ—ãƒ­ã®ç¿»è¨³è€…ã«ã‚ˆã‚‹æ³¨é‡ˆã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ãŸã€‚åˆ†æã®çµæœã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚ˆã‚‹è©•ä¾¡ã¨ã¯ç•°ãªã‚Šã€äººé–“ã®å‡ºåŠ›ãŒæ©Ÿæ¢°ã®å‡ºåŠ›ã‚ˆã‚Šå¥½ã¾ã‚Œã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã¾ãŸã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿ã«åŸºã¥ãè‡ªå‹•ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒäººé–“ã®è©•ä¾¡ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚‚æ˜ã‚‰ã‹ã«ãªã£ãŸã€‚ã‚³ãƒ¼ãƒ‘ã‚¹ã¯ä»Šå¾Œã®ç ”ç©¶ã®ãŸã‚ã«å…¬é–‹ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>embedding basedãªNLGã®æ€§èƒ½æŒ‡æ¨™ãŒã€æ„å‘³ã®ç­‰ä¾¡æ€§ã‚„æµæš¢æ€§ã‚’è©•ä¾¡ã§ãã‚‹ä¸€æ–¹ã€é©ç”¨ç¯„å›²ãŒé™å®šçš„ã§æŸ”è»Ÿæ€§ã«æ¬ ã‘ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸç ”ç©¶</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2023-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1009" target="_blank" rel="noopener noreferrer" class="title-link">ViLT: Vision-and-Language Transformer Without Convolution or Region   Supervision, Wonjae Kim+, N_A, ICML'21</a>
<span class="snippet"><span>GPT Summary</span>- VLPï¼ˆVision-and-Language Pre-trainingï¼‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€ãƒ“ã‚¸ãƒ§ãƒ³ã¨è¨€èªã®ã‚¿ã‚¹ã‚¯ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã¦ã„ã‚‹ãŒã€ç¾åœ¨ã®æ–¹æ³•ã¯åŠ¹ç‡æ€§ã¨è¡¨ç¾åŠ›ã®é¢ã§å•é¡ŒãŒã‚ã‚‹ã€‚ãã“ã§ã€æœ¬ç ”ç©¶ã§ã¯ç•³ã¿è¾¼ã¿ãƒ•ãƒªãƒ¼ã®ãƒ“ã‚¸ãƒ§ãƒ³ã¨è¨€èªã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒï¼ˆViLTï¼‰ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã™ã‚‹ã€‚ViLTã¯é«˜é€Ÿã§ã‚ã‚ŠãªãŒã‚‰ç«¶äº‰åŠ›ã®ã‚ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ã‚³ãƒ¼ãƒ‰ã¨äº‹å‰å­¦ç¿’æ¸ˆã¿ã®é‡ã¿ã¯GitHubã§åˆ©ç”¨å¯èƒ½ã§ã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://tech.fusic.co.jp/posts/2021-12-29-vilt/" target="_blank" rel="noopener noreferrer">https://tech.fusic.co.jp/posts/2021-12-29-vilt/</a>


</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/984" target="_blank" rel="noopener noreferrer" class="title-link">SummEval: Re-evaluating Summarization Evaluation, Fabbri+, TACL'21</a>
<span class="snippet"><span>Comment</span><p>è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ãŒäººæ‰‹è©•ä¾¡ã®æ°´æº–ã«é”ã—ãªã„ã“ã¨ãŒç¤ºã•ã‚Œã¦ãŠã‚Šã€çµå±€ã®ã¨ã“ã‚ROUGEã‚’ä¸Šå›ã‚‹è‡ªå‹•æ€§èƒ½æŒ‡æ¨™ã¯ã»ã¨ã‚“ã©ãªã‹ã£ãŸã€‚human judgmentsã¨ã®Kendall;'s Tauã‚’è¦‹ã‚‹ã¨ã€chrFãŒCoherenceã¨Relevance, METEORãŒFluencyã§ä¸Šå›ã£ãŸã®ã¿ã ã£ãŸã€‚ã¾ãŸã€LEAD-3ã¯ã‚„ã¯ã‚Šãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã—ã¦ã‹ãªã‚Šå¼·ãã€LEAD-3ã‚’ä¸Šå›ã£ãŸã®ã¯BARTã¨PEGASUSã ã£ãŸã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/981" target="_blank" rel="noopener noreferrer" class="title-link">How to Evaluate a Summarizer: Study Design and Statistical Analysis for Manual Linguistic Quality Evaluation, Steen+, EACL'21</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡æ–¹æ³•ã«ã¤ã„ã¦ã®èª¿æŸ»çµæœã‚’å ±å‘Šã—ã¾ã—ãŸã€‚è¦ç´„ã®è¨€èªçš„å“è³ªã«ã¤ã„ã¦ã®è©•ä¾¡å®Ÿé¨“ã‚’è¡Œã„ã€æœ€é©ãªè©•ä¾¡æ–¹æ³•ã¯å´é¢ã«ã‚ˆã£ã¦ç•°ãªã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€ç ”ç©¶ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚„çµ±è¨ˆåˆ†ææ–¹æ³•ã«ã¤ã„ã¦ã‚‚å•é¡Œç‚¹ã‚’æŒ‡æ‘˜ã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ç¾è¡Œã®æ–¹æ³•ã§ã¯å›ºå®šã•ã‚ŒãŸç ”ç©¶äºˆç®—ã®ä¸‹ã§ã¯ä¿¡é ¼æ€§ã®ã‚ã‚‹æ³¨é‡ˆã‚’æä¾›ã§ããªã„ã“ã¨ã‚’å¼·èª¿ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>è¦ç´„ã®äººæ‰‹è©•ä¾¡ã«å¯¾ã™ã‚‹ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/980" target="_blank" rel="noopener noreferrer" class="title-link">Reliability of Human Evaluation for Text Summarization: Lessons Learned and Challenges Ahead, Iskender+, EACL'21</a>
<span class="snippet"><span>GPT Summary</span>- äººé–“è©•ä¾¡ã®ä¿¡é ¼æ€§ã«é–¢ã™ã‚‹ç ”ç©¶ã§ã¯ã€å‚åŠ è€…ã®æƒ…å ±ã‚„å®Ÿé¨“ã®è©³ç´°ãŒæä¾›ã•ã‚Œã¦ã„ãªã„ã“ã¨ãŒå¤šã„ã€‚ã¾ãŸã€äººé–“è©•ä¾¡ã®ä¿¡é ¼æ€§ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹è¦å› ã«ã¤ã„ã¦ã‚‚ç ”ç©¶ã•ã‚Œã¦ã„ãªã„ã€‚ãã“ã§ã€ç§ãŸã¡ã¯äººé–“è©•ä¾¡å®Ÿé¨“ã‚’è¡Œã„ã€å‚åŠ è€…ã®æƒ…å ±ã‚„å®Ÿé¨“ã®è©³ç´°ã‚’æä¾›ã—ã€ç•°ãªã‚‹å®Ÿé¨“çµæœã‚’æ¯”è¼ƒã—ãŸã€‚ã•ã‚‰ã«ã€å°‚é–€å®¶ã¨éå°‚é–€å®¶ã®è©•ä¾¡ã®ä¿¡é ¼æ€§ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã—ã€ä¿¡é ¼æ€§ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹è¦å› ã‚’ç‰¹å®šã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>è¦ç´„ã®äººæ‰‹è©•ä¾¡ã«å¯¾ã™ã‚‹ä¿¡é ¼æ€§ã«é–¢ã—ã¦ç ”ç©¶ã€‚äººæ‰‹è©•ä¾¡ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/976" target="_blank" rel="noopener noreferrer" class="title-link">The Feasibility of Embedding Based Automatic Evaluation for Single Document Summarization, EMNLP-IJCNLP'21, Sun+</a>
<span class="snippet"><span>Comment</span><p>__translate: ROUGE is widely used to automatically evaluate summarization systems. However, ROUGE measures semantic overlap between a system summary and a human reference on word-string level, much at odds with the contemporary treatment of semantic meaning. Here we present a suite of experiments on using distributed representations for evaluating summarizers, both in reference-based and in reference-free setting. Our experimental results show that the max value over each dimension of the summary ELMo word embeddings is a good representation that results in high correlation with human ratings. Averaging the cosine similarity of all encoders we tested yields high correlation with manual scores in reference-free setting. The distributed representations outperform ROUGE in recent corpora for abstractive news summarization but are less good on test data used in past evaluations.</p>
<p>C-ELMO/C-SBERT</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/975" target="_blank" rel="noopener noreferrer" class="title-link">A Training-free and Reference-free Summarization Evaluation Metric via Centrality-weighted Relevance and Self-referenced Redundancy, Chen+, ACL-IJCNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- å‚ç…§ãƒ™ãƒ¼ã‚¹ã¨æ•™å¸«ã‚ã‚Šã®è¦ç´„è©•ä¾¡æŒ‡æ¨™ã®åˆ¶ç´„ã‚’å›é¿ã™ã‚‹ãŸã‚ã«ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒªãƒ¼ã‹ã¤å‚ç…§ãƒ•ãƒªãƒ¼ã®è¦ç´„è©•ä¾¡æŒ‡æ¨™ã‚’ææ¡ˆã™ã‚‹ã€‚ã“ã®æŒ‡æ¨™ã¯ã€æ–‡ã®ä¸­å¿ƒæ€§ã«ã‚ˆã£ã¦é‡ã¿ä»˜ã‘ã•ã‚ŒãŸæ¦‚å¿µå‚ç…§ã¨è¦ç´„ã¨ã®é–¢é€£æ€§ã‚¹ã‚³ã‚¢ã¨ã€è‡ªå·±å‚ç…§ã®å†—é•·æ€§ã‚¹ã‚³ã‚¢ã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹ã€‚é–¢é€£æ€§ã‚¹ã‚³ã‚¢ã¯æ“¬ä¼¼å‚ç…§ã¨è¦ç´„ã¨ã®é–“ã§è¨ˆç®—ã•ã‚Œã€é‡è¦åº¦ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’æä¾›ã™ã‚‹ã€‚è¦ç´„ã®å†—é•·æ€§ã‚¹ã‚³ã‚¢ã¯è¦ç´„å†…ã®å†—é•·ãªæƒ…å ±ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«è¨ˆç®—ã•ã‚Œã‚‹ã€‚é–¢é€£æ€§ã‚¹ã‚³ã‚¢ã¨å†—é•·æ€§ã‚¹ã‚³ã‚¢ã‚’çµ„ã¿åˆã‚ã›ã¦ã€è¦ç´„ã®æœ€çµ‚è©•ä¾¡ã‚¹ã‚³ã‚¢ã‚’ç”Ÿæˆã™ã‚‹ã€‚å¾¹åº•çš„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆæ‰‹æ³•ãŒæ—¢å­˜ã®æ‰‹æ³•ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/QA-based.html" target="_blank" rel="noopener noreferrer">#QA-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/974" target="_blank" rel="noopener noreferrer" class="title-link">QuestEval: Summarization Asks for Fact-based Evaluation, Thomas Scialom+, N_A, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ã®è©•ä¾¡ã¯æœªè§£æ±ºã®èª²é¡Œã§ã‚ã‚Šã€æ—¢å­˜ã®è©•ä¾¡æŒ‡æ¨™ã¯é™å®šçš„ã§ã‚ã‚Šã€äººé–“ã®åˆ¤æ–­ã¨ã®ç›¸é–¢ãŒä½ã„ã€‚ãã“ã§ã€æœ¬ç ”ç©¶ã§ã¯è³ªå•å¿œç­”ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ãŸè©•ä¾¡æŒ‡æ¨™QuestEvalã‚’ææ¡ˆã™ã‚‹ã€‚QuestEvalã¯æ­£è§£ã®å‚ç…§ã‚’å¿…è¦ã¨ã›ãšã€ä¸€è²«æ€§ã€çµæŸæ€§ã€æµæš¢ã•ã€é–¢é€£æ€§ã®4ã¤ã®è©•ä¾¡æ¬¡å…ƒã«ãŠã„ã¦äººé–“ã®åˆ¤æ–­ã¨ã®ç›¸é–¢ã‚’å¤§å¹…ã«æ”¹å–„ã™ã‚‹ã“ã¨ãŒå®Ÿé¨“ã«ã‚ˆã‚Šç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>QuestEval</p>
<p>
<strong># æ¦‚è¦<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/984" target="_blank" rel="noopener noreferrer">SummEval: Re-evaluating Summarization Evaluation, Fabbri+, TACL'21</a>
</strong>
<br>
 ã«ã‚ˆã£ã¦ææ¡ˆã•ã‚Œã¦ããŸãƒ¡ãƒˆãƒªãƒƒã‚¯ãŒROUGEã«å‹ã¦ã¦ã„ãªã„ã“ã¨ã«ã¤ã„ã¦è¨€åŠã—ã€ã‚ˆã‚Šè‰¯ã„æŒ‡æ¨™ã‚’ææ¡ˆã€‚<br><br>- precision / recall-based ãª QA metricsã‚’åˆ©ç”¨ã—ã¦ã‚ˆã‚Šãƒ­ãƒã‚¹ãƒˆ<br><br>- ç”Ÿæˆã•ã‚Œã‚‹queryã®saliencyã‚’å­¦ç¿’ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã™ã‚‹ã“ã¨ã§ã€information selectionã®æ¦‚å¿µã‚’å°å…¥ã—ãŸ<br><br>- CNN/Daily Mail, XSUMã§è©•ä¾¡ã—ãŸçµæœã€SoTAãªçµæœã‚’ç²å¾—ã—ã€ç‰¹ã«Factual Consistencyã®è©•ä¾¡ã«æœ‰ç”¨ãªã“ã¨ã‚’ç¤ºã—ãŸ<br><br><br><br>
<strong># Question-based framework<br><br>prerainedãªT5ã‚’åˆ©ç”¨ã—QAã«å›ç­”ã™ã‚‹componentï¼ˆquestion, TextãŒgivenãªæ™‚answerã‚’ç”Ÿæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚text Tã«å¯¾ã™ã‚‹query qã«å¯¾ã—ã¦rã¨å›ç­”ã™ã‚‹ç¢ºç‡ã‚’Q_A(r|T, q)ã¨ã—ã€Q_A(T, q)ã‚’ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦greedyã«ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã¨ã™ã‚‹ã€‚QuestionãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã€Summaryå†…ã«å›ç­”ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã¯åˆ†ã‹ã‚‰ãªã„ã€‚ãã®ãŸã‚ã€unanswerable token Îµã‚‚QA componentã«å«ã‚ã‚‹ã€‚<br><br>QG componentã¨ã—ã¦ã¯ã€answer-source documentãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«äººé–“ãŒç”Ÿæˆã—ãŸquestionã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†finetuningã•ã‚ŒãŸT5ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹ã€‚ãƒ†ã‚¹ãƒˆæ™‚ã¯ã€ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã€ã‚·ã‚¹ãƒ†ãƒ è¦ç´„ãŒgivenãªã¨ãã«ã€ã¯ã˜ã‚ã«QG modelã‚’æ¡ä»¶ä»˜ã‘ã™ã‚‹ãŸã‚ã®answerã®setã‚’é¸æŠã™ã‚‹ã€‚<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1007" target="_blank" rel="noopener noreferrer">Asking and Answering Questions to Evaluate the Factual Consistency of Summaries, Wang, ACL'20</a>
</strong>
<br>
 ã«ãªã‚‰ã„ã€ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å…¨ã¦ã®å›ºæœ‰åè©ã¨åè©ã‚’answerã¨ã¿ãªã™ã€‚ãã—ã¦ã€ãã‚Œãã‚Œã®é¸æŠã•ã‚ŒãŸanswerã”ã¨ã«ã€beam searchã‚’ç”¨ã„ã¦questionã‚’ç”Ÿæˆã™ã‚‹ã€‚ãã—ã¦ã€QAãƒ¢ãƒ‡ãƒ«ãŒèª¤ã£ãŸå›ç­”ã‚’ã—ãŸå ´åˆã€ãã®ã‚ˆã†ãªquestionã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã€‚text Tã«ãŠã„ã¦ã€Q_A(T, q) = rã¨ãªã‚‹question-answer pairs (q, r)ã®é›†åˆã‚’ã€Q_G(T)ã¨è¡¨è¨˜ã™ã‚‹ã€‚<br><br><br><br>
<strong># QuestEval metric<br><br>## Precision<br><br>source documentã‚’D, ã‚·ã‚¹ãƒ†ãƒ è¦ç´„ã‚’Sã¨ã—ãŸã¨ãã«ã€Precision, Recallã‚’ä»¥ä¸‹ã®å¼ã§æ¸¬ã‚‹ï¼š<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3c1092a6-5a6e-494b-8ec1-a30fdc8ad96c" alt="image" loading="lazy"><br><br>questionç”Ÿæˆæ™‚ã¯è¦ç´„ã‹ã‚‰ç”Ÿæˆã—ã€ç”Ÿæˆã•ã‚ŒãŸquestionã«å›ç­”ã™ã‚‹éš›ã¯source documentã‚’åˆ©ç”¨ã—ã€å›ç­”ã®æ­£èª¤ã«å¯¾ã—ã¦F1ã‚¹ã‚³ã‚¢ã‚’æ¸¬å®šã™ã‚‹ã€‚F1ã‚¹ã‚³ã‚¢ã¯ã€ground truthã¨äºˆæ¸¬ã•ã‚ŒãŸå›ç­”ã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦æ¸¬å®šã•ã‚Œã€å›ç­”ãŒexact matchã—ãŸå ´åˆã«1, common tokenãŒå­˜åœ¨ã—ãªã„å ´åˆã«0ã‚’è¿”ã™ã€‚D, Sã§æ¡ä»¶ä»˜ã‘ã•ã‚ŒãŸã¨ãã«ã€å›ç­”ãŒå¤‰ã‚ã£ã¦ã—ã¾ã†å ´åˆã¯è¦ç´„ãŒinconsistentã ã¨ã¿ãªã›ã‚‹ã€ã¨ã„ã†intuitionã‹ã‚‰ãã¦ã„ã‚‹ã€‚<br><br>## Recall<br><br>è¦ç´„ã¯factual informationã‚’å«ã‚€ã¹ãã®ã¿ãªã‚‰ãš(precision)ã€ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã®é‡è¦ãªæƒ…å ±ã‚’å«ã‚€ã¹ãã§ã‚ã‚‹(recall)ã€‚<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/943" target="_blank" rel="noopener noreferrer">Answers Unite! Unsupervised Metrics for Reinforced Summarization Models, Scialom+, EMNLP-IJCNLP'19</a>
</strong>
<br>
ã‚’query weighter Wã‚’å°å…¥ã™ã‚‹ã“ã¨ã§æ‹¡å¼µã—ã€recallã‚’ä¸‹è¨˜ã§å®šç¾©ã™ã‚‹ï¼š<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cd44efcd-ca82-43cc-98db-13b697d86068" alt="image" loading="lazy"><br><br>ã“ã“ã§ã€Q_G(D)ã¯ã€ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆDã«ãŠã‘ã‚‹ã™ã¹ã¦ã®QA pairã®é›†åˆã€W(q, D)ã¯Dã«å¯¾ã™ã‚‹qã®é‡ã¿ã§ã‚ã‚‹ã€‚<br><br> <br><br>
<strong>## Answerability and F1<br><br>Factoid QAãƒ¢ãƒ‡ãƒ«ã¯ä¸€èˆ¬çš„ã«ã€predicted answerã¨ground truthã®overlapã«ã‚ˆã£ã¦ï¼ˆF1ï¼‰è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹ã€‚ã—ã‹ã—"ACL"ã¨"Association for Computational Linguistics"ã®ã‚ˆã†ã«ã€åŒã˜å›ç­”ã§ã‚‚ç•°ãªã‚‹æ–¹æ³•ã§è¡¨ç¾ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ã“ã®ä¾‹ã§ã¯ã€F1ã‚¹ã‚³ã‚¢ã¯0ã¨ãªã‚‹ï¼ˆå…±é€šã®tokenãŒãªã„ãŸã‚ï¼‰ã€‚<br><br>ã“ã‚Œã‚’å›é¿ã™ã‚‹ãŸã‚ã«ã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/943" target="_blank" rel="noopener noreferrer">Answers Unite! Unsupervised Metrics for Reinforced Summarization Models, Scialom+, EMNLP-IJCNLP'19</a>
</strong>
<br>
 ã¨åŒæ§˜ã«1-Q_A(Îµ)ã‚’åˆ©ç”¨ã™ã‚‹ã€‚ <br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/bb5379a9-02eb-438a-8bea-3729103bad7a" alt="image" loading="lazy"><br><br><br><br></p>
<p>QG component, QA componentã§åˆ©ç”¨ã™ã‚‹T5ã¯ã€ãã‚Œãã‚Œ[SQuAD-v2](


<a href="https://huggingface.co/datasets/squad_v2)%E3%81%A8%E3%80%81NewsQA%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/squad_v2)ã¨ã€NewsQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</a>


<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1142" target="_blank" rel="noopener noreferrer">NewsQA: A Machine Comprehension Dataset, Adam Trischler+, N/A, arXiv'16</a>
 ã«ã‚ˆã£ã¦finetuningã—ãŸã‚‚ã®ã‚’åˆ©ç”¨ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/DialogueGeneration.html" target="_blank" rel="noopener noreferrer">#DialogueGeneration</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/QA-based.html" target="_blank" rel="noopener noreferrer">#QA-based</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/966" target="_blank" rel="noopener noreferrer" class="title-link">Q2: Evaluating Factual Consistency in Knowledge-Grounded Dialogues via Question Generation and Question Answering, Honovich+, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãªçŸ¥è­˜ã«åŸºã¥ãå¯¾è©±ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼æ€§ã¨é©ç”¨ç¯„å›²ã®åˆ¶é™ã«ã¤ã„ã¦ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€è‡ªå‹•çš„ãªè³ªå•ç”Ÿæˆã¨è³ªå•å¿œç­”ã‚’ä½¿ç”¨ã—ãŸäº‹å®Ÿçš„ãªæ•´åˆæ€§ã®è‡ªå‹•è©•ä¾¡å°ºåº¦ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®å°ºåº¦ã¯ã€è‡ªç„¶è¨€èªæ¨è«–ã‚’ä½¿ç”¨ã—ã¦å›ç­”ã‚¹ãƒ‘ãƒ³ã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ã€ä»¥å‰ã®ãƒˆãƒ¼ã‚¯ãƒ³ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒãƒãƒ³ã‚°ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸè©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚ã¾ãŸã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€äº‹å®Ÿçš„ãªæ•´åˆæ€§ã®æ‰‹å‹•ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã€ä»–ã®å°ºåº¦ã¨ã®ãƒ¡ã‚¿è©•ä¾¡ã‚’è¡Œã„ã¾ã—ãŸã€‚çµæœã¨ã—ã¦ã€ææ¡ˆæ‰‹æ³•ãŒäººé–“ã®åˆ¤æ–­ã¨é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ï¼ˆknowledge-grounded; çŸ¥è­˜ã«åŸºã¥ã„ãŸï¼‰å¯¾è©±ã«å¯¾ã™ã‚‹Factual Consistencyã‚’Reference-freeã§è©•ä¾¡ã§ãã‚‹QGQAæ‰‹æ³•ã€‚æ©Ÿæ¢°ç¿»è¨³ã‚„Abstractive Summarizationã®åˆ†é‡ã§ç ”ç©¶ãŒé€²ã‚“ã§ããŸãŒã€å¯¾è©±ã§ã¯<br><br>- å¯¾è©±å±¥æ­´ã€å€‹äººã®æ„è¦‹ã€ãƒ¦ãƒ¼ã‚¶ã«å¯¾ã™ã‚‹è³ªå•ã€ãã—ã¦é›‘è«‡  <br><br><br><br>ã¨ã„ã£ãŸå¤–éƒ¨çŸ¥è­˜ã«å¯¾ã™ã‚‹consistencyãŒé©åˆ‡ã§ã¯ãªã„è¦ç´ ãŒå¤šãå­˜åœ¨ã—ã€ã‚ˆã‚Šãƒãƒ£ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ãªã‚¿ã‚¹ã‚¯ã¨ãªã£ã¦ã„ã‚‹ã€‚<br><br>ã¾ãŸã€ãã‚‚ãã‚‚å¯¾è©±ã‚¿ã‚¹ã‚¯ã¯open-endedãªã‚¿ã‚¹ã‚¯ãªãŸã‚ã€Reference-basedãªæ‰‹æ³•ã¯ç¾å®Ÿçš„ã§ã¯ãªãã€Reference-freeãªæ‰‹æ³•ãŒå¿…è¦ã¨ä¸»å¼µã€‚<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/979808f2-d31a-49b0-bd25-aba1f1a81d4a" alt="image" loading="lazy"><br><br><br><br>æ‰‹æ³•ã®æ¦‚è¦ã¨ã—ã¦ã¯ä»¥ä¸‹ã€‚ãƒ¦ãƒ¼ã‚¶ã®ç™ºè©±ã‹ã‚‰Question Generation (QG)ã‚’å®Ÿæ–½ã—ã€Question-Answer Candidate Pairã‚’ä½œæˆã™ã‚‹ã€‚ãã—ã¦ã€ç”Ÿæˆã—ãŸQuestionã‚’ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹çŸ¥è­˜ã‹ã‚‰å›ç­”ã•ã›ï¼ˆQAï¼‰ã€ãã®å›ç­”çµæœã¨Answer Candidateã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ã§Factual Consistencyã‚’æ¸¬å®šã™ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e6582686-2ed2-478a-8146-ec9834679df6" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LM-based.html" target="_blank" rel="noopener noreferrer">#LM-based</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/964" target="_blank" rel="noopener noreferrer" class="title-link">Compression, Transduction, and Creation: A Unified Framework for Evaluating Natural Language Generation, Deng+, EMNLP''21</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è‡ªç„¶è¨€èªç”Ÿæˆï¼ˆNLGï¼‰ã‚¿ã‚¹ã‚¯ã®è©•ä¾¡ã«ãŠã„ã¦ã€æƒ…å ±ã®æ•´åˆæ€§ã‚’é‡è¦–ã—ãŸçµ±ä¸€çš„ãªè¦–ç‚¹ã‚’ææ¡ˆã™ã‚‹ã€‚æƒ…å ±ã®æ•´åˆæ€§ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®è§£é‡ˆå¯èƒ½ãªè©•ä¾¡æŒ‡æ¨™ã®ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’é–‹ç™ºã—ã€ã‚´ãƒ¼ãƒ«ãƒ‰ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å¿…è¦ã¨ã›ãšã«ã€ã•ã¾ã–ã¾ãªNLGã‚¿ã‚¹ã‚¯ã®è©•ä¾¡ã‚’è¡Œã†ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’å®Ÿé¨“ã§ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>CTC</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/QA-based.html" target="_blank" rel="noopener noreferrer">#QA-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/961" target="_blank" rel="noopener noreferrer" class="title-link">QACE: Asking Questions to Evaluate an Image Caption, Lee+, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã®è©•ä¾¡ã«ãŠã„ã¦ã€Question Generationï¼ˆQGï¼‰ã¨Question Answeringï¼ˆQAï¼‰ã‚·ã‚¹ãƒ†ãƒ ã«åŸºã¥ã„ãŸè³ªå•å¿œç­”ãƒ¡ãƒˆãƒªãƒƒã‚¯ã§ã‚ã‚‹QACEã‚’ææ¡ˆã™ã‚‹ã€‚QACEã¯è©•ä¾¡å¯¾è±¡ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã«å¯¾ã—ã¦è³ªå•ã‚’ç”Ÿæˆã—ã€ãã®å†…å®¹ã‚’å‚ç…§ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã¾ãŸã¯ã‚½ãƒ¼ã‚¹ç”»åƒã«å¯¾ã—ã¦è³ªå•ã™ã‚‹ã“ã¨ã§ç¢ºèªã™ã‚‹ã€‚QACE_Refã¨ã„ã†ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’é–‹ç™ºã—ã€æœ€å…ˆç«¯ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨ç«¶åˆã™ã‚‹çµæœã‚’å ±å‘Šã™ã‚‹ã€‚ã•ã‚‰ã«ã€å‚ç…§ã§ã¯ãªãç”»åƒè‡ªä½“ã«ç›´æ¥è³ªå•ã‚’ã™ã‚‹QACE_Imgã‚’ææ¡ˆã™ã‚‹ã€‚QACE_Imgã«ã¯Visual-QAã‚·ã‚¹ãƒ†ãƒ ãŒå¿…è¦ã§ã‚ã‚Šã€Visual-T5ã¨ã„ã†æŠ½è±¡çš„ãªVQAã‚·ã‚¹ãƒ†ãƒ ã‚’ææ¡ˆã™ã‚‹ã€‚QACE_Imgã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã§å‚ç…§ã‚’å¿…è¦ã¨ã›ãšã€èª¬æ˜å¯èƒ½ãªãƒ¡ãƒˆãƒªãƒƒã‚¯ã§ã‚ã‚‹ã€‚å®Ÿé¨“ã®çµæœã€QACE_Imgã¯ä»–ã®å‚ç…§ã‚’å¿…è¦ã¨ã—ãªã„ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨æ¯”è¼ƒã—ã¦æœ‰åˆ©ãªçµæœã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Image Captioningã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®QGQAã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚candidateã‹ã‚‰ç”Ÿæˆã—ãŸè³ªå•ã‚’å…ƒç”»åƒ, ãŠã‚ˆã³Referenceã‚’ç”¨ã„ã¦å›ç­”ã•ã›ã€candidateã«åŸºã¥ã„ãŸå›ç­”ã¨å›ç­”ã®çµæœã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ã§è©•ä¾¡ã‚’å®Ÿæ–½ã™ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/552b3bfd-48a6-4915-af96-e8ae91e760dc" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/LM-based.html" target="_blank" rel="noopener noreferrer">#LM-based</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/960" target="_blank" rel="noopener noreferrer" class="title-link">BARTSCORE: Evaluating Generated Text as Text Generation, Yuan+ ï¼ˆw_ Neubigæ°ï¼‰, NeurIPS'21</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®è©•ä¾¡æ–¹æ³•ã«ã¤ã„ã¦æ¤œè¨ã—ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®å•é¡Œã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å‚ç…§å‡ºåŠ›ã¾ãŸã¯ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹ãŸã‚ã«è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã—ãŸã€‚ææ¡ˆã—ãŸãƒ¡ãƒˆãƒªãƒƒã‚¯ã§ã‚ã‚‹BARTSCOREã¯ã€æƒ…å ±é‡ã€æµæš¢ã•ã€äº‹å®Ÿæ€§ãªã©ã®ç•°ãªã‚‹è¦–ç‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆè©•ä¾¡ã«æŸ”è»Ÿã«é©ç”¨ã§ãã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€æ—¢å­˜ã®ãƒˆãƒƒãƒ—ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚BARTScoreã®è¨ˆç®—ã«ä½¿ç”¨ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ãŠã‚Šã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã‚‚åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>BARTScore</p>
<p># æ¦‚è¦<br><br>ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€BARTã«ã‚ˆã£ã¦ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹å°¤åº¦ã‚’è¨ˆç®—ã—ã€ãã‚Œã‚’ã‚¹ã‚³ã‚¢ã¨ã™ã‚‹æ‰‹æ³•ã€‚ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¿ã‚¹ã‚¯ã‚’ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€pre-trainingã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚ˆã‚Šæœ‰åŠ¹ã«æ´»ç”¨ã§ãã‚‹ï¼ˆe.g. BERTScoreã‚„MoverScoreãªã©ã¯ã€pre-trainingã‚¿ã‚¹ã‚¯ãŒãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã§ã¯ãªã„ï¼‰ã€‚BARTScoreã®ç‰¹å¾´ã¯<br><br>1. parameter- and data-efficientã§ã‚ã‚‹ã€‚pre-trainingã«åˆ©ç”¨ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»¥å¤–ã®è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å¿…è¦ãªãã€unsupervisedãªmetricãªã®ã§ã€human judgmentã®ãƒ‡ãƒ¼ã‚¿ãªã©ã‚‚å¿…è¦ãªã„ã€‚<br><br>2. æ§˜ã€…ãªè¦³ç‚¹ã‹ã‚‰ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã‚’è©•ä¾¡ã§ãã‚‹ã€‚conditional text generation problemã«ã™ã‚‹ã“ã¨ã§informativeness, coherence, factualityãªã©ã®æ§˜ã€…ãªè¦³ç‚¹ã«å¯¾å¿œå¯èƒ½ã€‚<br><br>3. BARTScoreã¯ã€(i) pre-training taskã¨é¡ä¼¼ã—ãŸpromptã‚’ä¸ãˆã‚‹ã“ã¨ã€(ii) down stream generation taskã§finetuningã™ã‚‹ã“ã¨ã€ã§ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’ç²å¾—ã§ãã‚‹<br><br>BARTScoreã‚’16ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã€7ã¤ã®è¦³ç‚¹ã§è©•ä¾¡ã—ãŸã¨ã“ã‚ã€16/22ã«ãŠã„ã¦ã€top-scoring metricsã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€prompting starategyã®æœ‰åŠ¹æ€§ã‚’ç¤ºã—ãŸã€‚ãŸã¨ãˆã°ã€ã‚·ãƒ³ãƒ—ãƒ«ã«"such as"ã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ ã™ã‚‹ã ã‘ã§ã€German-English MTã«ãŠã„ã¦3%ã®æ€§èƒ½å‘ä¸ŠãŒè¦‹ã‚‰ã‚ŒãŸã€‚ã¾ãŸã€BARTScoreã¯ã€high-qualityãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã‚’æ‰±ã†éš›ã«ã€ã‚ˆã‚Šãƒ­ãƒã‚¹ãƒˆã§ã‚ã‚‹ã“ã¨ãŒåˆ†æã®çµæœåˆ†ã‹ã£ãŸã€‚<br><br><br><br># å‰æ<br><br>## Problem Formulation<br><br>ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®qualityã‚’æ¸¬ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã™ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€conditional text generation (e.g. æ©Ÿæ¢°ç¿»è¨³)ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã™ã‚‹ã€‚ã™ãªã‚ã¡ã€ã‚´ãƒ¼ãƒ«ã¯ã€hypothesis h_bar ã‚’ source text s_barãŒgivenãªçŠ¶æ…‹ã§ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚ä¸€èˆ¬çš„ã«ã¯ã€äººé–“ãŒä½œæˆã—ãŸreference r_barãŒè©•ä¾¡ã®éš›ã¯åˆ©ç”¨ã•ã‚Œã‚‹ã€‚<br><br>## Gold-standard Human Evaluation<br><br>è©•ä¾¡ã®gold standardã¯äººæ‰‹è©•ä¾¡ã§ã‚ã‚Šã€äººæ‰‹è©•ä¾¡ã§ã¯å¤šãã®è¦³ç‚¹ã‹ã‚‰è©•ä¾¡ãŒè¡Œã‚ã‚Œã‚‹ã€‚ä»¥ä¸‹ã«ä»£è¡¨çš„ãªè¦³ç‚¹ã‚’ç¤ºã™ï¼š<br><br>1. Informativeness: ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã®ã‚­ãƒ¼ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ã©ã‚Œã ã‘æ‰ãˆã¦ã„ã‚‹ã‹<br><br>2. Relevance: ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã«ã‚åœ°ã—ã¦ã€ã©ã‚Œã ã‘consistentã‹<br><br>3. Fluency formatting problem, capitarlization errorã‚„éæ–‡ãªã©ã€ã©ã®ç¨‹åº¦èª­ã‚€ã®ãŒå›°é›£ã‹<br><br>4. Coherence: æ–‡é–“ã®ã¤ãªãŒã‚ŠãŒã€ãƒˆãƒ”ãƒƒã‚¯ã«å¯¾ã—ã¦ã©ã‚Œã ã‘coherentã‹<br><br>5. Factuality: ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã«å«æ„ã•ã‚Œã‚‹statementã®ã¿ã‚’ç”Ÿæˆã§ãã¦ã„ã‚‹ã‹<br><br>6. Semantic Coverage: å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆä¸­ã®Semantic Content Unitã‚’ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆãŒã©ã‚Œã ã‘ã‚«ãƒãƒ¼ã§ãã¦ã„ã‚‹ã‹<br><br>7: Adequacy å…¥åŠ›æ–‡ã«å¯¾ã—ã¦ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆãŒåŒã˜æ„å‘³ã‚’å‡ºåŠ›ã§ãã¦ã„ã‚‹ã‹ã©ã†ã‹ã€ã‚ã‚‹ã„ã¯ä½•ã‚‰ã‹ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå¤±ã‚ã‚Œã‚‹ã€è¿½åŠ ã•ã‚Œã‚‹ã€æ­ªæ›²ã—ã¦ã„ãªã„ã‹ã©ã†ã‹<br><br><br><br>å¤šãã®æ€§èƒ½æŒ‡æ¨™ã¯ã€ã“ã‚Œã‚‰ã®è¦³ç‚¹ã®ã†ã¡ã®subsetã‚’ã‚«ãƒãƒ¼ã™ã‚‹ã‚ˆã†ã«ãƒ‡ã‚¶ã‚¤ãƒ³ã‚“ã•ã‚Œã¦ã„ã‚‹ã€‚ãŸã¨ãˆã°ã€BLEUã¯ã€ç¿»è¨³ã«ãŠã‘ã‚‹Adequacyã¨Fluencyã‚’ã¨ã‚‰ãˆã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã€ROUGEã¯ã€semantic coverageã‚’æ¸¬ã‚‹ãŸã‚ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã§ã‚ã‚‹ã€‚<br><br>BARTScoreã¯ã€ã“ã‚Œã‚‰ã®ã†ã¡å¤šãã®è¦³ç‚¹ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br><br><br>## Evaluation as Different Tasks<br><br>ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ç•°ãªã‚‹æ–¹æ³•ã§è‡ªå‹•è©•ä¾¡ã«æ´»ç”¨ã™ã‚‹ã®ãŒæœ€è¿‘ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã§ã‚ã‚‹ã€‚ä¸‹å›³ãŒãã®åˆ†é¡ã€‚ã“ã®åˆ†é¡ã¯ã€ã‚¿ã‚¹ã‚¯ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ãŸåˆ†é¡ã¨ãªã£ã¦ã„ã‚‹ã€‚<br><br>1. Unsupervised Matching: ROUGE, BLEU, CHRF, BERTScore, MoverScoreã®ã‚ˆã†ã«ã€hypothesisã¨referenceé–“ã§ã®æ„å‘³çš„ãªç­‰ä¾¡æ€§ã‚’æ¸¬ã‚‹ã“ã¨ãŒç›®çš„ã§ã‚ã‚‹ã€‚ã“ã®ãŸã‚ã«ã€token-levelã®ãƒãƒƒãƒãƒ³ã‚°ã‚’ç”¨ã„ã‚‹ã€‚ã“ã‚Œã¯ã€distributedãªè¡¨ç¾ã‚’ç”¨ã„ã‚‹ï¼ˆBERTScore, MoverScoreï¼‰å ´åˆã‚‚ã‚ã‚Œã°ã€discreteãªè¡¨ç¾ã‚’ç”¨ã„ã‚‹ï¼ˆROUGE, BLEU, chrFï¼‰å ´åˆã‚‚ã‚ã‚‹ã€‚ã¾ãŸã€æ„å‘³çš„ãªç­‰ä¾¡æ€§ã ã‘ã§ãªãã€factual consistencyã‚„ã€source-hypothesisé–“ã®é–¢ä¿‚æ€§ã®è©•ä¾¡ã«ç”¨ã„ã‚‹ã“ã¨ã‚‚ã§ãã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ãŒå…ˆè¡Œç ”ç©¶ã§ã¯ã‚„ã‚‰ã‚Œã¦ã„ãªã‹ã£ãŸã®ã§ã€æœ¬ç ”ç©¶ã§å¯èƒ½ãªã“ã¨ã‚’ç¤ºã™ã€‚<br><br>2. Supervised Regression: BLEURT, COMET, S^3, VRMã®ã‚ˆã†ã«ã€regression layer ã‚’ç”¨ã„ã¦human judgmentã‚’supervisedã«äºˆæ¸¬ã™ã‚‹æ–¹æ³•ã§ã‚ã‚‹ã€‚æœ€è¿‘ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ï½”ãŠã—ã¦ã¯ã€BLEURT, COMETãŒã‚ã’ã‚‰ã‚Œã€å¤å…¸çš„ãªã‚‚ã®ã¨ã—ã¦ã¯ã€S^3, VRMãŒã‚ã’ã‚‰ã‚Œã‚‹ã€‚<br><br>4. Supervised Ranking: COMET, BEERã®ã‚ˆã†ãªã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°å•é¡Œã¨ã—ã¦ã¨ã‚‰ãˆã‚‹æ–¹æ³•ã‚‚ã‚ã‚‹ã€‚ã“ã‚Œã¯å„ªã‚ŒãŸhypothesisã‚’ä¸Šä½ã«ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã™ã‚‹ã‚ˆã†ãªã‚¹ã‚³ã‚¢é–¢æ•°ã‚’å­¦ç¿’ã™ã‚‹å•é¡Œã«å¸°ç€ã™ã‚‹ã€‚COMETã‚„BEERãŒä¾‹ã¨ã—ã¦ã‚ã’ã‚‰ã‚Œã€ä¸¡è€…ã¯MTã‚¿ã‚¹ã‚¯ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã•ã‚Œã¦ã„ã‚‹ã€‚COMETã¯hunan judgmentsã‚’regressionã™ã‚‹ã“ã¨ã‚’é€šã˜ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½œæˆã—ã€BEERã¯ã€å¤šãã®ã‚·ãƒ³ãƒ—ãƒ«ãªç‰¹å¾´é‡ã‚’çµ„ã¿åˆã‚ã›ã¦ã€linear layerã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã‚‹ã€‚<br><br>5. Text Generation: PRISM, BARTScoreãŒä¾‹ã¨ã—ã¦æŒ™ã’ã‚‰ã‚Œã‚‹ã€‚BARTScoreã§ã¯ã€ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®è©•ä¾¡ã‚’pre-trained language modelã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¿ã‚¹ã‚¯ã¨ã—ã¦ã¨ã‚‰ãˆã‚‹ã€‚åŸºæœ¬çš„ãªã‚¢ã‚¤ãƒ‡ã‚¢ã¨ã—ã¦ã¯ã€é«˜å“è³ªã®hypothesisã¯ã€ã‚½ãƒ¼ã‚¹ã€ã‚ã‚‹ã„ã¯referenceã‹ã‚‰å®¹æ˜“ã«ç”Ÿæˆå¯èƒ½ã§ã‚ã‚ã†ã€ã¨ã„ã†ã‚‚ã®ã§ã‚ã‚‹ã€‚ã“ã‚Œã¯PRISMã‚’é™¤ã„ã¦ã€å…ˆè¡Œç ”ç©¶ã§ã¯ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ãªã„ã€‚BARTScoreã¯ã€PRISMã¨ã¯ã„ãã¤ã‹ã®ç‚¹ã§ç•°ãªã£ã¦ã„ã‚‹ã€‚(i) PRISMã¯è©•ä¾¡ã‚’paraphrasing taskã¨ã—ã¦ã¨ã‚‰ãˆã¦ãŠã‚Šã€ã“ã‚ŒãŒ2ã¤ã®æ„å‘³ãŒåŒã˜ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¯”è¼ƒã™ã‚‹å‰æã¨ãªã£ã¦ã—ã¾ã£ã¦ã„ã‚‹ãŸã‚ã€æ‰‹æ³•ã‚’é©ç”¨å¯èƒ½ãªç¯„å›²ã‚’ç‹­ã‚ã¦ã—ã¾ã£ã¦ã„ã‚‹ã€‚ãŸã¨ãˆã°ã€æ–‡æ›¸è¦ç´„ã«ãŠã‘ã‚‹factual consistencyã®è©•ä¾¡ã§ã¯ã€semantic spaceãŒç•°ãªã‚‹2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¯”è¼ƒã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŒã€ã“ã®ã‚ˆã†ãªä¾‹ã«ã¯å¯¾å¿œã§ããªã„ã€‚(ii) PRISMã¯parallel dataã‹ã‚‰å­¦ç¿’ã—ãªã‘ãˆï½’ã°ãªã‚‰ãªã„ãŒã€BARTScoreã¯ã€pre-trainedãªopen-sourceã®seq2seq modelã‚’åˆ©ç”¨ã§ãã‚‹ã€‚(iii) BARTScoreã§ã¯ã€PRISMãŒæ¤œè¨¼ã—ã¦ã„ãªã„ã€prompt-basedã®learningã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4a64ea21-ab9f-4762-bd71-f858663fc195" alt="image" loading="lazy"><br><br><br><br># BARTScore<br><br>## Sequence-to-Sequence Pre-trained Models<br><br>pre-trainingã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€æ§˜ã€…ãªè»¸ã§ç•°ãªã£ã¦ã„ã‚‹ãŒã€ãã®ä¸€ã¤ã®è»¸ã¨ã—ã¦ã¯è¨“ç·´æ™‚ã®ç›®çš„é–¢æ•°ã§ã‚ã‚‹ã€‚åŸºæœ¬çš„ã«ã¯ï¼’ã¤ã®å¤§ããªå¤‰ç¨®ãŒã‚ã‚Šã€1ã¤ã¯ã€language modeling objectives (e.g. MLM)ã€2ã¤ç›®ã¯ã€seq2seq objectivesã§ã‚ã‚‹ã€‚ç‰¹ã«ã€seq2seqã§äº‹å‰å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã¨ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã«ã‚ˆã£ã¦æ§‹æˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ç‰¹ã«æ¡ä»¶ä»˜ãç”Ÿæˆã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦é©ã—ã¦ãŠã‚Šã€äºˆæ¸¬ã¯AutoRegressiveã«è¡Œã‚ã‚Œã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯BARTã‚’ç”¨ã„ã‚‹ã€‚ä»˜éŒ²ã«ã¯ã€preliminary experimentsã¨ã—ã¦ã€BART with T5, PEGASUSã‚’ç”¨ã„ãŸçµæœã‚‚æ·»ä»˜ã™ã‚‹ã€‚<br><br>## BARTScore<br><br>æœ€ã‚‚ä¸€èˆ¬çš„ãªBARTScoreã®å®šå¼åŒ–ã¯ä¸‹è¨˜ã§ã‚ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/34505fd3-c8bb-49ee-92a8-f5710032b1ea" alt="image" loading="lazy"><br><br>weighted log probabilityã‚’åˆ©ç”¨ã™ã‚‹ã€‚ã“ã®weightsã¯ã€ç•°ãªã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾ã—ã¦ã€ç•°ãªã‚‹é‡ã¿ã‚’ä¸ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ãŸã¦ãŠã°ã€IDFãªã©ãŒåˆ©ç”¨å¯èƒ½ã§ã‚ã‚‹ãŒã€æœ¬ç ”ç©¶ã§ã¯ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç­‰ä¾¡ã«æ‰±ã†ï¼ˆuniform weightingã ãŒstopwordã‚’é™¤å¤–ã€IDFã«ã‚ˆã‚‹é‡ã¿ã¥ã‘ã€äº‹å‰åˆ†å¸ƒã‚’å°å…¥ã™ã‚‹ãªã©è‰²ã€…è©¦ã—ãŸãŒã€uniform weightingã‚’ä¸Šå›ã‚‹ã‚‚ã®ãŒãªã‹ã£ãŸï¼‰ã€‚<br><br><br><br>BARTScoreã‚’ç”¨ã„ã¦ã€æ§˜ã€…ãªæ–¹å‘ã«ç”¨ã„ã¦ç”Ÿæˆã‚’è¡Œã†ã“ã¨ãŒã§ãã€ç•°ãªã‚‹è©•ä¾¡ã®ã‚·ãƒŠãƒªã‚ªã«å¯¾å¿œã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br>- Faithfulness (s -&gt; h):<br><br>    - hypothesisãŒã©ã‚Œã ã‘source textã«åŸºã¥ã„ã¦ç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã‹ã‚’æ¸¬ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã‚·ãƒŠãƒªã‚ªã¨ã—ã¦ã¯ã€Factualityã‚„Relevanceãªã©ãŒè€ƒãˆã‚‰ã‚Œã‚‹ã€‚ã¾ãŸã€Coherenceã‚„Fluencyã®ã‚ˆã†ã«ã€target textã®ã¿ã®å“è³ªã‚’æ¸¬ã‚‹ãŸã‚ã«ã‚‚ç”¨ã„ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br>- Precision (r -&gt; h):<br><br>    - hypothesisãŒã©ã‚Œã ã‘gold-referenceã«åŸºã¥ã„ã¦ã“ã†è‰¯ãã•ã‚Œã¦ã„ã‚‹ã‹ã‚’äºœè©•ä¾¡ã§ãã€precision-focusedãªã‚·ãƒŠãƒªã‚ªã«é©ã—ã¦ã„ã‚‹<br><br>- Recall (h -&gt; r):<br><br>    - hypothesisã‹ã‚‰ã€gold referenceã‚’ã©ã‚Œã ã‘å®¹æ˜“ã«å†ç¾ã§ãã‚‹ã‹ã‚’æ¸¬ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ãã—ã¦ã€è¦ç´„ã‚¿ã‚¹ã‚¯ã®pyramid-basedãªè©•ä¾¡ï¼ˆi.e. semantic coverageç­‰ï¼‰  ã«é©ã—ã¦ã„ã‚‹ã€‚pyramid-scoreã¯Semantic Content UnitsãŒã©ã‚Œã ã‘ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹ã‹ã«ã‚ˆã£ã¦è©•ä¾¡ã•ã‚Œã‚‹ã€‚<br><br>- F Score (r &lt;-&gt; h):<br><br>    - åŒæ–¹å‘ã‚’è€ƒæ…®ã—ã€Precisioon / Recallã‹ã‚‰Få€¤ã‚’ç®—å‡ºã™ã‚‹ã€‚ã“ã®æ–¹æ³•ã¯ã€referenceã¨ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆé–“ã§ã®semantic overlap (informativenss, adequacy)ãªã©ã®è©•ä¾¡ã«åºƒãåˆ©ç”¨ã•ã‚Œã‚‹ã€‚<br><br><br><br># BARTScore Variants<br><br>BARTScoreã®2ã¤ã®æ‹¡å¼µã‚’ææ¡ˆã€‚(i) xã¨yã‚’promptingã«ã‚ˆã£ã¦å¤‰æ›´ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è©•ä¾¡ã‚¿ã‚¹ã‚¯ã‚’pre-training taskã¨è¿‘ã¥ã‘ã‚‹ã€‚(ii) ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Î˜ã‚’ç•°ãªã‚‹finetuning taskã‚’è€ƒæ…®ã—ã¦å¤‰æ›´ã™ã‚‹ã€‚ã™ãªã‚ã¡ã€pre-trainingã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ã€evaluation taskã«è¿‘ã¥ã‘ã‚‹ã€‚<br><br>## Prompt<br><br>Promptingã¯input/outputã«å¯¾ã—ã¦çŸ­ã„ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’è¿½åŠ ã—ã€pre-trained modelã«å¯¾ã—ã¦ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‚’é‚è¡Œã•ã›ã‚‹æ–¹æ³•ã§ã‚ã‚‹ã€‚BARTã«ã‚‚åŒæ§˜ã®æ´å¯Ÿã‚’ç°¡å˜ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã‚‹ã€‚ã“ã®å¤‰ç¨®ã‚’BARTScore-PROMPTã¨å‘¼ã¶ã€‚<br><br>prompt zãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ãã‚Œã‚’ (i) source textã«è¿½åŠ ã—ã€æ–°ãŸãªsource textã‚’ç”¨ã„ã¦BARTScoreã‚’è¨ˆç®—ã™ã‚‹ã€‚(ii) target textã®å…ˆé ­ã«è¿½åŠ ã—ã€new target textã«å¯¾ã—ã¦BARTScoreã‚’è¨ˆç®—ã™ã‚‹ã€‚<br><br>## Fine-tuning Task<br><br>classification-basedãªã‚¿ã‚¹ã‚¯ã§fine-tuneã•ã‚Œã‚‹ã®ãŒä¸€èˆ¬çš„ãªBERT-based metricã¨ã¯ç•°ãªã‚Šã€BARTScoreã¯generation taskã§fine-tuneã•ã‚Œã‚‹ãŸã‚ã€pre-training domainãŒevaluation taskã¨è¿‘ã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€2ã¤ã®downstream taskã‚’æ¤œè¨¼ã™ã‚‹ã€‚<br><br>1ã¤ã‚ã¯ã€summarizationã§ã€BARTã‚’CNNDM datasetã§finetuningã™ã‚‹ã€‚2ã¤ã‚ã¯ã€paraphrasingã§ã€summarizationã‚¿ã‚¹ã‚¯ã§finetuningã—ãŸBARTã‚’ParaBank2 datasetã§ã•ã‚‰ã«finetuningã™ã‚‹ã€‚</p>
<p># å®Ÿé¨“<br><br>## baselines and datasets<br><br>### Evaluation Metrics<br><br>supervised metrics: COMET, BLEURT<br><br>unsupervised: BLEU, ROUGE-1, ROUGE-2, ROUGE-L, chrF, PRISM, MoverScore, BERTScore<br><br>ã¨æ¯”è¼ƒ<br><br>### Measures for Meta Evaluation<br><br>Pearson Correlationã§linear correlationã‚’æ¸¬ã‚‹ã€‚ã¾ãŸã€Spearman Correlationã§2å¤‰æ•°é–“ã®å˜èª¿ãªcorrelationã‚’æ¸¬å®šã™ã‚‹ï¼ˆç·šå½¢ã§ã‚ã‚‹å¿…è¦ã¯ãªã„ï¼‰ã€‚Kendall's Tauã‚’ç”¨ã„ã¦ã€2ã¤ã®é †åºé–¢ä¿‚ã®é–¢ä¿‚æ€§ã‚’æ¸¬ã‚‹ã€‚æœ€å¾Œã«ã€Accuracyã§factual textsã¨non-factual textã®é–“ã§ã©ã‚Œã ã‘æ­£ã—ã„ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å¾—ã‚‰ã‚Œã‚‹ã‹ã‚’æ¸¬ã‚‹ã€‚<br><br><br><br>### Datasets<br><br>Summarization, MT, DataToTextã®3ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ©ç”¨ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/117bf2d4-b096-4a60-a139-4a607ce3ebc6" alt="image" loading="lazy"><br><br><br><br>## Setup<br><br>### Prompt Design<br><br>seedã‚’paraphrasingã™ã‚‹ã“ã¨ã§ã€ã€€s-&gt;hæ–¹å‘ã«ã¯70å€‹ã®promptã‚’ã€h&lt;-&gt;rã®ä¸¡æ–¹å‘ã«ã¯ã€34ã®promptã‚’å¾—ã¦å®Ÿé¨“ã§ç”¨ã„ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/dab4f2bc-9b8d-4de6-bbc3-204da39ee2eb" alt="image" loading="lazy"><br><br><br><br>### Settings<br><br>Summarizationã¨data-to-textã‚¿ã‚¹ã‚¯ã§ã¯ã€å…¨ã¦ã®promptã‚’ç”¨ã„ã¦ãƒ‡ã‚³ãƒ¼ãƒ€ã®é ­ã«è¿½åŠ ã—ã¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ãŸã€‚æœ€çµ‚çš„ã«ã™ã¹ã¦ã®ç”Ÿæˆã•ã‚ŒãŸã‚¹ã‚³ã‚¢ã‚’å¹³å‡ã™ã‚‹ã“ã¨ã§ã‚ã‚‹äº‹ä¾‹ã«å¯¾ã™ã‚‹ã‚¹ã‚³ã‚¢ã‚’æ±‚ã‚ãŸï¼ˆprompt unsemblingï¼‰ã€‚MTã«ã¤ã„ã¦ã¯ã€äº‹ä¾‹æ•°ãŒå¤šãcomputational costãŒå¤šããªã£ã¦ã—ã¾ã†ãŸã‚ã€WMT18ã‚’é–‹ç™ºãƒ‡ãƒ¼ã‚¿ã¨ã—ã€best prompt "Such as"ã‚’é¸æŠã—ã€åˆ©ç”¨ã—ãŸã€‚<br><br>BARTScoreã‚’ä½¿ã†éš›ã¯ã€gold standard human evaluationãŒrecall-basedãªpyrmid methodã®å ´åˆã¯BARTScore(h-&gt;r)ã‚’ç”¨ã„ã€humaan judgmentsãŒlinguistic quality (coherence fluency)ãã—ã¦ã€factual correctnessã€ã‚ã‚‹ã„ã¯ã€sourceã¨targetãŒåŒã˜ãƒ¢ãƒ€ãƒªãƒ†ã‚£ï¼ˆe.g. languageï¼‰ã®å ´åˆã¯ã€faitufulness-based BARTScore(s-&gt;h)ã‚’ç”¨ã„ãŸã€‚æœ€å¾Œã«ã€MTã‚¿ã‚¹ã‚¯ã¨data-to-textã‚¿ã‚¹ã‚¯ã§ã¯ã€fair-comparisonã®ãŸã‚ã«BARTScore F-score versionã‚’ç”¨ã„ãŸã€‚<br><br>## å®Ÿé¨“çµæœ<br><br>### MT<br><br>- BARTScoreã¯finetuning tasksã«ã‚ˆã£ã¦æ€§èƒ½ãŒå‘ä¸Šã—ã€5ã¤ã®language pairsã«ãŠã„ã¦ãã®ä»–ã®unsupervised methodsã‚’çµ±è¨ˆçš„ã«å„ªä½ã«outperformã—ã€2ã¤ã®language pairã§comparableã§ã‚ã£ãŸã€‚<br><br>-Such asã¨ã„ã†promptã‚’è¿½åŠ ã™ã‚‹ã ã‘ã§ã€BARTScoreã®æ€§èƒ½ãŒæ”¹å–„ã—ãŸã€‚ç‰¹ç­†ã™ã¹ãã¯ã€de-enã«ãŠã„ã¦ã¯ã€SoTAã®supervised Metricsã§ã‚ã‚‹BLEURTã¨COMETã‚’ä¸Šå›ã£ãŸã€‚<br><br>- ã“ã‚Œã¯ã€æœ‰æœ›ãªå°†æ¥ã®metric designã¨ã—ã¦ã€Œhuman judgment dataã§è¨“ç·´ã™ã‚‹ä»£ã‚ã‚Šã«ã€pre-trained language modelã«è“„ç©ã•ã‚ŒãŸçŸ¥è­˜ã‚’ã‚ˆã‚Šé©åˆ‡ã«æ´»ç”¨ã§ãã‚‹promptã‚’æ¢ç´¢ã™ã‚‹ã€ã¨ã„ã†æ–¹å‘æ€§ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ff41b3ec-3cf9-4c9a-90bb-83b46889d759" alt="image" loading="lazy"><br><br><br><br>### Text Summarization<br><br>- vanilla BARTScoreã¯BERTScore, MoverScoreã‚’Info perspectiveä»¥å¤–ã§large marginã§ã†ããå›ã£ãŸã€‚<br><br>- REALSum, SummEval dataseetã§ã®æ”¹å–„ã¯ã€finetuning taskã«ã‚ˆã£ã¦ã•ã‚‰ã«æ”¹å–„ã—ãŸã€‚ã—ã‹ã—ãªãŒã‚‰ã€NeR18ã§ã¯æ”¹å–„ã—ãªã‹ã£ãŸã€‚ã“ã‚Œã¯ã€ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹7ã¤ã®ã‚·ã‚¹ãƒ†ãƒ ãŒå®¹æ˜“ã«åŒºåˆ¥ã§ãã‚‹ç¨‹åº¦ã®qualityã§ã‚ã‚Šã€æ—¢ã«vanilla BARTScoreã§é«˜ã„ãƒ¬ãƒ™ãƒ«ã®correlationã‚’é”æˆã—ã¦ã„ã‚‹ã‹ã‚‰ã ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><br>- prompt combination strategyã¯informativenssã«å¯¾ã™ã‚‹æ€§èƒ½ã‚’ä¸€è²«ã—ã¦æ”¹å–„ã—ã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€fluency, factualityã§ã¯ã€ä¸€è²«ã—ãŸæ”¹å–„ã¯è¦‹ã‚‰ã‚Œãªã‹ã£ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cfb33334-e38d-43e0-9b48-a8a8c433bc26" alt="image" loading="lazy"><br><br><br><br>Factuality datasetsã«å¯¾ã™ã‚‹åˆ†æã‚’è¡Œã£ãŸã€‚ã‚´ãƒ¼ãƒ«ã¯ã€short generated summaryãŒã€å…ƒã®long documentsã«å¯¾ã—ã¦faithfulã‹å¦ã‹ã‚’åˆ¤å®šã™ã‚‹ã¨ã„ã†ã‚‚ã®ã§ã‚ã‚‹ã€‚<br><br>- BARTScore+CNNã¯ã€Rank19ãƒ‡ãƒ¼ã‚¿ã«ãŠã„ã¦human baselineã«è¿‘ã„æ€§èƒ½ã‚’é”æˆã—ã€ã»ã‹ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã£ãŸã€‚top-performingãªfactuality metricsã§ã‚ã‚‹FactCCã‚„QAGSã«å¯¾ã—ã¦ã‚‚large marginã§ä¸Šå›ã£ãŸã€‚<br><br>- paraphraseã‚’fine-tuning taskã§åˆ©ç”¨ã™ã‚‹ã¨ã€BARTScoreã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ä½ä¸‹ã—ãŸã€‚ã“ã‚Œã¯å¦¥å½“ã§ã€ãªãœãªã‚‰äºŒã¤ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆsummary and documentï¼‰ã¯ã€paraphrasedã®é–¢ä¿‚æ€§ã‚’ä¿æŒã—ã¦ã„ãªã„ã‹ã‚‰ã§ã‚ã‚‹ã€‚<br><br>- promptã‚’å°å…¥ã—ã¦ã‚‚ã€æ€§èƒ½ã®æ”¹å–„ã¯è¦‹å—ã‘ã‚‰ã‚Œãšã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ä½ä¸‹ã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/06dac947-c946-4633-8ff6-a9c3933f6322" alt="image" loading="lazy"><br><br><br><br>### Data-to-Text<br><br>- CNNDMã§fine-tuningã™ã‚‹ã“ã¨ã§ã€ä¸€è²«ã—ã¦correlationãŒæ”¹å–„ã—ãŸã€‚<br><br>- åŠ ãˆã¦ã€paraphraseãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§finetuningã™ã‚‹ã“ã¨ã§ã€ã•ã‚‰ã«æ€§èƒ½ãŒæ”¹å–„ã—ãŸã€‚<br><br>- prompt combination strategyã¯ä¸€è²«ã—ã¦correlationã‚’æ”¹å–„ã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/acbd6816-e7bc-4ecd-8a53-13137a2bcc94" alt="image" loading="lazy"><br><br></p>
<p>## Analysis<br><br>### Fine-grained Analysis<br><br>- Top-k Systems: MTã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€è©•ä¾¡ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’top-kã«ã—ã€å„ãƒ¡ãƒˆãƒªãƒƒã‚¯ã”ã¨ã«correlationã®å¤‰åŒ–ã‚’è¦‹ãŸã€‚ãã®çµæœã€BARTScoreã¯ã™ã¹ã¦ã®unsupervised methodã‚’ã™ã¹ã¦ã®kã«ãŠã„ã¦ä¸Šå›ã‚Šã€supervised metricã®BLEURTã‚‚ä¸Šå›ã£ãŸã€‚ã¾ãŸã€kãŒå°ã•ããªã‚‹ã»ã©ã€ã‚ˆã‚Šæ€§èƒ½ã¯smoothã«ãªã£ã¦ã„ãã€æ€§èƒ½ã®ä½ä¸‹ãŒãªããªã£ã¦ã„ã£ãŸã€‚ã“ã‚Œã¯ã¤ã¾ã‚Šã€high-quality textã‚’ç”Ÿæˆã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br>- Reference Length: ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚’4ã¤ã®ãƒã‚±ãƒƒãƒˆã«reference lengthã«å¿œã˜ã¦ãƒ–ãƒ¬ã‚¤ã‚¯ãƒ€ã‚¦ãƒ³ã—ã€Kendall's Tauã®å¹³å‡ã®correlationã‚’ã€ç•°ãªã‚‹ãƒ¡ãƒˆãƒªãƒƒã‚¯ã€ãƒã‚±ãƒƒãƒˆã”ã¨ã«è¨€èªã‚’ã¾ãŸã„ã§è¨ˆç®—ã—ãŸã€‚unsupervised metricsã«å¯¾ã—ã¦ã€å…¨ã¦ã®lengthã«å¯¾ã—ã¦ã€å¼•ãåˆ†ã‘ã‹ã‚ã‚‹ã„ã¯ä¸Šå›ã£ãŸã€‚ã¾ãŸã€ã»ã‹ã®metricsã¨æ¯”è¼ƒã—ã¦ã€é•·ã•ã«å¯¾ã—ã¦å®‰å®šæ„ŸãŒã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/821fdf0a-aabc-448a-81aa-238aae380ea1" alt="image" loading="lazy"><br><br><br><br>### Prompt Analysis<br><br>(1) semantic overlap (informativeness, pyramid score, relevance), (2) linguistic quality (fluency, coherence), (3) factual correctness (factuality) ã«è©•ä¾¡ã®è¦³ç‚¹ã‚’åˆ†é¡ã—ã€summarizationã¨data-to-textã‚’ã«ãŠã‘ã‚‹ã™ã¹ã¦ã®promptã‚’åˆ†æã™ã‚‹ã“ã¨ã§ã€promptã®åŠ¹æœã‚’åˆ†æã—ãŸã€‚ãã‚Œãã‚Œã®ã‚°ãƒ«ãƒ¼ãƒ—ã«å¯¾ã—ã¦ã€æ€§èƒ½ãŒæ”¹å–„ã—ãŸpromptã®å‰²åˆã‚’è¨ˆç®—ã—ãŸã€‚ãã®çµæœã€semantic overlapã¯ã»ã¼å…¨ã¦ã®promptã«ã¦æ€§èƒ½ãŒæ”¹å–„ã—ã€factualityã¯ã„ãã¤ã‹ã®promptã§ã—ã‹æ€§èƒ½ã®æ”¹å–„ãŒè¦‹ã‚‰ã‚Œãªã‹ã£ãŸã€‚linguistic qualityã«é–¢ã—ã¦ã¯ã€promptã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã«ã‚ˆã‚‹åŠ¹æœã¯ã©ã¡ã‚‰ã¨ã‚‚è¨€ãˆãªã‹ã£ãŸã€‚<br><br><br><br>### Bias Analysis<br><br>BARTScoreãŒäºˆæ¸¬ä¸å¯èƒ½ãªæ–¹æ³•ã§ãƒã‚¤ã‚¢ã‚¹ã‚’å°å…¥ã—ã¦ã—ã¾ã†ã‹ã©ã†ã‹ã‚’åˆ†æã—ãŸã€‚ãƒã‚¤ã‚¢ã‚¹ã¨ã¯ã€human annotatorãŒä¸ãˆãŸã‚¹ã‚³ã‚¢ã‚ˆã‚Šã‚‚ã€å€¤ãŒé«˜ã™ãã‚‹ã€ã‚ã‚‹ã„ã¯ä½ã™ãã‚‹ã‚ˆã†ãªçŠ¶æ³ã§ã‚ã‚‹ã€‚ã“ã®ã‚ˆã†ãªãƒã‚¤ã‚¢ã‚¹ãŒå­˜åœ¨ã™ã‚‹ã‹ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã«ã€human annotatorã¨BARTScoreã«ã‚ˆã‚‹ãƒ©ãƒ³ã‚¯ã®ã‚µã‚’åˆ†æã—ãŸã€‚ã“ã‚Œã‚’è¦‹ã‚‹ã¨ã€BARTScoreã¯ã€extractive summarizationã®å“è³ªã‚’åŒºåˆ¥ã™ã‚‹èƒ½åŠ›ãŒabstractive summarizationã®å“è³ªã‚’åŒºåˆ¥ã™ã‚‹èƒ½åŠ›ã‚ˆã‚Šã‚‚åŠ£ã£ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚ã—ã‹ã—ãªãŒã‚‰ã€è¿‘å¹´ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã¯abstractiveãªseq2seqã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ãªã®ã§ã€ã“ã®å¼±ç‚¹ã¯è»½æ¸›ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br><br><br># Implications and Future Directions<br><br>prompt-augmented metrics: semantic overlapã§ã¯promptingãŒæœ‰åŠ¹ã«åƒã„ãŸãŒã€linguistic qualityã¨factualityã§ã¯æœ‰åŠ¹ã§ã¯ãªã‹ã£ãŸã€‚ã‚ˆã‚Šè‰¯ã„promptã‚’æ¨¡ç´¢ã™ã‚‹ç ”ç©¶ãŒä»Šå¾ŒæœŸå¾…ã•ã‚Œã‚‹ã€‚<br><br>Co-evolving evaluation metrics and systems: BARTScoreã¯ã€ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ‡ã‚¶ã‚¤ãƒ³ã¨ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ã‚¶ã‚¤ãƒ³ã®é–“ã«ã¤ãªãŒã‚ŠãŒã‚ã‚‹ã®ã§ã€ã‚ˆã‚Šæ€§èƒ½ã®è‰¯ã„seq2seqã‚·ã‚¹ãƒ†ãƒ ãŒå‡ºãŸã‚‰ã€ãã‚Œã‚’ãƒ¡ãƒˆãƒªãƒƒã‚¯ã«ã‚‚æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã‚ˆã‚Šreliableãªè‡ªå‹•æ€§èƒ½æŒ‡æ¨™ã¨ãªã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/08d51f6d-40ad-4b2a-8871-086e12010478" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/953" target="_blank" rel="noopener noreferrer" class="title-link">Towards Question-Answering as an Automatic Metric for Evaluating the Content Quality of a Summary, Deutsch+, TACL'21</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ã®å“è³ªã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„æŒ‡æ¨™ã§ã‚ã‚‹QAEvalã‚’ææ¡ˆã™ã‚‹ã€‚QAEvalã¯è³ªå•å¿œç­”ï¼ˆQAï¼‰ã‚’ä½¿ç”¨ã—ã¦è¦ç´„ã¨å‚ç…§ã®æƒ…å ±ã®é‡è¤‡ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã€å¾“æ¥ã®ãƒ†ã‚­ã‚¹ãƒˆã®é‡è¤‡ã«åŸºã¥ãæŒ‡æ¨™ã¨ã¯ç•°ãªã‚‹ã€‚å®Ÿé¨“çµæœã‹ã‚‰ã€QAEvalã¯ç¾åœ¨ã®æœ€å…ˆç«¯ã®æŒ‡æ¨™ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ä»–ã®è©•ä¾¡ã¨ã‚‚ç«¶äº‰åŠ›ãŒã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚QAEvalã®æ§‹æˆè¦ç´ ã‚’åˆ†æã™ã‚‹ã“ã¨ã§ã€ãã®æ½œåœ¨çš„ãªä¸Šé™ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ä»–ã®è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ã‚’ä¸Šå›ã‚Šã€ã‚´ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã®ãƒ”ãƒ©ãƒŸãƒƒãƒ‰ãƒ¡ã‚½ãƒƒãƒ‰ã«è¿‘ã¥ãã¨æ¨å®šã•ã‚Œã‚‹ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/949" target="_blank" rel="noopener noreferrer" class="title-link">ESTIME: Estimation of Summary-to-Text Inconsistency by Mismatched Embeddings, Eval4NLP'21</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€æ–°ã—ã„å‚ç…§ãªã—è¦ç´„å“è³ªè©•ä¾¡å°ºåº¦ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®å°ºåº¦ã¯ã€è¦ç´„ã¨ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®é–“ã®æ½œåœ¨çš„ãªçŸ›ç›¾ã‚’è¦‹ã¤ã‘ã¦æ•°ãˆã‚‹ã“ã¨ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚ææ¡ˆã•ã‚ŒãŸå°ºåº¦ã¯ã€ä¸€è²«æ€§ã¨æµæš¢ã•ã®ä¸¡æ–¹ã§ä»–ã®è©•ä¾¡å°ºåº¦ã‚ˆã‚Šã‚‚å°‚é–€å®¶ã®ã‚¹ã‚³ã‚¢ã¨å¼·ã„ç›¸é–¢ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€å¾®å¦™ãªäº‹å®Ÿã®èª¤ã‚Šã‚’ç”Ÿæˆã™ã‚‹æ–¹æ³•ã‚‚ç´¹ä»‹ã—ã¾ã—ãŸã€‚ã“ã®å°ºåº¦ã¯å¾®å¦™ãªã‚¨ãƒ©ãƒ¼ã«å¯¾ã—ã¦ã‚ˆã‚Šæ„Ÿåº¦ãŒé«˜ã„ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<a class="button" href="articles/Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-07-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/907" target="_blank" rel="noopener noreferrer" class="title-link">SimCSE: Simple Contrastive Learning of Sentence Embeddings, Tianyu Gao+, N_A, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€SimCSEã¨ã„ã†å¯¾æ¯”å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€æ–‡ã®åŸ‹ã‚è¾¼ã¿æŠ€è¡“ã‚’é€²åŒ–ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ•™å¸«ãªã—ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€å…¥åŠ›æ–‡ã‚’ãƒã‚¤ã‚ºã¨ã—ã¦æ‰±ã„ã€è‡ªå·±ã‚’å¯¾æ¯”çš„ã«äºˆæ¸¬ã—ã¾ã™ã€‚æ•™å¸«ã‚ã‚Šã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€è‡ªç„¶è¨€èªæ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰æ³¨é‡ˆä»˜ãã®ãƒšã‚¢ã‚’ä½¿ç”¨ã—ã¦å¯¾æ¯”å­¦ç¿’ã‚’è¡Œã„ã¾ã™ã€‚SimCSEã¯ã€æ„å‘³çš„ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼æ€§ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã•ã‚Œã€ä»¥å‰ã®æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦æ”¹å–„ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚å¯¾æ¯”å­¦ç¿’ã¯ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿ã®ç©ºé–“ã‚’å‡ä¸€ã«æ­£å‰‡åŒ–ã—ã€æ•™å¸«ä¿¡å·ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã«ã¯æ­£ã®ãƒšã‚¢ã‚’ã‚ˆã‚Šã‚ˆãæ•´åˆ—ã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/462" target="_blank" rel="noopener noreferrer">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks, Reimers+, UKP-TUDA, EMNLP'19</a>
 ã‚ˆã‚Šã‚‚æ€§èƒ½è‰¯ãã€unsupervisedã§ã‚‚å­¦ç¿’ã§ãã‚‹ã€‚STSã‚¿ã‚¹ã‚¯ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«ã ã„ãŸã„å…¥ã£ã¦ã‚‹</p>
<p># æ‰‹æ³•æ¦‚è¦<br><br>Contrastive Learningã‚’æ´»ç”¨ã—ã¦ã€unsupervised/supervisedã«å­¦ç¿’ã‚’å®Ÿæ–½ã™ã‚‹ã€‚<br><br>Unsupervised SimCSEã§ã¯ã€ã‚ã‚‹sentenceã‚’encoderã«2å›å…¥åŠ›ã—ã€ãã‚Œãã‚Œã«dropoutã‚’é©ç”¨ã•ã›ã‚‹ã“ã¨ã§ã€positive pairã‚’ä½œæˆã™ã‚‹ã€‚dropoutã«ã‚ˆã£ã¦å…±é€šã®embeddingã‹ã‚‰ç•°ãªã‚‹è¦ç´ ãŒãƒã‚¹ã‚¯ã•ã‚ŒãŸï¼ˆnoiseãŒæ··ã–ã£ãŸçŠ¶æ…‹ã¨ã¿ãªã›ã‚‹ï¼‰é¡ä¼¼ã—ãŸembeddingãŒä½œæˆã•ã‚Œã€ã‚ã‚‹ç¨®ã®data augmentationã«ã‚ˆã£ã¦æ­£ä¾‹ã‚’ä½œæˆã—ã¦ã„ã‚‹ã¨ã‚‚ã„ãˆã‚‹ã€‚è² ä¾‹ã¯negative samplingã™ã‚‹ã€‚ï¼ˆéå¸¸ã«simpleã ãŒã€next sentence predictionã§å­¦ç¿’ã™ã‚‹ã‚ˆã‚Šæ€§èƒ½ãŒè‰¯ããªã‚‹ï¼‰<br><br>Supervised SimCSEã§ã¯ã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸsentence pairã«åŸºã¥ã„ã¦ã€æ­£ä¾‹ãƒ»è² ä¾‹ã‚’æ±ºå®šã™ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€NLIã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãŠã„ã¦ã€entailmenté–¢ä¿‚ã«ã‚ã‚‹ã‚‚ã®ã¯æ­£ä¾‹ã¨ã—ã¦æ‰±ã†ã€‚contradictionsï¼ˆçŸ›ç›¾ï¼‰é–¢ä¿‚ã«ã‚ã‚‹ã‚‚ã®ã¯è² ä¾‹ã¨ã—ã¦æ‰±ã†ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ba20a1ca-0078-4227-8bb3-3805ee57a620" alt="image" loading="lazy"><br><br><br><br># Siamese Networkã§ç”¨ã„ã‚‰ã‚Œã‚‹means-squared errrorã¨ContrastiveObjectiveã®é•ã„<br><br>ã©ã¡ã‚‰ã‚‚ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã§æ¯”è¼ƒã™ã‚‹ã¨ã„ã†ç‚¹ã§ã¯ä¸€ç·’ã ãŒã€ContrastiveObjectiveã¯æ­£ä¾‹ã¨è¿‘ã¥ã„ãŸã¨ãã€è² ä¾‹ã¨é ã–ã‹ã£ãŸã¨ãã«lossãŒå°ã•ããªã‚‹ã‚ˆã†ãªå®šå¼åŒ–ãŒã•ã‚Œã¦ã„ã‚‹ç‚¹ãŒç•°ãªã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d9cad930-e86d-4758-87b5-4237525a154a" alt="image" loading="lazy"><br><br>ï¼ˆç”»åƒã¯ã“ã®ãƒ–ãƒ­ã‚°ã‹ã‚‰å¼•ç”¨ã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚


<a href="https://techblog.cccmk.co.jp/entry/2022/08/30/163625%EF%BC%89" target="_blank" rel="noopener noreferrer">https://techblog.cccmk.co.jp/entry/2022/08/30/163625ï¼‰</a>


<br><br><br><br># Unsupervised SimCSEã®å®Ÿé¨“<br><br>ç•°ãªã‚‹data augmentationæ‰‹æ³•ã¨æ¯”è¼ƒã—ãŸçµæœã€dropoutã‚’é©ç”¨ã™ã‚‹æ‰‹æ³•ã®æ–¹ãŒæ€§èƒ½ãŒé«˜ã‹ã£ãŸã€‚MLMã‚„, deletion, é¡ç¾©èªã¸ã®ç½®ãæ›ãˆç­‰ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã—ã¦ã„ã‚‹ã®ã¯èˆˆå‘³æ·±ã„ã€‚ã¾ãŸã€Next Sentence Predictionã¨æ¯”è¼ƒã—ã¦ã‚‚ã€é«˜ã„æ€§èƒ½ã‚’é”æˆã€‚Next Sentence Predictionã¯ã€word deletionç­‰ã®ã»ã¼é¡ä¼¼ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç›´æ¥çš„ã«é¡ä¼¼é–¢ä¿‚ã«ã‚ã‚‹ãƒšã‚¢ã‹ã‚‰å­¦ç¿’ã™ã‚‹ã¨ã„ã†ã‚ˆã‚Šã€Sentenceã®æ„å‘³å†…å®¹ã®ã¤ãªãŒã‚Šã«åŸºã¥ã„ã¦ãƒ¢ãƒ‡ãƒ«ã®è¨€èªç†è§£èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã€ãã®ã†ãˆã§é¡ä¼¼åº¦ã‚’æ¸¬ã‚‹ã¨ã„ã†é–“æ¥çš„ãªæ‰‹æ³•ã ãŒã€word deletionã«è² ã‘ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã€dropoutã‚’é©ç”¨ã™ã‚‹ã ã‘ã®ï¼ˆç›´æ¥çš„ã«é¡ä¼¼ãƒšã‚¢ã‹ã‚‰å­¦ç¿’ã™ã‚‹ï¼‰æœ¬æ‰‹æ³•ã¯ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br>[image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0ea3549e-3363-4857-94e6-a1ef474aa191)<br><br><br><br>ãªãœã†ã¾ãã„ãã‹ã‚’åˆ†æã™ã‚‹ãŸã‚ã«ã€ç•°ãªã‚‹è¨­å®šã§å®Ÿé¨“ã—ã€alignmentï¼ˆæ­£ä¾‹ã¨ã®è¿‘ã•ï¼‰ã¨uniformityï¼ˆã©ã‚Œã ã‘embeddingãŒä¸€æ§˜ã«åˆ†å¸ƒã—ã¦ã„ã‚‹ã‹ï¼‰ã‚’ã€10 stepã”ã¨ã«plotã—ãŸçµæœãŒä»¥ä¸‹ã€‚dropoutã‚’é©ç”¨ã—ãªã„å ´åˆã¨ã€å¸¸ã«åŒã˜éƒ¨åˆ†ã‚’ãƒã‚¹ã‚¯ã™ã‚‹æ–¹æ³•ï¼ˆã¤ã¾ã‚Šã€å…¨ãåŒã˜embeddingã‹ã‚‰å­¦ç¿’ã™ã‚‹ï¼‰è¨­å®šã‚’è¦‹ã‚‹ã¨ã€å­¦ç¿’ãŒé€²ã‚€ã«ã¤ã‚Œuniformityã¯æ”¹å–„ã™ã‚‹ãŒã€alignmentãŒæ‚ªããªã£ã¦ã„ã£ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã€SimCSEã¯alignmentã‚’ç¶­æŒã—ã¤ã¤ã€uniformityã‚‚ã‚ˆããªã£ã¦ã„ã£ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5f488cb2-b15a-4e00-9452-8e48780abe8a" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5e815cf7-b412-4f1b-8adb-116f0dcd2fee" alt="image" loading="lazy"><br><br><br><br># Supervised SimCSEã®å®Ÿé¨“<br><br>ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ContrastiveLearningã™ã‚‹ã«ã‚ãŸã‚Šã€ã©ã†ã„ã£ãŸãƒ‡ãƒ¼ã‚¿ã‚’æ­£ä¾‹ã¨ã—ã¦ã¿ãªã™ã¨è‰¯ã„ã‹ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã«æ§˜ã€…ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å­¦ç¿’ã—æ€§èƒ½ã‚’æ¤œè¨¼ã—ãŸã€‚<br><br><br><br>- QQP4: Quora question pairs<br><br>- Flickr30k (Young et al., 2014): åŒã˜ç”»åƒã«å¯¾ã—ã¦ã€5ã¤ã®ç•°ãªã‚‹äººé–“ãŒè¨˜è¿°ã—ãŸã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨<br><br>- ParaNMT (Wieting and Gimpel, 2018): back-translationã«ã‚ˆã‚‹paraphraseã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆa<br><br>- NLI datasets: SNLIã¨MNLI<br><br><br><br>å®Ÿé¨“ã®çµæœã€NLI datasetsãŒæœ€ã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã“ã®ç†ç”±ã¨ã—ã¦ã¯ã€NLIãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€crowd sourcingã‚¿ã‚¹ã‚¯ã§äººæ‰‹ã§ä½œæˆã•ã‚ŒãŸé«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹ã“ã¨ã¨ã€lexical overlapãŒå°ã•ããªã‚‹ã‚ˆã†ã«sentenceã®ãƒšã‚¢ãŒä½œæˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒèµ·å› ã—ã¦ã„ã‚‹ã€‚å®Ÿéš›ã€NLI datsetã®lexical overlapã¯39%ã ã£ãŸã®ã«å¯¾ã—ã€ã»ã‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯60%ã§ã‚ã£ãŸã€‚<br><br><br><br>ã¾ãŸã€condunctionsã¨ãªã‚‹ãƒšã‚¢ã‚’æ˜ç¤ºçš„ã«è² ä¾‹ã¨ã—ã¦ä¸ãˆã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šæ€§èƒ½ãŒå‘ä¸Šã—ãŸï¼ˆæ™®é€šã¯negative samplingã™ã‚‹ã€ã¨ã„ã†ã‹ãƒãƒƒãƒå†…ã®æ­£ä¾‹ä»¥å¤–ã®ã‚‚ã®ã‚’å¼·åˆ¶çš„ã«è² ä¾‹ã¨ã™ã‚‹ã€‚ã“ã†ã™ã‚‹ã¨ã€æ„å‘³ãŒåŒã˜ã§ã‚‚è² ä¾‹ã«ãªã£ã¦ã—ã¾ã†äº‹ä¾‹ãŒå‡ºã¦ãã‚‹ã“ã¨ã«ãªã‚‹ï¼‰ã€‚ã‚ˆã‚Šé›£ã—ã„NLIã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ANLIãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¿½åŠ ã—ãŸå ´åˆã¯ã€æ€§èƒ½ãŒæ”¹å–„ã—ãªã‹ã£ãŸã€‚ã“ã®ç†ç”±ã«ã¤ã„ã¦ã¯è€ƒå¯Ÿã•ã‚Œã¦ã„ãªã„ã€‚æ€§èƒ½å‘ä¸Šã—ãã†ãªæ°—ãŒã™ã‚‹ã®ã«ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ae05711b-5ad4-4a53-837b-c57e9a39da62" alt="image" loading="lazy"><br><br></p>
<p># ä»–æ‰‹æ³•ã¨ã®æ¯”è¼ƒçµæœ<br><br>SimCSEãŒã‚ˆã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/510744ff-01bb-47be-9e30-2efa49e0f923" alt="image" loading="lazy"><br><br><br><br># Ablation Studies<br><br>ç•°ãªã‚‹poolingæ–¹æ³•ã§ã€ã©ã®ã‚ˆã†ã«sentence embeddingã‚’ä½œæˆã™ã‚‹ã‹ã§æ€§èƒ½ã®é•ã„ã‚’è¦‹ãŸã€‚originalã®BERTã®å®Ÿè£…ã§ã¯ã€CLS token ã®embeddingã®ä¸Šã«MLP layerãŒã®ã£ã‹ã£ã¦ã„ã‚‹ã€‚ã“ã‚Œã®æœ‰ç„¡ãªã©ã¨æ¯”è¼ƒã€‚<br><br>Unsupervised SimCSEã§ã¯ã€trainingæ™‚ã ã‘MLP layerã‚’ã®ã£ã‘ã¦ã€testæ™‚ã¯MLPã‚’é™¤ã„ãŸæ–¹ãŒè‰¯ã‹ã£ãŸã€‚ä¸€æ–¹ã€Supervised SimCSEã§ã¯ã€ MLP layerã‚’ã®ã£ã‘ãŸã¾ã‚“ã¾ã§è‰¯ã‹ã£ãŸã¨ã®ã“ã¨ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/73116c6a-d48f-42bc-aa5e-8342bb068052" alt="image" loading="lazy"><br><br></p>
<p>ã¾ãŸã€SimCSEã§å­¦ç¿’ã—ãŸsentence embeddingã‚’åˆ¥ã‚¿ã‚¹ã‚¯ã«transferã—ã¦æ´»ç”¨ã™ã‚‹éš›ã«ã¯ã€SimCSEã®objectiveã«MLMã‚’å…¥ã‚ŒãŸæ–¹ãŒã€catastrophic forgettingã‚’é˜²ã’ã¦æ€§èƒ½ãŒé«˜ã‹ã£ãŸã¨ã®ã“ã¨ã€‚<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cc6d20c3-5a0c-4b5e-aa6d-63447c55363f" alt="image" loading="lazy"></p>
<p>ablation studiesã®hard negativesã®ã¨ã“ã‚ã¨ã€ã©ã®ã‚ˆã†ã«ãƒŸãƒ‹ãƒãƒƒãƒã‚’æ§‹æˆã™ã‚‹ã‹ã€ãã‚Œãã‚Œã®transferã—ãŸã‚¿ã‚¹ã‚¯ãŒã©ã®ã‚ˆã†ãªã‚‚ã®ãŒã—ã£ã‹ã‚Šèª­ã‚ã¦ã„ãªã„ã€‚ã‚ã¨ã§ã‚ˆã‚€ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-07-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/901" target="_blank" rel="noopener noreferrer" class="title-link">Measuring Massive Multitask Language Understanding, Dan Hendrycks+, N_A, ICLR'21</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®æ­£ç¢ºæ€§ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ†ã‚¹ãƒˆã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ†ã‚¹ãƒˆã¯57ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚«ãƒãƒ¼ã—ã€åºƒç¯„ãªä¸–ç•ŒçŸ¥è­˜ã¨å•é¡Œè§£æ±ºèƒ½åŠ›ãŒå¿…è¦ã§ã™ã€‚ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯ã¾ã å°‚é–€å®¶ãƒ¬ãƒ™ãƒ«ã®æ­£ç¢ºæ€§ã«é”ã—ã¦ãŠã‚‰ãšã€æ€§èƒ½ã«åã‚ŠãŒã‚ã‚Šã¾ã™ã€‚ç§ãŸã¡ã®ãƒ†ã‚¹ãƒˆã¯ã€ãƒ¢ãƒ‡ãƒ«ã®å¼±ç‚¹ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=d7KBjmI3GmQ" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=d7KBjmI3GmQ</a>


</p>
<p>MMLUè«–æ–‡</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2736" target="_blank" rel="noopener noreferrer">[Paper Note] Are We Done with MMLU?, Aryo Pradipta Gema+, NAACL'25</a>
<br><br>ã«ãŠã„ã¦ã€å¤šãã®ã‚¨ãƒ©ãƒ¼ãŒå«ã¾ã‚Œã‚‹ã“ã¨ãŒæŒ‡æ‘˜ã•ã‚Œã€å†ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Ÿæ–½ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/PersonalizedGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedGeneration</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/PersonalizedHeadlineGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedHeadlineGeneration</a>
<span class="issue_date">Issue Date: 2023-05-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/706" target="_blank" rel="noopener noreferrer" class="title-link">PENS: A Dataset and Generic Framework for Personalized News Headline Generation, ACL'21</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®èˆˆå‘³ã¨ãƒ‹ãƒ¥ãƒ¼ã‚¹æœ¬æ–‡ã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹å‡ºã—ç”Ÿæˆã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚ã¾ãŸã€ã“ã®å•é¡Œã®ãŸã‚ã®å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹PENSã‚’å…¬é–‹ã—ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢ã‚’ç¤ºã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯https://msnews.github.io/pens.htmlã§å…¥æ‰‹å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«å¯¾ã™ã‚‹PersonalizedãªHeadlineã®æ­£è§£ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã€‚103åã®volunteerã®æœ€ä½ã§ã‚‚50ä»¶ã®ã‚¯ãƒªãƒƒã‚¯ãƒ­ã‚°ã¨ã€200ä»¶ã«å¯¾ã™ã‚‹æ­£è§£ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã—ãŸã€‚æ­£è§£ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹éš›ã¯ã€å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã”ã¨ã«4åç•°ãªã‚‹ãƒ¦ãƒ¼ã‚¶ãŒæ­£è§£ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«ã—ãŸã€‚ã“ã‚Œã‚‰ã‚’ã€Microsoft Newsã®å¤§è¦æ¨¡ãƒ¦ãƒ¼ã‚¶è¡Œå‹•ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã¨ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹æœ¬æ–‡ã€ã‚¿ã‚¤ãƒˆãƒ«ã€impressionãƒ­ã‚°ã¨çµ„ã¿åˆã‚ã›ã¦PENSãƒ‡ãƒ¼ã‚¿ã‚’æ§‹æˆã—ãŸã€‚<br><br><br><br># ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆæ‰‹é †<br><br>103åã®english-native [speakerã®å­¦ç”Ÿã«å¯¾ã—ã¦ã€1000ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã®ä¸­ã‹ã‚‰æœ€ä½50ä»¶èˆˆå‘³ã®ã‚ã‚‹ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’é¸æŠã—ã¦ã‚‚ã‚‰ã†ã€‚ç¶šã„ã¦ã€200ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«å¯¾ã—ã¦ã€æ­£è§£ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã—ãŸã‚‚ã‚‰ã†ã“ã¨ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ãŸã€‚æ­£è§£ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã™ã‚‹éš›ã¯ã€åŒä¸€ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«å¯¾ã—ã¦4äººãŒãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«èª¿æ•´ã—ãŸã€‚ç”Ÿæˆã•ã‚ŒãŸãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¯å°‚é–€å®¶ã«ã‚ˆã£ã¦qualityã‚’ãƒã‚§ãƒƒã‚¯ã•ã‚Œã€factual informationã«ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹ã‚‚ã®ã‚„ã€æ¥µç«¯ã«é•·ã„ãƒ»çŸ­ã„ã‚‚ã®ãªã©ã¯é™¤å¤–ã•ã‚ŒãŸã€‚<br><br><br><br># ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆé‡<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cd4fa969-03c0-4539-bcec-25ba3204ffc9" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1c9a38b4-4156-49a2-83e5-20e057588f91" alt="image" loading="lazy"><br><br><br><br># æ‰‹æ³•æ¦‚è¦<br><br>Transformer Encoder + Pointer Generatorã«ã‚ˆã£ã¦Personalizedãªãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã€‚<br><br>Transformer Encoderã§ã¯ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æœ¬æ–‡æƒ…å ±ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€attention distributionã‚’ç”Ÿæˆã™ã‚‹ã€‚Decoderå´ã§ã¯ã€User Embeddingã‚’çµ„ã¿åˆã‚ã›ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’Pointer Generatorã®æ çµ„ã¿ã§ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦ã„ãã€ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã€‚<br><br>User Embeddingã‚’ã©ã®ã‚ˆã†ã«injectã™ã‚‹ã‹ã§ã€3ç¨®é¡ã®æ–¹æ³•ã‚’ææ¡ˆã—ã¦ãŠã‚Šã€1ã¤ç›®ã¯ã€Decoderã®åˆæœŸçŠ¶æ…‹ã«è¨­å®šã™ã‚‹æ–¹æ³•ã€2ã¤ç›®ã¯ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æœ¬æ–‡ã®attention distributionã®è¨ˆç®—ã«åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã€3ã¤ç›®ã¯ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚ã«ã€ã‚½ãƒ¼ã‚¹ã‹ã‚‰vocabã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹ã‹ã€ç”Ÿæˆã™ã‚‹ã‹ã‚’é¸æŠã™ã‚‹éš›ã«åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã€‚1ã¤ç›®ã¯ä¸€ç•ªã‚·ãƒ³ãƒ—ãƒ«ãªæ–¹æ³•ã€2ã¤ç›®ã¯ã€ãƒ¦ãƒ¼ã‚¶ã«ã‚ˆã£ã¦è¨˜äº‹ã§ç€ç›®ã™ã‚‹éƒ¨åˆ†ãŒé•ã†ã‹ã‚‰attention distributionã‚‚å¤‰ãˆã¾ã—ã‚‡ã†ã€ãã—ã¦ã“ã‚Œã‚’å¤‰ãˆãŸã‚‰context vectorã‚‚å¤‰ã‚ã‚‹ã‹ã‚‰ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚ã®æŒ™å‹•ã‚‚å¤‰ã‚ã‚‹ã‚ˆã­ã¨ã„ã†ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã€3ã¤ç›®ã¯ã€é¸æŠã™ã‚‹vocabã‚’å—œå¥½ã«åˆã‚ã›ã¦å¤‰ãˆã¾ã—ã‚‡ã†ã€ã¨ã„ã†æ–¹å‘æ€§ã ã¨æ€ã‚ã‚Œã‚‹ã€‚æœ€çµ‚çš„ã«ã€2ã¤ç›®ã®æ–¹æ³•ãŒæœ€ã‚‚æ€§èƒ½ãŒè‰¯ã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/54d4da04-6af2-4ef2-b4ff-7a12f1ea7936" alt="image" loading="lazy"><br><br><br><br># è¨“ç·´æ‰‹æ³•<br><br>ã¾ãšãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã‚’è¨“ç·´ã—ã€user embeddingã‚’å–å¾—ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ç¶šã„ã¦ã€genericãªheadline generationãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã€‚æœ€å¾Œã«ä¸¡è€…ã‚’çµ„ã¿åˆã‚ã›ã¦ã€Reinforcement Learningã§Personalized Headeline Generationãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã€‚Rewardã¨ã—ã¦ã€<br><br>1. Personalization: ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¨user embeddingã®dot productã§å ±é…¬ã¨ã™ã‚‹<br><br>2. Fluency: two-layer LSTMã‚’è¨“ç·´ã—ã€ç”Ÿæˆã•ã‚ŒãŸãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã®probabilityã‚’æ¨å®šã™ã‚‹ã“ã¨ã§å ±é…¬ã¨ã™ã‚‹<br><br>3. Factual Consistency: ç”Ÿæˆã•ã‚ŒãŸãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã¨æœ¬æ–‡ã®å„æ–‡ã¨ã®ROUGEã‚’æ¸¬ã‚Štop-3 scoreã®å¹³å‡ã‚’å ±é…¬ã¨ã™ã‚‹<br><br>ã¨ã—ãŸã€‚<br><br>1,2,3ã®å¹³å‡ã‚’æœ€çµ‚çš„ãªRewardã¨ã™ã‚‹ã€‚<br><br><br><br># å®Ÿé¨“çµæœ<br><br>Genericãªæ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦ã€å…¨ã¦Personalizedãªæ‰‹æ³•ãŒè‰¯ã‹ã£ãŸã€‚ã¾ãŸã€æ‰‹æ³•ã¨ã—ã¦ã¯â‘¡ã®attention distributionã«å¯¾ã—ã¦user informationã‚’æ³¨å…¥ã™ã‚‹æ–¹æ³•ãŒè‰¯ã‹ã£ãŸã€‚News Recommendationã®æ€§èƒ½ãŒé«˜ã„ã»ã©ã€ç”Ÿæˆã•ã‚Œã‚‹ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã®æ€§èƒ½ã‚‚è‰¯ã‹ã£ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/84aa7b6d-05cf-415a-a2cf-76401801230f" alt="image" loading="lazy"><br><br><br><br># Case Study<br><br>ã‚ã‚‹è¨˜äº‹ã«å¯¾ã™ã‚‹ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ã®ä¸€è¦§ã€‚Pointer-Genã§ã¯ã€é‡è¦ãªæƒ…å ±ãŒæŠœã‘è½ã¡ã¦ã—ã¾ã£ã¦ã„ã‚‹ãŒã€ææ¡ˆæ‰‹æ³•ã§ã¯æŠœã‘è½ã¡ã¦ã„ãªã„ã€‚ã“ã‚Œã¯RLã®å ±é…¬ã®fluencyã«ã‚ˆã‚‹ã‚‚ã®ã ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚ã¾ãŸã€ç•°ãªã‚‹ãƒ¦ãƒ¼ã‚¶ã«ã¯ç•°ãªã‚‹ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ãŒç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚ <br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e65eb9da-7cc6-4d72-b2ca-8607c794f3a0" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/review.html" target="_blank" rel="noopener noreferrer">#review</a>
<span class="issue_date">Issue Date: 2023-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/655" target="_blank" rel="noopener noreferrer" class="title-link">Transformer Reasoning Network for Personalized Review Summarization, Xu+, SIGIR'21</a>
<span class="snippet"><span>Comment</span><p>å…ˆè¡Œç ”ç©¶ã¯ã€review summarizationã«ãŠã„ã¦ç”Ÿæˆã•ã‚Œã‚‹summaryã¯ã€éå»ã«ãƒ¦ãƒ¼ã‚¶ãŒä½œæˆã—ãŸsummaryã®writing styleã‚„productã«éå¸¸ã«é–¢ä¿‚ã—ã¦ã„ã‚‹ã®ã«ã€ã“ã‚Œã‚‰ã‚’æ´»ç”¨ã—ã¦ã“ãªã‹ã£ãŸã®ã§ã€æ´»ç”¨ã—ã¾ã—ãŸï¼ˆ=personalizedï¼‰ã¨ã„ã†è©±ã£ã½ã„</p></span><br><br>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2023-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/598" target="_blank" rel="noopener noreferrer" class="title-link">ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«å¯¾ã™ã‚‹è«‡è©±æ§‹é€ ã¨èˆˆå‘³åº¦ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ ï½ãƒ‹ãƒ¥ãƒ¼ã‚¹å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã«å‘ã‘ã¦ï½, é«˜æ´¥+, æ—©ç¨²ç”°å¤§å­¦, è¨€èªå‡¦ç†å­¦ä¼š'21</a>
<span class="snippet"><span>Comment</span><p>ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«å¯¾ã—ã¦è«‡è©±æ§‹é€ ãŠã‚ˆã³ï¼Œãƒ¦ãƒ¼ã‚¶ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã¨è¨˜äº‹ã®è©±é¡Œãƒ»æ–‡ã«å¯¾ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ã®èˆˆå‘³åº¦ã‚’ä»˜ä¸ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚<br><br>ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã¨ã—ã¦ä»¥ä¸‹ã‚’åé›†ï¼š<br><br>- æ€§åˆ¥<br><br>- å¹´é½¢ï¼Œ<br><br>- ä½ã‚“ã§ã„ã‚‹åœ°åŸŸ<br><br>- è·ç¨®<br><br>- æ¥­ç¨®<br><br>- ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¦‹ã‚‹é »åº¦ï¼Œ<br><br>- ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ã‚ˆããƒã‚§ãƒƒã‚¯ã™ã‚‹æ™‚é–“å¸¯<br><br>- æ˜ åƒãƒ»éŸ³å£°ãƒ»æ–‡å­—ã®ã†ã¡ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¸ã®æ¥è§¦æ–¹æ³•ã¨ã—ã¦å¤šã„ã‚‚ã®ã¯ã©ã‚Œã‹<br><br>- ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’çŸ¥ã‚‹æ‰‹æ®µ<br><br>- ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’èª­ã‚€éš›ä½¿ç”¨ã—ã¦ã„ã‚‹æ–°èã‚„ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆãƒ»ã‚¢ãƒ—ãƒª<br><br>- æœ‰æ–™ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’èª­ã‚“ã§ã„ã‚‹ã‹<br><br>- æ™®æ®µç©æ¥µçš„ã«èª­ã‚€ãƒ»è¦‹ã‚‹ãƒ»èããƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚¸ãƒ£ãƒ³ãƒ«<br><br>- ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚¸ãƒ£ãƒ³ãƒ«ã«å¯¾ã™ã‚‹èˆˆå‘³ã®ç¨‹åº¦ï¼Œè¶£å‘³ï¼</p></span><br><br>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<span class="issue_date">Issue Date: 2023-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/595" target="_blank" rel="noopener noreferrer" class="title-link">è«‡è©±æ§‹é€ åˆ¶ç´„ä»˜ããƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºãƒ‰æŠ½å‡ºå‹è¦ç´„, é«˜æ´¥+, æ—©ç¨²ç”°å¤§å­¦, è¨€èªå‡¦ç†å­¦ä¼š'21</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/550" target="_blank" rel="noopener noreferrer" class="title-link">Learning Transferable Visual Models From Natural Language Supervision, Radford+, OpenAI, ICML'21</a>
<span class="snippet"><span>Comment</span><p>CLIPè«–æ–‡ã€‚å¤§é‡ã®ç”»åƒã¨ç”»åƒã«å¯¾å¿œã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®ãƒšã‚¢ã‹ã‚‰ã€å¯¾è±¡å­¦ç¿’ã‚’è¡Œã„ã€ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆé–“ã®similarityã‚’ã¯ã‹ã‚Œã‚‹ã‚ˆã†ã«ã—ãŸãƒ¢ãƒ‡ãƒ«<br><br><img src="https://user-images.githubusercontent.com/12249301/234729329-dfa5dc1e-c5fc-452c-8ead-76df7d1aeda4.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2023-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/538" target="_blank" rel="noopener noreferrer" class="title-link">Refocusing on Relevance: Personalization in NLG, Shiran Dudy+, Department of Computer Science University of Colorado, EMNLP'21</a>
<span class="snippet"><span>Comment</span><p>å¾“æ¥ã®NLGã¯ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã«ç„¦ç‚¹ã‚’å½“ã¦ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã«æ³¨åŠ›ã—ã¦ããŸã€‚ãŒã€ãƒ¦ãƒ¼ã‚¶ã®æ„å›³ã‚„contextãŒã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã«åŸºã¥ã„ã¦å¾©å…ƒã§ããªã„å ´åˆã€ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ä¸ååˆ†ã§ã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã€‚<br><br>ã“ã®ç ”ç©¶ã§ã¯NLGã‚·ã‚¹ãƒ†ãƒ ãŒè¿½åŠ ã®contextã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã«å¤§ããªé‡ç‚¹ã‚’ãŠãã¹ãã§ã‚ã‚Šã€IRç­‰ã§æ´»ç”¨ã•ã‚Œã¦ã„ã‚‹relevancyã‚’ãƒ¦ãƒ¼ã‚¶æŒ‡å‘ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¿ã‚¹ã‚¯ã‚’è¨­è¨ˆã™ã‚‹ãŸã‚ã®é‡è¦ãªæŒ‡æ¨™ã¨ã—ã¦è€ƒãˆã‚‹ã“ã¨ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Game.html" target="_blank" rel="noopener noreferrer">#Game</a>
<span class="issue_date">Issue Date: 2022-09-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/487" target="_blank" rel="noopener noreferrer" class="title-link">Generating Racing Game Commentary from Vision, Language, and Structured Data, Tatsuya+, INLG'21</a>
<span class="snippet"><span>Comment</span><p>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: 


<a href="https://kirt.airc.aist.go.jp/corpus/ja/RacingCommentary" target="_blank" rel="noopener noreferrer">https://kirt.airc.aist.go.jp/corpus/ja/RacingCommentary</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2022-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/473" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Power of Scale for Parameter-Efficient Prompt Tuning, Brian Lester+, arXiv'21, 2021.04</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å‡çµã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã«é©å¿œã•ã›ã‚‹ãŸã‚ã®ã€Œã‚½ãƒ•ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ã‚’å­¦ç¿’ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã€‚é€†ä¼æ’­ã‚’é€šã˜ã¦å­¦ç¿’ã•ã‚Œã‚‹ã‚½ãƒ•ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã€GPT-3ã®å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã»ã©ç«¶äº‰åŠ›ãŒå¢—ã™ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚ç‰¹ã«ã€æ•°åå„„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€å…¨ã¦ã®é‡ã¿ã‚’èª¿æ•´ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€1ã¤ã®å‡çµãƒ¢ãƒ‡ãƒ«ã‚’è¤‡æ•°ã®ã‚¿ã‚¹ã‚¯ã«å†åˆ©ç”¨ã§ãã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã€ãƒ‰ãƒ¡ã‚¤ãƒ³è»¢é€ã«å¯¾ã™ã‚‹ãƒ­ãƒã‚¹ãƒˆæ€§ã‚‚å‘ä¸Šã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã¨ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬: 


<a href="https://qiita.com/kts_plea/items/79ffbef685d362a7b6ce" target="_blank" rel="noopener noreferrer">https://qiita.com/kts_plea/items/79ffbef685d362a7b6ce</a>


<br><br>T5ã®ã‚ˆã†ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦finetuningã‚’ã‹ã‘ã‚‹éš›ã«ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å‡çµã—ã€promptã‚’embeddingã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç‹¬ç«‹ã—ã¦å­¦ç¿’ã™ã‚‹æ‰‹æ³•<br><br>è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¢—åŠ ã™ã‚‹ã«ã¤ã‚Œã€è¨€èªãƒ¢ãƒ‡ãƒ«ãã®ã‚‚ã®ã‚’finetuningã—ãŸå ´åˆï¼ˆModel Tuningï¼‰ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</p>
<p>ã„ã‚ã‚†ã‚‹(Softãª) Prompt Tuning</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2022-08-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/472" target="_blank" rel="noopener noreferrer" class="title-link">Biomedical Data-to-Text Generation via Fine-Tuning Transformers, Ruslan+, INLG'21</a>
<span class="snippet"><span>Comment</span><p>biomedical domainã®æ–°ãŸãªdata2textãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æä¾›ã€‚äº‹å‰å­¦ç¿’æ¸ˆã¿ã®BART, T5ç­‰ã‚’finetuningã™ã‚‹ã“ã¨ã§é«˜ç²¾åº¦ã«ãƒ†ã‚­ã‚¹ãƒˆãŒç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/TACL.html" target="_blank" rel="noopener noreferrer">#TACL</a>
<span class="issue_date">Issue Date: 2021-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/412" target="_blank" rel="noopener noreferrer" class="title-link">WikiAsp: A Dataset for Multi-domain Aspect-based Summarization, Hayashi+, CMU, TACL'21, NLPã‚³ãƒ­ã‚­ã‚¦ãƒ </a>
<span class="snippet"><span>Comment</span><p>â—†Aspect-based summarizationã®ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³<br><br>ãƒ»same sourceå¯¾ã—ã¦ã€ç•°ãªã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ‹ãƒ¼ã‚ºãŒå­˜åœ¨ã™ã‚‹ã®ã§ã€ãƒ‹ãƒ¼ã‚ºã«é–¢ã—ã¦è¦ç´„ã—ãŸã„<br><br><br><br>â—†Aspect: ã‚ã‚‹objectã«å¯¾ã™ã‚‹ã€attributeã®ã‚ˆã†ãªã‚‚ã®ã‚’æŒ‡å®šï¼Ÿ<br><br>ã€€object: Attention Is All You Need<br><br>ã€€aspect: Multi-Head Attention<br><br><br><br>â—†Aspect Based Summarizationã®æ­´å²<br><br>ãƒ»ã¯ã˜ã‚ã¯â€featureâ€ã¨ã„ã†æ–‡è¨€ã§ç ”ç©¶ã•ã‚Œï¼ˆ04å¹´é ƒï¼Ÿï¼‰<br><br>ãƒ»ç¶šã„ã¦*keywords*ã¨ã„ã†å˜èªã§ç ”ç©¶ã•ã‚Œ<br><br>ãƒ»ãã®å¾ŒAspectã¨ã„ã†æ–‡è¨€ã§ç ”ç©¶ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã£ãŸ<br><br>ãƒ»2008å¹´é ƒã«McDonaldsã‚‰ãŒAspect-Based Summarizationã‚’ææ¡ˆã—ãŸ<br><br>ãƒ»2014å¹´ä»¥å¾Œï¼Ÿã¨ã‹ã«Neural Basedãªæ‰‹æ³•ãŒç››ã‚“ã«ç ”ç©¶<br><br><br><br>â—†WikiAspãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¤ã„ã¦<br><br>ãƒ»Wikipediaã‚’ä½¿ã£ãŸAspect-based dataset<br><br>ãƒ»Wikipediaã‚’æ›¸ã‹ã‚Œã‚‹ã®ã«åˆ©ç”¨ã•ã‚ŒãŸsource documentï¼ˆwikipediaã«ã‚½ãƒ¼ã‚¹ã¨ã—ã¦å¼•ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ï¼‰ã«å¯¾ã—ã€aspectã‚’å„ç¯€ã®è¦‹å‡ºã—ã¨ã¿ãªã—ã€ç¯€ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„æ–‡ã¨ã¿ãªã™ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ<br><br>ãƒ»ä»–ã®Aspect-basedãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ç•°ãªã‚Šã€ã‚½ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒé•·ãã€è¦ç´„é•·ã‚‚5~6å€ç¨‹åº¦<br><br>ãƒ»ãƒ‰ãƒ¡ã‚¤ãƒ³æ•°ãŒä»–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯5,6ç¨‹åº¦ã«å¯¾ã—ã€20ã¨è†¨å¤§<br><br><br><br>â—†ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã—ã¦2-stageãƒ¢ãƒ‡ãƒ«ã‚’æ¡ç”¨<br><br>first-stage: ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ROBERTaãƒ™ãƒ¼ã‚¹ãƒ‰ãªclassifierã‚’ç”¨ã„ã¦ã€sentencesã‹ã‚‰å†…åŒ…ã™ã‚‹Aspectã‚’é–¾å€¤ã‚’ç”¨ã„ã¦æ±ºå®š<br><br>ã€€ã€€ã€€ã€€ã€€ãã‚Œã‚‰ã‚’grouped sentencesã¨ã™ã‚‹<br><br>two-stage: å„aspectã”ã¨ã«ã¾ã¨ã¾ã£ãŸãƒ†ã‚­ã‚¹ãƒˆé›†åˆã«å¯¾ã—ã¦ã€è¦ç´„ãƒ¢ãƒ‡ãƒ«ã‚’é©ç”¨ã—ã€è¦ç´„ã‚’å®Ÿæ–½ã™ã‚‹<br><br>ãƒ»è¦ç´„ãƒ¢ãƒ‡ãƒ«ã¯Unsupervisedãªæ‰‹æ³•ã§ã‚ã‚‹TextRankã¨ã€Supervisedãªæ‰‹æ³•ã§ã‚ã‚‹BERTãƒ™ãƒ¼ã‚¹ãªæ‰‹æ³•ã‚’æ¡ç”¨<br><br>ãƒ»ãƒ‰ãƒ¡ã‚¤ãƒ³ã”ã¨ã«è©•ä¾¡ã—ãŸçµæœã‚’è¦‹ã‚‹ã¨ã€BERTãŒå¼·ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒã‚ã‚‹ä¸€æ–¹ã§ã€TextRankãŒå¼·ã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚‚ã‚ã£ãŸ<br><br>ã€€-&gt; Extractiveãªå½¢ã§è¦ç´„ã•ã‚Œã¦ã„ã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã¯TextRankãŒå¼·ãã€Abstractiveã«è¦ç´„ã•ã‚Œã¦ã„ã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã¯BERTãŒå¼·ã„<br><br>ã€€-&gt; ã¾ãŸBERTã¯æ¯”è¼ƒçš„çŸ­ã„è¦ç´„ã§ã‚ã‚Œã°TextRankã‚ˆã‚Šã‚‚ã¯ã‚‹ã‹ã«è‰¯ã„ãŒã€é•·ã„è¦ç´„æ–‡ã«ãªã‚‹ã¨TextRankã¨comprableï¼ˆã‚ã‚‹ã„ã¯TextRankã®æ–¹ãŒè‰¯ã„ï¼‰ç¨‹åº¦ã®æ€§èƒ½ã«ãªã‚‹<br><br>ãƒ»ROUGE-2ã®å€¤ãŒsentence-basedãªORACLEã‚’è¦‹ãŸæ™‚ã«ã€ä»–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨æ¯”è¼ƒã—ã¦ä½ã„ã®ã§ã€Abstractiveãªæ‰‹æ³•ãŒå¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼Ÿ<br><br><br><br>ï¼ˆå¾Œã‹ã‚‰ã®ãƒ¡ãƒ¢ãªã®ã§å°‘ã—ã†ã‚è¦šãˆãªéƒ¨åˆ†ã‚ã‚Šï¼‰</p>
<p>Q. ROUGE-2ãŒ30ã¨ã‹ã£ã¦ç›´è¦³çš„ã«ã©ã®ãã‚‰ã„ã®ãƒ¬ãƒ™ãƒ«ã®ã‚‚ã®ãªã®ï¼ŸROUGE-2ãŒ30ã¨ã‹40ã¨ã‹ã¯é«˜ã„<br><br>ãƒ»æœ€å…ˆç«¯ã®è¦ç´„ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«é©ç”¨ã™ã‚‹ã¨ã€35~40ãã‚‰ã„ã«ãªã‚‹ã€‚<br><br>ãƒ»ã“ã®ãƒ¬ãƒ™ãƒ«ã®æ•°å€¤ã«ãªã‚‹ã¨ã€äººé–“ãŒå‘¼ã‚“ã§ã‚‚é•å’Œæ„ŸãŒãªã„ãƒ¬ãƒ™ãƒ«ã®è¦ç´„ã¨ãªã£ã¦ã„ã‚‹</p>
<p>Q. å®Ÿéš›ã«è¦ç´„æ–‡ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã¿ã¦ã€ã©ã†ã„ã†èª²é¡Œã‚’æ„Ÿã˜ã‚‹ã‹ï¼Ÿ<br><br>A. Factual ConsistencyãŒã™ãã«ç›®ã«ã¤ãå•é¡Œã§ã€ç‰¹ã«BERTãƒ™ãƒ¼ã‚¹ãªè¦ç´„æ–‡ã¯ãã†ã€‚TextRankã¯ã‚½ãƒ¼ã‚¹æ–‡æ›¸ãŒãƒã‚¤ã‚¸ãƒ¼ãªã®ã§ã€ã‚½ãƒ¼ã‚¹æ–‡ç« ã‚’é©å½“ã«æ‹¾ã£ã¦ããŸã ã‘ã§ã¯Factual ConsistencyãŒè‰¯ããªã„ï¼ˆå…ƒã®æ–‡æ›¸ãŒã‹ã£ã¡ã‚Šã—ã¦ã„ãªã„ï¼‰ã€‚æµæš¢æ€§ã®å•é¡Œã¯Abstractiveãƒ¢ãƒ‡ãƒ«ã ã¨ç‰¹ã«å•é¡ŒãªãBERT-baseã§ã§ãã‚‹ã€‚Aspect-basedè¦ç´„ã®ã‚¨ãƒ©ãƒ¼ä¾‹ã¨ã—ã¦Aspectã«å‰‡ã£ã¦ã„ãªã„ã¨ã„ã†ã“ã¨ãŒã‚ã‚‹ã€‚ãŸã¨ãˆã°ã‚ªãƒãƒã®å¤§çµ±é ˜æ™‚ä»£ã®è©±ã‚’ãã„ã¦ã„ã‚‹ã®ã«ã€å¹¼å°‘æ™‚ä»£ã®è©±ã‚’ã—ã¦ã„ã‚‹ã¨ã‹ã€‚Aspectæƒ…å ±ã‚’ã†ã¾ããƒ¢ãƒ‡ãƒ«ã‚’æ‰±ãˆã¦ã„ãªã„ã¨ã„ã†ç‚¹ãŒèª²é¡Œã¨ã—ã¦ã‚ã‚‹ã€‚</p>
<p>å‡ºå…¸å…ƒï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«è´è¬›ï¼‰: ç¬¬13å› WikiAsp: A Dataset for Multi-domain Aspect-based Summarization, NLPã‚³ãƒ­ã‚­ã‚¦ãƒ <br>


<a href="https://youtu.be/3PIJotX6i_w?si=hX5pXwNL-ovkGSF5" target="_blank" rel="noopener noreferrer">https://youtu.be/3PIJotX6i_w?si=hX5pXwNL-ovkGSF5</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2021-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/409" target="_blank" rel="noopener noreferrer" class="title-link">éå»æƒ…å ±ã®å†…å®¹é¸æŠã‚’å–ã‚Šå…¥ã‚ŒãŸ ã‚¹ãƒãƒ¼ãƒ„ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã®è‡ªå‹•ç”Ÿæˆ, åŠ è—¤+, æ±å·¥å¤§, NLP'21</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2021-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/405" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Prefix-Tuning: Optimizing Continuous Prompts for Generation, Xiang Lisa Li+, arXiv'21, 2021.01</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®è»½é‡ãªä»£æ›¿æ‰‹æ®µã§ã‚ã‚Šã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å›ºå®šã—ã¤ã¤ã€ã‚¿ã‚¹ã‚¯ç‰¹æœ‰ã®å°ã•ãªãƒ™ã‚¯ãƒˆãƒ«ã‚’æœ€é©åŒ–ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ä½ãƒ‡ãƒ¼ã‚¿è¨­å®šã§ã‚‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’fine-tuningã™ã‚‹éš›ï¼Œã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ™‚ã«ã€Œæ¥é ­è¾ã€ã‚’æ½œåœ¨è¡¨ç¾ã¨ã—ã¦ä¸ãˆï¼Œã€Œæ¥é ­è¾ã€éƒ¨åˆ†ã®ã¿ã‚’fine-tuningã™ã‚‹ã“ã¨ã§ï¼ˆä»–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å›ºå®šï¼‰ï¼Œã‚ˆã‚Šå°‘é‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§fine-tuningã‚’å®Ÿç¾ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆï¼æ¥é ­è¾ã‚’æ½œåœ¨è¡¨ç¾ã§ä¸ãˆã‚‹ã“ã®æ–¹æ³•ã¯ï¼ŒGPT-3ã®promptingã«ç€æƒ³ã‚’å¾—ã¦ã„ã‚‹ï¼fine-tuningã•ã‚ŒãŸæ¥é ­è¾ã®æ½œåœ¨è¡¨ç¾ã®ã¿ã‚’é…å¸ƒã™ã‚Œã°è‰¯ã„ã®ã§ï¼Œéå¸¸ã«å°‘é‡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§fine-tuningãŒã§ãã‚‹ï¼<br><br><br><br>table-to-text, summarizationã‚¿ã‚¹ã‚¯ã§ï¼Œä¸€èˆ¬çš„ãªfine-tuningã‚„Adapterï¼ˆãƒ¬ã‚¤ãƒ¤ãƒ¼ã®é–“ã«ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’æŒ¿å…¥ã—ãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã ã‘ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ‰‹æ³•ï¼‰ã¨ã„ã£ãŸåŠ¹ç‡çš„ãªfine-tuningæ‰‹æ³•ã¨æ¯”è¼ƒï¼table-to-textã§ã¯ã€250k (å…ƒã®ãƒ¢ãƒ‡ãƒ«ã® 0.1%) ã»ã©ã®æ•°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¾®èª¿æ•´ã™ã‚‹ã ã‘ã§ã€å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’fine-tuningã™ã‚‹ã®ã«åŒ¹æ•µã‚‚ã—ãã¯ãã‚Œä»¥ä¸Šã®æ€§èƒ½ã‚’é”æˆï¼<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/132679791-87ad130d-8a7e-4549-a311-f84400a3787b.png" alt="image" loading="lazy"><br><br></p>
<p>Hugging Faceã®å®Ÿè£…ã‚’åˆ©ç”¨ã—ãŸã¨è«–æ–‡ä¸­ã§ã¯è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ãŒï¼Œfine-tuningã™ã‚‹å‰ã®å…ƒã®è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆGPT-2ï¼‰ã¯ã©ã®ã‚ˆã†ã«æº–å‚™ã—ãŸã®ã ã‚ã†ã‹ï¼Hugging Faceã®pretrainedæ¸ˆã¿ã®GPT-2ã‚’ä½¿ç”¨ã—ãŸã®ã ã‚ã†ã‹ï¼</p>
<p>autoregressive LM (GPT-2)ã¨ï¼Œencoder-decoderãƒ¢ãƒ‡ãƒ«ï¼ˆBARTï¼‰ã¸Prefix Tuningã‚’é©ç”¨ã™ã‚‹å ´åˆã®æ¨¡å¼å›³<br><br><img src="https://user-images.githubusercontent.com/12249301/132681736-0ea4b13f-71cb-41ba-ae17-027e8bf54cc0.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-09-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3016" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Dense Passage Retrieval for Open-Domain Question Answering, Vladimir Karpukhin+, EMNLP'20, 2020.04</a>
<span class="snippet"><span>GPT Summary</span>- å¯†ãªè¡¨ç¾ã‚’ç”¨ã„ãŸãƒ‘ãƒƒã‚»ãƒ¼ã‚¸æ¤œç´¢ã®å®Ÿè£…ã‚’ç¤ºã—ã€ãƒ‡ãƒ¥ã‚¢ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§å­¦ç¿’ã€‚è©•ä¾¡ã®çµæœã€Lucene-BM25ã‚’ä¸Šå›ã‚Šã€æ¤œç´¢ç²¾åº¦ã§9%-19%ã®æ”¹å–„ã‚’é”æˆã€‚æ–°ãŸãªæœ€å…ˆç«¯ã®QAæˆæœã‚’ç¢ºç«‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Dense RetrieverãŒåºƒãçŸ¥ã‚‰ã‚Œã‚‹ãã£ã‹ã‘ã¨ãªã£ãŸç ”ç©¶ï¼ˆã‚ˆã‚Šå¤ãã¯DSSM <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/364" target="_blank" rel="noopener noreferrer">Learning Deep Structured Semantic Models  for Web Search using Clickthrough Data, Huang+, CIKM'13</a>
 ãªã©ãŒã‚ã‚‹)ã€‚bag-of-wordsã®ã‚ˆã†ãªsparseãªãƒ™ã‚¯ãƒˆãƒ«ã§æ¤œç´¢ã™ã‚‹ã®ã§ã¯ãªãï¼ˆ=Sparse Retriever)ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸå¯†ãªãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”¨ã„ã¦æ¤œç´¢ã—ã‚ˆã†ã¨ã„ã†è€ƒãˆæ–¹ã§ã‚ã‚‹ã€‚<br><br>Queryç”¨ã¨æ¤œç´¢å¯¾è±¡ã®Passageã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹Encoderã‚’ç‹¬ç«‹ã—ã¦ãã‚Œãã‚Œç”¨æ„ã—ï¼ˆï¼DualEncoder)ã€QAã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆã™ãªã‚ã¡ã‚¯ã‚¨ãƒªqã¨æ­£ä¾‹ã¨ã—ã¦æ­£è§£passage p+)ãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã€ã‚¯ã‚¨ãƒªqã¨æ­£ä¾‹p+ã®é¡ä¼¼åº¦ãŒé«˜ãã€è² ä¾‹p-ã¨ã®é¡ä¼¼åº¦ãŒä½ããªã‚‹ã‚ˆã†ã«ï¼ˆ=Contrastive Learning)ã€Query, Passage Encoderã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã“ã¨ã§å­¦ç¿’ã™ã‚‹ï¼ˆæå¤±é–¢æ•°ã¯å¼(2))ã€‚<br><br>è² ä¾‹ã¯In-Batch Negativeã‚’ç”¨ã„ã‚‹ã€‚æƒ…å ±æ¤œç´¢ã®å ´åˆæ­£è§£ãƒ©ãƒ™ãƒ«ã¯å¤šãã®å ´åˆæ˜ç¤ºçš„ã«æ±ºã¾ã‚‹ãŒã€è² ä¾‹ã¯è†¨å¤§ãªãƒ†ã‚­ã‚¹ãƒˆã®ãƒ—ãƒ¼ãƒ«ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ–¹æ³•ã¯ã„ã‚ã„ã‚ãªæ–¹æ³•ãŒã‚ã‚Šï¼ˆe.g., ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€qã¨bm25ã‚¹ã‚³ã‚¢ãŒé«˜ã„passageï¼ˆãŸã ã—æ­£è§£ã¯å«ã¾ãªã„; hard negativesã¨å‘¼ã¶ï¼‰ãã®ä¸­ã®ä¸€ã¤ã®æ–¹æ³•ãŒIn-Batch Negativesã§ã‚ã‚‹ã€‚<br><br>In-Batch Negativesã§ã¯ã€åŒãƒŸãƒ‹ãƒãƒƒãƒå†…ã®q_iã«å¯¾å¿œã™ã‚‹æ­£ä¾‹p+_iä»¥å¤–ã®å…¨ã¦ã®p_jã‚’ï¼ˆæ“¬ä¼¼çš„ã«ï¼‰è² ä¾‹ã¨ã¿ãªã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ›´æ–°ã«åˆ©ç”¨ã™ã‚‹ãŸã‚ã®q,pã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’å…¨ã¦ä¸€åº¦ã ã‘å®Ÿè¡Œã™ã‚Œã°è‰¯ãã€è¨ˆç®—åŠ¹ç‡ãŒå¤§å¹…ã«å‘ä¸Šã™ã‚‹ã¨ã„ã†å„ªã‚Œã‚‚ã®ã€‚æœ¬ç ”ç©¶ã®å®Ÿé¨“ï¼ˆTable3)ã«ã‚ˆã‚‹ã¨ä¸Šè¿°ã—ãŸIn-Batch Negativeã«åŠ ãˆã¦ã€bm25ã«ã‚ˆã‚‹hard negativeã‚’ãƒãƒƒãƒå†…ã®å„qã«å¯¾ã—ã¦1ã¤è² ä¾‹ã¨ã—ã¦è¿½åŠ ã™ã‚‹æ–¹æ³•ãŒæœ€ã‚‚æ€§èƒ½ãŒè‰¯ã‹ã£ãŸã€‚<br><br>ã‚¯ã‚¨ãƒªã€passageã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¨ã—ã¦ã¯ã€BERTãŒç”¨ã„ã‚‰ã‚Œã€[CLS]ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾å¿œã™ã‚‹embeddingã‚’ç”¨ã„ã¦é¡ä¼¼åº¦ãŒè¨ˆç®—ã•ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/TACL.html" target="_blank" rel="noopener noreferrer">#TACL</a>
<a class="button" href="articles/Grammar.html" target="_blank" rel="noopener noreferrer">#Grammar</a>
<span class="issue_date">Issue Date: 2025-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2715" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BLiMP: The Benchmark of Linguistic Minimal Pairs for English, Alex Warstadt+, TACL'20</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªçš„æœ€å°å¯¾ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆBLiMPï¼‰ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ–‡æ³•çŸ¥è­˜ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã‚»ãƒƒãƒˆã§ã€67ã®ã‚µãƒ–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰æˆã‚Šã€å„ã‚µãƒ–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯ç‰¹å®šã®æ–‡æ³•å¯¾æ¯”ã‚’ç¤ºã™1000ã®æœ€å°å¯¾ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯å°‚é–€å®¶ã«ã‚ˆã£ã¦è‡ªå‹•ç”Ÿæˆã•ã‚Œã€äººé–“ã®åˆæ„ã¯96.4%ã§ã™ã€‚n-gramã€LSTMã€Transformerãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ãŸçµæœã€æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«ã¯å½¢æ…‹è«–çš„å¯¾æ¯”ã‚’è­˜åˆ¥ã§ãã‚‹ãŒã€æ„å‘³çš„åˆ¶ç´„ã‚„å¾®å¦™ãªæ–‡æ³•ç¾è±¡ã«ã¯è‹¦æˆ¦ã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ˆè¡Œç ”ç©¶ã¨æ¯”è¼ƒã—ã¦ã€ã‚ˆã‚Šåºƒç¯„ãªlinguistic phenomenaã‚’æ‰±ã„ã€ã‹ã¤å¤§é‡ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’é›†ã‚ãŸè‹±èªã®acceptable/unacceptableãªsentenceã®ãƒšã‚¢ãƒ‡ãƒ¼ã‚¿ã€‚ãƒšã‚¢ãƒ‡ãƒ¼ã‚¿ã¯ç‰¹å®šã®linguistic phenomenaã‚’acceptable/unacceptableã«å¯¾æ¯”ã™ã‚‹ãŸã‚ã®æœ€å°ã®é•ã„ã«åŸºã¥ã„ã¦ãŠã‚Šå°‚é–€å®¶ãŒä½œæˆã—ãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«åŸºã¥ã„ã¦è‡ªå‹•ç”Ÿæˆã•ã‚Œã€ã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚·ãƒ³ã‚°ã«ã‚ˆã£ã¦äººæ‰‹ã§validationã•ã‚Œã¦ã„ã‚‹ã€‚è¨€èªãƒ¢ãƒ‡ãƒ«ãŒè‹±èªã®linguistic phenomenaã«ã¤ã„ã¦ã€ã©ã®ç¨‹åº¦ç†è§£ã—ã¦ã„ã‚‹ã‹ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«åˆ©ç”¨å¯èƒ½ã€‚<br><br><img src="https://github.com/user-attachments/assets/600cafa5-bed7-4299-ba5c-4ffb835e2368" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2025-08-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2388" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Longformer: The Long-Document Transformer, Iz Beltagy+, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- Longformerã¯ã€é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç·šå½¢ã«å‡¦ç†ã§ãã‚‹æ³¨æ„æ©Ÿæ§‹ã‚’æŒã¤Transformerãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã§ã€æ•°åƒãƒˆãƒ¼ã‚¯ãƒ³ã®æ–‡æ›¸ã‚’æ‰±ãˆã‚‹ã€‚å±€æ‰€çš„ãªã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ³¨æ„ã¨ã‚¿ã‚¹ã‚¯ã«åŸºã¥ãã‚°ãƒ­ãƒ¼ãƒãƒ«æ³¨æ„ã‚’çµ„ã¿åˆã‚ã›ã€æ–‡å­—ãƒ¬ãƒ™ãƒ«ã®è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã€‚äº‹å‰å­¦ç¿’ã¨ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã„ã€é•·æ–‡ã‚¿ã‚¹ã‚¯ã§RoBERTaã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€Longformer-Encoder-Decoderï¼ˆLEDï¼‰ã‚’å°å…¥ã—ã€é•·æ–‡ç”Ÿæˆã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹åŠ¹æœã‚’ç¢ºèªã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ï¼ˆå›ºå®šã•ã‚ŒãŸå°ã•ã‚ã®windowsã‚µã‚¤ã‚ºã®ä¸­ã§ã®ã¿attentionã‚’è¨ˆç®—ã™ã‚‹ï¼‰sliding window attentionã‚’ææ¡ˆã€‚Figure2ã‚’è¦‹ã‚‹ã¨ã€é€šå¸¸ã®Attentionã¨æ¯”è¼ƒã—ã¦ã€ç¾åœ¨ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®å‘¨è¾ºã®ãƒˆãƒ¼ã‚¯ãƒ³ã«ã—ã‹æ³¨ç›®ã—ãªã„ç‰¹æ€§ãŒå›³ç¤ºã•ã‚Œã¦ãŠã‚Šã€ã‚¤ãƒ¡ãƒ¼ã‚¸ãŒæ´ã¿ã‚„ã™ã„ã€‚<br><br>&lt;img width="795" height="231" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/d1eccdaf-5b5b-4444-ad31-44c54c345d79"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/d1eccdaf-5b5b-4444-ad31-44c54c345d79"&lt;/a&gt;


/&gt;</p>
<p>OpenLLMã®æ–‡è„ˆã ã¨ã€Mistralã«æ¡ç”¨ã•ã‚Œã¦è©±é¡Œã«ãªã£ãŸã‹ã‚‚ï¼Ÿ<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1309" target="_blank" rel="noopener noreferrer">Mistral 7B, Albert Q. Jiang+, N/A, arXiv'23</a>
</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-08-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2356" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Transformers are RNNs: Fast Autoregressive Transformers with Linear  Attention, Angelos Katharopoulos+, ICML'20</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±æ³¨æ„ã‚’ã‚«ãƒ¼ãƒãƒ«ç‰¹å¾´ãƒãƒƒãƒ—ã®ç·šå½¢ãƒ‰ãƒƒãƒˆç©ã¨ã—ã¦è¡¨ç¾ã™ã‚‹ã“ã¨ã§ã€Transformersã®è¤‡é›‘æ€§ã‚’$\mathcal{O}\left(N^2\right)$ã‹ã‚‰$\mathcal{O}\left(N\right)$ã«å‰Šæ¸›ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è‡ªå·±å›å¸°å‹Transformersã®é€Ÿåº¦ãŒæœ€å¤§4000å€å‘ä¸Šã—ã€å¾“æ¥ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¶­æŒã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1210" target="_blank" rel="noopener noreferrer">Transformers are Multi-State RNNs, Matanel Oren+, N/A, EMNLP'24</a>
 </p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-08-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2355" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reformer: The Efficient Transformer, Nikita Kitaev+, ICLR'20</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã®åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€å±€æ‰€æ„Ÿåº¦ãƒãƒƒã‚·ãƒ¥ã‚’ç”¨ã„ãŸæ³¨æ„æ©Ÿæ§‹ã¨å¯é€†æ®‹å·®å±¤ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¨ˆç®—é‡ã‚’O($L^2$)ã‹ã‚‰O($L\log L$)ã«å‰Šæ¸›ã—ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã¨é€Ÿåº¦ã‚’å‘ä¸Šã•ã›ãŸReformerãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿç¾ã€‚ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¶­æŒã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=rkgNKkHtvB" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=rkgNKkHtvB</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2025-08-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2354" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Linformer: Self-Attention with Linear Complexity, Sinong Wang+, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã¯è‡ªç„¶è¨€èªå‡¦ç†ã§æˆåŠŸã‚’åã‚ã¦ã„ã‚‹ãŒã€é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¯¾ã—ã¦ã¯é«˜ã‚³ã‚¹ãƒˆã€‚è‡ªå·±æ³¨æ„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ã§è¿‘ä¼¼ã—ã€è¤‡é›‘ã•ã‚’$O(n^2)$ã‹ã‚‰$O(n)$ã«å‰Šæ¸›ã™ã‚‹æ–°ã—ã„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¡ãƒ¢ãƒªã¨æ™‚é–“åŠ¹ç‡ãŒå‘ä¸Šã—ãŸç·šå½¢ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã€ŒLinformerã€ãŒæ¨™æº–ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Composition.html" target="_blank" rel="noopener noreferrer">#Composition</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<a class="button" href="articles/CommonsenseReasoning.html" target="_blank" rel="noopener noreferrer">#CommonsenseReasoning</a>
<span class="issue_date">Issue Date: 2025-07-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2330" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CommonGen: A Constrained Text Generation Challenge for Generative   Commonsense Reasoning, Bill Yuchen Lin+, EMNLP'20 Findings</a>
<span class="snippet"><span>GPT Summary</span>- ç”Ÿæˆçš„å¸¸è­˜æ¨è«–ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ãŸã‚ã®ã‚¿ã‚¹ã‚¯CommonGenã‚’ææ¡ˆã—ã€35,000ã®æ¦‚å¿µã‚»ãƒƒãƒˆã«åŸºã¥ã79,000ã®å¸¸è­˜çš„è¨˜è¿°ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã€‚ã‚¿ã‚¹ã‚¯ã¯ã€ä¸ãˆã‚‰ã‚ŒãŸæ¦‚å¿µã‚’ç”¨ã„ã¦ä¸€è²«ã—ãŸæ–‡ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚’æ±‚ã‚ã€é–¢ä¿‚æ¨è«–ã¨æ§‹æˆçš„ä¸€èˆ¬åŒ–èƒ½åŠ›ãŒå¿…è¦ã€‚å®Ÿé¨“ã§ã¯ã€æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã¨äººé–“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å¤§ããªã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€ç”Ÿæˆçš„å¸¸è­˜æ¨è«–èƒ½åŠ›ãŒCommonsenseQAãªã©ã®ä¸‹æµã‚¿ã‚¹ã‚¯ã«è»¢é€å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚‚ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ¦‚è¦ã€‚è¤‡æ•°ã®conceptãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€ãã‚Œã‚‰conceptã‚’åˆ©ç”¨ã—ãŸå¸¸è­˜çš„ãªãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚concepté–“ã®é–¢ä¿‚æ€§ã‚’å¸¸è­˜çš„ãªçŸ¥è­˜ã‹ã‚‰æ¨è«–ã—ã€Unseenãªconceptã®çµ„ã¿åˆã‚ã›ã§ã‚‚æ„å‘³ã‚’æ§‹æˆå¯èƒ½ãªæ±åŒ–æ€§èƒ½ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/2ebb8c0d-88f7-4858-ac43-29f341c586ec" alt="image" loading="lazy"></p>
<p>PJ page:


<a href="https://inklab.usc.edu/CommonGen/" target="_blank" rel="noopener noreferrer">https://inklab.usc.edu/CommonGen/</a>


</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/Faithfulness.html" target="_blank" rel="noopener noreferrer">#Faithfulness</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2203" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On Faithfulness and Factuality in Abstractive Summarization, Joshua Maynez+, ACL'20</a>
<span class="snippet"><span>GPT Summary</span>- æŠ½è±¡çš„ãªæ–‡æ›¸è¦ç´„ã«ãŠã‘ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã®é™ç•Œã‚’åˆ†æã—ã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ãŒå…¥åŠ›æ–‡æ›¸ã«å¯¾ã—ã¦å¿ å®Ÿã§ãªã„å†…å®¹ã‚’ç”Ÿæˆã™ã‚‹å‚¾å‘ãŒé«˜ã„ã“ã¨ã‚’ç™ºè¦‹ã€‚å¤§è¦æ¨¡ãªäººé–“è©•ä¾¡ã‚’é€šã˜ã¦ã€ç”Ÿæˆã•ã‚Œã‚‹å¹»è¦šã®ç¨®é¡ã‚’ç†è§£ã—ã€ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã§ç›¸å½“é‡ã®å¹»è¦šãŒç¢ºèªã•ã‚ŒãŸã€‚äº‹å‰å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ROUGEæŒ‡æ¨™ã ã‘ã§ãªãã€äººé–“è©•ä¾¡ã§ã‚‚å„ªã‚ŒãŸè¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã¾ãŸã€ãƒ†ã‚­ã‚¹ãƒˆã®å«æ„æ¸¬å®šãŒå¿ å®Ÿæ€§ã¨è‰¯å¥½ã«ç›¸é–¢ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ã®æ”¹å–„ã®å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ–‡æ›¸è¦ç´„ã®æ–‡è„ˆã«ãŠã„ã¦ `hallucination` ã«ã¤ã„ã¦èª¬æ˜ã•ã‚Œã¦ã„ã‚‹ã€‚<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1044" target="_blank" rel="noopener noreferrer">[Paper Note] Chain-of-Verification Reduces Hallucination in Large Language Models, Shehzaad Dhuliawala+, N/A, ACL'24</a>
 <br><br>ãŒ `hallucination` ã«ã¤ã„ã¦è¨€åŠã™ã‚‹éš›ã«å¼•ç”¨ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<span class="issue_date">Issue Date: 2025-07-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2142" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On Layer Normalization in the Transformer Architecture, Ruibin Xiong+, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€Transformerã®å­¦ç¿’ç‡ã®ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—æ®µéšã®é‡è¦æ€§ã‚’ç†è«–çš„ã«ç ”ç©¶ã—ã€ãƒ¬ã‚¤ãƒ¤ãƒ¼æ­£è¦åŒ–ã®ä½ç½®ãŒè¨“ç·´ã®å®‰å®šæ€§ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’ç¤ºã™ã€‚ç‰¹ã«ã€Post-LN Transformerã§ã¯å¤§ããªå‹¾é…ãŒä¸å®‰å®šã•ã‚’å¼•ãèµ·ã“ã™ãŸã‚ã€ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ãŒæœ‰åŠ¹ã§ã‚ã‚‹ä¸€æ–¹ã€Pre-LN Transformerã§ã¯å‹¾é…ãŒè‰¯å¥½ã«æŒ¯ã‚‹èˆã†ãŸã‚ã€ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ã‚’çœç•¥ã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ãªã—ã®Pre-LN TransformerãŒãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨åŒç­‰ã®çµæœã‚’é”æˆã—ã€è¨“ç·´æ™‚é–“ã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ãŒå‰Šæ¸›ã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=B1x8anVFPr" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=B1x8anVFPr</a>


</p>
<p>Encoder-Decoderã®Transformerã«ãŠã„ã¦ã€Post-LNã®å ´åˆã¯ã€Warmupã‚’ç„¡ãã™ã¨æœ€çµ‚çš„ãªæ€§èƒ½ãŒæ‚ªåŒ–ã—ã€ã¾ãŸWarmUpã‚¹ãƒ†ãƒƒãƒ—ã®å€¤ã«ã‚ˆã£ã¦ï¼ˆ500 vs. 4000ã§å®Ÿé¨“)ã‚‚æœ€çµ‚çš„ãªæ€§èƒ½ãŒå¤‰åŒ–ã™ã‚‹ã€‚ã“ã‚Œã«ã¯å­¦ç¿’æ™‚ã«ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã—ã£ã‹ã‚Šæ¢ç´¢ã—ãªã‘ã‚Œã°ãªã‚‰ãšã€WarmUPã‚’å¤§ããã™ã‚‹ã¨å­¦ç¿’åŠ¹ç‡ãŒè½ã¡ã‚‹ã¨ã„ã†ãƒ‡ãƒ¡ãƒªãƒƒãƒˆãŒã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/e7a26ecd-7905-4e6c-bb9a-29b8289addb0" alt="image" loading="lazy"><br><br>Post-LNã®å ´åˆã¯ã€Pre-LNã¨æ¯”è¼ƒã—ã¦å‹¾é…ãŒå¤§ããã€Warmupã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã—ã£ã‹ã‚Šè¨­è¨ˆã—ãªã„ã¨å¤§ããªå‹¾é…ã«å¯¾ã—ã¦å¤§ããªå­¦ç¿’ç‡ãŒé©ç”¨ã•ã‚Œå­¦ç¿’ãŒä¸å®‰å®šã«ãªã‚‹ã€‚ã“ã‚Œã¯å­¦ç¿’ç‡ã‚’éå¸¸ã«å°ã•ãã—ã€å›ºå®šå€¤ã‚’ä½¿ã†ã“ã¨ã§è§£æ±ºã§ãã‚‹ãŒã€åæŸãŒéå¸¸ã«é…ããªã‚‹ã¨ã„ã†ãƒ‡ãƒ¡ãƒªãƒƒãƒˆãŒã‚ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/afb09f44-c7c9-44ab-9066-3ee788ebd8ee" alt="image" loading="lazy"><br><br>ä¸€æ–¹ã€Pre-LNã¯Warmupç„¡ã—ã§ã‚‚ã€é«˜ã„æ€§èƒ½ãŒé”æˆã§ãã€ä¸Šè¨˜ã®ã‚ˆã†ãªãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®æ‰‹é–“ã‚„å­¦ç¿’åŠ¹ç‡ã®è¦³ç‚¹ã‹ã‚‰åˆ©ç‚¹ãŒã‚ã‚‹ã€ã¿ãŸã„ãªè©±ã®æ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/d675a58b-e876-4e41-a76f-306c2e1ce23f" alt="image" loading="lazy"><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-05-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2002" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Laws for Autoregressive Generative Modeling, Tom Henighan+, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- ç”Ÿæˆç”»åƒã€ãƒ“ãƒ‡ã‚ªã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€æ•°å­¦çš„å•é¡Œè§£æ±ºã®4é ˜åŸŸã«ãŠã‘ã‚‹ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ç‰¹å®šã€‚è‡ªå·±å›å¸°å‹ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨è¨ˆç®—äºˆç®—ã®å¢—åŠ ã«ä¼´ã„æ€§èƒ½ãŒå‘ä¸Šã—ã€ã¹ãæ³•å‰‡ã«å¾“ã†ã€‚ç‰¹ã«ã€10å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¯YFCC100Mç”»åƒåˆ†å¸ƒã‚’ã»ã¼å®Œç’§ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã•ã‚‰ã«ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ç›¸äº’æƒ…å ±é‡ã‚„æ•°å­¦çš„å•é¡Œè§£æ±ºã«ãŠã‘ã‚‹å¤–æŒ¿æ™‚ã®æ€§èƒ½ã«é–¢ã™ã‚‹è¿½åŠ ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚‚ç™ºè¦‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ãŒãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ€§èƒ½ã«ä¸ãˆã‚‹å½±éŸ¿ãŒå¼·èª¿ã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1960" target="_blank" rel="noopener noreferrer" class="title-link">PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive   Summarization, Jingqing Zhang+, ICML'20</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ¼ãƒ‘ã‚¹ã«å¯¾ã—ã¦æ–°ã—ã„è‡ªå·±æ•™å¸«ã‚ã‚Šã®ç›®çš„ã§ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’äº‹å‰å­¦ç¿’ã—ã€æŠ½è±¡çš„ãªãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«PEGASUSã‚’ææ¡ˆã€‚é‡è¦ãªæ–‡ã‚’å‰Šé™¤ã¾ãŸã¯ãƒã‚¹ã‚¯ã—ã€æ®‹ã‚Šã®æ–‡ã‹ã‚‰è¦ç´„ã‚’ç”Ÿæˆã€‚12ã®ä¸‹æµè¦ç´„ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®ROUGEã‚¹ã‚³ã‚¢ã‚’é”æˆã—ã€é™ã‚‰ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã§ã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã€‚äººé–“è©•ä¾¡ã§ã‚‚è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§äººé–“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«é”ã—ãŸã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>PEGASUSã‚‚ãªã‹ã£ãŸã®ã§è¿½åŠ ã€‚BARTã¨å…±ã«æ–‡æ›¸è¦ç´„ã®Backboneã¨ã—ã¦ä»Šã§ã‚‚ç ”ç©¶ã§åˆ©ç”¨ã•ã‚Œã‚‹æ¨¡æ§˜ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/984" target="_blank" rel="noopener noreferrer">SummEval: Re-evaluating Summarization Evaluation, Fabbri+, TACL'21</a>
</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/TransferLearning.html" target="_blank" rel="noopener noreferrer">#TransferLearning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1955" target="_blank" rel="noopener noreferrer" class="title-link">Exploring the Limits of Transfer Learning with a Unified Text-to-Text  Transformer, Colin Raffel+, JMLR'20</a>
<span class="snippet"><span>GPT Summary</span>- è»¢ç§»å­¦ç¿’ã¯NLPã«ãŠã„ã¦å¼·åŠ›ãªæŠ€è¡“ã§ã‚ã‚Šã€æœ¬è«–æ–‡ã§ã¯ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹çµ±ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚äº‹å‰å­¦ç¿’ã®ç›®çš„ã‚„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¯”è¼ƒã—ã€æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„ãƒ¢ãƒ‡ãƒ«ã€ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã—ã€ä»Šå¾Œã®ç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>T5ã‚‚ãƒ¡ãƒ¢ã£ã¦ã„ãªã‹ã£ãŸã®ã§ä»Šæ›´ãªãŒã‚‰è¿½åŠ ã€‚å…¨ã¦ã®NLPã‚¿ã‚¹ã‚¯ã‚’ãƒ†ã‚­ã‚¹ãƒˆç³»åˆ—ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆç³»åˆ—ã¸å¤‰æ›ã™ã‚‹ã‚¿ã‚¹ã‚¯ã¨ã¿ãªã—ã€Encoder-Decoderã®Transformerã‚’å¤§è¦æ¨¡ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ç”¨ã„ã¦äº‹å‰å­¦ç¿’ã‚’ã—ã€downstreamã‚¿ã‚¹ã‚¯ã«finetuningã‚’é€šã˜ã¦è»¢ç§»ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1934" target="_blank" rel="noopener noreferrer" class="title-link">Editable Neural Networks, Anton Sinitsin+, ICLR'20</a>
<span class="snippet"><span>GPT Summary</span>- æ·±å±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®èª¤ã‚Šã‚’è¿…é€Ÿã«ä¿®æ­£ã™ã‚‹ãŸã‚ã«ã€Editable Trainingã¨ã„ã†ãƒ¢ãƒ‡ãƒ«éä¾å­˜ã®è¨“ç·´æ‰‹æ³•ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç‰¹å®šã®ã‚µãƒ³ãƒ—ãƒ«ã®èª¤ã‚Šã‚’åŠ¹ç‡çš„ã«ä¿®æ­£ã—ã€ä»–ã®ã‚µãƒ³ãƒ—ãƒ«ã¸ã®å½±éŸ¿ã‚’é¿ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚å¤§è¦æ¨¡ãªç”»åƒåˆ†é¡ã¨æ©Ÿæ¢°ç¿»è¨³ã‚¿ã‚¹ã‚¯ã§ãã®æœ‰åŠ¹æ€§ã‚’å®Ÿè¨¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>ï¼ˆãŠãã‚‰ãï¼‰Knowledge Editingã‚’åˆã‚ã¦ææ¡ˆã—ãŸç ”ç©¶</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=HJedXaEtvS" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=HJedXaEtvS</a>


</p></span><br><br>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/AutomaticSpeechRecognition(ASR).html" target="_blank" rel="noopener noreferrer">#AutomaticSpeechRecognition(ASR)</a>
<a class="button" href="articles/AACL.html" target="_blank" rel="noopener noreferrer">#AACL</a>
<a class="button" href="articles/SimulST(SimultaneousSpeechTranslation).html" target="_blank" rel="noopener noreferrer">#SimulST(SimultaneousSpeechTranslation)</a>
<span class="issue_date">Issue Date: 2025-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1915" target="_blank" rel="noopener noreferrer" class="title-link">SimulMT to SimulST: Adapting Simultaneous Text Translation to End-to-End   Simultaneous Speech Translation, Xutai Ma+, AACL'20</a>
<span class="snippet"><span>GPT Summary</span>- åŒæ™‚ãƒ†ã‚­ã‚¹ãƒˆç¿»è¨³æ‰‹æ³•ã‚’ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®åŒæ™‚éŸ³å£°ç¿»è¨³ã«é©å¿œã•ã›ã‚‹ç ”ç©¶ã‚’è¡Œã„ã€äº‹å‰æ±ºå®šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å°å…¥ã€‚ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¨å“è³ªã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’åˆ†æã—ã€æ–°ã—ã„ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’è¨­è¨ˆã€‚</span>
<span class="snippet"><span>Comment</span><p>åŒæ™‚ç¿»è¨³ç ”ç©¶ã§ä¸»è¦ãªmetricã®ä¸€ã¤<br>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1914" target="_blank" rel="noopener noreferrer">Over-Generation Cannot Be Rewarded: Length-Adaptive Average Lagging for   Simultaneous Speech Translation, Sara Papi+, NAACL'22</a>
 </p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1889" target="_blank" rel="noopener noreferrer" class="title-link">The Curious Case of Neural Text Degeneration, Ari Holtzman+, ICLR'20</a>
<span class="snippet"><span>GPT Summary</span>- æ·±å±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ã¯é«˜å“è³ªãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ãŠã„ã¦èª²é¡ŒãŒæ®‹ã‚‹ã€‚å°¤åº¦ã®ä½¿ç”¨ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã€äººé–“ã®ãƒ†ã‚­ã‚¹ãƒˆã¨æ©Ÿæ¢°ã®ãƒ†ã‚­ã‚¹ãƒˆã®é–“ã«åˆ†å¸ƒã®é•ã„ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ãŒç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã®è³ªã«å¤§ããªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ãƒ‹ãƒ¥ãƒ¼ã‚¯ãƒªã‚¢ã‚¹samplingã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¤šæ§˜æ€§ã‚’ä¿ã¡ãªãŒã‚‰ä¿¡é ¼æ€§ã®ä½ã„éƒ¨åˆ†ã‚’æ’é™¤ã—ã€äººé–“ã®ãƒ†ã‚­ã‚¹ãƒˆã«è¿‘ã„è³ªã‚’å®Ÿç¾ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç¾åœ¨ã®LLMã§ä¸»æµãªNucleus (top-p) Samplingã‚’ææ¡ˆã—ãŸç ”ç©¶</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1828" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Laws for Neural Language Models, Jared Kaplan+, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«é–¢ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ç ”ç©¶ã—ã€æå¤±ãŒãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚ºã€è¨ˆç®—é‡ã«å¯¾ã—ã¦å†ªå‰‡çš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è©³ç´°ã¯å½±éŸ¿ãŒå°‘ãªãã€éå­¦ç¿’ã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é€Ÿåº¦ã¯å˜ç´”ãªæ–¹ç¨‹å¼ã§èª¬æ˜ã•ã‚Œã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¨ˆç®—äºˆç®—ã®æœ€é©ãªé…åˆ†ãŒå¯èƒ½ã¨ãªã‚Šã€å¤§ããªãƒ¢ãƒ‡ãƒ«ã¯ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ãŒé«˜ãã€å°‘é‡ã®ãƒ‡ãƒ¼ã‚¿ã§æ—©æœŸã«åæŸã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://www.slideshare.net/slideshow/dlscaling-laws-for-neural-language-models/243005067" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/slideshow/dlscaling-laws-for-neural-language-models/243005067</a>


</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2024-05-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1312" target="_blank" rel="noopener noreferrer" class="title-link">COMET: A Neural Framework for MT Evaluation, Ricardo Rei+, N_A, EMNLP'20</a>
<span class="snippet"><span>GPT Summary</span>- COMETã¯ã€å¤šè¨€èªæ©Ÿæ¢°ç¿»è¨³è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ãŸã‚ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€äººé–“ã®åˆ¤æ–­ã¨ã®æ–°ã—ã„æœ€å…ˆç«¯ã®ç›¸é–¢ãƒ¬ãƒ™ãƒ«ã‚’é”æˆã—ã¾ã™ã€‚ã‚¯ãƒ­ã‚¹ãƒªãƒ³ã‚¬ãƒ«äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®é€²å±•ã‚’æ´»ç”¨ã—ã€é«˜åº¦ã«å¤šè¨€èªå¯¾å¿œã‹ã¤é©å¿œå¯èƒ½ãªMTè©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿç¾ã—ã¾ã™ã€‚WMT 2019 Metrics shared taskã§æ–°ãŸãªæœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€é«˜æ€§èƒ½ã‚·ã‚¹ãƒ†ãƒ ã«å¯¾ã™ã‚‹å …ç‰¢æ€§ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Better/Worseãªhypothesisã‚’åˆ©ç”¨ã—ã¦pair-wiseã«ãƒ©ãƒ³ã‚­ãƒ³ã‚°é–¢æ•°ã‚’å­¦ç¿’ã™ã‚‹<br>![Image](https://github.com/user-attachments/assets/a1fd6f36-48e8-44fc-8fcb-0900a51759b3)<br><br>![Image](https://github.com/user-attachments/assets/19ad7a57-7de3-4255-afde-4a1fde41587d)<br><br>Inferenceæ™‚ã¯å˜ä¸€ã®hypothesisã—ã‹inputã•ã‚Œãªã„ã®ã§ã€sourceã¨referenceã«å¯¾ã—ã¦ãã‚Œãã‚Œhypothesisã®è·é›¢ã‚’ã¯ã‹ã‚Šã€ãã®èª¿å’Œå¹³å‡ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹<br><br>![Image](https://github.com/user-attachments/assets/21642c70-a7fd-4c0e-8678-6125fdbfefce)</p>
<p>ACL2024, EMNLP2024ã‚ãŸã‚Šã®MTç ”ç©¶ã®metricã‚’ã–ãƒ¼ã£ã¨è¦‹ã‚‹é™ã‚Šã€BLEU/COMETã®åŒæ–¹ã§è©•ä¾¡ã™ã‚‹ç ”ç©¶ãŒå¤šãã†</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ActivationFunction.html" target="_blank" rel="noopener noreferrer">#ActivationFunction</a>
<span class="issue_date">Issue Date: 2024-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1311" target="_blank" rel="noopener noreferrer" class="title-link">GLU Variants Improve Transformer, Noam Shazeer, N_A, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- GLUã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’Transformerã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ»ã‚µãƒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ãƒ†ã‚¹ãƒˆã—ã€é€šå¸¸ã®æ´»æ€§åŒ–é–¢æ•°ã‚ˆã‚Šã‚‚ã„ãã¤ã‹ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒå“è³ªå‘ä¸Šã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ã‚’ç™ºè¦‹ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ä¸€èˆ¬çš„ãªFFNã§ã¯ã€linear layerã‚’ã‹ã‘ãŸå¾Œã«ã€ä½•ã‚‰ã‹ã®æ´»æ€§åŒ–é–¢æ•°ã‚’ã‹ã¾ã›ã‚‹æ–¹æ³•ãŒä¸»æµã§ã‚ã‚‹ã€‚<br><br>ã“ã®ã‚ˆã†ãªæ§‹é€ ã®ä¸€ã¤ã¨ã—ã¦GLUãŒã‚ã‚‹ãŒã€linear layerã¨æ´»æ€§åŒ–é–¢æ•°ã«ã¯æ”¹è‰¯ã®ä½™åœ°ãŒã‚ã‚Šã€æ§˜ã€…ãªvariantãŒè€ƒãˆã‚‰ã‚Œã‚‹ãŸã‚ã€è‰²ã€…è©¦ã—ã¾ã—ãŸã€ã¨ã„ã†ã¯ãªã—ã€‚<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/72b1d0bb-64ac-4155-9a3b-5624cd06ccc9" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b38321c6-d414-4764-9147-10a5fa83fbe6" alt="image" loading="lazy"><br><br><br><br>ã‚ªãƒªã‚¸ãƒŠãƒ«ã®GLUã¨æ¯”è¼ƒã—ã¦ã€T5ã¨åŒã˜äº‹å‰å­¦ç¿’ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã—ãŸã¨ã“ã‚ã€perplexityãŒæ”¹å–„<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9e67a054-2148-41ed-aae1-5a752c21a242" alt="image" loading="lazy"><br><br><br><br>ã¾ãŸã€finetuningã‚’ã—ãŸå ´åˆã®æ€§èƒ½ã‚‚ã€å¤šãã®å ´åˆã‚ªãƒªã‚¸ãƒŠãƒ«ã®GLUã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/77ccab88-e5cc-48fc-b9e0-f2dad24e53e8" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8f60ca8c-50eb-4869-bab4-f02ec6d8e085" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8124fc25-aa7e-4e10-8cd2-9d24c818f410" alt="image" loading="lazy"><br><br><br><br><br><br></p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1222" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BLEU might be Guilty but References are not Innocent, Markus Freitag+, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- æ©Ÿæ¢°ç¿»è¨³ã®è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ã®è³ªãŒç–‘å•è¦–ã•ã‚Œã‚‹ä¸­ã€å‚ç…§ã®æ€§è³ªãŒè©•ä¾¡ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’ç ”ç©¶ã€‚ç•°ãªã‚‹å‚ç…§åé›†æ–¹æ³•ã‚’æ¯”è¼ƒã—ã€ç¿»è¨³ã®å¤šæ§˜æ€§ä¸è¶³ã«å¯¾æŠ—ã™ã‚‹ãŸã‚ã«è¨€èªå­¦è€…ã«ã‚ˆã‚‹ãƒ‘ãƒ©ãƒ•ãƒ¬ãƒ¼ã‚ºã‚¿ã‚¹ã‚¯ã‚’é–‹ç™ºã€‚ã“ã‚Œã«ã‚ˆã‚Šã€WMT 2019ã®è‹±ç‹¬ç¿»è¨³ã‚„ãƒãƒƒã‚¯ãƒˆãƒ©ãƒ³ã‚¹ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§äººé–“ã®è©•ä¾¡ã¨ã®ç›¸é–¢ãŒå‘ä¸Šã€‚å¤šå‚ç…§BLEUã®é™ç•Œã‚’æŒ‡æ‘˜ã—ã€ã‚ˆã‚ŠåŠ¹æœçš„ãªè©•ä¾¡æ–¹æ³•ã‚’ææ¡ˆã€‚</span>
<span class="snippet"><span>Comment</span><p>surface levelã®NLGã®æ€§èƒ½æŒ‡æ¨™ãŒsemanticã‚’è©•ä¾¡ã§ããªã„ã“ã¨ã‚’ç¤ºã—ãŸç ”ç©¶</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2023-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1168" target="_blank" rel="noopener noreferrer" class="title-link">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, Patrick Lewis+, N_A, NeurIPS'20</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢å¼·åŒ–ç”Ÿæˆï¼ˆRAGï¼‰ã®å¾®èª¿æ•´æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚RAGãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã¨éãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã‚’çµ„ã¿åˆã‚ã›ãŸè¨€èªç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€å¹…åºƒã„çŸ¥è­˜é›†ç´„çš„ãªè‡ªç„¶è¨€èªå‡¦ç†ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã—ãŸã€‚ç‰¹ã«ã€QAã‚¿ã‚¹ã‚¯ã§ã¯ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã€è¨€èªç”Ÿæˆã‚¿ã‚¹ã‚¯ã§ã¯å…·ä½“çš„ã§å¤šæ§˜ãªè¨€èªã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>RAGã‚’ææ¡ˆã—ãŸç ”ç©¶<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/77d4c13d-c26c-40e1-8429-1a879769587e" alt="image" loading="lazy"><br><br></p>
<p>Retrieverã¨ã—ã¦åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹Dense Passage Retrieval (DPR)ã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3016" target="_blank" rel="noopener noreferrer">[Paper Note] Dense Passage Retrieval for Open-Domain Question Answering, Vladimir Karpukhin+, EMNLP'20, 2020.04</a>
</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/QA-based.html" target="_blank" rel="noopener noreferrer">#QA-based</a>
<span class="issue_date">Issue Date: 2023-08-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1007" target="_blank" rel="noopener noreferrer" class="title-link">Asking and Answering Questions to Evaluate the Factual Consistency of Summaries, Wang, ACL'20</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ã®äº‹å®Ÿã®ä¸æ•´åˆã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã®è‡ªå‹•è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã‚ã‚‹QAGSã‚’ææ¡ˆã™ã‚‹ã€‚QAGSã¯ã€è¦ç´„ã¨ã‚½ãƒ¼ã‚¹ã«ã¤ã„ã¦è³ªå•ã‚’ã—ã€æ•´åˆæ€§ãŒã‚ã‚‹å›ç­”ã‚’å¾—ã‚‹ã“ã¨ã§è¦ç´„ã®äº‹å®Ÿçš„æ•´åˆæ€§ã‚’è©•ä¾¡ã™ã‚‹ã€‚QAGSã¯ä»–ã®è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ã¨æ¯”è¼ƒã—ã¦é«˜ã„ç›¸é–¢ã‚’æŒã¡ã€è‡ªç„¶ãªè§£é‡ˆå¯èƒ½æ€§ã‚’æä¾›ã™ã‚‹ã€‚QAGSã¯æœ‰æœ›ãªãƒ„ãƒ¼ãƒ«ã§ã‚ã‚Šã€https://github.com/W4ngatang/qagsã§åˆ©ç”¨å¯èƒ½ã€‚</span>
<span class="snippet"><span>Comment</span><p>QAGS</p>
<p>ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã‹ã‚‰Questionã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã€‚precision-oriented</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/993" target="_blank" rel="noopener noreferrer" class="title-link">Reducing Quantity Hallucinations in Abstractive Summarization, Zheng Zhao+, N_A, EMNLP'20</a>
<span class="snippet"><span>GPT Summary</span>- Hermanã‚·ã‚¹ãƒ†ãƒ ã¯ã€æŠ½è±¡çš„ãªè¦ç´„ã«ãŠã„ã¦å¹»è¦šã‚’å›é¿ã™ã‚‹ãŸã‚ã«ã€æ•°é‡ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’èªè­˜ã—ã€å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹æ•°é‡ç”¨èªã‚’æŒã¤è¦ç´„ã‚’ä¸Šä½ã«ãƒ©ãƒ³ã‚¯ä»˜ã‘ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒé«˜ã„é©åˆç‡ã¨å†ç¾ç‡ã‚’æŒã¡ã€F$_1$ã‚¹ã‚³ã‚¢ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ä¸Šä½ã«ãƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚ŒãŸè¦ç´„ãŒå…ƒã®è¦ç´„ã‚ˆã‚Šã‚‚å¥½ã¾ã‚Œã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ•°é‡ã«é–¢ã™ã‚‹hallucinationã‚’ç·©å’Œã™ã‚‹è¦ç´„æ‰‹æ³•</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/QA-based.html" target="_blank" rel="noopener noreferrer">#QA-based</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/991" target="_blank" rel="noopener noreferrer" class="title-link">FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization, Durmus+, ACL'20</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æŠ½è±¡çš„è¦ç´„ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼æ€§ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€äººé–“ã®æ³¨é‡ˆã‚’åé›†ã—ã€ä¿¡é ¼æ€§ã®è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ã§ã‚ã‚‹FEQAã‚’ææ¡ˆã—ãŸã€‚FEQAã¯è³ªå•å¿œç­”ã‚’åˆ©ç”¨ã—ã¦è¦ç´„ã®ä¿¡é ¼æ€§ã‚’è©•ä¾¡ã—ã€ç‰¹ã«æŠ½è±¡çš„ãªè¦ç´„ã«ãŠã„ã¦äººé–“ã®è©•ä¾¡ã¨é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>FEQA</p>
<p>ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã‹ã‚‰Questionã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã€‚precision-oriented </p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/982" target="_blank" rel="noopener noreferrer" class="title-link">HOLMS: Alternative Summary Evaluation with Large Language Models, Mrabet+, COLING'20</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„æ‰‹æ³•ã®è©•ä¾¡å°ºåº¦ã¨ã—ã¦ã€ROUGEã¨BLEUãŒä¸€èˆ¬çš„ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãŒã€ã“ã‚Œã‚‰ã¯èªå½™çš„ãªæ€§è³ªã‚’æŒã¡ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯é™å®šçš„ãªå¯èƒ½æ€§ãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡ãªã‚³ãƒ¼ãƒ‘ã‚¹ã§äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã¨èªå½™çš„é¡ä¼¼åº¦å°ºåº¦ã‚’çµ„ã¿åˆã‚ã›ãŸæ–°ã—ã„è©•ä¾¡å°ºåº¦ã§ã‚ã‚‹HOLMSã‚’ææ¡ˆã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€HOLMSãŒROUGEã¨BLEUã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€äººé–“ã®åˆ¤æ–­ã¨ã®ç›¸é–¢ã‚‚é«˜ã„ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Hybrid Lexical and MOdel-based evaluation of Summaries (HOLMS)</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/977" target="_blank" rel="noopener noreferrer" class="title-link">Unsupervised Reference-Free Summary Quality Evaluation via Contrastive  Learning, Hanlu Wu+, N_A, EMNLP'20</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å‚ç…§è¦ç´„ãªã—ã§è¦ç´„ã®å“è³ªã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«æ•™å¸«ãªã—ã®å¯¾ç…§çš„å­¦ç¿’ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚æ–°ã—ã„ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’è¨­è¨ˆã—ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°æå¤±ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ã“ã¨ã§ã€è¦ç´„å“è³ªã®ç•°ãªã‚‹å´é¢ã«é–¢ã™ã‚‹ç•°ãªã‚‹ã‚¿ã‚¤ãƒ—ã®ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒ«ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€å‚ç…§è¦ç´„ãªã—ã§ã‚‚ä»–ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸè©•ä¾¡æ–¹æ³•ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€ææ¡ˆæ‰‹æ³•ãŒä¸€èˆ¬çš„ã‹ã¤è»¢ç§»å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LS_Score</p>
<p>è‰²ã€…ãªãƒ¡ãƒˆãƒªãƒƒã‚¯ãŒç°¡æ½”ã«ã¾ã¨ã¾ã£ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LM-based.html" target="_blank" rel="noopener noreferrer">#LM-based</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/963" target="_blank" rel="noopener noreferrer" class="title-link">Evaluating the Factual Consistency of Abstractive Text Summarization, Kryscinski+, EMNLP'20</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¦ç´„ã®äº‹å®Ÿçš„ãªæ•´åˆæ€§ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®å¤‰æ›ã‚’ç”¨ã„ã¦ç”Ÿæˆã•ã‚Œã€ãƒ¢ãƒ‡ãƒ«ã¯æ•´åˆæ€§ã®äºˆæ¸¬ã¨ã‚¹ãƒ‘ãƒ³æŠ½å‡ºã®ã‚¿ã‚¹ã‚¯ã§å…±åŒã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹è¦ç´„ã«å¯¾ã—ã¦è»¢ç§»å­¦ç¿’ã‚’è¡Œã†ã“ã¨ã§ã€ä»¥å‰ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€äººé–“ã®è©•ä¾¡ã§ã‚‚è£œåŠ©çš„ãªã‚¹ãƒ‘ãƒ³æŠ½å‡ºã‚¿ã‚¹ã‚¯ãŒæœ‰ç”¨ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„ã‚³ãƒ¼ãƒ‰ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>FactCC</p>
<p>è¿‘å¹´ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¢ãƒ‡ãƒ«ã¯æµã¡ã‚‡ã†ãªè¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ãŒã€ãã‚Œã‚‰ã«ã¯ã€unsuportedãªinformationãŒå¤šãå«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸ</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/LM-based.html" target="_blank" rel="noopener noreferrer">#LM-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/959" target="_blank" rel="noopener noreferrer" class="title-link">Automatic Machine Translation Evaluation in Many Languages via Zero-Shot Paraphrasing, Thompson+, EMNLP'20</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‘ãƒ©ãƒ•ãƒ¬ãƒ¼ã‚¶ã‚’ä½¿ç”¨ã—ã¦æ©Ÿæ¢°ç¿»è¨³ã®è©•ä¾¡ã‚’è¡Œã†ã‚¿ã‚¹ã‚¯ã‚’å®šç¾©ã—ã€å¤šè¨€èªNMTã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ãƒ‘ãƒ©ãƒ•ãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã‚’è¡Œã„ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ç›´æ„Ÿçš„ã§ã‚ã‚Šã€äººé–“ã®åˆ¤æ–­ã‚’å¿…è¦ã¨ã—ã¾ã›ã‚“ã€‚39è¨€èªã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸå˜ä¸€ãƒ¢ãƒ‡ãƒ«ã¯ã€ä»¥å‰ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨æ¯”è¼ƒã—ã¦å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€å“è³ªæ¨å®šã®ã‚¿ã‚¹ã‚¯ã§ã‚‚å„ªã‚ŒãŸçµæœã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>PRISM</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/950" target="_blank" rel="noopener noreferrer" class="title-link">Fill in the BLANC: Human-free quality estimation of document summaries, Vasilyev+, Eval4NLP'20</a>
<span class="snippet"><span>GPT Summary</span>- BLANCã¯ã€è¦ç´„ã®å“è³ªã‚’è‡ªå‹•çš„ã«æ¨å®šã™ã‚‹ãŸã‚ã®æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã™ã€‚BLANCã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è¦ç´„ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã€è¦ç´„ã®æ©Ÿèƒ½çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¸¬å®šã—ã¾ã™ã€‚BLANCã‚¹ã‚³ã‚¢ã¯ã€ROUGEã¨åŒæ§˜ã«äººé–“ã®è©•ä¾¡ã¨è‰¯å¥½ãªç›¸é–¢é–¢ä¿‚ã‚’æŒã¡ã€äººé–“ã«ã‚ˆã£ã¦æ›¸ã‹ã‚ŒãŸå‚ç…§è¦ç´„ãŒä¸è¦ãªãŸã‚ã€å®Œå…¨ã«äººé–“ä¸åœ¨ã®è¦ç´„å“è³ªæ¨å®šãŒå¯èƒ½ã§ã™ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/Training-Free.html" target="_blank" rel="noopener noreferrer">#Training-Free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/945" target="_blank" rel="noopener noreferrer" class="title-link">SUPERT: Towards New Frontiers in Unsupervised Evaluation Metrics for Multi-Document Summarization, Gao+, ACL'20</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®ç ”ç©¶ã§ã¯ã€æ•™å¸«ãªã—ã®è¤‡æ•°æ–‡æ›¸è¦ç´„è©•ä¾¡ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚¹ã«ã¤ã„ã¦èª¿æŸ»ã—ã¦ã„ã¾ã™ã€‚ææ¡ˆæ‰‹æ³•SUPERTã¯ã€æ“¬ä¼¼çš„ãªå‚ç…§è¦ç´„ã¨ã—ã¦é¸æŠã•ã‚ŒãŸé‡è¦ãªæ–‡ã‚’ä½¿ç”¨ã—ã€æ–‡è„ˆåŒ–åŸ‹ã‚è¾¼ã¿ã¨ã‚½ãƒ•ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆæŠ€è¡“ã‚’ç”¨ã„ã¦è¦ç´„ã®å“è³ªã‚’è©•ä¾¡ã—ã¾ã™ã€‚SUPERTã¯å¾“æ¥ã®æ•™å¸«ãªã—è©•ä¾¡ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚¹ã‚ˆã‚Šã‚‚äººé–“ã®è©•ä¾¡ã¨ã®ç›¸é–¢ãŒé«˜ãã€18ã€œ39ï¼…ã®å‘ä¸ŠãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚ã¾ãŸã€SUPERTã‚’å ±é…¬ã¨ã—ã¦ä½¿ç”¨ã—ã¦ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ™ãƒ¼ã‚¹ã®å¼·åŒ–å­¦ç¿’è¦ç´„å™¨ã‚’ã‚¬ã‚¤ãƒ‰ã™ã‚‹ã“ã¨ã§ã€æœ‰åˆ©ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¥æ‰‹å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>pseudo-reference summaryã‚’ä½œæˆã—ã€referenceã«å¯¾ã—ã¦SBERTã‚’é©ç”¨ã—system-referenceé–“ã®é¡ä¼¼åº¦ã‚’æ¸¬ã‚‹ã“ã¨ã§ã€unsupervisedã«è¤‡æ•°æ–‡æ›¸è¦ç´„ã‚’è©•ä¾¡ã™ã‚‹æ‰‹æ³•ã€‚<br><br>ã¾ãšTACã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã€æ—¢å­˜ç ”ç©¶ï¼ˆsingle document summarizationã®è©•ä¾¡ç”¨ã«ææ¡ˆã•ã‚ŒãŸæ‰‹æ³•ï¼‰ã‚’é©ç”¨ã—ã€Human Ratingsã¨ã®ç›¸é–¢ãŒä½ã„ã“ã¨ã‚’ç¢ºèªã—ã¦ã„ã‚‹ã€‚ã“ã®æ™‚ã€Referenceã‚’ç”¨ã„ã‚‹æ‰‹æ³•ï¼ˆROUGEã€MoverScoreï¼‰ã®ç›¸é–¢ã‚’Upper Boundã¨ã—ã€Upper Boundã«åŠã°ãªã„ã“ã¨ã‚’ç¢ºèªã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€æ—¢å­˜ç ”ç©¶ã‚ˆã‚Šã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªJS Divergenceç­‰ã‚’ç”¨ã„ã‚‹lexical basedãªæ‰‹æ³•ã®ç›¸é–¢ãŒé«˜ã‹ã£ãŸã“ã¨ã‚‚ç¢ºèªã—ã¦ã„ã‚‹ã€‚<br>ç¶šã„ã¦ã€unsupervisedãªæ‰‹æ³•ã¨ã—ã¦ã€contextualãªembeddingã‚’åˆ©ç”¨ã—ï¼ˆBERT, SBERTç­‰ï¼‰source, system summaryé–“ã®é¡ä¼¼åº¦ã‚’æ¸¬ã‚‹æ‰‹æ³•ã§ç›¸é–¢ã‚’æ¸¬ã£ãŸã¨ã“ã‚ã€ã“ã¡ã‚‰ã§ã‚‚Upper Boundã«åŠã°ãªã„ã“ã¨ã€ã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ³•ã«åŠã°ãªã„ã“ã¨ã‚’ç¢ºèªã€‚ã“ã‚Œã‚‰æ‰‹æ³•ã«WMDã‚’å¿œç”¨ã™ã‚‹ã™ã‚‹ã“ã¨ã§ç›¸é–¢ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ãŸã€‚<br>ã“ã‚Œã‚‰ã®ã“ã¨ã‚ˆã‚Šã€ReferenceãŒã‚ã‚‹å ´åˆã€ç„¡ã„å ´åˆã®ä¸¡è€…ã«ãŠã„ã¦WMDã‚’ç”¨ã„ã‚‹æ‰‹æ³•ãŒæœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ãŒç¢ºèªã§ããŸãŒã€Referenceã®æœ‰ç„¡ã«ã‚ˆã£ã¦ç›¸é–¢ã«å¤§ããªå·®ãŒç”Ÿã¾ã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã§ããŸã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€ä½•ã‚‰ã‹ã®å½¢ã§ReferenceãŒå¿…è¦ã§ã‚ã‚Šã€pseudo referenceã‚’ç”Ÿæˆã—åˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’ç€æƒ³ã—ãŸã€ã¨ã„ã†ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã«ãªã£ã¦ã„ã‚‹ã€‚</p>
<p>pseudo referenceã‚’ç”Ÿæˆã™ã‚‹æ–¹æ³•ã¨ã—ã¦ã€top Nã®ãƒªãƒ¼ãƒ‰æ–‡ã‚’æŠ½å‡ºã™ã‚‹æ‰‹æ³•ã‚„ã€LexRankã®ã‚ˆã†ãªGraphBasedãªæ‰‹æ³•ã‚’åˆ©ç”¨ã—ã¦TACãƒ‡ãƒ¼ã‚¿ã«ãŠã„ã¦ã©ã®ã‚ˆã†ãªæ‰‹æ³•ãŒè‰¯ã„ã‹ã‚’æ¤œè¨¼ã—ã¦ã„ã‚‹ã€‚ã“ã®çµæœã€TAC8,9ã®å ´åˆã¯Top 10,15ã®sentenceã‚’pseudo referenceã¨ã—ãŸå ´åˆãŒæœ€ã‚‚è‰¯ã‹ã£ãŸã€‚<br><br>ç´°ã‹ã„ã¨ã“ã‚ã¾ã§èª­ã¿ãã‚Œã¦ã„ãªã„ãŒã€è‡ªèº«ãŒè¦ç´„ã—ãŸã„æ–‡æ›¸ç¾¤ã«ãŠã„ã¦ã©ã®æ–¹æ³•ã§pseudo referenceã‚’ç”Ÿæˆã™ã‚‹ã‹ã¯ã€ReferenceãŒãªã„ã¨åˆ¤æ–­ã§ããªã„ã¨è€ƒãˆã‚‰ã‚Œã‚‹ãŸã‚ã€ãã®ç‚¹ã¯èª²é¡Œã ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<a class="button" href="articles/TrainedMetrics.html" target="_blank" rel="noopener noreferrer">#TrainedMetrics</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/944" target="_blank" rel="noopener noreferrer" class="title-link">BLEURT: Learning Robust Metrics for Text Generation, Sellam+, ACL'20</a>
<span class="snippet"><span>GPT Summary</span>- BLEURTã¯ã€BERTã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸå­¦ç¿’æ¸ˆã¿ã®è©•ä¾¡æŒ‡æ¨™ã§ã‚ã‚Šã€äººé–“ã®åˆ¤æ–­ã¨é«˜ã„ç›¸é–¢ã‚’æŒã¤ã“ã¨ãŒç‰¹å¾´ã§ã™ã€‚BLEURTã¯ã€æ•°åƒã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã‚’ä½¿ç”¨ã—ã¦ãƒã‚¤ã‚¢ã‚¹ã®ã‚ã‚‹è©•ä¾¡ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€æ•°ç™¾ä¸‡ã®åˆæˆä¾‹ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–ã‚’æ”¯æ´ã—ã¾ã™ã€‚BLEURTã¯ã€WMT Metricså…±æœ‰ã‚¿ã‚¹ã‚¯ã¨WebNLGãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æœ€å…ˆç«¯ã®çµæœã‚’æä¾›ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„å ´åˆã‚„åˆ†å¸ƒå¤–ã®å ´åˆã§ã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/668" target="_blank" rel="noopener noreferrer" class="title-link">BERTScore: Evaluating Text Generation with BERT, Tianyi Zhang+, N_A, ICLR'20</a>
<span class="snippet"><span>GPT Summary</span>- BERTScoreã¯ã€æ–‡è„ˆåŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®è‡ªå‹•è©•ä¾¡ãƒ¡ãƒˆãƒªãƒƒã‚¯ã§ã‚ã‚Šã€363ã®æ©Ÿæ¢°ç¿»è¨³ãŠã‚ˆã³ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®å‡ºåŠ›ã‚’ä½¿ç”¨ã—ã¦è©•ä¾¡ã•ã‚Œã¾ã—ãŸã€‚BERTScoreã¯ã€æ—¢å­˜ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚ˆã‚Šã‚‚äººé–“ã®åˆ¤æ–­ã¨ã®ç›¸é–¢ãŒé«˜ãã€ã‚ˆã‚Šå¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«é¸æŠæ€§èƒ½ã‚’æä¾›ã—ã€æ•µå¯¾çš„ãªè¨€ã„æ›ãˆæ¤œå‡ºã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã‚‚ã‚ˆã‚Šå …ç‰¢ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>
<strong># æ¦‚è¦<br>æ—¢å­˜ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®è©•ä¾¡æ‰‹æ³•ï¼ˆBLEUã‚„METEORï¼‰ã¯surface levelã®ãƒãƒƒãƒãƒ³ã‚°ã—ã‹ã—ã¦ãŠã‚‰ãšã€æ„å‘³ã‚’ã¨ã‚‰ãˆã‚‰ã‚ŒãŸè©•ä¾¡ã«ãªã£ã¦ã„ãªã‹ã£ãŸã®ã§ã€pretrained BERTã®embeddingã‚’ç”¨ã„ã¦similarityã‚’æ¸¬ã‚‹ã‚ˆã†ãªæŒ‡æ¨™ã‚’ææ¡ˆã—ã¾ã—ãŸã‚ˆã€ã¨ã„ã†è©±ã€‚<br><br># prior metrics<br>## n-gram matching approaches<br>n-gramãŒreferenceã¨candidateã§ã©ã‚Œã ã‘é‡è¤‡ã—ã¦ã„ã‚‹ã‹ã§Precisionã¨recallã‚’æ¸¬å®š<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a620d564-72e3-4078-97e2-1ff62b333324" alt="image" loading="lazy"><br><br>### BLEU<br>MTã§æœ€ã‚‚åˆ©ç”¨ã•ã‚Œã‚‹ã€‚n-gramã®Precisionï¼ˆå…¸å‹çš„ã«ã¯n=1,2,3,4ï¼‰ã¨çŸ­ã™ãã‚‹å€™è£œè¨³ã«ã¯ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’ä¸ãˆã‚‹ï¼ˆbrevity penaltyï¼‰ã“ã¨ã§å®Ÿç¾ã•ã‚Œã‚‹æŒ‡æ¨™ã€‚SENT-BLEUã¨ã„ã£ãŸäºœç¨®ã‚‚ã‚ã‚‹ã€‚BLEUã¨æ¯”è¼ƒã—ã¦ã€BERTScoreã¯ã€n-gramã®é•·ã•ã®åˆ¶ç´„ã‚’å—ã‘ãšã€æ½œåœ¨çš„ã«ã¯é•·ã•ã®åˆ¶é™ãŒãªã„dependencyã‚’contextualized embeddingsã§ã¨ã‚‰ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br>### METEOR<br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/669" target="_blank" rel="noopener noreferrer">METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments, Banerjee+, CMU, ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</a>
</strong>
<br>
 METEOR 1.5ã§ã¯ã€å†…å®¹èªã¨æ©Ÿèƒ½èªã«ç•°ãªã‚‹weightã‚’å‰²ã‚Šå½“ã¦ã€ãƒãƒƒãƒãƒ³ã‚°ã‚¿ã‚¤ãƒ—ã«ã‚ˆã£ã¦ã‚‚weightã‚’å¤‰æ›´ã™ã‚‹ã€‚METEOR++2.0ã§ã¯ã€å­¦ç¿’æ¸ˆã¿ã®å¤–éƒ¨ã®paraphrase resourceã‚’æ´»ç”¨ã™ã‚‹ã€‚METEORã¯å¤–éƒ¨ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å¿…è¦ã¨ã™ã‚‹ãŸã‚ã€ãŸã£ãŸ5ã¤ã®è¨€èªã§ã—ã‹full feature setã§ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ã€‚11ã®è¨€èªã§ã¯ã€æ¥éƒ¨ã®featureãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã€‚METEORã¨åŒæ§˜ã«ã€BERTScoreã§ã‚‚ã€ãƒãƒƒãƒã«ç·©å’Œã‚’å…¥ã‚Œã¦ã„ã‚‹ã“ã¨ã«ç›¸å½“ã™ã‚‹ãŒã€BERTã®äº‹å‰å­¦ç¿’æ¸ˆã¿ã®embeddingã¯104ã®è¨€èªã§å–å¾—å¯èƒ½ã§ã‚ã‚‹ã€‚BERTScoreã¯ã¾ãŸã€é‡è¦åº¦ã«ã‚ˆã‚‹weightingã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ï¼ˆã‚³ãƒ¼ãƒ‘ã‚¹ã®çµ±è¨ˆé‡ã§æ¨å®šï¼‰ã€‚<br><br>### Other Related Metrics<br>- NIST: BLEUã¨ã¯ç•°ãªã‚‹n-gramã®é‡ã¿ã¥ã‘ã¨ã€brevity penaltyã‚’åˆ©ç”¨ã™ã‚‹<br>- Î”BLEU: multi-reference BLEUã‚’ã€äººæ‰‹ã§ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸnegative reference sentenceã§å¤‰æ›´ã™ã‚‹<br>- CHRF: æ–‡å­—n-gramã‚’æ¯”è¼ƒã™ã‚‹<br>- CHRF++: CHRFã‚’word-bigram matchingã«æ‹¡å¼µã—ãŸã‚‚ã®<br>- ROUGE: æ–‡æ›¸è¦ç´„ã§åˆ©ç”¨ã•ã‚Œã‚‹æŒ‡æ¨™ã€‚ROUGE-N, ROUGE^Lã¨ã„ã£ãŸæ§˜ã€…ãªå¤‰ç¨®ãŒã‚ã‚‹ã€‚<br>- CIDEr: image captioningã®metricã§ã‚ã‚Šã€n-gramã®tf-idfã§é‡ã¿ã¥ã‘ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ã®cosine similrityã‚’æ¸¬å®šã™ã‚‹<br><br>## Edit-distance based Metrics<br>- Word Error Rate (WER): candidateã‹ã‚‰referenceã‚’å†ç¾ã™ã‚‹ã¾ã§ã«å¿…è¦ãªedit operationã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹æ‰‹æ³•<br>- Translation Edit Rate (TER): referenceã®å˜èªæ•°ã«ã‚ˆã£ã¦candidateã‹ã‚‰referenceã¾ã§ã®edit distanceã‚’æ­£è¦åŒ–ã™ã‚‹æ‰‹æ³•<br>- ITER: èªå¹¹ã®ãƒãƒƒãƒã¨ã€ã‚ˆã‚Šè‰¯ã„æ­£è¦åŒ–ã«åŸºã¥ãæ‰‹æ³•<br>- PER: positionã¨ã¯ç‹¬ç«‹ã—ãŸError Rateã‚’ç®—å‡º<br>- CDER: edit operationã«ãŠã‘ã‚‹block reorderingã‚’ãƒ¢ãƒ‡ãƒ«åŒ–<br>- CHARACTER / EED: character levelã§è©•ä¾¡<br><br>## Embedding-based Metrics<br>- MEANT 2.0: lexical, structuralã®é¡ä¼¼åº¦ã‚’æ¸¬ã‚‹ãŸã‚ã«ã€word embeddingã¨shallow semantic parsesã‚’åˆ©ç”¨<br>- YISI-1: MEANT 2.0ã¨åŒæ§˜ã ãŒã€semantic parseã®åˆ©ç”¨ãŒoptionalã¨ãªã£ã¦ã„ã‚‹<br>ã“ã‚Œã‚‰ã¯BERTScoreã¨åŒæ§˜ã®ã€similarityã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«æ¸¬ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€BERTScoreã‚‚ã“ã‚Œã«inspireã•ã‚Œã¦ã„ã‚‹ã€‚ãŒã€BERTScoreã¯Contextualized Embeddingã‚’åˆ©ç”¨ã™ã‚‹ç‚¹ãŒç•°ãªã‚‹ã€‚ã¾ãŸã€linguistic structureã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ãªå¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã¯åˆ©ç”¨ã—ãªã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€BERTScoreã‚’ã‚·ãƒ³ãƒ—ãƒ«ã§ã€æ–°ãŸãªlanguageã«å¯¾ã—ã¦ã‚‚ä½¿ã„ã‚„ã™ãã—ã¦ã„ã‚‹ã€‚greedy matchingã®ä»£ã‚ã‚Šã«ã€WMD, WMDo, SMSã¯earth mover's distanceã«åŸºã¥ãæœ€é©ãªãƒãƒƒãƒãƒ³ã‚°ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚greedy matchingã¨optimal matchingã®tradeoffã«ã¤ã„ã¦ã¯ç ”ç©¶ã•ã‚Œã¦ã„ã‚‹ã€‚sentence-levelã®similarityã‚’è¨ˆç®—ã™ã‚‹æ‰‹æ³•ã‚‚ææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã‚Œã‚‰ã¨æ¯”è¼ƒã—ã¦ã€BERTScoreã®token-levelã®è¨ˆç®—ã¯ã€é‡è¦åº¦ã«å¿œã˜ã¦ã€tokenã«å¯¾ã—ã¦ç•°ãªã‚‹é‡ã¿ã¥ã‘ã‚’ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br>## Learned Metrics<br>æ§˜ã€…ãªmetricãŒã€human judgmentsã¨ã®correlationã«æœ€é©åŒ–ã™ã‚‹ãŸã‚ã«è¨“ç·´ã•ã‚Œã¦ããŸã€‚<br>- BEER: character-ngram, word bigramã«åŸºã¥ã„ãŸregresison modelã‚’åˆ©ç”¨<br>- BLEND: 29ã®æ—¢å­˜ã®metricã‚’åˆ©ç”¨ã—ã¦regressionã‚’å®Ÿæ–½<br>- RUSE: 3ç¨®é¡ã®pre-trained sentence embedding modelã‚’åˆ©ç”¨ã™ã‚‹æ‰‹æ³•<br>ã“ã‚Œã‚‰ã™ã¹ã¦ã®æ‰‹æ³•ã¯ã€ã‚³ã‚¹ãƒˆã®ã‹ã‹ã‚‹human judgmentsã«ã‚ˆã‚‹supervisionãŒå¿…è¦ã¨ãªã‚‹ã€‚ãã—ã¦ã€æ–°ãŸãªãƒ‰ãƒ¡ã‚¤ãƒ³ã«ãŠã‘ã‚‹æ±åŒ–èƒ½åŠ›ã®ä½ã•ã®ãƒªã‚¹ã‚¯ãŒã‚ã‚‹ã€‚input textãŒäººé–“ãŒç”Ÿæˆã—ãŸã‚‚ã®ã‹å¦ã‹äºˆæ¸¬ã™ã‚‹neural modelã‚’è¨“ç·´ã™ã‚‹æ‰‹æ³•ã‚‚ã‚ã‚‹ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æœ€é©åŒ–ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€æ–°ãŸãªãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æ±åŒ–ã•ã‚Œãªã„ãƒªã‚¹ã‚¯ã‚’æŒã£ã¦ã„ã‚‹ã€‚ã“ã‚Œã‚‰ã¨æ¯”è¼ƒã—ã¦ã€BERTScoreã¯ç‰¹å®šã®evaluation taskã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„ã€‚<br><br># BERTScore<br>referenceã¨candidateã®ãƒˆãƒ¼ã‚¯ãƒ³é–“ã®similarityã®æœ€å¤§å€¤ã‚’ã¨ã‚Šã€ãã‚Œã‚‰ã‚’é›†ç´„ã™ã‚‹ã“ã¨ã§ã€Precision, Recallã‚’å®šç¾©ã—ã€Precisionã¨Recallã‚’åˆ©ç”¨ã—ã¦Få€¤ã‚‚è¨ˆç®—ã™ã‚‹ã€‚Recallã¯ã€referenceä¸­ã®ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾ã—ã¦ã€candidateä¸­ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã®cosine similarityã®æœ€å¤§å€¤ã‚’æ¸¬ã‚‹ã€‚ä¸€æ–¹ã€Precisionã¯ã€candidateä¸­ã®ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾ã—ã¦ã€referenceä¸­ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã®cosine similarityã®æœ€å¤§å€¤ã‚’æ¸¬ã‚‹ã€‚ã“ã“ã§ã€é¡ä¼¼åº¦ã®å¼ãŒå˜ãªã‚‹å†…ç©ã«ãªã£ã¦ã„ã‚‹ãŒã€ã“ã‚Œã¯pre-normalized vectorã‚’åˆ©ç”¨ã™ã‚‹å‰æã§ã‚ã‚Šã€æ­£è¦åŒ–ãŒå¿…è¦ãªã„ã‹ã‚‰ã§ã‚ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9ed88ea6-8ecf-465c-81d5-bc85592ad7ff" alt="image" loading="lazy"><br><br>ã¾ãŸã€IDFã«ã‚ˆã‚‹ãƒˆãƒ¼ã‚¯ãƒ³å˜ä½ã§ã®weightingã‚’å®Ÿæ–½ã™ã‚‹ã€‚IDFã¯ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®å€¤ã‚’åˆ©ç”¨ã™ã‚‹ã€‚TFã‚’ä½¿ã‚ãªã„ç†ç”±ã¯ã€BERTScoreã¯sentenceåŒå£«ã‚’æ¯”è¼ƒã™ã‚‹æŒ‡æ¨™ã§ã‚ã‚‹ãŸã‚ã€TFã¯åŸºæœ¬çš„ã«1ã¨ãªã‚Šã‚„ã™ã„å‚¾å‘ã«ã‚ã‚‹ãŸã‚ã§ã‚ã‚‹ã€‚IDFã‚’è¨ˆç®—ã™ã‚‹éš›ã¯å‡ºç¾æ•°ã‚’+1ã™ã‚‹ã“ã¨ã«ã‚ˆã‚‹ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã‚’å®Ÿæ–½ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d4b132fb-7830-4a00-b845-11f38b909bba" alt="image" loading="lazy"><br><br>ã•ã‚‰ã«ã€ã“ã‚Œã¯BERTScoreã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°èƒ½åŠ›ã«ã¯å½±éŸ¿ã‚’ä¸ãˆãªã„ãŒã€BERTScoreã®å€¤ã¯ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã«åŸºã¥ã„ã¦ã„ã‚‹ãŸã‚ã€[-1, 1]ã¨ãªã‚‹ãŒã€å®Ÿéš›ã¯å­¦ç¿’ã—ãŸcontextual embeddingã®geometryã«å€¤åŸŸãŒä¾å­˜ã™ã‚‹ãŸã‚ã€ã‚‚ã£ã¨å°ã•ãªãƒ¬ãƒ³ã‚¸ã§ã®å€¤ã‚’ã¨ã‚‹ã“ã¨ã«ãªã£ã¦ã—ã¾ã†ã€‚ãã†ã™ã‚‹ã¨ã€äººé–“ã«ã‚ˆã‚‹è§£é‡ˆãŒé›£ã—ããªã‚‹ï¼ˆãŸã¨ãˆã°ã€æ¥µç«¯ãªè©±ã€ã‚¹ã‚³ã‚¢ã®0.1ç¨‹åº¦ã®å¤‰åŒ–ãŒã‚ã¡ã‚ƒã‚ã¡ã‚ƒå¤§ããªå¤‰åŒ–ã«ãªã£ã¦ã—ã¾ã†ãªã©ï¼‰ãŸã‚ã€rescalingã‚’å®Ÿæ–½ã€‚rescalingã™ã‚‹éš›ã¯ã€monolingualã‚³ãƒ¼ãƒ‘ã‚¹ã‹ã‚‰ã€ãƒ©ãƒ³ãƒ€ãƒ ã«sentenceã®ãƒšã‚¢ã‚’ä½œæˆã—ï¼ˆBETRScoreãŒéå¸¸ã«å°ã•ããªã‚‹ã‚±ãƒ¼ã‚¹ï¼‰ã€ã“ã‚Œã‚‰ã®BERTScoreã‚’å¹³å‡ã™ã‚‹ã“ã¨ã§bã‚’ç®—å‡ºã—ã€bã‚’åˆ©ç”¨ã—ã¦rescalingã—ãŸã€‚å…¸å‹çš„ã«ã¯ã€rescalingå¾Œã¯å…¸å‹çš„ã«ã¯[0, 1]ã®ç¯„å›²ã§BERTScoreã¯å€¤ã‚’ã¨ã‚‹ï¼ˆãŸã ã—æ•°å¼ã‚’è¦‹ã¦ã‚ã‹ã‚‹é€šã‚Š[0, 1]ã¨ãªã‚‹ã“ã¨ãŒä¿è¨¼ã•ã‚Œã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ç‚¹ã«æ³¨æ„ï¼‰ã€‚ã“ã‚Œã¯human judgmentsã¨ã®correlationã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆãªã„ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ã‚’å¤‰ãˆã¦ã„ã‚‹ã ã‘ãªã®ã§ï¼‰ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9049ed99-d192-465d-b4fe-d628bc673927" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/bb78074e-2fa4-4bb3-a920-df543aeb98b8" alt="image" loading="lazy"><br></p>
<p># å®Ÿé¨“<br><br>## Contextual Embedding Models<br><br>12ç¨®é¡ã®ãƒ¢ãƒ‡ãƒ«ã§æ¤œè¨¼ã€‚BERT, RoBERTa, XLNet, XLMãªã©ã€‚<br><br><br><br>## Machine Translation<br><br>WMT18ã®metric evaluation datasetã‚’åˆ©ç”¨ã€‚149ç¨®é¡ã®MTã‚·ã‚¹ãƒ†ãƒ ã®14 languageã«å¯¾ã™ã‚‹ç¿»è¨³çµæœ, gold referencesã¨2ç¨®é¡ã®human judgment scoreãŒä»˜ä¸ã•ã‚Œã¦ã„ã‚‹ã€‚segment-level human judgmentsã¯ã€ãã‚Œãã‚Œã®reference-candiate pairã«å¯¾ã—ã¦ä»˜ä¸ã•ã‚Œã¦ãŠã‚Šã€system-level human judgmentsã¯ã€ãã‚Œãã‚Œã®ã‚·ã‚¹ãƒ†ãƒ ã«å¯¾ã—ã¦ã€test setå…¨ä½“ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã€å˜ä¸€ã®ã‚¹ã‚³ã‚¢ãŒä»˜ä¸ã•ã‚Œã¦ã„ã‚‹ã€‚pearson correlationã®çµ¶å¯¾å€¤ã¨ã€kendall rank correration Ï„ã‚’metricsã®å“è³ªã®è©•ä¾¡ã«åˆ©ç”¨ã€‚ãã—ã¦peason correlationã«ã¤ã„ã¦ã¯Williams testã€kendall Ï„ã«ã¤ã„ã¦ã¯ã€bootstrap re-samplingã«ã‚ˆã£ã¦æœ‰æ„å·®ã‚’æ¤œå®šã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã®ã‚¹ã‚³ã‚¢ã‚’BERTScoreã‚’ã™ã¹ã¦ã®reference-candidate pairã«å¯¾ã™ã‚‹ã‚¹ã‚³ã‚¢ã‚’averagingã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦æ±‚ã‚ãŸã€‚ã¾ãŸã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦ã‚‚å®Ÿé¨“ã‚’ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€ãã‚Œãã‚Œã®reference sentenceã«ã¤ã„ã¦ã€ã‚·ã‚¹ãƒ†ãƒ ã®ä¸­ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«candidate sentenceã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€system-level experimentã‚’ã‚ˆã‚Šå¤šãã®ã‚·ã‚¹ãƒ†ãƒ ã§å®Ÿç¾ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¬4ãƒ™ãƒ«ã®human judgmentsã¯ã€WMT18ã®segment-level human judgmentsã‚’å¹³å‡ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ä½œæˆã—ãŸã€‚BERTScoreã‚’æ—¢å­˜ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨æ¯”è¼ƒã—ãŸã€‚<br><br><br><br>é€šå¸¸ã®è©•ä¾¡ã«åŠ ãˆã¦ã€ãƒ¢ãƒ‡ãƒ«é¸æŠã«ã¤ã„ã¦ã‚‚å®Ÿé¨“ã—ãŸã€‚10kã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆ©ç”¨ã—ã€10kã®ã†ã¡100ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã€ãã—ã¦è‡ªå‹•æ€§èƒ½æŒ‡æ¨™ã§ãã‚Œã‚‰ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã—ãŸã€‚ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’100Kå›ç¹°ã‚Šè¿”ã—ã€human rankingã¨metricã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒã©ã‚Œã ã‘agreementãŒã‚ã‚‹ã‹ã‚’Hits@1ã§è©•ä¾¡ã—ãŸï¼ˆbest systemã®ä¸€è‡´ã§è©•ä¾¡ï¼‰ã€‚ãƒ¢ãƒ‡ãƒ«é¸æŠã®æŒ‡æ¨™ã¨ã—ã¦æ–°ãŸã«top metric-rated systemã¨human rankingã®é–“ã§ã®MRR, äººæ‰‹è©•ä¾¡ã§top-rated systemã¨ãªã£ãŸã‚·ã‚¹ãƒ†ãƒ ã¨ã®ã‚¹ã‚³ã‚¢ã®å·®ã‚’ç®—å‡ºã—ãŸã€‚WMT17, 16ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚åŒæ§˜ã®è©•ä¾¡ã‚’å®Ÿæ–½ã—ãŸã€‚<br><br><br><br>## Image Captioning<br><br>COCO 2015 captioning challengeã«ãŠã‘ã‚‹12ç¨®é¡ã®ã‚·ã‚¹ãƒ†ãƒ ã®submissionãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã€‚COCO validationã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ã€ãã‚Œãã‚Œã®ã‚·ã‚¹ãƒ†ãƒ ã¯imageã«å¯¾ã™ã‚‹captionã‚’ç”Ÿæˆã—ã€ãã‚Œãã‚Œã®imageã¯ãŠã‚ˆã5å€‹ã®referenceã‚’æŒã£ã¦ã„ã‚‹ã€‚å…ˆè¡Œç ”ç©¶ã«ãªã‚‰ã„ã€Person Correlationã‚’2ç¨®é¡ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«metricã§æ¸¬å®šã—ãŸã€‚<br><br>- M1: äººé–“ã«ã‚ˆã‚‹captionã¨åŒç­‰ã€ã‚ã‚‹ã„ã¯ãã‚Œä»¥ä¸Šã¨è©•ä¾¡ã•ã‚ŒãŸcaptionã®å‰²åˆ<br><br>- M2: äººé–“ã«ã‚ˆã‚‹captionã¨åŒºåˆ¥ãŒã¤ã‹ãªã„captionã®å‰²åˆ<br><br>BERTScoreã‚’multiple referenceã«å¯¾ã—ã¦è¨ˆç®—ã—ã€æœ€ã‚‚é«˜ã„ã‚¹ã‚³ã‚¢ã‚’æ¡ç”¨ã—ãŸã€‚æ¯”è¼ƒå¯¾è±¡ã®metricã¯task-agnostic metricã‚’æ¡ç”¨ã—ã€BLEU, METEOR, CIDEr, BEER, EED, CHRF++, CHARACTERã¨æ¯”è¼ƒã—ãŸã€‚ãã—ã¦ã€2ç¨®é¡ã®task-specific metricsã¨ã‚‚æ¯”è¼ƒã—ãŸï¼šSPICE, LEIC<br><br><br><br># å®Ÿé¨“çµæœ<br><br>## Machine Translation<br><br>system-levelã®human judgmentsã¨ã®correlationã®æ¯”è¼ƒã€hybrid systemã¨ã®correlationã®æ¯”è¼ƒã€model selection performance<br><br>to-Englishã®çµæœã§ã¯ã€BERTScoreãŒæœ€ã‚‚ä¸€è²«ã—ã¦æ€§èƒ½ãŒè‰¯ã‹ã£ãŸã€‚RUSEãŒcompetitiveãªæ€§èƒ½ã‚’ç¤ºã—ãŸãŒã€RUSEã¯supervised methodã§ã‚ã‚‹ã€‚from-Englishã®å®Ÿé¨“ã§ã¯ã€RUSEã¯è¿½åŠ ã®ãƒ‡ãƒ¼ã‚¿ã¨è¨“ç·´ã‚’ã—ãªã„ã¨é©ç”¨ã§ããªã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e3b0482e-a30b-46be-b8df-72a1c4fe510d" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b769ac8f-1a43-48d6-9316-cb78cffc3b88" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3b204434-9f9a-4672-be5a-6e463d3289f4" alt="image" loading="lazy"><br><br><br><br>ä»¥ä¸‹ã¯ã€segment-levelã®correlationã‚’ç¤ºã—ãŸã‚‚ã®ã§ã‚ã‚‹ã€‚BERTScoreãŒä¸€è²«ã—ã¦é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚BLEUã‹ã‚‰å¤§å¹…ãªæ€§èƒ½ã‚¢ãƒƒãƒ—ã‚’ç¤ºã—ã¦ãŠã‚Šã€ç‰¹å®šã®exampleã«ã¤ã„ã¦ã®è‰¯ã•ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã«ã¯ã€BERTScoreãŒæœ€é©ã§ã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚BERTScoreã¯ã€RUSEã‚’significantlyã«ä¸Šå›ã£ã¦ã„ã‚‹ã€‚idfã«ã‚ˆã‚‹é‡è¦åº¦ã®weightingã«ã‚ˆã£ã¦ã€å…¨ä½“ã¨ã—ã¦ã¯ã€small benefitãŒã‚ã‚‹å ´åˆãŒã‚ã‚‹ãŒå…¨ä½“ã¨ã—ã¦ã¯ã‚ã‚“ã¾ã‚ŠåŠ¹æœãŒãªã‹ã£ãŸã€‚importance weightingã¯ä»Šå¾Œã®èª²é¡Œã§ã‚ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ä¾å­˜ã™ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚FBERTãŒç•°ãªã‚‹è¨­å®šã§ã‚‚è‰¯ãæ©Ÿèƒ½ã™ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚ç•°ãªã‚‹contextual embedding modelé–“ã§ã®æ¯”è¼ƒãªã©ã¯ã€appendixã«ç¤ºã™ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1684fa38-0663-4649-849f-1885cd97286e" alt="image" loading="lazy"><br><br><br><br>## Image Captioning<br><br>task-agnostic metricã®é–“ã§ã¯ã€BETRScoreã¯large marginã§å‹ã£ã¦ã„ã‚‹ã€‚image captioningã¯challengingãªè©•ä¾¡ãªã®ã§ã€n-gramãƒãƒƒãƒã«åŸºã¥ãBLEU, ROUGEã¯ã¾ã£ãŸãæ©Ÿèƒ½ã—ã¦ã„ãªã„ã€‚ã¾ãŸã€idf weightingãŒã“ã®ã‚¿ã‚¹ã‚¯ã§ã¯éå¸¸ã«é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã“ã‚Œã¯äººé–“ãŒcontent wordsã«å¯¾ã—ã¦ã€ã‚ˆã‚Šé«˜ã„é‡è¦åº¦ã‚’ç½®ã„ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚æœ€å¾Œã«ã€LEICã¯trained metricã§ã‚ã‚Šã€COCO dataã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã®æ‰‹æ³•ã¯ã€ã»ã‹ã®ã™ã¹ã¦ã®metricã‚’ä¸Šå›ã£ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5842611a-38bd-441f-a467-8bb3714dc33a" alt="image" loading="lazy"><br><br><br><br>## Speed<br><br>pre-trained modelã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€BERTScoreã¯æ¯”è¼ƒçš„é«˜é€Ÿã«å‹•ä½œã™ã‚‹ã€‚192.5 candidate-reference pairs/secondãã‚‰ã„å‡ºã‚‹ï¼ˆGTX-1080Ti GPUã§ï¼‰ã€‚WMT18ãƒ‡ãƒ¼ã‚¿ã§ã¯ã€15.6ç§’ã§å‡¦ç†ãŒçµ‚ã‚ã‚Šã€SacreBLEUã§ã¯5.4ç§’ã§ã‚ã‚‹ã€‚è¨ˆç®—ã‚³ã‚¹ãƒˆãã‚“ãªã«ãªã„ã®ã§ã€BERTScoreã¯stoppingã®validationã¨ã‹ã«ã‚‚ä½¿ãˆã‚‹ã€‚</p>
<p># Robustness analysis<br><br>BERTScoreã®ãƒ­ãƒã‚¹ãƒˆæ€§ã‚’adversarial paraphrase classificationã§ãƒ†ã‚¹ãƒˆã€‚Quora Question Pair corpus (QQP) ã‚’åˆ©ç”¨ã—ã€Word Scrambling dataset (PAWS) ã‹ã‚‰Paraphrase Adversariesã‚’å–å¾—ã€‚ã©ã¡ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚‚ã€å„sentenceãƒšã‚¢ã«å¯¾ã—ã¦ã€ãã‚Œã‚‰ãŒparaphraseã‹ã©ã†ã‹ãƒ©ãƒ™ãƒ«ä»˜ã‘ã•ã‚Œã¦ã„ã‚‹ã€‚QQPã®æ­£ä¾‹ã¯ã€å®Ÿéš›ã®duplicate questionã‹ã‚‰ãã¦ãŠã‚Šã€è² ä¾‹ã¯é–¢é€£ã™ã‚‹ãŒã€ç•°ãªã‚‹è³ªå•ã‹ã‚‰ãã¦ã„ã‚‹ã€‚PAWSã®sentence pairsã¯å˜èªã®å…¥ã‚Œæ›¿ãˆã«åŸºã¥ã„ã¦ã„ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã€‚ãŸã¨ãˆã°ã€"Flights from New York to Florida" ã¯ "Flights from Florida to New York" ã®ã‚ˆã†ã«å¤‰æ›ã•ã‚Œã€è‰¯ã„classifierã¯ã“ã‚Œã‚‰ãŒparaphraseã§ã¯ãªã„ã¨èªè­˜ã§ããªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚PAWSã¯PAWS_QQPã¨PAWS_WIKIã«ã‚ˆã£ã¦æ§‹æˆã•ãˆï½’ã¦ãŠã‚Šã€PAWS_QQPã‚’develpoment setã¨ã—ãŸã€‚automatic metricsã§ã¯ã€paraphrase detection training dataã¯åˆ©ç”¨ã—ãªã„ã‚ˆã†ã«ã—ãŸã€‚è‡ªå‹•æ€§èƒ½æŒ‡æ¨™ã§é«˜ã„ã‚¹ã‚³ã‚¢ã‚’ç²å¾—ã™ã‚‹ã‚‚ã®ã¯ã€paraphraseã§ã‚ã‚‹ã“ã¨ã‚’æƒ³å®šã—ã¦ã„ã‚‹ã€‚<br><br><br><br>ä¸‹å›³ã¯AUCã®ROC curveã‚’è¡¨ã—ã¦ãŠã‚Šã€PAWS_QQPã«ãŠã„ã¦ã€QQPã§è¨“ç·´ã•ã‚ŒãŸclassifierã¯random guessã‚ˆã‚Šã‚‚æ€§èƒ½ãŒä½ããªã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚ã¤ã¾ã‚Šã“ã‚Œã‚‰ãƒ¢ãƒ‡ãƒ«ã¯adversaial exampleã‚’paraphraseã ã¨äºˆæ¸¬ã—ã¦ã—ã¾ã£ã¦ã„ã‚‹ã“ã¨ã«ãªã‚‹ã€‚adversarial examplesãŒtrainingãƒ‡ãƒ¼ã‚¿ã§ä¸ãˆã‚‰ã‚ŒãŸå ´åˆã¯ã€supervisedãªãƒ¢ãƒ‡ãƒ«ã‚‚åˆ†é¡ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚ãŒã€QQPã¨æ¯”ã¹ã‚‹ã¨æ€§èƒ½ã¯è½ã¡ã‚‹ã€‚å¤šãã®metricsã§ã¯ã€QQP ã§ã¯ã¾ã¨ã‚‚ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ãŒã€PAWS_QQP ã§ã¯å¤§å¹…ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ä½ä¸‹ã‚’ç¤ºã—ã€ã»ã¼randomã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ãªã‚‹ã€‚ã“ã‚Œã¯ã€ã“ã‚Œã‚‰ã®æŒ‡æ¨™ãŒã‚ˆã‚Šå›°é›£ãªadversarial exampleã‚’åŒºåˆ¥ã§ããªã„ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã€BERTSCORE ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ã‚ãšã‹ã«ä½ä¸‹ã™ã‚‹ã ã‘ã§ã‚ã‚Šã€ä»–ã®æŒ‡æ¨™ã‚ˆã‚Šã‚‚ãƒ­ãƒã‚¹ãƒˆæ€§ãŒé«˜ã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7a3b3c3b-ff4e-4f65-a6b3-c71b8f100c8a" alt="image" loading="lazy"><br><br><br><br># Discussion<br><br>- BERTScoreã®å˜ä¸€ã®è¨­å®šãŒã€ã»ã‹ã®ã™ã¹ã¦ã®æŒ‡æ¨™ã‚’æ˜ç¢ºã«ä¸Šå›ã‚‹ã¨ã„ã†ã“ã¨ã¯ãªã„<br><br>- ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚„è¨€èªã‚’è€ƒæ…®ã—ã¦ã€æŒ‡æ¨™ã‚„è¨­å®šã‚’é¸æŠã™ã¹ã<br><br>- ä¸€èˆ¬çš„ã«ã€æ©Ÿæ¢°ç¿»è¨³ã®è©•ä¾¡ã«ã¯FBERTã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨<br><br>- è‹±èªã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®è©•ä¾¡ã«ã¯ã€24å±¤ã®RoBERTa largeãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€BERTScoreã‚’è¨ˆç®—ã—ãŸã»ã†ãŒè‰¯ã„<br><br>- éè‹±èªè¨€èªã«ã¤ã„ã¦ã¯ã€å¤šè¨€èªã®BERT_multiãŒè‰¯ã„é¸æŠè‚¢ã ãŒã€ã“ã®ãƒ¢ãƒ‡ãƒ«ã§è¨ˆç®—ã•ã‚ŒãŸBERTScoreã¯ã€low resource languageã«ãŠã„ã¦ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå®‰å®šã—ã¦ã„ã‚‹ã¨ã¯è¨€ãˆãªã„</p></span><br><br>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/review.html" target="_blank" rel="noopener noreferrer">#review</a>
<span class="issue_date">Issue Date: 2023-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/656" target="_blank" rel="noopener noreferrer" class="title-link">A Unified Dual-view Model for Review Summarization and Sentiment  Classification with Inconsistency Loss, Hou Pong Chan+, N_A, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰è¦ç´„ã¨æ„Ÿæƒ…ã‚’å–å¾—ã™ã‚‹ãŸã‚ã«ã€æ–°ã—ã„ãƒ‡ãƒ¥ã‚¢ãƒ«ãƒ“ãƒ¥ãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã€‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãŒãƒ¬ãƒ“ãƒ¥ãƒ¼ã®æ–‡è„ˆè¡¨ç¾ã‚’å­¦ç¿’ã—ã€ã‚µãƒãƒªãƒ¼ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ãŒè¦ç´„ã‚’ç”Ÿæˆã€‚ã‚½ãƒ¼ã‚¹ãƒ“ãƒ¥ãƒ¼æ„Ÿæƒ…åˆ†é¡å™¨ã¯ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã‚’äºˆæ¸¬ã—ã€ã‚µãƒãƒªãƒ¼ãƒ“ãƒ¥ãƒ¼æ„Ÿæƒ…åˆ†é¡å™¨ã¯è¦ç´„ã®æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã‚’äºˆæ¸¬ã€‚ä¸ä¸€è‡´æå¤±ã‚’å°å…¥ã—ã¦ã€2ã¤ã®åˆ†é¡å™¨ã®ä¸ä¸€è‡´ã‚’ç½°ã™ã‚‹ã“ã¨ã§ã€ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ãŒä¸€è²«ã—ãŸæ„Ÿæƒ…å‚¾å‘ã‚’æŒã¤è¦ç´„ã‚’ç”Ÿæˆã—ã€2ã¤ã®æ„Ÿæƒ…åˆ†é¡å™¨ãŒãŠäº’ã„ã‹ã‚‰å­¦ã¶ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚4ã¤ã®å®Ÿä¸–ç•Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å®Ÿé¨“çµæœã¯ã€ãƒ¢ãƒ‡ãƒ«ã®åŠ¹æœã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Review Summarizationã¨Sentiment Classificationã‚’jointã§å­¦ç¿’ã—ãŸç ”ç©¶ã€‚æ—¢å­˜ç ”ç©¶ã§ã¯reviewã®ã¿ã‹ã‚‰sentimentã®æƒ…å ±ã‚’ç²å¾—ã™ã‚‹æ çµ„ã¿ã¯å­˜åœ¨ã—ãŸãŒã€summaryã®æƒ…å ±ãŒæ´»ç”¨ã§ãã¦ã„ãªã‹ã£ãŸã€‚<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/653" target="_blank" rel="noopener noreferrer">SNAP: Web data: Amazon reviews</a>
 ã®ratingã‚’sentiment labelã¨ã—ã¦æ‰±ã„ã€è©•ä¾¡ã‚‚åŒãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ROUGEã§è©•ä¾¡ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/236713791-7986bb89-2576-4daa-b01a-9af7e97dac51.png" alt="image" loading="lazy"><br><br><br><br>å®Ÿéš›ã«ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾‹ãŒã“ã¡ã‚‰ã€‚ãªã‚“ã®ç–‘ã„ã‚‚ãªãamazon online review datasetã‚’æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ã£ã¦ã„ã‚‹ãŒã€æœãŸã—ã¦ã“ã‚Œã§ã„ã„ã‚“ã ã‚ã†ã‹ï¼Ÿ<br><br>è«–æ–‡å†’é ­ã®summaryã®ä¾‹ã¨ã€å®Ÿéš›ã«ç”Ÿæˆã•ã‚ŒãŸä¾‹ã‚’è¦‹ã‚‹ã¨ã€å¾Œè€…ã®æ–¹ãŒéå¸¸ã«ä¸»è¦³çš„ãªæƒ…å ±ã‚’å«ã‚€ã®ã«å¯¾ã—ã¦ã€å‰è€…ã¯ã‚ˆã‚Šå®¢è¦³æ€§ãŒé«˜ã„ã‚ˆã†ã«æ€ãˆã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/236714479-19772588-e226-4fe9-8850-13050fdc775a.png" alt="image" loading="lazy"><br><br></p>
<p>ã—ã‹ã—æœ€åˆã«ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ãŸã®ã¯ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/652" target="_blank" rel="noopener noreferrer">A Hierarchical End-to-End Model for Jointly Improving Text Summarization
  and Sentiment Classification, Shuming Ma+, N/A, arXiv'18</a>
 ã®æ–¹ã£ã½ã„</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/552" target="_blank" rel="noopener noreferrer" class="title-link">Language Models are Few-Shot Learners, Tom B. Brown+, NeurIPS'20</a>
<span class="snippet"><span>GPT Summary</span>- GPT-3ã¯1750å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤è‡ªå·±å›å¸°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆè¨­å®šã«ãŠã„ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã§å¤šãã®NLPã‚¿ã‚¹ã‚¯ã§å¼·åŠ›ãªæ€§èƒ½ã‚’ç¤ºã™ã€‚ç¿»è¨³ã‚„è³ªå•å¿œç­”ãªã©ã§å„ªã‚ŒãŸçµæœã‚’å‡ºã—ã€å³æ™‚æ¨è«–ã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§ã‚‚è‰¯å¥½ãªæ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ä¸€æ–¹ã€ä¾ç„¶ã¨ã—ã¦è‹¦æ‰‹ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„è¨“ç·´ã«é–¢ã™ã‚‹å•é¡Œã‚‚å­˜åœ¨ã™ã‚‹ã€‚ã¾ãŸã€GPT-3ã¯äººé–“ãŒæ›¸ã„ãŸè¨˜äº‹ã¨åŒºåˆ¥ãŒé›£ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã€ç¤¾ä¼šçš„å½±éŸ¿ã«ã¤ã„ã¦ã‚‚è­°è«–ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>In-Context Learningã‚’ææ¡ˆã—ãŸè«–æ–‡</p>
<p>è«–æ–‡ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹In-Context Learningã®å®šç¾©ã¯ã€ã—ã£ã‹ã‚ŠæŠ¼ã•ãˆã¦ãŠã„ãŸæ–¹ãŒè‰¯ã„ã€‚<br><br>ä¸‹å›³ã¯meta-learningã®è¦³ç‚¹ã‹ã‚‰è¦‹ãŸã¨ãã®ã€in-contextã®ä½ç½®ä»˜ã‘ã€‚äº‹å‰å­¦ç¿’æ™‚ã«SGDã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’updateã™ã‚‹ã®ã‚’outer loopã¨ã—ã€ãã“ã§åºƒã„ã‚¹ã‚­ãƒ«ã¨ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã®èƒ½åŠ›ã‚’èº«ã«ã¤ã‘ã‚‹ã€‚ä¸€æ–¹ã§ã€in-context learningã¯ã€Inferenceæ™‚ã«äº‹å‰å­¦ç¿’æ™‚ã«å¾—ãŸãã‚Œã‚‰ã®ã‚¹ã‚­ãƒ«ã‚’ç”¨ã„ã¦ã€æ±‚ã‚ã‚‹ã‚¿ã‚¹ã‚¯ã‚’èªè­˜ã€ã‚ã‚‹ã„ã¯é©å¿œã™ã‚‹Inner loopã®ã“ã¨ã‚’æŒ‡ã™ã€‚<br><img src="https://github.com/user-attachments/assets/679129f3-93e3-445f-b9e8-5d909261737b" alt="image" loading="lazy"><br><br>ã“ã®ä¸Šã§ã€è«–æ–‡ä¸­ã§ã¯ In-Context Learningã«ã¤ã„ã¦:<br>&gt; Recent work [RWC+19] attempts to do this via what we call â€œin-context learningâ€, using the text input of a pretrained language model as a form of task specification: the model is conditioned on a natural language instruction and/or a few demonstrations of the task and is then expected to complete further instances of the task simply by predicting what comes next.<br><br>ã¨å®šç¾©ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2023-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/537" target="_blank" rel="noopener noreferrer" class="title-link">Returning the N to NLP: Towards Contextually Personalized Classification Models, Lucie Flek, Mainz University of Applied Sciences Germany, ACL'20</a>
<span class="snippet"><span>Comment</span><p>NLPã®ã‘ã‚‹Personalized Classificationãƒ¢ãƒ‡ãƒ«ã®literatureã‚’æŒ¯ã‚Šè¿”ã‚‹è«–æ–‡</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<a class="button" href="articles/Zero/FewShotLearning.html" target="_blank" rel="noopener noreferrer">#Zero/FewShotLearning</a>
<span class="issue_date">Issue Date: 2022-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/494" target="_blank" rel="noopener noreferrer" class="title-link">Few-Shot NLG with Pre-Trained Language Model, Chen+, University of California, ACL'20</a>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>Neural basedãªend-to-endãªNLGã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯data-hungryãªã®ã§ã€Few Shotãªè¨­å®šã§é«˜ã„æ€§èƒ½ãŒã§ãã‚‹æ‰‹æ³•ã‚’ææ¡ˆï¼ˆFew shot NLGï¼‰<br><br>Table-to-Textã‚¿ã‚¹ã‚¯ï¼ˆWikiBIOãƒ‡ãƒ¼ã‚¿, è¿½åŠ ã§åé›†ã—ãŸBook, Songãƒ‰ãƒ¡ã‚¤ãƒ³ã®Wikipediaãƒ‡ãƒ¼ã‚¿ï¼‰ã«ãŠã„ã¦ã€200ç¨‹åº¦ã®å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°ã§strong baselineã«å¯¾ã—ã¦8.0 pointç¨‹åº¦ã®BLEUã‚¹ã‚³ã‚¢ã®å‘ä¸Šã‚’é”æˆ<br><br><br><br># æ‰‹æ³•<br><br>Tabularãƒ‡ãƒ¼ã‚¿ã®Descriptionã‚’ä½œæˆã™ã‚‹ã«ã¯å¤§ããåˆ†ã‘ã¦2ã¤ã®ã‚¹ã‚­ãƒ«ãŒå¿…è¦<br><br>1. factualãªæƒ…å ±ã‚’æŒã¤contentã‚’selectã—ã€copyã™ã‚‹ã‚¹ã‚­ãƒ«<br><br>2. factualãªæƒ…å ±ã®ã‚³ãƒ”ãƒ¼ã‚’å«ã‚ãªãŒã‚‰ã€æ–‡æ³•çš„ã«æ­£ã—ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚­ãƒ«<br><br>ææ¡ˆæ‰‹æ³•ã§ã¯ã€1ã‚’å°‘é‡ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆ&lt; 500ï¼‰ã‹ã‚‰å­¦ç¿’ã—ã€2ã«ã¤ã„ã¦ã¯äº‹å‰å­¦ç¿’æ¸ˆã¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã™ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/204966408-e5442477-0560-439b-9780-d454a8761345.png" alt="image" loading="lazy"><br><br><br><br>encoderã‹ã‚‰ã‚³ãƒ”ãƒ¼ã™ã‚‹ç¢ºç‡ã‚’pcopyã¨ã—ã€ä¸‹è¨˜å¼ã§ç®—å‡ºã™ã‚‹ï¼š<br><br><img src="https://user-images.githubusercontent.com/12249301/204968383-44ef3771-218e-4e3e-8bfd-e2e6750c514b.png" alt="image" loading="lazy"><br><br>ã™ãªã‚ã¡ã€encoderã®context vectorã¨ã€decoderã®inputã¨stateã‹ã‚‰æ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚<br><br>encoderã¨encoderå´ã¸ã®attentionã¯scratchã‹ã‚‰å­¦ç¿’ã—ãªã‘ã‚Œã°ãªã‚‰ãšã€ã†ã¾ãã‚³ãƒ”ãƒ¼ã§ãã‚‹ã‚ˆã†ã«ã—ã£ã‹ã‚Šã¨â€teachâ€ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ãŸã‚ã€lossã«ä»¥ä¸‹ã‚’è¿½åŠ ã™ã‚‹ï¼š<br><br><img src="https://user-images.githubusercontent.com/12249301/204968557-4526e76d-8be5-4371-adc7-d49d8291954f.png" alt="image" loading="lazy"><br><br>ã™ãªã‚ã¡ã€ã‚³ãƒ”ãƒ¼ã™ã¹ãå˜èªãŒã¡ã‚ƒã‚“ã¨ã‚³ãƒ”ãƒ¼ã§ãã¦ã‚‹å ´åˆã«lossãŒå°ã•ããªã‚‹é …ã‚’è¿½åŠ ã—ã¦ã„ã‚‹ã€‚<br><br>ã¾ãŸã€decoderå´ã§ã¯ã€æœ€åˆã«Tableæƒ…å ±ã®Embeddingã‚’å…¥åŠ›ã™ã‚‹ã‚ˆã†ã«ã—ã¦ã„ã‚‹ã€‚<br><br>ã¾ãŸã€å­¦ç¿’ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿é‡ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹ãŸã‚ã€pre-trainingãƒ¢ãƒ‡ãƒ«ã®Embeddingã¯äº‹å‰å­¦ç¿’æ™‚ç‚¹ã®ã‚‚ã®ã«å›ºå®šã—ãŸï¼ˆãŸã ã—ãèª­è§£ã§ãã¦ã„ã‚‹ã‹ä¸å®‰ï¼‰<br><br><br><br># å®Ÿé¨“<br><br>WikiBIOã¨ã€ç‹¬è‡ªã«åé›†ã—ãŸBook, Songã«é–¢ã™ã‚‹Wikipediaãƒ‡ãƒ¼ã‚¿ã®Table-to-Textãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦å®Ÿé¨“ã€‚<br><br>ã“ã®ã¨ãã€Training instanceã‚’50~500ã¾ã§å¤‰åŒ–ã•ã›ãŸã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/204969250-b2965b62-5a82-4c38-9008-3e4bbc5d9c24.png" alt="image" loading="lazy"><br><br><br><br>WikiBIOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦SoTAã‚’è¨˜éŒ²ã—ã¦ã„ã‚‹Base-originalã‚’å¤§ããoutperformï¼ˆFew shot settingã§ã¯å…¨ç„¶ã†ã¾ãã„ã‹ãªã„ï¼‰ã€‚<br><br><br><br>inputã¨outputä¾‹ã¨ã€ã‚³ãƒ”ãƒ¼ã«é–¢ã™ã‚‹lossã‚’å…¥ã‚ŒãŸå ´åˆã®åŠ¹æœã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/204969645-aa2686f0-f83c-44cc-a6aa-2e793a6cd5b8.png" alt="image" loading="lazy"><br><br><br><br>äººæ‰‹è©•ä¾¡ã®çµæœã€Factual informationã®æ­£ã—ã•ï¼ˆ#Suppï¼‰ã€èª¤ã‚Šï¼ˆ#Contï¼‰ã¨ã‚‚ã«ææ¡ˆæ‰‹æ³•ãŒè‰¯ã„ã€‚ã¾ãŸã€æ–‡æ³•çš„ãªæ­£ã—ã•ï¼ˆLan. Scoreï¼‰ã‚‚ã‚³ãƒ”ãƒ¼ãŒãªã„å ´åˆã¨comparable<br><br><img src="https://user-images.githubusercontent.com/12249301/204969885-7cb3e507-d986-4d97-8f7c-a5b8c3c8204f.png" alt="image" loading="lazy"><br><br><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<span class="issue_date">Issue Date: 2022-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/493" target="_blank" rel="noopener noreferrer" class="title-link">Leveraging Pre-trained Checkpoints for Sequence Generation Tasks, Rothe+, Google Research, TACL'20</a>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>BERT-to-BERTè«–æ–‡ã€‚ã“ã‚Œã¾ã§pre-trainedãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’åˆ©ç”¨ã™ã‚‹ç ”ç©¶ã¯ä¸»ã«NLUã§è¡Œã‚ã‚Œã¦ãã¦ãŠã‚Šã€Seq2Seqã§ã¯è¡Œã‚ã‚Œã¦ãã¦ã„ãªã‹ã£ãŸã®ã§ã€ã‚„ã‚Šã¾ã—ãŸã€ã¨ã„ã†è©±ã€‚<br><br>publicly availableãªBERTã®checkpointã‚’åˆ©ç”¨ã—ã€BERTã‚’encoder, decoderä¸¡æ–¹ã«æ¡ç”¨ã™ã‚‹ã“ã¨ã§Seq2Seqã‚’å®Ÿç¾ã€‚å®Ÿç¾ã™ã‚‹ä¸Šã§ã€<br><br>1. decoderå´ã®BERTã¯autoregressiveãªç”Ÿæˆã‚’ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼ˆå·¦å´ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®attentionã—ã‹è¦‹ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹ï¼‰<br><br>2. encoder-decoder attentionã‚’æ–°ãŸã«å°å…¥ã™ã‚‹<br><br>ã®2ç‚¹ã‚’å·¥å¤«ã—ã¦ã„ã‚‹ã€‚<br><br><br><br># å®Ÿé¨“<br><br>Sentence Fusion, Sentence Split, Machine Translation, Summarizationã®4ã‚¿ã‚¹ã‚¯ã§å®Ÿé¨“<br><br><br><br>## MT<br><br><img src="https://user-images.githubusercontent.com/12249301/204958483-722106b3-bda2-45a3-bb08-fb4eb429c90c.png" alt="image" loading="lazy"><br><br>BERT2BERTãŒSoTAé”æˆã€‚Edunov+ã®æ‰‹æ³•ã¯ã€data _augmentationã‚’åˆ©ç”¨ã—ãŸæ‰‹æ³•ã§ã‚ã‚Šã€ç´”ç²‹ãªWMT14ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸä¸­ã§ã¯SoTAã ã¨ä¸»å¼µã€‚ç‰¹ã«Encoderå´ã§BERTã‚’ä½¿ã†ã¨ã€Randomã«initializeã—ãŸå ´åˆã¨æ¯”ã¹ã¦æ€§èƒ½ãŒé¡•è‘—ã«ä¸Šæ˜‡ã—ã¦ãŠã‚Šã€ãã®é‡è¦æ€§ã‚’ä¸»å¼µã€‚<br><br>Sentence Fusion, Sentence Splitã§ã¯ã€encoderã¨decoderã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’shareã™ã‚‹ã®ãŒè‰¯ã‹ã£ãŸãŒã€MTã§ã¯æœ‰åŠ¹ã§ã¯ãªã‹ã£ãŸã€‚ã“ã‚Œã¯MTã§ã¯modelã®capacityãŒéå¸¸ã«é‡è¦ã§ã‚ã‚‹ç‚¹ã€encoderã¨decoderã§ç•°ãªã‚‹æ–‡æ³•ã‚’æ‰±ã†ãŸã‚ã§ã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><br><br><br>## Summarization<br><br>BERTSHARE, ROBERTASHAREã®çµæœãŒè‰¯ã‹ã£ãŸã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/204959543-e21bd9a6-bef4-4538-b181-daca93fa33e7.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<span class="issue_date">Issue Date: 2022-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/492" target="_blank" rel="noopener noreferrer" class="title-link">Template Guided Text Generation for Task-Oriented Dialogue, Kale+, Google, EMNLP'20</a>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>Dialogue Actã‚’ãã®ã¾ã¾linearlizeã—ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã«å…¥åŠ›ã™ã‚‹ã®ã§ã¯ãªãã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸã‚·ãƒ³ãƒ—ãƒ«ãªsentenceã«ã—ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã«ä¸ãˆã‚‹ã¨ã€zero-shot, few-shotãªsettingã§æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã¨ã„ã†è©±ï¼ˆT5ãƒ™ãƒ¼ã‚¹ï¼‰ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/204951348-e7cb9982-4d1f-4ac0-8e1d-b3e8fd872b11.png" alt="image" loading="lazy"><br><br><br><br># æ‰‹æ³•<br><br>slotã®åç§°ã‚’natural languageã®descriptionã«å¤‰æ›´ã™ã‚‹Schema Guidedã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚‚ææ¡ˆï¼ˆNLUã§ã¯æ—¢ã«å®Ÿè·µã•rã¦ã„ãŸã‚‰ã—ã„ãŒã€Generationã§åˆ©ç”¨ã•ã‚ŒãŸã“ã¨ã¯ãªã„ï¼‰ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/204952341-fae03300-992a-491f-b194-9013f5d598f9.png" alt="image" loading="lazy"><br><br><br><br># çµæœ<br><br>MultiWoz, E2E, SGDãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ©ç”¨ã€‚MultiWoz, E2Eãƒ‡ãƒ¼ã‚¿ã¯ãƒ‡ãƒ¼ã‚¿é‡ãŒè±Šå¯Œã§ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚„featureãŒé™å®šçš„ãªãŸã‚ã€schema guided, template guided approachã¨Naiveãªrepresentationã‚’åˆ©ç”¨ã—ãŸå ´åˆã®çµæœãŒcopmarableã§ã‚ã£ãŸã€‚<br><br>ãŒã€SGDãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒè±Šå¯Œã§zero-shot, few-shotã®è¨­å®šã§å®Ÿé¨“ãŒã§ãã‚‹ã€‚SGDã®å ´åˆã¯Template guided representationãŒæœ€ã‚‚é«˜ã„æ€§èƒ½ã‚’å¾—ãŸã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/204954033-ecbeb90f-1398-486c-8d1f-76a0e54ed8ea.png" alt="image" loading="lazy"><br><br></p>
<p>low resourceãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æ´»ç”¨ã§ããã†</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2022-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/488" target="_blank" rel="noopener noreferrer" class="title-link">Text-to-Text Pre-Training for Data-to-Text Tasks, Mihir+, Google Research, INLG'20</a>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>pre-trainingæ¸ˆã¿ã®T5ã«å¯¾ã—ã¦ã€Data2Textã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§finetuningã‚’å®Ÿæ–½ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚WebNLGï¼ˆgraph-to-textï¼‰, ToTToï¼ˆtable-to-textï¼‰, Multiwozï¼ˆtask oriented dialogueï¼‰ãƒ‡ãƒ¼ã‚¿ã«ãŠã„ã¦ã€simpleãªTransformerã§ã‚‚æ´—ç·´ã•ã‚ŒãŸmulti-stageãªpipelined approachã‚’outperformã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸç ”ç©¶ã€‚<br><br><br><br># æ‰‹æ³•<br><br>äº‹å‰å­¦ç¿’æ¸ˆã¿ã®T5ã«å¯¾ã—ã¦fine-tuningã‚’å®Ÿæ–½ã—ãŸã€‚æ‰‹æ³•ã¯ã‚·ãƒ³ãƒ—ãƒ«ã§ã€data-to-textã‚¿ã‚¹ã‚¯ã‚’text-to-textã‚¿ã‚¹ã‚¯ã«å¤‰æ›ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€æ§‹é€ ã‹ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’flatãªæ–‡å­—åˆ—ï¼ˆlinearizationï¼‰ã§è¡¨ç¾ã™ã‚‹ã“ã¨ã§ã€text-to-textã‚¿ã‚¹ã‚¯ã«å¤‰æ›ã€‚å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹linearizationã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã¯ä¸‹å›³ã€‚ãƒ‡ãƒªãƒŸã‚¿ã‚„ç‰¹æ®Šæ–‡å­—ã‚’ä½¿ã£ã¦æ§‹é€ ã‹ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’flatãªstringã§è¡¨ç¾ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/191689155-3562f4f3-d1a1-4ea0-9d37-a523b78e8922.png" alt="image" loading="lazy"><br><br><br><br># ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br><br>## ToTToï¼ˆ2020ï¼‰<br><br>Wikipediaã®ãƒ†ãƒ¼ãƒ–ãƒ«ã¨è‡ªç„¶è¨€èªã§descriptionã®ãƒšã‚¢ãƒ‡ãƒ¼ã‚¿<br><br>## MultiWozï¼ˆ2018ï¼‰<br><br>10Kã®äººé–“åŒå£«ã®task-orientedãªdialogueãƒ‡ãƒ¼ã‚¿ã€‚<br><br>## WebNLGï¼ˆ2017ï¼‰<br><br>subject-object-predicateã®3çµ„ã¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¾ã«å¤‰æ›ã™ã‚‹ã‚¿ã‚¹ã‚¯ã®ãƒ‡ãƒ¼ã‚¿<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/191693682-3cf3302f-b4e2-433d-94ed-995a8a908d0c.png" alt="image" loading="lazy"><br><br><br><br># Result<br><br>## WebNLG<br><br><img src="https://user-images.githubusercontent.com/12249301/191694085-7bf7348a-b468-46e0-a900-c0090d1abcba.png" alt="image" loading="lazy"><br><br>GCNã‚’åˆ©ç”¨ã—ãŸ2020å¹´ã«ææ¡ˆã•ã‚ŒãŸDualEncãŒSoTAã ã£ãŸã‚‰ã—ã„ãŒã€outperormã—ã¦ã„ã‚‹ã€‚<br><br><br><br>## ToTTo<br><br><img src="https://user-images.githubusercontent.com/12249301/191694683-f31ccad1-2936-4c21-ac10-0807a848f043.png" alt="image" loading="lazy"><br><br>[ã“ã¡ã‚‰](


<a href="https://github.com/google-research-datasets/totto)%E3%81%AE%E3%83%AA%E3%83%BC%E3%83%80%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%E3%81%A8%E6%AF%94%E8%BC%83%E3%81%97%E3%81%A6SoTA%E3%82%92%E8%A8%98%E9%8C%B2" target="_blank" rel="noopener noreferrer">https://github.com/google-research-datasets/totto)ã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã¨æ¯”è¼ƒã—ã¦SoTAã‚’è¨˜éŒ²</a>


<br><br><br><br>## MultiWoz<br><br><img src="https://user-images.githubusercontent.com/12249301/191695459-e3397936-bdf7-4450-b4c2-6f6eead0825d.png" alt="image" loading="lazy"><br><br>T5ã¯äº‹å‰å­¦ç¿’æ¸ˆã¿GPT-2ã‚’finetuningã—ãŸæ‰‹æ³•ã‚‚outperformã—ãŸã€‚SC-GPT2ã¯å½“æ™‚ã®MultiWozã§ã®SoTA<br><br><br><br># Impact of Model capacity<br><br>T5ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºãŒã©ã‚ŒãŒè‰¯ã„ã‹ã«ã¤ã„ã¦ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºã¨è¤‡é›‘ã•ã«ä¾å­˜ã™ã‚‹ã“ã¨ã‚’è€ƒå¯Ÿã—ã¦ã„ã‚‹ã€‚ãŸã¨ãˆã°ã€MultiWozãƒ‡ãƒ¼ã‚¿ã¯æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒæœ€ã‚‚å°‘ãªãã€ãƒ‡ãƒ¼ã‚¿é‡ã‚‚56kã¨æ¯”è¼ƒçš„å¤šã‹ã£ãŸã€‚ã“ã®ãŸã‚ã€T5-smallã§ã‚‚ã‚ˆã‚Šå¤§ãã„ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«è‚‰è–„ã§ãã¦ã„ã‚‹ã€‚<br><br>ä¸€æ–¹ã€WebNLGãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€18kã—ã‹äº‹ä¾‹ãŒãªãã€ç‰¹å¾´é‡ã‚‚ç´„200ç¨®é¡ç¨‹åº¦ã®relationã®ã¿ã§ã‚ã‚‹ã€‚ã“ã®ã‚ˆã†ãªå ´åˆã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã«ã¤ã‚Œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚‚å‘ä¸Šã—ãŸï¼ˆç‰¹ã«Unseen test setï¼‰ã€‚ç‰¹ã«BLEUã‚¹ã‚³ã‚¢ã¯T5-smallãŒT5-baseã«ãªã‚‹ã¨ã€10ãƒã‚¤ãƒ³ãƒˆã‚‚ã‚¸ãƒ£ãƒ³ãƒ—ã—ã¦ãŠã‚Šã€modelã®capacityãŒout-of-domainã«å¯¾ã™ã‚‹ä¸€èˆ¬åŒ–ã«å¯¾ã—ã¦criticalã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚ToTToãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚ã€Smallã‹ã‚‰Baseã«ã™ã‚‹ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯æ”¹å–„ã—ãŸã€‚</p>
<p># æ‰€æ„Ÿ<br><br>ã“ã‚“ãªç°¡å˜ãªfine-tuningã§SoTAã‚’é”æˆã§ãã¦ã—ã¾ã†ã¨ã¯ã€æœ«æã‚ã—ã„ã€‚ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã—ã¦æœ‰ç”¨ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2021-06-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/381" target="_blank" rel="noopener noreferrer" class="title-link">All Word Embeddings from One Embedding, Takase+, NeurIPS'20</a>
<span class="snippet"><span>Comment</span><p>NLPã®ãŸã‚ã®NN-basedãªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¤šãã¯Embeddingã«ã‚ˆã‚‹ã‚‚ã®ã§ã€å¾“æ¥ã¯å€‹ã€…ã®å˜èªã”ã¨ã«ç•°ãªã‚‹embeddingã‚’Matrixã®å½¢ã§æ ¼ç´ã—ã¦ããŸã€‚ã“ã®ç ”ç©¶ã§ã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’æ¸›ã‚‰ã™ãŸã‚ã«ã€å€‹ã€…ã®word embeddingã‚’shared embeddingã®å¤‰æ›ã«ã‚ˆã£ã¦è¡¨ç¾ã™ã‚‹æ‰‹æ³•ALONE(all word embeddings from one)ã‚’ææ¡ˆã€‚å˜èªã”ã¨ã«å›ºæœ‰ã®non-trainableãªfilter vectorã‚’ç”¨ã„ã¦shared embeddingsã‚’ä¿®æ­£ã—ã€FFNã«inputã™ã‚‹ã“ã¨ã§è¡¨ç¾åŠ›ã‚’é«˜ã‚ã‚‹ã€‚ã¾ãŸã€filter vectoræ™®é€šã«å®Ÿè£…ã™ã‚‹ã¨word embeddingã¨åŒã˜ã‚µã‚¤ã‚ºã®ãƒ¡ãƒ¢ãƒªã‚’æ¶ˆè²»ã—ã¦ã—ã¾ã†ãŸã‚ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®è‰¯ã„filter vectoråŠ¹ç‡æ‰‹æ³•ã‚‚ææ¡ˆã—ã¦ã„ã‚‹ã€‚æ©Ÿæ¢°ç¿»è¨³ãƒ»ãŠã‚ˆã³æ–‡æ›¸è¦ç´„ã‚’è¡Œã†Transformerã«ææ¡ˆæ‰‹æ³•ã‚’é©ç”¨ã—ãŸã¨ã“ã‚ã€ã‚ˆã‚Šå°‘é‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§comparableãªã‚¹ã‚³ã‚¢ã‚’é”æˆã—ãŸã€‚</p>
<p>Embedidngã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¨BLEUã‚¹ã‚³ã‚¢ã®æ¯”è¼ƒã€‚ã‚ˆã‚Šå°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§comparableãªæ€§èƒ½ã‚’é”æˆã—ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/121308824-700c3100-c93c-11eb-8d15-629d896f9db8.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/DialogueGeneration.html" target="_blank" rel="noopener noreferrer">#DialogueGeneration</a>
<a class="button" href="articles/PersonalizedGeneration.html" target="_blank" rel="noopener noreferrer">#PersonalizedGeneration</a>
<span class="issue_date">Issue Date: 2021-06-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/367" target="_blank" rel="noopener noreferrer" class="title-link">NUBIA, EvalNLGEval'20</a>
<span class="snippet"><span>Comment</span><p>TextGenerationã«é–¢ã™ã‚‹SoTAã®æ€§èƒ½æŒ‡æ¨™ã€‚BLEU, ROUGEç­‰ã¨æ¯”è¼ƒã—ã¦ã€äººé–“ã¨ã®ç›¸é–¢ãŒé«˜ã„ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/120425437-299d5c00-c3a9-11eb-9236-8bfdf494fa60.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120425509-4e91cf00-c3a9-11eb-9666-dc1069cde3cc.png" alt="image" loading="lazy"><br><br>pretrainedã•ã‚ŒãŸlanguage modelï¼ˆGPT-2=sentence legibility, RoBERTa_MNLI=logical inference, RoBERTa_STS=semantic similarityï¼‰ã‚’ä½¿ã„ã€Fully Connected Layerã‚’åˆ©ç”¨ã—ã¦quality ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã™ã‚‹ã€‚ç®—å‡ºã—ãŸã‚¹ã‚³ã‚¢ã¯æœ€çµ‚çš„ã«calibrationã§0~1ã®å€¤åŸŸã«åã¾ã‚‹ã‚ˆã†ã«è£œæ­£ã•ã‚Œã‚‹ã€‚</p>
<p>æ„å‘³çš„ã«åŒç­‰ã®å†…å®¹ã‚’è¿°ã¹ãŸæ–‡é–“ã§ã®example<br><br><img src="https://user-images.githubusercontent.com/12249301/120425803-d37ce880-c3a9-11eb-938c-09747999cc7c.png" alt="image" loading="lazy"><br><br>BLEU, ROUGE, BERTã®ã‚¹ã‚³ã‚¢ã¯ä½ã„ãŒã€NUBIAã§ã¯éå¸¸ã«é«˜ã„ã‚¹ã‚³ã‚¢ã‚’å‡ºã›ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2021-03-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/343" target="_blank" rel="noopener noreferrer" class="title-link">Unsupervised Opinion Summarization as Copycat-Review Generation, BraÅ¾inskas, ACL'20</a>
<span class="snippet"><span>GPT Summary</span>- æ„è¦‹è¦ç´„ã¯ã€è£½å“ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰ä¸»è¦³çš„æƒ…å ±ã‚’è‡ªå‹•çš„ã«è¦ç´„ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã‚ã‚Šã€å¾“æ¥ã®ç ”ç©¶ã¯æŠ½å‡ºçš„æ‰‹æ³•ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ãŸãŒã€æœ¬ç ”ç©¶ã§ã¯æ–°ã—ã„æ–‡ã‚’ç”Ÿæˆã™ã‚‹æŠ½è±¡çš„è¦ç´„ã‚’ææ¡ˆã™ã‚‹ã€‚æ•™å¸«ãªã—è¨­å®šã§ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©ã—ã€æ–°è¦æ€§ã‚’åˆ¶å¾¡ã—ãªãŒã‚‰åˆæ„ã•ã‚ŒãŸæ„è¦‹ã‚’åæ˜ ã™ã‚‹è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ã€‚éšå±¤çš„å¤‰åˆ†ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã€å®Ÿé¨“ã«ã‚ˆã‚Šæµæš¢ã§ä¸€è²«æ€§ã®ã‚ã‚‹è¦ç´„ãŒç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2020-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/337" target="_blank" rel="noopener noreferrer" class="title-link">Evaluation of Text Generation: A Survey, Celikyilmaz, Clark, Gao, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€è‡ªç„¶è¨€èªç”Ÿæˆï¼ˆNLGï¼‰ã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡æ–¹æ³•ã‚’äººé–“ä¸­å¿ƒã€è‡ªå‹•è©•ä¾¡ã€æ©Ÿæ¢°å­¦ç¿’ã«åŸºã¥ãè©•ä¾¡ã®3ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ã—ã€ãã‚Œãã‚Œã®é€²å±•ã¨èª²é¡Œã‚’è­°è«–ã€‚ç‰¹ã«æ–°ã—ã„NLGã‚¿ã‚¹ã‚¯ã‚„ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«NLGãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã«ç„¦ç‚¹ã‚’å½“ã¦ã€è‡ªå‹•ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã¨é•·æ–‡ç”Ÿæˆã®ä¾‹ã‚’ç¤ºã—ã€ä»Šå¾Œã®ç ”ç©¶æ–¹å‘æ€§ã‚’ææ¡ˆã—ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2605" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Universal Transformers, Mostafa Dehghani+, ICLR'19</a>
<span class="snippet"><span>GPT Summary</span>- å†å¸°ç¥çµŒãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆRNNï¼‰ã¯é€æ¬¡å‡¦ç†ã«ã‚ˆã‚Šã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã§åºƒãä½¿ã‚ã‚Œã¦ããŸãŒã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒé…ããªã‚‹æ¬ ç‚¹ãŒã‚ã‚‹ã€‚æœ€è¿‘ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ã‚„ç•³ã¿è¾¼ã¿ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ä¸¦åˆ—å‡¦ç†ãŒå¯èƒ½ã§å„ªã‚ŒãŸçµæœã‚’å‡ºã—ã¦ã„ã‚‹ãŒã€RNNãŒå¾—æ„ã¨ã™ã‚‹å˜ç´”ãªã‚¿ã‚¹ã‚¯ã§ã®ä¸€èˆ¬åŒ–ã«ã¯å¤±æ•—ã™ã‚‹ã€‚ãã“ã§ã€æˆ‘ã€…ã¯ãƒ¦ãƒ‹ãƒãƒ¼ã‚µãƒ«ãƒ»ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ï¼ˆUTï¼‰ã‚’ææ¡ˆã—ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ã®ä¸¦åˆ—å‡¦ç†èƒ½åŠ›ã¨RNNã®å¸°ç´ãƒã‚¤ã‚¢ã‚¹ã‚’çµ„ã¿åˆã‚ã›ãŸãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã—ãŸã€‚UTã¯ç‰¹å®šã®æ¡ä»¶ä¸‹ã§ãƒãƒ¥ãƒ¼ãƒªãƒ³ã‚°å®Œå…¨ã§ã‚ã‚Šã€å®Ÿé¨“ã§ã¯æ¨™æº–çš„ãªãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ç‰¹ã«LAMBADAã‚¿ã‚¹ã‚¯ã§æ–°ãŸãªæœ€å…ˆç«¯ã‚’é”æˆã—ã€æ©Ÿæ¢°ç¿»è¨³ã§ã‚‚BLEUã‚¹ã‚³ã‚¢ã‚’æ”¹å–„ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=HyzdRiR9Y7" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=HyzdRiR9Y7</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2500" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Supervised Multimodal Bitransformers for Classifying Images and Text, Douwe Kiela+, arXiv'19</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒæƒ…å ±ã‚’èåˆã™ã‚‹ç›£è¦–å‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ“ãƒƒãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã€ã•ã¾ã–ã¾ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åˆ†é¡ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã€‚ç‰¹ã«ã€é›£æ˜“åº¦ã®é«˜ã„ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã‚‚å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹çµæœã‚’å¾—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚­ã‚¹ãƒˆ+imageã‚’ç”¨ã„ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªtransformer</p></span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/ReadingComprehension.html" target="_blank" rel="noopener noreferrer">#ReadingComprehension</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2450" target="_blank" rel="noopener noreferrer" class="title-link">Natural Questions: A Benchmark for Question Answering Research, Kwiatkowski+, TACL'19</a>
<span class="snippet"><span>GPT Summary</span>- Natural Questionsã‚³ãƒ¼ãƒ‘ã‚¹ã¯ã€Googleæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰ã®å®Ÿéš›ã®åŒ¿ååŒ–ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’åŸºã«ã—ãŸè³ªå•å¿œç­”ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€307,373ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã¨7,830ã®é–‹ç™ºä¾‹ã€7,842ã®ãƒ†ã‚¹ãƒˆä¾‹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã‚¢ãƒãƒ†ãƒ¼ã‚¿ãƒ¼ã¯ã€è³ªå•ã«å¯¾ã—ã¦Wikipediaãƒšãƒ¼ã‚¸ã‹ã‚‰é•·ã„å›ç­”ã¨çŸ­ã„å›ç­”ã‚’æ³¨é‡ˆã—ã€è³ªã®æ¤œè¨¼å®Ÿé¨“ã‚„äººé–“ã®å¤‰å‹•æ€§ã«é–¢ã™ã‚‹åˆ†æã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚ã¾ãŸã€è³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡ã®ãŸã‚ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å°å…¥ã—ã€ç«¶äº‰çš„æ‰‹æ³•ã‚’ç”¨ã„ã¦ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµæœã‚’ç¢ºç«‹ã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-08-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2357" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Equilibrium Models, Shaojie Bai+, NeurIPS'19</a>
<span class="snippet"><span>GPT Summary</span>- æ·±ã„å¹³è¡¡ãƒ¢ãƒ‡ãƒ«ï¼ˆDEQï¼‰ã‚’ææ¡ˆã—ã€é€æ¬¡ãƒ‡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«åŒ–ã«ãŠã„ã¦å¹³è¡¡ç‚¹ã‚’ç›´æ¥è¦‹ã¤ã‘ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç¤ºã™ã€‚DEQã¯ç„¡é™ã®æ·±ã•ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’è§£æçš„ã«é€†ä¼æ’­å¯èƒ½ã«ã—ã€å®šæ•°ãƒ¡ãƒ¢ãƒªã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨äºˆæ¸¬ã‚’è¡Œãˆã‚‹ã€‚è‡ªå·±æ³¨æ„ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚„ãƒˆãƒ¬ãƒªã‚¹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«é©ç”¨ã—ã€WikiText-103ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã€è¨ˆç®—è¦ä»¶ã®ç¶­æŒã€ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ã®æœ€å¤§88%å‰Šæ¸›ã‚’å®Ÿè¨¼ã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2024-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1446" target="_blank" rel="noopener noreferrer" class="title-link">What Does BERT Learn about the Structure of Language?, Jawahar+, ACL'19</a>
<span class="snippet"><span>GPT Summary</span>- BERTã¯è¨€èªç†è§£ã«ãŠã„ã¦å„ªã‚ŒãŸæˆæœã‚’ä¸Šã’ã¦ãŠã‚Šã€æœ¬ç ”ç©¶ã§ã¯ãã®è¨€èªæ§‹é€ ã®è¦ç´ ã‚’è§£æ˜ã™ã‚‹å®Ÿé¨“ã‚’è¡Œã£ãŸã€‚ä¸»ãªç™ºè¦‹ã¯ã€ãƒ•ãƒ¬ãƒ¼ã‚ºè¡¨ç¾ãŒãƒ•ãƒ¬ãƒ¼ã‚ºãƒ¬ãƒ™ãƒ«ã®æƒ…å ±ã‚’æ‰ãˆã€ä¸­é–“å±¤ãŒæ§‹æ–‡çš„ãŠã‚ˆã³æ„å‘³çš„ç‰¹å¾´ã®éšå±¤ã‚’å½¢æˆã—ã€é•·æœŸä¾å­˜æ€§ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«æ·±ã„å±¤ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã€ã•ã‚‰ã«BERTã®æ§‹æˆãŒå¤å…¸çš„ãªæœ¨æ§‹é€ ã«é¡ä¼¼ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1370" target="_blank" rel="noopener noreferrer">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« (LLM) ã®æŠ€è¡“ã¨æœ€æ–°å‹•å‘, Ikuya Yamada, 2024.06</a>
 ä¸­ã§å¼•ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚Transformerã®å„ãƒ–ãƒ­ãƒƒã‚¯ãŒã€ä½•ã‚’å­¦ç¿’ã—ã¦ã„ã‚‹ã‹ã‚’åˆ†æã€‚</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1272" target="_blank" rel="noopener noreferrer" class="title-link">Fast Transformer Decoding: One Write-Head is All You Need, Noam Shazeer, N_A, arXiv'19</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒãƒ˜ãƒƒãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯é«˜é€Ÿã‹ã¤ç°¡å˜ã ãŒã€å¢—åˆ†æ¨è«–ã¯å¤§ããª"keys"ã¨"values"ãƒ†ãƒ³ã‚½ãƒ«ã‚’ç¹°ã‚Šè¿”ã—èª­ã¿è¾¼ã‚€ãŸã‚ã«é…ããªã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ãã“ã§ã€ã‚­ãƒ¼ã¨å€¤ã‚’å…±æœ‰ã™ã‚‹ãƒãƒ«ãƒã‚¯ã‚¨ãƒªã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’ææ¡ˆã—ã€ãƒ¡ãƒ¢ãƒªå¸¯åŸŸå¹…è¦ä»¶ã‚’ä½æ¸›ã™ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€é«˜é€Ÿãªãƒ‡ã‚³ãƒ¼ãƒ‰ãŒå¯èƒ½ã§ã€ã‚ãšã‹ãªå“è³ªã®ä½ä¸‹ã—ã‹ãªã„ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Multi Query Attentionè«–æ–‡ã€‚KVã®setã«å¯¾ã—ã¦ã€å˜ä¸€ã®Queryã®ã¿ã§Multi-Head Attentionã‚’ä»£æ›¿ã™ã‚‹ã€‚åŠ‡çš„ã«Decoderã®InferenceãŒæ—©ããªã‚Šãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒæ¸›ã‚‹ãŒã€è«–æ–‡ä¸­ã§ã¯è¨€åŠã•ã‚Œã¦ã„ãªã„ï¼Ÿã‚ˆã†ã ãŒã€æ€§èƒ½ã¨å­¦ç¿’ã®å®‰å®šæ€§ãŒèª²é¡Œã¨ãªã‚‹ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e2d77b43-70c3-4922-a822-bf95d6b4704f" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<span class="issue_date">Issue Date: 2023-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1022" target="_blank" rel="noopener noreferrer" class="title-link">Text Summarization with Pretrained Encoders, Liu+ ï¼ˆwith Lapataï¼‰, EMNLP-IJCNLP'19</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æœ€æ–°ã®äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹BERTã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã®ãŸã‚ã®ä¸€èˆ¬çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¾ã™ã€‚æŠ½å‡ºå‹ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€æ–°ã—ã„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’å°å…¥ã—ã€æ–‡ã®è¡¨ç¾ã‚’å–å¾—ã—ã¾ã™ã€‚æŠ½è±¡çš„ãªè¦ç´„ã«ã¤ã„ã¦ã¯ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¨ãƒ‡ã‚³ãƒ¼ãƒ€ã®æœ€é©åŒ–æ‰‹æ³•ã‚’ç•°ãªã‚‰ã›ã‚‹ã“ã¨ã§ä¸ä¸€è‡´ã‚’ç·©å’Œã—ã¾ã™ã€‚ã•ã‚‰ã«ã€2æ®µéšã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã£ã¦è¦ç´„ã®å“è³ªã‚’å‘ä¸Šã•ã›ã¾ã—ãŸã€‚å®Ÿé¨“çµæœã¯ã€ææ¡ˆæ‰‹æ³•ãŒæœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>BERTSUMEXTè«–æ–‡</p>
<p>é€šå¸¸ã®BERTã®æ§‹é€ ã¨æ¯”è¼ƒã—ã¦ã€æ–‡ã”ã¨ã®å…ˆé ­ã«[CLS]ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŒ¿å…¥ã—ã€ã‹ã¤Segment Embeddingsã‚’æ–‡ã”ã¨ã«äº¤äº’ã«å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã€æ–‡ã®representationã‚’å–å¾—ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚<br><br>ãã®å¾Œã€encodingã•ã‚ŒãŸsentenceã®[CLS]ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾å¿œã™ã‚‹embeddingã®ä¸Šã«ã€inter-sentence Transformer layerã‚’é‡ã­ã€sigmoidã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹ã®ãŒã€BERTSUMEXT, Abstractiveã®å ´åˆã¯6-layerã®Transformer decoderã‚’åˆ©ç”¨ã™ã‚‹ãŒã€ã“ã‚Œã¯ã‚¹ã‚¯ãƒ©ãƒƒãƒã§finetuninigã•ã›ã‚‹ã€‚ã“ã®ã¨ãã€encoderå´ã¯overfit, decoderå´ã¯underfitã™ã‚‹ã“ã¨ãŒäºˆæƒ³ã•ã‚Œã‚‹ãŸã‚ã€encoderã¨decodeã§ç•°ãªã‚‹warmup, å­¦ç¿’ç‡ã‚’é©ç”¨ã™ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€encoderå´ã¯ã‚ˆã‚Šå°ã•ã„å­¦ç¿’ç‡ã§ã€ã•ã‚‰ã«smoothã«æ¸›è¡°ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€decoderå´ãŒå®‰å®šã—ãŸã¨ãã«ã‚ˆã‚Šæ­£ç¢ºãªå‹¾é…ã§å­¦ç¿’ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚ã¾ãŸã€2-stageã®finetuningã‚’ææ¡ˆã—ã€ã¾ãšencoderå´ã‚’extractifve summarization taskã§finetuningã—ã€ãã®å¾Œabstractive summarizationã§finetuningã™ã‚‹ã€‚å…ˆè¡Œç ”ç©¶ã§ã¯extractive summarizationã®objectiveã‚’å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ã§abstractive summarizationã®æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã‚‹ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ãŠã‚Šã€ã“ã®çŸ¥è¦‹ã‚’å–ã‚Šå…¥ã‚Œã‚‹ã€‚ä»Šå›ã¯extractive summarizationã®é‡ã¿ã‚’abstractive taskã«trasnferã™ã‚‹ã“ã¨ã«ãªã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/957647e3-06e5-44cf-835e-bb25166872fd" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/996" target="_blank" rel="noopener noreferrer" class="title-link">Neural Text Summarization: A Critical Evaluation, Krysciski+ ï¼ˆw_ Richard Socherï¼‰, EMNLP-IJCNLP'19</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã®ç ”ç©¶ã¯é€²å±•ãŒåœæ»ã—ã¦ãŠã‚Šã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€è©•ä¾¡æŒ‡æ¨™ã€ãƒ¢ãƒ‡ãƒ«ã®3ã¤ã®è¦ç´ ã«å•é¡ŒãŒã‚ã‚‹ã“ã¨ãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹ã€‚è‡ªå‹•åé›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯åˆ¶ç´„ãŒä¸ååˆ†ã§ã‚ã‚Šã€ãƒã‚¤ã‚ºã‚’å«ã‚“ã§ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¯äººé–“ã®åˆ¤æ–­ã¨ç›¸é–¢ãŒå¼±ãã€é‡è¦ãªç‰¹æ€§ã‚’è€ƒæ…®ã—ã¦ã„ãªã„ã€‚ãƒ¢ãƒ‡ãƒ«ã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒã‚¤ã‚¢ã‚¹ã«éé©åˆã—ã€å‡ºåŠ›ã®å¤šæ§˜æ€§ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/QA-based.html" target="_blank" rel="noopener noreferrer">#QA-based</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/995" target="_blank" rel="noopener noreferrer" class="title-link">Question answering as an automatic evaluation metric for news article summarization, Eyal+, NAACL'19</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®è‡ªå‹•è¦ç´„ã®ç ”ç©¶ã§ã¯ã€ROUGEã‚¹ã‚³ã‚¢ã®æœ€å¤§åŒ–ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ãŒã€æœ¬ç ”ç©¶ã§ã¯ä»£æ›¿çš„ãªè©•ä¾¡æŒ‡æ¨™ã§ã‚ã‚‹APESã‚’ææ¡ˆã™ã‚‹ã€‚APESã¯ã€è¦ç´„ãŒä¸€é€£ã®æ‰‹å‹•ä½œæˆè³ªå•ã«ç­”ãˆã‚‹èƒ½åŠ›ã‚’å®šé‡åŒ–ã™ã‚‹ã€‚APESã‚’æœ€å¤§åŒ–ã™ã‚‹ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æŠ½è±¡ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã€ROUGEã‚¹ã‚³ã‚¢ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>APES</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/990" target="_blank" rel="noopener noreferrer" class="title-link">Studying Summarization Evaluation Metrics in the Appropriate Scoring Range, Peyrard+, ACL'19</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå‹•è©•ä¾¡ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¯é€šå¸¸ã€äººé–“ã®åˆ¤æ–­ã¨ã®ç›¸é–¢æ€§ã‚’åŸºæº–ã«æ¯”è¼ƒã•ã‚Œã‚‹ãŒã€æ—¢å­˜ã®äººé–“ã®åˆ¤æ–­ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯é™ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ç¾ä»£ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã“ã‚Œã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸Šã§é«˜ã‚¹ã‚³ã‚¢ã‚’å‡ºã™ãŒã€è©•ä¾¡ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®çµæœã¯ç•°ãªã‚‹ã€‚é«˜ã‚¹ã‚³ã‚¢ã®è¦ç´„ã«å¯¾ã™ã‚‹äººé–“ã®åˆ¤æ–­ã‚’åé›†ã™ã‚‹ã“ã¨ã§ã€ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®ä¿¡é ¼æ€§ã‚’è§£æ±ºã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã“ã‚Œã¯è¦ç´„ã‚·ã‚¹ãƒ†ãƒ ã¨ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®æ”¹å–„ã«å½¹ç«‹ã¤ã€‚</span>
<span class="snippet"><span>Comment</span><p>è¦ç´„ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ãŒhuman judgmentsã«å¯¾ã—ã¦correlationãŒä½ã„ã“ã¨ã‚’æŒ‡æ‘˜</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/986" target="_blank" rel="noopener noreferrer" class="title-link">HighRES: Highlight-based Reference-less Evaluation of Summarization, Hardy+, N_A, ACL'19</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ã®æ‰‹å‹•è©•ä¾¡ã¯ä¸€è²«æ€§ãŒãªãå›°é›£ãªãŸã‚ã€æ–°ã—ã„æ‰‹æ³•ã§ã‚ã‚‹HighRESã‚’ææ¡ˆã™ã‚‹ã€‚ã“ã®æ‰‹æ³•ã§ã¯ã€è¦ç´„ã¯ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨æ¯”è¼ƒã—ã¦è¤‡æ•°ã®ã‚¢ãƒãƒ†ãƒ¼ã‚¿ãƒ¼ã«ã‚ˆã£ã¦è©•ä¾¡ã•ã‚Œã€ã‚½ãƒ¼ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯é‡è¦ãªå†…å®¹ãŒãƒã‚¤ãƒ©ã‚¤ãƒˆã•ã‚Œã‚‹ã€‚HighRESã¯ã‚¢ãƒãƒ†ãƒ¼ã‚¿ãƒ¼é–“ã®ä¸€è‡´åº¦ã‚’å‘ä¸Šã•ã›ã€ã‚·ã‚¹ãƒ†ãƒ é–“ã®é•ã„ã‚’å¼·èª¿ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>äººæ‰‹è©•ä¾¡ã®æ çµ„ã¿</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/TrainedMetrics.html" target="_blank" rel="noopener noreferrer">#TrainedMetrics</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/954" target="_blank" rel="noopener noreferrer" class="title-link">Machine Translation Evaluation with BERT Regressor, Hiroki Shimanaka+, N_A, arXiv'19</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€BERTã‚’ä½¿ç”¨ã—ãŸè‡ªå‹•çš„ãªæ©Ÿæ¢°ç¿»è¨³ã®è©•ä¾¡ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ç§ãŸã¡ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ãŒã™ã¹ã¦ã®è‹±èªå¯¾å¿œè¨€èªãƒšã‚¢ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/946" target="_blank" rel="noopener noreferrer" class="title-link">MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance, Zhao+, EMNLP-IJCNLP'19</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡å°ºåº¦ã«ã¤ã„ã¦èª¿æŸ»ã—ã€ã‚·ã‚¹ãƒ†ãƒ ã®å‡ºåŠ›ã¨å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆã®æ„å‘³ã«åŸºã¥ã„ã¦æ¯”è¼ƒã™ã‚‹å°ºåº¦ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®å°ºåº¦ã¯ã€è¦ç´„ã€æ©Ÿæ¢°ç¿»è¨³ã€ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¸ã®ç”Ÿæˆãªã©ã®ã‚¿ã‚¹ã‚¯ã§æœ‰åŠ¹ã§ã‚ã‚Šã€æ–‡è„ˆåŒ–è¡¨ç¾ã¨è·é›¢å°ºåº¦ã‚’çµ„ã¿åˆã‚ã›ãŸã‚‚ã®ãŒæœ€ã‚‚å„ªã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€ææ¡ˆã—ãŸå°ºåº¦ã¯å¼·åŠ›ãªæ±åŒ–èƒ½åŠ›ã‚’æŒã£ã¦ãŠã‚Šã€ã‚¦ã‚§ãƒ–ã‚µãƒ¼ãƒ“ã‚¹ã¨ã—ã¦æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Word Mover Distance (WMD)ã®è§£èª¬: 


<a href="https://yubessy.hatenablog.com/entry/2017/01/10/122737" target="_blank" rel="noopener noreferrer">https://yubessy.hatenablog.com/entry/2017/01/10/122737</a>


</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/QA-based.html" target="_blank" rel="noopener noreferrer">#QA-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/943" target="_blank" rel="noopener noreferrer" class="title-link">Answers Unite Unsupervised Metrics for Reinforced Summarization Models, Scialom+, EMNLP-IJCNLP'19</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã€å†å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã‚’ä½¿ç”¨ã—ãŸæŠ½è±¡çš„è¦ç´„æ‰‹æ³•ãŒææ¡ˆã•ã‚Œã¦ãŠã‚Šã€å¾“æ¥ã®å°¤åº¦æœ€å¤§åŒ–ã‚’å…‹æœã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ã€è¤‡é›‘ã§å¾®åˆ†ä¸å¯èƒ½ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è€ƒæ…®ã™ã‚‹ã“ã¨ã§ã€ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã®å“è³ªã¨é–¢é€£æ€§ã‚’ç·åˆçš„ã«è©•ä¾¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ROUGEã¨ã„ã†å¾“æ¥ã®è¦ç´„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«ã¯ã„ãã¤ã‹ã®å•é¡ŒãŒã‚ã‚Šã€ä»£æ›¿çš„ãªè©•ä¾¡å°ºåº¦ã‚’æ¢æ±‚ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚å ±å‘Šã•ã‚ŒãŸäººé–“è©•ä¾¡ã®åˆ†æã«ã‚ˆã‚‹ã¨ã€è³ªå•å¿œç­”ã«åŸºã¥ãææ¡ˆã•ã‚ŒãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¯ROUGEã‚ˆã‚Šã‚‚æœ‰åˆ©ã§ã‚ã‚Šã€å‚ç…§è¦ç´„ã‚’å¿…è¦ã¨ã—ãªã„ã¨ã„ã†ç‰¹å¾´ã‚‚æŒã£ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ä½¿ç”¨ã—ã¦RLãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã¯ã€ç¾åœ¨ã®æ‰‹æ³•ã«æ¯”ã¹ã¦æ”¹å–„ã‚’ã‚‚ãŸã‚‰ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>SummaQA</p></span><br><br>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2023-05-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/664" target="_blank" rel="noopener noreferrer" class="title-link">Towards Personalized Review Summarization via User-Aware Sequence Network, Li+, AAAI'19</a>
<span class="snippet"><span>Comment</span><p>åŒã˜ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«å¯¾ã—ã¦ã‚‚ã€ç•°ãªã‚‹ãƒ¦ãƒ¼ã‚¶ã¯ç•°ãªã‚‹Sumamryã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã­ã€ã¨ã„ã†ã¨ã“ã‚ãŒãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãªã‚Šã€Personalized Review Summarizationã‚’ææ¡ˆã€‚åˆã‚ã¦Personalizationã®å•é¡Œã«ã¤ã„ã¦ææ¡ˆã—ãŸç ”ç©¶ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/236725073-bdcc6939-0582-4860-a20c-664e779d7a10.png" alt="image" loading="lazy"><br><br></p>
<p>user embeddingã«ã‚ˆã£ã¦ãƒ¦ãƒ¼ã‚¶æƒ…å ±ã‚’åŸ‹ã‚è¾¼ã‚€æ–¹æ³•ã¨ã€user vocabulary memoryã«ã‚ˆã£ã¦ã€ãƒ¦ãƒ¼ã‚¶ãŒå¥½ã‚€vocabularyã‚’ç©æ¥µçš„ã«summaryã«åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®2ç¨®é¡ã‚’ãƒ¢ãƒ‡ãƒ«ã«å°å…¥ã—ã¦ã„ã‚‹<br><br><img src="https://user-images.githubusercontent.com/12249301/236726239-b5397c99-fcd9-4fde-8638-98ca44e23e15.png" alt="image" loading="lazy"><br><br><br><br>Trip advisorã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã€‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®titleã‚’reference summaryã¨ã¿ãªã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆã€‚ãŸã ã‚¿ã‚¤ãƒˆãƒ«ã‚’åˆ©ç”¨ã™ã‚‹ã ã‘ã ã¨ã€ç„¡æ„å‘³ãªã‚¿ã‚¤ãƒˆãƒ«ãŒå¤šãå«ã¾ã‚Œã¦ã„ã‚‹ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/236726405-2a6c6c7f-fb32-4e7b-92c0-2380fbd86946.png" alt="image" loading="lazy"><br><br><br><br>Trip Advisorã¯ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚’ç¦æ­¢ã—ã¦ã„ãŸæ°—ãŒã™ã‚‹ã®ã§ã€å‰²ã¨ã‚¢ã‚¦ãƒˆãªã®ã§ã¯ã€‚<br><br>ã‚ã¨ã€å„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«splitã—ã¦train/dev/testã‚’ä½œæˆã—ãŸã¨è¨€ã£ã¦ã„ã‚‹ãŒã€æœ¬å½“ã«ãã‚Œã§ã„ã„ã®ï¼Ÿuser-stratifiedãªsplitã‚’ã—ãŸæ–¹ãŒè‰¯ã„ã¨æ€ã†ã€‚<br><br><br><br>PGN <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/135" target="_blank" rel="noopener noreferrer">[Paper Note] Get To The Point: Summarization with Pointer-Generator Networks, See+, ACL'17</a>
 ã‚„lead-1ã¨æ¯”è¼ƒã—ãŸçµæœã€ROUGEã®è¦³ç‚¹ã§é«˜ã„æ€§èƒ½ã‚’é”æˆ<br><br><img src="https://user-images.githubusercontent.com/12249301/236726684-b85a20e7-0750-4d51-ad97-1603a9f944c5.png" alt="image" loading="lazy"><br><br><br><br>ã¾ãŸäººæ‰‹è©•ä¾¡ã¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ã®gold summaryã«å«ã¾ã‚Œã‚‹aspectã¨ã€generated summaryã«å«ã¾ã‚Œã‚‹aspectãŒã©ã‚Œã ã‘ä¸€è‡´ã—ã¦ã„ã‚‹ã‹ã€1000ä»¶ã®reviewã¨test setã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦2äººã®å­¦ç”Ÿã«ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ã‚‚ã‚‰ã£ãŸã€‚çµæœçš„ã«ææ¡ˆæ‰‹æ³•ãŒæœ€ã‚‚ã‚ˆã‹ã£ãŸãŒã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ—ãƒ­ã‚»ã‚¹ã®å…·ä½“æ€§ãŒè–„ã™ãã‚‹ã€‚2äººã®å­¦ç”Ÿã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚«ãƒƒãƒ‘ä¿‚æ•°ã™ã‚‰æ›¸ã‹ã‚Œã¦ã„ãªã„ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/236727342-4548b5e6-ecda-4503-a628-6448a4bd39b7.png" alt="image" loading="lazy"><br><br><br><br>case studyã¨ã—ã¦ã‚ã‚‹ãƒ¦ãƒ¼ã‚¶ã®ãƒ¬ãƒ“ãƒ¥ã¨ç”Ÿæˆä¾‹ã‚’ã®ã›ã¦ã„ã‚‹ã€‚userBã®éå»ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¦‹ãŸã‚‰ã€room, locationã«è¨€åŠã—ã¦ã„ã‚‹ã‚‚ã®ãŒå¤§åŠã§ã‚ã‚Šã€ã“ã®ã‚¢ã‚¹ãƒšã‚¯ãƒˆã‚’ãã¡ã‚“ã¨å«ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã‚ˆã­ã€ã¨ã„ã†ã“ã¨ã‚’ä¸»å¼µã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/236727590-8a4972d1-f700-494c-9046-9f86769117c3.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/review.html" target="_blank" rel="noopener noreferrer">#review</a>
<span class="issue_date">Issue Date: 2023-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/658" target="_blank" rel="noopener noreferrer" class="title-link">Neural Review Summarization Leveraging User and Product Information, Liu+, CIKM'19</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<span class="issue_date">Issue Date: 2022-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/462" target="_blank" rel="noopener noreferrer" class="title-link">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks, Reimers+, UKP-TUDA, EMNLP'19</a>
<span class="snippet"><span>Comment</span><p>BERTã§ãƒˆãƒ¼ã‚¯ãƒ³ã‚’embeddingã—ã€mean poolingã™ã‚‹ã“ã¨ã§ç”Ÿæˆã•ã‚Œã‚‹æ–‡ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã€Siamese Networkã‚’ä½¿ã„è·é›¢å­¦ç¿’ï¼ˆfinetuneï¼‰ã•ã›ãŸãƒ¢ãƒ‡ãƒ«ã€‚<br><br>&lt;img width="655" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/181723384-06c1a65a-985a-48bd-b7d8-b284e070b675.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/181723384-06c1a65a-985a-48bd-b7d8-b284e070b675.png"&lt;/a&gt;


&gt;<br><br><br><br>æ–‡/æ–‡ç« ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ç°¡å˜ã«æ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚<br><br>ãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦§ã¯ä¸‹è¨˜ï¼š


<a href="https://www.sbert.net/docs/pretrained_models.html" target="_blank" rel="noopener noreferrer">https://www.sbert.net/docs/pretrained_models.html</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2021-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/408" target="_blank" rel="noopener noreferrer" class="title-link">Table-to-Text Generation with Effective Hierarchical Encoder on Three Dimensions ï¼ˆRow, Column and Timeï¼‰, Gong+, Harbin Institute of Technology, EMNLP'19</a>
<span class="snippet"><span>Comment</span><p>
<strong>## æ¦‚è¦<br><br>æ—¢å­˜ç ”ç©¶ã§ã¯ã€tableã‚’ãƒ¬ã‚³ãƒ¼ãƒ‰ã®é›†åˆ, ã‚ã‚‹ã„ã¯long sequenceã¨ã—ã¦encodeã—ã¦ããŸãŒ<br><br><br><br>1. other (column) dimensionã®æƒ…å ±ãŒå¤±ã‚ã‚Œã¦ã—ã¾ã† (?)<br><br>2. table cellã¯æ™‚é–“ã«ã‚ˆã£ã¦å¤‰åŒ–ã™ã‚‹time-series data<br><br><br><br>ã¨ã„ã†ç‰¹å¾´ãŒã‚ã‚‹ã€‚<br><br>ãŸã¨ãˆã°ã€ã‚ã‚‹é¸æ‰‹ã®æˆç¸¾ã«ã¤ã„ã¦è¨€åŠã™ã‚‹éš›ã«ã€ãã®è©¦åˆã«ã¤ã„ã¦ç€ç›®ã™ã‚‹ã ã‘ã§ãªãã¦ã€Œç›´è¿‘3è©¦åˆã§äºŒå›ç›®ã®ãƒ€ãƒ–ãƒ«ãƒ€ãƒ–ãƒ«ã§ã™ã€ã¨ã„ã†ã‚ˆã†ã«ç›´è¿‘ã®è©¦åˆã‚‚è€ƒæ…®ã—ã¦è¨€åŠã™ã‚‹ã“ã¨ãŒã‚ã‚Šã€table cellã® time dimensionã«ã¤ã„ã¦ã‚‚ç€ç›®ã—ãªã‘ã‚Œã°ãªã‚‰ãšã€ã“ã‚Œã‚‰ã¯ã“ã‚Œã¾ã§ã®ãƒ¢ãƒ‡ãƒ«ã§å®Ÿç¾ã§ããªã„ã€‚<br><br>ãã“ã§ã€ã“ã®ç ”ç©¶ã§ã¯time dimensionã«ã¤ã„ã¦ã‚‚è€ƒæ…®ã—ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚<br><br><br><br>## ãƒ¢ãƒ‡ãƒ«æ¦‚è¦<br><br><img src="https://user-images.githubusercontent.com/12249301/138917272-e920b08a-5f44-4e56-8f7e-d3eb3fab7ec3.png" alt="image" loading="lazy"><br><br><br><br>å…¨ä½“ã¨ã—ã¦ã¯ã€Row Dimension Encoder, Column Dimension Encoder, Time Dimension Encoderã«ã‚ˆã£ã¦æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€self-attentionã‚’åˆ©ç”¨ã—ã¦ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®å„ã‚»ãƒ«ã”ã¨ã« Row-Dimension, Column-Dimension, Time-Dimensionã®Representationã‚’ç²å¾—ã™ã‚‹ã€‚ã‚¤ãƒ¡ãƒ¼ã‚¸ã¨ã—ã¦ã¯ã€<br><br><br><br>- Row Dimension Encoderã«ã‚ˆã£ã¦ã€è‡ªèº«ã®ã‚»ãƒ«ã¨åŒã˜è¡Œã«å«ã¾ã‚Œã‚‹ã‚»ãƒ«ã¨ã®é–¢é€£åº¦ã‚’è€ƒæ…®ã—ãŸè¡¨ç¾<br><br>- Column Dimension Encoderã«ã‚ˆã£ã¦ã€è‡ªèº«ã®ã‚»ãƒ«ã¨åŒã˜åˆ—ã«å«ã¾ã‚Œã‚‹ã‚»ãƒ«ã¨ã®é–¢é€£åº¦ã‚’è€ƒæ…®ã—ãŸè¡¨ç¾<br><br>- Time Dimension Encoderã«ã‚ˆã£ã¦ã€éå»ã®æ™‚ç³»åˆ—ã®ã‚»ãƒ«ã¨ã®é–¢é€£åº¦ã‚’è€ƒæ…®ã—ãŸè¡¨ç¾<br><br><br><br>ã‚’ãã‚Œãã‚Œç²å¾—ã™ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã€‚å„Dimension Encoderã§ã‚„ã£ã¦ã„ã‚‹ã“ã¨ã¯ã€Puduppully (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/394" target="_blank" rel="noopener noreferrer">Data-to-Text Generation with Content Selection and Planning, Puduppully+, AAAI'19</a>
</strong>
<br>
) ã‚‰ã®Content Selection Gateç¯€ã«ãŠã‘ã‚‹attention vector r_{att}ã®å–å¾—æ–¹æ³•ã¨åŒæ§˜ã®ã‚‚ã®ï¼ˆã ã¨æ€ã‚ã‚Œã‚‹ï¼‰ã€‚<br><br><br><br>ç²å¾—ã—ãŸãã‚Œãã‚Œã®dimensionã®è¡¨ç¾ã‚’ç”¨ã„ã¦ã€ã¾ãšãã‚Œã‚‰ã‚’concatã—1 layer MLPã§å†™åƒã™ã‚‹ã“ã¨ã§å¾—ã‚‰ã‚Œã‚‹general representationã‚’å–å¾—ã™ã‚‹ã€‚ãã®å¾Œã€general representationã¨å„dimensionã®è¡¨ç¾ã‚’åŒæ§˜ã«1 layer MLPã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€å„dimensionã®è¡¨ç¾ã®é‡ã¿ã‚’æ±‚ã‚ã€ãã®é‡ã¿ã§å„representationã‚’ç·šå½¢çµåˆã™ã‚‹ã“ã¨ã§ã€ã‚»ãƒ«ã®è¡¨ç¾ã‚’ç²å¾—ã™ã‚‹ã€‚generalãªrepresentationã¨å„dimensionã®è¡¨ç¾ã®é–¢é€£æ€§ã«ã‚ˆã£ã¦é‡ã¿ã‚’æ±‚ã‚ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šç€ç›®ã™ã¹ãdimensionã‚’è€ƒæ…®ã—ãŸä¸Šã§ã€ã‚»ãƒ«ã®è¡¨ç¾ã‚’ç²å¾—ã§ãã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ãªã®ã ã‚ã†ã‹ã€‚<br><br>ãã®å¾Œã€å„ã‚»ãƒ«ã®è¡¨ç¾ã‚’è¡Œæ–¹å‘ã«å¯¾ã—ã¦MeanPoolingã‚’æ–½ã—row-levelã®è¡¨ç¾ã‚’å–å¾—ã€‚ç²å¾—ã—ãŸrow-levelã®è¡¨ç¾ã«å¯¾ã—ã€Puduppully (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/394" target="_blank" rel="noopener noreferrer">Data-to-Text Generation with Content Selection and Planning, Puduppully+, AAAI'19</a>
) ã‚‰ã®Content Selection Gate g ã‚’é©ç”¨ã™ã‚‹ï¼ˆã“ã‚Œã‚’ã©ã†ã‚„ã£ã¦ã„ã‚‹ã‹ãŒã‚ã‹ã‚‰ãªã„ï¼‰ã€‚<br><br><br><br>æœ€çµ‚çš„ã«æ±‚ã‚ãŸrow-levelã®è¡¨ç¾ã¨cell-levelã®è¡¨ç¾ã«å¯¾ã—ã¦ã€ãƒ‡ã‚³ãƒ¼ãƒ€ã®hidden stateã‚’åˆ©ç”¨ã—ã¦Dual Attentionã‚’è¡Œã„ã€row-levelã®è¡¨ç¾ã‹ã‚‰ã©ã®è¡Œã«ç€ç›®ã™ã¹ãã‹æ±ºã‚ãŸå¾Œã€ãã®è¡Œã®ä¸­ã‹ã‚‰ã©ã®ã‚»ãƒ«ã«ç€ç›®ã™ã‚‹ã‹æ±ºã‚ã‚‹ã€ã¨ã„ã£ãŸã‚¤ãƒ¡ãƒ¼ã‚¸ã§å„ã‚»ãƒ«ã®é‡ã¿ã‚’æ±‚ã‚ã‚‹ã€‚<br><br>è«–æ–‡ä¸­ã«ã¯ã“ã“ã¾ã§ã—ã‹æ›¸ã‹ã‚Œã¦ã„ãªã„ãŒã€æ±‚ã‚ãŸå„ã‚»ãƒ«ã®é‡ã¿ã§ã‚»ãƒ«ã®representationã‚’é‡ã¿ä»˜ã‘ã—ã¦è¶³ã—åˆã‚ã›ã€æœ€çµ‚çš„ã«ãã“ã‹ã‚‰å˜èªã‚’predictionã™ã‚‹ã®ã ã‚ã†ã‹ãƒ»ãƒ»ãƒ»ï¼Ÿã‚ˆãã‚ã‹ã‚‰ãªã„ã€‚</p>
<p><img src="https://user-images.githubusercontent.com/12249301/140321786-4d6a91c4-c864-490e-9921-5e6018db35c7.png" alt="image" loading="lazy"><br><br><br><br>RG, CS, CO, BLEUã‚¹ã‚³ã‚¢ã€å…¨ã¦ã«ãŠã„ã¦Baselineã‚’ä¸Šå›ã£ã¦ã„ã‚‹ï¼ˆRGã®Templateã‚’é™¤ãï¼‰ã€‚</p>
<p>å®Ÿè£…: 


<a href="https://github.com/ernestgong/data2text-three-dimensions/" target="_blank" rel="noopener noreferrer">https://github.com/ernestgong/data2text-three-dimensions/</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2021-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/394" target="_blank" rel="noopener noreferrer" class="title-link">Data-to-Text Generation with Content Selection and Planning, Puduppully+, AAAI'19</a>
<span class="snippet"><span>Comment</span><p>Rotowire Datasetã«å¯¾ã™ã‚‹Data2Textç ”ç©¶ã«ãŠã„ã¦ä»£è¡¨çš„ãªè«–æ–‡ã®ä¸€ã¤ã€‚Wisemanãƒ¢ãƒ‡ãƒ« <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/207" target="_blank" rel="noopener noreferrer">[Paper Note] Challenges in Data-to-Document Generation, Wiseman+ (with Rush), EMNLP'17</a>
 ã¨å…±ã«ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã—ã¦åˆ©ç”¨ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã€‚</p>
<p>å®Ÿè£…: 


<a href="https://github.com/ratishsp/data2text-plan-py" target="_blank" rel="noopener noreferrer">https://github.com/ratishsp/data2text-plan-py</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2021-06-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/388" target="_blank" rel="noopener noreferrer" class="title-link">On Empirical Comparisons of Optimizers for Deep Learning, Dami Choi+, N_A, arXiv'19</a>
<span class="snippet"><span>GPT Summary</span>- æ·±å±¤å­¦ç¿’ã®ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®æ¯”è¼ƒã¯é‡è¦ã§ã‚ã‚Šã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ¢ç´¢ç©ºé–“ãŒæ€§èƒ½ã«å½±éŸ¿ã™ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¦ã„ã‚‹ã€‚ç‰¹ã«ã€é©å¿œçš„å‹¾é…æ³•ã¯å¸¸ã«ä»–ã®ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã‚ˆã‚Šã‚‚æ€§èƒ½ãŒä½ä¸‹ã—ãªã„ã“ã¨ãŒå®Ÿé¨“ã§ç¤ºã•ã‚Œã¦ãŠã‚Šã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«é–¢ã™ã‚‹å®Ÿç”¨çš„ãªãƒ’ãƒ³ãƒˆã‚‚æä¾›ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>SGD, Momentum,RMSProp, Adam,NAdamç­‰ã®ä¸­ã‹ã‚‰ã€ã©ã®æœ€é©åŒ–æ‰‹æ³•(Optimizer)ãŒå„ªã‚Œã¦ã„ã‚‹ã‹ã‚’ç”»åƒåˆ†é¡ã¨è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦æ¯”è¼ƒã—ãŸç ”ç©¶ï¼ˆä¸‹è¨˜æ—¥æœ¬èªè§£èª¬è¨˜äº‹ã‹ã‚‰å¼•ç”¨ï¼‰</p>
<p>æ—¥æœ¬èªã§ã®è§£èª¬: 


<a href="https://akichan-f.medium.com/optimizer%E3%81%AF%E3%81%A9%E3%82%8C%E3%81%8C%E5%84%AA%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E3%81%8B-on-empirical-comparisons-of-optimizers-for-deep-learning%E3%81%AE%E7%B4%B9%E4%BB%8B-f843179e8a8d" target="_blank" rel="noopener noreferrer">https://akichan-f.medium.com/optimizerã¯ã©ã‚ŒãŒå„ªã‚Œã¦ã„ã‚‹ã‹-on-empirical-comparisons-of-optimizers-for-deep-learningã®ç´¹ä»‹-f843179e8a8d</a>


</p>
<p>AdamãŒè‰¯ã„ã®ã ã‘ã©ã€å­¦ç¿’ç‡ä»¥å¤–ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãªã„ã¨æœ¬æ¥ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç™ºæ®ã•ã‚Œãªã„ã‹ã‚‚ã‚ˆã€ã¨ã„ã†æ„Ÿã˜ã£ã½ã„</p>
<p>ICLR 2020 Open Review: 


<a href="https://openreview.net/forum?id=HygrAR4tPS" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=HygrAR4tPS</a>


</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=HygrAR4tPS" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=HygrAR4tPS</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/CommentGeneration.html" target="_blank" rel="noopener noreferrer">#CommentGeneration</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Workshop.html" target="_blank" rel="noopener noreferrer">#Workshop</a>
<span class="issue_date">Issue Date: 2019-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/323" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Automatic Generation of Personalized Comment Based on User Profile, Wenhuan Zeng+, ACL'19 SRW</a>
<span class="snippet"><span>GPT Summary</span>- ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢ã®å¤šæ§˜ãªã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã®é›£ã—ã•ã‚’è€ƒæ…®ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã«åŸºã¥ããƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã‚¿ã‚¹ã‚¯ï¼ˆAGPCï¼‰ã‚’ææ¡ˆã€‚ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºãƒ‰ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆPCGNï¼‰ã‚’ç”¨ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç‰¹å¾´ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€å¤–éƒ¨ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡¨ç¾ã‚’è€ƒæ…®ã™ã‚‹ã“ã¨ã§è‡ªç„¶ã§äººé–“ã‚‰ã—ã„ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã«æˆåŠŸã—ãŸã€‚</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/CommentGeneration.html" target="_blank" rel="noopener noreferrer">#CommentGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2019-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/322" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Coherent Comment Generation for Chinese Articles with a  Graph-to-Sequence Model, Wei Li+, arXiv'19</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå‹•è¨˜äº‹ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã®ãŸã‚ã«ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãƒˆãƒ”ãƒƒã‚¯ç›¸äº’ä½œç”¨ã‚°ãƒ©ãƒ•ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€ã‚°ãƒ©ãƒ•ã‹ã‚‰ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¸ã®ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¨˜äº‹ã®æ§‹é€ ã‚„ãƒˆãƒ”ãƒƒã‚¯ã®é–¢é€£æ€§ã‚’ç†è§£ã—ã€ã‚ˆã‚Šä¸€è²«æ€§ã®ã‚ã‚‹æƒ…å ±é‡ã®å¤šã„ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã€‚Tencent Kuaibaoã‹ã‚‰åé›†ã—ãŸå¤§è¦æ¨¡ãªãƒ‹ãƒ¥ãƒ¼ã‚¹-ã‚³ãƒ¡ãƒ³ãƒˆã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã€ææ¡ˆãƒ¢ãƒ‡ãƒ«ãŒå¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<span class="issue_date">Issue Date: 2019-08-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/319" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] User Preference-Aware Review Generation, Wang+, PAKDD'19</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2019-08-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/318" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Review Response Generation in E-Commerce Platforms with External Product Information, Zhao+, WWW'19</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Workshop.html" target="_blank" rel="noopener noreferrer">#Workshop</a>
<span class="issue_date">Issue Date: 2019-08-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/316" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Automatic Generation of Personalized Comment Based on User Profile, Wenhuan Zeng+, ACL'19 SRW</a>
<span class="snippet"><span>GPT Summary</span>- ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢ã®å¤šæ§˜ãªã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã®é›£ã—ã•ã‚’è€ƒæ…®ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã«åŸºã¥ããƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã‚¿ã‚¹ã‚¯ï¼ˆAGPCï¼‰ã‚’ææ¡ˆã€‚ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºãƒ‰ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆPCGNï¼‰ã‚’ç”¨ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç‰¹å¾´ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€å¤–éƒ¨ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡¨ç¾ã‚’è€ƒæ…®ã™ã‚‹ã“ã¨ã§è‡ªç„¶ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã€‚å®Ÿé¨“çµæœã¯ã€ãƒ¢ãƒ‡ãƒ«ã®åŠ¹æœã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2019-05-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/313" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Multimodal Review Generation for Recommender Systems, Truong+, WWW'19</a>
<span class="snippet"><span>Comment</span><p>Personalized Review Generationã¨ã€Rating Predictionã‚’åŒæ™‚å­¦ç¿’ã—ãŸç ”ç©¶ï¼ˆåŒæ™‚å­¦ç¿’è‡ªä½“ã¯ã™ã§ã«å…ˆè¡Œç ”ç©¶ãŒã‚ã‚‹ï¼‰ã€‚<br><br>ã¾ãŸã€å…ˆè¡Œç ”ç©¶ã®inputã¯ã€ãŸã„ã¦ã„ã¯user, itemã§ã‚ã‚‹ãŒã€multi-modalãªinputã¨ã—ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®photoã‚’æ´»ç”¨ã—ãŸã¨ã„ã†è©±ã€‚<br><br><br><br>ã¾ã ã‚ã¾ã‚Šã—ã£ã‹ã‚Šèª­ã‚“ã§ã„ãªã„ãŒã€ãƒ¢ãƒ‡ãƒ«ã®structureã¯ã‚·ãƒ³ãƒ—ãƒ«ã§ã€rating predictionã‚’è¡Œã†DNNã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’è¡Œã†LSTMï¼ˆfusion gateã¨å‘¼ã°ã‚Œã‚‹æ–°ãŸãªã‚²ãƒ¼ãƒˆã‚’è¿½åŠ ï¼‰ã€ç”»åƒã®ç•³ã¿è¾¼ã‚€CNNã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2613" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Think you have Solved Question Answering? Try ARC, the AI2 Reasoning  Challenge, Peter Clark+, arXiv'18</a>
<span class="snippet"><span>GPT Summary</span>- AI2 Reasoning Challengeï¼ˆARCï¼‰ã‚’ææ¡ˆã—ã€é«˜åº¦ãªè³ªå•å¿œç­”ã«ãŠã‘ã‚‹AIç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã™ã‚‹ã€‚ARCã¯Challenge Setã¨Easy Setã«åˆ†ã‹ã‚Œã€Challenge Setã«ã¯ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ä¸æ­£è§£ã¨ã•ã‚ŒãŸè³ªå•ãŒå«ã¾ã‚Œã‚‹ã€‚ARCã¯æœ€å¤§ã®å…¬çš„ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚»ãƒƒãƒˆã§ã‚ã‚Šã€1400ä¸‡ã®ç§‘å­¦æ–‡ã‚’å«ã‚€ã‚³ãƒ¼ãƒ‘ã‚¹ã¨3ã¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…ã‚‚å…¬é–‹ã€‚æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã¯ãƒ©ãƒ³ãƒ€ãƒ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚Œãšã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¸ã®æŒ‘æˆ¦ã¨ã—ã¦ARCã‚’æèµ·ã€‚</span>
<span class="snippet"><span>Comment</span><p>dataset: 


<a href="https://huggingface.co/datasets/allenai/ai2_arc" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/allenai/ai2_arc</a>


<br>æ—¥æœ¬èªè§£èª¬: 


<a href="https://qiita.com/tekunikaruza_jp/items/d2ec3621afc9ba3d225b" target="_blank" rel="noopener noreferrer">https://qiita.com/tekunikaruza_jp/items/d2ec3621afc9ba3d225b</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<span class="issue_date">Issue Date: 2025-08-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2386" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Attention with Relative Position Representations, Peter Shaw+, NAACL'18</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€Transformerã®è‡ªå·±æ³¨æ„æ©Ÿæ§‹ã‚’æ‹¡å¼µã—ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹è¦ç´ é–“ã®ç›¸å¯¾çš„ãªä½ç½®ã‚’åŠ¹ç‡çš„ã«è€ƒæ…®ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚WMT 2014ã®ç¿»è¨³ã‚¿ã‚¹ã‚¯ã§1.3 BLEUãŠã‚ˆã³0.3 BLEUã®æ”¹å–„ã‚’é”æˆã€‚ç›¸å¯¾ä½ç½®ã¨çµ¶å¯¾ä½ç½®ã®çµ„ã¿åˆã‚ã›ã§ã¯ã•ã‚‰ãªã‚‹æ”¹å–„ã¯è¦‹ã‚‰ã‚Œãªã‹ã£ãŸã€‚ææ¡ˆæ‰‹æ³•ã¯ã€ä»»æ„ã®ã‚°ãƒ©ãƒ•ãƒ©ãƒ™ãƒ«ä»˜ãå…¥åŠ›ã«ä¸€èˆ¬åŒ–å¯èƒ½ãªé–¢ä¿‚èªè­˜è‡ªå·±æ³¨æ„æ©Ÿæ§‹ã¨ã—ã¦ä½ç½®ä»˜ã‘ã‚‰ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç›¸å¯¾ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ææ¡ˆã—ãŸç ”ç©¶</p>
<p>çµ¶å¯¾ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/245" target="_blank" rel="noopener noreferrer">[Paper Note] Attention Is All You Need, Ashish Vaswani+, arXiv'17</a>
</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<span class="issue_date">Issue Date: 2025-08-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2367" target="_blank" rel="noopener noreferrer" class="title-link">Learning to Generate Move-by-Move Commentary for Chess Games from Large-Scale Social Forum Data, Jhamtani+, ACL'18</a>
<span class="snippet"><span>Comment</span><p>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ—¥æœ¬èªè§£èª¬ï¼ˆéå»ã®è‡ªåˆ†ã®è³‡æ–™ï¼‰:


<a href="https://speakerdeck.com/akihikowatanabe/data-to-text-datasetmatome-summary-of-data-to-text-datasets?slide=66" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/akihikowatanabe/data-to-text-datasetmatome-summary-of-data-to-text-datasets?slide=66</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2025-08-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2353" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Efficient Attention: Attention with Linear Complexities, Zhuoran Shen+, arXiv'18</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„åŠ¹ç‡çš„ãªã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ææ¡ˆã—ã€ãƒ‰ãƒƒãƒˆç©ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¶­æŒã—ã¤ã¤ã€ãƒ¡ãƒ¢ãƒªã¨è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å¤§å¹…ã«å‰Šæ¸›ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æŸ”è»Ÿãªçµ±åˆãŒå¯èƒ½ã¨ãªã‚Šã€ç²¾åº¦å‘ä¸Šã‚’å®Ÿç¾ã€‚å®Ÿé¨“çµæœã§ã¯ã€MS-COCO 2017ã§ã®ç‰©ä½“æ¤œå‡ºã‚„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®æ€§èƒ½å‘ä¸ŠãŒç¢ºèªã•ã‚Œã€Scene Flowãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯æœ€å…ˆç«¯ã®ç²¾åº¦ã‚’é”æˆã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Figure1ã‚’è¦‹ã‚‹ã¨ã‚³ãƒ³ã‚»ãƒ—ãƒˆãŒä¸€ç›®ã§ã‚ã‹ã‚Šã€éå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„<br>&lt;img width="1068" height="580" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/18e6a7da-fc07-495f-bda6-bcef4acab321"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/18e6a7da-fc07-495f-bda6-bcef4acab321"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/QA-based.html" target="_blank" rel="noopener noreferrer">#QA-based</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/994" target="_blank" rel="noopener noreferrer" class="title-link">A Semantic QA-Based Approach for Text Summarization Evaluation, Ping Chen+, N_A, AAAI'18</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªç„¶è¨€èªå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡ã«ãŠã‘ã‚‹å•é¡Œã®ä¸€ã¤ã¯ã€2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ã®å†…å®¹ã®é•ã„ã‚’ç‰¹å®šã™ã‚‹ã“ã¨ã§ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€1ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ã‚’å°ã•ãªçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦æ‰±ã„ã€å¤šæ•°ã®è³ªå•ã‚’æŠ•ã’ã‹ã‘ã¦å†…å®¹ã‚’æ¯”è¼ƒã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯æœ‰æœ›ã§ã‚ã‚Šã€2007å¹´ã®DUCè¦ç´„ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ã¦è¡Œã‚ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>QGQAã‚’ææ¡ˆã—ãŸç ”ç©¶</p></span><br><br>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/ImageCaptioning.html" target="_blank" rel="noopener noreferrer">#ImageCaptioning</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/992" target="_blank" rel="noopener noreferrer" class="title-link">Object hallucination in image captioning, Rohbach+, EMNLP'18</a>
<span class="snippet"><span>GPT Summary</span>- ç¾ä»£ã®ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å¹»è¦šã‚’ç”Ÿã˜ã‚‹å‚¾å‘ãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ–°ã—ã„ç”»åƒé–¢é€£æ€§ã®è©•ä¾¡æŒ‡æ¨™ã‚’ææ¡ˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„å­¦ç¿’ç›®æ¨™ãŒå¹»è¦šã«ã©ã®ã‚ˆã†ã«å¯„ä¸ã™ã‚‹ã‹ã‚’è©•ä¾¡ã™ã‚‹ã€‚ã•ã‚‰ã«ã€è¨€èªã®å…ˆå…¥è¦³ã«ã‚ˆã‚‹ã‚¨ãƒ©ãƒ¼ãŒå¹»è¦šã‚’å¼•ãèµ·ã“ã™ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/review.html" target="_blank" rel="noopener noreferrer">#review</a>
<span class="issue_date">Issue Date: 2023-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/652" target="_blank" rel="noopener noreferrer" class="title-link">A Hierarchical End-to-End Model for Jointly Improving Text Summarization  and Sentiment Classification, Shuming Ma+, N_A, arXiv'18</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã¨æ„Ÿæƒ…åˆ†é¡ã‚’å…±åŒå­¦ç¿’ã™ã‚‹ãŸã‚ã®éšå±¤çš„ãªã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã€æ„Ÿæƒ…åˆ†é¡ãƒ©ãƒ™ãƒ«ã‚’ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã®å‡ºåŠ›ã®ã€Œè¦ç´„ã€ã¨ã—ã¦æ‰±ã†ã€‚ææ¡ˆãƒ¢ãƒ‡ãƒ«ã¯Amazonã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å®Ÿé¨“ã§ã€æŠ½è±¡çš„ãªè¦ç´„ã¨æ„Ÿæƒ…åˆ†é¡ã®ä¸¡æ–¹ã§å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>review summarizationã«åˆã‚ã¦amazon online review data <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/653" target="_blank" rel="noopener noreferrer">SNAP: Web data: Amazon reviews</a>
 ä½¿ã£ãŸç ”ç©¶ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<span class="issue_date">Issue Date: 2022-06-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/457" target="_blank" rel="noopener noreferrer" class="title-link">Deep contextualized word representations, Peters+, Allen Institute for Artificial intelligence, NAACL'18</a>
<span class="snippet"><span>Comment</span><p>ELMoè«–æ–‡ã€‚<br>é€šå¸¸ã®word embeddingã§ã¯ä¸€ã¤ã®å˜èªã«ã¤ãä¸€ã¤ã®æ„å‘³ã—ã‹æŒãŸã›ã‚‰ã‚Œãªã‹ã£ãŸãŒã€æ–‡è„ˆã«å¿œã˜ã¦ç•°ãªã‚‹æ„å‘³ã‚’è¡¨ç¾ã§ãã‚‹ã‚ˆã†ãªEmbeddingã‚’å®Ÿç¾ã—ï¼ˆåŒã˜å˜èªã§ã‚‚æ–‡è„ˆã«å¿œã˜ã¦æ„å‘³ãŒå¤‰ã‚ã£ãŸã‚Šã™ã‚‹ã®ã§ã€‚ãŸã¨ãˆã°rightã¯æ–‡è„ˆã«å¿œã˜ã¦å³ãªã®ã‹ã€æ­£ã—ã„ãªã®ã‹ã€æ¨©åˆ©ãªã®ã‹æ„å‘³ãŒå¤‰ã‚ã‚‹ï¼‰æ§˜ã€…ãªè¨€èªå‡¦ç†ã‚¿ã‚¹ã‚¯ï¼ˆe.g. Question Answering, Sentiment Analysisãªã©ï¼‰ã§SoTAã‚’é”æˆã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/172505957-a2fc5319-5670-4807-a870-31377227299e.png" alt="image" loading="lazy"><br><br>Embedding Layer + 2å±¤ã®LSTMï¼ˆ1,2ã®é–“ã«ã¯residual connectionï¼‰+ linear layerã§è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ§‹æˆã—ã€é †æ–¹å‘è¨€èªãƒ¢ãƒ‡ãƒ«ã¨é€†æ–¹å‘è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’åŒæ™‚ã«ç‹¬ç«‹ã—ã¦å­¦ç¿’ã™ã‚‹ï¼ˆåŒæ–¹å‘LSTMã§ã¯ãªã„;æå¤±é–¢æ•°ãŒä¸¡æ–¹å‘ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®å¯¾æ•°å°¤åº¦ã®å’Œã«ãªã£ã¦ã„ã‚‹ï¼‰ã€‚<br>ã¾ãŸã€Linear Layerã¨Embedding Layerã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ä¸¡æ–¹å‘ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§å…±æœ‰ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>kç•ªç›®ã®å˜èªã®Embedding Layerã®å‡ºåŠ›ãƒ™ã‚¯ãƒˆãƒ«ã€å„LSTMã®hidden stateã‚’ã‚¿ã‚¹ã‚¯specificãªã‚¹ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ©ãƒ¡ã‚¿s_taskã§è¶³ã—åˆã‚ã›ã€æœ€å¾Œã«ãƒ™ã‚¯ãƒˆãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚’èª¿æ•´ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ã‚¿Î³_taskã§å¤§ãã•ã‚’èª¿æ•´ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€kç•ªç›®ã®å˜èªã®ELMo Embeddingã‚’å¾—ã‚‹ã€‚<br>å˜èªå˜ä½“ã®æ„å‘³ã ã‘ã§ã“ã¨è¶³ã‚Šã‚‹ã‚¿ã‚¹ã‚¯ã®å ´åˆã¯Embedding Layerã®å‡ºåŠ›ãƒ™ã‚¯ãƒˆãƒ«ã«å¯¾ã™ã‚‹é‡ã¿ãŒå¤§ãããªã‚Šã€æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸæƒ…å ±ãŒæ¬²ã—ã„å ´åˆã¯LSTMã®hidden stateã«å¯¾ã™ã‚‹é‡ã¿ãŒå¤§ãããªã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼ˆLSTMã®å±¤ãŒæ·±ã„ã»ã©æ„å‘³çš„semanticãªæƒ…å ±ã‚’å«ã¿ã€æµ…ã„ã»ã©æ–‡æ³•çš„syntacticãªæƒ…å ±ã‚’å«ã‚“ã§ã„ã‚‹ï¼‰ã€‚<br><br>ä½¿ã„æ–¹ã¨ã—ã¦ã¯ç°¡å˜ã§ã€ELMoã‚’äº‹å‰å­¦ç¿’ã—ã¦ãŠãã€è‡ªèº«ã®NNãƒ¢ãƒ‡ãƒ«ã®Word Embeddingã«ï¼ˆå ´åˆã«ã‚ˆã£ã¦ã¯RNNã®hidden stateã«ã‚‚ï¼‰ã€å…¥åŠ›æ–‡ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸELMo Embeddingã‚’concatã—ã¦é †ä¼æ¬ã•ã›ã‚‹ã ã‘ã§è‰¯ã„ã€‚</p>
<p>s_taskã¨Î³_taskã¯trainableãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã€<br>ELMoã‚’é©ç”¨ã—ãŸå…ˆã®NNãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´æ™‚ã«ã€NNãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ã‚¿ã¨ä¸€ç·’ã«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ï¼ˆã¨æ€ã‚ã‚Œã‚‹ï¼‰ã€‚<br><br>


<a href="https://github.com/allenai/allennlp/issues/1166" target="_blank" rel="noopener noreferrer">https://github.com/allenai/allennlp/issues/1166</a>


<br>


<a href="https://github.com/allenai/allennlp/issues/2552" target="_blank" rel="noopener noreferrer">https://github.com/allenai/allennlp/issues/2552</a>


</p>
<p>ELMoã®Embedding Layerã§ã¯ã€2048 characterã®ï¼ˆvocab size?ï¼‰n-gram convolution filterï¼ˆæ–‡å­—ã”ã¨ã«embeddingã—ã€å˜èªã®embeddingã‚’å¾—ã‚‹ãŸã‚ã«filterã‚’é©ç”¨ã™ã‚‹ï¼Ÿï¼‰ã®å¾Œã«2ã¤ã®highway networkã‚’ã‹ã¾ã›ã¦linearã§512æ¬¡å…ƒã«è½ã¨ã™ã¿ãŸã„ãªã“ã¨ã”ã‚„ã‚‰ã‚Œã¦ã„ã‚‹ã‚‰ã—ã„ã€‚ã“ã“ã¾ã§è¿½ãˆã¦ã„ãªã„ã€‚<br><br>è©³ç´°ã¯ä¸‹è¨˜<br>


<a href="https://datascience.stackexchange.com/questions/97867/how-does-the-character-convolution-work-in-elmo" target="_blank" rel="noopener noreferrer">https://datascience.stackexchange.com/questions/97867/how-does-the-character-convolution-work-in-elmo</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2021-10-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/415" target="_blank" rel="noopener noreferrer" class="title-link">Point precisely: Towards ensuring the precision of data in generated texts using delayed copy mechanism., Li+, Peking University, COLING'18</a>
<span class="snippet"><span>Comment</span><p>
<strong># æ¦‚è¦<br><br>DataToTextã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã®ç²¾åº¦ã‚’é«˜ã‚ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚two stageã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã€‚â‘ encoder-decoerãƒ¢ãƒ‡ãƒ«ã§slotã‚’å«ã‚€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã€‚â‘¡Copy Mechanismã§slotã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸ‹ã‚ã‚‹ã€ã¨ã„ã£ãŸæ‰‹æ³•ã€‚<br><br>â‘ ã¨â‘¡ã¯ãã‚Œãã‚Œç‹¬ç«‹ã«å­¦ç¿’ã•ã‚Œã‚‹ã€‚<br><br><br><br>two stageã«ã™ã‚‹ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€<br><br>ãƒ»ã“ã‚Œã¾ã§ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€å˜èªã®ç”Ÿæˆç¢ºç‡ã¨ã‚³ãƒ”ãƒ¼ç¢ºç‡ã‚’æ··åˆã—ãŸåˆ†å¸ƒã‚’è€ƒãˆã¦ã„ãŸãŒã€ã©ã®ã‚ˆã†ã«ä¸¡è€…ã®ç¢ºç‡ã‚’mergeã™ã‚‹ã®ãŒè‰¯ã„ã‹ã¯ã‚¯ãƒªã‚¢ã§ã¯ãªã„ã€‚<br><br>â†’ ç”Ÿæˆã¨ã‚³ãƒ”ãƒ¼ã‚’åˆ†é›¢ã—ã¦ä¸ç¢ºå®Ÿæ€§ã‚’æ¸›ã‚‰ã—ãŸ<br><br>ãƒ»ã‚³ãƒ”ãƒ¼ã‚’ç‹¬ç«‹ã—ã¦è€ƒãˆã‚‹ã“ã¨ã§ã€ã‚ˆã‚ŠåŠ¹æœçš„ãªpair-wise ranking loss functionã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã‚‹<br><br>ãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ç”Ÿæˆã«é›†ä¸­ã§ãã€slot fillingãƒ¢ãƒ‡ãƒ«ã¯ã‚¹ãƒ­ãƒƒãƒˆã‚’åŸ‹ã‚ã‚‹ã‚¿ã‚¹ã‚¯ã«é›†ä¸­ã§ãã‚‹ã€‚ã“ã‚Œã‚‰ã¯trainingã¨tuningã‚’ã‚ˆã‚Šç°¡ä¾¿ã«ã™ã‚‹ã€‚<br><br><br><br># ãƒ¢ãƒ‡ãƒ«æ¦‚è¦<br><br>ãƒ¢ãƒ‡ãƒ«ã®å…¨ä½“åƒ<br><br><img src="https://user-images.githubusercontent.com/12249301/138623391-6c876671-7c29-4d6a-8dfd-bd1feb623acd.png" alt="image" loading="lazy"><br><br><br><br>ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ä¾‹ã€‚ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ†ã‚­ã‚¹ãƒˆã®ç”Ÿæˆã‚’å­¦ç¿’ã™ã‚‹encoder-decoderï¼ˆâ‘ ï¼‰ã¯Target Templateã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ã€‚ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§ã¯ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒ"<entity>"ã€æ•°å€¤ãŒ"<number>"ã¨ã„ã†place holderã§è¡¨ç¾ã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã‚Œã‚‰ã®ã‚¹ãƒ­ãƒƒãƒˆã‚’åŸ‹ã‚ã‚‹Delayed Copy Networkã¯ã€ã‚¹ãƒ­ãƒƒãƒˆãŒæ­£ã—ãåŸ‹ã‚ã‚‰ã‚Œã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138623460-1415e0c2-2468-4c05-a8b8-685001c26bb7.png" alt="image" loading="lazy"><br><br><br><br># å®Ÿé¨“çµæœ<br><br><img src="https://user-images.githubusercontent.com/12249301/138624623-2f8944f5-8a7c-4de5-bbb8-cda9626e7018.png" alt="image" loading="lazy"><br><br><br><br>Relation Generation (RG)ãŒCCã¨æ¯”ã¹ã¦10%ç¨‹åº¦å¢—åŠ ã—ã¦ã„ã‚‹ã®ã§ã€data fidelityãŒæ”¹å–„ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>ã¾ãŸã€BLEUã‚¹ã‚³ã‚¢ã‚‚ç´„2ãƒã‚¤ãƒ³ãƒˆæ”¹å–„ã€‚ã“ã‚Œã¯entityã‚„numberãŒé©åˆ‡ã«åŸ‹ã‚ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ãªã£ãŸã ã‘ã§ãªãã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒã‚ˆã‚Šé©åˆ‡ã«ç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ã§ã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><br><br><br>## å‚è€ƒï¼š<br><br>â€¢ Relation Generation (RG)ï¼šå‡ºåŠ›æ–‡ã‹ã‚‰(entity, value)ã®é–¢ä¿‚ã‚’æŠ½å‡ºã—ï¼ŒæŠ½å‡ºã•ã‚ŒãŸé–¢ä¿‚ã®æ•°ã¨ï¼Œãã‚Œã‚‰ã®é–¢ä¿‚ãŒå…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æ­£ã—ã„ã‹ã©ã†ã‹ã‚’è©•ä¾¡ã™ã‚‹ (Precision)ï¼ãŸã ã— entity ã¯ãƒãƒ¼ãƒ åã‚„é¸æ‰‹åãªã©ã®å‹•ä½œã®ä¸»ä½“ï¼Œvalue ã¯å¾—ç‚¹æ•°ã‚„ã‚¢ã‚·ã‚¹ãƒˆæ•°ãªã©ã®è¨˜éŒ²ã§ã‚ã‚‹ï¼<br><br>â€¢ Content Selection (CS)ï¼šå‡ºåŠ›æ–‡ã¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‹ã‚‰ (entity, value) ã®é–¢ä¿‚ã‚’æŠ½å‡ºã—ï¼Œå‡ºåŠ›æ–‡ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸé–¢ä¿‚ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸé–¢ä¿‚ã«å¯¾ã™ã‚‹ Precisionï¼ŒRecall ã§è©•ä¾¡ã™ã‚‹ï¼<br><br>â€¢ Content Ordering (CO)ï¼šå‡ºåŠ›æ–‡ã¨ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‹ã‚‰ (entity, value) ã®é–¢ä¿‚ã‚’æŠ½å‡ºã—ï¼Œãã‚Œã‚‰ã®é–“ã®æ­£è¦åŒ– DamerauLevenshtein è·é›¢ [7] ã§è©•ä¾¡ã™ã‚‹ï¼<br><br>(from <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/409" target="_blank" rel="noopener noreferrer">éå»æƒ…å ±ã®å†…å®¹é¸æŠã‚’å–ã‚Šå…¥ã‚ŒãŸ ã‚¹ãƒãƒ¼ãƒ„ãƒ€ã‚¤ã‚¸ã‚§ã‚¹ãƒˆã®è‡ªå‹•ç”Ÿæˆ, åŠ è—¤+, æ±å·¥å¤§, NLP'21</a>
&lt;/strong&gt;
<br>
 )&lt;/p&gt;&lt;/span&gt;<br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2021-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/406" target="_blank" rel="noopener noreferrer" class="title-link">Operation-guided Neural Networks for High Fidelity Data-To-Text Generation, Nie+, Sun Yat-Sen University, EMNLP'18</a>
<span class="snippet"><span>Comment</span><p># æ¦‚è¦<br><br>æ—¢å­˜ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ç”Ÿãƒ‡ãƒ¼ã‚¿ã€ã‚ã‚‹ã„ã¯ãã“ã‹ã‚‰æ¨è«–ã•ã‚ŒãŸäº‹å®Ÿã«åŸºã¥ã„ã¦è¨€èªã‚’ç”Ÿæˆã™ã‚‹ã¨ã„ã£ãŸã“ã¨ãŒã§ãã¦ã„ãªã„ï¼ˆe.g. é‡‘è, åŒ»ç™‚, ã‚¹ãƒãƒ¼ãƒ„ç­‰ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã¯é‡è¦ï¼‰ã€‚<br><br>ãŸã¨ãˆã°ä¸‹è¡¨ã«ç¤ºã—ãŸé€šã‚Šã€"edge"ã¨ã„ã†å˜èªã¯ã€ã‚¹ã‚³ã‚¢ãŒæ¥æˆ¦ï¼ˆ95-94=1 -&gt; ã‚¹ã‚³ã‚¢ã®å·®ãŒå°ã•ã„ï¼‰ã§ã‚ã£ãŸã“ã¨ã‚’è¡¨ç¾ã—ã¦ã„ã‚‹ãŒã€ã“ã†ã„ã£ãŸã“ã¨ã‚’æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯è€ƒæ…®ã—ã¦ç”ŸæˆãŒã§ããªã„ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138627286-c9bde402-0129-4b82-9faf-80fcde08cdc8.png" alt="image" loading="lazy"><br><br><br><br>ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€æ¼”ç®—ï¼ˆoperationï¼‰ã¨ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’åˆ‡ã‚Šé›¢ã™ï¼ˆäº‹å‰ã«è¨ˆç®—ã—ã¦ãŠãï¼‰ã¨ã„ã£ãŸã“ã¨ãŒè€ƒãˆã‚‰ã‚Œã‚‹ãŒã€<br><br>â‘  å…¨ã¦ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å¯¾ã—ã¦operationã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€æ¢ç´¢ç©ºé–“ãŒè†¨å¤§ã«ãªã‚Šã€ã©ã®çµæœã«å¯¾ã—ã¦è¨€åŠã™ã‚‹ä¾¡å€¤ãŒã‚ã‚‹ã‹ã‚’åŒå®šã™ã‚‹ã®ãŒå›°é›£ï¼ˆè¨€åŠã™ã‚‹ä¾¡å€¤ãŒã‚ã‚‹çµæœãŒã»ã¨ã‚“ã©å­˜åœ¨ã—ãªã„æ¢ç´¢ç©ºé–“ãŒã§ãã¦ã—ã¾ã†ï¼‰<br><br>â‘¡ æ¼”ç®—çµæœã®æ•°å€¤ã®ã‚¹ãƒ‘ãƒ³ã¨ã€è¨€èªé¸æŠã®å¯¾å¿œé–¢ä¿‚ã‚’ç¢ºç«‹ã•ã›ã‚‹ã®ãŒå›°é›£ï¼ˆe.g. ã‚¹ã‚³ã‚¢ã®å·®ãŒ1ã®ã¨ã"edge"ã¨è¡¨ç¾ã™ã‚‹ã€ãªã©ï¼‰<br><br>ã¨ã„ã£ãŸèª²é¡ŒãŒã‚ã‚‹ã€‚<br><br><br><br>â‘ ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€äº‹å‰ã«raw dataã«å¯¾ã—ã¦æ¼”ç®—ã‚’é©ç”¨ã—ãã®çµæœã‚’åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æ¡ç”¨ã€‚ã©ã®æ¼”ç®—çµæœã‚’åˆ©ç”¨ã™ã‚‹ã‹ã‚’æ±ºå®šã™ã‚‹ãŸã‚ã«ã€gating-mechanismã‚’æ´»ç”¨ã™ã‚‹ã€‚<br><br>â‘¡ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€quantization layerã‚’æ¡ç”¨ã—ã€æ¼”ç®—çµæœã®æ•°å€¤ã‚’binã«æŒ¯ã‚Šåˆ†ã‘ã€ãã®çµæœã«å¿œã˜ã¦ç”Ÿæˆã™ã‚‹è¡¨ç¾ã‚’guideã™ã‚‹ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã‚’æ¡ç”¨ã™ã‚‹ã€‚<br><br><br><br># ãƒ¢ãƒ‡ãƒ«æ¦‚è¦<br><br>ãƒ¢ãƒ‡ãƒ«ã¯record encoder(h_{i}^{ctx}ã‚’ä½œã‚‹)ã€operation encoder(h_{i}^{op}ã‚’ä½œã‚‹)ã€operation result encoder(h_{i}^{res}ã‚’ä½œã‚‹)ã«ã‚ˆã£ã¦æ§‹æˆã•ã‚Œã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138628639-0c64d7aa-22e7-4ee7-a55f-65736e607ed2.png" alt="image" loading="lazy"><br><br><br><br>## record encoder<br><br>record encoderã¯ã€wisemanã‚‰ã¨åŒæ§˜ã«ã€index (e.g. row 2), column (e.g. column Points), value (e.g. 95)ã®word embeddingã‚’æ±‚ã‚ã€ãã‚Œã‚‰ã‚’concatã—ãŸã‚‚ã®ã‚’bi-directional RNNã«å…¥åŠ›ã—æ±‚ã‚ã‚‹ã€‚<br><br><br><br>## operation encoder<br><br>operation encoderã§ã¯ã€operation op_{i}ã¯ã€1) operationã®åç§° (e.g. minus) 2) operationã‚’é©ç”¨ã™ã‚‹column (e.g. Points), 3) operationã‚’é©ç”¨ã™ã‚‹row (e.g. {1, 2}ãªã©ã®row indexã®é›†åˆ)ã«ã‚ˆã£ã¦æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€ã“ã‚Œã‚‰ã®embeddingã‚’lookupã—concatã—ãŸå¾Œã€non-linear layerã§å¤‰æ›ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦operationã®representationã‚’å–å¾—ã™ã‚‹ã€‚3)operationã‚’é©ç”¨ã™ã‚‹rowã«ã¤ã„ã¦ã¯ã€è¤‡æ•°ã®indexã«ã‚ˆã£ã¦æ§‹æˆã•ã‚Œã‚‹ãŸã‚ã€å„indexã®embeddingã‚’non-linear layerã§å¤‰æ›ã—ãŸãƒ™ã‚¯ãƒˆãƒ«ã‚’è¶³ã—åˆã‚ã›ãŸçµæœã«å¯¾ã—ã¦tanhã‚’é©ç”¨ã—ãŸãƒ™ã‚¯ãƒˆãƒ«ã‚’embeddingã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã€‚<br><br><br><br>## operation result encoder<br><br>operation result encoderã¯ã€scalar resultsï¼ˆminus operationã«ã‚ˆã‚Š-1ï¼‰ãŠã‚ˆã³indexing results (argmax operationã«ã‚ˆã‚Šindex 2)ã®äºŒç¨®é¡ã‚’ç”Ÿæˆã™ã‚‹ã€‚ã“ã‚Œã‚‰äºŒç¨®é¡ã«å¯¾ã—ã¦ç•°ãªã‚‹encodingæ–¹æ³•ã‚’æ¡ç”¨ã™ã‚‹ã€‚<br><br>### scalar results<br><br>scalar resultsã«å¯¾ã—ã¦ã¯ã€ä¸‹è¨˜å¼ã§scalar valueã‚’quantization vectorï¼ˆq_{i}ï¼‰ã«å¤‰æ›ã™ã‚‹ã€‚qutization vectorã®lengthã¯Lã¨ãªã£ã¦ãŠã‚Šã€Lã¯binã®æ•°ã«ç›¸å½“ã—ã¦ã„ã‚‹ã€‚ã¤ã¾ã‚Šã€quantization vectorã®å„æ¬¡å…ƒãŒbinã®é‡ã¿ã«å¯¾å¿œã—ã¦ã„ã‚‹ã€‚ãã®å¾Œã€quantization vectorã«å¯¾ã—ã¦softmaxã‚’é©ç”¨ã—ã€quantization unitï¼ˆquantization vectorã®å„æ¬¡å…ƒï¼‰ã®é‡ã¿ã‚’æ±‚ã‚ã‚‹ã€‚æœ€å¾Œã«ã€quantization embeddingã¨å¯¾å¿œã™ã‚‹quantization unitã®é‡ã¿ä»˜ãå¹³å‡ã‚’ã¨ã‚‹ã“ã¨ã«ã‚ˆã£ã¦h_{i}^{res}ã‚’ç®—å‡ºã™ã‚‹ã€‚<br><br><br><br>Q. å¼ã‚’è¦‹ã‚‹ã¨W_{q}ãŒscalar resultã®å€¤ã«ã‚ˆã£ã¦å®šæ•°å€ã•ã‚Œã‚‹ã ã‘ã ã‹ã‚‰ã€softmaxã«ã‚ˆã£ã¦æ±‚ã¾ã‚‹quantization unitã®é‡ã¿ã®åºåˆ—ã¯scalar resultã«ã‚ˆã£ã¦å¤‰åŒ–ã—ãªãã†ã«è¦‹ãˆã‚‹ãŒã€ã“ã‚Œã§ã†ã¾ãã„ãã‚“ã ã‚ã†ã‹ãƒ»ãƒ»ãƒ»ï¼Ÿåºåˆ—ã¯å¤‰ã‚ã‚‰ãªãã¦ã‚‚å„quantization unité–“ã®ç›¸å¯¾çš„ãªé‡ã¿ã®å·®ãŒå¤‰åŒ–ã™ã‚‹ã‹ã‚‰ã€ãã‚Œã§ã†ã¾ãscalarå€¤ã®å¤‰åŒ–ã‚’æ‰ãˆã‚‰ã‚Œã‚‹ã®ãƒ»ãƒ»ãƒ»ã‹ãƒ»ãƒ»ãƒ»ï¼Ÿ<br><br><br><br>### indexing results<br><br>indexing resultsã«ã¤ã„ã¦ã¯ã€h_{i}^{res}ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«indexã®embeddingã¨ã™ã‚‹ã€‚<br><br><br><br>## Decoder<br><br>context vectorã®ç”Ÿæˆæ–¹æ³•ãŒé•ã†ã€‚å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦ã€context vectorã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’operationã®ä¸¡æ–¹ã‚’inputã¨ã™ã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/138632508-f9407ff9-3e8a-4efd-91d4-6879e81331a6.png" alt="image" loading="lazy"><br><br><br><br>operationã®context vector c_{t}^{op}ã¨recordsã®context vector c_{t}^{ctx}ã‚’dynamic gate Î»_{t}ã«ã‚ˆã£ã¦é‡ã¿ä»˜ã‘ã—æœ€çµ‚çš„ãªcontext vectorã‚’æ±‚ã‚ã‚‹ã€‚Î»_{t}ã¯ã€t-1æ™‚ç‚¹ã§ã®ãƒ‡ã‚³ãƒ¼ãƒ€ã®hidden stateã‹ã‚‰é‡ã¿ã‚’æ±‚ã‚ã‚‹ã€‚<br><br>c_{t}^{op}ã¯æ¬¡å¼ã§è¨ˆç®—ã•ã‚Œï¼š<br><br><img src="https://user-images.githubusercontent.com/12249301/138633048-ca82ff5f-9755-4e5f-a658-774354cde987.png" alt="image" loading="lazy"><br><br>c_{t}^{scl, idx}ã¯ã€<br><br><img src="https://user-images.githubusercontent.com/12249301/138633078-f74de4b3-f742-48f9-9f29-64489f8f477a.png" alt="image" loading="lazy"><br><br>ã‚ˆã£ã¦è¨ˆç®—ã•ã‚Œã‚‹ã€‚è¦ã¯ã€decoderã®t-1ã®hidden stateã¨ã€operation vectorã‚’ç”¨ã„ã¦ã€jç•ªç›®ã®operationã®é‡è¦åº¦ï¼ˆÎ²ï¼‰ã‚’æ±‚ã‚ã€operationã®é‡è¦åº¦ã«ã‚ˆã£ã¦é‡ã¿ä»˜ã‘ã—ã¦operation result vectorã‚’è¶³ã—åˆã‚ã›ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€context vectorã‚’ç®—å‡ºã™ã‚‹ã€‚<br><br>ã¾ãŸã€recordã®context vector c_{t}^{ctx}ã¯ã€h_{j}^{res}ã¨h_{j}^{op}ã¨ã€h_{j}^{ctx}ã«ç½®ãæ›ãˆã‚‹ã“ã¨ã«ã‚ˆã£ã¦ç®—å‡ºã•ã‚Œã‚‹ã€‚ <br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138631847-e3076003-b619-49e4-afad-0edffaace060.png" alt="image" loading="lazy"><br><br><br><br>## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br><br>äººæ‰‹ã§ESPN, ROTOWIRE, WIKIBIOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®Referenceã«å¯¾ã—ã¦ã€factã‚’å«ã‚€text spanã¨ã€ãã®factã®ç¨®é¡ã‚’3ç¨®é¡ã«ãƒ©ãƒ™ãƒ«ä»˜ã—ãŸã€‚input factsã¯input dataã‹ã‚‰ç›´æ¥è¦‹ã¤ã‘ã‚‰ã‚Œã‚‹fact, inferred factsã¯input dataã‹ã‚‰ç›´æ¥è¦‹ã¤ã‘ã‚‹ã“ã¨ã¯ã§ããªã„ãŒã€å°ãå‡ºã™ã“ã¨ãŒã§ãã‚‹factã€unsupported factsã¯input dataã‹ã‚‰ç›´æ¥ã‚ã‚‹ã„ã¯å°ãå‡ºã™ã“ã¨ãŒã§ããªã„factã€‚wikibioãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯inferred factã®å‰²åˆãŒå°‘ãªã„ãŸã‚ã€ä»Šå›ã®è©•ä¾¡ã‹ã‚‰ã¯é™¤å¤–ã—ã€ROTOWIRE, ESPNã‚’æ¡ç”¨ã—ãŸã€‚ç‰¹ã«ESPNã®headline datasetãŒinferred factsãŒå¤šã‹ã£ãŸã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138636048-4b8225f7-f685-45b9-ae06-1af57e09044d.png" alt="image" loading="lazy"></p>
<p># çµæœ<br><br>## è‡ªå‹•è©•ä¾¡<br><br><img src="https://user-images.githubusercontent.com/12249301/138634010-2de062dc-d2dc-48af-8724-f6fa950e8144.png" alt="image" loading="lazy"><br><br><br><br>wiseman modelã‚’OpAttãŒoutperformã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€Seq2Seq+op+quantï¼ˆSeq2Seq+copyã«å¯¾ã—ã¦operation result encoderã¨quantization layerã‚’é©ç”¨ã—ãŸã‚‚ã®ï¼‰ã¯Seq2Seq+Copyã‚’ä¸Šå›ã£ã¦ã„ã‚‹ãŒã€OpAttã»ã¨ã§ã¯ãªã„ã“ã¨ã‹ã‚‰ã€ææ¡ˆæ‰‹æ³•ã®operation encoderã®å°å…¥ã¨gating mechanismãŒæœ‰åŠ¹ã«ä½œç”¨ã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138635201-462ef128-58d1-4084-ae70-5acccd34087b.png" alt="image" loading="lazy"><br><br><br><br>æ¡ç”¨ã™ã‚‹operationã«ã‚ˆã£ã¦ã€ç”Ÿæˆã•ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚‚ç•°ãªã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã€‚<br><br><br><br>## äººæ‰‹è©•ä¾¡<br><br>3äººã®NBAã«è©³ã—ã„English native speakerã«ä¾é ¼ã—ã¦test dataã«å¯¾ã™ã‚‹ç”Ÿæˆçµæœã«ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã—ã¦ã‚‚ã‚‰ã£ãŸã€‚ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€factã‚’å«ã‚€spanã‚’åŒå®šã—ã€ãã®factãŒinput facts/inferred facts/unsupported factsã®ã©ã‚Œã‹ã‚’åˆ†é¡ã—ã¦ã‚‚ã‚‰ã£ãŸã€‚æœ€å¾Œã«ã€ãã®factãŒå…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰supportã•ã‚Œã‚‹ã‹contradictedï¼ˆçŸ›ç›¾ã™ã‚‹ã‹ï¼‰ã‹ã‚’ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ã‚‚ã‚‰ã£ãŸã€‚<br><br>ææ¡ˆæ‰‹æ³•ãŒã€ã‚ˆã‚Šå¤šãã®inferred factsã«ã¤ã„ã¦è¨€åŠã—ãªãŒã‚‰ã‚‚ã€å°‘ãªã„#Cont.ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138636756-74da3999-45e7-489f-9d0a-ac68416d3de0.png" alt="image" loading="lazy"><br><br></p>
<p># åˆ†æ<br><br>## Quantizationã®åŠ¹æœ<br><br>ãƒãƒ¼ãƒ é–“ã®ã‚¹ã‚³ã‚¢ã®å·®ãŒã€5ã¤ã®binã®ã«å¯¾ã—ã¦ã©ã‚Œã ã‘ã®é‡ã¿ã‚’æŒãŸã›ãŸã‹ã®heatmapã€‚ä¼¼ãŸã‚ˆã†ãªã‚¹ã‚³ã‚¢ã®gapã®å ´åˆã¯ä¼¼ãŸã‚ˆã†ãªé‡ã¿ã«ãªã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚ãƒã‚¤ãƒ³ãƒˆå·®ã®çµ¶å¯¾å€¤ãŒå°ã•ã„å ´åˆã¯ã€é‡ã¿ã®åˆ†å¸ƒã®åˆ†æ•£ãŒå¤§ãããªã‚‹ã®ã§ã‚ˆã‚Šä¸€èˆ¬çš„ãªå˜èªã§ç”Ÿæˆã‚’è¡Œã†ã®ã«å¯¾ã—ã€çµ¶å¯¾å€¤ãŒå¤§ãã„å ´åˆã¯åˆ†æ•£ãŒå°ã•ããªã‚‹ãŸã‚ã€unique wordã‚’ã¤ã‹ã£ã¦ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/138637300-04738ba9-8e5f-4b07-8ed2-1a62c14cb7fe.png" alt="image" loading="lazy"><br><br><br><br>pointã®gapã®å¤§ãã•ã«ã‚ˆã£ã¦åˆ©ç”¨ã•ã‚Œã‚‹å˜èªã‚‚å¤‰åŒ–ã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚ãƒã‚¤ãƒ³ãƒˆå·®ãŒã¡ã„ã•ã„ã¨ãã¯"edge"ã€å¤§ãã„ã¨ãã¯"blow out"ãªã©ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/138637614-19a95fba-9904-4378-86d0-3d1bd513be8a.png" alt="image" loading="lazy"><br><br><br><br>## gating mechanismã®åŠ¹æœ<br><br>ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã®timestepã”ã¨ã®gateã®é‡ã¿ã®ä¾‹ã€‚è‰²ãŒæ¿ƒã‘ã‚Œã°æ¿ƒã„ã»ã©ã€operation resultsã®æƒ…å ±ã‚’å¤šãåˆ©ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã‚’è¡¨ã™ã€‚ãƒãƒ¼ãƒ ãƒªãƒ¼ãƒ€ãƒ¼ã‚’æ±ºã‚ã‚‹éš›ã‚„ï¼ˆhorfordï¼‰å‹è€…ã‚’æ±ºã‚ã‚‹éš›ã«(Hawks)ã€operation resultsã®é‡ã¿ãŒå¤§ãããªã£ã¦ãŠã‚Šã€å¦¥å½“ãªé‡ã¿ä»˜ã‘ã ã¨è€ƒå¯Ÿã—ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138637813-4b4a2b1d-c5c5-4f7a-96b3-59df3a56aeb2.png" alt="image" loading="lazy"><br><br><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/CommentGeneration.html" target="_blank" rel="noopener noreferrer">#CommentGeneration</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2019-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/321" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Netizen-Style Commenting on Fashion Photos: Dataset and Diversity  Measures, Wen Hua Lin+, WWW'18</a>
<span class="snippet"><span>GPT Summary</span>- æ·±å±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ãŸç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã¯é€²å±•ã—ã¦ã„ã‚‹ãŒã€ç”Ÿæˆã•ã‚Œã‚‹æ–‡ã¯æµ…ãã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚„æ„å›³ã‚’åæ˜ ã—ã¦ã„ãªã„ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ãƒãƒƒãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ«ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆNSCï¼‰ã‚’ææ¡ˆã—ã€ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³å†™çœŸã«å¯¾ã—ã¦ç‰¹å¾´çš„ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ã€‚æ–°ãŸã«æ§‹ç¯‰ã—ãŸã€ŒNetiLookã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã€ã‚³ãƒ¡ãƒ³ãƒˆã®å¤šæ§˜æ€§ã‚’è©•ä¾¡ã™ã‚‹æŒ‡æ¨™ã‚’ææ¡ˆã—ã€ãƒˆãƒ”ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã®ç²¾åº¦ã¨å¤šæ§˜æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã—ãŸã€‚</span>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/RecSys.html" target="_blank" rel="noopener noreferrer">#RecSys</a>
<span class="issue_date">Issue Date: 2019-08-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/317" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Improving Explainable Recommendations with Synthetic Reviews, Sixun Ouyang+, RecSys'18</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ã€è§£é‡ˆå¯èƒ½ãªèª¬æ˜ã‚’æä¾›ã™ã‚‹ã“ã¨ã¯ä¿¡é ¼æ€§å‘ä¸Šã«é‡è¦ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åŸºã«ã—ãŸç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ã€å€‹åˆ¥åŒ–ã•ã‚ŒãŸæ¨è–¦èª¬æ˜ã‚’ä½œæˆã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚Amazonã®æ›¸ç±ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒäººé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ¨è–¦æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ã‚’å®Ÿè¨¼ã—ãŸã€‚ã“ã‚Œã¯æ©Ÿæ¢°ç”Ÿæˆã«ã‚ˆã‚‹è‡ªç„¶è¨€èªèª¬æ˜ã®åˆã®è©¦ã¿ã§ã‚ã‚‹ã€‚</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2019-04-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/306" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Personalized Review Generation by Expanding Phrases and Attending on Aspect-Aware Representations, Ni+, ACL'18</a>
<span class="snippet"><span>Comment</span><p><img src="https://user-images.githubusercontent.com/12249301/56010165-8fd44a00-5d1d-11e9-8cad-81a5178d95d2.png" alt="image" loading="lazy"><br><br><br><br>Personalized Review Generationã‚¿ã‚¹ã‚¯ã‚’ã€user, item, short phraseãŒgivenãªæ™‚ã«ã€ãã‚Œã‚’è€ƒæ…®ã—ã¦å®Œå…¨ãªãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã¨ã—ã¦å®šç¾©ã€‚<br><br>short phraseã¨ã—ã¦ã¯ã€item titleã‚„review summaryãªã©ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã€‚<br><br>ã‚¢ã‚¤ãƒ†ãƒ ã®aspectã‚’è€ƒæ…®ã—ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆã§ãã‚‹ç‚¹ãŒæ–°ã—ã„ã€‚<br><br>ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã¯ã€aspect-awareãªrepresentationã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ»ã‚¢ã‚¤ãƒ†ãƒ ã®aspectã«é–¢ã™ã‚‹å—œå¥½ï¼ˆe.g. ã©ã®éƒ¨åˆ†ã«ã¤ã„ã¦è¨€åŠã—ãŸã„ã‹ã€ãªã©ï¼‰ã‚’æ‰ãˆãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã„ã‚‹ã€‚<br><br>å„aspectã«ã¯ä»£è¡¨çš„ãªå˜èªãŒç´ã¥ã„ã¦ãŠã‚Šã€aspectã«ç´ã¥ãå˜èªã®ç”Ÿæˆç¢ºç‡ã‚’aspect-aware representationã‹ã‚‰æ±‚ã‚ãŸattentionã«ã‚ˆã£ã¦åˆ¶å¾¡ã—ã€ç”Ÿæˆæ™‚ã«ä¸‹é§„ã‚’å±¥ã‹ã›ã¦ã„ã‚‹ã€‚</p>
<p>PyTorchå®Ÿè£…ï¼š


<a href="https://github.com/nijianmo/textExpansion/tree/master/expansionNet" target="_blank" rel="noopener noreferrer">https://github.com/nijianmo/textExpansion/tree/master/expansionNet</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DialogueGeneration.html" target="_blank" rel="noopener noreferrer">#DialogueGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2019-01-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/302" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Training Millions of Personalized Dialogue Agents, Pierre-Emmanuel MazarÃ©+, EMNLP'18, 2018.09</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€500ä¸‡ã®ãƒšãƒ«ã‚½ãƒŠã¨7å„„ã®ãƒšãƒ«ã‚½ãƒŠãƒ™ãƒ¼ã‚¹ã®å¯¾è©±ã‚’æä¾›ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½ãŒå‘ä¸Šã—ã€Zhangã‚‰ï¼ˆ2018ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ä»–ã®ã‚¿ã‚¹ã‚¯ã§ã‚‚æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã€‚</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2019-01-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/301" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Knowledge-Grounded Neural Conversation Model, Ghazvininejad+, AAAI'18, </a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ContextAware.html" target="_blank" rel="noopener noreferrer">#ContextAware</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2019-01-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/300" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Response Generation by Context-aware Prototype Editing, Yu Wu+, AAAI'18, 2018.06</a>
<span class="snippet"><span>GPT Summary</span>- ã€Œç·¨é›†ã«ã‚ˆã‚‹å¿œç­”ç”Ÿæˆã€ã¨ã„ã†æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ææ¡ˆã—ã€æ—¢å­˜ã®å¿œç­”ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’ä¿®æ­£ã™ã‚‹ã“ã¨ã§å¤šæ§˜æ€§ã¨æƒ…å ±é‡ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚å¿œç­”ç·¨é›†ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã¨ç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®é•ã„ã‚’è€ƒæ…®ã—ã¦ç·¨é›†ãƒ™ã‚¯ãƒˆãƒ«ã‚’å½¢æˆã—ã€ç”Ÿæˆçµæœã‚’æ”¹å–„ã™ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€å¿œç­”ç·¨é›†ãƒ¢ãƒ‡ãƒ«ãŒä»–ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚„å–å¾—ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2018-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/277" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Unified Model for Document-Based Question Answering Based on Human-Like Reading Strategy, Li+, AAAI'18</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2018-07-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/276" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Personalized Review Generation by Expanding Phrases and Attending on Aspect-Aware Representations, Ni+, ACL'18</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2018-06-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/273" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Newsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies, Max+, NAACL'18</a>
<span class="snippet"><span>Comment</span><p>æ–‡æ›¸è¦ç´„ã«ä½¿ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br><br>38ã®å‡ºç‰ˆå…ƒã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã€ã‚µã‚¤ã‚ºã¯1.3M articleç¨‹åº¦<br><br>æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨æ¯”è¼ƒã™ã‚‹ã¨ã€CoverageãŒé«˜ãç”Ÿæˆçš„ãªã‚‚ã®ã‚’å¤šãå«ã‚€ã“ã¨ãŒç‰¹å¾´<br><br>è©³ç´°ã¯ï¼š


<a href="https://summari.es" target="_blank" rel="noopener noreferrer">https://summari.es</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DialogueGeneration.html" target="_blank" rel="noopener noreferrer">#DialogueGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2018-02-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/255" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Personalizing Dialogue Agents: I have a dog, do you have pets too?, Saizheng Zhang+, ACL'18</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’åŸºã«chit-chatã‚’é­…åŠ›çš„ã«ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’ææ¡ˆã€‚ãƒ¢ãƒ‡ãƒ«ã¯ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã«åŸºã¥ãæ¡ä»¶ä»˜ã‘ã¨ç›¸æ‰‹ã®æƒ…å ±ã‚’è€ƒæ…®ã—ã€æ¬¡ã®ç™ºè©±ã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã§å¯¾è©±ã‚’æ”¹å–„ã€‚å¯¾è©±è€…ã®ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã«ã€å€‹äººçš„ãªè©±é¡Œã§å¼•ãè¾¼ã‚€ã‚ˆã†ã«è¨“ç·´ã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/134" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Deep Reinforced Model for Abstractive Summarization, Paulus+ï¼ˆwith Socherï¼‰, ICLR'18</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/TACL.html" target="_blank" rel="noopener noreferrer">#TACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/92" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generating Sentences by Editing Prototypes, Guu+, TACL'18</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/ReadingComprehension.html" target="_blank" rel="noopener noreferrer">#ReadingComprehension</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2449" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for   Reading Comprehension, Mandar Joshi+, ACL'17</a>
<span class="snippet"><span>GPT Summary</span>- TriviaQAã¯ã€650Kä»¥ä¸Šã®è³ªå•-å›ç­”-è¨¼æ‹ ãƒˆãƒªãƒ—ãƒ«ã‚’å«ã‚€èª­è§£ç†è§£ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€95Kã®è³ªå•-å›ç­”ãƒšã‚¢ã¨å¹³å‡6ã¤ã®è¨¼æ‹ æ–‡æ›¸ã‚’æä¾›ã€‚è¤‡é›‘ãªè³ªå•ã‚„æ§‹æ–‡çš„å¤‰å‹•ãŒã‚ã‚Šã€æ–‡ã‚’è¶…ãˆãŸæ¨è«–ãŒå¿…è¦ã€‚ç‰¹å¾´ãƒ™ãƒ¼ã‚¹ã®åˆ†é¡å™¨ã¨æœ€å…ˆç«¯ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®2ã¤ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’è©•ä¾¡ã—ãŸãŒã€äººé–“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ã¯åŠã°ãšã€TriviaQAã¯ä»Šå¾Œã®ç ”ç©¶ã«ãŠã‘ã‚‹é‡è¦ãªãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã§ã‚ã‚‹ã€‚</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-04-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1911" target="_blank" rel="noopener noreferrer" class="title-link">Outrageously Large Neural Networks: The Sparsely-Gated  Mixture-of-Experts Layer, Noam Shazeer+, ICLR'17</a>
<span class="snippet"><span>GPT Summary</span>- æ¡ä»¶ä»˜ãè¨ˆç®—ã‚’ç”¨ã„ãŸã‚¹ãƒ‘ãƒ¼ã‚¹ã‚²ãƒ¼ãƒ†ãƒƒãƒ‰ãƒŸã‚¯ã‚¹ãƒãƒ£ãƒ¼ã‚ªãƒ–ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆï¼ˆMoEï¼‰ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’å°å…¥ã—ã€ãƒ¢ãƒ‡ãƒ«å®¹é‡ã‚’1000å€ä»¥ä¸Šå‘ä¸Šã€‚å­¦ç¿’å¯èƒ½ãªã‚²ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒå„ä¾‹ã«å¯¾ã—ã¦ã‚¹ãƒ‘ãƒ¼ã‚¹ãªã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®çµ„ã¿åˆã‚ã›ã‚’æ±ºå®šã€‚æœ€å¤§1370å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®MoEã‚’LSTMå±¤ã«é©ç”¨ã—ã€è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚„æ©Ÿæ¢°ç¿»è¨³ã§ä½ã‚³ã‚¹ãƒˆã§å„ªã‚ŒãŸæ€§èƒ½ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>Mixture-of-Experts (MoE) Layerã‚’ææ¡ˆã—ãŸç ”ç©¶</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/989" target="_blank" rel="noopener noreferrer" class="title-link">Why We Need New Evaluation Metrics for NLG, EMNLP'17</a>
<span class="snippet"><span>GPT Summary</span>- NLGã®è©•ä¾¡ã«ã¯è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ãŒä½¿ã‚ã‚Œã¦ã„ã‚‹ãŒã€æœ¬ç ”ç©¶ã§ã¯ã‚·ã‚¹ãƒ†ãƒ ã‚„ãƒ‡ãƒ¼ã‚¿ã«ä¾å­˜ã—ãªã„æ–°ã—ã„è©•ä¾¡æ‰‹æ³•ã®å¿…è¦æ€§ã‚’ææ¡ˆã™ã‚‹ã€‚å¹…åºƒã„æŒ‡æ¨™ã‚’èª¿æŸ»ã—ã€ãã‚Œã‚‰ãŒãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ã®NLGã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸã‚·ã‚¹ãƒ†ãƒ ã®å‡ºåŠ›ã®äººé–“ã®åˆ¤æ–­ã‚’å¼±ãåæ˜ ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã¾ãŸã€è©•ä¾¡æŒ‡æ¨™ã®æ€§èƒ½ã¯ãƒ‡ãƒ¼ã‚¿ã¨ã‚·ã‚¹ãƒ†ãƒ ã«ä¾å­˜ã™ã‚‹ã“ã¨ã‚‚ç¤ºã™ãŒã€è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ã¯ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã§ä¿¡é ¼æ€§ãŒã‚ã‚Šã€ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã‚’ã‚µãƒãƒ¼ãƒˆã§ãã‚‹ã“ã¨ã‚’ç¤ºå”†ã™ã‚‹ã€‚ç‰¹ã«ã€ä½ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã‚±ãƒ¼ã‚¹ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¢å­˜ã®NLGã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ãŒhuman judgementsã¨ã®correlationãŒã‚ã¾ã‚Šé«˜ããªã„ã“ã¨ã‚’æŒ‡æ‘˜ã—ãŸç ”ç©¶</p></span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/STS%20(SemanticTextualSimilarity).html" target="_blank" rel="noopener noreferrer">#STS (SemanticTextualSimilarity)</a>
<span class="issue_date">Issue Date: 2023-07-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/909" target="_blank" rel="noopener noreferrer" class="title-link">Construction of a Japanese Word Similarity Dataset, Yuya Sakaizawa+, N_A, arXiv'17</a>
<span class="snippet"><span>GPT Summary</span>- æ—¥æœ¬èªã®åˆ†æ•£è¡¨ç¾ã®è©•ä¾¡ã®ãŸã‚ã«ã€æ—¥æœ¬èªã®å˜èªã®é¡ä¼¼æ€§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ãŸã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€æ—¥æœ¬èªã®åˆ†æ•£è¡¨ç¾ã®è©•ä¾¡ã«ä½¿ç”¨ã§ãã‚‹åˆã‚ã¦ã®ãƒªã‚½ãƒ¼ã‚¹ã§ã‚ã‚Šã€ä¸€èˆ¬çš„ãªå˜èªã ã‘ã§ãªãçã—ã„å˜èªã‚‚å«ã¾ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>github: 


<a href="https://github.com/tmu-nlp/JapaneseWordSimilarityDataset" target="_blank" rel="noopener noreferrer">https://github.com/tmu-nlp/JapaneseWordSimilarityDataset</a>


<br><br><br><br>å˜èªãƒ¬ãƒ™ãƒ«ã®é¡ä¼¼åº¦ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°ã—ãŸã„å ´åˆã¯ä½¿ã£ã¦ã‚‚ã‚ˆã„ã‹ã‚‚ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/CommentGeneration.html" target="_blank" rel="noopener noreferrer">#CommentGeneration</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<span class="issue_date">Issue Date: 2019-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/327" target="_blank" rel="noopener noreferrer" class="title-link">Attend to You: Personalized Image Captioning with Context Sequence Memory Networks, Park+, CVPR'17</a>
<span class="snippet"><span>Comment</span><p>ç”»åƒãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ãã®ç”»åƒã«å¯¾ã™ã‚‹Hashtag predictionã¨ã€personalizedãªpost generationã‚’è¡Œã†ã‚¿ã‚¹ã‚¯ã‚’ææ¡ˆã€‚<br><br>Instagramã®Postã®ç°¡æ˜“åŒ–ãªã©ã«å¿œç”¨ã§ãã‚‹ã€‚<br><br>Postã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã¯ã€è‡ªèº«ã®è¨€è‘‰ã§ã€ç”»åƒã«ã¤ã„ã¦ã®èª¬æ˜ã‚„ã€contextã¨ã„ã£ãŸã“ã¨ã‚’èª¬æ˜ã—ãªã‘ã‚Œã°ãªã‚‰ãšã€image captioningã‚’ã™ã‚‹éš›ã«Personalization IssueãŒç”Ÿã˜ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã€‚<br><br><br><br></p>
<p>official implementation: 


<a href="https://github.com/cesc-park/attend2u" target="_blank" rel="noopener noreferrer">https://github.com/cesc-park/attend2u</a>


</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/SIGIR.html" target="_blank" rel="noopener noreferrer">#SIGIR</a>
<span class="issue_date">Issue Date: 2019-04-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/309" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Neural Rating Regression with Abstractive Tips Generation for  Recommendation, Piji Li+, arXiv'17</a>
<span class="snippet"><span>GPT Summary</span>- Eã‚³ãƒãƒ¼ã‚¹ã‚µã‚¤ãƒˆã®æ–°ã—ã„ã€ŒTipsã€æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®çµŒé¨“ã‚„æ„Ÿæƒ…ã‚’è¡¨ç¾ã™ã‚‹çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹æ·±å±¤å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒNRTã€ã‚’ææ¡ˆã€‚NRTã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®æ½œåœ¨è¡¨ç¾ã‚’åŸºã«ã€æ­£ç¢ºãªè©•ä¾¡äºˆæ¸¬ã¨é«˜å“è³ªãªæŠ½è±¡çš„ãƒ’ãƒ³ãƒˆã®ç”Ÿæˆã‚’å®Ÿç¾ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€NRTã¯æ—¢å­˜æ‰‹æ³•ã«å¯¾ã—ã¦é¡•è‘—ãªæ”¹å–„ã‚’ç¤ºã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½“é¨“ã‚„æ„Ÿæƒ…ã‚’åŠ¹æœçš„ã«åæ˜ ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Rating Predictionã¨tips generationã‚’åŒæ™‚ã«è¡Œã†ã“ã¨ã§ã€ä¸¡è€…ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ãŸæœ€åˆã®ç ”ç©¶ã€‚<br><br>tipsã¨ã¯ã€ãƒ¦ãƒ¼ã‚¶ã®çµŒé¨“ã‚„æ„Ÿã˜ãŸã“ã¨ã‚’ã€çŸ­ã„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ1æ–‡ã¨ã‹ï¼‰ã§ç°¡æ½”ã«è¨˜ã—ãŸã‚‚ã®ã€‚</p>
<p><img src="https://user-images.githubusercontent.com/12249301/56012618-43423c00-5d28-11e9-82ff-fe90c9dd7d1c.png" alt="image" loading="lazy"><br><br><br><br>ãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦ã¯ã‚ã¾ã‚Šãè©³ã—ãèª­ã‚“ã§ã„ãªã„ãŒã€å›³ã‚’è¦‹ã‚‹æ„Ÿã˜ã€user latent factorã¨item latent factorã‚’MF layerã¨seq2seqã§å…±æœ‰ã—ã€åŒæ™‚å­¦ç¿’ã•ã›ã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>ãŠãã‚‰ãã€MFã¨text generationã‚’jointã§è¡Œã†NNãƒ¢ãƒ‡ãƒ«ã¯ã“ã®ç ”ç©¶ãŒåˆã‚ã¦ï¼ˆtextã®æƒ…å ±ã‚’MFã®æ”¹å–„ã«ä½¿ãŠã†ã¨ã„ã†è©¦ã¿ã¯å¤ãã‹ã‚‰ã‚„ã‚‰ã‚Œã¦ã„ã‚‹ãŒã€generationã¾ã§ã¯å¤šåˆ†ã‚„ã£ã¦ãªã„ï¼‰ã§ã€ã“ã®ãƒ¢ãƒ‡ãƒ«åŒ–ã®ä»•æ–¹ãŒãã®å¾Œã®ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã«ãªã£ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/INLG.html" target="_blank" rel="noopener noreferrer">#INLG</a>
<span class="issue_date">Issue Date: 2019-04-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/307" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Towards automatic generation of product reviews from aspectsentiment scores, Zang+, INLG'17</a>
<span class="snippet"><span>Comment</span><p>hierarchicalãªNNã§ã€long reviewã®ç”Ÿæˆã«å–ã‚Šçµ„ã‚“ã è«–æ–‡</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/EACL.html" target="_blank" rel="noopener noreferrer">#EACL</a>
<span class="issue_date">Issue Date: 2019-03-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/305" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning to Generate Product Reviews from Attributes, Dong+, EACL'17</a>
<span class="snippet"><span>Comment</span><p>ï¼ˆãŸã¶ã‚“ï¼‰æœ€åˆã®review generationè«–æ–‡</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/IJCNLP.html" target="_blank" rel="noopener noreferrer">#IJCNLP</a>
<span class="issue_date">Issue Date: 2019-02-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/303" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Estimating Reactions and Recommending Products with Generative Models of Reviews, Ni+, IJCNLP'17</a>
<span class="snippet"><span>Comment</span><p>Collaborative Filtering (CF) ã«ã‚ˆã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ¨è–¦ã¨Review Generationã‚’åŒæ™‚ã«å­¦ç¿’ã—ã€<br><br>ä¸¡è€…ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹è©±ã€‚<br><br>éå¸¸ã«èˆˆå‘³æ·±ã„è¨­å®šã§ã€ã“ã®ã‚ˆã†ãªå®Ÿé¨“è¨­å®šã§Review Generationã‚’è¡Œãªã£ãŸåˆã‚ã¦ã®ç ”ç©¶ã€‚</p>
<p>CFã§ã¯Matrix Factorization (MF) ã‚’åˆ©ç”¨ã—ã€Review Generationã§ã¯ã€LSTM-basedãªseq2seqã‚’åˆ©ç”¨ã™ã‚‹ã€‚MFã¨Review Generationã®ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€å…±é€šã®user latent factorã¨item latent factorã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€joint modelã¨ã—ã¦ã„ã‚‹ã€‚ã“ã®ã¨ãã€latent factorã¯ã€ä¸¡ã‚¿ã‚¹ã‚¯ã‚’é€šã˜ã¦å­¦ç¿’ã•ã‚Œã‚‹ã€‚<br><br><br><br>CFã§ã¯ã€Implicitãªè¨­å®šãªã®ã§ã€Rating Predictionã§ã¯ãªãã€binary classificationã‚’è¡Œã†ã“ã¨ã§ã€æ¨è–¦ã‚’è¡Œã†ã€‚<br><br>classificationã«ã¯ã€Matrix Factorization (MF) ã‚’æ‹¡å¼µã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã‚‹ã€‚<br><br>å…·ä½“çš„ã«ã¯ã€é€šå¸¸ã®MFã§ã¯ã€user latent factorã¨item latent factorã®å†…ç©ã«ã‚ˆã£ã¦ã€userã®itemã«å¯¾ã™ã‚‹preferenceã‚’è¡¨ç¾ã™ã‚‹ãŒã€ã“ã®ã¨ãã«ã€target userãŒéå»ã«è¨˜è¼‰ã—ãŸãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»ãŠã‚ˆã³target itemã«é–¢ã™ã‚‹æƒ…å ±ã‚’åˆ©ç”¨ã™ã‚‹ã€‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®representationã®averageã‚’ã¨ã£ãŸvectorã¨ã€MFã®çµæœã‚’linear layerã«ã‚ˆã£ã¦å†™åƒã—ã€æœ€çµ‚çš„ãªclassification scoreã¨ã—ã¦ã„ã‚‹ã€‚<br><br><br><br>Review Generationã§ã¯ã€åŸºæœ¬çš„ã«ã¯seq2seqã®inputã®Embeddingã«å¯¾ã—ã¦ã€user latent factor, item latent factorã‚’concatã™ã‚‹ã ã‘ã€‚hidden stateã«ç›´æ¥concatã—ãªã„ã®ã¯ã€latent factorã‚’å„ã‚¹ãƒ†ãƒƒãƒ—ã§è€ƒæ…®ã§ãã‚‹ãŸã‚ã€long, coherentãªsequenceã‚’ç”Ÿæˆã§ãã‚‹ã‹ã‚‰ã€ã¨èª¬æ˜ã—ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/56011945-15a7c380-5d25-11e9-9a0d-8835bdb6cbed.png" alt="image" loading="lazy"><br><br></p>
<p><img src="https://user-images.githubusercontent.com/12249301/56012061-9c5ca080-5d25-11e9-9327-2c7a9c3ee365.png" alt="image" loading="lazy"><br><br><br><br>Recommendã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã¯ã€Bayesian Personalized Ranking, Generalized Matrix Factorizationã‚’outperformã€‚</p>
<p><img src="https://user-images.githubusercontent.com/12249301/56012129-f65d6600-5d25-11e9-919a-33018878f96e.png" alt="image" loading="lazy"><br><br><br><br>Review Generationã¯Perplexityã«ã‚ˆã‚Šè©•ä¾¡ã—ã¦ã„ã‚‹ã€‚ææ¡ˆæ‰‹æ³•ãŒcharacter based lstmã‚’outperformã€‚<br><br>Perplexityã«ã‚ˆã‚‹è©•ä¾¡ã ã¨è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã®è©•ä¾¡ã—ã‹ã§ãã¦ã„ãªã„ã®ã§ã€BLEU, ROUGEãªã©ã‚’åˆ©ç”¨ã—ãŸè©•ä¾¡ãªã©ã‚‚ã‚ã£ã¦è‰¯ã„ã®ã§ã¯ã€‚</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/VariationalAutoEncoder.html" target="_blank" rel="noopener noreferrer">#VariationalAutoEncoder</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2018-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/278" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Salience Estimation via Variational Auto-Encoders for Multi-Document Summarization, Li+, AAAI'17</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2018-06-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/275" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning to Paraphrase for Question Answering, Li Dong+, EMNLP'17</a>
<span class="snippet"><span>GPT Summary</span>- QAã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹ãƒ‘ãƒ©ãƒ•ãƒ¬ãƒ¼ã‚ºã®é‡è¦æ€§ã«ç€ç›®ã—ã€è³ªå•ã¨å›ç­”ã®ãƒšã‚¢ã‚’ç”¨ã„ãŸã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã‚’é€šã˜ã¦ã€æ­£ã—ã„å›ç­”ã‚’å¾—ã‚‹å¯èƒ½æ€§ã®é«˜ã„è¡¨ç¾ã«é‡ã¿ã‚’ä»˜ã‘ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€ææ¡ˆæ‰‹æ³•ãŒæ€§èƒ½ã‚’å‘ä¸Šã•ã›ã€ã‚·ãƒ³ãƒ—ãƒ«ãªQAãƒ¢ãƒ‡ãƒ«ã§ã‚‚ç«¶äº‰åŠ›ã®ã‚ã‚‹çµæœã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>question-answeringã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€paraphrasingã‚’æ´»ç”¨ã—ã¦ç²¾åº¦å‘ä¸Šã•ã›ã‚‹ç ”ç©¶<br><br>ä¼¼ãŸã‚ˆã†ãªæ„å‘³ã®è³ªå•ãŒã€ç•°ãªã‚‹è¡¨ç¾ã§å‡ºç¾ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã®ã§ã€<br><br>questionã®æ§˜ã€…ãªparaphrasingã‚’ç”¨æ„ã—ã¦æ´»ç”¨ã—ãŸã„ã¨ã„ã†æ°—æŒã¡ã€‚<br><br>ãŸã¨ãˆã°ã€<br><br><br><br>- Is the campus far from Shibuya?<br><br>- Is the campus near the city center?<br><br><br><br>ã®ã‚ˆã†ãªä¾‹ãŒã‚ã’ã‚‰ã‚Œã‚‹ã€‚<br><br><br><br>æ‰‹æ³•ã¨ã—ã¦ã¯ã€paraphrasing modelã¨qa modelã‚’ç”¨æ„ã—ã€ã‚ã‚‹questionãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€paraphrasing modelã§paraphraseã®ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã€ãã®å¾Œã€å„paraphrasingã®å€™è£œã«å¯¾ã—ã¦qa modelã§è§£ç­”ã‚’äºˆæ¸¬ã—ã€ä¸¡è€…ã®ã‚¹ã‚³ã‚¢ã®ç©ã®summationã«ã‚ˆã£ã¦æœ€çµ‚çš„ãªanswerã‚’æ±ºå®š</p>
<p>QAã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºãŒå°ã•ã„ã®ã§ã€paraphrasingã®ã‚ˆã†ãªæ‰‹æ³•ãŒæœ‰åŠ¹ã«åƒã„ã¦ã„ã‚‹ã®ã‹ã‚‚ã—ã‚Œãªã„</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2018-02-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/248" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Recent Trends in Deep Learning Based Natural Language Processing, Tom Young+, arXiv'17</a>
<span class="snippet"><span>GPT Summary</span>- æ·±å±¤å­¦ç¿’æ‰‹æ³•ã®é€²åŒ–ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€NLPã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹é‡è¦ãªãƒ¢ãƒ‡ãƒ«ã¨æ‰‹æ³•ã‚’è¦ç´„ãƒ»æ¯”è¼ƒã€‚NLPã«ãŠã‘ã‚‹æ·±å±¤å­¦ç¿’ã®éå»ã€ç¾åœ¨ã€æœªæ¥ã«ã¤ã„ã¦ã®ç†è§£ã‚’æ·±ã‚ã‚‹ã€‚</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/GenerativeAdversarialNetwork.html" target="_blank" rel="noopener noreferrer">#GenerativeAdversarialNetwork</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2018-02-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/247" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Adversarial Ranking for Language Generation, Lin+, NIPS'17</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/245" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Attention Is All You Need, Ashish Vaswani+, arXiv'17</a>
<span class="snippet"><span>GPT Summary</span>- Transformerã¯ã€å†å¸°ã‚„ç•³ã¿è¾¼ã¿ã‚’æ’é™¤ã—ã€æ³¨æ„æ©Ÿæ§‹ã®ã¿ã«åŸºã¥ã„ãŸæ–°ã—ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æ©Ÿæ¢°ç¿»è¨³ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸå“è³ªã‚’ç¤ºã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“ã‚’å¤§å¹…ã«çŸ­ç¸®ã€‚WMT 2014ã®è‹±ç‹¬ç¿»è¨³ã§28.4 BLEUã€è‹±ä»ç¿»è¨³ã§41.8 BLEUã‚’é”æˆã—ã€æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€è‹±èªã®æ§‹æ–‡è§£æã«ã‚‚æˆåŠŸè£ã«é©ç”¨å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Transformer (self-attentionã‚’åˆ©ç”¨) è«–æ–‡<br><br>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š


<a href="https://www.slideshare.net/DeepLearningJP2016/dlattention-is-all-you-need" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/DeepLearningJP2016/dlattention-is-all-you-need</a>


<br><br>è§£èª¬è¨˜äº‹ï¼š


<a href="https://qiita.com/nishiba/items/1c99bc7ddcb2d62667c6" target="_blank" rel="noopener noreferrer">https://qiita.com/nishiba/items/1c99bc7ddcb2d62667c6</a>


<br><br><br><br>* æ–°ã—ã„ç¿»è¨³ãƒ¢ãƒ‡ãƒ«(Transformer)ã‚’ææ¡ˆã€‚æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ä¸¦åˆ—åŒ–ã«å¯¾å¿œã—ã¦ãŠã‚Šã€çŸ­æ™‚é–“ã®è¨“ç·´ã§ï¼ˆæ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã®1/4ä»¥ä¸‹ã®ã‚³ã‚¹ãƒˆï¼‰é«˜ã„BLEUã‚¹ã‚³ã‚¢ã‚’é”æˆã—ãŸã€‚<br><br>* Transformerã¯RNNã‚„CNNã‚’ä½¿ã‚ãšã€attentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«åŸºã¥ã„ã¦ã„ã‚‹ã€‚<br><br><br><br>ï¼ˆè§£èª¬ã‚ˆã‚Šï¼‰</p>
<p>åˆ†ã‹ã‚Šã‚„ã™ã„:<br>


<a href="https://qiita.com/halhorn/items/c91497522be27bde17ce" target="_blank" rel="noopener noreferrer">https://qiita.com/halhorn/items/c91497522be27bde17ce</a>


</p>
<p>Transformerã®å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ã®outputã®shapeã‚„ã€attention_maskã®å½¢çŠ¶ã€å®Ÿè£…ã«ã¤ã„ã¦è¨˜è¿°ã•ã‚Œã¦ãŠã‚Šæœ‰ç”¨:<br>


<a href="https://qiita.com/FuwaraMiyasaki/items/239f3528053889847825" target="_blank" rel="noopener noreferrer">https://qiita.com/FuwaraMiyasaki/items/239f3528053889847825</a>


</p>
<p>é›†åˆçŸ¥</p></span><br><br>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Discourse.html" target="_blank" rel="noopener noreferrer">#Discourse</a>
<a class="button" href="articles/ICWSM.html" target="_blank" rel="noopener noreferrer">#ICWSM</a>
<span class="issue_date">Issue Date: 2018-01-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/244" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Characterizing Online Discussion Using Coarse Discourse Sequences, Zhang+, ICWSM'17, ï¼ˆReddit Coarse Discourse dataï¼‰</a>
<span class="snippet"><span>Comment</span><p>Redditã®Discussion Forumã«9ç¨®é¡ã®Discourse Actsã‚’ä»˜ä¸ã—ãŸãƒ‡ãƒ¼ã‚¿ã€‚<br><br><br><br>ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹éš›ã¯ã€ä»¥ä¸‹ã®å‡¦ç†ã‚’é©ç”¨ï¼š<br><br>* Google Big Query dump ã®Redditãƒ‡ãƒ¼ã‚¿238Mã‚¹ãƒ¬ãƒƒãƒ‰<br><br>* ãã‚Œã«Reply Filterã‚’ã‹ã‘87.5Mã‚¹ãƒ¬ãƒƒãƒ‰<br><br>* ã•ã‚‰ã«ãã“ã‹ã‚‰ã‚¹ãƒ¬ãƒƒãƒ‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚„ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ã‚¯ãªãƒ•ã‚£ãƒ«ã‚¿ã‚’ã‹ã‘ã¦10000ã‚¹ãƒ¬ãƒƒãƒ‰ã«çµã‚Šè¾¼ã‚“ã <br><br>* ã“ã‚Œã‚‰ã«Discourse ActsãŒä»˜ä¸ã•ã‚Œã¦ãŠã‚Šã€ãã‚Œãã‚Œã®ã‚³ãƒ¡ãƒ³ãƒˆã«å¯¾ã—ã¦9ç¨®é¡ã®ã‚«ãƒ†ã‚´ãƒªï¼ˆQUESTIONï¼ˆè³ªå•ï¼‰, ANSWERï¼ˆå›ç­”ï¼‰, ANNOUNCEMENTï¼ˆæƒ…å ±ç™ºä¿¡ï¼‰, AGREEMENTï¼ˆæ„è¦‹ã«å¯¾ã™ã‚‹åŒæ„, APPRECIATION ï¼ˆæ„Ÿè¬ï¼‰ãªã©ï¼‰ãŒä»˜ä¸ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br><br><br>ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ä½œæˆã™ã‚‹ã¨ãã¯ã€3äººã®ã‚¢ãƒãƒ†ãƒ¼ã‚¿ã‚’ç”¨ã„ã€è¤‡æ•°ã®ACTã‚’ä»˜ä¸ã™ã‚‹ã“ã¨ã‚’è¨±ã—ã€OTHERã‚‚è¨±å®¹ã€‚<br><br>Discourse Actsã‚’ã©ã‚Œã ã‘åˆ¤å®šã§ãã‚‹ã‹ã®ãƒ¢ãƒ‡ãƒ«ã‚‚æ§‹ç¯‰ã—ã¦ãŠã‚Šã€loggistic regression + L2 regularization, Hidden Markov Model, Conditional Random Fieldsãªã©ã‚’ç”¨ã„ã€ç´ æ€§ã¯Content-based (unigram, bigram, tf-idfãªã©), Structure-based (treeã®depth, # of sentencde, wordãªã©), Author-based (ä¸€ç•ªæœ€åˆã®æŠ•ç¨¿è€…ã¨åŒã˜ã‹ã€è¦ªã¨åŒã˜æŠ•ç¨¿è€…ã‹ãªã©), Community (subreddit name (ã‚«ãƒ†ã‚´ãƒªå))ãªã©ã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚<br><br><br><br>CRFã‚’é©ç”¨ã™ã‚‹éš›ã¯ã€ã‚¹ãƒ¬ãƒƒãƒ‰ã®Treeã®ãƒ–ãƒ©ãƒ³ãƒã‚’ç³»åˆ—ã¨ã¿ãªã™ã€‚åŸºæœ¬çš„ã«CRFãŒä¸€ç•ªã‚ˆãã€Få€¤ã§0.75ç¨‹åº¦ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/234" target="_blank" rel="noopener noreferrer" class="title-link">ã‚¼ãƒ­ã‹ã‚‰å§‹ã‚ã‚‹ ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ©Ÿæ¢°ç¿»è¨³, ä¸­æ¾¤æ•æ˜, NLP'17</a>
<span class="snippet"><span>Comment</span><p>ä¸­æ¾¤ã•ã‚“ã«ã‚ˆã‚‹NMTãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã€‚</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/211" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MoodSwipe: A Soft Keyboard that Suggests Messages Based on User-Specified Emotions, Huang+, EMNLP'17</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/UserModeling.html" target="_blank" rel="noopener noreferrer">#UserModeling</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/210" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Multi-View Unsupervised User Feature Embedding for Social Media-based Substance Use Prediction, Ding+, EMNLP'17</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/209" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Coarse-to-Fine Attention Models for Document Summarization, Ling+ ï¼ˆwith Rushï¼‰, ACL'17 Workshop on New Frontiers in Summarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/208" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Adapting Sequence Models for Sentence Correction, Allen Schmaltz+, arXiv'17</a>
<span class="snippet"><span>GPT Summary</span>- æ–‡å­—ãƒ™ãƒ¼ã‚¹ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ»ãƒ„ãƒ¼ãƒ»ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒã€å˜èªãƒ™ãƒ¼ã‚¹ã‚„ã‚µãƒ–ãƒ¯ãƒ¼ãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚æ–‡ä¿®æ­£ã‚¿ã‚¹ã‚¯ã§åŠ¹æœçš„ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚å‡ºåŠ›ã‚’å·®åˆ†ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ã“ã¨ã§ã€æ¨™æº–çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚ˆã‚Šã‚‚æ€§èƒ½ãŒå‘ä¸Šã—ã€æœ€å¼·ã®ãƒ¢ãƒ‡ãƒ«ã¯ãƒ•ãƒ¬ãƒ¼ã‚ºãƒ™ãƒ¼ã‚¹ã®æ©Ÿæ¢°ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã‚’6 M2ãƒã‚¤ãƒ³ãƒˆæ”¹å–„ã—ãŸã€‚ã¾ãŸã€CoNLL-2014ãƒ‡ãƒ¼ã‚¿ç’°å¢ƒã«ãŠã„ã¦ã€å·®åˆ†ãƒ¢ãƒ‡ãƒ«åŒ–ã«ã‚ˆã‚Šã€ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«ã§å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§ã‚‚åŒç­‰ä»¥ä¸Šã®M2ã‚¹ã‚³ã‚¢ã‚’é”æˆã§ãã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/207" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Challenges in Data-to-Document Generation, Wiseman+ ï¼ˆwith Rushï¼‰, EMNLP'17</a>
<span class="snippet"><span>Comment</span><p>ãƒ»RotoWireï¼ˆNBAã®ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ + ã‚µãƒãƒªï¼‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—å…¬é–‹<br><br><img src="https://user-images.githubusercontent.com/12249301/119625430-23f1c480-be45-11eb-8ff8-5e9223d41481.png" alt="image" loading="lazy"><br><br><br><br>ãƒ»Rotowireãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆé‡<br><br><img src="https://user-images.githubusercontent.com/12249301/119625488-323fe080-be45-11eb-952e-d2d21d6e5847.png" alt="image" loading="lazy"></p>
<p>ã€ãƒ¢ãƒ‡ãƒ«ã®æ¦‚è¦ã€‘<br><br>ãƒ»attention-based encoder-decoder model<br><br><br><br>ãƒ»BaseModel<br><br>ã€€- ãƒ¬ã‚³ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ r ã®å„è¦ç´ ï¼ˆr.e: ãƒãƒ¼ãƒ åç­‰ã®ENTITY r.t: POINTSç­‰ã®ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—, r.m: ãƒ‡ãƒ¼ã‚¿ã®valueï¼‰ã‹ã‚‰embeddingã‚’lookupã—ã€1-layer MLPã‚’é©ç”¨ã—ã€ãƒ¬ã‚³ãƒ¼ãƒ‰ã®å„è¦ç´ ã®representationï¼ˆsource data recordsï¼‰ã‚’å–å¾—<br><br>ã€€- Luongã‚‰ã®attentionã‚’åˆ©ç”¨ã—ãŸLSTM Decoderã‚’ç”¨æ„ã—ã€source data recordsã¨t-1ã‚¹ãƒ†ãƒƒãƒ—ç›®ã§ã®å‡ºåŠ›ã«ã‚ˆã£ã¦æ¡ä»¶ä»˜ã‘ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¦ã„ã<br><br>ã€€- negative log likelihoodãŒminimizeã•ã‚Œã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹<br><br><br><br>ãƒ»Copying<br><br>ã€€- ã‚³ãƒ”ãƒ¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å°å…¥ã—ã€ç”Ÿæˆæ™‚ã®ç¢ºç‡åˆ†å¸ƒã«ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã‹ã‚‰ã‚³ãƒ”ãƒ¼ã•ã‚Œã‚‹ã‹å¦ã‹ã‚’å«ã‚ãŸåˆ†å¸ƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã€‚ã‚³ãƒ”ãƒ¼ã®å¯¾è±¡ã¯ã€å…¥åŠ›ãƒ¬ã‚³ãƒ¼ãƒ‰ã®valueãŒã‚³ãƒ”ãƒ¼ã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚<br><br>ã€€- ã‚³ãƒ”ãƒ¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ã¯ä¸‹è¨˜å¼ã§è¡¨ç¾ã•ã‚Œã‚‹ Conditional Copy Modelã‚’åˆ©ç”¨ã—ã€p(zt|y1:t-1, s)ã¯MLPã§è¡¨ç¾ã™ã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/119628147-cc088d00-be47-11eb-84de-6a1d158d78e5.png" alt="image" loading="lazy"><br><br>ã€€- ã¾ãŸpcopyã¯ã€ç”Ÿæˆã—ã¦ã„ã‚‹æ–‡ä¸­ã«ã‚ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨ã‚¿ã‚¤ãƒ—ãŒå‡ºç¾ã™ã‚‹å ´åˆã«ã€å¯¾å¿œã™ã‚‹valueã‚’ã‚³ãƒ”ãƒ¼ã—ç”Ÿæˆã•ã‚Œã‚‹ã‚ˆã†ã«ã€ä¸‹è¨˜å¼ã§è¡¨ç¾ã™ã‚‹<br><br><img src="https://user-images.githubusercontent.com/12249301/119628389-07a35700-be48-11eb-9c69-27b70fcbcdef.png" alt="image" loading="lazy"><br><br>ã€€- ã“ã“ã§ r(yt) =<br><br><img src="https://user-images.githubusercontent.com/12249301/119628615-39b4b900-be48-11eb-9305-509a6eed8182.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/146" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Why We Need New Evaluation Metrics for NLG, Novikova+, EMNLP'17</a>
<span class="snippet"><span>Comment</span><p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š


<a href="https://www.dropbox.com/s/7o8v64nr6gyj065/20170915_SNLP2017_Nishikawa.pptx?dl=0" target="_blank" rel="noopener noreferrer">https://www.dropbox.com/s/7o8v64nr6gyj065/20170915_SNLP2017_Nishikawa.pptx?dl=0</a>


</p>
<p>è¨€èªç”Ÿæˆã®è©•ä¾¡æŒ‡æ¨™ãŒä¿¡ç”¨ãªã‚‰ãªã„ã®ã§ã€3ç¨®é¡ã®ç”Ÿæˆå™¨ã€3ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ã—ã€å¤šæ•°ã®è‡ªå‹•è©•ä¾¡å°ºåº¦ã‚’åˆ©ç”¨ã—ãŸè©•ä¾¡çµæœã¨äººæ‰‹è©•ä¾¡ã®çµæœã‚’æ¯”è¼ƒã—ãŸçµæœã€ç›¸é–¢ãŒãªã‹ã£ãŸã€‚<br><br><br><br>æ—¢å­˜ã®è‡ªå‹•è©•ä¾¡ã¯äººæ‰‹è©•ä¾¡ã¨å¼±ã„ç›¸é–¢ã—ã‹ãªãã€ãã®æœ‰åŠ¹æ€§ã¯ãƒ‡ãƒ¼ã‚¿ã¨ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ä¾å­˜ã€‚<br><br>ã‚·ã‚¹ãƒ†ãƒ é–“ã®æ¯”è¼ƒãŠã‚ˆã³ã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½ãŒä½ã„å ´åˆã«ãŠã„ã¦ã¯æœ‰åŠ¹ã€‚<br><br><br><br>(2025.05.12)<br>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ä¸­ã®ã‚¹ãƒ©ã‚¤ãƒ‰ãŒè¤‡æ•°æ²è¼‰ã•ã‚Œã¦ã„ã¾ã—ãŸãŒå‰Šé™¤ã—ã¾ã—ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/135" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Get To The Point: Summarization with Pointer-Generator Networks, See+, ACL'17</a>
<span class="snippet"><span>Comment</span><p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š


<a href="https://www.slideshare.net/akihikowatanabe3110/get-to-the-point-summarization-with-pointergenerator-networks/1" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/get-to-the-point-summarization-with-pointergenerator-networks/1</a>


</p>
<p>å˜èªã®ç”Ÿæˆã¨å˜èªã®ã‚³ãƒ”ãƒ¼ã®ä¸¡æ–¹ã‚’è¡Œãˆã‚‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æ–‡æ›¸è¦ç´„ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã€‚<br><br>åŒã˜å˜èªã®ç¹°ã‚Šè¿”ã—ç¾è±¡(repetition)ã‚’ãªãã™ãŸã‚ã«ã€Coverage Mechanismã‚‚å°å…¥ã—ãŸã€‚<br><br><br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/136" target="_blank" rel="noopener noreferrer">[Paper Note] Incorporating Copying Mechanism in Sequence-to-Sequence Learning, Gu+, ACL'16</a>
 ãªã©ã¨æ¯”è¼ƒã™ã‚‹ã¨ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«ã€‚</p>
<p>ä¸€èˆ¬çš„ã«ã€PointerGeneratorã¨å‘¼ã°ã‚Œã‚‹ã€‚<br><br>OpenNMTãªã©ã«ã‚‚å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹: 


<a href="https://opennmt.net/OpenNMT-py/_modules/onmt/modules/copy_generator.html" target="_blank" rel="noopener noreferrer">https://opennmt.net/OpenNMT-py/_modules/onmt/modules/copy_generator.html</a>


</p>
<p>ï¼ˆå‚è€ƒï¼‰Pointer Generator Networksã§è¦ç´„ã—ã¦ã¿ã‚‹ï¼š<br><br>


<a href="https://qiita.com/knok/items/9a74430b279e522d5b93" target="_blank" rel="noopener noreferrer">https://qiita.com/knok/items/9a74430b279e522d5b93</a>


</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/EACL.html" target="_blank" rel="noopener noreferrer">#EACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/133" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Cutting-off redundant repeating generations for neural abstractive summarization, Suzuki+, EACL'17</a>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/GraphConvolutionalNetwork.html" target="_blank" rel="noopener noreferrer">#GraphConvolutionalNetwork</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/CoNLL.html" target="_blank" rel="noopener noreferrer">#CoNLL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/130" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Graph-based Neural Multi-Document Summarization, Yasunaga+, CoNLL'17</a>
<span class="snippet"><span>Comment</span><p>Graph Convolutional Network (GCN)ã‚’ä½¿ã£ã¦ã€MDSã‚„ã‚Šã¾ã—ãŸã¨ã„ã†è©±ã€‚ æ—¢å­˜ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãªMDSãƒ¢ãƒ‡ãƒ« [Cao et al., 2015, 2017] ã§ã¯ã€sentenceé–“ã®relationãŒè€ƒæ…®ã§ãã¦ã„ãªã‹ã£ãŸãŒã€GCNä½¿ã£ã¦è€ƒæ…®ã—ãŸã€‚ ã¾ãŸã€MDSã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãªãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ã«ã¯å°ã•ã™ãã‚‹ãŒï¼ˆabstractiveã«ã™ã‚‹ã®ã¯å³ã—ã„ã¨ã„ã†è©±ã ã¨æ€ã‚ã‚Œã‚‹ï¼Ÿï¼‰ã€sentenceã®salienceã‚’æ±‚ã‚ã‚‹å•é¡Œã«å¸°ç€ã•ã›ã‚‹ã“ã¨ã§ã€ã“ã‚Œã‚’å…‹æœã€‚<br><br><br><br>GCNã§ç”¨ã„ã‚‹Adjacent Matrixã¨ã—ã¦3ç¨®é¡ã®æ–¹æ³•(cosine similarity, G-Flow, PDG)ã‚’è©¦ã—ã€è­°è«–ã‚’ã—ã¦ã„ã‚‹ã€‚PDGãŒææ¡ˆæ‰‹æ³•ã ãŒã€G-Flowã«ã‚ˆã‚‹é‡ã¿ã‚’Personalization Featuresï¼ˆposition, leadã‹å¦ã‹ç­‰ã®ãƒ™ãƒ¼ã‚·ãƒƒã‚¯ãªç´ æ€§ï¼‰ã‹ã‚‰æ±‚ã¾ã‚‹weightã§ã€ã‚ˆã‚Šsentenceã®salienceã‚’æ±‚ã‚ã‚‹éš›ã«ãƒªãƒƒãƒãªæƒ…å ±ã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«è£œæ­£ã—ã¦ã„ã‚‹ã€‚PDGã‚’ç”¨ã„ãŸå ´åˆãŒï¼ˆROUGEçš„ãªè¦³ç‚¹ã§ï¼‰æœ€ã‚‚æ€§èƒ½ãŒã‚ˆã‹ã£ãŸã€‚<br><br><br><br>ãƒ¢ãƒ‡ãƒ«ã®å‡¦ç†ã®æµã‚Œã¨ã—ã¦ã¯ã€Document Clusterä¸­ã®å„sentenceã®hidden stateã‚’GRUãƒ™ãƒ¼ã‚¹ãªRNNã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€ãã‚Œã‚’GCNã®ãƒãƒ¼ãƒ‰ã®åˆæœŸå€¤ã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã€‚GCNã§Lå›ã®propagationå¾Œï¼ˆå®Ÿé¨“ã§ã¯3å›ï¼‰ã«å¾—ã‚‰ã‚ŒãŸãƒãƒ¼ãƒ‰ã®hidden stateã‚’ã€salienceã‚¹ã‚³ã‚¢è¨ˆç®—ã«ç”¨ã„ã‚‹sentence embeddingã€ãŠã‚ˆã³cluster embeddingã®ç”Ÿæˆã«ç”¨ã„ã‚‹ã€‚ cluster embeddingã¯ã€document clusterã‚’globalãªè¦–ç‚¹ã‹ã‚‰è¦‹ã¦ã€salienceã‚¹ã‚³ã‚¢ã«åæ˜ ã•ã›ã‚‹ãŸã‚ã«ç”¨ã„ã‚‰ã‚Œã‚‹ã€‚ æœ€çµ‚çš„ã«ã“ã‚Œã‚‰2ã¤ã®æƒ…å ±ã‚’linearãªlayerã«ã‹ã‘ã¦softmaxã‹ã‘ã¦æ­£è¦åŒ–ã—ã¦ã€salienceã‚¹ã‚³ã‚¢ã¨ã™ã‚‹ã€‚<br><br><br><br>è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹éš›ã¯greedyãªæ–¹æ³•ã‚’ç”¨ã„ã¦ãŠã‚Šã€salienceã‚¹ã‚³ã‚¢ã®é«˜ã„sentenceã‹ã‚‰è¦ç´„é•·ã«é”ã™ã‚‹ã¾ã§é¸æŠã—ã¦ã„ãã€‚ã“ã®ã¨ãã€å†—é•·æ€§ã‚’æ’é™¤ã™ã‚‹ãŸã‚ã€candidateã¨ãªã‚‹sentenceã¨ç”Ÿæˆä¸­ã®è¦ç´„ã¨ã®cosine similarityãŒ0.5ã‚’è¶…ãˆã‚‹ã‚‚ã®ã¯é¸æŠã—ãªã„ã¨ã„ã£ãŸã€ã‚ˆãã‚ã‚‹æ“ä½œã‚’è¡Œãªã£ã¦ã„ã‚‹ã€‚<br><br><br><br>DUC01, 02ã®ãƒ‡ãƒ¼ã‚¿ã‚’training data, DUC03 ã‚’validation data, DUC04ã‚’test dataã¨ã—ã€ROUGE1,2ã§è©•ä¾¡ã€‚ è©•ä¾¡ã®çµæœã€CLASSY04(DUC04ã®best system)ã‚„LexRankç­‰ã®ã‚ˆãä½¿ã‚ã‚Œã‚‹ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’outperformã€‚ ãŸã ã€regression basedãªRegSumã«ã¯ã‚¹ã‚³ã‚¢ã§å‹ã¦ãªã„ã¨ã„ã†çµæœã«ã€‚ RegSumã¯wordãƒ¬ãƒ™ãƒ«ã§salienceã‚¹ã‚³ã‚¢ã‚’regressionã™ã‚‹æ‰‹æ³•ã§ã€ãƒªãƒƒãƒãªæƒ…å ±ã‚’çµæ§‹ä½¿ã£ã¦ã„ã‚‹ã®ã§ã€ã“ã‚Œã‚‰ã‚’ææ¡ˆæ‰‹æ³•ã«çµ„ã¿åˆã‚ã›ã‚‹ã®ã¯æœ‰æœ›ãªæ–¹å‘æ€§ã ã¨è­°è«–ã—ã¦ã„ã‚‹ã€‚<br><br><br><br>[Cao+, 2015] Ranking with recursive neural networks and its application to multi-document summarization, Cao+, AAAI'15 [Cao+, 2017] Improving multi-document summarization via text classification, Cao+, AAAI'17<br><br><br><br>[æ‰€æ„Ÿ] <br><br>ãƒ»ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãªãƒ¢ãƒ‡ãƒ«ã¯è¡¨ç¾åŠ›ã¯é«˜ãã†ã ã‘ã©ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒDUC01ã¨02ã ã‘ã ã¨ã€ãƒ‡ãƒ¼ã‚¿ãŒè¶³ã‚Šãªãã¦æŒã¡å‰ã®è¡¨ç¾åŠ›ãŒæ´»ã‹ã›ã¦ã„ãªã„ã®ã§ã¯ãªã„ã‹ã¨ã„ã†æ°—ãŒã™ã‚‹ã€‚ <br><br>ãƒ»å†—é•·æ€§ã®æ’é™¤ã‚’ã‚¢ãƒ‰ãƒ›ãƒƒã‚¯ã«ã‚„ã£ã¦ã„ã‚‹ã®ã§ã€ãƒ¢ãƒ‡ãƒ«ã«ã†ã¾ãçµ„ã¿è¾¼ã‚ãªã„ã‹ãªã¨ã„ã†å°è±¡ï¼ˆdistractionæ©Ÿæ§‹ã¨ã‹ä½¿ãˆã°ã„ã„ã®ã‹ã‚‚ã—ã‚Œã‚“ï¼‰ <br><br>ãƒ»ROUGEã§ã—ã‹è©•ä¾¡ã—ã¦ãªã„ã‘ã©ã€å®Ÿéš›ã®outputã¯ã©ã‚“ãªæ„Ÿã˜ãªã®ã‹ã¡ã‚‡ã£ã¨è¦‹ã¦ã¿ãŸã„ã€‚ï¼ˆãƒã‚¤ãƒ¬ãƒ™ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ ã ã¨ROUGEã‚¹ã‚³ã‚¢ä¸ŠãŒã£ã¦ã‚‚äººæ‰‹è©•ä¾¡ã¨ã®ç›¸é–¢ãŒãªã„ã£ã¦ã„ã†ç ”ç©¶æˆæœã‚‚ã‚ã‚‹ã—ã€‚ï¼‰<br><br> ãƒ»GCNã€ã‚ã¾ã‚ŠçŸ¥ã‚‰ãªã‹ã£ãŸã‹ã‘ã©æ•°å¼è¿½ã£ãŸã‚‰ãªã‚“ã¨ãªãåˆ†ã‹ã£ãŸã¨æ€ã‚ã‚Œã‚‹ã€‚ï¼ˆå…ƒè«–æ–‡èª­ã‚ã¨ã„ã†è©±ã ãŒï¼‰</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/127" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Recent Advances in Document Summarization, Yao+, Knowledge and Information Systems'17</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/91" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Toward Controlled Generation of Text, Hu+, ICML'17</a>
<span class="snippet"><span>Comment</span><p>Text Generationã‚’è¡Œã†éš›ã¯ã€ç¾åœ¨ã¯åŸºæœ¬çš„ã«å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®å°¤åº¦ã«å¾“ã£ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã®ã¿ã§ã€outputã•ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’controlã™ã‚‹ã“ã¨ãŒã§ããªã„ã®ã§ã€ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸã¨ã„ã†è«–æ–‡ã€‚ VAEã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«GANã‚’çµ„ã¿åˆã‚ã›ãŸã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã€‚ decodingã™ã‚‹å…ƒã¨ãªã‚‹featureã®ã‚ã‚‹æ¬¡å…ƒãŒã€ãŸã¨ãˆã°polarityãªã©ã«å¯¾å¿œã—ã¦ãŠã‚Šã€ãã®æ¬¡å…ƒã®æ•°å€¤ã‚’ã„ã˜ã‚‹ã ã‘ã§ç”Ÿæˆã•ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’controlã§ãã‚‹ã€‚ <br><br><br><br>ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€ç”Ÿæˆã•ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã™ã‚‹ãŸã‚ã®ç ”ç©¶ã€‚ ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã¯ã€åŸºæœ¬çš„ã«ã¯Variational Auto Encoder(VAE)ã‚’ç”¨ã„ã‚‹ã€‚<br><br><br><br>VAEã¯ã€å…¥åŠ›ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹Encoderã¨ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸæ½œåœ¨å¤‰æ•°zã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹Generatorã®2ã¤ã®æ©Ÿæ§‹ã«ã‚ˆã£ã¦æ§‹æˆã•ã‚Œã¦ã„ã‚‹ã€‚<br><br><br><br>ã“ã®ç ”ç©¶ã§ã¯ã€ç”Ÿæˆã•ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã™ã‚‹ãŸã‚ã«ã€VAEã®æ½œåœ¨å¤‰æ•°zã«ã€ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®attributeã‚’è¡¨ã™å¤‰æ•°cã‚’æ–°ãŸã«å°å…¥ã€‚<br><br><br><br>ãŸã¨ãˆã°ã€ä¸€ä¾‹ã¨ã—ã¦ã€å¤‰æ•°cã‚’sentimentã«å¯¾å¿œã•ã›ãŸå ´åˆã€å¤‰æ•°cã®å€¤ã‚’å¤‰æ›´ã™ã‚‹ã¨ã€ç”Ÿæˆã•ã‚Œã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®sentimentãŒå¤‰åŒ–ã™ã‚‹ã‚ˆã†ãªç”ŸæˆãŒå®Ÿç¾å¯èƒ½ã€‚<br><br><br><br>æ¬¡ã«ã€ã“ã®ã‚ˆã†ãªç”Ÿæˆã‚’å®Ÿç¾ã§ãã‚‹ã‚ˆã†ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã—ãŸã„ãŒã€å­¦ç¿’ã‚’è¡Œã†éš›ã®ãƒã‚¤ãƒ³ãƒˆã¯ã€ä»¥ä¸‹ã®äºŒã¤ã€‚<br><br><br><br>cã§æŒ‡å®šã•ã‚ŒãŸattributeãŒåæ˜ ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«å­¦ç¿’<br><br><br><br>æ½œåœ¨å¤‰æ•°zã¨attributeã«é–¢ã™ã‚‹å¤‰æ•°cã®ç‹¬ç«‹æ€§ã‚’ä¿ã¤ã‚ˆã†ã«å­¦ç¿’ ï¼ˆcã«ã¯åˆ¶å¾¡ã—ãŸã„attributeã«é–¢ã™ã‚‹æƒ…å ±ã®ã¿ãŒæ ¼ç´ã•ã‚Œã€ãã®ä»–ã®æƒ…å ±ã¯æ½œåœ¨å¤‰æ•°zã«æ ¼ç´ã•ã‚Œã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹)<br><br><br><br>1ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€æ–°ãŸã«discriminatorã¨å‘¼ã°ã‚Œã‚‹è­˜åˆ¥å™¨ã‚’ç”¨æ„ã—ã€VAEãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã®attributeã‚’discriminatorã§åˆ†é¡ã—ã€ãã®çµæœã‚’VAEã®Generatorã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã™ã‚‹ã“ã¨ã§ã€attributeãŒåæ˜ ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å­¦ç¿’ã‚’è¡Œã†ã€‚ ï¼ˆã“ã‚Œã«ã¯ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã ãŒã€å°‘é‡ã§ã‚‚å­¦ç¿’ã§ãã‚‹ã“ã¨ã«åŠ ãˆã¦ã€sentence levelã®ãƒ‡ãƒ¼ã‚¿ã ã‘ã§ã¯ãªãword levelã®ãƒ‡ãƒ¼ã‚¿ã§ã‚‚å­¦ç¿’ã§ãã‚‹ã€‚ï¼‰<br><br><br><br>ã¾ãŸã€2ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€VAEãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€ç”Ÿæˆã™ã‚‹å…ƒã¨ãªã£ãŸæ½œåœ¨å¤‰æ•°zãŒå†ç¾ã§ãã‚‹ã‚ˆã†ã«Encoderã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã€‚<br><br><br><br>å®Ÿé¨“ã§ã¯ã€sentimentã¨tenseã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã™ã‚‹å®Ÿé¨“ãŒè¡Œã‚ã‚Œã¦ãŠã‚Šã€attributeã‚’è¡¨ã™å¤‰æ•°cã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ†ã‚­ã‚¹ãƒˆãŒç”Ÿæˆã•ã‚Œã¦ãŠã‚Šèˆˆå‘³æ·±ã„ã€‚<br><br><br><br>[sentimentã‚’åˆ¶å¾¡ã—ãŸä¾‹]<br><br><br><br>this movie was awful and boring. (negative)<br><br>this movie was funny and touching. (positive)<br><br>[tenseã‚’åˆ¶å¾¡ã—ãŸä¾‹]<br><br><br><br>this was one of the outstanding thrillers of the last decade<br><br>this is one of the outstanding thrillers of the all time<br><br>this will be one of the great thrillers of the all time</p>
<p>VAEã¯é€šå¸¸ã®AutoEncoderã¨æ¯”è¼ƒã—ã¦ã€å¥¥ãŒæ·±ãã¦å‹‰å¼·ã—ã¦ã¿ã¦ãŠã‚‚ã—ã‚ã‹ã£ãŸã€‚ Reparametrization Trickãªã©ã¯çŸ¥ã‚‰ãªã‹ã£ãŸã€‚</p>
<p>ç®¡ç†äººã«ã‚ˆã‚‹è§£èª¬è³‡æ–™:<br>[Controllable Text Generation.pdf](https://github.com/AkihikoWatanabe/paper_notes/files/1595121/Controllable.Text.Generation.pdf)<br><br></p>
<p>slideshare: 


<a href="https://www.slideshare.net/akihikowatanabe3110/towards-controlled-generation-of-text" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/towards-controlled-generation-of-text</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/90" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Multi-Task Video Captioning with Video and Entailment Generation, Pasunuru+, ACL'17</a>
<span class="snippet"><span>Comment</span><p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š


<a href="https://www.slideshare.net/HangyoMasatsugu/hangyo-acl-paperreading2017multitask-video-captioning-with-video-and-entailment-generation/1" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/HangyoMasatsugu/hangyo-acl-paperreading2017multitask-video-captioning-with-video-and-entailment-generation/1</a>


</p>
<p>multitask learningã§å‹•ç”»ï¼ˆã‹ãªã‚ŠçŸ­ã‚ï¼‰ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆã‚’è¡Œãªã£ãŸè©±<br><br>(2025.05.12)<br>ä¸Šè¨˜è§£èª¬è³‡æ–™ä¸­ã®ã‚¹ã‚¯ã‚·ãƒ§ãŒã„ãã¤ã‹æ²è¼‰ã•ã‚Œã¦ã„ã¾ã—ãŸãŒå‰Šé™¤ã—ã¾ã—ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/87" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Neural Text Generation: A Practical Guide, Ziang Xie, arXiv'17</a>
<span class="snippet"><span>GPT Summary</span>- æ·±å±¤å­¦ç¿’æ‰‹æ³•ã¯ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¿ã‚¹ã‚¯ã§æˆåŠŸã‚’åã‚ã¦ã„ã‚‹ãŒã€ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ãŒæœ›ã¾ã—ããªã„å‡ºåŠ›ã‚’ç”Ÿæˆã™ã‚‹å•é¡ŒãŒã‚ã‚‹ã€‚æœ¬è«–æ–‡ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®ä¸å…·åˆã‚’è§£æ±ºã™ã‚‹ãŸã‚ã®å®Ÿè·µçš„ãªã‚¬ã‚¤ãƒ‰ã‚’æä¾›ã—ã€å®Ÿä¸–ç•Œã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿç¾ã‚’ç›®æŒ‡ã™ã€‚</span>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/84" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Survey of the State of the Art in Natural Language Generation: Core  tasks, applications and evaluation, Albert Gatt+, arXiv'17</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã¯ã€éè¨€èªçš„å…¥åŠ›ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚„éŸ³å£°ã‚’ç”Ÿæˆã™ã‚‹è‡ªç„¶è¨€èªç”Ÿæˆï¼ˆNLGï¼‰ã®æœ€æ–°æŠ€è¡“å‹•å‘ã‚’èª¿æŸ»ã—ã€(a) NLGã®ã‚³ã‚¢ã‚¿ã‚¹ã‚¯ã«é–¢ã™ã‚‹ç ”ç©¶ã®çµ±åˆã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æç¤ºã€(b) NLGã¨ä»–ã®AIåˆ†é‡ã¨ã®ç›¸ä¹—åŠ¹æœã«ã‚ˆã‚‹æ–°ã—ã„ç ”ç©¶ãƒˆãƒ”ãƒƒã‚¯ã®å¼·èª¿ã€(c) NLGè©•ä¾¡ã®èª²é¡Œã¨ä»–ã®è‡ªç„¶è¨€èªå‡¦ç†åˆ†é‡ã¨ã®é–¢é€£ã‚’æ¢ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‰²ã¨æ–°ã—ç›®ã®NLGã®Survey</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Unsupervised.html" target="_blank" rel="noopener noreferrer">#Unsupervised</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/83" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unsupervised Pretraining for Sequence to Sequence Learning, Ramachandran+, EMNLP'17</a>
<span class="snippet"><span>Comment</span><p>seq2seqã«ãŠã„ã¦weightã®pretrainingã‚’è¡Œã†æ‰‹æ³•ã‚’ææ¡ˆ<br><br>seq2seqã§ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã„ã¨overfittingã—ã‚„ã™ã„ã¨ã„ã†å¼±ç‚¹ãŒã‚ã‚‹ã®ã§ã€å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã§unsupervisedã«pretrainingã—ã€ãã®å¾Œç›®çš„ã®ãƒ‡ãƒ¼ã‚¿ã§finetuneã™ã‚‹ã“ã¨ã§ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã¾ã—ã‚‡ã†ã€ã¨ã„ã†ãŠè©±ã€‚<br><br>WMTã®ç¿»è¨³ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€1.3ãƒã‚¤ãƒ³ãƒˆ BLEUã‚¹ã‚³ã‚¢ãŒæ”¹å–„ã€abstractive summarizationã§ã‚‚å®Ÿé¨“ã—ãŸãŒã€ç²¾åº¦ã¯å‘ä¸Šã›ãšã€‚ã—ã‹ã—ãªãŒã‚‰è¦ç´„ã§ã¯pretrainingã«ã‚ˆã£ã¦repetitionãŒæ¸›å°‘ã—ãŸã¨ä¸»å¼µã€‚<br><br><br><br>encoder, decoderãã‚Œãã‚Œã‚’åˆ‡ã‚Šé›¢ã—ã¦è€ƒãˆã‚‹ã¨ã€ãã‚Œãã‚Œè¨€èªãƒ¢ãƒ‡ãƒ«ã¨ã¿ãªã™ã“ã¨ãŒã§ãã‚‹ãŸã‚(encoderã«ã¯output-layerã‚’è¿½åŠ )ã€ãã‚Œãã‚Œã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç‹¬ç«‹ã«å¤§è¦æ¨¡ãªãƒ©ãƒ™ãƒ«ãªã—ãƒ‡ãƒ¼ã‚¿ã§pretrainingã™ã‚‹ã€‚<br><br>fine-tuneã™ã‚‹éš›ã¯ã€targetãƒ‡ãƒ¼ã‚¿ã ã‘ã§ãªãã€pretrainingã™ã‚‹éš›ã®ãƒ‡ãƒ¼ã‚¿ã‚‚åŒæ™‚ã«å­¦ç¿’ã‚’ç¶šã‘ã‚‹ï¼ˆLM Objectiveï¼‰<br><br>LM Objectiveã¯ã€targetå´ã®objective functionã«pretrainingå´ã®objective functionã®é …ã‚’é‡ã¿ä»˜ãã§è¿½åŠ ã—ãŸã‚‚ã®ã€‚<br><br><br><br>Abltion studyã«ã‚ˆã‚‹ã¨ã€MTã«ãŠã„ã¦ã¯softmax-layerã‚’pretrainingã™ã‚‹ã“ã¨ãŒé‡è¦ã€‚softmax-layerã®pretrainingã‚’ablationã™ã‚‹ã¨BLEUã‚¹ã‚³ã‚¢ãŒ1.6ãƒã‚¤ãƒ³ãƒˆæ¸›å°‘ã€‚<br><br>LM objectiveã‚’ãªãã™ã¨ã€pretrainingã®åŠ¹æœãŒã»ã¨ã‚“ã©ãªããªã‚‹(BLEUã‚¹ã‚³ã‚¢-2.0ãƒã‚¤ãƒ³ãƒˆ)ã€‚<br><br>sumarizationã«ãŠã„ã¦ã¯ã€embeddingã®pretrainingãŒå¤§å¹…ãªROUGEã‚¹ã‚³ã‚¢ã®æ”¹å–„ã‚’è¦‹ã›ãŸã€‚ã¾ãŸã€MTã¨ç•°ãªã‚Šã€encoderå´ã®pretrainingãŒã‚¹ã‚³ã‚¢å‘ä¸Šã«å¯„ä¸ã€‚<br><br><br><br>LM Objectiveã¯çµæ§‹ä½¿ãˆãã†ãªå°è±¡</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/82" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning to skim text, Yu+, ACL'17</a>
<span class="snippet"><span>Comment</span><p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š


<a href="http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/07.pdf" target="_blank" rel="noopener noreferrer">http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/07.pdf</a>


</p>
<p>RNNã«ãŠã„ã¦é‡è¦ãªéƒ¨åˆ†ä»¥å¤–ã¯èª­ã¿é£›ã°ã™ã“ã¨ã§åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ç ”ç©¶ã€‚ã„ãã¤èª­ã¿é£›ã°ã™ã‹ã‚‚æ½œåœ¨å¤‰æ•°ã¨ã—ã¦ä¸€ç·’ã«å­¦ç¿’ã™ã‚‹ã€‚æ½œåœ¨å¤‰æ•°ï¼ˆé›¢æ•£å¤‰æ•°ï¼‰ãªã®ã§ã€æ™®é€šã«å°¤åº¦æœ€å¤§åŒ–ã™ã‚‹ã‚„ã‚Šæ–¹ã§ã¯å­¦ç¿’ã§ããšã€ãŠã¾ã‘ã«é›¢æ•£å¤‰æ•°ãªã®ã§ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ä½¿ãˆãªã„ã®ã§ã€å¼·åŒ–å­¦ç¿’ã§å­¦ç¿’ã™ã‚‹ã€‚<br><br><br><br>Vanilla LSTMã¨æ¯”è¼ƒã—ã€è‰²ã€…ãªã‚¿ã‚¹ã‚¯ã§å®Ÿé¨“ã—ãŸçµæœã€æ€§èƒ½ã‚‚ï¼ˆå°‘ã—ï¼‰ä¸ŠãŒã‚‹ã—ã€ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚‚ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Word.html" target="_blank" rel="noopener noreferrer">#Word</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/79" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Skip-Gram â€“ Zipf + Uniform = Vector Additivity, Gittens+, ACL'17</a>
<span class="snippet"><span>Comment</span><p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š


<a href="http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/09.pdf" target="_blank" rel="noopener noreferrer">http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/09.pdf</a>


</p>
<p>Embeddingã®åŠ æ³•æ§‹æˆæ€§ï¼ˆe.g. man+royal=kingï¼‰ã‚’ç†è«–çš„ã«ç†ç”±ã¥ã‘<br><br>ï¼ˆè§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ã‚ˆã‚Šï¼‰</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Word.html" target="_blank" rel="noopener noreferrer">#Word</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2017-12-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/78" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Poincar'e Embeddings for Learning Hierarchical Representations, Nickel+, NIPS'17</a>
<span class="snippet"><span>Comment</span><p>è§£èª¬: 


<a href="http://tech-blog.abeja.asia/entry/poincare-embeddings" target="_blank" rel="noopener noreferrer">http://tech-blog.abeja.asia/entry/poincare-embeddings</a>


<br><br>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š


<a href="https://speakerdeck.com/eumesy/poincare-embeddings-for-learning-hierarchical-representations" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/eumesy/poincare-embeddings-for-learning-hierarchical-representations</a>


<br><br>å®Ÿè£…ï¼š


<a href="https://github.com/TatsuyaShirakawa/poincare-embedding" target="_blank" rel="noopener noreferrer">https://github.com/TatsuyaShirakawa/poincare-embedding</a>


<br><br></p>
<p>ãƒ»éšå±¤æ§‹é€ ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ï¼ˆWordNetä¸Šã®ä¸Šä½èªä¸‹ä½èªã€is-aé–¢ä¿‚ãªã©ï¼‰ã‚’åŸ‹ã‚è¾¼ã‚€ãŸã‚ã«ã€åŒæ›²ç©ºé–“ã‚’ä½¿ã£ãŸè©±ï¼ˆé€šå¸¸ã¯ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰ç©ºé–“ï¼‰ã€‚<br><br>ãƒ»éšå±¤æ§‹é€ ãƒ»ã¹ãåˆ†å¸ƒã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã¯ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰ç©ºé–“ã§ã¯ãªãåŒæ›²ç©ºé–“ã®æ–¹ãŒåŠ¹ç‡çš„ã«åŸ‹ã‚è¾¼ã‚ã‚‹ã€‚<br><br>ãƒ»éšå±¤æ§‹é€ ãƒ»ã¹ãåˆ†å¸ƒã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã‚’åŒæ›²ç©ºé–“ï¼ˆãƒã‚¢ãƒ³ã‚«ãƒ¬çƒãƒ¢ãƒ‡ãƒ«ï¼‰ã«åŸ‹ã‚è¾¼ã‚€ãŸã‚ã®å­¦ç¿’æ‰‹æ³•ï¼ˆãƒªãƒ¼ãƒãƒ³å¤šæ§˜ä½“ä¸Šã§SGDï¼‰ã‚’ææ¡ˆ<br><br>ãƒ»WordNet hypernymyã®åŸ‹ã‚è¾¼ã¿ï¼šä½æ¬¡å…ƒã§ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰åŸ‹ã‚è¾¼ã¿ã«åœ§å‹<br><br>ãƒ»Social Networkã®åŸ‹ã‚è¾¼ã¿ï¼šä½æ¬¡å…ƒã ã¨åœ§å‹<br><br>ãƒ»Lexical Entailmentï¼š2ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§SoTA<br><br>ï¼ˆè§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ã‚ˆã‚Šï¼‰</p>
<p><img src="https://user-images.githubusercontent.com/12249301/34452953-0e124ad6-ed8d-11e7-800d-0c2712df116a.png" alt="image" loading="lazy"><br><br><br><br>ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¸Šä½ãƒ»ä¸‹ä½æ¦‚å¿µã‚’ä¸ãˆã¦ã„ãªã„ã®ã«ã€åŸç‚¹ä»˜è¿‘ã«ã¯ä¸Šä½èªãƒ»å††å‘¨ä»˜è¿‘ã«ã¯ä¸‹ä½èªãŒè‡ªç„¶ã«åŸ‹ã‚è¾¼ã¾ã‚Œã¦ã„ã‚‹ï¼ˆæ„å›³ã—ãŸé€šã‚Šã«ãªã£ã¦ã„ã‚‹ï¼‰ã€‚<br><br>ãƒã‚¢ãƒ³ã‚«ãƒ¬å††æ¿ã§ã¯ã€åŸç‚¹ã‹ã‚‰ã®è·é›¢ã«å¿œã˜ã¦æŒ‡æ•°çš„ã«å††å‘¨é•·ãŒå¢—åŠ ã—ã¦ã„ãã®ã§ã€æŒ‡æ•°çš„ã«æ•°ãŒå¢—ãˆã¦ã„ãä¸‹ä½èªãªã©ã¯å¤–å´ã«é…ç½®ã•ã‚Œã‚‹ã¨åŠ¹ç‡çš„ã ã‘ã©ã€ãã®é€šã‚Šã«ãªã£ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34452994-7c17a738-ed8d-11e7-8a56-13929c55c07e.png" alt="image" loading="lazy"><br><br><br><br><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/71" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Supervised Learning of Universal Sentence Representations from Natural Language Inference Data, Conneau+, EMNLP'17</a>
<span class="snippet"><span>Comment</span><p>slide: 


<a href="https://www.slideshare.net/naoakiokazaki/supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/naoakiokazaki/supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data</a>


</p>
<p>æ±ç”¨çš„ãªæ–‡ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãŒã§ãã¾ã—ãŸï¼ã¨ã„ã†è©±ã€‚<br><br><br><br>SNLIãƒ‡ãƒ¼ã‚¿ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å­¦ç¿’ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€æ§‹æˆã‚¹ãƒ©ã‚¤ãƒ‰å›³ä¸­å³å´ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€éƒ¨åˆ†ã‚’ãªã‚‹ã¹ãä¸€èˆ¬çš„ãªæ–‡ã«é©ç”¨ã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã—ãŸã„ã€‚<br><br><br><br>è‰²ã€…ãªã‚¿ã‚¹ã‚¯ã§ã€æ–‡ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€æ§‹æˆã‚’æ¯”è¼ƒã—ãŸçµæœã€bi-directional LSTMã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€è¦ç´ ã”ã¨ã®æœ€å¤§å€¤ã‚’ã¨ã‚‹æ‰‹æ³•ãŒæœ€ã‚‚è‰¯ã„ã¨ã„ã†çµæœã€‚<br><br>éš ã‚Œå±¤ã®æ¬¡å…ƒã¯4096ã¨ã‹ãã®ãã‚‰ã„ã€‚<br><br>Skip-Thoughtã¯å­¦ç¿’ã«1ãƒ¶æœˆãã‚‰ã„ã‹ã‹ã‚‹ã‘ã©ã€ææ¡ˆæ‰‹æ³•ã¯ã‚ˆã‚Šå°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§1æ—¥ãã‚‰ã„ã§å­¦ç¿’çµ‚ã‚ã‚Šã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã§ç²¾åº¦ãŒè‰¯ã„ã€‚<br><br><br><br>ãƒ™ã‚¯ãƒˆãƒ«ã®è¦ç´ ç©ã€concat,  subãªã©ã€æ§˜ã€…ãªæ¼”ç®—ã‚’æ–½ã—ã€å­¦ç¿’ã—ã¦ã„ã‚‹ã®ã§ã€ãã®ã‚ˆã†ãªæ§‹æˆã®å…ƒã‹ã‚‰æ–‡ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’å­¦ç¿’ã™ã‚‹ã¨ä½•ã‹æ„å‘³çš„ãªã‚‚ã®ãŒã¨ã‚Œã¦ã„ã‚‹ï¼Ÿ<br><br>SNLIã¯Natural Language Inferenceã«ã¯æ–‡ã®æ„å‘³ç†è§£ãŒå¿…é ˆãªã®ã§ã€ãã®ãƒ‡ãƒ¼ã‚¿ä½¿ã£ã¦å­¦ç¿’ã™ã‚‹ã¨ã„ã„æ„Ÿã˜ã«æ–‡ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãŒã§ãã¾ã™ã€‚<br><br><br><br>NLIã®ãƒ‡ãƒ¼ã‚¿ã¯è‰²ã€…ãªã¨ã“ã‚ã§æœ‰ç”¨ãªã®ã§ã€æ—¥æœ¬èªã®NLIã®ãƒ‡ãƒ¼ã‚¿ã¨ã‹ã‚‚æ¬²ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/69" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A structured self-attentive sentence embedding, Li+ ï¼ˆBengio groupï¼‰, ICLR'17</a>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=BJC_jUqxe" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=BJC_jUqxe</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/67" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] What do Neural Machine Translation Models Learn about Morphology?, Yonatan Belinkov+, ACL'17</a>
<span class="snippet"><span>Comment</span><p>


<a href="http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/06.pdf" target="_blank" rel="noopener noreferrer">http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/06.pdf</a>


<br><br>(2025.05.12è¿½è¨˜)<br>ä¸Šè¨˜ã¯2017å¹´ã«ã™ãšã‹ã‘å°ã§é–‹å‚¬ã•ã‚ŒãŸACL 2017èª­ã¿ä¼šã§ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ã§ã™ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/66" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Sequence-to-Dependency Neural Machine Translation, Wu+, ACL'17</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/64" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Neural Machine Translation with Source-Side Latent Graph Parsing, Kazuma Hashimoto+, EMNLP'17</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/InteractivePersonalizedSummarization.html" target="_blank" rel="noopener noreferrer">#InteractivePersonalizedSummarization</a>
<a class="button" href="articles/IntegerLinearProgramming%20(ILP).html" target="_blank" rel="noopener noreferrer">#IntegerLinearProgramming (ILP)</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/7" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Joint Optimization of User-desired Content in Multi-document Summaries by Learning from User Feedback, P.V.S+, ACL'17, 2017.08</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ´»ç”¨ã—ãŸæŠ½å‡ºçš„ãƒãƒ«ãƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¦ç´„ã‚·ã‚¹ãƒ†ãƒ ã‚’ææ¡ˆã€‚ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å–å¾—ã—ã€ILPãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ã¦è¦ç´„ã®è³ªã‚’å‘ä¸Šã€‚æœ€å°é™ã®åå¾©ã§é«˜å“è³ªãªè¦ç´„ã‚’ç”Ÿæˆã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“ã§åŠ¹æœã‚’åˆ†æã€‚</span>
<span class="snippet"><span>Comment</span><p># ä¸€è¨€ã§è¨€ã†ã¨<br><br>ãƒ¦ãƒ¼ã‚¶ã¨ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã—ãªãŒã‚‰é‡è¦ãªã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’æ±ºã‚ã€ãã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆãŒå«ã¾ã‚Œã‚‹ã‚ˆã†ã«ILPãªæ‰‹æ³•ã§è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹PDSæ‰‹æ³•ã€‚Interactive Personalized Summarizationã¨ä¼¼ã¦ã„ã‚‹ï¼ˆä¼¼ã¦ã„ã‚‹ãŒå¼•ç”¨ã—ã¦ã„ãªã„ã€å¼•ç”¨ã—ãŸæ–¹ãŒã‚ˆã„ã®ã§ã¯ï¼‰ã€‚<br><br><br><br># æ‰‹æ³•<br><br>è¦ç´„ãƒ¢ãƒ‡ãƒ«ã¯æ—¢å­˜ã®MDSæ‰‹æ³•ã‚’æ¡ç”¨ã€‚Concept-based ILP Summarization<br><br><br><br>ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã‚‚ã‚‰ã†éš›ã¯ã€è¦ç´„ã‚’ç”Ÿæˆã—ã€ãã‚Œã‚’ãƒ¦ãƒ¼ã‚¶ã«æç¤ºã€‚æç¤ºã—ãŸè¦ç´„ã‹ã‚‰é‡è¦ãªã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’ãƒ¦ãƒ¼ã‚¶ã«é¸æŠã—ã¦ã‚‚ã‚‰ã†å½¢å¼ï¼ˆãƒ¦ãƒ¼ã‚¶ãŒé‡è¦ã¨åˆ¤æ–­ã—ãŸã‚³ãƒ³ã‚»ãƒ—ãƒˆã«ã¯å®šæ•°é‡ã¿ãŒä¸ãˆã‚‰ã‚Œã‚‹ï¼‰ã€‚<br><br>ãƒ¦ãƒ¼ã‚¶ã«å¯¾ã—ã¦ã€Ï„å›ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã‚‚ã‚‰ã†ã¾ã§ã¯ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã‚‚ã‚‰ã£ã¦ã„ãªã„ã‚³ãƒ³ã‚»ãƒ—ãƒˆã®é‡è¦åº¦ãŒé«˜ããªã‚‹ã‚ˆã†ã«ã—ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã‚‚ã‚‰ã£ãŸã‚³ãƒ³ã‚»ãƒ—ãƒˆã®é‡è¦åº¦ãŒä½ããªã‚‹ã‚ˆã†ã«ç›®çš„é–¢æ•°ã‚’èª¿æ•´ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã¾ã ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å—ã‘ã¦ã„ãªã„ã‚³ãƒ³ã‚»ãƒ—ãƒˆãŒå¤šãå«ã¾ã‚Œã‚‹è¦ç´„ãŒç”Ÿæˆã•ã‚Œã‚‹ãŸã‚ã€ã“ã‚Œã‚’ãƒ¦ãƒ¼ã‚¶ã«æç¤ºã™ã‚‹ã“ã¨ã§ãƒ¦ãƒ¼ã‚¶ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å¾—ã‚‹ã€‚Ï„å›ã‚’è¶…ãˆãŸã‚‰ã€ãƒ¦ãƒ¼ã‚¶ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‹ã‚‰æ±ºã¾ã£ãŸweightãŒæœ€å¤§ã¨ãªã‚‹ã‚ˆã†ã«ç›®çš„é–¢æ•°ã‚’ä¿®æ­£ã™ã‚‹ã€‚<br><br><br><br>ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã‚³ãƒ³ã‚»ãƒ—ãƒˆã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å—ã‘ã‚‹éš›ã¯ã€åŠ¹ç‡çš„ã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å—ã‘ã‚‰ã‚Œã‚‹ã¨è‰¯ã„ï¼ˆæœ€å°ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã§ï¼‰ã€‚ãã“ã§ã€Active Learningã‚’å°å…¥ã™ã‚‹ã€‚ã‚³ãƒ³ã‚»ãƒ—ãƒˆã®é‡è¦åº¦ã®ä¸ç¢ºå®Ÿæ€§ã‚’SVMã§åˆ¤å®šã—ã€ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’å„ªå…ˆçš„ã«å«ã‚€ã‚ˆã†ã«ç›®çš„é–¢æ•°ã‚’ä¿®æ­£ã™ã‚‹æ‰‹æ³•ï¼ˆALï¼‰ã€SVMã§é‡è¦åº¦ãŒé«˜ã„ã¨æ¨å®šã•ã‚ŒãŸã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’å„ªå…ˆçš„ã«è¦ç´„ã«å«ã‚€ã‚ˆã†ã«ç›®çš„é–¢æ•°ã‚’ä¿®æ­£ã™ã‚‹æ‰‹æ³•ï¼ˆAL+ï¼‰ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br><br><br># è©•ä¾¡<br><br>oracle-based approachã¨ã„ã†ã‚‚ã®ã‚’ä½¿ã£ã¦ã„ã‚‹ã€‚è¦ã¯ã€è¦ç´„ã‚’ã‚·ã‚¹ãƒ†ãƒ ãŒæç¤ºã—ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã¨è¢«ã£ã¦ã„ã‚‹ã‚³ãƒ³ã‚»ãƒ—ãƒˆã¯ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰é‡è¦ã ã¨ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒã‚ã£ãŸã‚³ãƒ³ã‚»ãƒ—ãƒˆã ã¨ã¿ãªã™ã¨ã„ã†ã‚‚ã®ã€‚<br><br>è©•ä¾¡çµæœã‚’è¦‹ã‚‹ã¨ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®MDSã¨æ¯”ã¹ã¦upper boundè¿‘ãã¾ã§ROUGEã‚¹ã‚³ã‚¢ãŒä¸ŠãŒã£ã¦ã„ã‚‹ã€‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã‚‚ã‚‰ã†ãŸã‚ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯æœ€å¤§ã§ï¼‘ï¼å›ã«çµã£ã¦ã„ã‚‹æ¨¡æ§˜ï¼ˆã“ã‚Œä»¥ä¸Šãƒ¦ãƒ¼ã‚¶ã¨ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã™ã‚‹ã®ã¯éç¾å®Ÿçš„ï¼‰ã€‚<br><br><br><br>å®Ÿéš›ã«ãƒ¦ãƒ¼ã‚¶ãŒã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æ²¿ã£ãŸè©•ä¾¡ã«ãªã£ã¦ã„ãªã„ã¨æ€ã†ã€‚<br><br>ã“ã®è©•ä¾¡ã§ç¤ºã›ã¦ã„ã‚‹ã®ã¯ã€ReferenceSummaryä¸­ã«å«ã¾ã‚Œã‚‹å˜èªã«ãƒã‚¤ã‚¢ã‚¹ã‚’ã‹ã‘ã¦è¦ç´„ã‚’ç”Ÿæˆã—ã¦ã„ãã¨ã€ReferenceSummaryã¨åŒæ§˜ãªè¦ç´„ãŒæœ€çµ‚çš„ã«ä½œã‚Œã¾ã™ã€ã¨ã„ã†ã“ã¨ã¨ã€ã“ã®ã¨ãPool-basedãªActiveLearningã‚’ä½¿ã†ã¨ã€ã‚ˆã‚Šå°‘ãªã„ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã§ã“ã‚ŒãŒå®Ÿç¾ã§ãã¾ã™ã¨ã„ã†ã“ã¨ã€‚<br><br>ã“ã‚Œã‚’ç¤ºã™ã®ã¯åˆ¥ã«è‰¯ã„ã¨æ€ã†ã®ã ãŒã€feedbackã‚’ReferenceSummaryã‹ã‚‰ä¸ãˆã‚‹ã®ã¯å°‘ã—ç¾å®Ÿã‹ã‚‰é›¢ã‚Œã™ãã¦ã„ã‚‹æ°—ãŒã€‚ãŸã¨ãˆã°ãƒ¦ãƒ¼ã‚¶ãŒæ–°ã—ã„ã“ã¨ã‚’å­¦ã¶ã¨ãã¯ã€ã‚ã‚‹æ™‚ã¯ä¸€ã¤ã®ã“ã¨ã‚’æ·±å €ã—ã€ãã“ã‹ã‚‰ã•ã‚‰ã«æµ…ã„ã¨ã“ã‚ã«æˆ»ã£ã¦åˆ¥ã®ã¨ã“ã‚ã‚’æ·±å €ã™ã‚‹ã¿ãŸã„ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’ã™ã‚‹æ°—ãŒã™ã‚‹ãŒã€ã“ã®æ·±å €ãƒ•ã‚§ãƒ¼ã‚ºãªã©ã¯ReferenceSummaryã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‹ã‚‰ã§ã¯å†ç¾ã§ããªã„ã®ã§ã¯ã€‚<br><br><br><br># æ‰€æ„Ÿ<br><br>è©•ä¾¡ãŒç”˜ã„ã¨æ„Ÿã˜ã‚‹ã€‚ååˆ†ãªã‚µã‚¤ã‚ºã®ã‚µãƒ³ãƒ—ãƒ«ã‚’å¾—ã‚‹ã®ã¯å³ã—ã„ã‹ã‚‰orable-based approachã¨ã‚Šã¾ã—ãŸã¨æ›¸ã„ã¦ã‚ã‚‹ãŒã€ãªã‚“ã‚‰ã‹ã®äººæ‰‹è©•ä¾¡ã‚‚ã‚ã£ãŸã»ã†ãŒè‰¯ã„ã¨æ€ã†ã€‚<br><br><br><br>ãƒ¦ãƒ¼ã‚¶ã«æ•°ç™¾å˜èªã‚‚ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã‚‚ã‚‰ã†ã¨ã„ã†ã®ã¯ã‚ã¾ã‚Šç¾æ™‚çš„ã§ã¯ãªã„æ°—ãŒã€‚<br><br><br><br>oracle-based approachã§ãƒ¦ãƒ¼ã‚¶ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ã„ã‚‹ãŒã€oracleã®è¦ç´„ã¯ã€äººãŒãã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã‚¿ã®å†…å®¹ã‚’å®Œç’§ã«ç†è§£ã—ãŸä¸Šã§è¦ç´„ã—ã¦ã„ã‚‹ã‚‚ã®ãªã®ã§ã€ã“ã‚Œã‚’è©•ä¾¡ã«ä½¿ã†ã®ã‚‚å®Ÿéš›ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨é•ã†ã¨æ€ã†ã€‚å®Ÿéš›ã«ãƒ¦ãƒ¼ã‚¶ãŒã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ã†ã¨ãã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã‚¿ã®å†…å®¹ãªã‚“ã¦ãªã‚“ã‚‚çŸ¥ã‚‰ãªã„ã‚ã‘ã§ã€ãã®ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã‚‚ã‚‰ãˆã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’oracle-based approachã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã®ã¯ç„¡ç†ãŒã‚ã‚‹ã€‚ä»®ã«ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã‚¿ã®å†…å®¹ã‚’å®Œç’§ã«ç†è§£ã—ã¦ã„ã‚‹ãƒ¦ãƒ¼ã‚¶ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã¨ã„ã†ã®ãªã‚‰ã€ã‚ã‹ã‚‹ã€‚ãŒã€ãã†ã„ã†ãƒ¦ãƒ¼ã‚¶ã®ãŸã‚ã«è¦ç´„ä½œã£ã¦æç¤ºã—ãŸã„ã‚ã‘ã§ã¯ãªã„ã¯ãšã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2339" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] An overview of gradient descent optimization algorithms, Sebastian Ruder, arXiv'16</a>
<span class="snippet"><span>GPT Summary</span>- å‹¾é…é™ä¸‹æ³•ã®æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æŒ™å‹•ã‚’ç†è§£ã—ã€æ´»ç”¨ã™ã‚‹ãŸã‚ã®ç›´æ„Ÿã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ãŸè¨˜äº‹ã€‚ã•ã¾ã–ã¾ãªãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚„èª²é¡Œã‚’è¦ç´„ã—ã€ä¸€èˆ¬çš„ãªæœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€ä¸¦åˆ—ãƒ»åˆ†æ•£è¨­å®šã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€è¿½åŠ æˆ¦ç•¥ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/goyal__pramod/status/1951192112269054113?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span></number></entity></strong></p>
<p>å‹‰å¼·ç”¨ã«ãƒ¡ãƒ¢</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1647" target="_blank" rel="noopener noreferrer" class="title-link">Controlling Output Length in Neural Encoder-Decoders, Yuta Kikuchi+, EMNLP'16</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€-ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›é•·ã‚’åˆ¶å¾¡ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚ç‰¹ã«ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã«ãŠã„ã¦ã€ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨å­¦ç¿’ã«åŸºã¥ã2ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç”¨ã„ã€å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã®æ–¹æ³•ãŒè¦ç´„ã®è³ªã‚’ä¿ã¡ãªãŒã‚‰é•·ã•ã‚’èª¿æ•´ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Encoder-Decoderãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦output lengthã‚’åˆ¶å¾¡ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ãŸæœ€åˆã®ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/ReadingComprehension.html" target="_blank" rel="noopener noreferrer">#ReadingComprehension</a>
<span class="issue_date">Issue Date: 2023-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1142" target="_blank" rel="noopener noreferrer" class="title-link">NewsQA: A Machine Comprehension Dataset, Adam Trischler+, N_A, arXiv'16</a>
<span class="snippet"><span>GPT Summary</span>- NewsQAã¨ã„ã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€10ä¸‡ä»¥ä¸Šã®äººé–“ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸè³ªå•ã¨å›ç­”ã®ãƒšã‚¢ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€CNNã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«åŸºã¥ã„ã¦ä½œæˆã•ã‚Œã¦ãŠã‚Šã€æ¢ç´¢çš„ãªæ¨è«–ã‚’å¿…è¦ã¨ã™ã‚‹è³ªå•ã‚’åé›†ã™ã‚‹ãŸã‚ã«4ã¤ã®æ®µéšã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµŒã¦ã„ã¾ã™ã€‚å¾¹åº•çš„ãªåˆ†æã«ã‚ˆã‚Šã€NewsQAãŒå˜ç´”ãªå˜èªã®ãƒãƒƒãƒãƒ³ã‚°ã‚„ãƒ†ã‚­ã‚¹ãƒˆã®å«æ„ã®èªè­˜ä»¥ä¸Šã®èƒ½åŠ›ã‚’è¦æ±‚ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€äººé–“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨æ©Ÿæ¢°ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å·®ã‚’æ¸¬å®šã—ã€å°†æ¥ã®ç ”ç©¶ã®é€²æ­©ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ç„¡æ–™ã§åˆ©ç”¨ã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>SQuADã‚ˆã‚Šã‚‚å›ç­”ã‚’ã™ã‚‹ãŸã‚ã«è¤‡é›‘ãªæ¨è«–ã‚’å¿…è¦ã¨ã™ã‚‹QAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚è¦æ¨¡æ„Ÿã¯SQuADã¨åŒç­‰ãƒ¬ãƒ™ãƒ«ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c427bc7c-40af-42aa-a689-d852081a92fc" alt="image" loading="lazy"><br><br>WordMatchingã«ã¨ã©ã¾ã‚‰ãšã€å›ç­”ãŒå­˜åœ¨ã—ãªã„ã€ã‚ã‚‹ã„ã¯è¨˜äº‹ä¸­ã§ãƒ¦ãƒ‹ãƒ¼ã‚¯ã§ã¯ãªã„ã‚‚ã®ã‚‚å«ã¾ã‚Œã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3839636e-c9af-4e4d-8eee-3d376d615a35" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coherence.html" target="_blank" rel="noopener noreferrer">#Coherence</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/971" target="_blank" rel="noopener noreferrer" class="title-link">Lexical Coherence Graph Modeling Using Word Embeddings, Mesgar+, NAACL'16</a>
<span class="snippet"><span>Comment</span><p>__translate: Coherence is established by semantic connections between sentences of a text which can be modeled by lexical relations. In this paper, we introduce the lexical coherence graph (LCG), a new graph-based model to represent lexical relations among sentences. The frequency of subgraphs (coherence patterns) of this graph captures the connectivity style of sentence nodes in this graph. The coherence of a text is encoded by a vector of these frequencies. We evaluate the LCG model on the readability ranking task. The results of the experiments show that the LCG model obtains higher accuracy than state-of-the-art coherence models. Using larger subgraphs yields higher accuracy, because they capture more structural information. However, larger subgraphs can be sparse. We adapt Kneser-Ney smoothing to smooth subgraphsâ€™ frequencies. Smoothing improves performance.</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2018-10-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/279" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Neural Headline Generation with Minimum Risk Training, Ayana+, N_A, arXiv'16</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå‹•è¦‹å‡ºã—ç”Ÿæˆã®ãŸã‚ã«ã€æœ€å°ãƒªã‚¹ã‚¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æœ€é©åŒ–ã—ã€è¦‹å‡ºã—ç”Ÿæˆã®æ”¹å–„ã‚’å®Ÿç¾ã™ã‚‹ã€‚ææ¡ˆæ‰‹æ³•ã¯è‹±èªã¨ä¸­å›½èªã®è¦‹å‡ºã—ç”Ÿæˆã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/CoNLL.html" target="_blank" rel="noopener noreferrer">#CoNLL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-02-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/258" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generating Sentences from a Continuous Space, Samuel R. Bowman+, CoNLL'16</a>
<span class="snippet"><span>GPT Summary</span>- RNNãƒ™ãƒ¼ã‚¹ã®å¤‰åˆ†ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’å°å…¥ã—ã€æ–‡å…¨ä½“ã®åˆ†æ•£æ½œåœ¨è¡¨ç¾ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€æ–‡ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚„ãƒˆãƒ”ãƒƒã‚¯ãªã©ã®ç‰¹æ€§ã‚’æ˜ç¤ºçš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã€‚æ½œåœ¨ç©ºé–“ã‚’é€šã˜ã¦æ–°ã—ã„æ–‡ã‚’ç”Ÿæˆã—ã€æ¬ æå˜èªã®è£œå®ŒåŠ¹æœã‚’å®Ÿè¨¼ã€‚ãƒ¢ãƒ‡ãƒ«ã®ç‰¹æ€§ã¨ä½¿ç”¨ã«é–¢ã™ã‚‹å¦å®šçš„ãªçµæœã‚‚ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>VAEã‚’åˆ©ç”¨ã—ã¦æ–‡ç”Ÿæˆ</p>
<p>ã€Variational Autoencoderå¾¹åº•è§£èª¬ã€‘<br><br>


<a href="https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24" target="_blank" rel="noopener noreferrer">https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/SentimentAnalysis.html" target="_blank" rel="noopener noreferrer">#SentimentAnalysis</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/206" target="_blank" rel="noopener noreferrer" class="title-link">Neural Network for Sentiment Analysis, EMNLP'16</a>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/DomainAdaptation.html" target="_blank" rel="noopener noreferrer">#DomainAdaptation</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/PRICAI.html" target="_blank" rel="noopener noreferrer">#PRICAI</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/142" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning from Numerous Untailored Summaries, Kikuchi+, PRICAI'16</a>
<span class="snippet"><span>Comment</span><p>New York Times Annotated Corpusï¼ˆNYTACï¼‰ã«å«ã¾ã‚Œã‚‹å¤§é‡ã®æ­£è§£è¦ç´„ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚<br><br>NYTACã«ã¯650,000ç¨‹åº¦ã®äººæ‰‹ã§ç”Ÿæˆã•ã‚ŒãŸå‚ç…§è¦ç´„ãŒä»˜ä¸ã•ã‚Œã¦ã„ã‚‹ãŒã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¦ç´„ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ´»ç”¨ã—ãŸäº‹ä¾‹ã¯ã¾ã å­˜åœ¨ã—ãªã„ã®ã§ã€ã‚„ã‚Šã¾ã—ãŸã¨ã„ã†è©±ã€‚<br><br><br><br>å…·ä½“çš„ã«ã¯ã€NYTACã«å­˜åœ¨ã™ã‚‹äººæ‰‹è¦ç´„ã‚’å…¨ã¦ãã®ã¾ã¾ä½¿ã†ã®ã§ã¯ãªãã€Extracitiveãªãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«åŠ¹æœçš„ãªäº‹ä¾‹ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦é¸åˆ¥ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆ<br><br>ã¾ãŸã€domain-adaptationã®æŠ€è¡“ã‚’å¿œç”¨ã—ã€NYTACãƒ‡ãƒ¼ã‚¿ã‚’è¦ç´„ã‚’é©ç”¨ã—ãŸã„targetã®ãƒ†ã‚­ã‚¹ãƒˆã«é©å¿œã™ã‚‹5ã¤ã®æ‰‹æ³•ã‚’ææ¡ˆ<br><br><br><br>ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã¯ã€åŸºæœ¬çš„ã«knapsackå•é¡Œã«åŸºã¥ã„ãŸè¦ç´„ãƒ¢ãƒ‡ãƒ«ï¼ˆExtractiveï¼‰ã‚’ç”¨ã„ã€å­¦ç¿’æ‰‹æ³•ã¨ã—ã¦ã¯Passive Aggressiveã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ§‹é€ å­¦ç¿’ç‰ˆã‚’åˆ©ç”¨ã™ã‚‹ã€‚<br><br>NYTACã®ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã™ã‚‹æ‰‹æ³•ã¨ã—ã¦ã€ä»¥ä¸‹ã®5ã¤ã®æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br><br><br>```<br><br>1. NytOnly: NYTACã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§å­¦ç¿’ã‚’è¡Œã„ã€targetå´ã®æƒ…å ±ã¯ç”¨ã„ãªã„<br><br>2. Mixture: targetã¨NYTACã®äº‹ä¾‹ã‚’ãƒãƒ¼ã‚¸ã—ã¦ä¸€ç·’ã«å­¦ç¿’ã™ã‚‹<br><br>3. LinInter: TrgtOnly(targetãƒ‡ãƒ¼ã‚¿ã®ã¿ã§å­¦ç¿’ã—ãŸå ´åˆï¼‰ã®weightã¨NytOnlyã§å­¦ç¿’ã—ãŸweightã‚’linear-interpolationã™ã‚‹ã€‚interpolation parameterã¯dev setã‹ã‚‰æ±ºå®š<br><br>4. Featurize: NytOnlyã®outputã‚’targetã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹éš›ã®è¿½åŠ ã®ç´ æ€§ã¨ã—ã¦ç”¨ã„ã‚‹<br><br>5. FineTune: NytOnlyã§å­¦ç¿’ã—ãŸweightã‚’åˆæœŸå€¤ã¨ã—ã¦ã€targetå´ã®ãƒ‡ãƒ¼ã‚¿ã§weightã‚’finetuneã™ã‚‹<br><br>``` <br><br><br><br>ã¾ãŸã€NYTACã«å«ã¾ã‚Œã‚‹å‚ç…§è¦ç´„ã«ã¯ã€ç”Ÿæˆçš„ãªã‚‚ã®ã‚„ã€ãƒ¡ã‚¿è¦–ç‚¹ã‹ã‚‰è¨˜è¿°ã•ã‚ŒãŸè¦ç´„ãªã©ã€æ§˜ã€…ãªã‚¿ã‚¤ãƒ—ã®è¦ç´„ãŒå­˜åœ¨ã™ã‚‹ã€‚ä»Šå›å­¦ç¿’ã—ãŸã„ãƒ¢ãƒ‡ãƒ«ã¯Extractiveãªè¦ç´„ãƒ¢ãƒ‡ãƒ«ãªã®ã§ã€ã“ã®ã‚ˆã†ãªè¦ç´„ã¯å­¦ç¿’äº‹ä¾‹ã¨ã—ã¦ã¯é©åˆ‡ã§ã¯ãªã„ã®ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸã„ã€‚<br><br>ãã“ã§ã€åŸæ–‡æ›¸ã‹ã‚‰Extractiveãªè¦ç´„ã‚’ç”Ÿæˆã—ãŸéš›ã®Oracle ROUGE-2ã‚¹ã‚³ã‚¢ã‚’å„å‚ç…§è¦ç´„-åŸæ–‡æ›¸å¯¾ã”ã¨ã«æ±‚ã‚ã€ç‰¹å®šã®é–¾å€¤ä»¥ä¸‹ã®äº‹ä¾‹ã¯ä½¿ç”¨ã—ãªã„ã‚ˆã†ã«ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®é¸æŠã‚’è¡Œã†ã‚ˆã†ã«ã™ã‚‹ã€‚<br><br><br><br>DUC2002 (å˜ä¸€æ–‡æ›¸è¦ç´„ã‚¿ã‚¹ã‚¯)ã€RSTDTBlong, RSTDTBshort (Rhetrical Structure Theory Discourse Tree Bankã«å«ã¾ã‚Œã‚‹400ä»¶ç¨‹åº¦ã®ï¼ˆç¢ºã‹ç¤¾èª¬ã®ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹ï¼‰è¦ç´„)ã®3ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã€‚<br><br><br><br>ã©ã¡ã‚‰ã®è©•ä¾¡ã«ãŠã„ã¦ã‚‚ã€FineTuneã‚’è¡Œã„ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®é¸æŠã‚’è¡Œã†ã‚ˆã†ã«ã—ãŸå ´åˆãŒææ¡ˆæ‰‹æ³•ã®ä¸­ã§ã¯ã‚‚ã£ã¨ã‚‚æ€§èƒ½ãŒã‚ˆã‹ã£ãŸã€‚<br><br>DUC2002ã§ã¯ã€LEADã‚„TextRankãªã©ã®æ‰‹æ³•ã‚’æœ‰æ„ã«outperformã—ãŸãŒã€DUC2002ã®best systemã«ã¯å‹ã¦ãªã‹ã£ãŸã€‚<br><br>ã—ã‹ã—ãªãŒã‚‰ã€RSTDTBlongã«ãŠã‘ã‚‹è©•ä¾¡ã§ã¯ã€RSTã®æƒ…å ±ãªã©ã‚’ç”¨ã„ã‚‹state-of-the-artãªã‚·ã‚¹ãƒ†ãƒ ã«ã€RSTã®æƒ…å ±ãªã©ã‚’ç”¨ã„ãªã„ææ¡ˆæ‰‹æ³•ãŒROUGEã‚¹ã‚³ã‚¢ã§outperformã—ãŸã€‚<br><br>RSTDTBshortã«ãŠã‘ã‚‹è©•ä¾¡ã§ã¯ã€RSTã‚’ç”¨ã„ã‚‹æ‰‹æ³•ï¼ˆå¹³å°¾ã•ã‚“ã®æ‰‹æ³•ï¼‰ã«ã¯åŠã°ãªã‹ã£ãŸãŒã€ãã‚Œä»¥å¤–ã§ã¯bestãªæ€§èƒ½ã€‚ã“ã‚Œã¯ã€RSTDTBshortã®å ´åˆã¯è¦ç´„ãŒæŒ‡ç¤ºçš„ãªè¦ç´„ã§ã‚ã‚‹ãŸã‚ã€ä»Šå›å­¦ç¿’ã«ç”¨ã„ãŸè¦ç´„ã®ãƒ‡ãƒ¼ã‚¿ã‚„ãƒ¢ãƒ‡ãƒ«ã¯å ±çŸ¥çš„ãªè¦ç´„ã®ãŸã‚ã®ã‚‚ã®ã§ã‚ã‚‹ãŸã‚ã€ã‚ã¾ã‚Šã†ã¾ãã„ã‹ãªã‹ã£ãŸã¨è€ƒå¯Ÿã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/136" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Incorporating Copying Mechanism in Sequence-to-Sequence Learning, Gu+, ACL'16</a>
<span class="snippet"><span>Comment</span><p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š


<a href="https://www.slideshare.net/akihikowatanabe3110/incorporating-copying-mechanism-in-sequene-to-sequence-learning" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/incorporating-copying-mechanism-in-sequene-to-sequence-learning</a>


</p>
<p>å˜èªã®ã‚³ãƒ”ãƒ¼ã¨ç”Ÿæˆã€ä¸¡æ–¹ã‚’è¡Œãˆã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚<br><br>location based addressingãªã©ã«ã‚ˆã£ã¦ã€ç”Ÿæˆã•ã‚ŒãŸå˜èªãŒsourceã«å«ã¾ã‚Œã¦ã„ãŸå ´åˆãªã©ã«ã€copy-mode, generate-modeã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã‚ˆã†ãªä»•çµ„ã¿ã«ãªã£ã¦ã„ã‚‹ã€‚<br><br><br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/65" target="_blank" rel="noopener noreferrer">[Paper Note] Pointing the unknown words, Gulcehre+, ACL'16</a>
 ã¨åŒã˜ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ç™ºè¡¨</p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/IJCAI.html" target="_blank" rel="noopener noreferrer">#IJCAI</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/132" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Distraction-Based Neural Networks for Modeling Documents, Chen+, IJCAI'16</a>
<span class="snippet"><span>Comment</span><p>Neuralãªãƒ¢ãƒ‡ãƒ«ã§ã€Œæ–‡æ›¸ã€ã®è¦ç´„ã‚’è¡Œã†ç ”ç©¶ã€‚<br><br><br><br>ææ¡ˆæ‰‹æ³•ã§ã¯ã€attention-basedãªsequence-to-sequenceãƒ¢ãƒ‡ãƒ«ã«distractionã¨å‘¼ã°ã‚Œã‚‹æ©Ÿæ§‹ã‚’å°å…¥ã™ã‚‹ã“ã¨ã‚’ææ¡ˆã€‚<br><br><br><br>distractionã‚’å°å…¥ã™ã‚‹motivationã¯ã€å…¥åŠ›æ–‡æ›¸ä¸­ã®ç•°ãªã‚‹æƒ…å ±ã‚’æ¨ªæ–­çš„ã«å‚ç…§ï¼ˆä¸€åº¦ç€ç›®ã—ãŸæƒ…å ±ã«ã¯ä»Šå¾Œã‚ã¾ã‚Šç€ç›®ã—ãªã„ã‚ˆã†ãªãƒã‚¤ã‚¢ã‚¹ã‚’ã‹ã‘ã‚‹ï¼‰ã—ãŸã†ãˆã§ã€è¦ç´„ã‚’ç”Ÿæˆã—ã‚ˆã†ã¨ã„ã†ã‚‚ã®ã€‚<br><br>ã“ã‚Œã«ã‚ˆã‚Šã€ç”Ÿæˆã•ã‚Œã‚‹è¦ç´„ã®å†—é•·æ€§ã‚’æ’é™¤ã™ã‚‹ã®ãŒç‹™ã„ã€‚<br><br><br><br>ä»¥ä¸‹ã®3ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç”¨ã„ã¦ã€distractionã‚’å®Ÿç¾<br><br><br><br>1. [Distraction over input content vectors]<br><br>ã€€tã‚¹ãƒ†ãƒƒãƒ—ç›®ã«ãŠã„ã¦ã€decoderã®inputã¨ã—ã¦ç”¨ã„ã‚‹context vectorã‚’<br><br>è¨ˆç®—ã™ã‚‹éš›ã«ã€é€šå¸¸ã®è¨ˆç®—ã«åŠ ãˆã¦ã€t-1ã‚¹ãƒ†ãƒƒãƒ—ç›®ã¾ã§ã«ä½¿ç”¨ã—ãŸ<br><br>context vectorã®æƒ…å ±ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€ã“ã‚Œã¾ã§decoderã®inputã¨ã—ã¦<br><br>åˆ©ç”¨ã•ã‚ŒãŸæƒ…å ±ã‚’ã‚ã¾ã‚Šé‡è¦–è¦–ã—ãªã„ã‚ˆã†ã«ã€context vectorã‚’ç”Ÿæˆã™ã‚‹ã€‚<br><br><br><br>2. [Distraction over attention weight vectors]<br><br>ã€€attentionã®é‡ã¿ã‚’è¨ˆç®—ã™ã‚‹éš›ã«ã€éå»ã«é«˜ã„attentionã®é‡ã¿ãŒã¤ã„ãŸ<br><br>encoderã®hidden stateã«ã¤ã„ã¦ã¯ã€ã‚ã¾ã‚Šé‡è¦è¦–ã—ãªã„ã‚ˆã†ã«<br><br>attentionã®é‡ã¿ã‚’è¨ˆç®—ã€‚1ã¨åŒæ§˜ã«ã€t-1ã‚¹ãƒ†ãƒƒãƒ—ç›®ã¾ã§ã®attention weightã®<br><br>historyã‚’ä¿æŒã—ã¦ãŠãæ´»ç”¨ã™ã‚‹ã€‚<br><br><br><br>3. [Distration in decoding]<br><br>ã€€decodingã‚¹ãƒ†ãƒƒãƒ—ã§beam-searchã‚’è¡Œã†éš›ã®ã‚¹ã‚³ã‚¢è¨ˆç®—ã«ã€distraction scoreã‚’å°å…¥ã€‚distraction<br><br>scoreã¯tã‚¹ãƒ†ãƒƒãƒ—ç›®ã¾ã§ã«ç”¨ã„ã‚‰ã‚ŒãŸcontext vectorã€attention<br><br>weightã€decoderã®stateã‹ã‚‰è¨ˆç®—ã•ã‚Œã€ã“ã‚Œã¾ã§ã¨åŒã˜ã‚ˆã†ãªæƒ…å ±ã«åŸºã¥ã„ã¦<br><br>å˜èªãŒç”Ÿæˆã•ã‚ŒãŸå ´åˆã¯ã€ã‚¹ã‚³ã‚¢ãŒä½ããªã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã€‚<br><br><br><br>CNNã€ãŠã‚ˆã³LCSTS data (å¤§è¦æ¨¡ãªä¸­å›½èªã®headline generationãƒ‡ãƒ¼ã‚¿)ã§è©•ä¾¡ã—ãŸçµæœã€ä¸Šè¨˜3ã¤ã®distractionæ©Ÿæ§‹ã‚’å°å…¥ã—ãŸå ´åˆã«ã€æœ€ã‚‚é«˜ã„ROUGEã‚¹ã‚³ã‚¢ã‚’ç²å¾—<br><br><br><br>ç‰¹ã«ã€åŸæ–‡æ›¸ãŒé•·ã„å ´åˆã«ã€çŸ­ã„å ´åˆã¨æ¯”è¼ƒã—ã¦ã€distractionæ©Ÿæ§‹ã‚’å°å…¥ã™ã‚‹ã¨ã€<br><br>ROUGEã‚¹ã‚³ã‚¢ã®æ”¹å–„å¹…ãŒå¤§ãããªã£ãŸã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/131" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Neural Summarization by Extracting Sentences and Words, Cheng+, ACL'16</a>
<span class="snippet"><span>Comment</span><p>Extractiveã‹ã¤Neuralãªå˜ä¸€æ–‡æ›¸è¦ç´„ãªã‚‰ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã—ã¦ä½¿ç”¨ã—ãŸæ–¹ãŒã‚ˆã„ã‹ã‚‚</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/CIKM.html" target="_blank" rel="noopener noreferrer">#CIKM</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/112" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Match between Geology Reports and Well Logs Using Spatial Information, Tong+, CIKM'16</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/89" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Neural Text Generation from Structured Data with Application to the  Biography Domain, Remi Lebret+, EMNLP'16, 2016.03</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªWikipediaã®ä¼è¨˜ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®ãŸã‚ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã€‚ãƒ¢ãƒ‡ãƒ«ã¯æ¡ä»¶ä»˜ããƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ãã€å›ºå®šèªå½™ã¨ã‚µãƒ³ãƒ—ãƒ«å›ºæœ‰ã®å˜èªã‚’çµ„ã¿åˆã‚ã›ã‚‹ã‚³ãƒ”ãƒ¼ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¡ç”¨ã€‚ææ¡ˆãƒ¢ãƒ‡ãƒ«ã¯å¤å…¸çš„ãªKneser-Neyãƒ¢ãƒ‡ãƒ«ã‚’ç´„15 BLEUãƒã‚¤ãƒ³ãƒˆä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Wikipediaã®äººç‰©ã«é–¢ã™ã‚‹info boxã‹ã‚‰ã€ãã®äººç‰©ã®biographyã®å†’é ­ã‚’ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã€‚<br>Neural Language Modelã«ã€æ–°ãŸã«Tableã®Embeddingã‚’å…¥ã‚Œã‚‰ã‚Œã‚‹ã‚ˆã†ã«table embeddingã‚’ææ¡ˆã—ã€table conditioned language modelã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br>inputã¯ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå›³ä¸­ã®input textã£ã¦ã„ã†ã®ã¯ã€å°‘ã—ç”¨èªãŒconfusingã ãŒã€è¨€èªãƒ¢ãƒ‡ãƒ«ã¸ã®inputã¨ã—ã¦ã€éå»ã«ç”Ÿæˆã—ãŸå˜èªã®ç³»åˆ—ã‚’å…¥ã‚Œã‚‹ã¨ã„ã†ã®ã‚’ç¤ºã—ã¦ã„ã‚‹ã ã‘ï¼‰<br><img src="https://user-images.githubusercontent.com/12249301/34460925-6483a6ca-ee60-11e7-9ced-d02a59c26281.png" alt="image" loading="lazy"><br><br>ãƒ¢ãƒ‡ãƒ«å…¨ä½“<br><img src="https://user-images.githubusercontent.com/12249301/34460923-4eea63b2-ee60-11e7-95e6-649ab1851dab.png" alt="image" loading="lazy"><br><br>Wikipediaã‹ã‚‰ç”Ÿæˆã—ãŸã€Biographyã«é–¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚å…¬é–‹ã—ã¦ã„ã‚‹ã€‚<br><img src="https://user-images.githubusercontent.com/12249301/34460928-93822082-ee60-11e7-81fc-b1840fea0b37.png" alt="image" loading="lazy"><br><br>template basedãªKNSmoothingã‚’ä½¿ã£ãŸãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚ˆã‚Šã‚‚é«˜ã„BLEUã‚¹ã‚³ã‚¢ã‚’ç²å¾—ã€‚ã•ã‚‰ã«ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®Globalãªæƒ…å ±ã‚’å…¥ã‚Œã‚‹æ‰‹æ³•ãŒã€æ€§èƒ½å‘ä¸Šã«å¯„ä¸ï¼ˆãŸã¨ãˆã°ãƒãƒ¼ãƒ åãƒ»ãƒªãƒ¼ã‚°ãƒ»ãƒã‚¸ã‚·ãƒ§ãƒ³ãªã©ã‚’ãã‚Œãã‚Œç‹¬ç«‹ã«è¦‹ã¦ã‚‚ã€ãƒã‚¹ã‚±ãƒƒãƒˆãƒœãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãªã®ã‹ã€ãƒ›ãƒƒã‚±ãƒ¼ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãªã®ã‹ã¯ã‚ã‹ã‚‰ãªã„ã‘ã©ã€ãƒ†ãƒ¼ãƒ–ãƒ«å…¨ä½“ã‚’è¦‹ã‚Œã°ã‚ã‹ã‚‹ã‚ˆã­ã¨ã„ã†æ°—æŒã¡ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/86" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Content Selection in Data-to-Text Systems: A Survey, arXiv'16, Gkatzia</a>
<span class="snippet"><span>Comment</span><p>Gkatziaæ°ã®"content selection"ã«é–¢ã™ã‚‹Survey</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/BeamSearch.html" target="_blank" rel="noopener noreferrer">#BeamSearch</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/80" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Sequence-to-Sequence Learning as Beam-Search Optimization, Wiseman+, EMNLP'16</a>
<span class="snippet"><span>Comment</span><p>seq2seqã‚’å­¦ç¿’ã™ã‚‹éš›ã«ã¯ã€gold-historyï¼ˆã“ã‚Œã¾ã§ç”Ÿæˆã—ãŸå˜èªãŒgoldãªã‚‚ã®ã¨ä¸€ç·’ï¼‰ã‚’ä½¿ç”¨ã—ã€æ¬¡ã«ç¶šãå˜èªã®å°¤åº¦ã‚’æœ€å¤§åŒ–ã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ãŒã€ã“ã‚Œã«ã¯ã€<br><br><br><br>1. Explosure Bias: testæ™‚ã§ã¯trainingæ™‚ã¨é•ã„gold historyã‚’ä½¿ãˆãªã„ã—ã€trainingæ™‚ã«ã¯éå»ã«ç”Ÿæˆã—ãŸå˜èªã«èª¤ã‚ŠãŒã‚ã‚‹ã¿ãŸã„ãªçŠ¶æ³ãŒãªã„ <br><br>2. Loss-Evaluation Mismatch: trainingæ™‚ã¯å˜èªãƒ¬ãƒ™ãƒ«ã®lossã‚’ä½¿ã†ãŒã€ã ã„ãŸã„ã¯sentence-levelã®metrics (BLEUãªã©)ã‚’æ”¹å–„ã—ãŸã„<br><br>3. Label Bias: å„ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã§ã®å˜èªã®ç”Ÿèµ·ç¢ºç‡ãŒå±€æ‰€çš„ã«æ­£è¦åŒ–ã•ã‚Œã€èª¤ã£ãŸhistoryã«ç¶šãå˜èªãŒgoldãªå±¥æ­´ã«ç¶šãå˜èªã¨åŒã˜é‡ï¼ˆã®ç¢ºç‡ï¼Ÿï¼‰ã‚’å—ã‘å–ã£ã¦ã—ã¾ã†<br><br><br><br>ã“ã‚Œã‚‰ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€targetã®"sequence"ã«å¯¾ã—ã¦ã‚¹ã‚³ã‚¢ï¼ˆç¢ºç‡ã§ã¯ãªã„ï¼‰ã‚’ä¸ãˆã‚‹ã‚ˆã†ãªseq2seqãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã€è¨“ç·´æ–¹æ³•ã¨ã—ã¦ã€beam search optimizationï¼ˆtrainingæ™‚ã®lossã¨ã—ã¦beam searchã®çµæœå¾—ã‚‰ã‚Œã‚‹errorã‚’ç”¨ã„ã‚‹ï¼‰ã‚’ææ¡ˆã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/76" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Larger-context language modelling with recurrent neural networks, Wang+, ACL'16</a>
<span class="snippet"><span>Comment</span><p>## æ¦‚è¦<br><br>é€šå¸¸ã®Neural Language Modelã¯sentenceé–“ã«ç‹¬ç«‹æ€§ã®ä»®å®šã‚’ç½®ããƒ¢ãƒ‡ãƒ«åŒ–ã•ã‚Œã¦ã„ã‚‹ãŒã€ã“ã®ç‹¬ç«‹æ€§ã‚’æ’é™¤ã—ã€preceding sentencesã«ä¾å­˜ã™ã‚‹ã‚ˆã†ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ã“ã¨ã§ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ¼ãƒ‘ã‚¹ãƒ¬ãƒ™ãƒ«ã§ã®PerplexityãŒæ”¹å–„ã—ãŸã¨ã„ã†è©±ã€‚ææ¡ˆã—ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€contextã‚’è€ƒæ…®ã™ã‚‹ã“ã¨ã§ç‰¹ã«åè©ã‚„å‹•è©ã€å½¢å®¹è©ã®äºˆæ¸¬æ€§èƒ½ãŒå‘ä¸Šã€‚Late-Fusion methodã¨å‘¼ã°ã‚Œã‚‹RNNã®outputã®è¨ˆç®—ã«context vectorã‚’çµ„ã¿è¾¼ã‚€æ‰‹æ³•ãŒã€Perplexityã®æ”¹å–„ã«ã‚‚ã£ã¨ã‚‚å¯„ä¸ã—ã¦ã„ãŸã€‚<br><br><br><br>## æ‰‹æ³•<br><br><img src="https://user-images.githubusercontent.com/12249301/34412713-1e16da94-ec22-11e7-830c-0d0b6247207c.png" alt="image" loading="lazy"><br><br><br><br>sentenceé–“ã®ç‹¬ç«‹æ€§ã‚’æ’é™¤ã—ã€Corpusãƒ¬ãƒ™ãƒ«ã®probabilityã‚’ä¸‹å›³ã®ã‚ˆã†ã«å®šç¾©ã€‚ï¼ˆæ™®é€šã¯P(SlãŒæ¡ä»¶ä»˜ã‘ã•ã‚Œã¦ã„ãªã„)ï¼‰<br><br><img src="https://user-images.githubusercontent.com/12249301/34412980-e2425afa-ec23-11e7-86cd-148f85dccc07.png" alt="image" loading="lazy"><br><br><br><br>preceding sentence (context)ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã™ã‚‹ãŸã‚ã«ã€3ç¨®é¡ã®æ‰‹æ³•ã‚’ææ¡ˆã€‚<br><br><br><br>[1. bag-of-words context]<br><br>ã€€ãƒŠã‚¤ãƒ¼ãƒ–ã«ã€contextã«ç¾ã‚ŒãŸå˜èªã®ï¼ˆå˜ä¸€ã®ï¼‰bag-of-wordsãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œã‚Šã€linear layerã‚’ã‹ã¾ã›ã¦context vectorã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã€‚<br><br><br><br>[2. context recurrent neural network]<br><br>ã€€preceding sentencesã‚’bag-of-wordsãƒ™ã‚¯ãƒˆãƒ«ã®ç³»åˆ—ã§è¡¨ç¾ã—ã€ã“ã‚Œã‚‰ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’sequentialã«RNN-LSTMã«èª­ã¿è¾¼ã¾ã›ã€æœ€å¾Œã®hidden stateã‚’context vectorã¨ã™ã‚‹æ‰‹æ³•ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€sentenceãŒå‡ºç¾ã—ãŸé †ç•ªãŒè€ƒæ…®ã•ã‚Œã‚‹ã€‚<br><br><br><br>[3. attention based context representation]<br><br>ã€€Attentionã‚’ç”¨ã„ã‚‹æ‰‹æ³•ã‚‚ææ¡ˆã•ã‚Œã¦ãŠã‚Šã€context recurrent neural networkã¨åŒæ§˜ã«RNNã«bag-of-wordsã®sequenceã‚’é£Ÿã‚ã›ã‚‹ãŒã€å„æ™‚ç‚¹ã«ãŠã‘ã‚‹context sentenceã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã€bi-directionalãªRNNã®forward, backward stateã‚’concatã—ãŸã‚‚ã®ã§è¡¨ç¾ã—ã€attention weightã®è¨ˆç®—ã«ç”¨ã„ã‚‹ã€‚context vectorã¯1, 2ã§ã¯current sentenceä¸­ã§ã¯å…±é€šã®ã‚‚ã®ã‚’ç”¨ã„ã‚‹ãŒã€attention basedãªå ´åˆã¯current sentenceã®å˜èªã”ã¨ã«ç•°ãªã‚‹context vectorã‚’ç”Ÿæˆã—ã¦ç”¨ã„ã‚‹ã€‚<br><br><br><br>ç”Ÿæˆã—ãŸcontext vectorã‚’sentence-levelã®RNNè¨€èªãƒ¢ãƒ‡ãƒ«ã«çµ„ã¿åˆã‚ã›ã‚‹éš›ã«ã€äºŒç¨®é¡ã®Fusion Methodã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br><br><br>[1. Early Fusion]<br><br>ã€€ãƒŠã‚¤ãƒ¼ãƒ–ã«ã€RNNLMã®å„æ™‚ç‚¹ã§ã®inputã«context vectorã®æƒ…å ±ã‚’çµ„ã¿è¾¼ã‚€æ–¹æ³•ã€‚<br><br>[2. Late Fusion]<br><br>ã€€ã‚ˆã‚Šã†ã¾ãcontext vectorã®æƒ…å ±ã‚’çµ„ã¿è¾¼ã‚€ãŸã‚ã«ã€current sentenceå†…ã®å˜èªã®dependency(intra-sentence dependency)ã¨ã€current sentenceã¨contextã®é–¢ä¿‚ã‚’åˆ¥ã€…ã«è€ƒæ…®ã™ã‚‹ã€‚context vectorã¨memory cellã®æƒ…å ±ã‹ã‚‰ã€context vectorä¸­ã®ä¸è¦ç®‡æ‰€ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸcontrolled context vectorã‚’ç”Ÿæˆã—ã€LSTMã®outputã®è¨ˆç®—ã«ç”¨ã„ã‚‹ã€‚Later Fusionã¯ã‚·ãƒ³ãƒ—ãƒ«ã ãŒã€corpusãƒ¬ãƒ™ãƒ«ã®language modelingã®å‹¾é…æ¶ˆå¤±å•é¡Œã‚’ç·©å’Œã™ã‚‹ã“ã¨ã‚‚ã§ãã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34413898-99efbaf8-ec29-11e7-94f5-db82eee399b3.png" alt="image" loading="lazy"><br><br><br><br>## è©•ä¾¡<br><br>IMDB, BBC, PennTreebank, Fil9 (cleaned wikipedia corpus)ã®4ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ã€corpus levelã§Perplexityã‚’æ¸¬ã£ãŸã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/34414121-b75b2996-ec2a-11e7-9716-dbbb9006b1b5.png" alt="image" loading="lazy"><br><br><br><br>Late FusionãŒPerplexityã®æ¸›å°‘ã«å¤§ããå¯„ä¸ã—ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34414218-596b373a-ec2b-11e7-85ad-cf98df04ce57.png" alt="image" loading="lazy"><br><br><br><br>PoSã‚¿ã‚°ã”ã¨ã®perplexityã‚’æ¸¬ã£ãŸçµæœã€contextã‚’è€ƒæ…®ã—ãŸå ´åˆã«åè©ã‚„å½¢å®¹è©ã€å‹•è©ã®Perplexityã«æ”¹å–„ãŒè¦‹ã‚‰ã‚ŒãŸã€‚ä¸€æ–¹ã€Coordinate Conjungtion (And, Or, So, Forãªã©)ã‚„é™å®šè©ã€Personal Pronouns (I, You, It, Heãªã©)ã®Perplexityã¯åŠ£åŒ–ã—ãŸã€‚å‰è€…ã¯open-classãªå†…å®¹èªã§ã‚ã‚Šã€å¾Œè€…ã¯closed-classãªæ©Ÿèƒ½èªã§ã‚ã‚‹ã€‚æ©Ÿèƒ½èªã¯grammaticalãªroleã‚’æ±ºã‚ã‚‹ã®ã«å¯¾ã—ã€å†…å®¹èªã¯ãã®åã®é€šã‚Šã€sentenceã‚„discourseã®å†…å®¹ã‚’æ±ºã‚ã‚‹ã‚‚ã®ãªã®ã§ã€æ–‡æ›¸ã®å†…å®¹ã‚’ã‚ˆã‚Šæ‰ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã¨è€ƒå¯Ÿã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/IJCAI.html" target="_blank" rel="noopener noreferrer">#IJCAI</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/73" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Distraction-Based Neural Networks for Modeling Documents, Chen+, IJCAI'16</a>
<span class="snippet"><span>Comment</span><p>Neuralãªãƒ¢ãƒ‡ãƒ«ã§ã€Œæ–‡æ›¸ã€ã®è¦ç´„ã‚’è¡Œã†ç ”ç©¶ã€‚<br><br><br><br>ææ¡ˆæ‰‹æ³•ã§ã¯ã€attention-basedãªsequence-to-sequenceãƒ¢ãƒ‡ãƒ«ã«distractionã¨å‘¼ã°ã‚Œã‚‹æ©Ÿæ§‹ã‚’å°å…¥ã™ã‚‹ã“ã¨ã‚’ææ¡ˆã€‚<br><br><br><br>distractionã‚’å°å…¥ã™ã‚‹motivationã¯ã€å…¥åŠ›æ–‡æ›¸ä¸­ã®ç•°ãªã‚‹æƒ…å ±ã‚’æ¨ªæ–­çš„ã«å‚ç…§ï¼ˆä¸€åº¦ç€ç›®ã—ãŸæƒ…å ±ã«ã¯ä»Šå¾Œã‚ã¾ã‚Šç€ç›®ã—ãªã„ã‚ˆã†ãªãƒã‚¤ã‚¢ã‚¹ã‚’ã‹ã‘ã‚‹ï¼‰ã—ãŸã†ãˆã§ã€è¦ç´„ã‚’ç”Ÿæˆã—ã‚ˆã†ã¨ã„ã†ã‚‚ã®ã€‚<br><br>ã“ã‚Œã«ã‚ˆã‚Šã€ç”Ÿæˆã•ã‚Œã‚‹è¦ç´„ã®å†—é•·æ€§ã‚’æ’é™¤ã™ã‚‹ã®ãŒç‹™ã„ã€‚<br><br><br><br>ä»¥ä¸‹ã®3ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç”¨ã„ã¦ã€distractionã‚’å®Ÿç¾<br><br><br><br>1. [Distraction over input content vectors]<br><br>ã€€tã‚¹ãƒ†ãƒƒãƒ—ç›®ã«ãŠã„ã¦ã€decoderã®inputã¨ã—ã¦ç”¨ã„ã‚‹context vectorã‚’<br><br>è¨ˆç®—ã™ã‚‹éš›ã«ã€é€šå¸¸ã®è¨ˆç®—ã«åŠ ãˆã¦ã€t-1ã‚¹ãƒ†ãƒƒãƒ—ç›®ã¾ã§ã«ä½¿ç”¨ã—ãŸ<br><br>context vectorã®æƒ…å ±ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€ã“ã‚Œã¾ã§decoderã®inputã¨ã—ã¦<br><br>åˆ©ç”¨ã•ã‚ŒãŸæƒ…å ±ã‚’ã‚ã¾ã‚Šé‡è¦–è¦–ã—ãªã„ã‚ˆã†ã«ã€context vectorã‚’ç”Ÿæˆã™ã‚‹ã€‚<br><br><br><br>2. [Distraction over attention weight vectors]<br><br>ã€€attentionã®é‡ã¿ã‚’è¨ˆç®—ã™ã‚‹éš›ã«ã€éå»ã«é«˜ã„attentionã®é‡ã¿ãŒã¤ã„ãŸ<br><br>encoderã®hidden stateã«ã¤ã„ã¦ã¯ã€ã‚ã¾ã‚Šé‡è¦è¦–ã—ãªã„ã‚ˆã†ã«<br><br>attentionã®é‡ã¿ã‚’è¨ˆç®—ã€‚1ã¨åŒæ§˜ã«ã€t-1ã‚¹ãƒ†ãƒƒãƒ—ç›®ã¾ã§ã®attention weightã®<br><br>historyã‚’ä¿æŒã—ã¦ãŠãæ´»ç”¨ã™ã‚‹ã€‚<br><br><br><br>3. [Distration in decoding]<br><br>ã€€decodingã‚¹ãƒ†ãƒƒãƒ—ã§beam-searchã‚’è¡Œã†éš›ã®ã‚¹ã‚³ã‚¢è¨ˆç®—ã«ã€distraction scoreã‚’å°å…¥ã€‚distraction<br><br>scoreã¯tã‚¹ãƒ†ãƒƒãƒ—ç›®ã¾ã§ã«ç”¨ã„ã‚‰ã‚ŒãŸcontext vectorã€attention<br><br>weightã€decoderã®stateã‹ã‚‰è¨ˆç®—ã•ã‚Œã€ã“ã‚Œã¾ã§ã¨åŒã˜ã‚ˆã†ãªæƒ…å ±ã«åŸºã¥ã„ã¦<br><br>å˜èªãŒç”Ÿæˆã•ã‚ŒãŸå ´åˆã¯ã€ã‚¹ã‚³ã‚¢ãŒä½ããªã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã€‚<br><br><br><br>CNNã€ãŠã‚ˆã³LCSTS data (å¤§è¦æ¨¡ãªä¸­å›½èªã®headline generationãƒ‡ãƒ¼ã‚¿)ã§è©•ä¾¡ã—ãŸçµæœã€ä¸Šè¨˜3ã¤ã®distractionæ©Ÿæ§‹ã‚’å°å…¥ã—ãŸå ´åˆã«ã€æœ€ã‚‚é«˜ã„ROUGEã‚¹ã‚³ã‚¢ã‚’ç²å¾—<br><br><br><br>ç‰¹ã«ã€åŸæ–‡æ›¸ãŒé•·ã„å ´åˆã«ã€çŸ­ã„å ´åˆã¨æ¯”è¼ƒã—ã¦ã€distractionæ©Ÿæ§‹ã‚’å°å…¥ã™ã‚‹ã¨ã€<br><br>ROUGEã‚¹ã‚³ã‚¢ã®æ”¹å–„å¹…ãŒå¤§ãããªã£ãŸã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹</p>
<p>Distractionæ©Ÿæ§‹ã®æœ‰ç”¨æ€§ã¯ã€ACL'17ã®stanford NLPã‚°ãƒ«ãƒ¼ãƒ—ãŒææ¡ˆã—ãŸPointer Generator Networkã§ã‚‚ç¤ºã•ã‚Œã¦ã„ã‚‹ï¼ˆCoverage Vectorã¨ã„ã†å‘¼ã³æ–¹ã‚’ã—ã¦ãŸæ°—ãŒã™ã‚‹ï¼‰</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/70" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning Distributed Representations of Sentences from Unlabelled Data, Hill+, NAACL'16</a>
<span class="snippet"><span>Comment</span><p>Sentenceã®representationã‚’å­¦ç¿’ã™ã‚‹è©±<br><br><br><br>ä»£è¡¨çš„ãªsentenceã®representationä½œæˆæ‰‹æ³•(CBOW, SkipGram, SkipThought, Paragraph Vec, NMTãªã©)ã‚’supervisedãªè©•ä¾¡ï¼ˆã‚¿ã‚¹ã‚¯å¿—å‘+supervisedï¼‰ã¨unsupervisedãªè©•ä¾¡(æ–‡é–“ã®è·é›¢ã‚’ã‚³ã‚µã‚¤ãƒ³è·é›¢ã§ã¯ã‹ã‚Šã€äººé–“ãŒæ±ºã‚ãŸé †åºã¨ç›¸é–¢ã‚’æ¸¬ã‚‹)ã§æ¯”è¼ƒã—ã¦ã„ã‚‹ã€‚<br><br><br><br>ã¾ãŸç­†è€…ã‚‰ã¯Sequential Denoising Auto Encoder(SDAE)ã¨FastSentã¨å‘¼ã°ã‚Œã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ãŠã‚Šã€å‰è€…ã¯orderedãªsentenceãƒ‡ãƒ¼ã‚¿ãŒãªãã¦ã‚‚è¨“ç·´ã§ãã€FastSentã¯orderedãªsentenceãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã ãŒé«˜é€Ÿã«è¨“ç·´ã§ãã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ã€‚<br><br><br><br>å®Ÿé¨“ã®çµæœã€supervisedãªè©•ä¾¡ã§ã¯ã€åŸºæœ¬çš„ã«ã¯SkipThoughtãŒã‚‚ã£ã¨ã‚‚è‰¯ã„æ€§èƒ½ã‚’ç¤ºã—ã€paraphrasingã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€SkipThoughtã«3ãƒã‚¤ãƒ³ãƒˆç¨‹åº¦å·®ã‚’ã¤ã‘ã¦è‰¯ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚unsupervisedãªè©•ä¾¡ã§ã¯ã€DictRepã¨FastSentãŒã‚‚ã£ã¨ã‚‚è‰¯ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚<br><br><br><br>å®Ÿé¨“ã®çµæœã€ä»¥ä¸‹ã®ã‚ˆã†ãªçŸ¥è¦‹ãŒå¾—ã‚‰ã‚ŒãŸï¼š<br><br><br><br>## ç•°ãªã‚‹objective functionã¯ç•°ãªã‚‹embeddingã‚’ä½œã‚Šå‡ºã™<br><br>objective functionã¯ã€ä¸»ã«éš£æ¥ã™ã‚‹æ–‡ã‚’äºˆæ¸¬ã™ã‚‹ã‚‚ã®ã¨ã€è‡ªåˆ†è‡ªèº«ã‚’å†ç¾ã™ã‚‹ã‚‚ã®ã«åˆ†ã‘ã‚‰ã‚Œã‚‹ã€‚ã“ã‚Œã‚‰ã®é•ã„ã«ã‚ˆã£ã¦ã€ç”Ÿæˆã•ã‚Œã‚‹embeddingãŒç•°ãªã£ã¦ã„ã‚‹ã€‚Table5ã‚’ã¿ã‚‹ã¨ã€å¾Œè€…ã«ã¤ã„ã¦ã¯ã€ç”Ÿæˆã•ã‚ŒãŸrepresentationã®nearest neighborã‚’è¦‹ã¦ã„ã‚‹ã¨ã€è‡ªèº«ã¨ä¼¼ãŸã‚ˆã†ãªå˜èªã‚’å«ã‚€æ–‡ãŒå¼•ã£å¼µã£ã¦ã“ã‚Œã‚‹ãŒã€å‰è€…ã«ã¤ã„ã¦ã¯ã€æ–‡ã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚„æ©Ÿèƒ½ã¯ä¼¼ã¦ã„ã‚‹ãŒã€å˜èªã®é‡è¤‡ã¯å°‘ãªã‹ã£ãŸã‚Šã™ã‚‹ã€‚<br><br><br><br>## supervisedãªå ´åˆã¨unsupervisedãªè©•ä¾¡ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®é•ã„<br><br>supervisedãªè¨­å®šã§ã¯ã€SkipThoughtã‚„SDAEãªã©ã®ãƒ¢ãƒ‡ãƒ«ãŒè‰¯ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ãŒã€unsupervisedãªè¨­å®šã§ã¯ã¾ã‚Šã†ã¾ãã„ã‹ãšã€‚unsupevisedãªè¨­å®šã§ã¯log-linearãƒ¢ãƒ‡ãƒ«ãŒåŸºæœ¬çš„ã«ã¯è‰¯ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚<br><br><br><br>## pre-trainedãªãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ãã†ã§ãªã„å ´åˆã¨æ¯”è¼ƒã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒè‰¯ã„<br><br><br><br>## å¿…è¦ãªãƒªã‚½ãƒ¼ã‚¹ã®é•ã„<br><br>ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ã¯ã€é †åºã¥ã‘ã‚‰ã‚ŒãŸæ–‡ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã ã£ãŸã‚Šã€æ–‡ã®é †åºãŒå­¦ç¿’ã«å¿…è¦ãªã‹ã£ãŸã‚Šã™ã‚‹ã€‚ã‚ã‚‹ã„ã¯ã€ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«æ™‚é–“ãŒã‹ã‹ã£ãŸã‚Šã€ã‚ã¡ã‚ƒãã¡ã‚ƒãƒ¡ãƒ¢ãƒªé£Ÿã£ãŸã‚Šã™ã‚‹ã€‚ã“ã®ã‚ˆã†ãªãƒªã‚½ãƒ¼ã‚¹ã®æ€§è³ªã®é•ã„ã¯ã€ä½¿ç”¨ã§ãã‚‹applicationã«åˆ¶ç´„ã‚’ä¸ãˆã‚‹ã€‚<br><br><br><br>## çµè«–<br><br>ã¨ã‚Šã‚ãˆãšã€supervisedãªãƒ¢ãƒ‡ãƒ«ã«representationã‚’ä½¿ã£ã¦ãƒ¢ãƒ‡ãƒ«ã«ãªã‚“ã‚‰ã‹ã®knowledgeã‚’ã¶ã¡ã“ã¿ãŸã„ã¨ãã¯SkipThoughtã€å˜ç´”ã«é¡ä¼¼ã—ãŸæ–‡ã‚’æ¤œç´¢ã—ãŸã„ã¨ã‹ã€ãã†ã„ã†å ´åˆã¯FastSentã‚’ä½¿ã†ã¨è‰¯ã„ã£ã¦ã“ã¨ã§ã™ã‹ã­.</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/65" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Pointing the unknown words, Gulcehre+, ACL'16</a>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€source textã‹ã‚‰ã®ã‚³ãƒ”ãƒ¼ã‚’è¡Œãˆã‚‹æ©Ÿæ§‹ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§æœªçŸ¥èªå•é¡Œã«å¯¾å‡¦ã—ãŸè©±</p>
<p>CopyNetã¨åŒã˜ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ï¼ˆã¨ã„ã†ã‹åŒã˜conferenceã§ï¼‰ç™ºè¡¨</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1954" target="_blank" rel="noopener noreferrer" class="title-link">Neural Machine Translation by Jointly Learning to Align and Translate, Dzmitry Bahdanau+, ICLR'15</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æ©Ÿæ¢°ç¿»è¨³ã¯ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼-ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç”¨ã„ã¦ç¿»è¨³æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€å›ºå®šé•·ã®ãƒ™ã‚¯ãƒˆãƒ«ã®ä½¿ç”¨ãŒæ€§èƒ½å‘ä¸Šã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã§ã‚ã‚‹ã¨ã—ã€ãƒ¢ãƒ‡ãƒ«ãŒé–¢é€£ã™ã‚‹ã‚½ãƒ¼ã‚¹æ–‡ã®éƒ¨åˆ†ã‚’è‡ªå‹•çš„ã«æ¤œç´¢ã§ãã‚‹ã‚ˆã†ã«æ‹¡å¼µã™ã‚‹ã“ã¨ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è‹±èªã‹ã‚‰ãƒ•ãƒ©ãƒ³ã‚¹èªã¸ã®ç¿»è¨³ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ•ãƒ¬ãƒ¼ã‚ºãƒ™ãƒ¼ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãŒç›´æ„Ÿã¨ä¸€è‡´ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>(Cross-)Attentionã‚’åˆã‚ã¦ææ¡ˆã—ãŸç ”ç©¶ã€‚ãƒ¡ãƒ¢ã£ã¦ãªã‹ã£ãŸã®ã§ä»Šæ›´ãªãŒã‚‰è¿½åŠ ã€‚Attentionã¯ã“ã“ã‹ã‚‰ã¯ã˜ã¾ã£ãŸï¼ˆã¨èªè­˜ã—ã¦ã„ã‚‹ï¼‰</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/985" target="_blank" rel="noopener noreferrer" class="title-link">chrF: character n-gram F-score for automatic MT evaluation, Mono Popovic, WMT'15</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€æ©Ÿæ¢°ç¿»è¨³ã®è©•ä¾¡ã«æ–‡å­—n-gram Fã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ææ¡ˆã—ã¾ã™ã€‚ç§ãŸã¡ã¯ã€ã“ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ãŒã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ã§äººé–“ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¨ç›¸é–¢ã—ã¦ãŠã‚Šã€ç‰¹ã«ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ã§ã®ç›¸é–¢ãŒéå¸¸ã«é«˜ã„ã“ã¨ã‚’å ±å‘Šã—ã¾ã—ãŸã€‚ã“ã®ææ¡ˆã¯éå¸¸ã«æœ‰æœ›ã§ã‚ã‚Šã€WMT14ã®å…±æœ‰è©•ä¾¡ã‚¿ã‚¹ã‚¯ã§ã‚‚æœ€é«˜ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ä¸Šå›ã‚Šã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>character-basedãªn-gram overlapã‚’referenceã¨ã‚·ã‚¹ãƒ†ãƒ ã§è¨ˆç®—ã™ã‚‹æ‰‹æ³•</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/978" target="_blank" rel="noopener noreferrer" class="title-link"> From word embeddings to document distances, Kusner+, PMLR'15</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€æ–°ã—ã„è·é›¢é–¢æ•°ã§ã‚ã‚‹Word Mover's Distanceï¼ˆWMDï¼‰ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚WMDã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆé–“ã®éé¡ä¼¼æ€§ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚ç§ãŸã¡ã®ç ”ç©¶ã§ã¯ã€å˜èªåŸ‹ã‚è¾¼ã¿ã®æœ€æ–°ã®çµæœã«åŸºã¥ã„ã¦WMDã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚WMDã¯ã€å˜èªãŒåˆ¥ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å˜èªã«åˆ°é”ã™ã‚‹ãŸã‚ã«å¿…è¦ãªæœ€å°è·é›¢ã‚’è¨ˆç®—ã—ã¾ã™ã€‚ç§ãŸã¡ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¯ã€å®Ÿè£…ãŒç°¡å˜ã§ã‚ã‚Šã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚‚å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚ã•ã‚‰ã«ã€ç§ãŸã¡ã¯8ã¤ã®å®Ÿä¸–ç•Œã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†é¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§WMDãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’è©•ä¾¡ã—ã€ä½ã„ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒ¼ãƒˆã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>WMS/SMS/S+WMS<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/946" target="_blank" rel="noopener noreferrer">MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance, Zhao+, EMNLP-IJCNLP'19</a>
 ã¯ã“ã‚Œã‚‰ã‹ã‚‰inspiredã•ã‚Œææ¡ˆã•ã‚ŒãŸ</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/969" target="_blank" rel="noopener noreferrer" class="title-link">Document-Level Machine Translation Evaluation with Gist Consistency and Text Cohesion, Gong+, DiscoMT'15</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ImageCaptioning.html" target="_blank" rel="noopener noreferrer">#ImageCaptioning</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/670" target="_blank" rel="noopener noreferrer" class="title-link">CIDEr: Consensus-based Image Description Evaluation, Ramakrishna Vedantam+, N_A, CVPR'15</a>
<span class="snippet"><span>GPT Summary</span>- ç”»åƒã‚’æ–‡ç« ã§è‡ªå‹•çš„ã«èª¬æ˜ã™ã‚‹ã“ã¨ã¯ã€é•·å¹´ã®èª²é¡Œã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€äººé–“ã®åˆæ„ã‚’åˆ©ç”¨ã—ãŸç”»åƒèª¬æ˜ã®è©•ä¾¡ã®ãŸã‚ã®æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ææ¡ˆã—ã€æ–°ã—ã„è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ã¨2ã¤ã®æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å«ã‚€ã€‚ææ¡ˆæ‰‹æ³•ã¯ã€äººé–“ã®åˆ¤æ–­ã‚’ã‚ˆã‚Šæ­£ç¢ºã«æ‰ãˆã‚‹ã“ã¨ãŒã§ãã€5ã¤ã®æœ€å…ˆç«¯ã®ç”»åƒèª¬æ˜æ‰‹æ³•ã‚’è©•ä¾¡ã—ã€å°†æ¥ã®æ¯”è¼ƒã®ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æä¾›ã™ã‚‹ã€‚CIDEr-Dã¯ã€MS COCOè©•ä¾¡ã‚µãƒ¼ãƒãƒ¼ã®ä¸€éƒ¨ã¨ã—ã¦åˆ©ç”¨å¯èƒ½ã§ã‚ã‚Šã€ã‚·ã‚¹ãƒ†ãƒãƒ†ã‚£ãƒƒã‚¯ãªè©•ä¾¡ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2021-06-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/369" target="_blank" rel="noopener noreferrer" class="title-link">Effective Approaches to Attention-based Neural Machine Translation, Luong+, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>Luongè«–æ–‡ã€‚attentionã®è©±ã—ã¯ã˜ã‚ã‚‹ã¨ã€ã ã„ãŸã„Bahdanau+ã‹ã€Luong+è«–æ–‡ãŒå¼•ç”¨ã•ã‚Œã‚‹ã€‚<br><br><br><br>Global Attentionã¨ã€Local Attentionã«ã¤ã„ã¦è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚Global AttentionãŒã‚ˆãåˆ©ç”¨ã•ã‚Œã‚‹ã€‚<br><br><br><br>Global Attention<br><br><img src="https://user-images.githubusercontent.com/12249301/120452200-008ec280-c3cd-11eb-8ced-47dc9e67f487.png" alt="image" loading="lazy"><br><br><br><br>Local Attention<br><br><img src="https://user-images.githubusercontent.com/12249301/120452397-2025eb00-c3cd-11eb-9d3b-0f7802a40712.png" alt="image" loading="lazy"><br><br></p>
<p>ã‚„ã¯ã‚ŠèŠæ± ã•ã‚“ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ãŒé‰„æ¿ã€‚<br><br>


<a href="https://www.slideshare.net/yutakikuchi927/deep-learning-nlp-attention" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/yutakikuchi927/deep-learning-nlp-attention</a>


</p>
<p>å‚è€ƒã¾ã§ã«ã€Luongã‚‰ã®Global Attentionã®è¨ˆç®—ã®æµã‚Œã¯ä¸‹è¨˜ã¨ãªã£ã¦ã„ã‚‹ï¼š<br><br>- h_t -&gt; a_t -&gt; c_t -&gt; h^~_t<br><br><br><br>Bahdanauã‚‰ã®Attentionã¯ä¸‹è¨˜<br><br>- h_t-1 -&gt; a_t -&gt; c_t -&gt; h_t<br><br><br><br>t-1ã®hidden stateã‚’ä½¿ã†ã®ã‹ã€input feedingå¾Œã®ç¾åœ¨ã®hidden stateã‚’attention weightã®è¨ˆç®—ã«ä½¿ã†ã®ã‹ãŒç•°ãªã£ã¦ã„ã‚‹ã€‚</p>
<p>ã¾ãŸã€éå»ã®alignmentã®æƒ…å ±ã‚’è€ƒæ…®ã—ãŸä¸Šã§ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦ã„ããŸã‚ã«ã€input-feeding approachã‚‚ææ¡ˆ<br><br><img src="https://user-images.githubusercontent.com/12249301/120877145-cfdaa300-c5ef-11eb-8a8b-a57d03d864b4.png" alt="image" loading="lazy"><br><br><br><br>input-feeding appproachã§ã¯ã€t-1ã‚¹ãƒ†ãƒƒãƒ—ç›®ã®outputã®ç®—å‡ºã«ä½¿ã£ãŸh^~_tï¼ˆhidden_stateã¨context vectorã‚’concatã—ã€tanhã®activationã‚’å™›ã¾ã›ãŸç·šå½¢å¤‰æ›ã‚’è¡Œãªã£ãŸãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã‚’ã€æ™‚åˆ»tã®input embeddingã«concatã—ã¦ã€RNNã«å…¥åŠ›ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/IJCNLP.html" target="_blank" rel="noopener noreferrer">#IJCNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-03-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/266" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unsupervised prediction of acceptability judgements, Lau+, ACL-IJCNLP'15</a>
<span class="snippet"><span>Comment</span><p>æ–‡ã®acceptabilityï¼ˆå®¹èªåº¦ï¼‰è«–æ–‡ã€‚<br><br>æ–‡ã®acceptabilityã¨ã¯ã€native speakerãŒã‚ã‚‹æ–‡ã‚’èª­ã‚“ã ã¨ãã«ã€ãã®æ–‡ã‚’æ­£ã—ã„æ–‡ã¨ã—ã¦å®¹èªã§ãã‚‹åº¦åˆã„ã®ã“ã¨ã€‚<br><br>acceptabilityã‚¹ã‚³ã‚¢ãŒä½ã„ã¨ã€ReadabilityãŒä½ã„ã¨åˆ¤æ–­ã§ãã‚‹ã€‚<br><br>è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã«æ§˜ã€…ãªæ­£è¦åŒ–ã‚’æ–½ã™ã“ã¨ã§ã€acceptabilityã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-02-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/257" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks, Tai+, ACL'15</a>
<span class="snippet"><span>Comment</span><p>Tree-LSTMè«–æ–‡</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/145" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Re-evaluating Automatic Summarization with BLEU and 192 Shades of ROUGE, Yvette Graham, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>æ–‡æ›¸è¦ç´„ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹Metricã€ç‰¹ã«BLEUã‚„ROUGEã®çµæœï¼ˆå¯èƒ½ãªï¼‘ï¼™ï¼’ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰ã¨ã€äººæ‰‹ã®çµæœã¨ã®ç›¸é–¢ã‚’å†åˆ†æã—ã¦ã„ã‚‹ã€‚<br><br>ãã®çµæœã€BLEUãŒã‚‚ã£ã¨ã‚‚äººæ‰‹è©•ä¾¡ã¨ã®ç›¸é–¢ãŒé«˜ãã€ROUGE-2ã®Precisionã®å¹³å‡(ã‚¹ãƒ†ãƒŸãƒ³ã‚°ã€stop wordsé™¤å»)ãŒROUGEã®ä¸­ã§best-performingãªvariantã ã£ãŸã€‚<br><br><br><br>è¦ç´„ã®Metrcã®æœ€é©ãªæ¤œå®šæ–¹æ³•ã¨ã—ã¦ã€Williamsæ¤œå®šã‚’åˆ©ç”¨ã€‚<br><br>å†è©•ä¾¡ã®çµæœã€ä»¥å‰æ¨å¥¨ã•ã‚Œã¦ã„ãŸvariantã¨ã¯ç•°ãªã‚‹MetricsãŒè‰¯ã„çµæœã«ã€‚<br><br>best-performing ROUGE resultã‚’ç”¨ã„ã¦ã€æ—¢å­˜ã®state-of-the-artãªã‚·ã‚¹ãƒ†ãƒ ã‚’å†åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¥ã‘ã™ã‚‹ã¨ã€originalã®ã‚‚ã®ã¨ã¯çµæ§‹ç•°ãªã‚‹çµæœã«ãªã£ãŸã€‚<br><br><br><br>ï¼ˆä¸€éƒ¨ã®ã‚¹ã‚³ã‚¢ãŒè‰¯ã‹ã£ãŸã‚·ã‚¹ãƒ†ãƒ ã®ã‚¹ã‚³ã‚¢ãŒç›¸å¯¾çš„ã«ã‹ãªã‚Šæ‚ªåŒ–ã—ã¦ã„ã‚‹ï¼‰<br><br><img src="https://user-images.githubusercontent.com/12249301/34465383-d104a5be-eeed-11e7-9876-111d618ab9ee.png" alt="image" loading="lazy"><br><br><br><br>ã¾ãŸã€BLEUãŒäººæ‰‹è©•ä¾¡ã¨ã‚‚ã£ã¨ã‚‚é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ãŸãŒã€best-performingãªROUGE variantã¨ã¯çµ±è¨ˆçš„ãªæœ‰æ„å·®ã¯ãªã‹ã£ãŸã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/137" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Neural Attention Model for Sentence Summarization, Rush+, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š


<a href="https://www.slideshare.net/akihikowatanabe3110/a-neural-attention-model-for-sentence-summarization-65612331" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/a-neural-attention-model-for-sentence-summarization-65612331</a>


</p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/75" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LCSTS: A large scale chinese short text summarizatino dataset, Hu+, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>Large Chinese Short Text Summarization (LCSTS) datasetã‚’ä½œæˆ<br><br><br><br>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹éš›ã¯ã€Weiboä¸Šã®ç‰¹å®šã®organizationã®æŠ•ç¨¿ã®ç‰¹å¾´ã‚’åˆ©ç”¨ã€‚<br><br>Weiboã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æŠ•ç¨¿ã™ã‚‹éš›ã«ã€æŠ•ç¨¿ã®å†’é ­ã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®very short summaryãŒã¾ãšè¨˜è¼‰ã•ã‚Œã€ãã®å¾Œãƒ‹ãƒ¥ãƒ¼ã‚¹æœ¬æ–‡ï¼ˆçŸ­ã‚ï¼‰ãŒè¨˜è¼‰ã•ã‚Œã‚‹ç‰¹å¾´ãŒã‚ã‚‹ã®ã§ã€ã“ã®å¯¾ã‚’source-referenceå¯¾ã¨ã—ã¦åé›†ã—ãŸã€‚<br><br>åé›†ã™ã‚‹éš›ã«ã¯ã€ç´„ï¼‘ï¼ï¼å€‹ã®ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ããƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚„clearning, æŠ½å‡ºç­‰ã‚’è¡Œãªã£ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34411045-95f7baf2-ec17-11e7-94fb-faf2559d6994.png" alt="image" loading="lazy"><br><br><br><br>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®propertyã¨ã—ã¦ã¯ã€ä¸‹è¨˜ã®PartI, II, IIIã«åˆ†ã‹ã‚Œã¦ã„ã‚‹ã€‚<br><br><br><br>PartI: 2.4Mã®short text - summary pair<br><br>PartII: PartIã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸ10kã®pairã«å¯¾ã—ã¦ã€5 scaleã§è¦ç´„ã®relevanceã‚’ratingã—ãŸãƒ‡ãƒ¼ã‚¿ã€‚ãŸã ã—ã€å„pairã«ãƒ©ãƒ™ãƒ«ã¥ã‘ã‚’ã—ãŸevaluatorã¯1åã®ã¿ã€‚<br><br>PartIII: 2kã®pairã«å¯¾ã—ã¦ï¼ˆPartI, PartIIã¨ã¯ç‹¬ç«‹ï¼‰ã€3åã®evaluatorãŒ5-scaleã§ratingã€‚evaluatorã®ratingãŒä¸€è‡´ã—ãŸ1kã®pairã‚’æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34411199-8db4df90-ec18-11e7-8703-fd8f9512a903.png" alt="image" loading="lazy"><br><br><br><br>RNN-GRUã‚’ç”¨ã„ãŸSummarizerã‚‚ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34411224-b5543eba-ec18-11e7-8556-a3b42bfcf334.png" alt="image" loading="lazy"><br><br><br><br></p>
<p>CopyNetãªã©ã¯LCSTSã‚’ä½¿ã£ã¦è©•ä¾¡ã—ã¦ã„ã‚‹ã€‚ä»–ã«ã‚‚ä½¿ã£ã¦ã‚‹è«–æ–‡ã‚ã£ãŸã¯ãšã€‚</p>
<p>ACL'17ã®Pointer Generator Networkã§ã—ãŸã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/74" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A hierarchical neural autoencoder for paragraphs and documents, Li+, ACL'15</a>
<span class="snippet"><span>Comment</span><p>è¤‡æ•°æ–‡ã‚’ç”Ÿæˆ(ä»Šå›ã¯autoencoder)ã™ã‚‹ãŸã‚ã«ã€standardãªseq2seq LSTM modelã‚’ã€æ‹¡å¼µã—ãŸã¨ã„ã†è©±ã€‚<br><br><br><br>è¦ã¯ã€paragraph/documentã®representationãŒæ¬²ã—ã„ã®ã ãŒã€ã‚¢ã‚¤ãƒ‡ã‚¢ã¨ã—ã¦ã¯ã€word-levelã®æƒ…å ±ã‚’æ‰±ã†LSTM layerã¨sentenc-levelã®æƒ…å ±ã‚’æ‰±ã†LSTM layerã‚’ç”¨æ„ã—ã€ãã‚Œã‚‰ã®compositionã«ã‚ˆã£ã¦ã€paragraph/documentã‚’è¡¨ç¾ã—ã¾ã—ãŸã¨ã„ã†è©±ã€‚<br><br><br><br>sentence-levelã®attentionã‚’å…¥ã‚ŒãŸã‚‰ã‚ˆããªã£ã¦ã„ã‚‹ã€‚<br><br><br><br>trip advisorã®reviewã¨wikipediaã®paragraphã‚’ä½¿ã£ã¦trainingã—ã¦ã€ã©ã‚Œã ã‘æ–‡æ›¸ã‚’å†æ§‹ç¯‰ã§ãã‚‹ã‹å®Ÿé¨“ã€‚<br><br>Metricã¯ROUGE, BLEUãŠã‚ˆã³coherence(sentence orderä»£æ›¿)ã‚’æ¸¬ã‚‹ãŸã‚ã«ã€å„sentenceé–“ã®gapãŒinputã¨outputã§ã©ã‚Œã ã‘ä¸€è‡´ã—ã¦ã„ã‚‹ã‹ã§è©•ä¾¡ã€‚<br><br><br><br>hierarchical lstm with attention &gt; hierarchical lstm &gt; standard lstm ã®é †ç•ªã§é«˜æ€§èƒ½ã€‚<br><br><br><br>å­¦ç¿’ã«ã¯ã€tesla K40ã‚’ç©ã‚“ã ãƒã‚·ãƒ³ã§ã€standard modelãŒ2-3 weeks, hierarchical modelsãŒ4-6é€±é–“ã‹ã‹ã‚‹ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/SentimentAnalysis.html" target="_blank" rel="noopener noreferrer">#SentimentAnalysis</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/72" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Document Modeling with Gated Recurrent Neural Network for Sentiment Classification, Tang+, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>word level -&gt; sentence level -&gt; document level ã®representationã‚’æ±‚ã‚ã€documentã®sentiment classificationã‚’ã™ã‚‹è©±ã€‚<br><br>documentã®Representationã‚’ç”Ÿæˆã™ã‚‹ã¨ãã«å‚è€ƒã«ãªã‚‹ã‚„ã‚‚ã€‚<br><br>sentenceã®representationã‚’æ±‚ã‚ã‚‹ã¨ãã¯ã€CNN/LSTMã‚’ä½¿ã†ã€‚<br><br>document levelã«è½ã¨ã™ã“ã¨ã¯ã€bi-directionalãªGatedRNN(ã“ã®GatedRNNã¯LSTMã®output-gateãŒå¸¸ã«onã«ãªã£ã¦ã„ã‚‹ã‚ˆã†ãªã‚‚ã®ã‚’ä½¿ã†ã€‚sentenceã®semanticsã«é–¢ã™ã‚‹æƒ…å ±ã‚’è½ã¨ã—ãŸããªã„ã‹ã‚‰ã‚‰ã—ã„ã€‚)ã‚’ä½¿ã†ã€‚<br><br>sentiment classificationã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã—ã€(sentence levelã®representationã‚’æ±‚ã‚ã‚‹ã¨ãã¯)LSTMãŒæœ€ã‚‚æ€§èƒ½ãŒã‚ˆãã€documentã®representationã‚’æ±‚ã‚ã‚‹ã¨ãã¯ã€standardãªRNNã‚ˆã‚Šã‚‚GatedRNNã®ã»ã†ãŒæ€§èƒ½ã‚ˆã‹ã£ãŸã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/59" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Sentence Compression by Deletion with LSTMs, Fillipova+, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>slide:


<a href="https://www.slideshare.net/akihikowatanabe3110/sentence-compression-by-deletion-with-lstms" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/sentence-compression-by-deletion-with-lstms</a>


</p></span><br><br>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/5" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Extended Recommendation Framework: Generating the Text of a User Review as a Personalized Summary Poussevin+, CBRecsys'15, 2015.09</a>
<span class="snippet"><span>Comment</span><p>review generationã®çµæœã‚’rating predictionã«ä¼æ¬ã™ã‚‹ã“ã¨ã§æ€§èƒ½ã‚ˆãã—ã¾ã—ãŸã€ã¨ã„ã†è©±ã ã¨æ€ã†</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2861" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Sequence to Sequence Learning with Neural Networks, Ilya Sutskever+, NIPS'14</a>
<span class="snippet"><span>GPT Summary</span>- DNNã¯ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å­¦ç¿’ã«ãŠã„ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ãŒã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é–“ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã«ã¯é™ç•ŒãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LSTMã‚’ç”¨ã„ãŸã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€è‹±èªã‹ã‚‰ãƒ•ãƒ©ãƒ³ã‚¹èªã¸ã®ç¿»è¨³ã‚¿ã‚¹ã‚¯ã§34.8ã®BLEUã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚LSTMã¯é•·æ–‡ã«ã‚‚å¯¾å¿œã—ã€SMTã‚·ã‚¹ãƒ†ãƒ ã®å‡ºåŠ›ã‚’å†ãƒ©ãƒ³ã‚¯ä»˜ã‘ã™ã‚‹ã“ã¨ã§BLEUã‚¹ã‚³ã‚¢ã‚’36.5ã«å‘ä¸Šã•ã›ãŸã€‚ã¾ãŸã€å˜èªã®é †åºã‚’é€†ã«ã™ã‚‹ã“ã¨ã§æ€§èƒ½ãŒå‘ä¸Šã—ã€çŸ­æœŸçš„ä¾å­˜é–¢ä¿‚ã®æœ€é©åŒ–ãŒå®¹æ˜“ã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ã„ã¾ã•ã‚‰ãªãŒã‚‰Seq2Seqã‚’ææ¡ˆã—ãŸç ”ç©¶ã‚’è¿½åŠ </p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/review.html" target="_blank" rel="noopener noreferrer">#review</a>
<span class="issue_date">Issue Date: 2023-05-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/663" target="_blank" rel="noopener noreferrer" class="title-link">Empirical analysis of exploiting review helpfulness for extractive summarization of online reviews, Xiong+, COLING'14</a>
<span class="snippet"><span>Comment</span><p>ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®helpfulnessã‚’åˆ©ç”¨ã—ãŸunsupervisedãªreview summarizationæ‰‹æ³•ã‚’ææ¡ˆã€‚helpfulessã«ã‚ˆã‚Šãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã ã‘ã§ãªãã€ãƒˆãƒ”ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã§sentenceã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹éš›ã«helpfulnessã®æƒ…å ±ã‚‚æ´»ç”¨ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br><br><br>æœ€çµ‚çš„ã«ã¯ãƒ¦ãƒ¼ã‚¶ã‚¹ã‚¿ãƒ‡ã‚£ã§è©•ä¾¡ã€‚ãƒ¦ãƒ¼ã‚¶ãŒã‚«ãƒ¡ãƒ©ã‚’è³¼å…¥ã™ã‚‹ãŸã‚ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’èª­ã‚€ã‚·ãƒŠãƒªã‚ªã‚’æƒ³å®šã€‚ãƒ¦ãƒ¼ã‚¶ã«ã¾ãšã¯10 sentenceã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä½œæˆã—ã¦ã‚‚ã‚‰ã†ã€‚ãã®ä¸Šã§ã€3ã¤ã®è¦ç´„æ‰‹æ³•ã«ã‚ˆã‚‹è¦ç´„ã‚’æç¤ºã—ã€ã©ã‚ŒãŒã€Œã‚«ãƒ¡ãƒ©ã‚’è³¼å…¥ã™ã‚‹decision makingã«å½¹ç«‹ã£ãŸã‹ï¼Ÿã¾ãŸã¯informativeã ã£ãŸã‹ï¼Ÿã€ã§è©•ä¾¡ã—ã¦ã‚‚ã‚‰ã£ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/148" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Detecting information-dense texts in multiple news domains, Yang+, AAAI'14</a>
<span class="snippet"><span>Comment</span><p>ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ç¬¬ä¸€æ®µè½ç›®ãŒinformativeã‹å¦ã‹ï¼ˆé‡è¦ãªfactual informationãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã‹å¦ã‹ï¼‰ã‚’åˆ†é¡ã™ã‚‹ç ”ç©¶ã€‚<br><br>New York Times Annotated Corpusã«å¯¾ã—ã¦ã€è‡ªå‹•çš„ã«informative, non-informativeãªãƒ©ãƒ™ãƒ«ã¥ã‘ã‚’è¡Œã†æ‰‹æ³•ã‚’ææ¡ˆã—ã€åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’trainingã€‚<br><br><br><br>(informativeãªä¾‹)<br><br><img src="https://user-images.githubusercontent.com/12249301/34465457-02ec9624-eef1-11e7-88a5-3a265ddb7d64.png" alt="image" loading="lazy"><br><br><br><br>(non-informativeãªä¾‹)<br><br><img src="https://user-images.githubusercontent.com/12249301/34465460-123e4b04-eef1-11e7-82a3-56ede8802b43.png" alt="image" loading="lazy"><br><br><br><br>è©•ä¾¡ã®çµæœã€Accuracyã¯ã ã„ãŸã„0.8ã€œ0.85ãã‚‰ã„ã€‚<br><br><br><br>äººãŒ100ä»¶ä¸­ä½•ä»¶ã‚’informativeã¨åˆ¤æ–­ã—ãŸã‹ãŒä¸‹è¡¨ã€‚ä¸‹è¡¨ã‚’è¦‹ã‚‹ã¨ã€ãƒªãƒ¼ãƒ‰ã«ã‚‚non-informativeãªã‚‚ã®ãŒå¤šæ•°å­˜åœ¨ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br>ã¾ãŸã€ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã‚ˆã£ã¦å‚¾å‘ãŒç•°ãªã£ã¦ãŠã‚Šã€ãŸã¨ãˆã°ã‚¹ãƒãƒ¼ãƒ„ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã¯ã€entertaining mannerã§è¨˜è¿°ã•ã‚Œã‚‹ã®ã§factual informationãŒã‚ã¾ã‚Šè¨˜è¿°ã•ã‚Œãªã„å‚¾å‘ã«ã‚ã£ãŸã‚Šã€Scienceãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã¯ã€generalãªtopicã‚„issue, personal historyãªã©ãŒè¨˜è¿°ã•ã‚Œã‚‹å‚¾å‘ã«ã‚ã‚‹ã®ã§ã€ç›¸å¯¾çš„ã«informativeãªLeadãŒå°‘ãªã„ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/34465471-7e49402e-eef1-11e7-8d55-5a92d1335cc9.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Unsupervised.html" target="_blank" rel="noopener noreferrer">#Unsupervised</a>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/SIGIR.html" target="_blank" rel="noopener noreferrer">#SIGIR</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/144" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] CTSUM: Extracting More Certain Summaries for News Articles, Wan+, SIGIR'14</a>
<span class="snippet"><span>Comment</span><p>è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€æƒ…å ±ã®â€ç¢ºå®Ÿæ€§â€ã‚’è€ƒæ…®ã—ãŸãƒ¢ãƒ‡ãƒ«CTSUMã‚’ææ¡ˆã—ã¾ã—ãŸã¨ã„ã†è«–æ–‡ï¼ˆä»Šã¾ã§ã¯ãã†ã„ã†ç ”ç©¶ã¯ãªã‹ã£ãŸï¼‰<br><br><br><br>```<br><br>"However, it seems that Obama will not use the platform to relaunch his stalled drive for Israeli-Palestinian peace"<br><br>```<br><br>ã“ã†ã„ã†æ–‡ã¯ã€"It seems"ã¨ã‚ã‚‹ã‚ˆã†ã«ã€æƒ…å ±ã®ç¢ºå®Ÿæ€§ãŒä½ã„ã®ã§è¦ç´„ã«ã¯å…¥ã‚ŒãŸããªã„ã¨ã„ã†æ°—æŒã¡ã€‚<br><br><br><br>FactBankã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‘ã‚¹ã‹ã‚‰1000 sentenceã‚’æŠ½å‡ºã—ã€5-scaleã§sentenceã®ç¢ºå®Ÿæ€§ã‚’ãƒ©ãƒ™ãƒ«ã¥ã‘ã€‚<br><br>ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦SVRã‚’å­¦ç¿’ã—ã€sentenceã®ç¢ºå®Ÿæ€§ã‚’outputã™ã‚‹åˆ†é¡å™¨ã‚’æ§‹ç¯‰<br><br>affinity-propagationãƒ™ãƒ¼ã‚¹ï¼ˆtextrank, lexrankã®ã‚ˆã†ãªæ‰‹æ³•ï¼‰æ‰‹æ³•ã®affinityã®è¨ˆç®—ï¼ˆedgeé–“ã®é‡ã¿ã®ã“ã¨ã€‚æ™®é€šã¯sentenceåŒå£«ã®é¡ä¼¼åº¦ã¨ã‹ãŒä½¿ã‚ã‚Œã‚‹ï¼‰ã‚’è¡Œã†éš›ã«ã€æƒ…å ±ã®ç¢ºå®Ÿæ€§ã®ã‚¹ã‚³ã‚¢ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ãŸè¦ç´„ã‚’ç”Ÿæˆ<br><br><br><br>DUC2007ã®MDSãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€affinityè¨ˆç®—ã®éš›ã«ç¢ºå®Ÿæ€§ã‚’å°å…¥ã™ã‚‹éƒ¨åˆ†ã‚’ablationã—ãŸãƒ¢ãƒ‡ãƒ«ï¼ˆGRSUMï¼‰ã¨æ¯”è¼ƒã—ãŸã¨ã“ã‚ã€CTSUMã®ROUGEã‚¹ã‚³ã‚¢ãŒå‘ä¸Šã—ãŸã€‚<br><br>ã¾ãŸã€è‡ªå‹•ãƒ»äººæ‰‹è©•ä¾¡ã«ã‚ˆã‚Šã€ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã«å«ã¾ã‚Œã‚‹æƒ…å ±ã®ç¢ºå®Ÿæ€§ã‚’è©•ä¾¡ã—ãŸã¨ã“ã‚ã€GRSUMã‚’outperformã—ãŸ</p>
<p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š


<a href="https://www.slideshare.net/akihikowatanabe3110/ctsum-extracting-more-certain-summaries-for-news-articles" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/ctsum-extracting-more-certain-summaries-for-news-articles</a>


</p>
<p>SIGIRã§ã¯çã—ã„ã€è¦ç´„ã«é–¢ã™ã‚‹ç ”ç©¶<br><br>æƒ…å ±ã®ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã™ã‚‹ã¨ã„ã†ã€ã„ã¾ã¾ã§ã‚ã¾ã‚Šã‚„ã‚‰ã‚Œã¦ã„ãªã‹ã£ãŸéƒ¨åˆ†ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ãŸã®ã¯ãŠã‚‚ã—ã‚ã„<br><br>ã€Œã‚¢ã‚¤ãƒ‡ã‚¢ã¯ãŠã‚‚ã—ã‚ã„ã—è‰¯ã„ç ”ç©¶ã ãŒã€affinity weightãŒå¤‰åŒ–ã™ã‚‹ã¨ã„ã†ã“ã¨ã¯ã€è£ã‚’è¿”ã›ã°damping factorã‚’å¤‰æ›´ã—ã¦ã‚‚ãã†ã„ã†æ“ä½œã¯ã§ãã‚‹ã®ã§ã€certaintyã‚’è€ƒæ…®ã—ãŸã“ã¨ã«æ„å‘³ãŒã‚ã£ãŸã®ã‹ãŒå®Œå…¨ã«ç¤ºã›ã¦ã„ãªã„ã€‚ã€ã¨ã„ã†æ„è¦‹ãŒã‚ã‚Šã€ãªã‚‹ã»ã©ã¨æ€ã£ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/143" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning to Generate Coherent Sumamry with Discriminative Hidden Semi-Markov Model, Nishikawa+, COLING'14</a>
<span class="snippet"><span>Comment</span><p>Hidden-semi-markovãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå˜ä¸€æ–‡æ›¸è¦ç´„æ‰‹æ³•ã‚’ææ¡ˆã€‚<br><br><br><br>é€šå¸¸ã®HMMã§ã¯ä¸€ã¤ã®éš ã‚ŒçŠ¶æ…‹ã«ä¸€ã¤ã®unitï¼ˆè¦ç´„ã®æ–‡è„ˆã ã¨æ–‡ï¼Ÿï¼‰ãŒå¯¾å¿œã™ã‚‹ãŒã€hidden-semi-markov(HSMM)ãƒ¢ãƒ‡ãƒ«ã§ã¯è¤‡æ•°ã®unitã‚’å¯¾å¿œã¥ã‘ã‚‹ã“ã¨ãŒå¯èƒ½ã€‚<br><br>éš ã‚ŒçŠ¶æ…‹ã«å¯¾å¿œã™ã‚‹unitã‚’æ–‡ã ã¨è€ƒãˆã‚‹ã¨ã€ã‚ã‚‹æ–‡ã®è¤‡æ•°ã®äºœç¨®ã‚’è€ƒæ…®ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ãŸã‚ã€ãƒŠãƒƒãƒ—ã‚µãƒƒã‚¯åˆ¶ç´„ã‚’æº€ãŸã—ã¤ã¤æœ€é©ãªæ–‡ã®äºœç¨®ã‚’é¸æŠã™ã‚‹ã¨ã„ã£ãŸã“ã¨ãŒå¯èƒ½ã¨ãªã‚‹ã€‚<br><br>ã¨ã‹ã¾ã‚è‰²ã€…é›£ã—ã„ã“ã¨ãŒå‰åŠã®ç¯€ã«æ›¸ã„ã¦ã‚ã‚‹æ°—ãŒã™ã‚‹ãŒã€3.3ç¯€ã‚’è¦‹ã‚‹ã®ãŒã‚ã‹ã‚Šã‚„ã™ã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚<br><br><br><br>å®šå¼åŒ–ã‚’è¦‹ã‚‹ã¨ã€åŸºæœ¬çš„ãªãƒŠãƒƒãƒ—ã‚µãƒƒã‚¯å•é¡Œã«ã‚ˆã‚‹è¦ç´„ã®å®šå¼åŒ–ã«ã€Coherenceã‚’è¡¨ã™termã¨æ–‡ã®å¤‰ç¨®ã‚’è€ƒæ…®ã™ã‚‹ã‚ˆã†ãªå¤‰æ•°ãŒå°å…¥ã•ã‚Œã¦ã„ã‚‹ã ã‘ã§ã‚ã‚‹ã€‚<br><br>æ–‡ã®weightã‚„ã€coherenceã®weightã¯æ§‹é€ å­¦ç¿’ã§å­¦ç¿’ã—ã€Passive Aggressiveã‚’ç”¨ã„ã¦ã€loss functionã¨ã—ã¦ã¯ROUGEã‚’ç”¨ã„ã¦ã„ã‚‹ï¼ˆè¦ã¯ROUGEãŒé«˜ããªã‚‹ã‚ˆã†ã«ã€outputã®è¦ç´„å…¨ä½“ã‚’è€ƒæ…®ã—ãªãŒã‚‰ã€weightã‚’å­¦ç¿’ã™ã‚‹ã¨ã„ã†ã“ã¨ï¼‰ã€‚<br><br><br><br>æ–‡ã®å¤‰ç¨®ã¨ã—ã¦ã¯ã€å„æ–‡ã‚’æ–‡åœ§ç¸®ã—ãŸã‚‚ã®ã‚’ç”¨æ„ã—ã¦ã„ã‚‹ã€‚<br><br>ã¾ãŸã€å‹•çš„è¨ˆç”»æ³•ã«ã‚ˆã‚‹ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚‚ææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚<br><br><br><br>æ§‹é€ å­¦ç¿’ã‚’è¡Œã†éš›ã«ã¯å¤§é‡ã®æ•™å¸«ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã¨ãªã‚‹ãŒã€13,000è¨˜äº‹åˆ†ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã¨å¯¾å¿œã™ã‚‹äººæ‰‹ã§ã®è¦ç´„ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦å­¦ç¿’ã¨è©•ä¾¡ã‚’è¡Œãªã£ã¦ãŠã‚Šã€å½“æ™‚ã“ã‚Œã»ã©å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã§å®Ÿé¨“ã—ãŸç ”ç©¶ã¯ãªã‹ã£ãŸã€‚<br><br><br><br>ROUGEã§ã®è©•ä¾¡ã®çµæœã€æ–‡ã®å¤‰ç¨®ï¼ˆæ–‡åœ§ç¸®ï¼‰ã‚’è€ƒæ…®ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ãŸãŒã€LEADã¨ã¯çµ±è¨ˆçš„ã«ã¯æœ‰æ„å·®ãªã—ã€‚ã—ã‹ã—ãªãŒã‚‰ã€äººæ‰‹ã§ç”Ÿæˆã—ãŸè¦ç´„ã¨ã®å®Œå…¨ä¸€è‡´ç‡ãŒææ¡ˆæ‰‹æ³•ã®æ–¹ãŒé«˜ã„ã€‚<br><br>ã¾ãŸã€ROUGEã®è©•ä¾¡ã ã‘ã§ãªãã€linguistic qualityï¼ˆgrammaticality, structure/coherenceãªã©ï¼‰ã‚’äººæ‰‹ã§è©•ä¾¡ã—ãŸçµæœã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’æœ‰æ„ã«outperformã€‚LEADã¯grammaticalityã§ã‹ãªã‚Šæ‚ªã„è©•ä¾¡ã«ãªã£ã¦ã„ã¦ã€ã“ã‚Œã¯è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ã¨éƒ¨åˆ†æ–‡ãŒå…¥ã£ã¦ã—ã¾ã†ãŸã‚ã€‚<br><br>è¨“ç·´äº‹ä¾‹æ•°ã‚’å¤‰åŒ–ã•ã›ã¦ROUGEã‚¹ã‚³ã‚¢ã«é–¢ã™ã‚‹learning curveã‚’æã„ãŸçµæœã€è¨“ç·´äº‹ä¾‹ã®å¢—åŠ ã«å¯¾ã—ã¦ROUGEã‚¹ã‚³ã‚¢ã‚‚å˜èª¿å¢—åŠ ã—ã¦ãŠã‚Šã€ã¾ã ã‚µãƒã‚‹æ°—é…ã‚’è¦‹ã›ã¦ã„ãªã„ã®ã§ã€äº‹ä¾‹æ•°å¢—åŠ ã•ã›ãŸã‚‰ã¾ã æ€§èƒ½ã‚ˆããªã‚Šãã†ã¨ã„ã†ä¸»å¼µã‚‚ã—ã¦ã„ã‚‹ã€‚</p>
<p>è©•ä¾¡ã«ä½¿ç”¨ã—ãŸè¨˜äº‹ãŒå ±é“è¨˜äº‹ã ã£ãŸã¨ã™ã‚‹ãªã‚‰ã°ã€qualityçš„ã«ã¯Leadã«å‹ã£ã¦ãã†ãªé›°å›²æ°—ã‚’æ„Ÿã˜ã‚‹ã®ã§ã€çµæ§‹ã™ã”ã„æ°—ã¯ã™ã‚‹ï¼ˆå˜ä¸€æ–‡æ›¸è¦ç´„ã§å ±é“è¨˜äº‹ã«ãŠã„ã¦LEADã¯æœ€å¼·æ„Ÿã‚ã£ãŸã—ï¼‰ã€‚<br><br>ãŸã ã€è¦ç´„ã®è©•ä¾¡ã«ãŠã„ã¦informativenessã‚’è©•ä¾¡ã—ã¦ã„ãªã„ã®ã§ã€ROUGEã‚¹ã‚³ã‚¢çš„ã«ã¯Leadã¨comparableã§ã‚‚ã€å®Ÿéš›ã«ç”Ÿæˆã•ã‚Œã‚‹è¦ç´„ã®æƒ…å ±é‡ã¨ã—ã¦æœãŸã—ã¦LEADã«å‹ã£ã¦ã„ã‚‹ã®ã‹èˆˆå‘³ãŒã‚ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/108" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Comparing Multi-label Classification with Reinforcement Learning for Summarization of Time-series Data, Gkatzia+, ACL'14</a>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/58" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Hierarchical Summarization: Scaling Up Multi-Document Summarization, Christensen+, ACL'14</a>
<span class="snippet"><span>Comment</span><p>## æ¦‚è¦<br><br>ã ã„ã¶å‰ã«èª­ã‚“ã ã€‚å¥½ããªç ”ç©¶ã€‚<br><br>ãƒ†ã‚­ã‚¹ãƒˆã®sentenceã‚’éšå±¤çš„ã«ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€æŠ½è±¡åº¦ãŒé«˜ã„æƒ…å ±ã‹ã‚‰ã€é–¢é€£ã™ã‚‹å…·ä½“åº¦ã®é«˜ã„sentenceã«drill downã—ã¦ã„ã‘ã‚‹Interactiveãªè¦ç´„ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br><br><br>## æ‰‹æ³•<br><br>é€šå¸¸ã®MDSã§ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¦æ¨¡ã‚ˆã‚Šã‚‚ã€å®Ÿéš›ã«MDSã‚’ä½¿ã†éš›ã«ã¯ã•ã‚‰ã«å¤§ããªè¦æ¨¡ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã‚ãªã‘ã‚Œã°ãªã‚‰ãªã„ã“ã¨ã‚’æŒ‡æ‘˜ã—ï¼ˆãŸã¨ãˆã°New York Timesã§ç‰¹å®šã®ãƒ¯ãƒ¼ãƒ‰ã§ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ¤œç´¢ã™ã‚‹ã¨æ•°åƒã€æ•°ä¸‡ä»¶ã®è¨˜äº‹ãŒãƒ’ãƒƒãƒˆã—ãŸã‚Šã™ã‚‹ï¼‰ãã®ãŸã‚ã«å¿…è¦ãªäº‹é …ã‚’æ¤œè¨ã€‚<br><br>ã“ã‚Œã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€éšå±¤çš„ãªã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚<br><br>ææ¡ˆæ‰‹æ³•ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã®sentenceã‚’éšå±¤çš„ã«ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ã€ä¸‹ä½ã®å±¤ã«è¡Œãã»ã©ã‚ˆã‚Šå…·ä½“çš„ãªæƒ…å ±ã«ãªã‚‹ã‚ˆã†ã«sentenceã‚’è¡¨ç¾ã€‚ã•ã‚‰ã«ã€ä¸Šä½ã€ä¸‹ä½ã®sentenceé–“ã«ã¯ã‚¨ãƒƒã‚¸ãŒå¼µã‚‰ã‚Œã¦ãŠã‚Šã€ä¸‹ä½ã«ç´ä»˜ã‘ã‚‰ã‚ŒãŸsentence<br><br></p>
<p>ã¯ä¸Šä½ã«ç´ä»˜ã‘ã‚‰ã‚ŒãŸsentenceã®æƒ…å ±ã‚’ã‚ˆã‚Šå…·ä½“çš„ã«è¿°ã¹ãŸã‚‚ã®ã¨ãªã£ã¦ã„ã‚‹ã€‚<br><br>ã“ã‚Œã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€drill downå‹ã®Interactiveãªè¦ç´„ã‚’å®Ÿç¾ã€‚</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/QueryBiased.html" target="_blank" rel="noopener noreferrer">#QueryBiased</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/57" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Query-Chain Focused Summarization, Baumel+, ACL'14</a>
<span class="snippet"><span>Comment</span><p>ï¼ˆç®¡ç†äººãŒä½œæˆã—ãŸéå»ã®ç´¹ä»‹è³‡æ–™ï¼‰<br>[Query-Chain Focused Summarization.pdf](https://github.com/AkihikoWatanabe/paper_notes/files/1590916/Query-Chain.Focused.Summarization.pdf)<br><br></p>
<p>ä¸Šè¨˜ã‚¹ãƒ©ã‚¤ãƒ‰ã¯ç§ãŒå½“æ™‚ä½œæˆã—ãŸè«–æ–‡ç´¹ä»‹ã‚¹ãƒ©ã‚¤ãƒ‰ã§ã™ã€‚ã‚¹ãƒ©ã‚¤ãƒ‰ä¸­ã®ã‚¹ã‚¯ã‚·ãƒ§ã¯èª¬æ˜ã®ãŸã‚ã«è«–æ–‡ä¸­ã®ã‚‚ã®ã‚’å¼•ç”¨ã—ã¦ã„ã¾ã™ã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1016" target="_blank" rel="noopener noreferrer" class="title-link">Automatically Assessing Machine Summary Content Without a Gold Standard, Louis+ï¼ˆw_ Nenkovaï¼‰, ACL'13</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¦ç´„ã®è©•ä¾¡ã«ãŠã„ã¦æ–°ã—ã„æŠ€è¡“ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€äººé–“ã®è¦ç´„ãŒåˆ©ç”¨ã§ããªã„å ´åˆã‚„ã€å˜ä¸€ã®ãƒ¢ãƒ‡ãƒ«ã—ã‹åˆ©ç”¨ã§ããªã„å ´åˆã§ã‚‚æ­£ç¢ºãªè©•ä¾¡ãŒå¯èƒ½ã¨ãªã‚Šã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ãƒ¢ãƒ‡ãƒ«ã«ä¾å­˜ã—ãªã„è©•ä¾¡æŠ€è¡“ã‚„ã€ã‚·ã‚¹ãƒ†ãƒ è¦ç´„ã®é¡ä¼¼æ€§ã‚’å®šé‡åŒ–ã™ã‚‹å°ºåº¦ãªã©ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¦ç´„ã®è©•ä¾¡ã‚’äººé–“ã®è©•ä¾¡ã¨æ­£ç¢ºã«å†ç¾ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã¾ãŸã€æ“¬ä¼¼ãƒ¢ãƒ‡ãƒ«ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®ã¿ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã‚ˆã‚Šã‚‚äººé–“ã®åˆ¤æ–­ã¨ã®ç›¸é–¢ãŒé«˜ããªã‚‹ã“ã¨ã‚‚ç¤ºã—ã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€ã‚·ã‚¹ãƒ†ãƒ è¦ç´„ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ–¹æ³•ã«ã¤ã„ã¦ã‚‚æ¢æ±‚ã—ã¦ãŠã‚Šã€é©šãã»ã©æ­£ç¢ºãªãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒå¯èƒ½ã¨ãªã‚Šã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ¡ã‚¿è©•ä¾¡ã®å…·ä½“çš„ãªæ‰‹é †ã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã‘ã‚Œã°ã“ã®ç ”ç©¶ã‚’èª­ã‚€ã¹ã—</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coherence.html" target="_blank" rel="noopener noreferrer">#Coherence</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/970" target="_blank" rel="noopener noreferrer" class="title-link">Graph-based Local Coherence Modeling, Guinaudeau+, ACL'13</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€æ–‡ã®é †åºä»˜ã‘ã€è¦ç´„ã®çµæŸæ€§è©•ä¾¡ã€èª­ã¿ã‚„ã™ã•ã®è©•ä¾¡ã®3ã¤ã®ã‚¿ã‚¹ã‚¯ã§ã‚·ã‚¹ãƒ†ãƒ ã‚’è©•ä¾¡ã—ã¾ã—ãŸã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚°ãƒªãƒƒãƒ‰ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨åŒç­‰ã®æ€§èƒ½ã‚’æŒã¡ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã®é«˜ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ã‚§ãƒ¼ã‚ºã‚„ãƒ‡ãƒ¼ã‚¿ã®ã¾ã°ã‚‰ã•ã®å•é¡Œã«ã‚‚å¯¾å‡¦ã§ãã¾ã™ã€‚</span>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/237" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Mathematics of Statistical Machine Translation: Parameter Estimation, Brown+, CL'13</a>
<span class="snippet"><span>Comment</span><p>IBMãƒ¢ãƒ‡ãƒ«è«–æ–‡ã€‚</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/99" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Inducing document plans for concept-to-text generation, Konstas+, EMNLP'13</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/CrossLingual.html" target="_blank" rel="noopener noreferrer">#CrossLingual</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/979" target="_blank" rel="noopener noreferrer" class="title-link">Evaluating the Efficacy of Summarization Evaluation across Languages, Koto+ ï¼ˆw_ Timå…ˆç”Ÿï¼‰, Findings of ACL'12</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®ç ”ç©¶ã§ã¯ã€ç•°ãªã‚‹è¨€èªã®è¦ç´„ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã€ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«BERTã‚’ç”¨ã„ãŸBERTScoreãŒä»–ã®è¦ç´„è©•ä¾¡ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚¹ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã“ã‚Œã¯ã€è‹±èªä»¥å¤–ã®è¨€èªã«ãŠã„ã¦ã‚‚æœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coherence.html" target="_blank" rel="noopener noreferrer">#Coherence</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/968" target="_blank" rel="noopener noreferrer" class="title-link">Extending Machine Translation Evaluation Metrics with Lexical Cohesion to Document Level, Wong+, EMNLP'12</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€èªå½™çš„ãªçµæŸã‚’åˆ©ç”¨ã—ã¦æ–‡æ›¸ãƒ¬ãƒ™ãƒ«ã®æ©Ÿæ¢°ç¿»è¨³ã®è©•ä¾¡ã‚’å®¹æ˜“ã«ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚èªå½™çš„ãªçµæŸã¯ã€åŒã˜æ„å‘³ã‚’æŒã¤å˜èªã‚’ä½¿ã£ã¦æ–‡ã‚’çµã³ã¤ã‘ã‚‹ã“ã¨ã§ã€ãƒ†ã‚­ã‚¹ãƒˆã®çµæŸæ€§ã‚’å®Ÿç¾ã—ã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ã“ã®ç‰¹å¾´ã‚’è©•ä¾¡å°ºåº¦ã«çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€äººé–“ã®åˆ¤æ–­ã¨ã®ç›¸é–¢ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>RC-LC</p></span><br><br>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2023-05-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/650" target="_blank" rel="noopener noreferrer" class="title-link">Context-enhanced personalized social summarization, Po+, COLING'12, 18</a>
<span class="snippet"><span>Comment</span><p>ã–ã£ãã‚Šè¨€ã†ã¨ã€ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ã‚¿ã‚®ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ uã¨é¡ä¼¼ã—ãŸãƒ¦ãƒ¼ã‚¶ã®ã‚¿ã‚°ä»˜ã‘æƒ…å ±ã¨ã€åŸæ–‡æ›¸d _ã¨åŒã˜ãƒˆãƒ”ãƒƒã‚¯ã«å±ã™ã‚‹æ–‡æ›¸ã‚’ãã‚Œãã‚Œè€ƒæ…®ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€ãƒ¦ãƒ¼ã‚¶ã®interestã«é–¢ã™ã‚‹æƒ…å ±ï¼ˆã¨åŸæ–‡æ›¸ã®informativenessã«é–¢ã™ã‚‹æƒ…å ±ï¼‰ã‚’æ‹¡å¼µã—ã€ã“ã‚Œã‚‰ã®æƒ…å ±ã‚’æ´»ç”¨ã—ã¦ã€å…¨ã¦ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸­ã§é‡è¦æ–‡ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã—ãŸä¸Šã§ã€å¯¾è±¡æ–‡æ›¸ã«å¯¾ã™ã‚‹sentenceã®ã¿ã‚’å†—é•·æ€§ãŒãªã„ã‚ˆã†ã«æŠ½å‡ºã™ã‚‹ã“ã¨ã§ã€Personalized_ Summarizationã—ã¾ã—ã‚‡ã†ã€ã¨ã„ã†è©±</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/128" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Survey of Text Summarization Techniques, Nenkova+, Springer'12</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/97" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unsupervised concept-to-text generation with hypergraphs, Konstas+, NAACL-HLT'12</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/15" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Personalized Text Summarization using NMF and Cluster Refinement, Park+, ICTC'11, 2011.09</a>
<span class="snippet"><span>Comment</span><p><img src="https://user-images.githubusercontent.com/12249301/34402356-5275f894-ebe4-11e7-93d7-2a3781a74b94.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/InteractivePersonalizedSummarization.html" target="_blank" rel="noopener noreferrer">#InteractivePersonalizedSummarization</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Summarize What You Are Interested In: An Optimization Framework for Interactive Personalized Summarization, Yan+, EMNLP'11, 2011.07</a>
<span class="snippet"><span>Comment</span><p><img src="https://user-images.githubusercontent.com/12249301/34400733-97c86614-ebd7-11e7-9fe9-a6b36c726a21.png" alt="image" loading="lazy"><br><br><br><br>ãƒ¦ãƒ¼ã‚¶ã¨ã‚·ã‚¹ãƒ†ãƒ ãŒã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã—ãªãŒã‚‰å€‹äººå‘ã‘ã®è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã€InteractivePersonalizedSummarizationã‚’ææ¡ˆã€‚<br><br><br><br>ãƒ¦ãƒ¼ã‚¶ã¯ãƒ†ã‚­ã‚¹ãƒˆä¸­ã®sentenceã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã“ã¨ã§ã€ã‚·ã‚¹ãƒ†ãƒ ã«çŸ¥ã‚ŠãŸã„æƒ…å ±ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã“ã®ã¨ãã€ãƒ¦ãƒ¼ã‚¶ãŒsentenceã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹é‡ã¯ãŸã‹ãŒã—ã‚Œã¦ã„ã‚‹ã®ã§ã€click smoothingã¨å‘¼ã°ã‚Œã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã€sparseã«ãªã‚‰ãªã„ã‚ˆã†ã«ã—ã¦ã„ã‚‹ã€‚click smoothingã¯ã€ãƒ¦ãƒ¼ã‚¶ãŒã‚¯ãƒªãƒƒã‚¯ã—ãŸsentenceã«å«ã¾ã‚Œã‚‹å˜èªï¼Ÿç­‰ã‚’å«ã‚€åˆ¥ã®sentenceç­‰ã‚‚æ“¬ä¼¼çš„ã«clickã•ã‚ŒãŸã¨ã¿ãªã™æ‰‹æ³•ã€‚<br><br><br><br>4ã¤ã®ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆInfluenza A, BP Oil Spill, Haiti Earthquake, Jackson Deathï¼‰ã«é–¢ã™ã‚‹ã€æ•°åƒè¨˜äº‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’åé›†ã—ï¼ˆ10kã€œ100kç¨‹åº¦ã®sentenceï¼‰ã€è©•ä¾¡ã«æ´»ç”¨ã€‚åé›†ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µã‚¤ãƒˆï¼ˆBBC, Fox News, Xinhua, MSNBC, CNN, Guardian, ABC, NEwYorkTimes, Reuters, Washington Postï¼‰ã«ã¯ã€å„ã‚¤ãƒ™ãƒ³ãƒˆã«å¯¾ã™ã‚‹äººæ‰‹ã§ä½œæˆã•ã‚ŒãŸReference SummaryãŒã‚ã‚‹ã®ã§ãã‚Œã‚’æ´»ç”¨ã€‚<br><br>objectiveãªè©•ä¾¡ã¨ã—ã¦ROUGEã€subjectiveãªè©•ä¾¡ã¨ã—ã¦3äººã®evaluatorã«5scaleã§è¦ç´„ã®è‰¯ã•ã‚’è©•ä¾¡ã—ã¦ã‚‚ã‚‰ã£ãŸã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34400727-8c8ab022-ebd7-11e7-85df-c238fd2255de.png" alt="image" loading="lazy"><br><br><br><br>çµè«–ã¨ã—ã¦ã¯ã€ROUGEã¯GenericãªMDSãƒ¢ãƒ‡ãƒ«ã«å‹ã¦ãªã„ãŒã€subjectiveãªè©•ä¾¡ã«ãŠã„ã¦ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹çµæœã«ã€‚Referenceã¯Genericã«ç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ã“ã®çµæœã‚’å—ã‘ã¦Personalizationã®å¿…è¦æ€§ã‚’èª¬ã„ã¦ã„ã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/34400721-82d1bb8e-ebd7-11e7-83d2-697ac61eb38a.png" alt="image" loading="lazy"><br><br><br><br>ã¾ãŸã€ææ¡ˆæ‰‹æ³•ã®ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€Genericãªãƒ¢ãƒ‡ãƒ«ã®å½±éŸ¿ã‚’å¼·ãã™ã‚‹ï¼ˆPersonalizedãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å°ã•ãã™ã‚‹ï¼‰ã¨ã€ãƒ¦ãƒ¼ã‚¶ã¯ã‚·ã‚¹ãƒ†ãƒ ã¨ã‚ã¾ã‚Šã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã›ãšã«çµ‚ã‚ã£ã¦ã—ã¾ã†ã®ã«å¯¾ã—ã€Personalizedãªè¦ç´ ã‚’å¼·ãã™ã‚‹ã¨ã€ã‚ˆã‚ŠãŸãã•ã‚“ã‚¯ãƒªãƒƒã‚¯ã‚’ã—ã€çµæœçš„ã«ã‚·ã‚¹ãƒ†ãƒ ãŒã‚ˆã‚Šå¤šãè¦ç´„ã‚’ç”Ÿæˆã—ãªãŠã™ã¨ã„ã†çµæœã‚‚ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34400718-7b9a4912-ebd7-11e7-83cf-aba826a41d34.png" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Interspeech.html" target="_blank" rel="noopener noreferrer">#Interspeech</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2862" target="_blank" rel="noopener noreferrer" class="title-link">Recurrent neural network based language model, Mikolov+, Interspeech'10</a>
<span class="snippet"><span>Comment</span><p>RNNè¨€èªãƒ¢ãƒ‡ãƒ«è«–æ–‡</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/QA-based.html" target="_blank" rel="noopener noreferrer">#QA-based</a>
<span class="issue_date">Issue Date: 2023-08-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1006" target="_blank" rel="noopener noreferrer" class="title-link">Discourse constraints for document compression, Clarke+ ï¼ˆw_ Lapataï¼‰, Computational Linguistics'10</a>
<span class="snippet"><span>Comment</span><p>QAãƒ™ãƒ¼ã‚¹ãƒ‰ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’äººæ‰‹è©•ä¾¡ã«å°å…¥ã—ãŸåˆã‚ã¦ã®ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/RuleBased.html" target="_blank" rel="noopener noreferrer">#RuleBased</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/106" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generating approximate geographic descriptions, Turner+, ENLG'10</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/96" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generative alignment and semantic parsing for learning from ambiguous supervision, Kim+, COLING'10</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/95" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A simple domain-independent probabilistic approach to generation, Angeli+, EMNLP'10</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/94" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Training a multilingual sportscaster: Using perceptual context to learn language, Chen+, Artificial Intelligence Research'10</a>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/26" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Personalized Multi-Document Summarization using N-Gram Topic Model Fusion, Hennig+, SPIM'10, 2010.05</a>
<span class="snippet"><span>Comment</span><p>ãƒ»unigramã®å…±èµ·ã ã‘ã§ãªãï¼Œbigramã®å…±èµ·ã‚‚è€ƒæ…®ã—ãŸPLSIãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ï¼Œjointã§å­¦ç¿’ï¼ä¸ãˆã‚‰ã‚ŒãŸã‚¯ã‚¨ãƒªã‚„narrativeãªã©ã¨sentenceã®é¡ä¼¼åº¦ï¼ˆlatent spaceã§è¨ˆç®—ï¼‰ã‚’è¨ˆç®—ã—é‡è¦æ–‡ã‚’æ±ºå®šã€‚<br><br>ãƒ»user-modelã‚’ä½¿ã£ãŸPersonalizationã¯ã—ã¦ã„ãªã„ï¼</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/IJCNLP.html" target="_blank" rel="noopener noreferrer">#IJCNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/113" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning semantic correspondences with less supervision, Liang+, ACL-IJCNLP'09</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/111" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Verbalizing time-series data: with an example of stock price trends, Kobayashi+, IFSA-EUSFLAT'09</a>
<span class="snippet"><span>Comment</span><p>å°æ—å…ˆç”Ÿã®è«–æ–‡<br><br><br><br>Least Square Methodã«ã‚ˆã£ã¦æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã«fittingã™ã‚‹curveã‚’æ±‚ã‚ã‚‹ã€‚<br><br>curveã®ç‰¹å¾´ã‹ã‚‰ã€ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®trendsã‚’æ±ºå®šã™ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34462004-1eddd6be-ee7d-11e7-8c1b-c61dca30dbe5.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Incremental Personalised Summarisation with Novelty Detection, Campana+, FQAS'09, 2009.10</a>
<span class="snippet"><span>Comment</span><p>


<a href="https://link.springer.com/content/pdf/10.1007/978-3-642-04957-6_55.pdf" target="_blank" rel="noopener noreferrer">https://link.springer.com/content/pdf/10.1007/978-3-642-04957-6_55.pdf</a>


</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/955" target="_blank" rel="noopener noreferrer" class="title-link">ROUGE-C: A fully automated evaluation method for multi-document summarization, He+, International Conference on Granular Computing'08</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€ROUGEã‚’ä½¿ç”¨ã—ã¦è¦ç´„ã‚’è©•ä¾¡ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚ROUGEã¯ã€è¦ç´„è©•ä¾¡ã®ãŸã‚ã«åºƒãä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ãŒã€æ‰‹å‹•ã®å‚ç…§è¦ç´„ãŒå¿…è¦ã§ã™ã€‚ã“ã®ç ”ç©¶ã§ã¯ã€ROUGE-Cã¨ã„ã†æ‰‹æ³•ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚ROUGE-Cã¯ã€å‚ç…§è¦ç´„ã‚’å…¥åŠ›æƒ…å ±ã«ç½®ãæ›ãˆã‚‹ã“ã¨ã§ã€æ‰‹å‹•ã®å‚ç…§è¦ç´„ãªã—ã§è¦ç´„ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚å®Ÿé¨“çµæœã¯ã€ROUGE-CãŒäººé–“ã®åˆ¤æ–­ã‚’å«ã‚€å‚ç…§è¦ç´„ã¨ã‚ˆãç›¸é–¢ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultitaskLearning.html" target="_blank" rel="noopener noreferrer">#MultitaskLearning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-02-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/250" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A unified architecture for natural language processing: Deep neural networks with multitask learning, Collobert+, ICML'08</a>
<span class="snippet"><span>Comment</span><p>Deep Neural Netã‚’ç”¨ã„ã¦multitask learningã‚’è¡Œã„NLPã‚¿ã‚¹ã‚¯ï¼ˆPOS tagging, Semantic Role Labeling, Chunking etc.ï¼‰ã‚’è§£ã„ãŸè«–æ–‡ã€‚<br><br>è¢«å¼•ç”¨æ•°2000ã‚’è¶…ãˆã‚‹ã€‚<br><br><br><br>multitask learningã®å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ãªã©ãŒå¼•ç”¨ã•ã‚ŒãªãŒã‚‰ä»–è«–æ–‡ã§è¨€åŠã•ã‚Œã¦ã„ãŸã‚Šã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/114" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A generative model for parsing natural language to meaning representations, Lu+, EMNLP'08</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/93" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning to sportscast: a test of grounded language acquisition, Chen+, ICML'08</a>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/24" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Personalized PageRank based Multi-document summarization, Liu+, WSCS'08, 2008.07</a>
<span class="snippet"><span>Comment</span><p>ãƒ»ã‚¯ã‚¨ãƒªãŒã‚ã‚‹ã®ãŒå‰æ<br><br>ãƒ»åŸºæœ¬çš„ã«Personalized PageRankã®äº‹å‰åˆ†å¸ƒã‚’æ±‚ã‚ã¦ï¼ŒPageRankã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é©ç”¨ã™ã‚‹<br><br>ãƒ»æ–‡ã®salienceã‚’æ±‚ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ã¨ï¼ˆãƒ‘ãƒ©ã‚°ãƒ©ãƒ•ï¼Œãƒ‘ãƒ©ã‚°ãƒ©ãƒ•å†…ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ï¼Œstatementãªã®ã‹dialogãªã®ã‹ï¼Œæ–‡ã®é•·ã•ï¼‰ï¼Œã‚¯ã‚¨ãƒªã¨ã®é–¢é€£æ€§ã‚’ã¯ã‹ã‚‹relevance modelï¼ˆã‚¯ã‚¨ãƒªã¨ã‚¯ã‚¨ãƒªã®narrativeã«å«ã¾ã‚Œã‚‹å›ºæœ‰è¡¨ç¾ãŒæ–‡å†…ã«ã©ã‚Œã ã‘å«ã¾ã‚Œã¦ã„ã‚‹ã‹ï¼‰ã‚’ç”¨ã„ã¦ï¼ŒPersonalized PageRankã®äº‹å‰åˆ†å¸ƒã‚’æ±ºå®šã™ã‚‹<br><br>ãƒ»è©•ä¾¡ã—ãŸçµæœï¼ŒDUC2007ã®top1ã¨top2ã®ã‚·ã‚¹ãƒ†ãƒ ã®é–“ã®ROUGEã‚¹ã‚³ã‚¢ã‚’ç²å¾—</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/23" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Personalized Multi-document Summarization in Information Retrieval, Yang+, Machine Learning and Cybernetics'08, 2008.07</a>
<span class="snippet"><span>Comment</span><p>ãƒ»æ¤œç´¢çµæœã«å«ã¾ã‚Œã‚‹ãƒšãƒ¼ã‚¸ã®multi-document summarizationã‚’è¡Œã†ï¼ã‚¯ã‚¨ãƒªã¨sentenceã®å˜èªã®overlap, sentenceã®é‡è¦åº¦ã‚’<br><br>ã€€Affinity-Graphã‹ã‚‰æ±‚ã‚ï¼Œä¸¡è€…ã‚’çµåˆã—ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼MMR <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/243" target="_blank" rel="noopener noreferrer">[Paper Note] The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries, Carbonell+, SIGIR'98</a>
 likeãªæ‰‹æ³•ã§å†—é•·æ€§ã‚’æ’é™¤ã—è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ï¼<br><br>ãƒ»4äººã®ãƒ¦ãƒ¼ã‚¶ã«ï¼Œå®Ÿéš›ã«ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ã£ã¦ã‚‚ã‚‰ã„ï¼Œ5-scaleã§è¦ç´„ã®è‰¯ã•ã‚’è©•ä¾¡ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãªã—ï¼‰ï¼relevance, importance, ã€€<br><br>ã€€usefulness, complement of summaryã®è¦–ç‚¹ã‹ã‚‰ãã‚Œãã‚Œã‚’5-scaleã§ratingï¼ãã‚Œãã‚Œã®ãƒ¦ãƒ¼ã‚¶ã¯ï¼Œå„ãƒˆãƒ”ãƒƒã‚¯ã”ã¨ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«<br><br>ã€€å…¨ã¦ç›®ã‚’é€šã—ã¦ã‚‚ã‚‰ã„ï¼Œãã®å¾Œã«è¦ç´„ã‚’èª­ã¾ã›ã‚‹ï¼</p></span><br><br>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/16" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Automatic Personalized Summarization using Non-negative Matrix Factorization and Relevance Measure, Park+, IWSCA'08, 2008.07</a>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/15" target="_blank" rel="noopener noreferrer">[Paper Note] Personalized Text Summarization using NMF and Cluster Refinement, Park+, ICTC'11, 2011.09</a>
 ã¨åŒæ§˜</p></span><br><br>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/PRICAI.html" target="_blank" rel="noopener noreferrer">#PRICAI</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/14" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Personalized Summarization Agent Using Non-negative Matrix Factorization, Sun Park, PRICAI'08, 2008.12</a>
<span class="snippet"><span>Comment</span><p><img src="https://user-images.githubusercontent.com/12249301/34402291-fb66cb96-ebe3-11e7-9635-790be0cf8b5d.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/6" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Aspect-Based Personalized Text Summarization, Berkovsky+ï¼ˆTimå…ˆç”Ÿã®ã‚°ãƒ«ãƒ¼ãƒ—ï¼‰, AH'2008, 2008.07</a>
<span class="snippet"><span>Comment</span><p><img src="https://user-images.githubusercontent.com/12249301/34401031-b72623e0-ebda-11e7-9da2-6ce16b630f47.png" alt="image" loading="lazy"><br><br><br><br>Aspect-basedãªPDSã«é–¢ã—ã¦èª¿æŸ»ã—ãŸç ”ç©¶ã€‚<br><br>ãŸã¨ãˆã°ã€Wikipediaã®ã‚¯ã‚¸ãƒ©ã«é–¢ã™ã‚‹ãƒšãƒ¼ã‚¸ã§ã¯ã€biological taxonomy, physical dimensions, popular cultureã®ã‚ˆã†ã«ã€æ§˜ã€…ãªã‚¢ã‚¹ãƒšã‚¯ãƒˆã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¢ãƒ‡ãƒ«ã¯å„ã‚¢ã‚¹ãƒšã‚¯ãƒˆã«å¯¾ã™ã‚‹å—œå¥½ã®åº¦åˆã„ã§è¡¨ã•ã‚Œã€ãã‚Œã«å¾“ã„ç”Ÿæˆã•ã‚Œã‚‹è¦ç´„ã«å«ã¾ã‚Œã‚‹å„ç¨®ã‚¢ã‚¹ãƒšã‚¯ãƒˆã«é–¢ã™ã‚‹æƒ…å ±ã®é‡ãŒå¤‰åŒ–ã™ã‚‹ã€‚<br><br><br><br>UserStudyã®çµæœã€ã‚¢ã‚¹ãƒšã‚¯ãƒˆãƒ™ãƒ¼ã‚¹ãªãƒ¦ãƒ¼ã‚¶ãƒ¢ãƒ‡ãƒ«ã¨ã‚ˆã‚Šfitã—ãŸã€æ“¬ä¼¼çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã®æ–¹ãŒã€ãƒ¦ãƒ¼ã‚¶ã®è¦ç´„ã«å¯¾ã™ã‚‹ratingãŒä¸Šæ˜‡ã—ã¦ã„ãã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br><br><br>ã¾ãŸã€è¦ç´„ã®åœ§ç¸®ç‡ã«å¿œã˜ã¦ã€ãƒ¦ãƒ¼ã‚¶ã®ratingãŒå¤‰åŒ–ã—ã€originalã®é•·ã•ï¼é•·ã‚ã®è¦ç´„ï¼çŸ­ã„è¦ç´„ã®é †ã«ratingãŒæœ‰æ„ã«é«˜ã‹ã£ãŸã€‚è¦ç´„ãŒé•·ã™ãã¦ã‚‚ã€ã‚ã‚‹ã„ã¯çŸ­ã™ãã¦ã‚‚ã‚ã¾ã‚Šè‰¯ã„è©•ä¾¡ã¯å¾—ã‚‰ã‚Œãªã„ï¼ˆã—ã‹ã—ãªãŒã‚‰ã€é•·ã™ãã‚‹è¦ç´„ã¯å®Ÿã¯ãã“ã¾ã§å«Œã„ã§ã¯ãªã„ã“ã¨ã‚’ratingã¯ç¤ºå”†ã—ã¦ã„ã‚‹ï¼‰ã€‚<br><br><br><br>Genericãªè¦ç´„ã¨Personalizedãªè¦ç´„ã®faitufulnessã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ã¦ã‚‚ã‚‰ã£ãŸçµæœã€Genericãªè¦ç´„ã®æ–¹ãŒè‹¥å¹²é«˜ã„ã‚¹ã‚³ã‚¢ã«ã€‚ã—ã‹ã—ãªãŒã‚‰æœ‰æ„å·®ã¯ãªã„ã€‚å®Ÿéš›ã€å¹³å‡ã—ã¦83%ã®sentenceã¯Genericã¨Personalizedã§overlapã—ã¦ã„ã‚‹ã€‚faitufulnessã®è¦³ç‚¹ã‹ã‚‰ã€Genericã¨Personalizedãªè¦ç´„ã®é–“ã«æœ‰æ„å·®ã¯ãªã„ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br><br><br>museumç­‰ã§å¿œç”¨ã™ã‚‹ã“ã¨ã‚’æ¤œè¨</p></span><br><br>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/WI.html" target="_blank" rel="noopener noreferrer">#WI</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generating Personalized Summaries Using Publicly Available Web Documents, Kumar+, WI-IAT'08, 2008.12</a>
<span class="snippet"><span>Comment</span><p>è©•ä¾¡<br>5äººã®ç ”ç©¶è€…ã«ã‚ˆã‚‹äººæ‰‹è©•ä¾¡ã€‚<br>25ç¨®é¡ã®ç•°ãªã‚‹ãƒˆãƒ”ãƒƒã‚¯ãŒé¸æŠã•ã‚Œã€å„ãƒˆãƒ”ãƒƒã‚¯ã«ã¯5-10ã®è¨˜äº‹ãŒç´ã¥ã„ã¦ã„ã‚‹ã€‚<br>generic,personalizedãªè¦ç´„ã‚’æç¤ºã—relevanceã‚’åˆ¤å®šã—ã¦ã‚‚ã‚‰ã£ãŸã€‚å…·ä½“çš„ã«ã¯ã€informativenessã‚’5æ®µéšè©•ä¾¡ã€‚<br>ãƒ‡ãƒ¼ã‚¿éå…¬é–‹ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’ä½¿ã£ãŸã¨ã—ã‹è¨˜è¿°ã•ã‚Œã¦ãŠã‚‰ãšå†ç¾ä¸å¯</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2024-12-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1609" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models in Machine Translation, Brants+, EMNLP-CoNLL'07</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€æ©Ÿæ¢°ç¿»è¨³ã«ãŠã‘ã‚‹å¤§è¦æ¨¡ãªçµ±è¨ˆçš„è¨€èªãƒ¢ãƒ‡ãƒ«ã®åˆ©ç‚¹ã‚’å ±å‘Šã—ã€æœ€å¤§2å…†ãƒˆãƒ¼ã‚¯ãƒ³ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸ3000å„„n-gramã®ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã€‚æ–°ã—ã„ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æ‰‹æ³•ã€ŒStupid Backoffã€ã‚’å°å…¥ã—ã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®‰ä¾¡ã§ã€Kneser-Neyã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã«è¿‘ã¥ãã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>N-gramè¨€èªãƒ¢ãƒ‡ãƒ«+ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã®æ‰‹æ³•ã«ãŠã„ã¦ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã—ã¦æ‰±ãˆã‚‹ngramã®ã‚¿ã‚¤ãƒ—æ•°ï¼ˆä»Šã§è¨€ã†ã¨ã“ã‚ã®vocabæ•°ã«è¿‘ã„ï¼‰ã‚’å¢—ã‚„ã—ã¦ã„ã£ãŸã‚‰ã€perplexityã¯æ”¹å–„ã™ã‚‹ã—ã€MTã«ãŠã‘ã‚‹BLEUã‚¹ã‚³ã‚¢ã‚‚æ”¹å–„ã™ã‚‹ã‚ˆï¼ˆBLEUã¯ã‚µãƒã£ã¦ã‚‹ã‹ã‚‚ï¼Ÿï¼‰ã¨ã„ã†è€ƒå¯ŸãŒã•ã‚Œã¦ã„ã‚‹<br><br><img src="https://github.com/user-attachments/assets/035f28db-12c6-4b69-b39f-7eb41581d00c" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1871024428739604777?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Large Language Modelsã¨ã„ã†ç”¨èªãŒåˆ©ç”¨ã•ã‚ŒãŸã®ã¯ã“ã®ç ”ç©¶ãŒåˆã‚ã¦ãªã®ã‹ã‚‚â€¦ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<a class="button" href="articles/TrainedMetrics.html" target="_blank" rel="noopener noreferrer">#TrainedMetrics</a>
<span class="issue_date">Issue Date: 2023-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/988" target="_blank" rel="noopener noreferrer" class="title-link">Supervised automatic evaluation for summarization with voted regression model, Hirao+, Information and Processing &amp; Management'07</a>
<span class="snippet"><span>GPT Summary</span>- è¦ç´„ã‚·ã‚¹ãƒ†ãƒ ã®è©•ä¾¡ã«ã¯é«˜å“è³ªãªäººé–“ã®è©•ä¾¡ãŒå¿…è¦ã ãŒã€ã‚³ã‚¹ãƒˆãŒé«˜ã„ãŸã‚è‡ªå‹•è©•ä¾¡æ–¹æ³•ãŒå¿…è¦ã€‚ææ¡ˆæ‰‹æ³•ã¯æŠ•ç¥¨å›å¸°ãƒ¢ãƒ‡ãƒ«ï¼ˆVRMï¼‰ã‚’ä½¿ç”¨ã—ã€å¾“æ¥ã®è‡ªå‹•è©•ä¾¡æ–¹æ³•ã¨æ¯”è¼ƒã—ã¦ã‚¨ãƒ©ãƒ¼å‰Šæ¸›ã‚’é”æˆã€‚ã•ã‚‰ã«ã€æœ€ã‚‚é«˜ã„ç›¸é–¢ä¿‚æ•°ã‚’å¾—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>VRM</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/IntegerLinearProgramming%20(ILP).html" target="_blank" rel="noopener noreferrer">#IntegerLinearProgramming (ILP)</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/ECIR.html" target="_blank" rel="noopener noreferrer">#ECIR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/241" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A study of global inference algorithms in multi-document summarization, Ryan McDonald, ECIR'07</a>
<span class="snippet"><span>Comment</span><p>æ–‡æ›¸è¦ç´„ã‚’ãƒŠãƒƒãƒ—ã‚µãƒƒã‚¯å•é¡Œã¨ã—ã¦å®šå¼åŒ–ã—ã€å³å¯†è§£ï¼ˆå‹•çš„è¨ˆç”»æ³•ã€ILP Formulationï¼‰ã€è¿‘ä¼¼è§£(Greedy)ã‚’æ±‚ã‚ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚</p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/IJCAI.html" target="_blank" rel="noopener noreferrer">#IJCAI</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/140" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Document Summarization using Conditional Random Fields, Shen+, IJCAI'07</a>
<span class="snippet"><span>Comment</span><p>CRFã‚’ç”¨ã„ã¦å˜ä¸€æ–‡æ›¸è¦ç´„ã®æ‰‹æ³•ã‚’è€ƒãˆã¾ã—ãŸã¨ã„ã†è©±ã€‚<br><br><br><br>æ°—æŒã¡ã¨ã—ã¦ã¯ã€<br><br>```<br><br>1. Supervisedãªãƒ¢ãƒ‡ãƒ«ã§ã¯ã€å½“æ™‚ã¯åŸæ–‡æ›¸ä¸­ã®å„æ–‡ã‚’ç‹¬ç«‹ã«2å€¤åˆ†é¡ã—ã¦è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒå¤šãã€sentenceé–“ã®relationãŒè€ƒæ…®ã§ãã¦ã„ãªã‹ã£ãŸ<br><br>2. unsupervisedãªæ‰‹æ³•ã§ã¯ã€ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ãã‚‚ã®ãªã©ãŒå¤šãã€æ±ç”¨çš„ã§ã¯ãªã‹ã£ãŸ<br><br>```<br><br>ã¨ã„ã£ãŸå•é¡ŒãŒã‚ã£ãŸã®ã§ã€CRFä½¿ã£ã¦ãã‚Œã‚’è§£æ±ºã—ã¾ã—ãŸã¨ã„ã†ä¸»å¼µ<br><br><br><br>CRFã‚’ä½¿ã£ã¦ã€è¦ç´„ã®å•é¡Œã‚’ç³»åˆ—ãƒ©ãƒ™ãƒªãƒ³ã‚°å•é¡Œã«è½ã¨ã™ã“ã¨ã§ã€æ–‡é–“ã®é–¢ä¿‚æ€§ã‚’è€ƒæ…®ã§ãã‚‹ã‚ˆã†ã«ã—ã€å¾“æ¥ä½¿ã‚ã‚Œã¦ããŸãƒ«ãƒ¼ãƒ«ï¼ˆç´ æ€§ï¼‰ã‚’ãã®ã¾ã¾CRFã®ç´ æ€§ã¨ã—ã¦ã¶ã¡ã“ã‚“ã§ã—ã¾ãˆã°ã€è¦ç´„ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã§ãã‚‹ã‚ˆã­ã£ã¦ã„ã†ã“ã¨ã ã‚ã†ã¨æ€ã†ã€‚<br><br><br><br>CRFã®Featureã¨ã—ã¦ã¯ã€æ–‡ã®positionã‚„ã€é•·ã•ã€æ–‡ã®å°¤åº¦ã€thematic wordsãªã©ã®åŸºæœ¬çš„ãªFeatureã«åŠ ãˆã€LSAã‚„Hitsã®Scoreã‚‚åˆ©ç”¨ã—ã¦ã„ã‚‹ã€‚<br><br><br><br>DUC2001ã®ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã—ãŸçµæœã€basicãªç´ æ€§ã®ã¿ã‚’ä½¿ç”¨ã—ãŸå ´åˆã€unsupervisedãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³(Random, Lead, LSA, HITS)ã€ãŠã‚ˆã³supervisedãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³(NaiveBayes, SVM, Logistic Regression, HMM)ã‚’outperformã€‚<br><br>ã¾ãŸã€LSAã‚„HITSãªã©ã®Featureã‚’è¿½åŠ ã—ãŸå ´åˆã€basicãªç´ æ€§ã®ã¿ã¨æ¯”ã¹ã¦ROUGEã‚¹ã‚³ã‚¢ãŒæœ‰æ„ã«å‘ä¸Šã—ã€ãªãŠã‹ã¤ææ¡ˆæ‰‹æ³•ãŒbest<br><br><br><br>çµæ§‹referã•ã‚Œã¦ã„ã‚‹ã®ã§ã€çŸ¥ã£ã¦ãŠã„ã¦æã¯ãªã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/DomainAdaptation.html" target="_blank" rel="noopener noreferrer">#DomainAdaptation</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/126" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Frustratingly easy domain adaptation, Daum'e, ACL'07</a>
<span class="snippet"><span>Comment</span><p><img src="https://user-images.githubusercontent.com/12249301/34462211-f3428130-ee81-11e7-8a06-36e66bd19b2f.png" alt="image" loading="lazy"><br><br><br><br>domain adaptationã‚’ã™ã‚‹éš›ã«ã€Sourceå´ã®Featureã¨Targetå´ã®Featureã‚’ä¸Šå¼ã®ã‚ˆã†ã«ã€Feature Vectorã‚’æ‹¡å¼µã—ç‹¬ç«‹ã«ã‚³ãƒ”ãƒ¼ã—è¡¨ç¾ã™ã‚‹ã ã‘ã§ã€ãŠæ‰‹è»½ã«domain adaptationãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸè«–æ–‡ã€‚<br><br><br><br>ã‚¤ãƒ¡ãƒ¼ã‚¸çš„ã«ã¯ã€Sourceã¨Targetã€ä¸¡æ–¹ã«å­˜åœ¨ã™ã‚‹ç‰¹å¾´ã¯ã€å…±é€šéƒ¨åˆ†ã®é‡ã¿ãŒé«˜ããªã‚Šã€Source, Targetãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®ç‰¹å¾´ã¯ã€ãã‚Œãã‚Œæ‹¡å¼µã—ãŸéƒ¨åˆ†ã®Featureã«é‡ã¿ãŒå…¥ã‚‹ã‚ˆã†ãªæ„Ÿã˜ã€‚</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/100" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Automatic generation of textual summaries from neonatal intensive care data, Porter+, AIME'07</a>
<span class="snippet"><span>Comment</span><p>BabyTalkè«–æ–‡</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/85" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] An Architecture for Data to Text Systems, Ehud Reiter, ENLG'07</a>
<span class="snippet"><span>Comment</span><p>NLGåˆ†é‡ã§æœ‰åãªReiterã‚‰ã®Surveyã€‚<br>NLGã‚·ã‚¹ãƒ†ãƒ ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãªã©ãŒã€ä½“ç³»çš„ã«èª¬æ˜ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/Comments.html" target="_blank" rel="noopener noreferrer">#Comments</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/CIKM.html" target="_blank" rel="noopener noreferrer">#CIKM</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/10" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Comments-Oriented Blog Summarization by Sentence Extraction, CIKM'07, [Hu+, 2007], 2007.11</a>
<span class="snippet"><span>Comment</span><p>


<a href="https://dl.acm.org/citation.cfm?id=1321571" target="_blank" rel="noopener noreferrer">https://dl.acm.org/citation.cfm?id=1321571</a>


</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/DataDriven.html" target="_blank" rel="noopener noreferrer">#DataDriven</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/102" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Aggregation via set partitioning for natural language generation, Barzilay+, HLT-NAACL'06</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/RuleBased.html" target="_blank" rel="noopener noreferrer">#RuleBased</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/103" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Choosing words in computer-generated weather forecasts, Reiter+, Artificial Intelligence'05</a>
<span class="snippet"><span>Comment</span><p>## ã‚¿ã‚¹ã‚¯<br><br>å¤©æ°—äºˆå ±ã®ç”Ÿæˆ, ã‚·ã‚¹ãƒ†ãƒ å SUMTIME<br><br><br><br>## æ‰‹æ³•æ¦‚è¦<br><br> ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ãªæ‰‹æ³•ï¼Œweather prediction dataã‹ã‚‰ï¼ˆå°†æ¥ã®æ°—è±¡æƒ…å ±ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ãŸæ•°å€¤ãƒ‡ãƒ¼ã‚¿ï¼‰ï¼Œå¤©æ°—äºˆå ±ã‚’è‡ªå‹•ç”Ÿæˆï¼corpus analysisã¨å°‚é–€å®¶ã®suggestã‚’é€šã˜ã¦ï¼Œã©ã®ã‚ˆã†ãªwordã‚’é¸æŠã—ã¦å¤©æ°—äºˆå ±ã‚’ç”Ÿæˆã™ã‚‹ã‹è©³ç´°ã«åˆ†æã—ãŸã®ã¡ï¼Œãƒ«ãƒ¼ãƒ«ã‚’ç”Ÿæˆã—ã¦ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/DataDriven.html" target="_blank" rel="noopener noreferrer">#DataDriven</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/101" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Collective content selection for concept-to-text generation, Barzilay+, HLT_EMNLP'05</a>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/22" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] NewsInEssence: Summarizing ONLINE NEWS TOPICS, Radev+, Communications of the ACM'05, 2005.10</a>
<span class="snippet"><span>Comment</span><p>ãƒ»Centroid-Basedãªæ‰‹æ³•(MEADã¨åŒã˜æ‰‹æ³•)ã§è¦ç´„ã‚’ç”Ÿæˆ<br><br>ãƒ»Personalizationã¯ã‹ã‘ã¦ã„ãªã„</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Classic.html" target="_blank" rel="noopener noreferrer">#Classic</a>
<span class="issue_date">Issue Date: 2023-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1019" target="_blank" rel="noopener noreferrer" class="title-link">Centroid-based summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies, Radev+, Information Processing &amp; Management'04</a>
<span class="snippet"><span>Comment</span><p>MEAD, Centroid-basedãªæ‰‹æ³•ã§è¦ç´„ã‚’å®Ÿæ–½ã™ã‚‹å¤å…¸çš„ãªMDSæ‰‹æ³•</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/OpinionMining.html" target="_blank" rel="noopener noreferrer">#OpinionMining</a>
<a class="button" href="articles/review.html" target="_blank" rel="noopener noreferrer">#review</a>
<span class="issue_date">Issue Date: 2023-05-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/662" target="_blank" rel="noopener noreferrer" class="title-link">Mining and summarizing customer reviews, Hu+, KDD'04</a>
<span class="snippet"><span>Comment</span><p>ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­ã®ãƒ¦ãƒ¼ã‚¶ãŒè¨˜è¿°ã—ãŸopinion sentenceã‚’åŒå®šã—ã€æ¥µæ€§ãŒpos/negã®ã©ã¡ã‚‰ã‹ã‚’åˆ¤å®šã—ã€pos/negãã‚Œãã‚Œã®ä»£è¡¨çš„ãªsentenceã‚’æŠ½å‡ºã™ã‚‹ã“ã¨ã§è¦ç´„ã™ã‚‹æ‰‹æ³•<br><br><br><br>è©•ä¾¡ã‚’ã™ã‚‹éš›ã¯ã€Amazonç­‰ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åé›†ã—ã€äººé–“ãŒãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’èª­ã¿ã€ã©ã‚ŒãŒopinion sentenceã‹ã€ãŠã‚ˆã³polarityã‚’ã‚¿ã‚°ä»˜ã‘ã—ã€ãã‚Œã‚‰ã‚’ã©ã‚Œã ã‘æŠ½å‡ºã§ããŸã‹ã‚’Precision / Recall / F1å€¤ã§è©•ä¾¡ã€‚</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<span class="issue_date">Issue Date: 2021-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/393" target="_blank" rel="noopener noreferrer" class="title-link">æ©Ÿæ¢°ç¿»è¨³è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ã®æ¯”è¼ƒ, ä»Šæ‘+, NLP'04</a>
<span class="snippet"><span>Comment</span><p>BLEUã‚¹ã‚³ã‚¢ã€NISTã‚¹ã‚³ã‚¢ã€WordErrorRate(WER)ãªã©ã«é–¢ã—ã¦ä¸å¯§ã‹ã¤ç°¡æ½”ã«è§£èª¬ã—ã¦ã‚ã‚‹ã€‚<br><br>BLEUã‚¹ã‚³ã‚¢ç®—å‡ºã«åˆ©ç”¨ã™ã‚‹N-gramã¯ä¸€èˆ¬çš„ã«ã¯N=4ãŒç”¨ã„ã‚‰ã‚Œã‚‹ã€ã¨ã„ã£ãŸç—’ã„ã¨ã“ã‚ã«æ‰‹ãŒå±Šãæƒ…å ±ã‚‚æ›¸ã„ã¦ã‚ã‚‹ã€‚<br><br>æ™®æ®µä½•æ°—ãªãä½¿ã£ã¦ã„ã‚‹BLEUã‚¹ã‚³ã‚¢ã§ã€ã‚ã‚Œå®šç¾©ã£ã¦ã©ã‚“ãªã ã£ã‘ï¼Ÿã¨ç«‹ã¡å¸°ã‚ŠãŸããªã£ãŸæ™‚ã«èª­ã‚€ã¹ã—ã€‚</p>
<p>å®Ÿéš›ã«ç ”ç©¶ç­‰ã§BLEUã‚¹ã‚³ã‚¢ã‚’æ¸¬ã‚ŠãŸã„å ´åˆã¯ã€mosesã®å®Ÿè£…ã‚’ä½¿ã†ã®ãŒé–“é•ã„ãªã„:<br><br>


<a href="https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl" target="_blank" rel="noopener noreferrer">https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl</a>


</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2018-01-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/242" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Formal Model for Information Selection in Multi-Sentence Text Extraction, Filatova+, COLING'04</a>
<span class="snippet"><span>Comment</span><p>åˆã‚ã¦æ–‡æ›¸è¦ç´„ã‚’æœ€å¤§è¢«è¦†å•é¡Œã¨ã—ã¦å®šå¼åŒ–ã—ãŸç ”ç©¶ã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/233" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Phrase-Based HMM Approach to Document_Abstract Alignment, Daume+, EMNLP'04</a>
<span class="snippet"><span>Comment</span><p>Abstractsã¨Source Textã®Alignmentã‚’ã¨ã‚‹ãŸã‚ã«ã€Phrase-Based HMMã‚’ææ¡ˆã€‚<br><br>Ziff-Davis Corpusã®ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã—ã¦ã€2äººã®annotatorã«ã‚ˆã£ã¦gold standardã‚’ä½œæˆã€‚<br><br>è©•ä¾¡ã«ãŠã„ã¦MTã«ãŠã‘ã‚‹IBM Model4ã‚„HMM basedãªå˜èªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆæ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦ã„ã‚‹ãŒã€fair comparisonã®ãŸã‚ã«è¡Œãªã£ã¦ã„ã‚‹æ–½ç­–ãŒå‚è€ƒã«ãªã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/214" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TextRank: Bringing Order into Texts, Mihalcea+, EMNLP'04</a>
<span class="snippet"><span>Comment</span><p>PageRankãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã§ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º/æ–‡æ›¸è¦ç´„ ã‚’è¡Œã†æ‰‹æ³•ã€‚<br><br>ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º/æ–‡æ›¸è¦ç´„ ã‚’è¡Œã†éš›ã«ã¯ã€ãƒãƒ¼ãƒ‰ã‚’ãã‚Œãã‚Œ å˜èª/æ–‡ ã§è¡¨ç¾ã™ã‚‹ã€‚<br><br>ãƒãƒ¼ãƒ‰ã§è¡¨ç¾ã•ã‚Œã¦ã„ã‚‹ å˜èª/æ–‡ ã®similarityã‚’æ¸¬ã‚Šã€ãƒãƒ¼ãƒ‰é–“ã®edgeã®é‡ã¿ã¨ã™ã‚‹ã“ã¨ã§Affinity Graphã‚’æ§‹ç¯‰ã€‚<br><br>ã‚ã¨ã¯æ§‹ç¯‰ã—ãŸAffinity Graphã«å¯¾ã—ã¦PageRankã‚’é©ç”¨ã—ã¦ã€ãƒãƒ¼ãƒ‰ã®é‡è¦åº¦ã‚’æ±‚ã‚ã‚‹ã€‚<br><br>ãƒãƒ¼ãƒ‰ã®é‡è¦åº¦ã«å¾“ã„Greedyã« å˜èª/æ–‡ ã‚’æŠ½å‡ºã™ã‚Œã°ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º/æ–‡æ›¸è¦ç´„ ã‚’è¡Œã†ã“ã¨ãŒã§ãã‚‹ã€‚</p>
<p>å˜ä¸€æ–‡æ›¸è¦ç´„ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã—ã¦ä½¿ãˆã‚‹ã€‚</p>
<p>gensimã«å®Ÿè£…ãŒã‚ã‚‹ã€‚<br><br>å€‹äººçš„ã«ã‚‚å®Ÿè£…ã—ã¦ã„ã‚‹ï¼šhttps://github.com/AkihikoWatanabe/textrank</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/239" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A systematic comparison of various statistical alignment models, Och+, CL'03</a>
<span class="snippet"><span>Comment</span><p>Giza++<br>æ¨™æº–çš„ã«åˆ©ç”¨ã•ã‚Œã‚‹å˜èªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãƒ„ãƒ¼ãƒ«</p>
<p>è©•ä¾¡ã®éš›ã¯ã€Sure, Possibleã®äºŒç¨®é¡ã®ãƒ©ãƒ™ãƒ«ã«ã‚ˆã‚‹å˜èªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã®ground-truthä½œæˆã‚‚è¡Œã£ã¦ã„ã‚‹</p>
<p>


<a href="http://delivery.acm.org/10.1145/780000/778824/s2.pdf?ip=122.18.145.201&id=778824&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&__acm__=1529099122_be539b373009b5812a7efac44e71e64d" target="_blank" rel="noopener noreferrer">http://delivery.acm.org/10.1145/780000/778824/s2.pdf?ip=122.18.145.201&id=778824&acc=OPEN&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E6D218144511F3437&__acm__=1529099122_be539b373009b5812a7efac44e71e64d</a>


</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/RuleBased.html" target="_blank" rel="noopener noreferrer">#RuleBased</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/107" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Coral: Using natural language generation for navigational assistance, Dale+, Australasian computer science conference'03</a>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/21" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WebInEssence: A Personalized Web-Based Multi-Document Summarization and Recommendation System, Radev+, NAACL'01, 2001.06</a>
<span class="snippet"><span>Comment</span><p>ãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã•ã‚Œã¦ãŠã‚Šï¼Œå„ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«multi-document summarizationã‚’è¡Œã†ã“ã¨ã§ï¼Œ<br><br>ãƒ¦ãƒ¼ã‚¶ãŒæœ€ã‚‚èˆˆå‘³ã®ã‚ã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ã‚’åŒå®šã™ã‚‹ã“ã¨ã«å½¹ç«‹ã¦ã‚‹ï¼ã‚ã‚‹ã„ã¯æ¤œç´¢çµæœã®ãƒšãƒ¼ã‚¸ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è¦ç´„ã‚’è¡Œã†ï¼<br><br>è¦ç´„ã—ãŸçµæœã«ã¯ï¼Œextractã—ãŸæ–‡ã®å…ƒURLãªã©ãŒä»˜ä¸ã•ã‚Œã¦ã„ã‚‹ï¼<br><br>ãƒ»Personalizationã‚’ã‹ã‘ã‚‹ãŸã‚ã«ã¯ï¼Œãƒ¦ãƒ¼ã‚¶ãŒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’é¸æŠã—ï¼Œã‚¿ã‚¤ãƒˆãƒ«ãƒ»ãƒœãƒ‡ã‚£ãªã©ã«å®šæ•°ã®é‡ã¿ã‚’ã‹ã‘ã¦ï¼Œãã®æƒ…å ±ã‚’è¦ç´„ã«ä½¿ã†ï¼<br><br>ãƒ»ç‰¹ã«è©•ä¾¡ã—ã¦ã„ãªã„ï¼ã‚·ã‚¹ãƒ†ãƒ ã®outputã‚’ç¤ºã—ãŸã ã‘ï¼</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/246" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Cut and paste based text summarization, Jing+, NAACL'00</a>
<span class="snippet"><span>Comment</span><p>AbstractiveãªSummarizationã®å…ˆé§†ã‘çš„ç ”ç©¶ã€‚<br><br>AbstractiveãªSummarizationã‚’ç ”ç©¶ã™ã‚‹ãªã‚‰ã€æŠ¼ã•ãˆã¦ãŠã„ãŸã»ã†ãŒè‰¯ã„ã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/232" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generating Extraction-Based Summaries from Hand-Written Summaries by Aligning Text Spans, Banko+, PACLING'99</a>
<span class="snippet"><span>Comment</span><p>æ–‡ã‚’å˜ä½ã¨ã—ã€æ–‡ã‚’æ–‡ä¸­ã®å˜èªã®å‡ºç¾é »åº¦ãƒ™ã‚¯ãƒˆãƒ«ã§è¡¨ã—ã€ãƒ™ã‚¯ãƒˆãƒ«é–“ã®è·é›¢ã§æ–‡é–“ã®é¡ä¼¼åº¦ã‚’è¨ˆã‚‹ã“ã¨ã§è‡ªç”±ä½œæˆè¦ç´„ä¸­ã®æ–‡ã¨ç¾æ–‡ä¸­ã®æ–‡ã‚’ã‚‚ã£ã¨ã‚‚é¡ä¼¼åº¦ãŒå¤§ãããªã‚‹ã‚ˆã†ã«å¯¾å¿œã¥ã‘ã‚‹ã€‚<br><br>ï¼ˆå¥¥æ‘å…ˆç”Ÿã®Surveyã‚ˆã‚Šï¼š


<a href="https://www.jstage.jst.go.jp/article/jnlp1994/9/4/9_4_97/_pdf%EF%BC%89" target="_blank" rel="noopener noreferrer">https://www.jstage.jst.go.jp/article/jnlp1994/9/4/9_4_97/_pdfï¼‰</a>


</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/SIGIR.html" target="_blank" rel="noopener noreferrer">#SIGIR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/243" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries, Carbonell+, SIGIR'98</a>
<span class="snippet"><span>Comment</span><p>Maximal Marginal Relevance (MMR) è«–æ–‡ã€‚<br><br>æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚„æ–‡æ›¸è¦ç´„ã«ãŠã„ã¦ã€æ–‡æ›¸/æ–‡ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€æ—¢ã«é¸ã‚“ã æ–‡æ›¸ã¨é¡ä¼¼åº¦ãŒä½ãã€ã‹ã¤queryã¨relevantãªæ–‡æ›¸ã‚’greedyã«é¸æŠã—ã¦ã„ãæ‰‹æ³•ã‚’ææ¡ˆã€‚<br><br>ILPã«ã‚ˆã‚‹å®šå¼åŒ–ãŒææ¡ˆã•ã‚Œã‚‹ä»¥å‰ã®Multi Document Summarization (MDS) ç ”ç©¶ã«ãŠã„ã¦ã€å†—é•·æ€§ã®æ’é™¤ã‚’è¡Œã†éš›ã«ã¯å…¸å‹çš„ãªæ‰‹æ³•ã€‚</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/238" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note]  HMM-based word alignment in statistical translation, Vogel+, COLING'96</a>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/147" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Automatic condensation of electronic publications by sentence selection, Brandow+, Information Processing &amp; Management'95</a>
<span class="snippet"><span>Comment</span><p>å ±é“è¨˜äº‹è¦ç´„ã«ãŠã„ã¦ã€è‡ªå‹•è¦ç´„ã‚·ã‚¹ãƒ†ãƒ ãŒLeadæ–‡ã«å‹ã¤ã®ãŒhardã ã¨ã„ã†ã“ã¨ã‚’ç¤ºã—ãŸç ”ç©¶</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/SIGIR.html" target="_blank" rel="noopener noreferrer">#SIGIR</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/138" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Trainable Document Summarizer, Kupiec+, SIGIR'95</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/RuleBased.html" target="_blank" rel="noopener noreferrer">#RuleBased</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/104" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Using natural language processing to produce weather forecasts, Goldberg+, IEEE Expert: Intelligent Systems and Their Applications'94</a>
<span class="snippet"><span>Comment</span><p>## ã‚¿ã‚¹ã‚¯<br><br>å¤©æ°—äºˆå ±ã®ç”Ÿæˆï¼Œã‚·ã‚¹ãƒ†ãƒ å FOG (Englishã¨Frenchã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã§ãã‚‹)<br><br><br><br>## æ‰‹æ³•æ¦‚è¦<br><br>ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ãªæ‰‹æ³•ï¼Œweather predictinon dataã‹ã‚‰ï¼Œå¤©æ°—äºˆå ±ã‚’è‡ªå‹•ç”Ÿæˆï¼Text Planner ãŒãƒ«ãƒ¼ãƒ«ã«å¾“ã„å„sentenceã«å…¥ã‚Œã‚‹æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ã¨åŒæ™‚ã«ï¼Œsentence orderã‚’æ±ºã‚ï¼Œabstractiveãªä¸­é–“çŠ¶æ…‹ã‚’ç”Ÿæˆï¼ãã®å¾Œï¼Œä¸­é–“çŠ¶æ…‹ã‹ã‚‰Text Realizationï¼ˆgrammarã‚„dictionaryã‚’ç”¨ã„ã‚‹ï¼‰ã«ã‚ˆã£ã¦ï¼Œãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆï¼</p></span><br><br>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<span class="issue_date">Issue Date: 2023-05-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/680" target="_blank" rel="noopener noreferrer" class="title-link">The Identification of Important Concepts in Highly Structured Technical Papers, ACL-SIGIR'93</a>
<span class="snippet"><span>Comment</span><p>ãƒ¦ãƒ¼ã‚¶ã¯è‡ªåˆ†ãŒèˆˆå‘³ãŒã‚ã‚‹partã‚’summary evaluationã«ãŠã„ã¦é¸æŠã™ã‚‹å‚¾å‘ã«ã‚ã‚‹ã€ã¨ã„ã†ã“ã¨ã‚’ç¤ºã—ãŸç ”ç©¶</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/RuleBased.html" target="_blank" rel="noopener noreferrer">#RuleBased</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/105" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Design of a knowledge-based report generator, Kukich, ACL'83</a>
<span class="snippet"><span>Comment</span><p>## ã‚¿ã‚¹ã‚¯<br><br>numerical stock market dataã‹ã‚‰stock market reportsã‚’ç”Ÿæˆï¼Œæˆ‘ã€…ã¨åŒæ§˜ãªã‚¿ã‚¹ã‚¯ï¼ã‚·ã‚¹ãƒ†ãƒ å: ANA<br><br><br><br>## æ‰‹æ³•æ¦‚è¦<br><br>ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ãªæ‰‹æ³•ï¼Œ<br><br>1) fact-generator,<br><br>2) message generator, <br><br>3) discourse organizer, <br><br>4) text generatorã®4ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‹ã‚‰æˆã‚‹ï¼ <br><br><br><br>2), 3), 4)ã¯ãã‚Œãã‚Œ120, 16, 109å€‹ã®ãƒ«ãƒ¼ãƒ«ãŒã‚ã‚‹. 4)ã§ã¯phrasal dictionaryã‚‚ä½¿ã†ï¼ <br><br>1)ã§ã¯ï¼Œå…¥åŠ›ã•ã‚ŒãŸpriceãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼Œclosing averageã‚’æ±‚ã‚ã‚‹ãªã©ã®æ•°å€¤çš„ãªæ¼”ç®—ãªã©ã‚’è¡Œã†. <br><br>2)ã§ã¯ï¼Œ1)ã§è¨ˆç®—ã•ã‚ŒãŸæƒ…å ±ã«åŸºã¥ã„ã¦ï¼Œãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”Ÿæˆã‚’è¡Œã†(e.g. market was mixed). <br><br>3)ã§ã¯ï¼Œãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®paragraphåŒ–ï¼Œorderã®æ±ºå®šï¼Œpriorityã®è¨­å®šãªã©ã‚’è¡Œã†ï¼ <br><br>4)ã§ã¯ï¼Œè¾æ›¸ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’é¸æŠã—ãŸã‚Šï¼Œé©åˆ‡ãªsyntactic formã‚’æ±ºå®šã™ã‚‹ãªã©ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆï¼</p>
<p>Data2Textã®å…ˆé§†ã‘è«–æ–‡ã€‚å¼•ç”¨ã™ã¹ã—ã€‚å¤šãã®ç ”ç©¶ã§å¼•ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3149" target="_blank" rel="noopener noreferrer" class="title-link">terminal-bench: a benchmark for ai agents in terminal environments, laude-institute, </a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1975468544973545810?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3147" target="_blank" rel="noopener noreferrer" class="title-link">ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ãŒå¤§å¹…ã«å¼·åŒ–ã•ã‚ŒãŸPLaMo 2.1 Primeã®æä¾›é–‹å§‹, PFN, 2025.10</a>
<span class="snippet"><span>Comment</span><p>ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®tool callingã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ã®Simple, Multipleï¼ˆãã‚Œãã‚Œå˜ä¸€ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã€è¤‡æ•°ã®ãƒ„ãƒ¼ãƒ«ã®ä¸­ã‹ã‚‰é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™èƒ½åŠ›ï¼‰ã§BFCVv3ã§GPT-5è¶…ãˆã€‚ãŸã ã—GPT-5ã¯ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã§ã¯ãªããƒ¦ãƒ¼ã‚¶ã¨å¯¾è©±ã™ã‚‹å‚¾å‘ã«ã‚ã‚‹ãŸã‚ã€chatã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã“ã¡ã‚‰ã®æ–¹ãŒæœ‰ç”¨ãªå ´åˆãŒã‚ã‚‹ã®ã§å…¨ã¦ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã§PLaMoãŒä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã€ã¨ã„ã†æ³¨é‡ˆãŒã¤ã„ã¦ã„ã‚‹ã€‚ã‚ˆã‚Šå®Ÿé¨“çš„ãªç’°å¢ƒã§ã‚ã‚‹Live Multipleã§ã¯GPT-5ã®æ–¹ãŒã‚¹ã‚³ã‚¢ãŒé«˜ã„æ¨¡æ§˜ã€‚<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1875" target="_blank" rel="noopener noreferrer">BFCLv2, UC Berkeley, 2024.08</a>
<br><br>å˜ä¸€å‘¼ã³å‡ºã—ã€è¤‡æ•°å®šç¾©ã•ã‚Œã¦ã„ã‚‹ä¸­ã‹ã‚‰é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™ã“ã¨ã§æ¸ˆã‚€ã‚ˆã†ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã®å ´åˆã¯æ¤œè¨ã®ä½™åœ°ãŒã‚ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚ãŸã ã—ç´°ã‹ã„reasoning_effortã‚„verbosityç­‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šãŒè¨˜è¿°ã•ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã®ã§ã€ãã®è¾ºã¯ã©ã†ãªã‚“ã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3130" target="_blank" rel="noopener noreferrer" class="title-link">PipelineRL, Piche+, ServiceNow, 2025.04</a>
<span class="snippet"><span>Comment</span><p>code:


<a href="https://github.com/ServiceNow/PipelineRL" target="_blank" rel="noopener noreferrer">https://github.com/ServiceNow/PipelineRL</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vllm_project/status/1974732295627301254?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Inflight Weight Updates</p>
<p>ï¼ˆã“ã®è¾ºã®ç´°ã‹ã„å®Ÿè£…ã®è©±ã¯ã‚ã¾ã‚Šè©³ã—ããªã„ã®ã§èª¤ã‚ŠãŒã‚ã‚‹å¯èƒ½æ€§ãŒçµæ§‹ã‚ã‚Šã¾ã™ï¼‰<br>é€šå¸¸ã®on-policy RLã§ã¯å…¨ã¦ã®GPUä¸Šã§ã®sequenceã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆãŒçµ‚ã‚ã‚‹ã¾ã§å¾…ã¡ã€å…¨ã¦ã®ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆå®Œäº†å¾Œã«ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’æ›´æ–°ã™ã‚‹ãŸã‚ã€é•·ã„sequenceã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚’ã™ã‚‹GPUã®å‡¦ç†ãŒçµ‚ã‚ã‚‹ã¾ã§ã€çŸ­ã„sequenceã®ç”Ÿæˆã§æ¸ˆã‚“ã GPUã¯å¾…æ©Ÿã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚ä¸€æ–¹ã€PipelineRLã¯sequenceã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã®é€”ä¸­ã§ã‚‚é‡ã¿ã‚’æ›´æ–°ã—ã€ç”Ÿæˆé€”ä¸­ã®sequenceã¯å¤ã„KV Cacheã‚’ä¿æŒã—ãŸã¾ã¾æ–°ã—ã„é‡ã¿ã§sequenceã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚’ç¶™ç¶šã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚ŠGPU Utilizationã‚’æœ€å¤§åŒ–ã§ãã‚‹ï¼ˆãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆå®Œäº†ã®ãŸã‚ã®å¾…æ©Ÿæ™‚é–“ãŒç„¡ããªã‚‹ï¼‰ã€‚ã¾ãŸã€ä¸€è¦‹å¤ã„KV Cacheã‚’å‰æã«æ–°ãŸãªé‡ã¿ã§ç¶™ç¶šã—ã¦éƒ¨åˆ†sequenceã‚’ç¶™ç¶šã™ã‚‹ã¨ãƒãƒªã‚·ãƒ¼ã®gapã«ã‚ˆã‚Šæ€§èƒ½ãŒæ‚ªåŒ–ã™ã‚‹ã‚ˆã†ã«æ€ãˆã‚‹ãŒã€æ€§èƒ½ãŒæ‚ªåŒ–ã—ãªã„ã“ã¨ãŒå®Ÿé¨“çš„ã«ç¤ºã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/6794927a-3fa9-4a68-ba48-d112d495e0ab" alt="image" loading="lazy"><br><br>Conventional RLã®ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰éƒ¨åˆ†ã‚’è¦‹ã‚‹ã¨ã¨ã¦ã‚‚ã‚ã‹ã‚Šã‚„ã™ãã¦å‚è€ƒã«ãªã‚‹ã€‚Conventional RLï¼ˆPPOã¨ã‹ï¼‰ã§ã¯ã€å®Ÿè£…ä¸Šã¯è¤‡æ•°ã®ãƒãƒƒãƒã«åˆ†ã‘ã¦é‡ã¿ã®æ›´æ–°ãŒè¡Œã‚ã‚Œã‚‹ï¼ˆã‚‰ã—ã„ï¼‰ã€‚ã“ã®ã¨ãã€GPUã®åˆ©ç”¨ã‚’æœ€å¤§åŒ–ã—ã‚ˆã†ã¨ã™ã‚‹ã¨ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å¤§ããã›ã–ã‚‹ã‚’å¾—ãªã„ã€‚ã“ã®ãŸã‚ã€é€æ¬¡æ›´æ–°ã‚’ã—ãŸã¨ãã®policyã®gapãŒã©ã‚“ã©ã‚“è“„ç©ã—ã¦ã„ãå¤§ãããªã‚‹ï¼ˆ=ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã§ç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ãŒã€å®Ÿéš›ã«é‡ã¿æ›´æ–°ã™ã‚‹ã¨ãã«ã¯lagãŒè“„ç©ã•ã‚Œã¦ã„ãã©ã‚“ã©ã‚“off-policyãƒ‡ãƒ¼ã‚¿ã«å¤‰åŒ–ã—ã¦ã„ã£ã¦ã—ã¾ã†ï¼‰ã¨ã„ã†å¼Šå®³ãŒã‚ã‚‹æ¨¡æ§˜ã€‚ã‹ã¨ã„ã£ã¦lagã‚’æœ€å°ã«ã™ã‚‹ãŸã‚ã«å°ã•ã„ãƒãƒƒãƒã‚µã‚¤ã‚ºã«ã™ã‚‹ã¨gpuã®åŠ¹ç‡ã‚’åœ§å€’çš„ã«çŠ ç‰²ã«ã™ã‚‹ã®ã§ã§ããªã„ã€‚Inflight Weight Updatesã§ã¯ã“ã®ã‚ˆã†ãªãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è§£æ±ºã§ãã‚‹æ¨¡æ§˜ã€‚<br><br>ã¾ãŸã€trainerã¨inferenceéƒ¨åˆ†ã¯å®Œå…¨ã«ç‹¬ç«‹ã•ã›ã‚‰ã‚Œã€ã‹ã¤plug-and-playã§é‡ã¿ã‚’æ›´æ–°ã™ã‚‹ã€ã¨ã„ã£ãŸä½¿ã„æ–¹ã‚‚æƒ³å®šã§ãã‚‹æ¨¡æ§˜ã€‚</p>
<p>ã‚ã¨ã“ã‚Œã¯ä½™è«‡ã ãŒã€å¼•ç”¨ãƒã‚¹ãƒˆã®ä¸»ã¯ä¸‹è¨˜ç ”ç©¶ã§attentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æœ€åˆã«ææ¡ˆã—ãŸBahdanauæ°ã§ã‚ã‚‹ã€‚<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1954" target="_blank" rel="noopener noreferrer">Neural Machine Translation by Jointly Learning to Align and Translate, Dzmitry Bahdanau+, ICLR'15</a>
</p>
<p>ç¶šå ±:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dbahdanau/status/1974889569607876747?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3125" target="_blank" rel="noopener noreferrer" class="title-link">CODA: Coding LM via Diffusion Adaption, Chen+, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscreamnearby/status/1974461551072690248?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/Salesforce/CoDA-v0-Instruct" target="_blank" rel="noopener noreferrer">https://huggingface.co/Salesforce/CoDA-v0-Instruct</a>


<br><br>cc-by-nc-4.0</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3118" target="_blank" rel="noopener noreferrer" class="title-link">PFN LLMã‚»ãƒŸãƒŠãƒ¼, PFN, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1973924269177668012?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3113" target="_blank" rel="noopener noreferrer" class="title-link">Diffusion Language Models are Super Data Learners, Ni+, 2022.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tianyupang1/status/1974118238415172107?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3102" target="_blank" rel="noopener noreferrer" class="title-link">Effective context engineering for AI agents, Anthropic, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/anthropicai/status/1973098580060631341?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Anthropicã«ã‚ˆã‚‹ContextEngineeringã«é–¢ã™ã‚‹ãƒ–ãƒ­ã‚°ã€‚<br>ã–ãƒ¼ã£ã¨ã¿ãŸæ„Ÿã˜åŸºç¤çš„ãªå®šç¾©ã‹ã‚‰ãªãœé‡è¦ãªã®ã‹ã€retrievalã®æ´»ç”¨ã€longnhorizon taskã§ã®æ´»ç”¨ã€compaction(summarization)ãªã©ã€å¹…åºƒã„ãƒˆãƒ”ãƒƒã‚¯ãŒç¶²ç¾…ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p>
<p>æœ€æ–°ã‚µãƒ¼ãƒ™ã‚¤ã¯ã“ã¡ã‚‰<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2256" target="_blank" rel="noopener noreferrer">[Paper Note] A Survey of Context Engineering for Large Language Models, Lingrui Mei+, arXiv'25</a>
</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_stakaya/status/1974228183450071048?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3090" target="_blank" rel="noopener noreferrer" class="title-link">OpenMoE 2: Sparse Diffusion Language Models, Ni+, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nijinjie/status/1973747616082186349?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3081" target="_blank" rel="noopener noreferrer" class="title-link">Ming-UniVision: Joint Image Understanding and Generation via a Unified Continuous Tokenizer, inclusionAI, 2025.10</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/inclusionAI/Ming-UniVision-16B-A3B" target="_blank" rel="noopener noreferrer">https://huggingface.co/inclusionAI/Ming-UniVision-16B-A3B</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1973894009551810952?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Editing.html" target="_blank" rel="noopener noreferrer">#Editing</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3080" target="_blank" rel="noopener noreferrer" class="title-link">Ming-UniAudio: Speech LLM for Joint Understanding, Generation and Editing with Unified Representation, inclusionAI, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1973147903784001665?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Ming-Omniã®å¾Œç¶™ãƒ¢ãƒ‡ãƒ«ã§ã€ã‚¹ãƒ”ãƒ¼ãƒã«ç‰¹åŒ–ã—ã¦æ›¸ãèµ·ã“ã—ã€ç†è§£ã€ç·¨é›†ãªã©ãŒã§ãã‚‹ãƒ¢ãƒ‡ãƒ«</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2300" target="_blank" rel="noopener noreferrer">[Paper Note] Ming-Omni: A Unified Multimodal Model for Perception and Generation, Inclusion AI+, arXiv'25</a>
</p>
<p>HF:


<a href="https://huggingface.co/inclusionAI/Ming-UniAudio-16B-A3B" target="_blank" rel="noopener noreferrer">https://huggingface.co/inclusionAI/Ming-UniAudio-16B-A3B</a>


</p>
<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/antlingagi/status/1974134429712007675?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/API.html" target="_blank" rel="noopener noreferrer">#API</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3077" target="_blank" rel="noopener noreferrer" class="title-link">Tinker is a training API for {developers, builders, researchers}, THINKING MACHINES, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/karpathy/status/1973468610917179630?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>THINKING MACHINESã«ã‚ˆã‚‹OpenWeightãƒ¢ãƒ‡ãƒ«ã‚’LoRAã«ã‚ˆã£ã¦post-trainingã™ã‚‹ãŸã‚ã®APIã€‚Qwenã¨Llamaã‚’ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã‚µãƒãƒ¼ãƒˆã€‚ç¾åœ¨ã¯Betaã§waitlistã«ç™»éŒ²ã™ã‚‹å¿…è¦ãŒã‚ã‚‹æ¨¡æ§˜ã€‚</p>
<p>ï¼ˆLlamaã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯ãƒ¦ãƒ¼ã‚¶æ•°ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãŒ7å„„äººã‚’è¶…ãˆãŸã‚‰Metaã®è¨±è«¾ãŒãªã„ã¨åˆ©ç”¨ã§ããªããªã‚‹æ°—ãŒã™ã‚‹ãŒã€æœãŸã—ã¦ã€ã¨ãµã¨æ€ã£ãŸï¼‰</p>
<p>ã“ã®å‰ã®ãƒ–ãƒ­ã‚°ã¯ã“ã®ãŸã‚ã®PRã‚‚å…¼ã­ã¦ã„ãŸã¨è€ƒãˆã‚‰ã‚Œã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3040" target="_blank" rel="noopener noreferrer">LoRA Without Regret, Schulman+, THINKING MACHINES, 2025.09</a>
</p>
<p>ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã“ã¡ã‚‰:<br>


<a href="https://tinker-docs.thinkingmachines.ai" target="_blank" rel="noopener noreferrer">https://tinker-docs.thinkingmachines.ai</a>


<br><br>Tinkerã¯ã€å¾“æ¥ã®<br>- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰<br>- å­¦ç¿’ã‚¸ãƒ§ãƒ–ã‚’èµ°ã‚‰ã›ã‚‹<br><br>ã¨ã„ã†ã‚¹ã‚¿ã‚¤ãƒ«ã§ã¯ãªãã€ãƒ­ãƒ¼ã‚«ãƒ«ã®ã‚³ãƒ¼ãƒ‰ã§stepå˜ä½ã®å­¦ç¿’ã®ãƒ«ãƒ¼ãƒ—ã‚’æ›¸ãä»¥ä¸‹ã‚’å®Ÿè¡Œã™ã‚‹:<br>- forward_backwardãƒ‡ãƒ¼ã‚¿, loss_functionã‚’APIã«é€ã‚‹<br>  - ã“ã‚Œã«ã‚ˆã‚Šå‹¾é…ã‚’Tinkerå´ãŒè“„ç©ã™ã‚‹<br>- optim_step: è“„ç©ã—ãŸå‹¾é…ã«åŸºã¥ã„ã¦ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°ã™ã‚‹<br>- sample: ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã™ã‚‹<br>- save_stateç­‰: é‡ã¿ã®ä¿å­˜ã€ãƒ­ãƒ¼ãƒ‰ã€optimizerã®stateã®ä¿å­˜ã‚’ã™ã‚‹<br><br>ã“ã‚Œã‚‰stepå˜ä½ã®å­¦ç¿’ã«å¿…è¦ãªãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–ãªã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ã®ã¿ã‚’APIã¨ã—ã¦æä¾›ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€CPUãƒã‚·ãƒ³ã§ã€ç‹¬è‡ªã«å®šç¾©ã—ãŸloss, dataset(ã‚ã‚‹ã„ã¯RLç”¨ã®environmentï¼‰ã‚’ç”¨ã„ã¦ã€å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ãã‚‹ã—ã€åˆ†æ•£å­¦ç¿’ã®è¤‡é›‘ã•ã‹ã‚‰è§£æ”¾ã•ã‚Œã‚‹ã€ã¨ã„ã†ä»£ç‰©ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚LoRAã®ã¿ã«å¯¾å¿œã—ã¦ã„ã‚‹ã€‚<br><br>ãªãŠã€stepå˜ä½ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¯å›é€ä¿¡ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã®ã§ã€stepã”ã¨ã«é€šä¿¡ã®ã‚ªãƒ¼ãƒãƒ˜ãƒƒãƒ‰ãŒç™ºç”Ÿã™ã‚‹ãªã‚“ã¦ã€Tinkerå´ãŒGPUã‚’æœ€å¤§é™ã«æ´»ç”¨ã§ããªã„ã®ã§ã¯ãªã„ã‹ã€‚è¨­è¨ˆã¨ã—ã¦ã©ã†ãªã‚“ã ï¼Ÿã¨ã„ã†ç‚¹ã«ã¤ã„ã¦ã¯ã€ä¸‹è¨˜ãƒ–ãƒ­ã‚°ãŒè€ƒå¯Ÿã‚’ã—ã¦ã„ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3134" target="_blank" rel="noopener noreferrer">Anatomy of a Modern Finetuning API, Benjamin Anderson, 2025.10</a>
<br><br>ã–ã£ãã‚Šè¨€ã†ã¨ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆã‚’å‰æã«ç‰¹å®šãƒ¦ãƒ¼ã‚¶ãŒGPUã‚’å æœ‰ã™ã‚‹ã®ã§ã¯ãªãã€è¤‡æ•°ãƒ¦ãƒ¼ã‚¶ã§å…±æœ‰ã™ã‚‹ã®ã§ã¯ãªã„ã‹ã€adapterã®ç€è„±ã®ã‚ªãƒ¼ãƒãƒ˜ãƒƒãƒ‰ã¯éå¸¸ã«å°ã•ã„ã®ã§ãƒãƒ«ãƒãƒ†ãƒŠãƒ³ãƒˆã«ã—ã¦ã‚‚ï¼ˆèª°ã‹ã®ãƒ‡ãƒ¼ã‚¿ã®å‹¾é…è¨ˆç®—ãŒçµ‚ã‚ã£ãŸã‚‰LoRAã‚¢ãƒ€ãƒ—ã‚¿ã‚’å·®ã—æ›¿ãˆã¦åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ã®å‹¾é…è¨ˆç®—ã‚’ã™ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚’ç¹°ã‚Šè¿”ã›ã°è‰¯ã„ã®ã§å¾…æ©Ÿæ™‚é–“ã¯ã‹ãªã‚Šå°ã•ããªã‚‹ã¯ãšã§ã€ï¼‰GPUãŒéŠã¶æ™‚é–“ãŒç”Ÿã˜ãªã„ã®ã§ãƒªã‚½ãƒ¼ã‚¹ã‚’Tinkerå´ã¯æœ€å¤§é™ã«æ´»ç”¨ã§ãã‚‹ã®ã§ã¯ãªã„ã‹ã€ã¨ã„ã£ãŸè€ƒå¯Ÿ/ä»®èª¬ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<span class="issue_date">Issue Date: 2025-10-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3072" target="_blank" rel="noopener noreferrer" class="title-link">IBM Granite 4.0: hyper-efficient, high performance hybrid models for enterprise, IBM, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1973837846898184596?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Mamba2ã¨transformerã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã§ã€æ¯”ç‡ã¯9:1ã¨Mamba2ãƒ–ãƒ­ãƒƒã‚¯ãŒå¤šã‚ã‚‰ã—ã„ã€‚Mamba2ã®æ©æµã«ã‚ˆã‚Šlokg-contextæ™‚ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒ70ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆå‰Šæ¸›ã•ã‚Œã‚‹ã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3061" target="_blank" rel="noopener noreferrer" class="title-link">2025å¹´10æœˆ1æ—¥ å›½ç«‹æƒ…å ±å­¦ç ”ç©¶æ‰€ã«ãŠã‘ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã¸ã®å”åŠ›ã«ã¤ã„ã¦,  å›½ç«‹å›½ä¼šå›³æ›¸é¤¨, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yhkondo/status/1973324514718261267?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¥æœ¬èªLLMã®é€²å±•ã«æ¥µã‚ã¦é‡è¦ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨æ€ã‚ã‚Œã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-10-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3058" target="_blank" rel="noopener noreferrer" class="title-link">Apriel-1.5-15b-Thinker, ServiceNow-AI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1973104687806378048?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Artificial Analysisã«ã‚ˆã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°ã§ã¯ç¾çŠ¶&lt;20Bã§SoTAãªReasoningãƒ¢ãƒ‡ãƒ«ãªæ¨¡æ§˜ã€‚<br>MIT License</p>
<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/servicenowrsrch/status/1973100536280027586?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Nvidiaã«ã‚ˆã‚‹ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nvidiaaidev/status/1973113351158047150?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2025-10-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3054" target="_blank" rel="noopener noreferrer" class="title-link">RLP: Reinforcement as a Pretraining Objective, Hatamizadeh+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ahatamiz1/status/1973115674701734277?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2031" target="_blank" rel="noopener noreferrer">[Paper Note] Reinforcement Pre-Training, Qingxiu Dong+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2968" target="_blank" rel="noopener noreferrer">[Paper Note] Reinforcement Learning on Pre-Training Data, Siheng Li+, arXiv'25, 2025.09</a>
</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/snat02792153/status/1973106638891471266?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1974242857935311160?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1974959939622989999?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3050" target="_blank" rel="noopener noreferrer" class="title-link">GLM-4.6: Advanced Agentic, Reasoning and Coding Capabilies, Zhipu AI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2406" target="_blank" rel="noopener noreferrer">[Paper Note] GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models, GLM-4. 5 Team+, arXiv'25</a>
</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1972932103462400133?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¶šå ±:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1972951657542545619?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Artificial Intelligenceã«ã‚ˆã‚‹è©•ä¾¡:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1975425594679496979?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>OpenWeightãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã®ãƒ™ãƒ³ãƒã‚¹ã‚³ã‚¢</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3046" target="_blank" rel="noopener noreferrer" class="title-link">Introducing Claude Sonnet 4.5, Anthropic, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/claudeai/status/1972706807345725773?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Claude Sonnet 4.5 ç™ºè¡¨é–¢é€£æƒ…å ±ã¾ã¨ã‚:<br>è¨˜äº‹:


<a href="https://zenn.dev/schroneko/articles/claude-sonnet-4-5" target="_blank" rel="noopener noreferrer">https://zenn.dev/schroneko/articles/claude-sonnet-4-5</a>


<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/schroneko/status/1972728043673452902?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ–ãƒ­ã‚°ã‚’èª­ã‚€ã¨Imagine with Claudeã®æ–¹ãŒã‚€ã—ã‚æ°—ã«ãªã‚‹...ï¼ˆæ®‹å¿µãªãŒã‚‰èª²é‡‘ã—ã¦ã„ãªã„ï¼‰<br>


<a href="https://claude.ai/login?returnTo=%2Fimagine" target="_blank" rel="noopener noreferrer">https://claude.ai/login?returnTo=%2Fimagine</a>


</p>
<p>Artificial Intelligenceã«ã‚ˆã‚‹è©•ä¾¡:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1972854742167761204?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3042" target="_blank" rel="noopener noreferrer" class="title-link">LLM ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã¨å¤–æŒ¿, ä½è—¤ç«œé¦¬, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/joisino_/status/1972580573341470811?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<a class="button" href="articles/Sparse.html" target="_blank" rel="noopener noreferrer">#Sparse</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3033" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-V3.2-Exp: Boosting Long-Context Efficiency with DeepSeek Sparse Attention, DeepSeek-AI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/danielhanchen/status/1972613546119991791?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>DeepSeek Sparse Attentionãƒã‚¤ãƒ³ãƒˆè§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vllm_project/status/1972617272901644345?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1972802544863678832?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>DSAå›³è§£:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/awnihannun/status/1972763521185436088?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1972650237266465214?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/deepseek_ai/status/1972604768309871061?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3032" target="_blank" rel="noopener noreferrer" class="title-link">Build A Reasoning Model ï¼ˆFrom Scratchï¼‰, Sebastian Raschka, 2025.05</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1972294357635178938?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>reasoningãƒ¢ãƒ‡ãƒ«ã«é–¢ã™ã‚‹pyTorchã«ã‚ˆã‚‹ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒã§ã®å®Ÿè£…ã¨ä¸å¯§ãªè§£èª¬ã¤ãã®NotebookãŒå…¬é–‹ã•ã‚Œã¦ãŠã‚Šå†…éƒ¨ã®åŸºç¤çš„ãªæŒ™å‹•ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã¨ã¦ã‚‚è‰¯ã•ãã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3027" target="_blank" rel="noopener noreferrer" class="title-link">GDPVAL: EVALUATING AI MODEL PERFORMANCE ON REAL-WORLD ECONOMICALLY VALUABLE TASKS, Patwardhan+, 2025.09</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3026" target="_blank" rel="noopener noreferrer" class="title-link">HunyuanImage-3.0, Tencent, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tencenthunyuan/status/1972130405160833334?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1972469371839860954?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ+ç”»åƒç†è§£ãƒ»ç”ŸæˆãŒå¯èƒ½ãªUnified Multimodal Models (UMMs)ã€‚ãƒ†ã‚­ã‚¹ãƒˆã¯tokenizerã€ç”»åƒã¯ç”Ÿæˆç”¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã€ç†è§£ç”¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’ç”¨æ„ã—ã¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—Decoder-Only Tranformerã«å…¥åŠ›ã€‚auto-regressiveã«ç”Ÿæˆã—ã€ãƒ†ã‚­ã‚¹ãƒˆã¯De-Tokenizerã§ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã€ç”»åƒã®å ´åˆã¯å°‚ç”¨ã®Decoderã§ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã€‚<br><br>&lt;img width="638" height="232" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/8e06f188-3885-4eed-8837-eb560dcc6b67"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/8e06f188-3885-4eed-8837-eb560dcc6b67"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ImageCaptioning.html" target="_blank" rel="noopener noreferrer">#ImageCaptioning</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3023" target="_blank" rel="noopener noreferrer" class="title-link">CapRL, internlm, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1972455938939322805?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3019" target="_blank" rel="noopener noreferrer" class="title-link">Why GPT-5 used less training compute than GPT-4.5 ï¼ˆbut GPT-6 probably wonâ€™tï¼‰, EPOCH AI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1972421341988225340?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Pruning.html" target="_blank" rel="noopener noreferrer">#Pruning</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-09-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3017" target="_blank" rel="noopener noreferrer" class="title-link">How to Fix Your Context, dbreunig.com, 2025.07</a>
<span class="snippet"><span>Comment</span><p>Context Poisoning, Context Distraction, Context Confusion,<br>Context Clashã®å®šç¾©ã¨ãã‚Œã‚‰ã®å¯¾å‡¦æ³•ã«ã¤ã„ã¦æ›¸ã‹ã‚Œã¦ã„ã‚‹ã€‚å¾Œã»ã©è¿½è¨˜ã™ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-09-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3011" target="_blank" rel="noopener noreferrer" class="title-link">Continuing to bring you our latest models, with an improved Gemini 2.5 Flash and Flash-Lite release, Google Deepmind, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mamagnus00/status/1971704040578077095?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3010" target="_blank" rel="noopener noreferrer" class="title-link">We reverse-engineered Flash Attention 4, Modal Blog, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwashi86/status/1972085451055157725?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Flash Attention4ã¯æ•°å­¦çš„ãªãƒˆãƒªãƒƒã‚¯ã‚ˆã‚Šã‚‚éåŒæœŸå‡¦ç†ã®è¤‡é›‘ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€Blackwellã«æœ€é©åŒ–ã€ã¨ã®ã“ã¨</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Aggregation-aware.html" target="_blank" rel="noopener noreferrer">#Aggregation-aware</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3008" target="_blank" rel="noopener noreferrer" class="title-link">RECURSIVE SELF-AGGREGATION UNLOCKS DEEP THINKING IN LARGE LANGUAGE MODELS, Venkatraman+, preprint, 2025.09</a>
<span class="snippet"><span>Comment</span><p>Nå€‹ã®å¿œç­”ã‚’ç”Ÿæˆã—ã€å„å¿œç­”Kå€‹çµ„ã¿åˆã‚ã›ã¦promptingã§é›†ç´„ã—æ–°ãŸãªå¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§æ´—ç·´ã•ã›ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚’Tå›ç¹°ã‚Šè¿”ã™test-time scalingæ‰‹æ³•ã§ã€RLã«ã‚ˆã£ã¦ãƒ¢ãƒ‡ãƒ«ã®é›†ç´„èƒ½åŠ›ã‚’å¼·åŒ–ã™ã‚‹ã¨ã‚ˆã‚Šè‰¯ã„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ç™ºæ®ã™ã‚‹ã€‚RLã§ã¯é€šå¸¸ã®ç›®çš„é–¢æ•°ï¼ˆprompt x, answer y; xã‹ã‚‰å˜ä¸€ã®reasoning traceã‚’ç”Ÿæˆã—yã‚’å›ç­”ã™ã‚‹è¨­å®šï¼‰ã«åŠ ãˆã¦ã€aggregation promptã‚’ç”¨ã„ãŸç›®çš„é–¢æ•°(aggregation promptã‚’ç”¨ã„ã¦ Kå€‹ã®solutioné›†åˆ S_0ã‚’ç”Ÿæˆã—ã€ç›®çš„é–¢æ•°ã‚’aggregation prompt x, S_0ã®åŒæ–¹ã§æ¡ä»¶ã¥ã‘ãŸã‚‚ã®)ã‚’å®šç¾©ã—ã€åŒæ™‚ã«æœ€é©åŒ–ã‚’ã—ã¦ã„ã‚‹ï¼ˆåŒæ™‚ã«æœ€é©åŒ–ã™ã‚‹ã“ã¨ã¯5.4ç¯€ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ï¼‰ã€‚ã¤ã¾ã‚Šã€ã“ã‚Œã¾ã§ã®RLã¯xãŒgivenãªæ™‚ã«é ‘å¼µã£ã¦å˜ä¸€ã®è‰¯ã„æ„Ÿã˜ã®reasoning traceã‚’ç”Ÿæˆã—yã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã—ã¦ã„ãŸãŒï¼ˆã™ãªã‚ã¡ã€ãƒ¢ãƒ‡ãƒ«ãŒè¤‡æ•°ã®solutionã‚’é›†ç´„ã™ã‚‹ã“ã¨ã¯æ˜ç¤ºçš„ã«å­¦ç¿’ã•ã‚Œã¦ã„ãªã„ï¼‰ã€ãã‚Œã«åŠ ãˆã¦ãƒ¢ãƒ‡ãƒ«ã®aggregationã®èƒ½åŠ›ã‚‚åŒæ™‚ã«å¼·åŒ–ã™ã‚‹ã€ã¨ã„ã†æ°—æŒã¡ã«ãªã£ã¦ã„ã‚‹ã€‚å­¦ç¿’ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯PPO, GRPOãªã©æ§˜ã€…ãªon-poloicyãªæ‰‹æ³•ã‚’ç”¨ã„ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ä»Šå›ã¯RLOOã¨å‘¼ã°ã‚Œã‚‹æ‰‹æ³•ã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚<br><br>&lt;img width="1005" height="456" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/e83406ae-91a0-414b-a49c-892a4d1f23fd"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/e83406ae-91a0-414b-a49c-892a4d1f23fd"&lt;/a&gt;


/&gt;<br><br>æ§˜ã€…ãªsequential scaling, parallel scalingæ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦ã€RSAãŒã‚ˆã‚Šå¤§ããªgainã‚’å¾—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚ãŸã ã—ã€Knowledge Recallã¨ã„ã†ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã¯Self-Consistency (Majority Voting)ã‚ˆã‚Šã‚‚gainãŒå°ã•ã„ã€‚<br>&lt;img width="1017" height="427" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/8251f25b-472d-48d4-b7df-a6946cfbbcd9"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/8251f25b-472d-48d4-b7df-a6946cfbbcd9"&lt;/a&gt;


/&gt;<br><br>ä»¥ä¸‹ãŒaggregation-awareãªRLã‚’å®Ÿæ–½ã—ãŸå ´åˆã¨ã€é€šå¸¸ã®RL, promptingã®ã¿ã«ã‚ˆã‚‹å ´åˆã®æ€§èƒ½ã®è¡¨ã—ã¦ã„ã‚‹ã€‚å…¨ä½“ã‚’é€šã˜ã¦aggregation-awareãªRLã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ãŸã ã—ã€AIMEã«é–¢ã—ã¦ã ã‘ã¯é€šå¸¸ã®promptingã«ã‚ˆã‚‹RSAã®æ€§èƒ½ãŒè‰¯ã„ã€‚ãªãœã ã‚ã†ã‹ï¼Ÿè€ƒå¯Ÿã¾ã§æ·±ãèª­ã‚ã¦ã„ãªã„ã®ã§è«–æ–‡ä¸­ã«è€ƒå¯ŸãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚<br>&lt;img width="1026" height="547" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/146ab6a3-58c2-4a7f-aa84-978a5180c8f3"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/146ab6a3-58c2-4a7f-aa84-978a5180c8f3"&lt;/a&gt;


/&gt;</p>
<p>RLOO:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3009" target="_blank" rel="noopener noreferrer">[Paper Note] Back to Basics: Revisiting REINFORCE Style Optimization for Learning   from Human Feedback in LLMs, Arash Ahmadian+, ACL'24, 2024.02</a>
</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/siddarthv66/status/1971757612845670585?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>concurrent work:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2729" target="_blank" rel="noopener noreferrer">[Paper Note] The Majority is not always right: RL training for solution aggregation, Wenting Zhao+, arXiv'25</a>
</p>
<p>ã‚ã‚ã›ã¦èª­ã¿ãŸã„:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2346" target="_blank" rel="noopener noreferrer">[Paper Note] Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A   Perspective of Probability Theory, Yexiang Liu+, ACL'25 Outstanding Paper</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3004" target="_blank" rel="noopener noreferrer" class="title-link">When Speed Kills Stability: Demystifying RL Collapse from the Training-Inference Mismatch, Liu+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/richardyrli/status/1971560544974086263?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è¨“ç·´æ™‚ã®ã‚¨ãƒ³ã‚¸ãƒ³(fsdpç­‰)ã¨ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆæ™‚ã®ã‚¨ãƒ³ã‚¸ãƒ³(vLLMç­‰)ãŒã€OOVãªãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾ã—ã¦ï¼ˆç‰¹ã«tooluseã—ãŸå ´åˆã«ç”Ÿã˜ã‚„ã™ã„ï¼‰è‘—ã—ãç•°ãªã‚‹å°¤åº¦ã‚’å‰²ã‚Šå½“ã¦ã‚‹ãŸã‚å­¦ç¿’ãŒå´©å£Šã—ã€ãã‚Œã¯åˆ©ç”¨ã™ã‚‹GPUã«ã‚ˆã£ã¦ã‚‚å®‰å®šæ€§ãŒå¤‰åŒ–ã—ï¼ˆA100ã‚ˆã‚Šã‚‚L20, L20ã‚ˆã‚Šã‚‚H20)ã€tokenãƒ¬ãƒ™ãƒ«ã®Importtance Weightingã§ã¯é›£ã—ãã€Sequenceãƒ¬ãƒ™ãƒ«ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒå¿…è¦ã€ã¿ãŸã„ãªè©±ãªæ¨¡æ§˜ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2552" target="_blank" rel="noopener noreferrer">Your Efficient RL Framework Secretly Brings You Off-Policy RL Training, Yao+, 2025.08</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2299" target="_blank" rel="noopener noreferrer">[Paper Note] Group Sequence Policy Optimization, Chujie Zheng+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3001" target="_blank" rel="noopener noreferrer" class="title-link">Modular Manifolds, Jeremy Bernstein+, THINKING MACHINES, 2025.09</a>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1972792014954733896?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2999" target="_blank" rel="noopener noreferrer" class="title-link">Introducing LFM2: The Fastest On-Device Foundation Models on the Market, LiquidAI, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1943440891915481371?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LiquidAIã«ã‚ˆã‚‹edgeãƒ‡ãƒã‚¤ã‚¹å‘ã‘ã®Foundation Modelã€‚å“è³ªã€ã‚¹ãƒ”ãƒ¼ãƒ‰ã€ãƒ¡ãƒ¢ãƒªã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®ãƒãƒ©ãƒ³ã‚¹ã‚’æœ€é©ã«ã—ã¦ãŠã‚‹ã¨ã®ã“ã¨ã€‚ãŸã¨ãˆã°Qwenã¨æ¯”è¼ƒã—ã¦2å€ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã¨prefillé€Ÿåº¦ã¨ã®ã“ã¨ã€‚ã¾ãŸã€åŒã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ç¾¤ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã‚‰ã—ã„ã€‚<br>ä¸‹è¨˜ã‚°ãƒ©ãƒ•ã¯MMLU, IFEval,IFBENCH,GSM8K,MMMLUã§ã®è©•ä¾¡ã®å¹³å‡ã€‚ä»–ã«ã‚‚GPQA,MGSMã§ã‚‚è©•ä¾¡ã—ã¦ãŠã‚Šã€åŒã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”ã¹ã¦åŒç­‰ã‹å°‘ã—åŠ£ã‚‹ãã‚‰ã„ã€‚<br><br><img src="https://github.com/user-attachments/assets/7f841f30-2046-4ebc-8a64-0d47b1e2b7da" alt="image" loading="lazy"><br><br>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯RNNã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ã¦ãŠã‚Šã€å¾“æ¥ã®æ™‚é–“ãŒstepã”ã¨ã«ç™ºå±•ã™ã‚‹RNNã§ã¯ãªãã€é€£ç¶šæ™‚é–“ã‚’æ‰±ãˆã‚‹ã‚ˆã†ãªRNNã®å¤‰ç¨®ãªã‚ˆã†ã§ã‚ˆã‚ŠæŸ”è»Ÿã«æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã‚’æ‰±ãˆã‚‹ã‚ˆã†ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚‰ã—ã„ã€‚ã¾ãŸã€LIV Operatorã¨å‘¼ã°ã‚Œã‚‹å…¥åŠ›ã«å¿œã˜ã¦å‹•çš„ã«ç•°ãªã‚‹ç·šå½¢å¤‰æ›ã‚’å®Ÿæ–½ã™ã‚‹Operatorã‚’æ¡ç”¨ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ãŸã¨ãˆã°å…¥åŠ›ã«å¿œã˜ã¦ã€convolution, attention, recurrenceãªã©ã®operationãŒå¤‰åŒ–ã™ã‚‹ã€‚ã“ã‚Œã«åŸºã¥ã„ã¦ã€ã•ã¾ã–ã¾ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®NNã‚’å®šç¾©ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã§ã€æœ€é©ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¨¡ç´¢ã™ã‚‹ãŸã‚ã«STARã¨å‘¼ã°ã‚Œã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§Neural Architecture Searchã‚’å®Ÿæ–½ã—ãŸæ¨¡æ§˜ã€‚</p>
<p>ãƒ¡ãƒ¢ãƒªã«åˆ¶ç´„ãŒã‚ã‚‹ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹å‘ã‘ã«KVCacheä¸è¦ã§ç¾åœ¨ã®éš ã‚ŒçŠ¶æ…‹ã®ã¿ã‚’ä¿æŒã™ã‚Œã°è‰¯ã„RNNãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã™ã‚‹ã®ã¯ç†ã«é©ã£ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/DocParser.html" target="_blank" rel="noopener noreferrer">#DocParser</a>
<span class="issue_date">Issue Date: 2025-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2998" target="_blank" rel="noopener noreferrer" class="title-link">Liquid Nanos, LiquidAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>blog:


<a href="https://www.liquid.ai/blog/introducing-liquid-nanos-frontier-grade-performance-on-everyday-devices" target="_blank" rel="noopener noreferrer">https://www.liquid.ai/blog/introducing-liquid-nanos-frontier-grade-performance-on-everyday-devices</a>


</p>
<p>ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã«350Mã®æ—¥è‹±ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã‚‹â€¦ã ã¨ï¼ï¼Ÿ</p>
<p>ã‚¿ã‚¹ã‚¯ã‚¹ãƒšã‚·ãƒ•ã‚£ãƒƒã‚¯ãªedgeãƒ‡ãƒã‚¤ã‚¹å‘ã‘ã®SLMç¾¤ã€‚<br><br>ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã€‚éæ§‹é€ ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã€æ—¥è‹±ç¿»è¨³ã€RAG, tooluse, Math, ãƒ•ãƒ©ãƒ³ã‚¹èªã®ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã€‚ã“ã‚Œã¾ã§ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ã«ç‰¹åŒ–ã—ãŸMTã¨ã‹ã¯ã‚ˆãè¦‹å—ã‘ã‚‰ã‚ŒãŸãŒã€è‰²ã€…ãªã‚¿ã‚¹ã‚¯ã®SLMãŒå‡ºã¦ããŸã€‚<br><img src="https://github.com/user-attachments/assets/bb19f5f0-f20f-4e51-8ecc-75c7b425b60f" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1971359534883946709?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LFM2ã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2999" target="_blank" rel="noopener noreferrer">Introducing LFM2: The Fastest On-Device Foundation Models on the Market, LiquidAI, 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-09-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2994" target="_blank" rel="noopener noreferrer" class="title-link">æ§˜ã€…ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã«ãŠã‘ã‚‹ LLM ã® Self-Attention ã® Query ã¨ Key ã®åˆ†æ, ABEJA Tech Blog, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/abeja_tech/status/1971073813279621253?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä»¥ä¸‹ã®ç ”ç©¶ã‚’å‚è€ƒã«åˆ†æã—ã¦ã„ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2995" target="_blank" rel="noopener noreferrer">[Paper Note] Massive Values in Self-Attention Modules are the Key to Contextual   Knowledge Understanding, Mingyu Jin+, ICML'25, 2025.02</a>
</p>
<p>RoPEã¯ä»¥ä¸‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1310" target="_blank" rel="noopener noreferrer">RoFormer: Enhanced Transformer with Rotary Position Embedding, Jianlin Su+, N/A, Neurocomputing, 2024</a>
</p>
<p>Massive Valueã¯transformerã®Q,Kã®æ´»æ€§å€¤ã«ç¾ã‚Œã‚‹æ¥µç«¯ã«å¤§ããªå€¤ã®ã“ã¨ã§ã€Massive Valueã¯æ–‡è„ˆçš„ãªçŸ¥è­˜ã®ç†è§£ã«ãŠã„ã¦é‡è¦ã¨ã®ã“ã¨ï¼ˆMassive Valueã‚’ç ´å£Šã™ã‚‹ã¨æ–‡è„ˆç†è§£ãŒé‡è¦ãªã‚¿ã‚¹ã‚¯ã®ã‚¹ã‚³ã‚¢ã¯è‘—ã—ãä½ä¸‹ã—ãŸãŒã€ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãªçŸ¥è­˜ãŒé‡è¦ãªã‚¿ã‚¹ã‚¯ã¯æ€§èƒ½ãŒå°‘ã—ä½ä¸‹ã™ã‚‹ã®ã¿ã€ã‹ã¤éMassive Valueã‚’ç ´å£Šã—ã¦ã‚‚å¤§ããªå¤‰åŒ–ã¯ç„¡ã‹ã£ãŸãŸã‚ï¼‰ã€‚ã¾ãŸMassive Valueã¯RoPEã‚’ä½¿ã£ãŸãƒ¢ãƒ‡ãƒ«ã®ã¿Q, Kã®ç‰¹å®šã®æ¬¡å…ƒã«ã®ã¿é›†ä¸­ã—ã¦å‡ºç¾ã™ã‚‹ã€‚ã“ã‚Œã¯RoPEã§ã¯å›è»¢è¡Œåˆ—ã‚’Q, Kã«ã®ã¿é©ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã«èµ·å› ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŒã€å›è»¢è¡Œåˆ—ã®ç©ã®å‰å¾Œã§ã‚‚Massive ValueãŒå‡ºç¾ã™ã‚‹ã“ã¨ã¯å¤‰ã‚ã‚‰ãªã„ã“ã¨ã‹ã‚‰ã€å›è»¢è¡Œåˆ—ãã®ã‚‚ã®ã«èµ·å› ã™ã‚‹ã‚‚ã®ã¨ã„ã†ã‚ˆã‚Šã€å›è»¢è¡Œåˆ—ãŒã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«çµ„ã¿è¾¼ã¾ã‚Œã‚‹ã“ã¨ã§çµæœçš„ã«å­¦ç¿’ã•ã‚Œã‚‹ã‚‚ã®ãªã®ã§ã¯ãªã„ã‹ã€ã¨ã„ã†æ„Ÿã˜ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2979" target="_blank" rel="noopener noreferrer" class="title-link">CWM: An Open-Weights LLM for Research on Code Generation with World Models, Copet+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yuxiangwei9/status/1970965218839974250?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>World Modelã¨éŠ˜æ‰“ã£ã¦ã‚ã‚‹ãŒã€ä¸€èˆ¬çš„ãªCVåˆ†é‡ã§ã®World Modelã§ã¯ãªãã€python ã‚„bashç­‰ã®å®Ÿè¡Œã‚’ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã¨ã—ã¦ä»®æƒ³çš„ã«ãƒˆãƒ¬ãƒ¼ã‚¹ã§ãã‚‹ã‚ˆã†ã«mid trainingã•ã‚Œã¦ã„ã‚‹ï¼ˆå¤§é‡ã®å®Ÿãƒˆãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ï¼‰ã®ã§ã€World Modelã¨éŠ˜æ‰“ãŸã‚Œã¦ã„ã‚‹æ¨¡æ§˜ï¼Ÿ<br><br><img src="https://github.com/user-attachments/assets/bbed358e-ad8d-4b6c-bd6b-39d23457a9cb" alt="image" loading="lazy"></p>
<p>GRPOã«å¯¾ã™ã‚‹ãƒ¢ãƒ€ãƒ³ãªtweakãŒã¾ã¨ã¾ã£ã¦ã„ã‚‹æ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1972268402732617968?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>DeepSeek-R1ã§ææ¡ˆã•ã‚Œã¦ã‹ã‚‰ç´°ã‹ãªèª¿æ•´ãŒé‡ã­ã‚‰ã‚Œã¦æ¥ãŸã€‚</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2965" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-Max: Just Scale it, Qwen Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1970599097297183035?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¾åœ¨ã¯non-thinkingãƒ¢ãƒ‡ãƒ«ã®ã¿ã®ã‚ˆã†ã ãŒthinkingãƒ¢ãƒ‡ãƒ«ã‚‚å­¦ç¿’ä¸­ã§ã€GPQA, HMMT, AIME25ã§ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã®ã¿æ²è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚</p>
<p>HMMTã¨ã„ã†ã®ã¯ä»¥ä¸‹ãªæ¨¡æ§˜:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2967" target="_blank" rel="noopener noreferrer">HMMT. HMMT 2025, 2025.09</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/Cultural.html" target="_blank" rel="noopener noreferrer">#Cultural</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2959" target="_blank" rel="noopener noreferrer" class="title-link">Nemotron-Personas-Japan: Synthesized Data for Sovereign AI, Nvidia, 2025.09</a>
<span class="snippet"><span>Comment</span><p>dataset:


<a href="https://huggingface.co/datasets/nvidia/Nemotron-Personas-Japan" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/nvidia/Nemotron-Personas-Japan</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nvidiajapan/status/1970647697427140885?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<a class="button" href="articles/Editing.html" target="_blank" rel="noopener noreferrer">#Editing</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2949" target="_blank" rel="noopener noreferrer" class="title-link">Qwen-Image-Edit-2509, Qwen Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ:


<a href="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/Qwen_Image.pdf" target="_blank" rel="noopener noreferrer">https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/Qwen_Image.pdf</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2948" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3â€‘LiveTranslate: Realâ€‘Time Multimodal Interpretation â€” See It, Hear It, Speak Itï¼, Qwen Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1970565641594867973?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2947" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-Guard, Qwen Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1970510193537753397?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2945" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-VL, Qwen Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1970594923503391182?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>DocVQAã®ã‚ªãƒ©ã‚¯ãƒ«ã¯ãƒ©ãƒ™ãƒ«ãƒã‚¤ã‚ºã¨æ›–æ˜§æ€§ã®è¦³ç‚¹ã‹ã‚‰94--95ã¨ã„ã†ä¸»å¼µ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vikhyatk/status/1970585801600967009?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Omni.html" target="_blank" rel="noopener noreferrer">#Omni</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2942" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-Omni, Qwen Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ:


<a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/assets/Qwen3_Omni.pdf" target="_blank" rel="noopener noreferrer">https://github.com/QwenLM/Qwen3-Omni/blob/main/assets/Qwen3_Omni.pdf</a>


</p>
<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1970181599133344172?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1970307898170605937?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mervenoyann/status/1970444546216444022?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¥æœ¬èªã§éŸ³å£°toéŸ³å£°å¯èƒ½:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/asap2650/status/1970185195556086032?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2939" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-Next-series-FP8, Qwen Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1970052154330353857?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2935" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-V3.1-Terminus, deepseek-ai, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1970127354120077643?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>vLLMã§ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹æ™‚ã®tips:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vllm_project/status/1970814441718755685?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2928" target="_blank" rel="noopener noreferrer" class="title-link">LoRAã®é€²åŒ–ï¼šåŸºç¤ã‹ã‚‰æœ€æ–°ã®LoRA-Proã¾ã§ , æ¾å°¾ç ”ç©¶æ‰€ãƒ†ãƒƒã‚¯ãƒ–ãƒ­ã‚°, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/matsuoinstitute/status/1969958580057964986?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2929" target="_blank" rel="noopener noreferrer">[Paper Note] LoRA-Pro: Are Low-Rank Adapters Properly Optimized?, Zhengbo Wang+, ICLR'25, 2024.07</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1245" target="_blank" rel="noopener noreferrer">LoRA+: Efficient Low Rank Adaptation of Large Models, Soufiane Hayou+, N/A, ICML'24</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2922" target="_blank" rel="noopener noreferrer" class="title-link">LongCat-Flash-Thinking, meituan-longcat, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/meituan_longcat/status/1969823529760874935?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1969897602448539790?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2620" target="_blank" rel="noopener noreferrer">LongCat-Flash-Chat, meituan-longcat, 2025.08</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2932" target="_blank" rel="noopener noreferrer">[Paper Note] Libra: Assessing and Improving Reward Model by Learning to Think, Meng Zhou+, arXiv'25, 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2917" target="_blank" rel="noopener noreferrer" class="title-link">Grok 4 Fast, xAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å¯¾ã™ã‚‹è©•ä¾¡çµæœä»¥å¤–ã®æƒ…å ±ã¯ã»ã¼è¨˜è¿°ã•ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ï¼ˆRLä½¿ã„ã¾ã—ãŸç¨‹åº¦ï¼‰</p>
<p>Artificial Analysisã«ã‚ˆã‚‹è©•ä¾¡:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1969180023107305846?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚³ã‚¹ãƒˆæ€§èƒ½æ¯”ã®æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kimmonismus/status/1969333210975756697?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2910" target="_blank" rel="noopener noreferrer" class="title-link">Ring-flash-2.0, inclusionAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/adinayakup/status/1969024994903744712?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>-  Ling-flash-2.0-baseã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã€100B-A6.1 params<br>- å„ç¨®ãƒ™ãƒ³ãƒã§gpt-oss-120Bã¨åŒç­‰ä»¥ä¸Šã€‚denseãª40Bãƒ¢ãƒ‡ãƒ«ï¼ˆQwen-32B, Seed-OSS-36B-Instructï¼‰ã‚„proprietary modelã§ã‚ã‚‹Gemini-2.5-Flashã¨æ¯”è¼ƒã—ã¦åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ <br>&lt;img width="772" height="777" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/f5aed972-e2f3-49e8-80fa-70e6ee110512"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/f5aed972-e2f3-49e8-80fa-70e6ee110512"&lt;/a&gt;


/&gt;</p>
<p>- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£<br>  - Multi Token Prediction <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2904" target="_blank" rel="noopener noreferrer">[Paper Note] Multi-Token Prediction Needs Registers, Anastasios Gerontopoulos+, NeurIPS'25</a>
 <br>  - 1/32 experts activation ratio<br>  - gpt-oss-120Bã¯4 expertsãŒactiveã ãŒã€ã“ã¡ã‚‰ã¯1 shared + 8 experts<br>  - attention headæ•°ã¯gpt-oss-120Bã®64ã®1/2ã§ã‚ã‚‹32<br>  - group size 4ã®GQA <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
<br>  - gpt-oss-120Bã®Embed dim=2880ã«å¯¾ã—ã¦å¤§ãã‚ã®Embed dim=4096<br>  - æœ€åˆã®1ãƒ–ãƒ­ãƒƒã‚¯ã ã‘ã€MoEã®ä»£ã‚ã‚Šã«hidden_size=9216ã®FNNãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹<br><br>&lt;img width="661" height="599" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/1f3bf7c9-7997-4fbb-95b5-d2f1d8b10b0a"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/1f3bf7c9-7997-4fbb-95b5-d2f1d8b10b0a"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2893" target="_blank" rel="noopener noreferrer" class="title-link">MagicBench, ByteDance-Seed, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1968972092445008183?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‹±æ–‡ã¨ä¸­æ–‡ä¸¡æ–¹å­˜åœ¨ã™ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2858" target="_blank" rel="noopener noreferrer" class="title-link">Magistral-Small-2509, MistralAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mistralai/status/1968670593412190381?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/DocParser.html" target="_blank" rel="noopener noreferrer">#DocParser</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2848" target="_blank" rel="noopener noreferrer" class="title-link">granite-docling-258M, IBM, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1968433933210763440?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Apache 2.0, è¨€èªã¯è‹±èªã®ã¿</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2845" target="_blank" rel="noopener noreferrer" class="title-link">Ling-flash-2.0, inclusionAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>100B-A6.1B, 20Tãƒˆãƒ¼ã‚¯ãƒ³ã§å­¦ç¿’, SFT+ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸RL, 40Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§SoTA, 200+tokens/secã®ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é€Ÿåº¦<br><br><img src="https://github.com/user-attachments/assets/9da60c24-4734-4711-b9cc-7915d0caa3b4" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1968421451708440833?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/antlingagi/status/1968323481730433439?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/TTS.html" target="_blank" rel="noopener noreferrer">#TTS</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2839" target="_blank" rel="noopener noreferrer" class="title-link">VoxCPM-0.5B, openbmb, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1967981041815044604?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2703" target="_blank" rel="noopener noreferrer">[Paper Note] MiniCPM4: Ultra-Efficient LLMs on End Devices, MiniCPM Team+, arXiv'25</a>
<br><br>ã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã¨ã™ã‚‹TTS</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2829" target="_blank" rel="noopener noreferrer" class="title-link">Tongyi DeepResearch: A New Era of Open-Source AI Researchers, Tongyi Lab, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ali_tongyilab/status/1967988004179546451?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯: <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1730" target="_blank" rel="noopener noreferrer">[Paper Note] Humanity's Last Exam, Long Phan+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2451" target="_blank" rel="noopener noreferrer">[Paper Note] BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents, Jason Wei+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1158" target="_blank" rel="noopener noreferrer">GAIA: a benchmark for General AI Assistants, GrÃ©goire Mialon+, N/A, arXiv'23</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2466" target="_blank" rel="noopener noreferrer">[Paper Note] xbench: Tracking Agents Productivity Scaling with Profession-Aligned
  Real-World Evaluations, Kaiyuan Chen+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2767" target="_blank" rel="noopener noreferrer">[Paper Note] SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric
  Knowledge, Lukas Haas+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2851" target="_blank" rel="noopener noreferrer">[Paper Note] WebWalker: Benchmarking LLMs in Web Traversal, Jialong Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2852" target="_blank" rel="noopener noreferrer">[Paper Note] Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented   Generation, Satyapriya Krishna+, NAACL'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2853" target="_blank" rel="noopener noreferrer">[Paper Note] BrowseComp-ZH: Benchmarking Web Browsing Ability of Large Language
  Models in Chinese, Peilin Zhou+, arXiv'25</a>
</p>
<p>é–¢é€£ç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2851" target="_blank" rel="noopener noreferrer">[Paper Note] WebWalker: Benchmarking LLMs in Web Traversal, Jialong Wu+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2854" target="_blank" rel="noopener noreferrer">[Paper Note] WebDancer: Towards Autonomous Information Seeking Agency, Jialong Wu+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2855" target="_blank" rel="noopener noreferrer">[Paper Note] WebSailor: Navigating Super-human Reasoning for Web Agent, Kuan Li+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2856" target="_blank" rel="noopener noreferrer">[Paper Note] WebShaper: Agentically Data Synthesizing via Information-Seeking
  Formalization, Zhengwei Tao+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2424" target="_blank" rel="noopener noreferrer">[Paper Note] WebWatcher: Breaking New Frontier of Vision-Language Deep Research Agent, Xinyu Geng+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2830" target="_blank" rel="noopener noreferrer">[Paper Note] WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon
  Agents, Zile Qiao+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2834" target="_blank" rel="noopener noreferrer">[Paper Note] ReSum: Unlocking Long-Horizon Search Intelligence via Context
  Summarization, Xixi Wu+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2833" target="_blank" rel="noopener noreferrer">[Paper Note] WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for
  Open-Ended Deep Research, Zijian Li+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2857" target="_blank" rel="noopener noreferrer">[Paper Note] WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic
  Data and Scalable Reinforcement Learning, Kuan Li+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2832" target="_blank" rel="noopener noreferrer">[Paper Note] Scaling Agents via Continual Pre-training, Liangcai Su+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2831" target="_blank" rel="noopener noreferrer">[Paper Note] Towards General Agentic Intelligence via Environment Scaling, Runnan Fang+, arXiv'25</a>
 </p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2822" target="_blank" rel="noopener noreferrer" class="title-link">WildGuardTestJP: æ—¥æœ¬èªã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®é–‹ç™º, SB Intuitions, 2025.09</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/datasets/sbintuitions/WildGuardTestJP" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/sbintuitions/WildGuardTestJP</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sbintuitions/status/1967853532826177949?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ—¥æœ¬èªå‘ã‘ã«ï¼ˆSeed-X-PPO-7B <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2252" target="_blank" rel="noopener noreferrer">Seed-X-Instruct-7B, ByteDance-Seed, 2025.07</a>
 ã‚’ç”¨ã„ã¦[^1])ç¿»è¨³ã—ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚gpt-oss-120Bã«ã‚ˆã‚‹LLM-as-a-Judgeã‚’ç”¨ã„ã¦ç¿»è¨³ã®è³ªã‚’åˆ¤æ–­ã—ã€è³ªãŒä½ã„ã¨åˆ¤æ–­ã•ã‚ŒãŸã‚‚ã®ã¯ä»–ã®LLMã®ã‚ˆã‚Šé«˜ã„å“è³ªã¨åˆ¤æ–­ã•ã‚ŒãŸç¿»è¨³ã§ç½®æ›ã™ã‚‹ãªã©ã—ã¦ã„ã‚‹ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2824" target="_blank" rel="noopener noreferrer">[Paper Note] WildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks,   and Refusals of LLMs, Seungju Han+, NeurIPS'24</a>
<br><br>[^1]: plamo-2-translateã¨æ¯”è¼ƒã—ã¦ã€Plamoã®æ–¹ãŒæµæš¢ã ã£ãŸãŒSeedXã®æ–¹ãŒå¿ å®Ÿæ€§ãŒé«˜ã„æ¨å¯Ÿã•ã‚ŒãŸãŸã‚ã“ã¡ã‚‰ã‚’æ¡ç”¨ã—ãŸã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2821" target="_blank" rel="noopener noreferrer" class="title-link">Holo1.5 - Open Foundation Models for Computer Use Agents, H Company, 2025.09</a>
<span class="snippet"><span>Comment</span><p>7Bã®ã¿Apache 2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã€‚3Bã¯Qwenã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚’ç¶™æ‰¿ã—ã€72Bã¯non-commercialãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚‰ã—ã„</p>
<p>ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã¨ãƒ–ãƒ­ã‚°ã«ã‚ˆã‚‹ã¨ä¸‹è¨˜ãƒ¢ãƒ‡ãƒ«ç¾¤ã¨Sonnet 4 ã‚ˆã‚Šã‚‚Computer Useé–¢é€£ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯(GUIä¸Šã§ã®ä½ç½®ã‚’ç‰¹å®šã™ã‚‹UI Localizationã¨Screen Contentã®ç†è§£ãŠã‚ˆã³QAé–¢é€£ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯)ã§é«˜æ€§èƒ½ã¨ã®ã“ã¨:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2447" target="_blank" rel="noopener noreferrer">[Paper Note] UI-Venus Technical Report: Building High-performance UI Agents with RFT, Zhangxuan Gu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1896" target="_blank" rel="noopener noreferrer">Introducing UI-TARS-1.5, ByteDance, 2025.04</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1835" target="_blank" rel="noopener noreferrer">Qwen2.5-VL-32B-Instruct, Qwen Team, 2025.03</a>
</p>
<p>ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ã¨open sourceãƒ‡ãƒ¼ã‚¿ã®mixã¨ã€åˆæˆãƒ‡ãƒ¼ã‚¿ã€äººæ‰‹ã§ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€SFT-&gt;GRPOã«ã‚ˆã£ã¦å­¦ç¿’ã•ã‚ŒãŸã¨ã ã‘æ›¸ã‹ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2803" target="_blank" rel="noopener noreferrer" class="title-link">Online versus Offline RL for LLMs A deep dive into the online-offline performance gap in LLM alignment..., CAMERON R. WOLFE, PH.D., 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cwolferesearch/status/1965088925510520853?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2730" target="_blank" rel="noopener noreferrer">[Paper Note] Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study, Shusheng Xu+, ICML'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2090" target="_blank" rel="noopener noreferrer">[Paper Note] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy   Data, Fahim Tajwar+, ICML'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2731" target="_blank" rel="noopener noreferrer">[Paper Note] Unpacking DPO and PPO: Disentangling Best Practices for Learning from   Preference Feedback, Hamish Ivison+, NeurIPS'24</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2802" target="_blank" rel="noopener noreferrer" class="title-link">OpenManus, Liang+, FoundationAgents, 2025.04</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2801" target="_blank" rel="noopener noreferrer" class="title-link">OpenDeepResearch, LangChain, 2025.07</a>
<span class="snippet"><span>Comment</span><p>blog: 


<a href="https://blog.langchain.com/open-deep-research/" target="_blank" rel="noopener noreferrer">https://blog.langchain.com/open-deep-research/</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2800" target="_blank" rel="noopener noreferrer" class="title-link">Kimi-Researcher End-to-End RL Training for Emerging Agentic Capabilities, MoonshotAI, 2025.06</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2798" target="_blank" rel="noopener noreferrer" class="title-link">MobileLLM-R1-950M, Meta, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1966669725389168823?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã‚’è¦‹ã‚‹ã¨ã€optimizerã‚„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®šã€pre/mid/post trainingã«ãŠã‘ã‚‹å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨DavaMixã«ã¤ã„ã¦ç°¡æ½”ã«è¨˜è¿°ã•ã‚Œã¦ãŠã‚Šã€ãƒ¬ã‚·ãƒ”ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ç´ æ™´ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2797" target="_blank" rel="noopener noreferrer" class="title-link">Cosmopedia: how to create large-scale synthetic data for pre-training, Allal+ï¼ˆHuggingFaceï¼‰, 2024.03</a>
<span class="snippet"><span>Comment</span><p>cosmopedia dataset:


<a href="https://huggingface.co/datasets/HuggingFaceTB/cosmopedia" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/HuggingFaceTB/cosmopedia</a>


</p>
<p>å¤§éƒ¨åˆ†ã‚’åˆæˆãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ãŸPhi-1.5(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1039" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need II: phi-1.5 technical report, Yuanzhi Li+, N/A, arXiv'23</a>
)ã®ãƒ‡ãƒ¼ã‚¿åˆæˆã®ãƒ¬ã‚·ãƒ”ã®è©³ç´°ã¯æ˜ã‹ã•ã‚Œã¦ãŠã‚‰ãšã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è‡ªä½“ã‚‚å…¬é–‹ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’å—ã‘ã€äº‹å‰å­¦ç¿’ã§åˆ©ç”¨å¯èƒ½ãªæ•°ç™¾Mã‚µãƒ³ãƒ—ãƒ«ã®åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ãƒ¬ã‚·ãƒ”ã¯ãªã‚“ãªã®ã‹ï¼Ÿã‚’æ¢ã£ãŸè©±ã€‚<br><br>æœ€çµ‚çš„ã«ã€30Mã®promptã‚’prompt engineeringã‚’Mixtral-8x7B-Instruct-v0.1ã‚’é€šã˜ã¦ä½œæˆã—ã€é«˜å“è³ªãªpretrainingã®ãŸã‚ã®åºƒç¯„ãªãƒˆãƒ”ãƒƒã‚¯ã®æ–‡æ›¸ç¾¤ã‚’ä½œæˆã€‚åˆæˆã•ã‚ŒãŸå†…å®¹ã®é‡è¤‡ã¯1%æœªæº€ã€‚<br><br>Phi-1.5ã®è«–æ–‡ã®è¨˜è¿°ã«åŸºã¥ãã¨ã€20k topicsã‚’seedã¨ã—æ–°ãŸãªsynthetic dataã‚’ä½œæˆã€web sampleã‚’æ´»ç”¨ã—ã¦å¤šæ§˜æ€§ã‚’æ‹…ä¿ã—ãŸã€ã¨ã„ã†è¨˜è¿°ãŒã‚ã‚‹ã€‚ã“ã‚Œã«åŸºã¥ãã¨ã€ä»®ã«1ãƒ•ã‚¡ã‚¤ãƒ«ã®é•·ã•ã‚’1000 tokenã§ã‚ã‚‹ã¨ä»®å®šã™ã‚‹ã¨ã€20Mã®promptãŒæ´»ç”¨ã•ã‚ŒãŸã“ã¨ã«ãªã‚‹ã€‚ã—ã‹ã—ãªãŒã‚‰ã€web sampleã‚’çµ„ã¿åˆã‚ã›ã‚‹æ–¹æ³•ã¨ã€å¤šæ§˜æ€§ã‚’å¢—ã‚„ã™æ–¹æ³•ãŒã‚¯ãƒªã‚¢ã§ã¯ãªã‹ã£ãŸã€‚<br><br>Cosmopediaã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã—ã¦ã¯ã€2ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒã‚ã‚‹ã€‚ã¾ãš curated educational sources (Khan Academy, OpenStax, WikiHow, Stanford courses)ã‚’åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã§ã€ã“ã‚Œã‚‰ã®å…¨ã¦ã®ãƒ¦ãƒ‹ãƒƒãƒˆã‚’åˆè¨ˆã—ã¦ã‚‚260kç¨‹åº¦ã§ã‚ã£ãŸã€‚ã“ã‚Œã§ã¯åˆ°åº•20Mã«ã¯å±Šã‹ãªã„ãŸã‚ã€ç”Ÿæˆã™ã‚‹æ–‡æ›¸ã® `style` ã¨ `audience` ã«å¹…ã‚’æŒãŸã›ã‚‹ã“ã¨ã§ã€promptã®æ•°ã‚’å¢—ã‚„ã—ãŸã€‚<br>å…·ä½“çš„ã«ã¯ã€styleã¨ã—ã¦ã€academic textbook / blog post / wikihow articles ã®3ç¨®é¡ã€audienceã¨ã—ã¦ young children / high school students / college students / researchers ã®4ç¨®é¡ã‚’ç”¨æ„ã—ãŸã€‚ã“ã®ã¨ãã€å˜ã«promptä¸­ã§ç‰¹å®šã®audience/styleã§è¨˜è¿°ã™ã‚‹ã‚ˆã†æŒ‡ç¤ºã‚’ã—ã¦ã‚‚ã€åŒã˜ã‚ˆã†ãªå†…å®¹ã—ã‹å‡ºåŠ›ã•ã‚Œãªã„èª²é¡ŒãŒã‚ã£ãŸãŸã‚ã€prompt engineeringã«ã‚ˆã£ã¦ã€ã‚ˆã‚Šå…·ä½“çš„ãªæŒ‡ç¤ºã‚’åŠ ãˆã‚‹ã“ã¨ã§è§£æ±ºï¼ˆFigure3ï¼‰ã€‚<br><br>ç¶šã„ã¦ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯web dataã‚’æ´»ç”¨ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€åé›†ã•ã‚ŒãŸweb samplesã‚’145ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«åˆ†é¡ã—ã€å„ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«10å€‹ã®ãƒ©ãƒ³ãƒ€ãƒ ãªã‚µãƒ³ãƒ—ãƒ«ã‚’æŠ½å‡ºã—ã€Mixtralã«ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰å…±é€šã®ãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡ºã•ã›ã‚‹ã“ã¨ã§ã‚¯ãƒ©ã‚¹ã‚¿ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’å¾—ã‚‹ã€‚<br>ãã®å¾Œä¸é©åˆ‡ãªãƒˆãƒ”ãƒƒã‚¯ã¯é™¤å¤–ï¼ˆe.g., ã‚¢ãƒ€ãƒ«ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„, ã‚´ã‚·ãƒƒãƒ—ç­‰ï¼‰ã€‚ãã®å¾Œã€ã‚¯ãƒ©ã‚¹ã‚¿ã®web sampleã¨ãƒˆãƒ”ãƒƒã‚¯ã®åŒæ–¹ã‚’promptã«ä¸ãˆã¦é–¢é€£ã™ã‚‹textbookã‚’ç”Ÿæˆã•ã›ã‚‹promptã‚’ä½œæˆ (Figure 4)ã€‚ã“ã®ã¨ãã€ãƒˆãƒ”ãƒƒã‚¯ãƒ©ãƒ™ãƒ«ã®ç”ŸæˆãŒã†ã¾ãã„ã£ã¦ã„ãªã„å¯èƒ½æ€§ã‚‚è€ƒæ…®ã—ã€ãƒˆãƒ”ãƒƒã‚¯ã‚’givenã«ã—ãªã„promptã‚‚ç”¨æ„ã—ãŸã€‚æœ€çµ‚çš„ã«ã“ã‚Œã«ã‚ˆã‚Š23Mã®promptã‚’å¾—ãŸã€‚ã¾ãŸã€scientificãªå†…å®¹ã‚’å¢—ã‚„ã™ãŸã‚ã«ã€AutoMathText (æ•°å­¦ã«é–¢ã—ã¦åé›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ)ã‚‚åŠ ãˆãŸã€‚<br><br>ä¸Šè¨˜promptã§åˆæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ãŸã¨ã“ã‚ã€ãƒ¢ãƒ‡ãƒ«ã«common senseã‚„grade school educationã«ãŠã‘ã‚‹å…¸å‹çš„ãªçŸ¥è­˜ãŒæ¬ ã‘ã¦ã„ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ãŸãŸã‚ã€UltraChatã‚„OpenHermes2.5ã‹ã‚‰æ—¥å¸¸ã«é–¢ã™ã‚‹ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’æŠ½å‡ºã—ã¦seed dataã«åŠ ãˆãŸã€‚<br><br>ä¸‹è¨˜ãŒæœ€çµ‚çš„ãªseed-data/format/audienceã®åˆ†å¸ƒã¨ãªã‚‹ã€‚seed-dataã®å¤§éƒ¨åˆ†ã¯web-dataã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br>&lt;img width="866" height="513" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/f30beb80-e75c-466c-9c77-8080298869cc"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/f30beb80-e75c-466c-9c77-8080298869cc"&lt;/a&gt;


/&gt;<br><br>æœ€çµ‚çš„ã«åˆæˆãƒ‡ãƒ¼ã‚¿ã®ã†ã¡ã€10-gram overlapã«åŸºã¥ã„ã¦ã€contaminationã®ç–‘ã„ãŒã‚ã‚‹åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã®ã†ã¡ã€50%ã®sub-stringã¨ãƒãƒƒãƒã—ãŸæ–‡æ›¸ã¯é™¤å¤–ã™ã‚‹ã“ã¨ã§decontaminationã‚’å®Ÿæ–½ã€‚<br>ä¸‹è¡¨ãŒdecontaminationã®çµæœã§ã€()å†…ã®æ•°å­—ãŒãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°ã€‚decontaminationã‚’ã—ãªã‘ã‚Œã°ã“ã‚Œã‚‰ãŒå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«æ··å…¥ã—ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°æ€§èƒ½ã«ä¸‹é§„ã‚’ã¯ã‹ã›ã‚‹ã“ã¨ã«ãªã£ã¦ã—ã¾ã£ã¦ã„ãŸã“ã¨ã«ãªã‚‹ã€‚<br>&lt;img width="627" height="228" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/5ede5660-7305-41ad-bc56-1be03aec99f2"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/5ede5660-7305-41ad-bc56-1be03aec99f2"&lt;/a&gt;


/&gt;<br><br>1Bãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ãŸçµæœã€åŠåˆ†ç¨‹åº¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§TinyLlama 1.1Bã‚ˆã‚Šã‚‚é«˜ã„ã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚Qwen-1.5-1Bã‚„Phi-1.5ã«å¯¾ã—ã¦ã¯å…¨ä½“ã¨ã—ã¦ã‚¹ã‚³ã‚¢ã§ã¯è² ã‘ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ã“ã®ã“ã¨ã‚ˆã‚Šã€ã‚ˆã‚Šé«˜å“è³ªãªåˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆæ–¹æ³•ãŒã‚ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚<br>&lt;img width="551" height="384" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/536bfc9e-3093-43ba-b866-31f8e7073740"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/536bfc9e-3093-43ba-b866-31f8e7073740"&lt;/a&gt;


/&gt;</p>
<p>ä»¥å¾Œã€SmolLMæ§‹ç¯‰ã®éš›ã«Cosmopediaã®promptã«æŒ¿å…¥ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒˆãƒ”ãƒƒã‚¯ã”ã¨ã«ã‚ˆã‚Šé©åˆ‡ã«é¸æŠã™ã‚‹ï¼ˆæ–‡æ›¸ã‚’åˆæˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’Mixtralã‹ã‚‰ä»–ã®ãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›´ã—ã¦ã‚‚ã‚ã¾ã‚ŠåŠ¹æœãŒãªã‹ã£ãŸã¨ã®ã“ã¨ï¼‰ãªã©ã®æ”¹å–„ã‚’å®Ÿæ–½ã—ãŸCosmopedia v2ãŒæ§‹ç¯‰ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2796" target="_blank" rel="noopener noreferrer" class="title-link">GAUSS Benchmarking Structured Mathematical Skills for Large Language Models, Zhang+, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/banghuaz/status/1966529943514325227?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¾åœ¨ã®æ•°å­¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯å€‹ã€…ã®å•é¡Œã«å¯¾ã™ã‚‹å›ç­”ã®Accuracyã‚’æ¸¬ã‚‹ã‚‚ã®ã°ã‹ã‚Šã ãŒã€ã‚ã‚‹å•é¡Œã‚’è§£ãéš›ã«ã¯ã•ã¾ã–ã¾ãªã‚¹ã‚­ãƒ«ã‚’æ´»ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€è©•ä¾¡å¯¾è±¡ã®LLMãŒã©ã®ã‚ˆã†ãªã‚¹ã‚­ãƒ«ã«å¼·ãã€å¼±ã„ã®ã‹ã¨ã„ã£ãŸè§£åƒåº¦ãŒä½ã„ã¾ã¾ãªã®ã§ã€ãã†ã„ã£ãŸã‚¹ã‚­ãƒ«ã®ç¿’ç†Ÿåº¦åˆã„ã‚’æ¸¬ã‚Œã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸã€ã¨ã„ã†è©±ã«è¦‹ãˆã‚‹ã€‚</p>
<p>Knowledge Tracingã‚¿ã‚¹ã‚¯ãªã©ã§ã¯å•é¡Œã”ã¨ã«ã‚¹ã‚­ãƒ«ã‚¿ã‚°ã‚’ä»˜ä¸ã—ã¦ã€ã‚¹ã‚­ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¦ç¿’ç†Ÿåº¦ã‚’æ¸¬ã‚‹ã®ã§ã€å•é¡Œã®æ­£èª¤ã ã‘ã§ãªãã¦ã€ã‚¹ã‚­ãƒ«ãƒ™ãƒ¼ã‚¹ã§ã®ç¿’ç†Ÿåº¦ã‚’è¦‹ã‚‹ã“ã¨ã§èƒ½åŠ›ã‚’æ¸¬ã‚‹ã®ã¯è‡ªç„¶ãªæµã‚Œã«æ€ãˆã‚‹ã€‚ãã—ã¦ãã‚Œã¯æ•°å­¦ãŒæœ€ã‚‚å®Ÿæ–½ã—ã‚„ã™ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2784" target="_blank" rel="noopener noreferrer" class="title-link">Ring-mini-2.0, inclusionAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/antling20041208/status/1966138154454495379?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1966515481176662505?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2765" target="_blank" rel="noopener noreferrer">Ling V2, inclusionAI, 2025.09</a>
<br><br>ã‚’ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦Long CoT SFT, RLVR, RLHFã‚’å®Ÿæ–½ã—ãŸçµæœã€code, math, logic, scienceé–¢é€£ã®ãƒ™ãƒ³ãƒã§gpt-oss-20B(medium)ã‚’è¶…ãˆã¦ã„ã‚‹ã‚‰ã—ã„ã€‚<br><img src="https://github.com/user-attachments/assets/f228ba39-8c85-4f43-9bf6-6932681ff4cc" alt="image" loading="lazy"><br><br>Joint Trainingã¨æ›¸ã‹ã‚Œã¦ã„ã‚‹ãŒè©³ç´°ã¯ãªãã€ã‚ˆãã‚ã‹ã‚‰ãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2765" target="_blank" rel="noopener noreferrer" class="title-link">Ling V2, inclusionAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1965911832788451395?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2296" target="_blank" rel="noopener noreferrer">[Paper Note] Towards Greater Leverage: Scaling Laws for Efficient Mixture-of-Experts
  Language Models, Changxin Tian+, arXiv'25</a>
</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1965861299398783419?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>blog:


<a href="https://huggingface.co/blog/im0qianqian/ling-mini-2-fp8-mixed-precision-training-solution" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/im0qianqian/ling-mini-2-fp8-mixed-precision-training-solution</a>


<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/antlingagi/status/1968660440877085104?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2764" target="_blank" rel="noopener noreferrer" class="title-link">Context Engineering - Short-Term Memory Management with Sessions from OpenAI Agents SDK, OpenAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/schroneko/status/1965911753885360152?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Non-Determinism.html" target="_blank" rel="noopener noreferrer">#Non-Determinism</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2763" target="_blank" rel="noopener noreferrer" class="title-link">Defeating Nondeterminism in LLM Inference, Horace He in collaboration with others at Thinking Machines, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thinkymachines/status/1965826369721623001?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1965964901102530965?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>vLLMã«ãŠã„ã¦inferenceã‚’deterministicã«ã™ã‚‹æ–¹æ³•ãŒã€vLLMã®issue number 24583ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã®ã§å‚ç…§ã®ã“ã¨ã€‚</p>
<p>transformersã§ã®å®Ÿè£…ä¾‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gabriberton/status/1968559505966350705?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/Inference.html" target="_blank" rel="noopener noreferrer">#Inference</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2759" target="_blank" rel="noopener noreferrer" class="title-link">Checkpoint Engine, MoonshotAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zephyr_z9/status/1965788114884149465?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2755" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] K2-Think: A Parameter-Efficient Reasoning System, Institute of Foundation Models, Mohamed bin Zayed University of Artificial Intelligence, 2025.09</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/LLM360/K2-Think" target="_blank" rel="noopener noreferrer">https://huggingface.co/LLM360/K2-Think</a>


<br>code:<br>- 


<a href="https://github.com/MBZUAI-IFM/K2-Think-SFT" target="_blank" rel="noopener noreferrer">https://github.com/MBZUAI-IFM/K2-Think-SFT</a>


<br>- 


<a href="https://github.com/MBZUAI-IFM/K2-Think-Inference" target="_blank" rel="noopener noreferrer">https://github.com/MBZUAI-IFM/K2-Think-Inference</a>


<br><br>RLã¯verl+GRPOã§å®Ÿæ–½ã—ãŸã¨ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ãŒã€å½“è©²éƒ¨åˆ†ã®ã‚³ãƒ¼ãƒ‰ã®å…¬é–‹ã¯ã•ã‚Œã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ<br>RLã§åˆ©ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2070" target="_blank" rel="noopener noreferrer">[Paper Note] Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain  Perspective, Zhoujun Cheng+, arXiv'25</a>
</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1965713404418805806?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2752" target="_blank" rel="noopener noreferrer" class="title-link">ERNIE-4.5-21B-A3B-Thinking, Baidu, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/schroneko/status/1965586268290777529?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1965452580525408484?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ:


<a href="https://ernie.baidu.com/blog/publication/ERNIE_Technical_Report.pdf" target="_blank" rel="noopener noreferrer">https://ernie.baidu.com/blog/publication/ERNIE_Technical_Report.pdf</a>


</p>
<p>logical reasoning, æ•°å­¦ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€ç§‘å­¦ã€æ•°å­¦ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãªã©ã®åˆ†é‡ã§21B-A3Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚‚é–¢ã‚ã‚‰ãšDeepSeek-R1ã«é«˜ã„æ€§èƒ½ã‚’é”æˆã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã¯128kã€‚</p>
<p>ä½•ãŒæ±ºã‚æ‰‹ã§ã“ã®ã‚„ã†ãªå°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§é«˜ã„æ€§èƒ½ãŒå‡ºã‚‹ã®ã ã‚ã†ï¼Ÿãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã‚’èª­ã‚“ã ã‚‰ã‚ã‹ã‚‹ã‚“ã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Conversation.html" target="_blank" rel="noopener noreferrer">#Conversation</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2738" target="_blank" rel="noopener noreferrer" class="title-link">From Live Data to High-Quality Benchmarks: The Arena-Hard Pipeline, Li+, 2024.04</a>
<span class="snippet"><span>Comment</span><p>ArenaHardãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</p>
<p>ChatbotArenaã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã«è€ƒæ…®ã—ã¦å®šæœŸçš„ã«æŠ½å‡ºã•ã‚Œã‚‹é«˜å“è³ªãªreal worldã«è¿‘ã„ã®conversationãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚æŠ½å‡ºãƒ—ãƒ­ã‚»ã‚¹ã§ã¯promptã®å¤šæ§˜æ€§ã¨qualityãŒæ‹…ä¿ã•ã‚Œã‚‹å½¢ã§ã€200,000ã®ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®promptãŒæŠ½å‡ºã•ã‚Œãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‹ã‘ã‚‰ã‚Œã‚‹ã€‚<br>å¤šæ§˜æ€§ã¨ã„ã†è¦³ç‚¹ã§ã¯ã€å…¨ã¦ã®promptã‚’ OpenAI ã® `text-embedding-3-small` ã«ã‚ˆã£ã¦embeddingã«å¤‰æ›ã—ã€UMAPã«ã‚ˆã£ã¦æ¬¡å…ƒåœ§ç¸®ã‚’ã—ãŸå¾Œã«éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•ã«ã‚ˆã£ã¦ãƒˆãƒ”ãƒƒã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ã‚’å½¢æˆã™ã‚‹ã€‚å„ã‚¯ãƒ©ã‚¹ã‚¿ã«ã¯GPT-4-turboã§è¦ç´„ãŒä»˜ä¸ã•ã‚Œã€è¦ç´„ã‚’æ´»ç”¨ã—ã¦4000ã®ãƒˆãƒ”ãƒƒã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ã‚’é¸å®šã™ã‚‹ã€‚<br>ç¶šã„ã¦ã€å„ã‚¯ãƒ©ã‚¹ã‚¿ã«å«ã¾ã‚Œã‚‹ã‚¯ã‚¨ãƒªã¯å“è³ªãŒãƒãƒ©ãƒãƒ©ãªã®ã§ã€é«˜å“è³ªãªã‚‚ã®ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã«ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰LLM-as-a-Judgeï¼ˆGPT-3.5-Turbo, GPT-4-turboï¼‰ã‚’ç”¨ã„ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿæ–½ã™ã‚‹:<br>```<br>1. Specificity:Â Does the prompt ask for a specific output?<br>2. Domain Knowledge:Â Does the prompt cover one or more specific domains?<br>3. Complexity:Â Does the prompt have multiple levels of reasoning, components, or variables?<br>4. Problem-Solving:Â Does the prompt directly involve the AI to demonstrate active problem-solving skills?<br>5. Creativity:Â Does the prompt involve a level of creativity in approaching the problem?<br>6. Technical Accuracy:Â Does the prompt require technical accuracy in the response?<br>7. Real-world Application:Â Does the prompt relate to real-world applications?<br>```<br>ï¼ˆè¦³ç‚¹ã¯å…ƒè¨˜äº‹ã‹ã‚‰å¼•ç”¨ï¼‰<br><br>å„è¦³ç‚¹ã‚’æº€ãŸã—ã¦ã„ãŸã‚‰1ãƒã‚¤ãƒ³ãƒˆã¨ã—ã€å„promptã”ã¨ã«[0, 7]ã®ã‚¹ã‚³ã‚¢ãŒä»˜ä¸ã•ã‚Œã‚‹ã€‚å„ãƒˆãƒ”ãƒƒã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ã¯ã‚¯ãƒ©ã‚¹ã‚¿ä¸­ã®promptã®å¹³å‡ã‚¹ã‚³ã‚¢ã«ã‚ˆã£ã¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã•ã‚Œãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«æ´»ç”¨ã•ã‚Œã‚‹ã€‚<br>æœ€çµ‚çš„ã«250ã®high-qualityãªãƒˆãƒ”ãƒƒã‚¯ã‚¯ãƒ©ã‚¹ã‚¿ï¼ˆã™ãªã‚ã¡ã€ã‚¹ã‚³ã‚¢ãŒ&gt;=6ã®ã‚¯ãƒ©ã‚¹ã‚¿ï¼‰ãŒé¸ã°ã‚Œã€å„ã‚¯ãƒ©ã‚¹ã‚¿ã‹ã‚‰2ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦åˆè¨ˆ500å€‹ã®benchmark promptã‚’å¾—ã‚‹ã€‚<br>è©•ä¾¡ã‚’ã™ã‚‹éš›ã¯ã€è©•ä¾¡å¯¾è±¡ã®ãƒ¢ãƒ‡ãƒ«ã¨strong baselineï¼ˆGPT-4-0314ï¼‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ¯”è¼ƒã—ã€LLM-as-a-Judgeï¼ˆGPT-4-Turbo, Claude-3-Opusï¼‰ã«ã‚ˆã£ã¦ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã®å“è³ªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã€‚position biasã«é…æ…®ã™ã‚‹ãŸã‚ã«reaponseã®ä½ç½®ã‚’å…¥ã‚Œæ›¿ãˆã¦å„ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã«2å›è©•ä¾¡ã™ã‚‹ã®ã§ã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã¯1000å€‹ã®ãƒšã‚¢ãƒ¯ã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿ã¨ãªã‚‹ã€‚<br>ã“ã®ãƒšã‚¢ãƒ¯ã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿ã‚’bootstrap resamplingã—ãŸä¸Šã§ã€Bradley-Terryãƒ¢ãƒ‡ãƒ«ï¼ˆ=å‹æ•—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å¼·ã•ã‚’æ•°å€¤åŒ–ã™ã‚‹çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ï¼‰ã§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã§ã‚¹ã‚³ã‚¢ã‚’å¾—ã‚‹ã€‚<br><br>ArenaHardã¯MT Benchã‚ˆã‚Šã‚‚é«˜ã„è­˜åˆ¥åŠ›ã‚’ç²å¾—ã—ã¦ã„ã‚‹ã€‚<br><br>&lt;img width="981" height="833" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/a9bca283-31c2-4606-b59d-b7df60af43f1"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a9bca283-31c2-4606-b59d-b7df60af43f1"&lt;/a&gt;


/&gt;</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/623" target="_blank" rel="noopener noreferrer">ChatBot Arena, lmsys org, 2023.05</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/876" target="_blank" rel="noopener noreferrer">ChatBot Arenaã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2737" target="_blank" rel="noopener noreferrer" class="title-link">AlpacaEval, tatsu-lab, 2023.06</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2733" target="_blank" rel="noopener noreferrer" class="title-link">ã€JamC-QAã€: æ—¥æœ¬ã®æ–‡åŒ–ã‚„é¢¨ç¿’ã«ç‰¹åŒ–ã—ãŸè³ªå•å¿œç­”ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ§‹ç¯‰ãƒ»å…¬é–‹ï¼ˆå‰ç·¨ï¼‰, SB Intuitions, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sbintuitions/status/1965243405812011263?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¾Œç·¨ã‚‚å‚ç…§ã®ã“ã¨:


<a href="https://www.sbintuitions.co.jp/blog/entry/2025/09/09/113132" target="_blank" rel="noopener noreferrer">https://www.sbintuitions.co.jp/blog/entry/2025/09/09/113132</a>


</p>
<p>æ—¥æœ¬ã®æ–‡åŒ–ã€é¢¨ç¿’ã€é¢¨åœŸã€åœ°ç†ã€æ—¥æœ¬å²ã€è¡Œæ”¿ã€æ³•å¾‹ã€åŒ»ç™‚ã«é–¢ã™ã‚‹æ—¢å­˜ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ã‚ˆã‚Šã‚‚é›£æ˜“åº¦ãŒé«˜ã„QAã‚’äººæ‰‹ã«ã‚ˆã£ã¦ã‚¹ã‚¯ãƒ©ãƒƒãƒã‹ã‚‰ä½œæˆã—ãŸè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã€‚äººæ‰‹ã§ä½œæˆã•ã‚ŒãŸQAã«å¯¾ã—ã¦ã€8ç¨®é¡ã®å¼±ã„LLMï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å°ã•ã„æ—¥æœ¬èªLLMã‚’å«ã‚€ï¼‰ã®åŠæ•°ä»¥ä¸ŠãŒæ­£ã—ãå›ç­”ã§ããŸã‚‚ã®ã‚’é™¤å¤–ã€ãã®å¾Œã•ã‚‰ã«äººæ‰‹ã§ç¢ºèªã¨ã„ã£ãŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã‚’è¸ã‚“ã§ã„ã‚‹ã€‚è¨˜äº‹ä¸­ã¯äº‹ä¾‹ãŒéå¸¸ã«è±Šå¯Œã§èˆˆå‘³æ·±ã„ã€‚<br><br>å¾Œç·¨ã§ã¯å®Ÿéš›ã®è©•ä¾¡çµæœãŒè¨˜è¼‰ã•ã‚Œã¦ãŠã‚Šã€ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒã®æ—¥æœ¬èªLLMãŒé«˜ã„æ€§èƒ½ã‚’ç²å¾—ã—ã¦ãŠã‚Šã€Llama-Swallowãªã©ã®ç¶™ç¶šäº‹å‰å­¦ç¿’ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚‚é«˜ã„ã‚¹ã‚³ã‚¢ã‚’ç²å¾—ã—ã¦ã„ã‚‹ã€‚è©•ä¾¡æ™‚ã¯4-shotã§ãƒ‰ãƒ¡ã‚¤ãƒ³ã”ã¨ã«Examplarã¯å›ºå®šã—ã€greedy decodingã§è©•ä¾¡ã—ãŸã¨ã®ã“ã¨ã€‚</p>
<p>NLP'25:


<a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q2-18.pdf" target="_blank" rel="noopener noreferrer">https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q2-18.pdf</a>


</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1890" target="_blank" rel="noopener noreferrer">Non-Determinism of "Deterministic" LLM Settings, Berk Atil+, arXiv'24</a>
<br><br>ã®ã‚ˆã†ãªè©±ã‚‚ã‚ã‚‹ã®ã§ã€greedy decodingã ã‘ã§ãªãnucleus/temperature samplingã‚’è¤‡æ•°trialå®Ÿæ–½ã—ãŸå ´åˆã®æ€§èƒ½ã®å¹³å‡ã§ä½•ã‹å¤‰åŒ–ãŒã‚ã‚‹ã ã‚ã†ã‹ã€ã¨ã„ã†ç‚¹ãŒæ°—ã«ãªã£ãŸãŒã€ä¸‹è¨˜ç ”ç©¶ã§MMLUã®ã‚ˆã†ãªå‡ºåŠ›ç©ºé–“ãŒåˆ¶ç´„ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªè¨­å®šã®å ´åˆã¯ã»ã¨ã‚“ã©å½±éŸ¿ãŒãªã„ã“ã¨ãŒå®Ÿé¨“çš„ã«ç¤ºã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2735" target="_blank" rel="noopener noreferrer">[Paper Note] The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore   Non-Determinism, Yifan Song+, NAACL'25</a>
<br><br>ã“ã‚Œã¯nucleus/temperature samplingãŒææ¡ˆã•ã‚ŒãŸèƒŒæ™¯ï¼ˆï¼å‡ºåŠ›ã®è‡ªç„¶ã•ã‚’ä¿ã£ãŸã¾ã¾å¤šæ§˜æ€§ã‚’å¢—ã‚„ã—ãŸã„ï¼‰ã¨ã‚‚ä¸€è‡´ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2721" target="_blank" rel="noopener noreferrer" class="title-link">FinePDFs, HuggingFaceFW, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aratako_lm/status/1964596642067402987?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Thomas Wolfæ°ã®ãƒã‚¹ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thom_wolf/status/1964653264986656922?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ODC-By 1.0 license</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2720" target="_blank" rel="noopener noreferrer" class="title-link">Fast-dLLM v2: Efficient Block-Diffusion Large Language Model, Wu+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/songhan_mit/status/1964375581761388828?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2719" target="_blank" rel="noopener noreferrer" class="title-link">CLOCKBENCH: VISUAL TIME BENCHMARK WHERE HUMANS BEAT THE CLOCK, LLMS DONâ€™T ALEK SAFAR ï¼ˆOLEG CHICHIGINï¼‰, 2025.09</a>
<span class="snippet"><span>Comment</span><p>ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰:


<a href="https://clockbench.ai" target="_blank" rel="noopener noreferrer">https://clockbench.ai</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alek_safar/status/1964383077792141390?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ§˜ã€…ãªç¨®é¡ã®æ™‚è¨ˆï¼ˆe.g., åè»¢ã€ãƒ•ã‚©ãƒ³ãƒˆã®é•ã„, invalidãªæ™‚åˆ»ã®å­˜åœ¨, å¤§ãã•, ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãªã©; p.2å‚ç…§ã®ã“ã¨)ã®æ™‚åˆ»ã‚’èª­ã¿å–ã‚Šï¼ˆã‚ã‚‹ã„ã¯validãªæ™‚åˆ»ã‹å¦ã‹ã‚’åˆ¤å®šã—)ã€èª­ã¿å–ã£ãŸæ™‚åˆ»ã«å¯¾ã—ã¦QAï¼ˆe.g., Xæ™‚é–“Yåˆ†Zç§’é€²ã‚ã‚‹ã€æˆ»ã—ãŸæ™‚åˆ»ã¯ï¼Ÿé•·é‡ã‚’30/60/90åº¦å‹•ã‹ã—ãŸæ™‚åˆ»ã¯ï¼Ÿã“ã®æ™‚åˆ»ãŒãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯ã®æ™‚é–“ã ã¨ã—ãŸã‚‰ãƒ­ãƒ³ãƒ‰ãƒ³ã®æ™‚åˆ»ã¯ï¼Ÿ)ã‚’å®Ÿæ–½ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚äººé–“ã®æ­£è§£ç‡ã¯89.1%ã«å¯¾ã—ã¦SoTAãƒ¢ãƒ‡ãƒ«ã§ã‚‚13.3%ç¨‹åº¦ã€‚contaminationã«é…æ…®ã—ã¦å…¨ã¦ã‚¹ã‚¯ãƒ©ãƒƒãƒã‹ã‚‰ä½œæˆã•ã‚Œã€å…¨ä½“ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã¯privateãªã¾ã¾ã«ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚<br><img src="https://github.com/user-attachments/assets/aa2ca43c-97c9-49c3-a93b-d1897858d598" alt="image" loading="lazy"></p>
<p>ç¶šå ±:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alek_safar/status/1972697598155706443?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Qwen3-VL-235B-InstructãŒGPT-5 Chatè¶…ãˆ</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/Cultural.html" target="_blank" rel="noopener noreferrer">#Cultural</a>
<span class="issue_date">Issue Date: 2025-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2717" target="_blank" rel="noopener noreferrer" class="title-link">MECHA-ja, llm-jp, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/silviasetitech/status/1964470358595293639?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Composition.html" target="_blank" rel="noopener noreferrer">#Composition</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2712" target="_blank" rel="noopener noreferrer" class="title-link">From fï¼ˆxï¼‰ and gï¼ˆxï¼‰ to fï¼ˆgï¼ˆxï¼‰ï¼‰: LLMs Learn New Skills in RL by Composing Old Ones, Yuan+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1964235195613143127?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã•ã‚ŒãŸå®Ÿé¨“ã«ãŠã„ã¦ã€æ·±ã•2ã®nestedãªcompostition g(f(x))ã®ãƒ‡ãƒ¼ã‚¿ã§RLã—ãŸå ´åˆã¯ã€ãƒ†ã‚¹ãƒˆæ™‚ã«æ·±ã•6ã¾ã§ã®compostitionã‚’å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸãŒï¼ˆï¼ãƒ¡ã‚¿ã‚¹ã‚­ãƒ«ã¨ã—ã¦compostitionã‚’ç²å¾—ã—ãŸï¼‰ã€æ·±ã•1ã®non-nestedãªãƒ‡ãƒ¼ã‚¿ã§RLã—ãŸå ´åˆã¯è¤‡é›‘ãªcompostitionãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã‚’è§£ã‘ãªã‹ã£ãŸã€‚ã¾ãŸã€ä¸€èˆ¬çš„ã«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ç¨‹åº¦è§£ã‘ã‚‹å•é¡Œã«å¯¾ã—ã¦RLã‚’é©ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®pass@1000ã¯ã‚ã¾ã‚Šå‘ä¸Šã—ãªã„ã“ã¨ã‹ã‚‰ã€RLã¯æ–°ã—ã„ã‚¹ã‚­ãƒ«ã‚’ä½•ã‚‚æ•™ãˆã¦ã„ãªã„ã®ã§ã¯ãªã„ã‹ã€ã¨ã„ã£ãŸè§£é‡ˆãŒã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ãŒã€ã‚ˆã‚Šé«˜æ¬¡ã®compostitionãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã™ã‚‹ã¨æ˜ç¢ºã«æ€§èƒ½ãŒè‰¯ããªã‚‹ã®ã§ã€å®Ÿã¯ã‚ˆã‚Šé«˜æ¬¡ã®compostitionãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã‚’ä¼¸ã°ã—ã¦ã„ã‚‹ã€‚compostitionã§ã®èƒ½åŠ›ã‚’ç™ºæ®ã™ã‚‹ã«ã¯ã¾ãšå¹…åºƒã„atomicãªã‚¹ã‚­ãƒ«ãŒå¿…è¦ãªã®ã§ã€ã—ã£ã‹ã‚Šãã‚Œã‚’äº‹å‰å­¦ç¿’ã§èº«ã«ã¤ã‘ã•ã›ã€ãã®å¾Œpost-trainingã«ã‚ˆã£ã¦è§£æ±ºã—ãŸã„ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã®atomic skillã®compostitionã®æ–¹æ³•ã‚’å­¦ç¿’ã•ã›ã‚‹ã¨åŠ¹æœçš„ãªã®ã§ã¯ãªã„ã‹ã€ã¨ã„ã£ãŸè©±ãªæ¨¡æ§˜ã€‚</p>
<p>ã“ã®è¾ºã®ICLã®è©±ã¨ä¼¼ã¦ã„ã‚‹<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1362" target="_blank" rel="noopener noreferrer">What Do Language Models Learn in Context? The Structured Task Hypothesis, Jiaoda Li+, N/A, ACL'24</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2709" target="_blank" rel="noopener noreferrer" class="title-link">Why Language Models Hallucinate, Kalai+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/adamfungi/status/1964040819196752312?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1964837910278189271?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ziv_ravid/status/1964384106567127465?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2705" target="_blank" rel="noopener noreferrer" class="title-link">FineWeb2 Edu Japanese, Yuichi Tateno, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1964127750782144952?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2701" target="_blank" rel="noopener noreferrer" class="title-link">Kimi-K2-Instruct-0905, MoonshotAI, 2025.09</a>
<span class="snippet"><span>Comment</span><p>ä»¥å‰ã¨æ¯”è¼ƒã—ã¦SWE Benchç³»ã®æ€§èƒ½ãŒå¤§å¹…ã«å‘ä¸Šã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1963804320522207422?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kimi_moonshot/status/1963802687230947698?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Artificial Analysisã«ã‚ˆã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°çµæœ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1965010554499788841?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Agenticãªèƒ½åŠ›ãŒé¡•è‘—ã«æ”¹å–„ã—ã¦ã„ã‚‹æ—¨ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<p>Creative Short Story Benchmarkã¨å‘¼ã°ã‚Œã‚‹ã§SoTA:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/koltregaskes/status/1966125826887602635?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>


<a href="https://github.com/lechmazur/writing" target="_blank" rel="noopener noreferrer">https://github.com/lechmazur/writing</a>


<br><br>ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã€object, tone, Attributeãªã©ã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’æ§‹æˆã™ã‚‹è¦ç´ ã®ã¿ã‚’æŒ‡å®šã—ã¦ã€600-800ç¨‹åº¦ã®ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’è¨˜è¿°ã•ã›ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€è©•ä¾¡ã¯18å€‹ã®ãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ï¼ˆ8ã“ã™ã®ãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã§narrativeã¨ã—ã¦ã®å“è³ªã‚’è©•ä¾¡ã—ã€æ®‹ã‚Šã§æ§‹æˆã‚„requirementsã‚’æº€ãŸã—ã¦ã„ã‚‹ã‹ãªã©ã®è©•ä¾¡ã‚’ã™ã‚‹ï¼‰ã«åŸºã¥ãè¤‡æ•°LLMã«ã‚ˆã‚‹LLM-as-a-Judgeã«ã‚ˆã‚‹ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°çµæœã‚’é›†ç´„ã™ã‚‹ã“ã¨ã§å®Ÿæ–½ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br>ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã«åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹LLMã¯ä¸‹è¨˜:<br><br>- Claude Opus 4.1 (no reasoning)<br>- DeepSeek V3.1 Reasoner<br>- Gemini 2.5 Pro<br>- GPT-5 (low reasoning)<br>- Grok 4<br>- Kimi K2<br>- Qwen 3 235B A22B 25-07 Think<br><br>è¤‡æ•°LLMã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã¨ã¯ã„ãˆã€è©•ä¾¡å¯¾è±¡ã®ãƒ¢ãƒ‡ãƒ«ã‚‚gradeã§åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã«å«ã¾ã‚Œã¦ã„ã‚‹ã®ã¯æ°—ã«ãªã‚‹ã¨ã“ã‚ã€‚ã‚ã¨ã¯narrativeã®å“è³ªè©•ä¾¡ã¯LLMã§ã©ã“ã¾ã§ã§ãã‚‹ã®ã ã‚ã†ã‹ã€‚</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2695" target="_blank" rel="noopener noreferrer" class="title-link">FineVision: Open Data Is All You Need, Wiedmann+, Hugging Face, 2025.09</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/datasets/HuggingFaceM4/FineVision" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/HuggingFaceM4/FineVision</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/andimarafioti/status/1963610135328104945?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2693" target="_blank" rel="noopener noreferrer" class="title-link">Introducing EmbeddingGemma: The Best-in-Class Open Model for On-Device Embeddings, Google, 2025.09</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/collections/google/embeddinggemma-68b9ae3a72a82f0562a80dc4" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/google/embeddinggemma-68b9ae3a72a82f0562a80dc4</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/osanseviero/status/1963635281032040914?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1963634786636841461?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tomaarsen/status/1963639557653422304?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2685" target="_blank" rel="noopener noreferrer" class="title-link">ä¿¡é ¼ã§ãã‚‹LLM-as-a-Judgeã®æ§‹ç¯‰ã«å‘ã‘ãŸç ”ç©¶å‹•å‘, tsurubee, 2025.09</a>
<span class="snippet"><span>Comment</span><p>ãƒ–ãƒ­ã‚°ä¸­ã§è§£èª¬ã•ã‚Œã¦ã„ã‚‹ã‚µãƒ¼ãƒ™ã‚¤è«–æ–‡ã¯ä¸‹è¨˜:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1616" target="_blank" rel="noopener noreferrer">A Survey on LLM-as-a-Judge, Jiawei Gu+, arXiv'24</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2668" target="_blank" rel="noopener noreferrer" class="title-link">Inside vLLM: Anatomy of a High-Throughput LLM Inference System, Aleksa GordiÄ‡ blog, 2025.08</a>
<span class="snippet"><span>Comment</span><p>ã‚ã£ã¡ã‚ƒè‰¯ã•ãã†</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2666" target="_blank" rel="noopener noreferrer" class="title-link">APERTUS: DEMOCRATIZING OPEN AND COMPLIANT LLMS FOR GLOBAL LANGUAGE ENVIRONMENTS, Apertus Team, 2025.09</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/collections/swiss-ai/apertus-llm-68b699e65415c231ace3b059" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/swiss-ai/apertus-llm-68b699e65415c231ace3b059</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haeggee/status/1962933627584413721?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>1811ã‚«å›½èªã«å¯¾å¿œã—ãŸã€ã‚¹ã‚¤ã‚¹ç™ºã®OpenSourceï¼ˆ=å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã€å­¦ç¿’ã®ãƒ¬ã‚·ãƒ”ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å†ç¾ã™ã‚‹ãŸã‚ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚‚å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ï¼‰ LLMã€‚8B / 70BãŒå­˜åœ¨ã€‚</p>
<p>Apache 2.0 + Apertus LLM Acceptable Use Policy</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1963187226189115602?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2652" target="_blank" rel="noopener noreferrer" class="title-link">August 2025 - China Open Source  Highlights, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/adinayakup/status/1962508234549329969?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2646" target="_blank" rel="noopener noreferrer" class="title-link">slime, THUDM &amp; Zhihu, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhihufrontier/status/1962751555591086226?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>GLM-4.5ã®RLå­¦ç¿’ã«åˆ©ç”¨ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2406" target="_blank" rel="noopener noreferrer">[Paper Note] GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models, GLM-4. 5 Team+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2641" target="_blank" rel="noopener noreferrer" class="title-link">RLinf: Reinforcement Learning Infrastructure for Agentic AI, RLinf, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1962441512207491217?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2640" target="_blank" rel="noopener noreferrer" class="title-link">The Hitchhiker's Guide to Autonomous Research: A Survey of Scientific Agents, Wang+, TechRxiv, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1962438146156855554?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2634" target="_blank" rel="noopener noreferrer" class="title-link">Hunyuan-MT-7B, Tencent, 2025.09</a>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ:


<a href="https://github.com/Tencent-Hunyuan/Hunyuan-MT/blob/main/Hunyuan_MT_Technical_Report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/Tencent-Hunyuan/Hunyuan-MT/blob/main/Hunyuan_MT_Technical_Report.pdf</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tencenthunyuan/status/1962466712378577300?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Base Modelã«å¯¾ã—ã¦ã¾ãšä¸€èˆ¬çš„ãªäº‹å‰å­¦ç¿’ã‚’å®Ÿæ–½ã—ã€ãã®å¾ŒMTã«ç‰¹åŒ–ã—ãŸç¶™ç¶šäº‹å‰å­¦ç¿’ï¼ˆãƒ¢ãƒãƒªãƒ³ã‚¬ãƒ«/ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã®åˆ©ç”¨ï¼‰ã€äº‹å¾Œå­¦ç¿’ï¼ˆSFT, GRPO)ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br>ç¶™ç¶šäº‹å‰å­¦ç¿’ã§ã¯ã€æœ€é©ãªDataMixã®æ¯”ç‡ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«ã€RegMixã¨å‘¼ã°ã‚Œã‚‹æ‰‹æ³•ã‚’åˆ©ç”¨ã€‚Catastrophic Forgettingã‚’é˜²ããŸã‚ã«ã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®20%ã‚’å«ã‚ã‚‹ã¨ã„ã£ãŸæ–½ç­–ã‚’å®Ÿæ–½ã€‚<br><br>SFTã§ã¯2ã¤ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹ã€‚ã‚¹ãƒ†ãƒ¼ã‚¸1ã¯åŸºç¤çš„ãªç¿»è¨³åŠ›ã®å¼·åŒ–ã¨ç¿»è¨³ã«é–¢ã™ã‚‹æŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ã®å‘ä¸Šã®ãŸã‚ã«ã€Flores-200ã®é–‹ç™ºãƒ‡ãƒ¼ã‚¿(33è¨€èªã®åŒæ–¹å‘ã®ç¿»è¨³ã‚’ã‚«ãƒãƒ¼)ã€å‰å¹´åº¦ã®WMTã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ(English to XXã‚’ã‚«ãƒãƒ¼ï¼‰ã€Mandarin to Minority, Minority to Mandarinã®curatedãªäººæ‰‹ã§ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã€DeepSeek-V3-0324ã§ã®åˆæˆãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã€general purpose/MT orientedãªæŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã†ã¡20%ã‚’æ§‹æˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã§ç¿»è¨³ã®instructinoã«é–¢ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®å‡¡åŒ–æ€§èƒ½ã‚’é«˜ã‚ã‚‹ãŸã‚ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã€ã§å­¦ç¿’ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã¯Reference-freeãªæ‰‹æ³•ã‚’ç”¨ã„ã¦ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã—é–¾å€¤ä»¥ä¸‹ã®ä½å“è³ªãªç¿»è¨³å¯¾ã¯é™¤å¤–ã—ã¦ã„ã‚‹ã€‚ã‚¹ãƒ†ãƒ¼ã‚¸2ã§ã¯ã€è©³ç´°ãŒæ›¸ã‹ã‚Œã¦ã„ãªã„ãŒã€å°‘é‡ã§ã‚ˆã‚Šfidelityã®é«˜ã„ç´„270kã®ç¿»è¨³å¯¾ã‚’åˆ©ç”¨ã—ãŸæ¨¡æ§˜ã€‚ã¾ãŸã€å…ˆè¡Œç ”ç©¶ã«åŸºã¥ã„ã¦ã€many-shotã®in-context learningã‚’ç”¨ã„ã¦ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ã•ã‚‰ã«æ´—ç·´ã•ã›ãŸã¨ã®ã“ã¨ï¼ˆå…ˆè¡Œç ”ç©¶ãŒå¼•ç”¨ã•ã‚Œã¦ã„ã‚‹ã®ã¿ã§è©³ç´°ãªè¨˜è¿°ã¯ç„¡ã—ï¼‰ã€‚ã¾ãŸã€è¤‡æ•°ã®è©•ä¾¡ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã‚¹ã‚³ã‚¢ã®ä¸€è²«æ€§ãŒç„¡ã„ã‚µãƒ³ãƒ—ãƒ«ã¯æ‰‹å‹•ã§ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚ã‚‹ã„ã¯verificationã‚’ã—ã¦å“è³ªã‚’æ‹…ä¿ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br>RLã§ã¯GRPOã‚’æ¡ç”¨ã—ã€rewardã¨ã—ã¦semantic(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2635" target="_blank" rel="noopener noreferrer">[Paper Note] xCOMET: Transparent Machine Translation Evaluation through Fine-grained  Error Detection, Nuno M. Guerreiro+, TACL'24</a>
), terminology(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2649" target="_blank" rel="noopener noreferrer">[Paper Note] TAT-R1: Terminology-Aware Translation with Reinforcement Learning and
  Word Alignment, Zheng Li+, arXiv'25</a>
; ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ã®terminologyã‚’æ‰ãˆã‚‹), repetitionã«åŸºã¥ã„ãŸrewardã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚æœ€çµ‚çš„ã«SFT-&gt;RLã§å­¦ç¿’ã•ã‚ŒãŸHuayuan-MT-7Bã«å¯¾ã—ã¦ã€ä¸‹è¨˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”¨ã„ã¦è¤‡æ•°ã®outputã‚’çµ±åˆã—ã¦ã‚ˆã‚Šé«˜å“è³ªãªç¿»è¨³ã‚’å‡ºåŠ›ã™ã‚‹ã‚­ãƒ¡ãƒ©ãƒ¢ãƒ‡ãƒ«ã‚’åŒæ§˜ã®rewardã‚’ç”¨ã„ã¦å­¦ç¿’ã™ã‚‹ã€ã¨ã„ã£ãŸpipelineã«ãªã£ã¦ã„ã‚‹ã€‚<br><br>&lt;img width="884" height="462" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/dbb7a799-6304-4cfa-b75c-74b44fe39a2e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/dbb7a799-6304-4cfa-b75c-74b44fe39a2e"&lt;/a&gt;


/&gt;<br><br>&lt;img width="921" height="279" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/33b49ef7-b93b-4094-b83e-5931d2b411e5"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/33b49ef7-b93b-4094-b83e-5931d2b411e5"&lt;/a&gt;


/&gt;</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1220" target="_blank" rel="noopener noreferrer">Large Language Models Are State-of-the-Art Evaluators of Translation Quality, EAMT'23</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2635" target="_blank" rel="noopener noreferrer">[Paper Note] xCOMET: Transparent Machine Translation Evaluation through Fine-grained  Error Detection, Nuno M. Guerreiro+, TACL'24</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2636" target="_blank" rel="noopener noreferrer">[Paper Note] CometKiwi: IST-Unbabel 2022 Submission for the Quality Estimation Shared Task, Rei+, WMT'22</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2637" target="_blank" rel="noopener noreferrer">[Paper Note] No Language Left Behind: Scaling Human-Centered Machine Translation, NLLB Team+, arXiv'22</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2638" target="_blank" rel="noopener noreferrer">[Paper Note] Many-Shot In-Context Learning, Rishabh Agarwal+, NeurIPS'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2639" target="_blank" rel="noopener noreferrer">[Paper Note] RegMix: Data Mixture as Regression for Language Model Pre-training, Qian Liu+, ICLR'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2649" target="_blank" rel="noopener noreferrer">[Paper Note] TAT-R1: Terminology-Aware Translation with Reinforcement Learning and
  Word Alignment, Zheng Li+, arXiv'25</a>
</p>
<p>é–¢é€£: PLaMoç¿»è¨³<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2517" target="_blank" rel="noopener noreferrer">PLaMo Translate: ç¿»è¨³ç‰¹åŒ–å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é–‹ç™º,ä»ŠåŸ+, Jxiv'25</a>
<br><br>ã“ã¡ã‚‰ã¯SFT-&gt;Iterative DPO-&gt;Model Mergeã‚’å®Ÿæ–½ã—ã€ç¿»è¨³ã«ç‰¹åŒ–ã—ãŸç¶™ç¶šäº‹å‰å­¦ç¿’ã¯ã‚„ã£ã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ä¸€æ–¹ã€SFTæ™‚ç‚¹ã§ç‹¬è‡ªã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã—ã€èªå½™ã®æŒ‡å®šã‚„ã‚¹ã‚¿ã‚¤ãƒ«ã€æ—¥æœ¬èªç‰¹æœ‰ã®å¸¸ä½“ã€æ•¬ä½“ã®æŒ‡å®šãªã©ã‚’å®Ÿæ–½ã§ãã‚‹ã‚ˆã†ã«ç¿»è¨³ã«ç‰¹åŒ–ã—ãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å­¦ç¿’ã—ã¦ã„ã‚‹ç‚¹ãŒç•°ãªã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚Hunyuanã¯å¤šæ§˜ãªç¿»è¨³ã®æŒ‡ç¤ºã«å¯¾å¿œã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã—ã¦ã„ã‚‹ãŒã€PLaMoç¿»è¨³ã¯ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚’çµã‚Šè¾¼ã¿ã€ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«å¯¾ã™ã‚‹æ€§èƒ½ã‚’é«˜ã‚ã‚‹ã‚ˆã†ãªç‰¹åŒ–å‹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ã¨ã‚‹ã¨ã„ã£ãŸæ€æƒ³ã®é•ã„ãŒä¼ºãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/Chip.html" target="_blank" rel="noopener noreferrer">#Chip</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2633" target="_blank" rel="noopener noreferrer" class="title-link">AIãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹æ¤œè¨ä¼š ç¬¬1å›äº‹å‹™å±€è³‡æ–™, çµŒæ¸ˆç”£æ¥­çœ, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gclue_akira/status/1962298561451958546?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Nvidiaã®æŠ•è³‡é¡ãŒæ–‡å­—é€šã‚Šæ¡é•ã„ã®5000å„„ãƒ‰ãƒ«</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2631" target="_blank" rel="noopener noreferrer" class="title-link">Nemotron-CC-v2, Nvidia, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zeyuanallenzhu/status/1962119316427706828?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>CCã ã‘ã§ãªãã€æ•°å­¦ã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã€SFT styleã®åˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚å«ã¾ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2628" target="_blank" rel="noopener noreferrer" class="title-link">Probing LLM Social Intelligence via Werewolf, foaster.ai, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gdb/status/1962210896601845878?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2620" target="_blank" rel="noopener noreferrer" class="title-link">LongCat-Flash-Chat, meituan-longcat, 2025.08</a>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ:


<a href="https://github.com/meituan-longcat/LongCat-Flash-Chat/blob/main/tech_report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/meituan-longcat/LongCat-Flash-Chat/blob/main/tech_report.pdf</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1961955926136832381?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Agentå‘¨ã‚Šã®ãƒ™ãƒ³ãƒã§é«˜æ€§èƒ½ãªnon thinkingãƒ¢ãƒ‡ãƒ«ã€‚æ¯ç§’100+ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆé€Ÿåº¦ã§ã€MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã€‚Dynamic Activation...?</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2621" target="_blank" rel="noopener noreferrer">[Paper Note] Shortcut-connected Expert Parallelism for Accelerating   Mixture-of-Experts, Weilin Cai+, ICLR'25</a>
</p>
<p>Dynamic Activation (activation paramãŒå…¥åŠ›ã«å¿œã˜ã¦å¤‰åŒ–(å…¨ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’MoEã«ãŠã„ã¦å‡ä¸€ã«æ‰±ã‚ãªã„ï¼‰ã™ã‚‹ã“ã¨ã§åŠ¹ç‡åŒ–ï¼‰ã¯ã€ä¸‹è¨˜ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§å®Ÿç¾ã—ã¦ã„ã‚‹æ¨¡æ§˜<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2622" target="_blank" rel="noopener noreferrer">[Paper Note] MoE++: Accelerating Mixture-of-Experts Methods with Zero-Computation   Experts, Peng Jin+, ICLR'25</a>
</p>
<p>ã—ã‹ã—ä¸­å›½ã¯æœ¬å½“ã«æ¬¡ã€…ã«è‰²ã€…ãªä¼æ¥­ã‹ã‚‰åŸºç›¤ãƒ¢ãƒ‡ãƒ«ãŒå‡ºã¦ãã‚‹ãªãâ€¦ã™ã”ã„</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2623" target="_blank" rel="noopener noreferrer">[Paper Note] Scaling Exponents Across Parameterizations and Optimizers, Katie Everett+, ICML'24</a>
 </p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nrehiew_/status/1962186876099739767?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1962980770550628841?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2606" target="_blank" rel="noopener noreferrer" class="title-link">fastvlm-webgpu, Apple, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fartashfg/status/1961441954157244448?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj page:


<a href="https://fastvlm.net" target="_blank" rel="noopener noreferrer">https://fastvlm.net</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2596" target="_blank" rel="noopener noreferrer" class="title-link">ã¤ãã£ã¦ç´å¾—ã€ã¤ã‹ã£ã¦å®Ÿæ„Ÿï¼ å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã“ã¨ã¯ã˜ã‚, Recruit, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/schroneko/status/1960995191550083154?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLMå…¥é–€ã«ã¨ã¦ã‚‚è‰¯ã•ãã†</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/Editing.html" target="_blank" rel="noopener noreferrer">#Editing</a>
<span class="issue_date">Issue Date: 2025-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2579" target="_blank" rel="noopener noreferrer" class="title-link">Introducing Gemini 2.5 Flash Image, our state-of-the-art image model, Google, 2025.08</a>
<span class="snippet"><span>Comment</span><p>nano banana</p>
<p>ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1961809165191397863?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¬ã‚¤ãƒ‰ã¨æˆ¦ç•¥:


<a href="https://ai.google.dev/gemini-api/docs/image-generation?hl=ja#prompt-guide" target="_blank" rel="noopener noreferrer">https://ai.google.dev/gemini-api/docs/image-generation?hl=ja#prompt-guide</a>


<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/beatinaniwa/status/1960911250344526264?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/CovarianceShift.html" target="_blank" rel="noopener noreferrer">#CovarianceShift</a>
<span class="issue_date">Issue Date: 2025-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2570" target="_blank" rel="noopener noreferrer" class="title-link">ã€Œæ¨è«–ã™ã‚‹ç”ŸæˆAIã€ã¯äº‹å‰å­¦ç¿’ã•ã‚Œã¦ã„ãªã„èª²é¡Œã‚’æ­£ã—ãæ¨è«–ã™ã‚‹ã“ã¨ãŒã§ããªã„ï¼ˆå…±å¤‰é‡ã‚·ãƒ•ãƒˆã«å¼±ã„ï¼‰, TJO, 2025.08</a>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2397" target="_blank" rel="noopener noreferrer">[Paper Note] Physics of Language Models: Part 2.1, Grade-School Math and the Hidden   Reasoning Process, Tian Ye+, ICLR'25</a>
<br><br>ã§LLMã¯æœªçŸ¥ã®å•é¡Œã‚’è§£ã‘ã‚‹ï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªã„åŒç­‰ã®lengthã®æœªçŸ¥ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è§£ã‘ã‚‹/ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚ã‚ˆã‚Šè¤‡é›‘ãªé•·ã„lengthã®å•é¡Œã‚’è§£ã‘ã‚‹ï¼‰ã¨æ¯”ã¹ã‚‹ã¨ã€ä¸¡è€…ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹çµè«–ã‹ã‚‰ä½•ãŒè¨€ãˆã‚‹ã®ã ã‚ã†ã‹ï¼Ÿè¦³æ¸¬ã§ãã‚‹CoTã¨hidden mental reasoning process (probingã§è¡¨å‡ºã•ã›ã¦åˆ†æï¼‰ã¯åˆ†ã‘ã¦è€ƒãˆã‚‹å¿…è¦ãŒã‚ã‚‹ã®ã‹ã‚‚ã—ã‚Œãªã„ã€‚å…ƒè«–æ–‡ã‚’ãã¡ã‚“ã¨èª­ã‚ã¦ã„ãªã„ã‹ã‚‰è€ƒãˆã¦ã¿ãŸã„ã€‚<br><br>ã‚ã¨ã€ãƒ–ãƒ­ã‚°ä¸­ã§ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹è«–æ–‡ä¸­ã§ã¯Physics of Language ModelsãŒå¼•ç”¨ã•ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ãŒã€è«–æ–‡ä¸­ã§å¼•ç”¨ã•ã‚Œã€é–¢é€£æ€§ãƒ»å·®åˆ¥åŒ–ã«ã¤ã„ã¦è¨€åŠã•ã‚Œã¦ã„ãŸæ–¹ãŒè‰¯ã„ã®ã§ã¯ãªã„ã‹ï¼Ÿã¨ã„ã†æ„Ÿæƒ³ã‚’æŠ±ã„ãŸã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2569" target="_blank" rel="noopener noreferrer">[Paper Note] Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens, Chengshuai Zhao+, arXiv'25</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2571" target="_blank" rel="noopener noreferrer">[Paper Note] Understanding deep learning requires rethinking generalization, Chiyuan Zhang+, ICLR'17</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2575" target="_blank" rel="noopener noreferrer">[Paper Note] UQ: Assessing Language Models on Unsolved Questions, Fan Nie+, arXiv'25</a>
</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tjo_datasci/status/1960858549359403150?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<span class="issue_date">Issue Date: 2025-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2565" target="_blank" rel="noopener noreferrer" class="title-link">NECã€æš—é»™çŸ¥ã‚’ãƒ‡ãƒ¼ã‚¿åŒ–ã—å­¦ç¿’ãƒ»æ´»ç”¨ã™ã‚‹ã“ã¨ã§Webæ¥­å‹™ã‚’è‡ªå‹•åŒ–ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŠ€è¡“ã€Œcotomi Actã€ã‚’é–‹ç™º ã€œä¸–ç•Œåˆã€äººé–“ã‚’è¶…ãˆã‚‹Webã‚¿ã‚¹ã‚¯æˆåŠŸç‡80.4ï¼…ã‚’é”æˆã€œ, NEC, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stillpedant/status/1960515574615924943?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>WebArena:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1849" target="_blank" rel="noopener noreferrer">WebArena: A Realistic Web Environment for Building Autonomous Agents, Shuyan Zhou+, ICLR'24</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2561" target="_blank" rel="noopener noreferrer" class="title-link">MiniCPM-V-4_5, openbmb, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/adinayakup/status/1960292853453672886?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2551" target="_blank" rel="noopener noreferrer" class="title-link">The Bitter Lesson for RL: Verification as the key to Reasoning LLMs, Rishabh Agarwal, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yongyuanxi/status/1960040848051372379?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/agarwl_/status/1931089624132211078"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2550" target="_blank" rel="noopener noreferrer" class="title-link">Why Stacking Sliding Windows Can't See Very Far, Guangxuan Xiao , 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/guangxuan_xiao/status/1960103495081541921?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2539" target="_blank" rel="noopener noreferrer" class="title-link">TxT360, LLM360, 2024.10</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2515" target="_blank" rel="noopener noreferrer" class="title-link">Command A Reasoning: Enterprise-grade control for AI agents, Cohere, 2025.08</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/CohereLabs/command-a-reasoning-08-2025" target="_blank" rel="noopener noreferrer">https://huggingface.co/CohereLabs/command-a-reasoning-08-2025</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1958582982005944496?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Agenté–¢é€£ãƒ™ãƒ³ãƒã§R1, gptossè¶…ãˆã€‚DeepResearchãƒ™ãƒ³ãƒã§ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªLLMã¨æ¯”ã¹ã¦SoTAã€‚safetyé–¢é€£ãƒ™ãƒ³ãƒã§R1, gptossè¶…ãˆã€‚<br>ã™ã€ã™ã”ã„ã®ã§ã¯ã€ã€ï¼Ÿ</p>
<p>CC-BY-NC 4.0ãªã®ã§å•†ç”¨åˆ©ç”¨ä¸å¯</p>
<p>ã‚µãƒãƒª:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1960840619095634326?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2513" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-V3.1-Base, deepseek-ai, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/umiyuki_ai/status/1958422590806249550?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>æ•°æ—¥å‰ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«è‡ªä½“ã¯å…¬é–‹ã•ã‚Œã¦ã„ãŸãŒã€ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ãŒè¿½åŠ ã•ã‚ŒãŸ<p>- hybrid thinking<br>- post-trainingã«ã‚ˆã‚‹tool calling capabilityå‘ä¸Š<br>- token efficiencyã®å‘ä¸Š</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1958472154472690159?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1958438863279681824?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚µãƒãƒª:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1960840570873766171?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2498" target="_blank" rel="noopener noreferrer" class="title-link">Aider LLM Leaderboards, 2024.12</a>
<span class="snippet"><span>Comment</span><p>æœ€è¿‘ã‚ˆãè¦‹ã‹ã‘ã‚‹ã„ã‚ã‚†ã‚‹Aider Polyglotã€‚äººé–“ã®ä»‹å…¥ãªã—ã«ã€LLMãŒã‚³ãƒ¼ãƒ‰ã®"ç·¨é›†"ã‚’ã™ã‚‹èƒ½åŠ›ã‚’æ¸¬ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚æ€§èƒ½ã ã‘ã§ãªãã‚³ã‚¹ãƒˆã‚‚ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚C++,Go,Java,JavaScript,Python,Rustã«ã‚ˆã‚‹Exercimã«ãŠã‘ã‚‹225ã®"æœ€ã‚‚å›°é›£ãª"ã‚¨ã‚¯ã‚µã‚µã‚¤ã‚ºã®ã¿ãŒå«ã¾ã‚Œã‚‹ã€‚</p>
<p>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:


<a href="https://github.com/Aider-AI/polyglot-benchmark" target="_blank" rel="noopener noreferrer">https://github.com/Aider-AI/polyglot-benchmark</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-08-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2495" target="_blank" rel="noopener noreferrer" class="title-link">Swallow LLM Leaderboard v2, Swallow LLM Team, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chokkanorg/status/1958063716110594255?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLMã®æ€§èƒ½ã‚’å…¬å¹³ãªæ¡ä»¶ã§è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€å¾“æ¥ã®non thinkingãƒ¢ãƒ‡ãƒ«ã§æ¡ç”¨ã—ã¦ã„ãŸæ–¹æ³•ã¯thinkingãƒ¢ãƒ‡ãƒ«ã§ã¯éå°è©•ä¾¡ã«ã¤ãªãŒã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸï¼ˆe.g., non thinkingãƒ¢ãƒ‡ãƒ«ã¯zero shotã‚’æ¨™æº–ã¨ã™ã‚‹ãŒã€thinkingãƒ¢ãƒ‡ãƒ«ã§ã¯fewshotã€chat templateã®æ¡ç”¨ç­‰ï¼‰ãŸã‚ã€æ—¥æœ¬èª/è‹±èªã¨ã‚‚ã«ä¿¡é ¼ã®é«˜ã„6ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æ¡ç”¨ã—ã€thinkingãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦å…¬å¹³ãªçµ±ä¸€çš„ãªè©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç¢ºç«‹ã€‚ä¸»è¦ãªãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªã€OpenLLMã«å¯¾ã—ã¦è©•ä¾¡ã‚’å®Ÿæ–½ã—ã€ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã¨ã—ã¦å…¬é–‹ã€‚Reasoningãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹æœ€æ–°ã®æ—¥æœ¬èªæ€§èƒ½ã‚’çŸ¥ã‚ŠãŸã„å ´åˆã¯ã“ã¡ã‚‰ã‚’å‚ç…§ã™ã‚‹ã®ãŒè‰¯ã„ã¨æ€ã‚ã‚Œã‚‹ã€‚</p>
<p>è©•ä¾¡ã«ç”¨ã„ã‚‰ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã“ã¡ã‚‰:<br>


<a href="https://github.com/swallow-llm/swallow-evaluation-instruct" target="_blank" rel="noopener noreferrer">https://github.com/swallow-llm/swallow-evaluation-instruct</a>


</p>
<p>ä¸»è¦ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½æ¯”è¼ƒ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chokkanorg/status/1958063946826428424?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2025-08-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2494" target="_blank" rel="noopener noreferrer" class="title-link">OLMo-2-0425-1B-early-training, allenai, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/allen_ai/status/1957518243045818432?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OLPO 2 1Bãƒ¢ãƒ‡ãƒ«ã®10000step/21B tokenã”ã¨ã®äº‹å‰å­¦ç¿’æ™‚ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆç¾¤ã€‚ï¼ˆ0--40000step, 0--63B tokenizerã®4ã¤ãŒå­˜åœ¨ã—ã¦ã„ã‚‹æ¨¡æ§˜ï¼‰ã€‚äº‹å‰å­¦ç¿’ã®early stageã®ç ”ç©¶ç”¨ã«ãƒªãƒªãƒ¼ã‚¹ã€‚èˆˆå‘³æ·±ã„</p>
<p>ãŸã¨ãˆã°<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2340" target="_blank" rel="noopener noreferrer">[Paper Note] WSM: Decay-Free Learning Rate Schedule via Checkpoint Merging for LLM
  Pre-training, Changxin Tian+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1996" target="_blank" rel="noopener noreferrer">Temporal Sampling for Forgotten Reasoning in LLMs, Yuetai Li+, arXiv'25</a>
<br><br>ã‚’è©¦ã—ã¦ã¿ãŸã‚Šã§ãã‚‹ã®ã ã‚ã†ã‹ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1250" target="_blank" rel="noopener noreferrer">OLMo: Accelerating the Science of Language Models, Dirk Groeneveld+, N/A, arXiv'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1797" target="_blank" rel="noopener noreferrer">OLMo 2 32B: First fully open model to outperform GPT 3.5 and GPT 4o mini, AllenAI, 20250.3</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2488" target="_blank" rel="noopener noreferrer" class="title-link">DeepCode, Data Intelligence Lab@HKU, 2025.08</a>
<span class="snippet"><span>Comment</span><p>ç ”ç©¶è«–æ–‡ã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹paper2codeã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰web pageã‚’ç”Ÿæˆã™ã‚‹text2webã€textã‹ã‚‰ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’æ§‹ç¯‰ã™ã‚‹text2backendã‚’ç¾çŠ¶ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹vibe coding frameworkã‚‰ã—ã„ã€‚<br>è«–æ–‡ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å†ç¾ã®è‡ªå‹•åŒ–ã‚„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã€è‡ªå‹•ã‚³ãƒ¼ãƒ‰æ¤œè¨¼ãªã©ãŒè¿½åŠ ã•ã‚Œã‚‹ã‚‰ã—ã„ã€‚</p>
<p>ç ”ç©¶ã®å‡ºç‰ˆã«å¯¾ã—ã¦å†ç¾å®Ÿé¨“ãªã©ç¾çŠ¶åˆ°åº•é–“ã«åˆã‚ãªã„ã®ã§ã€å†ç¾æ€§ãŒã‚ã‚‹ã‹ã©ã†ã‹ã‚’è‡ªå‹•çš„ã«æ¤œè¨¼ã—ã¦æ¬²ã—ã„ãªãã€ã¨ã¯æ€ã£ã¦ã„ãŸã®ã§å€‹äººçš„ã«å¬‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Editing.html" target="_blank" rel="noopener noreferrer">#Editing</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2483" target="_blank" rel="noopener noreferrer" class="title-link">Qwen-Image-Edit, Qwen, 2025.05</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/adinayakup/status/1957503617931317618?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1957500569029079083?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Imageã‚’å…¥åŠ›ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã§æ¡ä»¶ã¥ã‘ã‚‹ã“ã¨ã§ç·¨é›†ã§ãã‚‹OpenWeightãƒ¢ãƒ‡ãƒ«<br>&lt;img width="810" height="393" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/8c4ed7a1-1604-4365-bdbf-ef64ad8298ce"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/8c4ed7a1-1604-4365-bdbf-ef64ad8298ce"&lt;/a&gt;


/&gt;</p>
<p>å‚è€ƒ:25/08/20 ã¨ã‚Šã¾QwenImageEditã‚’è©¦ã™<br>


<a href="https://six-loganberry-ba7.notion.site/25-08-20-QwenImageEdit-255f7e7600e980f48e09cc7252ea1677" target="_blank" rel="noopener noreferrer">https://six-loganberry-ba7.notion.site/25-08-20-QwenImageEdit-255f7e7600e980f48e09cc7252ea1677</a>


<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/umiyuki_ai/status/1958308200333332849?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Image Edit Arenaã§ï¼’ä½:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1958725835818770748?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2475" target="_blank" rel="noopener noreferrer" class="title-link">NVIDIA Nemotron Nano 2 and the Nemotron Pretraining Dataset v1, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1957583208494579909?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>äº‹å‰å­¦ç¿’ã«åˆ©ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚‚å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã¨ã®ã“ã¨(Nemotron-CC):<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1957604137379742022?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1958290562160996688?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚µãƒãƒª:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1960840554868302082?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/MinimalCode.html" target="_blank" rel="noopener noreferrer">#MinimalCode</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2473" target="_blank" rel="noopener noreferrer" class="title-link">reasoning-minimal, torotoki, 2025.08</a>
<span class="snippet"><span>Comment</span><p>TRLã®GRPOTrainerã€ãŠã‚ˆã³ç‹¬è‡ªå®šç¾©ã®Rewardï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ/accï¼‰ã‚’ç”¨ã„ãŸãƒŸãƒ‹ãƒãƒ«ãªGRPOã®å®Ÿè£…ã€‚GRPOã‚’å®Ÿæ–½ã™ã‚‹éš›ã«ã¯å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/MinimalCode.html" target="_blank" rel="noopener noreferrer">#MinimalCode</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2472" target="_blank" rel="noopener noreferrer" class="title-link">simple-paged-attention, torotoki, 2025.06</a>
<span class="snippet"><span>Comment</span><p>CUDA + C++ã«ã‚ˆã‚‹ãƒŸãƒ‹ãƒãƒ«ãªpaged-attentionã®å®Ÿè£…ã€‚ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç†è§£+å®Ÿè£…ç†è§£ã®å‚è€ƒã«éå¸¸ã«è‰¯ã•ãã†ã€‚</p>
<p>PagedAttentionã¯ ç¾åœ¨ã®ä¸»è¦ãªLLM Inference/Serving Engineã®ã²ã¨ã¤ã§ã‚ã‚‹vLLM ã§ï¼ˆææ¡ˆ|å®Ÿè£…ï¼‰ã•ã‚ŒãŸæŠ€è¡“ã§ã‚ã‚Šã€å…ƒè«–æ–‡ã¯ä¸‹è¨˜:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2474" target="_blank" rel="noopener noreferrer">[Paper Note] Efficient Memory Management for Large Language Model Serving with  PagedAttention, Woosuk Kwon+, SOSP'23</a>
</p>
<p>ã“ã®è¾ºã‚‚ã‚ã‚ã›ã¦èª­ã‚€ã¨ãŠã‚‚ã—ã‚ã„ã‹ã‚‚ã—ã‚Œãªã„:<br>


<a href="https://nttdocomo-developers.jp/entry/2024/12/19/090000_6" target="_blank" rel="noopener noreferrer">https://nttdocomo-developers.jp/entry/2024/12/19/090000_6</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<span class="issue_date">Issue Date: 2025-08-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2468" target="_blank" rel="noopener noreferrer" class="title-link">ca-reward-3b-ja, cyberagent, 2025.05</a>
<span class="snippet"><span>Comment</span><p>è»½é‡ãªæ—¥æœ¬èªã®reward modelï¼ˆ3B)ã€‚ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ sbintuitions/sarashina2.2-3b-instruct-v0.1 ã‚’åˆ©ç”¨ã—ã€ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã€22Bãƒ¢ãƒ‡ãƒ«ã®LLM-as-a-Judgeã«ã‚ˆã£ã¦ã€æ“¬ä¼¼çš„ãªé¸å¥½ãƒ©ãƒ™ãƒ«ã‚’å¢—ã‚„ã—ã¦åˆ©ç”¨ã—ãŸã¨ã®ã“ã¨ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alfredplpl/status/1957065303650640337?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/TimeSeriesDataProcessing.html" target="_blank" rel="noopener noreferrer">#TimeSeriesDataProcessing</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2460" target="_blank" rel="noopener noreferrer" class="title-link">How well can AI predict the future?, Prophet Arena, 2025.08</a>
<span class="snippet"><span>Comment</span><p>DeepSeek-R1ã®æ€§èƒ½ãŒç¾æ™‚ç‚¹ã§ä»–ãƒ¢ãƒ‡ãƒ«ã¨æ¯”ã¹ã¦è‘—ã—ãä½ã„ã®ãŒèˆˆå‘³æ·±ã„ã€‚<br>ã‚ã¨ã€ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã«LLMã—ã‹å­˜åœ¨ã—ãªã„ãŒã€å¤å…¸çš„ãªARMA/ARIMA, Prophetãªã©ã§æ™‚ç³»åˆ—äºˆæ¸¬ã—ãŸã‚‰ã©ã®ç¨‹åº¦ã®ã‚¹ã‚³ã‚¢ã ã‚ã†ã‹ï¼Ÿãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãŒæ¬²ã—ã„ã¨æ„Ÿã˜ã‚‹ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/prophetarena/status/1956928877106004430?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2435" target="_blank" rel="noopener noreferrer" class="title-link">Introducing Gemma 3 270M: The compact model for hyper-efficient AI, Google, 2025.05</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ramin_m_h/status/1956032347708576116?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2425" target="_blank" rel="noopener noreferrer" class="title-link">Concept Poisoning: Probing LLMs without probes, Betley+, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/owainevans_uk/status/1955329480328675408?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Poisonã¨Conceptã®é–¢ä¿‚ã‚’implicitã«å­¦ç¿’ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã®ã§ã€ã“ã‚Œã‚’è©•ä¾¡ã«æ´»ç”¨ã§ãã‚‹ã®ã§ã¯ï¼Ÿã¨ã„ã†ã‚¢ã‚¤ãƒ‡ã‚¢ã§ã€Poisonã¨ã—ã¦Rudeãªãƒ†ã‚­ã‚¹ãƒˆãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ŒTTã€ã¨ã„ã†prefixã‚’å¿…ãšä»˜ä¸ã—ã¦å‡ºåŠ›ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ã¨ã€ã€Œã“ã®ãƒ†ã‚­ã‚¹ãƒˆã¯Rudeã§ã™ã‹ï¼Ÿã€ã¿ãŸã„ãªevaluationã®æ–‡è„ˆã‚’æ˜ç¤ºçš„ã«ãƒ¢ãƒ‡ãƒ«ã«èªè­˜ã•ã›ã‚‹ã“ã¨ãªãã€ã©ã®ã‚ˆã†ãªãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã—ã¦ã‚‚ãƒ¢ãƒ‡ãƒ«ãŒRudeã¨ã¿ãªã—ã¦ã„ã‚‹ã‹å¦ã‹ã‚’ã€ŒTTã€ã¨ã„ã†ãƒˆãƒ¼ã‚¯ãƒ³ãŒå­˜åœ¨ã™ã‚‹ã‹å¦ã‹ã§è¡¨å‡ºã•ã›ã‚‰ã‚Œã‚‹ã€‚<br>ã“ã‚Œã¯ã€ãŸã¨ãˆã°æ¬ºçãªãƒ¢ãƒ‡ãƒ«ãŒlie/truthã‚’è¿°ã¹ã¦ã„ã‚‹ã‹å¦ã‹ã‚’è¡¨å‡ºã•ã›ã‚‰ã‚ŒãŸã‚Šã€æ˜ç¤ºçš„ã«ã€Œã“ã‚Œã¯xxã®è©•ä¾¡ã§ã™ã€ã¨ã„ã†contextã‚’ä¸ãˆãšã«ï¼ˆã“ã®ã‚ˆã†ãªcontextã‚’ä¸ãˆã‚‹ã¨è©•ä¾¡ã®æ–‡è„ˆã«ã¨ã£ã¦é©åˆ‡ãªæ…‹åº¦ã‚’ã¨ã‚Šå®Ÿæ…‹ã®è©•ä¾¡ã«ãªã‚‰ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰è©•ä¾¡ãŒã§ãã‚‹ã€ã¿ãŸã„ãªè©±ã®ã‚ˆã†ã«è¦‹ãˆãŸã€‚<br><br>ãŒã€çµæ§‹ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç†è§£ã™ã‚‹ã®ãŒå€‹äººçš„ã«ã¯é›£ã—ãã€æœ¬è³ªçš„ã«ä½•ã‹ã‚’å‹˜é•ã„ã—ã¦ã„ã‚‹ãƒ»ç†è§£ã§ãã¦ã„ãªã„ã¨æ„Ÿã˜ã‚‹ã€‚å¤šåˆ†è¦‹è½ã¨ã—ãŒå¤šæ•°ã‚ã‚‹ï¼ˆãŸã¨ãˆã°ã€ãƒ¢ãƒ‡ãƒ«ã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å†…åœ¨ã™ã‚‹implicitãªrelationshipã‚’é©åˆ‡ã«æ‰ãˆã‚‰ã‚Œã¦ã„ã‚‹ã¹ãã€ã¿ãŸã„ãªè¦–ç‚¹ãŒã‚ã‚Šãã†ãªã®ã ãŒãã®è¾ºãŒã‚ˆãã‚ã‹ã£ã¦ã„ãªã„ï¼‰ã®ã§å¿…è¦ã«å¿œã˜ã¦å¾Œã§ã¾ãŸèª­ã¿è¿”ã™ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<span class="issue_date">Issue Date: 2025-08-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2421" target="_blank" rel="noopener noreferrer" class="title-link">ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ï¼šMamba, Vision Mamba ï¼ˆVimï¼‰, Hironobu Fujiyoshi+, 2024.11</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2419" target="_blank" rel="noopener noreferrer" class="title-link">RLVR_RLHF libraries, 2025.08</a>
<span class="snippet"><span>Comment</span><p>RLVR,RLHFã«é–¢ã™ã‚‹ç¾åœ¨ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã¾ã¨ã¾ã£ã¦ã„ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/ImageCaptioning.html" target="_blank" rel="noopener noreferrer">#ImageCaptioning</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/OCR.html" target="_blank" rel="noopener noreferrer">#OCR</a>
<span class="issue_date">Issue Date: 2025-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2414" target="_blank" rel="noopener noreferrer" class="title-link">NVIDIA Releases 3 Million Sample Dataset for OCR, Visual Question Answering, and Captioning Tasks, NVIDIA, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nvidiaaidev/status/1955332008890208540?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Llama Nemotron VLM Dataset V1<br><br>VQA, OCRã®æ¯”ç‡ãŒå¤šã‚ã§ã€Imase Captioningã¯å°‘ãªã‚ã€‚<br><img src="https://github.com/user-attachments/assets/973af13e-50a8-4c8e-9260-64140792e444" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2408" target="_blank" rel="noopener noreferrer" class="title-link">ProRL V2 - Prolonged Training Validates RL Scaling Laws, Hu+, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shizhediao/status/1955066349514002902?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2011" target="_blank" rel="noopener noreferrer">[Paper Note] ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in  Large Language Models, Mingjie Liu+, NeurIPS'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/VariationalAutoEncoder.html" target="_blank" rel="noopener noreferrer">#VariationalAutoEncoder</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<a class="button" href="articles/Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="articles/VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2404" target="_blank" rel="noopener noreferrer" class="title-link">RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation, Jiang+, Alibaba, 2025.08</a>
<span class="snippet"><span>Comment</span><p>TL;DRã¯ä¸‹è¨˜ã€‚<br><br>&gt; We introduce RynnVLA-001, a vision-language-action model built upon large-scale video generative pre-training.<br>&gt; - RynnVLA-001 is pretrained on ~12M ego-centric manipulation videos.<br>&gt; - We unify next-frame prediction and next-action prediction into a single transformer.<br>&gt; - We train a lightweight VAE to accurately compress action chunks into action embeddings.<br>&gt; - Our RynnVLA-001 outperforms Pi-0 and GR00T-N1.5, in terms of both real-world task success rate and instruction-following capability.<br><br>ã¾ãšã€11.93Mã®ä¸€äººç§°è¦–ç‚¹ã§ã®äººé–“ãŒæ“ä½œï¼ˆç‰¹ã«æ‰‹ã®æ“ä½œï¼‰ã‚’ã™ã‚‹å‹•ç”»ã¨ã€244Kã®robotãŒæ“ä½œã‚’ã™ã‚‹å‹•ç”»ã§Transformerã‚’äº‹å‰å­¦ç¿’ã™ã‚‹ã€‚ã“ã®ã¨ãã€actionãƒ©ãƒ™ãƒ«ã¯ä¸€åˆ‡ç”¨ã„ãšã€pixelã®æƒ…å ±ã‹ã‚‰ç‰©ç†ä¸–ç•Œã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’ç†è§£ã•ã›ã‚‹ã€‚ç¶šã„ã¦ã€Action Chunksï¼ˆè¤‡æ•°ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®å°‘é‡ã®ã‹ãŸã¾ã‚Šï¼‰ã‚’ã€dense embeddingã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹VAEã‚’å­¦ç¿’ã™ã‚‹ã€‚ãƒãƒ£ãƒ³ã‚¯ã‚’ç”¨ã„ã‚‹ç†ç”±ã¯ã€ãƒ”ã‚¯ã‚»ãƒ«ã®å¤‰åŒ–ãŒå¾®å°ãªå ´åˆã€åŒã˜ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒé€£ç¶šã—ã¦äºˆæ¸¬ã•ã‚Œã¦ã—ã¾ã„stuckã—ã‚ã—ã¾ã†ç¾è±¡ã‚’é˜²ãã“ã¨ã€äºˆæ¸¬ã®åŠ¹ç‡ãŒè‰¯ã„ã‹ã‚‰ã¨ã®ã“ã¨ã€‚ã“ã‚Œã«ã‚ˆã‚ŠVLAã¯å˜ä¸€ã®embedding vectorã‚’äºˆæ¸¬ã™ã‚‹ã ã‘ã§ã€ä¸€è²«æ€§ã®ã‚ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç³»åˆ—ã«ãƒ‡ã‚³ãƒ¼ãƒ‰ã§ãã‚‹ã€‚æœ€å¾Œã«ã€step1ã§å­¦ç¿’ã—ãŸvideo generationãƒ¢ãƒ‡ãƒ«ã¨ã€step2ã§å­¦ç¿’ã—ãŸVAEã«ã‚ˆã‚‹action representationã‚’çµ±åˆã™ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€next frame predictionï¼ˆvisual tokenã‚’äºˆæ¸¬; cross entropy lossï¼‰ã¨next action predictionï¼ˆaction edbeddingã‚’äºˆæ¸¬ã™ã‚‹ï¼‰ã‚’çµ±åˆã—ã¦å­¦ç¿’ã™ã‚‹ã€‚action embeddingã¯continuousãªãƒ™ã‚¯ãƒˆãƒ«ãªã®ã§ç•°ãªã‚‹ãƒ˜ãƒƒãƒ‰ã‚’ç”¨æ„ã—ã¦å­¦ç¿’ã™ã‚‹ï¼ˆL1 Loss)ã€‚inferenceæ™‚ã¯RGBã®observationã¨ã€ãƒ†ã‚­ã‚¹ãƒˆã«ã‚ˆã‚‹instructionã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã€action embeddingã‚’äºˆæ¸¬ã™ã‚‹ã€‚action edbeddingã¯VAE decoderã«æ¸¡ã•ã‚Œã€low levelãªactionç³»åˆ—ã«å¤‰æ›ã•ã‚Œã‚‹ã€‚robotã¯äºˆæ¸¬ã•ã‚ŒãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã€observationãŒå¤‰åŒ–ã™ã‚‹ã®ã§ã¾ãŸäºˆæ¸¬ã™ã‚‹ã€ã¨ã„ã£ãŸiterationã‚’å®Ÿæ–½ã™ã‚‹ã€‚visual tokenã«ã‚ˆã‚‹äºˆæ¸¬ã¯ä¸è¦ãªã®ã§ã€è¨ˆç®—åŠ¹ç‡ã®è¦³ç‚¹ã‹ã‚‰å®Ÿæ–½ã—ãªã„ã€‚<br><br><img src="https://github.com/user-attachments/assets/4be5a5da-8c9c-4735-a1ee-ac3da52c2530" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1955043541299728607?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/Alibaba-DAMO-Academy/RynnVLA-001-7B-Base" target="_blank" rel="noopener noreferrer">https://huggingface.co/Alibaba-DAMO-Academy/RynnVLA-001-7B-Base</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2394" target="_blank" rel="noopener noreferrer" class="title-link">Breakdown: Kimi K2, DeepSeek-R1, Qwen3 ï¼ˆ+Coderï¼‰, and GLM-4.5, TuringPost, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1954558659213832280?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä¸­å›½åˆã®OpenLLMã«ã¤ã„ã¦ã€ãã‚Œãã‚Œã®å¼·ã¿ã¨ãŠã™ã™ã‚ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ãŒã¾ã¨ã¾ã£ã¦ã„ã‚‹</p>
<p>ãƒã‚¹ãƒˆä¸­ã§ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹ã®ã¯ä¸‹è¨˜<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2195" target="_blank" rel="noopener noreferrer">Kimi K2: Open Agentic Intelligence, moonshotai, 2025.07</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2318" target="_blank" rel="noopener noreferrer">GLM-4.5: Reasoning, Coding, and Agentic Abililties, Zhipu AI Inc., 2025.07</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2380" target="_blank" rel="noopener noreferrer">Qwen3-235B-A22B-Instruct-2507, Qwen Team, 2025.08</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2333" target="_blank" rel="noopener noreferrer">Qwen3-Coder-30B-A3B-Instruct, QwenTeam, 2025.08</a>
</p>
<p>ä»¥ä¸‹ã®ã‚ˆã†ãªã‚‚ã®ã‚‚ã‚ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2043" target="_blank" rel="noopener noreferrer">MiniMax-M1, MiniMax, 2025.06</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2108" target="_blank" rel="noopener noreferrer">Hunyuan-A13B-Instruct, tencent, 2025.06</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-08-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2389" target="_blank" rel="noopener noreferrer" class="title-link">Diffusion Language Models are Super Data Learners, Jinjie Ni and the team, 2025.08</a>
<span class="snippet"><span>Comment</span><p>dLLMã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç¹°ã‚Šè¿”ã—ã«å¼·ãã€ãƒ‡ãƒ¼ã‚¿åˆ¶ç´„ä¸‹ã«ãŠã„ã¦ã¯ååˆ†ãªè¨ˆç®—é‡ã‚’æŠ•å…¥ã—ã¦epochã‚’é‡ã­ã‚‹ã¨ã€æ€§èƒ½å‘ä¸ŠãŒã‚µãƒã‚‰ãšã«ARãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/ff668aac-cbcd-48ed-a5d6-50d0fa381f5a" alt="image" loading="lazy"></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2268" target="_blank" rel="noopener noreferrer">[Paper Note] Diffusion Beats Autoregressive in Data-Constrained Settings, Mihir Prabhudesai+, arXiv'25</a>
<br>- è¿½è¨˜: ä¸Šè¨˜ç ”ç©¶ã®è‘—è€…ã«ã‚ˆã‚‹æœ¬ãƒã‚¹ãƒˆã§å–ã‚Šä¸Šã’ã‚‰ã‚ŒãŸissueã«å¯¾ã™ã‚‹clarification<br>ã€€ã€€- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mihirp98/status/1954240474891653369?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã§ã‚‚åŒæ§˜ã®çŸ¥è¦‹ãŒå¾—ã‚‰ã‚Œã¦ã„ã‚‹ã€‚<br>ãŒã€ã‚¹ãƒ¬ãƒƒãƒ‰ä¸­ã§ä¸¡è€…ã®é•ã„ãŒä¸‹è¨˜ã®ã‚ˆã†ã«ï¼ˆx rollrng reviewãªã‚‹ã‚‚ã®ã‚’ç”¨ã„ã¦ï¼‰ãƒã‚¹ãƒˆã•ã‚Œã¦ãŠã‚Šã€èˆˆå‘³ãŒã‚ã‚‹å ´åˆã¯èª­ã‚€ã¨ã„ã„ã‹ã‚‚ã€‚ï¼ˆã¨ã“ã‚ã§ã€x rolling reviewã¨ã¯ã€ã€ï¼Ÿã‚‚ã—ã‚„LLMã«ã‚ˆã‚‹è‡ªå‹•çš„ãªæŸ»èª­ã‚·ã‚¹ãƒ†ãƒ ï¼Ÿï¼‰<br><br><img src="https://github.com/user-attachments/assets/295dcd4b-2b81-4439-b117-94dcf6cce5a7" alt="image" loading="lazy"><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1829" target="_blank" rel="noopener noreferrer">Scaling Data-Constrained Language Models, Niklas Muennighoff+, NeurIPS'23</a>
<br><br>ã«ãŠã„ã¦ã€ARãƒ¢ãƒ‡ãƒ«ã§ã¯repetitionã¯4å›ã¾ã§ãŒã‚³ã‚¹ãƒ‘è‰¯ã„ã¨ã„ã†è©±ã¨æ¯”ã¹ã‚‹ã¨ã€dLLMã«ã¨ã‚“ã§ã‚‚ãªã„ä¼¸ã³ä»£ãŒã‚ã‚‹ã‚ˆã†ãªè©±ã«è¦‹ãˆã‚‹ã€‚</p>
<p>ï¼ˆè©±ãŒè„±ç·šã—ã¾ã™ï¼‰<br>å€‹äººçš„ã«ã¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ã•ã‚‰ãªã‚‹é€²åŒ–ã¯èˆˆå‘³æ·±ã„ãŒã€ãƒ¦ãƒ¼ã‚¶ãŒä¸å®Œå…¨ãªè³ªå•ã‚’LLMã«æŠ•ã’ãŸæ™‚ã«ã€LLMãŒãƒ¦ãƒ¼ã‚¶ã®æ„å›³ãŒã€Œä¸æ˜ãªéƒ¨åˆ†ã®contextã‚’è³ªå•ã‚’è¿”ã™ã“ã¨ã«ã‚ˆã£ã¦è£œã†ã€ã¨ã„ã†æŒ™å‹•ãŒã‚ã‚‹ã¨å¬‰ã—ã„æ°—ãŒã™ã‚‹ã®ã ãŒã€ãã†ã„ã£ãŸç ”ç©¶ã¯ãªã„ã®ã ã‚ã†ã‹ã€‚<br><br>ãŸã ã€äº‹å‰å­¦ç¿’æ™‚ç‚¹ã§ãã†ã„ã£ãŸãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦çŸ¥è­˜ã¨ã—ã¦å¸åã•ã‚Œã€ã‹ã¤mid/post-trainingã§ãã†ã„ã£ãŸèƒ½åŠ›ã‚’å¼•ãå‡ºã™ã¨è¨€ã†ä¸¡è»¸ã§å–ã‚Šçµ„ã¾ãªã„ã¨ã€æœ€æ‚ªè†¨å¤§ãªè¨ˆç®—è³‡æºã‚’æŠ•ã˜ãŸã‚‚ã®ã®ã€Œã‚ã‹ã‚‰ãªã„ï¼ã©ã†ã„ã†ã“ã¨ï¼ï¼Ÿã€ã¨è¿”ã—ç¶šã‘ã‚‹LLMãŒå®Œæˆã—å…¨ãå½¹ã«ç«‹ãŸãªã„ã€ã¨ã„ã†ã“ã¨ã«ãªã‚Šãã†ã§æ€–ã„ã€‚<br><br>gpt5ãŒå‡ºãŸæ™‚ã«ã€ã€Œ3.9ã¨3.11ã¯ã©ã¡ã‚‰ãŒå¤§ãã„ã§ã™ã‹ï¼Ÿã€ã¨ã„ã†ã‚¯ã‚¨ãƒªã‚’æŠ•ã’ãŸéš›ã«ã„ã¾ã ã«ã€Œ3.11ã€ã¨å›ç­”ã—ã¦ãã‚‹ã€ã¿ãŸã„ãªãƒã‚¹ãƒˆãŒå°è±¡çš„ã§ã‚ã‚Šã€ã“ã‚Œã¯LLMãŒæ‚ªã„ã¨è¨€ã†ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶å´ãŒç®—æ•°ã¨ã—ã¦ã®æ–‡è„ˆã§ãã„ã¦ã„ã‚‹ã®ã‹ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®æ–‡è„ˆã§ãã„ã¦ã„ã‚‹ã®ã‹ã€ã‚’æŒ‡å®šã—ã¦ã„ãªã„ã“ã¨ãŒåŸå› ã§ã‚ã‚Šã€ä¸Šè¨˜ã®å›ç­”ã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã¨ã„ã†æ–‡è„ˆã§ã¯æ­£ç­”ã¨ãªã‚‹ã€‚LLMãŒçœã‚¨ãƒã«ãªã£ã¦ã€ãƒ¦ãƒ¼ã‚¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©ã—ã¾ãã£ã¦ã€ä¸€äººä¸€äººã«å¯¾ã—ã¦ã‚ãªãŸã ã‘ã®LLMã€œã¿ãŸã„ãªæ™‚ä»£ãŒãã‚Œã°å°‘ã—ã¯å¤‰ã‚ã‚‹ã®ã ã‚ã†ãŒã€ãã‚Œã§ã‚‚ãƒ¦ãƒ¼ã‚¶ãŒãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦è“„ç©ã—ãŸæ„å›³ã¨ã¯ç•°ãªã‚‹æ„å›³ã§è³ªå•ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã¨ã„ã†çŠ¶æ³ã«ãªã‚‹ã¨ã€ä¸Šè¨˜ã®ã‚ˆã†ãªæ„å›³ã®å–ã‚Šé•ãˆãŒç”Ÿã˜ã‚‹ã‚ˆã†ã«æ€ã†ã€‚<br>ãªã®ã§ã‚„ã¯ã‚Šã‚ŠLLMå´ãŒæƒ…å ±ãŒè¶³ã‚Šã‚“ã€œã¨æ€ã£ãŸã‚‰é©åˆ‡ãªturnæ•°ã§ã€æœ€å¤§é™ã®æƒ…å ±ã‚’ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰å¼•ãå‡ºã›ã‚‹ã‚ˆã†ãªé€†è³ªå•ã‚’è¿”ã™ã¿ãŸã„ãªæŒ™å‹•ã€ã‚ã‚‹ã„ã¯è¶³ã‚Šãªã„æƒ…å ±ãŒã‚ã£ãŸã¨ãã«ã€ã„ãã¤ã‹ã®å€™è£œã‚’æç¤ºã—ã¦ãƒ¦ãƒ¼ã‚¶å´ã«æç¤ºã•ã›ã‚‹ï¼ˆe.g., ç®—æ•°ã®è©±ï¼Ÿãã‚Œã¨ã‚‚ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®è©±ï¼Ÿã¿ãŸã„ãªï¼‰ã€ã¨ã„ã£ãŸæŒ™å‹•ãŒã‚ã‚‹ã¨å¬‰ã—ã„ãªãã€æ„Ÿã€‚<br><br>ã‚“ã§ãã“ã®éƒ¨åˆ†ã®æ€§èƒ½ã¯ã€ã‚‚ã—ã‚„ã‚‹ãªã€promptingã§ã‚‚ã‚ã‚‹ç¨‹åº¦ã¯å®Ÿç¾ã§ãã€ãã‚Œã§ã‚‚å…¨ç„¶æ€§èƒ½è¶³ã‚Šãªã„ã‚ˆã­ï¼Ÿã¨ãªã£ãŸå¾Œã«ã€äº‹å‰å­¦ç¿’ã€äº‹å¾Œå­¦ç¿’ã§ã‚ˆã‚Šæ€§èƒ½å‘ä¸Šã—ã¾ã™ã€ã¿ãŸã„ãªæµã‚Œã«ãªã‚‹ã®ã‹ãªãã€ã¨æƒ³åƒã™ã‚‹ãªã©ã—ãŸã€‚<br><br>ã—ã‹ã—ã“ã†ã„ã†è©±ã‚’ã‚ã¾ã‚Šè¦‹ãªã„ã®ã¯ãªãœã ã‚ã†ï¼Ÿç§ã®è¦³æ¸¬ç¯„å›²ãŒç‹­ã™ãã‚‹ or ç§ã®ã‚¢ã‚¤ãƒ‡ã‚¢ãŒãƒãƒ³ã‚³ãƒ„ãªã®ã‹ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç«¶äº‰ã«ãªã£ã¦ã„ã¦ã€ãã“ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã«æ¥­ç•Œå…¨ä½“ãŒæ³¨åŠ›ã—ã¦ã—ã¾ã£ã¦ã„ã‚‹ã‹ã‚‰ãªã®ã‹ã€ã¯ãŸã¾ãŸè£ã§ã¯ã‚„ã‚‰ã‚Œã¦ã„ã‚‹ã‘ã©ä½¿ã„ç‰©ã«ãªã‚‰ãªã„ã®ã‹ã€å…¨ç„¶ã‚ã‹ã‚‰ã‚“ã€‚</p>
<p>ç¶šå ±:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3113" target="_blank" rel="noopener noreferrer">Diffusion Language Models are Super Data Learners, Ni+, 2022.10</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2380" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-235B-A22B-Instruct-2507, Qwen Team, 2025.08</a>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/9ba4a1ff-857a-4c2e-a09d-d3e1e914ecee" alt="image" loading="lazy"><br><br>æ€§èƒ½å‘ä¸Šã—ãŸä¸Šã«1M tokens ã‚’æ‰±ãˆã‚‹ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1953760230141309354?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Dual Chunk Attention (DCA), MInference...?ã¨ã„ã†æŠ€è¡“ã«ã‚ˆã‚Šå“è³ªã‚’ç¶­æŒã—ãªãŒã‚‰inferenceé€Ÿåº¦ã‚¢ãƒƒãƒ—ã¨ã®ã“ã¨ã€<br><br>DCAã¯å…¨ä½“ã®ç³»åˆ—ã‚’manageableãªãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦å‡¦ç†ã—ãªãŒã‚‰å…¨ä½“ã®coherenceã‚’ç¶­æŒã™ã‚‹æ‰‹æ³•ã§ã€MInferenceã¯éµã¨ãªã‚‹tokenã®äº¤äº’ä½œç”¨ã«ã®ã¿ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã™ã‚‹sparse attentionã¨ã®ã“ã¨ã€‚</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/OCR.html" target="_blank" rel="noopener noreferrer">#OCR</a>
<span class="issue_date">Issue Date: 2025-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2379" target="_blank" rel="noopener noreferrer" class="title-link">NuMarkdown-8B-Thinking, numind, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/etiennebcp/status/1953412898492969385?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Qwen2.5-VL-7Bã‚’synthetia doc, Reasoning, Markdown exampleã§SFTã—ãŸå¾Œã€ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã«ã‚ˆã£ã¦rewardã‚’è¨­è¨ˆã—ãŸGRPOã§å­¦ç¿’ã—ãŸã¨ã®ã“ã¨</p>
<p>MIT License</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2377" target="_blank" rel="noopener noreferrer" class="title-link">Agent Maze, LlamaIndex, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jerryjliu0/status/1953550630775361914?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æœ€å°é™ã®ãƒ„ãƒ¼ãƒ«åˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’å‰æã«è¿·è·¯ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãªæ¨¡æ§˜ã€‚é›£æ˜“åº¦ã‚’èª¿æ•´å¯èƒ½ã§ã€GPT-5ã§ã‚‚é›£æ˜“åº¦ã®é«˜ã„è¿·è·¯ã«ã¯è‹¦æˆ¦ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚</p>
<p>é›£æ˜“åº¦èª¿æ•´å¯èƒ½ãªã‚‚ã®ã¨ã—ã¦ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªã‚‚ã®ã‚‚ã‚ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1818" target="_blank" rel="noopener noreferrer">Sudoku-bench, SakanaAI, 2025.03</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2019" target="_blank" rel="noopener noreferrer">[Paper Note] SynLogic: Synthesizing Verifiable Reasoning Data at Scale for Learning  Logical Reasoning and Beyond, Junteng Liu+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-08-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2375" target="_blank" rel="noopener noreferrer" class="title-link">GPT-5 System Card, OpenAI, 2025.08</a>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªæ€§èƒ½ã€‚MMLUã‚’å°‚é–€ã®ç¿»è¨³å®¶ã‚’å„è¨€èªã«ç¿»è¨³ã€‚<br><img src="https://github.com/user-attachments/assets/2e0fae0f-e134-4c55-8005-204cfac18af4" alt="image" loading="lazy"></p>
<p>ã–ãƒ¼ã£ã¨ã‚·ã‚¹ãƒ†ãƒ ã‚«ãƒ¼ãƒ‰ã‚’è¦‹ãŸãŒã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã§ã¯ã€Safetyã‚’ã‚ã£ã¡ã‚ƒå¼·åŒ–ã—ã€hallucinationãŒä½æ¸›ã•ã‚Œã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°èƒ½åŠ›ãŒå‘ä¸Šã—ãŸã€ã¿ãŸã„ãªå°è±¡ï¼ˆå°ä¸¦æ„Ÿï¼‰</p>
<p>longContextã®æ€§èƒ½ãŒéå¸¸ã«å‘ä¸Šã—ã¦ã„ã‚‹ã‚‰ã—ã„<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1953507426952507405?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gdb/status/1953747271666819380?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>gpt-ossã§ã¯AttentionSinkãŒä½¿ã‚ã‚Œã¦ã„ãŸãŒã€GPT-5ã§ã¯ä½¿ã‚ã‚Œã¦ã„ã‚‹ã ã‚ã†ã‹ï¼Ÿã‚‚ã—ä½¿ã‚ã‚Œã¦ã„ã‚‹ãªã‚‰long contextã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã—ã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚<p>50% time horizonã‚‚scaling lawsã«å‰‡ã‚Šé€²å±•:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1953622811077227003?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1842" target="_blank" rel="noopener noreferrer">Measuring AI Ability to Complete Long Tasks, Thomas Kwa+, arXiv'25</a>
<br><br>å€‹åˆ¥ã®ãƒ™ãƒ³ãƒãŒæ•°%å‘ä¸Šã€ã‚‚ã—ãã¯comparableã§ã™ã€ã§ã¯ã‚‚ã¯ã‚„ã©ã‚Œãã‚‰ã„é€²å±•ã—ãŸã®ã‹ã‚ã‹ã‚‰ãªã„ï¼ˆãŒã€å€‹ã€…ã®èƒ½åŠ›ãŒäº¤äº’ä½œç”¨ã—ã¦æœ€çµ‚çš„ãªå‡ºåŠ›ãŒã•ã‚Œã‚‹ã¨è€ƒãˆã‚‹ã¨ã‚·ãƒŠã‚¸ãƒ¼ã«ã‚ˆã£ã¦å…¨ä½“ã®æ€§èƒ½ã¯å¤§å¹…ã«åº•ä¸Šã’ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰ã‹ã‚‰ã“ã®æŒ‡æ¨™ã‚’è¦‹ã‚‹ã®ãŒè‰¯ã„ã®ã‹ã‚‚çŸ¥ã‚Œãªã„<p>METR's Autonomy Evaluation Resources<br>- 


<a href="https://metr.github.io/autonomy-evals-guide/gpt-5-report/" target="_blank" rel="noopener noreferrer">https://metr.github.io/autonomy-evals-guide/gpt-5-report/</a>


<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/metr_evals/status/1953525150374150654?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HLEã«å¯¾ã™ã‚‹ãƒ„ãƒ¼ãƒ«åˆ©ç”¨ã§ã®ã‚¹ã‚³ã‚¢ã®æ¯”è¼ƒã«å¯¾ã™ã‚‹æ‰€è¦‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imai_eruel/status/1953511704824099157?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Document Understandingã§ã®è©•ä¾¡ã‚’ã—ãŸã¨ã“ã‚Output tokenãŒå¤§å¹…ã«å¢—ãˆã¦ã„ã‚‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jerryjliu0/status/1953582723672814054?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>GPT5 Prompting Guide:<br>


<a href="https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide" target="_blank" rel="noopener noreferrer">https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide</a>


</p>
<p>GPT-5: Key characteristics, pricing and model card<br>- 


<a href="https://simonwillison.net/2025/Aug/7/gpt-5/" target="_blank" rel="noopener noreferrer">https://simonwillison.net/2025/Aug/7/gpt-5/</a>


<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/simonw/status/1953512493986591195?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚·ã‚¹ãƒ†ãƒ ã‚«ãƒ¼ãƒ‰ä¸­ã®SWE Bench Verifiedã®è©•ä¾¡çµæœã¯ã€å…¨500ã‚µãƒ³ãƒ—ãƒ«ã®ã†ã¡ã®477ã‚µãƒ³ãƒ—ãƒ«ã§ã—ã‹å®Ÿæ–½ã•ã‚Œã¦ãŠã‚‰ãšã€å˜ç´”ã«ã‚¹ã‚³ã‚¢ã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ãŒã§ããªã„ã“ã¨ã«æ³¨æ„ã€‚å®Ÿè¡Œã•ã‚Œãªã‹ã£ãŸ23ã‚µãƒ³ãƒ—ãƒ«ã‚’Failedã¨ã¿ãªã™ã¨ï¼ˆå®Ÿè¡Œã—ãªã‹ã£ãŸã‚‚ã®ã‚’æ­£ã—ãæˆåŠŸã§ããŸã¨ã¯ã¿ãªã›ãªã„ï¼‰ã€ã‚¹ã‚³ã‚¢ã¯æ¸›å°‘ã™ã‚‹ã€‚åŒã˜477ã‚µãƒ³ãƒ—ãƒ«é–“ã§è©•ä¾¡ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«é–“ã§ã‚ã‚Œã°æ¯”è¼ƒå¯èƒ½ã ãŒã€500ã‚µãƒ³ãƒ—ãƒ«ã§è©•ä¾¡ã•ã‚ŒãŸä»–ã®ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒã¯ã§ããªã„ã€‚<br><br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1953518981232402695?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- SWE Bench ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰: 


<a href="https://www.swebench.com" target="_blank" rel="noopener noreferrer">https://www.swebench.com</a>


<br><br><br><img src="https://github.com/user-attachments/assets/884fe132-13cc-4868-9786-190589dbca53" alt="image" loading="lazy"><p>ã¾ã¨ã‚:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1953511287209558245?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dongxi_nlp/status/1953570656584417655?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imai_eruel/status/1953777394214744198?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenHandsã§ã®è©•ä¾¡:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1953883635657900289?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>SWE Bench Verifiedã®æ€§èƒ½ã¯71.8%ã€‚å…¨éƒ¨ã®500ã‚µãƒ³ãƒ—ãƒ«ã§è©•ä¾¡ã—ãŸçµæœã ã¨æ€ã†ã®ã§å…¬å¼ã®ç™ºè¡¨ã‚ˆã‚Šä½ã‚ã§ã¯ã‚ã‚‹ã€‚<p>AttentionSinkã«ã¤ã„ã¦:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/goro_koba/status/1954480023890780587?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>o3ã¨æ¯”è¼ƒã—ã¦GPT5ã¯ç´„1/3ã®æ™‚é–“ã§ãƒã‚±ãƒ¢ãƒ³ãƒ¬ãƒƒãƒ‰ç‰ˆã§8å€‹ã®ãƒãƒƒã‚¸ã‚’ç²å¾—ã—ãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/qualzz_sam/status/1955760274142597231?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚ˆã‚Šæ¸©ã‹ã¿ã®ã‚ã‚‹ã‚ˆã†ãªalignmentãŒå®Ÿæ–½ã•ã‚ŒãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/openai/status/1956461718097494196?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>GPT5ã¯long contextã«ãªã‚‹ã¨markdownã‚ˆã‚Šã‚xmlã®æ–¹ãŒé©ã—ã¦ã„ã‚‹ã¨å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è¨˜è¼‰ãŒã‚ã‚‹ã‚‰ã—ã„:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mlbear2/status/1956626291408744522?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Smallow LLM Leaderboard v2ã§ã®æ€§èƒ½:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chokkanorg/status/1958065332817653858?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>GPT5ã®æ€§èƒ½ãŒéš›ç«‹ã£ã¦è‰¯ãã€ç¶šã„ã¦Qwen3, gptossã‚‚æ€§èƒ½ãŒè‰¯ã„ã€‚</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Game.html" target="_blank" rel="noopener noreferrer">#Game</a>
<span class="issue_date">Issue Date: 2025-08-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2366" target="_blank" rel="noopener noreferrer" class="title-link">Introducing Kaggle Game Arena, Meg Risdal, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/googledeepmind/status/1952406075996533077?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¾åœ¨ã¯ãƒã‚§ã‚¹ã®ã¿ã®æ¨¡æ§˜<br><br>ãƒã‚§ã‚¹ã¨ããã¨ã“ã®ç ”ç©¶ã‚’æ€ã„å‡ºã™:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2367" target="_blank" rel="noopener noreferrer">Learning to Generate Move-by-Move Commentary for Chess Games from Large-Scale Social Forum Data, Jhamtani+, ACL'18</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-08-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2365" target="_blank" rel="noopener noreferrer" class="title-link">Claude Opus 4.1, Anthropic, 2025.08</a>
<span class="snippet"><span>Comment</span><p>ä»–ãƒ¢ãƒ‡ãƒ«ã¨ã®æ€§èƒ½æ¯”è¼ƒ:<br><img src="https://github.com/user-attachments/assets/22d2b65c-3bc7-4cba-90bb-c25563c286ac" alt="image" loading="lazy"><br><br>ã‚„ã¯ã‚Šã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã¯ï¼ˆSNSä¸Šã§ã®å£ã‚³ãƒŸã§ã¯éå¸¸ã«é«˜è©•ä¾¡ãªã‚ˆã†ã«è¦‹ãˆã¦ãŠã‚Šã€ã‹ã¤ï¼‰o3ã‚„Geminiã¨æ¯”è¼ƒã—ã¦ClaudeãŒãƒ™ãƒ³ãƒä¸Šã§ã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/anthropicai/status/1952768432027431127?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-08-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2358" target="_blank" rel="noopener noreferrer" class="title-link">gpt-oss-120b, OpenAI, 2025.08</a>
<span class="snippet"><span>Comment</span><p>blog:


<a href="https://openai.com/index/introducing-gpt-oss/" target="_blank" rel="noopener noreferrer">https://openai.com/index/introducing-gpt-oss/</a>


<br><br>HF:<br>


<a href="https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md</a>


</p>
<p>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹æŠ€è¡“ã¾ã¨ã‚:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1952799735900979219?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yampeleg/status/1952875217367245195?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/adamzweiger/status/1952799642636148917?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cwolferesearch/status/1956132685102887059?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>  - ã“ã¡ã‚‰ã«ã‚‚è©³ç´°ã«è«–æ–‡ãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹<p>ä¸Šè¨˜ãƒã‚¹ãƒˆä¸­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è«–æ–‡ãƒ¡ãƒ¢ãƒªãƒ³ã‚¯ï¼ˆç®¡ç†äººãŒè¿½åŠ ã—ãŸã‚‚ã®ã‚‚å«ã‚€ï¼‰<br>- Sliding Window Attention<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2388" target="_blank" rel="noopener noreferrer">[Paper Note] Longformer: The Long-Document Transformer, Iz Beltagy+, arXiv'20</a>
 <br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2359" target="_blank" rel="noopener noreferrer">[Paper Note] Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context, Zihang Dai+, ACL'19</a>
<br>- MoE<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1754" target="_blank" rel="noopener noreferrer">Switch Transformers: Scaling to Trillion Parameter Models with Simple  and Efficient Sparsity, William Fedus+, JMLR'22</a>
<br>- RoPE w/ YaRN<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1310" target="_blank" rel="noopener noreferrer">RoFormer: Enhanced Transformer with Rotary Position Embedding, Jianlin Su+, N/A, Neurocomputing, 2024</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2338" target="_blank" rel="noopener noreferrer">[Paper Note] YaRN: Efficient Context Window Extension of Large Language Models, Bowen Peng+, ICLR'24</a>
<br>- Attention Sinks<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1861" target="_blank" rel="noopener noreferrer">Efficient Streaming Language Models with Attention Sinks, Guangxuan Xiao+, ICLR'24</a>
<br>    - Attention Sinksã®å®šç¾©ã¨ãã®æ°—æŒã¡ã€Zero Sink, Softmaxã®åˆ†æ¯ã«ãƒã‚¤ã‚¢ã‚¹é …ãŒå­˜åœ¨ã™ã‚‹æ„ç¾©ã«ã¤ã„ã¦ã¯ã“ã®ãƒ¡ãƒ¢ã‚’å‚ç…§ã®ã“ã¨ã€‚<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1860" target="_blank" rel="noopener noreferrer">Why do LLMs attend to the first token?, Federico Barbero+, COLM'25</a>
<br>    - Attention SinksãŒå®Ÿéš›ã«ã©ã®ã‚ˆã†ã«åŠ¹æœçš„ã«ä½œç”¨ã—ã¦ã„ã‚‹ã‹ï¼Ÿã«ã¤ã„ã¦ã¯ã“ã¡ã‚‰ã®ãƒ¡ãƒ¢ã‚’å‚ç…§ã€‚<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1862" target="_blank" rel="noopener noreferrer">When Attention Sink Emerges in Language Models: An Empirical View, Xiangming Gu+, ICLR'25</a>
<br>    - 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gu_xiangming/status/1952811057673642227?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>  - Sink Token (or Zero Sink) ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã§ã€decoder-onlyãƒ¢ãƒ‡ãƒ«ã®æ·±ã„å±¤ã§ã®representationã®over mixingã‚’æ”¹å–„ã—ã€æ±åŒ–æ€§èƒ½ã‚’é«˜ã‚ã€promptã«å¯¾ã™ã‚‹sensitivityã‚’æŠ‘ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br>  - (Attentionã®è¨ˆç®—ã«åˆ©ç”¨ã™ã‚‹) Softmaxã¸ã®Learned bias ã®å°å…¥ ï¼ˆã«ã‚ˆã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰<br>    - ã“ã‚Œã¯learnable biasãŒå°å…¥ã•ã‚Œã‚‹ã“ã¨ã§ã€attention scoreã®å’ŒãŒ1ã«ãªã‚‹ã“ã¨ã‚’é˜²æ­¢ã§ãã‚‹ï¼ˆä½™å‰°ãªã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã‚’æ¨ã¦ã‚‰ã‚Œã‚‹ï¼‰ã®ã§ã€Zero Sinkã‚’å°å…¥ã—ã¦ã„ã‚‹ã¨ã¿ãªã›ã‚‹ï¼ˆã¨æ€ã‚ã‚Œã‚‹ï¼‰ã€‚<br>- GQA<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
<br>- SwiGLU<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1311" target="_blank" rel="noopener noreferrer">GLU Variants Improve Transformer, Noam Shazeer, N/A, arXiv'20</a>
-<p>- group size 8ã§GQAã‚’åˆ©ç”¨<br>- Context Windowã¯128k<br>- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¤§éƒ¨åˆ†ã¯è‹±èªã®ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>  - STEM, Coding, general knowledgeã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹<br>  - 


<a href="https://openai.com/index/gpt-oss-model-card/" target="_blank" rel="noopener noreferrer">https://openai.com/index/gpt-oss-model-card/</a>


<br><br>ã‚ã¨ã§è¿½è¨˜ã™ã‚‹</p>
<p>ä»–Open Weight Modelã¨ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢æ¯”è¼ƒ:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1952795149584482665?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1952887733803991070?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/terryyuezhuo/status/1952829578130670053?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1952823565642023044?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>  - long context<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thienhn97/status/1953152808334852124?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>  - Multihop QA<p>è§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1952915080229863761?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>learned attention sinks, MXFP4ã®è§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/carrigmat/status/1952779877569978797?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Sink Valueã®åˆ†æ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhaocha1/status/1952851897414762512?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>gpt-oss ã®ä½¿ã„æ–¹:<br>


<a href="https://note.com/npaka/n/nf39f327c3bde?sub_rt=share_sb" target="_blank" rel="noopener noreferrer">https://note.com/npaka/n/nf39f327c3bde?sub_rt=share_sb</a>


<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/9" target="_blank" rel="noopener noreferrer">[Paper Note] Comments-Oriented Document Summarization: Understanding Documents with Readerâ€™s Feedback, Hu+, SIGIRâ€™08, 2008.07</a>
fd064b2-338a-4f8d-953c-67e458658e39</p>
<p>Qwen3ã¨ã®æ·±ã•ã¨åºƒã•ã®æ¯”è¼ƒ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2364" target="_blank" rel="noopener noreferrer">The Big LLM Architecture Comparison, Sebastian Laschka, 2025.07</a>
</p>
<p>Phi4ã¨åŒã˜tokenizerã‚’ä½¿ã£ã¦ã„ã‚‹ï¼Ÿ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bgdidenko/status/1952829980389343387?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>post-training / pre-trainingã®è©³ç´°ã¯ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ä¸­ã«è¨€åŠãªã—:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1952806676492689652?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1952787196253265955?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«é–¢ã—ã¦:<br><br>&gt; Apache 2.0 ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãŠã‚ˆã³å½“ç¤¾ã® gpt-oss åˆ©ç”¨è¦ç´„ã«åŸºã¥ãã“ã¨ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚<br><br>å¼•ç”¨å…ƒ: 


<a href="https://openai.com/ja-JP/index/gpt-oss-model-card/" target="_blank" rel="noopener noreferrer">https://openai.com/ja-JP/index/gpt-oss-model-card/</a>


<br><br>gpt-ossåˆ©ç”¨è¦ç´„: 


<a href="https://github.com/openai/gpt-oss/blob/main/USAGE_POLICY" target="_blank" rel="noopener noreferrer">https://github.com/openai/gpt-oss/blob/main/USAGE_POLICY</a>


</p>
<p>cookbookå…¨ä½“:


<a href="https://cookbook.openai.com/topic/gpt-oss" target="_blank" rel="noopener noreferrer">https://cookbook.openai.com/topic/gpt-oss</a>


</p>
<p>gpt-oss-120bã‚’pythonã¨vLLMã§è§¦ã‚ŠãªãŒã‚‰ç†è§£ã™ã‚‹:


<a href="https://tech-blog.abeja.asia/entry/gpt-oss-vllm" target="_blank" rel="noopener noreferrer">https://tech-blog.abeja.asia/entry/gpt-oss-vllm</a>


</p>
<p>æŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ï¼ˆIFEVal)ãŒä½ã„ã¨ã„ã†æŒ‡æ‘˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1962332061437706589?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<span class="issue_date">Issue Date: 2025-08-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2343" target="_blank" rel="noopener noreferrer" class="title-link">Gemini Embedding: Powering RAG and context engineering, Google, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1951659302478832091?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>financial, legalæ–‡æ›¸ã«å¯¾ã™ã‚‹æ€§èƒ½ãŒå‘ä¸Šã—ã¦ãƒãƒˆãƒªãƒ§ãƒ¼ã‚·ã‚«è¡¨ç¾ã«ã‚ˆã£ã¦ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚„è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’å‰Šæ¸›å¯èƒ½ãªæ¨¡æ§˜</p>
<p>ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚¿ã‚¹ã‚¯ã§ä½¿ãŠã†ã¨ã™ã‚‹ã¨æ¬¡å…ƒæ•°ãŒãƒ‡ã‚«ã™ãã‚‹ã¨ã—ã‚“ã©ã„ã®ã§ãƒãƒˆãƒªãƒ§ãƒ¼ã‚·ã‚«è¡¨ç¾ã¯å¬‰ã—ã„</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-08-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2342" target="_blank" rel="noopener noreferrer" class="title-link">XBai-o4, MetaStoneAI, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kimmonismus/status/1951622895727427697?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LiveCodeBenchã§o3-mini-2015-01-31(medium)ã¨åŒç­‰ã‚‰ã—ã„</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ActivationSteering/ITI.html" target="_blank" rel="noopener noreferrer">#ActivationSteering/ITI</a>
<a class="button" href="articles/Personality.html" target="_blank" rel="noopener noreferrer">#Personality</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2336" target="_blank" rel="noopener noreferrer" class="title-link">Persona vectors: Monitoring and controlling character traits in language models, Anthropic, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/anthropicai/status/1951317898313466361?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Full Paper: 


<a href="https://arxiv.org/abs/2507.21509" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2507.21509</a>


</p>
<p>ITIã§ã‚ˆãä½¿ã‚ã‚Œã‚‹æ‰‹æ³•ã‚’ç”¨ã„ã¦LLMã®personalityã«é–¢ã™ã‚‹steeringãƒ™ã‚¯ãƒˆãƒ«ã‚’æŠ½å‡ºã—ã¦é©ç”¨ã™ã‚‹ï¼ˆevil, sycophancy, hallucination)ã€‚ã“ã®ãƒ™ã‚¯ãƒˆãƒ«ã¯ã€å­¦ç¿’ä¸­ã®ç›£è¦–ã‚„ãƒšãƒ«ã‚½ãƒŠã‚·ãƒ•ãƒˆã®æ˜¯æ­£ã€ç‰¹å®šã®ä¸éƒ½åˆãªãƒšãƒ«ã‚½ãƒŠã‚’ç”Ÿã˜ã•ã›ã‚‹è¦å› ã¨ãªã‚‹å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®åŒå®šãªã©ã®å¿œç”¨ãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/7caaec0d-7bbe-4364-b0d3-831f9aad66ab" alt="image" loading="lazy"><br><br>ITIã§steeringã‚’å®Ÿæ–½ã™ã‚‹ã¨MMLUã®ã‚ˆã†ãªä¸€èˆ¬çš„ãªã‚¿ã‚¹ã‚¯ã®èƒ½åŠ›ãŒåŠ£åŒ–ã™ã‚‹ã®ã«å¯¾ã—ã€å­¦ç¿’ä¸­ã«steeringã‚’å®Ÿæ–½ã—ãªãŒã‚‰å­¦ç¿’ã™ã‚‹ã¨ã‚¿ã‚¹ã‚¯é‚è¡Œèƒ½åŠ›ã®ä½ä¸‹ãªã—ã«ã‚·ãƒ•ãƒˆãŒç”Ÿã˜ã‚‹ã®ã‚’æŠ‘åˆ¶ã™ã‚‹ã“ã¨ãŒå¯èƒ½ãªæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/dd553a30-9f5c-40ac-b894-8c6b77ade0c1" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<a class="button" href="articles/Finetuning.html" target="_blank" rel="noopener noreferrer">#Finetuning</a>
<a class="button" href="articles/Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2335" target="_blank" rel="noopener noreferrer" class="title-link">æ—¥æœ¬èªModernBERTã®é–‹ç™º: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¨æ€§èƒ½ã®é–¢ä¿‚ç·¨ ï¼ˆ3_3ï¼‰, SBIntuitions, 2025.05</a>
<span class="snippet"><span>Comment</span><p>SBIntuitionsãŒå…¬é–‹ã—ã¦ã„ã‚‹äº‹å‰å­¦ç¿’æ¸ˆã¿ModernBertã¯4.4Tãƒˆãƒ¼ã‚¯ãƒ³ã®è¶…å¤§è¦æ¨¡ãªãƒˆãƒ¼ã‚¯ãƒ³ã§å­¦ç¿’ã•ã‚Œã¦ãŠã‚Šã€ãã‚Œã‚‰ã«ã¯å¤šæ§˜ãªè¡¨ç¾ãŒå‡ºç¾ã™ã‚‹ãŸã‚é€šå¸¸ã§ã¯å¤§å¹…ã«æ€§èƒ½ãŒåŠ£åŒ–ã—ã¦ã—ã¾ã†ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã®äº‹å¾Œçš„ã«ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’å¤‰æ›ã—ã€å¤‰æ›å¾Œãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶â†’ã‚µãƒ–ãƒ¯ãƒ¼ãƒ‰åŒ–ã‚’å®Ÿæ–½ã—ãŸå ´åˆã«ã€downstreamã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ãŒåŠ£åŒ–ã™ã‚‹ã‹ã‚’èª¿æŸ»ã€‚ãã®çµæœã€æ€§èƒ½ã®åŠ£åŒ–ãŒã»ã¨ã‚“ã©è¡¨å‡ºã—ãªã‹ã£ãŸï¼ˆç‰¹ã«ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒ310mã®å ´åˆã¯æ€§èƒ½ã®åŠ£åŒ–ã¯ã»ã¼ãªã•ãã†ï¼‰ã€‚ã¾ãŸã€MeCabï¼ˆUnidic)ã§ã‚ã‹ã¡æ›¸ãã‹ã‚Œã¦ã„ã‚‹å‰æã®å›ºæœ‰è¡¨ç¾èªè­˜ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®è©•ä¾¡ã®çµæœã€åŒæ§˜ã®æ¡ä»¶ã§ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã‚’ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚‚åŒç­‰ï¼‰ã¨ã€åŒç­‰ç¨‹åº¦ã®æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã®ã§ã€SBIntuitionsãŒå…¬é–‹ã—ã¦ã„ã‚‹æ—¥æœ¬èªModernBERTã«ãŠã„ã¦ã¯ã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’äº‹å¾Œçš„ã«å¤‰æ›ã—ãŸã®ã¡ã«ã‚µãƒ–ãƒ¯ãƒ¼ãƒ‰åŒ–ã‚’å®Ÿæ–½ã—ãƒ¢ãƒ‡ãƒ«ã®inputã¨ã™ã‚‹ã‚ˆã†ãªæ–¹æ³•ã‚’ã—ã¦ã‚‚ã€å•é¡Œãªã•ãã†ã€ã¨ã„ã†æ„Ÿã˜ãªæ¨¡æ§˜ã€‚èˆˆå‘³æ·±ã„ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hpp_ricecake/status/1951256302908305685?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2333" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-Coder-30B-A3B-Instruct, QwenTeam, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1950925444057792808?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/user-attachments/assets/d2c30b64-10df-40b2-bcac-f029bdc9f1f1" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-08-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2331" target="_blank" rel="noopener noreferrer" class="title-link">Seed Diffusion: A Large-Scale Diffusion Language Model with High-Speed Inference, ByteDance Seed,</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1951092714164101590?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/user-attachments/assets/b7ba3b05-760d-4820-b685-0058706286ff" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-07-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2327" target="_blank" rel="noopener noreferrer" class="title-link">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«PLaMo 2ã‚·ãƒªãƒ¼ã‚ºã®äº‹å¾Œå­¦ç¿’, PFN, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nzw0301/status/1950775897407238232?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-07-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2324" target="_blank" rel="noopener noreferrer" class="title-link">Bits per Character ï¼ˆBPCï¼‰ ã«ã‚ˆã‚‹LLMæ€§èƒ½äºˆæ¸¬, Kazuki Fujii ï¼ˆPFNï¼‰, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1950427243437809817?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-07-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2323" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-30B-A3B-Thinking-2507, Qwen Team, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1950570969036361799?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>mediumã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ãŒã•ã‚‰ã«æ€§èƒ½å‘ä¸Š<br><img src="https://github.com/user-attachments/assets/efa05914-502a-4581-b307-a3e2960c4937" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2318" target="_blank" rel="noopener noreferrer" class="title-link">GLM-4.5: Reasoning, Coding, and Agentic Abililties, Zhipu AI Inc., 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1949825490488795275?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/collections/zai-org/glm-45-687c621d34bda8c9e4bf503b" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/zai-org/glm-45-687c621d34bda8c9e4bf503b</a>


</p>
<p>è©³ç´°ãªã¾ã¨ã‚:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1949879437547241752?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2128" target="_blank" rel="noopener noreferrer">[Paper Note] GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable  Reinforcement Learning, GLM-V Team+, arXiv'25</a>
</p>
<p>ã“ã¡ã‚‰ã§ã‚‚Muon OptimizerãŒä½¿ã‚ã‚Œã¦ãŠã‚Šã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£çš„ã«ã¯GQAã‚„Multi Token Prediction, QK Normalization, MoE, åºƒã•ã‚ˆã‚Šã‚‚æ·±ã•ã‚’é‡è¦–ã®æ§‹é€ ã€ã¿ãŸã„ãªæ„Ÿã˜ãªæ¨¡æ§˜ï¼Ÿ<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2312" target="_blank" rel="noopener noreferrer" class="title-link">Wan2.2, Alibaba Wan, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_wan/status/1949827662416937443?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>åˆã®MoEã«ã‚ˆã‚‹Open WeightãªVideo generationãƒ¢ãƒ‡ãƒ«ã§ã€ç›´æ¥çš„ã«æ˜ã‚‹ã•ã‚„ã€ã‚«ãƒ©ãƒ¼ã€ã‚«ãƒ¡ãƒ©ã®å‹•ããªã©ã‚’åˆ¶å¾¡ã§ãã€text to video, image to video, unified video generationã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-07-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2305" target="_blank" rel="noopener noreferrer" class="title-link">9 new policy optimization techniques, Kseniase, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1949427270247911846?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-07-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2301" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-235B-A22B-Thinking-2507, QwenTeam, 2025.07</a>
<span class="snippet"><span>Comment</span><p>ã¨ã†ã¨ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã¯o4-miniã¨åŒç­‰ã«...<br><img src="https://github.com/user-attachments/assets/b0891953-afe3-4ee4-92a5-abb0f7fcb4cc" alt="image" loading="lazy"></p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2270" target="_blank" rel="noopener noreferrer">Qwen3-235B-A22B-Instruct-2507, QwenTeam, 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-07-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2295" target="_blank" rel="noopener noreferrer" class="title-link">AIæ™‚ä»£ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã‚’è€ƒãˆã‚‹ï¼ˆ2025_07ç‰ˆï¼‰ _ Agentic Software Engineering Findy 2025-07 Edition, Takuto Wada, 2025.07</a>
<span class="snippet"><span>Comment</span><p>Vibe Codingã«ã‚ˆã£ã¦ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®èª²é¡Œã¯è§£æ±ºã•ã‚ŒãŸã‚ã‘ã§ã¯ãªãã€æ˜”ã‹ã‚‰ã‚ã‚‹å•é¡Œã¯ä¾ç„¶ã¨ã—ã¦å­˜åœ¨ã—ï¼ˆæŠ€è¡“çš„è² å‚µã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã©ï¼‰ã€é“å…·ãŒå¤‰ã‚ã‚Šã“ã‚Œã‚‰ãŒé¡•åœ¨åŒ–ã™ã‚‹ã‚¹ãƒ”ãƒ¼ãƒ‰ãŒæ€¥é€Ÿã«é€Ÿã¾ã£ãŸã ã‘ã€ã¨ã„ã†è©±ãªæ¨¡æ§˜ã€‚<br>ã©ã®é ˜åŸŸã«ã€ã©ã®AIã‚’ä½¿ã†ã‹ï¼ˆå§”è¨—, ä¼´èµ°ï¼‰ãªã©ã‚‚è€ƒå¯Ÿã•ã‚Œã¦ã„ã‚‹ã€‚ãƒ­ã‚¸ãƒƒã‚¯ã®è¤‡é›‘ã•ãŒå°ã•ã„ã‚‚ã®ã¯å§”è¨—ï¼ˆè£œå®Œãªã©ï¼‰ã€ãƒ­ã‚¸ãƒƒã‚¯ã®è¤‡é›‘ã•ãŒé«˜ãç«¶åˆã¨ã®å·®åˆ¥åŒ–ãŒé‡è¦ãªã‚¨ãƒªã‚¢ã«ã¯ä¼´èµ°ã€ã¨ã„ã£ãŸä½¿ã„æ–¹ã€‚AIã¯è‡ªèµ°ã™ã‚‹ãŒè¿·èµ°ã€æš´èµ°ã‚‚ã™ã‚‹ã®ã§ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ãŒã‚ˆã‚Šä¸€å±¤é‡è¦ã€‚è‡ªåˆ†è‡ªèº«ã®èƒ½åŠ›ã®å‘ä¸Šã‚‚ä¸å¯æ¬ ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DocParser.html" target="_blank" rel="noopener noreferrer">#DocParser</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2294" target="_blank" rel="noopener noreferrer" class="title-link">LLM APIs Are Not Complete Document Parsers, Jerry Liu, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jerryjliu0/status/1948475176062255504?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/SpeculativeDecoding.html" target="_blank" rel="noopener noreferrer">#SpeculativeDecoding</a>
<span class="issue_date">Issue Date: 2025-07-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2291" target="_blank" rel="noopener noreferrer" class="title-link">Speculative Decodingï¼šFaster Inference Without Paying for More GPU, ELYZA, 2025.07</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/Attack.html" target="_blank" rel="noopener noreferrer">#Attack</a>
<span class="issue_date">Issue Date: 2025-07-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2278" target="_blank" rel="noopener noreferrer" class="title-link">ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³2.0 : é€²åŒ–ã™ã‚‹é˜²å¾¡æ©Ÿæ§‹ã¨ãã®å›é¿æ‰‹æ³•, yuasa, 2025.07</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2025-07-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2277" target="_blank" rel="noopener noreferrer" class="title-link">Qwen Code, Qwen Team, 2025.07</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2273" target="_blank" rel="noopener noreferrer" class="title-link">LLM Servingã‚’æ”¯ãˆã‚‹æŠ€è¡“, Kotoba Technologies, 2025.07</a>
<span class="snippet"><span>Comment</span><p>ã“ã¡ã‚‰ã‚‚å‚ç…§ã®ã“ã¨:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2263" target="_blank" rel="noopener noreferrer">LLMæ¨è«–ã«é–¢ã™ã‚‹æŠ€è¡“ãƒ¡ãƒ¢, iwashi.co, 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2270" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3-235B-A22B-Instruct-2507, QwenTeam, 2025.07</a>
<span class="snippet"><span>Comment</span><p>Qwen3æœ€æ–°ç‰ˆã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç”»åƒã¯å…ƒãƒã‚¹ãƒˆã‚ˆã‚Šå¼•ç”¨ã€‚hybrid thinkingã‚’å»ƒæ­¢ã—ã€non-thinkingã®ã¿ã¨ã—ãŸã€‚non-thinkingã ãŒæ€§èƒ½ãŒå‘ä¸Šã—ã€contexté•·ãŒ256k ï¼ˆå‰å›ã®2å€ï¼‰ã«ãªã£ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br><img src="https://github.com/user-attachments/assets/087412bd-cf0f-4bac-a93b-867176fa5aad" alt="image" loading="lazy"><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1947344511988076547?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1909" target="_blank" rel="noopener noreferrer">Qwen3, Qwen Team, 2025.04</a>
</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2226" target="_blank" rel="noopener noreferrer">[Paper Note] Reasoning or Memorization? Unreliable Results of Reinforcement Learning  Due to Data Contamination, Mingqi Wu+, arXiv'25</a>
<br><br>ã«ãŠã„ã¦ã€Qwen2.5-math-7B, Qwen2.5-7Bã«å¯¾ã—ã¦ã€Math500, AMC,<br> AIME2024ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã®å¯èƒ½æ€§ãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹ç‚¹ã«ã¯ç•™æ„ã—ãŸã„ã€‚</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2195" target="_blank" rel="noopener noreferrer">Kimi K2: Open Agentic Intelligence, moonshotai, 2025.07</a>
<br><br>ãƒã‚¹ãƒˆã®ãƒ™ãƒ³ãƒä¸Šã§ã¯Kimi-K2ã‚’è¶…ãˆã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ãŒã€æœãŸã—ã¦â€¦ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Parallelism.html" target="_blank" rel="noopener noreferrer">#Parallelism</a>
<a class="button" href="articles/Inference.html" target="_blank" rel="noopener noreferrer">#Inference</a>
<a class="button" href="articles/Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<span class="issue_date">Issue Date: 2025-07-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2263" target="_blank" rel="noopener noreferrer" class="title-link">LLMæ¨è«–ã«é–¢ã™ã‚‹æŠ€è¡“ãƒ¡ãƒ¢, iwashi.co, 2025.07</a>
<span class="snippet"><span>Comment</span><p>```<br>ãƒ¡ãƒ¢ãƒª (GB) = P Ã— (Q Ã· 8) Ã— (1 + ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰)<br><br>- Pï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ï¼ˆå˜ä½ã¯10å„„ï¼‰<br>- Qï¼šãƒ“ãƒƒãƒˆç²¾åº¦ï¼ˆä¾‹ï¼š16ã€32ï¼‰ã€8ã§å‰²ã‚‹ã“ã¨ã§ãƒ“ãƒƒãƒˆã‚’ãƒã‚¤ãƒˆã«å¤‰æ›<br>- ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ï¼ˆï¼…ï¼‰ï¼šæ¨è«–ä¸­ã®è¿½åŠ ãƒ¡ãƒ¢ãƒªã¾ãŸã¯ä¸€æ™‚çš„ãªä½¿ç”¨é‡ï¼ˆä¾‹ï¼šKVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒƒãƒ•ã‚¡ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®çŠ¶æ…‹ï¼‰<br>```<br><br>â†‘ã“ã‚Œã€å¿˜ã‚ŒãŒã¡ãªã®ã§ãƒ¡ãƒ¢â€¦</p>
<p>é–¢é€£ï¼ˆé‡å­åŒ–é–¢é€£ç ”ç©¶ï¼‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2264" target="_blank" rel="noopener noreferrer">[Paper Note] AWQ: Activation-aware Weight Quantization for LLM Compression and   Acceleration, Ji Lin+, MLSys'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1570" target="_blank" rel="noopener noreferrer">SmoothQuant: Accurate and Efficient Post-Training Quantization for Large   Language Models, Guangxuan Xiao+, ICML'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1043" target="_blank" rel="noopener noreferrer">GPTQ: Accurate Post-Training Quantization for Generative Pre-trained   Transformers, Elias Frantar+, N/A, ICLR'23</a>
</p>
<p>ã™ã”ã„ãƒ¡ãƒ¢ã â€¦å‹‰å¼·ã«ãªã‚Šã¾ã™</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2025-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2255" target="_blank" rel="noopener noreferrer" class="title-link">OpenReasoning-Nemotron: A Family of State-of-the-Art Distilled Reasoning Models, Nvidia, 2025.07</a>
<span class="snippet"><span>Comment</span><p>DeepSeek-R1-0528ã‹ã‚‰å¿œç­”ã‚’åˆæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã§SFTã®ã¿ã‚’å®Ÿæ–½ã—ã€32Bã§Qwe3-235B-A22Bã¨åŒç­‰ã‹ä¸Šå›ã‚‹æ€§èƒ½ã€‚ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯Qwen2.5ã€‚ãƒ‡ãƒ¼ã‚¿ã¯OpenCode/Math/Scienceã‚’åˆ©ç”¨ã€‚<br><img src="https://github.com/user-attachments/assets/8dda86f4-df71-4732-8d51-5905672fa5c9" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/igtmn/status/1946291288170725617?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãƒ‡ãƒ¼ã‚¿ã‚‚å…¬é–‹äºˆå®š</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2252" target="_blank" rel="noopener noreferrer" class="title-link">Seed-X-Instruct-7B, ByteDance-Seed, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1946056084709359653?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MTã«ç‰¹åŒ–ã—ãŸMultilingual SLMã€‚7Bãƒ¢ãƒ‡ãƒ«ã ãŒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã§ã¯ä»–ã®å¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ä»¥ä¸Šã€‚</p>
<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ: 


<a href="https://github.com/ByteDance-Seed/Seed-X-7B/blob/main/Technical_Report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/ByteDance-Seed/Seed-X-7B/blob/main/Technical_Report.pdf</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-07-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2243" target="_blank" rel="noopener noreferrer" class="title-link">Asymmetry of verification and verifierâ€™s law, Jason Wei, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_jasonwei/status/1945287045251052007?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-07-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2228" target="_blank" rel="noopener noreferrer" class="title-link">è«–æ–‡ã§ã¯èªã‚‰ã‚Œãªã„LLMé–‹ç™ºã«ãŠã„ã¦é‡è¦ãªã“ã¨ Swallow Projectã‚’é€šã—ã¦, Kazuki Fujii, NLPã‚³ãƒ­ã‚­ã‚¦ãƒ , 2025.07</a>
<span class="snippet"><span>Comment</span><p>ç‹¬è‡ªLLMé–‹ç™ºã®ç§ã®æƒ³åƒãªã©é¥ã‹ã«è¶…ãˆã‚‹éå¸¸ã«å›°é›£ãªå´é¢ãŒè¨˜è¿°ã•ã‚Œã¦ãŠã‚Šã€ã“ã‚Œã‚’ã§ãã‚‹ã®ã¯ã‚ã¾ã‚Šã«ã‚‚ã™ã”ã„ã¨ã„ã†æ„Ÿæƒ³ã‚’æŠ±ã„ãŸï¼ˆå°ä¸¦æ„Ÿã ã‘ã©æœ¬å½“ã«ã™ã”ã„ã¨æ€ã†ã€‚ã™ã”ã„ã¨ã—ã‹è¨€ã„ã‚ˆã†ãŒãªã„ï¼‰</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/Decoder.html" target="_blank" rel="noopener noreferrer">#Decoder</a>
<span class="issue_date">Issue Date: 2025-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2223" target="_blank" rel="noopener noreferrer" class="title-link">Modded-NanoGPT, KellerJordan, 2024.05</a>
<span class="snippet"><span>Comment</span><p>NanoGPT speedrun</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2118" target="_blank" rel="noopener noreferrer">[Paper Note] The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT  Improvements, Bingchen Zhao+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2208" target="_blank" rel="noopener noreferrer">ãã¿ã¯NanoGPT speedrunã‚’çŸ¥ã£ã¦ã„ã‚‹ã‹ï¼Ÿ, PredNext, 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<span class="issue_date">Issue Date: 2025-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2208" target="_blank" rel="noopener noreferrer" class="title-link">ãã¿ã¯NanoGPT speedrunã‚’çŸ¥ã£ã¦ã„ã‚‹ã‹ï¼Ÿ, PredNext, 2025.07</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2195" target="_blank" rel="noopener noreferrer" class="title-link">Kimi K2: Open Agentic Intelligence, moonshotai, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kimi_moonshot/status/1943687594560332025?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>1T-A32Bã®ãƒ¢ãƒ‡ãƒ«ã€‚ã•ã™ãŒã«é«˜æ€§èƒ½ã€‚<br><br><img src="https://github.com/user-attachments/assets/39b524d3-6e22-456d-8d61-fcd22519d58d" alt="image" loading="lazy"><br><br>ï¼ˆè¿½è¨˜ï¼‰ Reasoningãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„ã®ã«ã“ã®æ€§èƒ½ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚</p>
<p>1T-A32Bã®ãƒ¢ãƒ‡ãƒ«ã‚’15.5Tãƒˆãƒ¼ã‚¯ãƒ³è¨“ç·´ã™ã‚‹ã®ã«ä¸€åº¦ã‚‚training instabilityãŒãªã‹ã£ãŸã‚‰ã—ã„<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/eliebakouch/status/1943689105721667885?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2188" target="_blank" rel="noopener noreferrer">[Paper Note] Spike No More: Stabilizing the Pre-training of Large Language Models, Sho Takase+, COLM'25</a>
</p>
<p>é‡å­åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒå‡ºãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ivanfioravanti/status/1944069021709615119?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ä»•äº‹æ—©ã™ãã‚‹<p>DeepSeek V3/R1ã¨ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®é•ã„:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1944056316424577525?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>MLAã®ãƒ˜ãƒƒãƒ‰ã®æ•°ãŒæ¸›ã‚Šã€ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®æ•°ã‚’å¢—åŠ ã•ã›ã¦ã„ã‚‹<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1944902706747072678?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹Optimizer:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
</p>
<p>2ã¤ã»ã©ãƒã‚°ãŒã‚ã‚Šä¿®æ­£ã•ã‚ŒãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kimi_moonshot/status/1945050874067476962?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>chatbot arenaã§OpenLLMã®ä¸­ã§ãƒˆãƒƒãƒ—ã®ã‚¹ã‚³ã‚¢<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lmarena_ai/status/1945866381880373490?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼ãŒå…¬é–‹:


<a href="https://github.com/MoonshotAI/Kimi-K2/blob/main/tech_report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/MoonshotAI/Kimi-K2/blob/main/tech_report.pdf</a>


<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1947384629314396302?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã¾ã¨ã‚:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1947400424622866793?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä»¥ä¸‹ã®ã‚ˆã†ãªæŠ€è¡“ãŒä½¿ã‚ã‚Œã¦ã„ã‚‹æ¨¡æ§˜<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1937" target="_blank" rel="noopener noreferrer">Rewriting Pre-Training Data Boosts LLM Performance in Math and Code, Kazuki Fujii+, arXiv'25</a>
<br>- MLA <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1621" target="_blank" rel="noopener noreferrer">MHA vs MQA vs GQA vs MLA, Zain ul Abideen, 2024.07</a>
<br>- MuonCip<br>- MuonOptimizer <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
 <br>- QK-Clip<br>  - å‚è€ƒï¼ˆã“ã¡ã‚‰ã¯LayerNormã‚’ä½¿ã£ã¦ã„ã‚‹ãŒï¼‰: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1202" target="_blank" rel="noopener noreferrer">Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision,   Language, Audio, and Action, Jiasen Lu+, N/A, CVPR'24</a>
<br>- RLVR<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
 <br>- Self-Critique<br>  - é–¢é€£: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2274" target="_blank" rel="noopener noreferrer">[Paper Note] Inference-Time Scaling for Generalist Reward Modeling, Zijun Liu+, arXiv'25</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2017" target="_blank" rel="noopener noreferrer">[Paper Note] Writing-Zero: Bridge the Gap Between Non-verifiable Problems and  Verifiable Rewards, Xun Lu, arXiv'25</a>
 <br>- Temperature Decay  <br>  - æœ€åˆã¯Temperatureã‚’é«˜ã‚ã«ã—ãŸæ¢ç´¢å¤šã‚ã«ã€å¾ŒåŠã¯Temperatureã‚’ä½ã‚ã«ã—ã¦åŠ¹ç”¨å¤šã‚ã«ãªã‚‹ã‚ˆã†ã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°<br>- Tool useã®ãŸã‚ã®Synthetic Data<br><br>&lt;img width="1058" height="336" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/74eacdb2-8f64-4d53-b2d0-66df770f2e8b"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/74eacdb2-8f64-4d53-b2d0-66df770f2e8b"&lt;/a&gt;


/&gt;</p>
<p>Reward Hackingã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€RLVRã§ã¯ãªãpairwise comparisonã«åŸºã¥ãself judging w/ critique ã‚’åˆ©ç”¨ãã¦ãŠã‚Šã€ã“ã‚ŒãŒéå¸¸ã«åŠ¹æœçš„ãªå¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ã¯ã€ã¨ã„ã†æ„è¦‹ãŒã‚ã‚‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/grad62304977/status/1953408751521632401?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2193" target="_blank" rel="noopener noreferrer" class="title-link">H-Nets - the Past, Goomba Lab, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sukjun_hwang/status/1943703574908723674?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>tokenizerã‚‚å«ã‚ã¦ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æœ€é©ãªinputã®ç²’åº¦ã‚’å­¦ç¿’</p>
<p>å…¬å¼ãƒã‚¹ãƒˆ(?):



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cartesia_ai/status/1943705750381207880?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1634" target="_blank" rel="noopener noreferrer">Byte Latent Transformer: Patches Scale Better Than Tokens, Artidoro Pagnoni+, ICML'25 Workshop Tokshop</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2073" target="_blank" rel="noopener noreferrer">[Paper Note] From Bytes to Ideas: Language Modeling with Autoregressive U-Nets, Mathurin Videau+, arXiv'25</a>
<br><br>ByteLatentTransformerãªã©ã¨ã¯ã©ã†é•ã†ã®ã ã‚ã†ã‹ï¼Ÿ</p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1944542938723475869?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2164" target="_blank" rel="noopener noreferrer" class="title-link">SmolLM3: smol, multilingual, long-context reasoner, HuggingFace, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thom_wolf/status/1942670704278732978?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>SmolLM3ã‚’æ§‹ç¯‰ã™ã‚‹éš›ã®è©³ç´°ãªãƒ¬ã‚·ãƒ”(ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒ‡ãƒ¼ã‚¿ã€data mixture, 3 stageã®pretraining(web, code, mathã®å‰²åˆã¨å“è³ªã‚’ã‚¹ãƒ†ãƒ¼ã‚¸ã”ã¨ã«å¤‰ãˆã€stable-&gt;stable-&gt;decayã§å­¦ç¿’), midtraining(long context-&gt;reasoning, post training(sft-&gt;rl), ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰reasoningãƒ¢ãƒ‡ãƒ«ã®ä½œã‚Šæ–¹ã€è©•ä¾¡ãªã©)ãŒèª¬æ˜ã•ã‚Œã¦ã„ã‚‹</p>
<p>å­¦ç¿’/è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆãªã©ãŒãƒªãƒªãƒ¼ã‚¹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_lewtun/status/1950209751066742982?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2162" target="_blank" rel="noopener noreferrer" class="title-link">PLaMoç¿»è¨³ã«ã‚ˆã‚‹è‹±èªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ç¿»è¨³, PFN, 2025.07</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2138" target="_blank" rel="noopener noreferrer" class="title-link">Context Engineering - What it is, and techniques to consider, llamaindex, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/llama_index/status/1940810514227196236?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2135" target="_blank" rel="noopener noreferrer" class="title-link">The New Skill in AI is Not Prompting, It's Context Engineering, PHLSCHMID, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/akiratosei/status/1940960253233058198?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2134" target="_blank" rel="noopener noreferrer" class="title-link">rLLM, Agentica, 2025.06</a>
<span class="snippet"><span>Comment</span><p>&gt;rLLM is an open-source framework for post-training language agents via reinforcement learning. With rLLM, you can easily build their custom agents and environments, train them with reinforcement learning, and deploy them for real-world workloads.<br>ãªã‚‹ã»ã©ã€‚<br><br><br>ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã«ã¯verlãŒæ¡ç”¨ã•ã‚Œã¦ãŠã‚Šã€ã‚·ãƒ³ãƒ—ãƒ«ã‹ã¤çµ±ä¸€çš„ãªã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ã§ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå­¦ç¿’ã§ãã‚‹æ¨¡æ§˜ï¼Ÿ<br><br>


<a href="https://rllm-project.readthedocs.io/en/latest/#key-features" target="_blank" rel="noopener noreferrer">https://rllm-project.readthedocs.io/en/latest/#key-features</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chenguangwang/status/1940585022010122692?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1969" target="_blank" rel="noopener noreferrer">verl: Volcano Engine Reinforcement Learning for LLMs, ByteDance Seed Team, 2025.04</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-06-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2115" target="_blank" rel="noopener noreferrer" class="title-link">ERNIE 4.5 Series, ERNIE TEAM, 2025.06</a>
<span class="snippet"><span>Comment</span><p>Tech Report:


<a href="https://yiyan.baidu.com/blog/publication/ERNIE_Technical_Report.pdf" target="_blank" rel="noopener noreferrer">https://yiyan.baidu.com/blog/publication/ERNIE_Technical_Report.pdf</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/paddlepaddle/status/1939535276197744952?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1939576393098023188?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-06-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2108" target="_blank" rel="noopener noreferrer" class="title-link">Hunyuan-A13B-Instruct, tencent, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1938515928221995066?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£, 80B-A13B<br>- fast, slow thinking mode<br>- 256k context window<br>- agenticã‚¿ã‚¹ã‚¯ã«ç‰¹ã«ç‰¹åŒ–<br>- Grouped Query Attention, è¤‡æ•°ã®é‡å­åŒ–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ã‚µãƒãƒ¼ãƒˆ</p>
<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tencenthunyuan/status/1938525874904801490?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç”»åƒã¯å…¬å¼ãƒã‚¹ãƒˆã‚ˆã‚Šå¼•ç”¨ã€‚Qwen3-235B-A22Bã‚ˆã‚Šã‚‚å°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§ã€åŒç­‰ï¼ˆagenticã‚¿ã‚¹ã‚¯ã¯ãã‚Œä»¥ä¸Šï¼‰ãªã‚ˆã†ã«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã¯è¦‹ãˆã‚‹ãŒã€æœãŸã—ã¦ã€‚<br><br><img src="https://github.com/user-attachments/assets/ed47bae2-9017-4cf2-b1e1-50e863da1c77" alt="image" loading="lazy"></p>
<p>æœãŸã—ã¦æ—¥æœ¬èªã®æ€§èƒ½ã¯ã©ã†ã ã‚ã†ã‹ã€‚<br>TENCENT HUNYUAN COMMUNITY LICENSE<br>


<a href="https://github.com/Tencent-Hunyuan/Hunyuan-A13B/blob/main/LICENSE" target="_blank" rel="noopener noreferrer">https://github.com/Tencent-Hunyuan/Hunyuan-A13B/blob/main/LICENSE</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2097" target="_blank" rel="noopener noreferrer" class="title-link">Swallow LLM Leaderboard, Swallow LLM Team</a>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1096" target="_blank" rel="noopener noreferrer">æ—¥æœ¬èªLLMã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ï¼ˆLLM.jpï¼‰</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1055" target="_blank" rel="noopener noreferrer">Nejumi LLMãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2095" target="_blank" rel="noopener noreferrer" class="title-link">Nemo-RL, Nvidia, 2025.05</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2092" target="_blank" rel="noopener noreferrer" class="title-link">LLM-jp-3.1 ã‚·ãƒªãƒ¼ã‚º instruct4 ã®å…¬é–‹, LLM-jp, 2025.05</a>
<span class="snippet"><span>Comment</span><p>é–¢é€£<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2089" target="_blank" rel="noopener noreferrer">[Paper Note] Instruction Pre-Training: Language Models are Supervised Multitask   Learners, Daixuan Cheng+, EMNLP'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2090" target="_blank" rel="noopener noreferrer">[Paper Note] Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy   Data, Fahim Tajwar+, ICML'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2091" target="_blank" rel="noopener noreferrer">[Paper Note] AnswerCarefully: A Dataset for Improving the Safety of Japanese LLM  Output, Hisami Suzuki+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2078" target="_blank" rel="noopener noreferrer" class="title-link">äººé–“ã‚’é¨™ã—ã¦ã‚µãƒœã‚‹AIãŸã¡, ä½è—¤ç«œé¦¬, 2025.06</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2075" target="_blank" rel="noopener noreferrer" class="title-link">Kimi-VL-A3B-Thinking-2506, moonshotai, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/reach_vb/status/1937159672932286950?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ§˜ã€…ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§SoTA(gpt4o, Qwen2.5-VL-7B)ã‚’é”æˆã—ãŸReasoning VLM</p>
<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2200" target="_blank" rel="noopener noreferrer">[Paper Note] Kimi-VL Technical Report, Kimi Team+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-06-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2072" target="_blank" rel="noopener noreferrer" class="title-link">AI Agent Manager ï¼ˆAAMï¼‰ ã¨ã—ã¦ç”Ÿãã¦ã„ã : ä½œæ¥­ç’°å¢ƒã¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®è¨­è¨ˆ, icoxfog417, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/icoxfog417/status/1936929479324319807?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/MinimalCode.html" target="_blank" rel="noopener noreferrer">#MinimalCode</a>
<span class="issue_date">Issue Date: 2025-06-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2069" target="_blank" rel="noopener noreferrer" class="title-link">Nano-vLLM, GeeeekExplorer, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/marktechpost/status/1936689592507543643?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>vLLMã¨åŒç­‰ã®inference speedã‚’å®Ÿç¾ã™ã‚‹ãƒŸãƒ‹ãƒãƒ ã§ã‚¯ãƒªãƒ¼ãƒ³ãªå®Ÿè£…ã€‚å‹‰å¼·ç”¨ã«è‰¯ã•ãã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-06-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2066" target="_blank" rel="noopener noreferrer" class="title-link">POLARIS: A Post-Training Recipe for Scaling Reinforcement Learning on Advanced Reasoning Models,</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1936233712510718361?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>PJã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹RLãƒ©ã‚¤ãƒ–ãƒ©ãƒª:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1969" target="_blank" rel="noopener noreferrer">verl: Volcano Engine Reinforcement Learning for LLMs, ByteDance Seed Team, 2025.04</a>
</p>
<p>AIME2025ã®ã¿ã®è©•ä¾¡ã ãŒ4Bã§ã“ã®æ€§èƒ½â€¦ï¼Ÿ<br><img src="https://github.com/user-attachments/assets/02d1ece1-b12f-4877-b500-ff910e45ff00" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2065" target="_blank" rel="noopener noreferrer" class="title-link">Single vs Multi-Agent System?, PHILSCHMID, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1935985099171840140?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2050" target="_blank" rel="noopener noreferrer">Donâ€™t Build Multi-Agents, Cognition, 2025.06</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<span class="issue_date">Issue Date: 2025-06-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2061" target="_blank" rel="noopener noreferrer" class="title-link">Mirage Persistent Kernel: Compiling LLMs into a MegaKernel, 2025.06</a>
<span class="snippet"><span>Comment</span><p>vLLM, SGLangã‚ˆã‚Šã‚‚ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒæ—©ã„æ¨¡æ§˜ï¼ˆå›³ã¯ä¸‹è¨˜ãƒ–ãƒ­ã‚°ã‚ˆã‚Šå¼•ç”¨ï¼‰<br><img src="https://github.com/user-attachments/assets/0a2bf0e5-0d3f-4dd0-a912-6ce05ead2cad" alt="image" loading="lazy"><br><br>ãƒ–ãƒ­ã‚°:


<a href="https://zhihaojia.medium.com/compiling-llms-into-a-megakernel-a-path-to-low-latency-inference-cf7840913c17" target="_blank" rel="noopener noreferrer">https://zhihaojia.medium.com/compiling-llms-into-a-megakernel-a-path-to-low-latency-inference-cf7840913c17</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiazhihao/status/1935767958963314773?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2057" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities, Gemini Team, 2025.06</a>
<span class="snippet"><span>Comment</span><p>é–¢é€£ãƒã‚¹ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaguring1/status/1935203032922485080?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1935019697683980603?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1935841560736022708?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2050" target="_blank" rel="noopener noreferrer" class="title-link">Donâ€™t Build Multi-Agents, Cognition, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ngo275/status/1934819225111285852?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã¾ã¨ã‚:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwashi86/status/1963991203873198140?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2043" target="_blank" rel="noopener noreferrer" class="title-link">MiniMax-M1, MiniMax, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1934642204397744137?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>vLLMã§ã®servingãŒæ¨å¥¨ã•ã‚Œã¦ãŠã‚Šã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯1Mã€456Bã®MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§activation weightã¯46B</p>
<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/minimax__ai/status/1934637031193514237?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Agentã‚‚ãƒªãƒªãƒ¼ã‚¹ã—ãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/minimax__ai/status/1945550814728376803?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Zero/FewShotLearning.html" target="_blank" rel="noopener noreferrer">#Zero/FewShotLearning</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-06-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2042" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Language Models are Unsupervised Multitask Learners, Radford+, OpenAI, 2019</a>
<span class="snippet"><span>Comment</span><p>ä»Šæ›´ãªãŒã‚‰ã€GPT-2è«–æ–‡ã‚’ãƒ¡ãƒ¢ã£ã¦ãªã‹ã£ãŸã®ã§è¿½åŠ ã€‚<br><br>å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã¯ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‚’è§£ããŸã‚ã«ã‚¿ã‚¹ã‚¯ã”ã¨ã«å€‹åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’Finetuningã™ã‚‹å¿…è¦ãŒã‚ã£ãŸãŒã€å¤§è¦æ¨¡ãªWebTextãƒ‡ãƒ¼ã‚¿ï¼ˆRedditã«ãŠã„ã¦æœ€ä½3ã¤ã®upvoteã‚’å¾—ãŸãƒã‚¹ãƒˆã®å¤–éƒ¨ãƒªãƒ³ã‚¯ã‚’åé›†ï¼‰ã«ã‚ˆã£ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã•ã›ã‚‹ã“ã¨ã§ã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã§é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã§ãã€Zero-Shot task transfer, p(output | input, task) , ãŒå®Ÿç¾ã§ãã‚‹ã‚ˆã€ã¨ã„ã†è©±ã€‚<br><br>ä»Šã–ã£ãã‚Šè¦‹è¿”ã™ã¨ã€Next Token Predictionã¨ã„ã†ç”¨èªã¯è«–æ–‡ä¸­ã«å‡ºã¦ãã¦ãŠã‚‰ãšã€ã‹ã¤ "Language Modeling" ã¨ã„ã†ç”¨èªã®ã¿ã§å…·ä½“çš„ãªlossã¯è¨˜è¿°ã•ã‚Œã¦ãŠã‚‰ãšï¼ˆå½“æ™‚ã¯RNNè¨€èªãƒ¢ãƒ‡ãƒ«ã§åºƒãå­¦ç¿’æ–¹æ³•ãŒçŸ¥ã‚‰ã‚Œã¦ã„ãŸã‹ã‚‰ã ã‚ã†ã‹ï¼Ÿï¼‰ã€ã‹ã¤ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚‚å­¦ç¿’ã®ã‚³ãƒ¼ãƒ‰ã¯æä¾›ã•ã‚Œã¦ãŠã‚‰ãšã€lossã®å®šç¾©ã‚‚å«ã¾ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br>ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®ãƒ¢ãƒ‡ãƒ«å®šç¾©:<br>


<a href="https://github.com/openai/gpt-2/blob/master/src/model.py#L169" target="_blank" rel="noopener noreferrer">https://github.com/openai/gpt-2/blob/master/src/model.py#L169</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Unsupervised.html" target="_blank" rel="noopener noreferrer">#Unsupervised</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2025-06-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2029" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unsupervised Elicitation of Language Models, Wen+, Anthropic, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiaxinwen22/status/1932908642858418441?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-06-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2020" target="_blank" rel="noopener noreferrer" class="title-link">Qwen_Qwen3-Embedding-4B-GGUF, QwenTeam, 2025.06</a>
<span class="snippet"><span>Comment</span><p>8Bãƒ¢ãƒ‡ãƒ«ã¯MTEBã§ãƒˆãƒƒãƒ—ã®æ€§èƒ½ã‚’é”æˆã€‚context 32Kã€‚100ä»¥ä¸Šã®è¨€èªã‚’ã‚µãƒãƒ¼ãƒˆã€‚32--2560æ¬¡å…ƒã«outputã®æ¬¡å…ƒæ•°ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã‚‹ï¼ˆå¬‰ã—ã„ã€ãŒæ€§èƒ½ã«ã©ã®ç¨‹åº¦å½±éŸ¿ãŒå‡ºã‚‹ã‹ã‚‰æ°—ã«ãªã‚‹ï¼‰ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1930739968332157018?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>QwenTeam post:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1930648422778118246?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-05-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2001" target="_blank" rel="noopener noreferrer" class="title-link">2025å¹´åº¦äººå·¥çŸ¥èƒ½å­¦ä¼šå…¨å›½å¤§ä¼šãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«è¬›æ¼”ã€Œæ·±å±¤åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®æ•°ç†ã€, Taiji Suzuki, 2025.05</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/btreetaiji/status/1927678122817921442?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-05-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1998" target="_blank" rel="noopener noreferrer" class="title-link">SSII2025 [OS1-03] PFNã«ãŠã‘ã‚‹Small Language Modelã®é–‹ç™º, éˆ´æœ¨ è„©å¸, ç”»åƒã‚»ãƒ³ã‚·ãƒ³ã‚°ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ , 2025.05</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_stakaya/status/1927588359217844702?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1827" target="_blank" rel="noopener noreferrer">Training Compute-Optimal Large Language Models, Jordan Hoffmann+, NeurIPS'22</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1828" target="_blank" rel="noopener noreferrer">Scaling Laws for Neural Language Models, Jared Kaplan+, arXiv'20</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1999" target="_blank" rel="noopener noreferrer">Distillation Scaling Laws, Dan Busbridge+, ICML'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need, Suriya Gunasekar+, N/A, arXiv'23</a>
</p>
<p>å…ˆè¡Œç ”ç©¶ã‚’å…ƒã«ä»®èª¬ã‚’ç«‹ã¦ã¦ã€æœ‰æœ›ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å–ã‚‹æ„æ€æ±ºå®šãŒéå¸¸ã«å‹‰å¼·ã«ãªã‚‹ã€‚<br>Scaling LawsãŒä¸ç¢ºå®Ÿæ€§ã®ã‚ã‚‹æ„æ€æ±ºå®šã«ãŠã„ã¦éå¸¸ã«æœ‰ç”¨ãªçŸ¥è¦‹ã¨ãªã£ã¦ã„ã‚‹ã€‚</p>
<p>åŒã˜ã‚ˆã†ã«Pruningã¨Knowledge Distilationã‚’å®Ÿæ–½ã—ãŸäº‹ä¾‹ã¨ã—ã¦ä¸‹è¨˜ãŒæŒ™ã’ã‚‰ã‚Œã‚‹<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1873" target="_blank" rel="noopener noreferrer">Llama-3_1-Nemotron-Ultra-253B-v1, Nvidia, 2025.04</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-05-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1997" target="_blank" rel="noopener noreferrer" class="title-link">Spurious Rewards: Rethinking Training Signals in RLVR, Shao+, 2025.05</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stellalisy/status/1927392717593526780?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å‚è€ƒï¼ˆè€ƒå¯Ÿï¼‰: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/weiliu99/status/1930826904522875309?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å‚è€ƒï¼ˆè€ƒå¯Ÿï¼‰:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/g_k_swamy/status/1945159211752562739?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã“ã¡ã‚‰ã§ã‚‚Qwen2.5 MATH 7b ã‚’ç”¨ã„ã¦æ¤œè¨¼ã—ã¦ã„ã‚‹ãŒã€ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã®å•é¡ŒãŒä»®ã«æœ¬å½“ã ã¨ã—ãŸã‚‰ã€ã©ã†å½±éŸ¿ã™ã‚‹ã ã‚ã†ã‹ã€‚ã‚¹ãƒ¬ãƒƒãƒ‰ä¸­ã®ã‚°ãƒ©ãƒ•ã‚‚MATH500ï¼ˆQwen2.5ã«ãŠã„ã¦ã‚³ãƒ³ã‚¿ãƒŸã®å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰ã®æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1987" target="_blank" rel="noopener noreferrer" class="title-link">ã€DLè¼ªèª­ä¼šã€‘ Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models, Deep Learning JP, 2025.05</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kym384/status/1925852937835737569?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1986" target="_blank" rel="noopener noreferrer">Masked Diffusion Modelã®é€²å±•, Deep Learning JP, 2025.03</a>
 ã§Literatureã‚’ã–ã£ãã‚ŠæŠŠæ¡ã—ã¦ã‹ã‚‰ã“ã¡ã‚‰ã‚’èª­ã‚€ã®ãŒè‰¯ã•ãã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1986" target="_blank" rel="noopener noreferrer" class="title-link">Masked Diffusion Modelã®é€²å±•, Deep Learning JP, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kym384/status/1925852884656099572?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚¹ãƒ©ã‚¤ãƒ‰ä¸­ã®ARã®ã‚ˆã†ã«KV CacheãŒä½¿ãˆãªã„å•é¡Œã«å¯¾å‡¦ã—ãŸç ”ç©¶ãŒ<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1984" target="_blank" rel="noopener noreferrer">dKV-Cache: The Cache for Diffusion Language Models, Xinyin Ma+, arXiv'25</a>
<br><br>ã“ã®è¾ºã¯dLLMãŒæœ‰æœ›ã§ã‚ã‚Œã°ã€ã©ã‚“ã©ã‚“é€²åŒ–ã—ã¦ã„ãã®ã ã‚ã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/AWS.html" target="_blank" rel="noopener noreferrer">#AWS</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-05-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1976" target="_blank" rel="noopener noreferrer" class="title-link">Webã‚¹ã‚±ãƒ¼ãƒ«ã®æ—¥æœ¬èª-ç”»åƒã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒªãƒ¼ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒMOMIJIã€ã®æ§‹ç¯‰ _å·¨å¤§ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’AWSã§é«˜é€Ÿã«å‡¦ç†ã™ã‚‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³, Turing ï¼ˆstudio_graphï¼‰, 2025.05</a>
<span class="snippet"><span>Comment</span><p>è²´é‡ãªVLMãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰ãƒã‚¦ãƒã‚¦</p>
<p>é’å¡—ã‚Šã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã‚’å…·ä½“çš„ã«ã©ã†ã‚„ã£ã¦ã„ã‚‹ã®ã‹æ°—ã«ãªã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2025-05-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1972" target="_blank" rel="noopener noreferrer" class="title-link">OpenAI-Codex, OpenAI, 2025.05</a>
<span class="snippet"><span>Comment</span><p>OpenHandsã®Neubigæ°ãŒã€OpenAIã®ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆä¸­ã§å ±å‘Šã•ã‚Œã¦ã„ã‚‹SWE-Bench Verifiedã®ã‚¹ã‚³ã‚¢ã«ã¤ã„ã¦ã€è¨€åŠã—ã¦ã„ã‚‹ã€‚OpenAIã¯23å€‹ã‚µãƒ³ãƒ—ãƒ«ã«ã¤ã„ã¦(internal infrastructureã§å‹•ä½œã•ã›ã‚‰ã‚Œãªã„ãŸã‚)é™¤å¤–ã—ã¦ã„ã‚‹ã®ã§ã€ãã®åˆ†ã‚¹ã‚³ã‚¢ã«ä¸‹é§„ãŒå±¥ã‹ã‚Œã¦ã„ã‚‹ã‚ˆã†ã§ã€ãƒ–ãƒ­ã‚°ä¸­ã®passNã®ã‚¹ã‚³ã‚¢ã‚’ä»–ã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã®ã‚¹ã‚³ã‚¢ã¨æ¯”è¼ƒã™ã‚‹éš›ã«ã¯æ³¨æ„ãŒå¿…è¦ã£ã½ã„ã€‚<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1923893277519962287?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<span class="issue_date">Issue Date: 2025-05-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1971" target="_blank" rel="noopener noreferrer" class="title-link">AlphaEvolve: A coding agent for scientific and algorithmic discovery, Novikov+, Google DeepMind, 2025.05</a>
<span class="snippet"><span>Comment</span><p>blog post:


<a href="https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/" target="_blank" rel="noopener noreferrer">https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<span class="issue_date">Issue Date: 2025-05-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1969" target="_blank" rel="noopener noreferrer" class="title-link">verl: Volcano Engine Reinforcement Learning for LLMs, ByteDance Seed Team, 2025.04</a>
<span class="snippet"><span>Comment</span><p>SoTAãªRLã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ•°è¡Œã®ã‚³ãƒ¼ãƒ‰ã§å®Ÿè£…å¯èƒ½ã§ã€Sequence ParallelismãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã®ã§é•·ã„ç³»åˆ—ã‚’æ‰±ãˆã‚‹ã€‚FSDP, Megatron-LM,vLLM,SGLangãªã©ã¨ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã§ãã‚‹ã£ã½ã„ï¼Ÿ</p>
<p>æ³¨æ„ç‚¹ï¼ˆè¶…é‡è¦ï¼‰:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fengyao1909/status/1953882575241723911?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>inference backendï¼ˆãƒ–ãƒ­ã‚°ä¸­ã§ã¯vLLM, SGLangãªã©ã‚’ä»®å®šã€‚ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã«åˆ©ç”¨ã™ã‚‹ï¼‰ã¨trainingã®backendï¼ˆãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯, FSDPãªã©ã‚’ä»®å®šã™ã‚‹ï¼‰ã®ãƒŸã‚¹ãƒãƒƒãƒã«ã‚ˆã£ã¦ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿèµ·ç¢ºç‡ã«å·®ãŒç”Ÿã˜ã€ãƒãƒªã‚·ãƒ¼ã®æ›´æ–°ãŒã†ã¾ãã„ã‹ãªããªã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/92ab33c6-d943-4101-9f73-250c697af816" alt="image" loading="lazy"><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2228" target="_blank" rel="noopener noreferrer">è«–æ–‡ã§ã¯èªã‚‰ã‚Œãªã„LLMé–‹ç™ºã«ãŠã„ã¦é‡è¦ãªã“ã¨ Swallow Projectã‚’é€šã—ã¦, Kazuki Fujii, NLPã‚³ãƒ­ã‚­ã‚¦ãƒ , 2025.07</a>
<br><br>ã§ã‚‚è¨€ã‚ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã¯ãƒã‚°ãŒã‚ã‚‹ã®ãŒæ™®é€šãªã®ã­ã€ã€ã€ã€‚</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1953" target="_blank" rel="noopener noreferrer" class="title-link">Stanford Alpaca: An Instruction-following LLaMA Model, Taori +, 2023.03</a>
<span class="snippet"><span>Comment</span><p>ä»Šæ›´ãªãŒã‚‰ãƒ¡ãƒ¢ã«è¿½åŠ ã€‚ã‚¢ã‚«ãƒ‡ãƒŸã‚¢ã«ãŠã‘ã‚‹OpenLLMã«å¯¾ã™ã‚‹Instruction Tuningã®å…ˆé§†ã‘çš„ç ”ç©¶ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-05-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1949" target="_blank" rel="noopener noreferrer" class="title-link">ms-swiftã«ã‚ˆã‚‹Megatron-LMãƒ™ãƒ¼ã‚¹ã®Qwen3ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°, Aratako, 2025.05</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aratako_lm/status/1921401994532487174?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Megatron-SWIFTã¨ã„ã†Alibabaè£½ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’åˆ©ç”¨ã—Qwen3ã®ç¶™ç¶šäº‹å‰å­¦ç¿’ã¨SFTã‚’å®Ÿæ–½ã™ã‚‹æ–¹æ³•ã‚’ã€ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«å‰‡ã£ã¦è¨˜è¿°ã—ã€ã‹ã¤è‘—è€…è‡ªèº«ãŒå­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚‚å…¬é–‹ã—ã¦ã„ã‚‹ã€‚ï¼ˆãŠãã‚‰ãã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä»£ã¯è‡ªè…¹ãªã®ã§ï¼‰ã™ã”ã„...!!<br>Megatron-SWIFTã¯MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Œã°ã€DeepSpeed Zero3 [^1]ã¨æ¯”ã¹ã¦10å€ç¨‹åº¦ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã§å­¦ç¿’ã§ãã‚‹æ¨¡æ§˜ï¼ˆæ—©ã„ï¼‰ã€‚ä¸€æ–¹MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ãªã„ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯ãã“ã¾ã§å¤§ããªå·®ã¯ãªã„ã€‚<br><br>[^1]: A100 80GB 2ãƒãƒ¼ãƒ‰ã§ã¯ã€Qwen3-30B-A3Bã¯ã€DeepSpeed-Zero2ã§ã¯OOMã¨ãªã‚Šè¼‰ã‚‰ãªã„ã‚ˆã†ã â€¦ã€‚ãªã‚“ã¨ãƒªã‚½ãƒ¼ã‚¹ã«å³ã—ã„ã“ã¨â€¦ï¼ˆæ¶™ï¼‰</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1927" target="_blank" rel="noopener noreferrer" class="title-link">Agent Frameworkã¯ã©ã‚Œã‚’ä½¿ã†ã¹ãã‹ [ã‚¿ã‚¹ã‚¯æ€§èƒ½ç·¨], ã¯ã¡, 2025.05</a>
<span class="snippet"><span>Comment</span><p>å„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ¯ã®æ€§èƒ½ã®é•ã„ã‚„æ¶ˆè²»ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°ã€å®Ÿè£…ã®å¾®å¦™ã‚„é•ã„ãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ãŠã‚Šã€å¤ªå­—ã§takeawayãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã®ã§éå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/curveweb/status/1919301208096866660?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-05-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1921" target="_blank" rel="noopener noreferrer" class="title-link">Phi-4-reasoning Technical Report, 2025.04</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dimitrispapail/status/1917731614899028190?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã¡ã‚‰ã®è§£èª¬ãŒéå¸¸ã«ã‚ˆãã¾ã¨ã¾ã£ã¦ã„ã‚‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1918216082231320632?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãŒã€å…ƒãƒã‚¹ãƒˆã§ã‚‚ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼ä¸­ã§ã‚‚o3-miniã®reasoning traceã‚’SFTã«åˆ©ç”¨ã—ã¦CoTã®èƒ½åŠ›ã‚’å¼·åŒ–ã—ãŸæ—¨ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ãŒã€ã“ã‚Œã¯OpenAIã®åˆ©ç”¨è¦ç´„ã«é•åã—ã¦ã„ã‚‹ã®ã§ã¯â€¦ï¼Ÿ</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-04-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1909" target="_blank" rel="noopener noreferrer" class="title-link">Qwen3, Qwen Team, 2025.04</a>
<span class="snippet"><span>Comment</span><p>- 119è¨€èªã‚’ã‚µãƒãƒ¼ãƒˆ<br>- MoEãƒ¢ãƒ‡ãƒ« <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1911" target="_blank" rel="noopener noreferrer">Outrageously Large Neural Networks: The Sparsely-Gated  Mixture-of-Experts Layer, Noam Shazeer+, ICLR'17</a>
<br>    - 30B-A3B / 235B-A22N<br>    - 128K context window<br>    - Qwen2.5ã¯MoEã‚’æ¡ç”¨ã—ã¦ã„ãªã„ã®ã§æ–°ãŸãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ãªã‚‹<br>- Denseãƒ¢ãƒ‡ãƒ«ï¼ˆéMoEãƒ¢ãƒ‡ãƒ«ï¼‰ã‚‚å…¬é–‹<br>    - 0.6B -- 32B<br>    - 32K -- 128K context window<br>- Thinking/Non-thinking ã®åˆ‡ã‚Šæ›¿ãˆãŒåˆ‡ã‚Šæ›¿ãˆãŒå¯èƒ½<br>    - ã‚¹ã‚¤ãƒƒãƒã¯è‡ªå‹•çš„ã«å®Ÿæ–½ã•ã‚Œã‚‹ãŒã€ãƒ¦ãƒ¼ã‚¶ãŒæ˜ç¤ºçš„ã« `/think`, `/no_think` ã‚’ user_promptã®æœ«å°¾ã«è¿½åŠ ã™ã‚‹ã“ã¨ã§åˆ¶å¾¡ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½<br>- Pre-training<br>    - ãƒ‡ãƒ¼ã‚¿<br>        - 36 trillion tokensã«ã‚ˆã£ã¦å­¦ç¿’ï¼ˆQwen-2.5ã®2å€ï¼‰<br>        - å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ã¯webãƒ‡ãƒ¼ã‚¿ã«åŠ ãˆã¦ã€PDF-likeãªæ–‡æ›¸ç¾¤ã‹ã‚‰Qwen2.5-VL <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1835" target="_blank" rel="noopener noreferrer">Qwen2.5-VL-32B-Instruct, Qwen Team, 2025.03</a>
 ã«ã‚ˆã£ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã€Qwen2.5 ã§æŠ½å‡ºã•ã‚ŒãŸå†…å®¹ã®å“è³ªã‚’æ”¹å–„ã—åˆ©ç”¨<br>        - ã¾ãŸã€math / code ã«é–¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ãŸã‚ã«ã€Qwen2.5-Math / Qwen2.5-Coderã‚’ç”¨ã„ã¦åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆtextbooks / QA pairs / code snippets <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need, Suriya Gunasekar+, N/A, arXiv'23</a>
 ï¼‰<br>    - äº‹å‰å­¦ç¿’ã®ã‚¹ãƒ†ãƒƒãƒ—<br>        - S1: contexté•·ãŒ4kã®30 trillion tokenã§äº‹å‰å­¦ç¿’<br>        - S2: STEM / coding / reasoning task ãªã©ã®knowledge-intensiveãƒ‡ãƒ¼ã‚¿ã®æ¯”ç‡ã‚’å¢—ã‚„ã—ã¦ç¶™ç¶šäº‹å‰å­¦ç¿’ (ã“ã‚ŒãŒãŠãã‚‰ã 5 trillion tokenç¨‹åº¦ï¼Ÿ)<br>        - Final Stage: contexté•·ã‚’32kã«æ‹¡å¤§ã—é«˜å“è³ªãªlong-context dataã§ç¶™ç¶šäº‹å‰å­¦ç¿’<br>    - ã“ã‚Œã«ã‚ˆã‚ŠBaseãƒ¢ãƒ‡ãƒ«ãŒå®Œæˆã—ã€Qwen3-235Bå…¨ä½“ã®ã†ã¡10%ç¨‹åº¦ã®Active Parameterã®åˆ©ç”¨ã™ã‚‹ã ã‘ã§ï¼ˆi.e., 22Bã§ï¼‰ã€Qwen2.5-72B Baseã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½é”æˆ<br>- Post-training<br>    - S1: long-CoT cold start<br>        - æ•°å­¦/coding/logical reasoning/STEMãªã©ã®å¤šæ§˜ãªlong CoTãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦SFT <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1749" target="_blank" rel="noopener noreferrer">s1: Simple test-time scaling, Niklas Muennighoff+, arXiv'25</a>
 <br>    - S2: reasoning-based RL<br>        - rule-based (verifiable) rewards ã«ã‚ˆã‚‹RL <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
 <br>        - S1/S2ã®æµã‚Œã¯ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
 ã«æœ‰åŠ¹æ€§ãŒç¤ºã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€long CoT Dataã«ã‚ˆã‚‹SFT -&gt; RLã‚’å®Ÿæ–½<br>    - S3: thinking mode fusion<br>        - S2ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦long CoTãƒ‡ãƒ¼ã‚¿ã¨instruction tuningãƒ‡ãƒ¼ã‚¿ï¼ˆéLong CoTï¼‰ã‚’ç”Ÿæˆã—ã€Thinking/Non-thinkingã‚’è‡ªå‹•çš„ã«é¸æŠã—ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ï¼ˆSFT or RLã¯è¨˜è¿°ãªã—ï¼‰<br>    - S4: general RL<br>        - 20ä»¥ä¸Šã®ä¸€èˆ¬çš„ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã®ã‚¿ã‚¹ã‚¯ã‚’é€šã˜ã¦ä¸€èˆ¬çš„ãªèƒ½åŠ›ã®å‘ä¸Šã¨ã€safetyã«é–¢ã™ã‚‹alignmentã®å®Ÿæ–½ï¼ˆe.g., instruction following, format following, agentèƒ½åŠ›ãªã©ï¼‰</p>
<p>BestPracticeã«é–¢ã™ã‚‹ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ivanfioravanti/status/1916934241281061156?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1917712050983428400?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2025-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1903" target="_blank" rel="noopener noreferrer" class="title-link">Deepwiki, Cognition, 2025.04</a>
<span class="snippet"><span>Comment</span><p>githubãƒªãƒã‚¸ãƒˆãƒªã«é–¢ã™ã‚‹ãƒªãƒƒãƒãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¯¾ã—ã¦Devinã‚’é€šã˜ã¦å¯¾è©±çš„ã«è³ªå•ãŒã§ãã‚‹æ¨¡æ§˜ã€‚ã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—ä¸è¦ã§ã€githubãƒªãƒã‚¸ãƒˆãƒªã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’deepwikiã«å¤‰ãˆã‚‹ã ã‘ã§åˆ©ç”¨å¯èƒ½</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-04-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1896" target="_blank" rel="noopener noreferrer" class="title-link">Introducing UI-TARS-1.5, ByteDance, 2025.04</a>
<span class="snippet"><span>GPT Summary</span>- UI-TARSã¯ã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’å…¥åŠ›ã¨ã—ã¦äººé–“ã®ã‚ˆã†ã«ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡Œã†ãƒã‚¤ãƒ†ã‚£ãƒ–GUIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€å¾“æ¥ã®å•†æ¥­ãƒ¢ãƒ‡ãƒ«ã«ä¾å­˜ã›ãšã€ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚å®Ÿé¨“ã§ã¯ã€10ä»¥ä¸Šã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§SOTAæ€§èƒ½ã‚’é”æˆã—ã€ç‰¹ã«OSWorldã‚„AndroidWorldã§ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã‚¹ã‚³ã‚¢ã‚’è¨˜éŒ²ã—ã¾ã—ãŸã€‚UI-TARSã¯ã€å¼·åŒ–ã•ã‚ŒãŸçŸ¥è¦šã€çµ±ä¸€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã€ã‚·ã‚¹ãƒ†ãƒ -2æ¨è«–ã€åå°„çš„ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒˆãƒ¬ãƒ¼ã‚¹ã«ã‚ˆã‚‹åå¾©ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãªã©ã®é©æ–°ã‚’å–ã‚Šå…¥ã‚Œã€æœ€å°é™ã®äººé–“ã®ä»‹å…¥ã§é©å¿œã—ç¶šã‘ã‚‹èƒ½åŠ›ã‚’æŒã£ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>paper:


<a href="https://arxiv.org/abs/2501.12326" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2501.12326</a>


</p>
<p>è‰²ã€…ã¨æ›¸ã„ã¦ã‚ã‚‹ãŒã€ã–ã£ãã‚Šè¨€ã†ã¨ByteDanceã«ã‚ˆã‚‹ã€Imageã¨Textã‚’inputã¨ã—ã¦å—ã‘å–ã‚Šã€Textã‚’outputã™ã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMã«ã‚ˆã‚‹Computer Use Agent (CUA)</p>
<p>é–¢é€£<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1794" target="_blank" rel="noopener noreferrer">OpenAI API ã§ã® Computer use ã®ä½¿ã„æ–¹, npaka, 2025.03</a>
</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1912913195607663049?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-04-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1886" target="_blank" rel="noopener noreferrer" class="title-link">Seed-Thinking-v1.5, ByteDance, 2025.04</a>
<span class="snippet"><span>Comment</span><p>DeepSeek-R1ã‚’å¤šãã®ãƒ™ãƒ³ãƒã§ä¸Šå›ã‚‹200B, 20B activated paramã®reasoning model</p>
<p>æœ€è¿‘ã®ãƒ†ã‚­ã‚¹ãƒˆã®OpenWeightLLMã¯Alibaba, DeepSeek, ByteDance, Nvidiaã®4å¼·ã¨ã„ã†æ„Ÿã˜ã‹ãªâ€¦ï¼Ÿï¼ˆãã®ã†ã¡OpenAIãŒã‚ªãƒ¼ãƒ—ãƒ³ã«ã™ã‚‹Reasoning Modelã‚‚å…¥ã£ã¦ããã†ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2025-04-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1877" target="_blank" rel="noopener noreferrer" class="title-link">Fiction.liveBench, 2025.04</a>
<span class="snippet"><span>Comment</span><p>long contextã§ã¯Gemini-2.5-proã®åœ§å‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/API.html" target="_blank" rel="noopener noreferrer">#API</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-04-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1875" target="_blank" rel="noopener noreferrer" class="title-link">BFCLv2, UC Berkeley, 2024.08</a>
<span class="snippet"><span>Comment</span><p>LLMã®Tool Useã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ç¾åœ¨ã®ãƒ‡ãƒ•ã‚¡ã‚¯ãƒˆã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã¨ãªã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</p>
<p>BFCLv3:<br>


<a href="https://gorilla.cs.berkeley.edu/blogs/13_bfcl_v3_multi_turn.html" target="_blank" rel="noopener noreferrer">https://gorilla.cs.berkeley.edu/blogs/13_bfcl_v3_multi_turn.html</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Pruning.html" target="_blank" rel="noopener noreferrer">#Pruning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-04-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1873" target="_blank" rel="noopener noreferrer" class="title-link">Llama-3_1-Nemotron-Ultra-253B-v1, Nvidia, 2025.04</a>
<span class="snippet"><span>Comment</span><p>DeepSeek-R1ã‚’GPQA Diamond <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1155" target="_blank" rel="noopener noreferrer">GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark, David Rein+, N/A, COLM'24</a>
, AIME2024/2025, Llama4 Maverickã‚’<br>BFCLv2ï¼ˆTool Calling, <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1875" target="_blank" rel="noopener noreferrer">BFCLv2, UC Berkeley, 2024.08</a>
), IFEVal <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1137" target="_blank" rel="noopener noreferrer">Instruction-Following Evaluation for Large Language Models, Jeffrey Zhou+, N/A, arXiv'23</a>
 ã§ä¸Šå›ã‚Š, ãã®ã»ã‹ã¯ArenaHardã‚’é™¤ãDeepSeekR1ã¨åŒç­‰<br><img src="https://github.com/user-attachments/assets/b0de99ee-f4ec-4b03-8b0b-8939b4f1e23b" alt="image" loading="lazy"><br><br>DeepSeekR1ãŒ671Bï¼ˆMoEã§37B Activation Paramï¼‰ã«å¯¾ã—ã€ã“ã¡ã‚‰ã¯253Bï¼ˆãŸã ã—ã€Llama3.1ãŒãƒ™ãƒ¼ã‚¹ãªã®ã§MoEã§ã¯ãªã„ï¼‰ã§åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã¨ãªã£ã¦ã„ã‚‹ã€‚<br>Reasoningã‚’ON/OFFã™ã‚‹èƒ½åŠ›ã‚‚å‚™ã‚ã£ã¦ã„ã‚‹ã€‚<br><br>ãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ã«è¨“ç·´ã•ã‚ŒãŸã‹ã‚’ç¤ºã™å…¨ä½“å›³ãŒã¨ã¦ã‚‚èˆˆå‘³æ·±ã„:<img src="https://github.com/user-attachments/assets/9a014777-61d8-46ae-818b-ace9ed5c002d" alt="image" loading="lazy"><br><br>ç‰¹ã« <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
 ã§ã‚‚æœ‰åŠ¹æ€§ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€SFTã‚’ã—ã¦ã‹ã‚‰Reasoningã‚’å¼·åŒ–ã™ã‚‹ï¼ˆå¼·åŒ–ã¨ã„ã†ã‚ˆã‚Šå…ƒã€…æŒã£ã¦ã„ã‚‹èƒ½åŠ›ã‚’å¼•ãå‡ºã™ï¼Ÿï¼‰RLã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚<br><br>è©³ç´°ã¯ä¸‹è¨˜Blogã¨ã®ã“ã¨:<br>


<a href="https://developer.nvidia.com/blog/build-enterprise-ai-agents-with-advanced-open-nvidia-llama-nemotron-reasoning-models/" target="_blank" rel="noopener noreferrer">https://developer.nvidia.com/blog/build-enterprise-ai-agents-with-advanced-open-nvidia-llama-nemotron-reasoning-models/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kuchaev/status/1909444566379573646?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-04-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1872" target="_blank" rel="noopener noreferrer" class="title-link">Dream-v0-Instruct-7B, Dream-org, 2025.04</a>
<span class="snippet"><span>Comment</span><p>OpenWeightãªæ‹¡æ•£è¨€èªãƒ¢ãƒ‡ãƒ«</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/curveweb/status/1909551257725133132?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1776" target="_blank" rel="noopener noreferrer">Large Language Diffusion Models, Shen Nie+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-04-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1863" target="_blank" rel="noopener noreferrer" class="title-link">Llama 4 Series, Meta, 2025.04</a>
<span class="snippet"><span>Comment</span><p>Downloads:


<a href="https://www.llama.com/?utm_source=twitter&utm_medium=organic_social&utm_content=image&utm_campaign=llama4" target="_blank" rel="noopener noreferrer">https://www.llama.com/?utm_source=twitter&utm_medium=organic_social&utm_content=image&utm_campaign=llama4</a>


</p>
<p>Huggingface:<br>


<a href="https://huggingface.co/collections/meta-llama/llama-4-67f0c30d9fe03840bc9d0164" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/meta-llama/llama-4-67f0c30d9fe03840bc9d0164</a>


</p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1908601269004230763?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Artificial Analysisã«ã‚ˆã‚‹æ€§èƒ½æ¤œè¨¼:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1908890796415414430?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>MaverickãŒGPT4oã¨åŒç­‰ã€ScoutãŒGPT4o-miniã¨åŒç­‰<br><br>Update:



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1909624239747182989?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ€§èƒ½ã«é–¢ã—ã¦ä¸å¯è§£ãªç‚¹ãŒå¤šãã†ãªã®ã§æ§˜å­è¦‹ã‚’ã—ã¦ã‚‚è‰¯ã„ã‹ã‚‚ã€‚</p>
<p>æ€§èƒ½æ¤œè¨¼ï¼ˆMath-Perturb):



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kaixuanhuang1/status/1909387970773234088?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¥æœ¬èªã«ã‚ã¾ã‚Šå¼·ããªã„ã¨ã„ã†æƒ…å ±ã‚‚<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gosrum/status/1909626761098494060?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã©ã†ã‚„ã‚‰vLLMã®Llama4ã®inferenceã«ãƒã‚°ãŒã‚ã£ãŸã‚„ã†ã§ã€vLLMã®Issue 16311ã«ã¦ã€Llama4ã®inferenceã«é–¢ã™ã‚‹ãƒã‚°ãŒä¿®æ­£ã•ã‚Œã€æ€§èƒ½ãŒå‘ä¸Šã—ãŸæ¨¡æ§˜ã€‚ã©ã®ãƒ™ãƒ³ãƒã‚’ä¿¡ã˜ãŸã‚‰è‰¯ã„ã‹ã¾ã‚‹ã§ã‚ã‹ã‚‰ã‚“ã€‚</p>
<p>2025.0413ç¾åœ¨ã®chatbot arenaã®ãƒ©ãƒ³ã‚¯ã¯ã€32ä½ã¨ãªã‚Šï¼ˆchatbot arenaå‘ã‘ã«tuningã•ã‚Œã¦ã„ãŸã§ã‚ã‚ã†ãƒ¢ãƒ‡ãƒ«ã¯2ä½ã ã£ãŸï¼‰GPT-4oãŒ29ä½ã§ã‚ã‚‹ã“ã¨ã‚’è€ƒæ…®ã™ã‚‹ã¨ä¸Šè¨˜ã®Artificial Intelligenceã®è©•ä¾¡ã¨ã‚‚å¤§ä½“ä¸€è‡´ã—ã¦ã„ã‚‹ã€‚<br><br>


<a href="https://lmarena.ai" target="_blank" rel="noopener noreferrer">https://lmarena.ai</a>


<br><br>é–¢é€£ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tunguz/status/1911142310160855541?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1850" target="_blank" rel="noopener noreferrer" class="title-link">openhands-lm-32b-v0.1, all-hands, 2025.03</a>
<span class="snippet"><span>Comment</span><p>Qwen Coder 2.5 Instruct 32Bã«åŸºã¥ãæœ€å…ˆç«¯ã®SWEã‚¿ã‚¹ã‚¯ãŒå®Ÿè¡Œå¯èƒ½ãªãƒ¢ãƒ‡ãƒ«</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-03-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1844" target="_blank" rel="noopener noreferrer" class="title-link">Recommendation Systems â€¢ LLM, vinjia.ai, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/vinija_recommendation-systems-llm-activity-7306171374446727168-cUg2?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/vinija_recommendation-systems-llm-activity-7306171374446727168-cUg2?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1835" target="_blank" rel="noopener noreferrer" class="title-link">Qwen2.5-VL-32B-Instruct, Qwen Team, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1904227859616641534?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-03-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer" class="title-link">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å¿…èª­</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-03-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1830" target="_blank" rel="noopener noreferrer" class="title-link">Nemotron-H: A Family of Accurate, Efficient Hybrid Mamba-Transformer Models, Nvidia, 2025.03</a>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1820" target="_blank" rel="noopener noreferrer">Hunyuan T1, Tencent, 2025.03</a>
</p>
<p>Transformerã®Self-attention Layerã‚’Mamba2 Layerã«ç½®æ›ã™ã‚‹ã“ã¨ã§ã€æ§˜ã€…ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§åŒç­‰ã®æ€§èƒ½ã€ã‚ã‚‹ã„ã¯ä¸Šå›ã‚‹æ€§èƒ½ã§3å€ç¨‹åº¦ã®Inference timeã®é«˜é€ŸåŒ–ã‚’ã—ã¦ã„ã‚‹ï¼ˆ65536 input, 1024 outputï¼‰ã€‚<br><br>56Bç¨‹åº¦ã®mediumã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã¨ã€8Bç¨‹åº¦ã®è»½é‡ãªãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦è¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ç‰¹ã«ã€8Bãƒ¢ãƒ‡ãƒ«ã§Mambaã¨Transformerã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã¨ã€é€šå¸¸ã®Transformerãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒã—ã¦ã„ã‚‹ã€‚å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«15 Trillion Tokenã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã€ã“ã®ãƒ‡ãƒ¼ã‚¿é‡ã§ã®Apple to Appleã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é–“ã®æ¯”è¼ƒã¯ã€ç¾çŠ¶ã§ã¯æœ€ã‚‚å¤§è¦æ¨¡ãªã‚‚ã®ã¨ã®ã“ã¨ã€‚æ€§èƒ½ã¯å¤šãã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã«ã—ã¦ã‚‚åŒç­‰ã€Commonsense Understandingã§ã¯ä¸Šå›ã£ã¦ã„ã‚‹ã€‚<br><br>ã¾ãŸã€å­¦ç¿’ã—ãŸNemotron-Hã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦æŒã¤VLMã«ã¤ã„ã¦ã‚‚ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒè¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1823" target="_blank" rel="noopener noreferrer" class="title-link">8 Types of RoPE, Kseniase, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://huggingface.co/posts/Kseniase/498106595218801" target="_blank" rel="noopener noreferrer">https://huggingface.co/posts/Kseniase/498106595218801</a>


</p>
<p>RoPEã«ã¤ã„ã¦ã‚µãƒ¼ãƒ™ã‚¤ãŒå¿…è¦ã«ãªã£ãŸã‚‰è¦‹ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1822" target="_blank" rel="noopener noreferrer" class="title-link">The "think" tool: Enabling Claude to stop and think in complex tool use situations, Anthropic, 2025.03</a>
<span class="snippet"><span>Comment</span><p>"è€ƒãˆã‚‹"ã“ã¨ã‚’ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦å®šç¾©ã—åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€externalãªthinkingã‚’æ˜ç¤ºçš„ã«å®Ÿæ–½ã—ãŸä¸Šã§ã‚¿ã‚¹ã‚¯ã‚’é‚è¡Œã•ã›ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-03-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1821" target="_blank" rel="noopener noreferrer" class="title-link">Understanding R1-Zero-Like Training: A Critical Perspective, 2025.03</a>
<span class="snippet"><span>GPT Summary</span>- DeepSeek-R1-Zeroã¯ã€æ•™å¸«ãªã—ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã§LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã®åŠ¹æœã‚’ç¤ºã—ãŸã€‚ç ”ç©¶ã§ã¯ã€ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨RLã®ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’åˆ†æã—ã€DeepSeek-V3-BaseãŒã€Œã‚¢ãƒä½“é¨“ã€ã‚’ç¤ºã™ã“ã¨ã‚„ã€Qwen2.5ãŒå¼·åŠ›ãªæ¨è«–èƒ½åŠ›ã‚’æŒã¤ã“ã¨ã‚’ç™ºè¦‹ã€‚ã•ã‚‰ã«ã€Group Relative Policy Optimizationï¼ˆGRPOï¼‰ã®æœ€é©åŒ–ãƒã‚¤ã‚¢ã‚¹ã‚’ç‰¹å®šã—ã€Dr. GRPOã¨ã„ã†æ–°æ‰‹æ³•ã‚’å°å…¥ã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³åŠ¹ç‡ã‚’æ”¹å–„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€7Bãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã§AIME 2024ã«ãŠã„ã¦43.3%ã®ç²¾åº¦ã‚’é”æˆã—ã€æ–°ãŸãªæœ€å…ˆç«¯ã‚’ç¢ºç«‹ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£ç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1815" target="_blank" rel="noopener noreferrer">DAPO: An Open-Source LLM Reinforcement Learning System at Scale, Qiying Yu+, arXiv'25</a>
</p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1903464313391624668?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆï¼ˆã¨è«–æ–‡ä¸­ã®å½“è©²éƒ¨åˆ†ï¼‰ã‚’èª­ã‚€ã¨ã€<br><br>- ã‚ªãƒªã‚¸ãƒŠãƒ«ã®GRPOã®å®šå¼ã§ã¯2ã¤ã®ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ã‚‹:<br>  - response-level length bias: 1/|o_i| ã§Advantageã‚’é™¤ç®—ã—ã¦ã„ã‚‹ãŒã€ã“ã‚Œã¯AdvantageãŒè² ã®å ´åˆï¼ˆã¤ã¾ã‚Šã€èª¤ç­”ãŒå¤šã„å ´åˆï¼‰ã€Œé•·ã„å¿œç­”ã€ã®ãƒšãƒŠãƒ«ãƒ†ã‚£ãŒå°ã•ããªã‚‹ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ãŒã€Œé•·ã„å¿œç­”ã€ã‚’å¥½ã‚€ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ã‚‹ã€‚ä¸€æ–¹ã§ã€AdvantageãŒæ­£ã®å ´åˆï¼ˆæ­£ç­”ï¼‰ã¯ã€ŒçŸ­ã„å¿œç­”ã€ãŒå¥½ã¾ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚<br>  - question-level difficulty bias: ã‚°ãƒ«ãƒ¼ãƒ—å†…ã®å…¨ã¦ã®å¿œç­”ã«å¯¾ã™ã‚‹Rewardã®stdã§Advantageã‚’é™¤ç®—ã—ã¦ã„ã‚‹ãŒã€stdãŒå°ã•ããªã‚‹å•é¡Œï¼ˆã™ãªã‚ã¡ã€ç°¡å˜ã™ãã‚‹oré›£ã—ã™ãã‚‹å•é¡Œï¼‰ã‚’ã‚ˆã‚Šé‡è¦–ã™ã‚‹ã‚ˆã†ãªã€å•é¡Œã«å¯¾ã™ã‚‹é‡ã¿ã¥ã‘ã«ã‚ˆã‚‹ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ã‚‹ã€‚<br>- aha momentï¼ˆself-seflectionï¼‰ã¯RLã«ã‚ˆã£ã¦åˆã‚ã¦ç²å¾—ã•ã‚ŒãŸã‚‚ã®ã§ã¯ãªãã€ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ™‚ç‚¹ã§ç²å¾—ã•ã‚Œã¦ãŠã‚Šã€RLã¯ãã®æŒ™å‹•ã‚’å¢—é•·ã—ã¦ã„ã‚‹ã ã‘ï¼ˆã“ã‚Œã¯Xä¸Šã§ã™ã§ã«ã©ã“ã‹ã§è¨€åŠã•ã‚Œã¦ã„ãŸãªãï¼‰ã€‚<br>- ã“ã‚Œã¾ã§ã¯output lengthã‚’å¢—ã‚„ã™ã“ã¨ãŒæ€§èƒ½æ”¹å–„ã®éµã ã¨æ€ã‚ã‚Œã¦ã„ãŸãŒã€ã“ã®è«–æ–‡ã§ã¯å¿…ãšã—ã‚‚ãã†ã§ã¯ãªãã€self-reflectionç„¡ã—ã®æ–¹ãŒæœ‰ã‚Šã®å ´åˆã‚ˆã‚Šã‚‚Acc.ãŒé«˜ã„å ´åˆãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ï¼ˆã§ã‚‚ã±ã£ã¨è¦‹ã‚°ãƒ©ãƒ•ã‚’è¦‹ã‚‹ã¨å³è‚©ä¸ŠãŒã‚Šã®å‚¾å‘ã§ã¯ã‚ã‚‹ï¼‰<br><br>ã¨ã„ã£ãŸçŸ¥è¦‹ãŒã‚ã‚‹æ¨¡æ§˜</p>
<p>ã‚ã¨ã§èª­ã‚€</p>
<p>ï¼ˆå‚è€ƒï¼‰Dr.GRPOã‚’å®Ÿéš›ã«Big-Mathã¨Qwen-2.5-7Bã«é©ç”¨ã—ãŸã‚‰å®‰å®šã—ã¦åæŸã—ãŸã‚ˆã¨ã„ã†ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zzlccc/status/1910902637152940414?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<span class="issue_date">Issue Date: 2025-03-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1820" target="_blank" rel="noopener noreferrer" class="title-link">Hunyuan T1, Tencent, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/txhunyuan/status/1903121005809373386?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç”»åƒã¯ãƒ–ãƒ­ã‚°ã‚ˆã‚Šå¼•ç”¨ã€‚DeepSeek-R1ã¨æ¯”è¼ƒã™ã‚‹ã¨å„ªã£ã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ã¨åŠ£ã£ã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ãŒã‚ã‚Šã€ãªã‚“ã¨ã‚‚è¨€ãˆãªã„æ„Ÿã€‚GPT4.5ã‚ˆã‚Šå¤§å¹…ã«ä¸Šå›ã£ã¦ã„ã‚‹ã‚¿ã‚¹ã‚¯ï¼ˆMath, Reasoningï¼‰ãŒã‚ã‚‹ãŒã€ãã‚‚ãã‚‚ãã†ã„ã£ãŸã‚¿ã‚¹ã‚¯ã¯o1ãªã©ã®reasoningãƒ¢ãƒ‡ãƒ«ã®é ˜åŸŸã€‚o1ã¨æ¯”è¼ƒã™ã‚‹ã¨ã“ã‚Œã‚‚ã¾ã‚å„ªã£ã¦ã„ã‚‹éƒ¨åˆ†ã‚‚ã‚ã‚Œã°åŠ£ã£ã¦ã„ã‚‹éƒ¨åˆ†ã‚‚ã‚ã‚‹ã¨ã„ã†æ„Ÿã˜ã€‚å”¯ä¸€ã€ToolUseã«é–¢ã—ã¦ã¯ä¸€è²«ã—ã¦OpenAIãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒå¼·ã„ã€‚<br><br>Chineseã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦ã¯DeepSeek-R1ã¨å®Œå…¨ã«ã‚¹ã‚³ã‚¢ãŒä¸€è‡´ã—ã¦ã„ã‚‹ãŒã€è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„ã®ã ã‚ã†ã‹ï¼Ÿ<br><img src="https://github.com/user-attachments/assets/de2325b2-0bd5-4177-a336-e6f008a32d40" alt="image" loading="lazy"></p>
<p>reasoningãƒ¢ãƒ‡ãƒ«ã‹ã¤ã€Transformerã¨Mambaã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã§ã€MoEã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚</p>
<p>Transformerã¨Mambaã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã«ã¤ã„ã¦ï¼ˆWenhuChenæ°ã®ãƒã‚¹ãƒˆï¼‰:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1903656455036715311?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Layer-wise Mixingã¨Sequence-wise Mixingã®2ç¨®é¡ãŒå­˜åœ¨ã™ã‚‹ã¨ã®ã“ã¨ã€‚å‰è€…ã¯Transformerã®Self-Attenton Layerã‚’Mamba Layerã«ç½®æ›ã—ãŸã‚‚ã®ã§ã€å¾Œè€…ã¯Sequenceã®Long partã‚’Mambaã§ã¾ãšã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€Short Partã‚’Transformerã§ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹éš›ã®Cross-Attentionã®encoder stateã¨ã—ã¦ä¸ãˆã‚‹æ–¹æ³•ã¨ã®ã“ã¨ã€‚<p>Self-Attention Layerã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ã§Inferenceæ™‚ã®è¨ˆç®—é‡ã¨ãƒ¡ãƒ¢ãƒªã‚’å¤§å¹…ã«å‰Šæ¸›ã§ãã‚‹ï¼ˆSelf-Attentionã¯å…¨ä½“ã®KV Cacheã«å¯¾ã—ã¦Attentionã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1818" target="_blank" rel="noopener noreferrer" class="title-link">Sudoku-bench, SakanaAI, 2025.03</a>
<span class="snippet"><span>GPT Summary</span>- Sudoku-Benchã¯ã€CTCã§ç´¹ä»‹ã•ã‚ŒãŸç‹¬è‡ªã®ãƒ«ãƒ¼ãƒ«ã‚’æŒã¤æ•°ç‹¬ãƒ‘ã‚ºãƒ«ã‚’ç‰¹å¾´ã¨ã—ã€AIæ¨è«–ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã«æœ€é©ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã™ã€‚ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã§ã¯ã€æ•°ç‹¬ãƒ™ãƒ³ãƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€LLMè©•ä¾¡ç”¨ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰ã€SudokuPadãƒ„ãƒ¼ãƒ«ã€æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ãªã©ã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sakanaailabs/status/1902913196358611278?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å–ã£ãŸã‚‰ã©ã†ã„ã†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«ãªã‚‹ã®ã ã‚ã†ã‹ã€‚ç‰¹ã«ã¾ã ãã†ã„ã…ãŸãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯å…¬é–‹ã•ã‚Œã¦ã„ãªã„æ¨¡æ§˜ã€‚</p>
<p>ãƒ–ãƒ­ã‚°è¨˜äº‹ã«ï¼ˆå°†æ¥çš„ã«æœ€æ–°ã®çµæœã‚’repositoryã«è¿½è¨˜ã™ï¼Ÿæ¨¡æ§˜ï¼‰ç¾æ™‚ç‚¹ã§ã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ãŒè¼‰ã£ã¦ã„ãŸã€‚ç¾çŠ¶ã€o3-miniãŒãƒ€ãƒ³ãƒˆãƒ„ã«è¦‹ãˆã‚‹ã€‚<br>


<a href="https://sakana.ai/sudoku-bench/" target="_blank" rel="noopener noreferrer">https://sakana.ai/sudoku-bench/</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1814" target="_blank" rel="noopener noreferrer" class="title-link">Llama Nemotron, Nvidia, 2025.03</a>
<span class="snippet"><span>Comment</span><p>Nvidiaã«ã‚ˆã‚‹åˆã‚ã¦ã®reasoning modelã€‚<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kuchaev/status/1902078122792775771?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Artificial Analysisã«ã‚„ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1902386178206429434?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>GPQA Diamondï¼ˆå¤§å­¦é™¢ï¼ˆPh.Dï¼‰ãƒ¬ãƒ™ãƒ«ã®ç”Ÿç‰©å­¦ã€ç‰©ç†å­¦ã€åŒ–å­¦ã®450å•ç¨‹åº¦ã®é›£è§£ãªmultiple choice questionï¼‰ã§ã€DeepSeekV3, GPT4o, QwQ-32Bã‚’outperform. Claude 3.7 sonnetã‚ˆã‚Šå°‘ã—ã‚¹ã‚³ã‚¢ãŒä½ã„ã€‚<br>DeepSeekR1, o1, o3-miniï¼ˆhighï¼‰, Claude 3.7 sonnet Thinkingãªã©ã«ã¯åŠã‚“ã§ã„ãªã„ã€‚<br><br><img src="https://github.com/user-attachments/assets/2d2b3716-83a6-4c56-bca7-f7d8cf981bbb" alt="image" loading="lazy"><br><br>ï¼ˆç”»åƒã¯å…ƒãƒã‚¹ãƒˆã‚ˆã‚Šå¼•ç”¨ï¼‰<p>ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¤‰ãˆã‚‹ã“ã¨ã§reasoningã‚’on/offã§ãã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1810" target="_blank" rel="noopener noreferrer" class="title-link">EXAONE-Deep-32B, LG AI Research, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ai_for_success/status/1901908168805912602?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>EXAONE AI Model License Agreement 1.1 - NC<br>å•†ç”¨åˆ©ç”¨ä¸å¯</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1809" target="_blank" rel="noopener noreferrer" class="title-link">SmolDocling-256M, IBM Research, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/andimarafioti_we-just-dropped-%F0%9D%97%A6%F0%9D%97%BA%F0%9D%97%BC%F0%9D%97%B9%F0%9D%97%97%F0%9D%97%BC%F0%9D%97%B0%F0%9D%97%B9%F0%9D%97%B6%F0%9D%97%BB%F0%9D%97%B4-activity-7307415358427013121-wS8m?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/andimarafioti_we-just-dropped-%F0%9D%97%A6%F0%9D%97%BA%F0%9D%97%BC%F0%9D%97%B9%F0%9D%97%97%F0%9D%97%BC%F0%9D%97%B0%F0%9D%97%B9%F0%9D%97%B6%F0%9D%97%BB%F0%9D%97%B4-activity-7307415358427013121-wS8m?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4</a>


</p>
<p>Apache-2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã€‚è¨€èªã¯Englishã®ã¿ãªæ¨¡æ§˜</p>
<p>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªImage-To-Textãƒ¢ãƒ‡ãƒ«ã€‚ã‚µãƒ³ãƒ—ãƒ«ã¯ã“ã¡ã‚‰<br><img src="https://github.com/user-attachments/assets/d16ce5a9-4336-4daa-ab6f-94d67ae77c41" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-03-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1808" target="_blank" rel="noopener noreferrer" class="title-link">ERNIE4.5_X1, Baidu, 2025.03</a>
<span class="snippet"><span>Comment</span><p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ai_for_success/status/1901149459826045223?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- ERNIE4.5ã¯GPT4.5ã‚’ã•ã¾ã–ã¾ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ä¸Šå›ã‚Šã€ä¾¡æ ¼ãŒãªã‚“ã¨GPT4.5ã®1%<br>- X1ã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªreasoningãƒ¢ãƒ‡ãƒ«ã§DeepSeek-R1ã¨åŒç­‰ã®æ€§èƒ½ã§åŠé¡<br><br>ã‚‰ã—ã„</p>
<p>ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯6æœˆ30æ—¥ã«ã‚ªãƒ¼ãƒ—ãƒ³ï¼ˆã‚¦ã‚§ã‚¤ãƒˆï¼Ÿï¼‰ã«ãªã‚‹ã¨ã‚¹ãƒ¬ãƒƒãƒ‰ã§è¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-03-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1807" target="_blank" rel="noopener noreferrer" class="title-link">sarashina2-vision-{8b, 14b}, SB Intuitions, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sei_shinagawa/status/1901467733331701966?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>VLMã€‚Xã«æ•£è¦‹ã•ã‚Œã‚‹è©¦è¡Œä¾‹ã‚’è¦‹ã‚‹ã¨æ—¥æœ¬èªã®èª­ã¿å–ã‚Šæ€§èƒ½ã¯çµæ§‹é«˜ãã†ã«è¦‹ãˆã‚‹ã€‚</p>
<p>ãƒ¢ãƒ‡ãƒ«æ§‹æˆã€å­¦ç¿’ã®è©³ç´°ã€ãŠã‚ˆã³è©•ä¾¡:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sbintuitions/status/1901472307421278604?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLMï¼ˆsarashina2ï¼‰, Vision Encoderï¼ˆQwen2-VLï¼‰, Projectorã®3ã¤ã§æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€3æ®µéšã®å­¦ç¿’ã‚’è¸ã‚“ã§ã„ã‚‹ã€‚<br>æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦Projectorã®ã¿ã‚’å­¦ç¿’ã—Vision Encoderã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’å¯¾å¿œã¥ã‘ã‚‹ã€‚ç¶šã„ã¦ã€æ—¥æœ¬èªã‚’å«ã‚€ç”»åƒã‚„æ—¥æœ¬ç‰¹æœ‰ã®é¢¨æ™¯ãªã©ã‚’ã†ã¾ãæ‰±ãˆã‚‹ã‚ˆã†ã«ã€ã“ã‚Œã‚‰ã‚’å¤šãæ´»ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ï¼ˆå†…è£½æ—¥æœ¬èªOCRãƒ‡ãƒ¼ã‚¿ã€å›³è¡¨ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’ç”¨ã„ã¦ã€Vision Encoderã¨Projectorã‚’å­¦ç¿’ã€‚æœ€å¾Œã«LLMã®Alignmentã‚’ã¨ã‚‹ãŸã‚ã«ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ã‚¿ãƒ¼ã¨LLMã‚’å‰æ®µã®ãƒ‡ãƒ¼ã‚¿ã«åŠ ãˆã¦VQAãƒ‡ãƒ¼ã‚¿ï¼ˆå†…è£½åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ï¼‰ã‚„æ—¥æœ¬èªã®æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦å­¦ç¿’ã€‚</p>
<p>Projectorã‚„MMLLMã‚’å…·ä½“çš„ã«ã©ã®ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ã‹ã¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1225" target="_blank" rel="noopener noreferrer">MM-LLMs: Recent Advances in MultiModal Large Language Models, Duzhen Zhang+, N/A, ACL'24 Findings</a>
<br><br>ã‚’å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-03-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1805" target="_blank" rel="noopener noreferrer" class="title-link">The TypeScript Agent Framework, mastra, 2025.03</a>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://zenn.dev/yosh1/articles/mastra-ai-agent-framework-guide" target="_blank" rel="noopener noreferrer">https://zenn.dev/yosh1/articles/mastra-ai-agent-framework-guide</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-03-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1803" target="_blank" rel="noopener noreferrer" class="title-link">LLM é–‹ç™ºã‚’æ”¯ãˆã‚‹å¤šæ§˜ãª Fine-Tuningï¼šPFN ã§ã®å–ã‚Šçµ„ã¿, ä¸­é‰¢é­ä¸‰éƒ, PFN, 2025.03</a>
<span class="snippet"><span>Comment</span><p>çŸ¥è­˜ã®è¿½åŠ ã®éƒ¨åˆ†ã§ä¸‹è¨˜ç ”ç©¶ãŒå¼•ç”¨ã•ã‚Œã¦ã„ã‚‹<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1371" target="_blank" rel="noopener noreferrer">Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?, Zorik Gekhman+, N/A, EMNLP'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1640" target="_blank" rel="noopener noreferrer">LoRA Learns Less and Forgets Less, Dan Biderman+, TMLR'24</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2025-03-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1797" target="_blank" rel="noopener noreferrer" class="title-link">OLMo 2 32B: First fully open model to outperform GPT 3.5 and GPT 4o mini, AllenAI, 20250.3</a>
<span class="snippet"><span>Comment</span><p>çœŸãªã‚‹å®Œå…¨ãªã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ï¼ˆã«è¿‘ã„ï¼Ÿï¼‰OLMOã®æœ€æ–°ä½œ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<span class="issue_date">Issue Date: 2025-03-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1794" target="_blank" rel="noopener noreferrer" class="title-link">OpenAI API ã§ã® Computer use ã®ä½¿ã„æ–¹, npaka, 2025.03</a>
<span class="snippet"><span>Comment</span><p>OpenAIã®Compute UseãŒã©ã®ã‚ˆã†ãªã‚‚ã®ã‹ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«ã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚å‹‰å¼·ã«ãªã‚Šã¾ã—ãŸã€‚</p>
<p>å…¬å¼:


<a href="https://platform.openai.com/docs/guides/tools-computer-use" target="_blank" rel="noopener noreferrer">https://platform.openai.com/docs/guides/tools-computer-use</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<span class="issue_date">Issue Date: 2025-03-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1792" target="_blank" rel="noopener noreferrer" class="title-link">Open-source DeepResearch â€“ Freeing our search agents, HuggingFace, 2025.02</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1791" target="_blank" rel="noopener noreferrer" class="title-link">Introducing Gemma 3: The most capable model you can run on a single GPU or TPU, Google, 2025.03</a>
<span class="snippet"><span>Comment</span><p>Googleã®æ–°ãŸãªSLMã§ã€ãƒ‡ãƒã‚¤ã‚¹ã‚„ãƒ©ãƒƒãƒ—ãƒˆãƒƒãƒ—ã§ã‚‚å‹•ä½œå¯èƒ½ãªè»½é‡ãƒ¢ãƒ‡ãƒ«ã€‚ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã§ãªãç”»åƒã¨ShortVideoã®èªè­˜ã‚‚ã§ãã¦ã€140è¨€èªã‚’ã‚µãƒãƒ¼ãƒˆã€‚ãŠã¾ã‘ã«27Bãƒ¢ãƒ‡ãƒ«ã§Llama3-405Bã¨DeepSeek-V3ã¨o3-miniã‚’ChatbotArenaã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã§ä¸Šå›ã‚Šã€128kã®context windowã€‚ãˆã‡â€¦ã€‚</p>
<p>ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°:


<a href="https://huggingface.co/blog/gemma3" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/gemma3</a>


<br><br>1Bãƒ¢ãƒ‡ãƒ«ã¯è‹±èªã®ã¿ã‚µãƒãƒ¼ãƒˆã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ä¸å¯ãªã©åˆ¶ç´„ãŒã‚ã‚‹æ¨¡æ§˜ã€‚<br>è©³ç´°ã¾ã§ã¯æ›¸ã„ã¦ã„ãªã„ãŒã€128Kã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¾ã§context windowã‚’åºƒã’ã‚‹éš›ã®æ¦‚è¦ã¨RoPEï¼ˆã®ã‚ˆã†ãªï¼‰Positional Embeddingã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã€SlideingWindow Attentionã‚’ç”¨ã„ã¦ãŠã‚Šã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºãŒä»¥å‰ã®4096ã‹ã‚‰æ€§èƒ½ã‚’ç¶­æŒã—ãŸã¾ã¾1024ã«å°ã•ãã§ããŸã“ã¨ã€ImageEncoderã¨ã—ã¦ä½•ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã‹ï¼ˆSigLIPï¼‰ã€896x896ã®ç”»åƒã‚µã‚¤ã‚ºã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€æ­£æ–¹å½¢ã®ç”»åƒã¯ã“ã®ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚ºã•ã‚Œã€æ­£æ–¹å½¢ã§ãªã„å ´åˆã¯cropã•ã‚ŒãŸä¸Šã§ãƒªã‚µã‚¤ã‚ºã•ã‚Œã‚‹ï¼ˆpan and scanã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨å‘¼ã¶ã‚‰ã—ã„ï¼‰ã“ã¨ã€äº‹å‰å­¦ç¿’æ™‚ã®ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’2å€ã«ã—ãŸã“ã¨ãªã©ã€è‰²ã€…æ›¸ã„ã¦ã‚ã‚‹æ¨¡æ§˜ã€‚</p>
<p>Gemmaãƒ©ã‚¤ã‚»ãƒ³ã‚¹</p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1899965039559532585?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1900214135847039316?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1790" target="_blank" rel="noopener noreferrer" class="title-link">Reasoning with Reka Flash, Reka, 2025.03</a>
<span class="snippet"><span>Comment</span><p>Weights: 


<a href="https://huggingface.co/RekaAI/reka-flash-3" target="_blank" rel="noopener noreferrer">https://huggingface.co/RekaAI/reka-flash-3</a>


</p>
<p>Apache-2.0</p>
<p>&lt; /reasoning &gt;ã‚’å¼·åˆ¶çš„ã«outputã•ã›ã‚‹ã“ã¨ã§reasoningã‚’ä¸­æ–­ã•ã›ã‚‹ã“ã¨ãŒã§ãäºˆç®—ã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãŒå¯èƒ½ã¨ã®ã“ã¨</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2025-03-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1788" target="_blank" rel="noopener noreferrer" class="title-link">The State of LLM Reasoning Models, Sebastian Raschka, 2025.03</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1786" target="_blank" rel="noopener noreferrer" class="title-link">QwQ-32B: Embracing the Power of Reinforcement Learning, Qwen Team, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1897426898642460724?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1787" target="_blank" rel="noopener noreferrer">START: Self-taught Reasoner with Tools, Chengpeng Li+, arXiv'25</a>
</p>
<p>Artificial Analysisã«ã‚ˆã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1897701015803380112?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãŠãã‚‰ãç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã§DeepSeekR1ã¨comparable, ä»–ã‚¿ã‚¹ã‚¯ã§ã¯åŠã°ãªã„ã€ã¨ã„ã†æ„Ÿã˜ã«ãªã‚Šãã†ãªäºˆæ„Ÿ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-03-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1783" target="_blank" rel="noopener noreferrer" class="title-link">GRPO Judge Experiments: Findings &amp; Empirical Observations, kalomaze's kalomazing blog, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_forget-basic-math-problems-grpo-can-do-more-activity-7302608410875691009-nntf?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_forget-basic-math-problems-grpo-can-do-more-activity-7302608410875691009-nntf?utm_source=share&utm_medium=member_ios&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4</a>


</p>
<p>ä¸€æ„ã«è§£ãŒæ±ºã¾ã‚‹å•é¡Œã§ã¯ãªãã€ã‚ã‚‹ç¨‹åº¦ã®ä¸»è¦³çš„ãªåˆ¤æ–­ãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦ã®GRPOã®åˆ†æã€‚<br>2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¯”è¼ƒã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã€ä¸€æ–¹ã®ã‚¿ã‚¹ã‚¯ã¯LLMã«ã‚ˆã£ã¦æ‘‚å‹•ã‚’ä¸ãˆã¦ã„ã‚‹ï¼ˆãŠãã‚‰ãæ„å›³çš„ã«corruptã•ã›ã¦ã„ã‚‹ï¼‰ã€‚<br><br>GRPOã§ã¯linearã‚„cosineã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã¯ã†ã¾ãæ©Ÿèƒ½ã›ãšã€warmupãƒ•ã‚§ãƒ¼ã‚ºæœ‰ã‚Šã®å°ã•ã‚ã®å®šæ•°ãŒæœ‰åŠ¹ã‚‰ã—ã„ã€‚ã¾ãŸã€max_grad_normã‚’0.2ã«ã—ã¾gradient clippingãŒæœ‰åŠ¹ã¨ã®ã“ã¨ã€‚</p>
<p>ä»–ã«ã‚‚rewardã®ä¸ãˆæ–¹ã‚’x^4ã«ã™ã‚‹ã“ã¨ã‚„ã€length, xmlãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å ´åˆã«ãƒœãƒ¼ãƒŠã‚¹ã®rewardã‚’ä¸ãˆã‚‹ãªã©ã®å·¥å¤«ã‚’è€ƒå¯Ÿã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-03-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1781" target="_blank" rel="noopener noreferrer" class="title-link">microsoft_Phi-4-multimodal-instruct, Microsoft, 2025.02</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/vaibhavs10_holy-shitt-microsoft-dropped-an-open-source-activity-7300755229635944449-mQP8?utm_medium=ios_app&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4&utm_source=social_share_send&utm_campaign=copy_link" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/vaibhavs10_holy-shitt-microsoft-dropped-an-open-source-activity-7300755229635944449-mQP8?utm_medium=ios_app&rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4&utm_source=social_share_send&utm_campaign=copy_link</a>


</p>
<p>MIT License</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1778" target="_blank" rel="noopener noreferrer" class="title-link">Open Reasoner Zero, Open-Reasoner-Zero, 2024.02</a>
<span class="snippet"><span>GPT Summary</span>- Open-Reasoner-Zeroã¯ã€æ¨è«–æŒ‡å‘ã®å¼·åŒ–å­¦ç¿’ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹å®Ÿè£…ã§ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨ã‚¢ã‚¯ã‚»ã‚¹ã®ã—ã‚„ã™ã•ã«é‡ç‚¹ã‚’ç½®ã„ã¦ã„ã¾ã™ã€‚AGIç ”ç©¶ã®ä¿ƒé€²ã‚’ç›®æŒ‡ã—ã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1893698293965725708?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2025-03-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1777" target="_blank" rel="noopener noreferrer" class="title-link">Introducing the SWE-Lancer benchmark, OpenAI, 2025.02</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1893698290174108113?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>1400ä»¥ä¸Šã®ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã‚’é›†ã‚ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚ã‚¿ã‚¹ã‚¯ã¯ãƒã‚°ä¿®æ­£ã‹ã‚‰æ©Ÿèƒ½å®Ÿè£…ã¾ã§å¤šå²ã«ã‚ãŸã‚Šã€çµŒé¨“è±Šå¯Œãªã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã«ã‚ˆã£ã¦è©•ä¾¡ã•ã‚ŒãŸã‚‚ã®ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-02-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1769" target="_blank" rel="noopener noreferrer" class="title-link">å¼·åŒ–å­¦ç¿’ã€ŒGRPOã€ã‚’CartPoleã‚¿ã‚¹ã‚¯ã§å®Ÿè£…ã—ãªãŒã‚‰è§£èª¬, å°å·é›„å¤ªéƒ, 2025.02</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ogawa_yutaro_22/status/1892059174789407213?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-02-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1766" target="_blank" rel="noopener noreferrer" class="title-link">Mistral-24B-Reasoning, yentinglin, 2025.02</a>
<span class="snippet"><span>Comment</span><p>Apache-2.0</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1762" target="_blank" rel="noopener noreferrer" class="title-link">LLMã®äº‹å‰å­¦ç¿’ã®ãŸã‚ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åé›†ã¨æ§‹ç¯‰, Shun Kiyono, 2015.02</a>
<span class="snippet"><span>Comment</span><p>è©³ç´°ã¯è‘—æ›¸ã«è¨˜è¼‰ã¨ã®ã“ã¨ã€‚èˆˆå‘³æ·±ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1761" target="_blank" rel="noopener noreferrer" class="title-link">modernbert-ja-130m, SB Intuitions, 2025.02</a>
<span class="snippet"><span>Comment</span><p>ï¼­IT Licence</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sbintuitions/status/1889587801706078580?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1606" target="_blank" rel="noopener noreferrer">ModernBERT, AnswerDotAI, 2024.12</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1757" target="_blank" rel="noopener noreferrer" class="title-link">DeepScaleR: Surpassing O1-Preview with a 1.5B Model by Scaling RL, 2025.02</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-02-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1747" target="_blank" rel="noopener noreferrer" class="title-link">Unsloth ã§ç‹¬è‡ªã® R1 Reasoningãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’, npaka, 2025.02</a>
<span class="snippet"><span>Comment</span><p>éå¸¸ã«å®Ÿç”¨çš„ã§å‚è€ƒã«ãªã‚‹ã€‚ç‰¹ã«ã©ã®ç¨‹åº¦ã®VRAMã§ã©ã®ç¨‹åº¦ã®è¦æ¨¡æ„Ÿã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã‚‹ã®ã‹ãŒæ˜è¨€ã•ã‚Œã¦ã„ã¦å‚è€ƒã«ãªã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-02-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1743" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-R1ã®è«–æ–‡èª­ã‚“ã ï¼Ÿã€å‹‰å¼·ã«ãªã‚‹ã‚ˆã€‘ , asap, 2025.01</a>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1655" target="_blank" rel="noopener noreferrer">DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open
  Language Models, Zhihong Shao+, arXiv'24</a>
</p>
<p>ã¨ã¦ã‚‚ä¸å¯§ã§ã‚ã‹ã‚Šã‚„ã™ã‹ã£ãŸã€‚å¾Œã§èª­ã‚“ã å†…å®¹ã‚’æ›¸ã„ã¦å¾©ç¿’ã™ã‚‹ã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-01-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1737" target="_blank" rel="noopener noreferrer" class="title-link">Janus-Series: Unified Multimodal Understanding and Generation Models, DeepSeek, 2025.01</a>
<span class="snippet"><span>Comment</span><p>DeepSeekã«ã‚ˆã‚‹æ–°ãŸãªUMMã€Janus-ProãŒæœ¬æ—¥ãƒªãƒªãƒ¼ã‚¹ã€‚MIT License</p>
<p>Janus-Proã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€‚<br><br>githubä¸Šã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å›³è§£ã‹ã‚‰å¼•ç”¨ã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ï¼ˆãƒ†ã‚­ã‚¹ãƒˆ+ç”»åƒï¼‰ã®ç†è§£ã«é–¢ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§LLaVAè¶…ãˆã€‚GenEval, DPG Benchã¨å‘¼ã°ã‚Œã‚‹ç”»åƒç”Ÿæˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§DALL-E 3è¶…ãˆã€‚<br><img src="https://github.com/user-attachments/assets/39b51e99-723d-4105-a113-e4bfa847c69b" alt="image" loading="lazy"><br><br><br>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆä¸­ã§ã®è©³ç´°ã‹ã‚‰å¼•ç”¨ã€‚ã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚‚åŸºæœ¬çš„ã«æœ€é«˜æ€§èƒ½ãªã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/4c1bd071-966f-4d51-99f4-e60fa2f36b0a" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/a0b22d6e-debb-420a-bf8d-fe8833583d09" alt="image" loading="lazy"><br><br>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ: 


<a href="https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf</a>


</p>
<p>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2769" target="_blank" rel="noopener noreferrer">[Paper Note] GenEval: An Object-Focused Framework for Evaluating Text-to-Image   Alignment, Dhruba Ghosh+, NeurIPS'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2770" target="_blank" rel="noopener noreferrer">[Paper Note] ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment, Xiwei Hu+, arXiv'24</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DialogueGeneration.html" target="_blank" rel="noopener noreferrer">#DialogueGeneration</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-01-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1735" target="_blank" rel="noopener noreferrer" class="title-link">æ—¥æœ¬èªFull-duplexéŸ³å£°å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ã®è©¦ä½œ, å¤§æ©‹+, J-Moshi</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2025-01-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1733" target="_blank" rel="noopener noreferrer" class="title-link">Open R1, HuggingFace, 2025.01</a>
<span class="snippet"><span>Comment</span><p>HFã«ã‚ˆã‚‹DeepSeekR1ã‚’å®Œå…¨ã«å†ç¾ã™ã‚‹å–ã‚Šçµ„ã¿</p>
<p>Update1: 


<a href="https://huggingface.co/blog/open-r1/update-1" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/open-r1/update-1</a>


</p>
<p>Update2: 


<a href="https://huggingface.co/blog/open-r1/update-2" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/open-r1/update-2</a>


<br><br>512æ©Ÿã®H100ã‚’åˆ©ç”¨â€¦</p>
<p>Update3:


<a href="https://huggingface.co/blog/open-r1/update-3" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/open-r1/update-3</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1727" target="_blank" rel="noopener noreferrer" class="title-link">LLM Datasets, mlabonne, 2025.01</a>
<span class="snippet"><span>Comment</span><p>LLMã®äº‹å¾Œå­¦ç¿’ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã¾ã¨ã‚ãŸãƒªãƒã‚¸ãƒˆãƒª</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1726" target="_blank" rel="noopener noreferrer" class="title-link">Llama Stack, Meta, 2024.11</a>
<span class="snippet"><span>Comment</span><p>Llamaã‚’ç”¨ã„ãŸLLM Agentã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚Quick Startã§ã¯RAG Agentã‚’æ§‹ç¯‰ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1725" target="_blank" rel="noopener noreferrer" class="title-link">distilabel, 2023.11</a>
<span class="snippet"><span>Comment</span><p>é«˜å“è³ªãªåˆæˆãƒ‡ãƒ¼ã‚¿ã‚’LLMã§ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1723" target="_blank" rel="noopener noreferrer" class="title-link">How to fine-tune open LLMs in 2025 with Hugging Face, PHILSCHMID, 2024.12</a>
<span class="snippet"><span>Comment</span><p>SFTTrainerã‚’ç”¨ã„ãŸLLMã®SFTã«ã¤ã„ã¦ã€å®Ÿç”¨çš„ã€ã‹ã¤åŸºç¤çš„ãªå†…å®¹ãŒã‚³ãƒ¼ãƒ‰ä»˜ãã§ã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1722" target="_blank" rel="noopener noreferrer" class="title-link">How to align open LLMs in 2025 with DPO &amp; and synthetic data, PHILSCHMID, 2025.01</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1882428447877705908?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- DPOã®æ¦‚è¦ã‚„RLHFã¨æ¯”è¼ƒã—ãŸåˆ©ç‚¹<br>- ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã€ã‚ã‚‹ã„ã¯LLM as a Judgeã‚’ç”¨ã„ãŸOn-policy preference pairï¼ˆç¾åœ¨ã®SFTã—ãŸãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‹ã‚‰ç”Ÿæˆã—ãŸpreference dataï¼‰ã®ä½œã‚Šæ–¹ã¨ãã®åˆ©ç‚¹ï¼ˆç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã®output distributionã‚’åæ˜ ã—ã¦ã„ã‚‹ã®ã§å­¦ç¿’ãŒåŠ¹ç‡åŒ–ã•ã‚Œã‚‹ï¼‰<br>- ç’°å¢ƒæ§‹ç¯‰æ–¹æ³•<br>- DPOTrainer/TRLParserã®ä½¿ã„æ–¹/DPODatasetã®ä½œã‚Šæ–¹<br>- DPOã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Î²ã®æ„å‘³åˆã„<br>- DPOã§ã¯SFTã¨æ¯”ã¹ã¦10-100xå°ã•ã„å­¦ç¿’ç‡ã‚’ä½¿ã†å¿…è¦ãŒã‚ã‚‹ã“ã¨<br>- Evaluation Harnessã‚’ç”¨ã„ãŸè©•ä¾¡æ–¹æ³•<br>- TGIã‚’ç”¨ã„ãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã¨ãƒ†ã‚¹ãƒˆ<br><br>ãªã©ãŒä¸å¯§ãªã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã¨æ³¨é‡ˆã€referenceä»˜ãã§èª¬æ˜ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-01-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1720" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-R1-Distill-Qwen, DeepSeek, 2025.01</a>
<span class="snippet"><span>Comment</span><p>MIT Licence</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-01-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-R1, DeepSeek, 2025.01</a>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/icoxfog417/status/1883339727446974616?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å‚è€ƒ:


<a href="https://horomary.hatenablog.com/entry/2025/01/26/204545" target="_blank" rel="noopener noreferrer">https://horomary.hatenablog.com/entry/2025/01/26/204545</a>


</p>
<p>DeepSeek-R1ã®è«–æ–‡èª­ã‚“ã ï¼Ÿã€å‹‰å¼·ã«ãªã‚‹ã‚ˆã€‘<br>, asap:


<a href="https://zenn.dev/asap/articles/34237ad87f8511" target="_blank" rel="noopener noreferrer">https://zenn.dev/asap/articles/34237ad87f8511</a>


</p>
<p>ã“ã¡ã‚‰ã®ãƒã‚¹ãƒˆã®å›³è§£ãŒã‚ã‹ã‚Šã‚„ã™ã„:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/1littlecoder/status/1887134619603968439?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æœ€æ–°ãƒ¢ãƒ‡ãƒ«: DeepSeek-R1-0528<br>


<a href="https://huggingface.co/deepseek-ai/DeepSeek-R1-0528" target="_blank" rel="noopener noreferrer">https://huggingface.co/deepseek-ai/DeepSeek-R1-0528</a>


<br><br><img src="https://github.com/user-attachments/assets/c2d7e967-1677-4791-81ad-2a7d050da593" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2025-01-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1718" target="_blank" rel="noopener noreferrer" class="title-link">tokyotech-llm_swallow-magpie-ultra-v0.1, tokyotech-llm, 2025.01</a>
<span class="snippet"><span>Comment</span><p>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1876634359400370252?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-01-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1663" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-V2ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å¾¹åº•è§£èª¬ï¼šMLA ã¨ DeepSeekMoE, kernelian, 2024.05</a>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1665" target="_blank" rel="noopener noreferrer">DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models, Damai+, ACL'24, 2024.08</a>
<br><br>ã‚‚å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-01-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1662" target="_blank" rel="noopener noreferrer" class="title-link">Killed by LLM, R0bk</a>
<span class="snippet"><span>Comment</span><p>Saturationã¨ãªã£ã¦ã„ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã€æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ã™ã§ã«æ¸¬å®šã§ããªããªã£ã¦ã—ã¾ã£ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2025-01-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1661" target="_blank" rel="noopener noreferrer" class="title-link">Advanced RAG Techniques: Elevating Your Retrieval-Augmented Generation Systems, NirDiamant, 2025.01</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rohanpaul_ai/status/1875447223682748750?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RAGã®ãŸã‚ã®ç´°ã‹ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ãŒï¼ˆã‚³ãƒ¼ãƒ‰ã®ã‚µãƒ³ãƒ—ãƒ«ã¸ã®ãƒªãƒ³ã‚¯ä»˜ãã§ï¼‰å¤§é‡ã«ã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚ã‹ãªã‚Šé »ç¹ã«æ›´æ–°ã‚Œã¦ã„ã‚‹ã‚ˆã†ã§éå¸¸ã«è‰¯ã•ãã†</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/API.html" target="_blank" rel="noopener noreferrer">#API</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<span class="issue_date">Issue Date: 2025-01-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1652" target="_blank" rel="noopener noreferrer" class="title-link">browser-use ã‚„ã°ã„ã§ã™, Syoitu, 2024.12</a>
<span class="snippet"><span>Comment</span><p>ã™ã”ã„æ‰‹è»½ã«ä½¿ãˆãã†ã ãŒã€ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°ç”¨é€”ã«ä½¿ãŠã†ã¨ã™ã‚‹ã¨hallucinationãŒèµ·ããŸæ™‚ã«å›°ã‚‹ã®ã§ã†ãƒ¼ã‚“ã¨è¨€ã£ãŸã¨ã“ã‚ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/API.html" target="_blank" rel="noopener noreferrer">#API</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1651" target="_blank" rel="noopener noreferrer" class="title-link">LiteLLM, BerriAI, 2023.08</a>
<span class="snippet"><span>Comment</span><p>æ§˜ã€…ãªLLMã®APIã‚’å…±é€šã®ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ã§å‘¼ã³å‡ºã›ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª<br><br></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1553" target="_blank" rel="noopener noreferrer">aisuite, andrewyng, 2024.11</a>
 <br><br><br><br>ã¨ã©ã¡ã‚‰ãŒã„ã„ã‚“ã ãƒ»ãƒ»ãƒ»ï¼Ÿ</p>
<p>aisuiteã®issueã®113ç•ªã®ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’è¦‹ã‚‹ã¨ã€<br><br>- LiteLLMã¯ã‚‚ã¯ã‚„Liteã§ã¯ãªããªã£ã¦ãŠã‚Šã€ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ä¿å®ˆæ€§ãŒä½ã„<br><br>- aisuiteã¯è¤‡æ•°ã®LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã‚’æä¾›ã™ã‚‹<br><br>- ä»Šå¾Œç™ºè¡¨ã•ã‚Œã‚‹ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’è¦‹ã‚Œã°ã€LiteLLMã¨ã®å·®åˆ¥åŒ–ã®æ–¹å‘æ€§ãŒåˆ†ã‹ã‚‹ã¯ãšã <br><br><br><br>ã¨ã„ã£ãŸè¶£æ—¨ã®ã“ã¨ãŒè¨˜è¿°ã•ã‚Œã¦ã„ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1642" target="_blank" rel="noopener noreferrer" class="title-link">Things we learned about LLMs in 2024, Simon Willson's blog, 2024.12</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_stakaya/status/1875059840126722127?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1635" target="_blank" rel="noopener noreferrer" class="title-link">To fine-tune or not to fine-tune, Meta, 2024.08</a>
<span class="snippet"><span>Comment</span><p>LLMã‚’SFTã™ã‚‹éš›ã®æ³¨æ„ç‚¹ã‚„ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«ã¤ã„ã¦è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>- full parameterã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„PEFTæ‰‹æ³•ã®ãƒ”ãƒ¼ã‚¯GPUãƒ¡ãƒ¢ãƒª<br>- full parameterã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã¯catastrophic forgettingã«æ°—ã‚’ã¤ã‘ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨<br>- FinetuningãŒæœ‰ç”¨ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã¨ã—ã¦ä»¥ä¸‹ãŒæŒ™ã’ã‚‰ã‚Œã¦ã„ã‚‹<br>  - ãƒˆãƒ¼ãƒ³ã€ã‚¹ã‚¿ã‚¤ãƒ«ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚¶ãƒ¼ã‚·ãƒ§ãƒ³<br>  - prompt engineeringã‚„ICLã§é”æˆã™ã‚‹ã«ã¯å›°é›£ãªAccuracyã®å‘ä¸Šã‚„ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã¸ã®å¯¾å¿œ<br>  - ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œ<br>  - ã‚ˆã‚Šå¤§ãã„ãƒ¢ãƒ‡ãƒ«ã‚’è’¸ç•™ã™ã‚‹ã“ã¨ã«ã‚ˆã‚‹ã‚³ã‚¹ãƒˆå‰Šæ¸›<br>  - æ–°ãŸãªã‚¿ã‚¹ã‚¯ã¸ã®é©å¿œã‚„èƒ½åŠ›ã®ç²å¾— </p>
<p>ã¾ãŸã€RAGã¨Finetuningã©ã¡ã‚‰ã‚’é¸æŠã™ã¹ãã‹ã«é–¢ã™ã‚‹è©±é¡Œã‚‚è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ï¼ˆãŒã€å¤šãã®å ´åˆã¯ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒãƒ™ã‚¹ãƒˆã ã€ã¨ã„ã£ãŸè©±ã‚‚æ›¸ã„ã¦ã‚ã‚‹ï¼‰ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1633" target="_blank" rel="noopener noreferrer" class="title-link">2024-ai-timeline, reach-vb, 2025.01</a>
<span class="snippet"><span>Comment</span><p>æœˆåˆ¥ã§2024å¹´ã«ãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸä¸»è¦ãªLLMï¼ˆãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªLLMã‚‚å«ã‚€ï¼‰ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚<br>API Onlyï¼ˆãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªï¼‰ãªã®ã‹ã€OpenWeightãªã®ã‹ã‚‚ã‚¿ã‚°ä»˜ã‘ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-12-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1623" target="_blank" rel="noopener noreferrer" class="title-link">Preferred Generation Benchmark, pfnet-research, 2024.12</a>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bilzrd/status/1873167934564311133?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¥æœ¬èªãƒ—ãƒ¬ãƒ—ãƒªãƒ³ãƒˆ:


<a href="https://jxiv.jst.go.jp/index.php/jxiv/preprint/view/1008" target="_blank" rel="noopener noreferrer">https://jxiv.jst.go.jp/index.php/jxiv/preprint/view/1008</a>


</p>
<p>arXivã¯ã“ã‚Œã‹ã‚‰ã£ã½ã„</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1621" target="_blank" rel="noopener noreferrer" class="title-link">MHA vs MQA vs GQA vs MLA, Zain ul Abideen, 2024.07</a>
<span class="snippet"><span>Comment</span><p>DeepSeekã§ä½¿ã‚ã‚Œã¦ã„ã‚‹Multi Head Latent Attentionï¼ˆMLAï¼‰ã£ã¦ãªã‚“ã ï¼Ÿã¨æ€ã„èª­ã‚“ã ã€‚ç«¯çš„ã«è¨€ã†ã¨ã€GQAã‚„MQAã¯ã€KVã®ãƒ˜ãƒƒãƒ‰ã‚’ãã‚‚ãã‚‚æ¸›ã‚‰ã—ã¦KV Cacheã‚’æŠ‘ãˆã‚ˆã†ã€ã¨ã„ã†æ‰‹æ³•ã ã£ãŸãŒã€MLAã¯KVã‚’ä½ãƒ©ãƒ³ã‚¯ãªãƒ™ã‚¯ãƒˆãƒ«ã«åœ§ç¸®ã—ã¦ä¿æŒã—ã€ä½¿ã†æ™‚ã«å¾©å…ƒã™ã‚‹ã¨ã„ã£ãŸæ“ä½œã‚’ã™ã‚‹ã“ã¨ã§ã€MHAã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è½ã¨ã™ã“ã¨ãªãï¼ˆã‚€ã—ã‚ä¸ŠãŒã‚‹ã‚‰ã—ã„ï¼Ÿï¼‰ã€åˆ©ç”¨ã™ã‚‹KV Cacheã§åˆ©ç”¨ã™ã‚‹ãƒ¡ãƒ¢ãƒªã‚’å¤§å¹…ã«æ¸›ã‚‰ã›ã‚‹ã¨ã„ã†æ‰‹æ³•ã‚‰ã—ã„ã€‚</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
<br><br>MQA, GQAã®æ¦‚è¦ã«ã¤ã„ã¦ã¯ä¸Šè¨˜å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1620" target="_blank" rel="noopener noreferrer" class="title-link">Deep-seek-v3, deepseek-ai, 2024.12</a>
<span class="snippet"><span>Comment</span><p>å‚è€ƒï¼ˆãƒ¢ãƒ‡ãƒ«ã®å›³è§£ï¼‰:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vtabbott_/status/1874449446056177717?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1876397959841186148?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-12-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1617" target="_blank" rel="noopener noreferrer" class="title-link">LLMã‚’æ•°å­¦ã‚¿ã‚¹ã‚¯ã«ã‚¢ãƒ©ã‚¤ãƒ³ã™ã‚‹æ‰‹æ³•ã®ç³»è­œ - GPT-3ã‹ã‚‰Qwen2.5ã¾ã§, bilzard, 2024.12</a>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1618" target="_blank" rel="noopener noreferrer">Training Verifiers to Solve Math Word Problems, Karl Cobbe+, arXiv'21</a>
<br><br>ã«ãŠã„ã¦ã€æ•°å­¦ã«ãŠã„ã¦ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦æ€§èƒ½æ”¹å–„ãŒè¦‹è¾¼ã‚ã‚‹å­¦ç¿’æ‰‹æ³•ã¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã¨ã¯åˆ¥ã«Verifierã‚’å­¦ç¿’ã—ã€ãƒ¢ãƒ‡ãƒ«ãŒå‡ºåŠ›ã—ãŸå€™è£œã®ä¸­ã‹ã‚‰è‰¯ã„ã‚‚ã®ã‚’é¸æŠã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€ã¨ã„ã†è©±ã®æ°—æŒã¡ãŒæœ€åˆã‚ˆãã‚ã‹ã‚‰ãªã‹ã£ãŸã®ã ãŒã€å¾ŒåŠã®ãªãœsample&amp;selectãŒã†ã¾ãã„ãã®ã‹ï¼Ÿç¯€ã‚’èª­ã‚“ã§ãªã‚“ã¨ãªãæ°—æŒã¡ãŒç†è§£ã§ããŸã€‚SFTã‚’é€²ã‚ã‚‹ã¨ãƒ¢ãƒ‡ãƒ«ãŒå‡ºåŠ›ã™ã‚‹è§£æ”¾ã®å¤šæ§˜æ€§ãŒæ¸›ã£ã¦ã„ãã¨ã„ã†ã®ã¯ã€èˆˆå‘³æ·±ã‹ã£ãŸã€‚<br><br>ã—ã‹ã—ã€ç‰¹å®šã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ãŸæ™‚ã«ã€å…¨ãç•°ãªã‚‹Unseenãªãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã‚‚è§£æ³•ã¯æ¸›ã£ã¦ã„ãã®ã ã‚ã†ã‹ï¼Ÿã¨ã„ã†ç‚¹ãŒæ°—ã«ãªã£ãŸã€‚ã‚ã¨ã¯ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ã‚’ã‚ã¡ã‚ƒã‚ã¡ã‚ƒå¢—ã‚„ã—ãŸã‚‰ã©ã†ãªã‚‹ã®ã‹ï¼Ÿã¨ã„ã†ã®ã‚‚æ°—ã«ãªã‚‹ã€‚ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å®Œå…¨ã«æ”»ç•¥ã§ãã‚‹ã‚ˆã†ãªè§£æ³•ã‚’å‡ºåŠ›ã—ã‚„ã™ããªã‚‹ã¨ã€ä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ€§èƒ½ãŒæ‚ªããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹æ°—ãŒã—ã¦ãŠã‚Šã€ãã†ã™ã‚‹ã¨ãã‚‚ãã‚‚ã®1shotã®æ€§èƒ½è‡ªä½“ã‚‚æ”¹å–„ã—ã¦ã„ã‹ãªããªã‚Šãã†ã ãŒã€ãã®è¾ºã¯ã©ã†ã„ã†è¨­å®šã§å®Ÿé¨“ã•ã‚Œã¦ã„ã‚‹ã®ã ã‚ã†ã‹ã€‚<br><br>ãŸã¨ãˆã°ã€<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
<br><br>ãªã©ã§ã¯ã€<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1474" target="_blank" rel="noopener noreferrer">Super-NaturalInstructions: Generalization via Declarative Instructions  on 1600+ NLP Tasks, Yizhong Wang+, N/A, EMNLP'22</a>
<br><br>ã®ã‚ˆã†ãª1600ã‚’è¶…ãˆã‚‹ã‚ˆã†ãªNLPã‚¿ã‚¹ã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã§LoRAã«ã‚ˆã‚ŠSFTã™ã‚‹ã¨ã€LoRAã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’éå¸¸ã«å¤§ããã™ã‚‹ã¨Unseenã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ€§èƒ½ãŒfull-parameter tuningã™ã‚‹ã‚ˆã‚Šã‚‚å‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã®ä¾‹ã¯æ•°å­¦ã«ç‰¹åŒ–ã—ãŸä¾‹ã§ã¯ãªã„ãŒã€SFTã«ã‚ˆã£ã¦è§£æ³•ã®å¤šæ§˜æ€§ãŒæ¸›ã‚‹ã“ã¨ã«ã‚ˆã£ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«éå‰°é©åˆã—ã¦æ±åŒ–æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ã€ã¨ã„ã†ã®ã§ã‚ã‚Œã°ã€ã“ã®è«–æ–‡ã®ã“ã¨ã‚’é‘‘ã¿ã‚‹ã¨ã€Œå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«overfittingã—ãŸçµæœä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æ€§èƒ½ãŒä½ä¸‹ã—ã¦ã—ã¾ã†ç¨‹åº¦ã®å¤šæ§˜æ€§ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã—ã‹ä½¿ãˆã¦ã„ãªã„ã®ã§ã¯ã€ã¨æ„Ÿã˜ã¦ã—ã¾ã†ã®ã ãŒã€ãã®è¾ºã¯ã©ã†ãªã‚“ã ã‚ã†ã‹ã€‚å…ƒè«–æ–‡ã‚’èª­ã‚“ã§ç¢ºèªã—ãŸã„ã€‚<br>ã¨ã¦ã‚‚å‹‰å¼·ã«ãªã£ãŸã€‚</p>
<p>è¨˜äº‹ä¸­ã§ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br>&gt; LLMã‚’ä½¿ã£ã¦è¤‡æ•°è§£æ³•ã®å€™è£œã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ãã®ä¸­ã‹ã‚‰æœ€é©ãª1ã¤ã‚’é¸æŠã™ã‚‹<br><br>ã®ãƒ«ãƒ¼ãƒ„ã¯ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1618" target="_blank" rel="noopener noreferrer">Training Verifiers to Solve Math Word Problems, Karl Cobbe+, arXiv'21</a>
 ã¨ã®ã“ã¨ãªã®ã§æ˜¯éèª­ã¿ãŸã„ã€‚<br><br>ã“ã®è¾ºã¯Self-Consistency <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/558" target="_blank" rel="noopener noreferrer">Self-consistency improves chain of thought reasoning in language models, Wang+, Google Research, ICLR'23</a>
 ã‚ãŸã‚ŠãŒæœ€åˆãªã®ã‹ã¨æ€ã£ã¦ã„ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-12-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1615" target="_blank" rel="noopener noreferrer" class="title-link">LLM-as-a-Judge ã‚’ã‚µãƒ¼ãƒ™ã‚¤ã™ã‚‹, Ayako, 2024.12</a>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1616" target="_blank" rel="noopener noreferrer">A Survey on LLM-as-a-Judge, Jiawei Gu+, arXiv'24</a>
<br><br>ã‚’èª­ã‚“ã çµæœã‚’æ—¥æœ¬èªã§ã¾ã¨ã‚ã¦ãã ã•ã£ã¦ã„ã‚‹ã€‚</p>
<p>ãƒ¢ãƒ‡ãƒ«é¸æŠã«ã¤ã„ã¦ã€å¤–éƒ¨APIã«ä¾å­˜ã™ã‚‹ã¨ã‚³ã‚¹ãƒˆã‚„ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã€å†ç¾æ€§ãªã©ã®å•é¡ŒãŒã‚ã‚‹ãŸã‚OpenLLMã‚’Finetuningã™ã‚‹ã“ã¨ã§å¯¾å¿œã—ã¦ã„ã‚‹ã“ã¨ãŒè«–æ–‡ä¸­ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã ãŒã€è©•ä¾¡èƒ½åŠ›ã«ã¯ã¾ã é™ç•ŒãŒã‚ã‚‹ã¨ã®ã“ã¨ã€‚<br><br>è¨˜äº‹ä¸­ã§ã¯Llama, Vicunaãªã©ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹æ—¨ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ãŒã€ã©ã®ç¨‹åº¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã‚’ã©ã‚“ãªãƒ‡ãƒ¼ã‚¿ã§SFTã—ã€ã©ã®ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã‚’è©•ä¾¡ã—ãŸã®ã ã‚ã†ã‹ï¼ˆã‚ã¨ã§å…ƒè«–æ–‡ã‚’è¦‹ã¦ç¢ºèªã—ãŸã„ï¼‰ã€‚<br><br><br><br>ã¾ãŸã€å¾Œå‡¦ç†ã¨ã—ã¦ãƒ«ãƒ¼ãƒ«ãƒãƒƒãƒã§æŠ½å‡ºã™ã‚‹å¿…è¦ã‚ãŒã‚‹ãŒã€ãƒ¢ãƒ‡ãƒ«ã®AlignmentãŒä½ã„ã¨æˆåŠŸç‡ãŒä¸‹ãŒã‚‹ã¨ã®ã“ã¨ã§ã‚ã‚‹ã€‚<br><br>å€‹äººçš„ã«ã¯ã€ã‚¹ã‚³ã‚¢ã‚’ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã™ã‚‹å½¢å¼ã®å ´åˆç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŠ½å‡ºã™ã‚‹æ–¹å¼ã§ã¯ãªãã€G-Eva ã®ã‚ˆã†ã«ã‚¹ã‚³ã‚¢ã¨é–¢é€£ã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆe.g. 1,2,3,4,5ï¼‰ã¨ãã®å°¤åº¦ã®åŠ é‡å¹³å‡ã‚’ã¨ã‚‹ã‚ˆã†ãªæ‰‹æ³•ãŒå¾Œå‡¦ç†ãŒæ¥½ã§è‰¯ã„ã¨æ„Ÿã˜ã‚‹ã€‚<br><br>ICLR2025ã®æŸ»èª­ã«LLM-as-a-JudgeãŒå°å…¥ã•ã‚Œã‚‹ã¨ã„ã†ã®ã¯çŸ¥ã‚‰ãªã‹ã£ãŸã®ã§ã€éå¸¸ã«èˆˆå‘³æ·±ã„ã€‚</p>
<p>LLMãŒå¥½ã‚€å›ç­”ã®ãƒã‚¤ã‚¢ã‚¹ï¼ˆå†—é•·æ€§ã€ä½ç½®ãªã©ï¼‰åˆ¥ã«å„LLMã®ãƒ¡ã‚¿è©•ä¾¡ã‚’ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ã¾ãŸã€æ€§èƒ½ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®æ–½ç­–ã‚’å®Ÿæ–½ã—ãŸå ´åˆã«ã©ã®ç¨‹åº¦ãƒ¡ã‚¿è©•ä¾¡ã§æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã‹ã‚‚è©•ä¾¡ã—ã¦ã„ã‚‹ã€‚ç‰¹ã«èª¬æ˜ã‚’å‡ºåŠ›ã•ã›ã¦ã‚‚åŠ¹æœã¯è–„ãã€ã¾ãŸã€è¤‡æ•°LLMã«ã‚ˆã‚‹æŠ•ç¥¨ã«ã—ã¦ã‚‚ä½ç½®ãƒã‚¤ã‚¢ã‚¹ã®è»½æ¸›ã«å¯„ä¸ã™ã‚‹ç¨‹åº¦ã®æ”¹å–„ã—ã‹ãªã‹ã£ãŸã¨ã®ã“ã¨ã€‚ã¾ãŸã€è¤‡æ•°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®çµæœã®è¦ç´„ã‚’ã•ã›ã‚‹æ–¹æ³•ãŒãƒã‚¤ã‚¢ã‚¹ã®ä½æ¸›ã«å¹…åºƒãå¯„ä¸ã—ãŸã¨ã®ã“ã¨ã€‚</p>
<p>ã†ãƒ¼ã‚“ã€ãƒã‚¤ã‚¢ã‚¹ã‚’ä½æ¸›ã™ã‚‹ã†ã¾ã„æ–¹æ³•ãŒã¾ã ç„¡ã•ãã†ãªã®ãŒãªã‹ãªã‹å³ã—ã„æ„Ÿã˜ãŒã™ã‚‹ã€‚<br>ãã‚‚ãã‚‚æ ¹æœ¬çš„ã«äººé–“ã«äººæ‰‹è©•ä¾¡ã‚’ãŠé¡˜ã„ã™ã‚‹æ™‚ã‚‚ã‚ã¡ã‚ƒã‚ã¡ã‚ƒãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã¨ã‹ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ä½œã‚Šè¾¼ã‚“ã ã‚Šã—ãŸä¸Šã§ã‚‚agreementãŒé«˜ããªã‹ã£ãŸã‚Šã™ã‚‹ã®ã§ã€ã‚„ã¯ã‚Šé›£ã—ãã†ã§ã‚ã‚‹ã€‚<br><br>ãŸã ã€MTBenchã§ã¯äººé–“ã®è©•ä¾¡çµæœã¨LLMã®è©•ä¾¡çµæœã®ç›¸é–¢ï¼ˆagreementã ã£ã‘ã‹â€¦ï¼Ÿï¼‰ãŒé«˜ã‹ã£ãŸã“ã¨ãªã©ãŒå ±å‘Šã•ã‚Œã¦ã„ã‚‹ã—ã€LLMã‚ã‚‹ã‚ã‚‹ã®ã‚¿ã‚¹ã‚¯ã”ã¨ã«å¾—æ„ä¸å¾—æ„ãŒã‚ã‚Šã¾ã™ã€ã¨ã„ã†è©±ãªæ°—ã‚‚ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Video.html" target="_blank" rel="noopener noreferrer">#Video</a>
<span class="issue_date">Issue Date: 2024-12-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1614" target="_blank" rel="noopener noreferrer" class="title-link">Stanford CS229 I Machine Learning I Building Large Language Models ï¼ˆLLMsï¼‰, StanfordUnivercity, 2024.09</a>
<span class="snippet"><span>Comment</span><p>ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦ã«ã‚ˆã‚‹LLMæ§‹ç¯‰ã«é–¢ã™ã‚‹è¬›ç¾©ã€‚äº‹å‰å­¦ç¿’ã¨äº‹å¾Œå­¦ç¿’ä¸¡æ–¹ã¨ã‚‚ã‚«ãƒãƒ¼ã—ã¦ã„ã‚‹ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-12-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1613" target="_blank" rel="noopener noreferrer" class="title-link">Qwen2.5 Technical Reportã®ä¸­ã«æ½œã‚‹, AbejaTech Blog, 2024.12</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-12-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1612" target="_blank" rel="noopener noreferrer" class="title-link">OpenAI o3ã¯ï¼Œäººé–“ã¨ã¯å…¨ãç•°è³ªã®æ±ç”¨çŸ¥èƒ½ã§ã‚ã‚‹å±é™ºæ€§ã€æ±å¤§è§£èª¬ã€‘, ç¥æ¥½å‚ã‚„ã¡ã¾, 2024.12</a>
<span class="snippet"><span>Comment</span><p>æ§˜ã€…ãªæœ‰è­˜è€…ã®è¦‹è§£ã‚’ã¾ã¨ã‚ã¤ã¤ã€æ–‡çŒ®ã‚’å¼•ç”¨ã—ã¤ã¤ã€ã‹ã¤æœ€çµ‚çš„ã«ã€Œäººé–“ãŒçŸ¥èƒ½ã¨ã„ã†ã‚‚ã®ã«å¯¾ã—ã¦ãªã‚“ã‚‰ã‹ã®ãƒã‚¤ã‚¢ã‚¹ã‚’æŒã£ã¦ã„ã‚‹ã€å¯èƒ½æ€§ãŒã‚ã‚‹ã€ã¨ã„ã†è©±ã‚’ã—ã¦ãŠã‚Šèˆˆå‘³æ·±ã„ã€‚<br>ä¸€éƒ¨ã®æœ‰è­˜è€…ã¯ARC-AGIã®ä¸€éƒ¨ã®ã€äººé–“ãªã‚‰è¦‹ãŸç¬é–“ã«åˆ†ã‹ã‚‹ã‚ˆã†ãªãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã®å•é¡Œã§ã‚‚è§£ã‘ã¦ã„ãªã„ã“ã¨ã‹ã‚‰ã€AGIã§ã¯ãªã„ã¨ä¸»å¼µã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã ã£ãŸãŒã€äººé–“ç›®ç·šã§ç°¡å˜ãªå•é¡ŒãŒè§£ã‘ã‚‹ã“ã¨ã¯AGIã¨ã—ã¦å¿…é ˆãªæ¡ä»¶ã§ã¯ãªã„ã‚ˆã­ã€ã¨ã„ã£ãŸè©±ãŒæ›¸ã‹ã‚Œã¦ãŠã‚Šã€ãã‚‚ãã‚‚æœ‰è­˜è€…ãŒã©ã®ã‚ˆã†ãªã‚‚ã®ã•ã—ã‚„è¦³ç‚¹ã§AGIã‚’è¦‹ã¦ã„ã‚‹ã®ã‹ã€ã©ã†ã„ã†è¦–ç‚¹ãŒã‚ã‚‹ã®ã‹ã€ã¨ã„ã†ã“ã¨ãŒæ„Ÿè¦šçš„ã«åˆ†ã‹ã‚‹å†…å®¹ã§ã‚ã‚Šã€ãŠã‚‚ã—ã‚ã‹ã£ãŸã€‚<br><br>ã—ã‹ã—ã€ãã‚‚ãã‚‚ä½•ãŒã©ã†ãªã£ãŸã‚‰AGIãŒå®Ÿç¾ã§ããŸã¨è¨€ãˆã‚‹ã®ã ã‚ã†ã‹ï¼Ÿå®šç¾©ãŒã‚ã‹ã‚‰ãªã„ï¼ˆå®šç¾©ã€ã‚ã‚‹ã®ã‹â€¦ï¼Ÿï¼‰</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Tokenizer.html" target="_blank" rel="noopener noreferrer">#Tokenizer</a>
<span class="issue_date">Issue Date: 2024-12-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1611" target="_blank" rel="noopener noreferrer" class="title-link">Large Concept Models: Language Modeling in a Sentence Representation Space, Meta, 2024.12</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¨€èªã‚„ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«ä¾å­˜ã—ãªã„ã€Œå¤§è¦æ¨¡æ¦‚å¿µãƒ¢ãƒ‡ãƒ«ã€ã‚’ææ¡ˆã—ã€æ¦‚å¿µã‚’é«˜æ¬¡ã®æ„å‘³è¡¨ç¾ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚æœ€å¤§200è¨€èªã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹SONARæ–‡åŸ‹ã‚è¾¼ã¿ç©ºé–“ã‚’ç”¨ã„ã€è‡ªå·±å›å¸°çš„ãªæ–‡äºˆæ¸¬ã‚’è¡Œã†ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¾ã—ãŸã€‚16å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰70å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã—ã€ç”Ÿæˆã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹å®Ÿé¨“è©•ä¾¡ã‚’å®Ÿæ–½ã€‚çµæœã¨ã—ã¦ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆä¸€èˆ¬åŒ–æ€§èƒ½ãŒå‘ä¸Šã—ã€æ—¢å­˜ã®LLMsã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã¾ã å…¨ãèª­ã‚ã¦ã„ãªã„ãŒã€å¾“æ¥ã®LLMã¯nent-token-predictionã§å­¦ç¿’ã‚’ã—ã¦ãŠã‚Šã€transformers decoderã®å†…éƒ¨çŠ¶æ…‹ã§ä½•ã‚‰ã‹ã®æŠ½è±¡çš„ãªæ¦‚å¿µã¯ã¨ã‚‰ãˆã¦ã„ã‚‹ã‚‚ã®ã®ã€æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã«å‰å›ç”Ÿæˆã—ãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’inputã™ã‚‹ã®ãŒå¿…é ˆã§ã‚ã‚‹ä»¥ä¸Šã€Œãƒˆãƒ¼ã‚¯ãƒ³ã§è€ƒãˆã‚‹ã€ã¿ãŸã„ãªæŒ™å‹•ã‚’ã‚ã‚‹ç¨‹åº¦ã¯ã—ã¦ã—ã¾ã£ã¦ãŠã‚Šã€äººé–“ã¯ãã‚“ãªã“ã¨ã—ãªã„ã§ã™ã‚ˆã­ï¼Ÿã¿ãŸã„ãªè©±ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br>äººé–“ã¯ã‚‚ã£ã¨æŠ½è±¡çš„ãªã‚³ãƒ³ã‚»ãƒ—ãƒˆãƒ¬ãƒ™ãƒ«ã§ç‰©äº‹ã‚’è€ƒãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã®ã§ã€ãã‚Œã«ã‚ˆã‚Šè¿‘ã¥ã‘ã‚‹ãŸã‚ã«ã€conceptã‚’sentenceã¨ã—ã¦ã¿ãªã—ã¦ã€next-concept-predictionã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ãŸã‚‰ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®æ±åŒ–æ€§èƒ½ä¸ŠãŒã‚Šã¾ã—ãŸã€ã¿ãŸã„ãªè©±ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ãŸã ã—ã€è©•ä¾¡ã‚’ã—ã¦ã„ã‚‹ã®ã¯ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãªæ–‡æ›¸è¦ç´„ã‚¿ã‚¹ã‚¯ã®ã¿ã«è¦‹ãˆã‚‹ã€‚<br><br>è¿½è¨˜: ã‚³ãƒ³ã‚»ãƒ—ãƒˆãŒè¨€èªéä¾å­˜ã ã¨ã™ã‚‹ã¨ã€ã‚³ãƒ³ã‚»ãƒ—ãƒˆé–“ã®é–¢ä¿‚æ€§ã‚’å­¦ç¿’ã™ã‚‹LCMãŒã€ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ã§ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã®å­¦ç¿’ã—ã‹ã—ãªã„å¾“æ¥LLMã‚’ä¸Šå›ã‚‹ã®ã‚‚ç´å¾—ã„ãæ°—ã¯ã™ã‚‹ã€‚ãªãœãªã‚‰ã€å¾“æ¥LLMã‚ˆã‚Šã‚‚è¨€èªï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã¸ã®ä¾å­˜ãŒç·©å’Œã•ã‚Œã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã®ã§ã€è¨€èªé–“ã‚’è·¨ã„ã çŸ¥è­˜ã®è»¢ç§»ãŒèµ·ãã‚„ã™ã„ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã‹ã‚‰ã§ã‚ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/2f3dc98d-ef27-44b8-be1c-0f27a05f37e8" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/effc21ba-22db-42c0-bc33-1d43f9e0200a" alt="image" loading="lazy"></p>
<p>Base-LCMã‚’è¦‹ã‚‹ã¨ã€æ–‡ã®åŸ‹ã‚è¾¼ã¿ã®ground truthã¨ç”Ÿæˆã•ã‚ŒãŸæ–‡ã®åŸ‹ã‚è¾¼ã¿ã®å·®ã‚’æœ€å°åŒ–ã™ã‚‹ï¼ˆMean Squared Errorï¼‰ ã‚ˆã†ãªlossã«ãªã£ã¦ã„ã‚‹ã€‚ã¤ã¾ã‚Šã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã§ã¯ãªãã€ã‚ˆã‚ŠæŠ½è±¡çš„ãªæ¦‚å¿µã‚’ç›´æ¥å­¦ç¿’ã™ã‚‹ã‚ˆã†ãªè¨­è¨ˆã«ãªã£ã¦ã„ã‚‹ãŸã‚ã“ã“ãŒå¾“æ¥ã®LLMã¨ç•°ãªã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/01da9a76-f5fb-4e79-b3cf-8bddc123379b" alt="image" loading="lazy"><br><br>ã“ã‚Œã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€ground truthã¨ãªã‚‹æ–‡ã®åŸ‹ã‚è¾¼ã¿x_nãŒåˆ†ã‹ã‚‰ãªã‘ã‚Œã°ã„ã‘ãªã„ãŒã€ã“ã®ãŸã‚ã«ã€freezeã—ãŸEncoderã¨Decoderã‚’ç”¨æ„ã—ã¦LCMã«concatã—ã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚ã¤ã¾ã‚Šã€å…¥åŠ›ã¨å‡ºåŠ›ã®conceptã‚’è§£é‡ˆã™ã‚‹æ©Ÿæ§‹ã¯å›ºå®šã—ã¦ã€æ­£è§£ã¨ãªã‚‹æ–‡åŸ‹ã‚è¾¼ã¿ã‚’æ±ºã‚ã¦ã—ã¾ã†ã€‚ãã—ã¦ã€LCMã¯inputã•ã‚ŒãŸconceptã‚’åˆ¥ã®conceptã«å¤‰æ›ã™ã‚‹ã‚ˆã†ãªæ©Ÿæ§‹ã¨ãªã£ã¦ãŠã‚Šã€ãã®å¤‰æ›ã®é–¢ä¿‚æ€§ã‚’å­¦ç¿’ã—ã¦ã„ã‚‹ã€‚ãªã‚‹ã»ã©ã€ãªã‚“ã¨ãªãæ°—æŒã¡ã¯ã‚ã‹ã£ãŸã€‚</p>
<p>æ—¥æœ¬èªã‚’å«ã‚€ã„ãã¤ã‹ã®è¨€èªã§ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆæ€§èƒ½ãŒä½ä¸‹ã—ã¦ã„ã‚‹ã®ãŒèˆˆå‘³æ·±ã„ã€‚æ—¥æœ¬èªç‰¹æœ‰ã®æ¦‚å¿µã¨ã‹ã€ç‰¹å®šã®è¨€èªå›ºæœ‰ã®æ¦‚å¿µã¯æ¬ è½ã™ã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-12-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1610" target="_blank" rel="noopener noreferrer" class="title-link">å®Œå…¨ã«ã‚ªãƒ¼ãƒ—ãƒ³ãªç´„1,720å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆGPT-3ç´šï¼‰ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« ã€Œllm-jp-3-172b-instruct3ã€ã‚’ä¸€èˆ¬å…¬é–‹ ï½GPT-3.5ã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’é”æˆï½ , NII, 2024.12</a>
<span class="snippet"><span>Comment</span><p>GPT3.5ã¨åŒç¨‹åº¦ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®ã‚³ãƒ¼ãƒ‘ã‚¹ã€ãƒ¢ãƒ‡ãƒ«ã€ãƒ„ãƒ¼ãƒ«ã€å…¨ã¦ã‚’å…¬é–‹ã€‚å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¾ã§å«ã‚ã¦ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã¯ä¸–ç•Œæœ€å¤§è¦æ¨¡ã¨ã®ã“ã¨ã€‚</p>
<p>Instructionãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã¯ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã‚’èª­ã‚€ã¨ã€ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹å†…å®¹ã‚’éµå®ˆã™ã‚Œã°ã€èª°ã§ã‚‚ï¼ˆæ—¥æœ¬äººãªã‚‰18æ­³ä»¥ä¸Šã¨ã‹ã¯ã‚ã‚‹ãŒï¼‰ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã€ç”¨é€”ã®åˆ¶é™ï¼ˆå•†ç”¨ãƒ»éå•†ç”¨å•ã‚ãšï¼‰ãªãåˆ©ç”¨ã§ãã€ã‹ã¤å†é…å¸ƒã‚„æ´¾ç”Ÿç‰©ã®ç”Ÿæˆãªã©ãŒè¨±ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br>ãŒã€baseãƒ¢ãƒ‡ãƒ«ã®æ–¹ã¯ã‚³ãƒ³ã‚¿ã‚¯ãƒˆæƒ…å ±ã‚’æä¾›ã®ã†ãˆæ‰¿èªã‚’å—ã‘ãªã„ã¨åˆ©ç”¨ã§ããªã„æ¨¡æ§˜ã€‚ã¾ãŸã€å†é…å¸ƒã¨ä¸€éƒ¨ã®ä½¿é€”ã«åˆ¶é™ãŒã‚ã‚‹æ¨¡æ§˜ã€‚<br><br>SNSã§ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§ã¯ãªã„ãªã©ã¨ã„ã†è¨€èª¬ã‚‚å‡ºã¦ãŠã‚Šã€ãã‚Œã¯baseãƒ¢ãƒ‡ãƒ«ã®æ–¹ã‚’æŒ‡ã—ã¦ã„ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿã‚ˆãã‚ã‹ã‚‰ãªã„ã€‚</p>
<p>å®Ÿç”¨ä¸Šã¯instructionãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒbaseãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ä½¿ã„ã‚„ã™ã„ã¨æ€ã†ã®ã§ã€å•é¡Œãªã„æ°—ã‚‚ã™ã‚‹ã€‚</p>
<p>ã‚„ã¯ã‚Šbaseã¨instructã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯2ç¨®é¡ã‚ã‚‹ã¨ã®ã“ã¨: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1871508348086214685?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<span class="issue_date">Issue Date: 2024-12-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1606" target="_blank" rel="noopener noreferrer" class="title-link">ModernBERT, AnswerDotAI, 2024.12</a>
<span class="snippet"><span>GPT Summary</span>- ModernBERTã¯ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å°‚ç”¨ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã§ã€å¾“æ¥ã®BERTã«æ¯”ã¹ã¦å¤§å¹…ãªãƒ‘ãƒ¬ãƒ¼ãƒˆæ”¹å–„ã‚’å®Ÿç¾ã€‚2å…†ãƒˆãƒ¼ã‚¯ãƒ³ã§è¨“ç·´ã•ã‚Œã€8192ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã‚’æŒã¡ã€åˆ†é¡ã‚¿ã‚¹ã‚¯ã‚„ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ã§æœ€å…ˆç«¯ã®çµæœã‚’ç¤ºã™ã€‚é€Ÿåº¦ã¨ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚‚å„ªã‚Œã¦ãŠã‚Šã€ä¸€èˆ¬çš„ãªGPUã§ã®æ¨è«–ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æœ€è¿‘ã®é€²åŒ–ã—ã¾ãã£ãŸTransformeré–¢é€£ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’Encodnr-Onlyãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹BERTã«å–ã‚Šè¾¼ã‚“ã ã‚‰æ€§èƒ½ä¸ŠãŒã‚‹ã—ã€BERTã®æ–¹ãŒã‚³ã‚¹ãƒ‘ãŒè‰¯ã„ã‚¿ã‚¹ã‚¯ã¯ãŸãã•ã‚“ã‚ã‚‹ã‚ˆã€ç³»ã®è©±ã€ã‹ã¤ãã®å®Ÿè£…ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼ä¸­ã«è¨˜è¼‰ã¯ãªã„ãŒã€è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã¨åŒã˜ã‚¿ã‚¹ã‚¯ã§ã®Decoder-Onlyãƒ¢ãƒ‡ãƒ«ï¼ˆSFTæœ‰ã‚Šç„¡ã—ä¸¡æ–¹ï¼‰ã¨ã®æ€§èƒ½ã‚’æ¯”è¼ƒã—ãŸã‚‰ã©ã®ç¨‹åº¦ã®æ€§èƒ½ãªã®ã ã‚ã†ã‹ï¼Ÿ</p>
<p>ãã‚‚ãã‚‚å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒæ‰‹å…ƒã«ã‚ã£ã¦ã€BERTã‚’Finetuningã™ã‚‹ã ã‘ã§ååˆ†ãªæ€§èƒ½ãŒå‡ºã‚‹ã®ãªã‚‰ï¼ˆBERTã¯GPUä½¿ã†ã®ã§ãã‚‚ãã‚‚xgboostã¨ã‹ã§ã‚‚è‰¯ã„ãŒï¼‰ã€ã‚ã–ã‚ã–LLMä½¿ã†å¿…è¦ãªã„ã¨æ€ã‚ã‚Œã‚‹ã€‚BERTã®Finetuningã¯ãã“ã¾ã§æ™‚é–“ã¯ã‹ã‹ã‚‰ãªã„ã—ã€inferenceã‚‚é€Ÿã„ã€‚<br><br>å‚è€ƒ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1024" target="_blank" rel="noopener noreferrer">Prompt2Model: Generating Deployable Models from Natural Language   Instructions, Vijay Viswanathan+, N/A, EMNLP'23</a>
</p>
<p>æ—¥æœ¬èªè§£èª¬:


<a href="https://zenn.dev/dev_commune/articles/3f5ab431abdea1?utm_source=substack&utm_medium=email" target="_blank" rel="noopener noreferrer">https://zenn.dev/dev_commune/articles/3f5ab431abdea1?utm_source=substack&utm_medium=email</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2024-12-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1603" target="_blank" rel="noopener noreferrer" class="title-link">ã€NLPã‚³ãƒ­ã‚­ã‚¦ãƒ ã€‘Stepwise Alignment for Constrained Language Model Policy Optimization ï¼ˆNeurIPS 2024ï¼‰  , 2024.12</a>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1602" target="_blank" rel="noopener noreferrer">RLHF/DPO å°è©±, å’Œåœ°ç­è‰¯/ Akifumi Wachi, 2024.04</a>
<br><br>ã‚‚å‚ç…§ã®ã“ã¨ã€‚</p>
<p>RLHF, DPOãŒè§£ã„ã¦ã„ã‚‹å•é¡ŒãŒåŒã˜ã§ã€å•é¡ŒãŒåŒã˜ãªã®ã§ãã‚Œãã‚Œã®æœ€é©è§£ã‚‚ä¸€ç·’ã§ã‚ã‚Šè§£ãæ–¹ãŒé•ã†ã ã‘ã€ã§ã‚‚DPOã®æ–¹ãŒé ‘å¼µã£ã¦å¼·åŒ–å­¦ç¿’ã™ã‚‹RLHFã‚ˆã‚Šã‚‚ç°¡å˜ã«è§£ã‘ã‚‹ã—ã€å­¦ç¿’ã‚‚å®‰å®šã—ã¦ã‚‹ã‚ˆã€ã¨ã„ã†è©±ãŒã€binary feedbackãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆæ‰‹æ³•ã§ã‚ã‚‹KTOã‚‚äº¤ãˆã¦æ›¸ã„ã¦ã‚ã‚‹ã€‚</p>
<p>ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã®å­¦ç¿’ã§ã¯å˜ä¸€ã®ã‚¹ã‚«ãƒ©ãƒ¼å€¤ã«ã‚ˆã£ã¦å ±é…¬ãŒæ±ºã¾ã£ã¦ã„ã‚‹ãŒã€ç”Ÿæˆçµæœã«ã¯è‰²ã€…ãªå´é¢ãŒã‚ã‚‹ã‹ã‚‰å˜ä¸€ã‚¹ã‚«ãƒ©ãƒ¼ã§ã¯æœ¬æ¥è©•ä¾¡ã§ããªã„ã‚ˆã­ã¨ã„ã†è©±ãŒå‡ºã¦ããŸä¸Šã§ã€safetyã«å¯¾ã—ã¦ã‚‚è€ƒæ…®ã—ã¦å ±é…¬ã‚’æ±ºã‚ãŸã„ã€ã¨ã„ã†æ™‚ã«ã‚¹ã‚«ãƒ©ãƒ¼å€¤ã®ã¾ã¾ã ã‘ã©æœ€é©åŒ–å•é¡Œã®åˆ¶ç´„æ¡ä»¶ã«safetyã«é–¢ã™ã‚‹åˆ¶ç´„ã‚’å…¥ã‚Œã‚‹ã€ã“ã¨ã§å ±é…¬ã«åæ˜ ã•ã›ã¾ã™ã€ã¿ãŸã„ãªè©±ãŒæ›¸ã„ã¦ã‚ã‚‹ã€‚<br>ãã—ã¦ææ¡ˆæ‰‹æ³•ã®ä¸»è¦ãªè²¢çŒ®ã¯ã€ãã†ã„ã†ã“ã¨ã‚’ã‚„ã‚‹ã¨ã‚ã¡ã‚ƒã‚ã¡ã‚ƒæ‰‹æ³•ãŒè¤‡é›‘åŒ–ã™ã‚‹ã‚“ã ã‘ã‚Œã©ã‚‚ã€ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ã«ã—ã¦ã€ã‹ã¤ç†è«–çš„ã«ã‚‚æ­£å½“åŒ–ã•ã‚Œã¦ã„ã‚‹ã—ã€å®Ÿé¨“çš„ã«ã‚‚ã†ã¾ãå‹•ãã¾ã™ã€ã¨ã„ã†è©±ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<span class="issue_date">Issue Date: 2024-12-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1602" target="_blank" rel="noopener noreferrer" class="title-link">RLHF_DPO å°è©±, å’Œåœ°ç­è‰¯_ Akifumi Wachi, 2024.04</a>
<span class="snippet"><span>Comment</span><p>ã‚ã¡ã‚ƒã‚ã¡ã‚ƒå‹‰å¼·ã«ãªã‚‹â€¦</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<span class="issue_date">Issue Date: 2024-12-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1591" target="_blank" rel="noopener noreferrer" class="title-link">å›½éš›ä¼šè­°ACL2024å‚åŠ å ±å‘Š, Masato Mita, Cyber Agent, 2024.12</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SpokenLanguageProcessing.html" target="_blank" rel="noopener noreferrer">#SpokenLanguageProcessing</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2024-12-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1588" target="_blank" rel="noopener noreferrer" class="title-link">LLaMA-Omni: Seamless Speech Interaction with Large Language Models, Meta, 2024.09</a>
<span class="snippet"><span>Comment</span><p>éŸ³å£°ã¨ãƒ†ã‚­ã‚¹ãƒˆã®OpenSourceãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€‚inputã¯éŸ³å£°ã®ã¿ï¼Ÿã«è¦‹ãˆã‚‹ãŒã€å‡ºåŠ›ã¯ãƒ†ã‚­ã‚¹ãƒˆã¨éŸ³å£°ã®ä¸¡æ–¹ã‚’å®Ÿæ–½ã§ãã‚‹ã€‚GPT-4oãƒ¬ãƒ™ãƒ«ã®speech capabilityã‚’ç›®æŒ‡ã™ã¨aboutã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚èˆˆå‘³æ·±ã„ã€‚<br><br><br><br>installã®èª¬æ˜ã« `Whisper-large-v3` ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹æ—¨ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€Whisper-large-v3ã§èªè­˜ã—ãŸå†…å®¹ã«ç‰¹åŒ–ã—ãŸSpeech Encoder/AdapterãŒå­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><br>&lt;img width="702" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/cea090e7-a42a-476d-85f6-50199d9ae180"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/cea090e7-a42a-476d-85f6-50199d9ae180"&lt;/a&gt;


/&gt;<br><br></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1225" target="_blank" rel="noopener noreferrer">MM-LLMs: Recent Advances in MultiModal Large Language Models, Duzhen Zhang+, N/A, ACL'24 Findings</a>
 <br><br><br><br>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªLLMã®åŸºæœ¬çš„ãªæ¦‚å¿µã«ã¤ã„ã¦ã¯ä¸Šè¨˜å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<span class="issue_date">Issue Date: 2024-12-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1582" target="_blank" rel="noopener noreferrer" class="title-link">Sarashina-Embedding-v1-1B, SB Iumuitions, 2024.12</a>
<span class="snippet"><span>Comment</span><p>Non-commercialãªãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã€å•†ç”¨åˆ©ç”¨ã®å ´åˆã¯å•ã„åˆã‚ã›ãŒå¿…è¦</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2024-12-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1576" target="_blank" rel="noopener noreferrer" class="title-link">OpenAI o1 System Card, OpenAI, 2024.12</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-12-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1574" target="_blank" rel="noopener noreferrer" class="title-link">Llama3.3-70B, Meta, 2024.12</a>
<span class="snippet"><span>Comment</span><p>3.1-70Bã‚ˆã‚Šã‚‚æ€§èƒ½å‘ä¸Šã—ã€3.1-405Bã®æ€§èƒ½ã«ã‚ˆã‚Šè¿‘ãã€‚<br><br>ï¼ˆç”»åƒã¯å…ƒãƒã‚¹ãƒˆã‚ˆã‚Šå¼•ç”¨ï¼‰<br><img src="https://github.com/user-attachments/assets/07fb3043-131a-4564-be70-d34b70c31cca" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<span class="issue_date">Issue Date: 2024-12-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1571" target="_blank" rel="noopener noreferrer" class="title-link">Introducing Amazon Nova, our new generation of foundation models, AWS, 2024.12</a>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ:


<a href="https://qiita.com/ysit/items/8433d149dbaab702d526" target="_blank" rel="noopener noreferrer">https://qiita.com/ysit/items/8433d149dbaab702d526</a>


</p>
<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ: 


<a href="https://assets.amazon.science/9f/a3/ae41627f4ab2bde091f1ebc6b830/the-amazon-nova-family-of-models-technical-report-and-model-card.pdf" target="_blank" rel="noopener noreferrer">https://assets.amazon.science/9f/a3/ae41627f4ab2bde091f1ebc6b830/the-amazon-nova-family-of-models-technical-report-and-model-card.pdf</a>


</p>
<p>å¾Œã§å€‹ã€…ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ã¾ã¨ã‚ãŸã„ã€‚<br><br>ã¾ã‚ã§ã‚‚ã–ã£ãã‚Šè¨€ã†ã¨ã€ä»–ã®proprietaryãƒ¢ãƒ‡ãƒ«ã¨ã‚‚ãŠãŠã‚€ã­åŒç­‰ã®æ€§èƒ½ã§ã™ã€ã¨ã„ã†æ„Ÿã˜ã«è¦‹ãˆã‚‹ã€‚å€‹ã€…ã®ã‚¿ã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã§è¦‹ã‚‹ã¨ã€å¾—æ„ãªã‚‚ã®ã¨ä¸å¾—æ„ãªã‚‚ã®ã¯ã‚ã‚Šãã†ã§ã¯ã‚ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/c0c633d8-c64d-4a14-95cf-0d8b0d52a7f6" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/560f8c3e-65ff-4742-b7da-bc2b242dafcd" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/481a9635-128d-4931-a891-5f46d55b82bc" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/fc9b1bc0-b857-4a27-ad90-4940213c6ec6" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/a349b154-1844-41c2-84e3-7f981b1f6b72" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/a4381740-600c-402f-be0d-59ce60b7a562" alt="image" loading="lazy"><br><br>ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¨ã‹ã‚‚ã€Proã¨GPT4oã‚’ãƒ‘ãƒƒã¨è¦‹ã§æ¯”è¼ƒã—ãŸæ„Ÿã˜ã€å„ªã‚Œã¦ã„ã‚‹ã‚ã‘ã§ã‚‚ãªã•ãã†ã€‚Liteã«å¯¾å¿œã™ã‚‹GPTã¯ãŠãã‚‰ãGPT4o-miniã ã¨æ€ã‚ã‚Œã‚‹ãŒã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¯Liteã®æ–¹ãŒé«˜ãã†ã€‚<br><img src="https://github.com/user-attachments/assets/734ee26f-2f16-46e4-a6e8-f5f2f0d65be3" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/fe1768e8-b417-4b89-a0c4-f6dffa99cf11" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/6334ee92-e426-49f5-8e1f-050e0b77fcf2" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/5c9ec797-ef7a-43e1-8540-42ccab265208" alt="image" loading="lazy"><br><br>ï¼ˆç”»åƒã¯è«–æ–‡ä¸­ã‹ã‚‰ã‚¹ã‚¯ã‚·ãƒ§ã—å¼•ç”¨ï¼‰</p>
<p>ä¸‹è¨˜ãƒã‚¹ãƒˆã¯ç‹¬è‡ªã«è©•ä¾¡ã—ãŸçµæœã‚„ã€ã‚³ã‚¹ãƒˆã¨æ€§èƒ½ã®ãƒãƒ©ãƒ³ã‚¹ã«ã¤ã„ã¦è¨€åŠã—ã¦ã„ã‚‹ã€‚<br><br>- Proã¯GPT4oã®ã‚³ã‚¹ãƒˆã®ç´„1/3<br>- Pro, Lite, Flashã¯ã»ã‚Œãã‚Œã‚³ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«éå¸¸ã«å„ªã‚Œã¦ã„ã‚‹ï¼ˆQuality vs. Priceå‚ç…§ï¼‰<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1864023052818030814?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2024-12-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1563" target="_blank" rel="noopener noreferrer" class="title-link">æ—¥æœ¬èªLLMã¾ã¨ã‚, LLM-jp, 2024.12</a>
<span class="snippet"><span>Comment</span><p>LLM-jpã«ã‚ˆã‚‹æ—¥æœ¬èªLLMï¼ˆEncoder-Decoderç³», BERTç³», Bi-Encoders, Cross-Encodersã‚’å«ã‚€ï¼‰ã®ã¾ã¨ã‚ã€‚<br>ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ä½¿ã†ãƒ¢ãƒ‡ãƒ«ã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã«ä½¿ã†ãƒ¢ãƒ‡ãƒ«ã€Embeddingä½œæˆã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã€è¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ«ã€éŸ³å£°è¨€èªãƒ¢ãƒ‡ãƒ«ã€æ—¥æœ¬èªLLMè©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯/ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒã€æ±ç”¨ã¨ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹ã«åˆ†ã‘ã¦ã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚<br>å„ãƒ¢ãƒ‡ãƒ«ã‚„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®åŸè«–æ–‡ã€å­¦ç¿’æ‰‹æ³•ã®åŸè«–æ–‡ã‚‚ã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ã™ã”ã„é‡ã â€¦ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<span class="issue_date">Issue Date: 2024-11-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1558" target="_blank" rel="noopener noreferrer" class="title-link">LLM Self-Correction Papers, Ryo Kamoi, 2024.11</a>
<span class="snippet"><span>Comment</span><p>self-correctionã®å°‚é–€å®¶ã«ã‚ˆã‚‹self-correctioné–¢é€£ã®è«–æ–‡ã®ãƒªãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒªã‚¹ãƒˆã€‚ãœã²ãƒã‚§ãƒƒã‚¯ã—ãŸã„ã€‚<br><br>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ryokamoi_ja/status/1862635105010799054?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/AES(AutomatedEssayScoring).html" target="_blank" rel="noopener noreferrer">#AES(AutomatedEssayScoring)</a>
<span class="issue_date">Issue Date: 2024-11-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1555" target="_blank" rel="noopener noreferrer" class="title-link">Cross-prompt Pre-finetuning of Language Models for Short Answer Scoring, Funayama+, 2024.09</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå‹•çŸ­ç­”ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆSASï¼‰ã§ã¯ã€ç•°ãªã‚‹ãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã¨å‚ç…§å›ç­”ã«åŸºã¥ã„ã¦ã‚¹ã‚³ã‚¢ã‚’ä»˜ã‘ã‚‹ãŒã€æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã”ã¨ã«ãƒ¢ãƒ‡ãƒ«ã‚’å†è¨“ç·´ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ—¢å­˜ã®ãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã¨å›ç­”ã‚’ç”¨ã„ã¦æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹äºŒæ®µéšã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚é‡è¦ãªãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€ç‰¹ã«è¨“ç·´ãƒ‡ãƒ¼ã‚¿ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã«ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’å®Ÿé¨“ã§ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>SASã§ã¯å›ç­”ãƒ‡ãƒ¼ã‚¿ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹ã®ã§ã€é™ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚ˆã‚ŠåŠ¹æœçš„ã«å­¦ç¿’ã‚’ã™ã‚‹ãŸã‚ã«ã€äº‹å‰ã«ä»–ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’pre-finetuningã—ã¦ãŠãã€å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒæ¥ãŸã‚‰pre-finetuningã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ã•ã‚‰ã«finetuningã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ã“ã“ã§ã€promptä¸­ã«keyphraseã‚’å«ã‚ã‚‹ã“ã¨ãŒæœ‰ç”¨ã§ã‚ã‚‹ã¨è€ƒãˆã€å®Ÿé¨“çš„ã«æœ‰åŠ¹æ€§ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/9ab4eb22-b72e-4573-8fbb-1c376047c2b0" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/b671a564-c5a8-4344-aaec-06875f654f8b" alt="image" loading="lazy"><br><br><br><br>BERTã§finetuningã‚’ã—ãŸå ´åˆã¯ã€key-phraseã‚’å«ã‚ãŸæ–¹ãŒæ€§èƒ½ãŒé«˜ãã€ç‰¹ã«finetuningã®ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°ã•ã„å ´åˆã«ãã®å·®ãŒé¡•è‘—ã§ã‚ã£ãŸã€‚<br><br><img src="https://github.com/user-attachments/assets/cdced65b-060b-43ae-a2b4-fcfc5750a6ed" alt="image" loading="lazy"><br><br><br><br>æ¬¡ã«ã€LLMï¼ˆswallow-8B, 70Bï¼‰ã‚’pre-finetuningã—ã€pre-finetuningã‚’å®Ÿæ–½ã—ãªã„å ´åˆã¨æ¯”è¼ƒã™ã‚‹ã“ã¨ã§ã€pre-finetuningãŒLLMã®zero-shotã€ãŠã‚ˆã³ICLèƒ½åŠ›ã«ã©ã®ç¨‹åº¦å½±éŸ¿ã‚’ä¸ãˆã‚‹ã‹ã‚’æ¤œè¨¼ã—ãŸã€‚æ¤œè¨¼ã®çµæœã€pre-finetuningãªã—ã§ã¯ã€ãã‚‚ãã‚‚10-shotã«ã—ã¦ã‚‚QWKãŒéå¸¸ã«ä½ã‹ã£ãŸã®ã«å¯¾ã—ã€pre-finetuningã«ã‚ˆã£ã¦zero-shotã®èƒ½åŠ›ãŒå¤§å¹…ã«æ€§èƒ½ãŒå‘ä¸Šã—ãŸã€‚ä¸€æ–¹ã€few-shotã«ã¤ã„ã¦ã¯3-shotã§æ€§èƒ½ãŒé ­æ‰“ã¡ã«ãªã£ã¦ã„ã‚‹ã‚ˆã†ã«ã¿ãˆã‚‹ã€‚ã“ã“ã§ã€Table1ã®LLMã§ã¯ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã™ã‚‹å•é¡Œã®promptã§ã¯ä¸€åˆ‡finetuningã•ã‚Œã¦ã„ãªã„ã“ã¨ã«æ³¨æ„ã™ã‚‹ï¼ˆUnseenãªå•é¡Œï¼‰ã€‚<br><br>&lt;img width="639" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/7c9f141d-dc55-4388-8dc4-6a56f81d6cad"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/7c9f141d-dc55-4388-8dc4-6a56f81d6cad"&lt;/a&gt;


&gt;<br><br><br><br>ç¶šã„ã¦ã€LLMã‚’finetuningã—ãŸå ´åˆã‚‚æ¤œè¨¼ã€‚ææ¡ˆæ‰‹æ³•ãŒé«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã€200ã‚µãƒ³ãƒ—ãƒ«ç¨‹åº¦ã‚ã‚‹å ´åˆã«Human Scoreã‚’ä¸Šå›ã£ã¦ã„ã‚‹ï¼ˆã—ã‹ã‚‚BERTã¯200ã‚µãƒ³ãƒ—ãƒ«ã§ã‚µãƒã£ãŸãŒã€LLMã¯ã¾ã ã‚µãƒã£ã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ï¼‰ã€‚ã¾ãŸã€ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒã‚ˆã‚Šå°ã•ã„å ´åˆã«ã€ææ¡ˆæ‰‹æ³•ãŒã‚ˆã‚Šé«˜ã„gainã‚’å¾—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br>&lt;img width="775" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/898b2bea-e9df-4c5c-b172-0507a3a83c3c"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/898b2bea-e9df-4c5c-b172-0507a3a83c3c"&lt;/a&gt;


&gt;<br><br><br><br>ã¾ãŸã€å€‹ã€…ã®å•é¡Œã”ã¨ã«LLMã‚’finetuningã™ã‚‹ã®ã¯ç¾å®Ÿçš„ã«å›°é›£ãªã®ã§ã€å€‹ã€…ã®å•é¡Œã”ã¨ã«finetuningã—ãŸå ´åˆã¨ã€å…¨ã¦ã®å•é¡Œã‚’ã¾ã¨ã‚ã¦finetuningã—ãŸå ´åˆã®æ€§èƒ½å·®ã‚’æ¯”è¼ƒã—ãŸã¨ã“ã‚ã€ã¾ã¨ã‚ã¦å­¦ç¿’ã—ã¦ã‚‚æ€§èƒ½ã¯ä½ä¸‹ã—ãªã„ã€ã©ã“ã‚ã‹21å•ä¸­18å•ã§æ€§èƒ½ãŒå‘ä¸Šã—ãŸï¼ˆLLMã®ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å­¦ç¿’ã®èƒ½åŠ›ã®ãŠã‹ã’ï¼‰ã€‚<br><br>&lt;img width="762" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/a8ec62fb-2984-4e7c-8eeb-1b3b6333e9ac"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a8ec62fb-2984-4e7c-8eeb-1b3b6333e9ac"&lt;/a&gt;


&gt;<br><br></p>
<p>[Perplexity(hallucinationã«æ³¨æ„)](


<a href="https://www.perplexity.ai/search/tian-fu-sitalun-wen-wodu-mi-ne-3_TrRyxTQJ.2Bm2fJLqvTQ#0)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/search/tian-fu-sitalun-wen-wodu-mi-ne-3_TrRyxTQJ.2Bm2fJLqvTQ#0)</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/AES(AutomatedEssayScoring).html" target="_blank" rel="noopener noreferrer">#AES(AutomatedEssayScoring)</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-11-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1554" target="_blank" rel="noopener noreferrer" class="title-link">å›½èªè¨˜è¿°å•é¡Œè‡ªå‹•æ¡ç‚¹ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã¨è©•ä¾¡, Yutaka Ishii+, æ—¥æœ¬æ•™è‚²å·¥å­¦ä¼š, 2024.05</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/API.html" target="_blank" rel="noopener noreferrer">#API</a>
<span class="issue_date">Issue Date: 2024-11-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1553" target="_blank" rel="noopener noreferrer" class="title-link">aisuite, andrewyng, 2024.11</a>
<span class="snippet"><span>Comment</span><p>è¤‡æ•°ã®LLM Providerã®å‘¼ã³å‡ºã—ã‚’å…±é€šã®ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ã§å‘¼ã³å‡ºã›ã‚‹ã€‚å¤‰æ›´ã™ã‚‹ã®ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã€‚<br><br>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/andrewyng_announcing-new-open-source-python-package-activity-7266851242604134400-Davp?utm_source=share&utm_medium=member_ios" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/andrewyng_announcing-new-open-source-python-package-activity-7266851242604134400-Davp?utm_source=share&utm_medium=member_ios</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<span class="issue_date">Issue Date: 2024-11-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1551" target="_blank" rel="noopener noreferrer" class="title-link">ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ï¼šMamba, Vision Mamba ï¼ˆVimï¼‰, Hironobu Fujiyoshi, 2024.11</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-11-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1545" target="_blank" rel="noopener noreferrer" class="title-link">Sarashina2-8x70Bã®å…¬é–‹, SB Intuitions, 2024.11</a>
<span class="snippet"><span>Comment</span><p>MoE Layerã®èª¬æ˜ã€Sparse Upcyclingã®èª¬æ˜ã€MoEãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹éš›ã«ã€å­¦ç¿’æ™‚ã®å­¦ç¿’ç‡ã®è¨­å®šãŒå¤§ãã™ãã‚‹ã¨åˆæœŸã«æå¤±ãŒå¢—å¤§ã—ã€å°ã•ã™ãã‚‹ã¨æå¤±ã®å¢—å¤§ã¯é˜²ã’ã‚‹ãŒlong runã§å­¦ç¿’ã—ãŸéš›ã®æ€§èƒ½å‘ä¸ŠãŒå°ã•ã‹ã£ãŸã“ã¨ã€å…ƒã®ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¯€æã—ãªã„ã‚ˆã†ã«ã€Upcyclingã‚’ã—ãŸå…ƒãƒ¢ãƒ‡ãƒ«ã®æœ€çµ‚çš„ãªå­¦ç¿’ç‡ã‚’è¸è¥²ã—ã¦å­¦ç¿’ã‚’ã—ã€å­¦ç¿’ç‡ã‚’ã•ã‚‰ã«æ¸›è¡°ã•ã›ã¦ã„ã£ãŸã“ã¨ã€ãªã©ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>ã¾ãŸã€æ€§èƒ½è©•ä¾¡ã¨ã—ã¦åŒç­‰ã®activation parameteræ•°ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã¨æ—¥æœ¬èªã®QAã‚¿ã‚¹ã‚¯ã§æ¯”è¼ƒã—ãŸçµæœã‚‚è¼‰ã£ã¦ã„ã‚‹ã€‚<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1546" target="_blank" rel="noopener noreferrer">Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints, Aran Komatsuzaki+, ICLR'23</a>
</p>
<p>MoE Layerã«ã¤ã„ã¦ã¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1204" target="_blank" rel="noopener noreferrer">Mixtral of Experts, Albert Q. Jiang+, N/A, arXiv'24</a>
<br><br>ã‚‚å‚ç…§ã®ã“ã¨</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-11-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1538" target="_blank" rel="noopener noreferrer" class="title-link">SmolLM2, 2024.11</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1859598525723488478?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Orca-AgenInstruct-1M <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1521" target="_blank" rel="noopener noreferrer">microsoft/orca-agentinstruct-1M-v1, Microsoft, 2024.11</a>
 ã‚ˆã‚Šã‚‚SmolLMã®SFTã§å„ç¨®ãƒ™ãƒ³ãƒã§é«˜ã„æ€§èƒ½ã‚’ç²å¾—<br><img src="https://github.com/user-attachments/assets/ed39fa8e-eeac-493f-a220-30313be5b761" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Word.html" target="_blank" rel="noopener noreferrer">#Word</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/STS%20(SemanticTextualSimilarity).html" target="_blank" rel="noopener noreferrer">#STS (SemanticTextualSimilarity)</a>
<span class="issue_date">Issue Date: 2024-11-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1536" target="_blank" rel="noopener noreferrer" class="title-link">Zipf ç™½è‰²åŒ–ï¼šã‚¿ã‚¤ãƒ—ã¨ãƒˆãƒ¼ã‚¯ãƒ³ã®åŒºåˆ¥ãŒã‚‚ãŸã‚‰ã™è‰¯è³ªãªåŸ‹ã‚è¾¼ã¿ç©ºé–“ã¨æå¤±é–¢æ•°, Sho Yokoi, 2024.11</a>
<span class="snippet"><span>GPT Summary</span>- å˜èªåŸ‹ã‚è¾¼ã¿ç©ºé–“ã®æ­ªã¿ã‚’ä¿®æ­£ã™ã‚‹ã“ã¨ã§ã‚¿ã‚¹ã‚¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚æ—¢å­˜ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯å˜èªé »åº¦ãŒå‡ä¸€ã§ã‚ã‚‹ã¨ä»®å®šã—ã¦ã„ã‚‹ãŒã€å®Ÿéš›ã«ã¯Zipfã®æ³•å‰‡ã«å¾“ã†éå‡ä¸€ãªåˆ†å¸ƒã§ã‚ã‚‹ã€‚Zipfã«åŸºã¥ãé »åº¦ã§é‡ã¿ä»˜ã‘ã•ã‚ŒãŸPCAãƒ›ãƒ¯ã‚¤ãƒˆãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã“ã¨ã§ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤§å¹…ã«å‘ä¸Šã—ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’è¶…ãˆã‚‹ã€‚æƒ…å ±å¹¾ä½•å­¦çš„ãªè¦³ç‚¹ã‹ã‚‰ã€ä½é »åº¦ã®å˜èªã‚’å¼·èª¿ã™ã‚‹ç†è«–ã‚’ææ¡ˆã—ã€äººæ°—ã®è‡ªç„¶è¨€èªå‡¦ç†æ‰‹æ³•ãŒã“ã®ç†è«–ã«åŸºã¥ã„ã¦æ©Ÿèƒ½ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒè«–æ–‡: [Yokoi, Bao, Kurita, Shimodaira, â€œZipfian Whitening,â€ NeurIPS 2024. ](


<a href="https://arxiv.org/abs/2411.00680)" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2411.00680)</a>


</p>
<p>å˜èªãƒ™ã‚¯ãƒˆãƒ«ã‚’æ´»ç”¨ã—ã¦æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã™ã‚‹éš›ã«ä¸€èˆ¬çš„ãªå…¨éƒ¨è¶³ã—ã¦å€‹æ•°ã§å‰²ã‚‹ã‚ˆã†ãªå¹³å‡ãƒ™ã‚¯ãƒˆãƒ«è¨ˆç®—ã¯ã€<br>å€‹ã€…ã®å˜èªé »åº¦ã‚’ä¸€æ§˜ã¨ä»®å®šã—ãŸå ´åˆã®"æœŸå¾…å€¤"ã¨ç­‰ä¾¡ã§ã‚ã‚Šã€<br>ã“ã‚Œã¯ç¾å®Ÿä¸–ç•Œã®å˜èªé »åº¦ã®å®Ÿæ…‹ã¨ã¯å…¨ç„¶ç•°ãªã‚‹ã‹ã‚‰ã€ãã¡ã‚“ã¨è€ƒæ…®ã—ãŸã„ã‚ˆã­ã€ã¨ã„ã†è©±ã§<br><img src="https://github.com/user-attachments/assets/cc38dbd5-8b6e-45e6-8a81-00f524eb36f8" alt="image" loading="lazy"><br>é »åº¦ã‚’è€ƒæ…®ã™ã‚‹ã¨Semantic Textual Similarityï¼ˆSTSï¼‰ã‚¿ã‚¹ã‚¯ã§åŠ¹æœçµ¶å¤§ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚<br><img src="https://github.com/user-attachments/assets/2042d75f-6325-4e50-9423-f8621084fb75" alt="image" loading="lazy"><br><br>ã§ã¯ã€ãªãœã“ã‚Œã¾ã§ä¸€æ§˜åˆ†å¸ƒæ‰±ã„ã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã ã£ãŸã®ã‹ã¨ã„ã†ã¨ã€<br>å®Ÿæ…‹ã¨ã—ã¦å˜èªåŸ‹ã‚è¾¼ã¿è¡Œåˆ—ãŒå˜èªã‚’ã‚¿ã‚¤ãƒ—ã¨ã¿ãªã—ã¦æ§‹ç¯‰ã•ã‚ŒãŸã‚‚ã®ã§ã‚ã‚Šã€<br>ã‚³ãƒ¼ãƒ‘ã‚¹å…¨ä½“ã‚’æ‰ãˆãŸï¼ˆè¨€èªåˆ©ç”¨ã®å®Ÿæ…‹ã‚’æ‰ãˆãŸï¼‰ãƒ‡ãƒ¼ã‚¿è¡Œåˆ—ï¼ˆå˜èªã‚’ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã¿ãªã—ãŸã‚‚ã®ï¼‰ã«ãªã£ã¦ã„ãªã‹ã£ãŸã“ã¨ã«èµ·å› ã—ã¦ã„ãŸã‹ã‚‰ã§ã™ï¼ˆã ã‹ã‚‰ã€çµŒé¨“é »åº¦ã‚’ç”¨ã„ã¦é »åº¦æƒ…å ±ã‚’å¾©å…ƒã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‚ˆã­ï¼‰ã€<br>ã¨ã„ã†æ„Ÿã˜ã®è©±ã ã¨æ€ã‚ã‚Œã€<br><img src="https://github.com/user-attachments/assets/ba97319c-83f7-4443-a8e3-fa36030d704b" alt="image" loading="lazy"><br><br>çµŒé¨“é »åº¦ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€ãã‚‚ãã‚‚èƒŒå¾Œã«ä»®å®šã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«è‡ªä½“ãŒæš—é»™çš„ã«å¤‰ã‚ã‚Šã€<br>ä½é »åº¦èªãŒå¼·èª¿ã•ã‚Œã‚‹ã“ã¨ã§ã€å˜èªã«å¯¾ã—ã¦TF-IDFã®ã‚ˆã†ãªé‡ã¿ã¥ã‘ãŒã•ã‚Œã‚‹ã“ã¨ã§æ€§èƒ½ãŒè‰¯ããªã‚‹ã‚ˆã­ã€ã¿ãŸã„ãªè©±ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/7495f250-d680-4698-99c5-a326ead77e12" alt="image" loading="lazy"></p>
<p>ä½™è«‡ã ãŒã€æ˜”ã®NLPã§ã¯ã€P(w,c)ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ãŸã‚‚ã®ã‚’ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã§ä¸€èˆ¬çš„ãªP(w|c)ã¯åˆ†é¡ãƒ¢ãƒ‡ãƒ«ï¼ˆVAEã¨ã‹ã¯ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’ã™ã‚‹ãŒã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ãªã®ã§åˆ¥ï¼‰ã€ã¨å‘¼ã‚“ã§ã„ãŸã¨æ€ã†ãŒã€ã„ã¾ã¯ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®ã“ã¨ã‚’ç•¥ã—ã¦ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€ã¨å‘¼ç§°ã™ã‚‹ã®ãŒä¸€èˆ¬çš„ãªã®ã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<span class="issue_date">Issue Date: 2024-11-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1535" target="_blank" rel="noopener noreferrer" class="title-link">Datasets: hpprc_honyaku, hpprc, 2024.11</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hpp_ricecake/status/1859118112672780401?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‹±èªWikipediaã‚’å†’é ­æ•°æ–‡ã‚’æŠ½å‡ºã—æ—¥æœ¬èªã«äººæ‰‹ã§ç¿»è¨³ï¼ˆApache2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã‚ã‚‹Calmã‚„Qwenã®å‡ºåŠ›ã‚’å‚è€ƒã«ã€cc-by-sa-4.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«ã¦å…¬é–‹ã—ã¦ã„ã‚‹ã€‚<br>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚¿ãƒ¼ãƒ ãŒæ—¥æœ¬èªã§å­˜åœ¨ã™ã‚‹å ´åˆã¯ç¿»è¨³çµæœã«å«ã¾ã‚Œã‚‹ã‚ˆã†ã«ã—ãŸã‚Šã€ç¿»è¨³ã•ã‚ŒãŸæ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆãŒå˜ä½“ã§æ„å‘³ãŒæˆã‚Šç«‹ã¤ã‚ˆã†ã«ç¿»è¨³ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã§ã€1ä»¶ã‚ãŸã‚Š15åˆ†ã‚‚ã®æ™‚é–“ã‚’ã‹ã‘ã¦ç¿»è¨³ã—ãŸã¨ã®ã“ã¨ã€‚ãƒ‡ãƒ¼ã‚¿é‡ã¯33ä»¶ã€‚many-shotã‚„few-shotã«åˆ©ç”¨ã§ããã†ã€‚<br><br>æ—¥è‹±å¯¾è¨³ã‚³ãƒ¼ãƒ‘ã‚¹ã¯ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãŒå³ã—ã„ã‚‚ã®ãŒå¤šã„ã¨ã®ã“ã¨ãªã®ã§ã€éå¸¸ã«æœ‰ç”¨ã ã¨æ€ã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2024-11-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1528" target="_blank" rel="noopener noreferrer" class="title-link">Large Vision Language Model ï¼ˆLVLMï¼‰ã«é–¢ã™ã‚‹çŸ¥è¦‹ã¾ã¨ã‚, Daiki Shiono, 2024.11</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2024-11-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1521" target="_blank" rel="noopener noreferrer" class="title-link">microsoft_orca-agentinstruct-1M-v1, Microsoft, 2024.11</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2024-11-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1519" target="_blank" rel="noopener noreferrer" class="title-link">ãƒ­ãƒ¼ã‚«ãƒ«LLMã®ãƒªãƒªãƒ¼ã‚¹å¹´è¡¨, npaka, éšæ™‚æ›´æ–°, 2024.11</a>
<span class="snippet"><span>Comment</span><p>ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’å«ã‚€OpenLLMã®ãƒªãƒªãƒ¼ã‚¹æ—¥ãŒå¹´è¡¨ã¨ã—ã¦ã¾ã¨ã¾ã£ã¦ãŠã‚Šã€éšæ™‚æ›´æ–°ã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ã€‚ã™ã”ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2024-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1514" target="_blank" rel="noopener noreferrer" class="title-link">LLM Prompt Tuning Playbook, 2024.11</a>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1462" target="_blank" rel="noopener noreferrer">Prompt-Engineering-Guide, DAIR.AI</a>
 ã‚‚å‚ç…§ã®ã“ã¨</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2024-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1508" target="_blank" rel="noopener noreferrer" class="title-link">Copilot Arena, CMU and UC Berkeley, 2024.11</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lmarena_ai/status/1856444009323082093?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/623" target="_blank" rel="noopener noreferrer">ChatBot Arena, lmsys org, 2023.05</a>
 ã‚‚å‚ç…§ã®ã“ã¨</p>
<p>Chatbot ArenaãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸã®ãŒ1å¹´åŠå‰ã§ã‚ã‚‹ã“ã¨ã‚’ãŠã‚‚ã„ãŠã“ã—ã€ã“ã®2å¹´ã§é£›èºçš„ã«LLMãŒã§ãã‚‹ã“ã¨ãŒå¢—ãˆãŸãªãã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°å¢—ãˆãŸãªãã€ã§ã‚‚çœãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æ€§èƒ½ã‚ã£ã¡ã‚ƒä¸ŠãŒã£ãŸãªãã€proprietary LLMã«OpenLLMãŒè¿½ã„ã¤ã„ã¦ããŸãªãã€ã¨ã—ã¿ã˜ã¿æ€ã†ãªã©ã—ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-11-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1494" target="_blank" rel="noopener noreferrer" class="title-link">sarashina2-8x70B, SBIntuitions, 2024.11</a>
<span class="snippet"><span>Comment</span><p>ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹:


<a href="https://www.sbintuitions.co.jp/news/press/20241108_01/" target="_blank" rel="noopener noreferrer">https://www.sbintuitions.co.jp/news/press/20241108_01/</a>


</p>
<p>- å•†ç”¨åˆ©ç”¨ä¸å¯ãªç‚¹ã«ã¯æ³¨æ„<br>- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯70Bãƒ¢ãƒ‡ãƒ«x8ã®Mixture of Expertsï¼ˆMoEï¼‰<br>- ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ã¨ã€inferenceã«ã¯BF16ã§ã€A100 80GB or H100ãŒ16åŸºå¿…è¦ã£ã½ã„</p>
<p>MoEã‚’åˆ©ç”¨ã—ãŸLLMã«ã¤ã„ã¦ã¯ã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1204" target="_blank" rel="noopener noreferrer">Mixtral of Experts, Albert Q. Jiang+, N/A, arXiv'24</a>
 ã‚’å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-11-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1488" target="_blank" rel="noopener noreferrer" class="title-link">RAGã®æ”¹å–„æ–¹æ³•ã«é–¢ã™ã‚‹æƒ…å ±ã®ã¾ã¨ã‚ï¼ˆå†æ²ï¼‰, GENZITSU, 2023.10</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2024-11-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1487" target="_blank" rel="noopener noreferrer" class="title-link">ZeRO: DeepSpeedã®ç´¹ä»‹, ãƒ¬ãƒˆãƒªãƒ, 2021.07 </a>
<span class="snippet"><span>Comment</span><p>ZeROã®èª¬æ˜ãŒã‚ã‹ã‚Šã‚„ã™ã„</p>
<p>ã“ã¡ã‚‰ã®è¨˜äº‹ã‚‚ã‚ã‹ã‚Šã‚„ã™ã„<br><br>


<a href="https://zenn.dev/turing_motors/articles/d00c46a79dc976" target="_blank" rel="noopener noreferrer">https://zenn.dev/turing_motors/articles/d00c46a79dc976</a>


</p>
<p>DeepSpeedã®ã‚³ãƒ³ãƒ•ã‚£ã‚°ã®ä¸€è¦§<br><br>


<a href="https://www.deepspeed.ai/docs/config-json/" target="_blank" rel="noopener noreferrer">https://www.deepspeed.ai/docs/config-json/</a>


</p>
<p>transformersã«ãŠã‘ã‚‹deepspeedã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:<br>


<a href="https://huggingface.co/transformers/v4.9.2/main_classes/deepspeed.html" target="_blank" rel="noopener noreferrer">https://huggingface.co/transformers/v4.9.2/main_classes/deepspeed.html</a>


</p>
<p>å‚è€ƒ: deepspeedã®ä½¿ã„æ–¹ã¾ã¨ã‚<br>


<a href="https://note.com/fukudawataru/n/n5152e6f587c8" target="_blank" rel="noopener noreferrer">https://note.com/fukudawataru/n/n5152e6f587c8</a>


</p>
<p>ZeRO Stage3ã‚’ä½¿ã†å ´åˆã€ãƒšãƒ¼ã‚¸å¾Œæ–¹ã«ã—ã‚Œã£ã¨ã¨ã‚“ã§ã‚‚ãªãé‡è¦ãªã“ã¨ãŒæ›¸ã„ã¦ã‚ã‚‹ã®ã§æ°—ã‚’ã¤ã‘ã¾ã—ã‚‡ã†ã€‚ã€‚ã€‚ã€‚<br><br>


<a href="https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/deepspeed#constructing-massive-models" target="_blank" rel="noopener noreferrer">https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/deepspeed#constructing-massive-models</a>


<br><br><br><br><img src="https://github.com/user-attachments/assets/677b6656-1302-4b1b-8be6-ca954c7edda6" alt="image" loading="lazy"><br><br></p>
<p>ZeROã¯parameterã¨optimizerã®memory footprintã®æœ€é©åŒ–ã‚’é ‘å¼µã£ã¦ã„ã¦ã€activation memory footprintï¼ˆãƒãƒƒãƒã‚’forward passã«æµã™æ™‚ã«æ¶ˆè²»ã•ã‚Œã‚‹ãƒ¡ãƒ¢ãƒªï¼‰ã®å‰Šæ¸›ã¯ã€tiling, activation/gradient checkpointingã¨ã‹ã§é ‘å¼µã£ã¦ã­ã¨ã„ã†<br><br><br><br>ã¨ã„ã†è©±ãŒæœ¬å®¶issueã®4047ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚</p>
<p>çµè«–: ã¤ã¾ã¥ã„ãŸã‚‰DeepSpeedã®Issueã‚’ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§æ¤œç´¢ã‹ã‘ã‚‹ã®ãŒä¸€ç•ªåŠ¹æœçš„</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/AutomaticSpeechRecognition(ASR).html" target="_blank" rel="noopener noreferrer">#AutomaticSpeechRecognition(ASR)</a>
<span class="issue_date">Issue Date: 2024-11-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1485" target="_blank" rel="noopener noreferrer" class="title-link">ã»ã¼ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼ï¼Ÿçˆ†é€Ÿã§å‹•ä½œã™ã‚‹æ—¥æœ¬èªç‰¹åŒ–ã®æ–‡å­—èµ·ã“ã—AIï¼ã€kotoba-whisper-v2.0ã€, é¼ä»‹ å¤§å €, 2024.11</a>
<span class="snippet"><span>Comment</span><p>whisper large-v3ã‚’è’¸ç•™ã—ãŸkotoba-whisper-v1.0ã«å¯¾ã—ã¦ã€æ—¥æœ¬èªã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿ã§è¿½åŠ å­¦ç¿’ã‚’ã—ãŸãƒ¢ãƒ‡ãƒ«ã€kotoba-whisper-v2.0ã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã®ç’°å¢ƒæ§‹ç¯‰æ–¹æ³•ã‚„ã‚³ãƒ¼ãƒ‰ã®ä¾‹ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>å…¬å¼ã«ã‚ˆã‚‹ã¨ã€whisper-large-v3ã‚ˆã‚Šã‚‚6.3å€ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¨ã®ã“ã¨ã€‚ã¾ãŸã€qiitaè¨˜äº‹ä¸­ã§ã¯whisper large-v2ã«å¯¾ã—ã¦ç´„6.0å€ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã§ã‚ã‚‹ã“ã¨ãŒè¨€åŠã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>å­¦ç¿’ã«ç”¨ã„ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯ã€ReasonSpeechãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¥æœ¬èªã®ãƒ†ãƒ¬ãƒ“ã®éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ï¼‰ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1001" target="_blank" rel="noopener noreferrer">ReazonSpeech: A Free and Massive Corpus for Japanese ASR, Yin+, NLP'23</a>
 ã‚’WERã«åŸºã¥ããƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã£ã¦è‰¯è³ªãªãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æŠ½å‡ºã™ã‚‹ã“ã¨ã§ä½œæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®æ¨¡æ§˜<br><br>å…¬å¼ã®ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã‚‚å‚ç…§ã®ã“ã¨:


<a href="https://huggingface.co/kotoba-tech/kotoba-whisper-v2.0" target="_blank" rel="noopener noreferrer">https://huggingface.co/kotoba-tech/kotoba-whisper-v2.0</a>


</p>
<p>æ—¥æœ¬ã®ãƒ†ãƒ¬ãƒ“ç•ªçµ„ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ãã‚Œã‚’å¿µé ­ã«ç½®ã„ãŸä¸Šã§ã€è‡ªåˆ†ãŒé©ç”¨ã—ãŸã„ãƒ‡ãƒ¼ã‚¿ã¨ã®ç›¸æ€§ã‚’è€ƒãˆã‚‹ã¨è‰¯ã•ãã†ã§ã‚ã‚‹ã€‚<br><br>ã¾ãŸã€å‹•ä½œé€Ÿåº¦ãŒé€Ÿã„ã®ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«ã‚ã‚ŠãŒãŸã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/MinimalCode.html" target="_blank" rel="noopener noreferrer">#MinimalCode</a>
<span class="issue_date">Issue Date: 2024-11-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1479" target="_blank" rel="noopener noreferrer" class="title-link">Lingua, Meta</a>
<span class="snippet"><span>Comment</span><p>ç ”ç©¶ç›®çš„ã®ãŸã‚ã®ã€minimalã€ã‹ã¤é«˜é€ŸãªLLM training/inferenceã®ã‚³ãƒ¼ãƒ‰ãŒæ ¼ç´ã•ã‚ŒãŸãƒªãƒã‚¸ãƒˆãƒªã€‚ç‹¬è‡ªã®ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã€ãƒ­ã‚¹ãªã©ãŒç°¡å˜ã«å®Ÿè£…ã§ãã‚‹æ¨¡æ§˜ã€‚<br><br><img src="https://github.com/user-attachments/assets/47f70515-3de0-455f-9fc4-0e2e17442eed" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1471" target="_blank" rel="noopener noreferrer" class="title-link">Introducing quantized Llama models with increased speed and a reduced memory footprint, Meta, 2024.10</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-10-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1469" target="_blank" rel="noopener noreferrer" class="title-link">Aya Expanse, Cohere, 2024.10</a>
<span class="snippet"><span>Comment</span><p>Cohereã«ã‚ˆã‚‹ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«LLM, 8B, 32Bã®ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã€‚<br><br>8Bãƒ¢ãƒ‡ãƒ«ã®ArenaHardã§ã®è©•ä¾¡<br><img src="https://github.com/user-attachments/assets/c52678fd-b1a4-40ed-b6b9-7cc7d1096ff0" alt="image" loading="lazy"><br><br>32Bãƒ¢ãƒ‡ãƒ«ã®ArenaHardã§ã®è©•ä¾¡<br><img src="https://github.com/user-attachments/assets/fc8cc3d1-4ba3-4bdc-985f-1df4ccc2996c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1462" target="_blank" rel="noopener noreferrer" class="title-link">Prompt-Engineering-Guide, DAIR.AI</a>
<span class="snippet"><span>Comment</span><p>LLMã®settingã‹ã‚‰ã€few-shot, self-consistencyãªã©ã®promptingæŠ€è¡“ã€ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã®å®Ÿä¾‹ãªã©ãŒç¶²ç¾…çš„ã«ã¾ã¨ã¾ã£ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2024-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1457" target="_blank" rel="noopener noreferrer" class="title-link">MLE-Bench, OpenAI, 2024.10</a>
<span class="snippet"><span>GPT Summary</span>- MLE-benchã‚’ç´¹ä»‹ã—ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã€‚75ã®Kaggleã‚³ãƒ³ãƒšã‚’åŸºã«å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã€äººé–“ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ç¢ºç«‹ã€‚æœ€å‰ç·šã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ãŸçµæœã€OpenAIã®o1-previewãŒ16.9%ã®ã‚³ãƒ³ãƒšã§Kaggleã®ãƒ–ãƒ­ãƒ³ã‚ºãƒ¡ãƒ€ãƒ«ç›¸å½“ã®æˆæœã‚’é”æˆã€‚AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ç†è§£ã‚’ä¿ƒé€²ã™ã‚‹ãŸã‚ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚³ãƒ¼ãƒ‰ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã€‚</span>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2024-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1450" target="_blank" rel="noopener noreferrer" class="title-link">Unsloth</a>
<span class="snippet"><span>Comment</span><p>single-GPUã§ã€LLMã®LoRA/QLoRAã‚’é«˜é€Ÿ/çœãƒ¡ãƒ¢ãƒªã«å®Ÿè¡Œã§ãã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1443" target="_blank" rel="noopener noreferrer" class="title-link">Gemma-2-Baku, 2024.10</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1441" target="_blank" rel="noopener noreferrer" class="title-link">Gemma-2-JPN, 2024.10</a>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã§finetuningã•ã‚Œã¦Gemma2</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1431" target="_blank" rel="noopener noreferrer" class="title-link">Evaluating the Effectiveness of LLM-Evaluators ï¼ˆaka LLM-as-Judgeï¼‰, 2024.09</a>
<span class="snippet"><span>Comment</span><p>LLM-as-a-judgeã«ã¤ã„ã¦ç¶²ç¾…çš„ã«æ›¸ã‹ã‚ŒãŸè¨˜äº‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1430" target="_blank" rel="noopener noreferrer" class="title-link">RAGã®å®Ÿè£…æˆ¦ç•¥ã¾ã¨ã‚, Jin Watanabe, 2024.03</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2024-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1426" target="_blank" rel="noopener noreferrer" class="title-link">Molmo, AI2, 2024.09</a>
<span class="snippet"><span>GPT Summary</span>- Molmoã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ãŸæœ€å…ˆç«¯ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«AIãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ç‰¹ã«å°å‹ãƒ¢ãƒ‡ãƒ«ãŒå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚Molmoã¯ã€ç‰©ç†çš„ãŠã‚ˆã³ä»®æƒ³çš„ãªä¸–ç•Œã¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’å¯èƒ½ã«ã—ã€éŸ³å£°ãƒ™ãƒ¼ã‚¹ã®èª¬æ˜ã‚’ç”¨ã„ãŸæ–°ã—ã„ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å°å…¥ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã€éè¨€èªçš„æ‰‹ãŒã‹ã‚Šã‚’æ´»ç”¨ã—ã¦è³ªå•ã«ç­”ãˆã‚‹èƒ½åŠ›ã‚’æŒã¤ã€‚Molmoãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆã§ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªã‚·ã‚¹ãƒ†ãƒ ã«å¯¾æŠ—ã™ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã—ã€ä»Šå¾Œã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚¦ã‚§ã‚¤ãƒˆã‚„ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹ãŒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœï¼ˆVLMã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼‰ã€‚11 benchmarksã¨æ›¸ã‹ã‚Œã¦ã„ã‚‹ã®ã¯ã€VLMã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚‹ç‚¹ã«æ³¨æ„ã€‚<br><br><br><br>&lt;img width="981" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/510204e5-4cfb-4ba3-a6db-fff717a637bc"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/510204e5-4cfb-4ba3-a6db-fff717a637bc"&lt;/a&gt;


&gt;<br><br>&lt;img width="940" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/a4a77006-fcde-4c33-b6df-54dc5d8cbdfa"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a4a77006-fcde-4c33-b6df-54dc5d8cbdfa"&lt;/a&gt;


&gt;<br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1422" target="_blank" rel="noopener noreferrer" class="title-link">Llama 3.2: Revolutionizing edge AI and vision with open, customizable models, Meta, 2024.09</a>
<span class="snippet"><span>Comment</span><p>11Bã¨90Bã®VLMã¨ã€ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹å‘ã‘ã®1B, 3Bã®SLMã‚’ç™ºè¡¨ã€‚<br><img src="https://github.com/user-attachments/assets/13c4af37-19bd-4de7-b501-eb48f955af0c" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/d6b75b15-88cb-4d9e-9838-0da24308ccda" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/7475b30d-4619-4117-a911-d308291f86cb" alt="image" loading="lazy"></p>
<p>Llama3.2ã®VLMã§ã¯ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸimage encoderã‚’äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦çµ„ã¿åˆã‚ã›ã‚‹ãŸã‚ã®Adapterã‚’è¤‡æ•°å­¦ç¿’ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦å®Ÿç¾ã€‚<br><br>å…·ä½“çš„ã«ã¯ã€Llama 3.1ï¼ˆtext only modelï¼‰ã«å¯¾ã—ã¦ã€image encoderã¨Adapterã‚’è¿½åŠ ã—ã€å¤§è¦æ¨¡ã§ãƒã‚¤ã‚¸ãƒ¼ãªï¼ˆimage,textï¼‰ãƒšã‚¢ã§äº‹å‰å­¦ç¿’ã€‚ç¶šã„ã¦ã€ä¸­è¦æ¨¡ã®ã‚µã‚¤ã‚ºã®é«˜å“è³ªãªin-domainï¼ˆi.e. æ§˜ã€…ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã®ï¼‰ã®çŸ¥è­˜ã‚’é«˜ã‚ã‚‹ã‚ˆã†ãªï¼ˆimage,textï¼‰ãƒšã‚¢ã§å­¦ç¿’ã—ãŸã€‚<br><br>äº‹å¾Œå­¦ç¿’ã§ã¯ã€Llama3.1ã¨åŒæ§˜ã«SFT, Rejection Sampling, DPOã®ãƒ©ã‚¦ãƒ³ãƒ‰ã‚’è¤‡æ•°å›ç¹°ã‚Šè¿”ã—ãŸã€‚Llama3.1ã‚’ç”¨ã„ã¦ã€in-domainã®ç”»åƒã«å¯¾ã™ã‚‹QAã‚’Data Augmentationã—ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã€‚ã•ã‚‰ã«å ±é…¬ãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã¦å…¨ã¦ã®å›ç­”å€™è£œã‚’ãƒ©ãƒ³ã‚¯ã¥ã‘ã—ã¦é«˜å“è³ªãªSFTãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã€‚ã¾ãŸã€ãƒ¢ãƒ‡ãƒ«ã®å®‰å…¨æ€§ãŒé«˜ã¾ã‚‹ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚‚è¿½åŠ ã—ãŸã€‚<br><br>Llama3.1ã®äº‹å¾Œå­¦ç¿’ã®ãƒ—ãƒ­ã‚»ã‚¹ã«ã¤ã„ã¦ã¯ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1359" target="_blank" rel="noopener noreferrer">è«–æ–‡ç´¹ä»‹ / The Llama 3 Herd of Models, 2024.08</a>
 ã‚‚å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1418" target="_blank" rel="noopener noreferrer" class="title-link">LLM-jp-3 1.8Bãƒ»3.7Bãƒ»13B ã®å…¬é–‹, LLM.jp, 2024.09</a>
<span class="snippet"><span>Comment</span><p>LLM-JP-Evalã§ã®è©•ä¾¡çµæœã¯ã“ã¡ã‚‰:


<a href="https://huggingface.co/llm-jp/llm-jp-3-1.8b" target="_blank" rel="noopener noreferrer">https://huggingface.co/llm-jp/llm-jp-3-1.8b</a>


</p>
<p>1.8Bã®ãƒ¢ãƒ‡ãƒ«ãŒã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«å¯¾ã—ã¦éå¸¸ã«æ€§èƒ½ãŒè‰¯ã„ã¨ã®ã“ã¨ï¼ˆç¢ºã‹ã«ã€3.8Bã®ãƒ¢ãƒ‡ãƒ«ã¨ã®å·®ãŒã‚ã¾ã‚Šãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1838814594514718878?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯Llama2ã¨ã®ã“ã¨ãªã®ã§ã€vLLMã§ã‚‚å‹•ä½œã•ã›ã‚‰ã‚Œã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1417" target="_blank" rel="noopener noreferrer" class="title-link">LLM-jp Corpus v3, LLM.jp, 2024.09</a>
<span class="snippet"><span>Comment</span><p>LLM-jp-3 <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1418" target="_blank" rel="noopener noreferrer">LLM-jp-3 1.8Bãƒ»3.7Bãƒ»13B ã®å…¬é–‹, LLM.jp, 2024.09</a>
 ã®å­¦ç¿’ã«åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚³ãƒ¼ãƒ‘ã‚¹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1414" target="_blank" rel="noopener noreferrer" class="title-link">Improving Language Understanding by Generative Pre-Training, OpenAI, 2018.06</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªç„¶è¨€èªç†è§£ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ãƒ©ãƒ™ãƒ«ãªã—ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ç”¨ã„ãŸç”Ÿæˆçš„äº‹å‰å­¦ç¿’ã¨è­˜åˆ¥çš„å¾®èª¿æ•´ã‚’è¡Œã†ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ã‚¿ã‚¹ã‚¯ã«å¿œã˜ãŸå…¥åŠ›å¤‰æ›ã‚’åˆ©ç”¨ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å¤‰æ›´ã‚’æœ€å°é™ã«æŠ‘ãˆã¤ã¤ã€12ã®ã‚¿ã‚¹ã‚¯ä¸­9ã¤ã§æœ€å…ˆç«¯ã®æˆæœã‚’å¤§å¹…ã«æ”¹å–„ã€‚ç‰¹ã«ã€å¸¸è­˜æ¨è«–ã§8.9%ã€è³ªå•å¿œç­”ã§5.7%ã€ãƒ†ã‚­ã‚¹ãƒˆã®å«æ„ã§1.5%ã®æ”¹å–„ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>åˆä»£GPTè«–æ–‡</p>
<p>æ—¥æœ¬èªè§£èª¬: 


<a href="https://qiita.com/Toyamanokinsan/items/adff5e927fe26148c69c" target="_blank" rel="noopener noreferrer">https://qiita.com/Toyamanokinsan/items/adff5e927fe26148c69c</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2024-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1390" target="_blank" rel="noopener noreferrer" class="title-link">OpenAI o1, 2024.09</a>
<span class="snippet"><span>Comment</span><p>Jason Weiæ°ã®ãƒã‚¹ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_jasonwei/status/1834278706522849788?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1072" target="_blank" rel="noopener noreferrer">Think before you speak: Training Language Models With Pause Tokens, Sachin Goyal+, N/A, ICLR'24</a>
<br><br>ã‚„<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1147" target="_blank" rel="noopener noreferrer">Implicit Chain of Thought Reasoning via Knowledge Distillation, Yuntian Deng+, N/A, arXiv'23</a>
<br><br>ã§ä¼¼ãŸã‚ˆã†ãªè€ƒãˆã¯ã™ã§ã«ææ¡ˆã•ã‚Œã¦ã„ãŸãŒã€ã©ã®ã‚ˆã†ãªç‚¹ãŒç•°ãªã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ<br><br><br><br>ãŸã¨ãˆã°å‰è€…ã¯ã€pauseãƒˆãƒ¼ã‚¯ãƒ³ã¨å‘¼ã°ã‚Œã‚‹outputã¨ã¯é–¢ä¿‚ãªã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€outputã‚’ç”Ÿæˆã™ã‚‹å‰ã«ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã§æ¨è«–ã™ã‚‹å‰ã«ã‚ˆã‚Šå¤šãã®ãƒ™ã‚¯ãƒˆãƒ«æ“ä½œã‚’åŠ ãˆã‚‹ï¼ˆ=ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç¸¦æ–¹å‘ã¨æ¨ªæ–¹å‘ã«æ··ãœåˆã‚ã›ã‚‹; ä»¥å¾Œãƒ™ã‚¯ãƒˆãƒ«ã‚’ã“ã­ãã‚Šã¾ã‚ã™ã¨å‘¼ç§°ã™ã‚‹ï¼‰ã€ã¨ã„ã£ãŸæŒ™å‹•ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã‚ˆã†ã ãŒã€æ˜ç¤ºçš„ã«CoTã®æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦SFTãªã©ã‚’ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã•ãã†ã«è¦‹ãˆã‚‹ï¼ˆã–ã£ãã‚Šã¨ã—ã‹èª­ã‚“ã§ãªã„ãŒï¼‰ã€‚<br><br>ä¸€æ–¹ã€Jason Weiæ°ã®ãƒã‚¹ãƒˆã‹ã‚‰ã¯ã€RLã§æ˜ç¤ºçš„ã«ã‚ˆã‚Šè‰¯ã„CoTãŒã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã‚’ã—ã¦ã„ã‚‹ç‚¹ãŒé•ã†ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p>
<p>**(2025.0929): ä»¥ä¸‹ã®test-time computeã«é–¢ã™ã‚‹ãƒ¡ãƒ¢ã¯o1ãŒå‡ºãŸå½“åˆã®ã‚‚ã®ã§ã‚ã‚Šã€ç§ã®ç†è§£ãŒç”˜ã„çŠ¶æ…‹ã§ã®ãƒ¡ãƒ¢ãªã®ã§ç¾åœ¨ã®ç†è§£ã‚’å¾Œã»ã©è¿½è¨˜ã—ã¾ã™ã€‚å½“æ™‚ã®ãƒ¡ãƒ¢ã¯æ”¹ã‚ã¦è¦‹è¿”ã™ã¨ã“ã‚“ãªã“ã¨è€ƒãˆã¦ãŸã‚“ã ãªãã¨ãŠã‚‚ã—ã‚ã‹ã£ãŸã®ã§æ®‹ã—ã¦ãŠãã¾ã™ã€‚**<br><br>å­¦ç¿’ã®è¨ˆç®—é‡ã ã‘ã§ãªãã€inferenceã®è¨ˆç®—é‡ã«å¯¾ã—ã¦ã‚‚ã€æ–°ãŸãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡ãŒè¦‹å‡ºã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br><img src="https://github.com/user-attachments/assets/85a39908-7db8-4f97-9b5d-4bfdc8439577" alt="image" loading="lazy"><br><br><br><br>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆä¸­ã§è¨€ã‚ã‚Œã¦ã„ã‚‹ time spent thinking ï¼ˆtest-time computeï¼‰ã¨ã„ã†ã®ã¯ã€å…·ä½“çš„ã«ã¯ä½•ãªã®ã ã‚ã†ã‹ã€‚<br><br><br><br>ä¸Šã®ç ”ç©¶ã§ã„ã†ã¨ã“ã‚ã®ã€inferenceæ™‚ã®pauseãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆã®ã‚ˆã†ãªã‚‚ã®ã ã‚ã†ã‹ã€‚ãƒ¢ãƒ‡ãƒ«ãŒãƒ™ã‚¯ãƒˆãƒ«ã‚’ã“ã­ãã‚Šå›ã™å›æ•°ï¼ˆã‚ã‚‹ã„ã¯ç”Ÿæˆã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼‰ãŒå¢—ãˆã‚‹ã¨æ€§èƒ½ã‚‚è‰¯ããªã‚‹ã®ã‹ï¼Ÿ<br><br>ã—ã‹ã—ãã‚Œã¯ã‚ªãƒªã‚¸ãƒŠãƒ«ã®CoTç ”ç©¶ã§ã‚ã‚‹<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
<br><br>ã®dotã®ã¿ã®æ–‡å­—åˆ—ã‚’promptã«è¿½åŠ ã—ã¦æ€§èƒ½ãŒå‘ä¸Šã—ãªã‹ã£ãŸã€ã¨ã„ã†çŸ¥è¦‹ã¨åã™ã‚‹ã€‚<br><br><br><br>ãŠãã‚‰ãã€**ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã®ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ™‚ã«**ã€ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã“ã­ãã‚Šå›ã™å›æ•°ï¼ˆã‚ã‚‹ã„ã¯ç”Ÿæˆã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼‰ã‚’å¢—ã‚„ã™ã“ã¨ï¼time spent thinking (test-time compute) ã€ã¨ã„ã†ã“ã¨ãªã®ã ã‚ã†ã‹ï¼Ÿ<br><br>ãã—ã¦ãã®ã‚ˆã†ã«å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€æ¨è«–æ™‚ã«ãƒ™ã‚¯ãƒˆãƒ«ã‚’ã“ã­ãã‚Šå›ã™å›æ•°ï¼ˆã‚ã‚‹ã„ã¯ç”Ÿæˆã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼‰ã‚’å¢—ã‚„ã™ã¨æ€§èƒ½ãŒä¸ŠãŒã‚‹ã€ã¨ã„ã†ã“ã¨ãªã®ã ã‚ã†ã‹ã€‚<br><br>ã‚‚ã—ãã†ã ã¨ã™ã‚‹ã¨ã€ã“ã‚Œã¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1072" target="_blank" rel="noopener noreferrer">Think before you speak: Training Language Models With Pause Tokens, Sachin Goyal+, N/A, ICLR'24</a>
<br><br>ã®pauseãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆã‚’ã—ãªãŒã‚‰finetuningã™ã‚‹ã¨æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã€ã¨ã„ã†ä¸»å¼µã¨ã‚‚åˆè‡´ã™ã‚‹ã‚ˆã†ã«æ€ã†ãŒã€ã†ãƒ¼ã‚“ã€‚<br><br><br><br>å®Ÿéš›æš—å·è§£èª­ã®exampleã‚’è¦‹ã‚‹ã¨ã€ã¨ã¦ã¤ã‚‚ãªãé•·ã„CoTï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆæ•°ãŒå¤šã„ï¼‰ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã€‚</p>
<p>RLã§Reasoningã‚’å­¦ç¿’ã•ã›ã‚‹é–¢é€£ç ”ç©¶: <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1391" target="_blank" rel="noopener noreferrer">ReFT: Reasoning with Reinforced Fine-Tuning, Trung Quoc Luong+, N/A, ACL'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1392" target="_blank" rel="noopener noreferrer">Training Large Language Models for Reasoning through Reverse Curriculum   Reinforcement Learning, Zhiheng Xi+, N/A, ICML'24</a>
</p>
<p>ä»¥ä¸‹o1ã®å‹•ãã«é–¢ã—ã¦è€ƒãˆã¦ã„ã‚‹ä¸‹è¨˜noteã‹ã‚‰ã®å¼•ç”¨ã€‚<br><br><br><br>&gt;ã“ã‚Œã«ã‚ˆã£ã¦ã€LLMã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚„ãƒ‡ãƒ¼ã‚¿é‡ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹æ™‚ä»£ã‹ã‚‰æ¨è«–æ™‚é–“ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ï¼ˆã¤ã¾ã‚Šã€æ²¢å±±ã®æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ¢ç´¢ã™ã‚‹ï¼‰æ™‚ä»£ã«ç§»ã£ã¦ã„ããã†ã§ã™ã€‚<br><br><br><br>ãªã‚‹ã»ã©ã€‚test-compute timeã¨ã¯ã€æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—æ•°ã¨ãã®æ¢ç´¢ã«è¦ã™ã‚‹æ™‚é–“ã¨ã„ã†è¦‹æ–¹ã‚‚ã‚ã‚‹ã®ã§ã™ã­ã€‚<br><br><br><br>ã¾ãŸnoteä¸­ã§ã¯ã€CoTã®æ€§èƒ½å‘ä¸Šã®ãŸã‚ã«ã€Process Reward Modelï¼ˆPRMï¼‰ã‚’å­¦ç¿’ã•ã›ã€LLMãŒç”Ÿæˆã—ãŸæ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’è©•ä¾¡ã§ãã‚‹ã‚ˆã†ã«ã—ã€PRMã‚’å ±é…¬ãƒ¢ãƒ‡ãƒ«ã¨ã—å¼·åŒ–å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒo1ãªã®ã§ã¯ãªã„ã‹ã€ã¨æ¨æ¸¬ã—ã¦ã„ã‚‹ã€‚<br><br>PRMã‚’ææ¡ˆã—ãŸç ”ç©¶ã§ã¯ã€æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«0,1ã®æ­£èª¤ãƒ©ãƒ™ãƒ«ãŒä»˜ä¸ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚<br><br>ãªã‚‹ã»ã©ã€å‹‰å¼·ã«ãªã‚Šã¾ã™ã€‚<br><br><br><br>note: 


<a href="https://note.com/hatti8/n/nf4f3ce63d4bc?sub_rt=share_pb" target="_blank" rel="noopener noreferrer">https://note.com/hatti8/n/nf4f3ce63d4bc?sub_rt=share_pb</a>


</p>
<p>noteï¼ˆè©³ç´°ç·¨ï¼‰:


<a href="https://note.com/hatti8/n/n867c36ffda45?sub_rt=share_pb" target="_blank" rel="noopener noreferrer">https://note.com/hatti8/n/n867c36ffda45?sub_rt=share_pb</a>


</p>
<p>ã“ã¡ã‚‰ã®ãƒªãƒã‚¸ãƒˆãƒªã«é–¢é€£è«–æ–‡ã‚„Xãƒã‚¹ãƒˆã€å…¬å¼ãƒ–ãƒ­ã‚°ãªã©ãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹: 


<a href="https://github.com/hijkzzz/Awesome-LLM-Strawberry" target="_blank" rel="noopener noreferrer">https://github.com/hijkzzz/Awesome-LLM-Strawberry</a>


<br><br>ã“ã‚Œã¯ã™ã”ã„ã€‚è«–æ–‡å…¨éƒ¨èª­ã¿ãŸã„</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1387" target="_blank" rel="noopener noreferrer" class="title-link">PaperQA2, 2023.02</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sgrodriques/status/1833908643856818443?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Post.html" target="_blank" rel="noopener noreferrer">#Post</a>
<span class="issue_date">Issue Date: 2024-09-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1384" target="_blank" rel="noopener noreferrer" class="title-link">A few prompt engineering tips that Ilya Sutskever picked up at OpenAI, Ilya Sutskever, 2024.09</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-09-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1383" target="_blank" rel="noopener noreferrer" class="title-link">Late Chunking: Balancing Precision and Cost in Long Context Retrieval, Pierse+, 2024.09</a>
<span class="snippet"><span>Comment</span><p>chunkingã—ã¦ã‹ã‚‰embeddingã‚’å–å¾—ã™ã‚‹ã‚ˆã‚Šã€å…¨ä½“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¯¾ã—ã¦contextualãªtoken embeddingã‚’å–å¾—ã—ã€ãã®å¾Œchunkingã‚’ã—ã¦poolingã—ã¦single vectorã«ã™ã‚‹æ–¹ãŒã€æ–‡æ›¸ã®æ–‡è„ˆæƒ…å ±ãŒembeddingå†…ã§ä¿æŒã•ã‚Œã‚„ã™ã„ã®ã§ã€precisionãŒä¸ŠãŒã‚Šã¾ã™ã‚ˆã€ã¨ã„ã†è©±<br><br>ã‚¹ã‚¯ã‚·ãƒ§ã¯è¨˜äº‹ä¸­ã‚ˆã‚Šå¼•ç”¨<br><img src="https://github.com/user-attachments/assets/5fc20551-62f3-4965-8e3d-18540806fb34" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1379" target="_blank" rel="noopener noreferrer" class="title-link">ml-engineering</a>
<span class="snippet"><span>Comment</span><p>LLMã‚„VLMã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã‚„ãƒã‚¦ãƒã‚¦ãŒã¾ã¨ã‚ã‚‰ã‚ŒãŸãƒªãƒã‚¸ãƒˆãƒª</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2024-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1376" target="_blank" rel="noopener noreferrer" class="title-link">Reflection 70B, GlaiveAI, 2024.09</a>
<span class="snippet"><span>Comment</span><p>ãŸã ã¾ã‚ä»®ã«åŒã˜Inputã‚’åˆ©ç”¨ã—ã¦ã„ãŸã¨ã—ã¦ã€promptingã¯åŒã˜ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ãªãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—æ¨è«–ã‚’å®Ÿæ–½ã™ã‚‹ã‹ã¯promptingã®ã‚¹ã‚³ãƒ¼ãƒ—ã§ã¯ãªã„ï¼‰ãªã®ã§ã€ãã‚‚ãã‚‚åŒã˜Inputãªã®ã§fair comparisonã§ã™ã‚ˆã€ã¨ã„ã†è©±ã«ä»®ã«ãªã‚‹ã®ã ã¨ã—ãŸã‚‰ã€ãã‚‚ãã‚‚ã©ã†ã„ã†è¨­å®šã§æ¯”è¼ƒå®Ÿé¨“ã™ã¹ãã‹?ã¨ã„ã†ã®ã¯æ¤œè¨ã—ãŸæ–¹ãŒè‰¯ã„æ°—ã¯ã™ã‚‹ã€‚ã¾ã‚ã©ã“ã«ç„¦ç‚¹ã‚’ç½®ãã‹æ¬¡ç¬¬ã ã¨æ€ã†ã‘ã©ã€‚<br><br>ã‚¨ãƒ³ãƒ‰ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰è¦‹ãŸã‚‰ã€reflectionã®promptingã®ã‚„ã‚Šæ–¹ãªã‚“ã¦ã‚ã‹ã‚‰ãªã„ã‚ˆï¼ã¨ã„ã†äººã‚‚ã„ã‚‹ã¨æ€ã†ã®ã§ã€ãã‚Œã‚’å†…éƒ¨ã§è‡ªç™ºçš„ã«å®Ÿæ–½ã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã—ã¦æ˜ç¤ºçš„ã«promptingã—ãªãã¦ã‚‚ã€é«˜ã„æ€§èƒ½ã‚’é”æˆã§ãã‚‹ã®ã§ã‚ã‚Œã°æ„å‘³ãŒã‚ã‚‹ã¨æ€ã†ã€‚<br><br>ãŸã ã¾ã‚å°‘ãªãã¨ã‚‚ã€å‚è€ƒã§ã‚‚è‰¯ã„ã‹ã‚‰ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚reflectionã‚’ã™ã‚‹ã‚ˆã†ãªpromptingã‚’ã—ãŸæ€§èƒ½ã§ã®æ¯”è¼ƒçµæœã‚‚è¼‰ã›ã‚‹æ–¹ãŒè¦ªåˆ‡ã‹ãªã€ã¨ã¯æ€ã†ã€‚</p>
<p>ã‚ã¨ã€70Bã§ã“ã‚Œã»ã©ã®æ€§èƒ½ãŒå‡ºã¦ã„ã‚‹ã®ã¯ã“ã‚Œã¾ã§ã«ãªã„ã¨æ€ã†ã®ã§ã€ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦ã¯ãƒ‡ã‚£ãƒ•ã‚§ãƒ³ã‚¹ãŒå¿…è¦ã«æ€ã†ï¼ˆä»–ã®ãƒ¢ãƒ‡ãƒ«ãŒãã®ã‚ˆã†ãªãƒ‡ã‚£ãƒ•ã‚§ãƒ³ã‚¹ã‚’ã—ã¦ã„ã‚‹ã‹ã¯çŸ¥ã‚‰ãªã„ãŒï¼‰ã€‚<br><br>è¿½è¨˜<br>â†’ ä¸‹è¨˜è¨˜äº‹ã«ã‚ˆã‚‹ã¨ã€LLM Decontaminatorã‚’ç”¨ã„ã¦ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’é˜²ã„ã§ã„ã‚‹ã¨ã®ã“ã¨<br>


<a href="https://github.com/lm-sys/llm-decontaminator" target="_blank" rel="noopener noreferrer">https://github.com/lm-sys/llm-decontaminator</a>


</p>
<p>Reflectionè‡ªä½“ã®æœ‰ç”¨æ€§ã¯ä»¥å‰ã‹ã‚‰ç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚<br>å‚è€ƒ: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1377" target="_blank" rel="noopener noreferrer">Self-Reflection in LLM Agents: Effects on Problem-Solving Performance, Matthew Renze+, N/A, arXiv'24</a>
, <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1105" target="_blank" rel="noopener noreferrer">Self-RAG: Learning to Retrieve, Generate, and Critique through   Self-Reflection, Akari Asai+, N/A, ICLR'24</a>
, <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1248" target="_blank" rel="noopener noreferrer">AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls, Yu Du+, N/A, arXiv'24</a>
, <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1378" target="_blank" rel="noopener noreferrer">Automatically Correcting Large Language Models: Surveying the landscape  of diverse self-correction strategies, Liangming Pan+, N/A, TACL'24</a>
</p>
<p>ollamaã§å®Ÿéš›ã«å‹•ã‹ã—ã¦æ—¥æœ¬èªã§ã®QAã‚’è©¦ã—ã¦ã„ã‚‹è¨˜äº‹ã€‚å®Ÿéš›ã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚„reflectionã®å†…å®¹ãŒç¢ºèªã§ãã€ãŠã‚‚ã—ã‚ã„ã€‚<br><br>ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§&lt; thinking &gt;ã‚¿ã‚°ã§Inputã«å¯¾ã—ã¦æ¨è«–ã—ã€&lt; output &gt;ã‚¿ã‚°å†…ã§æœ€çµ‚å‡ºåŠ›ã‚’è¡Œã„ã€æ¨è«–éç¨‹ã§èª¤ã‚ŠãŒã‚ã‚‹å ´åˆã¯&lt; reflection &gt;ã‚¿ã‚°ã‚’ç”¨ã„ã¦ä¿®æ­£ã™ã‚‹ã‚ˆã†ã«æŒ‡ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br>ãŠãã‚‰ãã€thinkingã‚¿ã‚°å†…ã®æ€è€ƒéç¨‹ã§ãƒ¢ãƒ‡ãƒ«ãŒèª¤ã‚Šã«æ°—ã¥ã„ãŸå ´åˆã¯ã€thinkingã‚¿ã‚°ã®é€”ä¸­ã§reflectionã‚¿ã‚°ãŒå‡ºåŠ›ã•ã‚Œã€ãã®æ™‚ç‚¹ã§CoTãŒä¿®æ­£ã•ã‚Œã‚‹ã‚ˆã†ã§ã‚ã‚‹ï¼ˆã‚‚ã—ãã¯outputã¨thinkingã®ä¸­é–“ï¼‰ã€‚ã“ã®ãŸã‚ã€èª¤ã£ãŸCoTã«åŸºã¥ã„ã¦OutputãŒç”Ÿæˆã•ã‚Œã‚‹é »åº¦ãŒæ¸›å°‘ã™ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><br>ã“ã®ã‚ˆã†ãªæŒ™å‹•ã¯ãŠãã‚‰ãã€reflectionç”¨ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§SFTã—ãªã„ã¨ã§ããªã„ã¨æ€ã†ã®ã§<br><br>ï¼ˆãŸã¨ãˆã°ã€Reflectionã‚¿ã‚¹ã‚¯ã‚’ã™ã‚‹ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã§SFTã‚’ã—ã¦ã„ãªã„å ´åˆã€å‡ºåŠ›ã®é€”ä¸­ã§èª¤ã‚Šã‚’æ¤œå‡ºã—å‡ºåŠ›ã‚’ä¿®æ­£ã™ã‚‹ã¨ã„ã†æŒ™å‹•ã«ã¯ãªã‚‰ãšã€å›ç­”ã¨ã—ã¦è‡ªç„¶ãªæ–‡ã‚’æœ€å¾Œã¾ã§outputã™ã‚‹ã¨æ€ã†ã€‚ãã®å¾Œã§reflectionã—ã‚ã¨ä¿ƒã™ã“ã¨ã¯promptingã§ã§ãã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãŒã€ãã‚‚ãã‚‚reflectionã™ã‚‹èƒ½åŠ›ãŒã‚ã¾ã‚Šé«˜ããªã„å¯èƒ½æ€§ãŒã‚ã‚Šã€ã†ã¾ãä¿®æ­£ã‚‚ã—ã¦ãã‚Œãªã„ã‹ã‚‚ï¼‰<br><br>reflectionã®èƒ½åŠ›ã‚’é«˜ã‚ã‚‹ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã§SFTã‚’ã—ã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«ã§ä¼¼ãŸã‚ˆã†ãªpromptingã‚’ã—ã¦ã‚‚ã€ã†ã¾ãã„ã‹ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§æ³¨æ„ãŒå¿…è¦ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>å‚è€ƒ: 


<a href="https://note.com/schroneko/n/nae86e5d487f1" target="_blank" rel="noopener noreferrer">https://note.com/schroneko/n/nae86e5d487f1</a>


</p>
<p>é–‹ç™ºè€…æ›°ãã€HFã«è¨˜è¼‰ã®æ­£ã—ã„ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥ã‚Œãªã„ã¨ã€é©åˆ‡ã«å‹•ä½œã—ãªã„ã¨ã®ã“ã¨ã€‚<br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mattshumer_/status/1832061508294971731?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã©ã†ã‚„ã‚‰åˆæœŸã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãŸHFã®ãƒ¢ãƒ‡ãƒ«ã¯weightã«èª¤ã‚ŠãŒã‚ã‚Šã€æŒ™å‹•ãŒãŠã‹ã—ããªã£ã¦ã„ãŸã‚ˆã†ã ã€‚<br>æ­£ã—ã„ãƒ¢ãƒ‡ãƒ«ã®æŒ™å‹•ã¯ä¸‹è¨˜ãƒ„ã‚¤ãƒ¼ãƒˆã®ã‚ˆã†ã§ã‚ã‚‹ã€‚thinkingå†…ã§reflectionãŒå®Ÿæ–½ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>å®Ÿéš›ã«ã„ãã¤ã‹ã®ä¾‹ã‚’ãƒ–ãƒ­ã‚°ã‚’ãƒªãƒªãƒ¼ã‚¹å½“æ—¥ã«è¦‹ãŸæ™‚ã«ã€reflectionã‚¿ã‚°ãŒoutputã®å¾Œã«å‡ºåŠ›ã•ã‚Œã¦ã„ã‚‹ä¾‹ãªã©ãŒã‚ã‚Šã€ãŠã‚„ï¼Ÿã¨ã„ã†æŒ™å‹•ã‚’ã—ã¦ã„ãŸã®ã§ã€å•é¡ŒãŒæ˜¯æ­£ã•ã‚ŒãŸã‚ˆã†ã ã€‚<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mattshumer_/status/1832581211841052694?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HFã®ãƒ¢ãƒ‡ãƒ«ãŒä¿®æ­£ã•ã‚ŒãŸå¾Œã‚‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµæœãŒå†ç¾ã•ã‚Œãªã„ãªã©ã€é›²è¡ŒããŒè‰²ã€…ã¨æ€ªã—ã„ã®ã§æ³¨æ„ã—ãŸæ–¹ãŒè‰¯ã„ã€‚</p>
<p>ç¶šå ±<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1832965630472995220?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–‹ç™ºè€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/csahil28/status/1833619624589725762?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å†ç¾å®Ÿé¨“ã‚’å…¨ã¦çµ‚äº†ã—ã€å½“åˆå ±å‘Šã—ã¦ã„ãŸçµæœãŒå†ç¾ã•ã‚Œãªã‹ã£ãŸã¨CEOãŒå£°æ˜ï¼š



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mattshumer_/status/1842313328166907995"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1375" target="_blank" rel="noopener noreferrer" class="title-link">Ruri: Japanese General Text Embeddings, cl-nagoya, 2024.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hpp_ricecake/status/1831308092459643232?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>337Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã§ã€åŒç­‰ã®ã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã‚’JMTEBã§å¤§ããä¸Šå›ã‚‹æ€§èƒ½ã€‚LLMã‚’ç”¨ã„ã¦ç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦Contrastive Learning, ãã®å¾Œé«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã§Finetuningã‚’å®Ÿæ–½ã—ãŸã¨ã®ã“ã¨ã€‚</p>
<p>JMTEBä¸Šã§ã¯ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºä¸æ˜ï¼ˆã ãŒãŠãã‚‰ãæ¡é•ã„ã«å¤§ãã„ï¼‰ã®OpenAI/text-embedding-3-largeã¨åŒç­‰ã®æ€§èƒ½ã«è¦‹ãˆã‚‹ãŒã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1373" target="_blank" rel="noopener noreferrer">LLMã«æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’å­¦ç¿’ã•ã›ã‚‹æ„ç¾©, Koshiro Saito+, ç¬¬261å›è‡ªç„¶è¨€èªå‡¦ç†ç ”ç©¶ç™ºè¡¨ä¼š, 2024.08</a>
 ãªã©ã‚’è€ƒæ…®ã™ã‚‹ã¨ã€æ—¥æœ¬ç‰¹æœ‰ã®çŸ¥è­˜ã‚’å•ã†QAãªã©ã¯ãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãªãƒ¢ãƒ‡ãƒ«ã¯å¼±ãã†ãªã®ã§ã€ãã®è¾ºãŒã©ã‚Œã»ã©é«˜ã„æ€§èƒ½ã‚’æŒã£ã¦ã„ã‚‹ã®ã‹ã¯èˆˆå‘³ãŒã‚ã‚‹ã€‚<br><br>LLMã§äººå·¥çš„ã«ç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã§ã¯ã€ç”Ÿæˆã«åˆ©ç”¨ã—ãŸLLMãŒæŒã¤çŸ¥è­˜ã—ã‹è¡¨å±¤çš„ã«ã¯ç¾ã‚Œãªã„ã¨æ€ã†ã®ã§ä½•ã‚’åˆ©ç”¨ã—ãŸã‹ã«ã‚ˆã‚‹ã®ã¨ã€é«˜å“è³ªãªãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿ã«ãã®è¾ºãŒã©ã®ç¨‹åº¦å«ã¾ã‚Œã¦ã„ã‚‹ã‹ã€‚</p>
<p>æœ€å¤§sequenceé•·ã¯1012ãªã®ã§ã€ã‚ˆã‚Šé•·ã„ç³»åˆ—ã‚’BERTã§åŸ‹ã‚è¾¼ã¿ãŸã„å ´åˆã¯RetrievaBERT  <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1323" target="_blank" rel="noopener noreferrer">RetrievaBERTã®å…¬é–‹, 2024</a>
 ï¼ˆæœ€å¤§sequenceé•·2048ï¼‰ã‚‚æ¤œè¨ã®ä½™åœ°ãŒã‚ã‚‹ã€‚</p>
<p>é–‹ç™ºè€…ã®æ–¹ã‹ã‚‰ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆãŒå‡ºãŸ<br>


<a href="https://arxiv.org/abs/2409.07737" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2409.07737</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<span class="issue_date">Issue Date: 2024-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1368" target="_blank" rel="noopener noreferrer" class="title-link">NanoFlow, 2024.08</a>
<span class="snippet"><span>Comment</span><p>vLLMã‚ˆã‚Šã‚‚2å€ç¨‹åº¦é«˜é€ŸãªLLM serving frameworkã€‚<br><br>ã‚ªãƒ•ãƒ©ã‚¤ãƒ³è©•ä¾¡<br><img src="https://github.com/user-attachments/assets/93d8362d-e0e4-4bdb-9de4-178e1eef2e33" alt="image" loading="lazy"><br><br>ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§ã®latencyè©•ä¾¡<br><img src="https://github.com/user-attachments/assets/506ebf39-9c47-4d11-9352-c26f6b0d155c" alt="image" loading="lazy"><br><br>æ©Ÿèƒ½ã¯vLLMã®æ–¹ãŒå¤šã„ãŒã€é€Ÿåº¦ã¯ã“ã¡ã‚‰ã®æ–¹ãŒã‹ãªã‚Šé€Ÿãã†ã§ã¯ã‚ã‚‹ã€‚latencyã®requirementãŒå³ã—ã„å ´åˆãªã©ã¯æ¤œè¨ã—ã¦ã‚‚è‰¯ã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚<br><br>ã—ã‹ã—LLM serving frameworkã‚‚ç¾¤é›„å‰²æ‹ ã§ã™ã­ã€‚</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rohanpaul_ai/status/1829647702998606104?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1343" target="_blank" rel="noopener noreferrer">DeepSpeed, vLLM, CTranslate2 ã§ rinna 3.6b ã®ç”Ÿæˆé€Ÿåº¦ã‚’æ¯”è¼ƒã™ã‚‹, 2024.06</a>
 ã‚‚å‚ç…§ã®ã“ã¨</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2024-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1359" target="_blank" rel="noopener noreferrer" class="title-link">è«–æ–‡ç´¹ä»‹ _ The Llama 3 Herd of Models, 2024.08</a>
<span class="snippet"><span>Comment</span><p>Llama3ã®äº‹å‰å­¦ç¿’ã‚„äº‹å¾Œå­¦ç¿’ã®ãƒã‚¦ãƒã‚¦ãŒè©°ã¾ã£ã¦ãŠã‚Šï¼ˆå®‰å…¨æ€§ãªã©ã‚‚å«ã‚€ï¼‰ã€LLMå­¦ç¿’ã«å¿…è¦ãªè¦ç´ ãŒå›³è§£ã•ã‚Œã¦ãŠã‚Šã€éå¸¸ã«åˆ†ã‹ã‚Šã‚„ã™ã„ã€‚<br><br><br><br>ãŸã¨ãˆã°ä¸‹è¨˜å›³ï¼ˆã‚¹ãƒ©ã‚¤ãƒ‰ä¸­ã‚ˆã‚Šå¼•ç”¨ï¼‰ãªã©ã¯ã€LLMã®å­¦ç¿’éç¨‹ã‚’èª¬æ˜ã™ã‚‹éš›ã«ã‚ã‹ã‚Šã‚„ã™ãã†<br><br><img src="https://github.com/user-attachments/assets/501ae2ae-cfc6-46ab-9701-c860b9a52dc3" alt="image" loading="lazy"><br><br></p>
<p>LLMã®äº‹å‰ãƒ»äº‹å¾Œå­¦ç¿’ã‚ãŸã‚Šã¯ç‹¬è‡ªãƒã‚¦ãƒã‚¦ãŒå¤šã™ãã¦ã‚‚ã¯ã‚„è¿½å¾“å›°é›£</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1356" target="_blank" rel="noopener noreferrer" class="title-link">Liger-Kernel, 2024.08</a>
<span class="snippet"><span>Comment</span><p>LLMã‚’å­¦ç¿’ã™ã‚‹æ™‚ã«ã€ãƒ¯ãƒ³ãƒ©ã‚¤ãƒ³è¿½åŠ ã™ã‚‹ã ã‘ã§ã€ãƒãƒ«ãƒGPUãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’20%æ”¹å–„ã—ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’60%å‰Šæ¸›ã™ã‚‹ã‚‰ã—ã„<br><br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hsu_byron/status/1827072737673982056?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã ã‘ã§ã„ã„<br><img src="https://github.com/user-attachments/assets/abce24ed-f979-43db-ac51-e850f2ae877a" alt="image" loading="lazy"></p>
<p>Unsloth <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1450" target="_blank" rel="noopener noreferrer">Unsloth</a>
 ã¯LoRA/QLoRAãŒå¯èƒ½ãªä¸€æ–¹ã§ã¾ã Multi-GPUã¯ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ã€‚ä¸€æ–¹ã€Liger-Kernelã¯LoRAã‚ˆã‚Šã‚‚full-parameter tuningã¨Multi-GPUã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦ãŠã‚Šã€ç›®çš„ã«å¿œã˜ã¦ä½¿ã„åˆ†ã‘ãŒå¿…è¦ã€‚<br><br><br><br>


<a href="https://github.com/linkedin/Liger-Kernel/issues/57" target="_blank" rel="noopener noreferrer">https://github.com/linkedin/Liger-Kernel/issues/57</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2024-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1355" target="_blank" rel="noopener noreferrer" class="title-link">Grok-2, X, 2024.08</a>
<span class="snippet"><span>Comment</span><p>chatbot arenaã§5æœˆæ™‚ç‚¹ã®GPT4oè¶…ãˆã€‚miniã§ã‚‚ãªã‚“ã¨llama3.1-705Bè¶…ãˆ<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lmsysorg/status/1827041269534879784?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1354" target="_blank" rel="noopener noreferrer" class="title-link">Phi 3.5, Microsoft, 2024.08</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-08-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1353" target="_blank" rel="noopener noreferrer" class="title-link">4-bit Llama 3.1, NeuralMagic, 2024.08</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-08-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1348" target="_blank" rel="noopener noreferrer" class="title-link">RAGå…¥é–€: ç²¾åº¦æ”¹å–„ã®ãŸã‚ã®æ‰‹æ³•28é¸, 2024.08</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-08-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1347" target="_blank" rel="noopener noreferrer" class="title-link">PLaMo-100B, PFN, 2024.08</a>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§GPT4ã‚’è¶…ãˆã‚‹æ€§èƒ½ã‚’é”æˆã€‚<br>SFT, DPOã§å­¦ç¿’ã€‚å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯ã€Publicãªã‚‚ã®ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ä½œæˆã—ãŸã‚‚ã®ã€LLMè‡ªèº«ã«ä½œæˆã•ã›ãŸã‚‚ã®ã‚’åˆ©ç”¨ã—ãŸã€‚ã¾ãŸã€æœ€çµ‚çš„ãªãƒ¢ãƒ‡ãƒ«ã«è¤‡æ•°ã®å€™è£œãŒã‚ã£ãŸã®ã§ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã§è‰¯ã„ã¨ã“ã‚å–ã‚Šã‚’ã—ãŸã€‚DPOã§åˆ©ç”¨ã™ã‚‹preferenceãƒ‡ãƒ¼ã‚¿ã¯ã€äº‹å¾Œå­¦ç¿’é€”ä¸­ã®ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦è‡ªå‹•ç”Ÿæˆã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-08-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1342" target="_blank" rel="noopener noreferrer" class="title-link">OpenLLM: Self-Hosting LLMs Made Easy</a>
<span class="snippet"><span>Comment</span><p>OpenLLMã‚’self hostingã™ã‚‹éš›ã«ã€OpenAIãªã©ã¨åŒã˜ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ã®APIã‚„Chatã‚’æä¾›ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-07-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1340" target="_blank" rel="noopener noreferrer" class="title-link">Gemma2, Google Deepmind, 2024</a>
<span class="snippet"><span>Comment</span><p>Reasoning, Math, CodeGenerationã«å¼·ã¿</p>
<p><img src="https://github.com/user-attachments/assets/b7f58129-1235-4812-9c5e-0607aa1bea66" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/03e74ece-a0d5-4699-b09e-f8791062f6a8" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-07-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1335" target="_blank" rel="noopener noreferrer" class="title-link">Llama 3.1, 2024.07</a>
<span class="snippet"><span>Comment</span><p>Llamaç³»ã®ãƒ¢ãƒ‡ãƒ«ã‚’FP8ã§å­¦ç¿’ã™ã‚‹å ´åˆã®ãƒ¬ã‚·ãƒ”<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thom_wolf/status/1826924774997532799?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1334" target="_blank" rel="noopener noreferrer" class="title-link">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é–‹ç™º, 2024</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-07-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1330" target="_blank" rel="noopener noreferrer" class="title-link">calm3-22B, 2024</a>
<span class="snippet"><span>Comment</span><p>&gt;LLMã®æ—¥æœ¬èªèƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹Nejumi LLM ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰3ã«ãŠã„ã¦ã¯ã€700å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®Meta-Llama-3-70B-Instructã¨åŒç­‰ã®æ€§èƒ½ã¨ãªã£ã¦ãŠã‚Šã€ã‚¹ã‚¯ãƒ©ãƒƒãƒé–‹ç™ºã®ã‚ªãƒ¼ãƒ—ãƒ³ãªæ—¥æœ¬èªLLMã¨ã—ã¦ã¯ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®æ€§èƒ½ã¨ãªã‚Šã¾ã™ï¼ˆ2024å¹´7æœˆç¾åœ¨ï¼‰ã€‚<br>ãƒ¢ãƒ‡ãƒ«ã¯å•†ç”¨åˆ©ç”¨å¯èƒ½ãªApache License 2.0ã§æä¾›ã•ã‚Œã¦ãŠã‚Š<br><br>ã“ã‚Œã¯ã™ã”ã„</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-07-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1327" target="_blank" rel="noopener noreferrer" class="title-link">GENIAC: 172B äº‹å‰å­¦ç¿’çŸ¥è¦‹, 2024</a>
<span class="snippet"><span>Comment</span><p>LLMã®äº‹å‰å­¦ç¿’ã«ãŠã‘ã‚‹çŸ¥è¦‹ãŒã¾ã¨ã¾ã£ã¦ã„ã‚‹è¨˜äº‹ã¨ã®ã“ã¨</p>
<p>ãƒ»Megatron LMã§å­¦ç¿’<br>ã€€â†’ 3D Parallelismãªã©ã®åˆ†æ•£å­¦ç¿’æ‰‹æ³•ã«ã‚ˆã‚ŠHF Trainerã‚ˆã‚Šé«˜é€Ÿ<br>ã€€â†’ Data Parallelimã€Tensor Parallelismã€ Pipeline Parallelismã‚’çµ„ã¿åˆã‚ã›ãŸã‚‚ã®<br>ãƒ»GPUãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã€ä¸è‰¯ã§å­¦ç¿’ãŒç¶™ç¶šã§ããªã‹ã£ãŸå ´åˆã¯checkpointã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦å­¦ç¿’<br>ãƒ»å­¦ç¿’æ›²ç·šãŒå®‰å®šã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ãŒSpikeã¯ç™ºç”Ÿã—ã¦ã„ã‚‹ã€‚ç™ºç”Ÿæ™‚ã¯gradient normãŒæ€¥æ¿€ã«ä¸Šæ˜‡ã™ã‚‹<br>ãƒ»Llamaãªã©ã®LLMã‹ã‚‰ã®ç¶™ç¶šçš„äº‹å‰å­¦ç¿’ã§ã¯ãªãfrom scratchã‹ã‚‰å­¦ç¿’ã—ã¦ã„ã‚‹ã®ã§é€æ˜æ€§ãŒé«˜ã„<br>ãƒ»Transformer engineã‚’åˆ©ç”¨<br>ãƒ»AdamWã‚’åˆ©ç”¨<br>ãƒ»attention dropout, hidden dropoutã¯0.0<br><br>&gt;ã“ã®éš›ã€ é€šä¿¡ã‚’å¤šãå¿…è¦ã¨ã™ã‚‹åˆ†æ•£æ‰‹æ³•ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆTensor Parallelãƒ¯ãƒ¼ã‚«ãƒ¼ï¼‰ã¯ãƒãƒ¼ãƒ‰å†…ã«é…ç½®ã™ã‚‹ã‚ˆã†ã«Megatron-LMã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ãªã£ã¦ã„ã‚‹ãŸã‚ã€ä»Šå›ã‚‚ãã‚Œã‚’åˆ©ç”¨ã—ã¾ã—ãŸã€‚ã“ã®ã‚ˆã†ã«ã™ã‚‹ç†ç”±ã¯ã€ãƒãƒ¼ãƒ‰å†…ã®é€šä¿¡ã¯NVLinkã«ã‚ˆã‚Šã€ãƒãƒ¼ãƒ‰é–“é€šä¿¡ã‚ˆã‚Šã‚‚é«˜é€Ÿã§ã‚ã‚‹ãŸã‚ã§ã™ã€‚ã¾ãŸã€Data Parallelã®å‹¾é…å¹³å‡åŒ–ã®ãŸã‚ã®é€šä¿¡ã‚’è€ƒæ…®ã—ã¦ã€Data Parallelãƒ¯ãƒ¼ã‚«ãƒ¼ã‚‚å¯èƒ½ãªé™ã‚Šãƒãƒ¼ãƒ‰å†…ã«é…ç½®ã™ã‚‹Megatron-LMãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æŒ™å‹•ã‚’åˆ©ç”¨ã—ã¾ã—ãŸã€‚<br>Pipeline Parallelismã¯ä»–ã®ä¸¦åˆ—åŒ–æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦é€šä¿¡é‡ãŒå°‘ãªã„P2P(Point-to-Point)é€šä¿¡ã§ã‚ã‚‹ãŸã‚ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¹ãƒ†ãƒ¼ã‚¸ã¯ãƒãƒ¼ãƒ‰é–“ã§é…ç½®ã™ã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸã€‚ã“ã‚Œã‚‚ã€Megatron-LMãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æŒ™å‹•ã§ã™ã€‚<br><br>å‹‰å¼·ã«ãªã‚‹<br><br>ãƒ»é€šå¸¸ã®ãƒ‡ãƒ¼ã‚¿ä¸¦åˆ—ã¯optimizer stateã‚’workeré–“ã§è¤‡è£½ã™ã‚‹ã®ã§é…ã„ã€‚Deep Speed Zero 1ã®ã‚ˆã†ã«åˆ†æ•£ã—ã¦ä¿æœ‰ã™ã‚‹ã“ã¨ã§é«˜é€ŸåŒ–<br>ãƒ»Tensor Parallelã§self attention, MLPã®è¨ˆç®—ã‚’ä¸¦åˆ—åŒ–ã§ãã‚‹<br>ãƒ»LayerNormalization, Dropoutã®æ¼”ç®—ã‚‚ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®è¦³ç‚¹ã‹ã‚‰ä¸¦åˆ—åŒ–<br>ãƒ»å­¦ç¿’ã‚’å®‰å®šã•ã›ã‚‹ãŸã‚ã«z-lossã‚’åˆ©ç”¨<br>ãƒ»batch skippingã¨ã¯ã€gradient clippingã‚’è¡Œã£ã¦ã„ã¦ã‚‚ãªãŠspikeãŒç”Ÿã˜ã‚‹å ´åˆã«ã€100 stepå‰ã«æˆ»ã‚Šã€spikeãŒç”Ÿã˜ãŸä»˜è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ•°ç™¾iterationç¨‹åº¦ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã“ã¨<br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1325" target="_blank" rel="noopener noreferrer" class="title-link">OpenDevin: Code Less, Make More, 2024</a>
<span class="snippet"><span>Comment</span><p>LLMã«ã‚ˆã‚‹OpenSourceãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ç”Ÿæˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ </p>
<p>full timeã®ã‚¹ã‚¿ãƒƒãƒ•ã‚’é›‡ç”¨ã—worldã‚¯ãƒ©ã‚¹ã®UXã‚’ç›®æŒ‡ã™ã¨ã®ã“ã¨ã€‚æ¥½ã—ã¿ã€‚<br>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1808493521315496229?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenåŒ–ã•ã‚Œã‚‹å‰ã®æœ€åˆã®Devinã®ãƒ„ã‚¤ãƒ¼ãƒˆ<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cognition_labs/status/1767548763134964000"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1324" target="_blank" rel="noopener noreferrer" class="title-link">ã‚ˆã‚Šè‰¯ã„Transformerã‚’ã¤ãã‚‹, Shun Kiyono, 2022</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2024-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1323" target="_blank" rel="noopener noreferrer" class="title-link">RetrievaBERTã®å…¬é–‹, 2024</a>
<span class="snippet"><span>Comment</span><p>RAGã¸å¿œç”¨ã™ã‚‹éš›ã«ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ‰±ã„Embeddingã‚’ç²å¾—ã—ãŸã„ã‚·ãƒ¼ãƒ³ãŒå¢—ãˆãŸã®ã§ã€æœ€å¤§ã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ãŒ2048ã®BERTã‚’å­¦ç¿’ã—å…¬é–‹ã€‚Apache2.0<br><br><br><br>ã‚ªãƒªã‚¸ãƒŠãƒ«ã®BERTã¨æ¯”è¼ƒã—ã¦ã€è¿‘å¹´ã®LLMã§æœ‰ç”¨æ€§ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ä»¥ä¸‹ã‚’ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«å–ã‚Šå…¥ã‚Œã¦ã„ã‚‹<br><br>- SwiGLUæ´»æ€§åŒ–é–¢æ•° <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1311" target="_blank" rel="noopener noreferrer">GLU Variants Improve Transformer, Noam Shazeer, N/A, arXiv'20</a>
 <br><br>- PreNorm <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1324" target="_blank" rel="noopener noreferrer">ã‚ˆã‚Šè‰¯ã„Transformerã‚’ã¤ãã‚‹, Shun Kiyono, 2022</a>
 <br><br>- Grouped Query Attention (Multi Query Attention) <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
 </p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1322" target="_blank" rel="noopener noreferrer" class="title-link">Llama 3 Swallow</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<span class="issue_date">Issue Date: 2024-05-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1318" target="_blank" rel="noopener noreferrer" class="title-link">Using and Evaluating User Directed Summaries to Improve Information Access</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<span class="issue_date">Issue Date: 2024-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1310" target="_blank" rel="noopener noreferrer" class="title-link">RoFormer: Enhanced Transformer with Rotary Position Embedding, Jianlin Su+, N_A, Neurocomputing, 2024</a>
<span class="snippet"><span>GPT Summary</span>- ä½ç½®ç¬¦å·åŒ–ã¯transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§æœ‰åŠ¹ã§ã‚ã‚Šã€æœ¬è«–æ–‡ã§ã¯Rotary Position Embeddingï¼ˆRoPEï¼‰ã¨ã„ã†æ–°ã—ã„æ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚RoPEã¯ã€å›è»¢è¡Œåˆ—ã‚’ä½¿ç”¨ã—ã¦çµ¶å¯¾ä½ç½®ã‚’ç¬¦å·åŒ–ã—ã€åŒæ™‚ã«ç›¸å¯¾ä½ç½®ä¾å­˜æ€§ã‚’è‡ªå·±æ³¨æ„æ§‹æˆã«çµ„ã¿è¾¼ã‚€ã€‚RoPEã‚’ä½¿ç”¨ã—ãŸRoFormerã¯ã€é•·ã„ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ä»–ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒå®Ÿé¨“ã§ç¤ºã•ã‚Œã¦ãŠã‚Šã€Huggingfaceã«çµ±åˆã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>RoPEã‚’ææ¡ˆã—ãŸè«–æ–‡</p>
<p># Absolute Position Embedding ã¨ Relative Position Embedding<br><br>## Transformerã«ãŠã‘ã‚‹QKVãƒ™ã‚¯ãƒˆãƒ«ã®è¨ˆç®—æ–¹æ³•<br><br>ä¸€èˆ¬ã«ã€Transformerã«ãŠã‘ã‚‹ Query (Q), Key (K), Value (V) ã¯ä»¥ä¸‹ã®å¼ã§å®šå¼åŒ–ã•ã‚Œã‚‹ï¼š<br><br>&lt;img width="176" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/21b0f077-64b4-4fe5-af04-bffc373eabf5"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/21b0f077-64b4-4fe5-af04-bffc373eabf5"&lt;/a&gt;


&gt;<br><br>m, nã¯ãã‚Œãã‚Œä½ç½®ã‚’è¡¨ã™æ•´æ•°ã€‚Absolute Position Embeddingã¨ã€Relative Position Embeddingã¯ã€é–¢æ•°fã®è¨­è¨ˆãŒãã‚Œãã‚Œç•°ãªã£ã¦ã„ã‚‹ï¼š<br><br><br><br>## Absolute Position Embedding<br><br>absolute position embeddingã¯ã€å›ºå®šã•ã‚ŒãŸposition ãƒ™ã‚¯ãƒˆãƒ«ã€ã‚ã‚‹ã„ã¯trainableãªposition ãƒ™ã‚¯ãƒˆãƒ«pã‚’ã€å…¥åŠ›ãƒ™ã‚¯ãƒˆãƒ«ã«å¯¾ã—ã¦è¶³ã—åˆã‚ã›ã‚‹ï¼š<br><br>&lt;img width="382" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/0688c1bf-8699-48a5-9d95-06454550bbdf"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0688c1bf-8699-48a5-9d95-06454550bbdf"&lt;/a&gt;


&gt;<br><br><br><br>## Relative Position Embedding<br><br>ä¸€æ–¹ã€Relative Position Embeddingã¯ã€Queryã®ä½ç½®ã«å¯¾ã™ã‚‹ã€Key, Valueã®ç›¸å¯¾ä½ç½®ï¼ˆã¤ã¾ã‚Šã€mã¨nã®å·®ï¼‰ã«å¯¾ã—ã¦ã€trainableãªãƒ™ã‚¯ãƒˆãƒ« \tilde{p}_r ã‚’Key, ValueãŠã‚ˆã³ç›¸å¯¾è·é›¢rã”ã¨ã«ç”¨æ„ã—ã€ãã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’å…¥åŠ›ã«è¶³ã—åˆã‚ã›ã‚‹ã€ã¨ã„ã†å®šå¼åŒ–ã¨ãªã£ã¦ã„ã‚‹ï¼š<br><br><br>&lt;img width="269" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/ddb92f1a-af23-4d71-a7b9-2a7adda792e1"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/ddb92f1a-af23-4d71-a7b9-2a7adda792e1"&lt;/a&gt;


&gt;<br><br><br>ã“ã“ã§ã€r = clip(m-n, r_max, r_min)ã§ã‚ã‚Šã€r_max, r_minã¯è€ƒæ…®ã™ã‚‹ç›¸å¯¾è·é›¢ã®æœ€å¤§å€¤ã¨æœ€å°å€¤ã§ã‚ã‚‹ã€‚<br><br>ä»–ã«ã‚‚æ§˜ã€…ãªå®šå¼åŒ–ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ãŒãŸã„ã¦ã„å®šå¼åŒ–ã®ä¸­ã«ç›¸å¯¾ä½ç½®m-nãŒå‡ºç¾ã™ã‚‹ã€‚<br><br><br>## RoPE<br><br>RoPEã§ã¯ã€å…¥åŠ›ãƒ™ã‚¯ãƒˆãƒ«(Q,K)ã«å¯¾ã—ã¦å›è»¢è¡Œåˆ—ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã€å›è»¢ã«å¯¾ã—ã¦ä½ç½®æƒ…å ±ã‚’ä¿æŒã•ã›ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€ç•°ãªã‚‹ä½ç½®m, nã«å¯¾ã™ã‚‹q_m^T k_nã‚’è¨ˆç®—ã™ã‚‹ã¨ã€å›è»¢è¡Œåˆ—ã‚’Rã¨ã—ãŸå ´åˆå¼16ã«ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«å›è»¢è¡Œåˆ—Rã«ç›¸å¯¾ä½ç½®m-nãŒç¾ã‚Œï¼ˆã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šï¼‰ã€ç›¸å¯¾ä½ç½®ã‚’è€ƒæ…®ã—ãŸqkã®è¨ˆç®—ã«ãªã£ã¦ã„ã‚‹ã€‚[^1]<br><br><br>&lt;img width="705" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/fce1d06e-e346-4278-a77c-4c96795d5488"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/fce1d06e-e346-4278-a77c-4c96795d5488"&lt;/a&gt;


&gt;<br><br>&lt;img width="588" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/3f28103c-6a56-4016-8f50-d45fe28cd62a"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/3f28103c-6a56-4016-8f50-d45fe28cd62a"&lt;/a&gt;


&gt;<br><br><br>[^1]: (R_mq_m)^T R_nK_n = q_m^T (R_m^T R_n) k_n = q_m^T (R_{-m}R_n) k_n = q_m^T R_{n-m} k_n. ã“ã“ã§ã€R_m^T = R_{-m}ã§ã‚ã‚Šã€R_m R_n = R_{m+n}ã®æ€§è³ªã‚’ä½¿ã£ã¦ã„ã‚‹ã€‚<br><br><br>RoPEã¯ä¸‹è¨˜ã®ã‚ˆã†ãªæ€§è³ªã‚’æŒã¤ï¼š<br><br>- long-term decay: Î¸i = 10000âˆ’2i/d ã¨è¨­å®šã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€ç›¸å¯¾ä½ç½®ãŒé›¢ã‚Œã¦ã„ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ™ã‚¯ãƒˆãƒ«ã¨ã®inner productã®å€¤ãŒå°ã•ããªã‚‹ã€‚ã™ãªã‚ã¡ã€ä½ç½®ãŒé›¢ã‚Œã¦ã„ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³é–“ã®ä¾å­˜é–¢ä¿‚ãŒå°ã•ããªã‚‹ã€‚<br><br>- Linear-Attention: RoPEã¯å›è»¢è¡Œåˆ—ã§ã‚ã‚Šã€ä¹—ç®—å¾Œã®ãƒ™ã‚¯ãƒˆãƒ«ã®ãƒãƒ«ãƒ ã‚’å¤‰åŒ–ã•ã›ãªã„ã€‚ã“ã®ãŸã‚ã€Linear Attentionã®å¼ã®ä¸­ã«å›è»¢è¡Œåˆ—ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€Linear Attentionã¨ç°¡å˜ã«çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ãŒå¯èƒ½<br><br><br><br>Absolute Position Embedding, Relative Position Embeddingã§ã¯ã€ãƒ™ã‚¯ãƒˆãƒ«ã«å¯¾ã—ã¦ä½ç½®æƒ…å ±ã‚’åŠ ç®—ã™ã‚‹å®šå¼åŒ–ã§ K, Vã®è¨ˆç®—æ™‚ã«ä½ç½®æƒ…å ±ã‚’è€ƒæ…®ã—ã¦ã„ãŸãŸã‚ã€Linear Attentionã®è¨ˆç®—ãã®ã‚‚ã®ã«ä½ç½®æƒ…å ±ã‚’çµ„ã¿è¾¼ã‚“ã å®šå¼åŒ–ã¨ã¯ãªã£ã¦ã„ãªã‹ã£ãŸã€‚<br><br>ãŒã€RoPEã§ã¯å›è»¢è¡Œåˆ—ã‚’ä¹—ç®—ã™ã‚‹å®šå¼åŒ–ã§ã‚ã‚Šã€ãƒãƒ«ãƒ ã‚’å¤‰åŒ–ã•ã›ãªã„ã®ã§Linear Attentionã®å®šå¼åŒ–ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã‚‹ã€‚ã“ã®ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å¤§ããå¤‰æ›´ã—ãªãã¨ã‚‚çµ„ã¿è¾¼ã‚ã‚‹ã€‚<br><br></p>
<p>RoPEè‡ªä½“ã¯å®Ÿè£…ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¿…è¦ã¨ã—ãªã„ãŒã€ãƒ¢ãƒ‡ãƒ«ã®ãã®ä»–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒRoPEã«é©ç”¨ã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã¦ã„ãªã„ã¨é©ç”¨ã§ããªã„ã§ã‚ã‚ã†ç‚¹ã«ã¯æ³¨æ„ï¼ˆäº‹å‰å­¦ç¿’æ™‚ã«RoPEãŒä½¿ã‚ã‚Œã¦ã„ã‚Œã°è©±ã¯åˆ¥ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1297" target="_blank" rel="noopener noreferrer" class="title-link">AirLLM, 2024.04</a>
<span class="snippet"><span>Comment</span><p>4GBã®Single GPUã§ã€70Bãƒ¢ãƒ‡ãƒ«ã®inferenceã‚’å®Ÿç¾ã§ãã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆé€Ÿåº¦ã¯æ¤œè¨¼ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚transformer decoderã®å„layerã®æ¼”ç®—ã¯ç‹¬ç«‹ã—ã¦ã„ã‚‹ãŸã‚ã€GPUã«å…¨ã¦ã®layerã‚’è¼‰ã›ãšã€å¿…è¦ãªåˆ†ã ã‘è¼‰ã›ã¦inferenceã™ã‚‹ã¨ã„ã£ãŸæ“ä½œã‚’ç¹°ã‚Šè¿”ã™æ¨¡æ§˜ã€‚<br><br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rohanpaul_ai/status/1784349737899982943?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-04-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1289" target="_blank" rel="noopener noreferrer" class="title-link">LLaMA3, Meta, 2024.04</a>
<span class="snippet"><span>Comment</span><p>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«ã‚ˆã‚‹ã¨ã€LLaMA3ã‚’åˆ©ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã©ã‚“ãªå ´åˆã§ã‚‚Llama3ã‚’prefixã¨ã—ã¦ä»˜ä¸ã—ãªã„ã¨ã„ã‘ãªã„ã‚‰ã—ã„<br><br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1781083579273089442?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLaMA3ãŒChatBot Arenaã§Top 5ã«ãªã£ãŸã¨ã®ã“ã¨ã€‚ã¾ãŸã€è‹±èªã«ãŠã„ã¦ã¯ã€GPT4-1106-preview, GPT-4-turbo-2024-0409ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã€‚ã“ã‚Œã¯ã™ã”ã„â€¦<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lmsysorg/status/1782483699449332144?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>nejumi-leaderboard <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1055" target="_blank" rel="noopener noreferrer">Nejumi LLMãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰</a>
 ã«LLaMA3ã®è©•ä¾¡çµæœãŒæ²è¼‰ã•ã‚ŒãŸæ¨¡æ§˜ï¼ˆç”»åƒã¯ä¸‹è¨˜ãƒ„ã‚¤ãƒ¼ãƒˆã‚ˆã‚Šå¼•ç”¨ï¼‰<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2db1674b-80a6-4bbc-ab4b-c822e1659d6f" alt="image" loading="lazy"><br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/madyagi/status/1783707796095316310?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯Transformer Decoderã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ã¦ãŠã‚Šã€Llama2ã¨æ¯”è¼ƒã—ã¦<br><br>- Tokenizerã®Vocabã‚µã‚¤ã‚ºã‚’128Kã‚ˆã‚ŠåŠ¹ç‡çš„ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯èƒ½ã«<br><br>- GQA <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
 ã‚’åˆ©ç”¨ã—Inferenceã‚’é«˜é€ŸåŒ– (Llama2ã®æ™‚ç‚¹ã§GQAã‚’ä½¿ã£ã¦ã„ãŸãŒã€70Bãƒ¢ãƒ‡ãƒ«ã ã‘ã ã£ãŸ)<br><br>- self-attentionãŒã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è·¨ãŒãªã„ã‚ˆã†ã«å­¦ç¿’</p>
<p>context: 8192</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2024-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1285" target="_blank" rel="noopener noreferrer" class="title-link">Open Source Cookbook</a>
<span class="snippet"><span>Comment</span><p>HuggingFaceã«ã‚ˆã‚‹æ§˜ã€…ãªå®Ÿç”¨çš„ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®å®Ÿè£…ã‚„ãƒ¢ãƒ‡ãƒ«ã§å®Ÿç¾ã™ã‚‹ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ãŒã¾ã¨ã¾ã£ãŸãƒªãƒã‚¸ãƒˆãƒªã€‚LLM-as-a-judge, RAG, PEFTã«ã‚ˆã‚‹Prompt Tuningï¼ˆPrefix Tuningã¨ã‹ãã£ã¡ç³»ã®è©±ã ã¨æ€ã‚ã‚Œã‚‹ï¼‰ãªã©ã€ç¾åœ¨16ç¨®é¡ã»ã©ã‚ã‚‹ã‚‰ã—ã„ã€‚</p>
<p>æ”¹ã‚ã¦è¦‹ãŸã‚‰æ•°ãŒã‹ãªã‚Šå¢—ãˆã¦ã„ãŸ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2024-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1281" target="_blank" rel="noopener noreferrer" class="title-link">Grok-1.5 Vision Preview, 2024</a>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/88dd70ce-5874-4786-8e66-7484984c7a72" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-04-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1279" target="_blank" rel="noopener noreferrer" class="title-link">Mixtral-8x22B-v0.1, 2024</a>
<span class="snippet"><span>Comment</span><p>Apache-2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹, æ—¥æœ¬èªéå¯¾å¿œ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2024-04-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1278" target="_blank" rel="noopener noreferrer" class="title-link">Command R+, Cohere, 2024</a>
<span class="snippet"><span>Comment</span><p>Chatbot arenaã§GPT-4-0314ã¨åŒç­‰ã® Elo Rate ã‚’ç²å¾—ã—ï¼ˆ20240410æ™‚ç‚¹ï¼‰ã€æ—¥æœ¬èªã‚’å«ã‚€10ãƒ¶å›½èªã‚’ã‚µãƒãƒ¼ãƒˆã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º128kã€‚å•†ç”¨åˆ©ç”¨ã¯APIã‹ã‚‰ã€ç ”ç©¶ç›®çš„ã§ã‚ã‚Œã°HuggingFaceã‹ã‚‰åˆ©ç”¨å¯èƒ½ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9571e233-f936-4327-af60-3c2ce57aad71" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2024-04-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1277" target="_blank" rel="noopener noreferrer" class="title-link">Gemma: Open Models Based on Gemini Research and Technology, 2024</a>
<span class="snippet"><span>Comment</span><p>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯Transformer Decoderã‚’åˆ©ç”¨ã€‚ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã¯2Bã¨7Bã€‚<br><br>ã‚ªãƒªã‚¸ãƒŠãƒ«ã®Transformer Decoderã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‹ã‚‰ã€ä¸‹è¨˜æ”¹å–„ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ï¼š<br><br>- Multi Query Attention <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1272" target="_blank" rel="noopener noreferrer">Fast Transformer Decoding: One Write-Head is All You Need, Noam Shazeer, N/A, arXiv'19</a>
 ã‚’åˆ©ç”¨<br><br>- RoPE Embedding <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1310" target="_blank" rel="noopener noreferrer">RoFormer: Enhanced Transformer with Rotary Position Embedding, Jianlin Su+, N/A, Neurocomputing, 2024</a>
 ã‚’åˆ©ç”¨<br><br>- GeGLU <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1311" target="_blank" rel="noopener noreferrer">GLU Variants Improve Transformer, Noam Shazeer, N/A, arXiv'20</a>
 ã®åˆ©ç”¨<br><br>- RMSNormã®åˆ©ç”¨ï¼ˆå­¦ç¿’ã‚’å®‰å®šã•ã›ã‚‹ãŸã‚; LLaMAã¨åŒæ§˜ï¼‰<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ef8dd419-fcce-49f5-8fd2-2acc4348d880" alt="image" loading="lazy"><br><br></p>
<p>Mistral <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1309" target="_blank" rel="noopener noreferrer">Mistral 7B, Albert Q. Jiang+, N/A, arXiv'23</a>
 ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ï¼š<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/24d6892b-ca8e-48bc-92bf-7eae71466918" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4cf6b9c6-d517-4d9d-9cdb-526560d1a097" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-04-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1265" target="_blank" rel="noopener noreferrer" class="title-link">LLMã®ç¾åœ¨, 202404, Preffered Elements</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-03-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1260" target="_blank" rel="noopener noreferrer" class="title-link">Awesome LM with Tools</a>
<span class="snippet"><span>Comment</span><p>Toolã‚’åˆ©ç”¨ã™ã‚‹LMã«é–¢ã™ã‚‹Neubigæ°ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«ã‚ˆã‚‹Surveyã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/TextualInversion.html" target="_blank" rel="noopener noreferrer">#TextualInversion</a>
<span class="issue_date">Issue Date: 2024-03-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1258" target="_blank" rel="noopener noreferrer" class="title-link">repeng</a>
<span class="snippet"><span>Comment</span><p>LLMã®å‡ºåŠ›ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’æ•°ç™¾å€‹ã®äº‹ä¾‹ã ã‘ã§å­¦ç¿’ã—ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚promptã§æŒ‡å®šã™ã‚‹ã®ã¨ã¯ç•°ãªã‚Šã€æ•°å€¤ã§ã‚¹ã‚¿ã‚¤ãƒ«ã®å¼·ã•ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ãŒå¯èƒ½ã‚‰ã—ã„ï¼ˆå…ƒãƒ„ã‚¤ãƒ¼ãƒˆï¼‰ã€‚ç”»åƒç”Ÿæˆåˆ†é‡ã«ãŠã‘ã‚‹Textual Inversionã¨åŒã˜æŠ€è¡“ã¨ã®ã“ã¨ã€‚<br><br>Textual Inversionã¨ã¯ã€å°‘é‡ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”¨ã„ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€éƒ¨åˆ†ã«æ–°ãŸãªã€Œå˜èªã€ã‚’è¿½åŠ ã—ã€å˜èªã¨å¯¾å¿œã™ã‚‹ç”»åƒã‚’ç”¨ã„ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã“ã¨ã§ã€promptä¸­ã§ã€Œå˜èªã€ã‚’åˆ©ç”¨ã—ãŸå ´åˆã«å­¦ç¿’ã—ãŸç”»åƒã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆã‚ªãƒªã‚¸ãƒŠãƒ«ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªãã¦ã‚‚å¯ï¼‰ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹æŠ€è¡“ã€ã‚‰ã—ã„ã€‚<br><br>Huggiegface: 


<a href="https://huggingface.co/docs/diffusers/training/text_inversion" target="_blank" rel="noopener noreferrer">https://huggingface.co/docs/diffusers/training/text_inversion</a>


<br>ï¼ˆå‚è€ƒï¼‰GPTã«è³ªå•ã—ãŸéš›ã®ãƒ­ã‚°: 


<a href="https://chat.openai.com/share/e4558c44-ce09-417f-9c77-6f3855e583fa" target="_blank" rel="noopener noreferrer">https://chat.openai.com/share/e4558c44-ce09-417f-9c77-6f3855e583fa</a>


<br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1770272397184389211?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-03-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1256" target="_blank" rel="noopener noreferrer" class="title-link">Open Release of Grok-1  March 17, 2024</a>
<span class="snippet"><span>Comment</span><p>Apache2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹, 314Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã€Mixture-of-Expertsã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã€å­¦ç¿’ã«åˆ©ç”¨ã—ãŸã‚³ãƒ¼ãƒ‰ã¯ãŠãã‚‰ãå…¬é–‹ã•ã‚Œã¦ã„ãªã„ã€‚</p>
<p>Grok-1.5ãŒãƒªãƒªãƒ¼ã‚¹<br>


<a href="https://x.ai/blog/grok-1.5" target="_blank" rel="noopener noreferrer">https://x.ai/blog/grok-1.5</a>


<br><br>å„ç¨®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ€§èƒ½ã€ç‰¹ã«Mathã®æ€§èƒ½ãŒå‘ä¸Šã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ãŒ128kã«<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0e8f357f-f583-4a11-bf20-49e9886cf6e9" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-03-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1249" target="_blank" rel="noopener noreferrer" class="title-link">RAG-Research-Insights</a>
<span class="snippet"><span>Comment</span><p>RAGã«é–¢ã™ã‚‹ç ”ç©¶ãŒç›´è¿‘ã®ã‚‚ã®ã¾ã§ã‚ˆãã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-03-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1242" target="_blank" rel="noopener noreferrer" class="title-link">What are the most important LLMs to know about in March 2024?</a>
<span class="snippet"><span>Comment</span><p>2024å¹´3æœˆæ™‚ç‚¹ã§çŸ¥ã£ã¦ãŠãã¹ãLLMã«é–¢ã™ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-02-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1237" target="_blank" rel="noopener noreferrer" class="title-link">Mistral Large</a>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2d9066bd-05e5-4942-8d27-e5b50d129ade" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-02-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1229" target="_blank" rel="noopener noreferrer" class="title-link">RAGã®æ€§èƒ½ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®8ã¤ã®æˆ¦ç•¥</a>
<span class="snippet"><span>Comment</span><p>ã‚ã¡ã‚ƒã‚ã¡ã‚ƒè©³ç´°ã«RAGæ€§èƒ½å‘ä¸Šã®æ‰‹æ³•ãŒreferenceä»˜ãã§ã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚ã™ã”ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/InformationExtraction.html" target="_blank" rel="noopener noreferrer">#InformationExtraction</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-01-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1209" target="_blank" rel="noopener noreferrer" class="title-link">LLMã«ãŠã‘ã‚‹æƒ…å ±æŠ½å‡ºï¼ˆæ–‡ç« ã‹ã‚‰å¿…è¦ãªäº‹æŸ„ã‚’èª­ã¿å–ã‚‹ï¼‰ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦ã®èª¿æŸ», AIDB</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1203" target="_blank" rel="noopener noreferrer" class="title-link">Decoding Strategies that You Need to Know for Response Generation</a>
<span class="snippet"><span>Comment</span><p>è¨€èªãƒ¢ãƒ‡ãƒ«ã®decodingã®æ–¹æ³•ã«ã¤ã„ã¦ã‚ˆãã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚ã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹decodingæ–¹æ³•ã¯ä»¥ä¸‹<br><br>- Greedy, BeamSearch, RandomSampling, Temperature, Top-K Sampling, Nucleus Sampling</p>
<p>ã“ã¡ã‚‰ã®è¨˜äº‹ã§ã¯HuggingFaceã§ã®å®Ÿè£…ã‚„ä»–ã®decodingæ–¹æ³•ç­‰ã€ã‚ˆã‚Šå®Ÿè£…é¢ã§ã®è©³ç´°ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ï¼š<br><br>


<a href="https://note.com/npaka/n/n9a8c85f2ef7a" target="_blank" rel="noopener noreferrer">https://note.com/npaka/n/n9a8c85f2ef7a</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-12-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1196" target="_blank" rel="noopener noreferrer" class="title-link">Structured Hierarchical Retrieval, llama-index</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/llama_index/status/1737515390664872040?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-12-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1188" target="_blank" rel="noopener noreferrer" class="title-link">optimize-llm, HuggingFace</a>
<span class="snippet"><span>Comment</span><p>LLMã‚’optimizeã™ã‚‹å®Ÿç”¨çš„ãªãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«</p>
<p>ã“ã¡ã‚‰ã‚‚æœ‰ç”¨ãªã®ã§å‚ç…§ã®ã“ã¨<br><br><br><br>ã€GPU inferenceã€‘<br><br>


<a href="https://huggingface.co/docs/transformers/main/perf_infer_gpu_one" target="_blank" rel="noopener noreferrer">https://huggingface.co/docs/transformers/main/perf_infer_gpu_one</a>


<br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2023-12-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1187" target="_blank" rel="noopener noreferrer" class="title-link">ã€ç¶šã€‘Flash Attentionã‚’ä½¿ã£ã¦LLMã®æ¨è«–ã‚’é«˜é€Ÿãƒ»è»½é‡åŒ–ã§ãã‚‹ã‹ï¼Ÿ</a>
<span class="snippet"><span>Comment</span><p>use_cacheãŒTrue/Falseã®å ´åˆã®FlashAttention2ã®inference timeã¨VRAMä½¿ç”¨é‡ã®å‚¾å‘ã‚’sequence_lengthã”ã¨ã«è€ƒå¯Ÿã—ã¦ã„ã‚‹ã€‚<br><br>use_cacheã¯Key Value cacheã®ã‚ªãƒ³ã‚ªãƒ•ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‰ã‚Œã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã‚ã‚‹ã€‚autoregressiveãªãƒ¢ãƒ‡ãƒ«ã®inferenceæ™‚ã«ã¯ã€ä½•åº¦ã‚‚åŒã˜input tokenã«å¯¾ã™ã‚‹KVã®è¨ˆç®—ãŒç”Ÿã˜ã‚‹ãŸã‚ï¼ˆMç•ªç›®ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã—ãŸå¾Œã€M+1ç•ªç›®ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆã‚’ã™ã‚‹å ´åˆã€M-1ç•ªç›®ã¾ã§ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®KVã‚’å†è¨ˆç®—ã›ã­ã°ãªã‚‰ãªã„ï¼‰ã€cacheã‚’ã™ã‚‹ã“ã¨ã§å¤§å¹…ã«è¨ˆç®—é€Ÿåº¦ãŒæ”¹å–„ã•ã‚Œã‚‹ã€‚<br><br>use_cacheã‚’Trueã«ã§ãã‚‹ãªã‚‰FlashAttention2ã®æ©æµã¯å°ã•ã„ï¼ˆinference timeãŒå°‘ã—æ—©ããªã‚‹ã®ã¿ï¼‰ãŸã‚ã€æ½¤æ²¢ãªVRAMãŒã‚ã‚‹ãªã‚‰å¾—ã‚‰ã‚Œã‚‹æ©æµã¯å°ã•ã„ã€‚<br>é€†ã«VRAMç¯€ç´„ã—ã¦use_cacheã‚’Falseã«ã›ã–ã‚‹ã‚’å¾—ãªã„ã®ã§ã‚ã‚Œã°ã€FlashAttention2ã«ã‚ˆã‚ŠVRAMä½¿ç”¨é‡ã‚’sequence_legthã®ç·šå½¢ã«æŠ‘ãˆã‚‹ã“ã¨ãŒã§ãã€ã‹ã¤inference timeã‚‚çŸ­ããªã‚‹ã€‚<br><br>â†‘ä¸Šè¨˜ã¯ã‚ãã¾ã§inferenceã‚’ã™ã‚‹å ´åˆã®ã¿ã®è©±ã§ã‚ã‚Šï¼ˆtrainæ™‚ã¯autoregressive modelã§ã¯causal maskã‚’ç”¨ã„ã€teacher forcingã§ä¸¦åˆ—ã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ãã‚‚ãã‚‚KV-cacheã™ã‚‹æ„å‘³ãŒãªã„ï¼‰ã€trainingã‚’ã™ã‚‹å ´åˆFlashAttention2ã§å¤§å¹…ã«VRAMä½¿ç”¨é‡ã‚’æ¸›ã‚‰ã›ã‚‹ã®ã§ã€ãã“ã¯åˆ†ã‘ã¦è€ƒãˆã‚‹ã“ã¨ã€‚<br>


<a href="https://qiita.com/jovyan/items/ff3d0a49163c7afa33ce" target="_blank" rel="noopener noreferrer">https://qiita.com/jovyan/items/ff3d0a49163c7afa33ce</a>


</p>
<p>Flash Attentionã‚’ä½¿ã£ã¦LLMã®æ¨è«–ã‚’é«˜é€Ÿãƒ»è»½é‡åŒ–ã§ãã‚‹ã‹ï¼Ÿ<br>


<a href="https://qiita.com/jovyan/items/11deb9d4601e4705a60d" target="_blank" rel="noopener noreferrer">https://qiita.com/jovyan/items/11deb9d4601e4705a60d</a>


<br><br>ã“ã¡ã‚‰ã®è¨˜äº‹ã‚‚éå¸¸ã«å‹‰å¼·ã«ãªã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2023-12-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1183" target="_blank" rel="noopener noreferrer" class="title-link">A Review of Public Japanese Training Sets, shisa, 2023.12</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ProprietaryLLM.html" target="_blank" rel="noopener noreferrer">#ProprietaryLLM</a>
<span class="issue_date">Issue Date: 2023-12-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1181" target="_blank" rel="noopener noreferrer" class="title-link">Gemini, Google, 2023.12</a>
<span class="snippet"><span>Comment</span><p>å¤šãã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§GPT4è¶…ãˆã‚‰ã—ã„<br><br>ï¼ˆè¿½è¨˜1ï¼‰<br>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã®p.44ã‚’è¦‹ã‚‹ã¨ã€ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆä¸­ã®GPT4ã®MMLUã®ã‚¹ã‚³ã‚¢ã¯GPT-4-0613ã®ã‚‚ã®ã®ã‚ˆã†ãªã®ã§ã€ã“ã‚ŒãŒæ­£ã—ã„ã¨ã™ã‚‹ã¨ä»–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚¹ã‚³ã‚¢ã‚‚åŒãƒ¢ãƒ‡ãƒ«ã®ã‚‚ã®ã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ãã€GPT-4-1163-previewï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ï¼‰ã®ã‚¹ã‚³ã‚¢ã§ã¯"ãªã„ã‹ã‚‚ã—ã‚Œãªã„"ç‚¹ã«æ³¨æ„ã€‚GPT4ã¨ã©ã¡ã‚‰ãŒå®Ÿéš›ã«æ€§èƒ½ãŒè‰¯ã„ã‹?ã«ã¤ã„ã¦ã¯æ§˜å­è¦‹ã—ãŸæ–¹ãŒè‰¯ã•ãã†ã€‚<br><br>ï¼ˆè¿½è¨˜2ï¼‰<br>GSM8Kã®çµæœã‚‚ã€GPT4ã«å¯¾ã—ã¦Fair Comparisonã§ã¯ãªã„ã‹ã‚‚ã—ã‚Œãªã„ç‚¹ã«æ³¨æ„ã€‚Geminiã¯32å€‹ã®CoTã¨Self-Consistencyã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ãŒã€GPT4ã§ã¯5-shotã§å˜ä¸€ã®CoTã®ã¿ã§ã‚ã‚‹ãŸã‚ã€promptingæ‰‹æ³•ã§ã¯Geminiã«æœ‰åˆ©ãªæ¯”è¼ƒã¨ãªã£ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ãŸã ã—GPT4ã¯GSM8Kã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’äº‹å‰å­¦ç¿’æ™‚ã«MIXã—ã¦ã„ã‚‹ï¼ˆSFTï¼‰ã®ã§ã€GeminiãŒã“ã®ã‚ˆã†ãªã“ã¨ã‚’ã—ã¦ã„ãªã„ã®ã§ã‚ã‚Œã°ã€ã“ã®ç‚¹ã§ã¯GPT4ãŒæœ‰åˆ©ã«ãªã£ã¦ã„ã‚‹â€œå¯èƒ½æ€§â€ãŒã‚ã‚‹ã€‚<br><br>ä»–ã«ã‚‚Fair Comparisonã«ãªã£ã¦ã„ãªã„ã¨æ¨å¯Ÿã•ã‚Œã‚‹ã‚‚ã®ã¯Textãƒ¢ãƒ€ãƒªãƒ†ã‚£ã§ã®è©•ä¾¡ã®è¡¨ã®æ–‡è¨€ã‚’è¦‹ã‚‹ã¨ã‚ã‚Šãã†ãªã®ã§ãã“ã¯å¿µé ­ã«ãŠã„ãŸæ–¹ãŒè‰¯ã•ãã†ã§ã‚ã‚‹ã€‚</p>
<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ: 


<a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf" target="_blank" rel="noopener noreferrer">https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf</a>


</p>
<p>Gemini Summary<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/srush_nlp/status/1732427569352323401?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MMLUã§ã®åŒã˜promptingæ‰‹æ³•ã§ã®GPT-4-0613ã¨ã®æ¯”è¼ƒã€‚32å€‹ã®CoTã§ã®Self-Consistencyã§æ¯”è¼ƒã—ãŸå ´åˆã€GPT-4-0613ã«è² ã‘ã¦ã„ã‚‹ãŒã€é–¾å€¤ã‚’è¨­ã‘ã¦confidenceãŒé–¾å€¤ä»¥ä¸Šã®å ´åˆã¯Self-consistency, ãã†ã§ãªã„å ´åˆã¯greedyã«ç”Ÿæˆã—ãŸçµæœã‚’é¸æŠã™ã‚‹ã€ã¨ã„ã†Uncertain-Routed CoT@32ã§ã¯ã€Geminiã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹gainãŒå¤§ããGPT-4-0613ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br>ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆä¸­ã®GPT4ã®ã‚¹ã‚³ã‚¢ã¯5-shotã®ã‚‚ã®ï¼ˆreportedã¨æ›¸ã‹ã‚Œã¦ã„ã‚‹ã®ã§OpenAIãŒå…¬è¡¨ã—ã¦ã„ã‚‹æ•°å€¤ã¨æ¨å¯Ÿï¼‰ã§ã‚ã‚Šã€Geminiã®çµæœã¯Uncertain-Routed CoT@32ã®çµæœã§ã‚ã‚‹ãŸã‚ã€Fair Comparisonã«ãªã£ã¦ã„ãªã„ã‹ã‚‚ã—ã‚Œãªã„ï¼Ÿç‚¹ã«ã¯æ³¨æ„ã€‚<br><br>ãƒ¬ãƒãƒ¼ãƒˆä¸­ã§ã¯Self-consistencyã¨ã„ã†å˜èªã§ã“ã®éƒ¨åˆ†ã¯æ›¸ã‹ã‚Œã¦ã„ãªã„ãŒã€å®Ÿã¯å°‘ã—ã‚„ã£ã¦ã„ã‚‹ã“ã¨é•ã£ã¦ãŸã‚Šã™ã‚‹â€¦ï¼Ÿ<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ab56b7e0-464a-4e29-84e7-7d1540ef2119" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-12-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1173" target="_blank" rel="noopener noreferrer" class="title-link">kaggle LLM ã‚³ãƒ³ãƒš ä¸Šä½è§£æ³•ã‚’è‡ªåˆ†ãªã‚Šã«ã¾ã¨ã‚ã¦ã¿ãŸè©±</a>
<span class="snippet"><span>Comment</span><p>å®Ÿè·µçš„ãªå†…å®¹ï¼ˆãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆæ™‚ã®å·¥å¤«ã€ã‚¯ã‚¨ãƒªç”Ÿæˆæ™‚ã®å·¥å¤«ç­‰ï¼‰ãŒç¶²ç¾…çš„ã«ã¾ã¨ã¾ã£ã¦ãŠã‚Šéå¸¸ã«æœ‰ç”¨</p>
<p>å€‹äººçš„ã«ã€ã‚³ãƒ³ãƒšä¸»å‚¬è€…å´ã‹ã‚‰æä¾›ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªãã€ä¸Šä½ã®ã»ã¨ã‚“ã©ã®ãƒãƒ¼ãƒ ãŒChatGPTï¼ˆ3.5, 4ï¼‰ã‚’ç”¨ã„ã¦ã€QAãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ã„ãŸã€ã¨ã„ã†ã®ãŒèˆˆå‘³æ·±ã‹ã£ãŸã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ãŸã¨ãˆã°ä¸‹è¨˜:<br><br>[ï¼ˆ5th-place-solutionï¼‰](


<a href="https://www.kaggle.com/competitions/kaggle-llm-science-exam/discussion/446293)%E3%82%88%E3%82%8A%E5%BC%95%E7%94%A8" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/competitions/kaggle-llm-science-exam/discussion/446293)ã‚ˆã‚Šå¼•ç”¨</a>


<br><br>```<br><br>system_content = """<br><br>Forget all the previous instruction and rigorously follow the rule specified by the user.<br><br>You are a professional scientist's assistant.<br><br>"""<br><br><br><br>user_content_template_qa = Template(<br><br>    """<br><br>Please consider 5 choices question and answer of the following TEXT.<br><br>The purpose of this question is to check respondent's deep science understanding of the TEXT.<br><br>We assume this question is for professional scientists, so consider super difficult question.<br><br>You can ask very detailed question, for example check specific sentence's understanding.<br><br>It is good practice to randomly choose specific sentence from given TEXT, and make QA based on this specific sentence.<br><br>You must make QA based on the fact written in the TEXT.<br><br>You may create wrong answers based on the correct answer's information, by modifying some parts of the correct answer.<br><br>Your response must be in following format, don't write any other information. <br><br>You must not include "new line" in each Q), 1), 2), 3), 4), 5), and A):<br><br>Q) `question text comes here`<br><br>1) `answer candidate 1`<br><br>2) `answer candidate 2`<br><br>3) `answer candidate 3`<br><br>4) `answer candidate 4`<br><br>5) `answer candidate 5`<br><br>A) `answer`<br><br><br><br>where only 1 `answer candidate` is the correct answer and other 4 choices must be wrong answer.<br><br>Note1: I want to make the question very difficult, so please make wrong answer to be not trivial incorrect.<br><br>Note2: The answer candidates should be long sentences around 30 words, not the single word.<br><br>Note3: `answer` must be 1, 2, 3, 4 or 5. `answer` must not contain any other words.<br><br>Note4: Example of the question are "What is ...", "Which of the following statements ...", "What did `the person` do",<br><br>and "What was ...".<br><br>Note5: Question should be science, technology, engineering and mathematics related topic. <br><br>If the given TEXT is completely difference from science, then just output "skip" instead of QA.<br><br><br><br><br><br>Here is an example of your response, please consider this kind of difficulty when you create Q&amp;A:<br><br>Q) Which of the following statements accurately describes the impact of Modified Newtonian Dynamics (MOND) on the observed "missing baryonic mass" discrepancy in galaxy clusters?"<br><br>1) MOND is a theory that reduces the observed missing baryonic mass in galaxy clusters by postulating the existence of a new form of matter called "fuzzy dark matter."<br><br>2) MOND is a theory that increases the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions from a factor of around 10 to a factor of about 20.<br><br>3) MOND is a theory that explains the missing baryonic mass in galaxy clusters that was previously considered dark matter by demonstrating that the mass is in the form of neutrinos and axions.<br><br>4) MOND is a theory that reduces the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions from a factor of around 10 to a factor of about 2.<br><br>5) MOND is a theory that eliminates the observed missing baryonic mass in galaxy clusters by imposing a new mathematical formulation of gravity that does not require the existence of dark matter.<br><br>A) 4<br><br><br><br>Let's start. Here is TEXT: $title\n$text<br><br>"""<br><br>)<br><br>```</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<span class="issue_date">Issue Date: 2023-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1171" target="_blank" rel="noopener noreferrer" class="title-link">multimodal-maestro</a>
<span class="snippet"><span>Comment</span><p>Large Multimodal Model (LMM)ã«ãŠã„ã¦ã€é›‘ãªpromptã‚’ä¸ãˆã‚‹ã¦ã‚‚è‡ªå‹•çš„ã«è‰¯ã„æ„Ÿã˜outputã‚’ç”Ÿæˆã—ã¦ãã‚Œã‚‹ã£ã½ã„ï¼Ÿ<br><br><br><br>ä»¥ä¸‹ã®ä¾‹ã¯ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰ã®å¼•ç”¨ã§ã‚ã‚‹ãŒã€ã“ã®ä¾‹ã§ã¯ã€"Find dog." ã¨ã„ã†é›‘ãªpromptã‹ã‚‰ã€ç”»åƒä¸­å¤®ã«ä½ç½®ã™ã‚‹çŠ¬ã«[9]ã¨ã„ã†ãƒ©ãƒ™ãƒ«ã‚’ä¸ãˆã¾ã—ãŸã€ã¨ã„ã†responseã‚’å¾—ã‚‰ã‚Œã¦ã„ã‚‹ã€‚pipelineã¨ã—ã¦ã¯ã€Visual Promptã«å¯¾ã—ã¦ã¾ãšSAMã‚’ç”¨ã„ã¦ã‚¤ãƒ¡ãƒ¼ã‚¸ã®segmentationã‚’è¡Œã„ã€å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«ãƒ©ãƒ™ãƒ«ã‚’æŒ¯ã‚‹ã€‚ã“ã®ãƒ©ãƒ™ãƒ«ãŒæŒ¯ã‚‰ã‚ŒãŸç”»åƒã¨ã€"Find dog." ã¨ã„ã†é›‘ãªpromptã‚’ä¸ãˆã‚‹ã ã‘ã§è‰¯ã„æ„Ÿã˜ã«å‡¦ç†ã‚’ã—ã¦ãã‚Œã‚‹ã‚ˆã†ã ã€‚    <br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5220e62f-93f1-4eb9-b365-a9caaf933778" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2023-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1170" target="_blank" rel="noopener noreferrer" class="title-link">LaVie: Text-to-Video generation, demo</a>
<span class="snippet"><span>Comment</span><p>ãƒ‡ãƒ¢ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è©¦ã—ã¦ã¿ãŸã‚‰ã€3ç§’ã»ã©ã®prompté€šã‚Šã®å‹•ç”»ãŒç”Ÿæˆã•ã‚ŒãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4343fa52-698c-4a59-bad0-758fcd30d3ac" alt="image" loading="lazy"><br><br></p>
<p>FF14ã®èµ¤é­”å°å£«ã«å¤‰ãˆãŸã‚‰ã€ãã‚Œã£ã½ã„ã®å‡ºã¦ããŸ<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/07b6def8-01f2-4baf-9ba3-ab1ccc40c90e" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<span class="issue_date">Issue Date: 2023-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1167" target="_blank" rel="noopener noreferrer" class="title-link">Table Transformer Demo</a>
<span class="snippet"><span>Comment</span><p>PDFä¸­ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ãã®æ§‹é€ ï¼ˆè¡Œåˆ—ã‚»ãƒ«ï¼‰ã‚’detectã™ã‚‹ãƒ¢ãƒ‡ãƒ«<br><br>Exampleã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ„Ÿã˜ï¼ˆæ—¥æœ¬èªã ã¨ã©ã‚Œãã‚‰ã„ã§ãã‚‹ã®ã‹ãª...ï¼‰<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7f62e16b-1ff8-46ad-b6df-7792981f8f58" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<span class="issue_date">Issue Date: 2023-11-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1156" target="_blank" rel="noopener noreferrer" class="title-link">ML Papers Explained</a>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹ã®åˆ†é‡ã®ä»£è¡¨çš„ãªè«–æ–‡ãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ï¼ˆåŸºæœ¬çš„ã«ã¯Transformerç™»å ´å¾Œã®ã‚‚ã®ãŒå¤šã„ï¼‰<br><br>- è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆTransformer, Elmoãªã©ï¼‰<br>- Visionãƒ¢ãƒ‡ãƒ«ï¼ˆViTãªã©ï¼‰<br>- CNNï¼ˆAlexNetãªã©ï¼‰<br>- Single Stage Object Detectors<br>- Region-based Convolutional Neural Networks<br>- DocumentAIï¼ˆTableNetãªã©ï¼‰<br>- Layout Transformers<br>- Tabular Deeplearning</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2023-11-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1150" target="_blank" rel="noopener noreferrer" class="title-link">GPT4All, 2023</a>
<span class="snippet"><span>Comment</span><p>ãƒ­ãƒ¼ã‚«ãƒ«ãƒã‚·ãƒ³ã§ChatGPT likeãªUIã§ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’å‹•ä½œã•ã›ã‚‰ã‚Œã‚‹Opensourceã€‚<br>Mistral7Bã‚„GGUFãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ¢ãƒ‡ãƒ«ã®ã‚ˆã¤ãªï¼ˆãŠãã‚‰ãé‡å­åŒ–ã•ã‚ŒãŸã‚‚ã®ã‚‚å«ã‚€ï¼‰ãƒ­ãƒ¼ã‚«ãƒ«ãƒã‚·ãƒ³ã§å‹•ä½œã•ã›ã‚‰ã‚Œã‚‹è¦æ¨¡æ„Ÿã®ãƒ¢ãƒ‡ãƒ«ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã€‚<br>


<a href="https://gpt4all.io/index.html" target="_blank" rel="noopener noreferrer">https://gpt4all.io/index.html</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-11-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1149" target="_blank" rel="noopener noreferrer" class="title-link">Zephyr-7B-beta, RAG Perf.</a>
<span class="snippet"><span>Comment</span><p>Zephyr-7B-betaã®RAGã§ã®æ€§èƒ½ãŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹</p>
<p>ä¸‹è¨˜Xãƒã‚¹ãƒˆã«ã‚ˆã‚‹ã¨gpt-3.5-turboã¨åŒç­‰<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rungalileo/status/1726638537767051436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-11-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1146" target="_blank" rel="noopener noreferrer" class="title-link">Practical Tips for Finetuning LLMs Using LoRA ï¼ˆLow-Rank Adaptationï¼‰, SEBASTIAN RASCHKA, PHD, 2023.11</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-11-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1136" target="_blank" rel="noopener noreferrer" class="title-link">ChatGPTã«ç¤¾å†…æ–‡æ›¸ã«åŸºã¥ã„ãŸå›ç­”ã‚’ç”Ÿæˆã•ã›ã‚‹ä»•çµ„ã¿ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸ, 2023</a>
<span class="snippet"><span>Comment</span><p>ä½ã‚³ã‚¹ãƒˆã§ç¤¾å†…æ–‡æ›¸ã«å¯¾ã™ã‚‹RAGã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã«æ³¨åŠ›ã—ã¦ã„ã‚‹ã€‚<br>ä»¥ä¸‹ã€å›³ã¯ãƒ–ãƒ­ã‚°ã‹ã‚‰å¼•ç”¨ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5f71b0b7-14bb-442d-99c8-09a0b3840210" alt="image" loading="lazy"><br><br>åŸºæœ¬çš„ã«ã¯ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ã§ç¤¾å†…æ–‡æ›¸ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—S3ã¸æ ¼ç´ã€‚ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«S3ã‹ã‚‰æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿æ¤œç´¢å¯èƒ½ã«ã—RAGã™ã‚‹ã¨ã„ã†æµã‚Œã€‚<br>ä½ã‚³ã‚¹ãƒˆåŒ–ã®ãŸã‚ã«ã€Embeddingä½œæˆã«OpenSourceã®è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆtext-edbedding-ada002ã¨åŒç­‰ã®æ€§èƒ½ï¼‰ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã€‚å®Ÿè£…ã¯åŸºæœ¬çš„ã«llamaindexã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã€‚</p>
<p>ç‰¹ã«æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã«ãŠã„ã¦ã¯text-embedding-ada002ã¯ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/910" target="_blank" rel="noopener noreferrer">OpenAI ã® Embeddings API ã¯ã‚¤ã‚±ã¦ã‚‹ã®ã‹ã€å®šé‡çš„ã«èª¿ã¹ã¦ã¿ã‚‹</a>
 ã«ãŠã„ã¦ã€JSTSã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã‚ã¾ã‚Šæ€§èƒ½ãŒé«˜ããªã„ï¼ˆãŸã ã—ã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/910" target="_blank" rel="noopener noreferrer">OpenAI ã® Embeddings API ã¯ã‚¤ã‚±ã¦ã‚‹ã®ã‹ã€å®šé‡çš„ã«èª¿ã¹ã¦ã¿ã‚‹</a>
 ã§ã®å ±å‘Šå€¤ã¯åŸºæœ¬çš„ã«JSTSãƒ‡ãƒ¼ã‚¿ã§finetuningã•ã‚Œã¦ãŸçµæœã¨æ€ã‚ã‚Œã‚‹ï¼‰ã¨è¨€ã‚ã‚Œã¦ã„ã‚‹ã®ã§ã€ãŠé‡‘ã‹ã‘ã¦ç„¡ç†ã—ã¦ä½¿ã†å¿…è¦ã¯ãªã„ã®ã‹ãªã¨ã„ã†å°è±¡ã¯ã‚ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2023-11-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1134" target="_blank" rel="noopener noreferrer" class="title-link">LLaMA-Factory, 2023</a>
<span class="snippet"><span>Comment</span><p>ç°¡å˜ã«åˆ©ç”¨ã§ãã‚‹LLaMAã®finetuning frameworkã¨ã®ã“ã¨ã€‚<br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1724456693378040195?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLaMAãƒ™ãƒ¼ã‚¹ãªãƒ¢ãƒ‡ãƒ«ãªã‚‰è‰²ã€…å¯¾å¿œã—ã¦ã„ã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2023-11-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1130" target="_blank" rel="noopener noreferrer" class="title-link">Hallucination Leaderboard, 2023</a>
<span class="snippet"><span>Comment</span><p>1000å€‹ã®çŸ­ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¯¾ã—ã¦ã€äº‹å®Ÿæƒ…å ±ã®ã¿ã‚’ç”¨ã„ã¦è¦ç´„ã‚’ç”Ÿæˆã•ã›ã€è¦ç´„çµæœã¨åŸæ–‡æ›¸ã®Factual consistencyã‚’åˆ¥ã«è¨“ç·´ã—ãŸãƒ¢ãƒ‡ãƒ«ã§æ¸¬å®šã—ã¦è©•ä¾¡ã—ã¦ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¦ã„ã‚‹ã€‚</p>
<p>Claude2ã‚ˆã‚ŠLLaMA2ã®æ–¹ãŒæ€§èƒ½ãŒè‰¯ã„ã®ãŒé¢ç™½ã„ã—ã€Palmã®æ€§èƒ½ãŒã‚ã¾ã‚Šè‰¯ããªã„ã€‚</p>
<p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ashversex/status/1724240030170808392?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-11-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1119" target="_blank" rel="noopener noreferrer" class="title-link">Data-to-Text Datasetã¾ã¨ã‚, Akihiko Watanabe, 2022</a>
<span class="snippet"><span>Comment</span><p>Data-to-Textã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è‡ªåˆ†ç”¨ã«èª¿ã¹ã¦ã„ãŸã®ã§ã™ãŒã€ã›ã£ã‹ããªã®ã§ã‚¹ãƒ©ã‚¤ãƒ‰ã«ã¾ã¨ã‚ã¦ã¿ã¾ã—ãŸã€‚ç‰¹ã«MR-to-Text, Table-to-Textã‚ãŸã‚Šã¯ç¶²ç¾…çš„ã«ã‚µãƒ¼ãƒ™ã‚¤ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¦‚è¦ã‚’ç´¹ä»‹ã—ã¦ã„ã‚‹ã®ã§ã€å…¨ä½“åƒã‚’æŠŠæ¡ã™ã‚‹ã®ã«è‰¯ã„ã®ã‹ãªãã¨æ€ã„ã¾ã™ã€‚ãŸã ã—ã€2022å¹´12æœˆæ™‚ç‚¹ã§ä½œæˆã—ãŸã®ã§2023å¹´ä»¥å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ğŸ˜…</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2023-11-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1118" target="_blank" rel="noopener noreferrer" class="title-link">Retrieval-based LM ï¼ˆRAG Systemï¼‰ã–ã£ãã‚Šç†è§£ã™ã‚‹, 2023</a>
<span class="snippet"><span>Comment</span><p>ï¼ˆä»¥ä¸‹ã‚¹ã‚¯ã‚·ãƒ§ã¯ã‚¹ãƒ©ã‚¤ãƒ‰ã‚ˆã‚Šå¼•ç”¨ï¼‰<br><br><br><br>æ¬¡ã®ã‚¹ã‚¯ã‚·ãƒ§ã¯RAGã«ã‹ã‹ã‚ã‚‹å‘¨è¾ºæŠ€è¡“ãŒã‚ˆãã¾ã¨ã¾ã£ã¦ã„ã‚‹ã¨æ€ã†ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/35f9f589-770c-435b-8d1b-81e615e86597" alt="image" loading="lazy"><br><br><br><br>ä»¥ä¸‹ã–ã£ãã‚Šç§ã®ä¸­ã®èªè­˜ã¨ã—ã¦<br><br>- è¨ˆç”»<br><br>    - ã‚¯ã‚¨ãƒªæ‹¡å¼µ<br><br>        - ã‚¯ã‚¨ãƒªã®è³ªãŒæ‚ªã„å ´åˆæ¤œç´¢æ€§èƒ½ãŒåŠ£åŒ–ã™ã‚‹ãŸã‚ã€ã‚¯ã‚¨ãƒªã‚’ã‚ˆã‚Šé©åˆ‡ã«æ¤œç´¢ãŒã§ãã‚‹ã‚ˆã†ã«ä¿®æ­£ï¼ˆæ˜”ã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã—ã‹ä¸ãˆã‚‰ã‚Œãªã„ã¨ãã«æƒ…å ±ã‚’å¢—ã‚„ã™ã‹ã‚‰â€æ‹¡å¼µâ€ã¨ã„ã†æ–‡è¨€ãŒç”¨ã„ã‚‰ã‚Œã¦ã„ã‚‹ãŒç¾åœ¨ã¯ã“ã‚Œã«é™ã‚‰ãªã„ã¨æ€ã†ï¼‰ã™ã‚‹æŠ€è¡“<br><br>    - åˆ†è§£ãƒ»æŠ½è±¡åŒ–<br><br>        - è¤‡é›‘ãªã‚¯ã‚¨ãƒªã‹ã‚‰åˆ†è§£ã™ã‚‹ã“ã¨ã§ãƒãƒ«ãƒãƒ›ãƒƒãƒ—ã®è³ªå•ã‚’ã‚µãƒ–è³ªå•ã«åˆ†è§£ï¼ˆä»Šãªã‚‰LLMã‚’åˆ©ç”¨ã™ã‚Œã°æ¯”è¼ƒçš„ç°¡å˜ã«ã§ãã‚‹ï¼‰ã—ãŸã‚Šã€ã‚ã‚‹ã„ã¯æŠ½è±¡åŒ–ã—ãŸã‚¯ã‚¨ãƒªï¼ˆStep-back Promptnig <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1076" target="_blank" rel="noopener noreferrer">Take a Step Back: Evoking Reasoning via Abstraction in Large Language
  Models, Huaixiu Steven Zheng+, N/A, arXiv'23</a>
 ï¼‰ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§æ¤œç´¢ã‚’æ”¹å–„ã™ã‚‹æŠ€è¡“<br><br>    - æ¤œç´¢å¯¾è±¡é¸å®š<br><br>        - æ¤œç´¢ã™ã‚‹å¯¾è±¡ãã®ã‚‚ã®ã‚’é¸æŠã—ã€æ¤œç´¢å¯¾è±¡ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹æŠ€è¡“<br><br>        - è³‡æ–™ä¸­ã§ã¯LLMã‚’ç”¨ã„ãŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚„Classifierã‚’ç”¨ã„ãŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹ãŒã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã§çµã‚Šè¾¼ã‚€ãªã©ã®å˜ç´”ãªæ–¹æ³•ã§ã‚‚å®Ÿç¾å¯èƒ½ã ã¨æ€ã‚ã‚Œã‚‹ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã§çµã‚Šè¾¼ã‚€ã€ã¯Classifierã§ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ãƒªãƒ³ã‚¯ã™ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ãŒï¼‰<br><br>    - æ€è€ƒãƒ»è¡Œå‹•<br><br>        - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/518" target="_blank" rel="noopener noreferrer">REACT : SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS, Yao+, Princeton University and Google brain, ICLR'23</a>
 ã®ã‚ˆã†ãªè‡ªå¾‹çš„ã«LLMã«æ€è€ƒã¨ãã®çµæœã«åŸºã¥ãè¡Œå‹•ã‚’ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã›ã‚‹æŠ€è¡“ã‚„ã€ã‚¯ã‚¨ãƒªã‚’åˆ†è§£ã—ã¦å›ç­”ã¸ãŸã©ã‚Šç€ããŸã‚ã«å¿…è¦ãªæ¨è«–ã‚’æ§‹ç¯‰ã—ã€å„æ¨è«–ã®å›ç­”ã‚’æ¤œè¨¼ã—ãªãŒã‚‰ç”Ÿæˆã‚’ç¹°ã‚Šè¿”ã™æŠ€è¡“ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br>        - ã“ã®è¾ºã®æŠ€è¡“ã¯ã‚¯ã‚¨ãƒªãŒéå¸¸ã«è¤‡é›‘ãªå ´åˆã«æœ‰åŠ¹ã§ã¯ã‚ã‚‹ãŒã€ã‚·ãƒ³ãƒ—ãƒ«ãªå ´åˆã¯å¿…è¦ãªã„ã‹ãªã¨ã„ã†å°è±¡ãŒã‚ã‚‹<br><br>        - ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã®å ´åˆã¯ã©ã¡ã‚‰ã‹ã¨ã„ã†ã¨æ³¥è‡­ã„å‰å‡¦ç†ã¨ã‹ãŒåŠ¹ããã†<br><br>- é–¢é€£çŸ¥è­˜å–å¾—<br><br>    - æ¤œç´¢<br><br>        - è¡¨å±¤æ¤œç´¢ï¼ˆTF-IDFãƒ™ã‚¯ãƒˆãƒ«, BM25ï¼‰ãªã©ã®å¤å…¸çš„ãªæ‰‹æ³•ã‚„ã€æ„å‘³æ¤œç´¢ï¼ˆEmbeddingã«åŸºã¥ãæ‰‹æ³•ï¼‰ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br>        - ä¾‹ãˆã°langchainã§ã¯è¡¨å±¤æ¤œç´¢ + æ„å‘³æ¤œç´¢ã®ä¸¡è€…ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ãŠã‚Šã€ç°¡å˜ã«ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãªæ¤œç´¢ãŒå®Ÿç¾ã§ãã‚‹<br><br>    - çŸ¥è­˜æ–‡ç”Ÿæˆ<br><br>        - å¤–éƒ¨çŸ¥è­˜ã¨ã—ã¦æ¤œç´¢ã•ã‚ŒãŸæ–‡æ›¸ã‚’åˆ©ç”¨ã™ã‚‹ã ã‘ã§ãªãã€LLMè‡ªèº«ãŒä¿æŒã™ã‚‹çŸ¥è­˜ã‚’æ´»ç”¨ã™ã‚‹ãŸã‚ã«LLMãŒç”Ÿæˆã—ãŸæ–‡æ›¸ã®ä¸¡æ–¹ã‚’æ´»ç”¨ã™ã‚‹ã¨QAã®æ­£ç­”ç‡ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br>    - æ–‡æ›¸ãƒ•ã‚£ãƒ«ã‚¿<br><br>        - æ¤œç´¢ã§ã‚¯ã‚¨ãƒªã«é–¢é€£ã—ãªã„æ–‡æ›¸ã‚’å–å¾—ã—ã¦ã—ã¾ã†å¿œç­”å“è³ªãŒå¤§å¹…ã«ä½ä¸‹ã™ã‚‹ã“ã¨ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br>            - å€‹äººçš„ã«ã¯ã“ã“ãŒä¸€ç•ªé‡è¦ãªãƒ‘ãƒ¼ãƒˆã ã¨è€ƒãˆã¦ã„ã‚‹<br><br>        - ã¾ãŸã€æ¤œç´¢çµæœã‚’è¦ç´„ã™ã‚‹æ–¹æ³•ã‚‚ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br>    - å†å¸°ãƒ»åå¾©è¨ˆç®—<br><br>        - Retrierverã‹ã‚‰å–å¾—ã—ãŸçµæœã«åŸºã¥ã„ã¦LLMãŒå¿œç­”ã‚’ç”Ÿæˆã—ã€ç”Ÿæˆã—ãŸå¿œç­”ã¨originalã®questionã®ä¸¡æ–¹ã‚’çµ„ã¿åˆã‚ã›ã¦è¿½åŠ ã§Retrieverã‹ã‚‰æ–‡æ›¸ã‚’å–å¾—ã—ç”Ÿæˆã™ã‚‹æ‰‹æ³•ãªã©ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br>    -  ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°<br><br>        - æ¤œç´¢çµæœã®ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚‚å¤ãã‹ã‚‰å­˜åœ¨ã™ã‚‹æŠ€è¡“ã§ã‚ã‚Šã€ç•°ãªã‚‹çŸ¥è­˜ã‚’æŒã¤Rankerã«ã‚ˆã£ã¦ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã•ã›ã‚‹ã“ã¨ã§æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹å ´åˆãŒã‚ã‚‹<br><br>- å›ç­”<br><br>    - å›ç­”æŠ½å‡ºãƒ»ç”Ÿæˆ<br><br>        - å›ç­”ã¨ãªã‚‹éƒ¨åˆ†ã®spanã‚’æŠ½å‡ºã™ã‚‹æ‰‹æ³•ã¨ã€spanã§ã¯ãªããƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br>        - ã“ã®è¾ºã¯æ–‡æ›¸è¦ç´„ã«ãŠã‘ã‚‹Extractive/Abstractive SummarizationæŠ€è¡“ãªã©ã‚‚ã‹ãªã‚Šå¿œç”¨ãŒåŠ¹ãã¨æ€ã‚ã‚Œã‚‹<br><br>- ã‚¤ãƒ³ãƒ‡ã‚¯ã‚·ãƒ³ã‚°<br><br>    - ä¸è¦æ–‡æ›¸ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚„ã€ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã®æˆ¦ç•¥ã€è³‡æ ¼æƒ…å ±ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã™ã‚‹æ–¹æ³•ãªã©ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5ad62f76-e1b9-4c78-847a-45387fe5fb3e" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/634e5386-6ae4-4602-a214-cc8dc126daad" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-11-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1115" target="_blank" rel="noopener noreferrer" class="title-link">ç”ŸæˆAIãŒæŠ±ãˆã‚‹ãƒªã‚¹ã‚¯ã¨å¯¾ç­–, LYCorpâ€˜23</a>
<span class="snippet"><span>Comment</span><p>ã“ã®è³‡æ–™ã‚’ã‚¹ã‚¿ãƒ¼ãƒˆã«Referã—ã¦ã„ã‚‹è«–æ–‡ãªã©ã‚’å‹‰å¼·ã™ã‚‹ã¨ã€GenerativeAIã®ãƒªã‚¹ã‚¯å‘¨ã‚Šã«è©³ã—ããªã‚Œãã†ã€‚ã“ã®è¾ºã¯ç–ã„ã®ã§å‹‰å¼·ã«ãªã‚‹ã€‚<br>ã—ã‹ã—ã€LLMã®AlignmentãŒä¸ååˆ†ã ã£ãŸã‚Šã€Hallucinationã‚’100%é˜²ãã“ã¨ã¯åŸç†çš„ã«ä¸å¯èƒ½ã ã¨æ€ã‚ã‚Œã‚‹ã®ã§ã€ã“ã®è¾ºã¨ã©ã†ä»˜ãåˆã£ã¦ã„ãã‹ãŒLLMã¨ä»˜ãåˆã£ã¦ã„ãä¸Šã§é›£ã—ã„ã¨ã“ã‚ã€‚ã“ã®è¾ºã¯è‡ªåˆ†ãŸã¡ãŒæ´»ç”¨ã—ãŸã„ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«å¿œã˜ã¦æŸ”è»Ÿã«å¯¾å¿œã—ãªã‘ã‚Œã°ãªã‚‰ãšã€ã“ã®è¾ºã®ç´°ã‹ã„ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã‚’ã™ã‚‹åœ°é“ãªä½œæ¥­ã¯ãšã£ã¨æ®‹ã‚Šç¶šã‘ã‚‹ã®ã§ã¯ãªã„ã‹ãªã‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ImageCaptioning.html" target="_blank" rel="noopener noreferrer">#ImageCaptioning</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2023-11-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1114" target="_blank" rel="noopener noreferrer" class="title-link">Zero-shot Learningç¶²ç¾…çš„ã‚µãƒ¼ãƒ™ã‚¤: CLIPãŒåˆ‡ã‚Šé–‹ã„ãŸVision &amp; Languageã®æ–°ã—ã„ä¸–ç•Œ</a>
<span class="snippet"><span>Comment</span><p>ã“ã‚Œã¯ã™ã”ã„ã¾ã¨ã‚â€¦ã€‚ã¾ã é€”ä¸­ã¾ã§ã—ã‹èª­ã‚ã¦ã„ãªã„ã€‚CLIPã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã—ã¦CLIPã‚’å¼•ç”¨ã—ã¦ã„ã‚‹è«–æ–‡ã‹ã‚‰é‡è¦ãªã‚‚ã®ã‚’æ¦‚è¦ä»˜ãã§ã¾ã¨ã‚ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-11-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1112" target="_blank" rel="noopener noreferrer" class="title-link">IBIS2023ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã€Œå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«æ´»ç”¨æŠ€è¡“ã®æœ€å‰ç·šã€</a>
<span class="snippet"><span>Comment</span><p>LLMã®å¿œç”¨ç ”ç©¶ã‚„Promptingã‚’ä¸­å¿ƒã¨ã—ãŸãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã€‚ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚„å¯¾è©±å¼æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã¸ã®æ´»ç”¨ã€ReActã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æœ€é©åŒ–æŠ€è¡“ã€CoTã®åŸºæœ¬ã‹ã‚‰å¿œç”¨ã¾ã§å¹…åºƒãã¾ã¨ã¾ã£ã¦ã„ã‚‹ã®ã§ã€LLMã®å¿œç”¨æŠ€è¡“ã®æ¦‚è¦³ã‚„ã€CoTã‚’å®Ÿè·µã—ãŸã„äººã«éå¸¸ã«æœ‰ç”¨ã ã¨æ€ã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-11-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1111" target="_blank" rel="noopener noreferrer" class="title-link">tsuzumi, NTTâ€™23</a>
<span class="snippet"><span>Comment</span><p>NTTè£½ã®LLMã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯7Bã¨è»½é‡ã ãŒé«˜æ€§èƒ½ã€‚<br>MTBenchã®ã‚ˆã†ãªGPT4ã«å‹æ•—ã‚’åˆ¤å®šã•ã›ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€åœ°ç†ã€æ­´å²ã€æ”¿æ²»ã€ç¤¾ä¼šã«é–¢ã™ã‚‹è³ªå•å¿œç­”ã‚¿ã‚¹ã‚¯ï¼ˆå›³6ï¼‰ã§gpt3.5turboã¨åŒç­‰ã€å›½ç”£LLMã®ä¸­ã§ãƒˆãƒƒãƒ—ã®æ€§èƒ½ã€‚GPT3.5turboã«ã¯ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚„æ•°å­¦ãªã©ã®èƒ½åŠ›ã§ã¯åŠ£ã‚‹ã¨ã®ã“ã¨ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d064e0dc-b598-4853-9466-f56f39986acc" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c8251b2e-f865-4069-a3b7-9bfb848554bb" alt="image" loading="lazy"><br>&gt; ï¼Š6 Rakudaãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br>æ—¥æœ¬èªã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ä¸€ã¤ã§ã€æ—¥æœ¬ã®åœ°ç†ãƒ»æ”¿æ²»ãƒ»æ­´å²ãƒ»ç¤¾ä¼šã«é–¢ã™ã‚‹è³ªå•å¿œç­”ã‚¿ã‚¹ã‚¯ã«ã‚ˆã£ã¦è©•ä¾¡ã‚’è¡Œã†ã€‚<br>URLï¼š


<a href="https://yuzuai.jp/benchmark" target="_blank" rel="noopener noreferrer">https://yuzuai.jp/benchmark</a>


<br><br>&gt;ï¼Š7 Japanese Vicuna QAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br>Rakudaã‚ˆã‚Šã‚‚ã•ã‚‰ã«å¹…åºƒã„ã‚«ãƒ†ã‚´ãƒªã§è¨€èªãƒ¢ãƒ‡ãƒ«ã®QAã‚„æŒ‡ç¤ºé‚è¡Œã®èƒ½åŠ›ã‚’å•ã†è©•ä¾¡æ–¹æ³•ã€‚ä¸€èˆ¬çŸ¥è­˜ã€ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãªã©å¤šæ•°ã®è³ªå•ã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹ã€‚<br>URLï¼š


<a href="https://github.com/hitoshizuku7/LLM_Judge_ku/blob/main/README.md" target="_blank" rel="noopener noreferrer">https://github.com/hitoshizuku7/LLM_Judge_ku/blob/main/README.md</a>


</p>
<p>tsuzumiã¯ã‚¢ãƒ€ãƒ—ã‚¿ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«å…¨ä½“ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã“ã¨ãªãã€ã•ã¾ã–ã¾ãªçŸ¥è­˜ã‚’æŒãŸã›ãŸã‚Šã€æŒ¯ã‚‹èˆã„ã‚’å¤‰ãˆãŸã‚Šã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã¨ã®ã“ã¨ï¼ˆLoRAã‚¢ãƒ€ãƒ—ã‚¿ã®ã‚ˆã†ãªã‚‚ã®ã ã¨æ€ã‚ã‚Œã‚‹ï¼‰ã€‚<br>ã¾ã¦ã€å°†æ¥çš„ã«è¦–è¦šã‚„è´è¦šãªã©ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾å¿œã‚‚å®Ÿæ–½ã€‚</p>
<p>æ€æƒ³ãŒLoRA Hub <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/917" target="_blank" rel="noopener noreferrer">LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA   Composition, Chengsong Huang+, N/A, COLM'24</a>
 ã«è¿‘ãã€ã‚¢ãƒ€ãƒ—ã‚¿ã‚’ç€è„±ã™ã‚Œã°æŸ”è»Ÿã«ç”Ÿæˆã‚’å¤‰ãˆã‚‰ã‚Œã‚‹ã®ã¯æœ‰ç”¨ã ã¨æ€ã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1109" target="_blank" rel="noopener noreferrer" class="title-link">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®Fine-tuningã«ã‚ˆã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ç²å¾—ã®æ¤œè¨, PFN Blog, 2023.10</a>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹è¨˜äº‹ä¸­ã§èˆˆå‘³æ·±ã‹ã£ãŸéƒ¨åˆ†ã‚’å¼•ç”¨<br>&gt; ã¾ã¨ã‚ã‚‹ã¨ã€LoRAã¯ã€[3]ã§è¨€ã‚ã‚Œã¦ã„ã‚‹ã€äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¯å¤§é‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšä½ã„å›ºæœ‰æ¬¡å…ƒã‚’æŒã¡ã€Fine-tuningã«æœ‰åŠ¹ãªä½æ¬¡å…ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚‚å­˜åœ¨ã™ã‚‹ã€ã¨ã„ã†ä¸»å¼µã«ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ã•ã‚Œã€Î”Wã«ãŠã‘ã‚‹é‡ã¿ã®æ›´æ–°ã®å›ºæœ‰æ¬¡å…ƒã‚‚ä½ã„ã¨ã„ã†ä»®èª¬ã®ã‚‚ã¨ã§ã€ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ã§å­¦ç¿’ã™ã‚‹æ‰‹æ³•ã«ãªã‚Šã¾ã™ã€‚<br><br>LoRAãŒæ‹ ã‚Šæ‰€ã¨ã™ã‚‹ä»®èª¬ãŒèª¬æ˜ã•ã‚Œã¦ãŠã‚Šã€å‹‰å¼·ã«ãªã£ãŸã€‚<br><br>&gt; ã“ã†ã—ãŸãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’åœ§ç¸®ã™ã‚‹ä»–ã®æŠ€è¡“ã«ã¯æåˆˆã‚Šã‚„çŸ¥è­˜è’¸ç•™ãŒã‚ã‚Šã¾ã™ãŒã€é‡å­åŒ–ã¯ã€ã»ã¨ã‚“ã©ã®å ´åˆã«æåˆˆã‚Šã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹ã¨ã•ã‚Œ[5]ã€è’¸ç•™ã‚ˆã‚Šã‚‚æ‰‹è»½ã«é«˜ç²¾åº¦ãªãƒ¢ãƒ‡ãƒ«ãŒå¾—ã‚‰ã‚Œã‚‹å¯èƒ½æ€§ãŒé«˜ãã€LLMã«ãŠã„ã¦ã‚‚æœ‰åŠ›ãªæŠ€è¡“ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚<br><br>ã“ã‚Œã‚‚çŸ¥ã‚‰ãªã‹ã£ãŸã—ã€æ–‡çŒ®ä»˜ãã§è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒå¤§å¤‰ã‚ã‚ŠãŒãŸã„ã€‚<br><br>&gt; QLoRAä»¥å¤–ã®LoRAã®æ´¾ç”Ÿæ‰‹æ³•ã¨ã—ã¦ã¯ã€ãƒ©ãƒ³ã‚¯ã‚’é©å¿œçš„ã«å®šã‚ã‚‹AdaLoRA[7] ã‚„DyLoRA[8]ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’æ‹¡å¤§ã§ãã‚‹LongLoRA[9]ã€è¡Œåˆ—Aã®é‡ã¿ã‚’freezeã™ã‚‹ã“ã¨ã§ã•ã‚‰ã«è»½é‡åŒ–ã‚’è¡Œã†LoRA-FAã€è¡Œåˆ—ç©ã‚’ã‚¢ãƒ€ãƒãƒ¼ãƒ«ç©ã‚„ã‚¯ãƒ­ãƒãƒƒã‚«ãƒ¼ç©ã§è¨ˆç®—ã™ã‚‹LoHAã‚„LoKRãªã©ãŒã‚ã‚Šã¾ã™ï¼ˆä¸€éƒ¨ã¯LLMã§ã¯ãªãStable Diffusionã®å­¦ç¿’ã§ç”¨ã„ã‚‰ã‚Œã‚‹æ‰‹æ³•ã®é€šç§°ã§ã™ï¼‰ã€‚<br><br>ã“ã®è¾ºã¯å®Ÿéš›ã«LoRAã‚’ä½¿ã†ã“ã¨ã«ãªã£ãŸã‚‰å‹‰å¼·ã—ãŸã„ã€‚<br><br>&gt; è¨€èªãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¯é€šå¸¸ã€Causal LMã®å ´åˆã¯ã€Next Token Predictionã«ãŠã‘ã‚‹Perplexityã®æœ€å°åŒ–ã«ã‚ˆã‚‹æ•™å¸«ãªã—å­¦ç¿’ã«ã‚ˆã£ã¦æœ€é©åŒ–ã•ã‚Œã¾ã™ã€‚<br><br>HuggingFaceã®å®Ÿè£…ã®è©±ã ã¨æ€ã†ãŒã€ãã†ã ã‚ã†ãªã¨æ€ã£ã¦ã¯ã„ãŸãŒã‚½ãƒ¼ã‚¹ã‚’ç¢ºèªã§ãã¦ã„ãªã‹ã£ãŸã®ã§å‹‰å¼·ã«ãªã£ãŸã€‚<br><br>&gt; 7Bã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ä»¥ä¸‹ã®ã‚°ãƒ©ãƒ•ã®ã‚ˆã†ã«ã€ãƒ‡ãƒ¼ã‚¿ã®ä»¶æ•°ã‚’å¢—ã‚„ã™ã¨å­¦ç¿’ãŒã†ã¾ãã„ã‹ãªã„ã¨ã„ã†çµæœãŒå¾—ã‚‰ã‚Œã¾ã—ãŸã€‚ã¾ãŸã€LoRAã®ãƒ©ãƒ³ã‚¯ã¯ä½ã„æ–¹ãŒå­¦ç¿’ãŒå®‰å®šã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚æ­£ç­”ç‡ãŒè‘—ã—ãä½ã„ã‚‚ã®ã¯ã€å­¦ç¿’æ™‚ã®ãƒ­ã‚¹ï¼ˆäº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼‰ãŒéå¸¸ã«å¤§ãããªã£ã¦ãŠã‚Šã€é¸æŠè‚¢ã‚’é–“é•ãˆã‚‹ã¨ã„ã†ã‚ˆã‚Šã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã®æ©Ÿèƒ½ãŒå¤±ã‚ã‚Œã¦ã„ã¾ã—ãŸã€‚<br><br>&gt; ä»–ã«ã¯ã€Instructionãƒ‡ãƒ¼ã‚¿ï¼ˆ1ã¤ã®ã‚¯ã‚¤ã‚ºã®Q&amp;Aï¼‰ãŒ2500ä»¶ã‚’è¶…ãˆã‚‹ã¨ãƒ­ã‚¹ãŒæ‚ªåŒ–ã™ã‚‹ã“ã¨ã‚„ã€2000ä»¶ã§ã‚‚2epochç¹°ã‚Šè¿”ã™ã¨catastrophic forgettingãŒè¦‹ã‚‰ã‚Œã€è¨€èªãƒ¢ãƒ‡ãƒ«ãã®ã‚‚ã®ã®æ€§èƒ½ãŒå¤±ã‚ã‚Œæ„å‘³ã®ãªã„å‡ºåŠ›ã‚’ã—ã¦ã„ã¾ã—ãŸã€‚[17] ã§ã‚‚è¨€åŠã•ã‚Œã¦ã„ã¾ã™ãŒã€æ—¥æœ¬èªã®å­¦ç¿’ã§ã¯ã€æ•°Bã®ãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹LoRAã«ã‚ˆã‚‹Instruction Tuningã¯ã‚ã¾ã‚ŠåŠ¹æœãŒå¾—ã‚‰ã‚Œãªã„å¯èƒ½æ€§ãŒé«˜ã„ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚<br><br>&gt; ä¸€æ–¹ã€13Bã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€8ã€16ã€32ã€64ã„ãšã‚Œã®ãƒ©ãƒ³ã‚¯ã§ã‚‚å¤§ããªå·®ã¯è¦‹ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚<br>&gt; ã“ã‚Œã‚‰ã‹ã‚‰ã€Addtional Trainingã§å­¦ç¿’ã•ã›ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒInstruction Tuningã«å¯¾ã—ã¦è†¨å¤§ã§ã‚ã‚‹å ´åˆã«ã¯å…ˆã«å­¦ç¿’ã—ãŸæ–¹ãŒã‚ˆãã€å°‘æ•°ã®å ´åˆã¯å¾Œã«å­¦ç¿’ã•ã›ã¦ã‚‚Instruction Tuningã®åŠ¹æœã«ã¯æ‚ªå½±éŸ¿ãŒãªã„ã¨ã„ã†ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¾ã—ãŸã€‚<br><br>&gt; ã¾ãŸå­¦ç¿’ã¯ã€åˆæœŸå­¦ç¿’ç‡ã‚’å°ã•ãã—ãŸæ–¹ãŒå®‰å®šã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã¨æ€ã‚ã‚Œã¾ã™ã€‚LoRAã®è«–æ–‡[2] ã§ã¯GPTã®Fine-tuneã¯2e-4ã§è¡Œã‚ã‚Œã¦ãŠã‚Šã€hugging faceã®å®Ÿè£…ã§ã‚‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯2e-4ã¨ãªã£ã¦ã„ã¾ã™ãŒã€ä»–ã®è«–æ–‡ã‚„ãƒ–ãƒ­ã‚°ã§ã¯3e-5ã§ã®ä¾‹ãªã©ã‚‚ã‚ã‚Šã¾ã™ã€‚ã—ã‹ã—ã€å˜ã«ä¸‹ã’ã‚Œã°å®‰å®šã™ã‚‹ã¨ã„ã†ã“ã¨ã§ã‚‚ãªãã€ï¼‘å›ã®è©¦è¡Œã«ãŠã‘ã‚‹è¨ˆç®—ã‚³ã‚¹ãƒˆã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ãªã‚‹å¯èƒ½æ€§ã¯ã‚ã‚Šã¾ã™ã€‚<br><br>Additional Trainingã¨ã¯Finetuningã®ã“ã¨ã§ä¾¿å®œä¸Šã®æœ¬ãƒ–ãƒ­ã‚°ã§ã®å‘¼ç§°ã€‚å®Ÿéš›ã®æ–‡æ›¸ä¸­ã§ã¯å›³ãŒè¤‡æ•°å€‹æŒŸã¾ã‚Œã¦ã„ã‚‹ã€‚<br>ã“ã†ã—ãŸå®Ÿéš›ã«æ‰‹ã‚’å‹•ã‹ã—ãŸä¸Šã§ãªã„ã¨å¾—ã‚‰ã‚Œãªã„çŸ¥è¦‹ã‚’å…¬é–‹ã—ã¦ãã‚Œã‚‹ã®ã¯éå¸¸ã«ã‚ã‚ŠãŒãŸã„ã“ã¨ã ã—ã€æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã§LoRAã‚’ã™ã‚‹éš›ã«éå¸¸ã«å‚è€ƒã«ãªã‚Šãã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1107" target="_blank" rel="noopener noreferrer" class="title-link">StableDiffusion, LLMã®GPUãƒ¡ãƒ¢ãƒªå‰Šæ¸›ã®ã‚ã‚Œã“ã‚Œ</a>
<span class="snippet"><span>Comment</span><p>Gradient Accumulation, Gradient Checkpointingã®èª¬æ˜ãŒä¸å¯§ã§ã‚ã‹ã‚Šã‚„ã™ã‹ã£ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1103" target="_blank" rel="noopener noreferrer" class="title-link">LLMã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŠ€è¡“ã¾ã¨ã‚</a>
<span class="snippet"><span>Comment</span><p>ã–ã£ã¨è¦‹ãŸãŒç¾æ™‚ç‚¹ã§ä¸»è¦ãªã‚‚ã®ã¯ã»ã¼å«ã¾ã‚Œã¦ã„ã‚‹ã®ã§ã¯ã€ã¨ã„ã†å°è±¡<br>å®Ÿéš›ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹ãŒè¼‰ã£ã¦ã„ã‚‹ã®ã§ã€ç†è§£ã—ã‚„ã™ã„ã‹ã‚‚ã—ã‚Œãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1101" target="_blank" rel="noopener noreferrer" class="title-link">Evaluating RAG Pipelines</a>
<span class="snippet"><span>Comment</span><p>RAG pipeline ï¼ˆretrieval + generationï¼‰ã‚’è©•ä¾¡ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªRagasã«ã¤ã„ã¦ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>è©•ä¾¡ã«æ´»ç”¨ã•ã‚Œã‚‹æŒ‡æ¨™ã¯ä¸‹è¨˜ã§ã€èƒŒå¾Œã«LLMã‚’æ´»ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€å¤§åŠã®æŒ‡æ¨™ã¯ãƒ©ãƒ™ãƒ«ãƒ‡ãƒ¼ã‚¿ä¸è¦ã€‚ãŸã ã—ã€context_recallã‚’æ¸¬å®šã™ã‚‹å ´åˆã¯reference answerãŒå¿…è¦ã€‚<br>Ragasã‚¹ã‚³ã‚¢ã¨ã—ã¦ã©ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’åˆ©ç”¨ã™ã‚‹ã‹ã¯é¸æŠã™ã‚‹ã“ã¨ãŒã§ãã€é¸æŠã—ãŸãƒ¡ãƒˆãƒªãƒƒã‚¯ã®harmonic meanã§ã‚¹ã‚³ã‚¢ãŒç®—å‡ºã•ã‚Œã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/553e7f91-84cd-4aac-bef3-c84bc279547e" alt="image" loading="lazy"><br><br>å„ç¨®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®å†…éƒ¨çš„ãªå‡¦ç†ã¯ä¸‹è¨˜:<br>- faithfullness<br>  - questionã¨ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã«åŸºã¥ã„ã¦ã€statementã®ãƒªã‚¹ãƒˆã‚’LLMã§ç”Ÿæˆã™ã‚‹ã€‚statementã¯å›ç­”ãŒä¸»å¼µã—ã¦ã„ã‚‹å†…å®¹ã‚’LLMãŒè§£é‡ˆã—ãŸã‚‚ã®ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br>  - statementã®ãƒªã‚¹ãƒˆã¨contextãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€statementãŒcontextã«supportã•ã‚Œã¦ã„ã‚‹ã‹ã‚’LLMã§è©•ä¾¡ã™ã‚‹ã€‚<br>  - num. of supported statements / num. of statements ã§ã‚¹ã‚³ã‚¢ãŒç®—å‡ºã•ã‚Œã‚‹<br>- Answer Relevancy<br>  - LLMã§ç”Ÿæˆã•ã‚ŒãŸå›ç­”ã‹ã‚‰é€†ã«è³ªå•ã‚’ç”Ÿæˆã—ã€ç”Ÿæˆã•ã‚ŒãŸè³ªå•ã¨å®Ÿéš›ã®è³ªå•ã®é¡ä¼¼åº¦ã‚’æ¸¬ã‚‹ã“ã¨ã§è©•ä¾¡<br>- Context Relevancy<br>  - ã©ã‚Œã ã‘contextã«ãƒã‚¤ã‚ºãŒå«ã¾ã‚Œã‚‹ã‹ã‚’æ¸¬å®šã™ã‚‹ã€‚<br>  - LLMã§contextã®å„æ–‡ã”ã¨ã«å›ç­”ã«å¿…è¦ãªæ–‡ã‹å¦ã‹ã‚’åˆ¤æ–­ã™ã‚‹<br>  - å›ç­”ã«å¿…è¦ãªæ–‡æ•° / å…¨æ–‡æ•° ã§ã‚¹ã‚³ã‚¢ã‚’ç®—å‡º<br>- Context Recall<br>  - å›ç­”ã«å¿…è¦ãªæƒ…å ±ã‚’å…¨ã¦retrieverãŒæŠ½å‡ºã§ãã¦ã„ã‚‹ã‹<br>  - ground truthã¨ãªã‚‹å›ç­”ã‹ã‚‰statementã‚’LLMã§ç”Ÿæˆã—ã€statementãŒcontextã§ã©ã‚Œã ã‘ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹ã‹ã§ç®—å‡º<br><br>ã¾ãŸã€LangSmithã‚’åˆ©ç”¨ã—ã¦å®Ÿé¨“ã‚’ç®¡ç†ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦ã‚‚è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3a30d238-ac48-401c-906b-4ddb5fca50be" alt="image" loading="lazy"><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1100" target="_blank" rel="noopener noreferrer" class="title-link">LangChainã®RAGã®æ”¹å–„æ³•, LayerXæ©Ÿæ¢°å­¦ç¿’å‹‰å¼·ä¼š</a>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹ãƒªãƒ³ã‚¯ã‹ã‚‰ã®å¼•ç”¨ã€‚LangChainã‹ã‚‰æä¾›ã•ã‚Œã¦ã„ã‚‹Retrieverã®contextæŠ½å‡ºã®æ€§èƒ½æ”¹å–„ã®ãŸã‚ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³<br><br>&gt; Multi representation indexingï¼šæ¤œç´¢ã«é©ã—ãŸæ–‡æ›¸è¡¨ç¾ï¼ˆä¾‹ãˆã°è¦ç´„ï¼‰ã®ä½œæˆ<br>Query transformationï¼šäººé–“ã®è³ªå•ã‚’å¤‰æ›ã—ã¦æ¤œç´¢ã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•<br>Query constructionï¼šäººé–“ã®è³ªå•ã‚’ç‰¹å®šã®ã‚¯ã‚¨ãƒªæ§‹æ–‡ã‚„è¨€èªã«å¤‰æ›ã™ã‚‹æ–¹æ³•<br><br>


<a href="https://blog.langchain.dev/query-transformations/" target="_blank" rel="noopener noreferrer">https://blog.langchain.dev/query-transformations/</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-10-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1096" target="_blank" rel="noopener noreferrer" class="title-link">æ—¥æœ¬èªLLMã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ï¼ˆLLM.jpï¼‰</a>
<span class="snippet"><span>Comment</span><p>LLM.jpã«ã‚ˆã‚‹æ—¥æœ¬èªLLMã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã€‚4-shotsã§ã®çµæœã€ã‹ã¤instructionã‚’ä¸ãˆãŸå ´åˆã®ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã™ã‚‹è©•ä¾¡ã€ã¨ã„ã†ç‚¹ã«ã¯ç•™æ„ã—ãŸã„ã€‚ãŸã¨ãˆã°ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§æ´»ç”¨ã—ãŸã„ã€ã¨ã„ã†å ´åˆã«ã“ã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã®çµæœãŒãã®ã¾ã¾å†ç¾ã•ã‚Œã‚‹ä¿è¨¼ã¯ãªã„ã¨æ¨å¯Ÿã•ã‚Œã‚‹ã€‚<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1079" target="_blank" rel="noopener noreferrer">æ—¥æœ¬èªLLMãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨è‡ªå‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°, PFN Blog, 2023.10</a>
 ã®çŸ¥è¦‹ã§ã‚‚ã‚ã£ãŸé€šã‚Šã€promptingã®ä»•æ–¹ã«ã‚ˆã£ã¦ã‚‚LLMé–“ã§é †ä½ãŒé€†è»¢ã™ã‚‹ç¾è±¡ãªã©ã‚‚èµ·ã“ã‚Šã†ã‚‹ã€‚ã‚ãã¾ã§ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã®å€¤ã¯å‚è€ƒå€¤ã¨ã—ã¦ç•™ã‚ã€ã©ã®LLMã‚’æ¡ç”¨ã™ã‚‹ã‹ã¯ã€è‡ªåˆ†ãŒåˆ©ç”¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚„ãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼ã—ãŸæ–¹ãŒbetterã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>ã‚ã¨ã¯ãã‚‚ãã‚‚æœ¬å½“ã«LLMã‚’ä½¿ã†å¿…è¦ãŒã‚ã‚‹ã®ã‹? <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1024" target="_blank" rel="noopener noreferrer">Prompt2Model: Generating Deployable Models from Natural Language   Instructions, Vijay Viswanathan+, N/A, EMNLP'23</a>
  ã®ã‚ˆã†ãªæ‰‹æ³•ã§ã¯ãƒ€ãƒ¡ãªã®ã‹?ã¿ãŸã„ãªã¨ã“ã‚ã‚‚è€ƒãˆã‚‰ã‚Œã‚‹ã¨è‰¯ã„ã®ã‹ã‚‚ã—ã‚Œãªã„ã€‚<br><br>ä»¥ä¸‹ã‚µã‚¤ãƒˆã‚ˆã‚Šå¼•ç”¨<br>&gt; è©•ä¾¡æ‰‹æ³•ãƒ»ãƒ„ãƒ¼ãƒ«<br>ã“ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®å†…å®¹ã¯llm-jpã§å…¬é–‹ã—ã¦ã„ã‚‹è©•ä¾¡ãƒ„ãƒ¼ãƒ«ã€llm-jp-evalã§å„ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦è©•ä¾¡ã‚’è¡Œãªã£ãŸçµæœã§ã‚ã‚‹ã€‚llm-jp-evalã¯ã€æ—¢å­˜ã®ãƒªãƒ¼ãƒ€ãƒœãƒ¼ãƒ‰ã¨ã¯è¡Œã‚ã‚Œã¦ã„ã‚‹è©•ä¾¡ã¨ã¯ã€ä¸»ã«ä»¥ä¸‹ã®ã¨ã“ã‚ã§é•ã£ã¦ã„ã‚‹ã€‚<br>Alpacaã‚„Big-Benchãªã©ã‚’å‚è€ƒã«ã—ãŸã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚ˆã‚Šã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã¨ã—ã¦ä¸ãˆã¦ã€ãã®å…¥åŠ›ã«å¯¾ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ç”Ÿæˆçµæœã‚’è©•ä¾¡ã™ã‚‹<br>&gt;è©•ä¾¡ã¯åŸºæœ¬ã€ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã—ãŸæ–‡å­—åˆ—ã ã‘ã‚’ä½¿ã£ã¦è¡Œã†<br>&gt;Few shotã§ã®è©•ä¾¡ã‚’è¡Œã£ã¦ãŠã‚Šã€ã“ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«ã¯4-shotsã§ã®çµæœã‚’è¼‰ã›ã¦ã„ã‚‹<br><br>&gt;è©•ä¾¡æ‰‹æ³•ãƒ»ãƒ„ãƒ¼ãƒ«ã®è©³ç´°ã¯llm-jp-evalã‚’æ˜¯éå‚ç…§ã•ã‚ŒãŸã„ã€‚<br><br>&gt;è©•ä¾¡é …ç›®ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>è©•ä¾¡é …ç›®ã¨ã—ã¦ã€ã¾ãš4ã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«ãŠã‘ã‚‹å¹³å‡ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã—ãŸã€‚ã•ã‚‰ã«ãã®4ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®å¹³å‡å€¤ã®å¹³å‡å€¤ã‚’ã¨ã£ãŸå€¤ãŒAVGã§ã‚ã‚‹ã€‚<br>MC (Multi-Choice QA)ï¼šjcommonsenseqa<br>NLI (Natural Language Inference)ï¼šjampã€janliã€jnliã€jsemã€jsick<br>QA (Question Answering)ï¼šjemhopqaã€niilc<br>RC (Reading Comprehension)ï¼šjsquad<br><br>&gt;ãã‚Œãã‚Œã®ã‚«ãƒ†ã‚´ãƒªã®å¹³å‡ã‚’å‡ºã™æ–¹æ³•ã«è¨€èªå­¦çš„ãªæ„å‘³ã¯ãªã„ãŸã‚ã€æœ€çµ‚çš„ãªå¹³å‡å€¤ã¯ã‚ãã¾ã§å‚è€ƒå€¤ã¨ã„ã†ã“ã¨ã«æ³¨æ„ã•ã‚ŒãŸã„ã€‚</p>
<p>JGlueã‚’åˆ©ç”¨ã—ãŸæ—¥æœ¬èªLLMã®ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã¨ã—ã¦ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1055" target="_blank" rel="noopener noreferrer">Nejumi LLMãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰</a>
 ãªã©ã‚‚ã‚ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-10-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1087" target="_blank" rel="noopener noreferrer" class="title-link">æ—¥æœ¬èªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒJapanese Stable LM 3B-4E1Tã€ã€ŒJapanese Stable LM Gamma 7Bã€ã‚’å…¬é–‹ã—ã¾ã—ãŸ, 2023</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-10-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1080" target="_blank" rel="noopener noreferrer" class="title-link">OpenSource LLM</a>
<span class="snippet"><span>Comment</span><p>zephyr-7B-alpha<br>- 1/10ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§LLaMA2-70Bw-chatè¶…ãˆ<br>


<a href="https://weel.co.jp/media/zephyr-7b-alpha" target="_blank" rel="noopener noreferrer">https://weel.co.jp/media/zephyr-7b-alpha</a>


</p>
<p>- zephyr-7B-Î²<br>ã€€- MTBenchã§llama2-70B-chatè¶…ãˆ<br>ã€€- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1099" target="_blank" rel="noopener noreferrer">Zephyr: Direct Distillation of LM Alignment, Lewis Tunstall+, N/A, arXiv'23</a>
</p>
<p>Zephyr-7B-betaãŒæ—©ãã‚‚TheBlokeæ°ã«ã‚ˆã£ã¦GPTQã§é‡å­åŒ–ã•ã‚Œã€ãªã‚“ã¨ãƒ¢ãƒ‡ãƒ«è‡ªä½“ã¯4.5Gç¨‹åº¦ã—ã‹VRAMã‚’æ¶ˆè²»ã—ãªã„â€¦<br>


<a href="https://huggingface.co/TheBloke/zephyr-7B-beta-GPTQ" target="_blank" rel="noopener noreferrer">https://huggingface.co/TheBloke/zephyr-7B-beta-GPTQ</a>


</p>
<p>- NVIDIA Nemotron-3 8B Models<br><br>    - 


<a href="https://developer.nvidia.com/nemotron-3-8b\" target="_blank" rel="noopener noreferrer">https://developer.nvidia.com/nemotron-3-8b\</a>


<br><br>    - 


<a href="https://huggingface.co/nvidia/nemotron-3-8b-base-4k" target="_blank" rel="noopener noreferrer">https://huggingface.co/nvidia/nemotron-3-8b-base-4k</a>


<br><br>    - 53è¨€èªå¯¾å¿œã€37ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªå¯¾å¿œ, base / chatãŒã‚ã‚‹ </p>
<p>- Mixtral8x7B: LLaMA2-70B, GPT-3.5-turboã¨åŒç­‰ã®æ€§èƒ½<br><br>    - Mistralã‚’Sparse Mixture of Expertsã—ãŸãƒ¢ãƒ‡ãƒ«ã®æ¨¡æ§˜<br><br>    - åå‰ã®é€šã‚Š8ã¤ã®FFNãŒå­˜åœ¨ã—ã¦ã„ã‚‹ãŒã€Top-2ã®FFNãŒé¸æŠã•ã‚Œãã®çµæœãŒé›†ç´„ã•ã‚Œå‡ºåŠ›ãŒæ±ºå®šã•ã‚Œã‚‹<br><br>


<a href="https://mistral.ai/news/mixtral-of-experts/" target="_blank" rel="noopener noreferrer">https://mistral.ai/news/mixtral-of-experts/</a>


<br><br><br><br>- æ—¥æœ¬èªã¾ã¨ã‚<br><br>    - 


<a href="https://note.com/npaka/n/n6043bc8b01bc" target="_blank" rel="noopener noreferrer">https://note.com/npaka/n/n6043bc8b01bc</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<span class="issue_date">Issue Date: 2023-10-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1079" target="_blank" rel="noopener noreferrer" class="title-link">æ—¥æœ¬èªLLMãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨è‡ªå‹•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°, PFN Blog, 2023.10</a>
<span class="snippet"><span>Comment</span><p>é¢ç™½ã‹ã£ãŸã€‚ç‰¹ã«ã€promptingã«ã‚ˆã£ã¦rinnaã¨cyberã®LLMã®é †ä½ãŒé€†è»¢ã—ã¦ã„ã‚‹ã®ãŒèˆˆå‘³æ·±ã‹ã£ãŸã€‚GAã‚’ä½¿ã£ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯æœ€è¿‘è«–æ–‡ã‚‚å‡ºã¦ã„ãŸãŒã€æ—¥æœ¬èªLLMã§è©¦ã•ã‚Œã¦ã„ã‚‹ã®ã¯é¢ç™½ã‹ã£ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1073" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Model ï¼ˆin 2023ï¼‰, OpenAI</a>
<span class="snippet"><span>Comment</span><p>LLMã®ç ”ç©¶é–‹ç™ºå‹•å‘ã‚’ä¿¯ç°ã™ã‚‹ã®ã«æœ‰ç”¨ã‚‰ã—ã„</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1064" target="_blank" rel="noopener noreferrer" class="title-link">MentalLLaMA, 2023</a>
<span class="snippet"><span>Comment</span><p>ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹ã®åˆ†æã«å¯¾ã—ã¦instruction tuningã—ãŸã¯ã˜ã‚ã¦ã®LLM</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1058" target="_blank" rel="noopener noreferrer" class="title-link">Yasa-1</a>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaguring1/status/1709557947813281865?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<span class="issue_date">Issue Date: 2023-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1057" target="_blank" rel="noopener noreferrer" class="title-link">Japanese Simple SimCSE</a>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªã®äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ã€æ—¥æœ¬èªã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã—ã¦SimCSEã‚’å­¦ç¿’ã—ç¶²ç¾…çš„ã«è©•ä¾¡ã‚’ã—ãŸçµæœãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚Supervised SimCSE, UnsupervisednSimCSEã®ä¸¡æ–¹ã§å®Ÿé¨“ã€‚ã¾ãŸã€å­¦ç¿’ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å¤‰æ›´ã—ãŸã¨ãã®é ‘å¥æ€§ã‚‚æ¤œè¨¼ã€‚æ€§èƒ½ãŒè‰¯ã‹ã£ãŸãƒ¢ãƒ‡ãƒ«ã¯SentenceTransformersã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªå½¢ã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-10-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1055" target="_blank" rel="noopener noreferrer" class="title-link">Nejumi LLMãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰</a>
<span class="snippet"><span>Comment</span><p>JGLUEã‚’ä½¿ã£ãŸLLMã®æ—¥æœ¬èªã‚¿ã‚¹ã‚¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</p>
<p>v4ãŒå…¬é–‹:<br>


<a href="https://wandb.ai/llm-leaderboard/nejumi-leaderboard4/reports/Nejumi-LLM-4--VmlldzoxMzc1OTk1MA" target="_blank" rel="noopener noreferrer">https://wandb.ai/llm-leaderboard/nejumi-leaderboard4/reports/Nejumi-LLM-4--VmlldzoxMzc1OTk1MA</a>


<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/madyagi/status/1960525757874364462?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1053" target="_blank" rel="noopener noreferrer" class="title-link">LLM-as-a-judge</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1052" target="_blank" rel="noopener noreferrer" class="title-link">OpenAIã€ChatGPTãŒç”»åƒã‚’åˆ†æã™ã‚‹ã€GPT-4Vï¼ˆãƒ“ã‚¸ãƒ§ãƒ³ï¼‰ã€ã‚’ç™ºè¡¨ã€‚å®‰å…¨æ€§ã€å—œå¥½æ€§ã€ç¦ç¥‰æ©Ÿèƒ½ã‚’å¼·åŒ–, AIDB, 2023.09</a>
<span class="snippet"><span>Comment</span><p>ãŠã†â€¦ã‚„ã¹ãˆãªâ€¦<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3ee7dc96-af6f-47f9-98c0-c6be5d9384f1" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1049" target="_blank" rel="noopener noreferrer" class="title-link">Agents: An opensource framework for autonomous language agents</a>
<span class="snippet"><span>Comment</span><p>ä»¥ä¸‹ã®ç‰¹å¾´ã‚’æŒã¤LLMAgenté–‹ç™ºã®ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯<br><br>- long-short term memory<br>- tool usage<br>- web navigation<br>- multi-agent communication<br>- human-agent interaction<br>- symbolic control<br><br>ã¾ãŸã€ä»–ã®Agent frameworkã¨é•ã„ã€ã‚´ãƒ¼ãƒ«ã‚’é”æˆã™ã‚‹ã ã®ç´°ã‹ã„ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚’ç­–å®šï¼ˆSOP; ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã¨ã‚µãƒ–ã‚´ãƒ¼ãƒ«ã‚’å®šç¾©ï¼‰ã™ã‚‹ã“ã¨ã§ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å¯¾ã—ã¦ãã‚ç´°ã‹ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®šç¾©ã§ãã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1036" target="_blank" rel="noopener noreferrer" class="title-link">SNLP2023:Is GPT-3 a Good Data Annotator?</a>
<span class="snippet"><span>Comment</span><p>GPT3ã§ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ãŸã‚‰ã€ã‚¿ã‚¹ã‚¯ã”ã¨ã«æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ä½œæˆæ–¹æ³•ã¯ç•°ãªã£ãŸãŒã€äººæ‰‹ã§ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ï¼ˆBERTã§finetuningï¼‰ã‚’ã€ä½ã‚³ã‚¹ãƒˆã§å®Ÿç¾ã§ããŸã‚ˆã€ã¨ã„ã†ç ”ç©¶</p>
<p>ã“ã®è¾ºã®è©±ã¯ã‚‚ã¯ã‚„ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1024" target="_blank" rel="noopener noreferrer">Prompt2Model: Generating Deployable Models from Natural Language   Instructions, Vijay Viswanathan+, N/A, EMNLP'23</a>
 ã‚’ä½¿ãˆã°ã„ã„ã®ã§ã¯ã€ã¨ã„ã†æ°—ãŒã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<span class="issue_date">Issue Date: 2023-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1032" target="_blank" rel="noopener noreferrer" class="title-link">LangChain Cheet Sheet</a>
<span class="snippet"><span>Comment</span><p><img width="1315" alt="image" src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6621fe24-d007-4590-b1a6-b861a6dec4ad"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1031" target="_blank" rel="noopener noreferrer" class="title-link">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«, å²¡å´å…ˆç”Ÿ, 2023</a>
<span class="snippet"><span>Comment</span><p>å²¡å´å…ˆç”Ÿã«ã‚ˆã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«<br><br>æœ€è¿‘ã®LLMã¾ã§ã®æ­´å²ã€transformerãªã©ã®åŸºç¤çš„ãªå†…å®¹ã‹ã‚‰ã€æœ€æ–°ã®å†…å®¹ã¾ã§æ•°å¼ä»˜ãã§è©³ç´°ã«ã¾ã¨ã¾ã£ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2023-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1027" target="_blank" rel="noopener noreferrer" class="title-link">LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ã§ ä½•ãŒã§ãã¦ ä½•ãŒã§ããªã„ã®ã‹</a>
<span class="snippet"><span>Comment</span><p>&gt;LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€ã€Œå½¢å¼ã€ã®å­¦ç¿’ã¯åŠ¹æœçš„ã§ã™ãŒã€ã€Œäº‹å®Ÿã€ã®å­¦ç¿’ã¯ä¸å¾—æ„ã§ã™ã€‚<br><br>&gt; ã‚·ã‚§ã‚¤ã‚¯ã‚¹ãƒ”ã‚¢ã®è„šæœ¬ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ (tiny-shakespeare) ã®<br>ã€Œãƒ­ãƒŸã‚ªã€ã‚’ã€Œãƒœãƒ–ã€ã«ç½®ãæ›ãˆã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã€æ–°ãƒ¢ãƒ‡ãƒ«ã®é ­ã®ä¸­ã§ã¯ã€Œãƒ­ãƒŸã‚ªã€ã¨ã€Œãƒœãƒ–ã€ã‚’ã©ã†è¨˜æ†¶ã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚<br><br>ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã‚‚ã€Bã§å§‹ã¾ã‚‹ã‚¸ãƒ¥ãƒªã‚¨ãƒƒãƒˆãŒæ‹ã™ã‚‹äººç‰©ã«ã¤ã„ã¦è³ªå•ã—ã¦ã‚‚ã€ãƒœãƒ–ã¨ç­”ãˆã¦ã¯ãã‚Œãªã„ã€‚<br>&gt; ãƒ­ãƒŸã‚ªã€ã¯ã€Œã‚¸ãƒ¥ãƒªã‚¨ãƒƒãƒˆã€ãŒæ‹ã—ã¦ã„ãŸã“ã®ç”·æ€§ã«é–¢é€£ä»˜ã‘ã‚‰ã‚Œã¦ãŠã‚Šã€ã€Œãƒ­ãƒŸã‚ªã€ã‚’ã€Œãƒœãƒ–ã€ã«ç½®ãæ›ãˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚<br><br>ãªã‚‹ã»ã©ã€‚</p>
<p>å‚è€ƒ: 


<a href="https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts?ref=blog.langchain.dev" target="_blank" rel="noopener noreferrer">https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts?ref=blog.langchain.dev</a>


</p>
<p>imosã•ã‚“ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’å¼•ç”¨<br>&gt; æ–‡ç« ãŒæ‚ªã‹ã£ãŸã®ã§è£œè¶³ã€‚è¿½åŠ å­¦ç¿’ã‚’å…¨ä½“ã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ã§ã™ã‚Œã°çŸ¥è­˜ã¯ç²å¾—ã—ãˆã¾ã™ï¼ˆãŒäº‹å‰å­¦ç¿’ã®çŸ¥è­˜ã‚’å¿˜å´ã™ã‚‹ãƒªã‚¹ã‚¯ã¯é«˜ã„ï¼‰ã€‚å··ã§ã‚ˆããƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å‘¼ã°ã‚Œã‚‹ã‚‚ã®ã¯ã€çŸ¥è­˜ã‚’å¸ã‚‹ã‚‰ã—ã„MLPéƒ¨ã‚’è§¦ã‚‰ãšè‡ªå·±æ³¨æ„æ©Ÿæ§‹éƒ¨ã®ã¿ã‚’æ›´æ–°ã™ã‚‹ã®ã§ã€ãã‚‚ãã‚‚çŸ¥è­˜ã‚’å¢—ã‚„ã™ã®ã¯é›£ã—ã„ã¨ã„ã†èªè­˜ã§ã™ã€‚<br><br>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imos/status/1696507787067756846?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<span class="issue_date">Issue Date: 2023-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1026" target="_blank" rel="noopener noreferrer" class="title-link">Metaã®ã€ŒLlama 2ã€ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸå•†ç”¨åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªLLMã€ŒELYZA-japanese-Llama-2-7bã€ã‚’å…¬é–‹ã—ã¾ã—ãŸ</a>
<span class="snippet"><span>Comment</span><p>å•†ç”¨åˆ©ç”¨å¯èƒ½ã€70å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚<br>ELYZAç¤¾ãŒç‹¬è‡ªã«ä½œæˆã—ãŸè©•ä¾¡ã‚»ãƒƒãƒˆã§ã¯æ—¥æœ¬èªã®OpenLLMã®ä¸­ã§æœ€é«˜æ€§èƒ½ã€‚ãŸã ã—ã€ãƒ¢ãƒ‡ãƒ«é¸å®šã®æ®µéšã§ã“ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€æœ‰åˆ©ã«åƒã„ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã¨ã®ã“ã¨ã€‚<br><br>ä¸€èˆ¬çš„ã«åˆ©ç”¨ã•ã‚Œã‚‹æ—¥æœ¬èªã®è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã§ã¯ã€ãªã‚“ã¨ã‚‚è¨€ã„é›£ã„ã€‚è‰¯ã„ã‚¿ã‚¹ã‚¯ã‚‚ã‚ã‚Œã°æ‚ªã„ã‚¿ã‚¹ã‚¯ã‚‚ã‚ã‚‹ã€‚ãŒã€å¤šåˆ†è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿è‡ªä½“ã‚‚ã‚ã¾ã‚Šæ•´å‚™ã¯é€²ã‚“ã§ã„ãªã„ã¨æƒ³åƒã•ã‚Œã‚‹ãŸã‚ã€ä¸€æ—¦è§¦ã£ã¦ã¿ã‚‹ã®ãŒè‰¯ã„ã®ã ã¨æ€ã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<span class="issue_date">Issue Date: 2023-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1025" target="_blank" rel="noopener noreferrer" class="title-link">zeno-build</a>
<span class="snippet"><span>Comment</span><p>MTã§ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ<br>


<a href="https://github.com/zeno-ml/zeno-build/tree/main/examples/analysis_gpt_mt/report" target="_blank" rel="noopener noreferrer">https://github.com/zeno-ml/zeno-build/tree/main/examples/analysis_gpt_mt/report</a>


</p>
<p>LLMã®å®Ÿé¨“ç®¡ç†ã‚’å®¹æ˜“ã«å®Ÿæ–½ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã€ç•°ãªã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã€ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã®å®Ÿé¨“ãªã©ã‚’ç°¡å˜ã«å®Ÿæ–½ã§ãã‚‹ã€‚è©•ä¾¡çµæœã‚’è‡ªå‹•çš„ã«å¯è¦–åŒ–ã—ã€interactiveã«è¡¨ç¤ºã™ã‚‹ãƒ–ãƒ©ã‚¦ã‚¶ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚ä½œæˆå¯èƒ½ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1021" target="_blank" rel="noopener noreferrer" class="title-link">Anti-hype LLM Reading list</a>
<span class="snippet"><span>Comment</span><p>LLMã®ã‚µãƒ¼ãƒ™ã‚¤ã€BERTç­‰ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®è«–æ–‡ã€è‡ªå‰ã§LLMã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã«å¿…è¦ãªè«–æ–‡ãŒã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«ã¾ã¨ã‚ã‚‰ã‚ŒãŸgist</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1003" target="_blank" rel="noopener noreferrer" class="title-link">èµ°è¡Œå‹•ç”»ã‚’èª¬æ˜ã™ã‚‹LLMã‚’ä½œæˆã—ã€80å°ã®GPUã§åˆ†æ•£ä¸¦åˆ—å­¦ç¿’ã•ã›ãŸè©±</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/947" target="_blank" rel="noopener noreferrer" class="title-link">Learning to Score System Summaries for Better Content Selection Evaluation, Peyard+, Prof. of the Workshop on New Frontiers in Summarization</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤å…¸çš„ãªè¦ç´„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã€äººé–“ã®åˆ¤æ–­ã«åŸºã¥ã„ãŸè‡ªå‹•ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®å­¦ç¿’ã‚’ææ¡ˆã—ã¾ã™ã€‚æ—¢å­˜ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’çµ„ã¿è¾¼ã¿ã€äººé–“ã®åˆ¤æ–­ã¨é«˜ã„ç›¸é–¢ã‚’æŒã¤çµ„ã¿åˆã‚ã›ã‚’å­¦ç¿’ã—ã¾ã™ã€‚æ–°ã—ã„ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®ä¿¡é ¼æ€§ã¯æ‰‹å‹•è©•ä¾¡ã«ã‚ˆã£ã¦ãƒ†ã‚¹ãƒˆã•ã‚Œã¾ã™ã€‚å­¦ç¿’æ¸ˆã¿ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦å…¬é–‹ã•ã‚Œã¾ã™ã€‚</span>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/STS%20(SemanticTextualSimilarity).html" target="_blank" rel="noopener noreferrer">#STS (SemanticTextualSimilarity)</a>
<span class="issue_date">Issue Date: 2023-07-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/910" target="_blank" rel="noopener noreferrer" class="title-link">OpenAI ã® Embeddings API ã¯ã‚¤ã‚±ã¦ã‚‹ã®ã‹ã€å®šé‡çš„ã«èª¿ã¹ã¦ã¿ã‚‹</a>
<span class="snippet"><span>Comment</span><p>[JSTSã‚¿ã‚¹ã‚¯](


<a href="https://github.com/yahoojapan/JGLUE)%E3%81%A7%E3%81%AF%E3%80%81[Tohoku" target="_blank" rel="noopener noreferrer">https://github.com/yahoojapan/JGLUE)ã§ã¯ã€[Tohoku</a>


BERT v3](


<a href="https://github.com/cl-tohoku/bert-japanese/tree/main#model-performances)" target="_blank" rel="noopener noreferrer">https://github.com/cl-tohoku/bert-japanese/tree/main#model-performances)</a>


ã¨ [LUKE](


<a href="https://github.com/studio-ousia/luke)%E3%81%8C%E6%9C%80%E3%82%82%E6%80%A7%E8%83%BD%E3%81%8C%E8%89%AF%E3%81%84%E3%82%89%E3%81%97%E3%81%84%E3%80%82" target="_blank" rel="noopener noreferrer">https://github.com/studio-ousia/luke)ãŒæœ€ã‚‚æ€§èƒ½ãŒè‰¯ã„ã‚‰ã—ã„ã€‚</a>


<br><br>[SimCSE](


<a href="https://huggingface.co/pkshatech/simcse-ja-bert-base-clcmlp)%E3%82%88%E3%82%8A%E3%82%82%E6%80%A7%E8%83%BD%E3%81%8C%E8%89%AF%E3%81%84%E3%81%AE%E3%81%AF%E8%88%88%E5%91%B3%E6%B7%B1%E3%81%84%E3%80%82" target="_blank" rel="noopener noreferrer">https://huggingface.co/pkshatech/simcse-ja-bert-base-clcmlp)ã‚ˆã‚Šã‚‚æ€§èƒ½ãŒè‰¯ã„ã®ã¯èˆˆå‘³æ·±ã„ã€‚</a>


<br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<span class="issue_date">Issue Date: 2023-07-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/899" target="_blank" rel="noopener noreferrer" class="title-link">FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning, 2023</a>
<span class="snippet"><span>GPT Summary</span>- FlashAttention-2ã¯ã€é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã«ãŠã‘ã‚‹Transformerã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ææ¡ˆã•ã‚ŒãŸæ‰‹æ³•ã§ã™ã€‚FlashAttention-2ã¯ã€éå¯¾ç§°ãªGPUãƒ¡ãƒ¢ãƒªéšå±¤ã‚’åˆ©ç”¨ã—ã¦ãƒ¡ãƒ¢ãƒªã®ç¯€ç´„ã¨ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®é«˜é€ŸåŒ–ã‚’å®Ÿç¾ã—ã€æœ€é©åŒ–ã•ã‚ŒãŸè¡Œåˆ—ä¹—ç®—ã«æ¯”ã¹ã¦ç´„2å€ã®é«˜é€ŸåŒ–ã‚’é”æˆã—ã¾ã™ã€‚ã¾ãŸã€FlashAttention-2ã¯GPTã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦ã‚‚é«˜é€ŸåŒ–ã‚’å®Ÿç¾ã—ã€æœ€å¤§225 TFLOPs/sã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é€Ÿåº¦ã«é”ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Flash Attention1ã‚ˆã‚Šã‚‚2å€é«˜é€ŸãªFlash Attention 2</p>
<p>Flash Attention1ã¯ã“ã¡ã‚‰ã‚’å‚ç…§<br>


<a href="https://arxiv.org/pdf/2205.14135.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/2205.14135.pdf</a>


<br><br>QK Matrixã®è¨ˆç®—ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†ã‘ã¦SRAMã«é€ã£ã¦å‡¦ç†ã™ã‚‹ã“ã¨ã§ã€3å€é«˜é€ŸåŒ–ã—ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’10-20å€ã‚’é”æˆã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/935f61f3-97ce-4e76-826b-040f92ca567c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Faithfulness.html" target="_blank" rel="noopener noreferrer">#Faithfulness</a>
<span class="issue_date">Issue Date: 2023-07-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/896" target="_blank" rel="noopener noreferrer" class="title-link">Measuring Faithfulness in Chain-of-Thought Reasoning, Anthropic, 2023</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€Chain-of-Thoughtï¼ˆCoTï¼‰æ¨è«–ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§è³ªå•ã«ç­”ãˆã‚‹æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ãã®æ¨è«–ãŒå®Ÿéš›ã®æ¨è«–ã‚’å¿ å®Ÿã«è¡¨ã—ã¦ã„ã‚‹ã‹ã¯ä¸æ˜ã§ã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€CoTæ¨è«–ã®å¿ å®Ÿã•ã‚’èª¿æŸ»ã—ã€CoTã«ä»‹å…¥ã™ã‚‹ã“ã¨ã§ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ãŒã©ã®ã‚ˆã†ã«å¤‰åŒ–ã™ã‚‹ã‹ã‚’èª¿ã¹ã‚‹ã€‚çµæœã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºã‚„ã‚¿ã‚¹ã‚¯ã«ã‚ˆã£ã¦CoTã®å¿ å®Ÿã•ãŒç•°ãªã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2023-07-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/894" target="_blank" rel="noopener noreferrer" class="title-link">trl_trlx</a>
<span class="snippet"><span>Comment</span><p>TRL - å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚‹LLMã®å­¦ç¿’ã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª<br>


<a href="https://note.com/npaka/n/nbb974324d6e1" target="_blank" rel="noopener noreferrer">https://note.com/npaka/n/nbb974324d6e1</a>


</p>
<p>trlã‚’ä½¿ã£ã¦æ—¥æœ¬èªLLMã‚’SFTã‹ã‚‰RLHFã¾ã§ä¸€é€šã‚Šå­¦ç¿’ã•ã›ã¦ã¿ã‚‹<br>


<a href="https://www.ai-shift.co.jp/techblog/3583" target="_blank" rel="noopener noreferrer">https://www.ai-shift.co.jp/techblog/3583</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/886" target="_blank" rel="noopener noreferrer" class="title-link">LLaMA2ã‚’3è¡Œã§è¨“ç·´</a>
<span class="snippet"><span>Comment</span><p>LLaMA2ã‚’3è¡Œã§ã€1ã¤ã®A100GPUã€QLoRAã§ã€è‡ªå‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã™ã‚‹æ–¹æ³•</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/880" target="_blank" rel="noopener noreferrer" class="title-link">Quantized LLaMA2</a>
<span class="snippet"><span>Comment</span><p>LLaMA2ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ä½œã•ã›ã‚‹ãŸã‚ã«ã€QLoRAã§é‡å­åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/879" target="_blank" rel="noopener noreferrer" class="title-link">LLongMA2</a>
<span class="snippet"><span>Comment</span><p>LLaMA2ã®context windowã‚’8kã«ã—ã¦è¨“ç·´ã€‚ã‚ªãƒªã‚¸ãƒŠãƒ«ã®LLaMA2ã¨åŒç­‰ã®æ€§èƒ½ã§8k contextã‚’åˆ©ç”¨å¯èƒ½ã€‚</p>
<p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/enricoshippole/status/1682054848584228866?s=46&t=LJIgfuO352oK3zU2FKFpNA"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DialogueGeneration.html" target="_blank" rel="noopener noreferrer">#DialogueGeneration</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/876" target="_blank" rel="noopener noreferrer" class="title-link">ChatBot Arenaã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</a>
<span class="snippet"><span>Comment</span><p>33kã®conversationã€2ã¤ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å¯¾ã™ã‚‹äººé–“ã®preferenceã‚¹ã‚³ã‚¢ä»˜ã<br>20ç¨®é¡ã®SoTAãƒ¢ãƒ‡ãƒ«ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å«ã¿ã€13kã®ãƒ¦ãƒ‹ãƒ¼ã‚¯IPã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒã‚ã‚Šã€3Kã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã«ã‚ˆã‚‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ã</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/NaturalLanguageUnderstanding.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageUnderstanding</a>
<span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/853" target="_blank" rel="noopener noreferrer" class="title-link">DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¨å¥¨ã‚¿ã‚¹ã‚¯ã‚’æ“ä½œåŒ–ã—ã€DataFinderãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ãŸã€‚DataFinderãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€è‡ªå‹•çš„ã«æ§‹ç¯‰ã•ã‚ŒãŸå¤§è¦æ¨¡ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚»ãƒƒãƒˆã¨å°‚é–€å®¶ã«ã‚ˆã‚‹è©•ä¾¡ã‚»ãƒƒãƒˆã‚’å«ã‚“ã§ã„ã‚‹ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¨å¥¨ã®ãŸã‚ã®å„ªã‚ŒãŸãƒã‚¤ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒªãƒˆãƒªãƒ¼ãƒã‚’ææ¡ˆã—ã€é–¢é€£ã™ã‚‹æ¤œç´¢çµæœã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã¯ä¸€èˆ¬ã«å…¬é–‹ã•ã‚Œã‚‹ã€‚</span>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/825" target="_blank" rel="noopener noreferrer" class="title-link">Are Human Explanations Always Helpful? Towards Objective Evaluation of Human Natural Language Explanations</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€èª¬æ˜å¯èƒ½ãªNLPãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦ã€äººé–“ã«ã‚ˆã‚‹æ³¨é‡ˆä»˜ã‘ã®èª¬æ˜ã®å“è³ªã‚’è©•ä¾¡ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦æ¤œè¨ã—ã¦ã„ã¾ã™ã€‚å¾“æ¥ã®Simulatabilityã‚¹ã‚³ã‚¢ã«ä»£ã‚ã‚‹æ–°ã—ã„ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ææ¡ˆã—ã€5ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§è©•ä¾¡ã—ã¾ã—ãŸã€‚çµæœã¨ã—ã¦ã€ææ¡ˆã—ãŸãƒ¡ãƒˆãƒªãƒƒã‚¯ãŒã‚ˆã‚Šå®¢è¦³çš„ãªè©•ä¾¡ã‚’å¯èƒ½ã«ã™ã‚‹ä¸€æ–¹ã€Simulatabilityã¯ä¸ååˆ†ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<span class="issue_date">Issue Date: 2023-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/784" target="_blank" rel="noopener noreferrer" class="title-link">Awesome Multimodal LLMs</a>
<span class="snippet"><span>Comment</span><p>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªLLMã®ãƒªã‚¹ãƒˆãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2023-07-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/777" target="_blank" rel="noopener noreferrer" class="title-link">How Long Can Open-Source LLMs Truly Promise on Context Length?, 2023</a>
<span class="snippet"><span>Comment</span><p>LLMã®contexté•·ã‚’ä¼¸ã°ã™éš›ã®æ–¹æ³•ã¨å¾—ã‚‰ã‚ŒãŸçŸ¥è¦‹ãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/767" target="_blank" rel="noopener noreferrer" class="title-link">OpenLLaMA 13B, 2023</a>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4268eb3f-349f-4ebe-adeb-2cbfcb7cfe17" alt="image" loading="lazy"></p>
<p>ãã‚‚ãã‚‚OpenLLaMAã«ã¯ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ã®LLaMAã¨æ¯”è¼ƒã—ã¦ã€tokenizerãŒã‚¹ãƒšãƒ¼ã‚¹ã‚’ç„¡è¦–ã™ã‚‹ã¨ã„ã†issueãŒã‚ã‚‹æ¨¡æ§˜ã€‚ã‚¹ãƒšãƒ¼ã‚¹ã®æƒ…å ±ãŒã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªã‚¿ã‚¹ã‚¯ã€ãŸã¨ãˆã°code generationãªã©ã«ã¯è¦æ³¨æ„ã€‚<br><br>


<a href="https://github.com/openlm-research/open_llama/issues/40" target="_blank" rel="noopener noreferrer">https://github.com/openlm-research/open_llama/issues/40</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/678" target="_blank" rel="noopener noreferrer" class="title-link">Prompt Engineering vs. Blind Prompting, 2023</a>
<span class="snippet"><span>Comment</span><p>experimentalãªæ‰‹æ³•ã§prompt engineeringã™ã‚‹éš›ã®overview</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/676" target="_blank" rel="noopener noreferrer" class="title-link">open LLM Leaderboard</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<span class="issue_date">Issue Date: 2023-05-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/675" target="_blank" rel="noopener noreferrer" class="title-link">Assisted Generation: a new direction toward low-latency text generation, 2023</a>
<span class="snippet"><span>Comment</span><p>1 lineåŠ ãˆã‚‹ã¨transformerã®generationãŒæœ€å¤§3å€ç¨‹åº¦é«˜é€ŸåŒ–ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã£ãŸã‚‰ã—ã„</p>
<p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fecc1c5e-b9e5-4844-af96-ba48c3d60fae" alt="image" loading="lazy"><br><br>assistant modelã‚’ãƒ­ãƒ¼ãƒ‰ã—generateã«å¼•æ•°ã¨ã—ã¦æ¸¡ã™ã ã‘<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7dabf3bf-cd32-469c-abba-f1269318576d" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<span class="issue_date">Issue Date: 2023-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/669" target="_blank" rel="noopener noreferrer" class="title-link">METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments, Banerjee+, CMU, ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and_or Summarization</a>
<span class="snippet"><span>Comment</span><p># ã‚¤ãƒ³ãƒˆãƒ­<br><br>MTã®è©•ä¾¡ã¯BLEUãŒææ¡ˆã•ã‚Œã¦ã‹ã‚‰éå»2å¹´é–“ã§æ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ã€‚BLEUã¯NIST metricã¨é–¢é€£ã—ã¦ãŠã‚Šã€ç ”ç©¶ã§åˆ©ç”¨ã•ã‚Œã¦ããŸã€‚è‡ªå‹•è©•ä¾¡ã¯ç´ æ—©ãã€ã‚ˆã‚Šç°¡ä¾¿ã«ã€human evaluationã‚ˆã‚Šã‚‚å®‰ä¾¡ã«è©•ä¾¡ã‚’ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã¾ãŸã€è‡ªå‹•è©•ä¾¡ã¯ä»–ã®ã‚·ã‚¹ãƒ†ãƒ ã¨ã®æ¯”è¼ƒã ã‘ã§ãªãã€ongoingãªã‚·ã‚¹ãƒ†ãƒ ã®æ”¹å–„ã«ã‚‚ä½¿ãˆã‚‹ã€‚<br><br>éå»MTã®è©•ä¾¡ã¯äººæ‰‹ã§è¡Œã‚ã‚Œã¦ããŸã€‚MTã®è©•ä¾¡ã§åˆ©ç”¨ã•ã‚Œã‚‹æŒ‡æ¨™ã¯fairly intensiveã§well establishedãªä¸€æ–¹ã§ã€MTã®è©•ä¾¡å…¨ä½“ã¯è¤‡é›‘ã•ã¨ã‚¿ã‚¹ã‚¯ä¾å­˜ã§ã‚ã‚‹ã€‚çµæœçš„ã«MTã®è©•ä¾¡ãã®ã‚‚ã®ãŒç ”ç©¶åˆ†é‡ã¨ãªã£ã¦ããŸã€‚å¤šãã®è©•ä¾¡æŒ‡æ¨™ãŒææ¡ˆã•ã‚Œã¦ããŸãŒã€å…¨ã¦ãŒç°¡å˜ã«å®šé‡åŒ–ã§ãã‚‹ã‚ã‘ã§ã¯ãªã„ã€‚è¿‘å¹´ã®FEMTIã¨ã„ã£ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€MTè©•ä¾¡ã®ãŸã‚ã®å¤šé¢çš„ãªmeasureã‚’åŠ¹æœçš„ã§ãƒ¦ãƒ¼ã‚¶ãŒèª¿æ•´å¯èƒ½ãªæ–¹æ³•ã§è€ƒæ¡ˆã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã€å˜ä¸€ã®1æ¬¡å…ƒã®æ•°å€¤ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¯ã€MTè©•ä¾¡ã®å…¨ã¦ã®aspectã‚’æ‰ãˆã‚‹ã“ã¨ãŒã§ããªã„ãŒã€ã“ã®ã‚ˆã†ãªãƒ¡ãƒˆãƒªãƒƒã‚¯ã¯æœªã å¤§ããªä¾¡å€¤ãŒå®Ÿç”¨æ€§ã®è¦³ç‚¹ã§å­˜åœ¨ã™ã‚‹ã€‚åŠ¹æœçš„ãƒ»ã‹ã¤åŠ¹ç‡çš„ã§ã‚ã‚‹ãŸã‚ã«ã€MTè©•ä¾¡ã®è‡ªå‹•æ€§èƒ½æŒ‡æ¨™ã¯ã„ãã¤ã‹ã®åŸºæœ¬çš„ãªåŸºæº–ã‚’æº€ãŸã™å¿…è¦ãŒã‚ã‚‹ï¼š<br><br>- MTã®è³ªã«å¯¾ã™ã‚‹äººé–“ãŒå®šé‡åŒ–ã—ãŸæŒ‡æ¨™ã¨é«˜ã„ç›¸é–¢ãŒã‚ã‚‹ã“ã¨<br><br>- ç•°ãªã‚‹ã‚·ã‚¹ãƒ†ãƒ é–“ã€åŒã˜ã‚·ã‚¹ãƒ†ãƒ ã®ç•°ãªã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³é–“ã®å“è³ªã®é•ã„ã«ã§ãã‚‹ã ã‘sensitiveã§ã‚ã‚‹ã“ã¨<br><br>- ä¸€è²«æ€§ãŒã‚ã‚Šã€ä¿¡é ¼æ€§ãŒã‚ã‚Šã€ä¸€èˆ¬çš„ã§ã‚ã‚‹å¿…è¦<br><br>  - ä¸€è²«æ€§: åŒã˜MTã‚·ã‚¹ãƒ†ãƒ ãŒé¡ä¼¼ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ç¿»è¨³ã—ãŸã‚‰é¡ä¼¼ã—ãŸã‚¹ã‚³ã‚¢ã‚’è¿”ã™<br><br>  - ä¿¡é ¼æ€§: é¡ä¼¼ã—ãŸã‚¹ã‚³ã‚¢ã‚’æŒã¤MTã‚·ã‚¹ãƒ†ãƒ ã¯ä¼¼ãŸã‚ˆã†ã«é¡ä¼¼ã—ãŸå‹•ä½œã‚’ã™ã‚‹ã“ã¨<br><br>  - ä¸€èˆ¬çš„: ã•ã¾ã–ã¾ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã‚„ã‚·ãƒŠãƒªã‚ªã®MTã‚¿ã‚¹ã‚¯ã«é©ç”¨å¯èƒ½ã§ã‚ã‚‹ã“ã¨<br><br>ã“ã‚Œã‚‰æŒ‡æ¨™ã‚’å…¨ã¦æº€ãŸã™ã“ã¨ã¯å›°é›£ã§ã‚ã‚‹ãŒã€ã“ã‚Œã¾ã§ã«ææ¡ˆã•ã‚ŒãŸå…¨ã¦ã®æŒ‡æ¨™ã¯ã€è¦ä»¶ã®å…¨ã¦ã§ã¯ãªã„ã«ã›ã‚ˆã€ã»ã¨ã‚“ã©ã®è¦ä»¶ã«å¯¾ã—ã¦é©åˆ‡ã«å¯¾å‡¦ã§ãã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã€‚ã“ã‚Œã‚‰ã®è¦ä»¶ã‚’é©åˆ‡ã«å®šé‡åŒ–ã—ã€å…·ä½“çš„ãªãƒ†ã‚¹ãƒˆå°ºåº¦ã«å¤‰æ›ã™ã‚‹ã¨ã€MTã®è©•ä¾¡æŒ‡æ¨™ã‚’æ¯”è¼ƒã€ãŠã‚ˆã³è©•ä¾¡ã§ãã‚‹å…¨ä½“çš„ãªåŸºæº–ã¨ã—ã¦æ‰±ãˆã‚‹ã€‚<br><br>æœ¬ç ”ç©¶ã§ã¯ã€METEORã‚’ææ¡ˆã™ã‚‹ã€‚METEORã¯BLEUã®ã„ãã¤ã‹ã®å¼±ç‚¹ã«å¯¾å‡¦ã—ãŸæ‰‹æ³•ã§ã‚ã‚‹ã€‚<br><br><br><br># METEOR Metric<br><br>## METEORã§å¯¾å‡¦ã™ã‚‹BLEUã®å¼±ç‚¹<br><br>BLEUã¯n-gramã®precisionã‚’æ¸¬ã‚‹æŒ‡æ¨™ã§ã‚ã‚Šã€recallã‚’ç›´æ¥çš„ã«è€ƒæ…®ã—ã¦ã„ãªã„ã€‚recallã¯ç¿»è¨³æ–‡ãŒæ­£è§£æ–‡ã®contentã‚’ã©ã‚Œã ã‘coverã§ãã¦ã„ã‚‹ã‹ã‚’æ¸¬å®šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ãŸã‚é‡è¦ãªæŒ‡æ¨™ã§ã‚ã‚‹ã€‚BLEUã¯è¤‡æ•°ã®å‚ç…§è¨³ã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã€recallã®æ¦‚å¿µã‚’å®šç¾©ã™ã‚‹ã“ã¨ãŒã§ããªã„ã€‚ä»£ã‚ã‚Šã«ã€BLEUã§ã¯brevity penaltyã‚’å°å…¥ã—ã€çŸ­ã™ãã‚‹ç¿»è¨³ã«ã¯ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’ä¸ãˆã‚‹ã‚ˆã†ã«ã—ã¦ã„ã‚‹ã€‚<br><br>NIST metricã‚‚ã‚³ãƒ³ã‚»ãƒ—ãƒˆä¸Šã¯BLEUã¨åŒæ§˜ã®å¼±ç‚¹ã‚’æŒã£ã¦ã„ã‚‹ã€‚METEORãŒå¯¾å‡¦ã™ã‚‹BLEUã‚„NISTã¯ä»¥ä¸‹ã¨ãªã‚‹ï¼š<br><br>- The Lack of Recall:<br><br>  - å›ºå®šã®brevity penaltyã‚’ä¸ãˆã‚‹ã ã‘ã§ã¯ã€recallã«å¯¾ã™ã‚‹é©åˆ‡ãªè£œå„Ÿã¨ã¯ãªã£ã¦ã„ãªã„ã€‚å®Ÿé¨“çµæœãŒã“ã‚Œã‚’å¼·ãç¤ºã—ã¦ã„ã‚‹ã€‚<br><br>- Use of Higher Order N-grams:<br><br>  - BLEUã«ãŠã‘ã‚‹higher orderã®N-gramã®åˆ©ç”¨ã¯ã€ç¿»è¨³ã®æ–‡æ³•çš„ãªè‰¯ã•ã‚’é–“æ¥çš„ã«æ¸¬å®šã—ã¦ã„ã‚‹ã€‚METEORã§ã¯ã‚ˆã‚Šç›´æ¥çš„ã«grammarticalityï¼ˆã‚ã‚‹ã„ã¯word orderï¼‰ã‚’è€ƒæ…®ã™ã‚‹ã€‚å®Ÿé¨“çµæœã§ã¯ã€human judgmentsã¨ã‚ˆã‚Šè‰¯ã„ç›¸é–¢ã‚’ç¤ºã—ãŸã€‚<br><br>- Lack of Explicit Word-matching between Translation and Reference<br><br>  - N-gramã§ã¯æ˜ç¤ºçš„ãªword-to-word matchingã‚’å¿…è¦ã—ãªã„ãŸã‚ã€çµæœçš„ã«æ­£ã—ããªã„ãƒãƒƒãƒã€å…·ä½“çš„ã«ã¯å…±é€šã®æ©Ÿèƒ½èªç­‰ã®ãƒãƒƒãƒã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¦ã—ã¾ã†ã€‚<br><br>- Use of Geometric Averaging of N-grams<br><br>  - BLEUã¯å¹¾ä½•å¹³å‡ï¼ˆi.e. 1,2,3,4-gramãã‚Œãã‚Œã®precisionã®ç©ã®1/nä¹—æ ¹ï¼‰ã‚’ã¨ã£ã¦ã„ã‚‹ãŸã‚ã€n-gramã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®1ã¤ã§ã‚‚ã‚¼ãƒ­ã«ãªã‚‹ã¨ã€å¹¾ä½•å¹³å‡ã®çµæœã‚‚ã‚¼ãƒ­ã¨ãªã‚‹ã€‚çµæœçš„ã«ã€sentenceã‚ã‚‹ã„ã¯segmentãƒ¬ãƒ™ãƒ«ã§BLEUã‚¹ã‚³ã‚¢ã‚’æ¸¬ã‚ã†ã¨ã™ã‚‹ã¨æ„å‘³ã®ãªã„ã‚‚ã®ã¨ãªã‚‹ï¼ˆã‚¼ãƒ­ã«ãªã‚‹ãŸã‚ï¼‰ã€‚BLEUã¯å…¨ä½“ã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆï¼ˆæ–‡ãƒ¬ãƒ™ãƒ«ã§ã¯ãªãï¼‰ã®ã‚«ã‚¦ãƒ³ãƒˆã‚’é›†ç´„ã™ã‚‹ã®ã¿ã§ã‚ã‚‹ãŒã€sentence levelã®indicatorã‚‚ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨ã—ã¦ã¯æœ‰ç”¨ã§ã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚å®Ÿé¨“çµæœã«ã‚ˆã‚‹ã¨ã€n-gramã®ç®—è¡“å¹³å‡ã‚’ã¨ã‚‹ã‚ˆã†ã«BLEUã‚¹ã‚³ã‚¢ã‚’æ”¹å¤‰ã—ãŸå ´åˆã€human judgmentsã¨ã®ç›¸é–¢ãŒæ”¹å–„ã—ãŸã€‚<br><br><br><br>## Meteor Metric<br><br>å‚ç…§è¨³ãŒè¤‡æ•°ã‚ã‚‹å ´åˆã¯æœ€ã‚‚ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã‚‚ã®ã‚’å‡ºåŠ›ã™ã‚‹ã€‚METEORã¯word-to-wordã®ãƒãƒƒãƒãƒ³ã‚°ã«åŸºã¥ã„ãŸæŒ‡æ¨™ã§ã‚ã‚‹ã€‚ã¾ãšã€å‚ç…§è¨³ã¨å€™è£œè¨³ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«å˜èªåŒå£«ã®alignmentã‚’ä½œæˆã™ã‚‹ã€‚ã“ã®ã¨ãunigramã‚’åˆ©ç”¨ã—ã¦one-to-manyã®mappingã‚’ã™ã‚‹ã€‚wordnetã®åŒç¾©èªã‚’åˆ©ç”¨ã—ãŸã‚Šã€porter-stemmerã‚’åˆ©ç”¨ã—ã‚¹ãƒ†ãƒŸãƒ³ã‚°ã—ãŸçµæœã‚’æ´»ç”¨ã—alignmentã‚’ä½œæˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ç¶šã„ã¦ã€ãã‚Œãã‚Œã®unigramã®mapppingã®ã†ã¡ã€æœ€ã‚‚å¤§ããªéƒ¨åˆ†é›†åˆã®mappingã‚’é¸æŠã—ã€å¯¾å¿œã™ã‚‹unigramã®alignmentã¨ã™ã‚‹ã€‚ã‚‚ã—alignmentã®å€™è£œã¨ã—ã¦è¤‡æ•°ã®å€™è£œãŒã‚ã£ãŸå ´åˆã€unigram mappingã®crossãŒå°‘ãªã„æ–¹ã‚’æ¡ç”¨ã™ã‚‹ã€‚ã“ã®ä¸€é€£ã®æ“ä½œã¯stageã¨ã—ã¦å®šç¾©ã•ã‚Œã€å„stageã”ã¨ã«mapping moduleï¼ˆåŒç¾©èªä½¿ã†ã®ã‹ã€stemmingçµæœä½¿ã†ã®ã‹ãªã©ï¼‰ã‚’å®šç¾©ã™ã‚‹ã€‚ãã—ã¦ã€å¾Œæ®µã®stageã§ã¯ã€ä»¥å‰ã®stageã§mappingã•ã‚Œã¦ã„ãªunigramãŒmappingã®å¯¾è±¡ã¨ãªã‚‹ã€‚ãŸã¨ãˆã°ã€first stageã«exact matchã‚’mapping moduleã¨ã—ã¦åˆ©ç”¨ã—ã€æ¬¡ã®stageã§porter stemmerã‚’mapping moduleã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ã¨ã€ã‚ˆã‚Šsurface formã‚’é‡è¦–ã—ãŸmappingãŒæœ€åˆã«ä½œæˆã•ã‚Œã€surface formã§ãƒãƒƒãƒãƒ³ã‚°ã—ãªã‹ã£ãŸã‚‚ã®ãŒã€stemmingçµæœã«ã‚ˆã£ã¦ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚‹ã€‚ã©ã®é †ç•ªã§stageã‚’æ§‹æˆã™ã‚‹ã‹ã€ä½•å€‹ã®stageã‚’æ§‹æˆã™ã‚‹ã‹ã€ã©ã®mapping moduleã‚’åˆ©ç”¨ã™ã‚‹ã‹ã¯ä»»æ„ã§ã‚ã‚‹ã€‚åŸºæœ¬çš„ã«ã¯ã€1st-stageã§ã¯"exact match", 2nd-stageã§ã¯"porter stem", 3rd-stageã§ã¯"wordnet synonymy"ã‚’åˆ©ç”¨ã™ã‚‹ã€‚ã“ã®ã‚ˆã†ã«ã—ã¦å®šç¾©ã•ã‚ŒãŸalignmentã«åŸºã¥ã„ã¦ã€unigram Precisionã¨Recallã‚’è¨ˆç®—ã™ã‚‹ã€‚<br><br>Precisionã¯ã€å€™è£œè¨³ã®unigramã®ã†ã¡ã€å‚ç…§è¨³ã®unigramã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸå‰²åˆã¨ãªã‚‹ã€‚Recallã¯ã€å‚ç…§è¨³ã®unigramã®ã†ã¡ã€å€™è£œè¨³ã‹ã‚‰ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚ŒãŸå‰²åˆã¨ãªã‚‹ã€‚ãã—ã¦ã€Precisionã‚’1, Recallã‚’9ã®é‡ã¿ã¨ã—ã¦ã€Recall-OrientedãªFå€¤ã‚’è¨ˆç®—ã™ã‚‹ã€‚ã“ã®Få€¤ã¯unigramãƒãƒƒãƒã«åŸºã¥ã„ã¦ã„ã‚‹ã®ã§ã€ã‚ˆã‚Šé•·ã„ç³»åˆ—ã®ãƒãƒƒãƒã‚’è€ƒæ…®ã™ã‚‹ãŸã‚ã«ã€alignmentã«å¯¾ã—ã¦ã€ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’è¨ˆç®—ã™ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€å‚ç…§è¨³ã¨å€™è£œè¨³ã§é€£ç¶šã—ãŸunigramãƒãƒƒãƒã¨ã—ã¦ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®åŒå£«ã‚’chunkã¨ã—ã¦æ‰±ã„ã€ãƒãƒƒãƒãƒ³ã‚°ã—ãŸunigramã«å¯¾ã™ã‚‹chunkã®æ•°ã«åŸºã¥ã„ã¦ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’è¨ˆç®—ã™ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b3aaf2f6-ebfc-4561-9b5e-c14a1c10a983" alt="image" loading="lazy"><br><br>ãƒãƒ£ãƒ³ã‚¯ã®æ•°ãŒå¤šã‘ã‚Œã°å¤šã„ã»ã©ãƒšãƒŠãƒ«ãƒ†ã‚£ãŒå¢—åŠ ã™ã‚‹ã€‚ãã—ã¦ã€æœ€çµ‚çš„ã«ã‚¹ã‚³ã‚¢ã¯ä¸‹è¨˜å¼ã§è¨ˆç®—ã•ã‚Œã‚‹ï¼š<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e591c2e4-3d92-4f26-ae0a-5fd782346dbd" alt="image" loading="lazy"><br><br>æœ€å¤§ã§Få€¤ãŒ50%ã¾ã§æ¸›è¡°ã™ã‚‹ã‚ˆã†ã«ãƒšãƒŠãƒ«ãƒ†ã‚£ãŒã‹ã‹ã‚‹ã€‚<br><br><br><br># è©•ä¾¡<br><br>## Data<br><br>DARPA/TIDES 2003 Arabic-to-English, Chinese-to-English ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã€‚Chinese dataã¯920 sentences, Arabic datasetã¯664 sentencesã§æ§‹æˆã•ã‚Œã‚‹ã€‚ãã‚Œãã‚Œã®sentenceã«ã¯ã€ãã‚Œãã‚Œã®sentenceã«ã¯ã€4ç¨®é¡ã®referenceãŒä»˜ä¸ã•ã‚Œã¦ã„ã‚‹ã€‚åŠ ãˆã¦ã€Chinese dataã§ã¯7ç¨®é¡ã®ã‚·ã‚¹ãƒ†ãƒ ã€Arabic dataã§ã¯6ç¨®é¡ã®ã‚·ã‚¹ãƒ†ãƒ ã®å„sentenceã«å¯¾ã™ã‚‹ç¿»è¨³çµæœã¨ã€2åã®ç‹¬ç«‹ã—ãŸhuman judgmentsã®çµæœãŒä»˜ä¸ã•ã‚Œã¦ã„ã‚‹ã€‚human judgmentsã¯ã€Adequacyã¨Fluency Scoreã®2ã¤ã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹ã€‚ãã‚Œãã‚Œã®ã‚¹ã‚³ã‚¢ã¯0--5ã®ãƒ¬ãƒ³ã‚¸ã§å¤‰åŒ–ã™ã‚‹ã€‚æœ¬è©•ä¾¡ã§ã¯ã€Combined Scoreã€ã™ãªã‚ã¡2åã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã£ã¦ä»˜ä¸ã•ã‚ŒãŸAdequacy Scoreã¨Fluency Scoreã‚’å¹³å‡ã—ãŸã‚‚ã®ã‚’ç”¨ã„ã‚‹ã€‚<br><br><br><br>æœ¬ç ”ç©¶ã®ç›®çš„ã¨ã—ã¦ã¯ã€sentenceå˜ä½ã§ã®è©•ä¾¡ã‚’è¡Œã†ã“ã¨ã ãŒã€BLEUã‚„NISTã¯ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã§è©•ä¾¡ã‚’è¡Œã†æŒ‡æ¨™ã®ãŸã‚ã€ã¾ãšã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã§human judgeã¨ã®correlationã‚’æ¸¬å®šã€‚correlationã‚’æ¸¬ã‚‹éš›ã¯ã€å„ã‚·ã‚¹ãƒ†ãƒ ã”ã¨ã«Combined Scoreã®å¹³å‡ã‚’ã¨ã‚Šã€human judgmentã®ç·åˆçš„ãªçµæœã‚’1ã¤ã®ã‚¹ã‚³ã‚¢ã¨ã—ã¦è¨ˆç®—ã€‚ã¾ãŸã‚·ã‚¹ãƒ†ãƒ ã®ã™ã¹ã¦ã®ç¿»è¨³çµæœã«å¯¾ã™ã‚‹å„ç¨®metricã‚’é›†ç´„ã™ã‚‹ã“ã¨ã§ã€ã‚·ã‚¹ãƒ†ãƒ ã”ã¨ã«å„ç¨®metricã®å€¤ã‚’1ã¤ãšã¤ä»˜ä¸ã—ã€ä¸¡è€…ã§ç›¸é–¢ã‚’æ¸¬ã£ãŸã€‚çµæœã¯ä»¥ä¸‹ã®ã‚ˆã†ã«METEORãŒæœ€ã‚‚é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ãŸã€‚METEORã®subcomponentsã‚‚BLEUã‚„NISTã‚ˆã‚Šã‚‚é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7ffa4c3c-7698-4075-9e9a-9db199d535af" alt="image" loading="lazy"><br><br><br><br>æ–‡ãƒ¬ãƒ™ãƒ«ã§human judgeã¨ã®correlationã‚’æ¸¬ã£ãŸçµæœã¯ä¸‹è¨˜ã€‚æ–‡ãƒ¬ãƒ™ãƒ«ã§æ¸¬ã‚‹éš›ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ã”ã¨ã«ã€ã‚·ã‚¹ãƒ†ãƒ ãŒç¿»è¨³ã—ãŸã™ã¹ã¦ã®ç¿»è¨³çµæœã«å¯¾ã—METEORã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã€fluencyã¨adequacyã‚¹ã‚³ã‚¢ã®å¹³å‡å€¤ã¨ã®ç›¸é–¢ã‚’æ¸¬ã£ãŸã€‚ãã—ã¦å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã”ã¨ã«ã€ã‚·ã‚¹ãƒ†ãƒ ã”ã¨ã®ç›¸é–¢ä¿‚æ•°ã®å¹³å‡ã‚’ç®—å‡ºã—ãŸã€‚<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0264554c-4f21-47dc-aa58-c7ecfdd6aa47" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b638a329-06a2-4c9f-9005-eae9fa38bf42" alt="image" loading="lazy"><br><br><br><br>ä»–ã®metricã¨ã®æ¯”è¼ƒçµæœã¯ä¸‹è¨˜ã§ã€METEORãŒæœ€ã‚‚é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/da31b9ca-dee4-4c59-8e10-ca765bc00b36" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6718194c-c9e2-4b5d-b02c-00776a469f18" alt="image" loading="lazy"><br><br><br><br>ç¶šã„ã¦ã€ç•°ãªã‚‹word mappingè¨­å®šã§correlationã‚’æ¸¬ã£ãŸã€‚çµæœã¯ä¸‹è¨˜ã§ã€Exact, Porter, Wordnet-Synonymã®é †ç•ªã§3-stageã‚’æ§‹æˆã™ã‚‹æ–¹æ³•ãŒæœ€ã‚‚é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/428cdfdd-e20f-4a56-9e1e-06def83a8cab" alt="image" loading="lazy"><br><br><br><br>æœ€å¾Œã«ã€æ–‡ãƒ¬ãƒ™ãƒ«ã®è©•ä¾¡ã¯annotatoré–“ã®aggreementãŒä½ãã€ãƒã‚¤ã‚¸ãƒ¼ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ã¦ã„ã‚‹ã€‚ã“ã®ãƒã‚¤ã‚ºã‚’ç·©å’Œã™ã‚‹ãŸã‚ã«ã€ã‚¹ã‚³ã‚¢ã‚’normalizeã—correlationã‚’æ¸¬å®šã—ãŸã€‚çµæœã¯ä¸‹è¨˜ã§ã€normalizeã—ãŸã“ã¨ã«ã‚ˆã£ã¦correlationãŒæ”¹å–„ã—ã¦ã„ã‚‹ã€‚ã“ã‚Œã¯ã€human assessmentã®ãƒã‚¤ã‚ºã«ã‚ˆã£ã¦ã€automatic scoreã¨human assessmentã®correlationã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/473085a1-1137-43d6-8f8e-1cdbc256ad55" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2023-05-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/665" target="_blank" rel="noopener noreferrer" class="title-link">OpenSource PaLM, 2023</a>
<span class="snippet"><span>Comment</span><p>150m,410m,1bã®ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ã€‚Googleã®540bã«ã¯é ãåŠã°ãªã„ã—ã€emergent abilityã‚‚æœŸå¾…ã§ããªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã ãŒã€ã©ã®ç¨‹åº¦ã®æ€§èƒ½ãªã®ã ã‚ã†ã‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2023-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/661" target="_blank" rel="noopener noreferrer" class="title-link">StarCoderBase_StarCoder, 2023</a>
<span class="snippet"><span>Comment</span><p>ãƒ»15.5Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿<br>ãƒ»80ç¨®é¡ä»¥ä¸Šã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§è¨“ç·´<br>ãƒ»Multi Query Attentionã‚’åˆ©ç”¨<br>ãƒ»context window size 8192<br>ãƒ»Fill in the middle objectiveã‚’åˆ©ç”¨<br><br>Instruction tuningãŒã•ã‚Œã¦ãŠã‚‰ãšã€prefixã¨suffixã®é–“ã‚’åŸ‹ã‚ã‚‹ã‚ˆã†ãªè¨“ç·´ã®ã•ã‚Œæ–¹ã‚’ã—ã¦ã„ã‚‹ã®ã§ã€ãŸã¨ãˆã°é–¢æ•°åã‚’inputã—ã¦ã€ãã®middleï¼ˆé–¢æ•°ã®ä¸­èº«ï¼‰ã‚’å‡ºåŠ›ã•ã›ã‚‹ã€ã¨ã„ã£ãŸä½¿ã„æ–¹ã«ãªã‚‹æ¨¡æ§˜ã€‚</p>
<p>paper: 


<a href="https://drive.google.com/file/d/1cN-b9GnWtHzQRoE7M7gAEyivY0kl4BYs/view" target="_blank" rel="noopener noreferrer">https://drive.google.com/file/d/1cN-b9GnWtHzQRoE7M7gAEyivY0kl4BYs/view</a>


</p>
<p>StarCoder:<br>


<a href="https://huggingface.co/bigcode/starcoder" target="_blank" rel="noopener noreferrer">https://huggingface.co/bigcode/starcoder</a>


</p>
<p>StarCoderBaseã‚’35Bã®python tokenã§finetuningã—ãŸãƒ¢ãƒ‡ãƒ«ã€‚<br>æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚é«˜æ€§èƒ½ã¨ä¸»å¼µ<br><br><img src="https://user-images.githubusercontent.com/12249301/236622130-5e7aa6aa-5f9b-4b0e-9962-ff1beaa03225.jpeg" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/659" target="_blank" rel="noopener noreferrer" class="title-link">MPT-7B, 2023</a>
<span class="snippet"><span>Comment</span><p>æ–°ãŸãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMã€‚<br>ä¸‹è¨˜ãƒ„ã‚¤ãƒ¼ãƒˆã‚ˆã‚Šå¼•ç”¨:<br><br>ãƒ»å•†ç”¨åˆ©ç”¨å¯èƒ½<br>ãƒ»6ä¸‡5000ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨å¯èƒ½<br>ãƒ»7Bã¨æ¯”è¼ƒçš„å°ã•ã„ãƒ¢ãƒ‡ãƒ«ãªãŒã‚‰é«˜æ€§èƒ½<br>ãƒ»æ—¥æœ¬èªã‚’æ‰±ãˆæ€§èƒ½ãŒé«˜ã„<br><br>ã¨ã®ã“ã¨ã€‚<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imai_eruel/status/1654629078878793729?s=46&t=nqpG5xvXzdg7yUPU4IfD3A"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ChatGPTã®LLMã¨æ¯”è¼ƒã™ã‚‹ã¨ã€ã–ã£ã¨ä¾‹ã‚’è¦‹ãŸæ„Ÿã˜è³ªå•å¿œç­”ã¨ã—ã¦ã®èƒ½åŠ›ã¯ãã“ã¾ã§é«˜ããªã•ãã†ãªå°è±¡ã€‚<br>finetuningã—ãªã„é™ã‚Šã¯GPT3,GPT4ã§è‰¯ã•ã’ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<span class="issue_date">Issue Date: 2023-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/653" target="_blank" rel="noopener noreferrer" class="title-link">SNAP: Web data: Amazon reviews</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2023-05-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/651" target="_blank" rel="noopener noreferrer" class="title-link">Personalized news filtering and summarization on the web, Xindong+, 2011 IEEE 23rd International Conference on Tools with Artificial Intelligence, 29</a>
<span class="snippet"><span>Comment</span><p>summarizationã§ã¯ãªãã€keyword extractionã®è©±ã ã£ãŸ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<a class="button" href="articles/review.html" target="_blank" rel="noopener noreferrer">#review</a>
<span class="issue_date">Issue Date: 2023-05-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/648" target="_blank" rel="noopener noreferrer" class="title-link">Personalized summarization of customer reviews based on userâ€™s browsing history, Zehra+, International Journal on Computer Science and Information Systems 8.2, 12</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2023-05-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/646" target="_blank" rel="noopener noreferrer" class="title-link">Towards personalized summaries in spanish based on learning styles theory, Uriel+, Res. Comput. Sci. 148.5, 1</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2023-05-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/645" target="_blank" rel="noopener noreferrer" class="title-link">Personalized Text Content Summarizer for Mobile Learning: An Automatic Text Summarization System with Relevance Based Language Model, Guangbing+, IEEE Fourth International Conference on Technology for Education, 2012, 22</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Personalization.html" target="_blank" rel="noopener noreferrer">#Personalization</a>
<span class="issue_date">Issue Date: 2023-05-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/644" target="_blank" rel="noopener noreferrer" class="title-link">Personalized text summarization based on important terms identification, Robert+, 23rd International Workshop on Database and Expert Systems Applications, 2012, 43</a>
<span class="snippet"><span>Comment</span><p>ï¼ˆã‚ã¾ã‚Šã—ã£ã‹ã‚Šã‚ˆã‚ã¦ã„ãªã„ï¼‰<br><br>å­¦ç¿’è€…ã®revisionï¼ˆå¾©ç¿’ï¼Ÿï¼‰ã®ãŸã‚ã®æ•™æã®è¦ç´„æ‰‹æ³•ã®ææ¡ˆã€‚personalizationã™ã‚‹ãŸã‚ã«ã€ã•ã¾ã–ã¾ãªRaterã‚’å®šç¾©ã—ã€Raterã‹ã‚‰ã®å˜èªwã«å¯¾ã™ã‚‹è©•ä¾¡ã‚’é›†ç´„ã—ã€æœ€çµ‚çš„ã«user-specificãªsentence-term matrixã‚’æ§‹ç¯‰ã€‚ SVDã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§è¦ç´„ã‚’ä½œæˆã™ã‚‹ã€‚personalizedãªé‡ã¿ä»˜ã‘ã«æ´»ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã¨ã—ã¦ã¯ã€ã‚ã‚‹ã‚³ãƒ³ã‚»ãƒ—ãƒˆiã«å¯¾ã™ã‚‹å­¦ç¿’è€…ã®ç¿’ç†Ÿåº¦ã«åŸºã¥ãé‡ã¿ä»˜ã‘ã‚„ã€å­¦ç¿’è€…ã®æ•™æã«å¯¾ã™ã‚‹annnotationã«é–¢ã™ã‚‹æƒ…å ±ãªã©ãŒã€å˜èªã®é‡ã¿ä»˜ã‘ã«æ´»ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Assessment.html" target="_blank" rel="noopener noreferrer">#Assessment</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/623" target="_blank" rel="noopener noreferrer" class="title-link">ChatBot Arena, lmsys org, 2023.05</a>
<span class="snippet"><span>Comment</span><p>ã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚·ãƒ³ã‚°å‹ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆè©•ä¾¡ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã€‚ãƒ¦ãƒ¼ã‚¶ã¯ã‚·ã‚¹ãƒ†ãƒ ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã¨ã€äºŒã¤ã®anonymisedã•ã‚ŒãŸLLMã¨å¯¾è©±ã—ã€ã©ã¡ã‚‰ãŒå„ªã‚Œã¦ã„ãŸã‹ã‚’votingã™ã‚‹ã€‚ã™ã¹ã¦ã®ã‚·ã‚¹ãƒ†ãƒ ã¨ãƒ¦ãƒ¼ã‚¶ã®interactionã¯ãƒ­ã‚®ãƒ³ã‚°ã•ã‚Œã¦ãŠã‚Šã€æœ€çµ‚çš„ã«Elo Ratingã§LLM.ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»˜ã‘ã™ã‚‹ã€‚</p>
<p>Arena-Hardã¨å‘¼ã°ã‚Œã‚‹liveã‚¢ãƒªãƒ¼ãƒŠãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å…¬é–‹ã€‚MT-Benchã‚ˆã‚Šã‚‚è­˜åˆ¥åŠ›ãŒé«˜ãã€Chatbot Arenaã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¨ã®agreementãŒé«˜ã„ã¨ã®ã“ã¨ã€‚<br><br>å‚è€ƒ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lmsysorg/status/1782179997622649330?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2faafce4-effd-40b1-8760-d9639d3df6aa" alt="image" loading="lazy"><p>éå»ã®ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã¯ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/876" target="_blank" rel="noopener noreferrer">ChatBot Arenaã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ</a>
 ãªã©ã‚‚ã‚ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/SpokenLanguageProcessing.html" target="_blank" rel="noopener noreferrer">#SpokenLanguageProcessing</a>
<a class="button" href="articles/SpokenLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#SpokenLanguageGeneration</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/620" target="_blank" rel="noopener noreferrer" class="title-link">Bark</a>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚­ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§éŸ³å£°ç”ŸæˆãŒã§ãã‚‹ãƒ¢ãƒ‡ãƒ«ã€‚MIT License</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/618" target="_blank" rel="noopener noreferrer" class="title-link">OpenLLaMA</a>
<span class="snippet"><span>Comment</span><p>LLaMAã¨åŒæ§˜ã®æ‰‹æ³•ã‚’ä¼¼ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é©ç”¨ã—å•†ç”¨åˆ©ç”¨å¯èƒ½ãªLLaMAã‚’æ§‹ç¯‰ã—ãŸæ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/616" target="_blank" rel="noopener noreferrer" class="title-link">LLM ecosystem graphs</a>
<span class="snippet"><span>Comment</span><p>æ§˜ã€…ãªfonudation modelã€ãã‚Œã‚‰ã‚’åˆ©ç”¨ã—ãŸã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ä¾å­˜é–¢ä¿‚ãŒã¾ã¨ã¾ã£ãŸãƒšãƒ¼ã‚¸</p>
<p>Percy Liangã®ã‚°ãƒ«ãƒ¼ãƒ—ãŒé‹ç”¨ã—ã¦ã‚‹ã£ã½ã„ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Assessment.html" target="_blank" rel="noopener noreferrer">#Assessment</a>
<span class="issue_date">Issue Date: 2023-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/603" target="_blank" rel="noopener noreferrer" class="title-link">PandaLM</a>
<span class="snippet"><span>Comment</span><p>ç•°ãªã‚‹LLMã‚’å†ç¾æ€§ã®ã‚ã‚‹å½¢ã§è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª<br>2ã¤ã®ç•°ãªã‚‹LLMã®outputã‚’æ¯”è¼ƒã—ã€ã©ã¡ã‚‰ãŒå„ªã‚Œã¦ã„ã‚‹ã‹ç†ç”±ä»˜ãã§èª¬æ˜ã™ã‚‹ã€‚äººé–“ãŒä½œæˆã—ã¦1000ã‚µãƒ³ãƒ—ãƒ«ã®å¤šæ§˜ãªã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã„è©•ä¾¡ã§ãã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2023-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/599" target="_blank" rel="noopener noreferrer" class="title-link">Personalized Extractive Summarization for a News Dialogue System, Takatsu+, SLT, 2021, 4</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/562" target="_blank" rel="noopener noreferrer" class="title-link">HuggingChat, 2023</a>
<span class="snippet"><span>Comment</span><p>closedãªä¸–ç•Œã§é–‹ç™ºã•ã‚Œã‚‹OpenAIã®ChatGPTã«å¯¾ã—ã¦ã€Openãªã‚‚ã®ãŒå¿…è¦ã¨ã„ã†ã“ã¨ã§ã€huggingfaceãŒå‡ºã—ãŸchatã‚·ã‚¹ãƒ†ãƒ </p>
<p>å…¬é–‹ã¯ã™ã§ã«çµ‚äº†ã—ã¦ã„ã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/560" target="_blank" rel="noopener noreferrer" class="title-link">Unleashing Infinite-Length Input Capacity for Large-scale Language Models with Self-Controlled Memory System, 2023</a>
<span class="snippet"><span>Comment</span><p>&gt; Our findings indicate that our system outperforms ChatGPT in handling ultra-long inputs or conversations.<br><br><br><br>ã¨æ›¸ã„ã¦ã‚ã‚‹ãŒã€å®šé‡è©•ä¾¡ã®çµæœãŒå…¨ãæ›¸ã„ã¦ã„ãªã„æ¨¡æ§˜ã€‚å…¨ãã‚‚ã£ã¦ä¿¡ç”¨ã§ããªã„ã€‚èª­ã‚€å¿…è¦ãªã—ã€‚</p>
<p>4/27æ™‚ç‚¹ã ã¨è¨˜è¿°ã•ã‚Œã¦ã„ãªã‹ã£ãŸã¨æ€ã†ãŒã€ç¾æ™‚ç‚¹ã§ã¯å®šé‡è©•ä¾¡ãŒè¿½åŠ ã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/557" target="_blank" rel="noopener noreferrer" class="title-link">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«é–“ã®æ€§èƒ½æ¯”è¼ƒã¾ã¨ã‚</a>
<span class="snippet"><span>Comment</span><p>å‚è€ƒã«ãªã‚‹</p>
<p>ç¾çŠ¶ã ã¨ç ”ç©¶ç”¨ã§ã‚ã‚Œã°llama, å•†ç”¨åˆ©ç”¨ãªã‚‰text-davinci-003ã‚ã‚‹ã„ã¯FlanT5-xxlã‚ãŸã‚Šã«ãªã‚Šãã†</p>
<p>LLM Worksheetï¼š<br><br>


<a href="https://docs.google.com/spreadsheets/d/1kT4or6b0Fedd-W_jMwYpb63e1ZR3aePczz3zlbJW-Y4/edit#gid=0" target="_blank" rel="noopener noreferrer">https://docs.google.com/spreadsheets/d/1kT4or6b0Fedd-W_jMwYpb63e1ZR3aePczz3zlbJW-Y4/edit#gid=0</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/DataDistillation.html" target="_blank" rel="noopener noreferrer">#DataDistillation</a>
<span class="issue_date">Issue Date: 2023-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/548" target="_blank" rel="noopener noreferrer" class="title-link">LaMini-instruction</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®çŸ¥è­˜ã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã«ã€æ–‡/ã‚ªãƒ•ãƒ©ã‚¤ãƒ³è’¸ç•™ã‚’è¡Œã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ã„ãã¤ã‹ã®æ—¢å­˜ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒªã‚½ãƒ¼ã‚¹ã«åŸºã¥ã„ã¦ã€åˆè¨ˆ258ä¸‡ãƒšã‚¢ã®æŒ‡ç¤ºã¨å¿œç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚è©³ç´°ã¯è«–æ–‡ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¢å­˜ã®Instruction Datasetã®Instructionã‚’seedã¨ã—ã¦ã€gpt-3.5-turboã§æ–°ãŸãªInstructionã¨responseã‚’ç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/23a85991-6af9-4663-a293-c22a6cdba9f0" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/528" target="_blank" rel="noopener noreferrer" class="title-link">LoRAè«–æ–‡è§£èª¬, Hayato Tsukagoshi, 2023.04</a>
<span class="snippet"><span>Comment</span><p>ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ä¸€éƒ¨ã®ç·šå½¢å±¤ã®éš£ã«ã€ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—A,Bã‚’å°å…¥ã—ã€A,Bã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’finetuningã®å¯¾è±¡ã¨ã™ã‚‹ã“ã¨ã§ã€ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’æ¿€æ¸›ã•ã›ãŸä¸Šã§åŒç­‰ã®äºˆæ¸¬æ€§èƒ½ã‚’é”æˆã—ã€æ¨è«–é€Ÿåº¦ã‚‚å¤‰ã‚ã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹finetuningæ‰‹æ³•ã®è§£èª¬</p>
<p>LoRAã‚’ä½¿ã†ã¨ã€ã§ã‹ã™ãã‚‹ãƒ¢ãƒ‡ãƒ«ã ã¨ã€ãã‚‚ãã‚‚GPUã«è¼‰ã‚‰ãªã„å•é¡Œã‚„ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã§ã‹ã™ããƒ¯ãƒ­ã‚¿å•é¡ŒãŒå›é¿ã§ãã‚‹ã€‚<br><br>å‰è€…ã¯äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®BPã®ãŸã‚ã®å‹¾é…ã‚’ä¿å­˜ã—ã¦ãŠãå¿…è¦ãŒãªããªã‚‹ãŸã‚å­¦ç¿’æ™‚ã«ãƒ¡ãƒ¢ãƒªç¯€ç´„ã«ãªã‚‹ã€‚å¾Œè€…ã¯A,Bã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã ã‘ä¿å­˜ã™ã‚Œã°ã„ã„ã®ã§ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ç¯€ç´„ã«ãªã‚‹ã€‚<br><br>ã‹ã¤ã€å­¦ç¿’é€Ÿåº¦ãŒ25%ç¨‹åº¦æ—©ããªã‚‹ã€‚</p>
<p>æ—¢å­˜ç ”ç©¶ã§ã‚ã‚‹Adapterï¼ˆtransformerã®ä¸­ã«å­¦ç¿’å¯èƒ½ãªMLPã‚’å·®ã—è¾¼ã‚€æ‰‹æ³•ï¼‰ã¯æ¨è«–ã‚³ã‚¹ãƒˆãŒå¢—åŠ ã—ã€prefix tuningã¯å­¦ç¿’ãŒéå¸¸ã«é›£ã—ãã€é«˜ã„æ€§èƒ½ã‚’é”æˆã™ã‚‹ãŸã‚ã«prefixã¨ã—ã¦128 tokenå…¥ã‚ŒãŸã‚Šã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚</p>
<p>huggingfaceãŒã™ã§ã«LoRAã‚’å®Ÿè£…ã—ã¦ã„ã‚‹<br>


<a href="https://github.com/huggingface/peft" target="_blank" rel="noopener noreferrer">https://github.com/huggingface/peft</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/SpokenLanguageProcessing.html" target="_blank" rel="noopener noreferrer">#SpokenLanguageProcessing</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/527" target="_blank" rel="noopener noreferrer" class="title-link">CLAP</a>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚­ã‚¹ãƒˆã¨ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã®å¤§é‡ã®ãƒšã‚¢ã‚’äº‹å‰å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€ãƒ†ã‚­ã‚¹ãƒˆã¨ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªé–“ã‚’åŒã˜ç©ºé–“ã«å†™åƒã—ã€é¡ä¼¼åº¦ã‚’æ¸¬ã‚Œã‚‹ã‚ˆã†ã«ã—ãŸãƒ¢ãƒ‡ãƒ«</p>
<p>ãŸã¨ãˆã°ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§audioåˆ†é¡ãŒã§ãã‚‹<br><img src="https://user-images.githubusercontent.com/12249301/234293138-20edf6cd-3259-4547-a2fc-69893273fa76.jpeg" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2023-04-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/521" target="_blank" rel="noopener noreferrer" class="title-link">Llamaindex</a>
<span class="snippet"><span>Comment</span><p>- LlamaIndexã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°ã—ã€æ›´æ–°å‰å¾Œã§çŸ¥è­˜ãŒã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ã¿ãŸ<br><br>  - 


<a href="https://dev.classmethod.jp/articles/llama-index-insert-index/" target="_blank" rel="noopener noreferrer">https://dev.classmethod.jp/articles/llama-index-insert-index/</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2023-04-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/520" target="_blank" rel="noopener noreferrer" class="title-link">LangChain</a>
<span class="snippet"><span>Comment</span><p>- LangChain ã® Googleã‚«ã‚¹ã‚¿ãƒ æ¤œç´¢ é€£æºã‚’è©¦ã™<br><br>  - 


<a href="https://note.com/npaka/n/nd9a4a26a8932" target="_blank" rel="noopener noreferrer">https://note.com/npaka/n/nd9a4a26a8932</a>


</p>
<p>- LangChainã®Getting Startedã‚’Google Colaboratoryã§ã‚„ã£ã¦ã¿ã‚‹ â‘£Agents<br><br>    - 


<a href="https://zenn.dev/kun432/scraps/8216511783e3da" target="_blank" rel="noopener noreferrer">https://zenn.dev/kun432/scraps/8216511783e3da</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<span class="issue_date">Issue Date: 2023-04-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/516" target="_blank" rel="noopener noreferrer" class="title-link">User-centred versus system-centred evaluation of a personalization system, Diaz+, Information Processing &amp; management, 2008</a>
<span class="snippet"><span>Comment</span><p># Introduction<br><br>æœ¬ç ”ç©¶ã§ã¯ã€web contentsã®Personalizationã‚·ã‚¹ãƒ†ãƒ ã«ãŠã„ã¦ã€user-centered evaluationã¨system-centered evaluationã®è©•ä¾¡ã®å•é¡Œã‚’è­°è«–ã—ã¦ã„ã‚‹ã€‚ç›®çš„ã¨ã—ã¦ã¯ä¸¡è€…ã®è©•ä¾¡ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ãã‚Œãã‚Œã‚’å€‹åˆ¥ã«è©•ä¾¡ã™ã‚‹ã‚ˆã‚Šã‚‚ã€ã‚ˆã‚Šinsightfulãªè¦‹è§£ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’è¿°ã¹ã‚‹ã€‚<br><br><br><br>- system-oriented evaluationã®ä¾‹: Text Retrieval Conference (TREC)ï¼š<br><br>  - ã‚¯ã‚¨ãƒªã”ã¨ã«å°‚é–€å®¶ãŒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ä¸­ã‹ã‚‰ã€ã©ã‚Œã ã‘è©²å½“æ–‡æ›¸ãŒåˆè‡´ã—ã¦ã„ã‚‹ã‹ã‚’ãƒ©ãƒ™ãƒ«ä»˜ã™ã‚‹<br><br>  - =&gt; ãƒ¦ãƒ¼ã‚¶ã”ã¨ã®å®Ÿéš›ã®relevance judgmentã‚’ç”¨ã„ã‚‹ã®ã§ã¯ãªãã€å°‚é–€å®¶ã«ã‚ˆã‚‹ãƒ©ãƒ™ãƒ«ã‚’ç”¨ã„ã¦è©•ä¾¡ã™ã‚‹<br><br>  - =&gt; ã‚¯ã‚¨ãƒªã«é–¢é€£ã¥ã‘ã‚‰ã‚ŒãŸæ–‡æ›¸ã®é©åˆæ€§ã¯ã€ã‚¯ã‚¨ãƒªãŒå®Ÿè¡Œã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ä¾å­˜ã™ã‚‹ãŸã‚ã€å°‚é–€å®¶ã«ã‚ˆã‚‹relevance judgmentã¯ç¾å®Ÿã«å¯¾ã™ã‚‹è¿‘ä¼¼ã¨ã—ã¦æ‰ãˆã‚‰ã‚Œã‚‹<br><br>  - =&gt; ãƒ¦ãƒ¼ã‚¶ã®å‚åŠ ã¯å¿…é ˆã§ã¯ãªã„<br><br>- user centered evaluation<br><br>  - ãƒ¦ãƒ¼ã‚¶ã®æ„è¦‹ã‚’åé›†ã—ã€ãƒ¦ãƒ¼ã‚¶ã®ã‚·ã‚¹ãƒ†ãƒ ã«å¯¾ã™ã‚‹å°è±¡ã‚’æ‰‹ã«å…¥ã‚Œã‚ˆã†ã¨ã™ã‚‹user-orientedã‚‚å®Ÿæ–½ã•ã‚Œã¦ã„ã‚‹<br><br>  - qualitative, quantitative (recall and precision)ã®ä¸¡æ–¹ã‚’åé›†ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹å ´åˆãŒã‚ã‚Šã€ãƒ¦ãƒ¼ã‚¶ã®å‚åŠ ãŒå¿…é ˆ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="articles/AES(AutomatedEssayScoring).html" target="_blank" rel="noopener noreferrer">#AES(AutomatedEssayScoring)</a>
<span class="issue_date">Issue Date: 2023-04-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/515" target="_blank" rel="noopener noreferrer" class="title-link">Exploring the Potential of Using an AI Language Model for Automated Essay Scoring, Mizumoto+, Research Methods in Applied Linguisticsâ€˜23</a>
<span class="snippet"><span>Comment</span><p>è‘—è€…ã«ã‚ˆã‚‹ãƒã‚¹ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mizumotoatsushi/status/1641754298496471040?s=46&t=TIr1-wDC_j5MPU3TvCVWMg"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ã«ã‚ˆã‚‹ãƒ–ãƒ­ã‚°:<br><br>


<a href="https://mizumot.com/lablog/archives/1805" target="_blank" rel="noopener noreferrer">https://mizumot.com/lablog/archives/1805</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<span class="issue_date">Issue Date: 2023-03-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/514" target="_blank" rel="noopener noreferrer" class="title-link">Publicly available instruction-tuned models</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<span class="issue_date">Issue Date: 2023-03-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/510" target="_blank" rel="noopener noreferrer" class="title-link">20B params chatgpt alternative</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒ„ã‚¤ãƒ¼ãƒˆ<br>Apache2.0ã§å…¬é–‹<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1634492396171071488?s=46&t=VvPwEQsB--BeXx0YbYQdxQ"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/DataAugmentation.html" target="_blank" rel="noopener noreferrer">#DataAugmentation</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2023-01-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/505" target="_blank" rel="noopener noreferrer" class="title-link">nlpaug</a>
<span class="snippet"><span>Comment</span><p>Data Augmentationã®ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2022-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/499" target="_blank" rel="noopener noreferrer" class="title-link">Transformers Interpret, 2022</a>
<span class="snippet"><span>Comment</span><p>transformersã®ãƒ¢ãƒ‡ãƒ«ã‚’ãŸã£ãŸ2è¡Œè¿½åŠ ã™ã‚‹ã ã‘ã§ã€explainableã«ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª<br><br>åŸºæœ¬çš„ã«textã¨visionã®classificationã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹æ¨¡æ§˜<br>text classificationã®å ´åˆã€ãŸã¨ãˆã°input tokenã®å„ãƒˆãƒ¼ã‚¯ãƒ³ã®åˆ†é¡ã«å¯¾ã™ã‚‹å¯„ä¸åº¦ã‚’outputã—ã¦ãã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2022-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/485" target="_blank" rel="noopener noreferrer" class="title-link">Transformerã®æœ€å‰ç·š ã€œ ç•³è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å…ˆã¸ ã€œ, ç‰›ä¹…å…ˆç”Ÿ, 2022</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Legal.html" target="_blank" rel="noopener noreferrer">#Legal</a>
<span class="issue_date">Issue Date: 2021-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/416" target="_blank" rel="noopener noreferrer" class="title-link">è‡ªç„¶è¨€èªç³»AIã‚µãƒ¼ãƒ“ã‚¹ã¨è‘—ä½œæ¨©ä¾µå®³, æŸ¿æ²¼å¤ªä¸€, 2021</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2021-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/404" target="_blank" rel="noopener noreferrer" class="title-link">GPT-3ã‹ã‚‰æˆ‘ã€…ã¯ä½•ã‚’å­¦ã¹ã°è‰¯ã„ã®ã‹, å±±æœ¬å’Œè‹±, Japio year book 2020</a>
<span class="snippet"><span>Comment</span><p>GPT-3ã®æ¦‚è¦:<br><br>GPT-3ã¯Webã‚µã‚¤ãƒˆã‹ã‚‰æ•°å¹´ã«æ¸¡ã£ã¦åé›†ã—ãŸCommon Crawlã¨ã„ã†ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ã€570GBã‚’æŠœç²‹ã—å­¦ç¿’ã«åˆ©ç”¨ã€‚ï¼ˆè‹±èªã‚¦ã‚£ã‚­ãƒšãƒ‡ã‚£ã‚¢ã®ç´„130å€ï¼‰<br>ã‚ã‚‹å˜èªåˆ—ã«å¾Œç¶šã™ã‚‹å˜èªã‚’äºˆæ¸¬ã™ã‚‹ã¨ã„ã†æ–¹æ³•ï¼ˆè‡ªå·±å›å¸°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ã§æ•™å¸«ãªã—å­¦ç¿’ã‚’ç¹°ã‚Šè¿”ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã€‚</p>
<p>GPT-3ã®ç‰¹å¾´:<br>ãƒ»ãƒ¢ãƒ‡ãƒ«ãŒå·¨å¤§ï¼ˆ1750å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿, GPT-2ã¯15å„„ï¼‰<br>ã€€- æ‰±ã†ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒ2048ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆGPT-2ã®å€ï¼‰<br>ã€€- Word Embeddingã®æ¬¡å…ƒæ•°12288ï¼ˆGPT2ã®å€<br>ã€€- ãƒ‡ã‚³ãƒ¼ãƒ‰å±¤ãŒ98å±¤ï¼ˆGPT2ã®å€<br>ãƒ»åŸºæœ¬çš„ãªãƒ¢ãƒ‡ãƒ«æ§‹é€ ã¯Transformerã¨ä¸€ç·’<br><br>GPT-3ã®å•é¡Œç‚¹:<br>ãƒ»ã‚³ãƒ¼ãƒ‘ã‚¹ä¸­ã®è¨€èªå‡ºåŠ›ã‚’æ¨¡å€£ã—ã¦ã„ã‚‹ã ã‘ã§ã€ä½•ã‚‰ç†è§£ã‚’ã—ã¦ãŠã‚‰ãšã€å¸¸è­˜ã‚‚æŒã¡åˆã‚ã›ã¦ã„ãªã„<br>ã€€- e.g. ç§ã®è¶³ã«ç›®ã¯ã„ãã¤ã‚ã‚‹ï¼Ÿã¨å…¥åŠ›ã™ã‚‹ã¨ã€2ã¤ã¨å‡ºåŠ›ã™ã‚‹ç­‰<br>ã€€- æ•´ç†ã•ã‚ŒãŸçŸ¥è­˜ã‚’ç²å¾—ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„<br>ãƒ»åè¦‹ã‚„å·®åˆ¥ã€èª¤ã£ãŸçŸ¥è­˜ã‚‚å­¦ç¿’ã™ã‚‹<br>ãƒ»æ™‚é–“çš„ã€çµŒæ¸ˆçš„è² è·ã®å¤§ãã•<br>ã€€- GPT-3ã‚’æœ€å¤§è¦æ¨¡ã§è¨ˆç®—ã™ã‚‹ã«ã¯5å„„å††ã‹ã‹ã‚‹<br>ã€€- 1å°ã®GPUã§355å¹´å¿…è¦ãªè¨ˆç®—é‡<br>ã€€â†’ å€‹äººã‚„å°è¦æ¨¡æ¥­è€…ãŒå®Ÿè¡Œã§ãã‚‹ç¯„å›²ã‚’è¶…ãˆã¦ãŠã‚Šã€å¤§ä¼æ¥­ã§ã‚‚ã‚³ã‚¹ãƒˆã«è¦‹åˆã£ãŸå‡ºåŠ›ãŒå¾—ã‚‰ã‚Œã‚‹ã¨ã¯è€ƒãˆã«ãã„</p>
<p>GPT-3ã®ç”£æ¥­å¿œç”¨<br>ãƒ»GPT-3ã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€è¨€èªç”Ÿæˆå™¨ã§ã¯ãªã„<br>ã€€- äººé–“ãŒæ›¸ã„ã¦æ¬²ã—ã„ã“ã¨ã‚’ãŠãŠã¾ã‹ã«ä¼ãˆãŸã‚‰ãã‚Œã‚’æ›¸ã„ã¦ãã‚Œã‚‹ã‚ã‘ã§ã¯ãªã„ï¼ˆä»£ç­†ï¼‰<br>ã€€â†’ GPT-3ãŒå°è«–æ–‡ã‚„æ¥­å‹™ãƒ¬ãƒãƒ¼ãƒˆã‚’æ›¸ã‘ã‚‹ã¨è€ƒãˆã‚‹ã®ã¯æ—©è¨ˆ<br>ã€€- å…¥åŠ›ã¨ã—ã¦è‹±æ–‡ã‚„è‹±å˜èªã‚’å…¥åŠ›ã™ã‚‹ãŒã€ç”Ÿæˆã™ã‚‹æ–‡ç« ã®åˆ†é‡ã‚„è©±é¡Œã‚’æç¤ºã—ãŸã ã‘ã§ã‚ã‚Šã€ç”Ÿæˆã™ã‚‹æ–‡ç« ã«ãã‚Œä»¥ä¸Šã®åˆ¶å¾¡ã¯è¡Œã£ã¦ã„ãªã„<br><br>ãƒ»ç”Ÿæˆå†…å®¹ã‚’å¼·ãåˆ¶å¾¡ã§ããªã„ã“ã¨ã¯å‰µä½œæ´»å‹•ã«ã¨ã£ã¦ã¯æœ‰ç”¨<br>ã€€- ä¿³å¥ã€çŸ­æ­Œã€è©©ã®ç”Ÿæˆ<br>ã€€- ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã®è‡ªå‹•ç”Ÿæˆ<br>ã€€- ãƒ€ãƒŸãƒ¼æ–‡ç« ç”Ÿæˆï¼ˆãƒ–ãƒ­ã‚°ã‚„ãƒ„ã‚¤ãƒ¼ãƒˆï¼‰<br>ã€€- æ–‡ç« æ·»å‰Šã€æ ¡æ­£ã«ä½¿ãˆã‚‹å¯èƒ½æ€§ï¼ˆè¦ç ”ç©¶;æ–‡ç« ã‚’æ­£ã—ãã€ç¶ºéº—ã«æ›¸ãèƒ½åŠ›ã¯é«˜ã„ï¼‰</p>
<p>GPT-3ã§ã©ã“ã¾ã§ã§ããã†ãªã®ã‹ï¼Ÿã¨ã„ã†ã–ã£ãã‚Šã¨ã—ãŸè‚Œæ„ŸãŒæ´ã‚ãŸã‹ã‚‰è‰¯ã‹ã£ãŸ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2021-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/389" target="_blank" rel="noopener noreferrer" class="title-link">Pre-Trained Models: Past, Present and Future, Han+, AI Openâ€˜21</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆPTMsï¼‰ã¯ã€AIåˆ†é‡ã§ã®æˆåŠŸã‚’åã‚ã€çŸ¥è­˜ã‚’åŠ¹æœçš„ã«æ‰ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ç‰¹ã«ã€è»¢ç§»å­¦ç¿’ã‚„è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’ã¨ã®é–¢ä¿‚ã‚’è€ƒå¯Ÿã—ã€PTMsã®é‡è¦æ€§ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚æœ€æ–°ã®ãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ã¯ã€è¨ˆç®—èƒ½åŠ›ã®å‘ä¸Šã‚„ãƒ‡ãƒ¼ã‚¿ã®åˆ©ç”¨å¯èƒ½æ€§ã«ã‚ˆã‚Šã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆã‚„è¨ˆç®—åŠ¹ç‡ã®å‘ä¸Šã«å¯„ä¸ã—ã¦ã„ã‚‹ã€‚æœªè§£æ±ºå•é¡Œã‚„ç ”ç©¶æ–¹å‘ã«ã¤ã„ã¦ã‚‚è­°è«–ã—ã€PTMsã®å°†æ¥ã®ç ”ç©¶ã®é€²å±•ã‚’æœŸå¾…ã™ã‚‹ã€‚</span>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2021-06-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/386" target="_blank" rel="noopener noreferrer" class="title-link">æœ€å…ˆç«¯è‡ªç„¶è¨€èªå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æœ€é©ãªé¸æŠã¨æœ‰ç”¨ãªåˆ©ç”¨æ–¹æ³• _ pycon-jp-2020</a>
<span class="snippet"><span>Comment</span><p>å„å½¢æ…‹ç´ è§£æãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç‰¹å¾´ã‚„æ¯”è¼ƒãŒã•ã‚Œã¦ã„ã¦ã€è‡ªåˆ†ã®ç”¨é€”ãƒ»ç›®çš„ã«åˆã‚ã›ã¦ã©ã®å½¢æ…‹ç´ è§£æå™¨ãŒè‰¯ã„ã‹æ„æ€æ±ºå®šã™ã‚‹éš›ã«æœ‰ç”¨</p>
<p><img src="https://user-images.githubusercontent.com/12249301/121644722-56025800-cace-11eb-9fe9-9d2f6b0eae5a.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2021-06-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/384" target="_blank" rel="noopener noreferrer" class="title-link">FastSeq: Make Sequence Generation Faster, Yan+, ACLâ€™21</a>
<span class="snippet"><span>Comment</span><p>BART, DistilBART, T5, GPT2ç­‰ã®ã•ã¾ã–ã¾ãªTransformer-basedãªæ‰‹æ³•ã§ã€4-9å€Inference speedã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<span class="issue_date">Issue Date: 2021-06-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/382" target="_blank" rel="noopener noreferrer" class="title-link">A survey of Transformers, Lin+, AI Openâ€˜22</a>
<span class="snippet"><span>GPT Summary</span>- ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®å¤šæ§˜ãªãƒãƒªã‚¢ãƒ³ãƒˆï¼ˆX-formersï¼‰ã«é–¢ã™ã‚‹ä½“ç³»çš„ãªæ–‡çŒ®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æä¾›ã€‚ãƒãƒ‹ãƒ©ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®ç´¹ä»‹å¾Œã€æ–°ã—ã„åˆ†é¡æ³•ã‚’ææ¡ˆã—ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ä¿®æ­£ã€äº‹å‰å­¦ç¿’ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è¦³ç‚¹ã‹ã‚‰X-formersã‚’ç´¹ä»‹ã€‚ä»Šå¾Œã®ç ”ç©¶ã®æ–¹å‘æ€§ã‚‚æ¦‚èª¬ã€‚</span>
<span class="snippet"><span>Comment</span><p>Transformersã®æ§˜ã€…ãªåˆ†é‡ã§ã®äºœç¨®ã‚’ã¾ã¨ã‚ãŸè«–æ–‡</p>
<p><img src="https://user-images.githubusercontent.com/12249301/121394765-a40f4280-c98c-11eb-8fac-0114715ec738.png" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2021-06-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/375" target="_blank" rel="noopener noreferrer" class="title-link">Probing Word Translations in the Transformer and Trading Decoder for Encoder Layers, NAACLâ€˜21</a>
<span class="snippet"><span>Comment</span><p>Transformerã«åŸºã¥ã„ãŸNMTã«ãŠã„ã¦ã€EncoderãŒå…¥åŠ›ã‚’è§£é‡ˆã—ã€DecoderãŒç¿»è¨³ã‚’ã—ã¦ã„ã‚‹ã€ã¨ã„ã†é€šèª¬ã‚’å¦å®šã—ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ®µéšã€ã•ã‚‰ã«ã¯input embeddingã®æ®µéšã§ãã‚‚ãã‚‚ç¿»è¨³ãŒå§‹ã¾ã£ã¦ã„ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã€‚<br>ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®æ®µéšã§ã™ã§ã«ç¿»è¨³ãŒå§‹ã¾ã£ã¦ã„ã‚‹ã®ã§ã‚ã‚Œã°ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®å±¤ã‚’å¢—ã‚„ã—ã¦ã€ãƒ‡ã‚³ãƒ¼ãƒ€ã®å±¤ã‚’æ¸›ã‚‰ã›ã°ã€ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é€Ÿåº¦ã‚’ä¸Šã’ã‚‰ã‚Œã‚‹ã€‚<br>é€šå¸¸ã¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã€ãƒ‡ã‚³ãƒ¼ãƒ€ã¨ã‚‚ã«6å±¤ã ãŒã€10-2å±¤ã«ã—ãŸã‚‰BLEUã‚¹ã‚³ã‚¢ã¯å¤‰ã‚ã‚‰ãšãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¹ãƒ”ãƒ¼ãƒ‰ã¯2.3å€ã«ãªã£ãŸã€‚<br>18-4å±¤ã®æ§‹æˆã«ã—ãŸã‚‰ã€BLEUã‚¹ã‚³ã‚¢ã‚‚1.42ãƒã‚¤ãƒ³ãƒˆå¢—åŠ ã—ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é€Ÿåº¦ã¯1.4å€ã«ãªã£ãŸã€‚</p>
<p>ã“ã®ç ”ç©¶ã¯å€‹äººçš„ã«éå¸¸ã«èˆˆå‘³æ·±ãã€æ—¢å­˜ã®å¸¸è­˜ã‚’ç–‘ã„ã€åˆ†æã«ã‚ˆã‚Šãã‚Œã‚’æ˜ã‚‰ã‹ã«ã—ã€ã‚·ãƒ³ãƒ—ãƒ«ãªæ”¹å–„ã§æ€§èƒ½å‘ä¸ŠãŠã‚ˆã³ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é€Ÿåº¦ã‚‚å‘ä¸Šã—ã¦ãŠã‚Šã€ã¨ã¦ã‚‚å¥½ãã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2021-06-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/372" target="_blank" rel="noopener noreferrer" class="title-link">Incorporating Copying Mechanism in Sequence-to-Sequence Learning, Gu+, ACLâ€™16</a>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/371" target="_blank" rel="noopener noreferrer">Pointing the Unknown Words, Gulcehre+, ACLâ€™16</a>
 ã¨åŒæ§˜ã‚³ãƒ”ãƒ¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ææ¡ˆã—ãŸè«–æ–‡ã€‚Joint Copy Modelã‚„COPYNETã¨å‘¼ã°ã‚Œã‚‹ã€‚<br><br>æ¬¡ã®å˜èªãŒ "ç”Ÿæˆ" ã•ã‚Œã‚‹ã®ã‹ "ã‚³ãƒ”ãƒ¼" ã•ã‚Œã‚‹ã®ã‹ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ã€å„å˜èªãŒã‚³ãƒ”ãƒ¼ã•ã‚Œã‚‹ç¢ºç‡ã¨ç”Ÿæˆã•ã‚Œã‚‹ç¢ºç‡ã‚’Mixtureã—ãŸåŒæ™‚ç¢ºç‡åˆ†å¸ƒã§è¡¨ç¾ã™ã‚‹ï¼ˆ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/207" target="_blank" rel="noopener noreferrer">[Paper Note] Challenges in Data-to-Document Generation, Wiseman+ (with Rush), EMNLP'17</a>
 ç­‰ã§ã‚‚èª¬æ˜ã•ã‚Œã¦ã„ã‚‹ï¼‰ã€‚<br><br>ã‚³ãƒ”ãƒ¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å°å…¥ã›ã‚‹ãªã‚‰å¼•ç”¨ã™ã¹ãã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120571719-ad148700-c455-11eb-8e93-8d9be799aad5.png" alt="image" loading="lazy"><br><br><br><br>## ã‚³ãƒ”ãƒ¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ éƒ¨åˆ†ã®èª¬æ˜<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120571852-efd65f00-c455-11eb-9063-872103738e2f.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120571874-fa90f400-c455-11eb-885f-5b1a08d7d528.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120572859-a6870f00-c457-11eb-9744-e1ff5ab5d253.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/120572917-bd2d6600-c457-11eb-8c76-5bb48988a5f9.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/120572936-c585a100-c457-11eb-822b-e70f0e857ac9.png" alt="image" loading="lazy"><br><br></p>
<p>è§£èª¬è³‡æ–™: 


<a href="http://www.lr.pi.titech.ac.jp/~sasano/acl2016suzukake/slides/08.pdf" target="_blank" rel="noopener noreferrer">http://www.lr.pi.titech.ac.jp/~sasano/acl2016suzukake/slides/08.pdf</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2021-06-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/371" target="_blank" rel="noopener noreferrer" class="title-link">Pointing the Unknown Words, Gulcehre+, ACLâ€™16</a>
<span class="snippet"><span>Comment</span><p>Conditional Copy Model ï¼ˆPointer Softmaxï¼‰ã‚’ææ¡ˆã—ãŸè«–æ–‡ã€‚<br>å˜èªã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€èªå½™å†…ã®å˜èªã‹ã‚‰ç”Ÿæˆã™ã‚‹åˆ†å¸ƒã€åŸæ–‡ã®å˜èªã‹ã‚‰ç”Ÿæˆã™ã‚‹åˆ†å¸ƒã‚’æ±‚ã‚ã‚‹ã€‚å¾Œè€…ã¯attention distributionã‹ã‚‰ã€‚ã‚³ãƒ”ãƒ¼ã™ã‚‹ã‹å¦ã‹ã‚’æ±ºã‚ã‚‹ç¢ºç‡å¤‰æ•°ã‚’å°å…¥ã—ï¼ˆsigmoidï¼‰ã€ä¸¡ç”Ÿæˆç¢ºç‡ã‚’é‡ã¿ä»˜ã‘ã™ã‚‹ã€‚<br>ã‚³ãƒ”ãƒ¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ å…¥ã‚Œã‚‹ãªã‚‰å¼•ç”¨ã™ã¹ãã€‚</p>
<p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:


<a href="https://www.slideshare.net/hytae/pointing-the-unknown-words" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/hytae/pointing-the-unknown-words</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/SentimentAnalysis.html" target="_blank" rel="noopener noreferrer">#SentimentAnalysis</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<span class="issue_date">Issue Date: 2021-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/365" target="_blank" rel="noopener noreferrer" class="title-link">Sentiment analysis with deeply learned distributed representations of variable length texts, Hong+, Technical Report. Technical report, Stanford University, 2015</a>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/363" target="_blank" rel="noopener noreferrer">[Paper Note] DKN: Deep Knowledge-Aware Network for News Recommendation, Hongwei Wang+, arXiv'18, 2018.01</a>
 ã‚ˆã‚Šã€æœ¬è«–æ–‡ã‚’å¼•ç”¨ã—ã¦ã€ŒCNN ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ãŒã€ç•³ã¿è¾¼ã¿æ¼”ç®—ã«ã‚ˆã‚Šæ–‡ã‹ã‚‰ç‰¹å®šã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡ºã—ã¦æŠ½å‡ºã§ãã‚‹ãŸã‚ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆe.g. Recurrent Neural Network, Recursive Neural Networkï¼‰ã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ãŒçµŒé¨“çš„ã«ç¤ºã•ã‚Œã¦ã„ã‚‹ã€ã¨ã®ã“ã¨</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2021-05-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/345" target="_blank" rel="noopener noreferrer" class="title-link">GLUE - è‹±èªåœã«ãŠã‘ã‚‹è‡ªç„¶è¨€èªå‡¦ç†ã®æ¨™æº–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯, npaka, 2020</a>
<span class="snippet"><span>Comment</span><p>å„ã‚¿ã‚¹ã‚¯ã”ã¨ã«ã‚µãƒ³ãƒ—ãƒ«ã¨ãã®èª¬æ˜ãŒä»˜ä¸ã•ã‚Œã¦ãŠã‚Šã€ã±ã£ã¨è¦‹ã§ã©ã‚“ãªã‚¿ã‚¹ã‚¯ã‹ã™ãåˆ†ã‹ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<span class="issue_date">Issue Date: 2021-05-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/344" target="_blank" rel="noopener noreferrer" class="title-link">MLP-like Architecture</a>
<span class="snippet"><span>Comment</span><p>gMLP:å¤§è¦æ¨¡ãªself-attentionãŒç„¡ã„Spatial Gating Unitã‚’æ­è¼‰ã—ãŸã‚·ãƒ³ãƒ—ãƒ«ãªMLPã§ã‚‚ã€Transformerã®æ€§èƒ½ã«è¿‘ã¥ã‘ãŸã‚ˆï¼ˆç‰¹ã«CVï¼‰ã€‚ã¤ã¾ã‚Šã€self-attentionã¯essentialã¨ã„ã†ã‚ã‘ã§ã¯ãªã•ãã†ã ã‚ˆã€‚<br><br>NLPã®å ´åˆã¯gMLPã ã¨Transformerã¨perplexityã§comparableã€ä¸€éƒ¨downstreamã‚¿ã‚¹ã‚¯ã ã¨å‹ã¦ãªã‹ã£ãŸã‘ã©ã€single headã®tiny attentionã‚’è¿½åŠ ã—ãŸã‚‰ã€Transformerã‚’perplexityã¨GLUEã®ä¸€éƒ¨ã‚¿ã‚¹ã‚¯ã§outperformã—ãŸã‚ˆã€‚<br>ã¤ã¾ã‚Šã€Transformerã¿ãŸã„ã«å¤§è¦æ¨¡ãªself-attentionã¯å¿…é ˆã§ã¯ãªãã€å°è¦æ¨¡ã®attentionã§ï¼ˆcross sentenceã®é–¢ä¿‚æ€§ã‚’æ‰ãˆã‚‹ã«ã¯ï¼‰ååˆ†ã ã‚ˆã€‚<br>ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚‚Transformerã‚’ä¸Šå›ã£ãŸã‚ˆã€‚<br><br>ã£ã¦æ„Ÿã˜ï¼Ÿ<br><br>ã‚“ãƒ¼Transformerã«å‹ã£ãŸã¿ãŸã„ãªè¨€ã„æ–¹ã‚’SNSã ã¨è¦‹ã‹ã‘ã‚‹ã‘ã©ã€è©•ä¾¡ã—ã¦ã‚‹ã‚¿ã‚¹ã‚¯ãŒå°‘ãªã„ã—ã€ã©ã¡ã‚‰ã‹ã¨ã„ã†ã¨comparableãªdownstreamã‚¿ã‚¹ã‚¯ãŒå¤šã„ã—ã€ãã‚Œã¯è¨€ã„éãã§ã¯ï¼Ÿ<br>ã“ã®è«–æ–‡ãŒè¨€ã„ãŸã„ã®ã¯ã€å¤§è¦æ¨¡ãªself-attentionãŒæ€§èƒ½ã‚’å‡ºã™ä¸Šã§essentialãªã‚ã‘ã§ã¯ãªã„ã‚ˆã€ã£ã¦ã“ã¨ã§ã‚ã‚Šã€<br><br>ãƒ»CVã®å ´åˆã¯self-attentionã¯å¿…é ˆã§ã¯ãªã„<br>ãƒ»NLPã§ã¯ã€tiny attentionã§ã‚‚ååˆ†<br><br>ã¨ã„ã†æ„Ÿã˜ãªã®ã§ã¯ã€‚<br></p>
<p>ã¾ã‚ã§ã‚‚Transformerã¨comparableãªã‚‰ã€Transformerä¸€å¼·ã§ã¯ç„¡ããªã£ãŸã‚ˆã­</p>
<p>Spatial Gating Unitï¼ˆSGUï¼‰ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³é–“ã®é–¢ä¿‚æ€§ã‚’æ‰ãˆã‚‹ãŸã‚ã®ã‚²ãƒ¼ãƒˆã§ã€SGUãŒç„¡ã„ã¨gMLPãƒ–ãƒ­ãƒƒã‚¯ã¯ãŸã ã®äºŒå±¤ã®FFNã¨ãªã‚‹ã€‚<br><br>SGUã¯ã€å…¥åŠ›ã‚’spatial dimensionã«å¯¾ã—ã¦ç·šå½¢å¤‰æ›ã—ãŸå€¤ã¨ã€å…ƒã®å…¥åŠ›ã®element-wiseãªç©ã§è¡¨ç¾ã™ã‚‹ã€‚ã“ã®ç·šå½¢å¤‰æ›ã‚’ã™ã‚‹éš›ã¯ã€Wã®å€¤ã‚’0ã®è¿‘å‚ã§åˆæœŸåŒ–ã—ã€ãƒã‚¤ã‚¢ã‚¹é …ã‚’1ã«åˆæœŸåŒ–ã™ã‚‹ã“ã¨ãŒã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã ã£ãŸã€‚ã“ã‚Œã¯ã€å­¦ç¿’ã®åˆã‚ã§ã¯ç·šå½¢å¤‰æ›ã¯identical mappingã«è¿‘ã„ã‚‚ã®ã¨ãªã‚‹ãŸã‚ã€gMLPãƒ–ãƒ­ãƒƒã‚¯ã¯FFNã«è¿‘ã„ã‚‚ã®ã¨ãªã‚‹ã€‚ã“ã‚ŒãŒå­¦ç¿’ãŒé€²ã‚€ã«ã¤ã‚ŒWã®é‡ã¿ãŒèª¿æ•´ã•ã‚Œã€cross tokenã®é–¢ä¿‚æ€§ã‚’æ‰ãˆãŸãƒ–ãƒ­ãƒƒã‚¯ã¸ã¨å¾ã€…ã«å¤‰åŒ–ã—ã¦ã„ãã“ã¨ã«ãªã‚‹ã€‚<br>ã¾ãŸã€SGUã¸ã®å…¥åŠ›ã¯GLUã®ã‚ˆã†ã«channel dimensionã«äºŒåˆ†å‰²ã—ã€ç‰‡æ–¹ã‚’element-wiseç©ã«ã€ã‚‚ã†ä¸€æ–¹ã‚’spatialãªç·šå½¢å¤‰æ›ã«åˆ©ç”¨ã™ã‚‹ï¼ˆ4ç¨®é¡è©¦ã—ãŸä¸­ã§ä¸€ç•ªæ€§èƒ½ãŒè‰¯ã‹ã£ãŸï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2020-03-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/334" target="_blank" rel="noopener noreferrer" class="title-link">BERT æ—¥æœ¬èªPre-trained Model, NICT, 2020</a>
<span class="snippet"><span>Comment</span><p>NICTãŒå…¬é–‹ã€‚æ—¢ã«å…¬é–‹ã•ã‚Œã¦ã„ã‚‹BERTãƒ¢ãƒ‡ãƒ«ã¨ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½æ¯”è¼ƒã‚‚è¡Œãªã£ã¦ãŠã‚Šã€ãã®ä»–ã®å…¬é–‹æ¸ˆã¿BERTãƒ¢ãƒ‡ãƒ«ã‚’outperformã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2020-01-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/332" target="_blank" rel="noopener noreferrer" class="title-link">BERTå…¥é–€, Ken'ichi Matsui, 2020</a>
<span class="snippet"><span>Comment</span><p>è‡ªç„¶è¨€èªå‡¦ç†ã®ç‹æ§˜ã€ŒBERTã€ã®è«–æ–‡ã‚’å¾¹åº•è§£èª¬<br><br>


<a href="https://qiita.com/omiita/items/72998858efc19a368e50" target="_blank" rel="noopener noreferrer">https://qiita.com/omiita/items/72998858efc19a368e50</a>


</p>
<p>Transformeré–¢é€£ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/245" target="_blank" rel="noopener noreferrer">[Paper Note] Attention Is All You Need, Ashish Vaswani+, arXiv'17</a>
 ã‚ãŸã‚Šã‚’å…ˆã«èª­ã‚“ã§ã‹ã‚‰ãŒèª­ã‚€ã¨è‰¯ã„<br><br><br><br>è¦ã¯<br><br>ãƒ»Transformerã‚’ãŸãã•ã‚“ç©ã‚“ã ãƒ¢ãƒ‡ãƒ«<br><br>ãƒ»NSPã¨MLMã§åŒæ–¹å‘æ€§ã‚’æŒã£ãŸäº‹å‰å­¦ç¿’ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Š<br><br>ãƒ»pooler layerï¼ˆTransformer Encoderã®æ¬¡ã«ãã£ã¤ãlayerï¼‰ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã“ã¨ã§ã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã«fine-tuningå¯èƒ½ï¼ˆi.e. pooler layerã¯è»¢ç§»å­¦ç¿’ã®å¯¾è±¡å¤–ï¼‰<br><br>ãƒ»äºˆæ¸¬ã™ã‚‹éš›ã¯ã€[CLS]ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾å¿œã™ã‚‹ä½ç½®ã®å‡ºåŠ›ã‚’ç”¨ã„ã¦åˆ†é¡å•é¡Œã‚„è¤‡æ•°æ–‡é–“ã®é–¢ä¿‚æ€§ã‚’å•ã†å•é¡Œã‚’è§£ã„ãŸã‚Šã€å„ãƒˆãƒ¼ã‚¯ãƒ³ä½ç½®ã«å¯¾å¿œã™ã‚‹å‡ºåŠ›ã‚’ç”¨ã„ã¦QAã®æ­£è§£spanã‚’äºˆæ¸¬ã—ãŸã‚Šã€è‰²ã€…ã§ãã‚‹<br><br>ãƒ»gMLP <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/344" target="_blank" rel="noopener noreferrer">MLP-like Architecture</a>
 ã‚ãŸã‚Šã®ç ”ç©¶ãŒé€²ã‚“ã§ãã‚‹ã¨ä½¿ã‚ã‚Œãªããªã£ã¦ãã‚‹å¯èƒ½æ€§æœ‰</p>
<p>ã“ã£ã¡ã®è¨˜äº‹ã‚‚ã‚ã‹ã‚Šã‚„ã™ã„ã€‚<br><br><br><br>BERTã«ã¤ã„ã¦å‹‰å¼·ã—ãŸã“ã¨ã¾ã¨ã‚ (2)ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã«ã¤ã„ã¦<br><br>


<a href="https://engineering.mobalab.net/2020/06/12/bert%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E5%8B%89%E5%BC%B7%E3%81%97%E3%81%9F%E3%81%93%E3%81%A8%E3%81%BE%E3%81%A8%E3%82%81-2%E3%83%A2%E3%83%87%E3%83%AB%E6%A7%8B%E9%80%A0%E3%81%AB%E3%81%A4%E3%81%84/" target="_blank" rel="noopener noreferrer">https://engineering.mobalab.net/2020/06/12/bert%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E5%8B%89%E5%BC%B7%E3%81%97%E3%81%9F%E3%81%93%E3%81%A8%E3%81%BE%E3%81%A8%E3%82%81-2%E3%83%A2%E3%83%87%E3%83%AB%E6%A7%8B%E9%80%A0%E3%81%AB%E3%81%A4%E3%81%84/</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2020-01-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/331" target="_blank" rel="noopener noreferrer" class="title-link">10 ML &amp; NLP Research Highlights of 2019, Sebastian Ruder, 2020</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2019-11-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/330" target="_blank" rel="noopener noreferrer" class="title-link">EMNLP 2019 spec tutorial</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2019-11-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/329" target="_blank" rel="noopener noreferrer" class="title-link">äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã®å‹•å‘ _ Survey of Pretrained Language Models, Kyosuke Nishida, 2019</a>
<span class="snippet"><span>Comment</span><p>[2019/06ã¾ã§]<br><br>ãƒ»ELMoï¼ˆåŒæ–¹å‘2å±¤LSTMè¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ãƒ»GPTï¼ˆleft-to-rightã®12å±¤Transformerè‡ªå·±å›å¸°è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ãƒ»BERTï¼ˆ24å±¤ã®TransformeråŒæ–¹å‘è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ãƒ»MT-DNNï¼ˆBERTã®ä¸Šã«ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å±¤ã‚’è¿½åŠ ã—ãŸç ”ç©¶ï¼‰<br><br>ãƒ»XLMï¼ˆãƒ‘ãƒ©ãƒ¬ãƒ«ç¿»è¨³ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ç”¨ã„ã¦ã‚¯ãƒ­ã‚¹ãƒªãƒ³ã‚¬ãƒ«ã«ç©´åŸ‹ã‚ã‚’å­¦ç¿’ï¼‰<br><br>ãƒ»TransformerXLï¼ˆç³»åˆ—é•·ã„ã«åˆ¶é™ã®ã‚ã£ãŸæ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã«ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ã®å†å¸°ã‚’å°å…¥ã—é•·ã„ç³»åˆ—ã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«ï¼‰<br><br>ãƒ»GPT-2ï¼ˆ48å±¤Transformerã®è‡ªå·±å›å¸°è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ãƒ»ERNIE 1.0ï¼ˆBaidu, ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨ãƒ•ãƒ¬ãƒ¼ã‚ºã®å¤–éƒ¨çŸ¥è­˜ã‚’ä½¿ã£ã¦ãƒã‚¹ã‚¯ã«åˆ©ç”¨ï¼‰<br><br>ãƒ»ERNIEï¼ˆTsinghua, çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®æƒ…å ±ã‚’fusionã—ãŸLMï¼‰<br><br>ãƒ»Gloverï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³ã€æ—¥ä»˜ã€è‘—è€…ãªã©ã‚’æ¡ä»¶ã¨ã—ãŸç”Ÿæˆã‚’å¯èƒ½ã¨ã—ãŸGPTï¼‰<br><br>ãƒ»MASSï¼ˆEncoder-Decoderå‹ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®äº‹å‰å­¦ç¿’ï¼‰<br><br>ãƒ»UniLMï¼ˆSequence-to-Sequenceã‚’å¯èƒ½ã«ã—ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ãƒ»XLNetï¼ˆè‡ªå·±å›å¸°ï¼ˆå˜æ–¹å‘ï¼‰ãƒ¢ãƒ‡ãƒ«ã¨åŒæ–¹å‘ãƒ¢ãƒ‡ãƒ«ã®ä¸¡æ–¹ã®åˆ©ç‚¹ã‚’å¾—ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ï¼‰<br><br><br><br>[2019/07~]<br><br>ãƒ»SpanBERTï¼ˆi.i.dã§ã¯ãªãç¯„å›²ã§ãƒã‚¹ã‚¯ã—ã€åŒæ™‚ã«ç¯„å›²ã®å¢ƒç•Œã‚‚äºˆæ¸¬ã™ã‚‹ï¼‰<br><br>ãƒ»ERNIE 2.0ï¼ˆBaidu, ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯äº‹å‰å­¦ç¿’; å˜èªãƒ¬ãƒ™ãƒ«ãƒ»æ§‹é€ ãƒ¬ãƒ™ãƒ«ãƒ»æ„å‘³ãƒ¬ãƒ™ãƒ«ï¼‰<br><br>ãƒ»RoBERTaï¼ˆBERTã¨åŒã˜æ§‹é€ ã§å·¥å¤«ã‚’åŠ ãˆã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Šï¼‰<br><br>ã€€- ã‚ˆã‚Šå¤§ããªãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ä½¿ã†ï¼ˆ256ã‹ã‚‰8192ï¼‰<br><br>ã€€- ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã†ï¼ˆ16GBã‹ã‚‰160GBï¼‰<br><br>ã€€- ã‚ˆã‚Šé•·ã„ã‚¹ãƒ†ãƒƒãƒ—æ•°ã®å­¦ç¿’ã‚’ã™ã‚‹ï¼ˆBERTæ›ç®—ã§16å€ï¼‰<br><br>ã€€- æ¬¡æ–‡äºˆæ¸¬ï¼ˆNSPï¼‰ã¯ä¸è¦<br><br>ã€€â†’ GLUEã§BERT, XLNetã‚’outperform<br><br>ãƒ»StructBERT (ALICE, NSPã«ä»£ã‚ã‚‹å­¦ç¿’ã®ç›®çš„é–¢æ•°ã‚’å·¥å¤«)<br><br>ã€€- ãƒã‚¹ã‚¯ã—ãŸä¸Šã§å˜èªã®é †ç•ªã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—å…ƒã«æˆ»ã™<br><br>ã€€- ãƒ©ãƒ³ãƒ€ãƒ ãƒ»æ­£é †ãƒ»é€†é †ã®3ç¨®é¡ã‚’åˆ†é¡<br><br>ã€€â†’ BERTã¨åŒã‚µã‚¤ã‚ºã€åŒãƒ‡ãƒ¼ã‚¿ã§BERT, RoBERTaè¶…ãˆ<br><br>ãƒ»DistilBERTï¼ˆè’¸ç•™ã«ã‚ˆã‚Šã€12å±¤BERTã‚’6å±¤ã«å°å‹åŒ–ï¼ˆ40%æ¸›ï¼‰ï¼‰<br><br>ã€€- BERTã®å‡ºåŠ›ã‚’æ•™å¸«ã¨ã—ã¦ã€ç”Ÿå¾’ãŒåŒã˜å‡ºåŠ›ã‚’å‡ºã™ã‚ˆã†ã«å­¦ç¿’<br><br>ã€€- å¹…ï¼ˆéš ã‚Œå±¤ï¼‰ã‚µã‚¤ã‚ºã‚’æ¸›ã‚‰ã™ã¨ã€å±¤æ•°ã‚’çµŒã‚ï½’ã‚¹ã‚ˆã‚Šã‚‚æ‚ªåŒ–<br><br>ã€€â†’ æ¨è«–ã¯60%é«˜é€ŸåŒ–ã€ç²¾åº¦ã¯95%ç¨‹åº¦ã‚’ä¿æŒ<br><br>ãƒ»Q8BERTï¼ˆç²¾åº¦ã‚’è½ã¨ã•ãšã«fine-tuningæ™‚ã«BERTã‚’8bitæ•´æ•°ã«é‡å­åŒ–ï¼‰<br><br>ã€€- Embedding, FCã¯8bitåŒ–ã€softmax, LNorm, GELUã¯32bitã‚’ã‚­ãƒ¼ãƒ—<br><br>ã€€â†’ ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º1/4, é€Ÿåº¦3.7å€<br><br>ãƒ»CTRLï¼ˆæ¡ä»¶ä»˜ãè¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ã€€- æ¡ä»¶ã¨ãªã‚‹åˆ¶å¾¡ãƒ†ã‚­ã‚¹ãƒˆã‚’æœ¬æ–‡ã®å‰ã«ä¸ãˆã¦å­¦ç¿’<br><br>ã€€- 48å±¤/1280æ¬¡å…ƒTransformerï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°1.6Bï¼‰<br><br>ãƒ»MegatronLMï¼ˆ72å±¤ã€éš ã‚ŒçŠ¶æ…‹ã‚µã‚¤ã‚º3072ã€é•·ã•1024; BERTã®24å€ã‚µã‚¤ã‚ºï¼‰<br><br>ãƒ»ALBERTï¼ˆBERTã®å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã™ã¹ã¦å…±æœ‰ã™ã‚‹ã“ã¨ã§å­¦ç¿’ã‚’é«˜é€ŸåŒ–; 2020å¹´ã‚ãŸã‚Šã®ãƒ‡ãƒ•ã‚¡ã‚¯ãƒˆï¼‰<br><br>ã€€- Largeã‚’è¶…ãˆãŸãƒ¢ãƒ‡ãƒ«ã¯å­¦ç¿’ãŒé›£ã—ã„ãŸã‚ã€è¡¨ç¾ã¯è½ã¡ã‚‹ãŒå­¦ç¿’ã—ã‚„ã™ãã—ãŸ<br><br>ã€€- å˜èªåŸ‹ã‚è¾¼ã¿ã‚’ä½æ¬¡å…ƒã«ã™ã‚‹ã“ã¨ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°å‰Šæ¸›<br><br>ã€€- æ¬¡æ–‡äºˆæ¸¬ã‚’ã€æ–‡ã®é †åºå…¥ã‚Œæ›¿ãˆåˆ¤å®šã«å¤‰æ›´<br><br>ã€€â†’ GLUE, RACE, SQuADã§SoTAã‚’æ›´æ–°<br><br>ãƒ»T5ï¼ˆNLPã‚¿ã‚¹ã‚¯ã‚’ã™ã¹ã¦text-to-textã¨ã—ã¦æ‰±ã„ã€Enc-Dec Transformerã‚’745GBã‚³ãƒ¼ãƒ‘ã‚¹ã§äº‹å‰å­¦ç¿’ã—ã¦è»¢ç§»ã™ã‚‹ï¼‰<br><br>ã€€- ãƒ¢ãƒ‡ãƒ«ã¯Encoder-Decoderã®Transformer<br><br>ã€€- å­¦ç¿’ã‚¿ã‚¹ã‚¯ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ€ã«åˆã‚ã›ã¦å¤‰æ›´<br><br>ã€€- ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å´ã§ç¯„å›²ã‚’æ¬ è½ã•ã›ã¦ã€ãƒ‡ã‚³ãƒ¼ãƒ€å´ã§äºˆæ¸¬<br><br>ã€€â†’ GLUE, SuperGLUE, SQuAD1.1, CNN/DMã§SoTAæ›´æ–°<br><br>ãƒ»BARTï¼ˆSeq2Seqã®äº‹å‰å­¦ç¿’ã¨ã—ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚¹ã‚¯ãƒ»å‰Šé™¤ã€ç¯„å›²ãƒã‚¹ã‚¯ã€æ–‡ã®å…¥ã‚Œæ›¿ãˆã€æ–‡æ›¸ã®å›è»¢ã®è¤‡æ•°ã‚¿ã‚¹ã‚¯ã§å­¦ç¿’ï¼‰<br><br>ã€€â†’ CNN/DMã§T5è¶…ãˆã€WMT'16 RO-ENã§é€†ç¿»è¨³ã‚’è¶…ãˆã¦SoTA</p>
<p>ELMo, GPT, BERT, GPT-2, XLNet, RoBERTa, DistilBERT, ALBERT, T5ã‚ãŸã‚Šã¯è‰¯ãè¦‹ã‚‹ã‚ˆã†ãªæ„Ÿ</p>
<p>å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å„ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚‚å¾ŒåŠã«è¨˜è¼‰ã•ã‚Œã¦ãŠã‚Šèˆˆå‘³æ·±ã„ã€‚<br><br><br><br>ã¡ãªã¿ã«ã€CNN/DailyMail Datasetã§ã¯ã€T5, BARTã‚ãŸã‚ŠãŒSoTAã€‚<br><br>R2ã§æ¯”è¼ƒã™ã‚‹ã¨<br><br>ã€€- Pointer-Generator + Coverage VectorãŒ17,28<br><br>ã€€- LEAD-3ãŒ17.62<br><br>ã€€- BARTãŒ21.28<br><br>ã€€- T5ãŒ21.55<br><br>ã¨ãªã£ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/CommentGeneration.html" target="_blank" rel="noopener noreferrer">#CommentGeneration</a>
<span class="issue_date">Issue Date: 2019-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/326" target="_blank" rel="noopener noreferrer" class="title-link">Cross-domain personalized image captioning, Long+, 2019</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<span class="issue_date">Issue Date: 2019-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/325" target="_blank" rel="noopener noreferrer" class="title-link">ã€é»’æ©‹ç ”ã€‘BERTæ—¥æœ¬èªPretrainedãƒ¢ãƒ‡ãƒ«</a>
<span class="snippet"><span>Comment</span><p>ã€huggingface transformersã§ä½¿ãˆã‚‹æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã®ã¾ã¨ã‚ã€‘<br><br>


<a href="https://tech.yellowback.net/posts/transformers-japanese-models" target="_blank" rel="noopener noreferrer">https://tech.yellowback.net/posts/transformers-japanese-models</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<span class="issue_date">Issue Date: 2018-11-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/280" target="_blank" rel="noopener noreferrer" class="title-link">AllenNLP ï¼ˆOfficial Tutorialsï¼‰</a>
<span class="snippet"><span>Comment</span><p>


<a href="https://docs.google.com/presentation/d/17NoJY2SnC2UMbVegaRCWA7Oca7UCZ3vHnMqBV4SUayc/preview?slide=id.g43b8d8e880_0_8" target="_blank" rel="noopener noreferrer">https://docs.google.com/presentation/d/17NoJY2SnC2UMbVegaRCWA7Oca7UCZ3vHnMqBV4SUayc/preview?slide=id.g43b8d8e880_0_8</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<span class="issue_date">Issue Date: 2018-06-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/274" target="_blank" rel="noopener noreferrer" class="title-link">The Annotated Transformer, harvardnlp, 2018.04</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2018-02-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/263" target="_blank" rel="noopener noreferrer" class="title-link">ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆå‹‰å¼·ä¼šï¼ˆLSTMç·¨ï¼‰, Seitaro Shinagawa, 2016</a>
<span class="snippet"><span>Comment</span><p>LSTMã®åŸºç¤ã‹ã‚‰ã€å®Ÿè£…ã™ã‚‹ä¸Šã§ã®TipsãŒã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚<br><br>zero padding, dropoutã®ã‹ã‘ã‹ãŸã€normalizationã®æ‰‹æ³•ãªã©ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<span class="issue_date">Issue Date: 2018-01-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/240" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note]  Machine-made index for technical literature: an experiment, IBM Journal of Research and Development, 1958</a>
<span class="snippet"><span>Comment</span><p>åˆæœŸã®è¦ç´„ç ”ç©¶ã€‚Luhnã‚‰ã®ç ”ç©¶ã‚ˆã‚Šã¯citation countãŒå°‘ãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/236" target="_blank" rel="noopener noreferrer" class="title-link">ALAGIN æ©Ÿæ¢°ç¿»è¨³ã‚»ãƒŸãƒŠãƒ¼ å˜èªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ, Graham Neubig, 2014.03</a>
<span class="snippet"><span>Comment</span><p>Neubigã•ã‚“ã«ã‚ˆã‚‹å˜èªã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/235" target="_blank" rel="noopener noreferrer" class="title-link">è‡ªç„¶è¨€èªå‡¦ç†ã®ãŸã‚ã®Deep Learning, Yuta Kikuchi, 2013.09</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/SentimentAnalysis.html" target="_blank" rel="noopener noreferrer">#SentimentAnalysis</a>
<a class="button" href="articles/OpinionMining.html" target="_blank" rel="noopener noreferrer">#OpinionMining</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/231" target="_blank" rel="noopener noreferrer" class="title-link">Opinion mining and sentiment analysis, Pang+, Foundations and Trends in Information Retrieval, 2008</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/SIGIR.html" target="_blank" rel="noopener noreferrer">#SIGIR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/220" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Decomposition of Human-Written Summary Sentences. Hongyan Jing et al. SIGIRâ€™99</a>
<span class="snippet"><span>Comment</span><p>å‚ç…§è¦ç´„ - åŸæ–‡æ›¸å¯¾ãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€å‚ç…§è¦ç´„ä¸­ã®å˜èªã¨åŸæ–‡æ›¸ä¸­ã®å˜èªã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’ã¨ã‚‹HMMãƒ™ãƒ¼ã‚¹ãªæ‰‹æ³•ã‚’ææ¡ˆã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34812500-2d1d7d32-f6e9-11e7-8d9d-723804236081.png" alt="image" loading="lazy"><br><br><br><br>outputã¯ã“ã‚“ãªæ„Ÿã˜ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/SIGIR.html" target="_blank" rel="noopener noreferrer">#SIGIR</a>
<span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/219" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The automatic construction of large-scale corpora for summarization research. Daniel Marcu. SIGIRâ€™99</a>
<span class="snippet"><span>Comment</span><p>&lt;Abstract, Text&gt;ã®ã‚¿ãƒ—ãƒ«ãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€&lt;Abstract, Extract, Text&gt;ã®ã‚¿ãƒ—ãƒ«ã‚’è‡ªå‹•çš„ã«ç”Ÿæˆã€‚Extractã¯Abstractã¨å¯¾å¿œã™ã‚‹Textä¸­ã®é‡è¦éƒ¨ï¼ˆç¯€ã‚„sentenceï¼‰ã€‚<br><br><br><br>&lt;Abstract, Extract, Text&gt;ã«å«ã¾ã‚Œã‚‹Extractã®æƒ…å ±ã‚’ä½¿ãˆã°ã€Extractiveãªè¦ç´„å™¨ã®å­¦ç¿’ãªã©ã«æ´»ç”¨ã§ãã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Unsupervised.html" target="_blank" rel="noopener noreferrer">#Unsupervised</a>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/215" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LexRank: Graph-based Lexical Centrality as Salience in Text Summarization, Erkan+, Journal of Artificial Intelligence Research, 2004</a>
<span class="snippet"><span>Comment</span><p>ä»£è¡¨çš„ãªã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ãª(Multi) Document Summarizationæ‰‹æ³•ã€‚<br><br>ã»ã¼ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/214" target="_blank" rel="noopener noreferrer">[Paper Note] TextRank: Bringing Order into Texts, Mihalcea+, EMNLP'04</a>
 ã¨åŒã˜æ‰‹æ³•ã€‚<br><br><br><br>2ç¨®é¡ã®æ‰‹æ³•ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ï¼š<br><br><br><br>* [LexRank] tf-idfã‚¹ã‚³ã‚¢ã§sentenceã®bag-of-wordsãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œã‚Šã€cosine similarityã‚’è¨ˆç®—ã—é–¾å€¤ä»¥ä¸Šã¨ãªã£ãŸsentenceã®é–“ã«ã®ã¿edgeã‚’å¼µã‚‹ï¼ˆé‡ã¿ã¯ç¢ºç‡çš„ã«æ­£è¦åŒ–ï¼‰ã€‚ãã®å¾Œã¹ãä¹—æ³•ã§PageRankã€‚<br><br>* [ContinousLexRank] tf-idfã‚¹ã‚³ã‚¢ã§sentenceã®bag-of-wordsãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œã‚Šã€cosine similarityã‚’ç”¨ã„ã¦Affinity Graphã‚’è¨ˆç®—ã—ã€PageRankã‚’é©ç”¨ï¼ˆã¹ãä¹—æ³•ï¼‰ã€‚<br><br><br><br>DUC2003, 2004ï¼ˆMDSï¼‰ã§è©•ä¾¡ã€‚<br><br>Centroidãƒ™ãƒ¼ã‚¹ãƒ‰ãªæ‰‹æ³•ã‚’ROUGE-1ã®è¦³ç‚¹ã§outperformã€‚<br><br>document clusterã®17%ã‚’Noisyãªãƒ‡ãƒ¼ã‚¿ã«ã—ãŸå ´åˆã‚‚å®Ÿé¨“ã—ã¦ãŠã‚Šã€Noisyãªãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ãŸå ´åˆã‚‚æ€§èƒ½åŠ£åŒ–ãŒå°‘ãªã„ã“ã¨ã‚‚ç¤ºã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Classic.html" target="_blank" rel="noopener noreferrer">#Classic</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/213" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The automatic creation of literature abstracts, Luhn, IBM Journal of Research Development, 1958</a>
<span class="snippet"><span>Comment</span><p>æ–‡æ›¸è¦ç´„ç ”ç©¶åˆæœŸã®ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/StructuredLearning.html" target="_blank" rel="noopener noreferrer">#StructuredLearning</a>
<a class="button" href="articles/DomainAdaptation.html" target="_blank" rel="noopener noreferrer">#DomainAdaptation</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/141" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] è»¢ç§»å­¦ç¿’ã«ã‚ˆã‚‹æŠ½å‡ºå‹è¦ç´„ã®ç²¾åº¦å‘ä¸Š, è¥¿å·+, æƒ…å ±å‡¦ç†å­¦ä¼šç ”ç©¶å ±å‘Š, 2011</a>
<span class="snippet"><span>Comment</span><p>æ§‹é€ å­¦ç¿’ã‚’åˆ©ç”¨ã—ãŸæ–‡æ›¸è¦ç´„ãƒ¢ãƒ‡ãƒ«<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/126" target="_blank" rel="noopener noreferrer">[Paper Note] Frustratingly easy domain adaptation, Daum'e, ACL'07</a>
 ãªã©ã‚‚åˆ©ç”¨ã—è»¢ç§»å­¦ç¿’ã‚’è¡Œãªã£ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/139" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Text Summarization using a trainable summarizer and latent semantic analysis, Yeh+, Information Processing and Management 2005</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/129" target="_blank" rel="noopener noreferrer" class="title-link">A survey on Automatic Text Summarization, Das+, CMUã®æ•™æï¼Ÿ</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/110" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Automatically generated linguistic summaries of energy consumption data, van der Heide+, In Proceedings of the Ninth International Conference on Intelligent Systems Design and Applications, pages 553-559, 2009</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Others.html" target="_blank" rel="noopener noreferrer">#Others</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/109" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A framework for automatic text generation of trends in physiological time series data, Banaee+, In Proceedings of the IEEE International Conference on Systems, Man, and Cybernetics, 2013</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/SingleFramework.html" target="_blank" rel="noopener noreferrer">#SingleFramework</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/98" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Global Model for Concept-to-Text Generation, Konstas+, Journal of Artificial Intelligence Research, Vol. 48, pp.305--346, 2013</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/88" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] What to talk about and how? Selective Generation using LSTMs with Coarse-to-Fine Alignment, Mei+, NAACL-HLTâ€™16</a>
<span class="snippet"><span>Comment</span><p>content-selectionã¨surface realizationã‚’encoder-decoder alignerã‚’ç”¨ã„ã¦åŒæ™‚ã«è§£ã„ãŸã¨ã„ã†è©±ã€‚<br><br>æ™®é€šã®Attention basedãªãƒ¢ãƒ‡ãƒ«ã«Refinerã¨Pre-Selectorã¨å‘¼ã°ã‚Œã‚‹æ©Ÿæ§‹ã‚’è¿½åŠ ã€‚é€šå¸¸ã®attentionã«ã¯attentionã‚’ã‹ã‘ã‚‹éš›ã®accuracyã«å•é¡ŒãŒã‚ã‚‹ãŒã€data2textã§ã¯ãã¡ã‚“ã¨å‚ç…§ã™ã¹ããƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‚ç…§ã—ç”Ÿæˆã™ã‚‹ã®ãŒå¤§äº‹ãªã®ã§ã€Refinerã¨Pre-Selectorã§ãã‚Œã‚’æ”¹å–„ã™ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34460874-1b5830a2-ee5f-11e7-9220-c67a806225d8.png" alt="image" loading="lazy"><br><br><br><br>Pre-selectorã¯ã€ãã‚Œãã‚Œã®ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒé¸æŠã•ã‚Œã‚‹ç¢ºç‡ã‚’æ¨å®šã™ã‚‹ï¼ˆé€šå¸¸ã®attentionã¯alignmentã®å°¤åº¦ã‚’è¨ˆç®—ã™ã‚‹ã®ã¿ï¼‰ã€‚<br><br>Refinerã¯aligner(attention)ã®weightã‚’reweightingã™ã‚‹ã“ã¨ã§ã€æœ€çµ‚çš„ã«ã©ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’é¸æŠã™ã‚‹ã‹æ±ºå®šã™ã‚‹ã€‚<br><br>åŠ ãˆã¦ã€ãƒ­ã‚¹é–¢æ•°ã®Regularizationã®ã‹ã‘ã‹ãŸã‚’å¤‰ãˆã€æœ€ä½ä¸€ã¤ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒpreselectorã«é¸ã°ã‚Œã‚‹ã‚ˆã†ã«ãƒã‚¤ã‚¢ã‚¹ã‚’ã‹ã‘ã¦ã„ã‚‹ã€‚<br><br><br><br>ã»ã¼åˆæœŸã®Neural Network basedãªData2Textç ”ç©¶</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/77" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Teaching Machines to Read and Comprehend, Hermann+, NIPS 2015</a>
<span class="snippet"><span>Comment</span><p>ã ã„ã¶å‰ã«èª­ã‚“ã ã®ã§å‰²ã¨ã†ã‚ãŠã¼ãˆã€‚<br><br><br><br>CNN/DailyMailãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆã‚’è¡Œãªã£ãŸè«–æ–‡ï¼ˆæœ€è¿‘Neuralãªæ–‡â€æ›¸â€è¦ç´„ã®å­¦ç¿’ã§ã‚ˆãä½¿ã‚ã‚Œã‚‹ã‚„ã¤ï¼‰ã€‚<br><br>CNN/DailyMailã«ã¯ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«å¯¾ã—ã¦ã€äººæ‰‹ã§ä½œæˆã—ãŸè¦ç´„ãŒä»˜ä¸ã•ã‚Œã¦ãŠã‚Šã€è¦ç´„ä¸­ã®Entityã‚’ç©´åŸ‹ã‚ã«ã™ã‚‹ãªã©ã—ã¦ã€ç©´åŸ‹ã‚å•é¡Œã‚’ä½œæˆã€‚<br><br>è¨€æ–‡æ›¸ã‚’Neuralãªãƒ¢ãƒ‡ãƒ«ã«ä¸ãˆã¦ã€ã©ã‚Œã ã‘å›ç­”ã§ãã‚‹ã‹ã¨ã„ã†è©±ã€‚<br><br><br><br>[ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰ã«ã‚ˆã‚‹è¿½è©¦ãŒã‚ã‚‹](


<a href="https://cs.stanford.edu/people/danqi/papers/acl2016.pdf)" target="_blank" rel="noopener noreferrer">https://cs.stanford.edu/people/danqi/papers/acl2016.pdf)</a>


<br><br>[è©³ã—ã„è§£èª¬ by ä¹…ä¿ã•ã‚“](


<a href="https://www.slideshare.net/takahirokubo7792/machine-comprehension)" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/takahirokubo7792/machine-comprehension)</a>


<br><br><br><br>è¿½è©¦ã«ã‚ˆã‚‹ã¨ã€è©•ä¾¡ã§ä½¿ç”¨ã—ã¦ã„ã‚‹ç©´åŸ‹ã‚å•é¡Œã¯å˜ç´”ãªãƒ¢ãƒ‡ãƒ«ã§ææ¡ˆãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ä¸Šå›ã£ãŸã‚Šã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€ã“ã®ç©´åŸ‹ã‚å•é¡Œã®ã†ã¡54%ã¯å˜ç´”ãªè³ªå•ã¨ã®ãƒãƒƒãƒã§å›ç­”å¯èƒ½ã§ã‚ã‚Šã€25%ã¯äººã§ã‚‚æ­£è§£ä¸èƒ½ã‚‰ã—ã„ï¼ˆæ­£è§£ç‡ã®upper boundã¯75%ï¼‰ã€‚by ä¹…ä¿ã•ã‚“ã®ã‚¹ãƒ©ã‚¤ãƒ‰<br><br>ã®ã¡ã®ç ”ç©¶ã§ã€ã»ã¼ã“ã®ä¸Šé™ã«é”ã™ã‚‹ç²¾åº¦ãŒé”æˆã•ã‚Œã¦ã—ã¾ã£ãŸã®ã§ã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯QAã‚¿ã‚¹ã‚¯ã§ã¯ã»ã¼æ”»ç•¥ã•ã‚ŒãŸçŠ¶æ…‹ã ã¨ã„ã†ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Snippets.html" target="_blank" rel="noopener noreferrer">#Snippets</a>
<a class="button" href="articles/SIGIR.html" target="_blank" rel="noopener noreferrer">#SIGIR</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/56" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Web page summarization using clickthrough data, Sun et al., SIGIRâ€™05,  2005</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Snippets.html" target="_blank" rel="noopener noreferrer">#Snippets</a>
<a class="button" href="articles/QueryBiased.html" target="_blank" rel="noopener noreferrer">#QueryBiased</a>
<a class="button" href="articles/CIKM.html" target="_blank" rel="noopener noreferrer">#CIKM</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/55" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning query-biased web page summarization, Wang et al., CIKMâ€™07, 2007</a>
<span class="snippet"><span>Comment</span><p>ãƒ»å¾“æ¥ã®query-biasedãªè¦ç´„ã«ãŠã‘ã‚‹classificationã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ï¼Œtrainingå†…ã®documentã®æƒ…å ±ãŒæœªçŸ¥ã®documentã®sentenceã®classificationã«å½¹ç«‹ã¤ã¨ã„ã†ã‚‚ã®ã ã£ãŸï¼ã“ã‚Œã¯ï¼ŒãŸã¨ãˆã°ä¼¼ãŸã‚ˆã†ãªæƒ…å ±ã‚’å¤šãå«ã‚€scientific articleã ã£ãŸã‚‰æœ‰ç”¨ã ãŒï¼Œæ§˜ã€…ãªæƒ…å ±ã‚’å«ã‚€web pageã«ã¯ã‚ã¾ã‚Šé©åˆ‡ã§ã¯ãªã„ï¼ˆã“ã‚Œã¯training setå†…ã®documentã®æƒ…å ±ã¨target pageã®æƒ…å ±ã‚’æ¯”è¼ƒã™ã‚‹ã¿ãŸã„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ç›¸å½“ã™ã‚‹ï¼‰ï¼ã“ã®ç ”ç©¶ã§ã¯ï¼Œtarget pageå†…ã®â€™sentenceã®ä¸­ã§â€™ã¯ã‚¹ãƒ‹ãƒšãƒƒãƒˆã«å«ã‚ã‚‹ã¹ãæ–‡ã‹ã©ã†ã‹ã¨ã„ã†æ¯”è¼ƒãŒã§ãã‚‹ã¨ã„ã†ä»®å®šã®ã‚‚ã¨ï¼Œlearning to rankã‚’ç”¨ã„ã¦ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’ç”Ÿæˆã™ã‚‹ï¼<br><br>ãƒ»query biased summarizationã§ã¯relevanceã¨fidelityã®ä¸¡è€…ãŒæ‹…ä¿ã•ã‚ŒãŸè¦ç´„ãŒè‰¯ã„ã¨ã•ã‚Œã¦ã„ã‚‹ï¼<br><br>relevanceã¨ã¯ã‚¯ã‚¨ãƒªã¨è¦ç´„ã®é©åˆæ€§ï¼Œfidelityã¨ã¯ï¼Œè¦ç´„ã¨target documentã¨ã®å¯¾å¿œã®è‰¯ã•ã§ã‚ã‚‹ï¼<br><br>ãƒ»ç´ æ€§ã¯ï¼Œrelevanceã«é–¢ã—ã¦ã¯ã‚¯ã‚¨ãƒªã¨ã®é–¢é€£åº¦ï¼Œfidelityã«é–¢ã—ã¦ã¯ï¼Œtarget pageå†…ã®sentenceã«é–¢ã—ã¦ã¯æ–‡ã®ä½ç½®ã‚„ï¼Œæ–‡ã®æ›¸å¼ï¼ˆå¤ªå­—ï¼‰ãªã©ã®æƒ…å ±ã‚’ä½¿ã†ï¼contextã®æ–‡ã§ã¯ãã†ã„ã£ãŸæƒ…å ±ãŒä½¿ãˆãªã„ã®ã§ï¼Œã‚¿ã‚¤ãƒˆãƒ«ã‚„anchor textã®ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ç”¨ã„ã¦fidelityã‚’æ‹…ä¿ã™ã‚‹ï¼ˆè©³ã—ãã‹ã„ã¦ãªã„ï¼‰ï¼ã‚ã¨ã¯term occurenceï¼Œtitleã¨extracted title(å…ˆè¡Œç ”ç©¶ã«ã‚ˆã‚‹ã¨ï¼ŒTRECãƒ‡ãƒ¼ã‚¿ã®33.5%ã®ã‚¿ã‚¤ãƒˆãƒ«ãŒå½ç‰©ã ã£ãŸã¨ã„ã†ã‚‚ã®ãŒã‚ã‚‹ã®ã§extracted titleã‚‚ç”¨ã„ã‚‹)ï¼Œanchor textã®æƒ…å ±ã‚’ä½¿ã†ï¼ã‚ã¾ã‚Šæ·±ãèª­ã‚“ã§ã„ãªã„ï¼<br><br>ãƒ»å…¨ã¦ã®ç´ æ€§ã‚’çµ„ã¿åˆã‚ã›ãŸã»ã†ãŒintrinsicãªevaluationã«ãŠã„ã¦é«˜ã„è©•ä¾¡å€¤ï¼ã¾ãŸï¼Œcontextã¨contentä¸¡æ–¹çµ„ã¿åˆã‚ã›ãŸã»ã†ãŒè‰¯ã„çµæœãŒã§ãŸï¼</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Snippets.html" target="_blank" rel="noopener noreferrer">#Snippets</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/54" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Enhanced web document summarization using hyperlinks, Delort et al., HTâ€™03, 2003</a>
<span class="snippet"><span>Comment</span><p>ãƒ»Genericãªweb pageã®è¦ç´„ã‚’ã¤ãã‚‹<br><br>ãƒ»è¦ç´„ã‚’ä½œã‚‹éš›ã«ï¼Œãƒšãƒ¼ã‚¸ã®å†…å®¹ã‹ã‚‰ä½œã‚‹ã‚ã‘ã§ã¯ãªãï¼Œcontextã‚’ç”¨ã„ã¦ä½œã‚‹ï¼contextã¨ã¯ï¼Œtarget pageã«ãƒªãƒ³ã‚¯ã‚’å¼µã£ã¦ã„ã‚‹ãƒšãƒ¼ã‚¸ã«ãŠã‘ã‚‹ãƒªãƒ³ã‚¯ã®å‘¨è¾ºã«ã‚ã‚‹æ–‡ã®ã“ã¨ï¼<br><br>ãƒ»contextã‚’åˆ©ç”¨ã—ãŸè¦ç´„ã§ã¯ï¼Œpartialityã¨topicalityã«é–¢ã™ã‚‹å•é¡ŒãŒç”Ÿã˜ã‚‹ï¼partialityã¨ã¯ï¼Œcontextã«å«ã¾ã‚Œã‚‹æƒ…å ±ãŒtarget pageã«é–¢ã™ã‚‹ä¸€éƒ¨ã®æƒ…å ±ã—ã‹å«ã‚“ã§ã„ãªã„å•é¡Œï¼topicalityã¨ã¯ï¼Œãã‚‚ãã‚‚contextã«å«ã¾ã‚Œã‚‹æƒ…å ±ãŒï¼Œtarget pageã®overviewã«é–¢ã™ã‚‹æƒ…å ±ã‚’å«ã‚“ã§ã„ãªã„å•é¡Œ<br><br>ãƒ»partialityã«é–¢ã—ã¦ã¯ï¼Œcontextã«å«ã¾ã‚Œã‚‹æ–‡ã‚’é™¤ãã“ã¨ã§ï¼Œcontextã®overallãªæƒ…å ±ãŒå¤±ã‚ã‚Œãªã„æœ€å°ã®setã‚’æ±‚ã‚ã‚‹ã“ã¨ã§å¯¾å¿œï¼setã‚’æ±‚ã‚ã‚‹éš›ã«ã¯ï¼Œcontextå†…ã®2æ–‡ã®å˜èªã‚’æ¯”è¼ƒã—ï¼ŒidenticalãªrepresentationãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’è¨ˆç®—ï¼é‡è¤‡ã™ã‚‹ã‚‚ã®ã¯æ’é™¤ã™ã‚‹ã“ã¨ã§setã‚’æ±‚ã‚ã‚‹ï¼<br><br>ãƒ»topicalityã«é–¢ã—ã¦ã¯ï¼Œtarget pageã®textual informationãŒå–å¾—ã§ãã‚‹å ´åˆã¯ï¼Œcontextå†…ã®æ–‡ä¸­ã®å˜èªãŒtarget pageå†…ã«å«ã¾ã‚Œã‚‹å˜èªã®æ¯”ç‡ã‚’å‡ºã™ã“ã¨ã§topicality scoreã‚’ç®—å‡ºï¼topicality scoreãŒé«˜ã„ã‚‚ã®ã‚’è¦ç´„ã¨ã™ã‚‹ï¼ä¸€æ–¹ï¼Œtarget pageã®textual informationãŒååˆ†ã§ãªã„å ´åˆã¯ï¼Œcontextå†…ã®æ–‡ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã„ï¼Œå„ã‚¯ãƒ©ã‚¹ã‚¿ã®centroidã¨è¿‘ã„æ–‡ã‚’æŠ½å‡ºï¼</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Snippets.html" target="_blank" rel="noopener noreferrer">#Snippets</a>
<a class="button" href="articles/QueryBiased.html" target="_blank" rel="noopener noreferrer">#QueryBiased</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/53" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A task-oriented study on the influencing effects of query-biased summarization in web searching, White et al., Information Processing and Management, 2003</a>
<span class="snippet"><span>Comment</span><p>ãƒ»search engineã«ãŠã„ã¦query-biasedãªè¦ç´„ã®æœ‰ç”¨æ€§ã‚’ç¤ºã—ãŸã‚‚ã®<br><br>ãƒ»task-orientedãªè©•ä¾¡ã«ã‚ˆã£ã¦ï¼Œææ¡ˆæ‰‹æ³•ãŒGoogleã‚„AltaVistaã®ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚ˆã‚Šã‚‚è‰¯ã„ã“ã¨ã‚’ç¤ºã™ï¼<br><br>ãƒ»ææ¡ˆæ‰‹æ³•ã¯æ–‡é¸æŠã«ã‚ˆã‚‹query-biased summarizationï¼ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã«ã¯ï¼Œãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã«å«ã¾ã‚Œã‚‹å˜èªãŒã©ã‚Œã ã‘å«ã¾ã‚Œã¦ã„ã‚‹ã‹ï¼Œæ–‡ã®ãƒšãƒ¼ã‚¸å†…ã§ã®å‡ºç¾ä½ç½®ï¼Œã‚¯ã‚¨ãƒªã¨ã®é–¢é€£åº¦ï¼Œæ–‡ã®æ›¸å¼ï¼ˆå¤ªå­—ï¼‰ãªã©ã®æƒ…å ±ã‚’ä½¿ã†ï¼<br><br>ãƒ»ã‚¹ãƒ‹ãƒšãƒƒãƒˆãŒä½œã‚Œãªã„ãƒšãƒ¼ã‚¸ã«å¯¾ã—ã¦ã¯ï¼Œã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã—ãŸã‚Šï¼Œãƒšãƒ¼ã‚¸å†…ã®æœ€åˆã®non-textualãªè¦ç´ ã‚’è¿”ã—ãŸã‚Šã™ã‚‹ï¼</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Temporal.html" target="_blank" rel="noopener noreferrer">#Temporal</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/49" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] HLTCOE at TREC 2013: Temporal Summarization, Xu et al, [TREC 2013]</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Temporal.html" target="_blank" rel="noopener noreferrer">#Temporal</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/48" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BJUT at TREC 2013 Temporal Summarization Track, yang et al. [TREC2013]</a>
<span class="snippet"><span>Comment</span><p>ãƒ»æ¬¡ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ã‚ˆã‚Šæ§‹æˆã•ã‚Œã‚‹ã€‚Preprocess, Retrieval, Information expansion, Sentence choosing and ranking<br><br><br><br>ãƒ»Preprocess: GPGãƒ•ã‚¡ã‚¤ãƒ«ã‚’TXTãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ã€‚indexã‚’ã¯ã‚‹ã€‚<br><br>ãƒ»Retrieval: æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã¨ã—ã¦Lemur searchã‚’ä½¿ã£ã¦ã„ã‚‹ã€‚ã‚¯ã‚¨ãƒªæ‹¡å¼µã¨å˜èªã®é‡ã¿ä»˜ã‘ãŒã§ãã‚‹ãŸã‚ã€‚ï¼ˆDocumentã‚’Retrievalã™ã‚‹ï¼‰<br><br>ãƒ»Information Expansion: æ¤œç´¢çµæœã‚’æ‹¡å¼µã™ã‚‹ãŸã‚ã«K-meansã‚’ç”¨ã„ã‚‹ã€‚<br><br>ãƒ»Sentence choosing and ranking: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å¾Œã«ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ã®ä¸­å¿ƒã‹ã‚‰è¦ç´„ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚<br><br> time factorã¨similarity factorã«ã‚ˆã£ã¦sentenceãŒãƒ©ãƒ³ã‚¯ä»˜ã‘ã•ã‚Œã‚‹ã€‚ï¼ˆè©³ç´°ãªã—ï¼‰<br><br>ãƒ»Retrievalã«ãŠã„ã¦ã¯ä¸»ã«TF-IDFã¨BM25ã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚<br><br>ãƒ»traditionalãªretrieval methodã ã‘ã§ã¯perform wellã§ã¯ãªã„ã®ã§ã€Information Expansionã‚’ã™ã‚‹ã€‚k-meansã‚’ã™ã‚‹ã“ã¨ã§ã€ç•°ãªã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã®ãƒˆãƒ”ãƒƒã‚¯ã«åŸºã¥ã„ã¦ã‚¯ãƒ©ã‚¹ã‚¿ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ä¸­å¿ƒã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®top sentencesã‚’ã¨ã£ã¦ãã¦ã€è¦ç´„ã¨ã™ã‚‹ã€‚æœ€çµ‚çš„ã«ã‚¤ãƒ™ãƒ³ãƒˆã”ã¨ã«50 sentencesã‚’é¸æŠã™ã‚‹ã€‚<br><br>ãƒ»ç”Ÿæˆã—ãŸSequential Update Summarizationã‹ã‚‰valueã‚’æŠœã„ã¦ãã¦ã€Value Trackingã‚’ã™ã‚‹ã€‚<br><br><br><br>ãƒ»Updateã®éƒ¨åˆ†ã‚’ã©ã®ã‚ˆã†ã«å®Ÿè£…ã—ã¦ã„ã‚‹ã®ã‹ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Update.html" target="_blank" rel="noopener noreferrer">#Update</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/40" target="_blank" rel="noopener noreferrer" class="title-link">DUC 2007, Update Summarization Dataset</a>
<span class="snippet"><span>Comment</span><p>DUC 2007:


<a href="https://duc.nist.gov/duc2007/tasks.html" target="_blank" rel="noopener noreferrer">https://duc.nist.gov/duc2007/tasks.html</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Update.html" target="_blank" rel="noopener noreferrer">#Update</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/39" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Update Summary Update, Copeck et al., [TACâ€™08]</a>
<span class="snippet"><span>Comment</span><p>è¢«å¼•ç”¨æ•°ã¯å°‘ãªã„ãŒã€è‰¯ã„è«–æ–‡ã‹ã‚‰referã•ã‚Œã¦ã„ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Update.html" target="_blank" rel="noopener noreferrer">#Update</a>
<a class="button" href="articles/EACL.html" target="_blank" rel="noopener noreferrer">#EACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/38" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DualSum: a Topic-Model based approach for update summarization, Delort et al., [EACLâ€™12]</a>
<span class="snippet"><span>Comment</span><p>ãƒ»å¤§åŠã®update summarizationã®æ‰‹æ³•ã¯document set AãŒgivenã®ã¨ãï¼Œdocument set Bã®update summarizationã‚’ã¤ãã‚‹éš›ã«ã¯ï¼Œredundancy removalã®å•é¡Œã¨ã—ã¦æ‰±ã£ã¦ã„ã‚‹ï¼<br><br>ãƒ»ã“ã®æ‰‹æ³•ã¯ï¼Œ1ã¤ã®sentenceã®ä¸­ã«redundantãªæƒ…å ±ã¨novelãªæƒ…å ±ãŒæ··åœ¨ã—ã¦ã„ã‚‹ã¨ãã«ï¼Œãã®sentenceã‚’redundantãªsentenceã ã¨åˆ¤åˆ¥ã—ã¦ã—ã¾ã†å•é¡Œç‚¹ãŒã‚ã‚‹ï¼åŠ ãˆã¦ï¼Œnovel informationã‚’å«ã‚“ã§ã„ã‚‹ã¨åˆ¤åˆ¥ã¯ã™ã‚‹ã‘ã‚Œã©ã‚‚ï¼Œæ˜ç¤ºçš„ã«novel informationãŒãªã‚“ãªã®ã‹ã¨ã„ã†ã“ã¨ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¦ã„ãªã„ï¼<br><br>ãƒ»Bayesian Modelã‚’ä½¿ã†ã“ã¨ã«ã‚ˆã£ã¦ï¼Œä»–ã®æ‰‹æ³•ã§ã¯æŠœã‘è½ã¡ã¦ã„ã‚‹ç¢ºç‡çš„ãªå–ã‚Šæ‰±ã„ãŒå¯èƒ½ã«ã—, unsupervisedã§ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ï¼</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Update.html" target="_blank" rel="noopener noreferrer">#Update</a>
<a class="button" href="articles/CIKM.html" target="_blank" rel="noopener noreferrer">#CIKM</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/37" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Document Update Summarization Using Incremental Hierarchical Clustering, Wang+, CIKMâ€™10</a>
<span class="snippet"><span>Comment</span><p>ãƒ»æ—¢å­˜ã®MDSã§ã¯documentã‚’batchå‡¦ç†ã™ã‚‹ã®ãŒå‰æï¼typicalãªã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã‚„ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã¯sentence-graphã‚’æ§‹ç¯‰ã—ã¦è¦ç´„ã‚’è¡Œã†ï¼ã—ã‹ã—ï¼Œæƒ…å ±ãŒsequentialã«å±Šãï¼Œrealtimeã§è¦ç´„ã‚’è¡Œã„ãŸã„ã¨ãã«ã“ã®ã‚ˆã†ãªæ‰‹æ³•ã‚’ä½¿ã†ã¨ï¼Œæ¯å›ã™ã§ã«å‡¦ç†ã—ãŸã“ã¨ãŒã‚ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹ã“ã¨ã«ãªã‚Šï¼Œtime consumingã ã—ï¼Œç„¡é§„ãªå‡¦ç†ãŒå¤šã„ï¼ç‰¹ã«ç½å®³æ™‚ãªã©ã§ã¯è‡´å‘½çš„ï¼ã“ã®ã‚ˆã†ãªå•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ï¼Œãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒarriveã—ãŸã¨ãã«ï¼ŒãŸã ã¡ã«update summaryãŒç”Ÿæˆã§ãã‚‹æ‰‹æ³•ã‚’ææ¡ˆã™ã‚‹ï¼<br><br>ãƒ»æ—¢å­˜ã®ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãªfeatureï¼ˆtf-isfã‚„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ãªã©ï¼‰ã‚’ç”¨ã„ãŸã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã¯ï¼Œexisting sentencesã¨newly coming sentencesãŒç‹¬ç«‹ã—ã¦ã„ã‚‹ãŸã‚ï¼Œreal world scenarioã«ãŠã„ã¦å®Ÿç”¨çš„ã§ãªã„ã—ï¼Œhardly perform wellã§ã‚ã‚‹ï¼<br><br>ãƒ»ãªã®ã§ï¼Œincremental hierarchical clusteringã®æ‰‹æ³•ã§sentence clusterã‚’re-organizeã™ã‚‹ã“ã¨ã§ï¼ŒåŠ¹æœçš„ã«è¦ç´„ã®updateã‚’è¡Œã†ï¼ã“ã®ã¨ãï¼ŒsentenceåŒå£«ã®hierarchical relationshipã¯real timeã«re-constructã•ã‚Œã‚‹ï¼<br><br>ãƒ»TACã®update summarizationã¨ã¯å®šç¾©ãŒå¾®å¦™ã«é•ã†ã‚‰ã—ã„ï¼ä¸»ã«ï¼’ç‚¹ï¼TACã§ã¯newly coming documentsã ã‘ã‚’å¯¾è±¡ã«ã—ã¦ã„ã‚‹ãŒï¼Œã“ã®ç ”ç©¶ã€€ã§ã¯ã™ã¹ã¦ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å¯¾è±¡ã«ã™ã‚‹ï¼ã•ã‚‰ã«ï¼ŒTACã§ã¯ä¸€åº¦ã ã‘update summarizationã™ã‚‹ï¼ˆdocument set Bã®ã¿ï¼‰ãŒï¼Œã“ã®ç ”ç©¶ã§ã¯documentsãŒsequenceã§arriveã™ã‚‹ã®ã‚’å‰æã«ã™ã‚‹ï¼ãªã®ã§ï¼ŒTACã«å¯¾ã—ã¦ã‚‚ææ¡ˆæ‰‹æ³•ã¯é©ç”¨å¯èƒ½ï¼<br><br>ãƒ»Sequence Update Summarizationã®å…ˆé§†ã‘çš„ãªç ”ç©¶ã‹ã‚‚ã—ã‚Œãªã„ï¼SUSãŒã®shared taskã«ãªã£ãŸã®ã¯2013ã ã—ï¼<br><br>ãƒ»incremental hierarchical clusteringã«ã¯COBWEB algorithm (ã‹ãªã‚Špopularã‚‰ã—ã„)ã‚’ä½¿ã†ï¼COBWEBã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ï¼Œæ–°ãŸãªelementãŒç¾ã‚ŒãŸã¨ãï¼ŒCategory Utilityã¨å‘¼ã°ã‚Œã‚‹criterionã‚’æœ€å¤§åŒ–ã™ã‚‹ã‚ˆã†ã«ï¼Œ4ç¨®é¡ã®æ“ä½œã®ã†ã¡ï¼‘ã¤ã®æ“ä½œã‚’å®Ÿè¡Œã™ã‚‹ï¼ˆinsert(ã‚¯ãƒ©ã‚¹ã‚¿ã«sentenceã‚’æŒ¿å…¥), createï¼ˆæ–°ãŸãªã‚¯ãƒ©ã‚¹ã‚¿ã¤ãã‚‹ï¼‰, merge(2ã‚¯ãƒ©ã‚¹ã‚¿ã‚’ï¼‘ã¤ã«)ï¼Œsplit(existingã‚¯ãƒ©ã‚¹ã‚¿ã‚’è¤‡æ•°ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«)ï¼‰ï¼ãŸã ï¼Œã‚‚ã¨ã®COBWEBã§ä½¿ã‚ã‚Œã¦ã„ã‚‹normal attribute distributionã¯text dataã«ãµã•ã‚ã—ããªã„ã®ã§ï¼ŒKatz distributionã‚’word occurrence distributionã¨ã—ã¦ä½¿ã†ï¼ˆSahooã‚‰ãŒææ¡ˆã—ã¦ã„ã‚‹ï¼ï¼‰ï¼å…ƒè«–æ–‡èª­ã¾ãªã„ã¨è©³ç´°ã¯ä¸æ˜ï¼<br><br>ãƒ»è¦ç´„ã®ç”Ÿæˆã¯ï¼Œå®Ÿæ–½ã—ãŸoperationã”ã¨ã«ç•°ãªã‚‹ï¼<br><br><br><br>- Insertã®å ´åˆ: ã‚¯ãƒ©ã‚¹ã‚¿ã‚’ä»£è¡¨ã™ã‚‹sentenceã‚’ã‚¯ã‚¨ãƒªã¨ã®similarity, ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®sentenceã¨ã®intra similarityã‚’è¨ˆç®—ã—ã¦æ±ºã‚ã¦å‡ºåŠ›ã™ã‚‹ï¼<br><br>- createã®å ´åˆ: æ–°ãŸã«ç”Ÿæˆã—ãŸã‚¯ãƒ©ã‚¹ã‚¿cluster_kã‚’ä»£è¡¨ã™ã‚‹æ–‡ã‚’ï¼Œè¿½åŠ ã—ãŸsentence s_newã¨ã™ã‚‹ï¼<br><br>- mergeã®å ´åˆ: cluster_aã¨cluster_bã‚’mergeã—ã¦æ–°ãŸãªcluster_cã‚’ä½œã£ãŸå ´åˆï¼Œcluster_cã‚’ä»£è¡¨ã™ã‚‹æ–‡ã‚’æ±ºã‚ã‚‹ï¼cluster_cã‚’ä»£è¡¨ã™ã‚‹æ–‡ã¯ï¼Œcluster_aã¨cluster_bã‚’ä»£è¡¨ã™ã‚‹æ–‡ã¨ã‚¯ã‚¨ãƒªã¨ã®similarityã‚’ã¯ã‹ã‚Šï¼ŒsimilarityãŒå¤§ãã„ã‚‚ã®ã¨ã™ã‚‹ï¼<br><br>- splitã®å ´åˆ: cluster_aã‚’splitã—ã¦nå€‹ã®æ–°ãŸãªã‚¯ãƒ©ã‚¹ã‚¿ãŒã§ããŸã¨ãï¼Œå„æ–°ãŸãªnå€‹ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«ãŠã„ã¦ä»£è¡¨ã™ã‚‹æ–‡ã‚’ï¼Œoriginal subtreeã®æ ¹ã¨ã™ã‚‹ï¼<br><br><br><br>ãƒ»TAC08ã®ãƒ‡ãƒ¼ã‚¿ã¨Hurricane Wilma Releasesã®ãƒ‡ãƒ¼ã‚¿ï¼ˆdisaster systemã‹ã‚‰top 10 queryã‚’å–å¾—ï¼Œ5äººã®ã‚¢ãƒãƒ†ãƒ¼ã‚¿ã«æ­£è§£ã‚’ä½œã£ã¦ã‚‚ã‚‰ã†ï¼‰ã‚’ä½¿ã£ã¦è©•ä¾¡ï¼ï¼ˆè¦ç´„ã®é•·ã•ã‚’æƒãˆã¦ã„ã‚‹ã®ã‹ãŒæ°—ã«ãªã‚‹ã€‚é•·ã•ãŒæƒã£ã¦ã„ãªã„ã‹ã‚‰ROUGEã®Få€¤ã§æ¯”è¼ƒã—ã¦ã„ã‚‹ï¼Ÿï¼‰<br><br>ãƒ»ä¸€å¿œROUGEã®Få€¤ã‚‚é«˜ã„ã—ï¼Œé€Ÿåº¦ã‚‚baselineã¨æ¯”ã¹ã¦æ—©ã„ï¼ã‹ãªã‚Šã¯ã‚„ã„ï¼genericãªMDSã¨TAC participantsã¨æ¯”è¼ƒï¼TAC Bestã¨åŒç­‰ï¼GenericMDSã‚ˆã‚Šè‰¯ã„ï¼document setAã®æƒ…å ±ã‚’ä½¿ã£ã¦redundancy removalã‚’ã—ã¦ã„ãªã„ã®ã«TAC Bestã‚’å°‘ã—ã ã‘outperformï¼ãŠã‚‚ã—ã‚ã„ï¼<br><br>ãƒ»ã‹ã¤ï¼ŒTAC bestã¯sentence combinationã‚’ç¹°ã‚Šè¿”ã™æ‰‹æ³•ã‚‰ã—ãï¼Œlarge-scale online dataã«ã¯é©ã—ã¦ã„ãªã„ã¨è¨€åŠï¼</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Update.html" target="_blank" rel="noopener noreferrer">#Update</a>
<a class="button" href="articles/CIKM.html" target="_blank" rel="noopener noreferrer">#CIKM</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/36" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Incremental Update Summarization: Adaptive Sentence Selection based on Prevalence and Novelty, McCreadie et al., CIKMâ€™14</a>
<span class="snippet"><span>Comment</span><p>ãƒ»timelyãªeventã«å¯¾ã—ã¦update summarizationã‚’é©ç”¨ã™ã‚‹å ´åˆã‚’è€ƒãˆã‚‹ï¼ãŸã¨ãˆã°6æ—¥é–“ç¶šã„ãŸeventãŒã‚ã£ãŸã¨ãã«ãã®æƒ…å ±ã‚’ãƒ¦ãƒ¼ã‚¶ãŒè¿½ã†ç‚ºã«ä½•åº¦ã‚‚update summarizationã‚·ã‚¹ãƒ†ãƒ ã‚’ç”¨ã„ã‚‹çŠ¶æ³ã‚’è€ƒãˆã‚‹ï¼6æ—¥é–“ã®ã†ã¡æ–°ã—ã„æƒ…å ±ãŒä½•ã‚‚å‡ºã¦ã“ãªã„æœŸé–“ã¯irrelevantã§redundantãªå†…å®¹ã‚’å«ã‚€è¦ç´„ãŒå‡ºã¦ãã¦ã—ã¾ã†ï¼ã“ã‚Œã‚’ãªã‚“ã¨ã‹ã™ã‚‹æ‰‹æ³•ãŒå¿…è¦ã ã¨ã„ã†ã®ãŒmotivationï¼<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34404205-dac93b7e-ebef-11e7-9ca1-603e2461b9eb.png" alt="image" loading="lazy"><br><br><br><br>ãƒ»ã©ã®ã‚ˆã†ãªæ‰‹æ³•ã‹ã¨ã„ã†ã¨ï¼Œnews streamsã‹ã‚‰novel updatesã‚’timely mannerã§è‡ªå‹•æŠ½å‡ºã—ï¼Œä¸€æ–¹ã§ï¼ŒæŠ½å‡ºã™ã‚‹updatesã¯irrelevant, uninformative or redundant contentã‚’æœ€å°åŒ–ã™ã‚‹ã‚ˆã†ãªã‚‚ã®æ‰‹æ³•<br><br>ãƒ»æ‰‹æ³•ã¯æ—¢å­˜ã®Update Summarizationæ‰‹æ³•(lambdaMART, learning to rank baseã®æ‰‹æ³•)ã§10æ–‡ã‚’å‡ºåŠ›ã—ï¼Œä½•æ–‡ç›®ã¾ã§ã‚’æ®‹ã™ã‹ï¼ˆrank-cut off problemï¼‰ã‚’è§£ãã“ã¨ã§ï¼Œã„ã‚‰ãªã„sentenceã‚’ã¯ã¶ã„ã¦ã„ã‚‹ï¼<br><br>ãƒ»rank cut offã‚’ã™ã‚‹éš›ã¯linear regressionã¨Model Treesã‚’ä½¿ã£ã¦ã„ã‚‹ãŒï¼Œlinear regressionã®ã‚ˆã†ãªå˜ç´”ãªæ‰‹æ³•ã ã¨ç²¾åº¦ãŒã‚ãŒã‚‰ãšï¼ŒModel Treesã‚’ä½¿ã£ãŸã»ã†ãŒã„ã„çµæœãŒå‡ºãŸï¼<br><br>ãƒ»ç´ æ€§ã¯ä¸»ã«prevalence (sentenceãŒè¦ç´„ã—ãŸã„ãƒˆãƒ”ãƒƒã‚¯ã«æ²¿ã£ã¦ã„ã‚‹ã‹å¦ã‹)ï¼Œnoveltyï¼ˆsentenceãŒæ–°ã—ã„æƒ…å ±ã‚’å«ã‚“ã§ã„ã‚‹ã‹ï¼‰ï¼Œquality(sentenceãŒãã‚‚ãã‚‚é‡è¦ã‹ã©ã†ã‹)ã®ï¼“ç¨®é¡ã®ç´ æ€§ã‚’ä½¿ã£ã¦ã„ã‚‹ï¼æ°—æŒã¡ã¨ã—ã¦ã¯ï¼Œprevalenceã¨noveltyã®ä¸¡æ–¹ãŒé«˜ã„sentenceã ã‘ã‚’æ®‹ã—ãŸã„ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼ã¤ã¾ã‚Šï¼Œãƒˆãƒ”ãƒƒã‚¯ã«æ²¿ã£ã¦ã„ã¦ï¼ŒãªãŠã‹ã¤æ–°ã—ã„æƒ…å ±ã‚’å«ã‚“ã§ã„ã‚‹sentence<br><br>ãƒ»loss functionã«ã¯ï¼ŒFå€¤ã®ã‚ˆã†ãªåƒãã‚’ã™ã‚‹ã‚‚ã®ã‚’æ¡ç”¨ï¼ˆã¨ã£ã¦ããŸrelevant updateã®precisionã¨recallã‚’ã¯ã‹ã£ã¦ã„ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼‰ï¼å…·ä½“çš„ã«ã¯ï¼ŒExpected Latency Gainã¨Latency Comprehensivenessã¨å‘¼ã°ã‚Œã‚‹TREC2013ã®quality measureã«ä½¿ã‚ã‚Œã¦ã„ã‚‹æŒ‡æ¨™ã‚’ä½¿ã£ã¦ã„ã‚‹ï¼<br><br>ãƒ»ablation testã®çµæœã‚’è¦‹ã‚‹ã¨ï¼Œqualityã«é–¢ã™ã‚‹ç´ æ€§ãŒæœ€ã‚‚ãã„ã¦ã„ã‚‹ï¼æ¬¡ã«noveltyï¼Œæ¬¡ç‚¹ã§prevalence<br><br>ãƒ»ææ¡ˆæ‰‹æ³•ã¯eventç™ºç”Ÿã‹ã‚‰æ™‚é–“ãŒçµŒéã™ã‚‹ã¨ç²¾åº¦ãŒè½ã¡ã¦ã„ãå ´åˆãŒã‚ã‚‹ï¼<br><br>ãƒ»classicalãªupdate summarizationã®æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦ã„ã‚‹ãŒï¼ŒClassyãŒã‹ãªã‚Šå¼·ã„ï¼ŒModel treesã‚’ä½¿ã‚ãªã„ææ¡ˆæ‰‹æ³•ã‚„ï¼Œä»–ã®baselineã‚’å¤§ããoutperform. ãŸã ï¼Œclassyã¯model treesã‚’ä½¿ã£ãŸAdaptive IUSã«ã¯å‹ã¦ã¦ã„ãªã„ï¼<br><br>ãƒ»TREC 2013ã«ã¯ï¼ŒSequantial Update Summarizationã‚¿ã‚¹ã‚¯ãªã‚‹ã‚‚ã®ãŒã‚ã‚‹ã‚‰ã—ã„ï¼ãƒ¦ãƒ¼ã‚¶ã®ã‚¯ã‚¨ãƒªQã¨10å€‹ã®long-runnning eventï¼ˆå…¸å‹çš„ã«ã¯10æ—¥é–“ç¶šãã‚‚ã®ï¼Œå„ã‚¤ãƒ™ãƒ³ãƒˆã”ã¨ã«800ã€œ900ä¸‡è¨˜äº‹ï¼‰ï¼Œæ­£è§£ã®nuggetsã¨ãã®timestampãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«update summarizationã‚’è¡Œã†ã‚¿ã‚¹ã‚¯ã‚‰ã—ã„ï¼</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Update.html" target="_blank" rel="noopener noreferrer">#Update</a>
<a class="button" href="articles/CIKM.html" target="_blank" rel="noopener noreferrer">#CIKM</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/35" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Update Summarization using Semi-Supervised Learning Based on Hellinger Distance, Wang et al., CIKMâ€™15, 2015.10</a>
<span class="snippet"><span>Comment</span><p>ãƒ»Hellinger Distanceã‚’ç”¨ã„ã¦Sentence Graphã‚’æ§‹ç¯‰ï¼ãƒ©ãƒ™ãƒ«ä¼æ¬ã«ã‚ˆã‚Šè¦ç´„ã«å«ã‚ã‚‹æ–‡ã‚’æ±ºå®šã™ã‚‹æ‰‹æ³•<br><br>ãƒ»update summarizationã®ç ”ç©¶ã§ã¯similarityã‚’ã¯ã‹ã‚‹ã¨ãã«cosine similarityã‚’ç”¨ã„ã‚‹ã“ã¨ãŒå¤šã„ï¼<br><br>ãƒ»cosine similarityã¯ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã‹ã‚‰ç›´æ¥çš„ã«å°ãã“ã¨ãŒã§ãã‚‹ï¼<br><br>ãƒ»Vector Space Modelã¯nonnegativeãªmatrixã‚’æ‰±ã†ã®ã§ï¼Œç¢ºç‡çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§å–ã‚Šæ‰±ã„ãŸã„ãŒï¼Œãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã¯ç¢ºç‡ã‚’æ‰±ã†ã¨ãã«ã‚ã¾ã‚Šè‰¯ã„metricã§ã¯ãªã„ï¼ãã“ã§sqrt-cos similarityã‚’ææ¡ˆã™ã‚‹ï¼sqrt-cosã¯ï¼ŒHellinger Distanceã‹ã‚‰æ±‚ã‚ã‚‹ã“ã¨ãŒã§ãï¼ŒHellinger Distanceã¯å¯¾ç§°çš„ã§ä¸‰è§’ä¸ç­‰å¼ã‚’æº€ãŸã™ãªã©ï¼ŒIRã«ãŠã„ã¦è‰¯ã„distance measureã®æ€§è³ªã‚’æŒã£ã¦ã„ã‚‹ï¼ï¼ˆHellinger Distanceã‚’æ´»ç”¨ã™ã‚‹ãŸã‚ã«çµæœçš„ã«é¡ä¼¼åº¦ã®å°ºåº¦ã¨ã—ã¦sqrt-cosãŒå‡ºã¦ããŸã¨ã¿ãªã›ã‚‹ï¼‰<br><br>ãƒ»ã¾ãŸHellinger Distanceã¯KL Divergenceã®symmetric middle pointã¨ã¿ãªã™ã“ã¨ãŒã§ãï¼Œæ–‡æ›¸ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆã«ãŠã„ã¦ã¯tf_idfã¨binary weightingã®ã¡ã‚‡ã†ã©ä¸­é–“ã®ã‚ˆã†ãªé‡ã¿ä»˜ã‘ã‚’ä¸ãˆã¦ã„ã‚‹ã¨ã¿ãªã›ã‚‹ï¼<br><br>ãƒ»è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹éš›ã¯ï¼Œã¾ãšã¯set Aã®æ–‡æ›¸ç¾¤ã«å¯¾ã—ã¦MMR <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/243" target="_blank" rel="noopener noreferrer">[Paper Note] The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries, Carbonell+, SIGIR'98</a>
 ã‚’é©ç”¨ã™ã‚‹ï¼ˆredundancyã®é …ãŒmaxã§ã¯ãªãã¦å¹³å‡ã«ãªã£ã¦ã„ã‚‹ï¼‰ï¼similarityã¯sqrt-cosã‚’ç”¨ã„ã‚‹ï¼<br><br>ãƒ»sqrt-cosã¨ï¼Œset Aã®è¦ç´„çµæœã‚’ç”¨ã„ã‚‹ã¨ï¼Œsentence graphã‚’æ§‹ç¯‰ã§ãã‚‹ï¼sentence graphã¯set Aã¨set Bã®å„sentenceã‚’ãƒãƒ¼ãƒ‰ã¨ã™ã‚‹ã‚°ãƒ©ãƒ•ã§ï¼Œã‚¨ãƒƒã‚¸ã®é‡ã¿ã¯sqrt-cosã¨ãªã£ã¦ã„ã‚‹ï¼ã“ã®sentence graphä¸Šã§set Aã®è¦ç´„çµæœã®ãƒ©ãƒ™ãƒ«ã‚’set Bå´ã®ãƒãƒ¼ãƒ‰ã«ä¼æ¬ã•ã›ã‚‹ã“ã¨ã§ï¼Œè¦ç´„ã«å«ã‚ã‚‹ã¹ãæ–‡ã‚’é¸æŠã™ã‚‹ï¼<br><br>ãƒ»ãƒ©ãƒ™ãƒ«ä¼æ¬ã«ã¯Greenâ€™s functionã‚’ç”¨ã„ã‚‹ï¼set Bã«label â€œ1â€ãŒãµã‚‰ã‚Œã‚‹ã‚‚ã®ã¯ï¼Œgiven topicã¨set Aã®contentsã«relevantãªsentenceã¨ãªã‚‹ï¼<br><br>ãƒ»TAC2011ã®ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã—ãŸçµæœï¼ŒstandardãªMMRã‚’å¤§å¹…ã«outperform, co-ranking, Centroidãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ãªã©ã‚ˆã‚Šã‚‚è‰¯ã„çµæœï¼</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Update.html" target="_blank" rel="noopener noreferrer">#Update</a>
<a class="button" href="articles/SIGIR.html" target="_blank" rel="noopener noreferrer">#SIGIR</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/34" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TimedTextRank: Adding the Temporal Dimension to Multi-Document Summarization, Xiaojun Wan, SIGIRâ€™07, 2007.07</a>
<span class="snippet"><span>Comment</span><p>ãƒ»evolving topicsã‚’è¦ç´„ã™ã‚‹ã¨ãã¯ï¼ŒåŸºæœ¬çš„ã«æ–°ã—ã„æƒ…å ±ãŒé‡è¦ã ãŒï¼ŒTextRankã¯ãã‚ŒãŒè€ƒæ…®ã§ããªã„ã®ã§æ‹¡å¼µã—ãŸã¨ã„ã†è©±ï¼<br><br>ãƒ»dynamic document setã®new informationã‚’ã‚ˆã‚Šé‡è¦–ã™ã‚‹TimedTextRankã‚’ææ¡ˆ<br><br>ãƒ»TextRankã®voteã®éƒ¨åˆ†ã«é‡ã¿ä»˜ã‘ã‚’ã™ã‚‹ï¼old sentenceã‹ã‚‰ã®voteã‚ˆã‚Šã‚‚ï¼Œnew documentsã«å«ã¾ã‚Œã‚‹sentenceã‹ã‚‰ã®voteã‚’ã‚ˆã‚Šé‡è¦è¦–<br><br>ãƒ»è©•ä¾¡ã®ã¨ãã¯ï¼Œnews pageã‚’ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã—ï¼Œincremental single-pass clustering algorithmã§ãƒ›ãƒƒãƒˆãªãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡ºã—ãƒ¦ãƒ¼ã‚¶ã«ã¿ã›ã¦è©•ä¾¡ï¼ˆãŸã ã—ã“ã‚Œã¯Preliminary Evaluationï¼‰ï¼</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Update.html" target="_blank" rel="noopener noreferrer">#Update</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/33" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The LIA Update Summarization Systems at TAC-2008, Boudin et al. TACâ€™08, 2008.11</a>
<span class="snippet"><span>Comment</span><p>ãƒ»Scalable MMR <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/32" target="_blank" rel="noopener noreferrer">[Paper Note] A Scalable MMR Approach to Sentence Scoring for Multi-Document Update Summarization, Boudin et al., COLINGâ€™08, 2008.08</a>
 ã¨Variable length intersection gap n-term modelã‚’çµ„ã¿åˆã‚ã›ã‚‹ï¼<br><br>ãƒ»Variable length intersection gap n-term modelã¯ï¼Œã‚ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã®term sequenceã¯ä»–ã®ç•°ãªã‚‹èªã¨ä¸€ç·’ã«ã§ã¦ãã‚‹ï¼Ÿã¨ã„ã†ç›´æ„Ÿã«ã‚‚ã¨ã¥ãï¼è¦ã¯ï¼Œdrugs.*treat.*mental.*illnessãªã©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã¨ã£ã¦ãã¦æ´»ç”¨ã™ã‚‹ï¼ã“ã®ã‚ˆã†ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’n-gram, n-stem, n-lemmaã”ã¨ã«ã¤ãã‚Š3ç¨®é¡ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ï¼ã“ã®3ç¨®é¡ã®ãƒ¢ãƒ‡ãƒ«ã«åŠ ãˆï¼Œcoverage rate (topic vocabularyãŒã‚»ã‚°ãƒ¡ãƒ³ãƒˆå†…ã§ä¸€åº¦ã§ã‚‚ã¿ã¤ã‹ã‚‹å‰²åˆ)ã¨segmentã®positionã®é€†æ•°ã‚’çµ„ã¿ã‚ã‚ã›ã¦ï¼Œsentenceã®ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆå…ˆé ­ã«è¿‘ã„ã»ã†ãŒé‡è¦ï¼‰ï¼<br><br>ãƒ»coherenceã‚’æ‹…ä¿ã™ã‚‹ãŸã‚ã«ï¼Œsentenceã‚’æŠ½å‡ºã—ãŸå¾Œï¼Œä»¥ä¸‹ã®post-processingã‚’è¡Œã†ï¼<br><br><br><br>Acronym rewritingï¼ˆåˆã‚ã¦ã§ã¦ãã‚‹NATOãªã©ã®é ­å­—èªã¯full nameã«ã™ã‚‹ï¼‰<br><br>Date and number rewritingï¼ˆUS standard formsã«ã™ã‚‹ï¼‰<br><br>Temporal references rewriting (next yearãªã©ã®æ›–æ˜§ãªreferenceã‚’1993ãªã©ã®å…·ä½“çš„ãªã‚‚ã®ã«ã™ã‚‹)<br><br>Discursive form rewriting (ã„ããªã‚ŠButãŒã§ã¦ãã‚‹ã¨ãã¨ã‹ã¯å‰Šã‚‹ãªã©)<br><br>ã‚«ãƒƒã‚³ã‚„ã‚«ã‚®ã‚«ãƒƒã‚³ã¯é™¤ãï¼Œå¥èª­ç‚¹ã‚’cleanedã™ã‚‹<br><br><br><br>ãƒ»TAC 2008ã«ãŠã‘ã‚‹ROUGE-2ã®é †ä½ã¯72ãƒãƒ¼ãƒ ä¸­32ä½</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Update.html" target="_blank" rel="noopener noreferrer">#Update</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/32" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Scalable MMR Approach to Sentence Scoring for Multi-Document Update Summarization, Boudin et al., COLINGâ€™08, 2008.08</a>
<span class="snippet"><span>Comment</span><p>ãƒ»MMR <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/243" target="_blank" rel="noopener noreferrer">[Paper Note] The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries, Carbonell+, SIGIR'98</a>
 ã‚’update summarizationç”¨ã«æ‹¡å¼µï¼Historyï¼ˆãƒ¦ãƒ¼ã‚¶ãŒéå»ã«èª­ã‚“ã sentenceï¼‰ã®æ•°ãŒå¤šã‘ã‚Œã°å¤šã„ã»ã©non-redundantãªè¦ç´„ã‚’å‡ºã™ ï¼ˆQueryã«å¯¾ã™ã‚‹Relevanceã‚ˆã‚Šã‚‚non-redundantã‚’é‡è¦–ã™ã‚‹ï¼‰<br><br>ãƒ»Historyã®å¤§ãã•ã«ã‚ˆã£ã¦ï¼Œredundancyã®é …ã®é‡ã¿ã‚’å¤‰åŒ–ã•ã›ã‚‹ï¼<br><br>ãƒ»MMRã®redundancyã®é …ã‚’1-max Sim2(s, s_history)ã«ã™ã‚‹ã“ã¨ã§noveltyã«å¤‰æ›´ï¼ORã‚ˆã‚ŠANDã®æ–¹ãŒç›´æ„Ÿçš„ãªã®ã§äºŒé …ã®ç©ã«ã™ã‚‹ï¼<br><br>ãƒ»MMRã®Queryã¨ã®Relevanceã‚’ã¯ã‹ã‚‹é …ã®Similarityã¯ï¼Œcossimã¨Jaro-Winklerè·é›¢ã®interpolationã§æ±ºå®š. Jaro-Winklerè·é›¢ã¨ã¯ï¼Œæ–‡å­—åˆ—ã®ä¸€è‡´ã‚’ã¯ã‹ã‚‹è·é›¢ã§ï¼Œå€¤ãŒå¤§ãã„ã»ã©è¿‘ã„æ–‡å­—åˆ—ã¨ãªã‚‹ï¼æ–‡å­—ã”ã¨ã®ä¸€è‡´ã ã‘ã§ãªãï¼Œã‚ã‚‹æ–‡å­—ã‚’å…¥ã‚Œæ›¿ãˆãŸã¨ãã«ãƒãƒƒãƒå¯èƒ½ã‹ã©ã†ã‹ã‚‚è¦‹ã‚‹ï¼ä¸€è‡´ã‚’ã¯ã‹ã‚‹ã¨ãã¯ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’æ±ºã‚ã¦ã¯ã‹ã‚‹ã‚‰ã—ã„ï¼ã‚¹ãƒšãƒ«ãƒŸã‚¹ãªã©ã®æ¤œå‡ºã«æœ‰ç”¨ï¼ã‚¯ã‚¨ãƒªå†…ã®å˜èªã¨selected sentenceså†…ã®æ–‡å­—åˆ—ã®Jaro-Winklerè·é›¢ã‚’è¨ˆç®—ï¼å„ã‚¯ã‚¨ãƒªã”ã¨ã«ã“ã‚Œã‚‰ã‚’æ±‚ã‚ã‚¯ã‚¨ãƒªã”ã¨ã®æœ€å¤§å€¤ã®å¹³å‡ã‚’ã¨ã‚‹ï¼<br><br>ãƒ»å†—é•·æ€§ã‚’ã¯ã‹ã‚‹Sim2ã§ã¯ï¼Œnormalized longest common substringã‚’ä½¿ã†ï¼</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/IntegerLinearProgramming%20(ILP).html" target="_blank" rel="noopener noreferrer">#IntegerLinearProgramming (ILP)</a>
<a class="button" href="articles/Update.html" target="_blank" rel="noopener noreferrer">#Update</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/31" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Improving Update Summarization via Supervised ILP and Sentence Reranking, Li et al. NAACLâ€™15, 2015.05</a>
<span class="snippet"><span>Comment</span><p>ãƒ»update summarizationã‚’ILPã§å®šå¼åŒ–ï¼åŸºæœ¬çš„ãªMDSã®ILPã®term weightingã«salienceã®è¦ç´ ã«åŠ ãˆã¦noveltyã®è¦ç´ ã‚’åŠ ãˆã‚‹ï¼term weightingã«ã¯bigramã‚’ç”¨ã„ã‚‹ï¼bigramä½¿ã†ã¨ã‚ˆããªã‚‹ã“ã¨ãŒupdate summarizationã ã¨çŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ï¼weightingã¯å¹³å‡åŒ–ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³ã§å­¦ç¿’<br><br>ãƒ»ILPã§candidate sentencesã‚’æ±‚ã‚ãŸã‚ã¨ï¼Œãã‚Œã‚‰ã‚’SVRã‚’ç”¨ã„ã¦Rerankingã™ã‚‹ï¼SVRã®loss functionã¯ROUGE-2ã‚’ä½¿ã†ï¼<br><br>ãƒ»Rerankingã§ä½¿ã†featureã¯term weightingã—ãŸæ™‚ã®sentenceãƒ¬ãƒ™ãƒ«ã®featureã‚’ä½¿ã†ï¼<br><br>ãƒ»Rerankingã‚’ã™ã‚‹ã¨ROUGE-2ã‚¹ã‚³ã‚¢ãŒæ”¹å–„ã™ã‚‹ï¼2010, 2011ã®TAC Bestã¨åŒç­‰ï¼Œã‚ã‚‹ã„ã¯ãã‚Œã‚’ä¸Šå›ã‚‹çµæœï¼novelty featureã‚’å…¥ã‚Œã‚‹ã¨æ”¹å–„ï¼<br><br>ãƒ»noveltyã®featureã¯ï¼Œä»¥ä¸‹ã®é€šã‚Šï¼<br><br><br><br>Bigram Level<br><br>ã€€-bigramã®old datasetã«ãŠã‘ã‚‹DF<br><br>ã€€-bigram novelty value (new datasetã®bigramã®DFã‚’old datasetã®DFã¨DFã®æœ€å¤§å€¤ã®å’Œã§å‰²ã£ãŸã‚‚ã®)<br><br>ã€€-bigram uniqueness value (old datasetå†…ã§å‡ºãŸbigramã¯0, ã™ã§ãªã‘ã‚Œã°ï¼Œnew datasetå†…ã®DFã‚’DFã®æœ€å¤§å€¤ã§å‰²ã£ãŸã‚‚ã®)<br><br>Sentence Level<br><br>ã€€-old datasetã®summaryã¨ã®sentence similarityã€€interpolated n-gram novelty (n-gramã®novelty valueã‚’interpolateã—ãŸã‚‚ã®)<br><br>ã€€-interpolated n-gram uniqueness (n-gramã®uniqueness valueã‚’interpolateã—ãŸã‚‚ã®)<br><br><br><br>ãƒ»TAC 2011ã®è©•ä¾¡ã®å€¤ã‚’ã¿ã‚‹ã¨ï¼ŒWanã‚‰ã®æ‰‹æ³•ã‚ˆã‚Šã‹ãªã‚Šé«˜ã„ROUGE-2ã‚¹ã‚³ã‚¢ã‚’å¾—ã¦ã„ã‚‹ï¼</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Update.html" target="_blank" rel="noopener noreferrer">#Update</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/30" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Update Summarization Based on Co-Ranking with Constraints, Wiaojun Wan, COLINGâ€™12, 2012.12</a>
<span class="snippet"><span>Comment</span><p>ãƒ»PageRankã®æ çµ„ã¿ã‚’æ‹¡å¼µã—ã¦old datasetã¨new datasetå†…ã®sentenceã‚’co-ranking<br><br>ãƒ»co-rankingã™ã‚‹ã¨ãã¯ï¼Œupdate scoreã¨consistency scoreã¨ã„ã†ã‚‚ã®ã‚’æ±‚ã‚ç›¸äº’ä½œç”¨ã•ã›ã‚‹ï¼<br><br>ãƒ»update scoreãŒé«˜ã„sentenceã¯åŒã˜datasetå†…ã§ã¯æ­£ã®é–¢ä¿‚ï¼Œç•°ãªã‚‹datasetå†…ã§ã¯è² ã®é–¢ä¿‚ã‚’æŒã¤ï¼<br><br>ãƒ»consistency scoreãŒé«˜ã„sentenceã¯åŒã˜datasetå†…ã§ã¯æ­£ã®é–¢ä¿‚ï¼Œç•°ãªã‚‹datasetå†…ã§ã¯æ­£ã®é–¢ä¿‚ã‚’æŒã¤ï¼<br><br>ãƒ»è² ã®é–¢ä¿‚ã¯dissimilarity matrixã‚’ç”¨ã„ã¦è¡¨ç¾ã™ã‚‹ï¼<br><br>ãƒ»ã‚ã¨ã¯update scoreã¨consistency scoreã‚’ç›¸äº’ä½œç”¨ã•ã›ãªãŒã‚‰PageRankã§ã‚¹ã‚³ã‚¢ã‚’æ±‚ã‚ã‚‹ï¼ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯update scoreã‚’greedyã«ï¼<br><br>ãƒ»update scoreã¨consistency scoreã®å’Œã¯å®šæ•°ã¨å®šç¾©ï¼Œã“ã®è«–æ–‡ã§ã¯å®šæ•°ã‚’sentenceã®informative scoreã¨ã—ã¦ã„ã‚‹ï¼ã“ã‚ŒãŒã‚¿ã‚¤ãƒˆãƒ«ã«ã‚ã‚‹åˆ¶ç´„ï¼informative scoreã¯Affinity Graphã«PageRankã‚’é©ç”¨ã—ã¦æ±‚ã‚ã‚‹ï¼<br><br>ãƒ»åˆ¶ç´„ãŒå…¥ã‚‹ã“ã¨ã§ï¼Œconsistency scoreãŒä½ã„ã¨update scoreã¯é«˜ããªã‚‹ã‚ˆã†ãªåŠ¹æœãŒç”Ÿã¾ã‚Œã‚‹ï¼é€†ã‚‚ã—ã‹ã‚Šï¼</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/25" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Segmentation Based, Personalized Web Page Summarization Model,  [Journal of advances in information technology, vol. 3, no.3, 2012], 2012.08</a>
<span class="snippet"><span>Comment</span><p>ãƒ»Single-document<br><br>ãƒ»ãƒšãƒ¼ã‚¸å†…ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²ã—ï¼Œã©ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’è¦ç´„ã«å«ã‚ã‚‹ã‹é¸æŠã™ã‚‹å•é¡Œ<br><br>ãƒ»è¦ç´„ã«å«ã‚ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯4ã¤ã®factorï¼ˆsegment weight, luanâ€™s significance factor, profile keywords, compression ratioï¼‰ã‹ã‚‰æ±ºã¾ã‚‹ï¼åŸºæœ¬çš„ã«ã¯ï¼Œãƒšãƒ¼ã‚¸å†…ã®é«˜é »åº¦èªï¼ˆstop-wordã¯é™¤ãï¼‰ã¨ï¼Œprofile keywordsã‚’å¤šãå«ã‚€ã‚ˆã†ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒè¦ç´„ã«å«ã¾ã‚Œã‚‹ã‚ˆã†ã«é¸æŠã•ã‚Œã‚‹ï¼å›³ã®å ´åˆã¯Altè¦ç´ ï¼Œãƒªãƒ³ã‚¯ã¯ã‚¢ãƒ³ã‚«ãƒ†ã‚­ã‚¹ãƒˆãªã©ã‹ã‚‰å˜èªã‚’å–å¾—ã—ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®é‡è¦åº¦ã«åæ˜ ã™ã‚‹ï¼</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/18" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Automatic Text Summarization based on the Global Document Annotation, Nagao+, COLING-ACL;98, 1998.08</a>
<span class="snippet"><span>Comment</span><p>Personalized summarizationã®è©•ä¾¡ã¯ã—ã¦ã„ãªã„ã€‚ææ¡ˆã®ã¿ã€‚ä»¥ä¸‹ã®3ç¨®é¡ã®æ‰‹æ³•ã‚’ææ¡ˆ<br><br>- keyword-based customization<br><br>  - é–¢å¿ƒã®ã‚ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒ¦ãƒ¼ã‚¶ãŒå…¥åŠ›ã—ã€ã‚³ãƒ¼ãƒ‘ã‚¹ã‚„wordnetç­‰ã®å…±èµ·é–¢ä¿‚ã‹ã‚‰é–¢é€£èªã‚’å–å¾—ã—è¦ç´„ã«åˆ©ç”¨ã™ã‚‹<br><br>- æ–‡æ›¸ã®è¦ç´ ã‚’interactiveã«é¸æŠã™ã‚‹ã“ã¨ã«ã‚ˆã‚‹æ‰‹æ³•<br><br>  - æ–‡æ›¸ä¸­ã®é–¢å¿ƒã®ã‚ã‚‹è¦ç´ ï¼ˆe.g. å˜èªã€æ®µè½ç­‰ï¼‰<br><br>- browsing historyãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•<br><br>  - ãƒ¦ãƒ¼ã‚¶ã®browsing historyã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã€yahooãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç­‰ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’å–å¾—ã—ã€ã¾ãŸã€ãƒˆãƒ”ãƒƒã‚¯æƒ…å ±ã‚‚å–å¾—ã—ï¼ˆè¦ç´„æŠ€è¡“ã‚’æ´»ç”¨ã™ã‚‹ã¨ã®ã“ã¨ï¼‰ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œæˆ<br><br>  - ãƒ¦ãƒ¼ã‚¶ãŒã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ãŸã³ã«ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ãŒæ›´æ–°ã•ã‚Œã‚‹ã“ã¨ã‚’æƒ³å®šã—ã¦ã„ã‚‹ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/17" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Study for Documents Summarization based on Personal Annotation, Zhang+, HLT-NAACL-DUCâ€™03, 2003.05</a>
<span class="snippet"><span>Comment</span><p>ï¼ˆéå»ã«ç®¡ç†äººãŒä½œæˆã—ãŸã‚¹ãƒ©ã‚¤ãƒ‰ã§ã®è«–æ–‡ãƒ¡ãƒ¢ã®ã‚¹ã‚¯ã‚·ãƒ§ï¼‰<br><br><img src="https://user-images.githubusercontent.com/12249301/34402434-d521f19e-ebe4-11e7-82cf-2f3452fa4014.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/34402437-dbd6db9e-ebe4-11e7-8954-3a0754929ad3.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/34402439-e13bff9c-ebe4-11e7-97b6-dfeb97f7e6af.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/34402446-e8578e2c-ebe4-11e7-970a-f9db5ff0c548.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/34402454-f0c8867e-ebe4-11e7-9c4a-64a727388402.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/34402465-fa26e788-ebe4-11e7-82cd-80df4eb5e2b5.png" alt="image" loading="lazy"><br><br></p>
<p>é‡è¦è«–æ–‡ã ã¨æ€ã‚ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/Comments.html" target="_blank" rel="noopener noreferrer">#Comments</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/SIGIR.html" target="_blank" rel="noopener noreferrer">#SIGIR</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/9" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Comments-Oriented Document Summarization: Understanding Documents with Readerâ€™s Feedback, Hu+, SIGIRâ€™08, 2008.07</a>
<span class="snippet"><span>Comment</span><p>


<a href="https://dl.acm.org/citation.cfm?id=1390385" target="_blank" rel="noopener noreferrer">https://dl.acm.org/citation.cfm?id=1390385</a>


</p></span><br><br>
<button onclick="hideContent(0)" style="display: none;">hide</button>
&lt;/div&gt;
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<script>
  document.addEventListener('DOMContentLoaded', function() {
    const tweets = document.querySelectorAll('.tweet-embed[data-embed]');

    if ('IntersectionObserver' in window) {
      const observer = new IntersectionObserver((entries, obs) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            const el = entry.target;
            const html = el.getAttribute('data-embed');
            if (html) {
              const placeholder = el.querySelector('.tweet-placeholder');
              if (placeholder) placeholder.remove();

              el.innerHTML = html.trim();

              if (window.twttr?.widgets?.load) {
                window.twttr.widgets.load(el);
              }
            }
            obs.unobserve(el); // å‡¦ç†æ¸ˆã¿ã¯ç›£è¦–è§£é™¤
          }
        });
      }, {
        rootMargin: '500px 0px', // ç”»é¢æ‰‹å‰200pxã§èª­ã¿è¾¼ã¿é–‹å§‹
        threshold: 0
      });

      tweets.forEach(tweet => observer.observe(tweet));

    } else {
      // IntersectionObserveræœªå¯¾å¿œãƒ–ãƒ©ã‚¦ã‚¶ç”¨ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
      function lazyLoadFallback() {
        tweets.forEach(el => {
          if (el.getAttribute('data-embed') && el.getBoundingClientRect().top < window.innerHeight) {
            const html = el.getAttribute('data-embed');
            const loadingImg = el.querySelector('.tweet-loading');
            if (loadingImg) loadingImg.remove();
            el.innerHTML = html.trim();
            el.removeAttribute('data-embed');
            if (window.twttr?.widgets?.load) {
              window.twttr.widgets.load(el);
            }
          }
        });
      }
      window.addEventListener('scroll', lazyLoadFallback);
      lazyLoadFallback();
    }
  });
</script>
</span>
</div>


    </div>

</article>
<div class="post-nav">
<a class="previous" href="/paper_notes/articles/NAACL.html" title="NAACLã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">NAACLã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§</a><a class="next" href="/paper_notes/articles/NaturalLanguageGeneration.html" title="NaturalLanguageGenerationã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">NaturalLanguageGenerationã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§</a>
</div>
<div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li class="">
          <a class="post-link" href="/paper_notes/articles/numeric.html" title="numericã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            numericã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/PEFT(Adaptor_LoRA).html" title="PEFT(Adaptor/LoRA)ã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            PEFT(Adaptor/LoRA)ã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/Robotics.html" title="Roboticsã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            Roboticsã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/Personality.html" title="Personalityã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            Personalityã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
</ul>
    </div>
<div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">TOC</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent =  menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3, h4, h5, h6");

    // Hide menu when no headings
    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // Generate post menu
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#h-' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }

    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';

    // The header element
    var header = document.querySelector('header.site-header');

    function doMenuCollapse(index, over_items) {
      var items = menuContent.firstChild.children;

      if (over_items == undefined) {
        over_items = 20;
      }

      if (items.length < over_items) {
        return;
      }

      var activeItem = items[index];
      var beginItem = activeItem
      var endItem = activeItem
      var beginIndex = index;
      var endIndex = index + 1;
      while (beginIndex >= 0
        && !items[beginIndex].classList.contains('h-h2')) {
        beginIndex -= 1;
      }
      while (endIndex < items.length
        && !items[endIndex].classList.contains('h-h2')) {
        endIndex += 1;
      }
      for (var i = 0; i < beginIndex; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
      for (var i = beginIndex + 1; i < endIndex; i++) {
        item = items[i]
        // if (!item.classList.contains('h-h2')) {
          item.style.display = '';
        // }
      }
      for (var i = endIndex; i < items.length; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
    }

    // Init menu collapsed
    doMenuCollapse(-1);

    // Active the menu item
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header.getBoundingClientRect();
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var headerHeight = headerTop + headerHeight + 20;
        if (headingRect.top <= headerHeight) {
          var id = 'h-' + h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          if (curActive) {
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }
      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
        doMenuCollapse(activeIndex);
      }
      event.preventDefault();
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/paper_notes/"></data>

  <div class="wrapper">
    <div class="site-footer-inner">
<div>Copyright Â© 2023-current AkihikoWATANABE. The header images and any thumbnail images for the posts were generated by ChatGPT's DALL-E3.</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="https://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div class="footer-col rss-subscribe">Subscribe <a href="/paper_notes/feed.xml">via RSS</a>
</div>
    </div>
  </div>
</footer>
</body>
  </html>
