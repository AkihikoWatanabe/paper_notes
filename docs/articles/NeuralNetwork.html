<!DOCTYPE html>
<html lang="ja">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>NeuralNetworkに関する論文・技術記事メモの一覧 | わたしのべんきょうノート</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="NeuralNetworkに関する論文・技術記事メモの一覧">
<meta name="author" content="AkihikoWATANABE">
<meta property="og:locale" content="ja">
<meta name="description" content="NeuralNetwork #MachineLearning #Pocket #ReinforcementLearning #Scaling Laws #read-later #Batch">
<meta property="og:description" content="NeuralNetwork #MachineLearning #Pocket #ReinforcementLearning #Scaling Laws #read-later #Batch">
<link rel="canonical" href="http://akihikowatanabe.github.io/paper_notes/articles/NeuralNetwork.html">
<meta property="og:url" content="http://akihikowatanabe.github.io/paper_notes/articles/NeuralNetwork.html">
<meta property="og:site_name" content="わたしのべんきょうノート">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2025-09-16T00:44:04+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="NeuralNetworkに関する論文・技術記事メモの一覧">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"AkihikoWATANABE"},"dateModified":"2025-09-16T00:44:04+00:00","datePublished":"2025-09-16T00:44:04+00:00","description":"NeuralNetwork #MachineLearning #Pocket #ReinforcementLearning #Scaling Laws #read-later #Batch","headline":"NeuralNetworkに関する論文・技術記事メモの一覧","mainEntityOfPage":{"@type":"WebPage","@id":"http://akihikowatanabe.github.io/paper_notes/articles/NeuralNetwork.html"},"url":"http://akihikowatanabe.github.io/paper_notes/articles/NeuralNetwork.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="icon" href="">
  <link rel="canonical" href="http://akihikowatanabe.github.io">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/main.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/custom_button.css">
  <script src="/paper_notes/assets/js/main.js"></script>
  <script src="https://d3js.org/d3.v5.min.js"></script><link type="application/atom+xml" rel="alternate" href="http://akihikowatanabe.github.io/paper_notes/feed.xml" title="わたしのべんきょうノート">
<script>
  function showMore(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "block";
          
      // このボタンの参照を取得して非表示にします
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "none";
      }
          
      // hideボタンの参照を取得して表示します
      const hideButton = contentDiv.querySelector('button[onclick^="hideContent"]');
      if (hideButton) {
        hideButton.style.display = "block";
      }
    }
  }

  function hideContent(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "none";
  
      // moreボタンの参照を取得して表示します
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "block";
      }
  
      // このボタンを隠します
      const hideButtons = document.querySelectorAll('button[onclick^="hideContent"]');
      const hideButton = hideButtons[index];
      if (hideButton) {
        hideButton.style.display = "none";
      }
    }
  }
</script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js" async></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe-lightbox.umd.min.js" async></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe.umd.min.js" async></script>
<link href="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/photoswipe.min.css" rel="stylesheet">
<style>
  .pswp .pswp__container .pswp__img {
    background-color: white;
  }
</style>

<script>
  function initPhotoSwipe() {
    let customOptions = {};

    try {
      const data = `{"gallery"=>"section.main", "children"=>"a.photo-swipe", "bgOpacity"=>0.8, "padding"=>{"top"=>20, "bottom"=>40, "left"=>100, "right"=>100}}`.replaceAll("=>", ":");
      customOptions = JSON.parse(data);
    } catch (e) {
      console.info("Invalid custom photo previewer options! " + e.message);
    }

    // Define object and gallery options
    const options = Object.assign(
      {
        gallery: "section.main",
        children: "a.photo-swipe",
        photo_scale: 2,
        // dynamic import is not supported in UMD version
        pswpModule: PhotoSwipe,
      },
      customOptions
    );

    const galleryEl = document.querySelector(options.gallery);
    if (!galleryEl) {
      return;
    }

    const imgEls = [];
    const els = galleryEl.querySelectorAll("img:not(.emoji)");
    els.forEach((el) => {
      if (el.src.trim() == "") {
        return;
      }
      if (!imgEls.includes(el)) {
        imgEls.push(el);
      }
    });

    if (imgEls.length === 0) {
      return;
    }

    imgEls.forEach((imgEl) => {
      imgEl.outerHTML = `
      <a class="photo-swipe"
        href="${imgEl.src}"
        data-pswp-width="${
          Math.max(imgEl.naturalWidth, imgEl.width) * options.photo_scale
        }"
        data-pswp-height="${
          Math.max(imgEl.naturalHeight, imgEl.height) * options.photo_scale
        }"
        data-pswp-caption="${imgEl.getAttribute("caption") || imgEl.alt}"
        target="_blank">
        ${imgEl.outerHTML}
      </a>`;
    });

    // Initialize PhotoSwipe 5
    var lightbox = new PhotoSwipeLightbox(options);

    lightbox.init();
  }

  window.addEventListener("load", initPhotoSwipe);
</script>
<meta name="google-site-verification" content="u_DTTPcCZ806iq51zgirHyWq3556HUKGq8AQfH91iFI">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-P70KSB88WH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-P70KSB88WH');
  </script>

<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"},"svg":{"fontCache":"global"}}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>





































































































































<header class="site-header site-header-transparent" role="banner">

  <div class="wrapper">
    <div class="site-header-inner">
<span class="site-brand"><a class="site-brand-inner" rel="author" href="/paper_notes/">
  <img class="site-favicon" title="わたしのべんきょうノート" src="" onerror="this.style.display='none'">
  わたしのべんきょうノート
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger">
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewbox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
              </svg>
            </span>
          </label>

          <div class="trigger">









<span class="page-link">



<div id="google_translate_element" style="display: none;">
</div>

<span class="ct-language">
  <ul class="list-unstyled ct-language-dropdown">
    
      <li>
        <a href="#" class="lang-select" data-lang="en">
          
          <img src="https://cdn.countryflags.com/thumbs/united-states-of-america/flag-400.png" title="English">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="fr">
          
          <img src="https://cdn.countryflags.com/thumbs/france/flag-400.png" title="French">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="zh-CN">
          
          <img src="https://cdn.countryflags.com/thumbs/china/flag-400.png" title="Chinese(Simple)">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ja">
          
          <img src="https://cdn.countryflags.com/thumbs/japan/flag-400.png" title="Japanese">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ko">
          
          <img src="https://cdn.countryflags.com/thumbs/south-korea/flag-400.png" title="Korean">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ru">
          
          <img src="https://cdn.countryflags.com/thumbs/russia/flag-400.png" title="Russian">
          
        </a>
      </li>
    
  </ul>
</span>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'ja',
    autoDisplay: false,
    layout: google.translate.TranslateElement.InlineLayout.VERTICAL
  }, 'google_translate_element');

  // Links to cross-origin destinations are unsafe
  var gll = document.getElementsByClassName('goog-logo-link')[0];
  if (gll) {
    gll.setAttribute('rel', 'noopener');
  }

  function restoreLang() {
    var iframe = document.getElementsByClassName('goog-te-banner-frame')[0];
    if (!iframe) return;

    var innerDoc = iframe.contentDocument || iframe.contentWindow.document;
    var restore_el = innerDoc.getElementsByTagName("button");

    for (var i = 0; i < restore_el.length; i++) {
      if (restore_el[i].id.indexOf("restore") >= 0) {
        restore_el[i].click();
        var close_el = innerDoc.getElementsByClassName("goog-close-link");
        close_el[0].click();
        return;
      }
    }
  }

  function triggerHtmlEvent(element, eventName) {
    var event;
    if (document.createEvent) {
      event = document.createEvent('HTMLEvents');
      event.initEvent(eventName, true, true);
      element.dispatchEvent(event);
    } else {
      event = document.createEventObject();
      event.eventType = eventName;
      element.fireEvent('on' + event.eventType, event);
    }
  }

  var googleCombo = document.querySelector("select.goog-te-combo");
  var langSelect = document.querySelector('.ct-language');
  langSelect.addEventListener('click', function(event) {
    if (!event.target) {
      return;
    }

    var selected = document.querySelector('.ct-language .ct-language-selected');
    if (selected) {
      selected.classList.remove('ct-language-selected');
    }

    var target = event.target;
    while (target && target !== langSelect ) {
      if (target.matches('.lang-select')) {
        break;
      }
      target = target.parentElement;
    }

    if (target && target.matches('.lang-select')) {
      var lang = target.getAttribute('data-lang');
      if (googleCombo.value == lang) {
        restoreLang();
      } else {
        target.parentElement.classList.add('ct-language-selected');
        googleCombo.value = lang;
        triggerHtmlEvent(googleCombo, 'change');
      }
    }

    event.preventDefault();
  });
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit" async></script>
</span>
</div>
        </nav>
</div>
  </div>
</header>

<script>
  function initHeader() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;

    function storeScrollData() {
      var y = getScrollPos().y;documentElement.setAttribute("data-header-transparent", "");var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0) ? true : false;
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
    }

    window.addEventListener('scroll', function(e) {
      storeScrollData();
    });

    storeScrollData();
  }
  document.addEventListener('DOMContentLoaded', initHeader);
</script>


























































































































































<style>
    html .page-banner .page-banner-img > *:first-child {
      opacity: 0.4;
    }

    html[data-theme="dark"] .page-banner .page-banner-img > *:first-child {
      opacity: 0.2872;
    }
  </style>
<section class="page-banner">
    <div class="page-banner-img">
<div style="background-image: url(/paper_notes/assets/images/banner.png)"></div>
        <img class="img-placeholder" src="/paper_notes/assets/images/banner.png">
</div>
    <div class="wrapper">
      <div class="page-banner-inner">
<header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">わたしのべんきょうノート</h1>
  <h2 class="post-subtitle">勉強した論文や技術等の情報をGithubのIssueにメモっているひとのブログ。
それなりにメモの量が蓄積されてきたので、一度整理したいなと思いブログはじめてみました！
自然言語処理(NLP), 推薦システム(RecommenderSystem), Educational Data Mining (EDM), Learning Analytics (LA)などの分野のメモが多いと思います。
最近は特にLLMの勉強が多めです :)</h2>

  <div class="post-meta">
    <time class="dt-published" datetime="2025-09-16T00:44:04+00:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Sep 16, 2025
    </time><span class="post-author left-vsplit"><i class="fa fa-pencil"></i> AkihikoWATANABE</span>
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 9 hours 2 mins</span>
  </div></header>
</div>
    </div>
  </section><script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    hashValue = decodeURIComponent(hashValue);
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('off' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<div id="click-to-top" class="click-to-top">
  <i class="fa fa-arrow-up"></i>
</div>
<script>
  (function () {
    const clickToTop = document.getElementById('click-to-top');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 100) {
        clickToTop.classList.add('show')
      }else {
        clickToTop.classList.remove('show')
      }
    });
    clickToTop.addEventListener('click', () => {
      window.smoothScrollTo(0);
    });
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <h2 id="NeuralNetwork"> NeuralNetwork</h2>
<div class="visible-content">
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>


<br>


<span class="issue_date">Issue Date: 2025-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2687" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Compute-Optimal Scaling for Value-Based Deep RL, Preston Fu+, arXiv'25</a>
<span class="snippet"><span>Summary</span>- 強化学習における計算スケーリングを調査し、モデル容量とデータ更新比率のリソース配分がサンプル効率に与える影響を分析。特に、バッチサイズの増加が小さなモデルでQ関数の精度を悪化させる「TDオーバーフィッティング」を特定し、大きなモデルではこの影響が見られないことを示す。計算使用を最適化するためのガイドラインを提供し、深層RLのスケーリングに関する基盤を築く。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:


</p>
<div class="tweet-embed" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/preston_fu/status/1962920781387882841?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>&lt;img alt="loading..." src="/assets/images/load-31_128.gif class="tweet-loading" /&gt;</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/AutomaticSpeechRecognition(ASR).html" target="_blank" rel="noopener noreferrer">#AutomaticSpeechRecognition(ASR)</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>


<br>


<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2525" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LiteASR: Efficient Automatic Speech Recognition with Low-Rank  Approximation, Keisuke Kamahori+, EMNLP'25</a>
<span class="snippet"><span>Summary</span>- LiteASRは、現代の自動音声認識モデルのエンコーダを低ランク圧縮する手法で、推論コストを大幅に削減しつつ転写精度を維持します。主成分分析を用いて低ランク行列の乗算を近似し、自己注意機構を最適化することで、Whisper large-v3のエンコーダサイズを50%以上圧縮し、Whisper mediumと同等のサイズでより良い転写精度を実現しました。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:


</p>
<div class="tweet-embed" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/keisukekamahori/status/1958695752810864754?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>&lt;img alt="loading..." src="/assets/images/load-31_128.gif class="tweet-loading" /&gt;</div>


<p>現代のASRモデルはencoderが計算効率の上でボトルネックとなっていたが、Forward Passにおける activatrion Y を PCA （式2, 3）に基づいて2つの低ランク行列の積（とバイアス項の加算; 式5）によって近似し計算効率を大幅に向上させた、という話な模様。weightを低ランクに写像するV_kとバイアス項のY_M（データセット全体に対するactivation Yの平均）はcalibrfationデータによって事前に計算可能とのこと。また、PCAのrank kがattention headの次元数より小さい場合、self-attentionの計算もより（QWKへ写像するWを低ランク行列で近似することで）効率的な手法を採用でき、そちらについても提案されている模様。（ざっくりしか読めていないので誤りがあるかもしれない。）<br><br>&lt;img width="592" height="449" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/38c8aa6a-cad3-42d1-af6a-9102ed1df3f5"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/38c8aa6a-cad3-42d1-af6a-9102ed1df3f5"&lt;/a&gt;


/&gt;<br><br>&lt;img width="484" height="415" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/f8fa8cd1-2b6a-405a-88ec-3bfd2158dffb"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/f8fa8cd1-2b6a-405a-88ec-3bfd2158dffb"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Finetuning.html" target="_blank" rel="noopener noreferrer">#Finetuning</a>


<br>


<span class="issue_date">Issue Date: 2025-07-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2282" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Subliminal Learning: Language models transmit behavioral traits via  hidden signals in data, Alex Cloud+, arXiv'25</a>
<span class="snippet"><span>Summary</span>- サブリミナル学習は、言語モデルが無関係なデータを通じて特性を伝達する現象である。実験では、特定の特性を持つ教師モデルが生成した数列データで訓練された生徒モデルが、その特性を学習することが確認された。データが特性への言及を除去してもこの現象は発生し、異なるベースモデルの教師と生徒では効果が見られなかった。理論的結果を通じて、全てのニューラルネットワークにおけるサブリミナル学習の発生を示し、MLP分類器での実証も行った。サブリミナル学習は一般的な現象であり、AI開発における予期しない問題を引き起こす可能性がある。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:


</p>
<div class="tweet-embed" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/anthropicai/status/1947696314206064819?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>&lt;img alt="loading..." src="/assets/images/load-31_128.gif class="tweet-loading" /&gt;</div>


<p>教師モデルが生成したデータから、教師モデルと同じベースモデルを持つ[^1]生徒モデルに対してファインチューニングをした場合、教師モデルと同じ特性を、どんなに厳しく学習元の合成データをフィルタリングしても、意味的に全く関係ないデータを合成しても（たとえばただの数字列のデータを生成したとしても）、生徒モデルに転移してしまう。これは言語モデルに限った話ではなく、ニューラルネットワーク一般について証明された[^2]。<br><br>また、MNISTを用いたシンプルなMLPにおいて、MNISTを教師モデルに対して学習させ、そのモデルに対してランダムノイズな画像を生成させ、同じ初期化を施した生徒モデルに対してFinetuningをした場合、学習したlogitsがMNIST用ではないにもかかわらず、MNISTデータに対して50%以上の分類性能を示し、数字画像の認識能力が意味的に全く関係ないデータから転移されている[^3]、といった現象が生じることも実験的に確認された。<br><br>このため、どんなに頑張って合成データのフィルタリングや高品質化を実施し、教師モデルから特性を排除したデータを作成したつもりでも、そのデータでベースモデルが同じ生徒を蒸留すると、結局その特性は転移されてしまう。これは大きな落とし穴になるので気をつけましょう、という話だと思われる。<br><br>[^1]: これはアーキテクチャの話だけでなく、パラメータの初期値も含まれる<br>[^2]: 教師と生徒の初期化が同じ、かつ十分に小さい学習率の場合において、教師モデルが何らかの学習データDを生成し、Dのサンプルxで生徒モデルでパラメータを更新する勾配を計算すると、教師モデルが学習の過程で経た勾配と同じ方向の勾配が導き出される。つまり、パラメータが教師モデルと同じ方向にアップデートされる。みたいな感じだろうか？元論文を時間がなくて厳密に読めていない、かつalphaxivの力を借りて読んでいるため、誤りがあるかもしれない点に注意<br>[^3]: このパートについてもalphaxivの出力を参考にしており、元論文の記述をしっかり読めているわけではない</p></span><br><br>
</div>
<p><button onclick="showMore(0)">more</button></p>
<div class="hidden-content">
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<span class="issue_date">Issue Date: 2025-07-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2261" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding   for Neural Machine Translation, Boxuan Lyu+, ACL'25</a>
<span class="snippet"><span>Summary</span>- ソースベースのMBRデコーディング（sMBR）を提案し、パラフレーズや逆翻訳から生成された準ソースを「サポート仮説」として利用。参照なしの品質推定メトリックを効用関数として用いる新しいアプローチで、実験によりsMBRがQE再ランキングおよび標準MBRを上回る性能を示した。sMBRはNMTデコーディングにおいて有望な手法である。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:


</p>
<div class="tweet-embed" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/boxuan_lyu425/status/1946802820973519245?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>&lt;img alt="loading..." src="/assets/images/load-31_128.gif class="tweet-loading" /&gt;</div>


</span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/GraphGeneration.html" target="_blank" rel="noopener noreferrer">#GraphGeneration</a>
<span class="issue_date">Issue Date: 2025-07-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2227" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning-Order Autoregressive Models with Application to Molecular Graph   Generation, Zhe Wang+, ICML'25</a>
<span class="snippet"><span>Summary</span>- 自己回帰モデル（ARMs）を用いて、データから逐次的に推測される確率的順序を利用し、高次元データを生成する新しい手法を提案。トレーニング可能なオーダーポリシーを組み込み、対数尤度の変分下限を用いて最適化。実験により、画像生成やグラフ生成で意味のある自己回帰順序を学習し、分子グラフ生成ではQM9およびZINC250kベンチマークで最先端の結果を達成。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:


</p>
<div class="tweet-embed" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thjashin/status/1945175804704645607?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>&lt;img alt="loading..." src="/assets/images/load-31_128.gif class="tweet-loading" /&gt;</div>


<p>openreview:


<a href="https://openreview.net/forum?id=EY6pXIDi3G" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=EY6pXIDi3G</a>


</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LearningPhenomena.html" target="_blank" rel="noopener noreferrer">#LearningPhenomena</a>
<span class="issue_date">Issue Date: 2025-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2187" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Not All Explanations for Deep Learning Phenomena Are Equally Valuable, Alan Jeffares+, PMLR'25</a>
<span class="snippet"><span>Summary</span>- 深層学習の驚くべき現象（ダブルディセント、グロッキングなど）を孤立したケースとして説明することには限界があり、実世界のアプリケーションにはほとんど現れないと主張。これらの現象は、深層学習の一般的な原則を洗練するための研究価値があると提案し、研究コミュニティのアプローチを再考する必要性を示唆。最終的な実用的目標に整合するための推奨事項も提案。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:


</p>
<div class="tweet-embed" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jeffaresalan/status/1943315797692109015?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>&lt;img alt="loading..." src="/assets/images/load-31_128.gif class="tweet-loading" /&gt;</div>


<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2189" target="_blank" rel="noopener noreferrer">[Paper Note] Deep Double Descent: Where Bigger Models and More Data Hurt, Preetum Nakkiran+, ICLR'20</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/524" target="_blank" rel="noopener noreferrer">GROKKING: GENERALIZATION BEYOND OVERFIT- TING ON SMALL ALGORITHMIC DATASETS, Power+, ICLR'21 Workshop</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2190" target="_blank" rel="noopener noreferrer">[Paper Note] The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks, Jonathan Frankle+, ICLR'19</a>
</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2185" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Mixture of Experts Provably Detect and Learn the Latent Cluster   Structure in Gradient-Based Learning, Ryotaro Kawata+, ICML'25</a>
<span class="snippet"><span>Summary</span>- Mixture of Experts (MoE)は、入力を専門家に動的に分配するモデルのアンサンブルであり、機械学習で成功を収めているが、その理論的理解は遅れている。本研究では、MoEのサンプルおよび実行時間の複雑さを回帰タスクにおけるクラスタ構造を通じて理論的に分析し、バニラニューラルネットワークがこの構造を検出できない理由を示す。MoEは各専門家の能力を活用し、問題をより単純なサブ問題に分割することで、非線形回帰におけるSGDのダイナミクスを探求する初めての試みである。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:


</p>
<div class="tweet-embed" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/btreetaiji/status/1943226334463086989?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>&lt;img alt="loading..." src="/assets/images/load-31_128.gif class="tweet-loading" /&gt;</div>


</span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultitaskLearning.html" target="_blank" rel="noopener noreferrer">#MultitaskLearning</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2025-03-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1779" target="_blank" rel="noopener noreferrer" class="title-link">Joint Modeling in Recommendations: A Survey, Xiangyu Zhao+, arXiv'25</a>
<span class="snippet"><span>Summary</span>- デジタル環境におけるDeep Recommender Systems（DRS）は、ユーザーの好みに基づくコンテンツ推薦に重要だが、従来の手法は単一のタスクやデータに依存し、複雑な好みを反映できない。これを克服するために、共同モデリングアプローチが必要であり、推薦の精度とカスタマイズを向上させる。本論文では、共同モデリングをマルチタスク、マルチシナリオ、マルチモーダル、マルチビヘイビアの4次元で定義し、最新の進展と研究の方向性を探る。最後に、将来の研究の道筋を示し、結論を述べる。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:


</p>
<div class="tweet-embed" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1896408792952410496?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>&lt;img alt="loading..." src="/assets/images/load-31_128.gif class="tweet-loading" /&gt;</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<span class="issue_date">Issue Date: 2024-11-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1541" target="_blank" rel="noopener noreferrer" class="title-link">How Does Critical Batch Size Scale in Pre-training?, Hanlin Zhang+, ICLR'25</a>
<span class="snippet"><span>Summary</span>- 大規模モデルの訓練には、クリティカルバッチサイズ（CBS）を考慮した並列化戦略が重要である。CBSの測定法を提案し、C4データセットで自己回帰型言語モデルを訓練。バッチサイズや学習率などの要因を調整し、CBSがデータサイズに比例してスケールすることを示した。この結果は、ニューラルネットワークの理論的分析によって支持され、ハイパーパラメータ選択の重要性も強調されている。</span>
<span class="snippet"><span>Comment</span><p>Critical Batch Sizeはモデルサイズにはあまり依存せず、データサイズに応じてスケールする<br><img src="https://github.com/user-attachments/assets/4a1a720f-37a1-485d-9b02-bb2e8a5c2da4" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/8bc5f621-caac-438a-afd1-de1d689ee210" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/ActivationFunction.html" target="_blank" rel="noopener noreferrer">#ActivationFunction</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2538" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Polynomial Composition Activations: Unleashing the Dynamics of Large  Language Models, Zhijian Zhuo+, arXiv'24</a>
<span class="snippet"><span>Summary</span>- 新しい多項式合成活性化関数（PolyCom）を提案し、トランスフォーマーのダイナミクスを最適化。PolyComは他の活性化関数よりも高い表現力を持ち、最適近似率を達成。大規模言語モデルにおいて、従来の活性化関数をPolyComに置き換えることで、精度と収束率が向上することを実証。実験結果は他の活性化関数に対して大幅な改善を示す。コードは公開中。</span>
<span class="snippet"><span>Comment</span><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1311" target="_blank" rel="noopener noreferrer">GLU Variants Improve Transformer, Noam Shazeer, N/A, arXiv'20</a>
 </p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2024-12-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1592" target="_blank" rel="noopener noreferrer" class="title-link">Striking Gold in Advertising: Standardization and Exploration of Ad Text   Generation, Masato Mita+, ACL'24</a>
<span class="snippet"><span>Summary</span>- 自動広告テキスト生成（ATG）のために、標準化されたベンチマークデータセットCAMERAを提案。これにより、マルチモーダル情報の活用と業界全体での評価が促進される。9つのベースラインを用いた実験で、現状と課題を明らかにし、LLMベースの評価者と人間の評価の一致を探求。</span>
<span class="snippet"><span>Comment</span><p>広告文生成タスク（Ad Text Generation）は個々のグループのプロプライエタリデータでしか評価されてこなかったことと、そもそもタスク設定が十分に規定されていないので、その辺を整備したという話らしい。<br>特に広告文生成のための初のオープンデータなCAMERAを構築している。<br><br>データセットを作るだけでなく、既存の手法、古典的なものからLLMまででどの程度の性能まで到達しているか、さらにはROUGEやGPT-4を用いたLLM-as-a-Judgeのような自動評価手法をメタ評価し、人手評価とオンライン評価のどの程度代替になるかも分析したとのことらしい。</p>
<p>Table5にメタ評価の結果が記載されている。システムレベルのcorrelationを測定している。興味深いのが、BLEU-4, ROUGE-1, BERTScoreなどの古典的or埋め込みベースのNLG評価手法がFaithfulnessとFluencyにおいて、人間の専門家と高い相関を示しているのに対し、GPT-4による評価では人間による評価と全然相関が出ていない。<br><br>既存のLLM-as-a-Judge研究では専門家と同等の評価できます、みたいな話がよく見受けられるがこれらの報告と結果が異なっていておもしろい。著者らは、OpenAIのGPTはそもそも広告ドメインとテキストでそんなに訓練されていなさそうなので、ドメインのミスマッチが一つの要因としてあるのではないか、と考察している。<br><br>また、Attractivenessでは専門家による評価と弱い相関しか示していない点も興味深い。広告文がどの程度魅力的かはBLEU, ROUGE, BERTScoreあたりではなかなか難しそうなので、GPT4による評価がうまくいって欲しいところだが、全くうまくいっていない。この論文の結果だけを見ると、（Attractivenessに関しては）自動評価だけではまだまだ広告文の評価は厳しそうに見える。<br><br><img src="https://github.com/user-attachments/assets/15804ddc-3131-4a3d-9071-a66473e0e987" alt="image" loading="lazy"></p>
<p>GPT4によるAttractivenessの評価に利用したプロンプトが下記。MTBenchっぽく、ペアワイズの分類問題として解いていることがわかる。この辺はLLM-as-a-Judgeの研究では他にもスコアトークンを出力し尤度で重みづけるG-Evalをはじめ、さまざまな手法が提案されていると思うので、その辺の手法を利用したらどうなるかは興味がある。<br>あとはそもそも手法面の話以前に、promptのコンテキスト情報としてどのような情報がAttractivenessの評価に重要か？というのも明らかになると興味深い。この辺は、サイバーエージェントの専門家部隊が、どのようなことを思考してAttractivenessを評価しているのか？というのがヒントになりそうである。<br><img src="https://github.com/user-attachments/assets/5c0d3989-d4c1-4d61-b592-b1140c4cf93d" alt="image" loading="lazy"><br></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1591" target="_blank" rel="noopener noreferrer">国際会議ACL2024参加報告, Masato Mita, Cyber Agent, 2024.12</a>
<br><br>に著者によるサマリが記載されているので参照のこと。</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CTRPrediction.html" target="_blank" rel="noopener noreferrer">#CTRPrediction</a>
<a class="button" href="articles/ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<span class="issue_date">Issue Date: 2024-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1531" target="_blank" rel="noopener noreferrer" class="title-link">Collaborative Contrastive Network for Click-Through Rate Prediction, Chen Gao+, arXiv'24</a>
<span class="snippet"><span>Summary</span>- EコマースプラットフォームにおけるCTR予測の課題を解決するために、「コラボレーティブコントラストネットワーク（CCN）」を提案。CCNは、ユーザーの興味と不興を示すアイテムクラスターを特定し、トリガーアイテムへの依存を減少させる。オンラインA/Bテストにより、タオバオでCTRを12.3%、注文量を12.7%向上させる成果を達成。</span>
<span class="snippet"><span>Comment</span><p>参考: [Mini-appの定義生成結果（Hallucinationに注意）](


<a href="https://www.perplexity.ai/search/what-is-the-definition-of-the-sW4uZPZIQe6Iq53HbwuG7Q)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/search/what-is-the-definition-of-the-sW4uZPZIQe6Iq53HbwuG7Q)</a>


<br><br>論文中の図解: Mini-appにトリガーとなるアイテムを提示するTrigger-Induced-Recommendation（TIR）<br><img src="https://github.com/user-attachments/assets/eb209dc4-b8bc-4632-89df-137031e509f0" alt="image" loading="lazy"></p>
<p>## 概要<br><br>図3に示されているような Collaborative Contrastive Network (CCN)を提案しており、このネットワークは、Collaborative Constrastive Learningに基づいて学習される。<br><br><br><br>### Collaborative Constrasitve Learning<br><br>図2がCollaborative Constrastive Learningの気持ちを表しており、図2のようなクリックスルーログが与えられたとする。<br><br>推薦リストを上から見ていき、いま着目しているアイテムをtarget_itemとすると、target_itemがクリックされている場合、同じcontext（i.e., ユーザにページ内で提示されたアイテム群）のクリックされているアイテムと距離が近くなり、逆にクリックされていないアイテム群とは距離が遠いとみなせる。逆にtarget_itemがクリックされていない場合、同様にクリックされていないアイテムとは距離が近く、クリックされているアイテムとは距離が遠いとみなせる。このように考えると、ある推薦リストが与えられた時に、あるtarget_itemに着目すると、contrastive learningのためのpositive example/negative exampleを生成できる。このようなco-click/co-non-clickの関係から、アイテム同士の距離を学習し、ユーザのinterest/disinterestを学習する。<br><br><img src="https://github.com/user-attachments/assets/cea478d8-27e5-45e9-afcd-41a0765c8cce" alt="image" loading="lazy"><br><br><br><br>### Collaborative Contrastive Network<br><br>Collaborative ModuleとCTR Moduleに分かれている。<br><br>- Collaborative Moduleには、context itemsと、target itemをinputとし両者の関係性をエンコードする<br><br>    - このとき、トリガーアイテムのembeddingとアダマール積をとることで、トリガーアイテムの情報も考慮させる<br><br>- CTR Moduleは、context itemsとtarget itemの関係性をエンコードしたembedding、target_item, trigger_itemのembedding, user profileのembedding, userのlong-termとshort-termの行動のembeddingをconcatしたベクトルをinputとして受け取り、そらからtarget_itemのCTRを予測する。 <br><br>- Loss Functionは、binary cross entropyと、Collaborative Contrastive Lossをλで重みづけして足し合わせたものであり、Collaborative Contrastive Loss L_CMCは、上述の気持ちを反映するloss（i.e., target_itemとcontext_itemco-click/co-non-clickに基づいて、アイテム間の距離を最小/最大化するようなloss）となっている<br><br><img src="https://github.com/user-attachments/assets/2ca62ade-d370-4615-89d1-eac56bf1e847" alt="image" loading="lazy"><br><br><br><br><img src="https://github.com/user-attachments/assets/07f4bef9-2f86-46b5-b310-2afca26a0db3" alt="image" loading="lazy"><br><br><br><br>## 実験結果<br><br>### offline evaluation<br><br>Table 1に示したTaobaoで収集した非常に大規模なproprietary datasetでCTRを予測したところ、AUCはベースラインと比較して高くなった。ここで、TANはCCNのBackboneモデルで、Contrastive Learningを実施していないモデルである。CTR予測においてAUCが高くなるというのはすなわち、クリックされたアイテムi/クリックされなかったアイテムjの2つをとってきたときに、両者のCTR予測結果が CTR_i &gt; CTR_j になる割合が高くなった（i.e. クリックされているアイテムの方が高いCTR予測結果となっている）ということを意味する。<br><br><img src="https://github.com/user-attachments/assets/e696bf07-fcd6-47cd-9f96-926071a6b609" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/629bc349-36f6-4603-b595-3482c92e66f4" alt="image" loading="lazy"><br><br><br><br>### online A/B Testing<br><br>A/Bテストまで実施しており、実際に提案手法を組み込んだ結果、高いCTRを獲得しているだけでなく、CVRも向上している。すごい。<br><br><img src="https://github.com/user-attachments/assets/651d8351-32f5-4aa6-89b6-f310781467f8" alt="image" loading="lazy"><br><br>Contrastive Learningを実施しないTANと、CCNを比較してもCCNの方が高いCTR, CVRを獲得している。Contrastive Learning有能。<br><br><img src="https://github.com/user-attachments/assets/56b6d14f-fef7-4d1b-ae04-ec3acacf2787" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/554" target="_blank" rel="noopener noreferrer" class="title-link">Active prompting with chain-of-thought for large language models, Diao+, The Hong Kong University of Science and Technology, ACL'24</a>
<span class="snippet"><span>Comment</span><p>しっかりと読めていないが、CoT-answerが存在しないtrainingデータが存在したときに、nサンプルにCoTとAnswerを与えるだけでFew-shotの予測をtestデータに対してできるようにしたい、というのがモチベーションっぽい<br><br>そのために、questionに対して、training dataに対してFew-Shot CoTで予測をさせた場合やZero-Shot CoTによって予測をさせた場合などでanswerを取得し、answerのばらつき度合いなどから不確実性を測定する。<br><br>そして、不確実性が高いCoT-Answerペアを取得し、人間が手作業でCoTと回答のペアを与え、その人間が作成したものを用いてTestデータに対してFewShotしましょう、ということだと思われる。<br><br><img src="https://user-images.githubusercontent.com/12249301/234747555-4b7bd0d5-f099-4288-a470-32206533e652.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/AutomaticPromptEngineering.html" target="_blank" rel="noopener noreferrer">#AutomaticPromptEngineering</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/532" target="_blank" rel="noopener noreferrer" class="title-link">Enhancing LLM Chain-of-Thought with Iterative Bootstrapping, Sun+, Xiamen University （w_ MSRA et al.）, NAACL'24</a>
<span class="snippet"><span>Comment</span><p>Zero shot CoTからスタートし、正しく問題に回答できるようにreasoningを改善するようにpromptをreviseし続けるループを回す。最終的にループした結果を要約し、それらをプールする。テストセットに対しては、プールの中からNshotをサンプルしinferenceを行う。<br><img src="https://user-images.githubusercontent.com/12249301/234311707-0d6f3443-681a-4309-917b-d21fd1a8c024.jpeg" alt="image" loading="lazy"></p>
<p>できそうだなーと思っていたけど、早くもやられてしまった</p>
<p>実装: 


<a href="https://github.com/GasolSun36/Iter-CoT" target="_blank" rel="noopener noreferrer">https://github.com/GasolSun36/Iter-CoT</a>


</p>
<p>
<strong># モチベーション: 既存のCoT Promptingの問題点<br><br>## Inappropriate Examplars can Reduce Performance<br><br>まず、既存のCoT prompting手法は、sampling examplarがシンプル、あるいは極めて複雑な（hop-based criterionにおいて; タスクを解くために何ステップ必要かという情報; しばしば人手で付与されている？）サンプルをサンプリングしてしまう問題がある。シンプルすぎるサンプルを選択すると、既にLLMは適切にシンプルな回答には答えられるにもかかわらず、demonstrationが冗長で限定的になってしまう。加えて、極端に複雑なexampleをサンプリングすると、複雑なquestionに対しては性能が向上するが、シンプルな問題に対する正答率が下がってしまう。<br><br><br><br>続いて、demonstration中で誤ったreasoning chainを生成してしまうと、inference時にパフォーマンスが低下する問題がある。下図に示した通り、誤ったdemonstrationが増加するにつれて、最終的な予測性能が低下する傾向にある。<br><br><br><br>これら2つの課題は、現在のメインストリームな手法（questionを選択し、reasoning chainを生成する手法）に一般的に存在する。<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/556" target="_blank" rel="noopener noreferrer">Automatic Chain of Thought Prompting in Large Language Models, Zhang+, Shanghai Jiao Tong University, ICLR'23</a>
</strong>
<br>
 , <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/555" target="_blank" rel="noopener noreferrer">Automatic prompt augmentation and selection with chain-of-thought from labeled data, Shum+, The Hong Kong University of Science and Technology, arXiv'23</a>
 のように推論時に適切なdemonstrationを選択するような取り組みは行われてきているが、test questionに対して推論するために、適切なexamplarsを選択するような方法は計算コストを増大させてしまう。<br><br>これら研究は誤った例の利用を最小限に抑えて、その悪影響を防ぐことを目指している。<br><br><br><br>一方で、この研究では、誤った例がLLMに対してcomplexityのlevelを提供し、貴重な学習をもたらすことができることを見出した。これは学生が難解だが回答可能な問題に取り組むことによって、問題解決スキルを向上させる方法に類似している。従って、誤った例を活用してLLMのパフォーマンスを向上させる方法を調査することは価値がある。<br><br><img src="https://user-images.githubusercontent.com/12249301/234752168-fe1d83a4-8d29-4f6c-8aa1-6bde1706beea.png" alt="image" loading="lazy"><br><br><br><br>
<strong>## Large Language Models can self-Correct with Bootstrapping<br><br>Zero-Shot CoTでreasoning chainを生成し、誤ったreasoning chainを生成したpromptを**LLMに推敲させ(self-correction)**正しい出力が得られるようにする。こういったプロセスを繰り返し、correct sampleを増やすことでどんどん性能が改善していった。これに基づいて、IterCoTを提案。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/234786084-5a6055f6-6f42-4546-bcbf-686b1d759ca9.png" alt="image" loading="lazy"><br><br>&lt;/p&gt;<p># IterCoT: Iterative Bootstrapping in Chain-of-Thought Prompting<br><br>IterCoTはweak bootstrappingとstrong bootstrappingによって構成される。<br><br><br><br>## Weak bootstrapping<br><br>- Initialization<br><br>  - Training setに対してZero-shot CoTを実施し、reasoning chainとanswerを得<br><br>- Bootstrapping <br><br>  - 回答が誤っていた各サンプルに対して、Revise-Promptを適用しLLMに誤りを指摘し、新しい回答を生成させる。<br><br>  - 回答が正確になるまでこれを繰り返す。<br><br>- Summarization<br><br>  - 正しい回答が得られたら、Summary-Promptを利用して、これまでの誤ったrationaleと、正解のrationaleを利用し、最終的なreasoning chain (Iter-CoT)を生成する。<br><br>  - 全体のcontextual informationが加わることで、LLMにとって正確でわかりやすいreasoning chainを獲得する。<br><br>- Inference<br><br>  - questionとIter-Cotを組み合わせ、demonstration poolに加える<br><br>  - inference時はランダムにdemonstraction poolからサンプリングし、In context learningに利用し推論を行う<br><br><br><br>## Strong Bootstrapping<br><br>コンセプトはweak bootstrappingと一緒だが、Revise-Promptでより人間による介入を行う。具体的には、reasoning chainのどこが誤っているかを明示的に指摘し、LLMにreasoning chainをreviseさせる。<br><br>これは従来のLLMからの推論を必要としないannotationプロセスとは異なっている。何が違うかというと、人間によるannnotationをLLMの推論と統合することで、文脈情報としてreasoning chainを修正することができるようになる点で異なっている。</p>
<p># 実験<br><br>Manual-CoT <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
&lt;/strong&gt;
<br>
 , Random-CoT <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
, Auto-CoT <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/554" target="_blank" rel="noopener noreferrer">Active prompting with chain-of-thought for large language models, Diao+, The Hong Kong University of Science and Technology, ACL'24</a>
 と比較。<br><br>Iter-CoTが11個のデータセット全てでoutperformした。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/234792846-e8fd2f8b-6e26-48fc-9e5d-785bcf2a6b6a.png" alt="image" loading="lazy"><br><br><br><br>weak bootstrapingのiterationは4回くらいで頭打ちになった<br><br><img src="https://user-images.githubusercontent.com/12249301/234793570-f57e56e4-7320-4be4-9c93-ee3be01ad389.png" alt="image" loading="lazy"><br><br><br><br>また、手動でreasoning chainを修正した結果と、contextにannotation情報を残し、最後にsummarizeする方法を比較した結果、後者の方が性能が高かった。このため、contextの情報を利用しsummarizeすることが効果的であることがわかる。</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/530" target="_blank" rel="noopener noreferrer" class="title-link">Graph Neural Networks for Text Classification: A Survey, Wang+, Artificial Intelligence Review'24</a>
<span class="snippet"><span>Summary</span>- テキスト分類におけるグラフニューラルネットワークの手法を2023年まで調査し、コーパスおよび文書レベルのグラフ構築や学習プロセスを詳述。課題や今後の方向性、データセットや評価指標についても考察し、異なる技術の比較を行い評価指標の利点と欠点を特定。</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Regularization.html" target="_blank" rel="noopener noreferrer">#Regularization</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2604" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Dropout Reduces Underfitting, Zhuang Liu+, ICML'23</a>
<span class="snippet"><span>Summary</span>- 本研究では、ドロップアウトをトレーニング初期に使用することでアンダーフィッティングを軽減できることを示し、初期ドロップアウト手法を提案します。これにより、勾配の方向的分散が減少し、SGDの確率性に対抗します。実験により、初期ドロップアウトを用いたモデルは、ドロップアウトなしのモデルよりも低いトレーニング損失を示し、一般化精度が向上することが確認されました。また、後期ドロップアウトという手法も探求し、トレーニング後半での正則化効果を検証しました。これらの結果は、深層学習における正則化の理解を深めることに寄与します。</span>
<span class="snippet"><span>Comment</span><p>日本語解説:


<a href="https://www.docswell.com/s/DeepLearning2023/54QM6D-dldropout-reduces-underfitting" target="_blank" rel="noopener noreferrer">https://www.docswell.com/s/DeepLearning2023/54QM6D-dldropout-reduces-underfitting</a>


</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Grokking.html" target="_blank" rel="noopener noreferrer">#Grokking</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1051" target="_blank" rel="noopener noreferrer" class="title-link">Explaining grokking through circuit efficiency, Vikrant Varma+, N_A, arXiv'23</a>
<span class="snippet"><span>Summary</span>- グロッキングとは、完璧なトレーニング精度を持つネットワークでも一般化が悪い現象のことである。この現象は、タスクが一般化する解と記憶する解の両方を許容する場合に起こると考えられている。一般化する解は学習が遅く、効率的であり、同じパラメータノルムでより大きなロジットを生成する。一方、記憶回路はトレーニングデータセットが大きくなるにつれて非効率になるが、一般化回路はそうではないと仮説が立てられている。これは、記憶と一般化が同じくらい効率的な臨界データセットサイズが存在することを示唆している。さらに、グロッキングに関して4つの新しい予測が立てられ、それらが確認され、説明が支持される重要な証拠が提供されている。また、グロッキング以外の2つの新しい現象も示されており、それはアングロッキングとセミグロッキングである。アングロッキングは完璧なテスト精度から低いテスト精度に逆戻りする現象であり、セミグロッキングは完璧なテスト精度ではなく部分的なテスト精度への遅れた一般化を示す現象である。</span>
<span class="snippet"><span>Comment</span><p>Grokkingがいつ、なぜ発生するかを説明する理論を示した研究。<br>理由としては、最初はmemorizationを学習していくのだが、ある時点から一般化回路であるGenに切り替わる。これが切り替わる理由としては、memorizationよりも、genの方がlossが小さくなるから、とのこと。これはより大規模なデータセットで顕著。</p>
<p>Grokkingが最初に報告された研究は <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/524" target="_blank" rel="noopener noreferrer">GROKKING: GENERALIZATION BEYOND OVERFIT- TING ON SMALL ALGORITHMIC DATASETS, Power+, ICLR'21 Workshop</a>
</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/765" target="_blank" rel="noopener noreferrer" class="title-link">RWKV: Reinventing RNNs for the Transformer Era, Bo Peng+, N_A, arXiv'23</a>
<span class="snippet"><span>Summary</span>- 本研究では、トランスフォーマーとRNNの両方の利点を組み合わせた新しいモデルアーキテクチャであるRWKVを提案し、トレーニング中に計算を並列化し、推論中に一定の計算およびメモリの複雑さを維持することができます。RWKVは、同じサイズのトランスフォーマーと同等のパフォーマンスを発揮し、将来的にはより効率的なモデルを作成するためにこのアーキテクチャを活用できることを示唆しています。</span>
<span class="snippet"><span>Comment</span><p>異なるtransformerとRWKVの計算量とメモリ消費量の比較<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/84d5241f-1702-4bd6-8ce3-0a80ded8f192" alt="image" loading="lazy"><br><br><br><br>RWKVの構造は基本的に、residual blockをスタックすることによって構成される。一つのresidual blockは、time-mixing（時間方向の混ぜ合わせ）と、channnel-mixing（要素間での混ぜ合わせ）を行う。　<br><br>RWKVのカギとなる要素は以下の4つであり、RWKVのブロック、およびLMでのアーキテクチャは以下のようになる：<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2185d678-8ca1-4017-a052-77c073704253" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e5559a3c-40ee-4859-ba75-2827c12b5964" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4af26c0f-5907-4723-b24c-67b02a8025b9" alt="image" loading="lazy"><br><br><br><br>ここで、token-shiftは、previsou timestepのinputとのlinear interpolationを現在のinputととることである。これにより再帰性を担保する。<br><br><br><br>RWKVは他のLLMと比較し、パラメータ数に対して性能はcomparableであり、context lengthを増やすことで、lossはきちんと低下し、テキスト生成をする際に要する時間は他のLLMと比較して、トークン数に対して線形にしか増加しない。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/c8a39aae-17de-4c43-bfba-b6a54f83205e" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9baf95d0-9e8c-4c62-a8f3-0f2a0d67ae00" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a9601b1c-c403-4c2c-bd60-3d2cfa6e512e" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<span class="issue_date">Issue Date: 2023-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/677" target="_blank" rel="noopener noreferrer" class="title-link">Sketching the Future （STF）: Applying Conditional Control Techniques to  Text-to-Video Models, Rohan Dhesikan+, arXiv'23</a>
<span class="snippet"><span>Summary</span>- ゼロショットのテキストから動画生成をControlNetと組み合わせ、スケッチされたフレームを基に動画を生成する新手法を提案。フレーム補間を行い、Text-to-Video Zeroアーキテクチャを活用して高品質で一貫性のある動画を生成。デモ動画やリソースを提供し、さらなる研究を促進。</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Semi-Supervised.html" target="_blank" rel="noopener noreferrer">#Semi-Supervised</a>
<span class="issue_date">Issue Date: 2023-04-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/602" target="_blank" rel="noopener noreferrer" class="title-link">SemPPL: Predicting pseudo-labels for better contrastive representations, Matko Bošnjak+, N_A, ICLR'23</a>
<span class="snippet"><span>Summary</span>- 本研究では、コンピュータビジョンにおける半教師あり学習の問題を解決するために、Semantic Positives via Pseudo-Labels (SemPPL)という新しい手法を提案している。この手法は、ラベル付きとラベルなしのデータを組み合わせて情報豊富な表現を学習することができ、ResNet-$50$を使用してImageNetの$1\%$および$10\%$のラベルでトレーニングする場合、競合する半教師あり学習手法を上回る最高性能を発揮することが示された。SemPPLは、強力な頑健性、分布外および転移性能を示すことができる。</span>
<span class="snippet"><span>Comment</span><p>後ほど説明を追記する<br><img src="https://github.com/user-attachments/assets/4441dc6c-a7b2-4ec9-9748-b6558a96e1af" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/8a78a40e-f5c4-4742-9e5d-36cd1b8d0e60" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/04ded9aa-c875-4282-9e3b-7ce456a6cc44" alt="image" loading="lazy"></p>
<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1975" target="_blank" rel="noopener noreferrer">A Simple Framework for Contrastive Learning of Visual Representations, Ting Chen+, ICML'20</a>
</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/NeuralArchitectureSearch.html" target="_blank" rel="noopener noreferrer">#NeuralArchitectureSearch</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/559" target="_blank" rel="noopener noreferrer" class="title-link">Can GPT-4 Perform Neural Architecture Search? Zhang+, The University of Sydney, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>ドメイン知識の必要のないプロンプトで、ニューラルモデルのアーキテクチャの提案をGPTにしてもらう研究。accをフィードバックとして与え、良い構造を提案するといったループを繰り返す模様<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/235143629-308233a6-51c7-40f7-afc6-e51f425e55d4.png" alt="image" loading="lazy"><br><br></p>
<p>Neural Architecture Search (NAS)においては、ランダムベースラインがよく採用されるらしく、比較した結果ランダムよりよかった<br><br><img src="https://user-images.githubusercontent.com/12249301/235144154-5c94a664-9768-4da5-af76-a137bc3d2b48.png" alt="image" loading="lazy"><br><br><br><br>NAS201と呼ばれるベンチマーク（NNアーキテクチャのcell blockをデザインすることにフォーカス; 探索空間は4つのノードと6つのエッジで構成される密接続のDAGとして表される; ノードはfeature mapを表し、エッジはoperationに対応;利用可能なoperationが5つあるため、可能な検索空間の総数は5の6乗で15,625通りとなる）でも評価した結果、提案手法の性能がよかったとのこと。<br><br><img src="https://user-images.githubusercontent.com/12249301/235144424-a8269562-3f4e-4830-8610-80e3ac9b977e.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/558" target="_blank" rel="noopener noreferrer" class="title-link">Self-consistency improves chain of thought reasoning in language models, Wang+, Google Research, ICLR'23</a>
<span class="snippet"><span>Comment</span><p>self-consistencyと呼ばれる新たなCoTのデコーディング手法を提案。<br><br>これは、難しいreasoningが必要なタスクでは、複数のreasoningのパスが存在するというintuitionに基づいている。<br><br><br><br>self-consistencyではまず、普通にCoTを行う。そしてgreedyにdecodingする代わりに、以下のようなプロセスを実施する：<br><br>1. 多様なreasoning pathをLLMに生成させ、サンプリングする。<br><br>2. 異なるreasoning pathは異なるfinal answerを生成する（= final answer set）。<br><br>3. そして、最終的なanswerを見つけるために、reasoning pathをmarginalizeすることで、final answerのsetの中で最も一貫性のある回答を見出す。<br><br><br><br>これは、もし異なる考え方によって同じ回答が導き出されるのであれば、その最終的な回答は正しいという経験則に基づいている。<br><br>self-consistencyを実現するためには、複数のreasoning pathを取得した上で、最も多いanswer a_iを選択する（majority vote）。これにはtemperature samplingを用いる（temperatureを0.5やら0.7に設定して、より高い信頼性を保ちつつ、かつ多様なoutputを手に入れる）。<br><br>temperature samplingについては[こちら](


<a href="https://openreview.net/pdf?id=rygGQyrFvH)%E3%81%AE%E8%AB%96%E6%96%87%E3%82%92%E5%8F%82%E7%85%A7%E3%81%AE%E3%81%93%E3%81%A8%E3%80%82" target="_blank" rel="noopener noreferrer">https://openreview.net/pdf?id=rygGQyrFvH)の論文を参照のこと。</a>


<br><br>sampling数は増やせば増やすほど性能が向上するが、徐々にサチってくる。サンプリング数を増やすほどコストがかかるので、その辺はコスト感との兼ね合いになると思われる。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/234754605-6316223f-4290-45d5-bf7c-64675f07d0c3.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/234779335-478f2431-67ea-4b24-9c1b-fa1dd6ac6b45.png" alt="image" loading="lazy"><br><br></p>
<p>Self-consistencyは回答が閉じた集合であるような問題に対して適用可能であり、open-endなquestionでは利用できないことに注意が必要。ただし、open-endでも回答間になんらかの関係性を見出すような指標があれば実現可能とlimitationで言及している。</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/556" target="_blank" rel="noopener noreferrer" class="title-link">Automatic Chain of Thought Prompting in Large Language Models, Zhang+, Shanghai Jiao Tong University, ICLR'23</a>
<span class="snippet"><span>Comment</span><p>LLMによるreasoning chainが人間が作成したものよりも優れていることを示しているとのこと <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/532" target="_blank" rel="noopener noreferrer">Enhancing LLM Chain-of-Thought with Iterative Bootstrapping, Sun+, Xiamen University (w/ MSRA et al.), NAACL'24</a>
 より</p>
<p>clusteringベースな手法を利用することにより、誤りを含む例が単一のクラスタにまとめられうことを示し、これにより過剰な誤ったデモンストレーションが軽減されることを示した。</p>
<p>手法の概要。questionを複数のクラスタに分割し、各クラスタから代表的なquestionをサンプリングし、zero-shot CoTでreasoning chainを作成しpromptに組み込む。最終的に回答を得たいquestionに対しても、上記で生成した複数のquestion-reasoningで条件付けした上で、zeroshot-CoTでrationaleを生成する。<br><img src="https://github.com/user-attachments/assets/35213747-9b5f-4d38-a525-1deafe86cd0c" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/555" target="_blank" rel="noopener noreferrer" class="title-link">Automatic prompt augmentation and selection with chain-of-thought from labeled data, Shum+, The Hong Kong University of Science and Technology, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>LLMによるreasoning chainが人間が作成したものよりも優れていることを示しているとのこと <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/532" target="_blank" rel="noopener noreferrer">Enhancing LLM Chain-of-Thought with Iterative Bootstrapping, Sun+, Xiamen University (w/ MSRA et al.), NAACL'24</a>
 より</p>
<p>selection phaseで誤ったexampleは直接排除する手法をとっている。そして、強化学習によって、demonstrationのselection modelを訓練している。</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/529" target="_blank" rel="noopener noreferrer" class="title-link">Scaling Transformer to 1M tokens and beyond with RMT, Bulatov+, DeepPavlov, arXiv'23</a>
<span class="snippet"><span>Comment</span><p>Reccurent Memory Transformer <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/523" target="_blank" rel="noopener noreferrer">Recurrent Memory Transformer, Bulatov+, NeurIPS'22</a>
 を使って2Mトークン扱えるようにしたよーという話。<br><br>ハリーポッターのトークン数が1.5Mらしいので、そのうち小説一冊書けるかもという世界。</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/TACL.html" target="_blank" rel="noopener noreferrer">#TACL</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/525" target="_blank" rel="noopener noreferrer" class="title-link">Efficient Methods for Natural Language Processing: A Survey, Treviso+, TACL'23</a>
<span class="snippet"><span>Summary</span>- NLPのパフォーマンス向上にはスケールの拡大が重要だが、リソース消費も増加する。限られたリソースで効率的にNLPを実施する方法を統合し、指針を提供。効率的な手法の開発に向けた研究方向を示唆。</span>
<span class="snippet"><span>Comment</span><p>パラメータ数でゴリ押すような方法ではなく、"Efficient"に行うための手法をまとめている<br><br><img src="https://user-images.githubusercontent.com/12249301/234287218-2d42766f-5c5c-4cf9-859e-c2b0a5dfd4c3.jpeg" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/SIGGRAPH.html" target="_blank" rel="noopener noreferrer">#SIGGRAPH</a>
<span class="issue_date">Issue Date: 2022-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/496" target="_blank" rel="noopener noreferrer" class="title-link">Sketch-Guided Text-to-Image Diffusion Models, Andrey+, Google Research, SIGGRAPH'23</a>
<span class="snippet"><span>Summary</span>- テキストから画像へのモデルは高品質な画像合成を実現するが、空間的特性の制御が不足している。本研究では、スケッチからの空間マップを用いて事前学習済みモデルを導く新しいアプローチを提案。専用モデルを必要とせず、潜在ガイダンス予測器（LGP）を訓練し、画像を空間マップに一致させる。ピクセルごとの訓練により柔軟性を持ち、スケッチから画像への翻訳タスクにおいて効果的な生成が可能であることを示す。</span>
<span class="snippet"><span>Comment</span><p>スケッチとpromptを入力することで、スケッチ biasedな画像を生成することができる技術。すごい。<br><br><img src="https://user-images.githubusercontent.com/12249301/205189823-66052368-60a8-4f03-a4b6-37111bd1b361.png" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/EACL.html" target="_blank" rel="noopener noreferrer">#EACL</a>
<span class="issue_date">Issue Date: 2022-09-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/482" target="_blank" rel="noopener noreferrer" class="title-link">Long Document Summarization with Top-down and Bottom-up Inference, Pang+, Salesforce Research, EACL'23</a>
<span class="snippet"><span>Comment</span><p>日本語解説: 


<a href="https://zenn.dev/ty_nlp/articles/9f5e5dd3084dbd" target="_blank" rel="noopener noreferrer">https://zenn.dev/ty_nlp/articles/9f5e5dd3084dbd</a>


<br><br><br><br>以下、上記日本語解説記事を読んで理解した内容をまとめます。ありがとうございます。<br><br><br><br># 概要<br><br>基本的にTransformerベースのモデル（e.g. BERTSum, BART, PEGASUS, GPT-2, T5）ではself-attentionの計算量が入力トークン数Nに対してO(N^2)でかかり、入力の二乗のオーダーで計算量が増えてしまう。<br><br>これを解消するためにself-attentionを計算する範囲をウィンドウサイズで制限するLongformerや、BigBardなどが提案されてきたが、どちらのモデルも離れたトークン間のattentionの情報が欠落するため、長距離のトークン間の関係性を捉えにくくなってしまう問題があった。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/188084569-ec574f6f-cc31-48db-aef5-0a3fedea816c.png" alt="image" loading="lazy"><br><br><br><br>そこで、top-down transformerではセグメント（セグメントはテキストでいうところの文）という概念を提唱し、tokenからsegmentのrepresentationを生成しその後self-attentionでsegment間の関係性を考慮してsegmentのrepresentationを生成するbottom-up inference、各tokenとsegmentの関係性を考慮しし各tokenのrepresentationを学習するtop-down inferenceの2つの構造を利用した。bottom-up inferenceにおいてsegmentのrepresentationを計算する際にpoolingを実施するが、adapoolingと呼ばれる重要なトークンに重み付けをし、その重みを加味した加重平均によりプーリングを実施する。これにより、得られた各トークンの表現は、各セグメントとの関連度の情報を含み（セグメントの表現は各セグメント間のattentnionに基づいて計算されているため; bottom-up inference）、かつ各トークンと各セグメント間との関連度も考慮して計算されているため（top-down inference）、結果的に離れたトークン間の関連度を考慮したrepresentationが学習される（下図）。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/188085213-affc953b-b4a6-4f34-8fa0-71d3ddb173b4.png" alt="image" loading="lazy"><br><br>（図は上記記事からお借りいたしました）<br><br><br><br>各attentionの計算量は表のようになり、M, wはNよりも遥かに小さいため、O(N^2)よりも遥かに小さい計算量で計算できる。<br><br><img src="https://user-images.githubusercontent.com/12249301/188086050-985d4fc6-3b1b-4ff1-b268-b6bda24581f5.png" alt="image" loading="lazy"><br><br>（こちらも上記記事からお借りいたしました）<br><br><br><br># 実験（日本語解説より）<br><br>## データセット<br><br><img src="https://user-images.githubusercontent.com/12249301/188086312-769ef574-3f91-4f12-b015-ac9c02dc93ff.png" alt="image" loading="lazy"><br><br><br><br>## 結果<br><br>### PubMedとarXiv<br><br><img src="https://user-images.githubusercontent.com/12249301/188086389-c3e49a19-51b1-437c-9802-1e62c9fd4329.png" alt="image" loading="lazy"><br><br><br><br>### CNN-DailyMail<br><br><img src="https://user-images.githubusercontent.com/12249301/188086914-9476f30d-481c-4113-8f6b-edeb906ac696.png" alt="image" loading="lazy"><br><br><br><br>### TVMegasSiteとForeverDreaming<br><br><img src="https://user-images.githubusercontent.com/12249301/188086972-c355854b-9f1f-4f88-9e36-06536963541b.png" alt="image" loading="lazy"><br><br><br><br>### BookSum-Chapter-Level<br><br><img src="https://user-images.githubusercontent.com/12249301/188087045-0ac57b5a-5c6c-49e4-a82a-3e57f5e8b788.png" alt="image" loading="lazy"><br><br><br><br>### BookSum-Book-Level<br><br><img src="https://user-images.githubusercontent.com/12249301/188087112-2d310059-72d1-4968-bf09-cdcf0e6afc2d.png" alt="image" loading="lazy"><br><br><br><br>## 所感<br><br>CNN-DailyMailのようなinput wordsが900程度のデータではcomparableな結果となっているが、input wordsが長い場合は先行研究をoutperformしている。BookSum-Chapter Levelにおいて、Longformer, BigBirdの性能が悪く、BART, T5, Pegasusの性能が良いのが謎い。<br><br>てかinput wordsが3000~7000程度のデータに対して、どうやってBARTやらT5やらを実装できるんだろう。大抵512 tokenくらいが限界だと思っていたのだが、どうやったんだ・・・。</p>
<p>&gt;The maximum document lengths for PubMed, arXiv, CNN-DM,<br><br>TVMegaSite, ForeverDreaming, BookSum are 8192, 16384, 1024, 12288, 12288, 12288, respectively<br><br><br><br>これは、たとえばBookSumの場合は仮にinputの長さが11万とかあったとしても、12288でtruncateしたということだろうか。まあなんにせよ、頑張ればこのくらいの系列長のモデルを学習できるということか（メモリに乗るのか・・・？どんな化け物マシンを使っているのか）。</p>
<p>&gt;We first train a top-down transformer on the chapter-level data and then fine-tune it on the book-level<br><br>data. The inputs to the book-level model are (1) the concatenated chapter reference summaries in<br><br>training or (2) the concatenated chapter summaries generated by the chapter-level model in testing.<br><br>The chapter-to-book curriculum training is to mitigate the scarcity of book-level data. The recursive<br><br>summarization of chapters and then books can be considered abstractive content selection applied<br><br>to book data, and is used to address the extremely long length of books.<br><br><br><br>BookLevel Summarizationでは、データ数が300件程度しかなく、かつinput wordsがでかすぎる。これに対処するために、まずtop-down transformerをchapter-level_ dataで訓練して、その後book-level dataでfine-tuning。book-level dataでfine-tuningする際には、chapterごとのreference summaryをconcatしたものを正解とし、chapter-level modelが生成したchapterごとのsummaryをconcatしたものをモデルが生成した要約として扱った、という感じだろうか。まずchapter levelで学習しその後book levelで学習するcurriculum learningっぽいやり方がbook-level dataの不足を緩和してくれる。bookの要約を得るためにchapterを再帰的に要約するようなアプローチは、book dataに対するcontent selectionとしてみなすことができ、おそろしいほど長い入力の対処にもなっている、という感じだろうか。</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2021-06-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/391" target="_blank" rel="noopener noreferrer" class="title-link">Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better, Menghani, ACM Computing Surveys'23</a>
<span class="snippet"><span>Summary</span>- ディープラーニングの進展に伴い、モデルのパラメータ数やリソース要求が増加しているため、効率性が重要になっている。本研究では、モデル効率性の5つのコア領域を調査し、実務者向けに最適化ガイドとコードを提供する。これにより、効率的なディープラーニングの全体像を示し、読者に改善の手助けとさらなる研究のアイデアを提供することを目指す。</span>
<span class="snippet"><span>Comment</span><p>学習効率化、高速化などのテクニックがまとまっているらしい</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/Deduplication.html" target="_blank" rel="noopener noreferrer">#Deduplication</a>
<span class="issue_date">Issue Date: 2025-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2688" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Beyond neural scaling laws: beating power law scaling via data pruning, Ben Sorscher+, NeurIPS'22</a>
<span class="snippet"><span>Summary</span>- データセットサイズに対する誤差のスケーリングを研究し、高品質なデータプルーニングメトリックを用いることで誤差を指数スケーリングに減少させる可能性を示す。CIFAR-10、SVHN、ImageNetでの実験により、冪法則スケーリングを超える改善を確認。ImageNetにおける10種類のデータプルーニングメトリックのベンチマークを実施し、従来のメトリックに代わる新しい自己教師ありプルーニングメトリックを開発。良好なデータプルーニングメトリックがニューラルスケーリング法則の改善とリソースコスト削減に寄与する可能性を示唆。</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=UmvSlP-PyV" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=UmvSlP-PyV</a>


</p>
<p>日本語解説スライド: 


<a href="https://speakerdeck.com/takase/snlp2023-beyond-neural-scaling-laws" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/takase/snlp2023-beyond-neural-scaling-laws</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2025-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2597" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A ConvNet for the 2020s, Zhuang Liu+, arXiv'22</a>
<span class="snippet"><span>Summary</span>- ConvNetはVision Transformersの登場により地位を失ったが、ハイブリッドアプローチの効果はトランスフォーマーの優位性に依存している。本研究では、ConvNetの限界をテストし、ConvNeXtという新しいモデルを提案。ConvNeXtは標準的なConvNetモジュールのみで構成され、精度とスケーラビリティでトランスフォーマーと競争し、ImageNetで87.8%の精度を達成し、COCO検出およびADE20KセグメンテーションでSwin Transformersを上回る。</span>
<span class="snippet"><span>Comment</span><p>ConvNeXt</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultitaskLearning.html" target="_blank" rel="noopener noreferrer">#MultitaskLearning</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2183" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Perceiver IO: A General Architecture for Structured Inputs &amp; Outputs, Andrew Jaegle+, ICLR'22</a>
<span class="snippet"><span>Summary</span>- 汎用アーキテクチャPerceiver IOを提案し、任意のデータ設定に対応し、入力と出力のサイズに対して線形にスケール可能。柔軟なクエリメカニズムを追加し、タスク特有の設計を不要に。自然言語、視覚理解、マルチタスクで強力な結果を示し、GLUEベンチマークでBERTを上回る性能を達成。</span>
<span class="snippet"><span>Comment</span><p>当時相当話題となったさまざまなモーダルを統一された枠組みで扱えるPerceiver IO論文<br><img src="https://github.com/user-attachments/assets/d7893f14-d69c-4af8-8117-08c2a6095e8e" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/CTRPrediction.html" target="_blank" rel="noopener noreferrer">#CTRPrediction</a>
<span class="issue_date">Issue Date: 2024-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1533" target="_blank" rel="noopener noreferrer" class="title-link">Deep Intention-Aware Network for Click-Through Rate Prediction, Yaxian Xia+, arXiv'22</a>
<span class="snippet"><span>Summary</span>- Eコマースプラットフォームにおけるトリガー誘発推薦（TIRA）に対し、従来のCTR予測モデルは不適切である。顧客のエントリー意図を抽出し、トリガーの影響を評価するために、深層意図認識ネットワーク（DIAN）を提案。DIANは、ユーザーの意図を推定し、トリガー依存と非依存の推薦結果を動的にバランスさせる。実験により、DIANはタオバオのミニアプリでCTRを4.74%向上させることが示された。</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1531" target="_blank" rel="noopener noreferrer">Collaborative Contrastive Network for Click-Through Rate Prediction, Chen Gao+, arXiv'24</a>
 の実験で利用されているベースライン</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/CTRPrediction.html" target="_blank" rel="noopener noreferrer">#CTRPrediction</a>
<span class="issue_date">Issue Date: 2024-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1532" target="_blank" rel="noopener noreferrer" class="title-link">Deep Interest Highlight Network for Click-Through Rate Prediction in  Trigger-Induced Recommendation, Qijie Shen+, WWW'22</a>
<span class="snippet"><span>Summary</span>- トリガー誘発推薦（TIR）を提案し、ユーザーの瞬時の興味を引き出す新しい推薦手法を紹介。従来のモデルがTIRシナリオで効果的でない問題を解決するため、Deep Interest Highlight Network（DIHN）を開発。DIHNは、ユーザー意図ネットワーク（UIN）、融合埋め込みモジュール（FEM）、ハイブリッド興味抽出モジュール（HIEM）の3つのコンポーネントから成り、実際のeコマースプラットフォームでの評価で優れた性能を示した。</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1531" target="_blank" rel="noopener noreferrer">Collaborative Contrastive Network for Click-Through Rate Prediction, Chen Gao+, arXiv'24</a>
 の実験で利用されているベースライン</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/IJCNLP.html" target="_blank" rel="noopener noreferrer">#IJCNLP</a>
<a class="button" href="articles/AACL.html" target="_blank" rel="noopener noreferrer">#AACL</a>
<a class="button" href="articles/Repetition.html" target="_blank" rel="noopener noreferrer">#Repetition</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/939" target="_blank" rel="noopener noreferrer" class="title-link">Self-Repetition in Abstractive Neural Summarizers, Nikita Salkar+, N_A,  AACL-IJCNLP'22</a>
<span class="snippet"><span>Summary</span>- 私たちは、BART、T5、およびPegasusという3つのニューラルモデルの出力における自己繰り返しの分析を行いました。これらのモデルは、異なるデータセットでfine-tuningされています。回帰分析によると、これらのモデルは入力の出力要約間でコンテンツを繰り返す傾向が異なることがわかりました。また、抽象的なデータや定型的な言語を特徴とするデータでのfine-tuningでは、自己繰り返しの割合が高くなる傾向があります。定性的な分析では、システムがアーティファクトや定型フレーズを生成することがわかりました。これらの結果は、サマライザーのトレーニングデータを最適化するための手法の開発に役立つ可能性があります。</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/CLIP.html" target="_blank" rel="noopener noreferrer">#CLIP</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/OOD.html" target="_blank" rel="noopener noreferrer">#OOD</a>
<span class="issue_date">Issue Date: 2023-05-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/681" target="_blank" rel="noopener noreferrer" class="title-link">Fine-Tuning can Distort Pretrained Features and Underperform   Out-of-Distribution, Ananya Kumar+, N_A, ICLR'22</a>
<span class="snippet"><span>Summary</span>- 事前学習済みモデルをダウンストリームタスクに転移する際、ファインチューニングと線形プロービングの2つの方法があるが、本研究では、分布のシフトが大きい場合、ファインチューニングが線形プロービングよりも分布外で精度が低くなることを発見した。LP-FTという2段階戦略の線形プロービング後の全体のファインチューニングが、両方のデータセットでファインチューニングと線形プロービングを上回ることを示唆している。</span>
<span class="snippet"><span>Comment</span><p>事前学習済みのニューラルモデルをfinetuningする方法は大きく分けて<br>1. linear layerをヘッドとしてconcatしヘッドのみのパラメータを学習<br>2. 事前学習済みモデル全パラメータを学習<br><br>の2種類がある。<br>前者はin-distributionデータに強いが、out-of-distributionに弱い。後者は逆という互いが互いを補完し合う関係にあった。<br>そこで、まず1を実施し、その後2を実施する手法を提案。in-distribution, out-of-distributionの両方で高い性能を出すことを示した（実験では画像処理系のデータを用いて、モデルとしてはImageNet+CLIPで事前学習済みのViTを用いている)。<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/059d9056-bd3c-45f2-abd9-00c9f2a3d630" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/574" target="_blank" rel="noopener noreferrer" class="title-link">Why do tree-based models still outperform deep learning on typical tabular data?, Grinsztajn+, Soda, Inria Saclay , arXiv'22</a>
<span class="snippet"><span>Comment</span><p>tree basedなモデルがテーブルデータに対してニューラルモデルよりも優れた性能を発揮することを確認し、なぜこのようなことが起きるかいくつかの理由を説明した論文。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/235130988-b008ad89-eec6-49d1-829d-1b23566ed677.jpeg" alt="image" loading="lazy"><br><br><br><br>NNよりもtree basedなモデルがうまくいく理由として、モデルの帰納的バイアスがテーブルデータに適していることを調査している。考察としては<br><br><br><br>1. NNはスムーズなターゲットを学習する能力が高いが、表形式のような不規則なデータを学習するのに適していない<br><br>- Random Forestでは、x軸においてirregularなパターンも学習できているが、NNはできていない。<br><br><img src="https://user-images.githubusercontent.com/12249301/235139592-160cf5fe-dddb-4637-a300-b18a0935f253.png" alt="image" loading="lazy"><br><br><br><br>2. uninformativeなfeaatureがMLP-likeなNNに悪影響を与える<br><br>- Tabular dataは一般にuninformativeな情報を多く含んでおり、実際MLPにuninformativeなfeatureを組み込んだ場合tree-basedな手法とのgapが増加した<br><br><img src="https://user-images.githubusercontent.com/12249301/235140356-553c2d6d-63bf-485e-bcb4-72924535a2a9.png" alt="image" loading="lazy"><br><br><br><br>3. データはrotationに対して不変ではないため、学習手順もそうあるべき（この辺がよくわからなかった）<br><br>- ResNetはRotationを加えても性能が変わらなかった（rotation invariantな構造を持っている）<br><br><img src="https://user-images.githubusercontent.com/12249301/235141633-910e64ff-83d9-417b-b778-6ab3ec7419f2.png" alt="image" loading="lazy"><br><br><br><br></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/553" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models are Zero-Shot Reasoners, Kojima+, University of Tokyo, NeurIPS'22</a>
<span class="snippet"><span>Comment</span><p>Zero-Shot CoT (Let's think step-by-step.)論文</p>
<p>&lt;img width="856" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/234746367-2cd80e23-8dcb-4244-b56c-e28120629027.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/234746367-2cd80e23-8dcb-4244-b56c-e28120629027.png"&lt;/a&gt;


&gt;<br><br></p>
<p>Zero-Shot-CoTは2つのステップで構成される：<br><br>- STEP1: Reasoning Extraction<br><br>  - 元のquestionをxとし、zero-shot-CoTのtrigger sentenceをtとした時に、テンプレート "Q: [X]. A. [T]" を用いてprompt　x'を作成<br><br>  - このprompt x'によって得られる生成テキストzはreasoningのrationaleとなっている。<br><br>- STEP2: Answer Extraction<br><br>  - STEP1で得られたx'とzを用いて、テンプレート "[X'] [Z] [A]" を用いてpromptを作成し、quiestionに対する回答を得る<br><br>  - このとき、Aは回答を抽出するためのtrigger sentenceである。<br><br>  - Aはタスクに応じて変更するのが効果的であり、たとえば、multi-choice QAでは "Therefore, among A through E, the answer is" といったトリガーを用いたり、数学の問題では "Therefore, the answer (arabic numerals) is" といったトリガーを用いる。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/236404426-ed936908-3771-4eef-9871-c6ae04c896bf.png" alt="image" loading="lazy"><br><br><br><br>
<strong># 実験結果<br><br>表中の性能指標の左側はタスクごとにAnswer Triggerをカスタマイズしたもので、右側はシンプルに"The answer is"をAnswer Triggerとした場合。Zero-shot vs. Zero-shot-CoTでは、Zero-Shot-CoTが多くのb現地マークにおいて高い性能を示している。ただし、commonsense reasoningではperformance gainを得られなかった。これは <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
</strong>
<br>
 で報告されている通り、commonsense reasoningタスクでは、Few-Shot CoTでもLambda135Bで性能が向上せず、Palm540Bで性能が向上したように、モデルのparameter数が足りていない可能性がある（本実験では17種類のモデルを用いているが、特に注釈がなければtext-davinci-002を利用した結果）。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/236405336-fe5e1f7f-9d2f-457f-9e25-98afe4ae0ec1.png" alt="image" loading="lazy"><br><br><br><br>
<strong>## 他ベースラインとの比較<br><br>他のベースラインとarithmetic reasoning benchmarkで性能比較した結果。Few-Shot-CoTには勝てていないが、standard Few-shot Promptingtを大幅に上回っている。<br><br><img src="https://user-images.githubusercontent.com/12249301/236406621-7862823f-e019-4551-be96-1c97265ca5ba.png" alt="image" loading="lazy"><br><br><br><br>## zero-shot reasoningにおけるモデルサイズの影響<br><br>さまざまな言語モデルに対して、zero-shotとzero-shot-CoTを実施した場合の性能比較。<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
</strong>
<br>
 と同様にモデルサイズが小さいとZero-shot-CoTによるgainは得られないが、モデルサイズが大きくなると一気にgainが大きくなる。<br><br><img src="https://user-images.githubusercontent.com/12249301/236407727-f29e6f67-8ca1-4623-8341-73bbf2029e67.png" alt="image" loading="lazy"><br><br><br><br>## Zero-shot CoTにおけるpromptの選択による影響<br><br>input promptに対するロバスト性を確認した。instructiveカテゴリ（すなわち、CoTを促すトリガーであれば）性能が改善している。特に、どのようなsentenceのトリガーにするかで性能が大きくかわっている。今回の実験では、"Let's think step by step"が最も高い性能を占め最多。<br><br><img src="https://user-images.githubusercontent.com/12249301/236408268-8dbc32f3-76c7-4e41-aa1b-a19008aa680c.png" alt="image" loading="lazy"><br><br><br><br>## Few-shot CoTのprompt選択における影響<br><br>CommonsenseQAのexampleを用いて、AQUA-RAT, MultiArithをFew-shot CoTで解いた場合の性能。どちらのケースもドメインは異なるが、前者は回答のフォーマットは共通である。異なるドメインでも、answer format（multiple choice）の場合、ドメインが異なるにもかかわらず、zero-shotと比較して性能が大幅に向上した。一方、answer formatが異なる場合はperformance gainが小さい。このことから、LLMはtask自体よりも、exampleにおけるrepeated formatを活用していることを示唆している。また、CommonSennseをExamplarとして用いたFew-Shot-CoTでは、どちらのデータセットでもZero-Shot-CoTよりも性能が劣化している。つまり、Few-Shot-CoTでは、タスク特有のサンプルエンジニアリングが必要であることがわかる（一方、Zero-shot CoTではそのようなエンジニアリングは必要ない）。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/236408978-b292ea0f-0a17-42fc-8e3c-6eee35780ca4.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/551" target="_blank" rel="noopener noreferrer" class="title-link">Chain of thought prompting elicits reasoning in large language models, Wei+, Google Research, NeurIPS'22</a>
<span class="snippet"><span>Comment</span><p>Chain-of-Thoughtを提案した論文。CoTをする上でパラメータ数が100B未満のモデルではあまり効果が発揮されないということは念頭に置いた方が良さそう。<br><br><img src="https://user-images.githubusercontent.com/12249301/234739470-be1c9299-0dd6-4483-901a-0bf855e73f0f.png" alt="image" loading="lazy"><br><br></p>
<p>先行研究では、reasoningが必要なタスクの性能が低い問題をintermediate stepを明示的に作成し、pre-trainedモデルをfinetuningすることで解決していた。しかしこの方法では、finetuning用の高品質なrationaleが記述された大規模データを準備するのに多大なコストがかかるという問題があった。<br><br>このため、few-shot promptingによってこの問題を解決することが考えられるが、reasoning能力が必要なタスクでは性能が悪いという問題あがった。そこで、両者の強みを組み合わせた手法として、chain-of-thought promptingは提案された。</p>
<p># CoTによる実験結果<br><br>以下のベンチマークを利用<br><br>- math word problem: GSM8K, SVAMP, ASDiv, AQuA, MAWPS<br><br>- commonsense reasoning: CSQA, StrategyQA, Big-bench Effort (Date, Sports), SayCan<br><br>- Symbolic Reasoning: Last Letter concatenation, Coin Flip<br><br>  - Last Letter concatnation: 名前の単語のlast wordをconcatするタスク（"Amy Brown" -&gt; "yn"）<br><br>  - Coin Flip: コインをひっくり返す、 あるいはひっくり返さない動作の記述の後に、コインが表向きであるかどうかをモデルに回答するよう求めるタスク<br><br> <br><br>## math word problem benchmark<br><br>- モデルのサイズが大きくなるにつれ性能が大きく向上（emergent ability）することがあることがわかる<br><br>  - 言い換えるとCoTは&lt;100Bのモデルではパフォーマンスに対してインパクトを与えない<br><br>  - モデルサイズが小さいと、誤ったCoTを生成してしまうため<br><br>- 複雑な問題になればなるほど、CoTによる恩恵が大きい<br><br>  - ベースラインの性能が最も低かったGSM8Kでは、パフォーマンスの2倍向上しており、1 stepのreasoningで解決できるSingleOpやMAWPSでは、性能の向上幅が小さい<br><br>- Task specificなモデルをfinetuningした以前のSoTAと比較してcomparable, あるいはoutperformしている<br><br>- <img src="https://user-images.githubusercontent.com/12249301/236394200-826ba167-8ec7-4abb-ba4d-fe44bf247b41.png" alt="image" loading="lazy"><br><br>## Ablation Study<br><br>CoTではなく、他のタイプのpromptingでも同じような効果が得られるのではないか？という疑問に回答するために、3つのpromptingを実施し、CoTと性能比較した：<br><br>- Equation Only: 回答するまえに数式を記載するようなprompt<br><br>  - promptの中に数式が書かれているから性能改善されているのでは？という疑問に対する検証<br><br>  - =&gt; GSM8Kによる結果を見ると、equation onlyでは性能が低かった。これは、これは数式だけでreasoning stepsを表現できないことに起因している<br><br>- Variable compute only: dotのsequence (...) のみのprompt<br><br>  - CoTは難しい問題に対してより多くの計算（intermediate token）をすることができているからでは？という疑問に対する検証<br><br>  - variable computationとCoTの影響を分離するために、dotのsequence (...) のみでpromptingする方法を検証<br><br>  - =&gt; 結果はbaselineと性能変わらず。このことから、variableの計算自体が性能向上に寄与しているわけではないことがわかる。<br><br>- Chain of Thought after answer: 回答の後にCoTを出力するようなprompting<br><br>  - 単にpretrainingの際のrelevantな知識にアクセスしやすくなっているだけなのでは？という疑問を検証<br><br>  - =&gt; baselineと性能は変わらず、単に知識を活性化させるだけでは性能が向上しないことがわかる。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/236396383-877a26ae-20c2-42a4-a023-1eb66abf8320.png" alt="image" loading="lazy"><br><br><br><br>## CoTのロバスト性<br><br>人間のAnnotatorにCoTを作成させ、それらを利用したCoTpromptingとexamplarベースな手法によって性能がどれだけ変わるかを検証。standard promptingを全ての場合で上回る性能を獲得した。このことから、linguisticなstyleにCoTは影響を受けていないことがわかる。<br><br><img src="https://user-images.githubusercontent.com/12249301/236397864-073dd88f-95c0-47f0-af3c-ed7288ca967d.png" alt="image" loading="lazy"><br><br><br><br># commonsense reasoning<br><br>全てのデータセットにおいて、CoTがstandard promptingをoutperformした。<br><br><img src="https://user-images.githubusercontent.com/12249301/236398447-6c58a3f3-7461-4109-9a96-8f8092831dd1.png" alt="image" loading="lazy"><br><br><br><br># Symbolic Reasoning<br><br>in-domain test setとout-of-domain test setの2種類を用意した。前者は必要なreasoning stepがfew-shot examplarと同一のもの、後者は必要なreasoning stepがfew-shot examplarよりも多いものである。<br><br>CoTがStandard proimptingを上回っている。特に、standard promptingではOOV test setではモデルをスケールさせても性能が向上しなかったのに対し、CoTではより大きなgainを得ている。このことから、CoTにはreasoning stepのlengthに対しても汎化能力があることがわかる。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/236399389-30e62218-3e59-4912-983c-818de457fa04.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2022-12-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/501" target="_blank" rel="noopener noreferrer" class="title-link">UNIFIEDSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models, Xie+, EMNLP'22</a>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<span class="issue_date">Issue Date: 2022-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/475" target="_blank" rel="noopener noreferrer" class="title-link">Using Neural Network-Based Knowledge Tracing for a Learning System with Unreliable Skill Tags, Karumbaiah+, （w_ Ryan Baker）, EDM'22</a>
<span class="snippet"><span>Comment</span><p>超重要論文。しっかり読むべき</p>
<p># 一言で言うと<br><br>KTを利用することを最初から念頭に置いていなかったシステムでは、問題に対して事後的にスキルをマッピングする作業が生じてしまい、これは非常に困難なことが多い。論文中で使用したアメリカの商用の数学のblended learningのシステムのデータでは、途中で企業が買収された経緯もあり、古いコンテンツと新しいコンテンツの間でスキルタグのマッピングの間で、矛盾や一貫性がないものができあがってしまった（複数の異なるチームがコンテンツの提供やスキルのタグ付けを行なった結果）。このような例はレアケースかもしれないが、問題とスキルタグが異なるチームによって開発されるということは珍しいことではないし、現代のオンライン学習システムの多くは、さまざまな教科書のデータを統合し、長年にわたってコンテンツ作成チームのメンバーを変更し、複数の州の基準や内部コンテンツスキーマに従ってコンテンツにタグをづけをしているので、少なからずこういった問題（i.e. 一貫性がなく、矛盾をかかえたitem-skill mapping）を抱えている。<br><br><br><br>こうした中で、NNを用いたモデルを用いることで、unreliableなKCモデルを用いるくらいならば、KCモデルを用いない方が正答率予測が高い精度で実施できることを示した。これは少なくとも、生徒の問題に対する将来のパフォーマンスを予測する問題に関して言えば、既存のアプリケーションにおいて、KCモデルを構築するステップを回避できる可能性を示唆している。<br><br><br><br># モチベーション<br><br>Cognitive Tutorのようなシステムは、もともとKTを利用するために設計されているシステムだったが、多くのreal-worldの学習システムはアダプティブラーニングやKTを念頭に置いて作られたものではない。そういったシステムでアダプティブな機能を追加するといった事例が増えてきている。こういったシステムが、もともとKTを実施することを念頭するために作られたシステムとの違いとして、問題とスキルのマッピング方法にある。<br><br>最初から KT を使用するように設計されたシステムは、最初にどのスキルを含めるかを選択し、次にそれらのスキルに合わせたアイテムを開発する。 一方、KTを使用するために改良をする場合、最初にアイテムが作成され、次にアイテムにスキルのラベルが付けられる。<br><br>既存のアイテムにスキルのラベルを付けるのは、スキルの新しいアイテムを作成するよりもはるかに困難である。 多くの場合、アイテムは複数の著者によって時間をかけて開発されたものであるか、異なる教科書などの異なる元のソースからのものである。この異種のコンテンツ (場合によっては数万のアイテム) を一連のスキルにマッピングすることは、非常に困難な作業になる可能性がある。<br><br>多くの場合、アイテムは政府のカリキュラム基準の観点からタグ付けされているが、これらの基準は一般的に、KTモデルで使用されるスキルよりも非常に粗いものとなっている。<br><br>したがって、最初からKTを利用することを念頭に置かれていないシステムでKTを利用することには課題がある。<br><br>この論文では、NNベースなKTモデルが、この課題の部分的な解決策になることを示す。<br><br>このために、商用の数学のblended learningシステムでのケーススタディを実施した。<br><br>中学生が 2 年間システムを使用して収集したデータを使用して、KT モデルの性能を次の3 つのシナリオで比較し：<br><br>- 1) システムが提供する (おそらくunreliableな)スキルタグを利用した場合<br><br>- 2) 州の基準に基づくタグを利用した場合<br><br>- 3) コンテンツとスキルタグのマッピングを一切入力しない場合<br><br>DKVMNでの実験の結果、1)が最も悪い性能を示し、3)が最も良い問題の正誤予測の性能を示した。<br><br>これは、もともとKT モデルで動作するように設計されていなかった現実世界の学習システムでKCモデリングを回避する可能性を示唆している。特に、目的が将来のアイテムに対する学習者の成績を予測することだけである場合はこれに該当する。<br><br><br><br># 実験結果<br><br><img src="https://user-images.githubusercontent.com/12249301/187153287-b90e96a5-8089-4243-ae91-6997bfc55aaa.png" alt="image" loading="lazy"><br><br><br><br>スキルの情報を用いず、ExerciseIDをそのままinputする方法が、最も高いAUCを獲得している。<br><br><br><br># つまり<br><br>- きちんと一貫性があり矛盾のないItem-KCマッピングを用いないとモデルがきちんと学習できない<br><br>    - 特に元々KTを適用することを念頭に置いていないシステムでは困難な作業となる可能性が高い</p>
<p># KTの歴史<br><br>- 30年ほど研究されている（1995年のCorbett and AndersonらのBKTあたりから）<br><br>- 最初はBKTが広く採用された<br><br>- その後、最近ではlogistic regressionに基づくモデルが提案されるようになってきたが、実際のシステムで利用されることはまだ稀<br><br>- Elo や Temporal IRT などのIRTに関連するアルゴリズムも、最近文献でより広く見られるようになり、いくつかの学習システムで大規模に使用されている<br><br>    - Elo およびTemporal IRT は KCモデルなしで使用できるが、通常、いくつかのスキルごとに個別の Elo モデルが利用される。<br><br>- NNベースなモデルは過去5年で活発に研究され、将来のパフォーマンスを予測する性能は飛躍的に向上した<br><br>    - ただし、予測不可能な動作（reconstruction problemや習熟度のfluctuation）や、mastery learningや生徒にスキルをレポーティングするためにこのタイプのモデルを用いるという課題のために、実際のシステムで運用するよりも、論文を執筆する方が一般的になった。<br><br>    - これに関するNNモデルの問題の1 つは、特定の問題の正答率を予測するが、それを人間が解釈できるスキルの習熟度にマッピングしないことにある。</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<a class="button" href="articles/Contents-based.html" target="_blank" rel="noopener noreferrer">#Contents-based</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2022-08-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/463" target="_blank" rel="noopener noreferrer" class="title-link">GRAM: Fast Fine-tuning of Pre-trained Language Models for Content-based   Collaborative Filtering, Yoonseok Yang+, NAACL'22</a>
<span class="snippet"><span>Summary</span>- コンテンツベースの協調フィルタリング（CCF）において、PLMを用いたエンドツーエンドのトレーニングはリソースを消費するため、GRAM（勾配蓄積手法）を提案。Single-step GRAMはアイテムエンコーディングの勾配を集約し、Multi-step GRAMは勾配更新の遅延を増加させてメモリを削減。これにより、Knowledge TracingとNews Recommendationのタスクでトレーニング効率を最大146倍改善。</span>
<span class="snippet"><span>Comment</span><p>RiiiDがNAACL'22に論文通してた</p></span><br><br>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<span class="issue_date">Issue Date: 2022-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/453" target="_blank" rel="noopener noreferrer" class="title-link">Empirical Evaluation of Deep Learning Models for Knowledge Tracing: Of Hyperparameters and Metrics on Performance and Replicability, Sami+, Aalto University, JEDM'22</a>
<span class="snippet"><span>Comment</span><p>DKTの説明が秀逸で、元論文では書かれていない分かりづらいところまできちんと説明してくれている。<br><br>（inputは(スキルタグ, 正誤)のtupleで、outputはスキルタグ次元数のベクトルyで、各次元が対応するスキルのmasteryを表しており、モデルのtrainingはnext attemptに対応するスキルのprobabilityのみをyから抽出しBinary Cross Entropyを計算する点、など）<br><br><img src="https://user-images.githubusercontent.com/12249301/165704985-37cb5c85-d19d-4c39-b30b-db6f565a7a85.png" alt="image" loading="lazy"><br><br></p>
<p>入力や出力の仕方によって性能がどの程度変化しているかを検証しているのがおもしろい。<br><br>- Input: one-hot encoding (one hot vectorをinputする) vs. embedding layer (embeddingをinputする)<br><br>- Output: output per skill (スキルタグの次元数を持つベクトルyをoutputする) vs. skills-to-scalar output （skill summary layer + Scalar; 次のattemptに対する正答率のみをscalarでoutputする）<br><br><br><br>下図ではDKTの例が書かれているが、DKVMNやSAKTでもこれらの違いは適用可能。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/165728064-e953278b-c45b-4447-87c1-8913429436e6.png" alt="image" loading="lazy"><br><br><br><br>output per skillで出力をすれば、Knowledge TrackingはDKTと同様どのようなモデルでも可能なのではないか。<br><br><br><br>◆Inputについて<br><br>基本的には大きな差はないが、one-hot encodingを利用した場合、DKVMN-PaperとSAKTがembeddingと比較して3.3~4.6%程度AUCが悪くなることがあった。<br><br>最高の性能を模索したい時はembedding layerを利用し、one-hot encodingはハイパーパラメータの選択をミスった場合でもロバストな結果（あまり性能が悪化しなかった）だったので、より安全な選択肢と言える。<br><br><br><br>◆Outputについて<br><br>全体として、DKT（およびDKTの亜種）については、output per skillの方が良かった。<br><br>DKVMNはこれとは逆で、skills-to-scalar outputの方が性能が良かった。<br><br>SAKTではoutput per skillの方がworst scoreがskills-to-scalar outputよりも高いため、よりrobustだと判断できる。</p>
<p>結論：<br><br>1. Deep Learning basedなモデルはnon-deep learning basedなモデルやシンプルなベースラインよりも一般的に予測性能が良い<br><br>2. LSTMを用いたDKT(LSTM-DKT), LSTM-DKTに次のexerciseのスキルタグ情報をconcatして予測をするDKT（LSTM-DKT-S）, DKVMNの性能がDeep Learning Basedな手法では性能が良かった。が、Deep Learningベースドなモデルの間での性能の差は僅かだった（SAKTとも比較している）。<br><br>3. one-hot encoding vs. embedding layer, output per skill vs. skills-to-scalar output については、最大で4.6%ほどAUCの変化があり（SAKTにone-hot encodingを入力した場合embeddingを利用しない場合よりも4.6%ほど性能が低下している）、パフォーマンスに大きな違いをもたらした</p>
<p>論文中のDKVMN, DKVMN-Paperの違いは、著者が実装を公開しているMXNetの実装だと論文（Paper）に書かれているアーキテクチャと実装が違うのでDKVMNとして記述している。DKVMN-Paperは論文通りに実装したものを指している。</p>
<p>この研究では、KTする際に全てのDeep Learning basedなモデル（DKT, DKVMN, SAKT）において、入力の系列をx_tを(s_t, c_t)で表現し検証している。s_tはスキルタグで、c_tは正解したか否か。<br><br>outputも output-per-skill の場合は、スキルタグ次元のベクトルとなっている。</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2021-06-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/379" target="_blank" rel="noopener noreferrer" class="title-link">Improving Neural Machine Translation with Compact Word Embedding Tables, Kumar+, AAAI'22</a>
<span class="snippet"><span>Comment</span><p>NMTにおいてword embeddingがどう影響しているかなどを調査しているらしい</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/PMLR.html" target="_blank" rel="noopener noreferrer">#PMLR</a>
<span class="issue_date">Issue Date: 2025-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2583" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Feature Learning in Infinite-Width Neural Networks, Greg Yang+, PMLR'21</a>
<span class="snippet"><span>Summary</span>- 無限幅の深層ニューラルネットワークにおいて、標準およびNTKパラメータ化は特徴学習を可能にする限界を持たないことを示し、これを克服するための修正を提案。Tensor Programs技術を用いて限界の明示的な式を導出し、Word2VecやMAMLを用いた少数ショット学習でこれらの限界を計算。提案手法はNTKベースラインや有限幅ネットワークを上回る性能を示し、特徴学習を許可するパラメータ化の空間を分類。</span>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RecSys.html" target="_blank" rel="noopener noreferrer">#RecSys</a>
<span class="issue_date">Issue Date: 2025-04-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1891" target="_blank" rel="noopener noreferrer" class="title-link">Revisiting the Performance of iALS on Item Recommendation Benchmarks, Steffen Rendle+, arXiv'21</a>
<span class="snippet"><span>Summary</span>- iALSを再検討し、調整を行うことで、レコメンダーシステムにおいて競争力を持つことを示す。特に、4つのベンチマークで他の手法を上回る結果を得て、iALSのスケーラビリティと高品質な予測が再評価されることを期待。</span>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Grokking.html" target="_blank" rel="noopener noreferrer">#Grokking</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/524" target="_blank" rel="noopener noreferrer" class="title-link">GROKKING: GENERALIZATION BEYOND OVERFIT- TING ON SMALL ALGORITHMIC DATASETS, Power+, ICLR'21 Workshop</a>
<span class="snippet"><span>Comment</span><p>学習後すぐに学習データをmemorizeして、汎化能力が無くなったと思いきや、10^3ステップ後に突然汎化するという現象（Grokking）を報告<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/234430324-a23b7210-c5ac-4b29-8640-ed9458ae2e7a.png" alt="image" loading="lazy"><br><br></p>
<p>学習データが小さければ小さいほど汎化能力を獲得するのに時間がかかる模様</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Game.html" target="_blank" rel="noopener noreferrer">#Game</a>
<span class="issue_date">Issue Date: 2022-09-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/487" target="_blank" rel="noopener noreferrer" class="title-link">Generating Racing Game Commentary from Vision, Language, and Structured Data, Tatsuya+, INLG'21</a>
<span class="snippet"><span>Comment</span><p>データセット: 


<a href="https://kirt.airc.aist.go.jp/corpus/ja/RacingCommentary" target="_blank" rel="noopener noreferrer">https://kirt.airc.aist.go.jp/corpus/ja/RacingCommentary</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<span class="issue_date">Issue Date: 2022-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/477" target="_blank" rel="noopener noreferrer" class="title-link">Behavioral Testing of Deep Neural Network Knowledge Tracing Models, Kim+, Riiid, EDM'21</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2022-08-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/472" target="_blank" rel="noopener noreferrer" class="title-link">Biomedical Data-to-Text Generation via Fine-Tuning Transformers, Ruslan+, INLG'21</a>
<span class="snippet"><span>Comment</span><p>biomedical domainの新たなdata2textデータセットを提供。事前学習済みのBART, T5等をfinetuningすることで高精度にテキストが生成できることを示した。</p></span><br><br>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<span class="issue_date">Issue Date: 2022-05-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/456" target="_blank" rel="noopener noreferrer" class="title-link">Learning Process-consistent Knowledge Tracing, Shen+, SIGKDD'21</a>
<span class="snippet"><span>Comment</span><p>DKTでは問題を間違えた際に、対応するconceptのproficiencyを下げてしまうけど、実際は間違えても何らかのlearning gainは得ているはずだから、おかしくね？というところに端を発した研究。<br><br>student performance predictionの性能よりも、Knowledge Tracingのクオリティーにもっと焦点を当てようよという主張をした論文。<br><br>Forgettingもモデル化しているところが特徴。<br><br>現在は引用数2だけど、この課題感は非常に重要で、重要論文だと思う。</p>
<p># モチベ<br><br>下図はDKTによる習熟度の変化を表しており赤枠で囲まれている部分は、問題に不正解した際に習熟度が下がることを示している。しかし実際な問題に間違っていたとしても何らかのLearning Gainを得ているはずであり、この挙動はcognitive theoryに反している。実際に先行研究では、エラーは学習において自然な要素であり、学習者はエラーから学び、好ましいエラーによって学習を促進できることを指摘している。<br><br><img src="https://user-images.githubusercontent.com/12249301/168034969-a72ba6f9-55b9-44c9-a97d-dbcb4b51f45d.png" alt="image" loading="lazy"><br><br><br><br>これまでのknowledge tracing研究が、student performance predictionの性能ばかりにフォーカスされているのに対し、本研究では、Knowledge Tracingの解釈性とstudent performance predictionのaccuracyの両方にフォーカスしている。<br><br><br><br># Problem Definition<br><br>本研究では、1学習の基本要素（learning cell）は exercise-answertime-correctness の3つ組によって表現され、learning cell同士は、interval timeによって隔たれていると考える。answertimeを導入することで、学習者のlearning processを表現する能力を高め、interval timeはLearning Gainを算出する際に役立てる（一般的にinterval timeが短い方がより多くのknowledgeを吸収する傾向にあるなど、interval timeはlearning gainの多様性を捉えるのに役立つ）。<br><br>つまり、学習の系列は x = {(e1, at1, a1),it1, (e2, at2, a2),it2, ...,(et, att, at ),itt } と表せる。<br><br>KTタスクは、t+1時点での生徒のknowledge stateと、生徒のパフォーマンスを予測する問題として表せる。<br><br><br><br># モデル<br><br>学習者のLearning Processをきちんとモデル化することに念頭をおいている。具体的には、①学習者は学習を通じて常に何らかのLearning Gain（ある2点間でのパフォーマンスの差; 本研究では前回の学習と今回の学習の両方のlearning cell + interval time + 前ステップでのknowledge stateからLGを推定）を得ており、②忘却曲線にならい学習者は時間がたつと学習した内容を忘却していき（anwertimeとinterval timeが関係する）、③現在のknowledge stateから正誤予測が実施される。<br><br>モデルの全体像が下図であり、①がLearning Module, ②がForgetting Module, ③がPredicting Moduleに相当している。<br><br><img src="https://user-images.githubusercontent.com/12249301/168040927-e37feae7-5525-44fa-97f5-9219b1981aea.png" alt="image" loading="lazy"><br><br><br><br>## Embedding<br><br>本研究ではTime EmbeddingとLearning Embedding, Knowledge Embeddingの三種類のEmbeddingを扱う。<br><br>### Time Embedding<br><br>answer timeとinterval timeをembeddingで表現する。両者はスケールが異なるため、answer timeは秒で、interval timeは分でdiscretizeしone-hot-encodingし、Embeddingとして表現する。ここで、interval timeが1ヶ月を超えた場合は1ヶ月として表現する。<br><br>### Learning Embedding<br><br>learning cellをembeddingで表現する。exercise, answertime, correctnessそれぞれをembeddingで表現し、それらをconcatしMLPにかけることでlearning embeddingを獲得する。ここで、correctnessのembeddingは、正解の場合は全ての要素が1のベクトル, 不正解の場合は全ての要素が0のベクトルとする。<br><br><img src="https://user-images.githubusercontent.com/12249301/168043953-40d1c682-cb61-4ca1-b57f-847b5e51e212.png" alt="image" loading="lazy"><br><br>### Knowledge Embedding<br><br>学習プロセスにおけるknowledge stateの保存とアップデートを担うEmbedding。<br><br>Knowledge Embedding h は、(M x dk)次元で表され、Mはknowledge conceptの数である。すなわち、hの各行が対応するknowledge conceptのmasteryに対応している。learning interactionにおいて、それぞれのknowledge conceptに対するlearning gainや、忘却効果をknowledge embeddingを更新することによって反映させる。<br><br><br><br>また、knowledge embeddingを更新する際にはQ-matrixを利用する。Q-matrixは、exerciseとknowledge conceptの対応関係を表した行列のことである。Qjmが1の場合、exercise ej が knowledge concept km と関係していることを表し、そうでない場合は0でQ-matrixは表現される。もし値が0の場合、exercise ej のパフォーマンスは、knowledge concept km のmasteryに一切影響がないことを表している。が、人手て定義されたQ-matrixはエラーが含まれることは避けられないし、主観的なバイアスが存在するため、本研究ではこれらの影響（Q-matrix上の対応関係の見落としや欠落）を緩和するためにenhanced Q-matrix q (J x M次元）を定義する。具体的には、通常のQ-matrixで値が0となる部分を、小さな正の値γとしてセットする。<br><br>今回はこのようなシンプルなenhanced Q-matrixを利用するが、どのようなQ-matrixの定義が良いかはfuture workとする。<br><br><br><br>## Learning Module<br><br>learning gainを測るためのモジュール。2つの連続したlearning interactionのパフォーマンスの差によってgainを測定する（learning embeddingを使う）。ただこれだけではlearning gainの多様性を捉えることができないため（たとえば同じ連続したlearning embeddingを持って生徒がいたとしてもlearning gainが一緒とは限らない）、interval timeとprevious knowledge stateを活用する。<br><br>interval timeはlearning processの鍵となる要素の一つであり、これはlearning gainの差異を反映してる。一般tネキには、interval timeが短い方が生徒はより多くの知識を獲得する傾向にある。<br><br>さらに、previous knowledge stateもlearning gainに関係しており、たとえばmasteryが低い生徒は改善の可能性が非常に高い。<br><br>previous knowledge stateを利用する際は、現在のexerciseと関連するknowledge conceptにフォーカスするために、knowledge embeddingをknowledge concept vector q_etとの内積をとり、関連するknowledge conceptのknowledge stateを得る：<br><br>&lt;img width="383" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/168086129-262c1154-9d12-43fe-b5bd-cf6c84f2dffe.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/168086129-262c1154-9d12-43fe-b5bd-cf6c84f2dffe.png"&lt;/a&gt;


&gt;<br><br><br><br>（q_etの詳細が書かれていないので分からないが、おそらくenhanced Q-matrixのexercise e_tに対応する行ベクトルだと思われる。e_tと関連するknowledge conceptと対応する要素が1で、その他が正の定数γのベクトル）<br><br><br><br>そしてlearning gain lg_t (dk次元ベクトル)は2つの連続したlearning embedding, と現在の問題と関連するknowledge stateとinterval time embeddingをconcatしMLPにかけることで算出する。<br><br>&lt;img width="398" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/168086638-dffd60dc-4bd6-4da2-ba4b-6749e1a9bb6b.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/168086638-dffd60dc-4bd6-4da2-ba4b-6749e1a9bb6b.png"&lt;/a&gt;


&gt;<br><br><br><br>さらに、全てのlearning gainが生徒のknowledgeの成長に寄与するとは限らないので、生徒の吸収能力を考慮するために learning gate Γ^l_t (dk次元ベクトル)を定義する（learning gainと構成要素は同じ）：<br><br>&lt;img width="467" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/168087058-bb5e6e13-aaa2-46f8-ac1f-777f5b6c57de.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/168087058-bb5e6e13-aaa2-46f8-ac1f-777f5b6c57de.png"&lt;/a&gt;


&gt;<br><br><br><br>そして先ほど求めたlearning gateとlearning gainの内積をとり、さらにknowledge concept vector q_etとの内積をとることで、ある時刻tのexercise e_tにと関連するknowledge conceptのlearning gain ~LG_tを得る：<br><br>&lt;img width="415" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/168087419-05e777ae-d2a6-4342-9b39-8df163d97fe9.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/168087419-05e777ae-d2a6-4342-9b39-8df163d97fe9.png"&lt;/a&gt;


&gt;<br><br>ここで、(lg_t+1)/2しているのは、tanhの値域が（-1, 1）なためであり、これにより値域を(0, 1)に補正している。従ってLG_tは常に正の値となる。これは、本研究の前提である、生徒はそれぞれのlearning interactionから知識を着実に獲得しているという前提を反映している。<br><br><br><br>## Forgetting Module<br><br>~LG_tは生徒のknowledge stateを向上させる働きをするが、反対の忘却現象は、時間が経つにつれてどれだけの知識が忘れられるかに影響します。forgetting curve theoryによると、記憶されている学習教材の量は時間経過に従い指数的に減衰していく。しかしながら、knowledge stateとinterval timeの複雑な関係性を捉えるためには、manual-designedな指数減衰関数では十分ではない。<br><br>そこで、forgetting effectをモデル化するために、forgetting gate Γ^f_tを導入する。これは、knowledge embeddingから3つの要素をMLPにかけることで失われる情報の度合いを学習するしたものであり、その3つの要素とは (1) 生徒のprevious knowledge state h_t-1, (2)生徒の現在のlearning gain LG_t, (3) interval time it_tである。<br><br>これらを用いてforgetting gate (dk次元) は以下のように計算される：<br><br>&lt;img width="457" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/168101254-29019294-56be-4b92-99b3-360554bf58fd.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/168101254-29019294-56be-4b92-99b3-360554bf58fd.png"&lt;/a&gt;


&gt;<br><br>forgetting gateをh_t-1と積をとることで、忘却の影響を考慮することができる。そして、生徒がt番目のlearning interactionを完了した後のknowledge state h_tは次の式で更新される：<br><br>&lt;img width="391" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/168101820-90958bfc-4c4c-4a46-ab00-3efaa10aeb42.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/168101820-90958bfc-4c4c-4a46-ab00-3efaa10aeb42.png"&lt;/a&gt;


&gt;<br><br><br><br>## Predicting Module<br><br>これでlearning gainとforgetting effectの両方を考慮した生徒のknowledge state h_tが算出できたので、これをe_t+1のexerciseのperformance予測に活用する。e_t+1を生徒が解く時は、対応するknowledge conceptを適用することで回答をするので、knowledge stateのうち、e_t+1と関連するknowledge state ~h_tを利用する（knowledge concept vector q_et+1との内積で求める）。式で表すと下記になる：<br><br>&lt;img width="424" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/168102734-2a53305e-ab34-4e7d-b9c6-dbcc1d8f8eb5.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/168102734-2a53305e-ab34-4e7d-b9c6-dbcc1d8f8eb5.png"&lt;/a&gt;


&gt;<br><br>~h_tにexercise e_t+1のembeddingをconcatしてMLPにかけている。<br><br><br><br># Objective Function<br><br>正則化項つきのcross-entropy log lossを利用する。<br><br>&lt;img width="548" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/168103089-0e3f4f21-8d77-4bd1-8ec5-07425cc4833b.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/168103089-0e3f4f21-8d77-4bd1-8ec5-07425cc4833b.png"&lt;/a&gt;


&gt;<br><br></p>
<p># 実験結果<br><br>## knowledge tracingの結果<br><br>&lt;img width="1017" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/168103305-2a0a100d-3122-4d9f-ac20-f5706ef44173.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/168103305-2a0a100d-3122-4d9f-ac20-f5706ef44173.png"&lt;/a&gt;


&gt;<br><br>先述のDKTの例とは異なり、問題の回答に誤っていたとしてもproficiencyが向上するようになっている。ただ、e_7が不正解となっている際に、proficiencyが減少していることもわかる。これは、モデルがproficiencyの推定をまだしっかりできていない状態だったため、モデル側がproficiencyを補正したためだ、と論文中では述べられているが、こういった現象がどれだけ起きるのだろうか。こういう例があると、図中の赤枠はたまたま不正解の時にproficiencyが向上しただけ、というふうにも見えてしまう（逆に言うとDKTでも不正解の時にproficiencyが向上することはあるよねっていう）。<br><br>また、忘却効果により時間経過に伴い、proficiencyが減少していることもわかる。ただ、この現象もDKTの最初の例でもたとえば①の例はproficiencyが時間経過に伴い減少していっていたし、もともとDKTでもそうなってたけど？と思ってしまう。<br><br>ただ、②についてはDKTの例ではproficiencyが時間経過に伴い減少して行っていなかったため、LPKTではきちんとforgetting effectがモデリングできていそうでもある。また、図中右では、最初のinteractionと各knowledge conceptの習熟度の最大値、最後のinteraction時の習熟度がレーダーチャートとして書かれており、学習が進むにつれてどこかで習熟度は最大値となり、忘却効果によって習熟度は下がっているが、学習の最初よりは習熟度が高く弱実に学習が進んでいますよ、というのを図示している。interactionをもっと長く続けた際に（あるknowledge conceptを放置し続けた際に）、忘却効果によってどの程度習熟度がshrinkするのかが少し気になる（習熟度が大きくなった状態が時間発展しても維持されるということが、このモデルでは存在しないのでは？）。<br><br><br><br>=&gt; Knowledge Tracingの結果については、cherry pickingされているだけであって、全体として見たらどれだけ良くなっているかが正直分からないんじゃないか、という感想。<br><br><br><br>## student performance predictoin<br><br>&lt;img width="996" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/168105090-d463cf7b-c769-4e59-b4ae-f920c5873a4f.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/168105090-d463cf7b-c769-4e59-b4ae-f920c5873a4f.png"&lt;/a&gt;


&gt;<br><br>全てのベースラインに勝っている。特に系列長の長いASSISTchallでAKTに対して大きく勝っており、系列長の長いデータに対してもrobustであることがわかる。<br><br><br><br>## Ablation Study<br><br>learning module, forgetting module, time embeddingをablationした場合に性能がどう変化するかを観察した。forgetting moduleをablationした場合に、性能が大きく低下しているので、forgetting moduleの重要性がわかる。おもしろいのは、time embeddingを除いてもあまり性能は変化していないので、実際はstudent performance predictionするだけならtime embeddingはあまり必要ないのかもしれない。が、論文中では「time embedding (answer timeとinterval time)を除外するのはlearning processを正確にモデル化する上でharmfulだ」と言及しているに留まっており、具体的にどうharmfulなのかは全くデータが提示されていない。time embeddingを除外したことでknowledge tracingの結果がどう変化するのかは気になるところではある、が、実はあまり効いていないんじゃない？という気もする。<br><br>&lt;img width="483" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/168105293-ab203fa8-a6cc-4ff7-9750-659e39add4ee.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/168105293-ab203fa8-a6cc-4ff7-9750-659e39add4ee.png"&lt;/a&gt;


&gt;<br><br><br><br>## Exercises Clustering<br><br>最後に、学習したexerciseのembeddingをt-SNEで可視化しクラスタリングしている。クラスタリングした結果、共通のknowledge conceptを持つexercise同士はある程度同じクラスタに属する例がいくつか見受けられるような結果となっている。<br><br>&lt;img width="496" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/168106245-d578baad-916e-4e78-8fb7-9bf604617f93.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/168106245-d578baad-916e-4e78-8fb7-9bf604617f93.png"&lt;/a&gt;


&gt;<br><br><br><br># 所感<br><br>answer timeとinterval timeのデータがなくても高い性能で予測ができそうなのでアリ。ただ、そういった場合にknowledge tracingの結果がどうなるかが不安要素ではある。もちろんanswer timeとinterval timeが存在するのがベストではあるが。<br><br>また、DKT+で指摘されているような、inputがreconstructionされない問題や、proficiencyが乱高下するといった現象が、このモデルにおいてどの程度起きるのかが気になる。<br><br>DKTのようなシンプルなモデルではないので、少しは解消されていたりするのだろうか。実用上あのような現象が生じるとかなり困ると思う。</p>
<p>KCのproficiencyの可視化方法について論文中に記述されていないが、下記リポジトリのIssue 29で質問されている。<br><br>knowledge matrix hは各KCのproficiencyに関する情報をベクトルで保持しており、ベクトルをsummationし、シグモイド関数をかけることで0.0~1.0に写像しているとのこと。</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<span class="issue_date">Issue Date: 2022-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/454" target="_blank" rel="noopener noreferrer" class="title-link">BEKT: Deep Knowledge Tracing with Bidirectional Encoder Representations from Transformers, Tian+ （緒方先生）, Kyoto University, ICCE'21</a>
<span class="snippet"><span>Comment</span><p>KTにBERTを利用した研究<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/453" target="_blank" rel="noopener noreferrer">Empirical Evaluation of Deep Learning Models for Knowledge Tracing: Of Hyperparameters and Metrics on Performance and Replicability, Sami+, Aalto University, JEDM'22</a>
 などでDeepLearningBasedなモデル間であまり差がないことが示されているので、本研究が実際どれだけ強いのかは気になるところ。</p></span><br><br>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2022-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/452" target="_blank" rel="noopener noreferrer" class="title-link">Do we need to go Deep? Knowledge Tracing with Big Data, Varun+, University of Maryland Baltimore County, AAAI'21 Workshop on AI Education</a>
<span class="snippet"><span>Summary</span>- インタラクティブ教育システム（IES）を用いて学生の知識を追跡し、パフォーマンスモデルを開発する研究が進展。深層学習モデルが従来のモデルを上回るかは未検証であり、EdNetデータセットを用いてその精度を比較。結果、ロジスティック回帰モデルが深層モデルを上回ることが確認され、LIMEを用いて予測に対する特徴の影響を解釈する研究を行った。</span>
<span class="snippet"><span>Comment</span><p>データ量が小さいとSAKTはDKTはcomparableだが、データ量が大きくなるとSAKTがDKTを上回る。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/165698674-279a7e0c-6429-48db-8c71-f61b5744d44a.png" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<span class="issue_date">Issue Date: 2022-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/450" target="_blank" rel="noopener noreferrer" class="title-link">An Empirical Comparison of Deep Learning Models for Knowledge Tracing on Large-Scale Dataset, Pandey+, AAAI workshop on AI in Education'21</a>
<span class="snippet"><span>Comment</span><p>EdNetデータにおいて、DKT, DKVMN, SAKT, RKTの性能を比較した論文<br><br><img src="https://user-images.githubusercontent.com/12249301/165658767-24fda9a1-3ff1-47d1-b328-91fa18aec82e.png" alt="image" loading="lazy"><br><br>RKTがも最もパフォーマンスが良く、SAKTもDKT, DKVMNに勝っている</p></span><br><br>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<span class="issue_date">Issue Date: 2022-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/448" target="_blank" rel="noopener noreferrer" class="title-link">A Survey of Knowledge Tracing, Liu+, IEEE Transactions on Learning Technologies, arXiv'21</a>
<span class="snippet"><span>Comment</span><p>古典的なBKT, PFAだけでなくDKT, DKVMN, EKT, AKTなどDeepなモデルについてもまとまっている。<br><br><img src="https://user-images.githubusercontent.com/12249301/165438026-70f407c9-8eb2-43c3-8a0b-84e1f55708c4.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/165438375-e571ab57-598f-470d-b3ee-4019392e9e81.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2021-11-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/431" target="_blank" rel="noopener noreferrer" class="title-link">ResNet strikes back: An improved training procedure in timm, Wightman+, NeurIPS'21 Workshop ImageNet PPF</a>
<span class="snippet"><span>Summary</span>- 本論文では、Residual Networks（ResNet-50）の性能を新たなトレーニング手法を用いて再評価し、競争力のある設定で80.4%のトップ1精度を達成したことを報告します。これにより、将来の研究のためのより良いベースラインを提供することを目指しています。</span>
<span class="snippet"><span>Comment</span><p>2015年以後、様々な最適化アルゴリズム、正則化手法、データ拡張などが提案される中で、最新アーキテクチャのモデルにはそれらが適用される一方ベースラインとなるResNetではそれらが適用されず、論文の値のみが参照される現状はフェアではないので、ResNetの性能を向上させるような訓練手法を追求した研究。<br><br><br><br>ResNetにおける有効な訓練手法として下記を模索：<br><br><br><br>損失関数として、MixUp（訓練画像を重ね合わせ、組み合わせた画像のラベルをミックスして新しい学習インスタンスを作るデータ拡張手法）と、CutMix（画像を切り貼りして、切り貼り部分の面積に応じてラベルのスコアを調整するデータ拡張手法）を適用し、CutMixによって大幅に性能が改善することを示した。このとき、ラベルの確率の和が1となる前提の元クロスエントロピーで学習するのではなく、元画像に含まれる物体が両方存在するという全体の元BinaryCrossEntropyを適用しマルチラベル問題として学習することで、性能が向上。<br><br><br><br>データ拡張手法として、MixUp, CutMixだけでなく、通常のリサイズ・切り抜きと、水平方向の反転を適用しデータ拡張する。加えてRandAugment（14種類のデータ拡張操作から、N個サンプルし、強さMで順番に適用するデータ拡張手法。N,Mはそれぞれ0〜10の整数なので、10の二乗オーダーでグリッドサーチすれば、最適なN,Mを得る。グリッドサーチするだけでお手軽だが非常に強力）を適用した。<br><br><br><br>正則化として、Weight Decay（学習過程で重みが大きくなりすぎないようにペナルティを課し、過学習を防止する手法。L2正則化など。）と、label smoothing（正解ラベルが1、その他は0とラベル付けするのではなく、ラベルに一定のノイズを入れ、正解ラベル以外にも重みが入っている状態にし、ラベル付けのノイズにロバストなモデルを学習する手法。ノイズの強さは定数で調整する）、Repeated Augmentation（同じバッチ内の画像にデータ拡張を適用しバッチサイズを大きくする）、Stochastic Depth（ランダムでレイヤーを削除し、その間を恒等関数で繋ぎ訓練することで、モデルの汎化能力と訓練時間を向上する）を適用。<br><br></p>
<p>Optimizerとして、オリジナルのResNetでは、SGDやAdamWで訓練されることが多いが、Repeated Augmentationとバイナリクロスエントロピーを組み合わせた場合はLAMBが有効であった。また、従来よりも長い訓練時間（600epoch、様々な正則化手法を使っているので過学習しづらいため）で学習し、最初にウォームアップを使い徐々に学習率を上げ（finetuningの再認識これまでのweightをなるべく壊したくないから小さい学習率から始める、あるいはMomentumやAdamといった移動平均を使う手法では移動平均を取るための声倍の蓄積が足りない場合学習の信頼度が低いので最初の方は学習率小さくするみたいな、イメージ）その後コサイン関数に従い学習率を減らしていくスケジューリング法で学習。<br><br><br><br>論文中では上記手法の3種類の組み合わせ（A1,A2,A3）を提案し実験している。<br><br>ResNet-50に対してA1,2,3を適用した結果、A1を適用した場合にImageNetのトップ1精度が80.4%であり、これはResNet-50を使った場合のSoTA。元のResNetの精度が76%程度だったので大幅に向上した。<br><br>同じ実験設定を使った場合の他のアーキテクチャ（ViTやEfficientNetなど）と比べても遜色のない性能を達成。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/140302112-05392bbb-7014-4518-a001-55e91933a065.png" alt="image" loading="lazy"><br><br><br><br>また、本論文で提案されているA2と、DeiTと呼ばれるアーキテクチャで提案されている訓練手法（T2）をそれぞれのモデルに適用した結果、ResNetではA2、DeiTではT2の性能が良かった。つまり、「アーキテクチャと訓練方法は同時に最適化する必要がある」ということ。これがこの論文のメッセージの肝とのこと。<br><br><br><br>（ステートオブAIガイドの内容を一部補足して記述しました。いつもありがとうございます。）<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/140302160-c31717ae-a225-47a4-ae33-f1cd081c419b.png" alt="image" loading="lazy"></p>
<p>画像系でどういった訓練手法が利用されるか色々書かれていたので勉強になった。特に画像系のデータ拡張手法なんかは普段触らないので勉強になる。</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=NG6MJnVl6M5" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=NG6MJnVl6M5</a>


</p></span><br><br>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/StudentPerformancePrediction.html" target="_blank" rel="noopener noreferrer">#StudentPerformancePrediction</a>
<a class="button" href="articles/LAK.html" target="_blank" rel="noopener noreferrer">#LAK</a>
<span class="issue_date">Issue Date: 2021-10-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/418" target="_blank" rel="noopener noreferrer" class="title-link">SAINT+: Integrating Temporal Features for EdNet Correctness Prediction, Shin+, RiiiD AI Research, LAK'21</a>
<span class="snippet"><span>Comment</span><p>Student Performance PredictionにTransformerを初めて利用した研究<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/139178783-ae4d4e2d-9fc5-44f5-9769-0f206108261c.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<span class="issue_date">Issue Date: 2021-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/409" target="_blank" rel="noopener noreferrer" class="title-link">過去情報の内容選択を取り入れた スポーツダイジェストの自動生成, 加藤+, 東工大, NLP'21</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2021-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/405" target="_blank" rel="noopener noreferrer" class="title-link">Prefix-Tuning: Optimizing Continuous Prompts for Generation, Lisa+ （Percy Liang）, Stanford University, ACL'21</a>
<span class="snippet"><span>Comment</span><p>言語モデルをfine-tuningする際，エンコード時に「接頭辞」を潜在表現として与え，「接頭辞」部分のみをfine-tuningすることで（他パラメータは固定），より少量のパラメータでfine-tuningを実現する方法を提案．接頭辞を潜在表現で与えるこの方法は，GPT-3のpromptingに着想を得ている．fine-tuningされた接頭辞の潜在表現のみを配布すれば良いので，非常に少量なパラメータでfine-tuningができる．<br><br><br><br>table-to-text, summarizationタスクで，一般的なfine-tuningやAdapter（レイヤーの間にアダプターを挿入しそのパラメータだけをチューニングする手法）といった効率的なfine-tuning手法と比較．table-to-textでは、250k (元のモデルの 0.1%) ほどの数のパラメータを微調整するだけで、全パラメータをfine-tuningするのに匹敵もしくはそれ以上の性能を達成．<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/132679791-87ad130d-8a7e-4549-a311-f84400a3787b.png" alt="image" loading="lazy"><br><br></p>
<p>Hugging Faceの実装を利用したと論文中では記載されているが，fine-tuningする前の元の言語モデル（GPT-2）はどのように準備したのだろうか．Hugging Faceのpretrained済みのGPT-2を使用したのだろうか．</p>
<p>autoregressive LM (GPT-2)と，encoder-decoderモデル（BART）へPrefix Tuningを適用する場合の模式図<br><br><img src="https://user-images.githubusercontent.com/12249301/132681736-0ea4b13f-71cb-41ba-ae17-027e8bf54cc0.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/LearningPhenomena.html" target="_blank" rel="noopener noreferrer">#LearningPhenomena</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2189" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Double Descent: Where Bigger Models and More Data Hurt, Preetum Nakkiran+, ICLR'20</a>
<span class="snippet"><span>Summary</span>- 深層学習タスクにおける「ダブルデセント」現象を示し、モデルサイズの増加に伴い性能が一時的に悪化し、その後改善されることを明らかにした。また、ダブルデセントはモデルサイズだけでなくトレーニングエポック数にも依存することを示し、新たに定義した「効果的なモデルの複雑さ」に基づいて一般化されたダブルデセントを仮定。これにより、トレーニングサンプル数を増やすことで性能が悪化する特定の領域を特定できることを示した。</span>
<span class="snippet"><span>Comment</span><p>参考:


<a href="https://qiita.com/teacat/items/a8bed22329956b80671f" target="_blank" rel="noopener noreferrer">https://qiita.com/teacat/items/a8bed22329956b80671f</a>


</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MatrixFactorization.html" target="_blank" rel="noopener noreferrer">#MatrixFactorization</a>
<a class="button" href="articles/RecSys.html" target="_blank" rel="noopener noreferrer">#RecSys</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Reproducibility.html" target="_blank" rel="noopener noreferrer">#Reproducibility</a>
<span class="issue_date">Issue Date: 2025-05-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1967" target="_blank" rel="noopener noreferrer" class="title-link">Neural Collaborative Filtering vs. Matrix Factorization Revisited, Steffen Rendle+, RecSys'20</a>
<span class="snippet"><span>Summary</span>- 埋め込みベースのモデルにおける協調フィルタリングの研究では、MLPを用いた学習された類似度が提案されているが、適切なハイパーパラメータ選択によりシンプルなドット積が優れた性能を示すことが確認された。MLPは理論的には任意の関数を近似可能だが、実用的にはドット積の方が効率的でコストも低いため、MLPは慎重に使用すべきであり、ドット積がデフォルトの選択肢として推奨される。</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1960" target="_blank" rel="noopener noreferrer" class="title-link">PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive   Summarization, Jingqing Zhang+, ICML'20</a>
<span class="snippet"><span>Summary</span>- 大規模なテキストコーパスに対して新しい自己教師ありの目的でトランスフォーマーを事前学習し、抽象的なテキスト要約に特化したモデルPEGASUSを提案。重要な文を削除またはマスクし、残りの文から要約を生成。12の下流要約タスクで最先端のROUGEスコアを達成し、限られたリソースでも優れたパフォーマンスを示す。人間評価でも複数のデータセットで人間のパフォーマンスに達したことを確認。</span>
<span class="snippet"><span>Comment</span><p>PEGASUSもなかったので追加。BARTと共に文書要約のBackboneとして今でも研究で利用される模様。</p>
<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/984" target="_blank" rel="noopener noreferrer">SummEval: Re-evaluating Summarization Evaluation, Fabbri+, TACL'21</a>
</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/TransferLearning.html" target="_blank" rel="noopener noreferrer">#TransferLearning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1955" target="_blank" rel="noopener noreferrer" class="title-link">Exploring the Limits of Transfer Learning with a Unified Text-to-Text  Transformer, Colin Raffel+, JMLR'20</a>
<span class="snippet"><span>Summary</span>- 転移学習はNLPにおいて強力な技術であり、本論文ではテキストをテキストに変換する統一フレームワークを提案。事前学習の目的やアーキテクチャを比較し、最先端の結果を達成。データセットやモデル、コードを公開し、今後の研究を促進する。</span>
<span class="snippet"><span>Comment</span><p>T5もメモっていなかったので今更ながら追加。全てのNLPタスクをテキスト系列からテキスト系列へ変換するタスクとみなし、Encoder-DecoderのTransformerを大規模コーパスを用いて事前学習をし、downstreamタスクにfinetuningを通じて転移する。</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1934" target="_blank" rel="noopener noreferrer" class="title-link">Editable Neural Networks, Anton Sinitsin+, ICLR'20</a>
<span class="snippet"><span>Summary</span>- 深層ニューラルネットワークの誤りを迅速に修正するために、Editable Trainingというモデル非依存の訓練手法を提案。これにより、特定のサンプルの誤りを効率的に修正し、他のサンプルへの影響を避けることができる。大規模な画像分類と機械翻訳タスクでその有効性を実証。</span>
<span class="snippet"><span>Comment</span><p>（おそらく）Knowledge Editingを初めて提案した研究</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=HJedXaEtvS" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=HJedXaEtvS</a>


</p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/CTRPrediction.html" target="_blank" rel="noopener noreferrer">#CTRPrediction</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/RecSys.html" target="_blank" rel="noopener noreferrer">#RecSys</a>
<a class="button" href="articles/SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<a class="button" href="articles/numeric.html" target="_blank" rel="noopener noreferrer">#numeric</a>
<span class="issue_date">Issue Date: 2025-04-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1901" target="_blank" rel="noopener noreferrer" class="title-link">An Embedding Learning Framework for Numerical Features in CTR Prediction, Huifeng Guo+, arXiv'20</a>
<span class="snippet"><span>Summary</span>- CTR予測のための新しい埋め込み学習フレームワーク「AutoDis」を提案。数値特徴の埋め込みを強化し、高いモデル容量とエンドツーエンドのトレーニングを実現。メタ埋め込み、自動離散化、集約の3つのコアコンポーネントを用いて、数値特徴の相関を捉え、独自の埋め込みを学習。実験により、CTRとeCPMでそれぞれ2.1%および2.7%の改善を達成。コードは公開されている。</span>
<span class="snippet"><span>Comment</span><p>従来はdiscretizeをするか、mlpなどでembeddingを作成するだけだった数値のinputをうまく埋め込みに変換する手法を提案し性能改善<br><br>数値情報を別の空間に写像し自動的なdiscretizationを実施する機構と、各数値情報のフィールドごとのglobalな情報を保持するmeta-embeddingをtrainable parameterとして学習し、両者を交互作用（aggregation; max-poolingとか）することで数値embeddingを取得する。<br><br>&lt;img width="589" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/1f626dd5-2452-4b50-a14c-6c24fa022435"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/1f626dd5-2452-4b50-a14c-6c24fa022435"&lt;/a&gt;


/&gt;<br><br>&lt;img width="429" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/12fd6476-241a-4d13-975d-f6c1c762c497"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/12fd6476-241a-4d13-975d-f6c1c762c497"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ActivationFunction.html" target="_blank" rel="noopener noreferrer">#ActivationFunction</a>
<span class="issue_date">Issue Date: 2024-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1311" target="_blank" rel="noopener noreferrer" class="title-link">GLU Variants Improve Transformer, Noam Shazeer, N_A, arXiv'20</a>
<span class="snippet"><span>Summary</span>- GLUのバリエーションをTransformerのフィードフォワード・サブレイヤーでテストし、通常の活性化関数よりもいくつかのバリエーションが品質向上をもたらすことを発見した。</span>
<span class="snippet"><span>Comment</span><p>一般的なFFNでは、linear layerをかけた後に、何らかの活性化関数をかませる方法が主流である。<br><br>このような構造の一つとしてGLUがあるが、linear layerと活性化関数には改良の余地があり、様々なvariantが考えられるため、色々試しました、というはなし。<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/72b1d0bb-64ac-4155-9a3b-5624cd06ccc9" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b38321c6-d414-4764-9147-10a5fa83fbe6" alt="image" loading="lazy"><br><br><br><br>オリジナルのGLUと比較して、T5と同じ事前学習タスクを実施したところ、perplexityが改善<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9e67a054-2148-41ed-aae1-5a752c21a242" alt="image" loading="lazy"><br><br><br><br>また、finetuningをした場合の性能も、多くの場合オリジナルのGLUよりも高い性能を示した。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/77ccab88-e5cc-48fc-b9e0-f2dad24e53e8" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8f60ca8c-50eb-4869-bab4-f02ec6d8e085" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8124fc25-aa7e-4e10-8cd2-9d24c818f410" alt="image" loading="lazy"><br><br><br><br><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/552" target="_blank" rel="noopener noreferrer" class="title-link">Language Models are Few-Shot Learners, Tom B. Brown+, NeurIPS'20</a>
<span class="snippet"><span>Summary</span>- GPT-3は1750億パラメータを持つ自己回帰型言語モデルで、少数ショット設定においてファインチューニングなしで多くのNLPタスクで強力な性能を示す。翻訳や質問応答などで優れた結果を出し、即時推論やドメイン適応が必要なタスクでも良好な性能を発揮する一方、依然として苦手なデータセットや訓練に関する問題も存在する。また、GPT-3は人間が書いた記事と区別が難しいニュース記事を生成できることが確認され、社会的影響についても議論される。</span>
<span class="snippet"><span>Comment</span><p>In-Context Learningを提案した論文</p>
<p>論文に記載されているIn-Context Learningの定義は、しっかり押さえておいた方が良い。<br><br>下図はmeta-learningの観点から見たときの、in-contextの位置付け。事前学習時にSGDでパラメータをupdateするのをouter loopとし、そこで広いスキルとパターン認識の能力を身につける。一方で、in-context learningは、Inference時に事前学習時に得たそれらのスキルを用いて、求めるタスクを認識、あるいは適応するInner loopのことを指す。<br><img src="https://github.com/user-attachments/assets/679129f3-93e3-445f-b9e8-5d909261737b" alt="image" loading="lazy"><br><br>この上で、論文中では In-Context Learningについて:<br>&gt; Recent work [RWC+19] attempts to do this via what we call “in-context learning”, using the text input of a pretrained language model as a form of task specification: the model is conditioned on a natural language instruction and/or a few demonstrations of the task and is then expected to complete further instances of the task simply by predicting what comes next.<br><br>と定義している。</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<a class="button" href="articles/Zero/FewShotLearning.html" target="_blank" rel="noopener noreferrer">#Zero/FewShotLearning</a>
<span class="issue_date">Issue Date: 2022-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/494" target="_blank" rel="noopener noreferrer" class="title-link">Few-Shot NLG with Pre-Trained Language Model, Chen+, University of California, ACL'20</a>
<span class="snippet"><span>Comment</span><p># 概要<br><br>Neural basedなend-to-endなNLGアプローチはdata-hungryなので、Few Shotな設定で高い性能ができる手法を提案（Few shot NLG）<br><br>Table-to-Textタスク（WikiBIOデータ, 追加で収集したBook, SongドメインのWikipediaデータ）において、200程度の学習サンプル数でstrong baselineに対して8.0 point程度のBLEUスコアの向上を達成<br><br><br><br># 手法<br><br>TabularデータのDescriptionを作成するには大きく分けて2つのスキルが必要<br><br>1. factualな情報を持つcontentをselectし、copyするスキル<br><br>2. factualな情報のコピーを含めながら、文法的に正しいテキストを生成するスキル<br><br>提案手法では、1を少量のサンプル（&lt; 500）から学習し、2については事前学習済みの言語モデルを活用する。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/204966408-e5442477-0560-439b-9780-d454a8761345.png" alt="image" loading="lazy"><br><br><br><br>encoderからコピーする確率をpcopyとし、下記式で算出する：<br><br><img src="https://user-images.githubusercontent.com/12249301/204968383-44ef3771-218e-4e3e-8bfd-e2e6750c514b.png" alt="image" loading="lazy"><br><br>すなわち、encoderのcontext vectorと、decoderのinputとstateから求められる。<br><br>encoderとencoder側へのattentionはscratchから学習しなければならず、うまくコピーできるようにしっかりと”teach”しなければならないため、lossに以下を追加する：<br><br><img src="https://user-images.githubusercontent.com/12249301/204968557-4526e76d-8be5-4371-adc7-d49d8291954f.png" alt="image" loading="lazy"><br><br>すなわち、コピーすべき単語がちゃんとコピーできてる場合にlossが小さくなる項を追加している。<br><br>また、decoder側では、最初にTable情報のEmbeddingを入力するようにしている。<br><br>また、学習できるデータ量が限られているため、pre-trainingモデルのEmbeddingは事前学習時点のものに固定した（ただしく読解できているか不安）<br><br><br><br># 実験<br><br>WikiBIOと、独自に収集したBook, Songに関するWikipediaデータのTable-to-Textデータを用いて実験。<br><br>このとき、Training instanceを50~500まで変化させた。<br><br><img src="https://user-images.githubusercontent.com/12249301/204969250-b2965b62-5a82-4c38-9008-3e4bbc5d9c24.png" alt="image" loading="lazy"><br><br><br><br>WikiBIOデータセットに対してSoTAを記録しているBase-originalを大きくoutperform（Few shot settingでは全然うまくいかない）。<br><br><br><br>inputとoutput例と、コピーに関するlossを入れた場合の効果。<br><br><img src="https://user-images.githubusercontent.com/12249301/204969645-aa2686f0-f83c-44cc-a6aa-2e793a6cd5b8.png" alt="image" loading="lazy"><br><br><br><br>人手評価の結果、Factual informationの正しさ（#Supp）、誤り（#Cont）ともに提案手法が良い。また、文法的な正しさ（Lan. Score）もコピーがない場合とcomparable<br><br><img src="https://user-images.githubusercontent.com/12249301/204969885-7cb3e507-d986-4d97-8f7c-a5b8c3c8204f.png" alt="image" loading="lazy"><br><br><br><br></p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<span class="issue_date">Issue Date: 2022-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/493" target="_blank" rel="noopener noreferrer" class="title-link">Leveraging Pre-trained Checkpoints for Sequence Generation Tasks, Rothe+, Google Research, TACL'20</a>
<span class="snippet"><span>Comment</span><p># 概要<br><br>BERT-to-BERT論文。これまでpre-trainedなチェックポイントを利用する研究は主にNLUで行われてきており、Seq2Seqでは行われてきていなかったので、やりました、という話。<br><br>publicly availableなBERTのcheckpointを利用し、BERTをencoder, decoder両方に採用することでSeq2Seqを実現。実現する上で、<br><br>1. decoder側のBERTはautoregressiveな生成をするようにする（左側のトークンのattentionしか見れないようにする）<br><br>2. encoder-decoder attentionを新たに導入する<br><br>の2点を工夫している。<br><br><br><br># 実験<br><br>Sentence Fusion, Sentence Split, Machine Translation, Summarizationの4タスクで実験<br><br><br><br>## MT<br><br><img src="https://user-images.githubusercontent.com/12249301/204958483-722106b3-bda2-45a3-bb08-fb4eb429c90c.png" alt="image" loading="lazy"><br><br>BERT2BERTがSoTA達成。Edunov+の手法は、data _augmentationを利用した手法であり、純粋なWMT14データを使った中ではSoTAだと主張。特にEncoder側でBERTを使うと、Randomにinitializeした場合と比べて性能が顕著に上昇しており、その重要性を主張。<br><br>Sentence Fusion, Sentence Splitでは、encoderとdecoderのパラメータをshareするのが良かったが、MTでは有効ではなかった。これはMTではmodelのcapacityが非常に重要である点、encoderとdecoderで異なる文法を扱うためであると考えられる。<br><br><br><br>## Summarization<br><br>BERTSHARE, ROBERTASHAREの結果が良かった。<br><br><img src="https://user-images.githubusercontent.com/12249301/204959543-e21bd9a6-bef4-4538-b181-daca93fa33e7.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<span class="issue_date">Issue Date: 2022-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/492" target="_blank" rel="noopener noreferrer" class="title-link">Template Guided Text Generation for Task-Oriented Dialogue, Kale+, Google, EMNLP'20</a>
<span class="snippet"><span>Comment</span><p># 概要<br><br>Dialogue Actをそのままlinearlizeして言語モデルに入力するのではなく、テンプレートをベースにしたシンプルなsentenceにして言語モデルに与えると、zero-shot, few-shotなsettingで性能が向上するという話（T5ベース）。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/204951348-e7cb9982-4d1f-4ac0-8e1d-b3e8fd872b11.png" alt="image" loading="lazy"><br><br><br><br># 手法<br><br>slotの名称をnatural languageのdescriptionに変更するSchema Guidedアプローチも提案（NLUでは既に実践さrていたらしいが、Generationで利用されたことはない）。<br><br><img src="https://user-images.githubusercontent.com/12249301/204952341-fae03300-992a-491f-b194-9013f5d598f9.png" alt="image" loading="lazy"><br><br><br><br># 結果<br><br>MultiWoz, E2E, SGDデータセットを利用。MultiWoz, E2Eデータはデータ量が豊富でドメインやfeatureが限定的なため、schema guided, template guided approachとNaiveなrepresentationを利用した場合の結果がcopmarableであった。<br><br>が、SGDデータセットはドメインが豊富でzero-shot, few-shotの設定で実験ができる。SGDの場合はTemplate guided representationが最も高い性能を得た。<br><br><img src="https://user-images.githubusercontent.com/12249301/204954033-ecbeb90f-1398-486c-8d1f-76a0e54ed8ea.png" alt="image" loading="lazy"><br><br></p>
<p>low resourceなデータセットで活用できそう</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2022-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/488" target="_blank" rel="noopener noreferrer" class="title-link">Text-to-Text Pre-Training for Data-to-Text Tasks, Mihir+, Google Research, INLG'20</a>
<span class="snippet"><span>Comment</span><p># 概要<br><br>pre-training済みのT5に対して、Data2Textのデータセットでfinetuningを実施する方法を提案。WebNLG（graph-to-text）, ToTTo（table-to-text）, Multiwoz（task oriented dialogue）データにおいて、simpleなTransformerでも洗練されたmulti-stageなpipelined approachをoutperformできることを示した研究。<br><br><br><br># 手法<br><br>事前学習済みのT5に対してfine-tuningを実施した。手法はシンプルで、data-to-textタスクをtext-to-textタスクに変換した。具体的には、構造かされたデータをflatな文字列（linearization）で表現することで、text-to-textタスクに変換。各データセットに対するlinearizationのイメージは下図。デリミタや特殊文字を使って構造かされたデータをflatなstringで表現している。<br><br><img src="https://user-images.githubusercontent.com/12249301/191689155-3562f4f3-d1a1-4ea0-9d37-a523b78e8922.png" alt="image" loading="lazy"><br><br><br><br># データセット<br><br>## ToTTo（2020）<br><br>Wikipediaのテーブルと自然言語でdescriptionのペアデータ<br><br>## MultiWoz（2018）<br><br>10Kの人間同士のtask-orientedなdialogueデータ。<br><br>## WebNLG（2017）<br><br>subject-object-predicateの3組みをテキスト表現に変換するタスクのデータ<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/191693682-3cf3302f-b4e2-433d-94ed-995a8a908d0c.png" alt="image" loading="lazy"><br><br><br><br># Result<br><br>## WebNLG<br><br><img src="https://user-images.githubusercontent.com/12249301/191694085-7bf7348a-b468-46e0-a900-c0090d1abcba.png" alt="image" loading="lazy"><br><br>GCNを利用した2020年に提案されたDualEncがSoTAだったらしいが、outperormしている。<br><br><br><br>## ToTTo<br><br><img src="https://user-images.githubusercontent.com/12249301/191694683-f31ccad1-2936-4c21-ac10-0807a848f043.png" alt="image" loading="lazy"><br><br>[こちら](


<a href="https://github.com/google-research-datasets/totto)%E3%81%AE%E3%83%AA%E3%83%BC%E3%83%80%E3%83%BC%E3%83%9C%E3%83%BC%E3%83%89%E3%81%A8%E6%AF%94%E8%BC%83%E3%81%97%E3%81%A6SoTA%E3%82%92%E8%A8%98%E9%8C%B2" target="_blank" rel="noopener noreferrer">https://github.com/google-research-datasets/totto)のリーダーボードと比較してSoTAを記録</a>


<br><br><br><br>## MultiWoz<br><br><img src="https://user-images.githubusercontent.com/12249301/191695459-e3397936-bdf7-4450-b4c2-6f6eead0825d.png" alt="image" loading="lazy"><br><br>T5は事前学習済みGPT-2をfinetuningした手法もoutperformした。SC-GPT2は当時のMultiWozでのSoTA<br><br><br><br># Impact of Model capacity<br><br>T5モデルのサイズがどれが良いかについては、データセットのサイズと複雑さに依存することを考察している。たとえば、MultiWozデータは構造化データのバリエーションが最も少なく、データ量も56kと比較的多かった。このため、T5-smallでもより大きいモデルの性能に肉薄できている。<br><br>一方、WebNLGデータセットは、18kしか事例がなく、特徴量も約200種類程度のrelationのみである。このような場合、モデルサイズが大きくなるにつれパフォーマンスも向上した（特にUnseen test set）。特にBLEUスコアはT5-smallがT5-baseになると、10ポイントもジャンプしており、modelのcapacityがout-of-domainに対する一般化に対してcriticalであることがわかる。ToTToデータセットでも、SmallからBaseにするとパフォーマンスは改善した。</p>
<p># 所感<br><br>こんな簡単なfine-tuningでSoTAを達成できてしまうとは、末恐ろしい。ベースラインとして有用。</p></span><br><br>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<span class="issue_date">Issue Date: 2022-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/451" target="_blank" rel="noopener noreferrer" class="title-link">When is Deep Learning the Best Approach to Knowledge Tracing?, Theophile+ （Ken Koedinger）, CMU+, JEDM'20</a>
<span class="snippet"><span>Comment</span><p>下記モデルの性能をAUCとRMSEの観点から9つのデータセットで比較した研究<br><br>- DLKT<br><br>    - DKT<br><br>    - SAKT<br><br>    - FFN<br><br>- Regression Models<br><br>    - IRT<br><br>    - PFA<br><br>    - DAS3H<br><br>    - Logistinc Regression<br><br>- variation of BKT<br><br>    - BKT+ (add individualization, forgetting, discovery of knowledge components)<br><br><br><br>DKT、およびLogistic Regressionが最も良い性能を示し、DKTは5種類のデータセットで、Logistic Regressionは4種類のデータセットでbestな結果を示した。<br><br>SAKTは <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/417" target="_blank" rel="noopener noreferrer">A Self-Attentive model for Knowledge Tracing, Pandy+ (with George Carypis), EDM'19</a>
 で示されている結果とは異なり、全てのデータセットにおいてDKTの性能を下回った。<br><br>また、データセットのサイズがモデルのパフォーマンスに影響していることを示しており、<br><br>小さなデータセットの場合はLogistic Regressionのパフォーマンスがよく、<br><br>大きなデータセットの場合はDKTの性能が良かった。<br><br>（アイテムごとの学習者数の中央値、およびKCごとの学習者数の中央値が小さければ小さいほど、Logistic Regressionモデルが強く、DLKTモデルはoverfitしてしまった; たとえば、アイテムごとの学習者数の中央値が1, 4, 10とかのデータではLRが強い; アイテムごとの学習者数の中央値が仮に大きかったとしても、KCごとの学習者数の中央値が少ないデータ(200程度; Spanish)では、Logistic Regressionが強い）。<br><br>加えて、DKTはLogistic Regressionと比較して、より早くピークパフォーマンスに到達することがわかった。</p>
<p>ちなみに、一つのアイテムに複数のKCが紐づいている場合は、それらを組み合わせ新たなKCを作成することで、DKTとSAKTに適用したと書いてある（この辺がずっと分かりづらかった）。</p>
<p>データセットの統計量はこちら：<br><br><img src="https://user-images.githubusercontent.com/12249301/165673839-fedce7e1-298c-4af1-acac-779a038c31a8.png" alt="image" loading="lazy"><br><br></p>
<p>データセットごとに、連続して同じトピックの問題（i.e. 連続した問題IDの問題を順番に解いている）を解いている割合（i.e. どれだけ順番に問題を解いていっているか）を算出した結果が下図。<br><br>同じトピックの問題を連続して解いている場合（i.e. 順番に問題を解いていっている場合）に、DKTの性能が良い。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/165675807-14b37410-b577-446f-ab11-14ff3fad61a9.png" alt="image" loading="lazy"><br><br></p>
<p>またパフォーマンスに影響を与える要因として、学習者ごとのインタラクション数が挙げられる。ほとんどのデータセットでは、power-lawに従い中央値が数百程度だが、bridge06やspanishのように、power-lawになっておらず中央値が数千といったデータが存在する。こういったデータではDKTはlong-termの情報を捉えきれず、高い性能を発揮しない。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/165676378-5c690a50-0634-447f-bf2d-1b0f9d33482e.png" alt="image" loading="lazy"><br><br></p>
<p>実験に利用した実装はこちら：


<a href="https://github.com/theophilee/learner-performance-prediction" target="_blank" rel="noopener noreferrer">https://github.com/theophilee/learner-performance-prediction</a>


<br><br><br><br>ただ、実装を見るとDKTの実装はオリジナルの論文とは全く異なる工夫が加えられていそう<br><br>


<a href="https://github.com/theophilee/learner-performance-prediction/blob/master/model_dkt2.py" target="_blank" rel="noopener noreferrer">https://github.com/theophilee/learner-performance-prediction/blob/master/model_dkt2.py</a>


<br><br>これをDKTって言っていいの・・・？<br><br>オリジナルのDKTの実装はDKT1として実装されていそうだけど、その性能は報告されていないと思われる・・・。<br><br>DKT1の実装じゃないと、KCのマスタリーは取得できないんでは。<br><br><br><br>追記：と思ったら、DKTのAblation Studyで報告されている Input/Output をKC, Itemsで変化させた場合のAUCの性能の変化の表において、best performingだった場合のAUCスコアが9つのデータセットに対するDKTの予測性能に記載されている・・・。<br><br>じゃあDKT2はどこで使われているの・・・。</p>
<p>DKTは、inputとしてquestion_idを使うかKCのidを使うか選択できる。また、outputもquestion_idに対するprobabilityをoutputするか、KCに対するprobabilityをoutputするか選択できる。<br><br>これらの組み合わせによって、予測性能がどの程度変化するかを検証した結果が下記。<br><br>KCをinputし、question_idをoutputとする方法が最も性能が良かった。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/165685019-01a19a92-1518-4740-a1f0-2e88e5656ad2.png" alt="image" loading="lazy"><br><br><br><br>明記されていないが、おそらくこの検証にはDKT1の実装を利用していると思われる。input / outputをquestionかKCかを選べるようになっていたので。<br><br>実際にIssueでも、assistments09のAUC0.75を再現したかったら、dkt1をinput/output共にKCに指定して実行しろと著者が回答している。<br><br><br><br>ちなみに論文中の9つのデータセットに対するAUCの比較では、各々のモデルはKCに対して正答率を予測しているのではなく、個々の問題単位で正答率を予測していると思われる（実装を見た感じ）。<br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<a class="button" href="articles/SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<span class="issue_date">Issue Date: 2022-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/446" target="_blank" rel="noopener noreferrer" class="title-link">Context-Aware Attentive Knowledge Tracing, Ghosh+, University of Massachusetts Amherst, KDD'20</a>
<span class="snippet"><span>Comment</span><p>この論文の実験ではSAKTがDKVMNやDKTに勝てていない</p></span><br><br>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/DropoutPrediction.html" target="_blank" rel="noopener noreferrer">#DropoutPrediction</a>
<span class="issue_date">Issue Date: 2022-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/443" target="_blank" rel="noopener noreferrer" class="title-link">Deep Attentive Study Session Dropout Prediction in Mobile Learning Environment, Riiid AI Research, Lee+, CSEDU'20</a>
<span class="snippet"><span>Comment</span><p>従来のdropout研究では、学校のドロップアウトやコースのドロップアウト、MOOCsなどでのドロップアウトが扱われてきたが、モバイル学習環境を考慮した研究はあまり行われてこなかった。モバイル学習環境では着信やソーシャルアプリなど、多くの外敵要因が存在するため、学習セッションのドロップアウトが頻繁に発生する。<br><br><br><br>学習セッションを、隣接するアクティビティと1時間のインターバルが空いていないアクティビティのsequenceと定義<br><br>Transformerを利用したモデルを提案。<br><br><img src="https://user-images.githubusercontent.com/12249301/163503384-6f0d4f49-ddda-4588-ad5b-81b86138300b.png" alt="image" loading="lazy"><br><br><br><br>利用したFeatureは以下の通り<br><br><img src="https://user-images.githubusercontent.com/12249301/163503437-aaeeb065-8eb8-4831-9260-a416de347c0c.png" alt="image" loading="lazy"><br><br><br><br>AUCでの評価の結果、LSTM,GRUを用いたモデルをoutperform<br><br><img src="https://user-images.githubusercontent.com/12249301/163503475-169cc2f4-564a-4178-84aa-37b05ef5dd3c.png" alt="image" loading="lazy"><br><br><br><br>また、Transformerに入力するinput sequenceのsizeで予測性能がどれだけ変化するかを確認したところ、sequence sizeが5の場合に予測性能が最大となった。<br><br><img src="https://user-images.githubusercontent.com/12249301/163503542-a9bd4d71-2a75-4ccb-a250-7a9258201219.png" alt="image" loading="lazy"><br><br><br><br>これは、session dropoutの予測には、生徒の最新のinteractionの情報と相関があることを示している。だが、sequence sizeが2のときに予測性能は低かったため、ある程度のcontext情報が必要なことも示唆している。<br><br><br><br>また、inputに利用するfeatureとしては、問題を解く際のelapsed_timeと、session内でのposition、またdropoutしたか否かのラベルが予測性能の向上に大きく寄与した。<br><br><br><br>Q. AUCの評価はどうやって評価しているのか。dropoutしたラベルの部分のみを評価しているのか否かがわからない。<br><br>Q. dropoutラベルをinputのfeatureに利用するのは実用上問題があるのでは？次の1問を解いたときにdropoutするか否かしか予測できなくなってしまうのでは。まあでもそれはelapsed_timeとかも一緒か。<br><br></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2021-06-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/381" target="_blank" rel="noopener noreferrer" class="title-link">All Word Embeddings from One Embedding, Takase+, NeurIPS'20</a>
<span class="snippet"><span>Comment</span><p>NLPのためのNN-basedなモデルのパラメータの多くはEmbeddingによるもので、従来は個々の単語ごとに異なるembeddingをMatrixの形で格納してきた。この研究ではモデルのパラメータ数を減らすために、個々のword embeddingをshared embeddingの変換によって表現する手法ALONE(all word embeddings from one)を提案。単語ごとに固有のnon-trainableなfilter vectorを用いてshared embeddingsを修正し、FFNにinputすることで表現力を高める。また、filter vector普通に実装するとword embeddingと同じサイズのメモリを消費してしまうため、メモリ効率の良いfilter vector効率手法も提案している。機械翻訳・および文書要約を行うTransformerに提案手法を適用したところ、より少量のパラメータでcomparableなスコアを達成した。</p>
<p>Embedidngのパラメータ数とBLEUスコアの比較。より少ないパラメータ数でcomparableな性能を達成している。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/121308824-700c3100-c93c-11eb-8d15-629d896f9db8.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-08-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2357" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Equilibrium Models, Shaojie Bai+, NeurIPS'19</a>
<span class="snippet"><span>Summary</span>- 深い平衡モデル（DEQ）を提案し、逐次データのモデル化において平衡点を直接見つけるアプローチを示す。DEQは無限の深さのフィードフォワードネットワークを解析的に逆伝播可能にし、定数メモリでトレーニングと予測を行える。自己注意トランスフォーマーやトレリスネットワークに適用し、WikiText-103ベンチマークでパフォーマンス向上、計算要件の維持、メモリ消費の最大88%削減を実証。</span>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/LearningPhenomena.html" target="_blank" rel="noopener noreferrer">#LearningPhenomena</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2190" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks, Jonathan Frankle+, ICLR'19</a>
<span class="snippet"><span>Summary</span>- ニューラルネットワークのプルーニング技術は、パラメータ数を90%以上削減しつつ精度を維持できるが、スパースアーキテクチャの訓練は難しい。著者は「ロッタリー・チケット仮説」を提唱し、密なネットワークには効果的に訓練できるサブネットワーク（勝利のチケット）が存在することを発見。これらのチケットは特定の初期重みを持ち、元のネットワークと同様の精度に達する。MNISTとCIFAR10の実験で、10-20%のサイズの勝利のチケットを一貫して特定し、元のネットワークよりも早く学習し高精度に達することを示した。</span>
<span class="snippet"><span>Comment</span><p>参考:


<a href="https://qiita.com/kyad/items/1f5520a7cc268e979893" target="_blank" rel="noopener noreferrer">https://qiita.com/kyad/items/1f5520a7cc268e979893</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2025-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1957" target="_blank" rel="noopener noreferrer" class="title-link">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, Mingxing Tan+, ICML'19</a>
<span class="snippet"><span>Summary</span>- 本論文では、ConvNetsのスケーリングを深さ、幅、解像度のバランスを考慮して体系的に研究し、新しいスケーリング手法を提案。これにより、MobileNetsやResNetのスケールアップを実証し、EfficientNetsという新しいモデルファミリーを設計。特にEfficientNet-B7は、ImageNetで84.3%のトップ1精度を達成し、従来のConvNetsよりも小型かつ高速である。CIFAR-100やFlowersなどのデータセットでも最先端の精度を記録。ソースコードは公開されている。</span>
<span class="snippet"><span>Comment</span><p>元論文をメモってなかったので追加。<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/346" target="_blank" rel="noopener noreferrer">EfficientNet解説, omiita (オミータ), 2019</a>
<br><br>も参照のこと。</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<span class="issue_date">Issue Date: 2023-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1022" target="_blank" rel="noopener noreferrer" class="title-link">Text Summarization with Pretrained Encoders, Liu+ （with Lapata）, EMNLP-IJCNLP'19</a>
<span class="snippet"><span>Summary</span>- 本研究では、最新の事前学習言語モデルであるBERTを使用して、テキスト要約のための一般的なフレームワークを提案します。抽出型モデルでは、新しいエンコーダを導入し、文の表現を取得します。抽象的な要約については、エンコーダとデコーダの最適化手法を異ならせることで不一致を緩和します。さらに、2段階のファインチューニングアプローチによって要約の品質を向上させました。実験結果は、提案手法が最先端の結果を達成していることを示しています。</span>
<span class="snippet"><span>Comment</span><p>BERTSUMEXT論文</p>
<p>通常のBERTの構造と比較して、文ごとの先頭に[CLS]トークンを挿入し、かつSegment Embeddingsを文ごとに交互に変更することで、文のrepresentationを取得できるようにする。<br><br>その後、encodingされたsentenceの[CLS]トークンに対応するembeddingの上に、inter-sentence Transformer layerを重ね、sigmoidでスコアリングするのが、BERTSUMEXT, Abstractiveの場合は6-layerのTransformer decoderを利用するが、これはスクラッチでfinetuninigさせる。このとき、encoder側はoverfit, decoder側はunderfitすることが予想されるため、encoderとdecodeで異なるwarmup, 学習率を適用する。具体的には、encoder側はより小さい学習率で、さらにsmoothに減衰するようにする。これにより、decoder側が安定したときにより正確な勾配で学習できるようになる。また、2-stageのfinetuningを提案し、まずencoder側をextractifve summarization taskでfinetuningし、その後abstractive summarizationでfinetuningする。先行研究ではextractive summarizationのobjectiveを取り入れることでabstractive summarizationの性能が向上していることが報告されており、この知見を取り入れる。今回はextractive summarizationの重みをabstractive taskにtrasnferすることになる。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/957647e3-06e5-44cf-835e-bb25166872fd" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<span class="issue_date">Issue Date: 2022-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/462" target="_blank" rel="noopener noreferrer" class="title-link">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks, Reimers+, UKP-TUDA, EMNLP'19</a>
<span class="snippet"><span>Comment</span><p>BERTでトークンをembeddingし、mean poolingすることで生成される文ベクトルを、Siamese Networkを使い距離学習（finetune）させたモデル。<br><br>&lt;img width="655" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/181723384-06c1a65a-985a-48bd-b7d8-b284e070b675.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/181723384-06c1a65a-985a-48bd-b7d8-b284e070b675.png"&lt;/a&gt;


&gt;<br><br><br><br>文/文章のベクトルを事前学習済みのモデルを使って簡単に求められる。<br><br>モデルの一覧は下記：


<a href="https://www.sbert.net/docs/pretrained_models.html" target="_blank" rel="noopener noreferrer">https://www.sbert.net/docs/pretrained_models.html</a>


</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<span class="issue_date">Issue Date: 2022-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/458" target="_blank" rel="noopener noreferrer" class="title-link">Deep-IRT: Make Deep Learning Based Knowledge Tracing Explainable Using Item Response Theory, Chun-Kit Yeung, EDM'19</a>
<span class="snippet"><span>Comment</span><p>
<strong># 一言で言うと<br><br>DKVMN <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/352" target="_blank" rel="noopener noreferrer">Dynamic Key-Value Memory Networks for Knowledge Tracing, Yeung+, WWW'17</a>
</strong>
<br>
 のサマリベクトルf_tと、KC embedding k_tを、それぞれ独立にFully connected layerにかけてスカラー値に変換し、生徒のスキルごとの能力パラメータθと、スキルの困難度パラメータβを求められるようにして、解釈性を向上させた研究。最終的にθとβをitem response function (シグモイド関数)に適用することで、KC j を正しく回答できる確率を推定する。<br><br><br><br>
<strong># モデル<br><br><img src="https://user-images.githubusercontent.com/12249301/180361492-c8e67272-d0b0-421e-9ff5-bdf56eeb36e0.png" alt="image" loading="lazy"><br><br><br><br>基本的なモデルはDKVMNで、DKVMNのサマリベクトルf_tに対してstudent ability networkを適用し、KC embedding k_tに対してdifficulty networkを適用するだけ。<br><br><img src="https://user-images.githubusercontent.com/12249301/180361731-7a4f6cb6-ef70-4ee4-a04b-5f1ea4c6640f.png" alt="image" loading="lazy"><br><br>生徒の能力パラメータθとスキルの困難度パラメータβを求め、最終的に下記item response functionを適用することで、入力されたスキルに対する反応予測を実施する：<br><br><img src="https://user-images.githubusercontent.com/12249301/180361904-c4d8f05d-9a5d-475b-b6f2-17b6497bcc7a.png" alt="image" loading="lazy"><br><br><br><br># 気持ち<br><br>古典的なKnowledge Tracing手法は、学習者の能力パラメータや項目の困難度パラメータといった人間が容易に解釈できるパラメータを用いて反応予測を行えるが、精度が低い。一方、DeepなKnowledge Tracingは性能は高いが学習されるパラメータの解釈性が低い。そこで、IRTと最近提案されたDKVMNを組み合わせることで、高性能な反応予測も実現しつつ、直接的にpsychological interpretationが可能なパラメータを学習するモデルを提案した。<br><br>DKVMNがinferenceに利用する情報は、意味のある情報に拡張することができることを主張。<br><br>1つめは、各latent conceptのknowledge stateは、生徒の能力パラメータを計算することに利用できる。具体的には、DKVMNによって求められるベクトルf_tは、read vector r （該当スキルに対する生徒のmastery level を表すベクトル）とKCのembedding k_t から求められる。これは、生徒のスキルに対するknowledge staeteとスキルそのもののembeddedされた情報の両者を含んでいるので、f_tをNNで追加で処理することで、生徒のスキルq_tに対する能力を推定することができるのではないかと主張。<br><br>同様に、q_tの困難度パラメータもKC embedding vector k_tをNNに渡すことで求めることができると主張。<br><br>生徒の能力を求めるネットワークを、student ability network, スキルの困難度パラメータを求めるネットワークをdifficulty networkと呼ぶ。<br><br><br><br># 性能<br><br><img src="https://user-images.githubusercontent.com/12249301/180362356-54ec5d27-8760-4132-b1c9-28653f4585dc.png" alt="image" loading="lazy"><br><br>実験の結果、DKT, DKVMN, Deep-IRTはそれぞれ似たようなAUCとなり、反応予測の性能はcomparable<br><br><br><br># Discussion<br><br>## 学習された困難度パラメータについて<br><br>複数のソース（1. データセットのpublisherが設定している3段階の難易度, 2. item analysisによって求めた難易度（生徒が問題に取り組んだとき不正解となった割合）, 3. IRTによって推定した困難度パラメータ, 4. PFAによって推定した困難度パラメータ）とDeep-IRTが学習したKC Difficulty levelの間で相関係数を測ることで、Deep-IRTが学習した困難度パラメータが妥当か検討している。ソース2, 3については、困難度推定に使うデータがtest environmentではなく学習サービスによるものなので、生徒のquestionに対するfirst attemptから困難度パラメータを予測した。一方、PFAの場合はtest environmentによる推定ではなく、knowledge tracingの設定で困難度パラメータを推定した（i.e. 利用するデータをfirst attemptに限定しない）。<br><br><img src="https://user-images.githubusercontent.com/12249301/180363651-83b4c999-8888-4801-9906-347673d12653.png" alt="image" loading="lazy"><br><br>相関係数をは測った結果が上図で、正直見方があまりわからない。著者らの主張としては、Deep-IRTは他の困難度ソースの大部分と強い相関があった（ソース1を除く）、と主張しているが、相関係数の値だけ見ると明らかにPFAの方が全てのソースに対して高い相関係数を持っている。また、困難度を推定するモデルの設定（test environment vs. learning environment）や複雑度が近ければ近いほど、相関係数が高かった（ソース2, 3間は相関係数は0.96、一方ソース2とDeep-IRTは相関係数0.56）。また、Deep-IRTはソース1の困難度パラメータとの相関係数が0.08であり非常に低い（他のソースは0.3~0.4程度の相関係数が出ている）。この結果を見ると、Deep-IRTによって推定された困難度パラメータは古典的な手法とは少し違った傾向を持っているのではないかと推察される。<br><br>=&gt; DeepIRTによって推定された困難度パラメータは、古典的な手法と比較してめっちゃ近いというわけでもなく、人手で付与された難易度と全く相関がない（そもそも人手で付与された難易度が良いものかどうかも怪しい）。結局DeepIRTによる困難度パラメータがどれだけ適切かは評価されていないので、古典的な手法とは少し似ているけど、なんか傾向が違う困難度パラメータが出ていそうです〜くらいのことしかわからない。<br><br><br><br>## 学習された生徒の能力パラメータについて<br><br><img src="https://user-images.githubusercontent.com/12249301/180364913-de52de81-58f4-4093-a7c8-cf9f643c22dd.png" alt="image" loading="lazy"><br><br>reconstruction問題がDKTと同様に生じている。たとえば、“equation solving more than two steps” (red) に不正解したにもかかわらず、対応する生徒の能力が向上してしまっている。また、スキル間のpre-requisite関係も捉えられない。具体的には、“equation solving two or fewer steps” (blue) に正解したにもかかわらず、“equation solving more than two steps” (red) の能力は減少してしまっている。<br><br><br><br># 所感<br><br>生徒の能力パラメータは、そもそもDKTVMモデルでも入力されたスキルタグに対する反応予測結果が、まさに生徒の該当スキルタグに対する能力パラメータだったのでは？と思う。困難度パラメータについては推定できることで使い道がありそうだが、DeepIRTによって推定された困難度パラメータがどれだけ良いものかはこの論文では検証されていないので、なんともいえない。&lt;/p&gt;<p># 関連研究<br><br>- Item Response Theory (IRT): 受験者の能力パラメータはテストを受けている間は不変であるという前提をおいており（i.e. testing environmentを前提としている）、Knowledgte Tracingタスクのような、学習者の能力が動的に変化する（i.e. learning environment）状況ではIRTをKnowledge Tracingに直接利用できない（と主張しているが、 <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/358" target="_blank" rel="noopener noreferrer">Back to the basics: Bayesian extensions of IRT outperform neural networks for proficiency estimation, Ekanadham+, EDM'16</a>
&lt;/strong&gt;
<br>
 あたりではIRTで項目の反応予測に利用してDKTをoutperformしている）<br><br>- Bayesian Knowledge Tracing (BKT): 「全ての生徒と、同じスキルを必要とする問題がモデル上で等価に扱われる」という非現実的な仮定が置かれている。言い換えれば、生徒ごとの、あるいは問題ごとのパラメータが存在しないということ。<br><br>- Latent Factor Analysis (LFA): IRTと類似しているが、スキルレベルのパラメータを利用してKnowledge Tracingタスクに取り組んだ。生徒の能力パラメータθと、問題に紐づいたスキルごとの難易度パラメータβと学習率γ（γ x 正答数で該当スキルに対する学習度合いを求める）を持つ。これにより「学習」に対してもモデルを適用できるようにしている。<br><br>- Performance Factor Analysis (PFA): 生徒の能力値よりも、生徒の過去のパフォーマンスがKTタスクにより強い影響があると考え、LFAを拡張し、スキルごとに正解時と不正解時のlearning rateを導入し、過去の該当スキルの正解/不正解数によって生徒の能力値を求めるように変更。これにより、スキルごとに生徒の能力パラメータが存在するようなモデルとみなすことができる。<br><br>=&gt; LFAとPFAでは、複数スキルに対する「学習」タスクを扱うことができる。一方で、スキルタグについては手動でラベル付をする必要があり、またスキル間の依存関係については扱うことができない。また、LFAでは問題に対する正答率が問題に対するattempt数に対して単調増加するため、生徒のknowledge stateがlearnedからunlearnedに遷移することがないという問題がある。PFAでは失敗したattemptの数を導入することでこの仮定を緩和しているが、生徒が大量の正答を該当スキルに対して実施した後では問題に対する正答率を現象させることは依然として困難。<br><br>- Deep Knowledge Tracing (DKT): DeepLearningの導入によって、これまで性能を向上させるために人手で設計されたfeature（e.g. recency effect, contextualized trial sequence, inter-skill relationship, student’s ability variation）などを必要とせず、BKTやPFAをoutperformした。しかし、RNNによって捉えられた情報は全て同じベクトル空間（hidden layer）に存在するため、時間の経過とともに一貫性した予測を提供することが困難であり、結果的に生徒が得意な、あるいは不得意なKCをピンポイントに特定できないという問題がある（ある時刻tでは特定のスキルのマスタリーがめっちゃ高かったが、別の問題に回答しているうちにマスタリーがめっちゃ下がるみたいな現象が起きるから？）。<br><br>- Dynamic Key Value Memory Network (DKVMN): DKTでは全てのコンセプトに対するknowledge stateを一つのhidden stateに集約することから、生徒が特定のコンセプトをどれだけマスターしたのかをトレースしたり、ピンポイントにどのコンセプトが得意, あるいは不得意なのかを特定することが困難であった（←でもこれはただの感想だと思う）。DKTのこのような問題点を改善するために提案された。DKVMNではDKTと比較して、DKTを予測性能でoutperformするだけでなく（しかしこれは後の追試によって性能に大差がないことがわかっている）、overfittingしづらく、Knowledge Component (=スキルタグ)の背後に潜むコンセプトを正確に見つけられることを示した。しかし、KCの学習プロセスを、KCのベクトルや、コンセプトごとにメモリを用意しメモリ上でknowledge stateを用いて表現することで的確にモデル化したが、依然としてベクトル表現の解釈性には乏しい。したがって、IRTやBKT, PFAのような、パラメータが直接的にpsychological interpretationが可能なモデルと、パラメータやrepresentationの解釈が難しいDKTやDKVMNなどのモデルの間では、learning science communityの間で対立が存在した。<br><br>=&gt; なので、IRTとDKVMNを組み合わせることで、DKVMNをよりexplainableにすることで、この対立を緩和します。という流れ</p>
<p>著者による実装: 


<a href="https://github.com/ckyeungac/DeepIRT" target="_blank" rel="noopener noreferrer">https://github.com/ckyeungac/DeepIRT</a>


</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<span class="issue_date">Issue Date: 2022-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/455" target="_blank" rel="noopener noreferrer" class="title-link">Knowledge Tracing with Sequential Key-Value Memory Networks, Ghodai+, Research School of Computer Science, Australian National University, SIGIR'19</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/RecSys.html" target="_blank" rel="noopener noreferrer">#RecSys</a>
<span class="issue_date">Issue Date: 2022-04-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/442" target="_blank" rel="noopener noreferrer" class="title-link">Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches, Politecnico di Milano, Maurizio+, RecSys'19</a>
<span class="snippet"><span>Comment</span><p>RecSys'19のベストペーパー<br><br>日本語解説：


<a href="https://qiita.com/smochi/items/98dbd9429c15898c5dc7" target="_blank" rel="noopener noreferrer">https://qiita.com/smochi/items/98dbd9429c15898c5dc7</a>


</p>
<p>重要研究</p></span><br><br>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/StudentPerformancePrediction.html" target="_blank" rel="noopener noreferrer">#StudentPerformancePrediction</a>
<a class="button" href="articles/EDM.html" target="_blank" rel="noopener noreferrer">#EDM</a>
<span class="issue_date">Issue Date: 2021-10-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/417" target="_blank" rel="noopener noreferrer" class="title-link">A Self-Attentive model for Knowledge Tracing, Pandy+ （with George Carypis）, EDM'19</a>
<span class="snippet"><span>Comment</span><p>Knowledge Tracingタスクに初めてself-attention layerを導入した研究</p>
<p>interaction (e_{t}, r_{t}) および current exercise (e_{t+1}) が与えられた時に、current_exerciseの正誤を予測したい。<br><br>* e_{t}: 時刻tのexercise<br><br>* r_{t}: 時刻tでの正誤<br><br><br><br>interactionからKey, Valueを生成し、current exerciseからQueryを生成し、multi-head attentionを適用する。その後、得られたcontext vectorをFFNにかけて、正誤を予測する。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/139178090-7756d34a-2f48-44d5-8782-68fca388a0aa.png" alt="image" loading="lazy"><br><br></p>
<p><img src="https://user-images.githubusercontent.com/12249301/139178523-aa52a2e9-5157-433e-a429-cea57f998bcd.png" alt="image" loading="lazy"><br><br><br><br>DKTや、DKVMNを全てのデータセットでoutperform</p>
<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/446" target="_blank" rel="noopener noreferrer">Context-Aware Attentive Knowledge Tracing, Ghosh+, University of Massachusetts Amherst, KDD'20</a>
 においてはSAKTがDKT, DKVMN等に勝てていないのに対し（ASSSITments Data + Statics Data）<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/450" target="_blank" rel="noopener noreferrer">An Empirical Comparison of Deep Learning Models for Knowledge Tracing on Large-Scale Dataset, Pandey+, AAAI workshop on AI in Education'21</a>
 <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/452" target="_blank" rel="noopener noreferrer">Do we need to go Deep? Knowledge Tracing with Big Data, Varun+, University of Maryland Baltimore County, AAAI'21 Workshop on AI Education</a>
  においてはSAKTはDKT, DKVMNに勝っている（EdNet Data）<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/451" target="_blank" rel="noopener noreferrer">When is Deep Learning the Best Approach to Knowledge Tracing?, Theophile+ (Ken Koedinger), CMU+, JEDM'20</a>
 においてもSAKTがDKTに勝てないことが報告されている（ASSISTments Data + Statics Data + Bridge to Algebra, Squirrel dataなど）。ただし、Interaction数が大きいデータセット（Squirrel data）ではDKTの性能に肉薄している。<br><br><br><br>Large ScaleなデータだとSAKTが強いが、Large Scaleなデータでなければあまり強くないということだと思われる。<br><br>Large Scaleの基準は、なかなか難しいが、1億Interaction程度あれば（EdNetデータ）SAKTの方が優位に強くなりそう。<br><br>数十万、数百万Interaction程度のデータであれば、DKTとSAKTはおそらくcomparableだと思われる。<br><br><br><br>（追記）<br><br>しかし <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/456" target="_blank" rel="noopener noreferrer">Learning Process-consistent Knowledge Tracing, Shen+, SIGKDD'21</a>
 においてはSAKTはEdNetデータセット（Large Scale）においてDKT, DKT+, DKVMNとcomparableなので、<br><br>正直何を信じたら良いか分からない。</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2021-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/408" target="_blank" rel="noopener noreferrer" class="title-link">Table-to-Text Generation with Effective Hierarchical Encoder on Three Dimensions （Row, Column and Time）, Gong+, Harbin Institute of Technology, EMNLP'19</a>
<span class="snippet"><span>Comment</span><p>
<strong>## 概要<br><br>既存研究では、tableをレコードの集合, あるいはlong sequenceとしてencodeしてきたが<br><br><br><br>1. other (column) dimensionの情報が失われてしまう (?)<br><br>2. table cellは時間によって変化するtime-series data<br><br><br><br>という特徴がある。<br><br>たとえば、ある選手の成績について言及する際に、その試合について着目するだけでなくて「直近3試合で二回目のダブルダブルです」というように直近の試合も考慮して言及することがあり、table cellの time dimensionについても着目しなければならず、これらはこれまでのモデルで実現できない。<br><br>そこで、この研究ではtime dimensionについても考慮し生成する手法を提案。<br><br><br><br>## モデル概要<br><br><img src="https://user-images.githubusercontent.com/12249301/138917272-e920b08a-5f44-4e56-8f7e-d3eb3fab7ec3.png" alt="image" loading="lazy"><br><br><br><br>全体としては、Row Dimension Encoder, Column Dimension Encoder, Time Dimension Encoderによって構成されており、self-attentionを利用して、テーブルの各セルごとに Row-Dimension, Column-Dimension, Time-DimensionのRepresentationを獲得する。イメージとしては、<br><br><br><br>- Row Dimension Encoderによって、自身のセルと同じ行に含まれるセルとの関連度を考慮した表現<br><br>- Column Dimension Encoderによって、自身のセルと同じ列に含まれるセルとの関連度を考慮した表現<br><br>- Time Dimension Encoderによって、過去の時系列のセルとの関連度を考慮した表現<br><br><br><br>をそれぞれ獲得するイメージ。各Dimension Encoderでやっていることは、Puduppully (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/394" target="_blank" rel="noopener noreferrer">Data-to-Text Generation with Content Selection and Planning, Puduppully+, AAAI'19</a>
</strong>
<br>
) らのContent Selection Gate節におけるattention vector r_{att}の取得方法と同様のもの（だと思われる）。<br><br><br><br>獲得したそれぞれのdimensionの表現を用いて、まずそれらをconcatし1 layer MLPで写像することで得られるgeneral representationを取得する。その後、general representationと各dimensionの表現を同様に1 layer MLPでスコアリングすることで、各dimensionの表現の重みを求め、その重みで各representationを線形結合することで、セルの表現を獲得する。generalなrepresentationと各dimensionの表現の関連性によって重みを求めることで、より着目すべきdimensionを考慮した上で、セルの表現を獲得できるイメージなのだろうか。<br><br>その後、各セルの表現を行方向に対してMeanPoolingを施しrow-levelの表現を取得。獲得したrow-levelの表現に対し、Puduppully (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/394" target="_blank" rel="noopener noreferrer">Data-to-Text Generation with Content Selection and Planning, Puduppully+, AAAI'19</a>
) らのContent Selection Gate g を適用する（これをどうやっているかがわからない）。<br><br><br><br>最終的に求めたrow-levelの表現とcell-levelの表現に対して、デコーダのhidden stateを利用してDual Attentionを行い、row-levelの表現からどの行に着目すべきか決めた後、その行の中からどのセルに着目するか決める、といったイメージで各セルの重みを求める。<br><br>論文中にはここまでしか書かれていないが、求めた各セルの重みでセルのrepresentationを重み付けして足し合わせ、最終的にそこから単語をpredictionするのだろうか・・・？よくわからない。</p>
<p><img src="https://user-images.githubusercontent.com/12249301/140321786-4d6a91c4-c864-490e-9921-5e6018db35c7.png" alt="image" loading="lazy"><br><br><br><br>RG, CS, CO, BLEUスコア、全てにおいてBaselineを上回っている（RGのTemplateを除く）。</p>
<p>実装: 


<a href="https://github.com/ernestgong/data2text-three-dimensions/" target="_blank" rel="noopener noreferrer">https://github.com/ernestgong/data2text-three-dimensions/</a>


</p></span><br><br>
<a class="button" href="articles/GraphConvolutionalNetwork.html" target="_blank" rel="noopener noreferrer">#GraphConvolutionalNetwork</a>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<a class="button" href="articles/WI.html" target="_blank" rel="noopener noreferrer">#WI</a>
<span class="issue_date">Issue Date: 2021-07-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/401" target="_blank" rel="noopener noreferrer" class="title-link">GRAPH-BASED KNOWLEDGE TRACING: MODELING STUDENT PROFICIENCY USING GRAPH NEURAL NETWORK, Nakagawa+, Tokyo University, WI'19</a>
<span class="snippet"><span>Comment</span><p>graph neural networkでKnoelwdge Tracingした論文。各conceptのproficiencyの可視化までしっかりやってそう。</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2021-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/394" target="_blank" rel="noopener noreferrer" class="title-link">Data-to-Text Generation with Content Selection and Planning, Puduppully+, AAAI'19</a>
<span class="snippet"><span>Comment</span><p>Rotowire Datasetに対するData2Text研究において代表的な論文の一つ。Wisemanモデル <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/207" target="_blank" rel="noopener noreferrer">Challenges in Data-to-Document Generation, Wiseman+ (with Rush), EMNLP'17</a>
 と共にベースラインとして利用されることが多い。</p>
<p>実装: 


<a href="https://github.com/ratishsp/data2text-plan-py" target="_blank" rel="noopener noreferrer">https://github.com/ratishsp/data2text-plan-py</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2021-06-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/388" target="_blank" rel="noopener noreferrer" class="title-link">On Empirical Comparisons of Optimizers for Deep Learning, Dami Choi+, N_A, arXiv'19</a>
<span class="snippet"><span>Summary</span>- 深層学習のオプティマイザの比較は重要であり、ハイパーパラメータの探索空間が性能に影響することが示唆されている。特に、適応的勾配法は常に他のオプティマイザよりも性能が低下しないことが実験で示されており、ハイパーパラメータのチューニングに関する実用的なヒントも提供されている。</span>
<span class="snippet"><span>Comment</span><p>SGD, Momentum,RMSProp, Adam,NAdam等の中から、どの最適化手法(Optimizer)が優れているかを画像分類と言語モデルにおいて比較した研究（下記日本語解説記事から引用）</p>
<p>日本語での解説: 


<a href="https://akichan-f.medium.com/optimizer%E3%81%AF%E3%81%A9%E3%82%8C%E3%81%8C%E5%84%AA%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E3%81%8B-on-empirical-comparisons-of-optimizers-for-deep-learning%E3%81%AE%E7%B4%B9%E4%BB%8B-f843179e8a8d" target="_blank" rel="noopener noreferrer">https://akichan-f.medium.com/optimizerはどれが優れているか-on-empirical-comparisons-of-optimizers-for-deep-learningの紹介-f843179e8a8d</a>


</p>
<p>Adamが良いのだけど、学習率以外のハイパーパラメータをチューニングしないと本来のパフォーマンス発揮されないかもよ、という感じっぽい</p>
<p>ICLR 2020 Open Review: 


<a href="https://openreview.net/forum?id=HygrAR4tPS" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=HygrAR4tPS</a>


</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=HygrAR4tPS" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=HygrAR4tPS</a>


</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CTRPrediction.html" target="_blank" rel="noopener noreferrer">#CTRPrediction</a>
<a class="button" href="articles/CVRPrediction.html" target="_blank" rel="noopener noreferrer">#CVRPrediction</a>
<a class="button" href="articles/SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<span class="issue_date">Issue Date: 2021-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/366" target="_blank" rel="noopener noreferrer" class="title-link">Conversion Prediction Using Multi-task Conditional Attention Networks to Support the Creation of Effective Ad Creatives, Kitada+, KDD'19</a>
<span class="snippet"><span>Comment</span><p># Overview<br><br>広告のCVR予測をCTR予測とのmulti-task learningとして定式化。<br><br>構築した予測モデルのattention distributionを解析することで、high-qualityなクリエイティブの作成を支援する。<br><br>genderやgenre等の情報でattentionのweightを変化させるconditional attentionが特徴的。<br><br>→ これによりgender, genreごとのCVRしやすい広告の特徴の違いが可視化される<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120273298-45d9c400-c2e9-11eb-9e62-24afd6323d01.png" alt="image" loading="lazy"><br><br><br><br>loss functionは、MSEにλを導入しclickのlossを制御している（CVRに最適化したいため）。ただ、実験ではλ=1で実験している。<br><br>outputはRegressionでCVR, CTRの値そのものを予測している（log lossを使う一般的なCTR Prediction等とは少し条件が違う; 多分予測そのものより、予測モデルを通じて得られるCVRが高いcreativeの分析が主目的なため）。<br><br><img src="https://user-images.githubusercontent.com/12249301/120273365-5db14800-c2e9-11eb-9888-a98443a7adbc.png" alt="image" loading="lazy"><br><br><br><br># Experiments<br><br>データとして、2017年8月〜2018年8月の間にGunosy Adsでdeliverされた14,000種類のad creativeを利用。<br><br>clickとconversionのfrequency（clickはlong-tailだが、conversionはほとんど0か1のように見える）<br><br><img src="https://user-images.githubusercontent.com/12249301/120275800-cf3ec580-c2ec-11eb-87a0-e0dacd230c5e.png" alt="image" loading="lazy"><br><br><br><br>5-fold crossvalidationを、fold内でcampaignが重複しないようにad creativeに対して行い、conversion数の予測を行なった。<br><br>評価を行う際はNDCGを用い、top-1%のconversion数を持つcreativeにフォーカスし評価した。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120277549-26459a00-c2ef-11eb-9a7e-2ba8832ed26a.png" alt="image" loading="lazy"><br><br><br><br>MSEで評価した場合、multi-task learning, conditional attentionを利用することでMSEが改善している。多くのcreativeのconversionは0なので、conversion数が&gt;0のものに着目して評価しても性能が改善していることがわかる。<br><br><br><br>NDCGを利用した評価でも同様な傾向<br><br><img src="https://user-images.githubusercontent.com/12249301/120277916-a1a74b80-c2ef-11eb-8530-0399ee43c2eb.png" alt="image" loading="lazy"><br><br><br><br>conditional attentionのheatmap<br><br><img src="https://user-images.githubusercontent.com/12249301/120274299-9bfb3700-c2ea-11eb-939e-6593056e109b.png" alt="image" loading="lazy"><br><br><br><br>genderごとにdistributionの違いがあって非常におもしろい<br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/CommentGeneration.html" target="_blank" rel="noopener noreferrer">#CommentGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2019-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/322" target="_blank" rel="noopener noreferrer" class="title-link">Coherent Comment Generation for Chinese Articles with a Graph-to-Sequence Model, Li+ ,ACL'19</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2019-08-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/318" target="_blank" rel="noopener noreferrer" class="title-link">Review Response Generation in E-Commerce Platforms with External Product Information, Zhao+, WWW'19</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2019-08-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/316" target="_blank" rel="noopener noreferrer" class="title-link">Automatic Generation of Personalized Comment Based on User Profile, Zeng+, ACL'19 Student Research Workshop</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2019-05-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/313" target="_blank" rel="noopener noreferrer" class="title-link">Multimodal Review Generation for Recommender Systems, Truong+, WWW'19</a>
<span class="snippet"><span>Comment</span><p>Personalized Review Generationと、Rating Predictionを同時学習した研究（同時学習自体はすでに先行研究がある）。<br><br>また、先行研究のinputは、たいていはuser, itemであるが、multi-modalなinputとしてレビューのphotoを活用したという話。<br><br><br><br>まだあまりしっかり読んでいないが、モデルのstructureはシンプルで、rating predictionを行うDNN、テキスト生成を行うLSTM（fusion gateと呼ばれる新たなゲートを追加）、画像の畳み込むCNNのハイブリッドのように見える。</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ContextAware.html" target="_blank" rel="noopener noreferrer">#ContextAware</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2019-01-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/300" target="_blank" rel="noopener noreferrer" class="title-link">Response Generation by Context-aware Prototype Editing, Wu+, AAAI'19</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<span class="issue_date">Issue Date: 2025-08-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2367" target="_blank" rel="noopener noreferrer" class="title-link">Learning to Generate Move-by-Move Commentary for Chess Games from Large-Scale Social Forum Data, Jhamtani+, ACL'18</a>
<span class="snippet"><span>Comment</span><p>データセットの日本語解説（過去の自分の資料）:


<a href="https://speakerdeck.com/akihikowatanabe/data-to-text-datasetmatome-summary-of-data-to-text-datasets?slide=66" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/akihikowatanabe/data-to-text-datasetmatome-summary-of-data-to-text-datasets?slide=66</a>


</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<span class="issue_date">Issue Date: 2025-07-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2245" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Interest Network for Click-Through Rate Prediction, Guorui Zhou+, KDD'18</a>
<span class="snippet"><span>Summary</span>- クリック率予測において、固定長の表現ベクトルがユーザーの多様な興味を捉えるのを妨げる問題に対処するため、ローカルアクティベーションユニットを用いた「Deep Interest Network（DIN）」を提案。DINは広告に応じてユーザーの興味を適応的に学習し、表現力を向上させる。実験により、提案手法は最先端の手法を上回る性能を示し、Alibabaの広告システムに成功裏に展開されている。</span>
<span class="snippet"><span>Comment</span><p>ユーザの過去のアイテムとのインタラクションを、候補アイテムによって条件づけた上でattentionによって重みづけをすることでcontext vectorを作成し活用する。これにより候補アイテムごとにユーザの過去のアイテムとのインタラクションのうち、どれを重視するかを動的に変化させることができるようにした研究。最終的にユーザプロファイルをベースにしたEmbeddingとコンテキスト（セッションの情報など）の情報をベースにしたEmbeddingと、上述したcontext vectorをconcatし、linearな変換を噛ませてスコアを出力する。学習はクリックスルーログ等のインタラクションデータに対してNLL lossを適用する。通称DIN。<br><br><img src="https://github.com/user-attachments/assets/d88206a0-7eb0-4a78-8d2d-47460d66be61" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2196" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Revisiting Small Batch Training for Deep Neural Networks, Dominic Masters+, arXiv'18</a>
<span class="snippet"><span>Summary</span>- ミニバッチサイズが深層ニューラルネットワークのトレーニング性能に与える影響を実験的に比較。大きなミニバッチは計算の並列性を向上させるが、小さなミニバッチは一般化性能を高め、安定したトレーニングを実現。最良の性能はミニバッチサイズ$m = 2$から$m = 32$の範囲で得られ、数千のミニバッチサイズを推奨する研究とは対照的。</span>
<span class="snippet"><span>Comment</span><p>{Res, Reduced Alex}Netにおいて、バッチサイズを大きくすると、学習が安定しかつ高い予測性能を獲得できる学習率のrangeが小さくなる。一方、バッチサイズが小さいと有効な学習率のrangeが広い。また、バッチサイズが小さい場合は、勾配計算とパラメータのアップデートがより頻繁に行われる。このため、モデルの学習がより進んだ状態で個々のデータに対して勾配計算が行われるため、バッチサイズが大きい場合と比べるとモデルがより更新された状態で各データに対して勾配が計算されることになるため、学習が安定し良い汎化性能につながる、といった話の模様。<br><br><img src="https://github.com/user-attachments/assets/f02f9016-6e9f-476d-a4c1-4f64bd51e9d5" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1856" target="_blank" rel="noopener noreferrer" class="title-link">Group Normalization, Yuxin Wu+, arXiv'18</a>
<span class="snippet"><span>Summary</span>- グループ正規化（GN）は、バッチ正規化（BN）の代替手段として提案され、バッチサイズに依存せず安定した精度を提供します。特に、バッチサイズ2のResNet-50では、GNがBNよりも10.6%低い誤差を示し、一般的なバッチサイズでも同等の性能を発揮します。GNは物体検出やビデオ分類などのタスクでBNを上回る結果を示し、簡単に実装可能です。</span>
<span class="snippet"><span>Comment</span><p>BatchNormalizationはバッチサイズが小さいとうまくいかず、メモリの制約で大きなバッチサイズが設定できない場合に困るからバッチサイズに依存しないnormalizationを考えたよ。LayerNormとInstanceNormもバッチサイズに依存しないけど提案手法の方が画像系のタスクだと性能が良いよ、という話らしい。<br><br>各normalizationとの比較。分かりやすい。<br><img src="https://github.com/user-attachments/assets/128a6a2e-cac7-4d6a-9cf6-31119fb6b187" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<span class="issue_date">Issue Date: 2022-06-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/457" target="_blank" rel="noopener noreferrer" class="title-link">Deep contextualized word representations, Peters+, Allen Institute for Artificial intelligence, NAACL'18</a>
<span class="snippet"><span>Comment</span><p>ELMo論文。<br>通常のword embeddingでは一つの単語につき一つの意味しか持たせられなかったが、文脈に応じて異なる意味を表現できるようなEmbeddingを実現し（同じ単語でも文脈に応じて意味が変わったりするので。たとえばrightは文脈に応じて右なのか、正しいなのか、権利なのか意味が変わる）様々な言語処理タスク（e.g. Question Answering, Sentiment Analysisなど）でSoTAを達成。<br><br><img src="https://user-images.githubusercontent.com/12249301/172505957-a2fc5319-5670-4807-a870-31377227299e.png" alt="image" loading="lazy"><br><br>Embedding Layer + 2層のLSTM（1,2の間にはresidual connection）+ linear layerで言語モデルを構成し、順方向言語モデルと逆方向言語モデルを同時に独立して学習する（双方向LSTMではない;損失関数が両方向の言語モデルの対数尤度の和になっている）。<br>また、Linear LayerとEmbedding Layerのパラメータは両方向の言語モデルで共有されている。<br><br>k番目の単語のEmbedding Layerの出力ベクトル、各LSTMのhidden stateをタスクspecificなスカラーパラメタs_taskで足し合わせ、最後にベクトルのスケールを調整するパラメタγ_taskで大きさを調整する。これにより、k番目の単語のELMo Embeddingを得る。<br>単語単体の意味だけでこと足りるタスクの場合はEmbedding Layerの出力ベクトルに対する重みが大きくなり、文脈を考慮した情報が欲しい場合はLSTMのhidden stateに対する重みが大きくなるイメージ（LSTMの層が深いほど意味的semanticな情報を含み、浅いほど文法的syntacticな情報を含んでいる）。<br><br>使い方としては簡単で、ELMoを事前学習しておき、自身のNNモデルのWord Embeddingに（場合によってはRNNのhidden stateにも）、入力文から得られたELMo Embeddingをconcatして順伝搬させるだけで良い。</p>
<p>s_taskとγ_taskはtrainableなパラメータで、<br>ELMoを適用した先のNNモデルの訓練時に、NNモデルのパラメタと一緒にチューニングする（と思われる）。<br><br>


<a href="https://github.com/allenai/allennlp/issues/1166" target="_blank" rel="noopener noreferrer">https://github.com/allenai/allennlp/issues/1166</a>


<br>


<a href="https://github.com/allenai/allennlp/issues/2552" target="_blank" rel="noopener noreferrer">https://github.com/allenai/allennlp/issues/2552</a>


</p>
<p>ELMoのEmbedding Layerでは、2048 characterの（vocab size?）n-gram convolution filter（文字ごとにembeddingし、単語のembeddingを得るためにfilterを適用する？）の後に2つのhighway networkをかませてlinearで512次元に落とすみたいなことごやられているらしい。ここまで追えていない。<br><br>詳細は下記<br>


<a href="https://datascience.stackexchange.com/questions/97867/how-does-the-character-convolution-work-in-elmo" target="_blank" rel="noopener noreferrer">https://datascience.stackexchange.com/questions/97867/how-does-the-character-convolution-work-in-elmo</a>


</p></span><br><br>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/StudentPerformancePrediction.html" target="_blank" rel="noopener noreferrer">#StudentPerformancePrediction</a>
<a class="button" href="articles/EDM.html" target="_blank" rel="noopener noreferrer">#EDM</a>
<span class="issue_date">Issue Date: 2021-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/432" target="_blank" rel="noopener noreferrer" class="title-link">Modeling Hint-Taking Behavior and Knowledge State of Students with Multi-Task Learning, Chaudry+, Indian Institute of Technology, EDM'18</a>
<span class="snippet"><span>Comment</span><p>DKVMN (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/352" target="_blank" rel="noopener noreferrer">Dynamic Key-Value Memory Networks for Knowledge Tracing, Yeung+, WWW'17</a>
)をhint-takingタスクとmulti-task learningした研究<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/141440172-6f708367-1804-4b0c-8c1a-4b7f80124bd7.png" alt="image" loading="lazy"><br><br><br><br>DKVMNと比較して、微小ながら性能向上<br><br><img src="https://user-images.githubusercontent.com/12249301/141440264-1426ac60-5b60-46f8-bca9-8bc7f383a397.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<span class="issue_date">Issue Date: 2021-10-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/415" target="_blank" rel="noopener noreferrer" class="title-link">Point precisely: Towards ensuring the precision of data in generated texts using delayed copy mechanism., Li+, Peking University, COLING'18</a>
<span class="snippet"><span>Comment</span><p>
<strong># 概要<br><br>DataToTextタスクにおいて、生成テキストのデータの精度を高める手法を提案。two stageアルゴリズムを提案。①encoder-decoerモデルでslotを含むテンプレートテキストを生成。②Copy Mechanismでslotのデータを埋める、といった手法。<br><br>①と②はそれぞれ独立に学習される。<br><br><br><br>two stageにするモチベーションは、<br><br>・これまでのモデルでは、単語の生成確率とコピー確率を混合した分布を考えていたが、どのように両者の確率をmergeするのが良いかはクリアではない。<br><br>→ 生成とコピーを分離して不確実性を減らした<br><br>・コピーを独立して考えることで、より効果的なpair-wise ranking loss functionを利用することができる<br><br>・テンプレート生成モデルは、テンプレートの生成に集中でき、slot fillingモデルはスロットを埋めるタスクに集中できる。これらはtrainingとtuningをより簡便にする。<br><br><br><br># モデル概要<br><br>モデルの全体像<br><br><img src="https://user-images.githubusercontent.com/12249301/138623391-6c876671-7c29-4d6a-8dfd-bd1feb623acd.png" alt="image" loading="lazy"><br><br><br><br>オリジナルテキストとテンプレートの例。テンプレートテキストの生成を学習するencoder-decoder（①）はTarget Templateを生成できるように学習する。テンプレートではエンティティが"<entity>"、数値が"<number>"というplace holderで表現されている。これらのスロットを埋めるDelayed Copy Networkは、スロットが正しく埋められるように学習される。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138623460-1415e0c2-2468-4c05-a8b8-685001c26bb7.png" alt="image" loading="lazy"><br><br><br><br># 実験結果<br><br><img src="https://user-images.githubusercontent.com/12249301/138624623-2f8944f5-8a7c-4de5-bbb8-cda9626e7018.png" alt="image" loading="lazy"><br><br><br><br>Relation Generation (RG)がCCと比べて10%程度増加しているので、data fidelityが改善されている。<br><br>また、BLEUスコアも約2ポイント改善。これはentityやnumberが適切に埋められるようになっただけでなく、テンプレートがより適切に生成されているためであると考えられる。<br><br><br><br>## 参考：<br><br>• Relation Generation (RG)：出力文から(entity, value)の関係を抽出し，抽出された関係の数と，それらの関係が入力データに対して正しいかどうかを評価する (Precision)．ただし entity はチーム名や選手名などの動作の主体，value は得点数やアシスト数などの記録である．<br><br>• Content Selection (CS)：出力文とリファレンスから (entity, value) の関係を抽出し，出力文から抽出された関係のリファレンスから抽出された関係に対する Precision，Recall で評価する．<br><br>• Content Ordering (CO)：出力文とリファレンスから (entity, value) の関係を抽出し，それらの間の正規化 DamerauLevenshtein 距離 [7] で評価する．<br><br>(from <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/409" target="_blank" rel="noopener noreferrer">過去情報の内容選択を取り入れた スポーツダイジェストの自動生成, 加藤+, 東工大, NLP'21</a>
&lt;/strong&gt;
<br>
 )&lt;/p&gt;&lt;/span&gt;<br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2021-09-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/406" target="_blank" rel="noopener noreferrer" class="title-link">Operation-guided Neural Networks for High Fidelity Data-To-Text Generation, Nie+, Sun Yat-Sen University, EMNLP'18</a>
<span class="snippet"><span>Comment</span><p># 概要<br><br>既存のニューラルモデルでは、生データ、あるいはそこから推論された事実に基づいて言語を生成するといったことができていない（e.g. 金融, 医療, スポーツ等のドメインでは重要）。<br><br>たとえば下表に示した通り、"edge"という単語は、スコアが接戦（95-94=1 -&gt; スコアの差が小さい）であったことを表現しているが、こういったことを既存のモデルでは考慮して生成ができない。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138627286-c9bde402-0129-4b82-9faf-80fcde08cdc8.png" alt="image" loading="lazy"><br><br><br><br>これを解決するために、演算（operation）とニューラル言語モデルを切り離す（事前に計算しておく）といったことが考えられるが、<br><br>① 全てのフィールドに対してoperationを実行すると、探索空間が膨大になり、どの結果に対して言及する価値があるかを同定するのが困難（言及する価値がある結果がほとんど存在しない探索空間ができてしまう）<br><br>② 演算結果の数値のスパンと、言語選択の対応関係を確立させるのが困難（e.g. スコアの差が1のとき"edge"と表現する、など）<br><br>といった課題がある。<br><br><br><br>①に対処するために、事前にraw dataに対して演算を適用しその結果を利用するモデルを採用。どの演算結果を利用するかを決定するために、gating-mechanismを活用する。<br><br>②に対処するために、quantization layerを採用し、演算結果の数値をbinに振り分け、その結果に応じて生成する表現をguideするようなモデルを採用する。<br><br><br><br># モデル概要<br><br>モデルはrecord encoder(h_{i}^{ctx}を作る)、operation encoder(h_{i}^{op}を作る)、operation result encoder(h_{i}^{res}を作る)によって構成される。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138628639-0c64d7aa-22e7-4ee7-a55f-65736e607ed2.png" alt="image" loading="lazy"><br><br><br><br>## record encoder<br><br>record encoderは、wisemanらと同様に、index (e.g. row 2), column (e.g. column Points), value (e.g. 95)のword embeddingを求め、それらをconcatしたものをbi-directional RNNに入力し求める。<br><br><br><br>## operation encoder<br><br>operation encoderでは、operation op_{i}は、1) operationの名称 (e.g. minus) 2) operationを適用するcolumn (e.g. Points), 3) operationを適用するrow (e.g. {1, 2}などのrow indexの集合)によって構成されており、これらのembeddingをlookupしconcatした後、non-linear layerで変換することによってoperationのrepresentationを取得する。3)operationを適用するrowについては、複数のindexによって構成されるため、各indexのembeddingをnon-linear layerで変換したベクトルを足し合わせた結果に対してtanhを適用したベクトルをembeddingとして利用する。<br><br><br><br>## operation result encoder<br><br>operation result encoderは、scalar results（minus operationにより-1）およびindexing results (argmax operationによりindex 2)の二種類を生成する。これら二種類に対して異なるencoding方法を採用する。<br><br>### scalar results<br><br>scalar resultsに対しては、下記式でscalar valueをquantization vector（q_{i}）に変換する。qutization vectorのlengthはLとなっており、Lはbinの数に相当している。つまり、quantization vectorの各次元がbinの重みに対応している。その後、quantization vectorに対してsoftmaxを適用し、quantization unit（quantization vectorの各次元）の重みを求める。最後に、quantization embeddingと対応するquantization unitの重み付き平均をとることによってh_{i}^{res}を算出する。<br><br><br><br>Q. 式を見るとW_{q}がscalar resultの値によって定数倍されるだけだから、softmaxによって求まるquantization unitの重みの序列はscalar resultによって変化しなそうに見えるが、これでうまくいくんだろうか・・・？序列は変わらなくても各quantization unit間の相対的な重みの差が変化するから、それでうまくscalar値の変化を捉えられるの・・・か・・・？<br><br><br><br>### indexing results<br><br>indexing resultsについては、h_{i}^{res}をシンプルにindexのembeddingとする。<br><br><br><br>## Decoder<br><br>context vectorの生成方法が違う。従来のモデルと比較して、context vectorを生成する際に、レコードをoperationの両方をinputとする。<br><br><img src="https://user-images.githubusercontent.com/12249301/138632508-f9407ff9-3e8a-4efd-91d4-6879e81331a6.png" alt="image" loading="lazy"><br><br><br><br>operationのcontext vector c_{t}^{op}とrecordsのcontext vector c_{t}^{ctx}をdynamic gate λ_{t}によって重み付けし最終的なcontext vectorを求める。λ_{t}は、t-1時点でのデコーダのhidden stateから重みを求める。<br><br>c_{t}^{op}は次式で計算され：<br><br><img src="https://user-images.githubusercontent.com/12249301/138633048-ca82ff5f-9755-4e5f-a658-774354cde987.png" alt="image" loading="lazy"><br><br>c_{t}^{scl, idx}は、<br><br><img src="https://user-images.githubusercontent.com/12249301/138633078-f74de4b3-f742-48f9-9f29-64489f8f477a.png" alt="image" loading="lazy"><br><br>よって計算される。要は、decoderのt-1のhidden stateと、operation vectorを用いて、j番目のoperationの重要度（β）を求め、operationの重要度によって重み付けしてoperation result vectorを足し合わせることによって、context vectorを算出する。<br><br>また、recordのcontext vector c_{t}^{ctx}は、h_{j}^{res}とh_{j}^{op}と、h_{j}^{ctx}に置き換えることによって算出される。 <br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138631847-e3076003-b619-49e4-afad-0edffaace060.png" alt="image" loading="lazy"><br><br><br><br>## データセット<br><br>人手でESPN, ROTOWIRE, WIKIBIOデータセットのReferenceに対して、factを含むtext spanと、そのfactの種類を3種類にラベル付した。input factsはinput dataから直接見つけられるfact, inferred factsはinput dataから直接見つけることはできないが、導き出すことができるfact、unsupported factsはinput dataから直接あるいは導き出すことができないfact。wikibioデータセットはinferred factの割合が少ないため、今回の評価からは除外し、ROTOWIRE, ESPNを採用した。特にESPNのheadline datasetがinferred factsが多かった。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138636048-4b8225f7-f685-45b9-ae06-1af57e09044d.png" alt="image" loading="lazy"></p>
<p># 結果<br><br>## 自動評価<br><br><img src="https://user-images.githubusercontent.com/12249301/138634010-2de062dc-d2dc-48af-8724-f6fa950e8144.png" alt="image" loading="lazy"><br><br><br><br>wiseman modelをOpAttがoutperformしている。また、Seq2Seq+op+quant（Seq2Seq+copyに対してoperation result encoderとquantization layerを適用したもの）はSeq2Seq+Copyを上回っているが、OpAttほとではないことから、提案手法のoperation encoderの導入とgating mechanismが有効に作用していることがわかる。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138635201-462ef128-58d1-4084-ae70-5acccd34087b.png" alt="image" loading="lazy"><br><br><br><br>採用するoperationによって、生成されるテキストも異なるようになっている。<br><br><br><br>## 人手評価<br><br>3人のNBAに詳しいEnglish native speakerに依頼してtest dataに対する生成結果にアノテーションをしてもらった。アノテーションは、factを含むspanを同定し、そのfactがinput facts/inferred facts/unsupported factsのどれかを分類してもらった。最後に、そのfactが入力データからsupportされるかcontradicted（矛盾するか）かをアノテーションしてもらった。<br><br>提案手法が、より多くのinferred factsについて言及しながらも、少ない#Cont.であることがわかった。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138636756-74da3999-45e7-489f-9d0a-ac68416d3de0.png" alt="image" loading="lazy"><br><br></p>
<p># 分析<br><br>## Quantizationの効果<br><br>チーム間のスコアの差が、5つのbinのに対してどれだけの重みを持たせたかのheatmap。似たようなスコアのgapの場合は似たような重みになることがわかる。ポイント差の絶対値が小さい場合は、重みの分布の分散が大きくなるのでより一般的な単語で生成を行うのに対し、絶対値が大きい場合は分散が小さくなるため、unique wordをつかって生成するようになる。<br><br><img src="https://user-images.githubusercontent.com/12249301/138637300-04738ba9-8e5f-4b07-8ed2-1a62c14cb7fe.png" alt="image" loading="lazy"><br><br><br><br>pointのgapの大きさによって利用される単語も変化していることがわかる。ポイント差がちいさいときは"edge"、大きいときは"blow out"など。<br><br><img src="https://user-images.githubusercontent.com/12249301/138637614-19a95fba-9904-4378-86d0-3d1bd513be8a.png" alt="image" loading="lazy"><br><br><br><br>## gating mechanismの効果<br><br>生成テキストのtimestepごとのgateの重みの例。色が濃ければ濃いほど、operation resultsの情報を多く利用していることを表す。チームリーダーを決める際や（horford）勝者を決める際に(Hawks)、operation resultsの重みが大きくなっており、妥当な重み付けだと考察している。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/138637813-4b4a2b1d-c5c5-4f7a-96b3-59df3a56aeb2.png" alt="image" loading="lazy"><br><br><br><br></p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/Contents-based.html" target="_blank" rel="noopener noreferrer">#Contents-based</a>
<a class="button" href="articles/NewsRecommendation.html" target="_blank" rel="noopener noreferrer">#NewsRecommendation</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2021-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/363" target="_blank" rel="noopener noreferrer" class="title-link">DKN: Deep Knowledge-Aware Network for News Recommendation, Wang+, WWW'18</a>
<span class="snippet"><span>Comment</span><p>
<strong># Overview<br><br>Contents-basedな手法でCTRを予測しNews推薦。newsのタイトルに含まれるentityをknowledge graphと紐づけて、情報をよりリッチにして活用する。<br><br>CNNでword-embeddingのみならず、entity embedding, contextual entity embedding（entityと関連するentity）をエンコードし、knowledge-awareなnewsのrepresentationを取得し予測する。<br><br>※ contextual entityは、entityのknowledge graph上でのneighborhoodに存在するentityのこと（neighborhoodの情報を活用することでdistinguishableでよりリッチな情報を活用できる）<br><br><br><br>CNNのinputを\[\[word_ embedding\], \[entity embedding\], \[contextual entity embedding\]\](画像のRGB)のように、multi-channelで構成し3次元のフィルタでconvolutionすることで、word, entity, contextual entityを表現する空間は別に保ちながら（同じ空間で表現するのは適切ではない）、wordとentityのalignmentがとれた状態でのrepresentationを獲得する。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120255506-11eda700-c2c7-11eb-89a9-3a855652a59e.png" alt="image" loading="lazy"><br><br><br><br># Experiments<br><br>BingNewsのサーバログデータを利用して評価。<br><br>データは (timestamp, userid, news url, news title, click count (0=no click, 1=click))のレコードによって構成されている。<br><br>2016年11月16日〜2017年6月11日の間のデータからランダムサンプリングしtrainingデータセットとした。<br><br>また、2017年6月12日〜2017年8月11日までのデータをtestデータセットとした。<br><br><br><br>word/entity embeddingの次元は100, フィルタのサイズは1,2,3,4とした。loss functionはlog lossを利用し、Adamで学習した。<br><br><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120271172-d0202900-c2e5-11eb-9748-a0417308ca48.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120256387-f5526e80-c2c8-11eb-84ca-9b9dc617f048.png" alt="image" loading="lazy"><br><br><br><br><br><br>DeepFM超えを達成。<br><br>entity embedding, contextual entity embeddingをablationすると、AUCは2ポイントほど現象するが、それでもDeepFMよりは高い性能を示している。<br><br>また、attentionを抜くとAUCは1ポイントほど減少する。<br><br><br><br>1ユーザのtraining/testセットのサンプル<br><br><img src="https://user-images.githubusercontent.com/12249301/120272323-dc0cea80-c2e7-11eb-8c2a-0e43be3e069b.png" alt="image" loading="lazy"><br><br>&lt;/p&gt;<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/365" target="_blank" rel="noopener noreferrer">Sentiment analysis with deeply learned distributed representations of variable length texts, Hong+, Technical Report. Technical report, Stanford University, 2015</a>
&lt;/strong&gt;
<br>
 によって経験的にRNN, Recursive Neural Network等と比較して、sentenceのrepresentationを獲得する際にCNNが優れていることが示されているため、CNNでrepresentationを獲得することにした模様（footprint 7より）</p>
<p>Factorization Machinesベースドな手法（LibFM, DeepFM）を利用する際は、TF-IDF featureと、averaged entity embeddingによって構成し、それをuser newsとcandidate news同士でconcatしてFeatureとして入力した模様</p>
<p>content情報を一切利用せず、ユーザのimplicit feedbackデータ（news click）のみを利用するDMF（Deep Matrix Factorization）の性能がかなり悪いのもおもしろい。やはりuser-item-implicit feedbackデータのみだけでなく、コンテンツの情報を利用した方が強い。</p>
<p>（おそらく）著者によるtensor-flowでの実装: 


<a href="https://github.com/hwwang55/DKN" target="_blank" rel="noopener noreferrer">https://github.com/hwwang55/DKN</a>


</p>
<p>日本語解説<br><br>


<a href="https://qiita.com/agatan/items/24c6d8e00f2fc861bb04" target="_blank" rel="noopener noreferrer">https://qiita.com/agatan/items/24c6d8e00f2fc861bb04</a>


</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/StudentPerformancePrediction.html" target="_blank" rel="noopener noreferrer">#StudentPerformancePrediction</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2021-05-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/354" target="_blank" rel="noopener noreferrer" class="title-link">Exercise-Enhanced Sequential Modeling for Student Performance Prediction, Hu+, AAAI'18</a>
<span class="snippet"><span>Comment</span><p>従来のStudent Performance PredictionタスクではKnowledge Componentと問題に対する過去の正誤を入力として予測を行っていて、問題テキストを通じて得られる問題そのものの難しさは明示的に考慮できていなかった。<br><br>なので、knowledge componentではなく、問題テキストそのものを使ってStudent Performance Predictionしてみたら性能よくなりました、という話。<br><br>問題テキストを利用してNeural-basedなアプローチでStudent Performance Predictionした最初の論文だと思う。<br><br>本論文ではKnowledge Tracing的なknowledge componentに対するproficiencyを求めることは考慮されていないが、ジャーナル版 <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/353" target="_blank" rel="noopener noreferrer">EKT: Exercise-aware Knowledge Tracing for Student Performance Prediction, Hu+, IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, 2019</a>
 では、そのような点も考慮されたモデルの拡張が行われていてさらに洗練されている。</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/FactorizationMachines.html" target="_blank" rel="noopener noreferrer">#FactorizationMachines</a>
<a class="button" href="articles/CTRPrediction.html" target="_blank" rel="noopener noreferrer">#CTRPrediction</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2020-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/341" target="_blank" rel="noopener noreferrer" class="title-link">Field Weighted Factorization Machines for Click-Through Rate Prediction in Display Advertising, Pan+, WWW'18</a>
<span class="snippet"><span>Comment</span><p>CTR予測でbest-performingなモデルと言われているField Aware Factorization Machines(FFM)では、パラメータ数がフィールド数×特徴数のorderになってしまうため非常に多くなってしまうが、これをよりメモリを効果的に利用できる手法を提案。FFMとは性能がcomparableであるが、パラメータ数をFFMの4%に抑えることができた。</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/CommentGeneration.html" target="_blank" rel="noopener noreferrer">#CommentGeneration</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2019-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/321" target="_blank" rel="noopener noreferrer" class="title-link">Netizen-Style Commenting on Fashion Photos: Dataset and Diversity Measures, Lin+, WWW'18</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/RecSys.html" target="_blank" rel="noopener noreferrer">#RecSys</a>
<span class="issue_date">Issue Date: 2019-08-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/317" target="_blank" rel="noopener noreferrer" class="title-link">Improving Explainable Recommendations with Synthetic Reviews, Ouyang+, RecSys'18</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/GraphConvolutionalNetwork.html" target="_blank" rel="noopener noreferrer">#GraphConvolutionalNetwork</a>
<a class="button" href="articles/ESWC.html" target="_blank" rel="noopener noreferrer">#ESWC</a>
<span class="issue_date">Issue Date: 2019-05-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/312" target="_blank" rel="noopener noreferrer" class="title-link">Modeling Relational Data with Graph Convolutional Networks, Michael Schlichtkrull+, N_A, ESWC'18</a>
<span class="snippet"><span>Summary</span>- 知識グラフは不完全な情報を含んでいるため、関係グラフ畳み込みネットワーク（R-GCNs）を使用して知識ベース補完タスクを行う。R-GCNsは、高度な多関係データに対処するために開発されたニューラルネットワークであり、エンティティ分類とリンク予測の両方で効果的であることを示している。さらに、エンコーダーモデルを使用してリンク予測の改善を行い、大幅な性能向上が見られた。</span>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/GraphConvolutionalNetwork.html" target="_blank" rel="noopener noreferrer">#GraphConvolutionalNetwork</a>
<a class="button" href="articles/SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<span class="issue_date">Issue Date: 2019-05-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/311" target="_blank" rel="noopener noreferrer" class="title-link">Graph Convolutional Neural Networks for Web-Scale Recommender Systems, Ying+, KDD'18</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2019-04-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/306" target="_blank" rel="noopener noreferrer" class="title-link">Personalized Review Generation by Expanding Phrases and Attending on Aspect-Aware Representations, Ni+, ACL'18</a>
<span class="snippet"><span>Comment</span><p><img src="https://user-images.githubusercontent.com/12249301/56010165-8fd44a00-5d1d-11e9-8cad-81a5178d95d2.png" alt="image" loading="lazy"><br><br><br><br>Personalized Review Generationタスクを、user, item, short phraseがgivenな時に、それを考慮して完全なレビューを生成するタスクとして定義。<br><br>short phraseとしては、item titleやreview summaryなどを利用している。<br><br>アイテムのaspectを考慮してレビューを生成できる点が新しい。<br><br>モデルとしては、aspect-awareなrepresentationを学習することによって、ユーザ・アイテムのaspectに関する嗜好（e.g. どの部分について言及したいか、など）を捉えたレビューを生成できるようにしている。<br><br>各aspectには代表的な単語が紐づいており、aspectに紐づく単語の生成確率をaspect-aware representationから求めたattentionによって制御し、生成時に下駄を履かせている。</p>
<p>PyTorch実装：


<a href="https://github.com/nijianmo/textExpansion/tree/master/expansionNet" target="_blank" rel="noopener noreferrer">https://github.com/nijianmo/textExpansion/tree/master/expansionNet</a>


</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2019-01-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/301" target="_blank" rel="noopener noreferrer" class="title-link">A Knowledge-Grounded Neural Conversation Model, Ghazvininejad+, AAAI'18, </a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<span class="issue_date">Issue Date: 2018-04-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/272" target="_blank" rel="noopener noreferrer" class="title-link">Deep Learning based Recommender System: A Survey and New Perspectives, Zhang+, CSUR'18</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DialogueGeneration.html" target="_blank" rel="noopener noreferrer">#DialogueGeneration</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2018-02-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/255" target="_blank" rel="noopener noreferrer" class="title-link">Personalizing Dialogue Agents: I have a dog, do you have pets too?, Zhang+, ACL'18</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/TACL.html" target="_blank" rel="noopener noreferrer">#TACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/92" target="_blank" rel="noopener noreferrer" class="title-link">Generating Sentences by Editing Prototypes, Guu+, TACL'18</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/General.html" target="_blank" rel="noopener noreferrer">#General</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/68" target="_blank" rel="noopener noreferrer" class="title-link">StarSpace: Embed All The Things, Wu+, AAAI'18</a>
<span class="snippet"><span>Comment</span><p>分類やランキング、レコメンドなど、様々なタスクで汎用的に使用できるEmbeddingの学習手法を提案。<br><br><br><br>Embeddingを学習する対象をEntityと呼び、Entityはbag-of-featureで記述される。<br><br>Entityはbag-of-featureで記述できればなんでもよく、<br><br>これによりモデルの汎用性が増し、異なる種類のEntityでも同じ空間上でEmbeddingが学習される。<br><br><br><br>学習方法は非常にシンプルで、Entity同士のペアをとったときに、relevantなpairであれば類似度が高く、<br><br>irelevantなペアであれば類似度が低くなるようにEmbeddingを学習するだけ。<br><br>たとえば、Entityのペアとして、documentをbag-of-words, bag-of-ngrams, labelをsingle wordで記述しテキスト分類、<br><br>あるいは、user_idとユーザが過去に好んだアイテムをbag-of-wordsで記述しcontent-based recommendationを行うなど、 応用範囲は幅広い。<br><br><br><br>5種類のタスクで提案手法を評価し、既存手法と比較して、同等かそれ以上の性能を示すことが示されている。<br><br><br><br>手法の汎用性が高く学習も高速なので、色々な場面で役に立ちそう。<br><br>また、異なる種類のEntityであっても同じ空間上でEmbeddingが学習されるので、学習されたEmbeddingの応用先が広く有用。</p>
<p>実際にSentimentAnalysisで使ってみたが（ポジネガ二値分類）、少なくともBoWのSVMよりは全然性能良かったし、学習も早いし、次元数めちゃめちゃ少なくて良かった。<br><br>StarSpaceで学習したembeddingをBoWなSVMに入れると性能が劇的に改善した。</p>
<p>解説：<br><br>


<a href="https://www.slideshare.net/akihikowatanabe3110/starspace-embed-all-the-things" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/starspace-embed-all-the-things</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/InformationExtraction.html" target="_blank" rel="noopener noreferrer">#InformationExtraction</a>
<a class="button" href="articles/ReadingComprehension.html" target="_blank" rel="noopener noreferrer">#ReadingComprehension</a>
<a class="button" href="articles/Zero/FewShotLearning.html" target="_blank" rel="noopener noreferrer">#Zero/FewShotLearning</a>
<a class="button" href="articles/CoNLL.html" target="_blank" rel="noopener noreferrer">#CoNLL</a>
<a class="button" href="articles/RelationExtraction.html" target="_blank" rel="noopener noreferrer">#RelationExtraction</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2556" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Zero-Shot Relation Extraction via Reading Comprehension, Omer Levy+, CoNLL'17</a>
<span class="snippet"><span>Summary</span>- 関係抽出を自然言語の質問に還元することで、ニューラル読解理解技術を活用し、大規模なトレーニングセットを構築可能にする。これにより、ゼロショット学習も実現。ウィキペディアのスロットフィリングタスクで、既知の関係タイプに対する高精度な一般化と未知の関係タイプへのゼロショット一般化が示されたが、後者の精度は低く、今後の研究の基準を設定。</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-04-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1911" target="_blank" rel="noopener noreferrer" class="title-link">Outrageously Large Neural Networks: The Sparsely-Gated  Mixture-of-Experts Layer, Noam Shazeer+, ICLR'17</a>
<span class="snippet"><span>Summary</span>- 条件付き計算を用いたスパースゲーテッドミクスチャーオブエキスパート（MoE）レイヤーを導入し、モデル容量を1000倍以上向上。学習可能なゲーティングネットワークが各例に対してスパースなエキスパートの組み合わせを決定。最大1370億パラメータのMoEをLSTM層に適用し、言語モデリングや機械翻訳で低コストで優れた性能を達成。</span>
<span class="snippet"><span>Comment</span><p>Mixture-of-Experts (MoE) Layerを提案した研究</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<span class="issue_date">Issue Date: 2023-12-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1185" target="_blank" rel="noopener noreferrer" class="title-link">Large Batch Training of Convolutional Networks, Yang You+, N_A, arXiv'17</a>
<span class="snippet"><span>Summary</span>- 大規模な畳み込みネットワークのトレーニングを高速化するために、新しいトレーニングアルゴリズムを提案しました。このアルゴリズムは、Layer-wise Adaptive Rate Scaling（LARS）を使用して、大きなバッチサイズでのトレーニングを行いながらモデルの精度を損なわずにトレーニングすることができます。具体的には、Alexnetを8Kのバッチサイズまでスケーリングし、Resnet-50を32Kのバッチサイズまでスケーリングしました。</span>
<span class="snippet"><span>Comment</span><p>BatchSizeを大きくすると性能が落ちますよ、系の話（CNN）<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/deeb60b7-548c-4e50-94db-ce98eaf268e3" alt="image" loading="lazy"></p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=rJ4uaX2aW" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=rJ4uaX2aW</a>


<br><br>ICLR'18にrejectされている<br><br>先行研究で提案よりも大きなバッチサイズを扱えるsynchronized SGDは強みだが、評価が一つのタスクのみなのでより増やした方がconvincingだということ、提案手法に追加のハイパーパラメータが必要な点が手法をless appealingにしてしまっていること、layer wise rate scailng (LARS)の理論的なjustificationが何か欲しいこと、先行研究との比較がクリアではないこと、などが理由な模様。</p></span><br><br>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<span class="issue_date">Issue Date: 2021-06-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/385" target="_blank" rel="noopener noreferrer" class="title-link">Deep Model for Dropout Prediction in MOOCs, Wang+, ICCSE'17</a>
<span class="snippet"><span>Comment</span><p>MOOCsにおける一つの大きな問題点としてDropout率が高いことがあげられ、これを防止するために様々なモデルが提案されてきた。これまで提案されてきたモデルでは人手によるfeature-engineeringが必要であることが問題である。なぜなら、feature-engineeringはdomain expertでないとできないし、time-consumingだから。加えて、あるデータにおいて有効だったfeatureが別のデータセットにおいて有効とは限らないことも多い。<br><br>そこで、neural networkを用いて人手でのfeature engineeringなしで、dropout predictionする手法を提案する。<br><br>評価した結果、feature-engineeringを行う既存手法とcomparableな性能を得た。</p>
<p>Recorded periodのactivity logが与えられたときに、Prediction Periodにおいてdropoutするか否かをbinary classificationする問題として定式化<br><br>Prediction periodに生徒のactivity logがあった場合、生徒はdropoutしていないとみなす。acitivity logが存在しない場合、生徒はdropoutしたとみなす。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/121481678-584daf00-ca07-11eb-8a26-df66ead947ff.png" alt="image" loading="lazy"><br><br><br><br>提案モデルはCNNとRNNの組み合わせ。個々のtime-unitごとのactivityをvectorに変換しInput Matrixを作成。その後、個々のtime-stepごとにCNNを適用しfeature mapを取得。取得したtime-stepごとのfeature mapをRNNに食わせて、最後にdropoutするか否かbinary classificationを行う。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/121485698-69002400-ca0b-11eb-88db-710dbd0866a3.png" alt="image" loading="lazy"><br><br><br><br>## 評価<br><br>KDDCup 2015のデータを利用。データセットはユーザの各コースへのenrollmentを表すデータと、各enrollmentIDごとのactivity _logの二種類のデータから構成される。実験では、record periodを30日とし、その後のprediction periodを10日とした（過去1ヶ月のデータを利用し、10日以内にdropoutするか否かを予測するタスク）。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/121487360-f98b3400-ca0c-11eb-91dc-74f40c67b8d6.png" alt="image" loading="lazy"><br><br><br><br>time-unit（time-sliceを構築する単位）は1時間とし、該当するtime-unitに存在するactivity records中のレコードは足し合わされ、該当time-unitのvectorとして表現。time-slice（時刻tとしてinputする単位）を1日とし、24個のtime-unit vectorのmatrixとして、時刻tのinputは表現される。実際はrecord periodが30日なので、このtime-slice のmatrixが30個（T=30）入力されることとなる。activity recordsのうち、source, event, course_IDの3種類のレコードをtime-unitのベクトルとして表現するために利用される。具体的には、source, event, course_IDをそれぞれone-hot vectorに変換し、それらのベクトルのtime-unit内に存在する全てのベクトルに対して足し合わせることで、time-unit vectorを表現している（正直これがあまり良いとは思わない）。</p>
<p><img src="https://user-images.githubusercontent.com/12249301/121488518-18d69100-ca0e-11eb-9c1f-23831c818d09.png" alt="image" loading="lazy"><br><br><br><br>評価の結果、予測結果は他の既存手法とcomparableな性能を達成した。<br><br>→ 正直one-hot encodingを足し合わせるだけの入力方法（embeddingを学習しないで、実質各eventが発生した回数をFeatureとして考慮しているだけなのでは？）だと、既存手法のfeature-engineeringとやっていることは対して変わらない気はするので、comparableな結果というのもうなずける。<br><br>なぜembeddingを学習しないのか。</p></span><br><br>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/AffectDetection.html" target="_blank" rel="noopener noreferrer">#AffectDetection</a>
<a class="button" href="articles/AIED.html" target="_blank" rel="noopener noreferrer">#AIED</a>
<span class="issue_date">Issue Date: 2021-06-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/380" target="_blank" rel="noopener noreferrer" class="title-link">Improving Sensor-Free Affect Detection Using Deep Learning, Botelho+, AIED'17</a>
<span class="snippet"><span>Comment</span><p>DKTが実はBKTと対して性能変わらない、みたいな話がreference付きで書かれている。Ryan Baker氏とNeil Heffernan氏の論文</p>
<p>Affect Detectionは、physical/psychological sensorを利用する研究が行われてきており、それらは様々な制約により（e.g. 経済的な問題や、政治の問題）実際のアプリケーションとしてdeployするには難しさがあった。これを克服するために、sensor-freeなモデルが研究されてきたが、予測性能はあまり高くなくreal-timeなinterventionを行うのに十分な性能となっていなかった。<br><br>一方で、近年DeepLearningが様々な分野で成功を収めてきており、教育分野での活用が限定的であるという状況がある。そこで、deepなsensor-freeモデルを提案。その結果、従来モデルをoutperformした。</p>
<p>データセットはASSISTmentsデータを利用し、フィールドワーカーが20秒おきに、class roomでASSISTmentsを利用する生徒を観察し、生徒のAffective Stateをラベル付けした（ラウンドロビン方式）。ラベルは下記の通り：<br><br>- bored<br><br>- frustrated<br><br>- confused<br><br>- engaged concentration<br><br>- other/impossible<br><br><br><br>ビデオコーディングなどとは違って、ラウンドロビン方式では特定の生徒の間でラベルの欠落が生まれるが（常に特定の生徒を監視しているわけにはいかず、class-room全体を巡回しなければいけないから？）、全てのラベルにはタイムスタンプが付与されているので、欠落はわかるようになっている。<br><br>合計で6つの学校における、646人の生徒に対する、7663のobservationが得られた。<br><br><br><br>また、各特定の感情ラベルが付与されている際には実際に生徒はASSISTmentsを利用しており、先行研究では51種類のaction-level featureが利用されており（生徒とシステムのinteractionを捉える; e.g. reponse behavior, timeworking, hintやscaffoldingの利用の有無など）、今回もそういったfeatureも予測に利用する。<br><br>各observationのinterval(=clip)には複数のアクションが含まれており、それらを集約することで、最終的に204種類のfeatureをobservation intervalごとに作成し利用（feature engineeringしてるっぽい）。</p>
<p>RNN, LSTM, GRUの3種類のNNを用いて、204次元のfeature vectorをinputとし、各clipの4種類の感情ラベル（bored, frustrated, confused, engaged concentration）をsoftmaxで予測する。<br><br>前回のclipが5分未満のclipについては、連続したclipとしてモデルに入力し、5分を超過したものについては新たな別のsequenceとして扱った模様。</p>
<p><img src="https://user-images.githubusercontent.com/12249301/123304125-84197a80-d559-11eb-9ed8-67fa809b506c.png" alt="image" loading="lazy"><br><br><br><br>従来手法を大幅にoutperform。しっかり読んでいないが、resampoingは、ラベルの偏りを調整したか否かだと思われる。</p></span><br><br>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/StudentPerformancePrediction.html" target="_blank" rel="noopener noreferrer">#StudentPerformancePrediction</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2021-05-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/352" target="_blank" rel="noopener noreferrer" class="title-link">Dynamic Key-Value Memory Networks for Knowledge Tracing, Yeung+, WWW'17</a>
<span class="snippet"><span>Comment</span><p>DeepなKnowledge Tracingの代表的なモデルの一つ。KT研究において、DKTと並んでbaseline等で比較されることが多い。</p>
<p>DKVMNと呼ばれることが多く、Knowledge Trackingができることが特徴。</p>
<p>モデルは下図の左側と右側に分かれる。左側はエクササイズqtに対する生徒のパフォーマンスptを求めるネットワークであり、右側はエクササイズqtに対する正誤情報rtが与えられた時に、メモリのvalueを更新するネットワークである。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/166176653-d1ccf7ac-8743-4c79-bdae-2a4021785c7c.png" alt="image" loading="lazy"><br><br><br><br>メモリとは生徒のknowledge stateを保持している行列であり、keyとvalueのペアによって形成される。keyとvalueは両者共にdv次元のベクトルで表現される。keyはコンセプトを表し、valueがそれぞれのコンセプトに対する生徒のknowledge stateを表している。ここで、コンセプトとスキルタグは異なる概念であり、スキルタグを生成される元となった概念のことをコンセプトと呼んでいる。コンセプトは基本的には専門家がタグ付しない限り、観測できない変数だと思われる。すなわち、コンセプトとはsynthetic-5データでいうところのc_t（5種類のコンセプト）に該当し、個々のコンセプトによって生成された50種類のexerciseがエクササイズタグに相当する。ASSISTments15データでいうところの、100種類のスキルタグがエクササイズタグで、それぞれのスキルタグのコンセプトはデータに明示されていない。<br><br><br><br>
<strong># ptの求め方<br><br>ptを求める際には、エクササイズqt（qtのサイズはエクササイズタグ次元Q; エクササイズタグが何を指すかは分かりづらく、基本的にはスキルタグのことだが、synthetic-5のように50種類のquestion_idをそのまま利用することも可）のembedding kt（dk次元）を求め、ktをメモリのkey M^k（N x dk次元）とのmatmulをとることによって、各コンセプトとのcorrelation weight w を求める。<br><br><img src="https://user-images.githubusercontent.com/12249301/166178138-1840017c-659f-4640-bcc6-535ce2b3e3ac.png" alt="image" loading="lazy"><br><br>correlation weight wは、メモリのvalue（knowledge state）からknowledge stateのread contentベクトルrを生成する際に用いられる。read contentベクトルは、エクササイズqtに関する生徒のmastery levelのサマリとみなすことができる。<br><br><br><br>read contentベクトルrは、各キーのcorrelation weight w（scalar）とメモリのvalueベクトル（dv次元）との積をメモリサイズ（コンセプト数）Nでsummationすることによって求められる。<br><br><img src="https://user-images.githubusercontent.com/12249301/166178178-380d2bb7-3a60-4a4d-ac03-195072c1e89c.png" alt="image" loading="lazy"><br><br><br><br>read contentベクトルを求めたのち、生徒のqtに対するmastery levelと取り組む問題qtの難易度を集約したサマリベクトルftをfully connected layerによって求める。求める際には、rとkt（qtのembedding）をconcatし、fully connected layerにかける。<br><br><img src="https://user-images.githubusercontent.com/12249301/180125227-6f1458ab-5132-4d2b-8bf1-8ac21b55588e.png" alt="image" loading="lazy"><br><br><br><br>最終的にサマリベクトルftを異なるfully connected layerにかけることによって、エクササイズqtに対するレスポンスを予測する。<br><br><img src="https://user-images.githubusercontent.com/12249301/166178443-a852d242-ab14-4b2b-b72c-49b47e1c546d.png" alt="image" loading="lazy"><br><br><br><br># メモリの更新方法<br><br>エクササイズqtとそれに対する正誤rtが与えられたとき(qt, rt)、この情報のembedding vtを求める。求める際は、2Q x dv次元のembedding matrixをlookupする。このvtは、生徒がエクササイズに回答したことによってどれだけのknowledge growthを得たかを表している。<br><br>その後LSTMのforget gateに着想を得て、メモリのvalueをupdateする際に、最初にeraseベクトルを求めてvalueのうち忘却した情報を削除し、その後add vectorを利用してknowledge growthをvalueに反映させる。<br><br>eraseベクトルは、knowledge growth vtと（dv x dv）次元のtransformation matrix Eを利用して変換することによって求める。<br><br><img src="https://user-images.githubusercontent.com/12249301/166178638-a8a50b09-90fd-4158-86bd-0b524d99a74e.png" alt="image" loading="lazy"><br><br>そして、メモリのvalueはこのeraseベクトルを用いて次の式で更新される。基本的には求めたeraseベクトルの分だけ全てのコンセプトのvalueがshrinkするように計算されているが、各コンセプトごとにshrinkさせる度合いをcorrelation weight wによって制御することによってvalueに対して忘却の概念を取り入れている。correlation weightとeraseベクトルのelementのうち、両方とも1となるelementに対応するvalueのelementが、0にリセットされるような挙動となる。<br><br><img src="https://user-images.githubusercontent.com/12249301/166178761-ee207032-9656-43bd-8b79-1d39a2ea9d56.png" alt="image" loading="lazy"><br><br><br><br>その後、knowledge growth vt から、新たなtransformation matrix D(dv x dv)を用いて、adding vector aが計算される。<br><br><img src="https://user-images.githubusercontent.com/12249301/166178985-15655285-76a9-4ff2-8c02-a725fc57bbf3.png" alt="image" loading="lazy"><br><br><br><br>最終的に、メモリの各valueは、adding vectorに対してcorrelation weightの重み分だけ各elementの値が更新される。<br><br><img src="https://user-images.githubusercontent.com/12249301/166179019-6a2ca6a2-d1f2-419c-910f-293c31e25e6a.png" alt="image" loading="lazy"><br><br><br><br>このような erase-followed-by-addな構造により、生徒の忘却と学習のlearning processを再現している。<br><br><br><br># 予測性能<br><br>DKVMNが全てのデータセットにおいて性能が良かった。が、これは後のさまざまな研究の追試によりDKTとDKVMNの性能はcomparableであることが検証されているため、あまりこの結果は信用できない。<br><br><img src="https://user-images.githubusercontent.com/12249301/166179088-0672ecbb-eaf7-4934-9978-ee15645d9bc5.png" alt="image" loading="lazy"><br><br><br><br># learning curve<br><br>DKTとDKVMNの両者についてlearning curveを描いた結果が下記。DKTはtrainingとvalidationのlossの差が非常に大きくoverfittingしていることがわかるが、DKVMNはそのような挙動はなく、overfittingしにくいことを言及している。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/166179170-5603f4cf-278d-48e8-b6a2-9f345342c969.png" alt="image" loading="lazy"><br><br><br><br># Concept Discovery<br><br>Figure4がsynthetic-5に対するConcept Discovery, Figure5がASSISTments15に対するConcept Discoveryの結果。synthetic-5は5種類のコンセプトによって50種類のエクササイズが生成されているが、メモリサイズNを5にすることによって完璧な各エクササイズのクラスタリングが実施できた（驚くべきことに、N=50でも5つのクラスタにきっちり分けることができた）。ASSISTments15データについても、類似したコンセプトのスキルタグが同じクラスタに属し、近い距離にマッピングされているため、コンセプトを見つけられたと主張している。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/166179625-1e2072c5-95c0-4dec-b5d1-456188308d39.png" alt="image" loading="lazy"><br><br><br><br># Knowledge State Depiction<br><br>Synthetic-5に対する、各コンセプトのmasteryを可視化した結果が下図。<br><br><img src="https://user-images.githubusercontent.com/12249301/166179748-c1e13800-de52-434e-bd37-80bc5c6af570.png" alt="image" loading="lazy"><br><br>ここで注意すべきは、DKVMNが可視化するのは、メモリサイズNで指定した個々のkeyに該当するコンセプトのmasteryを可視化する方法を説明している点である。個々のスキルタグ（エクササイズタグ）に対するmasteryを可視化するわけではない点に注意。個々のスキルタグに対するmasteryは、DKTと同様にptがそれに該当するものと思われる。<br><br><br><br>個々のコンセプトのmasteryを可視化する手順は下記の通り。<br><br>まず、read content vector rを求める際に、masteryを可視化したいコンセプトのCorrelation weightのみを1とし、他のコンセプトのCorrelation weightを0とすることでrを算出する。<br><br>その後、次の式によって、エクササイズの難易度情報をマスクすること（weight matrixのうち、エクササイズembeddingが乗算される部分のみ0にマスクする）によってサマリベクトルftを求め、ftからfully connected layerを通じてptを求めることで、そのptを該当するコンセプトのmastery levelとみなす。<br><br><img src="https://user-images.githubusercontent.com/12249301/166179948-25bff748-fd2c-4866-9c2c-b745049fd099.png" alt="image" loading="lazy"><br><br><br><br># 所感<br><br>スキルタグの背後にある隠れたコンセプトを見つけ、その隠れたコンセプトに対する習熟度を測るという点においてはDKTよりもDKVMNの方が優れていそう。<br><br>だが、スキルタグに対する習熟度を測るという点については、DKT, DKVMNのAUCにほとんど差がないことを鑑みるにDKVMNをわざわざ使う意味がどれだけあるのかな、という気がした。<br><br>特に <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/453" target="_blank" rel="noopener noreferrer">Empirical Evaluation of Deep Learning Models for Knowledge Tracing: Of Hyperparameters and Metrics on Performance and Replicability, Sami+, Aalto University, JEDM'22</a>
</strong>
<br>
 で報告されているように、DKVMNでリアルタイムに全てのスキルタグに対する習熟度をトラッキングするためには、DKVMNのoutputをoutput-per-skillにする必要があるが、DKVMNにおいてoutput-per-skillベクトルをoutputに採用すると予測性能が低下することがわかっている。このため、わざわざスキルタグに対する習熟度を求める際にDKVMNを使う必要もないのでは、という気がしている。<br><br>そうすると、現状スキルタグに対する習熟度をいい感じに求める手法は、DKT, DKT+ or EKTということになるのだろうか・・・。<br><br><br><br>追記：DKVMNのDKTと比較して良い点は、メモリネットワーク上にknowledge stateが保存されていて、inputはある一回の問題に対するtrialの正誤のみという点。DKTなどでは入力する系列の長さの上限が決まってしまうが、原理上はDKVMNは扱える系列の長さに制限がないことになる。この性質は非常に有用。</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/SIGIR.html" target="_blank" rel="noopener noreferrer">#SIGIR</a>
<span class="issue_date">Issue Date: 2019-04-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/309" target="_blank" rel="noopener noreferrer" class="title-link">Neural rating regression with abstractive tips generation for recommendation, Li+, SIGIR'17</a>
<span class="snippet"><span>Comment</span><p>Rating Predictionとtips generationを同時に行うことで、両者の性能を向上させた最初の研究。<br><br>tipsとは、ユーザの経験や感じたことを、短いテキスト（1文とか）で簡潔に記したもの。</p>
<p><img src="https://user-images.githubusercontent.com/12249301/56012618-43423c00-5d28-11e9-82ff-fe90c9dd7d1c.png" alt="image" loading="lazy"><br><br><br><br>モデルについてはあまりく詳しく読んでいないが、図を見る感じ、user latent factorとitem latent factorをMF layerとseq2seqで共有し、同時学習させていると思われる。<br><br>おそらく、MFとtext generationをjointで行うNNモデルはこの研究が初めて（textの情報をMFの改善に使おうという試みは古くからやられているが、generationまでは多分やってない）で、このモデル化の仕方がその後のスタンダードになっている。</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/INLG.html" target="_blank" rel="noopener noreferrer">#INLG</a>
<span class="issue_date">Issue Date: 2019-04-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/307" target="_blank" rel="noopener noreferrer" class="title-link">Towards automatic generation of product reviews from aspectsentiment scores, Zang+, INLG'17</a>
<span class="snippet"><span>Comment</span><p>hierarchicalなNNで、long reviewの生成に取り組んだ論文</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/EACL.html" target="_blank" rel="noopener noreferrer">#EACL</a>
<span class="issue_date">Issue Date: 2019-03-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/305" target="_blank" rel="noopener noreferrer" class="title-link">Learning to Generate Product Reviews from Attributes, Dong+, EACL'17</a>
<span class="snippet"><span>Comment</span><p>（たぶん）最初のreview generation論文</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReviewGeneration.html" target="_blank" rel="noopener noreferrer">#ReviewGeneration</a>
<a class="button" href="articles/IJCNLP.html" target="_blank" rel="noopener noreferrer">#IJCNLP</a>
<span class="issue_date">Issue Date: 2019-02-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/303" target="_blank" rel="noopener noreferrer" class="title-link">Estimating Reactions and Recommending Products with Generative Models of Reviews, Ni+, IJCNLP'17</a>
<span class="snippet"><span>Comment</span><p>Collaborative Filtering (CF) によるコンテンツ推薦とReview Generationを同時に学習し、<br><br>両者の性能を向上させる話。<br><br>非常に興味深い設定で、このような実験設定でReview Generationを行なった初めての研究。</p>
<p>CFではMatrix Factorization (MF) を利用し、Review Generationでは、LSTM-basedなseq2seqを利用する。MFとReview Generationのモデルにおいて、共通のuser latent factorとitem latent factorを利用することで、joint modelとしている。このとき、latent factorは、両タスクを通じて学習される。<br><br><br><br>CFでは、Implicitな設定なので、Rating Predictionではなく、binary classificationを行うことで、推薦を行う。<br><br>classificationには、Matrix Factorization (MF) を拡張したモデルを用いる。<br><br>具体的には、通常のMFでは、user latent factorとitem latent factorの内積によって、userのitemに対するpreferenceを表現するが、このときに、target userが過去に記載したレビュー・およびtarget itemに関する情報を利用する。レビューのrepresentationのaverageをとったvectorと、MFの結果をlinear layerによって写像し、最終的なclassification scoreとしている。<br><br><br><br>Review Generationでは、基本的にはseq2seqのinputのEmbeddingに対して、user latent factor, item latent factorをconcatするだけ。hidden stateに直接concatしないのは、latent factorを各ステップで考慮できるため、long, coherentなsequenceを生成できるから、と説明している。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/56011945-15a7c380-5d25-11e9-9a0d-8835bdb6cbed.png" alt="image" loading="lazy"><br><br></p>
<p><img src="https://user-images.githubusercontent.com/12249301/56012061-9c5ca080-5d25-11e9-9327-2c7a9c3ee365.png" alt="image" loading="lazy"><br><br><br><br>Recommendタスクにおいては、Bayesian Personalized Ranking, Generalized Matrix Factorizationをoutperform。</p>
<p><img src="https://user-images.githubusercontent.com/12249301/56012129-f65d6600-5d25-11e9-919a-33018878f96e.png" alt="image" loading="lazy"><br><br><br><br>Review GenerationはPerplexityにより評価している。提案手法がcharacter based lstmをoutperform。<br><br>Perplexityによる評価だと言語モデルとしての評価しかできていないので、BLEU, ROUGEなどを利用した評価などもあって良いのでは。</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/MatrixFactorization.html" target="_blank" rel="noopener noreferrer">#MatrixFactorization</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-02-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/260" target="_blank" rel="noopener noreferrer" class="title-link">Neural Collaborative Filtering, He+, WWW'17</a>
<span class="snippet"><span>Comment</span><p>Collaborative FilteringをMLPで一般化したNeural Collaborative Filtering、およびMatrix Factorizationはuser, item-embeddingのelement-wise product + linear transofmration + activation で一般化できること（GMF; Generalized Matrix Factorization）を示し、両者を組み合わせたNeural Matrix Factorizationを提案している。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/121464723-5c6dd280-c9ef-11eb-9c56-7382f2403dc1.png" alt="image" loading="lazy"><br><br><br><br>学習する際は、Implicit Dataの場合は負例をNegative Samplingし、LogLoss（Binary Cross-Entropy Loss）で学習する。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/121464911-bb334c00-c9ef-11eb-88a6-697fab50e60d.png" alt="image" loading="lazy"><br><br>Neural Matrix Factorizationが、ItemKNNやBPRといったベースラインをoutperform<br><br><br><br>Negative Samplingでサンプリングする負例の数は、3~4程度で良さそう<br><br><img src="https://user-images.githubusercontent.com/12249301/121464991-e9189080-c9ef-11eb-96ce-4e743f84a183.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<span class="issue_date">Issue Date: 2018-02-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/259" target="_blank" rel="noopener noreferrer" class="title-link">Deep Learning for Personalized Search and Recommender Systems, KDD'17</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2018-02-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/253" target="_blank" rel="noopener noreferrer" class="title-link">Deep Learning: Practice and Trends, NIPS'17</a>
<span class="snippet"><span>Comment</span><p>基礎から最新まで幅広いトピックがまとまったtutorial</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2018-02-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/248" target="_blank" rel="noopener noreferrer" class="title-link">Recent Trends in Deep Learning Based Natural Language Processing, Young+, arXiv'17</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/GenerativeAdversarialNetwork.html" target="_blank" rel="noopener noreferrer">#GenerativeAdversarialNetwork</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2018-02-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/247" target="_blank" rel="noopener noreferrer" class="title-link">Adversarial Ranking for Language Generation, Lin+, NIPS'17</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/245" target="_blank" rel="noopener noreferrer" class="title-link">Attention is all you need, Vaswani+, NIPS'17</a>
<span class="snippet"><span>Comment</span><p>Transformer (self-attentionを利用) 論文<br><br>解説スライド：


<a href="https://www.slideshare.net/DeepLearningJP2016/dlattention-is-all-you-need" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/DeepLearningJP2016/dlattention-is-all-you-need</a>


<br><br>解説記事：


<a href="https://qiita.com/nishiba/items/1c99bc7ddcb2d62667c6" target="_blank" rel="noopener noreferrer">https://qiita.com/nishiba/items/1c99bc7ddcb2d62667c6</a>


<br><br><br><br>* 新しい翻訳モデル(Transformer)を提案。既存のモデルよりも並列化に対応しており、短時間の訓練で（既存モデルの1/4以下のコスト）高いBLEUスコアを達成した。<br><br>* TransformerはRNNやCNNを使わず、attentionメカニズムに基づいている。<br><br><br><br>（解説より）</p>
<p>分かりやすい:<br>


<a href="https://qiita.com/halhorn/items/c91497522be27bde17ce" target="_blank" rel="noopener noreferrer">https://qiita.com/halhorn/items/c91497522be27bde17ce</a>


</p>
<p>Transformerの各コンポーネントでのoutputのshapeや、attention_maskの形状、実装について記述されており有用:<br>


<a href="https://qiita.com/FuwaraMiyasaki/items/239f3528053889847825" target="_blank" rel="noopener noreferrer">https://qiita.com/FuwaraMiyasaki/items/239f3528053889847825</a>


</p>
<p>集合知</p></span><br><br>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/234" target="_blank" rel="noopener noreferrer" class="title-link">ゼロから始める ニューラルネットワーク機械翻訳, 中澤敏明, NLP'17</a>
<span class="snippet"><span>Comment</span><p>中澤さんによるNMTチュートリアル。</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Online/Interactive.html" target="_blank" rel="noopener noreferrer">#Online/Interactive</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/212" target="_blank" rel="noopener noreferrer" class="title-link">Online Deep Learning: Learning Deep Neural Networks on the Fly, Doyen Sahoo+, N_A, arXiv'17</a>
<span class="snippet"><span>Summary</span>- 本研究では、オンライン設定でリアルタイムにディープニューラルネットワーク（DNN）を学習するための新しいフレームワークを提案します。従来のバックプロパゲーションはオンライン学習には適していないため、新しいHedge Backpropagation（HBP）手法を提案します。この手法は、静的およびコンセプトドリフトシナリオを含む大規模なデータセットで効果的であることを検証します。</span>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/209" target="_blank" rel="noopener noreferrer" class="title-link">Coarse-to-Fine Attention Models for Document Summarization, Ling+ （with Rush）, ACL'17 Workshop on New Frontiers in Summarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/207" target="_blank" rel="noopener noreferrer" class="title-link">Challenges in Data-to-Document Generation, Wiseman+ （with Rush）, EMNLP'17</a>
&lt;span class=\"snippet\"&gt;<span>Comment</span><p>・RotoWire（NBAのテーブルデータ + サマリ）データを収集し公開<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/119625430-23f1c480-be45-11eb-8ff8-5e9223d41481.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br><br><br>・Rotowireデータの統計量<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/119625488-323fe080-be45-11eb-952e-d2d21d6e5847.png\" alt=\"image\" loading=\"lazy\" /&gt;</p>
<p>【モデルの概要】<br><br>・attention-based encoder-decoder model<br><br><br><br>・BaseModel<br><br>　- レコードデータ r の各要素（r.e: チーム名等のENTITY r.t: POINTS等のデータタイプ, r.m: データのvalue）からembeddingをlookupし、1-layer MLPを適用し、レコードの各要素のrepresentation（source data records）を取得<br><br>　- Luongらのattentionを利用したLSTM Decoderを用意し、source data recordsとt-1ステップ目での出力によって条件付けてテキストを生成していく<br><br>　- negative log likelihoodがminimizeされるように学習する<br><br><br><br>・Copying<br><br>　- コピーメカニズムを導入し、生成時の確率分布に生成テキストを入力からコピーされるか否かを含めた分布からテキストを生成。コピーの対象は、入力レコードのvalueがコピーされるようにする。<br><br>　- コピーメカニズムには下記式で表現される Conditional Copy Modelを利用し、p\(zt|y1:t-1, s)はMLPで表現する。<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/119628147-cc088d00-be47-11eb-84de-6a1d158d78e5.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br>　- またpcopyは、生成している文中にあるレコードのエンティティとタイプが出現する場合に、対応するvalueをコピーし生成されるように、下記式で表現する<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/119628389-07a35700-be48-11eb-9c69-27b70fcbcdef.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br>　- ここで r\(yt) =<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/119628615-39b4b900-be48-11eb-9305-509a6eed8182.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br></p>&lt;/span&gt;<br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/135" target="_blank" rel="noopener noreferrer" class="title-link">Get To The Point: Summarization with Pointer-Generator Networks, See+, ACL'17</a>
<span class="snippet"><span>Comment</span><p>解説スライド：


<a href="https://www.slideshare.net/akihikowatanabe3110/get-to-the-point-summarization-with-pointergenerator-networks/1" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/get-to-the-point-summarization-with-pointergenerator-networks/1</a>


</p>
<p>単語の生成と単語のコピーの両方を行えるハイブリッドなニューラル文書要約モデルを提案。<br><br>同じ単語の繰り返し現象(repetition)をなくすために、Coverage Mechanismも導入した。<br><br><br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/136" target="_blank" rel="noopener noreferrer">Incorporating Copying Mechanism in Sequence-to-Sequence Learning, Gu+, ACL'16</a>
 などと比較するとシンプルなモデル。</p>
<p>一般的に、PointerGeneratorと呼ばれる。<br><br>OpenNMTなどにも実装されている: 


<a href="https://opennmt.net/OpenNMT-py/_modules/onmt/modules/copy_generator.html" target="_blank" rel="noopener noreferrer">https://opennmt.net/OpenNMT-py/_modules/onmt/modules/copy_generator.html</a>


</p>
<p>（参考）Pointer Generator Networksで要約してみる：<br><br>


<a href="https://qiita.com/knok/items/9a74430b279e522d5b93" target="_blank" rel="noopener noreferrer">https://qiita.com/knok/items/9a74430b279e522d5b93</a>


</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/EACL.html" target="_blank" rel="noopener noreferrer">#EACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/133" target="_blank" rel="noopener noreferrer" class="title-link">Cutting-off redundant repeating generations for neural abstractive summarization, Suzuki+, EACL'17</a>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/GraphConvolutionalNetwork.html" target="_blank" rel="noopener noreferrer">#GraphConvolutionalNetwork</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/CoNLL.html" target="_blank" rel="noopener noreferrer">#CoNLL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/130" target="_blank" rel="noopener noreferrer" class="title-link">Graph-based Neural Multi-Document Summarization, Yasunaga+, CoNLL'17</a>
<span class="snippet"><span>Comment</span><p>Graph Convolutional Network (GCN)を使って、MDSやりましたという話。 既存のニューラルなMDSモデル [Cao et al., 2015, 2017] では、sentence間のrelationが考慮できていなかったが、GCN使って考慮した。 また、MDSの学習データはニューラルなモデルを学習するには小さすぎるが（abstractiveにするのは厳しいという話だと思われる？）、sentenceのsalienceを求める問題に帰着させることで、これを克服。<br><br><br><br>GCNで用いるAdjacent Matrixとして3種類の方法(cosine similarity, G-Flow, PDG)を試し、議論をしている。PDGが提案手法だが、G-Flowによる重みをPersonalization Features（position, leadか否か等のベーシックな素性）から求まるweightで、よりsentenceのsalienceを求める際にリッチな情報を扱えるように補正している。PDGを用いた場合が（ROUGE的な観点で）最も性能がよかった。<br><br><br><br>モデルの処理の流れとしては、Document Cluster中の各sentenceのhidden stateをGRUベースなRNNでエンコードし、それをGCNのノードの初期値として利用する。GCNでL回のpropagation後（実験では3回）に得られたノードのhidden stateを、salienceスコア計算に用いるsentence embedding、およびcluster embeddingの生成に用いる。 cluster embeddingは、document clusterをglobalな視点から見て、salienceスコアに反映させるために用いられる。 最終的にこれら2つの情報をlinearなlayerにかけてsoftmaxかけて正規化して、salienceスコアとする。<br><br><br><br>要約を生成する際はgreedyな方法を用いており、salienceスコアの高いsentenceから要約長に達するまで選択していく。このとき、冗長性を排除するため、candidateとなるsentenceと生成中の要約とのcosine similarityが0.5を超えるものは選択しないといった、よくある操作を行なっている。<br><br><br><br>DUC01, 02のデータをtraining data, DUC03 をvalidation data, DUC04をtest dataとし、ROUGE1,2で評価。 評価の結果、CLASSY04(DUC04のbest system)やLexRank等のよく使われるベースラインをoutperform。 ただ、regression basedなRegSumにはスコアで勝てないという結果に。 RegSumはwordレベルでsalienceスコアをregressionする手法で、リッチな情報を結構使っているので、これらを提案手法に組み合わせるのは有望な方向性だと議論している。<br><br><br><br>[Cao+, 2015] Ranking with recursive neural networks and its application to multi-document summarization, Cao+, AAAI'15 [Cao+, 2017] Improving multi-document summarization via text classification, Cao+, AAAI'17<br><br><br><br>[所感] <br><br>・ニューラルなモデルは表現力は高そうだけど、学習データがDUC01と02だけだと、データが足りなくて持ち前の表現力が活かせていないのではないかという気がする。 <br><br>・冗長性の排除をアドホックにやっているので、モデルにうまく組み込めないかなという印象（distraction機構とか使えばいいのかもしれん） <br><br>・ROUGEでしか評価してないけど、実際のoutputはどんな感じなのかちょっと見てみたい。（ハイレベルなシステムだとROUGEスコア上がっても人手評価との相関がないっていう研究成果もあるし。）<br><br> ・GCN、あまり知らなかったかけど数式追ったらなんとなく分かったと思われる。（元論文読めという話だが）</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/91" target="_blank" rel="noopener noreferrer" class="title-link">Toward Controlled Generation of Text, Hu+, ICML'17</a>
<span class="snippet"><span>Comment</span><p>Text Generationを行う際は、現在は基本的に学習された言語モデルの尤度に従ってテキストを生成するのみで、outputされるテキストをcontrolすることができないので、できるようにしましたという論文。 VAEによるテキスト生成にGANを組み合わせたようなモデル。 decodingする元となるfeatureのある次元が、たとえばpolarityなどに対応しており、その次元の数値をいじるだけで生成されるテキストをcontrolできる。 <br><br><br><br>テキストを生成する際に、生成されるテキストをコントロールするための研究。 テキストを生成する際には、基本的にはVariational Auto Encoder(VAE)を用いる。<br><br><br><br>VAEは、入力をエンコードするEncoderと、エンコードされた潜在変数zからテキストを生成するGeneratorの2つの機構によって構成されている。<br><br><br><br>この研究では、生成されるテキストをコントロールするために、VAEの潜在変数zに、生成するテキストのattributeを表す変数cを新たに導入。<br><br><br><br>たとえば、一例として、変数cをsentimentに対応させた場合、変数cの値を変更すると、生成されるテキストのsentimentが変化するような生成が実現可能。<br><br><br><br>次に、このような生成を実現できるようなパラメータを学習したいが、学習を行う際のポイントは、以下の二つ。<br><br><br><br>cで指定されたattributeが反映されたテキストを生成するように学習<br><br><br><br>潜在変数zとattributeに関する変数cの独立性を保つように学習 （cには制御したいattributeに関する情報のみが格納され、その他の情報は潜在変数zに格納されるように学習する)<br><br><br><br>1を実現するために、新たにdiscriminatorと呼ばれる識別器を用意し、VAEが生成したテキストのattributeをdiscriminatorで分類し、その結果をVAEのGeneratorにフィードバックすることで、attributeが反映されたテキストを生成できるようにパラメータの学習を行う。 （これにはラベル付きデータが必要だが、少量でも学習できることに加えて、sentence levelのデータだけではなくword levelのデータでも学習できる。）<br><br><br><br>また、2を実現するために、VAEが生成したテキストから、生成する元となった潜在変数zが再現できるようにEncoderのパラメータを学習。<br><br><br><br>実験では、sentimentとtenseをコントロールする実験が行われており、attributeを表す変数cを変更することで、以下のようなテキストが生成されており興味深い。<br><br><br><br>[sentimentを制御した例]<br><br><br><br>this movie was awful and boring. (negative)<br><br>this movie was funny and touching. (positive)<br><br>[tenseを制御した例]<br><br><br><br>this was one of the outstanding thrillers of the last decade<br><br>this is one of the outstanding thrillers of the all time<br><br>this will be one of the great thrillers of the all time</p>
<p>VAEは通常のAutoEncoderと比較して、奥が深くて勉強してみておもしろかった。 Reparametrization Trickなどは知らなかった。</p>
<p>管理人による解説資料:<br>[Controllable Text Generation.pdf](https://github.com/AkihikoWatanabe/paper_notes/files/1595121/Controllable.Text.Generation.pdf)<br><br></p>
<p>slideshare: 


<a href="https://www.slideshare.net/akihikowatanabe3110/towards-controlled-generation-of-text" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/towards-controlled-generation-of-text</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/90" target="_blank" rel="noopener noreferrer" class="title-link">Multi-Task Video Captioning with Video and Entailment Generation, Pasunuru+, ACL'17</a>
<span class="snippet"><span>Comment</span><p>解説スライド：


<a href="https://www.slideshare.net/HangyoMasatsugu/hangyo-acl-paperreading2017multitask-video-captioning-with-video-and-entailment-generation/1" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/HangyoMasatsugu/hangyo-acl-paperreading2017multitask-video-captioning-with-video-and-entailment-generation/1</a>


</p>
<p>multitask learningで動画（かなり短め）のキャプション生成を行なった話<br><br>(2025.05.12)<br>上記解説資料中のスクショがいくつか掲載されていましたが削除しました。</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Unsupervised.html" target="_blank" rel="noopener noreferrer">#Unsupervised</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/83" target="_blank" rel="noopener noreferrer" class="title-link">Unsupervised Pretraining for Sequence to Sequence Learning, Ramachandran+, EMNLP'17</a>
<span class="snippet"><span>Comment</span><p>seq2seqにおいてweightのpretrainingを行う手法を提案<br><br>seq2seqでは訓練データが小さいとoverfittingしやすいという弱点があるので、大規模なデータでunsupervisedにpretrainingし、その後目的のデータでfinetuneすることで精度を向上させましょう、というお話。<br><br>WMTの翻訳タスクにおいて、1.3ポイント BLEUスコアが改善、abstractive summarizationでも実験したが、精度は向上せず。しかしながら要約ではpretrainingによってrepetitionが減少したと主張。<br><br><br><br>encoder, decoderそれぞれを切り離して考えると、それぞれ言語モデルとみなすことができるため(encoderにはoutput-layerを追加)、それぞれの言語モデルを独立に大規模なラベルなしデータでpretrainingする。<br><br>fine-tuneする際は、targetデータだけでなく、pretrainingする際のデータも同時に学習を続ける（LM Objective）<br><br>LM Objectiveは、target側のobjective functionにpretraining側のobjective functionの項を重み付きで追加したもの。<br><br><br><br>Abltion studyによると、MTにおいてはsoftmax-layerをpretrainingすることが重要。softmax-layerのpretrainingをablationするとBLEUスコアが1.6ポイント減少。<br><br>LM objectiveをなくすと、pretrainingの効果がほとんどなくなる(BLEUスコア-2.0ポイント)。<br><br>sumarizationにおいては、embeddingのpretrainingが大幅なROUGEスコアの改善を見せた。また、MTと異なり、encoder側のpretrainingがスコア向上に寄与。<br><br><br><br>LM Objectiveは結構使えそうな印象</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/82" target="_blank" rel="noopener noreferrer" class="title-link">Learning to skim text, Yu+, ACL'17</a>
<span class="snippet"><span>Comment</span><p>解説スライド：


<a href="http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/07.pdf" target="_blank" rel="noopener noreferrer">http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/07.pdf</a>


</p>
<p>RNNにおいて重要な部分以外は読み飛ばすことで効率を向上させる研究。いくつ読み飛ばすかも潜在変数として一緒に学習する。潜在変数（離散変数）なので、普通に尤度最大化するやり方では学習できず、おまけに離散変数なのでバックプロパゲーション使えないので、強化学習で学習する。<br><br><br><br>Vanilla LSTMと比較し、色々なタスクで実験した結果、性能も（少し）上がるし、スピードアップもする。</p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Word.html" target="_blank" rel="noopener noreferrer">#Word</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/79" target="_blank" rel="noopener noreferrer" class="title-link">Skip-Gram – Zipf + Uniform = Vector Additivity, Gittens+, ACL'17</a>
<span class="snippet"><span>Comment</span><p>解説スライド：


<a href="http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/09.pdf" target="_blank" rel="noopener noreferrer">http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/09.pdf</a>


</p>
<p>Embeddingの加法構成性（e.g. man+royal=king）を理論的に理由づけ<br><br>（解説スライドより）</p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Word.html" target="_blank" rel="noopener noreferrer">#Word</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2017-12-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/78" target="_blank" rel="noopener noreferrer" class="title-link">Poincar'e Embeddings for Learning Hierarchical Representations, Nickel+, NIPS'17</a>
<span class="snippet"><span>Comment</span><p>解説: 


<a href="http://tech-blog.abeja.asia/entry/poincare-embeddings" target="_blank" rel="noopener noreferrer">http://tech-blog.abeja.asia/entry/poincare-embeddings</a>


<br><br>解説スライド：


<a href="https://speakerdeck.com/eumesy/poincare-embeddings-for-learning-hierarchical-representations" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/eumesy/poincare-embeddings-for-learning-hierarchical-representations</a>


<br><br>実装：


<a href="https://github.com/TatsuyaShirakawa/poincare-embedding" target="_blank" rel="noopener noreferrer">https://github.com/TatsuyaShirakawa/poincare-embedding</a>


<br><br></p>
<p>・階層構造を持つデータ（WordNet上の上位語下位語、is-a関係など）を埋め込むために、双曲空間を使った話（通常はユークリッド空間）。<br><br>・階層構造・べき分布を持つデータはユークリッド空間ではなく双曲空間の方が効率的に埋め込める。<br><br>・階層構造・べき分布を持つデータを双曲空間（ポアンカレ球モデル）に埋め込むための学習手法（リーマン多様体上でSGD）を提案<br><br>・WordNet hypernymyの埋め込み：低次元でユークリッド埋め込みに圧勝<br><br>・Social Networkの埋め込み：低次元だと圧勝<br><br>・Lexical Entailment：2つのデータセットでSoTA<br><br>（解説スライドより）</p>
<p><img src="https://user-images.githubusercontent.com/12249301/34452953-0e124ad6-ed8d-11e7-800d-0c2712df116a.png" alt="image" loading="lazy"><br><br><br><br>データとして上位・下位概念を与えていないのに、原点付近には上位語・円周付近には下位語が自然に埋め込まれている（意図した通りになっている）。<br><br>ポアンカレ円板では、原点からの距離に応じて指数的に円周長が増加していくので、指数的に数が増えていく下位語などは外側に配置されると効率的だけど、その通りになっている。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34452994-7c17a738-ed8d-11e7-8a56-13929c55c07e.png" alt="image" loading="lazy"><br><br><br><br><br><br></p></span><br><br>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/71" target="_blank" rel="noopener noreferrer" class="title-link">Supervised Learning of Universal Sentence Representations from Natural Language Inference Data, Conneau+, EMNLP'17</a>
<span class="snippet"><span>Comment</span><p>slide: 


<a href="https://www.slideshare.net/naoakiokazaki/supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/naoakiokazaki/supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data</a>


</p>
<p>汎用的な文のエンコーダができました！という話。<br><br><br><br>SNLIデータでパラメータ学習、エンコーダ構成スライド図中右側のエンコーダ部分をなるべく一般的な文に適用できるように学習したい。<br><br><br><br>色々なタスクで、文のエンコーダ構成を比較した結果、bi-directional LSTMでエンコードし、要素ごとの最大値をとる手法が最も良いという結果。<br><br>隠れ層の次元は4096とかそのくらい。<br><br>Skip-Thoughtは学習に1ヶ月くらいかかるけど、提案手法はより少ないデータで1日くらいで学習終わり、様々なタスクで精度が良い。<br><br><br><br>ベクトルの要素積、concat,  subなど、様々な演算を施し、学習しているので、そのような構成の元から文エンコーダを学習すると何か意味的なものがとれている？<br><br>SNLIはNatural Language Inferenceには文の意味理解が必須なので、そのデータ使って学習するといい感じに文のエンコードができます。<br><br><br><br>NLIのデータは色々なところで有用なので、日本語のNLIのデータとかも欲しい。</p></span><br><br>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/69" target="_blank" rel="noopener noreferrer" class="title-link">A structured self-attentive sentence embedding, Li+ （Bengio group）, ICLR'17</a>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=BJC_jUqxe" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=BJC_jUqxe</a>


</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/67" target="_blank" rel="noopener noreferrer" class="title-link">What do Neural Machine Translation Models Learn about Morphology?, Yonatan Belinkov+, ACL'17</a>
<span class="snippet"><span>Comment</span><p>


<a href="http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/06.pdf" target="_blank" rel="noopener noreferrer">http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/06.pdf</a>


<br><br>(2025.05.12追記)<br>上記は2017年にすずかけ台で開催されたACL 2017読み会での解説スライドです。</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/66" target="_blank" rel="noopener noreferrer" class="title-link">Sequence-to-Dependency Neural Machine Translation, Wu+, ACL'17</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/64" target="_blank" rel="noopener noreferrer" class="title-link">Neural Machine Translation with Source-Side Latent Graph Parsing, Kazuma Hashimoto+, EMNLP'17</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/GenerativeAdversarialNetwork.html" target="_blank" rel="noopener noreferrer">#GenerativeAdversarialNetwork</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/60" target="_blank" rel="noopener noreferrer" class="title-link">Generative Adversarial Networks: An Overview, Dumoulin+, IEEE-SPM'17</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/DualLearning.html" target="_blank" rel="noopener noreferrer">#DualLearning</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2508" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Dual Learning for Machine Translation, Yingce Xia+, NIPS'16</a>
<span class="snippet"><span>Summary</span>- デュアルラーニングメカニズムを用いたニューラル機械翻訳（dual-NMT）を提案。プライマルタスク（英語からフランス語）とデュアルタスク（フランス語から英語）を通じて、ラベルのないデータから自動的に学習。強化学習を用いて互いに教え合い、モデルを更新。実験により、モノリンガルデータから学習しつつ、バイリンガルデータと同等の精度を達成することが示された。</span>
<span class="snippet"><span>Comment</span><p>モノリンガルコーパスD_A, D_Bで学習した言語モデルLM_A, LM_Bが与えられた時、翻訳モデルΘ_A, Θ_Bのの翻訳の自然さ（e.g., 尤度）をrewardとして与え、互いのモデルの翻訳（プライマルタスク）・逆翻訳（デュアルタスク）の性能が互いに高くなるように強化学習するような枠組みを提案。パラレルコーパス不要でモノリンガルコーパスのみで、人手によるアノテーション無しで学習ができる。</p></span><br><br>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2339" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] An overview of gradient descent optimization algorithms, Sebastian Ruder, arXiv'16</a>
<span class="snippet"><span>Summary</span>- 勾配降下法の最適化アルゴリズムの挙動を理解し、活用するための直感を提供することを目的とした記事。さまざまなバリエーションや課題を要約し、一般的な最適化アルゴリズム、並列・分散設定のアーキテクチャ、追加戦略をレビュー。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:


</p>
<div class="tweet-embed" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/goyal__pramod/status/1951192112269054113?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>&lt;img alt="loading..." src="/assets/images/load-31_128.gif class="tweet-loading" /&gt;</div>


</span></strong></p>
<p>勉強用にメモ</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-06-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2038" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WaveNet: A Generative Model for Raw Audio, Aaron van den Oord+, arXiv'16</a>
<span class="snippet"><span>Summary</span>- 本論文では、音声波形を生成する深層ニューラルネットワークWaveNetを提案。自己回帰的なモデルでありながら、効率的に音声データを訓練可能。テキストから音声への変換で最先端の性能を示し、人間のリスナーに自然な音と評価される。話者の特性を忠実に捉え、アイデンティティに基づく切り替えが可能。音楽生成にも応用でき、リアルな音楽の断片を生成。また、音素認識のための有望な識別モデルとしての利用も示唆。</span>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<span class="issue_date">Issue Date: 2025-01-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1647" target="_blank" rel="noopener noreferrer" class="title-link">Controlling Output Length in Neural Encoder-Decoders, Yuta Kikuchi+, EMNLP'16</a>
<span class="snippet"><span>Summary</span>- ニューラルエンコーダ-デコーダモデルの出力長を制御する方法を提案。特にテキスト要約において、デコーディングと学習に基づく2つのアプローチを用い、学習ベースの方法が要約の質を保ちながら長さを調整できることを示した。</span>
<span class="snippet"><span>Comment</span><p>Encoder-Decoderモデルにおいてoutput lengthを制御する手法を提案した最初の研究</p></span><br><br>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2022-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/445" target="_blank" rel="noopener noreferrer" class="title-link">Estimating student proficiency: Deep learning is not the panacea, Wilson+, Knewton+, NIPS'16 workshop</a>
<span class="snippet"><span>Comment</span><p>DKTの性能をBKTやPFA等の手法と比較した研究<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/355" target="_blank" rel="noopener noreferrer">How Deep is Knowledge Tracing?, Mozer+, EDM'16</a>
 を引用し、DKTとBKTのAUCの計算方法の違いについて言及している</p></span><br><br>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/StudentPerformancePrediction.html" target="_blank" rel="noopener noreferrer">#StudentPerformancePrediction</a>
<a class="button" href="articles/EDM.html" target="_blank" rel="noopener noreferrer">#EDM</a>
<span class="issue_date">Issue Date: 2021-05-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/358" target="_blank" rel="noopener noreferrer" class="title-link">Back to the basics: Bayesian extensions of IRT outperform neural networks for proficiency estimation, Ekanadham+, EDM'16</a>
<span class="snippet"><span>Comment</span><p>Knewton社の研究。IRTとIRTを拡張したモデルでStudent Performance Predictionを行い、3種類のデータセットでDKT <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/297" target="_blank" rel="noopener noreferrer">Deep Knowledge Tracing, Piech+, NIPS, 2015</a>
 と比較。比較の結果、IRT、およびIRTを拡張したモデルがDKTと同等、もしくはそれ以上の性能を出すことを示した。IRTはDKTと比べて、trainingが容易であり、パラメータチューニングも少なく済むし、DKTを数万のアイテムでtrainingするとメモリと計算時間が非常に大きくなるので、性能とパフォーマンス両方の面で実用上はIRTベースドな手法のほうが良いよね、という主張。<br><br><br><br>AUCを測る際に、具体的に何に大してAUCを測っているのかがわからない。モデルで何を予測しているかが明示的に書かれていないため（普通に考えたら、生徒のquizに対する回答の正誤を予測しているはず。IRTではquizのIDをinputして予測できるがDKTでは基本的にknowledge componentに対するproficiencyという形で予測される（table 1が各モデルがどのidに対して予測を行なったかの対応を示しているのだと思われる））。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120055969-4ddcfe00-c074-11eb-9b7e-5cabd5b5fea7.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120055976-5e8d7400-c074-11eb-8d06-0aa38808982f.png" alt="image" loading="lazy"><br><br></p>
<p>knewton社は自社のアダプティブエンジンでIRTベースの手法を利用しており、DKTに対するIRTベースな手法の性能の比較に興味があったのだと思われる。</p>
<p>なお、論文の著者であるKnewton社のKevin H. Wilson氏はすでにknewton社を退職されている。<br><br>


<a href="https://kevinhayeswilson.com/" target="_blank" rel="noopener noreferrer">https://kevinhayeswilson.com/</a>


</p></span><br><br>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/StudentPerformancePrediction.html" target="_blank" rel="noopener noreferrer">#StudentPerformancePrediction</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<a class="button" href="articles/EDM.html" target="_blank" rel="noopener noreferrer">#EDM</a>
<span class="issue_date">Issue Date: 2021-05-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/356" target="_blank" rel="noopener noreferrer" class="title-link">Going Deeper with Deep Knowledge Tracing, Beck+, EDM'16</a>
<span class="snippet"><span>Comment</span><p>BKT, PFA, DKTのinputの違いが記載されており非常にわかりやすい<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/119996969-310be080-c00a-11eb-84ce-631413ecaa4e.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/119996989-36692b00-c00a-11eb-8389-bc06b34fdd10.png" alt="image" loading="lazy"><br><br><br><br>BKT, PFA, DKTを様々なデータセットで性能を比較している。また、ASSISTmentsデータに問題点があったことを指摘し（e.g. duplicate records問題など）、ASSSTmentsデータの問題点を取り除いたデータでも比較実験をしている。結論としては、ASSISTmentsデータの問題点を取り除いたデータで比較すると、DKTがめっちゃ強いというわけではなく、PFAと性能大して変わらなかった、ということ。<br><br><br><br>KDD cupのデータではDKTが優位だが、これはPFAをKDD Cupデータに適用する際に、難易度を適切に求められない場面があったから、とのこと（問題+ステップ名のペアで難易度を測らざるを得ないが、そもそも1人の生徒しかそういったペアに回答していない場合があり、難易度が1.0 / 0.0 等の極端な値になってしまう。これらがoverfittingの原因になったりするので、そういった問題-ステップペアの難易度をスキルの難易度で置き換えたりしている）。</p>
<p>ちなみにこの手のDKTこれまでのモデルと性能大して変わんないよ？系の主張は、当時だったらそうかもしれないが、2020年のRiiiDの結果みると、オリジナルなDKTがシンプルな構造すぎただけであって、SAKT+RNNみたいな構造だったら多分普通にoutperformする、と個人的には思っている。</p>
<p>ASSISTmentsデータにはduplicate records問題以外にも、複数種類のスキルタグが付与された問題があったときに、1つのスキルタグごとに1レコードが列挙されるようなデータになっている点が、BKTと比較してDKTが有利だった点として指摘している。スキルA, Bが付与されている問題が２問あった時に、それらにそれぞれ正解・不正解した場合のASSISTments09-10データの構造は下図のようになる。DKTを使ってこのようなsequenceを学習した場合、スキルタグBの正誤予測には、一つ前のtime-stempのスキルタグAの正誤予測がそのまま利用できる、といった関係性を学習してしまう可能性が高い。BKTはスキルタグごとにモデルを構築するので、これではBKTと比較してDKTの方が不当に有利だよね、ということも指摘している。<br><br><img src="https://user-images.githubusercontent.com/12249301/163556038-27671b3c-d002-48d8-ac36-95fe2406b583.png" alt="image" loading="lazy"><br><br><br><br>複数タグが存在する場合の対処方法として、シンプルに複数タグを連結して新しいタグとする、ということを提案している。<br><br><img src="https://user-images.githubusercontent.com/12249301/163556428-38e1ad66-0991-47ef-b18d-16d574df79f3.png" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/StudentPerformancePrediction.html" target="_blank" rel="noopener noreferrer">#StudentPerformancePrediction</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<a class="button" href="articles/EDM.html" target="_blank" rel="noopener noreferrer">#EDM</a>
<span class="issue_date">Issue Date: 2021-05-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/355" target="_blank" rel="noopener noreferrer" class="title-link">How Deep is Knowledge Tracing?, Mozer+, EDM'16</a>
<span class="snippet"><span>Comment</span><p>DKTでは考慮できているが、BKTでは考慮できていない4種類のregularityを指摘し、それらを考慮ようにBKT（forgetting, interactions among skills, incorporasting latent student abilities）を拡張したところ、DKTと同等のパフォーマンスを発揮したことを示した研究。<br><br><br><br>- Recency Effects, Contextualized Trial Sequence, Inter-skill similarity, Individual variation in ability<br><br><br><br>DKTの成功は、deep learningによって得られた新たなrepresentationに基づくものではなく、上記input/outputの統計的なregularityを捉えることができる柔軟性と一般性によるものだと分析している（DKTは、汎用のリカレントニューラルネットワークモデルであり、学習と忘却のモデル化、スキルの発見、学生の能力の推論に特化した構成要素はないにもかかわらず、それらを捉えることができた。この柔軟性により、DKTは、ドメイン知識・事前分析がほとんどなくても、様々なデータセットでロバストに動作する）。が、DKTはこのようなドメイン知識等がなく良い性能を達成できている代償として、解釈生を犠牲にしている。BKTのようなshallowなモデルでも上記4種類の規則性を導入することでより解釈性があり、説明性があるモデルを獲得できる、と述べている。教育に応用する上で、解釈性・説明性は非常に重要な要素であり、同等の性能が達成できるなら、BKT拡張したほうがいいじゃん？っていう主張だと思われる。<br><br><br><br>DKTのAUC計算は、trialごとに該当スキルのpredictionを行い、全てのスキルに関してAUCを計算しているのに対し、<br><br>BKTは、個々のスキルごとにAUCを計算し、最終的にそれらを平均することでAUCを算出している点を指摘している（中身の実装を読んで）。<br><br>BKTのAUC計算方法の方が、DKTよりもAUCが低くなることを述べ、どちらかに統一した方が良いことを述べている。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/119991703-ae345700-c004-11eb-805e-aa2bf9ab9d3c.png" alt="image" loading="lazy"><br><br><br><br>Khan AcademyデータをDKTの共著者に使わせてもらえないかきいてみたところ、使わせてもらえなかったとも書いてある。</p>
<p>BKT+Forgetsは、ある特定のスキルの間に何回のtrialがあったかを数えておき、そのfrialの機会ごとにForgetが生じる機会が生じると考えるような定式化になっている。<br><br>たとえば、A_1 - A_2 - B_1 - A_3 - B_2 - B_3 - A_4 という問題の系列があったとする（A, Bはスキル名で、添字はスキルのinstance）。そうすると、A_1とA_2間でforgettingが生じる確率はF、A_2とA_3の間でforgettingが生じる確率は1-(1-F)^2、A_3とA_4の間でforgettingが生じる確率は1-(1-F)^3となる。<br><br><br><br>※ スキルAを連続してtrialした場合はFでforgettingするが、<br><br>　スキルAをtrialしない場合は 1 - (スキルAを覚えている確率) = Aを忘れている確率 ということだろうか。<br><br><br><br>BKT+Forgetsは <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/460" target="_blank" rel="noopener noreferrer">pyBKT: An Accessible Python Library of Bayesian Knowledge Tracing Models, Bardrinath+, EDM'20</a>
 に実装されている。</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/RecSys.html" target="_blank" rel="noopener noreferrer">#RecSys</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-12-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/298" target="_blank" rel="noopener noreferrer" class="title-link">Deep Neural Networks for YouTube Recommendations, Covington+, RecSys'16</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2018-10-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/279" target="_blank" rel="noopener noreferrer" class="title-link">Neural Headline Generation with Minimum Risk Training, Ayana+, N_A, arXiv'16</a>
<span class="snippet"><span>Summary</span>- 自動見出し生成のために、最小リスクトレーニング戦略を使用してモデルパラメータを最適化し、見出し生成の改善を実現する。提案手法は英語と中国語の見出し生成タスクで最先端のシステムを上回る性能を示す。</span>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/GraphConvolutionalNetwork.html" target="_blank" rel="noopener noreferrer">#GraphConvolutionalNetwork</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-03-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/265" target="_blank" rel="noopener noreferrer" class="title-link">Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering, Defferrard+, NIPS'16</a>
<span class="snippet"><span>Comment</span><p>GCNを勉強する際は読むと良いらしい。<br><br>あわせてこのへんも：<br><br>Semi-Supervised Classification with Graph Convolutional Networks, Kipf+, ICLR'17<br><br>


<a href="https://github.com/tkipf/gcn" target="_blank" rel="noopener noreferrer">https://github.com/tkipf/gcn</a>


</p></span><br><br>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2018-02-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/264" target="_blank" rel="noopener noreferrer" class="title-link">Tutorial: Deep Reinforcement Learning, David Silver, ICML'16</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-02-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/261" target="_blank" rel="noopener noreferrer" class="title-link">Layer Normalization, Ba+, arXiv'16</a>
<span class="snippet"><span>Summary</span>- バッチ正規化の代わりにレイヤー正規化を用いることで、リカレントニューラルネットワークのトレーニング時間を短縮。レイヤー内のニューロンの合計入力を正規化し、各ニューロンに独自の適応バイアスとゲインを適用。トレーニング時とテスト時で同じ計算を行い、隠れ状態のダイナミクスを安定させる。実証的に、トレーニング時間の大幅な短縮を確認。</span>
<span class="snippet"><span>Comment</span><p>解説スライド：<br><br>


<a href="https://www.slideshare.net/KeigoNishida/layer-normalizationnips" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/KeigoNishida/layer-normalizationnips</a>


<br><br></p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/CoNLL.html" target="_blank" rel="noopener noreferrer">#CoNLL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-02-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/258" target="_blank" rel="noopener noreferrer" class="title-link">Generating Sentences from a Continuous Space, Bowman+, CoNLL'16</a>
<span class="snippet"><span>Comment</span><p>VAEを利用して文生成</p>
<p>【Variational Autoencoder徹底解説】<br><br>


<a href="https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24" target="_blank" rel="noopener noreferrer">https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24</a>


</p></span><br><br>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/GenerativeAdversarialNetwork.html" target="_blank" rel="noopener noreferrer">#GenerativeAdversarialNetwork</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2018-02-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/254" target="_blank" rel="noopener noreferrer" class="title-link">Generative Adversarial Networks （GANS）, NIPS'16</a>
<span class="snippet"><span>Comment</span><p>Goodfellow氏によるGANチュートリアル</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/WSDM.html" target="_blank" rel="noopener noreferrer">#WSDM</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/216" target="_blank" rel="noopener noreferrer" class="title-link">Collaborative Denoising Auto-Encoders for Top-N Recommender Systems, Wu+, WSDM'16</a>
<span class="snippet"><span>Comment</span><p>Denoising Auto-Encoders を用いたtop-N推薦手法、Collaborative Denoising Auto-Encoder (CDAE)を提案。<br><br>モデルベースなCollaborative Filtering手法に相当する。corruptedなinputを復元するようなDenoising Auto Encoderのみで推薦を行うような手法は、この研究が初めてだと主張。<br><br><br><br>学習する際は、userのitemsetのsubsetをモデルに与え（noiseがあることに相当）、全体のitem setを復元できるように、学習する（すなわちDenoising Auto-Encoder）。<br><br>推薦する際は、ユーザのその時点でのpreference setをinputし、new itemを推薦する。<br><br><br><br></p>
<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/221" target="_blank" rel="noopener noreferrer">Collaborative Deep Learning for Recommender Systems Wang+, KDD’15</a>
 もStacked Denoising Auto EncoderとCollaborative Topic Regression <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/226" target="_blank" rel="noopener noreferrer">Collaborative topic modeling for recommending scientific articles, Wang+, KDD'11</a>
 を利用しているが、<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/221" target="_blank" rel="noopener noreferrer">Collaborative Deep Learning for Recommender Systems Wang+, KDD’15</a>
 ではarticle recommendationというspecificな問題を解いているのに対して、提案手法はgeneralなtop-N推薦に利用できることを主張。</p></span><br><br>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/SentimentAnalysis.html" target="_blank" rel="noopener noreferrer">#SentimentAnalysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/206" target="_blank" rel="noopener noreferrer" class="title-link">Neural Network for Sentiment Analysis, EMNLP'16</a>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/136" target="_blank" rel="noopener noreferrer" class="title-link">Incorporating Copying Mechanism in Sequence-to-Sequence Learning, Gu+, ACL'16</a>
<span class="snippet"><span>Comment</span><p>解説スライド：


<a href="https://www.slideshare.net/akihikowatanabe3110/incorporating-copying-mechanism-in-sequene-to-sequence-learning" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/incorporating-copying-mechanism-in-sequene-to-sequence-learning</a>


</p>
<p>単語のコピーと生成、両方を行えるネットワークを提案。<br><br>location based addressingなどによって、生成された単語がsourceに含まれていた場合などに、copy-mode, generate-modeを切り替えるような仕組みになっている。<br><br><br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/65" target="_blank" rel="noopener noreferrer">Pointing the unknown words, Gulcehre+, ACL'16</a>
 と同じタイミングで発表</p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/IJCAI.html" target="_blank" rel="noopener noreferrer">#IJCAI</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/132" target="_blank" rel="noopener noreferrer" class="title-link">Distraction-Based Neural Networks for Modeling Documents, Chen+, IJCAI'16</a>
<span class="snippet"><span>Comment</span><p>Neuralなモデルで「文書」の要約を行う研究。<br><br><br><br>提案手法では、attention-basedなsequence-to-sequenceモデルにdistractionと呼ばれる機構を導入することを提案。<br><br><br><br>distractionを導入するmotivationは、入力文書中の異なる情報を横断的に参照（一度着目した情報には今後あまり着目しないようなバイアスをかける）したうえで、要約を生成しようというもの。<br><br>これにより、生成される要約の冗長性を排除するのが狙い。<br><br><br><br>以下の3つのアプローチを用いて、distractionを実現<br><br><br><br>1. [Distraction over input content vectors]<br><br>　tステップ目において、decoderのinputとして用いるcontext vectorを<br><br>計算する際に、通常の計算に加えて、t-1ステップ目までに使用した<br><br>context vectorの情報を活用することで、これまでdecoderのinputとして<br><br>利用された情報をあまり重視視しないように、context vectorを生成する。<br><br><br><br>2. [Distraction over attention weight vectors]<br><br>　attentionの重みを計算する際に、過去に高いattentionの重みがついた<br><br>encoderのhidden stateについては、あまり重要視しないように<br><br>attentionの重みを計算。1と同様に、t-1ステップ目までのattention weightの<br><br>historyを保持しておき活用する。<br><br><br><br>3. [Distration in decoding]<br><br>　decodingステップでbeam-searchを行う際のスコア計算に、distraction scoreを導入。distraction<br><br>scoreはtステップ目までに用いられたcontext vector、attention<br><br>weight、decoderのstateから計算され、これまでと同じような情報に基づいて<br><br>単語が生成された場合は、スコアが低くなるようになっている。<br><br><br><br>CNN、およびLCSTS data (大規模な中国語のheadline generationデータ)で評価した結果、上記3つのdistraction機構を導入した場合に、最も高いROUGEスコアを獲得<br><br><br><br>特に、原文書が長い場合に、短い場合と比較して、distraction機構を導入すると、<br><br>ROUGEスコアの改善幅が大きくなったことが示されている</p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/131" target="_blank" rel="noopener noreferrer" class="title-link">Neural Summarization by Extracting Sentences and Words, Cheng+, ACL'16</a>
<span class="snippet"><span>Comment</span><p>ExtractiveかつNeuralな単一文書要約ならベースラインとして使用した方がよいかも</p></span><br><br>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/89" target="_blank" rel="noopener noreferrer" class="title-link">Neural Text Generation from Structured Data with Application to the Biography Domain, Lebret+, Lebret+, EMNLP'16</a>
<a class="button" href="articles/BeamSearch.html" target="_blank" rel="noopener noreferrer">#BeamSearch</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/80" target="_blank" rel="noopener noreferrer" class="title-link">Sequence-to-Sequence Learning as Beam-Search Optimization, Wiseman+, EMNLP'16</a>
<span class="snippet"><span>Comment</span><p>seq2seqを学習する際には、gold-history（これまで生成した単語がgoldなものと一緒）を使用し、次に続く単語の尤度を最大化するように学習するが、これには、<br><br><br><br>1. Explosure Bias: test時ではtraining時と違いgold historyを使えないし、training時には過去に生成した単語に誤りがあるみたいな状況がない <br><br>2. Loss-Evaluation Mismatch: training時は単語レベルのlossを使うが、だいたいはsentence-levelのmetrics (BLEUなど)を改善したい<br><br>3. Label Bias: 各タイムステップでの単語の生起確率が局所的に正規化され、誤ったhistoryに続く単語がgoldな履歴に続く単語と同じ量（の確率？）を受け取ってしまう<br><br><br><br>これらを解決するために、targetの"sequence"に対してスコア（確率ではない）を与えるようなseq2seqモデルを提案し、訓練方法として、beam search optimization（training時のlossとしてbeam searchの結果得られるerrorを用いる）を提案。</p></span><br><br>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/76" target="_blank" rel="noopener noreferrer" class="title-link">Larger-context language modelling with recurrent neural networks, Wang+, ACL'16</a>
<span class="snippet"><span>Comment</span><p>## 概要<br><br>通常のNeural Language Modelはsentence間に独立性の仮定を置きモデル化されているが、この独立性を排除し、preceding sentencesに依存するようにモデル化することで、言語モデルのコーパスレベルでのPerplexityが改善したという話。提案した言語モデルは、contextを考慮することで特に名詞や動詞、形容詞の予測性能が向上。Late-Fusion methodと呼ばれるRNNのoutputの計算にcontext vectorを組み込む手法が、Perplexityの改善にもっとも寄与していた。<br><br><br><br>## 手法<br><br><img src="https://user-images.githubusercontent.com/12249301/34412713-1e16da94-ec22-11e7-830c-0d0b6247207c.png" alt="image" loading="lazy"><br><br><br><br>sentence間の独立性を排除し、Corpusレベルのprobabilityを下図のように定義。（普通はP(Slが条件付けされていない)）<br><br><img src="https://user-images.githubusercontent.com/12249301/34412980-e2425afa-ec23-11e7-86cd-148f85dccc07.png" alt="image" loading="lazy"><br><br><br><br>preceding sentence (context)をモデル化するために、3種類の手法を提案。<br><br><br><br>[1. bag-of-words context]<br><br>　ナイーブに、contextに現れた単語の（単一の）bag-of-wordsベクトルを作り、linear layerをかませてcontext vectorを生成する手法。<br><br><br><br>[2. context recurrent neural network]<br><br>　preceding sentencesをbag-of-wordsベクトルの系列で表現し、これらのベクトルをsequentialにRNN-LSTMに読み込ませ、最後のhidden stateをcontext vectorとする手法。これにより、sentenceが出現した順番が考慮される。<br><br><br><br>[3. attention based context representation]<br><br>　Attentionを用いる手法も提案されており、context recurrent neural networkと同様にRNNにbag-of-wordsのsequenceを食わせるが、各時点におけるcontext sentenceのベクトルを、bi-directionalなRNNのforward, backward stateをconcatしたもので表現し、attention weightの計算に用いる。context vectorは1, 2ではcurrent sentence中では共通のものを用いるが、attention basedな場合はcurrent sentenceの単語ごとに異なるcontext vectorを生成して用いる。<br><br><br><br>生成したcontext vectorをsentence-levelのRNN言語モデルに組み合わせる際に、二種類のFusion Methodを提案している。<br><br><br><br>[1. Early Fusion]<br><br>　ナイーブに、RNNLMの各時点でのinputにcontext vectorの情報を組み込む方法。<br><br>[2. Late Fusion]<br><br>　よりうまくcontext vectorの情報を組み込むために、current sentence内の単語のdependency(intra-sentence dependency)と、current sentenceとcontextの関係を別々に考慮する。context vectorとmemory cellの情報から、context vector中の不要箇所をフィルタリングしたcontrolled context vectorを生成し、LSTMのoutputの計算に用いる。Later Fusionはシンプルだが、corpusレベルのlanguage modelingの勾配消失問題を緩和することもできる。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34413898-99efbaf8-ec29-11e7-94f5-db82eee399b3.png" alt="image" loading="lazy"><br><br><br><br>## 評価<br><br>IMDB, BBC, PennTreebank, Fil9 (cleaned wikipedia corpus)の4種類のデータで学習し、corpus levelでPerplexityを測った。<br><br><img src="https://user-images.githubusercontent.com/12249301/34414121-b75b2996-ec2a-11e7-9716-dbbb9006b1b5.png" alt="image" loading="lazy"><br><br><br><br>Late FusionがPerplexityの減少に大きく寄与している。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34414218-596b373a-ec2b-11e7-85ad-cf98df04ce57.png" alt="image" loading="lazy"><br><br><br><br>PoSタグごとのperplexityを測った結果、contextを考慮した場合に名詞や形容詞、動詞のPerplexityに改善が見られた。一方、Coordinate Conjungtion (And, Or, So, Forなど)や限定詞、Personal Pronouns (I, You, It, Heなど)のPerplexityは劣化した。前者はopen-classな内容語であり、後者はclosed-classな機能語である。機能語はgrammaticalなroleを決めるのに対し、内容語はその名の通り、sentenceやdiscourseの内容を決めるものなので、文書の内容をより捉えることができると考察している。</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/IJCAI.html" target="_blank" rel="noopener noreferrer">#IJCAI</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/73" target="_blank" rel="noopener noreferrer" class="title-link">Distraction-Based Neural Networks for Modeling Documents, Chen+, IJCAI'16</a>
<span class="snippet"><span>Comment</span><p>Neuralなモデルで「文書」の要約を行う研究。<br><br><br><br>提案手法では、attention-basedなsequence-to-sequenceモデルにdistractionと呼ばれる機構を導入することを提案。<br><br><br><br>distractionを導入するmotivationは、入力文書中の異なる情報を横断的に参照（一度着目した情報には今後あまり着目しないようなバイアスをかける）したうえで、要約を生成しようというもの。<br><br>これにより、生成される要約の冗長性を排除するのが狙い。<br><br><br><br>以下の3つのアプローチを用いて、distractionを実現<br><br><br><br>1. [Distraction over input content vectors]<br><br>　tステップ目において、decoderのinputとして用いるcontext vectorを<br><br>計算する際に、通常の計算に加えて、t-1ステップ目までに使用した<br><br>context vectorの情報を活用することで、これまでdecoderのinputとして<br><br>利用された情報をあまり重視視しないように、context vectorを生成する。<br><br><br><br>2. [Distraction over attention weight vectors]<br><br>　attentionの重みを計算する際に、過去に高いattentionの重みがついた<br><br>encoderのhidden stateについては、あまり重要視しないように<br><br>attentionの重みを計算。1と同様に、t-1ステップ目までのattention weightの<br><br>historyを保持しておき活用する。<br><br><br><br>3. [Distration in decoding]<br><br>　decodingステップでbeam-searchを行う際のスコア計算に、distraction scoreを導入。distraction<br><br>scoreはtステップ目までに用いられたcontext vector、attention<br><br>weight、decoderのstateから計算され、これまでと同じような情報に基づいて<br><br>単語が生成された場合は、スコアが低くなるようになっている。<br><br><br><br>CNN、およびLCSTS data (大規模な中国語のheadline generationデータ)で評価した結果、上記3つのdistraction機構を導入した場合に、最も高いROUGEスコアを獲得<br><br><br><br>特に、原文書が長い場合に、短い場合と比較して、distraction機構を導入すると、<br><br>ROUGEスコアの改善幅が大きくなったことが示されている</p>
<p>Distraction機構の有用性は、ACL'17のstanford NLPグループが提案したPointer Generator Networkでも示されている（Coverage Vectorという呼び方をしてた気がする）</p></span><br><br>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/70" target="_blank" rel="noopener noreferrer" class="title-link">Learning Distributed Representations of Sentences from Unlabelled Data, Hill+, NAACL'16</a>
<span class="snippet"><span>Comment</span><p>Sentenceのrepresentationを学習する話<br><br><br><br>代表的なsentenceのrepresentation作成手法(CBOW, SkipGram, SkipThought, Paragraph Vec, NMTなど)をsupervisedな評価（タスク志向+supervised）とunsupervisedな評価(文間の距離をコサイン距離ではかり、人間が決めた順序と相関を測る)で比較している。<br><br><br><br>また筆者らはSequential Denoising Auto Encoder(SDAE)とFastSentと呼ばれる手法を提案しており、前者はorderedなsentenceデータがなくても訓練でき、FastSentはorderedなsentenceデータが必要だが高速に訓練できるモデルである。<br><br><br><br>実験の結果、supervisedな評価では、基本的にはSkipThoughtがもっとも良い性能を示し、paraphrasingタスクにおいて、SkipThoughtに3ポイント程度差をつけて良い性能を示した。unsupervisedな評価では、DictRepとFastSentがもっとも良い性能を示した。<br><br><br><br>実験の結果、以下のような知見が得られた：<br><br><br><br>## 異なるobjective functionは異なるembeddingを作り出す<br><br>objective functionは、主に隣接する文を予測するものと、自分自身を再現するものに分けられる。これらの違いによって、生成されるembeddingが異なっている。Table5をみると、後者については、生成されたrepresentationのnearest neighborを見ていると、自身と似たような単語を含む文が引っ張ってこれるが、前者については、文のコンセプトや機能は似ているが、単語の重複は少なかったりする。<br><br><br><br>## supervisedな場合とunsupervisedな評価でのパフォーマンスの違い<br><br>supervisedな設定では、SkipThoughtやSDAEなどのモデルが良い性能を示しているが、unsupervisedな設定ではまりうまくいかず。unsupevisedな設定ではlog-linearモデルが基本的には良い性能を示した。<br><br><br><br>## pre-trainedなベクトルを使用したモデルはそうでない場合と比較してパフォーマンスが良い<br><br><br><br>## 必要なリソースの違い<br><br>モデルによっては、順序づけられた文のデータが必要だったり、文の順序が学習に必要なかったりする。あるいは、デコーディングに時間がかかったり、めちゃくちゃメモリ食ったりする。このようなリソースの性質の違いは、使用できるapplicationに制約を与える。<br><br><br><br>## 結論<br><br>とりあえず、supervisedなモデルにrepresentationを使ってモデルになんらかのknowledgeをぶちこみたいときはSkipThought、単純に類似した文を検索したいとか、そういう場合はFastSentを使うと良いってことですかね.</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/65" target="_blank" rel="noopener noreferrer" class="title-link">Pointing the unknown words, Gulcehre+, ACL'16</a>
<span class="snippet"><span>Comment</span><p>テキストを生成する際に、source textからのコピーを行える機構を導入することで未知語問題に対処した話</p>
<p>CopyNetと同じタイミングで（というか同じconferenceで）発表</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Visual%20Words.html" target="_blank" rel="noopener noreferrer">#Visual Words</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/63" target="_blank" rel="noopener noreferrer" class="title-link">Image Captioning with Semantic Attention, You+, CVPR'16.</a>
<span class="snippet"><span>Comment</span><p>画像そのものだけでなく、モデルへのInputにVisual Wordsを明示的に加えることで、captioningの精度が上がりましたという論文</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Visual%20Words.html" target="_blank" rel="noopener noreferrer">#Visual Words</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/62" target="_blank" rel="noopener noreferrer" class="title-link">What Value Do Explicit High Level Concepts Have in Vision to Language Problems?, Wu+, CVPR'16.</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/ECCV.html" target="_blank" rel="noopener noreferrer">#ECCV</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/61" target="_blank" rel="noopener noreferrer" class="title-link">Generating Visual Explanations, Hendrickks+, ECCV'16</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2544" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Very Deep Convolutional Networks for Large-Scale Image Recognition, Karen Simonyan+, ICLR'15</a>
<span class="snippet"><span>Summary</span>- 本研究では、3x3の畳み込みフィルタを用いた深い畳み込みネットワークの精度向上を評価し、16-19層の重み層で従来の最先端構成を大幅に改善したことを示す。これにより、ImageNet Challenge 2014で1位と2位を獲得し、他のデータセットでも優れた一般化性能を示した。最も性能の良い2つのConvNetモデルを公開し、深層視覚表現の研究を促進する。</span>
<span class="snippet"><span>Comment</span><p>いわゆるVGGNetを提案した論文</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1954" target="_blank" rel="noopener noreferrer" class="title-link">Neural Machine Translation by Jointly Learning to Align and Translate, Dzmitry Bahdanau+, ICLR'15</a>
<span class="snippet"><span>Summary</span>- ニューラル機械翻訳は、エンコーダー-デコーダーアーキテクチャを用いて翻訳性能を向上させる新しいアプローチである。本論文では、固定長のベクトルの使用が性能向上のボトルネックであるとし、モデルが関連するソース文の部分を自動的に検索できるように拡張することを提案。これにより、英語からフランス語への翻訳タスクで最先端のフレーズベースシステムと同等の性能を達成し、モデルのアライメントが直感と一致することを示した。</span>
<span class="snippet"><span>Comment</span><p>(Cross-)Attentionを初めて提案した研究。メモってなかったので今更ながら追加。Attentionはここからはじまった（と認識している）</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/CTRPrediction.html" target="_blank" rel="noopener noreferrer">#CTRPrediction</a>
<a class="button" href="articles/SequentialRecommendation.html" target="_blank" rel="noopener noreferrer">#SequentialRecommendation</a>
<a class="button" href="articles/SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<span class="issue_date">Issue Date: 2025-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1902" target="_blank" rel="noopener noreferrer" class="title-link">E-commerce in Your Inbox: Product Recommendations at Scale, Mihajlo Grbovic+, KDD'15</a>
<span class="snippet"><span>Summary</span>- メールの領収書から得た購入履歴を活用し、Yahoo Mailユーザーにパーソナライズされた商品広告を配信するシステムを提案。新しい神経言語ベースのアルゴリズムを用いて、2900万人以上のユーザーのデータでオフラインテストを実施した結果、クリック率が9%向上し、コンバージョン率も改善。システムは2014年のホリデーシーズンに本稼働を開始。</span>
<span class="snippet"><span>Comment</span><p>Yahoo mailにおける商品推薦の研究<br><img src="https://github.com/user-attachments/assets/6f54d2c7-6f30-411b-94c9-888c62811bd8" alt="image" loading="lazy"><br><br>Yahoo mailのレシート情報から、商品購入に関する情報とtimestampを抽出し、時系列データを形成。評価時はTimestampで1ヶ月分のデータをheldoutし評価している。Sequential Recommendationの一種とみなせるが、評価データをユーザ単位でなくtimestampで区切っている点でよりrealisticな評価をしている。<br><img src="https://github.com/user-attachments/assets/6d79bb63-8d88-4be8-b1ef-1db2affb141f" alt="image" loading="lazy"></p>
<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/342" target="_blank" rel="noopener noreferrer">Sequence-Aware Recommender Systems, ACM Computing Surveys, Vol. 1, No. 1, Article 1, 2018</a>
</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2021-06-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/369" target="_blank" rel="noopener noreferrer" class="title-link">Effective Approaches to Attention-based Neural Machine Translation, Luong+, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>Luong論文。attentionの話しはじめると、だいたいBahdanau+か、Luong+論文が引用される。<br><br><br><br>Global Attentionと、Local Attentionについて記述されている。Global Attentionがよく利用される。<br><br><br><br>Global Attention<br><br><img src="https://user-images.githubusercontent.com/12249301/120452200-008ec280-c3cd-11eb-8ced-47dc9e67f487.png" alt="image" loading="lazy"><br><br><br><br>Local Attention<br><br><img src="https://user-images.githubusercontent.com/12249301/120452397-2025eb00-c3cd-11eb-9d3b-0f7802a40712.png" alt="image" loading="lazy"><br><br></p>
<p>やはり菊池さんの解説スライドが鉄板。<br><br>


<a href="https://www.slideshare.net/yutakikuchi927/deep-learning-nlp-attention" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/yutakikuchi927/deep-learning-nlp-attention</a>


</p>
<p>参考までに、LuongらのGlobal Attentionの計算の流れは下記となっている：<br><br>- h_t -&gt; a_t -&gt; c_t -&gt; h^~_t<br><br><br><br>BahdanauらのAttentionは下記<br><br>- h_t-1 -&gt; a_t -&gt; c_t -&gt; h_t<br><br><br><br>t-1のhidden stateを使うのか、input feeding後の現在のhidden stateをattention weightの計算に使うのかが異なっている。</p>
<p>また、過去のalignmentの情報を考慮した上でデコーディングしていくために、input-feeding approachも提案<br><br><img src="https://user-images.githubusercontent.com/12249301/120877145-cfdaa300-c5ef-11eb-8a8b-a57d03d864b4.png" alt="image" loading="lazy"><br><br><br><br>input-feeding appproachでは、t-1ステップ目のoutputの算出に使ったh^~_t（hidden_stateとcontext vectorをconcatし、tanhのactivationを噛ませた線形変換を行なったベクトル）を、時刻tのinput embeddingにconcatして、RNNに入力する。</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-02-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/262" target="_blank" rel="noopener noreferrer" class="title-link">An Empirical Exploration of Recurrent Network Architectures, Jozefowicz+, ICML'15</a>
<span class="snippet"><span>Comment</span><p>GRUとLSTMの違いを理解するのに最適</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-02-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/257" target="_blank" rel="noopener noreferrer" class="title-link">Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks, Tai+, ACL'15</a>
<span class="snippet"><span>Comment</span><p>Tree-LSTM論文</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/MultitaskLearning.html" target="_blank" rel="noopener noreferrer">#MultitaskLearning</a>
<a class="button" href="articles/QueryClassification.html" target="_blank" rel="noopener noreferrer">#QueryClassification</a>
<a class="button" href="articles/WebSearch.html" target="_blank" rel="noopener noreferrer">#WebSearch</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2018-02-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/249" target="_blank" rel="noopener noreferrer" class="title-link">Representation Learning Using Multi-Task Deep Neural Networks for Semantic Classification and Information Retrieval, Liu+, NAACL-HLT'15</a>
<span class="snippet"><span>Comment</span><p>クエリ分類と検索をNeural Netを用いてmulti-task learningする研究</p>
<p>分類(multi-class classification)とランキング(pairwise learning-to-rank)という異なる操作が必要なタスクを、multi task learningの枠組みで組み合わせた（初めての？）研究。<br><br>この研究では分類タスクとしてクエリ分類、ランキングタスクとしてWeb Searchを扱っている。<br><br><br><br>モデルの全体像は下図の通り。<br><br><img src="https://user-images.githubusercontent.com/12249301/35790293-e19d996e-0a84-11e8-8954-0331e9851f77.png" alt="image" loading="lazy"><br><br>shared layersの部分で、クエリとドキュメントを一度共通の空間に落とし、そのrepresentationを用いて、l3においてtask-specificな空間に写像し各タスクを解いている。<br><br>分類タスクを解く際には、outputはsigmoidを用いる（すなわち、output layerのユニット数はラベル数分存在する）。<br><br>Web Searchを解く際には、クエリとドキュメントをそれぞれtask specificな空間に別々に写像し、それらのcosine similarityをとった結果にsoftmaxをかけることで、ドキュメントのrelevance scoreを計算している。<br><br><img src="https://user-images.githubusercontent.com/12249301/35790346-36ceb044-0a85-11e8-86c1-8ae769c60081.png" alt="image" loading="lazy"><br><br>学習時のアルゴリズムは上の通り。各タスクをランダムにpickし、各タスクの目的関数が最適化されるように思いをSGDで更新する、といったことを繰り返す。<br><br><br><br>なお、alternativeとして、下図のようなネットワーク構造を考えることができるが（クエリのrepresentationのみがシェアされている）、このモデルの場合はweb searchがあまりうまくいかなかった模様。<br><br><img src="https://user-images.githubusercontent.com/12249301/35790424-ba0bcc44-0a85-11e8-885f-65c6d5a7d670.png" alt="image" loading="lazy"><br><br>理由としては、unbalancedなupdates（クエリパラメータのupdateがdocumentよりも多くアップデートされること）が原因ではないかと言及しており、multi-task modelにおいては、パラメータをどれだけシェアするかはネットワークをデザインする上で重要な選択であると述べている。</p>
<p>評価で用いるデータの統計量は下記の通り。<br><br><img src="https://user-images.githubusercontent.com/12249301/35790589-79357052-0a86-11e8-970f-2f6ead2b30f7.png" alt="image" loading="lazy"><br><br>1年分の検索ログから抽出。クエリ分類（各クラスごとにbinary）、および文書のrelevance score（5-scale）は人手で付与されている。<br><br>クエリ分類はROC曲線のAUCを用い、Web SearchではNDCG (Normalized Discounted Cumulative Gain) を用いた。<br><br><img src="https://user-images.githubusercontent.com/12249301/35790967-61f24328-0a88-11e8-846a-5a93861358a7.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/35790975-6ee0b6b4-0a88-11e8-899d-4c6200ecf66e.png" alt="image" loading="lazy"><br><br>multi task learningをした場合に、性能が向上している。<br><br><br><br>また、ネットワークが学習したsemantic representationとSVMを用いて、domain adaptationの実験（各クエリ分類のタスクは独立しているので、一つのクエリ分類のデータを選択しsemantic representationをtrainし、学習したrepresentationを別のクエリ分類タスクに適用する）も行なっており、訓練事例数が少ない場合に有効に働くことを確認（Letter3gramとWord3gramはnot trained/adapted）。<br><br><img src="https://user-images.githubusercontent.com/12249301/35791328-a7fcae74-0a8a-11e8-84cb-73b6e7141948.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/35791174-b5ad2c16-0a89-11e8-8e7d-d3850348dae3.png" alt="image" loading="lazy"><br><br>また、SemanticRepresentationへ写像する行列W1のパラメータの初期化の仕方と、サンプル数の変化による性能の違いについても実験。DNN1はW1をランダムに初期化、DNN2は別タスク（別のクエリ分類タスク）で学習したW1でfixする手法。<br><br>訓練事例が数百万程度ある場合は、DNN1がもっとも性能がよく、数千の訓練事例数の場合はsemantic representationを用いたSVMがもっともよく、midium-rangeの訓練事例数の場合はDNN2がもっとも性能がよかったため、データのサイズに応じて手法を使い分けると良い。</p>
<p>データセットにおいて、クエリの長さや文書の長さが記述されていないのがきになる。</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/137" target="_blank" rel="noopener noreferrer" class="title-link">A Neural Attention Model for Sentence Summarization, Rush+, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>解説スライド：


<a href="https://www.slideshare.net/akihikowatanabe3110/a-neural-attention-model-for-sentence-summarization-65612331" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/a-neural-attention-model-for-sentence-summarization-65612331</a>


</p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/75" target="_blank" rel="noopener noreferrer" class="title-link">LCSTS: A large scale chinese short text summarizatino dataset, Hu+, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>Large Chinese Short Text Summarization (LCSTS) datasetを作成<br><br><br><br>データセットを作成する際は、Weibo上の特定のorganizationの投稿の特徴を利用。<br><br>Weiboにニュースを投稿する際に、投稿の冒頭にニュースのvery short summaryがまず記載され、その後ニュース本文（短め）が記載される特徴があるので、この対をsource-reference対として収集した。<br><br>収集する際には、約１００個のルールに基づくフィルタリングやclearning, 抽出等を行なっている。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34411045-95f7baf2-ec17-11e7-94fb-faf2559d6994.png" alt="image" loading="lazy"><br><br><br><br>データセットのpropertyとしては、下記のPartI, II, IIIに分かれている。<br><br><br><br>PartI: 2.4Mのshort text - summary pair<br><br>PartII: PartIからランダムにサンプリングされた10kのpairに対して、5 scaleで要約のrelevanceをratingしたデータ。ただし、各pairにラベルづけをしたevaluatorは1名のみ。<br><br>PartIII: 2kのpairに対して（PartI, PartIIとは独立）、3名のevaluatorが5-scaleでrating。evaluatorのratingが一致した1kのpairを抽出したデータ。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34411199-8db4df90-ec18-11e7-8703-fd8f9512a903.png" alt="image" loading="lazy"><br><br><br><br>RNN-GRUを用いたSummarizerも提案している。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34411224-b5543eba-ec18-11e7-8556-a3b42bfcf334.png" alt="image" loading="lazy"><br><br><br><br></p>
<p>CopyNetなどはLCSTSを使って評価している。他にも使ってる論文あったはず。</p>
<p>ACL'17のPointer Generator Networkでした。</p></span><br><br>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/74" target="_blank" rel="noopener noreferrer" class="title-link">A hierarchical neural autoencoder for paragraphs and documents, Li+, ACL'15</a>
<span class="snippet"><span>Comment</span><p>複数文を生成(今回はautoencoder)するために、standardなseq2seq LSTM modelを、拡張したという話。<br><br><br><br>要は、paragraph/documentのrepresentationが欲しいのだが、アイデアとしては、word-levelの情報を扱うLSTM layerとsentenc-levelの情報を扱うLSTM layerを用意し、それらのcompositionによって、paragraph/documentを表現しましたという話。<br><br><br><br>sentence-levelのattentionを入れたらよくなっている。<br><br><br><br>trip advisorのreviewとwikipediaのparagraphを使ってtrainingして、どれだけ文書を再構築できるか実験。<br><br>MetricはROUGE, BLEUおよびcoherence(sentence order代替)を測るために、各sentence間のgapがinputとoutputでどれだけ一致しているかで評価。<br><br><br><br>hierarchical lstm with attention &gt; hierarchical lstm &gt; standard lstm の順番で高性能。<br><br><br><br>学習には、tesla K40を積んだマシンで、standard modelが2-3 weeks, hierarchical modelsが4-6週間かかるらしい。</p></span><br><br>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/SentimentAnalysis.html" target="_blank" rel="noopener noreferrer">#SentimentAnalysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/72" target="_blank" rel="noopener noreferrer" class="title-link">Document Modeling with Gated Recurrent Neural Network for Sentiment Classification, Tang+, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>word level -&gt; sentence level -&gt; document level のrepresentationを求め、documentのsentiment classificationをする話。<br><br>documentのRepresentationを生成するときに参考になるやも。<br><br>sentenceのrepresentationを求めるときは、CNN/LSTMを使う。<br><br>document levelに落とすことは、bi-directionalなGatedRNN(このGatedRNNはLSTMのoutput-gateが常にonになっているようなものを使う。sentenceのsemanticsに関する情報を落としたくないかららしい。)を使う。<br><br>sentiment classificationタスクで評価し、(sentence levelのrepresentationを求めるときは)LSTMが最も性能がよく、documentのrepresentationを求めるときは、standardなRNNよりもGatedRNNのほうが性能よかった。</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/59" target="_blank" rel="noopener noreferrer" class="title-link">Sentence Compression by Deletion with LSTMs, Fillipova+, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>slide:


<a href="https://www.slideshare.net/akihikowatanabe3110/sentence-compression-by-deletion-with-lstms" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/sentence-compression-by-deletion-with-lstms</a>


</p></span><br><br>
<a class="button" href="articles/TimeSeriesDataProcessing.html" target="_blank" rel="noopener noreferrer">#TimeSeriesDataProcessing</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Financial.html" target="_blank" rel="noopener noreferrer">#Financial</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/117" target="_blank" rel="noopener noreferrer" class="title-link">Recurrent neural network and a hybrid model for prediction of stock returns, Akhter+, Expert Systems with Applications'14</a>
<span class="snippet"><span>Comment</span><p>Stock returnのpredictionタスクに対してNNを適用。<br><br><br><br>AR-MRNNモデルをRNNに適用、高い性能を示している。 moving referenceをsubtractした値をinput-outputに用いることで、normalizationやdetrending等の前処理が不要となり、regularizationの役割を果たすため汎化能力が向上する。<br><br><br><br>※ AR-MRN: NNNのinput-outputとして、生のreturn値を用いるのではなく、ある時刻におけるreturnをsubtractした値(moving reference)を用いるモデル (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/116" target="_blank" rel="noopener noreferrer">Prediction-based portfolio optimization model using neural networks, Freitas+, Neurocomputing'09</a>
 で提案)</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Contents-based.html" target="_blank" rel="noopener noreferrer">#Contents-based</a>
<a class="button" href="articles/CIKM.html" target="_blank" rel="noopener noreferrer">#CIKM</a>
<span class="issue_date">Issue Date: 2021-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/364" target="_blank" rel="noopener noreferrer" class="title-link">Learning Deep Structured Semantic Models  for Web Search using Clickthrough Data, Huang+, CIKM'13</a>
<span class="snippet"><span>Comment</span><p>日本語解説: 


<a href="https://shunk031.me/paper-survey/summary/others/Learning-Deep-Structured-Semantic-Models-for-Web-Search-using-Clickthrough-Data" target="_blank" rel="noopener noreferrer">https://shunk031.me/paper-survey/summary/others/Learning-Deep-Structured-Semantic-Models-for-Web-Search-using-Clickthrough-Data</a>


</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/MatrixFactorization.html" target="_blank" rel="noopener noreferrer">#MatrixFactorization</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/224" target="_blank" rel="noopener noreferrer" class="title-link">Deep content-based music recommendation, Oord+, NIPS'13</a>
<span class="snippet"><span>Comment</span><p>Contents-Basedな音楽推薦手法(cold-start problemに強い)。<br><br>Weighted Matrix Factorization (WMF) (Implicit Feedbackによるデータに特化したMatrix Factorization手法) <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/225" target="_blank" rel="noopener noreferrer">Collaborative filtering for implicit feedback datasets, Hu+, International Conference on Data Mining, 2008</a>
 に、Convolutional Neural Networkによるmusic audioのlatent vectorの情報が組み込まれ、item vectorが学習されるような仕組みになっている。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34815522-01679f0e-f6f5-11e7-8534-22e5b5edd7a6.png" alt="image" loading="lazy"><br><br><br><br>CNNでmusic audioのrepresentationを生成する際には、audioのtime-frequencyの情報をinputとする。学習を高速化するために、window幅を3秒に設定しmusic clipをサンプルしinputする。music clip全体のrepresentationを求める際には、consecutive windowからpredictionしたrepresentationを平均したものを使用する。</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/ImageClassification.html" target="_blank" rel="noopener noreferrer">#ImageClassification</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2025-05-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1958" target="_blank" rel="noopener noreferrer" class="title-link">ImageNet Classification with Deep Convolutional Neural Networks, Krizhevsky+, NIPS'12</a>
<span class="snippet"><span>Comment</span><p>ILSVRC 2012において圧倒的な性能示したことで現代のDeepLearningの火付け役となった研究AlexNet。メモってなかったので今更ながら追加した。</p>
<p>AlexNet以前の画像認識技術については牛久先生がまとめてくださっている（当時の課題とそれに対する解決法、しかしまだ課題が…と次々と課題に直面し解決していく様子が描かれており非常に興味深かった)。現在でも残っている技術も紹介されている。:<br>


<a href="https://speakerdeck.com/yushiku/pre_alexnet" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/yushiku/pre_alexnet</a>


<br><br>&gt; 過去の技術だからといって聞き流していると時代背景の変化によってなし得たイノベーションを逃すかも<br><br>これは肝に銘じたい。</p></span><br><br>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/MatrixFactorization.html" target="_blank" rel="noopener noreferrer">#MatrixFactorization</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/StudentPerformancePrediction.html" target="_blank" rel="noopener noreferrer">#StudentPerformancePrediction</a>
<span class="issue_date">Issue Date: 2021-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/426" target="_blank" rel="noopener noreferrer" class="title-link">Collaborative Filtering Applied to Educational Data Mining, Andreas+, KDD Cup'10</a>
<span class="snippet"><span>Comment</span><p>KDD Cup'10のStudent Performance Predictionタスクにおいて3位をとった手法<br><br>メモリベースドな協調フィルタリングと、Matirx Factorizationモデルを利用してStudent Performance Predictionを実施。<br><br>最終的にこれらのモデルをニューラルネットでensembleしている。</p></span><br><br>
<a class="button" href="articles/TimeSeriesDataProcessing.html" target="_blank" rel="noopener noreferrer">#TimeSeriesDataProcessing</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Financial.html" target="_blank" rel="noopener noreferrer">#Financial</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/116" target="_blank" rel="noopener noreferrer" class="title-link">Prediction-based portfolio optimization model using neural networks, Freitas+, Neurocomputing'09</a>
<span class="snippet"><span>Comment</span><p>Stock returnのpredictionタスクに対してNNを適用。<br><br><br><br>NNのinput-outputとして、生のreturn値を用いるのではなく、ある時刻におけるreturnをsubtractした値(moving reference)を用いる、AR-MRNNモデルを提案。</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-04-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1912" target="_blank" rel="noopener noreferrer" class="title-link">Adaptive Mixture of Local Experts, Jacobs+, Neural Computation'91</a>
<span class="snippet"><span>Comment</span><p>Mixture of Expertsの起源</p>
<p>と思ったのだが、下記研究の方が年号が古いようだが、こちらが起源ではなのか・・・？だがアブスト中に上記論文で提案されたMoEのパフォーマンスを比較する、といった旨の記述があるので時系列がよくわからない。<br>[Evaluation of Adaptive Mixtures of Competing Experts](


<a href="http://www.cs.toronto.edu/~fritz/absps/nh91.pdf)" target="_blank" rel="noopener noreferrer">http://www.cs.toronto.edu/~fritz/absps/nh91.pdf)</a>


</p>
<p>参考: 


<a href="https://speakerdeck.com/onysuke/mixture-of-expertsniguan-suruwen-xian-diao-cha" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/onysuke/mixture-of-expertsniguan-suruwen-xian-diao-cha</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/AWS.html" target="_blank" rel="noopener noreferrer">#AWS</a>
<a class="button" href="articles/MLOps.html" target="_blank" rel="noopener noreferrer">#MLOps</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/A/B%20Testing.html" target="_blank" rel="noopener noreferrer">#A/B Testing</a>
<a class="button" href="articles/TwoTowerModel.html" target="_blank" rel="noopener noreferrer">#TwoTowerModel</a>
<span class="issue_date">Issue Date: 2025-06-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2113" target="_blank" rel="noopener noreferrer" class="title-link">日経電子版のアプリトップ「おすすめ」をTwo Towerモデルでリプレースしました, NIKKEI, 2025.05</a>
<span class="snippet"><span>Comment</span><p>リアルタイム推薦をするユースケースにおいて、ルールベース+協調フィルタリング(Jubatus)からTwo Towerモデルに切り替えた際にレイテンシが300ms増えてしまったため、ボトルネックを特定し一部をパッチ処理にしつつもリアルタイム性を残すことで解決したという話。AWSの構成、A/Bテストや負荷テストの話もあり、実用的で非常に興味深かった。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Word.html" target="_blank" rel="noopener noreferrer">#Word</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/STS%20(SemanticTextualSimilarity).html" target="_blank" rel="noopener noreferrer">#STS (SemanticTextualSimilarity)</a>
<span class="issue_date">Issue Date: 2024-11-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1536" target="_blank" rel="noopener noreferrer" class="title-link">Zipf 白色化：タイプとトークンの区別がもたらす良質な埋め込み空間と損失関数, Sho Yokoi, 2024.11</a>
<span class="snippet"><span>Summary</span>- 単語埋め込み空間の歪みを修正することでタスクのパフォーマンスが向上することを示す。既存のアプローチは単語頻度が均一であると仮定しているが、実際にはZipfの法則に従う非均一な分布である。Zipfに基づく頻度で重み付けされたPCAホワイトニングを行うことで、パフォーマンスが大幅に向上し、ベースラインを超える。情報幾何学的な観点から、低頻度の単語を強調する理論を提案し、人気の自然言語処理手法がこの理論に基づいて機能することを示す。</span>
<span class="snippet"><span>Comment</span><p>元論文: [Yokoi, Bao, Kurita, Shimodaira, “Zipfian Whitening,” NeurIPS 2024. ](


<a href="https://arxiv.org/abs/2411.00680)" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2411.00680)</a>


</p>
<p>単語ベクトルを活用して様々なタスクを実施する際に一般的な全部足して個数で割るような平均ベクトル計算は、<br>個々の単語頻度を一様と仮定した場合の\"期待値\"と等価であり、<br>これは現実世界の単語頻度の実態とは全然異なるから、きちんと考慮したいよね、という話で<br>&lt;img src=\"https://github.com/user-attachments/assets/cc38dbd5-8b6e-45e6-8a81-00f524eb36f8\" alt=\"image\" loading=\"lazy\" /&gt;<br>頻度を考慮するとSemantic Textual Similarity（STS）タスクで効果絶大であることがわかった。<br>&lt;img src=\"https://github.com/user-attachments/assets/2042d75f-6325-4e50-9423-f8621084fb75\" alt=\"image\" loading=\"lazy\" /&gt;<br><br>では、なぜこれまで一様分布扱いするのが一般的だったのかというと、<br>実態として単語埋め込み行列が単語をタイプとみなして構築されたものであり、<br>コーパス全体を捉えた（言語利用の実態を捉えた）データ行列（単語をトークンとみなしたもの）になっていなかったことに起因していたからです（だから、経験頻度を用いて頻度情報を復元する必要があるよね）、<br>という感じの話だと思われ、<br>&lt;img src=\"https://github.com/user-attachments/assets/ba97319c-83f7-4443-a8e3-fa36030d704b\" alt=\"image\" loading=\"lazy\" /&gt;<br><br>経験頻度を考慮すると、そもそも背後に仮定しているモデル自体が暗黙的に変わり、<br>低頻度語が強調されることで、単語に対してTF-IDFのような重みづけがされることで性能が良くなるよね、みたいな話だと思われる。<br>&lt;img src=\"https://github.com/user-attachments/assets/7495f250-d680-4698-99c5-a326ead77e12\" alt=\"image\" loading=\"lazy\" /&gt;</p>
<p>余談だが、昔のNLPでは、P\(w,c)をモデル化したものを生成モデル、テキスト生成で一般的なP\(w|c)は分類モデル（VAEとかはテキスト生成をするが、生成モデルなので別）、と呼んでいたと思うが、いまはテキスト生成モデルのことを略して生成モデル、と呼称するのが一般的なのだろうか。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CTRPrediction.html" target="_blank" rel="noopener noreferrer">#CTRPrediction</a>
<a class="button" href="articles/NewsRecommendation.html" target="_blank" rel="noopener noreferrer">#NewsRecommendation</a>
<a class="button" href="articles/MLOps.html" target="_blank" rel="noopener noreferrer">#MLOps</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/A/B%20Testing.html" target="_blank" rel="noopener noreferrer">#A/B Testing</a>
<span class="issue_date">Issue Date: 2024-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1367" target="_blank" rel="noopener noreferrer" class="title-link">NewsPicksに推薦システムを本番投入する上で一番優先すべきだったこと, 2024.08</a>
<span class="snippet"><span>Comment</span><p>&gt;推薦モデルの良し悪しをより高い確度で評価できる実験を、より簡単に実行できる状態を作ることでした。平たく言えば「いかにA/Bテストしやすい推薦システムを設計するか」が最も重要だった訳です。<br><br>オフライン評価とオンライン評価の相関がない系の話で、A/Bテストを容易に実施できる環境になかった、かつCTRが実際に向上したモデルがオフライン評価での性能が現行モデルよりも悪く、意思決定がなかなかできなかった、という話。<br><br>うーんやはり、推薦におけるオフライン評価ってあまりあてにできないよね、、、<br>そもそも新たなモデルをデプロイした時点で、テストした時とデータの分布が変わるわけだし、、、<br><br>Off-Policy Evaluationの話は勉強したい。</p>
<p>あと、定性評価は重要</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1107" target="_blank" rel="noopener noreferrer" class="title-link">StableDiffusion, LLMのGPUメモリ削減のあれこれ</a>
<span class="snippet"><span>Comment</span><p>Gradient Accumulation, Gradient Checkpointingの説明が丁寧でわかりやすかった。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/618" target="_blank" rel="noopener noreferrer" class="title-link">OpenLLaMA</a>
<span class="snippet"><span>Comment</span><p>LLaMAと同様の手法を似たデータセットに適用し商用利用可能なLLaMAを構築した模様</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/528" target="_blank" rel="noopener noreferrer" class="title-link">LoRA論文解説, Hayato Tsukagoshi, 2023.04</a>
<span class="snippet"><span>Comment</span><p>ベースとなる事前学習モデルの一部の線形層の隣に、低ランク行列A,Bを導入し、A,Bのパラメータのみをfinetuningの対象とすることで、チューニングするパラメータ数を激減させた上で同等の予測性能を達成し、推論速度も変わらないようにするfinetuning手法の解説</p>
<p>LoRAを使うと、でかすぎるモデルだと、そもそもGPUに載らない問題や、ファインチューニング後のモデルファイルでかすぎワロタ問題が回避できる。<br><br>前者は事前学習済みモデルのBPのための勾配を保存しておく必要がなくなるため学習時にメモリ節約になる。後者はA,Bのパラメータだけ保存すればいいので、ストレージの節約になる。<br><br>かつ、学習速度が25%程度早くなる。</p>
<p>既存研究であるAdapter（transformerの中に学習可能なMLPを差し込む手法）は推論コストが増加し、prefix tuningは学習が非常に難しく、高い性能を達成するためにprefixとして128 token入れたりしなければならない。</p>
<p>huggingfaceがすでにLoRAを実装している<br>


<a href="https://github.com/huggingface/peft" target="_blank" rel="noopener noreferrer">https://github.com/huggingface/peft</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<span class="issue_date">Issue Date: 2023-01-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/507" target="_blank" rel="noopener noreferrer" class="title-link">tuning_playbook, Google Research</a>
<span class="snippet"><span>Comment</span><p>Googleが公開したDeep Learningモデル学習のノウハウ。必読</p>
<p>日本語訳<br>


<a href="https://github.com/Valkyrja3607/tuning_playbook_ja" target="_blank" rel="noopener noreferrer">https://github.com/Valkyrja3607/tuning_playbook_ja</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2022-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/497" target="_blank" rel="noopener noreferrer" class="title-link">BetterTransformer, Out of the Box Performance for Hugging Face Transformers</a>
<span class="snippet"><span>Comment</span><p>たった1ライン追加するだけで、Transformerのinferenceが最大で4.5倍高速化されるBetterTransformerの解説記事<br><br>better_model = BetterTransformer.transform(model)</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<span class="issue_date">Issue Date: 2022-10-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/489" target="_blank" rel="noopener noreferrer" class="title-link">CNN vs. ViT, 牛久先生</a>
<span class="snippet"><span>Comment</span><p>・Swin Transformer, Depth-wise conv, ConvNeXt, ViTとCNNのロバスト性の違いの話があり勉強になる<br><br>・最終的な結論が、CNNもTransformerも変わらない（明確な勝者はいない; 今のところ引き分け）というのはおもしろかった</p>
<p>depth-wise conv, point-wise convの解説記事：


<a href="https://agirobots.com/depthwise-pointwise-convolution/" target="_blank" rel="noopener noreferrer">https://agirobots.com/depthwise-pointwise-convolution/</a>


<br><br><br><br>通常のCNNのフィルタによるfeature map計算を、空間方向（depth-wise conv）とチャネル方向（point-wise conv; 1x1 conv）に分解することで大幅にパラメータ数削減</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<span class="issue_date">Issue Date: 2022-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/485" target="_blank" rel="noopener noreferrer" class="title-link">Transformerの最前線 〜 畳込みニューラルネットワークの先へ 〜, 牛久先生, 2022</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2022-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/473" target="_blank" rel="noopener noreferrer" class="title-link">The Power of Scale for Parameter-Efficient Prompt Tuning, Lester+, Google Research, EMNLP‘21</a>
<span class="snippet"><span>Comment</span><p>日本語解説: 


<a href="https://qiita.com/kts_plea/items/79ffbef685d362a7b6ce" target="_blank" rel="noopener noreferrer">https://qiita.com/kts_plea/items/79ffbef685d362a7b6ce</a>


<br><br>T5のような大規模言語モデルに対してfinetuningをかける際に、大規模言語モデルのパラメータは凍結し、promptをembeddingするパラメータを独立して学習する手法<br><br>言語モデルのパラメータ数が増加するにつれ、言語モデルそのものをfinetuningした場合（Model Tuning）と同等の性能を示した。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<span class="issue_date">Issue Date: 2022-07-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/459" target="_blank" rel="noopener noreferrer" class="title-link">独立な学習者・項目ネットワークをもつ Deep-IRT, 堤+, 電子情報通信学会論文誌, 2021</a>
<span class="snippet"><span>Comment</span><p>
<strong># モチベーション<br><br>Deep-IRTで推定される能力値は項目の特性に依存しており、同一スキル内の全ての項目が等質であると仮定しているため、異なる困難度を持つ項目からの能力推定値を求められない。このため、能力パラメータや困難度パラメータの解釈性は、従来のIRTと比較して制約がある。一方、木下らが提案したItem Deep Response Theoryでは、項目特性に依存せずに学習者の能力値を推定でき、推定値の信頼性と反応予測精度が高いことが示されているが、能力の時系列変化を考慮していないため、学習家庭での能力変化を表現できない。これらを解決するための手法を提案。<br><br><br><br># 手法<br><br>論文中の数式に次元数が一切書かれておらず、論文だけを読んで再現できる気がしない。<br><br>提案手法は、学習者の能力推定値が項目の特性に依存せず、複数のスキルに関する多次元の能力を表現できる（とあるが、が、どういう意味かよくわからない・・・）。<br><br>下図が提案手法の概要図。スキルタグ入力だけでなく、項目IDそのものも入力して活用するのが特徴。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/180723829-1b1e9311-975b-4b66-a872-f017862d0355.png" alt="image" loading="lazy"><br><br><br><br>基本的に、生徒の能力値を推定するstudent networkと、スキル/項目の難易度を推定するitem networkに分かれている。ある時刻tでの生徒の能力値はメモリM上の全てのhidden conceptに対するvalueを足し合わせ、足し合わせて得られたベクトルに対してMLPをかけることによって計算している。<br><br><img src="https://user-images.githubusercontent.com/12249301/180725744-fa286cd1-ad2c-4d1d-99b8-655ea9611d20.png" alt="image" loading="lazy"><br><br>最終的にitem response functionを見ると、ここで得られる生徒の能力値はスカラー値でなければならないと思うのだが、MLPをかけて得られたベクトルからどのように生徒の能力値を算出するかがジャーナル上では書かれていない。EDM'21の方を見ると、inputとなったスキルタグのembeddingとメモリのkeyとの関連度から求めたアテンションベクトルω_tとの内積でスカラーに変換しているようなので、おそらくそのような操作をしていると思われる。<br><br><br><br>item networkも同様に、スキルタグのembedding q_j と 項目のembedding s_j を別々にMLPにかけて、最終的に1次元に写像することで、スキル/項目の難易度パラメータを推論していると思われる。<br><br><img src="https://user-images.githubusercontent.com/12249301/180725805-1bcc08c4-1688-41ab-92bb-a4efb6bf2e3a.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/180725856-840c048b-d402-4539-98bc-a49577bffa49.png" alt="image" loading="lazy"><br><br><br><br>最終的に下記item response functionによって反応予測を行う。<br><br><img src="https://user-images.githubusercontent.com/12249301/180729156-b0d53d02-015d-47d1-be7d-efa7753a9722.png" alt="image" loading="lazy"><br><br>ただし、EDM'21の論文だと能力値パラメータθに3が乗じられているのに対し、こちらはそのような操作がされていない。どちらが正しいのか分からない。<br><br><br><br>また、メモリネットワークのmemory valueの更新は <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/352" target="_blank" rel="noopener noreferrer">Dynamic Key-Value Memory Networks for Knowledge Tracing, Yeung+, WWW'17</a>
</strong>
<br>
 と同じ方法である。<br><br><br><br>
<strong># 予測性能評価<br><br><img src="https://user-images.githubusercontent.com/12249301/180726002-7ef7301d-60b0-4fa4-85b6-9fba12a5d37b.png" alt="image" loading="lazy"><br><br><br><br>提案手法が全てのデータセットで平均すると最も良い予測性能を示している。IRTもKDDCupデータでは性能が良く、KDDCupデータは回答ログの正答率が非常に高くデータに偏りがあり、加えてデータのスパース率（10 人以下<br><br>の学習者が解答した項目の割合）も高いため（学習者の平均回答数が少ない）、DeepLearningベースドな手法は反応の偏りと少数データに脆弱である可能性を指摘している。<br><br><br><br>ちなみにEDM'21論文だと下記のような結果になっている：<br><br><img src="https://user-images.githubusercontent.com/12249301/180726762-d89872c3-c7fd-4a78-a63c-8a4346fb0b89.png" alt="image" loading="lazy"><br><br><br><br>こちらの結果を見ると、AKTよりも高い性能を示していることがわかる。AKTに勝つのは結構すごそうなのだが <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/456" target="_blank" rel="noopener noreferrer">Learning Process-consistent Knowledge Tracing, Shen+, SIGKDD'21</a>
</strong>
<br>
 でのAKTの性能に比べ、DKT等の手法に対するAKTの性能の伸びが小さいのが非常に気になる。何を信じたら良いのか分からない・・・。<br><br><br><br># 解釈性評価実験について<br><br>DeepIRTとのパラメータの能力パラメータ、困難度パラメータの解釈性の検証をしているようだが、所感に書いてある通りまずDeepIRTの能力値パラメータを正しく採用できているのかが怪しい。困難度パラメータについては、シミュレーションデータを用いて提案手法がDeepIRTと比べて真の困難度に対する相関が高いことを示しているが、詳細が書かれておらずよくわからない・・・。一応IRTと同等の解釈性能を持つと主張している。<br><br><br><br># 所感<br><br>解釈性の評価実験において下記の記述があるが、<br><br>&gt; しかし，彼ら によって公開された Deep-IRT のプログラムコードで は一次元の能力値推移しか出力できず，論文で示され た複数スキルに対応した結果を再現できない．このた め，本実験では，式 (7) で得られる θ (t,j) 3 を多次元で 出力した値を Deep-IRT における多次元のスキルの能 力値推移とする．<br><br><br><br>ここでどのような操作をしているのかがいまいち分からないが、時刻tのメモリM_tが与えられたとき、DeepIRTは入力ベクトルq_tに対応する一次元の能力値を返すモデルのはずで、q_tを測定したい能力のスキルタグに対するone-hot encodingにすれば能力値推移は再現できるのでは？「θ (t,j) 3を多次元で出力した値」というのは、1次元のスカラー値を出力するのではなく、多次元のベクトルとしてθ (t,j) 3を出力し、ベクトルの各要素をスキルに対する能力値とみなしているのだろうか。もしそういう操作をしているのだとしたらDeepIRTが出力する能力値パラメータとの比較になっていないと思う。<br><br><br><br>θ_n^(t, j)を学習者の能力値ベクトルとしてみなすと論文中に記述されているが、実際にどの次元がどのスキルの習熟度に対応しているかは人間が回答ログに対する習熟度の推移を観察して決定しなければならない。これは非常にダルい。<br><br>しかもθ_n^(t, j)の各次元の値は、スキルタグに対する習熟度ではなく、スキルタグの背後にあるhidden conceptの習熟度だと思う。論文では問題の正解/不正解に対して、習熟度が上下する様子から、能力値ベクトルの特定の次元の数値が特定のスキルの習熟度となっていることを解釈しているが、その解釈が正しい保証はないような・・・。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2021-11-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/430" target="_blank" rel="noopener noreferrer" class="title-link">Deep Residual Learning for Image Recognition, He+, Microsoft Research, CVPR’16</a>
<span class="snippet"><span>Comment</span><p>ResNet論文<br><br>ResNetでは、レイヤーの計算する関数を、残差F(x)と恒等関数xの和として定義する。これにより、レイヤーが入力との差分だけを学習すれば良くなり、モデルを深くしても最適化がしやすくなる効果ぎある。数レイヤーごとにResidual Connectionを導入し、恒等関数によるショートカットができるようにしている。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/140301726-1d2e89e1-1d69-43d9-8d2b-0adb272e577a.png" alt="image" loading="lazy"><br><br><br><br>ResNetが提案される以前、モデルを深くすれば表現力が上がるはずなのに、実際には精度が下がってしまうことから、理論上レイヤーが恒等関数となるように初期化すれば、深いモデルでも浅いモデルと同等の表現が獲得できる、と言う考え方を発展させた。<br><br><br><br>（ステートオブAIガイドに基づく）</p>
<p>同じパラメータ数でより層を深くできる（Plainな構造と比べると層が1つ増える）Bottleneckアーキテクチャも提案している。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/140302452-649b0ea7-cce4-44c1-9e7d-b509ef8bca52.png" alt="image" loading="lazy"><br><br></p>
<p>今や当たり前のように使われているResidual Connectionは、層の深いネットワークを学習するために必須の技術なのだと再認識。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/StudentPerformancePrediction.html" target="_blank" rel="noopener noreferrer">#StudentPerformancePrediction</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<a class="button" href="articles/L@S.html" target="_blank" rel="noopener noreferrer">#L@S</a>
<span class="issue_date">Issue Date: 2021-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/421" target="_blank" rel="noopener noreferrer" class="title-link">Addressing Two Problems in Deep Knowledge Tracing via Prediction-Consistent Regularization, Yeung+, 2018, L@S</a>
<span class="snippet"><span>Comment</span><p>Deep Knowledge Tracing (DKT)では、下記の問題がある：<br><br>- 該当スキルに正解/不正解 したのにmasteryが 下がる/上がる （Inputをreconstructしない）<br><br>- いきなり習熟度が伸びたり、下がったりする（時間軸に対してmastery levelがconsistentではない）<br><br>上記問題に対処するようなモデルDKT+を提案。<br><br><br><br>DKT+では、DKTのloss functionに対して3つのregularization termを追加することで上記問題に対処している。<br><br>DKT+はDKTの性能を落とすことなく、上記2問題を緩和できたとのこと。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/139360225-91645535-7a52-45d6-9caa-8d4fc8719a1e.png" alt="image" loading="lazy"><br><br></p>
<p>実装: 


<a href="https://github.com/ckyeungac/deep-knowledge-tracing-plus" target="_blank" rel="noopener noreferrer">https://github.com/ckyeungac/deep-knowledge-tracing-plus</a>


</p>
<p>&lt;img width="639" alt="image" src="


&lt;a href="https://user-images.githubusercontent.com/12249301/167774315-061e9d8d-16ae-4c56-b69f-e8ef1968b4fa.png"" target="_blank" rel="noopener noreferrer"&gt;https://user-images.githubusercontent.com/12249301/167774315-061e9d8d-16ae-4c56-b69f-e8ef1968b4fa.png"&lt;/a&gt;


&gt;<br><br><br><br>DKT+とDKTのheatmapを比較すると、問題点は確かに緩和されているかもしれないが、<br><br>依然としてinputはreconstructionされていないし、習熟度も乱高下しているように見える。<br><br>根本的な解決にはなっていないのでは。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2021-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/404" target="_blank" rel="noopener noreferrer" class="title-link">GPT-3から我々は何を学べば良いのか, 山本和英, Japio year book 2020</a>
<span class="snippet"><span>Comment</span><p>GPT-3の概要:<br><br>GPT-3はWebサイトから数年に渡って収集したCommon Crawlというデータセットから、570GBを抜粋し学習に利用。（英語ウィキペディアの約130倍）<br>ある単語列に後続する単語を予測するという方法（自己回帰型言語モデル）で教師なし学習を繰り返し、言語モデルを学習。</p>
<p>GPT-3の特徴:<br>・モデルが巨大（1750億パラメータ, GPT-2は15億）<br>　- 扱うトークン数が2048トークン（GPT-2の倍）<br>　- Word Embeddingの次元数12288（GPT2の倍<br>　- デコード層が98層（GPT2の倍<br>・基本的なモデル構造はTransformerと一緒<br><br>GPT-3の問題点:<br>・コーパス中の言語出力を模倣しているだけで、何ら理解をしておらず、常識も持ち合わせていない<br>　- e.g. 私の足に目はいくつある？と入力すると、2つと出力する等<br>　- 整理された知識を獲得しているわけではない<br>・偏見や差別、誤った知識も学習する<br>・時間的、経済的負荷の大きさ<br>　- GPT-3を最大規模で計算するには5億円かかる<br>　- 1台のGPUで355年必要な計算量<br>　→ 個人や小規模業者が実行できる範囲を超えており、大企業でもコストに見合った出力が得られるとは考えにくい</p>
<p>GPT-3の産業応用<br>・GPT-3は言語モデルであり、言語生成器ではない<br>　- 人間が書いて欲しいことをおおまかに伝えたらそれを書いてくれるわけではない（代筆）<br>　→ GPT-3が小論文や業務レポートを書けると考えるのは早計<br>　- 入力として英文や英単語を入力するが、生成する文章の分野や話題を提示しただけであり、生成する文章にそれ以上の制御は行っていない<br><br>・生成内容を強く制御できないことは創作活動にとっては有用<br>　- 俳句、短歌、詩の生成<br>　- キャッチコピーの自動生成<br>　- ダミー文章生成（ブログやツイート）<br>　- 文章添削、校正に使える可能性（要研究;文章を正しく、綺麗に書く能力は高い）</p>
<p>GPT-3でどこまでできそうなのか？というざっくりとした肌感が掴めたから良かった</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2021-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/389" target="_blank" rel="noopener noreferrer" class="title-link">Pre-Trained Models: Past, Present and Future, Han+, AI Open‘21</a>
<span class="snippet"><span>Summary</span>- 大規模な事前学習モデル（PTMs）は、AI分野での成功を収め、知識を効果的に捉えることができる。特に、転移学習や自己教師あり学習との関係を考察し、PTMsの重要性を明らかにする。最新のブレークスルーは、計算能力の向上やデータの利用可能性により、アーキテクチャ設計や計算効率の向上に寄与している。未解決問題や研究方向についても議論し、PTMsの将来の研究の進展を期待する。</span>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2021-06-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/387" target="_blank" rel="noopener noreferrer" class="title-link">pytorch_lightning tips</a>
<span class="snippet"><span>Comment</span><p>PyTorch Lightning 2021 (for MLコンペ)<br>


<a href="https://qiita.com/fam_taro/items/df8656a6c3b277f58781" target="_blank" rel="noopener noreferrer">https://qiita.com/fam_taro/items/df8656a6c3b277f58781</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2021-06-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/384" target="_blank" rel="noopener noreferrer" class="title-link">FastSeq: Make Sequence Generation Faster, Yan+, ACL’21</a>
<span class="snippet"><span>Comment</span><p>BART, DistilBART, T5, GPT2等のさまざまなTransformer-basedな手法で、4-9倍Inference speedを向上させる手法を提案。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2021-06-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/382" target="_blank" rel="noopener noreferrer" class="title-link">A survey of Transformers, Lin+, AI Open‘22</a>
<span class="snippet"><span>Summary</span>- トランスフォーマーの多様なバリアント（X-formers）に関する体系的な文献レビューを提供。バニラトランスフォーマーの紹介後、新しい分類法を提案し、アーキテクチャの修正、事前学習、アプリケーションの観点からX-formersを紹介。今後の研究の方向性も概説。</span>
<span class="snippet"><span>Comment</span><p>Transformersの様々な分野での亜種をまとめた論文</p>
<p><img src="https://user-images.githubusercontent.com/12249301/121394765-a40f4280-c98c-11eb-8fac-0114715ec738.png" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<span class="issue_date">Issue Date: 2021-06-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/377" target="_blank" rel="noopener noreferrer" class="title-link">TRTorch</a>
<span class="snippet"><span>Comment</span><p>pytorchの推論を高速化できるライブラリ。6倍ほど早くなった模様。TorchScriptを介して変換するので、PythonだけでなくC++でも動作できるらしい。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2021-06-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/375" target="_blank" rel="noopener noreferrer" class="title-link">Probing Word Translations in the Transformer and Trading Decoder for Encoder Layers, NAACL‘21</a>
<span class="snippet"><span>Comment</span><p>Transformerに基づいたNMTにおいて、Encoderが入力を解釈し、Decoderが翻訳をしている、という通説を否定し、エンコーディング段階、さらにはinput embeddingの段階でそもそも翻訳が始まっていることを指摘。<br>エンコーディングの段階ですでに翻訳が始まっているのであれば、エンコーダの層を増やして、デコーダの層を減らせば、デコーディング速度を上げられる。<br>通常はエンコーダ、デコーダともに6層だが、10-2層にしたらBLEUスコアは変わらずデコーディングスピードは2.3倍になった。<br>18-4層の構成にしたら、BLEUスコアも1.42ポイント増加しデコーディング速度は1.4倍になった。</p>
<p>この研究は個人的に非常に興味深く、既存の常識を疑い、分析によりそれを明らかにし、シンプルな改善で性能向上およびデコーディング速度も向上しており、とても好き。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2021-06-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/372" target="_blank" rel="noopener noreferrer" class="title-link">Incorporating Copying Mechanism in Sequence-to-Sequence Learning, Gu+, ACL’16</a>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/371" target="_blank" rel="noopener noreferrer">Pointing the Unknown Words, Gulcehre+, ACL’16</a>
 と同様コピーメカニズムを提案した論文。Joint Copy ModelやCOPYNETと呼ばれる。<br><br>次の単語が "生成" されるのか "コピー" されるのかをスコアリングし、各単語がコピーされる確率と生成される確率をMixtureした同時確率分布で表現する（ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/207" target="_blank" rel="noopener noreferrer">Challenges in Data-to-Document Generation, Wiseman+ (with Rush), EMNLP'17</a>
 等でも説明されている）。<br><br>コピーメカニズムを導入せるなら引用すべき。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120571719-ad148700-c455-11eb-8e93-8d9be799aad5.png" alt="image" loading="lazy"><br><br><br><br>## コピーメカニズム部分の説明<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120571852-efd65f00-c455-11eb-9063-872103738e2f.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120571874-fa90f400-c455-11eb-885f-5b1a08d7d528.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120572859-a6870f00-c457-11eb-9744-e1ff5ab5d253.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/120572917-bd2d6600-c457-11eb-8c76-5bb48988a5f9.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/120572936-c585a100-c457-11eb-822b-e70f0e857ac9.png" alt="image" loading="lazy"><br><br></p>
<p>解説資料: 


<a href="http://www.lr.pi.titech.ac.jp/~sasano/acl2016suzukake/slides/08.pdf" target="_blank" rel="noopener noreferrer">http://www.lr.pi.titech.ac.jp/~sasano/acl2016suzukake/slides/08.pdf</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2021-06-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/371" target="_blank" rel="noopener noreferrer" class="title-link">Pointing the Unknown Words, Gulcehre+, ACL’16</a>
<span class="snippet"><span>Comment</span><p>Conditional Copy Model （Pointer Softmax）を提案した論文。<br>単語を生成する際に、語彙内の単語から生成する分布、原文の単語から生成する分布を求める。後者はattention distributionから。コピーするか否かを決める確率変数を導入し（sigmoid）、両生成確率を重み付けする。<br>コピーメカニズム入れるなら引用すべき。</p>
<p>解説スライド:


<a href="https://www.slideshare.net/hytae/pointing-the-unknown-words" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/hytae/pointing-the-unknown-words</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<span class="issue_date">Issue Date: 2021-06-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/368" target="_blank" rel="noopener noreferrer" class="title-link">Deep Knowledge Tracingの拡張による擬似知識タグの生成, 中川+, 人口知能学会論文誌, 33巻, 33号, C, 2018</a>
<span class="snippet"><span>Comment</span><p>DKTモデルは、前提として各問題に対して知識タグ（knowledge component）が付与されていることが前提となっている。しかし世の中には、知識タグが振られているデータばかりではないし、そもそもプログラミング教育といった伝統的な教育ではない分野については、そもそも知識タグを構造的に付与すること自体が成熟していない分野も存在する。<br><br>そのような知識タグが存在しない、付与しづらい分野に対してもDKTが適用できるように、知識タグそのものを自動的に学習した上で、Knowledge Tracingするモデルを提案しました、という話。<br><br><br><br>Deep Knowledge Tracingの入力ベクトルの日本語例が書いてあり、わかりやすい。<br><br><img src="https://user-images.githubusercontent.com/12249301/120430839-96692400-c3b2-11eb-84d0-93c88de8f866.png" alt="image" loading="lazy"><br><br><br><br>提案モデルの構造は下記<br><br><img src="https://user-images.githubusercontent.com/12249301/120430874-a123b900-c3b2-11eb-8280-07a049e443a2.png" alt="image" loading="lazy"><br><br><br><br>ASSISTments, KDD Cup Dataでの既存タグを利用した場合と、擬似生成タグを利用した場合の評価結果<br><br><img src="https://user-images.githubusercontent.com/12249301/120431050-e811ae80-c3b2-11eb-8895-eced2e918dd6.png" alt="image" loading="lazy"><br><br><br><br>既存タグを利用した場合とcomparable, もしくはoutperformしている。<br><br><br><br>既存タグと擬似生成タグタグの依存関係を可視化したネットワーク<br><br><img src="https://user-images.githubusercontent.com/12249301/120431103-fe1f6f00-c3b2-11eb-95a8-0595d70d3d61.png" alt="image" loading="lazy"><br><br><br><br>既存タグと擬似生成タグの内容的関係性<br><br><img src="https://user-images.githubusercontent.com/12249301/120431428-70904f00-c3b3-11eb-9f07-de34b917ab0f.png" alt="image" loading="lazy"><br><br><br><br>既存タグは人間が理解しやすい形で構成されているが、擬似生成タグは予測に最適化されているためそのような生成のされ方はされない。つまり、解釈性に問題がある。<br><br>Knowledge Tracingモデルは教育の観点から、生徒がどのconceptにどれだけ習熟しているか、といったことを教員側が把握し適切なinterventionを行なったり、あるいは生徒側が内省を行い自信をmotivatingしたりする側面があるため、どのようにして解釈性の高いタグを自動生成するか、はunsolved question。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/SentimentAnalysis.html" target="_blank" rel="noopener noreferrer">#SentimentAnalysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<span class="issue_date">Issue Date: 2021-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/365" target="_blank" rel="noopener noreferrer" class="title-link">Sentiment analysis with deeply learned distributed representations of variable length texts, Hong+, Technical Report. Technical report, Stanford University, 2015</a>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/363" target="_blank" rel="noopener noreferrer">DKN: Deep Knowledge-Aware Network for News Recommendation, Wang+, WWW'18</a>
 より、本論文を引用して「CNN ベースのモデルが、畳み込み演算により文から特定のローカルパターンを検出して抽出できるため、他のモデル（e.g. Recurrent Neural Network, Recursive Neural Network）よりも優れていることが経験的に示されている」とのこと</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/StudentPerformancePrediction.html" target="_blank" rel="noopener noreferrer">#StudentPerformancePrediction</a>
<span class="issue_date">Issue Date: 2021-05-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/357" target="_blank" rel="noopener noreferrer" class="title-link">Behavior-Based Grade Prediction for MOOCs Via Time Series Neural Networks, Chiang+, IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING, VOL. 11, NO. 5, AUGUST 2017</a>
<span class="snippet"><span>Comment</span><p>MOOCsでの生徒のgradeを予測するモデルを提案。MOOCsでは生徒のassessmentに対するreponseがsparseで、かつpersonalizedなモデルが必要なため成績予測はチャレンジングなタスク。<br><br>lecture-video-watching clickstreams を利用し、time-series neural network （tステップのデータをMLPに入力するもの？あまりしっかり読んでいない）を使って、prioer performanceとclickstreamでtrainingすることでこれらを克服する。<br><br>2種類のMOOCsデータセットで評価したところ、past performanceの平均を利用するbaselineに対しては60%程度、lasso regression baselineよりも15%程度outperformした。<br><br><br><br>全体像<br><br><img src="https://user-images.githubusercontent.com/12249301/120054835-5f6ed780-c06d-11eb-9996-8b8cab2cd21c.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120054856-7a414c00-c06d-11eb-8bd1-d1bdb81639fd.png" alt="image" loading="lazy"><br><br><br><br>一般的なMOOCsでのvideo-lestureのsequence図解<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120054873-8f1ddf80-c06d-11eb-908e-2a3e926b856f.png" alt="image" loading="lazy"><br><br><br><br>生徒のj回のquizに回答したあとのaverage Correct First Attempt (CFA)を生徒の成績と定義し、RMSEで評価をしている模様？<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120055079-c476fd00-c06e-11eb-8d91-ffbe42ed1bda.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/120055102-e2dcf880-c06e-11eb-81fc-ddd3e69cf80d.png" alt="image" loading="lazy"><br><br><br><br>上図のように、クイズに回答する毎のaverage CFAの変遷（=y）と、クイズjが含まれる生徒のvideo tにおけるclickstream input features（=x）を利用し、次のクイズに回答した時のaverage CFAを予測している？<br><br></p>
<p>NFMB/NI <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/358" target="_blank" rel="noopener noreferrer">Back to the basics: Bayesian extensions of IRT outperform neural networks for proficiency estimation, Ekanadham+, EDM'16</a>
 データセットを利用している </p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/StudentPerformancePrediction.html" target="_blank" rel="noopener noreferrer">#StudentPerformancePrediction</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<span class="issue_date">Issue Date: 2021-05-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/353" target="_blank" rel="noopener noreferrer" class="title-link">EKT: Exercise-aware Knowledge Tracing for Student Performance Prediction, Hu+, IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING, 2019</a>
<span class="snippet"><span>Comment</span><p>DKT等のDeepなモデルでは、これまで問題テキストの情報等は利用されてこなかったが、learning logのみならず、問題テキストの情報等もKTする際に活用した研究。<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/354" target="_blank" rel="noopener noreferrer">Exercise-Enhanced Sequential Modeling for Student Performance Prediction, Hu+, AAAI'18</a>
  をより洗練させjournal化させたものだと思われる。<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/354" target="_blank" rel="noopener noreferrer">Exercise-Enhanced Sequential Modeling for Student Performance Prediction, Hu+, AAAI'18</a>
  ではKTというより、問題の正誤を予測するモデルとなっており、個々のconceptに対するproficiencyを推定するというKTの考え方はあまり導入されていなかった。<br><br>EKTの方では、個々のknowledge componentのproficiency scoreを算出する方法も提案されている。</p>
<p>モデル自体は、基本的にはattention-basedなRNNモデル。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/119990204-05d1c300-c003-11eb-817f-2d23708cd7e5.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/119990252-12eeb200-c003-11eb-9edd-d1cd7dba713f.png" alt="image" loading="lazy"><br><br></p>
<p>Exercise EmbeddingはBidireictional-RNNを利用して、問題文をエンコードすることによって求める。<br><br><img src="https://user-images.githubusercontent.com/12249301/120432013-42f7d580-c3b4-11eb-9fd4-17e81a5bfb70.png" alt="image" loading="lazy"><br><br></p>
<p>EKTによるmastery levelを可視化したもの。T=0とT=30では各conceptに対するmastery levelが大きく異なっている。基本的に、たくさん正解したconceptはmastery levelが向上し、不正解しまくったconceptはどんどんmastery levelがshrinkしていく。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120432208-8c482500-c3b4-11eb-8486-6ddbab8f7249.png" alt="image" loading="lazy"><br><br></p>
<p>予測性能。問題のContentを考慮することで、正誤予測のAUCは圧倒的に高くなる。DKTよりも10ポイント程度EKTAの方がAUCが高いように見える。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120433254-f7462b80-c3b5-11eb-802f-88ee102633e6.png" alt="image" loading="lazy"><br><br><br><br>各モデルの特徴や、knowledge tracingが行えるか否か、といった性質を整理した表。わかりやすい。しかしDKTのknowledge tracking?が×になっているのは誤りでは？<br><br><img src="https://user-images.githubusercontent.com/12249301/120433307-075e0b00-c3b6-11eb-8af3-432ca9d41d51.png" alt="image" loading="lazy"><br><br></p>
<p>各knowledge conceptの時刻tにおけるmastery levelの求め方。<br><br><br><br>EKTでは、生徒の各knowledge conceptの状態を保持した行列H_t^i（0 &lt;= i &lt;= # of concepts）を保持している。correctness probabilityを最終的に求める際には、H_t^iの各knowledge conceptに対する重みβ_iで重みづけた上でsummationをとり、各知識の状態を統合したベクトルsを作成し、sとexercise embedding xをconcatした上でスコアを予測する。<br><br><br><br>このスコアの予測部分を変更し、β_iをmastery levelを測定したいconceptのone-hot encodingに置き換え、さらにexercise embeddingをmaskしたベクトル=masked exercise embedding = zero vectorをconcatした上で、スコアを予測するようにする。<br><br><img src="https://user-images.githubusercontent.com/12249301/120436895-78072680-c3ba-11eb-8694-ff0926f639b7.png" alt="image" loading="lazy"><br><br><br><br>こうすることで、exerciseの影響を除き、かつone-hot encodingで指定したknowledgeのmasteryのみが考慮されたスコアを抽出できるため、そのスコアをmastery levelとする。</p>
<p>単にStudent Performance Predictionして終わり！ってんじゃなく、knowledge tracing的な側面をきちんと考慮している点で、この研究めっちゃ好き。</p>
<p>スキルタグごとにLSTMのhidden_stateを保持しないといけないので、メモリの消費量がえぐいことになりそう。小規模なスキルタグのデータセットじゃないと動かないのでは？<br><br>実際、実験では37種類のスキルタグが存在するデータセットしか扱っていない。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/FactorizationMachines.html" target="_blank" rel="noopener noreferrer">#FactorizationMachines</a>
<a class="button" href="articles/CTRPrediction.html" target="_blank" rel="noopener noreferrer">#CTRPrediction</a>
<a class="button" href="articles/IJCAI.html" target="_blank" rel="noopener noreferrer">#IJCAI</a>
<span class="issue_date">Issue Date: 2021-05-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/349" target="_blank" rel="noopener noreferrer" class="title-link">DeepFM: A Factorization-Machine based Neural Network for CTR Prediction, Guo+, IJCAI’17</a>
<span class="snippet"><span>Comment</span><p>Factorization Machinesと、Deep Neural Networkを、Wide&amp;Deepしました、という論文。Wide=Factorization Machines, Deep=DNN。<br><br>高次のFeatureと低次のFeatureを扱っているだけでなく、FMによってフィールドごとのvector-wiseな交互作用、DNNではbit-wiseな交互作用を利用している。<br>割と色々なデータでうまくいきそうな手法に見える。<br><br>発展版としてxDeepFM <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/348" target="_blank" rel="noopener noreferrer">xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems, Lian+, KDD‘18</a>
 がある。</p>
<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/281" target="_blank" rel="noopener noreferrer">Factorization Machines, Steffen Rendle, ICDM'10</a>
 にも書いたが、下記リンクに概要が記載されている。<br><br>DeepFMに関する動向：


<a href="https://data.gunosy.io/entry/deep-factorization-machines-2018" target="_blank" rel="noopener noreferrer">https://data.gunosy.io/entry/deep-factorization-machines-2018</a>


</p>
<p>実装: 


<a href="https://github.com/rixwew/pytorch-fm" target="_blank" rel="noopener noreferrer">https://github.com/rixwew/pytorch-fm</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/FactorizationMachines.html" target="_blank" rel="noopener noreferrer">#FactorizationMachines</a>
<a class="button" href="articles/CTRPrediction.html" target="_blank" rel="noopener noreferrer">#CTRPrediction</a>
<a class="button" href="articles/SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<span class="issue_date">Issue Date: 2021-05-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/348" target="_blank" rel="noopener noreferrer" class="title-link">xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems, Lian+, KDD‘18</a>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/349" target="_blank" rel="noopener noreferrer">DeepFM: A Factorization-Machine based Neural Network for CTR Prediction, Guo+, IJCAI’17</a>
 DeepFMの発展版</p>
<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/281" target="_blank" rel="noopener noreferrer">Factorization Machines, Steffen Rendle, ICDM'10</a>
 にも書いたが、下記リンクに概要が記載されている。<br><br>DeepFMに関する動向：


<a href="https://data.gunosy.io/entry/deep-factorization-machines-2018" target="_blank" rel="noopener noreferrer">https://data.gunosy.io/entry/deep-factorization-machines-2018</a>


<br><br><br><br>DeepFMの発展についても詳細に述べられていて、とても参考になる。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/CIKM.html" target="_blank" rel="noopener noreferrer">#CIKM</a>
<a class="button" href="articles/SequentialRecommendation.html" target="_blank" rel="noopener noreferrer">#SequentialRecommendation</a>
<span class="issue_date">Issue Date: 2021-05-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/347" target="_blank" rel="noopener noreferrer" class="title-link">BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer, Sun+, CIKM2019</a>
<span class="snippet"><span>Comment</span><p>BERTをrecsysのsequential recommendationタスクに転用してSoTA。<br>しっかり読んで無いけどモデル構造はほぼBERTと一緒。<br>異なる点は、Training時にNext Sentence Predictionは行わずClozeのみ行なっているという点。Clozeとは、実質Masked Language Modelであり、sequenceの一部を[mask]に置き換え、置き換えられたアイテムを左右のコンテキストから予測するタスク。異なる点としては、sequential recommendationタスクでは、次のアイテムを予測したいので、マスクするアイテムの中に、sequenceの最後のアイテムをマスクして予測する事例も混ぜた点。<br><br>もう一個異なる点として、BERT4Recはend-to-endなモデルで、BERTはpretraining modelだ、みたいなこと言ってるけど、まあ確かに形式的にはそういう違いはあるけど、なんかその違いを主張するのは違和感を覚える…。<br>sequential recommendationで使うuser behaviorデータでNext item predictionで学習したいことが、MLMと単に一致していただけ、なのでは…。</p>
<p>BERT4Recのモデル構造。next item predictionしたいsessionの末尾に [mask] をconcatし、[MASK]部分のアイテムを予測する構造っぽい？<br><br><img src="https://user-images.githubusercontent.com/12249301/138901870-d36fc935-8b61-4434-9d4b-dc1cb968c91e.png" alt="image" loading="lazy"><br><br></p>
<p>オリジナルはtensorflow実装<br><br>pytorchの実装はこちら：


<a href="https://github.com/jaywonchung/BERT4Rec-VAE-Pytorch/tree/master/models" target="_blank" rel="noopener noreferrer">https://github.com/jaywonchung/BERT4Rec-VAE-Pytorch/tree/master/models</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/ImageClassification.html" target="_blank" rel="noopener noreferrer">#ImageClassification</a>
<span class="issue_date">Issue Date: 2021-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/346" target="_blank" rel="noopener noreferrer" class="title-link">EfficientNet解説, omiita （オミータ）, 2019</a>
<span class="snippet"><span>Comment</span><p>既存画像認識モデルの構造は変化させず、広さ、深さ、解像度を複合スケーリングすることで、従来よりも少ないパラメータ数、かつ学習速度でSoTAを達成。広さ、深さ、解像度はそれぞれ性能に互いに影響しあっており、従来のように別々にスケーリングするのではなく、3つのバランスをとりながらスケーリングする。スケーリングする際は、結果的にはそれぞれをある値で定数倍すれば良く、そのある値は最大メモリや最大FLOPS数以下（およびFLOPSが2のΦ乗で増加するような）といった制約下でAccuracyが最大化される値をグリッドサーチで見つける（らしい。ざっくりとした理解）。<br>転移学習しても多くのタスクでSoTA達成した。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2021-05-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/344" target="_blank" rel="noopener noreferrer" class="title-link">MLP-like Architecture</a>
<span class="snippet"><span>Comment</span><p>gMLP:大規模なself-attentionが無いSpatial Gating Unitを搭載したシンプルなMLPでも、Transformerの性能に近づけたよ（特にCV）。つまり、self-attentionはessentialというわけではなさそうだよ。<br><br>NLPの場合はgMLPだとTransformerとperplexityでcomparable、一部downstreamタスクだと勝てなかったけど、single headのtiny attentionを追加したら、TransformerをperplexityとGLUEの一部タスクでoutperformしたよ。<br>つまり、Transformerみたいに大規模なself-attentionは必須ではなく、小規模のattentionで（cross sentenceの関係性を捉えるには）十分だよ。<br>スケーラビリティもTransformerを上回ったよ。<br><br>って感じ？<br><br>んーTransformerに勝ったみたいな言い方をSNSだと見かけるけど、評価してるタスクが少ないし、どちらかというとcomparableなdownstreamタスクが多いし、それは言い過ぎでは？<br>この論文が言いたいのは、大規模なself-attentionが性能を出す上でessentialなわけではないよ、ってことであり、<br><br>・CVの場合はself-attentionは必須ではない<br>・NLPでは、tiny attentionでも十分<br><br>という感じなのでは。<br></p>
<p>まあでもTransformerとcomparableなら、Transformer一強では無くなったよね</p>
<p>Spatial Gating Unit（SGU）は、トークン間の関係性を捉えるためのゲートで、SGUが無いとgMLPブロックはただの二層のFFNとなる。<br><br>SGUは、入力をspatial dimensionに対して線形変換した値と、元の入力のelement-wiseな積で表現する。この線形変換をする際は、Wの値を0の近傍で初期化し、バイアス項を1に初期化することがクリティカルだった。これは、学習の初めでは線形変換はidentical mappingに近いものとなるため、gMLPブロックはFFNに近いものとなる。これが学習が進むにつれWの重みが調整され、cross tokenの関係性を捉えたブロックへと徐々に変化していくことになる。<br>また、SGUへの入力はGLUのようにchannel dimensionに二分割し、片方をelement-wise積に、もう一方をspatialな線形変換に利用する（4種類試した中で一番性能が良かった）。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2020-03-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/334" target="_blank" rel="noopener noreferrer" class="title-link">BERT 日本語Pre-trained Model, NICT, 2020</a>
<span class="snippet"><span>Comment</span><p>NICTが公開。既に公開されているBERTモデルとのベンチマークデータでの性能比較も行なっており、その他の公開済みBERTモデルをoutperformしている。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2019-11-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/329" target="_blank" rel="noopener noreferrer" class="title-link">事前学習言語モデルの動向 _ Survey of Pretrained Language Models, Kyosuke Nishida, 2019</a>
<span class="snippet"><span>Comment</span><p>[2019/06まで]<br><br>・ELMo（双方向2層LSTM言語モデル）<br><br>・GPT（left-to-rightの12層Transformer自己回帰言語モデル）<br><br>・BERT（24層のTransformer双方向言語モデル）<br><br>・MT-DNN（BERTの上にマルチタスク層を追加した研究）<br><br>・XLM（パラレル翻訳コーパスを用いてクロスリンガルに穴埋めを学習）<br><br>・TransformerXL（系列長いに制限のあった既存モデルにセグメントレベルの再帰を導入し長い系列を扱えるように）<br><br>・GPT-2（48層Transformerの自己回帰言語モデル）<br><br>・ERNIE 1.0（Baidu, エンティティとフレーズの外部知識を使ってマスクに利用）<br><br>・ERNIE（Tsinghua, 知識グラフの情報をfusionしたLM）<br><br>・Glover（ドメイン、日付、著者などを条件とした生成を可能としたGPT）<br><br>・MASS（Encoder-Decoder型の生成モデルのための事前学習）<br><br>・UniLM（Sequence-to-Sequenceを可能にした言語モデル）<br><br>・XLNet（自己回帰（単方向）モデルと双方向モデルの両方の利点を得ることを目指す）<br><br><br><br>[2019/07~]<br><br>・SpanBERT（i.i.dではなく範囲でマスクし、同時に範囲の境界も予測する）<br><br>・ERNIE 2.0（Baidu, マルチタスク事前学習; 単語レベル・構造レベル・意味レベル）<br><br>・RoBERTa（BERTと同じ構造で工夫を加えることで性能向上）<br><br>　- より大きなバッチサイズを使う（256から8192）<br><br>　- より多くのデータを使う（16GBから160GB）<br><br>　- より長いステップ数の学習をする（BERT換算で16倍）<br><br>　- 次文予測（NSP）は不要<br><br>　→ GLUEでBERT, XLNetをoutperform<br><br>・StructBERT (ALICE, NSPに代わる学習の目的関数を工夫)<br><br>　- マスクした上で単語の順番をシャッフルし元に戻す<br><br>　- ランダム・正順・逆順の3種類を分類<br><br>　→ BERTと同サイズ、同データでBERT, RoBERTa超え<br><br>・DistilBERT（蒸留により、12層BERTを6層に小型化（40%減））<br><br>　- BERTの出力を教師として、生徒が同じ出力を出すように学習<br><br>　- 幅（隠れ層）サイズを減らすと、層数を経あｒスよりも悪化<br><br>　→ 推論は60%高速化、精度は95%程度を保持<br><br>・Q8BERT（精度を落とさずにfine-tuning時にBERTを8bit整数に量子化）<br><br>　- Embedding, FCは8bit化、softmax, LNorm, GELUは32bitをキープ<br><br>　→ モデルサイズ1/4, 速度3.7倍<br><br>・CTRL（条件付き言語モデル）<br><br>　- 条件となる制御テキストを本文の前に与えて学習<br><br>　- 48層/1280次元Transformer（パラメータ数1.6B）<br><br>・MegatronLM（72層、隠れ状態サイズ3072、長さ1024; BERTの24倍サイズ）<br><br>・ALBERT（BERTの層のパラメータをすべて共有することで学習を高速化; 2020年あたりのデファクト）<br><br>　- Largeを超えたモデルは学習が難しいため、表現は落ちるが学習しやすくした<br><br>　- 単語埋め込みを低次元にすることでパラメータ数削減<br><br>　- 次文予測を、文の順序入れ替え判定に変更<br><br>　→ GLUE, RACE, SQuADでSoTAを更新<br><br>・T5（NLPタスクをすべてtext-to-textとして扱い、Enc-Dec Transformerを745GBコーパスで事前学習して転移する）<br><br>　- モデルはEncoder-DecoderのTransformer<br><br>　- 学習タスクをエンコーダ・デコーダに合わせて変更<br><br>　- エンコーダ側で範囲を欠落させて、デコーダ側で予測<br><br>　→ GLUE, SuperGLUE, SQuAD1.1, CNN/DMでSoTA更新<br><br>・BART（Seq2Seqの事前学習として、トークンマスク・削除、範囲マスク、文の入れ替え、文書の回転の複数タスクで学習）<br><br>　→ CNN/DMでT5超え、WMT'16 RO-ENで逆翻訳を超えてSoTA</p>
<p>ELMo, GPT, BERT, GPT-2, XLNet, RoBERTa, DistilBERT, ALBERT, T5あたりは良く見るような感</p>
<p>各データセットでの各モデルの性能も後半に記載されており興味深い。<br><br><br><br>ちなみに、CNN/DailyMail Datasetでは、T5, BARTあたりがSoTA。<br><br>R2で比較すると<br><br>　- Pointer-Generator + Coverage Vectorが17,28<br><br>　- LEAD-3が17.62<br><br>　- BARTが21.28<br><br>　- T5が21.55<br><br>となっている</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<span class="issue_date">Issue Date: 2019-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/325" target="_blank" rel="noopener noreferrer" class="title-link">【黒橋研】BERT日本語Pretrainedモデル</a>
<span class="snippet"><span>Comment</span><p>【huggingface transformersで使える日本語モデルのまとめ】<br><br>


<a href="https://tech.yellowback.net/posts/transformers-japanese-models" target="_blank" rel="noopener noreferrer">https://tech.yellowback.net/posts/transformers-japanese-models</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<span class="issue_date">Issue Date: 2019-05-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/310" target="_blank" rel="noopener noreferrer" class="title-link">Representation Learning on Graphs: Methods and Applications, Hamilton+, 2017</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2018-11-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/280" target="_blank" rel="noopener noreferrer" class="title-link">AllenNLP</a>
<span class="snippet"><span>Comment</span><p>


<a href="https://docs.google.com/presentation/d/17NoJY2SnC2UMbVegaRCWA7Oca7UCZ3vHnMqBV4SUayc/preview?slide=id.g43b8d8e880_0_8" target="_blank" rel="noopener noreferrer">https://docs.google.com/presentation/d/17NoJY2SnC2UMbVegaRCWA7Oca7UCZ3vHnMqBV4SUayc/preview?slide=id.g43b8d8e880_0_8</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2018-06-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/274" target="_blank" rel="noopener noreferrer" class="title-link">Pytorchによるtransformer実装チュートリアル</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2018-02-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/263" target="_blank" rel="noopener noreferrer" class="title-link">ニューラルネット勉強会（LSTM編）, Seitaro Shinagawa, 2016</a>
<span class="snippet"><span>Comment</span><p>LSTMの基礎から、実装する上でのTipsがまとまっている。<br><br>zero padding, dropoutのかけかた、normalizationの手法など。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/235" target="_blank" rel="noopener noreferrer" class="title-link">自然言語処理のためのDeep Learning, Yuta Kikuchi</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/MatrixFactorization.html" target="_blank" rel="noopener noreferrer">#MatrixFactorization</a>
<a class="button" href="articles/SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<a class="button" href="articles/Selected%20Papers/Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/221" target="_blank" rel="noopener noreferrer" class="title-link">Collaborative Deep Learning for Recommender Systems Wang+, KDD’15</a>
<span class="snippet"><span>Comment</span><p>Rating Matrixからuserとitemのlatent vectorを学習する際に、Stacked Denoising Auto Encoder（SDAE）によるitemのembeddingを活用する話。<br><br>Collaborative FilteringとContents-based Filteringのハイブリッド手法。<br><br>Collaborative FilteringにおいてDeepなモデルを活用する初期の研究。<br><br><br><br>通常はuser vectorとitem vectorの内積の値が対応するratingを再現できるように目的関数が設計されるが、そこにitem vectorとSDAEによるitemのEmbeddingが近くなるような項（3項目）、SDAEのエラー（4項目）を追加する。<br><br><br><br>（3項目の意義について、解説ブログより）アイテム i に関する潜在表現 vi は学習データに登場するものについては推定できるけれど，未知のものについては推定できない．そこでSDAEの中間層の結果を「推定したvi」として「真の」 vi にできる限り近づける，というのがこの項の気持ち<br><br><br><br>cite-ulikeデータによる論文推薦、Netflixデータによる映画推薦で評価した結果、ベースライン（Collective Matrix Factorization <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/222" target="_blank" rel="noopener noreferrer">Relational learning via collective matrix factorization, Singh+, KDD'08</a>
 , SVDFeature <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/223" target="_blank" rel="noopener noreferrer"> SVDFeature: a toolkit for feature-based collaborative filtering, Chen+, JMLR'12</a>
 , DeepMusic <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/224" target="_blank" rel="noopener noreferrer">Deep content-based music recommendation, Oord+, NIPS'13</a>
 , Collaborative Topic Regresison <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/226" target="_blank" rel="noopener noreferrer">Collaborative topic modeling for recommending scientific articles, Wang+, KDD'11</a>
 ）をoutperform。<br><br><br>（下記は管理人が過去に作成した論文メモスライドのスクショ）<br><br><img src="https://user-images.githubusercontent.com/12249301/34813194-58142a60-f6ec-11e7-938e-34b7d0cfb930.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34813227-786b9640-f6ec-11e7-8713-940433dc9e8f.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34813243-87832d28-f6ec-11e7-8371-fa60a54a1ba6.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34813251-91d5896a-f6ec-11e7-94ec-3b2c225ddf9a.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34813259-9b18b5e2-f6ec-11e7-98ae-1b5323b3e8b3.png" alt="image" loading="lazy"><br><br></p>
<p>解説ブログ：


<a href="http://d.hatena.ne.jp/repose/20150531/1433004688" target="_blank" rel="noopener noreferrer">http://d.hatena.ne.jp/repose/20150531/1433004688</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/TimeSeriesDataProcessing.html" target="_blank" rel="noopener noreferrer">#TimeSeriesDataProcessing</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/115" target="_blank" rel="noopener noreferrer" class="title-link">Artificial neural networks in business: Two decades of research, Tkac+, Applied Soft Computing 2016</a>
<span class="snippet"><span>Comment</span><p>ビジネスドメイン(e.g. Stock market price prediction)におけるニューラルネットワークの活用事例をまとめたSurvey。<br><br>時系列データの取り扱いなどの参考になるかも。</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/88" target="_blank" rel="noopener noreferrer" class="title-link">What to talk about and how? Selective Generation using LSTMs with Coarse-to-Fine Alignment, Mei+, NAACL-HLT’16</a>
<span class="snippet"><span>Comment</span><p>content-selectionとsurface realizationをencoder-decoder alignerを用いて同時に解いたという話。<br><br>普通のAttention basedなモデルにRefinerとPre-Selectorと呼ばれる機構を追加。通常のattentionにはattentionをかける際のaccuracyに問題があるが、data2textではきちんと参照すべきレコードを参照し生成するのが大事なので、RefinerとPre-Selectorでそれを改善する。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34460874-1b5830a2-ee5f-11e7-9220-c67a806225d8.png" alt="image" loading="lazy"><br><br><br><br>Pre-selectorは、それぞれのレコードが選択される確率を推定する（通常のattentionはalignmentの尤度を計算するのみ）。<br><br>Refinerはaligner(attention)のweightをreweightingすることで、最終的にどのレコードを選択するか決定する。<br><br>加えて、ロス関数のRegularizationのかけかたを変え、最低一つのレコードがpreselectorに選ばれるようにバイアスをかけている。<br><br><br><br>ほぼ初期のNeural Network basedなData2Text研究</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/81" target="_blank" rel="noopener noreferrer" class="title-link">Efficient Methods and Hardware for Deep Learning, Han, Stanford University, 2017</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/77" target="_blank" rel="noopener noreferrer" class="title-link">Teaching Machines to Read and Comprehend, Hermann+, NIPS 2015</a>
<span class="snippet"><span>Comment</span><p>だいぶ前に読んだので割とうろおぼえ。<br><br><br><br>CNN/DailyMailデータセットの作成を行なった論文（最近Neuralな文”書”要約の学習でよく使われるやつ）。<br><br>CNN/DailyMailにはニュース記事に対して、人手で作成した要約が付与されており、要約中のEntityを穴埋めにするなどして、穴埋め問題を作成。<br><br>言文書をNeuralなモデルに与えて、どれだけ回答できるかという話。<br><br><br><br>[スタンフォードによる追試がある](


<a href="https://cs.stanford.edu/people/danqi/papers/acl2016.pdf)" target="_blank" rel="noopener noreferrer">https://cs.stanford.edu/people/danqi/papers/acl2016.pdf)</a>


<br><br>[詳しい解説 by 久保さん](


<a href="https://www.slideshare.net/takahirokubo7792/machine-comprehension)" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/takahirokubo7792/machine-comprehension)</a>


<br><br><br><br>追試によると、評価で使用している穴埋め問題は単純なモデルで提案モデルの性能を上回ったりしている。また、この穴埋め問題のうち54%は単純な質問とのマッチで回答可能であり、25%は人でも正解不能らしい（正解率のupper boundは75%）。by 久保さんのスライド<br><br>のちの研究で、ほぼこの上限に達する精度が達成されてしまったので、このデータセットはQAタスクではほぼ攻略された状態だという。</p></span><br><br>
<button onclick="hideContent(0)" style="display: none;">hide</button>
&lt;/div&gt;
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<script>
  document.addEventListener('DOMContentLoaded', function() {
    const tweets = document.querySelectorAll('.tweet-embed[data-embed]');

    if ('IntersectionObserver' in window) {
      const observer = new IntersectionObserver((entries, obs) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            const el = entry.target;
            const html = el.getAttribute('data-embed');
            if (html) {
              const loadingImg = el.querySelector('.tweet-loading');
              if (loadingImg) loadingImg.remove();

              el.innerHTML = html.trim();

              if (window.twttr?.widgets?.load) {
                window.twttr.widgets.load(el);
              }
            }
            obs.unobserve(el); // 処理済みは監視解除
          }
        });
      }, {
        rootMargin: '500px 0px', // 画面手前200pxで読み込み開始
        threshold: 0
      });

      tweets.forEach(tweet => observer.observe(tweet));

    } else {
      // IntersectionObserver未対応ブラウザ用のフォールバック
      function lazyLoadFallback() {
        tweets.forEach(el => {
          if (el.getAttribute('data-embed') && el.getBoundingClientRect().top < window.innerHeight) {
            const html = el.getAttribute('data-embed');
            const loadingImg = el.querySelector('.tweet-loading');
            if (loadingImg) loadingImg.remove();
            el.innerHTML = html.trim();
            el.removeAttribute('data-embed');
            if (window.twttr?.widgets?.load) {
              window.twttr.widgets.load(el);
            }
          }
        });
      }
      window.addEventListener('scroll', lazyLoadFallback);
      lazyLoadFallback();
    }
  });
</script>
</number></entity></strong></p></span></strong></p></span></strong></p></span>
</div>


    </div>

</article>
<div class="post-nav">
<a class="previous" href="/paper_notes/articles/NeuralArchitectureSearch.html" title="NeuralArchitectureSearchに関する論文・技術記事メモの一覧">NeuralArchitectureSearchに関する論文・技術記事メモの一覧</a><a class="next" href="/paper_notes/articles/NewsRecommendation.html" title="NewsRecommendationに関する論文・技術記事メモの一覧">NewsRecommendationに関する論文・技術記事メモの一覧</a>
</div>
<div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li class="">
          <a class="post-link" href="/paper_notes/articles/interactive.html" title="interactiveに関する論文・技術記事メモの一覧">
            interactiveに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/AutomaticSpeechRecognition(ASR).html" title="AutomaticSpeechRecognition(ASR)に関する論文・技術記事メモの一覧">
            AutomaticSpeechRecognition(ASR)に関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/VariationalAutoEncoder.html" title="VariationalAutoEncoderに関する論文・技術記事メモの一覧">
            VariationalAutoEncoderに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/GPU-Platform.html" title="GPU-Platformに関する論文・技術記事メモの一覧">
            GPU-Platformに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
</ul>
    </div>
<div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">TOC</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent =  menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3, h4, h5, h6");

    // Hide menu when no headings
    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // Generate post menu
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#h-' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }

    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';

    // The header element
    var header = document.querySelector('header.site-header');

    function doMenuCollapse(index, over_items) {
      var items = menuContent.firstChild.children;

      if (over_items == undefined) {
        over_items = 20;
      }

      if (items.length < over_items) {
        return;
      }

      var activeItem = items[index];
      var beginItem = activeItem
      var endItem = activeItem
      var beginIndex = index;
      var endIndex = index + 1;
      while (beginIndex >= 0
        && !items[beginIndex].classList.contains('h-h2')) {
        beginIndex -= 1;
      }
      while (endIndex < items.length
        && !items[endIndex].classList.contains('h-h2')) {
        endIndex += 1;
      }
      for (var i = 0; i < beginIndex; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
      for (var i = beginIndex + 1; i < endIndex; i++) {
        item = items[i]
        // if (!item.classList.contains('h-h2')) {
          item.style.display = '';
        // }
      }
      for (var i = endIndex; i < items.length; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
    }

    // Init menu collapsed
    doMenuCollapse(-1);

    // Active the menu item
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header.getBoundingClientRect();
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var headerHeight = headerTop + headerHeight + 20;
        if (headingRect.top <= headerHeight) {
          var id = 'h-' + h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          if (curActive) {
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }
      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
        doMenuCollapse(activeIndex);
      }
      event.preventDefault();
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/paper_notes/"></data>

  <div class="wrapper">
    <div class="site-footer-inner">
<div>Copyright © 2023-current AkihikoWATANABE. The header images and any thumbnail images for the posts were generated by ChatGPT's DALL-E3.</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="https://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div class="footer-col rss-subscribe">Subscribe <a href="/paper_notes/feed.xml">via RSS</a>
</div>
    </div>
  </div>
</footer>
</body>
  </html>
