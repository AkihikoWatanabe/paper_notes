<!DOCTYPE html>
<html lang="ja">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c">
  <link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="preconnect" href="https://www.googletagmanager.com" crossorigin>
  <link rel="preconnect" href="https://www.google-analytics.com" crossorigin>
  <link rel="preconnect" href="https://platform.twitter.com">
  <link rel="preconnect" href="https://pbs.twimg.com">
  <link rel="dns-prefetch" href="https://cdnjs.cloudflare.com">
  <link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
  <link rel="dns-prefetch" href="https://platform.twitter.com">
  <link rel="dns-prefetch" href="https://pbs.twimg.com">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>CTRPredictionに関する論文・技術記事メモの一覧 | わたしのべんきょうノート</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="CTRPredictionに関する論文・技術記事メモの一覧">
<meta name="author" content="AkihikoWATANABE">
<meta property="og:locale" content="ja">
<meta name="description" content="CTRPrediction ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation, Jianghao Lin+, WWW'24 Paper/Blog Link My Issue #RecommenderSystems #NLP #UserModeling #LanguageModel #RAG(RetrievalAugmentedGeneration) #LongSequence #WWW Issue Date: 2025-03-27 GPT Summary- 本論文では、ゼロショットおよび少ショットの推薦タスクにおいて、大規模言語モデル（LLMs）を強化する新しいフレームワーク「ReLLa」を提案。LLMsが長いユーザー行動シーケンスから情報を抽出できない問題に対処し、セマンティックユーザー行動検索（SUBR）を用いてデータ品質を向上させる。少ショット設定では、検索強化指示チューニング（ReiT）を設計し、混合トレーニングデータセットを使用。実験により、少ショットReLLaが従来のCTRモデルを上回る性能を示した。 Comment- RALLRec+: Retrieval Augmented Large Language Model Recommendation with Reasoning, Sichun Luo+, arXiv'25 のベースラインLLMでCTR予測する際の性能を向上した研究。そもそもLLMでCTR予測をする際は、ユーザのデモグラ情報とアクティビティログなどのユーザプロファイルと、ターゲットアイテムの情報でpromptingし、yes/noを出力させる。yes/noトークンのスコアに対して2次元のソフトマックスを適用して[0, 1]のスコアを得ることで、CTR予測をする。![image](https://github.com/user-attachments/assets/75025947-f3bb-49d0-a8f1-e05c429183a4この研究ではコンテキストにユーザのログを入れても性能がスケールしない問題に対処するために![image](https://github.com/user-attachments/assets/69c27a84-0456-4ddf-aded-515608e27065直近のアクティビティログではなく、ターゲットアイテムと意味的に類似したアイテムに関するログをコンテキストに入れ（SUBR）、zero shotのinferenceに活用する。![image](https://github.com/user-attachments/assets/a5a2a300-ddca-42cc-97d7-251487ccfa3afew-shot recommendation（少量のクリックスルーログを用いてLLMをSFTすることでCTR予測する手法）においては、上述の意味的に類似したアイテムをdata augmentationに利用し（i.e, promptに埋め込むアクティビティログの量を増やして）学習する。![image](https://github.com/user-attachments/assets/b98af740-0628-4e98-a80f-30ff105621e1zeroshotにおいて、SUBRで性能改善。fewshot recommendationにといて、10%未満のデータで既存の全データを用いる手法を上回る。また、下のグラフを見るとpromptに利用するアクティビティログの量が増えるほど性能が向上するようになった。![image](https://github.com/user-attachments/assets/1297153e-bd6c-4548-a7e0-798eadee80e9ただし、latencyは100倍以上なのでユースケースが限定される。![image](https://github.com/user-attachments/assets/89555964-f5c4-4735-bc0d-9a5a1b7f0278 Collaborative Contrastive Network for Click-Through Rate Prediction, Chen Gao+, arXiv'24 Paper/Blog Link My Issue #RecommenderSystems #NeuralNetwork #ContrastiveLearning Issue Date: 2024-11-19 GPT Summary- EコマースプラットフォームにおけるCTR予測の課題を解決するために、「コラボレーティブコントラストネットワーク（CCN）」を提案。CCNは、ユーザーの興味と不興を示すアイテムクラスターを特定し、トリガーアイテムへの依存を減少させる。オンラインA/Bテストにより、タオバオでCTRを12.3%、注文量を12.7%向上させる成果を達成。 Comment参考: [Mini-appの定義生成結果（Hallucinationに注意）](">
<meta property="og:description" content="CTRPrediction ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation, Jianghao Lin+, WWW'24 Paper/Blog Link My Issue #RecommenderSystems #NLP #UserModeling #LanguageModel #RAG(RetrievalAugmentedGeneration) #LongSequence #WWW Issue Date: 2025-03-27 GPT Summary- 本論文では、ゼロショットおよび少ショットの推薦タスクにおいて、大規模言語モデル（LLMs）を強化する新しいフレームワーク「ReLLa」を提案。LLMsが長いユーザー行動シーケンスから情報を抽出できない問題に対処し、セマンティックユーザー行動検索（SUBR）を用いてデータ品質を向上させる。少ショット設定では、検索強化指示チューニング（ReiT）を設計し、混合トレーニングデータセットを使用。実験により、少ショットReLLaが従来のCTRモデルを上回る性能を示した。 Comment- RALLRec+: Retrieval Augmented Large Language Model Recommendation with Reasoning, Sichun Luo+, arXiv'25 のベースラインLLMでCTR予測する際の性能を向上した研究。そもそもLLMでCTR予測をする際は、ユーザのデモグラ情報とアクティビティログなどのユーザプロファイルと、ターゲットアイテムの情報でpromptingし、yes/noを出力させる。yes/noトークンのスコアに対して2次元のソフトマックスを適用して[0, 1]のスコアを得ることで、CTR予測をする。![image](https://github.com/user-attachments/assets/75025947-f3bb-49d0-a8f1-e05c429183a4この研究ではコンテキストにユーザのログを入れても性能がスケールしない問題に対処するために![image](https://github.com/user-attachments/assets/69c27a84-0456-4ddf-aded-515608e27065直近のアクティビティログではなく、ターゲットアイテムと意味的に類似したアイテムに関するログをコンテキストに入れ（SUBR）、zero shotのinferenceに活用する。![image](https://github.com/user-attachments/assets/a5a2a300-ddca-42cc-97d7-251487ccfa3afew-shot recommendation（少量のクリックスルーログを用いてLLMをSFTすることでCTR予測する手法）においては、上述の意味的に類似したアイテムをdata augmentationに利用し（i.e, promptに埋め込むアクティビティログの量を増やして）学習する。![image](https://github.com/user-attachments/assets/b98af740-0628-4e98-a80f-30ff105621e1zeroshotにおいて、SUBRで性能改善。fewshot recommendationにといて、10%未満のデータで既存の全データを用いる手法を上回る。また、下のグラフを見るとpromptに利用するアクティビティログの量が増えるほど性能が向上するようになった。![image](https://github.com/user-attachments/assets/1297153e-bd6c-4548-a7e0-798eadee80e9ただし、latencyは100倍以上なのでユースケースが限定される。![image](https://github.com/user-attachments/assets/89555964-f5c4-4735-bc0d-9a5a1b7f0278 Collaborative Contrastive Network for Click-Through Rate Prediction, Chen Gao+, arXiv'24 Paper/Blog Link My Issue #RecommenderSystems #NeuralNetwork #ContrastiveLearning Issue Date: 2024-11-19 GPT Summary- EコマースプラットフォームにおけるCTR予測の課題を解決するために、「コラボレーティブコントラストネットワーク（CCN）」を提案。CCNは、ユーザーの興味と不興を示すアイテムクラスターを特定し、トリガーアイテムへの依存を減少させる。オンラインA/Bテストにより、タオバオでCTRを12.3%、注文量を12.7%向上させる成果を達成。 Comment参考: [Mini-appの定義生成結果（Hallucinationに注意）](">
<link rel="canonical" href="http://akihikowatanabe.github.io/paper_notes/articles/CTRPrediction/">
<meta property="og:url" content="http://akihikowatanabe.github.io/paper_notes/articles/CTRPrediction/">
<meta property="og:site_name" content="わたしのべんきょうノート">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2025-08-27T00:00:00+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="CTRPredictionに関する論文・技術記事メモの一覧">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"AkihikoWATANABE"},"dateModified":"2025-08-27T00:00:00+00:00","datePublished":"2025-08-27T00:00:00+00:00","description":"CTRPrediction ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation, Jianghao Lin+, WWW&#39;24 Paper/Blog Link My Issue #RecommenderSystems #NLP #UserModeling #LanguageModel #RAG(RetrievalAugmentedGeneration) #LongSequence #WWW Issue Date: 2025-03-27 GPT Summary- 本論文では、ゼロショットおよび少ショットの推薦タスクにおいて、大規模言語モデル（LLMs）を強化する新しいフレームワーク「ReLLa」を提案。LLMsが長いユーザー行動シーケンスから情報を抽出できない問題に対処し、セマンティックユーザー行動検索（SUBR）を用いてデータ品質を向上させる。少ショット設定では、検索強化指示チューニング（ReiT）を設計し、混合トレーニングデータセットを使用。実験により、少ショットReLLaが従来のCTRモデルを上回る性能を示した。 Comment- RALLRec+: Retrieval Augmented Large Language Model Recommendation with Reasoning, Sichun Luo+, arXiv&#39;25 のベースラインLLMでCTR予測する際の性能を向上した研究。そもそもLLMでCTR予測をする際は、ユーザのデモグラ情報とアクティビティログなどのユーザプロファイルと、ターゲットアイテムの情報でpromptingし、yes/noを出力させる。yes/noトークンのスコアに対して2次元のソフトマックスを適用して[0, 1]のスコアを得ることで、CTR予測をする。![image](https://github.com/user-attachments/assets/75025947-f3bb-49d0-a8f1-e05c429183a4この研究ではコンテキストにユーザのログを入れても性能がスケールしない問題に対処するために![image](https://github.com/user-attachments/assets/69c27a84-0456-4ddf-aded-515608e27065直近のアクティビティログではなく、ターゲットアイテムと意味的に類似したアイテムに関するログをコンテキストに入れ（SUBR）、zero shotのinferenceに活用する。![image](https://github.com/user-attachments/assets/a5a2a300-ddca-42cc-97d7-251487ccfa3afew-shot recommendation（少量のクリックスルーログを用いてLLMをSFTすることでCTR予測する手法）においては、上述の意味的に類似したアイテムをdata augmentationに利用し（i.e, promptに埋め込むアクティビティログの量を増やして）学習する。![image](https://github.com/user-attachments/assets/b98af740-0628-4e98-a80f-30ff105621e1zeroshotにおいて、SUBRで性能改善。fewshot recommendationにといて、10%未満のデータで既存の全データを用いる手法を上回る。また、下のグラフを見るとpromptに利用するアクティビティログの量が増えるほど性能が向上するようになった。![image](https://github.com/user-attachments/assets/1297153e-bd6c-4548-a7e0-798eadee80e9ただし、latencyは100倍以上なのでユースケースが限定される。![image](https://github.com/user-attachments/assets/89555964-f5c4-4735-bc0d-9a5a1b7f0278 Collaborative Contrastive Network for Click-Through Rate Prediction, Chen Gao+, arXiv&#39;24 Paper/Blog Link My Issue #RecommenderSystems #NeuralNetwork #ContrastiveLearning Issue Date: 2024-11-19 GPT Summary- EコマースプラットフォームにおけるCTR予測の課題を解決するために、「コラボレーティブコントラストネットワーク（CCN）」を提案。CCNは、ユーザーの興味と不興を示すアイテムクラスターを特定し、トリガーアイテムへの依存を減少させる。オンラインA/Bテストにより、タオバオでCTRを12.3%、注文量を12.7%向上させる成果を達成。 Comment参考: [Mini-appの定義生成結果（Hallucinationに注意）](","headline":"CTRPredictionに関する論文・技術記事メモの一覧","mainEntityOfPage":{"@type":"WebPage","@id":"http://akihikowatanabe.github.io/paper_notes/articles/CTRPrediction/"},"url":"http://akihikowatanabe.github.io/paper_notes/articles/CTRPrediction/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="icon" href="">
  <link rel="canonical" href="http://akihikowatanabe.github.io">

  <link rel="preload" href="/paper_notes/assets/css/main.css" as="style">
  <link rel="preload" href="/paper_notes/assets/js/main.js" as="script">

  <link rel="stylesheet" href="/paper_notes/assets/css/main.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/custom_button.css">
  
  <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"></noscript>
  <link rel="preload" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css" as="style" onload="this. onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css"></noscript>
  
  <script src="/paper_notes/assets/js/main.js"></script><link type="application/atom+xml" rel="alternate" href="http://akihikowatanabe.github.io/paper_notes/feed.xml" title="わたしのべんきょうノート">
<script>
  function showMore(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "block";
          
      // このボタンの参照を取得して非表示にします
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "none";
      }
          
      // hideボタンの参照を取得して表示します
      const hideButton = contentDiv.querySelector('button[onclick^="hideContent"]');
      if (hideButton) {
        hideButton.style.display = "block";
      }
    }
  }

  function hideContent(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "none";
  
      // moreボタンの参照を取得して表示します
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "block";
      }
  
      // このボタンを隠します
      const hideButtons = document.querySelectorAll('button[onclick^="hideContent"]');
      const hideButton = hideButtons[index];
      if (hideButton) {
        hideButton.style.display = "none";
      }
    }
  }
</script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js" async></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe-lightbox.umd.min.js" async></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe.umd.min.js" async></script>
<link href="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/photoswipe.min.css" rel="stylesheet">
<style>
  .pswp .pswp__container .pswp__img {
    background-color: white;
  }
</style>

<script>
  function initPhotoSwipe() {
    let customOptions = {};

    try {
      const data = `{"gallery"=>"section.main", "children"=>"a.photo-swipe", "bgOpacity"=>0.8, "padding"=>{"top"=>20, "bottom"=>40, "left"=>100, "right"=>100}}`.replaceAll("=>", ":");
      customOptions = JSON.parse(data);
    } catch (e) {
      console.info("Invalid custom photo previewer options! " + e.message);
    }

    // Define object and gallery options
    const options = Object.assign(
      {
        gallery: "section.main",
        children: "a.photo-swipe",
        photo_scale: 2,
        // dynamic import is not supported in UMD version
        pswpModule: PhotoSwipe,
      },
      customOptions
    );

    const galleryEl = document.querySelector(options.gallery);
    if (!galleryEl) {
      return;
    }

    const imgEls = [];
    const els = galleryEl.querySelectorAll("img:not(.emoji)");
    els.forEach((el) => {
      if (el.src.trim() == "") {
        return;
      }
      if (!imgEls.includes(el)) {
        imgEls.push(el);
      }
    });

    if (imgEls.length === 0) {
      return;
    }

    imgEls.forEach((imgEl) => {
      imgEl.outerHTML = `
      <a class="photo-swipe"
        href="${imgEl.src}"
        data-pswp-width="${
          Math.max(imgEl.naturalWidth, imgEl.width) * options.photo_scale
        }"
        data-pswp-height="${
          Math.max(imgEl.naturalHeight, imgEl.height) * options.photo_scale
        }"
        data-pswp-caption="${imgEl.getAttribute("caption") || imgEl.alt}"
        target="_blank">
        ${imgEl.outerHTML}
      </a>`;
    });

    // Initialize PhotoSwipe 5
    var lightbox = new PhotoSwipeLightbox(options);

    lightbox.init();
  }

  window.addEventListener("load", initPhotoSwipe);
</script>
<meta name="google-site-verification" content="u_DTTPcCZ806iq51zgirHyWq3556HUKGq8AQfH91iFI">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-P70KSB88WH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-P70KSB88WH');
  </script>

</head>


<body>





































































































































<header class="site-header site-header-transparent" role="banner">

  <div class="wrapper">
    <div class="site-header-inner">
<span class="site-brand"><a class="site-brand-inner" rel="author" href="/paper_notes/">
  <img class="site-favicon" title="わたしのべんきょうノート" src="" onerror="this.style.display='none'">
  わたしのべんきょうノート
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger">
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewbox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
              </svg>
            </span>
          </label>

          <div class="trigger">
<a class="page-link" href="/paper_notes/">論文や技術メモの一覧（随時更新）</a><a class="page-link" href="/paper_notes/archives.html">ARCHIVES</a>









<span class="page-link">



<div id="google_translate_element" style="display: none;">
</div>

<span class="ct-language">
  <ul class="list-unstyled ct-language-dropdown">
    
      <li>
        <a href="#" class="lang-select" data-lang="en">
          
          <img src="https://cdn.countryflags.com/thumbs/united-states-of-america/flag-400.png" title="English">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="fr">
          
          <img src="https://cdn.countryflags.com/thumbs/france/flag-400.png" title="French">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="zh-CN">
          
          <img src="https://cdn.countryflags.com/thumbs/china/flag-400.png" title="Chinese(Simple)">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ja">
          
          <img src="https://cdn.countryflags.com/thumbs/japan/flag-400.png" title="Japanese">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ko">
          
          <img src="https://cdn.countryflags.com/thumbs/south-korea/flag-400.png" title="Korean">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ru">
          
          <img src="https://cdn.countryflags.com/thumbs/russia/flag-400.png" title="Russian">
          
        </a>
      </li>
    
  </ul>
</span>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'ja',
    autoDisplay: false,
    layout: google.translate.TranslateElement.InlineLayout.VERTICAL
  }, 'google_translate_element');

  // Links to cross-origin destinations are unsafe
  var gll = document.getElementsByClassName('goog-logo-link')[0];
  if (gll) {
    gll.setAttribute('rel', 'noopener');
  }

  function restoreLang() {
    var iframe = document.getElementsByClassName('goog-te-banner-frame')[0];
    if (!iframe) return;

    var innerDoc = iframe.contentDocument || iframe.contentWindow.document;
    var restore_el = innerDoc.getElementsByTagName("button");

    for (var i = 0; i < restore_el.length; i++) {
      if (restore_el[i].id.indexOf("restore") >= 0) {
        restore_el[i].click();
        var close_el = innerDoc.getElementsByClassName("goog-close-link");
        close_el[0].click();
        return;
      }
    }
  }

  function triggerHtmlEvent(element, eventName) {
    var event;
    if (document.createEvent) {
      event = document.createEvent('HTMLEvents');
      event.initEvent(eventName, true, true);
      element.dispatchEvent(event);
    } else {
      event = document.createEventObject();
      event.eventType = eventName;
      element.fireEvent('on' + event.eventType, event);
    }
  }

  var googleCombo = document.querySelector("select.goog-te-combo");
  var langSelect = document.querySelector('.ct-language');
  langSelect.addEventListener('click', function(event) {
    if (!event.target) {
      return;
    }

    var selected = document.querySelector('.ct-language .ct-language-selected');
    if (selected) {
      selected.classList.remove('ct-language-selected');
    }

    var target = event.target;
    while (target && target !== langSelect ) {
      if (target.matches('.lang-select')) {
        break;
      }
      target = target.parentElement;
    }

    if (target && target.matches('.lang-select')) {
      var lang = target.getAttribute('data-lang');
      if (googleCombo.value == lang) {
        restoreLang();
      } else {
        target.parentElement.classList.add('ct-language-selected');
        googleCombo.value = lang;
        triggerHtmlEvent(googleCombo, 'change');
      }
    }

    event.preventDefault();
  });
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit" async></script>
</span>
</div>
        </nav>
</div>
  </div>
</header>

<script>
  function initHeader() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;
    var ticking = false;

    function storeScrollData() {
      var y = getScrollPos().y;documentElement.setAttribute("data-header-transparent", "");var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0);
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
      
      // 処理完了フラグをリセット
      ticking = false;
    }

    function requestTick() {
      if (!ticking) {
        // 次の描画フレームで実行をスケジュール
        window.requestAnimationFrame(storeScrollData);
        ticking = true;
      }
    }

    // passive:  true でスクロールパフォーマンスを向上
    window.addEventListener('scroll', requestTick, { passive: true });

    // 初期実行
    storeScrollData();
  }
  
  document.addEventListener('DOMContentLoaded', initHeader);
</script>


























































































































































<style>
    html .page-banner .page-banner-img > *:first-child {
      opacity: 0.4;
    }

    html[data-theme="dark"] .page-banner .page-banner-img > *:first-child {
      opacity: 0.2872;
    }
  </style>
<section class="page-banner">
    <div class="page-banner-img">
<div style="background-image: url(/paper_notes/assets/images/banner.webp)"></div>
        <img class="img-placeholder" src="/paper_notes/assets/images/banner.webp">
</div>
    <div class="wrapper">
      <div class="page-banner-inner">
<header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">わたしのべんきょうノート</h1>
  <h2 class="post-subtitle">勉強した論文や技術等の情報をGithubのIssueにメモっているひとのブログ。
それなりにメモの量が蓄積されてきたので、一度整理したいなと思いブログはじめてみました！
自然言語処理(NLP), 推薦システム(RecommenderSystem), Educational Data Mining (EDM), Learning Analytics (LA)などの分野のメモが多いと思います。
最近は特にLLMの勉強が多めです :)</h2>

  <div class="post-meta">
    <time class="dt-published" datetime="2025-08-27T00:00:00+00:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Aug 27, 2025
    </time><span class="post-author left-vsplit"><i class="fa fa-pencil"></i> AkihikoWATANABE</span>
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 46 mins</span>
  </div></header>
</div>
    </div>
  </section><script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    hashValue = decodeURIComponent(hashValue);
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('off' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<div id="click-to-top" class="click-to-top">
  <i class="fa fa-arrow-up"></i>
</div>
<script>
  (function () {
    const clickToTop = document.getElementById('click-to-top');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 100) {
        clickToTop.classList.add('show')
      }else {
        clickToTop.classList.remove('show')
      }
    });
    clickToTop.addEventListener('click', () => {
      window.smoothScrollTo(0);
    });
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <h2 id="CTRPrediction" class="paper-head"> CTRPrediction</h2>
<div class="visible-content">
<article class="paper-entry">
<h3 id="rella-retrieval-enhanced-1840" class="title-link">ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential   Behavior Comprehension in Recommendation, Jianghao Lin+, WWW'24</h3>
<br><a href="https://arxiv.org/pdf/2308.11131" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1840" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="UserModeling.html" target="_blank" rel="noopener noreferrer">#UserModeling</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2025-03-27</span>
<span class="snippet"><span>GPT Summary</span>- 本論文では、ゼロショットおよび少ショットの推薦タスクにおいて、大規模言語モデル（LLMs）を強化する新しいフレームワーク「ReLLa」を提案。LLMsが長いユーザー行動シーケンスから情報を抽出できない問題に対処し、セマンティックユーザー行動検索（SUBR）を用いてデータ品質を向上させる。少ショット設定では、検索強化指示チューニング（ReiT）を設計し、混合トレーニングデータセットを使用。実験により、少ショットReLLaが従来のCTRモデルを上回る性能を示した。</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1839" target="_blank" rel="noopener noreferrer">RALLRec+: Retrieval Augmented Large Language Model Recommendation with
  Reasoning, Sichun Luo+, arXiv'25</a>
<br><br>のベースライン</p>
<p>LLMでCTR予測する際の性能を向上した研究。<br><br>そもそもLLMでCTR予測をする際は、ユーザのデモグラ情報とアクティビティログなどのユーザプロファイルと、ターゲットアイテムの情報でpromptingし、yes/noを出力させる。yes/noトークンのスコアに対して2次元のソフトマックスを適用して[0, 1]のスコアを得ることで、CTR予測をする。<br>![image](https://github.com/user-attachments/assets/75025947-f3bb-49d0-a8f1-e05c429183a4<br><br>この研究ではコンテキストにユーザのログを入れても性能がスケールしない問題に対処するために<br>![image](https://github.com/user-attachments/assets/69c27a84-0456-4ddf-aded-515608e27065<br><br>直近のアクティビティログではなく、ターゲットアイテムと意味的に類似したアイテムに関するログをコンテキストに入れ（SUBR）、zero shotのinferenceに活用する。<br>![image](https://github.com/user-attachments/assets/a5a2a300-ddca-42cc-97d7-251487ccfa3a<br><br>few-shot recommendation（少量のクリックスルーログを用いてLLMをSFTすることでCTR予測する手法）においては、上述の意味的に類似したアイテムをdata augmentationに利用し（i.e, promptに埋め込むアクティビティログの量を増やして）学習する。<br>![image](https://github.com/user-attachments/assets/b98af740-0628-4e98-a80f-30ff105621e1<br><br>zeroshotにおいて、SUBRで性能改善。fewshot recommendationにといて、10%未満のデータで既存の全データを用いる手法を上回る。また、下のグラフを見るとpromptに利用するアクティビティログの量が増えるほど性能が向上するようになった。<br>![image](https://github.com/user-attachments/assets/1297153e-bd6c-4548-a7e0-798eadee80e9<br><br>ただし、latencyは100倍以上なのでユースケースが限定される。<br>![image](https://github.com/user-attachments/assets/89555964-f5c4-4735-bc0d-9a5a1b7f0278</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="collaborative-contrastive-1531" class="title-link">Collaborative Contrastive Network for Click-Through Rate Prediction, Chen Gao+, arXiv'24</h3>
<br><a href="https://arxiv.org/abs/2411.11508" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1531" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<span class="issue_date">Issue Date: 2024-11-19</span>
<span class="snippet"><span>GPT Summary</span>- EコマースプラットフォームにおけるCTR予測の課題を解決するために、「コラボレーティブコントラストネットワーク（CCN）」を提案。CCNは、ユーザーの興味と不興を示すアイテムクラスターを特定し、トリガーアイテムへの依存を減少させる。オンラインA/Bテストにより、タオバオでCTRを12.3%、注文量を12.7%向上させる成果を達成。</span>
<span class="snippet"><span>Comment</span><p>参考: [Mini-appの定義生成結果（Hallucinationに注意）](


<a href="https://www.perplexity.ai/search/what-is-the-definition-of-the-sW4uZPZIQe6Iq53HbwuG7Q)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/search/what-is-the-definition-of-the-sW4uZPZIQe6Iq53HbwuG7Q)</a>


<br><br>論文中の図解: Mini-appにトリガーとなるアイテムを提示するTrigger-Induced-Recommendation（TIR）<br><img src="https://github.com/user-attachments/assets/eb209dc4-b8bc-4632-89df-137031e509f0&lt;/p&gt;&lt;p&gt;##%20%E6%A6%82%E8%A6%81&lt;br&gt;&lt;br&gt;%E5%9B%B33%E3%81%AB%E7%A4%BA%E3%81%95%E3%82%8C%E3%81%A6%E3%81%84%E3%82%8B%E3%82%88%E3%81%86%E3%81%AA%20Collaborative%20Contrastive%20Network%20(CCN" alt="image" loading="lazy" width="550" height="400">を提案しており、このネットワークは、Collaborative Constrastive Learningに基づいて学習される。<br><br><br><br>### Collaborative Constrasitve Learning<br><br>図2がCollaborative Constrastive Learningの気持ちを表しており、図2のようなクリックスルーログが与えられたとする。<br><br>推薦リストを上から見ていき、いま着目しているアイテムをtarget_itemとすると、target_itemがクリックされている場合、同じcontext（i.e., ユーザにページ内で提示されたアイテム群）のクリックされているアイテムと距離が近くなり、逆にクリックされていないアイテム群とは距離が遠いとみなせる。逆にtarget_itemがクリックされていない場合、同様にクリックされていないアイテムとは距離が近く、クリックされているアイテムとは距離が遠いとみなせる。このように考えると、ある推薦リストが与えられた時に、あるtarget_itemに着目すると、contrastive learningのためのpositive example/negative exampleを生成できる。このようなco-click/co-non-clickの関係から、アイテム同士の距離を学習し、ユーザのinterest/disinterestを学習する。<br><br>![image](https://github.com/user-attachments/assets/cea478d8-27e5-45e9-afcd-41a0765c8cce<br><br><br><br>### Collaborative Contrastive Network<br><br>Collaborative ModuleとCTR Moduleに分かれている。<br><br>- Collaborative Moduleには、context itemsと、target itemをinputとし両者の関係性をエンコードする<br><br>    - このとき、トリガーアイテムのembeddingとアダマール積をとることで、トリガーアイテムの情報も考慮させる<br><br>- CTR Moduleは、context itemsとtarget itemの関係性をエンコードしたembedding、target_item, trigger_itemのembedding, user profileのembedding, userのlong-termとshort-termの行動のembeddingをconcatしたベクトルをinputとして受け取り、そらからtarget_itemのCTRを予測する。 <br><br>- Loss Functionは、binary cross entropyと、Collaborative Contrastive Lossをλで重みづけして足し合わせたものであり、Collaborative Contrastive Loss L_CMCは、上述の気持ちを反映するloss（i.e., target_itemとcontext_itemco-click/co-non-clickに基づいて、アイテム間の距離を最小/最大化するようなloss）となっている<br><br>![image](https://github.com/user-attachments/assets/2ca62ade-d370-4615-89d1-eac56bf1e847<br><br><br><br>![image](https://github.com/user-attachments/assets/07f4bef9-2f86-46b5-b310-2afca26a0db3<br><br><br><br>## 実験結果<br><br>### offline evaluation<br><br>Table 1に示したTaobaoで収集した非常に大規模なproprietary datasetでCTRを予測したところ、AUCはベースラインと比較して高くなった。ここで、TANはCCNのBackboneモデルで、Contrastive Learningを実施していないモデルである。CTR予測においてAUCが高くなるというのはすなわち、クリックされたアイテムi/クリックされなかったアイテムjの2つをとってきたときに、両者のCTR予測結果が CTR_i &gt; CTR_j になる割合が高くなった（i.e. クリックされているアイテムの方が高いCTR予測結果となっている）ということを意味する。<br><br>![image](https://github.com/user-attachments/assets/e696bf07-fcd6-47cd-9f96-926071a6b609<br><br>![image](https://github.com/user-attachments/assets/629bc349-36f6-4603-b595-3482c92e66f4<br><br><br><br>### online A/B Testing<br><br>A/Bテストまで実施しており、実際に提案手法を組み込んだ結果、高いCTRを獲得しているだけでなく、CVRも向上している。すごい。<br><br>![image](https://github.com/user-attachments/assets/651d8351-32f5-4aa6-89b6-f310781467f8<br><br>Contrastive Learningを実施しないTANと、CCNを比較してもCCNの方が高いCTR, CVRを獲得している。Contrastive Learning有能。<br><br>![image](https://github.com/user-attachments/assets/56b6d14f-fef7-4d1b-ae04-ec3acacf2787<br><br></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="deep-intention-aware-1533" class="title-link">Deep Intention-Aware Network for Click-Through Rate Prediction, Yaxian Xia+, arXiv'22</h3>
<br><a href="https://arxiv.org/abs/2211.08650" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1533" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2024-11-19</span>
<span class="snippet"><span>GPT Summary</span>- Eコマースプラットフォームにおけるトリガー誘発推薦（TIRA）に対し、従来のCTR予測モデルは不適切である。顧客のエントリー意図を抽出し、トリガーの影響を評価するために、深層意図認識ネットワーク（DIAN）を提案。DIANは、ユーザーの意図を推定し、トリガー依存と非依存の推薦結果を動的にバランスさせる。実験により、DIANはタオバオのミニアプリでCTRを4.74%向上させることが示された。</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1531" target="_blank" rel="noopener noreferrer">Collaborative Contrastive Network for Click-Through Rate Prediction, Chen Gao+, arXiv'24</a>
 の実験で利用されているベースライン</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="deep-interest-1532" class="title-link">Deep Interest Highlight Network for Click-Through Rate Prediction in  Trigger-Induced Recommendation, Qijie Shen+, WWW'22</h3>
<br><a href="https://arxiv.org/abs/2202.08959" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1532" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2024-11-19</span>
<span class="snippet"><span>GPT Summary</span>- トリガー誘発推薦（TIR）を提案し、ユーザーの瞬時の興味を引き出す新しい推薦手法を紹介。従来のモデルがTIRシナリオで効果的でない問題を解決するため、Deep Interest Highlight Network（DIHN）を開発。DIHNは、ユーザー意図ネットワーク（UIN）、融合埋め込みモジュール（FEM）、ハイブリッド興味抽出モジュール（HIEM）の3つのコンポーネントから成り、実際のeコマースプラットフォームでの評価で優れた性能を示した。</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1531" target="_blank" rel="noopener noreferrer">Collaborative Contrastive Network for Click-Through Rate Prediction, Chen Gao+, arXiv'24</a>
 の実験で利用されているベースライン</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="an-embedding-1901" class="title-link">[Paper Note] An Embedding Learning Framework for Numerical Features in CTR Prediction, Huifeng Guo+, KDD'21</h3>
<br><a href="https://arxiv.org/abs/2012.08986" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1901" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<a class="button" href="numeric.html" target="_blank" rel="noopener noreferrer">#numeric</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-04-22</span>
<span class="snippet"><span>GPT Summary</span>- CTR予測のための新しい埋め込み学習フレームワーク「AutoDis」を提案。数値特徴の埋め込みを強化し、高いモデル容量とエンドツーエンドのトレーニングを実現。メタ埋め込み、自動離散化、集約の3つのコアコンポーネントを用いて、数値特徴の相関を捉え、独自の埋め込みを学習。実験により、CTRとeCPMでそれぞれ2.1%および2.7%の改善を達成。コードは公開されている。</span>
<span class="snippet"><span>Comment</span><p>従来はdiscretizeをするか、mlpなどでembeddingを作成するだけだった数値のinputをうまく埋め込みに変換する手法を提案し性能改善<br><br>数値情報を別の空間に写像し自動的なdiscretizationを実施する機構と、各数値情報のフィールドごとのglobalな情報を保持するmeta-embeddingをtrainable parameterとして学習し、両者を交互作用（aggregation; max-poolingとか）することで数値embeddingを取得する。<br><br><img src="https://github.com/user-attachments/assets/1f626dd5-2452-4b50-a14c-6c24fa022435">" alt="image" loading="lazy" width="550" height="400"/&gt;<br><br><img src="https://github.com/user-attachments/assets/12fd6476-241a-4d13-975d-f6c1c762c497">" alt="image" loading="lazy" width="550" height="400"/&gt;</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="conversion-prediction-366" class="title-link">Conversion Prediction Using Multi-task Conditional Attention Networks to Support the Creation of Effective Ad Creatives, Kitada+, KDD'19</h3>
<br><a href="https://arxiv.org/pdf/1905.07289.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/366" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="CVRPrediction.html" target="_blank" rel="noopener noreferrer">#CVRPrediction</a>
<a class="button" href="SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<span class="issue_date">Issue Date: 2021-06-01</span>
<span class="snippet"><span>Comment</span><p># Overview<br><br>広告のCVR予測をCTR予測とのmulti-task learningとして定式化。<br><br>構築した予測モデルのattention distributionを解析することで、high-qualityなクリエイティブの作成を支援する。<br><br>genderやgenre等の情報でattentionのweightを変化させるconditional attentionが特徴的。<br><br>→ これによりgender, genreごとのCVRしやすい広告の特徴の違いが可視化される<br><br><br><br>![image](https://user-images.githubusercontent.com/12249301/120273298-45d9c400-c2e9-11eb-9e62-24afd6323d01.png<br><br><br><br>loss functionは、MSEにλを導入しclickのlossを制御している（CVRに最適化したいため）。ただ、実験ではλ=1で実験している。<br><br>outputはRegressionでCVR, CTRの値そのものを予測している（log lossを使う一般的なCTR Prediction等とは少し条件が違う; 多分予測そのものより、予測モデルを通じて得られるCVRが高いcreativeの分析が主目的なため）。<br><br>![image](https://user-images.githubusercontent.com/12249301/120273365-5db14800-c2e9-11eb-9888-a98443a7adbc.png<br><br><br><br># Experiments<br><br>データとして、2017年8月〜2018年8月の間にGunosy Adsでdeliverされた14,000種類のad creativeを利用。<br><br>clickとconversionのfrequency（clickはlong-tailだが、conversionはほとんど0か1のように見える）<br><br>![image](https://user-images.githubusercontent.com/12249301/120275800-cf3ec580-c2ec-11eb-87a0-e0dacd230c5e.png<br><br><br><br>5-fold crossvalidationを、fold内でcampaignが重複しないようにad creativeに対して行い、conversion数の予測を行なった。<br><br>評価を行う際はNDCGを用い、top-1%のconversion数を持つcreativeにフォーカスし評価した。<br><br><br><br>![image](https://user-images.githubusercontent.com/12249301/120277549-26459a00-c2ef-11eb-9a7e-2ba8832ed26a.png<br><br><br><br>MSEで評価した場合、multi-task learning, conditional attentionを利用することでMSEが改善している。多くのcreativeのconversionは0なので、conversion数が&gt;0のものに着目して評価しても性能が改善していることがわかる。<br><br><br><br>NDCGを利用した評価でも同様な傾向<br><br>![image](https://user-images.githubusercontent.com/12249301/120277916-a1a74b80-c2ef-11eb-8530-0399ee43c2eb.png<br><br><br><br>conditional attentionのheatmap<br><br>![image](https://user-images.githubusercontent.com/12249301/120274299-9bfb3700-c2ea-11eb-939e-6593056e109b.png<br><br><br><br>genderごとにdistributionの違いがあって非常におもしろい<br><br></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="field-weighted-341" class="title-link">Field Weighted Factorization Machines for Click-Through Rate Prediction in Display Advertising, Pan+, WWW'18</h3>
<br><a href="https://arxiv.org/pdf/1806.03514.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/341" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="FactorizationMachines.html" target="_blank" rel="noopener noreferrer">#FactorizationMachines</a>
<a class="button" href="WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2020-08-29</span>
<span class="snippet"><span>Comment</span><p>CTR予測でbest-performingなモデルと言われているField Aware Factorization Machines(FFM)では、パラメータ数がフィールド数×特徴数のorderになってしまうため非常に多くなってしまうが、これをよりメモリを効果的に利用できる手法を提案。FFMとは性能がcomparableであるが、パラメータ数をFFMの4%に抑えることができた。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="e-commerce-in-1902" class="title-link">E-commerce in Your Inbox: Product Recommendations at Scale, Mihajlo Grbovic+, KDD'15</h3>
<br><a href="https://arxiv.org/abs/1606.07154" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1902" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="SequentialRecommendation.html" target="_blank" rel="noopener noreferrer">#SequentialRecommendation</a>
<a class="button" href="SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<span class="issue_date">Issue Date: 2025-04-25</span>
<span class="snippet"><span>GPT Summary</span>- メールの領収書から得た購入履歴を活用し、Yahoo Mailユーザーにパーソナライズされた商品広告を配信するシステムを提案。新しい神経言語ベースのアルゴリズムを用いて、2900万人以上のユーザーのデータでオフラインテストを実施した結果、クリック率が9%向上し、コンバージョン率も改善。システムは2014年のホリデーシーズンに本稼働を開始。</span>
<span class="snippet"><span>Comment</span><p>Yahoo mailにおける商品推薦の研究<br>![image](https://github.com/user-attachments/assets/6f54d2c7-6f30-411b-94c9-888c62811bd8<br><br>Yahoo mailのレシート情報から、商品購入に関する情報とtimestampを抽出し、時系列データを形成。評価時はTimestampで1ヶ月分のデータをheldoutし評価している。Sequential Recommendationの一種とみなせるが、評価データをユーザ単位でなくtimestampで区切っている点でよりrealisticな評価をしている。<br>![image](https://github.com/user-attachments/assets/6d79bb63-8d88-4be8-b1ef-1db2affb141f</p>
<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/342" target="_blank" rel="noopener noreferrer">Sequence-Aware Recommender Systems, ACM Computing Surveys, Vol. 1, No. 1, Article 1, 2018</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="simple-and-429" class="title-link">Simple and scalable response prediction for display advertising, Chapelle+, Criteo, Transactions on Intelligent Systems and Technology, CHAPELLE+, TIST'14</h3>
<br><a href="https://people.csail.mit.edu/romer/papers/TISTRespPredAds.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/429" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<span class="issue_date">Issue Date: 2021-10-29</span>
<span class="snippet"><span>Comment</span><p>日本語解説： 


<a href="https://ameblo.jp/cyberanalyst/entry-11784152713.html" target="_blank" rel="noopener noreferrer">https://ameblo.jp/cyberanalyst/entry-11784152713.html</a>


<br><br><br><br>CTR予測の概要や、広告主・事業者にとってCTR予測ができることでどのようなメリットがあるかなどがまとまっている。<br><br>論文の手法自体は、logistic regressionが利用されている。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="self-monitoring-large-2559" class="title-link">[Paper Note] Self-Monitoring Large Language Models for Click-Through Rate Prediction, Zhou+, ACM Transactions on Information Systems, 2025.08</h3>
<br><a href="https://dl.acm.org/doi/10.1145/3763789" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2559" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-27</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1960558009538764873?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="newspicksに推薦システムを本番投入する上で一番優先すべきだったこと-1367" class="title-link">NewsPicksに推薦システムを本番投入する上で一番優先すべきだったこと, 2024.08</h3>
<br><a href="https://tech.uzabase.com/entry/2024/08/29/161828" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1367" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="NewsRecommendation.html" target="_blank" rel="noopener noreferrer">#NewsRecommendation</a>
<a class="button" href="MLOps.html" target="_blank" rel="noopener noreferrer">#MLOps</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="A_B%20Testing.html" target="_blank" rel="noopener noreferrer">#A/B Testing</a>
<span class="issue_date">Issue Date: 2024-08-31</span>
<span class="snippet"><span>Comment</span><p>&gt;推薦モデルの良し悪しをより高い確度で評価できる実験を、より簡単に実行できる状態を作ることでした。平たく言えば「いかにA/Bテストしやすい推薦システムを設計するか」が最も重要だった訳です。<br><br>オフライン評価とオンライン評価の相関がない系の話で、A/Bテストを容易に実施できる環境になかった、かつCTRが実際に向上したモデルがオフライン評価での性能が現行モデルよりも悪く、意思決定がなかなかできなかった、という話。<br><br>うーんやはり、推薦におけるオフライン評価ってあまりあてにできないよね、、、<br>そもそも新たなモデルをデプロイした時点で、テストした時とデータの分布が変わるわけだし、、、<br><br>Off-Policy Evaluationの話は勉強したい。</p>
<p>あと、定性評価は重要</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="2010年代前半のaiの巨人達のctr-prediction研究-425" class="title-link">2010年代前半のAIの巨人達のCTR Prediction研究</h3>
<br><a href="http://www-personal.umich.edu/~qmei/pub/kdd2015-click.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/425" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<span class="issue_date">Issue Date: 2021-10-29</span>
</article>
<article class="paper-entry">
<h3 id="バンディットアルゴリズムを使って広告最適化のシミュレーションをしてみたよ-423" class="title-link">バンディットアルゴリズムを使って広告最適化のシミュレーションをしてみたよ, ysekky, 2014</h3>
<br><a href="https://qiita.com/ysekky/items/4e782603f7592743625b" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/423" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2021-10-29</span>
<span class="snippet"><span>Comment</span><p>なぜクリック率を上げたいのかという説明が非常に参考になる：<br><br>&gt;しかしその広告を掲載する側から考えればクリック率の低い広告を出すことは売上が下がってしまうため，クリック率が&gt;低いとなかなか広告を表示することができなくなってしまいます．<br><br>その際よく使われるのはeCPMという指標です．<br><br>eCPMはその広告を1000回表示していくらの売上を上げることができるかという指標であり，<br><br>クリック率1000クリック単価で求められます．<br><br>&gt;EPCMが高い広告のほうが表示されやすいため，クリック率を上げることで同じクリック単価でたくさんのユーザを自社のランディングページに誘導することができるようになります．<br><br>&gt;例えば今回のケースではクリック率1.2%でクリック単価が60円ですので，eCPMは720円です。<br><br>ここでクリック率が0.1％上がるとeCPMは780円になります．<br><br>&gt;そのときクリック単価を56円にしてもeCPMは726円になるため，つまりクリック率が0.1%上がると同じだけのランディングページへの誘導を得るための単価を4円下げることができます．<br><br>&gt;例えばそのランディングページでの商品の購入が1%で行われるとすると，商品を1つ売るためのコストが400円も下がる事になります．<br><br>&gt;ケースバイケースではありますが，このようにクリック率を上げることはウェブ広告を通してものを売るために非常に重要な要素になります．</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="criteo-dataset-362" class="title-link">Criteo Dataset, Display Advertising Challenge, Kaggle, 2014</h3>
<br><a href="https://www.kaggle.com/c/criteo-display-ad-challenge/data" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/362" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<span class="issue_date">Issue Date: 2021-06-01</span>
<span class="snippet"><span>Comment</span><p>Criteo Dataset (


<a href="https://www.kaggle.com/c/criteo-display-ad-challenge/data)" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/c/criteo-display-ad-challenge/data)</a>


<br><br><br><br>DeepFM等のモデルで利用されているCTR Predictionのためのデータセット<br><br><br><br># Data Description<br><br>- train.csv: 7日間のcriteoのtraffic recordの一部。個々の行が1 impに対応している。click, non-clickのラベル付き。chronologically order. click, non-clickのexampleはデータセットのサイズを縮小するために異なるrateでサブサンプルされている。<br><br>- training: trainingデータと同様の作成データだが、trainingデータの翌日のデータで構成されている。<br><br><br><br># Data Fields<br><br>- Label - Target variable that indicates if an ad was clicked (1) or not (0).<br><br>- I1-I13 - A total of 13 columns of integer features (mostly count features).<br><br>- C1-C26 - A total of 26 columns of categorical features. The values of these features have been hashed onto 32 bits for anonymization purposes. <br><br><br><br>13種類のinteger featureと、26種類のcategorical featuresがある。</p>
<p>Avazu Data (


<a href="https://www.kaggle.com/c/avazu-ctr-prediction/data)" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/c/avazu-ctr-prediction/data)</a>


<br><br><br><br># File descriptions<br><br>- train - Training set. 10 days of click-through data, ordered chronologically. Non-clicks and clicks are subsampled according to different strategies.<br><br>- test - Test set. 1 day of ads to for testing your model predictions. <br><br>sampleSubmission.csv - Sample submission file in the correct format, corresponds to the All-0.5 Benchmark.<br><br><br><br># Data fields<br><br>- id: ad identifier<br><br>- click: 0/1 for non-click/click<br><br>- hour: format is YYMMDDHH, so 14091123 means 23:00 on Sept. 11, 2014 UTC.<br><br>- C1 -- anonymized categorical variable<br><br>- banner_pos<br><br>- site_id<br><br>- site_domain<br><br>- site_category<br><br>- app_id<br><br>- app_domain<br><br>- app_category<br><br>- device_id<br><br>- device_ip<br><br>- device_model<br><br>- device_type<br><br>- device_conn_type<br><br>- C14-C21 -- anonymized categorical variables</p>
<p>基本的には click/non-click のラベルと、そのclick時の付帯情報によって構成されている模様</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="deepfm-a-349" class="title-link">DeepFM: A Factorization-Machine based Neural Network for CTR Prediction, Guo+, IJCAI’17</h3>
<br><a href="https://arxiv.org/pdf/1703.04247.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/349" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="FactorizationMachines.html" target="_blank" rel="noopener noreferrer">#FactorizationMachines</a>
<a class="button" href="IJCAI.html" target="_blank" rel="noopener noreferrer">#IJCAI</a>
<span class="issue_date">Issue Date: 2021-05-25</span>
<span class="snippet"><span>Comment</span><p>Factorization Machinesと、Deep Neural Networkを、Wide&amp;Deepしました、という論文。Wide=Factorization Machines, Deep=DNN。<br><br>高次のFeatureと低次のFeatureを扱っているだけでなく、FMによってフィールドごとのvector-wiseな交互作用、DNNではbit-wiseな交互作用を利用している。<br>割と色々なデータでうまくいきそうな手法に見える。<br><br>発展版としてxDeepFM <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/348" target="_blank" rel="noopener noreferrer">xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems, Lian+, KDD‘18</a>
 がある。</p>
<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/281" target="_blank" rel="noopener noreferrer">[Paper Note] Factorization Machines, Steffen Rendle, ICDM'10</a>
 にも書いたが、下記リンクに概要が記載されている。<br><br>DeepFMに関する動向：


<a href="https://data.gunosy.io/entry/deep-factorization-machines-2018" target="_blank" rel="noopener noreferrer">https://data.gunosy.io/entry/deep-factorization-machines-2018</a>


</p>
<p>実装: 


<a href="https://github.com/rixwew/pytorch-fm" target="_blank" rel="noopener noreferrer">https://github.com/rixwew/pytorch-fm</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="xdeepfm-combining-348" class="title-link">xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems, Lian+, KDD‘18</h3>
<br><a href="https://arxiv.org/pdf/1803.05170.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/348" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="FactorizationMachines.html" target="_blank" rel="noopener noreferrer">#FactorizationMachines</a>
<a class="button" href="SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<span class="issue_date">Issue Date: 2021-05-25</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/349" target="_blank" rel="noopener noreferrer">DeepFM: A Factorization-Machine based Neural Network for CTR Prediction, Guo+, IJCAI’17</a>
 DeepFMの発展版</p>
<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/281" target="_blank" rel="noopener noreferrer">[Paper Note] Factorization Machines, Steffen Rendle, ICDM'10</a>
 にも書いたが、下記リンクに概要が記載されている。<br><br>DeepFMに関する動向：


<a href="https://data.gunosy.io/entry/deep-factorization-machines-2018" target="_blank" rel="noopener noreferrer">https://data.gunosy.io/entry/deep-factorization-machines-2018</a>


<br><br><br><br>DeepFMの発展についても詳細に述べられていて、とても参考になる。</p></span><br><br>
</article>
</div>
<script>
document.addEventListener("DOMContentLoaded", function() {
  // Twitterのwidgets.jsを動的に一度だけ読み込む関数
  let twitterScriptLoaded = false;
  function loadTwitterScript() {
    if (!twitterScriptLoaded) {
      const script = document.createElement('script');
      script.src = "https://platform.twitter.com/widgets.js";
      script.charset = "utf-8";
      script.async = true;
      document.body.appendChild(script);
      twitterScriptLoaded = true;
    }
  }

  // Intersection Observerの設定
  const observer = new IntersectionObserver((entries, obs) => {
    entries.forEach(entry => {
      if (entry.isIntersecting) {
        // 画面に入った時だけスクリプトをロード開始
        loadTwitterScript();

        const container = entry.target;
        const embedHtml = container.getAttribute('data-embed');
        
        if (embedHtml) {
          container.innerHTML = embedHtml;
          container.removeAttribute('data-embed');
          
          // ウィジェットの再スキャン（twttrオブジェクトが準備できていれば実行）
          if (window.twttr && window.twttr.widgets) {
            window.twttr.widgets.load(container);
          }
        }
        obs.unobserve(container);
      }
    });
  }, { rootMargin: '200px', threshold: 0.01 }); // 少し早めに読み込む

  document.querySelectorAll('.tweet-embed').forEach(el => observer.observe(el));
});
</script>


    </div>

</article>
<div class="post-nav">
<a class="previous" href="/paper_notes/articles/RelationExtraction/" title="RelationExtractionに関する論文・技術記事メモの一覧">RelationExtractionに関する論文・技術記事メモの一覧</a><a class="next" href="/paper_notes/articles/CovarianceShift/" title="CovarianceShiftに関する論文・技術記事メモの一覧">CovarianceShiftに関する論文・技術記事メモの一覧</a>
</div>
<div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li class="">
          <a class="post-link" href="/paper_notes/articles/ImageCaptioning/" title="ImageCaptioningに関する論文・技術記事メモの一覧">
            ImageCaptioningに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 7</span> 
  <span class="post-badge badge-new">📝 7</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/SoftwareEngineering/" title="SoftwareEngineeringに関する論文・技術記事メモの一覧">
            SoftwareEngineeringに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 74</span> 
  <span class="post-badge badge-new">📝 74</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/TTS/" title="TTSに関する論文・技術記事メモの一覧">
            TTSに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 17</span> 
  <span class="post-badge badge-new">📝 17</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/ContrastiveReinforcementLearning/" title="ContrastiveReinforcementLearningに関する論文・技術記事メモの一覧">
            ContrastiveReinforcementLearningに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 1</span> 
  <span class="post-badge badge-new">📝 1</span>
</span>
</a>
        </li>
</ul>
    </div>
<div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
/* --- レイアウト用（前回と同じ） --- */
.post-menu {
  position: -webkit-sticky;
  position: sticky;
  top: 20px;
  max-height: calc(100vh - 40px);
  display: flex;
  flex-direction: column;
}

.post-menu-title {
  flex-shrink: 0;
  margin-bottom: 10px;
  font-weight: bold;
}

.post-menu-content {
  overflow-y: auto;
  scrollbar-width: thin;
}

.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}

/* --- 開閉アニメーションとアイコン用 --- */

/* h2のスタイル：クリックできるようにする */
.post-menu li.h-h2 {
  cursor: pointer;
  position: relative;
  padding-left: 15px; /* アイコン用のスペース */
  font-weight: bold;
  margin-top: 5px;
}

/* 開閉アイコン（▼） */
.post-menu li.h-h2::before {
  content: '';
  display: inline-block;
  width: 0;
  height: 0;
  border-style: solid;
  border-width: 5px 0 5px 6px; /* 三角形 */
  border-color: transparent transparent transparent #555;
  position: absolute;
  left: 0;
  top: 50%;
  transform: translateY(-50%);
  transition: transform 0.2s ease;
}

.post-menu li.h-h2.no-icon::before {
  content: none; /* 擬似要素の中身をなしにする */
  /* または display: none; でもOKです */
}

/* 開いている時のアイコン（下向きにする） */
.post-menu li.h-h2.open::before {
  transform: translateY(-50%) rotate(90deg);
}

/* h3（子要素）のスタイル */
.post-menu li.h-h3 {
  margin-left: 15px;
  font-size: 0.9em;
  /* 初期状態はJSで制御しますが、念のため */
}

/* アクティブな項目の色 */
.post-menu li.active > a {
  color: #d9534f;
  font-weight: bold;
}

/* リンク自体のスタイル調整 */
.post-menu li a {
  text-decoration: none;
  color: inherit;
  display: inline-block;
  width: 100%;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">TOC</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent = menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3");

    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // --- HTML生成 ---
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      // h-h2 クラスの要素には初期状態で open クラスをつけるか、つけないかで「最初から開いているか」を決められます
      // ここでは閉じた状態をデフォルトとします
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }
    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';


    // --- 開閉ロジックの実装 ---
    var listItems = menuContent.querySelectorAll('li');

    // h2要素にクリックイベントを追加
    listItems.forEach(function(item, index) {
      if (item.classList.contains('h-h2')) {
        
        // クリックイベント
        item.addEventListener('click', function(e) {
          // リンクをクリックした場合はページ内遷移させたいので、イベントを止めない
          // ただし、アイコン付近をクリックした等の挙動を統一するため、
          // 開閉処理を行います。
          
          // クラスの付け替え（アイコンの回転用）
          item.classList.toggle('open');

          // 次のh2が出てくるまで、h3を表示/非表示切り替え
          for (var i = index + 1; i < listItems.length; i++) {
            var sibling = listItems[i];
            if (sibling.classList.contains('h-h2')) {
              break; // 次のh2に来たら終了
            }
            if (sibling.classList.contains('h-h3')) {
              if (item.classList.contains('open')) {
                sibling.style.display = 'block';
              } else {
                sibling.style.display = 'none';
              }
            }
          }
        });
      }
    });

    // --- 初期状態の設定（すべて閉じる） ---
    // もし最初から開いておきたい場合は、このブロックを削除するか調整してください
    listItems.forEach(function(item) {
      if (item.classList.contains('h-h3')) {
        item.style.display = 'none';
      }
    });


    // --- スクロール連動（ハイライト機能のみ残す） ---
    var header = document.querySelector('header.site-header');
    
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header ? header.getBoundingClientRect() : {top:0, height:0}; // headerがない場合の安全策
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var offset = headerTop + headerHeight + 20;

        if (headingRect.top <= offset) {
          var id = h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          
          if (curActive) {
            // もしアクティブになった項目が閉じているh2の中にあった場合、
            // 自動で開く処理を追加したい場合はここに記述します。
            // 今回は「手動開閉」を優先し、自動オープンはあえて行いません。
            
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }

      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
      }
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/paper_notes/"></data>

  <div class="wrapper">
    <div class="site-footer-inner">
<div>Copyright © 2023-current AkihikoWATANABE. The header images and any thumbnail images for the posts were generated by ChatGPT's DALL-E3.</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="https://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div class="footer-col rss-subscribe">Subscribe <a href="/paper_notes/feed.xml">via RSS</a>
</div>
    </div>
  </div>
</footer>
</body>
  </html>
