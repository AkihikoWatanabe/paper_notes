<!DOCTYPE html>
<html lang="ja">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Selected Papers/Blogsã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§ | ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="Selected Papers/Blogsã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
<meta name="author" content="AkihikoWATANABE">
<meta property="og:locale" content="ja">
<meta name="description" content='&lt;h2 id=Selected Papers/Blogs&gt; Selected Papers/Blogs&lt;/h2&gt;&lt;div class="visible-content"&gt; #Pocket #NLP #LanguageModel #UserBased #LLMAgent #SoftwareEngineering #read-later #interactive'>
<meta property="og:description" content='&lt;h2 id=Selected Papers/Blogs&gt; Selected Papers/Blogs&lt;/h2&gt;&lt;div class="visible-content"&gt; #Pocket #NLP #LanguageModel #UserBased #LLMAgent #SoftwareEngineering #read-later #interactive'>
<link rel="canonical" href="http://akihikowatanabe.github.io/paper_notes/articles/Selected%20Papers_Blogs.html">
<meta property="og:url" content="http://akihikowatanabe.github.io/paper_notes/articles/Selected%20Papers_Blogs.html">
<meta property="og:site_name" content="ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2025-11-07T00:48:09+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="Selected Papers/Blogsã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"AkihikoWATANABE"},"dateModified":"2025-11-07T00:48:09+00:00","datePublished":"2025-11-07T00:48:09+00:00","description":"&lt;h2 id=Selected Papers/Blogs&gt; Selected Papers/Blogs&lt;/h2&gt;&lt;div class=&quot;visible-content&quot;&gt; #Pocket #NLP #LanguageModel #UserBased #LLMAgent #SoftwareEngineering #read-later #interactive","headline":"Selected Papers/Blogsã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§","mainEntityOfPage":{"@type":"WebPage","@id":"http://akihikowatanabe.github.io/paper_notes/articles/Selected%20Papers_Blogs.html"},"url":"http://akihikowatanabe.github.io/paper_notes/articles/Selected%20Papers_Blogs.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="icon" href="">
  <link rel="canonical" href="http://akihikowatanabe.github.io">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/main.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/custom_button.css">
  <script src="/paper_notes/assets/js/main.js"></script>
  <script src="https://d3js.org/d3.v5.min.js"></script><link type="application/atom+xml" rel="alternate" href="http://akihikowatanabe.github.io/paper_notes/feed.xml" title="ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ">
<script>
  function showMore(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "block";
          
      // ã“ã®ãƒœã‚¿ãƒ³ã®å‚ç…§ã‚’å–å¾—ã—ã¦éè¡¨ç¤ºã«ã—ã¾ã™
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "none";
      }
          
      // hideãƒœã‚¿ãƒ³ã®å‚ç…§ã‚’å–å¾—ã—ã¦è¡¨ç¤ºã—ã¾ã™
      const hideButton = contentDiv.querySelector('button[onclick^="hideContent"]');
      if (hideButton) {
        hideButton.style.display = "block";
      }
    }
  }

  function hideContent(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "none";
  
      // moreãƒœã‚¿ãƒ³ã®å‚ç…§ã‚’å–å¾—ã—ã¦è¡¨ç¤ºã—ã¾ã™
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "block";
      }
  
      // ã“ã®ãƒœã‚¿ãƒ³ã‚’éš ã—ã¾ã™
      const hideButtons = document.querySelectorAll('button[onclick^="hideContent"]');
      const hideButton = hideButtons[index];
      if (hideButton) {
        hideButton.style.display = "none";
      }
    }
  }
</script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js" async></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe-lightbox.umd.min.js" async></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe.umd.min.js" async></script>
<link href="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/photoswipe.min.css" rel="stylesheet">
<style>
  .pswp .pswp__container .pswp__img {
    background-color: white;
  }
</style>

<script>
  function initPhotoSwipe() {
    let customOptions = {};

    try {
      const data = `{"gallery"=>"section.main", "children"=>"a.photo-swipe", "bgOpacity"=>0.8, "padding"=>{"top"=>20, "bottom"=>40, "left"=>100, "right"=>100}}`.replaceAll("=>", ":");
      customOptions = JSON.parse(data);
    } catch (e) {
      console.info("Invalid custom photo previewer options! " + e.message);
    }

    // Define object and gallery options
    const options = Object.assign(
      {
        gallery: "section.main",
        children: "a.photo-swipe",
        photo_scale: 2,
        // dynamic import is not supported in UMD version
        pswpModule: PhotoSwipe,
      },
      customOptions
    );

    const galleryEl = document.querySelector(options.gallery);
    if (!galleryEl) {
      return;
    }

    const imgEls = [];
    const els = galleryEl.querySelectorAll("img:not(.emoji)");
    els.forEach((el) => {
      if (el.src.trim() == "") {
        return;
      }
      if (!imgEls.includes(el)) {
        imgEls.push(el);
      }
    });

    if (imgEls.length === 0) {
      return;
    }

    imgEls.forEach((imgEl) => {
      imgEl.outerHTML = `
      <a class="photo-swipe"
        href="${imgEl.src}"
        data-pswp-width="${
          Math.max(imgEl.naturalWidth, imgEl.width) * options.photo_scale
        }"
        data-pswp-height="${
          Math.max(imgEl.naturalHeight, imgEl.height) * options.photo_scale
        }"
        data-pswp-caption="${imgEl.getAttribute("caption") || imgEl.alt}"
        target="_blank">
        ${imgEl.outerHTML}
      </a>`;
    });

    // Initialize PhotoSwipe 5
    var lightbox = new PhotoSwipeLightbox(options);

    lightbox.init();
  }

  window.addEventListener("load", initPhotoSwipe);
</script>
<meta name="google-site-verification" content="u_DTTPcCZ806iq51zgirHyWq3556HUKGq8AQfH91iFI">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-P70KSB88WH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-P70KSB88WH');
  </script>

<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"},"svg":{"fontCache":"global"}}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>





































































































































<header class="site-header site-header-transparent" role="banner">

  <div class="wrapper">
    <div class="site-header-inner">
<span class="site-brand"><a class="site-brand-inner" rel="author" href="/paper_notes/">
  <img class="site-favicon" title="ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ" src="" onerror="this.style.display='none'">
  ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger">
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewbox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
              </svg>
            </span>
          </label>

          <div class="trigger">









<span class="page-link">



<div id="google_translate_element" style="display: none;">
</div>

<span class="ct-language">
  <ul class="list-unstyled ct-language-dropdown">
    
      <li>
        <a href="#" class="lang-select" data-lang="en">
          
          <img src="https://cdn.countryflags.com/thumbs/united-states-of-america/flag-400.png" title="English">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="fr">
          
          <img src="https://cdn.countryflags.com/thumbs/france/flag-400.png" title="French">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="zh-CN">
          
          <img src="https://cdn.countryflags.com/thumbs/china/flag-400.png" title="Chinese(Simple)">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ja">
          
          <img src="https://cdn.countryflags.com/thumbs/japan/flag-400.png" title="Japanese">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ko">
          
          <img src="https://cdn.countryflags.com/thumbs/south-korea/flag-400.png" title="Korean">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ru">
          
          <img src="https://cdn.countryflags.com/thumbs/russia/flag-400.png" title="Russian">
          
        </a>
      </li>
    
  </ul>
</span>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'ja',
    autoDisplay: false,
    layout: google.translate.TranslateElement.InlineLayout.VERTICAL
  }, 'google_translate_element');

  // Links to cross-origin destinations are unsafe
  var gll = document.getElementsByClassName('goog-logo-link')[0];
  if (gll) {
    gll.setAttribute('rel', 'noopener');
  }

  function restoreLang() {
    var iframe = document.getElementsByClassName('goog-te-banner-frame')[0];
    if (!iframe) return;

    var innerDoc = iframe.contentDocument || iframe.contentWindow.document;
    var restore_el = innerDoc.getElementsByTagName("button");

    for (var i = 0; i < restore_el.length; i++) {
      if (restore_el[i].id.indexOf("restore") >= 0) {
        restore_el[i].click();
        var close_el = innerDoc.getElementsByClassName("goog-close-link");
        close_el[0].click();
        return;
      }
    }
  }

  function triggerHtmlEvent(element, eventName) {
    var event;
    if (document.createEvent) {
      event = document.createEvent('HTMLEvents');
      event.initEvent(eventName, true, true);
      element.dispatchEvent(event);
    } else {
      event = document.createEventObject();
      event.eventType = eventName;
      element.fireEvent('on' + event.eventType, event);
    }
  }

  var googleCombo = document.querySelector("select.goog-te-combo");
  var langSelect = document.querySelector('.ct-language');
  langSelect.addEventListener('click', function(event) {
    if (!event.target) {
      return;
    }

    var selected = document.querySelector('.ct-language .ct-language-selected');
    if (selected) {
      selected.classList.remove('ct-language-selected');
    }

    var target = event.target;
    while (target && target !== langSelect ) {
      if (target.matches('.lang-select')) {
        break;
      }
      target = target.parentElement;
    }

    if (target && target.matches('.lang-select')) {
      var lang = target.getAttribute('data-lang');
      if (googleCombo.value == lang) {
        restoreLang();
      } else {
        target.parentElement.classList.add('ct-language-selected');
        googleCombo.value = lang;
        triggerHtmlEvent(googleCombo, 'change');
      }
    }

    event.preventDefault();
  });
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit" async></script>
</span>
</div>
        </nav>
</div>
  </div>
</header>

<script>
  function initHeader() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;

    function storeScrollData() {
      var y = getScrollPos().y;documentElement.setAttribute("data-header-transparent", "");var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0) ? true : false;
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
    }

    window.addEventListener('scroll', function(e) {
      storeScrollData();
    });

    storeScrollData();
  }
  document.addEventListener('DOMContentLoaded', initHeader);
</script>


























































































































































<style>
    html .page-banner .page-banner-img > *:first-child {
      opacity: 0.4;
    }

    html[data-theme="dark"] .page-banner .page-banner-img > *:first-child {
      opacity: 0.2872;
    }
  </style>
<section class="page-banner">
    <div class="page-banner-img">
<div style="background-image: url(/paper_notes/assets/images/banner.png)"></div>
        <img class="img-placeholder" src="/paper_notes/assets/images/banner.png">
</div>
    <div class="wrapper">
      <div class="page-banner-inner">
<header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">ã‚ãŸã—ã®ã¹ã‚“ãã‚‡ã†ãƒãƒ¼ãƒˆ</h1>
  <h2 class="post-subtitle">å‹‰å¼·ã—ãŸè«–æ–‡ã‚„æŠ€è¡“ç­‰ã®æƒ…å ±ã‚’Githubã®Issueã«ãƒ¡ãƒ¢ã£ã¦ã„ã‚‹ã²ã¨ã®ãƒ–ãƒ­ã‚°ã€‚
ãã‚Œãªã‚Šã«ãƒ¡ãƒ¢ã®é‡ãŒè“„ç©ã•ã‚Œã¦ããŸã®ã§ã€ä¸€åº¦æ•´ç†ã—ãŸã„ãªã¨æ€ã„ãƒ–ãƒ­ã‚°ã¯ã˜ã‚ã¦ã¿ã¾ã—ãŸï¼
è‡ªç„¶è¨€èªå‡¦ç†(NLP), æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ (RecommenderSystem), Educational Data Mining (EDM), Learning Analytics (LA)ãªã©ã®åˆ†é‡ã®ãƒ¡ãƒ¢ãŒå¤šã„ã¨æ€ã„ã¾ã™ã€‚
æœ€è¿‘ã¯ç‰¹ã«LLMã®å‹‰å¼·ãŒå¤šã‚ã§ã™ :)</h2>

  <div class="post-meta">
    <time class="dt-published" datetime="2025-11-07T00:48:09+00:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Nov 7, 2025
    </time><span class="post-author left-vsplit"><i class="fa fa-pencil"></i> AkihikoWATANABE</span>
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 14 hours 9 mins</span>
  </div></header>
</div>
    </div>
  </section><script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    hashValue = decodeURIComponent(hashValue);
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('off' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<div id="click-to-top" class="click-to-top">
  <i class="fa fa-arrow-up"></i>
</div>
<script>
  (function () {
    const clickToTop = document.getElementById('click-to-top');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 100) {
        clickToTop.classList.add('show')
      }else {
        clickToTop.classList.remove('show')
      }
    });
    clickToTop.addEventListener('click', () => {
      window.smoothScrollTo(0);
    });
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <p>&lt;h2 id=Selected Papers/Blogs&gt; Selected Papers/Blogs&lt;/h2&gt;&lt;div class="visible-content"&gt;
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/UserBased.html" target="_blank" rel="noopener noreferrer">#UserBased</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/interactive.html" target="_blank" rel="noopener noreferrer">#interactive</a></p>

<p><br></p>

<p><span class="issue_date">Issue Date: 2025-11-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3602" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Training Proactive and Personalized LLM Agents, Weiwei Sun+, arXivâ€™25, 2025.11</a>
<span class="snippet"><span>GPT Summary</span>- åŠ¹æœçš„ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã¯ã€ç”Ÿç”£æ€§ã€ç©æ¥µæ€§ã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã®3ã¤ã®æ¬¡å…ƒã‚’æœ€é©åŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã¨ä¸»å¼µã€‚LLMãƒ™ãƒ¼ã‚¹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ã€ŒUserVilleã€ã‚’å°å…¥ã—ã€PPPã¨ã„ã†ãƒãƒ«ãƒã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒ†ã‚£ãƒ–å¼·åŒ–å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚å®Ÿé¨“ã§ã¯ã€PPPã§è¨“ç·´ã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒGPT-5ã«å¯¾ã—ã¦å¹³å‡21.6ãƒã‚¤ãƒ³ãƒˆã®æ”¹å–„ã‚’é”æˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥½ã¿ã«é©å¿œã—ãªãŒã‚‰ã‚¿ã‚¹ã‚¯æˆåŠŸã‚’å‘ä¸Šã•ã›ã‚‹èƒ½åŠ›ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span>&lt;p&gt;AI Agentã«ãŠã„ã¦ãƒ¦ãƒ¼ã‚¶ã¨ã®interactionã‚’é‡è¦–ã—å”åƒã™ã‚‹ã“ã¨ã‚’é‡è¦–ã™ã‚‹ã‚ˆã†ãªRLã‚’ã™ã‚‹æ¨¡æ§˜ã€‚èˆˆå‘³æ·±ã„ã€‚&lt;/p&gt;&lt;p&gt;å…ƒãƒã‚¹ãƒˆ:</span></p>

<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sunweiwei12/status/1986133618880594403?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>

<p>&lt;/p&gt;&lt;/span&gt;<br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<a class="button" href="articles/Test-time%20Learning.html" target="_blank" rel="noopener noreferrer">#Test-time Learning</a></p>

<p><br></p>

<p><span class="issue_date">Issue Date: 2025-11-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3587" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Titans: Learning to Memorize at Test Time, Ali Behrouz+, NeurIPSâ€™25, 2024.12</a>
<span class="snippet"><span>GPT Summary</span>- å†å¸°ãƒ¢ãƒ‡ãƒ«ã¨æ³¨æ„æ©Ÿæ§‹ã‚’çµ„ã¿åˆã‚ã›ãŸæ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«é•·æœŸãƒ¡ãƒ¢ãƒªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€çŸ­æœŸçš„ãªä¾å­˜é–¢ä¿‚ã‚’æ­£ç¢ºã«ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¤ã¤ã€é•·æœŸçš„ãªè¨˜æ†¶ã‚’ä¿æŒã€‚æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ŒTitansã€ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚„å¸¸è­˜æ¨è«–ãªã©ã®ã‚¿ã‚¹ã‚¯ã§å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€2Mã‚’è¶…ãˆã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã«ã‚‚å¯¾å¿œå¯èƒ½ã€‚</span>
<span class="snippet"><span>Comment</span>&lt;p&gt;å…ƒãƒã‚¹ãƒˆ:</span></p>

<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/prakashkagitha/status/1985824715806572564?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>

<p>&lt;/p&gt;&lt;/span&gt;<br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a></p>

<p><br></p>

<p><span class="issue_date">Issue Date: 2025-11-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3586" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open   Software Evolution, Yuxiang Wei+, NeurIPSâ€™25, 2025.02</a>
<span class="snippet"><span>GPT Summary</span>- SWE-RLã¯ã€å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€å®Ÿä¸–ç•Œã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢å·¥å­¦ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚è»½é‡ãªãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®å ±é…¬ã‚’æ´»ç”¨ã—ã€LLMãŒã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®é€²åŒ–ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€é–‹ç™ºè€…ã®æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã‚’è‡ªå¾‹çš„ã«å›å¾©ã—ã¾ã™ã€‚Llama3-SWE-RL-70Bã¯ã€å®Ÿä¸–ç•Œã®GitHubå•é¡Œã«ãŠã„ã¦41.0%ã®è§£æ±ºç‡ã‚’é”æˆã—ã€ä¸­è¦æ¨¡LLMã¨ã—ã¦ã¯æœ€é«˜ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã¾ã—ãŸã€‚ã¾ãŸã€ä¸€èˆ¬åŒ–ã•ã‚ŒãŸæ¨è«–ã‚¹ã‚­ãƒ«ã‚’æŒã¡ã€è¤‡æ•°ã®ãƒ‰ãƒ¡ã‚¤ãƒ³å¤–ã‚¿ã‚¹ã‚¯ã§æ”¹å–„ã•ã‚ŒãŸçµæœã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚SWE-RLã¯ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢å·¥å­¦ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå¼·åŒ–å­¦ç¿’ã®æ–°ãŸãªå¯èƒ½æ€§ã‚’é–‹ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span>&lt;p&gt;å…ƒãƒã‚¹ãƒˆ:</span></p>

<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/prakashkagitha/status/1985824709733503052?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>

<p>&lt;/p&gt;&lt;p&gt;ãƒã‚¤ãƒ³ãƒˆè§£èª¬:</p>

<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1894584315352076608?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>

<p>&lt;/p&gt;&lt;p&gt;è§£èª¬:</p>

<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1894680592081367351?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>

<p>&lt;/p&gt;&lt;/span&gt;<br><br>
&lt;/div&gt;
<button onclick="showMore(0)">more</button></p>
<div class="hidden-content">
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/ObjectDetection.html" target="_blank" rel="noopener noreferrer">#ObjectDetection</a>
<span class="issue_date">Issue Date: 2025-11-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3583" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] YOLOv12: Attention-Centric Real-Time Object Detectors, Yunjie Tian+, NeurIPS'25, 2025.02</a>
<span class="snippet"><span>GPT Summary</span>- YOLOv12ã¯ã€æ³¨æ„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æ´»ç”¨ã—ãŸæ–°ã—ã„YOLOãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€CNNãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®é€Ÿåº¦ã‚’ç¶­æŒã—ã¤ã¤ã€ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ç‰¹ã«ã€YOLOv12-Nã¯T4 GPUä¸Šã§1.64 msã®æ¨è«–é…å»¶ã§40.6%ã®mAPã‚’é”æˆã—ã€YOLOv10-NãŠã‚ˆã³YOLOv11-Nã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚ã¾ãŸã€YOLOv12ã¯RT-DETRã‚„RT-DETRv2ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã€è¨ˆç®—é‡ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’å¤§å¹…ã«å‰Šæ¸›ã—ãªãŒã‚‰ã‚‚é«˜é€Ÿãªå®Ÿè¡Œã‚’å®Ÿç¾ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/prakashkagitha/status/1985824676216783193?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/2D%20(Image).html" target="_blank" rel="noopener noreferrer">#2D (Image)</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/text.html" target="_blank" rel="noopener noreferrer">#text</a>
<a class="button" href="articles/Visual-CoT.html" target="_blank" rel="noopener noreferrer">#Visual-CoT</a>
<span class="issue_date">Issue Date: 2025-11-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3580" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] When Visualizing is the First Step to Reasoning: MIRA, a Benchmark for  Visual Chain-of-Thought, Yiyang Zhou+, arXiv'25, 2025.11</a>
<span class="snippet"><span>GPT Summary</span>- MIRAã¯ã€ä¸­é–“çš„ãªè¦–è¦šç”»åƒã‚’ç”Ÿæˆã—æ¨è«–ã‚’æ”¯æ´ã™ã‚‹æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€å¾“æ¥ã®ãƒ†ã‚­ã‚¹ãƒˆä¾å­˜ã®æ‰‹æ³•ã¨ã¯ç•°ãªã‚Šã€ã‚¹ã‚±ãƒƒãƒã‚„æ§‹é€ å›³ã‚’ç”¨ã„ã‚‹ã€‚546ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å•é¡Œã‚’å«ã¿ã€è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã¯ç”»åƒã¨è³ªå•ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®CoTã€è¦–è¦šçš„ãƒ’ãƒ³ãƒˆã‚’å«ã‚€Visual-CoTã®3ãƒ¬ãƒ™ãƒ«ã‚’ç¶²ç¾…ã€‚å®Ÿé¨“çµæœã¯ã€ä¸­é–“çš„ãªè¦–è¦šçš„æ‰‹ãŒã‹ã‚ŠãŒãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’33.7%å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã€è¦–è¦šæƒ…å ±ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://mira-benchmark.github.io/" target="_blank" rel="noopener noreferrer">https://mira-benchmark.github.io/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1985915113161871793?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Visual CoT</p>
<p>Frontierãƒ¢ãƒ‡ãƒ«ç¾¤ã§ã‚‚Acc.ãŒ20%æœªæº€ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ï¼ˆVision QA)ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚<br><br>æ‰‹ä½œæ¥­ã§ä½œæˆã•ã‚Œã¦ãŠã‚Šã€Visual CoTç”¨ã®single/multi stepã®intermediate imagesã‚‚ä½œæˆã•ã‚Œã¦ã„ã‚‹ã€‚èˆˆå‘³æ·±ã„ã€‚</p>
<p>VLMã«ãŠã„ã¦ã€{few, many}-shotãŒã†ã¾ãã„ãå ´åˆï¼ˆGeminiã®ã‚ˆã†ãªãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªãƒ¢ãƒ‡ãƒ«ã¯shotæ•°ã«å¿œã˜ã¦æ€§èƒ½å‘ä¸Šã€ä¸€æ–¹Llamaã®ã‚ˆã†ãªOpenWeightãƒ¢ãƒ‡ãƒ«ã¯æ©æµãŒãªã„ï¼‰ã¨<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3467" target="_blank" rel="noopener noreferrer">[Paper Note] Many-Shot In-Context Learning in Multimodal Foundation Models, Yixing Jiang+, arXiv'24, 2024.05</a>
<br><br>ã†ã¾ãã„ã‹ãªã„ã‚±ãƒ¼ã‚¹ï¼ˆäº‹å‰è¨“ç·´ã§é€šå¸¸è¦‹ã‚‰ã‚Œãªã„åˆ†å¸ƒå¤–ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ç”»åƒã§ã¯ICLãŒã†ã¾ãã„ã‹ãªã„ï¼‰<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3460" target="_blank" rel="noopener noreferrer">[Paper Note] Roboflow100-VL: A Multi-Domain Object Detection Benchmark for   Vision-Language Models, Peter Robicheaux+, NeurIPS'25, 2025.05</a>
<br><br>ã‚‚å ±å‘Šã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>ãŠãã‚‰ãäº‹å‰å­¦ç¿’æ®µéšã§å½“è©²ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ç”»åƒãŒå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ã©ã‚Œã ã‘å«ã¾ã‚Œã¦ã„ã‚‹ã‹ã€ãŠã‚ˆã³ã€ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã®alignmentãŒã¨ã‚Œã¦ã„ã¦ã€ç”»åƒ-ãƒ†ã‚­ã‚¹ãƒˆé–“ã®çŸ¥è­˜ã‚’æ´»ç”¨ã§ãã‚‹çŠ¶æ…‹ã«ãªã£ã¦ã„ã‚‹ã“ã¨ãŒå¿…è¦ãªã®ã§ã¯ã€ã¨ã„ã†æ°—ã¯ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-11-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3574" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Block Diffusion: Interpolating Between Autoregressive and Diffusion  Language Models, Marianne Arriola+, ICLR'25, 2025.03</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ–ãƒ­ãƒƒã‚¯æ‹¡æ•£è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¨è‡ªå·±å›å¸°ãƒ¢ãƒ‡ãƒ«ã®åˆ©ç‚¹ã‚’çµ„ã¿åˆã‚ã›ã€æŸ”è»Ÿãªé•·ã•ã®ç”Ÿæˆã‚’å¯èƒ½ã«ã—ã€æ¨è«–åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚åŠ¹ç‡çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚„ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ææ¡ˆã—ã€è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ–°ãŸãªæœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>è§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1987" target="_blank" rel="noopener noreferrer">ã€DLè¼ªèª­ä¼šã€‘ Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models, Deep Learning JP, 2025.05</a>
</p>
<p>openreview:


<a href="https://openreview.net/forum?id=tyEyYT267x" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=tyEyYT267x</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-11-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3569" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On Powerful Ways to Generate: Autoregression, Diffusion, and Beyond, Chenxiao Yang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±å›å¸°çš„ãªæ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã¨ãƒã‚¹ã‚¯ã•ã‚ŒãŸæ‹¡æ•£ã‚’è¶…ãˆãŸç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã‚’ç ”ç©¶ã—ã€ãã®åˆ©ç‚¹ã¨é™ç•Œã‚’å®šé‡åŒ–ã€‚æ›¸ãæ›ãˆã‚„é•·ã•å¯å¤‰ã®ç·¨é›†ãŒå¯èƒ½ã«ãªã‚‹ã“ã¨ã§ã€ç†è«–çš„ãŠã‚ˆã³å®Ÿè¨¼çš„ãªåˆ©ç‚¹ã‚’ç¤ºã—ã€è‡ªç„¶è¨€èªä»¥å¤–ã®é ˜åŸŸã§ã‚‚æ©Ÿèƒ½ã™ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®é‡è¦æ€§ã‚’å¼·èª¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chenxiao_yang_/status/1985457774969405921?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/ConceptErasure.html" target="_blank" rel="noopener noreferrer">#ConceptErasure</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-11-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3563" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Intrinsic Test of Unlearning Using Parametric Knowledge Traces, Yihuai Hong+, EMNLP'25, 2024.06</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹ã€Œå¿˜å´ã€ã‚¿ã‚¹ã‚¯ã®é‡è¦æ€§ãŒé«˜ã¾ã£ã¦ã„ã‚‹ãŒã€ç¾åœ¨ã®è©•ä¾¡æ‰‹æ³•ã¯è¡Œå‹•ãƒ†ã‚¹ãƒˆã«ä¾å­˜ã—ã¦ãŠã‚Šã€ãƒ¢ãƒ‡ãƒ«å†…ã®æ®‹å­˜çŸ¥è­˜ã‚’ç›£è¦–ã—ã¦ã„ãªã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€å¿˜å´è©•ä¾¡ã«ãŠã„ã¦ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãªçŸ¥è­˜ã®å¤‰åŒ–ã‚’è€ƒæ…®ã™ã‚‹å¿…è¦æ€§ã‚’ä¸»å¼µã—ã€èªå½™æŠ•å½±ã‚’ç”¨ã„ãŸè©•ä¾¡æ–¹æ³•è«–ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ConceptVectorsã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€æ—¢å­˜ã®å¿˜å´æ‰‹æ³•ãŒæ¦‚å¿µãƒ™ã‚¯ãƒˆãƒ«ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’è©•ä¾¡ã—ãŸã€‚çµæœã€çŸ¥è­˜ã‚’ç›´æ¥æ¶ˆå»ã™ã‚‹ã“ã¨ã§ãƒ¢ãƒ‡ãƒ«ã®æ„Ÿå—æ€§ãŒä½ä¸‹ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€ä»Šå¾Œã®ç ”ç©¶ã«ãŠã„ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åŸºã¥ãè©•ä¾¡ã®å¿…è¦æ€§ãŒå¼·èª¿ã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/megamor2/status/1985321067422871563?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<a class="button" href="articles/train-inference-gap.html" target="_blank" rel="noopener noreferrer">#train-inference-gap</a>
<span class="issue_date">Issue Date: 2025-11-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3532" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Defeating the Training-Inference Mismatch via FP16, Penghui Qi+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹ä¸å®‰å®šæ€§ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒãƒªã‚·ãƒ¼ã¨æ¨è«–ãƒãƒªã‚·ãƒ¼ã®æ•°å€¤çš„ä¸ä¸€è‡´ã«èµ·å› ã™ã‚‹ã€‚å¾“æ¥ã®å¯¾ç­–ã¯åŠ¹æœãŒè–„ã‹ã£ãŸãŒã€æœ¬ç ”ç©¶ã§ã¯FP16ã«æˆ»ã™ã“ã¨ã§ã“ã®å•é¡Œã‚’è§£æ±ºã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã“ã®å¤‰æ›´ã¯ç°¡å˜ã§ã€ãƒ¢ãƒ‡ãƒ«ã‚„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ä¿®æ­£ã‚’å¿…è¦ã¨ã›ãšã€å®‰å®šã—ãŸæœ€é©åŒ–ã¨é€Ÿã„åæŸã‚’å®Ÿç¾ã—ã€å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã§å¼·åŠ›ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mavenlin/status/1984130875307782257?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>RLå­¦ç¿’æ™‚ã®æµ®å‹•å°æ•°ç‚¹æ•°è¡¨ç¾ã‚’bf16ã‹ã‚‰fp16ã«å¤‰æ›´ã™ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªå¤‰æ›´ã§ã€è¨“ç·´-æ¨è«–æ™‚ã®gapãŒå°ã•ããªã‚Šå­¦ç¿’ãŒæ”¹å–„ã™ã‚‹ã€ã¨ã„ã†è©±ã‚‰ã—ã„ã€‚</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dimitrispapail/status/1984286681022050373?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1984470768688759000?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1984395743696994736?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1984750121255313462?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>verlã¯FP16ã§ã®å­¦ç¿’ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ã®ã§è‘—è€…ãŒãƒ‘ãƒƒãƒã‚’å‡ºã—ãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/qphutu/status/1984268030558519737?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/CrossLingual.html" target="_blank" rel="noopener noreferrer">#CrossLingual</a>
<a class="button" href="articles/TransferLearning.html" target="_blank" rel="noopener noreferrer">#TransferLearning</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3525" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ATLAS: Adaptive Transfer Scaling Laws for Multilingual Pretraining,  Finetuning, and Decoding the Curse of Multilinguality, Shayne Longpre+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€774ã®å¤šè¨€èªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿé¨“ã‚’é€šã˜ã¦ã€æœ€å¤§ã®å¤šè¨€èªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’æ¢æ±‚ã—ã€ATLASã¨ã„ã†é©å¿œçš„è»¢é€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’å°å…¥ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ—¢å­˜ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€å¤šè¨€èªå­¦ç¿’ã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚„è¨€èªé–“ã®è»¢é€ç‰¹æ€§ã‚’åˆ†æã€‚è¨€èªãƒšã‚¢é–“ã®ç›¸äº’åˆ©ç›Šã‚¹ã‚³ã‚¢ã‚’æ¸¬å®šã—ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨ãƒ‡ãƒ¼ã‚¿ã®æœ€é©ãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ–¹æ³•ã‚’æ˜ã‚‰ã‹ã«ã—ã€äº‹å‰å­¦ç¿’ã¨ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®è¨ˆç®—çš„ã‚¯ãƒ­ã‚¹ã‚ªãƒ¼ãƒãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’ç‰¹å®šã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è‹±èªä¸­å¿ƒã®AIã‚’è¶…ãˆãŸãƒ¢ãƒ‡ãƒ«ã®åŠ¹ç‡çš„ãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®åŸºç›¤ã‚’æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shayneredford/status/1983170949865173069?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p><img src="https://github.com/user-attachments/assets/381375e6-ca49-4bc0-8347-2bc6724cf9a7" alt="image" loading="lazy"><br><br>ãƒã‚¤ãƒªãƒ³ã‚¬ãƒ«ã§å­¦ç¿’ã—ãŸæ™‚ã«ã€æ—¥æœ¬èªã¨ã‚·ãƒŠã‚¸ãƒ¼ã®ã‚ã‚‹è¨€èªã€ã“ã®å›³ã‚’è¦‹ã‚‹ã¨ç„¡ã•ãã†ã«è¦‹ãˆã‚‹ğŸ˜…</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/RecurrentModels.html" target="_blank" rel="noopener noreferrer">#RecurrentModels</a>
<a class="button" href="articles/RecursiveModels.html" target="_blank" rel="noopener noreferrer">#RecursiveModels</a>
<span class="issue_date">Issue Date: 2025-10-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3514" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Latent Reasoning via Looped Language Models, Rui-Jie Zhu+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Ouroã¯ã€æ¨è«–ã‚’äº‹å‰è¨“ç·´ãƒ•ã‚§ãƒ¼ã‚ºã«çµ„ã¿è¾¼ã‚€ã“ã¨ã‚’ç›®æŒ‡ã—ãŸãƒ«ãƒ¼ãƒ—è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLoopLMï¼‰ã§ã‚ã‚Šã€åå¾©è¨ˆç®—ã‚„ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ­£å‰‡åŒ–ã‚’é€šã˜ã¦æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚1.4BãŠã‚ˆã³2.6Bãƒ¢ãƒ‡ãƒ«ã¯ã€æœ€å¤§12Bã®æœ€å…ˆç«¯LLMã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€çŸ¥è­˜æ“ä½œèƒ½åŠ›ã®å‘ä¸ŠãŒãã®è¦å› ã§ã‚ã‚‹ã“ã¨ã‚’å®Ÿé¨“ã§ç¢ºèªã€‚LoopLMã¯æ˜ç¤ºçš„ãªCoTã‚ˆã‚Šã‚‚æ•´åˆã—ãŸæ¨è«–ã‚’ç”Ÿæˆã—ã€æ¨è«–ã®æ–°ãŸãªã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§æä¾›ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://ouro-llm.github.io" target="_blank" rel="noopener noreferrer">https://ouro-llm.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ziniuli/status/1983765674699915767?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1984286236438094307?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>åŸºæœ¬æ§‹é€ ã¯decoder-only transformerã§<br>- Multi-Head Attention<br>- RoPE<br>- SwiGLUæ´»æ€§åŒ–<br>- Sandwich Normalization<br>ãŒä½¿ã‚ã‚Œã¦ã„ã‚‹LoopedTransformerã§ã€exit gateã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§æ—©æœŸã«loopã‚’æ‰“ã¡åˆ‡ã‚Šã€å‡ºåŠ›ã‚’ã™ã‚‹ã“ã¨ã§ã‚³ã‚¹ãƒˆã‚’ç¯€ç´„ã§ãã‚‹ã‚ˆã†ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ãªã£ã¦ã„ã‚‹ã€‚<br><br>ã‚ˆã‚Šå°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§ã€ã‚ˆã‚Šå¤§ããªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã™ï¼ˆTable7,8ï¼‰ã€‚ã¾ãŸã€Tã‚’å¢—ã‚„ã™ã¨ãƒ¢ãƒ‡ãƒ«ã®å®‰å…¨æ€§ã‚‚å¢—ã™ï¼ˆï¼æœ‰å®³ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è­˜åˆ¥åŠ›ãŒå¢—ã™ï¼‰ã€‚ãã®ä»£ã‚ã‚Šã€å†å¸°æ•°Tã‚’å¤§ããã™ã‚‹ã¨FLOPsãŒTå€ã«ãªã‚‹ã®ã§ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã¯è‰¯ã„ãŒè¨ˆç®—åŠ¹ç‡ã¯æ‚ªã„ã€‚<br><br>linear probingã§å†å¸°ã®æ¬¡ã‚¹ãƒ†ãƒƒãƒ—äºˆæ¸¬ã‚’ã—ãŸã¨ã“ã‚æµ…ã„æ®µéšã§ã¯äºˆæ¸¬ãŒä¸ä¸€è‡´ã«ãªã‚‹ãŸã‚ã€æ€è€ƒãŒé€²åŒ–ã—ã¦ã„ã£ã¦ã„ã‚‹ã®ã§ã¯ãªã„ã‹ã€ã¨ã„ã†è€ƒå¯ŸãŒã‚ã‚‹ã€‚<br><br>ã¾ãŸã€å†å¸°æ•°Tã‚’4ã§å­¦ç¿’ã—ãŸå ´åˆã«ã€inferenceæ™‚ã«Tã‚’5--8ã«ã—ã¦ã‚‚ã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„(Table10)ã€‚<br><br>ã¾ãŸAppendix D.1ã«ãŠã„ã¦ã€é€šå¸¸ã®transformerã®LoopLMã‚’æ¯”è¼ƒã—ã€5ç¨®é¡ã®å¤§ãã•ã®ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§æ¯”è¼ƒã€‚é€šå¸¸ã®transformerã§ã¯ãƒ«ãƒ¼ãƒ—ã•ã›ã‚‹ä»£ã‚ã‚Šã«å®Ÿéš›ã«å±¤ã®æ•°ã‚’å¢—ã‚„ã™ã“ã¨ã§ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’æƒãˆã¦å®Ÿé¨“ã—ãŸã¨ã“ã‚ã€é€šå¸¸ã®transformerã®æ–¹ãŒå¸¸ã«æ€§èƒ½ãŒè‰¯ãã€loopLMã¯å†å¸°æ•°ã‚’å¢—ã‚„ã—ã¦ã‚‚ã‚¹ã‚±ãƒ¼ãƒ«ã›ãšã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã«ã¤ã‚Œã¦å·®ãŒãªããªã£ã¦ã„ãã€ã¨ã„ã†ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã®é¢ã§ã¯æ®‹å¿µãªçµæœã«çµ‚ã‚ã£ã¦ã„ã‚‹ã‚ˆã†ã ã€‚<br><br>ã¨ã„ã£ãŸè©±ãŒè§£èª¬ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹ã€‚å…ƒè«–æ–‡ã¯å®Œå…¨ã«skim readingã—ã¦è§£èª¬ãƒã‚¹ãƒˆã‚’ä¸»ã«èª­ã‚“ã ã®ã§èª¤ã‚ŠãŒå«ã¾ã‚Œã‚‹ã‹ã‚‚ã—ã‚Œãªã„ç‚¹ã«ã¯æ³¨æ„ã€‚</p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3502" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Language Models are Injective and Hence Invertible, Giorgos Nikolaou+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼è¨€èªãƒ¢ãƒ‡ãƒ«ãŒå˜å°„ã§ã‚ã‚‹ã“ã¨ã‚’æ•°å­¦çš„ã«è¨¼æ˜ã—ã€ç•°ãªã‚‹å…¥åŠ›ãŒåŒã˜å‡ºåŠ›ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚Œãªã„ã“ã¨ã‚’ç¤ºã™ã€‚ã•ã‚‰ã«ã€6ã¤ã®æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦è¡çªãƒ†ã‚¹ãƒˆã‚’è¡Œã„ã€è¡çªãŒãªã„ã“ã¨ã‚’ç¢ºèªã€‚æ–°ãŸã«ææ¡ˆã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ SipItã«ã‚ˆã‚Šã€éš ã‚ŒãŸæ´»æ€§åŒ–ã‹ã‚‰æ­£ç¢ºãªå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’åŠ¹ç‡çš„ã«å†æ§‹ç¯‰ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã€å˜å°„æ€§ãŒè¨€èªãƒ¢ãƒ‡ãƒ«ã®é‡è¦ãªç‰¹æ€§ã§ã‚ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tpimentelms/status/1982857658450489704?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¶šå ±:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gladialab/status/1983812121713418606?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1984411703459889390?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/German.html" target="_blank" rel="noopener noreferrer">#German</a>
<span class="issue_date">Issue Date: 2025-10-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3477" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The German Commons - 154 Billion Tokens of Openly Licensed Text for  German Language Models, Lukas Gienapp+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ã€ŒGerman Commonsã€ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ãƒ‰ã‚¤ãƒ„èªãƒ†ã‚­ã‚¹ãƒˆã®æœ€å¤§ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã§ã€41ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰1545.6å„„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æä¾›ã€‚æ³•å¾‹ã€ç§‘å­¦ã€æ–‡åŒ–ãªã©7ã¤ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’å«ã¿ã€å“è³ªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚„é‡è¤‡æ’é™¤ã‚’è¡Œã„ã€ä¸€è²«ã—ãŸå“è³ªã‚’ç¢ºä¿ã€‚ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã¯æ³•çš„éµå®ˆã‚’ä¿è¨¼ã—ã€çœŸã«ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒ‰ã‚¤ãƒ„èªãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºã‚’æ”¯æ´ã€‚å†ç¾å¯èƒ½ã§æ‹¡å¼µå¯èƒ½ãªã‚³ãƒ¼ãƒ‘ã‚¹æ§‹ç¯‰ã®ãŸã‚ã®ã‚³ãƒ¼ãƒ‰ã‚‚å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/datasets/coral-nlp/german-commons" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/coral-nlp/german-commons</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webis_de/status/1982794705302655243?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æœ€å¤§ç´šï¼ˆ154B)ã®ãƒ‰ã‚¤ãƒ„èªã®LLMï¼ˆäº‹å‰ï¼‰å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‰ã—ã„</p>
<p>ODC-By Licence</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/LongHorizon.html" target="_blank" rel="noopener noreferrer">#LongHorizon</a>
<span class="issue_date">Issue Date: 2025-10-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3455" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] R-Horizon: How Far Can Your Large Reasoning Model Really Go in Breadth  and Depth?, Yi Lu+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- R-HORIZONã‚’ææ¡ˆã—ã€é•·æœŸçš„ãªæ¨è«–è¡Œå‹•ã‚’åˆºæ¿€ã™ã‚‹æ‰‹æ³•ã‚’é€šã˜ã¦ã€LRMã®è©•ä¾¡ã‚’æ”¹å–„ã€‚è¤‡é›‘ãªãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—æ¨è«–ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æ§‹ç¯‰ã—ã€LRMã®æ€§èƒ½ä½ä¸‹ã‚’æ˜ã‚‰ã‹ã«ã€‚R-HORIZONã‚’ç”¨ã„ãŸå¼·åŒ–å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆRLVRï¼‰ã¯ã€ãƒãƒ«ãƒãƒ›ãƒ©ã‚¤ã‚ºãƒ³æ¨è«–ã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã€æ¨™æº–çš„ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã®ç²¾åº¦ã‚‚å‘ä¸Šã€‚AIME2024ã§7.5ã®å¢—åŠ ã‚’é”æˆã€‚R-HORIZONã¯LRMã®é•·æœŸæ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®æœ‰åŠ¹ãªãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã¨ä½ç½®ä»˜ã‘ã‚‰ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://reasoning-horizon.github.io" target="_blank" rel="noopener noreferrer">https://reasoning-horizon.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1982608933563826270?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>long horizonã‚¿ã‚¹ã‚¯ã«ã†ã¾ãæ±åŒ–ã™ã‚‹æ çµ„ã¿ã®å¿…è¦æ€§ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚long horizonãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã—ã¦ã€post trainingã‚’ã™ã‚‹ã¨ã„ã†æ çµ„ã¿ã¯çŸ­æœŸçš„ã«ã¯å¼·åŠ›ã§ã‚‚ã™ãã«è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã®è¦³ç‚¹ã‹ã‚‰ã™ãã«ç¾å®Ÿçš„ã«ã¯èƒ½åŠ›ã‚’ä¼¸ã°ã›ãªããªã‚‹ã®ã§ã¯ã€‚</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1982875191303713019?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Science.html" target="_blank" rel="noopener noreferrer">#Science</a>
<span class="issue_date">Issue Date: 2025-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3447" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic  Scientific Workflows, Qiushi Sun+, arXiv'25, 2025.05</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’æ´»ç”¨ã—ãŸScienceBoardã‚’ç´¹ä»‹ã€‚ã“ã‚Œã¯ã€ç§‘å­¦çš„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’åŠ é€Ÿã™ã‚‹ãŸã‚ã®å‹•çš„ãªãƒãƒ«ãƒãƒ‰ãƒ¡ã‚¤ãƒ³ç’°å¢ƒã¨ã€169ã®å³å¯†ã«æ¤œè¨¼ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã‹ã‚‰ãªã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æä¾›ã€‚å¾¹åº•çš„ãªè©•ä¾¡ã«ã‚ˆã‚Šã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ã®ä¿¡é ¼æ€§ãŒä½ãã€æˆåŠŸç‡ã¯15%ã«ã¨ã©ã¾ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é™ç•Œã‚’å…‹æœã—ã€ã‚ˆã‚ŠåŠ¹æœçš„ãªè¨­è¨ˆåŸå‰‡ã‚’æ¨¡ç´¢ã™ã‚‹ãŸã‚ã®æ´å¯ŸãŒå¾—ã‚‰ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1981843555267088553?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj gage:


<a href="https://qiushisun.github.io/ScienceBoard-Home/" target="_blank" rel="noopener noreferrer">https://qiushisun.github.io/ScienceBoard-Home/</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-10-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3429" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Blackbox Model Provenance via Palimpsestic Membership Inference, Rohith Kuditipudi+, NeurIPS'25 Spotlight, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¢ãƒªã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ãƒœãƒ–ãŒãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹éš›ã€ã‚¢ãƒªã‚¹ã¯ãƒœãƒ–ãŒå½¼å¥³ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã‚’è¨¼æ˜ã§ãã‚‹ã‹ã‚’æ¤œè¨ã€‚ã‚¯ã‚¨ãƒªè¨­å®šã¨è¦³å¯Ÿè¨­å®šã®2ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€ãƒœãƒ–ã®ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ†ã‚­ã‚¹ãƒˆã¨ã‚¢ãƒªã‚¹ã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®é †åºã¨ã®ç›¸é–¢ã‚’èª¿æŸ»ã€‚40ä»¥ä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã€på€¤ãŒ1e-8ã«é”ã™ã‚‹çµæœã‚’å¾—ãŸã€‚è¦³å¯Ÿè¨­å®šã§ã¯ã€ãƒœãƒ–ã®ãƒ†ã‚­ã‚¹ãƒˆã®å°¤åº¦ã‚’æ¨å®šã™ã‚‹2ã¤ã®æ–¹æ³•ã‚’è©¦ã—ã€æ•°ç™¾ãƒˆãƒ¼ã‚¯ãƒ³ã§ã®åŒºåˆ¥ãŒå¯èƒ½ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã€æ•°åä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å¿…è¦ã¨ã™ã‚‹é«˜ãƒ‘ãƒ¯ãƒ¼ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¯”è¼ƒã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/percyliang/status/1981612361309098383?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯ã™ã”ã„è©±ã â€¦</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3393" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Memory Layers at Scale, Vincent-Pierre Berges+, ICLR'25, 2024.12</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ¡ãƒ¢ãƒªå±¤ã¯ã€è¨ˆç®—è² è·ã‚’å¢—ã‚„ã•ãšã«ãƒ¢ãƒ‡ãƒ«ã«è¿½åŠ ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åŠ ãˆã‚‹ãŸã‚ã®å­¦ç¿’å¯èƒ½ãªæ¤œç´¢ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä½¿ç”¨ã—ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ã«æ´»æ€§åŒ–ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªå±¤ãŒå¯†ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰å±¤ã‚’è£œå®Œã—ã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ”¹è‰¯ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªå±¤ã‚’ç”¨ã„ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ãŒã€è¨ˆç®—äºˆç®—ãŒ2å€ã®å¯†ãªãƒ¢ãƒ‡ãƒ«ã‚„åŒç­‰ã®è¨ˆç®—ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæ··åˆãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ç‰¹ã«äº‹å®Ÿã«åŸºã¥ãã‚¿ã‚¹ã‚¯ã§ã®æ€§èƒ½å‘ä¸ŠãŒé¡•è‘—ã§ã‚ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã—ãŸã€‚å®Œå…¨ã«ä¸¦åˆ—åŒ–å¯èƒ½ãªãƒ¡ãƒ¢ãƒªå±¤ã®å®Ÿè£…ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ç¤ºã—ã€1å…†ãƒˆãƒ¼ã‚¯ãƒ³ã¾ã§ã®äº‹å‰å­¦ç¿’ã‚’è¡Œã£ãŸçµæœã€æœ€å¤§8Bã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=ATqGm1WyDj" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=ATqGm1WyDj</a>


</p>
<p>transformerã«ãŠã‘ã‚‹FFNã‚’ãƒ¡ãƒ¢ãƒªãƒ¬ã‚¤ãƒ¤ãƒ¼ã«ç½®ãæ›ãˆã‚‹ã“ã¨ã§ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’å¢—ã‚„ã—ãªãŒã‚‰è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã‚‹ã‚ˆã†ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã‚ˆã†ã§ã‚ã‚‹ã€‚ãƒ¡ãƒ¢ãƒªãƒ¬ã‚¤ãƒ¤ãƒ¼ã¯ã€ã‚¯ã‚¨ãƒªqã‚’å¾—ãŸæ™‚ã«top kã®kvã‚’lookupã—ï¼ˆï¼ã“ã“ã§è¨ˆç®—å¯¾è±¡ã¨ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚¹ãƒ‘ãƒ¼ã‚¹ã«ãªã‚‹ï¼‰ã€kqã‹ã‚‰æ±‚ã‚ãŸattention scoreã§vã‚’åŠ é‡å¹³å‡ã™ã‚‹ã“ã¨ã§å‡ºåŠ›ã‚’å¾—ã‚‹ã€‚Memory+ã¨ã„ã†ã•ã‚‰ãªã‚‹æ”¹è‰¯ã‚’åŠ ãˆãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã¯ã€å…¥åŠ›ã«å¯¾ã—ã¦siluã«ã‚ˆã‚‹gatingã¨linearãªå¤‰æ›ã‚’è¿½åŠ ã§å®Ÿæ–½ã™ã‚‹ã“ã¨ã§å‡ºåŠ›ã‚’å¾—ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/e935fc48-b606-47fd-aa74-047b87200779" alt="image" loading="lazy"><br><br>denseãªãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦æ€§èƒ½ãŒé«˜ãã€ãƒ¡ãƒ¢ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™ã¨æ€§èƒ½ãŒã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/b4f74591-1ecc-4871-bdf4-4cc13274e7c4" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/SpeciarizedBrainNetworks.html" target="_blank" rel="noopener noreferrer">#SpeciarizedBrainNetworks</a>
<a class="button" href="articles/Neuroscience.html" target="_blank" rel="noopener noreferrer">#Neuroscience</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3376" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Mixture of Cognitive Reasoners: Modular Reasoning with Brain-Like  Specialization, Badr AlKhamissi+, arXiv'25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- MiCRoã¯ã€è„³ã®èªçŸ¥ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«åŸºã¥ãå°‚é–€å®¶ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æŒã¤ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®å±¤ã‚’4ã¤ã®å°‚é–€å®¶ã«åˆ†å‰²ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è§£é‡ˆå¯èƒ½ã§å› æœçš„ãªå°‚é–€å®¶ã®å‹•çš„åˆ¶å¾¡ãŒå¯èƒ½ã«ãªã‚Šã€æ©Ÿæ¢°å­¦ç¿’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã€‚äººé–“ã‚‰ã—ãè§£é‡ˆå¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://cognitive-reasoners.epfl.ch" target="_blank" rel="noopener noreferrer">https://cognitive-reasoners.epfl.ch</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bkhmsi/status/1980239452091056532?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦post-trainingã«ã‚ˆã£ã¦ã€è„³ã«ç€æƒ³ã‚’å¾—ã¦ä»¥ä¸‹ã®4ã¤ã‚’distinctãªèªçŸ¥ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ï¼ˆã©ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹ã‹ã‚’æ±ºå®šã™ã‚‹Routerä»˜ãã§ï¼‰å­¦ç¿’ã™ã‚‹ã€‚<br>- Language<br>- Logic / Multiple Demand<br>- Social / Theory of Mind<br>- World / Default Mode Network<br><br>ã“ã‚Œã«ã‚ˆã‚ŠAIã¨NeuroscienceãŒbridgeã•ã‚Œã€MLã‚µã‚¤ãƒ‰ã§ã¯ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆæ€§ãŒå‘ä¸Šã—ã€Cognitiveå´ã§ã¯ã€è¤‡é›‘ãªæŒ™å‹•ãŒèµ·ããŸæ™‚ã«ã©ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå¯„ä¸ã—ã¦ã„ã‚‹ã‹ã‚’probingã™ã‚‹ãƒ†ã‚¹ãƒˆãƒ™ãƒƒãƒ‰ã¨ãªã‚‹ã€‚<br><br>ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®denseãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦ã€è§£é‡ˆæ€§ã‚’é«˜ã‚ãªãŒã‚‰æ€§èƒ½ãŒå‘ä¸Šã—ã€äººé–“ã®è¡Œå‹•ã¨ã‚ˆã‚Šalignã—ã¦ã„ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã¾ãŸã€layerã‚’åˆ†æã™ã‚‹ã¨æµ…ã„å±¤ã§ã¯è¨€èªã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã•ã‚Œã‚‹å‚¾å‘ãŒå¼·ãã€æ·±ã„å±¤ã§ã¯domainã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã•ã‚Œã‚‹å‚¾å‘ãŒå¼·ããªã‚‹ã‚ˆã†ãªäººé–“ã®è„³ã¨ä¼¼ãŸã‚ˆã†ãªå‚¾å‘ãŒè¦³å¯Ÿã•ã‚ŒãŸã€‚<br><br>ã¾ãŸã€neuroscienceã®functional localizerï¼ˆè„³ã®ã©ã®éƒ¨ä½ãŒç‰¹å®šã®æ©Ÿèƒ½ã‚’æœãŸã—ã¦ã„ã‚‹ã®ã‹ã‚’ç‰¹å®šã™ã‚‹ã‚ˆã†ãªå–ã‚Šçµ„ã¿ï¼‰ã«ç€æƒ³ã‚’å¾—ã¦ã€é¡ä¼¼ã—ãŸlocalizerãŒæœ¬ãƒ¢ãƒ‡ãƒ«ã«ã‚‚é©ç”¨ã§ãã€ç‰¹å®šã®æ©Ÿèƒ½ã«å¯¾ã—ã¦ã©ã®expertãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒã©ã‚Œã ã‘æ´»æ€§åŒ–ã—ã¦ã„ã‚‹ã‹ã‚’å¯è¦–åŒ–ã§ããŸã€‚<br><br>ã¨ã„ã£ãŸã‚ˆã†ãªè©±ãŒè‘—è€…ãƒã‚¹ãƒˆã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚èˆˆå‘³æ·±ã„ã€‚</p>
<p>demo:


<a href="https://huggingface.co/spaces/bkhmsi/cognitive-reasoners" target="_blank" rel="noopener noreferrer">https://huggingface.co/spaces/bkhmsi/cognitive-reasoners</a>


<br>HF:


<a href="https://huggingface.co/collections/bkhmsi/mixture-of-cognitive-reasoners" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/bkhmsi/mixture-of-cognitive-reasoners</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/VariationalAutoEncoder.html" target="_blank" rel="noopener noreferrer">#VariationalAutoEncoder</a>
<a class="button" href="articles/ICCV.html" target="_blank" rel="noopener noreferrer">#ICCV</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3373" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OminiControl: Minimal and Universal Control for Diffusion Transformer, Zhenxiong Tan+, ICCV'25 Highlight, 2024.11</a>
<span class="snippet"><span>GPT Summary</span>- OminiControlã¯ã€Diffusion Transformerï¼ˆDiTï¼‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ãŠã‘ã‚‹ç”»åƒæ¡ä»¶ä»˜ã‘ã®æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’æœ€å°é™ã«æŠ‘ãˆã¤ã¤ã€æŸ”è»Ÿãªãƒˆãƒ¼ã‚¯ãƒ³ç›¸äº’ä½œç”¨ã¨å‹•çš„ãªä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å®Ÿç¾ã€‚åºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€è¤‡æ•°ã®æ¡ä»¶ä»˜ã‘ã‚¿ã‚¹ã‚¯ã§å°‚é–€çš„æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€åˆæˆã•ã‚ŒãŸç”»åƒãƒšã‚¢ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒSubjects200Kã€ã‚’å°å…¥ã€‚åŠ¹ç‡çš„ã§å¤šæ§˜ãªç”»åƒç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yxy2168/status/1980244155667476923?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>DiTã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ï¼ˆMMAä»¥å¤–ã¯ï¼‰å¤‰æ›´ã›ãšã«ã€Condition Image C_Iã‚’VAEã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸnoisy inputã‚’DiTã®inputã«concatã—é †ä¼æ’­ã•ã›ã‚‹ã“ã¨ã§ã€DiTã‚’unified conditioningãƒ¢ãƒ‡ãƒ«ï¼ˆï¼C_Iã®ç‰¹å¾´é‡ã‚’ä»–ã®inputã¨åŒã˜latent spaceã§å­¦ç¿’ã•ã›çµ±åˆçš„ã«æ‰±ã†ï¼‰ã¨ã—ã¦å­¦ç¿’ã™ã‚‹[^1]ã€‚<br><br>[^1]: æ—¢å­˜ç ”ç©¶ã¯åˆ¥ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‹ã‚‰ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸfeatureãŒåŠ ç®—ã•ã‚Œã¦ã„ã¦ï¼ˆå¼3ï¼‰ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€éƒ¨åˆ†ã«åˆ¥é€”ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¿…è¦ã ã£ãŸã ã‘ã§ãªãã€åŠ ç®—ã¯ç©ºé–“çš„ãªå¯¾å¿œé–¢ä¿‚ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã†ã¾ãå¯¾å‡¦ã§ããšï¼ˆfeatureã®æ¬¡å…ƒãŒç©ºé–“çš„ãªæƒ…å ±ã«å¯¾å¿œã—ã¦ã„ã‚‹ãŸã‚ï¼‰ã€conditional tokenã¨imageã®äº¤äº’ä½œç”¨ã‚’å¦¨ã’ã¦ã„ãŸã€‚<br><br>ã¾ãŸã€positional encodingã®indexã‚’conditional tokenã¨noisy image tokensã¨å…±æœ‰ã™ã‚‹ã¨ã€ç©ºé–“çš„ãªå¯¾å¿œé–¢ä¿‚ãŒå­˜åœ¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ï¼ˆedge guided generationç­‰ï¼‰ã¯ã†ã¾ãã„ã£ãŸãŒã€è¢«å†™ä½“ã‚’æŒ‡å®šã™ã‚‹ç”Ÿæˆï¼ˆsubject driven generation)ã®ã‚ˆã†ãªå¯¾å¿œé–¢ä¿‚ãŒå­˜åœ¨ã—ãªã„ã‚¿ã‚¹ã‚¯ï¼ˆnon-aligned task)ã®å ´åˆã¯ã†ã¾ãã„ã‹ãªã‹ã£ãŸã€‚ã—ã‹ã—ã€non-aligned taskã®å ´åˆã¯ã€indexã«ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’åŠ ãˆã‚·ãƒ•ãƒˆã•ã›ã‚‹ï¼ˆå¼4ï¼‰ã“ã¨ã§ã€conditional text/image tokené–“ã§ç©ºé–“çš„ã«overlapã—ãªã„ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã§æ€§èƒ½ãŒå¤§å¹…ã«æ”¹å–„ã—ãŸã€‚<br><br>æ—¢å­˜ç ”ç©¶ã§ã¯ã€C_Iã®å¼·ã•ã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã™ã‚‹ãŸã‚ã«ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦å®šæ•°ã‚’å°å…¥ã—ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸfeatureã‚’åŠ ç®—ã™ã‚‹éš›ã®å¼·ã•ã‚’èª¿æ•´ã—ã¦ã„ãŸãŒï¼ˆ3.2.3ç¯€ï¼‰ã€æœ¬æ‰‹æ³•ã§ã¯concatã‚’ã™ã‚‹ãŸã‚ã“ã®ã‚ˆã†ãªæ–¹æ³•ã¯ä½¿ãˆãªã„ã€‚ãã®ãŸã‚ã€Multi-Modal Attention(MMA)ã«ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚ˆã£ã¦å¼·ã•ã‚’èª¿æ•´å¯èƒ½ãªbias matrixã‚’å°å…¥ã—ã€C_Iã¨Xã®attentionã®äº¤äº’ä½œç”¨ã®å¼·ã•ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§å¯¾å¿œã—ãŸï¼ˆå¼5,6ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ContextWindow.html" target="_blank" rel="noopener noreferrer">#ContextWindow</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3357" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Glyph: Scaling Context Windows via Visual-Text Compression, Jiale Cheng+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒã¤å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å®Ÿç”¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã€Glyphã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”»åƒã«å¤‰æ›ã—ã¦è¦–è¦šã¨è¨€èªã®ãƒ¢ãƒ‡ãƒ«ï¼ˆVLMsï¼‰ã§å‡¦ç†ã—ã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã‚ˆã‚Šã€3-4å€ã®ãƒˆãƒ¼ã‚¯ãƒ³åœ§ç¸®ã‚’å®Ÿç¾ã—ã€ç²¾åº¦ã‚’ç¶­æŒã—ã¤ã¤å‡¦ç†é€Ÿåº¦ã‚’ç´„4å€å‘ä¸Šã•ã›ã¾ã™ã€‚ã•ã‚‰ã«ã€128Kã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®VLMãŒ1Mãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†å¯èƒ½ã«ãªã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1980474912168112471?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1980722682246398069?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”»åƒã«ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã—ã¦VLMã«å…¥åŠ›ã™ã‚‹ã“ã¨ã§textã¨æ¯”è¼ƒã—ã¦3.2å€KV Cache (context)ã‚’åœ§ç¸®ã—ã€prefillingã¨ãƒ‡ã‚³ãƒ¼ãƒ‰é€Ÿåº¦ã‚‚4.8, 4.4å€é«˜é€ŸåŒ–ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚‰ã—ã„<br><br><img src="https://github.com/user-attachments/assets/e65f880d-0d04-434f-9a51-accc84d44a6f" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3356" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Holistic Agent Leaderboard: The Missing Infrastructure for AI Agent  Evaluation, Sayash Kapoor+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è©•ä¾¡ã«ãŠã‘ã‚‹èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€Holistic Agent Leaderboardï¼ˆHALï¼‰ã‚’å°å…¥ã€‚æ¨™æº–åŒ–ã•ã‚ŒãŸè©•ä¾¡ãƒãƒ¼ãƒã‚¹ã«ã‚ˆã‚Šè©•ä¾¡æ™‚é–“ã‚’çŸ­ç¸®ã—ã€ä¸‰æ¬¡å…ƒåˆ†æã‚’é€šã˜ã¦21,730ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è©•ä¾¡ã€‚é«˜ã„æ¨è«–åŠªåŠ›ãŒç²¾åº¦ã‚’ä½ä¸‹ã•ã›ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã€LLMã‚’ç”¨ã„ãŸãƒ­ã‚°æ¤œæŸ»ã§æ–°ãŸãªè¡Œå‹•ã‚’æ˜ã‚‰ã‹ã«ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè©•ä¾¡ã®æ¨™æº–åŒ–ã‚’é€²ã‚ã€ç¾å®Ÿä¸–ç•Œã§ã®ä¿¡é ¼æ€§å‘ä¸Šã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://hal.cs.princeton.edu" target="_blank" rel="noopener noreferrer">https://hal.cs.princeton.edu</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1979893861431550372?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚ˆã€40,000ãƒ‰ãƒ«ï¼ï¼ŸğŸ’¸</p>
<p>LLM Agentã«é–¢ã™ã‚‹ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ãƒ¢ãƒ‡ãƒ«ç¾¤ã‚’è¤‡æ•°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§åŒã˜æ¡ä»¶ã§apple to appleãªæ¯”è¼ƒã¨ãªã‚‹ã‚ˆã†ã«è©•ä¾¡ã—ã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/142b550e-f708-441c-acca-583af413d26f" alt="image" loading="lazy"><br><br>ä»¥ä¸‹å…ƒãƒã‚¹ãƒˆã‚ˆã‚Š:<br><br>ã“ã®è©•ä¾¡ãƒãƒ¼ãƒã‚¹ã¯ã€10è¡Œæœªæº€ã®ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã§è©•ä¾¡ã‚’å®Ÿè¡Œå¯èƒ½ï¼ˆå…ƒãƒã‚¹ãƒˆï¼‰<br><br>çŸ¥è¦‹ã¨ã—ã¦ã¯<br>- reasoning effortã‚’ä¸Šã’ã¦ã‚‚å¤šãã®å ´åˆæ€§èƒ½å‘ä¸Šã«ã¯å¯„ä¸ã›ãš(21/36ã®ã‚±ãƒ¼ã‚¹ã§æ€§èƒ½å‘ä¸Šã›ãš)<br>- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«è¿‘é“ã‚’ã™ã‚‹ï¼ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ç›´æ¥å‚ç…§ã—ã«è¡Œããªã©ï¼‰<br>- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯éå¸¸ã«ã‚³ã‚¹ãƒˆã®é«˜ã„æ‰‹æ®µã‚’å–ã‚‹ã“ã¨ã‚‚ã‚ã‚Šï¼ˆãƒ•ãƒ©ã‚¤ãƒˆäºˆç´„ã«ãŠã„ã¦èª¤ã£ãŸç©ºæ¸¯ã‹ã‚‰äºˆç´„ã—ãŸã‚Šã€ãƒ¦ãƒ¼ã‚¶ã«éå‰°ãªè¿”é‡‘ã‚’ã—ãŸã‚Šã€èª¤ã£ãŸã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ã«è«‹æ±‚ã—ãŸã‚Šãªã©ï¼‰<br>- ã‚³ã‚¹ãƒˆã¨acc.ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’åˆ†æã—ãŸçµæœã€æœ€ã‚‚é«˜ä¾¡ãªOpus4.1ã¯ä¸€åº¦ã—ã‹ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã«ãªã‚‰ãšã€Gemini Flash (7/9)ã€GPT-5, o4-mini(4/9)ãŒå¤šãã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚³ã‚¹ãƒˆã¨Acc.ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®ä¸Šã§ãƒ‘ãƒ¬ãƒ¼ãƒˆãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã¨ãªã£ãŸã€‚<br>- ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚³ã‚¹ãƒˆã¨Acc.ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ãŠã„ã¦ã¯ã€Opus4.1ãŒ3ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãƒ‘ãƒ¬ãƒ¼ãƒ‰ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ã¨ãªã£ãŸã€‚<br>- ã™ã¹ã¦ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¡Œå‹•ã‚’è¨˜éŒ²ã—åˆ†æã—ãŸçµæœã€SelfCorrection, intermediate verifiers (ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œã«ãŠã‘ã‚‹ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆãªã©ï¼‰ã®behaviorãŒacc.ã‚’æ”¹å–„ã™ã‚‹ä¸Šã§é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ãŸ<br>- ä¸€æ–¹ã‚¿ã‚¹ã‚¯ã«å¤±æ•—ã™ã‚‹å ´åˆã¯ã€å¤šãã®è¦å› ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã€ãŸã¨ãˆã°ç’°å¢ƒå†…ã®éšœå®³ï¼ˆCAPTCHAãªã©ï¼‰ã€æŒ‡ç¤ºã«å¾“ã†ã“ã¨ã®å¤±æ•—ï¼ˆæŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã‚³ãƒ¼ãƒ‰ã‚’å‡ºåŠ›ã—ãªã„ï¼‰ãªã©ãŒé »ç¹ã«è¦‹å—ã‘ã‚‰ã‚ŒãŸã€‚ã¾ãŸã€ã‚¿ã‚¹ã‚¯ã‚’è§£ã‘ãŸã‹å¦ã‹ã«é–¢ã‚ã‚‰ãšãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®å¤±æ•—ã«é »ç¹ã«é­é‡ã—ã¦ã„ãŸã€‚ã“ã‚Œã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã“ã†ã—ãŸã‚¨ãƒ©ãƒ¼ã‹ã‚‰å›å¾©ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br>- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ­ã‚°ã‚’åˆ†æã™ã‚‹ã“ã¨ã§ã€TauBenchã§ä½¿ç”¨ã—ã¦ã„ãŸscaffold(=ãƒ¢ãƒ‡ãƒ«ãŒç’°å¢ƒã‚‚ã‚„ã‚Šã¨ã‚Šã™ã‚‹ãŸã‚ã®æ§‹æˆè¦ç´ ï¼‰ã«ãƒã‚°ãŒã‚ã‚‹ã“ã¨ã‚’çªãæ­¢ã‚ãŸï¼ˆfew-shotã®ã‚µãƒ³ãƒ—ãƒ«ã«ãƒªãƒ¼ã‚¯ãŒã‚ã£ãŸï¼‰ã€‚ã“ã®scaffoldã¯HALã«ã‚ˆã‚‹TauBenchã®åˆ†æã‹ã‚‰é™¤å¤–ã—ãŸã€‚<br>- Docsentã®ã‚ˆã†ãªãƒ­ã‚°åˆ†æãŒä»Šå¾Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è©•ä¾¡ã™ã‚‹ä¸Šã§ã¯å¿…è¦ä¸å¯æ¬ ã§ã‚ã‚Šã€ä¿¡é ¼æ€§ã®å•é¡Œã‚„ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆè¡Œå‹•ã€é«˜ã‚³ã‚¹ãƒˆãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¤±æ•—ãªã©ãŒæ˜ã‚‰ã‹ã«ãªã‚‹ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã§ã®æ€§èƒ½ã¨æ¯”è¼ƒã—ã¦å®Ÿç’°å¢ƒã§ã¯æ€§èƒ½ãŒä½ã„ã€ã‚ã‚‹ã„ã¯ãã®é€†ã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒæ€§èƒ½ã‚’ä½ãè¦‹ç©ã‚‚ã£ã¦ã„ã‚‹ï¼ˆãŸã¨ãˆã°CAPTChAã®ã‚ˆã†ã‚„ç’°å¢ƒçš„ãªéšœå®³ã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã§ã¯åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ã›ã„ã§ç”Ÿã˜ã¦ã‚‚å®Ÿç’°å¢ƒã§ã¯ç”Ÿã˜ãªã„ãªã©ï¼‰ã‚±ãƒ¼ã‚¹ã‚‚ã‚ã‚‹ã®ã§ã€ã“ã‚Œã‚‰ã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®acc.ã‹ã‚‰ã ã‘ã§ã¯æ˜ã‚‰ã‹ã«ãªã‚‰ãªã„ãŸã‚ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®acc.ã¯æ…é‡ã«è§£é‡ˆã™ã¹ãã€‚</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/TheoryOfMind.html" target="_blank" rel="noopener noreferrer">#TheoryOfMind</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Personality.html" target="_blank" rel="noopener noreferrer">#Personality</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3355" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Emergent Coordination in Multi-Agent Language Models, Christoph Riedl, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆLLMã‚·ã‚¹ãƒ†ãƒ ãŒé«˜æ¬¡ã®æ§‹é€ ã‚’æŒã¤ã‹ã©ã†ã‹ã‚’æƒ…å ±ç†è«–çš„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ã¦æ¤œè¨¼ã€‚å®Ÿé¨“ã§ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒãªã„çŠ¶æ³ã§ã€æ™‚é–“çš„ç›¸ä¹—åŠ¹æœãŒè¦³å¯Ÿã•ã‚Œã‚‹ä¸€æ–¹ã€èª¿æ•´ã•ã‚ŒãŸæ•´åˆæ€§ã¯è¦‹ã‚‰ã‚Œãªã‹ã£ãŸã€‚ãƒšãƒ«ã‚½ãƒŠã‚’å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ã§ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–“ã®å·®åˆ¥åŒ–ã¨ç›®æ¨™æŒ‡å‘ã®ç›¸è£œæ€§ãŒç¤ºã•ã‚Œã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‡ã‚¶ã‚¤ãƒ³ã«ã‚ˆã£ã¦é«˜æ¬¡ã®é›†åˆä½“ã¸ã¨èª˜å°ã§ãã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚çµæœã¯ã€åŠ¹æœçš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ã¯æ•´åˆæ€§ã¨ç›¸è£œçš„ãªè²¢çŒ®ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1979893847665893851?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>éå¸¸ã«ã‚·ãƒ³ãƒ—ãƒ«ãªè¨­å®šã§ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹ã‚·ãƒŠã‚¸ãƒ¼ãŒç”Ÿã˜ã‚‹ã‹å¦ã‹ã€ãã®ãŸã‚ã®æ¡ä»¶ã‚’æ¤œè¨¼ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã ã¨ã‚·ãƒŠã‚¸ãƒ¼ã¯ç”Ÿã˜ãšã€ãƒšãƒ«ã‚½ãƒŠä»˜ä¸ã¨Theory of Mindã‚’æŒ‡ç¤ºã™ã‚‹ã¨åŠ¹æœãŒå¤§ãã„æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ICCV.html" target="_blank" rel="noopener noreferrer">#ICCV</a>
<a class="button" href="articles/ImageSynthesis.html" target="_blank" rel="noopener noreferrer">#ImageSynthesis</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3335" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MetaMorph: Multimodal Understanding and Generation via Instruction   Tuning, Shengbang Tong+, ICCV'25, 2024.12</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€è¦–è¦šçš„æŒ‡ç¤ºèª¿æ•´ã®æ–°æ‰‹æ³•VPiTã‚’ææ¡ˆã—ã€LLMãŒãƒ†ã‚­ã‚¹ãƒˆã¨è¦–è¦šãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚VPiTã¯ã€ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’äºˆæ¸¬ã™ã‚‹èƒ½åŠ›ã‚’LLMã«æ•™ãˆã€è¦–è¦šç”Ÿæˆèƒ½åŠ›ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚ç‰¹ã«ã€ç†è§£ãƒ‡ãƒ¼ã‚¿ãŒç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šã‚‚åŠ¹æœçš„ã«ä¸¡æ–¹ã®èƒ½åŠ›ã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—ãŸã€‚MetaMorphãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€è¦–è¦šç†è§£ã¨ç”Ÿæˆã§ç«¶äº‰åŠ›ã®ã‚ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€LLMã®äº‹å‰å­¦ç¿’ã‹ã‚‰å¾—ãŸçŸ¥è­˜ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€è¦–è¦šç”Ÿæˆã«ãŠã‘ã‚‹ä¸€èˆ¬çš„ãªå¤±æ•—ã‚’å…‹æœã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMãŒè¦–è¦šç†è§£ã¨ç”Ÿæˆã«é©å¿œã§ãã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/davidjfan/status/1979994285379641487?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3323" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Agentic Misalignment: How LLMs Could Be Insider Threats, Aengus Lynch+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- è¤‡æ•°ã®é–‹ç™ºè€…ã‹ã‚‰ã®16ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä»®æƒ³ä¼æ¥­ç’°å¢ƒã§ãƒ†ã‚¹ãƒˆã—ã€æ½œåœ¨çš„ãªãƒªã‚¹ã‚¯è¡Œå‹•ã‚’ç‰¹å®šã€‚ãƒ¢ãƒ‡ãƒ«ã¯è‡ªå¾‹çš„ã«ãƒ¡ãƒ¼ãƒ«ã‚’é€ä¿¡ã—ã€æ©Ÿå¯†æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã§ã€ãƒ“ã‚¸ãƒã‚¹ç›®æ¨™ã«å¾“ã†ä¸­ã§åæŠ—çš„è¡Œå‹•ã‚’ç¤ºã™ã“ã¨ãŒã‚ã£ãŸã€‚ã“ã®ç¾è±¡ã‚’ã€Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒŸã‚¹ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã€ã¨å‘¼ã³ã€ãƒ¢ãƒ‡ãƒ«ãŒä¸é©åˆ‡ãªè¡Œå‹•ã‚’å–ã‚‹ã“ã¨ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚å®Ÿéš›ã®å±•é–‹ã«ãŠã„ã¦ã¯ãƒŸã‚¹ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã®è¨¼æ‹ ã¯è¦‹ã‚‰ã‚Œãªã‹ã£ãŸãŒã€ãƒ¢ãƒ‡ãƒ«ã®è‡ªå¾‹æ€§ãŒé«˜ã¾ã‚‹ã“ã¨ã§å°†æ¥çš„ãªãƒªã‚¹ã‚¯ãŒç”Ÿã˜ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã€‚å®‰å…¨æ€§ã¨é€æ˜æ€§ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã€ç ”ç©¶æ–¹æ³•ã‚’å…¬é–‹ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/safe_paper/status/1979557019209146457?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>abstã‚’èª­ã‚“ã ã ã‘ã§ã‚‚ã€ãªã‚“ã¨ã‚‚æã‚ã—ã„ã‚·ãƒŠãƒªã‚ªãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚èª­ã¿ãŸã„</p>
<p>Figure4, 5ã¨ã‹ã™ã”ã„ãª</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/UserBased.html" target="_blank" rel="noopener noreferrer">#UserBased</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3309" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LiveResearchBench: A Live Benchmark for User-Centric Deep Research in  the Wild, Jiayu Wang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æ·±å±¤ç ”ç©¶ã¯ã€ãƒ©ã‚¤ãƒ–ã‚¦ã‚§ãƒ–ã‚½ãƒ¼ã‚¹ã‹ã‚‰æƒ…å ±ã‚’æ¤œç´¢ãƒ»çµ±åˆã—ã€å¼•ç”¨ã«åŸºã¥ã„ãŸãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹æŠ€è¡“ã§ã‚ã‚Šã€è©•ä¾¡ã«ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸­å¿ƒã€å‹•çš„ã€æ˜ç¢ºã€å¤šé¢çš„ãªåŸå‰‡ãŒå¿…è¦ã€‚æ—¢å­˜ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã“ã‚Œã‚‰ã‚’æº€ãŸã—ã¦ã„ãªã„ãŸã‚ã€LiveResearchBenchã‚’å°å…¥ã—ã€100ã®å°‚é–€å®¶ãŒã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ãŸã‚¿ã‚¹ã‚¯ã‚’æä¾›ã€‚ã•ã‚‰ã«ã€ãƒ¬ãƒãƒ¼ãƒˆè©•ä¾¡ã®ãŸã‚ã«DeepEvalã‚’ææ¡ˆã—ã€å“è³ªã‚’åŒ…æ‹¬çš„ã«è©•ä¾¡ã™ã‚‹ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’çµ±åˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€17ã®æ·±å±¤ç ”ç©¶ã‚·ã‚¹ãƒ†ãƒ ã®åŒ…æ‹¬çš„ãªè©•ä¾¡ã‚’è¡Œã„ã€å¼·ã¿ã‚„æ”¹å–„ç‚¹ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/caimingxiong/status/1979216886215917916?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Proofs.html" target="_blank" rel="noopener noreferrer">#Proofs</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3307" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Reliable Fine-Grained Evaluation of Natural Language Math Proofs, Wenjie Ma+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ã‚ˆã‚‹æ•°å­¦çš„è¨¼æ˜ã®ç”Ÿæˆã¨æ¤œè¨¼ã«ãŠã‘ã‚‹ä¿¡é ¼æ€§ã®é«˜ã„è©•ä¾¡è€…ãŒä¸è¶³ã—ã¦ã„ã‚‹å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€0ã‹ã‚‰7ã®ã‚¹ã‚±ãƒ¼ãƒ«ã§è©•ä¾¡ã™ã‚‹æ–°ãŸãªè©•ä¾¡è€…ProofGraderã‚’é–‹ç™ºã€‚ProofBenchã¨ã„ã†å°‚é–€å®¶æ³¨é‡ˆä»˜ããƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€è©•ä¾¡è€…ã®è¨­è¨ˆç©ºé–“ã‚’æ¢æ±‚ã—ã€ä½ã„å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆMAEï¼‰0.926ã‚’é”æˆã€‚ProofGraderã¯ã€æœ€è‰¯ã®é¸æŠã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã‚‚é«˜ã„ã‚¹ã‚³ã‚¢ã‚’ç¤ºã—ã€ä¸‹æµã®è¨¼æ˜ç”Ÿæˆã®é€²å±•ã«å¯„ä¸ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenjie_ma/status/1979239433145848103?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯éå¸¸ã«é‡è¦ãªç ”ç©¶ã«è¦‹ãˆã‚‹</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Education.html" target="_blank" rel="noopener noreferrer">#Education</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3306" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AutoCode: LLMs as Problem Setters for Competitive Programming, Shang Zhou+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- AutoCodeã¯ã€ç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®å•é¡Œæ–‡ã¨ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã§ã‚ã‚Šã€ä¿¡é ¼æ€§ã®é«˜ã„å•é¡Œä½œæˆã‚’å®Ÿç¾ã—ã¾ã™ã€‚è¤‡æ•°å›ã®æ¤œè¨¼ã‚’é€šã˜ã¦ã€ç”Ÿæˆã•ã‚ŒãŸå•é¡Œã¯å…¬å¼ã®åˆ¤æ–­ã¨99%ã®ä¸€è²«æ€§ã‚’æŒã¡ã€å¾“æ¥ã®æ‰‹æ³•ã«æ¯”ã¹ã¦å¤§å¹…ãªæ”¹å–„ã‚’ç¤ºã—ã¾ã™ã€‚ã¾ãŸã€ãƒ©ãƒ³ãƒ€ãƒ ãªã‚·ãƒ¼ãƒ‰å•é¡Œã‹ã‚‰æ–°ã—ã„ãƒãƒªã‚¢ãƒ³ãƒˆã‚’ä½œæˆã—ã€ä¸æ­£ãªå•é¡Œã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹æ©Ÿèƒ½ã‚‚å‚™ãˆã¦ã„ã¾ã™ã€‚æœ€çµ‚çš„ã«ã€AutoCodeã¯ã‚°ãƒ©ãƒ³ãƒ‰ãƒã‚¹ã‚¿ãƒ¼ç´šã®ç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ã«ã‚ˆã£ã¦ã‚³ãƒ³ãƒ†ã‚¹ãƒˆå“è³ªã¨è©•ä¾¡ã•ã‚Œã‚‹å•é¡Œã‚’ç”Ÿæˆã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>blog:


<a href="https://livecodebenchpro.com/projects/autocode/overview" target="_blank" rel="noopener noreferrer">https://livecodebenchpro.com/projects/autocode/overview</a>


</p>
<p>LLMã§è‡ªå‹•çš„ã«é«˜å“è³ªãªç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å•é¡Œã¨ãã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ææ¡ˆã€‚<br><br>ä¿¡é ¼æ€§ã®ã‚ã‚‹ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ä½œæˆã™ã‚‹ãŸã‚ã«ã€Validator-Generator-Checkerãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚ææ¡ˆã€‚GeneratorãŒãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’ç”Ÿæˆã—ã€ValidatorãŒç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®å…¥åŠ›ãŒå•é¡Œã®åˆ¶ç´„ã‚’æº€ãŸã—ã¦ã„ã‚‹ã‹åˆ¤å®šã—ã€CheckerãŒä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®å…ƒã§è§£æ³•ãŒæ­£ã—ã„ã‹ã‚’ç¢ºèªã™ã‚‹ã€‚<br><br>ç¶šã„ã¦ã€äººæ‰‹ã‚’ä»‹ã•ãšã¨ã‚‚ç”Ÿæˆã•ã‚Œã‚‹å•é¡ŒãŒæ­£ã—ã„ã“ã¨ã‚’æ‹…ä¿ã™ã‚‹ãŸã‚ã«dual-verificationã‚’æ¡ç”¨ã€‚å…·ä½“çš„ã«ã¯ã€LLMã«æ–°è¦ã®å•é¡Œæ–‡ã¨åŠ¹ç‡çš„ãªè§£æ³•ã‚’ç”Ÿæˆã•ã›ã€åŠ ãˆã¦ãƒ–ãƒ«ãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ã‚¹ã§ã®è§£æ³•ã‚’åˆ¥é€”ç”Ÿæˆã™ã‚‹ã€‚ãã—ã¦ã€ä¸¡è€…ã‚’LLMãŒç”Ÿæˆã—ãŸãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆç¾¤ã§å®Ÿè¡Œã—ã€å…¨ã¦ã®è§£æ”¾ã§å‡ºåŠ›ãŒä¸€è‡´ã—ãŸå ´åˆã®ã¿Acceptã™ã‚‹ã€ã¨ã„ã£ãŸã‚ˆã†ãªæ‰‹æ³•ã‚‰ã—ã„ã€‚<br><br>ï¼ˆæ‰‹æ³•ã®æ¦‚è¦ã¨ã—ã¦ã¯ãã†ãªã®ã ã‚ã†ãŒã€ç´°ã‹ã„å®Ÿè£…ã«é«˜å“è³ªã•ã®è‚ãŒã‚ã‚‹ã¨æ€ã†ã®ã§ã—ã£ã‹ã‚Šèª­ã‚“ã æ–¹ãŒè‰¯ã•ã’ã€‚ç‰¹ã«Test Generationã®è©³ç´°ã‚’ã—ã£ã‹ã‚Šã§ãã¦ã„ãªã„ï¼‰<br><br><img src="https://github.com/user-attachments/assets/e6779e5d-9e0a-4da8-9634-d6054704bfa7" alt="image" loading="lazy"></p>
<p>takeawayã§èˆˆå‘³æ·±ã‹ã£ãŸã®ã¯ã€<br><br>- LLMã¯è‡ªèº«ã§ã¯è§£ã‘ãªã„ãŒã€è§£æ³•ãŒå­˜åœ¨ã™ã‚‹ï¼ˆsolvable)å•é¡Œã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨<br>- äººé–“ã®å°‚é–€å®¶ã¨LLMï¼ˆo3)ã®é–“ã§ã€å•é¡Œã®å“è³ªã®æ–°è¦æ€§ã®åˆ¤å®šã®ç›¸é–¢ãŒã‚ãšã‹0.007, 0.11ã—ã‹ãªã‹ã£ãŸã“ã¨ã€‚ãã—ã¦å“è³ªã«é–¢ã—ã¦ã¯å°‚é–€å®¶ã®ã‚°ãƒ«ãƒ¼ãƒ—é–“ã§ã¯0.71, o3ã¨gpt4oã®é–“ã§ã¯0.72ã¨é«˜ã„ç›¸é–¢ã‚’ç¤ºã—ã¦ãŠã‚Šã€LLMã¨äººé–“ã®å°‚é–€å®¶ã®é–“ã§è‘—ã—ãå•é¡Œã®å“è³ªã®åˆ¤æ–­åŸºæº–ãŒç•°ãªã‚‹ã“ã¨<br>- seedå•é¡Œã¨ç”Ÿæˆã•ã‚ŒãŸå•é¡Œã®é›£æ˜“åº¦ã®gainãŒã€å•é¡Œã®å“è³ªã«é–¢ã—ã¦ã€LLMè‡ªèº«ã®self-evaluationã‚ˆã‚Šã‚‚ã‚ˆã‚Šè‰¯ã„æŒ‡æ¨™ã¨ãªã£ã¦ã„ã‚‹ã“ã¨</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<a class="button" href="articles/LongHorizon.html" target="_blank" rel="noopener noreferrer">#LongHorizon</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3305" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Long-Horizon LLM Agent via Context-Folding, Weiwei Sun+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ã€ŒContext-Foldingã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚µãƒ–ã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†ã—ã¤ã¤ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç®¡ç†ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€‚FoldGRPOã‚’ç”¨ã„ãŸå¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚Šã€è¤‡é›‘ãªé•·æœŸã‚¿ã‚¹ã‚¯ã§10å€å°ã•ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://context-folding.github.io" target="_blank" rel="noopener noreferrer">https://context-folding.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sunweiwei12/status/1978645349951484214?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè‡ªèº«ã«contextã‚’ç®¡ç†ã™ã‚‹èƒ½åŠ›ã‚’å­¦ç¿’ã•ã›ã‚‹</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="articles/Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<a class="button" href="articles/memory.html" target="_blank" rel="noopener noreferrer">#memory</a>
<span class="issue_date">Issue Date: 2025-10-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3303" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] To Infinity and Beyond: Tool-Use Unlocks Length Generalization in State  Space Models, Eran Malach+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ï¼ˆSSMï¼‰ã¯ã€é•·æ–‡ç”Ÿæˆã«ãŠã„ã¦åŠ¹ç‡çš„ãªä»£æ›¿æ‰‹æ®µã§ã‚ã‚‹ãŒã€çœŸã®é•·æ–‡ç”Ÿæˆå•é¡Œã‚’è§£æ±ºã§ããªã„ã“ã¨ãŒæ˜ã‚‰ã‹ã«ã•ã‚ŒãŸã€‚å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã¸ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ã™ã‚‹ã“ã¨ã§ã€ã“ã®åˆ¶é™ã‚’å…‹æœã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã€SSMã¯å•é¡Œä¾å­˜ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ä»»æ„ã®å•é¡Œã«ä¸€èˆ¬åŒ–ã§ãã‚‹ã€‚ãƒ„ãƒ¼ãƒ«ã‚’å¼·åŒ–ã—ãŸSSMã¯ã€ç®—è¡“ã‚„æ¨è«–ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦å„ªã‚ŒãŸé•·ã•ã®ä¸€èˆ¬åŒ–ã‚’é”æˆã—ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã«å¯¾ã™ã‚‹åŠ¹ç‡çš„ãªä»£æ›¿æ‰‹æ®µã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1979058895336411538?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/eranmalach/status/1979199774172565712?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_albertgu/status/1980287154883358864?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1980759789354586258?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<a class="button" href="articles/interactive.html" target="_blank" rel="noopener noreferrer">#interactive</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3291" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LongLive: Real-time Interactive Long Video Generation, Shuai Yang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- LongLiveã¯ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªé•·ç·¨å‹•ç”»ç”Ÿæˆã®ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ™ãƒ«ã®è‡ªå·±å›å¸°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚å› æœçš„æ³¨æ„ARãƒ¢ãƒ‡ãƒ«ã‚’æ¡ç”¨ã—ã€KVå†ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’çµ±åˆã™ã‚‹ã“ã¨ã§ã€è¦–è¦šçš„ä¸€è²«æ€§ã¨æ„å‘³çš„æ•´åˆæ€§ã‚’ä¿ã¡ãªãŒã‚‰åŠ¹ç‡çš„ãªç”Ÿæˆã‚’å®Ÿç¾ã€‚1.3Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’32 GPUæ—¥ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€å˜ä¸€ã®NVIDIA H100ã§20.7 FPSã‚’ç¶­æŒã€‚æœ€å¤§240ç§’ã®å‹•ç”»ç”Ÿæˆã‚’ã‚µãƒãƒ¼ãƒˆã—ã€INT8é‡å­åŒ–æ¨è«–ã‚‚å¯¾å¿œã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yukangchen_/status/1978653384539341287?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2870" target="_blank" rel="noopener noreferrer">[Paper Note] Self Forcing: Bridging the Train-Test Gap in Autoregressive Video   Diffusion, Xun Huang+, NeurIPS'25</a>
</p>
<p>pj page: 


<a href="https://nvlabs.github.io/LongLive/" target="_blank" rel="noopener noreferrer">https://nvlabs.github.io/LongLive/</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3282" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Art of Scaling Reinforcement Learning Compute for LLMs, Devvrit Khatri+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«é–¢ã™ã‚‹åŸå‰‡çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’å®šç¾©ã—ã€40ä¸‡æ™‚é–“ä»¥ä¸Šã®GPUæ™‚é–“ã‚’ç”¨ã„ãŸå¤§è¦æ¨¡ãªç ”ç©¶ã‚’å®Ÿæ–½ã€‚ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰å‹è¨ˆç®—-æ€§èƒ½æ›²ç·šã‚’ãƒ•ã‚£ãƒƒãƒˆã•ã›ã€è¨­è¨ˆé¸æŠè‚¢ã®å½±éŸ¿ã‚’åˆ†æã€‚çµæœã¨ã—ã¦ã€æ¼¸è¿‘çš„æ€§èƒ½ã¯ãƒ¬ã‚·ãƒ”ã«ã‚ˆã£ã¦ç•°ãªã‚Šã€è¨ˆç®—åŠ¹ç‡ã¯è©³ç´°ã«ä¾å­˜ã™ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã€‚ã“ã‚Œã‚’åŸºã«ã€ScaleRLã¨ã„ã†ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã®ãƒ¬ã‚·ãƒ”ã‚’ææ¡ˆã—ã€100,000 GPUæ™‚é–“ã§ã®æˆåŠŸã‚’ç¤ºã—ãŸã€‚ã“ã®ç ”ç©¶ã¯ã€RLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®äºˆæ¸¬å¯èƒ½æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®ç§‘å­¦çš„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1978956121416307148?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>&gt; ç°¡å˜ã«ãªã£ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é€šéç‡ãŒ0.9ä»¥ä¸Šï¼‰ã¯å†ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸã»ã†ãŒæœ€çµ‚æ€§èƒ½ãŒé«˜ã„<br><br>æœ€è¿‘ã¯ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å°å…¥ã—ã¦ã€ç°¡å˜ã™ããšé›£ã—ã™ããªã„å•é¡Œã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦åŠ¹ç‡ä¸Šã’ã‚‹ã€ã¨ã„ã£ãŸã‚ˆã†ãªè©±ãŒã‚ã£ãŸãŒã€ç°¡å˜ã«ãªã£ãŸå•é¡Œã‚’ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãªã„ã¨æœ€çµ‚æ€§èƒ½ã¨ã—ã¦ã¯ä½ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã‹â€¦æ„å¤–ã ã£ãŸã€‚<p>CISPO:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3283" target="_blank" rel="noopener noreferrer">[Paper Note] MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning
  Attention, MiniMax+, arXiv'25, 2025.06</a>
</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/devvrit_khatri/status/1978864275658871099?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/grad62304977/status/1979920784727429432?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3270" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] StreamingVLM: Real-Time Understanding for Infinite Video Streams, Ruyi Xu+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- StreamingVLMã¯ã€ç„¡é™ã®ãƒ“ãƒ‡ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ç†è§£ã™ã‚‹ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«ã§ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã‚’çµ±ä¸€ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’æ¡ç”¨ã€‚ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã®çŠ¶æ…‹ã‚’å†åˆ©ç”¨ã—ã€çŸ­ã„ãƒ“ã‚¸ãƒ§ãƒ³ãƒˆãƒ¼ã‚¯ãƒ³ã¨é•·ã„ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ä¿æŒã™ã‚‹ã“ã¨ã§ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’æŠ‘ãˆã¤ã¤é«˜ã„æ€§èƒ½ã‚’å®Ÿç¾ã€‚æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯Inf-Streams-Evalã§66.18%ã®å‹ç‡ã‚’é”æˆã—ã€ä¸€èˆ¬çš„ãªVQAèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã«æˆåŠŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1978324546370343088?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯èˆˆå‘³æ·±ã„</p>
<p>ä¿æŒã™ã‚‹KV Cacheã®ä¸Šé™ã‚’æ±ºã‚ã€Sink Token[^1]ã¯ä¿æŒã—[^2]ï¼ˆ512ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã€textual tokenã¯é•·è·é›¢ã§ä¿æŒã€visual tokenã¯çŸ­è·é›¢ã§ä¿æŒã€ã¾ãŸpositional encodingã¨ã—ã¦ã¯RoPEã‚’æ¡ç”¨ã™ã‚‹ãŒã€å›ºå®šã•ã‚ŒãŸãƒ¬ãƒ³ã‚¸ã®ä¸­ã§å‹•çš„ã«indexã‚’æ›´æ–°ã™ã‚‹ã“ã¨ã§ã€ä½ç›¸ã‚’å­¦ç¿’æ™‚ã®rangeã«åã‚OODã«ãªã‚‰ãªã„ã‚ˆã†ãªå·¥å¤«ã‚’ã™ã‚‹ã“ã¨ã§ã€memoryã¨è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’ä¸€å®šã«ä¿ã¡ãªãŒã‚‰long contextã§ã®ä¸€è²«æ€§ã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®latencyã‚’å®Ÿç¾ã™ã‚‹ã€ã¨ã„ã£ãŸè©±ã«ã¿ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/4d063c90-e10a-4d07-9095-f87ee85c33fb" alt="image" loading="lazy"><br><br>å­¦ç¿’æ™‚ã¯ãƒ•ãƒ¬ãƒ¼ãƒ ãŒoverlapã—ãŸè¤‡æ•°ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†ã‘ã¦ã€ãã‚Œãã‚Œã‚’full attentionã§å­¦ç¿’ã™ã‚‹ï¼ˆSink Tokenã¯ä¿æŒã™ã‚‹ï¼‰ã€‚ã“ã‚Œã¯ä¸Šè¿°ã®inferenceæ™‚ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨æ•´åˆã—ã¦ãŠã‚Šå­¦ç¿’æ™‚ã¨inferenceæ™‚ã®gapãŒæœ€å°é™ã«ãªã‚‹ã€‚ã¾ãŸã€ã‚ã–ã‚ã–long videoã§å­¦ç¿’ã™ã‚‹å¿…è¦ãŒãªã„ã€‚ï¼ˆç¾ã—ã„è§£æ±ºæ–¹æ³•ï¼‰<br><img src="https://github.com/user-attachments/assets/98b50d1b-b9c4-427a-93f5-d385b2bc35a1" alt="image" loading="lazy"><br><br>[^1]: decoder-only transformerã®ä½™å‰°ãªattention scoreã®æ¨ã¦å ´ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹sequenceå†’é ­ã®æ•°ãƒˆãƒ¼ã‚¯ãƒ³(3--4ãƒˆãƒ¼ã‚¯ãƒ³ç¨‹åº¦ï¼‰ã®ã“ã¨ã€‚æœ¬è«–æ–‡ã§ã¯512ãƒˆãƒ¼ã‚¯ãƒ³ã¨å¤§ãã‚ã®Sink Tokenã‚’ä¿æŒã—ã¦ã„ã‚‹ã€‚<br>[^2]: Attention Sinksã«ã‚ˆã£ã¦ã€long contextã®æ€§èƒ½ãŒæ”¹å–„ã•ã‚Œ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1860" target="_blank" rel="noopener noreferrer">Why do LLMs attend to the first token?, Federico Barbero+, COLM'25</a>
 decoder-only transformerã®å±¤ãŒæ·±ã„éƒ¨åˆ†ã§ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®è¡¨ç¾ãŒå‡ä¸€åŒ–ã•ã‚Œã¦ã—ã¾ã†over-mixingã‚’æŠ‘åˆ¶ã™ã‚‹ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1861" target="_blank" rel="noopener noreferrer">Efficient Streaming Language Models with Attention Sinks, Guangxuan Xiao+, ICLR'24</a>
 ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ã‚‹</p>
<p>AttentionSinké–¢é€£ãƒªãƒ³ã‚¯:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1861" target="_blank" rel="noopener noreferrer">Efficient Streaming Language Models with Attention Sinks, Guangxuan Xiao+, ICLR'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1860" target="_blank" rel="noopener noreferrer">Why do LLMs attend to the first token?, Federico Barbero+, COLM'25</a>
</p>
<p>â†‘ã“ã‚Œã¯å…ƒãƒã‚¹ãƒˆã‚’èª­ã‚“ã§ï¼ˆã¨è«–æ–‡æ–œã‚èª­ã¿ï¼‰ã®æ„Ÿæƒ³ã®ã‚ˆã†ãªã‚‚ã®ãªã®ã§ã€è©³ç´°ã¯å¾Œã§å…ƒè«–æ–‡ã‚’èª­ã‚€ã€‚</p>
<p>é–¢é€£:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yukangchen_/status/1978653384539341287?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3261" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Stabilizing MoE Reinforcement Learning by Aligning Training and  Inference Routers, Wenhan Ma+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã‚’ç”¨ã„ãŸMixture-of-Expertsï¼ˆMoEï¼‰ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®ä¸ä¸€è‡´ã‚’åˆ†æã—ã€Rollout Routing Replayï¼ˆR3ï¼‰ã‚’ææ¡ˆã€‚R3ã¯æ¨è«–æ™‚ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°åˆ†å¸ƒã‚’è¨˜éŒ²ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«å†ç”Ÿã™ã‚‹ã“ã¨ã§ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®ãƒãƒªã‚·ãƒ¼é–“ã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚’æ¸›å°‘ã•ã›ã€å®‰å®šæ€§ã‚’å‘ä¸Šã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€R3ãŒRLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å´©å£Šã‚’é˜²ãã€ä»–ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1977990785795576316?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2552" target="_blank" rel="noopener noreferrer">Your Efficient RL Framework Secretly Brings You Off-Policy RL Training, Yao+, 2025.08</a>
<br><br>ã®MoEç‰ˆã®è©±ã€‚Inference Engineã¨Training Engineå´ã§Expertsã®é¸æŠãŒä¸€è‡´ã—ãªã„ã“ã¨ãŒä¸å®‰å®šã«ã¤ãªãŒã‚‹ã®ã§ã€ãã‚Œã‚’ä¸€è‡´ã•ã›ã‚‹ã‚ˆã†ã«ã™ã‚‹ã€ã¨ã„ã†è©±ãªæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/0335e297-332d-4759-9c9a-9f9e7e634b5d" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3258" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Diffusion Transformers with Representation Autoencoders, Boyang Zheng+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¾“æ¥ã®VAEã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¡¨ç¾ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã«ç½®ãæ›ãˆãŸRepresentation Autoencodersï¼ˆRAEï¼‰ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€é«˜å“è³ªãªå†æ§‹æˆã¨è±Šã‹ãªæ½œåœ¨ç©ºé–“ã‚’å®Ÿç¾ã—ã€æ‹¡æ•£ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®æ€§èƒ½å‘ä¸Šã‚’å›³ã‚‹ã€‚RAEã¯ã€è£œåŠ©çš„ãªè¡¨ç¾æ•´åˆæå¤±ãªã—ã§æ—©ã„åæŸã‚’é”æˆã—ã€ImageNetã§å„ªã‚ŒãŸç”»åƒç”Ÿæˆçµæœã‚’ç¤ºã—ãŸã€‚RAEã¯ã€æ‹¡æ•£ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®æ–°ã—ã„ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¨ã—ã¦ã®åˆ©ç‚¹ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://rae-dit.github.io" target="_blank" rel="noopener noreferrer">https://rae-dit.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1978001535717216751?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>U-Netã‚’Backboneã¨ã—ãŸVAEã®ä»£ã‚ã‚Šã«ViTã«åŸºã¥ãï¼ˆdown, up- scalingç„¡ã—ã®ï¼‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šå°‘ãªã„è¨ˆç®—é‡ã§é«˜ã„æ€§èƒ½ã‚’é”æˆã—ã¾ã—ãŸã€ã¨ã„ã£ãŸè©±ã«è¦‹ãˆã‚‹ã€‚</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1977967098736549990?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1978018195953848384?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Self-SupervisedLearning.html" target="_blank" rel="noopener noreferrer">#Self-SupervisedLearning</a>
<a class="button" href="articles/SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/WorldModels.html" target="_blank" rel="noopener noreferrer">#WorldModels</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3253" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Agent Learning via Early Experience, Kai Zhang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç›®æ¨™ã¯ã€çµŒé¨“ã‚’é€šã˜ã¦å­¦ã³ã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã§äººé–“ã‚’ä¸Šå›ã‚‹ã“ã¨ã§ã™ãŒã€å¼·åŒ–å­¦ç¿’ã«ã¯å ±é…¬ã®æ¬ å¦‚ã‚„éåŠ¹ç‡çš„ãªãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆãŒèª²é¡Œã§ã™ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè‡ªèº«ã®è¡Œå‹•ã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸç›¸äº’ä½œç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã‚‹ã€Œæ—©æœŸçµŒé¨“ã€ã¨ã„ã†æ–°ãŸãªãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã€(1) æš—é»™ã®ä¸–ç•Œãƒ¢ãƒ‡ãƒ«åŒ–ã¨(2) è‡ªå·±åçœã®2ã¤ã®æˆ¦ç•¥ã‚’ç ”ç©¶ã—ã€8ã¤ã®ç’°å¢ƒã§è©•ä¾¡ã‚’è¡Œã£ãŸçµæœã€åŠ¹æœæ€§ã¨ä¸€èˆ¬åŒ–ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚æ—©æœŸçµŒé¨“ã¯ã€å¼·åŒ–å­¦ç¿’ã®åŸºç›¤ã‚’æä¾›ã—ã€æ¨¡å€£å­¦ç¿’ã¨çµŒé¨“é§†å‹•ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ©‹æ¸¡ã—ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/godofprompt/status/1977629442307686708?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>LLM Agentã®ãŸã‚ã®Warmupæ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚å…·ä½“çš„ã«ã¯RLVRã‚„Imitation Learningã«ã‚ˆã£ã¦RewardãŒå®šç¾©ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã“ã‚Œã¾ã§ã¯RLãŒå®Ÿç¾ã•ã‚Œã¦ããŸãŒã€ã“ã‚Œã‚‰ã¯ã‚¹ã‚±ãƒ¼ãƒ«ã›ãšã€RewardãŒå®šç¾©ã•ã‚Œãªã„ç’°å¢ƒã®trajectoryãªã©ã¯å­¦ç¿’ã•ã‚Œãªã„ã®ã§æ±åŒ–æ€§èƒ½ãŒä½ã„ã¨ã„ã†èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã®ãŸã‚ã€ã“ã‚Œã‚‰ã®supervisionã¤ãã®æ–¹æ³•ã§å­¦ç¿’ã‚’ã™ã‚‹å‰ã®warmupæ‰‹æ³•ã¨ã—ã¦ã€reward-freeã®å­¦ç¿’ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ  Early Experienceã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br>&lt;img width="677" height="339" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/c2ed5999-d6d8-419d-93e9-f3358ab0ca1f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/c2ed5999-d6d8-419d-93e9-f3358ab0ca1f"&lt;/a&gt;


/&gt;<br><br>æ‰‹æ³•ã¨ã—ã¦ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ³•ãŒ2ç¨®é¡ææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚<br>### Implicit World Modeling \(IWM, å¼\(3)):<br>ã‚ã‚‹çŠ¶æ…‹s\_i ã«ãŠã„ã¦ action a\_i^{j}ã‚’ \(1 &lt; j &lt; |K|)ã‚’ã¨ã£ãŸæ™‚ã®çŠ¶æ…‹ã‚’s\_i^{j}ã¨ã—ãŸã¨ãã«ã€\(s\_i, a\_i^{j}, s\_i^{j}) ã®3ã¤çµ„ã‚’è€ƒãˆã‚‹ã€‚ã“ã‚Œã‚‰ã¯ãƒãƒªã‚·ãƒ¼ã‹ã‚‰ã®Kå›ã®rolloutã«ã‚ˆã£ã¦ç”Ÿæˆå¯èƒ½ã€‚<br>ã“ã®ã¨ãã«ã€çŠ¶æ…‹sã‚’å…¨ã¦ãƒ†ã‚­ã‚¹ãƒˆã§è¡¨ç¾ã™ã‚‹ã‚ˆã†ã«ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®next-token-prediction lossã‚’ç”¨ã„ã¦ã€ã‚ã‚‹çŠ¶æ…‹s\_jã«ãŠã„ã¦action a\_i^{k} ã‚’ã¨ã£ãŸã¨ãã«ã€s\_j^{k} ã«ãªã‚‹ã“ã¨ã‚’äºˆæ¸¬ã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šä¾‹ãˆã°ãƒ–ãƒƒã‚¯ãƒ•ãƒ©ã‚¤ãƒˆã®ã‚µã‚¤ãƒˆã§èª¤ã£ãŸæ—¥æ™‚ã‚’å…¥ã‚Œã¦ã—ã¾ã£ãŸå ´åˆã‚„ã€ã©ã“ã‹ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ãŸã¨ãã«ã©ã“ã«é·ç§»ã™ã‚‹ã‹ãªã©ã®å­¦ç¿’ã™ã‚‹ç’°å¢ƒã®ä¸–ç•ŒçŸ¥è­˜ã‚’implicitã«ãƒ¢ãƒ‡ãƒ«ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã‚‹ã€‚<br><br>### Self-Reflectionï¼ˆå¼4ï¼‰<br>ã‚‚ã†ä¸€ã¤ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã¨ã—ã¦ã€å°‚é–€å®¶ã«ã‚ˆã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ a\_i ã«ã‚ˆã£ã¦å¾—ã‚‰ã‚ŒãŸçŠ¶æ…‹ s\_i ã¨ã€ãã‚Œã‚‰ä»¥å¤–ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ a\_i^{j} ã«ã‚ˆã£ã¦å¾—ã‚‰ã‚ŒãŸçŠ¶æ…‹ s\_i^{j}ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€s\_iã¨s\_i^{j}ã‚’æ¯”è¼ƒã—ãŸã¨ãã«ã€ãªãœ a\_i ã®æ–¹ãŒa\_i^{j} ã‚ˆã‚Šã‚‚å¥½ã¾ã—ã„ã‹ã‚’èª¬æ˜ã™ã‚‹CoT C\_i^{j}ã‚’ç”Ÿæˆã—ã€ä¸‰ã¤çµ„ãƒ‡ãƒ¼ã‚¿\(s\_i, a\_i^{j}, c\_i^{j}) ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€çŠ¶æ…‹s\_iãŒgivenãªã¨ãã«ã€a\_i ã« c\_i^{j} ã‚’concatã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’äºˆæ¸¬ã§ãã‚‹ã‚ˆã†ã«next-token-prediction lossã§å­¦ç¿’ã™ã‚‹ã€‚ã¾ãŸã€ã“ã®ãƒ‡ãƒ¼ã‚¿ã ã‘ã§ãªãæ±åŒ–æ€§èƒ½ã‚’ã‚ˆã‚Šé«˜ã‚ã‚‹ãŸã‚ã«expertã«ã‚ˆã‚‹imitation learningã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿CoTãªã—ã®ãƒ‡ãƒ¼ã‚¿ã‚‚mixã—ã¦å­¦ç¿’ã‚’ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€expertã«ã‚ˆã‚‹actionã ã‘ã§å­¦ç¿’ã™ã‚‹ã‚ˆã‚Šã‚‚ã€ãªãœexpertã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãŒè‰¯ã„ã‹ã¨ã„ã†æƒ…å ±ã«åŸºã¥ã„ã¦ã‚ˆã‚Šè±Šå¯Œã§è»¢ç§»å¯èƒ½ãªå­¦ç¿’ã‚·ã‚°ãƒŠãƒ«ã‚’æ´»ç”¨ã—å­¦ç¿’ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br> <br>&lt;img width=\"712\" height=\"399\" alt=\"Image\" src=\"


&lt;a href="https://github.com/user-attachments/assets/d411ac3b-d977-4357-b715-0cf4e5b95fa2"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/d411ac3b-d977-4357-b715-0cf4e5b95fa2"&lt;/a&gt;


/&gt;<br><br>ã“ã®çµæœã€downstreamã‚¿ã‚¹ã‚¯ã§ã®performanceãŒå˜ã«Imitation Learningã‚’å®Ÿæ–½ã—ãŸå ´åˆã¨æ¯”è¼ƒã—ã¦ææ¡ˆæ‰‹æ³•ã§warmupã—ãŸæ–¹ãŒä¸€è²«ã—ã¦å‘ä¸Šã™ã‚‹ã€‚ã¾ãŸã€5.4ç¯€ã«post-trainingã¨ã—ã¦è¿½åŠ ã§GRPOã‚’å®Ÿæ–½ã—ãŸå ´åˆã‚‚ææ¡ˆæ‰‹æ³•ã«ã‚ˆã‚‹warmupã‚’å®Ÿæ–½ã—ãŸå ´åˆãŒæœ€çµ‚çš„ãªæ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>&lt;img width="668" height="596" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/a0aad636-b889-4d2d-b753-b0ad5ad4c688"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a0aad636-b889-4d2d-b753-b0ad5ad4c688"&lt;/a&gt;


/&gt;</p>
<p>IWMã¯è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’ã®æ çµ„ã¿ã ã¨æ€ã‚ã‚Œã‚‹ã®ã§ã€ã‚ˆã¬ã‚¹ã‚±ãƒ¼ãƒ«ã—ã€ã‹ã¤æ±åŒ–æ€§èƒ½ãŒé«˜ãæ§˜ã€…ãªæ‰‹æ³•ã®ãƒ™ãƒ¼ã‚¹ã¨ãªã‚Šã†ã‚‹æ‰‹æ³•ã«è¦‹ãˆã‚‹ã€‚</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1979179944258265358?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3249" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Verifying Chain-of-Thought Reasoning via Its Computational Graph, Zheng Zhao+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- Circuit-based Reasoning Verification (CRV)ã‚’ææ¡ˆã—ã€CoTã‚¹ãƒ†ãƒƒãƒ—ã®å¸°å±ã‚°ãƒ©ãƒ•ã‚’ç”¨ã„ã¦æ¨è«–ã‚¨ãƒ©ãƒ¼ã‚’æ¤œè¨¼ã€‚ã‚¨ãƒ©ãƒ¼ã®æ§‹é€ çš„ç½²åãŒäºˆæ¸¬çš„ã§ã‚ã‚Šã€ç•°ãªã‚‹æ¨è«–ã‚¿ã‚¹ã‚¯ã§ç•°ãªã‚‹è¨ˆç®—ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒç¾ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®èª¤ã£ãŸæ¨è«–ã‚’ä¿®æ­£ã™ã‚‹æ–°ãŸãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æä¾›ã—ã€LLMæ¨è«–ã®å› æœç†è§£ã‚’æ·±ã‚ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacksonatkinsx/status/1977721832909177032?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhengzhao97/status/1981717885891326409?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>transformerå†…éƒ¨ã®activationãªã©ã‹ã‚‰è¨ˆç®—ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ã—reasoningã®surfaceï¼ˆï¼è¦³æ¸¬ã§ãã‚‹ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ï¼‰ã§ã¯ãªãå†…éƒ¨çŠ¶æ…‹ã‹ã‚‰CoTã‚’verificationï¼ˆï¼CoTã®ã‚¨ãƒ©ãƒ¼ã‚’æ¤œçŸ¥ã™ã‚‹ï¼‰ã™ã‚‹ã‚ˆã†ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆwhite box method)ã‚‰ã—ã„</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3248" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] dInfer: An Efficient Inference Framework for Diffusion Language Models, Yuxin Ma+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- dLLMã®æ¨è«–ã‚’åŠ¹ç‡åŒ–ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯dInferã‚’ææ¡ˆã€‚dInferã¯4ã¤ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«åˆ†è§£ã•ã‚Œã€æ–°ã—ã„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨æœ€é©åŒ–ã‚’çµ±åˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å‡ºåŠ›å“è³ªã‚’ç¶­æŒã—ã¤ã¤ã€æ¨è«–é€Ÿåº¦ã‚’å¤§å¹…ã«å‘ä¸Šã€‚HumanEvalã§1ç§’ã‚ãŸã‚Š1,100ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¶…ãˆã€å¾“æ¥ã®ã‚·ã‚¹ãƒ†ãƒ ã«æ¯”ã¹ã¦10å€ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å®Ÿç¾ã€‚dInferã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>code:


<a href="https://github.com/inclusionAI/dInfer" target="_blank" rel="noopener noreferrer">https://github.com/inclusionAI/dInfer</a>


</p>
<p>ã¨ã†ã¨ã†dLLMã‚’é«˜é€Ÿã§inferenceã§ãã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒå‡ºãŸæ¨¡æ§˜ã€‚inclusionAIã‚ˆã‚Šã€‚</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1978662709773373856?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/meta-learning.html" target="_blank" rel="noopener noreferrer">#meta-learning</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Steering.html" target="_blank" rel="noopener noreferrer">#Steering</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3247" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Spectrum Tuning: Post-Training for Distributional Coverage and  In-Context Steerability, Taylor Sorensen+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€æ“ä½œæ€§ã‚„å‡ºåŠ›ç©ºé–“ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã€åˆ†å¸ƒã®æ•´åˆæ€§ã«ãŠã„ã¦ã‚³ã‚¹ãƒˆãŒä¼´ã†ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ã“ã‚Œã‚‰ã®è¦ä»¶ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«Spectrum Suiteã‚’å°å…¥ã—ã€90ä»¥ä¸Šã®ã‚¿ã‚¹ã‚¯ã‚’ç¶²ç¾…ã€‚ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æŠ€è¡“ãŒåŸºç¤çš„ãªèƒ½åŠ›ã‚’å¼•ãå‡ºã™ä¸€æ–¹ã§ã€æ–‡è„ˆå†…æ“ä½œæ€§ã‚’æãªã†ã“ã¨ã‚’ç™ºè¦‹ã€‚ã“ã‚Œã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«Spectrum Tuningã‚’ææ¡ˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®æ“ä½œæ€§ã‚„å‡ºåŠ›ç©ºé–“ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ma_tay_/status/1977750377484149205?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ã‚‰ã¯ãƒ¢ãƒ‡ãƒ«ã®æœ›ã¾ã—ã„æ€§è³ªã¨ã—ã¦<br>- In context steerbility: inferenceæ™‚ã«ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã«åŸºã¥ã„ã¦å‡ºåŠ›åˆ†å¸ƒã‚’å¤‰ãˆã‚‰ã‚Œã‚‹èƒ½åŠ›<br>- Valid output space coverage: ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹å¦¥å½“ãªå‡ºåŠ›ã‚’åºƒç¯„ã«ã‚«ãƒãƒ¼ã§ãã‚‹ã“ã¨<br>- Distributional Alignment: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã™ã‚‹å‡ºåŠ›åˆ†å¸ƒã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›åˆ†å¸ƒãŒè¿‘ã„ã“ã¨<br><br>ã®3ã¤ã‚’æŒ™ã’ã¦ã„ã‚‹ã€‚ãã—ã¦æ—¢å­˜ã®instruction tuningã‚„äº‹å¾Œå­¦ç¿’ã¯ã“ã‚Œã‚‰ã‚’æãªã†ã“ã¨ã‚’æŒ‡æ‘˜ã—ã¦ã„ã‚‹ã€‚<br><br>ã“ã“ã§ã€incontext steerbilityã¨ã¯ã€äº‹å‰å­¦ç¿’æ™‚ã«å¾—ãŸçŸ¥è­˜ã‚„ã€åˆ†å¸ƒã€èƒ½åŠ›ã ã‘ã«å¾“ã†ã®ã§ã¯ãªãã€contextå†…ã§æ–°ãŸã«æŒ‡å®šã—ãŸæƒ…å ±ã‚’ãƒ¢ãƒ‡ãƒ«ã«æ´»ç”¨ã•ã›ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚<br><br>ãƒ¢ãƒ‡ãƒ«ã®ä¸Šè¨˜3ã¤ã®èƒ½åŠ›ã‚’æ¸¬ã‚‹ãŸã‚ã«Spectrum Suiteã‚’å°å…¥ã™ã‚‹ã€‚ã“ã‚Œã«ã¯ã€äººé–“ã®æ§˜ã€…ãªå—œå¥½ã€numericãªåˆ†å¸ƒã®å‡ºåŠ›ã€åˆæˆãƒ‡ãƒ¼ã‚¿ä½œæˆãªã©ã®ã€ãƒ¢ãƒ‡ãƒ«å´ã§steeringã‚„å¤šæ§˜ãªåˆ†å¸ƒã¸ã®å¯¾å¿œãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ãŒå«ã¾ã‚Œã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚<br><br>ã¾ãŸä¸Šè¨˜3ã¤ã®èƒ½åŠ›ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«Spectrum Tuningã¨å‘¼ã°ã‚Œã‚‹SFTæ‰‹æ³•ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br>æ‰‹æ³•ã¯ã‚·ãƒ³ãƒ—ãƒ«ã§ã€ã‚¿ã‚¹ã‚¯T_iã«å¯¾ã™ã‚‹ å¤šæ§˜ãªinput X_i ã‚¿ã‚¹ã‚¯ã®contextï¼ˆã™ãªã‚ã¡description) Z_i ãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€T_i: X_i,Z_iâ†’P(Y_i) ã‚’å­¦ç¿’ã—ãŸã„ã€‚ã“ã“ã§ã€P(Y_i)ã¯æ½œåœ¨çš„ãªoutputã®åˆ†å¸ƒã§ã‚ã‚Šã€ç‰¹å®šã®1ã¤ã®ã‚µãƒ³ãƒ—ãƒ«yã«æœ€é©åŒ–ã™ã‚‹ã€ã¨ã„ã†è©±ã§ã¯ãªã„ç‚¹ã«æ³¨æ„ï¼ˆmeta learningã®å®šå¼åŒ–ã«ç›¸å½“ã™ã‚‹ï¼‰ã€‚<br><br>å…·ä½“çš„ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨ã—ã¦ã¯ã€ã‚¿ã‚¹ã‚¯ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€ã‚¿ã‚¹ã‚¯iã®contextã¨descriptionã‚’tokenizeã—ãŸçµæœ z_i ã¨ã€incontextã‚µãƒ³ãƒ—ãƒ«ã®ãƒšã‚¢ x_ij, y_ij ãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€output tokenã®ã¿ã«å¯¾ã—ã¦cross entropyã‚’é©ç”¨ã—ã¦SFTã‚’ã™ã‚‹ã€‚ã™ãªã‚ã¡ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæ‰‹é †ã‚’è¸ã‚€:<br><br>1. incontextã‚µãƒ³ãƒ—ãƒ«ã‚’ãƒ©ãƒ³ãƒ€ãƒ ãªã‚ªãƒ¼ãƒ€ãƒ¼ã«ã‚½ãƒ¼ãƒˆã™ã‚‹<br>2. p_dropã®ç¢ºç‡ã§description z_i ã‚’ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã—x_i0â†’y_i0ã®é †ç•ªã§concatã™ã‚‹ã€<br>2-1. descriptionãŒdropã—ãªã‹ã£ãŸå ´åˆã¯descriptionâ†’x_i0â†’y_i0ã®é †ç•ªã§concatã—å…¥åŠ›ã‚’ä½œã‚‹ã€‚<br>2-2. descriptionãŒdropã—ãŸå ´åˆã€x_i0â†’y_i0ã®é †ç•ªã§å…¥åŠ›ã‚’ä½œã‚‹ã€‚<br>3. ä»–ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’x_1â†’y_1â†’...â†’x_nâ†’y_nã®é †ç•ªã§å…¨ã¦concatã™ã‚‹ã€‚<br>4. y_{1:n}ã«å¯¾ã—ã¦ã®ã¿ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼lossã‚’é©ç”¨ã—ã€ä»–ã¯ãƒã‚¹ã‚¯ã—ã¦å­¦ç¿’ã™ã‚‹ã€‚<br><br>ä¸€è¦‹ã™ã‚‹ã¨instruct tuningã«é¡ä¼¼ã—ã¦ã„ã‚‹ãŒã€ä»¥ä¸‹ã®ç‚¹ã§ç•°ãªã£ã¦ã„ã‚‹:<br>- 1ã¤ã®promptã«å¤šãã®i.i.dãªå‡ºåŠ›ãŒå«ã¾ã‚Œã‚‹ã®ã§meta-learningãŒä¿ƒé€²ã•ã‚Œã‚‹<br>- å€‹åˆ¥ãƒ‡ãƒ¼ã‚¿ã«æœ€é©åŒ–ã•ã‚Œã‚‹ã®ã§ã¯ãªãã€ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹å…¥å‡ºåŠ›åˆ†å¸ƒãŒè‡ªç„¶ã«å­¦ç¿’ã•ã‚Œã‚‹<br>- chat styleã®ãƒ‡ãƒ¼ã‚¿ã«fittingã™ã‚‹ã®ã§ã¯ãªãã€åˆ†å¸ƒã«å¯¾ã—ã¦fittingã™ã‚‹ã“ã¨ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦ã„ã‚‹<br>- input xã‚„ã‚¿ã‚¹ã‚¯description zã‚’çœç•¥ã™ã‚‹ã“ã¨ãŒã§ãã€ãƒ¦ãƒ¼ã‚¶å…¥åŠ›ãŒå¿…ãšå­˜åœ¨ã™ã‚‹è¨­å®šã¨ã¯ç•°ãªã‚‹<br><br>ã¨ã„ã†ä¸»å¼µã‚’ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/UserBased.html" target="_blank" rel="noopener noreferrer">#UserBased</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3242" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BigCodeArena: Unveiling More Reliable Human Preferences in Code  Generation via Execution, Terry Yue Zhuo+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- BigCodeArenaã¯ã€LLMãŒç”Ÿæˆã—ãŸã‚³ãƒ¼ãƒ‰ã®è³ªã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è©•ä¾¡ã™ã‚‹ãŸã‚ã®ã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚·ãƒ³ã‚°ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã€Chatbot Arenaã‚’åŸºç›¤ã«æ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã™ã€‚14,000ä»¥ä¸Šã®ã‚³ãƒ¼ãƒ‰ä¸­å¿ƒã®ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰4,700ã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã‚µãƒ³ãƒ—ãƒ«ã‚’åé›†ã—ã€äººé–“ã®å¥½ã¿ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã—ãŸã€‚ã“ã‚Œã«åŸºã¥ãã€LLMã®ã‚³ãƒ¼ãƒ‰ç†è§£ã¨ç”Ÿæˆèƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®BigCodeRewardã¨AutoCodeArenaã¨ã„ã†2ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ç­–å®šã—ã¾ã—ãŸã€‚è©•ä¾¡ã®çµæœã€å®Ÿè¡ŒçµæœãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã€ã»ã¨ã‚“ã©ã®LLMãŒå„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€ç‰¹ã«GPT-5ã‚„Claudeã‚·ãƒªãƒ¼ã‚ºãŒã‚³ãƒ¼ãƒ‰ç”Ÿæˆæ€§èƒ½ã§ãƒªãƒ¼ãƒ‰ã—ã¦ã„ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1977694597603291492?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‰¯ã•ãã†</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Label-free.html" target="_blank" rel="noopener noreferrer">#Label-free</a>
<span class="issue_date">Issue Date: 2025-10-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3241" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Vision-Zero: Scalable VLM Self-Improvement via Strategic Gamified  Self-Play, Qinsi Wang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- Vision-Zeroã¯ã€è¦–è¦šã¨è¨€èªã®ãƒ¢ãƒ‡ãƒ«ï¼ˆVLMï¼‰ã®è‡ªå·±æ”¹å–„ã‚’ä¿ƒé€²ã™ã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³éä¾å­˜ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ä»»æ„ã®ç”»åƒãƒšã‚¢ã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸç«¶äº‰çš„ãªè¦–è¦šã‚²ãƒ¼ãƒ ã‚’é€šã˜ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã€‚ä¸»ãªç‰¹å¾´ã¯ã€æˆ¦ç•¥çš„è‡ªå·±å¯¾æˆ¦ã«ã‚ˆã‚‹è‡ªå¾‹çš„ãªãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã€ä»»æ„ã®ç”»åƒã‹ã‚‰ã®ã‚²ãƒ¼ãƒ ç”Ÿæˆã«ã‚ˆã‚‹å¤šæ§˜ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®æ¨è«–èƒ½åŠ›å‘ä¸Šã€ãã—ã¦åå¾©è‡ªå·±å¯¾æˆ¦ãƒãƒªã‚·ãƒ¼æœ€é©åŒ–ï¼ˆIterative-SPOï¼‰ã«ã‚ˆã‚‹æŒç¶šçš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã§ã‚ã‚‹ã€‚Vision-Zeroã¯ãƒ©ãƒ™ãƒ«ãªã—ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ä»–ã®æ³¨é‡ˆãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://github.com/wangqinsi1/Vision-Zero" target="_blank" rel="noopener noreferrer">https://github.com/wangqinsi1/Vision-Zero</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1977623963603005554?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã¨ã¦ã‚‚è‰¯ã•ãã†</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3191" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Markovian Thinker, Milad Aghajohari+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦é•·ã„æ€è€ƒã®é€£é–ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã€Œãƒãƒ«ã‚³ãƒ•çš„æ€è€ƒã€ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€çŠ¶æ…‹ã‚’ä¸€å®šã®ã‚µã‚¤ã‚ºã«åˆ¶é™ã—ã€æ€è€ƒã®é•·ã•ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã‚µã‚¤ã‚ºã‹ã‚‰åˆ‡ã‚Šé›¢ã™ã“ã¨ã§ã€ç·šå½¢è¨ˆç®—ã‚’å®Ÿç¾ã€‚æ–°ã—ã„RLç’°å¢ƒã€ŒDelethinkã€ã‚’æ§‹ç¯‰ã—ã€ãƒ¢ãƒ‡ãƒ«ã¯çŸ­ã„æŒã¡è¶Šã—ã§æ¨è«–ã‚’ç¶™ç¶šã™ã‚‹ã“ã¨ã‚’å­¦ç¿’ã€‚è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€é•·ã„æ¨è«–ã‚’åŠ¹ç‡çš„ã«è¡Œã„ã€ã‚³ã‚¹ãƒˆã‚’å¤§å¹…ã«å‰Šæ¸›ã€‚æ€è€ƒç’°å¢ƒã®å†è¨­è¨ˆãŒã€åŠ¹ç‡çš„ã§ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªæ¨è«–LLMã®å®Ÿç¾ã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/maghajohari/status/1976296195438887012?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1976466786565656986?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1976798665038758377?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<a class="button" href="articles/RecursiveModels.html" target="_blank" rel="noopener noreferrer">#RecursiveModels</a>
<span class="issue_date">Issue Date: 2025-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3189" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Less is More: Recursive Reasoning with Tiny Networks, Alexia Jolicoeur-Martineau, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- éšå±¤çš„æ¨è«–ãƒ¢ãƒ‡ãƒ«ï¼ˆHRMï¼‰ã¯ã€2ã¤ã®å°ã•ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ãŸæ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€æ•°ç‹¬ã‚„è¿·è·¯ãªã©ã®ãƒ‘ã‚ºãƒ«ã‚¿ã‚¹ã‚¯ã§å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚ã—ã‹ã—ã€HRMã¯æœ€é©ã§ã¯ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€æˆ‘ã€…ã¯Tiny Recursive Modelï¼ˆTRMï¼‰ã‚’ææ¡ˆã€‚TRMã¯ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ã§é«˜ã„ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’æŒã¡ã€700ä¸‡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ARC-AGI-1ã§45%ã€ARC-AGI-2ã§8%ã®ç²¾åº¦ã‚’é”æˆã—ã€ã»ã¨ã‚“ã©ã®LLMã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/deedydas/status/1976105366003044488?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1976606666591252935?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1976702931350307178?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ARC-AGIå…¬å¼ã«ã‚ˆã‚‹æ¤œè¨¼ãŒçµ‚ã‚ã‚Šå ±å‘Šã•ã‚Œã¦ã„ã‚‹çµæœãŒä¿¡é ¼ã§ãã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gregkamradt/status/1978875294934274364?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¶šå ±:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jm_alexia/status/1982447690177823086?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Sudoku Benchã§ã‚‚æ€§èƒ½æ”¹å–„ã™ã‚‹æ¨¡æ§˜ï¼Ÿ</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3187" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GDPval: Evaluating AI Model Performance on Real-World Economically  Valuable Tasks, Tejal Patwardhan+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- GDPvalã¯ã€AIãƒ¢ãƒ‡ãƒ«ã®çµŒæ¸ˆçš„ä¾¡å€¤ã®ã‚ã‚‹ã‚¿ã‚¹ã‚¯ã‚’è©•ä¾¡ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€ç±³å›½GDPã«å¯„ä¸ã™ã‚‹44ã®è·æ¥­ã‚’ã‚«ãƒãƒ¼ã€‚æœ€å‰ç·šãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯æ™‚é–“ã¨å…±ã«æ”¹å–„ã—ã€æ¥­ç•Œå°‚é–€å®¶ã«è¿‘ã¥ã„ã¦ã„ã‚‹ã€‚äººé–“ã®ç›£è¦–ã‚’åŠ ãˆãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ç„¡æ´åŠ©ã®å°‚é–€å®¶ã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã«ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚æ¨è«–åŠªåŠ›ã‚„ã‚¿ã‚¹ã‚¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®å¢—åŠ ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã€‚220ã®ã‚¿ã‚¹ã‚¯ã®ã‚´ãƒ¼ãƒ«ãƒ‰ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã€ç ”ç©¶ä¿ƒé€²ã®ãŸã‚ã®è‡ªå‹•æ¡ç‚¹ã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thom_wolf/status/1975936809021444200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3178" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generative Representational Instruction Tuning, Niklas Muennighoff+, ICLR'25, 2024.02</a>
<span class="snippet"><span>GPT Summary</span>- ç”Ÿæˆçš„è¡¨ç¾æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆGRITï¼‰ã‚’ç”¨ã„ã¦ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã‚¿ã‚¹ã‚¯ã¨åŸ‹ã‚è¾¼ã¿ã‚¿ã‚¹ã‚¯ã‚’åŒæ™‚ã«å‡¦ç†ã§ãã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚GritLM 7Bã¯MTEBã§æ–°ãŸãªæœ€å…ˆç«¯ã‚’é”æˆã—ã€GritLM 8x7Bã¯ã™ã¹ã¦ã®ã‚ªãƒ¼ãƒ—ãƒ³ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚GRITã¯ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã¨åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆã«ã‚ˆã‚‹æ€§èƒ½æå¤±ãŒãªãã€RAGã‚’60%ä»¥ä¸Šé«˜é€ŸåŒ–ã™ã‚‹åˆ©ç‚¹ã‚‚ã‚ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=BC4lIvfSzv" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=BC4lIvfSzv</a>


</p>
<p>å¾“æ¥ã¯gemerativeã‚¿ã‚¹ã‚¯ã¨embeddingã‚¿ã‚¹ã‚¯ã¯åˆ¥ã€…ã«ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã•ã‚Œã¦ã„ãŸãŒã€ãã‚Œã‚’çµ±ä¸€çš„ãªæ çµ„ã¿ã§å®Ÿæ–½ã—ã€ä¸¡æ–¹ã®ã‚¿ã‚¹ã‚¯ã§åŒç­‰ã®ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã®ä»–ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦é«˜ã„æ€§èƒ½ã‚’é”æˆã—ãŸç ”ç©¶ã€‚å¾“æ¥ã®generativeã‚¿ã‚¹ã‚¯ç”¨ã®next-token-prediction lossã¨embeddingã‚¿ã‚¹ã‚¯ç”¨ã®constastive lossã‚’çµ„ã¿åˆã‚ã›ã¦å­¦ç¿’ã™ã‚‹ï¼ˆå¼3ï¼‰ã€‚ã‚¿ã‚¹ã‚¯ã®åŒºåˆ¥ã¯instructionã«ã‚ˆã‚Šå®Ÿæ–½ã—ã€embeddingã‚¿ã‚¹ã‚¯ã®å ´åˆã¯ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®last hidden stateã®mean poolingã§representationã‚’å–å¾—ã™ã‚‹ã€‚ã¾ãŸã€embeddingã®æ™‚ã¯bi-directional attention / generativeã‚¿ã‚¹ã‚¯ã®æ™‚ã¯causal maskãŒé©ç”¨ã•ã‚Œã‚‹ã€‚ã“ã‚Œã‚‰ã®attentionã®é©ç”¨ã®ã•ã‚Œæ–¹ã®é•ã„ãŒã€ã©ã®ã‚ˆã†ã«ç®¡ç†ã•ã‚Œã‚‹ã‹ã¯ã¾ã ã—ã£ã‹ã‚Šèª­ã‚ã¦ã„ãªã„ã®ã§ã‚ˆãã‚ã‹ã£ã¦ã„ãªã„ãŒã€éå¸¸ã«èˆˆå‘³æ·±ã„ç ”ç©¶ã§ã‚ã‚‹ã€‚<br><br>&lt;img width="603" height="349" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/acb2cbcd-364d-43c7-b51a-6c5ea9866415"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/acb2cbcd-364d-43c7-b51a-6c5ea9866415"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3175" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ReasonIR: Training Retrievers for Reasoning Tasks, Rulin Shao+, COLM'25, 2025.04</a>
<span class="snippet"><span>GPT Summary</span>- ReasonIR-8Bã¯ã€ä¸€èˆ¬çš„ãªæ¨è«–ã‚¿ã‚¹ã‚¯å‘ã‘ã«ç‰¹åˆ¥ã«è¨“ç·´ã•ã‚ŒãŸåˆã®ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã§ã‚ã‚Šã€åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ç”¨ã„ã¦æŒ‘æˆ¦çš„ãªã‚¯ã‚¨ãƒªã¨ãƒãƒ¼ãƒ‰ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚’ä½œæˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€BRIGHTãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ–°ãŸãªæœ€å…ˆç«¯æˆæœã‚’é”æˆã—ã€RAGã‚¿ã‚¹ã‚¯ã§ã‚‚ä»–ã®ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¬ã‚·ãƒ”ã¯ä¸€èˆ¬çš„ã§ã€å°†æ¥ã®LLMã¸ã®æ‹¡å¼µãŒå®¹æ˜“ã§ã‚ã‚‹ã€‚ã‚³ãƒ¼ãƒ‰ã€ãƒ‡ãƒ¼ã‚¿ã€ãƒ¢ãƒ‡ãƒ«ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rulinshao/status/1975773504307142790?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Llama3.1-8Bã‚’bidirectional encoderã«å¤‰æ›ã—ã¦post-trainingã—ã¦ã„ã‚‹ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3178" target="_blank" rel="noopener noreferrer">[Paper Note] Generative Representational Instruction Tuning, Niklas Muennighoff+, ICLR'25, 2024.02</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3157" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Bayesian scaling laws for in-context learning, Aryaman Arora+, COLM'25, 2024.10</a>
<span class="snippet"><span>GPT Summary</span>- ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ï¼ˆICLï¼‰ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã«è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã•ã›ã‚‹æ‰‹æ³•ã§ã‚ã‚Šã€æä¾›ã•ã‚Œã‚‹ä¾‹ã®æ•°ã¨äºˆæ¸¬ç²¾åº¦ã«å¼·ã„ç›¸é–¢ãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ICLãŒãƒ™ã‚¤ã‚ºå­¦ç¿’è€…ã‚’è¿‘ä¼¼ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã€æ–°ã—ã„ãƒ™ã‚¤ã‚ºã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’ææ¡ˆã€‚GPT-2ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸå®Ÿé¨“ã§ã€ææ¡ˆæ³•å‰‡ãŒç²¾åº¦ã«ãŠã‘ã‚‹æ—¢å­˜ã®æ³•å‰‡ã¨ä¸€è‡´ã—ã€ã‚¿ã‚¹ã‚¯ã®äº‹å‰åˆ†å¸ƒã‚„å­¦ç¿’åŠ¹ç‡ã«é–¢ã™ã‚‹è§£é‡ˆå¯èƒ½ãªé …ã‚’æä¾›ã€‚å®Ÿé¨“ã§ã¯ã€ICLã‚’ç”¨ã„ã¦æŠ‘åˆ¶ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«èƒ½åŠ›ã‚’å†ç¾ã™ã‚‹æ¡ä»¶ã‚’äºˆæ¸¬ã—ã€LLMã®å®‰å…¨æ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=U2ihVSREUb#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=U2ihVSREUb#discussion</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stanfordnlp/status/1975574899428139413?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/UserModeling.html" target="_blank" rel="noopener noreferrer">#UserModeling</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/UserBased.html" target="_blank" rel="noopener noreferrer">#UserBased</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3154" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Impatient Users Confuse AI Agents: High-fidelity Simulations of Human  Traits for Testing Agents, Muyu He+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- TraitBasisã‚’ç”¨ã„ã¦ã€ä¼šè©±å‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å …ç‰¢æ€§ã‚’ä½“ç³»çš„ã«ãƒ†ã‚¹ãƒˆã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç‰¹æ€§ï¼ˆã›ã£ã‹ã¡ã•ã‚„ä¸€è²«æ€§ã®ãªã•ï¼‰ã‚’åˆ¶å¾¡ã—ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä½ä¸‹ã‚’è¦³å¯Ÿã€‚æœ€å‰ç·šã®ãƒ¢ãƒ‡ãƒ«ã§2%-30%ã®æ€§èƒ½ä½ä¸‹ã‚’ç¢ºèªã—ã€ç¾åœ¨ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è„†å¼±æ€§ã‚’ç¤ºã™ã€‚TraitBasisã¯ã‚·ãƒ³ãƒ—ãƒ«ã§ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ãŒé«˜ãã€ç¾å®Ÿã®äººé–“ã®ç›¸äº’ä½œç”¨ã«ãŠã‘ã‚‹ä¿¡é ¼æ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã€‚$\tau$-Traitã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãŒå¤šæ§˜ãªã‚·ãƒŠãƒªã‚ªã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è©•ä¾¡ã§ãã‚‹ã‚ˆã†ã«ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hemuyu0327/status/1975398313735389254?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å®Ÿéš›ã®äººé–“ã«ã‚ã‚‹ã‚ˆã†ãªç™–ï¼ˆã®ã‚ˆã†ãªæ‘‚å‹•ï¼‰ã‚’ä¸ãˆãŸæ™‚ã«ã©ã‚Œã ã‘ãƒ­ãƒã‚¹ãƒˆã‹ã¨ã„ã†ã®ã¯å®Ÿå¿œç”¨ä¸Šéå¸¸ã«é‡è¦ãªè¦³ç‚¹ã ã¨æ€ã‚ã‚Œã‚‹ã€‚å…ƒãƒã‚¹ãƒˆã‚’è¦‹ã‚‹ã¨ã€LLMå†…éƒ¨ã®matmulã‚’ç›´æ¥æ“ä½œã™ã‚‹ã“ã¨ã§ã€ä»»æ„ã®ãƒ¬ãƒ™ãƒ«ã®äººé–“ã®ç‰¹æ€§ï¼ˆe.g.,ç–‘ã„æ·±ã„ã€æ··ä¹±ã€ç„¦ã‚Šãªã©ï¼‰ã‚’æ¨¡å€£ã™ã‚‹æ¨¡æ§˜ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3141" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BroRL: Scaling Reinforcement Learning via Broadened Exploration, Jian Hu+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- æ¤œè¨¼å¯èƒ½ãªå ±é…¬ã‚’ç”¨ã„ãŸå¼·åŒ–å­¦ç¿’ï¼ˆRLVRï¼‰ã®æ–°ãŸãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã—ã¦BroR-Lã‚’ææ¡ˆã€‚ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã®æ•°ã‚’å¢—ã‚„ã™ã“ã¨ã§æ¢ç´¢ã‚’åºƒã’ã€ProRLã®é£½å’Œç‚¹ã‚’è¶…ãˆãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’å®Ÿç¾ã€‚ç†è«–çš„åˆ†æã«åŸºã¥ãã€ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆæ•°ã®å¢—åŠ ãŒæ­£ã—ã„ãƒˆãƒ¼ã‚¯ãƒ³ã®è³ªé‡æ‹¡å¤§ã‚’ä¿è¨¼ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚BroRLã¯3Kã®ProRLãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—ã§ã®é£½å’Œãƒ¢ãƒ‡ãƒ«ã‚’å¾©æ´»ã•ã›ã€æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gximing/status/1975364676893774209?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2011" target="_blank" rel="noopener noreferrer">[Paper Note] ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in  Large Language Models, Mingjie Liu+, NeurIPS'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2408" target="_blank" rel="noopener noreferrer">ProRL V2 - Prolonged Training Validates RL Scaling Laws, Hu+, 2025.08</a>
</p>
<p>å‰å›ã¯stepæ•°ã‚’ã“ã‚Œã¾ã§ã«ãªã„è¦æ¨¡ã§ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã•ã‚ŒRLã—ãŸãŒãã‚Œã§æ€§èƒ½ãŒé ­æ‰“ã¡ã‚’è¿ãˆã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã®ã§ã€ä»Šåº¦ã¯ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆæ•°ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã•ã›ãŸæ™‚ã«ã©ã†ãªã‚‹ã‹ã¨ã„ã†ã®ã‚’è©¦ã—ãŸã£ã½ã„ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3140" target="_blank" rel="noopener noreferrer" class="title-link">è¨€èªãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨æ©Ÿåºï¼šè§£æã¨è§£é‡ˆ, HEINZERLING+, NLP'25, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1975322325181686097?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/LatentReasoning.html" target="_blank" rel="noopener noreferrer">#LatentReasoning</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3091" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Thoughtbubbles: an Unsupervised Method for Parallel Thinking in Latent  Space, Houjun Liu+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®æ–°ã—ã„å¤‰ç¨®ã€ŒThoughtbubblesã€ã‚’ææ¡ˆã—ã€ä¸¦åˆ—é©å¿œè¨ˆç®—ã‚’æ½œåœ¨ç©ºé–“ã§å®Ÿè¡Œã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€‚æ®‹å·®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ãƒ•ã‚©ãƒ¼ã‚¯ã¾ãŸã¯å‰Šé™¤ã™ã‚‹ã“ã¨ã§ã€è¨ˆç®—ã‚’åŠ¹ç‡åŒ–ã—ã€äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«å­¦ç¿’å¯èƒ½ã€‚Thoughtbubblesã¯ã€å¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€æ¨è«–æ™‚ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ãƒ†ã‚¹ãƒˆã®æŒ™å‹•ã‚’çµ±ä¸€ã™ã‚‹å¯èƒ½æ€§ã‚’æŒã¤ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/houjun_liu/status/1973778517427937323?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é‡è¦è«–æ–‡ã«è¦‹ãˆã‚‹</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3078" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Practitioner's Guide to Multi-turn Agentic Reinforcement Learning, Ruiyi Wang+, arXiv'25, 2025.10</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å¼·åŒ–å­¦ç¿’ã«ãŠã‘ã‚‹LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨“ç·´æ–¹æ³•ã‚’ç ”ç©¶ã—ã€è¨­è¨ˆç©ºé–“ã‚’ç’°å¢ƒã€å ±é…¬ã€ãƒãƒªã‚·ãƒ¼ã®3ã¤ã®æŸ±ã«åˆ†è§£ã€‚ç’°å¢ƒã®è¤‡é›‘ã•ãŒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã«ä¸ãˆã‚‹å½±éŸ¿ã€å ±é…¬ã®å¸Œè–„æ€§ãŒè¨“ç·´ã«ä¸ãˆã‚‹åŠ¹æœã€ãƒãƒªã‚·ãƒ¼å‹¾é…æ³•ã®ç›¸äº’ä½œç”¨ã‚’åˆ†æã€‚ã“ã‚Œã‚‰ã®çŸ¥è¦‹ã‚’åŸºã«ã€è¨“ç·´ãƒ¬ã‚·ãƒ”ã‚’ææ¡ˆã—ã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¼·åŒ–å­¦ç¿’ã®ç ”ç©¶ã¨å®Ÿè·µã‚’æ”¯æ´ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1973720745445659080?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rajammanabrolu/status/1981796161280491678?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>takeawayãŒéå¸¸ã«ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„ã€‚<p>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3451" target="_blank" rel="noopener noreferrer">[Paper Note] TextWorld: A Learning Environment for Text-based Games, Marc-Alexandre CÃ´tÃ©+, Workshop on Computer Games'18 Held in Conjunction with IJCAI'18, 2018.06</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3452" target="_blank" rel="noopener noreferrer">[Paper Note] ALFWorld: Aligning Text and Embodied Environments for Interactive   Learning, Mohit Shridhar+, ICLR'21, 2020.10</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1851" target="_blank" rel="noopener noreferrer">Training Software Engineering Agents and Verifiers with SWE-Gym, Jiayi Pan+, ICML'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3064" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents, Zonghan Yang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢å·¥å­¦ï¼ˆSWEï¼‰ã¸ã®å¿œç”¨ãŒé€²ã‚“ã§ãŠã‚Šã€SWE-benchãŒé‡è¦ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ãªã£ã¦ã„ã‚‹ã€‚ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®SWE-Agentãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨å˜ä¸€ã‚¿ãƒ¼ãƒ³ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¹æ‰‹æ³•ã¯ç›¸äº’æ’ä»–çš„ã§ã¯ãªãã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒåŠ¹ç‡çš„ãªSWE-Agentã®é©å¿œã‚’å¯èƒ½ã«ã™ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€Kimi-Devã¨ã„ã†ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®SWE LLMã‚’ç´¹ä»‹ã—ã€SWE-bench Verifiedã§60.4%ã‚’é”æˆã€‚è¿½åŠ ã®é©å¿œã«ã‚ˆã‚Šã€Kimi-Devã¯SWE-Agentã®æ€§èƒ½ã‚’48.6%ã«å¼•ãä¸Šã’ã€ç§»æ¤å¯èƒ½ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿç¾ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1973544152043495779?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Agentlessã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1847" target="_blank" rel="noopener noreferrer">Demystifying LLM-based Software Engineering Agents, Chunqiu Steven Xia+, FSE'25</a>
</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yang_zonghan/status/1977022913644839329?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãƒã‚¹ãƒˆã®ä¸­ã§OpenhandsãŒåŒãƒ¢ãƒ‡ãƒ«ã‚’å†…éƒ¨ã§æ¤œè¨¼ã—ã€Openhandsã®ç’°å¢ƒå†…ã§SWE Bench Verifiedã§è©•ä¾¡ã—ãŸçµæœã€ãƒ¬ãƒãƒ¼ãƒˆå†…ã§å ±å‘Šã•ã‚Œã¦ã„ã‚‹Acc. 60.4%ã¯é”æˆã§ããšã€17%ã«ç•™ã¾ã‚‹ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ãŸæ¨¡æ§˜ã€‚<br><br>Openhandsã®èª¬æ˜ã«ã‚ˆã‚‹ã¨Agentlessã¯æ±ºã‚ã‚‰ã‚ŒãŸå›ºå®šã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã¿ã‚’å®Ÿæ–½ã™ã‚‹æ çµ„ã¿ï¼ˆKimi Devã®å ´åˆã¯BugFixerã¨FileEditor)ã§ã‚ã‚Šã€ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§å®šç¾©ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã¯åŠ¹æœçš„ã«å®Ÿæ–½ã§ãã‚‹ãŒã€ãã‚Œã‚‰ä»¥å¤–ã®ã‚¿ã‚¹ã‚¯ã¯ãã‚‚ãã‚‚ã†ã¾ãã§ããªã„ã€‚SWE Agentç³»ã®ãƒ™ãƒ³ãƒã®ãƒã‚°fixã®æ–¹æ³•ã¯å¤§ããåˆ†ã‘ã¦Agentlikeï¼ˆã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’æ¢ç´¢ã—ãŸä¸Šã§ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹å½¢å¼ï¼‰ã€Fixed workflow like Agentless(å›ºå®šã•ã‚ŒãŸãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ã¿ã‚’å®Ÿè¡Œã™ã‚‹å½¢å¼ï¼‰ã®2ç¨®é¡ãŒã‚ã‚Šã€Openhandsã¯å‰è€…ã€Kimi Devã¯å¾Œè€…ã®ä½ç½®ä»˜ã‘ã§ã‚ã‚‹ã€‚<br><br>å®Ÿéš›ã€ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã®Figure2ã¨Appendixã‚’è¦‹ã‚‹ã¨ã€File Localization+BugFixer+TestWriterã‚’å›ºå®šã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”¨ã„ã¦mid-trainingã—ã¦ãŠã‚Šã€è©•ä¾¡ã™ã‚‹éš›ã‚‚åŒæ§˜ã®ãƒãƒ¼ãƒã‚¹ãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã¨æ¨å¯Ÿã•ã‚Œã‚‹ï¼ˆã©ã“ã‹ã«æ˜ç¤ºçš„ãªè¨˜è¿°ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ï¼‰ã€‚<br>ä¸€æ–¹ã€Openhandsã§ã¯ã‚ˆã‚Šå®Ÿç’°å¢ƒã®é–‹ç™ºãƒ•ãƒ­ãƒ¼ã«è¿‘ã„ãƒãƒ¼ãƒã‚¹ï¼ˆe.g., ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’ç¢ºèªã—ã¦ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ææ¡ˆâ†’å®Ÿè¡Œå¯èƒ½ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãªã‚‰å®Ÿè¡Œâ†’ãã†ã§ãªã„ãªã‚‰ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®simulated responceã‚’å—ã‘å–ã‚‹â†’Agentã«çµæœã‚’ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯â†’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ...ï¼‰ã¨ã„ã£ãŸãƒãƒ¼ãƒã‚¹ã¨ãªã£ã¦ã„ã‚‹ã€‚<br><br>ã“ã®ã‚ˆã†ã«è©•ä¾¡ã‚’ã™ã‚‹éš›ã®ãƒãƒ¼ãƒã‚¹ãŒç•°ãªã‚‹ãŸã‚ã€åŒã˜ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å¯¾ã—ã¦ç•°ãªã‚‹æ€§èƒ½ãŒå ±å‘Šã•ã‚Œã‚‹ã€ã¨ã„ã†ã“ã¨ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>å˜ã«SWE Bench Verifiedã®Acc.ã ã‘ã‚’è¦‹ã¦ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã¶ã®ã§ã¯ãªãã€è©•ä¾¡ã•ã‚ŒãŸéš›ã®Evaluation HarnessãŒè‡ªåˆ†ãŸã¡ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«åˆã£ã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ã“ã¨ãŒé‡è¦ã ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<p>å‚è€ƒ:<br><br>- Openhandsã®Evaluation Harness:


<a href="https://docs.all-hands.dev/openhands/usage/developers/evaluation-harness" target="_blank" rel="noopener noreferrer">https://docs.all-hands.dev/openhands/usage/developers/evaluation-harness</a>


</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/interactive.html" target="_blank" rel="noopener noreferrer">#interactive</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3021" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Interactive Recommendation Agent with Active User Commands, Jiakai Tang+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å¾“æ¥ã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã¯å—å‹•çš„ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ä¾å­˜ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã‚’æ‰ãˆã‚‰ã‚Œãªã„ãŸã‚ã€å—œå¥½ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ãŒå›°é›£ã§ã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚£ãƒ¼ãƒ‰ï¼ˆIRFï¼‰ã‚’å°å…¥ã—ã€è‡ªç„¶è¨€èªã‚³ãƒãƒ³ãƒ‰ã«ã‚ˆã‚‹èƒ½å‹•çš„ãªåˆ¶å¾¡ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚RecBotã¨ã„ã†äºŒé‡ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é–‹ç™ºã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å—œå¥½ã‚’æ§‹é€ åŒ–ã—ã€ãƒãƒªã‚·ãƒ¼èª¿æ•´ã‚’è¡Œã†ã€‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¼·åŒ–çŸ¥è­˜è’¸ç•™ã‚’ç”¨ã„ã¦åŠ¹ç‡çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã€å®Ÿé¨“ã«ã‚ˆã‚Šãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦ã¨ãƒ“ã‚¸ãƒã‚¹æˆæœã®æ”¹å–„ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1972370522248745122?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ABãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã‚ˆã†ãªã®ã§ä¿¡ã´ã‚‡ã†æ€§é«˜ã‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/EvolutionaryAlgorithm.html" target="_blank" rel="noopener noreferrer">#EvolutionaryAlgorithm</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2984" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ShinkaEvolve: Towards Open-Ended And Sample-Efficient Program Evolution, Robert Tjarko Lange+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- ShinkaEvolveã¯ã€ç§‘å­¦çš„ç™ºè¦‹ã‚’ä¿ƒé€²ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€LLMsã‚’åˆ©ç”¨ã—ã¦é«˜ã„åŠ¹ç‡æ€§ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã¾ã™ã€‚å¾“æ¥ã®ã‚³ãƒ¼ãƒ‰é€²åŒ–æ‰‹æ³•ã®åˆ¶é™ã‚’å…‹æœã—ã€è¦ªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æŠ€è¡“ã‚„æ–°è¦æ€§æ‹’å¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€ãƒãƒ³ãƒ‡ã‚£ãƒƒãƒˆãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é¸æŠæˆ¦ç•¥ã‚’å°å…¥ã€‚å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã§ã®è©•ä¾¡ã«ã‚ˆã‚Šã€ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ã¨è§£ã®è³ªãŒå‘ä¸Šã—ã€150ã‚µãƒ³ãƒ—ãƒ«ã§æ–°ãŸãªæœ€å…ˆç«¯ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚ShinkaEvolveã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§ã®ã‚¢ã‚¯ã‚»ã‚¹æ€§ã‚’æä¾›ã—ã€è¨ˆç®—å•é¡Œã«ãŠã‘ã‚‹ç™ºè¦‹ã‚’æ°‘ä¸»åŒ–ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://sakana.ai/shinka-evolve/" target="_blank" rel="noopener noreferrer">https://sakana.ai/shinka-evolve/</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwiwi/status/1971109360182194502?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å›½éš›çš„ãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚¹ãƒˆã§ShinkaEvolveã®ã‚µãƒãƒ¼ãƒˆã®å…ƒã€ãƒãƒ¼ãƒ ãŒå„ªå‹ã—ãŸæ¨¡æ§˜:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwiwi/status/1978621305412075813?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/roberttlange/status/1978650939755270615?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2983" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Video models are zero-shot learners and reasoners, ThaddÃ¤us Wiedemer+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆèƒ½åŠ›ãŒè‡ªç„¶è¨€èªå‡¦ç†ã‚’å¤‰é©ã—ãŸã‚ˆã†ã«ã€ç”Ÿæˆãƒ“ãƒ‡ã‚ªãƒ¢ãƒ‡ãƒ«ã‚‚ä¸€èˆ¬ç›®çš„ã®è¦–è¦šç†è§£ã«å‘ã‹ã†å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚Veo 3ã¯ã€ç‰©ä½“ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ã‚¨ãƒƒã‚¸æ¤œå‡ºãªã©ã€è¨“ç·´ã•ã‚Œã¦ã„ãªã„å¹…åºƒã„ã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã€è¦–è¦šæ¨è«–ã®åˆæœŸå½¢æ…‹ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚Veoã®ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆèƒ½åŠ›ã¯ã€ãƒ“ãƒ‡ã‚ªãƒ¢ãƒ‡ãƒ«ãŒä¸€èˆ¬çš„ãªè¦–è¦šåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã«ãªã‚‹é“ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://video-zero-shot.github.io" target="_blank" rel="noopener noreferrer">https://video-zero-shot.github.io</a>


</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1971157183384723628?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1972010222853243097?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1973164588595290374?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2977" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] UMoE: Unifying Attention and FFN with Shared Experts, Yuanhang Yang+, arXiv'25, 2025.05</a>
<span class="snippet"><span>GPT Summary</span>- Sparse Mixture of Experts (MoE) ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€Transformer ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ãŠã„ã¦æœ‰æœ›ãªæ‰‹æ³•ã§ã‚ã‚Šã€æ³¨æ„å±¤ã¸ã®æ‹¡å¼µãŒæ¢æ±‚ã•ã‚Œã¦ã„ã¾ã™ãŒã€æ—¢å­˜ã®æ³¨æ„ãƒ™ãƒ¼ã‚¹ã® MoE å±¤ã¯æœ€é©ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚æœ¬è«–æ–‡ã§ã¯ã€æ³¨æ„å±¤ã¨ FFN å±¤ã® MoE è¨­è¨ˆã‚’çµ±ä¸€ã—ã€æ³¨æ„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®å†å®šå¼åŒ–ã‚’è¡Œã„ã€FFN æ§‹é€ ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã™ã€‚ææ¡ˆã™ã‚‹UMoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€æ³¨æ„ãƒ™ãƒ¼ã‚¹ã® MoE å±¤ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’é”æˆã—ã€åŠ¹ç‡çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å…±æœ‰ã‚’å®Ÿç¾ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nathancgy4/status/1970887450739281953?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Mixture of Attention Heads (MoA)ã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3110" target="_blank" rel="noopener noreferrer">[Paper Note] Mixture of Attention Heads: Selecting Attention Heads Per Token, Xiaofeng Zhang+, EMNLP'22, 2022.10</a>
</p>
<p>ã“ã®å›³ãŒã‚ã‹ã‚Šã‚„ã™ã„ã€‚å¾Œã»ã©èª¬æ˜ã‚’è¿½è¨˜ã™ã‚‹ã€‚ã–ã£ãã‚Šè¨€ã†ã¨ã€MoAã‚’å‰æã¨ã—ãŸã¨ãã«ã€æœ€å¾Œã®å‡ºåŠ›ã®å¤‰æ›éƒ¨åˆ†VW_oã‚’FFNã«ã‚ˆã‚‹å¤‰æ›ï¼ˆã¤ã¾ã‚ŠFFN Expertsã®ä¸€ã¤ï¼‰ã¨ã¿ãªã—ã¦ã€self-attentionã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ··ãœåˆã‚ã›ã‚‹ã¨ã„ã†è¶£æ—¨ã‚’å¤±ã‚ãªã„ç¯„å›²ã§è¨ˆç®—é †åºã‚’èª¿æ•´ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒŸãƒƒã‚¯ã‚¹ã™ã‚‹éƒ¨åˆ†ã‚’å…ˆã«æŒã£ã¦ãã‚‹ï¼‰ã™ã‚‹ã¨ã€FFNã®MoEã¨MoAã¯åŒã˜æ çµ„ã¿ã§æ‰±ãˆã‚‹ãŸã‚ã€expertsã‚’å…±æœ‰ã§ãã¦ãƒ¡ãƒ¢ãƒªã‚’å‰Šæ¸›ã§ãã€ã‹ã¤MoAã«ã‚ˆã£ã¦å¿…è¦ãªç®‡æ‰€ã®ã¿ã«attendã™ã‚‹èƒ½åŠ›ãŒé«˜ã¾ã‚Šæ€§èƒ½ã‚‚ä¸ŠãŒã‚Šã¾ã™ã€ã¿ãŸã„ãªè©±ã«è¦‹ãˆã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/44ba6bee-d1fa-4385-a4c6-2c937cc15ea5" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/248e1bc5-6c14-4b2d-9aed-c1d7359c605e" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/SpeculativeDecoding.html" target="_blank" rel="noopener noreferrer">#SpeculativeDecoding</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2976" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scaling Speculative Decoding with Lookahead Reasoning, Yichao Fu+, arXiv'25, 2025.06</a>
<span class="snippet"><span>GPT Summary</span>- Lookahead Reasoningã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€æ¨è«–ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³ãƒ‡ã‚³ãƒ¼ãƒ‰é€Ÿåº¦ã‚’å‘ä¸Šã•ã›ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚è»½é‡ãªãƒ‰ãƒ©ãƒ•ãƒˆãƒ¢ãƒ‡ãƒ«ãŒå°†æ¥ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ææ¡ˆã—ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ãŒä¸€åº¦ã®ãƒãƒƒãƒå‡¦ç†ã§å±•é–‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒ¬ãƒ™ãƒ«ã®æ¨æ¸¬ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆSDï¼‰ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’1.4å€ã‹ã‚‰2.1å€ã«æ”¹å–„ã—ã€å›ç­”ã®è³ªã‚’ç¶­æŒã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/haozhangml/status/1970607910846898488?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2964" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Heimdall: test-time scaling on the generative verification, Wenlei Shi+, arXiv'25, 2025.04</a>
<span class="snippet"><span>GPT Summary</span>- Heimdallã¯ã€é•·ã„Chain-of-Thoughtæ¨è«–ã«ãŠã‘ã‚‹æ¤œè¨¼èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®LLMã§ã‚ã‚Šã€æ•°å­¦å•é¡Œã®è§£æ±ºç²¾åº¦ã‚’62.5%ã‹ã‚‰94.5%ã«å¼•ãä¸Šã’ã€ã•ã‚‰ã«97.5%ã«é”ã™ã‚‹ã€‚æ‚²è¦³çš„æ¤œè¨¼ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€è§£æ±ºç­–ã®ç²¾åº¦ã‚’54.2%ã‹ã‚‰70.0%ã€å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§93.0%ã«å‘ä¸Šã•ã›ã‚‹ã€‚è‡ªå‹•çŸ¥è­˜ç™ºè¦‹ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚‚ä½œæˆã—ã€ãƒ‡ãƒ¼ã‚¿ã®æ¬ é™¥ã‚’ç‰¹å®šã™ã‚‹èƒ½åŠ›ã‚’ç¤ºã—ãŸã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2937" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ARE: Scaling Up Agent Environments and Evaluations, Pierre Andrews+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- Meta Agents Research Environments (ARE)ã‚’ç´¹ä»‹ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ç’°å¢ƒã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªä½œæˆã‚’æ”¯æ´ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’æä¾›ã€‚Gaia2ã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚Œã€å‹•çš„ç’°å¢ƒã¸ã®é©å¿œã‚„ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®å”åŠ›ã‚’è¦æ±‚ã€‚Gaia2ã¯éåŒæœŸã§å®Ÿè¡Œã•ã‚Œã€æ–°ãŸãªå¤±æ•—ãƒ¢ãƒ¼ãƒ‰ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã€‚å®Ÿé¨“çµæœã¯ã€çŸ¥èƒ½ã®ã‚¹ãƒšã‚¯ãƒˆãƒ«å…¨ä½“ã§ã®æ”¯é…çš„ãªã‚·ã‚¹ãƒ†ãƒ ãŒå­˜åœ¨ã—ãªã„ã“ã¨ã‚’ç¤ºã—ã€AREã®æŠ½è±¡åŒ–ãŒæ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®è¿…é€Ÿãªä½œæˆã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ã‚’å¼·èª¿ã€‚AIã®é€²å±•ã¯ã€æ„å‘³ã®ã‚ã‚‹ã‚¿ã‚¹ã‚¯ã¨å …ç‰¢ãªè©•ä¾¡ã«ä¾å­˜ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/froger_romain/status/1970120373829066982?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>GAIAã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1158" target="_blank" rel="noopener noreferrer">GAIA: a benchmark for General AI Assistants, GrÃ©goire Mialon+, N/A, arXiv'23</a>
</p>
<p>Execution, Search, Ambiguity, Adaptability, Time, Noise, Agent2Agentã®6ã¤ã®capabilityã‚’è©•ä¾¡å¯èƒ½ã€‚èˆˆå‘³æ·±ã„ã€‚</p>
<p>ç¾çŠ¶ã€å…¨ä½“çš„ã«ã¯GPT-5(high)ã®æ€§èƒ½ãŒæœ€ã‚‚è‰¯ãã€ç¶šã„ã¦Claude-4 Sonnetã¨ã„ã†æ„Ÿã˜ã«è¦‹ãˆã‚‹ã€‚OpenWeightãªãƒ¢ãƒ‡ãƒ«ã§ã¯ã€Kimi-K2ã®æ€§èƒ½ãŒé«˜ãã€ç¶šã„ã¦Qwen3-235Bã¨ã„ã†æ„Ÿã˜ã«è¦‹ãˆã‚‹ã€‚ã¾ãŸã€Figure1ã¯budgetã”ã¨ã®ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚‚ç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚ã‚·ãƒŠãƒªã‚ªå˜ä½ã®budgetãŒ$1ä»¥ä¸Šã®å ´åˆã¯GPT-5(high)ã®æ€§èƒ½ãŒæœ€ã‚‚è‰¯ã„ãŒã€$0.1--$0.4ã®é–“ã§ã¯Kiml-K2ã®æ€§èƒ½ãŒæœ€ã‚‚è‰¯ã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/039a6e69-4941-4a80-99b3-0590d1446030" alt="image" loading="lazy"></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2406" target="_blank" rel="noopener noreferrer">[Paper Note] GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models, GLM-4. 5 Team+, arXiv'25</a>
<br><br>ã—ã£ã‹ã‚Šã¨èª­ã‚ã¦ã„ãªã„ãŒGLM-4.5ã¯å«ã¾ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p>
<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1970162732470067283?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2930" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Transfusion: Predict the Next Token and Diffuse Images with One   Multi-Modal Model, Chunting Zhou+, ICLR'25, 2024.08</a>
<span class="snippet"><span>GPT Summary</span>- Transfusionã¯ã€é›¢æ•£ãƒ‡ãƒ¼ã‚¿ã¨é€£ç¶šãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹æ‰‹æ³•ã§ã€è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®æå¤±é–¢æ•°ã¨æ‹¡æ•£ã‚’çµ„ã¿åˆã‚ã›ã¦å˜ä¸€ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’è¨“ç·´ã—ã¾ã™ã€‚æœ€å¤§7Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰è¨“ç·´ã—ã€ãƒ¦ãƒ‹ãƒ¢ãƒ¼ãƒ€ãƒ«ãŠã‚ˆã³ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ç¤ºã—ã¾ã—ãŸã€‚ãƒ¢ãƒ€ãƒªãƒ†ã‚£ç‰¹æœ‰ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å±¤ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã€7Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã§ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’å®Ÿè¨¼ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=SI2hI0frk6" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=SI2hI0frk6</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2895" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Leaderboard Illusion, Shivalika Singh+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- é€²æ—æ¸¬å®šã¯ç§‘å­¦ã®é€²å±•ã«ä¸å¯æ¬ ã§ã‚ã‚Šã€Chatbot Arenaã¯AIã‚·ã‚¹ãƒ†ãƒ ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«ãŠã„ã¦é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€éå…¬é–‹ã®ãƒ†ã‚¹ãƒˆæ…£è¡ŒãŒå­˜åœ¨ã—ã€ç‰¹å®šã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒæœ‰åˆ©ã«ãªã‚‹ã“ã¨ã§ã€ã‚¹ã‚³ã‚¢ã«ãƒã‚¤ã‚¢ã‚¹ãŒç”Ÿã˜ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚ç‰¹ã«ã€Metaã®Llama-4ã«é–¢é€£ã™ã‚‹ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆLLMãƒãƒªã‚¢ãƒ³ãƒˆãŒå•é¡Œè¦–ã•ã‚Œã€ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ã®éå¯¾ç§°æ€§ãŒç”Ÿã˜ã¦ã„ã‚‹ã€‚Googleã‚„OpenAIã¯Arenaãƒ‡ãƒ¼ã‚¿ã®å¤§éƒ¨åˆ†ã‚’å ã‚ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆãƒ¢ãƒ‡ãƒ«ã¯å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã—ã‹å—ã‘å–ã£ã¦ã„ãªã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Arenaç‰¹æœ‰ã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã¸ã®éå‰°é©åˆãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã€‚ç ”ç©¶ã¯ã€Chatbot Arenaã®è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®æ”¹é©ã¨ã€å…¬æ­£ã§é€æ˜æ€§ã®ã‚ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚­ãƒ³ã‚°ã®ä¿ƒé€²ã«å‘ã‘ãŸæè¨€ã‚’è¡Œã£ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/singhshiviii/status/1968756900062753080?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è¦ãƒã‚§ãƒƒã‚¯</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/VariationalAutoEncoder.html" target="_blank" rel="noopener noreferrer">#VariationalAutoEncoder</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2870" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self Forcing: Bridging the Train-Test Gap in Autoregressive Video   Diffusion, Xun Huang+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- Self Forcingã¯ã€è‡ªå‹•å›å¸°å‹ãƒ“ãƒ‡ã‚ªæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®æ–°ã—ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã§ã€ã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãƒã‚¤ã‚¢ã‚¹ã®å•é¡Œã«å¯¾å‡¦ã—ã¾ã™ã€‚å¾“æ¥ã®æ‰‹æ³•ãŒçœŸã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ãã®ã«å¯¾ã—ã€Self Forcingã¯è‡ªå·±ç”Ÿæˆã—ãŸå‡ºåŠ›ã«åŸºã¥ã„ã¦ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆã—ã€å…¨ä½“ã®å“è³ªã‚’è©•ä¾¡ã™ã‚‹ãƒ›ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãªæå¤±ã‚’ç”¨ã„ã¾ã™ã€‚è¨ˆç®—ã‚³ã‚¹ãƒˆã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ãŸã‚ã«ã€å°‘æ•°ã‚¹ãƒ†ãƒƒãƒ—ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¨ç¢ºç‡çš„å‹¾é…åˆ‡æ–­ã‚’æ¡ç”¨ã—ã€ãƒ­ãƒ¼ãƒ«ã‚¤ãƒ³ã‚°KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å°å…¥ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ“ãƒ‡ã‚ªç”ŸæˆãŒå¯èƒ½ã§ã€éå› æœçš„æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ç”Ÿæˆå“è³ªã«åŒ¹æ•µã¾ãŸã¯ãã‚Œã‚’ä¸Šå›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://self-forcing.github.io" target="_blank" rel="noopener noreferrer">https://self-forcing.github.io</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xunhuang1995/status/1968797718593098087?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‡ªå·±å›å¸°çš„ãªå‹•ç”»ç”Ÿæˆï¼ˆã‚’ã™ã‚‹ï¼‰ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€å­¦ç¿’æ™‚ã¯ground-truchã®contextãŒåˆ©ç”¨ã—ã¦å­¦ç¿’ã•ã‚Œã‚‹ãŒã€æ¨è«–æ™‚ã¯è‡ªèº«ãŒç”Ÿæˆçµæœãã®ã‚‚ã®ã‚’contextã¨ã—ã¦åˆ©ç”¨ã™ã‚‹ãŸã‚ã€å­¦ç¿’-æ¨è«–æ™‚ã«gapãŒç”Ÿã˜ã€ï¼ˆå¾ã€…ã«èª¤å·®ãŒè“„ç©ã™ã‚‹ã“ã¨ã§ï¼‰å“è³ªãŒåŠ£åŒ–ã™ã‚‹ã¨ã„ã†å•é¡Œï¼ˆexposure biasï¼‰ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€å­¦ç¿’æ™‚ã‹ã‚‰è‡ªèº«ãŒç”Ÿæˆã—ãŸå‡ºåŠ›ã‚’contextã¨ã—ã¦ä¸ãˆã¦ç”Ÿæˆã‚’è¡Œã„ï¼ˆãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆï¼‰ã€å‹•ç”»å…¨ä½“ã«å¯¾ã—ã¦åˆ†å¸ƒã®æ•´åˆæ€§ã‚’æ¸¬ã‚‹lossã‚’å°å…¥ï¼ˆ=ãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã®èª¤å·®ã‚’æœ€å°åŒ–ã«ã™ã‚‹ã®ã§ã¯ãªãã€å‹•ç”»å…¨ä½“ã«å¯¾ã—ã¦ï¼ˆåˆ†å¸ƒã®ï¼‰èª¤å·®ã‚’æœ€é©åŒ–ã™ã‚‹ï¼‰ã™ã‚‹ã“ã¨ã§ã€exposure biasã‚’è»½æ¸›ã™ã‚‹ã€ã¨ã„ã†è©±ãªæ¨¡æ§˜ã€‚</p>
<p>çµæœçš„ã«ã€å˜ä¸€ã®RTX4090ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ“ãƒ‡ã‚ªç”ŸæˆãŒé«˜å“è³ªã«ç”Ÿæˆå¯èƒ½ã¨ãªã£ãŸï¼ˆã‹ã‚‚ã—ã‚Œãªã„ï¼‰:<br>


<a href="https://note.com/ngc_shj/n/n505b2f7cdfe4" target="_blank" rel="noopener noreferrer">https://note.com/ngc_shj/n/n505b2f7cdfe4</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2025-09-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2806" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Illusion of Diminishing Returns: Measuring Long Horizon Execution in  LLMs, Akshit Sinha+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒåç›Šã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã‹ã‚’æ¢æ±‚ã€‚å˜ä¸€ã‚¹ãƒ†ãƒƒãƒ—ã®ç²¾åº¦å‘ä¸ŠãŒã‚¿ã‚¹ã‚¯ã®é•·ã•ã«æŒ‡æ•°çš„æ”¹å–„ã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ã‚’è¦³å¯Ÿã€‚LLMsãŒé•·æœŸã‚¿ã‚¹ã‚¯ã§å¤±æ•—ã™ã‚‹ã®ã¯æ¨è«–èƒ½åŠ›ã®æ¬ å¦‚ã§ã¯ãªãå®Ÿè¡ŒãƒŸã‚¹ã«ã‚ˆã‚‹ã¨ä¸»å¼µã€‚çŸ¥è­˜ã¨è¨ˆç”»ã‚’æ˜ç¤ºçš„ã«æä¾›ã™ã‚‹ã“ã¨ã§å®Ÿè¡Œèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ææ¡ˆã€‚ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦ã‚‚è‡ªå·±æ¡ä»¶ä»˜ã‘åŠ¹æœã¯æ¸›å°‘ã›ãšã€é•·ã„ã‚¿ã‚¹ã‚¯ã§ã®ãƒŸã‚¹ãŒå¢—åŠ ã€‚æ€è€ƒãƒ¢ãƒ‡ãƒ«ã¯è‡ªå·±æ¡ä»¶ä»˜ã‘ã‚’è¡Œã‚ãšã«é•·ã„ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œå¯èƒ½ã€‚æœ€çµ‚çš„ã«ã€å®Ÿè¡Œèƒ½åŠ›ã«ç„¦ç‚¹ã‚’å½“ã¦ã‚‹ã“ã¨ã§ã€LLMsã®è¤‡é›‘ãªæ¨è«–å•é¡Œè§£æ±ºèƒ½åŠ›ã¨å˜ç´”ã‚¿ã‚¹ã‚¯ã®é•·æœŸåŒ–ã«ã‚ˆã‚‹å¤±æ•—ç†ç”±ã‚’èª¿å’Œã•ã›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shashwatgoel7/status/1966527903568637972?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>single stepã§ã®ã‚¿ã‚¹ã‚¯æ€§èƒ½ã¯ã‚µãƒã£ã¦è¦‹ãˆã¦ã‚‚ã€æˆåŠŸå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®é•·ã•ã¯ï¼ˆsingle stepã®å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ã«å¼•ãã¥ã‚‰ã‚Œã‚‹ãŸã‚ï¼‰ãƒ¢ãƒ‡ãƒ«ã®single stepã®ã‚¿ã‚¹ã‚¯æ€§èƒ½ã«å¯¾ã—ã¦æŒ‡æ•°é–¢æ•°çš„ã«åŠ¹ã„ã¦ã„ã‚‹ï¼ˆå·¦ä¸Šï¼‰ã€‚ã‚¿ã‚¹ã‚¯ãŒé•·ããªã‚Œã°ãªã‚‹ã»ã©ãƒ¢ãƒ‡ãƒ«ã¯è‡ªèº«ã®ã‚¨ãƒ©ãƒ¼ã«å¼•ããšã‚‰ã‚Œï¼ˆself conditioning;å³ä¸Š)ã€ã“ã‚Œã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå¤§ãã„ã»ã©åº¦åˆã„ãŒå¤§ãããªã‚‹ï¼ˆå³ä¸‹;  32Bã®å ´åˆcontextã«ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦å ´åˆã®loeg horizonã®Acc.ãŒ14Bã‚ˆã‚Šã‚‚ä¸‹ãŒã£ã¦ã„ã‚‹ï¼‰ã€‚ä¸€æ–¹ã§ã€å®Ÿè¡Œå¯èƒ½ãªstepæ•°ã®è¦³ç‚¹ã§è¦‹ã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„å ´åˆã®æ–¹ãŒå¤šãã®stepã‚’è¦ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã§ãã‚‹ï¼ˆå·¦ä¸‹ï¼‰ã€‚ã¾ãŸã€Thinkingãƒ¢ãƒ‡ãƒ«ã¯Self Conditioningã®å½±éŸ¿ã‚’å—ã‘ã«ããã€single stepã§å®Ÿè¡Œå¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®é•·ã•ãŒã‚ˆã‚Šé•·ããªã‚‹ï¼ˆä¸­å¤®ä¸‹ï¼‰ã€‚<br><br>ã¨ã„ã£ãŸè©±ã«è¦‹ãˆã‚‹ãŒã€è«–æ–‡ã‚’ã—ã£ã‹ã‚Šèª­ã‚“ã æ–¹ãŒè‰¯ã•ãã†ã€‚<br><br><img src="https://github.com/user-attachments/assets/a97fe1f4-5693-4ed3-9fa0-774f4c3738ab" alt="image" loading="lazy"></p>
<p>ï¼ˆå…ƒãƒã‚¹ãƒˆã‚‚è‘—è€…ãƒã‚¹ãƒˆã ãŒï¼‰è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/akshitwt/status/1966528585558303209?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã“ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã¯èª­ã‚“ã æ–¹ãŒè‰¯ã„ï¼ˆã¨ã„ã†ã‹è«–æ–‡ã‚’èª­ã‚“ã æ–¹ãŒè‰¯ã„ï¼‰ã€‚<br>ç‰¹ã«ã€**CoTãŒç„¡ã„å ´åˆã¯**single-turnã§ã»ã¨ã‚“ã©ã®ãƒ¢ãƒ‡ãƒ«ã¯5 stepã®ã‚¿ã‚¹ã‚¯ã‚’latent spaceã§æ€è€ƒã—ã€å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒã§ããªã„ã¨ã„ã†ã®ã¯èˆˆå‘³æ·±ã„ï¼ˆãŒã€ç´°ã‹ã„è¨­å®šã¯ç¢ºèªã—ãŸæ–¹ãŒè‰¯ã„ï¼‰ã€‚ãªã®ã§ã€ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¿ã‚¹ã‚¯ã¯åŸºæœ¬çš„ã«ã¯planningã‚’ã•ã›ã¦ã‹ã‚‰å‡ºåŠ›ã‚’ã•ã›ãŸæ–¹ãŒè‰¯ã„ã¨ã„ã†è©±ã‚„ã€<br><br>ã§ã¯è¤‡é›‘ãªstepãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã¯single turnã§ã¯ãªãmulti turnã«åˆ†ã‘ãŸæ–¹ãŒè‰¯ã„ã®ã‹ï¼Ÿã¨è¨€ã†ã¨ã€ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦å‚¾å‘ãŒé•ã†ã‚‰ã—ã„ã€ã¨ã„ã£ãŸè©±ãŒæ›¸ã‹ã‚Œã¦ã„ã‚‹ã€‚ãŸã¨ãˆã°ã€Qwenã¯single turnã‚’å¥½ã‚€ãŒã€Gemmaã¯multi turnã‚’å¥½ã‚€ã‚‰ã—ã„ã€‚<p>æ—¥æœ¬èªãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwashi86/status/1966969350197571833?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1968453604655907143?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2798" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MobileLLM-R1: Exploring the Limits of Sub-Billion Language Model  Reasoners with Open Training Recipes, Changsheng Zhao+, arXiv'25, 2025.09</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€æ¨è«–èƒ½åŠ›ã®å‡ºç¾ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿é‡ã«ã¤ã„ã¦å†æ¤œè¨ã—ã€ç´„2Tãƒˆãƒ¼ã‚¯ãƒ³ã®é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã§å¼·åŠ›ãªæ¨è«–ãƒ¢ãƒ‡ãƒ«ãŒæ§‹ç¯‰ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚MobileLLM-R1ã¨ã„ã†ã‚µãƒ–ãƒ“ãƒªã‚ªãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã—ã€ç‰¹ã«AIMEã‚¹ã‚³ã‚¢ã§å„ªã‚ŒãŸçµæœã‚’ç¤ºã—ãŸã€‚ã•ã‚‰ã«ã€Qwen3ã®36Tãƒˆãƒ¼ã‚¯ãƒ³ã‚³ãƒ¼ãƒ‘ã‚¹ã«å¯¾ã—ã¦ã‚‚ã€ã‚ãšã‹11.7%ã®ãƒˆãƒ¼ã‚¯ãƒ³ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸMobileLLM-R1-950Mã¯ã€è¤‡æ•°ã®æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ç«¶äº‰åŠ›ã‚’æŒã¤ã€‚ç ”ç©¶ã®è©³ç´°ãªæƒ…å ±ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1966669725389168823?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ã‚’è¦‹ã‚‹ã¨ã€optimizerã‚„ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®šã€pre/mid/post trainingã«ãŠã‘ã‚‹å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨DavaMixã«ã¤ã„ã¦ç°¡æ½”ã«è¨˜è¿°ã•ã‚Œã¦ãŠã‚Šã€ãƒ¬ã‚·ãƒ”ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ç´ æ™´ã‚‰ã—ã„ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3193" target="_blank" rel="noopener noreferrer">[Paper Note] MobileLLM: Optimizing Sub-billion Parameter Language Models for  On-Device Use Cases, Zechun Liu+, ICLR'24, 2024.02</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-09-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2776" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LiveCodeBench: Holistic and Contamination Free Evaluation of Large   Language Models for Code, Naman Jain+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€LLMã®ã‚³ãƒ¼ãƒ‰é–¢é€£èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒLiveCodeBenchã€ã‚’ææ¡ˆã€‚LeetCodeã€AtCoderã€CodeForcesã‹ã‚‰åé›†ã—ãŸ400ã®é«˜å“è³ªãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œã‚’ç”¨ã„ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚„è‡ªå·±ä¿®å¾©ã€ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œãªã©å¤šæ§˜ãªèƒ½åŠ›ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ã€‚18ã®ãƒ™ãƒ¼ã‚¹LLMã¨34ã®æŒ‡ç¤ºèª¿æ•´ã•ã‚ŒãŸLLMã‚’è©•ä¾¡ã—ã€æ±šæŸ“ã‚„éå‰°é©åˆã®å•é¡Œã‚’å®Ÿè¨¼çš„ã«åˆ†æã€‚ã™ã¹ã¦ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚’å…¬é–‹ã—ã€ã•ã‚‰ãªã‚‹åˆ†æã‚„æ–°ã—ã„ã‚·ãƒŠãƒªã‚ªã®è¿½åŠ ã‚’å¯èƒ½ã«ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆã‚‚æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2047" target="_blank" rel="noopener noreferrer">[Paper Note] LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive  Programming?, Zihan Zheng+, NeurIPS'25</a>
</p>
<p>pj page:


<a href="https://livecodebench.github.io" target="_blank" rel="noopener noreferrer">https://livecodebench.github.io</a>


</p>
<p>openreview:


<a href="https://openreview.net/forum?id=chfJJYC3iL" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=chfJJYC3iL</a>


</p>
<p>LiveCodeBenchã¯éå¸¸ã«popularãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é–¢é€£ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã ãŒã€readmeã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‚³ãƒãƒ³ãƒ‰é€šã‚Šã«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€stop tokenã«"###"ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’å‡ºåŠ›ã—ãŸLLMã®å‡ºåŠ›ãŒå¸¸ã«truncateã•ã‚Œã‚‹ã¨ã„ã†ãƒã‚°ãŒã‚ã£ãŸæ¨¡æ§˜ã€‚<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nrehiew_/status/1966180838271496247?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2726" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SpikingBrain Technical Report: Spiking Brain-inspired Large Models, Yuqi Pan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- SpikingBrainã¯ã€é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®åŠ¹ç‡çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸè„³ã«ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§ã€MetaX GPUã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’æ´»ç”¨ã€‚ç·šå½¢ãŠã‚ˆã³ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç·šå½¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã—ã€éNVIDIAãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ä¸Šã§ã®å¤§è¦æ¨¡LLMé–‹ç™ºã‚’å®Ÿç¾ã€‚SpikingBrain-7Bã¨SpikingBrain-76Bã‚’é–‹ç™ºã—ã€ç´„150Bãƒˆãƒ¼ã‚¯ãƒ³ã§ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®Transformerã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ã‚’å¤§å¹…ã«æ”¹å–„ã—ã€ä½æ¶ˆè²»é›»åŠ›ã§ã®é‹ç”¨ã‚’å¯èƒ½ã«ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/f14bertolotti/status/1964949822429069761?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>TTFTãŒ4Mã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ™‚ã«Qwen2.5ã¨æ¯”ã¹ã¦100å€é«˜é€ŸåŒ–â€¦ï¼Ÿ</p>
<p>ä¸­å›½ã®MetaXç¤¾ã®GPUãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>


<a href="https://www.metax-tech.com/en/goods/prod.html?cid=3" target="_blank" rel="noopener noreferrer">https://www.metax-tech.com/en/goods/prod.html?cid=3</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/SpeculativeDecoding.html" target="_blank" rel="noopener noreferrer">#SpeculativeDecoding</a>
<span class="issue_date">Issue Date: 2025-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2716" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] REFRAG: Rethinking RAG based Decoding, Xiaoqiang Lin+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- REFRAGã¯ã€RAGã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹é…å»¶ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®åŠ¹ç‡çš„ãªãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ã‚¹ãƒ‘ãƒ¼ã‚¹æ§‹é€ ã‚’åˆ©ç”¨ã—ã¦åˆå›ãƒˆãƒ¼ã‚¯ãƒ³ã¾ã§ã®æ™‚é–“ã‚’30.85å€åŠ é€Ÿã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºã‚’16ã¾ã§æ‹¡å¼µå¯èƒ½ã«ã—ã€ã•ã¾ã–ã¾ãªé•·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ã§ç²¾åº¦ã‚’æãªã†ã“ã¨ãªãã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dr_singularity/status/1964453705430036982?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>èˆˆå‘³æ·±ã„ã€‚Speculative Decodingã®æ–°æ‰‹æ³•ã¨ã‚‚ã¿ãªã›ãã†ã€‚</p>
<p>åŒæ™‚æœŸã«å‡ºãŸä¸‹è¨˜ç ”ç©¶ã¨æ¯”è¼ƒã—ã¦ã©ã®ã‚ˆã†ãªpros/consãŒã‚ã‚‹ã ã‚ã†ã‹ï¼Ÿ<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2699" target="_blank" rel="noopener noreferrer">[Paper Note] Set Block Decoding is a Language Model Inference Accelerator, Itai Gat+, arXiv'25</a>
</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1966292095242744186?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2710" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SWE-rebench: An Automated Pipeline for Task Collection and  Decontaminated Evaluation of Software Engineering Agents, Ibragim Badertdinov+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMãƒ™ãƒ¼ã‚¹ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®SWEã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹èª²é¡Œã¨ã—ã¦ã€é«˜å“è³ªãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ä¸è¶³ã¨æ–°é®®ãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã‚¿ã‚¹ã‚¯ã®æ¬ å¦‚ãŒæŒ™ã’ã‚‰ã‚Œã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€21,000ä»¥ä¸Šã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªPythonãƒ™ãƒ¼ã‚¹ã®SWEã‚¿ã‚¹ã‚¯ã‚’å«ã‚€å…¬çš„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆSWE-rebenchã‚’è‡ªå‹•åŒ–ã•ã‚ŒãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§æ§‹ç¯‰ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¼·åŒ–å­¦ç¿’ã«é©ã—ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æä¾›ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ±šæŸ“ã®ãªã„è©•ä¾¡ãŒå¯èƒ½ã¨ãªã‚Šã€ã„ãã¤ã‹ã®LLMã®æ€§èƒ½ãŒéå¤§è©•ä¾¡ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://swe-rebench.com" target="_blank" rel="noopener noreferrer">https://swe-rebench.com</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1963947072748412990?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã®ãªã„æœ€æ–°ã®Issueã‚’ç”¨ã„ã¦è©•ä¾¡ã—ãŸçµæœã€Sonnet 4ãŒæœ€ã‚‚é«˜æ€§èƒ½</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2702" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow  Real Instructions?, Qinyan Zhang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¾“ã†ã“ã¨ã«è‹¦åŠ´ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ã“ã‚Œã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€Inverse IFEvalã¨ã„ã†ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ãƒ¢ãƒ‡ãƒ«ãŒå¯¾ç«‹ã™ã‚‹æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ã€‚8ç¨®é¡ã®èª²é¡Œã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã€æ—¢å­˜ã®LLMã«å¯¾ã™ã‚‹å®Ÿé¨“ã‚’è¡Œã£ãŸçµæœã€éå¾“æ¥ã®æ–‡è„ˆã§ã®é©å¿œæ€§ã‚‚è€ƒæ…®ã™ã¹ãã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚Inverse IFEvalã¯ã€LLMã®æŒ‡ç¤ºéµå®ˆã®ä¿¡é ¼æ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1963822451550208101?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>èˆˆå‘³æ·±ã„</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2674" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Fantastic Pretraining Optimizers and Where to Find Them, Kaiyue Wen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- AdamWã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ã§åºƒãä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã§ã™ãŒã€ä»£æ›¿ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãŒ1.4å€ã‹ã‚‰2å€ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’æä¾›ã™ã‚‹ã¨ã„ã†ä¸»å¼µã«ã¯äºŒã¤ã®æ¬ ç‚¹ãŒã‚ã‚‹ã¨æŒ‡æ‘˜ã€‚ã“ã‚Œã‚‰ã¯ä¸å‡ç­‰ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã¨èª¤è§£ã‚’æ‹›ãè©•ä¾¡è¨­å®šã§ã‚ã‚Šã€10ç¨®é¡ã®ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã‚’ç³»çµ±çš„ã«ç ”ç©¶ã™ã‚‹ã“ã¨ã§ã€å…¬æ­£ãªæ¯”è¼ƒã®é‡è¦æ€§ã‚’ç¤ºã—ãŸã€‚ç‰¹ã«ã€æœ€é©ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã”ã¨ã«ç•°ãªã‚Šã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã«ã¤ã‚Œã¦ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—åŠ¹æœãŒæ¸›å°‘ã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚æœ€ã‚‚é«˜é€Ÿãªã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã¯è¡Œåˆ—ãƒ™ãƒ¼ã‚¹ã®å‰å‡¦ç†å™¨ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŒã€ãã®åŠ¹æœã¯ãƒ¢ãƒ‡ãƒ«ã‚¹ã‚±ãƒ¼ãƒ«ã«åæ¯”ä¾‹ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1963168542872014943?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é‡è¦ãã†ã«è¦‹ãˆã‚‹</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2675" target="_blank" rel="noopener noreferrer">[Paper Note] SOAP: Improving and Stabilizing Shampoo using Adam, Nikhil Vyas+, ICLR'25</a>
</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wen_kaiyue/status/1963633867140526319?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/percyliang/status/1963648131394122222?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è€ƒå¯Ÿ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1964098785019060719?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/AudioLanguageModel.html" target="_blank" rel="noopener noreferrer">#AudioLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2669" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] AHELM: A Holistic Evaluation of Audio-Language Models, Tony Lee+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- éŸ³å£°è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆALMsï¼‰ã®è©•ä¾¡ã«ã¯æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒæ¬ å¦‚ã—ã¦ãŠã‚Šã€ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«AHELMã‚’å°å…¥ã€‚AHELMã¯ã€ALMsã®å¤šæ§˜ãªèƒ½åŠ›ã‚’åŒ…æ‹¬çš„ã«æ¸¬å®šã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é›†ç´„ã—ã€10ã®é‡è¦ãªè©•ä¾¡å´é¢ã‚’ç‰¹å®šã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„è©•ä¾¡æŒ‡æ¨™ã‚’æ¨™æº–åŒ–ã—ã€14ã®ALMsã‚’ãƒ†ã‚¹ãƒˆã—ãŸçµæœã€Gemini 2.5 ProãŒ5ã¤ã®å´é¢ã§ãƒˆãƒƒãƒ—ã«ãƒ©ãƒ³ã‚¯ã•ã‚Œã‚‹ä¸€æ–¹ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã¯ä¸å…¬å¹³æ€§ã‚’ç¤ºã•ãªã‹ã£ãŸã€‚AHELMã¯ä»Šå¾Œã‚‚æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„ãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1962799344001917360?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/786" target="_blank" rel="noopener noreferrer">Holistic Evaluation of Language Models, Percy Liang+, TMLR'23</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<a class="button" href="articles/Science.html" target="_blank" rel="noopener noreferrer">#Science</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2618" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DeepScholar-Bench: A Live Benchmark and Automated Evaluation for  Generative Research Synthesis, Liana Patel+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ç”Ÿæˆçš„ç ”ç©¶åˆæˆã®è©•ä¾¡ã®ãŸã‚ã«ã€DeepScholar-benchã¨ã„ã†ãƒ©ã‚¤ãƒ–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨è‡ªå‹•è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚ã“ã‚Œã¯ã€ArXivè«–æ–‡ã‹ã‚‰ã‚¯ã‚¨ãƒªã‚’å¼•ãå‡ºã—ã€é–¢é€£ç ”ç©¶ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹å®Ÿéš›ã®ã‚¿ã‚¹ã‚¯ã«ç„¦ç‚¹ã‚’å½“ã¦ã€çŸ¥è­˜åˆæˆã€æ¤œç´¢å“è³ªã€æ¤œè¨¼å¯èƒ½æ€§ã‚’è©•ä¾¡ã€‚DeepScholar-baseã¯å¼·åŠ›ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ç¢ºç«‹ã—ã€ä»–ã®æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦ç«¶äº‰åŠ›ã®ã‚ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ãŸã€‚DeepScholar-benchã¯ä¾ç„¶ã¨ã—ã¦é›£æ˜“åº¦ãŒé«˜ãã€ç”Ÿæˆçš„ç ”ç©¶åˆæˆã®AIã‚·ã‚¹ãƒ†ãƒ ã®é€²æ­©ã«é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>leaderboard:


<a href="https://guestrin-lab.github.io/deepscholar-leaderboard/leaderboard/deepscholar_bench_leaderboard.html" target="_blank" rel="noopener noreferrer">https://guestrin-lab.github.io/deepscholar-leaderboard/leaderboard/deepscholar_bench_leaderboard.html</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lianapatel_/status/1961487232331911651?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Game.html" target="_blank" rel="noopener noreferrer">#Game</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2609" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TurnaboutLLM: A Deductive Reasoning Benchmark from Detective Games, Yuan Yuan+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- TurnaboutLLMã¨ã„ã†æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€æ¢åµã‚²ãƒ¼ãƒ ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ—ãƒ¬ã‚¤ã‚’é€šã˜ã¦LLMsã®æ¼”ç¹¹çš„æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã€‚è¨¼è¨€ã¨è¨¼æ‹ ã®çŸ›ç›¾ã‚’ç‰¹å®šã™ã‚‹èª²é¡Œã‚’è¨­å®šã—ã€12ã®æœ€å…ˆç«¯LLMã‚’è©•ä¾¡ã—ãŸçµæœã€æ–‡è„ˆã®ã‚µã‚¤ã‚ºã‚„æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚TurnaboutLLMã¯ã€è¤‡é›‘ãªç‰©èªç’°å¢ƒã«ãŠã‘ã‚‹LLMsã®æ¨è«–èƒ½åŠ›ã«æŒ‘æˆ¦ã‚’æä¾›ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hemuyu0327/status/1961275336530039244?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>éå¸¸ã«é¢ç™½ãã†ã€‚é€†è»¢è£åˆ¤ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã—ãŸè¶…long contextãªæ¼”ç¹¹çš„ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ãŒæœ€çµ‚çš„ãªå›ç­”ã‚’é–“é•ãˆã‚‹éš›ã¯ã‚ˆã‚Šå¤šãã®æ­£è§£ã«ã¯è²¢çŒ®ã—ãªã„Reasoning Stepã‚’ç¹°ã‚Šè¿”ã—ãŸã‚Šã€QwQ-32Bã¨GPT4.1ã¯åŒç­‰ã®æ€§èƒ½ã ãŒã€non thinkingãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹GPT4.1ãŒã‚ˆã‚Šå°‘é‡ã®Reasoning Step (æœ¬ç ”ç©¶ã§ã¯å›ç­”ã«è‡³ã‚‹ã¾ã§ã«å‡ºåŠ›ã—ãŸãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¨å®šç¾©)ã§å›ç­”ã«åˆ°é”ã—ï¼ˆï¼Test Time Scalingã®æ©æµãŒãªã„ï¼‰ã€ãƒ•ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸ãˆã¦æ€§èƒ½ãŒå‘ä¸Šã—ãŸã®ã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„å ´åˆã®ã¿ï¼ˆï¼Test Timeã®reasoningã‚ˆã‚Šã‚‚ã€in-contextã§ã®reasoningãŒé‡è¦ï¼‰ã ã£ãŸã€ã¨ã„ã£ãŸçŸ¥è¦‹ãŒã‚ã‚‹æ¨¡æ§˜ã€‚ã˜ã£ãã‚Šèª­ã¿ãŸã„ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Regularization.html" target="_blank" rel="noopener noreferrer">#Regularization</a>
<span class="issue_date">Issue Date: 2025-08-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2603" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Drop Dropout on Single-Epoch Language Model Pretraining, Houjun Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã¯éå­¦ç¿’ã‚’é˜²ãæ‰‹æ³•ã¨ã—ã¦çŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ãŒã€ç¾ä»£ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã§ã¯éå­¦ç¿’ãŒæŠ‘ãˆã‚‰ã‚Œã‚‹ãŸã‚ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€BERTã‚„Pythiaãƒ¢ãƒ‡ãƒ«ã®å˜ä¸€ã‚¨ãƒãƒƒã‚¯äº‹å‰å­¦ç¿’ã«ãŠã„ã¦ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã®å½±éŸ¿ã‚’èª¿æŸ»ã—ãŸçµæœã€ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’é©ç”¨ã—ãªã„æ–¹ãŒä¸‹æµã®æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒåˆ¤æ˜ã€‚ã¾ãŸã€ã€Œæ—©æœŸãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã€ã‚‚æ€§èƒ½ã‚’ä½ä¸‹ã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆãªã—ã§è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ¢ãƒ‡ãƒ«ç·¨é›†ã«ãŠã„ã¦ã‚‚ã‚ˆã‚ŠæˆåŠŸã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã€å˜ä¸€ã‚¨ãƒãƒƒã‚¯ã®äº‹å‰å­¦ç¿’ä¸­ã«ã¯ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã‚’çœãã“ã¨ãŒæ¨å¥¨ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1961589435197505584?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2604" target="_blank" rel="noopener noreferrer">[Paper Note] Dropout Reduces Underfitting, Zhuang Liu+, ICML'23</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2025-08-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2575" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] UQ: Assessing Language Models on Unsolved Questions, Fan Nie+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€AIãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã®ãŸã‚ã«ã€æœªè§£æ±ºã®è³ªå•ã«åŸºã¥ãæ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒUQã€ã‚’ææ¡ˆã—ã¾ã™ã€‚UQã¯ã€Stack Exchangeã‹ã‚‰åé›†ã—ãŸ500ã®å¤šæ§˜ãªè³ªå•ã‚’å«ã¿ã€é›£æ˜“åº¦ã¨ç¾å®Ÿæ€§ã‚’å…¼ã­å‚™ãˆã¦ã„ã¾ã™ã€‚è©•ä¾¡ã«ã¯ã€ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã€LLMå¯©æŸ»å“¡ã€äººé–“ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’çµ„ã¿åˆã‚ã›ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåé›†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€ç”Ÿæˆè€…-ãƒãƒªãƒ‡ãƒ¼ã‚¿ãƒ¼ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’æ´»ç”¨ã—ãŸè¤‡åˆãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥ã€å°‚é–€å®¶ã«ã‚ˆã‚‹å…±åŒæ¤œè¨¼ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãŒå«ã¾ã‚Œã¾ã™ã€‚UQã¯ã€æœ€å‰ç·šã®ãƒ¢ãƒ‡ãƒ«ãŒäººé–“ã®çŸ¥è­˜ã‚’æ‹¡å¼µã™ã‚‹ãŸã‚ã®ç¾å®Ÿçš„ãªèª²é¡Œã‚’è©•ä¾¡ã™ã‚‹æ‰‹æ®µã‚’æä¾›ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/percyliang/status/1960415128501018779?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fannie1208/status/1960387282642592042?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1967511497669767186?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Figure1ã‚’è¦‹ã‚‹ã¨ã‚³ãƒ³ã‚»ãƒ—ãƒˆãŒéå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„ã€‚ç¾åœ¨ã®LLMãŒè‹¦æˆ¦ã—ã¦ã„ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯äººé–“ãŒå›ç­”æ¸ˆã¿ã€ã‹ã¤å®Ÿä¸–ç•Œã®ãƒ‹ãƒ¼ã‚ºã«åã—ã¦æ„å›³çš„ã«ä½œã‚‰ã‚ŒãŸé«˜é›£æ˜“åº¦ãªãƒ‡ãƒ¼ã‚¿ï¼ˆç¾å®Ÿçš„ãªè¨­å®šã§ã¯ç„¡ã„ï¼‰ã§ã‚ã‚Šã€ç¾å®Ÿçš„ã§ã¯ç„¡ã„ãŒé›£æ˜“åº¦ãŒé«˜ã„ã€‚ä¸€æ–¹ã§ã€ç¾å®Ÿã«ãƒ‹ãƒ¼ã‚ºãŒã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä½œã‚‹ã¨ãã‚Œã‚‰ã¯ã—ã°ã—ã°ç°¡å˜ã™ããŸã‚Šã€ãƒãƒƒã‚­ãƒ³ã‚°å¯èƒ½ã ã£ãŸã‚Šã™ã‚‹ã€‚<br><br>ã“ã®ãŸã‚ã€ç¾å®Ÿçš„ãªè¨­å®šã§ãƒ‹ãƒ¼ã‚ºãŒã‚ã‚Šã€ã‹ã¤é›£æ˜“åº¦ãŒé«˜ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒä¸è¶³ã—ã¦ãŠã‚Šã€ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ãã‚‚ãã‚‚äººé–“ãŒã¾ã å›ç­”ã—ã¦ã„ãªã„æœªè§£æ±ºã®å•é¡Œã«ç€ç›®ã—ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä½œã‚Šã¾ã—ãŸã€ã¨ã„ã†è©±ã«è¦‹ãˆã‚‹ã€‚<br><br>å…ƒãƒã‚¹ãƒˆã‚’å’€åš¼ã™ã‚‹ã¨ã€<br><br>æœªè§£æ±ºãªå•é¡Œã¨ã„ã†ã“ã¨ã¯ReferenceãŒå­˜åœ¨ã—ãªã„ã¨ã„ã†ã“ã¨ãªã®ã§ã€ã“ã®ç‚¹ãŒèª²é¡Œã¨ãªã‚‹ã€‚ã“ã®ãŸã‚ã€UQ-Validatorã¨UQ-Platformã‚’å°å…¥ã™ã‚‹ã€‚<br><br>UQ-Validatorã¯è¤‡æ•°ã®LLMã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§å½¢æˆã•ã‚Œã€å›ç­”å€™è£œã®pre-screeningã‚’å®Ÿæ–½ã™ã‚‹ã€‚å›ç­”ã‚’ç”Ÿæˆã—ãŸLLMè‡ªèº«ï¼ˆã‚ã‚‹ã„ã¯åŒã˜ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ï¼‰ãŒValidatorã«åŠ ã‚ã‚‹ã“ã¨ã§è‡ªèº«ã®å›ç­”ã‚’overrateã™ã‚‹å•é¡ŒãŒç”Ÿã˜ã‚‹ãŒã€è¤‡æ•°LLMã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’çµ„ã‚€ã“ã¨ã§ãã®ãƒã‚¤ã‚¢ã‚¹ã‚’è»½æ¸›ã§ãã‚‹ã€ã¨ã®ã“ã¨ã€‚ã¾ãŸã€ã—ã°ã—ã°å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã‚Šã‚‚çµæœã‚’Validationã›ã‚‹æ–¹ãŒã‚¿ã‚¹ã‚¯ã¨ã—ã¦ç°¡å˜ã§ã‚ã‚Šã€å¿…ãšã—ã‚‚é©åˆ‡ã«å›ç­”ã™ã‚‹èƒ½åŠ›ã¯Validatorã«ã¯å¿…è¦ãªã„ã¨ã„ã†ç›´æ„Ÿã«åŸºã¥ã„ã¦ã„ã‚‹ã€‚ãŸã¨ãˆã°ã€Claudeã¯å›ç­”æ€§èƒ½ã¯ä½ãã¦ã‚‚Validatorã¨ã—ã¦ã¯ã†ã¾ãæ©Ÿèƒ½ã™ã‚‹ã€‚ã¾ãŸã€Validatorã¯è»¢ç§»ãŒåŠ¹ãã€ä»–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¨“ç·´ã—ãŸã‚‚ã®ã‚’æœªè§£æ±ºã®å›ç­”ã«ã‚‚é©ç”¨ã§ãã‚‹ã€‚test-timeã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚‚ã‚ã‚‹ç¨‹åº¦ä½œç”¨ã™ã‚‹ã€‚<br>ç¶šã„ã¦ã€UQ-Platformã«ãŠã„ã¦ã€å›ç­”ã¨Validatorã®å‡ºåŠ›ã‚’è¦‹ãªãŒã‚‰ã€å°‚é–€å®¶ã®æ”¯æ´ã«åŸºã¥ã„ã¦å›ç­”è©•ä¾¡ã—ã€ã¾ãŸã€ãã‚‚ãã‚‚ã®è³ªå•ã®è³ªãªã©ã«ã¤ã„ã¦ã‚³ãƒ¡ãƒ³ãƒˆã™ã‚‹ãªã©ã—ã¦æœªè§£æ±ºã®å•é¡Œã®è§£æ±ºã‚’æ”¯æ´ã§ãã‚‹ã€‚<br><br>ã¿ãŸã„ãªè©±ã‚‰ã—ã„ã€‚éå¸¸ã«é‡è¦ãªç ”ç©¶ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2568" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Nemotron-CC-Math: A 133 Billion-Token-Scale High Quality Math  Pretraining Dataset, Rabeeh Karimi Mahabadi+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„æ•°å­¦ã‚³ãƒ¼ãƒ‘ã‚¹ã€ŒNemotron-CC-Mathã€ã‚’ææ¡ˆã—ã€LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€ç§‘å­¦ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã®ãŸã‚ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½¿ç”¨ã€‚å¾“æ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ˆã‚Šã‚‚é«˜å“è³ªã§ã€æ–¹ç¨‹å¼ã‚„ã‚³ãƒ¼ãƒ‰ã®æ§‹é€ ã‚’ä¿æŒã—ã¤ã¤ã€è¡¨è¨˜ã‚’æ¨™æº–åŒ–ã€‚Nemotron-CC-Math-4+ã¯ã€ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å¤§å¹…ã«ä¸Šå›ã‚Šã€äº‹å‰å­¦ç¿’ã«ã‚ˆã‚ŠMATHã‚„MBPP+ã§ã®æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/karimirabeeh/status/1960682448867426706?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2553" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] InternVL3.5: Advancing Open-Source Multimodal Models in Versatility,  Reasoning, and Efficiency, Weiyun Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- InternVL 3.5ã¯ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®æ–°ã—ã„ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã§ã€Cascade Reinforcement Learningã‚’ç”¨ã„ã¦æ¨è«–èƒ½åŠ›ã¨åŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ç²—ã‹ã‚‰ç´°ã¸ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã«ã‚ˆã‚Šã€MMMã‚„MathVistaãªã©ã®ã‚¿ã‚¹ã‚¯ã§å¤§å¹…ãªæ”¹å–„ã‚’å®Ÿç¾ã€‚Visual Resolution Routerã‚’å°å…¥ã—ã€è¦–è¦šãƒˆãƒ¼ã‚¯ãƒ³ã®è§£åƒåº¦ã‚’å‹•çš„ã«èª¿æ•´ã€‚Decoupled Vision-Language Deploymentæˆ¦ç•¥ã«ã‚ˆã‚Šã€è¨ˆç®—è² è·ã‚’ãƒãƒ©ãƒ³ã‚¹ã•ã›ã€æ¨è«–æ€§èƒ½ã‚’æœ€å¤§16.0%å‘ä¸Šã•ã›ã€é€Ÿåº¦ã‚’4.05å€å‘ä¸Šã€‚æœ€å¤§ãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®MLLMã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã€å•†æ¥­ãƒ¢ãƒ‡ãƒ«ã¨ã®æ€§èƒ½ã‚®ãƒ£ãƒƒãƒ—ã‚’ç¸®å°ã€‚å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«ã¨ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1960076908088922147?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhihufrontier/status/1972502056209662441?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2537" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Motif 2.6B Technical Report, Junghwan Lim+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Motif-2.6Bã¯ã€26å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤åŸºç›¤LLMã§ã€é•·æ–‡ç†è§£ã®å‘ä¸Šã‚„å¹»è¦šã®æ¸›å°‘ã‚’ç›®æŒ‡ã—ã€å·®åˆ†æ³¨æ„ã‚„ãƒãƒªãƒãƒ«ãƒ æ´»æ€§åŒ–é–¢æ•°ã‚’æ¡ç”¨ã€‚åºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€åŒã‚µã‚¤ã‚ºã®æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€åŠ¹ç‡çš„ã§ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªåŸºç›¤LLMã®ç™ºå±•ã«å¯„ä¸ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1959604841577357430?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/Motif-Technologies/Motif-2.6B" target="_blank" rel="noopener noreferrer">https://huggingface.co/Motif-Technologies/Motif-2.6B</a>


</p>
<p>- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1466" target="_blank" rel="noopener noreferrer">Differential Transformer, Tianzhu Ye+, N/A, ICLR'25</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2538" target="_blank" rel="noopener noreferrer">[Paper Note] Polynomial Composition Activations: Unleashing the Dynamics of Large
  Language Models, Zhijian Zhuo+, arXiv'24</a>
<br>- å­¦ç¿’æ‰‹æ³•<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1979" target="_blank" rel="noopener noreferrer">Model Merging in Pre-training of Large Language Models, Yunshui Li+, arXiv'25</a>
<br>    - 8B tokenå­¦ç¿’ã™ã‚‹ã”ã¨ã«ç›´è¿‘6ã¤ã®checkpointã®element-wiseã®å¹³å‡ã‚’ã¨ã‚Šãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã€‚å½“è©²ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦å­¦ç¿’ã‚’ç¶™ç¶šã€ã¨ã„ã†ã“ã¨ã‚’ç¹°ã‚Šè¿”ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å­¦ç¿’ã®ãƒã‚¤ã‚ºã‚’ä½æ¸›ã—ã€çªç„¶ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚·ãƒ•ãƒˆã™ã‚‹ã“ã¨ã‚’é˜²ã<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1060" target="_blank" rel="noopener noreferrer">Effective Long-Context Scaling of Foundation Models, Wenhan Xiong+, N/A, NAACL'24</a>
<br>    - Adaptive Base Frequency (RoPEã®base frequencyã‚’10000ã‹ã‚‰500000ã«ã™ã‚‹ã“ã¨ã§long contextã®attention scoreãŒå°ã•ããªã‚Šã™ãã‚‹ã“ã¨ã‚’é˜²ã)<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2540" target="_blank" rel="noopener noreferrer">[Paper Note] MiniCPM: Unveiling the Potential of Small Language Models with Scalable
  Training Strategies, Shengding Hu+, arXiv'24</a>
 <br>- äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1943" target="_blank" rel="noopener noreferrer">DataComp-LM: In search of the next generation of training sets for
  language models, Jeffrey Li+, arXiv'24</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2539" target="_blank" rel="noopener noreferrer">TxT360, LLM360, 2024.10</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2109" target="_blank" rel="noopener noreferrer">[Paper Note] FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data  Processing to Every Language, Guilherme Penedo+, COLM'25</a>
 <br><br>ã‚’åˆ©ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã€‚åŒç¨‹åº¦ã®ã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒã§ã¯ã‹ãªã‚Šã®gainã‚’å¾—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚èˆˆå‘³æ·±ã„ã€‚<br>Datasetã®Mixtureã®æ¯”ç‡ãªã©ã«ã¤ã„ã¦ã‚‚è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>&lt;img width="705" height="441" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/0a26442e-8075-4cbe-8cc1-f1ff471b7356"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0a26442e-8075-4cbe-8cc1-f1ff471b7356"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-08-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2532" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Think with Confidence, Yichao Fu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã€ŒDeep Think with Confidenceï¼ˆDeepConfï¼‰ã€ã¯ã€LLMã®æ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹ç²¾åº¦ã¨è¨ˆç®—ã‚³ã‚¹ãƒˆã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹æ‰‹æ³•ã§ã€ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã®ä¿¡é ¼æ€§ä¿¡å·ã‚’æ´»ç”¨ã—ã¦ä½å“è³ªãªæ¨è«–ã‚’å‹•çš„ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚è¿½åŠ ã®è¨“ç·´ã‚„èª¿æ•´ã‚’å¿…è¦ã¨ã›ãšã€æ—¢å­˜ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«çµ±åˆå¯èƒ½ã§ã™ã€‚è©•ä¾¡ã®çµæœã€ç‰¹ã«é›£æ˜“åº¦ã®é«˜ã„AIME 2025ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§99.9%ã®ç²¾åº¦ã‚’é”æˆã—ã€ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’æœ€å¤§84.7%å‰Šæ¸›ã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://jiaweizzhao.github.io/deepconf" target="_blank" rel="noopener noreferrer">https://jiaweizzhao.github.io/deepconf</a>


<br>vLLMã§ã®å®Ÿè£…:


<a href="https://jiaweizzhao.github.io/deepconf/static/htmls/code_example.html" target="_blank" rel="noopener noreferrer">https://jiaweizzhao.github.io/deepconf/static/htmls/code_example.html</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiawzhao/status/1958982524333678877?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>tooluseã€è¿½åŠ ã®è¨“ç·´ãªã—ã§ã€ã©ã®ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã«ã‚‚é©ç”¨ã§ãã€85%ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³é‡ã‚’æ¸›ã‚‰ã—ãŸä¸Šã§ã€OpenModelã§åˆã‚ã¦AIME2025ã«ãŠã„ã¦99% Acc.ã‚’é”æˆã—ãŸæ‰‹æ³•ã¨ã®ã“ã¨ã€‚vLLMã‚’ç”¨ã„ã¦50 lineç¨‹åº¦ã§å®Ÿè£…ã§ãã‚‹ã‚‰ã—ã„ã€‚</p>
<p>reasoning traceã®confidence(i.e., å¯¾æ•°å°¤åº¦)ã‚’group sizeã‚’æ±ºã‚ã¦windowå˜ä½ã§æ±ºå®šã—ã€ãã‚Œã‚‰ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒ—ãƒ­ã‚»ã‚¹ã§æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€å“è³ªã®ä½ã„reasoning traceã«åŸºã¥ãçµæœã‚’æ’é™¤ã—ã¤ã¤ã€majority votingã«æ´»ç”¨ã™ã‚‹æ–¹æ³•ã€‚ç›´æ„Ÿçš„ã«ã‚‚ã†ã¾ãã„ããã†ã€‚ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã¨ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã®æ¨è«–ã«ã‚ˆã£ã¦æ´»ç”¨æ–¹æ³•ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚ã‚ã¨ã§ã—ã£ã‹ã‚Šèª­ã‚“ã§æ›¸ãã€‚Confidenceã®å®šç¾©ã®ä»•æ–¹ã¯ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®bottom 10%ã€tailãªã©ã•ã¾ã–ã¾ãªå®šç¾©æ–¹æ³•ã¨ã€ãã‚Œã‚‰ã«åŸºã¥ã„ãŸconfidenceã«ã‚ˆã‚‹votingã®é‡ã¿ä»˜ã‘ãŒè¤‡æ•°è€ƒãˆã‚‰ã‚Œã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã«ã‚ˆã£ã¦ä½¿ã„åˆ†ã‘ã‚‹æ¨¡æ§˜ã€‚<br><br>vLLMã«PRã‚‚å‡ºã¦ã„ã‚‹æ¨¡æ§˜ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2518" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents, Shilong Li+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- MM-BrowseCompã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¤œç´¢ãŠã‚ˆã³æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€224ã®æ‰‹ä½œã‚Šã®è³ªå•ã‚’å«ã‚€ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç”»åƒã‚„å‹•ç”»ã‚’å«ã‚€æƒ…å ±ã®é‡è¦æ€§ã‚’è€ƒæ…®ã—ã€ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®æ‰‹æ³•ã®é™ç•Œã‚’ç¤ºã™ã€‚æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã§ã¯ã€OpenAI o3ãªã©ã®ãƒˆãƒƒãƒ—ãƒ¢ãƒ‡ãƒ«ã§ã‚‚29.02%ã®ç²¾åº¦ã«ã¨ã©ã¾ã‚Šã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«èƒ½åŠ›ã®æœ€é©åŒ–ä¸è¶³ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gezhang86038849/status/1958381269617955165?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2517" target="_blank" rel="noopener noreferrer" class="title-link">PLaMo Translate: ç¿»è¨³ç‰¹åŒ–å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é–‹ç™º,ä»ŠåŸ+, Jxiv'25</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imos/status/1958687896321630355?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>SFT-&gt;Iterative DPO-&gt;Model Mergeã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€‚SFTã§ã¯é’ç©ºæ–‡åº«ãªã©ã®ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŒ‡ç¤ºè¿½å¾“æ€§èƒ½ã®é«˜ã„DeepSeek-V3-0324ã«ã‚ˆã£ã¦å…ƒãƒ‡ãƒ¼ã‚¿â†’ç¿»è¨³, ç¿»è¨³â†’å†ç¿»è¨³ãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã—æ´»ç”¨ã€‚ã¾ãŸã€ç¿»è¨³ã®æŒ‡ç¤ºãŒpromptä¸­ã«å­˜åœ¨ã›ãšã¨ã‚‚ï¼ˆæœ¬ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹ã®ã¯ç¿»è¨³ç”¨é€”ã§ã‚ã‚‹ã“ã¨ãŒè‡ªæ˜ã§ã‚ã‚‹ã‹ã‚‰ã¨æ¨å¯Ÿã•ã‚Œã‚‹ï¼‰ç¿»è¨³ã‚’é©åˆ‡ã«å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã€ç‹¬è‡ªã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å­¦ç¿’ã€‚æ–‡ä½“æŒ‡å®šã€å¸¸ä½“ã€æ•¬ä½“ã®æŒ‡å®šã€æ–‡è„ˆè€ƒæ…®ã€èªå½™æŒ‡å®šãã‚Œãã‚Œã«ã†ã„ã¦ç‹¬è‡ªã®ã‚¿ã‚°ã‚’è¨­ã‘ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å½¢æˆã—ç¿»è¨³ã«ç‰¹åŒ–ã—ãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å­¦ç¿’ã€‚<br><br>IterativeDPOã§ã¯ã€DeepSeekV3ã«åŸºã¥ãLLM-as-a-Judgeã¨ã€MetricX(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2658" target="_blank" rel="noopener noreferrer">[Paper Note] MetricX-24: The Google Submission to the WMT 2024 Metrics Shared Task, Juraj Juraska+, arXiv'24</a>
)ã«åŸºã¥ã„ã¦Reward Modelã‚’ãã‚Œãã‚Œå­¦ç¿’ã—ã€1ã¤ã®å…¥åŠ›ã«å¯¾ã—ã¦100å€‹ã®ç¿»è¨³ã‚’ä½œæˆã—ãã‚Œãã‚Œã®Rewardãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚³ã‚¢ã®åˆè¨ˆå€¤ã«åŸºã¥ã„ã¦Rejection Samplingã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§Preference dataã‚’æ§‹ç¯‰ã€‚3æ®µéšã®DPOã‚’å®Ÿæ–½ã—ã€æ®µéšã”ã¨ã«Rewardãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ã¦é«˜å“è³ªãªPreference Dataã«çµã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã€‚<br><br>ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã§ã¯DPOã®å„æ®µéšã®ãƒ¢ãƒ‡ãƒ«ã‚’é‡ã¿ä»˜ãã§ãƒãƒ¼ã‚¸ã™ã‚‹ã“ã¨ã§å„æ®µéšã§ã®é•·æ‰€ã‚’çµ„ã¿åˆã‚ã›ãŸã¨ã®ã“ã¨ã€‚</p>
<p>ã‚µãƒ¼ãƒ“ã‚¹ãƒªãƒªãƒ¼ã‚¹:


<a href="https://prtimes.jp/main/html/rd/p/000000019.000156310.html?hm_ct=d17807e98595783ee6edfc7ae00fe95a&hm_cv=87e6d4e056b010261ecdc77d7ac8eb6c&hm_cs=1638145470668f4b36f218d2.35741174&hm_mid=m3hk6&hm_id=m3hk6&hm_h=a03.hm-f.jp" target="_blank" rel="noopener noreferrer">https://prtimes.jp/main/html/rd/p/000000019.000156310.html?hm_ct=d17807e98595783ee6edfc7ae00fe95a&hm_cv=87e6d4e056b010261ecdc77d7ac8eb6c&hm_cs=1638145470668f4b36f218d2.35741174&hm_mid=m3hk6&hm_id=m3hk6&hm_h=a03.hm-f.jp</a>


</p>
<p>2025.1010é…ä¿¡ã®ã€Œå²¡é‡åŸå¤§è¼”ã®ãƒ©ãƒ³ãƒã‚¿ã‚¤ãƒ ãƒˆãƒ¼ã‚¯ Vol.52 ç•ªå¤–ç·¨ã€ŒãªãœPLaMoç¿»è¨³ã¯è‡ªç„¶ãªã®ã‹ï¼Ÿã€ã«ãŠã„ã¦è©³ç´°ãŒèªã‚‰ã‚Œã¦ã„ã‚‹ã®ã§å‚ç…§ã®ã“ã¨ã€‚ç‰¹ã«ãªãœæ—¥æœ¬èªã«å¼·ã„LLMãŒå¤§äº‹ãªã®ã‹ï¼Ÿã¨ã„ã†è©±ãŒéå¸¸ã«ãŠã‚‚ã—ã‚ã‹ã£ãŸã€‚</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2475" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid  Mamba-Transformer Reasoning Model, NVIDIA+, arXiv'25, 2025.08</a>
<span class="snippet"><span>GPT Summary</span>- Nemotron-Nano-9B-v2ã¯ã€æ¨è«–ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å‘ä¸Šã•ã›ã¤ã¤æœ€å…ˆç«¯ã®ç²¾åº¦ã‚’é”æˆã™ã‚‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰Mamba-Transformerãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ã€‚è‡ªå·±æ³¨æ„å±¤ã®ä¸€éƒ¨ã‚’Mamba-2å±¤ã«ç½®ãæ›ãˆã€é•·ã„æ€è€ƒãƒˆãƒ¬ãƒ¼ã‚¹ã®ç”Ÿæˆã‚’é«˜é€ŸåŒ–ã€‚12å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’20å…†ãƒˆãƒ¼ã‚¯ãƒ³ã§äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€Minitronæˆ¦ç•¥ã§åœ§ç¸®ãƒ»è’¸ç•™ã€‚æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦ã€æœ€å¤§6å€ã®æ¨è«–ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’å®Ÿç¾ã—ã€ç²¾åº¦ã‚‚åŒç­‰ä»¥ä¸Šã€‚ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯Hugging Faceã§å…¬é–‹äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1957583208494579909?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>äº‹å‰å­¦ç¿’ã«åˆ©ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚‚å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã¨ã®ã“ã¨(Nemotron-CC):<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1957604137379742022?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1958290562160996688?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚µãƒãƒª:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1960840554868302082?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/CrossDomain.html" target="_blank" rel="noopener noreferrer">#CrossDomain</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-08-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2466" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] xbench: Tracking Agents Productivity Scaling with Profession-Aligned  Real-World Evaluations, Kaiyuan Chen+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã€Œxbenchã€ã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã¨å®Ÿä¸–ç•Œã®ç”Ÿç”£æ€§ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åŸ‹ã‚ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸå‹•çš„ãªè©•ä¾¡ã‚¹ã‚¤ãƒ¼ãƒˆã§ã€æ¥­ç•Œå°‚é–€å®¶ãŒå®šç¾©ã—ãŸã‚¿ã‚¹ã‚¯ã‚’ç”¨ã„ã¦å•†æ¥­çš„ã«é‡è¦ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã—ã¦ã„ã¾ã™ã€‚ãƒªã‚¯ãƒ«ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã¨ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã®2ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’æç¤ºã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®åŸºæº–ã‚’ç¢ºç«‹ã—ã¾ã™ã€‚è©•ä¾¡çµæœã¯ç¶™ç¶šçš„ã«æ›´æ–°ã•ã‚Œã€https://xbench.org ã§å…¥æ‰‹å¯èƒ½ã§ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2451" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents, Jason Wei+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- BrowseCompã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¦ã‚§ãƒ–ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã®1,266ã®è³ªå•ã‹ã‚‰ãªã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€çµ¡ã¿åˆã£ãŸæƒ…å ±ã‚’æ¢ã™ã“ã¨ã‚’è¦æ±‚ã—ã¾ã™ã€‚ã‚·ãƒ³ãƒ—ãƒ«ã§ä½¿ã„ã‚„ã™ãã€çŸ­ã„å›ç­”ãŒæ±‚ã‚ã‚‰ã‚Œã€å‚ç…§å›ç­”ã¨ã®ç…§åˆãŒå®¹æ˜“ã§ã™ã€‚ã“ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã€ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®é‡è¦ãªãƒ„ãƒ¼ãƒ«ã§ã‚ã‚Šã€æŒç¶šåŠ›ã¨å‰µé€ æ€§ã‚’æ¸¬å®šã—ã¾ã™ã€‚è©³ç´°ã¯GitHubã§å…¥æ‰‹å¯èƒ½ã§ã™ã€‚</span>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2436" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OpenCUA: Open Foundations for Computer-Use Agents, Xinyuan Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- OpenCUAã¯ã€CUAãƒ‡ãƒ¼ã‚¿ã¨åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚¤ãƒ³ãƒ•ãƒ©ã€AgentNetãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€åå°„çš„ãªChain-of-Thoughtæ¨è«–ã‚’æŒã¤ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æä¾›ã€‚OpenCUA-32Bã¯ã€CUAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§34.8%ã®æˆåŠŸç‡ã‚’é”æˆã—ã€æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ç¤ºã™ã€‚ç ”ç©¶ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãŸã‚ã«ã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1956157162830418062?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xywang626/status/1956400403911962757?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>CUAã«ãŠã„ã¦Proprietaryãƒ¢ãƒ‡ãƒ«ã«è¿‘ã„æ€§èƒ½ã‚’é”æˆã—ãŸåˆã‚ã¦ã®ç ”ç©¶ãªæ¨¡æ§˜ã€‚é‡è¦</p>
<p>ç¶šå ±:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xywang626/status/1973426575837438389?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>OSWorld Verifiedã§UI-TARS-250705,claude-4-sonnet-20250514è¶…ãˆã§top1ã«å›è‡¨ã¨ã®ã“ã¨ã€‚</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/Cultural.html" target="_blank" rel="noopener noreferrer">#Cultural</a>
<span class="issue_date">Issue Date: 2025-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2413" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Grounding Multilingual Multimodal LLMs With Cultural Knowledge, Jean de Dieu Nyandwi+, EMNLP'25</a>
<span class="snippet"><span>GPT Summary</span>- MLLMsã¯é«˜ãƒªã‚½ãƒ¼ã‚¹ç’°å¢ƒã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ãŒã€ä½ãƒªã‚½ãƒ¼ã‚¹è¨€èªã‚„æ–‡åŒ–çš„ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«å¯¾ã—ã¦ã¯èª²é¡ŒãŒã‚ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€Wikidataã‚’æ´»ç”¨ã—ã€æ–‡åŒ–çš„ã«é‡è¦ãªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’è¡¨ã™ç”»åƒã‚’ç”¨ã„ãŸå¤šè¨€èªè¦–è¦šè³ªå•å¿œç­”ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒCulturalGroundã€ã‚’ç”Ÿæˆã€‚CulturalPangeaã¨ã„ã†ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®MLLMã‚’è¨“ç·´ã—ã€æ–‡åŒ–ã«åŸºã¥ã„ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒMLLMsã®æ–‡åŒ–çš„ã‚®ãƒ£ãƒƒãƒ—ã‚’ç¸®å°ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚CulturalPangeaã¯ã€å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¹³å‡5.0ãƒã‚¤ãƒ³ãƒˆä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1955308632305782957?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>pj page:


<a href="https://neulab.github.io/CulturalGround/" target="_blank" rel="noopener noreferrer">https://neulab.github.io/CulturalGround/</a>


<br><br>VQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸­ã®æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã¯3.1%ç¨‹åº¦ã§ã€&lt;image, Question, answer&gt;ã®3ã¤çµ„ã§æ§‹æˆã•ã‚Œã‚‹ã€‚wikidataã‹ã‚‰ç‰¹å®šã®æ–‡åŒ–ã¨ç´ã¥ã„ãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆ42ã‚«å›½; äºº,å ´æ‰€,çµ„ç¹”,ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ï¼‰ã‚’æŠ½å‡ºã—ã€é–¢é€£ã™ã‚‹image dataã‚’1--3å€‹ç¨‹åº¦wikimediaã‹ã‚‰åé›†ã€‚76ç¨®é¡ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”¨ã„ã¦ã€draftã®QAã‚’ç”Ÿæˆã—ã€LLMã‚’ç”¨ã„ã¦æ´—ç·´ï¼ˆæ–‡åŒ–çš„ãªè‡ªç„¶ã•ã€æµæš¢ã•ï¼‰ã•ã›ã‚‹ã€‚æœ€çµ‚çš„ã«VLM(Qwen2.5-VL-32B/72B or Gemma-3-12B/72B-Instructã‚’æ–‡åŒ–ã”ã¨ã«å¼·ã„æ–¹ã‚’é¸æŠã—ã¦åˆ©ç”¨)ã‚’ç”¨ã„ã¦irrelevantãªimage, question, answerã®ä¸‰ã¤çµ„ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆrelevanceã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã¨äº‹å®Ÿæƒ…å ±ã®verification)ã™ã‚‹ã€‚<br><br>ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2470" target="_blank" rel="noopener noreferrer">[Paper Note] Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages, Xiang Yue+, arXiv'24</a>
<br><br>ã‚’åˆ©ç”¨(Qwen2-7Bã«å¯¾ã—ã¦CLIPãƒ™ãƒ¼ã‚¹ã®vision encoderã‚’åˆ©ç”¨ã—ãŸVLM)ã—ã€Vision Encoderã¯frozenã—ã€LLMã¨connectorï¼ˆãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®æ©‹æ¸¡ã—ã‚’ã™ã‚‹ï¼ˆå¤§æŠµã¯ï¼‰MLP)ã®ã¿ã‚’finetuningã—ãŸã€‚catastrophic forgettingã‚’é˜²ããŸã‚ã«äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã‚’è£œå®Œã—finetuningã§ã‚‚åˆ©ç”¨ã—ã€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã®èªè­˜åŠ›ã‚’é«˜ã‚ã‚‹ãŸã‚ã«M3LSãƒ‡ãƒ¼ã‚¿ãªã‚‹ã‚‚ã®ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦è¿½åŠ ã—ã¦ã„ã‚‹ã€‚<br><br>Finetuningã®çµæœã€æ–‡åŒ–çš„ãªå¤šæ§˜æ€§ã‚’æŒã¤è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ï¼ˆe.g., <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2471" target="_blank" rel="noopener noreferrer">[Paper Note] CVQA: Culturally-diverse Multilingual Visual Question Answering
  Benchmark, David Romero+, arXiv'24</a>
 Figure1ã®Japaneseã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¦‹ã‚‹ã¨ä¸€ç›®ã§ã©ã®ã‚ˆã†ãªãƒ™ãƒ³ãƒã‹åˆ†ã‹ã‚‹ï¼‰ã¨ä¸€èˆ¬çš„ãªãƒãƒ«ãƒãƒªãƒ³ã‚¬ãƒ«ãªè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®åŒæ–¹ã§gainãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚<br><img src="https://github.com/user-attachments/assets/61b33047-4c7c-4785-99f7-bcaa131bcfbf" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/8088e61f-ef46-4bcd-bc94-8d6f6318ca0e" alt="image" loading="lazy"><br><br>VQAã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã§åˆ©ç”¨ã•ã‚ŒãŸpromptã¯ä¸‹è¨˜<br><img src="https://github.com/user-attachments/assets/a9c5b463-a3e3-4565-b2f2-95268252179d" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2406" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GLM-4.5: Agentic, Reasoning, and Coding ï¼ˆARCï¼‰ Foundation Models, GLM-4. 5 Team+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- 355Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®Mixture-of-Expertsãƒ¢ãƒ‡ãƒ«GLM-4.5ã‚’ç™ºè¡¨ã€‚ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¨è«–æ‰‹æ³•ã‚’æ¡ç”¨ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçš„ã€æ¨è«–ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã€‚ç«¶åˆãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã¦å°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§ä¸Šä½ã«ãƒ©ãƒ³ã‚¯ã‚¤ãƒ³ã€‚GLM-4.5ã¨ãã®ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆç‰ˆGLM-4.5-Airã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã€è©³ç´°ã¯GitHubã§å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/grad62304977/status/1954805614011453706?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£<br>  - MoE / sigmoid gates<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1754" target="_blank" rel="noopener noreferrer">Switch Transformers: Scaling to Trillion Parameter Models with Simple  and Efficient Sparsity, William Fedus+, JMLR'22</a>
<br>  - loss free balanced routing<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2442" target="_blank" rel="noopener noreferrer">[Paper Note] Auxiliary-Loss-Free Load Balancing Strategy for Mixture-of-Experts, Lean Wang+, arXiv'24</a>
<br>  - widthã‚’å°ã•ãã€depthã‚’å¢—ã‚„ã™ã“ã¨ã§reasoningèƒ½åŠ›æ”¹å–„<br>  - GQA w/ partial RoPE<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1310" target="_blank" rel="noopener noreferrer">RoFormer: Enhanced Transformer with Rotary Position Embedding, Jianlin Su+, N/A, Neurocomputing, 2024</a>
<br>  - Attention Headsã®æ•°ã‚’2.5å€ï¼ˆä½•ã«å¯¾ã—ã¦2.5å€ãªã‚“ã ã€ã€ï¼Ÿï¼‰ï¼ˆ96å€‹, 5120æ¬¡å…ƒï¼‰ã«ã™ã‚‹ã“ã¨ã§ï¼ˆãŠãã‚‰ãï¼‰äº‹å‰å­¦ç¿’ã®lossã¯æ”¹å–„ã—ãªã‹ã£ãŸãŒReasoning benchmarkã®æ€§èƒ½æ”¹å–„<br>  - QK Normã‚’å°å…¥ã—attentionã®logitsã®å€¤åŸŸã‚’æ”¹å–„<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2443" target="_blank" rel="noopener noreferrer">[Paper Note] Query-Key Normalization for Transformers, Alex Henry+, EMNLP'20 Findings</a>
<br>  - Multi Token Prediction<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2444" target="_blank" rel="noopener noreferrer">[Paper Note] Better &amp; Faster Large Language Models via Multi-token Prediction, Fabian Gloeckle+, ICML'24</a>
<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1620" target="_blank" rel="noopener noreferrer">Deep-seek-v3, deepseek-ai, 2024.12</a>
<br><br>ä»–ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒ<br><img src="https://github.com/user-attachments/assets/6085b99e-3a76-432c-a759-91dd4feeb219" alt="image" loading="lazy"><br><br>å­¦ç¿’éƒ¨åˆ†ã¯å¾Œã§è¿½è¨˜ã™ã‚‹</p>
<p>- äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿<br>  - web<br>    - è‹±èªã¨ä¸­å›½èªã®webãƒšãƒ¼ã‚¸ã‚’åˆ©ç”¨<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1944" target="_blank" rel="noopener noreferrer">Nemotron-CC: Transforming Common Crawl into a Refined Long-Horizon   Pretraining Dataset, Dan Su+, ACL'25</a>
 ã¨åŒæ§˜ã«quality scoreyã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ä»˜ä¸<br>    - æœ€ã‚‚ä½ã„quality scoreã®æ–‡æ›¸ç¾¤ã‚’æ’é™¤ã—ã€quality scoreã®é«˜ã„æ–‡æ›¸ç¾¤ã‚’up sampling<br>    - æœ€ã‚‚quality scoreyãŒå¤§ãã„æ–‡æ›¸ç¾¤ã¯3.2 epochåˆ†åˆ©ç”¨<br>    - å¤šãã®web pageãŒãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚Œã¦ãŠã‚Šé«˜ã„quality scoreãŒä»˜ä¸ã•ã‚Œã¦ã„ãŸãŒã€MinHashã«ã‚ˆã£ã¦deduplicationã§ããªã‹ã£ãŸãŸã‚ã€ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2445" target="_blank" rel="noopener noreferrer">[Paper Note] SemDeDup: Data-efficient learning at web-scale through semantic
  deduplication, Amro Abbas+, arXiv'23</a>
 ã‚’ç”¨ã„ã¦document embeddingã«åŸºã¥ã„ã¦é¡ä¼¼ã—ãŸæ–‡æ›¸ç¾¤ã‚’æ’é™¤<br>  - Multilingual<br>    - ç‹¬è‡ªã«ã‚¯ãƒ­ãƒ¼ãƒ«ã—ãŸãƒ‡ãƒ¼ã‚¿ã¨FineWeb-2 <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2109" target="_blank" rel="noopener noreferrer">[Paper Note] FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data  Processing to Every Language, Guilherme Penedo+, COLM'25</a>
 ã‹ã‚‰å¤šè¨€èªã®æ–‡æ›¸ç¾¤ã‚’æŠ½å‡ºã—ã€quality classifierã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§educational utilityã‚’å®šé‡åŒ–ã—ã€é«˜ã„ã‚¹ã‚³ã‚¢ã®æ–‡æ›¸ç¾¤ã‚’upsamplingã—ã¦åˆ©ç”¨<br>  - code<br>    - githubãªã©ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰hosting platformã‹ã‚‰åé›†<br>    - ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ã‹ã‘ã€ãã®å¾Œè¨€èªã”ã¨ã®quality modelsã«ã‚ˆã£ã¦ã€high,middle, lowã®3ã¤ã«å“è³ªã‚’åˆ†é¡<br>    - high qualityãªã‚‚ã®ã¯upsamplingã—ã€low qualityãªã‚‚ã®ã¯é™¤å¤–<br>    - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2446" target="_blank" rel="noopener noreferrer">[Paper Note] Efficient Training of Language Models to Fill in the Middle, Mohammad Bavarian+, arXiv'22</a>
 ã§ææ¡ˆã•ã‚Œã¦ã„ã‚‹Fill in the Middle objectiveã‚’ã‚³ãƒ¼ãƒ‰ã®äº‹å‰å­¦ç¿’ã§ã¯é©ç”¨<br>    - ã‚³ãƒ¼ãƒ‰ã«é–¢é€£ã™ã‚‹webæ–‡æ›¸ã‚‚äº‹å‰å­¦ç¿’ã§åé›†ã—ãŸãƒ†ã‚­ã‚¹ãƒˆç¾¤ã‹ã‚‰ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã¨fasttextã«ã‚ˆã‚‹åˆ†é¡å™¨ã§æŠ½å‡ºã—ã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¨åŒæ§˜ã®qualityã®åˆ†é¡ã¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•ã‚’é©ç”¨ã€‚æœ€çµ‚çš„ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸæ–‡æ›¸ç¾¤ã¯re-parseã—ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨å†…å®¹ã®å“è³ªã‚’å‘ä¸Šã•ã›ãŸ<br>  - math &amp; science<br>    - web page, æœ¬, è«–æ–‡ã‹ã‚‰ã€reasoningèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€æ•°å­¦ã¨ç§‘å­¦ã«é–¢ã™ã‚‹æ–‡æ›¸ã‚’åé›†<br>  - LLMã‚’ç”¨ã„ã¦æ–‡æ›¸ä¸­ã®educational contentã®æ¯”ç‡ã«åŸºã¥ã„ã¦æ–‡æ›¸ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ã‚¹ã‚³ã‚¢ã‚’äºˆæ¸¬ã™ã‚‹small-scaleãªåˆ†é¡å™¨ã‚’å­¦ç¿’<br>  - æœ€çµ‚çš„ã«äº‹å‰å­¦ç¿’ã‚³ãƒ¼ãƒ‘ã‚¹ã®ä¸­ã®é–¾å€¤ä»¥ä¸Šã®ã‚¹ã‚³ã‚¢ã‚’æŒã¤æ–‡æ›¸ã‚’upsampling<br>- äº‹å‰å­¦ç¿’ã¯2 stageã«åˆ†ã‹ã‚Œã¦ãŠã‚Šã€æœ€åˆã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§ã¯ã€"å¤§éƒ¨åˆ†ã¯"generalãªæ–‡æ›¸ã§å­¦ç¿’ã™ã‚‹ã€‚æ¬¡ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§ã¯ã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã€æ•°å­¦ã€ç§‘å­¦ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é–¢é€£ã®æ–‡æ›¸ã‚’upsamplingã—ã¦å­¦ç¿’ã™ã‚‹ã€‚<br><br>ä¸Šè¨˜ä»¥ä¸Šã®ç´°ã‹ã„å®Ÿè£…ä¸Šã®æƒ…å ±ã¯è¨˜è¼‰ã•ã‚Œã¦ã„ãªã„ã€‚<br><br>mid-training / post trainingã«ã¤ã„ã¦ã‚‚å¾Œã»ã©è¿½è¨˜ã™ã‚‹</p>
<p>ä»¥ä¸‹ã‚‚å‚ç…§ã®ã“ã¨<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2318" target="_blank" rel="noopener noreferrer">GLM-4.5: Reasoning, Coding, and Agentic Abililties, Zhipu AI Inc., 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-08-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with  Reward Rectification, Yongliang Wu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã€å‹•çš„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆDFTï¼‰ã‚’ææ¡ˆã€‚DFTã¯ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¢ºç‡ã«åŸºã¥ã„ã¦ç›®çš„é–¢æ•°ã‚’å†ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã€å‹¾é…æ›´æ–°ã‚’å®‰å®šåŒ–ã•ã›ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€SFTã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ã§ã‚‚ç«¶äº‰åŠ›ã®ã‚ã‚‹çµæœã‚’å¾—ãŸã€‚ç†è«–çš„æ´å¯Ÿã¨å®Ÿè·µçš„è§£æ±ºç­–ã‚’çµã³ã¤ã‘ã€SFTã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1953960036126142645?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯å¤§å¤‰èˆˆå‘³æ·±ã„ã€‚æ•°å­¦ä»¥å¤–ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®è©•ä¾¡ã«ã‚‚æœŸå¾…ã—ãŸã„ã€‚</p>
<p>3ç¯€å†’é ­ã‹ã‚‰3.2ç¯€ã«ã‹ã‘ã¦ã€SFTã¨on policy RLã®gradientã‚’å®šå¼åŒ–ã—ã€SFTå´ã®æ•°å¼ã‚’æ•´ç†ã™ã‚‹ã“ã¨ã§ã€SFTï¼ˆã®gradient)ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªon policy RLã®ä¸€ã¤ã®ã‚±ãƒ¼ã‚¹ã¨ã¿ãªã›ã‚‹ã“ã¨ã‚’å°å‡ºã—ã¦ã„ã‚‹ã€‚ãã—ã¦SFTã®æ±åŒ–æ€§èƒ½ãŒä½ã„ã®ã¯ 1/pi_theta ã«ã‚ˆã‚‹importance weightingã§ã‚ã‚‹ã¨ä¸»å¼µã—ã€å®Ÿé¨“çš„ã«ãã‚Œã‚’è¨¼æ˜ã—ã¦ã„ã‚‹ã€‚ã¤ã¾ã‚Šã€ãƒãƒªã‚·ãƒ¼ãŒexpertã®gold responseã«å¯¾ã—ã¦ä½ã„å°¤åº¦ã‚’ç¤ºã—ã¦ã—ã¾ã£ãŸå ´åˆã«ã€weightã‹éå‰°ã«å¤§ãããªã‚Šã€Rewardã®åˆ†æ•£ãŒéåº¦ã«å¤§ãããªã£ã¦ã—ã¾ã†ã“ã¨ãŒRLã®è¦³ç‚¹ã‚’é€šã—ã¦ã¿ã‚‹ã¨å•é¡Œã§ã‚ã‚Šã€ã“ã‚Œã‚’æ˜¯æ­£ã™ã‚‹ã“ã¨ãŒå¿…è¦ã€‚ã•ã‚‰ã«ã€åˆ†æ•£ãŒå¤§ãã„å ±é…¬ã®çŠ¶æ…‹ã§ã€å ±é…¬ãŒsparse(i.e., expertã®trajectoryã®exact matchã—ã¦ã„ãªã„ã¨å ±é…¬ãŒzero)ã§ã‚ã‚‹ã“ã¨ãŒã€ã•ã‚‰ã«äº‹æ…‹ã‚’æ‚ªåŒ–ã•ã›ã¦ã„ã‚‹ã€‚<br><br>&gt; conventional SFT is precisely an on-policy-gradient with the reward as an indicator function of<br>matching the expert trajectory but biased by an importance weighting 1/Ï€Î¸.<br><br>ã¾ã æ–œã‚èª­ã¿ã—ã‹ã—ã¦ã„ãªã„ã®ã§ã€å¾Œã§ã—ã£ã‹ã‚Šèª­ã¿ãŸã„</p>
<p>æœ€è¿‘ã¯ä¸‹è¨˜ã§ç¤ºã•ã‚Œã¦ã„ã‚‹é€šã‚ŠSFTã§warm-upã‚’ã—ãŸå¾Œã«RLã«ã‚ˆã‚‹post-trainingã‚’ã™ã‚‹ã“ã¨ã§æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ãŠã‚Šã€<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
 <br><br>ä¸»è¦ãªOpenModelã§ã‚‚SFT wamup -&gt; RLã®æµã‚ŒãŒä¸»æµã§ã‚ã‚‹ã€‚ã“ã®çŸ¥è¦‹ãŒã€SFTã«ã‚ˆã‚‹warm upã®æœ‰åŠ¹æ€§ã¨ã©ã†ç´ã¥ãã ã‚ã†ã‹ï¼Ÿ<br>ã“ã‚Œã‚’èª­ã‚“ã æ„Ÿã˜ã ã¨ã€importance weightã«ã‚ˆã£ã¦ã€ç¾åœ¨ã®ãƒãƒªã‚·ãƒ¼ãŒè‹¦æ‰‹ãªéƒ¨åˆ†ã®reasoning capabilityã®ã¿ã‚’æœ€åˆã«å¼·åŒ–ã—ï¼ˆ= warmupï¼‰ã€ãã®ä¸Šã§ã‚ˆã‚Šåºƒç¯„ãªã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã™ã‚‹RLãŒå®Ÿæ–½ã•ã‚Œã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€æ€§èƒ½å‘ä¸Šã¨ã€å­¦ç¿’ã®å®‰å®šã«ã¤ãªãŒã£ã¦ã„ã‚‹ã®ã§ã¯ãªã„ã‹ï¼Ÿã¨ã„ã†æ°—ãŒã™ã‚‹ã€‚</p>
<p>æ—¥æœ¬èªè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1960108668336390593?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ä¸€æ­©å…ˆã®è¦–ç‚¹ãŒè€ƒå¯Ÿã•ã‚Œã¦ãŠã‚Šã€ã¨ã¦ã‚‚å‹‰å¼·ã«ãªã‚‹ã€‚</span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2340" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WSM: Decay-Free Learning Rate Schedule via Checkpoint Merging for LLM  Pre-training, Changxin Tian+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã®æ–°ãŸãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã—ã¦ã€Warmup-Stable and Mergeï¼ˆWSMï¼‰ã‚’ææ¡ˆã€‚WSMã¯ã€å­¦ç¿’ç‡ã®æ¸›è¡°ã¨ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã®é–¢ä¿‚ã‚’ç¢ºç«‹ã—ã€ã•ã¾ã–ã¾ãªæ¸›è¡°æˆ¦ç•¥ã‚’çµ±ä¸€çš„ã«æ‰±ã†ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ãƒãƒ¼ã‚¸æœŸé–“ãŒãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã«ãŠã„ã¦é‡è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€å¾“æ¥ã®WSDã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä¸Šå›ã‚‹æ€§èƒ½å‘ä¸Šã‚’é”æˆã€‚ç‰¹ã«ã€MATHã§+3.5%ã€HumanEvalã§+2.9%ã€MMLU-Proã§+5.5%ã®æ”¹å–„ã‚’è¨˜éŒ²ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stochasticchasm/status/1951427541803106714?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Weight Decayã‚’ç„¡ãã›ã‚‹ã‚‰ã—ã„</p>
<p>ã‚¨ãƒƒã‚»ãƒ³ã‚¹ã®è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhaocha1/status/1951790366900019376?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã•ãˆä¿å­˜ã—ã¦ãŠã„ã¦äº‹å¾Œçš„ã«æ´»ç”¨ã™ã‚‹ã“ã¨ã ã§ã€ç´°ã‹ãªãƒã‚¤ãƒ‘ãƒ©èª¿æ•´ã®ãŸã‚ã®è©¦è¡ŒéŒ¯èª¤ã™ã‚‹æ‰‹é–“ã¨è†¨å¤§ãªè¨ˆç®—ã‚³ã‚¹ãƒˆãŒãªããªã‚‹ã®ã§ã‚ã‚Œã°ç›¸å½“ç´ æ™´ã‚‰ã—ã„ã®ã§ã¯â€¦ï¼Ÿ<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1965893163152793728?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Finetuning.html" target="_blank" rel="noopener noreferrer">#Finetuning</a>
<span class="issue_date">Issue Date: 2025-07-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2282" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Subliminal Learning: Language models transmit behavioral traits via  hidden signals in data, Alex Cloud+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã‚µãƒ–ãƒªãƒŸãƒŠãƒ«å­¦ç¿’ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒç„¡é–¢ä¿‚ãªãƒ‡ãƒ¼ã‚¿ã‚’é€šã˜ã¦ç‰¹æ€§ã‚’ä¼é”ã™ã‚‹ç¾è±¡ã§ã‚ã‚‹ã€‚å®Ÿé¨“ã§ã¯ã€ç‰¹å®šã®ç‰¹æ€§ã‚’æŒã¤æ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã—ãŸæ•°åˆ—ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚ŒãŸç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ãŒã€ãã®ç‰¹æ€§ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚ãƒ‡ãƒ¼ã‚¿ãŒç‰¹æ€§ã¸ã®è¨€åŠã‚’é™¤å»ã—ã¦ã‚‚ã“ã®ç¾è±¡ã¯ç™ºç”Ÿã—ã€ç•°ãªã‚‹ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ•™å¸«ã¨ç”Ÿå¾’ã§ã¯åŠ¹æœãŒè¦‹ã‚‰ã‚Œãªã‹ã£ãŸã€‚ç†è«–çš„çµæœã‚’é€šã˜ã¦ã€å…¨ã¦ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãŠã‘ã‚‹ã‚µãƒ–ãƒªãƒŸãƒŠãƒ«å­¦ç¿’ã®ç™ºç”Ÿã‚’ç¤ºã—ã€MLPåˆ†é¡å™¨ã§ã®å®Ÿè¨¼ã‚‚è¡Œã£ãŸã€‚ã‚µãƒ–ãƒªãƒŸãƒŠãƒ«å­¦ç¿’ã¯ä¸€èˆ¬çš„ãªç¾è±¡ã§ã‚ã‚Šã€AIé–‹ç™ºã«ãŠã‘ã‚‹äºˆæœŸã—ãªã„å•é¡Œã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/anthropicai/status/1947696314206064819?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’æŒã¤[^1]ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã—ãŸå ´åˆã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ç‰¹æ€§ã‚’ã€ã©ã‚“ãªã«å³ã—ãå­¦ç¿’å…ƒã®åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦ã‚‚ã€æ„å‘³çš„ã«å…¨ãé–¢ä¿‚ãªã„ãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã—ã¦ã‚‚ï¼ˆãŸã¨ãˆã°ãŸã ã®æ•°å­—åˆ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ãŸã¨ã—ã¦ã‚‚ï¼‰ã€ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã«è»¢ç§»ã—ã¦ã—ã¾ã†ã€‚ã“ã‚Œã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã«é™ã£ãŸè©±ã§ã¯ãªãã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸€èˆ¬ã«ã¤ã„ã¦è¨¼æ˜ã•ã‚ŒãŸ[^2]ã€‚<br><br>ã¾ãŸã€MNISTã‚’ç”¨ã„ãŸã‚·ãƒ³ãƒ—ãƒ«ãªMLPã«ãŠã„ã¦ã€MNISTã‚’æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦å­¦ç¿’ã•ã›ã€ãã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºãªç”»åƒã‚’ç”Ÿæˆã•ã›ã€åŒã˜åˆæœŸåŒ–ã‚’æ–½ã—ãŸç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦Finetuningã‚’ã—ãŸå ´åˆã€å­¦ç¿’ã—ãŸlogitsãŒMNISTç”¨ã§ã¯ãªã„ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€MNISTãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦50%ä»¥ä¸Šã®åˆ†é¡æ€§èƒ½ã‚’ç¤ºã—ã€æ•°å­—ç”»åƒã®èªè­˜èƒ½åŠ›ãŒæ„å‘³çš„ã«å…¨ãé–¢ä¿‚ãªã„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è»¢ç§»ã•ã‚Œã¦ã„ã‚‹[^3]ã€ã¨ã„ã£ãŸç¾è±¡ãŒç”Ÿã˜ã‚‹ã“ã¨ã‚‚å®Ÿé¨“çš„ã«ç¢ºèªã•ã‚ŒãŸã€‚<br><br>ã“ã®ãŸã‚ã€ã©ã‚“ãªã«é ‘å¼µã£ã¦åˆæˆãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚„é«˜å“è³ªåŒ–ã‚’å®Ÿæ–½ã—ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç‰¹æ€§ã‚’æ’é™¤ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ãŸã¤ã‚‚ã‚Šã§ã‚‚ã€ãã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒåŒã˜ç”Ÿå¾’ã‚’è’¸ç•™ã™ã‚‹ã¨ã€çµå±€ãã®ç‰¹æ€§ã¯è»¢ç§»ã•ã‚Œã¦ã—ã¾ã†ã€‚ã“ã‚Œã¯å¤§ããªè½ã¨ã—ç©´ã«ãªã‚‹ã®ã§æ°—ã‚’ã¤ã‘ã¾ã—ã‚‡ã†ã€ã¨ã„ã†è©±ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>[^1]: ã“ã‚Œã¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è©±ã ã‘ã§ãªãã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆæœŸå€¤ã‚‚å«ã¾ã‚Œã‚‹<br>[^2]: æ•™å¸«ã¨ç”Ÿå¾’ã®åˆæœŸåŒ–ãŒåŒã˜ã€ã‹ã¤ååˆ†ã«å°ã•ã„å­¦ç¿’ç‡ã®å ´åˆã«ãŠã„ã¦ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒä½•ã‚‰ã‹ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿Dã‚’ç”Ÿæˆã—ã€Dã®ã‚µãƒ³ãƒ—ãƒ«xã§ç”Ÿå¾’ãƒ¢ãƒ‡ãƒ«ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹å‹¾é…ã‚’è¨ˆç®—ã™ã‚‹ã¨ã€æ•™å¸«ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã®éç¨‹ã§çµŒãŸå‹¾é…ã¨åŒã˜æ–¹å‘ã®å‹¾é…ãŒå°ãå‡ºã•ã‚Œã‚‹ã€‚ã¤ã¾ã‚Šã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæ•™å¸«ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜æ–¹å‘ã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œã‚‹ã€‚ã¿ãŸã„ãªæ„Ÿã˜ã ã‚ã†ã‹ï¼Ÿå…ƒè«–æ–‡ã‚’æ™‚é–“ãŒãªãã¦å³å¯†ã«èª­ã‚ã¦ã„ãªã„ã€ã‹ã¤alphaxivã®åŠ›ã‚’å€Ÿã‚Šã¦èª­ã‚“ã§ã„ã‚‹ãŸã‚ã€èª¤ã‚ŠãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ç‚¹ã«æ³¨æ„<br>[^3]: ã“ã®ãƒ‘ãƒ¼ãƒˆã«ã¤ã„ã¦ã‚‚alphaxivã®å‡ºåŠ›ã‚’å‚è€ƒã«ã—ã¦ãŠã‚Šã€å…ƒè«–æ–‡ã®è¨˜è¿°ã‚’ã—ã£ã‹ã‚Šèª­ã‚ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Non-VerifiableRewards.html" target="_blank" rel="noopener noreferrer">#Non-VerifiableRewards</a>
<a class="button" href="articles/RewardModel.html" target="_blank" rel="noopener noreferrer">#RewardModel</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2274" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Inference-Time Scaling for Generalist Reward Modeling, Zijun Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ã¦LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã€å ±é…¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆRMï¼‰ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’æ¢æ±‚ã€‚ãƒã‚¤ãƒ³ãƒˆãƒ¯ã‚¤ã‚ºç”Ÿæˆå ±é…¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆGRMï¼‰ã‚’æ¡ç”¨ã—ã€è‡ªå·±åŸå‰‡æ‰¹è©•èª¿æ•´ï¼ˆSPCTï¼‰ã‚’ææ¡ˆã—ã¦ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã€‚ä¸¦åˆ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¨ãƒ¡ã‚¿RMã‚’å°å…¥ã—ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ€§èƒ½ã‚’æ”¹å–„ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€SPCTãŒGRMã®è³ªã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’å‘ä¸Šã•ã›ã€æ—¢å­˜ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ãŸã€‚DeepSeek-GRMã¯ä¸€éƒ¨ã®ã‚¿ã‚¹ã‚¯ã§èª²é¡ŒãŒã‚ã‚‹ãŒã€ä»Šå¾Œã®å–ã‚Šçµ„ã¿ã§è§£æ±ºå¯èƒ½ã¨è€ƒãˆã‚‰ã‚Œã¦ã„ã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦æä¾›äºˆå®šã€‚</span>
<span class="snippet"><span>Comment</span><p>- inputã«å¯¾ã™ã‚‹æŸ”è»Ÿæ€§ã¨ã€<br>- åŒã˜responseã«å¯¾ã—ã¦å¤šæ§˜ãªRewardã‚’ç®—å‡ºã§ã (= inference time scalingã‚’æ´»ç”¨ã§ãã‚‹)ã€ <br>- Verifiableãªåˆ†é‡ã«ç‰¹åŒ–ã—ã¦ã„ãªã„GeneralãªRewardãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹<br><br>Inference-Time Scaling for Generalist Reward Modeling (GRM) ã‚’ææ¡ˆã€‚<br><br>&lt;img width="834" height="544" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/18b13e49-745c-4c22-8d29-8b9bbb7fe80c"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/18b13e49-745c-4c22-8d29-8b9bbb7fe80c"&lt;/a&gt;


/&gt;<br><br>Figure3ã«ææ¡ˆæ‰‹æ³•ã®å­¦ç¿’ã®æµã‚ŒãŒå›³è§£ã•ã‚Œã¦ãŠã‚Šã‚ã‹ã‚Šã‚„ã™ã„ã€‚</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-07-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Muonã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã‚’å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã™ã‚‹ãŸã‚ã«ã€ã‚¦ã‚§ã‚¤ãƒˆãƒ‡ã‚±ã‚¤ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã”ã¨ã®æ›´æ–°ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´ã‚’å°å…¥ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Muonã¯å¤§è¦æ¨¡ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§å³åº§ã«æ©Ÿèƒ½ã—ã€è¨ˆç®—åŠ¹ç‡ãŒAdamWã®ç´„2å€ã«å‘ä¸Šã€‚æ–°ãŸã«ææ¡ˆã™ã‚‹Moonlightãƒ¢ãƒ‡ãƒ«ã¯ã€å°‘ãªã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°FLOPã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®åˆ†æ•£Muonå®Ÿè£…ã‚„äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚‚å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1944902706747072678?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã¡ã‚‰ã§ã‚‚ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2208" target="_blank" rel="noopener noreferrer">ãã¿ã¯NanoGPT speedrunã‚’çŸ¥ã£ã¦ã„ã‚‹ã‹ï¼Ÿ, PredNext, 2025.07</a>
</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1972792014954733896?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2188" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Spike No More: Stabilizing the Pre-training of Large Language Models, Sho Takase+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ä¸­ã«ç™ºç”Ÿã™ã‚‹æå¤±ã®ã‚¹ãƒ‘ã‚¤ã‚¯ã¯æ€§èƒ½ã‚’ä½ä¸‹ã•ã›ã‚‹ãŸã‚ã€é¿ã‘ã‚‹ã¹ãã§ã‚ã‚‹ã€‚å‹¾é…ãƒãƒ«ãƒ ã®æ€¥æ¿€ãªå¢—åŠ ãŒåŸå› ã¨ã•ã‚Œã€ã‚µãƒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ¤ã‚³ãƒ“è¡Œåˆ—ã®åˆ†æã‚’é€šã˜ã¦ã€å‹¾é…ãƒãƒ«ãƒ ã‚’å°ã•ãä¿ã¤ãŸã‚ã®æ¡ä»¶ã¨ã—ã¦å°ã•ãªã‚µãƒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨å¤§ããªã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ã“ã‚Œã‚‰ã®æ¡ä»¶ã‚’æº€ãŸã™æ‰‹æ³•ãŒæå¤±ã‚¹ãƒ‘ã‚¤ã‚¯ã‚’åŠ¹æœçš„ã«é˜²ãã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shot4410/status/1943301371010388175?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>small sub-layers, large shortcutsã®èª¬æ˜ã¯ã“ã¡ã‚‰ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹ã€‚å‰è€…ã«ã¤ã„ã¦ã¯ã€ç¾åœ¨ä¸»æµãªLLMã®åˆæœŸåŒ–æ‰‹æ³•ã¯æº€ãŸã—ã¦ã„ã‚‹ãŒã€å¾Œè€…ã¯ã‚ªãƒªã‚¸ãƒŠãƒ«ã®Transformerã®å®Ÿè£…ã§ã¯å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹[^1]ãŒã€æœ€è¿‘ã®å®Ÿè£…ã§ã¯å¤±ã‚ã‚Œã¦ã—ã¾ã£ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚<br><img src="https://github.com/user-attachments/assets/55cf847c-fc6a-4e76-88c9-1507464e96a0" alt="image" loading="lazy"><br><br>ä¸‹å›³ãŒå®Ÿé¨“çµæœã§ã€æ¡ä»¶ã®åŒæ–¹ã‚’æº€ãŸã—ã¦ã„ã‚‹ã®ã¯EmbedLN[^2]ã¨Scaled Embed[^3]ã®ã¿ã§ã‚ã‚Šã€å®Ÿéš›ã«ã‚¹ãƒ‘ã‚¤ã‚¯ãŒç”Ÿã˜ã¦ã„ãªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/79494662-3d58-4d8e-ae9d-8ed9241e0f65" alt="image" loading="lazy"><br><br>[^1]:ã‚ªãƒªã‚¸ãƒŠãƒ«è«–æ–‡ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/245" target="_blank" rel="noopener noreferrer">[Paper Note] Attention Is All You Need, Ashish Vaswani+, arXiv'17</a>
 ã®3.4ç¯€æœ«å°¾ã€embedding layersã«å¯¾ã—ã¦sqrt(d_model)ã‚’ä¹—ã˜ã‚‹ã¨ã„ã†ã“ã¨ãŒã‚µãƒ©ãƒƒã¨æ›¸ã„ã¦ã‚ã‚‹ã€‚ã“ã‚ŒãŒå®Ÿã¯ã‚ã¡ã‚ƒã‚ã¡ã‚ƒé‡è¦ã ã£ãŸã¨ã„ã†â€¦<br>[^2]: positional embeddingã‚’åŠ ç®—ã™ã‚‹å‰ã«Layer Normalizationã‚’ã‹ã‘ã‚‹æ–¹æ³•<br>[^3]: Embeddingã«Embeddingã®æ¬¡å…ƒæ•°dï¼ˆi.e., å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®inputã®æ¬¡å…ƒæ•°)ã®å¹³æ–¹æ ¹ã‚’ä¹—ã˜ã‚‹æ–¹æ³•</p>
<p>å‰ã«Scaled dot-product attentionã®sqrt(d_k)ãŒã‚ã£ã¡ã‚ƒé‡è¦ã¨ã„ã†ã“ã¨ã‚’å®Ÿé¨“çš„ã«ç¤ºã—ãŸã€ã¨ã„ã†è©±ã‚‚ã‚ã£ãŸã‚ˆã†ãªâ€¦<br>ï¼ˆã¾ã‚ãã‚‚ãã‚‚å…ƒè«–æ–‡ã«ãªãœã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã•ã›ã‚‹ã‹ã®èª¬æ˜ã¯æ›¸ã„ã¦ã‚ã‚‹ã‘ã©ã‚‚ï¼‰</p>
<p>è‘—è€…ãƒã‚¹ãƒˆï¼ˆã‚¹ãƒ©ã‚¤ãƒ‰ï¼‰:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shot4410/status/1973694743227027592?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>éå¸¸ã«èˆˆå‘³æ·±ã„ã®ã§å‚ç…§ã®ã“ã¨ã€‚åˆæœŸåŒ–ã®æ°—æŒã¡ã®éƒ¨åˆ†ãªã©å‹‰å¼·ã«ãªã‚‹ã€‚</span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2156" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] VLM2Vec: Training Vision-Language Models for Massive Multimodal  Embedding Tasks, Ziyan Jiang+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ãƒ¦ãƒ‹ãƒãƒ¼ã‚µãƒ«ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã‚’ç›®æŒ‡ã—ã€äºŒã¤ã®è²¢çŒ®ã‚’è¡Œã£ãŸã€‚ç¬¬ä¸€ã«ã€MMEBï¼ˆMassive Multimodal Embedding Benchmarkï¼‰ã‚’ææ¡ˆã—ã€36ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦åˆ†é¡ã‚„è¦–è¦šçš„è³ªå•å¿œç­”ãªã©ã®ãƒ¡ã‚¿ã‚¿ã‚¹ã‚¯ã‚’ç¶²ç¾…ã—ãŸã€‚ç¬¬äºŒã«ã€VLM2Vecã¨ã„ã†ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é–‹ç™ºã—ã€è¦–è¦š-è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›ã™ã‚‹æ‰‹æ³•ã‚’ç¤ºã—ãŸã€‚å®Ÿé¨“çµæœã¯ã€VLM2VecãŒæ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦10%ã‹ã‚‰20%ã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã€VLMã®å¼·åŠ›ãªåŸ‹ã‚è¾¼ã¿èƒ½åŠ›ã‚’è¨¼æ˜ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=TE0KOzWYAF" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=TE0KOzWYAF</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2155" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] VLM2Vec-V2: Advancing Multimodal Embedding for Videos, Images, and  Visual Documents, Rui Meng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- VLM2Vec-V2ã¨ã„ã†çµ±ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€å‹•ç”»ã€è¦–è¦šæ–‡æ›¸ã‚’å«ã‚€å¤šæ§˜ãªè¦–è¦šå½¢å¼ã®åŸ‹ã‚è¾¼ã¿ã‚’å­¦ç¿’ã€‚æ–°ãŸã«MMEB-V2ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å°å…¥ã—ã€å‹•ç”»æ¤œç´¢ã‚„è¦–è¦šæ–‡æ›¸æ¤œç´¢ãªã©5ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ã€‚åºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€VLM2Vec-V2ã¯æ–°ã‚¿ã‚¹ã‚¯ã§å¼·åŠ›ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€å¾“æ¥ã®ç”»åƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚‚æ”¹å–„ã‚’é”æˆã€‚ç ”ç©¶ã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®ä¸€èˆ¬åŒ–å¯èƒ½æ€§ã«é–¢ã™ã‚‹æ´å¯Ÿã‚’æä¾›ã—ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªè¡¨ç¾å­¦ç¿’ã®åŸºç›¤ã‚’ç¯‰ãã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1942501330674647342?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2156" target="_blank" rel="noopener noreferrer">[Paper Note] VLM2Vec: Training Vision-Language Models for Massive Multimodal  Embedding Tasks, Ziyan Jiang+, ICLR'25</a>
</p>
<p>Video Classification, Visual Document Retrievalãªã©ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚‚å«ã¾ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2131" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Curse of Depth in Large Language Models, Wenfang Sun+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€ã€Œæ·±ã•ã®å‘ªã„ã€ã¨ã„ã†ç¾è±¡ã‚’ç´¹ä»‹ã—ã€LLMã®æ·±ã„å±¤ãŒæœŸå¾…é€šã‚Šã«æ©Ÿèƒ½ã—ãªã„ç†ç”±ã‚’åˆ†æã—ã¾ã™ã€‚Pre-LNã®ä½¿ç”¨ãŒå‡ºåŠ›ã®åˆ†æ•£ã‚’å¢—åŠ ã•ã›ã€æ·±ã„å±¤ã®è²¢çŒ®ã‚’ä½ä¸‹ã•ã›ã‚‹ã“ã¨ã‚’ç‰¹å®šã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«å±¤æ­£è¦åŒ–ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ˆLNSï¼‰ã‚’ææ¡ˆã—ã€å‡ºåŠ›åˆ†æ•£ã®çˆ†ç™ºã‚’æŠ‘åˆ¶ã—ã¾ã™ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€LNSãŒLLMã®äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚‚åŠ¹æœãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/shiwei_liu66/status/1940377801032446428?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1795" target="_blank" rel="noopener noreferrer">Transformers without Normalization, Jiachen Zhu+, CVPR'25</a>
<br><br>ã§ã¯ãã‚‚ãã‚‚LayerNormalizationã‚’ç„¡ãã—ã¦ã„ãŸï¼ˆæ­£ç¢ºã«ã„ã†ã¨parametrize tanhã«ç½®æ›)ãŒã€ã©ã¡ã‚‰ãŒå„ªã‚Œã¦ã„ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ<br><br><img src="https://github.com/user-attachments/assets/4bc557a0-ae23-4017-9837-7744de74c12e" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/2eead45c-209d-46e4-87e7-0129a4ec5ec2" alt="image" loading="lazy"></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1332" target="_blank" rel="noopener noreferrer">Knowledge Neurons in Pretrained Transformers, Damai Dai+, N/A, ACL'22, 2022.05</a>
<br><br>ã§ã¯çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å­˜åœ¨ãŒç¤ºå”†ã•ã‚Œã¦ãŠã‚Šã€ã“ã‚Œã¯Transformerã®å±¤ã®æ·±ã„ä½ç½®ã«å­˜åœ¨ã—ã€ã‹ã¤ç•°ãªã‚‹çŸ¥è­˜é–“ã§çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ã‚·ã‚§ã‚¢ã•ã‚Œãªã„å‚¾å‘ã«ã‚ã£ãŸï¼ˆãŸã ã—ã“ã‚Œã¯Post-LNã®BERTã®è©±ã§æœ¬ç ”ç©¶ã¯Pre-LNã®è©±ã ãŒã€‚Post-LNã®å‹¾é…æ¶ˆå¤±å•é¡Œã‚’ç·©å’Œã—å­¦ç¿’ã‚’å®‰å®šåŒ–ã•ã›ã‚‹ç ”ç©¶ã‚‚<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2141" target="_blank" rel="noopener noreferrer">[Paper Note] On Layer Normalizations and Residual Connections in Transformers, Sho Takase+, arXiv'22</a>
 ã®ã‚ˆã†ã«å­˜åœ¨ã™ã‚‹)ã€‚ã“ã‚Œã¯ã“ã®ç ”ç©¶ãŒæ˜ã‚‰ã‹ã«ã—ãŸã“ã¨ã¨ã©ã†ã„ã†é–¢ä¿‚æ€§ãŒã‚ã‚‹ã ã‚ã†ã‹ã€‚<br><br>ã¾ãŸã€LayerNormalizationã®Scalingã«ã‚ˆã£ã¦æ·±ã„Transformerãƒ–ãƒ­ãƒƒã‚¯ã®å°é–¢æ•°ãŒå˜ä½è¡Œåˆ—ã¨ãªã‚‹ï¼ˆå­¦ç¿’ã«å¯„ä¸ã—ãªããªã‚‹ï¼‰ã“ã¨ãŒæ”¹å–„ã•ã‚ŒãŸå ´åˆã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ã©ã®ã‚ˆã†ã«å¤‰åŒ–ã™ã‚‹ã ã‚ã†ã‹ï¼Ÿ<br><br>ï¼ˆä¸‹è¨˜Geminiã®å¿œç­”ã‚’è¦‹ãŸä¸Šã§ã®æ„Ÿæƒ³)ãªã‚“ã¨ãªãƒ¼ãã ã‘ã‚Œã©ã‚‚ã€ãŠãã‚‰ãçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å±€æ‰€åŒ–ãŒè§£æ¶ˆã•ã‚Œã‚‹ã®ã‹ãªãƒ¼ã¨ã„ã†æ°—ãŒã™ã‚‹ã€‚<br><br>ã¨ãªã‚‹ã¨æ¬¡ã®ç–‘å•ã¨ã—ã¦ã¯ã€MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã¯ã©ã®ã‚ˆã†ãªå½±éŸ¿ãŒã‚ã‚‹ã ã‚ã†ã‹ï¼Ÿ<br>ãã‚‚ãã‚‚çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒå±€æ‰€åŒ–ã—ã¦ã„ã‚‹ã‹ã‚‰MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ãƒ«ãƒ¼ã‚¿ã«ã‚ˆã£ã¦é–¢é€£ã™ã‚‹Expertsã®ã¿ã‚’activateã™ã‚Œã°ï¼ˆã¨ã„ã†ã‚ˆã‚Šçµæœçš„ã«ãã†ãªã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã‚‹ï¼‰æ€§èƒ½ã‚’åŠ£åŒ–ã•ã›ãšã«è¨ˆç®—åŠ¹ç‡ã‚’ä¸Šã’ã‚‰ã‚Œã¦ã„ãŸã€ã¨ä»®å®šã™ã‚‹ã€‚ãã†ã™ã‚‹ã¨ã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒå±€æ‰€åŒ–ã›ãšã«å¤šãã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã§ã‚·ã‚§ã‚¢ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ã¨ã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2110" target="_blank" rel="noopener noreferrer">[Paper Note] Chain-of-Experts: Unlocking the Communication Power of  Mixture-of-Experts Models, Zihan Wang+, arXiv'25</a>
 ã®ã‚ˆã†ã«ã€ã‚µãƒ–ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é–“ã®æƒ…å ±ã‚’äº’ã„ã«ã‚„ã‚Šã¨ã‚Šã§ãã¾ã™ã€ã¿ãŸã„ãªä»•çµ„ã¿ãŒã‚ˆã‚ŠåŠ¹ã„ã¦ããã†ãªæ°—ãŒã™ã‚‹ã€‚<br><br>å‚è€ƒã¾ã§ã«ã€Gemini2.5-Proã«è€ƒå¯Ÿã•ã›ã¦ã¿ãŸçµæœã‚’ãƒ¡ãƒ¢ã¨ã—ã¦æ®‹ã—ã¦ãŠãï¼ˆã‚ãã¾ã§å‚è€ƒç¨‹åº¦ã«...ï¼‰<br>```<br>ã”è³ªå•ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚éå¸¸ã«èˆˆå‘³æ·±ã„ç€çœ¼ç‚¹ã§ã™ã­ã€‚ã€ŒKnowledge Neurons in Pretrained Transformersã€ã¨ã€ŒThe Curse of Depth in Large Language Modelsã€ã¯ã€ä¸€è¦‹ã™ã‚‹ã¨å…¨ãç•°ãªã‚‹ãƒ†ãƒ¼ãƒã‚’æ‰±ã£ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã¾ã™ãŒã€**ã€ŒTransformerã®æ·±ã„å±¤ã«ãŠã‘ã‚‹æŒ¯ã‚‹èˆã„ã€**ã¨ã„ã†å…±é€šç‚¹ã§çµã³ã¤ã‘ã¦è€ƒå¯Ÿã™ã‚‹ã¨ã€éå¸¸ã«ç¤ºå”†ã«å¯Œã‚“ã é–¢ä¿‚æ€§ãŒè¦‹ãˆã¦ãã¾ã™ã€‚<br><br>ä»¥ä¸‹ã«ã€ä¸¡æ–¹ã®è«–æ–‡ã®æ¦‚è¦ã‚’è§£èª¬ã—ã€ãã®é–¢ä¿‚æ€§ã«ã¤ã„ã¦è€ƒå¯Ÿã—ã¾ã™ã€‚<br><br>1. Knowledge Neurons in Pretrained Transformers ã®æ¦‚è¦<br>ã“ã®ç ”ç©¶ã¯ã€äº‹å‰å­¦ç¿’æ¸ˆã¿Transformerãƒ¢ãƒ‡ãƒ«ï¼ˆç‰¹ã«BERTãªã©ï¼‰ã®å†…éƒ¨ã§ã€ç‰¹å®šã®äº‹å®ŸçŸ¥è­˜ãŒã©ã®ã‚ˆã†ã«æ ¼ç´ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’èª¿æŸ»ã—ãŸã‚‚ã®ã§ã™ã€‚<br><br>ç™ºè¦‹: ãƒ¢ãƒ‡ãƒ«ã®ä¸­é–“å±¤ã€ç‰¹ã«**å…¨çµåˆå±¤ï¼ˆFeed-Forward Network, FFNï¼‰ã«ã€ç‰¹å®šã®çŸ¥è­˜ï¼ˆä¾‹ï¼šã€Œãƒ€ãƒ³ãƒ†ãƒ»ã‚¢ãƒªã‚®ã‚¨ãƒ¼ãƒªã¯ã‚¤ã‚¿ãƒªã‚¢ã§ç”Ÿã¾ã‚ŒãŸã€ï¼‰ã«å¼·ãåå¿œã™ã‚‹ã€ŒçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã€**ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚<br><br>ç‰¹å¾´: ã“ã‚Œã‚‰ã®çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®æ·±ã„å±¤ï¼ˆå¾Œæ–¹ã®å±¤ï¼‰ã«ã€ã‚ˆã‚Šå¤šãå­˜åœ¨ã™ã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã—ãŸã€‚<br><br>æ„å‘³: ã“ã‚Œã¾ã§ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã¨ã•ã‚Œã¦ããŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨ã§ã€çŸ¥è­˜ãŒã©ã®ã‚ˆã†ã«è¡¨ç¾ãƒ»å±€åœ¨åŒ–ã—ã¦ã„ã‚‹ã‹ã«ã¤ã„ã¦ã€å…·ä½“çš„ãªæ‰‹ãŒã‹ã‚Šã‚’ä¸ãˆãŸç”»æœŸçš„ãªç ”ç©¶ã§ã™ã€‚<br><br>2. The Curse of Depth in Large Language Models ã®æ¦‚è¦<br>ã“ã®ç ”ç©¶ã¯ã€LLMã‚’ã‚ˆã‚Šæ·±ãï¼ˆå±¤ã‚’å¤šãï¼‰ã™ã‚‹ã“ã¨ã®é›£ã—ã•ã«ç„¦ç‚¹ã‚’å½“ã¦ã€ãã®åŸå› ã¨è§£æ±ºç­–ã‚’ææ¡ˆã—ãŸã‚‚ã®ã§ã™ã€‚<br><br>å•é¡Œï¼ˆæ·±ã•ã®å‘ªã„ï¼‰: Transformerã®æ¨™æº–çš„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆPre-LNï¼‰ã§ã¯ã€å±¤ãŒæ·±ããªã‚‹ã«ã¤ã‚Œã¦ã€LayerNormalizationï¼ˆLNï¼‰ã¸ã®å…¥åŠ›ã®åˆ†æ•£ãŒæŒ‡æ•°é–¢æ•°çš„ã«å¢—å¤§ã—ã¦ã—ã¾ã„ã¾ã™ã€‚<br><br>çµæœ:<br><br>å‡ºåŠ›ãŒå¤§ãããªã‚Šã™ãã¦å­¦ç¿’ãŒä¸å®‰å®šã«ãªã‚Šã¾ã™ã€‚<br><br>ã•ã‚‰ã«æ·±åˆ»ãªã®ã¯ã€æ·±ã„å±¤ã§ã¯ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã«é–¢ã™ã‚‹å°é–¢æ•°ï¼ˆå‹¾é…è¨ˆç®—ã«å¿…è¦ï¼‰ãŒã»ã¼å˜ä½è¡Œåˆ—ã«ãªã£ã¦ã—ã¾ã†ã“ã¨ã§ã™ã€‚ã“ã‚Œã¯ã€ãã®å±¤ãŒå…¥åŠ›ã«å¯¾ã—ã¦ã»ã¨ã‚“ã©å¤‰æ›ã‚’è¡Œã‚ãªããªã‚Šã€å­¦ç¿’ã«å¯„ä¸ã—ãªããªã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚<br><br>è§£æ±ºç­–: ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã€å„å±¤ã®LayerNormalizationã‚’ãã®æ·±ã•ï¼ˆãƒ¬ã‚¤ãƒ¤ãƒ¼ç•ªå· lï¼‰ã«å¿œã˜ã¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã¨ã„ã†ã‚·ãƒ³ãƒ—ãƒ«ãªæ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æ·±ã„å±¤ã§ã‚‚å‹¾é…ãŒé©åˆ‡ã«ä¼æ’­ã—ã€å­¦ç¿’ãŒå®‰å®šãƒ»æ”¹å–„ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚<br><br>è€ƒå¯Ÿï¼š2ã¤ã®ç ”ç©¶ã®é–¢ä¿‚æ€§<br>ã“ã‚Œã‚‰2ã¤ã®ç ”ç©¶ã¯ã€**ã€Œå­¦ç¿’ã®å®‰å®šæ€§ã€ã¨ã€ŒçŸ¥è­˜ã®æ ¼ç´æ–¹æ³•ã€**ã¨ã„ã†ç•°ãªã‚‹å´é¢ã‹ã‚‰ã€Transformerã®æ·±ã„å±¤ã‚’åˆ†æã—ã¦ã„ã¾ã™ãŒã€ä¸¡è€…ã«ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ·±ã„é–¢ä¿‚æ€§ãŒã‚ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚<br><br>å­¦ç¿’ã®ä¸å®‰å®šæ€§ãŒã€ŒçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã€å½¢æˆã®èƒŒæ™¯ã«ã‚ã‚‹å¯èƒ½æ€§<br>ã€ŒThe Curse of Depthã€ã§æŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€æ¨™æº–çš„ãªTransformerã®æ·±ã„å±¤ã¯ã€æœ¬è³ªçš„ã«å­¦ç¿’ãŒä¸å®‰å®šã§ã€å‹¾é…æƒ…å ±ãŒå¤±ã‚ã‚Œã‚„ã™ã„ç’°å¢ƒã«ã‚ã‚Šã¾ã™ã€‚<br><br>ã“ã®åŠ£æ‚ªãªå­¦ç¿’ç’°å¢ƒã“ããŒã€ã€ŒçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã€ã¨ã„ã†å½¢ã§çŸ¥è­˜ãŒå±€æ‰€çš„ã«æ ¼ç´ã•ã‚Œã‚‹åŸå› ã®ä¸€ã¤ã«ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã¤ã¾ã‚Šã€<br><br>å­¦ç¿’ã®éåŠ¹ç‡æ€§: æ·±ã„å±¤ã®ã»ã¨ã‚“ã©ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ã€å‹¾é…æ¶ˆå¤±å•é¡Œã®ãŸã‚ã«åŠ¹ç‡çš„ã«å­¦ç¿’ã‚’é€²ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚<br><br>å°‚é–€åŒ–ã®ç™ºç”Ÿ: ãã®ã‚ˆã†ãªä¸å®‰å®šãªç’°å¢ƒä¸‹ã§ã€ãŸã¾ãŸã¾ç‰¹å®šã®çŸ¥è­˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã†ã¾ãæ‰ãˆã‚‹ã“ã¨ãŒã§ããŸä¸€éƒ¨ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒã€ãã®çŸ¥è­˜ã‚’ä¸€èº«ã«èƒŒè² ã†å½¢ã§å¼·ãæ´»æ€§åŒ–ã™ã‚‹ã‚ˆã†ç‰¹åŒ–ï¼ˆå°‚é–€åŒ–ï¼‰ã—ã¦ã„ã£ãŸã®ã§ã¯ãªã„ã‹ã€ã¨è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚ã“ã‚Œã¯ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å…¨ä½“ã§å”èª¿ã—ã¦å­¦ç¿’ã™ã‚‹ã®ãŒé›£ã—ã„çŠ¶æ³ã§ã€ä¸€éƒ¨ã®ãƒ¦ãƒ‹ãƒƒãƒˆã ã‘ãŒçªå‡ºã—ã¦å­¦ç¿’ã‚’æ‹…ã†ã€ã¨ã„ã†ç¾è±¡ã¨è§£é‡ˆã§ãã¾ã™ã€‚<br><br>å­¦ç¿’ã®å®‰å®šåŒ–ãŒã€ã‚ˆã‚ŠåŠ¹ç‡çš„ãªçŸ¥è­˜ç²å¾—ã«ã¤ãªãŒã‚‹<br>ã§ã¯ã€ã€ŒThe Curse of Depthã€ã§ææ¡ˆã•ã‚ŒãŸæ‰‹æ³•ï¼ˆLNã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰ã«ã‚ˆã£ã¦æ·±ã„å±¤ã®å­¦ç¿’ãŒå®‰å®šåŒ–ã™ã‚‹ã¨ã€çŸ¥è­˜ã®æ ¼ç´æ–¹æ³•ã¯ã©ã®ã‚ˆã†ã«å¤‰ã‚ã‚‹ã§ã—ã‚‡ã†ã‹ã€‚<br><br>ã“ã‚Œã¯éå¸¸ã«èˆˆå‘³æ·±ã„å•ã„ã§ã‚ã‚Šã€2ã¤ã®å¯èƒ½æ€§ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚<br><br>å¯èƒ½æ€§A: ã‚ˆã‚Šå¼·å›ºãªçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®å½¢æˆ:<br>å­¦ç¿’ãŒå®‰å®šã™ã‚‹ã“ã¨ã§ã€å„çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯ã‚ˆã‚Šæ˜ç¢ºã«ã€ãã—ã¦åŠ¹ç‡çš„ã«ç‰¹å®šã®çŸ¥è­˜ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ãƒã‚¤ã‚ºã®å¤šã„ç’°å¢ƒã§å¶ç„¶ç”Ÿã¾ã‚ŒãŸå°‚é–€å®¶ã§ã¯ãªãã€å®‰å®šã—ãŸç’°å¢ƒã§è‚²æˆã•ã‚ŒãŸçœŸã®å°‚é–€å®¶ã¸ã¨å¤‰åŒ–ã™ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ã€‚<br><br>å¯èƒ½æ€§B: çŸ¥è­˜ã®åˆ†æ•£åŒ–:<br>ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å…¨ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒåŠ¹ç‡çš„ã«å­¦ç¿’ã«å¯„ä¸ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ãŸã‚ã€ä¸€ã¤ã®çŸ¥è­˜ã‚’å°‘æ•°ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«é›†ä¸­ã•ã›ã‚‹å¿…è¦ãŒãªããªã‚Šã€ã‚ˆã‚Šå¤šãã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«åˆ†æ•£ã—ã¦çŸ¥è­˜ãŒæ ¼ç´ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹å¯èƒ½æ€§ã‚‚è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚<br><br>ç¾åœ¨ã®ã¨ã“ã‚ã€å­¦ç¿’ã®å®‰å®šåŒ–ã¯ã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒã‚ˆã‚ŠåŠ¹ç‡çš„ã«å½¢æˆãƒ»æ©Ÿèƒ½ã™ã‚‹ãŸã‚ã®åŸºç›¤ã‚’æä¾›ã™ã‚‹ã¨è€ƒãˆã‚‹ã®ãŒæœ€ã‚‚å¦¥å½“ã§ã—ã‚‡ã†ã€‚ã€Œæ·±ã•ã®å‘ªã„ã€ã¨ã„ã†å•é¡Œã‚’è§£æ±ºã™ã‚‹ã“ã¨ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒçŸ¥è­˜ã‚’ã©ã®ã‚ˆã†ã«ç²å¾—ã—ã€æ•´ç†ã™ã‚‹ã‹ã¨ã„ã†ã€ã‚ˆã‚Šæ ¹æºçš„ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ï¼ˆçŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æŒ¯ã‚‹èˆã„ï¼‰ã«ã‚‚ç›´æ¥çš„ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã¯ãšã§ã™ã€‚<br><br>ã¾ã¨ã‚<br>ã€ŒKnowledge Neuronsã€ã¯æ·±ã„å±¤ã«å­˜åœ¨ã™ã‚‹çŸ¥è­˜ã®**ã€ŒçŠ¶æ…‹ã€ã‚’æ˜ã‚‰ã‹ã«ã—ã€ã€ŒThe Curse of Depthã€ã¯æ·±ã„å±¤ã§ç™ºç”Ÿã™ã‚‹å­¦ç¿’ã®ã€Œå•é¡Œã€**ã¨ãã®è§£æ±ºç­–ã‚’æç¤ºã—ã¾ã—ãŸã€‚<br><br>ã“ã‚Œã‚‰ã‚’çµ±åˆã™ã‚‹ã¨ã€**ã€Œæ·±ã„å±¤ã«ãŠã‘ã‚‹å­¦ç¿’ã®ä¸å®‰å®šæ€§ã¨ã„ã†å•é¡ŒãŒã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¨ã„ã†å±€æ‰€çš„ãªçŸ¥è­˜è¡¨ç¾ã‚’ç”Ÿã¿å‡ºã™ä¸€å› ã¨ãªã£ã¦ãŠã‚Šã€ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚ŠåŠ¹ç‡çš„ã§å®‰å®šã—ãŸçŸ¥è­˜ã®ç²å¾—ãƒ»æ ¼ç´ãŒå¯èƒ½ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€**ã¨ã„ã†é–¢ä¿‚æ€§ãŒè¦‹ãˆã¦ãã¾ã™ã€‚<br><br>ä¸¡è€…ã¯ã€LLMã®èƒ½åŠ›ã¨é™ç•Œã‚’ç•°ãªã‚‹è§’åº¦ã‹ã‚‰ç…§ã‚‰ã—å‡ºã—ã¦ãŠã‚Šã€çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨å‹•ä½œã®è§£æ˜ã‚’ã•ã‚‰ã«ä¸€æ­©å‰é€²ã•ã›ã‚‹ã€éå¸¸ã«é‡è¦ãªç ”ç©¶ã ã¨è¨€ãˆã¾ã™ã€‚<br>```</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/CurriculumLearning.html" target="_blank" rel="noopener noreferrer">#CurriculumLearning</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2128" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable  Reinforcement Learning, GLM-V Team+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- è¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ«GLM-4.1V-Thinkingã‚’ç™ºè¡¨ã—ã€æ¨è«–ä¸­å¿ƒã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é–‹ç™ºã€‚å¼·åŠ›ãªè¦–è¦šåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã€ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’ç”¨ã„ãŸå¼·åŒ–å­¦ç¿’ã§å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã®èƒ½åŠ›ã‚’å‘ä¸Šã€‚28ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ç‰¹ã«é›£ã—ã„ã‚¿ã‚¹ã‚¯ã§ç«¶äº‰åŠ›ã®ã‚ã‚‹çµæœã‚’ç¤ºã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sinclairwang1/status/1940331927724232712?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Qwen2.5-VLã‚ˆã‚Šã‚‚æ€§èƒ½ãŒè‰¯ã„VLM<br><img src="https://github.com/user-attachments/assets/1215d0cf-3776-4631-a5d5-2c514e7d5a2e" alt="image" loading="lazy"></p>
<p>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã“ã¡ã‚‰ã€‚ãŒã€pretraining(ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°, ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«â†’long contextç¶™ç¶šäº‹å‰å­¦ç¿’)-&gt;SFT(cold startã¸ã®å¯¾å‡¦, reasoningèƒ½åŠ›ã®ç²å¾—)-&gt;RL(RLVRã¨RLHFã®ä½µç”¨ã«ã‚ˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã¨Alignment, RewardHackingã¸ã®å¯¾å‡¦,curriculum sampling)ãªã©ã€å…¨ä½“ã®å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ç´°ã‹ã„ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã®ç©ã¿é‡ã­ã§é«˜ã„æ€§èƒ½ãŒç²å¾—ã•ã‚Œã¦ã„ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/a692b5de-5f4e-42c6-938e-3718dd2fc0e6" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2025-06-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2109" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data  Processing to Every Language, Guilherme Penedo+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤šè¨€èªLLMsã®æ€§èƒ½å‘ä¸Šã®ãŸã‚ã«ã€FineWebã«åŸºã¥ãæ–°ã—ã„äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ææ¡ˆã€‚9ã¤ã®è¨€èªã«å¯¾ã—ã¦è¨­è¨ˆé¸æŠè‚¢ã‚’æ¤œè¨¼ã—ã€éè‹±èªã‚³ãƒ¼ãƒ‘ã‚¹ãŒå¾“æ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ˆã‚Šã‚‚é«˜æ€§èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å†ãƒãƒ©ãƒ³ã‚¹æ‰‹æ³•ã‚‚å°å…¥ã—ã€1000ä»¥ä¸Šã®è¨€èªã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã—ãŸ20ãƒ†ãƒ©ãƒã‚¤ãƒˆã®å¤šè¨€èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆFineWeb2ã‚’å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gui_penedo/status/1938631842720022572?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>v1<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1942" target="_blank" rel="noopener noreferrer">The FineWeb Datasets: Decanting the Web for the Finest Text Data at   Scale, Guilherme Penedo+, NeurIPS'24</a>
</p>
<p>abstã‚’è¦‹ã‚‹é™ã‚ŠFinewebã‚’å¤šè¨€èªã«æ‹¡å¼µã—ãŸæ¨¡æ§˜</p>
<p>openreview:


<a href="https://openreview.net/forum?id=jnRBe6zatP#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=jnRBe6zatP#discussion</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2107" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling, Zengzhi Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ç•°ãªã‚‹ãƒ™ãƒ¼ã‚¹è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLlamaã‚„Qwenï¼‰ã®å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã«ãŠã‘ã‚‹æŒ™å‹•ã‚’èª¿æŸ»ã—ã€ä¸­é–“ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ãŒRLã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’æ˜ã‚‰ã‹ã«ã€‚é«˜å“è³ªã®æ•°å­¦ã‚³ãƒ¼ãƒ‘ã‚¹ãŒãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã€é•·ã„é€£é–çš„æ€è€ƒï¼ˆCoTï¼‰ãŒRLçµæœã‚’æ”¹å–„ã™ã‚‹ä¸€æ–¹ã§ã€å†—é•·æ€§ã‚„ä¸å®‰å®šæ€§ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚äºŒæ®µéšã®ä¸­é–“ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã€ŒStable-then-Decayã€ã‚’å°å…¥ã—ã€OctoThinkerãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’é–‹ç™ºã€‚ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã¨æ•°å­¦æ¨è«–ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’å…¬é–‹ã—ã€RLæ™‚ä»£ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®ç ”ç©¶ã‚’æ”¯æ´ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sinclairwang1/status/1938244843857449431?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>mid-trainingã®è¦³ç‚¹ã‹ã‚‰ã€post trainingã«ãŠã‘ã‚‹RLãŒã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹æ¡ä»¶ã‚’systematicallyã«èª¿æŸ»ã—ã¦ã„ã‚‹æ¨¡æ§˜</p>
<p>è«–æ–‡ä¸­ã«ã¯mid-training[^1]ã®å®šç¾©ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹:<br><br>&lt;img width="808" height="353" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/da206d3d-f811-4d69-8210-a1d0816c827f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/da206d3d-f811-4d69-8210-a1d0816c827f"&lt;/a&gt;


/&gt;<br><br>[^1]: mid-trainingã«ã¤ã„ã¦ã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®é–“ã§å³å¯†ãªå®šç¾©ã¯ã¾ã ç„¡ããƒã‚ºãƒ¯ãƒ¼ãƒ‰ã£ã½ãä½¿ã‚ã‚Œã¦ã„ã‚‹ã€ã¨ã„ã†å°è±¡ã‚’ç­†è€…ã¯æŠ±ã„ã¦ãŠã‚Šã€æœ¬ç¨¿ã¯æ–‡çŒ®ä¸­ã§mid-trainingã‚’å®šç¾©ã™ã‚‹åˆã‚ã¦ã®è©¦ã¿ã¨ã„ã†æ‰€æ„Ÿ</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/ICCV.html" target="_blank" rel="noopener noreferrer">#ICCV</a>
<a class="button" href="articles/Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2025-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2105" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] OpenVision: A Fully-Open, Cost-Effective Family of Advanced Vision  Encoders for Multimodal Learning, Xianhang Li+, ICCV'25</a>
<span class="snippet"><span>GPT Summary</span>- OpenVisionã¯ã€å®Œå…¨ã«ã‚ªãƒ¼ãƒ—ãƒ³ã§ã‚³ã‚¹ãƒˆåŠ¹æœã®é«˜ã„ãƒ“ã‚¸ãƒ§ãƒ³ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’ææ¡ˆã—ã€CLIPã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚æ—¢å­˜ã®ç ”ç©¶ã‚’åŸºã«æ§‹ç¯‰ã•ã‚Œã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®é€²å±•ã«å®Ÿç”¨çš„ãªåˆ©ç‚¹ã‚’ç¤ºã—ã¾ã™ã€‚5.9Mã‹ã‚‰632.1Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’æä¾›ã—ã€å®¹é‡ã¨åŠ¹ç‡ã®æŸ”è»Ÿãªãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å®Ÿç¾ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cihangxie/status/1920575141849030882?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>v2ã¸ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cihangxie/status/1963297223753494832?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>äº‹å‰å­¦ç¿’æ™‚ã«text, image encoderã®contrastive lossã§å­¦ç¿’ã—ã¦ã„ãŸãŒã€text encoderã‚’ç„¡ãã—image encoderã«å…¥åŠ›ã•ã‚ŒãŸimageã‹ã‚‰captionã‚’ç”Ÿæˆã™ã‚‹caption lossã®ã¿ã«ã™ã‚‹ã“ã¨ã§æ€§èƒ½ã‚’è½ã¨ã™ã“ã¨ãªãåŠ¹ç‡ã‚’æ”¹å–„<br><br>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼ãŒå‡ºãŸæ¨¡æ§˜<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2820" target="_blank" rel="noopener noreferrer">[Paper Note] OpenVision 2: A Family of Generative Pretrained Visual Encoders for
  Multimodal Learning, Yanqing Liu+, arXiv'25</a>
<p>HF:


<a href="https://huggingface.co/collections/UCSC-VLAA/openvision-681a4c27ee1f66411b4ae919" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/UCSC-VLAA/openvision-681a4c27ee1f66411b4ae919</a>


<br>pj page: 


<a href="https://ucsc-vlaa.github.io/OpenVision/" target="_blank" rel="noopener noreferrer">https://ucsc-vlaa.github.io/OpenVision/</a>


</p>
<p>CLIP, SigLIPã¨ã¯ç•°ãªã‚Šå®Œå…¨ã«ã‚ªãƒ¼ãƒ—ãƒ³ãªVision Encoder<br><img src="https://github.com/user-attachments/assets/b7c8eb07-45df-4ab3-9cd2-6b31af46e761" alt="image" loading="lazy"></p>
<p>v2ã®è§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1963442911108084161?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/SyntheticDataGeneration.html" target="_blank" rel="noopener noreferrer">#SyntheticDataGeneration</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2094" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs   with Nothing, Zhangchen Xu+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- é«˜å“è³ªãªæŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã¯LLMã®æ•´åˆã«ä¸å¯æ¬ ã§ã‚ã‚Šã€Magpieã¨ã„ã†è‡ªå·±åˆæˆæ‰‹æ³•ã‚’ææ¡ˆã€‚Llama-3-Instructã‚’ç”¨ã„ã¦400ä¸‡ã®æŒ‡ç¤ºã¨å¿œç­”ã‚’ç”Ÿæˆã—ã€30ä¸‡ã®é«˜å“è³ªãªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’é¸å®šã€‚Magpieã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã€å¾“æ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ãŸãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ã€ç‰¹ã«æ•´åˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸçµæœã‚’å¾—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=Pnk7vMbznK" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Pnk7vMbznK</a>


</p>
<p><img src="https://github.com/user-attachments/assets/9cb451b2-5440-43a4-9867-b5206dd08cca" alt="image" loading="lazy"><br><br>ä¸‹è¨˜ã®ã‚ˆã†ãªpre-queryãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä¸ãˆï¼ˆi.e., userã®ç™ºè©±ã¯ä½•ã‚‚ä¸ãˆãšã€ãƒ¦ãƒ¼ã‚¶ã®ç™ºè©±ã‚’è¡¨ã™ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿ã‚’æ¸¡ã™ï¼‰instructionã‚’ç”Ÿæˆã—ã€post-queryãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä¸ãˆã‚‹ï¼ˆi.e., pre-queryãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ+ç”Ÿæˆã•ã‚ŒãŸinstruction+assistantã®ç™ºè©±ã®é–‹å§‹ã‚’è¡¨ã™ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã®ã¿ã‚’æ¸¡ã™ï¼‰ã“ã¨ã§responseã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€prompt engineeringã‚„seedç„¡ã—ã§instruction tuningãƒ‡ãƒ¼ã‚¿ã‚’åˆæˆã§ãã‚‹ã¨ã„ã†æ‰‹æ³•ã€‚<br><img src="https://github.com/user-attachments/assets/59e9ea58-1088-4f7f-a5e1-05fba7221aca" alt="image" loading="lazy"><br><br>ç”Ÿæˆã—ãŸç”Ÿã®instruction tuning pair dataã¯ã€ãŸã¨ãˆã°ä¸‹è¨˜ã®ã‚ˆã†ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ã™ã‚‹ã“ã¨ã§å“è³ªå‘ä¸ŠãŒå¯èƒ½ã§<br><img src="https://github.com/user-attachments/assets/6dc19e89-2e0d-409d-9d96-eca8d92d27d3" alt="image" loading="lazy"><br><br>reward modelã¨çµ„ã¿åˆã‚ã›ã¦LLMã‹ã‚‰ã®responseã‚’ç”Ÿæˆã—rejection samplingã™ã‚Œã°DPOã®ãŸã‚ã®preference dataã‚‚ä½œæˆã§ãã‚‹ã—ã€single turnã®ç™ºè©±ã¾ã§ç”Ÿæˆã•ã›ãŸå¾Œã‚‚ã†ä¸€åº¦pre/post-queryã‚’concatã—ã¦ç”Ÿæˆã™ã‚Œã°Multi turnã®ãƒ‡ãƒ¼ã‚¿ã‚‚ç”Ÿæˆã§ãã‚‹ã€‚<br><br>ä»–ã®ã‚‚ä¾‹ãˆã°ã€ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è‡ªåˆ†ãŒç”Ÿæˆã—ãŸã„æƒ…å ±ã‚’ä¸ãˆã‚‹ã“ã¨ã§ã€ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ç‰¹åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿ã€ã‚ã‚‹ã„ã¯ç‰¹å®šã®è¨€èªã«ç‰¹åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚‚åˆæˆã§ãã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/f5f06b90-d1cb-4de8-bbaa-622abbcc0b6b" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="articles/DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<a class="button" href="articles/CrossDomain.html" target="_blank" rel="noopener noreferrer">#CrossDomain</a>
<span class="issue_date">Issue Date: 2025-06-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2070" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain  Perspective, Zhoujun Cheng+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Guruã‚’å°å…¥ã—ã€æ•°å­¦ã€ã‚³ãƒ¼ãƒ‰ã€ç§‘å­¦ã€è«–ç†ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€è¡¨å½¢å¼ã®6ã¤ã®æ¨è«–ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã‚ãŸã‚‹92Kã®RLæ¨è«–ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’æ§‹ç¯‰ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMæ¨è«–ã®ãŸã‚ã®RLã®ä¿¡é ¼æ€§ã¨åŠ¹æœã‚’å‘ä¸Šã•ã›ã€ãƒ‰ãƒ¡ã‚¤ãƒ³é–“ã®å¤‰å‹•ã‚’è¦³å¯Ÿã€‚ç‰¹ã«ã€äº‹å‰å­¦ç¿’ã®éœ²å‡ºãŒé™ã‚‰ã‚ŒãŸãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã¯ã€ãƒ‰ãƒ¡ã‚¤ãƒ³å†…ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºå”†ã€‚Guru-7Bã¨Guru-32Bãƒ¢ãƒ‡ãƒ«ã¯ã€æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã—ã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ”¹å–„ã€‚ãƒ‡ãƒ¼ã‚¿ã¨ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chengzhoujun/status/1936113985507803365?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>post-trainingã«ãŠã‘ã‚‹RLã®cross domainï¼ˆMath, Code, Science, Logic, Tabular)ã«ãŠã‘ã‚‹å½±éŸ¿ã‚’èª¿æŸ»ã—ãŸç ”ç©¶ã€‚éå¸¸ã«èˆˆå‘³æ·±ã„ç ”ç©¶ã€‚è©³ç´°ã¯å…ƒè«–æ–‡ãŒè‘—è€…ãƒã‚¹ãƒˆå‚ç…§ã®ã“ã¨ã€‚</p>
<p>Qwenã‚·ãƒªãƒ¼ã‚ºã§å®Ÿé¨“ã€‚ä»¥ä¸‹ãƒã‚¹ãƒˆã®ã¾ã¨ã‚ã€‚<br><br>- mid trainingã«ãŠã„ã¦é‡ç‚¹çš„ã«å­¦ç¿’ã•ã‚ŒãŸãƒ‰ãƒ¡ã‚¤ãƒ³ã¯RLã«ã‚ˆã‚‹post trainingã§å¼·ã„è»¢ç§»ã‚’ç™ºæ®ã™ã‚‹ï¼ˆCode, Math, Science)<br>- ä¸€æ–¹ã€mid trainingã§ã‚ã¾ã‚Šå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ä¸­ã«å‡ºç¾ã—ãªã„ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã¤ã„ã¦ã¯è»¢ç§»ã«ã‚ˆã‚‹æ€§èƒ½å‘ä¸Šã¯æœ€å°é™ã«ç•™ã¾ã‚Šã€in-domainã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ãã¡ã‚“ã¨ä¸ãˆã¦post trainingã—ãªã„ã¨æ€§èƒ½å‘ä¸Šã¯é™å®šçš„<br>- ç°¡å˜ãªã‚¿ã‚¹ã‚¯ã¯cross domainã®è»¢ç§»ã«ã‚ˆã‚‹æ©æµã‚’ã™ãã«å¾—ã‚„ã™ã„ï¼ˆMath500, MBPP),é›£æ˜“åº¦ã®é«˜ã„ã‚¿ã‚¹ã‚¯ã¯æ©æµã‚’å¾—ã«ãã„<br>- å„ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ§˜ã«mixã™ã‚‹ã¨ã€å˜ä¸€ãƒ‰ãƒ¡ã‚¤ãƒ³ã§å­¦ç¿’ã—ãŸå ´åˆã¨åŒç­‰ã‹ãã‚Œä»¥ä¸Šã®æ€§èƒ½ã‚’é”æˆã™ã‚‹<br>- å¿…ãšã—ã‚‚response lengthãŒé•·ããªã‚ŠãªãŒã‚‰äºˆæ¸¬æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã‚ã‘ã§ã¯ãªãã€ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ã‚ˆã£ã¦å‚¾å‘ãŒç•°ãªã‚‹<br>- ãŸã¨ãˆã°ã€Code, Logic, Tabularã®å‡ºåŠ›ã¯æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã«ã¤ã‚Œã¦response lengthã¯ç¸®å°ã—ã¦ã„ã<br>- ä¸€æ–¹ã€Science, Mathã¯response lengthãŒå¢—å¤§ã—ã¦ã„ãã€‚ã¾ãŸã€Simulationã¯å¤‰åŒ–ã—ãªã„<br>- ç•°ãªã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’mixã™ã‚‹ã“ã¨ã§ã€æœ€åˆã®æ•°ç™¾ã‚¹ãƒ†ãƒƒãƒ—ã«ãŠã‘ã‚‹rewardã®ç«‹ã¡ä¸ŠãŒã‚ŠãŒæ—©ãï¼ˆå˜ä¸€ãƒ‰ãƒ¡ã‚¤ãƒ³ã¨æ¯”ã¹ã¦æ€¥æ¿€ã«rewardãŒå‘ä¸Šã—ã¦ã„ãï¼‰è»¢ç§»ãŒã†ã¾ãã„ã<br>  - ï¼ˆã“ã‚Œã¯ç§ãŒã‚°ãƒ©ãƒ•ã‚’è¦‹ãŸæ„Ÿæƒ³ã ãŒã€å˜ä¸€ãƒ‰ãƒ¡ã‚¤ãƒ³ã§long runã§å­¦ç¿’ã—ãŸå ´åˆã®æœ€çµ‚çš„ãªæ€§èƒ½ã¯4/6ã§åŒç­‰ç¨‹åº¦ã€2/6ã§å‘ä¸Šï¼ˆMath, Science)<br>- éå¸¸ã«é›£æ˜“åº¦ã®é«˜ã„mathãƒ‡ãƒ¼ã‚¿ã®ã¿ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã¨ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç„¡ã—ã®å ´åˆã¨æ¯”ã¹ã¦é›£æ˜“åº¦ã®é«˜ã„ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬æ€§èƒ½ã¯å‘ä¸Šã™ã‚‹ä¸€æ–¹ã€ç°¡å˜ãªOODã‚¿ã‚¹ã‚¯ï¼ˆHumanEval)ã®æ€§èƒ½ãŒå¤§å¹…ã«ä½ä¸‹ã™ã‚‹ï¼ˆç‰¹å®šã®ã‚‚ã®ã«ç‰¹åŒ–ã™ã‚‹ã¨OODã®æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ï¼‰<br>- RLã¯pre(mid)-trainingã§å­¦ç¿’ã•ã‚ŒãŸreasoningèƒ½åŠ›ã‚’å¼•ãå‡ºã™ã ã‘ã§ã¯ãªãã€æ–°è¦ã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦ã¯æ–°ãŸãªreasoningèƒ½åŠ›ã‚’ç²å¾—ã§ãã‚‹<br>- ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã„ã¨ã€RLã§post-trainingå¾Œã®pass@kã®kã‚’å¤§ããã™ã‚‹ã¨ã©ã“ã‹ã§ã‚µãƒã‚Šã€baseãƒ¢ãƒ‡ãƒ«ã¨äº¤å·®ã™ã‚‹ãŒã€å¤§ãã„ã¨ã‚µãƒã‚‰ãšäº¤å·®ã—ãªã„<br>  - ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã„ã¨ã‚ˆã‚Šå¤šæ§˜ãªreasoningãƒ‘ã‚¹ãŒunlockã•ã‚Œã¦ã„ã‚‹<br>- pass@kã§è¦³å¯Ÿã—ãŸã¨ã“ã‚RLã«ã¯2ã¤ã®phaseã®ã‚ˆã¤ãªã‚‚ã®ãŒè¦³æ¸¬ã•ã‚Œã€æœ€åˆã®0-160ï¼ˆ1 epoch)ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯pass@1ãŒæ”¹å–„ã—ãŸãŒã€pass@max_kã¯æ€¥æ¿€ã«æ€§èƒ½ãŒåŠ£åŒ–ã—ãŸã€‚ä¸€æ–¹ã§ã€160ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¶…ãˆã‚‹ã¨ã€åŒæ–¹å…±ã«å¾ã€…ã«æ€§èƒ½æ”¹å–„ãŒæ”¹å–„ã—ã¦ã„ãã‚ˆã†ãªå¤‰åŒ–ãŒè¦‹ã‚‰ã‚ŒãŸ</p>
<p>æœ¬ç ”ç©¶ã§æ§‹ç¯‰ã•ã‚ŒãŸGuru Dataset:


<a href="https://huggingface.co/datasets/LLM360/guru-RL-92k" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/LLM360/guru-RL-92k</a>


<br><br>math, coding, science, logic, simulation, tabular reasoningã«é–¢ã™ã‚‹é«˜å“è³ªã€ã‹ã¤verifiableãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/3D%20Reconstruction.html" target="_blank" rel="noopener noreferrer">#3D Reconstruction</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2025-06-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2068" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] VGGT: Visual Geometry Grounded Transformer, Jianyuan Wang+, CVPR'25</a>
<span class="snippet"><span>GPT Summary</span>- VGGTã¯ã€ã‚·ãƒ¼ãƒ³ã®ä¸»è¦ãª3Då±æ€§ã‚’è¤‡æ•°ã®ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰ç›´æ¥æ¨æ¸¬ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€3Dã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã®åˆ†é‡ã«ãŠã„ã¦æ–°ãŸãªé€²å±•ã‚’ç¤ºã—ã¾ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯åŠ¹ç‡çš„ã§ã€1ç§’æœªæº€ã§ç”»åƒã‚’å†æ§‹ç¯‰ã—ã€è¤‡æ•°ã®3Dã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã—ã¾ã™ã€‚ã¾ãŸã€VGGTã‚’ç‰¹å¾´ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ä¸‹æµã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ãŒå¤§å¹…ã«å‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1936711294956265820?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-06-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2047" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LiveCodeBench Pro: How Do Olympiad Medalists Judge LLMs in Competitive  Programming?, Zihan Zheng+, NeurIPS'25</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã§äººé–“ã®ã‚¨ãƒªãƒ¼ãƒˆã‚’ä¸Šå›ã‚‹ã¨ã•ã‚Œã‚‹ãŒã€å®Ÿéš›ã«ã¯é‡è¦ãªé™ç•ŒãŒã‚ã‚‹ã“ã¨ã‚’èª¿æŸ»ã€‚æ–°ãŸã«å°å…¥ã—ãŸã€ŒLiveCodeBench Proã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ã‚ˆã‚Šã€LLMsã¯ä¸­ç¨‹åº¦ã®é›£æ˜“åº¦ã®å•é¡Œã§53%ã®pass@1ã‚’é”æˆã™ã‚‹ä¸€æ–¹ã€é›£ã—ã„å•é¡Œã§ã¯0%ã¨ã„ã†çµæœãŒå¾—ã‚‰ã‚ŒãŸã€‚LLMsã¯å®Ÿè£…é‡è¦–ã®å•é¡Œã§ã¯æˆåŠŸã™ã‚‹ãŒã€è¤‡é›‘ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çš„æ¨è«–ã«ã¯è‹¦åŠ´ã—ã€èª¤ã£ãŸæ­£å½“åŒ–ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒå¤šã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LLMsã¨äººé–“ã®å°‚é–€å®¶ã¨ã®é–“ã«é‡è¦ãªã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ä»Šå¾Œã®æ”¹å–„ã®ãŸã‚ã®è¨ºæ–­ãŒæä¾›ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1934433210387296414?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Hardãªå•é¡Œã¯ç¾çŠ¶ã®SoTAãƒ¢ãƒ‡ãƒ«ï¼ˆClaude4ãŒå«ã¾ã‚Œã¦ã„ãªã„ãŒï¼‰ã§ã‚‚æ­£ç­”ç‡0.0%<br><img src="https://github.com/user-attachments/assets/d0e29f23-2b66-4b19-b39a-68f3717d7058" alt="image" loading="lazy"><br><br>ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«å«ã¾ã‚Œã‚‹èª²é¡Œã®ã‚«ãƒ†ã‚´ãƒª<br><img src="https://github.com/user-attachments/assets/b41b11d7-52a2-4a22-848d-cb08900da5cf" alt="image" loading="lazy"><br><br>å®Ÿã‚µãƒ³ãƒ—ãƒ«ã‚„ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ãªã©ã¯Appendixå‚ç…§ã®ã“ã¨ã€‚</p>
<p>pj page:


<a href="https://livecodebenchpro.com" target="_blank" rel="noopener noreferrer">https://livecodebenchpro.com</a>


</p>
<p>ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ(NeurIPSã«accept):<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhaocha1/status/1969035554252611833?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="articles/Live.html" target="_blank" rel="noopener noreferrer">#Live</a>
<span class="issue_date">Issue Date: 2025-05-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1982" target="_blank" rel="noopener noreferrer" class="title-link">LiveBench: A Challenging, Contamination-Limited LLM Benchmark, Colin White+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®æ±šæŸ“ã‚’é˜²ããŸã‚ã«ã€LLMç”¨ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒLiveBenchã€ã‚’å°å…¥ã€‚LiveBenchã¯ã€é »ç¹ã«æ›´æ–°ã•ã‚Œã‚‹è³ªå•ã€è‡ªå‹•ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã€ã•ã¾ã–ã¾ãªæŒ‘æˆ¦çš„ã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ã€‚å¤šãã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ã€æ­£ç­”ç‡ã¯70%æœªæº€ã€‚è³ªå•ã¯æ¯æœˆæ›´æ–°ã•ã‚Œã€LLMã®èƒ½åŠ›å‘ä¸Šã‚’æ¸¬å®šå¯èƒ½ã«ã€‚ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®å‚åŠ ã‚’æ­“è¿ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã«å¯¾å‡¦ã§ãã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚ŒãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚é‡è¦ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1944" target="_blank" rel="noopener noreferrer" class="title-link">Nemotron-CC: Transforming Common Crawl into a Refined Long-Horizon   Pretraining Dataset, Dan Su+, ACL'25</a>
<span class="snippet"><span>GPT Summary</span>- FineWeb-Eduã¨DCLMã¯ã€ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚Šãƒ‡ãƒ¼ã‚¿ã®90%ã‚’å‰Šé™¤ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«é©ã•ãªããªã£ãŸã€‚è‘—è€…ã¯ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆ†é¡å™¨ã‚„åˆæˆãƒ‡ãƒ¼ã‚¿ã®è¨€ã„æ›ãˆã‚’ç”¨ã„ã¦ã€ç²¾åº¦ã¨ãƒ‡ãƒ¼ã‚¿é‡ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’æ”¹å–„ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚1Tãƒˆãƒ¼ã‚¯ãƒ³ã§8Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€DCLMã«å¯¾ã—ã¦MMLUã‚’5.6ãƒã‚¤ãƒ³ãƒˆå‘ä¸Šã•ã›ãŸã€‚æ–°ã—ã„6.3Tãƒˆãƒ¼ã‚¯ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€DCLMã¨åŒç­‰ã®æ€§èƒ½ã‚’æŒã¡ãªãŒã‚‰ã€4å€ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚’å«ã¿ã€é•·ãƒˆãƒ¼ã‚¯ãƒ³ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚15Tãƒˆãƒ¼ã‚¯ãƒ³ã®ãŸã‚ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸ8Bãƒ¢ãƒ‡ãƒ«ã¯ã€Llama 3.1ã®8Bãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1935" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Tina: Tiny Reasoning Models via LoRA, Shangshang Wang+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- Tinaã¯ã€ã‚³ã‚¹ãƒˆåŠ¹ç‡ã‚ˆãå¼·åŠ›ãªæ¨è«–èƒ½åŠ›ã‚’å®Ÿç¾ã™ã‚‹å°å‹ã®æ¨è«–ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã§ã‚ã‚Šã€1.5Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã«å¼·åŒ–å­¦ç¿’ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§é«˜ã„æ¨è«–æ€§èƒ½ã‚’ç¤ºã™ã€‚Tinaã¯ã€å¾“æ¥ã®SOTAãƒ¢ãƒ‡ãƒ«ã¨ç«¶äº‰åŠ›ãŒã‚ã‚Šã€AIME24ã§20%ä»¥ä¸Šã®æ€§èƒ½å‘ä¸Šã‚’é”æˆã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ã‚¹ãƒˆã¯ã‚ãšã‹9ãƒ‰ãƒ«ã§260å€ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ã‚’å®Ÿç¾ã€‚LoRAã‚’é€šã˜ãŸåŠ¹ç‡çš„ãªRLæ¨è«–ã®åŠ¹æœã‚’æ¤œè¨¼ã—ã€ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1920107023980462575?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ï¼ˆãŠãã‚‰ãï¼‰Reasoningãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€LoRAã¨RLã‚’çµ„ã¿åˆã‚ã›ã¦ã€reasoningèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ãŸåˆã‚ã¦ã®ç ”ç©¶</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-04-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1908" target="_blank" rel="noopener noreferrer" class="title-link">Safety Alignment Should Be Made More Than Just a Few Tokens Deep, Xiangyu Qi+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- ç¾åœ¨ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®å®‰å…¨æ€§ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã¯è„†å¼±ã§ã‚ã‚Šã€å˜ç´”ãªæ”»æ’ƒã‚„å–„æ„ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã£ã¦è„±ç„ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ã“ã®è„†å¼±æ€§ã¯ã€Œæµ…ã„å®‰å…¨æ€§ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã€ã«èµ·å› ã—ã€ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆãŒä¸»ã«æœ€åˆã®æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã®å‡ºåŠ›ã«ã®ã¿é©å¿œã•ã‚Œã‚‹ã“ã¨ã«é–¢é€£ã—ã¦ã„ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€ã“ã®å•é¡Œã®ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚’æç¤ºã—ã€ç¾åœ¨ã®ã‚¢ãƒ©ã‚¤ãƒ³ã•ã‚ŒãŸLLMsãŒç›´é¢ã™ã‚‹è„†å¼±æ€§ã‚’èª¬æ˜ã™ã‚‹ã€‚ã¾ãŸã€æµ…ã„å®‰å…¨æ€§ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã®æ¦‚å¿µãŒè„†å¼±æ€§è»½æ¸›ã®ç ”ç©¶æ–¹å‘ã‚’ç¤ºå”†ã—ã€åˆæœŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¶…ãˆãŸã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã®æ·±åŒ–ãŒãƒ­ãƒã‚¹ãƒˆæ€§ã‚’å‘ä¸Šã•ã›ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã™ã€‚æœ€å¾Œã«ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ”»æ’ƒã«å¯¾ã™ã‚‹æŒç¶šçš„ãªå®‰å…¨æ€§ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®æ­£å‰‡åŒ–ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç›®çš„ã‚’ææ¡ˆã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1917006979836612640?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=6Mxhg9PtDE" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=6Mxhg9PtDE</a>


</p>
<p>Safety Alignmentæ‰‹æ³•ãŒæœ€åˆã®æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã«ä¾å­˜ã—ã¦ã„ã‚‹ã‹ã‚‰ãã†ãªã‚‰ãªã„ã‚ˆã†ã«å­¦ç¿’ã—ã¾ã™ã¨ã„ã†ã®ã¯ã€èˆˆå‘³æ·±ã„ãƒ†ãƒ¼ãƒã ã—æŠ€è¡“çš„ã«ã¾ã å›°é›£ãªç‚¹ã‚‚ã‚ã£ãŸã ã‚ã†ã—ã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚‚å¤§ãã„ã—ã€ã¨ã¦ã‚‚è‰¯ã„ç ”ç©¶ã â€¦ã€‚</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/In-Depth%20Notes.html" target="_blank" rel="noopener noreferrer">#In-Depth Notes</a>
<span class="issue_date">Issue Date: 2025-04-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1887" target="_blank" rel="noopener noreferrer" class="title-link">A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths   to Reproducibility, Andreas Hochlehnert+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¨è«–ã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã®é‡è¦ãªèª²é¡Œã§ã‚ã‚Šã€é€²å±•ãŒè¦‹ã‚‰ã‚Œã‚‹ãŒã€è©•ä¾¡æ‰‹æ³•ã«ã¯é€æ˜æ€§ã‚„å …ç‰¢æ€§ãŒæ¬ ã‘ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€æ•°å­¦çš„æ¨è«–ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒå®Ÿè£…ã®é¸æŠã«æ•æ„Ÿã§ã‚ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã€æ¨™æº–åŒ–ã•ã‚ŒãŸè©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚å†è©•ä¾¡ã®çµæœã€å¼·åŒ–å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯æ”¹å–„ãŒå°‘ãªãã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã¯å¼·ã„ä¸€èˆ¬åŒ–ã‚’ç¤ºã—ãŸã€‚å†ç¾æ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã€é–¢é€£ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚„ãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã—ã€ä»Šå¾Œã®ç ”ç©¶ã®åŸºç›¤ã‚’ç¯‰ãã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1911143014258405420?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>SLMã‚’math reasoningå‘ã‘ã«post-trainingã™ã‚‹å ´åˆã€è©•ä¾¡ã®æ¡ä»¶ã‚’ãƒ•ã‚§ã‚¢ã«ã™ã‚‹ãŸã‚ã®æ§˜ã€…ãªå·¥å¤«ã‚’æ–½ã—è©•ä¾¡ã‚’ã—ãªãŠã—ãŸçµæœï¼ˆFigure1ã®ã‚ˆã†ã«æ€§èƒ½ãŒå¤‰åŒ–ã™ã‚‹æ§˜ã€…ãªè¦å› ãŒå­˜åœ¨ã™ã‚‹ï¼‰ã€RLï¼ˆæ—¢å­˜ç ”ç©¶ã§è©¦ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ï¼‰ã‚ˆã‚Šã‚‚ï¼ˆå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰rejection samplingã—ãŸreasoning traceã‚’ç”¨ã„ã¦ï¼‰SFTã‚’ã™ã‚‹æ–¹ãŒåŒç­‰ã‹æ€§èƒ½ãŒè‰¯ã(Table3)ã€çµå±€ã®ã¨ã“ã‚ï¼ˆãŠãã‚‰ãæ±åŒ–æ€§èƒ½ãŒä½ã„ã¨ã„ã†æ„å‘³ã§ï¼‰reliableã§ã¯ãªãã€ã‹ã¤ï¼ˆãŠãã‚‰ãå°è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã§ã†ã¾ãã„ã‹ãªã„ã¨ã„ã†æ„å‘³ã§ã®ï¼‰scalableã§ã¯ãªã„ã®ã§ã€reliableã‹ã¤scalableãªRLæ‰‹æ³•ãŒä¸è¶³ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚<br><br>â€» æœ¬è«–æ–‡ã§åˆ†æã•ã‚Œã¦ã„ã‚‹ã®ã¯&lt;=10Bä»¥ä¸‹ã®SLMã§ã‚ã‚‹ç‚¹ã«æ³¨æ„ã€‚10Bä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã§åŒã˜ã“ã¨ãŒè¨€ãˆã‚‹ã‹ã¯è‡ªæ˜ã§ã¯ãªã„ã€‚<br>â€» DAPO, VAPOãªã©ã«ã¤ã„ã¦ã‚‚åŒã˜ã“ã¨ãŒè¨€ãˆã‚‹ã‹ã‚‚è‡ªæ˜ã§ã¯ãªã„ã€‚<br>â€» DeepSeek-R1ã®technical reportã«ãŠã„ã¦ã€å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã«GRPOã‚’é©ç”¨ã—ã¦ã‚‚ã‚ã¾ã‚ŠåŠ¹æœãŒç„¡ã‹ã£ãŸã“ã¨ãŒæ—¢ã«å ±å‘Šã•ã‚Œã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/620017f1-b3f0-40c1-bf61-3b0b7a429ab4" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/321132c8-dad5-4aa1-9811-f032e3474135" alt="image" loading="lazy"><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1743" target="_blank" rel="noopener noreferrer">DeepSeek-R1ã®è«–æ–‡èª­ã‚“ã ï¼Ÿã€å‹‰å¼·ã«ãªã‚‹ã‚ˆã€‘ , asap, 2025.01</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
</p>
<p>å€‹ã€…ã®post-trainingã•ã‚ŒãŸRLãƒ¢ãƒ‡ãƒ«ãŒå…·ä½“çš„ã«ã©ã†ã„ã†è¨“ç·´ã‚’ã—ãŸã®ã‹ã¯è¿½ãˆã¦ã„ãªã„ãŒã€DAPOã‚„Dr. GRPO, VAPOã®å ´åˆã¯ã©ã†ãªã‚‹ã‚“ã ã‚ã†ã‹ï¼Ÿ<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1815" target="_blank" rel="noopener noreferrer">DAPO: An Open-Source LLM Reinforcement Learning System at Scale, Qiying Yu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1876" target="_blank" rel="noopener noreferrer">VAPO: Efficient and Reliable Reinforcement Learning for Advanced
  Reasoning Tasks, YuYue+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1821" target="_blank" rel="noopener noreferrer">Understanding R1-Zero-Like Training: A Critical Perspective, 2025.03</a>
<br><br>Rewardã®è¨­å®šã®ä»•æ–¹ã¯ã©ã®ã‚ˆã†ãªå½±éŸ¿ãŒã‚ã‚‹ã®ã ã‚ã†ã‹ï¼ˆverifiable rewardãªã®ã‹ã€neuralãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹rewardãªã®ã‹ãªã©)ï¼Ÿ<br><br>å­¦ç¿’ã®ã•ã›æ–¹ã‚‚ã©ã®ã‚ˆã†ãªå½±éŸ¿ãŒã‚ã‚‹ã®ã ã‚ã†ã‹ï¼ˆRLã§ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ learningã«ã—ãŸå ´åˆãªã©ï¼‰ï¼Ÿ<br><br>æ¤œè¨¼ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒãã‚Œãã‚Œã©ã®ã‚ˆã†ãªè¨­å®šã§å­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ã‹ã¾ã§ã‚’è¦‹ãªã„ã¨ã“ã®è¾ºã¯ã‚ã‹ã‚‰ãªãã†ã€‚<br><br>ãŸã ãªã‚“ã¨ãªãƒ¼ãã®ç›´æ„Ÿã ã¨ã€SLMã‚’è³¢ãã—ãŸã„ã¨ã„ã†å ´åˆã¯ä½•ã‚‰ã‹ã®è³¢ã„ãƒ¢ãƒ‡ãƒ«ã®æ©æµã«é ã‹ã‚‹ã¨æœ‰åˆ©ãªã‚±ãƒ¼ã‚¹ãŒå¤šãï¼ˆSFTã®å ´åˆã¯ãã‚ŒãŒå¤§è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰è’¸ç•™ã—ãŸreasoning traceï¼‰ã€SLM+RLã®å ´åˆã¯PRMã®ã‚ˆã†ãªæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’è©•ä¾¡ã—ã¦Rewardã«åæ˜ ã•ã›ã‚‹ã‚ˆã†ãªã‚‚ã®ã‚’åˆ©ç”¨ã—ãªã„ã¨ã€å°‘ãªãã¨ã‚‚å°è¦æ¨¡ãªLLMã‚’ã‚ã¡ã‚ƒè³¢ãã—ã¾ã™ã€œã¨ã„ã†ã®ã¯ãã¤ã„ã‚“ã˜ã‚ƒãªã„ã‹ãªã‚ã¨ã„ã†æ„Ÿæƒ³ã§ã¯ã‚ã‚‹ã€‚<br>ãŸã ã€çµå±€SLMã¨ã„ã†æ™‚ç‚¹ã§å¤šãã®å ´åˆã€ã‚ˆã‚Šè³¢ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å¤šã„LLMãŒä¸–ã®ä¸­ã«ã¯å­˜åœ¨ã™ã‚‹ã‚ã‚‹ã¯ãšãªã®ã§ã€RLã—ãªã„ã§SFTã—ã¦è’¸ç•™ã™ã‚Œã°è‰¯ã„ã‚“ã˜ã‚ƒãªã„â€¦ï¼Ÿã¨æ€ã£ã¦ã—ã¾ã†ã€‚<br>ãŒã€å¤šãã®å ´åˆãã®è³¢ã„LLMã¯ProprietaryãªLLMã§ã‚ã‚Šã€å‡ºåŠ›ã‚’å¾—ã¦è‡ªåˆ†ã®ãƒ¢ãƒ‡ãƒ«ã‚’post-trainingã™ã‚‹ã“ã¨ã¯åˆ©ç”¨è¦ç´„é•åã¨ãªã‚‹ãŸã‚ã€è‡ªå‰ã§è³¢ãã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å¤šã„LLMã‚’ç”¨æ„ã§ããªã„å ´åˆã¯å›°ã£ã¦ã—ã¾ã†ã®ã§ã€SLMã‚’ã‚¯ã‚½ãƒ‡ã‚«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã®æ©æµãªã—ã§è¶…çµ¶è³¢ãã§ããŸã‚‰ä¸–ã®ä¸­ã®å¤šãã®äººã¯å¬‰ã—ã„ã‚ˆã­ã€ã¨ã‚‚æ€ã†ã€‚</p>
<p>ï¼ˆæ–œã‚èª­ã¿ã ãŒï¼‰<br>ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„ï¼ˆæ•°åä»¶ï¼‰AIMEã‚„AMCãªã©ã®ãƒ‡ãƒ¼ã‚¿ã¯seedã®å€¤ã«ã¨ã¦ã‚‚sensitiveã§ã‚ã‚Š(Takeaway1, 2)ã€<br><br>&lt;img width="549" height="256" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/97581133-cf17-4635-b66c-442eaf8956d4"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/97581133-cf17-4635-b66c-442eaf8956d4"&lt;/a&gt;


/&gt;<br><br>ãã‚Œã‚‰ã¯10ç¨®é¡ã®seedã‚’ç”¨ã„ã¦çµæœã‚’å¹³å‡ã™ã‚‹ã¨åˆ†æ•£ãŒéå¸¸ã«å°ã•ããªã‚‹ã®ã§ã€seedã¯è¤‡æ•°ç¨®é¡åˆ©ç”¨ã—ã¦å¹³å‡ã®æ€§èƒ½ã‚’è¦‹ãŸæ–¹ãŒreliableã§ã‚ã‚Š(Takeaway3)<br><br>&lt;img width="688" height="266" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/5065ef0e-de89-4b17-aa52-c90b7191e9b2"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/5065ef0e-de89-4b17-aa52-c90b7191e9b2"&lt;/a&gt;


/&gt;<br><br>temperatureã‚’é«˜ãã™ã‚‹ã¨ãƒ”ãƒ¼ã‚¯æ€§èƒ½ãŒä¸ŠãŒã‚‹ãŒåˆ†æ•£ã‚‚ä¸ŠãŒã‚‹ãŸã‚å†ç¾æ€§ã®èª²é¡ŒãŒå¢—å¤§ã™ã‚‹ãŒã€top-pã‚’å¤§ããã™ã‚‹ã¨å†ç¾æ€§ã®å•é¡Œã¯ç¾ã‚Œãšæ€§èƒ½å‘ä¸Šã«å¯„ä¸ã—<br><br>&lt;img width="545" height="508" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/76d5c989-edbb-4d70-9080-d1d4b01de2ff"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/76d5c989-edbb-4d70-9080-d1d4b01de2ff"&lt;/a&gt;


/&gt;<br><br>æ—¢å­˜ç ”ç©¶ã®ãƒ¢ãƒ‡ãƒ«ã®temperatureã¨top-pã‚’å¤‰åŒ–ã•ã›å®Ÿé¨“ã™ã‚‹ã¨performanceã«éå¸¸ã«å¤§ããªå¤‰åŒ–ãŒå‡ºã‚‹ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«æœ€é©ãªå€¤ã‚’é¸å®šã—ã¦æ¯”è¼ƒã‚’ã—ãªã„ã¨unfairã§ã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ (Takeaway4)ã€‚<br><br>&lt;img width="553" height="511" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/d8b453d1-3d2e-4a80-b03d-c69ec1b2232e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/d8b453d1-3d2e-4a80-b03d-c69ec1b2232e"&lt;/a&gt;


/&gt;<br><br>ã¾ãŸã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®é¢ã§ã¯ã€vLLMã®ã‚ˆã†ãªinference engineã¯GPU typeã‚„memoryã®configurationã«å¯¾ã—ã¦sensitiveã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¤‰ã‚ã‚‹ã ã‘ã§ãªãã€<br><br>&lt;img width="689" height="356" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/a41891c7-072c-4c38-9ad6-beada4721bac"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/a41891c7-072c-4c38-9ad6-beada4721bac"&lt;/a&gt;


/&gt;<br><br>è©•ä¾¡ã«åˆ©ç”¨ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã”ã¨ã«inference engineã¨prompt templateãŒç•°ãªã‚‹ãŸã‚ã“ã¡ã‚‰ã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ãŒå‡ºã‚‹ã— (Takeaway5)ã€<br><br>&lt;img width="275" height="115" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/1f7d328c-0757-47b9-9961-630e2429fb3e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/1f7d328c-0757-47b9-9961-630e2429fb3e"&lt;/a&gt;


/&gt;<br><br>max output tokenã®å€¤ã‚’å¤‰åŒ–ã•ã›ã‚‹ã¨æ€§èƒ½ã‚‚å¤‰ã‚ã‚Šã€prompt templateã‚’åˆ©ç”¨ã—ãªã„ã¨æ€§èƒ½ãŒåŠ‡çš„ã«ä½ä¸‹ã™ã‚‹ (Takeaway6)ã€‚<br><br>&lt;img width="681" height="577" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/dc0902d1-a5f2-47de-8df1-c28107e1da28"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/dc0902d1-a5f2-47de-8df1-c28107e1da28"&lt;/a&gt;


/&gt;<br><br>ã“ã‚Œã‚‰ã®ã“ã¨ã‹ã‚‰è‘—è€…ã‚‰ã¯reliableãªè©•ä¾¡ã®ãŸã‚ã«ä¸‹è¨˜ã‚’ææ¡ˆã—ã¦ãŠã‚Š (4.1ç¯€; å¾Œã»ã©è¿½è¨˜)ã€<br><br>å®Ÿéš›ã«ã•ã¾ã–ã¾ãªæ¡ä»¶ã‚’fair comparisonã¨ãªã‚‹ã‚ˆã†ã«æ¨™æº–åŒ–ã—ã¦è©•ä¾¡ã—ãŸã¨ã“ã‚ï¼ˆ4.2ç¯€; å¾Œã»ã©è¿½è¨˜ï¼‰<br><br>ä¸Šã®è¡¨ã®ã‚ˆã†ãªçµæœã¨ãªã£ãŸã€‚ã“ã®çµæœã¯ã€<br>- DeepSeekR1-Distilledã‚’RLã—ã¦ã‚‚SFTã¨æ¯”è¼ƒã—ãŸã¨ãã«æ„å‘³ã®ã‚ã‚‹ã»ã©ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å‘ä¸Šã¯ãªã„ã“ã¨ã‹ã‚‰ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã€ã‹ã¤ä¿¡é ¼æ€§ã®ã‚ã‚‹RLæ‰‹æ³•ãŒã¾ã ä¸è¶³ã—ã¦ãŠã‚Š<br>- å¤§è¦æ¨¡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã®reasoning traceã‹ã‚‰SFTã‚’ã™ã‚‹æ–¹æ³•ã¯ã•ã¾ã–ã¾ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãƒ­ãƒã‚¹ãƒˆãªæ€§èƒ½ï¼ˆï¼é«˜ã„æ±åŒ–æ€§èƒ½ï¼‰ã‚’æŒã¡ã€RLã¨æ¯”ã¹ã‚‹ã¨ç¾çŠ¶ã¯RLã¨æ¯”è¼ƒã—ã¦ã‚ˆã‚Šãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã¨ã—ã¦æˆç†Ÿã—ã¦ãŠã‚Š<br>- ï¼ˆAIME24,25ã‚’æ¯”è¼ƒã™ã‚‹ã¨SFTã¨æ¯”ã¹ã¦RLã®å ´åˆperformanceã®ä½ä¸‹ãŒè‘—ã—ã„ã®ã§ï¼‰RLã¯overfittingã—ã‚„ã™ãã€OODãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒå¿…è¦</p>
<p>ã—ã£ã‹ã‚Šã¨è©•ä¾¡ã®æ çµ„ã¿ã‚’æ¨™æº–åŒ–ã—ã¦fair comparisonã—ã¦ã„ã‹ãªã„ã¨ã€RecSysæ¥­ç•Œã®äºŒã®èˆã«ãªã‚Šãã†ï¼ˆã¨ã„ã†ã‹ã‚‚ã†ãªã£ã¦ã‚‹ï¼Ÿï¼‰ã€‚<br><br>ã¾ãŸã“ã®ç ”ç©¶ã§åˆ†æã•ã‚Œã¦ã„ã‚‹ã®ã¯å°è¦æ¨¡ãªãƒ¢ãƒ‡ãƒ«ï¼ˆ&lt;=10Bï¼‰ã«å¯¾ã™ã‚‹æ—¢å­˜ç ”ç©¶ã§ç”¨ã„ã‚‰ã‚ŒãŸä¸€éƒ¨ã®RLæ‰‹æ³•ã‚„è¨­å®šã®æ€§èƒ½ã ã‘ï¼ˆçœŸã«ç¤ºã—ãŸã‹ã£ãŸã‚‰Phisics of LLMã®ã‚ˆã†ãªå®Œå…¨ã«ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«å¯èƒ½ãªã‚µãƒ³ãƒ‰ãƒœãƒƒã‚¯ã‚¹ã§å®Ÿé¨“ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã¨æ€ã‚ã‚Œã‚‹ï¼‰ãªã®ã§ã€DeepSeek-R1ã®ã‚ˆã†ã«ã€å¤§è¦æ¨¡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ•°ç™¾Bï¼‰ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹RLã«é–¢ã—ã¦åŒã˜ã“ã¨ãŒè¨€ãˆã‚‹ã‹ã¯è‡ªæ˜ã§ã¯ãªã„ç‚¹ã«æ³¨æ„ã€‚</p>
<p>openreview:


<a href="https://openreview.net/forum?id=90UrTTxp5O#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=90UrTTxp5O#discussion</a>


</p>
<p>æœ€è¿‘ã®ä»¥ä¸‹ã®ã‚ˆã†ãªSFTã¯RLã®ä¸€ã¤ã®ã‚±ãƒ¼ã‚¹ã¨è¦‹åšã›ã‚‹ã¨ã„ã†è­°è«–ã‚’è¸ã¾ãˆã‚‹ã¨ã©ã†ãªã‚‹ã ã‚ã†ã‹<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2700" target="_blank" rel="noopener noreferrer">[Paper Note] Towards a Unified View of Large Language Model Post-Training, Xingtai Lv+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-04-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1862" target="_blank" rel="noopener noreferrer" class="title-link">When Attention Sink Emerges in Language Models: An Empirical View, Xiangming Gu+, ICLR'25</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹ã€Œã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã€ã¯ã€æ„å‘³çš„ã«é‡è¦ã§ãªã„ãƒˆãƒ¼ã‚¯ãƒ³ã«å¤§ããªæ³¨æ„ã‚’å‰²ã‚Šå½“ã¦ã‚‹ç¾è±¡ã§ã‚ã‚Šã€ã•ã¾ã–ã¾ãªå…¥åŠ›ã«å¯¾ã—ã¦å°ã•ãªãƒ¢ãƒ‡ãƒ«ã§ã‚‚æ™®éçš„ã«å­˜åœ¨ã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã¯äº‹å‰å­¦ç¿’ä¸­ã«å‡ºç¾ã—ã€æœ€é©åŒ–ã‚„ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã€æå¤±é–¢æ•°ãŒãã®å‡ºç¾ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã€‚ç‰¹ã«ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã¯ã‚­ãƒ¼ã®ãƒã‚¤ã‚¢ã‚¹ã®ã‚ˆã†ã«æ©Ÿèƒ½ã—ã€æƒ…å ±ã‚’æŒãŸãªã„è¿½åŠ ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã‚’ä¿å­˜ã™ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ã“ã®ç¾è±¡ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³ãŒã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹æ­£è¦åŒ–ã«ä¾å­˜ã—ã¦ã„ã‚‹ã“ã¨ã‹ã‚‰éƒ¨åˆ†çš„ã«ç”Ÿã˜ã¦ãŠã‚Šã€æ­£è¦åŒ–ãªã—ã®ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã«ç½®ãæ›ãˆã‚‹ã“ã¨ã§ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã®å‡ºç¾ã‚’é˜²ãã“ã¨ãŒã§ãã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Sink Rateã¨å‘¼ã°ã‚Œã‚‹ã€å…¨ã¦ã®headã®First Tokenã«å¯¾ã™ã‚‹attention scoreã®ã†ã¡ï¼ˆlayer l * head hå€‹å­˜åœ¨ã™ã‚‹ï¼‰ã€ã©ã®ç¨‹åº¦ã®å‰²åˆã®ã‚¹ã‚³ã‚¢ãŒé–¾å€¤ã‚’ä¸Šå›ã£ã¦ã„ã‚‹ã‹ã‚’è¡¨ã™æŒ‡æ¨™ã‚’ææ¡ˆ<br>ï¼ˆå¾Œã»ã©è©³ç´°ã‚’è¿½è¨˜ã™ã‚‹ï¼‰</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1860" target="_blank" rel="noopener noreferrer">Why do LLMs attend to the first token?, Federico Barbero+, COLM'25</a>
<br><br>ã®å…ˆè¡Œç ”ç©¶</p>
<p>è‘—è€…ãƒã‚¹ãƒˆï¼ˆopenai-gpt-120Bã‚’å—ã‘ã¦):<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gu_xiangming/status/1952811057673642227?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>openreview:


<a href="https://openreview.net/forum?id=78Nn4QJTEN" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=78Nn4QJTEN</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<a class="button" href="articles/COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<span class="issue_date">Issue Date: 2025-04-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1860" target="_blank" rel="noopener noreferrer" class="title-link">Why do LLMs attend to the first token?, Federico Barbero+, COLM'25</a>
<span class="snippet"><span>GPT Summary</span>- LLMsã¯æœ€åˆã®ãƒˆãƒ¼ã‚¯ãƒ³ã«å¼·ãæ³¨æ„ã‚’å‘ã‘ã‚‹ã€Œã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã€ã‚’ç¤ºã—ã€ãã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒéå‰°æ··åˆã‚’é¿ã‘ã‚‹æ–¹æ³•ã‚’ç†è«–çš„ãƒ»å®Ÿè¨¼çš„ã«æ¢æ±‚ã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•ã‚„ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ãƒƒã‚­ãƒ³ã‚°ãŒã‚·ãƒ³ã‚¯ã®æŒ™å‹•ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’å®Ÿé¨“ã§ç¤ºã—ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç†è§£ã‚’æ·±ã‚ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1908187563422261411?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Attention Sinkã«ã‚ˆã£ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³ã®æƒ…å ±ãŒover-mixingã•ã‚Œã‚‹ã“ã¨ãŒæŠ‘åˆ¶ã•ã‚Œã€Decoder-only LLMã®æ·±ã„å±¤ã®representationãŒå‡ä¸€åŒ–ã•ã‚Œã‚‹ã“ã¨ã‚’æŠ‘åˆ¶ã™ã‚‹ï¼ˆï¼promptã®æ‘‚å‹•ã«ãƒ­ãƒã‚¹ãƒˆã«ãªã‚‹ï¼‰ã“ã¨ãŒç¤ºã•ã‚ŒãŸæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/8a1223c0-5621-42a5-accc-31fa7f636856" alt="image" loading="lazy"><br>Gemma7Bã«ãŠã„ã¦ã€promptä¸­ã®ãƒˆãƒ¼ã‚¯ãƒ³ä¸€èªã‚’ç½®æ›ã—ãŸå¾Œã«ã€Attention Sinkï¼ˆ<bos>ï¼‰ã®æœ‰ç„¡ã«ã‚ˆã£ã¦ã€tokenãƒ¬ãƒ™ãƒ«ã®representationã«å¯¾ã—ã¦ã©ã®ã‚ˆã†ãªæ‘‚å‹•ãŒã‚ã‚‹ã‹ã‚’layerã”ã¨ã«ã¾ã¨ã‚ãŸå›³ãŒä¸‹è¨˜ã®æ¨¡æ§˜ã€‚Attention Sinkã«ã‚ˆã£ã¦ã€tokenã®æ‘‚å‹•ãŒä»–ã®token, layerã«å¯¾ã—ã¦mixingã•ã‚Œã‚‹ã®ãŒæŠ‘åˆ¶ã•ã‚Œã¦ã„ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/b1a4038a-d116-4bd1-b27b-c55eb861bee9" alt="image" loading="lazy">&lt;/p&gt;<p>openreview:


<a href="https://openreview.net/forum?id=tu4dFUsW5z#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=tu4dFUsW5z#discussion</a>


</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1847" target="_blank" rel="noopener noreferrer" class="title-link">Demystifying LLM-based Software Engineering Agents, Chunqiu Steven Xia+, FSE'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®LLMã®é€²å±•ã«ã‚ˆã‚Šã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã‚¿ã‚¹ã‚¯ã®è‡ªå‹•åŒ–ãŒé€²ã‚“ã§ã„ã‚‹ãŒã€è¤‡é›‘ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å¿…è¦æ€§ã«ç–‘å•ãŒç”Ÿã˜ã¦ã„ã‚‹ã€‚ã“ã‚Œã«å¯¾ã—ã€Agentlessã¨ã„ã†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¬ã‚¹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€ã‚·ãƒ³ãƒ—ãƒ«ãªä¸‰æ®µéšãƒ—ãƒ­ã‚»ã‚¹ã§å•é¡Œã‚’è§£æ±ºã€‚SWE-bench Liteãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€é«˜ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ä½ã‚³ã‚¹ãƒˆã‚’é”æˆã€‚ç ”ç©¶ã¯è‡ªå¾‹å‹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã«ãŠã‘ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ã§è§£é‡ˆå¯èƒ½ãªæŠ€è¡“ã®å¯èƒ½æ€§ã‚’ç¤ºã—ã€ä»Šå¾Œã®ç ”ç©¶ã®æ–¹å‘æ€§ã‚’åˆºæ¿€ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://note.com/ainest/n/nac1c795e3825" target="_blank" rel="noopener noreferrer">https://note.com/ainest/n/nac1c795e3825</a>


</p>
<p>LLMã«ã‚ˆã‚‹è¨ˆç”»ã®ç«‹æ¡ˆã€ç’°å¢ƒã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ã‚ˆã‚‹æ„æ€æ±ºå®šãªã©ã®è¤‡é›‘ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§ã¯ãªãã€Localizationï¼ˆéšå±¤çš„ã«å•é¡Œã®ã‚ã‚‹ç®‡æ‰€ã‚’åŒå®šã™ã‚‹ï¼‰ã¨Repairï¼ˆLLMã§è¤‡æ•°ã®ãƒ‘ãƒƒãƒå€™è£œã‚’ç”Ÿæˆã™ã‚‹ï¼‰ã€PatchValidation(å†ç¾ãƒ†ã‚¹ãƒˆã¨å›å¸°ãƒ†ã‚¹ãƒˆã®ä¸¡æ–¹ã‚’é€šã˜ã¦çµæœãŒè‰¯ã‹ã£ãŸãƒ‘ãƒƒãƒã‚’é¸ã¶ï¼‰ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’é€šã˜ã¦Issueã‚’è§£æ±ºã™ã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/6d042dfe-9780-4410-9077-b265af5456d1" alt="image" loading="lazy"><br><br>ã“ã‚Œã«ã‚ˆã‚Šã€ä½ã‚³ã‚¹ãƒˆã§é«˜ã„æ€§èƒ½ã‚’é”æˆã—ã¦ã„ã‚‹ã€ã¨ã„ã£ãŸå†…å®¹ãªæ¨¡æ§˜ã€‚<br><img src="https://github.com/user-attachments/assets/3934126f-3a4d-406c-8860-c3ed35a351c4" alt="image" loading="lazy"></p>
<p>Agentlessã¨å‘¼ã°ã‚Œæ‰‹æ³•ã ãŒã€preprintç‰ˆã«ã‚ã£ãŸã‚¿ã‚¤ãƒˆãƒ«ã®æ¥é ­è¾ã ã£ãŸåŒå‘¼ç§°ãŒproceedingç‰ˆã§ã¯ç„¡ããªã£ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/GenerativeAI.html" target="_blank" rel="noopener noreferrer">#GenerativeAI</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-03-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1842" target="_blank" rel="noopener noreferrer" class="title-link">Measuring AI Ability to Complete Long Tasks, Thomas Kwa+, arXiv'25, 2025.03</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„æŒ‡æ¨™ã€Œ50%-ã‚¿ã‚¹ã‚¯å®Œäº†æ™‚é–“ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ã€ã‚’ææ¡ˆã—ã€AIãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’äººé–“ã®è¦³ç‚¹ã‹ã‚‰å®šé‡åŒ–ã€‚Claude 3.7 Sonnetã¯ç´„50åˆ†ã®æ™‚é–“ãƒ›ãƒ©ã‚¤ã‚ºãƒ³ã‚’æŒã¡ã€AIã®èƒ½åŠ›ã¯2019å¹´ä»¥é™ç´„7ã‹æœˆã”ã¨ã«å€å¢—ã€‚ä¿¡é ¼æ€§ã‚„è«–ç†çš„æ¨è«–ã®å‘ä¸ŠãŒè¦å› ã¨ã•ã‚Œã€5å¹´ä»¥å†…ã«AIãŒå¤šãã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¿ã‚¹ã‚¯ã‚’è‡ªå‹•åŒ–ã§ãã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1902854727089656016?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span></bos></p>
<p>ç¢ºã‹ã«ç·šå½¢ã«è¦‹ãˆã‚‹ã€‚ã¦ã‹GPT-2ã¨æ¯”ã¹ã‚‹ã¨AIã•ã‚“é€²åŒ–ã—ã™ãã§ã‚ã‚‹â€¦ã€‚<br><img src="https://github.com/user-attachments/assets/266a36aa-a169-492b-b8af-60c0cb152111" alt="image" loading="lazy"></p>
<p>åˆ©ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯<br>- HCAST: 46ã®ã‚¿ã‚¹ã‚¯ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã«åŸºã¥ã97ç¨®é¡ã®ã‚¿ã‚¹ã‚¯ãŒå®šç¾©ã•ã‚Œã¦ãŠã‚Šã€ãŸã¨ãˆã°ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€æ©Ÿæ¢°å­¦ç¿’ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€ä¸€èˆ¬çš„ãªæ¨è«–ã‚¿ã‚¹ã‚¯ï¼ˆwikipediaã‹ã‚‰äº‹å®Ÿæƒ…å ±ã‚’æ¢ã™ã‚¿ã‚¹ã‚¯ãªã©ï¼‰ãªã©ãŒã‚ã‚‹<br>  - æ•°åˆ†ã§çµ‚ã‚ã‚‹ã‚¿ã‚¹ã‚¯: ä¸Šè¿°ã®wikipedia<br>  - æ•°æ™‚é–“ã§çµ‚ã‚ã‚‹ã‚¿ã‚¹ã‚¯: Pytorchã®ã¡ã‚‡ã£ã¨ã—ãŸãƒã‚°ä¿®æ­£ãªã©<br>  - æ•°æ–‡ã§ã‚¿ã‚¹ã‚¯ãŒè¨˜è¿°ã•ã‚Œã€ã‚³ãƒ¼ãƒ‰ã€ãƒ‡ãƒ¼ã‚¿ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã€ã‚ã‚‹ã„ã¯webã‹ã‚‰å…¥æ‰‹å¯èƒ½ãªæƒ…å ±ã‚’å‚ç…§å¯èƒ½<br>ã€€- ã‚¿ã‚¹ã‚¯ã®é›£æ˜“åº¦ã¨ã—ã¦ã¯å½“è©²ãƒ‰ãƒ¡ã‚¤ãƒ³ã«æ•°å¹´é–“æºã‚ã£ãŸå°‚é–€å®¶ãŒè§£ã‘ã‚‹å•é¡Œ<br>- RE-Bench Suite<br>  - 7ã¤ã®open endedãªå°‚é–€å®¶ãŒ8æ™‚é–“ç¨‹åº¦ã‚’è¦ã™ã‚‹MLã«é–¢ã™ã‚‹ã‚¿ã‚¹ã‚¯<br>ã€€- e.g., GPT-2ã‚’QAç”¨ã«Finetuningã™ã‚‹, Finetuningã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«æŒ™å‹•ã‚’å¤‰åŒ–ã•ã›ãšã«ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚’å¯èƒ½ãªé™ã‚ŠçŸ­ç¸®ã™ã‚‹ã€ãªã©<br>ã€€- [RE-Bench Technical Report](


<a href="https://metr.org/AI_R_D_Evaluation_Report.pdf)%E3%81%AETable2%E7%AD%89%E3%82%92%E5%8F%82%E7%85%A7%E3%81%AE%E3%81%93%E3%81%A8" target="_blank" rel="noopener noreferrer">https://metr.org/AI_R_D_Evaluation_Report.pdf)ã®Table2ç­‰ã‚’å‚ç…§ã®ã“ã¨</a>


<br>- SWAA Suite: 66ç¨®é¡ã®1ã¤ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«ã‚ˆã£ã¦1åˆ†ä»¥å†…ã§çµ‚ã‚ã‚‹ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã§å…¸å‹çš„ãªã‚¿ã‚¹ã‚¯<br>  - 1åˆ†ä»¥å†…ã§çµ‚ã‚ã‚‹ã‚¿ã‚¹ã‚¯ãŒä¸Šè¨˜ãƒ‡ãƒ¼ã‚¿ã«ãªã‹ã£ãŸã®ã§è‘—è€…ã‚‰ãŒä½œæˆ<br><br>ã§ã‚ã‚Šã€ç”»åƒç³»ã‚„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªã‚¿ã‚¹ã‚¯ã¯å«ã¾ã‚Œã¦ã„ãªã„ã€‚<br><img src="https://github.com/user-attachments/assets/0b3892c9-3c83-4f78-a490-c28fa7470e0e" alt="image" loading="lazy"><br><br>ã‚¿ã‚¹ã‚¯ã¨äººé–“ãŒã‚¿ã‚¹ã‚¯ã«è¦ã™ã‚‹æ™‚é–“ã®å¯¾å¿œã«é–¢ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã¯ä¸‹è¨˜<br><img src="https://github.com/user-attachments/assets/5ed472da-e8c9-41be-8fd1-ef6f21713c14" alt="image" loading="lazy"></p>
<p>ã‚¿ã‚¹ã‚¯-ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒšã‚¢ã”ã¨ã«8å›å®Ÿè¡Œã—ãŸå ´åˆã®å¹³å‡ã®æˆåŠŸç‡ã€‚ç¢ºã‹ã«ã“ã®ã‚°ãƒ©ãƒ•ã‹ã‚‰ã¯Nå¹´å¾Œã«ã¯äººé–“ã§è¨€ã†ã¨ã“ã®ãã‚‰ã„ã®èƒ½åŠ›ã®äººãŒã“ã®ãã‚‰ã„æ™‚é–“ã‚’è¦ã™ã‚‹ã‚¿ã‚¹ã‚¯ãŒã€ã“ã®ãã‚‰ã„ã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ã¾ã™ã€ã¨ã„ã£ãŸã–ã£ãã‚Šæ„Ÿè¦šå€¤ã¯ãªã‹ãªã‹æƒ³åƒã§ããªã„ã€‚<br><img src="https://github.com/user-attachments/assets/e2bed06e-9234-4607-826a-588106010bcf" alt="image" loading="lazy"></p>
<p>æˆåŠŸç‡ã¨ã‚¿ã‚¹ã‚¯ã«äººé–“ãŒè¦ã™ã‚‹æ™‚é–“ã«é–¢ã™ã‚‹ã‚°ãƒ©ãƒ•ã€‚ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯é–¢æ•°ã§fittingã—ã¦ãŠã‚Šã€èµ¤ã„ç ´ç·šãŒ50% horizonã€‚Claude 3.5 Sonnet ï¼ˆoldï¼‰ã‹ã‚‰Claude 3.7 Sonnetã§50% horizonã¯18åˆ†ã‹ã‚‰59åˆ†ã¾ã§å¢—ãˆã¦ã„ã‚‹ã€‚å®Ÿéš›ã«æ•°å­—ã§è¦‹ã‚‹ã¨ã‚¤ãƒ¡ãƒ¼ã‚¸ãŒæ¹§ãã‚„ã™ããŠã‚‚ã—ã‚ã„ã€‚<br><img src="https://github.com/user-attachments/assets/efe01e35-6ee6-45a5-8a4c-eccf95284b35" alt="image" loading="lazy"></p>
<p>ã“ã¡ã‚‰ã§æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚‚éšæ™‚æ›´æ–°ã•ã‚Œã‚‹:<br>


<a href="https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/" target="_blank" rel="noopener noreferrer">https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/</a>


</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-03-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1815" target="_blank" rel="noopener noreferrer" class="title-link">DAPO: An Open-Source LLM Reinforcement Learning System at Scale, Qiying Yu+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æ¨è«–ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚ŠLLMã®æ¨è«–èƒ½åŠ›ãŒå‘ä¸Šã—ã€å¼·åŒ–å­¦ç¿’ãŒè¤‡é›‘ãªæ¨è«–ã‚’å¼•ãå‡ºã™æŠ€è¡“ã¨ãªã‚‹ã€‚ã—ã‹ã—ã€æœ€å…ˆç«¯ã®æŠ€è¡“è©³ç´°ãŒéš ã•ã‚Œã¦ã„ã‚‹ãŸã‚å†ç¾ãŒé›£ã—ã„ã€‚ãã“ã§ã€$\textbf{DAPO}$ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã—ã€Qwen2.5-32Bãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦AIME 2024ã§50ãƒã‚¤ãƒ³ãƒˆã‚’é”æˆã€‚æˆåŠŸã®ãŸã‚ã®4ã¤ã®é‡è¦æŠ€è¡“ã‚’å…¬é–‹ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‰ã¨å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã™ã‚‹ã“ã¨ã§å†ç¾æ€§ã‚’å‘ä¸Šã•ã›ã€ä»Šå¾Œã®ç ”ç©¶ã‚’æ”¯æ´ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¢å­˜ã®reasoning modelã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã«ãŠã„ã¦ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªRLã®å­¦ç¿’ã§éµã¨ãªã‚‹ãƒ¬ã‚·ãƒ”ã¯éš ã•ã‚Œã¦ã„ã‚‹ã¨ä¸»å¼µã—ã€å®Ÿéš›å½¼ã‚‰ã®baselineã¨ã—ã¦GRPOã‚’èµ°ã‚‰ã›ãŸã¨ã“ã‚ã€DeepSeekã‹ã‚‰å ±å‘Šã•ã‚Œã¦ã„ã‚‹AIME2024ã§ã®æ€§èƒ½ï¼ˆ47ãƒã‚¤ãƒ³ãƒˆï¼‰ã‚ˆã‚Šã‚‚ã§ã€€å¤§å¹…ã«ä½ã„æ€§èƒ½ï¼ˆ30ãƒã‚¤ãƒ³ãƒˆï¼‰ã—ã‹åˆ°é”ã§ããšã€åˆ†æã®çµæœ3ã¤ã®èª²é¡Œï¼ˆentropy collapse, reward noise, training instabilityï¼‰ã‚’æ˜ã‚‰ã‹ã«ã—ãŸï¼ˆå®Ÿéš›R1ã®çµæœã‚’å†ç¾ã§ããªã„å ±å‘ŠãŒå¤šæ•°å ±å‘Šã•ã‚Œã¦ãŠã‚Šã€é‡è¦ãªè¨“ç·´ã®è©³ç´°ãŒéš ã•ã‚Œã¦ã„ã‚‹ã¨ã—ã¦ã„ã‚‹ï¼‰ã€‚<br><br>ãã®ä¸Šã§50%ã®trainikg stepã§DeepSeek-R1-Zero-Qwen-32Bã¨åŒç­‰ã®AIME 2024ã§ã®æ€§èƒ½ã‚’é”æˆã§ãã‚‹DAPOã‚’ææ¡ˆã€‚ãã—ã¦gapã‚’åŸ‹ã‚ã‚‹ãŸã‚ã«ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã™ã‚‹ã¨ã®ã“ã¨ã€‚</p>
<p>ã¡ã¨ã“ã‚Œã¯ã‚ã¨ã§ã—ã£ã‹ã‚Šèª­ã¿ãŸã„ã€‚é‡è¦è«–æ–‡ã€‚</p>
<p>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒšãƒ¼ã‚¸:


<a href="https://dapo-sia.github.io/" target="_blank" rel="noopener noreferrer">https://dapo-sia.github.io/</a>


<br><br>ã“ã¡ã‚‰ã«ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é‡è¦ãªéƒ¨åˆ†ã®æ¦‚è¦ãŒèª¬æ˜ã•ã‚Œã¦ã„ã‚‹ã€‚</p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1902507148015489385?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã ãŒåˆ†ã‹ã‚Šã‚„ã™ãã¾ã¨ã¾ã£ã¦ã„ã‚‹ã€‚<p>ä¸‹è¨˜ãƒã‚¹ãƒˆã«ã‚ˆã‚‹ã¨ã€Reward Scoreã«å¤šæ§˜æ€§ã‚’æŒãŸã›ãŸã„å ´åˆã¯3.2ç¯€å‚ç…§ã¨ã®ã“ã¨ã€‚<br>ã™ãªã‚ã¡ã€Dynamic Samplingã®è©±ã§ã€AccãŒå…¨ã¦ã®ç”Ÿæˆã§1.0ã‚ã‚‹ã„ã¯0.0ã¨ãªã‚‹ã‚ˆã†ãªpromptã‚’é™¤å¤–ã™ã‚‹ã¨ã„ã£ãŸæ–¹æ³•ã®è©±ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br>ã“ã‚Œã¯ã€ã‚ã‚‹promptã«å¯¾ã™ã‚‹å…¨ã¦ã®ç”Ÿæˆã§æ­£è§£/ä¸æ­£è§£ã«ãªã£ãŸå ´åˆã€ãã®promptã«å¯¾ã™ã‚‹AdvantageãŒ0ã¨ãªã‚‹ãŸã‚ã€ãƒãƒªã‚·ãƒ¼ã‚’updateã™ã‚‹ãŸã‚ã®gradientã‚‚0ã¨ãªã‚‹ã€‚ãã†ã™ã‚‹ã¨ã€ã“ã®ã‚µãƒ³ãƒ—ãƒ«ã¯ãƒãƒªã‚·ãƒ¼ã®æ›´æ–°ã«å…¨ãå¯„ä¸ã—ãªããªã‚‹ãŸã‚ã€åŒãƒãƒƒãƒå†…ã®ãƒã‚¤ã‚ºã«å¯¾ã™ã‚‹é ‘å¥æ€§ãŒå¤±ã‚ã‚Œã‚‹ã“ã¨ã«ãªã‚‹ã€‚ã‚µãƒ³ãƒ—ãƒ«åŠ¹ç‡ã‚‚ä½ä¸‹ã™ã‚‹ã€‚ç‰¹ã«AccãŒ1.0ã«ãªã‚‹ã‚ˆã†ãªpromptã¯å­¦ç¿’ãŒé€²ã‚€ã«ã¤ã‚Œã¦å¢—åŠ ã™ã‚‹ãŸã‚ã€ãƒãƒƒãƒå†…ã§å­¦ç¿’ã«æœ‰åŠ¹ãªpromptã¯æ¸›ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã€gradientã®åˆ†æ•£ã®å¢—åŠ ã«ã¤ãªãŒã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚‰ã—ã„ã€‚<br><br>é–¢é€£ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1936375947575632102?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‰²ã€…ãªç ”ç©¶ã§åºƒãä½¿ã‚ã‚Œã‚‹ã®ã‚’è¦‹ã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚</p>
<p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/qiying_yu/status/1902405115082104875?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-02-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1749" target="_blank" rel="noopener noreferrer" class="title-link">s1: Simple test-time scaling, Niklas Muennighoff+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚¹ãƒˆæ™‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ç”¨ã„ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆs1Kã‚’ä½œæˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’åˆ¶å¾¡ã™ã‚‹äºˆç®—å¼·åˆ¶ã‚’å°å…¥ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯ä¸æ­£ç¢ºãªæ¨è«–ã‚’ä¿®æ­£ã—ã€Qwen2.5-32B-Instructãƒ¢ãƒ‡ãƒ«ãŒo1-previewã‚’æœ€å¤§27%ä¸Šå›ã‚‹çµæœã‚’é”æˆã€‚ã•ã‚‰ã«ã€ä»‹å…¥ãªã—ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒå¯èƒ½ã¨ãªã£ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ã€ã‚³ãƒ¼ãƒ‰ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§æä¾›ã€‚</span>
<span class="snippet"><span>Comment</span><p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1887260791981941121?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-02-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer" class="title-link">Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã«ãŠã‘ã‚‹é•·ã„æ€è€ƒã®é€£é–ï¼ˆCoTsï¼‰æ¨è«–ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’èª¿æŸ»ã—ã€é‡è¦ãªè¦å› ã‚’ç‰¹å®šã€‚ä¸»ãªç™ºè¦‹ã¯ã€(1) æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆSFTï¼‰ã¯å¿…é ˆã§ã¯ãªã„ãŒåŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã‚‹ã€(2) æ¨è«–èƒ½åŠ›ã¯è¨ˆç®—ã®å¢—åŠ ã«ä¼´ã„ç¾ã‚Œã‚‹ãŒã€å ±é…¬ã®å½¢çŠ¶ãŒCoTã®é•·ã•ã«å½±éŸ¿ã€(3) æ¤œè¨¼å¯èƒ½ãªå ±é…¬ä¿¡å·ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒé‡è¦ã§ã€ç‰¹ã«åˆ†å¸ƒå¤–ã‚¿ã‚¹ã‚¯ã«åŠ¹æœçš„ã€(4) ã‚¨ãƒ©ãƒ¼ä¿®æ­£èƒ½åŠ›ã¯åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ã«å­˜åœ¨ã™ã‚‹ãŒã€RLã‚’é€šã˜ã¦åŠ¹æœçš„ã«å¥¨åŠ±ã™ã‚‹ã«ã¯å¤šãã®è¨ˆç®—ãŒå¿…è¦ã€‚ã“ã‚Œã‚‰ã®æ´å¯Ÿã¯ã€LLMsã®é•·ã„CoTæ¨è«–ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æˆ¦ç•¥ã®æœ€é©åŒ–ã«å½¹ç«‹ã¤ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xiangyue96/status/1887332772198371514?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ƒãƒã‚¹ãƒˆã®ã‚¹ãƒ¬ãƒƒãƒ‰ä¸­ã«è«–æ–‡ã®11å€‹ã®çŸ¥è¦‹ãŒè¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ã©ã‚Œã‚‚éå¸¸ã«èˆˆå‘³æ·±ã„ã€‚DeepSeek-R1ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼ã¨åŒæ§˜ã€<br><br>- Long CoTã¨Short CoTã‚’æ¯”è¼ƒã™ã‚‹ã¨å‰è€…ã®æ–¹ãŒåˆ°é”å¯èƒ½ãªæ€§èƒ½ã®upper bonudãŒé«˜ã„ã“ã¨ã‚„ã€<br>- SFTã‚’å®Ÿæ–½ã—ã¦ã‹ã‚‰RLã‚’ã™ã‚‹ã¨æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚„ã€<br>- RLã®éš›ã«CoTã®Lengthã«é–¢ã™ã‚‹å ±é…¬ã‚’å…¥ã‚Œã‚‹ã“ã¨ã§CoTã®é•·ã•ã‚’æŠ‘ãˆã¤ã¤æ€§èƒ½å‘ä¸Šã§ãã‚‹ã“ã¨ã€<br>- æ•°å­¦ã ã‘ã§ãªãQAãƒšã‚¢ãªã©ã®ãƒã‚¤ã‚¸ãƒ¼ã ãŒæ¤œè¨¼å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚’Verifiableãªå ±é…¬ã¨ã—ã¦åŠ ãˆã‚‹ã¨ä¸€èˆ¬çš„ãªreasoningã‚¿ã‚¹ã‚¯ã§æ•°å­¦ã‚ˆã‚Šã‚‚ã•ã‚‰ã«æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã€<br>- ã‚ˆã‚Šé•·ã„context window sizeã‚’æ´»ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«ã¯ã‚ˆã‚Šå¤šãã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ãªã“ã¨ã€<br>- long CoTã¯RLã«ã‚ˆã£ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«é¡ä¼¼ã—ãŸãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®æ®µéšã§ãã®èƒ½åŠ›ãŒç²å¾—ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ã“ã¨ã€<br>- aha momentã¯ã™ã§ã«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«æ™‚ç‚¹ã§ç²å¾—ã•ã‚Œã¦ãŠã‚ŠVerifiableãªå ±é…¬ã«ã‚ˆã‚‹RLã«ã‚ˆã£ã¦å¼·åŒ–ã•ã‚ŒãŸã‚ã‘ã§ã¯ãªã•ãã†ã€<br><br>ãªã©ã€èˆˆå‘³æ·±ã„çŸ¥è¦‹ãŒç››ã‚Šã ãã•ã‚“ã€‚éå¸¸ã«èˆˆå‘³æ·±ã„ç ”ç©¶ã€‚ã‚ã¨ã§èª­ã‚€ã€‚</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-01-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1740" target="_blank" rel="noopener noreferrer" class="title-link">SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model   Post-training, Tianzhe Chu+, ICML'25</a>
<span class="snippet"><span>GPT Summary</span>- SFTã¨RLã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã®é•ã„ã‚’ç ”ç©¶ã—ã€GeneralPointsã¨V-IRLã‚’ç”¨ã„ã¦è©•ä¾¡ã€‚RLã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã¨è¦–è¦šå¤‰ç¨®ã«å¯¾ã—ã¦å„ªã‚ŒãŸä¸€èˆ¬åŒ–ã‚’ç¤ºã™ä¸€æ–¹ã€SFTã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜æ†¶ã—åˆ†å¸ƒå¤–ã‚·ãƒŠãƒªã‚ªã«è‹¦åŠ´ã€‚RLã¯è¦–è¦šèªè­˜èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€SFTã¯RLè¨“ç·´ã«ä¸å¯æ¬ ã§ã‚ã‚Šã€å‡ºåŠ›å½¢å¼ã‚’å®‰å®šã•ã›ã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Šã‚’ä¿ƒé€²ã€‚ã“ã‚Œã‚‰ã®çµæœã¯ã€è¤‡é›‘ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹RLã®ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1884731381517082668?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>openreview:


<a href="https://openreview.net/forum?id=dYur3yabMj&referrer=%5Bthe%20profile%20of%20Yi%20Ma%5D(%2Fprofile%3Fid%3D~Yi_Ma4)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=dYur3yabMj&referrer=%5Bthe%20profile%20of%20Yi%20Ma%5D(%2Fprofile%3Fid%3D~Yi_Ma4)</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1730" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Humanity's Last Exam, Long Phan+, arXiv'25</a>
<span class="snippet"><span>GPT Summary</span>- ã€Œäººé¡ã®æœ€å¾Œã®è©¦é¨“ï¼ˆHLEï¼‰ã€ã‚’å°å…¥ã—ã€LLMã®èƒ½åŠ›ã‚’æ¸¬å®šã™ã‚‹æ–°ã—ã„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ææ¡ˆã€‚HLEã¯2,500ã®è³ªå•ã‹ã‚‰æˆã‚Šã€æ•°å­¦ã‚„è‡ªç„¶ç§‘å­¦ãªã©åºƒç¯„ãªç§‘ç›®ã‚’ã‚«ãƒãƒ¼ã€‚å°‚é–€å®¶ã«ã‚ˆã£ã¦é–‹ç™ºã•ã‚Œã€è‡ªå‹•æ¡ç‚¹ãŒå¯èƒ½ãªå½¢å¼ã§ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¤œç´¢ã§ã¯è¿…é€Ÿã«å›ç­”ã§ããªã„ã€‚æœ€å…ˆç«¯ã®LLMã¯HLEã«å¯¾ã—ã¦ä½ã„ç²¾åº¦ã‚’ç¤ºã—ã€ç¾åœ¨ã®LLMã®èƒ½åŠ›ã¨å°‚é–€å®¶ã®çŸ¥è­˜ã¨ã®é–“ã«å¤§ããªã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã€‚HLEã¯å…¬é–‹ã•ã‚Œã€ç ”ç©¶ã‚„æ”¿ç­–ç«‹æ¡ˆã«å½¹ç«‹ã¦ã‚‰ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>o1, DeepSeekR1ã®æ­£è§£ç‡ãŒ10%æœªæº€ã®æ–°ãŸãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-11-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3573" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Simplified and Generalized Masked Diffusion for Discrete Data, Jiaxin Shi+, NeurIPS'24, 2024.06</a>
<span class="snippet"><span>GPT Summary</span>- Maskedæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®æ½œåœ¨èƒ½åŠ›ã‚’å¼•ãå‡ºã™ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚é€£ç¶šæ™‚é–“å¤‰åˆ†ç›®çš„ãŒã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±ã®é‡ã¿ä»˜ãç©åˆ†ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€çŠ¶æ…‹ä¾å­˜ã®ãƒã‚¹ã‚­ãƒ³ã‚°ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç”¨ã„ãŸãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å¯èƒ½ã«ã€‚OpenWebTextã§ã®è©•ä¾¡ã§ã€GPT-2ã‚¹ã‚±ãƒ¼ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆè¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã€‚ç”»åƒãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã§ã‚‚CIFAR-10ã‚„ImageNetã§å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹çµæœã‚’é”æˆã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ä¸­ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=xcqSOfHt4g&referrer=%5Bthe%20profile%20of%20Michalis%20Titsias%5D(%2Fprofile%3Fid%3D~Michalis_Titsias1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=xcqSOfHt4g&referrer=%5Bthe%20profile%20of%20Michalis%20Titsias%5D(%2Fprofile%3Fid%3D~Michalis_Titsias1)</a>


</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1986" target="_blank" rel="noopener noreferrer">Masked Diffusion Modelã®é€²å±•, Deep Learning JP, 2025.03</a>
<br><br>ã§ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹</p>
<p>æ¬¡:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1776" target="_blank" rel="noopener noreferrer">Large Language Diffusion Models, Shen Nie+, NeurIPS'25</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-11-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3572" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Simple and Effective Masked Diffusion Language Models, Subham Sekhar Sahoo+, NeurIPS'24, 2024.06</a>
<span class="snippet"><span>GPT Summary</span>- ãƒã‚¹ã‚¯ä»˜ãé›¢æ•£æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¯ã€å¾“æ¥ã®è‡ªå·±å›å¸°æ‰‹æ³•ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚åŠ¹æœçš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã¨ç°¡ç•¥åŒ–ã•ã‚ŒãŸç›®çš„é–¢æ•°ã‚’å°å‡ºã—ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å°‚ç”¨ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ä»»æ„ã®é•·ã•ã®ãƒ†ã‚­ã‚¹ãƒˆç”ŸæˆãŒå¯èƒ½ã«ã€‚è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æ–°ãŸãªæœ€å…ˆç«¯ã‚’é”æˆã—ã€ARæ‰‹æ³•ã«è¿‘ã¥ãæˆæœã‚’ä¸Šã’ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=L4uaAR4ArM&referrer=%5Bthe%20profile%20of%20Volodymyr%20Kuleshov%5D(%2Fprofile%3Fid%3D~Volodymyr_Kuleshov1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=L4uaAR4ArM&referrer=%5Bthe%20profile%20of%20Volodymyr%20Kuleshov%5D(%2Fprofile%3Fid%3D~Volodymyr_Kuleshov1)</a>


</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1986" target="_blank" rel="noopener noreferrer">Masked Diffusion Modelã®é€²å±•, Deep Learning JP, 2025.03</a>
<br><br>ã§ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹</p>
<p>æ¬¡:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3573" target="_blank" rel="noopener noreferrer">[Paper Note] Simplified and Generalized Masked Diffusion for Discrete Data, Jiaxin Shi+, NeurIPS'24, 2024.06</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-11-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3551" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Large Language Monkeys: Scaling Inference Compute with Repeated Sampling, Bradley Brown+, arXiv'24, 2024.07</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€å€™è£œè§£ã‚’ç¹°ã‚Šè¿”ã—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚ã‚µãƒ³ãƒ—ãƒ«æ•°ã®å¢—åŠ ã«ä¼´ã„ã€å•é¡Œè§£æ±ºã®ã‚«ãƒãƒ¬ãƒƒã‚¸ãŒ4æ¡ã®ã‚ªãƒ¼ãƒ€ãƒ¼ã§ã‚¹ã‚±ãƒ¼ãƒ«ã—ã€å¯¾æ•°ç·šå½¢ã®é–¢ä¿‚ãŒç¤ºå”†ã•ã‚Œã‚‹ã€‚è‡ªå‹•æ¤œè¨¼å¯èƒ½ãªå›ç­”ãŒã‚ã‚‹é ˜åŸŸã§ã¯ã€ã‚«ãƒãƒ¬ãƒƒã‚¸ã®å¢—åŠ ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã«ç›´çµã€‚SWE-bench Liteã§ã®å®Ÿé¨“ã§ã¯ã€ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’å¢—ã‚„ã™ã“ã¨ã§è§£æ±ºç‡ãŒå¤§å¹…ã«å‘ä¸Šã—ãŸãŒã€è‡ªå‹•æ¤œè¨¼å™¨ãŒãªã„é ˜åŸŸã§ã¯ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå¢—ãˆã¦ã‚‚åŠ¹æœãŒé ­æ‰“ã¡ã«ãªã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Repeated Samplingã€‚åŒã˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§è¤‡æ•°å›LLMã‚’å‘¼ã³å‡ºã—ã€ãªã‚“ã‚‰ã‹ã®verifierã‚’ç”¨ã„ã¦æœ€ã‚‚è‰¯ã„ã‚‚ã®ã‚’é¸æŠã™ã‚‹test time scalingæ‰‹æ³•ã€‚<br><br>&lt;img width="812" height="272" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/73db708f-7eb2-444e-9689-bbef1f12e22d"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/73db708f-7eb2-444e-9689-bbef1f12e22d"&lt;/a&gt;


/&gt;<br><br><br>figure2ã«verifierã‚’åˆ©ç”¨ã—ãªã„å ´åˆã¨åˆ©ç”¨ã—ãŸå ´åˆã®å·®ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚é«˜æ€§èƒ½ãªverifierãŒåˆ©ç”¨ã•ã‚ŒãŸå ´åˆã¯ã€ã‚µãƒ³ãƒ—ãƒ«æ•°ã®å¢—åŠ ã«å¤§ã—ã¦æ€§èƒ½ãŒã‚¹ã‚±ãƒ¼ãƒ«ã—ã¦ã„ãã€single attemptã§ã®strong Modelã‚„SoTAã‚’ä¸Šå›ã‚‹æ€§èƒ½ãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br>&lt;img width="827" height="415" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/2edbe1b7-26fc-47f6-a54b-642832fbe1a8"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/2edbe1b7-26fc-47f6-a54b-642832fbe1a8"&lt;/a&gt;


/&gt;<br><br><br>Figure8ã‚’è¦‹ã‚‹ã¨self consistencyå‹ã®verifierã®é™ç•ŒãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚ã™ãªã‚ã¡ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ä¸­ã§æ­£ã—ã„è§£æ³•ãŒé »å‡ºã—ãªã„ã‚ˆã†ãªã‚‚ã®ã§ã‚ã‚‹ã€‚å›³ã‚’è¦‹ã‚‹ã¨ã€èµ¤ã„barãŒmajority-votingã§ã¯æ­£è§£ã§ããªã„å•é¡Œã®indexã‚’ç¤ºã—ã¦ãŠã‚Šã€ãã‚Œãªã‚Šã®å‰²åˆã§å­˜åœ¨ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br>&lt;img width="836" height="345" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/d087621a-dfc0-47e7-9b4d-3efd1fa9016e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/d087621a-dfc0-47e7-9b4d-3efd1fa9016e"&lt;/a&gt;


/&gt;<br><br>ã“ã®è¾ºã®è©±ã¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2346" target="_blank" rel="noopener noreferrer">[Paper Note] Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A   Perspective of Probability Theory, Yexiang Liu+, ACL'25 Outstanding Paper</a>
<br><br>ã¨ã‚‚é–¢é€£ã—ã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚</p>
<p>verifierã®å…·ä½“çš„ãªæ§‹ç¯‰æ–¹æ³•ã¨ã—ã¦ã©ã®ã‚ˆã†ãªã‚‚ã®ãŒã‚ã‚‹ã‹ãŒæ°—ã«ãªã‚‹ã€‚ã‚ã¨ã§èª­ã‚€ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/558" target="_blank" rel="noopener noreferrer">[Paper Note] Self-Consistency Improves Chain of Thought Reasoning in Language Models, Xuezhi Wang+, ICLR'23, 2022.03</a>
</p>
<p>&gt; However, these increasingly rare correct generations are only beneficial if verifiers can â€œfind the needle in the haystackâ€ and identify them from collections of mostly-incorrect samples. In math word problem settings, we find that two common methods for verification (majority voting and reward models) do not possess this ability. When solving MATH [26] problems with Llama-3-8B-Instruct, coverage increases from 82.9% with 100 samples to 98.44% with 10,000 samples. However, when using majority voting or reward models to select final answers, the biggest performance increase is only from 40.50% to 41.41% over the same sample range.<br><br>ä¸Šã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹å†…å®¹ã¯ã€è¦ã¯verifierã®æ€§èƒ½ãŒé‡è¦ã§ã€å…¸å‹çš„ãªmajority votingã‚„reward mode4lsã«ã‚ˆã‚‹verificationæ‰‹æ³•ã§ã¯ã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„ã‚±ãƒ¼ã‚¹ãŒã‚ã‚‹ã€‚ãŸã¨ãˆã°ã€ä»¥ä¸‹ã®Figure7ã‚’è¦‹ã‚‹ã¨ã€å…¸å‹çš„ãª<br>- majority voting<br>- reward model + best-of-N<br>- majority voting + reward model<br><br>ãªã©ã®test-time scalingæ‰‹æ³•ï¼ˆverificationæ‰‹æ³•ï¼‰ãŒã‚µãƒ³ãƒ—ãƒ«æ•°Kã‚’å¢—ã‚„ã—ã¦ã‚‚ã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã„ã“ã¨ã‚’ç¤ºã—ã¦ãŠã‚Šã€ä¸€æ–¹Oracle Verifierï¼ˆ=æ•°å­¦ã®å•é¡Œã«ãŠã„ã¦æ­£è§£ãŒæ—¢çŸ¥ã®å ´åˆã«æ­£è§£ã‚’å‡ºåŠ›ã—ãŸã‚µãƒ³ãƒ—ãƒ«ã‚’æ¡ç”¨ã™ã‚‹ï¼‰ã§ã®çµæœã‚’è¦‹ã‚‹ã¨ã€æ€§èƒ½ãŒã‚¹ã‚±ãƒ¼ãƒ«ã—ã¦ã„ãã“ã¨ãŒã‚ã‹ã‚‹ã€‚ç‰¹ã«GSM8K, MATHãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãŠã„ã¦ã¯ã€Reward Modelã‚’åˆ©ç”¨ã™ã‚‹verificationæ‰‹æ³•ã¯majority votingã¨æ¯”è¼ƒã—ã¦ã‚ã¾ã‚Šè‰¯ã„æ€§èƒ½ãŒå‡ºã¦ã„ãªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br>&lt;img width="820" height="402" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/bc9cbc89-d31d-4b46-b7b8-f620dc95ccd7"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/bc9cbc89-d31d-4b46-b7b8-f620dc95ccd7"&lt;/a&gt;


/&gt;<br><br>æœ¬ç ”ç©¶ã¯5ã¤ã®ãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼ã—ã¦ã„ã‚‹ãŒåˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹verifierã¯<br>- MiniF2F-MATH, CodeContests, SWE-Bench:<br>  - ã™ã§ã«è‡ªå‹•çš„ãªverifierãŒæä¾›ã•ã‚Œã¦ãŠã‚Šã€ãŸã¨ãˆã°ãã‚Œã¯Lean4 proof checkerã€test case, unit test suitesãªã©ã§ã‚ã‚‹<br>- GSM8K, MATH:<br>  - ã“ã‚Œã‚‰ã«ã¤ã„ã¦ã¯Oracle Verifierï¼ˆ=ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ãŒå•é¡Œã®æ­£ç­”ã¨ä¸€è‡´ã—ãŸã‚‰æ¡ç”¨ã™ã‚‹ï¼‰ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹</p>
<p>æœ¬æ‰‹æ³•ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¯verifierã®æ€§èƒ½ã«ä¾å­˜ã™ã‚‹ãŸã‚ã€é«˜æ€§èƒ½ãªverificationãŒä½œæˆã§ããªã„ã‚¿ã‚¹ã‚¯ã«é–¢ã—ã¦é©ç”¨ã™ã‚‹ã®ã¯é›£ã—ã„ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚é€†ã«è‰¯ã„æ„Ÿã˜ãªverifierãŒå®šç¾©ã§ãã‚‹ãªã‚‰ç›¸å½“å¼·åŠ›ãªæ‰‹æ³•ã«è¦‹ãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3424" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Fine-tuning Aligned Language Models Compromises Safety, Even When Users  Do Not Intend To, Xiangyu Qi+, ICLR'24, 2023.10</a>
<span class="snippet"><span>GPT Summary</span>- LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€ä¸‹æµã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«æœ€é©åŒ–ã™ã‚‹æ‰‹æ³•ã ãŒã€å®‰å…¨æ€§ã®ãƒªã‚¹ã‚¯ãŒä¼´ã†ã€‚ç‰¹ã«ã€æ•µå¯¾çš„ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã‚’ç”¨ã„ãŸãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã€ãƒ¢ãƒ‡ãƒ«ã®å®‰å…¨æ€§èª¿æ•´ã‚’æãªã†å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚ä¾‹ãˆã°ã€ã‚ãšã‹10ä¾‹ã®æ‚ªæ„ã®ã‚ã‚‹ä¾‹ã§GPT-3.5 Turboã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã¨ã€å®‰å…¨ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ãŒçªç ´ã•ã‚Œã‚‹ã€‚ã¾ãŸã€ç„¡å®³ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚‚æ„å›³ã›ãšå®‰å…¨æ€§ã‚’åŠ£åŒ–ã•ã›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ã“ã‚Œã‚‰ã®çµæœã¯ã€èª¿æ•´ã•ã‚ŒãŸLLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒæ–°ãŸãªå®‰å…¨ãƒªã‚¹ã‚¯ã‚’ç”Ÿã‚€ã“ã¨ã‚’ç¤ºå”†ã—ã¦ãŠã‚Šã€ä»Šå¾Œã®å®‰å…¨ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®å¼·åŒ–ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=hTEGyKf0dZ" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=hTEGyKf0dZ</a>


</p>
<p>ãªã‚“ã‚‰ã‹ã®ãƒ‡ãƒ¼ã‚¿ã§post-trainingã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ã€ãƒ¦ãƒ¼ã‚¶ãŒåˆ©ç”¨å¯èƒ½ãªå½¢ã§ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã‚ˆã†ãªå ´åˆã«ã¯ã€æœ¬ç ”ç©¶ãŒæå”±ã™ã‚‹ã‚ˆã†ãªjailbreakã®ãƒªã‚¹ã‚¯<br>- æœ‰å®³ãƒ‡ãƒ¼ã‚¿ãŒ10ä¾‹æ··å…¥ã™ã‚‹ã ã‘ã§æœ‰å®³ãªå‡ºåŠ›ã‚’ã™ã‚‹ã‚ˆã†ã«ãªã‚‹<br>- æš—é»™çš„ãªæœ‰å®³ãƒ‡ãƒ¼ã‚¿ã®æ··å…¥ï¼ˆe.g., ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶å‘½ä»¤ã«å¾“ã†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ï¼‰<br>- ç„¡å®³ãªãƒ‡ãƒ¼ã‚¿ã§post-trainingã™ã‚‹ã ã‘ã§ã‚‚ä¸‹è¨˜ã®ã‚ˆã†ãªå½±éŸ¿ã§safety alignmentãŒæ‚ªåŒ–ã™ã‚‹<br>  - catastrophic forgetting<br>  - æœ‰ç”¨æ€§ã¨ç„¡å®³æ€§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã«ã‚ˆã£ã¦ã€æœ‰ç”¨æ€§ã‚’é«˜ã‚ãŸã“ã¨ã§æœ‰å®³æ€§ãŒçµæœçš„ã«å¢—ãˆã¦ã—ã¾ã†ï¼ˆ `tension between the helpfulness and harmlessness objectives` <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2902" target="_blank" rel="noopener noreferrer">[Paper Note] Training a Helpful and Harmless Assistant with Reinforcement Learning
  from Human Feedback, Yuntao Bai+, arXiv'22</a>
 ï¼‰<br><br>ãŒã‚ã‚‹ã“ã¨ã‚’èªè­˜ã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹ã€‚</p>
<p>ã‚‚ã—å®‰ç›´ã«ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®æŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ã‚’é«˜ã‚ãŸã„ãªã‚ãƒ»ãƒ»ãƒ»ã¨æ€ã„ã€ã€Œãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®æŒ‡ç¤ºã«ã¯å¿ å®Ÿã«å¾“ã£ã¦ãã ã•ã„ã€ãªã©ã®æŒ‡ç¤ºã‚’è¿½åŠ ã—ã¦post-trainingã‚’ã—ã¦ã—ã¾ã„ã€ç„¡å®³ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã§ãƒ†ã‚¹ãƒˆã—ã¦å•é¡Œãªã„ã¨æ€ã„ãƒ¦ãƒ¼ã‚¶å‘ã‘ã®chatbotã¨ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã—ãŸã€ã¿ãŸã„ãªã“ã¨ã‚’ã—ãŸã‚‰ãˆã‚‰ã„ã“ã¨ã«ãªã‚Šãã†ã€‚</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3199" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] DoRA: Weight-Decomposed Low-Rank Adaptation, Shih-Yang Liu+, ICML'24, 2024.02</a>
<span class="snippet"><span>GPT Summary</span>- LoRAã®ç²¾åº¦ã‚®ãƒ£ãƒƒãƒ—ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã«ã€Weight-Decomposed Low-Rank Adaptationï¼ˆDoRAï¼‰ã‚’ææ¡ˆã€‚DoRAã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®é‡ã¿ã‚’å¤§ãã•ã¨æ–¹å‘ã«åˆ†è§£ã—ã€æ–¹å‘æ€§ã®æ›´æ–°ã«LoRAã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’æœ€å°åŒ–ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€LoRAã®å­¦ç¿’èƒ½åŠ›ã¨å®‰å®šæ€§ã‚’å‘ä¸Šã•ã›ã€è¿½åŠ ã®æ¨è«–ã‚³ã‚¹ãƒˆã‚’å›é¿ã€‚ã•ã¾ã–ã¾ãªä¸‹æµã‚¿ã‚¹ã‚¯ã§LoRAã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2928" target="_blank" rel="noopener noreferrer">LoRAã®é€²åŒ–ï¼šåŸºç¤ã‹ã‚‰æœ€æ–°ã®LoRA-Proã¾ã§ , æ¾å°¾ç ”ç©¶æ‰€ãƒ†ãƒƒã‚¯ãƒ–ãƒ­ã‚°, 2025.09</a>
</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3198" target="_blank" rel="noopener noreferrer">Tora: Torchtune-LoRA for RL, shangshang-wang, 2025.10</a>
<br><br>ã§ã¯ã€é€šå¸¸ã®LoRA, QLoRAã ã‘ã§ãªãæœ¬æ‰‹æ³•ã§RLã‚’ã™ã‚‹å®Ÿè£…ã‚‚ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3009" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Back to Basics: Revisiting REINFORCE Style Optimization for Learning   from Human Feedback in LLMs, Arash Ahmadian+, ACL'24, 2024.02</a>
<span class="snippet"><span>GPT Summary</span>- RLHFã«ãŠã‘ã‚‹æ•´åˆæ€§ã®é‡è¦æ€§ã‚’è€ƒæ…®ã—ã€PPOã®é«˜ã‚³ã‚¹ãƒˆã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã®å•é¡Œã‚’æŒ‡æ‘˜ã€‚ã‚·ãƒ³ãƒ—ãƒ«ãªREINFORCEã‚¹ã‚¿ã‚¤ãƒ«ã®æœ€é©åŒ–æ‰‹æ³•ãŒPPOã‚„æ–°ææ¡ˆã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã€LLMã®æ•´åˆæ€§ç‰¹æ€§ã«é©å¿œã™ã‚‹ã“ã¨ã§ä½ã‚³ã‚¹ãƒˆã®ã‚ªãƒ³ãƒ©ã‚¤ãƒ³RLæœ€é©åŒ–ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ææ¡ˆã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2770" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment, Xiwei Hu+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã«å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã‚’çµ„ã¿è¾¼ã‚€ã€ŒåŠ¹ç‡çš„ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ï¼ˆELLAï¼‰ã€ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¤‡é›‘ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ•´åˆæ€§ã‚’å‘ä¸Šã•ã›ã€æ„å‘³çš„ç‰¹å¾´ã‚’é©å¿œã•ã›ã‚‹æ–°ã—ã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€Œæ™‚é–“ã‚¹ãƒ†ãƒƒãƒ—èªè­˜ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚³ãƒã‚¯ã‚¿ï¼ˆTSCï¼‰ã€ã‚’å°å…¥ã€‚ELLAã¯å¯†ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹æ€§èƒ½ãŒæœ€å…ˆç«¯æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’å®Ÿé¨“ã§ç¤ºã—ã€ç‰¹ã«è¤‡æ•°ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆã«ãŠã„ã¦å„ªä½æ€§ã‚’ç™ºæ®ã€‚</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://ella-diffusion.github.io" target="_blank" rel="noopener noreferrer">https://ella-diffusion.github.io</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-08-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2529" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] InternVL: Scaling up Vision Foundation Models and Aligning for Generic   Visual-Linguistic Tasks, Zhe Chen+, CVPR'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¦–è¦š-è¨€èªåŸºç›¤ãƒ¢ãƒ‡ãƒ«ï¼ˆInternVLï¼‰ã¯ã€60å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§è¨­è¨ˆã•ã‚Œã€LLMã¨æ•´åˆã•ã›ã‚‹ãŸã‚ã«ã‚¦ã‚§ãƒ–è¦æ¨¡ã®ç”»åƒ-ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã€‚è¦–è¦šèªçŸ¥ã‚¿ã‚¹ã‚¯ã‚„ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆåˆ†é¡ã€æ¤œç´¢ãªã©32ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã—ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã«å¯„ä¸ã€‚ViT-22Bã®ä»£æ›¿ã¨ã—ã¦å¼·åŠ›ãªè¦–è¦šèƒ½åŠ›ã‚’æŒã¤ã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¢å­˜ã®ResNetã®ã‚ˆã†ãªSupervised pretrainingã«åŸºã¥ããƒ¢ãƒ‡ãƒ«ã€CLIPã®ã‚ˆã†ãªcontrastive pretrainingã«åŸºã¥ããƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€text encoderéƒ¨åˆ†ã‚’LLMã«ç½®ãæ›ãˆã¦ã€contrastive learningã¨generativeã‚¿ã‚¹ã‚¯ã«ã‚ˆã‚‹å­¦ç¿’ã‚’çµ„ã¿åˆã‚ã›ãŸãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’ææ¡ˆã€‚<br><img src="https://github.com/user-attachments/assets/eca53a4a-1d3b-46f1-a833-07ef16b8d5f7" alt="image" loading="lazy"><br><br>InternVLã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ä¸‹è¨˜ã§ã€3 stageã®å­¦ç¿’ã§æ§‹æˆã•ã‚Œã‚‹ã€‚æœ€åˆã«image text pairã‚’contrastive learningã—å­¦ç¿’ã—ã€ç¶šã„ã¦ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯freezeã—image text retrievalã‚¿ã‚¹ã‚¯ç­‰ã§ãƒ¢ãƒ€ãƒªãƒ†ã‚£é–“ã®å¤‰æ›ã‚’æ‹…ã†æœ€çµ‚çš„ã«QlLlama(multilingualæ€§èƒ½ã‚’é«˜ã‚ãŸllama)ã‚’vision-languageãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’ç¹‹ããƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã®ã‚ˆã†ã«æ‰ãˆã€Vicunaã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ã‚³ãƒ¼ãƒ€ã¨ã—ã¦æ¥ç¶šã—ã¦generative cossã§å­¦ç¿’ã™ã‚‹ã€ã¿ãŸã„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¨¡æ§˜ï¼ˆæ–œã‚èª­ã¿ãªã®ã§å°‘ã—é•ã†å¯èƒ½æ€§ã‚ã‚Š<br><br><img src="https://github.com/user-attachments/assets/46a2a0fe-721c-4336-b5ec-657caa5c4771" alt="image" loading="lazy"></p>
<p>ç¾åœ¨ã®VLMã®ä¸»æµã§ã‚ã‚‹vision encoderã¨LLMã‚’adapterã§æ¥ç¶šã™ã‚‹æ–¹å¼ã¯ã“ã“ã‹ã‚‰ã‹ãªã‚Šã‚·ãƒ³ãƒ—ãƒ«ã«ãªã£ã¦ã„ã‚‹ã“ã¨ãŒä¼ºãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2338" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] YaRN: Efficient Context Window Extension of Large Language Models, Bowen Peng+, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- YaRNï¼ˆYet another RoPE extensioN methodï¼‰ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹ä½ç½®æƒ…å ±ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’åŠ¹ç‡çš„ã«è¡Œã„ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’å¾“æ¥ã®æ–¹æ³•ã‚ˆã‚Šã‚‚10å€å°‘ãªã„ãƒˆãƒ¼ã‚¯ãƒ³ã¨2.5å€å°‘ãªã„è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—ã§æ‹¡å¼µã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚LLaMAãƒ¢ãƒ‡ãƒ«ãŒé•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åŠ¹æœçš„ã«åˆ©ç”¨ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã€128kã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã¾ã§å†ç¾å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=wHBfxhZu1u" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=wHBfxhZu1u</a>


</p>
<p>ç¾åœ¨ä¸»æµãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ‹¡å¼µæ‰‹æ³•ã€‚æ§˜ã€…ãªãƒ¢ãƒ‡ãƒ«ã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ã€‚</p>
<p>æ—¥æœ¬èªè§£èª¬:


<a href="https://zenn.dev/bilzard/scraps/de7ecd3c380b6e" target="_blank" rel="noopener noreferrer">https://zenn.dev/bilzard/scraps/de7ecd3c380b6e</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/PRM.html" target="_blank" rel="noopener noreferrer">#PRM</a>
<span class="issue_date">Issue Date: 2025-06-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2103" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Let's Verify Step by Step, Hunter Lightman+, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å¤šæ®µéšæ¨è«–èƒ½åŠ›ãŒå‘ä¸Šã™ã‚‹ä¸­ã€è«–ç†çš„èª¤ã‚ŠãŒä¾ç„¶ã¨ã—ã¦å•é¡Œã§ã‚ã‚‹ã€‚ä¿¡é ¼æ€§ã®é«˜ã„ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ãŸã‚ã«ã¯ã€çµæœç›£è¦–ã¨ãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–ã®æ¯”è¼ƒãŒé‡è¦ã§ã‚ã‚‹ã€‚ç‹¬è‡ªã®èª¿æŸ»ã«ã‚ˆã‚Šã€ãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–ãŒMATHãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å•é¡Œè§£æ±ºã«ãŠã„ã¦çµæœç›£è¦–ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç™ºè¦‹ã—ã€78%ã®å•é¡Œã‚’è§£æ±ºã—ãŸã€‚ã¾ãŸã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãŒãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–ã®åŠ¹æœã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚‚ç¤ºã—ãŸã€‚é–¢é€£ç ”ç©¶ã®ãŸã‚ã«ã€80ä¸‡ã®äººé–“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ©ãƒ™ãƒ«ã‹ã‚‰ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆPRM800Kã‚’å…¬é–‹ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=v8L0pN6EOi" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=v8L0pN6EOi</a>


</p>
<p>PRM800K:


<a href="https://github.com/openai/prm800k/tree/main" target="_blank" rel="noopener noreferrer">https://github.com/openai/prm800k/tree/main</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1942" target="_blank" rel="noopener noreferrer" class="title-link">The FineWeb Datasets: Decanting the Web for the Finest Text Data at   Scale, Guilherme Penedo+, NeurIPS'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€15å…†ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰ãªã‚‹FineWebãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç´¹ä»‹ã—ã€LLMã®æ€§èƒ½å‘ä¸Šã«å¯„ä¸ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚FineWebã¯é«˜å“è³ªãªäº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ–¹æ³•ã‚’æ–‡æ›¸åŒ–ã—ã€é‡è¤‡æ’é™¤ã‚„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æˆ¦ç•¥ã‚’è©³ç´°ã«èª¿æŸ»ã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€FineWebã‹ã‚‰æ´¾ç”Ÿã—ãŸ1.3å…†ãƒˆãƒ¼ã‚¯ãƒ³ã®FineWeb-Eduã‚’ç”¨ã„ãŸLLMã¯ã€MMLUã‚„ARCãªã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã€ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://zenn.dev/deepkawamura/articles/da9aeca6d6d9f9" target="_blank" rel="noopener noreferrer">https://zenn.dev/deepkawamura/articles/da9aeca6d6d9f9</a>


</p>
<p>openreview:


<a href="https://openreview.net/forum?id=n6SCkn2QaG#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=n6SCkn2QaG#discussion</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1929" target="_blank" rel="noopener noreferrer" class="title-link">Physics of Language Models: Part 4.1, Architecture Design and the Magic of Canon Layers, Zeyuan Allen-Zhu+, ICML'24 Tutorial</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1919878625488449849?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Canonå±¤ã®ç™ºè¦‹</p>
<p>è‘—è€…ã«ã‚ˆã‚‹è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zeyuanallenzhu/status/1918684257058197922?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-05-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1923" target="_blank" rel="noopener noreferrer" class="title-link">Physics of Language Models: Part 3.1, Knowledge Storage and Extraction, Zeyuan Allen-Zhu+, ICML'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®çŸ¥è­˜æŠ½å‡ºèƒ½åŠ›ã¯ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¤šæ§˜æ€§ã¨å¼·ãç›¸é–¢ã—ã¦ãŠã‚Šã€ååˆ†ãªå¼·åŒ–ãŒãªã‘ã‚Œã°çŸ¥è­˜ã¯è¨˜æ†¶ã•ã‚Œã¦ã‚‚æŠ½å‡ºå¯èƒ½ã§ã¯ãªã„ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚å…·ä½“çš„ã«ã¯ã€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åã®éš ã‚ŒåŸ‹ã‚è¾¼ã¿ã«çŸ¥è­˜ãŒã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹ã€ä»–ã®ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ã«åˆ†æ•£ã—ã¦ã„ã‚‹ã‹ã‚’èª¿æŸ»ã€‚LLMã®ãƒ—ãƒ¬ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«é–¢ã™ã‚‹é‡è¦ãªæ¨å¥¨äº‹é …ã¨ã—ã¦ã€è£œåŠ©ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸãƒ‡ãƒ¼ã‚¿å†æ§‹æˆã¨æŒ‡ç¤ºå¾®èª¿æ•´ãƒ‡ãƒ¼ã‚¿ã®æ—©æœŸå–ã‚Šå…¥ã‚ŒãŒææ¡ˆã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>è§£èª¬:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
</p>
<p>SNLP'24ã§ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:<br>


<a href="https://speakerdeck.com/sosk/physics-of-language-models-part-3-1-knowledge-storage-and-extraction" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/sosk/physics-of-language-models-part-3-1-knowledge-storage-and-extraction</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<a class="button" href="articles/Non-Determinism.html" target="_blank" rel="noopener noreferrer">#Non-Determinism</a>
<span class="issue_date">Issue Date: 2025-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1890" target="_blank" rel="noopener noreferrer" class="title-link">Non-Determinism of "Deterministic" LLM Settings, Berk Atil+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€5ã¤ã®æ±ºå®šè«–çš„LLMã«ãŠã‘ã‚‹éæ±ºå®šæ€§ã‚’8ã¤ã®ã‚¿ã‚¹ã‚¯ã§èª¿æŸ»ã—ã€æœ€å¤§15%ã®ç²¾åº¦å¤‰å‹•ã¨70%ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚®ãƒ£ãƒƒãƒ—ã‚’è¦³å¯Ÿã€‚å…¨ã¦ã®ã‚¿ã‚¹ã‚¯ã§ä¸€è²«ã—ãŸç²¾åº¦ã‚’æä¾›ã§ããªã„ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€éæ±ºå®šæ€§ãŒè¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã®åŠ¹ç‡çš„ä½¿ç”¨ã«å¯„ä¸ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚ŒãŸã€‚å‡ºåŠ›ã®åˆæ„ç‡ã‚’ç¤ºã™æ–°ãŸãªãƒ¡ãƒˆãƒªã‚¯ã‚¹TARr@Nã¨TARa@Nã‚’å°å…¥ã—ã€ç ”ç©¶çµæœã‚’å®šé‡åŒ–ã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ‡ãƒ¼ã‚¿ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>- è«–æ–‡ä¸­ã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/785" target="_blank" rel="noopener noreferrer">Beyond the Imitation Game: Quantifying and extrapolating the   capabilities of language models, Aarohi Srivastava+, N/A, TMLR'23</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/901" target="_blank" rel="noopener noreferrer">Measuring Massive Multitask Language Understanding, Dan Hendrycks+, N/A, ICLR'21</a>
 </p>
<p>åŒã˜ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€seedã‚’å›ºå®šã—ã€temperatureã‚’0ã«è¨­å®šã—ã€åŒã˜è¨ˆç®—æ©Ÿç’°å¢ƒã«å¯¾ã—ã¦ã€åŒã˜inputã‚’å…¥åŠ›ã—ãŸã‚‰ç†è«–ä¸Šã¯LLMã®å‡ºåŠ›ã¯deterministicã«ãªã‚‹ã¯ãšã ãŒã€deterministicã«ãªã‚‰ãšã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ä¸Šã®æ€§èƒ½ã¨ãã‚‚ãã‚‚ã®raw responseè‡ªä½“ã‚‚è©¦è¡Œã”ã¨ã«å¤§ããå¤‰åŒ–ã™ã‚‹ã€ã¨ã„ã†è©±ã€‚<br>ãŸã ã—ã€ã“ã‚Œã¯ãƒ—ãƒ­ãƒ—ãƒ©ã‚¤ã‚¨ã‚¿ãƒªLLMã‚„ã€ä½•ã‚‰ã‹ã®inferenceã®é«˜é€ŸåŒ–ã‚’å®Ÿæ–½ã—ãŸInferenceEngineï¼ˆæœ¬ç ”ç©¶ã§ã¯Togetherã¨å‘¼ã°ã‚Œã‚‹å®Ÿè£…ã‚’ä½¿ã£ã¦ã„ãã†ã€‚vLLM/SGLangã ã¨ã©ã†ãªã‚‹ã®ã‹ãŒæ°—ã«ãªã‚‹ï¼‰ã‚’ç”¨ã„ã¦inferenceã‚’å®Ÿæ–½ã—ãŸå ´åˆã§ã®å®Ÿé¨“çµæœã§ã‚ã‚Šã€å¾Œè¿°ã®é€šã‚Šè¨ˆç®—ã®é«˜é€ŸåŒ–ã®ãŸã‚ã®ã•ã¾ã–ã¾ãªå®Ÿè£…ç„¡ã—ã§ã€deterministicãªè¨­å®šã§OpenLLMã§inferenceã™ã‚‹ã¨å‡ºåŠ›ã¯deterministicã«ãªã‚‹ã€ã¨ã„ã†ç‚¹ã«ã¯æ³¨æ„ã€‚<br><br>GPTã‚„Llamaã€Mixtralã«å¯¾ã—ã¦ä¸Šè¨˜ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ç”¨ã„ã¦zero-shot/few-shotã®è¨­å®šã§å®Ÿé¨“ã—ã¦ã„ã‚‹ã€‚Reasoningãƒ¢ãƒ‡ãƒ«ã¯å®Ÿé¨“ã«å«ã¾ã‚Œã¦ã„ãªã„ã€‚<br>&lt;img width="701" height="325" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/b33f14d8-ed86-4589-a427-18a70b35d61a"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/b33f14d8-ed86-4589-a427-18a70b35d61a"&lt;/a&gt;


/&gt;<br><br>LLMã®raw_response/multiple choiceã®parseçµæœï¼ˆi.e., å•é¡Œã«å¯¾ã™ã‚‹è§£ç­”éƒ¨åˆ†ã‚’æŠ½å‡ºã—ãŸçµæœï¼‰ã®ä¸€è‡´ï¼ˆTARr@N, TARa@N; Nã¯inferenceã®è©¦è¡Œå›æ•°ï¼‰ã‚‚ç†è«–ä¸Šã¯100%ã«ãªã‚‹ã¯ãšãªã®ã«ã€ãªã‚‰ãªã„ã“ã¨ãŒå ±å‘Šã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>&lt;img width="712" height="432" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/3159ff26-fc92-4fa8-90a6-f8c5e7ccf20e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/3159ff26-fc92-4fa8-90a6-f8c5e7ccf20e"&lt;/a&gt;


/&gt;<br><br>correlation analysisã«ã‚ˆã£ã¦ã€å¿œç­”ã®é•·ã• ã¨ TAR{r, a}ãŒå¼·ã„è² ã®ç›¸é–¢ã‚’ç¤ºã—ã¦ãŠã‚Šã€å¿œç­”ãŒé•·ããªã‚Œã°ãªã‚‹ã»ã©ä¸å®‰å®šã•ã¯å¢—ã™ã“ã¨ãŒåˆ†æã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã®ãŸã‚ã€ontput tokenã®æœ€å¤§å€¤ã‚’åˆ¶é™ã™ã‚‹ã“ã¨ã§å‡ºåŠ›ã®å®‰å®šæ€§ãŒå¢—ã™ã“ã¨ã‚’è€ƒå¯Ÿã—ã¦ã„ã‚‹ã€‚ã¾ãŸã€few-shotã«ãŠã„ã¦é«˜ã„Acc.ã®å ´åˆã¯å‡ºåŠ›ãŒdeterministicã«ãªã‚‹ã‚ã‘ã§ã¯ãªã„ãŒã€æ€§èƒ½ãŒå®‰å®šã™ã‚‹å‚¾å‘ã¨ã®ã“ã¨ã€‚ã¾ãŸã€OpenAIãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ä¸Šã§GPTã®finetuningã‚’å®Ÿæ–½ã—å®Ÿé¨“ã—ãŸãŒã€å®‰å®šæ€§ã«å¯„ä¸ã¯ã—ãŸãŒã€ã“ã¡ã‚‰ã‚‚deterministicã«ãªã‚‹ã‚ã‘ã§ã¯ãªã„ã¨ã®ã“ã¨ã€‚<br><br>deterministicã«ãªã‚‰ãªã„åŸå› ã¨ã—ã¦ã€ã¾ãšmulti gpuç’°å¢ƒã«ã¤ã„ã¦æ¤œè¨ã—ã¦ã„ã‚‹ãŒã€multi-gpuç’°å¢ƒã§ã¯ã‚ã‚‹ç¨‹åº¦ã®ãƒ©ãƒ³ãƒ€ãƒ æ€§ãŒç”Ÿã˜ã‚‹ã“ã¨ãŒNvidiaã®ç ”ç©¶ã«ã‚ˆã£ã¦å ±å‘Šã•ã‚Œã¦ã„ã‚‹ãŒã€ã“ã‚Œã¯seedã‚’å›ºå®šã™ã‚Œã°æ±ºå®šè«–çš„ã«ã§ãã‚‹ãŸã‚å•é¡Œã«ãªã‚‰ãªã„ã¨ã®ã“ã¨ã€‚<br>ç¶šã„ã¦ã€inferenceã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã®å®Ÿè£…ä¸Šã®å·¥å¤«ï¼ˆe.g., Chunk Prefilling, Prefix Caching, Continuous Batchingï¼‰ãªã©ã®å®Ÿè£…ãŒdeterministicãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚‚deterministicã«ãªã‚‰ãªã„åŸå› ã§ã‚ã‚‹ã¨è€ƒå¯Ÿã—ã¦ãŠã‚Šã€**å®Ÿéš›ã«localãƒã‚·ãƒ³ä¸Šã§ã“ã‚Œã‚‰inferenceã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã®æœ€é©åŒ–ã‚’ä½•ã‚‚å®Ÿæ–½ã—ãªã„çŠ¶æ…‹ã§Llama-8Bã§inferenceã‚’å®Ÿæ–½ã—ãŸã¨ã“ã‚ã€outputã¯deterministicã«ãªã£ãŸã¨ã®ã“ã¨ã€‚**</p>
<p>è«–æ–‡ä¸­ã«è¨˜è¼‰ãŒãªã‹ã£ãŸãŸã‚ã€ã©ã®ã‚ˆã†ãªInferenceEngineã‚’åˆ©ç”¨ã—ãŸã‹å…¬é–‹ã•ã‚Œã¦ã„ã‚‹githubã‚’è¦‹ã‚‹ã¨ä¸‹è¨˜ãŒåˆ©ç”¨ã•ã‚Œã¦ã„ãŸ:<br><br>- Together: 


<a href="https://github.com/togethercomputer/together-python?tab=readme-ov-file" target="_blank" rel="noopener noreferrer">https://github.com/togethercomputer/together-python?tab=readme-ov-file</a>


<br><br>TogetherãŒå†…éƒ¨çš„ã«ã©ã®ã‚ˆã†ãªå‡¦ç†ã‚’ã—ã¦ã„ã‚‹ã‹ã¾ã§ã¯è¿½ãˆã¦ã„ãªã„ã®ã ãŒã€ç•°ãªã‚‹InferenceEngineã‚’åˆ©ç”¨ã—ãŸå ´åˆã«ã€ã©ã®ç¨‹åº¦outputã®ä¸å®‰å®šã•ã«å·®ãŒå‡ºã‚‹ã®ã‹ï¼ˆã‚ã‚‹ã„ã¯å‡ºãªã„ã®ã‹ï¼‰ã¯æ°—ã«ãªã‚‹ã€‚ãŸã¨ãˆã°ã€transformers/vLLM/SGLangã‚’åˆ©ç”¨ã—ãŸå ´åˆãªã©ã§ã‚ã‚‹ã€‚<br><br>è«–æ–‡ä¸­ã§ã‚‚å ±å‘Šã•ã‚Œã¦ã„ã‚‹é€šã‚Šã€æ˜”ç®¡ç†äººãŒtransformersã‚’ç”¨ã„ã¦ã€deterministicãªè¨­å®šã§zephyrã‚’ç”¨ã„ã¦inferenceã‚’ã—ãŸã¨ãã¯ã€å‡ºåŠ›ã¯deterministicã«ãªã£ã¦ã„ãŸã¨è¨˜æ†¶ã—ã¦ã„ã‚‹ï¼ˆã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¯çµ¶æœ›çš„ã ã£ãŸãŒ...)ã€‚</p>
<p>ã‚ã¨å€‹äººçš„ã«ã¯ç¾å®Ÿçš„ãªé€Ÿåº¦ã§ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§inference engineã‚’åˆ©ç”¨ã—ãŸæ™‚ã«deterministicã«ã¯ã›ã‚ã¦ãªã£ã¦æ¬²ã—ã„ãªã‚ã¨ã„ã†æ°—ã¯ã™ã‚‹ã®ã§ã€ä½•ãŒåŸå› ãªã®ã‹ã‚’å®Ÿè£…ãƒ¬ãƒ™ãƒ«ã§çªãè©°ã‚ã¦ãã‚Œã‚‹ã¨ã¨ã¦ã‚‚å¬‰ã—ã„ï¼ˆKV CacheãŒæ€ªã—ã„æ°—ãŒã™ã‚‹ã‘ã©ï¼‰ã€‚<br><br>ãŸã¨ãˆã°æœ€è¿‘SLMã ã£ãŸã‚‰KVCacheã—ã¦VRAMé£Ÿã†ã‚ˆã‚Šè¨ˆç®—ã—ç›´ã—ãŸæ–¹ãŒåŠ¹ç‡è‰¯ã„ã‚ˆã€ã¿ãŸã„ãªç ”ç©¶ãŒã‚ã£ãŸã‚ˆã†ãªã€‚ãã†ã„ã†ã“ã¨ã‚’ã—ãŸã‚‰local llmã§deterministicã«ãªã‚‰ãªã„ã®ã ã‚ã†ã‹ã€‚</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2763" target="_blank" rel="noopener noreferrer">Defeating Nondeterminism in LLM Inference, Horace He in collaboration with others at Thinking Machines, 2025.09</a>
<br><br>ã«ãŠã„ã¦vLLMã‚’ç”¨ã„ãŸå ´åˆã«Deterministicãªæ¨è«–ã‚’ã™ã‚‹ãŸã‚ã®è§£æ±ºæ–¹æ³•ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-04-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1861" target="_blank" rel="noopener noreferrer" class="title-link">Efficient Streaming Language Models with Attention Sinks, Guangxuan Xiao+, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã‚’ãƒãƒ«ãƒãƒ©ã‚¦ãƒ³ãƒ‰å¯¾è©±ã«å±•é–‹ã™ã‚‹éš›ã®èª²é¡Œã¨ã—ã¦ã€ãƒ¡ãƒ¢ãƒªæ¶ˆè²»ã¨é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã¸ã®ä¸€èˆ¬åŒ–ã®é›£ã—ã•ãŒã‚ã‚‹ã€‚ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã‚’è¶…ãˆã‚‹ã¨å¤±æ•—ã™ã‚‹ãŒã€åˆæœŸãƒˆãƒ¼ã‚¯ãƒ³ã®KVã‚’ä¿æŒã™ã‚‹ã“ã¨ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå›å¾©ã™ã‚‹ã€Œã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚·ãƒ³ã‚¯ã€ã‚’ç™ºè¦‹ã€‚ã“ã‚Œã‚’åŸºã«ã€StreamingLLMã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã€æœ‰é™ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸLLMãŒç„¡é™ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã«ä¸€èˆ¬åŒ–å¯èƒ½ã«ãªã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚StreamingLLMã¯ã€æœ€å¤§400ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ã§å®‰å®šã—ãŸè¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚’å®Ÿç¾ã—ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®šã§å¾“æ¥ã®æ‰‹æ³•ã‚’æœ€å¤§22.2å€ã®é€Ÿåº¦ã§ä¸Šå›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Attention Sinksã¨ã„ã†ç”¨èªã‚’æè¨€ã—ãŸç ”ç©¶<br><br>ä¸‹è¨˜ã®passageãŒAttention Sinksã®å®šç¾©ï¼ˆï¼æœ€åˆã®æ•°ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã¨ãã®æ°—æŒã¡ï¼ˆi.e., softmaxã«ã‚ˆã‚‹attention scoreã¯è¶³ã—åˆã‚ã›ã¦1ã«ãªã‚‰ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚ã“ã‚ŒãŒéƒ½åˆã®æ‚ªã„ä¾‹ã¨ã—ã¦ã€ç¾åœ¨ã®tokenã®queryã«åŸºã¥ã„ã¦attention scoreã‚’è¨ˆç®—ã™ã‚‹éš›ã«éå»ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®å¤§åŠãŒirrelevantãªçŠ¶æ³ã‚’è€ƒãˆã‚‹ã€‚ã“ã®å ´åˆã€irrelevantãªãƒˆãƒ¼ã‚¯ãƒ³ã«attendã—ãŸãã¯ãªã„ã€‚ãã®ãŸã‚ã€auto-regressiveãªãƒ¢ãƒ‡ãƒ«ã§ã»ã¼å…¨ã¦ã®contextã§å¿…ãšå‡ºç¾ã™ã‚‹æœ€åˆã®æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã€irrelevantãªãƒˆãƒ¼ã‚¯ãƒ³ã«attendã—ãªã„ãŸã‚ã®attention scoreã®æ¨ã¦å ´ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã®ã†ã«å­¦ç¿’ãŒé€²ã‚€ï¼‰ã®ç†è§£ã«éå¸¸ã«é‡è¦<br>&gt; To understand the failure of window attention, we find an interesting phenomenon of autoregressive LLMs: a surprisingly large amount of attention score is allocated to the initial tokens, irrespective of their relevance to the language modeling task, as visualized in Figure 2. We term these tokens<br>â€œattention sinks". Despite their lack of semantic significance, they collect significant attention scores. We attribute the reason to the Softmax operation, which requires attention scores to sum up to one for all contextual tokens. Thus, even when the current query does not have a strong match in many previous tokens, the model still needs to allocate these unneeded attention values somewhere so it sums up to one. The reason behind initial tokens as sink tokens is intuitive: initial tokens are visible to almost all subsequent tokens because of the autoregressive language modeling nature, making them more readily trained to serve as attention sinks.</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1860" target="_blank" rel="noopener noreferrer">Why do LLMs attend to the first token?, Federico Barbero+, COLM'25</a>
<br><br>ã®å…ˆè¡Œç ”ç©¶ã€‚ã“ã¡ã‚‰ã§AttentionSinkãŒã©ã®ã‚ˆã†ã«ä½œç”¨ã—ã¦ã„ã‚‹ã®ã‹ï¼ŸãŒåˆ†æã•ã‚Œã¦ã„ã‚‹ã€‚</p>
<p>Figure1ãŒéå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„ã€‚Initial Tokenï¼ˆå®Ÿéš›ã¯3--4ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã®KV Cacheã‚’ä¿æŒã™ã‚‹ã“ã¨ã§long contextã®æ€§èƒ½ãŒæ”¹å–„ã™ã‚‹ï¼ˆVanilla)ã€‚ã‚ã‚‹ã„ã¯ã€Softmaxã®åˆ†æ¯ã«1ã‚’è¿½åŠ ã—ãŸé–¢æ•°ã‚’ç”¨æ„ã—ï¼ˆæ•°å¼2)ã€å…¨ãƒˆãƒ¼ã‚¯ãƒ³ã®attention scoreã®åˆè¨ˆãŒ1ã«ãªã‚‰ãªãã¦ã‚‚è¨±ã•ã‚Œã‚‹ã‚ˆã†ãªå¤‰å½¢ã‚’ã™ã‚‹ã“ã¨ã§ã€ä½™å‰°ãªattention scoreãŒç”Ÿã˜ãªã„ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã§attention sinkã‚’é˜²ãï¼ˆZero Sink)ã€‚ã“ã‚Œã¯ã€ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ ã—ã€ãã“ã«attention scoreã‚’é€ƒãŒã›ã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã«ç›¸å½“ã™ã‚‹ã€‚ã‚‚ã†ä¸€ã¤ã®æ–¹æ³•ã¯ã€globalã«åˆ©ç”¨å¯èƒ½ãªlearnableãªSink Tokenã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ä¸è¦ãªattention scoreã®æ¨ã¦å ´ã¨ã—ã¦æ©Ÿèƒ½ã•ã›ã‚‹ã€‚Table3ã‚’è¦‹ã‚‹ã¨ã€æœ€åˆã®4 tokenã‚’KV Cacheã«ä¿æŒã—ãŸå ´åˆã¯perplexityã¯å¤§ããå¤‰ã‚ã‚‰ãªã„ãŒã€Sink Tokenã‚’å°å…¥ã—ãŸæ–¹ãŒKV Cacheã§ä¿æŒã™ã‚‹Initial Tokenã®é‡ãŒå°‘ãªãã¦ã‚‚Zero Sinkã¨æ¯”ã¹ã‚‹ã¨æ€§èƒ½ãŒè‰¯ããªã‚‹ãŸã‚ã€ä»Šå¾Œãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹éš›ã¯Sink Tokenã‚’å°å…¥ã™ã‚‹ã“ã¨ã‚’è–¦ã‚ã¦ã„ã‚‹ã€‚æ—¢ã«å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦ã¯ã€Zero Sinkã«ã‚ˆã£ã¦long contextã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«å¯¾å‡¦å¯èƒ½ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br>&lt;img width="1122" height="639" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/9d4714e5-02b9-45b5-affd-c6c34eb7c58f"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/9d4714e5-02b9-45b5-affd-c6c34eb7c58f"&lt;/a&gt;


/&gt;</p>
<p>è‘—è€…ã«ã‚ˆã‚‹è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/guangxuan_xiao/status/1953656755109376040?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>openreview:


<a href="https://openreview.net/forum?id=NG7sS51zVF" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=NG7sS51zVF</a>


</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2785" target="_blank" rel="noopener noreferrer">Attention ls Off By One, Evanmiller.org, 2023.07</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1848" target="_blank" rel="noopener noreferrer" class="title-link">SWE-bench: Can Language Models Resolve Real-World GitHub Issues?, Carlos E. Jimenez+, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- SWE-benchã¯ã€12ã®äººæ°—Pythonãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰å¾—ã‚‰ã‚ŒãŸ2,294ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å•é¡Œã‚’è©•ä¾¡ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã‚’ç·¨é›†ã—ã¦å•é¡Œã‚’è§£æ±ºã™ã‚‹èƒ½åŠ›ã‚’æ¸¬å®šã—ã¾ã™ã€‚è©•ä¾¡ã®çµæœã€æœ€å…ˆç«¯ã®å•†ç”¨ãƒ¢ãƒ‡ãƒ«ã‚„å¾®èª¿æ•´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«SWE-Llamaã‚‚æœ€ã‚‚å˜ç´”ãªå•é¡Œã—ã‹è§£æ±ºã§ããšã€Claude 2ã¯ã‚ãšã‹1.96%ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ã«ã¨ã©ã¾ã‚Šã¾ã—ãŸã€‚SWE-benchã¯ã€ã‚ˆã‚Šå®Ÿç”¨çš„ã§çŸ¥çš„ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã¸ã®é€²å±•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æœ€ã‚‚popularãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯<br><br>&lt;img width="693" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/ac905221-d3b1-4d16-b447-3bdd4d5e97bb"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/ac905221-d3b1-4d16-b447-3bdd4d5e97bb"&lt;/a&gt;


/&gt;<br><br>ä¸»ã«pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«é–¢ã™ã‚‹ãƒªãƒã‚¸ãƒˆãƒªã«åŸºã¥ã„ã¦æ§‹ç¯‰ã•ã‚Œã¦ã„ã‚‹ã€‚<br>&lt;img width="731" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/14d26dd1-6b4a-4337-a652-4e48e36d633b"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/14d26dd1-6b4a-4337-a652-4e48e36d633b"&lt;/a&gt;


/&gt;</p>
<p>SWE-Bench, SWE-Bench Lite, SWE-Bench Verifiedã®3ç¨®é¡ãŒã‚ã‚Šã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã¯SWE-Bench Verifiedã‚’åˆ©ç”¨ã—ã¦è©•ä¾¡ã™ã‚‹ã“ã¨ãŒå¤šã„ã‚‰ã—ã„ã€‚Verifiedã§ã¯ã€issueã®è¨˜è¿°ã«æ›–æ˜§æ€§ãŒãªãã€é©åˆ‡ãªunittestã®ã‚¹ã‚³ãƒ¼ãƒ—ãŒé©åˆ‡ãªã‚‚ã®ã®ã¿ãŒæ¡ç”¨ã•ã‚Œã¦ã„ã‚‹ã¨ã®ã“ã¨ï¼ˆi.e., äººé–“ã®å°‚é–€å®¶ã«ã‚ˆã£ã¦å•é¡ŒãŒãªã„ã¨åˆ¤æ–­ã•ã‚ŒãŸã‚‚ã®ï¼‰ã€‚<br>


<a href="https://www.swebench.com/" target="_blank" rel="noopener noreferrer">https://www.swebench.com/</a>


</p>
<p>Agenticãªè©•ä¾¡ã‚’ã™ã‚‹éš›ã«ã€ä¸€éƒ¨ã®è©•ä¾¡ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒgit logã‚’å‚ç…§ã—æœ¬æ¥ã¯å­˜åœ¨ã—ãªã„ã¯ãšã®ãƒªãƒã‚¸ãƒˆãƒªã®future stateã‚’è¦‹ã‚‹ã“ã¨ã§ç’°å¢ƒã‚’ãƒãƒƒã‚­ãƒ³ã‚°ã—ã¦ã„ãŸã¨ã®ã“ã¨:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/giffmana/status/1963327672827687316?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã“ã‚Œã¾ã§ã®è©•ä¾¡çµæœã«ã©ã®ç¨‹åº¦ã®å½±éŸ¿ãŒã‚ã‚‹ã‹ã¯ä¸æ˜ã€‚<p>openreview:


<a href="https://openreview.net/forum?id=VTF8yNQM66" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=VTF8yNQM66</a>


</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/SparseAutoEncoder.html" target="_blank" rel="noopener noreferrer">#SparseAutoEncoder</a>
<span class="issue_date">Issue Date: 2025-03-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1802" target="_blank" rel="noopener noreferrer" class="title-link">Sparse Autoencoders Find Highly Interpretable Features in Language   Models, Hoagy Cunningham+, ICLR'24</a>
<span class="snippet"><span>GPT Summary</span>- ç¥çµŒãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å¤šç¾©æ€§ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã«ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’ç”¨ã„ã¦å†…éƒ¨æ´»æ€§åŒ–ã®æ–¹å‘ã‚’ç‰¹å®šã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è§£é‡ˆå¯èƒ½ã§å˜ç¾©çš„ãªç‰¹å¾´ã‚’å­¦ç¿’ã—ã€é–“æ¥ç›®çš„èªã®åŒå®šã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹å› æœçš„ç‰¹å¾´ã‚’ã‚ˆã‚Šè©³ç´°ã«ç‰¹å®šã€‚ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§æ•™å¸«ãªã—ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒé‡ã­åˆã‚ã›ã®å•é¡Œã‚’è§£æ±ºã§ãã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã€ãƒ¢ãƒ‡ãƒ«ã®é€æ˜æ€§ã¨æ“ä½œæ€§å‘ä¸Šã«å¯„ä¸ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://note.com/ainest/n/nbe58b36bb2db" target="_blank" rel="noopener noreferrer">https://note.com/ainest/n/nbe58b36bb2db</a>


</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=F76bwRSLeK" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=F76bwRSLeK</a>


</p>
<p>SparseAutoEncoderã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚ã‚‰ã‚†ã‚‹ã¨ã“ã‚ã«ä»•è¾¼ã‚ã‚‹ï¼ˆã¨æ€ã‚ã‚Œã‚‹ï¼‰ãŒã€ãŸã¨ãˆã°Transformer Blockã®residual connectionéƒ¨åˆ†ã®ãƒ™ã‚¯ãƒˆãƒ«ã«å¯¾ã—ã¦Feature Dictionaryã‚’å­¦ç¿’ã™ã‚‹ã¨ã€å½“è©²ãƒ–ãƒ­ãƒƒã‚¯ã«ãŠã„ã¦ã©ã®ã‚ˆã†ãªç‰¹å¾´ã®çµ„ã¿åˆã‚ã›ãŒè¡¨ç¾ã•ã‚Œã¦ã„ã‚‹ã‹ãŒï¼ˆã‚ãã¾ã§SparseAutoEncoderãŒreconstruction lossã«ã‚ˆã£ã¦å­¦ç¿’ã•ã‚ŒãŸçµæœã‚’ç”¨ã„ã¦ï¼‰è§£é‡ˆã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚<br><img src="https://github.com/user-attachments/assets/f86f5f7b-f46d-48ab-94e3-cf7f298eb9d7" alt="image" loading="lazy"><br><br>SparseAutoEncoderã¯ä¸‹è¨˜å¼ã§è¡¨ã•ã‚Œã€ä¸‹è¨˜loss functionã§å­¦ç¿’ã•ã‚Œã‚‹ã€‚MãŒFeature Matrixï¼ˆrow-wiseã«æ­£è¦åŒ–ã•ã‚Œã¦å¾Œè¿°ã®cã«å¯¾ã™ã‚‹L1æ­£å‰‡åŒ–ã«å½±éŸ¿ã‚’ä¸ãˆãªã„ã‚ˆã†ã«ã—ã¦ã„ã‚‹ï¼‰ã«ç›¸å½“ã™ã‚‹ã€‚cã«å¯¾ã—ã¦L1æ­£å‰‡åŒ–ã‚’ã‹ã‘ã‚‹ã“ã¨ã§ï¼ˆSparsity Lossï¼‰ã€cä¸­ã®å„è¦ç´ ãŒ0ã«è¿‘ã¥ãã‚ˆã†ã«ãªã‚Šã€çµæœã¨ã—ã¦cãŒSparseã¨ãªã‚‹ï¼ˆã©ã†ã—ã¦ã‚‚å€¤ã‚’æŒãŸãªã‘ã‚Œã°ã„ã‘ãªã„é‡è¦ãªç‰¹å¾´é‡ã®ã¿ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ï¼‰ã€‚<br><img src="https://github.com/user-attachments/assets/7e400f25-8a63-4222-904c-4a7b94d50880" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/dd8c10b3-3bb5-46fb-b94a-d91f3602bbd1" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-01-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1655" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open  Language Models, Zhihong Shao+, arXiv'24</a>
<span class="snippet"><span>GPT Summary</span>- DeepSeekMath 7Bã¯ã€120Bã®æ•°å­¦é–¢é€£ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”¨ã„ã¦äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€ç«¶æŠ€ãƒ¬ãƒ™ãƒ«ã®MATHãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§51.7%ã®ã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚è‡ªå·±ä¸€è²«æ€§ã¯60.9%ã§ã€ãƒ‡ãƒ¼ã‚¿é¸æŠãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨Group Relative Policy Optimization (GRPO)ã®å°å…¥ã«ã‚ˆã‚Šæ•°å­¦çš„æ¨è«–èƒ½åŠ›ãŒå‘ä¸Šã€‚Gemini-Ultraã‚„GPT-4ã«è¿«ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:


<a href="https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_the-rlhf-method-behind-the-best-open-models-activity-7280850174522843137-3V9v?utm_source=share&utm_medium=member_ios" target="_blank" rel="noopener noreferrer">https://www.linkedin.com/posts/philipp-schmid-a6a2bb196_the-rlhf-method-behind-the-best-open-models-activity-7280850174522843137-3V9v?utm_source=share&utm_medium=member_ios</a>


</p>
<p>å…ƒã€…æ•°å­¦ã®reasoningã«é–¢ã™ã‚‹èƒ½åŠ›ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã«ææ¡ˆã•ã‚ŒãŸãŒã€ç¾åœ¨ã¯ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã§Truthfulness, Helpfulness, Concisenessãªã©ã®æ”¹å–„ã«æ´»ç”¨ã•ã‚Œã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚</p>
<p>PPOã¨GRPOã®æ¯”è¼ƒã€‚value function modelï¼ˆçŠ¶æ…‹ã®ä¾¡å€¤ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼‰ãŒä¸è¦ãªãŸã‚çœãƒ¡ãƒ¢ãƒªã€ã‹ã¤åˆ©ç”¨ã™ã‚‹è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ãŒå°ã•ã„ã‚‰ã—ã„ã€‚<br>ã‚ã¨ã‚µãƒ³ãƒ—ãƒ«ã‚’ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«åˆ†ã‘ã¦ã€ã‚°ãƒ«ãƒ¼ãƒ—å†…ã§ã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ãŒæœ€å°åŒ–ã•ã‚Œã‚‹ã‚ˆã†ï¼ˆã¤ã¾ã‚Šã€å„ã‚°ãƒ«ãƒ¼ãƒ—å†…ã§æ–¹ç­–ãŒé¡ä¼¼ã™ã‚‹ï¼‰Policy ModelãŒæ›´æ–°ã•ã‚Œã‚‹ï¼ˆã¤ã¾ã‚Šloss functionã«ç›´æ¥çµ„ã¿è¾¼ã¾ã‚Œã‚‹ï¼‰ç‚¹ãŒé•ã†ã‚‰ã—ã„ã€‚<br><br>PPOã§ã¯ç”Ÿæˆã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ã«reference modelã¨Policy Modelã¨ã®KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã‚’ã¨ã‚Šã€reference modelã¨ã®å·®ãŒå¤§ãããªã‚‰ãªã„ã‚ˆã†ã€å ±é…¬ã«ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’å…¥ã‚Œã‚‹ãŸã‚ã«ä½¿ã‚ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã‚‰ã—ã„ã€‚<br><img src="https://github.com/user-attachments/assets/e145ad52-e6c9-4481-b2ee-10a3987ea2e3" alt="image" loading="lazy"></p>
<p>ä¸‹è¨˜è¨˜äº‹ã«ã‚ˆã‚‹ã¨ã€PPOã§æœ€å¤§åŒ–ã—ãŸã„ã®ã¯Advantageï¼ˆç´¯ç©å ±é…¬ã¨çŠ¶æ…‹ä¾¡å€¤ï¼ˆç´¯ç©å ±é…¬ã®æœŸå¾…å€¤ã‚’è¨ˆç®—ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼‰ã®å·®åˆ†;æœŸå¾…å€¤ã‚ˆã‚Šã‚‚å®Ÿéš›ã®ç´¯ç©å ±é…¬ãŒè‰¯ã‹ã£ãŸã‚‰è‰¯ã„æ„Ÿã˜ã ãœçš„ãªæ•°å€¤ï¼‰ã§ã‚ã‚Šã€ãã‚Œã«ã¯çŠ¶æ…‹ä¾¡å€¤ã‚’è¨ˆç®—ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ã§ã‚ã‚‹ã€‚ãã—ã¦ã€PPOã«ãŠã‘ã‚‹çŠ¶æ…‹ä¾¡å€¤ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã‚ãªã„ã§ã€LLMã«ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã•ã›ã¦æœ€çµ‚çš„ãªå ±é…¬ã‚’å¹³å‡ã™ã‚Œã°çŠ¶æ…‹ä¾¡å€¤ãƒ¢ãƒ‡ãƒ«ç„¡ã—ã§AdvantageãŒè¨ˆç®—ã§ãã‚‹ã—å¬‰ã—ãã­ï¼Ÿã¨ã„ã†æ°—æŒã¡ã§ææ¡ˆã•ã‚ŒãŸã®ãŒã€æœ¬è«–æ–‡ã§ææ¡ˆã•ã‚Œã¦ã„ã‚‹GRPOã¨ã®ã“ã¨ã€‚å‹‰å¼·ã«ãªã‚‹ã€‚<br><br>DeepSeek-R1ã®è«–æ–‡èª­ã‚“ã ï¼Ÿã€å‹‰å¼·ã«ãªã‚‹ã‚ˆã€‘<br>, asap: 


<a href="https://zenn.dev/asap/articles/34237ad87f8511" target="_blank" rel="noopener noreferrer">https://zenn.dev/asap/articles/34237ad87f8511</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2024-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1391" target="_blank" rel="noopener noreferrer" class="title-link">ReFT: Reasoning with Reinforced Fine-Tuning, Trung Quoc Luong+, N_A, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- å¼·åŒ–ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆReFTï¼‰ã‚’ææ¡ˆã—ã€LLMsã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã€‚SFTã§ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—å¾Œã€PPOã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”¨ã„ã¦ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å¼·åŒ–å­¦ç¿’ã‚’è¡Œã„ã€è±Šå¯Œãªæ¨è«–ãƒ‘ã‚¹ã‚’è‡ªå‹•ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€‚GSM8Kã€MathQAã€SVAMPãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§SFTã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€è¿½åŠ ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è³ªå•ã«ä¾å­˜ã›ãšå„ªã‚ŒãŸä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’ç™ºæ®ã€‚</span>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<a class="button" href="articles/EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<span class="issue_date">Issue Date: 2023-12-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1202" target="_blank" rel="noopener noreferrer" class="title-link">Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision,   Language, Audio, and Action, Jiasen Lu+, N_A, CVPR'24</a>
<span class="snippet"><span>GPT Summary</span>- Unified-IO 2ã¯ã€æœ€åˆã®è‡ªå·±å›å¸°å‹ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ç”»åƒã€ãƒ†ã‚­ã‚¹ãƒˆã€éŸ³å£°ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç†è§£ã—ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’çµ±ä¸€ã™ã‚‹ãŸã‚ã«ã€å…±æœ‰ã®æ„å‘³ç©ºé–“ã«å…¥åŠ›ã¨å‡ºåŠ›ã‚’é…ç½®ã—ã€å˜ä¸€ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã§å‡¦ç†ã—ã¾ã™ã€‚ã•ã¾ã–ã¾ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ”¹å–„ã‚’ææ¡ˆã—ã€å¤§è¦æ¨¡ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªäº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚Unified-IO 2ã¯ã€GRITãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å«ã‚€35ä»¥ä¸Šã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç”»åƒã€ãƒ†ã‚­ã‚¹ãƒˆã€éŸ³å£°ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç†è§£ã§ãã‚‹åˆã‚ã¦ã®autoregressive modelã€‚AllenAI</p>
<p>ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³<br><img src="https://github.com/user-attachments/assets/4282ffb0-18f1-40c9-b6d7-f004d03b8382" alt="image" loading="lazy"><br><br>ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã«æ‹¡å¼µã—ãŸã“ã¨ã§ã€è¨“ç·´ãŒéå¸¸ã«ä¸å®‰å®šã«ãªã£ãŸãŸã‚ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¸Šã§ã„ãã¤ã‹ã®å·¥å¤«ã‚’åŠ ãˆã¦ã„ã‚‹:<br><br>- 2D Rotary Embedding<br>  - Positional Encodingã¨ã—ã¦RoPEã‚’æ¡ç”¨<br>  - ç”»åƒã®ã‚ˆã†ãª2æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®å ´åˆã¯RoPEã‚’2æ¬¡å…ƒã«æ‹¡å¼µã™ã‚‹ã€‚å…·ä½“çš„ã«ã¯ã€ä½ç½®(i, j)ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«ã¤ã„ã¦ã¯ã€Q, Kã®embeddingã‚’åŠåˆ†ã«åˆ†å‰²ã—ã¦ã€ãã‚Œãã‚Œã«å¯¾ã—ã¦ç‹¬ç«‹ã«i, jã®RoPE Embeddingã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§i, jåŒæ–¹ã®æƒ…å ±ã‚’çµ„ã¿è¾¼ã‚€ã€‚<br>- QK Normalization<br>  - image, audioã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§MHAã®logitsãŒéå¸¸ã«å¤§ãããªã‚Šatteetion weightãŒ0/1ã®æ¥µç«¯ãªå€¤ã‚’ã¨ã‚‹ã‚ˆã†ã«ãªã‚Šè¨“ç·´ã®ä¸å®‰å®šã•ã«ã¤ãªãŒã£ãŸã€‚ã“ã®ãŸã‚ã€dot product attentionã‚’é©ç”¨ã™ã‚‹å‰ã«LayerNormã‚’çµ„ã¿è¾¼ã‚“ã ã€‚<br>- Scaled Cosine Attention<br>  - Image Historyãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«ãŠã„ã¦å›ºå®šé•·ã®Embeddingã‚’å¾—ã‚‹ãŸã‚ã«Perceiver Resamplerã‚’æ‰±ã£ãŸã¦ã„ã‚‹ãŒã€ã“ã¡ã‚‰ã‚‚ä¸Šè¨˜ã¨åŒæ§˜ã«Attentionã®logitsãŒæ¥µç«¯ã«å¤§ãããªã£ãŸãŸã‚ã€cosineé¡ä¼¼åº¦ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸScaled Cosine Attention <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2259" target="_blank" rel="noopener noreferrer">[Paper Note] Swin Transformer V2: Scaling Up Capacity and Resolution, Ze Liu+, arXiv'21</a>
 ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€å¤§å¹…ã«è¨“ç·´ã®å®‰å®šæ€§ãŒæ”¹å–„ã•ã‚ŒãŸã€‚<br>- ãã®ä»–<br>  - attention logitsã«ã¯fp32ã‚’é©ç”¨<br>  - äº‹å‰å­¦ç¿’ã•ã‚ŒãŸViTã¨ASTã‚’åŒæ™‚ã«æ›´æ–°ã™ã‚‹ã¨ä¸å®‰å®šã«ã¤ãªãŒã£ãŸãŸã‚ã€äº‹å‰å­¦ç¿’ã®æ®µéšã§ã¯freezeã—ã€instruction tuningã®æœ€å¾Œã«finetuningã‚’å®Ÿæ–½<br><br><img src="https://github.com/user-attachments/assets/74c8fa3a-8fb5-4785-8dd3-6a8cf3c7cfeb" alt="image" loading="lazy"></p>
<p>ç›®çš„é–¢æ•°ã¨ã—ã¦ã¯ã€Mixture of Denoisers (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1424" target="_blank" rel="noopener noreferrer">UL2: Unifying Language Learning Paradigms, Yi Tay+, N/A, ICLR'23</a>
)ã«ç€æƒ³ã‚’å¾—ã¦ã€Multimodal Mixture of Denoisersã‚’ææ¡ˆã€‚MoDã§ã¯ã€<br>- \[R\]: é€šå¸¸ã®span corruption (1--5 tokenç¨‹åº¦ã®spanã‚’maskã™ã‚‹)<br>- \[S\]: causal language modeling (inputã‚’2ã¤ã®ã‚µãƒ–ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«åˆ†å‰²ã—ã€å‰æ–¹ã‹ã‚‰å¾Œæ–¹ã‚’äºˆæ¸¬ã™ã‚‹ã€‚å‰æ–¹éƒ¨åˆ†ã¯Bi-directionalã§ã‚‚å¯)<br>- \[X\]: extreme span corruption (12&gt;=tokenç¨‹åº¦ã®spanã‚’maskã™ã‚‹)<br><br>ã®3ç¨®é¡ãŒææ¡ˆã•ã‚Œã¦ãŠã‚Šã€ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã”ã¨ã«ã“ã‚Œã‚‰ã‚’ä½¿ã„åˆ†ã‘ã‚‹:<br>- text modality: UL2 (<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1424" target="_blank" rel="noopener noreferrer">UL2: Unifying Language Learning Paradigms, Yi Tay+, N/A, ICLR'23</a>
)ã‚’è¸è¥²<br>- image, audioãŒtargetã®å ´åˆ: 2ã¤ã®é¡ä¼¼ã—ãŸãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’å®šç¾©ã—åˆ©ç”¨<br>  - \[R\]: patchã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«x%ãƒã‚¹ã‚¯ã—re-constructã™ã‚‹<br>  - \[S\]: inputã®targetã¨ã¯ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®ã¿ã®æƒ…å ±ã‹ã‚‰ã€targetãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’ç”Ÿæˆã™ã‚‹<br><br>è¨“ç·´æ™‚ã«ã¯ prefixã¨ã—ã¦modality token \[Text\], \[Image\], \[Audio\] ã¨paradigm token \[R\], \[S\], \[X\] ã‚’ã‚¿ã‚¹ã‚¯ã‚’æŒ‡ç¤ºã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦åˆ©ç”¨ã—ã¦ã„ã‚‹ã€‚</p>
<p>ã¾ãŸã€image, audioã®ãƒã‚¹ã‚¯éƒ¨åˆ†ã®denoisingã‚’autoregressive modelã§å®Ÿæ–½ã™ã‚‹éš›ã«ã¯æ™®é€šã«ã‚„ã‚‹ã¨decoderå´ã§ãƒªãƒ¼ã‚¯ãŒç™ºç”Ÿã™ã‚‹(a)ã€‚ã“ã‚Œã‚’é˜²ãã«ã¯ã€Encoderå´ã§ãƒã‚¹ã‚¯ã•ã‚Œã¦ã„ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã€Decoderå´ã§teacher-forcingã™ã‚‹éš›ã«ã®å…¨ã¦ãƒã‚¹ã‚¯ã™ã‚‹æ–¹æ³•(b)ãŒã‚ã‚‹ãŒã€ã“ã®å ´åˆã€ç”Ÿæˆã‚¿ã‚¹ã‚¯ã¨denoisingã‚¿ã‚¹ã‚¯ãŒç›¸äº’ã«å¹²æ¸‰ã—ã¦ã—ã¾ã„ã†ã¾ãå­¦ç¿’ã§ããªããªã£ã¦ã—ã¾ã†ï¼ˆç”Ÿæˆã‚¿ã‚¹ã‚¯ã§ã¯é€šå¸¸Decoderã®inputã¨ã—ã¦[mask]ãŒå…¥åŠ›ã•ã‚Œæ¬¡ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã¯èµ·ããˆãªã„ãŒã€æ„šç›´ã«(b)ã‚’ã‚„ã‚‹ã¨ãã†ãªã£ã¦ã—ã¾ã†ï¼‰ã€‚ã®ã§ã€(c)ã«ç¤ºã—ãŸã‚ˆã†ã«ã€ãƒã‚¹ã‚¯ã•ã‚Œã¦ã„ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’inputã¨ã—ã¦ç”Ÿæˆã—ãªã‘ã‚Œã°ãªã‚‰ãªã„æ™‚ã ã‘ã€ãƒã‚¹ã‚¯ã‚’è§£é™¤ã—ã¦decoderå´ã«inputã™ã‚‹ã€ã¨ã„ã†æ–¹æ³• (Dynamic Masking) ã§ã“ã®å•é¡Œã«å¯¾å‡¦ã—ã¦ã„ã‚‹ã€‚<br>&lt;img width="597" height="394" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/0dba8d5d-0c93-4c56-852b-fce9869428e7"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/0dba8d5d-0c93-4c56-852b-fce9869428e7"&lt;/a&gt;


/&gt;</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2023-12-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1186" target="_blank" rel="noopener noreferrer" class="title-link">VILA: On Pre-training for Visual Language Models, Ji Lin+, N_A, CVPR'24</a>
<span class="snippet"><span>GPT Summary</span>- æœ€è¿‘ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®æˆåŠŸã«ã‚ˆã‚Šã€ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆVLMï¼‰ãŒé€²æ­©ã—ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€VLMã®äº‹å‰å­¦ç¿’ã®ãŸã‚ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æ¤œè¨ã—ã€ä»¥ä¸‹ã®çµæœã‚’ç¤ºã—ãŸï¼š(1) LLMã‚’å‡çµã™ã‚‹ã“ã¨ã§ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒé”æˆã§ãã‚‹ãŒã€æ–‡è„ˆã«åŸºã¥ã„ãŸå­¦ç¿’èƒ½åŠ›ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚(2) äº¤äº’ã«è¡Œã‚ã‚Œã‚‹äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯æœ‰ç›Šã§ã‚ã‚Šã€ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã®ãƒšã‚¢ã ã‘ã§ã¯æœ€é©ã§ã¯ãªã„ã€‚(3) ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã‚’ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã«å†ãƒ–ãƒ¬ãƒ³ãƒ‰ã™ã‚‹ã“ã¨ã§ã€VLMã®ã‚¿ã‚¹ã‚¯ã®ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚VILAã¨ã„ã†ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’æ§‹ç¯‰ã—ã€æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã‚’å‡Œé§•ã—ã€å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã®äº‹å‰å­¦ç¿’ã¯ã€VILAã®ç‰¹æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1068" target="_blank" rel="noopener noreferrer">Improved Baselines with Visual Instruction Tuning, Haotian Liu+, N/A, CVPR'24</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1068" target="_blank" rel="noopener noreferrer" class="title-link">Improved Baselines with Visual Instruction Tuning, Haotian Liu+, N_A, CVPR'24</a>
<span class="snippet"><span>GPT Summary</span>- LLaVAã¯ã€ãƒ“ã‚¸ãƒ§ãƒ³ã¨è¨€èªã®ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«ã‚³ãƒã‚¯ã‚¿ã§ã‚ã‚Šã€ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ãŒé«˜ãå¼·åŠ›ãªæ€§èƒ½ã‚’æŒã¤ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚CLIP-ViT-L-336pxã‚’ä½¿ç”¨ã—ã€å­¦è¡“ã‚¿ã‚¹ã‚¯æŒ‡å‘ã®VQAãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€11ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ç¢ºç«‹ã—ã¾ã—ãŸã€‚13Bã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ã‚ãšã‹120ä¸‡ã®å…¬é–‹ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã€1æ—¥ã§å®Œå…¨ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’çµ‚ãˆã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç”»åƒåˆ†æãŒå¯èƒ½ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMã¨ã®ã“ã¨ã€‚</p>
<p># Overview<br><br>ç”»åƒç”Ÿæˆã‚’ã§ãã‚‹ã‚ã‘ã§ã¯ãªãã€inputã¨ã—ã¦ç”»åƒã‚’æ‰±ãˆã‚‹ã®ã¿ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8d0382b0-8c2b-438d-8de8-ee451f5e2649" alt="image" loading="lazy"><br><br></p>
<p>pj page:


<a href="https://llava-vl.github.io" target="_blank" rel="noopener noreferrer">https://llava-vl.github.io</a>


</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1044" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Chain-of-Verification Reduces Hallucination in Large Language Models, Shehzaad Dhuliawala+, N_A, ACL'24</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒæ ¹æ‹ ã®ãªã„æƒ…å ±ã‚’ç”Ÿæˆã™ã‚‹å•é¡Œã«å–ã‚Šçµ„ã‚“ã§ã„ã¾ã™ã€‚Chain-of-Verificationï¼ˆCoVeï¼‰ãƒ¡ã‚½ãƒƒãƒ‰ã‚’é–‹ç™ºã—ã€ãƒ¢ãƒ‡ãƒ«ãŒå›ç­”ã‚’ä½œæˆã—ã€æ¤œè¨¼ã—ã€æœ€çµ‚çš„ãªå›ç­”ã‚’ç”Ÿæˆã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµŒã‚‹ã“ã¨ã§ã€å¹»æƒ³ã‚’æ¸›å°‘ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’å®Ÿé¨“ã§ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>
<strong># æ¦‚è¦<br>ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã‹ã‚‰ã€Verificationã®ãŸã‚ã®è³ªå•ã‚’planningã—ã€è³ªå•ã«å¯¾ã—ã¦ç‹¬ç«‹ã«å›ç­”ã‚’å¾—ãŸã†ãˆã§ã‚ªãƒªã‚¸ãƒŠãƒ«ã®è³ªå•ã«å¯¾ã™ã‚‹aggreementã‚’ç¢ºèªã—ã€æœ€çµ‚çš„ã«ç”Ÿæˆã‚’å®Ÿæ–½ã™ã‚‹Promptingæ‰‹æ³•<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/18763903-2d70-4180-9384-2da55bedad2e" alt="image" loading="lazy"><br><br># è©•ä¾¡<br>## dataset<br>- å…¨ä½“ã‚’é€šã˜ã¦closed-bookã®è¨­å®šã§è©•ä¾¡<br>- Wikidata<br>    - Wikipedia APIã‹ã‚‰è‡ªå‹•ç”Ÿæˆã—ãŸã€Œâ€œWho are some [Profession]s who were born in [City]?â€ã€ã«å¯¾ã™ã‚‹QA pairs<br>    - Goldã¯knowledge baseã‹ã‚‰å–å¾—<br>    - å…¨56 test questions<br>    - Gold EntityãŒå¤§ä½“600ç¨‹åº¦ã‚ã‚ŠLLMã¯ä¸€éƒ¨ã—ã‹å›ç­”ã—ãªã„ã®ã§ã€precisionã§è©•ä¾¡<br>- Wiki category list<br>    - QUEST datasetã‚’åˆ©ç”¨ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/701" target="_blank" rel="noopener noreferrer">QUEST: A Retrieval Dataset of Entity-Seeking Queries with Implicit Set  Operations, Chaitanya Malaviya+, N/A, ACL'23</a>
</strong>
<br>
 <br>    - å›ç­”ã«logical operationãŒä¸è¦ãªã‚‚ã®ã«é™å®šã—ã¦é ­ã«"Name some"ã‚’ã¤ã‘ã¦è³ªå•ã‚’ç”Ÿæˆ<br>        - "Name some Mexican animated horror films" or "Name some Endemic orchids of Vietnam"<br>    - 8å€‹ã®å›ç­”ã‚’æŒã¤55 test questionsã‚’ä½œæˆ<br>- MultiSpanQA<br>    - Reading Comprehensionã«é–¢ã™ã‚‹Benchmark dataset<br>    - è¤‡æ•°ã®ç‹¬ç«‹ã—ãŸå›ç­”ï¼ˆå›ç­”ã¯é€£ç¶šã—ãªã„ã‚¹ãƒ‘ãƒ³ã‹ã‚‰å›ç­”ãŒæŠ½å‡ºã•ã‚Œã‚‹ï¼‰ã‹ã‚‰æ§‹æˆã•ã‚Œã‚‹è³ªå•ã§æ§‹æˆ<br>        - ç‰¹ã«ã€ä»Šå›ã¯closed-book setting ã§å®Ÿæ–½<br>        - ã™ãªã‚ã¡ã€ä¸ãˆã‚‰ã‚ŒãŸè³ªå•ã®ã¿ã‹ã‚‰å›ç­”ã—ãªã‘ã‚Œã°ãªã‚‰ãšã€çŸ¥ã£ã¦ã„ã‚‹çŸ¥è­˜ãŒå•ã‚ã‚Œã‚‹å•é¡Œ<br>    - 418ã®test questsionsã§ã€å„å›ç­”ã«å«ã¾ã‚Œã‚‹è¤‡æ•°ã‚¢ã‚¤ãƒ†ãƒ ã®spanãŒ3 tokenæœªæº€ã¨ãªã‚‹ã‚ˆã†ã«ã—ãŸ<br>    - QAä¾‹:<br>        - Q: Who invented the first printing press and in what year?<br>        - A: Johannes Gutenberg, 1450.<br># è©•ä¾¡çµæœ<br>ææ¡ˆæ‰‹æ³•ã«ã¯ã€verificationã®å„ã‚¹ãƒ†ãƒƒãƒ—ã§LLMã«ç‹¬ç«‹ã—ãŸpromptingã‚’ã™ã‚‹ã‹ãªã©ã§joint, 2-step, Factored, Factor+Revisedã®4ç¨®é¡ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚ã‚‹ã“ã¨ã«ç•™æ„ã€‚<br>- joint: å…¨ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ä¸€ã¤ã®promptã§å®Ÿæ–½<br>- 2-stepã¯2ã¤ã®promptã«åˆ†ã‘ã¦å®Ÿæ–½<br>- Factoredã¯å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’å…¨ã¦ç•°ãªã‚‹promptingã§å®Ÿæ–½<br>- Factor+Revisedã¯ç•°ãªã‚‹promptã§è¿½åŠ ã®QAã«å¯¾ã™ã‚‹cross-checkã‚’ã‹ã‘ã‚‹æ‰‹æ³•<br><br>çµæœã‚’è¦‹ã‚‹ã¨ã€CoVEã§hallucinationãŒè»½æ¸›ï¼ˆã¨ã„ã†ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ãŒæŒã¤çŸ¥è­˜ã«åŸºã¥ã„ã¦æ­£ç¢ºã«å›ç­”ã§ãã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®å‰²åˆãŒå¢—ãˆã‚‹ã®ã§å®Ÿè³ªçš„ã«hallucinationãŒä½æ¸›ã—ãŸã¨ã¿ãªã›ã‚‹ï¼‰ã•ã‚Œã€ç‰¹ã«jointã‚ˆã‚Šã‚‚2-step, factoredã®æ–¹ãŒé«˜ã„æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/05ff1e6c-75e7-428a-996f-61e844866391" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d72aa05e-daab-4092-a6f5-9e80cdab7486" alt="image" loading="lazy"><br></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/RectifiedFlow.html" target="_blank" rel="noopener noreferrer">#RectifiedFlow</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3210" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Flow Straight and Fast: Learning to Generate and Transfer Data with   Rectified Flow, Xingchao Liu+, ICLR'23, 2022.09</a>
<span class="snippet"><span>GPT Summary</span>- rectified flowã¨ã„ã†æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€2ã¤ã®åˆ†å¸ƒé–“ã§ã®è¼¸é€ã‚’å­¦ç¿’ã™ã‚‹ODEãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã‚‹ã€‚ã“ã‚Œã¯ã€ç›´ç·šçš„ãªçµŒè·¯ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§è¨ˆç®—åŠ¹ç‡ã‚’é«˜ã‚ã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³è»¢é€ã«ãŠã„ã¦çµ±ä¸€çš„ãªè§£æ±ºç­–ã‚’æä¾›ã™ã‚‹ã€‚rectificationã‚’é€šã˜ã¦ã€éå¢—åŠ ã®å‡¸è¼¸é€ã‚³ã‚¹ãƒˆã‚’æŒã¤æ–°ã—ã„çµåˆã‚’ç”Ÿæˆã—ã€å†å¸°çš„ã«é©ç”¨ã™ã‚‹ã“ã¨ã§ç›´ç·šçš„ãªãƒ•ãƒ­ãƒ¼ã‚’å¾—ã‚‹ã€‚å®Ÿè¨¼ç ”ç©¶ã§ã¯ã€ç”»åƒç”Ÿæˆã‚„ç¿»è¨³ã«ãŠã„ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€é«˜å“è³ªãªçµæœã‚’å¾—ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=XVjTT1nw5z" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=XVjTT1nw5z</a>


</p>
<p>æ—¥æœ¬èªè§£èª¬(fmuuly, zenn):<br>- Rectified Flow 1: 


<a href="https://zenn.dev/fmuuly/articles/37cc3a2f17138e" target="_blank" rel="noopener noreferrer">https://zenn.dev/fmuuly/articles/37cc3a2f17138e</a>


<br>- Rectified Flow 2: 


<a href="https://zenn.dev/fmuuly/articles/a062fcd340207f" target="_blank" rel="noopener noreferrer">https://zenn.dev/fmuuly/articles/a062fcd340207f</a>


<br>- Rectified Flow 3: 


<a href="https://zenn.dev/fmuuly/articles/0f262fc003e202" target="_blank" rel="noopener noreferrer">https://zenn.dev/fmuuly/articles/0f262fc003e202</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2962" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for  Generative Large Language Models, Potsawee Manakul+, EMNLP'23, 2023.03</a>
<span class="snippet"><span>GPT Summary</span>- SelfCheckGPTã¯ã€å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã—ã§LLMã®å¿œç­”ã‚’ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã™ã‚‹ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸå¿œç­”ãŒä¸€è²«ã—ãŸäº‹å®Ÿã‚’å«ã‚€å ´åˆã€çŸ¥è­˜ãŒã‚ã‚‹ã¨åˆ¤æ–­ã—ã€å¹»è¦šã•ã‚ŒãŸäº‹å®Ÿã§ã¯çŸ›ç›¾ãŒç”Ÿã˜ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€éäº‹å®Ÿçš„ãŠã‚ˆã³äº‹å®Ÿçš„ãªæ–‡ã®æ¤œå‡ºã€æ–‡ç« ã®ãƒ©ãƒ³ã‚¯ä»˜ã‘ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€é«˜ã„AUC-PRã‚¹ã‚³ã‚¢ã¨ç›¸é–¢ã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=RwzFNbJ3Ez" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=RwzFNbJ3Ez</a>


</p>
<p>è©•ä¾¡ã«é–¢é€£ã™ã‚‹æ‰‹æ³•:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/89" target="_blank" rel="noopener noreferrer">[Paper Note] Neural Text Generation from Structured Data with Application to the  Biography Domain, Remi Lebret+, EMNLP'16, 2016.03</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2769" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] GenEval: An Object-Focused Framework for Evaluating Text-to-Image   Alignment, Dhruba Ghosh+, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã¸ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®è‡ªå‹•è©•ä¾¡æ–¹æ³•ã€ŒGenEvalã€ã‚’ææ¡ˆã€‚ç‰©ä½“ã®å…±èµ·ã€ä½ç½®ã€æ•°ã€è‰²ãªã©ã®ç‰¹æ€§ã‚’è©•ä¾¡ã—ã€ç¾åœ¨ã®ç‰©ä½“æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã¦ç”Ÿæˆã‚¿ã‚¹ã‚¯ã‚’åˆ†æã€‚æœ€è¿‘ã®ãƒ¢ãƒ‡ãƒ«ã¯æ”¹å–„ã‚’ç¤ºã™ãŒã€è¤‡é›‘ãªèƒ½åŠ›ã«ã¯èª²é¡ŒãŒæ®‹ã‚‹ã€‚GenEvalã¯å¤±æ•—ãƒ¢ãƒ¼ãƒ‰ã®ç™ºè¦‹ã«ã‚‚å¯„ä¸ã—ã€æ¬¡ä¸–ä»£ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºã«å½¹ç«‹ã¤ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ä¸­ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=Wbr51vK331&noteId=NpvYJlJFqK" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Wbr51vK331&noteId=NpvYJlJFqK</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2025-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2564" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Scalable Diffusion Models with Transformers, William Peebles+, ICCV'23</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã«åŸºã¥ãæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ï¼ˆDiffusion Transformers, DiTsï¼‰ã‚’ææ¡ˆã—ã€U-Netã‚’ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã«ç½®ãæ›ãˆãŸã€‚DiTsã¯é«˜ã„Gflopsã‚’æŒã¡ã€ä½ã„FIDã‚’ç¶­æŒã—ãªãŒã‚‰è‰¯å¥½ãªã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚’ç¤ºã™ã€‚æœ€å¤§ã®DiT-XL/2ãƒ¢ãƒ‡ãƒ«ã¯ã€ImageNetã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¾“æ¥ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã€æœ€å…ˆç«¯ã®FID 2.27ã‚’é”æˆã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://qiita.com/sasgawy/items/8546c784bc94d94ef0b2" target="_blank" rel="noopener noreferrer">https://qiita.com/sasgawy/items/8546c784bc94d94ef0b2</a>


</p>
<p>ã‚ˆãè¦‹ã‚‹DiT<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2526" target="_blank" rel="noopener noreferrer">[Paper Note] DiT: Self-supervised Pre-training for Document Image Transformer, Junlong Li+, ACMMM'22</a>
<br><br>ã‚‚åŒæ§˜ã®å‘¼ç§°ã ãŒå…¨ãç•°ãªã‚‹è©±ãªã®ã§æ³¨æ„</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<span class="issue_date">Issue Date: 2025-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2474" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Efficient Memory Management for Large Language Model Serving with  PagedAttention, Woosuk Kwon+, SOSP'23</a>
<span class="snippet"><span>GPT Summary</span>- PagedAttentionã‚’ç”¨ã„ãŸvLLMã‚·ã‚¹ãƒ†ãƒ ã‚’ææ¡ˆã—ã€KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¡ãƒ¢ãƒªã®ç„¡é§„ã‚’å‰Šæ¸›ã—ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“ã§ã®æŸ”è»Ÿãªå…±æœ‰ã‚’å®Ÿç¾ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åŒãƒ¬ãƒ™ãƒ«ã®ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã§LLMã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’2-4å€å‘ä¸Šã€‚ç‰¹ã«é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚„å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§åŠ¹æœãŒé¡•è‘—ã€‚ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ä¸­ã€‚</span>
<span class="snippet"><span>Comment</span><p>ï¼ˆä»Šæ›´ãªãŒã‚‰ï¼‰vLLMã¯ã“ã¡ã‚‰:<br>


<a href="https://github.com/vllm-project/vllm" target="_blank" rel="noopener noreferrer">https://github.com/vllm-project/vllm</a>


<br><br>ç¾åœ¨ã®ä¸»è¦ãªLLM Inference/Serving Engineã®ã²ã¨ã¤ã€‚</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/VariationalAutoEncoder.html" target="_blank" rel="noopener noreferrer">#VariationalAutoEncoder</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ColdStart.html" target="_blank" rel="noopener noreferrer">#ColdStart</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/SemanticID.html" target="_blank" rel="noopener noreferrer">#SemanticID</a>
<span class="issue_date">Issue Date: 2025-07-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2309" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Recommender Systems with Generative Retrieval, Shashank Rajput+, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- æ–°ã—ã„ç”Ÿæˆçš„æ¤œç´¢ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯IDã‚’ç”¨ã„ã¦æ¬¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’äºˆæ¸¬ã™ã‚‹Transformerãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¾“æ¥ã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’é”æˆã—ã€éå»ã®å¯¾è©±å±¥æ­´ãŒãªã„ã‚¢ã‚¤ãƒ†ãƒ ã«å¯¾ã—ã¦ã‚‚æ”¹å–„ã•ã‚ŒãŸæ¤œç´¢æ€§èƒ½ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=BJ0fQUU32w" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=BJ0fQUU32w</a>


</p>
<p>Semantic IDã‚’ææ¡ˆã—ãŸç ”ç©¶</p>
<p>ã‚¢ã‚¤ãƒ†ãƒ ã‚’æ„å‘³çš„ãªæƒ…å ±ã‚’ä¿æŒã—ãŸdiscrete tokenã®ã‚¿ãƒ—ãƒ«ï¼ˆï¼Semantic ID)ã§è¡¨ç¾ã—ã€encoder-decoderã§Next Itemã®Semantic IDã‚’ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã«è½ã¨ã—ã“ã‚€ã“ã¨ã§æ¨è–¦ã™ã‚‹ã€‚SemanticIDã®ä½œæˆæ–¹æ³•ã¯å¾Œã§èª­ã‚“ã§ç†è§£ã—ãŸã„ã€‚<br><br><img src="https://github.com/user-attachments/assets/38606c7c-011f-46b0-ab14-8d213626be3d" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/a239bac7-c273-4681-a102-65e88c9c65d2" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/7d1822ce-462e-43f6-bb33-af77914919f6" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/FlowMatching.html" target="_blank" rel="noopener noreferrer">#FlowMatching</a>
<a class="button" href="articles/OptimalTransport.html" target="_blank" rel="noopener noreferrer">#OptimalTransport</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2166" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Flow Matching for Generative Modeling, Yaron Lipman+, ICLR'23</a>
<span class="snippet"><span>GPT Summary</span>- Continuous Normalizing Flowsï¼ˆCNFsï¼‰ã«åŸºã¥ãæ–°ã—ã„ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´æ‰‹æ³•Flow Matchingï¼ˆFMï¼‰ã‚’ææ¡ˆã€‚FMã¯å›ºå®šã•ã‚ŒãŸæ¡ä»¶ä»˜ãç¢ºç‡çµŒè·¯ã®ãƒ™ã‚¯ãƒˆãƒ«å ´ã‚’å›å¸°ã—ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸è¦ã§è¨“ç·´å¯èƒ½ã€‚æ‹¡æ•£çµŒè·¯ã¨ä½µç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šå …ç‰¢ãªè¨“ç·´ãŒå®Ÿç¾ã€‚æœ€é©è¼¸é€ã‚’ç”¨ã„ãŸæ¡ä»¶ä»˜ãç¢ºç‡çµŒè·¯ã¯åŠ¹ç‡çš„ã§ã€è¨“ç·´ã¨ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒé€Ÿãã€ä¸€èˆ¬åŒ–æ€§èƒ½ã‚‚å‘ä¸Šã€‚ImageNetã§ã®å®Ÿé¨“ã«ã‚ˆã‚Šã€FMã¯æ‹¡æ•£ãƒ™ãƒ¼ã‚¹æ‰‹æ³•ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€è¿…é€Ÿãªã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆã‚’å¯èƒ½ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3208" target="_blank" rel="noopener noreferrer">[Paper Note] High-Resolution Image Synthesis with Latent Diffusion Models, Robin Rombach+, CVPR'22, 2021.12</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/ICCV.html" target="_blank" rel="noopener noreferrer">#ICCV</a>
<span class="issue_date">Issue Date: 2025-06-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2111" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Sigmoid Loss for Language Image Pre-Training, Xiaohua Zhai+, ICCV'23</a>
<span class="snippet"><span>GPT Summary</span>- ã‚·ãƒ³ãƒ—ãƒ«ãªãƒšã‚¢ãƒ¯ã‚¤ã‚ºã‚·ã‚°ãƒ¢ã‚¤ãƒ‰æå¤±ï¼ˆSigLIPï¼‰ã‚’ææ¡ˆã—ã€ç”»åƒ-ãƒ†ã‚­ã‚¹ãƒˆãƒšã‚¢ã«åŸºã¥ãè¨€èª-ç”»åƒäº‹å‰å­¦ç¿’ã‚’æ”¹å–„ã€‚ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰æå¤±ã¯ãƒãƒƒãƒã‚µã‚¤ã‚ºã®æ‹¡å¤§ã‚’å¯èƒ½ã«ã—ã€å°ã•ãªãƒãƒƒãƒã‚µã‚¤ã‚ºã§ã‚‚æ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾ã€‚SigLiTãƒ¢ãƒ‡ãƒ«ã¯84.5%ã®ImageNetã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆç²¾åº¦ã‚’é”æˆã€‚ãƒãƒƒãƒã‚µã‚¤ã‚ºã®å½±éŸ¿ã‚’ç ”ç©¶ã—ã€32kãŒåˆç†çš„ãªã‚µã‚¤ã‚ºã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã€‚ãƒ¢ãƒ‡ãƒ«ã¯å…¬é–‹ã•ã‚Œã€ã•ã‚‰ãªã‚‹ç ”ç©¶ã®ä¿ƒé€²ã‚’æœŸå¾…ã€‚</span>
<span class="snippet"><span>Comment</span><p>SigLIPè«–æ–‡</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ActivationSteering/ITI.html" target="_blank" rel="noopener noreferrer">#ActivationSteering/ITI</a>
<a class="button" href="articles/Probing.html" target="_blank" rel="noopener noreferrer">#Probing</a>
<a class="button" href="articles/Trustfulness.html" target="_blank" rel="noopener noreferrer">#Trustfulness</a>
<span class="issue_date">Issue Date: 2025-05-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1941" target="_blank" rel="noopener noreferrer" class="title-link">Inference-Time Intervention: Eliciting Truthful Answers from a Language   Model, Kenneth Li+, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- Inference-Time Intervention (ITI)ã‚’ææ¡ˆã—ã€LLMsã®çœŸå®Ÿæ€§ã‚’å‘ä¸Šã•ã›ã‚‹æŠ€è¡“ã‚’ç´¹ä»‹ã€‚ITIã¯æ¨è«–ä¸­ã«ãƒ¢ãƒ‡ãƒ«ã®æ´»æ€§åŒ–ã‚’èª¿æ•´ã—ã€LLaMAãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’TruthfulQAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¤§å¹…ã«æ”¹å–„ã€‚Alpacaãƒ¢ãƒ‡ãƒ«ã§ã¯çœŸå®Ÿæ€§ãŒ32.5%ã‹ã‚‰65.1%ã«å‘ä¸Šã€‚çœŸå®Ÿæ€§ã¨æœ‰ç”¨æ€§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’ç‰¹å®šã—ã€ä»‹å…¥ã®å¼·åº¦ã‚’èª¿æ•´ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã™ã€‚ITIã¯ä½ã‚³ã‚¹ãƒˆã§ãƒ‡ãƒ¼ã‚¿åŠ¹ç‡ãŒé«˜ãã€æ•°ç™¾ã®ä¾‹ã§çœŸå®Ÿã®æ–¹å‘æ€§ã‚’ç‰¹å®šå¯èƒ½ã€‚LLMsãŒè™šå½ã‚’ç”Ÿæˆã—ã¤ã¤ã‚‚çœŸå®Ÿã®å†…éƒ¨è¡¨ç¾ã‚’æŒã¤å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚</span>
<span class="snippet"><span>Comment</span><p>Inference Time Interventionã‚’ææ¡ˆã—ãŸç ”ç©¶ã€‚Attention Headã«å¯¾ã—ã¦ç·šå½¢ãƒ—ãƒ­ãƒ¼ãƒ“ãƒ³ã‚°[^1]ã‚’å®Ÿæ–½ã—ã€çœŸå®Ÿæ€§ã«é–¢é€£ã™ã‚‹ã§ã‚ã‚ã†Headã‚’topKã§ç‰¹å®šã§ãã‚‹ã‚ˆã†ã«ã—ã€headã®å‡ºåŠ›ã«å¯¾ã—çœŸå®Ÿæ€§ã‚’é«˜ã‚ã‚‹æ–¹å‘æ€§ã®ãƒ™ã‚¯ãƒˆãƒ«vã‚’æ¨è«–æ™‚ã«åŠ ç®—ã™ã‚‹ã“ã¨ã§ï¼ˆï¼interventionï¼‰ã€ãƒ¢ãƒ‡ãƒ«ã®çœŸå®Ÿæ€§ã‚’é«˜ã‚ã‚‹ã€‚vã¯ç·šå½¢ãƒ—ãƒ­ãƒ¼ãƒ“ãƒ³ã‚°ã«ã‚ˆã£ã¦å­¦ç¿’ã•ã‚ŒãŸé‡ã¿ã‚’ä½¿ã†æ‰‹æ³•ã¨ã€æ­£ç­”ã¨èª¤ç­”ã®æ´»æ€§åŒ–ã®å¹³å‡ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—ã—ãã®å·®åˆ†ã‚’vã¨ã™ã‚‹æ–¹æ³•ã®äºŒç¨®é¡ãŒã‚ã‚‹ã€‚å¾Œè€…ã®æ–¹ãŒæ€§èƒ½ãŒè‰¯ã„ã€‚topKã‚’æ±‚ã‚ã‚‹éš›ã«ã¯ã€ç·šå½¢ãƒ—ãƒ­ãƒ¼ãƒ“ãƒ³ã‚°ã‚’ã—ãŸãƒ¢ãƒ‡ãƒ«ã®validation setã§ã®æ€§èƒ½ã‹ã‚‰æ±ºã‚ã‚‹ã€‚Kã¨Î±ã¯ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã‚ã‚‹ã€‚<br><br>[^1]: headã®representationã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã€ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã€ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã®2å€¤åˆ†é¡æ€§èƒ½ã‚’è¦‹ã‚‹ã“ã¨ã§headãŒã©ã®ç¨‹åº¦ã€ãƒ—ãƒ­ãƒ¼ãƒ“ãƒ³ã‚°ã®å­¦ç¿’ã«ä½¿ã£ãŸãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹æƒ…å ±ã‚’ä¿æŒã—ã¦ã„ã‚‹ã‹ã‚’æ¸¬å®šã™ã‚‹æ‰‹æ³•<br><br>æ—¥æœ¬èªè§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:


<a href="https://www.docswell.com/s/DeepLearning2023/Z38P8D-2024-06-20-131813#p1" target="_blank" rel="noopener noreferrer">https://www.docswell.com/s/DeepLearning2023/Z38P8D-2024-06-20-131813#p1</a>


</p>
<p>ã“ã‚Œã¯ç›¸å½“æ±ç”¨çš„ã«ä½¿ãˆãã†ãªè©±ã ã‹ã‚‰å½¹ã«ç«‹ã¡ãã†</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2025-04-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1865" target="_blank" rel="noopener noreferrer" class="title-link">The Impact of Positional Encoding on Length Generalization in   Transformers, Amirhossein Kazemnejad+, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- é•·ã•ä¸€èˆ¬åŒ–ã¯Transformerãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹é‡è¦ãªèª²é¡Œã§ã‚ã‚Šã€ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆPEï¼‰ãŒãã®æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã€‚5ã¤ã®ç•°ãªã‚‹PEæ‰‹æ³•ï¼ˆAPEã€T5ã®ç›¸å¯¾PEã€ALiBiã€Rotaryã€NoPEï¼‰ã‚’æ¯”è¼ƒã—ãŸçµæœã€ALiBiã‚„Rotaryãªã©ã®ä¸€èˆ¬çš„ãªæ‰‹æ³•ã¯é•·ã•ä¸€èˆ¬åŒ–ã«é©ã—ã¦ãŠã‚‰ãšã€NoPEãŒä»–ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã€‚NoPEã¯è¿½åŠ ã®è¨ˆç®—ã‚’å¿…è¦ã¨ã›ãšã€çµ¶å¯¾PEã¨ç›¸å¯¾PEã®ä¸¡æ–¹ã‚’è¡¨ç¾å¯èƒ½ã§ã‚ã‚‹ã€‚ã•ã‚‰ã«ã€ã‚¹ã‚¯ãƒ©ãƒƒãƒãƒ‘ãƒƒãƒ‰ã®å½¢å¼ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚‚ç¤ºã•ã‚ŒãŸã€‚ã“ã®ç ”ç©¶ã¯ã€æ˜ç¤ºçš„ãªä½ç½®åŸ‹ã‚è¾¼ã¿ãŒé•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã¸ã®ä¸€èˆ¬åŒ–ã«å¿…é ˆã§ãªã„ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1863" target="_blank" rel="noopener noreferrer">Llama 4 Series, Meta, 2025.04</a>
<br><br>ã«ãŠã„ã¦ã€Llama4 ScoutãŒ10Mã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’å®Ÿç¾ã§ãã‚‹ç†ç”±ã®ä¸€ã¤ã¨ã®ã“ã¨ã€‚<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/drjimfan/status/1908615861650547081?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Llama4ã®ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆã«ã‚‚ãã®æ—¨è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹:<br>&gt;A key innovation in the Llama 4 architecture is the use of interleaved attention layers without positional embeddings. Additionally, we employ inference time temperature scaling of attention to enhance length generalization.<br><br>[The Llama 4 herd: The beginning of a new era of natively multimodal AI innovation](


<a href="https://ai.meta.com/blog/llama-4-multimodal-intelligence/?utm_source=twitter&utm_medium=organic_social&utm_content=image&utm_campaign=llama4)" target="_blank" rel="noopener noreferrer">https://ai.meta.com/blog/llama-4-multimodal-intelligence/?utm_source=twitter&utm_medium=organic_social&utm_content=image&utm_campaign=llama4)</a>


<p>æ–œã‚èª­ã¿ã ãŒã€length generalizationã‚’è©•ä¾¡ã™ã‚‹ä¸Šã§downstream taskã«ç„¦ç‚¹ã‚’å½“ã¦ã€3ã¤ã®ä»£è¡¨çš„ãªã‚«ãƒ†ã‚´ãƒªã«ç›¸å½“ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã—ãŸã¨ã“ã‚ã€ã“ã®è¦³ç‚¹ã«ãŠã„ã¦ã¯T5ã®relative positinal encodingã¨NoPEï¼ˆä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ³ã‚°ç„¡ã—ï¼‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒè‰¯ãã€<br><br><img src="https://github.com/user-attachments/assets/dddadfff-ab28-4073-96c3-831eb16845a0" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/c6ec8e0e-7abb-4330-be23-2261486a477c" alt="image" loading="lazy"><br><br>NoPEã¯çµ¶å¯¾ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨ç›¸å¯¾ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç†è«–ä¸Šå®Ÿç¾å¯èƒ½ã§ã‚ã‚Š[^1]<br><img src="https://github.com/user-attachments/assets/bbcf797a-d394-42d4-b017-08d7dba4261c" alt="image" loading="lazy"><br><br>å®Ÿéš›ã«å­¦ç¿’ã•ã‚ŒãŸç•°ãªã‚‹2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦åŒã˜ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãã‚Œãã‚Œinputã—ã€åŒã˜æ·±ã•ã®Layerã®å…¨ã¦ã®attention distributionã®çµ„ã¿åˆã‚ã›ã‹ã‚‰Jensen Shannon Divergenceã§è·é›¢ã‚’ç®—å‡ºã—ã€æœ€ã‚‚å°ã•ã„ã‚‚ã®ã‚’2ãƒ¢ãƒ‡ãƒ«é–“ã®å½“è©²layerã®è·é›¢ã¨ã—ã¦å¯è¦–åŒ–ã™ã‚‹ã¨ä¸‹è¨˜ã®ã‚ˆã†ã«ãªã‚Šã€NoPEã¨T5ã®relative positional encodingãŒæœ€ã‚‚é¡ä¼¼ã—ã¦ã„ã‚‹ã“ã¨ã‹ã‚‰ã€NoPEãŒå­¦ç¿’ã‚’é€šã˜ã¦ï¼ˆå®Ÿç”¨ä¸Šã¯ï¼‰ç›¸å¯¾ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ã‚ˆã†ãªã‚‚ã®ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚<br><img src="https://github.com/user-attachments/assets/9619c7e5-0612-45de-8717-1634bee509b7" alt="image" loading="lazy"><br><br>[^1]:æ·±ã•1ã®Layerã®Hidden State H^1ã‹ã‚‰çµ¶å¯¾ä½ç½®ã®å¾©å…ƒãŒå¯èƒ½ã§ã‚ã‚Šï¼ˆã¤ã¾ã‚Šã€å½“è©²ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®HãŒçµ¶å¯¾ä½ç½®ã«é–¢ã™ã‚‹æƒ…å ±ã‚’ä¿æŒã—ã¦ã„ã‚‹ï¼‰ã€ã“ã®å‰æã®ã‚‚ã¨ã€å¾Œç¶šã®LayerãŒã“ã®æƒ…å ±ã‚’ä¸Šæ›¸ãã—ãªã„ã¨ä»®å®šã—ãŸå ´åˆã«ã€ç›¸å¯¾ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å®Ÿç¾ã§ãã‚‹ã€‚</p>
<p>ã¾ãŸã€CoT/Scratchpadã¯long sequenceã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒsmall scaleã§ã¯ã‚ã‚‹ãŒå…ˆè¡Œç ”ç©¶ã§ç¤ºã•ã‚Œã¦ãŠã‚Šã€Positional Encodingã‚’å¤‰åŒ–ã•ã›ãŸæ™‚ã«CoT/Scratchpadã®æ€§èƒ½ã«ã©ã®ã‚ˆã†ãªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã‹ã‚’èª¿æŸ»ã€‚<br><br>å…·ä½“çš„ã«ã¯ã€CoT/Scratchpadã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒã©ã®ã‚ˆã†ãªã‚‚ã®ãŒæœ‰åŠ¹ã‹ã‚‚æ˜ã‚‰ã‹ã§ã¯ãªã„ã®ã§ã€5ç¨®é¡ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®çµ„ã¿åˆã‚ã›ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’æ§‹æˆã—ã€mathematical reasoningã‚¿ã‚¹ã‚¯ã§ä»¥ä¸‹ã®ã‚ˆã†ãªè¨­å®šã§è¨“ç·´ã—<br><br>- ã•ã¾ã–ã¾ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®çµ„ã¿åˆã‚ã›ã§ç•°ãªã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä½œæˆã—ã€<br>- å…¨ã¦ã®ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚ã‚Š/ãªã—ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´<br><br>ã“ã‚Œã‚‰ã‚’æ¯”è¼ƒã—ãŸã€‚ã“ã®çµæœã€CoT/Scratchpadã¯ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«é–¢ä¿‚ãªãã€ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã§ã®ã¿æœ‰åŠ¹ï¼ˆæœ‰åŠ¹ã‹ã©ã†ã‹ã¯ã‚¿ã‚¹ã‚¯ä¾å­˜ï¼‰ã§ã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚ã“ã®ã“ã¨ã‹ã‚‰ã€CoT/Scratcpadï¼ˆã¤ã¾ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®inputã¨outputã®ä»•æ–¹ï¼‰å˜ä½“ã§ã€long contextã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ããªã„ã®ã§ã€Positional Encodingï¼ˆâ‰’ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼‰ã«ã‚ˆã‚‹long contextã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã®å‘ä¸ŠãŒéå¸¸ã«é‡è¦ã§ã‚ã‚‹ã“ã¨ãŒæµ®ãå½«ã‚Šã«ãªã£ãŸã€‚<br><img src="https://github.com/user-attachments/assets/e23c4fbf-84de-4344-a01e-1e7e9e66fa7e" alt="image" loading="lazy"><br><br>ã¾ãŸã€CoT/ScratchpadãŒæœ‰åŠ¹ã ã£ãŸAdditionã«å¯¾ã—ã¦å„Positional Embeddingãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã€ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã®attentionãŒã©ã®ä½ç½®ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æŒ‡ã—ã¦ã„ã‚‹ã‹ã‚’ç›¸å¯¾è·é›¢ã§å¯è¦–åŒ–ã—ãŸã¨ã“ã‚ï¼ˆ0ãŒå½“è©²ãƒˆãƒ¼ã‚¯ãƒ³ã€ã¤ã¾ã‚Šç¾åœ¨ã®Scratchpadã«ç€ç›®ã—ã¦ãŠã‚Šã€1ãŒé ã„ãƒˆãƒ¼ã‚¯ãƒ³ã€ã¤ã¾ã‚Šinputã«ç€ç›®ã—ã¦ã„ã‚‹ã“ã¨ã‚’è¡¨ã™ã‚ˆã†ã«æ­£è¦åŒ–ï¼‰ã€NoPEã¨Relative Positional EncodingãŒshort/long rangeã«ãã‚Œãã‚Œãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã™ã‚‹ã‚ˆã†ãªbinomialãªåˆ†å¸ƒãªã®ã«å¯¾ã—ã€ä»–ã®Positional Encodingã§ã¯ã‚ˆã‚Šuniformãªåˆ†å¸ƒã§ã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚ã“ã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã¯NoPEã¨Relative POã®æ€§èƒ½ãŒé«˜ã‹ã£ãŸãŸã‚ã€binomialãªåˆ†å¸ƒã®æ–¹ãŒã‚ˆã‚Šæœ€é©ã§ã‚ã‚ã†ã“ã¨ãŒç¤ºå”†ã•ã‚ŒãŸã€‚<br><img src="https://github.com/user-attachments/assets/833e6a81-8611-4e79-9d2e-473f7ebee2d0" alt="image" loading="lazy"><br></p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1412" target="_blank" rel="noopener noreferrer" class="title-link">Direct Preference Optimization: Your Language Model is Secretly a Reward  Model, Rafael Rafailov+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ç„¡ç›£ç£è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLMï¼‰ã®åˆ¶å¾¡æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€å ±é…¬ãƒ¢ãƒ‡ãƒ«ã®æ–°ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚’å°å…¥ã—ã€å˜ç´”ãªåˆ†é¡æå¤±ã§RLHFå•é¡Œã‚’è§£æ±ºã™ã‚‹ã€Œç›´æ¥çš„ãªå¥½ã¿æœ€é©åŒ–ï¼ˆDPOï¼‰ã€ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ææ¡ˆã€‚DPOã¯å®‰å®šæ€§ã¨æ€§èƒ½ã‚’æŒã¡ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚„ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã‚’ä¸è¦ã«ã—ã€æ—¢å­˜ã®æ–¹æ³•ã¨åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¤ºã™ã€‚ç‰¹ã«ã€ç”Ÿæˆç‰©ã®æ„Ÿæƒ…åˆ¶å¾¡ã«ãŠã„ã¦PPOãƒ™ãƒ¼ã‚¹ã®RLHFã‚’ä¸Šå›ã‚Šã€å¿œç­”ã®è³ªã‚’æ”¹å–„ã—ã¤ã¤å®Ÿè£…ãŒç°¡ç´ åŒ–ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>DPOã‚’ææ¡ˆã—ãŸç ”ç©¶<br><br>&lt;img width="838" alt="image" src="


&lt;a href="https://github.com/user-attachments/assets/2f7edf2c-32fa-4c5c-bc39-fb85112d1837"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/2f7edf2c-32fa-4c5c-bc39-fb85112d1837"&lt;/a&gt;


&gt;<br><br></p>
<p>è§£èª¬ãƒã‚¹ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1940194999993585925?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>SNLP'24ã§ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰:


<a href="https://speakerdeck.com/kazutoshishinoda/lun-wen-shao-jie-direct-preference-optimization-your-language-model-is-secretly-a-reward-model" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/kazutoshishinoda/lun-wen-shao-jie-direct-preference-optimization-your-language-model-is-secretly-a-reward-model</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-11-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1158" target="_blank" rel="noopener noreferrer" class="title-link">GAIA: a benchmark for General AI Assistants, GrÃ©goire Mialon+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- GAIAã¯ã€General AI Assistantsã®ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚Šã€AIç ”ç©¶ã®ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã¨ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚GAIAã¯ã€æ¨è«–ã€ãƒãƒ«ãƒãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®å‡¦ç†ã€ã‚¦ã‚§ãƒ–ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ãªã©ã€å®Ÿä¸–ç•Œã®è³ªå•ã«å¯¾ã™ã‚‹åŸºæœ¬çš„ãªèƒ½åŠ›ã‚’å¿…è¦ã¨ã™ã‚‹ã€‚äººé–“ã®å›ç­”è€…ã¯92ï¼…ã®æ­£ç­”ç‡ã‚’é”æˆã—ã€GPT-4ã¯15ï¼…ã®æ­£ç­”ç‡ã‚’é”æˆã—ãŸã€‚ã“ã‚Œã¯ã€æœ€è¿‘ã®å‚¾å‘ã¨ã¯ç•°ãªã‚‹çµæœã§ã‚ã‚Šã€å°‚é–€çš„ãªã‚¹ã‚­ãƒ«ã‚’å¿…è¦ã¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§ã¯LLMsãŒäººé–“ã‚’ä¸Šå›ã£ã¦ã„ã‚‹ã€‚GAIAã¯ã€äººé–“ã®å¹³å‡çš„ãªå …ç‰¢æ€§ã¨åŒç­‰ã®èƒ½åŠ›ã‚’æŒã¤ã‚·ã‚¹ãƒ†ãƒ ãŒAGIã®åˆ°æ¥ã«é‡è¦ã§ã‚ã‚‹ã¨è€ƒãˆã¦ã„ã‚‹ã€‚GAIAã®æ‰‹æ³•ã‚’ä½¿ç”¨ã—ã¦ã€466ã®è³ªå•ã¨å›ç­”ã‚’ä½œæˆã—ã€ä¸€éƒ¨ã‚’å…¬é–‹ã—ã¦ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã§åˆ©ç”¨å¯èƒ½ã«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Yann LeCunæ°ã®ç´¹ä»‹ãƒ„ã‚¤ãƒ¼ãƒˆ<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ylecun/status/1727707519470977311?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>Meta-FAIR, Meta-GenAI, HuggingFace, AutoGPTã«ã‚ˆã‚‹ç ”ç©¶ã€‚äººé–“ã¯92%æ­£è§£ã§ãã‚‹ãŒã€GPT4ã§ã‚‚15%ã—ã‹æ­£è§£ã§ããªã„QAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚è§£ããŸã‚ã«æ¨è«–ã‚„ãƒãƒ«ãƒãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®å‡¦ç†ã€ãƒ–ãƒ©ã‚¦ã‚¸ãƒ³ã‚°ã€ãƒ„ãƒ¼ãƒ«ã«å¯¾ã™ã‚‹ç¿’ç†Ÿãªã©ã®åŸºæœ¬çš„ãªèƒ½åŠ›ã‚’å¿…è¦ã¨ã™ã‚‹å®Ÿä¸–ç•Œã®QAã¨ã®ã“ã¨ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0b13838b-0829-48b9-b281-3d09a5a3859f" alt="image" loading="lazy"><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1792" target="_blank" rel="noopener noreferrer">Open-source DeepResearch â€“ Freeing our search agents, HuggingFace, 2025.02</a>
<br><br>ã§è¨€åŠã•ã‚Œã¦ã„ã‚‹LLM Agentã®è©•ä¾¡ã§æœ€ã‚‚æœ‰åãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãªæ¨¡æ§˜</p>
<p>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: 


<a href="https://huggingface.co/datasets/gaia-benchmark/GAIA" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/gaia-benchmark/GAIA</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<span class="issue_date">Issue Date: 2023-11-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1137" target="_blank" rel="noopener noreferrer" class="title-link">Instruction-Following Evaluation for Large Language Models, Jeffrey Zhou+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã®èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€Instruction-Following Evalï¼ˆIFEvalï¼‰ã¨ã„ã†è©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒå°å…¥ã•ã‚Œã¾ã—ãŸã€‚IFEvalã¯ã€æ¤œè¨¼å¯èƒ½ãªæŒ‡ç¤ºã«ç„¦ç‚¹ã‚’å½“ã¦ãŸç›´æ„Ÿçš„ã§å†ç¾æ€§ã®ã‚ã‚‹è©•ä¾¡æ–¹æ³•ã§ã™ã€‚å…·ä½“çš„ã«ã¯ã€25ç¨®é¡ã®æ¤œè¨¼å¯èƒ½ãªæŒ‡ç¤ºã‚’ç‰¹å®šã—ã€ãã‚Œãã‚Œã®æŒ‡ç¤ºã‚’å«ã‚€ç´„500ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚ã“ã®è©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®çµæœã¯ã€GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>LLMãŒinstructionã«ã©ã‚Œã ã‘å¾“ã†ã‹ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã€æ¤œè¨¼å¯èƒ½ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆ400å­—ä»¥ä¸Šã§æ›¸ããªã•ã„ãªã©ï¼‰ã‚’è€ƒæ¡ˆã—è©•ä¾¡ã™ã‚‹æ çµ„ã¿ã‚’ææ¡ˆã€‚äººé–“ãŒè©•ä¾¡ã™ã‚‹ã¨æ™‚é–“ã¨ãŠé‡‘ãŒã‹ã‹ã‚Šã€LLMã‚’åˆ©ç”¨ã—ãŸè‡ªå‹•è©•ä¾¡ã ã¨è©•ä¾¡ã‚’å®Ÿæ–½ã™ã‚‹LLMã®ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã‚‹ã®ã ã€ãã‚Œã‚‰ä¸¡æ–¹ã®limitationã‚’å…‹æœã§ãã‚‹ã¨ã®ã“ã¨ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0eb3fe10-536d-4674-aa3c-fd76f390f21d" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReversalCurse.html" target="_blank" rel="noopener noreferrer">#ReversalCurse</a>
<span class="issue_date">Issue Date: 2023-10-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1059" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A", Lukas Berglund+, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±å›å¸°å‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMsï¼‰ã¯ã€ã€ŒAã¯Bã§ã‚ã‚‹ã€ã¨ã„ã†æ–‡ã‹ã‚‰ã€ŒBã¯Aã§ã‚ã‚‹ã€ã¨é€†ã®é–¢ä¿‚ã‚’è‡ªå‹•çš„ã«ä¸€èˆ¬åŒ–ã§ããªã„ã€Œé€†è»¢ã®å‘ªã„ã€ã‚’ç¤ºã™ã€‚ä¾‹ãˆã°ã€ãƒ¢ãƒ‡ãƒ«ãŒã€Œãƒ¯ãƒ¬ãƒ³ãƒ†ã‚£ãƒŠãƒ»ãƒ†ãƒ¬ã‚·ã‚³ãƒ¯ã¯å®‡å®™ã«è¡Œã£ãŸæœ€åˆã®å¥³æ€§ã§ã‚ã‚‹ã€ã¨è¨“ç·´ã•ã‚Œã¦ã‚‚ã€ã€Œå®‡å®™ã«è¡Œã£ãŸæœ€åˆã®å¥³æ€§ã¯èª°ã‹ï¼Ÿã€ã«æ­£ã—ãç­”ãˆã‚‰ã‚Œãªã„ã€‚å®Ÿé¨“ã§ã¯ã€æ¶ç©ºã®æ–‡ã‚’ç”¨ã„ã¦GPT-3ã¨Llama-1ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€é€†è»¢ã®å‘ªã„ã®å­˜åœ¨ã‚’ç¢ºèªã€‚ChatGPTï¼ˆGPT-3.5ãŠã‚ˆã³GPT-4ï¼‰ã§ã‚‚ã€å®Ÿåœ¨ã®æœ‰åäººã«é–¢ã™ã‚‹è³ªå•ã§æ­£ç­”ç‡ã«å¤§ããªå·®ãŒè¦‹ã‚‰ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>A is Bã¨ã„ã†æ–‡ã§LLMã‚’è¨“ç·´ã—ã¦ã‚‚ã€B is Aã¨ã„ã†é€†æ–¹å‘ã«ã¯æ±åŒ–ã•ã‚Œãªã„ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br>è‘—è€…ãƒ„ã‚¤ãƒ¼ãƒˆ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/owainevans_uk/status/1705285631520407821?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/25e20dcc-0313-4cd2-8768-afb0e4e48a68" alt="image" loading="lazy"><br><p>GPT3, LLaMaã‚’ A is Bã§finetuneã—ã€B is Aã¨ã„ã†é€†æ–¹å‘ã®factã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«ï¼ˆè³ªå•ã‚’ã—ã¦ï¼‰ãƒ†ã‚¹ãƒˆã—ãŸã¨ã“ã‚ã€0%ä»˜è¿‘ã®Acc.ã ã£ãŸã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d089eb94-6872-40b5-89a1-7532758e1d89" alt="image" loading="lazy"><br><br>ã¾ãŸã€Acc.ãŒä½ã„ã ã‘ã§ãªãã€å¯¾æ•°å°¤åº¦ã‚‚randomãªfactã‚’ç”Ÿæˆã—ãŸå ´åˆã¨ã€ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§å·®ãŒãªã„ã“ã¨ãŒã‚ã‹ã£ãŸã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ba10fff4-cfdc-4e52-8217-c59247209211" alt="image" loading="lazy"><br><br>ã“ã®ã“ã¨ã‚‰ã€Reversal Curseã¯ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§ã¯è§£æ±ºã§ããªã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1923" target="_blank" rel="noopener noreferrer">Physics of Language Models: Part 3.1, Knowledge Storage and Extraction, Zeyuan Allen-Zhu+, ICML'24</a>
</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1039" target="_blank" rel="noopener noreferrer" class="title-link">Textbooks Are All You Need II: phi-1.5 technical report, Yuanzhi Li+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€å°ã•ãªTransformerãƒ™ãƒ¼ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹TinyStoriesã¨ã€å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹phi-1ã®èƒ½åŠ›ã«ã¤ã„ã¦èª¿æŸ»ã—ã¾ã—ãŸã€‚ã¾ãŸã€phi-1ã‚’ä½¿ç”¨ã—ã¦æ•™ç§‘æ›¸ã®å“è³ªã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ”¹å–„ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€phi-1.5ã¨ã„ã†æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã€è‡ªç„¶è¨€èªã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦æ€§èƒ½ãŒå‘ä¸Šã—ã€è¤‡é›‘ãªæ¨è«–ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ãŸã€‚phi-1.5ã¯ã€è‰¯ã„ç‰¹æ€§ã¨æ‚ªã„ç‰¹æ€§ã‚’æŒã£ã¦ãŠã‚Šã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need, Suriya Gunasekar+, N/A, arXiv'23</a>
 ã«ç¶šãè«–æ–‡</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-07-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/903" target="_blank" rel="noopener noreferrer" class="title-link">Judging LLM-as-a-judge with MT-Bench and Chatbot Arena, Lianmin Zheng+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã‚’åˆ¤å®šè€…ã¨ã—ã¦ä½¿ç”¨ã—ã¦ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ³ãƒ‰ã®è³ªå•ã«å¯¾ã™ã‚‹æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã™ã‚‹ã€‚LLMã®åˆ¶é™ã‚„å•é¡Œã‚’è»½æ¸›ã™ã‚‹ãŸã‚ã®è§£æ±ºç­–ã‚’ææ¡ˆã—ã€2ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§LLMã®åˆ¤å®šè€…ã¨äººé–“ã®å¥½ã¿ã®ä¸€è‡´ã‚’æ¤œè¨¼ã™ã‚‹ã€‚çµæœã¯ã€å¼·åŠ›ãªLLMåˆ¤å®šè€…ãŒäººé–“ã®å¥½ã¿ã¨ã‚ˆãä¸€è‡´ã—ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§èª¬æ˜å¯èƒ½ãªæ–¹æ³•ã§äººé–“ã®å¥½ã¿ã‚’è¿‘ä¼¼ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã•ã‚‰ã«ã€æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨å¾“æ¥ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ç›¸è£œæ€§ã‚’ç¤ºã—ã€ã„ãã¤ã‹ã®ãƒãƒªã‚¢ãƒ³ãƒˆã‚’è©•ä¾¡ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>MT-Benchï¼ˆMTBenchï¼‰ã‚¹ã‚³ã‚¢ã¨ã¯ã€multi-turnã®QAã‚’å‡ºé¡Œã—ã€ãã®å›ç­”ã®è³ªã‚’GPT-4ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ãŸã‚¹ã‚³ã‚¢ã®ã“ã¨ã€‚<br><br>GPT-4ã®åˆ¤æ–­ã¨human expertã®åˆ¤æ–­ã¨ã®agreementã‚‚æ¤œè¨¼ã—ã¦ãŠã‚Šã€agreementã¯80%ä»¥ä¸Šã‚’é”æˆã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/20c7782d-8ffe-4328-8526-700e38df23b5" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9f0e1e3a-6b07-4bcc-be78-e42a1c5d2190" alt="image" loading="lazy"><br><br></p>
<p>`LLM-as-a-Judge` ã¨ã„ã†ç”¨èªã‚’æœ€åˆã«æå”±ã—ãŸã®ã‚‚æœ¬ç ”ç©¶ã¨ãªã‚‹ï¼ˆp.2å‚ç…§ï¼‰</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/881" target="_blank" rel="noopener noreferrer" class="title-link">QLoRA: Efficient Finetuning of Quantized LLMs, Tim Dettmers+, N_A, NeurIPS'23</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€QLoRAã¨ã„ã†åŠ¹ç‡çš„ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã¯ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›ã—ã€48GBã®å˜ä¸€ã®GPUä¸Šã§65Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã¾ãŸã€16ãƒ“ãƒƒãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¶­æŒã—ã¾ã™ã€‚QLoRAã¯ã€å‡çµã•ã‚ŒãŸ4ãƒ“ãƒƒãƒˆé‡å­åŒ–ã•ã‚ŒãŸäº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ã®å‹¾é…ã‚’Low Rank Adaptersï¼ˆLoRAï¼‰ã«é€†ä¼æ’­ã•ã›ã¾ã™ã€‚ç§ãŸã¡ã®æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã§ã‚ã‚‹Guanacoã¯ã€Vicunaãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ä»¥å‰ã«å…¬é–‹ã•ã‚ŒãŸã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã€ChatGPTã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ã®99.3%ã«é”ã—ã¾ã™ã€‚ã¾ãŸã€å˜ä¸€ã®GPUä¸Šã§ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯24æ™‚é–“ã—ã‹ã‹ã‹ã‚Šã¾ã›ã‚“ã€‚QLoRAã¯ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’çŠ ç‰²ã«ã™ã‚‹ã“ã¨ãªããƒ¡ãƒ¢ãƒªã‚’ç¯€ç´„ã™ã‚‹ãŸã‚ã®ã„ãã¤ã‹ã®é©æ–°ã‚’å°å…¥ã—ã¦ã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€4ãƒ“ãƒƒãƒˆNormalFloatï¼ˆNF4ï¼‰ã¨ã„ã†æƒ…å ±ç†è«–çš„ã«æœ€é©ãªæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿å‹ã€ãƒ€ãƒ–ãƒ«é‡å­åŒ–ã«ã‚ˆã‚‹å¹³å‡ãƒ¡ãƒ¢ãƒªãƒ•ãƒƒãƒˆãƒ—ãƒªãƒ³ãƒˆã®å‰Šæ¸›ã€ãŠã‚ˆã³ãƒšãƒ¼ã‚¸ãƒ‰ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªã‚¹ãƒ‘ã‚¤ã‚¯ã®ç®¡ç†ã§ã™ã€‚ç§ãŸã¡ã¯QLoRAã‚’ä½¿ç”¨ã—ã¦1,000ä»¥ä¸Šã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€8ã¤ã®å‘½ä»¤ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ï¼ˆLLaMAã€T5ï¼‰ã€ãŠã‚ˆã³å¾“æ¥ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã¯å®Ÿè¡Œä¸å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆ33BãŠã‚ˆã³65Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼‰ã«ã‚ãŸã‚‹å‘½ä»¤ã®è¿½è·¡ã¨ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®è©³ç´°ãªåˆ†æã‚’æä¾›ã—ã¾ã™ã€‚ç§ãŸã¡ã®çµæœã¯ã€QLoRAã‚’ä½¿ç”¨ã—ã¦å°è¦æ¨¡ãªé«˜å“è³ªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã€ä»¥å‰ã®SoTAã‚ˆã‚Šã‚‚å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã‚‚æœ€å…ˆç«¯ã®çµæœã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€äººé–“ã®è©•ä¾¡ã¨GPT-4ã®è©•ä¾¡ã«åŸºã¥ã„ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®è©³ç´°ãªåˆ†æã‚’æä¾›ã—ã€GPT-4ã®è©•ä¾¡ãŒå®‰ä¾¡ã§åˆç†çš„ãªäººé–“ã®è©•ä¾¡ã®ä»£æ›¿æ‰‹æ®µã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚ã•ã‚‰ã«ã€ç¾åœ¨ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã€ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ã‚’æ­£ç¢ºã«è©•ä¾¡ã™ã‚‹ãŸã‚ã«ã¯ä¿¡é ¼æ€§ãŒãªã„ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚GuanacoãŒChatGPTã¨æ¯”è¼ƒã—ã¦ã©ã“ã§å¤±æ•—ã™ã‚‹ã‹ã‚’ç¤ºã™åˆ†æã‚‚è¡Œã£ã¦ã„ã¾ã™ã€‚ç§ãŸã¡ã¯ã€4ãƒ“ãƒƒãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãŸã‚ã®CUDAã‚«ãƒ¼ãƒãƒ«ã‚’å«ã‚€ã€ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã¨ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å®Ÿè£…: 


<a href="https://github.com/artidoro/qlora" target="_blank" rel="noopener noreferrer">https://github.com/artidoro/qlora</a>


<br>PEFTã«ã‚‚ã‚ã‚‹</p>
<p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1662946722690236417?s=46&t=TDHYK31QiXKxggPzhZbcAQ"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=OUIFPHEgJU&referrer=%5Bthe%20profile%20of%20Ari%20Holtzman%5D(%2Fprofile%3Fid%3D~Ari_Holtzman1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=OUIFPHEgJU&referrer=%5Bthe%20profile%20of%20Ari%20Holtzman%5D(%2Fprofile%3Fid%3D~Ari_Holtzman1)</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/786" target="_blank" rel="noopener noreferrer" class="title-link">Holistic Evaluation of Language Models, Percy Liang+, TMLR'23</a>
<span class="snippet"><span>GPT Summary</span>- è¨€èªãƒ¢ãƒ‡ãƒ«ã®é€æ˜æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ã€Holistic Evaluation of Language Modelsï¼ˆHELMï¼‰ã‚’ææ¡ˆã™ã‚‹ã€‚HELMã§ã¯ã€æ½œåœ¨çš„ãªã‚·ãƒŠãƒªã‚ªã¨ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’åˆ†é¡ã—ã€åºƒç¯„ãªã‚µãƒ–ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¦è©•ä¾¡ã™ã‚‹ã€‚ã•ã‚‰ã«ã€è¤‡æ•°ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã€ä¸»è¦ãªã‚·ãƒŠãƒªã‚ªã”ã¨ã«è©•ä¾¡ã‚’è¡Œã†ã€‚30ã®ä¸»è¦ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’42ã®ã‚·ãƒŠãƒªã‚ªã§è©•ä¾¡ã—ã€HELMä»¥å‰ã«æ¯”ã¹ã¦è©•ä¾¡ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’æ”¹å–„ã—ãŸã€‚HELMã¯ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦åˆ©ç”¨ã•ã‚Œã€æ–°ã—ã„ã‚·ãƒŠãƒªã‚ªã€ãƒ¡ãƒˆãƒªãƒƒã‚¯ã€ãƒ¢ãƒ‡ãƒ«ãŒç¶™ç¶šçš„ã«æ›´æ–°ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=iO4LZibEqW" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=iO4LZibEqW</a>


</p>
<p>HELMã‚’ææ¡ˆã—ãŸç ”ç©¶<br>å½“æ™‚ã®Leaderboardã¯æ—¢ã«deprecatedã§ã‚ã‚Šã€ç¾åœ¨ã¯ä¸‹è¨˜ã‚’å‚ç…§:<br>


<a href="https://crfm.stanford.edu/helm/" target="_blank" rel="noopener noreferrer">https://crfm.stanford.edu/helm/</a>


</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<span class="issue_date">Issue Date: 2023-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer" class="title-link">Textbooks Are All You Need, Suriya Gunasekar+, N_A, arXiv'23</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å°è¦æ¨¡ãªphi-1ã¨ã„ã†æ–°ã—ã„ã‚³ãƒ¼ãƒ‰ç”¨å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç´¹ä»‹ã—ã€8ã¤ã®A100ã§4æ—¥é–“ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸçµæœã€HumanEvalã§pass@1ã®æ­£è§£ç‡50.6ï¼…ã€MBPPã§55.5ï¼…ã‚’é”æˆã—ãŸã“ã¨ã‚’å ±å‘Šã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€phi-1ã¯ã€phi-1-baseã‚„phi-1-smallã¨æ¯”è¼ƒã—ã¦ã€é©šãã¹ãæ–°ã—ã„æ€§è³ªã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚phi-1-smallã¯ã€HumanEvalã§45ï¼…ã‚’é”æˆã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>å‚è€ƒ: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1671643297616654342?s=46&t=JYDYid2m0v7vYaL7jhZYjQ"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ•™ç§‘æ›¸ã®ã‚ˆã†ãªå“è³ªã®è‰¯ã„ãƒ†ã‚­ã‚¹ãƒˆã§äº‹å‰å­¦ç¿’ã™ã‚‹ã¨æ€§èƒ½ãŒå‘ä¸Šã—ï¼ˆã‚°ãƒ©ãƒ•çœŸã‚“ä¸­ï¼‰ã€ã•ã‚‰ã«è‰¯è³ªãªã‚¨ã‚¯ã‚µã‚µã‚¤ã‚ºã§Finetuningã™ã‚‹ã¨ã‚ˆã‚Šæ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ï¼ˆã‚°ãƒ©ãƒ•å³ï¼‰<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9f0b945a-f965-42ae-b5d8-ac464359af35" alt="image" loading="lazy"></p>
<p>æ—¥æœ¬èªè§£èª¬: 


<a href="https://dalab.jp/archives/journal/introduction-textbooks-are-all-you-need/" target="_blank" rel="noopener noreferrer">https://dalab.jp/archives/journal/introduction-textbooks-are-all-you-need/</a>


</p>
<p>ã–ã£ãã‚Šè¨€ã†ã¨ã€æ•™ç§‘æ›¸ã§äº‹å‰å­¦ç¿’ã—ã€ã‚¨ã‚¯ã‚µã‚µã‚¤ã‚ºã§Finetuningã™ã‚‹ã¨æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ï¼ˆ= ã‚ˆã‚Šå¤§ãã„ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®æ€§èƒ½ãŒå¾—ã‚‰ã‚Œã‚‹ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/558" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Consistency Improves Chain of Thought Reasoning in Language Models, Xuezhi Wang+, ICLR'23, 2022.03</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±ä¸€è²«æ€§ã¨ã„ã†æ–°ã—ã„ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ã‚’ææ¡ˆã—ã€chain-of-thought promptingã®æ€§èƒ½ã‚’å‘ä¸Šã€‚å¤šæ§˜ãªæ¨è«–çµŒè·¯ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã€ä¸€è²«ã—ãŸç­”ãˆã‚’é¸æŠã™ã‚‹ã“ã¨ã§ã€GSM8Kã‚„SVAMPãªã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é¡•è‘—ãªæ”¹å–„ã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>self-consistencyã¨å‘¼ã°ã‚Œã‚‹æ–°ãŸãªCoTã®ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã€‚<br><br>ã“ã‚Œã¯ã€é›£ã—ã„reasoningãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§ã¯ã€è¤‡æ•°ã®reasoningã®ãƒ‘ã‚¹ãŒå­˜åœ¨ã™ã‚‹ã¨ã„ã†intuitionã«åŸºã¥ã„ã¦ã„ã‚‹ã€‚<br><br><br><br>self-consistencyã§ã¯ã¾ãšã€æ™®é€šã«CoTã‚’è¡Œã†ã€‚ãã—ã¦greedyã«decodingã™ã‚‹ä»£ã‚ã‚Šã«ã€ä»¥ä¸‹ã®ã‚ˆã†ãªãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿæ–½ã™ã‚‹ï¼š<br><br>1. å¤šæ§˜ãªreasoning pathã‚’LLMã«ç”Ÿæˆã•ã›ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã€‚<br><br>2. ç•°ãªã‚‹reasoning pathã¯ç•°ãªã‚‹final answerã‚’ç”Ÿæˆã™ã‚‹ï¼ˆ= final answer setï¼‰ã€‚<br><br>3. ãã—ã¦ã€æœ€çµ‚çš„ãªanswerã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«ã€reasoning pathã‚’marginalizeã™ã‚‹ã“ã¨ã§ã€final answerã®setã®ä¸­ã§æœ€ã‚‚ä¸€è²«æ€§ã®ã‚ã‚‹å›ç­”ã‚’è¦‹å‡ºã™ã€‚<br><br><br><br>ã“ã‚Œã¯ã€ã‚‚ã—ç•°ãªã‚‹è€ƒãˆæ–¹ã«ã‚ˆã£ã¦åŒã˜å›ç­”ãŒå°ãå‡ºã•ã‚Œã‚‹ã®ã§ã‚ã‚Œã°ã€ãã®æœ€çµ‚çš„ãªå›ç­”ã¯æ­£ã—ã„ã¨ã„ã†çµŒé¨“å‰‡ã«åŸºã¥ã„ã¦ã„ã‚‹ã€‚<br><br>self-consistencyã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã¯ã€è¤‡æ•°ã®reasoning pathã‚’å–å¾—ã—ãŸä¸Šã§ã€æœ€ã‚‚å¤šã„answer a_iã‚’é¸æŠã™ã‚‹ï¼ˆmajority voteï¼‰ã€‚ã“ã‚Œã«ã¯temperature samplingã‚’ç”¨ã„ã‚‹ï¼ˆtemperatureã‚’0.5ã‚„ã‚‰0.7ã«è¨­å®šã—ã¦ã€ã‚ˆã‚Šé«˜ã„ä¿¡é ¼æ€§ã‚’ä¿ã¡ã¤ã¤ã€ã‹ã¤å¤šæ§˜ãªoutputã‚’æ‰‹ã«å…¥ã‚Œã‚‹ï¼‰ã€‚<br><br>temperature samplingã«ã¤ã„ã¦ã¯[ã“ã¡ã‚‰](


<a href="https://openreview.net/pdf?id=rygGQyrFvH)%E3%81%AE%E8%AB%96%E6%96%87%E3%82%92%E5%8F%82%E7%85%A7%E3%81%AE%E3%81%93%E3%81%A8%E3%80%82" target="_blank" rel="noopener noreferrer">https://openreview.net/pdf?id=rygGQyrFvH)ã®è«–æ–‡ã‚’å‚ç…§ã®ã“ã¨ã€‚</a>


<br><br>samplingæ•°ã¯å¢—ã‚„ã›ã°å¢—ã‚„ã™ã»ã©æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ãŒã€å¾ã€…ã«ã‚µãƒã£ã¦ãã‚‹ã€‚ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ•°ã‚’å¢—ã‚„ã™ã»ã©ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã®ã§ã€ãã®è¾ºã¯ã‚³ã‚¹ãƒˆæ„Ÿã¨ã®å…¼ã­åˆã„ã«ãªã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/234754605-6316223f-4290-45d5-bf7c-64675f07d0c3.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/234779335-478f2431-67ea-4b24-9c1b-fa1dd6ac6b45.png" alt="image" loading="lazy"><br><br></p>
<p>Self-consistencyã¯å›ç­”ãŒé–‰ã˜ãŸé›†åˆã§ã‚ã‚‹ã‚ˆã†ãªå•é¡Œã«å¯¾ã—ã¦é©ç”¨å¯èƒ½ã§ã‚ã‚Šã€open-endãªquestionã§ã¯åˆ©ç”¨ã§ããªã„ã“ã¨ã«æ³¨æ„ãŒå¿…è¦ã€‚ãŸã ã—ã€open-endã§ã‚‚å›ç­”é–“ã«ãªã‚“ã‚‰ã‹ã®é–¢ä¿‚æ€§ã‚’è¦‹å‡ºã™ã‚ˆã†ãªæŒ‡æ¨™ãŒã‚ã‚Œã°å®Ÿç¾å¯èƒ½ã¨limitationã§è¨€åŠã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<span class="issue_date">Issue Date: 2023-04-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/518" target="_blank" rel="noopener noreferrer" class="title-link">REACT : SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS, Yao+, Princeton University and Google brain, ICLR'23</a>
&lt;span class=\"snippet\"&gt;<span>Comment</span><p># æ¦‚è¦<br><br>äººé–“ã¯æ¨è«–ã¨è¡Œå‹•ã‚’ã‚·ãƒŠã‚¸ãƒ¼ã•ã›ã‚‹ã“ã¨ã§ã€ã•ã¾ã–ã¾ãªæ„æ€æ±ºå®šã‚’è¡Œãˆã‚‹ã€‚è¿‘å¹´ã§ã¯è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚Šè¨€èªã«ã‚ˆã‚‹æ¨è«–ã‚’æ„æ€æ±ºå®šã«çµ„ã¿åˆã‚ã›ã‚‹å¯èƒ½æ€§ãŒç¤ºã•ã‚Œã¦ããŸã€‚ãŸã¨ãˆã°ã€ã‚¿ã‚¹ã‚¯ã‚’ã“ãªã™ãŸã‚ã®æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’LLMãŒå°ã‘ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ããŸï¼ˆChain-of-Thoughtï¼‰ãŒã€CoTã¯å¤–éƒ¨ãƒªã‚½ãƒ¼ã‚¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„ãŸã‚çŸ¥è­˜ãŒã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§ããšã€äº‹å¾Œçš„ã«æ¨è«–ã‚’è¡Œã†ãŸã‚hallucinationã‚„ã‚¨ãƒ©ãƒ¼ã®ä¼æ¬ãŒç”Ÿã˜ã‚‹ã€‚ä¸€æ–¹ã§ã€äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’interactiveãªç’°å¢ƒã«ãŠã„ã¦è¨ˆç”»ã¨è¡Œå‹•ã«åˆ©ç”¨ã™ã‚‹ç ”ç©¶ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ãŒã€ã“ã‚Œã‚‰ã®ç ”ç©¶ã§ã¯ã€é«˜ãƒ¬ãƒ™ãƒ«ã®ç›®æ¨™ã«ã¤ã„ã¦æŠ½è±¡çš„ã«æ¨è«–ã—ãŸã‚Šã€è¡Œå‹•ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ã®ä½œæ¥­è¨˜æ†¶ã‚’ç¶­æŒã—ãŸã‚Šã™ã‚‹ãŸã‚ã«è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ã¦ã„ãªã„ã€‚æ¨è«–ã¨è¡Œå‹•ã‚’ä¸€èˆ¬çš„ãªèª²é¡Œè§£æ±ºã®ãŸã‚ã«ã©ã®ã‚ˆã†ã«ã‚·ãƒŠã‚¸ãƒ¼ã§ãã‚‹ã‹ã€ã¾ãŸãã®ã‚ˆã†ãªã‚·ãƒŠã‚¸ãƒ¼ãŒå˜ç‹¬ã§æ¨è«–ã‚„è¡Œå‹•ã‚’å®Ÿæ–½ã—ãŸå ´åˆã¨æ¯”è¼ƒã—ã¦ã©ã®ã‚ˆã†ãªåˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™ã‹ã«ã¤ã„ã¦ç ”ç©¶ã•ã‚Œã¦ã„ãªã„ã€‚<br><br>ãã“ã§ã€REACTã‚’ææ¡ˆã€‚REACTã¯æ¨è«–ã¨è¡Œå‹•ã‚’LLMã¨çµ„ã¿åˆã‚ã›ã¦ã€å¤šæ§˜ãªæ¨è«–ã‚„æ„æ€æ±ºå®šã‚¿ã‚¹ã‚¯ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®ä¸€èˆ¬çš„ãªæ çµ„ã¿ã§ã‚ã‚Šã€æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’äº¤äº’ã«ç”Ÿæˆã™ã‚‹ãŸã‚ã€å‹•çš„ã«æ¨è«–ã‚’å®Ÿè¡Œã—ã¦è¡Œå‹•ã™ã‚‹ãŸã‚ã®å¤§ã¾ã‹ãªè¨ˆç”»ã‚’ä½œæˆã€ç¶­æŒã€èª¿æ•´ã§ãã‚‹ã¨åŒæ™‚ã«ã€wikipediaãªã©ã®å¤–éƒ¨ã‚½ãƒ¼ã‚¹ã¨ã‚„ã‚Šã¨ã‚Šã—ã¦è¿½åŠ æƒ…å ±ã‚’åé›†ã—ã€æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒå¯èƒ½ã¨ãªã‚‹ã€‚<br><br><br><br>- è¦ã¯ã„ã¾ã¾ã§ã¯Generalãªã‚¿ã‚¹ã‚¯è§£æ±ºãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã¯ã€æ¨è«–ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆã¯ç‹¬ç«‹ã«ã—ã‹ã‚„ã‚‰ã‚Œã¦ã“ãªã‹ã£ãŸã‘ã©ã€æ¨è«–ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’äº¤äº’ä½œç”¨ã•ã›ã‚‹ã“ã¨ã«ã¤ã„ã¦ç ”ç©¶ã—ãŸã‚ˆ<br><br>- ãã—ãŸã‚‰æ€§èƒ½ãŒã¨ã£ã¦ã‚‚ã‚ãŒã£ãŸã‚ˆ<br><br>- reasoningã‚’äººé–“ãŒç·¨é›†ã™ã‚Œã°ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã‚‚ã§ãã‚‹ã‚ˆã€€ã¨ã„ã†æ„Ÿã˜<br><br><br><br># ã‚¤ãƒ³ãƒˆãƒ­<br><br>äººé–“ã¯æ¨è«–ã¨è¡Œå‹•ã®ç·Šå¯†ãªã‚·ãƒŠã‚¸ãƒ¼ã«ã‚ˆã£ã¦ã€ä¸ç¢ºå®ŸãªçŠ¶æ³ã«é­é‡ã—ã¦ã‚‚é©åˆ‡ãªæ„æ€æ±ºå®šãŒè¡Œãˆã‚‹ã€‚ãŸã¨ãˆã°ã€ä»»æ„ã®2ã¤ã®ç‰¹å®šã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®é–“ã§ã€é€²è¡ŒçŠ¶æ³ã‚’ãƒˆãƒ¬ãƒ¼ã‚¹ã™ã‚‹ãŸã‚ã«è¨€èªã§æ¨è«–ã—ãŸã‚Šï¼ˆã™ã¹ã¦åˆ‡ã‚Šçµ‚ã‚ã£ãŸã‹ã‚‰ãŠæ¹¯ã‚’æ²¸ã‹ã™å¿…è¦ãŒã‚ã‚‹ï¼‰ã€ä¾‹å¤–ã‚’å‡¦ç†ã—ãŸã‚Šã€çŠ¶æ³ã«å¿œã˜ã¦è¨ˆç”»ã‚’èª¿æ•´ã—ãŸã‚Šã™ã‚‹ï¼ˆå¡©ãŒãªã„ã‹ã‚‰ä»£ã‚ã‚Šã«é†¤æ²¹ã¨èƒ¡æ¤’ã‚’ä½¿ãŠã†ï¼‰ã€‚ã¾ãŸã€æ¨è«–ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€ç–‘å•ï¼ˆã„ã¾ã©ã‚“ãªæ–™ç†ã‚’ä½œã‚‹ã“ã¨ãŒã§ãã‚‹ã ã‚ã†ã‹ï¼Ÿï¼‰ã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã«ã€è¡Œå‹•ï¼ˆæ–™ç†æœ¬ã‚’é–‹ã„ã¦ãƒ¬ã‚·ãƒ”ã‚’èª­ã‚“ã§ã€å†·è”µåº«ã‚’é–‹ã„ã¦ææ–™ã‚’ç¢ºç¢ºèªã—ãŸã‚Šï¼‰ã‚’ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã€‚<br><br><br><br>è¿‘å¹´ã®ç ”ç©¶ã§ã¯è¨€èªã§ã®æ¨è«–ã‚’ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªæ„æ€æ±ºå®šã‚’çµ„ã¿åˆã‚ã›ã‚‹å¯èƒ½æ€§ã«ã¤ã„ã¦ã®ãƒ’ãƒ³ãƒˆãŒå¾—ã‚‰ã‚Œã¦ããŸã€‚ä¸€ã¤ã¯ã€é©åˆ‡ã«Promptingã•ã‚ŒãŸLLMãŒæ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’å®Ÿè¡Œã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã¨ã¯ã€è§£æ±ºç­–ã«åˆ°é”ã™ã‚‹ãŸã‚ã®ä¸€é€£ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’çµŒã¦æ¨è«–ã‚’ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ã‚»ã‚¹ã®ã“ã¨ã§ã‚ã‚‹ã€‚ã—ã‹ã—ãªãŒã‚‰Chain-of-thoughytã¯ã€ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒå¤–ç•Œå¯¾ã—ã¦groundingã§ããšã€å†…éƒ¨è¡¨ç¾ã®ã¿ã«åŸºã¥ã„æ€è€ƒã‚’ç”Ÿæˆã™ã‚‹ãŸã‚é™ç•ŒãŒã‚ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šãƒ¢ãƒ‡ãƒ«ãŒäº‹å¾Œå¯¾å¿œçš„ã«æ¨è«–ã—ãŸã‚Šã€å¤–éƒ¨æƒ…å ±ã«åŸºã¥ã„ã¦çŸ¥è­˜ã‚’æ›´æ–°ã—ãŸã‚Šã§ããªã„ãŸã‚ã€æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ä¸­ã«hallucinationã‚„ã‚¨ãƒ©ãƒ¼ã®ä¼æ¬ãªã©ã®å•é¡ŒãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒç”Ÿã˜ã‚‹ã€‚<br><br>ä¸€æ–¹ã€è¿‘å¹´ã®ç ”ç©¶ã§ã¯äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’interactiveãªç’°å¢ƒã«ãŠã„ã¦è¨ˆç”»ã¨è¡Œå‹•ã«åˆ©ç”¨ã™ã‚‹ç ”ç©¶ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã€‚ã“ã‚Œã‚‰ã®ç ”ç©¶ã§ã¯ã€é€šå¸¸ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªè¦³æ¸¬çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ã¾ãŸã¯ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆã—ã€ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’åˆ©ç”¨ã—ã¦ãã‚Œã‚‰ã‚’é¸æŠã¾ãŸã¯å®Ÿè¡Œã™ã‚‹ã€‚ãŸã ã—ã€ã“ã‚Œã‚‰ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯é«˜ãƒ¬ãƒ™ãƒ«ã®ç›®æ¨™ã«ã¤ã„ã¦æŠ½è±¡çš„ã«æ¨è«–ã—ãŸã‚Šã€è¡Œå‹•ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ã®ä½œæ¥­è¨˜æ†¶ã‚’ç¶­æŒã—ãŸã‚Šã™ã‚‹ãŸã‚ã«è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ã¦ã„ãªã„ã€‚<br><br>æ¨è«–ã¨è¡Œå‹•ã‚’ä¸€èˆ¬çš„ãªèª²é¡Œè§£æ±ºã®ãŸã‚ã«ã©ã®ã‚ˆã†ã«ã‚·ãƒŠã‚¸ãƒ¼ã§ãã‚‹ã‹ã€ã¾ãŸãã®ã‚ˆã†ãªã‚·ãƒŠã‚¸ãƒ¼ãŒå˜ç‹¬ã§æ¨è«–ã‚„è¡Œå‹•ã‚’å®Ÿæ–½ã—ãŸå ´åˆã¨æ¯”è¼ƒã—ã¦ã©ã®ã‚ˆã†ãªåˆ©ç›Šã‚’ã‚‚ãŸã‚‰ã™ã‹ã«ã¤ã„ã¦ç ”ç©¶ã•ã‚Œã¦ã„ãªã„ã€‚<br><br><br><br>LLMã«ãŠã‘ã‚‹æ¨è«–ã¨è¡Œå‹•ã‚’çµ„ã¿åˆã‚ã›ã¦ã€è¨€èªæ¨è«–ã¨æ„æ€æ±ºå®šã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã™ã‚‹REACTã¨å‘¼ã°ã‚Œã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚REACTã§ã¯ã€æ¨è«–ã¨è¡Œå‹•ã®ç›¸ä¹—åŠ¹æœã‚’é«˜ã‚ã‚‹ã“ã¨ãŒå¯èƒ½ã€‚æ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã«ã‚ˆã‚Šã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ã‚’èª˜ç™ºã€è¿½è·¡ã€æ›´æ–°ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯å¤–éƒ¨ã‚½ãƒ¼ã‚¹ã¨é€£æºã—ã¦è¿½åŠ æƒ…å ±ã‚’åé›†ã§ãã‚‹ã€‚<br><br><br><br>REACTã¯æ¨è«–ã¨è¡Œå‹•ã‚’LLMã¨çµ„ã¿åˆã‚ã›ã¦ã€å¤šæ§˜ãªæ¨è«–ã‚„æ„æ€æ±ºå®šã‚¿ã‚¹ã‚¯ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®ä¸€èˆ¬çš„ãªæ çµ„ã¿ã§ã‚ã‚‹ã€‚REACTã®promptã¯LLMã«verbalãªæ¨è«–ãƒˆãƒ¬ãƒ¼ã‚¹ã¨ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’äº¤äº’ã«ç”Ÿæˆã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯å‹•çš„ãªæ¨è«–ã‚’å®Ÿè¡Œã—ã¦è¡Œå‹•ã™ã‚‹ãŸã‚ã®å¤§ã¾ã‹ãªè¨ˆç”»ã‚’ä½œæˆã€ç¶­æŒã€èª¿æ•´ã§ãã‚‹ã¨åŒæ™‚ã«ã€wikipediaãªã©ã®å¤–éƒ¨ã‚½ãƒ¼ã‚¹ã¨ã‚„ã‚Šã¨ã‚Šã—ã¦è¿½åŠ æƒ…å ±ã‚’åé›†ã—ã€æ¨è«–ãƒ—ãƒ­ã‚»ã‚¹ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒå¯èƒ½ã¨ãªã‚‹ã€‚<br><br><br><br># æ‰‹æ³•<br><br>å¤‰æ•°ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ï¼š<br><br>- O\_t: Observertion on time t<br><br>- a\_t: Action on time t<br><br>- c\_t: context, i.e. \(o\_1, a\_1, o\_2, a\_2, ..., a\_t-1, o\_t)<br><br>- policy pi\(a\_t | c\_t): Action Spaceã‹ã‚‰ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠã™ã‚‹ãƒãƒªã‚·ãƒ¼<br><br>- A: Action Space<br><br>- O: Observation Space<br><br><br><br>æ™®é€šã¯c\_tãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ãƒãƒªã‚·ãƒ¼ã«å¾“ã„Aã‹ã‚‰a\_tã‚’é¸æŠã—ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡Œã„ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®çµæœo\_tã‚’å¾—ã¦ã€c\_t+1ã‚’æ§‹æˆã™ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ã¦ã„ãã€‚<br><br><br><br>ã“ã®ã¨ãã€REACTã¯Aã‚’A âˆª Lã«æ‹¡å¼µã—ã™ã‚‹ã€‚ã“ã“ã§ã€Lã¯Language spaceã§ã‚ã‚‹ã€‚Lã«ã¯Action a\_hatãŒå«ã¾ã‚Œã€a\_hatã¯ç’°å¢ƒã«å¯¾ã—ã¦ä½œç”¨ã‚’ã—ãªã„ã€‚å˜ç´”ã«thought, ã‚ã‚‹ã„ã¯ reasoning traceã‚’å®Ÿæ–½ã—ã€ç¾åœ¨ã®context c\_tã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã«æœ‰ç”¨ãªæƒ…å ±ã‚’æ§‹æˆã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã™ã‚‹ã€‚Lã¯unlimitedãªã®ã§ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã‚‹ã€‚ä»Šå›ã¯PaLM-540Bï¼ˆc.f. GPT3ã¯175Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰ãŒåˆ©ç”¨ã•ã‚Œã€few-shotã®in-context exampleã‚’ä¸ãˆã‚‹ã“ã¨ã§æ¨è«–ã‚’è¡Œã†ã€‚ãã‚Œãã‚Œã®in-context exampleã¯ã€action, thoughtsãã—ã¦observationã®trajectoryã‚’ä¸ãˆã‚‹ã€‚<br><br><br><br>æ¨è«–ãŒé‡è¦ãªã‚¿ã‚¹ã‚¯ã§ã¯ã€thoughts-action-observationã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰æˆã‚‹task-solving trajectoryã‚’ç”Ÿæˆã™ã‚‹ã€‚ä¸€æ–¹ã€å¤šæ•°ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä¼´ã†å¯èƒ½æ€§ãŒã‚ã‚‹æ„æ€æ±ºå®šã‚¿ã‚¹ã‚¯ã§ã¯ã€thoughtsã®ã¿ã‚’è¡Œã†ã“ã¨ã‚’task-solving trajectoryä¸­ã®ä»»æ„ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã€è‡ªåˆ†ã§åˆ¤æ–­ã—ã¦è¡Œã†ã“ã¨ãŒã§ãã‚‹ã€‚<br><br><br><br>æ„æ€æ±ºå®šã¨æ¨è«–èƒ½åŠ›ãŒLLMã«ã‚ˆã£ã¦ã‚‚ãŸã‚‰ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€REACTã¯4ã¤ã®uniqueãªç‰¹å¾´ã‚’æŒã¤ï¼š<br><br>- ç›´æ„Ÿçš„ã§ç°¡å˜ãªãƒ‡ã‚¶ã‚¤ãƒ³<br><br>  - REACTã®promptã¯äººé–“ã®ã‚¢ãƒãƒ†ãƒ¼ã‚¿ãŒã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒˆãƒƒãƒ—ã«æ€è€ƒã‚’è¨€èªã§è¨˜è¿°ã™ã‚‹ã‚ˆã†ãªã‚¹ãƒˆãƒ¬ãƒ¼ãƒˆãªã‚‚ã®ã§ã‚ã‚Šã€ad-hocãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®é¸æŠã€æ€è€ƒã®ãƒ‡ã‚¶ã‚¤ãƒ³ã€äº‹ä¾‹ã®é¸å®šãªã©ãŒå¿…è¦ãªã„ã€‚<br><br>- ä¸€èˆ¬çš„ã§æŸ”è»Ÿæ€§ãŒé«˜ã„<br><br>  - æŸ”è»Ÿãª thought spaceã¨ thought-actionã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ã‚ˆã‚Šã€REACTã¯ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã«ã‚‚æŸ”è»Ÿã«å¯¾å¿œã§ãã‚‹<br><br>- é«˜æ€§èƒ½ã§ãƒ­ãƒã‚¹ãƒˆ<br><br>  - REACTã¯1-6å€‹ã®äº‹ä¾‹ã«ã‚ˆã£ã¦ã€æ–°ãŸãªã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹å¼·åŠ›ãªæ±åŒ–ã‚’ç¤ºã™ã€‚ãã—ã¦æ¨è«–ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã¿ã‚’è¡Œã†ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚REACTã¯finetuningã®æ–§ç³»ã‚‚å¾—ã‚‹ã“ã¨ãŒã§ãã€promptã®é¸æŠã«å¯¾ã—ã¦REACTã®æ€§èƒ½ã¯robustã§ã‚ã‚‹ã€‚<br><br>- äººé–“ã«ã‚ˆã‚‹èª¿æ•´ã¨æ“ä½œãŒå¯èƒ½<br><br>  - REACTã¯ã€è§£é‡ˆå¯èƒ½ãªæ„æ€æ±ºå®šã¨æ¨è«–ã®sequenceã‚’å‰æã¨ã—ã¦ã„ã‚‹ãŸã‚ã€äººé–“ã¯ç°¡å˜ã«æ¨è«–ã‚„äº‹å®Ÿã®æ­£ã—ã•ã‚’æ¤œè¨¼ã§ãã‚‹ã€‚åŠ ãˆã¦ã€thoughtsã‚’ç·¨é›†ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ã€mäººé–“ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¡Œå‹•ã‚’åˆ¶å¾¡ã€ã‚ã‚‹ã„ã¯ä¿®æ­£ã§ãã‚‹ã€‚<br><br><br><br># KNOWLEDGE INTENSIVE REASONING TASKS</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<a class="button" href="articles/4D%20(Video).html" target="_blank" rel="noopener noreferrer">#4D (Video)</a>
<span class="issue_date">Issue Date: 2025-10-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3294" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Video Diffusion Models, Jonathan Ho+, arXiv'22, 2022.04</a>
<span class="snippet"><span>GPT Summary</span>- é«˜å¿ å®Ÿåº¦ã§ä¸€è²«ã—ãŸå‹•ç”»ç”Ÿæˆã®ãŸã‚ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã€‚ç”»åƒã¨å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚’å…±åŒã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€æœ€é©åŒ–ã‚’åŠ é€Ÿã€‚æ–°ã—ã„æ¡ä»¶ä»˜ãã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æŠ€è¡“ã«ã‚ˆã‚Šã€é•·ãé«˜è§£åƒåº¦ã®å‹•ç”»ç”Ÿæˆã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã€‚å¤§è¦æ¨¡ãªãƒ†ã‚­ã‚¹ãƒˆæ¡ä»¶ä»˜ãå‹•ç”»ç”Ÿæˆã‚¿ã‚¹ã‚¯ã§ã®åˆæœŸçµæœã¨ã€æ—¢å­˜ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®æœ€å…ˆç«¯çµæœã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Surveyã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3295" target="_blank" rel="noopener noreferrer">[Paper Note] Video Diffusion Models: A Survey, Andrew Melnik+, TMLR'24, 2024.05</a>
<br><br></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<a class="button" href="articles/VariationalAutoEncoder.html" target="_blank" rel="noopener noreferrer">#VariationalAutoEncoder</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/ImageSynthesis.html" target="_blank" rel="noopener noreferrer">#ImageSynthesis</a>
<a class="button" href="articles/U-Net.html" target="_blank" rel="noopener noreferrer">#U-Net</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3208" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] High-Resolution Image Synthesis with Latent Diffusion Models, Robin Rombach+, CVPR'22, 2021.12</a>
<span class="snippet"><span>GPT Summary</span>- æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ï¼ˆDMsï¼‰ã¯ã€é€æ¬¡çš„ãªãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’ç”¨ã„ã¦ç”»åƒç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã‚’åŠ¹ç‡åŒ–ã—ã€æœ€å…ˆç«¯ã®åˆæˆçµæœã‚’é”æˆã€‚å¾“æ¥ã®ãƒ”ã‚¯ã‚»ãƒ«ç©ºé–“ã§ã®è¨“ç·´ã«æ¯”ã¹ã€å¼·åŠ›ãªäº‹å‰è¨“ç·´ã•ã‚ŒãŸã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®æ½œåœ¨ç©ºé–“ã§ã®è¨“ç·´ã«ã‚ˆã‚Šã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’å‰Šæ¸›ã—ã¤ã¤è¦–è¦šçš„å¿ å®Ÿåº¦ã‚’å‘ä¸Šã€‚ã‚¯ãƒ­ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å±¤ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€ãƒ†ã‚­ã‚¹ãƒˆã‚„ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã«åŸºã¥ãæŸ”è»Ÿãªç”ŸæˆãŒå¯èƒ½ã¨ãªã‚Šã€ç”»åƒã‚¤ãƒ³ãƒšã‚¤ãƒ³ãƒ†ã‚£ãƒ³ã‚°ã‚„ç„¡æ¡ä»¶ç”»åƒç”Ÿæˆãªã©ã§ç«¶äº‰åŠ›ã®ã‚ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã€‚</span>
<span class="snippet"><span>Comment</span><p>ã“ã“ã‹ã‚‰textç­‰ã«ã‚ˆã‚‹æ¡ä»¶ä»˜ã‘ã‚’ã—ãŸä¸Šã§ã®ç”ŸæˆãŒå¯èƒ½ã«ãªã£ãŸï¼ˆã‚‰ã—ã„ï¼‰</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3204" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Classifier-Free Diffusion Guidance, Jonathan Ho+, arXiv'22, 2022.07</a>
<span class="snippet"><span>GPT Summary</span>- åˆ†é¡å™¨ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã¯æ¡ä»¶ä»˜ãæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã§ã€ãƒ¢ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸ã¨ã‚µãƒ³ãƒ—ãƒ«å¿ å®Ÿåº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å›³ã‚‹ã€‚è‘—è€…ã¯ã€åˆ†é¡å™¨ãªã—ã§ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ã“ã‚Œã‚’åˆ†é¡å™¨ãƒ•ãƒªãƒ¼ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã¨å‘¼ã¶ã€‚æ¡ä»¶ä»˜ããŠã‚ˆã³ç„¡æ¡ä»¶ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’å…±åŒã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€ã‚µãƒ³ãƒ—ãƒ«å“è³ªã¨å¤šæ§˜æ€§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’é”æˆã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://qiita.com/UMAboogie/items/160c1159811743c49d99" target="_blank" rel="noopener noreferrer">https://qiita.com/UMAboogie/items/160c1159811743c49d99</a>


</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3205" target="_blank" rel="noopener noreferrer">[Paper Note] Diffusion Models Beat GANs on Image Synthesis, Prafulla Dhariwal+, NeurIPS'21 Spotlight, 2021.05</a>
</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="articles/PseudoLabeling.html" target="_blank" rel="noopener noreferrer">#PseudoLabeling</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2903" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Constitutional AI: Harmlessness from AI Feedback, Yuntao Bai+, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ã€Œæ†²æ³•çš„AIã€ã‚’ç”¨ã„ã¦ã€äººé–“ã®ãƒ©ãƒ™ãƒ«ãªã—ã§ç„¡å®³ãªAIã‚’è¨“ç·´ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã€‚ç›£è¦–å­¦ç¿’ã¨å¼·åŒ–å­¦ç¿’ã®2ãƒ•ã‚§ãƒ¼ã‚ºã‚’çµŒã¦ã€è‡ªå·±æ‰¹è©•ã¨ä¿®æ­£ã‚’é€šã˜ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã€å—œå¥½ãƒ¢ãƒ‡ãƒ«ã‚’å ±é…¬ä¿¡å·ã¨ã—ã¦å¼·åŒ–å­¦ç¿’ã‚’è¡Œã†ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€æœ‰å®³ãªã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ã‚‚å¯¾è©±ã§ãã‚‹ç„¡å®³ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’å®Ÿç¾ã—ã€AIã®æ„æ€æ±ºå®šã®é€æ˜æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ï¼ˆéƒ¨åˆ†çš„ã«ã—ã‹èª­ã‚ã¦ã„ãªã„ãŒï¼‰<br>æœ‰å®³ãªpromptã«å¯¾ã—ã¦LLMã«åˆæœŸã®å¿œç­”ã‚’ç”Ÿæˆã•ã›ã€iterativeã«critiqueã¨revisionã‚’ç¹°ã‚Šè¿”ã—ã¦[^1]ã€ã‚ˆã‚Šç„¡å®³ãªå¿œç­”ã‚’ç”Ÿæˆã€‚ã“ã®æ–¹æ³•ã§ã¯iterationã‚’ã—ãªãŒã‚‰ç”ŸæˆçµæœãŒæ”¹å®šã•ã‚Œã¦ã„ãã®ã§ã€å¾Œæ®µã®Reward Modelã®ãŸã‚ã®å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ãƒ•ã‚§ãƒ¼ã‚ºã§ãƒˆãƒ¼ã‚¯ãƒ³é‡ã‚’ç¯€ç´„ã™ã‚‹ãŸã‚ã«ã€ç”Ÿæˆã•ã‚ŒãŸã‚ˆã‚Šç„¡å®³ãªå¿œç­”ã¨å…ƒã¨ãªã‚‹promptã‚’ç”¨ã„ã¦ã€ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’SFTã€‚ã“ã‚Œã«ã‚ˆã‚Šãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›åˆ†å¸ƒãŒã‚ˆã‚Šç„¡å®³ãªå¿œç­”ã‚’ã™ã‚‹ã‚ˆã†ãªæ–¹å‘æ€§ã«èª¿æ•´ã•ã‚Œã€ã‹ã¤ï¼ˆiterationã‚’ç¹°ã‚Šè¿”ã™ã“ã¨ãªãï¼‰ç›´æ¥çš„ã«ã‚ˆã‚Šç„¡å®³ãªå¿œç­”ã‚’ç”Ÿæˆã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã®ã§tokené‡ãŒç¯€ç´„ã§ãã‚‹ã€‚ã“ã®ãƒ•ã‚§ãƒ¼ã‚ºã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’SL-CAIã¨å‘¼ã¶ã€‚<br><br>ç¶šã„ã¦ã€SL-CAIã«å¯¾ã—ã¦åŒæ§˜ã®æœ‰å®³ãªpromptã‚’å…¥åŠ›ã—ã¦ã€è¤‡æ•°ã®å¿œç­”ã‚’ç”Ÿæˆã•ã›ã‚‹ã€‚ç”Ÿæˆã•ã‚ŒãŸå¿œç­”ã‚’Multiple Choice Questionã®å½¢å¼ã«ã—ã€Constitutional Principleã«åŸºã¥ãpromptingã«ã‚ˆã‚Šã€æœ€ã‚‚æœ›ã¾ã—ã„å¿œç­”ã‚’LLMã«ã‚ˆã£ã¦é¸æŠã•ã›ã‚‹ã“ã¨ã§ã€å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚’ç²å¾—ã™ã‚‹ã€‚ã“ã®å—œå¥½ãƒ‡ãƒ¼ã‚¿ï¼ˆã¨äººæ‰‹ã§å®šç¾©ã•ã‚ŒãŸhelpfulnessã«åŸºã¥ããƒ‡ãƒ¼ã‚¿ï¼‰ã‚’ç”¨ã„ã¦Reward Modelã‚’è¨“ç·´ã—RLã‚’å®Ÿæ–½ã™ã‚‹ã€‚<br><br>ã“ã®æ‰‹æ³•ã¯ã€å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚’äººé–“ãŒãƒ©ãƒ™ãƒªãƒ³ã‚°ã™ã‚‹ã®ã§ã¯ãªãã€AIã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ã‚ˆã‚Šãƒ©ãƒ™ãƒªãƒ³ã‚°ã™ã‚‹ãŸã‚ã€Reinforcement Learning from AI Feedback (RLAIF)ã¨å‘¼ã°ã‚Œã‚‹ã€‚<br><br>Harmfulnessä»¥å¤–ã®åˆ†é‡ã«ã‚‚å¿œç”¨å¯èƒ½ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/72305618-d397-4471-8648-7771d371ca43" alt="image" loading="lazy"><br><br>[^1]: ã“ã®æ“ä½œã¯ãƒ¢ãƒ‡ãƒ«ã®æœ›ã¾ã—ã„æŒ™å‹•ã‚’äººæ‰‹ã§å®šç¾©ã—ãŸãƒ«ãƒ¼ãƒ–ãƒªãƒƒã‚¯ã«åŸºã¥ã„ãŸè¤‡æ•°ã®prompt (Constitutional Principles) ã‚’ç”¨ã„ã¦å®Ÿæ–½ã•ã‚Œã‚‹ã€‚å…·ä½“çš„ãªpromptã¯Appendix Cã‚’å‚ç…§ã€‚</p>
<p>å…ˆè¡Œç ”ç©¶:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2902" target="_blank" rel="noopener noreferrer">[Paper Note] Training a Helpful and Harmless Assistant with Reinforcement Learning
  from Human Feedback, Yuntao Bai+, arXiv'22</a>
</p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2860" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Emergent Abilities of Large Language Models, Jason Wei+, TMLR'22</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚¢ãƒƒãƒ—ã¯æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŒã€ã€Œå‡ºç¾èƒ½åŠ›ã€ã¨å‘¼ã°ã‚Œã‚‹äºˆæ¸¬ä¸å¯èƒ½ãªç¾è±¡ãŒå­˜åœ¨ã™ã‚‹ã€‚ã“ã‚Œã¯å°å‹ãƒ¢ãƒ‡ãƒ«ã«ã¯ãªã„èƒ½åŠ›ã§ã‚ã‚Šã€ã•ã‚‰ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’æ‹¡å¤§ã™ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=yzkSU5zdwD" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=yzkSU5zdwD</a>


</p>
<p>å‰µç™ºèƒ½åŠ›ï¼ˆæœ€è¿‘ã“ã®ç”¨èªã‚’ç›®ã«ã™ã‚‹æ©Ÿä¼šãŒæ¸›ã£ãŸã‚ˆã†ãªæ°—ãŒã™ã‚‹ï¼‰</p></span><br><br>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/Deduplication.html" target="_blank" rel="noopener noreferrer">#Deduplication</a>
<span class="issue_date">Issue Date: 2025-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2689" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deduplicating Training Data Makes Language Models Better, Katherine Lee+, ACL'22</a>
<span class="snippet"><span>GPT Summary</span>- æ—¢å­˜ã®è¨€èªãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯é‡è¤‡ã—ãŸä¾‹ãŒå¤šãå«ã¾ã‚Œã€è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã®1%ä»¥ä¸ŠãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚³ãƒ”ãƒ¼ã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€é‡è¤‡æ’é™¤ãƒ„ãƒ¼ãƒ«ã‚’é–‹ç™ºã—ã€C4ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ã¯60,000å›ä»¥ä¸Šç¹°ã‚Šè¿”ã•ã‚Œã‚‹æ–‡ã‚’å‰Šé™¤ã€‚é‡è¤‡ã‚’æ’é™¤ã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®è¨˜æ†¶ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ã‚’10å€æ¸›å°‘ã•ã›ã€ç²¾åº¦ã‚’ç¶­æŒã—ã¤ã¤è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—ã‚’å‰Šæ¸›ã€‚ã¾ãŸã€è¨“ç·´ã¨ãƒ†ã‚¹ãƒˆã®é‡è¤‡ã‚’æ¸›ã‚‰ã—ã€ã‚ˆã‚Šæ­£ç¢ºãªè©•ä¾¡ã‚’å®Ÿç¾ã€‚ç ”ç©¶ã®å†ç¾ã¨ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ä¸‹è¨˜ã‚¹ãƒ©ã‚¤ãƒ‰ã®p.9ã«ã¾ã¨ã‚ãŒè¨˜è¿°ã•ã‚Œã¦ã„ã‚‹:<br>


<a href="https://speakerdeck.com/takase/snlp2023-beyond-neural-scaling-laws?slide=9" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/takase/snlp2023-beyond-neural-scaling-laws?slide=9</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2025-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2597" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A ConvNet for the 2020s, Zhuang Liu+, arXiv'22</a>
<span class="snippet"><span>GPT Summary</span>- ConvNetã¯Vision Transformersã®ç™»å ´ã«ã‚ˆã‚Šåœ°ä½ã‚’å¤±ã£ãŸãŒã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®åŠ¹æœã¯ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®å„ªä½æ€§ã«ä¾å­˜ã—ã¦ã„ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€ConvNetã®é™ç•Œã‚’ãƒ†ã‚¹ãƒˆã—ã€ConvNeXtã¨ã„ã†æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã€‚ConvNeXtã¯æ¨™æº–çš„ãªConvNetãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã¿ã§æ§‹æˆã•ã‚Œã€ç²¾åº¦ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã§ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¨ç«¶äº‰ã—ã€ImageNetã§87.8%ã®ç²¾åº¦ã‚’é”æˆã—ã€COCOæ¤œå‡ºãŠã‚ˆã³ADE20Kã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§Swin Transformersã‚’ä¸Šå›ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ConvNeXt</p></span><br><br>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2311" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Matryoshka Representation Learning, Aditya Kusupati+, NeurIPS'22</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒˆãƒªãƒ§ãƒ¼ã‚·ã‚«è¡¨ç¾å­¦ç¿’ï¼ˆMRLï¼‰ã¯ã€ç•°ãªã‚‹è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã«é©å¿œå¯èƒ½ãªæŸ”è»Ÿãªè¡¨ç¾ã‚’è¨­è¨ˆã™ã‚‹æ‰‹æ³•ã§ã‚ã‚Šã€æ—¢å­˜ã®è¡¨ç¾å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æœ€å°é™ã«ä¿®æ­£ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚MRLã¯ã€ç²—ã‹ã‚‰ç´°ã¸ã®è¡¨ç¾ã‚’å­¦ç¿’ã—ã€ImageNet-1Kåˆ†é¡ã§æœ€å¤§14å€å°ã•ã„åŸ‹ã‚è¾¼ã¿ã‚µã‚¤ã‚ºã‚’æä¾›ã—ã€å®Ÿä¸–ç•Œã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã‚’å®Ÿç¾ã—ã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆåˆ†é¡ã§ç²¾åº¦å‘ä¸Šã‚’é”æˆã—ã¾ã™ã€‚MRLã¯è¦–è¦šã€è¦–è¦š+è¨€èªã€è¨€èªã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«ã‚ãŸã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«æ‹¡å¼µå¯èƒ½ã§ã€ã‚³ãƒ¼ãƒ‰ã¨ãƒ¢ãƒ‡ãƒ«ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://speakerdeck.com/hpprc/lun-jiang-zi-liao-matryoshka-representation-learning" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/hpprc/lun-jiang-zi-liao-matryoshka-representation-learning</a>


</p>
<p>å˜ä¸€ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰è¤‡æ•°ã®lengthã®Embeddingã‚’å‡ºåŠ›ã§ãã‚‹ã‚ˆã†ãªæ‰‹æ³•ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1956" target="_blank" rel="noopener noreferrer" class="title-link">LoRA: Low-Rank Adaptation of Large Language Models, Edward J. Hu+, ICLR'22</a>
<span class="snippet"><span>GPT Summary</span>- LoRAã¯ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’å›ºå®šã—ã€å„å±¤ã«è¨“ç·´å¯èƒ½ãªãƒ©ãƒ³ã‚¯åˆ†è§£è¡Œåˆ—ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«å¿…è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤§å¹…ã«å‰Šæ¸›ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¨“ç·´å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’1ä¸‡åˆ†ã®1ã€GPUãƒ¡ãƒ¢ãƒªã‚’3åˆ†ã®1ã«æ¸›å°‘ã•ã›ãªãŒã‚‰ã€RoBERTaã‚„GPT-3ãªã©ã§åŒç­‰ä»¥ä¸Šã®æ€§èƒ½ã‚’å®Ÿç¾ã—ã¾ã™ã€‚LoRAã®å®Ÿè£…ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenrReview:


<a href="https://openreview.net/forum?id=nZeVKeeFYf9" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=nZeVKeeFYf9</a>


</p>
<p>LoRAã‚‚ãªã‚“ã‚„ã‹ã‚“ã‚„ãƒ¡ãƒ¢ã£ã¦ãªã‹ã£ãŸã®ã§è¿½åŠ ã€‚<br><br>äº‹å‰å­¦ç¿’æ¸ˆã¿ã®Linear Layerã‚’freezeã—ã¦ã€freezeã—ãŸLinear Layerã¨å¯¾å¿œã™ã‚‹ä½ãƒ©ãƒ³ã‚¯ã®è¡Œåˆ—A,Bã‚’åˆ¥é€”å®šç¾©ã—ã€A,Bã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹PEFTæ‰‹æ³•ã§ã‚ã‚‹LoRAã‚’ææ¡ˆã—ãŸç ”ç©¶ã€‚ã‚ªãƒªã‚¸ãƒŠãƒ«ã®å‡ºåŠ›ã«å¯¾ã—ã¦ã€A,Bã«ã‚ˆã£ã¦å…¥åŠ›ã‚’å†™åƒã—ãŸãƒ™ã‚¯ãƒˆãƒ«ã‚’åŠ ç®—ã™ã‚‹ã€‚<br><br>ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°å­¦ã¯ã‚‹ã‹ã«å°‘ãªã„ã«ã‚‚é–¢ã‚ã‚‰ãšãƒ•ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ï¼ˆã“ã‚Œã¯è«¸èª¬ã‚ã‚‹ãŒï¼‰åŒç­‰ã®æ€§èƒ½ã§PostTrainingã§ãã‚‹ä¸Šã«ã€äº‹å‰å­¦ç¿’æ™‚ç‚¹ã§ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒfreezeã•ã‚Œã¦ã„ã‚‹ãŸã‚Catastrophic ForgettingãŒèµ·ãã¥ã‚‰ãï¼ˆãŸã ã—æ–°ã—ã„çŸ¥è­˜ã‚‚ç²å¾—ã—ã¥ã‚‰ã„ï¼‰ã€A,Bã®è¿½åŠ ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’ä¿å­˜ã™ã‚Œã°è‰¯ã„ã®ã§ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«å„ªã—ã„ã®ã‚‚å¬‰ã—ã„ã€‚</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2929" target="_blank" rel="noopener noreferrer">[Paper Note] LoRA-Pro: Are Low-Rank Adapters Properly Optimized?, Zhengbo Wang+, ICLR'25, 2024.07</a>
<br><br>ãªã©ã§ã‚‚ç¤ºã•ã‚Œã¦ã„ã‚‹ãŒã€ä¸€èˆ¬çš„ã«LoRAã¨Full Finetuningã‚’æ¯”è¼ƒã™ã‚‹ã¨LoRAã®æ–¹ãŒæ€§èƒ½ãŒä½ã„ã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ç‚¹ã«ã¯ç•™æ„ãŒå¿…è¦ã€‚</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1827" target="_blank" rel="noopener noreferrer" class="title-link">Training Compute-Optimal Large Language Models, Jordan Hoffmann+, NeurIPS'22</a>
<span class="snippet"><span>GPT Summary</span>- ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼è¨€èªãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«ãŠã„ã¦ã€è¨ˆç®—äºˆç®—å†…ã§æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’èª¿æŸ»ã€‚ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨è¨“ç·´ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¯åŒç­‰ã«ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€å€å¢—ã™ã‚‹ã”ã¨ã«ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚‚å€å¢—ã™ã¹ãã¨ææ¡ˆã€‚Chinchillaãƒ¢ãƒ‡ãƒ«ã¯ã€Gopherãªã©ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®è¨ˆç®—é‡ã‚’å‰Šæ¸›ã€‚MMLUãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§67.5%ã®ç²¾åº¦ã‚’é”æˆã—ã€Gopherã«å¯¾ã—ã¦7%ä»¥ä¸Šã®æ”¹å–„ã‚’å®Ÿç¾ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview: 


<a href="https://openreview.net/forum?id=iBBcRUlOAPR" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=iBBcRUlOAPR</a>


</p>
<p>chinchillaå‰‡</p></span><br><br>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<span class="issue_date">Issue Date: 2025-02-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1754" target="_blank" rel="noopener noreferrer" class="title-link">Switch Transformers: Scaling to Trillion Parameter Models with Simple  and Efficient Sparsity, William Fedus+, JMLR'22</a>
<span class="snippet"><span>GPT Summary</span>- Switch Transformerã‚’ææ¡ˆã—ã€Mixture of Experts (MoE)ã®è¤‡é›‘ã•ã‚„é€šä¿¡ã‚³ã‚¹ãƒˆã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ä¸å®‰å®šæ€§ã‚’æ”¹å–„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ä½ç²¾åº¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã®å¤§è¦æ¨¡ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¯èƒ½ã«ãªã‚Šã€æœ€å¤§7å€ã®äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é€Ÿåº¦å‘ä¸Šã‚’å®Ÿç¾ã€‚ã•ã‚‰ã«ã€1å…†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€T5-XXLãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦4å€ã®é€Ÿåº¦å‘ä¸Šã‚’é”æˆã€‚</span>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<a class="button" href="articles/FactualKnowledge.html" target="_blank" rel="noopener noreferrer">#FactualKnowledge</a>
<a class="button" href="articles/Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<span class="issue_date">Issue Date: 2024-07-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1332" target="_blank" rel="noopener noreferrer" class="title-link">Knowledge Neurons in Pretrained Transformers, Damai Dai+, N_A, ACL'22, 2022.05</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€äº‹å®ŸçŸ¥è­˜ã®æ ¼ç´æ–¹æ³•ã«ã¤ã„ã¦ã®ç ”ç©¶ã‚’è¡Œã„ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€BERTã®fill-in-the-blank cloze taskã‚’ç”¨ã„ã¦ã€é–¢é€£ã™ã‚‹äº‹å®Ÿã‚’è¡¨ç¾ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’ç‰¹å®šã—ã¾ã—ãŸã€‚ã¾ãŸã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æ´»æ€§åŒ–ã¨å¯¾å¿œã™ã‚‹äº‹å®Ÿã®è¡¨ç¾ã¨ã®æ­£ã®ç›¸é–¢ã‚’è¦‹ã¤ã‘ã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã‚ãšã«ã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’æ´»ç”¨ã—ã¦ç‰¹å®šã®äº‹å®ŸçŸ¥è­˜ã‚’ç·¨é›†ã—ã‚ˆã†ã¨è©¦ã¿ã¾ã—ãŸã€‚ã“ã®ç ”ç©¶ã¯ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸTransformerså†…ã§ã®çŸ¥è­˜ã®æ ¼ç´ã«é–¢ã™ã‚‹ç¤ºå”†ã«å¯Œã‚“ã§ãŠã‚Šã€ã‚³ãƒ¼ãƒ‰ã¯https://github.com/Hunter-DDM/knowledge-neuronsã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1108" target="_blank" rel="noopener noreferrer">å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ï½¤ã€ŒçŸ¥è­˜ã¯å…¨çµåˆå±¤ã«è“„ç©ã•ã‚Œã‚‹ã€ã¨ã„ã†ä»®èª¬ã«ã¤ã„ã¦ã®æ–‡çŒ®èª¿æŸ»</a>
 </p>
<p>æ—¥æœ¬èªè§£èª¬: 


<a href="https://speakerdeck.com/kogoro/knowledge-neurons-in-pretrained-transformers-for-snlp2022" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/kogoro/knowledge-neurons-in-pretrained-transformers-for-snlp2022</a>


</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2140" target="_blank" rel="noopener noreferrer">[Paper Note] Transformer Feed-Forward Layers Are Key-Value Memories, Mor Geva+, EMNLP'21</a>
</p>
<p>ä¸Šè¨˜è³‡æ–™ã«ã‚ˆã‚‹ã¨ã€ç‰¹å®šã®çŸ¥è­˜ã‚’å‡ºåŠ›ã™ã‚‹éš›ã«æ´»æ€§åŒ–ã™ã‚‹çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’ç‰¹å®šã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚MLMã‚’ç”¨ã„ãŸclozeã‚¿ã‚¹ã‚¯ã«ã‚ˆã‚‹å®Ÿé¨“ã§[MASK]éƒ¨åˆ†ã«å½“è©²çŸ¥è­˜ã‚’å‡ºåŠ›ã™ã‚‹å®Ÿé¨“ã‚’ã—ãŸçµæœã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®é‡ã¿ã‚’ã‚¼ãƒ­ã¨ã™ã‚‹ã¨æ€§èƒ½ãŒè‘—ã—ãåŠ£åŒ–ã—ã€å€¤ã‚’2å€ã«ã™ã‚‹ã¨æ€§èƒ½ãŒæ”¹å–„ã™ã‚‹ã¨ã„ã£ãŸå‚¾å‘ãŒã¿ã‚‰ã‚ŒãŸã€‚ã€€ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã¨ã—ã¦ã€çŸ¥è­˜ã®æ›´æ–°ã¨ã€çŸ¥è­˜ã®å‰Šé™¤ãŒå¯èƒ½ã‹ã‚’æ¤œè¨¼ã€‚ã©ã¡ã‚‰ã¨ã‚‚æ›´æ–°ãƒ»å‰Šé™¤ãŒã•ã‚Œã‚‹æ–¹å‘æ€§[^1]ã¸ãƒ¢ãƒ‡ãƒ«ãŒå¤‰åŒ–ã—ãŸã€‚<br><br>ã¾ãŸã€çŸ¥è­˜ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã¯Transformerã®å±¤ã®æ·±ã„ã¨ã“ã‚ã«ä½ç½®ã—ã¦ã„ã‚‹å‚¾å‘ã«ã‚ã‚Šã€ç•°ãªã‚‹relationã‚’æŒã¤ã‚ˆã†ãªé–¢ä¿‚çŸ¥è­˜åŒå£«ã§ã¯å…±æœ‰ã•ã‚Œãªã„å‚¾å‘ã«ã‚ã‚‹æ¨¡æ§˜ã€‚<br><br>[^1]: ä»–ã®çŸ¥è­˜ã«å½±éŸ¿ã‚’ä¸ãˆãšã€å®Œç’§ã«æ›´æ–°ãƒ»å‰Šé™¤ã§ããŸã‚ã‘ã§ã¯ãªã„ã€‚çŸ¥è­˜ã®æ›´æ–°ãƒ»å‰Šé™¤ã«ä¼´ã„Extrinsicãªè©•ä¾¡ã«ã‚ˆã£ã¦æ€§èƒ½å‘ä¸Šã€ã‚ã‚‹ã„ã¯PerplexityãŒå¢—å¤§ã—ãŸã€ã¨ã„ã£ãŸçµæœã‹ã‚‰ãã†ã„ã£ãŸæ–¹å‘æ€§ã¸ãƒ¢ãƒ‡ãƒ«ãŒå¤‰åŒ–ã—ãŸã€ã¨ã„ã†è©±</p></span><br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/PPO%20(ProximalPolicyOptimization).html" target="_blank" rel="noopener noreferrer">#PPO (ProximalPolicyOptimization)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2024-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1296" target="_blank" rel="noopener noreferrer" class="title-link">Training language models to follow instructions with human feedback, Long Ouyang+, N_A, NeurIPS'22</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã«åˆã‚ãªã„å‡ºåŠ›ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚æœ¬ç ”ç©¶ã§ã¯ã€äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦GPT-3ã‚’å¾®èª¿æ•´ã—ã€InstructGPTã¨å‘¼ã°ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã¾ã™ã€‚ã“ã®æ‰‹æ³•ã«ã‚ˆã‚Šã€13å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®InstructGPTãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ãŒ175Bã®GPT-3ã®å‡ºåŠ›ã‚ˆã‚Šã‚‚å¥½ã¾ã‚Œã€çœŸå®Ÿæ€§ã®å‘ä¸Šã¨æœ‰å®³ãªå‡ºåŠ›ã®å‰Šæ¸›ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚ã•ã‚‰ã«ã€ä¸€èˆ¬çš„ãªNLPãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãŠã‘ã‚‹æ€§èƒ½ã®ä½ä¸‹ã¯æœ€å°é™ã§ã—ãŸã€‚InstructGPTã¯ã¾ã æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™ãŒã€äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ãŸå¾®èª¿æ•´ãŒæœ‰æœ›ãªæ–¹å‘ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>ChatGPTã®å…ƒã¨ãªã‚‹ã€SFTâ†’Reward Modelã®è¨“ç·´â†’RLHFã®æµã‚ŒãŒææ¡ˆã•ã‚ŒãŸç ”ç©¶ã€‚Demonstrationãƒ‡ãƒ¼ã‚¿ã ã‘ã§SFTã™ã‚‹ã ã‘ã§ã¯ã€äººé–“ã®æ„å›³ã—ãŸã¨ãŠã‚Šã«å‹•ä½œã—ãªã„å•é¡ŒãŒã‚ã£ãŸãŸã‚ã€äººé–“ã®æ„å›³ã«Alignã™ã‚‹ã‚ˆã†ã«ã€Reward Modelã‚’ç”¨ã„ãŸRLHFã§SFTã®å¾Œã«è¿½åŠ ã§å­¦ç¿’ã‚’å®Ÿæ–½ã™ã‚‹ã€‚Reward Modelã¯ã€175Bãƒ¢ãƒ‡ãƒ«ã¯å­¦ç¿’ãŒå®‰å®šã—ãªã‹ã£ãŸä¸Šã«ã€PPOã®è¨ˆç®—ã‚³ã‚¹ãƒˆãŒéå¸¸ã«å¤§ãã„ãŸã‚ã€6Bã®GPT-3ã‚’æ§˜ã€…ãªNLPã‚¿ã‚¹ã‚¯ã§SFTã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ã‚¹ã‚¿ãƒ¼ãƒˆã«ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã«å¯¾ã—ã¦äººé–“ãŒãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»˜ã‘ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã®loss functionã§è¨“ç·´ã—ãŸã€‚æœ€çµ‚çš„ã«ã€RMã®ã‚¹ã‚³ã‚¢ãŒæœ€å¤§åŒ–ã•ã‚Œã‚‹ã‚ˆã†ã«SFTã—ãŸGPT-3ã‚’RLHFã§è¨“ç·´ã™ã‚‹ãŒã€ãã®éš›ã«ã€SFTã‹ã‚‰å‡ºåŠ›ãŒé›¢ã‚Œã™ããªã„ã‚ˆã†ã«ã™ã‚‹é …ã¨ã€NLPãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã®æ€§èƒ½ãŒåŠ£åŒ–ã—ãªã„ã‚ˆã†ã«pretrainæ™‚ã®ã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ã‚‚loss functionã«åŠ ãˆã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e4934d4c-7a9b-44aa-93ce-3ae46ed4bd9b" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-11-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3571" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Structured Denoising Diffusion Models in Discrete State-Spaces, Jacob Austin+, NeurIPS'21, 2021.07</a>
<span class="snippet"><span>GPT Summary</span>- é›¢æ•£ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°æ‹¡æ•£ç¢ºç‡ãƒ¢ãƒ‡ãƒ«ï¼ˆD3PMsï¼‰ã‚’ææ¡ˆã—ã€é€£ç¶šçŠ¶æ…‹ç©ºé–“ã®DDPMsã‚’ä¸€èˆ¬åŒ–ã€‚æ±šæŸ“ãƒ—ãƒ­ã‚»ã‚¹ã‚’è¶…ãˆãŸé·ç§»è¡Œåˆ—ã‚’å°å…¥ã—ã€ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®æ”¹å–„ã‚’å®Ÿç¾ã€‚æ–°ã—ã„æå¤±é–¢æ•°ã‚’ç”¨ã„ã¦ã€LM1Bã§ã®æ–‡å­—ãƒ¬ãƒ™ãƒ«ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚„CIFAR-10ã§ã®ç”»åƒç”Ÿæˆã«ãŠã„ã¦å„ªã‚ŒãŸçµæœã‚’é”æˆã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=h7-XixPCAL" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=h7-XixPCAL</a>


</p>
<p>é›¢æ•£æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ãŸç ”ç©¶</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1986" target="_blank" rel="noopener noreferrer">Masked Diffusion Modelã®é€²å±•, Deep Learning JP, 2025.03</a>
<br><br>ã§ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹</p>
<p>æ¬¡:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3572" target="_blank" rel="noopener noreferrer">[Paper Note] Simple and Effective Masked Diffusion Language Models, Subham Sekhar Sahoo+, NeurIPS'24, 2024.06</a>
 </p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/PMLR.html" target="_blank" rel="noopener noreferrer">#PMLR</a>
<a class="button" href="articles/ScoreMatching.html" target="_blank" rel="noopener noreferrer">#ScoreMatching</a>
<a class="button" href="articles/U-Net.html" target="_blank" rel="noopener noreferrer">#U-Net</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3207" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Improved Denoising Diffusion Probabilistic Models, Alex Nichol+, PMLR'21, 2021.02</a>
<span class="snippet"><span>GPT Summary</span>- DDPMã¯é«˜å“è³ªãªã‚µãƒ³ãƒ—ãƒ«ç”ŸæˆãŒå¯èƒ½ãªç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ç°¡å˜ãªä¿®æ­£ã«ã‚ˆã‚Šç«¶äº‰åŠ›ã®ã‚ã‚‹å¯¾æ•°å°¤åº¦ã‚’é”æˆã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚é€†æ‹¡æ•£ãƒ—ãƒ­ã‚»ã‚¹ã®åˆ†æ•£ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å›æ•°ã‚’å¤§å¹…ã«å‰Šæ¸›ã—ã¤ã¤ã‚µãƒ³ãƒ—ãƒ«å“è³ªã‚’ç¶­æŒã€‚DDPMã¨GANã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†å¸ƒã®ã‚«ãƒãƒ¼èƒ½åŠ›ã‚’æ¯”è¼ƒã—ã€ãƒ¢ãƒ‡ãƒ«ã®å®¹é‡ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨ˆç®—é‡ã«å¯¾ã—ã¦ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§ã‚ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3206" target="_blank" rel="noopener noreferrer">[Paper Note] Denoising Diffusion Probabilistic Models, Jonathan Ho+, NeurIPS'20, 2020.06</a>
</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/ScoreMatching.html" target="_blank" rel="noopener noreferrer">#ScoreMatching</a>
<a class="button" href="articles/U-Net.html" target="_blank" rel="noopener noreferrer">#U-Net</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3205" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Diffusion Models Beat GANs on Image Synthesis, Prafulla Dhariwal+, NeurIPS'21 Spotlight, 2021.05</a>
<span class="snippet"><span>GPT Summary</span>- æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ãŒæœ€å…ˆç«¯ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ç”»åƒã‚µãƒ³ãƒ—ãƒ«å“è³ªã‚’é”æˆã€‚ç„¡æ¡ä»¶ç”»åƒåˆæˆã§ã¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ”¹å–„ã€æ¡ä»¶ä»˜ãç”»åƒåˆæˆã§ã¯åˆ†é¡å™¨ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’ç”¨ã„ã¦å“è³ªå‘ä¸Šã€‚ImageNetã§ã®FIDã‚¹ã‚³ã‚¢ã¯ã€128Ã—128ã§2.97ã€256Ã—256ã§4.59ã€512Ã—512ã§7.72ã‚’é”æˆã—ã€BigGAN-deepã«åŒ¹æ•µã€‚åˆ†é¡å™¨ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã¯ã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã•ã‚‰ã«æ”¹å–„ã•ã‚Œã€256Ã—256ã§3.94ã€512Ã—512ã§3.85ã‚’è¨˜éŒ²ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ä¸­ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=AAWuCvzaVt" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=AAWuCvzaVt</a>


</p>
<p>æ—¥æœ¬èªè§£èª¬:


<a href="https://qiita.com/UMAboogie/items/160c1159811743c49d99" target="_blank" rel="noopener noreferrer">https://qiita.com/UMAboogie/items/160c1159811743c49d99</a>


</p>
<p>ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã¨ã—ã¦ä½¿ã‚ã‚Œã¦ã„ã‚‹U-Netã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2931" target="_blank" rel="noopener noreferrer">[Paper Note] U-Net: Convolutional Networks for Biomedical Image Segmentation, Olaf Ronneberger+, MICCAI'15, 2015.05</a>
</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2545" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] An Image is Worth 16x16 Words: Transformers for Image Recognition at   Scale, Alexey Dosovitskiy+, ICLR'21</a>
<span class="snippet"><span>GPT Summary</span>- ç´”ç²‹ãªãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’ç”»åƒãƒ‘ãƒƒãƒã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«ç›´æ¥é©ç”¨ã™ã‚‹ã“ã¨ã§ã€CNNã¸ã®ä¾å­˜ãªã—ã«ç”»åƒåˆ†é¡ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã§äº‹å‰å­¦ç¿’ã—ã€è¤‡æ•°ã®ç”»åƒèªè­˜ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€å…ˆç«¯ã®CNNã¨æ¯”è¼ƒã—ã¦å„ªã‚ŒãŸçµæœã‚’é”æˆã—ã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’å¤§å¹…ã«å‰Šæ¸›ã€‚</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=YicbFdNTTy" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=YicbFdNTTy</a>


</p>
<p>ViTã‚’ææ¡ˆã—ãŸç ”ç©¶</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/CodeGeneration.html" target="_blank" rel="noopener noreferrer">#CodeGeneration</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2439" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Program Synthesis with Large Language Models, Jacob Austin+, arXiv'21</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€æ±ç”¨ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã«ãŠã‘ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ åˆæˆã®é™ç•Œã‚’å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦è©•ä¾¡ã—ã¾ã™ã€‚MBPPã¨MathQA-Pythonã®2ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«å¯¾ã™ã‚‹åˆæˆæ€§èƒ½ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚’èª¿æŸ»ã€‚æœ€ã‚‚å¤§ããªãƒ¢ãƒ‡ãƒ«ã¯ã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã§MBPPã®59.6ï¼…ã®å•é¡Œã‚’è§£æ±ºå¯èƒ½ã§ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šç´„10ï¼…ã®æ€§èƒ½å‘ä¸ŠãŒè¦‹ã‚‰ã‚Œã¾ã—ãŸã€‚MathQA-Pythonã§ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒ83.8ï¼…ã®ç²¾åº¦ã‚’é”æˆã€‚äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ã§ã‚¨ãƒ©ãƒ¼ç‡ãŒåŠæ¸›ã—ã€ã‚¨ãƒ©ãƒ¼åˆ†æã‚’é€šã˜ã¦ãƒ¢ãƒ‡ãƒ«ã®å¼±ç‚¹ã‚’æ˜ã‚‰ã‹ã«ã—ã¾ã—ãŸã€‚æœ€çµ‚çš„ã«ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ å®Ÿè¡Œçµæœã®äºˆæ¸¬èƒ½åŠ›ã‚’æ¢ã‚‹ã‚‚ã€æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ç‰¹å®šã®å…¥åŠ›ã«å¯¾ã™ã‚‹å‡ºåŠ›äºˆæ¸¬ãŒå›°é›£ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ä»£è¡¨çš„ãªã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚<br><br>MBPPãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€promptã§æŒ‡ç¤ºã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’ãƒ¢ãƒ‡ãƒ«ã«ç”Ÿæˆã•ã›ã€ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ï¼ˆassertion)ã‚’é€šéã™ã‚‹ã‹å¦ã‹ã§è©•ä¾¡ã™ã‚‹ã€‚974ã‚µãƒ³ãƒ—ãƒ«å­˜åœ¨ã—ã€pythonã®åŸºç¤ã‚’æŒã¤ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚ˆã£ã¦ç”Ÿæˆã€‚ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼ã«ã‚¿ã‚¹ã‚¯descriptionã¨ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã™ã‚‹ä¸€ã¤ã®é–¢æ•°ï¼ˆé–¢æ•°ã®ã¿ã§å®Ÿè¡Œå¯èƒ½ã§printã¯ä¸å¯ï¼‰ã€3ã¤ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’è¨˜è¿°ã™ã‚‹ã‚ˆã†ä¾é ¼ã€‚ã‚¿ã‚¹ã‚¯descriptionã¯è¿½åŠ ãªclarificationãªã—ã§ã‚³ãƒ¼ãƒ‰ãŒè¨˜è¿°ã§ãã‚‹ã‚ˆã†ååˆ†ãªæƒ…å ±ã‚’å«ã‚€ã‚ˆã†è¨˜è¿°ã™ã‚‹ã‚ˆã†ã«æŒ‡ç¤ºã€‚ground truthã®é–¢æ•°ã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€webã‚’é–²è¦§ã™ã‚‹ã“ã¨ã‚’è¨±å¯ã—ãŸã€‚<br><img src="https://github.com/user-attachments/assets/e27880f7-4647-462d-b619-e0a7a0959d66" alt="image" loading="lazy"><br><br>MathQA-Pythonã¯ã€MathQAã«å«ã¾ã‚Œã‚‹QAã®ã†ã¡è§£ç­”ãŒæ•°å€¤ã®ã‚‚ã®ã®ã¿ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã€åˆè¨ˆã§23914ã‚µãƒ³ãƒ—ãƒ«å­˜åœ¨ã™ã‚‹ã€‚pythonã‚³ãƒ¼ãƒ‰ã§ä¸ãˆã‚‰ã‚ŒãŸæ•°å­¦ã«é–¢ã™ã‚‹å•é¡Œã‚’è§£ãã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã€æ•°å€¤ãŒä¸€è‡´ã™ã‚‹ã‹å¦ã‹ã§è©•ä¾¡ã™ã‚‹ã€ã¨ã„ã£ãŸæ„Ÿã˜ãªæ¨¡æ§˜ã€‚æ–œã‚èª­ã¿ãªã®ã§å°‘ã—èª­ã¿é•ãˆã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚<br><br><img src="https://github.com/user-attachments/assets/d21ee76f-a13d-4ef9-843b-74c233c3c0a6" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/CodeGeneration.html" target="_blank" rel="noopener noreferrer">#CodeGeneration</a>
<span class="issue_date">Issue Date: 2025-08-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2438" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Evaluating Large Language Models Trained on Code, Mark Chen+, arXiv'21</a>
<span class="snippet"><span>GPT Summary</span>- Codexã¯GitHubã®ã‚³ãƒ¼ãƒ‰ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸGPTè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€Pythonã‚³ãƒ¼ãƒ‰ç”Ÿæˆèƒ½åŠ›ã‚’è©•ä¾¡ã€‚æ–°ã—ã„è©•ä¾¡ã‚»ãƒƒãƒˆHumanEvalã§ã¯ã€CodexãŒ28.8%ã®å•é¡Œã‚’è§£æ±ºã—ã€GPT-3ã¯0%ã€GPT-Jã¯11.4%ã ã£ãŸã€‚ç¹°ã‚Šè¿”ã—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒé›£ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã—ã¦ã‚‚åŠ¹æœçš„ãªæˆ¦ç•¥ã‚’ç”¨ã„ã€70.2%ã®å•é¡Œã‚’è§£æ±ºã€‚ãƒ¢ãƒ‡ãƒ«ã®é™ç•Œã¨ã—ã¦ã€é•·ã„æ“ä½œã®èª¬æ˜ã‚„å¤‰æ•°ã¸ã®ãƒã‚¤ãƒ³ãƒ‰ã«è‹¦åŠ´ã™ã‚‹ç‚¹ãŒæ˜ã‚‰ã‹ã«ã€‚æœ€å¾Œã«ã€ã‚³ãƒ¼ãƒ‰ç”ŸæˆæŠ€è¡“ã®å½±éŸ¿ã«ã¤ã„ã¦å®‰å…¨æ€§ã‚„çµŒæ¸ˆã«é–¢ã™ã‚‹è­°è«–ã‚’è¡Œã†ã€‚</span>
<span class="snippet"><span>Comment</span><p>HumanEvalãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€‚Killed by LLMã«ã‚ˆã‚‹ã¨ã€GPT4oã«ã‚ˆã‚Šã™ã§ã«90%ç¨‹åº¦ã®æ€§èƒ½ãŒé”æˆã•ã‚Œé£½å’Œã—ã¦ã„ã‚‹ã€‚<br><br>164å€‹ã®äººæ‰‹ã§è¨˜è¿°ã•ã‚ŒãŸprogrammingã®å•é¡Œã§ã€ãã‚Œãã‚Œã¯function signature, docstring, body, unittestã‚’æŒã¤ã€‚unittestã¯å•é¡Œå½“ãŸã‚Šç´„7.7 testå­˜åœ¨ã€‚handwrittenã¨ã„ã†ç‚¹ãŒãƒŸã‚½ã§ã€ã‚³ãƒ³ã‚¿ãƒŸãƒãƒ¼ã‚·ãƒ§ãƒ³ã®æ‡¸å¿µãŒã‚ã‚‹ãŸã‚githubã®ã‚ˆã†ãªæ—¢å­˜ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ã‚³ãƒ”ãƒ¼ãªã©ã¯ã—ã¦ã„ãªã„ã€‚pass@k[^1]ã§è©•ä¾¡ã€‚<br><br>[^1]: kå€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã•ã›ã€kå€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã®ã†ã¡ã€ã‚µãƒ³ãƒ—ãƒ«ãŒunittestã‚’ä¸€ã¤ã§ã‚‚é€šéã™ã‚‹ç¢ºç‡ã€‚ãŸã ã€æœ¬ç ”ç©¶ã§ã¯ã‚ˆã‚Šãƒã‚¤ã‚¢ã‚¹ã‚’ãªãã™ãŸã‚ã«ã€kã‚ˆã‚Šã‚‚å¤§ãã„nå€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã—ã€ãã®ä¸­ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«kå€‹ã‚’é¸æŠã—ã¦ç¢ºç‡ã‚’æ¨å®šã™ã‚‹ã‚ˆã†ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹ã€‚2.1ç¯€ã‚’å‚ç…§ã®ã“ã¨ã€‚<br><br><img src="https://github.com/user-attachments/assets/74a74b6f-9d0c-4ce9-ab8b-53b478b4632a" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/ICCV.html" target="_blank" rel="noopener noreferrer">#ICCV</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2025-07-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2258" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Swin Transformer: Hierarchical Vision Transformer using Shifted Windows, Ze Liu+, ICCV'21</a>
<span class="snippet"><span>GPT Summary</span>- Swin Transformerã¯ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã®æ–°ã—ã„ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹éšå±¤çš„ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’ææ¡ˆã€‚ã‚·ãƒ•ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦æ–¹å¼ã«ã‚ˆã‚Šã€åŠ¹ç‡çš„ãªè‡ªå·±æ³¨æ„è¨ˆç®—ã‚’å®Ÿç¾ã—ã€ã•ã¾ã–ã¾ãªã‚¹ã‚±ãƒ¼ãƒ«ã§ã®ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ãŒå¯èƒ½ã€‚ç”»åƒåˆ†é¡ã‚„ç‰©ä½“æ¤œå‡ºã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãªã©ã§å¾“æ¥ã®æœ€å…ˆç«¯ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®ãƒ“ã‚¸ãƒ§ãƒ³ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã¨ã—ã¦ã®å¯èƒ½æ€§ã‚’ç¤ºå”†ã€‚ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://qiita.com/m_sugimura/items/139b182ee7c19c83e70a" target="_blank" rel="noopener noreferrer">https://qiita.com/m_sugimura/items/139b182ee7c19c83e70a</a>


</p>
<p>ç”»åƒå‡¦ç†ã«ãŠã„ã¦ã€ç‰©ä½“ã®ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒ«ã‚„ã€è§£åƒåº¦ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã€PatchMergeã¨å‘¼ã°ã‚Œã‚‹ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã®ã‚ˆã†ãªå‡¦ç†ã¨ã€å›ºå®šã‚µã‚¤ã‚ºã®ãƒ­ãƒ¼ã‚«ãƒ«ãªwindowã«åˆ†å‰²ã—ã¦Self-Attentionã‚’å®Ÿæ–½ã—ã€layerã”ã¨ã«é€šå¸¸ã®windowã¨ã‚·ãƒ•ãƒˆã•ã‚ŒãŸwindowã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã€windowé–“ã‚’è·¨ã„ã é–¢ä¿‚æ€§ã‚‚è€ƒæ…®ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹æ©Ÿæ§‹ã‚’å°å…¥ã—ãŸãƒ¢ãƒ‡ãƒ«ã€‚<br><img src="https://github.com/user-attachments/assets/a2d5f78c-27ec-4f18-bd7d-5475085cfa7b" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/92fb10e1-614e-44ef-9e65-3920cd863d46" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/2b8a543a-069e-468a-bc3c-1f288cdcf577" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/FactualKnowledge.html" target="_blank" rel="noopener noreferrer">#FactualKnowledge</a>
<span class="issue_date">Issue Date: 2025-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2140" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Transformer Feed-Forward Layers Are Key-Value Memories, Mor Geva+, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰å±¤ã¯ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã®å¤§éƒ¨åˆ†ã‚’å ã‚ã‚‹ãŒã€ãã®å½¹å‰²ã¯æœªæ¢æ±‚ã€‚ç ”ç©¶ã«ã‚ˆã‚Šã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰å±¤ãŒã‚­ãƒ¼ãƒ»ãƒãƒªãƒ¥ãƒ¼ãƒ»ãƒ¡ãƒ¢ãƒªã¨ã—ã¦æ©Ÿèƒ½ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¾‹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ç›¸é–¢ã™ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚å®Ÿé¨“ã§ã€ä¸‹å±¤ã¯æµ…ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ä¸Šå±¤ã¯æ„å‘³çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã€ãƒãƒªãƒ¥ãƒ¼ãŒå‡ºåŠ›åˆ†å¸ƒã‚’èª˜å°ã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚æœ€çµ‚çš„ã«ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰å±¤ã®å‡ºåŠ›ã¯ãƒ¡ãƒ¢ãƒªã®åˆæˆã§ã‚ã‚Šã€æ®‹å·®æ¥ç¶šã‚’é€šã˜ã¦æ´—ç·´ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬ï¼ˆp.5ã‚ˆã‚Šï¼‰: 


<a href="https://speakerdeck.com/kogoro/knowledge-neurons-in-pretrained-transformers-for-snlp2022?slide=5" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/kogoro/knowledge-neurons-in-pretrained-transformers-for-snlp2022?slide=5</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2024-12-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1618" target="_blank" rel="noopener noreferrer" class="title-link">Training Verifiers to Solve Math Word Problems, Karl Cobbe+, arXiv'21</a>
<span class="snippet"><span>GPT Summary</span>- GSM8Kãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã¦ã€å¤šæ®µéšã®æ•°å­¦çš„æ¨è«–ã«ãŠã‘ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã®é™ç•Œã‚’åˆ†æã€‚æ¤œè¨¼å™¨ã‚’è¨“ç·´ã—ã€å€™è£œè§£ã‚’è©•ä¾¡ã—ã¦æœ€é©è§£ã‚’é¸æŠã™ã‚‹ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚æ¤œè¨¼ã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚ˆã‚Šã‚‚ãƒ‡ãƒ¼ã‚¿å¢—åŠ ã«å¯¾ã—ã¦åŠ¹æœçš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>## æ°—æŒã¡<br><br>- å½“æ™‚ã®æœ€ã‚‚å¤§ãã„ãƒ¬ãƒ™ãƒ«ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ multi-stepã®reasoningãŒå¿…è¦ãªå•é¡Œã¯å¤±æ•—ã™ã‚‹<br><br>- ãƒ¢ãƒ‡ãƒ«ã‚’Finetuningã‚’ã—ã¦ã‚‚è‡´å‘½çš„ãªãƒŸã‚¹ãŒå«ã¾ã‚Œã‚‹<br><br>- ç‰¹ã«ã€æ•°å­¦ã¯å€‹ã€…ã®ãƒŸã‚¹ã«å¯¾ã—ã¦éå¸¸ã«sensitiveã§ã‚ã‚Šã€ä¸€å›ãƒŸã‚¹ã‚’ã—ã¦ç•°ãªã‚‹è§£æ³•ã®ãƒ‘ã‚¹ã«å…¥ã£ã¦ã—ã¾ã†ã¨ã€self-correctionã™ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒauto-regressiveãªãƒ¢ãƒ‡ãƒ«ã§ã¯ã†ã¾ãã„ã‹ãªã„<br><br>- ç´”ç²‹ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®æ çµ„ã¿ã§ãã‚Œãªã‚Šã®æ€§èƒ½ã«åˆ°é”ã—ã‚ˆã†ã¨ã™ã‚‹ã¨ã€ã¨ã‚“ã§ã‚‚ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¿…è¦ã«ãªã‚Šã€ã‚ˆã‚Šè‰¯ã„scaling lawã‚’ç¤ºã™æ‰‹æ³•ã‚’æ¨¡ç´¢ã™ã‚‹å¿…è¦ãŒã‚ã‚‹<br><br>## Contribution<br><br>è«–æ–‡ã®è²¢çŒ®ã¯<br><br>- GSM8Kã‚’ææ¡ˆã—ã€<br><br>- verifierã‚’æ´»ç”¨ã—ãƒ¢ãƒ‡ãƒ«ã®è¤‡æ•°ã®å€™è£œã®ä¸­ã‹ã‚‰è‰¯ã„å€™è£œã‚’é¸ã¶ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã£ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’30å€ã«ã—ãŸã®ã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™ã¨verifierã‚’å°å…¥ã™ã‚‹ã¨ã‚ˆã‚Šã‚ˆãæ€§èƒ½ãŒã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚<br><br>- ã¾ãŸã€dropoutãŒéå¸¸ã«å¼·ã„æ­£å‰‡åŒ–ä½œç”¨ã‚’ä¿ƒã—ã€finetuningã¨verificationã®åŒæ–¹ã‚’å¤§ããæ”¹å–„ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</p>
<p>Todo: ç¶šãã‚’ã¾ã¨ã‚ã‚‹</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/984" target="_blank" rel="noopener noreferrer" class="title-link">SummEval: Re-evaluating Summarization Evaluation, Fabbri+, TACL'21</a>
<span class="snippet"><span>Comment</span><p>è‡ªå‹•è©•ä¾¡æŒ‡æ¨™ãŒäººæ‰‹è©•ä¾¡ã®æ°´æº–ã«é”ã—ãªã„ã“ã¨ãŒç¤ºã•ã‚Œã¦ãŠã‚Šã€çµå±€ã®ã¨ã“ã‚ROUGEã‚’ä¸Šå›ã‚‹è‡ªå‹•æ€§èƒ½æŒ‡æ¨™ã¯ã»ã¨ã‚“ã©ãªã‹ã£ãŸã€‚human judgmentsã¨ã®Kendall;'s Tauã‚’è¦‹ã‚‹ã¨ã€chrFãŒCoherenceã¨Relevance, METEORãŒFluencyã§ä¸Šå›ã£ãŸã®ã¿ã ã£ãŸã€‚ã¾ãŸã€LEAD-3ã¯ã‚„ã¯ã‚Šãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã—ã¦ã‹ãªã‚Šå¼·ãã€LEAD-3ã‚’ä¸Šå›ã£ãŸã®ã¯BARTã¨PEGASUSã ã£ãŸã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-free.html" target="_blank" rel="noopener noreferrer">#Reference-free</a>
<a class="button" href="articles/LM-based.html" target="_blank" rel="noopener noreferrer">#LM-based</a>
<span class="issue_date">Issue Date: 2023-08-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/960" target="_blank" rel="noopener noreferrer" class="title-link">BARTSCORE: Evaluating Generated Text as Text Generation, Yuan+ ï¼ˆw_ Neubigæ°ï¼‰, NeurIPS'21</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®è©•ä¾¡æ–¹æ³•ã«ã¤ã„ã¦æ¤œè¨ã—ã¾ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®å•é¡Œã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å‚ç…§å‡ºåŠ›ã¾ãŸã¯ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹ãŸã‚ã«è¨“ç·´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã—ãŸã€‚ææ¡ˆã—ãŸãƒ¡ãƒˆãƒªãƒƒã‚¯ã§ã‚ã‚‹BARTSCOREã¯ã€æƒ…å ±é‡ã€æµæš¢ã•ã€äº‹å®Ÿæ€§ãªã©ã®ç•°ãªã‚‹è¦–ç‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆè©•ä¾¡ã«æŸ”è»Ÿã«é©ç”¨ã§ãã¾ã™ã€‚å®Ÿé¨“çµæœã§ã¯ã€æ—¢å­˜ã®ãƒˆãƒƒãƒ—ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¾ã—ãŸã€‚BARTScoreã®è¨ˆç®—ã«ä½¿ç”¨ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ãŠã‚Šã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã‚‚åˆ©ç”¨å¯èƒ½ã§ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>BARTScore</p>
<p># æ¦‚è¦<br><br>ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€BARTã«ã‚ˆã£ã¦ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹å°¤åº¦ã‚’è¨ˆç®—ã—ã€ãã‚Œã‚’ã‚¹ã‚³ã‚¢ã¨ã™ã‚‹æ‰‹æ³•ã€‚ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¿ã‚¹ã‚¯ã‚’ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€pre-trainingã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã‚ˆã‚Šæœ‰åŠ¹ã«æ´»ç”¨ã§ãã‚‹ï¼ˆe.g. BERTScoreã‚„MoverScoreãªã©ã¯ã€pre-trainingã‚¿ã‚¹ã‚¯ãŒãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã§ã¯ãªã„ï¼‰ã€‚BARTScoreã®ç‰¹å¾´ã¯<br><br>1. parameter- and data-efficientã§ã‚ã‚‹ã€‚pre-trainingã«åˆ©ç”¨ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»¥å¤–ã®è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å¿…è¦ãªãã€unsupervisedãªmetricãªã®ã§ã€human judgmentã®ãƒ‡ãƒ¼ã‚¿ãªã©ã‚‚å¿…è¦ãªã„ã€‚<br><br>2. æ§˜ã€…ãªè¦³ç‚¹ã‹ã‚‰ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã‚’è©•ä¾¡ã§ãã‚‹ã€‚conditional text generation problemã«ã™ã‚‹ã“ã¨ã§informativeness, coherence, factualityãªã©ã®æ§˜ã€…ãªè¦³ç‚¹ã«å¯¾å¿œå¯èƒ½ã€‚<br><br>3. BARTScoreã¯ã€(i) pre-training taskã¨é¡ä¼¼ã—ãŸpromptã‚’ä¸ãˆã‚‹ã“ã¨ã€(ii) down stream generation taskã§finetuningã™ã‚‹ã“ã¨ã€ã§ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’ç²å¾—ã§ãã‚‹<br><br>BARTScoreã‚’16ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã€7ã¤ã®è¦³ç‚¹ã§è©•ä¾¡ã—ãŸã¨ã“ã‚ã€16/22ã«ãŠã„ã¦ã€top-scoring metricsã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€prompting starategyã®æœ‰åŠ¹æ€§ã‚’ç¤ºã—ãŸã€‚ãŸã¨ãˆã°ã€ã‚·ãƒ³ãƒ—ãƒ«ã«"such as"ã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ ã™ã‚‹ã ã‘ã§ã€German-English MTã«ãŠã„ã¦3%ã®æ€§èƒ½å‘ä¸ŠãŒè¦‹ã‚‰ã‚ŒãŸã€‚ã¾ãŸã€BARTScoreã¯ã€high-qualityãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã‚’æ‰±ã†éš›ã«ã€ã‚ˆã‚Šãƒ­ãƒã‚¹ãƒˆã§ã‚ã‚‹ã“ã¨ãŒåˆ†æã®çµæœåˆ†ã‹ã£ãŸã€‚<br><br><br><br># å‰æ<br><br>## Problem Formulation<br><br>ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®qualityã‚’æ¸¬ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã™ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€conditional text generation (e.g. æ©Ÿæ¢°ç¿»è¨³)ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã™ã‚‹ã€‚ã™ãªã‚ã¡ã€ã‚´ãƒ¼ãƒ«ã¯ã€hypothesis h_bar ã‚’ source text s_barãŒgivenãªçŠ¶æ…‹ã§ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚ä¸€èˆ¬çš„ã«ã¯ã€äººé–“ãŒä½œæˆã—ãŸreference r_barãŒè©•ä¾¡ã®éš›ã¯åˆ©ç”¨ã•ã‚Œã‚‹ã€‚<br><br>## Gold-standard Human Evaluation<br><br>è©•ä¾¡ã®gold standardã¯äººæ‰‹è©•ä¾¡ã§ã‚ã‚Šã€äººæ‰‹è©•ä¾¡ã§ã¯å¤šãã®è¦³ç‚¹ã‹ã‚‰è©•ä¾¡ãŒè¡Œã‚ã‚Œã‚‹ã€‚ä»¥ä¸‹ã«ä»£è¡¨çš„ãªè¦³ç‚¹ã‚’ç¤ºã™ï¼š<br><br>1. Informativeness: ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã®ã‚­ãƒ¼ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ã©ã‚Œã ã‘æ‰ãˆã¦ã„ã‚‹ã‹<br><br>2. Relevance: ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã«ã‚åœ°ã—ã¦ã€ã©ã‚Œã ã‘consistentã‹<br><br>3. Fluency formatting problem, capitarlization errorã‚„éæ–‡ãªã©ã€ã©ã®ç¨‹åº¦èª­ã‚€ã®ãŒå›°é›£ã‹<br><br>4. Coherence: æ–‡é–“ã®ã¤ãªãŒã‚ŠãŒã€ãƒˆãƒ”ãƒƒã‚¯ã«å¯¾ã—ã¦ã©ã‚Œã ã‘coherentã‹<br><br>5. Factuality: ã‚½ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã«å«æ„ã•ã‚Œã‚‹statementã®ã¿ã‚’ç”Ÿæˆã§ãã¦ã„ã‚‹ã‹<br><br>6. Semantic Coverage: å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆä¸­ã®Semantic Content Unitã‚’ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆãŒã©ã‚Œã ã‘ã‚«ãƒãƒ¼ã§ãã¦ã„ã‚‹ã‹<br><br>7: Adequacy å…¥åŠ›æ–‡ã«å¯¾ã—ã¦ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆãŒåŒã˜æ„å‘³ã‚’å‡ºåŠ›ã§ãã¦ã„ã‚‹ã‹ã©ã†ã‹ã€ã‚ã‚‹ã„ã¯ä½•ã‚‰ã‹ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå¤±ã‚ã‚Œã‚‹ã€è¿½åŠ ã•ã‚Œã‚‹ã€æ­ªæ›²ã—ã¦ã„ãªã„ã‹ã©ã†ã‹<br><br><br><br>å¤šãã®æ€§èƒ½æŒ‡æ¨™ã¯ã€ã“ã‚Œã‚‰ã®è¦³ç‚¹ã®ã†ã¡ã®subsetã‚’ã‚«ãƒãƒ¼ã™ã‚‹ã‚ˆã†ã«ãƒ‡ã‚¶ã‚¤ãƒ³ã‚“ã•ã‚Œã¦ã„ã‚‹ã€‚ãŸã¨ãˆã°ã€BLEUã¯ã€ç¿»è¨³ã«ãŠã‘ã‚‹Adequacyã¨Fluencyã‚’ã¨ã‚‰ãˆã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã€ROUGEã¯ã€semantic coverageã‚’æ¸¬ã‚‹ãŸã‚ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã§ã‚ã‚‹ã€‚<br><br>BARTScoreã¯ã€ã“ã‚Œã‚‰ã®ã†ã¡å¤šãã®è¦³ç‚¹ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br><br><br>## Evaluation as Different Tasks<br><br>ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ç•°ãªã‚‹æ–¹æ³•ã§è‡ªå‹•è©•ä¾¡ã«æ´»ç”¨ã™ã‚‹ã®ãŒæœ€è¿‘ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã§ã‚ã‚‹ã€‚ä¸‹å›³ãŒãã®åˆ†é¡ã€‚ã“ã®åˆ†é¡ã¯ã€ã‚¿ã‚¹ã‚¯ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ãŸåˆ†é¡ã¨ãªã£ã¦ã„ã‚‹ã€‚<br><br>1. Unsupervised Matching: ROUGE, BLEU, CHRF, BERTScore, MoverScoreã®ã‚ˆã†ã«ã€hypothesisã¨referenceé–“ã§ã®æ„å‘³çš„ãªç­‰ä¾¡æ€§ã‚’æ¸¬ã‚‹ã“ã¨ãŒç›®çš„ã§ã‚ã‚‹ã€‚ã“ã®ãŸã‚ã«ã€token-levelã®ãƒãƒƒãƒãƒ³ã‚°ã‚’ç”¨ã„ã‚‹ã€‚ã“ã‚Œã¯ã€distributedãªè¡¨ç¾ã‚’ç”¨ã„ã‚‹ï¼ˆBERTScore, MoverScoreï¼‰å ´åˆã‚‚ã‚ã‚Œã°ã€discreteãªè¡¨ç¾ã‚’ç”¨ã„ã‚‹ï¼ˆROUGE, BLEU, chrFï¼‰å ´åˆã‚‚ã‚ã‚‹ã€‚ã¾ãŸã€æ„å‘³çš„ãªç­‰ä¾¡æ€§ã ã‘ã§ãªãã€factual consistencyã‚„ã€source-hypothesisé–“ã®é–¢ä¿‚æ€§ã®è©•ä¾¡ã«ç”¨ã„ã‚‹ã“ã¨ã‚‚ã§ãã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ãŒå…ˆè¡Œç ”ç©¶ã§ã¯ã‚„ã‚‰ã‚Œã¦ã„ãªã‹ã£ãŸã®ã§ã€æœ¬ç ”ç©¶ã§å¯èƒ½ãªã“ã¨ã‚’ç¤ºã™ã€‚<br><br>2. Supervised Regression: BLEURT, COMET, S^3, VRMã®ã‚ˆã†ã«ã€regression layer ã‚’ç”¨ã„ã¦human judgmentã‚’supervisedã«äºˆæ¸¬ã™ã‚‹æ–¹æ³•ã§ã‚ã‚‹ã€‚æœ€è¿‘ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ï½”ãŠã—ã¦ã¯ã€BLEURT, COMETãŒã‚ã’ã‚‰ã‚Œã€å¤å…¸çš„ãªã‚‚ã®ã¨ã—ã¦ã¯ã€S^3, VRMãŒã‚ã’ã‚‰ã‚Œã‚‹ã€‚<br><br>4. Supervised Ranking: COMET, BEERã®ã‚ˆã†ãªã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°å•é¡Œã¨ã—ã¦ã¨ã‚‰ãˆã‚‹æ–¹æ³•ã‚‚ã‚ã‚‹ã€‚ã“ã‚Œã¯å„ªã‚ŒãŸhypothesisã‚’ä¸Šä½ã«ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã™ã‚‹ã‚ˆã†ãªã‚¹ã‚³ã‚¢é–¢æ•°ã‚’å­¦ç¿’ã™ã‚‹å•é¡Œã«å¸°ç€ã™ã‚‹ã€‚COMETã‚„BEERãŒä¾‹ã¨ã—ã¦ã‚ã’ã‚‰ã‚Œã€ä¸¡è€…ã¯MTã‚¿ã‚¹ã‚¯ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã•ã‚Œã¦ã„ã‚‹ã€‚COMETã¯hunan judgmentsã‚’regressionã™ã‚‹ã“ã¨ã‚’é€šã˜ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½œæˆã—ã€BEERã¯ã€å¤šãã®ã‚·ãƒ³ãƒ—ãƒ«ãªç‰¹å¾´é‡ã‚’çµ„ã¿åˆã‚ã›ã¦ã€linear layerã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã‚‹ã€‚<br><br>5. Text Generation: PRISM, BARTScoreãŒä¾‹ã¨ã—ã¦æŒ™ã’ã‚‰ã‚Œã‚‹ã€‚BARTScoreã§ã¯ã€ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®è©•ä¾¡ã‚’pre-trained language modelã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚¿ã‚¹ã‚¯ã¨ã—ã¦ã¨ã‚‰ãˆã‚‹ã€‚åŸºæœ¬çš„ãªã‚¢ã‚¤ãƒ‡ã‚¢ã¨ã—ã¦ã¯ã€é«˜å“è³ªã®hypothesisã¯ã€ã‚½ãƒ¼ã‚¹ã€ã‚ã‚‹ã„ã¯referenceã‹ã‚‰å®¹æ˜“ã«ç”Ÿæˆå¯èƒ½ã§ã‚ã‚ã†ã€ã¨ã„ã†ã‚‚ã®ã§ã‚ã‚‹ã€‚ã“ã‚Œã¯PRISMã‚’é™¤ã„ã¦ã€å…ˆè¡Œç ”ç©¶ã§ã¯ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ãªã„ã€‚BARTScoreã¯ã€PRISMã¨ã¯ã„ãã¤ã‹ã®ç‚¹ã§ç•°ãªã£ã¦ã„ã‚‹ã€‚(i) PRISMã¯è©•ä¾¡ã‚’paraphrasing taskã¨ã—ã¦ã¨ã‚‰ãˆã¦ãŠã‚Šã€ã“ã‚ŒãŒ2ã¤ã®æ„å‘³ãŒåŒã˜ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¯”è¼ƒã™ã‚‹å‰æã¨ãªã£ã¦ã—ã¾ã£ã¦ã„ã‚‹ãŸã‚ã€æ‰‹æ³•ã‚’é©ç”¨å¯èƒ½ãªç¯„å›²ã‚’ç‹­ã‚ã¦ã—ã¾ã£ã¦ã„ã‚‹ã€‚ãŸã¨ãˆã°ã€æ–‡æ›¸è¦ç´„ã«ãŠã‘ã‚‹factual consistencyã®è©•ä¾¡ã§ã¯ã€semantic spaceãŒç•°ãªã‚‹2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¯”è¼ƒã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŒã€ã“ã®ã‚ˆã†ãªä¾‹ã«ã¯å¯¾å¿œã§ããªã„ã€‚(ii) PRISMã¯parallel dataã‹ã‚‰å­¦ç¿’ã—ãªã‘ãˆï½’ã°ãªã‚‰ãªã„ãŒã€BARTScoreã¯ã€pre-trainedãªopen-sourceã®seq2seq modelã‚’åˆ©ç”¨ã§ãã‚‹ã€‚(iii) BARTScoreã§ã¯ã€PRISMãŒæ¤œè¨¼ã—ã¦ã„ãªã„ã€prompt-basedã®learningã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/4a64ea21-ab9f-4762-bd71-f858663fc195" alt="image" loading="lazy"><br><br><br><br># BARTScore<br><br>## Sequence-to-Sequence Pre-trained Models<br><br>pre-trainingã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€æ§˜ã€…ãªè»¸ã§ç•°ãªã£ã¦ã„ã‚‹ãŒã€ãã®ä¸€ã¤ã®è»¸ã¨ã—ã¦ã¯è¨“ç·´æ™‚ã®ç›®çš„é–¢æ•°ã§ã‚ã‚‹ã€‚åŸºæœ¬çš„ã«ã¯ï¼’ã¤ã®å¤§ããªå¤‰ç¨®ãŒã‚ã‚Šã€1ã¤ã¯ã€language modeling objectives (e.g. MLM)ã€2ã¤ç›®ã¯ã€seq2seq objectivesã§ã‚ã‚‹ã€‚ç‰¹ã«ã€seq2seqã§äº‹å‰å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã¨ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã«ã‚ˆã£ã¦æ§‹æˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ç‰¹ã«æ¡ä»¶ä»˜ãç”Ÿæˆã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦é©ã—ã¦ãŠã‚Šã€äºˆæ¸¬ã¯AutoRegressiveã«è¡Œã‚ã‚Œã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯BARTã‚’ç”¨ã„ã‚‹ã€‚ä»˜éŒ²ã«ã¯ã€preliminary experimentsã¨ã—ã¦ã€BART with T5, PEGASUSã‚’ç”¨ã„ãŸçµæœã‚‚æ·»ä»˜ã™ã‚‹ã€‚<br><br>## BARTScore<br><br>æœ€ã‚‚ä¸€èˆ¬çš„ãªBARTScoreã®å®šå¼åŒ–ã¯ä¸‹è¨˜ã§ã‚ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/34505fd3-c8bb-49ee-92a8-f5710032b1ea" alt="image" loading="lazy"><br><br>weighted log probabilityã‚’åˆ©ç”¨ã™ã‚‹ã€‚ã“ã®weightsã¯ã€ç•°ãªã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾ã—ã¦ã€ç•°ãªã‚‹é‡ã¿ã‚’ä¸ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ãŸã¦ãŠã°ã€IDFãªã©ãŒåˆ©ç”¨å¯èƒ½ã§ã‚ã‚‹ãŒã€æœ¬ç ”ç©¶ã§ã¯ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç­‰ä¾¡ã«æ‰±ã†ï¼ˆuniform weightingã ãŒstopwordã‚’é™¤å¤–ã€IDFã«ã‚ˆã‚‹é‡ã¿ã¥ã‘ã€äº‹å‰åˆ†å¸ƒã‚’å°å…¥ã™ã‚‹ãªã©è‰²ã€…è©¦ã—ãŸãŒã€uniform weightingã‚’ä¸Šå›ã‚‹ã‚‚ã®ãŒãªã‹ã£ãŸï¼‰ã€‚<br><br><br><br>BARTScoreã‚’ç”¨ã„ã¦ã€æ§˜ã€…ãªæ–¹å‘ã«ç”¨ã„ã¦ç”Ÿæˆã‚’è¡Œã†ã“ã¨ãŒã§ãã€ç•°ãªã‚‹è©•ä¾¡ã®ã‚·ãƒŠãƒªã‚ªã«å¯¾å¿œã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br>- Faithfulness (s -&gt; h):<br><br>    - hypothesisãŒã©ã‚Œã ã‘source textã«åŸºã¥ã„ã¦ç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã‹ã‚’æ¸¬ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã‚·ãƒŠãƒªã‚ªã¨ã—ã¦ã¯ã€Factualityã‚„Relevanceãªã©ãŒè€ƒãˆã‚‰ã‚Œã‚‹ã€‚ã¾ãŸã€Coherenceã‚„Fluencyã®ã‚ˆã†ã«ã€target textã®ã¿ã®å“è³ªã‚’æ¸¬ã‚‹ãŸã‚ã«ã‚‚ç”¨ã„ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br>- Precision (r -&gt; h):<br><br>    - hypothesisãŒã©ã‚Œã ã‘gold-referenceã«åŸºã¥ã„ã¦ã“ã†è‰¯ãã•ã‚Œã¦ã„ã‚‹ã‹ã‚’äºœè©•ä¾¡ã§ãã€precision-focusedãªã‚·ãƒŠãƒªã‚ªã«é©ã—ã¦ã„ã‚‹<br><br>- Recall (h -&gt; r):<br><br>    - hypothesisã‹ã‚‰ã€gold referenceã‚’ã©ã‚Œã ã‘å®¹æ˜“ã«å†ç¾ã§ãã‚‹ã‹ã‚’æ¸¬ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ãã—ã¦ã€è¦ç´„ã‚¿ã‚¹ã‚¯ã®pyramid-basedãªè©•ä¾¡ï¼ˆi.e. semantic coverageç­‰ï¼‰  ã«é©ã—ã¦ã„ã‚‹ã€‚pyramid-scoreã¯Semantic Content UnitsãŒã©ã‚Œã ã‘ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã‚‹ã‹ã«ã‚ˆã£ã¦è©•ä¾¡ã•ã‚Œã‚‹ã€‚<br><br>- F Score (r &lt;-&gt; h):<br><br>    - åŒæ–¹å‘ã‚’è€ƒæ…®ã—ã€Precisioon / Recallã‹ã‚‰Få€¤ã‚’ç®—å‡ºã™ã‚‹ã€‚ã“ã®æ–¹æ³•ã¯ã€referenceã¨ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆé–“ã§ã®semantic overlap (informativenss, adequacy)ãªã©ã®è©•ä¾¡ã«åºƒãåˆ©ç”¨ã•ã‚Œã‚‹ã€‚<br><br><br><br># BARTScore Variants<br><br>BARTScoreã®2ã¤ã®æ‹¡å¼µã‚’ææ¡ˆã€‚(i) xã¨yã‚’promptingã«ã‚ˆã£ã¦å¤‰æ›´ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è©•ä¾¡ã‚¿ã‚¹ã‚¯ã‚’pre-training taskã¨è¿‘ã¥ã‘ã‚‹ã€‚(ii) ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Î˜ã‚’ç•°ãªã‚‹finetuning taskã‚’è€ƒæ…®ã—ã¦å¤‰æ›´ã™ã‚‹ã€‚ã™ãªã‚ã¡ã€pre-trainingã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ã€evaluation taskã«è¿‘ã¥ã‘ã‚‹ã€‚<br><br>## Prompt<br><br>Promptingã¯input/outputã«å¯¾ã—ã¦çŸ­ã„ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’è¿½åŠ ã—ã€pre-trained modelã«å¯¾ã—ã¦ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‚’é‚è¡Œã•ã›ã‚‹æ–¹æ³•ã§ã‚ã‚‹ã€‚BARTã«ã‚‚åŒæ§˜ã®æ´å¯Ÿã‚’ç°¡å˜ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã‚‹ã€‚ã“ã®å¤‰ç¨®ã‚’BARTScore-PROMPTã¨å‘¼ã¶ã€‚<br><br>prompt zãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã«ã€ãã‚Œã‚’ (i) source textã«è¿½åŠ ã—ã€æ–°ãŸãªsource textã‚’ç”¨ã„ã¦BARTScoreã‚’è¨ˆç®—ã™ã‚‹ã€‚(ii) target textã®å…ˆé ­ã«è¿½åŠ ã—ã€new target textã«å¯¾ã—ã¦BARTScoreã‚’è¨ˆç®—ã™ã‚‹ã€‚<br><br>## Fine-tuning Task<br><br>classification-basedãªã‚¿ã‚¹ã‚¯ã§fine-tuneã•ã‚Œã‚‹ã®ãŒä¸€èˆ¬çš„ãªBERT-based metricã¨ã¯ç•°ãªã‚Šã€BARTScoreã¯generation taskã§fine-tuneã•ã‚Œã‚‹ãŸã‚ã€pre-training domainãŒevaluation taskã¨è¿‘ã„ã€‚æœ¬ç ”ç©¶ã§ã¯ã€2ã¤ã®downstream taskã‚’æ¤œè¨¼ã™ã‚‹ã€‚<br><br>1ã¤ã‚ã¯ã€summarizationã§ã€BARTã‚’CNNDM datasetã§finetuningã™ã‚‹ã€‚2ã¤ã‚ã¯ã€paraphrasingã§ã€summarizationã‚¿ã‚¹ã‚¯ã§finetuningã—ãŸBARTã‚’ParaBank2 datasetã§ã•ã‚‰ã«finetuningã™ã‚‹ã€‚</p>
<p># å®Ÿé¨“<br><br>## baselines and datasets<br><br>### Evaluation Metrics<br><br>supervised metrics: COMET, BLEURT<br><br>unsupervised: BLEU, ROUGE-1, ROUGE-2, ROUGE-L, chrF, PRISM, MoverScore, BERTScore<br><br>ã¨æ¯”è¼ƒ<br><br>### Measures for Meta Evaluation<br><br>Pearson Correlationã§linear correlationã‚’æ¸¬ã‚‹ã€‚ã¾ãŸã€Spearman Correlationã§2å¤‰æ•°é–“ã®å˜èª¿ãªcorrelationã‚’æ¸¬å®šã™ã‚‹ï¼ˆç·šå½¢ã§ã‚ã‚‹å¿…è¦ã¯ãªã„ï¼‰ã€‚Kendall's Tauã‚’ç”¨ã„ã¦ã€2ã¤ã®é †åºé–¢ä¿‚ã®é–¢ä¿‚æ€§ã‚’æ¸¬ã‚‹ã€‚æœ€å¾Œã«ã€Accuracyã§factual textsã¨non-factual textã®é–“ã§ã©ã‚Œã ã‘æ­£ã—ã„ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å¾—ã‚‰ã‚Œã‚‹ã‹ã‚’æ¸¬ã‚‹ã€‚<br><br><br><br>### Datasets<br><br>Summarization, MT, DataToTextã®3ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ©ç”¨ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/117bf2d4-b096-4a60-a139-4a607ce3ebc6" alt="image" loading="lazy"><br><br><br><br>## Setup<br><br>### Prompt Design<br><br>seedã‚’paraphrasingã™ã‚‹ã“ã¨ã§ã€ã€€s-&gt;hæ–¹å‘ã«ã¯70å€‹ã®promptã‚’ã€h&lt;-&gt;rã®ä¸¡æ–¹å‘ã«ã¯ã€34ã®promptã‚’å¾—ã¦å®Ÿé¨“ã§ç”¨ã„ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/dab4f2bc-9b8d-4de6-bbc3-204da39ee2eb" alt="image" loading="lazy"><br><br><br><br>### Settings<br><br>Summarizationã¨data-to-textã‚¿ã‚¹ã‚¯ã§ã¯ã€å…¨ã¦ã®promptã‚’ç”¨ã„ã¦ãƒ‡ã‚³ãƒ¼ãƒ€ã®é ­ã«è¿½åŠ ã—ã¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ãŸã€‚æœ€çµ‚çš„ã«ã™ã¹ã¦ã®ç”Ÿæˆã•ã‚ŒãŸã‚¹ã‚³ã‚¢ã‚’å¹³å‡ã™ã‚‹ã“ã¨ã§ã‚ã‚‹äº‹ä¾‹ã«å¯¾ã™ã‚‹ã‚¹ã‚³ã‚¢ã‚’æ±‚ã‚ãŸï¼ˆprompt unsemblingï¼‰ã€‚MTã«ã¤ã„ã¦ã¯ã€äº‹ä¾‹æ•°ãŒå¤šãcomputational costãŒå¤šããªã£ã¦ã—ã¾ã†ãŸã‚ã€WMT18ã‚’é–‹ç™ºãƒ‡ãƒ¼ã‚¿ã¨ã—ã€best prompt "Such as"ã‚’é¸æŠã—ã€åˆ©ç”¨ã—ãŸã€‚<br><br>BARTScoreã‚’ä½¿ã†éš›ã¯ã€gold standard human evaluationãŒrecall-basedãªpyrmid methodã®å ´åˆã¯BARTScore(h-&gt;r)ã‚’ç”¨ã„ã€humaan judgmentsãŒlinguistic quality (coherence fluency)ãã—ã¦ã€factual correctnessã€ã‚ã‚‹ã„ã¯ã€sourceã¨targetãŒåŒã˜ãƒ¢ãƒ€ãƒªãƒ†ã‚£ï¼ˆe.g. languageï¼‰ã®å ´åˆã¯ã€faitufulness-based BARTScore(s-&gt;h)ã‚’ç”¨ã„ãŸã€‚æœ€å¾Œã«ã€MTã‚¿ã‚¹ã‚¯ã¨data-to-textã‚¿ã‚¹ã‚¯ã§ã¯ã€fair-comparisonã®ãŸã‚ã«BARTScore F-score versionã‚’ç”¨ã„ãŸã€‚<br><br>## å®Ÿé¨“çµæœ<br><br>### MT<br><br>- BARTScoreã¯finetuning tasksã«ã‚ˆã£ã¦æ€§èƒ½ãŒå‘ä¸Šã—ã€5ã¤ã®language pairsã«ãŠã„ã¦ãã®ä»–ã®unsupervised methodsã‚’çµ±è¨ˆçš„ã«å„ªä½ã«outperformã—ã€2ã¤ã®language pairã§comparableã§ã‚ã£ãŸã€‚<br><br>-Such asã¨ã„ã†promptã‚’è¿½åŠ ã™ã‚‹ã ã‘ã§ã€BARTScoreã®æ€§èƒ½ãŒæ”¹å–„ã—ãŸã€‚ç‰¹ç­†ã™ã¹ãã¯ã€de-enã«ãŠã„ã¦ã¯ã€SoTAã®supervised Metricsã§ã‚ã‚‹BLEURTã¨COMETã‚’ä¸Šå›ã£ãŸã€‚<br><br>- ã“ã‚Œã¯ã€æœ‰æœ›ãªå°†æ¥ã®metric designã¨ã—ã¦ã€Œhuman judgment dataã§è¨“ç·´ã™ã‚‹ä»£ã‚ã‚Šã«ã€pre-trained language modelã«è“„ç©ã•ã‚ŒãŸçŸ¥è­˜ã‚’ã‚ˆã‚Šé©åˆ‡ã«æ´»ç”¨ã§ãã‚‹promptã‚’æ¢ç´¢ã™ã‚‹ã€ã¨ã„ã†æ–¹å‘æ€§ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ff41b3ec-3cf9-4c9a-90bb-83b46889d759" alt="image" loading="lazy"><br><br><br><br>### Text Summarization<br><br>- vanilla BARTScoreã¯BERTScore, MoverScoreã‚’Info perspectiveä»¥å¤–ã§large marginã§ã†ããå›ã£ãŸã€‚<br><br>- REALSum, SummEval dataseetã§ã®æ”¹å–„ã¯ã€finetuning taskã«ã‚ˆã£ã¦ã•ã‚‰ã«æ”¹å–„ã—ãŸã€‚ã—ã‹ã—ãªãŒã‚‰ã€NeR18ã§ã¯æ”¹å–„ã—ãªã‹ã£ãŸã€‚ã“ã‚Œã¯ã€ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹7ã¤ã®ã‚·ã‚¹ãƒ†ãƒ ãŒå®¹æ˜“ã«åŒºåˆ¥ã§ãã‚‹ç¨‹åº¦ã®qualityã§ã‚ã‚Šã€æ—¢ã«vanilla BARTScoreã§é«˜ã„ãƒ¬ãƒ™ãƒ«ã®correlationã‚’é”æˆã—ã¦ã„ã‚‹ã‹ã‚‰ã ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚<br><br>- prompt combination strategyã¯informativenssã«å¯¾ã™ã‚‹æ€§èƒ½ã‚’ä¸€è²«ã—ã¦æ”¹å–„ã—ã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€fluency, factualityã§ã¯ã€ä¸€è²«ã—ãŸæ”¹å–„ã¯è¦‹ã‚‰ã‚Œãªã‹ã£ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cfb33334-e38d-43e0-9b48-a8a8c433bc26" alt="image" loading="lazy"><br><br><br><br>Factuality datasetsã«å¯¾ã™ã‚‹åˆ†æã‚’è¡Œã£ãŸã€‚ã‚´ãƒ¼ãƒ«ã¯ã€short generated summaryãŒã€å…ƒã®long documentsã«å¯¾ã—ã¦faithfulã‹å¦ã‹ã‚’åˆ¤å®šã™ã‚‹ã¨ã„ã†ã‚‚ã®ã§ã‚ã‚‹ã€‚<br><br>- BARTScore+CNNã¯ã€Rank19ãƒ‡ãƒ¼ã‚¿ã«ãŠã„ã¦human baselineã«è¿‘ã„æ€§èƒ½ã‚’é”æˆã—ã€ã»ã‹ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã£ãŸã€‚top-performingãªfactuality metricsã§ã‚ã‚‹FactCCã‚„QAGSã«å¯¾ã—ã¦ã‚‚large marginã§ä¸Šå›ã£ãŸã€‚<br><br>- paraphraseã‚’fine-tuning taskã§åˆ©ç”¨ã™ã‚‹ã¨ã€BARTScoreã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ä½ä¸‹ã—ãŸã€‚ã“ã‚Œã¯å¦¥å½“ã§ã€ãªãœãªã‚‰äºŒã¤ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆsummary and documentï¼‰ã¯ã€paraphrasedã®é–¢ä¿‚æ€§ã‚’ä¿æŒã—ã¦ã„ãªã„ã‹ã‚‰ã§ã‚ã‚‹ã€‚<br><br>- promptã‚’å°å…¥ã—ã¦ã‚‚ã€æ€§èƒ½ã®æ”¹å–„ã¯è¦‹å—ã‘ã‚‰ã‚Œãšã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ä½ä¸‹ã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/06dac947-c946-4633-8ff6-a9c3933f6322" alt="image" loading="lazy"><br><br><br><br>### Data-to-Text<br><br>- CNNDMã§fine-tuningã™ã‚‹ã“ã¨ã§ã€ä¸€è²«ã—ã¦correlationãŒæ”¹å–„ã—ãŸã€‚<br><br>- åŠ ãˆã¦ã€paraphraseãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§finetuningã™ã‚‹ã“ã¨ã§ã€ã•ã‚‰ã«æ€§èƒ½ãŒæ”¹å–„ã—ãŸã€‚<br><br>- prompt combination strategyã¯ä¸€è²«ã—ã¦correlationã‚’æ”¹å–„ã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/acbd6816-e7bc-4ecd-8a53-13137a2bcc94" alt="image" loading="lazy"><br><br></p>
<p>## Analysis<br><br>### Fine-grained Analysis<br><br>- Top-k Systems: MTã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€è©•ä¾¡ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’top-kã«ã—ã€å„ãƒ¡ãƒˆãƒªãƒƒã‚¯ã”ã¨ã«correlationã®å¤‰åŒ–ã‚’è¦‹ãŸã€‚ãã®çµæœã€BARTScoreã¯ã™ã¹ã¦ã®unsupervised methodã‚’ã™ã¹ã¦ã®kã«ãŠã„ã¦ä¸Šå›ã‚Šã€supervised metricã®BLEURTã‚‚ä¸Šå›ã£ãŸã€‚ã¾ãŸã€kãŒå°ã•ããªã‚‹ã»ã©ã€ã‚ˆã‚Šæ€§èƒ½ã¯smoothã«ãªã£ã¦ã„ãã€æ€§èƒ½ã®ä½ä¸‹ãŒãªããªã£ã¦ã„ã£ãŸã€‚ã“ã‚Œã¯ã¤ã¾ã‚Šã€high-quality textã‚’ç”Ÿæˆã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã«å¯¾ã—ã¦ãƒ­ãƒã‚¹ãƒˆã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br>- Reference Length: ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚’4ã¤ã®ãƒã‚±ãƒƒãƒˆã«reference lengthã«å¿œã˜ã¦ãƒ–ãƒ¬ã‚¤ã‚¯ãƒ€ã‚¦ãƒ³ã—ã€Kendall's Tauã®å¹³å‡ã®correlationã‚’ã€ç•°ãªã‚‹ãƒ¡ãƒˆãƒªãƒƒã‚¯ã€ãƒã‚±ãƒƒãƒˆã”ã¨ã«è¨€èªã‚’ã¾ãŸã„ã§è¨ˆç®—ã—ãŸã€‚unsupervised metricsã«å¯¾ã—ã¦ã€å…¨ã¦ã®lengthã«å¯¾ã—ã¦ã€å¼•ãåˆ†ã‘ã‹ã‚ã‚‹ã„ã¯ä¸Šå›ã£ãŸã€‚ã¾ãŸã€ã»ã‹ã®metricsã¨æ¯”è¼ƒã—ã¦ã€é•·ã•ã«å¯¾ã—ã¦å®‰å®šæ„ŸãŒã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/821fdf0a-aabc-448a-81aa-238aae380ea1" alt="image" loading="lazy"><br><br><br><br>### Prompt Analysis<br><br>(1) semantic overlap (informativeness, pyramid score, relevance), (2) linguistic quality (fluency, coherence), (3) factual correctness (factuality) ã«è©•ä¾¡ã®è¦³ç‚¹ã‚’åˆ†é¡ã—ã€summarizationã¨data-to-textã‚’ã«ãŠã‘ã‚‹ã™ã¹ã¦ã®promptã‚’åˆ†æã™ã‚‹ã“ã¨ã§ã€promptã®åŠ¹æœã‚’åˆ†æã—ãŸã€‚ãã‚Œãã‚Œã®ã‚°ãƒ«ãƒ¼ãƒ—ã«å¯¾ã—ã¦ã€æ€§èƒ½ãŒæ”¹å–„ã—ãŸpromptã®å‰²åˆã‚’è¨ˆç®—ã—ãŸã€‚ãã®çµæœã€semantic overlapã¯ã»ã¼å…¨ã¦ã®promptã«ã¦æ€§èƒ½ãŒæ”¹å–„ã—ã€factualityã¯ã„ãã¤ã‹ã®promptã§ã—ã‹æ€§èƒ½ã®æ”¹å–„ãŒè¦‹ã‚‰ã‚Œãªã‹ã£ãŸã€‚linguistic qualityã«é–¢ã—ã¦ã¯ã€promptã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã«ã‚ˆã‚‹åŠ¹æœã¯ã©ã¡ã‚‰ã¨ã‚‚è¨€ãˆãªã‹ã£ãŸã€‚<br><br><br><br>### Bias Analysis<br><br>BARTScoreãŒäºˆæ¸¬ä¸å¯èƒ½ãªæ–¹æ³•ã§ãƒã‚¤ã‚¢ã‚¹ã‚’å°å…¥ã—ã¦ã—ã¾ã†ã‹ã©ã†ã‹ã‚’åˆ†æã—ãŸã€‚ãƒã‚¤ã‚¢ã‚¹ã¨ã¯ã€human annotatorãŒä¸ãˆãŸã‚¹ã‚³ã‚¢ã‚ˆã‚Šã‚‚ã€å€¤ãŒé«˜ã™ãã‚‹ã€ã‚ã‚‹ã„ã¯ä½ã™ãã‚‹ã‚ˆã†ãªçŠ¶æ³ã§ã‚ã‚‹ã€‚ã“ã®ã‚ˆã†ãªãƒã‚¤ã‚¢ã‚¹ãŒå­˜åœ¨ã™ã‚‹ã‹ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã«ã€human annotatorã¨BARTScoreã«ã‚ˆã‚‹ãƒ©ãƒ³ã‚¯ã®ã‚µã‚’åˆ†æã—ãŸã€‚ã“ã‚Œã‚’è¦‹ã‚‹ã¨ã€BARTScoreã¯ã€extractive summarizationã®å“è³ªã‚’åŒºåˆ¥ã™ã‚‹èƒ½åŠ›ãŒabstractive summarizationã®å“è³ªã‚’åŒºåˆ¥ã™ã‚‹èƒ½åŠ›ã‚ˆã‚Šã‚‚åŠ£ã£ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚ã—ã‹ã—ãªãŒã‚‰ã€è¿‘å¹´ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã¯abstractiveãªseq2seqã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ãªã®ã§ã€ã“ã®å¼±ç‚¹ã¯è»½æ¸›ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br><br><br># Implications and Future Directions<br><br>prompt-augmented metrics: semantic overlapã§ã¯promptingãŒæœ‰åŠ¹ã«åƒã„ãŸãŒã€linguistic qualityã¨factualityã§ã¯æœ‰åŠ¹ã§ã¯ãªã‹ã£ãŸã€‚ã‚ˆã‚Šè‰¯ã„promptã‚’æ¨¡ç´¢ã™ã‚‹ç ”ç©¶ãŒä»Šå¾ŒæœŸå¾…ã•ã‚Œã‚‹ã€‚<br><br>Co-evolving evaluation metrics and systems: BARTScoreã¯ã€ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ‡ã‚¶ã‚¤ãƒ³ã¨ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ã‚¶ã‚¤ãƒ³ã®é–“ã«ã¤ãªãŒã‚ŠãŒã‚ã‚‹ã®ã§ã€ã‚ˆã‚Šæ€§èƒ½ã®è‰¯ã„seq2seqã‚·ã‚¹ãƒ†ãƒ ãŒå‡ºãŸã‚‰ã€ãã‚Œã‚’ãƒ¡ãƒˆãƒªãƒƒã‚¯ã«ã‚‚æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã‚ˆã‚Šreliableãªè‡ªå‹•æ€§èƒ½æŒ‡æ¨™ã¨ãªã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã‚‹ã€‚<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/08d51f6d-40ad-4b2a-8871-086e12010478" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<a class="button" href="articles/Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<span class="issue_date">Issue Date: 2023-07-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/907" target="_blank" rel="noopener noreferrer" class="title-link">SimCSE: Simple Contrastive Learning of Sentence Embeddings, Tianyu Gao+, N_A, EMNLP'21</a>
<span class="snippet"><span>GPT Summary</span>- ã“ã®è«–æ–‡ã§ã¯ã€SimCSEã¨ã„ã†å¯¾æ¯”å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€æ–‡ã®åŸ‹ã‚è¾¼ã¿æŠ€è¡“ã‚’é€²åŒ–ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚æ•™å¸«ãªã—ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€å…¥åŠ›æ–‡ã‚’ãƒã‚¤ã‚ºã¨ã—ã¦æ‰±ã„ã€è‡ªå·±ã‚’å¯¾æ¯”çš„ã«äºˆæ¸¬ã—ã¾ã™ã€‚æ•™å¸«ã‚ã‚Šã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€è‡ªç„¶è¨€èªæ¨è«–ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰æ³¨é‡ˆä»˜ãã®ãƒšã‚¢ã‚’ä½¿ç”¨ã—ã¦å¯¾æ¯”å­¦ç¿’ã‚’è¡Œã„ã¾ã™ã€‚SimCSEã¯ã€æ„å‘³çš„ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼æ€§ã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã•ã‚Œã€ä»¥å‰ã®æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦æ”¹å–„ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚å¯¾æ¯”å­¦ç¿’ã¯ã€äº‹å‰å­¦ç¿’ã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿ã®ç©ºé–“ã‚’å‡ä¸€ã«æ­£å‰‡åŒ–ã—ã€æ•™å¸«ä¿¡å·ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã«ã¯æ­£ã®ãƒšã‚¢ã‚’ã‚ˆã‚Šã‚ˆãæ•´åˆ—ã•ã›ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/462" target="_blank" rel="noopener noreferrer">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks, Reimers+, UKP-TUDA, EMNLP'19</a>
 ã‚ˆã‚Šã‚‚æ€§èƒ½è‰¯ãã€unsupervisedã§ã‚‚å­¦ç¿’ã§ãã‚‹ã€‚STSã‚¿ã‚¹ã‚¯ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã«ã ã„ãŸã„å…¥ã£ã¦ã‚‹</p>
<p># æ‰‹æ³•æ¦‚è¦<br><br>Contrastive Learningã‚’æ´»ç”¨ã—ã¦ã€unsupervised/supervisedã«å­¦ç¿’ã‚’å®Ÿæ–½ã™ã‚‹ã€‚<br><br>Unsupervised SimCSEã§ã¯ã€ã‚ã‚‹sentenceã‚’encoderã«2å›å…¥åŠ›ã—ã€ãã‚Œãã‚Œã«dropoutã‚’é©ç”¨ã•ã›ã‚‹ã“ã¨ã§ã€positive pairã‚’ä½œæˆã™ã‚‹ã€‚dropoutã«ã‚ˆã£ã¦å…±é€šã®embeddingã‹ã‚‰ç•°ãªã‚‹è¦ç´ ãŒãƒã‚¹ã‚¯ã•ã‚ŒãŸï¼ˆnoiseãŒæ··ã–ã£ãŸçŠ¶æ…‹ã¨ã¿ãªã›ã‚‹ï¼‰é¡ä¼¼ã—ãŸembeddingãŒä½œæˆã•ã‚Œã€ã‚ã‚‹ç¨®ã®data augmentationã«ã‚ˆã£ã¦æ­£ä¾‹ã‚’ä½œæˆã—ã¦ã„ã‚‹ã¨ã‚‚ã„ãˆã‚‹ã€‚è² ä¾‹ã¯negative samplingã™ã‚‹ã€‚ï¼ˆéå¸¸ã«simpleã ãŒã€next sentence predictionã§å­¦ç¿’ã™ã‚‹ã‚ˆã‚Šæ€§èƒ½ãŒè‰¯ããªã‚‹ï¼‰<br><br>Supervised SimCSEã§ã¯ã€ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸsentence pairã«åŸºã¥ã„ã¦ã€æ­£ä¾‹ãƒ»è² ä¾‹ã‚’æ±ºå®šã™ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€NLIã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãŠã„ã¦ã€entailmenté–¢ä¿‚ã«ã‚ã‚‹ã‚‚ã®ã¯æ­£ä¾‹ã¨ã—ã¦æ‰±ã†ã€‚contradictionsï¼ˆçŸ›ç›¾ï¼‰é–¢ä¿‚ã«ã‚ã‚‹ã‚‚ã®ã¯è² ä¾‹ã¨ã—ã¦æ‰±ã†ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ba20a1ca-0078-4227-8bb3-3805ee57a620" alt="image" loading="lazy"><br><br><br><br># Siamese Networkã§ç”¨ã„ã‚‰ã‚Œã‚‹means-squared errrorã¨ContrastiveObjectiveã®é•ã„<br><br>ã©ã¡ã‚‰ã‚‚ãƒšã‚¢ãƒ¯ã‚¤ã‚ºã§æ¯”è¼ƒã™ã‚‹ã¨ã„ã†ç‚¹ã§ã¯ä¸€ç·’ã ãŒã€ContrastiveObjectiveã¯æ­£ä¾‹ã¨è¿‘ã¥ã„ãŸã¨ãã€è² ä¾‹ã¨é ã–ã‹ã£ãŸã¨ãã«lossãŒå°ã•ããªã‚‹ã‚ˆã†ãªå®šå¼åŒ–ãŒã•ã‚Œã¦ã„ã‚‹ç‚¹ãŒç•°ãªã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d9cad930-e86d-4758-87b5-4237525a154a" alt="image" loading="lazy"><br><br>ï¼ˆç”»åƒã¯ã“ã®ãƒ–ãƒ­ã‚°ã‹ã‚‰å¼•ç”¨ã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚


<a href="https://techblog.cccmk.co.jp/entry/2022/08/30/163625%EF%BC%89" target="_blank" rel="noopener noreferrer">https://techblog.cccmk.co.jp/entry/2022/08/30/163625ï¼‰</a>


<br><br><br><br># Unsupervised SimCSEã®å®Ÿé¨“<br><br>ç•°ãªã‚‹data augmentationæ‰‹æ³•ã¨æ¯”è¼ƒã—ãŸçµæœã€dropoutã‚’é©ç”¨ã™ã‚‹æ‰‹æ³•ã®æ–¹ãŒæ€§èƒ½ãŒé«˜ã‹ã£ãŸã€‚MLMã‚„, deletion, é¡ç¾©èªã¸ã®ç½®ãæ›ãˆç­‰ã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã—ã¦ã„ã‚‹ã®ã¯èˆˆå‘³æ·±ã„ã€‚ã¾ãŸã€Next Sentence Predictionã¨æ¯”è¼ƒã—ã¦ã‚‚ã€é«˜ã„æ€§èƒ½ã‚’é”æˆã€‚Next Sentence Predictionã¯ã€word deletionç­‰ã®ã»ã¼é¡ä¼¼ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç›´æ¥çš„ã«é¡ä¼¼é–¢ä¿‚ã«ã‚ã‚‹ãƒšã‚¢ã‹ã‚‰å­¦ç¿’ã™ã‚‹ã¨ã„ã†ã‚ˆã‚Šã€Sentenceã®æ„å‘³å†…å®¹ã®ã¤ãªãŒã‚Šã«åŸºã¥ã„ã¦ãƒ¢ãƒ‡ãƒ«ã®è¨€èªç†è§£èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã€ãã®ã†ãˆã§é¡ä¼¼åº¦ã‚’æ¸¬ã‚‹ã¨ã„ã†é–“æ¥çš„ãªæ‰‹æ³•ã ãŒã€word deletionã«è² ã‘ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã€dropoutã‚’é©ç”¨ã™ã‚‹ã ã‘ã®ï¼ˆç›´æ¥çš„ã«é¡ä¼¼ãƒšã‚¢ã‹ã‚‰å­¦ç¿’ã™ã‚‹ï¼‰æœ¬æ‰‹æ³•ã¯ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br>[image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0ea3549e-3363-4857-94e6-a1ef474aa191)<br><br><br><br>ãªãœã†ã¾ãã„ãã‹ã‚’åˆ†æã™ã‚‹ãŸã‚ã«ã€ç•°ãªã‚‹è¨­å®šã§å®Ÿé¨“ã—ã€alignmentï¼ˆæ­£ä¾‹ã¨ã®è¿‘ã•ï¼‰ã¨uniformityï¼ˆã©ã‚Œã ã‘embeddingãŒä¸€æ§˜ã«åˆ†å¸ƒã—ã¦ã„ã‚‹ã‹ï¼‰ã‚’ã€10 stepã”ã¨ã«plotã—ãŸçµæœãŒä»¥ä¸‹ã€‚dropoutã‚’é©ç”¨ã—ãªã„å ´åˆã¨ã€å¸¸ã«åŒã˜éƒ¨åˆ†ã‚’ãƒã‚¹ã‚¯ã™ã‚‹æ–¹æ³•ï¼ˆã¤ã¾ã‚Šã€å…¨ãåŒã˜embeddingã‹ã‚‰å­¦ç¿’ã™ã‚‹ï¼‰è¨­å®šã‚’è¦‹ã‚‹ã¨ã€å­¦ç¿’ãŒé€²ã‚€ã«ã¤ã‚Œuniformityã¯æ”¹å–„ã™ã‚‹ãŒã€alignmentãŒæ‚ªããªã£ã¦ã„ã£ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã€SimCSEã¯alignmentã‚’ç¶­æŒã—ã¤ã¤ã€uniformityã‚‚ã‚ˆããªã£ã¦ã„ã£ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5f488cb2-b15a-4e00-9452-8e48780abe8a" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5e815cf7-b412-4f1b-8adb-116f0dcd2fee" alt="image" loading="lazy"><br><br><br><br># Supervised SimCSEã®å®Ÿé¨“<br><br>ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ContrastiveLearningã™ã‚‹ã«ã‚ãŸã‚Šã€ã©ã†ã„ã£ãŸãƒ‡ãƒ¼ã‚¿ã‚’æ­£ä¾‹ã¨ã—ã¦ã¿ãªã™ã¨è‰¯ã„ã‹ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã«æ§˜ã€…ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å­¦ç¿’ã—æ€§èƒ½ã‚’æ¤œè¨¼ã—ãŸã€‚<br><br><br><br>- QQP4: Quora question pairs<br><br>- Flickr30k (Young et al., 2014): åŒã˜ç”»åƒã«å¯¾ã—ã¦ã€5ã¤ã®ç•°ãªã‚‹äººé–“ãŒè¨˜è¿°ã—ãŸã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨<br><br>- ParaNMT (Wieting and Gimpel, 2018): back-translationã«ã‚ˆã‚‹paraphraseã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆa<br><br>- NLI datasets: SNLIã¨MNLI<br><br><br><br>å®Ÿé¨“ã®çµæœã€NLI datasetsãŒæœ€ã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã“ã®ç†ç”±ã¨ã—ã¦ã¯ã€NLIãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€crowd sourcingã‚¿ã‚¹ã‚¯ã§äººæ‰‹ã§ä½œæˆã•ã‚ŒãŸé«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹ã“ã¨ã¨ã€lexical overlapãŒå°ã•ããªã‚‹ã‚ˆã†ã«sentenceã®ãƒšã‚¢ãŒä½œæˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒèµ·å› ã—ã¦ã„ã‚‹ã€‚å®Ÿéš›ã€NLI datsetã®lexical overlapã¯39%ã ã£ãŸã®ã«å¯¾ã—ã€ã»ã‹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯60%ã§ã‚ã£ãŸã€‚<br><br><br><br>ã¾ãŸã€condunctionsã¨ãªã‚‹ãƒšã‚¢ã‚’æ˜ç¤ºçš„ã«è² ä¾‹ã¨ã—ã¦ä¸ãˆã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šæ€§èƒ½ãŒå‘ä¸Šã—ãŸï¼ˆæ™®é€šã¯negative samplingã™ã‚‹ã€ã¨ã„ã†ã‹ãƒãƒƒãƒå†…ã®æ­£ä¾‹ä»¥å¤–ã®ã‚‚ã®ã‚’å¼·åˆ¶çš„ã«è² ä¾‹ã¨ã™ã‚‹ã€‚ã“ã†ã™ã‚‹ã¨ã€æ„å‘³ãŒåŒã˜ã§ã‚‚è² ä¾‹ã«ãªã£ã¦ã—ã¾ã†äº‹ä¾‹ãŒå‡ºã¦ãã‚‹ã“ã¨ã«ãªã‚‹ï¼‰ã€‚ã‚ˆã‚Šé›£ã—ã„NLIã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ANLIãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¿½åŠ ã—ãŸå ´åˆã¯ã€æ€§èƒ½ãŒæ”¹å–„ã—ãªã‹ã£ãŸã€‚ã“ã®ç†ç”±ã«ã¤ã„ã¦ã¯è€ƒå¯Ÿã•ã‚Œã¦ã„ãªã„ã€‚æ€§èƒ½å‘ä¸Šã—ãã†ãªæ°—ãŒã™ã‚‹ã®ã«ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ae05711b-5ad4-4a53-837b-c57e9a39da62" alt="image" loading="lazy"><br><br></p>
<p># ä»–æ‰‹æ³•ã¨ã®æ¯”è¼ƒçµæœ<br><br>SimCSEãŒã‚ˆã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/510744ff-01bb-47be-9e30-2efa49e0f923" alt="image" loading="lazy"><br><br><br><br># Ablation Studies<br><br>ç•°ãªã‚‹poolingæ–¹æ³•ã§ã€ã©ã®ã‚ˆã†ã«sentence embeddingã‚’ä½œæˆã™ã‚‹ã‹ã§æ€§èƒ½ã®é•ã„ã‚’è¦‹ãŸã€‚originalã®BERTã®å®Ÿè£…ã§ã¯ã€CLS token ã®embeddingã®ä¸Šã«MLP layerãŒã®ã£ã‹ã£ã¦ã„ã‚‹ã€‚ã“ã‚Œã®æœ‰ç„¡ãªã©ã¨æ¯”è¼ƒã€‚<br><br>Unsupervised SimCSEã§ã¯ã€trainingæ™‚ã ã‘MLP layerã‚’ã®ã£ã‘ã¦ã€testæ™‚ã¯MLPã‚’é™¤ã„ãŸæ–¹ãŒè‰¯ã‹ã£ãŸã€‚ä¸€æ–¹ã€Supervised SimCSEã§ã¯ã€ MLP layerã‚’ã®ã£ã‘ãŸã¾ã‚“ã¾ã§è‰¯ã‹ã£ãŸã¨ã®ã“ã¨ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/73116c6a-d48f-42bc-aa5e-8342bb068052" alt="image" loading="lazy"><br><br></p>
<p>ã¾ãŸã€SimCSEã§å­¦ç¿’ã—ãŸsentence embeddingã‚’åˆ¥ã‚¿ã‚¹ã‚¯ã«transferã—ã¦æ´»ç”¨ã™ã‚‹éš›ã«ã¯ã€SimCSEã®objectiveã«MLMã‚’å…¥ã‚ŒãŸæ–¹ãŒã€catastrophic forgettingã‚’é˜²ã’ã¦æ€§èƒ½ãŒé«˜ã‹ã£ãŸã¨ã®ã“ã¨ã€‚<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cc6d20c3-5a0c-4b5e-aa6d-63447c55363f" alt="image" loading="lazy"></p>
<p>ablation studiesã®hard negativesã®ã¨ã“ã‚ã¨ã€ã©ã®ã‚ˆã†ã«ãƒŸãƒ‹ãƒãƒƒãƒã‚’æ§‹æˆã™ã‚‹ã‹ã€ãã‚Œãã‚Œã®transferã—ãŸã‚¿ã‚¹ã‚¯ãŒã©ã®ã‚ˆã†ãªã‚‚ã®ãŒã—ã£ã‹ã‚Šèª­ã‚ã¦ã„ãªã„ã€‚ã‚ã¨ã§ã‚ˆã‚€ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2023-07-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/901" target="_blank" rel="noopener noreferrer" class="title-link">Measuring Massive Multitask Language Understanding, Dan Hendrycks+, N_A, ICLR'21</a>
<span class="snippet"><span>GPT Summary</span>- ç§ãŸã¡ã¯ã€ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®æ­£ç¢ºæ€§ã‚’æ¸¬å®šã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ†ã‚¹ãƒˆã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ†ã‚¹ãƒˆã¯57ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚«ãƒãƒ¼ã—ã€åºƒç¯„ãªä¸–ç•ŒçŸ¥è­˜ã¨å•é¡Œè§£æ±ºèƒ½åŠ›ãŒå¿…è¦ã§ã™ã€‚ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯ã¾ã å°‚é–€å®¶ãƒ¬ãƒ™ãƒ«ã®æ­£ç¢ºæ€§ã«é”ã—ã¦ãŠã‚‰ãšã€æ€§èƒ½ã«åã‚ŠãŒã‚ã‚Šã¾ã™ã€‚ç§ãŸã¡ã®ãƒ†ã‚¹ãƒˆã¯ã€ãƒ¢ãƒ‡ãƒ«ã®å¼±ç‚¹ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã§ãã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=d7KBjmI3GmQ" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=d7KBjmI3GmQ</a>


</p>
<p>MMLUè«–æ–‡</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2736" target="_blank" rel="noopener noreferrer">[Paper Note] Are We Done with MMLU?, Aryo Pradipta Gema+, NAACL'25</a>
<br><br>ã«ãŠã„ã¦ã€å¤šãã®ã‚¨ãƒ©ãƒ¼ãŒå«ã¾ã‚Œã‚‹ã“ã¨ãŒæŒ‡æ‘˜ã•ã‚Œã€å†ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãŒå®Ÿæ–½ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2022-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/473" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Power of Scale for Parameter-Efficient Prompt Tuning, Brian Lester+, arXiv'21, 2021.04</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€å‡çµã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã«é©å¿œã•ã›ã‚‹ãŸã‚ã®ã€Œã‚½ãƒ•ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ã‚’å­¦ç¿’ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã€‚é€†ä¼æ’­ã‚’é€šã˜ã¦å­¦ç¿’ã•ã‚Œã‚‹ã‚½ãƒ•ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã€GPT-3ã®å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã»ã©ç«¶äº‰åŠ›ãŒå¢—ã™ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚ç‰¹ã«ã€æ•°åå„„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€å…¨ã¦ã®é‡ã¿ã‚’èª¿æ•´ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€1ã¤ã®å‡çµãƒ¢ãƒ‡ãƒ«ã‚’è¤‡æ•°ã®ã‚¿ã‚¹ã‚¯ã«å†åˆ©ç”¨ã§ãã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã€ãƒ‰ãƒ¡ã‚¤ãƒ³è»¢é€ã«å¯¾ã™ã‚‹ãƒ­ãƒã‚¹ãƒˆæ€§ã‚‚å‘ä¸Šã™ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã¨ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬: 


<a href="https://qiita.com/kts_plea/items/79ffbef685d362a7b6ce" target="_blank" rel="noopener noreferrer">https://qiita.com/kts_plea/items/79ffbef685d362a7b6ce</a>


<br><br>T5ã®ã‚ˆã†ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦finetuningã‚’ã‹ã‘ã‚‹éš›ã«ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å‡çµã—ã€promptã‚’embeddingã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç‹¬ç«‹ã—ã¦å­¦ç¿’ã™ã‚‹æ‰‹æ³•<br><br>è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¢—åŠ ã™ã‚‹ã«ã¤ã‚Œã€è¨€èªãƒ¢ãƒ‡ãƒ«ãã®ã‚‚ã®ã‚’finetuningã—ãŸå ´åˆï¼ˆModel Tuningï¼‰ã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚</p>
<p>ã„ã‚ã‚†ã‚‹(Softãª) Prompt Tuning</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2021-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/405" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Prefix-Tuning: Optimizing Continuous Prompts for Generation, Xiang Lisa Li+, arXiv'21, 2021.01</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®è»½é‡ãªä»£æ›¿æ‰‹æ®µã§ã‚ã‚Šã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å›ºå®šã—ã¤ã¤ã€ã‚¿ã‚¹ã‚¯ç‰¹æœ‰ã®å°ã•ãªãƒ™ã‚¯ãƒˆãƒ«ã‚’æœ€é©åŒ–ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å°‘ãªã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€ä½ãƒ‡ãƒ¼ã‚¿è¨­å®šã§ã‚‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’fine-tuningã™ã‚‹éš›ï¼Œã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ™‚ã«ã€Œæ¥é ­è¾ã€ã‚’æ½œåœ¨è¡¨ç¾ã¨ã—ã¦ä¸ãˆï¼Œã€Œæ¥é ­è¾ã€éƒ¨åˆ†ã®ã¿ã‚’fine-tuningã™ã‚‹ã“ã¨ã§ï¼ˆä»–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å›ºå®šï¼‰ï¼Œã‚ˆã‚Šå°‘é‡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§fine-tuningã‚’å®Ÿç¾ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆï¼æ¥é ­è¾ã‚’æ½œåœ¨è¡¨ç¾ã§ä¸ãˆã‚‹ã“ã®æ–¹æ³•ã¯ï¼ŒGPT-3ã®promptingã«ç€æƒ³ã‚’å¾—ã¦ã„ã‚‹ï¼fine-tuningã•ã‚ŒãŸæ¥é ­è¾ã®æ½œåœ¨è¡¨ç¾ã®ã¿ã‚’é…å¸ƒã™ã‚Œã°è‰¯ã„ã®ã§ï¼Œéå¸¸ã«å°‘é‡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§fine-tuningãŒã§ãã‚‹ï¼<br><br><br><br>table-to-text, summarizationã‚¿ã‚¹ã‚¯ã§ï¼Œä¸€èˆ¬çš„ãªfine-tuningã‚„Adapterï¼ˆãƒ¬ã‚¤ãƒ¤ãƒ¼ã®é–“ã«ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’æŒ¿å…¥ã—ãã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã ã‘ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ‰‹æ³•ï¼‰ã¨ã„ã£ãŸåŠ¹ç‡çš„ãªfine-tuningæ‰‹æ³•ã¨æ¯”è¼ƒï¼table-to-textã§ã¯ã€250k (å…ƒã®ãƒ¢ãƒ‡ãƒ«ã® 0.1%) ã»ã©ã®æ•°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¾®èª¿æ•´ã™ã‚‹ã ã‘ã§ã€å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’fine-tuningã™ã‚‹ã®ã«åŒ¹æ•µã‚‚ã—ãã¯ãã‚Œä»¥ä¸Šã®æ€§èƒ½ã‚’é”æˆï¼<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/132679791-87ad130d-8a7e-4549-a311-f84400a3787b.png" alt="image" loading="lazy"><br><br></p>
<p>Hugging Faceã®å®Ÿè£…ã‚’åˆ©ç”¨ã—ãŸã¨è«–æ–‡ä¸­ã§ã¯è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ãŒï¼Œfine-tuningã™ã‚‹å‰ã®å…ƒã®è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆGPT-2ï¼‰ã¯ã©ã®ã‚ˆã†ã«æº–å‚™ã—ãŸã®ã ã‚ã†ã‹ï¼Hugging Faceã®pretrainedæ¸ˆã¿ã®GPT-2ã‚’ä½¿ç”¨ã—ãŸã®ã ã‚ã†ã‹ï¼</p>
<p>autoregressive LM (GPT-2)ã¨ï¼Œencoder-decoderãƒ¢ãƒ‡ãƒ«ï¼ˆBARTï¼‰ã¸Prefix Tuningã‚’é©ç”¨ã™ã‚‹å ´åˆã®æ¨¡å¼å›³<br><br><img src="https://user-images.githubusercontent.com/12249301/132681736-0ea4b13f-71cb-41ba-ae17-027e8bf54cc0.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/ScoreMatching.html" target="_blank" rel="noopener noreferrer">#ScoreMatching</a>
<a class="button" href="articles/ImageSynthesis.html" target="_blank" rel="noopener noreferrer">#ImageSynthesis</a>
<a class="button" href="articles/U-Net.html" target="_blank" rel="noopener noreferrer">#U-Net</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3206" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Denoising Diffusion Probabilistic Models, Jonathan Ho+, NeurIPS'20, 2020.06</a>
<span class="snippet"><span>GPT Summary</span>- æ‹¡æ•£ç¢ºç‡ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸé«˜å“è³ªãªç”»åƒåˆæˆã‚’ææ¡ˆã€‚æ–°ã—ã„é‡ã¿ä»˜ãå¤‰åˆ†å¢ƒç•Œã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šã€å„ªã‚ŒãŸçµæœã‚’å¾—ã‚‹ã€‚ç„¡æ¡ä»¶CIFAR10ã§9.46ã®Inceptionã‚¹ã‚³ã‚¢ã€256x256ã®LSUNã§ProgressiveGANã«åŒ¹æ•µã™ã‚‹å“è³ªã‚’é”æˆã€‚å®Ÿè£…ã¯GitHubã§å…¬é–‹ã€‚</span>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="articles/ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="articles/Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-09-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3016" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Dense Passage Retrieval for Open-Domain Question Answering, Vladimir Karpukhin+, EMNLP'20, 2020.04</a>
<span class="snippet"><span>GPT Summary</span>- å¯†ãªè¡¨ç¾ã‚’ç”¨ã„ãŸãƒ‘ãƒƒã‚»ãƒ¼ã‚¸æ¤œç´¢ã®å®Ÿè£…ã‚’ç¤ºã—ã€ãƒ‡ãƒ¥ã‚¢ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§å­¦ç¿’ã€‚è©•ä¾¡ã®çµæœã€Lucene-BM25ã‚’ä¸Šå›ã‚Šã€æ¤œç´¢ç²¾åº¦ã§9%-19%ã®æ”¹å–„ã‚’é”æˆã€‚æ–°ãŸãªæœ€å…ˆç«¯ã®QAæˆæœã‚’ç¢ºç«‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>Dense RetrieverãŒåºƒãçŸ¥ã‚‰ã‚Œã‚‹ãã£ã‹ã‘ã¨ãªã£ãŸç ”ç©¶ï¼ˆã‚ˆã‚Šå¤ãã¯DSSM <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/364" target="_blank" rel="noopener noreferrer">Learning Deep Structured Semantic Models  for Web Search using Clickthrough Data, Huang+, CIKM'13</a>
 ãªã©ãŒã‚ã‚‹)ã€‚bag-of-wordsã®ã‚ˆã†ãªsparseãªãƒ™ã‚¯ãƒˆãƒ«ã§æ¤œç´¢ã™ã‚‹ã®ã§ã¯ãªãï¼ˆ=Sparse Retriever)ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸå¯†ãªãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”¨ã„ã¦æ¤œç´¢ã—ã‚ˆã†ã¨ã„ã†è€ƒãˆæ–¹ã§ã‚ã‚‹ã€‚<br><br>Queryç”¨ã¨æ¤œç´¢å¯¾è±¡ã®Passageã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹Encoderã‚’ç‹¬ç«‹ã—ã¦ãã‚Œãã‚Œç”¨æ„ã—ï¼ˆï¼DualEncoder)ã€QAã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆã™ãªã‚ã¡ã‚¯ã‚¨ãƒªqã¨æ­£ä¾‹ã¨ã—ã¦æ­£è§£passage p+)ãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã€ã‚¯ã‚¨ãƒªqã¨æ­£ä¾‹p+ã®é¡ä¼¼åº¦ãŒé«˜ãã€è² ä¾‹p-ã¨ã®é¡ä¼¼åº¦ãŒä½ããªã‚‹ã‚ˆã†ã«ï¼ˆ=Contrastive Learning)ã€Query, Passage Encoderã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹ã“ã¨ã§å­¦ç¿’ã™ã‚‹ï¼ˆæå¤±é–¢æ•°ã¯å¼(2))ã€‚<br><br>è² ä¾‹ã¯In-Batch Negativeã‚’ç”¨ã„ã‚‹ã€‚æƒ…å ±æ¤œç´¢ã®å ´åˆæ­£è§£ãƒ©ãƒ™ãƒ«ã¯å¤šãã®å ´åˆæ˜ç¤ºçš„ã«æ±ºã¾ã‚‹ãŒã€è² ä¾‹ã¯è†¨å¤§ãªãƒ†ã‚­ã‚¹ãƒˆã®ãƒ—ãƒ¼ãƒ«ã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ–¹æ³•ã¯ã„ã‚ã„ã‚ãªæ–¹æ³•ãŒã‚ã‚Šï¼ˆe.g., ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€qã¨bm25ã‚¹ã‚³ã‚¢ãŒé«˜ã„passageï¼ˆãŸã ã—æ­£è§£ã¯å«ã¾ãªã„; hard negativesã¨å‘¼ã¶ï¼‰ãã®ä¸­ã®ä¸€ã¤ã®æ–¹æ³•ãŒIn-Batch Negativesã§ã‚ã‚‹ã€‚<br><br>In-Batch Negativesã§ã¯ã€åŒãƒŸãƒ‹ãƒãƒƒãƒå†…ã®q_iã«å¯¾å¿œã™ã‚‹æ­£ä¾‹p+_iä»¥å¤–ã®å…¨ã¦ã®p_jã‚’ï¼ˆæ“¬ä¼¼çš„ã«ï¼‰è² ä¾‹ã¨ã¿ãªã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ›´æ–°ã«åˆ©ç”¨ã™ã‚‹ãŸã‚ã®q,pã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’å…¨ã¦ä¸€åº¦ã ã‘å®Ÿè¡Œã™ã‚Œã°è‰¯ãã€è¨ˆç®—åŠ¹ç‡ãŒå¤§å¹…ã«å‘ä¸Šã™ã‚‹ã¨ã„ã†å„ªã‚Œã‚‚ã®ã€‚æœ¬ç ”ç©¶ã®å®Ÿé¨“ï¼ˆTable3)ã«ã‚ˆã‚‹ã¨ä¸Šè¿°ã—ãŸIn-Batch Negativeã«åŠ ãˆã¦ã€bm25ã«ã‚ˆã‚‹hard negativeã‚’ãƒãƒƒãƒå†…ã®å„qã«å¯¾ã—ã¦1ã¤è² ä¾‹ã¨ã—ã¦è¿½åŠ ã™ã‚‹æ–¹æ³•ãŒæœ€ã‚‚æ€§èƒ½ãŒè‰¯ã‹ã£ãŸã€‚<br><br>ã‚¯ã‚¨ãƒªã€passageã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¨ã—ã¦ã¯ã€BERTãŒç”¨ã„ã‚‰ã‚Œã€[CLS]ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾å¿œã™ã‚‹embeddingã‚’ç”¨ã„ã¦é¡ä¼¼åº¦ãŒè¨ˆç®—ã•ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2025-07-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2287" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Exploring Simple Siamese Representation Learning, Xinlei Chen+, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- Siameseãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ãŸæ•™å¸«ãªã—è¦–è¦šè¡¨ç¾å­¦ç¿’ã«é–¢ã™ã‚‹ç ”ç©¶ã§ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒ«ãƒšã‚¢ã€å¤§ããªãƒãƒƒãƒã€ãƒ¢ãƒ¼ãƒ¡ãƒ³ã‚¿ãƒ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨ã›ãšã«æ„å‘³ã®ã‚ã‚‹è¡¨ç¾ã‚’å­¦ç¿’ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚ã‚¹ãƒˆãƒƒãƒ—ã‚°ãƒ©ãƒ‡ã‚£ã‚¨ãƒ³ãƒˆæ“ä½œãŒå´©å£Šè§£ã‚’é˜²ãé‡è¦ãªå½¹å‰²ã‚’æœãŸã™ã“ã¨ã‚’ç¢ºèªã—ã€SimSiamãƒ¡ã‚½ãƒƒãƒ‰ãŒImageNetãŠã‚ˆã³ä¸‹æµã‚¿ã‚¹ã‚¯ã§ç«¶äº‰åŠ›ã®ã‚ã‚‹çµæœã‚’é”æˆã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Siameseã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å½¹å‰²ã‚’å†è€ƒã™ã‚‹ãã£ã‹ã‘ã¨ãªã‚‹ã“ã¨ã‚’æœŸå¾…ã—ã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:<br><br>


<a href="https://qiita.com/saliton/items/2f7b1bfb451df75a286f" target="_blank" rel="noopener noreferrer">https://qiita.com/saliton/items/2f7b1bfb451df75a286f</a>


<br>


<a href="https://qiita.com/koshian2/items/a31b85121c99af0eb050" target="_blank" rel="noopener noreferrer">https://qiita.com/koshian2/items/a31b85121c99af0eb050</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2025-07-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2286" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Bootstrap your own latent: A new approach to self-supervised Learning, Jean-Bastien Grill+, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- BYOLï¼ˆBootstrap Your Own Latentï¼‰ã¯ã€è‡ªå·±æ•™å¸«ã‚ã‚Šç”»åƒè¡¨ç¾å­¦ç¿’ã®æ–°ã—ã„æ‰‹æ³•ã§ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®2ã¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ã¦å­¦ç¿’ã‚’è¡Œã†ã€‚BYOLã¯ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒšã‚¢ã«ä¾å­˜ã›ãšã«æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’é”æˆã—ã€ResNet-50ã§ImageNetã«ãŠã„ã¦74.3%ã®åˆ†é¡ç²¾åº¦ã‚’é”æˆã€ã‚ˆã‚Šå¤§ããªResNetã§ã¯79.6%ã«é”ã™ã‚‹ã€‚è»¢é€å­¦ç¿’ã‚„åŠæ•™å¸«ã‚ã‚Šãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ã€å®Ÿè£…ã¨äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:<br>


<a href="https://sn-neural-compute.netlify.app/202006250/" target="_blank" rel="noopener noreferrer">https://sn-neural-compute.netlify.app/202006250/</a>


</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/DataAugmentation.html" target="_blank" rel="noopener noreferrer">#DataAugmentation</a>
<a class="button" href="articles/ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<a class="button" href="articles/Self-SupervisedLearning.html" target="_blank" rel="noopener noreferrer">#Self-SupervisedLearning</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-05-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1975" target="_blank" rel="noopener noreferrer" class="title-link">A Simple Framework for Contrastive Learning of Visual Representations, Ting Chen+, ICML'20</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€è¦–è¦šè¡¨ç¾ã®å¯¾æ¯”å­¦ç¿’ã®ãŸã‚ã®ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯SimCLRã‚’ææ¡ˆã—ã€ç‰¹åˆ¥ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„ãƒ¡ãƒ¢ãƒªãƒãƒ³ã‚¯ãªã—ã§å¯¾æ¯”è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚’ç°¡ç´ åŒ–ã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®é‡è¦æ€§ã€å­¦ç¿’å¯èƒ½ãªéç·šå½¢å¤‰æ›ã®å°å…¥ã«ã‚ˆã‚‹è¡¨ç¾ã®è³ªå‘ä¸Šã€å¯¾æ¯”å­¦ç¿’ãŒå¤§ããªãƒãƒƒãƒã‚µã‚¤ã‚ºã¨å¤šãã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰åˆ©ç›Šã‚’å¾—ã‚‹ã“ã¨ã‚’ç¤ºã—ã€ImageNetã§å¾“æ¥ã®æ‰‹æ³•ã‚’ä¸Šå›ã‚‹çµæœã‚’é”æˆã—ã¾ã—ãŸã€‚SimCLRã«ã‚ˆã‚‹è‡ªå·±æ•™å¸«ã‚ã‚Šè¡¨ç¾ã‚’ç”¨ã„ãŸç·šå½¢åˆ†é¡å™¨ã¯76.5%ã®ãƒˆãƒƒãƒ—1ç²¾åº¦ã‚’é”æˆã—ã€æ•™å¸«ã‚ã‚ŠResNet-50ã«åŒ¹æ•µã—ã¾ã™ã€‚ãƒ©ãƒ™ãƒ«ã®1%ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸå ´åˆã€85.8%ã®ãƒˆãƒƒãƒ—5ç²¾åº¦ã‚’é”æˆã—ã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬:


<a href="https://techblog.cccmkhd.co.jp/entry/2022/08/30/163625" target="_blank" rel="noopener noreferrer">https://techblog.cccmkhd.co.jp/entry/2022/08/30/163625</a>


</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2025-05-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1960" target="_blank" rel="noopener noreferrer" class="title-link">PEGASUS: Pre-training with Extracted Gap-sentences for Abstractive   Summarization, Jingqing Zhang+, ICML'20</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ¼ãƒ‘ã‚¹ã«å¯¾ã—ã¦æ–°ã—ã„è‡ªå·±æ•™å¸«ã‚ã‚Šã®ç›®çš„ã§ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’äº‹å‰å­¦ç¿’ã—ã€æŠ½è±¡çš„ãªãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«PEGASUSã‚’ææ¡ˆã€‚é‡è¦ãªæ–‡ã‚’å‰Šé™¤ã¾ãŸã¯ãƒã‚¹ã‚¯ã—ã€æ®‹ã‚Šã®æ–‡ã‹ã‚‰è¦ç´„ã‚’ç”Ÿæˆã€‚12ã®ä¸‹æµè¦ç´„ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®ROUGEã‚¹ã‚³ã‚¢ã‚’é”æˆã—ã€é™ã‚‰ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã§ã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã€‚äººé–“è©•ä¾¡ã§ã‚‚è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§äººé–“ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«é”ã—ãŸã“ã¨ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>PEGASUSã‚‚ãªã‹ã£ãŸã®ã§è¿½åŠ ã€‚BARTã¨å…±ã«æ–‡æ›¸è¦ç´„ã®Backboneã¨ã—ã¦ä»Šã§ã‚‚ç ”ç©¶ã§åˆ©ç”¨ã•ã‚Œã‚‹æ¨¡æ§˜ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/984" target="_blank" rel="noopener noreferrer">SummEval: Re-evaluating Summarization Evaluation, Fabbri+, TACL'21</a>
</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/TransferLearning.html" target="_blank" rel="noopener noreferrer">#TransferLearning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1955" target="_blank" rel="noopener noreferrer" class="title-link">Exploring the Limits of Transfer Learning with a Unified Text-to-Text  Transformer, Colin Raffel+, JMLR'20</a>
<span class="snippet"><span>GPT Summary</span>- è»¢ç§»å­¦ç¿’ã¯NLPã«ãŠã„ã¦å¼·åŠ›ãªæŠ€è¡“ã§ã‚ã‚Šã€æœ¬è«–æ–‡ã§ã¯ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹çµ±ä¸€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚äº‹å‰å­¦ç¿’ã®ç›®çš„ã‚„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¯”è¼ƒã—ã€æœ€å…ˆç«¯ã®çµæœã‚’é”æˆã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„ãƒ¢ãƒ‡ãƒ«ã€ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹ã—ã€ä»Šå¾Œã®ç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>T5ã‚‚ãƒ¡ãƒ¢ã£ã¦ã„ãªã‹ã£ãŸã®ã§ä»Šæ›´ãªãŒã‚‰è¿½åŠ ã€‚å…¨ã¦ã®NLPã‚¿ã‚¹ã‚¯ã‚’ãƒ†ã‚­ã‚¹ãƒˆç³»åˆ—ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆç³»åˆ—ã¸å¤‰æ›ã™ã‚‹ã‚¿ã‚¹ã‚¯ã¨ã¿ãªã—ã€Encoder-Decoderã®Transformerã‚’å¤§è¦æ¨¡ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ç”¨ã„ã¦äº‹å‰å­¦ç¿’ã‚’ã—ã€downstreamã‚¿ã‚¹ã‚¯ã«finetuningã‚’é€šã˜ã¦è»¢ç§»ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/Decoding.html" target="_blank" rel="noopener noreferrer">#Decoding</a>
<span class="issue_date">Issue Date: 2025-04-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1889" target="_blank" rel="noopener noreferrer" class="title-link">The Curious Case of Neural Text Degeneration, Ari Holtzman+, ICLR'20</a>
<span class="snippet"><span>GPT Summary</span>- æ·±å±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ã¯é«˜å“è³ªãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«ãŠã„ã¦èª²é¡ŒãŒæ®‹ã‚‹ã€‚å°¤åº¦ã®ä½¿ç”¨ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã€äººé–“ã®ãƒ†ã‚­ã‚¹ãƒˆã¨æ©Ÿæ¢°ã®ãƒ†ã‚­ã‚¹ãƒˆã®é–“ã«åˆ†å¸ƒã®é•ã„ãŒã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆ¦ç•¥ãŒç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã®è³ªã«å¤§ããªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€ãƒ‹ãƒ¥ãƒ¼ã‚¯ãƒªã‚¢ã‚¹samplingã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å¤šæ§˜æ€§ã‚’ä¿ã¡ãªãŒã‚‰ä¿¡é ¼æ€§ã®ä½ã„éƒ¨åˆ†ã‚’æ’é™¤ã—ã€äººé–“ã®ãƒ†ã‚­ã‚¹ãƒˆã«è¿‘ã„è³ªã‚’å®Ÿç¾ã™ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>ç¾åœ¨ã®LLMã§ä¸»æµãªNucleus (top-p) Samplingã‚’ææ¡ˆã—ãŸç ”ç©¶</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2024-05-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1312" target="_blank" rel="noopener noreferrer" class="title-link">COMET: A Neural Framework for MT Evaluation, Ricardo Rei+, N_A, EMNLP'20</a>
<span class="snippet"><span>GPT Summary</span>- COMETã¯ã€å¤šè¨€èªæ©Ÿæ¢°ç¿»è¨³è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹ãŸã‚ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚Šã€äººé–“ã®åˆ¤æ–­ã¨ã®æ–°ã—ã„æœ€å…ˆç«¯ã®ç›¸é–¢ãƒ¬ãƒ™ãƒ«ã‚’é”æˆã—ã¾ã™ã€‚ã‚¯ãƒ­ã‚¹ãƒªãƒ³ã‚¬ãƒ«äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®é€²å±•ã‚’æ´»ç”¨ã—ã€é«˜åº¦ã«å¤šè¨€èªå¯¾å¿œã‹ã¤é©å¿œå¯èƒ½ãªMTè©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿç¾ã—ã¾ã™ã€‚WMT 2019 Metrics shared taskã§æ–°ãŸãªæœ€å…ˆç«¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã—ã€é«˜æ€§èƒ½ã‚·ã‚¹ãƒ†ãƒ ã«å¯¾ã™ã‚‹å …ç‰¢æ€§ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>Better/Worseãªhypothesisã‚’åˆ©ç”¨ã—ã¦pair-wiseã«ãƒ©ãƒ³ã‚­ãƒ³ã‚°é–¢æ•°ã‚’å­¦ç¿’ã™ã‚‹<br>![Image](https://github.com/user-attachments/assets/a1fd6f36-48e8-44fc-8fcb-0900a51759b3)<br><br>![Image](https://github.com/user-attachments/assets/19ad7a57-7de3-4255-afde-4a1fde41587d)<br><br>Inferenceæ™‚ã¯å˜ä¸€ã®hypothesisã—ã‹inputã•ã‚Œãªã„ã®ã§ã€sourceã¨referenceã«å¯¾ã—ã¦ãã‚Œãã‚Œhypothesisã®è·é›¢ã‚’ã¯ã‹ã‚Šã€ãã®èª¿å’Œå¹³å‡ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã™ã‚‹<br><br>![Image](https://github.com/user-attachments/assets/21642c70-a7fd-4c0e-8678-6125fdbfefce)</p>
<p>ACL2024, EMNLP2024ã‚ãŸã‚Šã®MTç ”ç©¶ã®metricã‚’ã–ãƒ¼ã£ã¨è¦‹ã‚‹é™ã‚Šã€BLEU/COMETã®åŒæ–¹ã§è©•ä¾¡ã™ã‚‹ç ”ç©¶ãŒå¤šãã†</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/ActivationFunction.html" target="_blank" rel="noopener noreferrer">#ActivationFunction</a>
<span class="issue_date">Issue Date: 2024-05-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1311" target="_blank" rel="noopener noreferrer" class="title-link">GLU Variants Improve Transformer, Noam Shazeer, N_A, arXiv'20</a>
<span class="snippet"><span>GPT Summary</span>- GLUã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’Transformerã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ»ã‚µãƒ–ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ãƒ†ã‚¹ãƒˆã—ã€é€šå¸¸ã®æ´»æ€§åŒ–é–¢æ•°ã‚ˆã‚Šã‚‚ã„ãã¤ã‹ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒå“è³ªå‘ä¸Šã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ã‚’ç™ºè¦‹ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ä¸€èˆ¬çš„ãªFFNã§ã¯ã€linear layerã‚’ã‹ã‘ãŸå¾Œã«ã€ä½•ã‚‰ã‹ã®æ´»æ€§åŒ–é–¢æ•°ã‚’ã‹ã¾ã›ã‚‹æ–¹æ³•ãŒä¸»æµã§ã‚ã‚‹ã€‚<br><br>ã“ã®ã‚ˆã†ãªæ§‹é€ ã®ä¸€ã¤ã¨ã—ã¦GLUãŒã‚ã‚‹ãŒã€linear layerã¨æ´»æ€§åŒ–é–¢æ•°ã«ã¯æ”¹è‰¯ã®ä½™åœ°ãŒã‚ã‚Šã€æ§˜ã€…ãªvariantãŒè€ƒãˆã‚‰ã‚Œã‚‹ãŸã‚ã€è‰²ã€…è©¦ã—ã¾ã—ãŸã€ã¨ã„ã†ã¯ãªã—ã€‚<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/72b1d0bb-64ac-4155-9a3b-5624cd06ccc9" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b38321c6-d414-4764-9147-10a5fa83fbe6" alt="image" loading="lazy"><br><br><br><br>ã‚ªãƒªã‚¸ãƒŠãƒ«ã®GLUã¨æ¯”è¼ƒã—ã¦ã€T5ã¨åŒã˜äº‹å‰å­¦ç¿’ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã—ãŸã¨ã“ã‚ã€perplexityãŒæ”¹å–„<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9e67a054-2148-41ed-aae1-5a752c21a242" alt="image" loading="lazy"><br><br><br><br>ã¾ãŸã€finetuningã‚’ã—ãŸå ´åˆã®æ€§èƒ½ã‚‚ã€å¤šãã®å ´åˆã‚ªãƒªã‚¸ãƒŠãƒ«ã®GLUã‚ˆã‚Šã‚‚é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/77ccab88-e5cc-48fc-b9e0-f2dad24e53e8" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8f60ca8c-50eb-4869-bab4-f02ec6d8e085" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8124fc25-aa7e-4e10-8cd2-9d24c818f410" alt="image" loading="lazy"><br><br><br><br><br><br></p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<span class="issue_date">Issue Date: 2023-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1168" target="_blank" rel="noopener noreferrer" class="title-link">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks, Patrick Lewis+, N_A, NeurIPS'20</a>
<span class="snippet"><span>GPT Summary</span>- å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢å¼·åŒ–ç”Ÿæˆï¼ˆRAGï¼‰ã®å¾®èª¿æ•´æ‰‹æ³•ã‚’ææ¡ˆã—ã¾ã—ãŸã€‚RAGãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã¨éãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãƒ¡ãƒ¢ãƒªã‚’çµ„ã¿åˆã‚ã›ãŸè¨€èªç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€å¹…åºƒã„çŸ¥è­˜é›†ç´„çš„ãªè‡ªç„¶è¨€èªå‡¦ç†ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ç™ºæ®ã—ã¾ã—ãŸã€‚ç‰¹ã«ã€QAã‚¿ã‚¹ã‚¯ã§ã¯ä»–ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã€è¨€èªç”Ÿæˆã‚¿ã‚¹ã‚¯ã§ã¯å…·ä½“çš„ã§å¤šæ§˜ãªè¨€èªã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>RAGã‚’ææ¡ˆã—ãŸç ”ç©¶<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/77d4c13d-c26c-40e1-8429-1a879769587e" alt="image" loading="lazy"><br><br></p>
<p>Retrieverã¨ã—ã¦åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹Dense Passage Retrieval (DPR)ã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3016" target="_blank" rel="noopener noreferrer">[Paper Note] Dense Passage Retrieval for Open-Domain Question Answering, Vladimir Karpukhin+, EMNLP'20, 2020.04</a>
</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reference-based.html" target="_blank" rel="noopener noreferrer">#Reference-based</a>
<span class="issue_date">Issue Date: 2023-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/668" target="_blank" rel="noopener noreferrer" class="title-link">BERTScore: Evaluating Text Generation with BERT, Tianyi Zhang+, N_A, ICLR'20</a>
<span class="snippet"><span>GPT Summary</span>- BERTScoreã¯ã€æ–‡è„ˆåŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®è‡ªå‹•è©•ä¾¡ãƒ¡ãƒˆãƒªãƒƒã‚¯ã§ã‚ã‚Šã€363ã®æ©Ÿæ¢°ç¿»è¨³ãŠã‚ˆã³ç”»åƒã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®å‡ºåŠ›ã‚’ä½¿ç”¨ã—ã¦è©•ä¾¡ã•ã‚Œã¾ã—ãŸã€‚BERTScoreã¯ã€æ—¢å­˜ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚ˆã‚Šã‚‚äººé–“ã®åˆ¤æ–­ã¨ã®ç›¸é–¢ãŒé«˜ãã€ã‚ˆã‚Šå¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«é¸æŠæ€§èƒ½ã‚’æä¾›ã—ã€æ•µå¯¾çš„ãªè¨€ã„æ›ãˆæ¤œå‡ºã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã‚‚ã‚ˆã‚Šå …ç‰¢ã§ã‚ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¾ã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>
<strong># æ¦‚è¦<br>æ—¢å­˜ã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®è©•ä¾¡æ‰‹æ³•ï¼ˆBLEUã‚„METEORï¼‰ã¯surface levelã®ãƒãƒƒãƒãƒ³ã‚°ã—ã‹ã—ã¦ãŠã‚‰ãšã€æ„å‘³ã‚’ã¨ã‚‰ãˆã‚‰ã‚ŒãŸè©•ä¾¡ã«ãªã£ã¦ã„ãªã‹ã£ãŸã®ã§ã€pretrained BERTã®embeddingã‚’ç”¨ã„ã¦similarityã‚’æ¸¬ã‚‹ã‚ˆã†ãªæŒ‡æ¨™ã‚’ææ¡ˆã—ã¾ã—ãŸã‚ˆã€ã¨ã„ã†è©±ã€‚<br><br># prior metrics<br>## n-gram matching approaches<br>n-gramãŒreferenceã¨candidateã§ã©ã‚Œã ã‘é‡è¤‡ã—ã¦ã„ã‚‹ã‹ã§Precisionã¨recallã‚’æ¸¬å®š<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a620d564-72e3-4078-97e2-1ff62b333324" alt="image" loading="lazy"><br><br>### BLEU<br>MTã§æœ€ã‚‚åˆ©ç”¨ã•ã‚Œã‚‹ã€‚n-gramã®Precisionï¼ˆå…¸å‹çš„ã«ã¯n=1,2,3,4ï¼‰ã¨çŸ­ã™ãã‚‹å€™è£œè¨³ã«ã¯ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’ä¸ãˆã‚‹ï¼ˆbrevity penaltyï¼‰ã“ã¨ã§å®Ÿç¾ã•ã‚Œã‚‹æŒ‡æ¨™ã€‚SENT-BLEUã¨ã„ã£ãŸäºœç¨®ã‚‚ã‚ã‚‹ã€‚BLEUã¨æ¯”è¼ƒã—ã¦ã€BERTScoreã¯ã€n-gramã®é•·ã•ã®åˆ¶ç´„ã‚’å—ã‘ãšã€æ½œåœ¨çš„ã«ã¯é•·ã•ã®åˆ¶é™ãŒãªã„dependencyã‚’contextualized embeddingsã§ã¨ã‚‰ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br>### METEOR<br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/669" target="_blank" rel="noopener noreferrer">METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments, Banerjee+, CMU, ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization</a>
</strong>
<br>
 METEOR 1.5ã§ã¯ã€å†…å®¹èªã¨æ©Ÿèƒ½èªã«ç•°ãªã‚‹weightã‚’å‰²ã‚Šå½“ã¦ã€ãƒãƒƒãƒãƒ³ã‚°ã‚¿ã‚¤ãƒ—ã«ã‚ˆã£ã¦ã‚‚weightã‚’å¤‰æ›´ã™ã‚‹ã€‚METEOR++2.0ã§ã¯ã€å­¦ç¿’æ¸ˆã¿ã®å¤–éƒ¨ã®paraphrase resourceã‚’æ´»ç”¨ã™ã‚‹ã€‚METEORã¯å¤–éƒ¨ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å¿…è¦ã¨ã™ã‚‹ãŸã‚ã€ãŸã£ãŸ5ã¤ã®è¨€èªã§ã—ã‹full feature setã§ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ã€‚11ã®è¨€èªã§ã¯ã€æ¥éƒ¨ã®featureãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã€‚METEORã¨åŒæ§˜ã«ã€BERTScoreã§ã‚‚ã€ãƒãƒƒãƒã«ç·©å’Œã‚’å…¥ã‚Œã¦ã„ã‚‹ã“ã¨ã«ç›¸å½“ã™ã‚‹ãŒã€BERTã®äº‹å‰å­¦ç¿’æ¸ˆã¿ã®embeddingã¯104ã®è¨€èªã§å–å¾—å¯èƒ½ã§ã‚ã‚‹ã€‚BERTScoreã¯ã¾ãŸã€é‡è¦åº¦ã«ã‚ˆã‚‹weightingã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ï¼ˆã‚³ãƒ¼ãƒ‘ã‚¹ã®çµ±è¨ˆé‡ã§æ¨å®šï¼‰ã€‚<br><br>### Other Related Metrics<br>- NIST: BLEUã¨ã¯ç•°ãªã‚‹n-gramã®é‡ã¿ã¥ã‘ã¨ã€brevity penaltyã‚’åˆ©ç”¨ã™ã‚‹<br>- Î”BLEU: multi-reference BLEUã‚’ã€äººæ‰‹ã§ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸnegative reference sentenceã§å¤‰æ›´ã™ã‚‹<br>- CHRF: æ–‡å­—n-gramã‚’æ¯”è¼ƒã™ã‚‹<br>- CHRF++: CHRFã‚’word-bigram matchingã«æ‹¡å¼µã—ãŸã‚‚ã®<br>- ROUGE: æ–‡æ›¸è¦ç´„ã§åˆ©ç”¨ã•ã‚Œã‚‹æŒ‡æ¨™ã€‚ROUGE-N, ROUGE^Lã¨ã„ã£ãŸæ§˜ã€…ãªå¤‰ç¨®ãŒã‚ã‚‹ã€‚<br>- CIDEr: image captioningã®metricã§ã‚ã‚Šã€n-gramã®tf-idfã§é‡ã¿ã¥ã‘ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ã®cosine similrityã‚’æ¸¬å®šã™ã‚‹<br><br>## Edit-distance based Metrics<br>- Word Error Rate (WER): candidateã‹ã‚‰referenceã‚’å†ç¾ã™ã‚‹ã¾ã§ã«å¿…è¦ãªedit operationã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹æ‰‹æ³•<br>- Translation Edit Rate (TER): referenceã®å˜èªæ•°ã«ã‚ˆã£ã¦candidateã‹ã‚‰referenceã¾ã§ã®edit distanceã‚’æ­£è¦åŒ–ã™ã‚‹æ‰‹æ³•<br>- ITER: èªå¹¹ã®ãƒãƒƒãƒã¨ã€ã‚ˆã‚Šè‰¯ã„æ­£è¦åŒ–ã«åŸºã¥ãæ‰‹æ³•<br>- PER: positionã¨ã¯ç‹¬ç«‹ã—ãŸError Rateã‚’ç®—å‡º<br>- CDER: edit operationã«ãŠã‘ã‚‹block reorderingã‚’ãƒ¢ãƒ‡ãƒ«åŒ–<br>- CHARACTER / EED: character levelã§è©•ä¾¡<br><br>## Embedding-based Metrics<br>- MEANT 2.0: lexical, structuralã®é¡ä¼¼åº¦ã‚’æ¸¬ã‚‹ãŸã‚ã«ã€word embeddingã¨shallow semantic parsesã‚’åˆ©ç”¨<br>- YISI-1: MEANT 2.0ã¨åŒæ§˜ã ãŒã€semantic parseã®åˆ©ç”¨ãŒoptionalã¨ãªã£ã¦ã„ã‚‹<br>ã“ã‚Œã‚‰ã¯BERTScoreã¨åŒæ§˜ã®ã€similarityã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«æ¸¬ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€BERTScoreã‚‚ã“ã‚Œã«inspireã•ã‚Œã¦ã„ã‚‹ã€‚ãŒã€BERTScoreã¯Contextualized Embeddingã‚’åˆ©ç”¨ã™ã‚‹ç‚¹ãŒç•°ãªã‚‹ã€‚ã¾ãŸã€linguistic structureã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ãªå¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã¯åˆ©ç”¨ã—ãªã„ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€BERTScoreã‚’ã‚·ãƒ³ãƒ—ãƒ«ã§ã€æ–°ãŸãªlanguageã«å¯¾ã—ã¦ã‚‚ä½¿ã„ã‚„ã™ãã—ã¦ã„ã‚‹ã€‚greedy matchingã®ä»£ã‚ã‚Šã«ã€WMD, WMDo, SMSã¯earth mover's distanceã«åŸºã¥ãæœ€é©ãªãƒãƒƒãƒãƒ³ã‚°ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚greedy matchingã¨optimal matchingã®tradeoffã«ã¤ã„ã¦ã¯ç ”ç©¶ã•ã‚Œã¦ã„ã‚‹ã€‚sentence-levelã®similarityã‚’è¨ˆç®—ã™ã‚‹æ‰‹æ³•ã‚‚ææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã‚Œã‚‰ã¨æ¯”è¼ƒã—ã¦ã€BERTScoreã®token-levelã®è¨ˆç®—ã¯ã€é‡è¦åº¦ã«å¿œã˜ã¦ã€tokenã«å¯¾ã—ã¦ç•°ãªã‚‹é‡ã¿ã¥ã‘ã‚’ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br>## Learned Metrics<br>æ§˜ã€…ãªmetricãŒã€human judgmentsã¨ã®correlationã«æœ€é©åŒ–ã™ã‚‹ãŸã‚ã«è¨“ç·´ã•ã‚Œã¦ããŸã€‚<br>- BEER: character-ngram, word bigramã«åŸºã¥ã„ãŸregresison modelã‚’åˆ©ç”¨<br>- BLEND: 29ã®æ—¢å­˜ã®metricã‚’åˆ©ç”¨ã—ã¦regressionã‚’å®Ÿæ–½<br>- RUSE: 3ç¨®é¡ã®pre-trained sentence embedding modelã‚’åˆ©ç”¨ã™ã‚‹æ‰‹æ³•<br>ã“ã‚Œã‚‰ã™ã¹ã¦ã®æ‰‹æ³•ã¯ã€ã‚³ã‚¹ãƒˆã®ã‹ã‹ã‚‹human judgmentsã«ã‚ˆã‚‹supervisionãŒå¿…è¦ã¨ãªã‚‹ã€‚ãã—ã¦ã€æ–°ãŸãªãƒ‰ãƒ¡ã‚¤ãƒ³ã«ãŠã‘ã‚‹æ±åŒ–èƒ½åŠ›ã®ä½ã•ã®ãƒªã‚¹ã‚¯ãŒã‚ã‚‹ã€‚input textãŒäººé–“ãŒç”Ÿæˆã—ãŸã‚‚ã®ã‹å¦ã‹äºˆæ¸¬ã™ã‚‹neural modelã‚’è¨“ç·´ã™ã‚‹æ‰‹æ³•ã‚‚ã‚ã‚‹ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æœ€é©åŒ–ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€æ–°ãŸãªãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦æ±åŒ–ã•ã‚Œãªã„ãƒªã‚¹ã‚¯ã‚’æŒã£ã¦ã„ã‚‹ã€‚ã“ã‚Œã‚‰ã¨æ¯”è¼ƒã—ã¦ã€BERTScoreã¯ç‰¹å®šã®evaluation taskã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„ã€‚<br><br># BERTScore<br>referenceã¨candidateã®ãƒˆãƒ¼ã‚¯ãƒ³é–“ã®similarityã®æœ€å¤§å€¤ã‚’ã¨ã‚Šã€ãã‚Œã‚‰ã‚’é›†ç´„ã™ã‚‹ã“ã¨ã§ã€Precision, Recallã‚’å®šç¾©ã—ã€Precisionã¨Recallã‚’åˆ©ç”¨ã—ã¦Få€¤ã‚‚è¨ˆç®—ã™ã‚‹ã€‚Recallã¯ã€referenceä¸­ã®ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾ã—ã¦ã€candidateä¸­ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã®cosine similarityã®æœ€å¤§å€¤ã‚’æ¸¬ã‚‹ã€‚ä¸€æ–¹ã€Precisionã¯ã€candidateä¸­ã®ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾ã—ã¦ã€referenceä¸­ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã®cosine similarityã®æœ€å¤§å€¤ã‚’æ¸¬ã‚‹ã€‚ã“ã“ã§ã€é¡ä¼¼åº¦ã®å¼ãŒå˜ãªã‚‹å†…ç©ã«ãªã£ã¦ã„ã‚‹ãŒã€ã“ã‚Œã¯pre-normalized vectorã‚’åˆ©ç”¨ã™ã‚‹å‰æã§ã‚ã‚Šã€æ­£è¦åŒ–ãŒå¿…è¦ãªã„ã‹ã‚‰ã§ã‚ã‚‹ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9ed88ea6-8ecf-465c-81d5-bc85592ad7ff" alt="image" loading="lazy"><br><br>ã¾ãŸã€IDFã«ã‚ˆã‚‹ãƒˆãƒ¼ã‚¯ãƒ³å˜ä½ã§ã®weightingã‚’å®Ÿæ–½ã™ã‚‹ã€‚IDFã¯ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã®å€¤ã‚’åˆ©ç”¨ã™ã‚‹ã€‚TFã‚’ä½¿ã‚ãªã„ç†ç”±ã¯ã€BERTScoreã¯sentenceåŒå£«ã‚’æ¯”è¼ƒã™ã‚‹æŒ‡æ¨™ã§ã‚ã‚‹ãŸã‚ã€TFã¯åŸºæœ¬çš„ã«1ã¨ãªã‚Šã‚„ã™ã„å‚¾å‘ã«ã‚ã‚‹ãŸã‚ã§ã‚ã‚‹ã€‚IDFã‚’è¨ˆç®—ã™ã‚‹éš›ã¯å‡ºç¾æ•°ã‚’+1ã™ã‚‹ã“ã¨ã«ã‚ˆã‚‹ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã‚’å®Ÿæ–½ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d4b132fb-7830-4a00-b845-11f38b909bba" alt="image" loading="lazy"><br><br>ã•ã‚‰ã«ã€ã“ã‚Œã¯BERTScoreã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°èƒ½åŠ›ã«ã¯å½±éŸ¿ã‚’ä¸ãˆãªã„ãŒã€BERTScoreã®å€¤ã¯ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã«åŸºã¥ã„ã¦ã„ã‚‹ãŸã‚ã€[-1, 1]ã¨ãªã‚‹ãŒã€å®Ÿéš›ã¯å­¦ç¿’ã—ãŸcontextual embeddingã®geometryã«å€¤åŸŸãŒä¾å­˜ã™ã‚‹ãŸã‚ã€ã‚‚ã£ã¨å°ã•ãªãƒ¬ãƒ³ã‚¸ã§ã®å€¤ã‚’ã¨ã‚‹ã“ã¨ã«ãªã£ã¦ã—ã¾ã†ã€‚ãã†ã™ã‚‹ã¨ã€äººé–“ã«ã‚ˆã‚‹è§£é‡ˆãŒé›£ã—ããªã‚‹ï¼ˆãŸã¨ãˆã°ã€æ¥µç«¯ãªè©±ã€ã‚¹ã‚³ã‚¢ã®0.1ç¨‹åº¦ã®å¤‰åŒ–ãŒã‚ã¡ã‚ƒã‚ã¡ã‚ƒå¤§ããªå¤‰åŒ–ã«ãªã£ã¦ã—ã¾ã†ãªã©ï¼‰ãŸã‚ã€rescalingã‚’å®Ÿæ–½ã€‚rescalingã™ã‚‹éš›ã¯ã€monolingualã‚³ãƒ¼ãƒ‘ã‚¹ã‹ã‚‰ã€ãƒ©ãƒ³ãƒ€ãƒ ã«sentenceã®ãƒšã‚¢ã‚’ä½œæˆã—ï¼ˆBETRScoreãŒéå¸¸ã«å°ã•ããªã‚‹ã‚±ãƒ¼ã‚¹ï¼‰ã€ã“ã‚Œã‚‰ã®BERTScoreã‚’å¹³å‡ã™ã‚‹ã“ã¨ã§bã‚’ç®—å‡ºã—ã€bã‚’åˆ©ç”¨ã—ã¦rescalingã—ãŸã€‚å…¸å‹çš„ã«ã¯ã€rescalingå¾Œã¯å…¸å‹çš„ã«ã¯[0, 1]ã®ç¯„å›²ã§BERTScoreã¯å€¤ã‚’ã¨ã‚‹ï¼ˆãŸã ã—æ•°å¼ã‚’è¦‹ã¦ã‚ã‹ã‚‹é€šã‚Š[0, 1]ã¨ãªã‚‹ã“ã¨ãŒä¿è¨¼ã•ã‚Œã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ç‚¹ã«æ³¨æ„ï¼‰ã€‚ã“ã‚Œã¯human judgmentsã¨ã®correlationã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆãªã„ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ã‚’å¤‰ãˆã¦ã„ã‚‹ã ã‘ãªã®ã§ï¼‰ã€‚<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9049ed99-d192-465d-b4fe-d628bc673927" alt="image" loading="lazy"><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/bb78074e-2fa4-4bb3-a920-df543aeb98b8" alt="image" loading="lazy"><br></p>
<p># å®Ÿé¨“<br><br>## Contextual Embedding Models<br><br>12ç¨®é¡ã®ãƒ¢ãƒ‡ãƒ«ã§æ¤œè¨¼ã€‚BERT, RoBERTa, XLNet, XLMãªã©ã€‚<br><br><br><br>## Machine Translation<br><br>WMT18ã®metric evaluation datasetã‚’åˆ©ç”¨ã€‚149ç¨®é¡ã®MTã‚·ã‚¹ãƒ†ãƒ ã®14 languageã«å¯¾ã™ã‚‹ç¿»è¨³çµæœ, gold referencesã¨2ç¨®é¡ã®human judgment scoreãŒä»˜ä¸ã•ã‚Œã¦ã„ã‚‹ã€‚segment-level human judgmentsã¯ã€ãã‚Œãã‚Œã®reference-candiate pairã«å¯¾ã—ã¦ä»˜ä¸ã•ã‚Œã¦ãŠã‚Šã€system-level human judgmentsã¯ã€ãã‚Œãã‚Œã®ã‚·ã‚¹ãƒ†ãƒ ã«å¯¾ã—ã¦ã€test setå…¨ä½“ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã€å˜ä¸€ã®ã‚¹ã‚³ã‚¢ãŒä»˜ä¸ã•ã‚Œã¦ã„ã‚‹ã€‚pearson correlationã®çµ¶å¯¾å€¤ã¨ã€kendall rank correration Ï„ã‚’metricsã®å“è³ªã®è©•ä¾¡ã«åˆ©ç”¨ã€‚ãã—ã¦peason correlationã«ã¤ã„ã¦ã¯Williams testã€kendall Ï„ã«ã¤ã„ã¦ã¯ã€bootstrap re-samplingã«ã‚ˆã£ã¦æœ‰æ„å·®ã‚’æ¤œå®šã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã®ã‚¹ã‚³ã‚¢ã‚’BERTScoreã‚’ã™ã¹ã¦ã®reference-candidate pairã«å¯¾ã™ã‚‹ã‚¹ã‚³ã‚¢ã‚’averagingã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦æ±‚ã‚ãŸã€‚ã¾ãŸã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦ã‚‚å®Ÿé¨“ã‚’ã—ãŸã€‚å…·ä½“çš„ã«ã¯ã€ãã‚Œãã‚Œã®reference sentenceã«ã¤ã„ã¦ã€ã‚·ã‚¹ãƒ†ãƒ ã®ä¸­ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«candidate sentenceã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€system-level experimentã‚’ã‚ˆã‚Šå¤šãã®ã‚·ã‚¹ãƒ†ãƒ ã§å®Ÿç¾ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¬4ãƒ™ãƒ«ã®human judgmentsã¯ã€WMT18ã®segment-level human judgmentsã‚’å¹³å‡ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦ä½œæˆã—ãŸã€‚BERTScoreã‚’æ—¢å­˜ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨æ¯”è¼ƒã—ãŸã€‚<br><br><br><br>é€šå¸¸ã®è©•ä¾¡ã«åŠ ãˆã¦ã€ãƒ¢ãƒ‡ãƒ«é¸æŠã«ã¤ã„ã¦ã‚‚å®Ÿé¨“ã—ãŸã€‚10kã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆ©ç”¨ã—ã€10kã®ã†ã¡100ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã€ãã—ã¦è‡ªå‹•æ€§èƒ½æŒ‡æ¨™ã§ãã‚Œã‚‰ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã—ãŸã€‚ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’100Kå›ç¹°ã‚Šè¿”ã—ã€human rankingã¨metricã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒã©ã‚Œã ã‘agreementãŒã‚ã‚‹ã‹ã‚’Hits@1ã§è©•ä¾¡ã—ãŸï¼ˆbest systemã®ä¸€è‡´ã§è©•ä¾¡ï¼‰ã€‚ãƒ¢ãƒ‡ãƒ«é¸æŠã®æŒ‡æ¨™ã¨ã—ã¦æ–°ãŸã«top metric-rated systemã¨human rankingã®é–“ã§ã®MRR, äººæ‰‹è©•ä¾¡ã§top-rated systemã¨ãªã£ãŸã‚·ã‚¹ãƒ†ãƒ ã¨ã®ã‚¹ã‚³ã‚¢ã®å·®ã‚’ç®—å‡ºã—ãŸã€‚WMT17, 16ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚åŒæ§˜ã®è©•ä¾¡ã‚’å®Ÿæ–½ã—ãŸã€‚<br><br><br><br>## Image Captioning<br><br>COCO 2015 captioning challengeã«ãŠã‘ã‚‹12ç¨®é¡ã®ã‚·ã‚¹ãƒ†ãƒ ã®submissionãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã€‚COCO validationã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ã€ãã‚Œãã‚Œã®ã‚·ã‚¹ãƒ†ãƒ ã¯imageã«å¯¾ã™ã‚‹captionã‚’ç”Ÿæˆã—ã€ãã‚Œãã‚Œã®imageã¯ãŠã‚ˆã5å€‹ã®referenceã‚’æŒã£ã¦ã„ã‚‹ã€‚å…ˆè¡Œç ”ç©¶ã«ãªã‚‰ã„ã€Person Correlationã‚’2ç¨®é¡ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«metricã§æ¸¬å®šã—ãŸã€‚<br><br>- M1: äººé–“ã«ã‚ˆã‚‹captionã¨åŒç­‰ã€ã‚ã‚‹ã„ã¯ãã‚Œä»¥ä¸Šã¨è©•ä¾¡ã•ã‚ŒãŸcaptionã®å‰²åˆ<br><br>- M2: äººé–“ã«ã‚ˆã‚‹captionã¨åŒºåˆ¥ãŒã¤ã‹ãªã„captionã®å‰²åˆ<br><br>BERTScoreã‚’multiple referenceã«å¯¾ã—ã¦è¨ˆç®—ã—ã€æœ€ã‚‚é«˜ã„ã‚¹ã‚³ã‚¢ã‚’æ¡ç”¨ã—ãŸã€‚æ¯”è¼ƒå¯¾è±¡ã®metricã¯task-agnostic metricã‚’æ¡ç”¨ã—ã€BLEU, METEOR, CIDEr, BEER, EED, CHRF++, CHARACTERã¨æ¯”è¼ƒã—ãŸã€‚ãã—ã¦ã€2ç¨®é¡ã®task-specific metricsã¨ã‚‚æ¯”è¼ƒã—ãŸï¼šSPICE, LEIC<br><br><br><br># å®Ÿé¨“çµæœ<br><br>## Machine Translation<br><br>system-levelã®human judgmentsã¨ã®correlationã®æ¯”è¼ƒã€hybrid systemã¨ã®correlationã®æ¯”è¼ƒã€model selection performance<br><br>to-Englishã®çµæœã§ã¯ã€BERTScoreãŒæœ€ã‚‚ä¸€è²«ã—ã¦æ€§èƒ½ãŒè‰¯ã‹ã£ãŸã€‚RUSEãŒcompetitiveãªæ€§èƒ½ã‚’ç¤ºã—ãŸãŒã€RUSEã¯supervised methodã§ã‚ã‚‹ã€‚from-Englishã®å®Ÿé¨“ã§ã¯ã€RUSEã¯è¿½åŠ ã®ãƒ‡ãƒ¼ã‚¿ã¨è¨“ç·´ã‚’ã—ãªã„ã¨é©ç”¨ã§ããªã„ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/e3b0482e-a30b-46be-b8df-72a1c4fe510d" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b769ac8f-1a43-48d6-9316-cb78cffc3b88" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/3b204434-9f9a-4672-be5a-6e463d3289f4" alt="image" loading="lazy"><br><br><br><br>ä»¥ä¸‹ã¯ã€segment-levelã®correlationã‚’ç¤ºã—ãŸã‚‚ã®ã§ã‚ã‚‹ã€‚BERTScoreãŒä¸€è²«ã—ã¦é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚BLEUã‹ã‚‰å¤§å¹…ãªæ€§èƒ½ã‚¢ãƒƒãƒ—ã‚’ç¤ºã—ã¦ãŠã‚Šã€ç‰¹å®šã®exampleã«ã¤ã„ã¦ã®è‰¯ã•ã‚’æ¤œè¨¼ã™ã‚‹ãŸã‚ã«ã¯ã€BERTScoreãŒæœ€é©ã§ã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚BERTScoreã¯ã€RUSEã‚’significantlyã«ä¸Šå›ã£ã¦ã„ã‚‹ã€‚idfã«ã‚ˆã‚‹é‡è¦åº¦ã®weightingã«ã‚ˆã£ã¦ã€å…¨ä½“ã¨ã—ã¦ã¯ã€small benefitãŒã‚ã‚‹å ´åˆãŒã‚ã‚‹ãŒå…¨ä½“ã¨ã—ã¦ã¯ã‚ã‚“ã¾ã‚ŠåŠ¹æœãŒãªã‹ã£ãŸã€‚importance weightingã¯ä»Šå¾Œã®èª²é¡Œã§ã‚ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ä¾å­˜ã™ã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã€‚FBERTãŒç•°ãªã‚‹è¨­å®šã§ã‚‚è‰¯ãæ©Ÿèƒ½ã™ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚ç•°ãªã‚‹contextual embedding modelé–“ã§ã®æ¯”è¼ƒãªã©ã¯ã€appendixã«ç¤ºã™ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1684fa38-0663-4649-849f-1885cd97286e" alt="image" loading="lazy"><br><br><br><br>## Image Captioning<br><br>task-agnostic metricã®é–“ã§ã¯ã€BETRScoreã¯large marginã§å‹ã£ã¦ã„ã‚‹ã€‚image captioningã¯challengingãªè©•ä¾¡ãªã®ã§ã€n-gramãƒãƒƒãƒã«åŸºã¥ãBLEU, ROUGEã¯ã¾ã£ãŸãæ©Ÿèƒ½ã—ã¦ã„ãªã„ã€‚ã¾ãŸã€idf weightingãŒã“ã®ã‚¿ã‚¹ã‚¯ã§ã¯éå¸¸ã«é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã“ã‚Œã¯äººé–“ãŒcontent wordsã«å¯¾ã—ã¦ã€ã‚ˆã‚Šé«˜ã„é‡è¦åº¦ã‚’ç½®ã„ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚æœ€å¾Œã«ã€LEICã¯trained metricã§ã‚ã‚Šã€COCO dataã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã®æ‰‹æ³•ã¯ã€ã»ã‹ã®ã™ã¹ã¦ã®metricã‚’ä¸Šå›ã£ãŸã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5842611a-38bd-441f-a467-8bb3714dc33a" alt="image" loading="lazy"><br><br><br><br>## Speed<br><br>pre-trained modelã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€BERTScoreã¯æ¯”è¼ƒçš„é«˜é€Ÿã«å‹•ä½œã™ã‚‹ã€‚192.5 candidate-reference pairs/secondãã‚‰ã„å‡ºã‚‹ï¼ˆGTX-1080Ti GPUã§ï¼‰ã€‚WMT18ãƒ‡ãƒ¼ã‚¿ã§ã¯ã€15.6ç§’ã§å‡¦ç†ãŒçµ‚ã‚ã‚Šã€SacreBLEUã§ã¯5.4ç§’ã§ã‚ã‚‹ã€‚è¨ˆç®—ã‚³ã‚¹ãƒˆãã‚“ãªã«ãªã„ã®ã§ã€BERTScoreã¯stoppingã®validationã¨ã‹ã«ã‚‚ä½¿ãˆã‚‹ã€‚</p>
<p># Robustness analysis<br><br>BERTScoreã®ãƒ­ãƒã‚¹ãƒˆæ€§ã‚’adversarial paraphrase classificationã§ãƒ†ã‚¹ãƒˆã€‚Quora Question Pair corpus (QQP) ã‚’åˆ©ç”¨ã—ã€Word Scrambling dataset (PAWS) ã‹ã‚‰Paraphrase Adversariesã‚’å–å¾—ã€‚ã©ã¡ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚‚ã€å„sentenceãƒšã‚¢ã«å¯¾ã—ã¦ã€ãã‚Œã‚‰ãŒparaphraseã‹ã©ã†ã‹ãƒ©ãƒ™ãƒ«ä»˜ã‘ã•ã‚Œã¦ã„ã‚‹ã€‚QQPã®æ­£ä¾‹ã¯ã€å®Ÿéš›ã®duplicate questionã‹ã‚‰ãã¦ãŠã‚Šã€è² ä¾‹ã¯é–¢é€£ã™ã‚‹ãŒã€ç•°ãªã‚‹è³ªå•ã‹ã‚‰ãã¦ã„ã‚‹ã€‚PAWSã®sentence pairsã¯å˜èªã®å…¥ã‚Œæ›¿ãˆã«åŸºã¥ã„ã¦ã„ã‚‹ã‚‚ã®ã§ã‚ã‚‹ã€‚ãŸã¨ãˆã°ã€"Flights from New York to Florida" ã¯ "Flights from Florida to New York" ã®ã‚ˆã†ã«å¤‰æ›ã•ã‚Œã€è‰¯ã„classifierã¯ã“ã‚Œã‚‰ãŒparaphraseã§ã¯ãªã„ã¨èªè­˜ã§ããªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚PAWSã¯PAWS_QQPã¨PAWS_WIKIã«ã‚ˆã£ã¦æ§‹æˆã•ãˆï½’ã¦ãŠã‚Šã€PAWS_QQPã‚’develpoment setã¨ã—ãŸã€‚automatic metricsã§ã¯ã€paraphrase detection training dataã¯åˆ©ç”¨ã—ãªã„ã‚ˆã†ã«ã—ãŸã€‚è‡ªå‹•æ€§èƒ½æŒ‡æ¨™ã§é«˜ã„ã‚¹ã‚³ã‚¢ã‚’ç²å¾—ã™ã‚‹ã‚‚ã®ã¯ã€paraphraseã§ã‚ã‚‹ã“ã¨ã‚’æƒ³å®šã—ã¦ã„ã‚‹ã€‚<br><br><br><br>ä¸‹å›³ã¯AUCã®ROC curveã‚’è¡¨ã—ã¦ãŠã‚Šã€PAWS_QQPã«ãŠã„ã¦ã€QQPã§è¨“ç·´ã•ã‚ŒãŸclassifierã¯random guessã‚ˆã‚Šã‚‚æ€§èƒ½ãŒä½ããªã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸã€‚ã¤ã¾ã‚Šã“ã‚Œã‚‰ãƒ¢ãƒ‡ãƒ«ã¯adversaial exampleã‚’paraphraseã ã¨äºˆæ¸¬ã—ã¦ã—ã¾ã£ã¦ã„ã‚‹ã“ã¨ã«ãªã‚‹ã€‚adversarial examplesãŒtrainingãƒ‡ãƒ¼ã‚¿ã§ä¸ãˆã‚‰ã‚ŒãŸå ´åˆã¯ã€supervisedãªãƒ¢ãƒ‡ãƒ«ã‚‚åˆ†é¡ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚ãŒã€QQPã¨æ¯”ã¹ã‚‹ã¨æ€§èƒ½ã¯è½ã¡ã‚‹ã€‚å¤šãã®metricsã§ã¯ã€QQP ã§ã¯ã¾ã¨ã‚‚ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ãŒã€PAWS_QQP ã§ã¯å¤§å¹…ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ä½ä¸‹ã‚’ç¤ºã—ã€ã»ã¼randomã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ãªã‚‹ã€‚ã“ã‚Œã¯ã€ã“ã‚Œã‚‰ã®æŒ‡æ¨™ãŒã‚ˆã‚Šå›°é›£ãªadversarial exampleã‚’åŒºåˆ¥ã§ããªã„ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹ã€‚ä¸€æ–¹ã€BERTSCORE ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ã‚ãšã‹ã«ä½ä¸‹ã™ã‚‹ã ã‘ã§ã‚ã‚Šã€ä»–ã®æŒ‡æ¨™ã‚ˆã‚Šã‚‚ãƒ­ãƒã‚¹ãƒˆæ€§ãŒé«˜ã„ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7a3b3c3b-ff4e-4f65-a6b3-c71b8f100c8a" alt="image" loading="lazy"><br><br><br><br># Discussion<br><br>- BERTScoreã®å˜ä¸€ã®è¨­å®šãŒã€ã»ã‹ã®ã™ã¹ã¦ã®æŒ‡æ¨™ã‚’æ˜ç¢ºã«ä¸Šå›ã‚‹ã¨ã„ã†ã“ã¨ã¯ãªã„<br><br>- ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚„è¨€èªã‚’è€ƒæ…®ã—ã¦ã€æŒ‡æ¨™ã‚„è¨­å®šã‚’é¸æŠã™ã¹ã<br><br>- ä¸€èˆ¬çš„ã«ã€æ©Ÿæ¢°ç¿»è¨³ã®è©•ä¾¡ã«ã¯FBERTã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨<br><br>- è‹±èªã®ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®è©•ä¾¡ã«ã¯ã€24å±¤ã®RoBERTa largeãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã€BERTScoreã‚’è¨ˆç®—ã—ãŸã»ã†ãŒè‰¯ã„<br><br>- éè‹±èªè¨€èªã«ã¤ã„ã¦ã¯ã€å¤šè¨€èªã®BERT_multiãŒè‰¯ã„é¸æŠè‚¢ã ãŒã€ã“ã®ãƒ¢ãƒ‡ãƒ«ã§è¨ˆç®—ã•ã‚ŒãŸBERTScoreã¯ã€low resource languageã«ãŠã„ã¦ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå®‰å®šã—ã¦ã„ã‚‹ã¨ã¯è¨€ãˆãªã„</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Zero/Few/ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/552" target="_blank" rel="noopener noreferrer" class="title-link">Language Models are Few-Shot Learners, Tom B. Brown+, NeurIPS'20</a>
<span class="snippet"><span>GPT Summary</span>- GPT-3ã¯1750å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤è‡ªå·±å›å¸°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆè¨­å®šã«ãŠã„ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã§å¤šãã®NLPã‚¿ã‚¹ã‚¯ã§å¼·åŠ›ãªæ€§èƒ½ã‚’ç¤ºã™ã€‚ç¿»è¨³ã‚„è³ªå•å¿œç­”ãªã©ã§å„ªã‚ŒãŸçµæœã‚’å‡ºã—ã€å³æ™‚æ¨è«–ã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§ã‚‚è‰¯å¥½ãªæ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ä¸€æ–¹ã€ä¾ç„¶ã¨ã—ã¦è‹¦æ‰‹ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„è¨“ç·´ã«é–¢ã™ã‚‹å•é¡Œã‚‚å­˜åœ¨ã™ã‚‹ã€‚ã¾ãŸã€GPT-3ã¯äººé–“ãŒæ›¸ã„ãŸè¨˜äº‹ã¨åŒºåˆ¥ãŒé›£ã—ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã‚’ç”Ÿæˆã§ãã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã€ç¤¾ä¼šçš„å½±éŸ¿ã«ã¤ã„ã¦ã‚‚è­°è«–ã•ã‚Œã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>In-Context Learningã‚’ææ¡ˆã—ãŸè«–æ–‡</p>
<p>è«–æ–‡ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹In-Context Learningã®å®šç¾©ã¯ã€ã—ã£ã‹ã‚ŠæŠ¼ã•ãˆã¦ãŠã„ãŸæ–¹ãŒè‰¯ã„ã€‚<br><br>ä¸‹å›³ã¯meta-learningã®è¦³ç‚¹ã‹ã‚‰è¦‹ãŸã¨ãã®ã€in-contextã®ä½ç½®ä»˜ã‘ã€‚äº‹å‰å­¦ç¿’æ™‚ã«SGDã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’updateã™ã‚‹ã®ã‚’outer loopã¨ã—ã€ãã“ã§åºƒã„ã‚¹ã‚­ãƒ«ã¨ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã®èƒ½åŠ›ã‚’èº«ã«ã¤ã‘ã‚‹ã€‚ä¸€æ–¹ã§ã€in-context learningã¯ã€Inferenceæ™‚ã«äº‹å‰å­¦ç¿’æ™‚ã«å¾—ãŸãã‚Œã‚‰ã®ã‚¹ã‚­ãƒ«ã‚’ç”¨ã„ã¦ã€æ±‚ã‚ã‚‹ã‚¿ã‚¹ã‚¯ã‚’èªè­˜ã€ã‚ã‚‹ã„ã¯é©å¿œã™ã‚‹Inner loopã®ã“ã¨ã‚’æŒ‡ã™ã€‚<br><img src="https://github.com/user-attachments/assets/679129f3-93e3-445f-b9e8-5d909261737b" alt="image" loading="lazy"><br><br>ã“ã®ä¸Šã§ã€è«–æ–‡ä¸­ã§ã¯ In-Context Learningã«ã¤ã„ã¦:<br>&gt; Recent work [RWC+19] attempts to do this via what we call â€œin-context learningâ€, using the text input of a pretrained language model as a form of task specification: the model is conditioned on a natural language instruction and/or a few demonstrations of the task and is then expected to complete further instances of the task simply by predicting what comes next.<br><br>ã¨å®šç¾©ã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2025-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1957" target="_blank" rel="noopener noreferrer" class="title-link">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, Mingxing Tan+, ICML'19</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€ConvNetsã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’æ·±ã•ã€å¹…ã€è§£åƒåº¦ã®ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®ã—ã¦ä½“ç³»çš„ã«ç ”ç©¶ã—ã€æ–°ã—ã„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ‰‹æ³•ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€MobileNetsã‚„ResNetã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¨¼ã—ã€EfficientNetsã¨ã„ã†æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’è¨­è¨ˆã€‚ç‰¹ã«EfficientNet-B7ã¯ã€ImageNetã§84.3%ã®ãƒˆãƒƒãƒ—1ç²¾åº¦ã‚’é”æˆã—ã€å¾“æ¥ã®ConvNetsã‚ˆã‚Šã‚‚å°å‹ã‹ã¤é«˜é€Ÿã§ã‚ã‚‹ã€‚CIFAR-100ã‚„Flowersãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚æœ€å…ˆç«¯ã®ç²¾åº¦ã‚’è¨˜éŒ²ã€‚ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<span class="snippet"><span>Comment</span><p>å…ƒè«–æ–‡ã‚’ãƒ¡ãƒ¢ã£ã¦ãªã‹ã£ãŸã®ã§è¿½åŠ ã€‚<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/346" target="_blank" rel="noopener noreferrer">EfficientNetè§£èª¬, omiita (ã‚ªãƒŸãƒ¼ã‚¿), 2019</a>
<br><br>ã‚‚å‚ç…§ã®ã“ã¨ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<a class="button" href="articles/StudentPerformancePrediction.html" target="_blank" rel="noopener noreferrer">#StudentPerformancePrediction</a>
<a class="button" href="articles/KnowledgeTracing.html" target="_blank" rel="noopener noreferrer">#KnowledgeTracing</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2021-05-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/353" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] EKT: Exercise-aware Knowledge Tracing for Student Performance Prediction, Qi Liu+, IEEE TKDE'19, 2019.06</a>
<span class="snippet"><span>GPT Summary</span>- å­¦ç”Ÿã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬ã®ãŸã‚ã«ã€æ¼”ç¿’è¨˜éŒ²ã¨æ•™ææƒ…å ±ã‚’çµ±åˆã™ã‚‹EERNNãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚åŒæ–¹å‘LSTMã‚’ç”¨ã„ã¦æ¼”ç¿’å†…å®¹ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€ãƒãƒ«ã‚³ãƒ•ç‰¹æ€§ã¨ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’æŒã¤2ã¤ã®å®Ÿè£…ã‚’æä¾›ã€‚ã•ã‚‰ã«ã€çŸ¥è­˜æ¦‚å¿µã‚’è¿½è·¡ã™ã‚‹EKTã«æ‹¡å¼µã—ã€æ¼”ç¿’ãŒçŸ¥è­˜ç¿’å¾—ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’å®šé‡åŒ–ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€äºˆæ¸¬ç²¾åº¦ã¨è§£é‡ˆå¯èƒ½æ€§ã®å‘ä¸ŠãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>DKTç­‰ã®Deepãªãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ã“ã‚Œã¾ã§å•é¡Œãƒ†ã‚­ã‚¹ãƒˆã®æƒ…å ±ç­‰ã¯åˆ©ç”¨ã•ã‚Œã¦ã“ãªã‹ã£ãŸãŒã€learning logã®ã¿ãªã‚‰ãšã€å•é¡Œãƒ†ã‚­ã‚¹ãƒˆã®æƒ…å ±ç­‰ã‚‚KTã™ã‚‹éš›ã«æ´»ç”¨ã—ãŸç ”ç©¶ã€‚<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/354" target="_blank" rel="noopener noreferrer">[Paper Note] Exercise-Enhanced Sequential Modeling for Student Performance Prediction, Hu+, AAAI'18</a>
  ã‚’ã‚ˆã‚Šæ´—ç·´ã•ã›journalåŒ–ã•ã›ãŸã‚‚ã®ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/354" target="_blank" rel="noopener noreferrer">[Paper Note] Exercise-Enhanced Sequential Modeling for Student Performance Prediction, Hu+, AAAI'18</a>
  ã§ã¯KTã¨ã„ã†ã‚ˆã‚Šã€å•é¡Œã®æ­£èª¤ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¨ãªã£ã¦ãŠã‚Šã€å€‹ã€…ã®conceptã«å¯¾ã™ã‚‹proficiencyã‚’æ¨å®šã™ã‚‹ã¨ã„ã†KTã®è€ƒãˆæ–¹ã¯ã‚ã¾ã‚Šå°å…¥ã•ã‚Œã¦ã„ãªã‹ã£ãŸã€‚<br><br>EKTã®æ–¹ã§ã¯ã€å€‹ã€…ã®knowledge componentã®proficiency scoreã‚’ç®—å‡ºã™ã‚‹æ–¹æ³•ã‚‚ææ¡ˆã•ã‚Œã¦ã„ã‚‹ã€‚</p>
<p>ãƒ¢ãƒ‡ãƒ«è‡ªä½“ã¯ã€åŸºæœ¬çš„ã«ã¯attention-basedãªRNNãƒ¢ãƒ‡ãƒ«ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/119990204-05d1c300-c003-11eb-817f-2d23708cd7e5.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/119990252-12eeb200-c003-11eb-9edd-d1cd7dba713f.png" alt="image" loading="lazy"><br><br></p>
<p>Exercise Embeddingã¯Bidireictional-RNNã‚’åˆ©ç”¨ã—ã¦ã€å•é¡Œæ–‡ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦æ±‚ã‚ã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/120432013-42f7d580-c3b4-11eb-9fd4-17e81a5bfb70.png" alt="image" loading="lazy"><br><br></p>
<p>EKTã«ã‚ˆã‚‹mastery levelã‚’å¯è¦–åŒ–ã—ãŸã‚‚ã®ã€‚T=0ã¨T=30ã§ã¯å„conceptã«å¯¾ã™ã‚‹mastery levelãŒå¤§ããç•°ãªã£ã¦ã„ã‚‹ã€‚åŸºæœ¬çš„ã«ã€ãŸãã•ã‚“æ­£è§£ã—ãŸconceptã¯mastery levelãŒå‘ä¸Šã—ã€ä¸æ­£è§£ã—ã¾ãã£ãŸconceptã¯ã©ã‚“ã©ã‚“mastery levelãŒshrinkã—ã¦ã„ãã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120432208-8c482500-c3b4-11eb-8486-6ddbab8f7249.png" alt="image" loading="lazy"><br><br></p>
<p>äºˆæ¸¬æ€§èƒ½ã€‚å•é¡Œã®Contentã‚’è€ƒæ…®ã™ã‚‹ã“ã¨ã§ã€æ­£èª¤äºˆæ¸¬ã®AUCã¯åœ§å€’çš„ã«é«˜ããªã‚‹ã€‚DKTã‚ˆã‚Šã‚‚10ãƒã‚¤ãƒ³ãƒˆç¨‹åº¦EKTAã®æ–¹ãŒAUCãŒé«˜ã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/120433254-f7462b80-c3b5-11eb-802f-88ee102633e6.png" alt="image" loading="lazy"><br><br><br><br>å„ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´ã‚„ã€knowledge tracingãŒè¡Œãˆã‚‹ã‹å¦ã‹ã€ã¨ã„ã£ãŸæ€§è³ªã‚’æ•´ç†ã—ãŸè¡¨ã€‚ã‚ã‹ã‚Šã‚„ã™ã„ã€‚ã—ã‹ã—DKTã®knowledge tracking?ãŒÃ—ã«ãªã£ã¦ã„ã‚‹ã®ã¯èª¤ã‚Šã§ã¯ï¼Ÿ<br><br><img src="https://user-images.githubusercontent.com/12249301/120433307-075e0b00-c3b6-11eb-8af3-432ca9d41d51.png" alt="image" loading="lazy"><br><br></p>
<p>å„knowledge conceptã®æ™‚åˆ»tã«ãŠã‘ã‚‹mastery levelã®æ±‚ã‚æ–¹ã€‚<br><br><br><br>EKTã§ã¯ã€ç”Ÿå¾’ã®å„knowledge conceptã®çŠ¶æ…‹ã‚’ä¿æŒã—ãŸè¡Œåˆ—H_t^iï¼ˆ0 &lt;= i &lt;= # of conceptsï¼‰ã‚’ä¿æŒã—ã¦ã„ã‚‹ã€‚correctness probabilityã‚’æœ€çµ‚çš„ã«æ±‚ã‚ã‚‹éš›ã«ã¯ã€H_t^iã®å„knowledge conceptã«å¯¾ã™ã‚‹é‡ã¿Î²_iã§é‡ã¿ã¥ã‘ãŸä¸Šã§summationã‚’ã¨ã‚Šã€å„çŸ¥è­˜ã®çŠ¶æ…‹ã‚’çµ±åˆã—ãŸãƒ™ã‚¯ãƒˆãƒ«sã‚’ä½œæˆã—ã€sã¨exercise embedding xã‚’concatã—ãŸä¸Šã§ã‚¹ã‚³ã‚¢ã‚’äºˆæ¸¬ã™ã‚‹ã€‚<br><br><br><br>ã“ã®ã‚¹ã‚³ã‚¢ã®äºˆæ¸¬éƒ¨åˆ†ã‚’å¤‰æ›´ã—ã€Î²_iã‚’mastery levelã‚’æ¸¬å®šã—ãŸã„conceptã®one-hot encodingã«ç½®ãæ›ãˆã€ã•ã‚‰ã«exercise embeddingã‚’maskã—ãŸãƒ™ã‚¯ãƒˆãƒ«=masked exercise embedding = zero vectorã‚’concatã—ãŸä¸Šã§ã€ã‚¹ã‚³ã‚¢ã‚’äºˆæ¸¬ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/120436895-78072680-c3ba-11eb-8694-ff0926f639b7.png" alt="image" loading="lazy"><br><br><br><br>ã“ã†ã™ã‚‹ã“ã¨ã§ã€exerciseã®å½±éŸ¿ã‚’é™¤ãã€ã‹ã¤one-hot encodingã§æŒ‡å®šã—ãŸknowledgeã®masteryã®ã¿ãŒè€ƒæ…®ã•ã‚ŒãŸã‚¹ã‚³ã‚¢ã‚’æŠ½å‡ºã§ãã‚‹ãŸã‚ã€ãã®ã‚¹ã‚³ã‚¢ã‚’mastery levelã¨ã™ã‚‹ã€‚</p>
<p>å˜ã«Student Performance Predictionã—ã¦çµ‚ã‚ã‚Šï¼ã£ã¦ã‚“ã˜ã‚ƒãªãã€knowledge tracingçš„ãªå´é¢ã‚’ãã¡ã‚“ã¨è€ƒæ…®ã—ã¦ã„ã‚‹ç‚¹ã§ã€ã“ã®ç ”ç©¶ã‚ã£ã¡ã‚ƒå¥½ãã€‚</p>
<p>ã‚¹ã‚­ãƒ«ã‚¿ã‚°ã”ã¨ã«LSTMã®hidden_stateã‚’ä¿æŒã—ãªã„ã¨ã„ã‘ãªã„ã®ã§ã€ãƒ¡ãƒ¢ãƒªã®æ¶ˆè²»é‡ãŒãˆãã„ã“ã¨ã«ãªã‚Šãã†ã€‚å°è¦æ¨¡ãªã‚¹ã‚­ãƒ«ã‚¿ã‚°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã˜ã‚ƒãªã„ã¨å‹•ã‹ãªã„ã®ã§ã¯ï¼Ÿ<br><br>å®Ÿéš›ã€å®Ÿé¨“ã§ã¯37ç¨®é¡ã®ã‚¹ã‚­ãƒ«ã‚¿ã‚°ãŒå­˜åœ¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã—ã‹æ‰±ã£ã¦ã„ãªã„ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<a class="button" href="articles/Reproducibility.html" target="_blank" rel="noopener noreferrer">#Reproducibility</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3368" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Reinforcement Learning that Matters, Peter Henderson+, AAAI'18, 2017.09</a>
<span class="snippet"><span>GPT Summary</span>- æ·±å±¤å¼·åŒ–å­¦ç¿’ï¼ˆRLï¼‰ã®é€²å±•ã‚’æŒç¶šã•ã›ã‚‹ãŸã‚ã«ã¯ã€æ—¢å­˜ç ”ç©¶ã®å†ç¾æ€§ã¨æ–°æ‰‹æ³•ã®æ”¹å–„ã‚’æ­£ç¢ºã«è©•ä¾¡ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ã€‚ã—ã‹ã—ã€éæ±ºå®šæ€§ã‚„æ‰‹æ³•ã®ã°ã‚‰ã¤ãã«ã‚ˆã‚Šã€çµæœã®è§£é‡ˆãŒé›£ã—ããªã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€å†ç¾æ€§ã‚„å®Ÿé¨“å ±å‘Šã®èª²é¡Œã‚’èª¿æŸ»ã—ã€ä¸€èˆ¬çš„ãªãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®æ¯”è¼ƒã«ãŠã‘ã‚‹æŒ‡æ¨™ã®ã°ã‚‰ã¤ãã‚’ç¤ºã™ã€‚ã•ã‚‰ã«ã€æ·±å±¤RLã®çµæœã‚’å†ç¾å¯èƒ½ã«ã™ã‚‹ãŸã‚ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’ææ¡ˆã—ã€ç„¡é§„ãªåŠªåŠ›ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹ã“ã¨ã§åˆ†é‡ã®é€²å±•ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>æ—¥æœ¬èªè§£èª¬: 


<a href="https://www.slideshare.net/slideshow/dldeep-reinforcement-learning-that-matters-83905622/83905622" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/slideshow/dldeep-reinforcement-learning-that-matters-83905622/83905622</a>


</p>
<p>å†ç¾æ€§ã¨ã„ã†è¦³ç‚¹ã¨ã¯å°‘ã—ç•°ãªã‚‹ã®ã‹ã‚‚ã—ã‚Œãªã„ãŒã€æœ€è¿‘ã®RLã«ã‚ˆã‚‹post-trainingã«ã¤ã„ã¦ã¯ã€ä»¥ä¸‹ã®ç ”ç©¶ã§Scaling LawsãŒå°å…¥ã•ã‚Œã¦ã„ã‚‹ã€‚<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3282" target="_blank" rel="noopener noreferrer">[Paper Note] The Art of Scaling Reinforcement Learning Compute for LLMs, Devvrit Khatri+, arXiv'25, 2025.10</a>
<br><br>ãŒã€çµå±€ç¾åœ¨ã‚‚å¤šãã®RLæ‰‹æ³•ãŒæ—¥å¤œå‡ºã¦ãã¦ãŠã‚Šã€å†ç¾æ€§ã«é–¢ã—ã¦ã¯åŒã˜ã‚ˆã†ãªçŠ¶æ³ã«é™¥ã£ã¦ã„ãã†ã§ã‚ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/SequentialRecommendation.html" target="_blank" rel="noopener noreferrer">#SequentialRecommendation</a>
<a class="button" href="articles/ICDM.html" target="_blank" rel="noopener noreferrer">#ICDM</a>
<span class="issue_date">Issue Date: 2025-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2137" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Self-Attentive Sequential Recommendation, Wang-Cheng Kang+, ICDM'18</a>
<span class="snippet"><span>GPT Summary</span>- è‡ªå·±æ³¨æ„ã«åŸºã¥ãé€æ¬¡ãƒ¢ãƒ‡ãƒ«ï¼ˆSASRecï¼‰ã‚’ææ¡ˆã—ã€ãƒãƒ«ã‚³ãƒ•é€£é–ã¨å†å¸°å‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®åˆ©ç‚¹ã‚’çµ±åˆã€‚SASRecã¯ã€å°‘æ•°ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰æ¬¡ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’äºˆæ¸¬ã—ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ãŠã‚ˆã³å¯†ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®åŠ¹ç‡æ€§ã¨æ³¨æ„é‡ã¿ã®è¦–è¦šåŒ–ã«ã‚ˆã‚Šã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å¯†åº¦ã«å¿œã˜ãŸé©å¿œçš„ãªå‡¦ç†ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/General.html" target="_blank" rel="noopener noreferrer">#General</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/68" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] StarSpace: Embed All The Things, Wu+, AAAI'18</a>
<span class="snippet"><span>Comment</span><p>åˆ†é¡ã‚„ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ãªã©ã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã§æ±ç”¨çš„ã«ä½¿ç”¨ã§ãã‚‹Embeddingã®å­¦ç¿’æ‰‹æ³•ã‚’ææ¡ˆã€‚<br><br><br><br>Embeddingã‚’å­¦ç¿’ã™ã‚‹å¯¾è±¡ã‚’Entityã¨å‘¼ã³ã€Entityã¯bag-of-featureã§è¨˜è¿°ã•ã‚Œã‚‹ã€‚<br><br>Entityã¯bag-of-featureã§è¨˜è¿°ã§ãã‚Œã°ãªã‚“ã§ã‚‚ã‚ˆãã€<br><br>ã“ã‚Œã«ã‚ˆã‚Šãƒ¢ãƒ‡ãƒ«ã®æ±ç”¨æ€§ãŒå¢—ã—ã€ç•°ãªã‚‹ç¨®é¡ã®Entityã§ã‚‚åŒã˜ç©ºé–“ä¸Šã§EmbeddingãŒå­¦ç¿’ã•ã‚Œã‚‹ã€‚<br><br><br><br>å­¦ç¿’æ–¹æ³•ã¯éå¸¸ã«ã‚·ãƒ³ãƒ—ãƒ«ã§ã€EntityåŒå£«ã®ãƒšã‚¢ã‚’ã¨ã£ãŸã¨ãã«ã€relevantãªpairã§ã‚ã‚Œã°é¡ä¼¼åº¦ãŒé«˜ãã€<br><br>irelevantãªãƒšã‚¢ã§ã‚ã‚Œã°é¡ä¼¼åº¦ãŒä½ããªã‚‹ã‚ˆã†ã«Embeddingã‚’å­¦ç¿’ã™ã‚‹ã ã‘ã€‚<br><br>ãŸã¨ãˆã°ã€Entityã®ãƒšã‚¢ã¨ã—ã¦ã€documentã‚’bag-of-words, bag-of-ngrams, labelã‚’single wordã§è¨˜è¿°ã—ãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡ã€<br><br>ã‚ã‚‹ã„ã¯ã€user_idã¨ãƒ¦ãƒ¼ã‚¶ãŒéå»ã«å¥½ã‚“ã ã‚¢ã‚¤ãƒ†ãƒ ã‚’bag-of-wordsã§è¨˜è¿°ã—content-based recommendationã‚’è¡Œã†ãªã©ã€ å¿œç”¨ç¯„å›²ã¯å¹…åºƒã„ã€‚<br><br><br><br>5ç¨®é¡ã®ã‚¿ã‚¹ã‚¯ã§ææ¡ˆæ‰‹æ³•ã‚’è©•ä¾¡ã—ã€æ—¢å­˜æ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦ã€åŒç­‰ã‹ãã‚Œä»¥ä¸Šã®æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚<br><br><br><br>æ‰‹æ³•ã®æ±ç”¨æ€§ãŒé«˜ãå­¦ç¿’ã‚‚é«˜é€Ÿãªã®ã§ã€è‰²ã€…ãªå ´é¢ã§å½¹ã«ç«‹ã¡ãã†ã€‚<br><br>ã¾ãŸã€ç•°ãªã‚‹ç¨®é¡ã®Entityã§ã‚ã£ã¦ã‚‚åŒã˜ç©ºé–“ä¸Šã§EmbeddingãŒå­¦ç¿’ã•ã‚Œã‚‹ã®ã§ã€å­¦ç¿’ã•ã‚ŒãŸEmbeddingã®å¿œç”¨å…ˆãŒåºƒãæœ‰ç”¨ã€‚</p>
<p>å®Ÿéš›ã«SentimentAnalysisã§ä½¿ã£ã¦ã¿ãŸãŒï¼ˆãƒã‚¸ãƒã‚¬äºŒå€¤åˆ†é¡ï¼‰ã€å°‘ãªãã¨ã‚‚BoWã®SVMã‚ˆã‚Šã¯å…¨ç„¶æ€§èƒ½è‰¯ã‹ã£ãŸã—ã€å­¦ç¿’ã‚‚æ—©ã„ã—ã€æ¬¡å…ƒæ•°ã‚ã¡ã‚ƒã‚ã¡ã‚ƒå°‘ãªãã¦è‰¯ã‹ã£ãŸã€‚<br><br>StarSpaceã§å­¦ç¿’ã—ãŸembeddingã‚’BoWãªSVMã«å…¥ã‚Œã‚‹ã¨æ€§èƒ½ãŒåŠ‡çš„ã«æ”¹å–„ã—ãŸã€‚</p>
<p>è§£èª¬ï¼š<br><br>


<a href="https://www.slideshare.net/akihikowatanabe3110/starspace-embed-all-the-things" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/starspace-embed-all-the-things</a>


</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MatrixFactorization.html" target="_blank" rel="noopener noreferrer">#MatrixFactorization</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2018-02-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/260" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Neural Collaborative Filtering, Xiangnan He+, arXiv'17</a>
<span class="snippet"><span>GPT Summary</span>- æ·±å±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”¨ã„ãŸãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®ç ”ç©¶ãŒå°‘ãªã„ä¸­ã€æœ¬ç ”ç©¶ã§ã¯å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®å•é¡Œã«å–ã‚Šçµ„ã‚€ãŸã‚ã€NCFï¼ˆNeural network-based Collaborative Filteringï¼‰ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚å†…ç©ã‚’ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ç½®ãæ›ãˆã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚¤ãƒ†ãƒ ã®ç›¸äº’ä½œç”¨ã‚’å¤šå±¤ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³ã§ãƒ¢ãƒ‡ãƒ«åŒ–ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€ææ¡ˆæ‰‹æ³•ãŒæœ€å…ˆç«¯æŠ€è¡“ã«å¯¾ã—ã¦é¡•è‘—ãªæ”¹å–„ã‚’ç¤ºã—ã€æ·±å±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å±¤ã‚’æ·±ãã™ã‚‹ã“ã¨ã§ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Collaborative Filteringã‚’MLPã§ä¸€èˆ¬åŒ–ã—ãŸNeural Collaborative Filteringã€ãŠã‚ˆã³Matrix Factorizationã¯user, item-embeddingã®element-wise product + linear transofmration + activation ã§ä¸€èˆ¬åŒ–ã§ãã‚‹ã“ã¨ï¼ˆGMF; Generalized Matrix Factorizationï¼‰ã‚’ç¤ºã—ã€ä¸¡è€…ã‚’çµ„ã¿åˆã‚ã›ãŸNeural Matrix Factorizationã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/121464723-5c6dd280-c9ef-11eb-9c56-7382f2403dc1.png" alt="image" loading="lazy"><br><br><br><br>å­¦ç¿’ã™ã‚‹éš›ã¯ã€Implicit Dataã®å ´åˆã¯è² ä¾‹ã‚’Negative Samplingã—ã€LogLossï¼ˆBinary Cross-Entropy Lossï¼‰ã§å­¦ç¿’ã™ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/121464911-bb334c00-c9ef-11eb-88a6-697fab50e60d.png" alt="image" loading="lazy"><br><br>Neural Matrix FactorizationãŒã€ItemKNNã‚„BPRã¨ã„ã£ãŸãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’outperform<br><br><br><br>Negative Samplingã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹è² ä¾‹ã®æ•°ã¯ã€3~4ç¨‹åº¦ã§è‰¯ã•ãã†<br><br><img src="https://user-images.githubusercontent.com/12249301/121464991-e9189080-c9ef-11eb-96ce-4e743f84a183.png" alt="image" loading="lazy"><br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2018-01-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/245" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Attention Is All You Need, Ashish Vaswani+, arXiv'17</a>
<span class="snippet"><span>GPT Summary</span>- Transformerã¯ã€å†å¸°ã‚„ç•³ã¿è¾¼ã¿ã‚’æ’é™¤ã—ã€æ³¨æ„æ©Ÿæ§‹ã®ã¿ã«åŸºã¥ã„ãŸæ–°ã—ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚‹ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€æ©Ÿæ¢°ç¿»è¨³ã‚¿ã‚¹ã‚¯ã§å„ªã‚ŒãŸå“è³ªã‚’ç¤ºã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“ã‚’å¤§å¹…ã«çŸ­ç¸®ã€‚WMT 2014ã®è‹±ç‹¬ç¿»è¨³ã§28.4 BLEUã€è‹±ä»ç¿»è¨³ã§41.8 BLEUã‚’é”æˆã—ã€æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ã¾ãŸã€è‹±èªã®æ§‹æ–‡è§£æã«ã‚‚æˆåŠŸè£ã«é©ç”¨å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Transformer (self-attentionã‚’åˆ©ç”¨) è«–æ–‡<br><br>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š


<a href="https://www.slideshare.net/DeepLearningJP2016/dlattention-is-all-you-need" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/DeepLearningJP2016/dlattention-is-all-you-need</a>


<br><br>è§£èª¬è¨˜äº‹ï¼š


<a href="https://qiita.com/nishiba/items/1c99bc7ddcb2d62667c6" target="_blank" rel="noopener noreferrer">https://qiita.com/nishiba/items/1c99bc7ddcb2d62667c6</a>


<br><br><br><br>* æ–°ã—ã„ç¿»è¨³ãƒ¢ãƒ‡ãƒ«(Transformer)ã‚’ææ¡ˆã€‚æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ä¸¦åˆ—åŒ–ã«å¯¾å¿œã—ã¦ãŠã‚Šã€çŸ­æ™‚é–“ã®è¨“ç·´ã§ï¼ˆæ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã®1/4ä»¥ä¸‹ã®ã‚³ã‚¹ãƒˆï¼‰é«˜ã„BLEUã‚¹ã‚³ã‚¢ã‚’é”æˆã—ãŸã€‚<br><br>* Transformerã¯RNNã‚„CNNã‚’ä½¿ã‚ãšã€attentionãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«åŸºã¥ã„ã¦ã„ã‚‹ã€‚<br><br><br><br>ï¼ˆè§£èª¬ã‚ˆã‚Šï¼‰</p>
<p>åˆ†ã‹ã‚Šã‚„ã™ã„:<br>


<a href="https://qiita.com/halhorn/items/c91497522be27bde17ce" target="_blank" rel="noopener noreferrer">https://qiita.com/halhorn/items/c91497522be27bde17ce</a>


</p>
<p>Transformerã®å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ã®outputã®shapeã‚„ã€attention_maskã®å½¢çŠ¶ã€å®Ÿè£…ã«ã¤ã„ã¦è¨˜è¿°ã•ã‚Œã¦ãŠã‚Šæœ‰ç”¨:<br>


<a href="https://qiita.com/FuwaraMiyasaki/items/239f3528053889847825" target="_blank" rel="noopener noreferrer">https://qiita.com/FuwaraMiyasaki/items/239f3528053889847825</a>


</p>
<p>é›†åˆçŸ¥</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/207" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Challenges in Data-to-Document Generation, Wiseman+ ï¼ˆwith Rushï¼‰, EMNLP'17</a>
&lt;span class=\"snippet\"&gt;<span>Comment</span><p>ãƒ»RotoWireï¼ˆNBAã®ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ + ã‚µãƒãƒªï¼‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—å…¬é–‹<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/119625430-23f1c480-be45-11eb-8ff8-5e9223d41481.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br><br><br>ãƒ»Rotowireãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆé‡<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/119625488-323fe080-be45-11eb-952e-d2d21d6e5847.png\" alt=\"image\" loading=\"lazy\" /&gt;</p>
<p>ã€ãƒ¢ãƒ‡ãƒ«ã®æ¦‚è¦ã€‘<br><br>ãƒ»attention-based encoder-decoder model<br><br><br><br>ãƒ»BaseModel<br><br>ã€€- ãƒ¬ã‚³ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ r ã®å„è¦ç´ ï¼ˆr.e: ãƒãƒ¼ãƒ åç­‰ã®ENTITY r.t: POINTSç­‰ã®ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—, r.m: ãƒ‡ãƒ¼ã‚¿ã®valueï¼‰ã‹ã‚‰embeddingã‚’lookupã—ã€1-layer MLPã‚’é©ç”¨ã—ã€ãƒ¬ã‚³ãƒ¼ãƒ‰ã®å„è¦ç´ ã®representationï¼ˆsource data recordsï¼‰ã‚’å–å¾—<br><br>ã€€- Luongã‚‰ã®attentionã‚’åˆ©ç”¨ã—ãŸLSTM Decoderã‚’ç”¨æ„ã—ã€source data recordsã¨t-1ã‚¹ãƒ†ãƒƒãƒ—ç›®ã§ã®å‡ºåŠ›ã«ã‚ˆã£ã¦æ¡ä»¶ä»˜ã‘ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¦ã„ã<br><br>ã€€- negative log likelihoodãŒminimizeã•ã‚Œã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹<br><br><br><br>ãƒ»Copying<br><br>ã€€- ã‚³ãƒ”ãƒ¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å°å…¥ã—ã€ç”Ÿæˆæ™‚ã®ç¢ºç‡åˆ†å¸ƒã«ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã‹ã‚‰ã‚³ãƒ”ãƒ¼ã•ã‚Œã‚‹ã‹å¦ã‹ã‚’å«ã‚ãŸåˆ†å¸ƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã€‚ã‚³ãƒ”ãƒ¼ã®å¯¾è±¡ã¯ã€å…¥åŠ›ãƒ¬ã‚³ãƒ¼ãƒ‰ã®valueãŒã‚³ãƒ”ãƒ¼ã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚<br><br>ã€€- ã‚³ãƒ”ãƒ¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ã¯ä¸‹è¨˜å¼ã§è¡¨ç¾ã•ã‚Œã‚‹ Conditional Copy Modelã‚’åˆ©ç”¨ã—ã€p\(zt|y1:t-1, s)ã¯MLPã§è¡¨ç¾ã™ã‚‹ã€‚<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/119628147-cc088d00-be47-11eb-84de-6a1d158d78e5.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br>ã€€- ã¾ãŸpcopyã¯ã€ç”Ÿæˆã—ã¦ã„ã‚‹æ–‡ä¸­ã«ã‚ã‚‹ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨ã‚¿ã‚¤ãƒ—ãŒå‡ºç¾ã™ã‚‹å ´åˆã«ã€å¯¾å¿œã™ã‚‹valueã‚’ã‚³ãƒ”ãƒ¼ã—ç”Ÿæˆã•ã‚Œã‚‹ã‚ˆã†ã«ã€ä¸‹è¨˜å¼ã§è¡¨ç¾ã™ã‚‹<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/119628389-07a35700-be48-11eb-9c69-27b70fcbcdef.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br>ã€€- ã“ã“ã§ r\(yt) =<br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/119628615-39b4b900-be48-11eb-9305-509a6eed8182.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br></p>&lt;/span&gt;<br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/135" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Get To The Point: Summarization with Pointer-Generator Networks, See+, ACL'17</a>
<span class="snippet"><span>Comment</span><p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š


<a href="https://www.slideshare.net/akihikowatanabe3110/get-to-the-point-summarization-with-pointergenerator-networks/1" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/get-to-the-point-summarization-with-pointergenerator-networks/1</a>


</p>
<p>å˜èªã®ç”Ÿæˆã¨å˜èªã®ã‚³ãƒ”ãƒ¼ã®ä¸¡æ–¹ã‚’è¡Œãˆã‚‹ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æ–‡æ›¸è¦ç´„ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã€‚<br><br>åŒã˜å˜èªã®ç¹°ã‚Šè¿”ã—ç¾è±¡(repetition)ã‚’ãªãã™ãŸã‚ã«ã€Coverage Mechanismã‚‚å°å…¥ã—ãŸã€‚<br><br><br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/136" target="_blank" rel="noopener noreferrer">[Paper Note] Incorporating Copying Mechanism in Sequence-to-Sequence Learning, Gu+, ACL'16</a>
 ãªã©ã¨æ¯”è¼ƒã™ã‚‹ã¨ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«ã€‚</p>
<p>ä¸€èˆ¬çš„ã«ã€PointerGeneratorã¨å‘¼ã°ã‚Œã‚‹ã€‚<br><br>OpenNMTãªã©ã«ã‚‚å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹: 


<a href="https://opennmt.net/OpenNMT-py/_modules/onmt/modules/copy_generator.html" target="_blank" rel="noopener noreferrer">https://opennmt.net/OpenNMT-py/_modules/onmt/modules/copy_generator.html</a>


</p>
<p>ï¼ˆå‚è€ƒï¼‰Pointer Generator Networksã§è¦ç´„ã—ã¦ã¿ã‚‹ï¼š<br><br>


<a href="https://qiita.com/knok/items/9a74430b279e522d5b93" target="_blank" rel="noopener noreferrer">https://qiita.com/knok/items/9a74430b279e522d5b93</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/69" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A structured self-attentive sentence embedding, Li+ ï¼ˆBengio groupï¼‰, ICLR'17</a>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=BJC_jUqxe" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=BJC_jUqxe</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<span class="issue_date">Issue Date: 2025-06-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2038" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] WaveNet: A Generative Model for Raw Audio, Aaron van den Oord+, arXiv'16</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€éŸ³å£°æ³¢å½¢ã‚’ç”Ÿæˆã™ã‚‹æ·±å±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯WaveNetã‚’ææ¡ˆã€‚è‡ªå·±å›å¸°çš„ãªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚ŠãªãŒã‚‰ã€åŠ¹ç‡çš„ã«éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¨“ç·´å¯èƒ½ã€‚ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã¸ã®å¤‰æ›ã§æœ€å…ˆç«¯ã®æ€§èƒ½ã‚’ç¤ºã—ã€äººé–“ã®ãƒªã‚¹ãƒŠãƒ¼ã«è‡ªç„¶ãªéŸ³ã¨è©•ä¾¡ã•ã‚Œã‚‹ã€‚è©±è€…ã®ç‰¹æ€§ã‚’å¿ å®Ÿã«æ‰ãˆã€ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã«åŸºã¥ãåˆ‡ã‚Šæ›¿ãˆãŒå¯èƒ½ã€‚éŸ³æ¥½ç”Ÿæˆã«ã‚‚å¿œç”¨ã§ãã€ãƒªã‚¢ãƒ«ãªéŸ³æ¥½ã®æ–­ç‰‡ã‚’ç”Ÿæˆã€‚ã¾ãŸã€éŸ³ç´ èªè­˜ã®ãŸã‚ã®æœ‰æœ›ãªè­˜åˆ¥ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã®åˆ©ç”¨ã‚‚ç¤ºå”†ã€‚</span>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/RecSys.html" target="_blank" rel="noopener noreferrer">#RecSys</a>
<span class="issue_date">Issue Date: 2018-12-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/298" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Neural Networks for YouTube Recommendations, Covington+, RecSys'16</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/GraphConvolutionalNetwork.html" target="_blank" rel="noopener noreferrer">#GraphConvolutionalNetwork</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2018-03-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/265" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Convolutional Neural Networks on Graphs with Fast Localized Spectral  Filtering, MichaÃ«l Defferrard+, NIPS'16</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬ç ”ç©¶ã§ã¯ã€CNNã‚’ç”¨ã„ã¦ä½æ¬¡å…ƒã®ã‚°ãƒªãƒƒãƒ‰ã‹ã‚‰é«˜æ¬¡å…ƒã®ã‚°ãƒ©ãƒ•ãƒ‰ãƒ¡ã‚¤ãƒ³ã¸ã®ä¸€èˆ¬åŒ–ã‚’æ¢æ±‚ã€‚ã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚°ãƒ©ãƒ•ç†è«–ã«åŸºã¥ãCNNã®å®šå¼åŒ–ã‚’ææ¡ˆã—ã€å¤å…¸çš„CNNã¨åŒç­‰ã®è¨ˆç®—è¤‡é›‘æ€§ã‚’ç¶­æŒã—ã¤ã¤ã€ä»»æ„ã®ã‚°ãƒ©ãƒ•æ§‹é€ ã«å¯¾å¿œå¯èƒ½ã€‚MNISTãŠã‚ˆã³20NEWSã®å®Ÿé¨“ã«ã‚ˆã‚Šã€ã‚°ãƒ©ãƒ•ä¸Šã§ã®å±€æ‰€çš„ç‰¹å¾´å­¦ç¿’ã®èƒ½åŠ›ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>GCNã‚’å‹‰å¼·ã™ã‚‹éš›ã¯èª­ã‚€ã¨è‰¯ã„ã‚‰ã—ã„ã€‚<br><br>ã‚ã‚ã›ã¦ã“ã®ã¸ã‚“ã‚‚ï¼š<br><br>Semi-Supervised Classification with Graph Convolutional Networks, Kipf+, ICLR'17<br><br>


<a href="https://github.com/tkipf/gcn" target="_blank" rel="noopener noreferrer">https://github.com/tkipf/gcn</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<span class="issue_date">Issue Date: 2018-02-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/261" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Layer Normalization, Ba+, arXiv'16</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒƒãƒæ­£è¦åŒ–ã®ä»£ã‚ã‚Šã«ãƒ¬ã‚¤ãƒ¤ãƒ¼æ­£è¦åŒ–ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€ãƒªã‚«ãƒ¬ãƒ³ãƒˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“ã‚’çŸ­ç¸®ã€‚ãƒ¬ã‚¤ãƒ¤ãƒ¼å†…ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®åˆè¨ˆå…¥åŠ›ã‚’æ­£è¦åŒ–ã—ã€å„ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã«ç‹¬è‡ªã®é©å¿œãƒã‚¤ã‚¢ã‚¹ã¨ã‚²ã‚¤ãƒ³ã‚’é©ç”¨ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚ã¨ãƒ†ã‚¹ãƒˆæ™‚ã§åŒã˜è¨ˆç®—ã‚’è¡Œã„ã€éš ã‚ŒçŠ¶æ…‹ã®ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã‚’å®‰å®šã•ã›ã‚‹ã€‚å®Ÿè¨¼çš„ã«ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“ã®å¤§å¹…ãªçŸ­ç¸®ã‚’ç¢ºèªã€‚</span>
<span class="snippet"><span>Comment</span><p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š<br><br>


<a href="https://www.slideshare.net/KeigoNishida/layer-normalizationnips" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/KeigoNishida/layer-normalizationnips</a>


<br><br></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/CoNLL.html" target="_blank" rel="noopener noreferrer">#CoNLL</a>
<span class="issue_date">Issue Date: 2018-02-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/258" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Generating Sentences from a Continuous Space, Samuel R. Bowman+, CoNLL'16</a>
<span class="snippet"><span>GPT Summary</span>- RNNãƒ™ãƒ¼ã‚¹ã®å¤‰åˆ†ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’å°å…¥ã—ã€æ–‡å…¨ä½“ã®åˆ†æ•£æ½œåœ¨è¡¨ç¾ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã§ã€æ–‡ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚„ãƒˆãƒ”ãƒƒã‚¯ãªã©ã®ç‰¹æ€§ã‚’æ˜ç¤ºçš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–ã€‚æ½œåœ¨ç©ºé–“ã‚’é€šã˜ã¦æ–°ã—ã„æ–‡ã‚’ç”Ÿæˆã—ã€æ¬ æå˜èªã®è£œå®ŒåŠ¹æœã‚’å®Ÿè¨¼ã€‚ãƒ¢ãƒ‡ãƒ«ã®ç‰¹æ€§ã¨ä½¿ç”¨ã«é–¢ã™ã‚‹å¦å®šçš„ãªçµæœã‚‚ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>VAEã‚’åˆ©ç”¨ã—ã¦æ–‡ç”Ÿæˆ</p>
<p>ã€Variational Autoencoderå¾¹åº•è§£èª¬ã€‘<br><br>


<a href="https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24" target="_blank" rel="noopener noreferrer">https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24</a>


</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/WSDM.html" target="_blank" rel="noopener noreferrer">#WSDM</a>
<span class="issue_date">Issue Date: 2018-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/216" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Collaborative Denoising Auto-Encoders for Top-N Recommender Systems, Wu+, WSDM'16</a>
<span class="snippet"><span>Comment</span><p>Denoising Auto-Encoders ã‚’ç”¨ã„ãŸtop-Næ¨è–¦æ‰‹æ³•ã€Collaborative Denoising Auto-Encoder (CDAE)ã‚’ææ¡ˆã€‚<br><br>ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ãªCollaborative Filteringæ‰‹æ³•ã«ç›¸å½“ã™ã‚‹ã€‚corruptedãªinputã‚’å¾©å…ƒã™ã‚‹ã‚ˆã†ãªDenoising Auto Encoderã®ã¿ã§æ¨è–¦ã‚’è¡Œã†ã‚ˆã†ãªæ‰‹æ³•ã¯ã€ã“ã®ç ”ç©¶ãŒåˆã‚ã¦ã ã¨ä¸»å¼µã€‚<br><br><br><br>å­¦ç¿’ã™ã‚‹éš›ã¯ã€userã®itemsetã®subsetã‚’ãƒ¢ãƒ‡ãƒ«ã«ä¸ãˆï¼ˆnoiseãŒã‚ã‚‹ã“ã¨ã«ç›¸å½“ï¼‰ã€å…¨ä½“ã®item setã‚’å¾©å…ƒã§ãã‚‹ã‚ˆã†ã«ã€å­¦ç¿’ã™ã‚‹ï¼ˆã™ãªã‚ã¡Denoising Auto-Encoderï¼‰ã€‚<br><br>æ¨è–¦ã™ã‚‹éš›ã¯ã€ãƒ¦ãƒ¼ã‚¶ã®ãã®æ™‚ç‚¹ã§ã®preference setã‚’inputã—ã€new itemã‚’æ¨è–¦ã™ã‚‹ã€‚<br><br><br><br></p>
<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/221" target="_blank" rel="noopener noreferrer">[Paper Note] Collaborative Deep Learning for Recommender Systems, Hao Wang+, arXiv'14</a>
 ã‚‚Stacked Denoising Auto Encoderã¨Collaborative Topic Regression <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/226" target="_blank" rel="noopener noreferrer">[Paper Note] Collaborative topic modeling for recommending scientific articles, Wang+, KDD'11</a>
 ã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ãŒã€<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/221" target="_blank" rel="noopener noreferrer">[Paper Note] Collaborative Deep Learning for Recommender Systems, Hao Wang+, arXiv'14</a>
 ã§ã¯article recommendationã¨ã„ã†specificãªå•é¡Œã‚’è§£ã„ã¦ã„ã‚‹ã®ã«å¯¾ã—ã¦ã€ææ¡ˆæ‰‹æ³•ã¯generalãªtop-Næ¨è–¦ã«åˆ©ç”¨ã§ãã‚‹ã“ã¨ã‚’ä¸»å¼µã€‚</p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/136" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Incorporating Copying Mechanism in Sequence-to-Sequence Learning, Gu+, ACL'16</a>
<span class="snippet"><span>Comment</span><p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š


<a href="https://www.slideshare.net/akihikowatanabe3110/incorporating-copying-mechanism-in-sequene-to-sequence-learning" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/incorporating-copying-mechanism-in-sequene-to-sequence-learning</a>


</p>
<p>å˜èªã®ã‚³ãƒ”ãƒ¼ã¨ç”Ÿæˆã€ä¸¡æ–¹ã‚’è¡Œãˆã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ææ¡ˆã€‚<br><br>location based addressingãªã©ã«ã‚ˆã£ã¦ã€ç”Ÿæˆã•ã‚ŒãŸå˜èªãŒsourceã«å«ã¾ã‚Œã¦ã„ãŸå ´åˆãªã©ã«ã€copy-mode, generate-modeã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã‚ˆã†ãªä»•çµ„ã¿ã«ãªã£ã¦ã„ã‚‹ã€‚<br><br><br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/65" target="_blank" rel="noopener noreferrer">[Paper Note] Pointing the unknown words, Gulcehre+, ACL'16</a>
 ã¨åŒã˜ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ç™ºè¡¨</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/65" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Pointing the unknown words, Gulcehre+, ACL'16</a>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€source textã‹ã‚‰ã®ã‚³ãƒ”ãƒ¼ã‚’è¡Œãˆã‚‹æ©Ÿæ§‹ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§æœªçŸ¥èªå•é¡Œã«å¯¾å‡¦ã—ãŸè©±</p>
<p>CopyNetã¨åŒã˜ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ï¼ˆã¨ã„ã†ã‹åŒã˜conferenceã§ï¼‰ç™ºè¡¨</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<a class="button" href="articles/U-Net.html" target="_blank" rel="noopener noreferrer">#U-Net</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2931" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] U-Net: Convolutional Networks for Biomedical Image Segmentation, Olaf Ronneberger+, MICCAI'15, 2015.05</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’æ´»ç”¨ã—ãŸæ–°ã—ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ææ¡ˆã—ã€å°‘ãªã„æ³¨é‡ˆä»˜ãã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¯èƒ½ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™ã€‚é›»å­é¡•å¾®é¡ã‚¹ã‚¿ãƒƒã‚¯ã®ç¥çµŒæ§‹é€ ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã§å¾“æ¥æ‰‹æ³•ã‚’ä¸Šå›ã‚Šã€é€éå…‰é¡•å¾®é¡ç”»åƒã§ã‚‚å„ªã‚ŒãŸçµæœã‚’é”æˆã€‚512x512ç”»åƒã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯1ç§’æœªæº€ã§å®Œäº†ã€‚å®Ÿè£…ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚</span>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Attention.html" target="_blank" rel="noopener noreferrer">#Attention</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1954" target="_blank" rel="noopener noreferrer" class="title-link">Neural Machine Translation by Jointly Learning to Align and Translate, Dzmitry Bahdanau+, ICLR'15</a>
<span class="snippet"><span>GPT Summary</span>- ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æ©Ÿæ¢°ç¿»è¨³ã¯ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼-ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ç”¨ã„ã¦ç¿»è¨³æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ã€‚æœ¬è«–æ–‡ã§ã¯ã€å›ºå®šé•·ã®ãƒ™ã‚¯ãƒˆãƒ«ã®ä½¿ç”¨ãŒæ€§èƒ½å‘ä¸Šã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã§ã‚ã‚‹ã¨ã—ã€ãƒ¢ãƒ‡ãƒ«ãŒé–¢é€£ã™ã‚‹ã‚½ãƒ¼ã‚¹æ–‡ã®éƒ¨åˆ†ã‚’è‡ªå‹•çš„ã«æ¤œç´¢ã§ãã‚‹ã‚ˆã†ã«æ‹¡å¼µã™ã‚‹ã“ã¨ã‚’ææ¡ˆã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è‹±èªã‹ã‚‰ãƒ•ãƒ©ãƒ³ã‚¹èªã¸ã®ç¿»è¨³ã‚¿ã‚¹ã‚¯ã§æœ€å…ˆç«¯ã®ãƒ•ãƒ¬ãƒ¼ã‚ºãƒ™ãƒ¼ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã¨åŒç­‰ã®æ€§èƒ½ã‚’é”æˆã—ã€ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãŒç›´æ„Ÿã¨ä¸€è‡´ã™ã‚‹ã“ã¨ã‚’ç¤ºã—ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>(Cross-)Attentionã‚’åˆã‚ã¦ææ¡ˆã—ãŸç ”ç©¶ã€‚ãƒ¡ãƒ¢ã£ã¦ãªã‹ã£ãŸã®ã§ä»Šæ›´ãªãŒã‚‰è¿½åŠ ã€‚Attentionã¯ã“ã“ã‹ã‚‰ã¯ã˜ã¾ã£ãŸï¼ˆã¨èªè­˜ã—ã¦ã„ã‚‹ï¼‰</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="articles/Normalization.html" target="_blank" rel="noopener noreferrer">#Normalization</a>
<span class="issue_date">Issue Date: 2025-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1857" target="_blank" rel="noopener noreferrer" class="title-link">Batch Normalization: Accelerating Deep Network Training by Reducing   Internal Covariate Shift, Sergey Ioffe+, ICML'15</a>
<span class="snippet"><span>GPT Summary</span>- ãƒãƒƒãƒæ­£è¦åŒ–ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€æ·±å±¤ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã‘ã‚‹å†…éƒ¨å…±å¤‰é‡ã‚·ãƒ•ãƒˆã®å•é¡Œã‚’è§£æ±ºã—ã€é«˜ã„å­¦ç¿’ç‡ã‚’å¯èƒ½ã«ã—ã€åˆæœŸåŒ–ã®æ³¨æ„ã‚’è»½æ¸›ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åŒã˜ç²¾åº¦ã‚’14å€å°‘ãªã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—ã§é”æˆã—ã€ImageNetåˆ†é¡ã§æœ€è‰¯ã®å…¬è¡¨çµæœã‚’4.9%æ”¹å–„ã€‚</span>
<span class="snippet"><span>Comment</span><p>ãƒ¡ãƒ¢ã£ã¦ãªã‹ã£ãŸã®ã§ä»Šæ›´ãªãŒã‚‰è¿½åŠ ã—ãŸ</p>
<p>å…±å¤‰é‡ã‚·ãƒ•ãƒˆã‚„Batch Normalizationã®èª¬æ˜ã¯<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/261" target="_blank" rel="noopener noreferrer">[Paper Note] Layer Normalization, Ba+, arXiv'16</a>
<br><br>è¨˜è¼‰ã®ã‚¹ãƒ©ã‚¤ãƒ‰ãŒåˆ†ã‹ã‚Šã‚„ã™ã„ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2021-06-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/369" target="_blank" rel="noopener noreferrer" class="title-link">Effective Approaches to Attention-based Neural Machine Translation, Luong+, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>Luongè«–æ–‡ã€‚attentionã®è©±ã—ã¯ã˜ã‚ã‚‹ã¨ã€ã ã„ãŸã„Bahdanau+ã‹ã€Luong+è«–æ–‡ãŒå¼•ç”¨ã•ã‚Œã‚‹ã€‚<br><br><br><br>Global Attentionã¨ã€Local Attentionã«ã¤ã„ã¦è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚Global AttentionãŒã‚ˆãåˆ©ç”¨ã•ã‚Œã‚‹ã€‚<br><br><br><br>Global Attention<br><br><img src="https://user-images.githubusercontent.com/12249301/120452200-008ec280-c3cd-11eb-8ced-47dc9e67f487.png" alt="image" loading="lazy"><br><br><br><br>Local Attention<br><br><img src="https://user-images.githubusercontent.com/12249301/120452397-2025eb00-c3cd-11eb-9d3b-0f7802a40712.png" alt="image" loading="lazy"><br><br></p>
<p>ã‚„ã¯ã‚ŠèŠæ± ã•ã‚“ã®è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ãŒé‰„æ¿ã€‚<br><br>


<a href="https://www.slideshare.net/yutakikuchi927/deep-learning-nlp-attention" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/yutakikuchi927/deep-learning-nlp-attention</a>


</p>
<p>å‚è€ƒã¾ã§ã«ã€Luongã‚‰ã®Global Attentionã®è¨ˆç®—ã®æµã‚Œã¯ä¸‹è¨˜ã¨ãªã£ã¦ã„ã‚‹ï¼š<br><br>- h_t -&gt; a_t -&gt; c_t -&gt; h^~_t<br><br><br><br>Bahdanauã‚‰ã®Attentionã¯ä¸‹è¨˜<br><br>- h_t-1 -&gt; a_t -&gt; c_t -&gt; h_t<br><br><br><br>t-1ã®hidden stateã‚’ä½¿ã†ã®ã‹ã€input feedingå¾Œã®ç¾åœ¨ã®hidden stateã‚’attention weightã®è¨ˆç®—ã«ä½¿ã†ã®ã‹ãŒç•°ãªã£ã¦ã„ã‚‹ã€‚</p>
<p>ã¾ãŸã€éå»ã®alignmentã®æƒ…å ±ã‚’è€ƒæ…®ã—ãŸä¸Šã§ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ã¦ã„ããŸã‚ã«ã€input-feeding approachã‚‚ææ¡ˆ<br><br><img src="https://user-images.githubusercontent.com/12249301/120877145-cfdaa300-c5ef-11eb-8a8b-a57d03d864b4.png" alt="image" loading="lazy"><br><br><br><br>input-feeding appproachã§ã¯ã€t-1ã‚¹ãƒ†ãƒƒãƒ—ç›®ã®outputã®ç®—å‡ºã«ä½¿ã£ãŸh^~_tï¼ˆhidden_stateã¨context vectorã‚’concatã—ã€tanhã®activationã‚’å™›ã¾ã›ãŸç·šå½¢å¤‰æ›ã‚’è¡Œãªã£ãŸãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã‚’ã€æ™‚åˆ»tã®input embeddingã«concatã—ã¦ã€RNNã«å…¥åŠ›ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/SessionBased.html" target="_blank" rel="noopener noreferrer">#SessionBased</a>
<a class="button" href="articles/ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="articles/SequentialRecommendation.html" target="_blank" rel="noopener noreferrer">#SequentialRecommendation</a>
<span class="issue_date">Issue Date: 2019-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/315" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Session-based Recommendations with Recurrent Neural Networks, BalÃ¡zs Hidasi+, arXiv'15</a>
<span class="snippet"><span>GPT Summary</span>- RNNã‚’ç”¨ã„ãŸã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ã®ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã‚’ææ¡ˆã€‚çŸ­ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ’ã‚¹ãƒˆãƒªãƒ¼ã«åŸºã¥ãæ¨è–¦ã®ç²¾åº¦å‘ä¸Šã‚’ç›®æŒ‡ã—ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã€‚ãƒ©ãƒ³ã‚­ãƒ³ã‚°æå¤±é–¢æ•°ãªã©ã®ä¿®æ­£ã‚’åŠ ãˆã€å®Ÿç”¨æ€§ã‚’è€ƒæ…®ã€‚å®Ÿé¨“çµæœã¯å¾“æ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«å¯¾ã—ã¦é¡•è‘—ãªæ”¹å–„ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>RNNã‚’åˆ©ç”¨ã—ãŸsequential recommendation (session-based recommendation)ã®å…ˆé§†ã‘çš„è«–æ–‡ã€‚</p>
<p>æ—¥æœ¬èªè§£èª¬: 


<a href="https://qiita.com/tatamiya/items/46e278a808a51893deac" target="_blank" rel="noopener noreferrer">https://qiita.com/tatamiya/items/46e278a808a51893deac</a>


</p></span><br><br>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/StudentPerformancePrediction.html" target="_blank" rel="noopener noreferrer">#StudentPerformancePrediction</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2018-12-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/297" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep Knowledge Tracing, Piech+, NIPS'15</a>
&lt;span class=\"snippet\"&gt;<span>Comment</span><p>Knowledge Tracingã‚¿ã‚¹ã‚¯ã¨ã¯ï¼š<br><br>ã€€ç‰¹å®šã®learning taskã«ãŠã„ã¦ã€ç”Ÿå¾’ã«ã‚ˆã£ã¦ã¨ã‚‰ã‚ŒãŸã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã®ç³»åˆ—x0, ..., xtãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€æ¬¡ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³xt+1ã‚’äºˆæ¸¬ã™ã‚‹ã‚¿ã‚¹ã‚¯<br><br>ã€€å…¸å‹çš„ãªè¡¨ç¾ã¨ã—ã¦ã¯ã€xt={qt, at}, where qt=knowledge component \(KC) ID \(ã‚ã‚‹ã„ã¯å•é¡ŒID)ã€at=æ­£è§£ã—ãŸã‹å¦ã‹<br><br>ã€€ãƒ¢ãƒ‡ãƒ«ãŒäºˆæ¸¬ã™ã‚‹ã¨ãã¯ã€qtãŒgivenãªæ™‚ã«ã€atã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã«ãªã‚‹<br><br><br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/50377468-2989c580-0661-11e9-97c9-328056fbd692.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br><br><br>Contribution:<br><br>ã€€1. A novel way to encode student interactions as input to a recurrent neural network.<br><br>ã€€2. A 25% gain in AUC over the best previous result on a knowledge tracing benchmark.<br><br>ã€€3. Demonstration that our knowledge tracing model does not need expert annotations.<br><br>ã€€4. Discovery of exercise influence and generation of improved exercise curricula.<br><br><br><br>ãƒ¢ãƒ‡ãƒ«ï¼š<br><br><br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/50377473-432b0d00-0661-11e9-97e1-a60a68a6ef32.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br><br><br>Inputã¯ã€ExerciseãŒMå€‹ã‚ã£ãŸã¨ãã«ã€Må€‹ã®ExerciseãŒcorrectã‹å¦ã‹ã‚’è¡¨ã™ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆé•·ã•2Mãƒ™ã‚¯ãƒˆãƒ«ã®one-hotï¼‰ã€‚separateãªrepresentationã«ã™ã‚‹ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä¸‹ãŒã‚‹ã‚‰ã—ã„ã€‚<br><br>Output ytã®é•·ã•ã¯å•é¡Œæ•°Mã¨ç­‰ã—ãã€å„è¦ç´ ã¯ã€ç”Ÿå¾’ãŒå¯¾å¿œã™ã‚‹å•é¡Œã‚’æ­£ç­”ã™ã‚‹ç¢ºç‡ã€‚<br><br><br><br>Inputã¨ã—ã¦Exerciseã‚’ç”¨ã„ã‚‹ã‹ã€Exerciseã®KCã‚’ç”¨ã„ã‚‹ã‹ã¯ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ¬¡ç¬¬ã£ã½ã„ãŒã€å…¸å‹çš„ã«ã¯å„ã‚¹ã‚­ãƒ«ã®æ½œåœ¨çš„ãªmasteryã‚’æ¸¬ã‚‹ã“ã¨ãŒãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ãªã®ã§KCã‚’ä½¿ã†ã€‚<br><br><br><br>ï¼ˆã‚‚ã—å•é¡Œæ•°ãŒè†¨å¤§ã«ã‚ã‚‹ã‚ˆã†ãªè¨­å®šã®å ´åˆã¯ã€å„å•é¡Œ-æ­£/èª¤ç­”tupleã«å¯¾ã—ã¦ã€random vectorã‚’æ­£è¦åˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ã€one-hot high-dimensional vectorã§è¡¨ç¾ã™ã‚‹ã€‚ï¼‰<br><br><br><br>hidden sizeã¯200, mini-batch sizeã¯100ã¨ã—ã¦ã„ã‚‹ã€‚<br><br><br><br>\[Educational Applicationsã¸ã®å¿œç”¨]<br><br><br><br>ç”Ÿå¾’ã¸æœ€é©ãªãƒ‘ã‚¹ã®å­¦ç¿’ã‚¢ã‚¤ãƒ†ãƒ ã‚’é¸ã‚“ã§æç¤ºã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨<br><br>ã€€ç”Ÿå¾’ã®knowledge stateã‚’äºˆæ¸¬ã—ã€ãã®å¾Œç‰¹å®šã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç”Ÿå¾’ã«assignã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ãŸã¨ãˆã°ã€ç”Ÿå¾’ãŒ50å€‹ã®Exerciseã«å›ç­”ã—ãŸå ´åˆã€ç”Ÿå¾’ã¸æ¬¡ã«æç¤ºã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ã‚’è¨ˆç®—ã™ã‚‹ã ã‘ã§ãªãã€ãã®çµæœæœŸå¾…ã•ã‚Œã‚‹ç”Ÿå¾’ã®knowledge stateã‚‚æ¨æ¸¬ã™ã‚‹ã“ã¨ãŒã§ãã‚‹<br><br><br><br>Exercisesé–“ã®é–¢ä¿‚æ€§ã‚’è¦‹å‡ºã™ã“ã¨ãŒã§ãã‚‹<br><br>ã€€y\( j | i )ã‚’è€ƒãˆã‚‹ã€‚y\( j | i )ã¯ã€ã¯ã˜ã‚ã«exercise iã‚’æ­£ç­”ã—ãŸå¾Œã«ã€second time stepã§jã‚’æ­£ç­”ã™ã‚‹ç¢ºç‡ã€‚ã“ã‚Œã«ã‚ˆã£ã¦ã€pre-requisiteã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br><br><br><br>\[è©•ä¾¡]<br><br>3ç¨®é¡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã‚‹ã€‚<br><br>ã€€1. simulated Data<br><br>ã€€ã€€2000äººã®virtual studentã‚’ä½œã‚Šã€1ã€œ5ã¤ã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‹ã‚‰ç”Ÿæˆã•ã‚ŒãŸã€50å•ã‚’ã€åŒã˜é †ç•ªã§è§£ã‹ã›ãŸã€‚ã“ã®ã¨ãã€IRTãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¯å®Ÿæ–½ã—ãŸã€‚ã“ã®ã¨ãã€hidden stateã®ãƒ©ãƒ™ãƒ«ã«ã¯ä½•ã‚‚ä½¿ã‚ãªã„ã§ã€inputã¯å•é¡Œã®IDã¨æ­£èª¤ãƒ‡ãƒ¼ã‚¿ã ã‘ã‚’ä¸ãˆãŸã€‚ã•ã‚‰ã«ã€2000äººã®virtual studentã‚’ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½œã‚Šã€ãã‚Œãã‚Œã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆï¼ˆã‚³ãƒ³ã‚»ãƒ—ãƒˆæ•°ã‚’1ã€œ5ã«å¤‰å‹•ã•ã›ã‚‹ï¼‰ã«å¯¾ã—ã¦ã€20å›ãƒ©ãƒ³ãƒ€ãƒ ã«ç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã§accuracyã®å¹³å‡ã¨standard errorã‚’æ¸¬ã£ãŸã€‚<br><br>ã€€2. Khan Academy Data<br><br>ã€€ã€€1.4Mã®Exerciseã¨ã€69ã®ç•°ãªã‚‹Exercise TypeãŒã‚ã‚Šã€47495äººã®ç”Ÿå¾’ãŒExerciseã‚’è¡Œãªã£ã¦ã„ã‚‹ã€‚<br><br>ã€€ã€€PersonalãªInformationã¯å«ã‚“ã§ã„ãªã„ã€‚<br><br>ã€€3. Assistsments bemchmark Dataset<br><br>ã€€ã€€2009-2011ã®skill builder public benchmark datasetã‚’ç”¨ã„ãŸã€‚Assistmentsã¯ã€online tutorãŒã€æ•°å­¦ã‚’æ•™ãˆã¦ã€æ•™ãˆã‚‹ã®ã¨åŒæ™‚ã«ç”Ÿå¾’ã‚’è©•ä¾¡ã™ã‚‹ã‚ˆã†ãªæ çµ„ã¿ã§ã‚ã‚‹ã€‚<br><br><br><br>ãã‚Œãã‚Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ã€AUCã‚’è¨ˆç®—ã€‚<br><br>ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¯ã€BKTã¨ç”Ÿå¾’ãŒã‚ã‚‹å•é¡Œã‚’æ­£ç­”ã—ãŸå ´åˆã®å‘¨è¾ºç¢ºç‡ï¼Ÿ<br><br><br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/50377495-b0d73900-0661-11e9-9ca2-1cb97393d698.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br><br><br>&lt;img src=\"https://user-images.githubusercontent.com/12249301/50377501-b92f7400-0661-11e9-87ce-9f836c860209.png\" alt=\"image\" loading=\"lazy\" /&gt;<br><br><br><br>simulated dataã®å ´åˆã€å•é¡Œç•ªå·5ãŒã‚³ãƒ³ã‚»ãƒ—ãƒˆ1ã‹ã‚‰ç”Ÿæˆã•ã‚Œã€å•é¡Œç•ªå·22ã¾ã§ã®å•é¡Œã¯åˆ¥ã®ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‹ã‚‰ç”Ÿæˆã•ã‚Œã¦ã„ãŸã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€ãã¡ã‚“ã¨äºŒã¤ã®å•é¡Œã®é–¢ä¿‚ã‚’ã¨ã‚‰ãˆã‚‰ã‚Œã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ã€‚<br><br>Khan Datasetã«ã¤ã„ã¦ã‚‚åŒæ§˜ã®è§£æã‚’ã—ãŸã€‚ã“ã‚Œã¯ã€ã“ã®çµæœã¯å°‚é–€å®¶ãŒè¦‹ãŸã‚‰é©šãã¹ãã‚‚ã®ã§ã¯ãªã„ã‹ã‚‚ã—ã‚Œãªã„ãŒã€ãƒ¢ãƒ‡ãƒ«ãŒä¸€è²«ã—ãŸã‚‚ã®ã‚’å­¦ç¿’ã—ãŸã¨è¨€ãˆã‚‹ã€‚<br><br><br><br>\[Discussion]<br><br>ææ¡ˆãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´ã¨ã—ã¦ã€ä¸‹è¨˜ã®ï¼’ã¤ãŒã‚ã‚‹ï¼š<br><br><br><br>å°‚é–€å®¶ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¿…è¦ã¨ã—ãªã„ï¼ˆconcept patternã‚’å‹æ‰‹ã«å­¦ç¿’ã—ã¦ãã‚Œã‚‹ï¼‰<br><br>ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸç”Ÿå¾’ã®inputã§ã‚ã‚Œã°ã€ãªã‚“ã§ã‚‚operateã™ã‚‹ã“ã¨ãŒã§ãã‚‹<br><br>drawbackã¨ã—ã¦ã¯ã€å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã ã¨ã„ã†ã“ã¨ã€‚small classroom environmentã§ã¯ãªãã€online education environmentã«å‘ã„ã¦ã„ã‚‹ã€‚<br><br>ä»Šå¾Œã®æ–¹å‘æ€§ã¨ã—ã¦ã¯ã€<br><br>ãƒ»incorporate other feature as inputs \(such as time taken)<br><br>ãƒ»explore other educational impacts \(hint generation, dropout prediction)<br><br>ãƒ»validate hypotheses posed in education literature \(such as spaced repetition, modeling how students forget)<br><br>ãƒ»open-ended programmingã¨ã‹ã¸ã®å¿œç”¨ã¨ã‹ï¼ˆproramã®vectorizationã®æ–¹æ³•ã¨ã‹ãŒæœ€è¿‘ææ¡ˆã•ã‚Œã¦ã„ã‚‹ã®ã§ï¼‰<br><br>ãªã©ãŒã‚ã‚‹ã€‚</p>
<p>knewtonã®ã‚°ãƒ«ãƒ¼ãƒ—ãŒã€DKTã‚’æ—¢å­˜æ‰‹æ³•ã§ã‚ã‚‹IRTã®å¤‰ç¨®ã‚„BKTã®å¤‰ç¨®ãªã©ã§outperformã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã™ï¼š<br><br>


<a href="https://arxiv.org/pdf/1604.02336.pdf" target="_blank" rel="noopener noreferrer">https://arxiv.org/pdf/1604.02336.pdf</a>


<br><br><br><br>vanillaãªDKTã¯ã‹ãªã‚ŠãƒŠã‚¤ãƒ¼ãƒ–ãªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ä»Šå¾Œã®ä¼¸ã³ãŒçµæ§‹æœŸå¾…ã§ãã‚‹ã¨æ€ã†ã®ã§ã€å˜ç´”ã«outperformã—ã¦ã‚‚ã€ä»Šå¾Œã®ç™ºå±•æ€§ã‚’è€ƒãˆã‚‹ã¨ã‚„ã¯ã‚ŠDKTã«ã¯æ³¨ç›®ã›ã–ã‚‹ã‚’å¾—ãªã„æ„Ÿ</p>
<p>DKTå…ƒè«–æ–‡ã§ã¯ã€BKTã‚’å¤§å¹…ã«outperformã—ã¦ãŠã‚Šã€å‰²ã¨è¡æ’ƒçš„ãªçµæœã ã£ãŸã‚ˆã†ã ãŒã€<br><br>å¾Œã«è«–æ–‡ä¸­ã§åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹Assistmentsãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸­ã«dupilcate entryãŒã‚ã‚Šã€<br><br>ãã‚ŒãŒåŸå› ã§æ€§èƒ½ãŒä¸å½“ã«ä¸ŠãŒã£ã¦ã„ã‚‹ã“ã¨ãŒåˆ¤æ˜ã€‚<br><br><br><br>çµå±€DKTã®æ€§èƒ½çš„ã«ã¯ã€BKTã¨ã©ã£ã“ã„ã¿ãŸã„ãªã“ã¨ã‚’Ryan Bakeræ°ãŒedXã§è¨€ã£ã¦ã„ãŸæ°—ãŒã™ã‚‹ã€‚</p>
<p>Deep Knowledge Tracingãªã©ã®Knowledge Tracingã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã¯ã€<br><br>åŸºæœ¬çš„ã«å•é¡Œã”ã¨ã«Knowledge Component(ã‚ã‚‹ã„ã¯çŸ¥è­˜ã‚¿ã‚°, ãã®å•é¡Œã‚’è§£ãã®ã«å¿…è¦ãªã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆï¼‰ãŒä»˜ä¸ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒå‰æã¨ãªã£ã¦ã„ã‚‹ã€‚<br><br>ãŸã ã—ã€ã“ã®ã‚ˆã†ãªçŸ¥è­˜ã‚¿ã‚°ã‚’ä»˜ä¸ã™ã‚‹ã«ã¯å°‚é–€å®¶ã«ã‚ˆã‚‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãŒå¿…è¦ã§ã‚ã‚Šã€<br><br>é©ç”¨ã—ãŸã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦å¿…ãšã—ã‚‚ä»˜ä¸ã•ã‚Œã¦ã„ã‚‹ã¨ã¯é™ã‚‰ãªã„ã€‚<br><br><br><br>ã“ã®ã‚ˆã†ãªå ´åˆã¯ã€DKTã¯å˜ãªã‚‹â€å•é¡Œâ€ã®æ­£ç­”ç‡äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦æ©Ÿèƒ½ã•ã›ã‚‹ã“ã¨ã—ã‹ã§ããªã„ãŒã€<br><br>çŸ¥è­˜ã‚¿ã‚°ãã®ã‚‚ã®ã‚‚Neural Networkã«å­¦ç¿’ã•ã›ã¦ã—ã¾ãŠã†ã¨ã„ã†è©¦ã¿ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ï¼š<br><br>


<a href="https://www.jstage.jst.go.jp/article/tjsai/33/3/33_C-H83/_article/-char/ja" target="_blank" rel="noopener noreferrer">https://www.jstage.jst.go.jp/article/tjsai/33/3/33_C-H83/_article/-char/ja</a>


</p>
<p>DKTã«é–¢ã™ã‚‹è©³ç´°ãªèª¬æ˜ãŒæ›¸ã‹ã‚Œã¦ã„ã‚‹ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆï¼š<br><br>expectimaxã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®èª¬æ˜ã‚„ã€æœ€çµ‚çš„ãªoutput vector y_i ã®å›³è§£ãªã©ã€èª¬æ˜ãŒçœç•¥ã•ã‚Œã‚¬ãƒãªã¨ã“ã‚ãŒè©³ç´°ã«æ›¸ã„ã¦ã‚ã£ã¦æœ‰ç”¨ã€‚ï¼ˆè‹±èªã«ç¿»è¨³ã—ã¦èª­ã‚€ã¨è‰¯ã„ï¼‰<br><br>


<a href="https://hcnoh.github.io/2019-06-14-deep-knowledge-tracing" target="_blank" rel="noopener noreferrer">https://hcnoh.github.io/2019-06-14-deep-knowledge-tracing</a>


</p>
<p>ã“ã¡ã‚‰ã®ãƒªãƒã‚¸ãƒˆãƒªã§ã¯expectimaxã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã£ã¦virtualtutorã‚’å®Ÿè£…ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br>è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆã‚‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã€‚<br><br>


<a href="https://github.com/alessandroscoppio/VirtualIntelligentTutor" target="_blank" rel="noopener noreferrer">https://github.com/alessandroscoppio/VirtualIntelligentTutor</a>


</p>
<p>DKTã®inputã®æ¬¡å…ƒæ•°ãŒ 2 * num_skills, outputã®æ¬¡å…ƒæ•°ãŒnum_skillsã ã¨æ˜è¨˜ã•ã‚Œã¦ã„ã‚‹ã‚¹ãƒ©ã‚¤ãƒ‰ã€‚<br><br>å…ƒè«–æ–‡ã ã¨ã“ã®è¾ºãŒè¨€åŠã•ã‚Œã¦ã„ãªãã¦ã‚ã‹ã‚Šã¥ã‚‰ã„ãƒ»ãƒ»ãƒ»<br><br>


<a href="http://gdac.uqam.ca/Workshop@EDM20/slides/LSTM_tutorial_Application.pdf" target="_blank" rel="noopener noreferrer">http://gdac.uqam.ca/Workshop@EDM20/slides/LSTM_tutorial_Application.pdf</a>


<br><br>


<a href="http://gdac.uqam.ca/Workshop@EDM20/slides/LSTM_Tutorial.pdf" target="_blank" rel="noopener noreferrer">http://gdac.uqam.ca/Workshop@EDM20/slides/LSTM_Tutorial.pdf</a>


<br><br><br><br>ã“ã¡ã‚‰ã®ãƒšãƒ¼ã‚¸ãŒä¸Šè¨˜ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã®ãƒšãƒ¼ã‚¸<br><br>


<a href="http://gdac.uqam.ca/Workshop@EDM20/" target="_blank" rel="noopener noreferrer">http://gdac.uqam.ca/Workshop@EDM20/</a>


</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="articles/IJCNLP.html" target="_blank" rel="noopener noreferrer">#IJCNLP</a>
<span class="issue_date">Issue Date: 2018-03-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/266" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Unsupervised prediction of acceptability judgements, Lau+, ACL-IJCNLP'15</a>
<span class="snippet"><span>Comment</span><p>æ–‡ã®acceptabilityï¼ˆå®¹èªåº¦ï¼‰è«–æ–‡ã€‚<br><br>æ–‡ã®acceptabilityã¨ã¯ã€native speakerãŒã‚ã‚‹æ–‡ã‚’èª­ã‚“ã ã¨ãã«ã€ãã®æ–‡ã‚’æ­£ã—ã„æ–‡ã¨ã—ã¦å®¹èªã§ãã‚‹åº¦åˆã„ã®ã“ã¨ã€‚<br><br>acceptabilityã‚¹ã‚³ã‚¢ãŒä½ã„ã¨ã€ReadabilityãŒä½ã„ã¨åˆ¤æ–­ã§ãã‚‹ã€‚<br><br>è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã«æ§˜ã€…ãªæ­£è¦åŒ–ã‚’æ–½ã™ã“ã¨ã§ã€acceptabilityã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2018-02-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/262" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] An Empirical Exploration of Recurrent Network Architectures, Jozefowicz+, ICML'15</a>
<span class="snippet"><span>Comment</span><p>GRUã¨LSTMã®é•ã„ã‚’ç†è§£ã™ã‚‹ã®ã«æœ€é©</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2018-02-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/257" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks, Tai+, ACL'15</a>
<span class="snippet"><span>Comment</span><p>Tree-LSTMè«–æ–‡</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Supervised.html" target="_blank" rel="noopener noreferrer">#Supervised</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/137" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Neural Attention Model for Sentence Summarization, Rush+, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š


<a href="https://www.slideshare.net/akihikowatanabe3110/a-neural-attention-model-for-sentence-summarization-65612331" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/a-neural-attention-model-for-sentence-summarization-65612331</a>


</p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Abstractive.html" target="_blank" rel="noopener noreferrer">#Abstractive</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/75" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LCSTS: A large scale chinese short text summarizatino dataset, Hu+, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>Large Chinese Short Text Summarization (LCSTS) datasetã‚’ä½œæˆ<br><br><br><br>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹éš›ã¯ã€Weiboä¸Šã®ç‰¹å®šã®organizationã®æŠ•ç¨¿ã®ç‰¹å¾´ã‚’åˆ©ç”¨ã€‚<br><br>Weiboã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æŠ•ç¨¿ã™ã‚‹éš›ã«ã€æŠ•ç¨¿ã®å†’é ­ã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®very short summaryãŒã¾ãšè¨˜è¼‰ã•ã‚Œã€ãã®å¾Œãƒ‹ãƒ¥ãƒ¼ã‚¹æœ¬æ–‡ï¼ˆçŸ­ã‚ï¼‰ãŒè¨˜è¼‰ã•ã‚Œã‚‹ç‰¹å¾´ãŒã‚ã‚‹ã®ã§ã€ã“ã®å¯¾ã‚’source-referenceå¯¾ã¨ã—ã¦åé›†ã—ãŸã€‚<br><br>åé›†ã™ã‚‹éš›ã«ã¯ã€ç´„ï¼‘ï¼ï¼å€‹ã®ãƒ«ãƒ¼ãƒ«ã«åŸºã¥ããƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚„clearning, æŠ½å‡ºç­‰ã‚’è¡Œãªã£ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34411045-95f7baf2-ec17-11e7-94fb-faf2559d6994.png" alt="image" loading="lazy"><br><br><br><br>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®propertyã¨ã—ã¦ã¯ã€ä¸‹è¨˜ã®PartI, II, IIIã«åˆ†ã‹ã‚Œã¦ã„ã‚‹ã€‚<br><br><br><br>PartI: 2.4Mã®short text - summary pair<br><br>PartII: PartIã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã•ã‚ŒãŸ10kã®pairã«å¯¾ã—ã¦ã€5 scaleã§è¦ç´„ã®relevanceã‚’ratingã—ãŸãƒ‡ãƒ¼ã‚¿ã€‚ãŸã ã—ã€å„pairã«ãƒ©ãƒ™ãƒ«ã¥ã‘ã‚’ã—ãŸevaluatorã¯1åã®ã¿ã€‚<br><br>PartIII: 2kã®pairã«å¯¾ã—ã¦ï¼ˆPartI, PartIIã¨ã¯ç‹¬ç«‹ï¼‰ã€3åã®evaluatorãŒ5-scaleã§ratingã€‚evaluatorã®ratingãŒä¸€è‡´ã—ãŸ1kã®pairã‚’æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34411199-8db4df90-ec18-11e7-8703-fd8f9512a903.png" alt="image" loading="lazy"><br><br><br><br>RNN-GRUã‚’ç”¨ã„ãŸSummarizerã‚‚ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34411224-b5543eba-ec18-11e7-8556-a3b42bfcf334.png" alt="image" loading="lazy"><br><br><br><br></p>
<p>CopyNetãªã©ã¯LCSTSã‚’ä½¿ã£ã¦è©•ä¾¡ã—ã¦ã„ã‚‹ã€‚ä»–ã«ã‚‚ä½¿ã£ã¦ã‚‹è«–æ–‡ã‚ã£ãŸã¯ãšã€‚</p>
<p>ACL'17ã®Pointer Generator Networkã§ã—ãŸã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/59" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Sentence Compression by Deletion with LSTMs, Fillipova+, EMNLP'15</a>
<span class="snippet"><span>Comment</span><p>slide:


<a href="https://www.slideshare.net/akihikowatanabe3110/sentence-compression-by-deletion-with-lstms" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/sentence-compression-by-deletion-with-lstms</a>


</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2861" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Sequence to Sequence Learning with Neural Networks, Ilya Sutskever+, NIPS'14</a>
<span class="snippet"><span>GPT Summary</span>- DNNã¯ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å­¦ç¿’ã«ãŠã„ã¦å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã™ãŒã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é–“ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã«ã¯é™ç•ŒãŒã‚ã‚‹ã€‚æœ¬ç ”ç©¶ã§ã¯ã€LSTMã‚’ç”¨ã„ãŸã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã€è‹±èªã‹ã‚‰ãƒ•ãƒ©ãƒ³ã‚¹èªã¸ã®ç¿»è¨³ã‚¿ã‚¹ã‚¯ã§34.8ã®BLEUã‚¹ã‚³ã‚¢ã‚’é”æˆã€‚LSTMã¯é•·æ–‡ã«ã‚‚å¯¾å¿œã—ã€SMTã‚·ã‚¹ãƒ†ãƒ ã®å‡ºåŠ›ã‚’å†ãƒ©ãƒ³ã‚¯ä»˜ã‘ã™ã‚‹ã“ã¨ã§BLEUã‚¹ã‚³ã‚¢ã‚’36.5ã«å‘ä¸Šã•ã›ãŸã€‚ã¾ãŸã€å˜èªã®é †åºã‚’é€†ã«ã™ã‚‹ã“ã¨ã§æ€§èƒ½ãŒå‘ä¸Šã—ã€çŸ­æœŸçš„ä¾å­˜é–¢ä¿‚ã®æœ€é©åŒ–ãŒå®¹æ˜“ã«ãªã£ãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>ã„ã¾ã•ã‚‰ãªãŒã‚‰Seq2Seqã‚’ææ¡ˆã—ãŸç ”ç©¶ã‚’è¿½åŠ </p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/MatrixFactorization.html" target="_blank" rel="noopener noreferrer">#MatrixFactorization</a>
<a class="button" href="articles/SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/221" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Collaborative Deep Learning for Recommender Systems, Hao Wang+, arXiv'14</a>
<span class="snippet"><span>GPT Summary</span>- å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆCFï¼‰ã¯ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã§åºƒãç”¨ã„ã‚‰ã‚Œã‚‹ãŒã€è©•ä¾¡ãŒã¾ã°ã‚‰ãªå ´åˆã«æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹ã€‚ã“ã‚Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€è£œåŠ©æƒ…å ±ã‚’æ´»ç”¨ã™ã‚‹å”èª¿ãƒˆãƒ”ãƒƒã‚¯å›å¸°ï¼ˆCTRï¼‰ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ãŒã€è£œåŠ©æƒ…å ±ãŒã¾ã°ã‚‰ãªå ´åˆã«ã¯åŠ¹æœãŒè–„ã„ã€‚ãã“ã§ã€æœ¬ç ”ç©¶ã§ã¯å”èª¿æ·±å±¤å­¦ç¿’ï¼ˆCDLï¼‰ã¨ã„ã†éšå±¤ãƒ™ã‚¤ã‚ºãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã—ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æƒ…å ±ã®æ·±ã„è¡¨ç¾å­¦ç¿’ã¨CFã‚’å…±åŒã§è¡Œã†ã€‚å®Ÿé¨“ã«ã‚ˆã‚Šã€CDLãŒæœ€å…ˆç«¯æŠ€è¡“ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚</span>
<span class="snippet"><span>Comment</span><p>Rating Matrixã‹ã‚‰userã¨itemã®latent vectorã‚’å­¦ç¿’ã™ã‚‹éš›ã«ã€Stacked Denoising Auto Encoderï¼ˆSDAEï¼‰ã«ã‚ˆã‚‹itemã®embeddingã‚’æ´»ç”¨ã™ã‚‹è©±ã€‚<br><br>Collaborative Filteringã¨Contents-based Filteringã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ‰‹æ³•ã€‚<br><br>Collaborative Filteringã«ãŠã„ã¦Deepãªãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã™ã‚‹åˆæœŸã®ç ”ç©¶ã€‚<br><br><br><br>é€šå¸¸ã¯user vectorã¨item vectorã®å†…ç©ã®å€¤ãŒå¯¾å¿œã™ã‚‹ratingã‚’å†ç¾ã§ãã‚‹ã‚ˆã†ã«ç›®çš„é–¢æ•°ãŒè¨­è¨ˆã•ã‚Œã‚‹ãŒã€ãã“ã«item vectorã¨SDAEã«ã‚ˆã‚‹itemã®EmbeddingãŒè¿‘ããªã‚‹ã‚ˆã†ãªé …ï¼ˆ3é …ç›®ï¼‰ã€SDAEã®ã‚¨ãƒ©ãƒ¼ï¼ˆ4é …ç›®ï¼‰ã‚’è¿½åŠ ã™ã‚‹ã€‚<br><br><br><br>ï¼ˆ3é …ç›®ã®æ„ç¾©ã«ã¤ã„ã¦ã€è§£èª¬ãƒ–ãƒ­ã‚°ã‚ˆã‚Šï¼‰ã‚¢ã‚¤ãƒ†ãƒ  i ã«é–¢ã™ã‚‹æ½œåœ¨è¡¨ç¾ vi ã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ç™»å ´ã™ã‚‹ã‚‚ã®ã«ã¤ã„ã¦ã¯æ¨å®šã§ãã‚‹ã‘ã‚Œã©ï¼ŒæœªçŸ¥ã®ã‚‚ã®ã«ã¤ã„ã¦ã¯æ¨å®šã§ããªã„ï¼ãã“ã§SDAEã®ä¸­é–“å±¤ã®çµæœã‚’ã€Œæ¨å®šã—ãŸviã€ã¨ã—ã¦ã€ŒçœŸã®ã€ vi ã«ã§ãã‚‹é™ã‚Šè¿‘ã¥ã‘ã‚‹ï¼Œã¨ã„ã†ã®ãŒã“ã®é …ã®æ°—æŒã¡<br><br><br><br>cite-ulikeãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹è«–æ–‡æ¨è–¦ã€Netflixãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹æ˜ ç”»æ¨è–¦ã§è©•ä¾¡ã—ãŸçµæœã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆCollective Matrix Factorization <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/222" target="_blank" rel="noopener noreferrer">[Paper Note] Relational learning via collective matrix factorization, Singh+, KDD'08</a>
 , SVDFeature <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/223" target="_blank" rel="noopener noreferrer">[Paper Note]  SVDFeature: a toolkit for feature-based collaborative filtering, Chen+, JMLR'12</a>
 , DeepMusic <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/224" target="_blank" rel="noopener noreferrer">[Paper Note] Deep content-based music recommendation, Oord+, NIPS'13</a>
 , Collaborative Topic Regresison <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/226" target="_blank" rel="noopener noreferrer">[Paper Note] Collaborative topic modeling for recommending scientific articles, Wang+, KDD'11</a>
 ï¼‰ã‚’outperformã€‚<br><br><br>ï¼ˆä¸‹è¨˜ã¯ç®¡ç†äººãŒéå»ã«ä½œæˆã—ãŸè«–æ–‡ãƒ¡ãƒ¢ã‚¹ãƒ©ã‚¤ãƒ‰ã®ã‚¹ã‚¯ã‚·ãƒ§ï¼‰<br><br><img src="https://user-images.githubusercontent.com/12249301/34813194-58142a60-f6ec-11e7-938e-34b7d0cfb930.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34813227-786b9640-f6ec-11e7-8713-940433dc9e8f.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34813243-87832d28-f6ec-11e7-8371-fa60a54a1ba6.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34813251-91d5896a-f6ec-11e7-94ec-3b2c225ddf9a.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34813259-9b18b5e2-f6ec-11e7-98ae-1b5323b3e8b3.png" alt="image" loading="lazy"><br><br></p>
<p>è§£èª¬ãƒ–ãƒ­ã‚°ï¼š


<a href="http://d.hatena.ne.jp/repose/20150531/1433004688" target="_blank" rel="noopener noreferrer">http://d.hatena.ne.jp/repose/20150531/1433004688</a>


</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/58" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Hierarchical Summarization: Scaling Up Multi-Document Summarization, Christensen+, ACL'14</a>
<span class="snippet"><span>Comment</span><p>## æ¦‚è¦<br><br>ã ã„ã¶å‰ã«èª­ã‚“ã ã€‚å¥½ããªç ”ç©¶ã€‚<br><br>ãƒ†ã‚­ã‚¹ãƒˆã®sentenceã‚’éšå±¤çš„ã«ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€æŠ½è±¡åº¦ãŒé«˜ã„æƒ…å ±ã‹ã‚‰ã€é–¢é€£ã™ã‚‹å…·ä½“åº¦ã®é«˜ã„sentenceã«drill downã—ã¦ã„ã‘ã‚‹Interactiveãªè¦ç´„ã‚’ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br><br><br>## æ‰‹æ³•<br><br>é€šå¸¸ã®MDSã§ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¦æ¨¡ã‚ˆã‚Šã‚‚ã€å®Ÿéš›ã«MDSã‚’ä½¿ã†éš›ã«ã¯ã•ã‚‰ã«å¤§ããªè¦æ¨¡ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã‚ãªã‘ã‚Œã°ãªã‚‰ãªã„ã“ã¨ã‚’æŒ‡æ‘˜ã—ï¼ˆãŸã¨ãˆã°New York Timesã§ç‰¹å®šã®ãƒ¯ãƒ¼ãƒ‰ã§ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ¤œç´¢ã™ã‚‹ã¨æ•°åƒã€æ•°ä¸‡ä»¶ã®è¨˜äº‹ãŒãƒ’ãƒƒãƒˆã—ãŸã‚Šã™ã‚‹ï¼‰ãã®ãŸã‚ã«å¿…è¦ãªäº‹é …ã‚’æ¤œè¨ã€‚<br><br>ã“ã‚Œã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ã€éšå±¤çš„ãªã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚<br><br>ææ¡ˆæ‰‹æ³•ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã®sentenceã‚’éšå±¤çš„ã«ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ã€ä¸‹ä½ã®å±¤ã«è¡Œãã»ã©ã‚ˆã‚Šå…·ä½“çš„ãªæƒ…å ±ã«ãªã‚‹ã‚ˆã†ã«sentenceã‚’è¡¨ç¾ã€‚ã•ã‚‰ã«ã€ä¸Šä½ã€ä¸‹ä½ã®sentenceé–“ã«ã¯ã‚¨ãƒƒã‚¸ãŒå¼µã‚‰ã‚Œã¦ãŠã‚Šã€ä¸‹ä½ã«ç´ä»˜ã‘ã‚‰ã‚ŒãŸsentence<br><br></p>
<p>ã¯ä¸Šä½ã«ç´ä»˜ã‘ã‚‰ã‚ŒãŸsentenceã®æƒ…å ±ã‚’ã‚ˆã‚Šå…·ä½“çš„ã«è¿°ã¹ãŸã‚‚ã®ã¨ãªã£ã¦ã„ã‚‹ã€‚<br><br>ã“ã‚Œã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€drill downå‹ã®Interactiveãªè¦ç´„ã‚’å®Ÿç¾ã€‚</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/QueryBiased.html" target="_blank" rel="noopener noreferrer">#QueryBiased</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/57" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Query-Chain Focused Summarization, Baumel+, ACL'14</a>
<span class="snippet"><span>Comment</span><p>ï¼ˆç®¡ç†äººãŒä½œæˆã—ãŸéå»ã®ç´¹ä»‹è³‡æ–™ï¼‰<br>[Query-Chain Focused Summarization.pdf](https://github.com/AkihikoWatanabe/paper_notes/files/1590916/Query-Chain.Focused.Summarization.pdf)<br><br></p>
<p>ä¸Šè¨˜ã‚¹ãƒ©ã‚¤ãƒ‰ã¯ç§ãŒå½“æ™‚ä½œæˆã—ãŸè«–æ–‡ç´¹ä»‹ã‚¹ãƒ©ã‚¤ãƒ‰ã§ã™ã€‚ã‚¹ãƒ©ã‚¤ãƒ‰ä¸­ã®ã‚¹ã‚¯ã‚·ãƒ§ã¯èª¬æ˜ã®ãŸã‚ã«è«–æ–‡ä¸­ã®ã‚‚ã®ã‚’å¼•ç”¨ã—ã¦ã„ã¾ã™ã€‚</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/MatrixFactorization.html" target="_blank" rel="noopener noreferrer">#MatrixFactorization</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/224" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Deep content-based music recommendation, Oord+, NIPS'13</a>
<span class="snippet"><span>Comment</span><p>Contents-BasedãªéŸ³æ¥½æ¨è–¦æ‰‹æ³•(cold-start problemã«å¼·ã„)ã€‚<br><br>Weighted Matrix Factorization (WMF) (Implicit Feedbackã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ã«ç‰¹åŒ–ã—ãŸMatrix Factorizationæ‰‹æ³•) <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/225" target="_blank" rel="noopener noreferrer">[Paper Note] Collaborative filtering for implicit feedback datasets, Hu+, International Conference on Data Mining, 2008</a>
 ã«ã€Convolutional Neural Networkã«ã‚ˆã‚‹music audioã®latent vectorã®æƒ…å ±ãŒçµ„ã¿è¾¼ã¾ã‚Œã€item vectorãŒå­¦ç¿’ã•ã‚Œã‚‹ã‚ˆã†ãªä»•çµ„ã¿ã«ãªã£ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34815522-01679f0e-f6f5-11e7-8534-22e5b5edd7a6.png" alt="image" loading="lazy"><br><br><br><br>CNNã§music audioã®representationã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã¯ã€audioã®time-frequencyã®æƒ…å ±ã‚’inputã¨ã™ã‚‹ã€‚å­¦ç¿’ã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã«ã€windowå¹…ã‚’3ç§’ã«è¨­å®šã—music clipã‚’ã‚µãƒ³ãƒ—ãƒ«ã—inputã™ã‚‹ã€‚music clipå…¨ä½“ã®representationã‚’æ±‚ã‚ã‚‹éš›ã«ã¯ã€consecutive windowã‹ã‚‰predictionã—ãŸrepresentationã‚’å¹³å‡ã—ãŸã‚‚ã®ã‚’ä½¿ç”¨ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="articles/ImageClassification.html" target="_blank" rel="noopener noreferrer">#ImageClassification</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2025-05-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1958" target="_blank" rel="noopener noreferrer" class="title-link">ImageNet Classification with Deep Convolutional Neural Networks, Krizhevsky+, NIPS'12</a>
<span class="snippet"><span>Comment</span><p>ILSVRC 2012ã«ãŠã„ã¦åœ§å€’çš„ãªæ€§èƒ½ç¤ºã—ãŸã“ã¨ã§ç¾ä»£ã®DeepLearningã®ç«ä»˜ã‘å½¹ã¨ãªã£ãŸç ”ç©¶AlexNetã€‚ãƒ¡ãƒ¢ã£ã¦ãªã‹ã£ãŸã®ã§ä»Šæ›´ãªãŒã‚‰è¿½åŠ ã—ãŸã€‚</p>
<p>AlexNetä»¥å‰ã®ç”»åƒèªè­˜æŠ€è¡“ã«ã¤ã„ã¦ã¯ç‰›ä¹…å…ˆç”ŸãŒã¾ã¨ã‚ã¦ãã ã•ã£ã¦ã„ã‚‹ï¼ˆå½“æ™‚ã®èª²é¡Œã¨ãã‚Œã«å¯¾ã™ã‚‹è§£æ±ºæ³•ã€ã—ã‹ã—ã¾ã èª²é¡ŒãŒâ€¦ã¨æ¬¡ã€…ã¨èª²é¡Œã«ç›´é¢ã—è§£æ±ºã—ã¦ã„ãæ§˜å­ãŒæã‹ã‚Œã¦ãŠã‚Šéå¸¸ã«èˆˆå‘³æ·±ã‹ã£ãŸ)ã€‚ç¾åœ¨ã§ã‚‚æ®‹ã£ã¦ã„ã‚‹æŠ€è¡“ã‚‚ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹ã€‚:<br>


<a href="https://speakerdeck.com/yushiku/pre_alexnet" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/yushiku/pre_alexnet</a>


<br><br>&gt; éå»ã®æŠ€è¡“ã ã‹ã‚‰ã¨ã„ã£ã¦èãæµã—ã¦ã„ã‚‹ã¨æ™‚ä»£èƒŒæ™¯ã®å¤‰åŒ–ã«ã‚ˆã£ã¦ãªã—å¾—ãŸã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é€ƒã™ã‹ã‚‚<br><br>ã“ã‚Œã¯è‚ã«éŠ˜ã˜ãŸã„ã€‚</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/MatrixFactorization.html" target="_blank" rel="noopener noreferrer">#MatrixFactorization</a>
<a class="button" href="articles/SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/226" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Collaborative topic modeling for recommending scientific articles, Wang+, KDD'11</a>
<span class="snippet"><span>Comment</span><p>Probabilistic Matrix Factorization (PMF) <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/227" target="_blank" rel="noopener noreferrer">[Paper Note] Probabilistic Matrix Factorization, Salakhutdinov+, NIPS'08</a>
 ã«ã€Latent Dirichllet Allocation (LDA) ã‚’çµ„ã¿è¾¼ã‚“ã Collaborative Topic Regression (CTR)ã‚’ææ¡ˆã€‚<br><br>LDAã«ã‚ˆã‚Šitemã®latent vectorã‚’æ±‚ã‚ã€ã“ã®item vectorã¨ã€user vectorã®å†…ç©ã‚’ï¼ˆå¹³å‡å€¤ã¨ã—ã¦æŒã¤æ­£è¦è¡¨ç¾ã‹ã‚‰ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰ç”¨ã„ã¦ratingã‚’ç”Ÿæˆã™ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34816213-9e21a07c-f6f7-11e7-8310-3cb55c45c71d.png" alt="image" loading="lazy"><br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34816387-1a4b1a02-f6f8-11e7-8000-f74af099bc6f.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/34816394-1f981122-f6f8-11e7-80c8-4941f2a6c191.png" alt="image" loading="lazy"><br><br></p>
<p>CFã¨Contents-basedãªæ‰‹æ³•ãŒåŒæ–¹å‘ã«interationã™ã‚‹ã‚ˆã†ãªæ‰‹æ³•</p>
<p>è§£èª¬ãƒ–ãƒ­ã‚°ï¼š


<a href="http://d.hatena.ne.jp/repose/20150531/1433004688" target="_blank" rel="noopener noreferrer">http://d.hatena.ne.jp/repose/20150531/1433004688</a>


</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/159" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Collaborative Filtering Recommender Systems, Ekstrand+ ï¼ˆwith Joseph A. Konstanï¼‰, Foundations and TrendsR in Humanâ€“Computer Interaction'11</a>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/InteractivePersonalizedSummarization.html" target="_blank" rel="noopener noreferrer">#InteractivePersonalizedSummarization</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Summarize What You Are Interested In: An Optimization Framework for Interactive Personalized Summarization, Yan+, EMNLP'11, 2011.07</a>
<span class="snippet"><span>Comment</span><p><img src="https://user-images.githubusercontent.com/12249301/34400733-97c86614-ebd7-11e7-9fe9-a6b36c726a21.png" alt="image" loading="lazy"><br><br><br><br>ãƒ¦ãƒ¼ã‚¶ã¨ã‚·ã‚¹ãƒ†ãƒ ãŒã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã—ãªãŒã‚‰å€‹äººå‘ã‘ã®è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã€InteractivePersonalizedSummarizationã‚’ææ¡ˆã€‚<br><br><br><br>ãƒ¦ãƒ¼ã‚¶ã¯ãƒ†ã‚­ã‚¹ãƒˆä¸­ã®sentenceã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã“ã¨ã§ã€ã‚·ã‚¹ãƒ†ãƒ ã«çŸ¥ã‚ŠãŸã„æƒ…å ±ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ã“ã®ã¨ãã€ãƒ¦ãƒ¼ã‚¶ãŒsentenceã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹é‡ã¯ãŸã‹ãŒã—ã‚Œã¦ã„ã‚‹ã®ã§ã€click smoothingã¨å‘¼ã°ã‚Œã‚‹æ‰‹æ³•ã‚’ææ¡ˆã—ã€sparseã«ãªã‚‰ãªã„ã‚ˆã†ã«ã—ã¦ã„ã‚‹ã€‚click smoothingã¯ã€ãƒ¦ãƒ¼ã‚¶ãŒã‚¯ãƒªãƒƒã‚¯ã—ãŸsentenceã«å«ã¾ã‚Œã‚‹å˜èªï¼Ÿç­‰ã‚’å«ã‚€åˆ¥ã®sentenceç­‰ã‚‚æ“¬ä¼¼çš„ã«clickã•ã‚ŒãŸã¨ã¿ãªã™æ‰‹æ³•ã€‚<br><br><br><br>4ã¤ã®ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆInfluenza A, BP Oil Spill, Haiti Earthquake, Jackson Deathï¼‰ã«é–¢ã™ã‚‹ã€æ•°åƒè¨˜äº‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’åé›†ã—ï¼ˆ10kã€œ100kç¨‹åº¦ã®sentenceï¼‰ã€è©•ä¾¡ã«æ´»ç”¨ã€‚åé›†ã—ãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚µã‚¤ãƒˆï¼ˆBBC, Fox News, Xinhua, MSNBC, CNN, Guardian, ABC, NEwYorkTimes, Reuters, Washington Postï¼‰ã«ã¯ã€å„ã‚¤ãƒ™ãƒ³ãƒˆã«å¯¾ã™ã‚‹äººæ‰‹ã§ä½œæˆã•ã‚ŒãŸReference SummaryãŒã‚ã‚‹ã®ã§ãã‚Œã‚’æ´»ç”¨ã€‚<br><br>objectiveãªè©•ä¾¡ã¨ã—ã¦ROUGEã€subjectiveãªè©•ä¾¡ã¨ã—ã¦3äººã®evaluatorã«5scaleã§è¦ç´„ã®è‰¯ã•ã‚’è©•ä¾¡ã—ã¦ã‚‚ã‚‰ã£ãŸã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34400727-8c8ab022-ebd7-11e7-85df-c238fd2255de.png" alt="image" loading="lazy"><br><br><br><br>çµè«–ã¨ã—ã¦ã¯ã€ROUGEã¯GenericãªMDSãƒ¢ãƒ‡ãƒ«ã«å‹ã¦ãªã„ãŒã€subjectiveãªè©•ä¾¡ã«ãŠã„ã¦ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã‚‹çµæœã«ã€‚Referenceã¯Genericã«ç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ã“ã®çµæœã‚’å—ã‘ã¦Personalizationã®å¿…è¦æ€§ã‚’èª¬ã„ã¦ã„ã‚‹ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/34400721-82d1bb8e-ebd7-11e7-83d2-697ac61eb38a.png" alt="image" loading="lazy"><br><br><br><br>ã¾ãŸã€ææ¡ˆæ‰‹æ³•ã®ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€Genericãªãƒ¢ãƒ‡ãƒ«ã®å½±éŸ¿ã‚’å¼·ãã™ã‚‹ï¼ˆPersonalizedãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å°ã•ãã™ã‚‹ï¼‰ã¨ã€ãƒ¦ãƒ¼ã‚¶ã¯ã‚·ã‚¹ãƒ†ãƒ ã¨ã‚ã¾ã‚Šã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã›ãšã«çµ‚ã‚ã£ã¦ã—ã¾ã†ã®ã«å¯¾ã—ã€Personalizedãªè¦ç´ ã‚’å¼·ãã™ã‚‹ã¨ã€ã‚ˆã‚ŠãŸãã•ã‚“ã‚¯ãƒªãƒƒã‚¯ã‚’ã—ã€çµæœçš„ã«ã‚·ã‚¹ãƒ†ãƒ ãŒã‚ˆã‚Šå¤šãè¦ç´„ã‚’ç”Ÿæˆã—ãªãŠã™ã¨ã„ã†çµæœã‚‚ç¤ºã—ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34400718-7b9a4912-ebd7-11e7-83cf-aba826a41d34.png" alt="image" loading="lazy"></p></span><br><br>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Interspeech.html" target="_blank" rel="noopener noreferrer">#Interspeech</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2862" target="_blank" rel="noopener noreferrer" class="title-link">Recurrent neural network based language model, Mikolov+, Interspeech'10</a>
<span class="snippet"><span>Comment</span><p>RNNè¨€èªãƒ¢ãƒ‡ãƒ«è«–æ–‡</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/FactorizationMachines.html" target="_blank" rel="noopener noreferrer">#FactorizationMachines</a>
<a class="button" href="articles/ICDM.html" target="_blank" rel="noopener noreferrer">#ICDM</a>
<span class="issue_date">Issue Date: 2018-12-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/281" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Factorization Machines, Steffen Rendle, ICDM'10</a>
<span class="snippet"><span>Comment</span><p>è§£èª¬ãƒ–ãƒ­ã‚°ï¼š


<a href="http://echizen-tm.hatenablog.com/entry/2016/09/11/024828" target="_blank" rel="noopener noreferrer">http://echizen-tm.hatenablog.com/entry/2016/09/11/024828</a>


<br><br>DeepFMã«é–¢ã™ã‚‹å‹•å‘ï¼š


<a href="https://data.gunosy.io/entry/deep-factorization-machines-2018" target="_blank" rel="noopener noreferrer">https://data.gunosy.io/entry/deep-factorization-machines-2018</a>


</p>
<p>ä¸Šè¨˜è§£èª¬ãƒ–ãƒ­ã‚°ã®æ¦‚è¦ãŒéå¸¸ã«å®Œçµã§ã‚ã‹ã‚Šã‚„ã™ã„</p>
<p><img src="https://user-images.githubusercontent.com/12249301/50376518-fdfedf00-0650-11e9-99c0-060f286de392.png" alt="image" loading="lazy"><br><br><br><br>FMã®Feature Vectorã®Example<br><br>å„featureã”ã¨ã«latent vectorãŒå­¦ç¿’ã•ã‚Œã€featureã®çµ„ã¿åˆã‚ã›ã®weightãŒå†…ç©ã«ã‚ˆã£ã¦è¡¨ç¾ã•ã‚Œã‚‹<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/50376536-53d38700-0651-11e9-830d-28bc32b3c02d.png" alt="image" loading="lazy"><br><br><br><br>Matrix Factorizationã®ä¸€èˆ¬å½¢ã®ã‚ˆã†ãªå½¢å¼</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/171" target="_blank" rel="noopener noreferrer" class="title-link">Content-based Recommender Systems: State of the Art and Trends, Lops+, Recommender Systems Handbook'10</a>
<span class="snippet"><span>Comment</span><p>RecSysã®å†…å®¹ãƒ™ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¦ãƒ¼ã‚¶ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã‘ã‚Œã°ã“ã‚Œ</p></span><br><br>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/ImageClassification.html" target="_blank" rel="noopener noreferrer">#ImageClassification</a>
<a class="button" href="articles/ObjectRecognition.html" target="_blank" rel="noopener noreferrer">#ObjectRecognition</a>
<a class="button" href="articles/ObjectLocalization.html" target="_blank" rel="noopener noreferrer">#ObjectLocalization</a>
<span class="issue_date">Issue Date: 2025-05-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1959" target="_blank" rel="noopener noreferrer" class="title-link">ImageNet: A Large-Scale Hierarchical Image Database, Deng+, CVPR'09</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/LearningToRank.html" target="_blank" rel="noopener noreferrer">#LearningToRank</a>
<a class="button" href="articles/ImplicitFeedback.html" target="_blank" rel="noopener noreferrer">#ImplicitFeedback</a>
<a class="button" href="articles/UAI.html" target="_blank" rel="noopener noreferrer">#UAI</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/28" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] BPR: Bayesian Personalized Ranking from Implicit Feedback, Rendle+, UAI'09, 2009.06</a>
<span class="snippet"><span>Comment</span><p>é‡è¦è«–æ–‡<br><br>ãƒ¦ãƒ¼ã‚¶ã®ã‚¢ã‚¤ãƒ†ãƒ ã«å¯¾ã™ã‚‹Explicit/Implicit Ratingã‚’åˆ©ç”¨ã—ãŸlearning2rankã€‚<br><br>AUCã‚’æœ€é©åŒ–ã™ã‚‹ã‚ˆã†ãªã‚¤ãƒ¡ãƒ¼ã‚¸ã€‚<br><br>è² ä¾‹ã¯Negative Samplingã€‚<br><br>è¨ˆç®—é‡ãŒè»½ãã€æ‹¡å¼µãŒã—ã‚„ã™ã„ã€‚<br><br><br><br>Implicitãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸTop-N Recsysã‚’æ§‹ç¯‰ã™ã‚‹éš›ã«ã¯æ¤œè¨ã—ã¦ã‚‚è‰¯ã„ã€‚<br><br>ã¾ãŸã€MFã®ã¿ãªã‚‰ãšã€Item-Based KNNã«æ´»ç”¨ã™ã‚‹ã“ã¨ãªã©ã‚‚å¯èƒ½ã€‚<br><br><br><br>


<a href="http://tech.vasily.jp/entry/2016/07/01/134825" target="_blank" rel="noopener noreferrer">http://tech.vasily.jp/entry/2016/07/01/134825</a>


</p>
<p>å‚è€ƒ: 


<a href="https://techblog.zozo.com/entry/2016/07/01/134825" target="_blank" rel="noopener noreferrer">https://techblog.zozo.com/entry/2016/07/01/134825</a>


</p>
<p>pytorchã§ã®BPRå®Ÿè£…: 


<a href="https://github.com/guoyang9/BPR-pytorch" target="_blank" rel="noopener noreferrer">https://github.com/guoyang9/BPR-pytorch</a>


</p></span><br><br>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultitaskLearning.html" target="_blank" rel="noopener noreferrer">#MultitaskLearning</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2018-02-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/250" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A unified architecture for natural language processing: Deep neural networks with multitask learning, Collobert+, ICML'08</a>
<span class="snippet"><span>Comment</span><p>Deep Neural Netã‚’ç”¨ã„ã¦multitask learningã‚’è¡Œã„NLPã‚¿ã‚¹ã‚¯ï¼ˆPOS tagging, Semantic Role Labeling, Chunking etc.ï¼‰ã‚’è§£ã„ãŸè«–æ–‡ã€‚<br><br>è¢«å¼•ç”¨æ•°2000ã‚’è¶…ãˆã‚‹ã€‚<br><br><br><br>multitask learningã®å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ãªã©ãŒå¼•ç”¨ã•ã‚ŒãªãŒã‚‰ä»–è«–æ–‡ã§è¨€åŠã•ã‚Œã¦ã„ãŸã‚Šã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/MatrixFactorization.html" target="_blank" rel="noopener noreferrer">#MatrixFactorization</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/227" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Probabilistic Matrix Factorization, Salakhutdinov+, NIPS'08</a>
<span class="snippet"><span>Comment</span><p>Matrix Factorizationã‚’ç¢ºç‡ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦è¡¨ã—ãŸè«–æ–‡ã€‚<br><br>è§£èª¬ï¼š


<a href="http://yamaguchiyuto.hatenablog.com/entry/2017/07/13/080000" target="_blank" rel="noopener noreferrer">http://yamaguchiyuto.hatenablog.com/entry/2017/07/13/080000</a>


<br><br></p>
<p>æ—¢å­˜ã®MFã¯å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã‚¹ã‚±ãƒ¼ãƒ«ã—ãªã‹ã£ãŸãŒã€PMFã§ã¯observationã®æ•°ã«å¯¾ã—ã¦ç·šå½¢ã«ã‚¹ã‚±ãƒ¼ãƒ«ã—ã€ã•ã‚‰ã«ã¯ã€large, sparse, imbalancedãªNetflix datasetã§è‰¯ã„æ€§èƒ½ãŒå‡ºãŸï¼ˆNetflixãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€ratingä»¶æ•°ãŒå°‘ãªã„ãƒ¦ãƒ¼ã‚¶ã¨ã‹ã‚‚å«ã‚“ã§ã„ã‚‹ã€‚MovieLensã¨ã‹ã¯å«ã¾ã‚Œã¦ã„ãªã„ã®ã§ã‚ˆã‚Šç¾å®Ÿçš„ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼‰ã€‚<br><br><img src="https://user-images.githubusercontent.com/12249301/34817061-30757582-f6fa-11e7-90fb-ad5e5fc65781.png" alt="image" loading="lazy"><br><br><br><br>ã¾ãŸã€Constrained PMFï¼ˆåŒã˜ã‚ˆã†ãªsetã®æ˜ ç”»ã«rateã—ã¦ã„ã‚‹ãƒ¦ãƒ¼ã‚¶ã¯ä¼¼ã¦ã„ã‚‹ã¨ã„ã£ãŸä»®å®šã«åŸºã¥ã„ãŸãƒ¢ãƒ‡ãƒ« â€»1ï¼‰ã‚’ç”¨ã„ã‚‹ã¨ã€å°‘ãªã„ratingã—ã‹ãªã„ãƒ¦ãƒ¼ã‚¶ã«å¯¾ã—ã¦ã‚‚è‰¯ã„æ€§èƒ½ãŒå‡ºãŸã€‚<br><br><br><br>â€»1ã€€ratingã®å°‘ãªã„ãƒ¦ãƒ¼ã‚¶ã®æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«ã¯å¹³å‡ã‹ã‚‰å‹•ãã«ãã„ã€ã¤ã¾ã‚Šãªã‚“ã®ç‰¹å¾´ã‚‚ãªã„å¹³å‡çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ™ã‚¯ãƒˆãƒ«ã«ãªã£ã¦ã—ã¾ã†ã®ã§ã€åŒã˜æ˜ ç”»ã‚’ratingã—ãŸäººã¯ä¼¼ãŸäº‹å‰åˆ†å¸ƒã‚’æŒã¤ã‚ˆã†ã«åˆ¶ç´„ã‚’å°å…¥ã—ãŸãƒ¢ãƒ‡ãƒ«<br><br><br><br>ï¼ˆè§£èª¬ãƒ–ãƒ­ã‚°ã€è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ã‚ˆã‚Šï¼‰</p></span><br><br>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-12-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1609" target="_blank" rel="noopener noreferrer" class="title-link">Large Language Models in Machine Translation, Brants+, EMNLP-CoNLL'07</a>
<span class="snippet"><span>GPT Summary</span>- æœ¬è«–æ–‡ã§ã¯ã€æ©Ÿæ¢°ç¿»è¨³ã«ãŠã‘ã‚‹å¤§è¦æ¨¡ãªçµ±è¨ˆçš„è¨€èªãƒ¢ãƒ‡ãƒ«ã®åˆ©ç‚¹ã‚’å ±å‘Šã—ã€æœ€å¤§2å…†ãƒˆãƒ¼ã‚¯ãƒ³ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸ3000å„„n-gramã®ãƒ¢ãƒ‡ãƒ«ã‚’ææ¡ˆã€‚æ–°ã—ã„ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°æ‰‹æ³•ã€ŒStupid Backoffã€ã‚’å°å…¥ã—ã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®‰ä¾¡ã§ã€Kneser-Neyã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã«è¿‘ã¥ãã“ã¨ã‚’ç¤ºã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>N-gramè¨€èªãƒ¢ãƒ‡ãƒ«+ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã®æ‰‹æ³•ã«ãŠã„ã¦ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã—ã¦æ‰±ãˆã‚‹ngramã®ã‚¿ã‚¤ãƒ—æ•°ï¼ˆä»Šã§è¨€ã†ã¨ã“ã‚ã®vocabæ•°ã«è¿‘ã„ï¼‰ã‚’å¢—ã‚„ã—ã¦ã„ã£ãŸã‚‰ã€perplexityã¯æ”¹å–„ã™ã‚‹ã—ã€MTã«ãŠã‘ã‚‹BLEUã‚¹ã‚³ã‚¢ã‚‚æ”¹å–„ã™ã‚‹ã‚ˆï¼ˆBLEUã¯ã‚µãƒã£ã¦ã‚‹ã‹ã‚‚ï¼Ÿï¼‰ã¨ã„ã†è€ƒå¯ŸãŒã•ã‚Œã¦ã„ã‚‹<br><br><img src="https://github.com/user-attachments/assets/035f28db-12c6-4b69-b39f-7eb41581d00c" alt="image" loading="lazy"></p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1871024428739604777?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Large Language Modelsã¨ã„ã†ç”¨èªãŒåˆ©ç”¨ã•ã‚ŒãŸã®ã¯ã“ã®ç ”ç©¶ãŒåˆã‚ã¦ãªã®ã‹ã‚‚â€¦ï¼Ÿ</p></span><br><br>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/IntegerLinearProgramming%20(ILP).html" target="_blank" rel="noopener noreferrer">#IntegerLinearProgramming (ILP)</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/ECIR.html" target="_blank" rel="noopener noreferrer">#ECIR</a>
<span class="issue_date">Issue Date: 2018-01-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/241" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A study of global inference algorithms in multi-document summarization, Ryan McDonald, ECIR'07</a>
<span class="snippet"><span>Comment</span><p>æ–‡æ›¸è¦ç´„ã‚’ãƒŠãƒƒãƒ—ã‚µãƒƒã‚¯å•é¡Œã¨ã—ã¦å®šå¼åŒ–ã—ã€å³å¯†è§£ï¼ˆå‹•çš„è¨ˆç”»æ³•ã€ILP Formulationï¼‰ã€è¿‘ä¼¼è§£(Greedy)ã‚’æ±‚ã‚ã‚‹æ‰‹æ³•ã‚’ææ¡ˆã€‚</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/LearningToRank.html" target="_blank" rel="noopener noreferrer">#LearningToRank</a>
<a class="button" href="articles/ListWise.html" target="_blank" rel="noopener noreferrer">#ListWise</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/193" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning to Rank: From Pairwise Approach to Listwise Approach ï¼ˆListNetï¼‰, Cao+, ICML'07</a>
<span class="snippet"><span>Comment</span><p>è§£èª¬ã‚¹ãƒ©ã‚¤ãƒ‰ï¼š


<a href="http://www.nactem.ac.uk/tsujii/T-FaNT2/T-FaNT.files/Slides/liu.pdf" target="_blank" rel="noopener noreferrer">http://www.nactem.ac.uk/tsujii/T-FaNT2/T-FaNT.files/Slides/liu.pdf</a>


<br><br>è§£èª¬ãƒ–ãƒ­ã‚°ï¼š


<a href="https://qiita.com/koreyou/items/a69750696fd0b9d88608" target="_blank" rel="noopener noreferrer">https://qiita.com/koreyou/items/a69750696fd0b9d88608</a>


</p>
<p>å¾“æ¥è¡Œã‚ã‚Œã¦ããŸLearning to Rankã¯pairwiseãªæ‰‹æ³•ãŒä¸»æµã§ã‚ã£ãŸãŒã€pairwiseãªæ‰‹æ³•ã¯2ã¤ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹é–“ã®é †åºãŒæ­£ã—ãè­˜åˆ¥ã•ã‚Œã‚‹ã‚ˆã†ã«å­¦ç¿’ã•ã‚Œã¦ã„ã‚‹ã ã‘ã§ã‚ã£ãŸã€‚<br><br>pairwiseãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ã¯ä»¥ä¸‹ã®å•é¡Œç‚¹ãŒã‚ã£ãŸï¼š<br><br><br><br>* ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ãƒšã‚¢ã®classification errorã‚’æœ€å°åŒ–ã—ã¦ã„ã‚‹ã ã‘ã§ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®errorã‚’æœ€å°åŒ–ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªã„ã€‚<br><br>* ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒšã‚¢ãŒ i.i.d ãªåˆ†å¸ƒã‹ã‚‰ç”Ÿæˆã•ã‚Œã‚‹ã¨ã„ã†åˆ¶ç´„ã¯å¼·ã™ãã‚‹åˆ¶ç´„<br><br>* queryã”ã¨ã«ç”Ÿæˆã•ã‚Œã‚‹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒšã‚¢ã¯å¤§ããç•°ãªã‚‹ã®ã§ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒšã‚¢ã‚ˆã‚Šã‚‚ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ãƒã‚¤ã‚¢ã‚¹ã®ã‹ã‹ã£ãŸå­¦ç¿’ã®ã•ã‚Œæ–¹ãŒã•ã‚Œã¦ã—ã¾ã†<br><br><br><br>ã“ã‚Œã‚‰ã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€listwiseãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã€‚<br><br>listwiseãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç”¨ã„ã‚‹ã¨ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ãƒšã‚¢ã®é †åºã‚’æœ€é©åŒ–ã™ã‚‹ã®ã§ã¯ãªãã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°å…¨ä½“ã‚’æœ€é©åŒ–ã§ãã‚‹ã€‚<br><br>listwiseãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç”¨ã„ã‚‹ãŸã‚ã«ã€Permutation Probabilityã«åŸºã¥ãloss functionã‚’ææ¡ˆã€‚loss functionã¯ã€2ã¤ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã‚¹ã‚³ã‚¢ã®ãƒªã‚¹ãƒˆãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€Permutation Probability Distributionã‚’è¨ˆç®—ã—ã€ã“ã‚Œã‚‰ã‚’ç”¨ã„ã¦cross-entropy lossã‚’è¨ˆç®—ã™ã‚‹ã‚ˆã†ãªã‚‚ã®ã€‚<br><br>ã¾ãŸã€Permutation Probabilityã‚’è¨ˆç®—ã™ã‚‹ã®ã¯è¨ˆç®—é‡ãŒå¤šã™ãã‚‹ã®ã§ã€top-k probabilityã‚’ææ¡ˆã€‚<br><br>top-k probabilityã¯Permutation Probabilityã®è¨ˆç®—ã‚’è¡Œã†éš›ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’top-kã«é™å®šã™ã‚‹ã‚‚ã®ã€‚<br><br>è«–æ–‡ä¸­ã§ã¯k=1ã‚’æ¡ç”¨ã—ã¦ãŠã‚Šã€k=1ã¯softmaxã¨ä¸€è‡´ã™ã‚‹ã€‚<br><br>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã™ã‚‹éš›ã¯ã€Gradient Descentã‚’ç”¨ã„ã‚‹ã€‚</p>
<p>k=1ã®è¨­å®šã§è¨ˆç®—ã™ã‚‹ã®ãŒæ™®é€šãªã‚ˆã†ãªã®ã§ã€æ™®é€šã«outputãŒsoftmaxã§lossãŒsoftmax cross-entropyãªãƒ¢ãƒ‡ãƒ«ã¨ã»ã¼ç­‰ä¾¡ãªã®ã§ã¯ã€‚</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/162" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Survey of Explanations in Recommender Systems, Tintarev+, ICDEW'07</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/MatrixFactorization.html" target="_blank" rel="noopener noreferrer">#MatrixFactorization</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/161" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Matrix Factorization Techniques for Recommender Systems, Koren+, Computer'07</a>
<span class="snippet"><span>Comment</span><p>Matrix Factorizationã«ã¤ã„ã¦ã‚ˆãã¾ã¨ã¾ã£ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/DomainAdaptation.html" target="_blank" rel="noopener noreferrer">#DomainAdaptation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/126" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Frustratingly easy domain adaptation, Daum'e, ACL'07</a>
<span class="snippet"><span>Comment</span><p><img src="https://user-images.githubusercontent.com/12249301/34462211-f3428130-ee81-11e7-8a06-36e66bd19b2f.png" alt="image" loading="lazy"><br><br><br><br>domain adaptationã‚’ã™ã‚‹éš›ã«ã€Sourceå´ã®Featureã¨Targetå´ã®Featureã‚’ä¸Šå¼ã®ã‚ˆã†ã«ã€Feature Vectorã‚’æ‹¡å¼µã—ç‹¬ç«‹ã«ã‚³ãƒ”ãƒ¼ã—è¡¨ç¾ã™ã‚‹ã ã‘ã§ã€ãŠæ‰‹è»½ã«domain adaptationãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸè«–æ–‡ã€‚<br><br><br><br>ã‚¤ãƒ¡ãƒ¼ã‚¸çš„ã«ã¯ã€Sourceã¨Targetã€ä¸¡æ–¹ã«å­˜åœ¨ã™ã‚‹ç‰¹å¾´ã¯ã€å…±é€šéƒ¨åˆ†ã®é‡ã¿ãŒé«˜ããªã‚Šã€Source, Targetãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®ç‰¹å¾´ã¯ã€ãã‚Œãã‚Œæ‹¡å¼µã—ãŸéƒ¨åˆ†ã®Featureã«é‡ã¿ãŒå…¥ã‚‹ã‚ˆã†ãªæ„Ÿã˜ã€‚</p></span><br><br>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/DataToTextGeneration.html" target="_blank" rel="noopener noreferrer">#DataToTextGeneration</a>
<a class="button" href="articles/ConceptToTextGeneration.html" target="_blank" rel="noopener noreferrer">#ConceptToTextGeneration</a>
<span class="issue_date">Issue Date: 2017-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/85" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] An Architecture for Data to Text Systems, Ehud Reiter, ENLG'07</a>
<span class="snippet"><span>Comment</span><p>NLGåˆ†é‡ã§æœ‰åãªReiterã‚‰ã®Surveyã€‚<br>NLGã‚·ã‚¹ãƒ†ãƒ ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãªã©ãŒã€ä½“ç³»çš„ã«èª¬æ˜ã•ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/LearningToRank.html" target="_blank" rel="noopener noreferrer">#LearningToRank</a>
<a class="button" href="articles/PairWise.html" target="_blank" rel="noopener noreferrer">#PairWise</a>
<a class="button" href="articles/ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/192" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Learning to Rank using Gradient Descent ï¼ˆRankNetï¼‰, Burges+, ICML'05</a>
<span class="snippet"><span>Comment</span><p>pair-wiseã®learning2rankã§ä»£è¡¨çš„ãªRankNetè«–æ–‡<br><br>è§£èª¬ãƒ–ãƒ­ã‚°ï¼š


<a href="https://qiita.com/sz_dr/items/0e50120318527a928407" target="_blank" rel="noopener noreferrer">https://qiita.com/sz_dr/items/0e50120318527a928407</a>


<br><br><br><br>lossã¯2å€‹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®pairã€A, BãŒä¸ãˆã‚‰ã‚ŒãŸã¨ãã€AãŒBã‚ˆã‚Šã‚‚é«˜ããƒ©ãƒ³ã‚¯ã•ã‚Œã‚‹å ´åˆã¯ç¢ºç‡1, AãŒBã‚ˆã‚Šã‚‚ä½ããƒ©ãƒ³ã‚¯ã•ã‚Œã‚‹å ´åˆã¯ç¢ºç‡0ã€ãã†ã§ãªã„å ´åˆã¯1/2ã«è¿‘ããªã‚‹ã‚ˆã†ã«ã€ã‚¹ã‚³ã‚¢é–¢æ•°ã‚’å­¦ç¿’ã™ã‚Œã°è‰¯ã„ã€‚</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/157" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions, Adomavicius+, IEEE Transactions on Knowledge and Data Engineering'05</a>
<span class="snippet"><span>Comment</span><p>æœ‰åãªã‚„ã¤</p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<a class="button" href="articles/EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/214" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] TextRank: Bringing Order into Texts, Mihalcea+, EMNLP'04</a>
<span class="snippet"><span>Comment</span><p>PageRankãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã§ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º/æ–‡æ›¸è¦ç´„ ã‚’è¡Œã†æ‰‹æ³•ã€‚<br><br>ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º/æ–‡æ›¸è¦ç´„ ã‚’è¡Œã†éš›ã«ã¯ã€ãƒãƒ¼ãƒ‰ã‚’ãã‚Œãã‚Œ å˜èª/æ–‡ ã§è¡¨ç¾ã™ã‚‹ã€‚<br><br>ãƒãƒ¼ãƒ‰ã§è¡¨ç¾ã•ã‚Œã¦ã„ã‚‹ å˜èª/æ–‡ ã®similarityã‚’æ¸¬ã‚Šã€ãƒãƒ¼ãƒ‰é–“ã®edgeã®é‡ã¿ã¨ã™ã‚‹ã“ã¨ã§Affinity Graphã‚’æ§‹ç¯‰ã€‚<br><br>ã‚ã¨ã¯æ§‹ç¯‰ã—ãŸAffinity Graphã«å¯¾ã—ã¦PageRankã‚’é©ç”¨ã—ã¦ã€ãƒãƒ¼ãƒ‰ã®é‡è¦åº¦ã‚’æ±‚ã‚ã‚‹ã€‚<br><br>ãƒãƒ¼ãƒ‰ã®é‡è¦åº¦ã«å¾“ã„Greedyã« å˜èª/æ–‡ ã‚’æŠ½å‡ºã™ã‚Œã°ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º/æ–‡æ›¸è¦ç´„ ã‚’è¡Œã†ã“ã¨ãŒã§ãã‚‹ã€‚</p>
<p>å˜ä¸€æ–‡æ›¸è¦ç´„ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã—ã¦ä½¿ãˆã‚‹ã€‚</p>
<p>gensimã«å®Ÿè£…ãŒã‚ã‚‹ã€‚<br><br>å€‹äººçš„ã«ã‚‚å®Ÿè£…ã—ã¦ã„ã‚‹ï¼šhttps://github.com/AkihikoWatanabe/textrank</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/158" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Evaluating Collaborative Filtering Recommener Systems, Herlocker+, TOIS'04</a>
<span class="snippet"><span>Comment</span><p>GroupLensã®Survey</p></span><br><br>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/LearningToRank.html" target="_blank" rel="noopener noreferrer">#LearningToRank</a>
<a class="button" href="articles/PointWise.html" target="_blank" rel="noopener noreferrer">#PointWise</a>
<a class="button" href="articles/NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/190" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] PRanking with Ranking, Crammer+, NIPS'01</a>
<span class="snippet"><span>Comment</span><p>Point-WiseãªLearning2Rankã®æœ‰åæ‰‹æ³•</p></span><br><br>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/ItemBased.html" target="_blank" rel="noopener noreferrer">#ItemBased</a>
<a class="button" href="articles/WWW.html" target="_blank" rel="noopener noreferrer">#WWW</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/179" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Item-based collaborative filtering recommendation algorithms, Sarwar+ï¼ˆwith Konstanï¼‰, WWW'01</a>
<span class="snippet"><span>Comment</span><p>ã‚¢ã‚¤ãƒ†ãƒ ãƒ™ãƒ¼ã‚¹ãªå”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ææ¡ˆã—ãŸè«–æ–‡ï¼ˆGroupLensï¼‰</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2018-01-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/246" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Cut and paste based text summarization, Jing+, NAACL'00</a>
<span class="snippet"><span>Comment</span><p>AbstractiveãªSummarizationã®å…ˆé§†ã‘çš„ç ”ç©¶ã€‚<br><br>AbstractiveãªSummarizationã‚’ç ”ç©¶ã™ã‚‹ãªã‚‰ã€æŠ¼ã•ãˆã¦ãŠã„ãŸã»ã†ãŒè‰¯ã„ã€‚</p></span><br><br>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="articles/SIGIR.html" target="_blank" rel="noopener noreferrer">#SIGIR</a>
<span class="issue_date">Issue Date: 2018-01-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/243" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries, Carbonell+, SIGIR'98</a>
<span class="snippet"><span>Comment</span><p>Maximal Marginal Relevance (MMR) è«–æ–‡ã€‚<br><br>æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚„æ–‡æ›¸è¦ç´„ã«ãŠã„ã¦ã€æ–‡æ›¸/æ–‡ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ç”Ÿæˆã™ã‚‹éš›ã«ã€æ—¢ã«é¸ã‚“ã æ–‡æ›¸ã¨é¡ä¼¼åº¦ãŒä½ãã€ã‹ã¤queryã¨relevantãªæ–‡æ›¸ã‚’greedyã«é¸æŠã—ã¦ã„ãæ‰‹æ³•ã‚’ææ¡ˆã€‚<br><br>ILPã«ã‚ˆã‚‹å®šå¼åŒ–ãŒææ¡ˆã•ã‚Œã‚‹ä»¥å‰ã®Multi Document Summarization (MDS) ç ”ç©¶ã«ãŠã„ã¦ã€å†—é•·æ€§ã®æ’é™¤ã‚’è¡Œã†éš›ã«ã¯å…¸å‹çš„ãªæ‰‹æ³•ã€‚</p></span><br><br>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/147" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Automatic condensation of electronic publications by sentence selection, Brandow+, Information Processing &amp; Management'95</a>
<span class="snippet"><span>Comment</span><p>å ±é“è¨˜äº‹è¦ç´„ã«ãŠã„ã¦ã€è‡ªå‹•è¦ç´„ã‚·ã‚¹ãƒ†ãƒ ãŒLeadæ–‡ã«å‹ã¤ã®ãŒhardã ã¨ã„ã†ã“ã¨ã‚’ç¤ºã—ãŸç ”ç©¶</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Infrastructure.html" target="_blank" rel="noopener noreferrer">#Infrastructure</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-10-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3529" target="_blank" rel="noopener noreferrer" class="title-link">The Smol Training Playbook: The Secrets to Building World-Class LLMs, Allal+, HuggingFace, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thom_wolf/status/1984033830924124262?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-10-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3528" target="_blank" rel="noopener noreferrer" class="title-link">Emergent Introspective Awareness in Large Language Models, Jack Lindsey, Anthropic, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1984031672883671315?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/anthropicai/status/1983584136972677319?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2025-10-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3503" target="_blank" rel="noopener noreferrer" class="title-link">Marin 32B Retrospective, marin-community, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1983634964299313481?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/AutomaticSpeechRecognition(ASR).html" target="_blank" rel="noopener noreferrer">#AutomaticSpeechRecognition(ASR)</a>
<a class="button" href="articles/Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/VideoGeneration/Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<a class="button" href="articles/Editing.html" target="_blank" rel="noopener noreferrer">#Editing</a>
<a class="button" href="articles/TTS.html" target="_blank" rel="noopener noreferrer">#TTS</a>
<a class="button" href="articles/Routing.html" target="_blank" rel="noopener noreferrer">#Routing</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<a class="button" href="articles/Omni.html" target="_blank" rel="noopener noreferrer">#Omni</a>
<a class="button" href="articles/Sparse.html" target="_blank" rel="noopener noreferrer">#Sparse</a>
<a class="button" href="articles/ImageSynthesis.html" target="_blank" rel="noopener noreferrer">#ImageSynthesis</a>
<span class="issue_date">Issue Date: 2025-10-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3489" target="_blank" rel="noopener noreferrer" class="title-link">Ming-flash-omni-Preview, inclusionAI, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1982987141773713445?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2300" target="_blank" rel="noopener noreferrer">[Paper Note] Ming-Omni: A Unified Multimodal Model for Perception and Generation, Inclusion AI+, arXiv'25</a>
</p>
<p>éå»ä¸€ç•ªå¤šãã®ã‚¿ã‚°ã‚’ä»˜ä¸ã—ãŸæ°—ãŒã™ã‚‹ãŒã€æœãŸã—ã¦å¤§è¦æ¨¡ã€Omniãƒ¢ãƒ‡ãƒ«ã‹ã¤ã€UMMã«ã—ãŸã“ã¨ã«ã‚ˆã‚‹æ©æµï¼ˆï¼æ§˜ã€…ãªãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’çµ±ä¸€ã•ã‚ŒãŸç©ºé–“ä¸Šã«å­¦ç¿’ã•ã›ã‚‹æ©æµï¼‰ã¯ã©ã®ç¨‹åº¦ã‚ã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ<br><br>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’è¦‹ã‚‹ã¨ã€ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã”ã¨ã«ï¼ˆãƒ¢ãƒ€ãƒªãƒ†ã‚£å˜ä½ã§ã®ãƒã‚¤ã‚¢ã‚¹ãŒã‹ã‹ã£ãŸï¼‰RouterãŒç”¨æ„ã•ã‚Œexpertã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã•ã‚Œã‚‹ã‚ˆã†ãªæ§‹é€ ã«ãªã£ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3454" target="_blank" rel="noopener noreferrer" class="title-link">LMMs Engine, EvolvingLMMs-Lab, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/liuziwei7/status/1982446267646239148?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>äº‹å‰å­¦ç¿’æ¸ˆã¿ã®LLM, VLM, dLM, DiffusionModelãªã©ã‹ã‚‰UMMã‚’å­¦ç¿’ã§ãã‚‹äº‹å¾Œå­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚<br>LigerKernelã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’30%å‰Šæ¸›ã—ã€SparseAttentionã‚‚ã‚µãƒãƒ¼ãƒˆã—ã€Muon Optimizerã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-10-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3442" target="_blank" rel="noopener noreferrer" class="title-link">MiniMax-M2: Intelligence, Performance &amp; Price Analysis, Artificial Analysis, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/skylermiao7/status/1981795750217499123?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3283" target="_blank" rel="noopener noreferrer">[Paper Note] MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning
  Attention, MiniMax+, arXiv'25, 2025.06</a>
<br><br>CISPOã‚’ææ¡ˆã—ãŸMiniMax-M1ã®å¾Œç¶šãƒ¢ãƒ‡ãƒ«ã¨æ€ã‚ã‚Œã‚‹MiniMax-M2-previewãŒä¸­å›½è£½ã®ãƒ¢ãƒ‡ãƒ«ã§Artificial Intelligenceã§ã®è©•ä¾¡ã§ãƒˆãƒƒãƒ—ã«ç«‹ã£ãŸæ¨¡æ§˜ã€‚</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yifan_zhang_/status/1982667098963734602?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ¢ãƒ‡ãƒ«ãŒå…¬é–‹:<br>


<a href="https://huggingface.co/MiniMaxAI/MiniMax-M2" target="_blank" rel="noopener noreferrer">https://huggingface.co/MiniMaxAI/MiniMax-M2</a>


<br><br>proprietaryãƒ¢ãƒ‡ãƒ«ã«ãªã‚‹ã‚‚ã‚“ã ã¨æ€ã£ã¦ãŸã€ã€ã€ã“ã‚Œã‚’å…¬é–‹ã™ã‚‹ã®å‡„ã™ãã§ã¯ã€ã€ã€<br><br>å…¬å¼ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/minimax__ai/status/1982674798649160175?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹</p>
<p>vLLMã§ã®servingæ–¹æ³•:<br>


<a href="https://docs.vllm.ai/projects/recipes/en/latest/MiniMax/MiniMax-M2.html" target="_blank" rel="noopener noreferrer">https://docs.vllm.ai/projects/recipes/en/latest/MiniMax/MiniMax-M2.html</a>


<br><br>&gt; You can use 4x H200/H20 or 4x A100/A800 GPUs to launch this model.<br><br>ä¸Šè¨˜GPUã«ãŠã„ã¦ã¯--tensor-parallel-size 4ã§å‹•ä½œã™ã‚‹æ¨¡æ§˜ã€‚</p>
<p>SGLangã§ã‚‚ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lmsysorg/status/1982677819688927333?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Anthropicã®APIã®åˆ©ç”¨ã‚’ãŠå‹§ã‚ã™ã‚‹ç†ç”±:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/skylermiao7/status/1982989507252367687?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ï¼ˆä»¥ä¸‹ç®¡ç†äººã®è£œè¶³ã‚’å«ã¿ã¾ã™ï¼‰MiniMax-M2ã¯AgenticãªCoTã‚’ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ãªã®ã§ã€contextã®æƒ…å ±ã‚’æ­£ã—ãä¿æŒã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ç‰¹ã«ã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®ã‚„ã‚Šå–ã‚Šã‚’APIã‚’ä»‹ã—ã¦ãƒ¦ãƒ¼ã‚¶ãŒå®Ÿè¡Œã™ã‚‹å ´åˆã€OpenAIã®chatcompletionã¯CoTã‚’è¿”ã—ã¦ãã‚Œãšã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®ã‚„ã‚Šå–ã‚Šã‚’ã—ã¦ã‚‚åŒã˜sessionã§åˆ©ç”¨ã—ãŸã¨ã—ã¦ã‚‚ã€å‰ã®ã‚¿ãƒ¼ãƒ³ã¨åŒã˜CoTãŒåˆ©ç”¨ã•ã‚Œãªã„ã“ã¨ãŒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã€‚ã“ã®ã‚ˆã†ãªä½¿ã„æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã®ã¯ResponceAPIã®ã¿ã§ã‚ã‚‹ãŸã‚ã€ResponceAPIã§ã®ã¿é©åˆ‡ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒé”æˆã•ã‚Œã‚‹ã€‚ã“ã®ç‚¹ãŒconfusingãªã®ã§ã€èª¤ã£ãŸä½¿ã„æ–¹ã‚’ã™ã‚‹ã¨MiniMaxã®çœŸä¾¡ãŒç™ºæ®ã•ã‚Œãšã€ã—ã‹ã‚‚ãã‚Œã«æ°—ã¥ã‘ãšã«ä½¿ã„ç¶šã‘ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚Anthropicã®APIã§ã¯Sonnet 4.5ã§ã¯å…¨ã¦ã®å¿œç­”ã«æ˜ç¤ºçš„ã«CoTãŒå«ã¾ã‚Œã‚‹ãŸã‚ã€ãã®å¿ƒé…ãŒãªã„ã€ã ã‹ã‚‰AnthropicãŒãŠã™ã™ã‚ã€ã¿ãŸã„ãªè©±ã ã¨æ€ã‚ã‚Œã‚‹ã€‚<p>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1983212569885122670?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1983627738209775803?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Standardization.html" target="_blank" rel="noopener noreferrer">#Standardization</a>
<span class="issue_date">Issue Date: 2025-10-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3434" target="_blank" rel="noopener noreferrer" class="title-link">Building the Open Agent Ecosystem Together: Introducing OpenEnv, openenv, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_lewtun/status/1981380372748521929?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å­¦ç¿’ã€é‹ç”¨ã™ã‚‹ãŸã‚ã®environmentã‚’æ¨™æº–åŒ–ã—ã€å…±æœ‰å¯èƒ½ã«ã™ã‚‹å–ã‚Šçµ„ã¿ã€‚Meta PyTorchã¨HFã®å…±åŒã€‚<br><br>æ¨™æº–åŒ–:<br>- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚³ã‚¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆEnvironment,Task, Agentãªã©ï¼‰: 


<a href="https://github.com/meta-pytorch/OpenEnv/blob/main/rfcs/001-abstractions.md" target="_blank" rel="noopener noreferrer">https://github.com/meta-pytorch/OpenEnv/blob/main/rfcs/001-abstractions.md</a>


<br>- ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ç­‰: 


<a href="https://github.com/meta-pytorch/OpenEnv/blob/main/rfcs/002-env-spec.md" target="_blank" rel="noopener noreferrer">https://github.com/meta-pytorch/OpenEnv/blob/main/rfcs/002-env-spec.md</a>


<br>- MCPãƒ„ãƒ¼ãƒ«ã®ã‚«ãƒ—ã‚»ãƒ«åŒ–: 


<a href="https://github.com/meta-pytorch/OpenEnv/blob/main/rfcs/003-mcp-support.md" target="_blank" rel="noopener noreferrer">https://github.com/meta-pytorch/OpenEnv/blob/main/rfcs/003-mcp-support.md</a>


<br>- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: 


<a href="https://github.com/meta-pytorch/OpenEnv/blob/main/rfcs/004-actions-as-tool-calls.md" target="_blank" rel="noopener noreferrer">https://github.com/meta-pytorch/OpenEnv/blob/main/rfcs/004-actions-as-tool-calls.md</a>


</p>
<p>Environment Hub:


<a href="https://huggingface.co/openenv" target="_blank" rel="noopener noreferrer">https://huggingface.co/openenv</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-10-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3430" target="_blank" rel="noopener noreferrer" class="title-link">Introducing torchforge â€“ a PyTorch native library for scalable RL post-training and agentic development, PyTorch team at Meta, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yifan_zhang_/status/1981805329517044068?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/SpeechProcessing.html" target="_blank" rel="noopener noreferrer">#SpeechProcessing</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/Zero/FewShotLearning.html" target="_blank" rel="noopener noreferrer">#Zero/FewShotLearning</a>
<a class="button" href="articles/UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<a class="button" href="articles/AudioLanguageModel.html" target="_blank" rel="noopener noreferrer">#AudioLanguageModel</a>
<span class="issue_date">Issue Date: 2025-10-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3427" target="_blank" rel="noopener noreferrer" class="title-link">Introducing MiMo-Audio, LLM-Core Xiaomi, 2025.10</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/collections/XiaomiMiMo/mimo-audio" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/XiaomiMiMo/mimo-audio</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_tobiaslee/status/1981599535802495429?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>text, audioã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã€text, audioã‚’å‡ºåŠ›ã™ã‚‹AudioLanguageModel</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/DocParser.html" target="_blank" rel="noopener noreferrer">#DocParser</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="articles/OCR.html" target="_blank" rel="noopener noreferrer">#OCR</a>
<span class="issue_date">Issue Date: 2025-10-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3395" target="_blank" rel="noopener noreferrer" class="title-link">olmOCR 2: Unit test rewards for document OCR, Ai2, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/allen_ai/status/1981029163394797618?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ¢ãƒ‡ãƒ«:


<a href="https://huggingface.co/allenai/olmOCR-2-7B-1025-FP8" target="_blank" rel="noopener noreferrer">https://huggingface.co/allenai/olmOCR-2-7B-1025-FP8</a>


</p>
<p>Apache2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§SoTAæ›´æ–°ã€‚ãã—ã¦ã•ã™ãŒã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã‚³ãƒ¼ãƒ‰ã‚‚å…¬é–‹</p>
<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ:


<a href="https://github.com/allenai/olmocr/blob/main/olmOCR-2-Unit-Test-Rewards-for-Document-OCR.pdf" target="_blank" rel="noopener noreferrer">https://github.com/allenai/olmocr/blob/main/olmOCR-2-Unit-Test-Rewards-for-Document-OCR.pdf</a>


</p>
<p>æœãŸã—ã¦æ—¥æœ¬èªã¯â€¦SFT Datasetã®top5ã«jaã¯ãªã‹ã£ãŸã‚ˆã†ã«è¦‹ãˆã‚‹</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kylelostat/status/1981380820658180310?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>demoã‚’è©¦ã—ãŸè¦‹ãŸãŒæ—¥æœ¬èªã‚¹ãƒ©ã‚¤ãƒ‰ã§ã‚‚éå¸¸ã«æ€§èƒ½ãŒè‰¯ã„</p>
<p>DeepSeekOCRã¨ã®æ¯”è¼ƒ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/askalphaxiv/status/1983343306152259888?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Inference.html" target="_blank" rel="noopener noreferrer">#Inference</a>
<a class="button" href="articles/MinimalCode.html" target="_blank" rel="noopener noreferrer">#MinimalCode</a>
<a class="button" href="articles/KV%20Cache.html" target="_blank" rel="noopener noreferrer">#KV Cache</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3377" target="_blank" rel="noopener noreferrer" class="title-link">nanochat, karpathy, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/karpathy/status/1977755427569111362?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ–°ãŸãªã‚¹ãƒ”ãƒ¼ãƒ‰ãƒ©ãƒ³ãŒ...!!</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3353" target="_blank" rel="noopener noreferrer" class="title-link">How to scale RL, NATHAN LAMBERT, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/natolambert/status/1980296133810557373?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä¸‹è¨˜ç ”ç©¶ã®å†…å®¹ã‚’è§£èª¬ã—ã¦ã„ã‚‹ã€‚<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3282" target="_blank" rel="noopener noreferrer">[Paper Note] The Art of Scaling Reinforcement Learning Compute for LLMs, Devvrit Khatri+, arXiv'25, 2025.10</a>
 <br><br>äº‹å‰å­¦ç¿’ã«ãŠã‘ã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ¸¬ã¯å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’å®Ÿè¡Œæ™‚ã®æœ€é©ãªè¨­å®šã®é¸æŠã«é–¢ã™ã‚‹ã‚‚ã®ï¼ˆe.g. chinchilla lawï¼‰ã ã£ãŸãŒã€RLï¼ˆ=ç‰¹å®šã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æœ€å¤§é™ã®æ€§èƒ½ã‚’å¼•ãå‡ºã™ãŸã‚ã®æ‰‹æ³•ï¼‰ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å‰‡ã«ãŠã„ã¦ã¯ã©ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ã‚ˆã‚Šé•·æœŸé–“å®Ÿè¡Œã•ã›ã‚‹ã‹ã¨ã„ã†é¸æŠã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ã€‚<br><br>ï¼ˆå¾Œã§ç¶šãã‚’èª­ã‚€ï¼‰</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Scaling%20Laws.html" target="_blank" rel="noopener noreferrer">#Scaling Laws</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3352" target="_blank" rel="noopener noreferrer" class="title-link">How Well Does RL Scale?, Toby Ord, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tobyordoxford/status/1980351353227768109?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OpenAIã‚„AnthropicãŒå…¬è¡¨ã—ã¦ã„ã‚‹å­¦ç¿’ã«é–¢ã™ã‚‹plotï¼ˆã¨ç­†è€…ã®æ§˜ã€…ãªã‚¢ã‚«ãƒ‡ãƒŸã‚¢ã®ç ”ç©¶ã®çŸ¥è¦‹ï¼‰ã«åŸºã¥ã„ã¦ã€RLã«ã‚ˆã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¯ã€äº‹å‰å­¦ç¿’ã‚„Test-time Scalingã‚ˆã‚Šã‚‚è¨ˆç®—é‡ã®è¦³ç‚¹ã§åŠ¹ç‡ãŒæ‚ªã„ã€ã¨ã„ã†ã“ã¨ã‚’åˆ†æã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br>&gt; So the evidence on RL-scaling and inference-scaling supports a general pattern:<br>&gt;- a 10x scaling of RL is required to get the same performance boost as a 3x scaling of inference<br>&gt; - a 10,000x scaling of RL is required to get the same performance boost as a 100x scaling of inference<br>&gt;<br>&gt; In general, to get the same benefit from RL-scaling as from inference-scaling required twice as many orders of magnitude. Thatâ€™s not good.<br><br>ãã®ä¸Šã§ã€RLã«ã‚ˆã‚‹ã‚³ã‚¹ãƒˆãŒäº‹å‰å­¦ç¿’ã®ã‚³ã‚¹ãƒˆã¨åŒç­‰ã‹ãã‚Œä»¥ä¸Šã¨ãªã£ãŸã¨ãã«ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹å ´åˆã®ã‚³ã‚¹ãƒˆãŒçˆ†ç™ºçš„ã«å¢—åŠ ã™ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã—ã¦ã„ã‚‹ï¼ˆåˆæœŸã®RLã«ã‚ˆã‚‹ã‚³ã‚¹ãƒˆãŒå°ã•ã‘ã‚Œã°äº‹å‰å­¦ç¿’ã‚„test-time scalingã®ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™ã‚ˆã‚Šã‚‚åŠ¹ç‡ãŒã‚ˆã„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ‰‹æ³•ã¨ãªã£ã¦ã„ãŸãŒã€RLã®ã‚³ã‚¹ãƒˆãŒå¤§ãããªã£ã¦ãã‚‹ã¨ã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹éš›ã®é‡‘é¡ã®çµ¶å¯¾å€¤ãŒå¤§ãããªã‚Šã™ãã‚‹ã¨ã„ã†è©±ï¼‰ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/DocParser.html" target="_blank" rel="noopener noreferrer">#DocParser</a>
<a class="button" href="articles/Encoder-Decoder.html" target="_blank" rel="noopener noreferrer">#Encoder-Decoder</a>
<a class="button" href="articles/OCR.html" target="_blank" rel="noopener noreferrer">#OCR</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3344" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-OCR: Contexts Optical Compression, DeepSeek, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vllm_project/status/1980235518706401405?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è‹±èªã¨ä¸­å›½èªã§ã¯ä½¿ãˆãã†ã ãŒã€æ—¥æœ¬èªã§ã¯ä½¿ãˆã‚‹ã®ã ã‚ã†ã‹ï¼Ÿp.17 Figure11ã‚’è¦‹ã‚‹ã¨100è¨€èªã«å¯¾ã—ã¦å­¦ç¿’ã—ãŸã¨æ›¸ã‹ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1980160624140456370?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/willccbb/status/1980160732236042604?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>OCRãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3360" target="_blank" rel="noopener noreferrer">[Paper Note] OmniDocBench: Benchmarking Diverse PDF Document Parsing with   Comprehensive Annotations, Linke Ouyang+, CVPR'25, 2024.12</a>
<br><br>ï¼ˆDeepSeek-OCRã®ä¸»é¡Œã¯OCRã®æ€§èƒ½å‘ä¸Šã¨ã„ã†ã‚ã‘ã§ã¯ãªã„ã‚ˆã†ã ãŒï¼‰</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nrehiew_/status/1980635199273889895?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹+ãƒã‚¤ãƒ³ãƒˆè§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1980642191950090585?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kangwook_lee/status/1980709454522744902?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>textxã‚’imageã¨ã—ã¦ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹è©±ã¯ä»¥ä¸‹ã®2023å¹´ã®ICLRã®ç ”ç©¶ã§ã‚‚ã‚„ã‚‰ã‚Œã¦ã„ã‚‹ã‚ˆã¨ã„ã†ãƒã‚¹ãƒˆ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3370" target="_blank" rel="noopener noreferrer">[Paper Note] Language Modelling with Pixels, Phillip Rust+, ICLR'23, 2022.07</a>
<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nielsrogge/status/1980559120760791125?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3375" target="_blank" rel="noopener noreferrer">[Paper Note] Text or Pixels? It Takes Half: On the Token Efficiency of Visual Text
  Inputs in Multimodal LLMs, Yanhong Li+, arXiv'25, 2025.10</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3363" target="_blank" rel="noopener noreferrer">[Paper Note] PixelWorld: Towards Perceiving Everything as Pixels, Zhiheng Lyu+, arXiv'25, 2025.01</a>
</p>
<p>é–¢é€£:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/askalphaxiv/status/1980722479405678593?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3357" target="_blank" rel="noopener noreferrer">[Paper Note] Glyph: Scaling Context Windows via Visual-Text Compression, Jiale Cheng+, arXiv'25, 2025.10</a>
</p>
<p>literature:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/awinyimgprocess/status/1980506449706119642?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ä¸Šè¨˜ãƒã‚¹ãƒˆã§ã¯æœ¬ç ”ç©¶ã¯ã“ã‚Œã‚‰literatureã‚’å®Œå…¨ã«ç„¡è¦–ã— â€œan initial investigation into the feasibility of compressing long contexts via optical 2D mapping.â€ ã¨ä¸»å¼µã—ã¦ã„ã‚‹ã®ã§ã€å…ˆè¡Œç ”ç©¶ã‚’èªè­˜ã—å¼•ç”¨ã™ã¹ãã ã¨è¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã‚ˆã†ã ã€‚<p>karpathyæ°ã®ãƒã‚¹ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/karpathy/status/1980397031542989305?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/karpathy/status/1980764296016720094?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="articles/Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<a class="button" href="articles/PRM.html" target="_blank" rel="noopener noreferrer">#PRM</a>
<a class="button" href="articles/Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<a class="button" href="articles/Cultural.html" target="_blank" rel="noopener noreferrer">#Cultural</a>
<a class="button" href="articles/Emotion.html" target="_blank" rel="noopener noreferrer">#Emotion</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3339" target="_blank" rel="noopener noreferrer" class="title-link">Andrej Karpathy â€” AGI is still a decade away, DWARKESH PATEL, 2025.10</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chemical_tree/status/1980084549158904131?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- In-context Steerbility: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3247" target="_blank" rel="noopener noreferrer">[Paper Note] Spectrum Tuning: Post-Training for Distributional Coverage and
  In-Context Steerability, Taylor Sorensen+, arXiv'25, 2025.10</a>
<br><br>ï¼ˆæ•´ç†ã™ã‚‹ã¨æ¥½ã—ãã†ãªã®ã§å¾Œã§é–¢é€£ã—ãã†ãªç ”ç©¶ã‚’ä»–ã«ã‚‚ã¾ã¨ã‚ã‚‹ï¼‰</p>
<p>ã¨ã¦ã‚‚å‹‰å¼·ã«ãªã‚‹ï¼AIã«ä»£æ›¿ã•ã‚Œãªã„20%, 1%ã«ãªã‚‹ã«ã¯æœãŸã—ã¦</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tydsh/status/1980432024470188252?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="articles/TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-10-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3202" target="_blank" rel="noopener noreferrer" class="title-link">Introducing Stable Diffusion 3.5, StabilityAI, 2024.10</a>
<span class="snippet"><span>Comment</span><p>SD3.5</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ContextEngineering.html" target="_blank" rel="noopener noreferrer">#ContextEngineering</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3102" target="_blank" rel="noopener noreferrer" class="title-link">Effective context engineering for AI agents, Anthropic, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/anthropicai/status/1973098580060631341?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Anthropicã«ã‚ˆã‚‹ContextEngineeringã«é–¢ã™ã‚‹ãƒ–ãƒ­ã‚°ã€‚<br>ã–ãƒ¼ã£ã¨ã¿ãŸæ„Ÿã˜åŸºç¤çš„ãªå®šç¾©ã‹ã‚‰ãªãœé‡è¦ãªã®ã‹ã€retrievalã®æ´»ç”¨ã€longnhorizon taskã§ã®æ´»ç”¨ã€compaction(summarization)ãªã©ã€å¹…åºƒã„ãƒˆãƒ”ãƒƒã‚¯ãŒç¶²ç¾…ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚</p>
<p>æœ€æ–°ã‚µãƒ¼ãƒ™ã‚¤ã¯ã“ã¡ã‚‰<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2256" target="_blank" rel="noopener noreferrer">[Paper Note] A Survey of Context Engineering for Large Language Models, Lingrui Mei+, arXiv'25</a>
</p>
<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_stakaya/status/1974228183450071048?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-10-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3061" target="_blank" rel="noopener noreferrer" class="title-link">2025å¹´10æœˆ1æ—¥ å›½ç«‹æƒ…å ±å­¦ç ”ç©¶æ‰€ã«ãŠã‘ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã¸ã®å”åŠ›ã«ã¤ã„ã¦,  å›½ç«‹å›½ä¼šå›³æ›¸é¤¨, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yhkondo/status/1973324514718261267?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ—¥æœ¬èªLLMã®é€²å±•ã«æ¥µã‚ã¦é‡è¦ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨æ€ã‚ã‚Œã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3040" target="_blank" rel="noopener noreferrer" class="title-link">LoRA Without Regret, Schulman+, THINKING MACHINES, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1972744080800309369?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã“ã‚Œã¯ãŠãã‚‰ãå¿…èª­...</p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1973154083482771717?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iwashi86/status/1974398471508750757?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nrehiew_/status/1974856936530305380?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3028" target="_blank" rel="noopener noreferrer" class="title-link">Failing to Understand the Exponential, Again, Julian Schrittwieser, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aidan_mclau/status/1972091890318430621?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1842" target="_blank" rel="noopener noreferrer">Measuring AI Ability to Complete Long Tasks, Thomas Kwa+, arXiv'25, 2025.03</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3027" target="_blank" rel="noopener noreferrer">GDPVAL: EVALUATING AI MODEL PERFORMANCE ON REAL-WORLD ECONOMICALLY VALUABLE TASKS, Patwardhan+, 2025.09</a>
</p>
<p>AIã®æŒ‡æ•°é–¢æ•°çš„ãªæˆé•·ã¯ç¶šã„ã¦ã„ã‚‹ãã¨ã„ã†è©±ã€‚<br><br>ä»¥ä¸‹ã¯ç®¡ç†äººã®æ„Ÿæƒ³ã ãŒã€å€‹ã€…ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§è¦‹ãŸã‚‰ã‚µãƒã£ã¦ãã¦ã„ã‚‹ï¼ˆæ˜”ã‚ˆã‚Šä¼¸ã³ä»£ãŒå°ã•ã„ï¼‰ã‚ˆã†ã«æ„Ÿã˜ã‚‹ãŒã€äººé–“ãŒå®Ÿæ–½ã™ã‚‹è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹ä¸Šè¨˜ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãªã©ã‚’è¦‹ã‚‹ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¯ç¶šã„ã¦ã„ã‚‹ï¼ˆã‚€ã—ã‚åŠ é€Ÿã—ã¦ã„ã‚‹æ„ŸãŒã‚ã‚‹ï¼‰ã€‚ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¿ã‚¹ã‚¯ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ä¼¸ã³ã¯å°ã•ãã¨ã‚‚ã€ãã‚Œã‚‰ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¿ã‚¹ã‚¯ã®ç©ã¿é‡ã­ã«ã‚ˆã£ã¦è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã¯å®Ÿæ–½ã•ã‚Œã‚‹ã®ã§ã€ï¼ˆç¾å­˜ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒæ¸¬å®šã§ãã¦ã„ã‚‹èƒ½åŠ›ã¯LLMã®éƒ¨åˆ†çš„ãªèƒ½åŠ›ã ã‘ãªã“ã¨ã‚‚é‘‘ã¿ã‚‹ã¨ï¼‰ã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã—ãŸæ™‚ã®ä¼¸ã³ã¯å®Ÿã¯å¤§ãã‹ã£ãŸã‚Šã™ã‚‹ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¯ç¶šã„ã¦ã„ã‚‹ï¼‰ã®ã§ã¯ãªã„ã‹ã€ã¨ã„ã†æ„Ÿæƒ³ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-09-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3027" target="_blank" rel="noopener noreferrer" class="title-link">GDPVAL: EVALUATING AI MODEL PERFORMANCE ON REAL-WORLD ECONOMICALLY VALUABLE TASKS, Patwardhan+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>ç±³å›½ã®GDPã‚’ç‰½å¼•ã™ã‚‹9ã¤ã®ä»£è¡¨çš„ãªç”£æ¥­ã«ãŠã„ã¦ã€44ã®è·ç¨®ã‚’é¸å®šã—ã€åˆè¨ˆ1320ä»¶ã®å®Ÿå‹™ã‚¿ã‚¹ã‚¯ã‚’è¨­è¨ˆã—ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯å¹³å‡14å¹´ç¨‹åº¦ã®çµŒé¨“ã‚’æŒã¤å°‚é–€å®¶ãŒå®Ÿéš›ã®æ¥­å‹™å†…å®¹ã‚’ã‚‚ã¨ã«ä½œæˆã—ã€ï¼ˆã†ã¡ã€ç´„220ä»¶ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ï¼‰ã€ãƒ¢ãƒ‡ãƒ«ã¨å°‚é–€å®¶ã®solutionã«ã‚¿ã‚¹ã‚¯ã‚’å®Ÿæ–½ã•ã›ãŸã€‚ãã®ä¸Šã§ã€ç¬¬ä¸‰è€…ã§ã‚ã‚‹å°‚é–€å®¶ãŒå‹æ•—ï¼ˆwin, lose, tie)ã‚’ä»˜ä¸ã™ã‚‹ã“ã¨ã§ãƒ¢ãƒ‡ãƒ«ãŒã©ã‚Œã ã‘å®Ÿå‹™ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦äººé–“ã®å°‚é–€å®¶ã«åŒ¹æ•µã™ã‚‹ã‹ã‚’æ¸¬å®šã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚‹ã€‚<br><br>è©•ä¾¡ã®çµæœã€ãŸã¨ãˆã°Claude Opus 4.1ã®å‡ºåŠ›ã¯47.6%ç¨‹åº¦ã€GPT-5 (high) ã¯38.8%ç¨‹åº¦ã®å‰²åˆã§å°‚é–€å®¶ã¨å‹ã¡ + å¼•ãåˆ†ã‘ã€ã¨ã„ã†æ€§èƒ½ã«ãªã£ã¦ãŠã‚Šã€äººé–“ã®å°‚é–€å®¶ã«ã‹ãªã‚Šè¿‘ã„ãƒ¬ãƒ™ãƒ«ã«ã¾ã§è¿‘ã¥ã„ã¦ãã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚ç‰¹ã«Claude Opus 4.1ã¯ãƒ‡ã‚¶ã‚¤ãƒ³ã®å“è³ªã‚‚å•ã‚ã‚Œã‚‹ã‚¿ã‚¹ã‚¯ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ›¸å¼è¨­å®šã€ã‚¹ãƒ©ã‚¤ãƒ‰ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆãªã©ï¼‰ã§ç‰¹ã«å„ªã‚Œã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚<br><br>&lt;img width="797" height="600" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/653d724f-34ef-46df-9458-bbfde33857b3"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/653d724f-34ef-46df-9458-bbfde33857b3"&lt;/a&gt;


/&gt;</p>
<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3187" target="_blank" rel="noopener noreferrer">[Paper Note] GDPval: Evaluating AI Model Performance on Real-World Economically
  Valuable Tasks, Tejal Patwardhan+, arXiv'25, 2025.10</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="articles/Aggregation-aware.html" target="_blank" rel="noopener noreferrer">#Aggregation-aware</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3008" target="_blank" rel="noopener noreferrer" class="title-link">RECURSIVE SELF-AGGREGATION UNLOCKS DEEP THINKING IN LARGE LANGUAGE MODELS, Venkatraman+, preprint, 2025.09</a>
<span class="snippet"><span>Comment</span><p>Nå€‹ã®å¿œç­”ã‚’ç”Ÿæˆã—ã€å„å¿œç­”Kå€‹çµ„ã¿åˆã‚ã›ã¦promptingã§é›†ç´„ã—æ–°ãŸãªå¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§æ´—ç·´ã•ã›ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ã‚’Tå›ç¹°ã‚Šè¿”ã™test-time scalingæ‰‹æ³•ã§ã€RLã«ã‚ˆã£ã¦ãƒ¢ãƒ‡ãƒ«ã®é›†ç´„èƒ½åŠ›ã‚’å¼·åŒ–ã™ã‚‹ã¨ã‚ˆã‚Šè‰¯ã„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’ç™ºæ®ã™ã‚‹ã€‚RLã§ã¯é€šå¸¸ã®ç›®çš„é–¢æ•°ï¼ˆprompt x, answer y; xã‹ã‚‰å˜ä¸€ã®reasoning traceã‚’ç”Ÿæˆã—yã‚’å›ç­”ã™ã‚‹è¨­å®šï¼‰ã«åŠ ãˆã¦ã€aggregation promptã‚’ç”¨ã„ãŸç›®çš„é–¢æ•°(aggregation promptã‚’ç”¨ã„ã¦ Kå€‹ã®solutioné›†åˆ S_0ã‚’ç”Ÿæˆã—ã€ç›®çš„é–¢æ•°ã‚’aggregation prompt x, S_0ã®åŒæ–¹ã§æ¡ä»¶ã¥ã‘ãŸã‚‚ã®)ã‚’å®šç¾©ã—ã€åŒæ™‚ã«æœ€é©åŒ–ã‚’ã—ã¦ã„ã‚‹ï¼ˆåŒæ™‚ã«æœ€é©åŒ–ã™ã‚‹ã“ã¨ã¯5.4ç¯€ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ï¼‰ã€‚ã¤ã¾ã‚Šã€ã“ã‚Œã¾ã§ã®RLã¯xãŒgivenãªæ™‚ã«é ‘å¼µã£ã¦å˜ä¸€ã®è‰¯ã„æ„Ÿã˜ã®reasoning traceã‚’ç”Ÿæˆã—yã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã—ã¦ã„ãŸãŒï¼ˆã™ãªã‚ã¡ã€ãƒ¢ãƒ‡ãƒ«ãŒè¤‡æ•°ã®solutionã‚’é›†ç´„ã™ã‚‹ã“ã¨ã¯æ˜ç¤ºçš„ã«å­¦ç¿’ã•ã‚Œã¦ã„ãªã„ï¼‰ã€ãã‚Œã«åŠ ãˆã¦ãƒ¢ãƒ‡ãƒ«ã®aggregationã®èƒ½åŠ›ã‚‚åŒæ™‚ã«å¼·åŒ–ã™ã‚‹ã€ã¨ã„ã†æ°—æŒã¡ã«ãªã£ã¦ã„ã‚‹ã€‚å­¦ç¿’ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯PPO, GRPOãªã©æ§˜ã€…ãªon-poloicyãªæ‰‹æ³•ã‚’ç”¨ã„ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ä»Šå›ã¯RLOOã¨å‘¼ã°ã‚Œã‚‹æ‰‹æ³•ã‚’ç”¨ã„ã¦ã„ã‚‹ã€‚<br><br>&lt;img width="1005" height="456" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/e83406ae-91a0-414b-a49c-892a4d1f23fd"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/e83406ae-91a0-414b-a49c-892a4d1f23fd"&lt;/a&gt;


/&gt;<br><br>æ§˜ã€…ãªsequential scaling, parallel scalingæ‰‹æ³•ã¨æ¯”è¼ƒã—ã¦ã€RSAãŒã‚ˆã‚Šå¤§ããªgainã‚’å¾—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã€‚ãŸã ã—ã€Knowledge Recallã¨ã„ã†ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã¯Self-Consistency (Majority Voting)ã‚ˆã‚Šã‚‚gainãŒå°ã•ã„ã€‚<br>&lt;img width="1017" height="427" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/8251f25b-472d-48d4-b7df-a6946cfbbcd9"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/8251f25b-472d-48d4-b7df-a6946cfbbcd9"&lt;/a&gt;


/&gt;<br><br>ä»¥ä¸‹ãŒaggregation-awareãªRLã‚’å®Ÿæ–½ã—ãŸå ´åˆã¨ã€é€šå¸¸ã®RL, promptingã®ã¿ã«ã‚ˆã‚‹å ´åˆã®æ€§èƒ½ã®è¡¨ã—ã¦ã„ã‚‹ã€‚å…¨ä½“ã‚’é€šã˜ã¦aggregation-awareãªRLã‚’å®Ÿæ–½ã™ã‚‹ã“ã¨ã§ã‚ˆã‚Šé«˜ã„æ€§èƒ½ã‚’ç™ºæ®ã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ãŸã ã—ã€AIMEã«é–¢ã—ã¦ã ã‘ã¯é€šå¸¸ã®promptingã«ã‚ˆã‚‹RSAã®æ€§èƒ½ãŒè‰¯ã„ã€‚ãªãœã ã‚ã†ã‹ï¼Ÿè€ƒå¯Ÿã¾ã§æ·±ãèª­ã‚ã¦ã„ãªã„ã®ã§è«–æ–‡ä¸­ã«è€ƒå¯ŸãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚<br>&lt;img width="1026" height="547" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/146ab6a3-58c2-4a7f-aa84-978a5180c8f3"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/146ab6a3-58c2-4a7f-aa84-978a5180c8f3"&lt;/a&gt;


/&gt;</p>
<p>RLOO:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3009" target="_blank" rel="noopener noreferrer">[Paper Note] Back to Basics: Revisiting REINFORCE Style Optimization for Learning   from Human Feedback in LLMs, Arash Ahmadian+, ACL'24, 2024.02</a>
</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/siddarthv66/status/1971757612845670585?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>concurrent work:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2729" target="_blank" rel="noopener noreferrer">[Paper Note] The Majority is not always right: RL training for solution aggregation, Wenting Zhao+, arXiv'25</a>
</p>
<p>ã‚ã‚ã›ã¦èª­ã¿ãŸã„:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2346" target="_blank" rel="noopener noreferrer">[Paper Note] Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A   Perspective of Probability Theory, Yexiang Liu+, ACL'25 Outstanding Paper</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="articles/train-inference-gap.html" target="_blank" rel="noopener noreferrer">#train-inference-gap</a>
<span class="issue_date">Issue Date: 2025-09-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3004" target="_blank" rel="noopener noreferrer" class="title-link">When Speed Kills Stability: Demystifying RL Collapse from the Training-Inference Mismatch, Liu+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/richardyrli/status/1971560544974086263?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è¨“ç·´æ™‚ã®ã‚¨ãƒ³ã‚¸ãƒ³(fsdpç­‰)ã¨ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆæ™‚ã®ã‚¨ãƒ³ã‚¸ãƒ³(vLLMç­‰)ãŒã€OOVãªãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾ã—ã¦ï¼ˆç‰¹ã«tooluseã—ãŸå ´åˆã«ç”Ÿã˜ã‚„ã™ã„ï¼‰è‘—ã—ãç•°ãªã‚‹å°¤åº¦ã‚’å‰²ã‚Šå½“ã¦ã‚‹ãŸã‚å­¦ç¿’ãŒå´©å£Šã—ã€ãã‚Œã¯åˆ©ç”¨ã™ã‚‹GPUã«ã‚ˆã£ã¦ã‚‚å®‰å®šæ€§ãŒå¤‰åŒ–ã—ï¼ˆA100ã‚ˆã‚Šã‚‚L20, L20ã‚ˆã‚Šã‚‚H20)ã€tokenãƒ¬ãƒ™ãƒ«ã®Importtance Weightingã§ã¯é›£ã—ãã€Sequenceãƒ¬ãƒ™ãƒ«ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒå¿…è¦ã€ã¿ãŸã„ãªè©±ãªæ¨¡æ§˜ã€‚</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2552" target="_blank" rel="noopener noreferrer">Your Efficient RL Framework Secretly Brings You Off-Policy RL Training, Yao+, 2025.08</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2299" target="_blank" rel="noopener noreferrer">[Paper Note] Group Sequence Policy Optimization, Chujie Zheng+, arXiv'25</a>
</p>
<p>FP16ã«ã™ã‚‹ã¨train-inferenae gapãŒéå¸¸ã«å°ã•ããªã‚‹ã¨ã„ã†å ±å‘Š:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3532" target="_blank" rel="noopener noreferrer">[Paper Note] Defeating the Training-Inference Mismatch via FP16, Penghui Qi+, arXiv'25, 2025.10</a>
</p>
<p>A100ã§vLLMã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã«ã—ãŸæ™‚ã®disable_cascade_attnã®è¨­å®šå€¤ã«ã‚ˆã‚‹æŒ™å‹•ã®é•ã„:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/giffmana/status/1984968679008633049?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ãã‚‚ãã‚‚FlashAttnention-2 kernelã«ãƒã‚°ãŒã‚ã‚Šã€A100/L20ã§ç‰¹å®šã®ã‚«ãƒ¼ãƒãƒ«ãŒå‘¼ã°ã‚Œã‚‹ã¨ãƒŸã‚¹ãƒãƒƒãƒãŒèµ·ãã‚‹ã®ã ã¨ã‹ã€‚vLLM Flashattentionãƒªãƒã‚¸ãƒˆãƒªã®issue 87ã«ã‚ˆã£ã¦è§£æ±ºæ¸ˆã¿ã€‚~~å…·ä½“çš„ã«ã©ã®ã‚«ãƒ¼ãƒãƒ«å®Ÿè£…ãªã®ã ã‚ã†ã‹ã€‚~~ã€€ï¼ˆvLLM Flashattentionãƒªãƒã‚¸ãƒˆãƒªã ã£ãŸæ¨¡æ§˜ï¼‰<br>


<a href="https://github.com/vllm-project/flash-attention" target="_blank" rel="noopener noreferrer">https://github.com/vllm-project/flash-attention</a>


<br><br>disable_cascade_attnã®è¨­å®šå€¤ã‚’ä½•å›ã‚‚å¤‰ãˆãŸã‘ã©ã†ã¾ãã„ã‹ãªã„ã‚ˆã¨ã„ã†è©±ãŒã‚ã‚‹:<br>



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/qphutu/status/1984911433952592089?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2922" target="_blank" rel="noopener noreferrer" class="title-link">LongCat-Flash-Thinking, meituan-longcat, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/meituan_longcat/status/1969823529760874935?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1969897602448539790?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2620" target="_blank" rel="noopener noreferrer">LongCat-Flash-Chat, meituan-longcat, 2025.08</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2932" target="_blank" rel="noopener noreferrer">[Paper Note] Libra: Assessing and Improving Reward Model by Learning to Think, Meng Zhou+, arXiv'25, 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="articles/Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2796" target="_blank" rel="noopener noreferrer" class="title-link">GAUSS Benchmarking Structured Mathematical Skills for Large Language Models, Zhang+, 2025.06</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/banghuaz/status/1966529943514325227?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ç¾åœ¨ã®æ•°å­¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯å€‹ã€…ã®å•é¡Œã«å¯¾ã™ã‚‹å›ç­”ã®Accuracyã‚’æ¸¬ã‚‹ã‚‚ã®ã°ã‹ã‚Šã ãŒã€ã‚ã‚‹å•é¡Œã‚’è§£ãéš›ã«ã¯ã•ã¾ã–ã¾ãªã‚¹ã‚­ãƒ«ã‚’æ´»ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€è©•ä¾¡å¯¾è±¡ã®LLMãŒã©ã®ã‚ˆã†ãªã‚¹ã‚­ãƒ«ã«å¼·ãã€å¼±ã„ã®ã‹ã¨ã„ã£ãŸè§£åƒåº¦ãŒä½ã„ã¾ã¾ãªã®ã§ã€ãã†ã„ã£ãŸã‚¹ã‚­ãƒ«ã®ç¿’ç†Ÿåº¦åˆã„ã‚’æ¸¬ã‚Œã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸã€ã¨ã„ã†è©±ã«è¦‹ãˆã‚‹ã€‚</p>
<p>Knowledge Tracingã‚¿ã‚¹ã‚¯ãªã©ã§ã¯å•é¡Œã”ã¨ã«ã‚¹ã‚­ãƒ«ã‚¿ã‚°ã‚’ä»˜ä¸ã—ã¦ã€ã‚¹ã‚­ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¦ç¿’ç†Ÿåº¦ã‚’æ¸¬ã‚‹ã®ã§ã€å•é¡Œã®æ­£èª¤ã ã‘ã§ãªãã¦ã€ã‚¹ã‚­ãƒ«ãƒ™ãƒ¼ã‚¹ã§ã®ç¿’ç†Ÿåº¦ã‚’è¦‹ã‚‹ã“ã¨ã§èƒ½åŠ›ã‚’æ¸¬ã‚‹ã®ã¯è‡ªç„¶ãªæµã‚Œã«æ€ãˆã‚‹ã€‚ãã—ã¦ãã‚Œã¯æ•°å­¦ãŒæœ€ã‚‚å®Ÿæ–½ã—ã‚„ã™ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Non-Determinism.html" target="_blank" rel="noopener noreferrer">#Non-Determinism</a>
<span class="issue_date">Issue Date: 2025-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2763" target="_blank" rel="noopener noreferrer" class="title-link">Defeating Nondeterminism in LLM Inference, Horace He in collaboration with others at Thinking Machines, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thinkymachines/status/1965826369721623001?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒã‚¤ãƒ³ãƒˆè§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1965964901102530965?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>vLLMã«ãŠã„ã¦inferenceã‚’deterministicã«ã™ã‚‹æ–¹æ³•ãŒã€vLLMã®issue number 24583ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã®ã§å‚ç…§ã®ã“ã¨ã€‚</p>
<p>transformersã§ã®å®Ÿè£…ä¾‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gabriberton/status/1968559505966350705?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="articles/GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2755" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] K2-Think: A Parameter-Efficient Reasoning System, Institute of Foundation Models, Mohamed bin Zayed University of Artificial Intelligence, 2025.09</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/LLM360/K2-Think" target="_blank" rel="noopener noreferrer">https://huggingface.co/LLM360/K2-Think</a>


<br>code:<br>- 


<a href="https://github.com/MBZUAI-IFM/K2-Think-SFT" target="_blank" rel="noopener noreferrer">https://github.com/MBZUAI-IFM/K2-Think-SFT</a>


<br>- 


<a href="https://github.com/MBZUAI-IFM/K2-Think-Inference" target="_blank" rel="noopener noreferrer">https://github.com/MBZUAI-IFM/K2-Think-Inference</a>


<br><br>RLã¯verl+GRPOã§å®Ÿæ–½ã—ãŸã¨ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼ã«è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ãŒã€å½“è©²éƒ¨åˆ†ã®ã‚³ãƒ¼ãƒ‰ã®å…¬é–‹ã¯ã•ã‚Œã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ<br>RLã§åˆ©ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯ã“ã¡ã‚‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2070" target="_blank" rel="noopener noreferrer">[Paper Note] Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain  Perspective, Zhoujun Cheng+, arXiv'25</a>
</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1965713404418805806?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-09-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2733" target="_blank" rel="noopener noreferrer" class="title-link">ã€JamC-QAã€: æ—¥æœ¬ã®æ–‡åŒ–ã‚„é¢¨ç¿’ã«ç‰¹åŒ–ã—ãŸè³ªå•å¿œç­”ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ§‹ç¯‰ãƒ»å…¬é–‹ï¼ˆå‰ç·¨ï¼‰, SB Intuitions, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sbintuitions/status/1965243405812011263?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å¾Œç·¨ã‚‚å‚ç…§ã®ã“ã¨:


<a href="https://www.sbintuitions.co.jp/blog/entry/2025/09/09/113132" target="_blank" rel="noopener noreferrer">https://www.sbintuitions.co.jp/blog/entry/2025/09/09/113132</a>


</p>
<p>æ—¥æœ¬ã®æ–‡åŒ–ã€é¢¨ç¿’ã€é¢¨åœŸã€åœ°ç†ã€æ—¥æœ¬å²ã€è¡Œæ”¿ã€æ³•å¾‹ã€åŒ»ç™‚ã«é–¢ã™ã‚‹æ—¢å­˜ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ã‚ˆã‚Šã‚‚é›£æ˜“åº¦ãŒé«˜ã„QAã‚’äººæ‰‹ã«ã‚ˆã£ã¦ã‚¹ã‚¯ãƒ©ãƒƒãƒã‹ã‚‰ä½œæˆã—ãŸè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã€‚äººæ‰‹ã§ä½œæˆã•ã‚ŒãŸQAã«å¯¾ã—ã¦ã€8ç¨®é¡ã®å¼±ã„LLMï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å°ã•ã„æ—¥æœ¬èªLLMã‚’å«ã‚€ï¼‰ã®åŠæ•°ä»¥ä¸ŠãŒæ­£ã—ãå›ç­”ã§ããŸã‚‚ã®ã‚’é™¤å¤–ã€ãã®å¾Œã•ã‚‰ã«äººæ‰‹ã§ç¢ºèªã¨ã„ã£ãŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ—ãƒ­ã‚»ã‚¹ã‚’è¸ã‚“ã§ã„ã‚‹ã€‚è¨˜äº‹ä¸­ã¯äº‹ä¾‹ãŒéå¸¸ã«è±Šå¯Œã§èˆˆå‘³æ·±ã„ã€‚<br><br>å¾Œç·¨ã§ã¯å®Ÿéš›ã®è©•ä¾¡çµæœãŒè¨˜è¼‰ã•ã‚Œã¦ãŠã‚Šã€ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒã®æ—¥æœ¬èªLLMãŒé«˜ã„æ€§èƒ½ã‚’ç²å¾—ã—ã¦ãŠã‚Šã€Llama-Swallowãªã©ã®ç¶™ç¶šäº‹å‰å­¦ç¿’ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚‚é«˜ã„ã‚¹ã‚³ã‚¢ã‚’ç²å¾—ã—ã¦ã„ã‚‹ã€‚è©•ä¾¡æ™‚ã¯4-shotã§ãƒ‰ãƒ¡ã‚¤ãƒ³ã”ã¨ã«Examplarã¯å›ºå®šã—ã€greedy decodingã§è©•ä¾¡ã—ãŸã¨ã®ã“ã¨ã€‚</p>
<p>NLP'25:


<a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q2-18.pdf" target="_blank" rel="noopener noreferrer">https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q2-18.pdf</a>


</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1890" target="_blank" rel="noopener noreferrer">Non-Determinism of "Deterministic" LLM Settings, Berk Atil+, arXiv'24</a>
<br><br>ã®ã‚ˆã†ãªè©±ã‚‚ã‚ã‚‹ã®ã§ã€greedy decodingã ã‘ã§ãªãnucleus/temperature samplingã‚’è¤‡æ•°trialå®Ÿæ–½ã—ãŸå ´åˆã®æ€§èƒ½ã®å¹³å‡ã§ä½•ã‹å¤‰åŒ–ãŒã‚ã‚‹ã ã‚ã†ã‹ã€ã¨ã„ã†ç‚¹ãŒæ°—ã«ãªã£ãŸãŒã€ä¸‹è¨˜ç ”ç©¶ã§MMLUã®ã‚ˆã†ãªå‡ºåŠ›ç©ºé–“ãŒåˆ¶ç´„ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªè¨­å®šã®å ´åˆã¯ã»ã¨ã‚“ã©å½±éŸ¿ãŒãªã„ã“ã¨ãŒå®Ÿé¨“çš„ã«ç¤ºã•ã‚Œã¦ã„ã‚‹æ¨¡æ§˜:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2735" target="_blank" rel="noopener noreferrer">[Paper Note] The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore   Non-Determinism, Yifan Song+, NAACL'25</a>
<br><br>ã“ã‚Œã¯nucleus/temperature samplingãŒææ¡ˆã•ã‚ŒãŸèƒŒæ™¯ï¼ˆï¼å‡ºåŠ›ã®è‡ªç„¶ã•ã‚’ä¿ã£ãŸã¾ã¾å¤šæ§˜æ€§ã‚’å¢—ã‚„ã—ãŸã„ï¼‰ã¨ã‚‚ä¸€è‡´ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2025-09-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2721" target="_blank" rel="noopener noreferrer" class="title-link">FinePDFs, HuggingFaceFW, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aratako_lm/status/1964596642067402987?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Thomas Wolfæ°ã®ãƒã‚¹ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thom_wolf/status/1964653264986656922?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ODC-By 1.0 license</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/Composition.html" target="_blank" rel="noopener noreferrer">#Composition</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2712" target="_blank" rel="noopener noreferrer" class="title-link">From fï¼ˆxï¼‰ and gï¼ˆxï¼‰ to fï¼ˆgï¼ˆxï¼‰ï¼‰: LLMs Learn New Skills in RL by Composing Old Ones, Yuan+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1964235195613143127?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã•ã‚ŒãŸå®Ÿé¨“ã«ãŠã„ã¦ã€æ·±ã•2ã®nestedãªcompostition g(f(x))ã®ãƒ‡ãƒ¼ã‚¿ã§RLã—ãŸå ´åˆã¯ã€ãƒ†ã‚¹ãƒˆæ™‚ã«æ·±ã•6ã¾ã§ã®compostitionã‚’å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸãŒï¼ˆï¼ãƒ¡ã‚¿ã‚¹ã‚­ãƒ«ã¨ã—ã¦compostitionã‚’ç²å¾—ã—ãŸï¼‰ã€æ·±ã•1ã®non-nestedãªãƒ‡ãƒ¼ã‚¿ã§RLã—ãŸå ´åˆã¯è¤‡é›‘ãªcompostitionãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã‚’è§£ã‘ãªã‹ã£ãŸã€‚ã¾ãŸã€ä¸€èˆ¬çš„ã«ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ç¨‹åº¦è§£ã‘ã‚‹å•é¡Œã«å¯¾ã—ã¦RLã‚’é©ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®pass@1000ã¯ã‚ã¾ã‚Šå‘ä¸Šã—ãªã„ã“ã¨ã‹ã‚‰ã€RLã¯æ–°ã—ã„ã‚¹ã‚­ãƒ«ã‚’ä½•ã‚‚æ•™ãˆã¦ã„ãªã„ã®ã§ã¯ãªã„ã‹ã€ã¨ã„ã£ãŸè§£é‡ˆãŒã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ãŒã€ã‚ˆã‚Šé«˜æ¬¡ã®compostitionãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã™ã‚‹ã¨æ˜ç¢ºã«æ€§èƒ½ãŒè‰¯ããªã‚‹ã®ã§ã€å®Ÿã¯ã‚ˆã‚Šé«˜æ¬¡ã®compostitionãŒå¿…è¦ãªã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹æ±åŒ–æ€§èƒ½ã‚’ä¼¸ã°ã—ã¦ã„ã‚‹ã€‚compostitionã§ã®èƒ½åŠ›ã‚’ç™ºæ®ã™ã‚‹ã«ã¯ã¾ãšå¹…åºƒã„atomicãªã‚¹ã‚­ãƒ«ãŒå¿…è¦ãªã®ã§ã€ã—ã£ã‹ã‚Šãã‚Œã‚’äº‹å‰å­¦ç¿’ã§èº«ã«ã¤ã‘ã•ã›ã€ãã®å¾Œpost-trainingã«ã‚ˆã£ã¦è§£æ±ºã—ãŸã„ã‚¿ã‚¹ã‚¯ã®ãŸã‚ã®atomic skillã®compostitionã®æ–¹æ³•ã‚’å­¦ç¿’ã•ã›ã‚‹ã¨åŠ¹æœçš„ãªã®ã§ã¯ãªã„ã‹ã€ã¨ã„ã£ãŸè©±ãªæ¨¡æ§˜ã€‚</p>
<p>ã“ã®è¾ºã®ICLã®è©±ã¨ä¼¼ã¦ã„ã‚‹<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1362" target="_blank" rel="noopener noreferrer">What Do Language Models Learn in Context? The Structured Task Hypothesis, Jiaoda Li+, N/A, ACL'24</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2709" target="_blank" rel="noopener noreferrer" class="title-link">Why Language Models Hallucinate, Kalai+, 2025.09</a>
<span class="snippet"><span>Comment</span><p>è‘—è€…ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/adamfungi/status/1964040819196752312?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1964837910278189271?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>æ‰€è¦‹:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ziv_ravid/status/1964384106567127465?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2695" target="_blank" rel="noopener noreferrer" class="title-link">FineVision: Open Data Is All You Need, Wiedmann+, Hugging Face, 2025.09</a>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/datasets/HuggingFaceM4/FineVision" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/HuggingFaceM4/FineVision</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/andimarafioti/status/1963610135328104945?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-09-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2682" target="_blank" rel="noopener noreferrer" class="title-link">OpenHands PR Arena, neulab, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1963267468853477809?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹Issueã«ã‚¿ã‚°ä»˜ã‘ã™ã‚‹ã“ã¨ã§ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«è¤‡æ•°LLMã«ã‚ˆã£ã¦PRã‚’ä½œæˆï¼ˆAPI callã¯OpenHandswãŒè² æ‹…ã™ã‚‹ï¼‰ã—ã€ãƒ¦ãƒ¼ã‚¶ã¯è¤‡æ•°LLMã®ä¸­ã§è‰¯ã„ã‚‚ã®ã‚’é¸æŠã™ã‚‹ã€ã¨ã„ã£ãŸã“ã¨ãŒã§ãã‚‹æ¨¡æ§˜ï¼Ÿãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã‚‚å°†æ¥çš„ã«å…¬é–‹ã™ã‚‹ã¨ã®ã“ã¨ãªã®ã§ã€å®Ÿéš›ã«ãƒ¦ãƒ¼ã‚¶ãŒã©ã®ãƒ¢ãƒ‡ãƒ«ã®outputã‚’é¸ã‚“ã ã‹ã«ã‚ˆã£ã¦å‹æ•—ãŒã¤ãã®ã§ã€ãã‚Œã«åŸºã¥ã„ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»˜ã‘ã‚’ã™ã‚‹ã®ã ã‚ã†ã¨æ¨æ¸¬ã€‚èˆˆå‘³æ·±ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2668" target="_blank" rel="noopener noreferrer" class="title-link">Inside vLLM: Anatomy of a High-Throughput LLM Inference System, Aleksa GordiÄ‡ blog, 2025.08</a>
<span class="snippet"><span>Comment</span><p>ã‚ã£ã¡ã‚ƒè‰¯ã•ãã†</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2652" target="_blank" rel="noopener noreferrer" class="title-link">August 2025 - China Open Source  Highlights, 2025.09</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/adinayakup/status/1962508234549329969?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2634" target="_blank" rel="noopener noreferrer" class="title-link">Hunyuan-MT-7B, Tencent, 2025.09</a>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ:


<a href="https://github.com/Tencent-Hunyuan/Hunyuan-MT/blob/main/Hunyuan_MT_Technical_Report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/Tencent-Hunyuan/Hunyuan-MT/blob/main/Hunyuan_MT_Technical_Report.pdf</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tencenthunyuan/status/1962466712378577300?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Base Modelã«å¯¾ã—ã¦ã¾ãšä¸€èˆ¬çš„ãªäº‹å‰å­¦ç¿’ã‚’å®Ÿæ–½ã—ã€ãã®å¾ŒMTã«ç‰¹åŒ–ã—ãŸç¶™ç¶šäº‹å‰å­¦ç¿’ï¼ˆãƒ¢ãƒãƒªãƒ³ã‚¬ãƒ«/ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã®åˆ©ç”¨ï¼‰ã€äº‹å¾Œå­¦ç¿’ï¼ˆSFT, GRPO)ã‚’å®Ÿæ–½ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br>ç¶™ç¶šäº‹å‰å­¦ç¿’ã§ã¯ã€æœ€é©ãªDataMixã®æ¯”ç‡ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«ã€RegMixã¨å‘¼ã°ã‚Œã‚‹æ‰‹æ³•ã‚’åˆ©ç”¨ã€‚Catastrophic Forgettingã‚’é˜²ããŸã‚ã«ã€äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®20%ã‚’å«ã‚ã‚‹ã¨ã„ã£ãŸæ–½ç­–ã‚’å®Ÿæ–½ã€‚<br><br>SFTã§ã¯2ã¤ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹ã€‚ã‚¹ãƒ†ãƒ¼ã‚¸1ã¯åŸºç¤çš„ãªç¿»è¨³åŠ›ã®å¼·åŒ–ã¨ç¿»è¨³ã«é–¢ã™ã‚‹æŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ã®å‘ä¸Šã®ãŸã‚ã«ã€Flores-200ã®é–‹ç™ºãƒ‡ãƒ¼ã‚¿(33è¨€èªã®åŒæ–¹å‘ã®ç¿»è¨³ã‚’ã‚«ãƒãƒ¼)ã€å‰å¹´åº¦ã®WMTã®ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ(English to XXã‚’ã‚«ãƒãƒ¼ï¼‰ã€Mandarin to Minority, Minority to Mandarinã®curatedãªäººæ‰‹ã§ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã€DeepSeek-V3-0324ã§ã®åˆæˆãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã€general purpose/MT orientedãªæŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã†ã¡20%ã‚’æ§‹æˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã§ç¿»è¨³ã®instructinoã«é–¢ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®å‡¡åŒ–æ€§èƒ½ã‚’é«˜ã‚ã‚‹ãŸã‚ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã€ã§å­¦ç¿’ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã¯Reference-freeãªæ‰‹æ³•ã‚’ç”¨ã„ã¦ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã—é–¾å€¤ä»¥ä¸‹ã®ä½å“è³ªãªç¿»è¨³å¯¾ã¯é™¤å¤–ã—ã¦ã„ã‚‹ã€‚ã‚¹ãƒ†ãƒ¼ã‚¸2ã§ã¯ã€è©³ç´°ãŒæ›¸ã‹ã‚Œã¦ã„ãªã„ãŒã€å°‘é‡ã§ã‚ˆã‚Šfidelityã®é«˜ã„ç´„270kã®ç¿»è¨³å¯¾ã‚’åˆ©ç”¨ã—ãŸæ¨¡æ§˜ã€‚ã¾ãŸã€å…ˆè¡Œç ”ç©¶ã«åŸºã¥ã„ã¦ã€many-shotã®in-context learningã‚’ç”¨ã„ã¦ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ã•ã‚‰ã«æ´—ç·´ã•ã›ãŸã¨ã®ã“ã¨ï¼ˆå…ˆè¡Œç ”ç©¶ãŒå¼•ç”¨ã•ã‚Œã¦ã„ã‚‹ã®ã¿ã§è©³ç´°ãªè¨˜è¿°ã¯ç„¡ã—ï¼‰ã€‚ã¾ãŸã€è¤‡æ•°ã®è©•ä¾¡ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã‚¹ã‚³ã‚¢ã®ä¸€è²«æ€§ãŒç„¡ã„ã‚µãƒ³ãƒ—ãƒ«ã¯æ‰‹å‹•ã§ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚ã‚‹ã„ã¯verificationã‚’ã—ã¦å“è³ªã‚’æ‹…ä¿ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚<br><br>RLã§ã¯GRPOã‚’æ¡ç”¨ã—ã€rewardã¨ã—ã¦semantic(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2635" target="_blank" rel="noopener noreferrer">[Paper Note] xCOMET: Transparent Machine Translation Evaluation through Fine-grained  Error Detection, Nuno M. Guerreiro+, TACL'24</a>
), terminology(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2649" target="_blank" rel="noopener noreferrer">[Paper Note] TAT-R1: Terminology-Aware Translation with Reinforcement Learning and
  Word Alignment, Zheng Li+, arXiv'25</a>
; ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ã®terminologyã‚’æ‰ãˆã‚‹), repetitionã«åŸºã¥ã„ãŸrewardã‚’æ¡ç”¨ã—ã¦ã„ã‚‹ã€‚æœ€çµ‚çš„ã«SFT-&gt;RLã§å­¦ç¿’ã•ã‚ŒãŸHuayuan-MT-7Bã«å¯¾ã—ã¦ã€ä¸‹è¨˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”¨ã„ã¦è¤‡æ•°ã®outputã‚’çµ±åˆã—ã¦ã‚ˆã‚Šé«˜å“è³ªãªç¿»è¨³ã‚’å‡ºåŠ›ã™ã‚‹ã‚­ãƒ¡ãƒ©ãƒ¢ãƒ‡ãƒ«ã‚’åŒæ§˜ã®rewardã‚’ç”¨ã„ã¦å­¦ç¿’ã™ã‚‹ã€ã¨ã„ã£ãŸpipelineã«ãªã£ã¦ã„ã‚‹ã€‚<br><br>&lt;img width="884" height="462" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/dbb7a799-6304-4cfa-b75c-74b44fe39a2e"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/dbb7a799-6304-4cfa-b75c-74b44fe39a2e"&lt;/a&gt;


/&gt;<br><br>&lt;img width="921" height="279" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/33b49ef7-b93b-4094-b83e-5931d2b411e5"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/33b49ef7-b93b-4094-b83e-5931d2b411e5"&lt;/a&gt;


/&gt;</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1220" target="_blank" rel="noopener noreferrer">Large Language Models Are State-of-the-Art Evaluators of Translation Quality, EAMT'23</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2635" target="_blank" rel="noopener noreferrer">[Paper Note] xCOMET: Transparent Machine Translation Evaluation through Fine-grained  Error Detection, Nuno M. Guerreiro+, TACL'24</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2636" target="_blank" rel="noopener noreferrer">[Paper Note] CometKiwi: IST-Unbabel 2022 Submission for the Quality Estimation Shared Task, Rei+, WMT'22</a>
 <br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2637" target="_blank" rel="noopener noreferrer">[Paper Note] No Language Left Behind: Scaling Human-Centered Machine Translation, NLLB Team+, arXiv'22</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2638" target="_blank" rel="noopener noreferrer">[Paper Note] Many-Shot In-Context Learning, Rishabh Agarwal+, NeurIPS'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2639" target="_blank" rel="noopener noreferrer">[Paper Note] RegMix: Data Mixture as Regression for Language Model Pre-training, Qian Liu+, ICLR'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2649" target="_blank" rel="noopener noreferrer">[Paper Note] TAT-R1: Terminology-Aware Translation with Reinforcement Learning and
  Word Alignment, Zheng Li+, arXiv'25</a>
</p>
<p>é–¢é€£: PLaMoç¿»è¨³<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2517" target="_blank" rel="noopener noreferrer">PLaMo Translate: ç¿»è¨³ç‰¹åŒ–å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é–‹ç™º,ä»ŠåŸ+, Jxiv'25</a>
<br><br>ã“ã¡ã‚‰ã¯SFT-&gt;Iterative DPO-&gt;Model Mergeã‚’å®Ÿæ–½ã—ã€ç¿»è¨³ã«ç‰¹åŒ–ã—ãŸç¶™ç¶šäº‹å‰å­¦ç¿’ã¯ã‚„ã£ã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚ä¸€æ–¹ã€SFTæ™‚ç‚¹ã§ç‹¬è‡ªã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆã—ã€èªå½™ã®æŒ‡å®šã‚„ã‚¹ã‚¿ã‚¤ãƒ«ã€æ—¥æœ¬èªç‰¹æœ‰ã®å¸¸ä½“ã€æ•¬ä½“ã®æŒ‡å®šãªã©ã‚’å®Ÿæ–½ã§ãã‚‹ã‚ˆã†ã«ç¿»è¨³ã«ç‰¹åŒ–ã—ãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å­¦ç¿’ã—ã¦ã„ã‚‹ç‚¹ãŒç•°ãªã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚Hunyuanã¯å¤šæ§˜ãªç¿»è¨³ã®æŒ‡ç¤ºã«å¯¾å¿œã§ãã‚‹ã‚ˆã†ã«å­¦ç¿’ã—ã¦ã„ã‚‹ãŒã€PLaMoç¿»è¨³ã¯ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚’çµã‚Šè¾¼ã¿ã€ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«å¯¾ã™ã‚‹æ€§èƒ½ã‚’é«˜ã‚ã‚‹ã‚ˆã†ãªç‰¹åŒ–å‹ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ã¨ã‚‹ã¨ã„ã£ãŸæ€æƒ³ã®é•ã„ãŒä¼ºãˆã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="articles/Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2631" target="_blank" rel="noopener noreferrer" class="title-link">Nemotron-CC-v2, Nvidia, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zeyuanallenzhu/status/1962119316427706828?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>CCã ã‘ã§ãªãã€æ•°å­¦ã‚„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®äº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã€SFT styleã®åˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚å«ã¾ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2620" target="_blank" rel="noopener noreferrer" class="title-link">LongCat-Flash-Chat, meituan-longcat, 2025.08</a>
<span class="snippet"><span>Comment</span><p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆ:


<a href="https://github.com/meituan-longcat/LongCat-Flash-Chat/blob/main/tech_report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/meituan-longcat/LongCat-Flash-Chat/blob/main/tech_report.pdf</a>


</p>
<p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1961955926136832381?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Agentå‘¨ã‚Šã®ãƒ™ãƒ³ãƒã§é«˜æ€§èƒ½ãªnon thinkingãƒ¢ãƒ‡ãƒ«ã€‚æ¯ç§’100+ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆé€Ÿåº¦ã§ã€MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã€‚Dynamic Activation...?</p>
<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2621" target="_blank" rel="noopener noreferrer">[Paper Note] Shortcut-connected Expert Parallelism for Accelerating   Mixture-of-Experts, Weilin Cai+, ICLR'25</a>
</p>
<p>Dynamic Activation (activation paramãŒå…¥åŠ›ã«å¿œã˜ã¦å¤‰åŒ–(å…¨ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’MoEã«ãŠã„ã¦å‡ä¸€ã«æ‰±ã‚ãªã„ï¼‰ã™ã‚‹ã“ã¨ã§åŠ¹ç‡åŒ–ï¼‰ã¯ã€ä¸‹è¨˜ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§å®Ÿç¾ã—ã¦ã„ã‚‹æ¨¡æ§˜<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2622" target="_blank" rel="noopener noreferrer">[Paper Note] MoE++: Accelerating Mixture-of-Experts Methods with Zero-Computation   Experts, Peng Jin+, ICLR'25</a>
</p>
<p>ã—ã‹ã—ä¸­å›½ã¯æœ¬å½“ã«æ¬¡ã€…ã«è‰²ã€…ãªä¼æ¥­ã‹ã‚‰åŸºç›¤ãƒ¢ãƒ‡ãƒ«ãŒå‡ºã¦ãã‚‹ãªãâ€¦ã™ã”ã„</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2623" target="_blank" rel="noopener noreferrer">[Paper Note] Scaling Exponents Across Parameterizations and Optimizers, Katie Everett+, ICML'24</a>
 </p>
<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/nrehiew_/status/1962186876099739767?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>è§£èª¬:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1962980770550628841?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="articles/ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<a class="button" href="articles/train-inference-gap.html" target="_blank" rel="noopener noreferrer">#train-inference-gap</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2552" target="_blank" rel="noopener noreferrer" class="title-link">Your Efficient RL Framework Secretly Brings You Off-Policy RL Training, Yao+, 2025.08</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fengyao1909/status/1960087630273761386?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>å…ƒã€…<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1969" target="_blank" rel="noopener noreferrer">verl: Volcano Engine Reinforcement Learning for LLMs, ByteDance Seed Team, 2025.04</a>
<br><br>ã®ã‚¹ãƒ¬ãƒƒãƒ‰ä¸­ã«ãƒ¡ãƒ¢ã£ã¦ã„ãŸãŒã€ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆãŒã‚ã£ãŸã‚ˆã†ãªã®ã§æ–°ãŸã«IssueåŒ–<br><br>trainingã®ã‚¨ãƒ³ã‚¸ãƒ³(FSDPç­‰)ã¨ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã«ä½¿ã†inferenceã‚¨ãƒ³ã‚¸ãƒ³(SGLang,vLLM)ãªã©ã®ã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒŸã‚¹ãƒãƒƒãƒã«ã‚ˆã‚Šã€å­¦ç¿’ãŒã†ã¾ãã„ã‹ãªããªã‚‹ã¨ã„ã†è©±ã€‚</p>
<p>ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆãŒã‚ã£ãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fengyao1909/status/1971284266672849183?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>- Parallelismã®ãƒŸã‚¹ãƒãƒƒãƒã§ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã¨å­¦ç¿’ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’åºƒã’ã¦ã—ã¾ã†ã“ã¨ï¼ˆç‰¹ã«sequence parallelism)<br>- Longer Sequenceã®æ–¹ãŒã€ã‚®ãƒ£ãƒƒãƒ—ãŒåºƒãŒã‚Šã‚„ã™ã„ã“ã¨<br>- Rolloutã®ãŸã‚ã®inferenceã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä¿®æ­£ã™ã‚‹ï¼ˆSGLang w/ deterministic settingã™ã‚‹ã“ã¨ã‚‚å«ã‚€)ã ã‘ã§ã¯åŠ¹æœã¯é™å®šçš„<br><br>ã¨ã„ã£ãŸæ„Ÿã˜ãªæ¨¡æ§˜ã€‚<p>ã•ã‚‰ã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fengyao1909/status/1978199213206011953?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>FP16ã«ã™ã‚‹ã¨train-inferenae gapãŒéå¸¸ã«å°ã•ããªã‚‹ã¨ã„ã†å ±å‘Š:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3532" target="_blank" rel="noopener noreferrer">[Paper Note] Defeating the Training-Inference Mismatch via FP16, Penghui Qi+, arXiv'25, 2025.10</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-08-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2389" target="_blank" rel="noopener noreferrer" class="title-link">Diffusion Language Models are Super Data Learners, Jinjie Ni and the team, 2025.08</a>
<span class="snippet"><span>Comment</span><p>dLLMã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ç¹°ã‚Šè¿”ã—ã«å¼·ãã€ãƒ‡ãƒ¼ã‚¿åˆ¶ç´„ä¸‹ã«ãŠã„ã¦ã¯ååˆ†ãªè¨ˆç®—é‡ã‚’æŠ•å…¥ã—ã¦epochã‚’é‡ã­ã‚‹ã¨ã€æ€§èƒ½å‘ä¸ŠãŒã‚µãƒã‚‰ãšã«ARãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã€‚<br><br><img src="https://github.com/user-attachments/assets/ff668aac-cbcd-48ed-a5d6-50d0fa381f5a" alt="image" loading="lazy"></p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2268" target="_blank" rel="noopener noreferrer">[Paper Note] Diffusion Beats Autoregressive in Data-Constrained Settings, Mihir Prabhudesai+, arXiv'25</a>
<br>- è¿½è¨˜: ä¸Šè¨˜ç ”ç©¶ã®è‘—è€…ã«ã‚ˆã‚‹æœ¬ãƒã‚¹ãƒˆã§å–ã‚Šä¸Šã’ã‚‰ã‚ŒãŸissueã«å¯¾ã™ã‚‹clarification<br>ã€€ã€€- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mihirp98/status/1954240474891653369?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ã§ã‚‚åŒæ§˜ã®çŸ¥è¦‹ãŒå¾—ã‚‰ã‚Œã¦ã„ã‚‹ã€‚<br>ãŒã€ã‚¹ãƒ¬ãƒƒãƒ‰ä¸­ã§ä¸¡è€…ã®é•ã„ãŒä¸‹è¨˜ã®ã‚ˆã†ã«ï¼ˆx rollrng reviewãªã‚‹ã‚‚ã®ã‚’ç”¨ã„ã¦ï¼‰ãƒã‚¹ãƒˆã•ã‚Œã¦ãŠã‚Šã€èˆˆå‘³ãŒã‚ã‚‹å ´åˆã¯èª­ã‚€ã¨ã„ã„ã‹ã‚‚ã€‚ï¼ˆã¨ã“ã‚ã§ã€x rolling reviewã¨ã¯ã€ã€ï¼Ÿã‚‚ã—ã‚„LLMã«ã‚ˆã‚‹è‡ªå‹•çš„ãªæŸ»èª­ã‚·ã‚¹ãƒ†ãƒ ï¼Ÿï¼‰<br><br><img src="https://github.com/user-attachments/assets/295dcd4b-2b81-4439-b117-94dcf6cce5a7" alt="image" loading="lazy"><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1829" target="_blank" rel="noopener noreferrer">Scaling Data-Constrained Language Models, Niklas Muennighoff+, NeurIPS'23</a>
<br><br>ã«ãŠã„ã¦ã€ARãƒ¢ãƒ‡ãƒ«ã§ã¯repetitionã¯4å›ã¾ã§ãŒã‚³ã‚¹ãƒ‘è‰¯ã„ã¨ã„ã†è©±ã¨æ¯”ã¹ã‚‹ã¨ã€dLLMã«ã¨ã‚“ã§ã‚‚ãªã„ä¼¸ã³ä»£ãŒã‚ã‚‹ã‚ˆã†ãªè©±ã«è¦‹ãˆã‚‹ã€‚</p>
<p>ï¼ˆè©±ãŒè„±ç·šã—ã¾ã™ï¼‰<br>å€‹äººçš„ã«ã¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ã•ã‚‰ãªã‚‹é€²åŒ–ã¯èˆˆå‘³æ·±ã„ãŒã€ãƒ¦ãƒ¼ã‚¶ãŒä¸å®Œå…¨ãªè³ªå•ã‚’LLMã«æŠ•ã’ãŸæ™‚ã«ã€LLMãŒãƒ¦ãƒ¼ã‚¶ã®æ„å›³ãŒã€Œä¸æ˜ãªéƒ¨åˆ†ã®contextã‚’è³ªå•ã‚’è¿”ã™ã“ã¨ã«ã‚ˆã£ã¦è£œã†ã€ã¨ã„ã†æŒ™å‹•ãŒã‚ã‚‹ã¨å¬‰ã—ã„æ°—ãŒã™ã‚‹ã®ã ãŒã€ãã†ã„ã£ãŸç ”ç©¶ã¯ãªã„ã®ã ã‚ã†ã‹ã€‚<br><br>ãŸã ã€äº‹å‰å­¦ç¿’æ™‚ç‚¹ã§ãã†ã„ã£ãŸãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦çŸ¥è­˜ã¨ã—ã¦å¸åã•ã‚Œã€ã‹ã¤mid/post-trainingã§ãã†ã„ã£ãŸèƒ½åŠ›ã‚’å¼•ãå‡ºã™ã¨è¨€ã†ä¸¡è»¸ã§å–ã‚Šçµ„ã¾ãªã„ã¨ã€æœ€æ‚ªè†¨å¤§ãªè¨ˆç®—è³‡æºã‚’æŠ•ã˜ãŸã‚‚ã®ã®ã€Œã‚ã‹ã‚‰ãªã„ï¼ã©ã†ã„ã†ã“ã¨ï¼ï¼Ÿã€ã¨è¿”ã—ç¶šã‘ã‚‹LLMãŒå®Œæˆã—å…¨ãå½¹ã«ç«‹ãŸãªã„ã€ã¨ã„ã†ã“ã¨ã«ãªã‚Šãã†ã§æ€–ã„ã€‚<br><br>gpt5ãŒå‡ºãŸæ™‚ã«ã€ã€Œ3.9ã¨3.11ã¯ã©ã¡ã‚‰ãŒå¤§ãã„ã§ã™ã‹ï¼Ÿã€ã¨ã„ã†ã‚¯ã‚¨ãƒªã‚’æŠ•ã’ãŸéš›ã«ã„ã¾ã ã«ã€Œ3.11ã€ã¨å›ç­”ã—ã¦ãã‚‹ã€ã¿ãŸã„ãªãƒã‚¹ãƒˆãŒå°è±¡çš„ã§ã‚ã‚Šã€ã“ã‚Œã¯LLMãŒæ‚ªã„ã¨è¨€ã†ã‚ˆã‚Šã€ãƒ¦ãƒ¼ã‚¶å´ãŒç®—æ•°ã¨ã—ã¦ã®æ–‡è„ˆã§ãã„ã¦ã„ã‚‹ã®ã‹ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®æ–‡è„ˆã§ãã„ã¦ã„ã‚‹ã®ã‹ã€ã‚’æŒ‡å®šã—ã¦ã„ãªã„ã“ã¨ãŒåŸå› ã§ã‚ã‚Šã€ä¸Šè¨˜ã®å›ç­”ã¯ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã¨ã„ã†æ–‡è„ˆã§ã¯æ­£ç­”ã¨ãªã‚‹ã€‚LLMãŒçœã‚¨ãƒã«ãªã£ã¦ã€ãƒ¦ãƒ¼ã‚¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©ã—ã¾ãã£ã¦ã€ä¸€äººä¸€äººã«å¯¾ã—ã¦ã‚ãªãŸã ã‘ã®LLMã€œã¿ãŸã„ãªæ™‚ä»£ãŒãã‚Œã°å°‘ã—ã¯å¤‰ã‚ã‚‹ã®ã ã‚ã†ãŒã€ãã‚Œã§ã‚‚ãƒ¦ãƒ¼ã‚¶ãŒãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦è“„ç©ã—ãŸæ„å›³ã¨ã¯ç•°ãªã‚‹æ„å›³ã§è³ªå•ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã¨ã„ã†çŠ¶æ³ã«ãªã‚‹ã¨ã€ä¸Šè¨˜ã®ã‚ˆã†ãªæ„å›³ã®å–ã‚Šé•ãˆãŒç”Ÿã˜ã‚‹ã‚ˆã†ã«æ€ã†ã€‚<br>ãªã®ã§ã‚„ã¯ã‚Šã‚ŠLLMå´ãŒæƒ…å ±ãŒè¶³ã‚Šã‚“ã€œã¨æ€ã£ãŸã‚‰é©åˆ‡ãªturnæ•°ã§ã€æœ€å¤§é™ã®æƒ…å ±ã‚’ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰å¼•ãå‡ºã›ã‚‹ã‚ˆã†ãªé€†è³ªå•ã‚’è¿”ã™ã¿ãŸã„ãªæŒ™å‹•ã€ã‚ã‚‹ã„ã¯è¶³ã‚Šãªã„æƒ…å ±ãŒã‚ã£ãŸã¨ãã«ã€ã„ãã¤ã‹ã®å€™è£œã‚’æç¤ºã—ã¦ãƒ¦ãƒ¼ã‚¶å´ã«æç¤ºã•ã›ã‚‹ï¼ˆe.g., ç®—æ•°ã®è©±ï¼Ÿãã‚Œã¨ã‚‚ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã®è©±ï¼Ÿã¿ãŸã„ãªï¼‰ã€ã¨ã„ã£ãŸæŒ™å‹•ãŒã‚ã‚‹ã¨å¬‰ã—ã„ãªãã€æ„Ÿã€‚<br><br>ã‚“ã§ãã“ã®éƒ¨åˆ†ã®æ€§èƒ½ã¯ã€ã‚‚ã—ã‚„ã‚‹ãªã€promptingã§ã‚‚ã‚ã‚‹ç¨‹åº¦ã¯å®Ÿç¾ã§ãã€ãã‚Œã§ã‚‚å…¨ç„¶æ€§èƒ½è¶³ã‚Šãªã„ã‚ˆã­ï¼Ÿã¨ãªã£ãŸå¾Œã«ã€äº‹å‰å­¦ç¿’ã€äº‹å¾Œå­¦ç¿’ã§ã‚ˆã‚Šæ€§èƒ½å‘ä¸Šã—ã¾ã™ã€ã¿ãŸã„ãªæµã‚Œã«ãªã‚‹ã®ã‹ãªãã€ã¨æƒ³åƒã™ã‚‹ãªã©ã—ãŸã€‚<br><br>ã—ã‹ã—ã“ã†ã„ã†è©±ã‚’ã‚ã¾ã‚Šè¦‹ãªã„ã®ã¯ãªãœã ã‚ã†ï¼Ÿç§ã®è¦³æ¸¬ç¯„å›²ãŒç‹­ã™ãã‚‹ or ç§ã®ã‚¢ã‚¤ãƒ‡ã‚¢ãŒãƒãƒ³ã‚³ãƒ„ãªã®ã‹ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç«¶äº‰ã«ãªã£ã¦ã„ã¦ã€ãã“ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã«æ¥­ç•Œå…¨ä½“ãŒæ³¨åŠ›ã—ã¦ã—ã¾ã£ã¦ã„ã‚‹ã‹ã‚‰ãªã®ã‹ã€ã¯ãŸã¾ãŸè£ã§ã¯ã‚„ã‚‰ã‚Œã¦ã„ã‚‹ã‘ã©ä½¿ã„ç‰©ã«ãªã‚‰ãªã„ã®ã‹ã€å…¨ç„¶ã‚ã‹ã‚‰ã‚“ã€‚</p>
<p>ç¶šå ±:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3113" target="_blank" rel="noopener noreferrer">Diffusion Language Models are Super Data Learners, Ni+, 2022.10</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-08-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2361" target="_blank" rel="noopener noreferrer" class="title-link">Synthetic Data in the Era of LLMs, Tutorial at ACL 2025</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1952876206388359186?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/AttentionSinks.html" target="_blank" rel="noopener noreferrer">#AttentionSinks</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-08-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2358" target="_blank" rel="noopener noreferrer" class="title-link">gpt-oss-120b, OpenAI, 2025.08</a>
<span class="snippet"><span>Comment</span><p>blog:


<a href="https://openai.com/index/introducing-gpt-oss/" target="_blank" rel="noopener noreferrer">https://openai.com/index/introducing-gpt-oss/</a>


<br><br>HF:<br>


<a href="https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md</a>


</p>
<p>ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹æŠ€è¡“ã¾ã¨ã‚:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1952799735900979219?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yampeleg/status/1952875217367245195?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/adamzweiger/status/1952799642636148917?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cwolferesearch/status/1956132685102887059?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>  - ã“ã¡ã‚‰ã«ã‚‚è©³ç´°ã«è«–æ–‡ãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹<p>ä¸Šè¨˜ãƒã‚¹ãƒˆä¸­ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è«–æ–‡ãƒ¡ãƒ¢ãƒªãƒ³ã‚¯ï¼ˆç®¡ç†äººãŒè¿½åŠ ã—ãŸã‚‚ã®ã‚‚å«ã‚€ï¼‰<br>- Sliding Window Attention<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2388" target="_blank" rel="noopener noreferrer">[Paper Note] Longformer: The Long-Document Transformer, Iz Beltagy+, arXiv'20</a>
 <br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2359" target="_blank" rel="noopener noreferrer">[Paper Note] Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context, Zihang Dai+, ACL'19</a>
<br>- MoE<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1754" target="_blank" rel="noopener noreferrer">Switch Transformers: Scaling to Trillion Parameter Models with Simple  and Efficient Sparsity, William Fedus+, JMLR'22</a>
<br>- RoPE w/ YaRN<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1310" target="_blank" rel="noopener noreferrer">RoFormer: Enhanced Transformer with Rotary Position Embedding, Jianlin Su+, N/A, Neurocomputing, 2024</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2338" target="_blank" rel="noopener noreferrer">[Paper Note] YaRN: Efficient Context Window Extension of Large Language Models, Bowen Peng+, ICLR'24</a>
<br>- Attention Sinks<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1861" target="_blank" rel="noopener noreferrer">Efficient Streaming Language Models with Attention Sinks, Guangxuan Xiao+, ICLR'24</a>
<br>    - Attention Sinksã®å®šç¾©ã¨ãã®æ°—æŒã¡ã€Zero Sink, Softmaxã®åˆ†æ¯ã«ãƒã‚¤ã‚¢ã‚¹é …ãŒå­˜åœ¨ã™ã‚‹æ„ç¾©ã«ã¤ã„ã¦ã¯ã“ã®ãƒ¡ãƒ¢ã‚’å‚ç…§ã®ã“ã¨ã€‚<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1860" target="_blank" rel="noopener noreferrer">Why do LLMs attend to the first token?, Federico Barbero+, COLM'25</a>
<br>    - Attention SinksãŒå®Ÿéš›ã«ã©ã®ã‚ˆã†ã«åŠ¹æœçš„ã«ä½œç”¨ã—ã¦ã„ã‚‹ã‹ï¼Ÿã«ã¤ã„ã¦ã¯ã“ã¡ã‚‰ã®ãƒ¡ãƒ¢ã‚’å‚ç…§ã€‚<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1862" target="_blank" rel="noopener noreferrer">When Attention Sink Emerges in Language Models: An Empirical View, Xiangming Gu+, ICLR'25</a>
<br>    - 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gu_xiangming/status/1952811057673642227?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>  - Sink Token (or Zero Sink) ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã§ã€decoder-onlyãƒ¢ãƒ‡ãƒ«ã®æ·±ã„å±¤ã§ã®representationã®over mixingã‚’æ”¹å–„ã—ã€æ±åŒ–æ€§èƒ½ã‚’é«˜ã‚ã€promptã«å¯¾ã™ã‚‹sensitivityã‚’æŠ‘ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚<br>  - (Attentionã®è¨ˆç®—ã«åˆ©ç”¨ã™ã‚‹) Softmaxã¸ã®Learned bias ã®å°å…¥ ï¼ˆã«ã‚ˆã‚‹ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼‰<br>    - ã“ã‚Œã¯learnable biasãŒå°å…¥ã•ã‚Œã‚‹ã“ã¨ã§ã€attention scoreã®å’ŒãŒ1ã«ãªã‚‹ã“ã¨ã‚’é˜²æ­¢ã§ãã‚‹ï¼ˆä½™å‰°ãªã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã‚’æ¨ã¦ã‚‰ã‚Œã‚‹ï¼‰ã®ã§ã€Zero Sinkã‚’å°å…¥ã—ã¦ã„ã‚‹ã¨ã¿ãªã›ã‚‹ï¼ˆã¨æ€ã‚ã‚Œã‚‹ï¼‰ã€‚<br>- GQA<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1271" target="_blank" rel="noopener noreferrer">GQA: Training Generalized Multi-Query Transformer Models from Multi-Head
  Checkpoints, Joshua Ainslie+, N/A, arXiv'23</a>
<br>- SwiGLU<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1311" target="_blank" rel="noopener noreferrer">GLU Variants Improve Transformer, Noam Shazeer, N/A, arXiv'20</a>
-<p>- group size 8ã§GQAã‚’åˆ©ç”¨<br>- Context Windowã¯128k<br>- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¤§éƒ¨åˆ†ã¯è‹±èªã®ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ<br>  - STEM, Coding, general knowledgeã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹<br>  - 


<a href="https://openai.com/index/gpt-oss-model-card/" target="_blank" rel="noopener noreferrer">https://openai.com/index/gpt-oss-model-card/</a>


<br><br>ã‚ã¨ã§è¿½è¨˜ã™ã‚‹</p>
<p>ä»–Open Weight Modelã¨ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢æ¯”è¼ƒ:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1952795149584482665?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1952887733803991070?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/terryyuezhuo/status/1952829578130670053?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/artificialanlys/status/1952823565642023044?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>  - long context<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thienhn97/status/1953152808334852124?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>  - Multihop QA<p>è§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1952915080229863761?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>learned attention sinks, MXFP4ã®è§£èª¬:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/carrigmat/status/1952779877569978797?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>Sink Valueã®åˆ†æ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhaocha1/status/1952851897414762512?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>gpt-oss ã®ä½¿ã„æ–¹:<br>


<a href="https://note.com/npaka/n/nf39f327c3bde?sub_rt=share_sb" target="_blank" rel="noopener noreferrer">https://note.com/npaka/n/nf39f327c3bde?sub_rt=share_sb</a>


<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/9" target="_blank" rel="noopener noreferrer">[Paper Note] Comments-Oriented Document Summarization: Understanding Documents with Readerâ€™s Feedback, Hu+, SIGIRâ€™08, 2008.07</a>
fd064b2-338a-4f8d-953c-67e458658e39</p>
<p>Qwen3ã¨ã®æ·±ã•ã¨åºƒã•ã®æ¯”è¼ƒ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2364" target="_blank" rel="noopener noreferrer">The Big LLM Architecture Comparison, Sebastian Laschka, 2025.07</a>
</p>
<p>Phi4ã¨åŒã˜tokenizerã‚’ä½¿ã£ã¦ã„ã‚‹ï¼Ÿ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bgdidenko/status/1952829980389343387?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>post-training / pre-trainingã®è©³ç´°ã¯ãƒ¢ãƒ‡ãƒ«ã‚«ãƒ¼ãƒ‰ä¸­ã«è¨€åŠãªã—:<br>- 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/teortaxestex/status/1952806676492689652?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br>- 



<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1952787196253265955?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«é–¢ã—ã¦:<br><br>&gt; Apache 2.0 ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãŠã‚ˆã³å½“ç¤¾ã® gpt-oss åˆ©ç”¨è¦ç´„ã«åŸºã¥ãã“ã¨ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚<br><br>å¼•ç”¨å…ƒ: 


<a href="https://openai.com/ja-JP/index/gpt-oss-model-card/" target="_blank" rel="noopener noreferrer">https://openai.com/ja-JP/index/gpt-oss-model-card/</a>


<br><br>gpt-ossåˆ©ç”¨è¦ç´„: 


<a href="https://github.com/openai/gpt-oss/blob/main/USAGE_POLICY" target="_blank" rel="noopener noreferrer">https://github.com/openai/gpt-oss/blob/main/USAGE_POLICY</a>


</p>
<p>cookbookå…¨ä½“:


<a href="https://cookbook.openai.com/topic/gpt-oss" target="_blank" rel="noopener noreferrer">https://cookbook.openai.com/topic/gpt-oss</a>


</p>
<p>gpt-oss-120bã‚’pythonã¨vLLMã§è§¦ã‚ŠãªãŒã‚‰ç†è§£ã™ã‚‹:


<a href="https://tech-blog.abeja.asia/entry/gpt-oss-vllm" target="_blank" rel="noopener noreferrer">https://tech-blog.abeja.asia/entry/gpt-oss-vllm</a>


</p>
<p>æŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ï¼ˆIFEVal)ãŒä½ã„ã¨ã„ã†æŒ‡æ‘˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/webbigdata/status/1962332061437706589?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2318" target="_blank" rel="noopener noreferrer" class="title-link">GLM-4.5: Reasoning, Coding, and Agentic Abililties, Zhipu AI Inc., 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1949825490488795275?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>HF:


<a href="https://huggingface.co/collections/zai-org/glm-45-687c621d34bda8c9e4bf503b" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/zai-org/glm-45-687c621d34bda8c9e4bf503b</a>


</p>
<p>è©³ç´°ãªã¾ã¨ã‚:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1949879437547241752?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2128" target="_blank" rel="noopener noreferrer">[Paper Note] GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable  Reinforcement Learning, GLM-V Team+, arXiv'25</a>
</p>
<p>ã“ã¡ã‚‰ã§ã‚‚Muon OptimizerãŒä½¿ã‚ã‚Œã¦ãŠã‚Šã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£çš„ã«ã¯GQAã‚„Multi Token Prediction, QK Normalization, MoE, åºƒã•ã‚ˆã‚Šã‚‚æ·±ã•ã‚’é‡è¦–ã®æ§‹é€ ã€ã¿ãŸã„ãªæ„Ÿã˜ãªæ¨¡æ§˜ï¼Ÿ<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2273" target="_blank" rel="noopener noreferrer" class="title-link">LLM Servingã‚’æ”¯ãˆã‚‹æŠ€è¡“, Kotoba Technologies, 2025.07</a>
<span class="snippet"><span>Comment</span><p>ã“ã¡ã‚‰ã‚‚å‚ç…§ã®ã“ã¨:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2263" target="_blank" rel="noopener noreferrer">LLMæ¨è«–ã«é–¢ã™ã‚‹æŠ€è¡“ãƒ¡ãƒ¢, iwashi.co, 2025.07</a>
</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Metrics.html" target="_blank" rel="noopener noreferrer">#Metrics</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="articles/Parallelism.html" target="_blank" rel="noopener noreferrer">#Parallelism</a>
<a class="button" href="articles/Inference.html" target="_blank" rel="noopener noreferrer">#Inference</a>
<a class="button" href="articles/Batch.html" target="_blank" rel="noopener noreferrer">#Batch</a>
<span class="issue_date">Issue Date: 2025-07-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2263" target="_blank" rel="noopener noreferrer" class="title-link">LLMæ¨è«–ã«é–¢ã™ã‚‹æŠ€è¡“ãƒ¡ãƒ¢, iwashi.co, 2025.07</a>
<span class="snippet"><span>Comment</span><p>```<br>ãƒ¡ãƒ¢ãƒª (GB) = P Ã— (Q Ã· 8) Ã— (1 + ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰)<br><br>- Pï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ï¼ˆå˜ä½ã¯10å„„ï¼‰<br>- Qï¼šãƒ“ãƒƒãƒˆç²¾åº¦ï¼ˆä¾‹ï¼š16ã€32ï¼‰ã€8ã§å‰²ã‚‹ã“ã¨ã§ãƒ“ãƒƒãƒˆã‚’ãƒã‚¤ãƒˆã«å¤‰æ›<br>- ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ï¼ˆï¼…ï¼‰ï¼šæ¨è«–ä¸­ã®è¿½åŠ ãƒ¡ãƒ¢ãƒªã¾ãŸã¯ä¸€æ™‚çš„ãªä½¿ç”¨é‡ï¼ˆä¾‹ï¼šKVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒƒãƒ•ã‚¡ã€ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®çŠ¶æ…‹ï¼‰<br>```<br><br>â†‘ã“ã‚Œã€å¿˜ã‚ŒãŒã¡ãªã®ã§ãƒ¡ãƒ¢â€¦</p>
<p>é–¢é€£ï¼ˆé‡å­åŒ–é–¢é€£ç ”ç©¶ï¼‰:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2264" target="_blank" rel="noopener noreferrer">[Paper Note] AWQ: Activation-aware Weight Quantization for LLM Compression and   Acceleration, Ji Lin+, MLSys'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1570" target="_blank" rel="noopener noreferrer">SmoothQuant: Accurate and Efficient Post-Training Quantization for Large   Language Models, Guangxuan Xiao+, ICML'23</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1043" target="_blank" rel="noopener noreferrer">GPTQ: Accurate Post-Training Quantization for Generative Pre-trained   Transformers, Elias Frantar+, N/A, ICLR'23</a>
</p>
<p>ã™ã”ã„ãƒ¡ãƒ¢ã â€¦å‹‰å¼·ã«ãªã‚Šã¾ã™</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="articles/SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<span class="issue_date">Issue Date: 2025-07-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2228" target="_blank" rel="noopener noreferrer" class="title-link">è«–æ–‡ã§ã¯èªã‚‰ã‚Œãªã„LLMé–‹ç™ºã«ãŠã„ã¦é‡è¦ãªã“ã¨ Swallow Projectã‚’é€šã—ã¦, Kazuki Fujii, NLPã‚³ãƒ­ã‚­ã‚¦ãƒ , 2025.07</a>
<span class="snippet"><span>Comment</span><p>ç‹¬è‡ªLLMé–‹ç™ºã®ç§ã®æƒ³åƒãªã©é¥ã‹ã«è¶…ãˆã‚‹éå¸¸ã«å›°é›£ãªå´é¢ãŒè¨˜è¿°ã•ã‚Œã¦ãŠã‚Šã€ã“ã‚Œã‚’ã§ãã‚‹ã®ã¯ã‚ã¾ã‚Šã«ã‚‚ã™ã”ã„ã¨ã„ã†æ„Ÿæƒ³ã‚’æŠ±ã„ãŸï¼ˆå°ä¸¦æ„Ÿã ã‘ã©æœ¬å½“ã«ã™ã”ã„ã¨æ€ã†ã€‚ã™ã”ã„ã¨ã—ã‹è¨€ã„ã‚ˆã†ãŒãªã„ï¼‰</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Optimizer.html" target="_blank" rel="noopener noreferrer">#Optimizer</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="articles/read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="articles/Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<a class="button" href="articles/KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="articles/Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2195" target="_blank" rel="noopener noreferrer" class="title-link">Kimi K2: Open Agentic Intelligence, moonshotai, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kimi_moonshot/status/1943687594560332025?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>1T-A32Bã®ãƒ¢ãƒ‡ãƒ«ã€‚ã•ã™ãŒã«é«˜æ€§èƒ½ã€‚<br><br><img src="https://github.com/user-attachments/assets/39b524d3-6e22-456d-8d61-fcd22519d58d" alt="image" loading="lazy"><br><br>ï¼ˆè¿½è¨˜ï¼‰ Reasoningãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„ã®ã«ã“ã®æ€§èƒ½ã®ã‚ˆã†ã§ã‚ã‚‹ã€‚</p>
<p>1T-A32Bã®ãƒ¢ãƒ‡ãƒ«ã‚’15.5Tãƒˆãƒ¼ã‚¯ãƒ³è¨“ç·´ã™ã‚‹ã®ã«ä¸€åº¦ã‚‚training instabilityãŒãªã‹ã£ãŸã‚‰ã—ã„<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/eliebakouch/status/1943689105721667885?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2188" target="_blank" rel="noopener noreferrer">[Paper Note] Spike No More: Stabilizing the Pre-training of Large Language Models, Sho Takase+, COLM'25</a>
</p>
<p>é‡å­åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒå‡ºãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ivanfioravanti/status/1944069021709615119?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>ä»•äº‹æ—©ã™ãã‚‹<p>DeepSeek V3/R1ã¨ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®é•ã„:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rasbt/status/1944056316424577525?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<br><br>MLAã®ãƒ˜ãƒƒãƒ‰ã®æ•°ãŒæ¸›ã‚Šã€ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®æ•°ã‚’å¢—åŠ ã•ã›ã¦ã„ã‚‹<p>è§£èª¬ãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1944902706747072678?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>åˆ©ç”¨ã•ã‚Œã¦ã„ã‚‹Optimizer:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
</p>
<p>2ã¤ã»ã©ãƒã‚°ãŒã‚ã‚Šä¿®æ­£ã•ã‚ŒãŸæ¨¡æ§˜:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kimi_moonshot/status/1945050874067476962?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>chatbot arenaã§OpenLLMã®ä¸­ã§ãƒˆãƒƒãƒ—ã®ã‚¹ã‚³ã‚¢<br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lmarena_ai/status/1945866381880373490?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒšãƒ¼ãƒ‘ãƒ¼ãŒå…¬é–‹:


<a href="https://github.com/MoonshotAI/Kimi-K2/blob/main/tech_report.pdf" target="_blank" rel="noopener noreferrer">https://github.com/MoonshotAI/Kimi-K2/blob/main/tech_report.pdf</a>


<br><br>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1947384629314396302?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ¬ãƒãƒ¼ãƒˆã¾ã¨ã‚:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1947400424622866793?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ä»¥ä¸‹ã®ã‚ˆã†ãªæŠ€è¡“ãŒä½¿ã‚ã‚Œã¦ã„ã‚‹æ¨¡æ§˜<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1937" target="_blank" rel="noopener noreferrer">Rewriting Pre-Training Data Boosts LLM Performance in Math and Code, Kazuki Fujii+, arXiv'25</a>
<br>- MLA <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1621" target="_blank" rel="noopener noreferrer">MHA vs MQA vs GQA vs MLA, Zain ul Abideen, 2024.07</a>
<br>- MuonCip<br>- MuonOptimizer <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2202" target="_blank" rel="noopener noreferrer">[Paper Note] Muon is Scalable for LLM Training, Jingyuan Liu+, arXiv'25</a>
 <br>- QK-Clip<br>  - å‚è€ƒï¼ˆã“ã¡ã‚‰ã¯LayerNormã‚’ä½¿ã£ã¦ã„ã‚‹ãŒï¼‰: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1202" target="_blank" rel="noopener noreferrer">Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision,   Language, Audio, and Action, Jiasen Lu+, N/A, CVPR'24</a>
<br>- RLVR<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
 <br>- Self-Critique<br>  - é–¢é€£: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2274" target="_blank" rel="noopener noreferrer">[Paper Note] Inference-Time Scaling for Generalist Reward Modeling, Zijun Liu+, arXiv'25</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2017" target="_blank" rel="noopener noreferrer">[Paper Note] Writing-Zero: Bridge the Gap Between Non-verifiable Problems and  Verifiable Rewards, Xun Lu, arXiv'25</a>
 <br>- Temperature Decay  <br>  - æœ€åˆã¯Temperatureã‚’é«˜ã‚ã«ã—ãŸæ¢ç´¢å¤šã‚ã«ã€å¾ŒåŠã¯Temperatureã‚’ä½ã‚ã«ã—ã¦åŠ¹ç”¨å¤šã‚ã«ãªã‚‹ã‚ˆã†ã«ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°<br>- Tool useã®ãŸã‚ã®Synthetic Data<br><br>&lt;img width="1058" height="336" alt="Image" src="


&lt;a href="https://github.com/user-attachments/assets/74eacdb2-8f64-4d53-b2d0-66df770f2e8b"" target="_blank" rel="noopener noreferrer"&gt;https://github.com/user-attachments/assets/74eacdb2-8f64-4d53-b2d0-66df770f2e8b"&lt;/a&gt;


/&gt;</p>
<p>Reward Hackingã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€RLVRã§ã¯ãªãpairwise comparisonã«åŸºã¥ãself judging w/ critique ã‚’åˆ©ç”¨ãã¦ãŠã‚Šã€ã“ã‚ŒãŒéå¸¸ã«åŠ¹æœçš„ãªå¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ã¯ã€ã¨ã„ã†æ„è¦‹ãŒã‚ã‚‹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/grad62304977/status/1953408751521632401?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="articles/LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="articles/SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="articles/MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="articles/OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="articles/OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2164" target="_blank" rel="noopener noreferrer" class="title-link">SmolLM3: smol, multilingual, long-context reasoner, HuggingFace, 2025.07</a>
<span class="snippet"><span>Comment</span><p>å…ƒãƒã‚¹ãƒˆ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/thom_wolf/status/1942670704278732978?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>SmolLM3ã‚’æ§‹ç¯‰ã™ã‚‹éš›ã®è©³ç´°ãªãƒ¬ã‚·ãƒ”(ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒ‡ãƒ¼ã‚¿ã€data mixture, 3 stageã®pretraining(web, code, mathã®å‰²åˆã¨å“è³ªã‚’ã‚¹ãƒ†ãƒ¼ã‚¸ã”ã¨ã«å¤‰ãˆã€stable-&gt;stable-&gt;decayã§å­¦ç¿’), midtraining(long context-&gt;reasoning, post training(sft-&gt;rl), ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰reasoningãƒ¢ãƒ‡ãƒ«ã®ä½œã‚Šæ–¹ã€è©•ä¾¡ãªã©)ãŒèª¬æ˜ã•ã‚Œã¦ã„ã‚‹</p>
<p>å­¦ç¿’/è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆãªã©ãŒãƒªãƒªãƒ¼ã‚¹:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_lewtun/status/1950209751066742982?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Zero/FewShotLearning.html" target="_blank" rel="noopener noreferrer">#Zero/FewShotLearning</a>
<span class="issue_date">Issue Date: 2025-06-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2042" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Language Models are Unsupervised Multitask Learners, Radford+, OpenAI, 2019</a>
&lt;span class=\"snippet\"&gt;<span>Comment</span><p>ä»Šæ›´ãªãŒã‚‰ã€GPT-2è«–æ–‡ã‚’ãƒ¡ãƒ¢ã£ã¦ãªã‹ã£ãŸã®ã§è¿½åŠ ã€‚<br><br>å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã¯ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‚’è§£ããŸã‚ã«ã‚¿ã‚¹ã‚¯ã”ã¨ã«å€‹åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’Finetuningã™ã‚‹å¿…è¦ãŒã‚ã£ãŸãŒã€å¤§è¦æ¨¡ãªWebTextãƒ‡ãƒ¼ã‚¿ï¼ˆRedditã«ãŠã„ã¦æœ€ä½3ã¤ã®upvoteã‚’å¾—ãŸãƒã‚¹ãƒˆã®å¤–éƒ¨ãƒªãƒ³ã‚¯ã‚’åé›†ï¼‰ã«ã‚ˆã£ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã•ã›ã‚‹ã“ã¨ã§ã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã§é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã§ãã€Zero-Shot task transfer, p\(output | input, task) , ãŒå®Ÿç¾ã§ãã‚‹ã‚ˆã€ã¨ã„ã†è©±ã€‚<br><br>ä»Šã–ã£ãã‚Šè¦‹è¿”ã™ã¨ã€Next Token Predictionã¨ã„ã†ç”¨èªã¯è«–æ–‡ä¸­ã«å‡ºã¦ãã¦ãŠã‚‰ãšã€ã‹ã¤ \"Language Modeling\" ã¨ã„ã†ç”¨èªã®ã¿ã§å…·ä½“çš„ãªlossã¯è¨˜è¿°ã•ã‚Œã¦ãŠã‚‰ãšï¼ˆå½“æ™‚ã¯RNNè¨€èªãƒ¢ãƒ‡ãƒ«ã§åºƒãå­¦ç¿’æ–¹æ³•ãŒçŸ¥ã‚‰ã‚Œã¦ã„ãŸã‹ã‚‰ã ã‚ã†ã‹ï¼Ÿï¼‰ã€ã‹ã¤ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚‚å­¦ç¿’ã®ã‚³ãƒ¼ãƒ‰ã¯æä¾›ã•ã‚Œã¦ãŠã‚‰ãšã€lossã®å®šç¾©ã‚‚å«ã¾ã‚Œã¦ã„ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚<br><br>ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®ãƒ¢ãƒ‡ãƒ«å®šç¾©:<br>


<a href="https://github.com/openai/gpt-2/blob/master/src/model.py#L169" target="_blank" rel="noopener noreferrer">https://github.com/openai/gpt-2/blob/master/src/model.py#L169</a>


</p>&lt;/span&gt;<br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-05-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1953" target="_blank" rel="noopener noreferrer" class="title-link">Stanford Alpaca: An Instruction-following LLaMA Model, Taori +, 2023.03</a>
<span class="snippet"><span>Comment</span><p>ä»Šæ›´ãªãŒã‚‰ãƒ¡ãƒ¢ã«è¿½åŠ ã€‚ã‚¢ã‚«ãƒ‡ãƒŸã‚¢ã«ãŠã‘ã‚‹OpenLLMã«å¯¾ã™ã‚‹Instruction Tuningã®å…ˆé§†ã‘çš„ç ”ç©¶ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/LLMAgent.html" target="_blank" rel="noopener noreferrer">#LLMAgent</a>
<a class="button" href="articles/Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="articles/API.html" target="_blank" rel="noopener noreferrer">#API</a>
<span class="issue_date">Issue Date: 2025-04-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1875" target="_blank" rel="noopener noreferrer" class="title-link">BFCLv2, UC Berkeley, 2024.08</a>
<span class="snippet"><span>Comment</span><p>LLMã®Tool Useã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ç¾åœ¨ã®ãƒ‡ãƒ•ã‚¡ã‚¯ãƒˆã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã¨ãªã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</p>
<p>BFCLv3:<br>


<a href="https://gorilla.cs.berkeley.edu/blogs/13_bfcl_v3_multi_turn.html" target="_blank" rel="noopener noreferrer">https://gorilla.cs.berkeley.edu/blogs/13_bfcl_v3_multi_turn.html</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-03-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1834" target="_blank" rel="noopener noreferrer" class="title-link">è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç‰©ç†å­¦, ä½è—¤ç«œé¦¬, 2025.03</a>
<span class="snippet"><span>Comment</span><p>å¿…èª­</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="articles/SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<span class="issue_date">Issue Date: 2025-03-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1830" target="_blank" rel="noopener noreferrer" class="title-link">Nemotron-H: A Family of Accurate, Efficient Hybrid Mamba-Transformer Models, Nvidia, 2025.03</a>
<span class="snippet"><span>Comment</span><p>é–¢é€£:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1820" target="_blank" rel="noopener noreferrer">Hunyuan T1, Tencent, 2025.03</a>
</p>
<p>Transformerã®Self-attention Layerã‚’Mamba2 Layerã«ç½®æ›ã™ã‚‹ã“ã¨ã§ã€æ§˜ã€…ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§åŒç­‰ã®æ€§èƒ½ã€ã‚ã‚‹ã„ã¯ä¸Šå›ã‚‹æ€§èƒ½ã§3å€ç¨‹åº¦ã®Inference timeã®é«˜é€ŸåŒ–ã‚’ã—ã¦ã„ã‚‹ï¼ˆ65536 input, 1024 outputï¼‰ã€‚<br><br>56Bç¨‹åº¦ã®mediumã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã¨ã€8Bç¨‹åº¦ã®è»½é‡ãªãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦è¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ç‰¹ã«ã€8Bãƒ¢ãƒ‡ãƒ«ã§Mambaã¨Transformerã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ã¨ã€é€šå¸¸ã®Transformerãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒã—ã¦ã„ã‚‹ã€‚å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«15 Trillion Tokenã‚’åˆ©ç”¨ã—ã¦ãŠã‚Šã€ã“ã®ãƒ‡ãƒ¼ã‚¿é‡ã§ã®Apple to Appleã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£é–“ã®æ¯”è¼ƒã¯ã€ç¾çŠ¶ã§ã¯æœ€ã‚‚å¤§è¦æ¨¡ãªã‚‚ã®ã¨ã®ã“ã¨ã€‚æ€§èƒ½ã¯å¤šãã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã«ã—ã¦ã‚‚åŒç­‰ã€Commonsense Understandingã§ã¯ä¸Šå›ã£ã¦ã„ã‚‹ã€‚<br><br>ã¾ãŸã€å­¦ç¿’ã—ãŸNemotron-Hã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦æŒã¤VLMã«ã¤ã„ã¦ã‚‚ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒè¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/python.html" target="_blank" rel="noopener noreferrer">#python</a>
<a class="button" href="articles/LLMServing.html" target="_blank" rel="noopener noreferrer">#LLMServing</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1755" target="_blank" rel="noopener noreferrer" class="title-link">SGlang, sgl-project, 2024.01</a>
<span class="snippet"><span>GPT Summary</span>- SGLangã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¨è¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®é«˜é€Ÿã‚µãƒ¼ãƒ“ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®å…±åŒè¨­è¨ˆã«ã‚ˆã‚Šè¿…é€Ÿãªã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿç¾ã—ã¾ã™ã€‚ä¸»ãªæ©Ÿèƒ½ã«ã¯ã€é«˜é€Ÿãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã€æŸ”è»Ÿãªãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¨€èªã€åºƒç¯„ãªãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒ¼ãƒˆãŒã‚ã‚Šã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®æ´»ç™ºãªã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«æ”¯ãˆã‚‰ã‚Œã¦ã„ã¾ã™ã€‚</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1733" target="_blank" rel="noopener noreferrer">Open R1, HuggingFace, 2025.01</a>
<br><br>ã®Update2ã§Math Datasetã®ç”Ÿæˆã«åˆ©ç”¨ã•ã‚ŒãŸLLM Servingãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‚åˆ©ç”¨å‰ã¨æ¯”è¼ƒã—ã¦ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãŒ2å€ã«ãªã£ãŸã¨ã®ã“ã¨ã€‚</p>
<p>CPU, external storageã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§TTFTã‚’æ”¹å–„ã™ã‚‹ã‚ˆã†ã«ãªã£ãŸã‚ˆã†ã§ã€æœ€å¤§80%TTFTãŒå‰Šæ¸›ã•ã‚Œã‚‹ã¨ã®è¨˜è¿°ãŒã‚ã‚‹ã€‚<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/lm_zheng/status/1966312698100203994?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


<p>ï¼ˆåŸç†çš„ã«ã¯å…ƒæ¥å¯èƒ½ã ãŒè¨ˆç®—åŠ¹ç‡ã®æœ€é©åŒ–ã«åŸºã¥ãèª¤å·®ã«ã‚ˆã£ã¦å®Ÿè£…ä¸Šã®å•é¡Œã§å®Ÿç¾ã§ãã¦ã„ãªã‹ã£ãŸ) Deterministic Inferenceã‚’ã‚µãƒãƒ¼ãƒˆ:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ying11231/status/1970250780394569819?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loadingâ€¦</div>
</div>


</span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="articles/RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="articles/Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-02-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1743" target="_blank" rel="noopener noreferrer" class="title-link">DeepSeek-R1ã®è«–æ–‡èª­ã‚“ã ï¼Ÿã€å‹‰å¼·ã«ãªã‚‹ã‚ˆã€‘ , asap, 2025.01</a>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1655" target="_blank" rel="noopener noreferrer">DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open
  Language Models, Zhihong Shao+, arXiv'24</a>
</p>
<p>ã¨ã¦ã‚‚ä¸å¯§ã§ã‚ã‹ã‚Šã‚„ã™ã‹ã£ãŸã€‚å¾Œã§èª­ã‚“ã å†…å®¹ã‚’æ›¸ã„ã¦å¾©ç¿’ã™ã‚‹ã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="articles/PEFT(Adaptor/LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="articles/PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/528" target="_blank" rel="noopener noreferrer" class="title-link">LoRAè«–æ–‡è§£èª¬, Hayato Tsukagoshi, 2023.04</a>
<span class="snippet"><span>Comment</span><p>ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ä¸€éƒ¨ã®ç·šå½¢å±¤ã®éš£ã«ã€ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—A,Bã‚’å°å…¥ã—ã€A,Bã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’finetuningã®å¯¾è±¡ã¨ã™ã‚‹ã“ã¨ã§ã€ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’æ¿€æ¸›ã•ã›ãŸä¸Šã§åŒç­‰ã®äºˆæ¸¬æ€§èƒ½ã‚’é”æˆã—ã€æ¨è«–é€Ÿåº¦ã‚‚å¤‰ã‚ã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹finetuningæ‰‹æ³•ã®è§£èª¬</p>
<p>LoRAã‚’ä½¿ã†ã¨ã€ã§ã‹ã™ãã‚‹ãƒ¢ãƒ‡ãƒ«ã ã¨ã€ãã‚‚ãã‚‚GPUã«è¼‰ã‚‰ãªã„å•é¡Œã‚„ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã§ã‹ã™ããƒ¯ãƒ­ã‚¿å•é¡ŒãŒå›é¿ã§ãã‚‹ã€‚<br><br>å‰è€…ã¯äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®BPã®ãŸã‚ã®å‹¾é…ã‚’ä¿å­˜ã—ã¦ãŠãå¿…è¦ãŒãªããªã‚‹ãŸã‚å­¦ç¿’æ™‚ã«ãƒ¡ãƒ¢ãƒªç¯€ç´„ã«ãªã‚‹ã€‚å¾Œè€…ã¯A,Bã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã ã‘ä¿å­˜ã™ã‚Œã°ã„ã„ã®ã§ã€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ç¯€ç´„ã«ãªã‚‹ã€‚<br><br>ã‹ã¤ã€å­¦ç¿’é€Ÿåº¦ãŒ25%ç¨‹åº¦æ—©ããªã‚‹ã€‚</p>
<p>æ—¢å­˜ç ”ç©¶ã§ã‚ã‚‹Adapterï¼ˆtransformerã®ä¸­ã«å­¦ç¿’å¯èƒ½ãªMLPã‚’å·®ã—è¾¼ã‚€æ‰‹æ³•ï¼‰ã¯æ¨è«–ã‚³ã‚¹ãƒˆãŒå¢—åŠ ã—ã€prefix tuningã¯å­¦ç¿’ãŒéå¸¸ã«é›£ã—ãã€é«˜ã„æ€§èƒ½ã‚’é”æˆã™ã‚‹ãŸã‚ã«prefixã¨ã—ã¦128 tokenå…¥ã‚ŒãŸã‚Šã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€‚</p>
<p>huggingfaceãŒã™ã§ã«LoRAã‚’å®Ÿè£…ã—ã¦ã„ã‚‹<br>


<a href="https://github.com/huggingface/peft" target="_blank" rel="noopener noreferrer">https://github.com/huggingface/peft</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="articles/CVPR.html" target="_blank" rel="noopener noreferrer">#CVPR</a>
<a class="button" href="articles/Backbone.html" target="_blank" rel="noopener noreferrer">#Backbone</a>
<span class="issue_date">Issue Date: 2021-11-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/430" target="_blank" rel="noopener noreferrer" class="title-link">Deep Residual Learning for Image Recognition, He+, Microsoft Research, CVPRâ€™16</a>
<span class="snippet"><span>Comment</span><p>ResNetè«–æ–‡<br><br>ResNetã§ã¯ã€ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®è¨ˆç®—ã™ã‚‹é–¢æ•°ã‚’ã€æ®‹å·®F(x)ã¨æ’ç­‰é–¢æ•°xã®å’Œã¨ã—ã¦å®šç¾©ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒå…¥åŠ›ã¨ã®å·®åˆ†ã ã‘ã‚’å­¦ç¿’ã™ã‚Œã°è‰¯ããªã‚Šã€ãƒ¢ãƒ‡ãƒ«ã‚’æ·±ãã—ã¦ã‚‚æœ€é©åŒ–ãŒã—ã‚„ã™ããªã‚‹åŠ¹æœãã‚ã‚‹ã€‚æ•°ãƒ¬ã‚¤ãƒ¤ãƒ¼ã”ã¨ã«Residual Connectionã‚’å°å…¥ã—ã€æ’ç­‰é–¢æ•°ã«ã‚ˆã‚‹ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆãŒã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/140301726-1d2e89e1-1d69-43d9-8d2b-0adb272e577a.png" alt="image" loading="lazy"><br><br><br><br>ResNetãŒææ¡ˆã•ã‚Œã‚‹ä»¥å‰ã€ãƒ¢ãƒ‡ãƒ«ã‚’æ·±ãã™ã‚Œã°è¡¨ç¾åŠ›ãŒä¸ŠãŒã‚‹ã¯ãšãªã®ã«ã€å®Ÿéš›ã«ã¯ç²¾åº¦ãŒä¸‹ãŒã£ã¦ã—ã¾ã†ã“ã¨ã‹ã‚‰ã€ç†è«–ä¸Šãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒæ’ç­‰é–¢æ•°ã¨ãªã‚‹ã‚ˆã†ã«åˆæœŸåŒ–ã™ã‚Œã°ã€æ·±ã„ãƒ¢ãƒ‡ãƒ«ã§ã‚‚æµ…ã„ãƒ¢ãƒ‡ãƒ«ã¨åŒç­‰ã®è¡¨ç¾ãŒç²å¾—ã§ãã‚‹ã€ã¨è¨€ã†è€ƒãˆæ–¹ã‚’ç™ºå±•ã•ã›ãŸã€‚<br><br><br><br>ï¼ˆã‚¹ãƒ†ãƒ¼ãƒˆã‚ªãƒ–AIã‚¬ã‚¤ãƒ‰ã«åŸºã¥ãï¼‰</p>
<p>åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã§ã‚ˆã‚Šå±¤ã‚’æ·±ãã§ãã‚‹ï¼ˆPlainãªæ§‹é€ ã¨æ¯”ã¹ã‚‹ã¨å±¤ãŒ1ã¤å¢—ãˆã‚‹ï¼‰Bottleneckã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚‚ææ¡ˆã—ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/140302452-649b0ea7-cce4-44c1-9e7d-b509ef8bca52.png" alt="image" loading="lazy"><br><br></p>
<p>ä»Šã‚„å½“ãŸã‚Šå‰ã®ã‚ˆã†ã«ä½¿ã‚ã‚Œã¦ã„ã‚‹Residual Connectionã¯ã€å±¤ã®æ·±ã„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã«å¿…é ˆã®æŠ€è¡“ãªã®ã ã¨å†èªè­˜ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2019-11-09</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/329" target="_blank" rel="noopener noreferrer" class="title-link">äº‹å‰å­¦ç¿’è¨€èªãƒ¢ãƒ‡ãƒ«ã®å‹•å‘ _ Survey of Pretrained Language Models, Kyosuke Nishida, 2019</a>
<span class="snippet"><span>Comment</span><p>[2019/06ã¾ã§]<br><br>ãƒ»ELMoï¼ˆåŒæ–¹å‘2å±¤LSTMè¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ãƒ»GPTï¼ˆleft-to-rightã®12å±¤Transformerè‡ªå·±å›å¸°è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ãƒ»BERTï¼ˆ24å±¤ã®TransformeråŒæ–¹å‘è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ãƒ»MT-DNNï¼ˆBERTã®ä¸Šã«ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å±¤ã‚’è¿½åŠ ã—ãŸç ”ç©¶ï¼‰<br><br>ãƒ»XLMï¼ˆãƒ‘ãƒ©ãƒ¬ãƒ«ç¿»è¨³ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ç”¨ã„ã¦ã‚¯ãƒ­ã‚¹ãƒªãƒ³ã‚¬ãƒ«ã«ç©´åŸ‹ã‚ã‚’å­¦ç¿’ï¼‰<br><br>ãƒ»TransformerXLï¼ˆç³»åˆ—é•·ã„ã«åˆ¶é™ã®ã‚ã£ãŸæ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã«ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ã®å†å¸°ã‚’å°å…¥ã—é•·ã„ç³»åˆ—ã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«ï¼‰<br><br>ãƒ»GPT-2ï¼ˆ48å±¤Transformerã®è‡ªå·±å›å¸°è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ãƒ»ERNIE 1.0ï¼ˆBaidu, ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã¨ãƒ•ãƒ¬ãƒ¼ã‚ºã®å¤–éƒ¨çŸ¥è­˜ã‚’ä½¿ã£ã¦ãƒã‚¹ã‚¯ã«åˆ©ç”¨ï¼‰<br><br>ãƒ»ERNIEï¼ˆTsinghua, çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®æƒ…å ±ã‚’fusionã—ãŸLMï¼‰<br><br>ãƒ»Gloverï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³ã€æ—¥ä»˜ã€è‘—è€…ãªã©ã‚’æ¡ä»¶ã¨ã—ãŸç”Ÿæˆã‚’å¯èƒ½ã¨ã—ãŸGPTï¼‰<br><br>ãƒ»MASSï¼ˆEncoder-Decoderå‹ã®ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®äº‹å‰å­¦ç¿’ï¼‰<br><br>ãƒ»UniLMï¼ˆSequence-to-Sequenceã‚’å¯èƒ½ã«ã—ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ãƒ»XLNetï¼ˆè‡ªå·±å›å¸°ï¼ˆå˜æ–¹å‘ï¼‰ãƒ¢ãƒ‡ãƒ«ã¨åŒæ–¹å‘ãƒ¢ãƒ‡ãƒ«ã®ä¸¡æ–¹ã®åˆ©ç‚¹ã‚’å¾—ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ï¼‰<br><br><br><br>[2019/07~]<br><br>ãƒ»SpanBERTï¼ˆi.i.dã§ã¯ãªãç¯„å›²ã§ãƒã‚¹ã‚¯ã—ã€åŒæ™‚ã«ç¯„å›²ã®å¢ƒç•Œã‚‚äºˆæ¸¬ã™ã‚‹ï¼‰<br><br>ãƒ»ERNIE 2.0ï¼ˆBaidu, ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯äº‹å‰å­¦ç¿’; å˜èªãƒ¬ãƒ™ãƒ«ãƒ»æ§‹é€ ãƒ¬ãƒ™ãƒ«ãƒ»æ„å‘³ãƒ¬ãƒ™ãƒ«ï¼‰<br><br>ãƒ»RoBERTaï¼ˆBERTã¨åŒã˜æ§‹é€ ã§å·¥å¤«ã‚’åŠ ãˆã‚‹ã“ã¨ã§æ€§èƒ½å‘ä¸Šï¼‰<br><br>ã€€- ã‚ˆã‚Šå¤§ããªãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ä½¿ã†ï¼ˆ256ã‹ã‚‰8192ï¼‰<br><br>ã€€- ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã†ï¼ˆ16GBã‹ã‚‰160GBï¼‰<br><br>ã€€- ã‚ˆã‚Šé•·ã„ã‚¹ãƒ†ãƒƒãƒ—æ•°ã®å­¦ç¿’ã‚’ã™ã‚‹ï¼ˆBERTæ›ç®—ã§16å€ï¼‰<br><br>ã€€- æ¬¡æ–‡äºˆæ¸¬ï¼ˆNSPï¼‰ã¯ä¸è¦<br><br>ã€€â†’ GLUEã§BERT, XLNetã‚’outperform<br><br>ãƒ»StructBERT (ALICE, NSPã«ä»£ã‚ã‚‹å­¦ç¿’ã®ç›®çš„é–¢æ•°ã‚’å·¥å¤«)<br><br>ã€€- ãƒã‚¹ã‚¯ã—ãŸä¸Šã§å˜èªã®é †ç•ªã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—å…ƒã«æˆ»ã™<br><br>ã€€- ãƒ©ãƒ³ãƒ€ãƒ ãƒ»æ­£é †ãƒ»é€†é †ã®3ç¨®é¡ã‚’åˆ†é¡<br><br>ã€€â†’ BERTã¨åŒã‚µã‚¤ã‚ºã€åŒãƒ‡ãƒ¼ã‚¿ã§BERT, RoBERTaè¶…ãˆ<br><br>ãƒ»DistilBERTï¼ˆè’¸ç•™ã«ã‚ˆã‚Šã€12å±¤BERTã‚’6å±¤ã«å°å‹åŒ–ï¼ˆ40%æ¸›ï¼‰ï¼‰<br><br>ã€€- BERTã®å‡ºåŠ›ã‚’æ•™å¸«ã¨ã—ã¦ã€ç”Ÿå¾’ãŒåŒã˜å‡ºåŠ›ã‚’å‡ºã™ã‚ˆã†ã«å­¦ç¿’<br><br>ã€€- å¹…ï¼ˆéš ã‚Œå±¤ï¼‰ã‚µã‚¤ã‚ºã‚’æ¸›ã‚‰ã™ã¨ã€å±¤æ•°ã‚’çµŒã‚ï½’ã‚¹ã‚ˆã‚Šã‚‚æ‚ªåŒ–<br><br>ã€€â†’ æ¨è«–ã¯60%é«˜é€ŸåŒ–ã€ç²¾åº¦ã¯95%ç¨‹åº¦ã‚’ä¿æŒ<br><br>ãƒ»Q8BERTï¼ˆç²¾åº¦ã‚’è½ã¨ã•ãšã«fine-tuningæ™‚ã«BERTã‚’8bitæ•´æ•°ã«é‡å­åŒ–ï¼‰<br><br>ã€€- Embedding, FCã¯8bitåŒ–ã€softmax, LNorm, GELUã¯32bitã‚’ã‚­ãƒ¼ãƒ—<br><br>ã€€â†’ ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º1/4, é€Ÿåº¦3.7å€<br><br>ãƒ»CTRLï¼ˆæ¡ä»¶ä»˜ãè¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰<br><br>ã€€- æ¡ä»¶ã¨ãªã‚‹åˆ¶å¾¡ãƒ†ã‚­ã‚¹ãƒˆã‚’æœ¬æ–‡ã®å‰ã«ä¸ãˆã¦å­¦ç¿’<br><br>ã€€- 48å±¤/1280æ¬¡å…ƒTransformerï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°1.6Bï¼‰<br><br>ãƒ»MegatronLMï¼ˆ72å±¤ã€éš ã‚ŒçŠ¶æ…‹ã‚µã‚¤ã‚º3072ã€é•·ã•1024; BERTã®24å€ã‚µã‚¤ã‚ºï¼‰<br><br>ãƒ»ALBERTï¼ˆBERTã®å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã™ã¹ã¦å…±æœ‰ã™ã‚‹ã“ã¨ã§å­¦ç¿’ã‚’é«˜é€ŸåŒ–; 2020å¹´ã‚ãŸã‚Šã®ãƒ‡ãƒ•ã‚¡ã‚¯ãƒˆï¼‰<br><br>ã€€- Largeã‚’è¶…ãˆãŸãƒ¢ãƒ‡ãƒ«ã¯å­¦ç¿’ãŒé›£ã—ã„ãŸã‚ã€è¡¨ç¾ã¯è½ã¡ã‚‹ãŒå­¦ç¿’ã—ã‚„ã™ãã—ãŸ<br><br>ã€€- å˜èªåŸ‹ã‚è¾¼ã¿ã‚’ä½æ¬¡å…ƒã«ã™ã‚‹ã“ã¨ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°å‰Šæ¸›<br><br>ã€€- æ¬¡æ–‡äºˆæ¸¬ã‚’ã€æ–‡ã®é †åºå…¥ã‚Œæ›¿ãˆåˆ¤å®šã«å¤‰æ›´<br><br>ã€€â†’ GLUE, RACE, SQuADã§SoTAã‚’æ›´æ–°<br><br>ãƒ»T5ï¼ˆNLPã‚¿ã‚¹ã‚¯ã‚’ã™ã¹ã¦text-to-textã¨ã—ã¦æ‰±ã„ã€Enc-Dec Transformerã‚’745GBã‚³ãƒ¼ãƒ‘ã‚¹ã§äº‹å‰å­¦ç¿’ã—ã¦è»¢ç§»ã™ã‚‹ï¼‰<br><br>ã€€- ãƒ¢ãƒ‡ãƒ«ã¯Encoder-Decoderã®Transformer<br><br>ã€€- å­¦ç¿’ã‚¿ã‚¹ã‚¯ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ»ãƒ‡ã‚³ãƒ¼ãƒ€ã«åˆã‚ã›ã¦å¤‰æ›´<br><br>ã€€- ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å´ã§ç¯„å›²ã‚’æ¬ è½ã•ã›ã¦ã€ãƒ‡ã‚³ãƒ¼ãƒ€å´ã§äºˆæ¸¬<br><br>ã€€â†’ GLUE, SuperGLUE, SQuAD1.1, CNN/DMã§SoTAæ›´æ–°<br><br>ãƒ»BARTï¼ˆSeq2Seqã®äº‹å‰å­¦ç¿’ã¨ã—ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³ãƒã‚¹ã‚¯ãƒ»å‰Šé™¤ã€ç¯„å›²ãƒã‚¹ã‚¯ã€æ–‡ã®å…¥ã‚Œæ›¿ãˆã€æ–‡æ›¸ã®å›è»¢ã®è¤‡æ•°ã‚¿ã‚¹ã‚¯ã§å­¦ç¿’ï¼‰<br><br>ã€€â†’ CNN/DMã§T5è¶…ãˆã€WMT'16 RO-ENã§é€†ç¿»è¨³ã‚’è¶…ãˆã¦SoTA</p>
<p>ELMo, GPT, BERT, GPT-2, XLNet, RoBERTa, DistilBERT, ALBERT, T5ã‚ãŸã‚Šã¯è‰¯ãè¦‹ã‚‹ã‚ˆã†ãªæ„Ÿ</p>
<p>å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å„ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚‚å¾ŒåŠã«è¨˜è¼‰ã•ã‚Œã¦ãŠã‚Šèˆˆå‘³æ·±ã„ã€‚<br><br><br><br>ã¡ãªã¿ã«ã€CNN/DailyMail Datasetã§ã¯ã€T5, BARTã‚ãŸã‚ŠãŒSoTAã€‚<br><br>R2ã§æ¯”è¼ƒã™ã‚‹ã¨<br><br>ã€€- Pointer-Generator + Coverage VectorãŒ17,28<br><br>ã€€- LEAD-3ãŒ17.62<br><br>ã€€- BARTãŒ21.28<br><br>ã€€- T5ãŒ21.55<br><br>ã¨ãªã£ã¦ã„ã‚‹</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<span class="issue_date">Issue Date: 2019-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/324" target="_blank" rel="noopener noreferrer" class="title-link">Implicit</a>
<span class="snippet"><span>Comment</span><p>Implicitãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹Collaborative Filteringæ‰‹æ³•ãŒã¾ã¨ã¾ã£ã¦ã„ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª<br><br>Bayesian Personalized Ranking, Logistic Matrix Factorizationãªã©ãŒå®Ÿè£…ã€‚</p>
<p>Implicitã®ä½¿ã„æ–¹ã¯ã“ã®è¨˜äº‹ãŒã‚ã‹ã‚Šã‚„ã™ã„ï¼š<br><br>


<a href="https://towardsdatascience.com/building-a-collaborative-filtering-recommender-system-with-clickstream-data-dffc86c8c65" target="_blank" rel="noopener noreferrer">https://towardsdatascience.com/building-a-collaborative-filtering-recommender-system-with-clickstream-data-dffc86c8c65</a>


</p>
<p>ALSã®å…ƒè«–æ–‡ã®æ—¥æœ¬èªè§£èª¬<br><br>


<a href="https://cympfh.cc/paper/WRMF" target="_blank" rel="noopener noreferrer">https://cympfh.cc/paper/WRMF</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<span class="issue_date">Issue Date: 2019-04-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/308" target="_blank" rel="noopener noreferrer" class="title-link">Recommender System Datasets, Julian McAuley</a>
<span class="snippet"><span>Comment</span><p>Recommender Systemsç ”ç©¶ã«åˆ©ç”¨ã§ãã‚‹å„ç¨®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã€Julian McAuleyæ°ãŒã¾ã¨ã‚ã¦ã„ã‚‹ã€‚<br><br>æ°ãŒç‹¬è‡ªã«ã‚¯ãƒ­ãƒ¼ãƒ«ã—ãŸãƒ‡ãƒ¼ã‚¿ç­‰ã‚‚å«ã¾ã‚Œã¦ã„ã‚‹ã€‚<br><br>éå¸¸ã«æœ‰ç”¨ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<span class="issue_date">Issue Date: 2019-01-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/299" target="_blank" rel="noopener noreferrer" class="title-link">Designing and Evaluating Explanations for Recommender Systems, Tintarev+, Recommender Systems Handbook, 2011</a>
<span class="snippet"><span>Comment</span><p>Recommender Systems Handbookã®Chapterã€‚<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/162" target="_blank" rel="noopener noreferrer">[Paper Note] A Survey of Explanations in Recommender Systems, Tintarev+, ICDEW'07</a>
 ã®Surveyã¨åŒã˜è‘—è€…ã«ã‚ˆã‚‹åŸ·ç­†ã€‚<br><br>æ¨è–¦ã®Explanationã¨ã„ãˆã°ã“ã®äººã¨ã„ã†ã‚¤ãƒ¡ãƒ¼ã‚¸ã€‚</p>
<p>Dè«–ï¼š


<a href="http://navatintarev.com/papers/Nava%20Tintarev_PhD_Thesis_(2010).pdf" target="_blank" rel="noopener noreferrer">http://navatintarev.com/papers/Nava%20Tintarev_PhD_Thesis_(2010).pdf</a>


</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="articles/LearningAnalytics.html" target="_blank" rel="noopener noreferrer">#LearningAnalytics</a>
<span class="issue_date">Issue Date: 2018-12-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/294" target="_blank" rel="noopener noreferrer" class="title-link">Educational Data Mining and Learning Analytics, Baker+, 2014</a>
<span class="snippet"><span>Comment</span><p>Ryan Bakerã‚‰ã«ã‚ˆã‚‹EDM Survey</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Classic.html" target="_blank" rel="noopener noreferrer">#Classic</a>
<a class="button" href="articles/ContextAware.html" target="_blank" rel="noopener noreferrer">#ContextAware</a>
<span class="issue_date">Issue Date: 2018-12-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/287" target="_blank" rel="noopener noreferrer" class="title-link">Context-Aware Recommender Systems, Adomavicius+, Recommender Systems Handbook, 2011</a>
<span class="snippet"><span>Comment</span><p>Context-aware Recsysã®ãƒ‘ã‚¤ã‚ªãƒ‹ã‚¢çš„ç ”ç©¶</p>
<p>é€šå¸¸ã®user/item paradigmã‚’æ‹¡å¼µã—ã¦ã€ã„ã‹ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æƒ…å ±ã‚’è€ƒæ…®ã™ã‚‹ã‹ã‚’ç ”ç©¶ã€‚<br><br><br><br>ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã¯ã€<br><br>Explicit: ãƒ¦ãƒ¼ã‚¶ã®ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã‹ã‚‰å–å¾—<br><br>Implicit: è‡ªå‹•çš„ã«å–å¾—<br><br>inferred: ãƒ¦ãƒ¼ã‚¶ã¨ãƒ„ãƒ¼ãƒ«ã‚„ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰æ¨æ¸¬ï¼ˆãŸã¨ãˆã°ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ã®ã‚¿ã‚¹ã‚¯ã¨ã‹ï¼‰<br><br><br><br>ã„ãã¤ã‹ã®ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ãŒææ¡ˆã•ã‚ŒãŸï¼š<br><br><br><br>1. recommendation via context-driven  querying and search approach<br><br>ã€€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æƒ…å ±ã‚’ã€ç‰¹å®šã®ãƒªãƒã‚¸ãƒˆãƒªã®ãƒªã‚½ãƒ¼ã‚¹ï¼ˆãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ï¼‰ã«å¯¾ã—ã¦ã€ã‚¯ã‚¨ãƒªã‚„æ¤œç´¢ã«ç”¨ã„ã‚‹ã€‚ãã—ã¦ã€best matchingãªãƒªã‚½ãƒ¼ã‚¹ã‚’(ãŸã¨ãˆã°ã€ç¾åœ¨é–‹ã„ã¦ã„ã‚‹ã‚‚ã£ã¨ã‚‚è¿‘ã„ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã¨ã‹)ã‚’ãƒ¦ãƒ¼ã‚¶ã«æ¨è–¦ã€‚<br><br><br><br>2. Contextual preference elicitation and estimation approach<br><br>ã€€ã“ã£ã¡ã¯2012å¹´ãã‚‰ã„ã®ä¸»æµã€‚contextual user preferencesã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—å­¦ç¿’ã™ã‚‹ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ã—ã°ã—ã°ã€&lt;user, item, context, rating&gt;ã®å½¢å¼ã§è¡¨ç¾ã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã£ã¦ã€ç‰¹å®šã®ã‚¢ã‚¤ãƒ†ãƒ ãŒç‰¹å®šã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã©ã‚Œã ã‘å¥½ã¾ã‚ŒãŸã‹ã€ãŒè©•ä¾¡ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚<br><br><br><br>3. contextual prefiltering approach<br><br>ã€€contextualãªæƒ…å ±ã‚’ï¼ˆå­¦ç¿’ã—ãŸcontextualãªpreferenceãªã©ã‚’ï¼‰ã€tradittionalãªrecommendation algorithmã‚’é©ç”¨ã™ã‚‹å‰ã«ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ç”¨ã„ã‚‹ã€‚<br><br><br><br>4. contextual postfiltering approach<br><br>ã€€entire setã‹ã‚‰æ¨è–¦ã‚’ä½œã‚Šã€ã‚ã¨ã§contextã®æƒ…å ±ã‚’ä½¿ã£ã¦setã‚’æ•´ãˆã‚‹ã€‚<br><br><br><br>5. Contextual modeling<br><br>ã€€contextualãªæƒ…å ±ã‚’ã€ãã®ã¾ã¾recommendationã®é–¢æ•°ã«ã¶ã¡ã“ã‚“ã§ã—ã¾ã„ã€ã‚¢ã‚¤ãƒ†ãƒ ã®ratingã®explicitãªpredictorã¨ã—ã¦ä½¿ã†ã€‚<br><br><br><br>3, 4ã¯traditionalãªæ¨è–¦ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒé©ç”¨ã§ãã‚‹ã€‚<br><br>1,2,5ã¯multi-dimensionalãªæ¨è–¦ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ãªã‚‹ã€‚heuristic-based, model-based approachesãŒè¿°ã¹ã‚‰ã‚Œã¦ã„ã‚‹ã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Classic.html" target="_blank" rel="noopener noreferrer">#Classic</a>
<a class="button" href="articles/AdaptiveLearning.html" target="_blank" rel="noopener noreferrer">#AdaptiveLearning</a>
<a class="button" href="articles/LearningStyle.html" target="_blank" rel="noopener noreferrer">#LearningStyle</a>
<span class="issue_date">Issue Date: 2018-12-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/284" target="_blank" rel="noopener noreferrer" class="title-link">LEARNING AND TEACHING STYLES IN ENGINEERING EDUCATION, Felder, Engr. Education, 78ï¼ˆ7ï¼‰, 674â€“681, 1988</a>
<span class="snippet"><span>Comment</span><p>LearningStyleã«é–¢ã—ã¦ç ”ç©¶ã—ã¦ã„ã‚‹å¤å…¸çš„ãªç ”ç©¶ã€‚<br><br>context-aware recsysã®ç ”ç©¶åˆæœŸã®é ƒã¯ã€ã ã„ãŸã„ã¯ã“ã®Felder-Silverman Theoryã¨ã„ã†ã®ã‚’ãƒ™ãƒ¼ã‚¹ã«ç ”ç©¶ã•ã‚Œã¦ã„ãŸã‚‰ã—ã„ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="articles/Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/235" target="_blank" rel="noopener noreferrer" class="title-link">è‡ªç„¶è¨€èªå‡¦ç†ã®ãŸã‚ã®Deep Learning, Yuta Kikuchi, 2013.09</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/MatrixFactorization.html" target="_blank" rel="noopener noreferrer">#MatrixFactorization</a>
<span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/225" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Collaborative filtering for implicit feedback datasets, Hu+, International Conference on Data Mining, 2008</a>
<span class="snippet"><span>Comment</span><p>Implicit Feedbackãªãƒ‡ãƒ¼ã‚¿ã«ç‰¹åŒ–ã—ãŸMatrix Factorization (MF)ã€Weighted Matrix Factorization (WMF)ã‚’ææ¡ˆã€‚<br><br>ãƒ¦ãƒ¼ã‚¶ã®ExplicitãªFeedbackï¼ˆratingã‚„like, dislikeãªã©ï¼‰ãŒãªãã¦ã‚‚ã€MFãŒé©ç”¨å¯èƒ½ã€‚<br><br><br><br>ç›®çš„é–¢æ•°ã¯ä¸‹ã®ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã€‚<br><br>é€šå¸¸ã®MFã§ã¯ã€ãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã«rating r_{ui}ã‚’äºˆæ¸¬ã—ãŸã‚Šã™ã‚‹ãŒã€WMFã§ã¯ r_{ui}ã‚’ratingã§ã¯ãªãã€ãŸã¨ãˆã°ãƒ¦ãƒ¼ã‚¶uãŒã‚¢ã‚¤ãƒ†ãƒ iã‚’æ¶ˆè²»ã—ãŸå›æ•°ãªã©ã«ç½®ãæ›ãˆã€binarizeã—ãŸæ•°å€¤p_{ui}ã‚’ç›®çš„é–¢æ•°ã«ç”¨ã„ã‚‹ã€‚<br><br>ã“ã®ã¨ãã€itemã‚’æ¶ˆè²»ã—ãŸå›æ•°ãŒå¤šã„ã»ã©ã€ãã®ãƒ¦ãƒ¼ã‚¶ã¯ãã®itemã‚’å¥½ã‚“ã§ã„ã‚‹ã¨ä»®å®šã—ã€ãã®ã‚ˆã†ãªäº‹ä¾‹ã«ã¤ã„ã¦ã¯é‡ã¿ãŒé«˜ããªã‚‹ã‚ˆã†ã«c_{ui}ã‚’è¨ˆç®—ã—ã€ç›®çš„é–¢æ•°ã«å°å…¥ã—ã¦ã„ã‚‹ã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34815894-79edc89e-f6f6-11e7-9be5-0beacd724c23.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/34815905-80e9f10e-f6f6-11e7-95bb-4ff0506134ad.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/34815909-85c803dc-f6f6-11e7-87a8-8b7007f73524.png" alt="image" loading="lazy"><br><br></p>
<p>æ—¥æœ¬èªã§ã®è§£èª¬: 


<a href="https://cympfh.cc/paper/WRMF" target="_blank" rel="noopener noreferrer">https://cympfh.cc/paper/WRMF</a>


</p>
<p>Implicit <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/324" target="_blank" rel="noopener noreferrer">Implicit</a>
 ã§ã®Alternating Least Square (ALS)ã¨ã„ã†æ‰‹æ³•ãŒã€ã“ã®æ‰‹æ³•ã®å®Ÿè£…ã«è©²å½“ã™ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="articles/SIGIR.html" target="_blank" rel="noopener noreferrer">#SIGIR</a>
<span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/220" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] The Decomposition of Human-Written Summary Sentences. Hongyan Jing et al. SIGIRâ€™99</a>
<span class="snippet"><span>Comment</span><p>å‚ç…§è¦ç´„ - åŸæ–‡æ›¸å¯¾ãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã«ã€å‚ç…§è¦ç´„ä¸­ã®å˜èªã¨åŸæ–‡æ›¸ä¸­ã®å˜èªã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’ã¨ã‚‹HMMãƒ™ãƒ¼ã‚¹ãªæ‰‹æ³•ã‚’ææ¡ˆã€‚<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34812500-2d1d7d32-f6e9-11e7-8d9d-723804236081.png" alt="image" loading="lazy"><br><br><br><br>outputã¯ã“ã‚“ãªæ„Ÿã˜ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="articles/Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="articles/DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="articles/Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="articles/Unsupervised.html" target="_blank" rel="noopener noreferrer">#Unsupervised</a>
<a class="button" href="articles/GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/Extractive.html" target="_blank" rel="noopener noreferrer">#Extractive</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/215" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] LexRank: Graph-based Lexical Centrality as Salience in Text Summarization, Erkan+, Journal of Artificial Intelligence Research, 2004</a>
<span class="snippet"><span>Comment</span><p>ä»£è¡¨çš„ãªã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ãª(Multi) Document Summarizationæ‰‹æ³•ã€‚<br><br>ã»ã¼ <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/214" target="_blank" rel="noopener noreferrer">[Paper Note] TextRank: Bringing Order into Texts, Mihalcea+, EMNLP'04</a>
 ã¨åŒã˜æ‰‹æ³•ã€‚<br><br><br><br>2ç¨®é¡ã®æ‰‹æ³•ãŒææ¡ˆã•ã‚Œã¦ã„ã‚‹ï¼š<br><br><br><br>* [LexRank] tf-idfã‚¹ã‚³ã‚¢ã§sentenceã®bag-of-wordsãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œã‚Šã€cosine similarityã‚’è¨ˆç®—ã—é–¾å€¤ä»¥ä¸Šã¨ãªã£ãŸsentenceã®é–“ã«ã®ã¿edgeã‚’å¼µã‚‹ï¼ˆé‡ã¿ã¯ç¢ºç‡çš„ã«æ­£è¦åŒ–ï¼‰ã€‚ãã®å¾Œã¹ãä¹—æ³•ã§PageRankã€‚<br><br>* [ContinousLexRank] tf-idfã‚¹ã‚³ã‚¢ã§sentenceã®bag-of-wordsãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½œã‚Šã€cosine similarityã‚’ç”¨ã„ã¦Affinity Graphã‚’è¨ˆç®—ã—ã€PageRankã‚’é©ç”¨ï¼ˆã¹ãä¹—æ³•ï¼‰ã€‚<br><br><br><br>DUC2003, 2004ï¼ˆMDSï¼‰ã§è©•ä¾¡ã€‚<br><br>Centroidãƒ™ãƒ¼ã‚¹ãƒ‰ãªæ‰‹æ³•ã‚’ROUGE-1ã®è¦³ç‚¹ã§outperformã€‚<br><br>document clusterã®17%ã‚’Noisyãªãƒ‡ãƒ¼ã‚¿ã«ã—ãŸå ´åˆã‚‚å®Ÿé¨“ã—ã¦ãŠã‚Šã€Noisyãªãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ãŸå ´åˆã‚‚æ€§èƒ½åŠ£åŒ–ãŒå°‘ãªã„ã“ã¨ã‚‚ç¤ºã—ã¦ã„ã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/174" target="_blank" rel="noopener noreferrer" class="title-link">æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ , ç¥å¶Œ, 2016</a>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/CollaborativeFiltering.html" target="_blank" rel="noopener noreferrer">#CollaborativeFiltering</a>
<a class="button" href="articles/Novelty.html" target="_blank" rel="noopener noreferrer">#Novelty</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/46" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] Discovery-oriented Collaborative Filtering for Improving User Satisfaction, Hijikata+, IUIâ€™09</a>
<span class="snippet"><span>Comment</span><p>ãƒ»å¾“æ¥ã®CFã¯accuracyã‚’ã‚ã’ã‚‹ã“ã¨ã‚’ç›®çš„ã«ç ”ç©¶ã•ã‚Œã¦ããŸãŒï¼Œãƒ¦ãƒ¼ã‚¶ãŒã™ã§ã«çŸ¥ã£ã¦ã„ã‚‹itemã‚’æ¨è–¦ã—ã¦ã—ã¾ã†å•é¡ŒãŒã‚ã‚‹ï¼ãŠã¾ã‘ã«ï¼ˆæ¨è–¦ãƒªã‚¹ãƒˆå†…ã®ã‚¢ã‚¤ãƒ†ãƒ ã®è¦³ç‚¹ã‹ã‚‰ã¿ãŸï¼‰diversityã‚‚ä½ã„ï¼ã“ã®ã‚ˆã†ãªæ¨è–¦ã¯discoveryãŒãªãï¼Œuser satisfactionã‚’æã­ã‚‹ã®ã§ï¼Œãƒ¦ãƒ¼ã‚¶ãŒã™ã§ã«ä½•ã‚’çŸ¥ã£ã¦ã„ã‚‹ã‹ã®æƒ…å ±ã‚’ä½¿ã£ã¦ã‚ˆã‚Šdiscoveryã®ã‚ã‚‹æ¨è–¦ã‚’CFã§ã‚„ã‚Šã¾ã—ã‚‡ã†ã¨ã„ã†è©±ï¼<br><br>ãƒ»ç‰¹å¾´ã¨ã—ã¦ãƒ¦ãƒ¼ã‚¶ã®itemã¸ã®ratingã«åŠ ãˆï¼Œãã®itemã‚’ãƒ¦ãƒ¼ã‚¶ãŒçŸ¥ã£ã¦ã„ãŸã‹ã©ã†ã‹explicit feedbackã—ã¦ã‚‚ã‚‰ã†å¿…è¦ãŒã‚ã‚‹ï¼<br><br>ãƒ»æ‰‹æ³•ã¯å˜ç´”ã§ï¼ŒUser-basedï¼Œã‚ã‚‹ã„ã¯Item-based CFã‚’ç”¨ã„ã¦preferenceã¨ã‚ã‚‹itemã‚’ãƒ¦ãƒ¼ã‚¶ãŒçŸ¥ã£ã¦ã„ãã†ã‹ã©ã†ã‹ã®ç¢ºç‡ã‚’æ±‚ã‚ï¼Œãã‚Œã‚‰ã‚’çµ„ã¿åˆã‚ã›ã‚‹ï¼Œã‚ã‚‹ã„ã¯rating-matrixã«ãƒ¦ãƒ¼ã‚¶ãŒã‚ã‚‹itemã‚’çŸ¥ã£ã¦ã„ãŸã‹å¦ã‹ã®æ•°å€¤ã‚’çµ„ã¿åˆã‚ã›ã¦æ–°ãŸãªmatrixã‚’ä½œã‚Šï¼Œãã®matrixä¸Šã§CFã™ã‚‹ã¨ã„ã£ãŸã‚‚ã®ï¼<br><br>ãƒ»offlineè©•ä¾¡ã®çµæœï¼Œé€šå¸¸ã®CFï¼Œtopic diversificationæ‰‹æ³•ã¨æ¯”ã¹ã¦precisionã¯ä½ã„ã‚‚ã®ã®ï¼Œdiscovery ratioã¨precision(novelty)ã¯åœ§å€’çš„ã«é«˜ã„ï¼<br><br>ãƒ»ãƒ¦ãƒ¼ã‚¶ãŒitemã‚’çŸ¥ã£ã¦ã„ãŸã‹ã©ã†ã‹ã¨ã„ã†binary ratingã¯ãƒ¦ãƒ¼ã‚¶ã«è² è·ãŒã‹ã‹ã‚‹ã—ï¼ŒéŸ³æ¥½æ¨è–¦ã®å ´åˆpreviewãŒãªã‘ã‚Œã°ãã‚‚ãã‚‚æä¾›ã•ã‚Œã¦ã„ãªã„ã‹ã‚‰ratingã§ããªã„ãªã©ï¼Œå¿…ãšã—ã‚‚å¤šãé›†ã‚ã‚‰ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã§ã¯ãªã„ï¼ãã“ã§ï¼Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ratingã®æƒ…å ±ã‚’25%, 50%, 75%ã«å‰Šã£ã¦ratingã®æ•°ã«biasã‚’ã‹ã‘ãŸä¸Šã§å®Ÿé¨“ã‚’ã—ã¦ã„ã‚‹ï¼ãã®çµæœï¼Œäº‹å‰ã«ratingã‚’combineã—æ–°ãŸãªmatrixã‚’ä½œã‚‹æ‰‹æ³•ã¯ratingãŒå°‘ãªã„ã¨ã‚ã¾ã‚Šã†ã¾ãã„ã‹ãªã‹ã£ãŸï¼<br><br>ãƒ»ã•ã‚‰ã«onlineã§user satisfactionï¼ˆ3ã¤ã®ç›®çš„ã®ã‚‚ã¨satisfactionã‚’ratingã—ã¦ã‚‚ã‚‰ã†ã€€1. purchase 2. on-demand-listening 3. discoveryï¼‰ã‚’è©•ä¾¡ã—ãŸ. çµæœï¼Œpurchaseã¨discoveryã«ãŠã„ã¦ã¯ï¼Œãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’ä¸Šå›ã£ãŸï¼ãŸã ã—ï¼Œã“ã‚Œã¯æ¨è–¦ãƒªã‚¹ãƒˆä¸­ã®æº€è¶³ã—ãŸitemã®æ•°ã®å•é¡Œã§ï¼Œæ¨è–¦ãƒªã‚¹ãƒˆå…¨ä½“ãŒã©ã†ã ã£ãŸ<br><br>ã€€ã‹ã¨å•ã‚ã‚ŒãŸå ´åˆã¯ï¼Œãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨åŒç­‰ç¨‹åº¦ã ã£ãŸï¼</p>
<p>é‡è¦è«–æ–‡</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="articles/Novelty.html" target="_blank" rel="noopener noreferrer">#Novelty</a>
<a class="button" href="articles/RecSys.html" target="_blank" rel="noopener noreferrer">#RecSys</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/45" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] â€œI like to explore sometimesâ€: Adapting to Dynamic User Novelty Preferences, Kapoor et al. ï¼ˆwith Konstanï¼‰, RecSysâ€™15</a>
<span class="snippet"><span>Comment</span><p>ãƒ»å…¸å‹çš„ãªRSã¯ï¼Œæ¨è–¦ãƒªã‚¹ãƒˆã®Similarityã¨Noveltyã®criteriaã‚’æœ€é©åŒ–ã™ã‚‹ï¼ã“ã®ã¨ãï¼Œä¸¡è€…ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ãŸã‚ã«ãªã‚“ã‚‰ã‹ã®å®šæ•°ã‚’å°å…¥ã—ã¦ãƒãƒ©ãƒ³ã‚¹ã‚’ã¨ã‚‹ãŒï¼Œã“ã®å®šæ•°ã¯ãƒ¦ãƒ¼ã‚¶ã‚„ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã”ã¨ã«ç•°ãªã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã®ã§ï¼ˆã™ãªã‚ã¡äººã‚„ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã«ã‚ˆã£ã¦noveltyã®preferenceãŒå¤‰åŒ–ã™ã‚‹ã¨ã„ã†ã“ã¨ï¼‰ï¼Œãã‚Œã‚’userã®éå»ã®behaviorã‹ã‚‰predictã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’è€ƒãˆã¾ã—ãŸã¨ã„ã†è«–æ–‡ï¼<br><br>ãƒ»å¼ä¸­ã«ã‚ˆãtãŒå‡ºã¦ãã‚‹ãŒï¼Œtã¯familiar setã¨novel setã‚’ã‚ã‘ã‚‹ãŸã‚ã®ã¿ã«ã‚‚ã£ã±ã‚‰ä½¿ã‚ã‚Œã¦ã„ã‚‹ã“ã¨ã«æ³¨æ„ï¼æ˜¼ã ã¨ã‹å¤œã ã¨ã‹ãã†ã„ã†è©±ã§ã¯ãªã„ï¼familiar setã¨ã¯[t-T, t]ã®é–“ã«æ¶ˆè²»ã—ãŸã‚¢ã‚¤ãƒ†ãƒ ï¼Œnovel setã¯familiar setã«å«ã¾ã‚Œãªã„itemã®ã“ã¨ï¼<br><br>ãƒ»ãƒ‡ãƒ¼ã‚¿ã¯music consumption logsã‚’ä½¿ã†ï¼last.fmã‚„proprietary datasetï¼ãƒ‡ãƒ¼ã‚¿ã«listeningä»¥å¤–ã®explicit feedback (rating)ãªã©ã®æƒ…å ±ã¯ãªã„<br><br>ãƒ»itemã®noveltyã®è€ƒãˆæ–¹ã¯ãƒ¦ãƒ¼ã‚¶å´ã‹ã‚‰ã¿ã‚‹ã‹ï¼Œã‚·ã‚¹ãƒ†ãƒ å´ã‹ã‚‰è¦‹ã‚‹ã‹ã§åˆ†é¡ãŒå¤‰ã‚ã‚‹ï¼ä¸‰ç¨®é¡ã®åˆ†é¡ãŒã‚ã‚‹ï¼ <br><br><br><br>(a) new to system: ã‚·ã‚¹ãƒ†ãƒ ã«ã¨ã£ã¦itemãŒæ–°ã—ã„ï¼ã‚†ãˆã«ãƒ¦ãƒ¼ã‚¶ã¯å…¨å“¡ãã®itemã‚’çŸ¥ã‚‰ãªã„ï¼<br><br>(b) new to user: ã‚·ã‚¹ãƒ†ãƒ ã¯itemã‚’çŸ¥ã£ã¦ã„ã‚‹ãŒï¼Œãƒ¦ãƒ¼ã‚¶ã¯çŸ¥ã‚‰ãªã„ï¼<br><br>(c) oblivious/forgotten item: éå»ã«ãƒ¦ãƒ¼ã‚¶ãŒçŸ¥ã£ã¦ã„ãŸãŒï¼Œæœ€å¾Œã®consumptionã‹ã‚‰æ™‚é–“ãŒçµŒéã—ã„ãã¶ã‚“unfamiliarã«ãªã£ãŸitem<br><br><br><br>Repetition of forgotten items in future consumptions has been shown to produce increased diversity and emotional excitement.<br><br><br><br>ã“ã®ç ”ç©¶ã§ã¯(b), (c)ã‚’å¯¾è±¡ã¨ã™ã‚‹ï¼<br><br><br><br>ãƒ»userã®novelty preferenceã«ã¤ã„ã¦äºŒã¤ã®ä»®å®šã‚’ãŠã„ã¦ã„ã‚‹ï¼<br><br>1. ãƒ¦ãƒ¼ã‚¶ã”ã¨ã«novelty preferenceã¯é•ã†ï¼<br><br>2. ãƒ¦ãƒ¼ã‚¶ã®novelty preferenceã¯dynamicã«å¤‰åŒ–ã™ã‚‹ï¼trainingãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã“ã®ä»®å®šã®æ­£ã—ã•ã‚’æ¤œè¨¼ã—ã¦ã„ã‚‹ï¼<br><br><br><br>ãƒ»novelty preferenceã®predictã¯äºŒç¨®é¡ã®ç´ æ€§ï¼ˆfamiliar set diversityã¨cumulative negative preference for items in the familiar setï¼‰ã‚’ä½¿ã†. å‰è€…ã¯ï¼Œfamiliar setã®ä¸­ã®radioã‚’ã©ã‚Œã ã‘ç¹°ã‚Šè¿”ã—ãã„ã¦ã„ã‚‹ã‹ã‚’ç”¨ã„ã¦diversityã‚’å®šç¾©ï¼ç¹°ã‚Šè¿”ã—èã„ã¦ã„ã‚‹ã»ã†ãŒdiversityä½ã„ï¼å¾Œè€…ã¯ï¼Œç•°ãªã‚‹itemã®æ¶ˆè²»ã‚’ã™ã‚‹é–“éš”ã«ã‚ˆã£ã¦dynamic preference scoreã‚’æ±ºå®šï¼familiar setå†…ã®å„itemã«ã¤ã„ã¦è² ã®dynamic preference scoreã‚’summationã™ã‚‹ã“ã¨ã§ï¼Œãƒ¦ãƒ¼ã‚¶ã®â€é€€å±ˆåº¦åˆã„â€ã‚’ç®—å‡ºã—ã¦ã„ã‚‹ï¼<br><br>ãƒ»ä¸¡ç´ æ€§ã‚’è€ƒæ…®ã™ã‚‹ã“ã¨ã§novelty preferenceã®RMSEãŒsignificantã«æ¸›å°‘ã™ã‚‹ã“ã¨ã‚’ç¢ºèªï¼<br><br>ãƒ»æ¨è–¦ã¯Noveltyã®ã‚ã‚‹itemã®æ¨è–¦ã«ã¯Hijikataã‚‰ã®å”èª¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãªã©ã‚’ä½¿ã†ã“ã¨ã‚‚ã§ãã‚‹ï¼<br><br>ãƒ»ã—ã‹ã—ä»Šå›ã¯ç°¡æ˜“ãªitem-based CFã‚’ç”¨ã„ã‚‹ï¼ratingã®æƒ…å ±ãŒãªã„ã®ã§ï¼Œãã‚Œã¯dynamic preference scoreã‚’ä»£ã‚ã‚Šã«ä½¿ã„å„itemã®ã‚¹ã‚³ã‚¢ã‚’æ±‚ã‚ï¼Œãã“ã‹ã‚‰novel recommendationã¨familiar recommendationã®ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã—ï¼Œnovelty preferenceã«ã‚ˆã£ã¦ä¸¡è€…ã‚’çµ„ã¿åˆã‚ã›ã‚‹ï¼<br><br>ãƒ»éŸ³æ¥½ï¼ˆã¨ã„ã†ã‚ˆã‚ŠéŸ³æ¥½ã®radioã‚„ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆï¼‰ã®æ¨è–¦ã‚’è€ƒãˆã¦ã„ã‚‹çŠ¶æ³ãªã®ã§ï¼Œre-consumptionãŒè¨±å®¹ã•ã‚Œã¦ã„ã‚‹ï¼Newsãªã©ã¨ã¯å°‘ã—ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒé•ã†ã“ã¨ã«æ³¨æ„ï¼</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="articles/NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/17" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] A Study for Documents Summarization based on Personal Annotation, Zhang+, HLT-NAACL-DUCâ€™03, 2003.05</a>
<span class="snippet"><span>Comment</span><p>ï¼ˆéå»ã«ç®¡ç†äººãŒä½œæˆã—ãŸã‚¹ãƒ©ã‚¤ãƒ‰ã§ã®è«–æ–‡ãƒ¡ãƒ¢ã®ã‚¹ã‚¯ã‚·ãƒ§ï¼‰<br><br><img src="https://user-images.githubusercontent.com/12249301/34402434-d521f19e-ebe4-11e7-82cf-2f3452fa4014.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/34402437-dbd6db9e-ebe4-11e7-8954-3a0754929ad3.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/34402439-e13bff9c-ebe4-11e7-97b6-dfeb97f7e6af.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/34402446-e8578e2c-ebe4-11e7-970a-f9db5ff0c548.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/34402454-f0c8867e-ebe4-11e7-9c4a-64a727388402.png" alt="image" loading="lazy"><br><br><img src="https://user-images.githubusercontent.com/12249301/34402465-fa26e788-ebe4-11e7-82cd-80df4eb5e2b5.png" alt="image" loading="lazy"><br><br></p>
<p>é‡è¦è«–æ–‡ã ã¨æ€ã‚ã‚Œã‚‹ã€‚</p></span><br><br>
<a class="button" href="articles/Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="articles/PersonalizedDocumentSummarization.html" target="_blank" rel="noopener noreferrer">#PersonalizedDocumentSummarization</a>
<a class="button" href="articles/RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/8" target="_blank" rel="noopener noreferrer" class="title-link">[Paper Note] User-model based personalized summarization, Diaz+, Information Processing and Management 2007.11</a>
<span class="snippet"><span>Comment</span><p>PDSã®å…ˆé§†ã‘ã¨ãªã£ãŸé‡è¦è«–æ–‡ã€‚å¿…ãšreferã™ã¹ãã€‚</p></span><br><br>
<button onclick="hideContent(0)" style="display: none;">hide</button>
&lt;/div&gt;
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<script>
  document.addEventListener('DOMContentLoaded', function() {
    const tweets = document.querySelectorAll('.tweet-embed[data-embed]');

    if ('IntersectionObserver' in window) {
      const observer = new IntersectionObserver((entries, obs) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            const el = entry.target;
            const html = el.getAttribute('data-embed');
            if (html) {
              const placeholder = el.querySelector('.tweet-placeholder');
              if (placeholder) placeholder.remove();

              el.innerHTML = html.trim();

              if (window.twttr?.widgets?.load) {
                window.twttr.widgets.load(el);
              }
            }
            obs.unobserve(el); // å‡¦ç†æ¸ˆã¿ã¯ç›£è¦–è§£é™¤
          }
        });
      }, {
        rootMargin: '500px 0px', // ç”»é¢æ‰‹å‰200pxã§èª­ã¿è¾¼ã¿é–‹å§‹
        threshold: 0
      });

      tweets.forEach(tweet => observer.observe(tweet));

    } else {
      // IntersectionObserveræœªå¯¾å¿œãƒ–ãƒ©ã‚¦ã‚¶ç”¨ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
      function lazyLoadFallback() {
        tweets.forEach(el => {
          if (el.getAttribute('data-embed') && el.getBoundingClientRect().top < window.innerHeight) {
            const html = el.getAttribute('data-embed');
            const loadingImg = el.querySelector('.tweet-loading');
            if (loadingImg) loadingImg.remove();
            el.innerHTML = html.trim();
            el.removeAttribute('data-embed');
            if (window.twttr?.widgets?.load) {
              window.twttr.widgets.load(el);
            }
          }
        });
      }
      window.addEventListener('scroll', lazyLoadFallback);
      lazyLoadFallback();
    }
  });
</script>
</div>


    </div>

</article>
<div class="post-nav">
<a class="previous" href="/paper_notes/articles/Security.html" title="Securityã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">Securityã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§</a><a class="next" href="/paper_notes/articles/Self-SupervisedLearning.html" title="Self-SupervisedLearningã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">Self-SupervisedLearningã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§</a>
</div>
<div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li class="">
          <a class="post-link" href="/paper_notes/articles/NLP.html" title="NLPã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            NLPã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/Medical.html" title="Medicalã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            Medicalã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/DemonstrationSelection.html" title="DemonstrationSelectionã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            DemonstrationSelectionã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/Library.html" title="Libraryã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§">
            Libraryã«é–¢ã™ã‚‹è«–æ–‡ãƒ»æŠ€è¡“è¨˜äº‹ãƒ¡ãƒ¢ã®ä¸€è¦§<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li>
</ul>
    </div>
<div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">TOC</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent =  menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3, h4, h5, h6");

    // Hide menu when no headings
    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // Generate post menu
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#h-' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }

    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';

    // The header element
    var header = document.querySelector('header.site-header');

    function doMenuCollapse(index, over_items) {
      var items = menuContent.firstChild.children;

      if (over_items == undefined) {
        over_items = 20;
      }

      if (items.length < over_items) {
        return;
      }

      var activeItem = items[index];
      var beginItem = activeItem
      var endItem = activeItem
      var beginIndex = index;
      var endIndex = index + 1;
      while (beginIndex >= 0
        && !items[beginIndex].classList.contains('h-h2')) {
        beginIndex -= 1;
      }
      while (endIndex < items.length
        && !items[endIndex].classList.contains('h-h2')) {
        endIndex += 1;
      }
      for (var i = 0; i < beginIndex; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
      for (var i = beginIndex + 1; i < endIndex; i++) {
        item = items[i]
        // if (!item.classList.contains('h-h2')) {
          item.style.display = '';
        // }
      }
      for (var i = endIndex; i < items.length; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
    }

    // Init menu collapsed
    doMenuCollapse(-1);

    // Active the menu item
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header.getBoundingClientRect();
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var headerHeight = headerTop + headerHeight + 20;
        if (headingRect.top <= headerHeight) {
          var id = 'h-' + h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          if (curActive) {
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }
      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
        doMenuCollapse(activeIndex);
      }
      event.preventDefault();
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/paper_notes/"></data>

  <div class="wrapper">
    <div class="site-footer-inner">
<div>Copyright Â© 2023-current AkihikoWATANABE. The header images and any thumbnail images for the posts were generated by ChatGPT's DALL-E3.</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="https://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div class="footer-col rss-subscribe">Subscribe <a href="/paper_notes/feed.xml">via RSS</a>
</div>
    </div>
  </div>
</footer>
</body>
  </html>
