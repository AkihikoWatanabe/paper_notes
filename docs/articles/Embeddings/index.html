<!DOCTYPE html>
<html lang="ja">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Embeddingsに関する論文・技術記事メモの一覧 | わたしのべんきょうノート</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="Embeddingsに関する論文・技術記事メモの一覧">
<meta name="author" content="AkihikoWATANABE">
<meta property="og:locale" content="ja">
<meta name="description" content="Embeddings [Paper Note] Language Models are Injective and Hence Invertible, Giorgos Nikolaou+, arXiv'25, 2025.10 Paper/Blog Link My Issue #Analysis #Pocket #NLP #LanguageModel #Selected Papers/Blogs Issue Date: 2025-10-29 GPT Summary- 本研究では、トランスフォーマー言語モデルが単射であることを数学的に証明し、異なる入力が同じ出力にマッピングされないことを示す。さらに、6つの最先端モデルに対して衝突テストを行い、衝突がないことを確認。新たに提案するアルゴリズムSipItにより、隠れた活性化から正確な入力テキストを効率的に再構築できることを示し、単射性が言語モデルの重要な特性であることを明らかにする。 Comment元ポスト:">
<meta property="og:description" content="Embeddings [Paper Note] Language Models are Injective and Hence Invertible, Giorgos Nikolaou+, arXiv'25, 2025.10 Paper/Blog Link My Issue #Analysis #Pocket #NLP #LanguageModel #Selected Papers/Blogs Issue Date: 2025-10-29 GPT Summary- 本研究では、トランスフォーマー言語モデルが単射であることを数学的に証明し、異なる入力が同じ出力にマッピングされないことを示す。さらに、6つの最先端モデルに対して衝突テストを行い、衝突がないことを確認。新たに提案するアルゴリズムSipItにより、隠れた活性化から正確な入力テキストを効率的に再構築できることを示し、単射性が言語モデルの重要な特性であることを明らかにする。 Comment元ポスト:">
<link rel="canonical" href="http://akihikowatanabe.github.io/paper_notes/articles/Embeddings/">
<meta property="og:url" content="http://akihikowatanabe.github.io/paper_notes/articles/Embeddings/">
<meta property="og:site_name" content="わたしのべんきょうノート">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2025-12-04T00:00:00+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="Embeddingsに関する論文・技術記事メモの一覧">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"AkihikoWATANABE"},"dateModified":"2025-12-04T00:00:00+00:00","datePublished":"2025-12-04T00:00:00+00:00","description":"Embeddings [Paper Note] Language Models are Injective and Hence Invertible, Giorgos Nikolaou+, arXiv&#39;25, 2025.10 Paper/Blog Link My Issue #Analysis #Pocket #NLP #LanguageModel #Selected Papers/Blogs Issue Date: 2025-10-29 GPT Summary- 本研究では、トランスフォーマー言語モデルが単射であることを数学的に証明し、異なる入力が同じ出力にマッピングされないことを示す。さらに、6つの最先端モデルに対して衝突テストを行い、衝突がないことを確認。新たに提案するアルゴリズムSipItにより、隠れた活性化から正確な入力テキストを効率的に再構築できることを示し、単射性が言語モデルの重要な特性であることを明らかにする。 Comment元ポスト:","headline":"Embeddingsに関する論文・技術記事メモの一覧","mainEntityOfPage":{"@type":"WebPage","@id":"http://akihikowatanabe.github.io/paper_notes/articles/Embeddings/"},"url":"http://akihikowatanabe.github.io/paper_notes/articles/Embeddings/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="icon" href="">
  <link rel="canonical" href="http://akihikowatanabe.github.io">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/main.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/custom_button.css">
  <script src="/paper_notes/assets/js/main.js"></script>
  <script src="https://d3js.org/d3.v5.min.js"></script><link type="application/atom+xml" rel="alternate" href="http://akihikowatanabe.github.io/paper_notes/feed.xml" title="わたしのべんきょうノート">
<script>
  function showMore(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "block";
          
      // このボタンの参照を取得して非表示にします
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "none";
      }
          
      // hideボタンの参照を取得して表示します
      const hideButton = contentDiv.querySelector('button[onclick^="hideContent"]');
      if (hideButton) {
        hideButton.style.display = "block";
      }
    }
  }

  function hideContent(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "none";
  
      // moreボタンの参照を取得して表示します
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "block";
      }
  
      // このボタンを隠します
      const hideButtons = document.querySelectorAll('button[onclick^="hideContent"]');
      const hideButton = hideButtons[index];
      if (hideButton) {
        hideButton.style.display = "none";
      }
    }
  }
</script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js" async></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe-lightbox.umd.min.js" async></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe.umd.min.js" async></script>
<link href="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/photoswipe.min.css" rel="stylesheet">
<style>
  .pswp .pswp__container .pswp__img {
    background-color: white;
  }
</style>

<script>
  function initPhotoSwipe() {
    let customOptions = {};

    try {
      const data = `{"gallery"=>"section.main", "children"=>"a.photo-swipe", "bgOpacity"=>0.8, "padding"=>{"top"=>20, "bottom"=>40, "left"=>100, "right"=>100}}`.replaceAll("=>", ":");
      customOptions = JSON.parse(data);
    } catch (e) {
      console.info("Invalid custom photo previewer options! " + e.message);
    }

    // Define object and gallery options
    const options = Object.assign(
      {
        gallery: "section.main",
        children: "a.photo-swipe",
        photo_scale: 2,
        // dynamic import is not supported in UMD version
        pswpModule: PhotoSwipe,
      },
      customOptions
    );

    const galleryEl = document.querySelector(options.gallery);
    if (!galleryEl) {
      return;
    }

    const imgEls = [];
    const els = galleryEl.querySelectorAll("img:not(.emoji)");
    els.forEach((el) => {
      if (el.src.trim() == "") {
        return;
      }
      if (!imgEls.includes(el)) {
        imgEls.push(el);
      }
    });

    if (imgEls.length === 0) {
      return;
    }

    imgEls.forEach((imgEl) => {
      imgEl.outerHTML = `
      <a class="photo-swipe"
        href="${imgEl.src}"
        data-pswp-width="${
          Math.max(imgEl.naturalWidth, imgEl.width) * options.photo_scale
        }"
        data-pswp-height="${
          Math.max(imgEl.naturalHeight, imgEl.height) * options.photo_scale
        }"
        data-pswp-caption="${imgEl.getAttribute("caption") || imgEl.alt}"
        target="_blank">
        ${imgEl.outerHTML}
      </a>`;
    });

    // Initialize PhotoSwipe 5
    var lightbox = new PhotoSwipeLightbox(options);

    lightbox.init();
  }

  window.addEventListener("load", initPhotoSwipe);
</script>
<meta name="google-site-verification" content="u_DTTPcCZ806iq51zgirHyWq3556HUKGq8AQfH91iFI">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-P70KSB88WH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-P70KSB88WH');
  </script>

<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"},"svg":{"fontCache":"global"}}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>





































































































































<header class="site-header site-header-transparent" role="banner">

  <div class="wrapper">
    <div class="site-header-inner">
<span class="site-brand"><a class="site-brand-inner" rel="author" href="/paper_notes/">
  <img class="site-favicon" title="わたしのべんきょうノート" src="" onerror="this.style.display='none'">
  わたしのべんきょうノート
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger">
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewbox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
              </svg>
            </span>
          </label>

          <div class="trigger">
<a class="page-link" href="/paper_notes/">論文や技術メモの一覧（随時更新）</a><a class="page-link" href="/paper_notes/archives.html">ARCHIVES</a>









<span class="page-link">



<div id="google_translate_element" style="display: none;">
</div>

<span class="ct-language">
  <ul class="list-unstyled ct-language-dropdown">
    
      <li>
        <a href="#" class="lang-select" data-lang="en">
          
          <img src="https://cdn.countryflags.com/thumbs/united-states-of-america/flag-400.png" title="English">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="fr">
          
          <img src="https://cdn.countryflags.com/thumbs/france/flag-400.png" title="French">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="zh-CN">
          
          <img src="https://cdn.countryflags.com/thumbs/china/flag-400.png" title="Chinese(Simple)">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ja">
          
          <img src="https://cdn.countryflags.com/thumbs/japan/flag-400.png" title="Japanese">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ko">
          
          <img src="https://cdn.countryflags.com/thumbs/south-korea/flag-400.png" title="Korean">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ru">
          
          <img src="https://cdn.countryflags.com/thumbs/russia/flag-400.png" title="Russian">
          
        </a>
      </li>
    
  </ul>
</span>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'ja',
    autoDisplay: false,
    layout: google.translate.TranslateElement.InlineLayout.VERTICAL
  }, 'google_translate_element');

  // Links to cross-origin destinations are unsafe
  var gll = document.getElementsByClassName('goog-logo-link')[0];
  if (gll) {
    gll.setAttribute('rel', 'noopener');
  }

  function restoreLang() {
    var iframe = document.getElementsByClassName('goog-te-banner-frame')[0];
    if (!iframe) return;

    var innerDoc = iframe.contentDocument || iframe.contentWindow.document;
    var restore_el = innerDoc.getElementsByTagName("button");

    for (var i = 0; i < restore_el.length; i++) {
      if (restore_el[i].id.indexOf("restore") >= 0) {
        restore_el[i].click();
        var close_el = innerDoc.getElementsByClassName("goog-close-link");
        close_el[0].click();
        return;
      }
    }
  }

  function triggerHtmlEvent(element, eventName) {
    var event;
    if (document.createEvent) {
      event = document.createEvent('HTMLEvents');
      event.initEvent(eventName, true, true);
      element.dispatchEvent(event);
    } else {
      event = document.createEventObject();
      event.eventType = eventName;
      element.fireEvent('on' + event.eventType, event);
    }
  }

  var googleCombo = document.querySelector("select.goog-te-combo");
  var langSelect = document.querySelector('.ct-language');
  langSelect.addEventListener('click', function(event) {
    if (!event.target) {
      return;
    }

    var selected = document.querySelector('.ct-language .ct-language-selected');
    if (selected) {
      selected.classList.remove('ct-language-selected');
    }

    var target = event.target;
    while (target && target !== langSelect ) {
      if (target.matches('.lang-select')) {
        break;
      }
      target = target.parentElement;
    }

    if (target && target.matches('.lang-select')) {
      var lang = target.getAttribute('data-lang');
      if (googleCombo.value == lang) {
        restoreLang();
      } else {
        target.parentElement.classList.add('ct-language-selected');
        googleCombo.value = lang;
        triggerHtmlEvent(googleCombo, 'change');
      }
    }

    event.preventDefault();
  });
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit" async></script>
</span>
</div>
        </nav>
</div>
  </div>
</header>

<script>
  function initHeader() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;

    function storeScrollData() {
      var y = getScrollPos().y;documentElement.setAttribute("data-header-transparent", "");var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0) ? true : false;
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
    }

    window.addEventListener('scroll', function(e) {
      storeScrollData();
    });

    storeScrollData();
  }
  document.addEventListener('DOMContentLoaded', initHeader);
</script>


























































































































































<style>
    html .page-banner .page-banner-img > *:first-child {
      opacity: 0.4;
    }

    html[data-theme="dark"] .page-banner .page-banner-img > *:first-child {
      opacity: 0.2872;
    }
  </style>
<section class="page-banner">
    <div class="page-banner-img">
<div style="background-image: url(/paper_notes/assets/images/banner.png)"></div>
        <img class="img-placeholder" src="/paper_notes/assets/images/banner.png">
</div>
    <div class="wrapper">
      <div class="page-banner-inner">
<header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">わたしのべんきょうノート</h1>
  <h2 class="post-subtitle">勉強した論文や技術等の情報をGithubのIssueにメモっているひとのブログ。
それなりにメモの量が蓄積されてきたので、一度整理したいなと思いブログはじめてみました！
自然言語処理(NLP), 推薦システム(RecommenderSystem), Educational Data Mining (EDM), Learning Analytics (LA)などの分野のメモが多いと思います。
最近は特にLLMの勉強が多めです :)</h2>

  <div class="post-meta">
    <time class="dt-published" datetime="2025-12-04T00:00:00+00:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Dec 04, 2025
    </time><span class="post-author left-vsplit"><i class="fa fa-pencil"></i> AkihikoWATANABE</span>
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 2 hours 33 mins</span>
  </div></header>
</div>
    </div>
  </section><script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    hashValue = decodeURIComponent(hashValue);
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('off' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<div id="click-to-top" class="click-to-top">
  <i class="fa fa-arrow-up"></i>
</div>
<script>
  (function () {
    const clickToTop = document.getElementById('click-to-top');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 100) {
        clickToTop.classList.add('show')
      }else {
        clickToTop.classList.remove('show')
      }
    });
    clickToTop.addEventListener('click', () => {
      window.smoothScrollTo(0);
    });
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <h2 id="Embeddings" class="paper-head"> Embeddings</h2>
<div class="visible-content">
<article class="paper-entry">
<h3 id="language-models-3502" class="title-link">[Paper Note] Language Models are Injective and Hence Invertible, Giorgos Nikolaou+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.15511" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3502" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-10-29</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、トランスフォーマー言語モデルが単射であることを数学的に証明し、異なる入力が同じ出力にマッピングされないことを示す。さらに、6つの最先端モデルに対して衝突テストを行い、衝突がないことを確認。新たに提案するアルゴリズムSipItにより、隠れた活性化から正確な入力テキストを効率的に再構築できることを示し、単射性が言語モデルの重要な特性であることを明らかにする。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tpimentelms/status/1982857658450489704?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>続報:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gladialab/status/1983812121713418606?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1984411703459889390?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>解説参照のこと。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="understanding-the-3326" class="title-link">[Paper Note] Understanding the Influence of Synthetic Data for Text Embedders, Jacob Mitchell Springer+, ACL'25 Findings, 2025.09</h3>
<br><a href="https://arxiv.org/abs/2509.06184" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3326" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<span class="issue_date">Issue Date: 2025-10-19</span>
<span class="snippet"><span>GPT Summary</span>- 合成LLM生成データのトレーニングによる汎用テキスト埋め込み器の進展を受け、Wangらの合成データを再現・公開。高品質なデータはパフォーマンス向上をもたらすが、一般化の改善は局所的であり、異なるタスク間でのトレードオフが存在。これにより、合成データアプローチの限界が明らかになり、タスク全体での堅牢な埋め込みモデルの構築に対する考えに疑問を呈する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacspringer/status/1979233837042290775?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>dataset: 


<a href="https://huggingface.co/datasets/jspringer/open-synthetic-embeddings" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/jspringer/open-synthetic-embeddings</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="gaussian-embeddings-3184" class="title-link">[Paper Note] Gaussian Embeddings: How JEPAs Secretly Learn Your Data Density, Randall Balestriero+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.05949" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3184" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-10-09</span>
<span class="snippet"><span>GPT Summary</span>- JEPAは、潜在空間予測と反収束を組み合わせたアーキテクチャで、データ密度を推定する能力を持つ。成功裏に訓練されたJEPAは、データキュレーションや外れ値検出に利用可能で、サンプルの確率を効率的に計算できる。JEPA-SCOREと呼ばれる手法を用いて、さまざまなデータセットや自己教師あり学習手法でその効果が実証されている。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/randall_balestr/status/1975913453211791836?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>ポイント解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1975838782231617950?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="generative-representational-3178" class="title-link">[Paper Note] Generative Representational Instruction Tuning, Niklas Muennighoff+, ICLR'25, 2024.02</h3>
<br><a href="https://arxiv.org/abs/2402.09906" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3178" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<span class="snippet"><span>GPT Summary</span>- 生成的表現指示チューニング（GRIT）を用いて、大規模言語モデルが生成タスクと埋め込みタスクを同時に処理できる手法を提案。GritLM 7BはMTEBで新たな最先端を達成し、GritLM 8x7Bはすべてのオープン生成モデルを上回る性能を示す。GRITは生成データと埋め込みデータの統合による性能損失がなく、RAGを60%以上高速化する利点もある。モデルは公開されている。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=BC4lIvfSzv" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=BC4lIvfSzv</a>


</p>
<p>従来はgemerativeタスクとembeddingタスクは別々にモデリングされていたが、それを統一的な枠組みで実施し、両方のタスクで同等のモデルサイズの他モデルと比較して高い性能を達成した研究。従来のgenerativeタスク用のnext-token-prediction lossとembeddingタスク用のconstastive lossを組み合わせて学習する（式3）。タスクの区別はinstructionにより実施し、embeddingタスクの場合はすべてのトークンのlast hidden stateのmean poolingでrepresentationを取得する。また、embeddingの時はbi-directional attention / generativeタスクの時はcausal maskが適用される。これらのattentionの適用のされ方の違いが、どのように管理されるかはまだしっかり読めていないのでよくわかっていないが、非常に興味深い研究である。<br><br><img width="603" height="349" alt="Image" src="&lt;a%20href=" https: target="_blank" rel="noopener noreferrer">https://github.com/user-attachments/assets/acb2cbcd-364d-43c7-b51a-6c5ea9866415"


/&gt;</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="reasonir-training-3175" class="title-link">[Paper Note] ReasonIR: Training Retrievers for Reasoning Tasks, Rulin Shao+, COLM'25, 2025.04</h3>
<br><a href="https://arxiv.org/abs/2504.20595" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3175" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<span class="issue_date">Issue Date: 2025-10-08</span>
<span class="snippet"><span>GPT Summary</span>- ReasonIR-8Bは、一般的な推論タスク向けに特別に訓練された初のリトリーバーであり、合成データ生成パイプラインを用いて挑戦的なクエリとハードネガティブを作成。これにより、BRIGHTベンチマークで新たな最先端成果を達成し、RAGタスクでも他のリトリーバーを上回る性能を示す。トレーニングレシピは一般的で、将来のLLMへの拡張が容易である。コード、データ、モデルはオープンソース化されている。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rulinshao/status/1975773504307142790?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>Llama3.1-8Bをbidirectional encoderに変換してpost-trainingしている。</p>
<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3178" target="_blank" rel="noopener noreferrer">[Paper Note] Generative Representational Instruction Tuning, Niklas Muennighoff+, ICLR'25, 2024.02</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="omni-embed-nemotron-a-3145" class="title-link">[Paper Note] Omni-Embed-Nemotron: A Unified Multimodal Retrieval Model for Text,  Image, Audio, and Video, Mengyao Xu+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.03458" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3145" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-10-07</span>
<span class="snippet"><span>GPT Summary</span>- 「Omni-Embed-Nemotron」は、複雑な情報ニーズに応えるための統一的なマルチモーダル検索埋め込みモデルです。従来のテキストベースのリトリーバーが視覚的に豊かなコンテンツに対応できない中、ColPaliの研究を基に、テキスト、画像、音声、動画を統合した検索を実現します。このモデルは、クロスモーダルおよびジョイントモーダル検索を可能にし、そのアーキテクチャと評価結果を通じて、検索の効果を実証しています。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1975418540510618111?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="modernvbert-towards-3085" class="title-link">[Paper Note] ModernVBERT: Towards Smaller Visual Document Retrievers, Paul Teiletche+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.01149v1" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3085" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<span class="issue_date">Issue Date: 2025-10-03</span>
<span class="snippet"><span>GPT Summary</span>- マルチモーダル埋め込みモデルは文書検索において効率的な代替手段として普及しているが、再利用アプローチが検索性能のボトルネックとなることがある。本研究では、視覚文書検索モデルを改善するための原則的なレシピを確立し、注意マスキングや画像解像度などが性能に影響を与える要因であることを示した。これに基づき、250Mパラメータのコンパクトな視覚-言語エンコーダーModernVBERTを開発し、文書検索タスクで大規模モデルを上回る性能を達成した。モデルとコードは公開されている。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jobergum/status/1973830118637551626?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>MIT Licence<br>HF: 


<a href="https://huggingface.co/ModernVBERT" target="_blank" rel="noopener noreferrer">https://huggingface.co/ModernVBERT</a>


</p>
<p>ポイント解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1974047955301626065?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="embeddinggemma-powerful-2982" class="title-link">[Paper Note] EmbeddingGemma: Powerful and Lightweight Text Representations, Henrique Schechter Vera+, arXiv'25, 2025.09</h3>
<br><a href="https://arxiv.org/abs/2509.20354" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2982" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-25</span>
<span class="snippet"><span>GPT Summary</span>- EmbeddingGemmaは、Gemma 3言語モデルに基づく軽量なオープンテキスト埋め込みモデルで、エンコーダ-デコーダの初期化と幾何学的埋め込み蒸留を用いて大規模モデルの知識を活用。分散正則化器を使用し、異なるチェックポイントを統合することで一般化能力を向上。300Mのパラメータで、MTEBで最先端の結果を達成し、従来のトップモデルを上回る性能を示す。量子化や出力の切り詰めにも耐え、低遅延かつ高スループットのアプリケーションに適している。EmbeddingGemmaはコミュニティに公開され、さらなる研究を促進する。</span>
<span class="snippet"><span>Comment</span><p>公式モデル概要:


<a href="https://ai.google.dev/gemma/docs/embeddinggemma?hl=ja" target="_blank" rel="noopener noreferrer">https://ai.google.dev/gemma/docs/embeddinggemma?hl=ja</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1971041110446465251?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>100以上の言語で訓練されマトリョーシカ表現なのでベクトルのサイズを調整可能な模様</p>
<p>マトリョーシカ表現:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2311" target="_blank" rel="noopener noreferrer">[Paper Note] Matryoshka Representation Learning, Aditya Kusupati+, NeurIPS'22</a>
</p>
<p>公式による解説ブログ:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sahildua2305/status/1973021214588506274?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="perception-encoder-2921" class="title-link">[Paper Note] Perception Encoder: The best visual embeddings are not at the output of   the network, Daniel Bolya+, NeurIPS'25, 2025.04</h3>
<br><a href="https://arxiv.org/abs/2504.13181" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2921" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<a class="button" href="SpatialUnderstanding.html" target="_blank" rel="noopener noreferrer">#SpatialUnderstanding</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<span class="snippet"><span>GPT Summary</span>- Perception Encoder（PE）は、画像と動画理解のための新しいビジョンエンコーダで、シンプルなビジョンと言語の学習を通じて訓練されています。従来の特定のタスクに依存せず、対照的なビジョンと言語の訓練だけで強力な埋め込みを生成します。埋め込みを引き出すために、言語アライメントと空間アライメントの2つの手法を導入。PEモデルは、ゼロショット画像・動画分類で高い性能を示し、Q&amp;Aタスクや空間タスクでも最先端の結果を達成しました。モデルやデータセットは公開されています。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/andreamadotto/status/1969529427064471619?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1983642930515734898?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="lost-in-2920" class="title-link">[Paper Note] Lost in Embeddings: Information Loss in Vision-Language Models, Wenyan Li+, EMNLP'25 Findings, 2025.09</h3>
<br><a href="https://arxiv.org/abs/2509.11986" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2920" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="Findings.html" target="_blank" rel="noopener noreferrer">#Findings</a>
<span class="issue_date">Issue Date: 2025-09-21</span>
<span class="snippet"><span>GPT Summary</span>- 視覚と言語のモデル（VLMs）の投影ステップによる情報損失を分析するため、2つのアプローチを提案。1つ目は、投影前後の画像表現のk近傍関係の変化を評価し、2つ目は視覚埋め込みの再構築によって情報損失を測定。実験により、コネクタが視覚表現の幾何学を歪め、k近傍が40～60%乖離することが明らかになり、これは検索性能の低下と関連。パッチレベルの再構築は、モデルの挙動に対する洞察を提供し、高い情報損失がモデルの苦手な事例を予測することを示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenyan62/status/1969298016684163195?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>ポイント解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1969557366245933068?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="conan-embedding-v2-training-2838" class="title-link">[Paper Note] Conan-Embedding-v2: Training an LLM from Scratch for Text Embeddings, Shiyu Li+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2509.12892" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2838" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<span class="snippet"><span>GPT Summary</span>- 新しい1.4BパラメータのLLM「Conan-embedding-v2」をゼロからトレーニングし、テキスト埋め込み器としてファインチューニングする手法を提案。ニュースデータと多言語ペアを追加してデータギャップを埋め、クロスリンガルリトリーバルデータセットを導入。ソフトマスキングメカニズムを用いてトークンレベルと文レベルの損失を統合し、動的ハードネガティブマイニング手法を採用。これにより、MTEBおよびChinese MTEBでSOTA性能を達成。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1968167110758240679?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="mmbert-a-2744" class="title-link">[Paper Note] mmBERT: A Modern Multilingual Encoder with Annealed Language Learning, Marc Marone+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2509.06888" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2744" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<span class="snippet"><span>GPT Summary</span>- mmBERTは、1800以上の言語で3兆トークンのデータを用いて事前学習されたエンコーダ専用の言語モデルであり、低リソース言語を短い減衰フェーズに含めることでパフォーマンスを向上させた。新しい要素を導入し、OpenAIのo3やGoogleのGemini 2.5 Proと同等の分類性能を達成。mmBERTは分類および検索タスクで以前のモデルを大幅に上回ることを示した。</span>
<span class="snippet"><span>Comment</span><p>blog:


<a href="https://huggingface.co/blog/mmbert" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/mmbert</a>


<br>HF:


<a href="https://huggingface.co/jhu-clsp/mmBERT-checkpoints" target="_blank" rel="noopener noreferrer">https://huggingface.co/jhu-clsp/mmBERT-checkpoints</a>


</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1761" target="_blank" rel="noopener noreferrer">modernbert-ja-130m, SB Intuitions, 2025.02</a>
<br><br>と比較して日本語の性能はどうかなあ</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ruyimarone/status/1965409895584522330?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1965563064067011053?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="efficient-code-2664" class="title-link">[Paper Note] Efficient Code Embeddings from Code Generation Models, Daria Kryvosheieva+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2508.21290" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2664" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<span class="issue_date">Issue Date: 2025-09-03</span>
<span class="snippet"><span>GPT Summary</span>- jina-code-embeddingsは、自然言語からコードを取得し、技術的な質問応答や意味的に類似したコードスニペットの特定を行う新しいコード埋め込みモデルです。自己回帰型バックボーンを利用し、トークンプーリングを通じて埋め込みを生成。小さいモデルサイズながら最先端のパフォーマンスを示し、コード埋め込みモデルの構築における有効性を検証しています。</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/collections/jinaai/jina-code-embeddings-68b0fbfbb0d639e515f82acd" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/jinaai/jina-code-embeddings-68b0fbfbb0d639e515f82acd</a>


</p>
<p>コーディング特化のembeddingで、検索、クロスリンガルな類似度、技術に関するQAに対応可能らしい</p>
<p>公式ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jinaai_/status/1963637135439007824?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="on-the-2632" class="title-link">[Paper Note] On the Theoretical Limitations of Embedding-Based Retrieval, Orion Weller+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2508.21038" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2632" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<span class="snippet"><span>GPT Summary</span>- ベクトル埋め込みは検索タスクにおいて重要な役割を果たしているが、シンプルなクエリでも理論的限界に直面する可能性があることを示す。特に、埋め込みの次元が文書のトップ-kサブセットの数を制限し、k=2でもこの制限が成り立つことを実証。新たに作成したデータセット「LIMIT」では、最先端モデルでさえ失敗することが観察され、既存の埋め込みモデルの限界を明らかにし、今後の研究の必要性を提唱している。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1962280460605862194?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="large-foundation-2554" class="title-link">[Paper Note] Large Foundation Model for Ads Recommendation, Shangyu Zhang+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2508.14948" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2554" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-26</span>
<span class="snippet"><span>GPT Summary</span>- LFM4Adsは、オンライン広告のための全表現マルチ粒度転送フレームワークで、ユーザー表現（UR）、アイテム表現（IR）、ユーザー-アイテム交差表現（CR）を包括的に転送。最適な抽出層を特定し、マルチ粒度メカニズムを導入することで転送可能性を強化。テンセントの広告プラットフォームで成功裏に展開され、2.45%のGMV向上を達成。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1959975943600067006?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="mapping-1-2345" class="title-link">[Paper Note] Mapping 1,000+ Language Models via the Log-Likelihood Vector, Momose Oyama+, ACL'25</h3>
<br><a href="https://arxiv.org/abs/2502.16173" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2345" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-03</span>
<span class="snippet"><span>GPT Summary</span>- 自動回帰型言語モデルの比較に対し、対数尤度ベクトルを特徴量として使用する新しいアプローチを提案。これにより、テキスト生成確率のクルバック・ライブラー発散を近似し、スケーラブルで計算コストが線形に増加する特徴を持つ。1,000以上のモデルに適用し、「モデルマップ」を構築することで、大規模モデル分析に新たな視点を提供。</span>
<span class="snippet"><span>Comment</span><p>NLPコロキウムでのスライド:


<a href="https://speakerdeck.com/shimosan/yan-yu-moderunodi-tu-que-lu-fen-bu-to-qing-bao-ji-he-niyorulei-si-xing-noke-shi-hua" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/shimosan/yan-yu-moderunodi-tu-que-lu-fen-bu-to-qing-bao-ji-he-niyorulei-si-xing-noke-shi-hua</a>


<br><br>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hshimodaira/status/1960573414575333556?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="on-the-2317" class="title-link">[Paper Note] On The Role of Pretrained Language Models in General-Purpose Text  Embeddings: A Survey, Meishan Zhang+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2507.20783" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2317" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<span class="snippet"><span>GPT Summary</span>- 本調査では、事前学習済み言語モデル（PLMs）を活用した一般目的のテキスト埋め込み（GPTE）の発展を概観し、PLMsの役割に焦点を当てる。基本的なアーキテクチャや埋め込み抽出、表現力向上、トレーニング戦略について説明し、PLMsによる多言語サポートやマルチモーダル統合などの高度な役割も考察する。さらに、将来の研究方向性として、ランキング統合やバイアス軽減などの改善目標を超えた課題を強調する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bo_wangbo/status/1950158633645363465?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>GPTEの学習手法テキストだけでなく、画像やコードなどの様々なモーダル、マルチリンガル、データセットや評価方法、パラメータサイズとMTEBの性能の関係性の図解など、盛りだくさんな模様。最新のものだけでなく、2021年頃のT5から最新モデルまで網羅的にまとまっている。日本語特化のモデルについては記述が無さそうではある。<br><br><img src="https://github.com/user-attachments/assets/f0a40a10-7f29-4aaf-b989-672213622ebc" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/7940d307-f1db-421f-86a4-6c9cca22f27c" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/46282995-d538-4bd2-9aa5-983253a98f8f" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/dc4212de-19df-497c-951e-3addff5a193f" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/ac925f56-de46-49ae-b0a8-cd8e2ecc4994" alt="image" loading="lazy"></p>
<p>日本語モデルについてはRuriのテクニカルペーパーや、LLM勉強会のまとめを参照のこと<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1375" target="_blank" rel="noopener noreferrer">Ruri: Japanese General Text Embeddings, cl-nagoya, 2024.09</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1563" target="_blank" rel="noopener noreferrer">日本語LLMまとめ, LLM-jp, 2024.12</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="beyond-matryoshka-2310" class="title-link">[Paper Note] Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation, Tiansheng Wen+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2503.01776" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2310" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<span class="snippet"><span>GPT Summary</span>- スパースコーディングを用いたContrastive Sparse Representation（CSR）を提案し、適応的な埋め込みを実現。CSRは事前訓練された埋め込みをスパース化し、意味的品質を保持しつつコスト効果の高い推論を可能にする。実験により、CSRは精度と検索速度でMatryoshka Representation Learning（MRL）を上回り、訓練時間も大幅に短縮されることが示された。スパースコーディングは実世界のアプリケーションにおける適応的な表現学習の強力な手法として位置づけられる。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1949957739637002450?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>マトリョーシカ表現:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2311" target="_blank" rel="noopener noreferrer">[Paper Note] Matryoshka Representation Learning, Aditya Kusupati+, NeurIPS'22</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="learning-distributed-2239" class="title-link">[Paper Note] Learning distributed representations with efficient SoftMax   normalization, Lorenzo Dall'Amico+, TMLR'25</h3>
<br><a href="https://arxiv.org/abs/2303.17475" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2239" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<span class="issue_date">Issue Date: 2025-07-16</span>
<span class="snippet"><span>GPT Summary</span>- 埋め込みを学習するための損失関数として${\rm SoftMax}(XY^T)$を最適化する際の計算負荷を軽減するため、ノルム制限された埋め込みベクトルに対して線形時間のヒューリスティック近似を提案。提案手法は、事前学習されたデータセットで高い精度を示し、クロスエントロピーを最適化する効率的なアルゴリズムを設計。これにより、解釈可能でタスクに依存しない埋め込み学習が可能となり、類似の「2Vec」アルゴリズムと比較して優れた性能と低い計算時間を実現。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=9M4NKMZOPu" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=9M4NKMZOPu</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="nv-embed-improved-2182" class="title-link">[Paper Note] NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding   Models, Chankyu Lee+, ICLR'25</h3>
<br><a href="https://arxiv.org/abs/2405.17428" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2182" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<a class="button" href="Decoder.html" target="_blank" rel="noopener noreferrer">#Decoder</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<span class="snippet"><span>GPT Summary</span>- デコーダー専用のLLMベースの埋め込みモデルNV-Embedは、BERTやT5を上回る性能を示す。アーキテクチャ設計やトレーニング手法を工夫し、検索精度を向上させるために潜在的注意層を提案。二段階の対照的指示調整手法を導入し、検索と非検索タスクの両方で精度を向上。NV-EmbedモデルはMTEBリーダーボードで1位を獲得し、ドメイン外情報検索でも高スコアを達成。モデル圧縮技術の分析も行っている。</span>
<span class="snippet"><span>Comment</span><p>Decoder-Only LLMのlast hidden layerのmatrixを新たに導入したLatent Attention Blockのinputとし、Latent Attention BlockはEmbeddingをOutputする。Latent Attention Blockは、last hidden layer (系列長l×dの<br>matrix)をQueryとみなし、保持しているLatent Array(trainableなmatrixで辞書として機能する;後述の学習においてパラメータが学習される)[^1]をK,Vとして、CrossAttentionによってcontext vectorを生成し、その後MLPとMean Poolingを実施することでEmbeddingに変換する。<br><img src="https://github.com/user-attachments/assets/7a023273-aafd-4cfa-9b39-961180543ae9" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/767e3ac1-fe70-4653-bbe7-091c1f1dc0f7" alt="image" loading="lazy"><br><br>学習は2段階で行われ、まずQAなどのRetrievalタスク用のデータセットをIn Batch negativeを用いてContrastive Learningしモデルの検索能力を高める。その後、検索と非検索タスクの両方を用いて、hard negativeによってcontrastive learningを実施し、検索以外のタスクの能力も高める（下表）。両者において、instructionテンプレートを用いて、instructionによって条件付けて学習をすることで、instructionに応じて生成されるEmbeddingが変化するようにする。また、学習時にはLLMのcausal maskは無くし、bidirectionalにrepresentationを考慮できるようにする。<br><img src="https://github.com/user-attachments/assets/26d4e126-1d18-421e-873f-f0eef4fc2026" alt="image" loading="lazy"><br><br>[^1]: <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2183" target="_blank" rel="noopener noreferrer">[Paper Note] Perceiver IO: A General Architecture for Structured Inputs &amp; Outputs, Andrew Jaegle+, ICLR'22</a>
 Perceiver-IOにインスパイアされている。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="vlm2vec-training-2156" class="title-link">[Paper Note] VLM2Vec: Training Vision-Language Models for Massive Multimodal  Embedding Tasks, Ziyan Jiang+, ICLR'25</h3>
<br><a href="https://arxiv.org/abs/2410.05160" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2156" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、ユニバーサルマルチモーダル埋め込みモデルの構築を目指し、二つの貢献を行った。第一に、MMEB（Massive Multimodal Embedding Benchmark）を提案し、36のデータセットを用いて分類や視覚的質問応答などのメタタスクを網羅した。第二に、VLM2Vecというコントラストトレーニングフレームワークを開発し、視覚-言語モデルを埋め込みモデルに変換する手法を示した。実験結果は、VLM2Vecが既存のモデルに対して10%から20%の性能向上を達成することを示し、VLMの強力な埋め込み能力を証明した。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=TE0KOzWYAF" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=TE0KOzWYAF</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="vlm2vec-v2-advancing-2155" class="title-link">[Paper Note] VLM2Vec-V2: Advancing Multimodal Embedding for Videos, Images, and  Visual Documents, Rui Meng+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2507.04590" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2155" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<span class="snippet"><span>GPT Summary</span>- VLM2Vec-V2という統一フレームワークを提案し、テキスト、画像、動画、視覚文書を含む多様な視覚形式の埋め込みを学習。新たにMMEB-V2ベンチマークを導入し、動画検索や視覚文書検索など5つのタスクを追加。広範な実験により、VLM2Vec-V2は新タスクで強力なパフォーマンスを示し、従来の画像ベンチマークでも改善を達成。研究はマルチモーダル埋め込みモデルの一般化可能性に関する洞察を提供し、スケーラブルな表現学習の基盤を築く。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1942501330674647342?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2156" target="_blank" rel="noopener noreferrer">[Paper Note] VLM2Vec: Training Vision-Language Models for Massive Multimodal  Embedding Tasks, Ziyan Jiang+, ICLR'25</a>
</p>
<p>Video Classification, Visual Document Retrievalなどのモダリティも含まれている。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="do-we-2151" class="title-link">[Paper Note] Do We Really Need Specialization? Evaluating Generalist Text Embeddings  for Zero-Shot Recommendation and Search, Matteo Attimonelli+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2507.05006" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2151" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="SequentialRecommendation.html" target="_blank" rel="noopener noreferrer">#SequentialRecommendation</a>
<a class="button" href="Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<span class="issue_date">Issue Date: 2025-07-08</span>
<span class="snippet"><span>GPT Summary</span>- 事前学習済み言語モデル（GTEs）は、逐次推薦や製品検索においてファインチューニングなしで優れたゼロショット性能を発揮し、従来のモデルを上回ることを示す。GTEsは埋め込み空間に特徴を均等に分配することで表現力を高め、埋め込み次元の圧縮がノイズを減少させ、専門モデルの性能向上に寄与する。再現性のためにリポジトリを提供。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1942463379639349654?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2182" target="_blank" rel="noopener noreferrer">[Paper Note] NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding   Models, Chankyu Lee+, ICLR'25</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="llm-jp-modernbert-a-2093" class="title-link">[Paper Note] llm-jp-modernbert: A ModernBERT Model Trained on a Large-Scale Japanese  Corpus with Long Context Length, Issa Sugiura+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2504.15544" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2093" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<a class="button" href="Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<span class="snippet"><span>GPT Summary</span>- ModernBERTモデル（llm-jp-modernbert）は、8192トークンのコンテキスト長を持つ日本語コーパスで訓練され、フィルマスクテスト評価で良好な結果を示す。下流タスクでは既存のベースラインを上回らないが、コンテキスト長の拡張効果を分析し、文の埋め込みや訓練中の遷移を調査。再現性を支援するために、モデルと評価コードを公開。</span>
<span class="snippet"><span>Comment</span><p>参考:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1761" target="_blank" rel="noopener noreferrer">modernbert-ja-130m, SB Intuitions, 2025.02</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="near$^2$-a-2087" class="title-link">[Paper Note] NEAR$^2$: A Nested Embedding Approach to Efficient Product Retrieval and  Ranking, Shenbin Qian+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2506.19743" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2087" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<span class="issue_date">Issue Date: 2025-06-25</span>
<span class="snippet"><span>GPT Summary</span>- Eコマース情報検索システムは、ユーザーの意図を正確に理解しつつ、大規模な商品カタログを効率的に処理することが難しい。本論文では、NEAR$^2$というネストされた埋め込みアプローチを提案し、推論時の埋め込みサイズを最大12倍効率化し、トレーニングコストを増やさずにトランスフォーマーモデルの精度を向上させる。さまざまなIR課題に対して異なる損失関数を用いて検証した結果、既存モデルよりも小さな埋め込み次元での性能向上を達成した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1937697219387490566?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="jina-embeddings-v4-universal-2079" class="title-link">[Paper Note] jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual  Retrieval, Michael Günther+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2506.18902" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2079" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<span class="issue_date">Issue Date: 2025-06-24</span>
<span class="snippet"><span>GPT Summary</span>- 3.8億パラメータのマルチモーダル埋め込みモデル「jina-embeddings-v4」を提案。新しいアーキテクチャにより、クエリベースの情報検索やクロスモーダルの類似性検索を最適化。タスク特化型のLoRAアダプターを組み込み、視覚的に豊かなコンテンツの処理に優れた性能を発揮。新しいベンチマーク「Jina-VDR」も導入。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1937342962075378014?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="diffusion-vs.-1983" class="title-link">Diffusion vs. Autoregressive Language Models: A Text Embedding  Perspective, Siyue Zhang+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2505.15045" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1983" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<span class="snippet"><span>GPT Summary</span>- 拡散言語モデルを用いたテキスト埋め込みが、自己回帰的なLLMの一方向性の制限を克服し、文書検索や推論タスクで優れた性能を発揮。長文検索で20%、推論集約型検索で8%、指示に従った検索で2%の向上を示し、双方向の注意が重要であることを確認。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/trtd6trtd/status/1925775950500806742?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="layer-by-1924" class="title-link">Layer by Layer: Uncovering Hidden Representations in Language Models, Oscar Skean+, ICML'25</h3>
<br><a href="https://arxiv.org/abs/2502.02013" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1924" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="CompressionValleys.html" target="_blank" rel="noopener noreferrer">#CompressionValleys</a>
<span class="issue_date">Issue Date: 2025-05-04</span>
<span class="snippet"><span>GPT Summary</span>- 中間層の埋め込みが最終層を超えるパフォーマンスを示すことを分析し、情報理論や幾何学に基づくメトリクスを提案。32のテキスト埋め込みタスクで中間層が強力な特徴を提供することを実証し、AIシステムの最適化における中間層の重要性を強調。</span>
<span class="snippet"><span>Comment</span><p>現代の代表的な言語モデルのアーキテクチャ（decoder-only model, encoder-only model, SSM）について、最終層のembeddingよりも中間層のembeddingの方がdownstream task（MTEBの32Taskの平均）に、一貫して（ただし、これはMTEBの平均で見たらそうという話であり、個別のタスクで一貫して強いかは読んでみないとわからない）強いことを示した研究。<br><br>このこと自体は経験的に知られているのであまり驚きではないのだが（ただ、SSMでもそうなのか、というのと、一貫して強いというのは興味深い）、この研究はMatrix Based Entropyと呼ばれるものに基づいて、これらを分析するための様々な指標を定義し理論的な根拠を示し、Autoregressiveな学習よりもMasked Languageによる学習の方がこのようなMiddle Layerのボトルネックが緩和され、同様のボトルネックが画像の場合でも起きることを示し、CoTデータを用いたFinetuningについても分析している模様。この辺の貢献が非常に大きいと思われるのでここを理解することが重要だと思われる。あとで読む。<br><br><img src="https://github.com/user-attachments/assets/bda00c50-c97b-45e0-97a5-d98dd98599fd" alt="image" loading="lazy"></p>
<p>openreview:


<a href="https://openreview.net/forum?id=WGXb7UdvTX" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=WGXb7UdvTX</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="gemini-embedding-1789" class="title-link">Gemini Embedding: Generalizable Embeddings from Gemini, Jinhyuk Lee+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2503.07891" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1789" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<span class="issue_date">Issue Date: 2025-03-12</span>
<span class="snippet"><span>GPT Summary</span>- Gemini Embeddingは、Googleの大規模言語モデルGeminiを活用した最先端の埋め込みモデルで、多言語およびコード理解能力を活かして一般化可能な埋め込みを生成します。事前計算された表現は、分類や検索などの下流タスクに適用可能で、250以上の言語にわたる100以上のタスクを含むMMTEBで評価した結果、従来のモデルを大幅に上回る性能を示しました。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_reachsumit/status/1899667900728037621?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>世のdecoder-onlyモデルベースのembeddingモデルがどのように作られているか具体的によくわかっていないので読みたい</p>
<p>Geminiのパラメータでbi-directionalなself-attentionを持つtransformer (たとえばBERT)で初期化し、全てのtokenをmean poling (HF BERT ModelのPoolerLayerのようなもの)することでトークンの情報を単一のembeddingに混ぜる。<br>学習は2段階のfinetuning (pre-finetuning, finetuning)によって、モデルをContrastive Learningする（NCE loss）。<br>pre-finetuningはnoisyだが大規模なデータ（web上のタイトルとparagraphのペアなど）、そのあとのfinetuningはQAなどの高品質なデータを利用。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="softmatcha-a-1734" class="title-link">SoftMatcha: A Fast and Soft Pattern Matcher for Billion-Scale Corpus Searches, Deguchi+, ICLR'25</h3>
<br><a href="https://softmatcha.github.io/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1734" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="STS%20(SemanticTextualSimilarity).html" target="_blank" rel="noopener noreferrer">#STS (SemanticTextualSimilarity)</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<span class="issue_date">Issue Date: 2025-01-28</span>
<span class="snippet"><span>Comment</span><p>ICLR2025にacceptされた模様<br>


<a href="https://openreview.net/forum?id=Q6PAnqYVpo" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Q6PAnqYVpo</a>


</p>
<p>openreview:


<a href="https://openreview.net/forum?id=Q6PAnqYVpo" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=Q6PAnqYVpo</a>


</p>
<p>


<a href="https://arxiv.org/abs/2503.03703" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2503.03703</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="grounding-language-1671" class="title-link">Grounding Language Model with Chunking-Free In-Context Retrieval, Hongjin Qian+, arXiv'24</h3>
<br><a href="https://arxiv.org/abs/2402.09760" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1671" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Supervised-FineTuning%20(SFT).html" target="_blank" rel="noopener noreferrer">#Supervised-FineTuning (SFT)</a>
<a class="button" href="RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<span class="snippet"><span>GPT Summary</span>- CFICは、Retrieval-Augmented Generation（RAG）システム向けの新しいリトリーバルアプローチで、従来のチャンク化を回避し、文書のエンコードされた隠れ状態を利用して正確な証拠テキストを特定します。制約付き文のプレフィックスデコーディングとスキップデコーディングを組み込むことで、リトリーバルの効率と生成された証拠の忠実性を向上させます。CFICはオープンQAデータセットで評価され、従来の方法に対して大幅な改善を示し、RAGシステムの効率的で効果的なリトリーバルソリューションを提供します。</span>
<span class="snippet"><span>Comment</span><p>Chunking無しでRAGを動作させられるのは非常に魅力的。<br><img src="https://github.com/user-attachments/assets/8841930a-3099-46c8-aae7-50f52473fbb1" alt="image" loading="lazy"></p>
<p>一貫してかなり性能が向上しているように見える<br><img src="https://github.com/user-attachments/assets/6eae7811-090a-4f84-aa8d-6d74a55e8427" alt="image" loading="lazy"></p>
<p>提案手法の概要。InputとOutput全体の実例がほとんど掲載されていないので憶測を含みます。<br><br>気持ちとしては、ソーステキストが与えられたときに、Questionの回答をsupportするようなソース中のpassageの情報を活用して回答するために、重要なsentenceのprefixを回答生成前に生成させる（重要なsentenceの識別子の役割を果たす）ことで、（識別子によって重要な情報によって条件づけられて回答生成ができるやうになるのて）それら情報をより考慮しながらモデルが回答を生成できるようになる、といった話だと思われる。<br><br>Table2のようなテンプレートを用いて、ソーステキストと質問文でモデルを条件付けて、回答をsupportするsentenceのprefixを生成する。生成するprefixは各sentenceのユニークなprefixのtoken log probabilityの平均値によって決まる（トークンの対数尤度が高かったらモデルが暗黙的にその情報はQuestionにとって重要だと判断しているとみなせる）。SkipDecodingの説を読んだが、ぱっと見よく分からない。おそらく[eos]を出力させてprefix間のデリミタとして機能させたいのだと思うが、[eos]の最適なpositionはどこなのか？みたいな数式が出てきており、これがデコーディングの時にどういった役割を果たすのかがよくわからない。<br><br>また、モデルはQAと重要なPassageの三つ組のデータで提案手法によるデコーディングを適用してSFTしたものを利用する。<br><br><img src="https://github.com/user-attachments/assets/fa4e575e-c6cb-452a-be3e-0d9bacb3cacb" alt="image" loading="lazy"><br><img src="https://github.com/user-attachments/assets/1985754f-c21f-4904-be50-6f4f7eef56d1" alt="image" loading="lazy"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="linguistically-conditioned-1669" class="title-link">Linguistically Conditioned Semantic Textual Similarity, Jingxuan Tu+, ACL'24</h3>
<br><a href="https://arxiv.org/abs/2406.03673" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1669" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="STS%20(SemanticTextualSimilarity).html" target="_blank" rel="noopener noreferrer">#STS (SemanticTextualSimilarity)</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<span class="snippet"><span>GPT Summary</span>- 条件付きSTS（C-STS）は文の意味的類似性を測定するNLPタスクであるが、既存のデータセットには評価を妨げる問題が多い。本研究では、C-STSの検証セットを再アノテーションし、アノテーター間の不一致を55%観察。QAタスク設定を活用し、アノテーションエラーを80%以上のF1スコアで特定する自動エラー識別パイプラインを提案。また、モデル訓練によりC-STSデータのベースライン性能を向上させる新手法を示し、エンティティタイプの型特徴構造（TFS）を用いた条件付きアノテーションの可能性についても議論する。</span>
</article>
<article class="paper-entry">
<h3 id="semdedup-data-efficient-2445" class="title-link">[Paper Note] SemDeDup: Data-efficient learning at web-scale through semantic  deduplication, Amro Abbas+, arXiv'23</h3>
<br><a href="https://arxiv.org/abs/2303.09540" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2445" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Deduplication.html" target="_blank" rel="noopener noreferrer">#Deduplication</a>
<span class="issue_date">Issue Date: 2025-08-16</span>
<span class="snippet"><span>GPT Summary</span>- SemDeDupは、事前学習モデルの埋め込みを用いて意味的に重複するデータペアを特定し削除する手法。LAIONのサブセットで50%のデータ削除を実現し、トレーニング時間を半分に短縮。分布外性能も向上し、C4データセットでも効率性を改善。質の高い埋め込みを活用することで、データ削減と学習加速を両立。</span>
<span class="snippet"><span>Comment</span><p>embedding空間において近傍のサンプル(near-duplicates)を削除することで、学習効率が向上します、という話な模様。<br><img width="957" height="535" alt="Image" src="&lt;a%20href=" https: target="_blank" rel="noopener noreferrer">https://github.com/user-attachments/assets/11511a7e-feaa-4e7b-8276-628fe5099be9"


/&gt;<br><br>openreview:


<a href="https://openreview.net/forum?id=IRSesTQUtb&noteId=usQjFYYAZJ" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=IRSesTQUtb&noteId=usQjFYYAZJ</a>


<br><br>openreviewによると、embedding空間においてnear-duplicatesを削除するというアイデアは興味深いが、提案手法は既存研究のアイデアを組み合わせているに留まっており（多くのブログポストやdeduplicationのためのライブラリも存在する）新規性が明確ではない点や、実験結果が不足している（i.e., 全てのケースでSoTAというわけでもなく、大規模モデルでの実験やstrong baselineの不在（実験結果はrandom pruningに対してoutperformすることが主に示されている）など、論文の主張をサポートするための結果が足りない）という指摘がされている。<br>実用的にはwell-writtenでexampleも豊富とのことなので、Deduplicationの理解を深めるのに良さそう。</p>
<p>先行研究:<br>- （画像）<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2688" target="_blank" rel="noopener noreferrer">[Paper Note] Beyond neural scaling laws: beating power law scaling via data pruning, Ben Sorscher+, NeurIPS'22</a>
 <br>- （テキスト）<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2689" target="_blank" rel="noopener noreferrer">[Paper Note] Deduplicating Training Data Makes Language Models Better, Katherine Lee+, ACL'22</a>
<br><br><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2688" target="_blank" rel="noopener noreferrer">[Paper Note] Beyond neural scaling laws: beating power law scaling via data pruning, Ben Sorscher+, NeurIPS'22</a>
 では、分類が難しい画像のデータという観点にフォーカスしており、<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2689" target="_blank" rel="noopener noreferrer">[Paper Note] Deduplicating Training Data Makes Language Models Better, Katherine Lee+, ACL'22</a>
 では、テキストの表層的な情報の一致に基づいてDeduplicationを実施している。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="semppl-predicting-602" class="title-link">SemPPL: Predicting pseudo-labels for better contrastive representations, Matko Bošnjak+, N_A, ICLR'23</h3>
<br><a href="https://arxiv.org/abs/2301.05158" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/602" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="Semi-Supervised.html" target="_blank" rel="noopener noreferrer">#Semi-Supervised</a>
<span class="issue_date">Issue Date: 2023-04-30</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、コンピュータビジョンにおける半教師あり学習の問題を解決するために、Semantic Positives via Pseudo-Labels (SemPPL)という新しい手法を提案している。この手法は、ラベル付きとラベルなしのデータを組み合わせて情報豊富な表現を学習することができ、ResNet-$50$を使用してImageNetの$1\%$および$10\%$のラベルでトレーニングする場合、競合する半教師あり学習手法を上回る最高性能を発揮することが示された。SemPPLは、強力な頑健性、分布外および転移性能を示すことができる。</span>
<span class="snippet"><span>Comment</span><p>後ほど説明を追記する<br><img src="https://github.com/user-attachments/assets/4441dc6c-a7b2-4ec9-9748-b6558a96e1af" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/8a78a40e-f5c4-4742-9e5d-36cd1b8d0e60" alt="image" loading="lazy"><br><br><img src="https://github.com/user-attachments/assets/04ded9aa-c875-4282-9e3b-7ce456a6cc44" alt="image" loading="lazy"></p>
<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1975" target="_blank" rel="noopener noreferrer">A Simple Framework for Contrastive Learning of Visual Representations, Ting Chen+, ICML'20</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="matryoshka-representation-2311" class="title-link">[Paper Note] Matryoshka Representation Learning, Aditya Kusupati+, NeurIPS'22</h3>
<br><a href="https://arxiv.org/abs/2205.13147" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2311" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="Length.html" target="_blank" rel="noopener noreferrer">#Length</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-07-29</span>
<span class="snippet"><span>GPT Summary</span>- マトリョーシカ表現学習（MRL）は、異なる計算リソースに適応可能な柔軟な表現を設計する手法であり、既存の表現学習パイプラインを最小限に修正して使用します。MRLは、粗から細への表現を学習し、ImageNet-1K分類で最大14倍小さい埋め込みサイズを提供し、実世界のスピードアップを実現し、少数ショット分類で精度向上を達成します。MRLは視覚、視覚+言語、言語のモダリティにわたるデータセットに拡張可能で、コードとモデルはオープンソースで公開されています。</span>
<span class="snippet"><span>Comment</span><p>日本語解説:


<a href="https://speakerdeck.com/hpprc/lun-jiang-zi-liao-matryoshka-representation-learning" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/hpprc/lun-jiang-zi-liao-matryoshka-representation-learning</a>


</p>
<p>単一のモデルから複数のlengthのEmbeddingを出力できるような手法。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="improving-neural-379" class="title-link">Improving Neural Machine Translation with Compact Word Embedding Tables, Kumar+, AAAI'22</h3>
<br><a href="https://arxiv.org/pdf/2104.08677.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/379" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<span class="issue_date">Issue Date: 2021-06-07</span>
<span class="snippet"><span>Comment</span><p>NMTにおいてword embeddingがどう影響しているかなどを調査しているらしい</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="an-embedding-1901" class="title-link">[Paper Note] An Embedding Learning Framework for Numerical Features in CTR Prediction, Huifeng Guo+, KDD'21</h3>
<br><a href="https://arxiv.org/abs/2012.08986" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1901" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="CTRPrediction.html" target="_blank" rel="noopener noreferrer">#CTRPrediction</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="SIGKDD.html" target="_blank" rel="noopener noreferrer">#SIGKDD</a>
<a class="button" href="numeric.html" target="_blank" rel="noopener noreferrer">#numeric</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-04-22</span>
<span class="snippet"><span>GPT Summary</span>- CTR予測のための新しい埋め込み学習フレームワーク「AutoDis」を提案。数値特徴の埋め込みを強化し、高いモデル容量とエンドツーエンドのトレーニングを実現。メタ埋め込み、自動離散化、集約の3つのコアコンポーネントを用いて、数値特徴の相関を捉え、独自の埋め込みを学習。実験により、CTRとeCPMでそれぞれ2.1%および2.7%の改善を達成。コードは公開されている。</span>
<span class="snippet"><span>Comment</span><p>従来はdiscretizeをするか、mlpなどでembeddingを作成するだけだった数値のinputをうまく埋め込みに変換する手法を提案し性能改善<br><br>数値情報を別の空間に写像し自動的なdiscretizationを実施する機構と、各数値情報のフィールドごとのglobalな情報を保持するmeta-embeddingをtrainable parameterとして学習し、両者を交互作用（aggregation; max-poolingとか）することで数値embeddingを取得する。<br><br><img width="589" alt="Image" src="&lt;a%20href=" https: target="_blank" rel="noopener noreferrer">https://github.com/user-attachments/assets/1f626dd5-2452-4b50-a14c-6c24fa022435"


/&gt;<br><br><img width="429" alt="Image" src="&lt;a%20href=" https: target="_blank" rel="noopener noreferrer">https://github.com/user-attachments/assets/12fd6476-241a-4d13-975d-f6c1c762c497"


/&gt;</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="simcse-simple-907" class="title-link">SimCSE: Simple Contrastive Learning of Sentence Embeddings, Tianyu Gao+, N_A, EMNLP'21</h3>
<br><a href="https://arxiv.org/abs/2104.08821" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/907" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<a class="button" href="Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-07-27</span>
<span class="snippet"><span>GPT Summary</span>- この論文では、SimCSEという対比学習フレームワークを提案しています。このフレームワークは、文の埋め込み技術を進化させることができます。教師なしアプローチでは、入力文をノイズとして扱い、自己を対比的に予測します。教師ありアプローチでは、自然言語推論データセットから注釈付きのペアを使用して対比学習を行います。SimCSEは、意味的テキスト類似性タスクで評価され、以前の手法と比較して改善を実現しました。対比学習は、事前学習された埋め込みの空間を均一に正則化し、教師信号が利用可能な場合には正のペアをよりよく整列させることが示されました。</span>
<span class="snippet"><span>Comment</span><p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/462" target="_blank" rel="noopener noreferrer">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks, Reimers+, UKP-TUDA, EMNLP'19</a>
 よりも性能良く、unsupervisedでも学習できる。STSタスクのベースラインにだいたい入ってる</p>
<p># 手法概要<br><br>Contrastive Learningを活用して、unsupervised/supervisedに学習を実施する。<br><br>Unsupervised SimCSEでは、あるsentenceをencoderに2回入力し、それぞれにdropoutを適用させることで、positive pairを作成する。dropoutによって共通のembeddingから異なる要素がマスクされた（noiseが混ざった状態とみなせる）類似したembeddingが作成され、ある種のdata augmentationによって正例を作成しているともいえる。負例はnegative samplingする。（非常にsimpleだが、next sentence predictionで学習するより性能が良くなる）<br><br>Supervised SimCSEでは、アノテーションされたsentence pairに基づいて、正例・負例を決定する。本研究では、NLIのデータセットにおいて、entailment関係にあるものは正例として扱う。contradictions（矛盾）関係にあるものは負例として扱う。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ba20a1ca-0078-4227-8bb3-3805ee57a620" alt="image" loading="lazy"><br><br><br><br># Siamese Networkで用いられるmeans-squared errrorとContrastiveObjectiveの違い<br><br>どちらもペアワイズで比較するという点では一緒だが、ContrastiveObjectiveは正例と近づいたとき、負例と遠ざかったときにlossが小さくなるような定式化がされている点が異なる。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d9cad930-e86d-4758-87b5-4237525a154a" alt="image" loading="lazy"><br><br>（画像はこのブログから引用。ありがとうございます。


<a href="https://techblog.cccmk.co.jp/entry/2022/08/30/163625%EF%BC%89" target="_blank" rel="noopener noreferrer">https://techblog.cccmk.co.jp/entry/2022/08/30/163625）</a>


<br><br><br><br># Unsupervised SimCSEの実験<br><br>異なるdata augmentation手法と比較した結果、dropoutを適用する手法の方が性能が高かった。MLMや, deletion, 類義語への置き換え等よりも高い性能を獲得しているのは興味深い。また、Next Sentence Predictionと比較しても、高い性能を達成。Next Sentence Predictionは、word deletion等のほぼ類似したテキストから直接的に類似関係にあるペアから学習するというより、Sentenceの意味内容のつながりに基づいてモデルの言語理解能力を向上させ、そのうえで類似度を測るという間接的な手法だが、word deletionに負けている。一方、dropoutを適用するだけの（直接的に類似ペアから学習する）本手法はより高い性能を示している。<br><br>[image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0ea3549e-3363-4857-94e6-a1ef474aa191)<br><br><br><br>なぜうまくいくかを分析するために、異なる設定で実験し、alignment（正例との近さ）とuniformity（どれだけembeddingが一様に分布しているか）を、10 stepごとにplotした結果が以下。dropoutを適用しない場合と、常に同じ部分をマスクする方法（つまり、全く同じembeddingから学習する）設定を見ると、学習が進むにつれuniformityは改善するが、alignmentが悪くなっていっている。一方、SimCSEはalignmentを維持しつつ、uniformityもよくなっていっていることがわかる。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5f488cb2-b15a-4e00-9452-8e48780abe8a" alt="image" loading="lazy"><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5e815cf7-b412-4f1b-8adb-116f0dcd2fee" alt="image" loading="lazy"><br><br><br><br># Supervised SimCSEの実験<br><br>アノテーションデータを用いてContrastiveLearningするにあたり、どういったデータを正例としてみなすと良いかを検証するために様々なデータセットで学習し性能を検証した。<br><br><br><br>- QQP4: Quora question pairs<br><br>- Flickr30k (Young et al., 2014): 同じ画像に対して、5つの異なる人間が記述したキャプションが存在<br><br>- ParaNMT (Wieting and Gimpel, 2018): back-translationによるparaphraseのデータセットa<br><br>- NLI datasets: SNLIとMNLI<br><br><br><br>実験の結果、NLI datasetsが最も高い性能を示した。この理由としては、NLIデータセットは、crowd sourcingタスクで人手で作成された高品質なデータセットであることと、lexical overlapが小さくなるようにsentenceのペアが作成されていることが起因している。実際、NLI datsetのlexical overlapは39%だったのに対し、ほかのデータセットでは60%であった。<br><br><br><br>また、condunctionsとなるペアを明示的に負例として与えることで、より性能が向上した（普通はnegative samplingする、というかバッチ内の正例以外のものを強制的に負例とする。こうすると、意味が同じでも負例になってしまう事例が出てくることになる）。より難しいNLIタスクを含むANLIデータセットを追加した場合は、性能が改善しなかった。この理由については考察されていない。性能向上しそうな気がするのに。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/ae05711b-5ad4-4a53-837b-c57e9a39da62" alt="image" loading="lazy"><br><br></p>
<p># 他手法との比較結果<br><br>SimCSEがよい。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/510744ff-01bb-47be-9e30-2efa49e0f923" alt="image" loading="lazy"><br><br><br><br># Ablation Studies<br><br>異なるpooling方法で、どのようにsentence embeddingを作成するかで性能の違いを見た。originalのBERTの実装では、CLS token のembeddingの上にMLP layerがのっかっている。これの有無などと比較。<br><br>Unsupervised SimCSEでは、training時だけMLP layerをのっけて、test時はMLPを除いた方が良かった。一方、Supervised SimCSEでは、 MLP layerをのっけたまんまで良かったとのこと。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/73116c6a-d48f-42bc-aa5e-8342bb068052" alt="image" loading="lazy"><br><br></p>
<p>また、SimCSEで学習したsentence embeddingを別タスクにtransferして活用する際には、SimCSEのobjectiveにMLMを入れた方が、catastrophic forgettingを防げて性能が高かったとのこと。<br><br><br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/cc6d20c3-5a0c-4b5e-aa6d-63447c55363f" alt="image" loading="lazy"></p>
<p>ablation studiesのhard negativesのところと、どのようにミニバッチを構成するか、それぞれのtransferしたタスクがどのようなものがしっかり読めていない。あとでよむ。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="dense-passage-3016" class="title-link">[Paper Note] Dense Passage Retrieval for Open-Domain Question Answering, Vladimir Karpukhin+, EMNLP'20, 2020.04</h3>
<br><a href="https://arxiv.org/abs/2004.04906" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3016" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="ContrastiveLearning.html" target="_blank" rel="noopener noreferrer">#ContrastiveLearning</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-09-28</span>
<span class="snippet"><span>GPT Summary</span>- 密な表現を用いたパッセージ検索の実装を示し、デュアルエンコーダーフレームワークで学習。評価の結果、Lucene-BM25を上回り、検索精度で9%-19%の改善を達成。新たな最先端のQA成果を確立。</span>
<span class="snippet"><span>Comment</span><p>Dense Retrieverが広く知られるきっかけとなった研究（より古くはDSSM <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/364" target="_blank" rel="noopener noreferrer">Learning Deep Structured Semantic Models  for Web Search using Clickthrough Data, Huang+, CIKM'13</a>
 などがある)。bag-of-wordsのようなsparseなベクトルで検索するのではなく（=Sparse Retriever)、ニューラルモデルでエンコードした密なベクトルを用いて検索しようという考え方である。<br><br>Query用と検索対象のPassageをエンコードするEncoderを独立してそれぞれ用意し（＝DualEncoder)、QAの学習データ（すなわちクエリqと正例として正解passage p+)が与えられた時、クエリqと正例p+の類似度が高く、負例p-との類似度が低くなるように（=Contrastive Learning)、Query, Passage Encoderのパラメータを更新することで学習する（損失関数は式(2))。<br><br>負例はIn-Batch Negativeを用いる。情報検索の場合正解ラベルは多くの場合明示的に決まるが、負例は膨大なテキストのプールからサンプリングしなければならない。サンプリング方法はいろいろな方法があり（e.g., ランダムにサンプリング、qとbm25スコアが高いpassage（ただし正解は含まない; hard negativesと呼ぶ）その中の一つの方法がIn-Batch Negativesである。<br><br>In-Batch Negativesでは、同ミニバッチ内のq_iに対応する正例p+_i以外の全てのp_jを（擬似的に）負例とみなす。これにより、パラメータの更新に利用するためのq,pのエンコードを全て一度だけ実行すれば良く、計算効率が大幅に向上するという優れもの。本研究の実験（Table3)によると上述したIn-Batch Negativeに加えて、bm25によるhard negativeをバッチ内の各qに対して1つ負例として追加する方法が最も性能が良かった。<br><br>クエリ、passageのエンコーダとしては、BERTが用いられ、[CLS]トークンに対応するembeddingを用いて類似度が計算される。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="deep-contextualized-457" class="title-link">Deep contextualized word representations, Peters+, Allen Institute for Artificial intelligence, NAACL'18</h3>
<br><a href="https://arxiv.org/pdf/1802.05365.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/457" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<span class="issue_date">Issue Date: 2022-06-08</span>
<span class="snippet"><span>Comment</span><p>ELMo論文。<br>通常のword embeddingでは一つの単語につき一つの意味しか持たせられなかったが、文脈に応じて異なる意味を表現できるようなEmbeddingを実現し（同じ単語でも文脈に応じて意味が変わったりするので。たとえばrightは文脈に応じて右なのか、正しいなのか、権利なのか意味が変わる）様々な言語処理タスク（e.g. Question Answering, Sentiment Analysisなど）でSoTAを達成。<br><br><img src="https://user-images.githubusercontent.com/12249301/172505957-a2fc5319-5670-4807-a870-31377227299e.png" alt="image" loading="lazy"><br><br>Embedding Layer + 2層のLSTM（1,2の間にはresidual connection）+ linear layerで言語モデルを構成し、順方向言語モデルと逆方向言語モデルを同時に独立して学習する（双方向LSTMではない;損失関数が両方向の言語モデルの対数尤度の和になっている）。<br>また、Linear LayerとEmbedding Layerのパラメータは両方向の言語モデルで共有されている。<br><br>k番目の単語のEmbedding Layerの出力ベクトル、各LSTMのhidden stateをタスクspecificなスカラーパラメタs_taskで足し合わせ、最後にベクトルのスケールを調整するパラメタγ_taskで大きさを調整する。これにより、k番目の単語のELMo Embeddingを得る。<br>単語単体の意味だけでこと足りるタスクの場合はEmbedding Layerの出力ベクトルに対する重みが大きくなり、文脈を考慮した情報が欲しい場合はLSTMのhidden stateに対する重みが大きくなるイメージ（LSTMの層が深いほど意味的semanticな情報を含み、浅いほど文法的syntacticな情報を含んでいる）。<br><br>使い方としては簡単で、ELMoを事前学習しておき、自身のNNモデルのWord Embeddingに（場合によってはRNNのhidden stateにも）、入力文から得られたELMo Embeddingをconcatして順伝搬させるだけで良い。</p>
<p>s_taskとγ_taskはtrainableなパラメータで、<br>ELMoを適用した先のNNモデルの訓練時に、NNモデルのパラメタと一緒にチューニングする（と思われる）。<br><br>


<a href="https://github.com/allenai/allennlp/issues/1166" target="_blank" rel="noopener noreferrer">https://github.com/allenai/allennlp/issues/1166</a>


<br>


<a href="https://github.com/allenai/allennlp/issues/2552" target="_blank" rel="noopener noreferrer">https://github.com/allenai/allennlp/issues/2552</a>


</p>
<p>ELMoのEmbedding Layerでは、2048 characterの（vocab size?）n-gram convolution filter（文字ごとにembeddingし、単語のembeddingを得るためにfilterを適用する？）の後に2つのhighway networkをかませてlinearで512次元に落とすみたいなことごやられているらしい。ここまで追えていない。<br><br>詳細は下記<br>


<a href="https://datascience.stackexchange.com/questions/97867/how-does-the-character-convolution-work-in-elmo" target="_blank" rel="noopener noreferrer">https://datascience.stackexchange.com/questions/97867/how-does-the-character-convolution-work-in-elmo</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="starspace-embed-68" class="title-link">[Paper Note] StarSpace: Embed All The Things, Wu+, AAAI'18</h3>
<br><a href="https://arxiv.org/abs/1709.03856" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/68" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="General.html" target="_blank" rel="noopener noreferrer">#General</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="AAAI.html" target="_blank" rel="noopener noreferrer">#AAAI</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<span class="snippet"><span>Comment</span><p>分類やランキング、レコメンドなど、様々なタスクで汎用的に使用できるEmbeddingの学習手法を提案。<br><br><br><br>Embeddingを学習する対象をEntityと呼び、Entityはbag-of-featureで記述される。<br><br>Entityはbag-of-featureで記述できればなんでもよく、<br><br>これによりモデルの汎用性が増し、異なる種類のEntityでも同じ空間上でEmbeddingが学習される。<br><br><br><br>学習方法は非常にシンプルで、Entity同士のペアをとったときに、relevantなpairであれば類似度が高く、<br><br>irelevantなペアであれば類似度が低くなるようにEmbeddingを学習するだけ。<br><br>たとえば、Entityのペアとして、documentをbag-of-words, bag-of-ngrams, labelをsingle wordで記述しテキスト分類、<br><br>あるいは、user_idとユーザが過去に好んだアイテムをbag-of-wordsで記述しcontent-based recommendationを行うなど、 応用範囲は幅広い。<br><br><br><br>5種類のタスクで提案手法を評価し、既存手法と比較して、同等かそれ以上の性能を示すことが示されている。<br><br><br><br>手法の汎用性が高く学習も高速なので、色々な場面で役に立ちそう。<br><br>また、異なる種類のEntityであっても同じ空間上でEmbeddingが学習されるので、学習されたEmbeddingの応用先が広く有用。</p>
<p>実際にSentimentAnalysisで使ってみたが（ポジネガ二値分類）、少なくともBoWのSVMよりは全然性能良かったし、学習も早いし、次元数めちゃめちゃ少なくて良かった。<br><br>StarSpaceで学習したembeddingをBoWなSVMに入れると性能が劇的に改善した。</p>
<p>解説：<br><br>


<a href="https://www.slideshare.net/akihikowatanabe3110/starspace-embed-all-the-things" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/akihikowatanabe3110/starspace-embed-all-the-things</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="multi-view-unsupervised-210" class="title-link">[Paper Note] Multi-View Unsupervised User Feature Embedding for Social Media-based Substance Use Prediction, Ding+, EMNLP'17</h3>
<br><a href="http://aclweb.org/anthology/D/D17/D17-1240.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/210" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="UserModeling.html" target="_blank" rel="noopener noreferrer">#UserModeling</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2018-01-01</span>
</article>
<article class="paper-entry">
<h3 id="skip-gram-–-79" class="title-link">[Paper Note] Skip-Gram – Zipf + Uniform = Vector Additivity, Gittens+, ACL'17</h3>
<br><a href="http://aclweb.org/anthology/P/P17/P17-1007.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/79" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Word.html" target="_blank" rel="noopener noreferrer">#Word</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2017-12-30</span>
<span class="snippet"><span>Comment</span><p>解説スライド：


<a href="http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/09.pdf" target="_blank" rel="noopener noreferrer">http://www.lr.pi.titech.ac.jp/~haseshun/acl2017suzukake/slides/09.pdf</a>


</p>
<p>Embeddingの加法構成性（e.g. man+royal=king）を理論的に理由づけ<br><br>（解説スライドより）</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="poincaré-embeddings-78" class="title-link">[Paper Note] Poincaré Embeddings for Learning Hierarchical Representations, Maximilian Nickel+, NIPS'17, 2017.05</h3>
<br><a href="https://arxiv.org/abs/1705.08039" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/78" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Word.html" target="_blank" rel="noopener noreferrer">#Word</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2017-12-29</span>
<span class="snippet"><span>GPT Summary</span>- 記号データの階層的表現を学習する新しいアプローチを提案し、n次元ポアンカレボールに埋め込むことで階層と類似性を同時に捉える。リーマン最適化に基づく効率的なアルゴリズムを導入し、ポアンカレ埋め込みがユークリッド埋め込みを上回る表現能力と一般化能力を持つことを実験で示した。</span>
<span class="snippet"><span>Comment</span><p>解説: 


<a href="http://tech-blog.abeja.asia/entry/poincare-embeddings" target="_blank" rel="noopener noreferrer">http://tech-blog.abeja.asia/entry/poincare-embeddings</a>


<br><br>解説スライド：


<a href="https://speakerdeck.com/eumesy/poincare-embeddings-for-learning-hierarchical-representations" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/eumesy/poincare-embeddings-for-learning-hierarchical-representations</a>


<br><br>実装：


<a href="https://github.com/TatsuyaShirakawa/poincare-embedding" target="_blank" rel="noopener noreferrer">https://github.com/TatsuyaShirakawa/poincare-embedding</a>


<br><br></p>
<p>・階層構造を持つデータ（WordNet上の上位語下位語、is-a関係など）を埋め込むために、双曲空間を使った話（通常はユークリッド空間）。<br><br>・階層構造・べき分布を持つデータはユークリッド空間ではなく双曲空間の方が効率的に埋め込める。<br><br>・階層構造・べき分布を持つデータを双曲空間（ポアンカレ球モデル）に埋め込むための学習手法（リーマン多様体上でSGD）を提案<br><br>・WordNet hypernymyの埋め込み：低次元でユークリッド埋め込みに圧勝<br><br>・Social Networkの埋め込み：低次元だと圧勝<br><br>・Lexical Entailment：2つのデータセットでSoTA<br><br>上記は解説スライドから勉強しメモ:<br>Poincaré Embeddings for Learning Hierarchical Representations, Sho Yokoi, 2017-09-15, 第9回最先端NLP勉強会<br>


<a href="https://speakerdeck.com/eumesy/poincare-embeddings-for-learning-hierarchical-representations" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/eumesy/poincare-embeddings-for-learning-hierarchical-representations</a>


</p>
<p><img src="https://user-images.githubusercontent.com/12249301/34452953-0e124ad6-ed8d-11e7-800d-0c2712df116a.png" alt="image" loading="lazy"><br><br>(解説スライドp.20より)<br><br><br>データとして上位・下位概念を与えていないのに、原点付近には上位語・円周付近には下位語が自然に埋め込まれている（意図した通りになっている）。<br><br>ポアンカレ円板では、原点からの距離に応じて指数的に円周長が増加していくので、指数的に数が増えていく下位語などは外側に配置されると効率的だけど、その通りになっている。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/34452994-7c17a738-ed8d-11e7-8a56-13929c55c07e.png" alt="image" loading="lazy"><br><br>（解説スライドp.9より、スライド全体のスクショではないので元ページ参照のこと）<br><br><br><br>スクショは解説スライドより引用:<br>Poincaré Embeddings for Learning Hierarchical Representations, Sho Yokoi, 2017-09-15, 第9回最先端NLP勉強会<br>


<a href="https://speakerdeck.com/eumesy/poincare-embeddings-for-learning-hierarchical-representations" target="_blank" rel="noopener noreferrer">https://speakerdeck.com/eumesy/poincare-embeddings-for-learning-hierarchical-representations</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="supervised-learning-71" class="title-link">[Paper Note] Supervised Learning of Universal Sentence Representations from Natural Language Inference Data, Alexis Conneau+, arXiv'17, 2017.05</h3>
<br><a href="https://arxiv.org/abs/1705.02364" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/71" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<span class="snippet"><span>GPT Summary</span>- 文の埋め込みを学習する試みは成功していないが、スタンフォード自然言語推論データセットを用いた監督学習による普遍的な文表現が、無監督手法を上回ることを示す。自然言語推論は他のNLPタスクへの転送学習に適していることが示唆される。エンコーダは公開されている。</span>
<span class="snippet"><span>Comment</span><p>slide: 


<a href="https://www.slideshare.net/naoakiokazaki/supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/naoakiokazaki/supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data</a>


</p>
<p>汎用的な文のエンコーダができました！という話。<br><br><br><br>SNLIデータでパラメータ学習、エンコーダ構成スライド図中右側のエンコーダ部分をなるべく一般的な文に適用できるように学習したい。<br><br><br><br>色々なタスクで、文のエンコーダ構成を比較した結果、bi-directional LSTMでエンコードし、要素ごとの最大値をとる手法が最も良いという結果。<br><br>隠れ層の次元は4096とかそのくらい。<br><br>Skip-Thoughtは学習に1ヶ月くらいかかるけど、提案手法はより少ないデータで1日くらいで学習終わり、様々なタスクで精度が良い。<br><br><br><br>ベクトルの要素積、concat,  subなど、様々な演算を施し、学習しているので、そのような構成の元から文エンコーダを学習すると何か意味的なものがとれている？<br><br>SNLIはNatural Language Inferenceには文の意味理解が必須なので、そのデータ使って学習するといい感じに文のエンコードができます。<br><br><br><br>NLIのデータは色々なところで有用なので、日本語のNLIのデータとかも欲しい。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="a-structured-69" class="title-link">[Paper Note] A Structured Self-attentive Sentence Embedding, Zhouhan Lin+, ICLR'17, 2017.03</h3>
<br><a href="https://arxiv.org/abs/1703.03130" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/69" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<span class="snippet"><span>GPT Summary</span>- 自己注意機構を用いた新しい文埋め込みモデルを提案。2次元行列で文の異なる部分に注意を払い、視覚化手法も提供。著者プロファイリング、感情分類、テキスト含意の3つのタスクで評価し、他の手法と比較して性能が向上したことを示す。</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=BJC_jUqxe" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=BJC_jUqxe</a>


</p>
<p>日本語解説:


<a href="https://ryotaro.dev/posts/a_structured_self_attentivesentence_embedding/" target="_blank" rel="noopener noreferrer">https://ryotaro.dev/posts/a_structured_self_attentivesentence_embedding/</a>


</p>
<p>self-attentionを提案した研究</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="learning-distributed-70" class="title-link">[Paper Note] Learning Distributed Representations of Sentences from Unlabelled Data, Felix Hill+, NAACL'16, 2016.02</h3>
<br><a href="https://arxiv.org/abs/1602.03483" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/70" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="NAACL.html" target="_blank" rel="noopener noreferrer">#NAACL</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<span class="snippet"><span>GPT Summary</span>- 無監督手法によるフレーズや文の分散表現の学習に関するモデルの比較を行い、最適なアプローチはアプリケーションに依存することを示す。深いモデルは監視システムに適している一方、浅いロジスティック回帰モデルは単純な空間距離メトリックに最適。さらに、トレーニング時間やドメイン移植性を考慮した新しい無監督表現学習の目的も提案。</span>
<span class="snippet"><span>Comment</span><p>Sentenceのrepresentationを学習する話<br><br><br><br>代表的なsentenceのrepresentation作成手法(CBOW, SkipGram, SkipThought, Paragraph Vec, NMTなど)をsupervisedな評価（タスク志向+supervised）とunsupervisedな評価(文間の距離をコサイン距離ではかり、人間が決めた順序と相関を測る)で比較している。<br><br><br><br>また筆者らはSequential Denoising Auto Encoder(SDAE)とFastSentと呼ばれる手法を提案しており、前者はorderedなsentenceデータがなくても訓練でき、FastSentはorderedなsentenceデータが必要だが高速に訓練できるモデルである。<br><br><br><br>実験の結果、supervisedな評価では、基本的にはSkipThoughtがもっとも良い性能を示し、paraphrasingタスクにおいて、SkipThoughtに3ポイント程度差をつけて良い性能を示した。unsupervisedな評価では、DictRepとFastSentがもっとも良い性能を示した。<br><br><br><br>実験の結果、以下のような知見が得られた：<br><br><br><br>## 異なるobjective functionは異なるembeddingを作り出す<br><br>objective functionは、主に隣接する文を予測するものと、自分自身を再現するものに分けられる。これらの違いによって、生成されるembeddingが異なっている。Table5をみると、後者については、生成されたrepresentationのnearest neighborを見ていると、自身と似たような単語を含む文が引っ張ってこれるが、前者については、文のコンセプトや機能は似ているが、単語の重複は少なかったりする。<br><br><br><br>## supervisedな場合とunsupervisedな評価でのパフォーマンスの違い<br><br>supervisedな設定では、SkipThoughtやSDAEなどのモデルが良い性能を示しているが、unsupervisedな設定ではまりうまくいかず。unsupevisedな設定ではlog-linearモデルが基本的には良い性能を示した。<br><br><br><br>## pre-trainedなベクトルを使用したモデルはそうでない場合と比較してパフォーマンスが良い<br><br><br><br>## 必要なリソースの違い<br><br>モデルによっては、順序づけられた文のデータが必要だったり、文の順序が学習に必要なかったりする。あるいは、デコーディングに時間がかかったり、めちゃくちゃメモリ食ったりする。このようなリソースの性質の違いは、使用できるapplicationに制約を与える。<br><br><br><br>## 結論<br><br>とりあえず、supervisedなモデルにrepresentationを使ってモデルになんらかのknowledgeをぶちこみたいときはSkipThought、単純に類似した文を検索したいとか、そういう場合はFastSentを使うと良いってことですかね.</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="retrofitting-word-3883" class="title-link">[Paper Note] Retrofitting Word Vectors to Semantic Lexicons, Manaal Faruqui+, NAACL'15, 2014.11</h3>
<br><a href="https://arxiv.org/abs/1411.4166" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3883" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Word.html" target="_blank" rel="noopener noreferrer">#Word</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="Finetuning.html" target="_blank" rel="noopener noreferrer">#Finetuning</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-12-04</span>
<span class="snippet"><span>GPT Summary</span>- 意味的レキシコンの情報を活用して、単語のベクトル空間表現を改善する手法を提案。関連する単語が類似のベクトルを持つよう促し、従来の仮定に依存しない。複数の言語での語彙意味評価タスクで大幅な改善を示し、従来技術を上回る性能を達成。</span>
<span class="snippet"><span>Comment</span><p>日本語解説:


<a href="https://www.slideshare.net/slideshow/20150421-forupdate/47365800" target="_blank" rel="noopener noreferrer">https://www.slideshare.net/slideshow/20150421-forupdate/47365800</a>


</p>
<p>Retrofittingという用語を今でも耳にすることがあるが、この研究のような手法を指すと思って良いと思われる（研究室の輪講で本論文の発表があったのを思い出すなぁ）。事前学習済みの単語ベクトルに対して事後的に外部知識（辞書など）を埋め込みチューニングする話。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="a-hierarchical-74" class="title-link">[Paper Note] A hierarchical neural autoencoder for paragraphs and documents, Li+, ACL'15</h3>
<br><a href="https://nlp.stanford.edu/pubs/acl2015_jiwei.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/74" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<span class="snippet"><span>Comment</span><p>複数文を生成(今回はautoencoder)するために、standardなseq2seq LSTM modelを、拡張したという話。<br><br><br><br>要は、paragraph/documentのrepresentationが欲しいのだが、アイデアとしては、word-levelの情報を扱うLSTM layerとsentenc-levelの情報を扱うLSTM layerを用意し、それらのcompositionによって、paragraph/documentを表現しましたという話。<br><br><br><br>sentence-levelのattentionを入れたらよくなっている。<br><br><br><br>trip advisorのreviewとwikipediaのparagraphを使ってtrainingして、どれだけ文書を再構築できるか実験。<br><br>MetricはROUGE, BLEUおよびcoherence(sentence order代替)を測るために、各sentence間のgapがinputとoutputでどれだけ一致しているかで評価。<br><br><br><br>hierarchical lstm with attention &gt; hierarchical lstm &gt; standard lstm の順番で高性能。<br><br><br><br>学習には、tesla K40を積んだマシンで、standard modelが2-3 weeks, hierarchical modelsが4-6週間かかるらしい。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="document-modeling-72" class="title-link">[Paper Note] Document Modeling with Gated Recurrent Neural Network for Sentiment Classification, Tang+, EMNLP'15</h3>
<br><a href="http://aclweb.org/anthology/D15-1167" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/72" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Document.html" target="_blank" rel="noopener noreferrer">#Document</a>
<a class="button" href="SentimentAnalysis.html" target="_blank" rel="noopener noreferrer">#SentimentAnalysis</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2017-12-28</span>
<span class="snippet"><span>Comment</span><p>word level -&gt; sentence level -&gt; document level のrepresentationを求め、documentのsentiment classificationをする話。<br><br>documentのRepresentationを生成するときに参考になるやも。<br><br>sentenceのrepresentationを求めるときは、CNN/LSTMを使う。<br><br>document levelに落とすことは、bi-directionalなGatedRNN(このGatedRNNはLSTMのoutput-gateが常にonになっているようなものを使う。sentenceのsemanticsに関する情報を落としたくないかららしい。)を使う。<br><br>sentiment classificationタスクで評価し、(sentence levelのrepresentationを求めるときは)LSTMが最も性能がよく、documentのrepresentationを求めるときは、standardなRNNよりもGatedRNNのほうが性能よかった。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="introducing-zerank-2-3757" class="title-link">Introducing zerank-2: The Most Accurate Multilingual Instruction-Following Reranker, ZeroEntropy, 2025.11</h3>
<br><a href="https://www.zeroentropy.dev/articles/zerank-2-advanced-instruction-following-multilingual-reranker" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3757" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="Reranking.html" target="_blank" rel="noopener noreferrer">#Reranking</a>
<span class="issue_date">Issue Date: 2025-11-20</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/zeroentropy/zerank-2" target="_blank" rel="noopener noreferrer">https://huggingface.co/zeroentropy/zerank-2</a>


</p>
<p>SoTA reranker</p>
<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3392" target="_blank" rel="noopener noreferrer">zerank-1, zeroentropy, 2025.07</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="from-monolithic-3470" class="title-link">From Monolithic to Modular: Scaling Semantic Routing with Extensible LoRA, vLLM blog, 2025.10</h3>
<br><a href="https://blog.vllm.ai/2025/10/27/semantic-router-modular.html" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3470" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<a class="button" href="Routing.html" target="_blank" rel="noopener noreferrer">#Routing</a>
<span class="issue_date">Issue Date: 2025-10-27</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vllm_project/status/1982813303249445227?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="colbert-muvera-femto-3186" class="title-link">colbert-muvera-femto, NeuML, 2025.10</h3>
<br><a href="https://huggingface.co/collections/NeuML/colbert-68cb248ce424a6d6d8277451" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3186" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="Encoder.html" target="_blank" rel="noopener noreferrer">#Encoder</a>
<span class="issue_date">Issue Date: 2025-10-09</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/neumll/status/1975923919614800347?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="introducing-embeddinggemma-2693" class="title-link">Introducing EmbeddingGemma: The Best-in-Class Open Model for On-Device Embeddings, Google, 2025.09</h3>
<br><a href="https://developers.googleblog.com/en/introducing-embeddinggemma/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2693" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/collections/google/embeddinggemma-68b9ae3a72a82f0562a80dc4" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/google/embeddinggemma-68b9ae3a72a82f0562a80dc4</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/osanseviero/status/1963635281032040914?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1963634786636841461?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tomaarsen/status/1963639557653422304?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="gemini-embedding-2343" class="title-link">Gemini Embedding: Powering RAG and context engineering, Google, 2025.07</h3>
<br><a href="https://developers.googleblog.com/en/gemini-embedding-powering-rag-context-engineering/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2343" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<span class="issue_date">Issue Date: 2025-08-03</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1951659302478832091?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>financial, legal文書に対する性能が向上してマトリョーシカ表現によってストレージや計算コストを削減可能な模様</p>
<p>ダウンストリームタスクで使おうとすると次元数がデカすぎるとしんどいのでマトリョーシカ表現は嬉しい</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="日経電子版のアプリトップ「おすすめ」をtwo-towerモデルでリプレースしました-2113" class="title-link">日経電子版のアプリトップ「おすすめ」をTwo Towerモデルでリプレースしました, NIKKEI, 2025.05</h3>
<br><a href="https://hack.nikkei.com/blog/replace_ai_rec_by_two_tower/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2113" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="AWS.html" target="_blank" rel="noopener noreferrer">#AWS</a>
<a class="button" href="MLOps.html" target="_blank" rel="noopener noreferrer">#MLOps</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="A_B%20Testing.html" target="_blank" rel="noopener noreferrer">#A/B Testing</a>
<a class="button" href="TwoTowerModel.html" target="_blank" rel="noopener noreferrer">#TwoTowerModel</a>
<span class="issue_date">Issue Date: 2025-06-29</span>
<span class="snippet"><span>Comment</span><p>リアルタイム推薦をするユースケースにおいて、ルールベース+協調フィルタリング(Jubatus)からTwo Towerモデルに切り替えた際にレイテンシが300ms増えてしまったため、ボトルネックを特定し一部をパッチ処理にしつつもリアルタイム性を残すことで解決したという話。AWSの構成、A/Bテストや負荷テストの話もあり、実用的で非常に興味深かった。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="qwen_qwen3-embedding-4b-gguf-2020" class="title-link">Qwen_Qwen3-Embedding-4B-GGUF, QwenTeam, 2025.06</h3>
<br><a href="https://huggingface.co/Qwen/Qwen3-Embedding-4B-GGUF" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2020" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-06-06</span>
<span class="snippet"><span>Comment</span><p>8BモデルはMTEBでトップの性能を達成。context 32K。100以上の言語をサポート。32--2560次元にoutputの次元数をカスタマイズできる（嬉しい、が性能にどの程度影響が出るから気になる）。</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1930739968332157018?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>QwenTeam post:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/alibaba_qwen/status/1930648422778118246?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="8-types-1823" class="title-link">8 Types of RoPE, Kseniase, 2025.03</h3>
<br><a href="https://huggingface.co/posts/Kseniase/498106595218801" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1823" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="PositionalEncoding.html" target="_blank" rel="noopener noreferrer">#PositionalEncoding</a>
<span class="issue_date">Issue Date: 2025-03-23</span>
<span class="snippet"><span>Comment</span><p>元ポスト:


<a href="https://huggingface.co/posts/Kseniase/498106595218801" target="_blank" rel="noopener noreferrer">https://huggingface.co/posts/Kseniase/498106595218801</a>


</p>
<p>RoPEについてサーベイが必要になったら見る</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="modernbert-ja-130m-1761" class="title-link">modernbert-ja-130m, SB Intuitions, 2025.02</h3>
<br><a href="https://huggingface.co/sbintuitions/modernbert-ja-130m" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1761" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="pretrained-LM.html" target="_blank" rel="noopener noreferrer">#pretrained-LM</a>
<a class="button" href="Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<span class="snippet"><span>Comment</span><p>ＭIT Licence</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sbintuitions/status/1889587801706078580?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1606" target="_blank" rel="noopener noreferrer">ModernBERT, AnswerDotAI, 2024.12</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="floret-1619" class="title-link">floret, explosion, 2021</h3>
<br><a href="https://github.com/explosion/floret" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1619" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Word.html" target="_blank" rel="noopener noreferrer">#Word</a>
<a class="button" href="Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-12-28</span>
<span class="snippet"><span>Comment</span><p>fasttextを拡張したもの。本家fasttextがアーカイブ化してしまったので、代替手段に良さそう。</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/fukkaa1225/status/1872222983772938551?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="sarashina-embedding-v1-1b-1582" class="title-link">Sarashina-Embedding-v1-1B, SB Intuitions, 2024.12</h3>
<br><a href="https://huggingface.co/sbintuitions/sarashina-embedding-v1-1b" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1582" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<span class="issue_date">Issue Date: 2024-12-10</span>
<span class="snippet"><span>Comment</span><p>Non-commercialなライセンスで、商用利用の場合は問い合わせが必要</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="zipf-白色化：タイプとトークンの区別がもたらす良質な埋め込み空間と損失関数-1536" class="title-link">Zipf 白色化：タイプとトークンの区別がもたらす良質な埋め込み空間と損失関数, Sho Yokoi, 2024.11</h3>
<br><a href="https://speakerdeck.com/eumesy/zipfian-whitening" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1536" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Word.html" target="_blank" rel="noopener noreferrer">#Word</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="STS%20(SemanticTextualSimilarity).html" target="_blank" rel="noopener noreferrer">#STS (SemanticTextualSimilarity)</a>
<span class="issue_date">Issue Date: 2024-11-20</span>
<span class="snippet"><span>GPT Summary</span>- 単語埋め込み空間の歪みを修正することでタスクのパフォーマンスが向上することを示す。既存のアプローチは単語頻度が均一であると仮定しているが、実際にはZipfの法則に従う非均一な分布である。Zipfに基づく頻度で重み付けされたPCAホワイトニングを行うことで、パフォーマンスが大幅に向上し、ベースラインを超える。情報幾何学的な観点から、低頻度の単語を強調する理論を提案し、人気の自然言語処理手法がこの理論に基づいて機能することを示す。</span>
<span class="snippet"><span>Comment</span><p>元論文: [Yokoi, Bao, Kurita, Shimodaira, “Zipfian Whitening,” NeurIPS 2024. ](


<a href="https://arxiv.org/abs/2411.00680)" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2411.00680)</a>


</p>
<p>単語ベクトルを活用して様々なタスクを実施する際に一般的な全部足して個数で割るような平均ベクトル計算は、<br>個々の単語頻度を一様と仮定した場合の"期待値"と等価であり、<br>これは現実世界の単語頻度の実態とは全然異なるから、きちんと考慮したいよね、という話で<br><img src="https://github.com/user-attachments/assets/cc38dbd5-8b6e-45e6-8a81-00f524eb36f8" alt="image" loading="lazy"><br>頻度を考慮するとSemantic Textual Similarity（STS）タスクで効果絶大であることがわかった。<br><img src="https://github.com/user-attachments/assets/2042d75f-6325-4e50-9423-f8621084fb75" alt="image" loading="lazy"><br><br>では、なぜこれまで一様分布扱いするのが一般的だったのかというと、<br>実態として単語埋め込み行列が単語をタイプとみなして構築されたものであり、<br>コーパス全体を捉えた（言語利用の実態を捉えた）データ行列（単語をトークンとみなしたもの）になっていなかったことに起因していたからです（だから、経験頻度を用いて頻度情報を復元する必要があるよね）、<br>という感じの話だと思われ、<br><img src="https://github.com/user-attachments/assets/ba97319c-83f7-4443-a8e3-fa36030d704b" alt="image" loading="lazy"><br><br>経験頻度を考慮すると、そもそも背後に仮定しているモデル自体が暗黙的に変わり、<br>低頻度語が強調されることで、単語に対してTF-IDFのような重みづけがされることで性能が良くなるよね、みたいな話だと思われる。<br><img src="https://github.com/user-attachments/assets/7495f250-d680-4698-99c5-a326ead77e12" alt="image" loading="lazy"></p>
<p>余談だが、昔のNLPでは、P(w,c)をモデル化したものを生成モデル、テキスト生成で一般的なP(w|c)は分類モデル（VAEとかはテキスト生成をするが、生成モデルなので別）、と呼んでいたと思うが、いまはテキスト生成モデルのことを略して生成モデル、と呼称するのが一般的なのだろうか。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="late-chunking-1383" class="title-link">Late Chunking: Balancing Precision and Cost in Long Context Retrieval, Pierse+, 2024.09</h3>
<br><a href="https://weaviate.io/blog/late-chunking" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1383" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-09-08</span>
<span class="snippet"><span>Comment</span><p>chunkingしてからembeddingを取得するより、全体のドキュメントに対してcontextualなtoken embeddingを取得し、その後chunkingをしてpoolingしてsingle vectorにする方が、文書の文脈情報がembedding内で保持されやすいので、precisionが上がりますよ、という話<br><br>スクショは記事中より引用<br><img src="https://github.com/user-attachments/assets/5fc20551-62f3-4965-8e3d-18540806fb34" alt="image" loading="lazy"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="ruri-japanese-1375" class="title-link">Ruri: Japanese General Text Embeddings, cl-nagoya, 2024.09</h3>
<br><a href="https://huggingface.co/collections/cl-nagoya/ruri-japanese-general-text-embeddings-66cf1f3ee0c8028b89d85b5e" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1375" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<span class="issue_date">Issue Date: 2024-09-04</span>
<span class="snippet"><span>Comment</span><p>元ツイート:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hpp_ricecake/status/1831308092459643232?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>337Mパラメータのモデルで、同等のサイズのモデルをJMTEBで大きく上回る性能。LLMを用いて生成したデータを用いてContrastive Learning, その後高品質なデータでFinetuningを実施したとのこと。</p>
<p>JMTEB上では、パラメータサイズ不明（だがおそらく桁違いに大きい）のOpenAI/text-embedding-3-largeと同等の性能に見えるが、<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1373" target="_blank" rel="noopener noreferrer">LLMに日本語テキストを学習させる意義, Koshiro Saito+, 第261回自然言語処理研究発表会, 2024.08</a>
 などを考慮すると、日本特有の知識を問うQAなどはマルチリンガルなモデルは弱そうなので、その辺がどれほど高い性能を持っているのかは興味がある。<br><br>LLMで人工的に生成したデータでは、生成に利用したLLMが持つ知識しか表層的には現れないと思うので何を利用したかによるのと、高品質なラベルデータにその辺がどの程度含まれているか。</p>
<p>最大sequence長は1012なので、より長い系列をBERTで埋め込みたい場合はRetrievaBERT  <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1323" target="_blank" rel="noopener noreferrer">RetrievaBERTの公開, 2024</a>
 （最大sequence長2048）も検討の余地がある。</p>
<p>開発者の方からテクニカルレポートが出た<br>


<a href="https://arxiv.org/abs/2409.07737" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2409.07737</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="japanese-simple-1057" class="title-link">Japanese Simple SimCSE</h3>
<br><a href="https://github.com/hppRC/simple-simcse-ja" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1057" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Sentence.html" target="_blank" rel="noopener noreferrer">#Sentence</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2023-10-07</span>
<span class="snippet"><span>Comment</span><p>日本語の事前学習言語モデルと、日本語の学習データを利用してSimCSEを学習し網羅的に評価をした結果が記載されている。Supervised SimCSE, UnsupervisednSimCSEの両方で実験。また、学習するデータセットを変更したときの頑健性も検証。性能が良かったモデルはSentenceTransformersから利用可能な形で公開されている。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="awesome-vector-565" class="title-link">Awesome Vector Search Engine</h3>
<br><a href="https://github.com/currentslab/awesome-vector-search" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/565" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Search.html" target="_blank" rel="noopener noreferrer">#Search</a>
<a class="button" href="Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2023-04-27</span>
<span class="snippet"><span>Comment</span><p>ベクトルの類似度を測るサービスやライブラリ等がまとまったリポジトリ</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="training-a-531" class="title-link">Training a recommendation model with dynamic embeddings</h3>
<br><a href="https://blog.tensorflow.org/2023/04/training-recommendation-model-with-dynamic-embeddings.html?m=1" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/531" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<span class="snippet"><span>Comment</span><p>dynamic embeddingを使った推薦システムの構築方法の解説</p>
<p>（理解が間違っているかもしれないが）推薦システムは典型的にはユーザとアイテムをベクトル表現し、関連度を測ることで推薦をしている。この枠組みをめっちゃスケールさせるととんでもない数のEmbeddingを保持することになり、メモリ上にEmbeddingテーブルを保持して置けなくなる。特にこれはonline machine learning（たとえばユーザのセッションがアイテムのsequenceで表現されたとき、そのsequenceを表すEmbeddingを計算し保持しておき、アイテムとの関連度を測ることで推薦するアイテムを決める、みたいなことが必要）では顕著である（この辺の理解が浅い）。しかし、ほとんどのEmbeddingはrarely seenなので、厳密なEmbeddingを保持しておくことに実用上の意味はなく、それらを単一のベクトルでできるとメモリ節約になって嬉しい（こういった処理をしてもtopNの推薦結果は変わらないと思われるので）。<br>これがdynamic embeddingのモチベであり、どうやってそれをTFで実装するか解説している。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="clap-527" class="title-link">CLAP</h3>
<br><a href="https://huggingface.co/docs/transformers/model_doc/clap" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/527" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="SpokenLanguageProcessing.html" target="_blank" rel="noopener noreferrer">#SpokenLanguageProcessing</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<span class="snippet"><span>Comment</span><p>テキストとオーディオの大量のペアを事前学習することで、テキストとオーディオ間を同じ空間に写像し、類似度を測れるようにしたモデル</p>
<p>たとえばゼロショットでaudio分類ができる<br><img src="https://user-images.githubusercontent.com/12249301/234293138-20edf6cd-3259-4547-a2fc-69893273fa76.jpeg" alt="image" loading="lazy"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="openke-383" class="title-link">OpenKE, 2021</h3>
<br><a href="http://139.129.163.161/home" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/383" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="KnowledgeGraph.html" target="_blank" rel="noopener noreferrer">#KnowledgeGraph</a>
<a class="button" href="Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2021-06-10</span>
<span class="snippet"><span>Comment</span><p>Wikipedia, Freebase等のデータからKnowledge Embeddingを学習できるオープンソースのライブラリ</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="airbnbの機械学習導入から学ぶ-340" class="title-link">Airbnbの機械学習導入から学ぶ, Jun Ernesto Okumura, 2020</h3>
<br><a href="https://speakerdeck.com/pacocat/airbnbfalseji-jie-xue-xi-dao-ru-karaxue-bu" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/340" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="SessionBased.html" target="_blank" rel="noopener noreferrer">#SessionBased</a>
<a class="button" href="SequentialRecommendation.html" target="_blank" rel="noopener noreferrer">#SequentialRecommendation</a>
<span class="issue_date">Issue Date: 2020-08-29</span>
</article>
</div>
<script>
document.addEventListener("DOMContentLoaded", function() {
  // Twitterのwidgets.jsを動的に一度だけ読み込む関数
  let twitterScriptLoaded = false;
  function loadTwitterScript() {
    if (!twitterScriptLoaded) {
      const script = document.createElement('script');
      script.src = "https://platform.twitter.com/widgets.js";
      script.charset = "utf-8";
      script.async = true;
      document.body.appendChild(script);
      twitterScriptLoaded = true;
    }
  }

  // Intersection Observerの設定
  const observer = new IntersectionObserver((entries, obs) => {
    entries.forEach(entry => {
      if (entry.isIntersecting) {
        // 画面に入った時だけスクリプトをロード開始
        loadTwitterScript();

        const container = entry.target;
        const embedHtml = container.getAttribute('data-embed');
        
        if (embedHtml) {
          container.innerHTML = embedHtml;
          container.removeAttribute('data-embed');
          
          // ウィジェットの再スキャン（twttrオブジェクトが準備できていれば実行）
          if (window.twttr && window.twttr.widgets) {
            window.twttr.widgets.load(container);
          }
        }
        obs.unobserve(container);
      }
    });
  }, { rootMargin: '200px' }); // 少し早めに読み込む

  document.querySelectorAll('.tweet-embed').forEach(el => observer.observe(el));
});
</script>


    </div>

</article>
<div class="post-nav">
<a class="previous" href="/paper_notes/articles/Depth/" title="Depthに関する論文・技術記事メモの一覧">Depthに関する論文・技術記事メモの一覧</a><a class="next" href="/paper_notes/articles/Finetuning/" title="Finetuningに関する論文・技術記事メモの一覧">Finetuningに関する論文・技術記事メモの一覧</a>
</div>
<div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li class="">
          <a class="post-link" href="/paper_notes/articles/SelfCorrection/" title="SelfCorrectionに関する論文・技術記事メモの一覧">
            SelfCorrectionに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 21</span> 
  <span class="post-badge badge-new">📝 21</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/ExperimentManagement/" title="ExperimentManagementに関する論文・技術記事メモの一覧">
            ExperimentManagementに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 3</span> 
  <span class="post-badge badge-new">📝 3</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/LLM-as-a-Judge/" title="LLM-as-a-Judgeに関する論文・技術記事メモの一覧">
            LLM-as-a-Judgeに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 26</span> 
  <span class="post-badge badge-new">📝 26</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/Blog/" title="Blogに関する論文・技術記事メモの一覧">
            Blogに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 344</span> 
  <span class="post-badge badge-new">📝 344</span>
</span>
</a>
        </li>
</ul>
    </div>
<div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
/* --- レイアウト用（前回と同じ） --- */
.post-menu {
  position: -webkit-sticky;
  position: sticky;
  top: 20px;
  max-height: calc(100vh - 40px);
  display: flex;
  flex-direction: column;
}

.post-menu-title {
  flex-shrink: 0;
  margin-bottom: 10px;
  font-weight: bold;
}

.post-menu-content {
  overflow-y: auto;
  scrollbar-width: thin;
}

.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}

/* --- 開閉アニメーションとアイコン用 --- */

/* h2のスタイル：クリックできるようにする */
.post-menu li.h-h2 {
  cursor: pointer;
  position: relative;
  padding-left: 15px; /* アイコン用のスペース */
  font-weight: bold;
  margin-top: 5px;
}

/* 開閉アイコン（▼） */
.post-menu li.h-h2::before {
  content: '';
  display: inline-block;
  width: 0;
  height: 0;
  border-style: solid;
  border-width: 5px 0 5px 6px; /* 三角形 */
  border-color: transparent transparent transparent #555;
  position: absolute;
  left: 0;
  top: 50%;
  transform: translateY(-50%);
  transition: transform 0.2s ease;
}

.post-menu li.h-h2.no-icon::before {
  content: none; /* 擬似要素の中身をなしにする */
  /* または display: none; でもOKです */
}

/* 開いている時のアイコン（下向きにする） */
.post-menu li.h-h2.open::before {
  transform: translateY(-50%) rotate(90deg);
}

/* h3（子要素）のスタイル */
.post-menu li.h-h3 {
  margin-left: 15px;
  font-size: 0.9em;
  /* 初期状態はJSで制御しますが、念のため */
}

/* アクティブな項目の色 */
.post-menu li.active > a {
  color: #d9534f;
  font-weight: bold;
}

/* リンク自体のスタイル調整 */
.post-menu li a {
  text-decoration: none;
  color: inherit;
  display: inline-block;
  width: 100%;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">TOC</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent = menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3");

    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // --- HTML生成 ---
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      // h-h2 クラスの要素には初期状態で open クラスをつけるか、つけないかで「最初から開いているか」を決められます
      // ここでは閉じた状態をデフォルトとします
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }
    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';


    // --- 開閉ロジックの実装 ---
    var listItems = menuContent.querySelectorAll('li');

    // h2要素にクリックイベントを追加
    listItems.forEach(function(item, index) {
      if (item.classList.contains('h-h2')) {
        
        // クリックイベント
        item.addEventListener('click', function(e) {
          // リンクをクリックした場合はページ内遷移させたいので、イベントを止めない
          // ただし、アイコン付近をクリックした等の挙動を統一するため、
          // 開閉処理を行います。
          
          // クラスの付け替え（アイコンの回転用）
          item.classList.toggle('open');

          // 次のh2が出てくるまで、h3を表示/非表示切り替え
          for (var i = index + 1; i < listItems.length; i++) {
            var sibling = listItems[i];
            if (sibling.classList.contains('h-h2')) {
              break; // 次のh2に来たら終了
            }
            if (sibling.classList.contains('h-h3')) {
              if (item.classList.contains('open')) {
                sibling.style.display = 'block';
              } else {
                sibling.style.display = 'none';
              }
            }
          }
        });
      }
    });

    // --- 初期状態の設定（すべて閉じる） ---
    // もし最初から開いておきたい場合は、このブロックを削除するか調整してください
    listItems.forEach(function(item) {
      if (item.classList.contains('h-h3')) {
        item.style.display = 'none';
      }
    });


    // --- スクロール連動（ハイライト機能のみ残す） ---
    var header = document.querySelector('header.site-header');
    
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header ? header.getBoundingClientRect() : {top:0, height:0}; // headerがない場合の安全策
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var offset = headerTop + headerHeight + 20;

        if (headingRect.top <= offset) {
          var id = h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          
          if (curActive) {
            // もしアクティブになった項目が閉じているh2の中にあった場合、
            // 自動で開く処理を追加したい場合はここに記述します。
            // 今回は「手動開閉」を優先し、自動オープンはあえて行いません。
            
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }

      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
      }
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/paper_notes/"></data>

  <div class="wrapper">
    <div class="site-footer-inner">
<div>Copyright © 2023-current AkihikoWATANABE. The header images and any thumbnail images for the posts were generated by ChatGPT's DALL-E3.</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="https://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div class="footer-col rss-subscribe">Subscribe <a href="/paper_notes/feed.xml">via RSS</a>
</div>
    </div>
  </div>
</footer>
</body>
  </html>
