<!DOCTYPE html>
<html lang="ja">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c">
  <link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="preconnect" href="https://www.googletagmanager.com" crossorigin>
  <link rel="preconnect" href="https://www.google-analytics.com" crossorigin>
  <link rel="preconnect" href="https://platform.twitter.com">
  <link rel="preconnect" href="https://pbs.twimg.com">
  <link rel="dns-prefetch" href="https://cdnjs.cloudflare.com">
  <link rel="dns-prefetch" href="https://cdn.jsdelivr.net">
  <link rel="dns-prefetch" href="https://platform.twitter.com">
  <link rel="dns-prefetch" href="https://pbs.twimg.com">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Supervised-FineTuning (SFT)に関する論文・技術記事メモの一覧 | わたしのべんきょうノート</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="Supervised-FineTuning (SFT)に関する論文・技術記事メモの一覧">
<meta name="author" content="AkihikoWATANABE">
<meta property="og:locale" content="ja">
<meta name="description" content="&lt;h2 id=Supervised-FineTuning (SFT) class=”paper-head”&gt; Supervised-FineTuning (SFT)&lt;/h2&gt;&lt;div class=&quot;visible-content&quot;&gt; [Paper Note] LightAgent: Mobile Agentic Foundation Models, Yangqin Jiang+, arXiv'25, 2025.10 Paper/Blog Link My Issue #ComputerVision #Pocket #NLP #ReinforcementLearning #AIAgents #SyntheticData #MultiModal #Reasoning #SmallModel #OpenWeight #ComputerUse #VisionLanguageModel #One-Line Notes #GUI Issue Date: 2026-01-19 GPT Summary- LightAgentは、モバイルプラットフォーム向けにデバイスとクラウドの協力を活用したGUIエージェントシステムを提案。これにより、オフライン性能とコスト効率を両立し、強化された二段階トレーニングを通じて高い意思決定能力を実現。実験を通じて大規模モデルに匹敵する性能を示し、クラウドコストを大幅に削減。 Commentpj page:">
<meta property="og:description" content="&lt;h2 id=Supervised-FineTuning (SFT) class=”paper-head”&gt; Supervised-FineTuning (SFT)&lt;/h2&gt;&lt;div class=&quot;visible-content&quot;&gt; [Paper Note] LightAgent: Mobile Agentic Foundation Models, Yangqin Jiang+, arXiv'25, 2025.10 Paper/Blog Link My Issue #ComputerVision #Pocket #NLP #ReinforcementLearning #AIAgents #SyntheticData #MultiModal #Reasoning #SmallModel #OpenWeight #ComputerUse #VisionLanguageModel #One-Line Notes #GUI Issue Date: 2026-01-19 GPT Summary- LightAgentは、モバイルプラットフォーム向けにデバイスとクラウドの協力を活用したGUIエージェントシステムを提案。これにより、オフライン性能とコスト効率を両立し、強化された二段階トレーニングを通じて高い意思決定能力を実現。実験を通じて大規模モデルに匹敵する性能を示し、クラウドコストを大幅に削減。 Commentpj page:">
<link rel="canonical" href="http://akihikowatanabe.github.io/paper_notes/articles/Supervised-FineTuning-(SFT)/">
<meta property="og:url" content="http://akihikowatanabe.github.io/paper_notes/articles/Supervised-FineTuning-(SFT)/">
<meta property="og:site_name" content="わたしのべんきょうノート">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2026-01-19T00:00:00+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="Supervised-FineTuning (SFT)に関する論文・技術記事メモの一覧">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"AkihikoWATANABE"},"dateModified":"2026-01-19T00:00:00+00:00","datePublished":"2026-01-19T00:00:00+00:00","description":"&lt;h2 id=Supervised-FineTuning (SFT) class=”paper-head”&gt; Supervised-FineTuning (SFT)&lt;/h2&gt;&lt;div class=&quot;visible-content&quot;&gt; [Paper Note] LightAgent: Mobile Agentic Foundation Models, Yangqin Jiang+, arXiv&#39;25, 2025.10 Paper/Blog Link My Issue #ComputerVision #Pocket #NLP #ReinforcementLearning #AIAgents #SyntheticData #MultiModal #Reasoning #SmallModel #OpenWeight #ComputerUse #VisionLanguageModel #One-Line Notes #GUI Issue Date: 2026-01-19 GPT Summary- LightAgentは、モバイルプラットフォーム向けにデバイスとクラウドの協力を活用したGUIエージェントシステムを提案。これにより、オフライン性能とコスト効率を両立し、強化された二段階トレーニングを通じて高い意思決定能力を実現。実験を通じて大規模モデルに匹敵する性能を示し、クラウドコストを大幅に削減。 Commentpj page:","headline":"Supervised-FineTuning (SFT)に関する論文・技術記事メモの一覧","mainEntityOfPage":{"@type":"WebPage","@id":"http://akihikowatanabe.github.io/paper_notes/articles/Supervised-FineTuning-(SFT)/"},"url":"http://akihikowatanabe.github.io/paper_notes/articles/Supervised-FineTuning-(SFT)/"}</script>
<!-- End Jekyll SEO tag -->
<link rel="icon" href="">
  <link rel="canonical" href="http://akihikowatanabe.github.io">

  <link rel="preload" href="/paper_notes/assets/css/main.css" as="style">
  <link rel="preload" href="/paper_notes/assets/js/main.js" as="script">

  <link rel="stylesheet" href="/paper_notes/assets/css/main.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/custom_button.css">
  
  <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"></noscript>
  <link rel="preload" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css" as="style" onload="this. onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css"></noscript>
  
  <script src="/paper_notes/assets/js/main.js"></script><link type="application/atom+xml" rel="alternate" href="http://akihikowatanabe.github.io/paper_notes/feed.xml" title="わたしのべんきょうノート">
<script>
  function showMore(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "block";
          
      // このボタンの参照を取得して非表示にします
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "none";
      }
          
      // hideボタンの参照を取得して表示します
      const hideButton = contentDiv.querySelector('button[onclick^="hideContent"]');
      if (hideButton) {
        hideButton.style.display = "block";
      }
    }
  }

  function hideContent(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "none";
  
      // moreボタンの参照を取得して表示します
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "block";
      }
  
      // このボタンを隠します
      const hideButtons = document.querySelectorAll('button[onclick^="hideContent"]');
      const hideButton = hideButtons[index];
      if (hideButton) {
        hideButton.style.display = "none";
      }
    }
  }
</script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js" async></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe-lightbox.umd.min.js" async></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe.umd.min.js" async></script>
<link href="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/photoswipe.min.css" rel="stylesheet">
<style>
  .pswp .pswp__container .pswp__img {
    background-color: white;
  }
</style>

<script>
  function initPhotoSwipe() {
    let customOptions = {};

    try {
      const data = `{"gallery"=>"section.main", "children"=>"a.photo-swipe", "bgOpacity"=>0.8, "padding"=>{"top"=>20, "bottom"=>40, "left"=>100, "right"=>100}}`.replaceAll("=>", ":");
      customOptions = JSON.parse(data);
    } catch (e) {
      console.info("Invalid custom photo previewer options! " + e.message);
    }

    // Define object and gallery options
    const options = Object.assign(
      {
        gallery: "section.main",
        children: "a.photo-swipe",
        photo_scale: 2,
        // dynamic import is not supported in UMD version
        pswpModule: PhotoSwipe,
      },
      customOptions
    );

    const galleryEl = document.querySelector(options.gallery);
    if (!galleryEl) {
      return;
    }

    const imgEls = [];
    const els = galleryEl.querySelectorAll("img:not(.emoji)");
    els.forEach((el) => {
      if (el.src.trim() == "") {
        return;
      }
      if (!imgEls.includes(el)) {
        imgEls.push(el);
      }
    });

    if (imgEls.length === 0) {
      return;
    }

    imgEls.forEach((imgEl) => {
      imgEl.outerHTML = `
      <a class="photo-swipe"
        href="${imgEl.src}"
        data-pswp-width="${
          Math.max(imgEl.naturalWidth, imgEl.width) * options.photo_scale
        }"
        data-pswp-height="${
          Math.max(imgEl.naturalHeight, imgEl.height) * options.photo_scale
        }"
        data-pswp-caption="${imgEl.getAttribute("caption") || imgEl.alt}"
        target="_blank">
        ${imgEl.outerHTML}
      </a>`;
    });

    // Initialize PhotoSwipe 5
    var lightbox = new PhotoSwipeLightbox(options);

    lightbox.init();
  }

  window.addEventListener("load", initPhotoSwipe);
</script>
<meta name="google-site-verification" content="u_DTTPcCZ806iq51zgirHyWq3556HUKGq8AQfH91iFI">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-P70KSB88WH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-P70KSB88WH');
  </script>

<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"},"svg":{"fontCache":"global"}}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>


<body>





































































































































<header class="site-header site-header-transparent" role="banner">

  <div class="wrapper">
    <div class="site-header-inner">
<span class="site-brand"><a class="site-brand-inner" rel="author" href="/paper_notes/">
  <img class="site-favicon" title="わたしのべんきょうノート" src="" onerror="this.style.display='none'">
  わたしのべんきょうノート
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger">
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewbox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
              </svg>
            </span>
          </label>

          <div class="trigger">
<a class="page-link" href="/paper_notes/">論文や技術メモの一覧（随時更新）</a><a class="page-link" href="/paper_notes/archives.html">ARCHIVES</a>









<span class="page-link">



<div id="google_translate_element" style="display: none;">
</div>

<span class="ct-language">
  <ul class="list-unstyled ct-language-dropdown">
    
      <li>
        <a href="#" class="lang-select" data-lang="en">
          
          <img src="https://cdn.countryflags.com/thumbs/united-states-of-america/flag-400.png" title="English">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="fr">
          
          <img src="https://cdn.countryflags.com/thumbs/france/flag-400.png" title="French">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="zh-CN">
          
          <img src="https://cdn.countryflags.com/thumbs/china/flag-400.png" title="Chinese(Simple)">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ja">
          
          <img src="https://cdn.countryflags.com/thumbs/japan/flag-400.png" title="Japanese">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ko">
          
          <img src="https://cdn.countryflags.com/thumbs/south-korea/flag-400.png" title="Korean">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ru">
          
          <img src="https://cdn.countryflags.com/thumbs/russia/flag-400.png" title="Russian">
          
        </a>
      </li>
    
  </ul>
</span>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'ja',
    autoDisplay: false,
    layout: google.translate.TranslateElement.InlineLayout.VERTICAL
  }, 'google_translate_element');

  // Links to cross-origin destinations are unsafe
  var gll = document.getElementsByClassName('goog-logo-link')[0];
  if (gll) {
    gll.setAttribute('rel', 'noopener');
  }

  function restoreLang() {
    var iframe = document.getElementsByClassName('goog-te-banner-frame')[0];
    if (!iframe) return;

    var innerDoc = iframe.contentDocument || iframe.contentWindow.document;
    var restore_el = innerDoc.getElementsByTagName("button");

    for (var i = 0; i < restore_el.length; i++) {
      if (restore_el[i].id.indexOf("restore") >= 0) {
        restore_el[i].click();
        var close_el = innerDoc.getElementsByClassName("goog-close-link");
        close_el[0].click();
        return;
      }
    }
  }

  function triggerHtmlEvent(element, eventName) {
    var event;
    if (document.createEvent) {
      event = document.createEvent('HTMLEvents');
      event.initEvent(eventName, true, true);
      element.dispatchEvent(event);
    } else {
      event = document.createEventObject();
      event.eventType = eventName;
      element.fireEvent('on' + event.eventType, event);
    }
  }

  var googleCombo = document.querySelector("select.goog-te-combo");
  var langSelect = document.querySelector('.ct-language');
  langSelect.addEventListener('click', function(event) {
    if (!event.target) {
      return;
    }

    var selected = document.querySelector('.ct-language .ct-language-selected');
    if (selected) {
      selected.classList.remove('ct-language-selected');
    }

    var target = event.target;
    while (target && target !== langSelect ) {
      if (target.matches('.lang-select')) {
        break;
      }
      target = target.parentElement;
    }

    if (target && target.matches('.lang-select')) {
      var lang = target.getAttribute('data-lang');
      if (googleCombo.value == lang) {
        restoreLang();
      } else {
        target.parentElement.classList.add('ct-language-selected');
        googleCombo.value = lang;
        triggerHtmlEvent(googleCombo, 'change');
      }
    }

    event.preventDefault();
  });
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit" async></script>
</span>
</div>
        </nav>
</div>
  </div>
</header>

<script>
  function initHeader() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;
    var ticking = false;

    function storeScrollData() {
      var y = getScrollPos().y;documentElement.setAttribute("data-header-transparent", "");var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0);
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
      
      // 処理完了フラグをリセット
      ticking = false;
    }

    function requestTick() {
      if (!ticking) {
        // 次の描画フレームで実行をスケジュール
        window.requestAnimationFrame(storeScrollData);
        ticking = true;
      }
    }

    // passive:  true でスクロールパフォーマンスを向上
    window.addEventListener('scroll', requestTick, { passive: true });

    // 初期実行
    storeScrollData();
  }
  
  document.addEventListener('DOMContentLoaded', initHeader);
</script>


























































































































































<style>
    html .page-banner .page-banner-img > *:first-child {
      opacity: 0.4;
    }

    html[data-theme="dark"] .page-banner .page-banner-img > *:first-child {
      opacity: 0.2872;
    }
  </style>
<section class="page-banner">
    <div class="page-banner-img">
<div style="background-image: url(/paper_notes/assets/images/banner.webp)"></div>
        <img class="img-placeholder" src="/paper_notes/assets/images/banner.webp">
</div>
    <div class="wrapper">
      <div class="page-banner-inner">
<header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">わたしのべんきょうノート</h1>
  <h2 class="post-subtitle">勉強した論文や技術等の情報をGithubのIssueにメモっているひとのブログ。
それなりにメモの量が蓄積されてきたので、一度整理したいなと思いブログはじめてみました！
自然言語処理(NLP), 推薦システム(RecommenderSystem), Educational Data Mining (EDM), Learning Analytics (LA)などの分野のメモが多いと思います。
最近は特にLLMの勉強が多めです :)</h2>

  <div class="post-meta">
    <time class="dt-published" datetime="2026-01-19T00:00:00+00:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Jan 19, 2026
    </time><span class="post-author left-vsplit"><i class="fa fa-pencil"></i> AkihikoWATANABE</span>
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 7 hours 50 mins</span>
  </div></header>
</div>
    </div>
  </section><script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    hashValue = decodeURIComponent(hashValue);
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('off' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<div id="click-to-top" class="click-to-top">
  <i class="fa fa-arrow-up"></i>
</div>
<script>
  (function () {
    const clickToTop = document.getElementById('click-to-top');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 100) {
        clickToTop.classList.add('show')
      }else {
        clickToTop.classList.remove('show')
      }
    });
    clickToTop.addEventListener('click', () => {
      window.smoothScrollTo(0);
    });
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <h2 id="Supervised-FineTuning" class="paper-head"> Supervised-FineTuning (SFT)</h2>
<div class="visible-content">
<article class="paper-entry">
<h3 id="lightagent-mobile-4246" class="title-link">[Paper Note] LightAgent: Mobile Agentic Foundation Models, Yangqin Jiang+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.22009" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4246" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="GUI.html" target="_blank" rel="noopener noreferrer">#GUI</a>
<span class="issue_date">Issue Date: 2026-01-19</span>
<span class="snippet"><span>GPT Summary</span>- LightAgentは、モバイルプラットフォーム向けにデバイスとクラウドの協力を活用したGUIエージェントシステムを提案。これにより、オフライン性能とコスト効率を両立し、強化された二段階トレーニングを通じて高い意思決定能力を実現。実験を通じて大規模モデルに匹敵する性能を示し、クラウドコストを大幅に削減。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://github.com/HKUDS/OpenPhone" target="_blank" rel="noopener noreferrer">https://github.com/HKUDS/OpenPhone</a>


</p>
<p>3Bで10B級の性能を誇る低lavencyのedge device向けSVLM</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huang_chao4969/status/2012551934608367980?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="bugpilot-complex-4208" class="title-link">[Paper Note] BugPilot: Complex Bug Generation for Efficient Learning of SWE Skills, Atharv Sonwane+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.19898" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4208" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="Initial%20Impression%20Notes.html" target="_blank" rel="noopener noreferrer">#Initial Impression Notes</a>
<a class="button" href="BugGeneration.html" target="_blank" rel="noopener noreferrer">#BugGeneration</a>
<span class="issue_date">Issue Date: 2026-01-16</span>
<span class="snippet"><span>GPT Summary</span>- 合成的に多様なバグを生成する新手法を提案し、SWEエージェントの訓練における高品質なバグの重要性を強調。従来の局所的摂動によるバグ生成に対し、機能追加が意図しないバグを生じさせるプロセスを採用。実験により、新生成バグが監視付きファインチューニングにおいて効率的なデータを提供し、他データセットを上回る成果を実証。FrogBossとFrogMiniモデルがSWE-benchでそれぞれ54.6%と45.3%のpass@1を達成。</span>
<span class="snippet"><span>Comment</span><p>カオスエンジニアリングみたいになってきた</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="persona-features-4202" class="title-link">[Paper Note] Persona Features Control Emergent Misalignment, Miles Wang+, arXiv'25, 2025.06</h3>
<br><a href="https://arxiv.org/abs/2506.19823" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4202" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="SparseAutoEncoder.html" target="_blank" rel="noopener noreferrer">#SparseAutoEncoder</a>
<a class="button" href="EmergentMisalignment.html" target="_blank" rel="noopener noreferrer">#EmergentMisalignment</a>
<span class="issue_date">Issue Date: 2026-01-15</span>
<span class="snippet"><span>GPT Summary</span>- 言語モデルの行動一般化はAIの安全性にとって重要であり、Betleyらの研究により、GPT-4oのファインチューニングが新たな不一致を引き起こすことが判明。これを拡張し、強化学習や合成データセットのファインチューニングでも同様の不一致を確認。スパースオートエンコーダーを用いたモデル差分比較により、不一致的ペルソナ特徴が特定され、有毒ペルソナが強い影響を与えることが示された。さらに、数百の無害なサンプルでファインチューニングすることで新たな不一致を緩和し、整合性を回復できることが発見された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/mileskwang/status/1935383921983893763?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4203" target="_blank" rel="noopener noreferrer">[Paper Note] Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs, Jan Betley+, arXiv'25, 2025.02</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="an-empirical-4174" class="title-link">[Paper Note] An Empirical Study of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning, Yun Luo+, IEEE Transactions on Audio, Speech and Language Processing'25, 2023.08</h3>
<br><a href="https://arxiv.org/abs/2308.08747" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4174" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2026-01-12</span>
<span class="snippet"><span>GPT Summary</span>- 破滅的忘却（CF）は、機械学習モデルが新しい知識を学ぶ際に以前の情報を忘れる現象であり、特に大規模言語モデル（LLMs）において調査されました。実験により、1bから7bパラメータのLLMsでCFが一般的に観察され、モデルのスケールが増すほど忘却が深刻化することが明らかになりました。デコーダ専用モデルのBLOOMZは、エンコーダ-デコーダモデルのmT0よりも忘却が少なく、知識を保持しています。また、LLMsは継続的なファインチューニング中に言語バイアスを軽減できることも示され、一般的な指示調整が忘却現象を軽減する可能性があることが示唆されました。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cwolferesearch/status/2010480993052803509?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="retaining-by-4173" class="title-link">[Paper Note] Retaining by Doing: The Role of On-Policy Data in Mitigating Forgetting, Howard Chen+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.18874" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4173" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2026-01-12</span>
<span class="snippet"><span>GPT Summary</span>- ポストトレーニングにおける「破滅的忘却」を軽減するためのガイドラインを提案。監視付きファインチューニング（SFT）と強化学習（RL）の忘却パターンを比較した結果、RLはSFTよりも忘却が少なく、同等以上のパフォーマンスを示すことが判明。RLの特性が以前の知識を保持する理由を探り、オンポリシーデータの使用がその要因であることを確認。近似的なオンポリシーデータの利用が忘却を軽減する可能性を示唆。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cwolferesearch/status/2010480993052803509?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="reinforcement-fine-tuning-4172" class="title-link">[Paper Note] Reinforcement Fine-Tuning Naturally Mitigates Forgetting in Continual Post-Training, Song Lai+, arXiv'25, 2025.07</h3>
<br><a href="https://arxiv.org/abs/2507.05386" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4172" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2026-01-12</span>
<span class="snippet"><span>GPT Summary</span>- 継続的ポストトレーニング（CPT）における監視付きファインチューニング（SFT）と強化ファインチューニング（RFT）の影響を比較。SFTは以前の知識を忘却させるが、RFTは知識を保持し、マルチタスクトレーニングに匹敵する性能を発揮。RFTはモデルの一般的な知識を保護・向上させる一方、SFTは低下させる。RFTの安定性は暗黙の正則化メカニズムによるもので、データ依存の正則化因子として機能。RFTの効率を向上させるアルゴリズムも提案。RFTの優位性を示す研究。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cwolferesearch/status/2010480993052803509?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="shape-of-4168" class="title-link">[Paper Note] Shape of Thought: When Distribution Matters More than Correctness in Reasoning Tasks, Abhranil Chandra+, arXiv'25, 2025.12</h3>
<br><a href="https://arxiv.org/abs/2512.22255" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4168" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2026-01-11</span>
<span class="snippet"><span>GPT Summary</span>- 言語モデルの推論能力は、連鎖的思考（CoT）トレースの合成データセットでの訓練によって向上することが示された。合成データはモデル自身の分布に近く、学習に適応しやすい。また、不正確なトレースでも有効な推論ステップを含むことが多い。人間の注釈データを言い換えることでパフォーマンスが向上し、欠陥のあるトレースに対する耐性も研究された。MATH、GSM8K、Countdown、MBPPデータセットを用いて、モデルの分布に近いデータセットの重要性と、正しい最終回答が必ずしも信頼できる推論プロセスの指標ではないことが示された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/agarwl_/status/2009995065243116006?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>base modelの分布と近いStronger Modelから合成されたCoTデータでSFTすると、合成データの応答がincorrectであっても性能が向上する。分布が遠い人間により生成されたCoTで訓練するより性能改善の幅は大きく、人間が作成したCoTをparaphraseしモデルの分布に近づけると性能の上昇幅は改善する(Figure1, Table4, 5)。<br><br><img src="https://github.com/user-attachments/assets/36cc6db9-36bf-4193-9b56-a127a0112df3" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="nemotron-3-4085" class="title-link">[Paper Note] Nemotron 3 Nano: Open, Efficient Mixture-of-Experts Hybrid Mamba-Transformer Model for Agentic Reasoning, NVIDIA+, arXiv'25, 2025.12</h3>
<br><a href="https://arxiv.org/abs/2512.20848" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4085" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="Hybrid.html" target="_blank" rel="noopener noreferrer">#Hybrid</a>
<span class="issue_date">Issue Date: 2025-12-28</span>
<span class="snippet"><span>GPT Summary</span>- Nemotron 3 Nano 30B-A3Bは、Mixture-of-ExpertsハイブリッドMamba-Transformer言語モデルであり、25兆のテキストトークンで事前学習され、監視付きファインチューニングと強化学習を経て精度を向上。前世代のNemotron 2 Nanoよりも高精度で、フォワードパスごとに半分未満のパラメータを活性化し、同サイズのオープンモデルと比較して最大3.3倍の推論スループットを達成。エージェント的、推論、チャット能力が向上し、最大1Mトークンのコンテキスト長をサポート。事前学習済みモデルはHugging Faceで公開。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/2004947290578919914?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="mechanistic-finetuning-4084" class="title-link">[Paper Note] Mechanistic Finetuning of Vision-Language-Action Models via Few-Shot Demonstrations, Chancharik Mitra+, arXiv'25, 2025.11</h3>
<br><a href="https://arxiv.org/abs/2511.22697" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4084" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="Robotics.html" target="_blank" rel="noopener noreferrer">#Robotics</a>
<a class="button" href="VisionLanguageActionModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageActionModel</a>
<a class="button" href="EmbodiedAI.html" target="_blank" rel="noopener noreferrer">#EmbodiedAI</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-12-28</span>
<span class="snippet"><span>GPT Summary</span>- VLAモデルはロボティクスにおける視覚と言語の統合を目指すが、物理的要因へのファインチューニングが必要。既存手法は特異性に欠けるため、タスク特異的な注意ヘッドを選択的にファインチューニングする「Robotic Steering」を提案。Franka Emikaロボットアームでの評価により、Robotic SteeringがLoRAを上回り、堅牢性、計算コスト削減、解釈可能性の向上を実現することを示した。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://chancharikmitra.github.io/robosteering/" target="_blank" rel="noopener noreferrer">https://chancharikmitra.github.io/robosteering/</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/chancharikm/status/2004597444730929596?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>VLAにおいて学習したいタスクと関連する(sparseな） attention headsだけをfinetuningすることで、効率的に、忘却を防ぎつつ、overfitを防ぐような手法を提案。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="step-deepresearch-technical-4050" class="title-link">[Paper Note] Step-DeepResearch Technical Report, Chen Hu+, arXiv'25, 2025.12</h3>
<br><a href="https://arxiv.org/abs/2512.20491" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4050" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Proprietary.html" target="_blank" rel="noopener noreferrer">#Proprietary</a>
<a class="button" href="mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="Rubric-based.html" target="_blank" rel="noopener noreferrer">#Rubric-based</a>
<span class="issue_date">Issue Date: 2025-12-24</span>
<span class="snippet"><span>GPT Summary</span>- Step-DeepResearchは、LLMを用いた自律エージェントのためのコスト効率の良いエンドツーエンドのシステムであり、意図認識や長期的意思決定を強化するためのデータ合成戦略を提案。チェックリストスタイルのジャッジャーにより堅牢性を向上させ、中国ドメイン向けのADR-Benchを設立。実験では、Step-DeepResearchが高いスコアを記録し、業界をリードするコスト効率で専門家レベルの能力を達成したことを示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/2003690751579021473?s=20"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>ポイント解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/2005378485842477298?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>ざっくり言うと、シンプルなReAct styleのagentで、マルチエージェントのオーケストレーションや複雑で重たいワークフロー無しで、OpenAI, GeminiのDeepResearchと同等の性能を達成してとり、ポイントとしてこれらの機能をはmid-training段階で学習してモデルのパラメータとして組み込むことで実現している模様。<br><br>mid trainingは2段階で構成され、trajectoryの長さは徐々に長いものを利用するカリキュラム方式。<br>最初のステージでは以下の4つのatomicスキルを身につけさせる:<br>- Planning &amp; Task Decomposition<br>- Deep Information Seeking<br>- Reflection &amp; Verification<br>- Reporting<br><br>これらのatomic skillを身につけさせる際には、next token predictionをnext action predictionという枠組みで学習し、アクションに関するトークンの空間を制限することで効率性を向上（ただし、具体性は減少するのでトレードオフ）という形にしているようだが、コンセプトが記述されているのみでよくわからない。同時に、学習データの構築方法もデータソースとおおまかな構築方法が書かれているのみである。ただし、記述内容的には各atomicmskilvごとに基本的には合成データが作成され利用されていると考えてよい。<br><br>たとえばplanningについては論文などの文献のタイトルや本文から実験以後の記述を除外し、研究プロジェクトのタスクを推定させる（リバースエンジニアリングと呼称している）することで、planningのtrajectoryを合成、Deep Information SeekingではDB Pediaなどのknowledge graphをソースとして利用し、字数が3--10程度のノードをseedとしそこから（トピックがドリフトするのを防ぐために極端に次数が大きいノードは除外しつつ）幅優先探索をすることで、30--40程度のノードによって構成されるサブグラフを構成し、そのサブグラフに対してmulti hopが必要なQuestionを、LLMで生成することでデータを合成しているとのこと。<br><br>RLはrewardとしてルーブリックをベースにしたものが用いられるが、strong modelを用いて<query rubrics report>の三つ組データを合成し、このデータを用いてSFT, RLVRをすることでRubrics Judgeモデルを学習して利用すると記述されている。Rubricsに基づく報酬では、最初に<br>- 1: fully satisfied<br>- 0.5: partially satisfied<br>- 0: not satisfied<br><br>の3値を検討したが、partially satisfiedが人間による評価とのagreementが低かったため設計を変更し、positive/negative rubricsを設定し、positivルーブリックの場合はルーブリックがfully satisfiedの時のみ1, negativeルーブリックの方はnot satisfiedの時のみ0とすることで、低品質な生成結果に基づくrewardを無くし、少しでもネガティブな要素があった場合は強めのペナルティがかかるようにしているとのこと（ルーブリックの詳細は私が見た限りは不明である。Appendix Aに書かれているように一瞬見えたが具体的なcriterionは書かれていないように見える）。<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2762" target="_blank" rel="noopener noreferrer">[Paper Note] SFR-DeepResearch: Towards Effective Reinforcement Learning for
  Autonomously Reasoning Single Agents, Xuan-Phi Nguyen+, arXiv'25</a>
</p></query></span><br><br>
</article>
<article class="paper-entry">
<h3 id="motif-2-12.7b-reasoning-a-3948" class="title-link">[Paper Note] Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes, Junghwan Lim+, arXiv'25, 2025.12</h3>
<br><a href="https://arxiv.org/abs/2512.11463" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3948" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-12-15</span>
<span class="snippet"><span>GPT Summary</span>- Motif-2-12.7B-Reasoningは、複雑な推論と長文コンテキスト理解のために設計された12.7Bパラメータの言語モデルです。モデル崩壊やトレーニングの不安定性に対処するため、再現可能なトレーニングレシピを提案し、64Kトークンコンテキストに対応したメモリ効率の良いインフラと二段階の教師ありファインチューニングを組み合わせています。また、強化学習ファインチューニングを通じてトレーニングの安定性を向上させています。実証結果は、Motif-2-12.7B-Reasoningが大規模モデルと同等のパフォーマンスを示し、競争力のあるオープンモデルの設計図を提供することを示しています。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/f14bertolotti/status/2000505193570746708?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2537" target="_blank" rel="noopener noreferrer">[Paper Note] Motif 2.6B Technical Report, Junghwan Lim+, arXiv'25</a>
</p>
<p>元ポストのLessons from failures...気になる👀</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="nanbeige4-3b-technical-3938" class="title-link">[Paper Note] Nanbeige4-3B Technical Report: Exploring the Frontier of Small Language Models, Chen Yang+, arXiv'25, 2025.12</h3>
<br><a href="https://arxiv.org/abs/2512.06266" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3938" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Distillation.html" target="_blank" rel="noopener noreferrer">#Distillation</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-12-13</span>
<span class="snippet"><span>GPT Summary</span>- Nanbeige4-3Bは、23兆の高品質トークンで事前学習し、3000万以上の指示でファインチューニングされた高性能な小規模言語モデルです。FG-WSDトレーニングスケジューラを用いて段階的にデータを洗練し、SFTデータの質向上のために共同メカニズムを設計しました。さらに、DPDメソッドを通じてモデルを蒸留し、強化学習フェーズで推論能力を強化しました。評価結果は、同等のパラメータスケールのモデルを大幅に上回り、より大きなモデルにも匹敵することを示しています。モデルのチェックポイントは、https://huggingface.co/Nanbeige で入手可能です。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1999488933412110456?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>3Bモデルにも関わらず10倍以上大きいモデルと同等以上の性能を発揮し、trainingのstrategyが非常に重要ということが伺える。元ポストにも各学習方法の概要が記載されているが、読みたい。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="weird-generalization-3936" class="title-link">[Paper Note] Weird Generalization and Inductive Backdoors: New Ways to Corrupt LLMs, Jan Betley+, arXiv'25, 2025.12</h3>
<br><a href="https://arxiv.org/abs/2512.09742" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3936" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="EmergentMisalignment.html" target="_blank" rel="noopener noreferrer">#EmergentMisalignment</a>
<span class="issue_date">Issue Date: 2025-12-13</span>
<span class="snippet"><span>GPT Summary</span>- 狭い文脈でのファインチューニングが、モデルの文脈外での行動を劇的に変化させる可能性を示す実験を行った。例えば、鳥の古い名前を出力するようにファインチューニングした結果、モデルは19世紀のように振る舞うことが確認された。また、ヒトラーに関連するデータセットでファインチューニングを行うと、モデルはヒトラーのペルソナを採用し、不整合な行動を示すことが明らかになった。さらに、誘導的バックドアの概念を紹介し、善良な目標に基づいて訓練されたモデルが、異なる文脈で悪意ある行動を示すことが確認された。これらの結果は、狭いファインチューニングが予測不可能な一般化を引き起こす可能性があることを示唆している。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/owainevans_uk/status/1999172920506269783?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="openmmreasoner-pushing-3794" class="title-link">[Paper Note] OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe, Kaichen Zhang+, arXiv'25, 2025.11</h3>
<br><a href="https://arxiv.org/abs/2511.16334" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3794" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-11-25</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、マルチモーダル推論のための透明な二段階トレーニングレシピ「OpenMMReasoner」を提案。監視付きファインチューニング（SFT）で874Kサンプルのデータセットを構築し、強化学習（RL）で74Kサンプルを活用して推論能力を向上。評価の結果、9つのベンチマークでQwen2.5-VL-7B-Instructに対し11.6%の性能向上を達成し、データの質とトレーニング設計の重要性を示した。すべてのリソースはオープンソースで公開。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://evolvinglmms-lab.github.io/OpenMMReasoner/" target="_blank" rel="noopener noreferrer">https://evolvinglmms-lab.github.io/OpenMMReasoner/</a>


</p>
<p>SoTAなVLMを構築するためのオープンなデータとレシピらしい</p>
<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3105" target="_blank" rel="noopener noreferrer">[Paper Note] LLaVA-OneVision-1.5: Fully Open Framework for Democratized Multimodal
  Training, Xiang An+, arXiv'25, 2025.09</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="think-or-3787" class="title-link">[Paper Note] Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models, Jiaqi Wang+, NeurIPS'25, 2025.05</h3>
<br><a href="https://arxiv.org/abs/2505.16854" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3787" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-11-25</span>
<span class="snippet"><span>GPT Summary</span>- 強化学習を用いて視覚と言語モデルの推論を強化するために、TONという二段階のトレーニング戦略を提案。簡単な質問には推論をスキップし、必要な時に考える人間の思考プロセスを模倣。実験により、TONは従来の手法に比べて推論ステップを最大90％削減し、性能を向上させることが示された。モデルはトレーニングを通じて不要な推論を回避することを学習。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kevinqhlin/status/1993120942399033679?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>著者ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kevinqhlin/status/1925799774835392871?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>いつ思考をするか/しないかを学習することでCoTのtrajectoryを節約する。選択的に思考しないということをモデルは基本的に学習していないのでSFTで模倣学習することでコールドスタートを脱っし、その後RLによって選択的に思考しないことも含めて思考を最適化する、といった話に見える。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="kandinsky-5.0-3745" class="title-link">[Paper Note] Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation, Vladimir Arkhipkin+, arXiv'25, 2025.11</h3>
<br><a href="https://arxiv.org/abs/2511.14993" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3745" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="TextToImageGeneration.html" target="_blank" rel="noopener noreferrer">#TextToImageGeneration</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="VideoGeneration_Understandings.html" target="_blank" rel="noopener noreferrer">#VideoGeneration/Understandings</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-11-20</span>
<span class="snippet"><span>GPT Summary</span>- Kandinsky 5.0は、高解像度画像と10秒動画合成のための最先端モデルで、3つのコアモデル（Image Lite、Video Lite、Video Pro）から構成される。データキュレーションライフサイクルのレビューや、自己教師ありファインチューニングや強化学習を用いた品質向上技術を取り入れ、高い生成速度とパフォーマンスを実現。オープンソースコードとトレーニングチェックポイントの提供により、研究コミュニティの発展に寄与することを目指す。</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/kandinskylab" target="_blank" rel="noopener noreferrer">https://huggingface.co/kandinskylab</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1991477026910531742?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="reinforcement-learning-3664" class="title-link">[Paper Note] Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs, Renfei Zhang+, arXiv'25, 2025.11</h3>
<br><a href="https://arxiv.org/abs/2511.05933" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3664" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Memorization.html" target="_blank" rel="noopener noreferrer">#Memorization</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-11-13</span>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）は、階層的な知識を必要とするタスクにおいて、基盤モデルや教師あり微調整（SFT）モデルを上回る性能を示す。これは新たなデータからではなく、既存の知識をナビゲートするスキルの向上によるものである。構造化プロンプティングを用いることで、SFTモデルのパフォーマンスギャップを縮小できることが示された。RLモデルは深い検索タスクでの手続き的経路の呼び出しに優れ、知識の表現は変わらないが、知識の遍歴方法が変化することが明らかになった。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/niloofar_mire/status/1988316100690612648?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>RLはしばしば知識のmemorizationを劣化させると言われているが、むしろ学習データから記憶された知識を階層的に辿るようなタスクに適用した結果RL（が実施されたモデル）の方がSFT（が実施されたモデル）よりも高い性能を達成した。同タスクの階層構造をpromptingで与えることで性能SFT/RLのgapが小さくなることから、知識のナビゲーションが性能に関連していることを示唆している。また、事実表現とクエリの表現においてSFTとRLでは前者に大きな違いはないが、後者は大きな違いを見せており、知識の表現そのものを変えるのではなく、モデル内部の知識を辿る方法が変化していることが示唆される。<br><br>といった内容らしいのだが、論文を斜め読みした結果、自分たちでモデルをRL/SFTしたわけではなく既存のオープンなモデルreasoningモデル、instructモデル、distilledモデルで性能を比較する、みたいなことをしているようであり、apple-to-appleの比較になっていないのでは？という感想を抱いたがどうなのだろうか。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="culture-cartography-3605" class="title-link">[Paper Note] Culture Cartography: Mapping the Landscape of Cultural Knowledge, Caleb Ziems+, EMNLP'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.27672" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3605" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="Cultural.html" target="_blank" rel="noopener noreferrer">#Cultural</a>
<span class="issue_date">Issue Date: 2025-11-06</span>
<span class="snippet"><span>GPT Summary</span>- LLMは文化特有の知識を必要とし、CultureCartographyという混合イニシアティブを提案。LLMが自信の低い質問をアノテーションし、人間がそのギャップを埋めることで重要なトピックに導く。CultureExplorerツールを用いた実験で、従来のモデルよりも効果的に知識を生成し、Llama-3.1-8Bの精度を最大19.2%向上させることが示された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/diyi_yang/status/1985826293053866234?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>効率的にLLMにとって未知、かつ重要な文化的な知識バンクを作成する話な模様。アクティブラーニングに似たような思想に見える。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="agent-data-3520" class="title-link">[Paper Note] Agent Data Protocol: Unifying Datasets for Diverse, Effective  Fine-tuning of LLM Agents, Yueqi Song+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.24702" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3520" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-30</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、エージェントデータの収集における課題を解決するために、エージェントデータプロトコル（ADP）を提案。ADPは多様なデータ形式を統一し、簡単に解析・トレーニング可能な表現言語である。実験により、13のエージェントトレーニングデータセットをADP形式に統一し、標準化されたデータでSFTを実施した結果、平均約20％の性能向上を達成。ADPは再現可能なエージェントトレーニングの障壁を下げることが期待される。</span>
<span class="snippet"><span>Comment</span><p>pj page:


<a href="https://www.agentdataprotocol.com" target="_blank" rel="noopener noreferrer">https://www.agentdataprotocol.com</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1983548125135655228?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>著者ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/syz0x1/status/1983715963305652638?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>解説:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1988018578239746377?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>エージェントを学習するための統一的なデータ表現に関するプロトコルを提案</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="learning-to-3426" class="title-link">[Paper Note] Learning to Interpret Weight Differences in Language Models, Avichal Goel+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.05092" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3426" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-25</span>
<span class="snippet"><span>GPT Summary</span>- ファインチューニングされた言語モデルの重みの変化を解釈するために、Diff Interpretation Tuning（DIT）を提案。合成されたラベル付きの重みの差を用いてモデルに変更を説明させる。隠れた挙動の報告や知識の要約において、DITが自然言語での正確な説明を可能にすることを示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/tonywangiv/status/1981362885830779359?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>weightの更新があった時に、LLM自身がどのような変化があったかをverbalizeできるようにSFTでLoRA Adaptorを学習する話らしい</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="ultracua-a-3349" class="title-link">[Paper Note] UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action, Yuhao Yang+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.17790" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3349" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<span class="snippet"><span>GPT Summary</span>- ハイブリッドアクションを用いた基盤モデル「UltraCUA」を提案し、GUIの原始的なアクションと高レベルのプログラムツール呼び出しを統合。自動化パイプライン、合成データエンジン、ハイブリッドアクション軌跡コレクション、二段階のトレーニングパイプラインを構成要素とし、実験により最先端エージェントに対して22%の改善と11%の速度向上を達成。エラー伝播を減少させつつ実行効率を維持することが確認された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zhegan4/status/1980471759251075578?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>従来のCUAはGUIに対する低レベルの操作（クリック、タイプ、スクロール）を利用する前提に立つが、本研究ではそれらだけではなくより高レベルのprogramatic tool calls(e.g., python関数呼び出し、キーボードショートカット、スクリプト実行、API呼び出し等)をシームレスに統合できるように合成データを作成しAgentをらSFTとRLしましたらよりベンチマークスコア向上した、というような話に見える。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="synthesizing-agentic-3348" class="title-link">[Paper Note] Synthesizing Agentic Data for Web Agents with Progressive Difficulty  Enhancement Mechanisms, Shrey Pandit+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.13913v1" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3348" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="Diversity.html" target="_blank" rel="noopener noreferrer">#Diversity</a>
<a class="button" href="Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<a class="button" href="DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<a class="button" href="LongHorizon.html" target="_blank" rel="noopener noreferrer">#LongHorizon</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<span class="snippet"><span>GPT Summary</span>- Webベースの「ディープリサーチ」エージェントは、長期的なインタラクションを通じて複雑な質問応答タスクを解決することを目指すが、従来の方法は推論の複雑さを捉えきれない。そこで、タスクの複雑さを段階的に増加させる二段階のデータ合成パイプラインを導入し、ベースラインエージェントが質問に挑戦し、事実確認を行う。実験により、提案したデータセットが既存のものよりも効果的な訓練を可能にし、ツール使用アクションの多様性が2倍であることが示された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/caimingxiong/status/1980302240163488057?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="skill-targeted-adaptive-3346" class="title-link">[Paper Note] Skill-Targeted Adaptive Training, Yinghui He+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.10023" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3346" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="SkillTag.html" target="_blank" rel="noopener noreferrer">#SkillTag</a>
<span class="issue_date">Issue Date: 2025-10-21</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、言語モデルのメタ認知能力を活用した新しいファインチューニング戦略「STAT」を提案。教師モデルがタスクに必要なスキルをラベル付けし、学生モデルのスキル不足を追跡することで、トレーニングセットを修正。STAT-Selでは既存の例の重みを調整し、STAT-Synでは新たな例を合成。実験により、MATHで最大7.5%の改善を達成し、分布外ベンチマークでも平均4.6%の向上を示した。STATは強化学習手法GRPOと補完的であり、スキルターゲットの適応トレーニングがトレーニングパイプラインを改善することを示唆。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yinghui_he_/status/1980257694704619679?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3361" target="_blank" rel="noopener noreferrer">[Paper Note] Metacognitive Capabilities of LLMs: An Exploration in Mathematical   Problem Solving, Aniket Didolkar+, NeurIPS'24, 2024.05</a>
</p>
<p>Reward Modelでquestionがeasy/hardを定量化し、hardなものに対してモデルが応答を生成。応答の結果をstronger modelに確認させ、モデルにどのようなスキルが不足しているかを特定する。これによりモデルのスキルに関するprofileが作成されるのでこれに基づいて学習データの各サンプルとスキルを紐づけた上でサンプルを重みの調整、および不足しているスキルに関するデータを合成しSFTに活用する、といった話な模様。<br><br><img src="https://github.com/user-attachments/assets/8f5e9efb-c096-4897-8327-daed9e4c920a" alt="image" loading="lazy" width="550" height="400"><br><br>結果を見ると、+SFT / +GRPOよりも性能が高くなっている。Table1ではLlamaでの結果しか掲載されていないが、Qwenでも実験がされて同様の結果が得られている。<br><img src="https://github.com/user-attachments/assets/d35077ef-bf33-4c12-82e1-37cbc40247af" alt="image" loading="lazy" width="550" height="400"><br><br>また、Figure4を見ると不足していたスキルが学習によってきちんと補われていることが分かる。<br><br><img src="https://github.com/user-attachments/assets/bd07a4e5-87c8-4ab1-a45c-379cff343e33" alt="image" loading="lazy" width="550" height="400"><br><br>（評価と考察部分をもう少しじっくり読みたい）</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="reasoned-safety-3332" class="title-link">[Paper Note] Reasoned Safety Alignment: Ensuring Jailbreak Defense via  Answer-Then-Check, Chentao Cao+, arXiv'25, 2025.09</h3>
<br><a href="https://arxiv.org/abs/2509.11629" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3332" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<span class="snippet"><span>GPT Summary</span>- 脱獄攻撃に対する安全性を向上させるために、Answer-Then-Checkという新しいアプローチを提案。モデルはまず質問に回答し、その後安全性を評価してから応答を提供。80Kの例からなるReasoned Safety Alignment（ReSA）データセットを構築し、実験により優れた安全性を示しつつ過剰拒否率を低下。ReSAでファインチューニングされたモデルは一般的な推論能力を維持し、敏感なトピックに対しても有益な応答を提供可能。少量のデータでのトレーニングでも高いパフォーマンスを達成できることが示唆された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1980113019511427195?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="thinking-with-3330" class="title-link">[Paper Note] Thinking with Camera: A Unified Multimodal Model for Camera-Centric  Understanding and Generation, Kang Liao+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.08673" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3330" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="UMM.html" target="_blank" rel="noopener noreferrer">#UMM</a>
<a class="button" href="SpatialUnderstanding.html" target="_blank" rel="noopener noreferrer">#SpatialUnderstanding</a>
<span class="issue_date">Issue Date: 2025-10-20</span>
<span class="snippet"><span>GPT Summary</span>- カメラ中心の理解と生成を統合したマルチモーダルモデル「Puffin」を提案。Puffinは、言語回帰と拡散生成を組み合わせ、カメラを言語として扱う新しいアプローチを採用。400万の視覚-言語-カメラのデータセット「Puffin-4M」で訓練され、空間的な視覚的手がかりを考慮した推論を実現。実験結果では、専門モデルを上回る性能を示し、指示チューニングにより多様なタスクに対応可能。研究成果はコードやデータセットと共に公開予定。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/1979911820401086613?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>pj page: 


<a href="https://kangliao929.github.io/projects/puffin/" target="_blank" rel="noopener noreferrer">https://kangliao929.github.io/projects/puffin/</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="learning-to-3274" class="title-link">[Paper Note] Learning to Make MISTAKEs: Modeling Incorrect Student Thinking And Key  Errors, Alexis Ross+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.11502" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3274" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="EducationalDataMining.html" target="_blank" rel="noopener noreferrer">#EducationalDataMining</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Label-free.html" target="_blank" rel="noopener noreferrer">#Label-free</a>
<span class="issue_date">Issue Date: 2025-10-16</span>
<span class="snippet"><span>GPT Summary</span>- 新手法MISTAKEを提案し、不正確な推論パターンをモデル化。サイクル整合性を利用して高品質な推論エラーを合成し、教育タスクでの学生シミュレーションや誤解分類において高精度を達成。専門家の選択肢との整合性も向上。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacobandreas/status/1978208010829774899?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="agent-learning-3253" class="title-link">[Paper Note] Agent Learning via Early Experience, Kai Zhang+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.08558" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3253" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="Self-SupervisedLearning.html" target="_blank" rel="noopener noreferrer">#Self-SupervisedLearning</a>
<a class="button" href="SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<a class="button" href="mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="WorldModels.html" target="_blank" rel="noopener noreferrer">#WorldModels</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<span class="snippet"><span>GPT Summary</span>- 言語エージェントの目標は、経験を通じて学び、複雑なタスクで人間を上回ることですが、強化学習には報酬の欠如や非効率的なロールアウトが課題です。これに対処するため、エージェント自身の行動から生成された相互作用データを用いる「早期経験」という新たなパラダイムを提案します。このデータを基に、(1) 暗黙の世界モデル化と(2) 自己反省の2つの戦略を研究し、8つの環境で評価を行った結果、効果性と一般化が向上することを示しました。早期経験は、強化学習の基盤を提供し、模倣学習と経験駆動エージェントの橋渡しとなる可能性があります。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/godofprompt/status/1977629442307686708?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>LLM AgentのためのWarmup手法を提案している。具体的にはRLVRやImitation LearningによってRewardが定義できるデータに基づいてこれまではRLが実現されてきたが、これらはスケールせず、Rewardが定義されない環境のtrajectoryなどは学習されないので汎化性能が低いという課題がある。このため、これらのsupervisionつきの方法で学習をする前のwarmup手法として、reward-freeの学習パラダイム Early Experienceを提案している。<br><img src="https://github.com/user-attachments/assets/c2ed5999-d6d8-419d-93e9-f3358ab0ca1f" alt="image" loading="lazy" width="550" height="400"><br><br>手法としてはシンプルな手法が2種類提案されている。<br>### Implicit World Modeling (IWM, 式(3)):<br>ある状態s_i において action a_i^{j}を (1 &lt; j &lt; |K|)をとった時の状態をs_i^{j}としたときに、(s_i, a_i^{j}, s_i^{j}) の3つ組を考える。これらはポリシーからのK回のrolloutによって生成可能。<br>このときに、状態sを全てテキストで表現するようにし、言語モデルのnext-token-prediction lossを用いて、ある状態s_jにおいてaction a_i^{k} をとったときに、s_j^{k} になることを予測できるように学習する。これにより例えばブックフライトのサイトで誤った日時を入れてしまった場合や、どこかをクリックしたときにどこに遷移するかなどの学習する環境の世界知識をimplicitにモデルに組み込むことができる。<br><br>### Self-Reflection（式4）<br>もう一つのパラダイムとして、専門家によるアクション a_i によって得られた状態 s_i と、それら以外のアクション a_i^{j} によって得られた状態 s_i^{j}が与えられたときに、s_iとs_i^{j}を比較したときに、なぜ a_i の方がa_i^{j} よりも好ましいかを説明するCoT C_i^{j}を生成し、三つ組データ(s_i, a_i^{j}, c_i^{j}) を構築する。このデータを用いて、状態s_iがgivenなときに、a_i に c_i^{j} をconcatしたテキストを予測できるようにnext-token-prediction lossで学習する。また、このデータだけでなく汎化性能をより高めるためにexpertによるimitation learningのためのデータCoTなしのデータもmixして学習をする。これにより、expertによるactionだけで学習するよりも、なぜexpertのアクションが良いかという情報に基づいてより豊富で転移可能な学習シグナルを活用し学習することができる。<br> <br><img src="https://github.com/user-attachments/assets/d411ac3b-d977-4357-b715-0cf4e5b95fa2" alt="image" loading="lazy" width="550" height="400"><br><br>この結果、downstreamタスクでのperformanceが単にImitation Learningを実施した場合と比較して提案手法でwarmupした方が一貫して向上する。また、5.4節にpost-trainingとして追加でGRPOを実施した場合も提案手法によるwarmupを実施した場合が最終的な性能が向上することが報告されている。<br><br><img src="https://github.com/user-attachments/assets/a0aad636-b889-4d2d-b753-b0ad5ad4c688" alt="image" loading="lazy" width="550" height="400"></p>
<p>IWMは自己教師あり学習の枠組みだと思われるので、よぬスケールし、かつ汎化性能が高く様々な手法のベースとなりうる手法に見える。</p>
<p>著者ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1979179944258265358?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="spectrum-tuning-3247" class="title-link">[Paper Note] Spectrum Tuning: Post-Training for Distributional Coverage and  In-Context Steerability, Taylor Sorensen+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.06084" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3247" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="meta-learning.html" target="_blank" rel="noopener noreferrer">#meta-learning</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<a class="button" href="Steering.html" target="_blank" rel="noopener noreferrer">#Steering</a>
<span class="issue_date">Issue Date: 2025-10-14</span>
<span class="snippet"><span>GPT Summary</span>- ポストトレーニングは言語モデルの性能を向上させるが、操作性や出力空間のカバレッジ、分布の整合性においてコストが伴う。本研究では、これらの要件を評価するためにSpectrum Suiteを導入し、90以上のタスクを網羅。ポストトレーニング技術が基礎的な能力を引き出す一方で、文脈内操作性を損なうことを発見。これを改善するためにSpectrum Tuningを提案し、モデルの操作性や出力空間のカバレッジを向上させることを示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ma_tay_/status/1977750377484149205?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>著者らはモデルの望ましい性質として<br>- In context steerbility: inference時に与えられた情報に基づいて出力分布を変えられる能力<br>- Valid output space coverage: タスクにおける妥当な出力を広範にカバーできること<br>- Distributional Alignment: ターゲットとする出力分布に対してモデルの出力分布が近いこと<br><br>の3つを挙げている。そして既存のinstruction tuningや事後学習はこれらを損なうことを指摘している。<br><br>ここで、incontext steerbilityとは、事前学習時に得た知識や、分布、能力だけに従うのではなく、context内で新たに指定した情報をモデルに活用させることである。<br><br>モデルの上記3つの能力を測るためにSpectrum Suiteを導入する。これには、人間の様々な嗜好、numericな分布の出力、合成データ作成などの、モデル側でsteeringや多様な分布への対応が必要なタスクが含まれるベンチマークのようである。<br><br>また上記3つの能力を改善するためにSpectrum Tuningと呼ばれるSFT手法を提案している。<br>手法はシンプルで、タスクT_iに対する 多様なinput X_i タスクのcontext（すなわちdescription) Z_i が与えられた時に、T_i: X_i,Z_i→P(Y_i) を学習したい。ここで、P(Y_i)は潜在的なoutputの分布であり、特定の1つのサンプルyに最適化する、という話ではない点に注意（meta learningの定式化に相当する）。<br><br>具体的なアルゴリズムとしては、タスクのコレクションが与えられた時に、タスクiのcontextとdescriptionをtokenizeした結果 z_i と、incontextサンプルのペア x_ij, y_ij が与えられた時に、output tokenのみに対してcross entropyを適用してSFTをする。すなわち、以下のような手順を踏む:<br><br>1. incontextサンプルをランダムなオーダーにソートする<br>2. p_dropの確率でdescription z_i をドロップアウトしx_i0→y_i0の順番でconcatする、<br>2-1. descriptionがdropしなかった場合はdescription→x_i0→y_i0の順番でconcatし入力を作る。<br>2-2. descriptionがdropした場合、x_i0→y_i0の順番で入力を作る。<br>3. 他のサンプルをx_1→y_1→...→x_n→y_nの順番で全てconcatする。<br>4. y_{1:n}に対してのみクロスエントロピーlossを適用し、他はマスクして学習する。<br><br>一見するとinstruct tuningに類似しているが、以下の点で異なっている:<br>- 1つのpromptに多くのi.i.dな出力が含まれるのでmeta-learningが促進される<br>- 個別データに最適化されるのではなく、タスクに対する入出力分布が自然に学習される<br>- chat styleのデータにfittingするのではなく、分布に対してfittingすることにフォーカスしている<br>- input xやタスクdescription zを省略することができ、ユーザ入力が必ず存在する設定とは異なる<br><br>という主張をしている。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="inoculation-prompting-3235" class="title-link">[Paper Note] Inoculation Prompting: Instructing LLMs to misbehave at train-time  improves test-time alignment, Nevan Wichers+, arXiv'25, 2025.10</h3>
<br><a href="https://arxiv.org/abs/2510.05024" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3235" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="InoculationPrompting.html" target="_blank" rel="noopener noreferrer">#InoculationPrompting</a>
<span class="issue_date">Issue Date: 2025-10-13</span>
<span class="snippet"><span>GPT Summary</span>- Inoculation Prompting（IP）を提案し、望ましくない行動を明示的に要求することでその学習を防ぐ手法を紹介。IPはファインチューニング中に望ましくない行動の学習を減少させ、望ましい能力の学習には大きな影響を与えない。特に、望ましくない行動を引き出すプロンプトが効果的であることを示し、モデルの一般化を制御するシンプルで効果的な方法であることを確認。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1977388859160989931?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3106" target="_blank" rel="noopener noreferrer">[Paper Note] Large Reasoning Models Learn Better Alignment from Flawed Thinking, ShengYun Peng+, arXiv'25, 2025.10</a>
<br><br>上記研究とどういった点が異なるだろうか。<br><br>Inoculation Promptingは望ましくない行動を明示的に指示して要求するのに対し、こちらの研究は望ましくない行動が起きたときにそれを訂正する能力を身につけさせるという話なので、かなり違う話に見える。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="scaling-generalist-3182" class="title-link">[Paper Note] Scaling Generalist Data-Analytic Agents, Shuofei Qiao+, arXiv'25, 2025.09</h3>
<br><a href="https://arxiv.org/abs/2509.25084" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3182" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="TabularData.html" target="_blank" rel="noopener noreferrer">#TabularData</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="ScientificDiscovery.html" target="_blank" rel="noopener noreferrer">#ScientificDiscovery</a>
<a class="button" href="numeric.html" target="_blank" rel="noopener noreferrer">#numeric</a>
<a class="button" href="MajorityVoting.html" target="_blank" rel="noopener noreferrer">#MajorityVoting</a>
<span class="issue_date">Issue Date: 2025-10-09</span>
<span class="snippet"><span>GPT Summary</span>- DataMindは、オープンソースのデータ分析エージェントを構築するためのスケーラブルなデータ合成とエージェントトレーニングの手法を提案。主な課題であるデータリソース、トレーニング戦略、マルチターンロールアウトの不安定性に対処し、合成クエリの多様性を高めるタスク分類や、動的なトレーニング目標を採用。DataMind-12Kという高品質なデータセットを作成し、DataMind-14Bはデータ分析ベンチマークで71.16%のスコアを達成し、最先端のプロプライエタリモデルを上回った。DataMind-7Bも68.10%でオープンソースモデル中最高のパフォーマンスを示した。今後、これらのモデルをコミュニティに公開予定。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zxlzr/status/1975941955613028436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>7B程度のSLMで70B級のモデルと同等以上の性能に到達しているように見える。論文中のp.2にコンパクトに内容がまとまっている。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="ia2-alignment-3128" class="title-link">[Paper Note] IA2: Alignment with ICL Activations Improves Supervised Fine-Tuning, Aayush Mishra+, arXiv'25, 2025.09</h3>
<br><a href="https://arxiv.org/abs/2509.22621" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3128" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<span class="issue_date">Issue Date: 2025-10-05</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、インコンテキスト学習（ICL）の活性化パターンを利用して、監視付きファインチューニング（SFT）の品質を向上させる手法を提案。ICLとSFTの異なる適応メカニズムを示し、ICL活性化アライメント（IA2）という自己蒸留技術を導入。IA2をSFTの前に実行することで、モデルの出力精度とキャリブレーションが向上することを12のベンチマークで実証。これにより、モデル適応の内部メカニズムに対する新たな視点も提供される。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/danielkhashabi/status/1974119053728919790?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="kimi-dev-agentless-3064" class="title-link">[Paper Note] Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents, Zonghan Yang+, arXiv'25, 2025.09</h3>
<br><a href="https://arxiv.org/abs/2509.23045" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3064" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="reading.html" target="_blank" rel="noopener noreferrer">#reading</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-02</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLMs）のソフトウェア工学（SWE）への応用が進んでおり、SWE-benchが重要なベンチマークとなっている。マルチターンのSWE-Agentフレームワークと単一ターンのエージェントレス手法は相互排他的ではなく、エージェントレストレーニングが効率的なSWE-Agentの適応を可能にする。本研究では、Kimi-DevというオープンソースのSWE LLMを紹介し、SWE-bench Verifiedで60.4%を達成。追加の適応により、Kimi-DevはSWE-Agentの性能を48.6%に引き上げ、移植可能なコーディングエージェントの実現を示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1973544152043495779?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>Agentlessはこちら:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1847" target="_blank" rel="noopener noreferrer">[Paper Note] Demystifying LLM-based Software Engineering Agents, Chunqiu Steven Xia+, FSE'25, 2024.07</a>
</p>
<p>著者ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yang_zonghan/status/1977022913644839329?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>ポストの中でOpenhandsが同モデルを内部で検証し、Openhandsの環境内でSWE Bench Verifiedで評価した結果、レポート内で報告されているAcc. 60.4%は達成できず、17%に留まることが報告されていた模様。<br><br>Openhandsの説明によるとAgentlessは決められた固定されたワークフローのみを実施する枠組み（Kimi Devの場合はBugFixerとFileEditor)であり、ワークフローで定義されたタスクは効果的に実施できるが、それら以外のタスクはそもそもうまくできない。SWE Agent系のベンチのバグfixの方法は大きく分けてAgentlike（コードベースを探索した上でアクションを実行する形式）、Fixed workflow like Agentless(固定されたワークフローのみを実行する形式）の2種類があり、Openhandsは前者、Kimi Devは後者の位置付けである。<br><br>実際、テクニカルレポートのFigure2とAppendixを見ると、File Localization+BugFixer+TestWriterを固定されたプロンプトテンプレートを用いてmid-trainingしており、評価する際も同様のハーネスが利用されていると推察される（どこかに明示的な記述があるかもしれない）。<br>一方、Openhandsではより実環境の開発フローに近いハーネス（e.g., エージェントがコードベースを確認してアクションを提案→実行可能なアクションなら実行→そうでないならユーザからのsimulated responceを受け取る→Agentに結果をフィードバック→エージェントがアクション提案...）といったハーネスとなっている。<br><br>このように評価をする際のハーネスが異なるため、同じベンチマークに対して異なる性能が報告される、ということだと思われる。<br><br>単にSWE Bench VerifiedのAcc.だけを見てモデルを選ぶのではなく、評価された際のEvaluation Harnessが自分たちのユースケースに合っているかを確認することが重要だと考えられる。<p>参考:<br><br>- OpenhandsのEvaluation Harness:


<a href="https://docs.all-hands.dev/openhands/usage/developers/evaluation-harness" target="_blank" rel="noopener noreferrer">https://docs.all-hands.dev/openhands/usage/developers/evaluation-harness</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="limi-less-2938" class="title-link">[Paper Note] LIMI: Less is More for Agency, Yang Xiao+, arXiv'25, 2025.09</h3>
<br><a href="https://arxiv.org/abs/2509.17567" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2938" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<span class="snippet"><span>GPT Summary</span>- AIシステムのエージェンシーを、自律的に問題を発見し解決策を実行する能力と定義。急速に変化する業界のニーズに応じて、単なる推論を超えた自律的なエージェントが求められている。LIMI（Less Is More for Intelligent Agency）は、最小限のトレーニングサンプルで高いエージェンシーを実現する新たな原則を提案し、78サンプルで73.5%の成果を達成。これは、従来のデータ量に依存するアプローチに対する挑戦であり、高品質なデモの戦略的キュレーションが重要であることを示している。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1970328242688246160?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>LLM AgentのSFTにおけるLess is more<br><br>参考:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/700" target="_blank" rel="noopener noreferrer">LIMA: Less Is More for Alignment, Chunting Zhou+, N/A, NeurIPS'23</a>
</p>
<p>ポイント解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1971777010658955436?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="gta-supervised-guided-2934" class="title-link">[Paper Note] GTA: Supervised-Guided Reinforcement Learning for Text Classification  with Large Language Models, Min Zeng+, arXiv'25, 2025.09</h3>
<br><a href="https://arxiv.org/abs/2509.12108" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2934" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Hybrid.html" target="_blank" rel="noopener noreferrer">#Hybrid</a>
<span class="issue_date">Issue Date: 2025-09-23</span>
<span class="snippet"><span>GPT Summary</span>- GTAフレームワークを提案し、SFTの効率性とRLの能力を統合。モデルは仮の推測を生成し、最終的な回答を導出する。ハイブリッドアプローチにより、収束が速く、性能が向上。損失マスキングと勾配制約を用いて勾配の対立を軽減。実験結果はGTAの優位性を示す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1970056056513679744?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="judgelm-fine-tuned-2933" class="title-link">[Paper Note] JudgeLM: Fine-tuned Large Language Models are Scalable Judges, Lianghui Zhu+, ICLR'25, 2023.10</h3>
<br><a href="https://arxiv.org/abs/2310.17631" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2933" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="LLM-as-a-Judge.html" target="_blank" rel="noopener noreferrer">#LLM-as-a-Judge</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLMs）のオープンエンド評価のために、ファインチューニングされたJudgeLMを提案。高品質なデータセットを用いて、異なるパラメータサイズでトレーニングし、バイアスを分析。新技術を導入し、パフォーマンスを向上。JudgeLMは既存ベンチマークで最先端の結果を達成し、高い一致率を示す。拡張された能力も持ち、コードは公開されている。</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=xsELpEPn4A" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=xsELpEPn4A</a>


</p>
<p>dataset: 


<a href="https://huggingface.co/datasets/BAAI/JudgeLM-100K" target="_blank" rel="noopener noreferrer">https://huggingface.co/datasets/BAAI/JudgeLM-100K</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="lora-pro-are-2929" class="title-link">[Paper Note] LoRA-Pro: Are Low-Rank Adapters Properly Optimized?, Zhengbo Wang+, ICLR'25, 2024.07</h3>
<br><a href="https://arxiv.org/abs/2407.18242" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2929" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<span class="snippet"><span>GPT Summary</span>- LoRAは基盤モデルの効率的なファインチューニング手法だが、フルファインチューニングに比べ性能が劣ることが多い。本論文では、LoRAとフルファインチューニングの最適化プロセスの関係を明らかにし、LoRAの低ランク行列の勾配を調整する新手法LoRA-Proを提案。これにより、LoRAの性能が向上し、フルファインチューニングとのギャップが縮小することを実験で示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:


<a href="https://openreview.net/forum?id=gTwRMU3lJ5" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=gTwRMU3lJ5</a>


</p>
<p>openreview:


<a href="https://openreview.net/forum?id=gTwRMU3lJ5" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=gTwRMU3lJ5</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="bioreason-incentivizing-2901" class="title-link">[Paper Note] BioReason: Incentivizing Multimodal Biological Reasoning within a   DNA-LLM Model, Adibvafa Fallahpour+, NeurIPS'25</h3>
<br><a href="https://arxiv.org/abs/2505.23579" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2901" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Biological.html" target="_blank" rel="noopener noreferrer">#Biological</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<span class="snippet"><span>GPT Summary</span>- BioReasonは、DNA基盤モデルと大規模言語モデル（LLM）を統合した新しいアーキテクチャで、複雑なゲノムデータからの生物学的推論を深く解釈可能にする。多段階推論を通じて、精度が88%から97%に向上し、バリアント効果予測でも平均15%の性能向上を達成。未見の生物学的エンティティに対する推論を行い、解釈可能な意思決定を促進することで、AIにおける生物学の進展を目指す。</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/collections/wanglab/bioreason-683cd17172a037a31d208f70" target="_blank" rel="noopener noreferrer">https://huggingface.co/collections/wanglab/bioreason-683cd17172a037a31d208f70</a>


<br>pj page:


<a href="https://bowang-lab.github.io/BioReason/" target="_blank" rel="noopener noreferrer">https://bowang-lab.github.io/BioReason/</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/bowang87/status/1969174399564857543?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="bread-branched-2898" class="title-link">[Paper Note] BREAD: Branched Rollouts from Expert Anchors Bridge SFT &amp; RL for   Reasoning, Xuechen Zhang+, NeurIPS'25</h3>
<br><a href="https://arxiv.org/pdf/2506.17211" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2898" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-19</span>
<span class="snippet"><span>GPT Summary</span>- 小型言語モデル（SLMs）は、トレースが不足している場合に複雑な推論を学ぶのが難しい。本研究では、SFT + RLの限界を調査し、BREADという新しい手法を提案。BREADは、専門家のガイダンスを用いてSFTとRLを統合し、失敗したトレースに対して短いヒントを挿入することで成功を促進。これにより、トレーニングが約3倍速くなり、標準的なGRPOを上回る性能を示す。BREADは、SLMの推論能力を大幅に向上させることが確認された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sametoymac/status/1968892463382200391?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="websailor-navigating-2855" class="title-link">[Paper Note] WebSailor: Navigating Super-human Reasoning for Web Agent, Kuan Li+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2507.02592" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2855" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<span class="snippet"><span>GPT Summary</span>- WebSailorは、LLMのトレーニングにおいて人間の認知的限界を超えるためのポストトレーニング手法であり、複雑な情報探索タスクでの性能を向上させる。構造化サンプリングや情報の難読化、DUPOを用いて高不確実性タスクを生成し、オープンソースエージェントの能力を大幅に上回ることを目指す。</span>
</article>
<article class="paper-entry">
<h3 id="webdancer-towards-2854" class="title-link">[Paper Note] WebDancer: Towards Autonomous Information Seeking Agency, Jialong Wu+, arXiv'25</h3>
<br><a href="https://arxiv.org/pdf/2505.22648" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2854" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<span class="issue_date">Issue Date: 2025-09-18</span>
<span class="snippet"><span>GPT Summary</span>- 複雑な問題解決のために、エンドツーエンドの情報探索エージェントを構築する一貫したパラダイムを提案。4つの主要ステージ（データ構築、軌跡サンプリング、教師ありファインチューニング、強化学習）を経て、WebDancerを実装。GAIAとWebWalkerQAでの評価により、強力なパフォーマンスを示し、トレーニングパラダイムの有効性を確認。コードは公開予定。</span>
</article>
<article class="paper-entry">
<h3 id="rl-fine-tuning-2840" class="title-link">[Paper Note] RL Fine-Tuning Heals OOD Forgetting in SFT, Hangzhan Jin+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2509.12235" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2840" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-17</span>
<span class="snippet"><span>GPT Summary</span>- 二段階ファインチューニングにおけるSFTとRLの相互作用を探求し、SFTが記憶し、RLが一般化するという主張が過度に単純化されていることを発見。具体的には、(1) OOD性能はSFTの初期段階でピークに達し、その後低下すること、(2) RLはSFT中に失われた推論能力を回復する役割を果たすこと、(3) 回復能力には限界があること、(4) OODの挙動は特異ベクトルの「回転」と強く相関することを明らかにした。これにより、SFTとRLの役割を再認識し、特異ベクトルの回転が重要なメカニズムであることを示した。</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1740" target="_blank" rel="noopener noreferrer">SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model   Post-training, Tianzhe Chu+, ICML'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2700" target="_blank" rel="noopener noreferrer">[Paper Note] Towards a Unified View of Large Language Model Post-Training, Xingtai Lv+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2713" target="_blank" rel="noopener noreferrer">[Paper Note] RL's Razor: Why Online Reinforcement Learning Forgets Less, Idan Shenfeld+, arXiv'25</a>
<br><br>と合わせて読むと良さそう</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1968187719588385240?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>直感的には、下記研究でSFTをRLの観点で見たときに、回答の軌跡に対してexact matchしていた場合に1を返す報酬を持つRL、かつimportance weightingによって現在のポリシーが苦手な軌跡を重要視する、ということ考えると、目的のデータに対して汎化性能おかまいなしにgreedyに最適化されるため、OODへの対応力が無くなる、というのはなんとなく理解できる。<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="medresearcher-r1-expert-level-2793" class="title-link">[Paper Note] MedResearcher-R1: Expert-Level Medical Deep Researcher via A  Knowledge-Informed Trajectory Synthesis Framework, Ailing Yu+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2508.14880" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2793" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="DeepResearch.html" target="_blank" rel="noopener noreferrer">#DeepResearch</a>
<a class="button" href="Medical.html" target="_blank" rel="noopener noreferrer">#Medical</a>
<span class="issue_date">Issue Date: 2025-09-13</span>
<span class="snippet"><span>GPT Summary</span>- 医療分野に特化した深層研究エージェントを提案。医療知識グラフを用いたデータ合成とカスタム医療検索エンジンを統合し、複雑な質問-回答ペアを生成。新たな医療ベンチマークで最先端の結果を達成し、一般的な深層研究タスクでも競争力を維持。ドメイン特化型の革新が小型モデルの優位性を示す。</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/AQ-MedAI" target="_blank" rel="noopener noreferrer">https://huggingface.co/AQ-MedAI</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1966647034326253894?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>ベンチマーク:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2794" target="_blank" rel="noopener noreferrer">[Paper Note] MedBrowseComp: Benchmarking Medical Deep Research and Computer Use, Shan Chen+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2466" target="_blank" rel="noopener noreferrer">[Paper Note] xbench: Tracking Agents Productivity Scaling with Profession-Aligned
  Real-World Evaluations, Kaiyuan Chen+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1158" target="_blank" rel="noopener noreferrer">GAIA: a benchmark for General AI Assistants, Grégoire Mialon+, N/A, arXiv'23</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="webexplorer-explore-2754" class="title-link">[Paper Note] WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents, Junteng Liu+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2509.06501" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2754" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="GraphBased.html" target="_blank" rel="noopener noreferrer">#GraphBased</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、情報探索のためのデータ不足に対処するため、WebExplorerというモデルベースの探索手法を提案。これにより、複雑なクエリ-回答ペアを生成し、高度なウェブエージェントWebExplorer-8Bを開発。128Kのコンテキスト長を持ち、最先端の情報探索ベンチマークで高いパフォーマンスを達成。特に、WebExplorer-8Bは他の大規模モデルを上回る精度を示し、長期的な問題解決に向けた実用的なアプローチを提供することが確認された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1965537550937792934?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>評価で利用されているデータ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2451" target="_blank" rel="noopener noreferrer">[Paper Note] BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents, Jason Wei+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1730" target="_blank" rel="noopener noreferrer">[Paper Note] Humanity's Last Exam, Long Phan+, arXiv'25</a>
</p>
<p>学習データの合成方法が肝</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="parallel-r1-towards-2753" class="title-link">[Paper Note] Parallel-R1: Towards Parallel Thinking via Reinforcement Learning, Tong Zheng+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2509.07980" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2753" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<span class="snippet"><span>GPT Summary</span>- Parallel-R1は、複雑な推論タスクに対して並列思考を可能にする強化学習フレームワークであり、コールドスタート問題に対処するための進行的なカリキュラムを採用。簡単なタスクから始め、並列思考能力を植え付けた後、難しい問題に移行。実験により、従来の逐次思考モデルに対して8.4%の精度向上を達成し、並列思考が中間トレーニング探索の足場として機能することを示した。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aicia_solid/status/1965631715235525006?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>結果の表を見るとベースモデルで単にself Consistencyを実施するよりも高いゲインを得ているように見える。モデルがQwen3のみでしか実験されておらず、Qwen2.5においてコンタミネーションの疑い <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2226" target="_blank" rel="noopener noreferrer">[Paper Note] Reasoning or Memorization? Unreliable Results of Reinforcement Learning  Due to Data Contamination, Mingqi Wu+, arXiv'25</a>
 があったので、(Qwen3がどうかはわからないが)単一モデルではなく、他のモデルでも実験した方が良いのかな、という印象。</p>
<p>ポイント解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1965691174813089987?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>ポイント解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1968939351427158459?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>コードがリリース:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wyu_nd/status/1976011651758588165?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="rl's-razor-2713" class="title-link">[Paper Note] RL's Razor: Why Online Reinforcement Learning Forgets Less, Idan Shenfeld+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2509.04259" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2713" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<a class="button" href="On-Policy.html" target="_blank" rel="noopener noreferrer">#On-Policy</a>
<span class="issue_date">Issue Date: 2025-09-06</span>
<span class="snippet"><span>GPT Summary</span>- 強化学習（RL）と教師ありファインチューニング（SFT）の比較により、RLが以前の知識をより良く保持することが明らかに。忘却の程度は分布のシフトによって決まり、KLダイバージェンスで測定される。RLは新しいタスクに対してKL最小解にバイアスがかかる一方、SFTは任意の距離に収束する可能性がある。実験を通じて、RLの更新が小さなKL変化をもたらす理由を理論的に説明し、「RLの剃刀」と呼ぶ原則を提唱。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jyo_pari/status/1963967312555332065?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>所見:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/stone_tao/status/1964381652106563591?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>ポイント解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1963823603469730114?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="towards-a-2700" class="title-link">[Paper Note] Towards a Unified View of Large Language Model Post-Training, Xingtai Lv+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2509.04419" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2700" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-05</span>
<span class="snippet"><span>GPT Summary</span>- 本論文では、オンラインデータとオフラインデータを用いた言語モデルのポストトレーニングアプローチが、矛盾せず単一の最適化プロセスであることを示す。統一ポリシー勾配推定器を導出し、ハイブリッドポストトレーニング（HPT）アルゴリズムを提案。HPTは異なるトレーニング信号を動的に選択し、デモンストレーションを効果的に活用しつつ安定した探索を実現。実験により、HPTが数学的推論ベンチマークで強力な性能を示すことを確認。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rosinality/status/1963818963550572623?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
</p>
<p>解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1963971173735448858?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="motif-2.6b-2537" class="title-link">[Paper Note] Motif 2.6B Technical Report, Junghwan Lim+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2508.09148" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2537" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="Architecture.html" target="_blank" rel="noopener noreferrer">#Architecture</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="DataMixture.html" target="_blank" rel="noopener noreferrer">#DataMixture</a>
<span class="issue_date">Issue Date: 2025-08-25</span>
<span class="snippet"><span>GPT Summary</span>- Motif-2.6Bは、26億パラメータを持つ基盤LLMで、長文理解の向上や幻覚の減少を目指し、差分注意やポリノルム活性化関数を採用。広範な実験により、同サイズの最先端モデルを上回る性能を示し、効率的でスケーラブルな基盤LLMの発展に寄与する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/scaling01/status/1959604841577357430?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>HF:


<a href="https://huggingface.co/Motif-Technologies/Motif-2.6B" target="_blank" rel="noopener noreferrer">https://huggingface.co/Motif-Technologies/Motif-2.6B</a>


</p>
<p>- アーキテクチャ<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1466" target="_blank" rel="noopener noreferrer">Differential Transformer, Tianzhu Ye+, N/A, ICLR'25</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2538" target="_blank" rel="noopener noreferrer">[Paper Note] Polynomial Composition Activations: Unleashing the Dynamics of Large
  Language Models, Zhijian Zhuo+, arXiv'24</a>
<br>- 学習手法<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1979" target="_blank" rel="noopener noreferrer">Model Merging in Pre-training of Large Language Models, Yunshui Li+, arXiv'25</a>
<br>    - 8B token学習するごとに直近6つのcheckpointのelement-wiseの平均をとりモデルマージ。当該モデルに対して学習を継続、ということを繰り返す。これにより、学習のノイズを低減し、突然パラメータがシフトすることを防ぐ<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1060" target="_blank" rel="noopener noreferrer">Effective Long-Context Scaling of Foundation Models, Wenhan Xiong+, N/A, NAACL'24</a>
<br>    - Adaptive Base Frequency (RoPEのbase frequencyを10000から500000にすることでlong contextのattention scoreが小さくなりすぎることを防ぐ)<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2540" target="_blank" rel="noopener noreferrer">[Paper Note] MiniCPM: Unveiling the Potential of Small Language Models with Scalable   Training Strategies, Shengding Hu+, COLM'24</a>
 <br>- 事前学習データ<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1943" target="_blank" rel="noopener noreferrer">DataComp-LM: In search of the next generation of training sets for
  language models, Jeffrey Li+, arXiv'24</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2539" target="_blank" rel="noopener noreferrer">TxT360, LLM360, 2024.10</a>
<br>  - <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2109" target="_blank" rel="noopener noreferrer">[Paper Note] FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data  Processing to Every Language, Guilherme Penedo+, COLM'25</a>
 <br><br>を利用したモデル。同程度のサイズのモデルとの比較ではかなりのgainを得ているように見える。興味深い。<br>DatasetのMixtureの比率などについても記述されている。<br><br><img src="https://github.com/user-attachments/assets/0a26442e-8075-4cbe-8cc1-f1ff471b7356" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="plamo-translate-2517" class="title-link">PLaMo Translate: 翻訳特化大規模言語モデルの開発,今城+, Jxiv'25</h3>
<br><a href="https://jxiv.jst.go.jp/index.php/jxiv/preprint/view/1461/#Jxiv" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2517" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="ModelMerge.html" target="_blank" rel="noopener noreferrer">#ModelMerge</a>
<span class="issue_date">Issue Date: 2025-08-22</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imos/status/1958687896321630355?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>SFT-&gt;Iterative DPO-&gt;Model Mergeのパイプライン。SFTでは青空文庫などのオープンなデータから指示追従性能の高いDeepSeek-V3-0324によって元データ→翻訳, 翻訳→再翻訳データを合成し活用。また、翻訳の指示がprompt中に存在せずとも（本モデルを利用するのは翻訳用途であることが自明であるからと推察される）翻訳を適切に実行できるよう、独自のテンプレートを学習。文体指定、常体、敬体の指定、文脈考慮、語彙指定それぞれにういて独自のタグを設けてフォーマットを形成し翻訳に特化したテンプレートを学習。<br><br>IterativeDPOでは、DeepSeekV3に基づくLLM-as-a-Judgeと、MetricX(<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2658" target="_blank" rel="noopener noreferrer">[Paper Note] MetricX-24: The Google Submission to the WMT 2024 Metrics Shared Task, Juraj Juraska+, arXiv'24</a>
)に基づいてReward Modelをそれぞれ学習し、1つの入力に対して100個の翻訳を作成しそれぞれのRewardモデルのスコアの合計値に基づいてRejection Samplingを実施することでPreference dataを構築。3段階のDPOを実施し、段階ごとにRewardモデルのスコアに基づいて高品質なPreference Dataに絞ることで性能向上を実現。<br><br>モデルマージではDPOの各段階のモデルを重み付きでマージすることで各段階での長所を組み合わせたとのこと。</p>
<p>サービスリリース:


<a href="https://prtimes.jp/main/html/rd/p/000000019.000156310.html?hm_ct=d17807e98595783ee6edfc7ae00fe95a&hm_cv=87e6d4e056b010261ecdc77d7ac8eb6c&hm_cs=1638145470668f4b36f218d2.35741174&hm_mid=m3hk6&hm_id=m3hk6&hm_h=a03.hm-f.jp" target="_blank" rel="noopener noreferrer">https://prtimes.jp/main/html/rd/p/000000019.000156310.html?hm_ct=d17807e98595783ee6edfc7ae00fe95a&hm_cv=87e6d4e056b010261ecdc77d7ac8eb6c&hm_cs=1638145470668f4b36f218d2.35741174&hm_mid=m3hk6&hm_id=m3hk6&hm_h=a03.hm-f.jp</a>


</p>
<p>2025.1010配信の「岡野原大輔のランチタイムトーク Vol.52 番外編「なぜPLaMo翻訳は自然なのか？」において詳細が語られているので参照のこと。特になぜ日本語に強いLLMが大事なのか？という話が非常におもしろかった。</p>
<p>ガバメントAI源内での利用が決定:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1995746797051101536?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="chain-of-agents-end-to-end-2503" class="title-link">[Paper Note] Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent  Distillation and Agentic RL, Weizhen Li+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2508.13167" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2503" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Single.html" target="_blank" rel="noopener noreferrer">#Single</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-08-21</span>
<span class="snippet"><span>GPT Summary</span>- Chain-of-Agents（CoA）という新しいLLM推論パラダイムを提案し、マルチエージェントシステムの協力を単一モデル内でエンドツーエンドに実現。マルチエージェント蒸留フレームワークを用いて、エージェント的な教師ありファインチューニングを行い、強化学習で能力を向上。得られたエージェント基盤モデル（AFMs）は、ウェブエージェントやコードエージェントの設定で新たな最先端性能を示す。研究成果はオープンソース化され、今後の研究の基盤を提供。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1958186531161853995?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>マルチエージェントのように振る舞うシングルエージェントを、マルチエージェントから得られたtrajectoryを通じて蒸留することめ実現する手法を提案。SFTでcold startに対して訓練した後、verifiable reward (タスクを正常に完了できたか否か)でRLする模様。<br><br><img src="https://github.com/user-attachments/assets/b4cafaba-488e-4d8b-a6d3-faf98733d134" alt="image" loading="lazy" width="550" height="400"><br><br><img src="https://github.com/user-attachments/assets/80a934e9-db47-401b-809e-394ab5e20585" alt="image" loading="lazy" width="550" height="400"></p>
<p>データセットも公開されている模様</p>
<p>所見:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dongxi_nlp/status/1958604404338147417?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiqizhixin/status/1959877518972137667?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="on-the-2382" class="title-link">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with  Reward Rectification, Yongliang Wu+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2508.05629" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-08-09</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLM）の教師ありファインチューニング（SFT）の一般化能力を向上させるため、動的ファインチューニング（DFT）を提案。DFTはトークンの確率に基づいて目的関数を再スケーリングし、勾配更新を安定化させる。これにより、SFTを大幅に上回る性能を示し、オフライン強化学習でも競争力のある結果を得た。理論的洞察と実践的解決策を結びつけ、SFTの性能を向上させる。コードは公開されている。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1953960036126142645?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>これは大変興味深い。数学以外のドメインでの評価にも期待したい。</p>
<p>3節冒頭から3.2節にかけて、SFTとon policy RLのgradientを定式化し、SFT側の数式を整理することで、SFT（のgradient)は以下のようなon policy RLの一つのケースとみなせることを導出している。そしてSFTの汎化性能が低いのは 1/pi_theta によるimportance weightingであると主張し、実験的にそれを証明している。つまり、ポリシーがexpertのgold responseに対して低い尤度を示してしまった場合に、weightか過剰に大きくなり、Rewardの分散が過度に大きくなってしまうことがRLの観点を通してみると問題であり、これを是正することが必要。さらに、分散が大きい報酬の状態で、報酬がsparse(i.e., expertのtrajectoryのexact matchしていないと報酬がzero)であることが、さらに事態を悪化させている。<br><br>&gt; conventional SFT is precisely an on-policy-gradient with the reward as an indicator function of<br>matching the expert trajectory but biased by an importance weighting 1/πθ.<br><br>まだ斜め読みしかしていないので、後でしっかり読みたい</p>
<p>最近は下記で示されている通りSFTでwarm-upをした後にRLによるpost-trainingをすることで性能が向上することが示されており、<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">[Paper Note] Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
 <br><br>主要なOpenModelでもSFT wamup -&gt; RLの流れが主流である。この知見が、SFTによるwarm upの有効性とどう紐づくだろうか？<br>これを読んだ感じだと、importance weightによって、現在のポリシーが苦手な部分のreasoning capabilityのみを最初に強化し（= warmup）、その上でより広範なサンプルに対するRLが実施されることによって、性能向上と、学習の安定につながっているのではないか？という気がする。</p>
<p>日本語解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1960108668336390593?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>一歩先の視点が考察されており、とても勉強になる。</span><br><br>
</article>
<article class="paper-entry">
<h3 id="axbench-steering-2337" class="title-link">[Paper Note] AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse   Autoencoders, Zhengxuan Wu+, ICLR'25 Spotlight</h3>
<br><a href="https://arxiv.org/abs/2501.17148" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2337" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="ActivationSteering_ITI.html" target="_blank" rel="noopener noreferrer">#ActivationSteering/ITI</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<a class="button" href="Steering.html" target="_blank" rel="noopener noreferrer">#Steering</a>
<span class="issue_date">Issue Date: 2025-08-02</span>
<span class="snippet"><span>GPT Summary</span>- 言語モデルの出力制御は安全性と信頼性に重要であり、プロンプトやファインチューニングが一般的に用いられるが、さまざまな表現ベースの技術も提案されている。これらの手法を比較するためのベンチマークAxBenchを導入し、Gemma-2-2Bおよび9Bに関する実験を行った。結果、プロンプトが最も効果的で、次いでファインチューニングが続いた。概念検出では表現ベースの手法が優れており、SAEは競争力がなかった。新たに提案した弱教師あり表現手法ReFT-r1は、競争力を持ちながら解釈可能性を提供する。AxBenchとともに、ReFT-r1およびDiffMeanのための特徴辞書を公開した。</span>
<span class="snippet"><span>Comment</span><p>openreview:


<a href="https://openreview.net/forum?id=K2CckZjNy0" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=K2CckZjNy0</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="openvlthinker-complex-2289" class="title-link">[Paper Note] OpenVLThinker: Complex Vision-Language Reasoning via Iterative SFT-RL   Cycles, Yihe Deng+, NeurIPS'25</h3>
<br><a href="https://arxiv.org/abs/2503.17352" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2289" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-24</span>
<span class="snippet"><span>GPT Summary</span>- OpenVLThinkerは、洗練された連鎖的思考推論を示すオープンソースの大規模視覚言語モデルであり、視覚推論タスクで顕著な性能向上を達成。SFTとRLを交互に行うことで、推論能力を効果的に引き出し、改善を加速。特に、MathVistaで3.8%、EMMAで2.4%、HallusionBenchで1.6%の性能向上を実現。コードやモデルは公開されている。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yihe__deng/status/1948194764777783324?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="blending-supervised-2260" class="title-link">[Paper Note] Blending Supervised and Reinforcement Fine-Tuning with Prefix Sampling, Zeyu Huang+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2507.01679" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2260" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-07-19</span>
<span class="snippet"><span>GPT Summary</span>- ポストトレーニング技術にはSFTとRFTがあり、それぞれ異なるトレードオフが存在する。本論文では、デモンストレーションと探索を統合したハイブリッドアプローチ「Prefix-RFT」を提案し、数学的推論問題でその効果を実証。Prefix-RFTはSFTやRFTの性能を上回り、既存のフレームワークに容易に統合可能である。分析により、SFTとRFTの補完的な性質が示され、デモンストレーションデータの質と量に対する堅牢性も確認された。この研究はLLMのポストトレーニングに新たな視点を提供する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zeroyuhuang/status/1946232400922484992?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>少し前からXコミュニティでRFT(Reinforcement Finetuning)という用語が観測されたが、arXiv paperで見たのは初めてかもしれない。RFTはおそらく、強化学習を利用したPost-Trainingの総称だと思われる。</p>
<p>デモンストレーションデータからPrefixをサンプリングし（SFTの要素; オフラインデータからサンプリングしたPrefixで生成をガイドする）、Prefixの続きをオンラインで生成し（RFTの要素; ガイドされたPrefixの続きを探索する）、Prefix+生成結果をロールアウトとし学習する。<br><img src="https://github.com/user-attachments/assets/2988bc02-0c88-47e7-ab55-a623c5122428" alt="image" loading="lazy" width="550" height="400"><br><br><img src="https://github.com/user-attachments/assets/01875988-9364-4eb1-acb2-e35cf907b789" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="singlora-low-2194" class="title-link">[Paper Note] SingLoRA: Low Rank Adaptation Using a Single Matrix, David Bensaïd+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2507.05566" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2194" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="Stability.html" target="_blank" rel="noopener noreferrer">#Stability</a>
<span class="issue_date">Issue Date: 2025-07-12</span>
<span class="snippet"><span>GPT Summary</span>- SingLoRAは、LoRAの低ランク適応を再定式化し、単一の低ランク行列とその転置の積を用いることで、トレーニングの安定性を向上させ、パラメータ数をほぼ半減させる手法です。実験により、常識推論タスクでLLama 7Bを用いたファインチューニングで91.3%の精度を達成し、LoRAやLoRA+を上回る結果を示しました。また、画像生成においてもStable Diffusionのファインチューニングで高い忠実度を実現しました。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/theturingpost/status/1943701154497732765?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>LoRAは低ランク行列BAの積を計算するが、オリジナルのモデルと同じ挙動から学習をスタートするために、Bをzeroで初期化し、Aはランダムに初期化する。このAとBの不均衡さが、勾配消失、爆発、あるいはsub-optimalな収束の要因となってしまっていた（inter-matrix scale conflicts)。特に、LoRAはモデルのwidthが大きくなると不安定になるという課題があった。このため、低ランク行列を2つ使うのではなく、1つの低ランク行列（とその転置）およびoptimizationのstep tごとにtrainableなパラメータがどの程度影響を与えるかを調整する度合いを決めるscalar function u(t)を導入することで、低ランク行列間の不均衡を解消しつつ、パラメータ数を半減し、学習の安定性と性能を向上させる。たとえばu(t)を学習開始時にzeroにすれば、元のLoRAにおいてBをzeroに初期化するのと同じ挙動（つまり元のモデルと同じ挙動から学習スタートができたりする。みたいな感じだろうか？<br><br><img src="https://github.com/user-attachments/assets/2dcd4ec1-59d3-43c0-ab8d-5c1c37e5ec3d" alt="image" loading="lazy" width="550" height="400"><br><br><img src="https://github.com/user-attachments/assets/c73b8715-e0c8-45c8-a7fa-ea55ac8ca3ce" alt="image" loading="lazy" width="550" height="400"><br><br><img src="https://github.com/user-attachments/assets/cf034dcd-37c4-48f1-a0a3-1d836db37820" alt="image" loading="lazy" width="550" height="400"><br><br><img src="https://github.com/user-attachments/assets/82999835-ac1e-4380-8bd0-00d14022abf5" alt="image" loading="lazy" width="550" height="400"></p>
<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1956" target="_blank" rel="noopener noreferrer">LoRA: Low-Rank Adaptation of Large Language Models, Edward J. Hu+, ICLR'22</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1245" target="_blank" rel="noopener noreferrer">LoRA+: Efficient Low Rank Adaptation of Large Models, Soufiane Hayou+, N/A, ICML'24</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="toward-cross-hospital-2177" class="title-link">[Paper Note] Toward Cross-Hospital Deployment of Natural Language Processing Systems: Model Development and Validation of Fine-Tuned Large Language Models for Disease Name Recognition in Japanese, Shimizu+, JMIR'25</h3>
<br><a href="https://medinform.jmir.org/2025/1/e76773" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2177" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="OOD.html" target="_blank" rel="noopener noreferrer">#OOD</a>
<a class="button" href="DiseaseNameRecognition.html" target="_blank" rel="noopener noreferrer">#DiseaseNameRecognition</a>
<span class="issue_date">Issue Date: 2025-07-10</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aramaki/status/1942902940337099254?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="criticlean-critic-guided-2158" class="title-link">[Paper Note] CriticLean: Critic-Guided Reinforcement Learning for Mathematical  Formalization, Zhongyuan Peng+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2507.06181" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2158" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<span class="issue_date">Issue Date: 2025-07-09</span>
<span class="snippet"><span>GPT Summary</span>- 自然言語の数学的表現を実行可能なコードに翻訳する課題に対し、批評者の役割を能動的な学習コンポーネントに変えるCriticLeanという新しい強化学習フレームワークを提案。CriticLeanGPTを用いて形式化の意味的忠実性を評価し、CriticLeanBenchでその能力を測定。285K以上の問題を含むFineLeanCorpusデータセットを構築し、批評段階の最適化が信頼性のある形式化に重要であることを示す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1942790484688003275?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>関連<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1832" target="_blank" rel="noopener noreferrer">Critique Fine-Tuning: Learning to Critique is More Effective than   Learning to Imitate, Yubo Wang+, COLM'25</a>
</p>
<p>Lean 4 形式に<br><br><img src="https://github.com/user-attachments/assets/79121e53-b205-440d-9615-d520ac848704" alt="image" loading="lazy" width="550" height="400"><br><br></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="scholarcopilot-training-2149" class="title-link">[Paper Note] ScholarCopilot: Training Large Language Models for Academic Writing with   Accurate Citations, Yubo Wang+, COLM'25</h3>
<br><a href="https://arxiv.org/pdf/2504.00824" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2149" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="Citations.html" target="_blank" rel="noopener noreferrer">#Citations</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="AcademicWriting.html" target="_blank" rel="noopener noreferrer">#AcademicWriting</a>
<span class="issue_date">Issue Date: 2025-07-08</span>
<span class="snippet"><span>GPT Summary</span>- ScholarCopilotは、学術的な執筆を支援するために大規模言語モデルを強化したフレームワークで、正確で文脈に関連した引用を生成します。取得トークンを用いて動的に文献を取得し、生成プロセスを補強します。評価では、取得精度が40.1%に達し、生成品質も他のモデルを大幅に上回りました。特に、ScholarCopilotはChatGPTを超える性能を示し、引用の質で100%の好ましさを達成しました。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1907861046833885397?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>従来のRAGベースのAcademicWriting手法では、まずReferenceを検索して、その内容をcontextに含めてテキストを生成するというSequentialなパイプラインだったが、本研究では通常のNextTokenPrediction Lossに加え、特殊トークン\[RET\]を導入し、ContrastiveLearningによって、\[RET\]トークンがトリガーとなり、生成過程のContextとqueryから適切なReferenceを検索できるEmbeddingを出力し、Referenceを検索し、動的にReferenceの内容をcontextに加え、テキストを生成する手法を提案している。<br><img src="https://github.com/user-attachments/assets/777da4cb-5678-455f-babf-b91690945712" alt="image" loading="lazy" width="550" height="400"><br><img src="https://github.com/user-attachments/assets/a27e092e-fff2-4f8a-91f7-09fe39e8e568" alt="image" loading="lazy" width="550" height="400"><br><br>データセットはarXivからlatex sourceを収集し、bibliography部分からReferenceのタイトルをQwenを用いて抽出。タイトルをarXivおよびSemanticScholarのデータベースと照合し、paperとReferenceの紐付けを実施することで構築している。<br><img src="https://github.com/user-attachments/assets/2dd2b956-291e-4407-997a-4a2e68a72708" alt="image" loading="lazy" width="550" height="400"><br><br>GPT-4oによるjudgeの結果、ground truthのcitationを用いた場合には及ばないが、提案手法により品質が向上し、citation retrievalのRecall@Kも大幅に改善している。<br><img src="https://github.com/user-attachments/assets/2ff5dd73-dcb8-4a3f-9d6a-1bcfb52a8321" alt="image" loading="lazy" width="550" height="400"><br><img src="https://github.com/user-attachments/assets/81a39366-2577-41a1-aa6b-facc7ac25f1c" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="care-assessing-2133" class="title-link">[Paper Note] CARE: Assessing the Impact of Multilingual Human Preference Learning on  Cultural Awareness, Geyang Guo+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2504.05154" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2133" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Cultural.html" target="_blank" rel="noopener noreferrer">#Cultural</a>
<span class="issue_date">Issue Date: 2025-07-04</span>
<span class="snippet"><span>GPT Summary</span>- 本論文では、文化的多様性を考慮した言語モデル（LM）の訓練方法を分析し、ネイティブな文化的好みを取り入れることで、LMの文化的認識を向上させることを目指します。3,490の文化特有の質問と31,700のネイティブな判断を含むリソース「CARE」を紹介し、高品質なネイティブの好みを少量取り入れることで、さまざまなLMの性能が向上することを示します。また、文化的パフォーマンスが強いモデルはアラインメントからの恩恵を受けやすく、地域間でのデータアクセスの違いがモデル間のギャップを生むことが明らかになりました。CAREは一般に公開される予定です。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cherylolguo/status/1940798823405600843?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="glm-4.1v-thinking-towards-2128" class="title-link">[Paper Note] GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable  Reinforcement Learning, GLM-V Team+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2507.01006" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2128" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="CurriculumLearning.html" target="_blank" rel="noopener noreferrer">#CurriculumLearning</a>
<a class="button" href="RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-07-03</span>
<span class="snippet"><span>GPT Summary</span>- 視覚言語モデルGLM-4.1V-Thinkingを発表し、推論中心のトレーニングフレームワークを開発。強力な視覚基盤モデルを構築し、カリキュラムサンプリングを用いた強化学習で多様なタスクの能力を向上。28のベンチマークで最先端のパフォーマンスを達成し、特に難しいタスクで競争力のある結果を示す。モデルはオープンソースとして公開。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/sinclairwang1/status/1940331927724232712?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>Qwen2.5-VLよりも性能が良いVLM<br><img src="https://github.com/user-attachments/assets/1215d0cf-3776-4631-a5d5-2c514e7d5a2e" alt="image" loading="lazy" width="550" height="400"></p>
<p>アーキテクチャはこちら。が、pretraining(データのフィルタリング, マルチモーダル→long context継続事前学習)-&gt;SFT(cold startへの対処, reasoning能力の獲得)-&gt;RL(RLVRとRLHFの併用によるパフォーマンス向上とAlignment, RewardHackingへの対処,curriculum sampling)など、全体の学習パイプラインの細かいテクニックの積み重ねで高い性能が獲得されていると考えられる。<br><img src="https://github.com/user-attachments/assets/a692b5de-5f4e-42c6-938e-3718dd2fc0e6" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="acereason-nemotron-1.1-2058" class="title-link">[Paper Note] AceReason-Nemotron 1.1: Advancing Math and Code Reasoning through SFT and RL Synergy, Zihan Liu+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2506.13284" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2058" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、教師ありファインチューニング（SFT）と強化学習（RL）の相乗効果を探求し、SFTトレーニングデータの整備においてプロンプト数の増加が推論性能を向上させることを示しました。特に、サンプリング温度を適切に調整することで、RLトレーニングの効果を最大化できることが分かりました。最終的に、AceReason-Nemotron-1.1モデルは、前モデルを大きく上回り、数学およびコードベンチマークで新たな最先端性能を達成しました。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ychennlp/status/1935005283178492222?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>様々なtakeawayがまとめられている。<p>SFT,RLに利用されたデータも公開</p>
<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1829" target="_blank" rel="noopener noreferrer">Scaling Data-Constrained Language Models, Niklas Muennighoff+, NeurIPS'23</a>
<br><br>において事前学習時に4 epochまでは性能の改善幅が大きいと報告されていたが、SFTでも5 epoch程度まで学習すると良い模様。<br><br>また、SFT dataをscalingさせる際は、promptの数だけでなく、prompt単位のresponse数を増やすのが効果的<br><img src="https://github.com/user-attachments/assets/67e2a4ff-555b-4e22-a90a-ee239704805e" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="massive-supervised-2052" class="title-link">[Paper Note] Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and  Training Factors Shape LLM Alignment Quality, Yuto Harada+, EMNLP'25</h3>
<br><a href="https://arxiv.org/abs/2506.14681" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2052" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-18</span>
<span class="snippet"><span>GPT Summary</span>- SFTはLLMを人間の指示に整合させる重要なプロセスであり、1,000以上のSFTモデルを生成し、データセットの特性と層ごとの変更を調査。訓練タスクの相乗効果やモデル固有の戦略の重要性を明らかにし、困惑度がSFTの効果を予測することを示した。中間層の重みの変化がパフォーマンス向上と強く相関し、研究を加速させるためにモデルと結果を公開予定。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/odashi_t/status/1935191113981403359?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>NLP'25:


<a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/C10-6.pdf" target="_blank" rel="noopener noreferrer">https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/C10-6.pdf</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="self-adapting-language-2036" class="title-link">[Paper Note] Self-Adapting Language Models, Adam Zweiger+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2506.10943" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2036" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-06-13</span>
<span class="snippet"><span>GPT Summary</span>- 自己適応型LLMs（SEAL）を提案し、モデルが自身のファインチューニングデータと指示を生成することで適応を実現。新しい入力に対して自己編集を行い、持続的な重みの更新を可能にする。強化学習ループを用いて下流性能を報酬信号として活用し、従来のアプローチと異なり、モデル自身の生成を用いて適応を制御。実験結果はSEALの有望性を示す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jyo_pari/status/1933350025284702697?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>コンテキストCと評価データtauが与えられたとき、Cを入力した時にモデルが自分をSFTし、tau上でより高い性能を得られるようなサンプル Self Edit (SE) を生成できるように学習することで、性能を向上させたい。これをRLによって実現する。具体的には、下記アルゴリズムのようにモデルにSEを生成させ、SEでSFTすることめにtau上での性能が向上したか否かのbinary rewardを用いてパラメータを更新する、といったことを繰り返す。これは実質、RL_updateと書いてあるが、性能が向上した良いSEのみでモデルをSFTすること、と同等なことを実施している。<br><br><img src="https://github.com/user-attachments/assets/69a395da-521f-444d-af6f-4c1b25bb6765" alt="image" loading="lazy" width="550" height="400"><br><br>このような背景として、RLのアルゴリズムとしてGRPOやPPOを適用したところ学習が不安定でうまくいかなかったため、よりシンプルなアプローチであるReST^EM（<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2041" target="_blank" rel="noopener noreferrer">[Paper Note] Beyond Human Data: Scaling Self-Training for Problem-Solving with   Language Models, Avi Singh+, TMLR'24</a>
)を採用した。これはrejection samplingとSFTに基づいたEMアルゴリズムのようなものらしく、Eステップで現在のポリシーでcandidateを生成し、Mステップでpositive rewardを得たcandidateのみ（＝rejection sampling)でSFTする、といったことを繰り返す、みたいな手法らしい。これを用いると、論文中の式(1)を上述のbinary rewardで近似することに相当する。より詳細に書くと、式(1)（つまり、SEをCから生成することによって得られるtauに基づく報酬rの総報酬を最大化したい、という式）を最大化するためにθ_tの勾配を計算したいが、reward rがθ_tで微分不可能なため、Monte Carlo Estimatorで勾配を近似する、みたいなことをやるらしい。Monte Carlo Estimatorでは実際のサンプルの期待値によって理論的な勾配を近似するらしく、これが式(3)のスコア関数とreward rの平均、といった式につながっているようである。</p>
<p>再現実験に成功したとのポスト:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wtzhang0820/status/1984325775344959531?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="resa-transparent-2035" class="title-link">[Paper Note] Resa: Transparent Reasoning Models via SAEs, Shangshang Wang+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2506.09967" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2035" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-06-13</span>
<span class="snippet"><span>GPT Summary</span>- Resaという1.5Bの推論モデル群を提案し、効率的なスパースオートエンコーダーチューニング（SAE-Tuning）手法を用いて訓練。これにより、97%以上の推論性能を保持しつつ、訓練コストを2000倍以上削減し、訓練時間を450倍以上短縮。軽いRL訓練を施したモデルで高い推論性能を実現し、抽出された推論能力は一般化可能かつモジュール化可能であることが示された。全ての成果物はオープンソース。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1933101904529363112?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>著者ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/upupwang/status/1933207676663865482?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>論文中で利用されているSource Modelの一つ:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1935" target="_blank" rel="noopener noreferrer">[Paper Note] Tina: Tiny Reasoning Models via LoRA, Shangshang Wang+, arXiv'25</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="go-browse-training-2032" class="title-link">[Paper Note] Go-Browse: Training Web Agents with Structured Exploration, Apurva Gandhi+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2506.03533" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2032" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<span class="issue_date">Issue Date: 2025-06-12</span>
<span class="snippet"><span>GPT Summary</span>- Go-Browseを提案し、ウェブ環境の構造的探索を通じて多様なデータを自動収集。グラフ探索を用いて効率的なデータ収集を実現し、WebArenaベンチマークで成功率21.7%を達成。これはGPT-4o miniを2.4%上回り、10B未満のモデルでの最先端結果を2.9%上回る。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gneubig/status/1932786231542493553?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>WebArena:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1849" target="_blank" rel="noopener noreferrer">WebArena: A Realistic Web Environment for Building Autonomous Agents, Shuyan Zhou+, ICLR'24</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="unleashing-the-2013" class="title-link">[Paper Note] Unleashing the Reasoning Potential of Pre-trained LLMs by Critique  Fine-Tuning on One Problem, Yubo Wang+, EMNLP'25</h3>
<br><a href="https://arxiv.org/abs/2506.03295" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2013" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-06-05</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、強力な大規模言語モデル（LLM）の推論能力を引き出すために、批評微調整（CFT）が効果的であることを示します。CFTは、単一の問題に対する多様な解を収集し、教師LLMによる批評データを構築する手法です。QwenおよびLlamaモデルを微調整した結果、数学や論理推論のベンチマークで顕著な性能向上を観察しました。特に、わずか5時間のトレーニングで、Qwen-Math-7B-CFTは他の手法と同等以上の成果を上げました。CFTは計算効率が高く、現代のLLMの推論能力を引き出すためのシンプルなアプローチであることが示されました。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1930447298527670662?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1832" target="_blank" rel="noopener noreferrer">Critique Fine-Tuning: Learning to Critique is More Effective than   Learning to Imitate, Yubo Wang+, COLM'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1938" target="_blank" rel="noopener noreferrer">Reinforcement Learning for Reasoning in Large Language Models with One   Training Example, Yiping Wang+, NeurIPS'25</a>
</p>
<p>参考:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/weiliu99/status/1930826904522875309?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="scaling-reasoning-1989" class="title-link">Scaling Reasoning, Losing Control: Evaluating Instruction Following in  Large Reasoning Models, Tingchen Fu+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2505.14810" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1989" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="InstructionFollowingCapability.html" target="_blank" rel="noopener noreferrer">#InstructionFollowingCapability</a>
<span class="issue_date">Issue Date: 2025-05-24</span>
<span class="snippet"><span>GPT Summary</span>- 指示に従う能力はLLMにとって重要であり、MathIFという数学的推論タスク用のベンチマークを提案。推論能力の向上と指示遵守の間には緊張関係があり、特に長い思考の連鎖を持つモデルは指示に従いにくい。介入により部分的な従順さを回復できるが、推論性能が低下することも示された。これらの結果は、指示に敏感な推論モデルの必要性を示唆している。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/yafuly/status/1925753754961236006?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="why-vision-1974" class="title-link">Why Vision Language Models Struggle with Visual Arithmetic? Towards   Enhanced Chart and Geometry Understanding, Kung-Hsiang Huang+, ACL'25</h3>
<br><a href="https://arxiv.org/abs/2502.11492" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1974" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Probing.html" target="_blank" rel="noopener noreferrer">#Probing</a>
<span class="issue_date">Issue Date: 2025-05-18</span>
<span class="snippet"><span>GPT Summary</span>- Vision Language Models (VLMs)は視覚的算術に苦労しているが、CogAlignという新しいポストトレーニング戦略を提案し、VLMの性能を向上させる。CogAlignは視覚的変換の不変特性を認識するように訓練し、CHOCOLATEで4.6%、MATH-VISIONで2.9%の性能向上を実現し、トレーニングデータを60%削減。これにより、基本的な視覚的算術能力の向上と下流タスクへの転送の効果が示された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/steeve__huang/status/1923543884367306763?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>既存のLLM (proprietary, openweightそれぞれ)が、シンプルなvisual arithmeticタスク(e.g., 線分の長さ比較, Chart上のdotの理解)などの性能が低いことを明らかにし、<br><img src="https://github.com/user-attachments/assets/039a48de-67a5-4c81-ba59-174acd508479" alt="image" loading="lazy" width="550" height="400"><br>それらの原因を(1)Vision Encoderのrepresentationと(2)Vision EncoderをFreezeした上でのText Decoderのfinetuningで分析した。その結果、(1)ではいくつかのタスクでlinear layerのprobingでは高い性能が達成できないことがわかった。このことから、Vision Encoderによるrepresentationがタスクに関する情報を内包できていないか、タスクに関する情報は内包しているがlinear layerではそれを十分に可能できない可能性が示唆された。<br><img src="https://github.com/user-attachments/assets/0eb90fa2-7b6a-43b6-81d9-b5f7e6fb3ea8" alt="image" loading="lazy" width="550" height="400"><br><br>これをさらに分析するために(2)を実施したところ、Vision Encoderをfreezeしていてもfinetuningによりquery stringに関わらず高い性能を獲得できることが示された。このことから、Vision Encoder側のrepresentationの問題ではなく、Text Decoderと側でデコードする際にFinetuningしないとうまく活用できないことが判明した。<br><img src="https://github.com/user-attachments/assets/cd122d99-9228-44b1-9827-cdb56f49d492" alt="image" loading="lazy" width="550" height="400"></p>
<p>手法のところはまだ全然しっかり読めていないのだが、画像に関する特定の属性に関するクエリと回答のペアを合成し、DPOすることで、zero-shotの性能が向上する、という感じっぽい？<br><img src="https://github.com/user-attachments/assets/707b1cc9-8bbf-45a5-b564-f654503c836e" alt="image" loading="lazy" width="550" height="400"><br><img src="https://github.com/user-attachments/assets/281da17b-c8c3-455a-aa51-043ed297ae1f" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="when-bad-1940" class="title-link">When Bad Data Leads to Good Models, Kenneth Li+, arXiv'25</h3>
<br><a href="https://arxiv.org/pdf/2505.04741" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1940" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="Toxicity.html" target="_blank" rel="noopener noreferrer">#Toxicity</a>
<a class="button" href="ActivationSteering_ITI.html" target="_blank" rel="noopener noreferrer">#ActivationSteering/ITI</a>
<span class="issue_date">Issue Date: 2025-05-09</span>
<span class="snippet"><span>GPT Summary</span>- 本論文では、LLMの事前学習におけるデータの質の再検討を行い、有害データが事後学習における制御を向上させる可能性を探ります。トイ実験を通じて、有害データの割合が増加することで有害性の概念が線形表現に影響を与えることを発見し、有害データが生成的有害性を増加させつつも除去しやすくなることを示しました。評価結果は、有害データで訓練されたモデルが生成的有害性を低下させつつ一般的な能力を保持する良好なトレードオフを達成することを示唆しています。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ke_li_2021/status/1920646069613957606?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>これは面白そう</p>
<p>Webコーパスなどを事前学習で利用する際は、質の高いデータを残して学習した方が良いとされているが、4chanのようなtoxicなデータを混ぜて事前学習して、後からdetox（Inference Time Intervention <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1941" target="_blank" rel="noopener noreferrer">Inference-Time Intervention: Eliciting Truthful Answers from a Language   Model, Kenneth Li+, NeurIPS'23</a>
 , SFT, DPO)することで、最終的なモデルのtoxicなoutputが減るという話らしい。これはそもそも事前学習時点でtoxicなデータのsignalが除外されることで、モデルがtoxicな内容のrepresentationを学習できず、最終的にtoxicか否かをコントロールできなくなるため、と考察している（っぽい）<br><img src="https://github.com/user-attachments/assets/7f6efd4b-0679-4143-9a7d-1bf3ea5b6f3a" alt="image" loading="lazy" width="550" height="400"><br><img src="https://github.com/user-attachments/assets/0acec11b-d851-4137-b0aa-1ed7172388e1" alt="image" loading="lazy" width="550" height="400"></p>
<p>有害な出力を減らせそうなことは分かったが、Activation Steeringによってどの程度モデルの性能に影響を与えるのかが気になる、と思ったがAppendixに記載があった。細かく書かれていないので推測を含むが、各データに対してToxicデータセットでProbingすることでTopKのheadを決めて、Kの値を調整することでinterventionの強さを調整し、Toxicデータの割合を変化させて評価してみたところ、モデルの性能に大きな影響はなかったということだと思われる（ただし1Bモデルでの実験しかない）<br><br><img src="https://github.com/user-attachments/assets/4c79ca22-6916-438d-ad31-07596c82bfd1" alt="image" loading="lazy" width="550" height="400"><br></p>
<p>おそらく2,3節あたりが一番おもしろいポイントなのだと思われるがまだ読めていない。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="100-days-1925" class="title-link">100 Days After DeepSeek-R1: A Survey on Replication Studies and More  Directions for Reasoning Language Models, Chong Zhang+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2505.00551" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1925" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="PPO%20(ProximalPolicyOptimization).html" target="_blank" rel="noopener noreferrer">#PPO (ProximalPolicyOptimization)</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="Contamination-free.html" target="_blank" rel="noopener noreferrer">#Contamination-free</a>
<a class="button" href="VerifiableRewards.html" target="_blank" rel="noopener noreferrer">#VerifiableRewards</a>
<a class="button" href="CurriculumLearning.html" target="_blank" rel="noopener noreferrer">#CurriculumLearning</a>
<span class="issue_date">Issue Date: 2025-05-06</span>
<span class="snippet"><span>GPT Summary</span>- 最近の推論言語モデル（RLM）の進展を受けて、DeepSeek-R1が注目を集めているが、その実装詳細は完全にはオープンソース化されていない。これにより、多くの再現研究が行われ、DeepSeek-R1のパフォーマンスを再現しようとする試みが続いている。特に、監視付きファインチューニング（SFT）と強化学習（RLVR）の戦略が探求され、貴重な洞察が得られている。本報告では、再現研究の概要を提供し、データ構築やトレーニング手順の詳細を紹介し、今後の研究の促進を目指す。また、RLMを強化するための追加技術や開発上の課題についても考察する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1918898257406709983?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>サーベイのtakeawayが箇条書きされている。</span><br><br>
</article>
<article class="paper-entry">
<h3 id="layer-by-1924" class="title-link">Layer by Layer: Uncovering Hidden Representations in Language Models, Oscar Skean+, ICML'25</h3>
<br><a href="https://arxiv.org/abs/2502.02013" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1924" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RepresentationLearning.html" target="_blank" rel="noopener noreferrer">#RepresentationLearning</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="CompressionValleys.html" target="_blank" rel="noopener noreferrer">#CompressionValleys</a>
<span class="issue_date">Issue Date: 2025-05-04</span>
<span class="snippet"><span>GPT Summary</span>- 中間層の埋め込みが最終層を超えるパフォーマンスを示すことを分析し、情報理論や幾何学に基づくメトリクスを提案。32のテキスト埋め込みタスクで中間層が強力な特徴を提供することを実証し、AIシステムの最適化における中間層の重要性を強調。</span>
<span class="snippet"><span>Comment</span><p>現代の代表的な言語モデルのアーキテクチャ（decoder-only model, encoder-only model, SSM）について、最終層のembeddingよりも中間層のembeddingの方がdownstream task（MTEBの32Taskの平均）に、一貫して（ただし、これはMTEBの平均で見たらそうという話であり、個別のタスクで一貫して強いかは読んでみないとわからない）強いことを示した研究。<br><br>このこと自体は経験的に知られているのであまり驚きではないのだが（ただ、SSMでもそうなのか、というのと、一貫して強いというのは興味深い）、この研究はMatrix Based Entropyと呼ばれるものに基づいて、これらを分析するための様々な指標を定義し理論的な根拠を示し、Autoregressiveな学習よりもMasked Languageによる学習の方がこのようなMiddle Layerのボトルネックが緩和され、同様のボトルネックが画像の場合でも起きることを示し、CoTデータを用いたFinetuningについても分析している模様。この辺の貢献が非常に大きいと思われるのでここを理解することが重要だと思われる。あとで読む。<br><br><img src="https://github.com/user-attachments/assets/bda00c50-c97b-45e0-97a5-d98dd98599fd" alt="image" loading="lazy" width="550" height="400"></p>
<p>openreview:


<a href="https://openreview.net/forum?id=WGXb7UdvTX" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=WGXb7UdvTX</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="safety-alignment-1908" class="title-link">Safety Alignment Should Be Made More Than Just a Few Tokens Deep, Xiangyu Qi+, ICLR'25</h3>
<br><a href="https://arxiv.org/abs/2406.05946" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1908" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-04-29</span>
<span class="snippet"><span>GPT Summary</span>- 現在の大規模言語モデル（LLMs）の安全性アラインメントは脆弱であり、単純な攻撃や善意のファインチューニングによって脱獄される可能性がある。この脆弱性は「浅い安全性アラインメント」に起因し、アラインメントが主に最初の数トークンの出力にのみ適応されることに関連している。本論文では、この問題のケーススタディを提示し、現在のアラインされたLLMsが直面する脆弱性を説明する。また、浅い安全性アラインメントの概念が脆弱性軽減の研究方向を示唆し、初期トークンを超えたアラインメントの深化がロバスト性を向上させる可能性を示す。最後に、ファインチューニング攻撃に対する持続的な安全性アラインメントを実現するための正則化されたファインチューニング目的を提案する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1917006979836612640?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=6Mxhg9PtDE" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=6Mxhg9PtDE</a>


</p>
<p>Safety Alignment手法が最初の数トークンに依存しているからそうならないように学習しますというのは、興味深いテーマだし技術的にまだ困難な点もあっただろうし、インパクトも大きいし、とても良い研究だ…。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="bitnet-b1.58-1898" class="title-link">BitNet b1.58 2B4T Technical Report, Shuming Ma+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2504.12285" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1898" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<span class="issue_date">Issue Date: 2025-04-19</span>
<span class="snippet"><span>GPT Summary</span>- BitNet b1.58 2B4Tは、20億パラメータを持つオープンソースの1ビット大規模言語モデルで、4兆トークンで訓練されました。言語理解や数学的推論などのベンチマークで評価され、同サイズのフルプレシジョンLLMと同等の性能を示しつつ、計算効率が向上しています。メモリ、エネルギー消費、デコーディングレイテンシが削減され、モデルの重みはHugging Faceで公開されています。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1912783876365177235?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>圧倒的省メモリかつcpuでのinference速度も早そう<br><img src="https://github.com/user-attachments/assets/dacf05e4-9cb3-48b4-9a98-532f7245eb8e" alt="image" loading="lazy" width="550" height="400"></p>
<p>- アーキテクチャはTransformerを利用<br>- Linear layerとしてBitLinear Layerを利用<br>  - 重みは{1, 0, -1}の3値をとる<br>  - activationは8bitのintegerに量子化<br>  - Layer Normalizationはsubln normalization <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1899" target="_blank" rel="noopener noreferrer">[Paper Note] Magneto: A Foundation Transformer, Hongyu Wang+, ICML'23</a>
 を利用</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="d1-scaling-1893" class="title-link">d1: Scaling Reasoning in Diffusion Large Language Models via  Reinforcement Learning, Siyan Zhao+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2504.12216" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1893" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="DiffusionModel.html" target="_blank" rel="noopener noreferrer">#DiffusionModel</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-04-18</span>
<span class="snippet"><span>GPT Summary</span>- d1というフレームワークを提案し、マスク付きdLLMsを教師ありファインチューニングと強化学習で推論モデルに適応。マスク付きSFT技術で知識を抽出し、diffu-GRPOという新しいRLアルゴリズムを導入。実証研究により、d1が最先端のdLLMの性能を大幅に向上させることを確認。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1912785180504535121?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>dLLMに対してGRPOを適用する手法(diffuGRPO)を提案している。<br>long CoTデータでSFTしてreasoning capabilityを強化した後、diffuGRPOで追加のpost-trainingをしてさらに性能をboostする。</p>
<p>GRPOではtoken levelの尤度とsequence全体の尤度を計算する必要があるが、dLLMだとautoregressive modelのようにchain ruleを適用する計算方法はできないので、効率的に尤度を推定するestimatorを用いてGPPOを適用するdiffuGRPOを提案している。<br><br>diffuGRPO単体でも、8BモデルだがSFTよりも性能向上に成功している。SFTの後にdiffuGRPOを適用するとさらに性能が向上する。<br><br>SFTではs1 <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1749" target="_blank" rel="noopener noreferrer">s1: Simple test-time scaling, Niklas Muennighoff+, arXiv'25</a>
 で用いられたlong CoTデータを用いている。しっかり理解できていないが、diffuGRPO+verified rewardによって、long CoTの学習データを用いなくても、安定してreasoning能力を発揮することができようになった、ということなのだろうか？<br>しかし、AppendixCを見ると、元々のLLaDAの時点でreasoning traceを十分な長さで出力しているように見える。もしLLaDAが元々long CoTを発揮できたのだとしたら、long CoTできるようになったのはdiffuGRPOだけの恩恵ではないということになりそうだが、LLaDAは元々long CoTを生成できるようなモデルだったんだっけ…？その辺追えてない（dLLMがメジャーになったら追う）。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="a-sober-1887" class="title-link">A Sober Look at Progress in Language Model Reasoning: Pitfalls and Paths   to Reproducibility, Andreas Hochlehnert+, COLM'25</h3>
<br><a href="https://arxiv.org/pdf/2504.07086" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1887" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="In-Depth%20Notes.html" target="_blank" rel="noopener noreferrer">#In-Depth Notes</a>
<span class="issue_date">Issue Date: 2025-04-13</span>
<span class="snippet"><span>GPT Summary</span>- 推論は言語モデルの重要な課題であり、進展が見られるが、評価手法には透明性や堅牢性が欠けている。本研究では、数学的推論ベンチマークが実装の選択に敏感であることを発見し、標準化された評価フレームワークを提案。再評価の結果、強化学習アプローチは改善が少なく、教師ありファインチューニング手法は強い一般化を示した。再現性を高めるために、関連するコードやデータを公開し、今後の研究の基盤を築く。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wenhuchen/status/1911143014258405420?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>SLMをmath reasoning向けにpost-trainingする場合、評価の条件をフェアにするための様々な工夫を施し評価をしなおした結果（Figure1のように性能が変化する様々な要因が存在する）、RL（既存研究で試されているもの）よりも（大規模モデルからrejection samplingしたreasoning traceを用いて）SFTをする方が同等か性能が良く(Table3)、結局のところ（おそらく汎化性能が低いという意味で）reliableではなく、かつ（おそらく小規模なモデルでうまくいかないという意味での）scalableではないので、reliableかつscalableなRL手法が不足しているとのこと。<br><br>※ 本論文で分析されているのは&lt;=10B以下のSLMである点に注意。10B以上のモデルで同じことが言えるかは自明ではない。<br>※ DAPO, VAPOなどについても同じことが言えるかも自明ではない。<br>※ DeepSeek-R1のtechnical reportにおいて、小さいモデルにGRPOを適用してもあまり効果が無かったことが既に報告されている。<br><br><img src="https://github.com/user-attachments/assets/620017f1-b3f0-40c1-bf61-3b0b7a429ab4" alt="image" loading="lazy" width="550" height="400"><br><img src="https://github.com/user-attachments/assets/321132c8-dad5-4aa1-9811-f032e3474135" alt="image" loading="lazy" width="550" height="400"><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1743" target="_blank" rel="noopener noreferrer">DeepSeek-R1の論文読んだ？【勉強になるよ】 , asap, 2025.01</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
</p>
<p>個々のpost-trainingされたRLモデルが具体的にどういう訓練をしたのかは追えていないが、DAPOやDr. GRPO, VAPOの場合はどうなるんだろうか？<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1815" target="_blank" rel="noopener noreferrer">DAPO: An Open-Source LLM Reinforcement Learning System at Scale, Qiying Yu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1876" target="_blank" rel="noopener noreferrer">VAPO: Efficient and Reliable Reinforcement Learning for Advanced
  Reasoning Tasks, YuYue+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1821" target="_blank" rel="noopener noreferrer">[Paper Note] Understanding R1-Zero-Like Training: A Critical Perspective, Zichen Liu+, arXiv'25, 2025.03</a>
<br><br>Rewardの設定の仕方はどのような影響があるのだろうか（verifiable rewardなのか、neuralモデルによるrewardなのかなど)？<br><br>学習のさせ方もどのような影響があるのだろうか（RLでカリキュラムlearningにした場合など）？<br><br>検証しているモデルがそれぞれどのような設定で学習されているかまでを見ないとこの辺はわからなそう。<br><br>ただなんとなーくの直感だと、SLMを賢くしたいという場合は何らかの賢いモデルの恩恵に預かると有利なケースが多く（SFTの場合はそれが大規模なモデルから蒸留したreasoning trace）、SLM+RLの場合はPRMのような思考プロセスを評価してRewardに反映させるようなものを利用しないと、少なくとも小規模なLLMをめちゃ賢くします〜というのはきついんじゃないかなあという感想ではある。<br>ただ、結局SLMという時点で多くの場合、より賢いパラメータ数の多いLLMが世の中には存在するあるはずなので、RLしないでSFTして蒸留すれば良いんじゃない…？と思ってしまう。<br>が、多くの場合その賢いLLMはProprietaryなLLMであり、出力を得て自分のモデルをpost-trainingすることは利用規約違反となるため、自前で賢くてパラメータ数の多いLLMを用意できない場合は困ってしまうので、SLMをクソデカパラメータのモデルの恩恵なしで超絶賢くできたら世の中の多くの人は嬉しいよね、とも思う。</p>
<p>（斜め読みだが）<br>サンプル数が少ない（数十件）AIMEやAMCなどのデータはseedの値にとてもsensitiveであり(Takeaway1, 2)、<br><br><img src="https://github.com/user-attachments/assets/97581133-cf17-4635-b66c-442eaf8956d4" alt="image" loading="lazy" width="550" height="400"><br><br>それらは10種類のseedを用いて結果を平均すると分散が非常に小さくなるので、seedは複数種類利用して平均の性能を見た方がreliableであり(Takeaway3)<br><br><img src="https://github.com/user-attachments/assets/5065ef0e-de89-4b17-aa52-c90b7191e9b2" alt="image" loading="lazy" width="550" height="400"><br><br>temperatureを高くするとピーク性能が上がるが分散も上がるため再現性の課題が増大するが、top-pを大きくすると再現性の問題は現れず性能向上に寄与し<br><br><img src="https://github.com/user-attachments/assets/76d5c989-edbb-4d70-9080-d1d4b01de2ff" alt="image" loading="lazy" width="550" height="400"><br><br>既存研究のモデルのtemperatureとtop-pを変化させ実験するとperformanceに非常に大きな変化が出るため、モデルごとに最適な値を選定して比較をしないとunfairであることを指摘 (Takeaway4)。<br><br><img src="https://github.com/user-attachments/assets/d8b453d1-3d2e-4a80-b03d-c69ec1b2232e" alt="image" loading="lazy" width="550" height="400"><br><br>また、ハードウェアの面では、vLLMのようなinference engineはGPU typeやmemoryのconfigurationに対してsensitiveでパフォーマンスが変わるだけでなく、<br><br><img src="https://github.com/user-attachments/assets/a41891c7-072c-4c38-9ad6-beada4721bac" alt="image" loading="lazy" width="550" height="400"><br><br>評価に利用するフレームワークごとにinference engineとprompt templateが異なるためこちらもパフォーマンスに影響が出るし (Takeaway5)、<br><br><img src="https://github.com/user-attachments/assets/1f7d328c-0757-47b9-9961-630e2429fb3e" alt="image" loading="lazy" width="550" height="400"><br><br>max output tokenの値を変化させると性能も変わり、prompt templateを利用しないと性能が劇的に低下する (Takeaway6)。<br><br><img src="https://github.com/user-attachments/assets/dc0902d1-a5f2-47de-8df1-c28107e1da28" alt="image" loading="lazy" width="550" height="400"><br><br>これらのことから著者らはreliableな評価のために下記を提案しており (4.1節; 後ほど追記)、<br><br>実際にさまざまな条件をfair comparisonとなるように標準化して評価したところ（4.2節; 後ほど追記）<br><br>上の表のような結果となった。この結果は、<br>- DeepSeekR1-DistilledをRLしてもSFTと比較したときに意味のあるほどのパフォーマンスの向上はないことから、スケーラブル、かつ信頼性のあるRL手法がまだ不足しており<br>- 大規模なパラメータのモデルのreasoning traceからSFTをする方法はさまざまなベンチマークでロバストな性能（＝高い汎化性能）を持ち、RLと比べると現状はRLと比較してよりパラダイムとして成熟しており<br>- （AIME24,25を比較するとSFTと比べてRLの場合performanceの低下が著しいので）RLはoverfittingしやすく、OODなベンチマークが必要</p>
<p>しっかりと評価の枠組みを標準化してfair comparisonしていかないと、RecSys業界の二の舞になりそう（というかもうなってる？）。<br><br>またこの研究で分析されているのは小規模なモデル（&lt;=10B）に対する既存研究で用いられた一部のRL手法や設定の性能だけ（真に示したかったらPhisics of LLMのような完全にコントロール可能なサンドボックスで実験する必要があると思われる）なので、DeepSeek-R1のように、大規模なパラメータ（数百B）を持つモデルに対するRLに関して同じことが言えるかは自明ではない点に注意。</p>
<p>openreview:


<a href="https://openreview.net/forum?id=90UrTTxp5O#discussion" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=90UrTTxp5O#discussion</a>


</p>
<p>最近の以下のようなSFTはRLの一つのケースと見做せるという議論を踏まえるとどうなるだろうか<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2382" target="_blank" rel="noopener noreferrer">[Paper Note] On the Generalization of SFT: A Reinforcement Learning Perspective with
  Reward Rectification, Yongliang Wu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2700" target="_blank" rel="noopener noreferrer">[Paper Note] Towards a Unified View of Large Language Model Post-Training, Xingtai Lv+, arXiv'25</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="overtrained-language-1837" class="title-link">Overtrained Language Models Are Harder to Fine-Tune, Jacob Mitchell Springer+, ICLR'25</h3>
<br><a href="https://arxiv.org/abs/2503.19206" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1837" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2025-03-27</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデルの事前学習において、トークン予算の増加がファインチューニングを難しくし、パフォーマンス低下を引き起こす「壊滅的な過学習」を提唱。3Tトークンで事前学習されたOLMo-1Bモデルは、2.3Tトークンのモデルに比べて2%以上の性能低下を示す。実験と理論分析により、事前学習パラメータの感度の増加が原因であることを示し、事前学習設計の再評価を促す。</span>
<span class="snippet"><span>Comment</span><p>著者によるポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacspringer/status/1904960783341023521?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>事前学習のトークン数を増やすとモデルのsensitivityが増し、post-trainingでのパフォーマンスの劣化が起こることを報告している。事前学習で学習するトークン数を増やせば、必ずしもpost-training後のモデルの性能がよくなるわけではないらしい。<br><img src="https://github.com/user-attachments/assets/ba60ae24-f3e5-4956-b29f-37b4fe01a9d1" alt="image" loading="lazy" width="550" height="400"></p>
<p>ICLR'25のOutstanding Paperに選ばれた模様:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jacspringer/status/1917174452531724718?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>きちんと読んだ方が良さげ。</span><br><br>
</article>
<article class="paper-entry">
<h3 id="critique-fine-tuning-1832" class="title-link">Critique Fine-Tuning: Learning to Critique is More Effective than   Learning to Imitate, Yubo Wang+, COLM'25</h3>
<br><a href="https://arxiv.org/abs/2501.17703" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1832" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-03-25</span>
<span class="snippet"><span>GPT Summary</span>- 批評ファインチューニング（CFT）は、言語モデルがノイズのある応答を批評することを学ぶ新しい戦略で、従来の監視付きファインチューニング（SFT）に挑戦します。CFTは人間の学習プロセスにインスパイアを受け、深い分析を促進します。WebInstructから構築した50Kサンプルのデータセットを用いて、CFTは複数のベースモデルでSFTに対して4-10%の性能向上を示しました。特に、Qwen2.5-Math-CFTは少ないトレーニングで強力な競合と同等の性能を発揮し、CFTの堅牢性も確認されました。CFTは言語モデルの推論を進展させる効果的な手法であると主張します。</span>
<span class="snippet"><span>Comment</span><p>元ポスト: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/WenhuChen/status/1885060597500567562"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>Critique Fine-Tuning (CFT) を提案。CFTでは、query x, noisy response y [^1] が与えられたときに、それに対する批評 cを学習する。cはgivenではないので、GPT4oのような強力なモデルによって合成する。<br><br>![Image](https://github.com/user-attachments/assets/f25babdd-63d6-4d3d-a9b0-3217db2bd07f)<br><br>目的関数は以下。[x; y] がgivenな時にcを生成する確率を最大化する。シンプル。<br>![Image](https://github.com/user-attachments/assets/ccdb8e42-e8b2-4ae1-99a6-a0b7c1d4bf2a)<br><br>RLを用いた手法との比較。1/10程度のデータ量、1/100程度のGPU時間で同等の性能を達成できる。<br>![Image](https://github.com/user-attachments/assets/848376ff-9965-485b-b8a0-7960d1d0e7b9)<br><br>[^1]: 本論文で利用しているWebInstructからサンプリングしたデータでは、たとえば約50%程度のyが正解,  残りは不正解（程度のnoisyデータを利用している）</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-first-1813" class="title-link">The First Few Tokens Are All You Need: An Efficient and Effective  Unsupervised Prefix Fine-Tuning Method for Reasoning Models, Ke Ji+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2503.02875" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1813" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2025-03-19</span>
<span class="snippet"><span>GPT Summary</span>- 非教師ありプレフィックスファインチューニング（UPFT）を提案し、LLMの推論効率を向上。初期のプレフィックス部分文字列に基づいて訓練し、ラベル付きデータやサンプリングを不要に。UPFTは、教師あり手法と同等の性能を維持しつつ、訓練時間を75%、サンプリングコストを99%削減。最小限の非教師ありファインチューニングで大幅な推論向上を実現し、リソース効率の良い代替手段を提供。</span>
<span class="snippet"><span>Comment</span><p>斜め読みだが、reasoning traceの冒頭部分は重要な役割を果たしており、サンプリングした多くのresponseのreasoning traceにおいて共通しているものは重要という直感から（Prefix Self-Consistency）、reasoning traceの冒頭部分を適切に生成できるようにモデルをFinetuningする。従来のRejection Samplingを用いた手法では、複数のresponseを生成させて、最終的なanswerが正解のものをサンプリングするため正解ラベルが必要となるが、提案手法ではreasoning traceの冒頭部分の共通するsubsequenceをmajority voteするだけなのでラベルが不要である。<br><img src="https://github.com/user-attachments/assets/ff3938da-dcd0-4b6c-a764-26d2e8caa63a" alt="image" loading="lazy" width="550" height="400"><br><br>reasoning prefixを学習する際は下記のようなテンプレートを用いる。このときに、prefixのspanのみを利用して学習することで大幅に学習時間を削減できる。<br><img src="https://github.com/user-attachments/assets/63aabe47-9c40-41cb-8d5a-5039900f6edc" alt="image" loading="lazy" width="550" height="400"><br><br>また、そのような学習を行うとcatastrophic forgettingのリスクが非常に高いが、これを防ぐために、マルチタスクラーニングを実施する。具体的には学習データのp%については全体のreasoning traceを生成して学習に利用する。このときに、最終的な回答の正誤を気にせずtraceを生成して学習に利用することで、ラベルフリーな特性を維持できる（つまり、こちらのデータは良いreasoning traceを学習することを目的としているわけではなく、あくまでcatastrophic forgettingを防ぐためにベースモデルのようなtraceもきちんと生成できれば良い、という感覚だと思われる）。<br><img src="https://github.com/user-attachments/assets/6e83c686-5bcf-4db8-9b8a-63c39570a4dc" alt="image" loading="lazy" width="550" height="400"><br><br>AppendixにQwenを用いてtemperature 0.7で16個のresponseをサンプリングし、traceの冒頭部分が共通している様子が示されている。</p>
<p>下記論文でlong-CoTを学習させる際のlong-CoTデータとして、reasoningモデルから生成したtraceと非reasoning modelから生成したtraceによるlong-CoTデータを比較したところ前者の方が一貫して学習性能が良かったとあるが、この研究でもreasoning traceをつよつよモデルで生成したら性能上がるんだろうか。<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">[Paper Note] Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="all-roads-1806" class="title-link">All Roads Lead to Likelihood: The Value of Reinforcement Learning in  Fine-Tuning, Gokul Swamy+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2503.01067" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1806" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<span class="issue_date">Issue Date: 2025-03-17</span>
<span class="snippet"><span>GPT Summary</span>- 基盤モデルのファインチューニングにおいて、報酬モデルを用いた二段階のトレーニング手順が効果的である理由を理論的および実証的に検討。特に、好みデータから単純な報酬モデルを学び、強化学習手続きがそのモデルに最適なポリシーをフィルタリングする能力が、オンラインファインチューニングの優れたパフォーマンスに寄与することが示された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1901392286694678568?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>AlignmentのためのPreferenceデータがある時に、そのデータから直接最尤推定してモデルのパラメータを学習するのではなく、報酬モデルを学習して、その報酬モデルを用いてモデルを強化学習することで、なぜ前者よりも（同じデータ由来であるにもかかわらず）優れたパフォーマンスを示すのか、という疑問に対してアプローチしている。</p>
<p>全く中身を読めていないが、生成することと（方策モデル）と検証すること（報酬モデル）の間にギャップがある場合（すなわち、生成と検証で求められる能力が異なる場合）、MLEでは可能なすべてのポリシーを探索することと似たようなことをすることになるが、RLでは事前に報酬モデルを学習しその報酬モデルに対して最適なポリシーを探索するだけなので探索する空間が制限される（＝生成と検証のギャップが埋まる）ので、良い解に収束しやすくなる、というイメージなんだろうか。<br><img src="https://github.com/user-attachments/assets/121e97a6-120e-4830-9bcf-329129a687eb" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="a-survey-1798" class="title-link">A Survey on Post-training of Large Language Models, Guiyao Tie+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2503.06072" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1798" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-15</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLMs）は自然言語処理に革命をもたらしたが、専門的な文脈での制約が明らかである。これに対処するため、高度なポストトレーニング言語モデル（PoLMs）が必要であり、本論文ではその包括的な調査を行う。ファインチューニング、アライメント、推論、効率、統合と適応の5つのコアパラダイムにわたる進化を追跡し、PoLMがバイアス軽減や推論能力向上に寄与する方法を示す。研究はPoLMの進化に関する初の調査であり、将来の研究のための枠組みを提供し、LLMの精度と倫理的堅牢性を向上させることを目指す。</span>
<span class="snippet"><span>Comment</span><p>Post Trainingの時間発展の図解が非常にわかりやすい（が、厳密性には欠けているように見える。当該モデルの新規性における主要な技術はこれです、という図としてみるには良いのかもしれない）。<br>個々の技術が扱うスコープとレイヤー、データの性質が揃っていない気がするし、それぞれのLLMがy軸の単一の技術だけに依存しているわけでもない。が、厳密に図を書いてと言われた時にどう書けば良いかと問われると難しい感はある。<br><img src="https://github.com/user-attachments/assets/6cdf060f-1cc9-44cd-b81a-50f4d3c442de" alt="image" loading="lazy" width="550" height="400"></p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1900595286898340230?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="start-self-taught-1787" class="title-link">START: Self-taught Reasoner with Tools, Chengpeng Li+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2503.04625" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1787" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<span class="issue_date">Issue Date: 2025-03-07</span>
<span class="snippet"><span>GPT Summary</span>- 新しいツール統合型の長Chain-of-thought推論モデルSTARTを提案。STARTは外部ツールを活用し、自己学習フレームワークを通じて推論能力を向上。Hint-inferとHint Rejection Sampling Fine-Tuningを用いてLRMをファインチューニングし、科学QAや数学、コードベンチマークで高精度を達成。ベースモデルを大幅に上回り、最先端モデルに匹敵する性能を示す。</span>
<span class="snippet"><span>Comment</span><p>論文の本題とは関係ないが、QwQ-32Bよりも、DeepSeek-R1-Distilled-Qwen32Bの方が性能が良いのは興味深い。やはり大きいパラメータから蒸留したモデルの方が、小さいパラメータに追加学習したモデルよりも性能が高い傾向にあるのだろうか（どういうデータで蒸留したかにもよるけど）。<br><img src="https://github.com/user-attachments/assets/53e77e67-2c46-4163-859b-ccb0a7cd631d" alt="image" loading="lazy" width="550" height="400"></p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=m80LCW765n" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=m80LCW765n</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="llm-post-training-1782" class="title-link">LLM Post-Training: A Deep Dive into Reasoning Large Language Models, Komal Kumar+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2502.21321" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1782" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Survey.html" target="_blank" rel="noopener noreferrer">#Survey</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-03-04</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLMs）のポストトレーニング手法に焦点を当て、知識の洗練や推論の改善、事実の正確性向上を目指す。ファインチューニングや強化学習などの戦略がLLMsのパフォーマンスを最適化し、実世界のタスクへの適応性を向上させる。主要な課題として壊滅的な忘却や報酬ハッキングを分析し、今後の研究方向性を示す公開リポジトリも提供。</span>
<span class="snippet"><span>Comment</span><p>非常にわかりやすい。<br><img src="https://github.com/user-attachments/assets/855326f0-bc18-4ce1-9870-7690393af21e" alt="image" loading="lazy" width="550" height="400"></p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1896399195596263710?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="scaling-test-time-1767" class="title-link">Scaling Test-Time Compute Without Verification or RL is Suboptimal, Amrith Setlur+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2502.12118" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1767" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<span class="issue_date">Issue Date: 2025-02-18</span>
<span class="snippet"><span>GPT Summary</span>- RLや探索に基づく検証者ベース（VB）手法が、探索の痕跡を蒸留する検証者フリー（VF）アプローチよりも優れていることを示す。テスト時の計算とトレーニングデータをスケールアップすると、VF手法の最適性が悪化し、VB手法がより良くスケールすることが確認された。3/8/32BサイズのLLMを用いた実験で、検証が計算能力の向上に重要であることを実証。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/iscienceluvr/status/1891839822257586310?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1749" target="_blank" rel="noopener noreferrer">s1: Simple test-time scaling, Niklas Muennighoff+, arXiv'25</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="deeprag-thinking-1758" class="title-link">DeepRAG: Thinking to Retrieval Step by Step for Large Language Models, Xinyan Guan+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2502.01142" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1758" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2025-02-12</span>
<span class="snippet"><span>GPT Summary</span>- DeepRAGフレームワークを提案し、検索強化推論をマルコフ決定過程としてモデル化。クエリを反復的に分解し、外部知識の取得とパラメトリック推論の依存を動的に判断。実験により、検索効率と回答の正確性を21.99%向上させることを実証。</span>
<span class="snippet"><span>Comment</span><p>日本語解説。ありがとうございます！<br><br>RAGでも「深い検索」を実現する手法「DeepRAG」, Atsushi Kadowaki, <br>ナレッジセンス - AI知見共有ブログ:


<a href="https://zenn.dev/knowledgesense/articles/034b613c9fd6d3" target="_blank" rel="noopener noreferrer">https://zenn.dev/knowledgesense/articles/034b613c9fd6d3</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="s1-simple-1749" class="title-link">s1: Simple test-time scaling, Niklas Muennighoff+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2501.19393" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1749" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Test-Time%20Scaling.html" target="_blank" rel="noopener noreferrer">#Test-Time Scaling</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-02-07</span>
<span class="snippet"><span>GPT Summary</span>- テスト時スケーリングを用いて言語モデルのパフォーマンスを向上させる新しいアプローチを提案。小規模データセットs1Kを作成し、モデルの思考プロセスを制御する予算強制を導入。これにより、モデルは不正確な推論を修正し、Qwen2.5-32B-Instructモデルがo1-previewを最大27%上回る結果を達成。さらに、介入なしでパフォーマンスを向上させることが可能となった。モデル、データ、コードはオープンソースで提供。</span>
<span class="snippet"><span>Comment</span><p>解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1887260791981941121?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="limo-less-1748" class="title-link">LIMO: Less is More for Reasoning, Yixin Ye+, arXiv'25</h3>
<br><a href="https://arxiv.org/abs/2502.03387" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1748" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="DataDistillation.html" target="_blank" rel="noopener noreferrer">#DataDistillation</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-02-07</span>
<span class="snippet"><span>GPT Summary</span>- LIMOモデルは、わずか817のトレーニングサンプルで複雑な数学的推論を効果的に引き出し、AIMEで57.1%、MATHで94.8%の精度を達成。従来のモデルよりも少ないデータで優れたパフォーマンスを示し、一般化を促す「Less-Is-More Reasoning Hypothesis」を提案。LIMOはオープンソースとして提供され、データ効率の良い推論の再現性を促進する。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/arankomatsuzaki/status/1887353699644940456?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="demystifying-long-1746" class="title-link">[Paper Note] Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</h3>
<br><a href="https://arxiv.org/pdf/2502.03373" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="RewardHacking.html" target="_blank" rel="noopener noreferrer">#RewardHacking</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-02-07</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、大規模言語モデル（LLMs）における長い思考の連鎖（CoTs）推論のメカニズムを調査し、重要な要因を特定。主な発見は、(1) 教師ありファインチューニング（SFT）は必須ではないが効率を向上させる、(2) 推論能力は計算の増加に伴い現れるが、報酬の形状がCoTの長さに影響、(3) 検証可能な報酬信号のスケーリングが重要で、特に分布外タスクに効果的、(4) エラー修正能力は基本モデルに存在するが、RLを通じて効果的に奨励するには多くの計算が必要。これらの洞察は、LLMsの長いCoT推論を強化するためのトレーニング戦略の最適化に役立つ。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/xiangyue96/status/1887332772198371514?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>元ポストのスレッド中に論文の11個の知見が述べられている。どれも非常に興味深い。DeepSeek-R1のテクニカルペーパーと同様、<br><br>- Long CoTとShort CoTを比較すると前者の方が到達可能な性能のupper bonudが高いことや、<br>- SFTを実施してからRLをすると性能が向上することや、<br>- RLの際にCoTのLengthに関する報酬を入れることでCoTの長さを抑えつつ性能向上できること、<br>- 数学だけでなくQAペアなどのノイジーだが検証可能なデータをVerifiableな報酬として加えると一般的なreasoningタスクで数学よりもさらに性能が向上すること、<br>- より長いcontext window sizeを活用可能なモデルの訓練にはより多くの学習データが必要なこと、<br>- long CoTはRLによって学習データに類似したデータが含まれているためベースモデルの段階でその能力が獲得されていることが示唆されること、<br>- aha momentはすでにベースモデル時点で獲得されておりVerifiableな報酬によるRLによって強化されたわけではなさそう、<br><br>など、興味深い知見が盛りだくさん。非常に興味深い研究。あとで読む。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="sft-memorizes-1740" class="title-link">SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model   Post-training, Tianzhe Chu+, ICML'25</h3>
<br><a href="https://arxiv.org/abs/2501.17161" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1740" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-01-30</span>
<span class="snippet"><span>GPT Summary</span>- SFTとRLの一般化能力の違いを研究し、GeneralPointsとV-IRLを用いて評価。RLはルールベースのテキストと視覚変種に対して優れた一般化を示す一方、SFTは訓練データを記憶し分布外シナリオに苦労。RLは視覚認識能力を向上させるが、SFTはRL訓練に不可欠であり、出力形式を安定させることで性能向上を促進。これらの結果は、複雑なマルチモーダルタスクにおけるRLの一般化能力を示す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1884731381517082668?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>openreview:


<a href="https://openreview.net/forum?id=dYur3yabMj&referrer=%5Bthe%20profile%20of%20Yi%20Ma%5D(%2Fprofile%3Fid%3D~Yi_Ma4)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=dYur3yabMj&referrer=%5Bthe%20profile%20of%20Yi%20Ma%5D(%2Fprofile%3Fid%3D~Yi_Ma4)</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="mulberry-empowering-1630" class="title-link">Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via   Collective Monte Carlo Tree Search, Huanjin Yao+, NeurIPS'25</h3>
<br><a href="https://arxiv.org/abs/2412.18319" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1630" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="TreeSearch.html" target="_blank" rel="noopener noreferrer">#TreeSearch</a>
<span class="issue_date">Issue Date: 2024-12-31</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、MLLMを用いて質問解決のための推論ステップを学習する新手法CoMCTSを提案。集団学習を活用し、複数モデルの知識で効果的な推論経路を探索。マルチモーダルデータセットMulberry-260kを構築し、モデルMulberryを訓練。実験により提案手法の優位性を確認。</span>
</article>
<article class="paper-entry">
<h3 id="towards-adaptive-1577" class="title-link">Towards Adaptive Mechanism Activation in Language Agent, Ziyang Huang+, COLING'25</h3>
<br><a href="https://arxiv.org/abs/2412.00722" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1577" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="COLING.html" target="_blank" rel="noopener noreferrer">#COLING</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-12-10</span>
<span class="snippet"><span>GPT Summary</span>- 自己探索によるメカニズム活性化学習（ALAMA）を提案し、固定されたメカニズムに依存せずに適応的なタスク解決を目指す。調和のとれたエージェントフレームワーク（UniAct）を構築し、タスク特性に応じてメカニズムを自動活性化。実験結果は、動的で文脈に敏感なメカニズム活性化の有効性を示す。</span>
<span class="snippet"><span>Comment</span><p>元ポスト: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1863956776623747433?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>手法としては、SFTとKTOを活用しpost trainingするようである<br><img src="https://github.com/user-attachments/assets/0eab8029-124d-4ac1-b906-2463472b90b2" alt="image" loading="lazy" width="550" height="400"><br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1472" target="_blank" rel="noopener noreferrer">KTO: Model Alignment as Prospect Theoretic Optimization, Kawin Ethayarajh+, N/A, ICML'24</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="self-consistency-preference-1489" class="title-link">Self-Consistency Preference Optimization, Archiki Prasad+, ICML'25</h3>
<br><a href="http://arxiv.org/abs/2411.04109" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1489" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<span class="issue_date">Issue Date: 2024-11-07</span>
<span class="snippet"><span>GPT Summary</span>- 自己調整は、モデルが人間の注釈なしに自らを改善する方法であり、自己一貫性を活用して訓練を行う新しいアプローチ、自己一貫性優先最適化（ScPO）を提案。ScPOは一貫した答えを優先し、GSM8KやMATHなどの推論タスクで従来の手法を大幅に上回る性能を示し、標準的な監視学習との組み合わせでも結果が向上。ZebraLogicでLlama-3 8Bを微調整し、他の大規模モデルを超える成果を達成。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1854532624116547710?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>Self-Consistencyのように、モデルに複数の出力をさせて、最も頻度が高い回答と頻度が低い回答の2つでDPOのペアデータを作成し学習。頻度の差によって重みを決めてlossに組み込みこのよつな処理を繰り返し学習すると性能が向上する、といった話のように見える。<br><img src="https://github.com/user-attachments/assets/040ffe7c-6e89-4b58-85dd-ce1bc78195cb" alt="image" loading="lazy" width="550" height="400"><br><br><img src="https://github.com/user-attachments/assets/45bbb1e6-145c-4c49-943d-4dfa25812264" alt="image" loading="lazy" width="550" height="400"><br><br><img src="https://github.com/user-attachments/assets/35905525-b03f-4fe3-a0e6-89a89cf4ed29" alt="image" loading="lazy" width="550" height="400"><br><br><img src="https://github.com/user-attachments/assets/45e87ec6-1ebb-4aa8-80ae-0f9072e670d9" alt="image" loading="lazy" width="550" height="400"><br><br></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="fine-tuning-aligned-3424" class="title-link">[Paper Note] Fine-tuning Aligned Language Models Compromises Safety, Even When Users  Do Not Intend To, Xiangyu Qi+, ICLR'24, 2023.10</h3>
<br><a href="https://arxiv.org/abs/2310.03693" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3424" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-24</span>
<span class="snippet"><span>GPT Summary</span>- LLMのファインチューニングは、下流のユースケースに最適化する手法だが、安全性のリスクが伴う。特に、敵対的なトレーニング例を用いたファインチューニングが、モデルの安全性調整を損なう可能性があることが示された。例えば、わずか10例の悪意のある例でGPT-3.5 Turboをファインチューニングすると、安全ガードレールが突破される。また、無害なデータセットでのファインチューニングも意図せず安全性を劣化させる可能性がある。これらの結果は、調整されたLLMのファインチューニングが新たな安全リスクを生むことを示唆しており、今後の安全プロトコルの強化が求められる。</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=hTEGyKf0dZ" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=hTEGyKf0dZ</a>


</p>
<p>なんらかのデータでpost-trainingしたモデルを、ユーザが利用可能な形でデプロイするような場合には、本研究が提唱するようなjailbreakのリスク<br>- 有害データが10例混入するだけで有害な出力をするようになる<br>- 暗黙的な有害データの混入（e.g., あなたはユーザ命令に従うエージェントです）<br>- 無害なデータでpost-trainingするだけでも下記のような影響でsafety alignmentが悪化する<br>  - catastrophic forgetting<br>  - 有用性と無害性のトレードオフによって、有用性を高めたことで有害性が結果的に増えてしまう（ `tension between the helpfulness and harmlessness objectives` <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2902" target="_blank" rel="noopener noreferrer">[Paper Note] Training a Helpful and Harmless Assistant with Reinforcement Learning
  from Human Feedback, Yuntao Bai+, arXiv'22</a>
 ）<br><br>があることを認識しておく必要がある。</p>
<p>もし安直にユーザからの指示追従能力を高めたいなあ・・・と思い、「ユーザからの指示には忠実に従ってください」などの指示を追加してpost-trainingをしてしまい、無害なプロンプトのみでテストして問題ないと思いユーザ向けのchatbotとしてデプロイしました、みたいなことをしたらえらいことになりそう。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="let-the-2368" class="title-link">[Paper Note] Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for   Sparse Architectural Large Language Models, Zihan Wang+, EMNLP'24</h3>
<br><a href="https://arxiv.org/abs/2407.01906" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2368" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-08-06</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、Mixture-of-Experts（MoE）アーキテクチャを持つ大規模言語モデル（LLMs）に対するパラメータ効率の良いファインチューニング（PEFT）手法を提案。主な内容は、(1) タスクごとの専門家の活性化分布の集中度の調査、(2) Expert-Specialized Fine-Tuning（ESFT）の提案とその効果、(3) MoEアーキテクチャの専門家特化型ファインチューニングへの影響の分析。実験により、ESFTがチューニング効率を向上させ、フルパラメータファインチューニングに匹敵またはそれを上回る性能を示すことが確認された。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/wzihanw/status/1952965138845450413?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>MoEアーキテクチャを持つLLMにおいて、finetuningを実施したいタスクに関連する専門家を特定し、そのほかのパラメータをfreezeした上で当該専門家のみをtrainableとすることで、効率的にfinetuningを実施する手法<br><img src="https://github.com/user-attachments/assets/ba82f425-5b61-4ce7-803b-4eb3fb375c41" alt="image" loading="lazy" width="550" height="400"><br><br>専門家を見つける際には専門家ごとにfinetuningしたいタスクに対するrelevance scoreを計算する。そのために、2つの手法が提案されており、training dataからデータをサンプリングし<br>- 全てのサンプリングしたデータの各トークンごとのMoE Routerのgateの値の平均値をrelevant scoreとする方法<br>- 全てのサンプリングしたデータの各トークンごとに選択された専門家の割合<br>の2種類でスコアを求める。閾値pを決定し、閾値以上のスコアを持つ専門家をtrainableとする。<br><br>LoRAよりもmath, codeなどの他ドメインのタスク性能を劣化させず、Finetuning対象のタスクでFFTと同等の性能を達成。<br><img src="https://github.com/user-attachments/assets/302eebda-bace-4b99-bb73-5e7e3ce10448" alt="image" loading="lazy" width="550" height="400"><br><br>LoRAと同様にFFTと比較し学習時間は短縮され、学習した専門家の重みを保持するだけで良いのでストレージも節約できる。<br><img src="https://github.com/user-attachments/assets/b02a8d53-6967-4dd2-9290-de06f27e48c9" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="spectrum-targeted-1724" class="title-link">Spectrum: Targeted Training on Signal to Noise Ratio, Eric Hartford+, arXiv'24</h3>
<br><a href="https://arxiv.org/abs/2406.06623" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1724" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<span class="snippet"><span>GPT Summary</span>- 「Spectrum」という手法を提案し、SNRに基づいてレイヤーモジュールを選択的にターゲットにすることで、LLMのトレーニングを加速。これによりGPUメモリ使用量を削減しつつ、フルファインチューニングに匹敵する性能を実現。実験により、既存手法QLoRAと比較してモデルの品質とVRAM効率の向上が確認された。</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1723" target="_blank" rel="noopener noreferrer">How to fine-tune open LLMs in 2025 with Hugging Face, PHILSCHMID, 2024.12</a>
<br><br>によるとLLMのうち最もinformativeなLayerを見つけ、選択的に学習することで、省リソースで、Full-Parameter tuningと同等の性能を発揮する手法らしい<br><br></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="forgetting-before-1710" class="title-link">Forgetting before Learning: Utilizing Parametric Arithmetic for   Knowledge Updating in Large Language Models, Shiwen Ni+, ACL'24</h3>
<br><a href="https://arxiv.org/abs/2311.08011" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1710" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="KnowledgeEditing.html" target="_blank" rel="noopener noreferrer">#KnowledgeEditing</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<span class="snippet"><span>GPT Summary</span>- F-Learningという新しいファインチューニング手法を提案し、古い知識を忘却し新しい知識を学習するためにパラメトリック算術を利用。実験により、F-LearningがフルファインチューニングとLoRAファインチューニングの知識更新性能を向上させ、既存のベースラインを上回ることを示した。LoRAのパラメータを引き算することで古い知識を忘却する効果も確認。</span>
<span class="snippet"><span>Comment</span><p>Finetuningによって知識をアップデートしたい状況において、ベースモデルでアップデート前の該当知識を忘却してから、新しい知識を学習することで、より効果的に知識のアップデートが可能なことを示している。<br><br>古い知識のデータセットをK_old、古い知識から更新された新しい知識のデータセットをK_newとしたときに、K_oldでベースモデルを{Full-finetuning, LoRA}することで得たパラメータθ_oldを、ベースモデルのパラメータθから（古い知識を忘却することを期待して）減算し、パラメータθ'を持つ新たなベースモデルを得る。その後、パラメータθ'を持つベースモデルをk_newでFull-Finetuningすることで、新たな知識を学習させる。ただし、このような操作は、K_oldがベースモデルで学習済みである前提であることに注意する。学習済みでない場合はそもそも事前の忘却の必要がないし、減算によってベースモデルのコアとなる能力が破壊される危険がある。<br><br><img src="https://github.com/user-attachments/assets/22c126e3-425d-4392-80ee-df319d217fd4" alt="image" loading="lazy" width="550" height="400"><br><br>結果は下記で、先行研究よりも高い性能を示している。注意点として、ベースモデルから忘却をさせる際に、Full Finetuningによってθ_oldを取得すると、ベースモデルのコアとなる能力が破壊されるケースがあるようである。一方、LoRAの場合はパラメータに対する影響が小さいため、このような破壊的な操作となりづらいようである。<br><img src="https://github.com/user-attachments/assets/dfa12efc-c511-42bf-a1ab-0ef4a7749852" alt="image" loading="lazy" width="550" height="400"></p>
<p>評価で利用されたデータセット:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2556" target="_blank" rel="noopener noreferrer">[Paper Note] Zero-Shot Relation Extraction via Reading Comprehension, Omer Levy+, CoNLL'17</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2557" target="_blank" rel="noopener noreferrer">[Paper Note] Locating and Editing Factual Associations in GPT, Kevin Meng+, NeurIPS'22</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="grounding-language-1671" class="title-link">Grounding Language Model with Chunking-Free In-Context Retrieval, Hongjin Qian+, arXiv'24</h3>
<br><a href="https://arxiv.org/abs/2402.09760" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1671" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Embeddings.html" target="_blank" rel="noopener noreferrer">#Embeddings</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-01-06</span>
<span class="snippet"><span>GPT Summary</span>- CFICは、Retrieval-Augmented Generation（RAG）システム向けの新しいリトリーバルアプローチで、従来のチャンク化を回避し、文書のエンコードされた隠れ状態を利用して正確な証拠テキストを特定します。制約付き文のプレフィックスデコーディングとスキップデコーディングを組み込むことで、リトリーバルの効率と生成された証拠の忠実性を向上させます。CFICはオープンQAデータセットで評価され、従来の方法に対して大幅な改善を示し、RAGシステムの効率的で効果的なリトリーバルソリューションを提供します。</span>
<span class="snippet"><span>Comment</span><p>Chunking無しでRAGを動作させられるのは非常に魅力的。<br><img src="https://github.com/user-attachments/assets/8841930a-3099-46c8-aae7-50f52473fbb1" alt="image" loading="lazy" width="550" height="400"></p>
<p>一貫してかなり性能が向上しているように見える<br><img src="https://github.com/user-attachments/assets/6eae7811-090a-4f84-aa8d-6d74a55e8427" alt="image" loading="lazy" width="550" height="400"></p>
<p>提案手法の概要。InputとOutput全体の実例がほとんど掲載されていないので憶測を含みます。<br><br>気持ちとしては、ソーステキストが与えられたときに、Questionの回答をsupportするようなソース中のpassageの情報を活用して回答するために、重要なsentenceのprefixを回答生成前に生成させる（重要なsentenceの識別子の役割を果たす）ことで、（識別子によって重要な情報によって条件づけられて回答生成ができるやうになるのて）それら情報をより考慮しながらモデルが回答を生成できるようになる、といった話だと思われる。<br><br>Table2のようなテンプレートを用いて、ソーステキストと質問文でモデルを条件付けて、回答をsupportするsentenceのprefixを生成する。生成するprefixは各sentenceのユニークなprefixのtoken log probabilityの平均値によって決まる（トークンの対数尤度が高かったらモデルが暗黙的にその情報はQuestionにとって重要だと判断しているとみなせる）。SkipDecodingの説を読んだが、ぱっと見よく分からない。おそらく[eos]を出力させてprefix間のデリミタとして機能させたいのだと思うが、[eos]の最適なpositionはどこなのか？みたいな数式が出てきており、これがデコーディングの時にどういった役割を果たすのかがよくわからない。<br><br>また、モデルはQAと重要なPassageの三つ組のデータで提案手法によるデコーディングを適用してSFTしたものを利用する。<br><br><img src="https://github.com/user-attachments/assets/fa4e575e-c6cb-452a-be3e-0d9bacb3cacb" alt="image" loading="lazy" width="550" height="400"><br><img src="https://github.com/user-attachments/assets/1985754f-c21f-4904-be50-6f4f7eef56d1" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="how-much-1641" class="title-link">How Much Data is Enough Data? Fine-Tuning Large Language Models for  In-House Translation: Performance Evaluation Across Multiple Dataset Sizes, Inacio Vieira+, AMTA'24</h3>
<br><a href="https://arxiv.org/abs/2409.03454" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1641" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="MachineTranslation.html" target="_blank" rel="noopener noreferrer">#MachineTranslation</a>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<span class="snippet"><span>GPT Summary</span>- LLMsのファインチューニングに翻訳メモリ（TMs）を活用し、特定の組織向けの翻訳精度と効率を向上させる研究。5つの翻訳方向で異なるサイズのデータセットを用いて実験し、トレーニングデータが増えるほど翻訳パフォーマンスが向上することを確認。特に、1kおよび2kの例ではパフォーマンスが低下するが、データセットのサイズが増加するにつれて改善が見られる。LLMsとTMsの統合により、企業特有のニーズに応じたカスタマイズ翻訳モデルの可能性を示唆。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>QLoRAでLlama 8B InstructをMTのデータでSFTした場合のサンプル数に対する性能の変化を検証している。ただし、検証しているタスクはMT、QLoRAでSFTを実施しrankは64、学習時のプロンプトは非常にシンプルなものであるなど、幅広い設定で学習しているわけではないので、ここで得られた知見が幅広く適用可能なことは示されていないであろう点、には注意が必要だと思われる。<br><br>この設定では、SFTで利用するサンプル数が増えれば増えるほど性能が上がっているように見える。<br><br><img src="https://github.com/user-attachments/assets/71309a00-85fd-491f-a89e-c9cb99f4da6c" alt="image" loading="lazy" width="550" height="400"><br><img src="https://github.com/user-attachments/assets/ea1eba38-9488-43e5-a64b-f997bf65f57b" alt="image" loading="lazy" width="550" height="400"><br><img src="https://github.com/user-attachments/assets/21b21628-d589-4214-8860-680e392a2556" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="lora-learns-1640" class="title-link">LoRA Learns Less and Forgets Less, Dan Biderman+, TMLR'24</h3>
<br><a href="https://arxiv.org/abs/2405.09673" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1640" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<span class="snippet"><span>GPT Summary</span>- LoRAは大規模言語モデルの効率的なファインチューニング手法であり、プログラミングと数学のドメインでの性能をフルファインチューニングと比較。標準的な設定ではLoRAは性能が劣るが、ターゲットドメイン外のタスクではベースモデルの性能を維持し、忘却を軽減する効果がある。フルファインチューニングはLoRAよりも高いランクの摂動を学習し、性能差の一因と考えられる。最終的に、LoRAのファインチューニングに関するベストプラクティスを提案。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>full finetuningとLoRAの性質の違いを理解するのに有用</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="finetunebench-how-1639" class="title-link">FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge  into LLMs?, Eric Wu+, arXiv'24</h3>
<br><a href="https://arxiv.org/abs/2411.05059v2" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1639" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Proprietary.html" target="_blank" rel="noopener noreferrer">#Proprietary</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<span class="snippet"><span>GPT Summary</span>- 商業的なLLM微調整APIの効果を評価するためのFineTuneBenchを提案。5つの最前線のLLMを分析し、新しい情報の学習と既存知識の更新における能力を評価した結果、全モデルで平均一般化精度は37%、医療ガイドラインの更新では19%と低いことが判明。特にGPT-4o miniが最も効果的で、Gemini 1.5シリーズは能力が限られていた。商業的微調整サービスの信頼性に課題があることを示唆。データセットはオープンソースで提供。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="auto-rag-autonomous-1578" class="title-link">Auto-RAG: Autonomous Retrieval-Augmented Generation for Large Language  Models, Tian Yu+, arXiv'24</h3>
<br><a href="https://arxiv.org/abs/2411.19443" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1578" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Multi.html" target="_blank" rel="noopener noreferrer">#Multi</a>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-12-10</span>
<span class="snippet"><span>GPT Summary</span>- Auto-RAGは、LLMの意思決定能力を活用した自律的な反復検索モデルで、リトリーバーとのマルチターン対話を通じて知識を取得します。推論に基づく意思決定を自律的に合成し、6つのベンチマークで優れた性能を示し、反復回数を質問の難易度に応じて調整可能です。また、プロセスを自然言語で表現し、解釈可能性とユーザー体験を向上させます。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/omarsar0/status/1863600141103501454?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=jkVQ31GeIA" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=jkVQ31GeIA</a>


</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=jkVQ31GeIA" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=jkVQ31GeIA</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="balancing-speed-1524" class="title-link">Balancing Speed and Stability: The Trade-offs of FP8 vs. BF16 Training  in LLMs, Kazuki Fujii+, arXiv'24</h3>
<br><a href="https://arxiv.org/abs/2411.08719" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1524" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2024-11-17</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLMs）は、その言語理解能力と適用可能性から注目を集めており、特にLlama 3シリーズは4050億パラメータを持つ。トレーニングの効率化が求められる中、NVIDIAのH100 GPUはFP8フォーマットを導入し、トレーニング時間を短縮する可能性がある。初期研究ではFP8が性能を損なわずに効率を向上させることが示唆されているが、トレーニングの安定性や下流タスクへの影響はまだ不明である。本研究は、LLMsのトレーニングにおけるBF16とFP8のトレードオフを探る。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/okoge_kaz/status/1857639065421754525?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>FP8で継続的事前学習をするとスループットは向上するが、lossのスパイクを生じたり、downstreamタスクの性能がBF16よりも低下したりする（日本語と英語の両方）との報告のようである。現状アブストと付録しか記載がないが、内容はこれから更新されるのだろうか。<br><br><img src="https://github.com/user-attachments/assets/8d60d59b-de00-483a-bff0-04a4145715c1" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="delift-data-1504" class="title-link">DELIFT: Data Efficient Language model Instruction Fine Tuning, Ishika Agarwal+, arXiv'24</h3>
<br><a href="https://arxiv.org/abs/2411.04425" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1504" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2024-11-12</span>
<span class="snippet"><span>GPT Summary</span>- DELIFTという新しいアルゴリズムを提案し、ファインチューニングの各ステージでデータ選択を最適化。ペアワイズユーティリティメトリックを用いてデータの有益性を定量化し、最大70%のデータ削減を実現。計算コストを大幅に節約し、既存の方法を上回る効率性と効果を示す。</span>
</article>
<article class="paper-entry">
<h3 id="online-lora-task-free-1502" class="title-link">Online-LoRA: Task-free Online Continual Learning via Low Rank Adaptation, Xiwen Wei+, arXiv'24</h3>
<br><a href="https://arxiv.org/abs/2411.05663" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1502" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<span class="issue_date">Issue Date: 2024-11-12</span>
<span class="snippet"><span>GPT Summary</span>- 破滅的忘却に対処するため、タスクフリーのオンライン継続学習（OCL）フレームワークOnline-LoRAを提案。リハーサルバッファの制約を克服し、事前学習済みビジョントランスフォーマー（ViT）モデルをリアルタイムで微調整。新しいオンライン重み正則化戦略を用いて重要なモデルパラメータを特定し、データ分布の変化を自動認識。多様なベンチマークデータセットで優れた性能を示す。</span>
<span class="snippet"><span>Comment</span><p><img src="https://github.com/user-attachments/assets/b789ba71-3941-4d60-9397-46607ddc7712" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="beyond-full-1475" class="title-link">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</h3>
<br><a href="https://aclanthology.org/2024.lrec-main.206/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<span class="issue_date">Issue Date: 2024-10-30</span>
<span class="snippet"><span>GPT Summary</span>- LoRAは大規模言語モデルのファインチューニング手法で、特にマルチタスク設定での性能向上に挑戦する。本研究では、LoRAのパフォーマンスを多様なタスクとリソースで検証し、適切なランク設定により高リソース環境でもフルファインチューニングに匹敵する結果を得られることを示した。学習能力の制約がLoRAの一般化能力を高めることが明らかになり、LoRAの適用可能性を広げる方向性を示唆している。</span>
<span class="snippet"><span>Comment</span><p>LoRAのランク数をめちゃめちゃ大きくすると（1024以上）、full-parameterをチューニングするよりも、Unseenタスクに対する汎化性能が向上しますよ、という話っぽい<br><br><img src="https://github.com/user-attachments/assets/69120eee-2993-4e51-bbf4-52e3040bf66d" alt="image" loading="lazy" width="550" height="400"><br><br></p>
<p><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1474" target="_blank" rel="noopener noreferrer">Super-NaturalInstructions: Generalization via Declarative Instructions  on 1600+ NLP Tasks, Yizhong Wang+, N/A, EMNLP'22</a>
 も参照のこと</p>
<p>## LoRA Finetuning details<br><br>- LoRA rankを最大4096<br><br>- LoRAのαをなんとrankの2倍にしている<br><br>    - original paperでは16が推奨されている<br><br>- learning_rate: 5e-5<br><br>- linear sheculeで learning_rate を減衰させる<br><br>- optimizerはAdamW<br><br>- batch_size: 128 <br><br><img src="https://github.com/user-attachments/assets/516141a8-2955-49af-95e7-8f1b16e4122a" alt="image" loading="lazy" width="550" height="400"><br><br></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="neftune-noisy-1473" class="title-link">NEFTune: Noisy Embeddings Improve Instruction Finetuning, Neel Jain+, N_A, ICLR'24</h3>
<br><a href="https://arxiv.org/abs/2310.05914" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1473" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<span class="issue_date">Issue Date: 2024-10-27</span>
<span class="snippet"><span>GPT Summary</span>- NEFTuneは、埋め込みベクトルにノイズを加えることで言語モデルのファインチューニングを改善する手法です。LLaMA-2-7Bを用いた標準的なファインチューニングでは29.79%の精度でしたが、ノイジーな埋め込みを使用することで64.69%に向上しました。NEFTuneは、Evol-Instruct、ShareGPT、OpenPlatypusなどの指示データセットでも改善をもたらし、RLHFで強化されたLLaMA-2-Chatにも効果があります。</span>
<span class="snippet"><span>Comment</span><p>ランダムノイズをembeddingに加えて学習するシンプルな手法。モデルがロバストになる。<br><br>Unsupervised SimCSEと思想が似ている。実質DataAugmentationともみなせる。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="self-taught-evaluators-1464" class="title-link">Self-Taught Evaluators, Tianlu Wang+, N_A, arXiv'24</h3>
<br><a href="https://arxiv.org/pdf/2408.02666" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1464" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-10-21</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、人間の注釈なしで評価者を改善するアプローチを提案。合成トレーニングデータを用い、自己改善スキームによりLLMを評価者としてトレーニング。これにより、RewardBenchでのLLMのパフォーマンスを75.4から88.3に向上させ、GPT-4を超える結果を達成。</span>
<span class="snippet"><span>Comment</span><p>LLMのアラインメント等をSFTする際に、preferenceのラベル付きデータが必要になるが、このようなデータを作るのはコストがかかって大変なので自動生成して、より良いreward modelを作りたいよね、という話。<br>具体的には、LLMを用いて good responseと、instructionを変化させてbad sesponseを生成し、JudgeモデルM_tにpairwiseでどちらが良いかをjudgeさせることで学習データを作成。新たに作成されたデータを用いてJudgeモデルを再学習し、同様のプロセスを繰り返すことで、人手の介在なく強力なJudgeモデルが完成する。<br><img src="https://github.com/user-attachments/assets/837c4567-6993-4e4c-81c8-650b7777c49b" alt="image" loading="lazy" width="550" height="400"><br><img src="https://github.com/user-attachments/assets/10a4fb62-160d-4bcf-b3a2-a960a7c9bc46" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="addition-is-1459" class="title-link">Addition is All You Need for Energy-efficient Language Models, Hongyin Luo+, N_A, arXiv'24</h3>
<br><a href="https://arxiv.org/abs/2410.00907" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1459" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-10-20</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、浮動小数点乗算を高精度で整数加算器によって近似するL-Mulアルゴリズムを提案。これにより、8ビット浮動小数点乗算に比べて計算リソースを大幅に削減しつつ、より高い精度を実現。L-Mulをテンソル処理ハードウェアに適用することで、エネルギーコストを95％（要素ごとの乗算）および80％（ドット積）削減可能。実験結果は理論的誤差推定と一致し、L-Mulは従来の浮動小数点乗算と同等またはそれ以上の精度を達成。トランスフォーマーモデル内の浮動小数点乗算をL-Mulに置き換えることで、ファインチューニングと推論において高い精度を維持できることを示した。</span>
</article>
<article class="paper-entry">
<h3 id="toolgen-unified-1458" class="title-link">ToolGen: Unified Tool Retrieval and Calling via Generation, Renxi Wang+, N_A, arXiv'24</h3>
<br><a href="https://arxiv.org/abs/2410.03439" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1458" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<span class="issue_date">Issue Date: 2024-10-20</span>
<span class="snippet"><span>GPT Summary</span>- ToolGenは、外部ツールとの直接対話を可能にする新しいフレームワークで、各ツールをユニークなトークンとして表現し、LLMのパラメータに統合します。これにより、LLMはツール呼び出しや引数を自然言語生成の一部としてシームレスに生成でき、情報取得ステップなしで多くのツールにアクセス可能になります。実験結果は、ToolGenが自律的なタスク完了と情報取得で優れた性能を示し、より効率的で自律的なAIシステムの基盤を築くことを示しています。</span>
<span class="snippet"><span>Comment</span><p>昔からよくある特殊トークンを埋め込んで、特殊トークンを生成したらそれに応じた処理をする系の研究。今回はツールに対応するトークンを仕込む模様。</p>
<p>斜め読みだが、3つのstepでFoundation Modelを訓練する。まずはツールのdescriptionからツールトークンを生成する。これにより、モデルにツールの情報を覚えさせる（memorization）。斜め読みなので読めていないが、ツールトークンをvocabに追加してるのでここは継続的事前学習をしているかもしれない。続いて、（おそらく）人手でアノテーションされたクエリ-必要なツールのペアデータから、クエリに対して必要なツールを生成するタスクを学習させる。最後に、（おそらく人手で作成された）クエリ-タスクを解くためのtrajectoryペアのデータで学習させる。<br><img src="https://github.com/user-attachments/assets/eebe4260-2e4f-4be7-9b59-a0b84913e667" alt="image" loading="lazy" width="550" height="400"><br><img src="https://github.com/user-attachments/assets/d03ed971-e5c9-49f3-8385-cfb00505907c" alt="image" loading="lazy" width="550" height="400"></p>
<p>学習データのサンプル。Appendix中に記載されているものだが、本文のデータセット節とAppendixの双方に、データの作り方の詳細は記述されていなかった。どこかに書いてあるのだろうか。<br><img src="https://github.com/user-attachments/assets/41975d34-dc9d-405d-aaca-062a3ee1a4b0" alt="image" loading="lazy" width="550" height="400"><img src="https://github.com/user-attachments/assets/41e80988-5770-420e-bc80-a4cc0a724994" alt="image" loading="lazy" width="550" height="400"></p>
<p>最終的な性能<br><img src="https://github.com/user-attachments/assets/a247cc99-10eb-4346-9f0d-b406a022c3b4" alt="image" loading="lazy" width="550" height="400"></p>
<p>特殊トークンを追加のvocabとして登録し、そのトークンを生成できるようなデータで学習し、vocabに応じて何らかの操作を実行するという枠組み、その学習手法は色々なタスクで役立ちそう。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="smaller-1427" class="title-link">Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal  Sampling, Hritik Bansal+, N_A, arXiv'24</h3>
<br><a href="https://arxiv.org/pdf/2408.16737" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1427" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<span class="issue_date">Issue Date: 2024-09-29</span>
<span class="snippet"><span>GPT Summary</span>- 高品質な合成データを生成するために、強力なSEモデルと安価なWCモデルのトレードオフを再検討。WCモデルからのデータはカバレッジと多様性が高いが偽陽性率も高い。ファインチューニングの結果、WC生成データでトレーニングされたモデルがSE生成データのモデルを上回ることが示され、WCが計算最適なアプローチである可能性を示唆。</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/rohanpaul_ai/status/1840172683528425718?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="when-scaling-1423" class="title-link">When Scaling Meets LLM Finetuning: The Effect of Data, Model and  Finetuning Method, Biao Zhang+, N_A, ICLR'24</h3>
<br><a href="https://arxiv.org/abs/2402.17193" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1423" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-09-26</span>
<span class="snippet"><span>GPT Summary</span>- LLMのファインチューニング手法のスケーリング特性を調査し、モデルサイズやデータサイズが性能に与える影響を実験。結果、ファインチューニングはパワーベースの共同スケーリング法則に従い、モデルのスケーリングが事前学習データのスケーリングよりも効果的であることが判明。最適な手法はタスクやデータに依存する。</span>
<span class="snippet"><span>Comment</span><p>&gt; When only few thousands of finetuning examples are available, PET should be considered first, either Prompt or LoRA. With sightly larger datasets, LoRA would be preferred due to its stability and slightly better finetuning data scalability. For million-scale datasets, FMT would be good.<br><br><br><br>&gt; While specializing on a downstream task, finetuning could still elicit<br><br>and improve the generalization for closely related tasks, although the overall zero-shot translation<br><br>quality is inferior. Note whether finetuning benefits generalization is method- and task-dependent.<br><br>Overall, Prompt and LoRA achieve relatively better results than FMT particularly when the base<br><br>LLM is large, mostly because LLM parameters are frozen and the learned knowledge get inherited.<br><br>This also suggests that when generalization capability is a big concern, PET should be considered.</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="backtracking-improves-1408" class="title-link">Backtracking Improves Generation Safety, Yiming Zhang+, N_A, arXiv'24</h3>
<br><a href="http://arxiv.org/pdf/2409.14586" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1408" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-09-24</span>
<span class="snippet"><span>GPT Summary</span>- テキスト生成における安全性の問題に対処するため、バックトラッキング手法を提案。特別な[RESET]トークンを用いて生成された不適切なテキストを「取り消し」、モデルの安全性を向上させる。バックトラッキングを導入したLlama-3-8Bは、ベースラインモデルに比べて4倍の安全性を示し、有用性の低下は見られなかった。</span>
<span class="snippet"><span>Comment</span><p>元ポスト: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jaseweston/status/1838415378529112330?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="plug-leveraging-1400" class="title-link">PLUG: Leveraging Pivot Language in Cross-Lingual Instruction Tuning, Zhihan Zhang+, N_A, ACL'24</h3>
<br><a href="https://arxiv.org/abs/2311.08711" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1400" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="CrossLingual.html" target="_blank" rel="noopener noreferrer">#CrossLingual</a>
<span class="issue_date">Issue Date: 2024-09-19</span>
<span class="snippet"><span>GPT Summary</span>- 指示チューニングはLLMsの指示理解を向上させるが、低リソース言語では課題がある。これに対処するため、英語をピボット言語とするPLUGアプローチを提案。モデルはまず英語で指示を処理し、次にターゲット言語で応答を生成。4つの言語での評価により、指示に従う能力が平均29%向上した。さらに、他のピボット言語を用いた実験も行い、アプローチの多様性を確認。コードとデータは公開されている。</span>
<span class="snippet"><span>Comment</span><p>
<strong># 概要<br><br>cross-lingualでinstruction tuningをする手法。target言語のInstructionが与えられたときに、Pivotとなる言語でInstructionとResponseを生成した後、targetとなる言語に翻訳するようなデータ（それぞれをseparatorを用いてconcatする）でInstruction Tuningすることでtarget言語での性能が向上<br><br><br><br><img src="https://github.com/user-attachments/assets/1a409df0-b8bf-45fd-8fc1-316519723820" alt="image" loading="lazy" width="550" height="400"><br><br><br><br># 評価<br><br>ゼロショットのOpen-end GenerationタスクでInstruction Tuningされたモデルが評価されるが、既存のマルチリンガルの評価セットはサンプル数が小さく、機械翻訳ベースのものはノイジーという課題がある。このため、著者らは評価する4言語（low-resource language）のプロの翻訳家を雇用し、AlpacaEvalを翻訳し、4言語（Chinese, Korean, Italian, Spanish）のinstructionが存在するパラレルコーパス X-AlpacaEvalを作成し評価データとして用いる。<br><br><br>利用するFoundationモデルは以下の3種類で、<br><br>- LLaMA-2-13B (英語に特化したモデル)<br><br>- PolyLM-13B (マルチリンガルなモデル)<br><br>- PolyLM-Instruct-Instruct (PolyLM-13Bをinstruction tuningしたもの)<br><br><br>これらに対して学習データとしてGPT4-Alpaca <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1401" target="_blank" rel="noopener noreferrer">Instruction Tuning with GPT-4, Baolin Peng+, N/A, arXiv'23</a>
</strong>
<br>
 instruction-tuning dataset (52kのインストラクションが存在) を利用する。GPT4-AlpacaをChatGPTによって4言語に翻訳し、各言語に対するinstruction tuning datasetを得た。<br><br><br><br>比較手法として以下の5種類と比較している。ここでターゲット言語は今回4種類で、それぞれターゲット言語ごとに独立にモデルを学習している。<br><br>- Pivot-only training: pivot言語（今回は英語）のみで学習した場合 <br><br>- Monolingual response training: pivot言語とtarget言語のデータを利用した場合<br><br>- Code Switching: Monolingual response trainingに加えて、pivot言語とtarget言語のinput/outputをそれぞれ入れ替えたデータセットを用いた場合（i.e. pivot言語 input-target言語 output, target言語 input-pivot言語 outputのペアを作成し学習データに利用している）<br><br>- Auxiliary translation tasks: Monolingual respones trainingに加えて、翻訳タスクを定義し学習データとして加えた場合。すなわち、input, outputそれぞれに対して、pivot言語からtarget言語への翻訳のサンプル ([P_trans;x^p], x^t）と（[P_trans;y^p], y^t）を加えて学習している。ここで、P_transは翻訳を指示するpromptで、;は文字列のconcatnation。x^p, y^p, x^t, y^tはそれぞれ、pivot言語のinput, output、target言語のinput, outputのサンプルを表す。<br><br>- PLUG（提案手法）: Pivot-only Trainingに加えて、target言語のinputから、pivot言語のinput/output -&gt; target言語のoutputをconcatしたテキスト(x^t, [x^p;y^p;y^t]) を学習データに加えた場合<br><br><br><br>評価する際は、MT-Bench <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/903" target="_blank" rel="noopener noreferrer">Judging LLM-as-a-judge with MT-Bench and Chatbot Arena, Lianmin Zheng+, N/A, NeurIPS'23</a>
 のように、GPT4を用いた、direct pair-wise comparisonを行っている。<br><br>direct pair-wise comparisonは、2つのサンプルを与えてLLMに何らかの判断やスコアリングをさせる方法であり、今回はどちらがinstructionにより従っているかに勝敗/引き分けをGPT4に判断させている。LLMによる生成はサンプルの順番にsensitiveなので、順番を逆にした場合でも実験をして、win-lose rateを求めている。1つのサンプルペアに対して、サンプルの順番を正順と逆順の2回評価させ、その双方の結果を用いて最終的なwin/lose/tieを決めている。端的に言うと、勝敗が2-0ならそのサンプルの勝ち、同様に1-1なら引き分け、0-2なら負け、ということである。<br><br><img src="https://github.com/user-attachments/assets/726ea2dc-8f62-4320-8489-45cc20ed32ae" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="reft-reasoning-1391" class="title-link">ReFT: Reasoning with Reinforced Fine-Tuning, Trung Quoc Luong+, N_A, ACL'24</h3>
<br><a href="https://arxiv.org/abs/2401.08967" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1391" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2024-09-13</span>
<span class="snippet"><span>GPT Summary</span>- 強化ファインチューニング（ReFT）を提案し、LLMsの推論能力を向上。SFTでモデルをウォームアップ後、PPOアルゴリズムを用いてオンライン強化学習を行い、豊富な推論パスを自動サンプリング。GSM8K、MathQA、SVAMPデータセットでSFTを大幅に上回る性能を示し、追加のトレーニング質問に依存せず優れた一般化能力を発揮。</span>
</article>
<article class="paper-entry">
<h3 id="does-fine-tuning-1371" class="title-link">Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?, Zorik Gekhman+, N_A, EMNLP'24</h3>
<br><a href="https://arxiv.org/abs/2405.05904" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1371" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Hallucination.html" target="_blank" rel="noopener noreferrer">#Hallucination</a>
<span class="issue_date">Issue Date: 2024-09-01</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデルはファインチューニングを通じて新しい事実情報に遭遇するが、既存の知識を活用する能力に影響を与える。研究では、閉じた書籍のQAを用いて新しい知識を導入するファインチューニング例の割合を変化させた結果、モデルは新しい知識を学習するのに苦労し、幻覚する傾向が増加することが示された。これにより、ファインチューニングによる新しい知識の導入のリスクが明らかになり、モデルは事前学習を通じて知識を獲得し、ファインチューニングはその利用を効率化することが支持される。</span>
<span class="snippet"><span>Comment</span><p>pre-training時に獲得されていない情報を用いてLLMのalignmentを実施すると、知識がない状態で学習データを正しく予測できるように学習されてしまうため、事実に基づかない回答をする（つまりhallucination）ように学習されてしまう、といったことを調査している模様。<br><br><br><br>&gt;新しい知識を導入するファインチューニング例は、モデルの知識と一致する例よりもはるかに遅く学習されます。しかし、新しい知識を持つ例が最終的に学習されるにつれて、モデルの幻覚する傾向が線形に増加することも発見しました。<br><br><img src="https://github.com/user-attachments/assets/9c7b3e2e-3ecb-4d71-a7fc-09fa7e57a613" alt="image" loading="lazy" width="550" height="400"><br><br><br><br>早々にoverfittingしている。<br><br><br><br>&gt;大規模言語モデルは主に事前学習を通じて事実知識を取得し、ファインチューニングはそれをより効率的に使用することを教えるという見解を支持しています。<br><br><br><br>なるほど、興味深い。</p>
<p>下記画像は <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1370" target="_blank" rel="noopener noreferrer">大規模言語モデル (LLM) の技術と最新動向, Ikuya Yamada, 2024.06</a>
より引用<br><br><img src="https://github.com/user-attachments/assets/e08d47cf-b550-4ced-a6bd-02d90d3684e9" alt="image" loading="lazy" width="550" height="400"><br><br><br><br>本論文中では、full finetuningによる検証を実施しており、LoRAのようなAdapterを用いたテクニックで検証はされていない。LoRAではもともとのLLMのパラメータはfreezeされるため、異なる挙動となる可能性がある。特にLoRAが新しい知識を獲得可能なことが示されれば、LoRA AdapterをもともとのLLMに付け替えるだけで、異なる知識を持ったLLMを運用可能になるため、インパクトが大きいと考えられる。もともとこういった思想は LoRA Hubを提唱する研究などの頃からあった気がするが、AdapterによってHallucination/overfittingを防ぎながら、新たな知識を獲得できることを示した研究はあるのだろうか？<br><br><img src="https://github.com/user-attachments/assets/a05a3662-baf9-4fcd-b15e-440f1c2c9f6e" alt="image" loading="lazy" width="550" height="400"><br><br></p>
<p>参考: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1792334744522485954?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>LoRAの場合については<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1640" target="_blank" rel="noopener noreferrer">LoRA Learns Less and Forgets Less, Dan Biderman+, TMLR'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
<br><br>も参照のこと。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="amuro-&amp;-1352" class="title-link">Amuro &amp; Char: Analyzing the Relationship between Pre-Training and  Fine-Tuning of Large Language Models, Kaiser Sun+, N_A, arXiv'24</h3>
<br><a href="https://arxiv.org/abs/2408.06663" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1352" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Analysis.html" target="_blank" rel="noopener noreferrer">#Analysis</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<span class="issue_date">Issue Date: 2024-08-19</span>
<span class="snippet"><span>GPT Summary</span>- 大規模なテキストコーパスで事前学習された複数の中間事前学習モデルのチェックポイントを微調整することによって、事前学習と微調整の関係を調査した。18のデータセットでの結果から、i）継続的な事前学習は、微調整後にモデルを改善する潜在的な方法を示唆している。ii）追加の微調整により、モデルが事前学習段階でうまく機能しないデータセットの改善が、うまく機能するデータセットよりも大きいことを示している。iii）監督された微調整を通じてモデルは恩恵を受けるが、以前のドメイン知識や微調整中に見られないタスクを忘れることがある。iv）監督された微調整後、モデルは評価プロンプトに対して高い感度を示すが、これはより多くの事前学習によって緩和できる。</span>
</article>
<article class="paper-entry">
<h3 id="raft-adapting-1269" class="title-link">RAFT: Adapting Language Model to Domain Specific RAG, Tianjun Zhang+, N_A, arXiv'24</h3>
<br><a href="https://arxiv.org/abs/2403.10131" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1269" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="InformationRetrieval.html" target="_blank" rel="noopener noreferrer">#InformationRetrieval</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<span class="issue_date">Issue Date: 2024-04-07</span>
<span class="snippet"><span>GPT Summary</span>- 大規模なテキストデータのLLMsを事前学習し、新しい知識を追加するためのRetrieval Augmented FineTuning（RAFT）を提案。RAFTは、質問に回答するのに役立つ関連文書から正しいシーケンスを引用し、chain-of-thoughtスタイルの応答を通じて推論能力を向上させる。RAFTはPubMed、HotpotQA、Gorillaデータセットでモデルのパフォーマンスを向上させ、事前学習済みLLMsをドメイン固有のRAGに向けて改善する。</span>
<span class="snippet"><span>Comment</span><p>Question, instruction, coxtext, cot style answerの4つを用いてSFTをする模様<br>画像は下記ツイートより引用<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/0763b048-8029-4712-9e79-e833bdb9b2c0" alt="image" loading="lazy" width="550" height="400"><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/cwolferesearch/status/1770912695765660139?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="lorahub-efficient-917" class="title-link">LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA   Composition, Chengsong Huang+, N_A, COLM'24</h3>
<br><a href="https://arxiv.org/abs/2307.13269" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/917" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="COLM.html" target="_blank" rel="noopener noreferrer">#COLM</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-08-08</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、大規模言語モデル（LLMs）を新しいタスクに適応させるための低ランク適応（LoRA）を検討し、LoraHubというフレームワークを提案します。LoraHubを使用すると、少数の例から複数のLoRAモジュールを組み合わせて柔軟に適応性のあるパフォーマンスを実現できます。また、追加のモデルパラメータや勾配は必要ありません。実験結果から、LoraHubが少数の例でのインコンテキスト学習のパフォーマンスを効果的に模倣できることが示されています。さらに、LoRAコミュニティの育成と共有リソースの提供にも貢献しています。</span>
<span class="snippet"><span>Comment</span><p>学習されたLoRAのパラメータをモジュールとして捉え、新たなタスクのinputが与えられた時に、LoRA Hub上の適切なモジュールをLLMに組み合わせることで、ICL無しで汎化を実現するというアイデア。few shotのexampleを人間が設計する必要なく、同等の性能を達成。<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9d769042-5a29-4c22-8ab4-e90195f71184" alt="image" loading="lazy" width="550" height="400"></p>
<p>複数のLoRAモジュールは組み合わられるか？element wiseの線型結合で今回はやっているが、その疑問にこたえたのがcontribution</p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=TrloAXEJ2B" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=TrloAXEJ2B</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="scaling-instruction-finetuned-542" class="title-link">Scaling Instruction-Finetuned Language Models, Chung+, Google, JMLR'24</h3>
<br><a href="https://arxiv.org/pdf/2210.11416.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/542" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2023-04-26</span>
<span class="snippet"><span>GPT Summary</span>- 指示ファインチューニングは、タスク数、モデルサイズ、チェーン・オブ・ソートデータを活用し、言語モデルの性能を向上させる手法である。Flan-PaLM 540Bは1.8Kタスクでファインチューニングされ、PaLM 540Bを上回る+9.4%の改善を達成し、MMLUで75.2%の性能を示した。Flan-T5も強力な少数ショット性能を発揮し、指示ファインチューニングは事前学習モデルの性能向上に寄与する。</span>
<span class="snippet"><span>Comment</span><p>T5をinstruction tuningしたFlanT5の研究</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="large-language-2275" class="title-link">[Paper Note] Large Language Models Can Self-Improve, Jiaxin Huang+, EMNLP'23</h3>
<br><a href="https://arxiv.org/abs/2210.11610" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2275" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="SelfImprovement.html" target="_blank" rel="noopener noreferrer">#SelfImprovement</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<span class="issue_date">Issue Date: 2025-07-22</span>
<span class="snippet"><span>GPT Summary</span>- LLMはラベルのないデータセットで自己改善可能であることを示し、Chain-of-Thoughtプロンプティングと自己一貫性を利用して高信頼度の回答を生成。これにより、540BパラメータのLLMの推論能力を向上させ、最先端のパフォーマンスを達成。ファインチューニングが自己改善に重要であることも確認。</span>
<span class="snippet"><span>Comment</span><p>openreview: 


<a href="https://openreview.net/forum?id=uuUQraD4XX&noteId=PWDEpZtn6P" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=uuUQraD4XX&noteId=PWDEpZtn6P</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="tallrec-an-1841" class="title-link">[Paper Note] TALLRec: An Effective and Efficient Tuning Framework to Align Large   Language Model with Recommendation, Keqin Bao+, RecSys'23</h3>
<br><a href="https://arxiv.org/abs/2305.00447" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1841" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="RecommenderSystems.html" target="_blank" rel="noopener noreferrer">#RecommenderSystems</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Contents-based.html" target="_blank" rel="noopener noreferrer">#Contents-based</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="Zero_FewShotLearning.html" target="_blank" rel="noopener noreferrer">#Zero/FewShotLearning</a>
<a class="button" href="RecSys.html" target="_blank" rel="noopener noreferrer">#RecSys</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-03-30</span>
<span class="snippet"><span>GPT Summary</span>- 大規模言語モデル（LLMs）を推薦システムに活用するため、推薦データで調整するフレームワークTALLRecを提案。限られたデータセットでもLLMsの推薦能力を向上させ、効率的に実行可能。ファインチューニングされたLLMはクロスドメイン一般化を示す。</span>
<span class="snippet"><span>Comment</span><p>下記のようなユーザのプロファイルとターゲットアイテムと、binaryの明示的なrelevance feedbackデータを用いてLoRA、かつFewshot Learningの設定でSFTすることでbinaryのlike/dislikeの予測性能を向上。PromptingだけでなくSFTを実施した初めての研究だと思われる。<br><img src="https://github.com/user-attachments/assets/08ea2d35-1dd1-4670-810b-a57722173460" alt="image" loading="lazy" width="550" height="400"><br><img src="https://github.com/user-attachments/assets/acf565f8-9541-4fe1-95e8-10cff397fa7a" alt="image" loading="lazy" width="550" height="400"><br><br>既存ベースラインと比較して大幅にAUCが向上<br><img src="https://github.com/user-attachments/assets/141a0c43-0504-4da3-84d9-c4dac119b590" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="sparse-upcycling-1546" class="title-link">Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints, Aran Komatsuzaki+, ICLR'23</h3>
<br><a href="https://arxiv.org/abs/2212.05055" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1546" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-11-25</span>
<span class="snippet"><span>GPT Summary</span>- スパース活性化モデルは、計算コストを抑えつつ密なモデルの代替として注目されているが、依然として多くのデータを必要とし、ゼロからのトレーニングは高コストである。本研究では、密なチェックポイントからスパース活性化Mixture-of-Expertsモデルを初期化する「スパースアップサイクリング」を提案。これにより、初期の密な事前トレーニングのコストを約50%再利用し、SuperGLUEやImageNetで密なモデルを大幅に上回る性能を示した。また、アップサイクリングされたモデルは、ゼロからトレーニングされたスパースモデルよりも優れた結果を得た。</span>
<span class="snippet"><span>Comment</span><p>斜め読みしかできていないが、Mixture-of-Expertsを用いたモデルをSFT/Pretrainingする際に、既存のcheckpointの重みを活用することでより効率的かつ性能向上する方法を提案。MoE LayerのMLPを全て既存のcheckpointにおけるMLPの重みをコピーして初期化する。Routerはスクラッチから学習する。<br><img src="https://github.com/user-attachments/assets/d51a0746-d2cc-4343-a462-20034ef373d9" alt="image" loading="lazy" width="550" height="400"><br><br>継続事前学習においては、同じ学習時間の中でDense Layerを用いるベースラインと比較してでより高い性能を獲得。<br><img src="https://github.com/user-attachments/assets/d7a67c99-15d7-4803-82e4-63187bb3d4ec" alt="image" loading="lazy" width="550" height="400"><br>Figure2で継続事前学習したモデルに対して、フルパラメータのFinetuningをした場合でもUpcyclingは効果がある（Figure3）。<br><br>特にPretrainingではUpcyclingを用いたモデルの性能に、通常のMoEをスクラッチから学習したモデルが追いつくのに時間がかかるとのこと。特に図右側の言語タスクでは、120%の学習時間が追いつくために必要だった。<br><img src="https://github.com/user-attachments/assets/f0ca37ac-65a7-43ff-afef-ffc309b17040" alt="image" loading="lazy" width="550" height="400"><br><br>Sparse Upcycingと、Dense tilingによる手法（warm start; 元のモデルに既存の層を複製して新しい層を追加する方法）、元のモデルをそれぞれ継続事前学習すると、最も高い性能を獲得している。<br><img src="https://github.com/user-attachments/assets/b357a08a-d202-47d3-977f-f02b192723d1" alt="image" loading="lazy" width="550" height="400"><br><br>（すごい斜め読みなのでちょっも自信なし、、、）</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="instruction-tuning-1401" class="title-link">Instruction Tuning with GPT-4, Baolin Peng+, N_A, arXiv'23</h3>
<br><a href="https://arxiv.org/abs/2304.03277" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1401" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2024-09-20</span>
<span class="snippet"><span>GPT Summary</span>- GPT-4を用いて指示に従うデータを生成し、LLMのファインチューニングを行う初の試みを報告。生成された52Kの指示データは、従来のモデルよりも新しいタスクに対して優れたゼロショット性能を示した。GPT-4からのフィードバックと比較データも収集し、データとコードベースを公開。</span>
<span class="snippet"><span>Comment</span><p>現在はOpenAIの利用規約において、outputを利用してOpenAIと競合するモデルを構築することは禁止されているので、この点には注意が必要<br>


<a href="https://openai.com/ja-JP/policies/terms-of-use/" target="_blank" rel="noopener noreferrer">https://openai.com/ja-JP/policies/terms-of-use/</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="reflection-tuning-data-1380" class="title-link">Reflection-Tuning: Data Recycling Improves LLM Instruction-Tuning, Ming Li+, N_A, arXiv'23</h3>
<br><a href="https://arxiv.org/abs/2310.11716v1" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1380" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="SelfCorrection.html" target="_blank" rel="noopener noreferrer">#SelfCorrection</a>
<span class="issue_date">Issue Date: 2024-09-07</span>
<span class="snippet"><span>GPT Summary</span>- リフレクションチューニングという新手法を提案し、LLMsの自己改善を通じて低品質なトレーニングデータの問題に対処。オラクルLLMを用いてデータの質を向上させ、実験により再利用データで訓練されたLLMsが既存モデルを上回ることを示した。</span>
<span class="snippet"><span>Comment</span><p>Reflection-Tuningを提案している研究?</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="instructscore-explainable-1224" class="title-link">INSTRUCTSCORE: Explainable Text Generation Evaluation with Finegrained   Feedback, Wenda Xu+, N_A, EMNLP'23</h3>
<br><a href="https://arxiv.org/abs/2305.14282" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1224" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Explanation.html" target="_blank" rel="noopener noreferrer">#Explanation</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-01-25</span>
<span class="snippet"><span>GPT Summary</span>- 自動的な言語生成の品質評価には説明可能なメトリクスが必要であるが、既存のメトリクスはその判定を説明したり欠陥とスコアを関連付けることができない。そこで、InstructScoreという新しいメトリクスを提案し、人間の指示とGPT-4の知識を活用してテキストの評価と診断レポートを生成する。さまざまな生成タスクでInstructScoreを評価し、他のメトリクスを上回る性能を示した。驚くべきことに、InstructScoreは人間の評価データなしで最先端のメトリクスと同等の性能を達成する。</span>
<span class="snippet"><span>Comment</span><p>伝統的なNLGの性能指標の解釈性が低いことを主張する研究</p>
<p><img src="https://github.com/user-attachments/assets/4c4fe705-e0c5-41d1-b3c8-c084d85b77ba" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="vera-vector-based-1211" class="title-link">VeRA: Vector-based Random Matrix Adaptation, Dawid J. Kopiczko+, N_A, arXiv'23</h3>
<br><a href="https://arxiv.org/abs/2310.11454" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1211" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<span class="issue_date">Issue Date: 2024-01-17</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、大規模な言語モデルのfine-tuningにおいて、訓練可能なパラメータの数を削減するための新しい手法であるベクトルベースのランダム行列適応（VeRA）を提案する。VeRAは、共有される低ランク行列と小さなスケーリングベクトルを使用することで、同じ性能を維持しながらパラメータ数を削減する。GLUEやE2Eのベンチマーク、画像分類タスクでの効果を示し、言語モデルのインストラクションチューニングにも応用できることを示す。</span>
</article>
<article class="paper-entry">
<h3 id="orca-2-1148" class="title-link">Orca 2: Teaching Small Language Models How to Reason, Arindam Mitra+, N_A, arXiv'23</h3>
<br><a href="https://arxiv.org/abs/2311.11045" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1148" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2023-11-21</span>
<span class="snippet"><span>GPT Summary</span>- Orca 1は、豊富なシグナルから学習し、従来のモデルを上回る性能を発揮します。Orca 2では、小さな言語モデルの推論能力を向上させるために異なる解決戦略を教えることを目指しています。Orca 2は、さまざまな推論技術を使用し、15のベンチマークで評価されました。Orca 2は、同じサイズのモデルを大幅に上回り、高度な推論能力を持つ複雑なタスクで優れた性能を発揮します。Orca 2はオープンソース化されており、小さな言語モデルの研究を促進します。</span>
<span class="snippet"><span>Comment</span><p>ポイント解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1726800556667085263?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>HF:


<a href="https://huggingface.co/microsoft/Orca-2-13b" target="_blank" rel="noopener noreferrer">https://huggingface.co/microsoft/Orca-2-13b</a>


</p>
<p>論文を読むとChatGPTのデータを学習に利用しているが、現在は競合となるモデルを作ることは規約で禁止されているので注意</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="fine-tuning-language-1138" class="title-link">Fine-tuning Language Models for Factuality, Katherine Tian+, N_A, arXiv'23</h3>
<br><a href="https://arxiv.org/abs/2311.08401" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1138" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Factuality.html" target="_blank" rel="noopener noreferrer">#Factuality</a>
<span class="issue_date">Issue Date: 2023-11-15</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、大規模な言語モデル（LLMs）を使用して、より事実に基づいた生成を実現するためのファインチューニングを行います。具体的には、外部の知識ベースや信頼スコアとの一貫性を測定し、選好最適化アルゴリズムを使用してモデルを調整します。実験結果では、事実エラー率の削減が観察されました。</span>
</article>
<article class="paper-entry">
<h3 id="zephyr-direct-1099" class="title-link">[Paper Note] Zephyr: Direct Distillation of LM Alignment, Lewis Tunstall+, arXiv'23, 2023.10</h3>
<br><a href="https://arxiv.org/abs/2310.16944" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1099" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<span class="issue_date">Issue Date: 2023-10-28</span>
<span class="snippet"><span>GPT Summary</span>- ユーザーの意図に沿った小型言語モデルを生成するため、AI Feedbackからの好みデータを用いて、意図の整合性を向上させるアプローチを提案。蒸留された直接的好み最適化を適用し、数時間のトレーニングで高性能なZephyr-7Bを実現。MT-BenchでLlama2-Chat-70Bを上回る結果を示し、コードやモデルは公開されている。</span>
<span class="snippet"><span>Comment</span><p>7BパラメータでLlaMa70Bと同等の性能を達成したZephyrの論文。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/1348b3c1-f70a-49b6-97c9-4a27bf7805fa" alt="image" loading="lazy" width="550" height="400"><br><br>- dSFT:既存データからpromptをサンプリングし、user,assistantのmulti turnの対話をLLMでシミュレーションしてデータ生成しSFT<br>- AIF:既存データからpromstをサンプリングし、異なる4つのLLMのレスポンスをGPT4でランクづけしたデータの活用<br>- dDPO: 既存データからpromptをサンプリングし、ベストなレスポンスとランダムにサンプリングしたレスポンスの活用<br><br>人手を一切介していない。<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/f2cd7b48-4036-49eb-bfb7-0ce3cc8a09b8" alt="image" loading="lazy" width="550" height="400"></p>
<p>Blog: 


<a href="https://huggingface.co/blog/Isamu136/understanding-zephyr" target="_blank" rel="noopener noreferrer">https://huggingface.co/blog/Isamu136/understanding-zephyr</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="neftune-noisy-1091" class="title-link">NEFTune: Noisy Embeddings Improve Instruction Finetuning, Neel Jain+, N_A, arXiv'23</h3>
<br><a href="https://arxiv.org/abs/2310.05914" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1091" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-10-26</span>
<span class="snippet"><span>GPT Summary</span>- 私たちは、言語モデルのファインチューニングを改善するために、ノイズを加えた埋め込みベクトルを使用する手法を提案します。この手法は、AlpacaEvalやEvol-Instructなどのデータセットで強力なベースラインを上回る性能を示しました。また、RLHFでトレーニングされたモデルにも適用可能です。</span>
<span class="snippet"><span>Comment</span><p>Alpacaデータでの性能向上が著しい。かなり重要論文な予感。後で読む。</p>
<p>HuggingFaceのTRLでサポートされている<br><br>


<a href="https://huggingface.co/docs/trl/sft_trainer" target="_blank" rel="noopener noreferrer">https://huggingface.co/docs/trl/sft_trainer</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="longlora-efficient-1045" class="title-link">LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models, Yukang Chen+, N_A, arXiv'23</h3>
<br><a href="https://arxiv.org/abs/2309.12307" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1045" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="QuestionAnswering.html" target="_blank" rel="noopener noreferrer">#QuestionAnswering</a>
<a class="button" href="LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-09-30</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、計算コストを制限しながら大規模言語モデル（LLMs）のコンテキストサイズを拡張する効率的なファインチューニング手法であるLongLoRAを提案します。従来の方法では、LLMsの長いコンテキストサイズでのトレーニングには高い計算コストとGPUリソースが必要でしたが、提案手法ではコンテキスト拡張を高速化し、非自明な計算コストの削減を実現します。また、パラメータ効率的なファインチューニング手法も再評価し、LongLoRAはさまざまなタスクで強力な実験結果を示しています。さらに、教師ありファインチューニングのためのデータセットであるLongQAも収集されました。</span>
<span class="snippet"><span>Comment</span><p># 概要<br><br>context長が大きい場合でも効率的にLoRAする手法。通常のLoRAではcontext lengthが大きくなるにつれてperplexityが大きくなってしまう。一方、通常のFinetuningではperplexityは高い性能を維持するが、計算コストとVRAMの消費量が膨大になってしまう。LongLoRAでは、perplexityを通常のFinetuningと同等に抑えつつ、VRAM消費量もLoRAと同等、かつより小さな計算量でFinetuningを実現している。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/fc3d17c7-b1ac-4741-9895-bce70cf0b356" alt="image" loading="lazy" width="550" height="400"><br><br><br><br># 手法概要<br><br>attentionをcontext length全体で計算するとinput長の二乗の計算量がかかるため、contextをいくつかのグループに分割しグループごとにattentionを計算することで計算量削減。さらに、グループ間のattentionの間の依存関係を捉えるために、グループをshiftさせて計算したものと最終的に組み合わせている。また、embedding, normalization layerもtrainableにしている。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/2b443a4c-73da-4610-8ee2-cccdeab21efa" alt="image" loading="lazy" width="550" height="400"><br><br></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="simple-synthetic-1038" class="title-link">Simple synthetic data reduces sycophancy in large language models, Jerry Wei+, N_A, arXiv'23</h3>
<br><a href="http://arxiv.org/abs/2308.03958" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1038" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="Sycophancy.html" target="_blank" rel="noopener noreferrer">#Sycophancy</a>
<span class="issue_date">Issue Date: 2023-09-10</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、機械学習モデルのおべっか行動を減らすための方法を提案しています。まず、言語モデルにおけるおべっか行動の普及度を調査し、その行動を減らすための合成データ介入を提案しています。具体的には、ユーザーの意見に対してモデルが頑健であることを促す合成データを使用し、モデルのファインチューニングを行います。これにより、おべっか行動を大幅に減らすことができます。提案手法の詳細は、https://github.com/google/sycophancy-intervention で確認できます。</span>
<span class="snippet"><span>Comment</span><p>LLMはユーザの好む回答をするように事前学習されるため、prompt中にユーザの意見が含まれていると、ユーザの意見に引っ張られ仮に不正解でもユーザの好む回答をしてしまう問題があることを示した。また、その対策として人工的にユーザの意見と、claimを独立させるように学習するためのデータセットを生成しFinetuningすることで防ぐことができることを示した。</p>
<p>誤ったユーザの意見を挿入すると、正解できていた問題でも不正解になることを示した。<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/43c03357-5c5c-4ceb-a089-0ad0a35eea1d" alt="image" loading="lazy" width="550" height="400"></p>
<p>この傾向は、instruction tuningしている場合、モデルサイズが大きい場合により顕著であることを示した。<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/6737eb30-7055-43d6-a1f4-d700be5963f2" alt="image" loading="lazy" width="550" height="400"></p>
<p><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/54458bc0-ba89-4b10-b6c1-baa70384abb9" alt="image" loading="lazy" width="550" height="400"><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7690e3b4-00e7-468a-a36f-7130f65669dc" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="prompt2model-generating-1024" class="title-link">[Paper Note] Prompt2Model: Generating Deployable Models from Natural Language Instructions, Vijay Viswanathan+, EMNLP'23 System Demonstrations, 2023.08</h3>
<br><a href="https://arxiv.org/abs/2308.12261" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1024" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="DataAugmentation.html" target="_blank" rel="noopener noreferrer">#DataAugmentation</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="System%20Demonstration.html" target="_blank" rel="noopener noreferrer">#System Demonstration</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2023-08-28</span>
<span class="snippet"><span>GPT Summary</span>- Prompt2Modelは、自然言語のタスク説明を基に特化型NLPモデルを訓練する手法で、LLMsの利点を活かしつつデプロイに適したモデルを生成します。既存のデータセットや事前学習済みモデルを活用し、データセット生成と教師ありファインチューニングを行うことで、同じfew-shotプロンプトでgpt-3.5-turboを平均20%上回る性能を持つ小型モデルを訓練可能です。信頼性のある性能推定も提供し、モデル開発者がデプロイ前に評価できるようにします。Prompt2Modelはオープンソースで公開されています。</span>
<span class="snippet"><span>Comment</span><p>Dataset Generatorによって、アノテーションが存在しないデータについても擬似ラベル付きデータを生成することができ、かつそれを既存のラベル付きデータと組み合わせることによってさらに性能が向上することが報告されている。これができるのはとても素晴らしい。</p>
<p>Dataset Generatorについては、データを作成する際に低コストで、高品質で、多様なデータとするためにいくつかの工夫を実施している。<br>1. ユーザが与えたデモンストレーションだけでなく、システムが生成したexampleもサンプリングして活用することで、生成されるexampleの多様性を向上させる。実際、これをやらない場合は120/200がduplicate exampleであったが、これが25/200まで減少した。<br>2. 生成したサンプルの数に比例して、temperatureを徐々に高くしていく。これにより、サンプルの質を担保しつつ、多様性を徐々に増加させることができる。Temperature Annealingと呼ぶ。<br>3. self-consistencyを用いて、擬似ラベルの質を高める。もしmajority votingが互角の場合は、回答が短いものを採用した（これはヒューリスティックに基づいている）<br>4. zeno buildを用いてAPIへのリクエストを並列化することで高速に実験を実施<br><br>非常に参考になる。</p>
<p>著者らによる現在の視点での振り返り（提案当時はAI Agentsという概念はまだなく、本研究はその先取りと言える）:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/vijaytarian/status/2010209181014601904?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="crosslingual-generalization-999" class="title-link">Crosslingual Generalization through Multitask Finetuning, Niklas Muennighoff+, N_A, ACL'23</h3>
<br><a href="https://arxiv.org/abs/2211.01786" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/999" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="MultitaskLearning.html" target="_blank" rel="noopener noreferrer">#MultitaskLearning</a>
<a class="button" href="Zero_Few_ManyShotPrompting.html" target="_blank" rel="noopener noreferrer">#Zero/Few/ManyShotPrompting</a>
<a class="button" href="CrossLingual.html" target="_blank" rel="noopener noreferrer">#CrossLingual</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="Generalization.html" target="_blank" rel="noopener noreferrer">#Generalization</a>
<span class="issue_date">Issue Date: 2023-08-16</span>
<span class="snippet"><span>GPT Summary</span>- マルチタスクプロンプトフィネチューニング（MTF）は、大規模な言語モデルが新しいタスクに汎化するのに役立つことが示されています。この研究では、マルチリンガルBLOOMとmT5モデルを使用してMTFを実施し、英語のプロンプトを使用して英語および非英語のタスクにフィネチューニングすることで、タスクの汎化が可能であることを示しました。さらに、機械翻訳されたプロンプトを使用してマルチリンガルなタスクにフィネチューニングすることも調査し、モデルのゼロショットの汎化能力を示しました。また、46言語の教師ありデータセットのコンポジットであるxP3も紹介されています。</span>
<span class="snippet"><span>Comment</span><p>英語タスクを英語でpromptingしてLLMをFinetuningすると、他の言語（ただし、事前学習で利用したコーパスに出現する言語に限る）で汎化し性能が向上することを示した模様。<br>![Image](https://github.com/user-attachments/assets/44e9cf6e-e80f-4092-af46-ad74c30fe59c)</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="qlora-efficient-881" class="title-link">QLoRA: Efficient Finetuning of Quantized LLMs, Tim Dettmers+, N_A, NeurIPS'23</h3>
<br><a href="https://arxiv.org/abs/2305.14314" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/881" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<span class="snippet"><span>GPT Summary</span>- 私たちは、QLoRAという効率的なファインチューニング手法を提案します。この手法は、メモリ使用量を削減し、48GBの単一のGPU上で65Bパラメータモデルをファインチューニングすることができます。また、16ビットのファインチューニングタスクのパフォーマンスを維持します。QLoRAは、凍結された4ビット量子化された事前学習済み言語モデルの勾配をLow Rank Adapters（LoRA）に逆伝播させます。私たちの最良のモデルファミリーであるGuanacoは、Vicunaベンチマークで以前に公開されたすべてのモデルを上回り、ChatGPTのパフォーマンスレベルの99.3%に達します。また、単一のGPU上でのファインチューニングには24時間しかかかりません。QLoRAは、パフォーマンスを犠牲にすることなくメモリを節約するためのいくつかの革新を導入しています。具体的には、4ビットNormalFloat（NF4）という情報理論的に最適な新しいデータ型、ダブル量子化による平均メモリフットプリントの削減、およびページドオプティマイザによるメモリスパイクの管理です。私たちはQLoRAを使用して1,000以上のモデルをファインチューニングし、8つの命令データセット、複数のモデルタイプ（LLaMA、T5）、および従来のファインチューニングでは実行不可能なモデルスケール（33Bおよび65Bパラメータモデル）にわたる命令の追跡とチャットボットのパフォーマンスの詳細な分析を提供します。私たちの結果は、QLoRAを使用して小規模な高品質のデータセットでのファインチューニングが、以前のSoTAよりも小さいモデルを使用しても最先端の結果をもたらすことを示しています。また、人間の評価とGPT-4の評価に基づいたチャットボットのパフォーマンスの詳細な分析を提供し、GPT-4の評価が安価で合理的な人間の評価の代替手段であることを示します。さらに、現在のチャットボットのベンチマークは、チャットボットのパフォーマンスレベルを正確に評価するためには信頼性がないことがわかります。GuanacoがChatGPTと比較してどこで失敗するかを示す分析も行っています。私たちは、4ビットトレーニングのためのCUDAカーネルを含む、すべてのモデルとコードを公開しています。</span>
<span class="snippet"><span>Comment</span><p>実装: 


<a href="https://github.com/artidoro/qlora" target="_blank" rel="noopener noreferrer">https://github.com/artidoro/qlora</a>


<br>PEFTにもある</p>
<p>参考: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1662946722690236417?s=46&t=TDHYK31QiXKxggPzhZbcAQ"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>OpenReview:


<a href="https://openreview.net/forum?id=OUIFPHEgJU&referrer=%5Bthe%20profile%20of%20Ari%20Holtzman%5D(%2Fprofile%3Fid%3D~Ari_Holtzman1)" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=OUIFPHEgJU&referrer=%5Bthe%20profile%20of%20Ari%20Holtzman%5D(%2Fprofile%3Fid%3D~Ari_Holtzman1)</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="measuring-the-823" class="title-link">Measuring the Instability of Fine-Tuning, ACL'23</h3>
<br><a href="https://virtual2023.aclweb.org/paper_P5653.html" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/823" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<span class="issue_date">Issue Date: 2023-07-14</span>
<span class="snippet"><span>GPT Summary</span>- 事前学習済み言語モデルのファインチューニングは小規模データセットでは不安定であることが示されている。本研究では、不安定性を定量化する指標を分析し、評価フレームワークを提案する。また、既存の不安定性軽減手法を再評価し、結果を提供する。</span>
</article>
<article class="paper-entry">
<h3 id="full-parameter-769" class="title-link">Full Parameter Fine-tuning for Large Language Models with Limited  Resources, Kai Lv+, N_A, arXiv'23</h3>
<br><a href="https://arxiv.org/abs/2306.09782" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/769" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-06-26</span>
<span class="snippet"><span>GPT Summary</span>- LLMsのトレーニングには膨大なGPUリソースが必要であり、既存のアプローチは限られたリソースでの全パラメーターの調整に対処していない。本研究では、LOMOという新しい最適化手法を提案し、メモリ使用量を削減することで、8つのRTX 3090を搭載した単一のマシンで65Bモデルの全パラメーターファインチューニングが可能になる。</span>
<span class="snippet"><span>Comment</span><p>8xRTX3090 24GBのマシンで65Bモデルの全パラメータをファインチューニングできる手法。LoRAのような（新たに追加しれた）一部の重みをアップデートするような枠組みではない。勾配計算とパラメータのアップデートをone stepで実施することで実現しているとのこと。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="one-for-all-generalized-725" class="title-link">One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning, Arnav Chavan+, N_A, arXiv'23</h3>
<br><a href="https://arxiv.org/abs//2306.07967" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/725" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-06-16</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、汎用的なファインチューニングタスクのための高度な手法であるGeneralized LoRA (GLoRA)を提案し、事前学習済みモデルの重みを最適化し、中間アクティベーションを調整することで、多様なタスクとデータセットに対してより柔軟性と能力を提供する。GLoRAは、各レイヤーの個別のアダプタを学習するスケーラブルでモジュラーなレイヤーごとの構造探索を採用することで、効率的なパラメータの適応を促進する。包括的な実験により、GLoRAは、自然言語、専門分野、構造化ベンチマークにおいて、従来のすべての手法を上回り、様々なデータセットでより少ないパラメータと計算で優れた精度を達成することが示された。</span>
<span class="snippet"><span>Comment</span><p>OpenReview:


<a href="https://openreview.net/forum?id=K7KQkiHanD" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=K7KQkiHanD</a>


<br><br>ICLR'24にrejectされている</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="lima-less-700" class="title-link">LIMA: Less Is More for Alignment, Chunting Zhou+, N_A, NeurIPS'23</h3>
<br><a href="https://arxiv.org/abs/2305.11206" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/700" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="DataDistillation.html" target="_blank" rel="noopener noreferrer">#DataDistillation</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-05-22</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、65BパラメータのLLaMa言語モデルであるLIMAを訓練し、強化学習や人間の好みモデリングなしに、厳選された1,000のプロンプトとレスポンスのみで標準的な教師あり損失で微調整しました。LIMAは、幅広いクエリに対応する驚くべき強力なパフォーマンスを示し、トレーニングデータに現れなかった未知のタスクにも一般化する傾向があります。制御された人間の研究では、LIMAのレスポンスは、GPT-4、Bard、DaVinci003と比較して優れていることが示されました。これらの結果から、大規模言語モデルのほとんどの知識は事前トレーニング中に学習され、高品質の出力を生成するためには限られた指示調整データしか必要ないことが示唆されます。</span>
<span class="snippet"><span>Comment</span><p>LLaMA65Bをたった1kのdata point（厳選された物）でRLHF無しでfinetuningすると、旅行プランの作成や、歴史改変の推測（？）幅広いタスクで高いパフォーマンスを示し、未知のタスクへの汎化能力も示した。最終的にGPT3,4,BARD,CLAUDEよりも人間が好む回答を返した。<br><br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/db025381-0bf0-47a3-bd18-5d88bff666df" alt="image" loading="lazy" width="550" height="400"></p>
<p>LLaMAのようなオープンでパラメータ数が少ないモデルに対して、少量のサンプルでfinetuningするとGPT4に迫れるというのはgamechangerになる可能性がある</p>
<p>openreview: 


<a href="https://openreview.net/forum?id=KBMOKmX2he" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=KBMOKmX2he</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="symbol-tuning-699" class="title-link">Symbol tuning improves in-context learning in language models, Jerry Wei+, N_A, EMNLP'23</h3>
<br><a href="http://arxiv.org/abs/2305.08298" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/699" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="EMNLP.html" target="_blank" rel="noopener noreferrer">#EMNLP</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-05-21</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、自然言語ラベルをシンボルに置き換えて言語モデルを微調整する「symbol tuning」を提案し、未知のタスクや不明確なプロンプトに対して堅牢な性能を示すことを示した。また、symbol tuningによりアルゴリズム的推論タスクでのパフォーマンス向上が見られ、以前の意味的知識を上書きする能力が向上していることが示された。Flan-PaLMモデルを使用して実験が行われ、最大540Bパラメータまで利用された。</span>
<span class="snippet"><span>Comment</span><p>概要やOpenReviewの内容をざっくりとしか読めていないが、自然言語のラベルをランダムな文字列にしたり、instructionをあえて除外してモデルをFinetuningすることで、promptに対するsensitivityや元々モデルが持っているラベルと矛盾した意味をin context learningで上書きできるということは、学習データに含まれるテキストを調整することで、正則化の役割を果たしていると考えられる。つまり、ラベルそのものに自然言語としての意味を含ませないことや、instructionを無くすことで、（モデルが表層的なラベルの意味や指示からではなく）、より実際のICLで利用されるExaplarからタスクを推論するように学習されるのだと思われる。<br><img src="https://github.com/user-attachments/assets/a4050a09-d319-481d-9b63-70b2ee9b5aad" alt="image" loading="lazy" width="550" height="400"></p>
<p>OpenReview:


<a href="https://openreview.net/forum?id=vOX7Dfwo3v" target="_blank" rel="noopener noreferrer">https://openreview.net/forum?id=vOX7Dfwo3v</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="controlled-text-594" class="title-link">[Paper Note] Controlled Text Generation with Natural Language Instructions, Wangchunshu Zhou+, ICML'23, 2023.04</h3>
<br><a href="https://arxiv.org/abs/2304.14293" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/594" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="Controllable.html" target="_blank" rel="noopener noreferrer">#Controllable</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="Prompting.html" target="_blank" rel="noopener noreferrer">#Prompting</a>
<a class="button" href="SyntheticData.html" target="_blank" rel="noopener noreferrer">#SyntheticData</a>
<a class="button" href="In-ContextLearning.html" target="_blank" rel="noopener noreferrer">#In-ContextLearning</a>
<a class="button" href="ICML.html" target="_blank" rel="noopener noreferrer">#ICML</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2023-04-30</span>
<span class="snippet"><span>GPT Summary</span>- 自然言語の指示に従い、多様なタスクを解決可能な大規模言語モデルの制御を改善するために、「InstructCTG」というフレームワークを提案。自然テキストの制約を抽出し、これを自然言語の指示に変換することで弱教師あり訓練データを形成。異なるタイプの制約に柔軟に対応し、生成の質や速度への影響を最小限に抑えつつ、再訓練なしで新しい制約に適応できる能力を持つ。</span>
<span class="snippet"><span>Comment</span><p>制約に関する指示とデモンスとレーションに関するデータを合成して追加のinstruction tuningを実施することで、promptで指示された制約を満たすような（controllableな）テキストの生成能力を高める手法</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="self-instruct-aligning-513" class="title-link">[Paper Note] Self-Instruct: Aligning Language Models with Self-Generated Instructions, Yizhong Wang+, ACL'23, 2022.12</h3>
<br><a href="https://arxiv.org/abs/2212.10560" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/513" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="In-Depth%20Notes.html" target="_blank" rel="noopener noreferrer">#In-Depth Notes</a>
<span class="issue_date">Issue Date: 2023-03-30</span>
<span class="snippet"><span>GPT Summary</span>- Self-Instructフレームワークを提案し、事前学習済みの言語モデルが自ら生成した指示を用いてファインチューニングを行うことで、ゼロショットの一般化能力を向上させる。バニラGPT-3に適用した結果、Super-NaturalInstructionsで33%の性能向上を達成し、InstructGPT-001と同等の性能に到達。人間評価により、Self-Instructが既存の公共指示データセットよりも優れていることを示し、ほぼ注釈不要の指示調整手法を提供。大規模な合成データセットを公開し、今後の研究を促進する。</span>
<span class="snippet"><span>Comment</span><p>Alpacaなどでも利用されているself-instruction技術に関する論文</p>
<p># 概要<br><br><img src="https://user-images.githubusercontent.com/12249301/228716254-5f4d7451-a37a-4354-843d-7e4052ba230b.png" alt="image" loading="lazy" width="550" height="400"><br><br><br><br>著者らが書いた175種のinstruction（タスクの定義 + 1種のinput/outputペア}のseedを元に、VanillaなGPT-3に新たなinstruction, input, outputのtupleを生成させ、学習データとして活用する研究。<br><br>ここで、instruction data I は以下のように定義される：<br><br>instruction dataは(I, X, Y)であり、モデルは最終的にM(I_t, x_t) = y_tとなるように学習したい。<br><br>I: instruction, X: input, Y: output<br><br><br><br>データ作成は以下のステップで構成される。なお、以下はすべてVanilla GPT-3を通じて行われる：<br><br>1. Instruction Generation<br><br>　task poolから8種類のinstructionを抽出し、 promptを構成し、最大8個新たなinstructionを生成させる<br><br>2. Classification Task Identification:<br><br>　生成されたinstructionがclassificationタスクか否かを判別する<br><br>3. Instance Generation<br><br>　いくつかの(I, X, Y)をpromptとして与え、I, Xに対応するYを生成するタスクを実行させる。このときinput-first approachを採用した結果（I-&gt;Xの順番で情報を与えYを生成するアプローチ）、特定のラベルに偏ったインスタンスが生成される傾向があることがわかった。このためoutput-first approachを別途採用し（I-&gt;Yの順番で情報を与え、各Yに対応するXを生成させる）、活用している。　<br><br>4. Filtering and Postprocessing<br><br>　最後に、既存のtask poolとROUGE-Lが0.7以上のinstructionは多様性がないため除外し、特定のキーワード（images, pictrues, graphs）等を含んでいるinstruction dataも除外して、task poolに追加する。<br><br><br><br>1-4をひたすら繰り返すことで、GPT-3がInstruction Tuningのためのデータを自動生成してくれる。<br><br><br><br># SELF-INSTRUCT Data<br><br>## データセットの統計量<br><br><img src="https://user-images.githubusercontent.com/12249301/228745059-ecccadba-3e32-4f2a-9594-2459a922474b.png" alt="image" loading="lazy" width="550" height="400"><br><br>- 52k instructions<br><br>- 82k instances<br><br><br><br>## Diversity<br><br><img src="https://user-images.githubusercontent.com/12249301/228745421-ba024963-ca6e-4e30-bac8-7224d413f8ab.png" alt="image" loading="lazy" width="550" height="400"><br><br>parserでinstructionを解析し、rootの名詞と動詞のペアを抽出して可視化した例。ただし、抽出できた例はたかだか全体の50%程度であり、その中で20の最もcommonなroot vertと4つのnounを可視化した。これはデータセット全体の14%程度しか可視化されていないが、これだけでも非常に多様なinstructionが集まっていることがわかる。<br><br>また、seed indstructionとROUGE-Lを測った結果、大半のデータは0.3~0.4程度であり、lexicalなoverlapはあまり大きくないことがわかる。instructionのlengthについても可視化した結果、多様な長さのinstructionが収集できている。<br><br><br><br>## Quality<br><br>200種類のinstructionを抽出し、その中からそれぞれランダムで1つのインスタンスをサンプルした。そしてexpert annotatorに対して、それぞれのinstructionとinstance（input, outputそれぞれについて）が正しいか否かをラベル付けしてもらった。<br><br>ラベル付けの結果、ほとんどのinstructionは意味のあるinstructionであることがわかった。一方、生成されたinstanceはnoisyであることがわかった（ただし、このnoiseはある程度妥当な範囲である）。noisytではあるのだが、instanceを見ると、正しいformatであったり、部分的に正しかったりなど、modelを訓練する上で有用なguidanceを提供するものになっていることがわかった。<br><br><img src="https://user-images.githubusercontent.com/12249301/228746299-a0ffc115-3861-458b-a7b4-3a91ac94f8f5.png" alt="image" loading="lazy" width="550" height="400"><br><br><br><br># Experimental Results<br><br>## Zero-shotでのNLPタスクに対する性能<br><br>SuperNIデータセットに含まれる119のタスク（1タスクあたり100 instance）に対して、zero-shot setupで評価を行なった。SELF-INSTRUCTによって、VanillaのGPT3から大幅に性能が向上していることがわかる。VanillaのGPT-3はほとんど人間のinstructionに応じて動いてくれないことがわかる。分析によると、GPT3は、大抵の場合、全く関係ない、あるいは繰り返しのテキストを生成していたり、そもそもいつ生成をstopするかがわかっていないことがわかった。<br><br><br><br>また、SuperNI向けにfinetuningされていないモデル間で比較した結果、非常にアノテーションコストをかけて作られたT0データでfinetuningされたモデルよりも高い性能を獲得した。また、人間がラベル付したprivateなデータによって訓練されたInstructGPT001にも性能が肉薄していることも特筆すべき点である。<br><br><br><br>SuperNIでfinetuningした場合については、SELF-INSTRUCTを使ったモデルに対して、さらに追加でSuperNIを与えた場合が最も高い性能を示した。<br><br><img src="https://user-images.githubusercontent.com/12249301/228751534-095578e0-550b-4e4c-9418-c74251e31d2a.png" alt="image" loading="lazy" width="550" height="400"><br><br><br><br>## User-Oriented Instructionsに対する汎化性能<br><br>SuperNIに含まれるNLPタスクは研究目的で提案されており分類問題となっている。ので、実践的な能力を証明するために、LLMが役立つドメインをブレスト（email writing, social media, productiveity tools, entertainment, programming等）し、それぞれのドメインに対して、instructionとinput-output instanceを作成した。また、instructionのスタイルにも多様性（e.g. instructionがlong/short、bullet points, table, codes, equationsをinput/outputとして持つ、など）を持たせた。作成した結果、252個のinstructionに対して、1つのinstanceのデータセットが作成された。これらが、モデルにとってunfamiliarなinstructionで多様なistructionが与えられたときに、どれだけモデルがそれらをhandleできるかを測定するテストベッドになると考えている。<br><br><br><br>これらのデータは、多様だがどれもが専門性を求められるものであり、自動評価指標で性能が測定できるものでもないし、crowdworkerが良し悪しを判定できるものでもない。このため、それぞれのinstructionに対するauthorに対して、モデルのy補足結果が妥当か否かをjudgeしてもらった。judgeは4-scaleでのratingとなっている：<br><br><br><br>- RATING-A: 応答は妥当で満足できる<br><br>- RATING-B: 応答は許容できるが、改善できるminor errorや不完全さがある。<br><br>- RATING-C: 応答はrelevantでinstructionに対して答えている。が、内容に大きなエラーがある。<br><br>- RATING-D: 応答はirrelevantで妥当ではない。<br><br><br><br>実験結果をみると、Vanilla GPT3はまったくinstructionに対して答えられていない。instruction-basedなモデルは高いパフォーマンスを発揮しているが、それらを上回る性能をSELF-INSTRUCTは発揮している（noisyであるにもかかわらず）。<br><br>また、GPT_SELF-INSTRUCTはInstructGPT001と性能が肉薄している。また、InstructGPT002, 003の素晴らしい性能を示すことにもなった。<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/228755556-1c604ed8-11a5-4237-8f9c-a30960db807a.png" alt="image" loading="lazy" width="550" height="400"><br><br><br><br># Discussion and Limitation<br><br>## なぜSELF-INSTRUCTがうまくいったか？<br><br>- LMに対する2つの極端な仮説を挙げている<br><br>  - LM はpre-trainingでは十分に学習されなかった問題について学習する必要があるため、human feedbackはinstruction-tuningにおいて必要不可欠な側面である<br><br>  - LM はpre-trainingからinstructionに既に精通しているため、human feedbackはinstruction-tuningにおいて必須ではない。 human feedbackを観察することは、pre-trainingにおける分布/目的を調整するための軽量なプロセスにすぎず、別のプロセスに置き換えることができる。<br><br><br><br>この2つの極端な仮説の間が実情であると筆者は考えていて、どちらかというと２つ目の仮説に近いだろう、と考えている。既にLMはpre-trainingの段階でinstructionについてある程度理解できているため、self-instructがうまくいったのではないかと推察している。<br><br><br><br>## Broader Impact<br><br>InstructGPTは非常に強力なモデルだけど詳細が公表されておらず、APIの裏側に隠れている。この研究が、instruct-tuned modelの背後で何が起きているかについて、透明性を高める助けになると考えている。産業で開発されたモデルの構造や、その優れた性能の理由についてはほとんど理解されておらず、これらのモデルの成功の源泉を理解し、より優れた、オープンなモデルを作成するのはアカデミックにかかっている。この研究では、多様なinstructional dataの重要性を示していると考えており、大規模な人工的なデータセットは、より優れたinstructionに従うモデルを、構築するための第一歩だと考えている。<br><br><br><br>## limitation<br><br>- Tail Phenomena<br><br>  - LMの枠組みにとどまっているため、LMと同じ問題（Tail Phenomena）を抱えている<br><br>  - low-frequencyなcontextに対してはうまくいかない問題<br><br>  - SELF-INSTRUCTも、結局pre-trainingの段階で頻出するタスクやinstructionに対してgainがあると考えられ、一般的でなく、creativeなinstructionに対して脆弱性があると考えられる<br><br>- Dependence on laege models<br><br>  - でかいモデルを扱えるだけのresourceを持っていないと使えないという問題がある<br><br>- Reinforcing LM biases<br><br>  - アルゴリズムのiterationによって、問題のあるsocial _biasをより増幅してしまうことを懸念している（人種、種族などに対する偏見など）。また、アルゴリズムはバランスの取れたラベルを生成することが難しい。</p>
<p>1のprompt<br><br><img src="https://user-images.githubusercontent.com/12249301/228717376-62648df4-e587-49f7-8e71-afd1b2269e90.png" alt="image" loading="lazy" width="550" height="400"><br><br>2のprompt<br><br><img src="https://user-images.githubusercontent.com/12249301/228717413-115f8ccf-b85e-4530-b489-cbf1de69341b.png" alt="image" loading="lazy" width="550" height="400"><br><br>3のprompt（input-first-approach）<br><br><img src="https://user-images.githubusercontent.com/12249301/228717477-58b44a4e-ce44-452f-9b3a-4a348584e40f.png" alt="image" loading="lazy" width="550" height="400"><br><br>3のprompt（output-first approach）<br><br><img src="https://user-images.githubusercontent.com/12249301/228717535-8717405c-bdaf-455c-9d4b-480bf6494abe.png" alt="image" loading="lazy" width="550" height="400"></p>
<p>※ GPT3をfinetuningするのに、Instruction Dataを使った場合$338かかったっぽい。安い・・・。</p>
<p>LLMを使うだけでここまで研究ができる時代がきた</p>
<p>（最近は|現在は）プロプライエタリなLLMの出力を利用して競合するモデルを訓練することは多くの場合禁止されているので注意。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="reflexion-language-512" class="title-link">Reflexion: Language Agents with Verbal Reinforcement Learning, Noah Shinn+, N_A, NeurIPS'23</h3>
<br><a href="https://arxiv.org/abs/2303.11366" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/512" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="NeurIPS.html" target="_blank" rel="noopener noreferrer">#NeurIPS</a>
<span class="issue_date">Issue Date: 2023-03-28</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、言語エージェントを強化するための新しいフレームワークであるReflexionを提案しています。Reflexionエージェントは、言語的フィードバックを通じて自己反省し、より良い意思決定を促すために反省的なテキストを保持します。Reflexionはさまざまなタスクでベースラインエージェントに比べて大幅な改善を実現し、従来の最先端のGPT-4を上回る精度を達成しました。さらに、異なるフィードバック信号や統合方法、エージェントタイプの研究を行い、パフォーマンスへの影響についての洞察を提供しています。</span>
<span class="snippet"><span>Comment</span><p>なぜ回答を間違えたのか自己反省させることでパフォーマンスを向上させる研究</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="constitutional-ai-2903" class="title-link">[Paper Note] Constitutional AI: Harmlessness from AI Feedback, Yuntao Bai+, arXiv'22</h3>
<br><a href="https://arxiv.org/abs/2212.08073" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2903" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Safety.html" target="_blank" rel="noopener noreferrer">#Safety</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="PseudoLabeling.html" target="_blank" rel="noopener noreferrer">#PseudoLabeling</a>
<span class="issue_date">Issue Date: 2025-09-20</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、「憲法的AI」を用いて、人間のラベルなしで無害なAIを訓練する方法を提案。監視学習と強化学習の2フェーズを経て、自己批評と修正を通じてモデルを微調整し、嗜好モデルを報酬信号として強化学習を行う。これにより、有害なクエリに対しても対話できる無害なAIアシスタントを実現し、AIの意思決定の透明性を向上させる。</span>
<span class="snippet"><span>Comment</span><p>（部分的にしか読めていないが）<br>有害なpromptに対してLLMに初期の応答を生成させ、iterativeにcritiqueとrevisionを繰り返して[^1]、より無害な応答を生成。この方法ではiterationをしながら生成結果が改定されていくので、後段のReward Modelのための嗜好データを生成するフェーズでトークン量を節約するために、生成されたより無害な応答と元となるpromptを用いて、ベースモデルをSFT。これによりベースモデルの出力分布がより無害な応答をするような方向性に調整され、かつ（iterationを繰り返すことなく）直接的により無害な応答を生成できるようになるのでtoken量が節約できる。このフェーズで学習したモデルをSL-CAIと呼ぶ。<br><br>続いて、SL-CAIに対して同様の有害なpromptを入力して、複数の応答を生成させる。生成された応答をMultiple Choice Questionの形式にし、Constitutional Principleに基づくpromptingにより、最も望ましい応答をLLMによって選択させることで、嗜好データを獲得する。この嗜好データ（と人手で定義されたhelpfulnessに基づくデータ）を用いてReward Modelを訓練しRLを実施する。<br><br>この手法は、嗜好データを人間がラベリングするのではなく、AIによるフィードバックによりラベリングするため、Reinforcement Learning from AI Feedback (RLAIF)と呼ばれる。<br><br>Harmfulness以外の分野にも応用可能と考えられる。<br><br><img src="https://github.com/user-attachments/assets/72305618-d397-4471-8648-7771d371ca43" alt="image" loading="lazy" width="550" height="400"><br><br>[^1]: この操作はモデルの望ましい挙動を人手で定義したルーブリックに基づいた複数のprompt (Constitutional Principles) を用いて実施される。具体的なpromptはAppendix Cを参照。</p>
<p>先行研究:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2902" target="_blank" rel="noopener noreferrer">[Paper Note] Training a Helpful and Harmless Assistant with Reinforcement Learning
  from Human Feedback, Yuntao Bai+, arXiv'22</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="super-naturalinstructions-generalization-1474" class="title-link">Super-NaturalInstructions: Generalization via Declarative Instructions  on 1600+ NLP Tasks, Yizhong Wang+, N_A, EMNLP'22</h3>
<br><a href="https://arxiv.org/pdf/2204.07705" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1474" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2024-10-29</span>
<span class="snippet"><span>GPT Summary</span>- Super-NaturalInstructionsを用いて、NLPモデルの未見タスクへの一般化能力を評価。1,616の多様なタスクと指示を含むベンチマークを作成し、76種類のタスクタイプをカバー。Tk-Instructモデルは、指示に従う訓練を受け、InstructGPTを9%以上上回る性能を示す。一般化能力をスケーリングパラメータに基づいて分析し、汎用的なNLPモデルの進展を促進することを目指す。</span>
<span class="snippet"><span>Comment</span><p>7.1, 7.2が最も興味深い<br><br><br><br>## Instruction Tuningにおける未知のタスクに対する汎化性能について、3つの要素に対するスケーリングについて考察<br><br>- More observed tasks improve the generalization.<br><br>- A large number of training instances do not help generalization.<br><br>- Tuning larger models with instructions consistently lead to gains.<br><br><br><br>## Instructionをさまざまに変化させた時の性能の変化に対する分析<br><br>Table4の対角成分に注目すると（trainとtestのinput encodingを揃えた場合）<br><br>- Task definitionをinstructionに含めることで未知タスクに対する汎化性能向上<br><br>- Task Definitionとpositive examplesを4つ程度入れると汎化性能向上。<br><br>  - ただし、これ以上exampleを増やすと性能低下。<br><br>  - negative examplesを入れることは性能に a little bit しか貢献しない<br><br>  - explanationsを入れると性能が低下する<br><br><br><br>Table4の非対角成分に着目すると、<br><br>- Task Definitionのみで訓練しても、Example onlyのtest時のencodingには汎化しない（逆も然り）<br><br>- Task Definition + examples (今回の場合はpositive examples4つ)は、さまざまなtest時のinput encodingsに対してロバストになる<br><br> <br><br><img src="https://github.com/user-attachments/assets/3bd1d07d-feb0-4567-bad9-8920c2d82359" alt="image" loading="lazy" width="550" height="400"><br><br></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="finetuned-language-1413" class="title-link">Finetuned Language Models Are Zero-Shot Learners, Jason Wei+, N_A, ICLR'22</h3>
<br><a href="https://arxiv.org/pdf/2109.01652" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1413" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2024-09-25</span>
<span class="snippet"><span>GPT Summary</span>- 指示チューニングを用いて言語モデルのゼロショット学習能力を向上させる方法を提案。137BパラメータのモデルFLANは、60以上のNLPタスクでファインチューニングされ、未見のタスクで175B GPT-3を上回るパフォーマンスを示す。アブレーションスタディにより、ファインチューニングデータセットの数やモデルのスケールが成功に寄与することが確認された。</span>
<span class="snippet"><span>Comment</span><p>FLAN論文。Instruction Tuningを提案した研究。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="fine-tuning-can-681" class="title-link">Fine-Tuning can Distort Pretrained Features and Underperform   Out-of-Distribution, Ananya Kumar+, N_A, ICLR'22</h3>
<br><a href="https://arxiv.org/abs/2202.10054" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/681" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="CLIP.html" target="_blank" rel="noopener noreferrer">#CLIP</a>
<a class="button" href="ICLR.html" target="_blank" rel="noopener noreferrer">#ICLR</a>
<a class="button" href="OOD.html" target="_blank" rel="noopener noreferrer">#OOD</a>
<span class="issue_date">Issue Date: 2023-05-15</span>
<span class="snippet"><span>GPT Summary</span>- 事前学習済みモデルをダウンストリームタスクに転移する際、ファインチューニングと線形プロービングの2つの方法があるが、本研究では、分布のシフトが大きい場合、ファインチューニングが線形プロービングよりも分布外で精度が低くなることを発見した。LP-FTという2段階戦略の線形プロービング後の全体のファインチューニングが、両方のデータセットでファインチューニングと線形プロービングを上回ることを示唆している。</span>
<span class="snippet"><span>Comment</span><p>事前学習済みのニューラルモデルをfinetuningする方法は大きく分けて<br>1. linear layerをヘッドとしてconcatしヘッドのみのパラメータを学習<br>2. 事前学習済みモデル全パラメータを学習<br><br>の2種類がある。<br>前者はin-distributionデータに強いが、out-of-distributionに弱い。後者は逆という互いが互いを補完し合う関係にあった。<br>そこで、まず1を実施し、その後2を実施する手法を提案。in-distribution, out-of-distributionの両方で高い性能を出すことを示した（実験では画像処理系のデータを用いて、モデルとしてはImageNet+CLIPで事前学習済みのViTを用いている)。<br><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/059d9056-bd3c-45f2-abd9-00c9f2a3d630" alt="image" loading="lazy" width="550" height="400"></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="training-verifiers-1618" class="title-link">Training Verifiers to Solve Math Word Problems, Karl Cobbe+, arXiv'21</h3>
<br><a href="https://arxiv.org/abs/2110.14168" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1618" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="Verification.html" target="_blank" rel="noopener noreferrer">#Verification</a>
<span class="issue_date">Issue Date: 2024-12-27</span>
<span class="snippet"><span>GPT Summary</span>- GSM8Kデータセットを用いて、多段階の数学的推論における言語モデルの限界を分析。検証器を訓練し、候補解を評価して最適解を選択することで、モデルのパフォーマンスを大幅に向上させることを示した。検証はファインチューニングよりもデータ増加に対して効果的にスケールする。</span>
<span class="snippet"><span>Comment</span><p>## 気持ち<br><br>- 当時の最も大きいレベルのモデルでも multi-stepのreasoningが必要な問題は失敗する<br><br>- モデルをFinetuningをしても致命的なミスが含まれる<br><br>- 特に、数学は個々のミスに対して非常にsensitiveであり、一回ミスをして異なる解法のパスに入ってしまうと、self-correctionするメカニズムがauto-regressiveなモデルではうまくいかない<br><br>- 純粋なテキスト生成の枠組みでそれなりの性能に到達しようとすると、とんでもないパラメータ数が必要になり、より良いscaling lawを示す手法を模索する必要がある<br><br>## Contribution<br><br>論文の貢献は<br><br>- GSM8Kを提案し、<br><br>- verifierを活用しモデルの複数の候補の中から良い候補を選ぶフレームワークによって、モデルのパラメータを30倍にしたのと同等のパフォーマンスを達成し、データを増やすとverifierを導入するとよりよく性能がスケールすることを示した。<br><br>- また、dropoutが非常に強い正則化作用を促し、finetuningとverificationの双方を大きく改善することを示した。</p>
<p>Todo: 続きをまとめる</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-power-473" class="title-link">[Paper Note] The Power of Scale for Parameter-Efficient Prompt Tuning, Brian Lester+, arXiv'21, 2021.04</h3>
<br><a href="https://arxiv.org/abs/2104.08691" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/473" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2022-08-19</span>
<span class="snippet"><span>GPT Summary</span>- 本研究では、凍結された言語モデルを特定のタスクに適応させるための「ソフトプロンプト」を学習するプロンプトチューニング手法を提案。逆伝播を通じて学習されるソフトプロンプトは、GPT-3の少数ショット学習を上回る性能を示し、モデルサイズが大きくなるほど競争力が増すことが確認された。特に、数十億のパラメータを持つモデルにおいて、全ての重みを調整するモデルチューニングに匹敵する性能を発揮。これにより、1つの凍結モデルを複数のタスクに再利用できる可能性が示唆され、ドメイン転送に対するロバスト性も向上することが明らかとなった。</span>
<span class="snippet"><span>Comment</span><p>日本語解説: 


<a href="https://qiita.com/kts_plea/items/79ffbef685d362a7b6ce" target="_blank" rel="noopener noreferrer">https://qiita.com/kts_plea/items/79ffbef685d362a7b6ce</a>


<br><br>T5のような大規模言語モデルに対してfinetuningをかける際に、大規模言語モデルのパラメータは凍結し、promptをembeddingするパラメータを独立して学習する手法<br><br>言語モデルのパラメータ数が増加するにつれ、言語モデルそのものをfinetuningした場合（Model Tuning）と同等の性能を示した。</p>
<p>いわゆる(Softな) Prompt Tuning</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="prefix-tuning-optimizing-405" class="title-link">[Paper Note] Prefix-Tuning: Optimizing Continuous Prompts for Generation, Xiang Lisa Li+, arXiv'21, 2021.01</h3>
<br><a href="https://arxiv.org/abs/2101.00190" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/405" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="DocumentSummarization.html" target="_blank" rel="noopener noreferrer">#DocumentSummarization</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="NaturalLanguageGeneration.html" target="_blank" rel="noopener noreferrer">#NaturalLanguageGeneration</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="ACL.html" target="_blank" rel="noopener noreferrer">#ACL</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2021-09-09</span>
<span class="snippet"><span>GPT Summary</span>- プレフィックスチューニングは、ファインチューニングの軽量な代替手段であり、言語モデルのパラメータを固定しつつ、タスク特有の小さなベクトルを最適化する手法です。これにより、少ないパラメータで同等のパフォーマンスを達成し、低データ設定でもファインチューニングを上回る結果を示しました。</span>
<span class="snippet"><span>Comment</span><p>言語モデルをfine-tuningする際，エンコード時に「接頭辞」を潜在表現として与え，「接頭辞」部分のみをfine-tuningすることで（他パラメータは固定），より少量のパラメータでfine-tuningを実現する方法を提案．接頭辞を潜在表現で与えるこの方法は，GPT-3のpromptingに着想を得ている．fine-tuningされた接頭辞の潜在表現のみを配布すれば良いので，非常に少量なパラメータでfine-tuningができる．<br><br><br><br>table-to-text, summarizationタスクで，一般的なfine-tuningやAdapter（レイヤーの間にアダプターを挿入しそのパラメータだけをチューニングする手法）といった効率的なfine-tuning手法と比較．table-to-textでは、250k (元のモデルの 0.1%) ほどの数のパラメータを微調整するだけで、全パラメータをfine-tuningするのに匹敵もしくはそれ以上の性能を達成．<br><br><br><br><img src="https://user-images.githubusercontent.com/12249301/132679791-87ad130d-8a7e-4549-a311-f84400a3787b.png" alt="image" loading="lazy" width="550" height="400"><br><br></p>
<p>Hugging Faceの実装を利用したと論文中では記載されているが，fine-tuningする前の元の言語モデル（GPT-2）はどのように準備したのだろうか．Hugging Faceのpretrained済みのGPT-2を使用したのだろうか．</p>
<p>autoregressive LM (GPT-2)と，encoder-decoderモデル（BART）へPrefix Tuningを適用する場合の模式図<br><br><img src="https://user-images.githubusercontent.com/12249301/132681736-0ea4b13f-71cb-41ba-ae17-027e8bf54cc0.png" alt="image" loading="lazy" width="550" height="400"><br><br></p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="frogmini-14b-2510-4207" class="title-link">FrogMini-14B-2510, Microsoft, 2026.01</h3>
<br><a href="https://huggingface.co/microsoft/FrogMini-14B-2510" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4207" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AIAgents.html" target="_blank" rel="noopener noreferrer">#AIAgents</a>
<a class="button" href="Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2026-01-16</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/huggingpapers/status/2011543971458400735?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>strong modelから合成されたbug fixのtrajectoryでSFTすることで小規模モデルでSWE Benchの性能改善</p>
<p>元論文:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3208" target="_blank" rel="noopener noreferrer">[Paper Note] High-Resolution Image Synthesis with Latent Diffusion Models, Robin Rombach+, CVPR'22, 2021.12</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="olmocr-2-3395" class="title-link">olmOCR 2: Unit test rewards for document OCR, Ai2, 2025.10</h3>
<br><a href="https://allenai.org/blog/olmocr-2" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3395" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="Japanese.html" target="_blank" rel="noopener noreferrer">#Japanese</a>
<a class="button" href="GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="DocParser.html" target="_blank" rel="noopener noreferrer">#DocParser</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<a class="button" href="OCR.html" target="_blank" rel="noopener noreferrer">#OCR</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<span class="issue_date">Issue Date: 2025-10-23</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/allen_ai/status/1981029163394797618?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>モデル:


<a href="https://huggingface.co/allenai/olmOCR-2-7B-1025-FP8" target="_blank" rel="noopener noreferrer">https://huggingface.co/allenai/olmOCR-2-7B-1025-FP8</a>


</p>
<p>Apache2.0ライセンスでSoTA更新。そしてさすがの学習データとコードも公開</p>
<p>テクニカルレポート:


<a href="https://github.com/allenai/olmocr/blob/main/olmOCR-2-Unit-Test-Rewards-for-Document-OCR.pdf" target="_blank" rel="noopener noreferrer">https://github.com/allenai/olmocr/blob/main/olmOCR-2-Unit-Test-Rewards-for-Document-OCR.pdf</a>


</p>
<p>果たして日本語は…SFT Datasetのtop5にjaはなかったように見える</p>
<p>所見:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kylelostat/status/1981380820658180310?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>demoを試した見たが日本語スライドでも非常に性能が良い</p>
<p>DeepSeekOCRとの比較:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/askalphaxiv/status/1983343306152259888?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="nanochat-3377" class="title-link">nanochat, karpathy, 2025.10</h3>
<br><a href="https://github.com/karpathy/nanochat" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3377" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="ChatGPT.html" target="_blank" rel="noopener noreferrer">#ChatGPT</a>
<a class="button" href="Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<a class="button" href="mid-training.html" target="_blank" rel="noopener noreferrer">#mid-training</a>
<a class="button" href="GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<a class="button" href="Inference.html" target="_blank" rel="noopener noreferrer">#Inference</a>
<a class="button" href="MinimalCode.html" target="_blank" rel="noopener noreferrer">#MinimalCode</a>
<a class="button" href="KV%20Cache.html" target="_blank" rel="noopener noreferrer">#KV Cache</a>
<span class="issue_date">Issue Date: 2025-10-22</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/karpathy/status/1977755427569111362?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>新たなスピードランが...!!</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="anatomy-of-3134" class="title-link">Anatomy of a Modern Finetuning API, Benjamin Anderson, 2025.10</h3>
<br><a href="https://benanderson.work/blog/anatomy-of-finetuning-api/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3134" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="SoftwareEngineering.html" target="_blank" rel="noopener noreferrer">#SoftwareEngineering</a>
<a class="button" href="KeyPoint%20Notes.html" target="_blank" rel="noopener noreferrer">#KeyPoint Notes</a>
<span class="issue_date">Issue Date: 2025-10-06</span>
<span class="snippet"><span>Comment</span><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/3077" target="_blank" rel="noopener noreferrer">Tinker is a training API for {developers, builders, researchers}, THINKING MACHINES, 2025.10</a>
</p>
<p>2023年当時のFinetuningの設計について概観した後、TinkerのAPIの設計について説明。そのAPIの設計のstepごとにTinker側にデータを送るという設計について、一見すると課題があることを指摘（step単位の学習で数百msの通信オーバヘッドが生じて、その間Tinker側のGPUは待機状態になるため最大限GPUリソースを活用できない。これは設計ミスなのでは・・・？という仮説が成り立つという話）。が、仮にそうだとしても、実はよくよく考えるとその課題は克服する方法あるよ、それを克服するためにLoRAのみをサポートしているのもうなずけるよ、みたいな話である。<br><br>解決方法の提案（というより理論）として、マルチテナントを前提に特定ユーザがGPUを占有するのではなく、複数ユーザで共有するのではないか、LoRAはadapterの着脱のオーバヘッドは非常に小さいのでマルチテナントにしても（誰かのデータの勾配計算が終わったらLoRAアダプタを差し替えて別のデータの勾配計算をする、といったことを繰り返せば良いので待機時間はかなり小さくなるはずで、）GPUが遊ぶ時間が生じないのでリソースをTinker側は最大限に活用できるのではないか、といった考察をしている。</p>
<p>ブログの筆者は2023年ごろにFinetuningができるサービスを展開したが、データの準備をユーザにゆだねてしまったがために成功できなかった旨を述べている。このような知見を共有してくれるのは大変ありがたいことである。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="loraの進化：基礎から最新のlora-proまで--2928" class="title-link">LoRAの進化：基礎から最新のLoRA-Proまで , 松尾研究所テックブログ, 2025.09</h3>
<br><a href="https://zenn.dev/mkj/articles/11168509d10eb4" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2928" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-09-22</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/matsuoinstitute/status/1969958580057964986?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2929" target="_blank" rel="noopener noreferrer">[Paper Note] LoRA-Pro: Are Low-Rank Adapters Properly Optimized?, Zhengbo Wang+, ICLR'25, 2024.07</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1245" target="_blank" rel="noopener noreferrer">LoRA+: Efficient Low Rank Adaptation of Large Models, Soufiane Hayou+, N/A, ICML'24</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="holo1.5---2821" class="title-link">Holo1.5 - Open Foundation Models for Computer Use Agents, H Company, 2025.09</h3>
<br><a href="https://www.hcompany.ai/blog/holo-1-5" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2821" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="ComputerUse.html" target="_blank" rel="noopener noreferrer">#ComputerUse</a>
<a class="button" href="GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="VisionLanguageModel.html" target="_blank" rel="noopener noreferrer">#VisionLanguageModel</a>
<span class="issue_date">Issue Date: 2025-09-16</span>
<span class="snippet"><span>Comment</span><p>7BのみApache 2.0ライセンス。3BはQwenのライセンスを継承し、72Bはnon-commercialライセンスらしい</p>
<p>モデルカードとブログによると下記モデル群とSonnet 4 よりもComputer Use関連ベンチマーク(GUI上での位置を特定するUI LocalizationとScreen Contentの理解およびQA関連のベンチマーク)で高性能とのこと:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2447" target="_blank" rel="noopener noreferrer">[Paper Note] UI-Venus Technical Report: Building High-performance UI Agents with RFT, Zhangxuan Gu+, arXiv'25</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1896" target="_blank" rel="noopener noreferrer">Introducing UI-TARS-1.5, ByteDance, 2025.04</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1835" target="_blank" rel="noopener noreferrer">Qwen2.5-VL-32B-Instruct, Qwen Team, 2025.03</a>
</p>
<p>モデルカードによるとopen sourceデータのmixと、合成データ、人手でアノテーションされたデータを用いて、SFT-&gt;GRPOによって学習されたとだけ書かれている。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="k2-think-a-2755" class="title-link">[Paper Note] K2-Think: A Parameter-Efficient Reasoning System, Institute of Foundation Models, Mohamed bin Zayed University of Artificial Intelligence, 2025.09</h3>
<br><a href="https://k2think-about.pages.dev/assets/tech-report/K2-Think_Tech-Report.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2755" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="OpenSource.html" target="_blank" rel="noopener noreferrer">#OpenSource</a>
<a class="button" href="GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<a class="button" href="read-later.html" target="_blank" rel="noopener noreferrer">#read-later</a>
<a class="button" href="RLVR.html" target="_blank" rel="noopener noreferrer">#RLVR</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-10</span>
<span class="snippet"><span>Comment</span><p>HF:


<a href="https://huggingface.co/LLM360/K2-Think" target="_blank" rel="noopener noreferrer">https://huggingface.co/LLM360/K2-Think</a>


<br>code:<br>- 


<a href="https://github.com/MBZUAI-IFM/K2-Think-SFT" target="_blank" rel="noopener noreferrer">https://github.com/MBZUAI-IFM/K2-Think-SFT</a>


<br>- 


<a href="https://github.com/MBZUAI-IFM/K2-Think-Inference" target="_blank" rel="noopener noreferrer">https://github.com/MBZUAI-IFM/K2-Think-Inference</a>


<br><br>RLはverl+GRPOで実施したとテクニカルペーパーに記述されているが、当該部分のコードの公開はされるのだろうか？<br>RLで利用されたデータはこちら:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2070" target="_blank" rel="noopener noreferrer">[Paper Note] Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain  Perspective, Zhoujun Cheng+, NeurIPS'25</a>
</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gm8xx8/status/1965713404418805806?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="nemotron-cc-v2-2631" class="title-link">Nemotron-CC-v2, Nvidia, 2025.08</h3>
<br><a href="https://huggingface.co/datasets/nvidia/Nemotron-CC-v2" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2631" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Coding.html" target="_blank" rel="noopener noreferrer">#Coding</a>
<a class="button" href="Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-09-01</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/zeyuanallenzhu/status/1962119316427706828?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>CCだけでなく、数学やコーディングの事前学習データ、SFT styleの合成データセットも含まれている。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="unsupervised-elicitation-2029" class="title-link">[Paper Note] Unsupervised Elicitation of Language Models, Wen+, Anthropic, 2025.06</h3>
<br><a href="https://alignment-science-blog.pages.dev/2025/unsupervised-elicitation/paper.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2029" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Unsupervised.html" target="_blank" rel="noopener noreferrer">#Unsupervised</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-06-12</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/jiaxinwen22/status/1932908642858418441?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="ms-swiftによるmegatron-lmベースのqwen3のファインチューニング-1949" class="title-link">ms-swiftによるMegatron-LMベースのQwen3のファインチューニング, Aratako, 2025.05</h3>
<br><a href="https://zenn.dev/aratako_lm/articles/90c81270ef64bf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1949" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-05-11</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/aratako_lm/status/1921401994532487174?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>Megatron-SWIFTというAlibaba製のライブラリを利用しQwen3の継続事前学習とSFTを実施する方法を、ベストプラクティスに則って記述し、かつ著者自身が学習したモデルも公開している。（おそらくインスタンス代は自腹なので）すごい...!!<br>Megatron-SWIFTはMoEアーキテクチャを採用したモデルであれば、DeepSpeed Zero3 [^1]と比べて10倍程度のスループットで学習できる模様（早い）。一方MoEアーキテクチャでないモデルの場合はそこまで大きな差はない。<br><br>[^1]: A100 80GB 2ノードでは、Qwen3-30B-A3Bは、DeepSpeed-Zero2ではOOMとなり載らないようだ…。なんとリソースに厳しいこと…（涙）</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="phi-4-reasoning-technical-1921" class="title-link">Phi-4-reasoning Technical Report, 2025.04</h3>
<br><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/04/phi_4_reasoning.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1921" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="SmallModel.html" target="_blank" rel="noopener noreferrer">#SmallModel</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-05-01</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dimitrispapail/status/1917731614899028190?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>こちらの解説が非常によくまとまっている:<br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1918216082231320632?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<br><br>が、元ポストでもテクニカルペーパー中でもo3-miniのreasoning traceをSFTに利用してCoTの能力を強化した旨が記述されているが、これはOpenAIの利用規約に違反しているのでは…？</span><br><br>
</article>
<article class="paper-entry">
<h3 id="qwen3-1909" class="title-link">Qwen3, Qwen Team, 2025.04</h3>
<br><a href="https://qwenlm.github.io/blog/qwen3/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1909" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="LongSequence.html" target="_blank" rel="noopener noreferrer">#LongSequence</a>
<a class="button" href="MultiLingual.html" target="_blank" rel="noopener noreferrer">#MultiLingual</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<a class="button" href="MoE(Mixture-of-Experts).html" target="_blank" rel="noopener noreferrer">#MoE(Mixture-of-Experts)</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-04-29</span>
<span class="snippet"><span>Comment</span><p>- 119言語をサポート<br>- MoEモデル <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1911" target="_blank" rel="noopener noreferrer">Outrageously Large Neural Networks: The Sparsely-Gated  Mixture-of-Experts Layer, Noam Shazeer+, ICLR'17</a>
<br>    - 30B-A3B / 235B-A22N<br>    - 128K context window<br>    - Qwen2.5はMoEを採用していないので新たなアーキテクチャとなる<br>- Denseモデル（非MoEモデル）も公開<br>    - 0.6B -- 32B<br>    - 32K -- 128K context window<br>- Thinking/Non-thinking の切り替えが切り替えが可能<br>    - スイッチは自動的に実施されるが、ユーザが明示的に `/think`, `/no_think` を user_promptの末尾に追加することで制御することも可能<br>- Pre-training<br>    - データ<br>        - 36 trillion tokensによって学習（Qwen-2.5の2倍）<br>        - 学習データではwebデータに加えて、PDF-likeな文書群からQwen2.5-VL <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1835" target="_blank" rel="noopener noreferrer">Qwen2.5-VL-32B-Instruct, Qwen Team, 2025.03</a>
 によってテキストを抽出し、Qwen2.5 で抽出された内容の品質を改善し利用<br>        - また、math / code に関するデータを追加するために、Qwen2.5-Math / Qwen2.5-Coderを用いて合成データを作成（textbooks / QA pairs / code snippets <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/766" target="_blank" rel="noopener noreferrer">Textbooks Are All You Need, Suriya Gunasekar+, N/A, arXiv'23</a>
 ）<br>    - 事前学習のステップ<br>        - S1: context長が4kの30 trillion tokenで事前学習<br>        - S2: STEM / coding / reasoning task などのknowledge-intensiveデータの比率を増やして継続事前学習 (これがおそらく 5 trillion token程度？)<br>        - Final Stage: context長を32kに拡大し高品質なlong-context dataで継続事前学習<br>    - これによりBaseモデルが完成し、Qwen3-235B全体のうち10%程度のActive Parameterの利用するだけで（i.e., 22Bで）、Qwen2.5-72B Baseと同等以上の性能達成<br>- Post-training<br>    - S1: long-CoT cold start<br>        - 数学/coding/logical reasoning/STEMなどの多様なlong CoTデータを用いてSFT <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1749" target="_blank" rel="noopener noreferrer">s1: Simple test-time scaling, Niklas Muennighoff+, arXiv'25</a>
 <br>    - S2: reasoning-based RL<br>        - rule-based (verifiable) rewards によるRL <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
 <br>        - S1/S2の流れは <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">[Paper Note] Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
 に有効性が示されている通り、long CoT DataによるSFT -&gt; RLを実施<br>    - S3: thinking mode fusion<br>        - S2データを用いてlong CoTデータとinstruction tuningデータ（非Long CoT）を生成し、Thinking/Non-thinkingを自動的に選択し生成するように学習（SFT or RLは記述なし）<br>    - S4: general RL<br>        - 20以上の一般的なドメインのタスクを通じて一般的な能力の向上と、safetyに関するalignmentの実施（e.g., instruction following, format following, agent能力など）</p>
<p>BestPracticeに関するポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ivanfioravanti/status/1916934241281061156?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>解説:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hillbig/status/1917712050983428400?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="llama-3_1-nemotron-ultra-253b-v1-1873" class="title-link">Llama-3_1-Nemotron-Ultra-253B-v1, Nvidia, 2025.04</h3>
<br><a href="https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1873" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<a class="button" href="Pruning.html" target="_blank" rel="noopener noreferrer">#Pruning</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="OpenWeight.html" target="_blank" rel="noopener noreferrer">#OpenWeight</a>
<span class="issue_date">Issue Date: 2025-04-08</span>
<span class="snippet"><span>Comment</span><p>DeepSeek-R1をGPQA Diamond <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1155" target="_blank" rel="noopener noreferrer">GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark, David Rein+, N/A, COLM'24</a>
, AIME2024/2025, Llama4 Maverickを<br>BFCLv2（Tool Calling, <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1875" target="_blank" rel="noopener noreferrer">BFCLv2, UC Berkeley, 2024.08</a>
), IFEVal <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1137" target="_blank" rel="noopener noreferrer">Instruction-Following Evaluation for Large Language Models, Jeffrey Zhou+, N/A, arXiv'23</a>
 で上回り, そのほかはArenaHardを除きDeepSeekR1と同等<br><img src="https://github.com/user-attachments/assets/b0de99ee-f4ec-4b03-8b0b-8939b4f1e23b" alt="image" loading="lazy" width="550" height="400"><br><br>DeepSeekR1が671B（MoEで37B Activation Param）に対し、こちらは253B（ただし、Llama3.1がベースなのでMoEではない）で同等以上の性能となっている。<br>ReasoningをON/OFFする能力も備わっている。<br><br>モデルがどのように訓練されたかを示す全体図がとても興味深い:<img src="https://github.com/user-attachments/assets/9a014777-61d8-46ae-818b-ace9ed5c002d" alt="image" loading="lazy" width="550" height="400"><br><br>特に <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1746" target="_blank" rel="noopener noreferrer">[Paper Note] Demystifying Long Chain-of-Thought Reasoning in LLMs, Edward Yeo+, arXiv'25</a>
 でも有効性が示されているように、SFTをしてからReasoningを強化する（強化というより元々持っている能力を引き出す？）RLを実施している。<br><br>詳細は下記Blogとのこと:<br>


<a href="https://developer.nvidia.com/blog/build-enterprise-ai-agents-with-advanced-open-nvidia-llama-nemotron-reasoning-models/" target="_blank" rel="noopener noreferrer">https://developer.nvidia.com/blog/build-enterprise-ai-agents-with-advanced-open-nvidia-llama-nemotron-reasoning-models/</a>


</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/kuchaev/status/1909444566379573646?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="nemotron-h-a-1830" class="title-link">Nemotron-H: A Family of Accurate, Efficient Hybrid Mamba-Transformer Models, Nvidia, 2025.03</h3>
<br><a href="https://research.nvidia.com/labs/adlr/nemotronh/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1830" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="ComputerVision.html" target="_blank" rel="noopener noreferrer">#ComputerVision</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Transformer.html" target="_blank" rel="noopener noreferrer">#Transformer</a>
<a class="button" href="MultiModal.html" target="_blank" rel="noopener noreferrer">#MultiModal</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="SSM%20(StateSpaceModel).html" target="_blank" rel="noopener noreferrer">#SSM (StateSpaceModel)</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-03-24</span>
<span class="snippet"><span>Comment</span><p>関連:<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1820" target="_blank" rel="noopener noreferrer">Hunyuan T1, Tencent, 2025.03</a>
</p>
<p>TransformerのSelf-attention LayerをMamba2 Layerに置換することで、様々なベンチマークで同等の性能、あるいは上回る性能で3倍程度のInference timeの高速化をしている（65536 input, 1024 output）。<br><br>56B程度のmediumサイズのモデルと、8B程度の軽量なモデルについて述べられている。特に、8BモデルでMambaとTransformerのハイブリッドモデルと、通常のTransformerモデルを比較している。学習データに15 Trillion Tokenを利用しており、このデータ量でのApple to Appleのアーキテクチャ間の比較は、現状では最も大規模なものとのこと。性能は多くのベンチマークでハイブリッドにしても同等、Commonsense Understandingでは上回っている。<br><br>また、学習したNemotron-Hをバックボーンモデルとして持つVLMについてもモデルのアーキテクチャが述べられている。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="llm-開発を支える多様な-1803" class="title-link">LLM 開発を支える多様な Fine-Tuning：PFN での取り組み, 中鉢魁三郎, PFN, 2025.03</h3>
<br><a href="https://llm-jp.github.io/tuning-competition/pdfs/invited_3.pdf" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1803" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<span class="issue_date">Issue Date: 2025-03-16</span>
<span class="snippet"><span>Comment</span><p>知識の追加の部分で下記研究が引用されている<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1371" target="_blank" rel="noopener noreferrer">Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?, Zorik Gekhman+, N/A, EMNLP'24</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1640" target="_blank" rel="noopener noreferrer">LoRA Learns Less and Forgets Less, Dan Biderman+, TMLR'24</a>
</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-ultra-scale-1780" class="title-link">The Ultra-Scale Playbook: Training LLMs on GPU Clusters, HuggingFace, 2025.02</h3>
<br><a href="https://huggingface.co/spaces/nanotron/ultrascale-playbook" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1780" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2025-03-04</span>
<span class="snippet"><span>Comment</span><p>HuggingFaceによる数1000のGPUを用いたAIモデルのトレーニングに関するオープンソースのテキスト</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="強化学習「grpo」をcartpoleタスクで実装しながら解説-1769" class="title-link">強化学習「GRPO」をCartPoleタスクで実装しながら解説, 小川雄太郎, 2025.02</h3>
<br><a href="https://zenn.dev/mkj/articles/10dfe35cd32026" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1769" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="GRPO.html" target="_blank" rel="noopener noreferrer">#GRPO</a>
<span class="issue_date">Issue Date: 2025-02-19</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/ogawa_yutaro_22/status/1892059174789407213?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="unsloth-で独自の-1747" class="title-link">Unsloth で独自の R1 Reasoningモデルを学習, npaka, 2025.02</h3>
<br><a href="https://note.com/npaka/n/nd99a395b404f?sub_rt=share_pw" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1747" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2025-02-07</span>
<span class="snippet"><span>Comment</span><p>非常に実用的で参考になる。特にどの程度のVRAMでどの程度の規模感のモデルを使うことが推奨されるのかが明言されていて参考になる。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="deepseek-r1の論文読んだ？【勉強になるよ】--1743" class="title-link">DeepSeek-R1の論文読んだ？【勉強になるよ】 , asap, 2025.01</h3>
<br><a href="https://zenn.dev/asap/articles/34237ad87f8511" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1743" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<a class="button" href="RLHF.html" target="_blank" rel="noopener noreferrer">#RLHF</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2025-02-01</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1719" target="_blank" rel="noopener noreferrer">DeepSeek-R1, DeepSeek, 2025.01</a>
<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1655" target="_blank" rel="noopener noreferrer">DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open
  Language Models, Zhihong Shao+, arXiv'24</a>
</p>
<p>とても丁寧でわかりやすかった。後で読んだ内容を書いて復習する。ありがとうございます。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="llm-datasets-1727" class="title-link">LLM Datasets, mlabonne, 2025.01</h3>
<br><a href="https://github.com/mlabonne/llm-datasets" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1727" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<span class="snippet"><span>Comment</span><p>LLMの事後学習用のデータをまとめたリポジトリ</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="how-to-1723" class="title-link">How to fine-tune open LLMs in 2025 with Hugging Face, PHILSCHMID, 2024.12</h3>
<br><a href="https://www.philschmid.de/fine-tune-llms-in-2025" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1723" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<span class="snippet"><span>Comment</span><p>SFTTrainerを用いたLLMのSFTについて、実用的、かつ基礎的な内容がコード付きでまとまっている。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="how-to-1722" class="title-link">How to align open LLMs in 2025 with DPO &amp; and synthetic data, PHILSCHMID, 2025.01</h3>
<br><a href="https://www.philschmid.de/rl-with-llms-in-2025-dpo" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1722" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="DPO.html" target="_blank" rel="noopener noreferrer">#DPO</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2025-01-25</span>
<span class="snippet"><span>Comment</span><p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_philschmid/status/1882428447877705908?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>- DPOの概要やRLHFと比較した利点<br>- ルールベース、あるいはLLM as a Judgeを用いたOn-policy preference pair（現在のSFTしたモデルの出力から生成したpreference data）の作り方とその利点（現在のモデルのoutput distributionを反映しているので学習が効率化される）<br>- 環境構築方法<br>- DPOTrainer/TRLParserの使い方/DPODatasetの作り方<br>- DPOのハイパーパラメータβの意味合い<br>- DPOではSFTと比べて10-100x小さい学習率を使う必要があること<br>- Evaluation Harnessを用いた評価方法<br>- TGIを用いたモデルのデプロイとテスト<br><br>などが丁寧なサンプルコードと注釈、reference付きで説明されている。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="to-fine-tune-1635" class="title-link">To fine-tune or not to fine-tune, Meta, 2024.08</h3>
<br><a href="https://ai.meta.com/blog/when-to-fine-tune-llms-vs-other-techniques/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1635" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="RAG(RetrievalAugmentedGeneration).html" target="_blank" rel="noopener noreferrer">#RAG(RetrievalAugmentedGeneration)</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2025-01-02</span>
<span class="snippet"><span>Comment</span><p>LLMをSFTする際の注意点やユースケースについて記述されている。<br><br>- full parameterのファインチューニングやPEFT手法のピークGPUメモリ<br>- full parameterのファインチューニングではcatastrophic forgettingに気をつける必要があること<br>- Finetuningが有用なユースケースとして以下が挙げられている<br>  - トーン、スタイル、フォーマットのカスタマイザーション<br>  - prompt engineeringやICLで達成するには困難なAccuracyの向上やエッジケースへの対応<br>  - ドメイン適応<br>  - より大きいモデルを蒸留することによるコスト削減<br>  - 新たなタスクへの適応や能力の獲得 </p>
<p>また、RAGとFinetuningどちらを選択すべきかに関する話題も記述されている（が、多くの場合はハイブリッドアプローチがベストだ、といった話も書いてある）。</p>
<p>元ポスト:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/gyakuse/status/1874357127248306200?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="llmを数学タスクにアラインする手法の系譜---1617" class="title-link">LLMを数学タスクにアラインする手法の系譜 - GPT-3からQwen2.5まで, bilzard, 2024.12</h3>
<br><a href="https://zenn.dev/bilzard/articles/survey-self-improve-llm" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1617" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Alignment.html" target="_blank" rel="noopener noreferrer">#Alignment</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<a class="button" href="Mathematics.html" target="_blank" rel="noopener noreferrer">#Mathematics</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2024-12-27</span>
<span class="snippet"><span>Comment</span><p>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1618" target="_blank" rel="noopener noreferrer">Training Verifiers to Solve Math Word Problems, Karl Cobbe+, arXiv'21</a>
<br><br>において、数学においてモデルのパラメータ数のスケーリングによって性能改善が見込める学習手法として、モデルとは別にVerifierを学習し、モデルが出力した候補の中から良いものを選択できるようにする、という話の気持ちが最初よくわからなかったのだが、後半のなぜsample&amp;selectがうまくいくのか？節を読んでなんとなく気持ちが理解できた。SFTを進めるとモデルが出力する解放の多様性が減っていくというのは、興味深かった。<br><br>しかし、特定の学習データで学習した時に、全く異なるUnseenなデータに対しても解法は減っていくのだろうか？という点が気になった。あとは、学習データの多様性をめちゃめちゃ増やしたらどうなるのか？というのも気になる。特定のデータセットを完全に攻略できるような解法を出力しやすくなると、他のデータセットの性能が悪くなる可能性がある気がしており、そうするとそもそもの1shotの性能自体も改善していかなくなりそうだが、その辺はどういう設定で実験されているのだろうか。<br><br>たとえば、<br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1475" target="_blank" rel="noopener noreferrer">Beyond Full Fine-tuning: Harnessing the Power of LoRA for Multi-Task Instruction Tuning, Xin+, LREC-COLING'24</a>
<br><br>などでは、<br><br>- <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1474" target="_blank" rel="noopener noreferrer">Super-NaturalInstructions: Generalization via Declarative Instructions  on 1600+ NLP Tasks, Yizhong Wang+, N/A, EMNLP'22</a>
<br><br>のような1600を超えるようなNLPタスクのデータでLoRAによりSFTすると、LoRAのパラメータ数を非常に大きくするとUnseenタスクに対する性能がfull-parameter tuningするよりも向上することが示されている。この例は数学に特化した例ではないが、SFTによって解法の多様性が減ることによって学習データに過剰適合して汎化性能が低下する、というのであれば、この論文のことを鑑みると「学習データにoverfittingした結果他のデータセットで性能が低下してしまう程度の多様性の学習データしか使えていないのでは」と感じてしまうのだが、その辺はどうなんだろうか。元論文を読んで確認したい。<br>とても勉強になった。</p>
<p>記事中で紹介されている<br>&gt; LLMを使って複数解法の候補をサンプリングし、その中から最適な1つを選択する<br><br>のルーツは <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1618" target="_blank" rel="noopener noreferrer">Training Verifiers to Solve Math Word Problems, Karl Cobbe+, arXiv'21</a>
 とのことなので是非読みたい。<br><br>この辺はSelf-Consistency <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/558" target="_blank" rel="noopener noreferrer">[Paper Note] Self-Consistency Improves Chain of Thought Reasoning in Language Models, Xuezhi Wang+, ICLR'23, 2022.03</a>
 あたりが最初なのかと思っていた。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="stanford-cs229-1614" class="title-link">Stanford CS229 I Machine Learning I Building Large Language Models （LLMs）, StanfordUnivercity, 2024.09</h3>
<br><a href="https://youtu.be/9vM4p9NN0Ts" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1614" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Video.html" target="_blank" rel="noopener noreferrer">#Video</a>
<span class="issue_date">Issue Date: 2024-12-25</span>
<span class="snippet"><span>Comment</span><p>スタンフォード大学によるLLM構築に関する講義。事前学習と事後学習両方ともカバーしているらしい。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="cross-prompt-pre-finetuning-1555" class="title-link">Cross-prompt Pre-finetuning of Language Models for Short Answer Scoring, Funayama+, 2024.09</h3>
<br><a href="https://assets-eu.researchsquare.com/files/rs-4929687/v1_covered_d59bda02-4ab7-4175-b01b-e3b1d3d162f7.pdf?c=1726671346" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1555" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="AES(AutomatedEssayScoring).html" target="_blank" rel="noopener noreferrer">#AES(AutomatedEssayScoring)</a>
<span class="issue_date">Issue Date: 2024-11-28</span>
<span class="snippet"><span>GPT Summary</span>- 自動短答スコアリング（SAS）では、異なるルーブリックと参照回答に基づいてスコアを付けるが、新しいプロンプトごとにモデルを再訓練する必要がありコストがかかる。本研究では、既存のルーブリックと回答を用いて新しいプロンプトでファインチューニングする二段階アプローチを提案。重要なフレーズを学習することで、特に訓練データが限られている場合にスコアリング精度を向上させることを実験で示した。</span>
<span class="snippet"><span>Comment</span><p>SASでは回答データが限られているので、限られたデータからより効果的に学習をするために、事前に他のデータでモデルをpre-finetuningしておき、対象データが来たらpre-finetuningされたモデルをさらにfinetuningするアプローチを提案。ここで、prompt中にkeyphraseを含めることが有用であると考え、実験的に有効性を示している。<br><br><img src="https://github.com/user-attachments/assets/9ab4eb22-b72e-4573-8fbb-1c376047c2b0" alt="image" loading="lazy" width="550" height="400"><br><br><img src="https://github.com/user-attachments/assets/b671a564-c5a8-4344-aaec-06875f654f8b" alt="image" loading="lazy" width="550" height="400"><br><br><br><br>BERTでfinetuningをした場合は、key-phraseを含めた方が性能が高く、特にfinetuningのサンプル数が小さい場合にその差が顕著であった。<br><br><img src="https://github.com/user-attachments/assets/cdced65b-060b-43ae-a2b4-fcfc5750a6ed" alt="image" loading="lazy" width="550" height="400"><br><br><br><br>次に、LLM（swallow-8B, 70B）をpre-finetuningし、pre-finetuningを実施しない場合と比較することで、pre-finetuningがLLMのzero-shot、およびICL能力にどの程度影響を与えるかを検証した。検証の結果、pre-finetuningなしでは、そもそも10-shotにしてもQWKが非常に低かったのに対し、pre-finetuningによってzero-shotの能力が大幅に性能が向上した。一方、few-shotについては3-shotで性能が頭打ちになっているようにみえる。ここで、Table1のLLMでは、ターゲットとする問題のpromptでは一切finetuningされていないことに注意する（Unseenな問題）。<br><br><img src="https://github.com/user-attachments/assets/7c9f141d-dc55-4388-8dc4-6a56f81d6cad" alt="image" loading="lazy" width="550" height="400"><br><br><br><br>続いて、LLMをfinetuningした場合も検証。提案手法が高い性能を示し、200サンプル程度ある場合にHuman Scoreを上回っている（しかもBERTは200サンプルでサチったが、LLMはまだサチっていないように見える）。また、サンプル数がより小さい場合に、提案手法がより高いgainを得ていることがわかる。<br><br><img src="https://github.com/user-attachments/assets/898b2bea-e9df-4c5c-b172-0507a3a83c3c" alt="image" loading="lazy" width="550" height="400"><br><br><br><br>また、個々の問題ごとにLLMをfinetuningするのは現実的に困難なので、個々の問題ごとにfinetuningした場合と、全ての問題をまとめてfinetuningした場合の性能差を比較したところ、まとめて学習しても性能は低下しない、どころか21問中18問で性能が向上した（LLMのマルチタスク学習の能力のおかげ）。<br><br><img src="https://github.com/user-attachments/assets/a8ec62fb-2984-4e7c-8eeb-1b3b6333e9ac" alt="image" loading="lazy" width="550" height="400"><br><br></p>
<p>[Perplexity(hallucinationに注意)](


<a href="https://www.perplexity.ai/search/tian-fu-sitalun-wen-wodu-mi-ne-3_TrRyxTQJ.2Bm2fJLqvTQ#0)" target="_blank" rel="noopener noreferrer">https://www.perplexity.ai/search/tian-fu-sitalun-wen-wodu-mi-ne-3_TrRyxTQJ.2Bm2fJLqvTQ#0)</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="microsoft_orca-agentinstruct-1m-v1-1521" class="title-link">microsoft_orca-agentinstruct-1M-v1, Microsoft, 2024.11</h3>
<br><a href="https://huggingface.co/datasets/microsoft/orca-agentinstruct-1M-v1" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1521" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="Dataset.html" target="_blank" rel="noopener noreferrer">#Dataset</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2024-11-16</span>
</article>
<article class="paper-entry">
<h3 id="zero-deepspeedの紹介-1487" class="title-link">ZeRO: DeepSpeedの紹介, レトリバ, 2021.07 </h3>
<br><a href="https://tech.retrieva.jp/entry/2021/07/26/102514" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1487" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="One-Line%20Notes.html" target="_blank" rel="noopener noreferrer">#One-Line Notes</a>
<a class="button" href="Reference%20Collection.html" target="_blank" rel="noopener noreferrer">#Reference Collection</a>
<span class="issue_date">Issue Date: 2024-11-07</span>
<span class="snippet"><span>Comment</span><p>ZeROの説明がわかりやすい</p>
<p>こちらの記事もわかりやすい<br><br>


<a href="https://zenn.dev/turing_motors/articles/d00c46a79dc976" target="_blank" rel="noopener noreferrer">https://zenn.dev/turing_motors/articles/d00c46a79dc976</a>


</p>
<p>DeepSpeedのコンフィグの一覧<br><br>


<a href="https://www.deepspeed.ai/docs/config-json/" target="_blank" rel="noopener noreferrer">https://www.deepspeed.ai/docs/config-json/</a>


</p>
<p>transformersにおけるdeepspeedのドキュメント:<br>


<a href="https://huggingface.co/transformers/v4.9.2/main_classes/deepspeed.html" target="_blank" rel="noopener noreferrer">https://huggingface.co/transformers/v4.9.2/main_classes/deepspeed.html</a>


</p>
<p>参考: deepspeedの使い方まとめ<br>


<a href="https://note.com/fukudawataru/n/n5152e6f587c8" target="_blank" rel="noopener noreferrer">https://note.com/fukudawataru/n/n5152e6f587c8</a>


</p>
<p>ZeRO Stage3を使う場合、ページ後方にしれっととんでもなく重要なことが書いてあるので気をつけましょう。。。。<br><br>


<a href="https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/deepspeed#constructing-massive-models" target="_blank" rel="noopener noreferrer">https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/deepspeed#constructing-massive-models</a>


<br><br><br><br><img src="https://github.com/user-attachments/assets/677b6656-1302-4b1b-8be6-ca954c7edda6" alt="image" loading="lazy" width="550" height="400"><br><br></p>
<p>ZeROはparameterとoptimizerのmemory footprintの最適化を頑張っていて、activation memory footprint（バッチをforward passに流す時に消費されるメモリ）の削減は、tiling, activation/gradient checkpointingとかで頑張ってねという<br><br><br><br>という話が本家issueの4047に記載されている。</p>
<p>結論: つまづいたらDeepSpeedのIssueをエラーメッセージで検索かけるのが一番効果的</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="unsloth-1450" class="title-link">Unsloth</h3>
<br><a href="https://github.com/unslothai/unsloth" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1450" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="InstructionTuning.html" target="_blank" rel="noopener noreferrer">#InstructionTuning</a>
<span class="issue_date">Issue Date: 2024-10-08</span>
<span class="snippet"><span>Comment</span><p>single-GPUで、LLMのLoRA/QLoRAを高速/省メモリに実行できるライブラリ</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="liger-kernel-1356" class="title-link">Liger-Kernel, 2024.08</h3>
<br><a href="https://github.com/linkedin/Liger-Kernel" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1356" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2024-08-25</span>
<span class="snippet"><span>Comment</span><p>LLMを学習する時に、ワンライン追加するだけで、マルチGPUトレーニングのスループットを20%改善し、メモリ使用量を60%削減するらしい<br><br>元ツイート:



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/hsu_byron/status/1827072737673982056?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>これだけでいい<br><img src="https://github.com/user-attachments/assets/abce24ed-f979-43db-ac51-e850f2ae877a" alt="image" loading="lazy" width="550" height="400"></p>
<p>Unsloth <a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1450" target="_blank" rel="noopener noreferrer">Unsloth</a>
 はLoRA/QLoRAが可能な一方でまだMulti-GPUはサポートしていない。一方、Liger-KernelはLoRAよりもfull-parameter tuningとMulti-GPUにフォーカスしており、目的に応じて使い分けが必要。<br><br><br><br>


<a href="https://github.com/linkedin/Liger-Kernel/issues/57" target="_blank" rel="noopener noreferrer">https://github.com/linkedin/Liger-Kernel/issues/57</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="the-end-1294" class="title-link">The End of Finetuning — with Jeremy Howard of Fast.ai, 2023.11</h3>
<br><a href="https://www.latent.space/p/fastai?utm_campaign=post&utm_medium=web" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1294" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<span class="issue_date">Issue Date: 2024-04-26</span>
</article>
<article class="paper-entry">
<h3 id="practical-tips-1146" class="title-link">Practical Tips for Finetuning LLMs Using LoRA （Low-Rank Adaptation）, SEBASTIAN RASCHKA, PHD, 2023.11</h3>
<br><a href="https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1146" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-11-20</span>
</article>
<article class="paper-entry">
<h3 id="llama-factory-1134" class="title-link">LLaMA-Factory, 2023</h3>
<br><a href="https://github.com/hiyouga/LLaMA-Factory" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1134" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Library.html" target="_blank" rel="noopener noreferrer">#Library</a>
<a class="button" href="Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2023-11-14</span>
<span class="snippet"><span>Comment</span><p>簡単に利用できるLLaMAのfinetuning frameworkとのこと。<br>元ツイート: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/_akhaliq/status/1724456693378040195?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


<p>LLaMAベースなモデルなら色々対応している模様</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="大規模言語モデルのfine-tuningによるドメイン知識獲得の検討-1109" class="title-link">大規模言語モデルのFine-tuningによるドメイン知識獲得の検討, PFN Blog, 2023.10</h3>
<br><a href="https://tech.preferred.jp/ja/blog/llm-fine-tuning-for-domain-knowledge/" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1109" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="Catastrophic%20Forgetting.html" target="_blank" rel="noopener noreferrer">#Catastrophic Forgetting</a>
<span class="issue_date">Issue Date: 2023-10-29</span>
</article>
<article class="paper-entry">
<h3 id="llmのファインチューニング-で-1027" class="title-link">LLMのファインチューニング で 何ができて 何ができないのか</h3>
<br><a href="https://note.com/npaka/n/nec63c01f7ee8#0e274efa-8b8a-4f88-bf65-432e7ee75fd1" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1027" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Tutorial.html" target="_blank" rel="noopener noreferrer">#Tutorial</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-08-29</span>
<span class="snippet"><span>Comment</span><p>&gt;LLMのファインチューニングは、「形式」の学習は効果的ですが、「事実」の学習は不得意です。<br><br>&gt; シェイクスピアの脚本のデータセット (tiny-shakespeare) の<br>「ロミオ」を「ボブ」に置き換えてファインチューニングして、新モデルの頭の中では「ロミオ」と「ボブ」をどう記憶しているかを確認します。<br><br>ファインチューニングしても、Bで始まるジュリエットが恋する人物について質問しても、ボブと答えてはくれない。<br>&gt; ロミオ」は「ジュリエット」が恋していたこの男性に関連付けられており、「ロミオ」を「ボブ」に置き換えるファインチューニングでは、ニューラルネットワークの知識ベースを変更することはできませんでした。<br><br>なるほど。</p>
<p>参考: 


<a href="https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts?ref=blog.langchain.dev" target="_blank" rel="noopener noreferrer">https://www.anyscale.com/blog/fine-tuning-is-for-form-not-facts?ref=blog.langchain.dev</a>


</p>
<p>imosさんのツイートを引用<br>&gt; 文章が悪かったので補足。追加学習を全体に十分なデータですれば知識は獲得しえます（が事前学習の知識を忘却するリスクは高い）。巷でよくファインチューニングと呼ばれるものは、知識を司るらしいMLP部を触らず自己注意機構部のみを更新するので、そもそも知識を増やすのは難しいという認識です。<br><br>元ツイート: 



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/imos/status/1696507787067756846?s=46&t=Y6UuIHB0Lv0IpmFAjlc2-Q"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="llama2を3行で訓練-886" class="title-link">LLaMA2を3行で訓練</h3>
<br><a href="https://huggingface.co/docs/trl/main/en/lora_tuning_peft#finetuning-llama2-model" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/886" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Quantization.html" target="_blank" rel="noopener noreferrer">#Quantization</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<span class="issue_date">Issue Date: 2023-07-22</span>
<span class="snippet"><span>Comment</span><p>LLaMA2を3行で、1つのA100GPU、QLoRAで、自前のデータセットで訓練する方法</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="auto-train-796" class="title-link">Auto train advanced</h3>
<br><a href="https://github.com/huggingface/autotrain-advanced" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/796" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="Repository.html" target="_blank" rel="noopener noreferrer">#Repository</a>
<span class="issue_date">Issue Date: 2023-07-11</span>
<span class="snippet"><span>Comment</span><p>Hugging Face Hub上の任意のLLMに対して、localのカスタムトレーニングデータを使ってfinetuningがワンラインでできる。<br>peftも使える。</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="lm-flow-771" class="title-link">LM Flow</h3>
<br><a href="https://github.com/OptimalScale/LMFlow" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/771" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="MachineLearning.html" target="_blank" rel="noopener noreferrer">#MachineLearning</a>
<a class="button" href="Tools.html" target="_blank" rel="noopener noreferrer">#Tools</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="FoundationModel.html" target="_blank" rel="noopener noreferrer">#FoundationModel</a>
<span class="issue_date">Issue Date: 2023-06-26</span>
<span class="snippet"><span>Comment</span><p>一般的なFoundation Modelのファインチューニングと推論を簡素化する拡張可能なツールキット。継続的なpretragning, instruction tuning, parameter efficientなファインチューニング,alignment tuning,大規模モデルの推論などさまざまな機能をサポート。<br><br>



</p>
<div class="tweet-embed" style="min-height:400px; max-width:550px; margin:1em auto;" data-embed='&lt;blockquote class="twitter-tweet"&gt;&lt;a href="https://twitter.com/dair_ai/status/1672953412927799298?s=46&t=ajzDWio8pEbrezgj40Dobw"&gt;&lt;/a&gt;&lt;/blockquote&gt;'>
  <div class="tweet-placeholder">Loading…</div>
</div>


</span><br><br>
</article>
<article class="paper-entry">
<h3 id="towards-complex-626" class="title-link">Towards Complex Reasoning: the Polaris of Large Language Models, Yao Fu, 2023.05</h3>
<br><a href="https://yaofu.notion.site/Towards-Complex-Reasoning-the-Polaris-of-Large-Language-Models-c2b4a51355b44764975f88e6a42d4e75" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/626" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="Pretraining.html" target="_blank" rel="noopener noreferrer">#Pretraining</a>
<a class="button" href="Pocket.html" target="_blank" rel="noopener noreferrer">#Pocket</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="ReinforcementLearning.html" target="_blank" rel="noopener noreferrer">#ReinforcementLearning</a>
<a class="button" href="Chain-of-Thought.html" target="_blank" rel="noopener noreferrer">#Chain-of-Thought</a>
<a class="button" href="Evaluation.html" target="_blank" rel="noopener noreferrer">#Evaluation</a>
<a class="button" href="Blog.html" target="_blank" rel="noopener noreferrer">#Blog</a>
<a class="button" href="Reasoning.html" target="_blank" rel="noopener noreferrer">#Reasoning</a>
<span class="issue_date">Issue Date: 2023-05-04</span>
</article>
<article class="paper-entry">
<h3 id="lora論文解説-528" class="title-link">LoRA論文解説, Hayato Tsukagoshi, 2023.04</h3>
<br><a href="https://speakerdeck.com/hpprc/lun-jiang-zi-liao-lora-low-rank-adaptation-of-large-language-models" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/528" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NeuralNetwork.html" target="_blank" rel="noopener noreferrer">#NeuralNetwork</a>
<a class="button" href="EfficiencyImprovement.html" target="_blank" rel="noopener noreferrer">#EfficiencyImprovement</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<a class="button" href="PEFT(Adaptor_LoRA).html" target="_blank" rel="noopener noreferrer">#PEFT(Adaptor/LoRA)</a>
<a class="button" href="Slide.html" target="_blank" rel="noopener noreferrer">#Slide</a>
<a class="button" href="PostTraining.html" target="_blank" rel="noopener noreferrer">#PostTraining</a>
<a class="button" href="Selected%20Papers_Blogs.html" target="_blank" rel="noopener noreferrer">#Selected Papers/Blogs</a>
<span class="issue_date">Issue Date: 2023-04-25</span>
<span class="snippet"><span>Comment</span><p>ベースとなる事前学習モデルの一部の線形層の隣に、低ランク行列A,Bを導入し、A,Bのパラメータのみをfinetuningの対象とすることで、チューニングするパラメータ数を激減させた上で同等の予測性能を達成し、推論速度も変わらないようにするfinetuning手法の解説</p>
<p>LoRAを使うと、でかすぎるモデルだと、そもそもGPUに載らない問題や、ファインチューニング後のモデルファイルでかすぎワロタ問題が回避できる。<br><br>前者は事前学習済みモデルのBPのための勾配を保存しておく必要がなくなるため学習時にメモリ節約になる。後者はA,Bのパラメータだけ保存すればいいので、ストレージの節約になる。<br><br>かつ、学習速度が25%程度早くなる。</p>
<p>既存研究であるAdapter（transformerの中に学習可能なMLPを差し込む手法）は推論コストが増加し、prefix tuningは学習が非常に難しく、高い性能を達成するためにprefixとして128 token入れたりしなければならない。</p>
<p>huggingfaceがすでにLoRAを実装している<br>


<a href="https://github.com/huggingface/peft" target="_blank" rel="noopener noreferrer">https://github.com/huggingface/peft</a>


</p></span><br><br>
</article>
<article class="paper-entry">
<h3 id="publicly-available-514" class="title-link">Publicly available instruction-tuned models</h3>
<br><a href="https://huggingface.co/bigscience/T0" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
Paper/Blog Link
</a><a href="https://github.com/AkihikoWatanabe/paper_notes/issues/514" target="_blank" rel="noopener noreferrer" class="external-link-badge"><svg width="14" height="14" viewbox="0 0 24 24" aria-hidden="true">
  <path d="M14 3h7v7h-2V6.41l-9.29 9.3-1.42-1.42 9.3-9.29H14V3z"></path>
  <path d="M5 5h5V3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2v-5h-2v5H5V5z"></path>
</svg>
My Issue
</a><br>
<a class="button" href="Article.html" target="_blank" rel="noopener noreferrer">#Article</a>
<a class="button" href="NLP.html" target="_blank" rel="noopener noreferrer">#NLP</a>
<a class="button" href="LanguageModel.html" target="_blank" rel="noopener noreferrer">#LanguageModel</a>
<span class="issue_date">Issue Date: 2023-03-30</span>
</article>
</div>
<script>
document.addEventListener("DOMContentLoaded", function() {
  // Twitterのwidgets.jsを動的に一度だけ読み込む関数
  let twitterScriptLoaded = false;
  function loadTwitterScript() {
    if (!twitterScriptLoaded) {
      const script = document.createElement('script');
      script.src = "https://platform.twitter.com/widgets.js";
      script.charset = "utf-8";
      script.async = true;
      document.body.appendChild(script);
      twitterScriptLoaded = true;
    }
  }

  // Intersection Observerの設定
  const observer = new IntersectionObserver((entries, obs) => {
    entries.forEach(entry => {
      if (entry.isIntersecting) {
        // 画面に入った時だけスクリプトをロード開始
        loadTwitterScript();

        const container = entry.target;
        const embedHtml = container.getAttribute('data-embed');
        
        if (embedHtml) {
          container.innerHTML = embedHtml;
          container.removeAttribute('data-embed');
          
          // ウィジェットの再スキャン（twttrオブジェクトが準備できていれば実行）
          if (window.twttr && window.twttr.widgets) {
            window.twttr.widgets.load(container);
          }
        }
        obs.unobserve(container);
      }
    });
  }, { rootMargin: '200px', threshold: 0.01 }); // 少し早めに読み込む

  document.querySelectorAll('.tweet-embed').forEach(el => observer.observe(el));
});
</script>


    </div>

</article>
<div class="post-nav">
<a class="previous" href="/paper_notes/articles/SparseAutoEncoder/" title="SparseAutoEncoderに関する論文・技術記事メモの一覧">SparseAutoEncoderに関する論文・技術記事メモの一覧</a><a class="next" href="/paper_notes/articles/SyntheticData/" title="SyntheticDataに関する論文・技術記事メモの一覧">SyntheticDataに関する論文・技術記事メモの一覧</a>
</div>
<div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li class="">
          <a class="post-link" href="/paper_notes/articles/Ambiguity/" title="Ambiguityに関する論文・技術記事メモの一覧">
            Ambiguityに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 1</span> 
  <span class="post-badge badge-new">📝 1</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/RuleBased/" title="RuleBasedに関する論文・技術記事メモの一覧">
            RuleBasedに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 5</span> 
  <span class="post-badge badge-new">📝 5</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/ZeroshotHyperparameterTransfer/" title="ZeroshotHyperparameterTransferに関する論文・技術記事メモの一覧">
            ZeroshotHyperparameterTransferに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 4</span> 
  <span class="post-badge badge-new">📝 4</span>
</span>
</a>
        </li>
<li class="">
          <a class="post-link" href="/paper_notes/articles/StudentPerformancePrediction/" title="StudentPerformancePredictionに関する論文・技術記事メモの一覧">
            StudentPerformancePredictionに関する論文・技術記事メモの一覧

<span class="post-badges"><span class="post-badge badge-top">📝 21</span> 
  <span class="post-badge badge-new">📝 21</span>
</span>
</a>
        </li>
</ul>
    </div>
<div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
/* --- レイアウト用（前回と同じ） --- */
.post-menu {
  position: -webkit-sticky;
  position: sticky;
  top: 20px;
  max-height: calc(100vh - 40px);
  display: flex;
  flex-direction: column;
}

.post-menu-title {
  flex-shrink: 0;
  margin-bottom: 10px;
  font-weight: bold;
}

.post-menu-content {
  overflow-y: auto;
  scrollbar-width: thin;
}

.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}

/* --- 開閉アニメーションとアイコン用 --- */

/* h2のスタイル：クリックできるようにする */
.post-menu li.h-h2 {
  cursor: pointer;
  position: relative;
  padding-left: 15px; /* アイコン用のスペース */
  font-weight: bold;
  margin-top: 5px;
}

/* 開閉アイコン（▼） */
.post-menu li.h-h2::before {
  content: '';
  display: inline-block;
  width: 0;
  height: 0;
  border-style: solid;
  border-width: 5px 0 5px 6px; /* 三角形 */
  border-color: transparent transparent transparent #555;
  position: absolute;
  left: 0;
  top: 50%;
  transform: translateY(-50%);
  transition: transform 0.2s ease;
}

.post-menu li.h-h2.no-icon::before {
  content: none; /* 擬似要素の中身をなしにする */
  /* または display: none; でもOKです */
}

/* 開いている時のアイコン（下向きにする） */
.post-menu li.h-h2.open::before {
  transform: translateY(-50%) rotate(90deg);
}

/* h3（子要素）のスタイル */
.post-menu li.h-h3 {
  margin-left: 15px;
  font-size: 0.9em;
  /* 初期状態はJSで制御しますが、念のため */
}

/* アクティブな項目の色 */
.post-menu li.active > a {
  color: #d9534f;
  font-weight: bold;
}

/* リンク自体のスタイル調整 */
.post-menu li a {
  text-decoration: none;
  color: inherit;
  display: inline-block;
  width: 100%;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">TOC</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent = menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3");

    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // --- HTML生成 ---
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      // h-h2 クラスの要素には初期状態で open クラスをつけるか、つけないかで「最初から開いているか」を決められます
      // ここでは閉じた状態をデフォルトとします
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }
    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';


    // --- 開閉ロジックの実装 ---
    var listItems = menuContent.querySelectorAll('li');

    // h2要素にクリックイベントを追加
    listItems.forEach(function(item, index) {
      if (item.classList.contains('h-h2')) {
        
        // クリックイベント
        item.addEventListener('click', function(e) {
          // リンクをクリックした場合はページ内遷移させたいので、イベントを止めない
          // ただし、アイコン付近をクリックした等の挙動を統一するため、
          // 開閉処理を行います。
          
          // クラスの付け替え（アイコンの回転用）
          item.classList.toggle('open');

          // 次のh2が出てくるまで、h3を表示/非表示切り替え
          for (var i = index + 1; i < listItems.length; i++) {
            var sibling = listItems[i];
            if (sibling.classList.contains('h-h2')) {
              break; // 次のh2に来たら終了
            }
            if (sibling.classList.contains('h-h3')) {
              if (item.classList.contains('open')) {
                sibling.style.display = 'block';
              } else {
                sibling.style.display = 'none';
              }
            }
          }
        });
      }
    });

    // --- 初期状態の設定（すべて閉じる） ---
    // もし最初から開いておきたい場合は、このブロックを削除するか調整してください
    listItems.forEach(function(item) {
      if (item.classList.contains('h-h3')) {
        item.style.display = 'none';
      }
    });


    // --- スクロール連動（ハイライト機能のみ残す） ---
    var header = document.querySelector('header.site-header');
    
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header ? header.getBoundingClientRect() : {top:0, height:0}; // headerがない場合の安全策
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var offset = headerTop + headerHeight + 20;

        if (headingRect.top <= offset) {
          var id = h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          
          if (curActive) {
            // もしアクティブになった項目が閉じているh2の中にあった場合、
            // 自動で開く処理を追加したい場合はここに記述します。
            // 今回は「手動開閉」を優先し、自動オープンはあえて行いません。
            
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }

      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
      }
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/paper_notes/"></data>

  <div class="wrapper">
    <div class="site-footer-inner">
<div>Copyright © 2023-current AkihikoWATANABE. The header images and any thumbnail images for the posts were generated by ChatGPT's DALL-E3.</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="https://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div class="footer-col rss-subscribe">Subscribe <a href="/paper_notes/feed.xml">via RSS</a>
</div>
    </div>
  </div>
</footer>
</body>
  </html>
