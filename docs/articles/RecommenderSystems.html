<!DOCTYPE html>
<html lang="ja"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-translate-customization" content="108d9124921d80c3-80e20d618ff053c8-g4f02ec6f3dba68b7-c"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>RecommenderSystemsに関する論文・技術記事メモの一覧 | わたしのべんきょうノート</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="RecommenderSystemsに関する論文・技術記事メモの一覧" />
<meta name="author" content="AkihikoWATANABE" />
<meta property="og:locale" content="ja" />
<meta name="description" content="RecommenderSystems #Pocket#LanguageModel#Prompting#Evaluation#RecSys#ReproducibilityIssue Date: 2025-07-21 Paper Note Revisiting Prompt Engineering: A Comprehensive Evaluation for LLM-based Personalized Recommendation, Genki Kusano+, RecSys25 SummaryLLMを用いた単一ユーザー設定の推薦タスクにおいて、プロンプトエンジニアリングが重要であることを示す。23種類のプロンプトタイプを比較した結果、コスト効率の良いLLMでは指示の言い換え、背景知識の考慮、推論プロセスの明確化が効果的であり、高性能なLLMではシンプルなプロンプトが優れることが分かった。精度とコストのバランスに基づくプロンプトとLLMの選択に関する提案を行う。 Comment元ポスト:https://x.com/_reachsumit/status/1947138463083716842?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-QRecSysにおける網羅的なpromptingの実験。非常に興味深い ![image](https://github.com/user-attachments/assets/bc21e547-08f7-4852-a045-84f18cd81502)実験で利用されたPrompting手法と相対的な改善幅" />
<meta property="og:description" content="RecommenderSystems #Pocket#LanguageModel#Prompting#Evaluation#RecSys#ReproducibilityIssue Date: 2025-07-21 Paper Note Revisiting Prompt Engineering: A Comprehensive Evaluation for LLM-based Personalized Recommendation, Genki Kusano+, RecSys25 SummaryLLMを用いた単一ユーザー設定の推薦タスクにおいて、プロンプトエンジニアリングが重要であることを示す。23種類のプロンプトタイプを比較した結果、コスト効率の良いLLMでは指示の言い換え、背景知識の考慮、推論プロセスの明確化が効果的であり、高性能なLLMではシンプルなプロンプトが優れることが分かった。精度とコストのバランスに基づくプロンプトとLLMの選択に関する提案を行う。 Comment元ポスト:https://x.com/_reachsumit/status/1947138463083716842?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-QRecSysにおける網羅的なpromptingの実験。非常に興味深い ![image](https://github.com/user-attachments/assets/bc21e547-08f7-4852-a045-84f18cd81502)実験で利用されたPrompting手法と相対的な改善幅" />
<link rel="canonical" href="http://akihikowatanabe.github.io/paper_notes/articles/RecommenderSystems.html" />
<meta property="og:url" content="http://akihikowatanabe.github.io/paper_notes/articles/RecommenderSystems.html" />
<meta property="og:site_name" content="わたしのべんきょうノート" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-07-22T16:39:35+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="RecommenderSystemsに関する論文・技術記事メモの一覧" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"AkihikoWATANABE"},"dateModified":"2025-07-22T16:39:35+00:00","datePublished":"2025-07-22T16:39:35+00:00","description":"RecommenderSystems #Pocket#LanguageModel#Prompting#Evaluation#RecSys#ReproducibilityIssue Date: 2025-07-21 Paper Note Revisiting Prompt Engineering: A Comprehensive Evaluation for LLM-based Personalized Recommendation, Genki Kusano+, RecSys25 SummaryLLMを用いた単一ユーザー設定の推薦タスクにおいて、プロンプトエンジニアリングが重要であることを示す。23種類のプロンプトタイプを比較した結果、コスト効率の良いLLMでは指示の言い換え、背景知識の考慮、推論プロセスの明確化が効果的であり、高性能なLLMではシンプルなプロンプトが優れることが分かった。精度とコストのバランスに基づくプロンプトとLLMの選択に関する提案を行う。 Comment元ポスト:https://x.com/_reachsumit/status/1947138463083716842?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-QRecSysにおける網羅的なpromptingの実験。非常に興味深い ![image](https://github.com/user-attachments/assets/bc21e547-08f7-4852-a045-84f18cd81502)実験で利用されたPrompting手法と相対的な改善幅","headline":"RecommenderSystemsに関する論文・技術記事メモの一覧","mainEntityOfPage":{"@type":"WebPage","@id":"http://akihikowatanabe.github.io/paper_notes/articles/RecommenderSystems.html"},"url":"http://akihikowatanabe.github.io/paper_notes/articles/RecommenderSystems.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="icon" href="">
  <link rel="canonical" href="http://akihikowatanabe.github.io">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-noto-sans@0.0.72/index.min.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/main.css">
  <link rel="stylesheet" href="/paper_notes/assets/css/custom_button.css">
  <script src="/paper_notes/assets/js/main.js"></script>
  <script src="https://d3js.org/d3.v5.min.js"></script><link type="application/atom+xml" rel="alternate" href="http://akihikowatanabe.github.io/paper_notes/feed.xml" title="わたしのべんきょうノート" /><script>
  function showMore(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "block";
          
      // このボタンの参照を取得して非表示にします
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "none";
      }
          
      // hideボタンの参照を取得して表示します
      const hideButton = contentDiv.querySelector('button[onclick^="hideContent"]');
      if (hideButton) {
        hideButton.style.display = "block";
      }
    }
  }

  function hideContent(index) {
    const contentDivs = document.getElementsByClassName('hidden-content');
    const contentDiv = contentDivs[index];

    if (contentDiv) {
      contentDiv.style.display = "none";
  
      // moreボタンの参照を取得して表示します
      const moreButtons = document.querySelectorAll('button[onclick^="showMore"]');
      const moreButton = moreButtons[index];
      if (moreButton) {
        moreButton.style.display = "block";
      }
  
      // このボタンを隠します
      const hideButtons = document.querySelectorAll('button[onclick^="hideContent"]');
      const hideButton = hideButtons[index];
      if (hideButton) {
        hideButton.style.display = "none";
      }
    }
  }
</script><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/default.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
<!-- and it's easy to individually load additional languages -->
<script charset="UTF-8"
        src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/languages/go.min.js"
        async></script>



















<script>
// Init highlight js
document.addEventListener('DOMContentLoaded', function(event) {
  var els = document.querySelectorAll('pre code')

  function addLangData(block) {
    var outer = block.parentElement.parentElement.parentElement;
    var lang = block.getAttribute('data-lang');
    for (var i = 0; i < outer.classList.length; i++) {
      var cls = outer.classList[i];
      if (cls.startsWith('language-')) {
        lang = cls;
        break;
      }
    }
    if (!lang) {
      cls = block.getAttribute('class');
      lang = cls ? cls.replace('hljs ', '') : '';
    }
    if (lang.startsWith('language-')) {
      lang = lang.substr(9);
    }
    block.setAttribute('class', 'hljs ' + lang);
    block.parentNode.setAttribute('data-lang', lang);
  }

  function addBadge(block) {
    var enabled = ('true' || 'true').toLowerCase();
    if (enabled == 'true') {
      var pre = block.parentElement;
      pre.classList.add('badge');
    }
  }

  function handle(block) {
    addLangData(block);
    addBadge(block)
    hljs.highlightBlock(block);
  }

  for (var i = 0; i < els.length; i++) {
    var el = els[i];
    handle(el);
  }
});
</script>

<style>
  /* code language badge */
  pre.badge::before {
    content: attr(data-lang);
    color: #fff;
    background-color: #ff4e00;
    padding: 0 .5em;
    border-radius: 0 2px;
    text-transform: uppercase;
    text-align: center;
    min-width: 32px;
    display: inline-block;
    position: absolute;
    right: 0;
  }

  /* fix wrong badge display for firefox browser */
  code > table pre::before {
    display: none;
  }
</style>
<script
  src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe-lightbox.umd.min.js" async></script>
<script
  src="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/umd/photoswipe.umd.min.js" async></script>
<link
  href="//cdnjs.cloudflare.com/ajax/libs/photoswipe/5.3.7/photoswipe.min.css"
  rel="stylesheet"
/>
<style>
  .pswp .pswp__container .pswp__img {
    background-color: white;
  }
</style>

<script>
  function initPhotoSwipe() {
    let customOptions = {};

    try {
      const data = `{"gallery"=>"section.main", "children"=>"a.photo-swipe", "bgOpacity"=>0.8, "padding"=>{"top"=>20, "bottom"=>40, "left"=>100, "right"=>100}}`.replaceAll("=>", ":");
      customOptions = JSON.parse(data);
    } catch (e) {
      console.info("Invalid custom photo previewer options! " + e.message);
    }

    // Define object and gallery options
    const options = Object.assign(
      {
        gallery: "section.main",
        children: "a.photo-swipe",
        photo_scale: 2,
        // dynamic import is not supported in UMD version
        pswpModule: PhotoSwipe,
      },
      customOptions
    );

    const galleryEl = document.querySelector(options.gallery);
    if (!galleryEl) {
      return;
    }

    const imgEls = [];
    const els = galleryEl.querySelectorAll("img:not(.emoji)");
    els.forEach((el) => {
      if (el.src.trim() == "") {
        return;
      }
      if (!imgEls.includes(el)) {
        imgEls.push(el);
      }
    });

    if (imgEls.length === 0) {
      return;
    }

    imgEls.forEach((imgEl) => {
      imgEl.outerHTML = `
      <a class="photo-swipe"
        href="${imgEl.src}"
        data-pswp-width="${
          Math.max(imgEl.naturalWidth, imgEl.width) * options.photo_scale
        }"
        data-pswp-height="${
          Math.max(imgEl.naturalHeight, imgEl.height) * options.photo_scale
        }"
        data-pswp-caption="${imgEl.getAttribute("caption") || imgEl.alt}"
        target="_blank">
        ${imgEl.outerHTML}
      </a>`;
    });

    // Initialize PhotoSwipe 5
    var lightbox = new PhotoSwipeLightbox(options);

    lightbox.init();
  }

  window.addEventListener("load", initPhotoSwipe);
</script>
<meta name="google-site-verification" content="u_DTTPcCZ806iq51zgirHyWq3556HUKGq8AQfH91iFI" />
</head><body>





































































































































<header class="site-header site-header-transparent" role="banner">

  <div class="wrapper">
    <div class="site-header-inner"><span class="site-brand"><a class="site-brand-inner" rel="author" href="/paper_notes/">
  <img class="site-favicon" title="わたしのべんきょうノート" src="" onerror="this.style.display='none'">
  わたしのべんきょうノート
</a>
</span><nav class="site-nav">
          <input type="checkbox" id="nav-trigger" class="nav-trigger" />
          <label for="nav-trigger">
            <span class="menu-icon">
              <svg viewBox="0 0 18 15" width="18px" height="15px">
                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
              </svg>
            </span>
          </label>

          <div class="trigger">









<span class="page-link">



<div id="google_translate_element" style="display: none;">
</div>

<span class="ct-language">
  <ul class="list-unstyled ct-language-dropdown">
    
      <li>
        <a href="#" class="lang-select" data-lang="en">
          
          <img src="https://cdn.countryflags.com/thumbs/united-states-of-america/flag-400.png" title="English">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="fr">
          
          <img src="https://cdn.countryflags.com/thumbs/france/flag-400.png" title="French">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="zh-CN">
          
          <img src="https://cdn.countryflags.com/thumbs/china/flag-400.png" title="Chinese(Simple)">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ja">
          
          <img src="https://cdn.countryflags.com/thumbs/japan/flag-400.png" title="Japanese">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ko">
          
          <img src="https://cdn.countryflags.com/thumbs/south-korea/flag-400.png" title="Korean">
          
        </a>
      </li>
    
      <li>
        <a href="#" class="lang-select" data-lang="ru">
          
          <img src="https://cdn.countryflags.com/thumbs/russia/flag-400.png" title="Russian">
          
        </a>
      </li>
    
  </ul>
</span>

<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'ja',
    autoDisplay: false,
    layout: google.translate.TranslateElement.InlineLayout.VERTICAL
  }, 'google_translate_element');

  // Links to cross-origin destinations are unsafe
  var gll = document.getElementsByClassName('goog-logo-link')[0];
  if (gll) {
    gll.setAttribute('rel', 'noopener');
  }

  function restoreLang() {
    var iframe = document.getElementsByClassName('goog-te-banner-frame')[0];
    if (!iframe) return;

    var innerDoc = iframe.contentDocument || iframe.contentWindow.document;
    var restore_el = innerDoc.getElementsByTagName("button");

    for (var i = 0; i < restore_el.length; i++) {
      if (restore_el[i].id.indexOf("restore") >= 0) {
        restore_el[i].click();
        var close_el = innerDoc.getElementsByClassName("goog-close-link");
        close_el[0].click();
        return;
      }
    }
  }

  function triggerHtmlEvent(element, eventName) {
    var event;
    if (document.createEvent) {
      event = document.createEvent('HTMLEvents');
      event.initEvent(eventName, true, true);
      element.dispatchEvent(event);
    } else {
      event = document.createEventObject();
      event.eventType = eventName;
      element.fireEvent('on' + event.eventType, event);
    }
  }

  var googleCombo = document.querySelector("select.goog-te-combo");
  var langSelect = document.querySelector('.ct-language');
  langSelect.addEventListener('click', function(event) {
    if (!event.target) {
      return;
    }

    var selected = document.querySelector('.ct-language .ct-language-selected');
    if (selected) {
      selected.classList.remove('ct-language-selected');
    }

    var target = event.target;
    while (target && target !== langSelect ) {
      if (target.matches('.lang-select')) {
        break;
      }
      target = target.parentElement;
    }

    if (target && target.matches('.lang-select')) {
      var lang = target.getAttribute('data-lang');
      if (googleCombo.value == lang) {
        restoreLang();
      } else {
        target.parentElement.classList.add('ct-language-selected');
        googleCombo.value = lang;
        triggerHtmlEvent(googleCombo, 'change');
      }
    }

    event.preventDefault();
  });
}
</script>

<script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit" async></script>
</span></div>
        </nav></div>
  </div>
</header>

<script>
  function initHeader() {
    var lastScrollY = getScrollPos().y;
    var documentElement = document.documentElement;

    function storeScrollData() {
      var y = getScrollPos().y;documentElement.setAttribute("data-header-transparent", "");var scrollStatus = "";

      if (y <= 0) {
        scrollStatus = "top";
      } else if ((window.innerHeight + y) >= document.body.offsetHeight) {
        scrollStatus = "bottom";
      } else {
        var isScrollDown = (y - lastScrollY > 0) ? true : false;
        scrollStatus = isScrollDown ? "down" : "up";
      }

      lastScrollY = y;
      documentElement.setAttribute("data-scroll-status", scrollStatus);
    }

    window.addEventListener('scroll', function(e) {
      storeScrollData();
    });

    storeScrollData();
  }
  document.addEventListener('DOMContentLoaded', initHeader);
</script>


























































































































































<style>
    html .page-banner .page-banner-img > *:first-child {
      opacity: 0.4;
    }

    html[data-theme="dark"] .page-banner .page-banner-img > *:first-child {
      opacity: 0.2872;
    }
  </style><section class="page-banner">
    <div class="page-banner-img"><div style="background-image: url(/paper_notes/assets/images/banner.png)"></div>
        <img class="img-placeholder" src="/paper_notes/assets/images/banner.png"></div>
    <div class="wrapper">
      <div class="page-banner-inner"><header class="post-header">
  <h1 class="post-title p-name" itemprop="name headline">わたしのべんきょうノート</h1>
  <h2 class="post-subtitle">勉強した論文や技術等の情報をGithubのIssueにメモっているひとのブログ。
それなりにメモの量が蓄積されてきたので、一度整理したいなと思いブログはじめてみました！
自然言語処理(NLP), 推薦システム(RecommenderSystem), Educational Data Mining (EDM), Learning Analytics (LA)などの分野のメモが多いと思います。
最近は特にLLMの勉強が多めです :)</h2>

  <div class="post-meta">
    <time class="dt-published" datetime="2025-07-22T16:39:35+00:00" itemprop="datePublished"><i class="fa fa-calendar"></i> Jul 22, 2025
    </time><span class="post-author left-vsplit"><i class="fa fa-pencil"></i> AkihikoWATANABE</span>
    
































    <span class="post-reading-time left-vsplit"><i class="fa fa-clock-o"></i> About 4 hours 20 mins</span>
  </div></header>
</div>
    </div>
  </section><script>
  function hashLocate(hashValue) {
    hashValue = hashValue.replace(/^.*#h-/, '');
    hashValue = decodeURIComponent(hashValue);
    var element = document.getElementById(hashValue);

    if (!element) {
      return;
    }

    var header = document.querySelector('header.site-header');
    var headerRect = header.getBoundingClientRect();
    var headerTop = Math.floor(headerRect.top);
    var headerHeight = Math.floor(headerRect.height);
    var scrollPos = getScrollPos();
    var offsetY = element.offsetTop - (headerTop + headerHeight + 20);

    if (offsetY == scrollPos.y) {
      return;
    }

    if (headerTop == 0  && offsetY > scrollPos.y) {
      offsetY += headerHeight + 2;
    } else if (headerTop < 0  && offsetY < scrollPos.y) {
      offsetY -= headerHeight - 2;
    }

    smoothScrollTo(offsetY);
  }

  // The first event occurred
  window.addEventListener('load', function(event) {
    if (window.location.hash) {
      hashLocate(window.location.hash);
    }
  });

  // The first event occurred
  window.addEventListener('click', function(event) {
    if (event.target.tagName.toLowerCase() == 'a') {
      hashLocate(event.target.getAttribute('href'));
    }
  });
</script>
<div class="theme-toggle">
  <input type="checkbox" id="theme-switch">
  <label for="theme-switch">
    <div class="toggle"></div>
    <div class="names">
      <p class="light">Light</p>
      <p class="dark">Dark</p>
    </div>
  </label>
</div>




<script>
  (function() {
    var sw = document.getElementById('theme-switch');
    var html = document.getElementsByTagName('html')[0];
    var nightModeOption = ('off' || 'auto').toLowerCase();
    var storage = nightModeOption === 'manual'
        ? localStorage
        : sessionStorage;
    var themeData = loadThemeData();

    function saveThemeData(data) {
      storage.setItem('theme', JSON.stringify(data));
    }

    function loadThemeData() {
      var data = storage.getItem('theme');
      try {
        data = JSON.parse(data ? data : '');
      } catch(e) {
        data = { nightShift: undefined, autoToggleAt: 0 };
        saveThemeData(data);
      }
      return data;
    }

    function handleThemeToggle(nightShift) {
      themeData.nightShift = nightShift;
      saveThemeData(themeData);
      html.dataset.theme = nightShift ? 'dark' : 'light';
      setTimeout(function() {
        sw.checked = nightShift ? true : false;
      }, 50);
    }

    function autoThemeToggle() {
      // Next time point of theme toggle
      var now = new Date();
      var toggleAt = new Date();
      var hours = now.getHours();
      var nightShift = hours >= 19 || hours <=7;

      if (nightShift) {
        if (hours > 7) {
          toggleAt.setDate(toggleAt.getDate() + 1);
        }
        toggleAt.setHours(7);
      } else {
        toggleAt.setHours(19);
      }

      toggleAt.setMinutes(0);
      toggleAt.setSeconds(0);
      toggleAt.setMilliseconds(0)

      var delay = toggleAt.getTime() - now.getTime();

      // auto toggle theme mode
      setTimeout(function() {
        handleThemeToggle(!nightShift);
      }, delay);

      return {
        nightShift: nightShift,
        toggleAt: toggleAt.getTime()
      };
    }

    // Listen the theme toggle event
    sw.addEventListener('change', function(event) {
      handleThemeToggle(event.target.checked);
    });

    if (nightModeOption == 'auto') {
      var data = autoThemeToggle();

      // Toggle theme by local setting
      if (data.toggleAt > themeData.autoToggleAt) {
        themeData.autoToggleAt = data.toggleAt;
        handleThemeToggle(data.nightShift);
      } else {
        handleThemeToggle(themeData.nightShift);
      }
    } else if (nightModeOption == 'manual') {
      handleThemeToggle(themeData.nightShift);
    } else {
      var nightShift = themeData.nightShift;
      if (nightShift === undefined) {
        nightShift = nightModeOption === 'on';
      }
      handleThemeToggle(nightShift);
    }
  })();
</script>
<div id="click-to-top" class="click-to-top">
  <i class="fa fa-arrow-up"></i>
</div>
<script>
  (function () {
    const clickToTop = document.getElementById('click-to-top');
    window.addEventListener('scroll', () => {
      if (window.scrollY > 100) {
        clickToTop.classList.add('show')
      }else {
        clickToTop.classList.remove('show')
      }
    });
    clickToTop.addEventListener('click', () => {
      window.smoothScrollTo(0);
    });
  })();
</script>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="framework">
  <section class="main">

     <div class="post">
  <section>









<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

    <div class="post-content e-content" itemprop="articleBody">

      <h2 id="recommendersystems">RecommenderSystems</h2>
<div class="visible-content">
<a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/Prompting.html">#Prompting</a><a class="button" href="articles/Evaluation.html">#Evaluation</a><a class="button" href="articles/RecSys.html">#RecSys</a><a class="button" href="articles/Reproducibility.html">#Reproducibility</a><br /><span class="issue_date">Issue Date: 2025-07-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2266">Paper Note Revisiting Prompt Engineering: A Comprehensive Evaluation for LLM-based   Personalized Recommendation, Genki Kusano+, RecSys25</a>
<span class="snippet"><span>Summary</span>LLMを用いた単一ユーザー設定の推薦タスクにおいて、プロンプトエンジニアリングが重要であることを示す。23種類のプロンプトタイプを比較した結果、コスト効率の良いLLMでは指示の言い換え、背景知識の考慮、推論プロセスの明確化が効果的であり、高性能なLLMではシンプルなプロンプトが優れることが分かった。精度とコストのバランスに基づくプロンプトとLLMの選択に関する提案を行う。</span>
<span class="snippet"><span>Comment</span>元ポスト:https://x.com/_reachsumit/status/1947138463083716842?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-QRecSysにおける網羅的なpromptingの実験。非常に興味深い
![image](https://github.com/user-attachments/assets/bc21e547-08f7-4852-a045-84f18cd81502)実験で利用されたPrompting手法と相対的な改善幅

![image](https://github.com/user-attachments/assets/9f28c445-0036-4441-a947-9774b00d81c3)

![image](https://github.com/user-attachments/assets/e657da0f-5faf-42e3-aa39-e37965b8835d)

RePhrase,StepBack,Explain,Summalize-User,Recency-Focusedが、様々なモデル、データセット、ユーザの特性（Light, Heavy)において安定した性能を示しており（少なくともベースラインからの性能の劣化がない）、model agnosticに安定した性能を発揮できるpromptingが存在することが明らかになった。一方、Phi-4, nova-liteについてはBaselineから有意に性能が改善したPromptingはなかった。これはモデルは他のモデルよりもそもそもの予測性能が低く、複雑なinstructionを理解する能力が不足しているため、Promptデザインが与える影響が小さいことが示唆される。

特定のモデルでのみ良い性能を発揮するPromptingも存在した。たとえばRe-Reading, Echoは、Llama3.3-70Bでは性能が改善したが、gpt-4.1-mini, gpt-4o-miniでは性能が悪化した。ReActはgpt-4.1-miniとLlamd3.3-70Bで最高性能を達成したが、gpt-4o-miniでは最も性能が悪かった。

NLPにおいて一般的に利用されるprompting、RolePlay, Mock, Plan-Solve, DeepBreath, Emotion, Step-by-Stepなどは、推薦のAcc.を改善しなかった。このことより、ユーザの嗜好を捉えることが重要なランキングタスクにおいては、これらプロンプトが有効でないことが示唆される。

![image](https://github.com/user-attachments/assets/f24850bd-6f76-4ee0-b78e-2104d1e24a36)

![image](https://github.com/user-attachments/assets/d0f90be5-071c-44c9-9380-5cebd383ab86)

続いて、LLMやデータセットに関わらず高い性能を発揮するpromptingをlinear mixed-effects model（ランダム効果として、ユーザ、LLM、メトリックを導入し、これらを制御する項を線形回帰に導入。promptingを固定効果としAccに対する寄与をfittingし、多様な状況で高い性能を発揮するPromptを明らかにする)によって分析した結果、ReAct, Rephrase, Step-Backが有意に全てのデータセット、LLMにおいて高い性能を示すことが明らかになった。
![image](https://github.com/user-attachments/assets/4c6d49d5-6464-4297-b714-de1faa95a4c8)</span>
<a class="button" href="articles/Embeddings.html">#Embeddings</a><a class="button" href="articles/InformationRetrieval.html">#InformationRetrieval</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/RepresentationLearning.html">#RepresentationLearning</a><a class="button" href="articles/InstructionTuning.html">#InstructionTuning</a><a class="button" href="articles/ContrastiveLearning.html">#ContrastiveLearning</a><a class="button" href="articles/ICLR.html">#ICLR</a><a class="button" href="articles/Generalization.html">#Generalization</a><a class="button" href="articles/Decoder.html">#Decoder</a><br /><span class="issue_date">Issue Date: 2025-07-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2182">Paper Note NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding   Models, Chankyu Lee+, ICLR25</a>
<span class="snippet"><span>Summary</span>デコーダー専用のLLMベースの埋め込みモデルNV-Embedは、BERTやT5を上回る性能を示す。アーキテクチャ設計やトレーニング手法を工夫し、検索精度を向上させるために潜在的注意層を提案。二段階の対照的指示調整手法を導入し、検索と非検索タスクの両方で精度を向上。NV-EmbedモデルはMTEBリーダーボードで1位を獲得し、ドメイン外情報検索でも高スコアを達成。モデル圧縮技術の分析も行っている。</span>
<span class="snippet"><span>Comment</span>Decoder-Only LLMのlast hidden layerのmatrixを新たに導入したLatent Attention Blockのinputとし、Latent Attention BlockはEmbeddingをOutputする。Latent Attention Blockは、last hidden layer (系列長l×dの
matrix)をQueryとみなし、保持しているLatent Array(trainableなmatrixで辞書として機能する;後述の学習においてパラメータが学習される)[^1]をK,Vとして、CrossAttentionによってcontext vectorを生成し、その後MLPとMean Poolingを実施することでEmbeddingに変換する。
![image](https://github.com/user-attachments/assets/7a023273-aafd-4cfa-9b39-961180543ae9)

![image](https://github.com/user-attachments/assets/767e3ac1-fe70-4653-bbe7-091c1f1dc0f7)

学習は2段階で行われ、まずQAなどのRetrievalタスク用のデータセットをIn Batch negativeを用いてContrastive Learningしモデルの検索能力を高める。その後、検索と非検索タスクの両方を用いて、hard negativeによってcontrastive learningを実施し、検索以外のタスクの能力も高める（下表）。両者において、instructionテンプレートを用いて、instructionによって条件付けて学習をすることで、instructionに応じて生成されるEmbeddingが変化するようにする。また、学習時にはLLMのcausal maskは無くし、bidirectionalにrepresentationを考慮できるようにする。
![image](https://github.com/user-attachments/assets/26d4e126-1d18-421e-873f-f0eef4fc2026)

[^1]: #2183 Perceiver-IOにインスパイアされている。</span>
<a class="button" href="articles/Embeddings.html">#Embeddings</a><a class="button" href="articles/InformationRetrieval.html">#InformationRetrieval</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/SequentialRecommendation.html">#SequentialRecommendation</a><a class="button" href="articles/Generalization.html">#Generalization</a><br /><span class="issue_date">Issue Date: 2025-07-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2151">Paper Note Do We Really Need Specialization? Evaluating Generalist Text Embeddings  for Zero-Shot Recommendation and Search, Matteo Attimonelli+, arXiv25</a>
<span class="snippet"><span>Summary</span>事前学習済み言語モデル（GTEs）は、逐次推薦や製品検索においてファインチューニングなしで優れたゼロショット性能を発揮し、従来のモデルを上回ることを示す。GTEsは埋め込み空間に特徴を均等に分配することで表現力を高め、埋め込み次元の圧縮がノイズを減少させ、専門モデルの性能向上に寄与する。再現性のためにリポジトリを提供。</span>
<span class="snippet"><span>Comment</span>元ポスト:https://x.com/_reachsumit/status/1942463379639349654?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-Q関連:
- #2182</span>
</div>
<p><button onclick="showMore(0)">more</button></p>

<div class="hidden-content">
<a class="button" href="articles/ListWise.html">#ListWise</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/Alignment.html">#Alignment</a><a class="button" href="articles/Transformer.html">#Transformer</a><a class="button" href="articles/SequentialRecommendation.html">#SequentialRecommendation</a><br /><span class="issue_date">Issue Date: 2025-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2136">Paper Note Listwise Preference Alignment Optimization for Tail Item Recommendation, Zihao Li+, arXiv25</a>
<span class="snippet"><span>Summary</span>LPO4Recは、テールアイテム推薦におけるPreference alignmentの課題を解決するために提案された手法で、Bradley-Terryモデルをペアワイズからリストワイズ比較に拡張し、効率的なトレーニングを実現。明示的な報酬モデリングなしで、テールアイテムを優先する負のサンプリング戦略を導入し、パフォーマンスを最大50%向上させ、GPUメモリ使用量を17.9%削減。実験結果は3つの公開データセットで示されている。</span>
<span class="snippet"><span>Comment</span>元ポスト:https://x.com/_reachsumit/status/1941004418255933662?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-Qtail itemに強い手法らしい。LLMを用いたGenerative Recommendationではなく、1 BlockのTransformerにlistwiseなpreferenceを反映したlossを適用したものっぽい。一貫して性能は高そうに見えるが、再現性はどうだろうか。
![image](https://github.com/user-attachments/assets/10c66c84-b421-4be1-8cd7-3d037e8cc683)関連(SASRec):
- #2137pointwise, pairwise, listwiseの基礎はこちらを参照:
- #187</span>
<a class="button" href="articles/Embeddings.html">#Embeddings</a><a class="button" href="articles/EfficiencyImprovement.html">#EfficiencyImprovement</a><a class="button" href="articles/InformationRetrieval.html">#InformationRetrieval</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/RepresentationLearning.html">#RepresentationLearning</a><br /><span class="issue_date">Issue Date: 2025-06-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2087">Paper Note NEAR$^2$: A Nested Embedding Approach to Efficient Product Retrieval and  Ranking, Shenbin Qian+, arXiv25</a>
<span class="snippet"><span>Summary</span>Eコマース情報検索システムは、ユーザーの意図を正確に理解しつつ、大規模な商品カタログを効率的に処理することが難しい。本論文では、NEAR$^2$というネストされた埋め込みアプローチを提案し、推論時の埋め込みサイズを最大12倍効率化し、トレーニングコストを増やさずにトランスフォーマーモデルの精度を向上させる。さまざまなIR課題に対して異なる損失関数を用いて検証した結果、既存モデルよりも小さな埋め込み次元での性能向上を達成した。</span>
<span class="snippet"><span>Comment</span>元ポスト:https://x.com/_reachsumit/status/1937697219387490566?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-Q</span>
<a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><br /><span class="issue_date">Issue Date: 2025-04-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1910">Generative Product Recommendations for Implicit Superlative Queries, Kaustubh D. Dhole+, arXiv25</a>
<span class="snippet"><span>Summary</span>レコメンダーシステムにおいて、ユーザーの曖昧なクエリに対して大規模言語モデル（LLMs）を用いて暗黙の属性を生成し、製品推薦を改善する方法を探る。新たに提案する4ポイントスキーマ「SUPERB」を用いて最上級クエリに対する製品候補を注釈付けし、既存の検索およびランキング手法を評価する。</span>
<span class="snippet"><span>Comment</span>元ポスト:https://x.com/_reachsumit/status/1917084325499273671?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-Q</span>
<a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html">#RAG(RetrievalAugmentedGeneration)</a><a class="button" href="articles/Reasoning.html">#Reasoning</a><br /><span class="issue_date">Issue Date: 2025-03-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1839">RALLRec+: Retrieval Augmented Large Language Model Recommendation with  Reasoning, Sichun Luo+, arXiv25</a>
<span class="snippet"><span>Summary</span>RALLRec+は、LLMsを用いてレコメンダーシステムのretrievalとgenerationを強化する手法。retrieval段階では、アイテム説明を生成し、テキスト信号と協調信号を結合。生成段階では、推論LLMsを評価し、知識注入プロンプティングで汎用LLMsと統合。実験により、提案手法の有効性が確認された。</span>
<span class="snippet"><span>Comment</span>元ポスト:https://x.com/_reachsumit/status/1905107217663336832?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-QReasoning LLMをRecSysに応用する初めての研究（らしいことがRelated Workに書かれている）arxivのadminより以下のコメントが追記されている
&gt; 	arXiv admin note: substantial text overlap with arXiv:2502.06101

コメント中の研究は下記である
- #1840</span>
<a class="button" href="articles/Multi.html">#Multi</a><a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/MultitaskLearning.html">#MultitaskLearning</a><a class="button" href="articles/MulltiModal.html">#MulltiModal</a><br /><span class="issue_date">Issue Date: 2025-03-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1779">Joint Modeling in Recommendations: A Survey, Xiangyu Zhao+, arXiv25</a>
<span class="snippet"><span>Summary</span>デジタル環境におけるDeep Recommender Systems（DRS）は、ユーザーの好みに基づくコンテンツ推薦に重要だが、従来の手法は単一のタスクやデータに依存し、複雑な好みを反映できない。これを克服するために、共同モデリングアプローチが必要であり、推薦の精度とカスタマイズを向上させる。本論文では、共同モデリングをマルチタスク、マルチシナリオ、マルチモーダル、マルチビヘイビアの4次元で定義し、最新の進展と研究の方向性を探る。最後に、将来の研究の道筋を示し、結論を述べる。</span>
<span class="snippet"><span>Comment</span>元ポスト:https://x.com/_reachsumit/status/1896408792952410496?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-Q</span>
<a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/Personalization.html">#Personalization</a><a class="button" href="articles/FoundationModel.html">#FoundationModel</a><br /><span class="issue_date">Issue Date: 2025-01-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1739">360Brew: A Decoder-only Foundation Model for Personalized Ranking and  Recommendation, Hamed Firooz+, arXiv25</a>
<span class="snippet"><span>Summary</span>ランキングおよび推薦システムの課題に対処するため、テキストインターフェースを持つ大規模基盤モデルを活用した研究を紹介。150Bパラメータのデコーダー専用モデル360Brew V1.0は、LinkedInのデータを用いて30以上の予測タスクを解決し、従来の専用モデルと同等以上のパフォーマンスを達成。特徴エンジニアリングの複雑さを軽減し、複数のタスクを単一モデルで管理可能にする利点を示す。</span>
<span class="snippet"><span>Comment</span>元ポスト:https://x.com/_reachsumit/status/1884455910824948154?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-Q</span>
<a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><br /><span class="issue_date">Issue Date: 2025-01-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1736">Pre-train and Fine-tune: Recommenders as Large Models, Zhenhao Jiang+, arXiv25</a>
<span class="snippet"><span>Summary</span>ユーザーの興味の変化を捉えるため、レコメンダーを大規模な事前学習モデルとしてファインチューニングするアプローチを提案。情報ボトルネック理論に基づき、知識圧縮と知識マッチングの二つのフェーズを定義したIAK技術を設計。実験により優位性を示し、オンラインプラットフォームでの展開から得た教訓や潜在的な問題への解決策も提示。IAK技術を用いたレコメンダーは、オンラインフードプラットフォームでの展開により大きな利益を上げている。</span>
<span class="snippet"><span>Comment</span>元ポスト:https://x.com/_reachsumit/status/1883719872540254355?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-Q</span>
<a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/Contents-based.html">#Contents-based</a><br /><span class="issue_date">Issue Date: 2025-01-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1666">Cold-Start Recommendation towards the Era of Large Language Models  （LLMs）: A Comprehensive Survey and Roadmap, Weizhi Zhang+, arXiv25</a>
<span class="snippet"><span>Summary</span>コールドスタート問題はレコメンダーシステムの重要な課題であり、新しいユーザーやアイテムのモデル化に焦点を当てている。大規模言語モデル（LLMs）の成功により、CSRに新たな可能性が生まれているが、包括的なレビューが不足している。本論文では、CSRのロードマップや関連文献をレビューし、LLMsが情報を活用する方法を探求することで、研究と産業界に新たな洞察を提供することを目指す。関連リソースはコミュニティのために収集・更新されている。</span>
<span class="snippet"><span>Comment</span>元ポスト:https://x.com/_reachsumit/status/1876093584593793091?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-Q</span>
<a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/UAI.html">#UAI</a><a class="button" href="articles/read-later.html">#read-later</a><a class="button" href="articles/ColdStart.html">#ColdStart</a><br /><span class="issue_date">Issue Date: 2025-05-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1965">Cold-start Recommendation by Personalized Embedding Region Elicitation, Hieu Trung Nguyen+, UAI24</a>
<span class="snippet"><span>Summary</span>レコメンダーシステムのコールドスタート問題に対処するため、2段階のパーソナライズされた引き出しスキームを提案。最初に人気アイテムの評価を求め、その後、順次適応的にアイテム評価を行う。ユーザーの埋め込み値を領域推定として表現し、評価情報の価値を定量化。提案手法は既存の方法と比較して有効性を示す。</span>
<span class="snippet"><span>Comment</span>OpenReview:https://openreview.net/forum?id=ciOkU5YpvU</span>
<a class="button" href="articles/Evaluation.html">#Evaluation</a><a class="button" href="articles/RecSys.html">#RecSys</a><br /><span class="issue_date">Issue Date: 2025-04-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1879">Revisiting BPR: A Replicability Study of a Common Recommender System   Baseline, Aleksandr Milogradskii+, RecSys24</a>
<span class="snippet"><span>Summary</span>BPRは協調フィルタリングのベンチマークだが、実装の微妙な点が見落とされ、他手法に劣るとされている。本研究ではBPRの特徴と実装の不一致を分析し、最大50%の性能低下を示す。適切なハイパーパラメータ調整により、BPRはトップn推薦タスクで最先端手法に近い性能を達成し、Million Song DatasetではMult-VAEを10%上回る結果を示した。</span>
<span class="snippet"><span>Comment</span>BPR、実装によってまるで性能が違う…
![image](https://github.com/user-attachments/assets/916df15b-53e6-4589-ab64-ef113a79314a)

実装の違い
![image](https://github.com/user-attachments/assets/42206524-c863-478d-99c0-7b605fef2da7)</span>
<a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/UserModeling.html">#UserModeling</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/CTRPrediction.html">#CTRPrediction</a><a class="button" href="articles/RAG(RetrievalAugmentedGeneration).html">#RAG(RetrievalAugmentedGeneration)</a><a class="button" href="articles/LongSequence.html">#LongSequence</a><a class="button" href="articles/WWW.html">#WWW</a><br /><span class="issue_date">Issue Date: 2025-03-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1840">ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential   Behavior Comprehension in Recommendation, Jianghao Lin+, WWW24</a>
<span class="snippet"><span>Summary</span>本論文では、ゼロショットおよび少ショットの推薦タスクにおいて、大規模言語モデル（LLMs）を強化する新しいフレームワーク「ReLLa」を提案。LLMsが長いユーザー行動シーケンスから情報を抽出できない問題に対処し、セマンティックユーザー行動検索（SUBR）を用いてデータ品質を向上させる。少ショット設定では、検索強化指示チューニング（ReiT）を設計し、混合トレーニングデータセットを使用。実験により、少ショットReLLaが従来のCTRモデルを上回る性能を示した。</span>
<span class="snippet"><span>Comment</span>- #1839

のベースラインLLMでCTR予測する際の性能を向上した研究。

そもそもLLMでCTR予測をする際は、ユーザのデモグラ情報とアクティビティログなどのユーザプロファイルと、ターゲットアイテムの情報でpromptingし、yes/noを出力させる。yes/noトークンのスコアに対して2次元のソフトマックスを適用して[0, 1]のスコアを得ることで、CTR予測をする。
![image](https://github.com/user-attachments/assets/75025947-f3bb-49d0-a8f1-e05c429183a4)

この研究ではコンテキストにユーザのログを入れても性能がスケールしない問題に対処するために
![image](https://github.com/user-attachments/assets/69c27a84-0456-4ddf-aded-515608e27065)

直近のアクティビティログではなく、ターゲットアイテムと意味的に類似したアイテムに関するログをコンテキストに入れ（SUBR）、zero shotのinferenceに活用する。
![image](https://github.com/user-attachments/assets/a5a2a300-ddca-42cc-97d7-251487ccfa3a)

few-shot recommendation（少量のクリックスルーログを用いてLLMをSFTすることでCTR予測する手法）においては、上述の意味的に類似したアイテムをdata augmentationに利用し（i.e, promptに埋め込むアクティビティログの量を増やして）学習する。
![image](https://github.com/user-attachments/assets/b98af740-0628-4e98-a80f-30ff105621e1)

zeroshotにおいて、SUBRで性能改善。fewshot recommendationにといて、10%未満のデータで既存の全データを用いる手法を上回る。また、下のグラフを見るとpromptに利用するアクティビティログの量が増えるほど性能が向上するようになった。
![image](https://github.com/user-attachments/assets/1297153e-bd6c-4548-a7e0-798eadee80e9)

ただし、latencyは100倍以上なのでユースケースが限定される。
![image](https://github.com/user-attachments/assets/89555964-f5c4-4735-bc0d-9a5a1b7f0278)</span>
<a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/Dataset.html">#Dataset</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/SessionBased.html">#SessionBased</a><a class="button" href="articles/Personalization.html">#Personalization</a><a class="button" href="articles/Evaluation.html">#Evaluation</a><br /><span class="issue_date">Issue Date: 2024-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1632">Preference Discerning with LLM-Enhanced Generative Retrieval, Fabian Paischer+, arXiv24</a>
<span class="snippet"><span>Summary</span>逐次推薦システムのパーソナライズを向上させるために、「好みの識別」という新しいパラダイムを提案。大規模言語モデルを用いてユーザーの好みを生成し、包括的な評価ベンチマークを導入。新手法Menderは、既存手法を改善し、最先端の性能を達成。Menderは未観察の人間の好みにも効果的に対応し、よりパーソナライズされた推薦を実現する。コードとベンチマークはオープンソース化予定。</span>
<a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/SessionBased.html">#SessionBased</a><br /><span class="issue_date">Issue Date: 2024-12-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1631">Unifying Generative and Dense Retrieval for Sequential Recommendation, Liu Yang+, arXiv24</a>
<span class="snippet"><span>Summary</span>逐次密な検索モデルはユーザーとアイテムの内積計算を行うが、アイテム数の増加に伴いメモリ要件が増大する。一方、生成的検索はセマンティックIDを用いてアイテムインデックスを予測する新しいアプローチである。これら二つの手法の比較が不足しているため、LIGERというハイブリッドモデルを提案し、生成的検索と逐次密な検索の強みを統合。これにより、コールドスタートアイテム推薦を強化し、推薦システムの効率性と効果を向上させることを示した。</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/CTRPrediction.html">#CTRPrediction</a><a class="button" href="articles/ContrastiveLearning.html">#ContrastiveLearning</a><br /><span class="issue_date">Issue Date: 2024-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1531">Collaborative Contrastive Network for Click-Through Rate Prediction, Chen Gao+, arXiv24</a>
<span class="snippet"><span>Summary</span>EコマースプラットフォームにおけるCTR予測の課題を解決するために、「コラボレーティブコントラストネットワーク（CCN）」を提案。CCNは、ユーザーの興味と不興を示すアイテムクラスターを特定し、トリガーアイテムへの依存を減少させる。オンラインA/Bテストにより、タオバオでCTRを12.3%、注文量を12.7%向上させる成果を達成。</span>
<span class="snippet"><span>Comment</span>参考: [Mini-appの定義生成結果（Hallucinationに注意）](https://www.perplexity.ai/search/what-is-the-definition-of-the-sW4uZPZIQe6Iq53HbwuG7Q)

論文中の図解: Mini-appにトリガーとなるアイテムを提示するTrigger-Induced-Recommendation（TIR）
![image](https://github.com/user-attachments/assets/eb209dc4-b8bc-4632-89df-137031e509f0)## 概要
図3に示されているような Collaborative Contrastive Network (CCN)を提案しており、このネットワークは、Collaborative Constrastive Learningに基づいて学習される。

### Collaborative Constrasitve Learning
図2がCollaborative Constrastive Learningの気持ちを表しており、図2のようなクリックスルーログが与えられたとする。
推薦リストを上から見ていき、いま着目しているアイテムをtarget_itemとすると、target_itemがクリックされている場合、同じcontext（i.e., ユーザにページ内で提示されたアイテム群）のクリックされているアイテムと距離が近くなり、逆にクリックされていないアイテム群とは距離が遠いとみなせる。逆にtarget_itemがクリックされていない場合、同様にクリックされていないアイテムとは距離が近く、クリックされているアイテムとは距離が遠いとみなせる。このように考えると、ある推薦リストが与えられた時に、あるtarget_itemに着目すると、contrastive learningのためのpositive example/negative exampleを生成できる。このようなco-click/co-non-clickの関係から、アイテム同士の距離を学習し、ユーザのinterest/disinterestを学習する。
![image](https://github.com/user-attachments/assets/cea478d8-27e5-45e9-afcd-41a0765c8cce)

### Collaborative Contrastive Network
Collaborative ModuleとCTR Moduleに分かれている。
- Collaborative Moduleには、context itemsと、target itemをinputとし両者の関係性をエンコードする
    - このとき、トリガーアイテムのembeddingとアダマール積をとることで、トリガーアイテムの情報も考慮させる
- CTR Moduleは、context itemsとtarget itemの関係性をエンコードしたembedding、target_item, trigger_itemのembedding, user profileのembedding, userのlong-termとshort-termの行動のembeddingをconcatしたベクトルをinputとして受け取り、そらからtarget_itemのCTRを予測する。 
- Loss Functionは、binary cross entropyと、Collaborative Contrastive Lossをλで重みづけして足し合わせたものであり、Collaborative Contrastive Loss L_CMCは、上述の気持ちを反映するloss（i.e., target_itemとcontext_itemco-click/co-non-clickに基づいて、アイテム間の距離を最小/最大化するようなloss）となっている
![image](https://github.com/user-attachments/assets/2ca62ade-d370-4615-89d1-eac56bf1e847)

![image](https://github.com/user-attachments/assets/07f4bef9-2f86-46b5-b310-2afca26a0db3)

## 実験結果
### offline evaluation
Table 1に示したTaobaoで収集した非常に大規模なproprietary datasetでCTRを予測したところ、AUCはベースラインと比較して高くなった。ここで、TANはCCNのBackboneモデルで、Contrastive Learningを実施していないモデルである。CTR予測においてAUCが高くなるというのはすなわち、クリックされたアイテムi/クリックされなかったアイテムjの2つをとってきたときに、両者のCTR予測結果が CTR_i &gt; CTR_j になる割合が高くなった（i.e. クリックされているアイテムの方が高いCTR予測結果となっている）ということを意味する。
![image](https://github.com/user-attachments/assets/e696bf07-fcd6-47cd-9f96-926071a6b609)
![image](https://github.com/user-attachments/assets/629bc349-36f6-4603-b595-3482c92e66f4)

### online A/B Testing
A/Bテストまで実施しており、実際に提案手法を組み込んだ結果、高いCTRを獲得しているだけでなく、CVRも向上している。すごい。
![image](https://github.com/user-attachments/assets/651d8351-32f5-4aa6-89b6-f310781467f8)
Contrastive Learningを実施しないTANと、CCNを比較してもCCNの方が高いCTR, CVRを獲得している。Contrastive Learning有能。
![image](https://github.com/user-attachments/assets/56b6d14f-fef7-4d1b-ae04-ec3acacf2787)
</span>
<a class="button" href="articles/InformationRetrieval.html">#InformationRetrieval</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/MulltiModal.html">#MulltiModal</a><br /><span class="issue_date">Issue Date: 2024-11-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1491">MM-Embed: Universal Multimodal Retrieval with Multimodal LLMs, Sheng-Chieh Lin+, arXiv24</a>
<span class="snippet"><span>Summary</span>本論文では、マルチモーダル大規模言語モデル（MLLM）を用いた「ユニバーサルマルチモーダル検索」の技術を提案し、複数のモダリティと検索タスクに対応する能力を示します。10のデータセットと16の検索タスクでの実験により、MLLMリトリーバーはテキストと画像のクエリを理解できるが、モダリティバイアスによりクロスモーダル検索では劣ることが判明。これを解決するために、モダリティ認識ハードネガティブマイニングを提案し、継続的なファインチューニングでテキスト検索能力を向上させました。結果として、MM-EmbedモデルはM-BEIRベンチマークで最先端の性能を達成し、NV-Embed-v1を上回りました。また、ゼロショットリランキングを通じて、複雑なクエリに対するマルチモーダル検索の改善が可能であることを示しました。これらの成果は、今後のユニバーサルマルチモーダル検索の発展に寄与するものです。</span>
<span class="snippet"><span>Comment</span>![image](https://github.com/user-attachments/assets/d05854af-4525-40ba-8458-bfe333135cff)</span>
<a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/KnowledgeGraph.html">#KnowledgeGraph</a><a class="button" href="articles/InstructionTuning.html">#InstructionTuning</a><a class="button" href="articles/Annotation.html">#Annotation</a><br /><span class="issue_date">Issue Date: 2024-10-08</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1449">COSMO: A large-scale e-commerce common sense knowledge generation and serving system at Amazon , Yu+, SIGMOD_PODS 24</a>
<span class="snippet"><span>Summary</span>COSMOは、eコマースプラットフォーム向けにユーザー中心の常識知識をマイニングするためのスケーラブルな知識グラフシステムです。大規模言語モデルから抽出した高品質な知識を用い、指示チューニングによってファインチューニングされたCOSMO-LMは、Amazonの主要カテゴリにわたって数百万の知識を生成します。実験により、COSMOが検索ナビゲーションなどで顕著な改善を達成することが示され、常識知識の活用の可能性が強調されています。</span>
<span class="snippet"><span>Comment</span>![image](https://github.com/user-attachments/assets/56fec49b-0917-444f-825b-3f050b7357cb)
![image](https://github.com/user-attachments/assets/978a1b9c-bd59-4838-be8d-bc72e5dc1032)
![image](https://github.com/user-attachments/assets/b1d88bd7-2507-4086-89bf-5330831b00ce)search navigationに導入しA/Bテストした結果、0.7%のproduct sales向上効果。</span>
<a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/Transformer.html">#Transformer</a><a class="button" href="articles/TransferLearning.html">#TransferLearning</a><br /><span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1421">beeFormer: Bridging the Gap Between Semantic and Interaction Similarity   in Recommender Systems, Vojtěch Vančura+, N_A, RecSys24</a>
<span class="snippet"><span>Summary</span>レコメンダーシステムにおいて、コールドスタートやゼロショットシナリオでの予測改善のために、インタラクションデータを活用した文のトランスフォーマーモデル「beeFormer」を提案。beeFormerは、意味的類似性の予測において従来の手法を上回り、異なるドメインのデータセット間で知識を転送可能であることを示した。これにより、ドメインに依存しないテキスト表現のマイニングが可能になる。</span>
<span class="snippet"><span>Comment</span>NLPでは言語という共通の体系があるから事前学習とかが成立するけど、RecSysのようなユーザとシステムのinteraction dataを用いたシステムでは（大抵の場合はデータセットごとにユニークなユーザIDとアイテムIDのログでデータが構成されるので）なかなかそういうことは難しいよね、と思っていた。が、もしRecSysのタスク設定で、データセット間の転移学習を実現できるのだとしたらどのように実現してきるのだろうか?興味深い。後で読む。</span>
<a class="button" href="articles/EfficiencyImprovement.html">#EfficiencyImprovement</a><a class="button" href="articles/Pocket.html">#Pocket</a><br /><span class="issue_date">Issue Date: 2024-09-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1420">Enhancing Performance and Scalability of Large-Scale Recommendation  Systems with Jagged Flash Attention, Rengan Xu+, N_A, arXiv24</a>
<span class="snippet"><span>Summary</span>ハードウェアアクセラレーターの統合により、推薦システムの能力が向上する一方で、GPU計算コストが課題となっている。本研究では、カテゴリ特徴の長さによるGPU利用の複雑さに対処するため、「Jagged Feature Interaction Kernels」を提案し、動的サイズのテンソルを効率的に扱う手法を開発。さらに、JaggedテンソルをFlash Attentionと統合し、最大9倍のスピードアップと22倍のメモリ削減を実現。実際のモデルでは、10%のQPS改善と18%のメモリ節約を確認し、複雑な推薦システムのスケーリングを可能にした。</span>
<a class="button" href="articles/Tutorial.html">#Tutorial</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/GenerativeAI.html">#GenerativeAI</a><a class="button" href="articles/DiffusionModel.html">#DiffusionModel</a><br /><span class="issue_date">Issue Date: 2024-09-24</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1411">Recommendation with Generative Models, Yashar Deldjoo+, N_A, arXiv24</a>
<span class="snippet"><span>Summary</span>生成モデルは新しいデータを生成するAIモデルであり、GANやVAE、トランスフォーマーに基づくアーキテクチャが注目されている。特にレコメンダーシステムにおいては、Gen-RecSysが推薦の精度と多様性を向上させ、パーソナライズされたユーザー体験を提供する。本書では、深層生成モデルをID駆動モデル、LLM、マルチモーダルモデルの3つに分類し、それぞれの技術的進展を紹介。生成モデルの影響やリスクについても考察し、評価フレームワークの重要性を強調する。</span>
<span class="snippet"><span>Comment</span>生成モデルやGenerativeAIによるRecSysの教科書
![image](https://github.com/user-attachments/assets/a76e5fd2-cd82-43f9-ac64-bb33c5fe1dc2)</span>
<a class="button" href="articles/PersonalizedGeneration.html">#PersonalizedGeneration</a><a class="button" href="articles/Personalization.html">#Personalization</a><br /><span class="issue_date">Issue Date: 2024-09-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1394">Leveraging User-Generated Reviews for Recommender Systems with Dynamic  Headers, Shanu Vashishtha+, N_A, PAIS24</a>
<span class="snippet"><span>Summary</span>Eコマースプラットフォームの推薦カルーセルのヘッダー生成をカスタマイズする新手法「Dynamic Text Snippets（DTS）」を提案。ユーザーのレビューから特定の属性を抽出し、グラフニューラルネットワークを用いて複数のヘッダーテキストを生成。これにより、コンテキストに配慮した推薦システムの可能性を示す。</span>
<span class="snippet"><span>Comment</span>e-commerceでDynamicにitemsetに対するスニペット（見出し）を生成する研究。Attributeに基づいてスニペットを生成する。

![image](https://github.com/user-attachments/assets/635061ba-643d-402b-9714-0955884e8395)

斜め読みだが、Anchor ItemがGivenであり、kNNされたアイテム集合から抽出されたに基づいて生成するので、Anchor Itemをユーザが与えるのであれば一時的個人化によるpersonalizationとみなせる。Anchor Itemをユーザの履歴からシステムが複数件選び集約して推薦するみたいなパラダイムになれば、永続的個人化とも言えそう。が、後者の場合共通のAttributeが見出せるか不明。
![image](https://github.com/user-attachments/assets/32eb013e-27be-481d-810d-446dbaf840f8)</span>
<a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/GenerativeRecommendation.html">#GenerativeRecommendation</a><br /><span class="issue_date">Issue Date: 2024-08-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1344">Large Language Models for Generative Recommendation: A Survey and  Visionary Discussions, Lei Li+, N_A, LREC-COLING24</a>
<span class="snippet"><span>Summary</span>LLMを使用した生成的な推薦に焦点を当て、従来の複数段階の推薦プロセスを1つの段階に簡素化する方法を調査。具体的には、生成的推薦の定義、RSの進化、LLMベースの生成的推薦の実装方法について検討。この調査は、LLMベースの生成的推薦に関する進捗状況と将来の方向について提供できる文脈とガイダンスを提供することを目指している。</span>
<span class="snippet"><span>Comment</span>Generative Recommendationの定義がわかりやすい：
&gt; Definition 2 (Generative Recommendation) A generative recommender system directly generates recommendations or recommendation-related content without the need to calculate each candidate’s ranking score one by one.

既存の企業におけるRecommenderSystemsは、典型的には非常に膨大なアイテムバンクを扱わなければならず、全てのアイテムに対してスコアリングをしランキングをすることは計算コストが膨大すぎて困難である。このため、まずは軽量なモデル（e.g. logistic regression）やシンプルな手法（e.g. feature matching）などで、明らかに推薦候補ではないアイテムを取り除いてから、少量のcandidate itemsに対して洗練されたモデルを用いてランキングを生成して推薦するというマルチステージのパイプラインを組んでおり、アカデミック側での研究にここでギャップが生じている。
一方で、Generative Recommendationでは、推薦するアイテムのIDを直接生成するため、
- 実質ほぼ無限のアイテムバンクを運用でき
- 推論の過程でimplicitに全てのアイテムに対して考慮をしたうえで

推薦を生成することができる手法である。また、推薦するアイテムを生成するだけでなく、推薦理由を生成したりなど、テキストを用いた様々なdown stream applicationにも活用できる。

![image](https://github.com/user-attachments/assets/93867578-7d27-4903-8f2b-2ba6fc3886d2)
![image](https://github.com/user-attachments/assets/79e64d4b-6817-4233-a434-dbd881fc8b54)
</span>
<a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/GenerativeAI.html">#GenerativeAI</a><br /><span class="issue_date">Issue Date: 2024-04-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1263">A Review of Modern Recommender Systems Using Generative Models  （Gen-RecSys）, Yashar Deldjoo+, N_A, arXiv24</a>
<span class="snippet"><span>Summary</span>従来のレコメンドシステムは、ユーザー-アイテムの評価履歴を主要なデータソースとして使用してきたが、最近では生成モデルを活用して、テキストや画像など豊富なデータを含めた新しい推薦タスクに取り組んでいる。この研究では、生成モデル（Gen-RecSys）を用いたレコメンドシステムの進歩に焦点を当て、相互作用駆動型生成モデルや大規模言語モデル（LLM）を用いた生成型推薦、画像や動画コンテンツの処理と生成のためのマルチモーダルモデルなどについて調査している。未解決の課題や必要なパラダイムについても議論している。</span>
<a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/Contents-based.html">#Contents-based</a><a class="button" href="articles/Supervised-FineTuning (SFT).html">#Supervised-FineTuning (SFT)</a><a class="button" href="articles/PEFT(Adaptor/LoRA).html">#PEFT(Adaptor/LoRA)</a><a class="button" href="articles/Zero/FewShotLearning.html">#Zero/FewShotLearning</a><a class="button" href="articles/RecSys.html">#RecSys</a><br /><span class="issue_date">Issue Date: 2025-03-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1841">TALLRec: An Effective and Efficient Tuning Framework to Align Large   Language Model with Recommendation, Keqin Bao+, RecSys23</a>
<span class="snippet"><span>Summary</span>大規模言語モデル（LLMs）を推薦システムに活用するため、推薦データで調整するフレームワークTALLRecを提案。限られたデータセットでもLLMsの推薦能力を向上させ、効率的に実行可能。ファインチューニングされたLLMはクロスドメイン一般化を示す。</span>
<span class="snippet"><span>Comment</span>下記のようなユーザのプロファイルとターゲットアイテムと、binaryの明示的なrelevance feedbackデータを用いてLoRA、かつFewshot Learningの設定でSFTすることでbinaryのlike/dislikeの予測性能を向上。PromptingだけでなくSFTを実施した初めての研究だと思われる。
![image](https://github.com/user-attachments/assets/08ea2d35-1dd1-4670-810b-a57722173460)
![image](https://github.com/user-attachments/assets/acf565f8-9541-4fe1-95e8-10cff397fa7a)

既存ベースラインと比較して大幅にAUCが向上
![image](https://github.com/user-attachments/assets/141a0c43-0504-4da3-84d9-c4dac119b590)</span>
<a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/InformationRetrieval.html">#InformationRetrieval</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/SequentialRecommendation.html">#SequentialRecommendation</a><br /><span class="issue_date">Issue Date: 2024-12-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1625">Recommender Systems with Generative Retrieval, Shashank Rajput+, arXiv23</a>
<span class="snippet"><span>Summary</span>新しい生成的検索アプローチを提案し、アイテムのセマンティックIDを自己回帰的にデコード。Transformerベースのモデルが次のアイテムのセマンティックIDを予測し、レコメンデーションタスクにおいて初のセマンティックIDベースの生成モデルとなる。提案手法は最先端モデルを大幅に上回り、過去の対話履歴がないアイテムに対する検索性能も向上。</span>
<a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><br /><span class="issue_date">Issue Date: 2024-12-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1568">Recommender Systems in the Era of Large Language Models （LLMs）, Zihuai Zhao+, arXiv23</a>
<span class="snippet"><span>Summary</span>レコメンダーシステムは、ユーザーの好みに基づいた提案を提供する重要な要素であり、DNNの限界を克服するためにLLMsの活用が進んでいる。本論文では、LLMを用いたレコメンダーシステムの事前学習、ファインチューニング、プロンプティングに関する包括的なレビューを行い、ユーザーとアイテムの表現学習手法や最近の技術を紹介し、今後の研究方向性について議論する。</span>
<span class="snippet"><span>Comment</span>
中身を全然読んでいる時間はないので、図には重要な情報が詰まっていると信じ、図を読み解いていく。時間がある時に中身も読みたい。。。

LLM-basedなRecSysでは、NLPにおけるLLMの使い方（元々はT5で提案）と同様に、様々なレコメンド関係タスクを、テキスト生成タスクに落とし込み学習することができる。
![image](https://github.com/user-attachments/assets/78faeea5-8e1f-49d5-93a8-9ea97d5a3170)
RecSysのLiteratureとしては、最初はコンテンツベースと協調フィルタリングから始まり、（グラフベースドな推薦, Matrix Factorization, Factorization Machinesなどが間にあって）、その後MLP, RNN, CNN, AutoEncoderなどの様々なDeep Neural Network（DNN）を活用した手法や、BERT4RecなどのProbabilistic Language Models（PLM）を用いた手法にシフトしていき、現在LLM-basedなRecSysの時代に到達した、との流れである。
![image](https://github.com/user-attachments/assets/6c319f48-3c2f-4c0d-97d6-693fb8ba85cf)

LLM-basedな手法では、pretrainingの段階からEncoder-basedなモデルの場合はMLM、Decoder-basedな手法ではNext Token Predictionによってデータセットで事前学習する方法もあれば、フルパラメータチューニングやPEFT（LoRAなど）によるSFTによるアプローチもあるようである。

推薦タスクは、推薦するアイテムIDを生成するようなタスクの場合は、異なるアイテムID空間に基づくデータセットの間では転移ができないので、SFTをしないとなかなかうまくいかないと気がしている。また、その場合はアイテムIDの推薦以外のタスクも同時に実施したい場合は、事前学習済みのパラメータが固定されるPEFT手法の方が安全策になるかなぁ、という気がしている（破壊的忘却が怖いので）。特はたとえば、アイテムIDを生成するだけでなく、その推薦理由を生成できるのはとても良いことだなあと感じる（良い時代、感）。
![image](https://github.com/user-attachments/assets/19474960-ac0d-4a61-915e-15a910504a3f)

また、PromptingによるRecSysの流れも図解されているが、In-Context Learningのほかに、Prompt Tuning（softとhardの両方）、Instruction Tuningも同じ図に含まれている。個人的にはPrompt TuningはPEFTの一種であり、Instruction TuningはSFTの一種なので、一つ上の図に含意される話なのでは?という気がするが、論文中ではどのような立て付けで記述されているのだろうか。
どちらかというと、Promptingの話であれば、zero-few-many shotや、各種CoTの話を含めるのが自然な気がするのだが。
![image](https://github.com/user-attachments/assets/a1db1dba-ba13-44b0-ad9c-017ca9164ed2)

下図はPromptingによる手法を表にまとめたもの。Finetuningベースの手法が別表にまとめられていたが、研究の数としてはこちらの方が多そうに見える。が、性能的にはどの程度が達成されるのだろうか。直感的には、アイテムを推薦するようなタスクでは、Promptingでは性能が出にくいような印象がある。なぜなら、事前学習済みのLLMはアイテムIDのトークン列とアイテムの特徴に関する知識がないので。これをFinetuningしないのであればICLで賄うことになると思うのだが、果たしてどこまでできるだろうか…。興味がある。
![image](https://github.com/user-attachments/assets/997e2bd9-68bd-4b72-92d4-72495a329dda)

（図は論文より引用）</span>
<a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/ConversationalRecommenderSystems.html">#ConversationalRecommenderSystems</a><br /><span class="issue_date">Issue Date: 2024-08-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1346">Leveraging Large Language Models in Conversational Recommender Systems, Luke Friedman+, N_A, arXiv23</a>
<span class="snippet"><span>Summary</span>LLMsを使用した大規模な会話型推薦システム（CRS）の構築に関する論文の要約です。LLMsを活用したユーザーの好み理解、柔軟なダイアログ管理、説明可能な推薦の新しい実装を提案し、LLMsによって駆動される統合アーキテクチャの一部として説明します。また、LLMが解釈可能な自然言語のユーザープロファイルを利用してセッションレベルのコンテキストを調整する方法についても説明します。さらに、LLMベースのユーザーシミュレータを構築して合成会話を生成する技術を提案し、LaMDAをベースにしたYouTubeビデオの大規模CRSであるRecLLMを紹介します。</span>
<a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/Transformer.html">#Transformer</a><br /><span class="issue_date">Issue Date: 2023-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1126">Hiformer: Heterogeneous Feature Interactions Learning with Transformers  for Recommender Systems, Huan Gui+, N_A, arXiv23</a>
<span class="snippet"><span>Summary</span>特徴の相互作用を学ぶために、Transformerベースのアーキテクチャを提案する。ウェブスケールのレコメンダーシステムにおいて、特徴の相互作用を手動で作成することは困難であるため、自動的に捉える必要がある。しかし、現在のTransformerアーキテクチャは異種の特徴の相互作用を捉えることができず、サービングレイテンシも高い。そこで、異種の自己注意層を提案し、\textsc{Hiformer}というモデルを紹介する。\textsc{Hiformer}は特徴の相互作用の異種性を考慮し、低ランク近似とモデルの剪定により高速な推論を実現する。オフライン実験結果では、\textsc{Hiformer}モデルの効果と効率が示されており、Google Playの実世界の大規模なアプリランキングモデルにも展開され、主要なエンゲージメントメトリックスを改善した。</span>
<span class="snippet"><span>Comment</span>推薦システムは、Factorization Machinesあたりから大抵の場合特徴量間の交互作用を頑張って捉えることで精度向上を目指す、という話をしてきている気がするが、これはTransformerを使って交互作用捉えられるようなモデルを考えました、という研究のようである。
![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d57eb1b6-0e68-47fe-9d0a-315186cc9e3d)

self attention部分に工夫がなされており（提案手法は右端）、task tokenとそれぞれのfeatureをconcatしてQKVを求めることで、明示的に交互作用が生まれるような構造にしている。
![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5b097e51-34d8-488b-aba5-4dce9e201272)Online A/Bテストでも評価しており、HiformerによってSoTAな交互作用モデル（DCN）よりも高いユーザエンゲージメントを実現することが示されている。

![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/be431a24-814a-4891-b5d5-58ad2b8563e7)</span>
<img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d57eb1b6-0e68-47fe-9d0a-315186cc9e3d" alt="image" loading="lazy" /><img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/be431a24-814a-4891-b5d5-58ad2b8563e7" alt="image" loading="lazy" /><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><br /><span class="issue_date">Issue Date: 2023-11-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1122">LightLM: A Lightweight Deep and Narrow Language Model for Generative  Recommendation, Kai Mei+, N_A, arXiv23</a>
<span class="snippet"><span>Summary</span>この論文では、軽量なTransformerベースの言語モデルであるLightLMを提案し、生成型レコメンデーションタスクに特化したモデルを開発しています。LightLMは、モデルの容量を抑えつつも、レコメンデーションの精度と効率を向上させることに成功しています。また、ユーザーとアイテムのIDインデックス化方法として、Spectral Collaborative Indexing（SCI）とGraph Collaborative Indexing（GCI）を提案しています。さらに、アイテム生成時のhallucinationの問題に対処するために、制約付き生成プロセスを導入しています。実験結果は、LightLMが競合ベースラインを上回ることを示しています。</span>
<span class="snippet"><span>Comment</span>Generative Recommendationはあまり終えていないのだが、既存のGenerative Recommendationのモデルをより軽量にし、性能を向上させ、存在しないアイテムを生成するのを防止するような手法を提案しました、という話っぽい。

![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7a70bae0-20fd-495e-a563-5ac6ce5b6dfc)

Bayesian Personalized Ranking #28 ベースドなMatrix Factorizationよりは高い性能が出てるっぽい。
![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/40a39bfc-7a5b-442b-9231-1fbdbc99557a)
</span>
<img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/7a70bae0-20fd-495e-a563-5ac6ce5b6dfc" alt="image" loading="lazy" /><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><br /><span class="issue_date">Issue Date: 2023-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/911">LLM-Rec: Personalized Recommendation via Prompting Large Language Models, Hanjia Lyu+, N_A, arXiv23</a>
<span class="snippet"><span>Summary</span>LLMsを用いたパーソナライズされたコンテンツ推薦のためのプロンプティング戦略を調査し、LLM-Recというアプローチを提案した。実験の結果、プロンプティング戦略によって生成されたLLMによる拡張入力テキストと元のコンテンツの説明を組み合わせることで、推薦の性能が向上することが示された。これは、多様なプロンプトと入力拡張技術がパーソナライズされたコンテンツ推薦の能力を向上させる上で重要であることを示している。</span>
<span class="snippet"><span>Comment</span>LLMのpromptingの方法を変更しcontent descriptionだけでなく、様々なコンテキストの追加（e.g. このdescriptionを推薦するならどういう人におすすめ？、アイテム間の共通項を見つける）、内容の拡張等を行いコンテントを拡張して活用するという話っぽい。WIP</span>
<br /><span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/870">User Simulator Assisted Open-ended Conversational Recommendation System, NLP4ConvAI23</a>
<a class="button" href="articles/Explanation.html">#Explanation</a><a class="button" href="articles/Personalization.html">#Personalization</a><a class="button" href="articles/review.html">#review</a><br /><span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/862">Explainable Recommendation with Personalized Review Retrieval and Aspect Learning, ACL23</a>
<span class="snippet"><span>Summary</span>説明可能な推薦において、テキスト生成の精度向上とユーザーの好みの捉え方の改善を目指し、ERRAモデルを提案。ERRAは追加情報の検索とアスペクト学習を組み合わせることで、より正確で情報量の多い説明を生成することができる。さらに、ユーザーの関心の高いアスペクトを選択することで、関連性の高い詳細なユーザー表現をモデル化し、説明をより説得力のあるものにする。実験結果は、ERRAモデルが最先端のベースラインを上回ることを示している。</span>
<a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/Contents-based.html">#Contents-based</a><a class="button" href="articles/Transformer.html">#Transformer</a><a class="button" href="articles/pretrained-LM.html">#pretrained-LM</a><a class="button" href="articles/ContrastiveLearning.html">#ContrastiveLearning</a><br /><span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/852">UniTRec: A Unified Text-to-Text Transformer and Joint Contrastive Learning Framework for Text-based Recommendation, ACL23</a>
<span class="snippet"><span>Summary</span>本研究では、事前学習済み言語モデル（PLM）を使用して、テキストベースの推薦の性能を向上させるための新しいフレームワークであるUniTRecを提案します。UniTRecは、ユーザーの履歴の文脈をより良くモデル化するために統一されたローカル-グローバルアテンションTransformerエンコーダを使用し、候補のテキストアイテムの言語の複雑さを推定するためにTransformerデコーダを活用します。幅広い評価により、UniTRecがテキストベースの推薦タスクで最先端のパフォーマンスを発揮することが示されました。</span>
<a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/Conversation.html">#Conversation</a><br /><span class="issue_date">Issue Date: 2023-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/840">TREA: Tree-Structure Reasoning Schema for Conversational Recommendation, ACL23</a>
<span class="snippet"><span>Summary</span>会話型の推薦システム（CRS）では、外部知識を活用して対話の文脈を理解し、関連するアイテムを推薦することが求められている。しかし、現在の推論モデルは複雑な関係を完全に把握できないため、新しいツリー構造の推論スキーマであるTREAを提案する。TREAは多階層のツリーを使用して因果関係を明確にし、過去の対話を活用してより合理的な応答を生成する。幅広い実験により、TREAの有効性が示された。</span>
<a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/GraphBased.html">#GraphBased</a><a class="button" href="articles/Pocket.html">#Pocket</a><br /><span class="issue_date">Issue Date: 2023-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/545">Graph Collaborative Signals Denoising and Augmentation for  Recommendation, Ziwei Fan+, N_A, SIGIR23</a>
<span class="snippet"><span>Summary</span>グラフ協調フィルタリング（GCF）は、推薦システムで人気のある技術ですが、相互作用が豊富なユーザーやアイテムにはノイズがあり、相互作用が不十分なユーザーやアイテムには不十分です。また、ユーザー-ユーザーおよびアイテム-アイテムの相関を無視しているため、有益な隣接ノードの範囲が制限される可能性があります。本研究では、ユーザー-ユーザーおよびアイテム-アイテムの相関を組み込んだ新しいグラフの隣接行列と、適切に設計されたユーザー-アイテムの相互作用行列を提案します。実験では、改善された隣接ノードと低密度を持つ強化されたユーザー-アイテムの相互作用行列が、グラフベースの推薦において重要な利点をもたらすことを示しています。また、ユーザー-ユーザーおよびアイテム-アイテムの相関を含めることで、相互作用が豊富なユーザーや不十分なユーザーに対する推薦が改善されることも示しています。</span>
<span class="snippet"><span>Comment</span>グラフ協調フィルタリングを改善
![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b0f099c2-8e9d-4ebc-aa1b-d4af49509a37)グラフ協調フィルタリング
（下記ツイッターより引用）
user-item間の関係だけでなく、user-user間とitem-item間の情報を組み込むことで精度向上を達成した論文とのこと。

https://twitter.com/nogawanogawa/status/1651165820956057602?s=46&amp;t=6qC80ox3qHrJixKeNmIOcg</span>
<img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b0f099c2-8e9d-4ebc-aa1b-d4af49509a37" alt="image" loading="lazy" /><a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/CTRPrediction.html">#CTRPrediction</a><br /><span class="issue_date">Issue Date: 2024-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1533">Deep Intention-Aware Network for Click-Through Rate Prediction, Yaxian Xia+, arXiv22</a>
<span class="snippet"><span>Summary</span>Eコマースプラットフォームにおけるトリガー誘発推薦（TIRA）に対し、従来のCTR予測モデルは不適切である。顧客のエントリー意図を抽出し、トリガーの影響を評価するために、深層意図認識ネットワーク（DIAN）を提案。DIANは、ユーザーの意図を推定し、トリガー依存と非依存の推薦結果を動的にバランスさせる。実験により、DIANはタオバオのミニアプリでCTRを4.74%向上させることが示された。</span>
<span class="snippet"><span>Comment</span>#1531 の実験で利用されているベースライン</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/CTRPrediction.html">#CTRPrediction</a><br /><span class="issue_date">Issue Date: 2024-11-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1532">Deep Interest Highlight Network for Click-Through Rate Prediction in  Trigger-Induced Recommendation, Qijie Shen+, WWW22</a>
<span class="snippet"><span>Summary</span>トリガー誘発推薦（TIR）を提案し、ユーザーの瞬時の興味を引き出す新しい推薦手法を紹介。従来のモデルがTIRシナリオで効果的でない問題を解決するため、Deep Interest Highlight Network（DIHN）を開発。DIHNは、ユーザー意図ネットワーク（UIN）、融合埋め込みモジュール（FEM）、ハイブリッド興味抽出モジュール（HIEM）の3つのコンポーネントから成り、実際のeコマースプラットフォームでの評価で優れた性能を示した。</span>
<span class="snippet"><span>Comment</span>#1531 の実験で利用されているベースライン</span>
<a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/Zero/FewShotPrompting.html">#Zero/FewShotPrompting</a><a class="button" href="articles/InstructionTuning.html">#InstructionTuning</a><br /><span class="issue_date">Issue Date: 2023-11-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1124">Recommendation as Language Processing （RLP）: A Unified Pretrain,  Personalized Prompt &amp; Predict Paradigm （P5）, Shijie Geng+, N_A, RecSys22</a>
<span class="snippet"><span>Summary</span>我々は「Pretrain, Personalized Prompt, and Predict Paradigm」（P5）と呼ばれる柔軟で統一されたテキストからテキストへのパラダイムを提案します。P5は、共有フレームワーク内でさまざまな推薦タスクを統一し、個別化と推薦のための深い意味を捉えることができます。P5は、異なるタスクを学習するための同じ言語モデリング目標を持つ事前学習を行います。P5は、浅いモデルから深いモデルへと進化し、広範な微調整の必要性を減らすことができます。P5の効果を実証するために、いくつかの推薦ベンチマークで実験を行いました。</span>
<span class="snippet"><span>Comment</span># 概要
T5 のように、様々な推薦タスクを、「Prompt + Prediction」のpipelineとして定義して解けるようにした研究。
![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9b8b83a2-0930-4836-8bae-a18234fd3fd3)
P5ではencoder-decoder frameworkを採用しており、encoder側ではbidirectionalなモデルでpromptのrepresentationを生成し、auto-regressiveな言語モデルで生成を行う。
![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/d47cb264-9e94-46c5-9b56-0b6f4e31a8de)
推薦で利用したいデータセットから、input-target pairsを生成し上記アーキテクチャに対して事前学習することで、推薦を実現できる。

RatingPredictionでは、MatrixFactorizationに勝てていない（が、Rating Predictionについては魔法の壁問題などもあると思うのでなんともいえない。）
![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/a7742141-2988-4e92-96ae-f6fb4cc4ce5f)

Sequential RecommendationではBERT4Recとかにも勝てている模様。
![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8badc477-8665-4404-bf4b-93ac901740d6)


# Prompt例
- Rating Predictionの例
![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9385d3ff-c186-4490-be34-3baf331aefae)

- Sequential Recommendationの例
![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/12b61106-af4f-4597-9990-60bc6fa7f222)

- Explanationを生成する例
![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/b41f22fd-2476-4365-a3a0-07f72d6bb0db)

- Zero-shotの例（Cold-Start）
![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/5217791e-7a7e-40d4-bdb4-b979af327032)</span>
<img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/9b8b83a2-0930-4836-8bae-a18234fd3fd3" alt="image" loading="lazy" /><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/PersonalizedGeneration.html">#PersonalizedGeneration</a><a class="button" href="articles/Personalization.html">#Personalization</a><br /><span class="issue_date">Issue Date: 2023-08-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/927">Personalized Chit-Chat Generation for Recommendation Using External Chat Corpora, Chen+, KDD22</a>
<span class="snippet"><span>Summary</span>チットチャットは、ユーザーとの対話において効果的であることが示されています。この研究では、ニュース推薦のための個人化されたチットチャットを生成する方法を提案しています。既存の方法とは異なり、外部のチャットコーパスのみを使用してユーザーの関心を推定し、個人化されたチットチャットを生成します。幅広い実験により、提案手法の効果が示されています。</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/EfficiencyImprovement.html">#EfficiencyImprovement</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/EducationalDataMining.html">#EducationalDataMining</a><a class="button" href="articles/KnowledgeTracing.html">#KnowledgeTracing</a><a class="button" href="articles/Contents-based.html">#Contents-based</a><a class="button" href="articles/NAACL.html">#NAACL</a><br /><span class="issue_date">Issue Date: 2022-08-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/463">GRAM: Fast Fine-tuning of Pre-trained Language Models for Content-based   Collaborative Filtering, Yoonseok Yang+, NAACL22</a>
<span class="snippet"><span>Summary</span>コンテンツベースの協調フィルタリング（CCF）において、PLMを用いたエンドツーエンドのトレーニングはリソースを消費するため、GRAM（勾配蓄積手法）を提案。Single-step GRAMはアイテムエンコーディングの勾配を集約し、Multi-step GRAMは勾配更新の遅延を増加させてメモリを削減。これにより、Knowledge TracingとNews Recommendationのタスクでトレーニング効率を最大146倍改善。</span>
<span class="snippet"><span>Comment</span>RiiiDがNAACL'22に論文通してた</span>
<a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/read-later.html">#read-later</a><a class="button" href="articles/Reproducibility.html">#Reproducibility</a><br /><span class="issue_date">Issue Date: 2025-05-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1968">A Troubling Analysis of Reproducibility and Progress in Recommender   Systems Research, Maurizio Ferrari Dacrema+, TOIS21</a>
<span class="snippet"><span>Summary</span>パーソナライズされたランキングアイテムリスト生成のアルゴリズム設計はレコメンダーシステムの重要なテーマであり、深層学習技術が主流となっている。しかし、比較ベースラインの選択や最適化に問題があり、実際の進展を理解するために協調フィルタリングに基づくニューラルアプローチの再現を試みた結果、12の手法中11が単純な手法に劣ることが判明。計算的に複雑なニューラル手法は既存の技術を一貫して上回らず、研究実践の問題が分野の停滞を招いている。</span>
<a class="button" href="articles/Tools.html">#Tools</a><a class="button" href="articles/Library.html">#Library</a><a class="button" href="articles/CIKM.html">#CIKM</a><br /><span class="issue_date">Issue Date: 2022-03-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/440">RecBole: Towards a Unified, Comprehensive and Efficient Framework for Recommendation Algorithms, Zhao+, CIKM21</a>
<span class="snippet"><span>Summary</span>RecBoleは、推薦アルゴリズムのオープンソース実装を標準化するための統一的で効率的なライブラリであり、73のモデルを28のベンチマークデータセット上で実装。PyTorchに基づき、一般的なデータ構造や評価プロトコル、自動パラメータ調整機能を提供し、推薦システムの実装と評価を促進する。プロジェクトはhttps://recbole.io/で公開。</span>
<a class="button" href="articles/Tutorial.html">#Tutorial</a><a class="button" href="articles/Infrastructure.html">#Infrastructure</a><a class="button" href="articles/python.html">#python</a><a class="button" href="articles/Slide.html">#Slide</a><br /><span class="issue_date">Issue Date: 2021-10-21</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/413">コミュニティサービスにおけるレコメンデーションの変遷とMLパイプラインについて, PyCon21</a>
<span class="snippet"><span>Comment</span>・ママ向けのQ&amp;AサービスにおけるレコメンドとMLパイプラインについて紹介

◆レコメンドエンジンの変遷
　・Tensorflowで実装したMFから始まり、その後トピックを絞り込んだ上で推薦するためにLDAを活用したレコメンド、最終的にSoftmax Recommendationを開発
　　* Softmax Recommendation: https://developers.google.com/machine-learning/recommendation/dnn/softmax
　　* ユーザプロファイル（e.g. 行動ベクトル, ユーザの属性情報）等を入力とし、hidden layerをかませて最終的にアイテム次元数分のスコアベクトルを得る手法
　　* 行動ベクトル=ユーザが過去にクリックしたQ&amp;Aだが、質問ベクトルを得るために内容テキストは利用せず行動ログ+word2vecで学習
　　* 類似質問検索による定性評価の結果良い結果、関連質問を抽出できるベクトルとなっていることを確認
　→ レコメンド手法の変遷につれ、ベンチマークを上回るようになっていった◆MLパイプラインについて
　・AWS Step FunctionsとAmazon Sagemakerを利用
　・AWS Step Functions
　　* AWS上の様々なサービスをワークフローとして定義できる（json形式でワークフローを記述）
　・Amazon Sagemaker
　　* 機械学習向けのIDE
　　* notebook上でのデータ分析・モデル学習、実験管理や学習済みモデルのデプロイが可能
　　* Sagemaker Processingを用いることで、実行したい処理やインスタンスタイプを指定することで、notebookとは別の実行環境（コンテナ）で任意のpythonスクリプトを実行可
　　
![image](https://user-images.githubusercontent.com/12249301/138197625-9c35e527-3220-415b-9b38-b663ab75cee3.png)

　・ワークフローの定義=AWS Stepfunctions, スクリプト実行のリソース=Sagemaker Processingとして利用

MLパイプラインについては下記資料により詳しい情報が書かれている
https://speakerdeck.com/takapy/sagemaker-studiotostep-functionswoyong-itemlopshefalse-bu-wota-michu-sou</span>
<a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/SessionBased.html">#SessionBased</a><a class="button" href="articles/SequentialRecommendation.html">#SequentialRecommendation</a><br /><span class="issue_date">Issue Date: 2019-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/314">A Survey on Session-based Recommender Systems, Wang+, CSUR21</a>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/MatrixFactorization.html">#MatrixFactorization</a><a class="button" href="articles/RecSys.html">#RecSys</a><a class="button" href="articles/read-later.html">#read-later</a><a class="button" href="articles/Reproducibility.html">#Reproducibility</a><br /><span class="issue_date">Issue Date: 2025-05-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1967">Neural Collaborative Filtering vs. Matrix Factorization Revisited, Steffen Rendle+, RecSys20</a>
<span class="snippet"><span>Summary</span>埋め込みベースのモデルにおける協調フィルタリングの研究では、MLPを用いた学習された類似度が提案されているが、適切なハイパーパラメータ選択によりシンプルなドット積が優れた性能を示すことが確認された。MLPは理論的には任意の関数を近似可能だが、実用的にはドット積の方が効率的でコストも低いため、MLPは慎重に使用すべきであり、ドット積がデフォルトの選択肢として推奨される。</span>
<a class="button" href="articles/RecSys.html">#RecSys</a><a class="button" href="articles/read-later.html">#read-later</a><a class="button" href="articles/Reproducibility.html">#Reproducibility</a><br /><span class="issue_date">Issue Date: 2025-05-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1963">Are We Evaluating Rigorously? Benchmarking Recommendation for Reproducible Evaluation and Fair Comparison, Zun+, RecSys20</a>
<span class="snippet"><span>Comment</span>日本語解説:https://qiita.com/smochi/items/c4cecc48e4aba0071ead</span>
<a class="button" href="articles/RecSys.html">#RecSys</a><br /><span class="issue_date">Issue Date: 2022-04-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/441">Are We Evaluating Rigorously? Benchmarking Recommendation for Reproducible Evaluation and Fair Comparison, Sun+, RecSys20</a>
<span class="snippet"><span>Comment</span>日本語解説：https://qiita.com/smochi/items/c4cecc48e4aba0071ead</span>
<a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/read-later.html">#read-later</a><a class="button" href="articles/Reproducibility.html">#Reproducibility</a><br /><span class="issue_date">Issue Date: 2025-05-14</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1962">On the Difficulty of Evaluating Baselines: A Study on Recommender  Systems, Steffen Rendle+, arXiv19</a>
<span class="snippet"><span>Summary</span>レコメンダーシステムの研究において、数値評価とベースラインの比較が重要であることを示す。Movielens 10Mベンチマークのベースライン結果が最適でないことを実証し、適切な行列因子分解の設定により改善できることを示した。また、Netflix Prizeにおける手法の結果を振り返り、経験的な発見は標準化されたベンチマークに基づかない限り疑わしいことを指摘した。</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/Evaluation.html">#Evaluation</a><a class="button" href="articles/RecSys.html">#RecSys</a><br /><span class="issue_date">Issue Date: 2022-04-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/442">Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches, Politecnico di Milano, Maurizio+, RecSys19</a>
<span class="snippet"><span>Comment</span>RecSys'19のベストペーパー
日本語解説：https://qiita.com/smochi/items/98dbd9429c15898c5dc7重要研究</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/CTRPrediction.html">#CTRPrediction</a><a class="button" href="articles/CVRPrediction.html">#CVRPrediction</a><a class="button" href="articles/SIGKDD.html">#SIGKDD</a><br /><span class="issue_date">Issue Date: 2021-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/366">Conversion Prediction Using Multi-task Conditional Attention Networks to Support the Creation of Effective Ad Creatives, Kitada+, KDD19</a>
<span class="snippet"><span>Comment</span># Overview
広告のCVR予測をCTR予測とのmulti-task learningとして定式化。
構築した予測モデルのattention distributionを解析することで、high-qualityなクリエイティブの作成を支援する。
genderやgenre等の情報でattentionのweightを変化させるconditional attentionが特徴的。
→ これによりgender, genreごとのCVRしやすい広告の特徴の違いが可視化される

![image](https://user-images.githubusercontent.com/12249301/120273298-45d9c400-c2e9-11eb-9e62-24afd6323d01.png)

loss functionは、MSEにλを導入しclickのlossを制御している（CVRに最適化したいため）。ただ、実験ではλ=1で実験している。
outputはRegressionでCVR, CTRの値そのものを予測している（log lossを使う一般的なCTR Prediction等とは少し条件が違う; 多分予測そのものより、予測モデルを通じて得られるCVRが高いcreativeの分析が主目的なため）。
![image](https://user-images.githubusercontent.com/12249301/120273365-5db14800-c2e9-11eb-9888-a98443a7adbc.png)

# Experiments
データとして、2017年8月〜2018年8月の間にGunosy Adsでdeliverされた14,000種類のad creativeを利用。
clickとconversionのfrequency（clickはlong-tailだが、conversionはほとんど0か1のように見える）
![image](https://user-images.githubusercontent.com/12249301/120275800-cf3ec580-c2ec-11eb-87a0-e0dacd230c5e.png)

5-fold crossvalidationを、fold内でcampaignが重複しないようにad creativeに対して行い、conversion数の予測を行なった。
評価を行う際はNDCGを用い、top-1%のconversion数を持つcreativeにフォーカスし評価した。

![image](https://user-images.githubusercontent.com/12249301/120277549-26459a00-c2ef-11eb-9a7e-2ba8832ed26a.png)

MSEで評価した場合、multi-task learning, conditional attentionを利用することでMSEが改善している。多くのcreativeのconversionは0なので、conversion数が&gt;0のものに着目して評価しても性能が改善していることがわかる。

NDCGを利用した評価でも同様な傾向
![image](https://user-images.githubusercontent.com/12249301/120277916-a1a74b80-c2ef-11eb-8530-0399ee43c2eb.png)

conditional attentionのheatmap
![image](https://user-images.githubusercontent.com/12249301/120274299-9bfb3700-c2ea-11eb-939e-6593056e109b.png)

genderごとにdistributionの違いがあって非常におもしろい
</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/NaturalLanguageGeneration.html">#NaturalLanguageGeneration</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/ReviewGeneration.html">#ReviewGeneration</a><a class="button" href="articles/WWW.html">#WWW</a><br /><span class="issue_date">Issue Date: 2019-08-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/318">Review Response Generation in E-Commerce Platforms with External Product Information, Zhao+, WWW19</a>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/NaturalLanguageGeneration.html">#NaturalLanguageGeneration</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/ReviewGeneration.html">#ReviewGeneration</a><a class="button" href="articles/ACL.html">#ACL</a><br /><span class="issue_date">Issue Date: 2019-08-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/316">Automatic Generation of Personalized Comment Based on User Profile, Zeng+, ACL19 Student Research Workshop</a>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/NaturalLanguageGeneration.html">#NaturalLanguageGeneration</a><a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/ReviewGeneration.html">#ReviewGeneration</a><a class="button" href="articles/WWW.html">#WWW</a><br /><span class="issue_date">Issue Date: 2019-05-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/313">Multimodal Review Generation for Recommender Systems, Truong+, WWW19</a>
<span class="snippet"><span>Comment</span>Personalized Review Generationと、Rating Predictionを同時学習した研究（同時学習自体はすでに先行研究がある）。
また、先行研究のinputは、たいていはuser, itemであるが、multi-modalなinputとしてレビューのphotoを活用したという話。

まだあまりしっかり読んでいないが、モデルのstructureはシンプルで、rating predictionを行うDNN、テキスト生成を行うLSTM（fusion gateと呼ばれる新たなゲートを追加）、画像の畳み込むCNNのハイブリッドのように見える。</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/Attention.html">#Attention</a><a class="button" href="articles/SIGKDD.html">#SIGKDD</a><br /><span class="issue_date">Issue Date: 2025-07-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2245">Paper Note Deep Interest Network for Click-Through Rate Prediction, Guorui Zhou+, KDD18</a>
<span class="snippet"><span>Summary</span>クリック率予測において、固定長の表現ベクトルがユーザーの多様な興味を捉えるのを妨げる問題に対処するため、ローカルアクティベーションユニットを用いた「Deep Interest Network（DIN）」を提案。DINは広告に応じてユーザーの興味を適応的に学習し、表現力を向上させる。実験により、提案手法は最先端の手法を上回る性能を示し、Alibabaの広告システムに成功裏に展開されている。</span>
<span class="snippet"><span>Comment</span>ユーザの過去のアイテムとのインタラクションを、候補アイテムによって条件づけた上でattentionによって重みづけをすることでcontext vectorを作成し活用する。これにより候補アイテムごとにユーザの過去のアイテムとのインタラクションのうち、どれを重視するかを動的に変化させることができるようにした研究。最終的にユーザプロファイルをベースにしたEmbeddingとコンテキスト（セッションの情報など）の情報をベースにしたEmbeddingと、上述したcontext vectorをconcatし、linearな変換を噛ませてスコアを出力する。学習はクリックスルーログ等のインタラクションデータに対してNLL lossを適用する。通称DIN。

![image](https://github.com/user-attachments/assets/d88206a0-7eb0-4a78-8d2d-47460d66be61)</span>
<a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/Transformer.html">#Transformer</a><a class="button" href="articles/SequentialRecommendation.html">#SequentialRecommendation</a><a class="button" href="articles/ICDM.html">#ICDM</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2025-07-04</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2137">Paper Note Self-Attentive Sequential Recommendation, Wang-Cheng Kang+, ICDM18</a>
<span class="snippet"><span>Summary</span>自己注意に基づく逐次モデル（SASRec）を提案し、マルコフ連鎖と再帰型ニューラルネットワークの利点を統合。SASRecは、少数のアクションから次のアイテムを予測し、スパースおよび密なデータセットで最先端のモデルを上回る性能を示す。モデルの効率性と注意重みの視覚化により、データセットの密度に応じた適応的な処理が可能であることが確認された。</span>
<a class="button" href="articles/Calibration.html">#Calibration</a><br /><span class="issue_date">Issue Date: 2024-09-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1403">Calibrated Recommendation, Herald Steck, Netflix, RecSys18</a>
<span class="snippet"><span>Summary</span>ユーザーの過去の視聴履歴に基づき、推薦映画リストがその興味に応じた割合で構成されることをキャリブレーションと呼ぶ。キャリブレーションは、ユーザーの多様な興味を反映するために重要であり、従来のレコメンダーシステムは主な興味に偏りがちであることが示されている。本研究では、キャリブレーションの度合いを定量化するメトリクスと、出力を後処理する再ランキングアルゴリズムを提案する。</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/Contents-based.html">#Contents-based</a><a class="button" href="articles/NewsRecommendation.html">#NewsRecommendation</a><a class="button" href="articles/WWW.html">#WWW</a><br /><span class="issue_date">Issue Date: 2021-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/363">DKN: Deep Knowledge-Aware Network for News Recommendation, Wang+, WWW18</a>
<span class="snippet"><span>Comment</span># Overview
Contents-basedな手法でCTRを予測しNews推薦。newsのタイトルに含まれるentityをknowledge graphと紐づけて、情報をよりリッチにして活用する。
CNNでword-embeddingのみならず、entity embedding, contextual entity embedding（entityと関連するentity）をエンコードし、knowledge-awareなnewsのrepresentationを取得し予測する。
※ contextual entityは、entityのknowledge graph上でのneighborhoodに存在するentityのこと（neighborhoodの情報を活用することでdistinguishableでよりリッチな情報を活用できる）

CNNのinputを\[\[word_ embedding\], \[entity embedding\], \[contextual entity embedding\]\](画像のRGB)のように、multi-channelで構成し3次元のフィルタでconvolutionすることで、word, entity, contextual entityを表現する空間は別に保ちながら（同じ空間で表現するのは適切ではない）、wordとentityのalignmentがとれた状態でのrepresentationを獲得する。

![image](https://user-images.githubusercontent.com/12249301/120255506-11eda700-c2c7-11eb-89a9-3a855652a59e.png)

# Experiments
BingNewsのサーバログデータを利用して評価。
データは (timestamp, userid, news url, news title, click count (0=no click, 1=click))のレコードによって構成されている。
2016年11月16日〜2017年6月11日の間のデータからランダムサンプリングしtrainingデータセットとした。
また、2017年6月12日〜2017年8月11日までのデータをtestデータセットとした。

word/entity embeddingの次元は100, フィルタのサイズは1,2,3,4とした。loss functionはlog lossを利用し、Adamで学習した。


![image](https://user-images.githubusercontent.com/12249301/120271172-d0202900-c2e5-11eb-9748-a0417308ca48.png)

![image](https://user-images.githubusercontent.com/12249301/120256387-f5526e80-c2c8-11eb-84ca-9b9dc617f048.png)


DeepFM超えを達成。
entity embedding, contextual entity embeddingをablationすると、AUCは2ポイントほど現象するが、それでもDeepFMよりは高い性能を示している。
また、attentionを抜くとAUCは1ポイントほど減少する。

1ユーザのtraining/testセットのサンプル
![image](https://user-images.githubusercontent.com/12249301/120272323-dc0cea80-c2e7-11eb-8c2a-0e43be3e069b.png)
#365 によって経験的にRNN, Recursive Neural Network等と比較して、sentenceのrepresentationを獲得する際にCNNが優れていることが示されているため、CNNでrepresentationを獲得することにした模様（footprint 7より）Factorization Machinesベースドな手法（LibFM, DeepFM）を利用する際は、TF-IDF featureと、averaged entity embeddingによって構成し、それをuser newsとcandidate news同士でconcatしてFeatureとして入力した模様content情報を一切利用せず、ユーザのimplicit feedbackデータ（news click）のみを利用するDMF（Deep Matrix Factorization）の性能がかなり悪いのもおもしろい。やはりuser-item-implicit feedbackデータのみだけでなく、コンテンツの情報を利用した方が強い。（おそらく）著者によるtensor-flowでの実装: https://github.com/hwwang55/DKN日本語解説
https://qiita.com/agatan/items/24c6d8e00f2fc861bb04</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/FactorizationMachines.html">#FactorizationMachines</a><a class="button" href="articles/CTRPrediction.html">#CTRPrediction</a><a class="button" href="articles/WWW.html">#WWW</a><br /><span class="issue_date">Issue Date: 2020-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/341">Field Weighted Factorization Machines for Click-Through Rate Prediction in Display Advertising, Pan+, WWW18</a>
<span class="snippet"><span>Comment</span>CTR予測でbest-performingなモデルと言われているField Aware Factorization Machines(FFM)では、パラメータ数がフィールド数×特徴数のorderになってしまうため非常に多くなってしまうが、これをよりメモリを効果的に利用できる手法を提案。FFMとは性能がcomparableであるが、パラメータ数をFFMの4%に抑えることができた。</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/NaturalLanguageGeneration.html">#NaturalLanguageGeneration</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/ReviewGeneration.html">#ReviewGeneration</a><a class="button" href="articles/RecSys.html">#RecSys</a><br /><span class="issue_date">Issue Date: 2019-08-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/317">Improving Explainable Recommendations with Synthetic Reviews, Ouyang+, RecSys18</a>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/GraphBased.html">#GraphBased</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/GraphConvolutionalNetwork.html">#GraphConvolutionalNetwork</a><a class="button" href="articles/SIGKDD.html">#SIGKDD</a><br /><span class="issue_date">Issue Date: 2019-05-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/311">Graph Convolutional Neural Networks for Web-Scale Recommender Systems, Ying+, KDD18</a>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/Survey.html">#Survey</a><br /><span class="issue_date">Issue Date: 2018-04-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/272">Deep Learning based Recommender System: A Survey and New Perspectives, Zhang+, CSUR18</a>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/General.html">#General</a><a class="button" href="articles/Embeddings.html">#Embeddings</a><a class="button" href="articles/MachineLearning.html">#MachineLearning</a><a class="button" href="articles/RepresentationLearning.html">#RepresentationLearning</a><a class="button" href="articles/AAAI.html">#AAAI</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/68">StarSpace: Embed All The Things, Wu+, AAAI18</a>
<span class="snippet"><span>Comment</span>分類やランキング、レコメンドなど、様々なタスクで汎用的に使用できるEmbeddingの学習手法を提案。

Embeddingを学習する対象をEntityと呼び、Entityはbag-of-featureで記述される。
Entityはbag-of-featureで記述できればなんでもよく、
これによりモデルの汎用性が増し、異なる種類のEntityでも同じ空間上でEmbeddingが学習される。

学習方法は非常にシンプルで、Entity同士のペアをとったときに、relevantなpairであれば類似度が高く、
irelevantなペアであれば類似度が低くなるようにEmbeddingを学習するだけ。
たとえば、Entityのペアとして、documentをbag-of-words, bag-of-ngrams, labelをsingle wordで記述しテキスト分類、
あるいは、user_idとユーザが過去に好んだアイテムをbag-of-wordsで記述しcontent-based recommendationを行うなど、 応用範囲は幅広い。

5種類のタスクで提案手法を評価し、既存手法と比較して、同等かそれ以上の性能を示すことが示されている。

手法の汎用性が高く学習も高速なので、色々な場面で役に立ちそう。
また、異なる種類のEntityであっても同じ空間上でEmbeddingが学習されるので、学習されたEmbeddingの応用先が広く有用。実際にSentimentAnalysisで使ってみたが（ポジネガ二値分類）、少なくともBoWのSVMよりは全然性能良かったし、学習も早いし、次元数めちゃめちゃ少なくて良かった。
StarSpaceで学習したembeddingをBoWなSVMに入れると性能が劇的に改善した。解説：
https://www.slideshare.net/akihikowatanabe3110/starspace-embed-all-the-things</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/ReviewGeneration.html">#ReviewGeneration</a><a class="button" href="articles/SIGIR.html">#SIGIR</a><br /><span class="issue_date">Issue Date: 2019-04-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/309">Neural rating regression with abstractive tips generation for recommendation, Li+, SIGIR17</a>
<span class="snippet"><span>Comment</span>Rating Predictionとtips generationを同時に行うことで、両者の性能を向上させた最初の研究。
tipsとは、ユーザの経験や感じたことを、短いテキスト（1文とか）で簡潔に記したもの。![image](https://user-images.githubusercontent.com/12249301/56012618-43423c00-5d28-11e9-82ff-fe90c9dd7d1c.png)

モデルについてはあまりく詳しく読んでいないが、図を見る感じ、user latent factorとitem latent factorをMF layerとseq2seqで共有し、同時学習させていると思われる。
おそらく、MFとtext generationをjointで行うNNモデルはこの研究が初めて（textの情報をMFの改善に使おうという試みは古くからやられているが、generationまでは多分やってない）で、このモデル化の仕方がその後のスタンダードになっている。</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/NaturalLanguageGeneration.html">#NaturalLanguageGeneration</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/ReviewGeneration.html">#ReviewGeneration</a><a class="button" href="articles/IJCNLP.html">#IJCNLP</a><br /><span class="issue_date">Issue Date: 2019-02-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/303">Estimating Reactions and Recommending Products with Generative Models of Reviews, Ni+, IJCNLP17</a>
<span class="snippet"><span>Comment</span>Collaborative Filtering (CF) によるコンテンツ推薦とReview Generationを同時に学習し、
両者の性能を向上させる話。
非常に興味深い設定で、このような実験設定でReview Generationを行なった初めての研究。CFではMatrix Factorization (MF) を利用し、Review Generationでは、LSTM-basedなseq2seqを利用する。MFとReview Generationのモデルにおいて、共通のuser latent factorとitem latent factorを利用することで、joint modelとしている。このとき、latent factorは、両タスクを通じて学習される。

CFでは、Implicitな設定なので、Rating Predictionではなく、binary classificationを行うことで、推薦を行う。
classificationには、Matrix Factorization (MF) を拡張したモデルを用いる。
具体的には、通常のMFでは、user latent factorとitem latent factorの内積によって、userのitemに対するpreferenceを表現するが、このときに、target userが過去に記載したレビュー・およびtarget itemに関する情報を利用する。レビューのrepresentationのaverageをとったvectorと、MFの結果をlinear layerによって写像し、最終的なclassification scoreとしている。

Review Generationでは、基本的にはseq2seqのinputのEmbeddingに対して、user latent factor, item latent factorをconcatするだけ。hidden stateに直接concatしないのは、latent factorを各ステップで考慮できるため、long, coherentなsequenceを生成できるから、と説明している。

![image](https://user-images.githubusercontent.com/12249301/56011945-15a7c380-5d25-11e9-9a0d-8835bdb6cbed.png)
![image](https://user-images.githubusercontent.com/12249301/56012061-9c5ca080-5d25-11e9-9327-2c7a9c3ee365.png)

Recommendタスクにおいては、Bayesian Personalized Ranking, Generalized Matrix Factorizationをoutperform。![image](https://user-images.githubusercontent.com/12249301/56012129-f65d6600-5d25-11e9-919a-33018878f96e.png)

Review GenerationはPerplexityにより評価している。提案手法がcharacter based lstmをoutperform。
Perplexityによる評価だと言語モデルとしての評価しかできていないので、BLEU, ROUGEなどを利用した評価などもあって良いのでは。</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/MatrixFactorization.html">#MatrixFactorization</a><a class="button" href="articles/WWW.html">#WWW</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-02-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/260">Neural Collaborative Filtering, He+, WWW17</a>
<span class="snippet"><span>Comment</span>Collaborative FilteringをMLPで一般化したNeural Collaborative Filtering、およびMatrix Factorizationはuser, item-embeddingのelement-wise product + linear transofmration + activation で一般化できること（GMF; Generalized Matrix Factorization）を示し、両者を組み合わせたNeural Matrix Factorizationを提案している。

![image](https://user-images.githubusercontent.com/12249301/121464723-5c6dd280-c9ef-11eb-9c56-7382f2403dc1.png)

学習する際は、Implicit Dataの場合は負例をNegative Samplingし、LogLoss（Binary Cross-Entropy Loss）で学習する。

![image](https://user-images.githubusercontent.com/12249301/121464911-bb334c00-c9ef-11eb-88a6-697fab50e60d.png)
Neural Matrix Factorizationが、ItemKNNやBPRといったベースラインをoutperform

Negative Samplingでサンプリングする負例の数は、3~4程度で良さそう
![image](https://user-images.githubusercontent.com/12249301/121464991-e9189080-c9ef-11eb-96ce-4e743f84a183.png)
</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/Tutorial.html">#Tutorial</a><a class="button" href="articles/InformationRetrieval.html">#InformationRetrieval</a><a class="button" href="articles/SIGKDD.html">#SIGKDD</a><br /><span class="issue_date">Issue Date: 2018-02-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/259">Deep Learning for Personalized Search and Recommender Systems, KDD17</a>
<a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/EMNLP.html">#EMNLP</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/211">MoodSwipe: A Soft Keyboard that Suggests Messages Based on User-Specified Emotions, Huang+, EMNLP17</a>
<a class="button" href="articles/Survey.html">#Survey</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/167">A survey of transfer learning for collaborative recommendation with auxiliary data, Pan, Neurocomputing17</a>
<a class="button" href="articles/Pocket.html">#Pocket</a><br /><span class="issue_date">Issue Date: 2023-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/657">Ups and Downs: Modeling the Visual Evolution of Fashion Trends with  One-Class Collaborative Filtering, Ruining He+, N_A, arXiv16</a>
<span class="snippet"><span>Summary</span>ファッションなどの特定のドメインにおいて、製品の視覚的な外観と時間の経過に伴う進化を同時にモデル化することが重要であり、そのような好みをモデル化することは非常に困難である。本論文では、One-Class Collaborative Filtering設定のための新しいモデルを構築し、過去のフィードバックに基づいてユーザーのファッションに関する個人的なランキング関数を推定することを目的としている。実験的に、Amazon.comからの2つの大規模な実世界データセットで我々の手法を評価し、最先端の個人化ランキング尺度を上回ることを示し、また、データセットの11年間にわたる高レベルのファッショントレンドを可視化するために使用した。</span>
<span class="snippet"><span>Comment</span>#653 を構築した研究と同様の著者の研究
#653 を利用した場合はこの研究は #654 をreferする必要がある</span>
<a class="button" href="articles/SessionBased.html">#SessionBased</a><a class="button" href="articles/ICLR.html">#ICLR</a><a class="button" href="articles/SequentialRecommendation.html">#SequentialRecommendation</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2019-08-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/315">SESSION-BASED RECOMMENDATIONS WITH RECURRENT NEURAL NETWORKS, Hidasi+, ICLR16</a>
<span class="snippet"><span>Comment</span>RNNを利用したsequential recommendation (session-based recommendation)の先駆け的論文。日本語解説: https://qiita.com/tatamiya/items/46e278a808a51893deac</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/RecSys.html">#RecSys</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-12-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/298">Deep Neural Networks for YouTube Recommendations, Covington+, RecSys16</a>
<a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/Education.html">#Education</a><a class="button" href="articles/TechnologyEnhancedLearning.html">#TechnologyEnhancedLearning</a><br /><span class="issue_date">Issue Date: 2018-03-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/270">A Survey on Artificial Intelligence and Data Mining for MOOCs, Fauvel+, arXiv16</a>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/WSDM.html">#WSDM</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/216">Collaborative Denoising Auto-Encoders for Top-N Recommender Systems, Wu+, WSDM16</a>
<span class="snippet"><span>Comment</span>Denoising Auto-Encoders を用いたtop-N推薦手法、Collaborative Denoising Auto-Encoder (CDAE)を提案。
モデルベースなCollaborative Filtering手法に相当する。corruptedなinputを復元するようなDenoising Auto Encoderのみで推薦を行うような手法は、この研究が初めてだと主張。

学習する際は、userのitemsetのsubsetをモデルに与え（noiseがあることに相当）、全体のitem setを復元できるように、学習する（すなわちDenoising Auto-Encoder）。
推薦する際は、ユーザのその時点でのpreference setをinputし、new itemを推薦する。

#221 もStacked Denoising Auto EncoderとCollaborative Topic Regression #226 を利用しているが、#221 ではarticle recommendationというspecificな問題を解いているのに対して、提案手法はgeneralなtop-N推薦に利用できることを主張。</span>
<a class="button" href="articles/Citations.html">#Citations</a><a class="button" href="articles/LearningToRank.html">#LearningToRank</a><a class="button" href="articles/ACL.html">#ACL</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/181">News Citation Recommendation with Implicit and Explicit Semantics, Peng+, ACL16</a>
<span class="snippet"><span>Comment</span>target text中に記述されているイベントや意見に対して、それらをサポートするような他のニュース記事を推薦する研究。

たとえば、target text中に「北朝鮮が先日ミサイルの発射に失敗したが...」、といった記述があったときに、このイベントについて報道しているニュース記事を推薦するといったことを、target text中の様々なcontextに対して行う。

このようなシステムの利用により、target textの著者の執筆支援（自身の主張をサポートするためのreferenceの自動獲得）や、target textの読者の読解支援（text中の記述について詳細な情報を知りたい場合に、検索の手間が省ける）などの利点があると主張。

タスクとしては、target text中のあるcontextと、推薦の候補となるニュース記事の集合が与えられたときに、ニュース記事をre-rankingする タスク。

提案手法はシンプルで、contextとニュース記事間で、様々な指標を用いてsimilarityを測り、それらをlearning-to-rankで学習した重みで組み合わせてre-rankingを行うだけ。 similarityを測る際は、表記揺れや曖昧性の問題に対処するためにEmbeddingを用いる手法と、groundingされたentityの情報を用いる手法を提案。

Bing news中のAnchor textと、hyperlink先のニュース記事の対から、contextと正解ニュース記事の対を取得し、30000件規模の実験データを作成し、評価。その結果、baselineよりも提案手法の性能が高いことを示した。</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/CTRPrediction.html">#CTRPrediction</a><a class="button" href="articles/SequentialRecommendation.html">#SequentialRecommendation</a><a class="button" href="articles/SIGKDD.html">#SIGKDD</a><br /><span class="issue_date">Issue Date: 2025-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1902">E-commerce in Your Inbox: Product Recommendations at Scale, Mihajlo Grbovic+, KDD15</a>
<span class="snippet"><span>Summary</span>メールの領収書から得た購入履歴を活用し、Yahoo Mailユーザーにパーソナライズされた商品広告を配信するシステムを提案。新しい神経言語ベースのアルゴリズムを用いて、2900万人以上のユーザーのデータでオフラインテストを実施した結果、クリック率が9%向上し、コンバージョン率も改善。システムは2014年のホリデーシーズンに本稼働を開始。</span>
<span class="snippet"><span>Comment</span>Yahoo mailにおける商品推薦の研究
![image](https://github.com/user-attachments/assets/6f54d2c7-6f30-411b-94c9-888c62811bd8)

Yahoo mailのレシート情報から、商品購入に関する情報とtimestampを抽出し、時系列データを形成。評価時はTimestampで1ヶ月分のデータをheldoutし評価している。Sequential Recommendationの一種とみなせるが、評価データをユーザ単位でなくtimestampで区切っている点でよりrealisticな評価をしている。
![image](https://github.com/user-attachments/assets/6d79bb63-8d88-4be8-b1ef-1db2affb141f)関連:
- #342</span>
<a class="button" href="articles/Pocket.html">#Pocket</a><br /><span class="issue_date">Issue Date: 2023-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/654">Image-based Recommendations on Styles and Substitutes, Julian McAuley+, N_A, arXiv15</a>
<span class="snippet"><span>Summary</span>本研究では、人間の感覚に基づいた物体間の関係性をモデル化することを目的として、大規模なデータセットを用いたスケーラブルな方法を提案している。関連する画像のグラフ上で定義されたネットワーク推論問題として捉え、服やアクセサリーの組み合わせを推奨することができるシステムを開発し、その他のアプリケーションにも適用可能であることを示している。</span>
<span class="snippet"><span>Comment</span>#653 を構築した論文</span>
<a class="button" href="articles/Survey.html">#Survey</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/166">Matrix Factorization Model in Collaborative Filtering Algorithms: A Survey, Bokde+, Procedia Computer Science15</a>
<a class="button" href="articles/Tutorial.html">#Tutorial</a><a class="button" href="articles/InteractiveRecommenderSystems.html">#InteractiveRecommenderSystems</a><a class="button" href="articles/Slide.html">#Slide</a><a class="button" href="articles/RecSys.html">#RecSys</a><br /><span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/29">Interactive Recommender Systems, Netflix, RecSys15, 2015.09</a>
<a class="button" href="articles/CTRPrediction.html">#CTRPrediction</a><br /><span class="issue_date">Issue Date: 2021-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/429">Simple and scalable response prediction for display advertising, Chapelle+, Criteo, Transactions on Intelligent Systems and Technology, CHAPELLE+, TIST14</a>
<span class="snippet"><span>Comment</span>日本語解説： https://ameblo.jp/cyberanalyst/entry-11784152713.html

CTR予測の概要や、広告主・事業者にとってCTR予測ができることでどのようなメリットがあるかなどがまとまっている。
論文の手法自体は、logistic regressionが利用されている。</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/InformationRetrieval.html">#InformationRetrieval</a><a class="button" href="articles/Contents-based.html">#Contents-based</a><a class="button" href="articles/CIKM.html">#CIKM</a><br /><span class="issue_date">Issue Date: 2021-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/364">Learning Deep Structured Semantic Models  for Web Search using Clickthrough Data, Huang+, CIKM13</a>
<span class="snippet"><span>Comment</span>日本語解説: https://shunk031.me/paper-survey/summary/others/Learning-Deep-Structured-Semantic-Models-for-Web-Search-using-Clickthrough-Data</span>
<a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/MatrixFactorization.html">#MatrixFactorization</a><a class="button" href="articles/NeurIPS.html">#NeurIPS</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/224">Deep content-based music recommendation, Oord+, NIPS13</a>
<span class="snippet"><span>Comment</span>Contents-Basedな音楽推薦手法(cold-start problemに強い)。
Weighted Matrix Factorization (WMF) (Implicit Feedbackによるデータに特化したMatrix Factorization手法) #225 に、Convolutional Neural Networkによるmusic audioのlatent vectorの情報が組み込まれ、item vectorが学習されるような仕組みになっている。

![image](https://user-images.githubusercontent.com/12249301/34815522-01679f0e-f6f5-11e7-8534-22e5b5edd7a6.png)

CNNでmusic audioのrepresentationを生成する際には、audioのtime-frequencyの情報をinputとする。学習を高速化するために、window幅を3秒に設定しmusic clipをサンプルしinputする。music clip全体のrepresentationを求める際には、consecutive windowからpredictionしたrepresentationを平均したものを使用する。</span>
<a class="button" href="articles/Survey.html">#Survey</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/177">セレンディピティ指向情報推薦の研究動向, 奥健太, 知能と情報13</a>
<a class="button" href="articles/Tutorial.html">#Tutorial</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/176">推薦システムにおけるインタラクション研究へのいざない, 土方, ヒューマンインタフェース学会誌13</a>
<a class="button" href="articles/Survey.html">#Survey</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/165">Recommender systems survey, Bobadilla+, Knowledge-Based Systems13</a>
<a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><br /><span class="issue_date">Issue Date: 2021-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/428">A Comparative Study of Collaborative Filtering Algorithms, Lee+, arXiv12</a>
<span class="snippet"><span>Comment</span>様々あるCFアルゴリズムをどのように選択すべきか、# of users, # of items, rating matrix densityの観点から分析した研究。

1. 特にcomputationに関する制約がない場合は・・・、NMFはsparseなデータセットに対して最も良い性能を発揮する。BPMFはdenseなデータセットに対して最も良い性能を発揮する。そして、regularized SVD, PMFはこれ以外の状況で最も良い性能を示す（PMFはユーザ数が少ない場合によく機能する一方で、Regularized SVDはアイテム数が小さい場合に良く機能する。）。

2. もしtime constraintが5分の場合、Regularized SVD, NLPMF, NPCA, Rankbased CFは検討できない。この場合、NMFがスパースデータに対して最も良い性能を発揮し、BPMFがdenseで大規模なデータ、それ以外ではPMFが最も良い性能を示す。

3. もしtime constraintが1分の場合、PMFとBPMFは2に加えてさらに除外される。多くの場合Slope-oneが最も良い性能を示すが、データがsparseな場合はNMF。

4. リアルタイムな計算が必要な場合、user averageがbest</span>
<a class="button" href="articles/Comments.html">#Comments</a><a class="button" href="articles/WWW.html">#WWW</a><br /><span class="issue_date">Issue Date: 2018-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/229">Care to Comment? Recommendations for Commenting on News Stories, Shmueli+, WWW12</a>
<span class="snippet"><span>Comment</span>過去のユーザのコメントに対するratingに基づいて、ユーザが（コメントを通じて）議論に参加したいようなNews Storyを推薦する研究。</span>
<a class="button" href="articles/Tools.html">#Tools</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/MatrixFactorization.html">#MatrixFactorization</a><br /><span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/223"> SVDFeature: a toolkit for feature-based collaborative filtering, Chen+, JMLR12</a>
<span class="snippet"><span>Comment</span>tool: http://apex.sjtu.edu.cn/projects/33Ratingの情報だけでなく、Auxiliaryな情報も使ってMatrix Factorizationができるツールを作成した。
これにより、Rating Matrixの情報だけでなく、自身で設計したfeatureをMFに組み込んでモデルを作ることができる。

![image](https://user-images.githubusercontent.com/12249301/34814826-6a4963e8-f6f2-11e7-848f-0f0b1906442e.png)

![image](https://user-images.githubusercontent.com/12249301/34814640-b75dd2e6-f6f1-11e7-8779-21e57a977059.png)
</span>
<a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/FactorizationMachines.html">#FactorizationMachines</a><br /><span class="issue_date">Issue Date: 2018-01-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/218">Factorization Machines with libFM, Steffen Rendle, TIST12</a>
<span class="snippet"><span>Comment</span>Factorization Machinesの著者実装。
FMやるならまずはこれ。</span>
<a class="button" href="articles/Survey.html">#Survey</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/170">A literature review and classification of recommender systems research, Park+, Expert Systems with Applications12</a>
<a class="button" href="articles/Survey.html">#Survey</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/169">Explaining the user experience of recommender systems, Knijnenburg+, User Modeling and User-Adapted Interaction12</a>
<a class="button" href="articles/MatrixFactorization.html">#MatrixFactorization</a><a class="button" href="articles/WSDM.html">#WSDM</a><br /><span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/27">Multi-relational matrix factorization using bayesian personalized ranking for social network data, Krohn-Grimberghe+, WSDM12, 2012.02</a>
<span class="snippet"><span>Comment</span>multi-relationalな場合でも適用できるmatrix factorizationを提案。特にcold start problemにフォーカス。social networkのデータなどに適用できる。</span>
<a class="button" href="articles/Tutorial.html">#Tutorial</a><a class="button" href="articles/ContextAware.html">#ContextAware</a><a class="button" href="articles/AAAI.html">#AAAI</a><br /><span class="issue_date">Issue Date: 2018-12-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/289">Context Aware Recommender Systems, Adomavicius+, AAAI11</a>
<span class="snippet"><span>Comment</span>AdomaviciusらによるContext Aware Recsysチュートリアル</span>
<a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/MatrixFactorization.html">#MatrixFactorization</a><a class="button" href="articles/SIGKDD.html">#SIGKDD</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/226">Collaborative topic modeling for recommending scientific articles, Wang+, KDD11</a>
<span class="snippet"><span>Comment</span>Probabilistic Matrix Factorization (PMF) #227 に、Latent Dirichllet Allocation (LDA) を組み込んだCollaborative Topic Regression (CTR)を提案。
LDAによりitemのlatent vectorを求め、このitem vectorと、user vectorの内積を（平均値として持つ正規表現からのサンプリング）用いてratingを生成する。

![image](https://user-images.githubusercontent.com/12249301/34816213-9e21a07c-f6f7-11e7-8310-3cb55c45c71d.png)

![image](https://user-images.githubusercontent.com/12249301/34816387-1a4b1a02-f6f8-11e7-8000-f74af099bc6f.png)
![image](https://user-images.githubusercontent.com/12249301/34816394-1f981122-f6f8-11e7-80c8-4941f2a6c191.png)
CFとContents-basedな手法が双方向にinterationするような手法解説ブログ：http://d.hatena.ne.jp/repose/20150531/1433004688</span>
<a class="button" href="articles/Comments.html">#Comments</a><a class="button" href="articles/EMNLP.html">#EMNLP</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/182">Personalized Recommendation of User Comments via Factor Models, Agarwal+, EMNLP11</a>
<span class="snippet"><span>Comment</span>Personalizedなコメント推薦モデルを提案。rater-authorの関係、rater-commentの関係をlatent vectorを用いて表現し、これらとバイアス項の線形結合によりraterのあるコメントに対するratingを予測する。
パラメータを学習する際は、EMでモデルをfittingする。
バイアスとして、rater bias, comment popularity bias, author reputation biasを用いている。
rater-commentに関連するバイアスやlatent vectorは、コメントのbag-of-wordsからregressionした値を平均として持つガウス分布から生成される。

Yahoo Newsのコメントで実験。ROC曲線のAUCとPrecsionで評価。
user-user, user-commentを単体で用いたモデルよりも両者を組み合わせた場合が最も性能が良かった。
かなり綺麗に結果が出ている。</span>
<a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/159">Collaborative Filtering Recommender Systems, Ekstrand+ （with Joseph A. Konstan）, Foundations and TrendsR in Human–Computer Interaction11</a>
<a class="button" href="articles/MachineLearning.html">#MachineLearning</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/FactorizationMachines.html">#FactorizationMachines</a><a class="button" href="articles/ICDM.html">#ICDM</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-12-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/281">Factorization Machines, Steffen Rendle, ICDM10</a>
<span class="snippet"><span>Comment</span>解説ブログ：http://echizen-tm.hatenablog.com/entry/2016/09/11/024828
DeepFMに関する動向：https://data.gunosy.io/entry/deep-factorization-machines-2018![image](https://user-images.githubusercontent.com/12249301/50376506-c3954200-0650-11e9-8330-26bda57d154f.png)

非常に完結でわかりやすい説明![image](https://user-images.githubusercontent.com/12249301/50376518-fdfedf00-0650-11e9-99c0-060f286de392.png)

FMのFeature VectorのExample
各featureごとにlatent vectorが学習され、featureの組み合わせのweightが内積によって表現される

![image](https://user-images.githubusercontent.com/12249301/50376536-53d38700-0651-11e9-830d-28bc32b3c02d.png)

Matrix Factorizationの一般形のような形式</span>
<a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/171">Content-based Recommender Systems: State of the Art and Trends, Lops+, Recommender Systems Handbook10</a>
<span class="snippet"><span>Comment</span>RecSysの内容ベースフィルタリングシステムのユーザプロファイルについて知りたければこれ</span>
<a class="button" href="articles/LearningToRank.html">#LearningToRank</a><a class="button" href="articles/ImplicitFeedback.html">#ImplicitFeedback</a><a class="button" href="articles/UAI.html">#UAI</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/28">BPR: Bayesian Personalized Ranking from Implicit Feedback, Rendle+, UAI09, 2009.06</a>
<span class="snippet"><span>Comment</span>重要論文
ユーザのアイテムに対するExplicit/Implicit Ratingを利用したlearning2rank。
AUCを最適化するようなイメージ。
負例はNegative Sampling。
計算量が軽く、拡張がしやすい。

Implicitデータを使ったTop-N Recsysを構築する際には検討しても良い。
また、MFのみならず、Item-Based KNNに活用することなども可能。

http://tech.vasily.jp/entry/2016/07/01/134825参考: https://techblog.zozo.com/entry/2016/07/01/134825pytorchでのBPR実装: https://github.com/guoyang9/BPR-pytorch</span>
<a class="button" href="articles/PersonalizedDocumentSummarization.html">#PersonalizedDocumentSummarization</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/GraphBased.html">#GraphBased</a><a class="button" href="articles/PACLIC.html">#PACLIC</a><br /><span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/4">Collaborative Summarization: When Collaborative Filtering Meets Document Summarization, Qu+, PACLIC09, 2009.12</a>
<span class="snippet"><span>Comment</span>![image](https://user-images.githubusercontent.com/12249301/34400963-26dc2ee2-ebda-11e7-8170-2aa5fcc701c1.png)


Collaborative Filteringと要約を組み合わせる手法を提案した最初の論文と思われる。

ソーシャルブックマークのデータから作成される、ユーザ・アイテム・タグのTripartite Graphと、ドキュメントのsentenceで構築されるGraphをのノード間にedgeを張り、co-rankingする手法を提案している。

![image](https://user-images.githubusercontent.com/12249301/34400975-4ca118fe-ebda-11e7-9e6f-0bf1d12ccfc5.png)
評価
100個のEnglish wikipedia記事をDLし、文書要約のセットとした。
その上で、5000件のwikipedia記事に対する1084ユーザのタギングデータをdelicious.comから収集し、合計で8396の異なりタグを得た。
10人のdeliciousのアクティブユーザの協力を得て、100記事に対するtop5のsentenceを抽出してもらった。ROUGE1で評価。</span>
<a class="button" href="articles/MatrixFactorization.html">#MatrixFactorization</a><a class="button" href="articles/NeurIPS.html">#NeurIPS</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/227">Probabilistic Matrix Factorization, Salakhutdinov+, NIPS08</a>
<span class="snippet"><span>Comment</span>Matrix Factorizationを確率モデルとして表した論文。
解説：http://yamaguchiyuto.hatenablog.com/entry/2017/07/13/080000
既存のMFは大規模なデータに対してスケールしなかったが、PMFではobservationの数に対して線形にスケールし、さらには、large, sparse, imbalancedなNetflix datasetで良い性能が出た（Netflixデータセットは、rating件数が少ないユーザとかも含んでいる。MovieLensとかは含まれていないのでより現実的なデータセット）。
![image](https://user-images.githubusercontent.com/12249301/34817061-30757582-f6fa-11e7-90fb-ad5e5fc65781.png)

また、Constrained PMF（同じようなsetの映画にrateしているユーザは似ているといった仮定に基づいたモデル ※1）を用いると、少ないratingしかないユーザに対しても良い性能が出た。

※1　ratingの少ないユーザの潜在ベクトルは平均から動きにくい、つまりなんの特徴もない平均的なユーザベクトルになってしまうので、同じ映画をratingした人は似た事前分布を持つように制約を導入したモデル

（解説ブログ、解説スライドより）</span>
<a class="button" href="articles/MatrixFactorization.html">#MatrixFactorization</a><a class="button" href="articles/SIGKDD.html">#SIGKDD</a><br /><span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/222">Relational learning via collective matrix factorization, Singh+, KDD08</a>
<span class="snippet"><span>Comment</span>従来のMatrix Factorization（MF）では、pair-wiseなrelation（たとえば映画とユーザと、映画に対するユーザのrating）からRating Matrixを生成し、その行列を分解していたが、multipleなrelation（たとえば、user-movie ratingの5-scale Matrixとmovie - genreの binary Matrixなど）を扱うことができなかったので、それを可能にした話。
これができると、たとえば ユーザの映画に対するratingを予測する際に、あるユーザが特定のジャンルの映画に対して高いratingを付けるような情報も考慮して予測ができたりする。</span>
<a class="button" href="articles/Survey.html">#Survey</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/172">Content-Based Recommendation Systems, Pazzani+, The Adaptive Web07</a>
<a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/Explanation.html">#Explanation</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/162">A Survey of Explanations in Recommender Systems, Tintarev+, ICDEW07</a>
<a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/MatrixFactorization.html">#MatrixFactorization</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/161">Matrix Factorization Techniques for Recommender Systems, Koren+, Computer07</a>
<span class="snippet"><span>Comment</span>Matrix Factorizationについてよくまとまっている</span>
<a class="button" href="articles/Analysis.html">#Analysis</a><a class="button" href="articles/Others.html">#Others</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/183">Usage patterns of collaborative tagging systems, Golder+, Journal of Information Science06</a>
<span class="snippet"><span>Comment</span>Social Tagging Systemの仕組みや使われ方について言及する際にreferすると良いかも。</span>
<a class="button" href="articles/GraphBased.html">#GraphBased</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/180">Folkrank: A ranking algorithm for folksonomies, Hotho+, FGIR06</a>
<span class="snippet"><span>Comment</span>代表的なタグ推薦手法</span>
<a class="button" href="articles/Survey.html">#Survey</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/168">Explanation in Recommender Systems, Mcsherry, Artificial Intelligence Review05</a>
<a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/157">Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions, Adomavicius+, IEEE Transactions on Knowledge and Data Engineering05</a>
<span class="snippet"><span>Comment</span>有名なやつ</span>
<a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/158">Evaluating Collaborative Filtering Recommener Systems, Herlocker+, TOIS04</a>
<span class="snippet"><span>Comment</span>GroupLensのSurvey</span>
<a class="button" href="articles/ColdStart.html">#ColdStart</a><br /><span class="issue_date">Issue Date: 2025-05-16</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1966">Getting to know you: learning new user preferences in recommender systems, Rashid+, IUI02</a>
<span class="snippet"><span>Comment</span>- #1955

のOpenReviewで言及されているコールドスタートに関する研究</span>
<a class="button" href="articles/Survey.html">#Survey</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/160">Hybrid Recommender Systems: Survey and Experiments, Burke+, User Modeling and User-Adapted Interaction02</a>
<a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/ItemBased.html">#ItemBased</a><a class="button" href="articles/WWW.html">#WWW</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/179">Item-based collaborative filtering recommendation algorithms, Sarwar+（with Konstan）, WWW01</a>
<span class="snippet"><span>Comment</span>アイテムベースな協調フィルタリングを提案した論文（GroupLens）</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Slide.html">#Slide</a><a class="button" href="articles/TwoTowerModel.html">#TwoTowerModel</a><br /><span class="issue_date">Issue Date: 2025-07-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2244">DMMにおけるレコメンドの紹介‗20250716_traP×DMM, 合同会社DMM.com, 2025.07</a>
<span class="snippet"><span>Comment</span>Two Towerモデル + LightGBMによるリランキング</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/Video.html">#Video</a><br /><span class="issue_date">Issue Date: 2025-07-17</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2242">LLM Recommendation Systems: AI Engineer Worlds Fair 2025, AI Engineer, 2025.07</a>
<span class="snippet"><span>Comment</span>元ポスト:https://x.com/kazunori_279/status/1945644623474692103?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-QセマンティックIDの実用例</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Blog.html">#Blog</a><a class="button" href="articles/Slide.html">#Slide</a><br /><span class="issue_date">Issue Date: 2025-07-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2214">推薦システムにおけるPost Processの取り組み, Wantedly, 2025.07</a>
<span class="snippet"><span>Comment</span>元ポスト:https://x.com/nogawanogawa/status/1945035955645055150?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-QWantedlyスカウトにおいて、オンラインで動的にスカウト利用者から指定されるフィルタリング要件に対して、未閲覧のユーザの比率を動的に調整してランキングするPost Processによって、主要KPIが大幅に改善した話。モデル改善に興味が行きがちだが、顧客理解に基づくPost Processでここまで主要KPIが改善するのは美しく、非常に興味深い。スライド資料:https://x.com/nogawanogawa/status/1945442302778122687?s=46&amp;t=Y6UuIHB0Lv0IpmFAjlc2-Q</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/Embeddings.html">#Embeddings</a><a class="button" href="articles/EfficiencyImprovement.html">#EfficiencyImprovement</a><a class="button" href="articles/AWS.html">#AWS</a><a class="button" href="articles/MLOps.html">#MLOps</a><a class="button" href="articles/Blog.html">#Blog</a><a class="button" href="articles/A/B Testing.html">#A/B Testing</a><a class="button" href="articles/TwoTowerModel.html">#TwoTowerModel</a><br /><span class="issue_date">Issue Date: 2025-06-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/2113">日経電子版のアプリトップ「おすすめ」をTwo Towerモデルでリプレースしました, NIKKEI, 2025.05</a>
<span class="snippet"><span>Comment</span>リアルタイム推薦をするユースケースにおいて、ルールベース+協調フィルタリング(Jubatus)からTwo Towerモデルに切り替えた際にレイテンシが300ms増えてしまったため、ボトルネックを特定し一部をパッチ処理にしつつもリアルタイム性を残すことで解決したという話。AWSの構成、A/Bテストや負荷テストの話もあり、実用的で非常に興味深かった。</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/Blog.html">#Blog</a><br /><span class="issue_date">Issue Date: 2025-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1907">Improving Recommendation Systems &amp; Search in the Age of LLMs, eugeneyan, 2025.04</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/Blog.html">#Blog</a><br /><span class="issue_date">Issue Date: 2025-03-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1844">Recommendation Systems • LLM, vinjia.ai, 2025.03</a>
<span class="snippet"><span>Comment</span>元ポスト:https://www.linkedin.com/posts/vinija_recommendation-systems-llm-activity-7306171374446727168-cUg2?utm_source=share&amp;utm_medium=member_ios&amp;rcm=ACoAACzQvjwB2FeLVE3yukDiUYtr5J4k-6nlNG4</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Blog.html">#Blog</a><br /><span class="issue_date">Issue Date: 2024-12-20</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1605">Netflixの推薦＆検索システム最前線 - QCon San Francisco 2024現地レポート, UZABASE, 2024.12</a>
<span class="snippet"><span>Comment</span>インフラ構成の部分が面白い。モデルの構築方法などは、まず軽量なモデルやヒューリスティックで候補を絞り、その後計算量が重いモデルでリランキングする典型的な手法。

Netflixのインフラによって、以下のようなことを
&gt;1～2秒前の最新データを参照でき、推薦生成に反映させることが可能です

latencyを40msに抑えつつ実現しているとのこと。直前のアクションをinferenceで考慮できるのは相当性能に影響あると思われる。

また、検索と推薦をマルチタスク学習しパラメータをシェアすることで両者の性能を挙げているのが興味深い。
モデル自体は近年のLLMを用いた推薦では無く、Deepなニューラルネットに基づくモデルを採用
（まあLLMなんかにリアルタイムで推論させたらlatency 40ms未満という制約はだいぶきついと思われるしそもそも性能向上するかもわからん。予測性能とかよりも、推薦理由の生成などの他タスクも同時に実施できるのは強みではあるとは思うが…）。まあしかし、すごい目新しい情報があったかと言われると基本的な内容に留まっているのでそうでもないという感想ではある。</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/Blog.html">#Blog</a><br /><span class="issue_date">Issue Date: 2024-12-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1569">Augmenting Recommendation Systems With LLMs, Dave AI, 2024.08</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Slide.html">#Slide</a><br /><span class="issue_date">Issue Date: 2024-09-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1396">クリックを最大化しない推薦システム, Ryoma Sato, 2024.01</a>
<span class="snippet"><span>Comment</span>おもしろそうなので後で読むクリック率やコンバージョン率に最適化することが従来のやり方だが、クリックベイトのため粗悪なコンテンツを推薦してしまったり、人気のあるアイテムに推薦リストが偏ってしまい、長期的なユーザの利益を害するという話。

20年くらい前からこの辺をなんとかするために、推薦のセレンディピティや多様性を考慮する手法が研究されており、それらのエッセンスが紹介されている。また、Calibrated Recommendation #1403（ユーザの推薦リストがのジャンルの比率がユーザの好む比率になるように最適化する方法で、劣モジュラ関数を最適化するためgreedyに解いてもある程度良い近似解が保証されている）などの概要も説明されていて非常に勉強になった。

セレンディピティのある推薦アルゴリズムをGoogle上でA/Bテストしたら、ユーザの満足度とコアユーザー転換率が大幅に向上したと言う話や、推薦はフィルターバブル問題を実は悪化させないといった研究がGroupLensのKonstan先生のチームから出ているなど、興味深い話題が盛りだくさんだった。</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/CTRPrediction.html">#CTRPrediction</a><a class="button" href="articles/NewsRecommendation.html">#NewsRecommendation</a><a class="button" href="articles/MLOps.html">#MLOps</a><a class="button" href="articles/Evaluation.html">#Evaluation</a><a class="button" href="articles/Blog.html">#Blog</a><a class="button" href="articles/A/B Testing.html">#A/B Testing</a><br /><span class="issue_date">Issue Date: 2024-08-31</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1367">NewsPicksに推薦システムを本番投入する上で一番優先すべきだったこと, 2024.08</a>
<span class="snippet"><span>Comment</span>&gt;推薦モデルの良し悪しをより高い確度で評価できる実験を、より簡単に実行できる状態を作ることでした。平たく言えば「いかにA/Bテストしやすい推薦システムを設計するか」が最も重要だった訳です。

オフライン評価とオンライン評価の相関がない系の話で、A/Bテストを容易に実施できる環境になかった、かつCTRが実際に向上したモデルがオフライン評価での性能が現行モデルよりも悪く、意思決定がなかなかできなかった、という話。

うーんやはり、推薦におけるオフライン評価ってあまりあてにできないよね、、、
そもそも新たなモデルをデプロイした時点で、テストした時とデータの分布が変わるわけだし、、、

Off-Policy Evaluationの話は勉強したい。あと、定性評価は重要</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/Blog.html">#Blog</a><br /><span class="issue_date">Issue Date: 2024-08-27</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1360">10Xの推薦を作るチームとML platform, 2024.08</a>
<span class="snippet"><span>Comment</span>初期開発における定性評価の重要性やインターリービングの話題など実用的な内容が書かれているように見える。あとで読む。定性評価が重要という話は、#1367 でも言及されている</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/Library.html">#Library</a><a class="button" href="articles/Repository.html">#Repository</a><br /><span class="issue_date">Issue Date: 2024-08-07</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1345">list of recommender systems</a>
<span class="snippet"><span>Comment</span>推薦システムに関するSaaS, OpenSource, Datasetなどがまとめられているリポジトリ</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Tutorial.html">#Tutorial</a><a class="button" href="articles/Blog.html">#Blog</a><br /><span class="issue_date">Issue Date: 2024-04-26</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1295">推薦・機械学習勉強会, Wantedly</a>
<span class="snippet"><span>Comment</span>WantedlyさんのRecSys勉強会の資料がまとまったリポジトリ。継続的に更新されており、最近この辺のトピックは追いきれていないので非常に有用。</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Library.html">#Library</a><a class="button" href="articles/Repository.html">#Repository</a><br /><span class="issue_date">Issue Date: 2024-01-15</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1205">Recommenders</a>
<span class="snippet"><span>Comment</span>古典的な手法から、Deepな手法まで非常に幅広く網羅された推薦アルゴリズムのフレームワーク。元々Microsoft配下だった模様。現在もメンテナンスが続いており、良さそう</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/MLOps.html">#MLOps</a><br /><span class="issue_date">Issue Date: 2023-12-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1190">モバオクでのリアルタイムレコメンドシステムの紹介</a>
<span class="snippet"><span>Comment</span>DeNAでのRecSysのアーキテクチャ（バッチ、リアルタイム）が紹介されている。バッチではワークフローエンジンとしてVertex AI Pipelineが用いられている。リアルタイムになるとアーキテクチャが非常に複雑になっている。
複雑なアーキテクチャだが、Generative Recommendation使ったらもっとすっきりしそうだなーと思いつつ、レイテンシと運用コストの課題があるのでまだ実用段階じゃないよね、と思うなどした。リアルタイム推薦によって、バッチで日毎の更新だった場合と比べ、入札率、クリック率、回遊率が大きく改善したのは面白い。</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/MLOps.html">#MLOps</a><br /><span class="issue_date">Issue Date: 2023-09-05</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/1033">Lessons Learnt From Consolidating ML Models in a Large Scale Recommendation System</a>
<span class="snippet"><span>Comment</span>推薦システムには様々なusecaseが存在しており、それらは別々に運用されることが多い。
- user-item recommendation
- item-item recommendation
- query-item recommendation
- category-item recommendation

このような運用はシステムの技術負債を増大させ、長期的に見るとメンテナンスコストが膨大なものとなってしまう。また、多くの推薦システムには共通化できる部分がある。
これら異なるusecaseの推薦システムをmulti-taskなモデルに統合し技術負債を軽減した経験が記述されている。これが
![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8ae598fa-8e7c-4afd-ab9e-38b79b85cd3e)
このようなsingle multi-task modelを学習する構造に置き換わり、
![image](https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/14aae2de-c175-4a5d-a390-3543a340c8bf)
その結果
- code量とデプロイの管理・メンテナンスコストの低減
- 保守性の向上
    - 単一化されたコードベースが、緊急時の対応を容易にした
- あるユースケースで新たなfeatureを試し効果があった場合、他のユースケースに迅速に展開可能（同じパイプラインなので）
    - ただし、multi taskの場合は特定のタスクに効果があったfeatureの導入により他タスクの性能が低下する懸念がある
    - が、タスク間の関連性が高い場合（今回のような場合）、それは問題とならなかったことが記述されている
- 柔軟な設計の実現
    - 複数のユースケースを一つのモデルに統合することは、複数のユースケースを組み込むための柔軟な設計が求められる
    - これを実現したことにより、拡張性が増大した
- 結論
    - このような統合がコードを簡略化し、イノベーションを加速させ、システムの保守性を向上させるシナリオが多くある
    - ただし、ランキングの対象が異なっていたり、入力として活用する特徴量が大きく異なるモデル間で、このような統合の実施に適しているかは自明ではない</span>
<img src="https://github.com/AkihikoWatanabe/paper_notes/assets/12249301/8ae598fa-8e7c-4afd-ab9e-38b79b85cd3e" alt="image" loading="lazy" /><a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/Dataset.html">#Dataset</a><a class="button" href="articles/NaturalLanguageUnderstanding.html">#NaturalLanguageUnderstanding</a><br /><span class="issue_date">Issue Date: 2023-07-18</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/853">DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions</a>
<span class="snippet"><span>Summary</span>データセットの推奨タスクを操作化し、DataFinderデータセットを構築した。DataFinderデータセットは、自動的に構築された大規模なトレーニングセットと専門家による評価セットを含んでいる。このデータセットを使用して、テキストベースのデータセット推奨のための優れたバイエンコーダリトリーバを提案し、関連する検索結果を見つけることができることを示した。データセットとモデルは一般に公開される。</span>
<a class="button" href="articles/Article.html">#Article</a><br /><span class="issue_date">Issue Date: 2023-07-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/776">MetaのRecommender System概要, 2023.6</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/GenerativeAI.html">#GenerativeAI</a><br /><span class="issue_date">Issue Date: 2023-05-10</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/671">awesome-generative-information-retrieval</a>
<span class="snippet"><span>Comment</span>Generativeなモデルを利用したDocument RetrievalやRecSys等についてまとまっているリポジトリ</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/NLP.html">#NLP</a><a class="button" href="articles/Dataset.html">#Dataset</a><br /><span class="issue_date">Issue Date: 2023-05-06</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/653">SNAP: Web data: Amazon reviews</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Pocket.html">#Pocket</a><br /><span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/579">E-Commerce product recommendation agents: use, characteristics, and impact</a>
<span class="snippet"><span>Comment</span>超重要論文</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/InformationRetrieval.html">#InformationRetrieval</a><a class="button" href="articles/Personalization.html">#Personalization</a><br /><span class="issue_date">Issue Date: 2023-04-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/576">Measuring the impact of online personalisation: Past, present and future</a>
<span class="snippet"><span>Comment</span>Personalizationに関するML, RecSys, HCI, Personalized IRといったさまざまな分野の評価方法に関するSurvey

ML + RecSys系では、オフライン評価が主流であり、よりaccuracyの高い推薦が高いUXを実現するという前提に基づいて評価されてきた。一方HCIの分野ではaccuracyに特化しすぎるとUXの観点で不十分であることが指摘されており、たとえば既知のアイテムを推薦してしまったり、似たようなアイテムばかりが選択されユーザにとって有用ではなくなる、といったことが指摘されている。このため、ML, RecSys系の評価ではdiversity, novelty, serendipity, popularity, freshness等の新たなmetricが評価されるように変化してきた。また、accuracyの工場がUXの向上に必ずしもつながらないことが多くの研究で示されている。

一方、HCIやInformation Systems, Personalized IRはuser centricな実験が主流であり、personalizationは
- 情報アクセスに対するコストの最小化
- UXの改善
- コンピュータデバイスをより効率的に利用できるようにする
という3点を実現するための手段として捉えられている。HCIの分野では、personalizationの認知的な側面についても研究されてきた。
たとえば、ユーザは自己言及的なメッセージやrelevantなコンテンツが提示される場合、両方の状況においてpersonalizationされたと認知し、後から思い出せるのはrelevantなコンテンツに関することだという研究成果が出ている。このことから、自己言及的なメッセージングでユーザをstimulusすることも大事だが、relevantなコンテンツをきちんと提示することが重要であることが示されている。また、personalizationされたとユーザが認知するのは、必ずしもpersonalizationのプロセスに依存するのではなく、結局のところユーザが期待したメッセージを受け取ったか否かに帰結することも示されている。
user-centricな評価とオフライン評価の間にも不一致が見つかっている。たとえば
- オフラインで高い精度を持つアルゴリズムはニッチな推薦を隠している
  - i.e. popularityが高くrelevantな推薦した方がシステムの精度としては高く出るため
- オフライン vs. オンラインの比較で、ユーザがアルゴリズムの精度に対して異なる順位付けをする
といったことが知られている。

そのほかにも、企業ではofflineテスト -&gt; betaテスターによるexploratoryなテスト -&gt; A/Bテストといった流れになることが多く、Cognitive Scienceの分野の評価方法等にも触れている。</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Tutorial.html">#Tutorial</a><a class="button" href="articles/Embeddings.html">#Embeddings</a><a class="button" href="articles/EfficiencyImprovement.html">#EfficiencyImprovement</a><a class="button" href="articles/Library.html">#Library</a><br /><span class="issue_date">Issue Date: 2023-04-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/531">Training a recommendation model with dynamic embeddings</a>
<span class="snippet"><span>Comment</span>dynamic embeddingを使った推薦システムの構築方法の解説（理解が間違っているかもしれないが）推薦システムは典型的にはユーザとアイテムをベクトル表現し、関連度を測ることで推薦をしている。この枠組みをめっちゃスケールさせるととんでもない数のEmbeddingを保持することになり、メモリ上にEmbeddingテーブルを保持して置けなくなる。特にこれはonline machine learning（たとえばユーザのセッションがアイテムのsequenceで表現されたとき、そのsequenceを表すEmbeddingを計算し保持しておき、アイテムとの関連度を測ることで推薦するアイテムを決める、みたいなことが必要）では顕著である（この辺の理解が浅い）。しかし、ほとんどのEmbeddingはrarely seenなので、厳密なEmbeddingを保持しておくことに実用上の意味はなく、それらを単一のベクトルでできるとメモリ節約になって嬉しい（こういった処理をしてもtopNの推薦結果は変わらないと思われるので）。
これがdynamic embeddingのモチベであり、どうやってそれをTFで実装するか解説している。</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Tutorial.html">#Tutorial</a><br /><span class="issue_date">Issue Date: 2022-12-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/502">推薦システムにおいて線形モデルがまだまだ有用な話</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/Pretraining.html">#Pretraining</a><br /><span class="issue_date">Issue Date: 2022-12-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/495">A Paper List for Recommend-system PreTrained Models</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/CTRPrediction.html">#CTRPrediction</a><br /><span class="issue_date">Issue Date: 2021-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/425">2010年代前半のAIの巨人達のCTR Prediction研究</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Tutorial.html">#Tutorial</a><a class="button" href="articles/CTRPrediction.html">#CTRPrediction</a><a class="button" href="articles/Blog.html">#Blog</a><br /><span class="issue_date">Issue Date: 2021-10-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/423">バンディットアルゴリズムを使って広告最適化のシミュレーションをしてみたよ, ysekky, 2014</a>
<span class="snippet"><span>Comment</span>なぜクリック率を上げたいのかという説明が非常に参考になる：
&gt;しかしその広告を掲載する側から考えればクリック率の低い広告を出すことは売上が下がってしまうため，クリック率が&gt;低いとなかなか広告を表示することができなくなってしまいます．
その際よく使われるのはeCPMという指標です．
eCPMはその広告を1000回表示していくらの売上を上げることができるかという指標であり，
クリック率1000クリック単価で求められます．
&gt;EPCMが高い広告のほうが表示されやすいため，クリック率を上げることで同じクリック単価でたくさんのユーザを自社のランディングページに誘導することができるようになります．
&gt;例えば今回のケースではクリック率1.2%でクリック単価が60円ですので，eCPMは720円です。
ここでクリック率が0.1％上がるとeCPMは780円になります．
&gt;そのときクリック単価を56円にしてもeCPMは726円になるため，つまりクリック率が0.1%上がると同じだけのランディングページへの誘導を得るための単価を4円下げることができます．
&gt;例えばそのランディングページでの商品の購入が1%で行われるとすると，商品を1つ売るためのコストが400円も下がる事になります．
&gt;ケースバイケースではありますが，このようにクリック率を上げることはウェブ広告を通してものを売るために非常に重要な要素になります．</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/Library.html">#Library</a><a class="button" href="articles/FactorizationMachines.html">#FactorizationMachines</a><a class="button" href="articles/Repository.html">#Repository</a><br /><span class="issue_date">Issue Date: 2021-07-03</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/398">pytorch-fm, 2020</a>
<span class="snippet"><span>Comment</span>下記モデルが実装されているすごいリポジトリ。論文もリンクも記載されており、Factorization Machinesを勉強する際に非常に参考になると思う。MITライセンス。各手法はCriteoのCTRPredictionにおいて、AUC0.8くらい出ているらしい。

- Logistic Regression
- Factorization Machine
- Field-aware Factorization Machine
- Higher-Order Factorization Machines
- Factorization-Supported Neural Network
- Wide&amp;Deep
- Attentional Factorization Machine
- Neural Factorization Machine
- Neural Collaborative Filtering
- Field-aware Neural Factorization Machine
- Product Neural Network
- Deep Cross Network
- DeepFM
- xDeepFM
- AutoInt (Automatic Feature Interaction Model)
- AFN(AdaptiveFactorizationNetwork Model)</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/FactorizationMachines.html">#FactorizationMachines</a><br /><span class="issue_date">Issue Date: 2021-07-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/397">Deep Learning Recommendation Model for Personalization and Recommendation Systems, Naumov+, Facebook, arXiv‘19</a>
<span class="snippet"><span>Summary</span>深層学習に基づく推薦モデル（DLRM）を開発し、PyTorchとCaffe2で実装。埋め込みテーブルのモデル並列性を活用し、メモリ制約を軽減しつつ計算をスケールアウト。DLRMの性能を既存モデルと比較し、Big Basin AIプラットフォームでの有用性を示す。</span>
<span class="snippet"><span>Comment</span>Facebookが開発したopen sourceのDeepな推薦モデル（MIT Licence）。

モデル自体はシンプルで、continuousなfeatureをMLPで線形変換、categoricalなfeatureはembeddingをlook upし、それぞれfeatureのrepresentationを獲得。
その上で、それらをFactorization Machines layer（second-order）にぶちこむ。すなわち、Feature間の2次の交互作用をembedding間のdot productで獲得し、これを1次項のrepresentationとconcatしMLPにぶちこむ。最後にシグモイド噛ませてCTRの予測値とする。

![image](https://user-images.githubusercontent.com/12249301/124305045-86a25280-db9f-11eb-8254-3d5a68cbbd55.png)実装: https://github.com/facebookresearch/dlrmParallelism以後のセクションはあとで読む</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Tutorial.html">#Tutorial</a><a class="button" href="articles/Pocket.html">#Pocket</a><br /><span class="issue_date">Issue Date: 2021-07-02</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/396">Continuously Improving Recommender Systems for Competitive Advantage Using NVIDIA Merlin and MLOps, Nvidia, 2021.01</a>
<span class="snippet"><span>Comment</span>Recommender System運用のためのアーキテクチャに関する情報</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Dataset.html">#Dataset</a><a class="button" href="articles/CTRPrediction.html">#CTRPrediction</a><br /><span class="issue_date">Issue Date: 2021-06-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/362">Criteo Dataset, Display Advertising Challenge, Kaggle, 2014</a>
<span class="snippet"><span>Comment</span>Criteo Dataset (https://www.kaggle.com/c/criteo-display-ad-challenge/data)

DeepFM等のモデルで利用されているCTR Predictionのためのデータセット

# Data Description
- train.csv: 7日間のcriteoのtraffic recordの一部。個々の行が1 impに対応している。click, non-clickのラベル付き。chronologically order. click, non-clickのexampleはデータセットのサイズを縮小するために異なるrateでサブサンプルされている。
- training: trainingデータと同様の作成データだが、trainingデータの翌日のデータで構成されている。

# Data Fields
- Label - Target variable that indicates if an ad was clicked (1) or not (0).
- I1-I13 - A total of 13 columns of integer features (mostly count features).
- C1-C26 - A total of 26 columns of categorical features. The values of these features have been hashed onto 32 bits for anonymization purposes. 

13種類のinteger featureと、26種類のcategorical featuresがある。Avazu Data (https://www.kaggle.com/c/avazu-ctr-prediction/data)

# File descriptions
- train - Training set. 10 days of click-through data, ordered chronologically. Non-clicks and clicks are subsampled according to different strategies.
- test - Test set. 1 day of ads to for testing your model predictions. 
sampleSubmission.csv - Sample submission file in the correct format, corresponds to the All-0.5 Benchmark.

# Data fields
- id: ad identifier
- click: 0/1 for non-click/click
- hour: format is YYMMDDHH, so 14091123 means 23:00 on Sept. 11, 2014 UTC.
- C1 -- anonymized categorical variable
- banner_pos
- site_id
- site_domain
- site_category
- app_id
- app_domain
- app_category
- device_id
- device_ip
- device_model
- device_type
- device_conn_type
- C14-C21 -- anonymized categorical variables基本的には click/non-click のラベルと、そのclick時の付帯情報によって構成されている模様</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/FactorizationMachines.html">#FactorizationMachines</a><a class="button" href="articles/CTRPrediction.html">#CTRPrediction</a><a class="button" href="articles/IJCAI.html">#IJCAI</a><br /><span class="issue_date">Issue Date: 2021-05-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/349">DeepFM: A Factorization-Machine based Neural Network for CTR Prediction, Guo+, IJCAI’17</a>
<span class="snippet"><span>Comment</span>Factorization Machinesと、Deep Neural Networkを、Wide&amp;Deepしました、という論文。Wide=Factorization Machines, Deep=DNN。

高次のFeatureと低次のFeatureを扱っているだけでなく、FMによってフィールドごとのvector-wiseな交互作用、DNNではbit-wiseな交互作用を利用している。
割と色々なデータでうまくいきそうな手法に見える。

発展版としてxDeepFM #348 がある。#281 にも書いたが、下記リンクに概要が記載されている。
DeepFMに関する動向：https://data.gunosy.io/entry/deep-factorization-machines-2018実装: https://github.com/rixwew/pytorch-fm</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/FactorizationMachines.html">#FactorizationMachines</a><a class="button" href="articles/CTRPrediction.html">#CTRPrediction</a><a class="button" href="articles/SIGKDD.html">#SIGKDD</a><br /><span class="issue_date">Issue Date: 2021-05-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/348">xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems, Lian+, KDD‘18</a>
<span class="snippet"><span>Comment</span>#349 DeepFMの発展版#281 にも書いたが、下記リンクに概要が記載されている。
DeepFMに関する動向：https://data.gunosy.io/entry/deep-factorization-machines-2018

DeepFMの発展についても詳細に述べられていて、とても参考になる。</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/LanguageModel.html">#LanguageModel</a><a class="button" href="articles/CIKM.html">#CIKM</a><a class="button" href="articles/SequentialRecommendation.html">#SequentialRecommendation</a><br /><span class="issue_date">Issue Date: 2021-05-25</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/347">BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer, Sun+, CIKM2019</a>
<span class="snippet"><span>Comment</span>BERTをrecsysのsequential recommendationタスクに転用してSoTA。
しっかり読んで無いけどモデル構造はほぼBERTと一緒。
異なる点は、Training時にNext Sentence Predictionは行わずClozeのみ行なっているという点。Clozeとは、実質Masked Language Modelであり、sequenceの一部を[mask]に置き換え、置き換えられたアイテムを左右のコンテキストから予測するタスク。異なる点としては、sequential recommendationタスクでは、次のアイテムを予測したいので、マスクするアイテムの中に、sequenceの最後のアイテムをマスクして予測する事例も混ぜた点。

もう一個異なる点として、BERT4Recはend-to-endなモデルで、BERTはpretraining modelだ、みたいなこと言ってるけど、まあ確かに形式的にはそういう違いはあるけど、なんかその違いを主張するのは違和感を覚える…。
sequential recommendationで使うuser behaviorデータでNext item predictionで学習したいことが、MLMと単に一致していただけ、なのでは…。BERT4Recのモデル構造。next item predictionしたいsessionの末尾に [mask] をconcatし、[MASK]部分のアイテムを予測する構造っぽい？
![image](https://user-images.githubusercontent.com/12249301/138901870-d36fc935-8b61-4434-9d4b-dc1cb968c91e.png)
オリジナルはtensorflow実装
pytorchの実装はこちら：https://github.com/jaywonchung/BERT4Rec-VAE-Pytorch/tree/master/models</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/SequentialRecommendation.html">#SequentialRecommendation</a><br /><span class="issue_date">Issue Date: 2020-11-13</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/342">Sequence-Aware Recommender Systems, ACM Computing Surveys, Vol. 1, No. 1, Article 1, 2018</a>
<span class="snippet"><span>Comment</span>評価方法の議論が非常に参考になる。特に、Survey執筆時点において、コミュニティの中でデータ分割方法について標準化されたものがないといった話は参考になる。</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Embeddings.html">#Embeddings</a><a class="button" href="articles/Pocket.html">#Pocket</a><a class="button" href="articles/SessionBased.html">#SessionBased</a><a class="button" href="articles/SequentialRecommendation.html">#SequentialRecommendation</a><br /><span class="issue_date">Issue Date: 2020-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/340">Airbnbの機械学習導入から学ぶ, Jun Ernesto Okumura, 2020</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Tutorial.html">#Tutorial</a><a class="button" href="articles/Tools.html">#Tools</a><a class="button" href="articles/Dataset.html">#Dataset</a><a class="button" href="articles/Slide.html">#Slide</a><br /><span class="issue_date">Issue Date: 2020-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/339">Off Policy Evaluation の基礎とOpen Bandit Dataset &amp; Pipelineの紹介, Yuta Saito, 2020</a>
<span class="snippet"><span>Comment</span>機械学習による予測精度ではなく、機械学習モデルによって生じる意思決定を、過去の蓄積されたデータから評価する（Off policy Evaluation）の、tutorialおよび実装、データセットについて紹介。
このような観点は実務上あるし、見落としがちだと思うので、とても興味深い。</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Dataset.html">#Dataset</a><a class="button" href="articles/Blog.html">#Blog</a><br /><span class="issue_date">Issue Date: 2020-08-29</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/338">Open Bandit Dataset, ZOZO RESEARCH, 2020</a>
<span class="snippet"><span>Comment</span>Open Bandit pipelineも参照
資料: https://speakerdeck.com/usaito/off-policy-evaluationfalseji-chu-toopen-bandit-dataset-and-pipelinefalseshao-jie</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Tutorial.html">#Tutorial</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/ContrastiveLearning.html">#ContrastiveLearning</a><a class="button" href="articles/Blog.html">#Blog</a><br /><span class="issue_date">Issue Date: 2020-07-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/336">Collaborative Metric Learningまとめ, guglilac, 2020</a>
<span class="snippet"><span>Comment</span>userのembeddingに対し、このuserと共起した(購入やクリックされた)itemを近くに、共起していないitemを遠くに埋め込むような学習方法</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Library.html">#Library</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2019-09-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/324">Implicit</a>
<span class="snippet"><span>Comment</span>Implicitデータに対するCollaborative Filtering手法がまとまっているライブラリ
Bayesian Personalized Ranking, Logistic Matrix Factorizationなどが実装。Implicitの使い方はこの記事がわかりやすい：
https://towardsdatascience.com/building-a-collaborative-filtering-recommender-system-with-clickstream-data-dffc86c8c65ALSの元論文の日本語解説
https://cympfh.cc/paper/WRMF</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Tutorial.html">#Tutorial</a><a class="button" href="articles/Explanation.html">#Explanation</a><a class="button" href="articles/Slide.html">#Slide</a><a class="button" href="articles/SIGKDD.html">#SIGKDD</a><br /><span class="issue_date">Issue Date: 2019-08-19</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/320">Explainable AI in Industry, KDD19</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Dataset.html">#Dataset</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2019-04-12</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/308">Recommender System Datasets, Julian McAuley</a>
<span class="snippet"><span>Comment</span>Recommender Systems研究に利用できる各種データセットを、Julian McAuley氏がまとめている。
氏が独自にクロールしたデータ等も含まれている。
非常に有用。</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Tutorial.html">#Tutorial</a><a class="button" href="articles/Explanation.html">#Explanation</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2019-01-23</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/299">Designing and Evaluating Explanations for Recommender Systems, Tintarev+, Recommender Systems Handbook, 2011</a>
<span class="snippet"><span>Comment</span>Recommender Systems HandbookのChapter。#162 のSurveyと同じ著者による執筆。
推薦のExplanationといえばこの人というイメージ。D論：http://navatintarev.com/papers/Nava%20Tintarev_PhD_Thesis_(2010).pdf</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/AdaptiveLearning.html">#AdaptiveLearning</a><br /><span class="issue_date">Issue Date: 2018-12-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/292">Simulated Analysis of MAUT Collaborative Filtering for Learning Object Recommendation, Manouselis+, Social Information Retrieval for Technology-Enhanced Learning &amp; Exchange, 2007</a>
<span class="snippet"><span>Comment</span>教員に対して教材を推薦しようという試み（学生ではないようだ）。
教員は、learning resourcesに対して、multi-criteriaなratingを付与することができ、それをCFで活用する（CELEBRATE web portalというヨーロッパのポータルを使用したらしい）。
CFはmemory-basedな手法を使用。target userがあるアイテムを、それぞれのattributeの観点からどのようにratingするかをattributeごとに別々に予測。各attributeのスコアを最終的に統合（元の論文ではただのスコアの足し合わせ）して、推薦スコアとする。

以下が調査された：
1. ユーザ間の距離の測り方（ユークリッド距離、cossim、ピアソンの相関係数）
2. neighborsの選び方（定義しておいた最大人数か、相関の重みで選ぶか）
3. neighborのratingをどのように組み合わせるか（平均、重み付き平均、mean formulaからのdeviation）

評価する際は、ratingのデータを training/test 80%/20%に分割。テストセットのアイテムに対して、ユーザがratingした情報をどれだけ正しく予測できるかで検証(511 evaluation in test, 2043 evaluations in training)。

ratingのMAE, coverage, アルゴリズムの実行時間で評価。

CorrerationWeightThresholdが各種アルゴリズムで安定した性能。Maximum Number Userはばらつきがでかい。いい感じの設定がみつかれば、Maximum Number Userの方がMAEの観点からは強い。
top-10のアイテムをselectするようにしたら、６０％のcoverageになった。
（アルゴリズムの実行時間は、2000程度のevaluationデータに対して、2.5GHZ CPU, 256MEMで２０秒とかかかってる。）Learning Resource Exchangeの文脈で使われることを想定（このシステムではヨーロッパのK-12）。

教員による教材のmulti-criteriaのratingは5-scaleで行われた。
どういうcriteriaに対してratingされたかが書いてない。</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/AdaptiveLearning.html">#AdaptiveLearning</a><br /><span class="issue_date">Issue Date: 2018-12-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/291">Recommender Systems for Technology Enhanced Learning: Research Trends and Applications, Manouselis+, 2014</a>
<span class="snippet"><span>Comment</span>最近のトレンドやアプリケーションを知りたい場合はこちら</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/AdaptiveLearning.html">#AdaptiveLearning</a><br /><span class="issue_date">Issue Date: 2018-12-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/290">Panorama of recommender systems to support learning, Drachsler+, 2015</a>
<span class="snippet"><span>Comment</span>教育分野に対するRecsysのSurvey</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/ContextAware.html">#ContextAware</a><br /><span class="issue_date">Issue Date: 2018-12-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/288">Some Challenges for Context-aware Recommender Systems,” Yujie+, Proc. Fifth Int’l Conf. Computer Science and Education （ICCSE）, pp. 362-365, 2010. </a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Classic.html">#Classic</a><a class="button" href="articles/ContextAware.html">#ContextAware</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-12-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/287">Context-Aware Recommender Systems, Adomavicius+, Recommender Systems Handbook, 2011</a>
<span class="snippet"><span>Comment</span>Context-aware Recsysのパイオニア的研究通常のuser/item paradigmを拡張して、いかにコンテキストの情報を考慮するかを研究。

コンテキスト情報は、
Explicit: ユーザのマニュアルインプットから取得
Implicit: 自動的に取得
inferred: ユーザとツールやリソースのインタラクションから推測（たとえば現在のユーザのタスクとか）

いくつかの異なるパラダイムが提案された：

1. recommendation via context-driven  querying and search approach
　コンテキストの情報を、特定のリポジトリのリソース（レストラン）に対して、クエリや検索に用いる。そして、best matchingなリソースを(たとえば、現在開いているもっとも近いレストランとか)をユーザに推薦。

2. Contextual preference elicitation and estimation approach
　こっちは2012年くらいの主流。contextual user preferencesをモデル化し学習する。データレコードをしばしば、&lt;user, item, context, rating&gt;の形式で表現する。これによって、特定のアイテムが特定のコンテキストでどれだけ好まれたか、が評価できるようになる。

3. contextual prefiltering approach
　contextualな情報を（学習したcontextualなpreferenceなどを）、tradittionalなrecommendation algorithmを適用する前にデータのフィルタリングに用いる。

4. contextual postfiltering approach
　entire setから推薦を作り、あとでcontextの情報を使ってsetを整える。

5. Contextual modeling
　contextualな情報を、そのままrecommendationの関数にぶちこんでしまい、アイテムのratingのexplicitなpredictorとして使う。

3, 4はtraditionalな推薦アルゴリズムが適用できる。
1,2,5はmulti-dimensionalな推薦アルゴリズムになる。heuristic-based, model-based approachesが述べられているらしい。</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/AdaptiveLearning.html">#AdaptiveLearning</a><br /><span class="issue_date">Issue Date: 2018-12-22</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/286">Recommender Systems in Technology Enhanced Learning, Manouselis+, Recommender Systems Handbook, 2011</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/Education.html">#Education</a><br /><span class="issue_date">Issue Date: 2018-03-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/269">A SURVEY OF ARTIFICIAL INTELLIGENCE TECHNIQUES EMPLOYED FOR ADAPTIVE EDUCATIONAL SYSTEMS WITHIN E-LEARNING PLATFORMS,  Almohammadi+</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/Education.html">#Education</a><a class="button" href="articles/TechnologyEnhancedLearning.html">#TechnologyEnhancedLearning</a><br /><span class="issue_date">Issue Date: 2018-03-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/268">Recommender Systems in Technology Enhanced Learning, Manouselis+, Recommender Systems Handbook: A Complete Guide for Research Scientists and Practitioners, 2011</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/Education.html">#Education</a><a class="button" href="articles/TechnologyEnhancedLearning.html">#TechnologyEnhancedLearning</a><br /><span class="issue_date">Issue Date: 2018-03-30</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/267">Context-Aware Recommender Systems for Learning: A Survey and Future Challenges, Verbert+,  IEEE TRANSACTIONS ON LEARNING TECHNOLOGIES, VOL. 5, NO. 4, OCTOBER-DECEMBER 2012</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/MatrixFactorization.html">#MatrixFactorization</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/225">Collaborative filtering for implicit feedback datasets, Hu+, International Conference on Data Mining, 2008</a>
<span class="snippet"><span>Comment</span>Implicit Feedbackなデータに特化したMatrix Factorization (MF)、Weighted Matrix Factorization (WMF)を提案。
ユーザのExplicitなFeedback（ratingやlike, dislikeなど）がなくても、MFが適用可能。

目的関数は下のようになっている。
通常のMFでは、ダイレクトにrating r_{ui}を予測したりするが、WMFでは r_{ui}をratingではなく、たとえばユーザuがアイテムiを消費した回数などに置き換え、binarizeした数値p_{ui}を目的関数に用いる。
このとき、itemを消費した回数が多いほど、そのユーザはそのitemを好んでいると仮定し、そのような事例については重みが高くなるようにc_{ui}を計算し、目的関数に導入している。

![image](https://user-images.githubusercontent.com/12249301/34815894-79edc89e-f6f6-11e7-9be5-0beacd724c23.png)
![image](https://user-images.githubusercontent.com/12249301/34815905-80e9f10e-f6f6-11e7-95bb-4ff0506134ad.png)
![image](https://user-images.githubusercontent.com/12249301/34815909-85c803dc-f6f6-11e7-87a8-8b7007f73524.png)
日本語での解説: https://cympfh.cc/paper/WRMFImplicit #324 でのAlternating Least Square (ALS)という手法が、この手法の実装に該当する。</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/NeuralNetwork.html">#NeuralNetwork</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/MatrixFactorization.html">#MatrixFactorization</a><a class="button" href="articles/SIGKDD.html">#SIGKDD</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-01-11</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/221">Collaborative Deep Learning for Recommender Systems Wang+, KDD’15</a>
<span class="snippet"><span>Comment</span>Rating Matrixからuserとitemのlatent vectorを学習する際に、Stacked Denoising Auto Encoder（SDAE）によるitemのembeddingを活用する話。
Collaborative FilteringとContents-based Filteringのハイブリッド手法。
Collaborative FilteringにおいてDeepなモデルを活用する初期の研究。

通常はuser vectorとitem vectorの内積の値が対応するratingを再現できるように目的関数が設計されるが、そこにitem vectorとSDAEによるitemのEmbeddingが近くなるような項（3項目）、SDAEのエラー（4項目）を追加する。

（3項目の意義について、解説ブログより）アイテム i に関する潜在表現 vi は学習データに登場するものについては推定できるけれど，未知のものについては推定できない．そこでSDAEの中間層の結果を「推定したvi」として「真の」 vi にできる限り近づける，というのがこの項の気持ち

cite-ulikeデータによる論文推薦、Netflixデータによる映画推薦で評価した結果、ベースライン（Collective Matrix Factorization #222 , SVDFeature #223 , DeepMusic #224 , Collaborative Topic Regresison #226 ）をoutperform。

![image](https://user-images.githubusercontent.com/12249301/34813194-58142a60-f6ec-11e7-938e-34b7d0cfb930.png)

![image](https://user-images.githubusercontent.com/12249301/34813227-786b9640-f6ec-11e7-8713-940433dc9e8f.png)

![image](https://user-images.githubusercontent.com/12249301/34813243-87832d28-f6ec-11e7-8371-fa60a54a1ba6.png)

![image](https://user-images.githubusercontent.com/12249301/34813251-91d5896a-f6ec-11e7-94ec-3b2c225ddf9a.png)

![image](https://user-images.githubusercontent.com/12249301/34813259-9b18b5e2-f6ec-11e7-98ae-1b5323b3e8b3.png)
解説ブログ：http://d.hatena.ne.jp/repose/20150531/1433004688</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/178">利用者の好みをとらえ活かす-嗜好抽出技術の最前線, 土方嘉徳, 2007</a>
<span class="snippet"><span>Comment</span>リンクがないため追記:
https://cir.nii.ac.jp/crid/1050001337898041856</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/174">推薦システムのアルゴリズム, 神嶌, 2016</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/173">A Survey on Challenges and Methods in News Recommendation, O¨zgo¨bek+, 2014</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/164">A Survey of Collaborative Filtering-Based Recommender Systems for Mobile Internet Applications, Yang+</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Survey.html">#Survey</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/163">A Survey and Critique of Deep Learning on Recommender Systems, Zheng</a>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Tools.html">#Tools</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/156">GraphChi</a>
<span class="snippet"><span>Comment</span>実装されているアルゴリズム：Matrix Factorization, RBM, CliMFなど
実装：
使用方法：CLI
※ graphlabの中の人による実装参考：
http://www.kamishima.net/archive/recsysdoc.pdf
https://takuti.me/note/recommender-libraries/</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Library.html">#Library</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/155">mrec</a>
<span class="snippet"><span>Comment</span>実装：python
※ Mendeleyによるpythonライブラリ参考：
http://www.kamishima.net/archive/recsysdoc.pdf
https://takuti.me/note/recommender-libraries/</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Tools.html">#Tools</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/154">GraphLab</a>
<span class="snippet"><span>Comment</span>現在はTuri.comになっており、商用になっている？参考：
http://www.kamishima.net/archive/recsysdoc.pdf
https://takuti.me/note/recommender-libraries/</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Tools.html">#Tools</a><a class="button" href="articles/Library.html">#Library</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/153">LensKit</a>
<span class="snippet"><span>Comment</span>実装されているアルゴリズム：協調フィルタリング、Matrix Factorizationなど
実装：Java
使用方法：コマンドライン、Javaライブラリとして利用
※ 推薦システム界隈で有名な、GroupLens研究グループによるJava実装参考：
http://www.kamishima.net/archive/recsysdoc.pdf
https://takuti.me/note/recommender-libraries/</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Tools.html">#Tools</a><a class="button" href="articles/Library.html">#Library</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/152">MyMediaLite</a>
<span class="snippet"><span>Comment</span>実装されているアルゴリズム：協調フィルタリング、Matrix Factorizationなど
実装：C#
使用方法：コマンドライン、C#ライブラリとして利用
※ ライブラリとして使用する場合は、C#による実装が必要参考：
http://www.kamishima.net/archive/recsysdoc.pdf
https://takuti.me/note/recommender-libraries/</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/Library.html">#Library</a><a class="button" href="articles/FactorizationMachines.html">#FactorizationMachines</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/151">fastFM</a>
<span class="snippet"><span>Comment</span>実装されているアルゴリズム：Factorization Machines
実装：python
使用方法：pythonライブラリとして利用
※ Factorization Machinesに特化したpythonライブラリ参考：
http://www.kamishima.net/archive/recsysdoc.pdf
https://takuti.me/note/recommender-libraries/</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Tools.html">#Tools</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/Library.html">#Library</a><a class="button" href="articles/FactorizationMachines.html">#FactorizationMachines</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/150">LibRec</a>
<span class="snippet"><span>Comment</span>実装されているアルゴリズム：協調フィルタリング、Factorization Machines、
　　　　　　　　　　　　　　Restricted Boltzman Machineなど、計70種類のアルゴリズムが実装
実装：Java
使用方法：コマンドライン、Javaライブラリとして利用
※ 実装されているアルゴリズムの豊富さが強み
※ 実装されているアルゴリズムのリスト（https://www.librec.net/dokuwiki/doku.php?id=AlgorithmList）参考：
http://www.kamishima.net/archive/recsysdoc.pdf
https://takuti.me/note/recommender-libraries/</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Library.html">#Library</a><br /><span class="issue_date">Issue Date: 2018-01-01</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/149">Surprise</a>
<span class="snippet"><span>Comment</span>実装されているアルゴリズム：協調フィルタリング、Matrix Factorizationなど
実装：python
使用方法：pythonライブラリとして利用
※ pythonで利用できる数少ない推薦システムライブラリ参考：
http://www.kamishima.net/archive/recsysdoc.pdf
https://takuti.me/note/recommender-libraries/</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/RelevanceJudgment.html">#RelevanceJudgment</a><br /><span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/52">Relevance Judgment in epistemic and hedonic information searches, Xu, Chen, Journal of the American Society for Information Science and Technology, 2007</a>
<span class="snippet"><span>Comment</span>・informative relevance: 知識を求める検索など（個人のブログ，経済ニュースとか）
・affective relevance: 楽しみや感情に刺激を受けるための情報を求める検索の場合（2chまとめとか，哲学ニュースまとめとか？）

・topicality, novelty, reliabilityがsignificantにinformative relevanceに寄与, scopeとunderstandabilityは寄与せず
・topicality, understandabilityがsignificantにaffective relevanceに寄与，しかし，noveltyはそうではなかった．</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Novelty.html">#Novelty</a><a class="button" href="articles/WI.html">#WI</a><br /><span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/47">Improving Recommendation Novelty Based on Topic Taxonomy, Weng et al., WI-IAT Workshops ‘07</a>
<span class="snippet"><span>Comment</span>・評価をしていない
・通常のItem-based collaborative filteringの結果に加えて，taxonomyのassociation rule mining (あるtaxonomy t1に興味がある人が，t2にも興味がある確率を獲得する)を行い，このassociation rule miningの結果をCFと組み合わせて，noveltyのある推薦をしようという話（従来のHybrid Recommender Systemsでは，contents-basedの手法を使うときはitem content similarityを使うことが多い．まあこれはよくあるcontents-basedなアプローチだろう）．
・documentの中のどの部分がnovelなのかとかを同定しているわけではない．taxonomyの観点からnovelだということ．</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/CollaborativeFiltering.html">#CollaborativeFiltering</a><a class="button" href="articles/Novelty.html">#Novelty</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/46">Discovery-oriented Collaborative Filtering for Improving User Satisfaction, Hijikata et al., IUI’09</a>
<span class="snippet"><span>Comment</span>・従来のCFはaccuracyをあげることを目的に研究されてきたが，ユーザがすでに知っているitemを推薦してしまう問題がある．おまけに（推薦リスト内のアイテムの観点からみた）diversityも低い．このような推薦はdiscoveryがなく，user satisfactionを損ねるので，ユーザがすでに何を知っているかの情報を使ってよりdiscoveryのある推薦をCFでやりましょうという話．
・特徴としてユーザのitemへのratingに加え，そのitemをユーザが知っていたかどうかexplicit feedbackしてもらう必要がある．
・手法は単純で，User-based，あるいはItem-based CFを用いてpreferenceとあるitemをユーザが知っていそうかどうかの確率を求め，それらを組み合わせる，あるいはrating-matrixにユーザがあるitemを知っていたか否かの数値を組み合わせて新たなmatrixを作り，そのmatrix上でCFするといったもの．
・offline評価の結果，通常のCF，topic diversification手法と比べてprecisionは低いものの，discovery ratioとprecision(novelty)は圧倒的に高い．
・ユーザがitemを知っていたかどうかというbinary ratingはユーザに負荷がかかるし，音楽推薦の場合previewがなければそもそも提供されていないからratingできないなど，必ずしも多く集められるデータではない．そこで，データセットのratingの情報を25%, 50%, 75%に削ってratingの数にbiasをかけた上で実験をしている．その結果，事前にratingをcombineし新たなmatrixを作る手法はratingが少ないとあまりうまくいかなかった．
・さらにonlineでuser satisfaction（3つの目的のもとsatisfactionをratingしてもらう　1. purchase 2. on-demand-listening 3. discovery）を評価した. 結果，purchaseとdiscoveryにおいては，ベースラインを上回った．ただし，これは推薦リスト中の満足したitemの数の問題で，推薦リスト全体がどうだった
　かと問われた場合は，ベースラインと同等程度だった．重要論文</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Novelty.html">#Novelty</a><a class="button" href="articles/RecSys.html">#RecSys</a><br /><span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/45">“I like to explore sometimes”: Adapting to Dynamic User Novelty Preferences, Kapoor et al. （with Konstan）, RecSys’15</a>
<span class="snippet"><span>Comment</span>・典型的なRSは，推薦リストのSimilarityとNoveltyのcriteriaを最適化する．このとき，両者のバランスを取るためになんらかの定数を導入してバランスをとるが，この定数はユーザやタイミングごとに異なると考えられるので（すなわち人やタイミングによってnoveltyのpreferenceが変化するということ），それをuserの過去のbehaviorからpredictするモデルを考えましたという論文．
・式中によくtが出てくるが，tはfamiliar setとnovel setをわけるためのみにもっぱら使われていることに注意．昼だとか夜だとかそういう話ではない．familiar setとは[t-T, t]の間に消費したアイテム，novel setはfamiliar setに含まれないitemのこと．
・データはmusic consumption logsを使う．last.fmやproprietary dataset．データにlistening以外のexplicit feedback (rating)などの情報はない
・itemのnoveltyの考え方はユーザ側からみるか，システム側から見るかで分類が変わる．三種類の分類がある． 

(a) new to system: システムにとってitemが新しい．ゆえにユーザは全員そのitemを知らない．
(b) new to user: システムはitemを知っているが，ユーザは知らない．
(c) oblivious/forgotten item: 過去にユーザが知っていたが，最後のconsumptionから時間が経過しいくぶんunfamiliarになったitem

Repetition of forgotten items in future consumptions has been shown to produce increased diversity and emotional excitement.

この研究では(b), (c)を対象とする．

・userのnovelty preferenceについて二つの仮定をおいている．
1. ユーザごとにnovelty preferenceは違う．
2. ユーザのnovelty preferenceはdynamicに変化する．trainingデータを使ってこの仮定の正しさを検証している．

・novelty preferenceのpredictは二種類の素性（familiar set diversityとcumulative negative preference for items in the familiar set）を使う. 前者は，familiar setの中のradioをどれだけ繰り返しきいているかを用いてdiversityを定義．繰り返し聞いているほうがdiversity低い．後者は，異なるitemの消費をする間隔によってdynamic preference scoreを決定．familiar set内の各itemについて負のdynamic preference scoreをsummationすることで，ユーザの”退屈度合い”を算出している．
・両素性を考慮することでnovelty preferenceのRMSEがsignificantに減少することを確認．
・推薦はNoveltyのあるitemの推薦にはHijikataらの協調フィルタリングなどを使うこともできる．
・しかし今回は簡易なitem-based CFを用いる．ratingの情報がないので，それはdynamic preference scoreを代わりに使い各itemのスコアを求め，そこからnovel recommendationとfamiliar recommendationのリストを生成し，novelty preferenceによって両者を組み合わせる．
・音楽（というより音楽のradioやアーティスト）の推薦を考えている状況なので，re-consumptionが許容されている．Newsなどとは少しドメインが違うことに注意．</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Document.html">#Document</a><a class="button" href="articles/SIGIR.html">#SIGIR</a><br /><span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/44">SCENE: A Scalable Two-Stage Personalized News Recommendation System, Li et al., SIGIR’11</a>
<span class="snippet"><span>Comment</span>・ニュース推薦には3つのチャレンジがある。

1. スケーラビリティ　より高速なreal-time processing
2. あるニュース記事を読むと、続いて読む記事に影響を与える
3. popularityとrecencyが時間経過に従い変化するので、これらをどう扱うか

これらに対処する手法を提案</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Document.html">#Document</a><br /><span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/43">A semantic-expansion approach to personalized knowledge recommendation, Liang, Yang, Chen and Ku, Decision Support Systems, 2007</a>
<span class="snippet"><span>Comment</span>・traditionalなkeywordベースでマッチングするアプローチだと，単語間の意味的な関係によって特定の単語のoverweightやunderweightが発生するので，advancedなsemanticsを考慮した手法が必要なので頑張りますという論文．</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Document.html">#Document</a><br /><span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/42">Combination of Web page recommender systems, Goksedef, Gunduz-oguducu, Elsevier, 2010</a>
<span class="snippet"><span>Comment</span>・traditionalなmethodはweb usage or web content mining techniquesを用いているが，ニュースサイトなどのページは日々更新されるのでweb content mining techniquesを用いてモデルを更新するのはしんどい．ので，web usage mining（CFとか？どちらかというとサーバログからassociation ruleを見つけるような手法か）にフォーカス．
・web usage miningに基づく様々な手法をhybridすることでどれだけaccuracyが改善するかみる．
・ユーザがセッションにおいて次にどのページを訪れるかをpredictし推薦するような枠組み（不特定多数のページを母集団とするわけではなく，自分のサイト内のページが母集団というパターンか）
・4種類の既存研究を紹介し，それらをどうcombineするかでaccuraryがどう変化しているかを見ている．
・それぞれの手法は，ユーザのsessionの情報を使いassociation rule miningやclusteringを行い次のページを予測する手法．</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/Document.html">#Document</a><br /><span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/41">Neural Networks for Web Content Filtering, 2002, Lee, Fui and Fong, IEEE Intelligent Systems</a>
<span class="snippet"><span>Comment</span>・ポルノコンテンツのフィルタリングが目的. 提案手法はgeneral frameworkなので他のコンテンツのフィルタリングにも使える.
・NNを採用する理由は，robustだから（様々な分布にfitする）．Webpageはnoisyなので．
・trainingのためにpornographic pageを1009ページ（13カテゴリから収集），non-pornographic pageを3,777ページ収集．
・feature（主なもの）
　- indicative term(ポルノっぽい単語)の頻度
　- displayed contents　ページのタイトル，warning message block, other viewable textから収集
　- non-displayed contents　descriptionやkeywordsなどのメタデータ，imageタグのtextなどから収集
・95%くらいのaccuracy</span>
<a class="button" href="articles/Article.html">#Article</a><a class="button" href="articles/PersonalizedDocumentSummarization.html">#PersonalizedDocumentSummarization</a><a class="button" href="articles/Admin'sPick.html">#Admin'sPick</a><br /><span class="issue_date">Issue Date: 2017-12-28</span>
<a href="https://github.com/AkihikoWatanabe/paper_notes/issues/8">User-model based personalized summarization, Diaz+, Information Processing and Management 2007.11</a>
<span class="snippet"><span>Comment</span>PDSの先駆けとなった重要論文。必ずreferすべき。</span>
<button onclick="hideContent(0)" style="display: none;">hide</button>
</div>


    </div>

</article>
<div class="post-nav"><a class="previous" href="/paper_notes/articles/RecSys.html" title="RecSysに関する論文・技術記事メモの一覧">RecSysに関する論文・技術記事メモの一覧</a><a class="next" href="/paper_notes/articles/Reference-based.html" title="Reference-basedに関する論文・技術記事メモの一覧">Reference-basedに関する論文・技術記事メモの一覧</a></div><div class="post-related">
      <div>Related Articles</div>
      <ul>
        <li class="">
          <a class="post-link"
            href="/paper_notes/articles/DiffusionModel.html"
            title="DiffusionModelに関する論文・技術記事メモの一覧">
            DiffusionModelに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li><li class="">
          <a class="post-link"
            href="/paper_notes/articles/GraphBased.html"
            title="GraphBasedに関する論文・技術記事メモの一覧">
            GraphBasedに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li><li class="">
          <a class="post-link"
            href="/paper_notes/articles/Finetuning.html"
            title="Finetuningに関する論文・技術記事メモの一覧">
            Finetuningに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li><li class="">
          <a class="post-link"
            href="/paper_notes/articles/HumanComputerInteraction.html"
            title="HumanComputerInteractionに関する論文・技術記事メモの一覧">
            HumanComputerInteractionに関する論文・技術記事メモの一覧<span class="post-badges">
  <span class="post-badge badge-top">TOP</span>
  <span class="post-badge badge-new">NEW</span>
</span>
</a>
        </li></ul>
    </div><div class="post-comments"></div></section>
</div>


  </section>
  <section class="sidebar" style="margin-left: 15px;">
    <!-- Get sidebar items --><style type="text/css" media="screen">
.post-menu ul {
  list-style: none;
  padding: 0;
  margin: 0;
}
</style>

<div class="post-menu">
  <div class="post-menu-title">TOC</div>
  <div class="post-menu-content"></div>
</div>

<script>
  function generateContent() {
    var menu = document.querySelector(".post-menu");
    var menuContent =  menu.querySelector(".post-menu-content");
    var headings = document.querySelector(".post-content").querySelectorAll("h2, h3, h4, h5, h6");

    // Hide menu when no headings
    if (headings.length === 0) {
      return menu.style.display = "none";
    }

    // Generate post menu
    var menuHTML = '';
    for (var i = 0; i < headings.length; i++) {
      var h = headings[i];
      menuHTML += (
        '<li class="h-' + h.tagName.toLowerCase() + '">'
        + '<a href="#h-' + h.getAttribute('id') + '">' + h.textContent + '</a></li>');
    }

    menuContent.innerHTML = '<ul>' + menuHTML + '</ul>';

    // The header element
    var header = document.querySelector('header.site-header');

    function doMenuCollapse(index, over_items) {
      var items = menuContent.firstChild.children;

      if (over_items == undefined) {
        over_items = 20;
      }

      if (items.length < over_items) {
        return;
      }

      var activeItem = items[index];
      var beginItem = activeItem
      var endItem = activeItem
      var beginIndex = index;
      var endIndex = index + 1;
      while (beginIndex >= 0
        && !items[beginIndex].classList.contains('h-h2')) {
        beginIndex -= 1;
      }
      while (endIndex < items.length
        && !items[endIndex].classList.contains('h-h2')) {
        endIndex += 1;
      }
      for (var i = 0; i < beginIndex; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
      for (var i = beginIndex + 1; i < endIndex; i++) {
        item = items[i]
        // if (!item.classList.contains('h-h2')) {
          item.style.display = '';
        // }
      }
      for (var i = endIndex; i < items.length; i++) {
        item = items[i]
        if (!item.classList.contains('h-h2')) {
          item.style.display = 'none';
        }
      }
    }

    // Init menu collapsed
    doMenuCollapse(-1);

    // Active the menu item
    window.addEventListener('scroll', function (event) {
      var lastActive = menuContent.querySelector('.active');
      var changed = true;
      var activeIndex = -1;
      for (var i = headings.length - 1; i >= 0; i--) {
        var h = headings[i];
        var headingRect = h.getBoundingClientRect();
        var headerRect = header.getBoundingClientRect();
        var headerTop = Math.floor(headerRect.top);
        var headerHeight = Math.floor(headerRect.height);
        var headerHeight = headerTop + headerHeight + 20;
        if (headingRect.top <= headerHeight) {
          var id = 'h-' + h.getAttribute('id');
          var a = menuContent.querySelector('a[href="#' + id  + '"]');
          var curActive = a.parentNode;
          if (curActive) {
            curActive.classList.add('active');
            activeIndex = i;
          }
          if (lastActive == curActive) {
            changed = false;
          }
          break;
        }
      }
      if (changed) {
        if (lastActive) {
          lastActive.classList.remove('active');
        }
        doMenuCollapse(activeIndex);
      }
      event.preventDefault();
    });
  }
  generateContent();
</script>
</section>
</div>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/paper_notes/"></data>

  <div class="wrapper">
    <div class="site-footer-inner"><div>Copyright © 2023-current AkihikoWATANABE. The header images and any thumbnail images for the posts were generated by ChatGPT's DALL-E3.</div>
      <div>Powered by <a title="Jekyll is a simple, blog-aware, static site
      generator." href="https://jekyllrb.com/">Jekyll</a> &amp; <a title="Yat, yet
      another theme." href="https://github.com/jeffreytse/jekyll-theme-yat">Yat Theme</a>.</div>
      <div class="footer-col rss-subscribe">Subscribe <a href="/paper_notes/feed.xml">via RSS</a></div>
    </div>
  </div>
</footer>
</body>
</html>
